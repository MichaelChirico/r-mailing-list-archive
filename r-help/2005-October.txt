From lisawang at uhnres.utoronto.ca  Sat Oct  1 00:14:23 2005
From: lisawang at uhnres.utoronto.ca (Lisa Wang)
Date: Fri, 30 Sep 2005 17:14:23 -0500
Subject: [R] How to get to the varable in a list
Message-ID: <433DB8BF.3E0E22C7@uhnres.utoronto.ca>

Hello,

I have a list "lis" as the following:

$"1"
  x1 x2
4  3  1

$"2"
  x1 x2
3  3  2
5  3  2

$"3"
  x1 x2
2  3  3
6  3  3

How do I get the x1 varible?  for example ss"1"

-------------- next part --------------
This e-mail may contain confidential and/or privileged information for the sole use of the intended recipient. Any review or distribution by anyone other than the person for whom it was originally intended is strictly prohibited. If you have received this e-mail in error, please contact the sender and delete all copies. Opinions, conclusions or other information contained in this e-mail may not be that of the organization.

From 8-T at gmx.net  Sat Oct  1 02:39:13 2005
From: 8-T at gmx.net (=?ISO-8859-1?Q?Ram=F3n_Casero_Ca=F1as?=)
Date: Sat, 01 Oct 2005 01:39:13 +0100
Subject: [R] update MASS
Message-ID: <433DDAB1.6050903@gmx.net>


I'd like to update MASS from version 7.2-11 to version 7-2.19. I am
running R 2.0.1 on ubuntu, that installs MASS with the package r-cran-vr.

I have tried doing update.packages(), and I get a list of packages that
I could update, but none is called MASS.

I have tried the following too, right after launching emacs, but to no
avail.

<QUOTE>
> update.packages("MASS")
trying URL `http://cran.r-project.org/src/contrib/PACKAGES'
Content type `text/plain; charset=iso-8859-1' length 65650 bytes
opened URL
==================================================
downloaded 64Kb

Error in old.packages(lib.loc = lib.loc, contriburl = contriburl, method
= method,  :
	no installed.packages for (invalid?) lib.loc=MASS
</QUOTE>


I have the package installed in /usr/lib/R/library/MASS. I can do

<QUOTE>
> library(MASS)
> search()
 [1] ".GlobalEnv"        "package:MASS"      "package:methods"
 [4] "package:stats"     "package:graphics"  "package:grDevices"
 [7] "package:utils"     "package:datasets"  "Autoloads"
[10] "package:base"
</QUOTE>


How could I update the package?

Thanks,

-- 
Ram??n Casero Ca??as

web:    http://www.robots.ox.ac.uk/~rcasero/



From diseasemodeler at yahoo.com  Sat Oct  1 03:40:55 2005
From: diseasemodeler at yahoo.com (David Hartley)
Date: Fri, 30 Sep 2005 18:40:55 -0700 (PDT)
Subject: [R] Inverse autocorrelation function?
Message-ID: <20051001014056.22981.qmail@web33103.mail.mud.yahoo.com>

In time series analysis it is helpful to plot the
autocorrelation function (ACF), partial
autocorrelation function (PACF), and the inverse
autocorrelation function (IACF). The stats library
provides the ability to compute and plot the ACF and
PACF, but I cannot find an [R] procedure to compute
and plot the IACF. Is there one? 

Best regards, 

David Hartley, PhD



From rab45+ at pitt.edu  Sat Oct  1 06:26:08 2005
From: rab45+ at pitt.edu (rab45+@pitt.edu)
Date: Sat, 01 Oct 2005 00:26:08 -0400 (EDT)
Subject: [R] R and Data Storage
Message-ID: <58553.209.195.160.60.1128140768.squirrel@webmail.pitt.edu>

Where I work a lot of people end up using Excel spreadsheets for storing
data. This has limitations and maybe some less than obvious problems. I'd
like to recommend a uniform way for storing and archiving data collected
in the department. Most of the data could be stored in simple csv type
files but it would be nice to have something that stores more information
about the variables and units. netcdf seems like overkill (and not easy
for casual users). Same for postgres and mysql databases. Could someone
recommend some system for storing relatively small data sets (50-100
variables, <1000 records) that would be reliable, safe, and easy for
people to view and edit their data that works nicely with R and is open
source? Am I asking for the moon?

Rick  B.



From tobias.verbeke at telenet.be  Sat Oct  1 10:36:56 2005
From: tobias.verbeke at telenet.be (Tobias Verbeke)
Date: Sat, 01 Oct 2005 10:36:56 +0200
Subject: [R] R and Data Storage
In-Reply-To: <58553.209.195.160.60.1128140768.squirrel@webmail.pitt.edu>
References: <58553.209.195.160.60.1128140768.squirrel@webmail.pitt.edu>
Message-ID: <433E4AA8.4040106@telenet.be>

rab45+ at pitt.edu wrote:

>Where I work a lot of people end up using Excel spreadsheets for storing
>data. This has limitations and maybe some less than obvious problems. I'd
>like to recommend a uniform way for storing and archiving data collected
>in the department. Most of the data could be stored in simple csv type
>files but it would be nice to have something that stores more information
>about the variables and units. netcdf seems like overkill (and not easy
>for casual users). Same for postgres and mysql databases. Could someone
>recommend some system for storing relatively small data sets (50-100
>variables, <1000 records) that would be reliable, safe, and easy for
>people to view and edit their data that works nicely with R and is open
>source? Am I asking for the moon?
>  
>
Would the StatDataML format meet your needs ?
It is open, XML-based, stores variable
types and works nicely with R (as R wizards designed
StatDataML and the corresponding R package).

See
http://cran.r-project.org/src/contrib/Descriptions/StatDataML.html
or
http://www.omegahat.org/StatDataML/

HTH,
Tobias



From ajayshah at mayin.org  Sat Oct  1 09:32:00 2005
From: ajayshah at mayin.org (Ajay Narottam Shah)
Date: Sat, 1 Oct 2005 13:02:00 +0530
Subject: [R] Placing axes label strings closer to the graph?
Message-ID: <20051001073200.GA2786@lubyanka.local>

Folks,

I have placed an example of a self-contained R program later in this
mail. It generates a file inflation.pdf. When I stare at the picture,
I see the "X label string" and "Y label string" sitting lonely and far
away from the axes. How can these distances be adjusted? I read ?par
and didn't find this directly.

I want to hang on to 2.8 x 2.8 inches as the overall size of graph,
but it will be nice if the inner square frame was bigger and thus the
axes were closer to the strings. I will be happy with (say)
par(mai=c(.6,.6,.2,.2)). But if I just do this, the "X label string"
and "Y label string" were lost.

Thanks,

        -ans.

D <- structure(list(dates = c(1983, 1984, 1985, 1986, 1987, 1988,
                      1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996,
                      1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004,
                      2005), inflation = c(7.6, 12.1, 6.3, 6.8, 8.7,
                               8.8, 9.4, 6.1, 11.6, 13.5, 9.6, 7.5, 10.1, 10.2,
                               9.3, 7, 13.1, 3.4, 3.7, 4.3, 4.1, 3.7, 4)),
               .Names = c("dates", "inflation"), row.names =
               c("1", "2", "3", "4", "5", "6", "7", "8", "9",
                 "10", "11", "12", "13", "14", "15", "16", "17",
                 "18", "19", "20", "21", "22", "23"), class =
               "data.frame")

pdf(file="inflation.pdf", width=2.8, height=2.8, bg="cadetblue1")
par(mai=c(0.8,0.8,0.2,0.2))
plot(D$dates, D$inflation, xlab="X label string", ylab="Y label string",
     type="l", lwd=2, col="cadetblue4", cex.axis=0.6, cex.lab=0.6)

-- 
Ajay Shah                                                   Consultant
ajayshah at mayin.org                      Department of Economic Affairs
http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi



From ripley at stats.ox.ac.uk  Sat Oct  1 12:01:53 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 1 Oct 2005 11:01:53 +0100 (BST)
Subject: [R] R-2.1.1 on AIX 5.*
In-Reply-To: <200509291642.20698.raphael.bolze@ens-lyon.fr>
References: <200509291642.20698.raphael.bolze@ens-lyon.fr>
Message-ID: <Pine.LNX.4.61.0510011056490.21972@gannet.stats>

Note your first error message is

> "connections.c", line 2580.18: 1506-052 (S) Duplicate case label for value 4.
> Labels must be unique.

and the relevant line is

#if SIZEOF_LONG == 8
             case sizeof(long):

so you have somehow got options to give you 4-byete longs although 
configure found 8-byte longs.  How you managed that is not clear from your 
output, and it has never been reported before.

Other people have succeeded on AIX 5.x, including with 2.2.0-beta.  Our 
advice would be to try the latter (since the 2.1.x branch is no longer 
under development), and to ask detailed programming questions in a 
suitable forum (an AIX forum, or R-devel where you are more likely to get 
a response).


On Thu, 29 Sep 2005, Raphael Bolze wrote:

> Hi,
>
> I need to install R-2.1.1 on a AIX machine. (i have tried several machine with
> different os version : 5.1, 5.2 and 5.3)
> I have tried several configuration which was advise on the R-install and admin
> section :
> but none goes to the end of compilation.
>
> my configure command line is :
> #>./configure --prefix=$HOME/local/R-2.1.1 CC=xlc_r CXX=xlC_r F77=xlf_r
> --without-x --without-readline OBJECT_MODE=64 LDFLAGS="-brtl" CFLAGS="-O
> -qstrict" FFLAGS="-O -qstrict" CXXFLAGS="-O -qstrict"
>
> then i compiled the source :
> #>make
> and i have the following error.
> making vsnprintf.d from vsnprintf.c
>        xlc_r -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H   -O -qstrict -c Rmain.c -o Rmain.o
>        xlc_r -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H   -O -qstrict -c CConverters.c -o
> CConverters.o
>        xlc_r -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H   -O -qstrict -c CommandLineArgs.c -o
> CommandLin
> eArgs.o
> "CommandLineArgs.c", line 170.32: 1506-1298 (W) The subscript 31 is out of
> range. The valid range is 0 to 30.
>        xlc_r -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H   -O -qstrict -c Rdynload.c -o
> Rdynload.o
>        xlc_r -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H   -O -qstrict -c Renviron.c -o
> Renviron.o
>        xlc_r -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H   -O -qstrict -c RNG.c -o RNG.o
>        xlc_r -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H   -O -qstrict -c apply.c -o apply.o
>        xlc_r -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H   -O -qstrict -c arithmetic.c -o
> arithmetic.o
>        xlc_r -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H   -O -qstrict -c apse.c -o apse.o
>        xlc_r -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H   -O -qstrict -c array.c -o array.o
>        xlc_r -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H   -O -qstrict -c attrib.c -o attrib.o
>        xlc_r -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H   -O -qstrict -c base.c -o base.o
>        xlc_r -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H   -O -qstrict -c bind.c -o bind.o
>        xlc_r -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H   -O -qstrict -c builtin.c -o builtin.o
>        xlc_r -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H   -O -qstrict -c character.c -o
> character.o
>        xlc_r -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H   -O -qstrict -c coerce.c -o coerce.o
>        xlc_r -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H   -O -qstrict -c colors.c -o colors.o
>        xlc_r -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H   -O -qstrict -c complex.c -o complex.o
>        xlc_r -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H   -O -qstrict -c connections.c -o
> connections.o
> "connections.c", line 2580.18: 1506-052 (S) Duplicate case label for value 4.
> Labels must be unique.
> "connections.c", line 2598.18: 1506-052 (S) Duplicate case label for value 4.
> Labels must be unique.
> "connections.c", line 2757.18: 1506-052 (S) Duplicate case label for value 4.
> Labels must be unique.
> "connections.c", line 2801.18: 1506-052 (S) Duplicate case label for value 4.
> Labels must be unique.
> make: 1254-004 The error code from the last command is 1.
>
>
> Stop.
> make: 1254-004 The error code from the last command is 2.
>
>
> Stop.
> make: 1254-004 The error code from the last command is 1.
>
>
> Stop.
> make: 1254-004 The error code from the last command is 1.
>
>
> Stop.
>
>
> Anyone can help me !
> Thanks for you help.
>
> Rapha?l BOLZE
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Sat Oct  1 12:12:53 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 1 Oct 2005 11:12:53 +0100 (BST)
Subject: [R] update MASS
In-Reply-To: <433DDAB1.6050903@gmx.net>
References: <433DDAB1.6050903@gmx.net>
Message-ID: <Pine.LNX.4.61.0510011105130.21972@gannet.stats>

On Sat, 1 Oct 2005, Ram?n Casero Ca?as wrote:

> I'd like to update MASS from version 7.2-11 to version 7-2.19. I am
> running R 2.0.1 on ubuntu, that installs MASS with the package r-cran-vr.

First, MASS is part of VR, so it is VR you update.

Second, please do *READ THE HELP PAGE*.  The first argument of 
update.packages() is not a package name.

Third, check the CRAN information, here at

 	http://cran.r-project.org/src/contrib/Descriptions/VR.html

and note

Depends:	R (>= 2.1.0), graphics, stats
                       ^^^^^

and no VR update is currently available for your version of R.

Your R is seriously only of date.  You might want to wait a week and then 
install 2.2.0.


> I have tried doing update.packages(), and I get a list of packages that
> I could update, but none is called MASS.
>
> I have tried the following too, right after launching emacs, but to no
> avail.
>
> <QUOTE>
>> update.packages("MASS")
> trying URL `http://cran.r-project.org/src/contrib/PACKAGES'
> Content type `text/plain; charset=iso-8859-1' length 65650 bytes
> opened URL
> ==================================================
> downloaded 64Kb
>
> Error in old.packages(lib.loc = lib.loc, contriburl = contriburl, method
> = method,  :
> 	no installed.packages for (invalid?) lib.loc=MASS
> </QUOTE>
>
>
> I have the package installed in /usr/lib/R/library/MASS. I can do
>
> <QUOTE>
>> library(MASS)
>> search()
> [1] ".GlobalEnv"        "package:MASS"      "package:methods"
> [4] "package:stats"     "package:graphics"  "package:grDevices"
> [7] "package:utils"     "package:datasets"  "Autoloads"
> [10] "package:base"
> </QUOTE>
>
>
> How could I update the package?
>
> Thanks,
>
> -- 
> Ram?n Casero Ca?as
>
> web:    http://www.robots.ox.ac.uk/~rcasero/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Sat Oct  1 12:28:02 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 1 Oct 2005 11:28:02 +0100 (BST)
Subject: [R] Placing axes label strings closer to the graph?
In-Reply-To: <20051001073200.GA2786@lubyanka.local>
References: <20051001073200.GA2786@lubyanka.local>
Message-ID: <Pine.LNX.4.61.0510011115450.21972@gannet.stats>

Use mtext() to put labels in the margin line you want.  title() writes 
xlab and ylab in line 3 AFAIR.  So you could use something like

par(mai=c(0.6,0.6,0.2,0.2))
plot(D$dates, D$inflation,
      type="l", lwd=2, col="cadetblue4", cex.axis=0.6)
mtext("X label string", 1, line=2, cex = 0.6)
mtext("Y label string", 2, line=2, cex = 0.6)

*However*, your error is to use cex to change the font size, not pointsize 
(which scales the lines suitably). Try instead

pdf(file="inflation.pdf", width=2.8, height=2.8, pointsize=6)
plot(D$dates, D$inflation, xlab="X label string", ylab="Y label string",
      type="l", lwd=2, col="cadetblue4")

On Sat, 1 Oct 2005, Ajay Narottam Shah wrote:

> Folks,
>
> I have placed an example of a self-contained R program later in this
> mail. It generates a file inflation.pdf. When I stare at the picture,
> I see the "X label string" and "Y label string" sitting lonely and far
> away from the axes. How can these distances be adjusted? I read ?par
> and didn't find this directly.
>
> I want to hang on to 2.8 x 2.8 inches as the overall size of graph,
> but it will be nice if the inner square frame was bigger and thus the
> axes were closer to the strings. I will be happy with (say)
> par(mai=c(.6,.6,.2,.2)). But if I just do this, the "X label string"
> and "Y label string" were lost.
>
> Thanks,
>
>        -ans.
>
> D <- structure(list(dates = c(1983, 1984, 1985, 1986, 1987, 1988,
>                      1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996,
>                      1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004,
>                      2005), inflation = c(7.6, 12.1, 6.3, 6.8, 8.7,
>                               8.8, 9.4, 6.1, 11.6, 13.5, 9.6, 7.5, 10.1, 10.2,
>                               9.3, 7, 13.1, 3.4, 3.7, 4.3, 4.1, 3.7, 4)),
>               .Names = c("dates", "inflation"), row.names =
>               c("1", "2", "3", "4", "5", "6", "7", "8", "9",
>                 "10", "11", "12", "13", "14", "15", "16", "17",
>                 "18", "19", "20", "21", "22", "23"), class =
>               "data.frame")
>
> pdf(file="inflation.pdf", width=2.8, height=2.8, bg="cadetblue1")
> par(mai=c(0.8,0.8,0.2,0.2))
> plot(D$dates, D$inflation, xlab="X label string", ylab="Y label string",
>     type="l", lwd=2, col="cadetblue4", cex.axis=0.6, cex.lab=0.6)
>
> -- 
> Ajay Shah                                                   Consultant
> ajayshah at mayin.org                      Department of Economic Affairs
> http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From john.maindonald at anu.edu.au  Sat Oct  1 12:32:58 2005
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sat, 1 Oct 2005 20:32:58 +1000
Subject: [R] Multiple expressions, when using substitute()
Message-ID: <AA4E55C3-34AF-491F-8F22-38F3441A1725@anu.edu.au>

expression() accepts multiple expressions as arguments, thus:

plot(1:2, 1:2)
legend("topleft",
               expression(y == a * x^b,
                                    "where "* paste(y=="wood; ",  
x=="dbh")))

Is there a way to do this when values are to be substituted
for a and b? i.e., the first element of the legend argument
to legend() becomes, effectively:
   substitute(y == a * x^b, list(a = B[1], b=B[2]))

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Bioinformation Science, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.



From roebuck at wotan.mdacc.tmc.edu  Sat Oct  1 13:07:45 2005
From: roebuck at wotan.mdacc.tmc.edu (Paul Roebuck)
Date: Sat, 1 Oct 2005 06:07:45 -0500 (CDT)
Subject: [R] X-Axis Label Overwritten By TickMark Values
Message-ID: <Pine.OSF.4.58.0510010546290.167927@odin.mdacc.tmc.edu>

Can someone tell me how to fix the left margin of plot region
such that the tick values don't overwrite the x-axis label?
I haven't been able to set the correct par option to fix this...

TIA

------------
grdev <- function(...) {
    get(getOption("device"))(...)
}

plotFixMe <- function(spectrum, ...) {
    saved.par <- par(las = 1, tcl = 0.3)
    on.exit(par(saved.par))

    plot(spectrum,
         type = "l",
         col  = "blue",
         xlab = "",
         ylab = "",
         ...)
    title(main = "x-axis label overwritten by tick values",
          xlab = "Index",
          ylab = "Intensity")
}

grdev()
plotFixMe(rnorm(50)*20000, ylim = c(0, 50000))

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From kjetil at redcotel.bo  Sat Oct  1 02:52:20 2005
From: kjetil at redcotel.bo (Kjetil Holuerson)
Date: Fri, 30 Sep 2005 20:52:20 -0400
Subject: [R] update MASS
In-Reply-To: <433DDAB1.6050903@gmx.net>
References: <433DDAB1.6050903@gmx.net>
Message-ID: <433DDDC4.5020305@redcotel.bo>

Ram??n Casero Ca??as wrote:
> I'd like to update MASS from version 7.2-11 to version 7-2.19. I am
> running R 2.0.1 on ubuntu, that installs MASS with the package r-cran-vr.
> 
My installed version of MASS, 7-2.20, has version requirement R>= 2.1.0,
so you will need to update R first.

Kjetil


> I have tried doing update.packages(), and I get a list of packages that
> I could update, but none is called MASS.
> 
> I have tried the following too, right after launching emacs, but to no
> avail.
> 
> <QUOTE>
>> update.packages("MASS")
> trying URL `http://cran.r-project.org/src/contrib/PACKAGES'
> Content type `text/plain; charset=iso-8859-1' length 65650 bytes
> opened URL
> ==================================================
> downloaded 64Kb
> 
> Error in old.packages(lib.loc = lib.loc, contriburl = contriburl, method
> = method,  :
> 	no installed.packages for (invalid?) lib.loc=MASS
> </QUOTE>
> 
> 
> I have the package installed in /usr/lib/R/library/MASS. I can do
> 
> <QUOTE>
>> library(MASS)
>> search()
>  [1] ".GlobalEnv"        "package:MASS"      "package:methods"
>  [4] "package:stats"     "package:graphics"  "package:grDevices"
>  [7] "package:utils"     "package:datasets"  "Autoloads"
> [10] "package:base"
> </QUOTE>
> 
> 
> How could I update the package?
> 
> Thanks,
> 



--



From nakama at ki.rim.or.jp  Sat Oct  1 14:19:28 2005
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Sat, 01 Oct 2005 21:19:28 +0900 (JST)
Subject: [R] R-2.1.1 on AIX 5.*
In-Reply-To: <200509291642.20698.raphael.bolze@ens-lyon.fr>
References: <200509291642.20698.raphael.bolze@ens-lyon.fr>
Message-ID: <20051001.211928.607964436.nakama@ki.rim.or.jp>

Hi,

> my configure command line is :
> #>./configure --prefix=$HOME/local/R-2.1.1 CC=xlc_r CXX=xlC_r F77=xlf_r 
> --without-x --without-readline OBJECT_MODE=64 LDFLAGS="-brtl" CFLAGS="-O 
                                 ^^^^^^^^^^^^^^
It is 64bit at the time of configure.

> then i compiled the source :
> #>make

It is 32bit at the time of make.
# OBJECT_MODE=64 is not set by an environmental variable.
--
EIJI Nakama



From f.harrell at vanderbilt.edu  Sat Oct  1 14:35:00 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sat, 01 Oct 2005 07:35:00 -0500
Subject: [R] R and Data Storage
In-Reply-To: <58553.209.195.160.60.1128140768.squirrel@webmail.pitt.edu>
References: <58553.209.195.160.60.1128140768.squirrel@webmail.pitt.edu>
Message-ID: <433E8274.2050508@vanderbilt.edu>

rab45+ at pitt.edu wrote:
> Where I work a lot of people end up using Excel spreadsheets for storing
> data. This has limitations and maybe some less than obvious problems. I'd
> like to recommend a uniform way for storing and archiving data collected
> in the department. Most of the data could be stored in simple csv type
> files but it would be nice to have something that stores more information
> about the variables and units. netcdf seems like overkill (and not easy
> for casual users). Same for postgres and mysql databases. Could someone
> recommend some system for storing relatively small data sets (50-100
> variables, <1000 records) that would be reliable, safe, and easy for
> people to view and edit their data that works nicely with R and is open
> source? Am I asking for the moon?
> 
> Rick  B.

What I use is the facilities in the Hmisc package, which handles 
variable labels and units of measurement and has functions for importing 
data (saving labels in the appropriate place) and making use of the 
attributes (e.g., combining labels and units with a smaller font for the 
units portion in an axis label).  When such an annotated data frame is 
saved using save(...., compress=TRUE), load()'ing it back will provide 
an annotated data frame, quickly.  The contents( ) function can show the 
attributes, and we use html(contents( )) to put up a web page with 
hyperlinks for value labels (factor variable levels attribute).

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From 8-T at gmx.net  Sat Oct  1 15:37:13 2005
From: 8-T at gmx.net (=?ISO-8859-1?Q?Ram=F3n_Casero_Ca=F1as?=)
Date: Sat, 01 Oct 2005 14:37:13 +0100
Subject: [R] update MASS
In-Reply-To: <Pine.LNX.4.61.0510011105130.21972@gannet.stats>
References: <433DDAB1.6050903@gmx.net>
	<Pine.LNX.4.61.0510011105130.21972@gannet.stats>
Message-ID: <433E9109.1000708@gmx.net>

Prof Brian Ripley wrote:
> On Sat, 1 Oct 2005, Ram??n Casero Ca??as wrote:
> 
>> I'd like to update MASS from version 7.2-11 to version 7-2.19. I am
>> running R 2.0.1 on ubuntu, that installs MASS with the package r-cran-vr.
> 
> 
> First, MASS is part of VR, so it is VR you update.

Thanks Prof Ripley, and Kjetil too, for your help. I am sure this was
obvious to anyone but me, but I found the wording in

http://www.stats.ox.ac.uk/pub/MASS4/Software.html#RUnix

a bit confusing. May I suggest that where it says ``To get the very
latest version, use update.packages() from an R session'', it could be
added: ``Note also that the current version of your R base system may
limit the update, i.e. if the R base system you are running is too old,
you will not be able to get the latest version of MASS. You can check
the dependencies of MASS from the <a
href="http://cran.r-project.org/src/contrib/Descriptions/VR.html">Description
file of VR at CRAN</a>''.

And maybe right before ``As the VR bundle is now recommended'' it could
say ``MASS does not have its own package, but comes bundled with other
libraries in a package called VR. Thus if you want to use/update MASS
you need to install/update VR''.

> Your R is seriously only of date.  You might want to wait a week and
> then install 2.2.0.

Searching a bit more I have found that this problem has been brought up
in the ubuntu forums

http://ubuntuforums.org/archive/index.php/t-49178.html

i.e. that the GNU R version is too old. As a temporal fix, it is
suggested to install the sarge .deb packages from
http://cran.r-project.org/ and then Linux/debian/stable, overlooking the
dependencies error with libc6.

I'll update to 2.2.0 in a week, but for the moment I did the former and
it seems to work with the code I was writting.

Cheers,

-- 
Ram??n Casero Ca??as

web:    http://www.robots.ox.ac.uk/~rcasero/



From phgrosjean at sciviews.org  Sat Oct  1 16:01:18 2005
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Sat, 01 Oct 2005 16:01:18 +0200
Subject: [R] Dots in function names
In-Reply-To: <433D922A.4010304@noaa.gov>
References: <433D7C3A.1030909@noaa.gov> <x2y85eidwn.fsf@turmalin.kubism.ku.dk>
	<433D922A.4010304@noaa.gov>
Message-ID: <433E96AE.4020309@sciviews.org>

Mike Prager wrote:
> on 9/30/2005 2:55 PM Peter Dalgaard said the following:
> 
> 
>>"Mike Prager" <Mike.Prager at noaa.gov> writes:
>> 
>>
>>
>>>Recent R function names seem to be using CaseOfTheLetters to mark words 
>>>rather than dots as was done previously.  Is the use of dots in function 
>>>names deprecated, or is that simply a style choice?  Will function names 
>>>with dots cause problems in future revisions?
>>>   
>>>
>>
>>Well, come the S4 revolution and dots will cause trouble no more...
>>
>>The main reason dots have fallen from grace is that they cause
>>ambiguity in relation to S3 methods. In a nutshell: t.test is not a
>>transpose method for objects of class "test". Since we check S3
>>methods automatically,  it is problematic to keep track of things that
>>look like S3 methods without being so. Check out
>>.make_S3_methods_stop_list() (in the tools package).
>>
> 
> My thanks to Thomas Lumley and Peter Dalgaard for their replies.  Being 
> skeptical about software revolutions, I infer that dots will be of some 
> concern for a long time.
> 
> At the same time, I expect that having names with underscores would 
> limit compatibility with S-PLUS. 
> 
> As a user, I have not encountered problems with dots, and I don't 
> understand whether the concern is likely to apply at the user level.  (I 
> was unable to locate the function that P.D. mentioned above.)  Sorry if 
> this seems dense, but I am not particularly conversant with the 
> internals of R nor experienced in object-oriented programming.
> 
> So while I understand Peter's example showing that dots can be 
> ambiguous, I am still at a loss as to whether that is of real practical 
> concern at a user level; for example, in writing functions that will 
> have limited distribution, or for functions that eventually may be 
> incorporated into an R package.  I am guessing not, but will appreciate 
> more comments if I have that wrong....
> 
> Mike Prager

For sure, for "writing functions that will have limited distribution", 
you can choice the convention that best suits you! Otherwise, the dot in 
functions poses other problems with S3 methods in situations like syntax 
highlighting and automatic code inspection. It is clear that everything 
would have been a lot easier if the dot was *only* used for S3 methods 
constructs. This is not the case. Nobody can change it now, and S4 is 
there that solves the problem in a different way. So, we leave pretty 
well with it until now. No reasons we cannot "survive" with it in the 
future too! ;-)
Best,

Philippe Grosjean



From qsb at nlbmol.ibp.ac.cn  Sat Oct  1 16:45:29 2005
From: qsb at nlbmol.ibp.ac.cn (Simple)
Date: Sat, 1 Oct 2005 22:45:29 +0800
Subject: [R] need suggestion about building formual
In-Reply-To: <433C35CF.50007@pdf.com>
References: <200509281428.38761.qsb@nlbmol.ibp.ac.cn> <433C35CF.50007@pdf.com>
Message-ID: <200510012245.29338.qsb@nlbmol.ibp.ac.cn>

Thanks for your kind respond. Although the answer didn't solve my question 
clearly,maybe I still not understand the art of R.

I'm sorry that I had not talked the problem clearly, maybe a example with more 
detail will be suitable as suggested in the the posting guide.
 
In function fitting program, such as Sigmaplot, a fitting formula, can be  
write in separate form:
G=a+(b*x)^(1/2)
k=exp((G-G0)/(R*T))
fit k to y

of course,in R's nls, can write as:
mynls<-nls(formula=y~exp((a+(b*x)^(1/2)-G0)/(R*T)),data=mydata,...)

In this example, the formula is simple and acceptable. However, when the 
formula is more complexity,writing all in one formula,the readability will be 
damaged.So I'm looking for a way to write simple and readable code in this 
situation.   

  
Spencer Graves wrote:
> 	  I'm not certain what you are asking.
>
> 	  You can build expressions in R as character strings and then execute
> them.  Example:
>
> expr <- paste("two <-", 1, "+", 1)
> eval(parse(text=expr))
> two
>
> 	  If this does not answer your question, PLEASE do read the posting
> guide, "www.R-project.org/posting-guide.html".  It can help increase the
> chances of a quick and useful reply.
>
> 	  spencer graves
>
> Simple wrote:
> > hi,
> > I'm an newbie for R,I want do some fitting in R.
> >
> > I wander if it is possible to write a few of equations but only one
> > formual when fitting
> >
> > Currently,My problem is,in R, is there methods combination a few
> > equations into one formual?
> > For example,
> > y=f1(k);
> > k=f2(t);
> > t=f3(x);
> > although it is certain that the can be equations turn into one formual as
> > y~f(x),but write such a complexity string make me painful.
> >
> > I have searched the web and found out there were only examples with one
> > formual.any suggestion?
> >
> > I hope that I have omit something.



From MSchwartz at mn.rr.com  Sat Oct  1 17:10:23 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Sat, 01 Oct 2005 10:10:23 -0500
Subject: [R] Multiple expressions, when using substitute()
In-Reply-To: <AA4E55C3-34AF-491F-8F22-38F3441A1725@anu.edu.au>
References: <AA4E55C3-34AF-491F-8F22-38F3441A1725@anu.edu.au>
Message-ID: <1128179423.4261.6.camel@localhost.localdomain>

On Sat, 2005-10-01 at 20:32 +1000, John Maindonald wrote:
> expression() accepts multiple expressions as arguments, thus:
> 
> plot(1:2, 1:2)
> legend("topleft",
>                expression(y == a * x^b,
>                                     "where "* paste(y=="wood; ",  
> x=="dbh")))
> 
> Is there a way to do this when values are to be substituted
> for a and b? i.e., the first element of the legend argument
> to legend() becomes, effectively:
>    substitute(y == a * x^b, list(a = B[1], b=B[2]))

John,

Try this:

a <- 5
b <- 3

L <- list(bquote(y == .(a) * x^.(b)),
          "where y = wood; x = dbh")

plot(1:2, 1:2)

legend(legend = do.call("expression", L),
       "topleft")


Note the creation of the list 'L', which uses bquote() and then
the .(Var) construct, where 'Var' are your variables to be replaced.
Then in the legend() call, the use of do.call() to apply expression() to
the elements of list 'L'.

HTH,

Marc Schwartz



From MSchwartz at mn.rr.com  Sat Oct  1 17:23:55 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Sat, 01 Oct 2005 10:23:55 -0500
Subject: [R] X-Axis Label Overwritten By TickMark Values
In-Reply-To: <Pine.OSF.4.58.0510010546290.167927@odin.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0510010546290.167927@odin.mdacc.tmc.edu>
Message-ID: <1128180235.4261.19.camel@localhost.localdomain>

On Sat, 2005-10-01 at 06:07 -0500, Paul Roebuck wrote:
> Can someone tell me how to fix the left margin of plot region
> such that the tick values don't overwrite the x-axis label?
> I haven't been able to set the correct par option to fix this...
> 
> TIA
> 
> ------------
> grdev <- function(...) {
>     get(getOption("device"))(...)
> }
> 
> plotFixMe <- function(spectrum, ...) {
>     saved.par <- par(las = 1, tcl = 0.3)
>     on.exit(par(saved.par))
> 
>     plot(spectrum,
>          type = "l",
>          col  = "blue",
>          xlab = "",
>          ylab = "",
>          ...)
>     title(main = "x-axis label overwritten by tick values",
>           xlab = "Index",
>           ylab = "Intensity")
> }
> 
> grdev()
> plotFixMe(rnorm(50)*20000, ylim = c(0, 50000))


Paul,

This is the Y axis label, not the X axis.

Set par("mar") prior to creating the plot to increase the left hand
margin space and then use mtext() rather than title() to move the Y axis
label further left by using the 'line' argument.


grdev <- function(...) {
    get(getOption("device"))(...)
}

plotFixMe <- function(spectrum, ...) {
    saved.par <- par(las = 1, tcl = 0.3)
    on.exit(par(saved.par))

    par(mar = c(5, 6, 4, 2))

    plot(spectrum,
         type = "l",
         col  = "blue",
         xlab = "",
         ylab = "",
         ...)

    title(main = "x-axis label overwritten by tick values")

    mtext(1, text = "Index", line = 3)
    mtext(2, text = "Intensity", line = 5, las = 3)
}

grdev()
plotFixMe(rnorm(50)*20000, ylim = c(0, 50000))


See ?par and ?mtext for more information.

BTW, I would not use 'tcl = 0.3' which, as a positive value, places the
tick marks themselves within the plot region. That's contrary to typical
guidance, since the tick marks get lost in this plot and more
importantly, can overwrite data points in certain plot types.

HTH,

Marc Schwartz



From janderson_net at yahoo.com  Sat Oct  1 17:59:40 2005
From: janderson_net at yahoo.com (James Anderson)
Date: Sat, 1 Oct 2005 08:59:40 -0700 (PDT)
Subject: [R] questions about R
Message-ID: <20051001155940.14710.qmail@web34005.mail.mud.yahoo.com>

Hi, 
  I am new to R. I have one question about outputing
files in a loop; Suppose I have the following loop:

for (i in 1:10) {
  temp = 100*2 matrix;
}
 I want to output the value of temp into 10 files with
each file containing the number of looping index (i.e,
file1.csv, file2.csv, ...) without headers. How can I
realize this? 
  Thanks.

  James



From ramasamy at cancer.org.uk  Sat Oct  1 19:17:34 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Sat, 01 Oct 2005 18:17:34 +0100
Subject: [R] List Email Statistic
In-Reply-To: <1128083531.7208.14.camel@localhost.localdomain>
References: <20050930044734.77405.qmail@web34203.mail.mud.yahoo.com>
	<1128083531.7208.14.camel@localhost.localdomain>
Message-ID: <1128187054.5890.4.camel@dhcp-123.wolf.ox.ac.uk>

This also depends on which field you are interested in, for example

 MEDSTATS  (http://tinyurl.com/bwha8)
 ED-STATS  (http://lists.psu.edu/archives/edstat-l.html)
and a few more http://tinyurl.com/a8wo4

Regards, Adai



On Fri, 2005-09-30 at 07:32 -0500, Marc Schwartz wrote:
> On Thu, 2005-09-29 at 23:47 -0500, JosÃ© Raul Capablanca wrote:
> > Dear All, 
> > How can I can to know a mail list , to speak about
> > exclusively statistic. Thanks. 
> 
> If you have access to Usenet either via an NNTP server or via Google
> Groups, there are three principal groups for general statistics
> discussion:
> 
>   sci.stat.consult (http://groups.google.com/group/sci.stat.consult)
>   sci.stat.math    (http://groups.google.com/group/sci.stat.math)
> 
>   sci.stat.edu     (http://groups.google.com/group/sci.stat.edu)
> 
> 
> There is a greater level of volume on the first two for general
> discussion. sci.stat.edu (which is targeted more to statistics education
> discussion) has been split off as a gateway to the edstat-L list, which
> has substantively reduced its daily volume.
> 
> HTH,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From MSchwartz at mn.rr.com  Sat Oct  1 18:21:54 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Sat, 01 Oct 2005 11:21:54 -0500
Subject: [R] questions about R
In-Reply-To: <20051001155940.14710.qmail@web34005.mail.mud.yahoo.com>
References: <20051001155940.14710.qmail@web34005.mail.mud.yahoo.com>
Message-ID: <1128183715.4261.35.camel@localhost.localdomain>

On Sat, 2005-10-01 at 08:59 -0700, James Anderson wrote:
> Hi, 
>   I am new to R. I have one question about outputing
> files in a loop; Suppose I have the following loop:
> 
> for (i in 1:10) {
>   temp = 100*2 matrix;
> }
>  I want to output the value of temp into 10 files with
> each file containing the number of looping index (i.e,
> file1.csv, file2.csv, ...) without headers. How can I
> realize this? 
>   Thanks.
> 
>   James

See ?write.table for the file creation and ?paste for creating the
filenames themselves:


for (i in 1:10) {
  temp = matrix(rnorm(200), ncol = 2)
  write.table(temp, file = paste("file", i, ".csv", sep = ""),
              row.names = FALSE, col.names = FALSE, sep = ",")
}


HTH,

Marc Schwartz



From MSchwartz at mn.rr.com  Sat Oct  1 18:41:33 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Sat, 01 Oct 2005 11:41:33 -0500
Subject: [R] List Email Statistic
In-Reply-To: <1128187054.5890.4.camel@dhcp-123.wolf.ox.ac.uk>
References: <20050930044734.77405.qmail@web34203.mail.mud.yahoo.com>
	<1128083531.7208.14.camel@localhost.localdomain>
	<1128187054.5890.4.camel@dhcp-123.wolf.ox.ac.uk>
Message-ID: <1128184893.4261.41.camel@localhost.localdomain>

Indeed.

I was not aware of the additional non-usenet statistics Google Groups.

Some familiar names on the MEDSTATS list...  :-)

Thanks Adai.

Marc

On Sat, 2005-10-01 at 18:17 +0100, Adaikalavan Ramasamy wrote:
> This also depends on which field you are interested in, for example
> 
>  MEDSTATS  (http://tinyurl.com/bwha8)
>  ED-STATS  (http://lists.psu.edu/archives/edstat-l.html)
> and a few more http://tinyurl.com/a8wo4
> 
> Regards, Adai
> 
> 
> 
> On Fri, 2005-09-30 at 07:32 -0500, Marc Schwartz wrote:
> > On Thu, 2005-09-29 at 23:47 -0500, JosÃ© Raul Capablanca wrote:
> > > Dear All, 
> > > How can I can to know a mail list , to speak about
> > > exclusively statistic. Thanks. 
> > 
> > If you have access to Usenet either via an NNTP server or via Google
> > Groups, there are three principal groups for general statistics
> > discussion:
> > 
> >   sci.stat.consult (http://groups.google.com/group/sci.stat.consult)
> >   sci.stat.math    (http://groups.google.com/group/sci.stat.math)
> > 
> >   sci.stat.edu     (http://groups.google.com/group/sci.stat.edu)
> > 
> > 
> > There is a greater level of volume on the first two for general
> > discussion. sci.stat.edu (which is targeted more to statistics education
> > discussion) has been split off as a gateway to the edstat-L list, which
> > has substantively reduced its daily volume.
> > 
> > HTH,
> > 
> > Marc Schwartz



From jimh at datagrove.com  Sat Oct  1 20:10:11 2005
From: jimh at datagrove.com (Jim Hurd)
Date: Sat, 1 Oct 2005 14:10:11 -0400
Subject: [R] help with loading National Comorbidity Survey
Message-ID: <BIG-REDwQG3Y2lQXW2c00000618@bigred.datagrove.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051001/c4a8b868/attachment.pl

From ripley at stats.ox.ac.uk  Sat Oct  1 21:25:29 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 1 Oct 2005 20:25:29 +0100 (BST)
Subject: [R] Regression slope confidence interval
In-Reply-To: <Pine.LNX.4.58.0509291229090.14546@egon.stats.ucl.ac.uk>
References: <Pine.LNX.4.58.0509291214060.14546@egon.stats.ucl.ac.uk>
	<433BCF47.9060900@optonline.net>
	<Pine.LNX.4.58.0509291229090.14546@egon.stats.ucl.ac.uk>
Message-ID: <Pine.LNX.4.61.0510012019350.32148@gannet.stats>

On Thu, 29 Sep 2005, Christian Hennig wrote:

>> ?confint
>>
>
> Thank you to all of you.
>
> As far as I see this is not mentioned on the lm help page (though I
> presumably don't have the recent version), which I would
> suggest...

and I would suggest that you study a good book on the subject.

(confint and its lm method come from MASS.  It is not specific to lm. 
There are lots of applicable generics not mentioned on the help pages of 
specific model-fitting functions.)

help.search("confidence interval") does get you there, for example.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sat Oct  1 22:02:47 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 1 Oct 2005 21:02:47 +0100 (BST)
Subject: [R] ACCESS R and dates
In-Reply-To: <20050930175351.2181F203FE@ws5-1.us4.outblaze.com>
References: <20050930175351.2181F203FE@ws5-1.us4.outblaze.com>
Message-ID: <Pine.LNX.4.61.0510012053430.32148@gannet.stats>

On Fri, 30 Sep 2005, sloan jones wrote:

> I have used the RODBC package to read in data I have stored in an Access 
> file. When I am using data from files other than ACCESS I have no 
> problem using the survival package to work with dates; however, with the 
> ACCESS data the dates are reading-in in the following format: 
> "2004-02-11 Pacific Standard Time". How do I remove the "Pacific 
> Standard Time" part in ACCESS or R so that I can coerce the data into a 
> workable format?  Any suggestions?

If this really is a character vector and not the result of printing a 
"Date" object, see ?strftime.  But you haven't told us anything like 
enough to go on.

As far as I know the survival package expects numeric values (e.g. of days 
or years) and not dates as implemented in R, except for survexp() which 
wants a different format, that of the 'dates' package (which it partially 
incorporates).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From xuhy at ucla.edu  Sat Oct  1 22:21:52 2005
From: xuhy at ucla.edu (Haiyong Xu)
Date: Sat, 01 Oct 2005 13:21:52 -0700
Subject: [R] dec2bin?
Message-ID: <433EEFE0.6050308@ucla.edu>

Hello,

I just want to ask if there is any function that can convert decimal 
number to binary vector.

Thanks a lot.
Haiyong



From roebuck at wotan.mdacc.tmc.edu  Sat Oct  1 23:00:45 2005
From: roebuck at wotan.mdacc.tmc.edu (Paul Roebuck)
Date: Sat, 1 Oct 2005 16:00:45 -0500 (CDT)
Subject: [R] Y-Axis Label Overwritten By TickMark Values
In-Reply-To: <1128180235.4261.19.camel@localhost.localdomain>
References: <Pine.OSF.4.58.0510010546290.167927@odin.mdacc.tmc.edu>
	<1128180235.4261.19.camel@localhost.localdomain>
Message-ID: <Pine.OSF.4.58.0510011419580.205016@odin.mdacc.tmc.edu>

On Sat, 1 Oct 2005, Marc Schwartz wrote:

> On Sat, 2005-10-01 at 06:07 -0500, Paul Roebuck wrote:
>
> > Can someone tell me how to fix the left margin of plot region
> > such that the tick values don't overwrite the x-axis label?
> > I haven't been able to set the correct par option to fix this...
>
> This is the Y axis label, not the X axis.

Oops. I'd been up all night...

> Set par("mar") prior to creating the plot to increase the left
> hand margin space and then use mtext() rather than title() to
> move the Y axis label further left by using the 'line' argument.
>
> [SNIP code]
>
> See ?par and ?mtext for more information.

What a black art. Pray tell where you learned this that I
may study there as well. In at least one of my prior attempts,
I had used par("mar") but hadn't realized that title(ylab)
would have to be changed; it just didn't seem (to me anyway)
like wanting to display slightly larger numbers as tickmark
values would have required using other low-level plot commands.

After about a hour of trying different options, I found myself
really wanting to use the "R Plot Wizard(TM)" that lets you
interactively set the LAF of the plot, then generates the
appropriate R code to make it so.

> BTW, I would not use 'tcl = 0.3' which, as a positive value,
> places the tick marks themselves within the plot region.
> That's contrary to typical guidance, since the tick marks
> get lost in this plot and more importantly, can overwrite
> data points in certain plot types.

Was emulating Matlab's plot output and that's how it places
tickmarks (for better or worse). I actually needed to place
tickmarks on all sides but hadn't found that option yet.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From goran.brostrom at gmail.com  Sat Oct  1 23:19:00 2005
From: goran.brostrom at gmail.com (=?UTF-8?Q?G=C3=B6ran_Brostr=C3=B6m?=)
Date: Sat, 1 Oct 2005 23:19:00 +0200
Subject: [R] cox proportional-hazards regress for interval censor data
In-Reply-To: <BAY101-F3271A5440706E684B9E602DD8C0@phx.gbl>
References: <BAY101-F3271A5440706E684B9E602DD8C0@phx.gbl>
Message-ID: <148ed8180510011419595978d2@mail.gmail.com>

On 9/29/05, Lixia ZHU <lixiazhu at hotmail.com> wrote:
> Hi. I used coxph(surv(start,end,event)~~event,data) to deal with interval
> censor data.

Did it work;)? I guess the answer is No. First, 'surv' is not a
recognized function (I know of).
Second, the ~~ look weird. And, relating a survival object to an event
indicator, what relation do you mean it has to 'interval censor data'?

You have to give more detail and be more precise in order to get a
valuable answer.
--
GÃ¶ran BrostrÃ¶m



From ripley at stats.ox.ac.uk  Sat Oct  1 23:44:29 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 1 Oct 2005 22:44:29 +0100 (BST)
Subject: [R] dec2bin?
In-Reply-To: <433EEFE0.6050308@ucla.edu>
References: <433EEFE0.6050308@ucla.edu>
Message-ID: <Pine.LNX.4.61.0510012236480.813@gannet.stats>

On Sat, 1 Oct 2005, Haiyong Xu wrote:

> I just want to ask if there is any function that can convert decimal
> number to binary vector.

What do you mean by a binary vector?  Function intToBits might be what you 
are looking for, e.g.

> x <- as.integer(1234)
> y <- intToBits(x)
> options(width=50)
> y
  [1] 00 01 00 00 01 00 01 01 00 00 01 00 00 00 00
[16] 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
[31] 00 00
> z <- paste((0:1)[1+ (rev(y) == 1)], collapse="")
> z
[1] "00000000000000000000010011010010"
> gsub("^0*", "", z)
[1] "10011010010"

Do any of these give what you are looking for?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sat Oct  1 23:56:42 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 1 Oct 2005 22:56:42 +0100 (BST)
Subject: [R] Y-Axis Label Overwritten By TickMark Values
In-Reply-To: <Pine.OSF.4.58.0510011419580.205016@odin.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0510010546290.167927@odin.mdacc.tmc.edu>
	<1128180235.4261.19.camel@localhost.localdomain>
	<Pine.OSF.4.58.0510011419580.205016@odin.mdacc.tmc.edu>
Message-ID: <Pine.LNX.4.61.0510012244380.813@gannet.stats>

On Sat, 1 Oct 2005, Paul Roebuck wrote:

> On Sat, 1 Oct 2005, Marc Schwartz wrote:
>
>> On Sat, 2005-10-01 at 06:07 -0500, Paul Roebuck wrote:
>>
>>> Can someone tell me how to fix the left margin of plot region
>>> such that the tick values don't overwrite the x-axis label?
>>> I haven't been able to set the correct par option to fix this...
>>
>> This is the Y axis label, not the X axis.
>
> Oops. I'd been up all night...
>
>> Set par("mar") prior to creating the plot to increase the left
>> hand margin space and then use mtext() rather than title() to
>> move the Y axis label further left by using the 'line' argument.
>>
>> [SNIP code]
>>
>> See ?par and ?mtext for more information.
>
> What a black art. Pray tell where you learned this that I
> may study there as well.

The basic manual `An Introduction to R' is where we expect all new users 
to R to learn of the existence of such things: for historical reasons it 
takes the S/R graphics model further than most other topics.

There is an expanded version of that material and several examples in 
MASS4 (just consult the index), and a similar level/depth of coverage in 
Paul Murrell's book on R Graphics.

(Full details of all these sources are found in the FAQ.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From MSchwartz at mn.rr.com  Sun Oct  2 00:03:25 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Sat, 01 Oct 2005 17:03:25 -0500
Subject: [R] Y-Axis Label Overwritten By TickMark Values
In-Reply-To: <Pine.OSF.4.58.0510011419580.205016@odin.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0510010546290.167927@odin.mdacc.tmc.edu>
	<1128180235.4261.19.camel@localhost.localdomain>
	<Pine.OSF.4.58.0510011419580.205016@odin.mdacc.tmc.edu>
Message-ID: <1128204205.4261.65.camel@localhost.localdomain>

On Sat, 2005-10-01 at 16:00 -0500, Paul Roebuck wrote:
> On Sat, 1 Oct 2005, Marc Schwartz wrote:
> 
> > On Sat, 2005-10-01 at 06:07 -0500, Paul Roebuck wrote:
> >
> > > Can someone tell me how to fix the left margin of plot region
> > > such that the tick values don't overwrite the x-axis label?
> > > I haven't been able to set the correct par option to fix this...
> >
> > This is the Y axis label, not the X axis.
> 
> Oops. I'd been up all night...

Been there, done that...  ;-)

> > Set par("mar") prior to creating the plot to increase the left
> > hand margin space and then use mtext() rather than title() to
> > move the Y axis label further left by using the 'line' argument.
> >
> > [SNIP code]
> >
> > See ?par and ?mtext for more information.
> 
> What a black art. Pray tell where you learned this that I
> may study there as well. In at least one of my prior attempts,
> I had used par("mar") but hadn't realized that title(ylab)
> would have to be changed; it just didn't seem (to me anyway)
> like wanting to display slightly larger numbers as tickmark
> values would have required using other low-level plot commands.


Look under the Documentation/Manuals link on the R Home page and read
through "An Introduction to R". That's the place to start.

Searching the e-mail list archives is yet another resource:

 http://finzi.psych.upenn.edu/search.html

There is also a relatively new R Graphics Gallery (with code) here:

  http://addictedtor.free.fr/graphiques/index.php


<shameless plug>

  Paul Murrell's new book "R Graphics"

  More info here:

    http://www.stat.auckland.ac.nz/~paul/RGraphics/rgraphics.html

</shameless plug>



> After about a hour of trying different options, I found myself
> really wanting to use the "R Plot Wizard(TM)" that lets you
> interactively set the LAF of the plot, then generates the
> appropriate R code to make it so.

No MS-like Wizards here...Only the intelligent human ones  ;-)

> > BTW, I would not use 'tcl = 0.3' which, as a positive value,
> > places the tick marks themselves within the plot region.
> > That's contrary to typical guidance, since the tick marks
> > get lost in this plot and more importantly, can overwrite
> > data points in certain plot types.
> 
> Was emulating Matlab's plot output and that's how it places
> tickmarks (for better or worse). I actually needed to place
> tickmarks on all sides but hadn't found that option yet.

I'd say for worse...See Cleveland and/or Tufte for references. There is
a foundational reason for the way R does things: Sensible Defaults.

See ?axis (using 'side = 3' and 'side = 4') for more information here.

HTH,

Marc Schwartz



From sapsi at pobox.com  Sun Oct  2 05:10:19 2005
From: sapsi at pobox.com (Saptarshi Guha)
Date: Sat, 1 Oct 2005 22:10:19 -0500
Subject: [R] How to load user defined functions written in another file
Message-ID: <DA890603-310A-4981-B62E-85D47A3DA537@pobox.com>

Hello,
     This is most probably basic, but i simply couldn't find the answer.
I have written a function in a separate file multi.r, and would like  
to load this into the R-IDE so that I can use my function.
How do i go about it?

Thank you in advance.
Saptarshi


Saptarshi Guha|sapsi at pobox.com|http://blue.chem.psu.edu/~saptarshi



From sapsi at pobox.com  Sun Oct  2 05:23:31 2005
From: sapsi at pobox.com (Saptarshi Guha)
Date: Sat, 1 Oct 2005 22:23:31 -0500
Subject: [R] How to load user defined functions written in another file
In-Reply-To: <DA890603-310A-4981-B62E-85D47A3DA537@pobox.com>
References: <DA890603-310A-4981-B62E-85D47A3DA537@pobox.com>
Message-ID: <E47544FC-8E84-4273-84B5-183C81F8822C@pobox.com>

Hello,
     I'm sorry for the silly question. Just found out how. Use 'source'.

Thanks for your time.
Saptarshi


On Oct 1, 2005, at 10:10 PM, Saptarshi Guha wrote:

> Hello,
>      This is most probably basic, but i simply couldn't find the  
> answer.
> I have written a function in a separate file multi.r, and would like
> to load this into the R-IDE so that I can use my function.
> How do i go about it?



From e.rapsomaniki at mail.cryst.bbk.ac.uk  Sun Oct  2 11:04:28 2005
From: e.rapsomaniki at mail.cryst.bbk.ac.uk (e.rapsomaniki@mail.cryst.bbk.ac.uk)
Date: Sun,  2 Oct 2005 10:04:28 +0100
Subject: [R] convering upper triangular matrix into vector
Message-ID: <1128243868.433fa29c83ad0@webmail.cryst.bbk.ac.uk>

Hi

I have two symmetrical distance matrices and want to compute the correlation
coefficient between them (after turning them into vectors). 

Is there a way of selecting only the upper triangular part of each matrix, then
convert this into a vector so I can compute the correlation?

Many Thanks
Eleni Rapsomaniki



From p.dalgaard at biostat.ku.dk  Sun Oct  2 12:16:52 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 02 Oct 2005 12:16:52 +0200
Subject: [R] convering upper triangular matrix into vector
In-Reply-To: <1128243868.433fa29c83ad0@webmail.cryst.bbk.ac.uk>
References: <1128243868.433fa29c83ad0@webmail.cryst.bbk.ac.uk>
Message-ID: <x2br289qaz.fsf@turmalin.kubism.ku.dk>

e.rapsomaniki at mail.cryst.bbk.ac.uk writes:

> Hi
> 
> I have two symmetrical distance matrices and want to compute the correlation
> coefficient between them (after turning them into vectors). 
> 
> Is there a way of selecting only the upper triangular part of each matrix, then
> convert this into a vector so I can compute the correlation?

X[upper.tri(X)]

(as help.search("triangular") would have told you soon enough)

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From dimitris.rizopoulos at med.kuleuven.be  Sun Oct  2 12:24:56 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Sun, 2 Oct 2005 12:24:56 +0200
Subject: [R] convering upper triangular matrix into vector
References: <1128243868.433fa29c83ad0@webmail.cryst.bbk.ac.uk>
Message-ID: <01da01c5c73b$88e1e270$0540210a@www.domain>

look at: '?upper.tri()'

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: <e.rapsomaniki at mail.cryst.bbk.ac.uk>
To: <R-help at stat.math.ethz.ch>
Sent: Sunday, October 02, 2005 11:04 AM
Subject: [R] convering upper triangular matrix into vector


> Hi
>
> I have two symmetrical distance matrices and want to compute the 
> correlation
> coefficient between them (after turning them into vectors).
>
> Is there a way of selecting only the upper triangular part of each 
> matrix, then
> convert this into a vector so I can compute the correlation?
>
> Many Thanks
> Eleni Rapsomaniki
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From tokkass at yahoo.com  Sun Oct  2 12:36:37 2005
From: tokkass at yahoo.com (toka tokas)
Date: Sun, 2 Oct 2005 03:36:37 -0700 (PDT)
Subject: [R] plot question when type = "b" and pch is a vector
Message-ID: <20051002103637.19080.qmail@web35304.mail.mud.yahoo.com>

Dear R users,

I've been struggling some days with the following
problem: I'm interesting in producing the following
plot

x <- seq(0.01, 10, length = 20)

plot(c(0, 10), c(-20, 20), type = "n", xlab = "x", 
        ylab = expression(2 * alpha * log(x)))

pch. <- rep(NA, length(x))
for(i in 1:4){
    pch.[7] <- as.character(i)
    lines(x, 2 * i * log(x), type = "b", pch = pch.,
lty = 1)
}

where all the line segments are connected, except from
the 7th one where I've put the value of alpha -- in
other words I'd like to produce a line plot where the
label appears at each line with some white space
around it.

thanks in advance,
tokas



From sekemp at glam.ac.uk  Sun Oct  2 12:55:22 2005
From: sekemp at glam.ac.uk (Kemp S E (Comp))
Date: Sun, 2 Oct 2005 11:55:22 +0100
Subject: [R] arima.sim bug?
Message-ID: <0BA7EE4D4646E0409D458D347C508B780128013D@MAILSERV1.uni.glam.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051002/42452ff4/attachment.pl

From pcavatore at yahoo.it  Sun Oct  2 11:25:10 2005
From: pcavatore at yahoo.it (Paolo Cavatore)
Date: Sun, 2 Oct 2005 11:25:10 +0200
Subject: [R] modeling language for optimization problems
Message-ID: <019b01c5c74a$945198d0$7d5a0a3e@paolodell>

Does anyone know whether R has its own modeling language for optimization 
problems (like SIMPLE in NuOPT for S-plus)?

Paolo



From sundar.dorai-raj at pdf.com  Sun Oct  2 14:24:26 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Sun, 02 Oct 2005 07:24:26 -0500
Subject: [R] arima.sim bug?
In-Reply-To: <0BA7EE4D4646E0409D458D347C508B780128013D@MAILSERV1.uni.glam.ac.uk>
References: <0BA7EE4D4646E0409D458D347C508B780128013D@MAILSERV1.uni.glam.ac.uk>
Message-ID: <433FD17A.7040404@pdf.com>



Kemp S E (Comp) wrote:
> Hi,
> 
> I am using the arima.sim function to generate some AR time series. However, the function does not seem to produce exactly the same time series when I specify the innov parameter. For example
> 
> 
>>r <- rnorm(300)
>>x <- arima.sim(300, model=list(order=c(1,0,0),ar=c(.96)), innov=r, n.start=10)
>>y <- arima.sim(300, model=list(order=c(1,0,0),ar=c(.96)), innov=r, n.start=10)
> 
> 
>>x[1:10]
> 
> [1] 3.194806 4.214894 5.168017 7.925152 8.810817 9.131695
>  [7] 7.521283 8.266911 8.923429 9.651293
> 
> 
>>y[1:10]
> 
> [1] -0.7202632  0.4564274  1.5598893  4.4613486
>  [5]  5.4855660  5.9394547  4.4567320  5.3249417
>  [9]  6.0991390  6.9399748
> 
> Given the fact that I have provided the innovations shouldn't the time series be exactly the same?
> 
> Any help would be greatly appreciated.
> 
> All the best,
> 
> Sam.
> 

Not a bug, but a difference in seeds. Try:

set.seed(1)
r <- rnorm(300)
m <- list(order = c(1,0,0), ar = c(.96))
set.seed(1)
x <- arima.sim(300, model = m, innov = r, n.start = 10)
set.seed(1)
y <- arima.sim(300, model = m, innov = r, n.start = 10)

all.equal(x, y)
# [1] TRUE

HTH,

--sundar



From jfox at mcmaster.ca  Sun Oct  2 15:18:38 2005
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 2 Oct 2005 09:18:38 -0400
Subject: [R] plot question when type = "b" and pch is a vector
In-Reply-To: <20051002103637.19080.qmail@web35304.mail.mud.yahoo.com>
Message-ID: <20051002131837.OOGB26550.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear tokas,

How about:

x <- seq(0.01, 10, length = 20)
xx <- x[7]
x[7] <- NA

plot(c(0, 10), c(-20, 20), type = "n", xlab = "x", 
        ylab = expression(2 * alpha * log(x)))
for(i in 1:4){
    lines(x, 2 * i * log(x), lty = 1)
    text(xx,  2 * i * log(xx), i)     
    }

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of toka tokas
> Sent: Sunday, October 02, 2005 5:37 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] plot question when type = "b" and pch is a vector
> 
> Dear R users,
> 
> I've been struggling some days with the following
> problem: I'm interesting in producing the following plot
> 
> x <- seq(0.01, 10, length = 20)
> 
> plot(c(0, 10), c(-20, 20), type = "n", xlab = "x", 
>         ylab = expression(2 * alpha * log(x)))
> 
> pch. <- rep(NA, length(x))
> for(i in 1:4){
>     pch.[7] <- as.character(i)
>     lines(x, 2 * i * log(x), type = "b", pch = pch., lty = 1) }
> 
> where all the line segments are connected, except from the 
> 7th one where I've put the value of alpha -- in other words 
> I'd like to produce a line plot where the label appears at 
> each line with some white space around it.
> 
> thanks in advance,
> tokas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Sun Oct  2 16:15:49 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 02 Oct 2005 16:15:49 +0200
Subject: [R] How to get to the varable in a list
In-Reply-To: <433DB8BF.3E0E22C7@uhnres.utoronto.ca>
References: <433DB8BF.3E0E22C7@uhnres.utoronto.ca>
Message-ID: <433FEB95.4000504@statistik.uni-dortmund.de>

Lisa Wang wrote:

> Hello,
> 
> I have a list "lis" as the following:
> 
> $"1"
>   x1 x2
> 4  3  1
> 
> $"2"
>   x1 x2
> 3  3  2
> 5  3  2
> 
> $"3"
>   x1 x2
> 2  3  3
> 6  3  3
> 
> How do I get the x1 varible?  for example ss"1"


I can only guess you mean something like

   lis[[1]][["x1"]]


Uwe Ligges



> 
> 
> ------------------------------------------------------------------------
> 
> This e-mail may contain confidential and/or privileged inf...{{dropped}}



From ripley at stats.ox.ac.uk  Sun Oct  2 16:33:47 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 2 Oct 2005 15:33:47 +0100 (BST)
Subject: [R] User error (was arima.sim bug?)
In-Reply-To: <0BA7EE4D4646E0409D458D347C508B780128013D@MAILSERV1.uni.glam.ac.uk>
References: <0BA7EE4D4646E0409D458D347C508B780128013D@MAILSERV1.uni.glam.ac.uk>
Message-ID: <Pine.LNX.4.61.0510021528520.17389@gannet.stats>

On Sun, 2 Oct 2005, Kemp S E (Comp) wrote:

> Hi,
>
> I am using the arima.sim function to generate some AR time series. 
> However, the function does not seem to produce exactly the same time 
> series when I specify the innov parameter. For example
>
>> r <- rnorm(300)
>> x <- arima.sim(300, model=list(order=c(1,0,0),ar=c(.96)), innov=r, n.start=10)
>> y <- arima.sim(300, model=list(order=c(1,0,0),ar=c(.96)), innov=r, n.start=10)
>
>> x[1:10]
> [1] 3.194806 4.214894 5.168017 7.925152 8.810817 9.131695
> [7] 7.521283 8.266911 8.923429 9.651293
>
>> y[1:10]
> [1] -0.7202632  0.4564274  1.5598893  4.4613486
> [5]  5.4855660  5.9394547  4.4567320  5.3249417
> [9]  6.0991390  6.9399748
>
> Given the fact that I have provided the innovations shouldn't the time 
> series be exactly the same?

No.  Hint: where does the randomness for the burn-in come from?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sun Oct  2 16:37:32 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 2 Oct 2005 15:37:32 +0100 (BST)
Subject: [R] modeling language for optimization problems
In-Reply-To: <019b01c5c74a$945198d0$7d5a0a3e@paolodell>
References: <019b01c5c74a$945198d0$7d5a0a3e@paolodell>
Message-ID: <Pine.LNX.4.61.0510021534250.17389@gannet.stats>

On Sun, 2 Oct 2005, Paolo Cavatore wrote:

> Does anyone know whether R has its own modeling language for optimization
> problems (like SIMPLE in NuOPT for S-plus)?

No.  Note that SIMPLE is the language of NUOPT, not of S-PLUS.  There is 
an (extra-cost) interface module S+NUOPT, but it is an interface to 
NUOPT's engine.

As far as I am aware R itself covers almost none of the ground of S+NUOPT, 
and available packages cover only a small part of it.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From stgries at arcor.de  Sun Oct  2 16:46:43 2005
From: stgries at arcor.de (stgries@arcor.de)
Date: Sun, 2 Oct 2005 16:46:43 +0200 (CEST)
Subject: [R] Size of jpegs/pngs
Message-ID: <31587199.1128264403171.JavaMail.ngmail@webmail-03.arcor-online.net>

Dear all

I have trouble with setting the size for jpegs and pngs. I need to save a dendrogram of 1000 words into a jpeg or png file. On one of my computers, the following works just fine: 

bb<-agnes(aa, method="ward")
jpeg("C:/Temp/test.txt", width=17000, height=2000)
plot(bb)
dev.off()

On my main computer, however, this doesn't work:
> jpeg("C:/Temp/test.txt", width=17000, height=2000)
Error in jpeg("C:/Temp/test.txt", width = 17000, height = 2000) : 
        unable to start device devWindows
In addition: Warning message:
Unable to allocate bitmap 

This is a Windows XP Pro SP2 system, which is started with this chsort
> R.version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    1.1            
year     2005           
month    06             
day      20             
language R  

which is started with a shortcut.
"C:\rw2011\bin\Rgui.exe --max-mem-size=1500M"

I checked the web and the R-help pages, tried out the ppsize option, and compared the options settings with those of the machine that works (which actually runs R 2.0.1 of 15 Nov 2004), but couldn't come up with an explanation. Any idea what I do wrong?
STG
--
Stefan Th. Gries
----------------------------------------
Max Planck Inst. for Evol. Anthropology
http://people.freenet.de/Stefan_Th_Gries
----------------------------------------

Machen Sie aus 14 Cent spielend bis zu 100 Euro!
Die neue Gaming-Area von Arcor - ??ber 50 Onlinespiele im Angebot.
http://www.arcor.de/rd/emf-gaming-1



From henric.nilsson at statisticon.se  Sun Oct  2 17:47:25 2005
From: henric.nilsson at statisticon.se (Henric Nilsson)
Date: Sun, 02 Oct 2005 17:47:25 +0200
Subject: [R] p-level in packages mgcv and gam
In-Reply-To: <AC705FBD-B408-4BC1-89B8-9727C1571A3D@globetrotter.net>
References: <mailman.10.1127988001.20586.r-help@stat.math.ethz.ch>
	<10EFB5D9-AB44-430E-86F0-7E57A7B0FD3B@globetrotter.net>
	<AC705FBD-B408-4BC1-89B8-9727C1571A3D@globetrotter.net>
Message-ID: <4340010D.5020202@statisticon.se>

Denis Chabot said the following on 2005-09-29 21:55:

> OK, I think I understand better but still have two points to clarify.
> 
> The first one is about the number of df. I think those who replied on  
> this objected to the way I chose df, not the fact that I would run a  
> model with 7.4 df per se. If I read you correctly, I artificially  
> reduce my p-value by using the estimated df found in a mgcv gam model  
> into another model where I fix df. This is fine, I am quite willing  not 
> to run a second model with a fixed df and instead tell my readers  that 
> my model is "marginally significant" with a p-value of 0.03.
> 
> This being said, do you know of guidelines for choosing df? A  colleague 
> told me he does not go above 10% of the number of points.  Should I be 
> concerned when mgcv estimates 7.4 df for 34 points? Note  that for this 
> particular model P < 1e-16, and P is also very small if  I fix df to 
> either 4 or 7.
> 
> My second point is the difference between models fitted by packages  gam 
> and mgcv. Sure, some of you have said "different algorithms". And  when 

Maybe that wasn't well put. Think of it as different implementations. 
The packages `mgcv' and `gam' are by no means the only implementations 
of GAM; see e.g. the `gss' package.

> I specify dfs, shouldn't P-values be very similar for the 2  packages? 
> If not, what does it say of the confidence we can have in  the models?

Since there's no universally accepted definition of what a GAM is, you 
shouldn't expect the results to be the same.

> I draw your attention to this exampl: I obtained P-values of 0.50 and  
> 0.03 with packages gam and mgcv respectively:

In this case, however, you're trying to compare apples to oranges...

>  > library(gam)
> Loading required package: splines
>  > data(kyphosis)
>  > kyp1 <- gam(Kyphosis ~ s(Number, 3), family=binomial, data=kyphosis)
>  > summary.gam(kyp1)
> 
> Call: gam(formula = Kyphosis ~ s(Number, 3), family = binomial, data  = 
> kyphosis)
> Deviance Residuals:
>     Min      1Q  Median      3Q     Max
> -1.3646 -0.6233 -0.4853 -0.3133  2.0965
> 
> (Dispersion Parameter for binomial family taken to be 1)
> 
>     Null Deviance: 83.2345 on 80 degrees of freedom
> Residual Deviance: 71.9973 on 76.9999 degrees of freedom
> AIC: 79.9976
> 
> Number of Local Scoring Iterations: 7
> 
> DF for Terms and Chi-squares for Nonparametric Effects
> 
>              Df Npar Df Npar Chisq  P(Chi)
> (Intercept)   1
> s(Number, 3)  1       2    1.37149 0.50375

This test concerns only the non-linear part of the term s(Number, 3). In 
order to simultaneously test both the linear and non-linear part, as 
mgcv::summary.gam does, you'd

 > kyp1.1 <- gam(Kyphosis ~ 1, family=binomial, data=kyphosis)
 > anova(kyp1.1, kyp1, test = "Chisq")
Analysis of Deviance Table

Model 1: Kyphosis ~ 1
Model 2: Kyphosis ~ s(Number, 3)
   Resid. Df Resid. Dev      Df Deviance P(>|Chi|)
1   80.0000     83.234
2   76.9999     71.997  3.0001   11.237     0.011


HTH,
Henric

>  > detach(package:gam)
>  > library(mgcv)
> This is mgcv 1.3-7
>  > kyp2 <- gam(Kyphosis ~ s(Number, k=4, fx=T),  family=binomial,  
> data=kyphosis)
>  > summary.gam(kyp2)
> 
> Family: binomial
> Link function: logit
> 
> Formula:
> Kyphosis ~ s(Number, k = 4, fx = T)
> 
> Parametric coefficients:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)  -1.5504     0.3342   -4.64 3.49e-06 ***
> ---
> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> 
> Approximate significance of smooth terms:
>           edf Est.rank Chi.sq p-value
> s(Number)   3        3  8.898  0.0307 *
> ---
> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> 
> R-sq.(adj) =  0.101   Deviance explained = 12.5%
> UBRE score = 0.075202  Scale est. = 1         n = 81
>  > kyp2$deviance
> [1] 72.85893
>  > kyp2$null.deviance
> [1] 83.23447
>  > kyp2$df.null
> [1] 80
>  > kyp2$df.residual
> [1] 77
> 
> How can we explain this huge difference?
> 
> Denis
> 
> 
>> Le 05-09-29 à 06:00, r-help-request at stat.math.ethz.ch a écrit :
>>
>> De : Henric Nilsson <henric.nilsson at statisticon.se>
>> Date : 29 septembre 2005 03:55:19 HAE
>> À : ym at climpact.com
>> Cc : r-help at stat.math.ethz.ch
>> Objet : Rép : [R] p-level in packages mgcv and gam
>> Répondre à : Henric Nilsson <henric.nilsson at statisticon.se>
>>
>>
>> Yves Magliulo said the following on 2005-09-28 17:05:
>>
>>> hi,
>>> i'll try to help you, i send a mail about this subject last  week... and
>>> i did not have any response...
>>> I'm using gam from package mgcv. 1)
>>> How to interpret the significance of smooth terms is hard for me to
>>> understand perfectly : using UBRE, you fix df. p-value are  estimated 
>>> by chi-sq distribution using GCV, the best df are  estimated by GAM. 
>>> (that's what i want) and
>>> p-values
>>
>>
>>
>> This is not correct. The df are estimated in both cases (i.e. UBRE  
>> and GCV), but the scale parameter is fixed in the UBRE case. Hence,  
>> by default UBRE is used for family = binomial or poisson since the  
>> scale parameter is assumed to be 1. Similarly, GCV is the default  for 
>> family = gaussian since we most often want the scale (usually  denoted 
>> sigma^2) to be estimated.
>>
>>
>>> are estimated by an F distribution But in that case they said "use at
>>> your own risk" in ?summary.gam
>>
>>
>>
>> The warning applies in both cases. The p-values are conditional on  
>> the smoothing parameters, and the uncertainty of the smooths is not  
>> taken into account when computing the p-values.
>>
>>
>>> so you can also look at the chi.sq : but i don't know how to choose a
>>
>>
>>
>> No...
>>
>>
>>> criterion like for p-values... for me, chi.sq show the best  
>>> predictor in
>>> a model, but it's hard to reject one with it.
>>
>>
>>
>> Which version of mgcv do you use? The confusion probably stems from  
>> earlier versions of mgcv (< 1.3-5): the summary and anova methods  
>> used to have a column denoted Chi.sq even when the displayed  
>> statistic was computed as F. Recent versions of mgcv has
>>
>> > summary(b)
>>
>> Family: gaussian
>> Link function: identity
>>
>> Formula:
>> y ~ s(x0) + s(x1) + s(x2) + s(x3)
>>
>> Parametric coefficients:
>>             Estimate Std. Error t value Pr(>|t|)
>> (Intercept)   7.9150     0.1049   75.44   <2e-16 ***
>> ---
>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>
>> Approximate significance of smooth terms:
>>         edf Est.rank      F  p-value
>> s(x0) 5.173    9.000  3.785 0.000137 ***
>> s(x1) 2.357    9.000 34.631  < 2e-16 ***
>> s(x2) 8.517    9.000 84.694  < 2e-16 ***
>> s(x3) 1.000    1.000  0.444 0.505797
>> ---
>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>
>> R-sq.(adj) =  0.726   Deviance explained = 73.7%
>> GCV score =  4.611   Scale est. = 4.4029    n = 400
>>
>>
>> If we assume that the scale is known and fixed at 4.4029, we get
>>
>> > summary(b, dispersion = 4.4029)
>>
>> Family: gaussian
>> Link function: identity
>>
>> Formula:
>> y ~ s(x0) + s(x1) + s(x2) + s(x3)
>>
>> Parametric coefficients:
>>             Estimate Std. Error z value Pr(>|z|)
>> (Intercept)   7.9150     0.1049   75.44   <2e-16 ***
>> ---
>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>
>> Approximate significance of smooth terms:
>>         edf Est.rank  Chi.sq p-value
>> s(x0) 5.173    9.000  34.067 8.7e-05 ***
>> s(x1) 2.357    9.000 311.679 < 2e-16 ***
>> s(x2) 8.517    9.000 762.255 < 2e-16 ***
>> s(x3) 1.000    1.000   0.444   0.505
>> ---
>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>
>> R-sq.(adj) =  0.726   Deviance explained = 73.7%
>> GCV score =  4.611   Scale est. = 4.4029    n = 400
>>
>> Note that t/F changed into z/Chi.sq.
>>
>>
>>> so as far as i m concerned, i use GCV methods, and fix a 5% on the  null
>>> hypothesis (pvalue) to select significant predictor. after, i look  
>>> at my
>>> smooth, and if the parametrization look fine to me, i validate.
>>> generaly, for p-values smaller than 0.001, you can be confident. over
>>> 0.001, you have to check. 2)
>>> for difference between package gam and mgcv, i sent a mail about this
>>
>>
>>
>> The underlying algorithms are very different.
>>
>>
>> HTH,
>> Henric
>>
>>
>> De : "Liaw, Andy" <andy_liaw at merck.com>
>> Date : 28 septembre 2005 14:01:25 HAE
>> À : 'Denis Chabot' <chabotd at globetrotter.net>, Peter Dalgaard  
>> <p.dalgaard at biostat.ku.dk>
>> Cc : Thomas Lumley <tlumley at u.washington.edu>, R list <r- 
>> help at stat.math.ethz.ch>
>> Objet : RE: [R] p-level in packages mgcv and gam
>>
>> Just change the df in what Thomas described to the degree of  
>> polynomial, and
>> everything he said still applies.  Any good book on regression that  
>> covers
>> polynomial regression ought to point this out.
>>
>> Andy
>>
>>
>>> From: Denis Chabot
>>>
>>> But what about another analogy, that of polynomials? You may not be
>>> sure what degree polynomial to use, and you have not decided before
>>> analysing your data. You fit different polynomials to your data,
>>> checking if added degrees increase r2 sufficiently by doing F-tests.
>>>
>>> I thought it was the same thing with GAMs. You can fit a
>>> model with 4
>>> df, and in some cases it is of interest to see if this is a better
>>> fit than a linear fit. But why can't you also check if 7df is better
>>> than 4df? And if you used mgcv first and it tells you that 7df is
>>> better than 4df, why bother repeating the comparison 7df
>>> against 4df,
>>> why not just take the p-value for the model with 7df (fixed)?
>>>
>>> Denis
>>
>>
> 
> 
>> De : Peter Dalgaard <p.dalgaard at biostat.ku.dk>
>> Date : 28 septembre 2005 12:04:58 HAE
>> À : Thomas Lumley <tlumley at u.washington.edu>
>> Cc : Denis Chabot <chabotd at globetrotter.net>, R list <r- 
>> help at stat.math.ethz.ch>
>> Objet : Rép : [R] p-level in packages mgcv and gam
>>
>> Thomas Lumley <tlumley at u.washington.edu> writes:
>>
>>>
>>> Bob, on the other hand, chooses the amount of smoothing depending on
>>> the data. When a 4 df smooth fits best he ends up with the same model
>>> as Alice and the same p-value.  When some other df fits best he ends
>>> up with a different model and a *smaller* p-value than Alice.
>>
>>
>> This doesn't actually follow, unless the p-value (directly or
>> indirectly) found its way into the definition of "best fit". It does
>> show the danger, though.
>>
>> -- 
>>    O__  ---- Peter Dalgaard             Øster Farimagsgade 5, Entr.B
>>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)  
>> 35327918
>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)  
>> 35327907
>>
> 
>> De : Thomas Lumley <tlumley at u.washington.edu>
>> Date : 26 septembre 2005 12:54:43 HAE
>> À : Denis Chabot <chabotd at globetrotter.net>
>> Cc : r-help at stat.math.ethz.ch
>> Objet : Rép : [R] p-level in packages mgcv and gam
>>
>> On Mon, 26 Sep 2005, Denis Chabot wrote:
>>
>> But the mgcv manual warns that p-level for the smooth can be
>> underestimated when df are estimated by the model. Most of the time
>> my p-levels are so small that even doubling them would not result in
>> a value close to the P=0.05 threshold, but I have one case with  P=0.033.
>>
>> I thought, probably naively, that running a second model with fixed
>> df, using the value of df found in the first model. I could not
>> achieve this with mgcv: its gam function does not seem to accept
>> fractional values of df (in my case 8.377).
>>
>> No, this won't work.  The problem is the usual one with model  
>> selection: the p-value is calculated as if the df had been fixed,  
>> when really it was estimated.
>>
>> It is likely to be quite hard to get an honest p-value out of  
>> something that does adaptive smoothing.
>>
>>     -thomas
>> De : Thomas Lumley <tlumley at u.washington.edu>
>> Date : 28 septembre 2005 11:33:27 HAE
>> À : Denis Chabot <chabotd at globetrotter.net>
>> Cc : R list <r-help at stat.math.ethz.ch>
>> Objet : Rép : [R] p-level in packages mgcv and gam
>>
>> On Wed, 28 Sep 2005, Denis Chabot wrote:
>>
>> I only got one reply to my message:
>>
>> No, this won't work.  The problem is the usual one with model
>> selection: the p-value is calculated as if the df had been fixed,
>> when really it was estimated.
>>
>> It is likely to be quite hard to get an honest p-value out of
>> something that does adaptive smoothing.
>>
>>     -thomas
>>
>> I do not understand this: it seems that a lot of people chose df=4
>> for no particular reason, but p-levels are correct. If instead I
>> choose df=8 because a previous model has estimated this to be an
>> optimal df, P-levels are no good because df are estimated?
>>
>> Yes. I know this sounds strange initially, but it really does make  
>> sense if you think about it carefully.
>>
>> Suppose that Alice and Bob are kyphosis researchers, and that Alice  
>> always chooses 4df for smoothing Age.  We would all agree that her  
>> p-values are correct [in fact we wouldn't, but that is a separate  issue]
>>
>> Bob, on the other hand, chooses the amount of smoothing depending  on 
>> the data. When a 4 df smooth fits best he ends up with the same  model 
>> as Alice and the same p-value.  When some other df fits best  he ends 
>> up with a different model and a *smaller* p-value than Alice.
>>
>> In particular, this is still true under the null hypothesis that  Age 
>> has no effect [If Alice and Bob are interested in p-values, the  null 
>> hypothesis must be plausible.]
>>
>> If Bob's p-values are always less than or equal to Alice's p-values  
>> under the null hypothesis, and Alice's p-values are less than 0.05  5% 
>> of the time, then Bob's p-values are less than 0.05 more than 5%  of 
>> the time.
>>
>>
>>     -thomas
>>
>>
>> Furthermore, shouldn't packages gam and mgcv give similar results
>> when the same data and df are used? I tried this:
>>
>> library(gam)
>> data(kyphosis)
>> kyp1 <- gam(Kyphosis ~ s(Age, 4), family=binomial, data=kyphosis)
>> kyp2 <- gam(Kyphosis ~ s(Number, 4), family=binomial, data=kyphosis)
>> kyp3 <- gam(Kyphosis ~ s(Start, 4), family=binomial, data=kyphosis)
>> anova.gam(kyp1)
>> anova.gam(kyp2)
>> anova.gam(kyp3)
>>
>> detach(package:gam)
>> library(mgcv)
>> kyp4 <- gam(Kyphosis ~ s(Age, k=4, fx=T),  family=binomial,
>> data=kyphosis)
>> kyp5 <- gam(Kyphosis ~ s(Number, k=4, fx=T),  family=binomial,
>> data=kyphosis)
>> kyp6 <- gam(Kyphosis ~ s(Start, k=4, fx=T),  family=binomial,
>> data=kyphosis)
>> anova.gam(kyp4)
>> anova.gam(kyp5)
>> anova.gam(kyp6)
>>
>>
>> P levels for these models, by pair
>>
>> kyp1 vs kyp4: p= 0.083 and 0.068 respectively (not too bad)
>> kyp2 vs kyp5: p= 0.445 and 0.03 (wow!)
>> kyp3 vs kyp6: p= 0.053 and 0.008 (wow again)
>>
>> Also if you plot all these you find that the mgcv plots are smoother
>> than the gam plots, even the same df are used all the time.
>>
>> I am really confused now!
>>
>> Denis
>>
> 
>>
>> Thomas Lumley            Assoc. Professor, Biostatistics
>> tlumley at u.washington.edu    University of Washington, SeattleDe :  
>> Thomas Lumley <tlumley at u.washington.edu>
>> Date : 28 septembre 2005 14:35:26 HAE
>> À : Denis Chabot <chabotd at globetrotter.net>
>> Cc : Peter Dalgaard <p.dalgaard at biostat.ku.dk>, R list <r- 
>> help at stat.math.ethz.ch>
>> Objet : Rép : [R] p-level in packages mgcv and gam
>>
>> On Wed, 28 Sep 2005, Denis Chabot wrote:
>>
>> But what about another analogy, that of polynomials? You may not be  
>> sure what degree polynomial to use, and you have not decided before  
>> analysing your data. You fit different polynomials to your data,  
>> checking if added degrees increase r2 sufficiently by doing F-tests.
>>
>> Yes, you can. And this procedure gives you incorrect p-values.
>>
>>  They may not be very incorrect -- it depends on how much model  
>> selection you do, and how strongly the feature you are selecting on  
>> is related to the one you are testing.
>>
>> For example, using step() to choose a polynomial in x even when x  is 
>> unrelated to y and z inflates the Type I error rate by giving a  
>> biased estimate of the residual mean squared error:
>>
>> once<-function(){
>>   y<-rnorm(50);x<-runif(50);z<-rep(0:1,25)
>>   summary(step(lm(y~z),
>>         scope=list(lower=~z,upper=~z+x+I(x^2)+I(x^3)+I(x^4)),
>>         trace=0))$coef["z",4]
>>  }
>> p<-replicate(1000,once())
>> mean(p<0.05)
>> [1] 0.072
>>
>> which is significantly higher than you would expect for an honest  
>> level 0.05 test.
>>
>>     -thomas
> 
>



From ripley at stats.ox.ac.uk  Sun Oct  2 18:15:43 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 2 Oct 2005 17:15:43 +0100 (BST)
Subject: [R] Memory management on Windows (was Size of jpegs/pngs)
In-Reply-To: <31587199.1128264403171.JavaMail.ngmail@webmail-03.arcor-online.net>
References: <31587199.1128264403171.JavaMail.ngmail@webmail-03.arcor-online.net>
Message-ID: <Pine.LNX.4.61.0510021706490.18487@gannet.stats>

I think this an issue about the amount of graphics memory.  You are asking 
for an image of about 17*2*3 = 102Mb, and you need more than that.

>From the help page:

      Windows imposes limits on the size of bitmaps: these are not
      documented in the SDK and may depend on the version of Windows. It
      seems that 'width' and 'height' are each limited to 2^15-1 and
      there is a 16Mb limit on the total amount of memory in Windows
      95/98/ME.

so I do wonder why you are surprised.

My laptop appears to be limited to about half your example with a 128Mb 
graphics card (and lots of other things going on).

On Sun, 2 Oct 2005 stgries at arcor.de wrote:

> Dear all
>
> I have trouble with setting the size for jpegs and pngs. I need to save 
> a dendrogram of 1000 words into a jpeg or png file. On one of my 
> computers, the following works just fine:
>
> bb<-agnes(aa, method="ward")
> jpeg("C:/Temp/test.txt", width=17000, height=2000)
> plot(bb)
> dev.off()
>
> On my main computer, however, this doesn't work:
>> jpeg("C:/Temp/test.txt", width=17000, height=2000)
> Error in jpeg("C:/Temp/test.txt", width = 17000, height = 2000) :
>        unable to start device devWindows
> In addition: Warning message:
> Unable to allocate bitmap
>
> This is a Windows XP Pro SP2 system, which is started with this chsort
>> R.version
>         _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    1.1
> year     2005
> month    06
> day      20
> language R
>
> which is started with a shortcut.
> "C:\rw2011\bin\Rgui.exe --max-mem-size=1500M"
>
> I checked the web and the R-help pages, tried out the ppsize option, and 
> compared the options settings with those of the machine that works 
> (which actually runs R 2.0.1 of 15 Nov 2004), but couldn't come up with 
> an explanation. Any idea what I do wrong?

Did you read the help page?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From 8-T at gmx.net  Sun Oct  2 21:03:37 2005
From: 8-T at gmx.net (=?ISO-8859-1?Q?Ram=F3n_Casero_Ca=F1as?=)
Date: Sun, 02 Oct 2005 20:03:37 +0100
Subject: [R] rate instead of scale in ?ks.test
Message-ID: <43402F09.4090700@gmx.net>


I am not sure whether I'm doing something wrong or there is a bug in the
documentation of ks.test. Following the posting guide, as I'm not sure,
I haven't found this in the bug tracker, and the R FAQ says that stats
is an Add-on package of R, I think this is the place to send it.


?ks.test provides the example

<QUOTE>
# Does x come from a shifted gamma distribution with shape 3 and scale 2?
ks.test(x+2, "pgamma", 3, 2) # two-sided
</QUOTE>


Maybe it should say ``with shape 3 and rate 2''?


If I do

> x <- rgamma(1e6, shape = 3, scale = 2)
> ks.test( x, 'pgamma', 3, 2 )

	One-sample Kolmogorov-Smirnov test

data:  x
D = 0.7513, p-value < 2.2e-16
alternative hypothesis: two.sided


whereas with


> y <- rgamma(1e6, shape = 3, rate = 2)
 ks.test( y, 'pgamma', 3, 2 )

	One-sample Kolmogorov-Smirnov test

data:  y
D = 5e-04, p-value = 0.9469
alternative hypothesis: two.sided


If forcing the parameter meaning:

> ks.test( x, 'pgamma', shape = 3, scale = 2 )

	One-sample Kolmogorov-Smirnov test

data:  x
D = 9e-04, p-value = 0.3645
alternative hypothesis: two.sided



> version
platform i386-pc-linux-gnu
arch     i386
os       linux-gnu
system   i386, linux-gnu
status
major    2
minor    1.1
year     2005
month    06
day      20
language R

> packageDescription( "stats" )
Package: stats
Version: 2.1.1
Priority: base
Title: The R Stats Package
Author: R Development Core Team and contributors worldwide
Maintainer: R Core Team <R-core at r-project.org>
Description: R statistical functions
License: GPL Version 2 or later.
Built: R 2.1.1; i386-pc-linux-gnu; 2005-06-29 23:30:55; unix

-- File: /usr/lib/R/library/stats/DESCRIPTION

Cheers,

-- 
Ram??n Casero Ca??as

web:    http://www.robots.ox.ac.uk/~rcasero/



From chabotd at globetrotter.net  Sun Oct  2 21:04:09 2005
From: chabotd at globetrotter.net (Denis Chabot)
Date: Sun, 02 Oct 2005 15:04:09 -0400
Subject: [R] p-level in packages mgcv and gam
In-Reply-To: <4340010D.5020202@statisticon.se>
References: <mailman.10.1127988001.20586.r-help@stat.math.ethz.ch>
	<10EFB5D9-AB44-430E-86F0-7E57A7B0FD3B@globetrotter.net>
	<AC705FBD-B408-4BC1-89B8-9727C1571A3D@globetrotter.net>
	<4340010D.5020202@statisticon.se>
Message-ID: <005C73DA-28F3-42EA-90A2-5C86C7CE901C@globetrotter.net>

Thank you very much Henric, now I see!

Denis
Le 05-10-02 ?? 11:47, Henric Nilsson a ??crit :

> This test concerns only the non-linear part of the term s(Number,  
> 3). In order to simultaneously test both the linear and non-linear  
> part, as mgcv::summary.gam does, you'd
>
> > kyp1.1 <- gam(Kyphosis ~ 1, family=binomial, data=kyphosis)
> > anova(kyp1.1, kyp1, test = "Chisq")
> Analysis of Deviance Table
>
> Model 1: Kyphosis ~ 1
> Model 2: Kyphosis ~ s(Number, 3)
>   Resid. Df Resid. Dev      Df Deviance P(>|Chi|)
> 1   80.0000     83.234
> 2   76.9999     71.997  3.0001   11.237     0.011
>
>
> HTH,
> Henric
>
>



From sun at cae.wisc.edu  Sun Oct  2 22:07:09 2005
From: sun at cae.wisc.edu (Hongyu Sun)
Date: Sun, 2 Oct 2005 15:07:09 -0500
Subject: [R] generalized linear model for multinomial data?
References: <000701c5c4f2$2d591630$d636a986@mast405>
Message-ID: <00d101c5c78c$e210d530$d1769792@uwstar>

Dear All:

Does R have the package as in SAS's generalized logits model for nominal 
response data? I have searched but cannot find the windows package.

Many thanks,

HS



From ksroka at poczta.onet.pl  Sun Oct  2 22:08:45 2005
From: ksroka at poczta.onet.pl (Krzysztof Sroka)
Date: Sun, 2 Oct 2005 22:08:45 +0200
Subject: [R] question for some tests
Message-ID: <000601c5c78d$1b931f70$04f9cf57@mathkit>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051002/8120f126/attachment.pl

From Roger.Bivand at nhh.no  Sun Oct  2 22:24:26 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 2 Oct 2005 22:24:26 +0200 (CEST)
Subject: [R] question for some tests
In-Reply-To: <000601c5c78d$1b931f70$04f9cf57@mathkit>
Message-ID: <Pine.LNX.4.44.0510022220480.30705-100000@reclus.nhh.no>

On Sun, 2 Oct 2005, Krzysztof Sroka wrote:

> Hi! I come from Poland, and my English is not as good as it should be,
> so I have to apologize for my mistakes.  I would like to ask you for a
> package, where I can find a test, which is named The Test Of Series (in
> Poland). In econometric models we use this test to check if the
> residuals are completely random ( I mean with destiny). And one more
> thing - I would like to know where I can find a test for symetric of
> residuals (called The Test For The Indicator Of The Structure).  And In
> general, where I can the list for the tests being used in ecometrics.

R has Task Views, posted on the Archive Network (CRAN), and one of these 
is for econometrics:

http://cran.r-project.org/src/contrib/Views/Econometrics.html

It is quite dense (many links), certainly has what you need, but you will 
have to look around to find what fits your needs more closely. I would 
look at the lmtest package to start with, the Task View includes much 
more.

> 
> With greetings, 
> Krzysztof Sroka
> 
> Please, answer on my e-mail address: ksroka at poczta.onet.pl 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From spencer.graves at pdf.com  Sun Oct  2 22:24:57 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 02 Oct 2005 15:24:57 -0500
Subject: [R] Access to particular predict value
In-Reply-To: <200509281650.47447.viudez_ant@gva.es>
References: <200509281650.47447.viudez_ant@gva.es>
Message-ID: <43404219.3030106@pdf.com>

	  If you would still like help from this list, please provide a very 
simple reproducible example to help what you tried that didn't quite 
work.  There are several functions that use inverse distance weighting 
(IDW) and kriging for geostatistical computations.

	  spencer graves
p.s.   PLEASE do read the posting guide! 
"www.R-project.org/posting-guide.html".  I believe that people who use 
the posting guide generally get better answers quicker, because it is 
easier for others to understand what they want.

Toni Vi??dez wrote:

> Hi everybody:
> 
> I just generate interpolation maps with differents methods, like IDW and 
> kriging, and now i want to compare the predict values versus real, and i 
> don't who is the commant to do it. I want for example, if I pass from console 
> the coordinates of a place, return me the predict value.
> Could anybody tell me how should do?.
> 
> Thanks in advance

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From jfox at mcmaster.ca  Sun Oct  2 22:27:03 2005
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 2 Oct 2005 16:27:03 -0400
Subject: [R] generalized linear model for multinomial data?
In-Reply-To: <00d101c5c78c$e210d530$d1769792@uwstar>
Message-ID: <20051002202702.QWQC26550.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Hongyu,

See multinom() in the nnet package, associated with Venables and Ripley's
Modern Applied Statistics with S.

John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Hongyu Sun
> Sent: Sunday, October 02, 2005 3:07 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] generalized linear model for multinomial data?
> 
> Dear All:
> 
> Does R have the package as in SAS's generalized logits model 
> for nominal response data? I have searched but cannot find 
> the windows package.
> 
> Many thanks,
> 
> HS
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From spencer.graves at pdf.com  Sun Oct  2 22:28:11 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 02 Oct 2005 15:28:11 -0500
Subject: [R] R-code for binormla distribution
In-Reply-To: <Pine.LNX.4.60.0509281710360.28322@olive.iro.umontreal.ca>
References: <Pine.LNX.4.60.0509281710360.28322@olive.iro.umontreal.ca>
Message-ID: <434042DB.4040207@pdf.com>

	  What are you trying to do that requires binormal probabilities other 
than pmvnorm?

	  spencer graves

Nabil Channouf wrote:

> Dear users,
> does any one have a code (S or R) to compute the binormal distribution 
> (or the upper its quadrant area) other than the pmvnorm.
> Thanks
> 
> 

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From sun at cae.wisc.edu  Sun Oct  2 22:38:43 2005
From: sun at cae.wisc.edu (Hongyu Sun)
Date: Sun, 2 Oct 2005 15:38:43 -0500
Subject: [R] generalized linear model for multinomial data?
References: <20051002202702.QWQC26550.tomts20-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <013601c5c791$4af7db30$d1769792@uwstar>

Dear Professor: Thanks! I just found it. It is bundled within the VR 
package.

Hongyu

----- Original Message ----- 
From: "John Fox" <jfox at mcmaster.ca>
To: "'Hongyu Sun'" <sun at cae.wisc.edu>
Cc: <r-help at stat.math.ethz.ch>
Sent: Sunday, October 02, 2005 3:27 PM
Subject: RE: [R] generalized linear model for multinomial data?


> Dear Hongyu,
>
> See multinom() in the nnet package, associated with Venables and Ripley's
> Modern Applied Statistics with S.
>
> John
>
> --------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> 905-525-9140x23604
> http://socserv.mcmaster.ca/jfox
> -------------------------------- 
>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Hongyu Sun
>> Sent: Sunday, October 02, 2005 3:07 PM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] generalized linear model for multinomial data?
>>
>> Dear All:
>>
>> Does R have the package as in SAS's generalized logits model
>> for nominal response data? I have searched but cannot find
>> the windows package.
>>
>> Many thanks,
>>
>> HS
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>



From gpapayia at yahoo.com  Mon Oct  3 00:19:03 2005
From: gpapayia at yahoo.com (George Papayiannis)
Date: Sun, 2 Oct 2005 15:19:03 -0700 (PDT)
Subject: [R] Selecting columns of a table (not consecutive)
Message-ID: <20051002221903.88046.qmail@web35914.mail.mud.yahoo.com>

Hi everyone,

I have a table with 10 columns and many rows.
I want to select the 3rd,4th and 10th column.

If I wanted to select the 3rd and 4th it would be no
problem.

q3[ ,(3:4)]

but how do I select the 10th along with it?

Thanks for your help,
George

p.s Please respond if you know, assignment is due
tomorrow...

Thanks again..



From nlemeur at fhcrc.org  Mon Oct  3 00:29:56 2005
From: nlemeur at fhcrc.org (Nolwenn LeMeur)
Date: Mon, 03 Oct 2005 00:29:56 +0200
Subject: [R] Selecting columns of a table (not consecutive)
In-Reply-To: <20051002221903.88046.qmail@web35914.mail.mud.yahoo.com>
References: <20051002221903.88046.qmail@web35914.mail.mud.yahoo.com>
Message-ID: <43405F64.6010109@fhcrc.org>

George Papayiannis wrote:

>Hi everyone,
>
>I have a table with 10 columns and many rows.
>I want to select the 3rd,4th and 10th column.
>
>If I wanted to select the 3rd and 4th it would be no
>problem.
>
>q3[ ,(3:4)]
>
>but how do I select the 10th along with it?
>
>Thanks for your help,
>George
>
>p.s Please respond if you know, assignment is due
>tomorrow...
>
>Thanks again..
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>
Hi George,

Try
 subset(q3, select=c(3,4,10))

Nolwenn



From Mike.Lawrence at Dal.Ca  Mon Oct  3 01:00:54 2005
From: Mike.Lawrence at Dal.Ca (Mike Lawrence)
Date: Sun,  2 Oct 2005 20:00:54 -0300
Subject: [R] What is Mandel's (Fitting) Test?
Message-ID: <20051002200054.ud0hs35ozf8cscgw@my1.dal.ca>

Hello everyone,

A little background first:
I have collected psychophysical data from 12 participants, and each
participant's data is represented as a scatter plot (Percieved roughness versus
Physical roughness). I would like to know whether, on average, this data is
best fit by a linear function or by a quadratic function. (we have a priori
reasons to expect a quadratic)

Some of my colleagues have suggested the following methods of testing this:
1. For each participant, calculate the r-square values for linear and quadratic
fits, z-transform the resulting values. Collect these z-transformed scores and
then perform a dependent t-test across participants. If significant, then a
quadratic fits better.
2. For each participant, calculate the amount of variance left over from the
linear fit that is accounted for by the quadratic fit. Perform a one-sample
t-test to see if this population of scores differs from zero
3. Same as #2, but z-transform before performing the t-test.

However, I'm sure that these tests fail to take into account the fact that a
quadratic function will generally have an advantage over a linear function
simply by dint of having more terms to play with. So I've been looking for a
test that takes this advantage into account and I came across something called
the Mandel Test. It is available in the quantchem package, but the manual
contains a very meagre description of it's details (assumptions, etc).
Furthermore, besides biology/chemistry papers that reference it in passing,
I've been able to find only one reference online that addresses it's use
(http://www.econ.kuleuven.be/public/ndbae06/PDF-FILES/vanloco.doc), but even
then it lacks specificity.

So the question is, what is the Mandel Test? What are the assumptions and
limitations of the test? Does it sound appropriate for my purposes (if not, how
about the other tests suggested above)? How does it differ from the Lack-of-Fit
test?

Any help would be greatly appreciated.

Cheers,

Mike

-- 

Mike Lawrence, BA(Hons)
Research Assistant to Dr. Gail Eskes
Dalhousie University & QEII Health Sciences Centre (Psychiatry)

Mike.Lawrence at Dal.Ca

"The road to Wisdom? Well, it's plain and simple to express:
Err and err and err again, but less and less and less."
- Piet Hein



From spencer.graves at pdf.com  Mon Oct  3 01:42:14 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 02 Oct 2005 18:42:14 -0500
Subject: [R] R-code for binormla distribution
In-Reply-To: <434042DB.4040207@pdf.com>
References: <Pine.LNX.4.60.0509281710360.28322@olive.iro.umontreal.ca>
	<434042DB.4040207@pdf.com>
Message-ID: <43407056.9000504@pdf.com>

	  Why do you say "we do not have the package that contains pmvnorm"? 
It is in library(mvtnorm), which you can get via CRAN (the Comprehensive 
R Archive Network).  If you are using Windows or a standard Linux of 
MacOS, "install.packages('mvtnorm')" should install it on your computer 
(unless you are using a computer with special protection that makes this 
difficult;  if you are using XEmacs, you should exit R under XEmacs and 
run "install.packages" from Rgui).  Then "library('mvtnorm')" should 
make it available to your R session.  If you are using some other 
operating system, you may need to access the source, but that's 
available via CRAN alse.

	  If you have not tried "install.packages", please do so.  If you have 
tried "install.packages" and can't make it work, please describe your 
operating system, etc., as explained in the posting guide! 
"www.R-project.org/posting-guide.html".

	  spencer graves

Nabil Channouf wrote:
 > Dear  Mr. Graves,
 > i'm trying to write my own function with R, because we do not have the
 > package that contains pmvnorm and i need to compute the upper quadrant
 > area of the bivariate standard normal, or at least to know the details
 > of the function pmvnorm written in Splus or in R.
 > Thanks


Spencer Graves wrote:
>       What are you trying to do that requires binormal probabilities 
> other than pmvnorm?
> 
>       spencer graves
> 
> Nabil Channouf wrote:
> 
>> Dear users,
>> does any one have a code (S or R) to compute the binormal distribution 
>> (or the upper its quadrant area) other than the pmvnorm.
>> Thanks
>>
>>
> 

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From spencer.graves at pdf.com  Mon Oct  3 02:28:59 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 02 Oct 2005 19:28:59 -0500
Subject: [R] Local install of a contributed package under Linux (was:
 R-code for binormla distribution)
In-Reply-To: <43407056.9000504@pdf.com>
References: <Pine.LNX.4.60.0509281710360.28322@olive.iro.umontreal.ca>
	<434042DB.4040207@pdf.com> <43407056.9000504@pdf.com>
Message-ID: <43407B4B.6060204@pdf.com>

	  There probably is a way under Linux to install a contributed package 
in your local directory.  I don't know how, but if you read the 
documentation on "download.packages" and "install.packages", you might 
be able to do it without bothering your Info Tech department.  I know 
there is a way, and with luck someone who knows will respond to this 
email.  If you try something with "download.packages" and 
"install.packages", and you can't make it work, please tell us what you 
try and what doesn't work.  Maybe someone who uses R on Linux will 
respond.  If not, ask your Info Tech department.

	  Spencer Graves

Nabil Channouf wrote:
 > Mr Graves,
 > we are working with linux and it is so complicated to install any thing,
 > it should be via the informaticians of the department and we have to
 > make a request and wait. I will ask them to do it on monday.
 > Thank you so much

Spencer Graves wrote:

>       Why do you say "we do not have the package that contains pmvnorm"? 
> It is in library(mvtnorm), which you can get via CRAN (the Comprehensive 
> R Archive Network).  If you are using Windows or a standard Linux of 
> MacOS, "install.packages('mvtnorm')" should install it on your computer 
> (unless you are using a computer with special protection that makes this 
> difficult;  if you are using XEmacs, you should exit R under XEmacs and 
> run "install.packages" from Rgui).  Then "library('mvtnorm')" should 
> make it available to your R session.  If you are using some other 
> operating system, you may need to access the source, but that's 
> available via CRAN alse.
> 
>       If you have not tried "install.packages", please do so.  If you 
> have tried "install.packages" and can't make it work, please describe 
> your operating system, etc., as explained in the posting guide! 
> "www.R-project.org/posting-guide.html".
> 
>       spencer graves
> 
> Nabil Channouf wrote:
>  > Dear  Mr. Graves,
>  > i'm trying to write my own function with R, because we do not have the
>  > package that contains pmvnorm and i need to compute the upper quadrant
>  > area of the bivariate standard normal, or at least to know the details
>  > of the function pmvnorm written in Splus or in R.
>  > Thanks
> 
> 
> Spencer Graves wrote:
> 
>>       What are you trying to do that requires binormal probabilities 
>> other than pmvnorm?
>>
>>       spencer graves
>>
>> Nabil Channouf wrote:
>>
>>> Dear users,
>>> does any one have a code (S or R) to compute the binormal 
>>> distribution (or the upper its quadrant area) other than the pmvnorm.
>>> Thanks
>>>
>>>
>>
> 

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From baron at psych.upenn.edu  Mon Oct  3 03:00:41 2005
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Sun, 2 Oct 2005 21:00:41 -0400
Subject: [R] Local install of a contributed package under Linux (was:
	R-code for binormla distribution)
In-Reply-To: <43407B4B.6060204@pdf.com>
References: <Pine.LNX.4.60.0509281710360.28322@olive.iro.umontreal.ca>
	<434042DB.4040207@pdf.com> <43407056.9000504@pdf.com>
	<43407B4B.6060204@pdf.com>
Message-ID: <20051003010041.GA9031@psych>

Try

R CMD INSTALL -l lib pkgs

The help file is in the utils package.  I'm sure this is
documented in the manual too.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron



From ggrothendieck at gmail.com  Mon Oct  3 07:37:54 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 3 Oct 2005 01:37:54 -0400
Subject: [R] grob questions
Message-ID: <971536df0510022237v7b91c484g2cb998321d192d5b@mail.gmail.com>

If I run the following example from:
http://www.stat.auckland.ac.nz/~paul/grid/doc/grobs.pdf

> grid.newpage()
> pushViewport(viewport(w = 0.5, h = 0.5))
> myplot <- gTree(name = "myplot", children = gList(rectGrob(name = "box",
+ gp = gpar(col = "grey")), xaxisGrob(name = "xaxis")))
> grid.draw(myplot)
> grid.edit("myplot::xaxis", at = 1:10/11)
> grid.edit("myplot::xaxis::labels", label = round(1:10/11, 2))
> grid.edit("myplot::xaxis::labels", y = unit(-1, "lines"))

then

> str(myplot$children$xaxis)

lists 'at' but not the 'labels'.

yet if I do this then the labels are listed:

> xx <- xaxisGrob(name = "myX", at = 1:10)
> childNames(xx)
[1] "major"  "ticks"  "labels"


1. How do I get to labels in the first case?

2. Is there a better construct than myplot$children$xaxis?

Thanks.



From p.dalgaard at biostat.ku.dk  Mon Oct  3 08:10:01 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 03 Oct 2005 08:10:01 +0200
Subject: [R] Selecting columns of a table (not consecutive)
In-Reply-To: <43405F64.6010109@fhcrc.org>
References: <20051002221903.88046.qmail@web35914.mail.mud.yahoo.com>
	<43405F64.6010109@fhcrc.org>
Message-ID: <x2y85bcerq.fsf@turmalin.kubism.ku.dk>

Nolwenn LeMeur <nlemeur at fhcrc.org> writes:

> George Papayiannis wrote:
> 
> >Hi everyone,
> >
> >I have a table with 10 columns and many rows.
> >I want to select the 3rd,4th and 10th column.
> >
> >If I wanted to select the 3rd and 4th it would be no
> >problem.
> >
> >q3[ ,(3:4)]
> >
> >but how do I select the 10th along with it?
> >

> Try
>  subset(q3, select=c(3,4,10))

Yes, but q3[,c(3:4,10)] works too. Notice that the index can be an
arbitrary numeric vector.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From vito_ricci at yahoo.com  Mon Oct  3 08:11:59 2005
From: vito_ricci at yahoo.com (Vito Ricci)
Date: Mon, 3 Oct 2005 08:11:59 +0200 (CEST)
Subject: [R] ast package?
In-Reply-To: <x27jcyjwqs.fsf@turmalin.kubism.ku.dk>
Message-ID: <20051003061159.25666.qmail@web36115.mail.mud.yahoo.com>

Hi,

several people asked me where they can found ast.
Prof. Masarotto should put it on CRAN as soon as
possible. ast package has many functions useful in
time series analysis.

Regards,

Vito

--- Peter Dalgaard <p.dalgaard at biostat.ku.dk> ha
scritto: 

> "Rabaa, Maia" <mrabaa at jhsph.edu> writes:
> 
> > According to the extremely helpful reference card
> for time series analysis provided at:
>
http://cran.r-project.org/doc/contrib/Ricci-refcard-ts.pdf,
> the ast package is necessary to perform some of the
> functions.
> > Where can this package be installed from, as I
> cannot find it from my pulldown list, nor can I find
> it on the web?
> > Thanks.
> 
> It's not *that* hard to find, although it helps if
> you know a few
> words of Italian...
> 
> http://sirio.stat.unipd.it/index.php?id=libast
> 
> I don't know why Guido doesn't want to put this on
> CRAN.
>   
> > Maia
> 
> -- 
>    O__  ---- Peter Dalgaard             ??ster
> Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099,
> 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark     
>     Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             
>     FAX: (+45) 35327907
> 


Diventare costruttori di soluzioni
Became solutions' constructors

"The business of the statistician is to catalyze 
the scientific learning process."  
George E. P. Box

"Statistical thinking will one day be as necessary for efficient citizenship as the ability to read and write"
H. G. Wells

Top 10 reasons to become a Statistician

     1. Deviation is considered normal
     2. We feel complete and sufficient
     3. We are 'mean' lovers
     4. Statisticians do it discretely and continuously
     5. We are right 95% of the time
     6. We can legally comment on someone's posterior distribution
     7. We may not be normal, but we are transformable
     8. We never have to say we are certain
     9. We are honestly significantly different
    10. No one wants our jobs


Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese  http://www.modugno.it/archivio/palesesanto_spirito/



From Sze_Sing_LEE/DMO/NCC at nccs.com.sg  Mon Oct  3 08:13:04 2005
From: Sze_Sing_LEE/DMO/NCC at nccs.com.sg (Sze_Sing_LEE/DMO/NCC@nccs.com.sg)
Date: Mon, 3 Oct 2005 14:13:04 +0800
Subject: [R] unable to compute MAD in aCGH package
Message-ID: <OF478DB13E.F4B3E92E-ON4825708F.00203460-4825708F.00222BAB@nccs.com.sg>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051003/947c6515/attachment.pl

From Peter.Rossi at chicagogsb.edu  Mon Oct  3 04:31:13 2005
From: Peter.Rossi at chicagogsb.edu (Rossi, Peter E.)
Date: Sun, 2 Oct 2005 21:31:13 -0500
Subject: [R] [R-pkgs] release of version 2.0-1 of bayesm
Message-ID: <1E7B167439290641966EB161D433079854537D@GSBEX.gsb.uchicago.edu>

Folks-
 
We are pleased to announce the release of version 2.0-1 of bayesm.
 
Highlights of the new version:
1. Bayesian treatment of SUR (seemingly unrelated regression)
2. Added clustering to mixture of normals models
3. Added routines to compute implied univ and bivariate densities from
   mixture of normals MCMC draws
4. improved input error checking in many routines
 
please get rid of your old version and install the new one!
 
peter
 
................................
  Peter E. Rossi
 Joseph T. and Bernice S. Lewis Professor of Marketing and Statistics
 Editor, Quantitative Marketing and Economics
 Rm 353, Graduate School of Business, U of Chicago
 5807 S. Woodlawn Ave, Chicago IL 60637
 Tel: (773) 702-7513   |   Fax: (773) 834-2081 
  WWW: http://ChicagoGsb.edu/fac/peter.rossi
  SSRN: http://ssrn.com/author=22862

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From assicma at yahoo.com  Mon Oct  3 09:18:11 2005
From: assicma at yahoo.com (assic ma)
Date: Mon, 3 Oct 2005 00:18:11 -0700 (PDT)
Subject: [R] seeking an simple example of randomForest package - thanks!
Message-ID: <20051003071811.70922.qmail@web51411.mail.yahoo.com>

hi, dear all,

    does anyboby have an simple example of
classification by using randomForest? Thanks a lot! 

best 
assicma



From maechler at stat.math.ethz.ch  Mon Oct  3 09:31:37 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 3 Oct 2005 09:31:37 +0200
Subject: [R] rate instead of scale in ?ks.test
In-Reply-To: <43402F09.4090700@gmx.net>
References: <43402F09.4090700@gmx.net>
Message-ID: <17216.56921.71421.113092@stat.math.ethz.ch>

>>>>> "Ramon" == Ram??n Casero Ca??as <8-T at gmx.net>
>>>>>     on Sun, 02 Oct 2005 20:03:37 +0100 writes:

    Ramon> I am not sure whether I'm doing something wrong or
    Ramon> there is a bug in the documentation of
    Ramon> ks.test. Following the posting guide, as I'm not
    Ramon> sure, I haven't found this in the bug tracker, and
    Ramon> the R FAQ says that stats is an Add-on package of
    Ramon> R, I think this is the place to send it.

well "stats" is not exactly what we'd call an "Add-on package".
You cannot get an R installation without it.

    Ramon> ?ks.test provides the example

 Ramon> <QUOTE>

 Ramon> # Does x come from a shifted gamma distribution with shape 3 and scale 2?
 Ramon> ks.test(x+2, "pgamma", 3, 2) # two-sided

 Ramon> </QUOTE>


    Ramon> Maybe it should say ``with shape 3 and rate 2''?

Definitely.  You are right
{and there's a small history to the reason for this "typo",
 not really worth of our time though}. 

This is such a trivial bug fix that it can even be applied to
the code-frozen R 2.2 beta.

Thank you, Ram??n!

Martin Maechler, ETH Zurich



From maechler at stat.math.ethz.ch  Mon Oct  3 09:49:38 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 3 Oct 2005 09:49:38 +0200
Subject: [R] Local install of a contributed package under Linux
In-Reply-To: <20051003010041.GA9031@psych>
References: <Pine.LNX.4.60.0509281710360.28322@olive.iro.umontreal.ca>
	<434042DB.4040207@pdf.com> <43407056.9000504@pdf.com>
	<43407B4B.6060204@pdf.com> <20051003010041.GA9031@psych>
Message-ID: <17216.58002.919678.126913@stat.math.ethz.ch>

>>>>> "Jon" == Jonathan Baron <baron at psych.upenn.edu>
>>>>>     on Sun, 2 Oct 2005 21:00:41 -0400 writes:

    Jon> Try
    Jon> R CMD INSTALL -l lib pkgs

    Jon> The help file is in the utils package.  I'm sure this is
    Jon> documented in the manual too.

yes, and yes.

The other thing people like the original poster often "forget" is
to subsequently *use* the local library {remember: a library is
directory (aka "folder") of installed packages}:

Either use
       library("mvtnorm", lib.loc = <path.to.local.library>)

every time you use the locally installed package, or rather
add the  local library to the libraries that are always searched
through.  There are several ways to do so in unix-alikes:
- Setting R_LIBS in (one of) the Renviron files;
- Calling .libPaths() in (one of) your Rprofile (files) or in
  other startup code
- <<more ways, but these are less recommended>>

Read ?Startup , ?.libPaths (and ?library) for more info.

Regards,
Martin Maechler



From ripley at stats.ox.ac.uk  Mon Oct  3 09:12:39 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 Oct 2005 08:12:39 +0100 (BST)
Subject: [R] Local install of a contributed package under Linux (was:
 R-code for binormla distribution)
In-Reply-To: <20051003010041.GA9031@psych>
References: <Pine.LNX.4.60.0509281710360.28322@olive.iro.umontreal.ca>
	<434042DB.4040207@pdf.com> <43407056.9000504@pdf.com>
	<43407B4B.6060204@pdf.com> <20051003010041.GA9031@psych>
Message-ID: <Pine.LNX.4.61.0510030800530.28926@gannet.stats>

On Sun, 2 Oct 2005, Jonathan Baron wrote:

> Try
>
> R CMD INSTALL -l lib pkgs
>
> The help file is in the utils package.  I'm sure this is
> documented in the manual too.

But you still need to ensure that library() can find the packages.


I think the simplest way is that we have set up by default for new R 
users:

1) Set the environment variable R_LIBS.  For a site in 
R_HOME/etc/Renviron.site, or for a user in ~/.Renviron.  For example,
include the line

R_LIBS=~/R/library

2) Ensure that this directory exists, e.g.

mkdir -p ~/R/library

(If it does not exist the setting will be ignored, so it is safe to set it 
for all users.)

3) Use install.packages() inside R.  This will by default use the first 
element in .libPaths(), which will be ~/R/library.  Suggest to users that 
they use would do best to use

install.packages(pkgs, .libPaths()[1], dependencies = TRUE)

when they want to add packages, and update.packages(.libPaths()[1]) to 
update the packages they have installed.

Note that this works for Windows users too (although using ~ is perhaps 
dependent on setting HOME:  our Windows default use the network drive P: 
instead).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From u9126801 at stat.nctu.edu.tw  Mon Oct  3 10:46:54 2005
From: u9126801 at stat.nctu.edu.tw (Chin Chieh)
Date: Mon, 3 Oct 2005 16:46:54 +0800
Subject: [R] Foreign function calls without 'PACKAGE' argument
Message-ID: <00e401c5c7f7$01a642d0$2a72718c@winnie>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051003/bb5c3aaa/attachment.pl

From dieter.menne at menne-biomed.de  Mon Oct  3 11:37:34 2005
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Mon, 3 Oct 2005 09:37:34 +0000 (UTC)
Subject: [R] seeking an simple example of randomForest package - thanks!
References: <20051003071811.70922.qmail@web51411.mail.yahoo.com>
Message-ID: <loom.20051003T113705-230@post.gmane.org>

assic ma <assicma <at> yahoo.com> writes:

>     does anyboby have an simple example of
> classification by using randomForest? Thanks a lot! 

What's wrong with the simple example in the documentation?

Dieter



From frank.schmid at vwi.unibe.ch  Mon Oct  3 12:30:09 2005
From: frank.schmid at vwi.unibe.ch (Frank Schmid)
Date: Mon, 03 Oct 2005 12:30:09 +0200
Subject: [R] Save output
Message-ID: <0INS00H4I55H2C@ubecx01.unibe.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051003/26fd8177/attachment.pl

From vincent at 7d4.com  Mon Oct  3 13:38:13 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Mon, 03 Oct 2005 13:38:13 +0200
Subject: [R] Save output
In-Reply-To: <0INS00H4I55H2C@ubecx01.unibe.ch>
References: <0INS00H4I55H2C@ubecx01.unibe.ch>
Message-ID: <43411825.3000201@7d4.com>

Frank Schmid a ??crit :

> Dear R-Mastermind
> Within a while or a for-loop, is there a way that I can save to disk the
> results of the previous calculations at the end of each loop with filenames
> called "file01.Rdata", "file02.Rdata" etc?

as a toy example :

for (i in 1:nbfiles)
  {
  fullname = paste("myfile_",i, sep="");
  write.table(intable, fullname);
  }

see
?paste
hih



From Mike.Lawrence at Dal.Ca  Mon Oct  3 14:00:57 2005
From: Mike.Lawrence at Dal.Ca (Mike Lawrence)
Date: Mon,  3 Oct 2005 09:00:57 -0300
Subject: [R] Save output
In-Reply-To: <0INS00H4I55H2C@ubecx01.unibe.ch>
References: <0INS00H4I55H2C@ubecx01.unibe.ch>
Message-ID: <20051003090057.zdr7mmxt9zlgcsss@my1.dal.ca>

I think this is what you're looking for:

file_name_root = "myfile"

for(i in 1:10)

	result<- of_some_function

	out_file<-paste(file_name_root, i, ".txt", sep = "")

	write.table(result, file = out_file)

}

the above code produces 10 files ("myfile1.txt" to "myfile10.txt"), each
containing whatever was calculated on that loop. If you have loops 
within loops
and you want to write during the innermost loop, remember to take this into
account like so:

file_name_root = "myfile"

for (i in 1:10)

	for(q in 1:10)

		result<- of_some_function

		out_file<-paste(file_name_root, i, q, ".txt", sep = "")

		write.table(result, file = out_file)

	}

}

That way, when "i" iterates and when "q" resets to 1, you don't write 
over your
previous output.


Quoting Frank Schmid <frank.schmid at vwi.unibe.ch>:

> Dear R-Mastermind
>
>
> Within a while or a for-loop, is there a way that I can save to disk the
> results of the previous calculations at the end of each loop with filenames
> called "file01.Rdata", "file02.Rdata" etc?
>
> So far, I have tried to write the outcome of each loop in a 3 dimensional
> array and saved it just once after the loop. Or is there another way so that
> I can keep the resulting matrix of every step in the loop?
>
> Thank you very much for your help
>
>
> Frank Schmid
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



-- 

Mike Lawrence, BA(Hons)
Research Assistant to Dr. Gail Eskes
Dalhousie University & QEII Health Sciences Centre (Psychiatry)

Mike.Lawrence at Dal.Ca

"The road to Wisdom? Well, it's plain and simple to express:
Err and err and err again, but less and less and less."
- Piet Hein



From francoisromain at free.fr  Mon Oct  3 14:11:11 2005
From: francoisromain at free.fr (Romain Francois)
Date: Mon, 03 Oct 2005 14:11:11 +0200
Subject: [R] Save output
In-Reply-To: <0INS00H4I55H2C@ubecx01.unibe.ch>
References: <0INS00H4I55H2C@ubecx01.unibe.ch>
Message-ID: <43411FDF.7030406@free.fr>

Le 03.10.2005 12:30, Frank Schmid a ??crit :

> Dear R-Mastermind
>
>
> Within a while or a for-loop, is there a way that I can save to disk the
> results of the previous calculations at the end of each loop with 
> filenames
> called "file01.Rdata", "file02.Rdata" etc?
>
> So far, I have tried to write the outcome of each loop in a 3 dimensional
> array and saved it just once after the loop. Or is there another way 
> so that
> I can keep the resulting matrix of every step in the loop?
>
> Thank you very much for your help
>
>
> Frank Schmid
>  
>
?save
?sprintf

for(i in 1:12){
 tmp <- rnorm(10) # change it with your computations
 save(tmp, file=sprintf('file%02d.RData',i))
}

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~
~~~~~~      Romain FRANCOIS - http://addictedtor.free.fr         ~~~~~~
~~~~        Etudiant  ISUP - CS3 - Industrie et Services           ~~~~
~~                http://www.isup.cicrp.jussieu.fr/                  ~~
~~~~           Stagiaire INRIA Futurs - Equipe SELECT              ~~~~
~~~~~~   http://www.inria.fr/recherche/equipes/select.fr.html    ~~~~~~
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~



From andrea.zangrando at unipd.it  Mon Oct  3 14:24:35 2005
From: andrea.zangrando at unipd.it (Andrea Zangrando)
Date: Mon, 03 Oct 2005 14:24:35 +0200
Subject: [R] heatmap
Message-ID: <43412303.3060708@unipd.it>

Hi,
i created a graph with heatmap(sma) function:

heatmap(dataHeat(x))

and I wish to change the gradation of colors from blue to red, how could 
i do?
Using "heatmap(dataHeat(x), col=c(2,4))" i will use only 2 colors 
without gradation.

Ty so much
Andrea



From francoisromain at free.fr  Mon Oct  3 14:37:52 2005
From: francoisromain at free.fr (Romain Francois)
Date: Mon, 03 Oct 2005 14:37:52 +0200
Subject: [R] heatmap
In-Reply-To: <43412303.3060708@unipd.it>
References: <43412303.3060708@unipd.it>
Message-ID: <43412620.8040502@free.fr>

Le 03.10.2005 14:24, Andrea Zangrando a ??crit :

>Hi,
>i created a graph with heatmap(sma) function:
>
>heatmap(dataHeat(x))
>
>and I wish to change the gradation of colors from blue to red, how could 
>i do?
>Using "heatmap(dataHeat(x), col=c(2,4))" i will use only 2 colors 
>without gradation.
>
>Ty so much
>Andrea
>  
>
Hello,

Check bluered() in the gplots package.

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~
~~~~~~      Romain FRANCOIS - http://addictedtor.free.fr         ~~~~~~
~~~~        Etudiant  ISUP - CS3 - Industrie et Services           ~~~~
~~                http://www.isup.cicrp.jussieu.fr/                  ~~
~~~~           Stagiaire INRIA Futurs - Equipe SELECT              ~~~~
~~~~~~   http://www.inria.fr/recherche/equipes/select.fr.html    ~~~~~~
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~



From vincent at 7d4.com  Mon Oct  3 14:41:41 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Mon, 03 Oct 2005 14:41:41 +0200
Subject: [R] heatmap
In-Reply-To: <43412303.3060708@unipd.it>
References: <43412303.3060708@unipd.it>
Message-ID: <43412705.9040301@7d4.com>

Andrea Zangrando a ??crit :

> ... and I wish to change the gradation of colors 
> from blue to red, how could  i do?

Hello,
here's how I build such a palette.

a = 15;
palwhiteblue = rgb(a:0, a:0, a, max=a);
palredwhite  = rgb(a, 0:a, 0:a, max=a);
palwhite     = rep(rgb(1,1,1), 8);
palRWB       = c(palredwhite, palwhite, palwhiteblue);

of course, to adapt to your own uses.
hih
Vincent



From Roger.Bivand at nhh.no  Mon Oct  3 15:00:51 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 3 Oct 2005 15:00:51 +0200 (CEST)
Subject: [R] heatmap
In-Reply-To: <43412620.8040502@free.fr>
Message-ID: <Pine.LNX.4.44.0510031457300.31221-100000@reclus.nhh.no>

On Mon, 3 Oct 2005, Romain Francois wrote:

> Le 03.10.2005 14:24, Andrea Zangrando a ??crit :
> 
> >Hi,
> >i created a graph with heatmap(sma) function:
> >
> >heatmap(dataHeat(x))
> >
> >and I wish to change the gradation of colors from blue to red, how could 
> >i do?
> >Using "heatmap(dataHeat(x), col=c(2,4))" i will use only 2 colors 
> >without gradation.
> >
> >Ty so much
> >Andrea
> >  
> >
> Hello,
> 
> Check bluered() in the gplots package.

Or roll your own in base:

> myBlRd <- colorRampPalette(c("blue", "red"))
> myBlRd
function (n) 
{
    x <- ramp(seq(0, 1, length = n))
    rgb(x[, 1], x[, 2], x[, 3], max = 255)
}
<environment: 0x9a5792c>
> myBlRd(15)
 [1] "#0000FF" "#1200EC" "#2400DA" "#3600C8" "#4800B6" "#5B00A3" "#6D0091"
 [8] "#7F007F" "#91006D" "#A3005B" "#B60048" "#C80036" "#DA0024" "#EC0012"
[15] "#FF0000"


> 
> Romain
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From jerk_alert at hotmail.com  Mon Oct  3 15:41:05 2005
From: jerk_alert at hotmail.com (Ken Termiso)
Date: Mon, 03 Oct 2005 13:41:05 +0000
Subject: [R] Problem building/checking library that requires input from user
Message-ID: <BAY101-F32D302175FCA5ED52233B6E8800@phx.gbl>

Hi all,

I've got a package i've written that i am trying to check, build, and 
install. This is my 1st time doing this, so apologies in advance... ;)

The package that I've written requires input from the user. It needs to know 
sample sizes and then runs some calcs, (sample sizes are just integers), and 
it gets this info from the user as

num_reps <- readline("How many reps do you have... ")

num_reps <- as.integer(num_reps)

and then loops

for(i in 1:num_reps)
{
      #code
}


HOWEVER, I get this error msg when trying to check/build/install:

Error in 1:num_con_biol_reps : NA/NaN argument

Presumably this is because R thinks the variable is never initialized before 
i try to use it as a loop limit...

Anyway around this?? I tried initializing the num_reps variable in the code 
before the readline, but get the same error...


Thanks very much in advance,
Ken



From dmbates at gmail.com  Mon Oct  3 16:17:23 2005
From: dmbates at gmail.com (Douglas Bates)
Date: Mon, 3 Oct 2005 09:17:23 -0500
Subject: [R] Bug in lmer?
In-Reply-To: <20050930214401.77008.qmail@web50602.mail.yahoo.com>
References: <17212.59265.851874.843569@stat.math.ethz.ch>
	<20050930214401.77008.qmail@web50602.mail.yahoo.com>
Message-ID: <40e66e0b0510030717j71893e72u3610cc6c22ae2997@mail.gmail.com>

It is indeed a bug and I will address it.

On 9/30/05, Horacio Montenegro <nepossiver at yahoo.com> wrote:
>
>     Just to add more info:
>
>     I've got the same error with both lme4 0.95-10 &
> Matrix 0.95-13 and lme4 0.98-1 & Matrix 0.98-7, always
> running on Win98SE, R 2.1.1. So it seems to occur with
> any Windows version.
>
>     cheers,
>          Horacio
>
> >
> > I'm putting the data and an R script up for FTP,
> > so that you or others can run this ``from anywhere''
> > via
> >
> >
> >
> source("ftp://stat.ethz.ch/U/maechler/R/mltloc-ex.R",
> > echo = TRUE)
> >
> > Maybe this helps diagnosis,
> > Martin Maechler
> >
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Mon Oct  3 16:25:56 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 Oct 2005 15:25:56 +0100 (BST)
Subject: [R] Problem building/checking library that requires input from
 user
In-Reply-To: <BAY101-F32D302175FCA5ED52233B6E8800@phx.gbl>
References: <BAY101-F32D302175FCA5ED52233B6E8800@phx.gbl>
Message-ID: <Pine.LNX.4.61.0510031521160.4535@gannet.stats>

Either use \dontrun in a \examples{} section of a help page (see Writing 
R Extensions), or something like

num_reps <- if(interactive()) readline("How many reps do you have... ") else 500


On Mon, 3 Oct 2005, Ken Termiso wrote:

> Hi all,
>
> I've got a package i've written that i am trying to check, build, and
> install. This is my 1st time doing this, so apologies in advance... ;)
>
> The package that I've written requires input from the user. It needs to know
> sample sizes and then runs some calcs, (sample sizes are just integers), and
> it gets this info from the user as
>
> num_reps <- readline("How many reps do you have... ")
>
> num_reps <- as.integer(num_reps)
>
> and then loops
>
> for(i in 1:num_reps)
> {
>      #code
> }
>
>
> HOWEVER, I get this error msg when trying to check/build/install:
>
> Error in 1:num_con_biol_reps : NA/NaN argument
>
> Presumably this is because R thinks the variable is never initialized before
> i try to use it as a loop limit...
>
> Anyway around this?? I tried initializing the num_reps variable in the code
> before the readline, but get the same error...

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From reid_huntsinger at merck.com  Mon Oct  3 16:27:10 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Mon, 3 Oct 2005 10:27:10 -0400
Subject: [R] modeling language for optimization problems
Message-ID: <355C35514FEAC9458F75947F5270974D076D06@usctmx1103.merck.com>

Have you looked at the R interface to GLPK (the GNU Linear Programming Kit)?
http://cran.r-project.org/src/contrib/Descriptions/glpk.html

Reid Huntsinger

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Prof Brian Ripley
Sent: Sunday, October 02, 2005 10:38 AM
To: Paolo Cavatore
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] modeling language for optimization problems


On Sun, 2 Oct 2005, Paolo Cavatore wrote:

> Does anyone know whether R has its own modeling language for optimization
> problems (like SIMPLE in NuOPT for S-plus)?

No.  Note that SIMPLE is the language of NUOPT, not of S-PLUS.  There is 
an (extra-cost) interface module S+NUOPT, but it is an interface to 
NUOPT's engine.

As far as I am aware R itself covers almost none of the ground of S+NUOPT, 
and available packages cover only a small part of it.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Mon Oct  3 16:35:49 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 Oct 2005 15:35:49 +0100 (BST)
Subject: [R] modeling language for optimization problems
In-Reply-To: <355C35514FEAC9458F75947F5270974D076D06@usctmx1103.merck.com>
References: <355C35514FEAC9458F75947F5270974D076D06@usctmx1103.merck.com>
Message-ID: <Pine.LNX.4.61.0510031529370.4535@gannet.stats>

On Mon, 3 Oct 2005, Huntsinger, Reid wrote:

> Have you looked at the R interface to GLPK (the GNU Linear Programming Kit)?
> http://cran.r-project.org/src/contrib/Descriptions/glpk.html

NUOPT is not just about LP: the subject was `language for optimization'.
Its manual says

`NUOPT is a collection of powerful optimization methods, including:

- primal-dual interior point method with higher order correction for 
Linear Programming (LP) models.

- simplex method for Linear Programming (LP) and mixed integer programming 
(MILP) models.

- primal-dual interior point method based on line search for general 
Convex Programming (CP) models including convex Quadratic Programming 
(CQP) models.

- primal-dual interior point method based on trust region method for 
general Non-Linear Programming (NLP) models.

- primal-dual interior point method based on quasi-Newton method for 
general Non-Linear Programming (NLP) models.

- active set method for convex Quadratic Programming (CQP) models and 
mixed integer Quadratic Programming(MIQP) models.'

In any case, I don't see GLPK as a `language' and other LP solvers are 
available in R.


> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Prof Brian Ripley
> Sent: Sunday, October 02, 2005 10:38 AM
> To: Paolo Cavatore
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] modeling language for optimization problems
>
>
> On Sun, 2 Oct 2005, Paolo Cavatore wrote:
>
>> Does anyone know whether R has its own modeling language for optimization
>> problems (like SIMPLE in NuOPT for S-plus)?
>
> No.  Note that SIMPLE is the language of NUOPT, not of S-PLUS.  There is
> an (extra-cost) interface module S+NUOPT, but it is an interface to
> NUOPT's engine.
>
> As far as I am aware R itself covers almost none of the ground of S+NUOPT,
> and available packages cover only a small part of it.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mkondrin at hppi.troitsk.ru  Mon Oct  3 16:36:36 2005
From: mkondrin at hppi.troitsk.ru (mkondrin)
Date: Mon, 03 Oct 2005 18:36:36 +0400
Subject: [R] grob questions
In-Reply-To: <971536df0510022237v7b91c484g2cb998321d192d5b@mail.gmail.com>
References: <971536df0510022237v7b91c484g2cb998321d192d5b@mail.gmail.com>
Message-ID: <434141F4.5070302@hppi.troitsk.ru>

Gabor Grothendieck wrote:

>If I run the following example from:
>http://www.stat.auckland.ac.nz/~paul/grid/doc/grobs.pdf
>
>  
>
>>grid.newpage()
>>pushViewport(viewport(w = 0.5, h = 0.5))
>>myplot <- gTree(name = "myplot", children = gList(rectGrob(name = "box",
>>    
>>
>+ gp = gpar(col = "grey")), xaxisGrob(name = "xaxis")))
>  
>
>>grid.draw(myplot)
>>grid.edit("myplot::xaxis", at = 1:10/11)
>>grid.edit("myplot::xaxis::labels", label = round(1:10/11, 2))
>>grid.edit("myplot::xaxis::labels", y = unit(-1, "lines"))
>>    
>>
>
>then
>
>  
>
>>str(myplot$children$xaxis)
>>    
>>
>
>lists 'at' but not the 'labels'.
>
>yet if I do this then the labels are listed:
>
>  
>
>>xx <- xaxisGrob(name = "myX", at = 1:10)
>>childNames(xx)
>>    
>>
>[1] "major"  "ticks"  "labels"
>
>
>1. How do I get to labels in the first case?
>
>2. Is there a better construct than myplot$children$xaxis?
>
>Thanks.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>
grid.get("myplot::xaxis::labels")$label

or

grid.get("myplot::xaxis")$children$labels$label

R-object representing grob in R (in your case this is - myplot) is not 
dynamic you have to update it with grid.get. The argument is the name of 
the grob.



From mkondrin at hppi.troitsk.ru  Mon Oct  3 16:49:26 2005
From: mkondrin at hppi.troitsk.ru (mkondrin)
Date: Mon, 03 Oct 2005 18:49:26 +0400
Subject: [R] Foreign function calls without 'PACKAGE' argument
In-Reply-To: <00e401c5c7f7$01a642d0$2a72718c@winnie>
References: <00e401c5c7f7$01a642d0$2a72718c@winnie>
Message-ID: <434144F6.1040501@hppi.troitsk.ru>

Chin Chieh wrote:

>as title,when I check my own R package
>It appear the warning:Foreign function calls without 'PACKAGE' argument, I don't know what's wrong....can somebody help me ,thanks
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>
This is a warning not an error. .C, .Call and friends functions take 
optional PACKAGE argument. See ?.Call for details.



From JAROSLAW.W.TUSZYNSKI at saic.com  Mon Oct  3 17:00:15 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Mon, 3 Oct 2005 11:00:15 -0400 
Subject: [R] dec2bin?
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD503DF883A@us-arlington-0668.mail.saic.com>

It is unclear what you are trying to do, but check bin2raw in caTools
package:

>  print(x <- (1:5)*pi)      
[1]  3.141593  6.283185  9.424778 12.566371
[5] 15.707963
>         print(y <- bin2raw(x))
 [1] 18 2d 44 54 fb 21 09 40 18 2d 44 54 fb 21 19
[16] 40 d2 21 33 7f 7c d9 22 40 18 2d 44 54 fb 21
[31] 29 40 5e 38 55 29 7a 6a 2f 40
>         print(z <- raw2bin(y,"double"))
[1]  3.141593  6.283185  9.424778 12.566371
[5] 15.707963 


May be that is what you need.

 Jarek 
====================================================\==== 
 Jarek Tuszynski, PhD.                           o / \ 
 Science Applications International Corporation  <\__,|  
 (703) 676-4192                                   ">  \ 
 Jaroslaw.W.Tuszynski at saic.com                     `   \ 



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Haiyong Xu
Sent: Saturday, October 01, 2005 4:22 PM
To: Help R
Subject: [R] dec2bin?

Hello,

I just want to ask if there is any function that can convert decimal number
to binary vector.

Thanks a lot.
Haiyong

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From kevinvol2002 at yahoo.com  Mon Oct  3 17:41:32 2005
From: kevinvol2002 at yahoo.com (Hai Lin)
Date: Mon, 3 Oct 2005 08:41:32 -0700 (PDT)
Subject: [R] lmList error message
In-Reply-To: <x2fyxu7tmb.fsf@turmalin.kubism.ku.dk>
Message-ID: <20051003154132.9128.qmail@web32401.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051003/ff80ab64/attachment.pl

From jerk_alert at hotmail.com  Mon Oct  3 17:41:31 2005
From: jerk_alert at hotmail.com (Ken Termiso)
Date: Mon, 03 Oct 2005 15:41:31 +0000
Subject: [R] Problem building/checking library that requires input from
	user
Message-ID: <BAY101-F302DF2042124B7E0E3C10AE8800@phx.gbl>

Thanks, Dr Warnes & Prof Ripley...

However, upon following the instructions below, I'm getting syntax errors on 
the line that has \dontshow...below is my code...I get the same error if i 
omit the first block and just try \dontrun...

\dontshow{
num_reps <- 10
}

\dontrun{
num_reps <- readline(""How many reps do you have... ")
num_reps <- as.integer(num_reps)
}


could this have anything to do with it running on OS X 10.3 ?? (long 
shot...but i'm thoroughly lost)..

thanks again,
ken


>From: "Warnes, Gregory R" <gregory.r.warnes at pfizer.com>
>To: "'Ken Termiso'" <jerk_alert at hotmail.com>
>Subject: RE: [R] Problem building/checking library that requires input from 
>user
>Date: Mon, 3 Oct 2005 10:11:15 -0400
>
>
>Try changing the example code to:
>
>\dontshow{
>   num_reps <- 10
>}
>\dontrun{
>   num_reps <- readline("How many reps do you have... ")
>   num_reps <- as.integer(num_reps)
>}
>
>-Greg
>
>
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Ken Termiso
> > Sent: Monday, October 03, 2005 9:41 AM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] Problem building/checking library that requires
> > input from
> > user
> >
> >
> > Hi all,
> >
> > I've got a package i've written that i am trying to check, build, and
> > install. This is my 1st time doing this, so apologies in advance... ;)
> >
> > The package that I've written requires input from the user.
> > It needs to know
> > sample sizes and then runs some calcs, (sample sizes are just
> > integers), and
> > it gets this info from the user as
> >
> > num_reps <- readline("How many reps do you have... ")
> >
> > num_reps <- as.integer(num_reps)
> >
> > and then loops
> >
> > for(i in 1:num_reps)
> > {
> >       #code
> > }
> >
> >
> > HOWEVER, I get this error msg when trying to check/build/install:
> >
> > Error in 1:num_con_biol_reps : NA/NaN argument
> >
> > Presumably this is because R thinks the variable is never
> > initialized before
> > i try to use it as a loop limit...
> >
> > Anyway around this?? I tried initializing the num_reps
> > variable in the code
> > before the readline, but get the same error...
> >
> >
> > Thanks very much in advance,
> > Ken
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> >
>----------------------------------------------------------------------
>LEGAL NOTICE
>Unless expressly stated otherwise, this message is confidential and may be 
>privileged.  It is intended for the addressee(s) only.  Access to this 
>E-mail by anyone else is unauthorized.  If you are not an addressee, any 
>disclosure or copying of the contents of this E-mail or any action taken 
>(or not taken) in reliance on it is unauthorized and may be unlawful.  If 
>you are not an addressee, please inform the sender immediately.



From gregory.r.warnes at pfizer.com  Mon Oct  3 17:48:28 2005
From: gregory.r.warnes at pfizer.com (Warnes, Gregory R)
Date: Mon, 3 Oct 2005 11:48:28 -0400 
Subject: [R] Problem building/checking library that requires input fro	m
	user
Message-ID: <915D2D65A9986440A277AC5C98AA466F01863400@groamrexm02.amer.pfizer.com>

What file are you putting these into?  

I believe this is the correct syntax for the \example{} section of an .Rd
file.

If you want to do this in a plain R file, (e.g. package/tests/somename.R),
you can use 

if(interactive)
{
 num_reps <- readline(""How many reps do you have... ")
 num_reps <- as.integer(num_reps)
}
else
 num_reps <- 10

instead.

-G


> -----Original Message-----
> From: Ken Termiso [mailto:jerk_alert at hotmail.com]
> Sent: Monday, October 03, 2005 11:42 AM
> To: Warnes, Gregory R; ripley at stats.ox.ac.uk
> Cc: r-help at stat.math.ethz.ch
> Subject: RE: [R] Problem building/checking library that requires input
> from user
> 
> 
> Thanks, Dr Warnes & Prof Ripley...
> 
> However, upon following the instructions below, I'm getting 
> syntax errors on 
> the line that has \dontshow...below is my code...I get the 
> same error if i 
> omit the first block and just try \dontrun...
> 
> \dontshow{
> num_reps <- 10
> }
> 
> \dontrun{
> num_reps <- readline(""How many reps do you have... ")
> num_reps <- as.integer(num_reps)
> }
> 
> 
> could this have anything to do with it running on OS X 10.3 ?? (long 
> shot...but i'm thoroughly lost)..
> 
> thanks again,
> ken
> 
> 
> >From: "Warnes, Gregory R" <gregory.r.warnes at pfizer.com>
> >To: "'Ken Termiso'" <jerk_alert at hotmail.com>
> >Subject: RE: [R] Problem building/checking library that 
> requires input from 
> >user
> >Date: Mon, 3 Oct 2005 10:11:15 -0400
> >
> >
> >Try changing the example code to:
> >
> >\dontshow{
> >   num_reps <- 10
> >}
> >\dontrun{
> >   num_reps <- readline("How many reps do you have... ")
> >   num_reps <- as.integer(num_reps)
> >}
> >
> >-Greg
> >
> >
> > > -----Original Message-----
> > > From: r-help-bounces at stat.math.ethz.ch
> > > [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Ken Termiso
> > > Sent: Monday, October 03, 2005 9:41 AM
> > > To: r-help at stat.math.ethz.ch
> > > Subject: [R] Problem building/checking library that requires
> > > input from
> > > user
> > >
> > >
> > > Hi all,
> > >
> > > I've got a package i've written that i am trying to 
> check, build, and
> > > install. This is my 1st time doing this, so apologies in 
> advance... ;)
> > >
> > > The package that I've written requires input from the user.
> > > It needs to know
> > > sample sizes and then runs some calcs, (sample sizes are just
> > > integers), and
> > > it gets this info from the user as
> > >
> > > num_reps <- readline("How many reps do you have... ")
> > >
> > > num_reps <- as.integer(num_reps)
> > >
> > > and then loops
> > >
> > > for(i in 1:num_reps)
> > > {
> > >       #code
> > > }
> > >
> > >
> > > HOWEVER, I get this error msg when trying to check/build/install:
> > >
> > > Error in 1:num_con_biol_reps : NA/NaN argument
> > >
> > > Presumably this is because R thinks the variable is never
> > > initialized before
> > > i try to use it as a loop limit...
> > >
> > > Anyway around this?? I tried initializing the num_reps
> > > variable in the code
> > > before the readline, but get the same error...
> > >
> > >
> > > Thanks very much in advance,
> > > Ken
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> > >
> > >
> >-------------------------------------------------------------
> ---------
> >LEGAL NOTICE
> >Unless expressly stated otherwise, this message is 
> confidential and may be 
> >privileged.  It is intended for the addressee(s) only.  
> Access to this 
> >E-mail by anyone else is unauthorized.  If you are not an 
> addressee, any 
> >disclosure or copying of the contents of this E-mail or any 
> action taken 
> >(or not taken) in reliance on it is unauthorized and may be 
> unlawful.  If 
> >you are not an addressee, please inform the sender immediately.
> 
> 
> 
>



From ripley at stats.ox.ac.uk  Mon Oct  3 17:49:16 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 Oct 2005 16:49:16 +0100 (BST)
Subject: [R] dec2bin?
In-Reply-To: <CA0BCF3BED56294AB91E3AD74B849FD503DF883A@us-arlington-0668.mail.saic.com>
References: <CA0BCF3BED56294AB91E3AD74B849FD503DF883A@us-arlington-0668.mail.saic.com>
Message-ID: <Pine.LNX.4.61.0510031633340.5644@gannet.stats>

On Mon, 3 Oct 2005, Tuszynski, Jaroslaw W. wrote:

> It is unclear what you are trying to do, but check bin2raw in caTools
> package:
>
>>  print(x <- (1:5)*pi)
> [1]  3.141593  6.283185  9.424778 12.566371
> [5] 15.707963
>>         print(y <- bin2raw(x))
> [1] 18 2d 44 54 fb 21 09 40 18 2d 44 54 fb 21 19
> [16] 40 d2 21 33 7f 7c d9 22 40 18 2d 44 54 fb 21
> [31] 29 40 5e 38 55 29 7a 6a 2f 40
>>         print(z <- raw2bin(y,"double"))
> [1]  3.141593  6.283185  9.424778 12.566371
> [5] 15.707963
>
>
> May be that is what you need.

I fail to see what that has to do with the question (there are no `binary 
vectors' in the answer - raw vectors are no more or less binary than 
numeric ones), but in any case it can be done in base R 2.2.0 more 
efficiently by

> options(width=50)
> (y <- writeBin(x, raw()))
  [1] 18 2d 44 54 fb 21 09 40 18 2d 44 54 fb 21 19
[16] 40 d2 21 33 7f 7c d9 22 40 18 2d 44 54 fb 21
[31] 29 40 5e 38 55 29 7a 6a 2f 40


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Haiyong Xu
> Sent: Saturday, October 01, 2005 4:22 PM
> To: Help R
> Subject: [R] dec2bin?
>
> Hello,
>
> I just want to ask if there is any function that can convert decimal number
> to binary vector.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From afshart at exchange.sba.miami.edu  Mon Oct  3 18:16:40 2005
From: afshart at exchange.sba.miami.edu (Afshartous, David)
Date: Mon, 3 Oct 2005 12:16:40 -0400
Subject: [R] "symbol print-name too long"
Message-ID: <6BCB4D493A447546A8126F24332056E8F28B71@school1.business.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051003/63a65db5/attachment.pl

From Daniel.Pick at biogenidec.com  Mon Oct  3 18:15:53 2005
From: Daniel.Pick at biogenidec.com (Daniel Pick)
Date: Mon, 3 Oct 2005 09:15:53 -0700
Subject: [R] gnomeGUI installation
Message-ID: <OF1BA15286.1992BF70-ON8825708F.0058A8DE-8825708F.0059792A@biogenidec.com>


Hello,
   I have successfully downloaded the sources and built R as a shared
library on a Red Hat Enterprise Level 3 box.  I am now trying to build the
GNOME GUI, but configure is barfing on glade.  According to the system
logs, the RPM for libglade2-devel-2.0.1-3.x86_64 is installed, but in
/usr/bin, where gnomeGUI configure is looking, what's there is
libglade-convert.  How do I fix this?

Dan



From ligges at statistik.uni-dortmund.de  Mon Oct  3 18:25:26 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 03 Oct 2005 18:25:26 +0200
Subject: [R] Problem building/checking library that requires input from
 user
In-Reply-To: <BAY101-F302DF2042124B7E0E3C10AE8800@phx.gbl>
References: <BAY101-F302DF2042124B7E0E3C10AE8800@phx.gbl>
Message-ID: <43415B76.3010101@statistik.uni-dortmund.de>

Ken Termiso wrote:

> Thanks, Dr Warnes & Prof Ripley...
> 
> However, upon following the instructions below, I'm getting syntax errors on 
> the line that has \dontshow...below is my code...I get the same error if i 
> omit the first block and just try \dontrun...
> 
> \dontshow{
> num_reps <- 10
> }
> 
> \dontrun{
> num_reps <- readline(""How many reps do you have... ")

Here is a syntax error, obviously.... (hint: "")

Uwe Ligges


> num_reps <- as.integer(num_reps)
> }
> 
> 
> could this have anything to do with it running on OS X 10.3 ?? (long 
> shot...but i'm thoroughly lost)..
> 
> thanks again,
> ken
> 
> 
> 
>>From: "Warnes, Gregory R" <gregory.r.warnes at pfizer.com>
>>To: "'Ken Termiso'" <jerk_alert at hotmail.com>
>>Subject: RE: [R] Problem building/checking library that requires input from 
>>user
>>Date: Mon, 3 Oct 2005 10:11:15 -0400
>>
>>
>>Try changing the example code to:
>>
>>\dontshow{
>>  num_reps <- 10
>>}
>>\dontrun{
>>  num_reps <- readline("How many reps do you have... ")
>>  num_reps <- as.integer(num_reps)
>>}
>>
>>-Greg
>>
>>
>>
>>>-----Original Message-----
>>>From: r-help-bounces at stat.math.ethz.ch
>>>[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Ken Termiso
>>>Sent: Monday, October 03, 2005 9:41 AM
>>>To: r-help at stat.math.ethz.ch
>>>Subject: [R] Problem building/checking library that requires
>>>input from
>>>user
>>>
>>>
>>>Hi all,
>>>
>>>I've got a package i've written that i am trying to check, build, and
>>>install. This is my 1st time doing this, so apologies in advance... ;)
>>>
>>>The package that I've written requires input from the user.
>>>It needs to know
>>>sample sizes and then runs some calcs, (sample sizes are just
>>>integers), and
>>>it gets this info from the user as
>>>
>>>num_reps <- readline("How many reps do you have... ")
>>>
>>>num_reps <- as.integer(num_reps)
>>>
>>>and then loops
>>>
>>>for(i in 1:num_reps)
>>>{
>>>      #code
>>>}
>>>
>>>
>>>HOWEVER, I get this error msg when trying to check/build/install:
>>>
>>>Error in 1:num_con_biol_reps : NA/NaN argument
>>>
>>>Presumably this is because R thinks the variable is never
>>>initialized before
>>>i try to use it as a loop limit...
>>>
>>>Anyway around this?? I tried initializing the num_reps
>>>variable in the code
>>>before the readline, but get the same error...
>>>
>>>
>>>Thanks very much in advance,
>>>Ken
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide!
>>>http://www.R-project.org/posting-guide.html
>>>
>>>
>>
>>----------------------------------------------------------------------
>>LEGAL NOTICE
>>Unless expressly stated otherwise, this message is confidential and may be 
>>privileged.  It is intended for the addressee(s) only.  Access to this 
>>E-mail by anyone else is unauthorized.  If you are not an addressee, any 
>>disclosure or copying of the contents of this E-mail or any action taken 
>>(or not taken) in reliance on it is unauthorized and may be unlawful.  If 
>>you are not an addressee, please inform the sender immediately.
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From jerk_alert at hotmail.com  Mon Oct  3 18:29:13 2005
From: jerk_alert at hotmail.com (Ken Termiso)
Date: Mon, 03 Oct 2005 16:29:13 +0000
Subject: [R] Problem building/checking library that requires input from
	user
Message-ID: <BAY101-F793D4373E8F89D83AA682E8800@phx.gbl>

It was in a plain R file...I did not interpret the word 'example' in your 
email as I should've...

So, i've been able to fix the num_reps variable problem - thanks!!



>From: "Warnes, Gregory R" <gregory.r.warnes at pfizer.com>
>To: "'Ken Termiso'" <jerk_alert at hotmail.com>
>CC: "R-Help (E-mail)" <r-help at stat.math.ethz.ch>
>Subject: RE: [R] Problem building/checking library that requires input from 
>user
>Date: Mon, 3 Oct 2005 11:48:28 -0400
>
>What file are you putting these into?
>
>I believe this is the correct syntax for the \example{} section of an .Rd
>file.
>
>If you want to do this in a plain R file, (e.g. package/tests/somename.R),
>you can use
>
>if(interactive)
>{
>  num_reps <- readline(""How many reps do you have... ")
>  num_reps <- as.integer(num_reps)
>}
>else
>  num_reps <- 10
>
>instead.
>
>-G
>
>
> > -----Original Message-----
> > From: Ken Termiso [mailto:jerk_alert at hotmail.com]
> > Sent: Monday, October 03, 2005 11:42 AM
> > To: Warnes, Gregory R; ripley at stats.ox.ac.uk
> > Cc: r-help at stat.math.ethz.ch
> > Subject: RE: [R] Problem building/checking library that requires input
> > from user
> >
> >
> > Thanks, Dr Warnes & Prof Ripley...
> >
> > However, upon following the instructions below, I'm getting
> > syntax errors on
> > the line that has \dontshow...below is my code...I get the
> > same error if i
> > omit the first block and just try \dontrun...
> >
> > \dontshow{
> > num_reps <- 10
> > }
> >
> > \dontrun{
> > num_reps <- readline(""How many reps do you have... ")
> > num_reps <- as.integer(num_reps)
> > }
> >
> >
> > could this have anything to do with it running on OS X 10.3 ?? (long
> > shot...but i'm thoroughly lost)..
> >
> > thanks again,
> > ken
> >
> >
> > >From: "Warnes, Gregory R" <gregory.r.warnes at pfizer.com>
> > >To: "'Ken Termiso'" <jerk_alert at hotmail.com>
> > >Subject: RE: [R] Problem building/checking library that
> > requires input from
> > >user
> > >Date: Mon, 3 Oct 2005 10:11:15 -0400
> > >
> > >
> > >Try changing the example code to:
> > >
> > >\dontshow{
> > >   num_reps <- 10
> > >}
> > >\dontrun{
> > >   num_reps <- readline("How many reps do you have... ")
> > >   num_reps <- as.integer(num_reps)
> > >}
> > >
> > >-Greg
> > >
> > >
> > > > -----Original Message-----
> > > > From: r-help-bounces at stat.math.ethz.ch
> > > > [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Ken Termiso
> > > > Sent: Monday, October 03, 2005 9:41 AM
> > > > To: r-help at stat.math.ethz.ch
> > > > Subject: [R] Problem building/checking library that requires
> > > > input from
> > > > user
> > > >
> > > >
> > > > Hi all,
> > > >
> > > > I've got a package i've written that i am trying to
> > check, build, and
> > > > install. This is my 1st time doing this, so apologies in
> > advance... ;)
> > > >
> > > > The package that I've written requires input from the user.
> > > > It needs to know
> > > > sample sizes and then runs some calcs, (sample sizes are just
> > > > integers), and
> > > > it gets this info from the user as
> > > >
> > > > num_reps <- readline("How many reps do you have... ")
> > > >
> > > > num_reps <- as.integer(num_reps)
> > > >
> > > > and then loops
> > > >
> > > > for(i in 1:num_reps)
> > > > {
> > > >       #code
> > > > }
> > > >
> > > >
> > > > HOWEVER, I get this error msg when trying to check/build/install:
> > > >
> > > > Error in 1:num_con_biol_reps : NA/NaN argument
> > > >
> > > > Presumably this is because R thinks the variable is never
> > > > initialized before
> > > > i try to use it as a loop limit...
> > > >
> > > > Anyway around this?? I tried initializing the num_reps
> > > > variable in the code
> > > > before the readline, but get the same error...
> > > >
> > > >
> > > > Thanks very much in advance,
> > > > Ken
> > > >
> > > > ______________________________________________
> > > > R-help at stat.math.ethz.ch mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide!
> > > > http://www.R-project.org/posting-guide.html
> > > >
> > > >
> > >-------------------------------------------------------------
> > ---------
> > >LEGAL NOTICE
> > >Unless expressly stated otherwise, this message is
> > confidential and may be
> > >privileged.  It is intended for the addressee(s) only.
> > Access to this
> > >E-mail by anyone else is unauthorized.  If you are not an
> > addressee, any
> > >disclosure or copying of the contents of this E-mail or any
> > action taken
> > >(or not taken) in reliance on it is unauthorized and may be
> > unlawful.  If
> > >you are not an addressee, please inform the sender immediately.
> >
> >
> >
> >



From ripley at stats.ox.ac.uk  Mon Oct  3 19:01:58 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 Oct 2005 18:01:58 +0100 (BST)
Subject: [R] gnomeGUI installation
In-Reply-To: <OF1BA15286.1992BF70-ON8825708F.0058A8DE-8825708F.0059792A@biogenidec.com>
References: <OF1BA15286.1992BF70-ON8825708F.0058A8DE-8825708F.0059792A@biogenidec.com>
Message-ID: <Pine.LNX.4.61.0510031747390.17887@gannet.stats>

On Mon, 3 Oct 2005, Daniel Pick wrote:

>   I have successfully downloaded the sources and built R as a shared
> library on a Red Hat Enterprise Level 3 box.  I am now trying to build the
> GNOME GUI, but configure is barfing on glade.  According to the system
> logs, the RPM for libglade2-devel-2.0.1-3.x86_64 is installed, but in
> /usr/bin, where gnomeGUI configure is looking, what's there is
> libglade-convert.  How do I fix this?

By reading the manual.  In the R-admin manual it says

`Please check you have all the requirements.  You need at least the
following packages or later installed:

audiofile-0.2.1
esound-0.2.23
glib-1.2.10
gtk+-1.2.10
imlib-1.9.10
ORBit-0.5.12
gnome-libs-1.4.1.2
libxml-1.8.16
libglade-0.17

...

Remember that some package management systems (such as @acronym{RPM} and
deb) make a distinction between the user version of a package and the
developer version.  The latter usually has the same name but with the
extension @samp{-devel} or @samp{-dev}.  If you use a pre-packaged
version of @acronym{GNOME} then you must have the developer versions of
the above packages in order to compile the R-GNOME console.'

My FC3 box has

gannet% rpm -qa | grep ^libglade
libglade2-devel-2.4.0-5
libglade-devel-0.17-15
libglade2-2.4.0-5
libglade-0.17-15

and note that libglade2[-devel] is NOT a later version of libglade (in the 
same way that gtk2 is different from gtk).

AFAICS it is likely that /usr/bin/libglade-config is provided by 
libglade-devel-0.17-15.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From roger.bos at gmail.com  Mon Oct  3 19:09:21 2005
From: roger.bos at gmail.com (roger bos)
Date: Mon, 3 Oct 2005 13:09:21 -0400
Subject: [R] modeling language for optimization problems
In-Reply-To: <Pine.LNX.4.61.0510031529370.4535@gannet.stats>
References: <355C35514FEAC9458F75947F5270974D076D06@usctmx1103.merck.com>
	<Pine.LNX.4.61.0510031529370.4535@gannet.stats>
Message-ID: <1db726800510031009q3350e2d6h88e41cdbfc6c60f6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051003/4021ebb6/attachment.pl

From dmbates at gmail.com  Mon Oct  3 19:18:22 2005
From: dmbates at gmail.com (Douglas Bates)
Date: Mon, 3 Oct 2005 12:18:22 -0500
Subject: [R] modeling language for optimization problems
In-Reply-To: <1db726800510031009q3350e2d6h88e41cdbfc6c60f6@mail.gmail.com>
References: <355C35514FEAC9458F75947F5270974D076D06@usctmx1103.merck.com>
	<Pine.LNX.4.61.0510031529370.4535@gannet.stats>
	<1db726800510031009q3350e2d6h88e41cdbfc6c60f6@mail.gmail.com>
Message-ID: <40e66e0b0510031018rd79361fw66e7c6d9e4eda205@mail.gmail.com>

On 10/3/05, roger bos <roger.bos at gmail.com> wrote:
> Paolo,
>  As others have alluded, R does not have any one package that is as
> versatile and powerful as NuOpt, but R does have many different optimization
> packages, so you can do LP, QP, Integer programming, and many more types of
> optimization, all without having to learn a new language. But being free,
> they are admittedly not as powerful as NuOpt. The main thing I know you can
> do in NuOpt that you cannot do in R (to my knowledge) is mixed integer
> quadratic programming, which would be nice, but there are many work arounds.
>  Thanks,
>  Roger

The Dakota project  http://endo.sandia.gov/DAKOTA/ provides an
interface to many different open source or freely available
optimization routines.  I haven't checked whether mixed integer
programming is included in the collection.

>  On 10/3/05, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> >
> > On Mon, 3 Oct 2005, Huntsinger, Reid wrote:
> >
> > > Have you looked at the R interface to GLPK (the GNU Linear Programming
> > Kit)?
> > > http://cran.r-project.org/src/contrib/Descriptions/glpk.html
> >
> > NUOPT is not just about LP: the subject was `language for optimization'.
> > Its manual says
> >
> > `NUOPT is a collection of powerful optimization methods, including:
> >
> > - primal-dual interior point method with higher order correction for
> > Linear Programming (LP) models.
> >
> > - simplex method for Linear Programming (LP) and mixed integer programming
> > (MILP) models.
> >
> > - primal-dual interior point method based on line search for general
> > Convex Programming (CP) models including convex Quadratic Programming
> > (CQP) models.
> >
> > - primal-dual interior point method based on trust region method for
> > general Non-Linear Programming (NLP) models.
> >
> > - primal-dual interior point method based on quasi-Newton method for
> > general Non-Linear Programming (NLP) models.
> >
> > - active set method for convex Quadratic Programming (CQP) models and
> > mixed integer Quadratic Programming(MIQP) models.'
> >
> > In any case, I don't see GLPK as a `language' and other LP solvers are
> > available in R.
> >
> >
> > > From: r-help-bounces at stat.math.ethz.ch
> > > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Prof Brian Ripley
> > > Sent: Sunday, October 02, 2005 10:38 AM
> > > To: Paolo Cavatore
> > > Cc: r-help at stat.math.ethz.ch
> > > Subject: Re: [R] modeling language for optimization problems
> > >
> > >
> > > On Sun, 2 Oct 2005, Paolo Cavatore wrote:
> > >
> > >> Does anyone know whether R has its own modeling language for
> > optimization
> > >> problems (like SIMPLE in NuOPT for S-plus)?
> > >
> > > No. Note that SIMPLE is the language of NUOPT, not of S-PLUS. There is
> > > an (extra-cost) interface module S+NUOPT, but it is an interface to
> > > NUOPT's engine.
> > >
> > > As far as I am aware R itself covers almost none of the ground of
> > S+NUOPT,
> > > and available packages cover only a small part of it.
> >
> > --
> > Brian D. Ripley, ripley at stats.ox.ac.uk
> > Professor of Applied Statistics, http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford, Tel: +44 1865 272861 (self)
> > 1 South Parks Road, +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK Fax: +44 1865 272595
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From mschwartz at mn.rr.com  Mon Oct  3 19:21:38 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Mon, 03 Oct 2005 12:21:38 -0500
Subject: [R] gnomeGUI installation
In-Reply-To: <Pine.LNX.4.61.0510031747390.17887@gannet.stats>
References: <OF1BA15286.1992BF70-ON8825708F.0058A8DE-8825708F.0059792A@biogenidec.com>
	<Pine.LNX.4.61.0510031747390.17887@gannet.stats>
Message-ID: <1128360098.5957.9.camel@localhost.localdomain>

On Mon, 2005-10-03 at 18:01 +0100, Prof Brian Ripley wrote:
> On Mon, 3 Oct 2005, Daniel Pick wrote:
> 
> >   I have successfully downloaded the sources and built R as a shared
> > library on a Red Hat Enterprise Level 3 box.  I am now trying to build the
> > GNOME GUI, but configure is barfing on glade.  According to the system
> > logs, the RPM for libglade2-devel-2.0.1-3.x86_64 is installed, but in
> > /usr/bin, where gnomeGUI configure is looking, what's there is
> > libglade-convert.  How do I fix this?
> 
> By reading the manual.  In the R-admin manual it says
> 
> `Please check you have all the requirements.  You need at least the
> following packages or later installed:
> 
> audiofile-0.2.1
> esound-0.2.23
> glib-1.2.10
> gtk+-1.2.10
> imlib-1.9.10
> ORBit-0.5.12
> gnome-libs-1.4.1.2
> libxml-1.8.16
> libglade-0.17
> 
> ...
> 
> Remember that some package management systems (such as @acronym{RPM} and
> deb) make a distinction between the user version of a package and the
> developer version.  The latter usually has the same name but with the
> extension @samp{-devel} or @samp{-dev}.  If you use a pre-packaged
> version of @acronym{GNOME} then you must have the developer versions of
> the above packages in order to compile the R-GNOME console.'
> 
> My FC3 box has
> 
> gannet% rpm -qa | grep ^libglade
> libglade2-devel-2.4.0-5
> libglade-devel-0.17-15
> libglade2-2.4.0-5
> libglade-0.17-15
> 
> and note that libglade2[-devel] is NOT a later version of libglade (in the 
> same way that gtk2 is different from gtk).
> 
> AFAICS it is likely that /usr/bin/libglade-config is provided by 
> libglade-devel-0.17-15.


That is correct, subject of course to RPM version differences between
FC3/4 and RHEL3/4.  Using RPM, this can be confirmed with:

$ rpm -q --whatprovides /usr/bin/libglade-config
libglade-devel-0.17-16

which is the output on FC4.

HTH,

Marc Schwartz



From JAROSLAW.W.TUSZYNSKI at saic.com  Mon Oct  3 19:26:17 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Mon, 3 Oct 2005 13:26:17 -0400 
Subject: [R] dec2bin?
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD503DF8A22@us-arlington-0668.mail.saic.com>

Function bin2raw was written in order to convert vectors of any type into
vectors containing binary form (little or big endian) of those values
(stored in hex format as 'raw' since it is the only 1-byte type in R). It
was needed in order to convert R vectors to Base64 format commonly used by
XML files. 

It is a great news that next version of R (2.2.0) will extend capabilities
of writeBin function to do the same. If it is more efficient (most likely)
than bin2raw and raw2bin will be retired. In the current version of R the
best solution I could find was too inefficient:

    print(x <- (1:5)*pi)
    writeBin(x, "temp.dat")
    y = readBin("temp.dat", "raw", n = length(x)*8)
    y

 Jarek 
====================================================\==== 
 Jarek Tuszynski, PhD.                           o / \ 
 Science Applications International Corporation  <\__,|  
 (703) 676-4192                                   ">  \ 
 Jaroslaw.W.Tuszynski at saic.com                     `   \ 



-----Original Message-----
From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk] 
Sent: Monday, October 03, 2005 11:49 AM
To: Tuszynski, Jaroslaw W.
Cc: Haiyong Xu; Help R
Subject: Re: [R] dec2bin?

On Mon, 3 Oct 2005, Tuszynski, Jaroslaw W. wrote:

> It is unclear what you are trying to do, but check bin2raw in caTools
> package:
>
>>  print(x <- (1:5)*pi)
> [1]  3.141593  6.283185  9.424778 12.566371 [5] 15.707963
>>         print(y <- bin2raw(x))
> [1] 18 2d 44 54 fb 21 09 40 18 2d 44 54 fb 21 19 [16] 40 d2 21 33 7f 
> 7c d9 22 40 18 2d 44 54 fb 21 [31] 29 40 5e 38 55 29 7a 6a 2f 40
>>         print(z <- raw2bin(y,"double"))
> [1]  3.141593  6.283185  9.424778 12.566371 [5] 15.707963
>
>
> May be that is what you need.

I fail to see what that has to do with the question (there are no `binary 
vectors' in the answer - raw vectors are no more or less binary than 
numeric ones), but in any case it can be done in base R 2.2.0 more 
efficiently by

> options(width=50)
> (y <- writeBin(x, raw()))
  [1] 18 2d 44 54 fb 21 09 40 18 2d 44 54 fb 21 19
[16] 40 d2 21 33 7f 7c d9 22 40 18 2d 44 54 fb 21
[31] 29 40 5e 38 55 29 7a 6a 2f 40


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Haiyong Xu
> Sent: Saturday, October 01, 2005 4:22 PM
> To: Help R
> Subject: [R] dec2bin?
>
> Hello,
>
> I just want to ask if there is any function that can convert decimal
number
> to binary vector.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jerk_alert at hotmail.com  Mon Oct  3 20:05:25 2005
From: jerk_alert at hotmail.com (Ken Termiso)
Date: Mon, 03 Oct 2005 18:05:25 +0000
Subject: [R] Library error when using R CMD check
Message-ID: <BAY101-F7A8E9FF327FEA0E7141E1E8800@phx.gbl>

Hi,

I've got a library I'm trying to build, and am having an error on R CMD 
check...

The source is fine, and the script runs OK, but during the script test 
execution it downloads a library from an online repository, which goes fine 
and it says that installation was successful...

However, after it installs the library OK, it then cannot find it (despite 
it being installed properly in the R installation even before I ran R CMD 
check)...it is looking in the working directory's .Rcheck folder, and halts 
because it cannot find it there...

I'm not sure at all what I'm sup'd to do...?? Is there a way for me to tell 
R CMD check to only look for installed libraries in another place?

I'm sorry if this is vague, but I'm pretty thoroughly confused here...

This is Mac OS X 10.3...but I am trying to build a source library that will 
be cross-platform (there is only R code / no C code or anything 
fancy...sourcing my scripts from this library works on mac and win2k pro)...

Thanks in advance,
Ken



From ripley at stats.ox.ac.uk  Mon Oct  3 20:11:12 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 Oct 2005 19:11:12 +0100 (BST)
Subject: [R] modeling language for optimization problems
In-Reply-To: <1db726800510031009q3350e2d6h88e41cdbfc6c60f6@mail.gmail.com>
References: <355C35514FEAC9458F75947F5270974D076D06@usctmx1103.merck.com>
	<Pine.LNX.4.61.0510031529370.4535@gannet.stats>
	<1db726800510031009q3350e2d6h88e41cdbfc6c60f6@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0510031905030.18893@gannet.stats>

On Mon, 3 Oct 2005, roger bos wrote:

> As others have alluded, R does not have any one package that is as
> versatile and powerful as NuOpt, but R does have many different optimization
> packages, so you can do LP, QP, Integer programming, and many more types of
> optimization, all without having to learn a new language. But being free,
> they are admittedly not as powerful as NuOpt. The main thing I know you can
> do in NuOpt that you cannot do in R (to my knowledge) is mixed integer
> quadratic programming, which would be nice, but there are many work arounds.

Please tell us which R packages provide

>> - primal-dual interior point method based on line search for general
>> Convex Programming (CP) models including convex Quadratic Programming
>> (CQP) models.
>>
>> - primal-dual interior point method based on trust region method for
>> general Non-Linear Programming (NLP) models.
>>
>> - primal-dual interior point method based on quasi-Newton method for
>> general Non-Linear Programming (NLP) models.
>>
>> - active set method for convex Quadratic Programming (CQP) models and
>> mixed integer Quadratic Programming(MIQP) models.'

and how you found them?  I get

> help.search("interior point")
...
rq.fit.fn(quantreg)     Quantile Regression Fitting via Interior Point
                         Methods
rq.fit.fnb(quantreg)    Quantile Regression Fitting via Interior Point
                         Methods
rq.fit.fnc(quantreg)    Quantile Regression Fitting via Interior Point
                         Methods
> help.search("convex programming")
No help files found with alias or concept or title matching 'convex
programming' using fuzzy matching.
...


> Thanks,
> Roger
>
> On 10/3/05, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>>
>> On Mon, 3 Oct 2005, Huntsinger, Reid wrote:
>>
>>> Have you looked at the R interface to GLPK (the GNU Linear Programming
>> Kit)?
>>> http://cran.r-project.org/src/contrib/Descriptions/glpk.html
>>
>> NUOPT is not just about LP: the subject was `language for optimization'.
>> Its manual says
>>
>> `NUOPT is a collection of powerful optimization methods, including:
>>
>> - primal-dual interior point method with higher order correction for
>> Linear Programming (LP) models.
>>
>> - simplex method for Linear Programming (LP) and mixed integer programming
>> (MILP) models.
>>
>> - primal-dual interior point method based on line search for general
>> Convex Programming (CP) models including convex Quadratic Programming
>> (CQP) models.
>>
>> - primal-dual interior point method based on trust region method for
>> general Non-Linear Programming (NLP) models.
>>
>> - primal-dual interior point method based on quasi-Newton method for
>> general Non-Linear Programming (NLP) models.
>>
>> - active set method for convex Quadratic Programming (CQP) models and
>> mixed integer Quadratic Programming(MIQP) models.'
>>
>> In any case, I don't see GLPK as a `language' and other LP solvers are
>> available in R.
>>
>>
>>> From: r-help-bounces at stat.math.ethz.ch
>>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Prof Brian Ripley
>>> Sent: Sunday, October 02, 2005 10:38 AM
>>> To: Paolo Cavatore
>>> Cc: r-help at stat.math.ethz.ch
>>> Subject: Re: [R] modeling language for optimization problems
>>>
>>>
>>> On Sun, 2 Oct 2005, Paolo Cavatore wrote:
>>>
>>>> Does anyone know whether R has its own modeling language for
>> optimization
>>>> problems (like SIMPLE in NuOPT for S-plus)?
>>>
>>> No. Note that SIMPLE is the language of NUOPT, not of S-PLUS. There is
>>> an (extra-cost) interface module S+NUOPT, but it is an interface to
>>> NUOPT's engine.
>>>
>>> As far as I am aware R itself covers almost none of the ground of
>> S+NUOPT,
>>> and available packages cover only a small part of it.
>>
>> --
>> Brian D. Ripley, ripley at stats.ox.ac.uk
>> Professor of Applied Statistics, http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford, Tel: +44 1865 272861 (self)
>> 1 South Parks Road, +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK Fax: +44 1865 272595
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From h.wickham at gmail.com  Mon Oct  3 20:20:24 2005
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 3 Oct 2005 13:20:24 -0500
Subject: [R] Grid: constructing a gTree with grobs that use named viewports
	from a vpTree
Message-ID: <f8e6ff050510031120m55211c1dk513af25701ac7d6a@mail.gmail.com>

I'm trying to create a layout with named viewports that I can use for
other functions.  I create the viewport tree that I want, and a list
of grobs with the viewports describing where they should go.

library(grid)
vp <- vpTree(
	viewport(layout=grid.layout(2,2), name="layout"),
	children=vpList(
		viewport(layout.pos.col = 1, layout.pos.row=1, name="tl"),
		viewport(layout.pos.col = 2, layout.pos.row=2, name="br")
	)
)


grobs <- gList(
	rectGrob(vp="tl"),
	textGrob("Top left", vp="tl"),
	textGrob("Bottom right", vp="br")
)


I can draw the grobs using the following code:

grid.newpage()
pushViewport(vp)
upViewport(1)
grid.draw(grobs)

But I want a grob that represents those grobs drawn in the appropriate
viewports.  I had hoped I could do something like:

grid.newpage()
grid.draw(gTree(vp=vp, children = grobs))

But I get:

 Error in downViewport.vpPath(vp, strict = TRUE, recording = FALSE) :
	Viewport 'tl' was not found

presumably because no equivalent of the upViewport(1) command is used.

What should I be doing here?

Thanks,

Hadley



From pmuhl830 at gmail.com  Mon Oct  3 20:33:20 2005
From: pmuhl830 at gmail.com (Peter Muhlberger)
Date: Mon, 03 Oct 2005 14:33:20 -0400
Subject: [R] ML optimization question--unidimensional unfolding scaling
Message-ID: <BF66F1B0.11DC0%pmuhl830@gmail.com>

I'm trying to put together an R routine to conduct unidimensional unfolding
scaling analysis using maximum likelihood.  My problem is that ML
optimization will get stuck at latent scale points that are far from
optimal.  The point optimizes on one of the observed variables but not
others and for ML to move away from this 'local optimum', it has to move in
a direction in which the likelihood is decreasing, which it won't.

It's not hard to know where to look for a more optimal value--it'll be just
on the other side of the mean of a curve.  So, I can find better values, but
these values need to be fed back into ML for continued optimization.
Problem is, optim or nlm don't allow me to feed them new values for
parameters and in any event ML will likely choke w/ parameters jumping
around.  

One solution I've thought of is to restart optim or nlm w/ the new values
whenever a point jumps.  Is there any good way to get optim or nlm to
prematurely terminate, return control to the calling program, while
retaining a copy of the estimates?

Perhaps ML isn't the best approach for this kind of problem.  Suggestions
welcome!

Cheers,
Peter



From JAROSLAW.W.TUSZYNSKI at saic.com  Mon Oct  3 20:41:21 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Mon, 3 Oct 2005 14:41:21 -0400 
Subject: [R] Library error when using R CMD check
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD503DF8B0E@us-arlington-0668.mail.saic.com>

Maybe you forgot to list the name of dependent package in 'Depends' section
of 'DESCRIPTION' file. I think that would have effect you describe. See 

http://cran.r-project.org/doc/manuals/R-exts.html#The-DESCRIPTION-file for
details.

Jarek

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] 
Sent: Monday, October 03, 2005 2:05 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Library error when using R CMD check

Hi,

I've got a library I'm trying to build, and am having an error on R CMD
check...

The source is fine, and the script runs OK, but during the script test
execution it downloads a library from an online repository, which goes fine
and it says that installation was successful...

However, after it installs the library OK, it then cannot find it (despite
it being installed properly in the R installation even before I ran R CMD
check)...it is looking in the working directory's .Rcheck folder, and halts
because it cannot find it there...

I'm not sure at all what I'm sup'd to do...?? Is there a way for me to tell
R CMD check to only look for installed libraries in another place?

I'm sorry if this is vague, but I'm pretty thoroughly confused here...

This is Mac OS X 10.3...but I am trying to build a source library that will
be cross-platform (there is only R code / no C code or anything
fancy...sourcing my scripts from this library works on mac and win2k pro)...

Thanks in advance,
Ken

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From h.wickham at gmail.com  Mon Oct  3 20:50:47 2005
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 3 Oct 2005 13:50:47 -0500
Subject: [R] Grid: constructing a gTree with grobs that use named
	viewports from a vpTree
In-Reply-To: <f8e6ff050510031120m55211c1dk513af25701ac7d6a@mail.gmail.com>
References: <f8e6ff050510031120m55211c1dk513af25701ac7d6a@mail.gmail.com>
Message-ID: <f8e6ff050510031150x4c7f82b6pe7249dc18ed55283@mail.gmail.com>

> But I get:
>
>  Error in downViewport.vpPath(vp, strict = TRUE, recording = FALSE) :
>         Viewport 'tl' was not found
>
> presumably because no equivalent of the upViewport(1) command is used.
>
> What should I be doing here?

I've solved my own problem - I need to use childrenvp instead and
construct a fuller viewport path:

grobs <- gList(
	rectGrob(vp=vpPath("layout","tl")),
	textGrob("Top left", vp=vpPath("layout","tl")),
	textGrob("Bottom right", vp=vpPath("layout","br"))
)

grid.draw(gTree(childrenvp=vp, children = grobs))

Hadley



From greg.snow at ihc.com  Mon Oct  3 19:58:26 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Mon, 03 Oct 2005 11:58:26 -0600
Subject: [R] R and Data Storage
Message-ID: <s3412fa6.030@lp-msg1.co.ihc.com>

You might want to look at sqlite (http://www.sqlite.org/).  There is
already
an R package for accessing these databases and the website shows
some GUI interfaces that may be easy enough for tha casual user.
Best of all it is small, quick, free, and open source.

Greg Snow, Ph.D.
Statistical Data Center, LDS Hospital
Intermountain Health Care
greg.snow at ihc.com
(801) 408-8111

>>> <rab45+ at pitt.edu> 09/30/05 10:26PM >>>
Where I work a lot of people end up using Excel spreadsheets for
storing
data. This has limitations and maybe some less than obvious problems.
I'd
like to recommend a uniform way for storing and archiving data
collected
in the department. Most of the data could be stored in simple csv type
files but it would be nice to have something that stores more
information
about the variables and units. netcdf seems like overkill (and not
easy
for casual users). Same for postgres and mysql databases. Could
someone
recommend some system for storing relatively small data sets (50-100
variables, <1000 records) that would be reliable, safe, and easy for
people to view and edit their data that works nicely with R and is
open
source? Am I asking for the moon?

Rick  B.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From roebuck at wotan.mdacc.tmc.edu  Mon Oct  3 21:24:57 2005
From: roebuck at wotan.mdacc.tmc.edu (Paul Roebuck)
Date: Mon, 3 Oct 2005 14:24:57 -0500 (CDT)
Subject: [R] Library error when using R CMD check
In-Reply-To: <BAY101-F7A8E9FF327FEA0E7141E1E8800@phx.gbl>
References: <BAY101-F7A8E9FF327FEA0E7141E1E8800@phx.gbl>
Message-ID: <Pine.OSF.4.58.0510031413200.5014@wotan.mdacc.tmc.edu>

On Mon, 3 Oct 2005, Ken Termiso wrote:

> I've got a library I'm trying to build, and am having an error on R CMD
> check...
>
> The source is fine, and the script runs OK, but during the script test
> execution it downloads a library from an online repository, which goes fine
> and it says that installation was successful...
>
> However, after it installs the library OK, it then cannot find it (despite
> it being installed properly in the R installation even before I ran R CMD
> check)...it is looking in the working directory's .Rcheck folder, and halts
> because it cannot find it there...
>
> I'm not sure at all what I'm sup'd to do...?? Is there a way for me to tell
> R CMD check to only look for installed libraries in another place?

This help any?

$ R_LIBS=<colon separated pathname list>
$ env R_LIBS=$R_LIBS R CMD check <pkgname>

Note that the first line would normally corespond to the
entry of the same name in your <~/.Renviron> file. In the case
of Mac OS X, it should normally be:

    R_LIBS=~/Library/R/library

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From rolf at math.unb.ca  Mon Oct  3 21:31:28 2005
From: rolf at math.unb.ca (Rolf Turner)
Date: Mon, 3 Oct 2005 16:31:28 -0300 (ADT)
Subject: [R] Getting eps into Word documents.
Message-ID: <200510031931.j93JVSQ9028469@erdos.math.unb.ca>

A student in one of my courses has asked me about getting R graphics
output (under Linux) into a Word document.  I.e. she wants to do her
R thing under Linux, but then do her word processing using Word.

Scanning around the r-help archives I encountered an inquiry about
this topic --- eps into Word documents --- from Paul Johnson but
found no replies to it.  I tried contacting him but the email address
in the archives appeared not to be valid.  Does anyone know a
satisfactory solution to the problem of including a graphic which
exists in the form of a *.eps (encapsulated postscript) file into a
Word document.  If so, would you be willing to share it with me and
my student?

If so, please be gentle in your explanation.  I am not myself (repeat
***NOT***) a user of Word!

Thanks.

			cheers,

				Rolf Turner
				rolf at math.unb.ca



From mschwartz at mn.rr.com  Mon Oct  3 21:46:36 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Mon, 03 Oct 2005 14:46:36 -0500
Subject: [R] Getting eps into Word documents.
In-Reply-To: <200510031931.j93JVSQ9028469@erdos.math.unb.ca>
References: <200510031931.j93JVSQ9028469@erdos.math.unb.ca>
Message-ID: <1128368796.5957.25.camel@localhost.localdomain>

On Mon, 2005-10-03 at 16:31 -0300, Rolf Turner wrote:
> A student in one of my courses has asked me about getting R graphics
> output (under Linux) into a Word document.  I.e. she wants to do her
> R thing under Linux, but then do her word processing using Word.
> 
> Scanning around the r-help archives I encountered an inquiry about
> this topic --- eps into Word documents --- from Paul Johnson but
> found no replies to it.  I tried contacting him but the email address
> in the archives appeared not to be valid.  Does anyone know a
> satisfactory solution to the problem of including a graphic which
> exists in the form of a *.eps (encapsulated postscript) file into a
> Word document.  If so, would you be willing to share it with me and
> my student?
> 
> If so, please be gentle in your explanation.  I am not myself (repeat
> ***NOT***) a user of Word!

Hehe...  :-)

Rolf, just use the guidance provided in ?postscript. In the details
section it indicates:

     The postscript produced by R is EPS (_Encapsulated PostScript_)
     compatible, and can be included into other documents, e.g., into
     LaTeX, using '\includegraphics{<filename>}'.  For use in this way
     you will probably want to set 'horizontal = FALSE, onefile =
     FALSE, paper = "special"'.

So use something like the following:


postscript("RPlot.eps", height = 4, width = 4, 
           horizontal = FALSE, onefile = FALSE,
           paper = "special")

plot(1:5)

dev.off()


You can then import the .eps file into Word or most other such
applications that can import encapsulated postscript files.

The recent versions of Word will also automatically generate a bitmapped
preview of the plot upon import.  BTW, OO.org 2.0, which is in late beta
testing now, also generates EPS preview images upon import.

The key to doing this successfully is using the arguments to
postscript() as defined above. I have never had a problem with this.

More information is available from MS here:

http://support.microsoft.com/?kbid=290362

HTH,

Marc Schwartz



From uofiowa at gmail.com  Mon Oct  3 21:52:38 2005
From: uofiowa at gmail.com (Omar Lakkis)
Date: Mon, 3 Oct 2005 15:52:38 -0400
Subject: [R] log4j
Message-ID: <3f87cc6d0510031252w6151bafaiefdef29297a1963f@mail.gmail.com>

Is there a log4j, or similar, package for R?



From lforzani at stat.umn.edu  Mon Oct  3 22:28:06 2005
From: lforzani at stat.umn.edu (lforzani)
Date: Mon, 03 Oct 2005 15:28:06 CDT
Subject: [R] spline.des
Message-ID: <200510032028.j93KS6Af012861@saturn.software.umn.edu>

Hello, I am using library fda and I can not run a lot of functions because
I receive the error:

Error in bsplineS(evalarg, breaks, norder, nderiv) : 
        couldn't find function "spline.des"


do you know how I can fix that? Thnaks. Liliana



From ligges at statistik.uni-dortmund.de  Mon Oct  3 22:59:28 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 03 Oct 2005 22:59:28 +0200
Subject: [R] spline.des
In-Reply-To: <200510032028.j93KS6Af012861@saturn.software.umn.edu>
References: <200510032028.j93KS6Af012861@saturn.software.umn.edu>
Message-ID: <43419BB0.3060404@statistik.uni-dortmund.de>

lforzani wrote:
> Hello, I am using library fda and I can not run a lot of functions because
> I receive the error:
> 
> Error in bsplineS(evalarg, breaks, norder, nderiv) : 
>         couldn't find function "spline.des"
> 
> 
> do you know how I can fix that? Thnaks. Liliana

Version of R (most recent?)?
Version of fda (most recent?)?
Example code to reproduce this error message?

Well, looking at the code of a recent version of fda suggests this is a 
bug. Please report bugs to the package maintainer rather than to an R 
mailing list.


> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Yes, please do so.

Uwe Ligges



From tom at maladmin.com  Mon Oct  3 19:18:58 2005
From: tom at maladmin.com (tom wright)
Date: Mon, 03 Oct 2005 13:18:58 -0400
Subject: [R] Getting eps into Word documents.
In-Reply-To: <200510031931.j93JVSQ9028469@erdos.math.unb.ca>
References: <200510031931.j93JVSQ9028469@erdos.math.unb.ca>
Message-ID: <1128359938.4459.8.camel@localhost.localdomain>

On Mon, 2005-03-10 at 16:31 -0300, Rolf Turner wrote:
> A student in one of my courses has asked me about getting R graphics
> output (under Linux) into a Word document.  I.e. she wants to do her
> R thing under Linux, but then do her word processing using Word.
> 
> Scanning around the r-help archives I encountered an inquiry about
> this topic --- eps into Word documents --- from Paul Johnson but
> found no replies to it.  I tried contacting him but the email address
> in the archives appeared not to be valid.  Does anyone know a
> satisfactory solution to the problem of including a graphic which
> exists in the form of a *.eps (encapsulated postscript) file into a
> Word document.  If so, would you be willing to share it with me and
> my student?
> 
> If so, please be gentle in your explanation.  I am not myself (repeat
> ***NOT***) a user of Word!
> 
> Thanks.
> 
> 			cheers,
> 
> 				Rolf Turner
> 				rolf at math.unb.ca

R can also create more generic image formats such as png, i just use
these when I'm forced to insert graphics for presentations
?png



From Ted.Harding at nessie.mcc.ac.uk  Mon Oct  3 23:00:23 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 03 Oct 2005 22:00:23 +0100 (BST)
Subject: [R] Getting eps into Word documents.
In-Reply-To: <1128368796.5957.25.camel@localhost.localdomain>
Message-ID: <XFMail.051003220023.Ted.Harding@nessie.mcc.ac.uk>

Rolf (& Marc)

On 03-Oct-05 Marc Schwartz (via MN) wrote:
> On Mon, 2005-10-03 at 16:31 -0300, Rolf Turner wrote:
>> A student in one of my courses has asked me about getting R graphics
>> output (under Linux) into a Word document.  I.e. she wants to do her
>> R thing under Linux, but then do her word processing using Word.
>> 
>> Scanning around the r-help archives I encountered an inquiry about
>> this topic --- eps into Word documents --- from Paul Johnson but
>> found no replies to it.  I tried contacting him but the email address
>> in the archives appeared not to be valid.  Does anyone know a
>> satisfactory solution to the problem of including a graphic which
>> exists in the form of a *.eps (encapsulated postscript) file into a
>> Word document.  If so, would you be willing to share it with me and
>> my student?
>> 
>> If so, please be gentle in your explanation.  I am not myself (repeat
>> ***NOT***) a user of Word!
> 
> Hehe...  :-)
> 
> Rolf, just use the guidance provided in ?postscript. In the details
> section it indicates:
> 
>      The postscript produced by R is EPS (_Encapsulated PostScript_)
>      compatible, and can be included into other documents, e.g., into
>      LaTeX, using '\includegraphics{<filename>}'.  For use in this way
>      you will probably want to set 'horizontal = FALSE, onefile =
>      FALSE, paper = "special"'.
> 
> So use something like the following:
> 
> 
> postscript("RPlot.eps", height = 4, width = 4, 
>            horizontal = FALSE, onefile = FALSE,
>            paper = "special")
> 
> plot(1:5)
> 
> dev.off()
> 
> 
> You can then import the .eps file into Word or most other such
> applications that can import encapsulated postscript files.
> 
> The recent versions of Word will also automatically generate a
> bitmapped preview of the plot upon import.  BTW, OO.org 2.0,
> which is in late beta testing now, also generates EPS preview
> images upon import.
> 
> The key to doing this successfully is using the arguments to
> postscript() as defined above. I have never had a problem with this.
> 
> More information is available from MS here:
> 
> http://support.microsoft.com/?kbid=290362
> 
> HTH,
> 
> Marc Schwartz

This suggestion could be problematic in that

a) According to the MS web site above, it applies to recent Word
   (Office 2002/2003) or possibly earlier "depending on installed
   graphics filters".

b) It won't work anyway if printed to a non-PostScript printer.

If either of these applies to Rolf's student, she could have problems.

[Just to add my own "disclaimer": the only version of Word I'm in
any position to ever touch, and then only if driven to, belongs
to Office 98; and I'm sure that this doesn't know a thing about
PostScript!]

Another option to consider, since she's doing her R work on Linux,
is that recent versions of the ImageMagick program 'convert' have
the capability to convert EPS into WMF (Windows Metafile; use
file extension ".wmf" for 'convert') or EMF (Enhanced Metafile);
use file extension ".emf". The gubbins is built in to a file
"wmf.so" in the lib/ImageMagick tree.

Likewise, the program 'pstoedit' can do it (to ".wmf" or ".emf"),
using library /usr/local/lib/pstoedit/libp2edrvwmf.so (on my machine).

Most Linux distributions these days come with ImageMagick and
pstoedit. If not already installed in the machine she's using it
should be straightforward to get this dome.

Hoping this helps,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 03-Oct-05                                       Time: 22:00:11
------------------------------ XFMail ------------------------------



From Mike.Prager at noaa.gov  Mon Oct  3 23:27:20 2005
From: Mike.Prager at noaa.gov (Mike Prager)
Date: Mon, 03 Oct 2005 17:27:20 -0400
Subject: [R] Getting eps into Word documents.
In-Reply-To: <200510031931.j93JVSQ9028469@erdos.math.unb.ca>
References: <200510031931.j93JVSQ9028469@erdos.math.unb.ca>
Message-ID: <4341A238.3020009@noaa.gov>

on 10/3/2005 3:31 PM Rolf Turner said the following:

>[...] Does anyone know a
>satisfactory solution to the problem of including a graphic which
>exists in the form of a *.eps (encapsulated postscript) file into a
>Word document.  If so, would you be willing to share it with me and
>my student?
>
>  
>

Recent versions of Word import EPS quite well.  I just tried it with 
Word 2003 (also known as Word 11), and the figure was imported 
properly.  Word added a preview all by itself.

To do this, I opened an Explorer (directory) window on the directory 
with the files, then dragged the EPS file to Word.  I am certain it can 
also be done through the menu system.

I then converted an EPS file's line endings to *ix format and repeated 
the above.  It still worked fine.

-- 

Michael Prager, Ph.D.
Population Dynamics Team, NMFS SE Fisheries Science Center
NOAA Center for Coastal Fisheries and Habitat Research
Beaufort, North Carolina  28516
http://shrimp.ccfhrb.noaa.gov/~mprager/
Opinions expressed are personal, not official.  No
government endorsement of any product is made or implied.



From ericpante at earthlink.net  Mon Oct  3 23:31:01 2005
From: ericpante at earthlink.net (Eric Pante)
Date: Mon, 3 Oct 2005 17:31:01 -0400
Subject: [R] sampling vectors
Message-ID: <fca0140a7c6e0ddafffbc1519f87528d@earthlink.net>


Hello Listers,

I am trying to sample a vector to create a new one of sample length, 
witha  sum equal to the sum of the initial vector:

initial = 10, 30, 10 (sum=50)
sample example = 5, 35, 10 (sum=50) or 25, 15, 10  (sum=50), etc ...

My problem is to control the sum, so it stays constant.
Any suggestions would be very helpful !

Thank you in advance,
Eric



From Robbie.Turner at mightyriver.co.nz  Mon Oct  3 23:31:39 2005
From: Robbie.Turner at mightyriver.co.nz (Robbie Turner)
Date: Tue, 4 Oct 2005 10:31:39 +1300
Subject: [R] Error in xy.coords(x, y, xlabel, ylabel,
	log) : x and y lengths differ
Message-ID: <BE25BFDC3C606A4986BEA378B0519A5A0182D264@akr-mail-01.mrp.net.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051004/8e1b08da/attachment.pl

From mschwartz at mn.rr.com  Mon Oct  3 23:44:05 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Mon, 03 Oct 2005 16:44:05 -0500
Subject: [R] Getting eps into Word documents.
In-Reply-To: <XFMail.051003220023.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.051003220023.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <1128375845.5957.64.camel@localhost.localdomain>

On Mon, 2005-10-03 at 22:00 +0100, Ted Harding wrote:
> Rolf (& Marc)
> 
> On 03-Oct-05 Marc Schwartz (via MN) wrote:
> > On Mon, 2005-10-03 at 16:31 -0300, Rolf Turner wrote:
> >> A student in one of my courses has asked me about getting R graphics
> >> output (under Linux) into a Word document.  I.e. she wants to do her
> >> R thing under Linux, but then do her word processing using Word.
> >> 
> >> Scanning around the r-help archives I encountered an inquiry about
> >> this topic --- eps into Word documents --- from Paul Johnson but
> >> found no replies to it.  I tried contacting him but the email address
> >> in the archives appeared not to be valid.  Does anyone know a
> >> satisfactory solution to the problem of including a graphic which
> >> exists in the form of a *.eps (encapsulated postscript) file into a
> >> Word document.  If so, would you be willing to share it with me and
> >> my student?
> >> 
> >> If so, please be gentle in your explanation.  I am not myself (repeat
> >> ***NOT***) a user of Word!
> > 
> > Hehe...  :-)
> > 
> > Rolf, just use the guidance provided in ?postscript. In the details
> > section it indicates:
> > 
> >      The postscript produced by R is EPS (_Encapsulated PostScript_)
> >      compatible, and can be included into other documents, e.g., into
> >      LaTeX, using '\includegraphics{<filename>}'.  For use in this way
> >      you will probably want to set 'horizontal = FALSE, onefile =
> >      FALSE, paper = "special"'.
> > 
> > So use something like the following:
> > 
> > 
> > postscript("RPlot.eps", height = 4, width = 4, 
> >            horizontal = FALSE, onefile = FALSE,
> >            paper = "special")
> > 
> > plot(1:5)
> > 
> > dev.off()
> > 
> > 
> > You can then import the .eps file into Word or most other such
> > applications that can import encapsulated postscript files.
> > 
> > The recent versions of Word will also automatically generate a
> > bitmapped preview of the plot upon import.  BTW, OO.org 2.0,
> > which is in late beta testing now, also generates EPS preview
> > images upon import.
> > 
> > The key to doing this successfully is using the arguments to
> > postscript() as defined above. I have never had a problem with this.
> > 
> > More information is available from MS here:
> > 
> > http://support.microsoft.com/?kbid=290362
> > 
> > HTH,
> > 
> > Marc Schwartz
> 
> This suggestion could be problematic in that

Ted,

> a) According to the MS web site above, it applies to recent Word
>    (Office 2002/2003) or possibly earlier "depending on installed
>    graphics filters".

The Word EPS filter has been around for some time. I recall using it
years ago. Note that it is listed on that site in both categories of
filters for some reason.  In the older versions of Word, there was no
preview image generated, hence you ended up with a box/frame place
holder of sorts, unless you added a preview image before importing.

That being said, one does need to install the import filters from the
Office CD, which may not be part of the default settings on all prior
versions. It may require going back into the Office set up program to
install them.

> b) It won't work anyway if printed to a non-PostScript printer.

True, which is the case irrespective of Word/Windows. If you don't have
a PS printer locally or accessible via network, you can always install a
PS printer driver and print to a file, which can then be printed by a
third party if required.  

If one has ps2pdf/Ghostscript available, you can also convert the PS
file to PDF and then print it via Acrobat or other PDF viewers.  

> If either of these applies to Rolf's student, she could have problems.
> 
> [Just to add my own "disclaimer": the only version of Word I'm in
> any position to ever touch, and then only if driven to, belongs
> to Office 98; and I'm sure that this doesn't know a thing about
> PostScript!]
> 
> Another option to consider, since she's doing her R work on Linux,
> is that recent versions of the ImageMagick program 'convert' have
> the capability to convert EPS into WMF (Windows Metafile; use
> file extension ".wmf" for 'convert') or EMF (Enhanced Metafile);
> use file extension ".emf". The gubbins is built in to a file
> "wmf.so" in the lib/ImageMagick tree.
> 
> Likewise, the program 'pstoedit' can do it (to ".wmf" or ".emf"),
> using library /usr/local/lib/pstoedit/libp2edrvwmf.so (on my machine).
> 
> Most Linux distributions these days come with ImageMagick and
> pstoedit. If not already installed in the machine she's using it
> should be straightforward to get this dome.
> 
> Hoping this helps,
> Ted.

Ted, the critical issue with doing the WMF/EMF conversion on Linux is
that the libEMF stuff generates lousy quality (and visually bitmapped)
output. I have tried it in the past and gave up, staying with EPS/PDF
formats for vector graphics. If one wants to convert the EPS file to
WMF/EMF, it is best done on Windows using native Windows drivers, rather
than on Linux.

When SVG graphics go mainstream and cross-platform, that should help
significantly with this whole issue.

HTH,

Marc



From a.manigs at gmail.com  Tue Oct  4 00:06:03 2005
From: a.manigs at gmail.com (A Mani)
Date: Tue, 4 Oct 2005 03:36:03 +0530
Subject: [R] Clustering Large Data Sets
Message-ID: <a6821d990510031506s47d1e9f5x3ab75cd5428355ff@mail.gmail.com>

Hello,
        Suppose the problem is to cluster each document in a set of
'n' documents (.csv) separately by some clustering method. If 'n' is
very large, then is there a method of increasing speed and efficiency
by treating the set as a document vector or as a set of document
vectors ?

Thanks

--
A. Mani
Member, Cal. Math. Soc



From maj at stats.waikato.ac.nz  Tue Oct  4 01:05:18 2005
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Tue, 04 Oct 2005 12:05:18 +1300
Subject: [R] R for teaching multivariate statistics
In-Reply-To: <mailman.9.1128247201.5680.r-help@stat.math.ethz.ch>
References: <mailman.9.1128247201.5680.r-help@stat.math.ethz.ch>
Message-ID: <4341B92E.5080508@stats.waikato.ac.nz>

Greetings all -

Next year I will be teaching a third year course in applied statistics 
about 1/3 of which is multivariate statistics. I would be interested in 
hearing experiences from those who have taught multivariate statistics 
using R. Especially I am interested in the textbook that you used or 
recommended.

If you reply directly to me I will summarize to reduce list traffic.

Regards,  Murray Jorgensen

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441    Mobile 021 1395 862



From Andrew.Haywood at poyry.com.au  Tue Oct  4 02:36:31 2005
From: Andrew.Haywood at poyry.com.au (Andrew.Haywood@poyry.com.au)
Date: Tue, 4 Oct 2005 10:36:31 +1000
Subject: [R] newbie questions - looping through hierarchial datafille
Message-ID: <OF918EDC88.BF1AA4B2-ONCA257090.0003341B-CA257090.00035B10@poyry.fi>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051004/2cdb014f/attachment.pl

From e.catchpole at adfa.edu.au  Tue Oct  4 04:29:32 2005
From: e.catchpole at adfa.edu.au (ecatchpole)
Date: Tue, 04 Oct 2005 12:29:32 +1000
Subject: [R] Error in xy.coords(x, y, xlabel, ylabel,
	log) : x and y lengths differ
In-Reply-To: <BE25BFDC3C606A4986BEA378B0519A5A0182D264@akr-mail-01.mrp.net.nz>
References: <BE25BFDC3C606A4986BEA378B0519A5A0182D264@akr-mail-01.mrp.net.nz>
Message-ID: <4341E90C.80000@adfa.edu.au>

Try

plot(data.df$temp, data.df$output)

Ted.

On 04/10/05 07:31,  Robbie Turner wrote,:
> I am currently trying to use R to construct a regression model to
> explain output based on temperature. I have combined my output and temp
> data into a notepad file. there is no problem with loading the data into
> R.
> 
>>data.df
>     output temp
> 1    850   17
> 2    849   17
> 3    905   17
> 4    925   17
> 5   1043   19
> 6   1104   20
> 7   1097   18
> 8    979   19
> 9    926   18
> 10  1133   18
> ~~
> ~~
> 240 1124   12
> 241 1344   12
> 242 1375   11
> 243 1359   12
> 
> but when I try to plot the data I keep getting this error:
> 
>>plot(temp,output)
> Error in xy.coords(x, y, xlabel, ylabel, log) : 
>         x and y lengths differ
> 
> any advice on how to over come this error would be greatly appreciated.
> 
> Cheers, Robbie.



From spluque at gmail.com  Tue Oct  4 05:52:32 2005
From: spluque at gmail.com (Sebastian Luque)
Date: Mon, 03 Oct 2005 22:52:32 -0500
Subject: [R] pdf plotting of splom
Message-ID: <873bnihrb3.fsf@gmail.com>

Hi,

The following code produces a plot on X11:


splom(~iris[1:4], groups = Species, data = iris,
      panel = panel.superpose,
      key = list(title = "Three Varieties of Iris",
        columns = 3,
        points = list(pch = super.sym$pch[1:3],
          col = super.sym$col[1:3]),
        text = list(c("Setosa", "Versicolor", "Virginica"))))

However, when I try the same code in a pdf device (whether using 'print'
or not), produces a pdf file with only the layout of all the panels.  The
panels are completely empty.


pdf("splom-test.pdf", family = "Times", bg = "white")
print(splom(~iris[1:4], groups = Species, data = iris,
      panel = panel.superpose,
      key = list(title = "Three Varieties of Iris",
        columns = 3,
        points = list(pch = super.sym$pch[1:3],
          col = super.sym$col[1:3]),
        text = list(c("Setosa", "Versicolor", "Virginica")))))
dev.off()

Curiously, some points appear for a split second when opening the file,
but they seem to be replaced by white space immediately, hence the totally
empty panels.

Any pointers as to what might be going on?  I wasn't able to find possible
explanations on the documentation or the archives.


Thanks in advance,

-- 
Sebastian P. Luque



From spluque at gmail.com  Tue Oct  4 06:06:57 2005
From: spluque at gmail.com (Sebastian Luque)
Date: Mon, 03 Oct 2005 23:06:57 -0500
Subject: [R] pdf plotting of splom
References: <873bnihrb3.fsf@gmail.com>
Message-ID: <87y85agc2m.fsf@gmail.com>

Sebastian Luque <spluque at gmail.com> wrote:

[...]

> pdf("splom-test.pdf", family = "Times", bg = "white")

[...]

Silly me, it occurred to me to check more carefully that bg argument,
which does something different in xyplot (namely, give a background to the
figure region, not the plot region as it seems to in this case).

So, removing that bg argument was the answer.  Sorry.


Cheers,

-- 
Sebastian P. Luque



From christoph.lehmann at gmx.ch  Tue Oct  4 07:22:12 2005
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Tue, 04 Oct 2005 07:22:12 +0200
Subject: [R] Getting eps into Word documents.
In-Reply-To: <1128359938.4459.8.camel@localhost.localdomain>
References: <200510031931.j93JVSQ9028469@erdos.math.unb.ca>
	<1128359938.4459.8.camel@localhost.localdomain>
Message-ID: <43421184.4000701@gmx.ch>

as far as I know (and I am not a specialist), there is no way of 
importing EPS in word, nor in openoffice, if you want to be able to 
"see" the graphics in the word processor and not only a placeholder. So 
either
a) use formats such as bmp, png,
or
b) under windows: convert eps to e.g. wmf using a tool, such as corel 
draw, or import the eps into powerpoint, then save it as wmf
c) try to import the eps in inkscape (I think this opensource tool is 
available also for windows), but I have never tried this

.. I have to admit, that under linux I have found no way so far, to 
import an eps graphics into a word document (neither ooo writer, nor 
msword, running with wine).

Christoph

tom wright wrote:
> On Mon, 2005-03-10 at 16:31 -0300, Rolf Turner wrote:
> 
>>A student in one of my courses has asked me about getting R graphics
>>output (under Linux) into a Word document.  I.e. she wants to do her
>>R thing under Linux, but then do her word processing using Word.
>>
>>Scanning around the r-help archives I encountered an inquiry about
>>this topic --- eps into Word documents --- from Paul Johnson but
>>found no replies to it.  I tried contacting him but the email address
>>in the archives appeared not to be valid.  Does anyone know a
>>satisfactory solution to the problem of including a graphic which
>>exists in the form of a *.eps (encapsulated postscript) file into a
>>Word document.  If so, would you be willing to share it with me and
>>my student?
>>
>>If so, please be gentle in your explanation.  I am not myself (repeat
>>***NOT***) a user of Word!
>>
>>Thanks.
>>
>>			cheers,
>>
>>				Rolf Turner
>>				rolf at math.unb.ca
> 
> 
> R can also create more generic image formats such as png, i just use
> these when I'm forced to insert graphics for presentations
> ?png
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From vincent at 7d4.com  Tue Oct  4 07:59:39 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Tue, 04 Oct 2005 07:59:39 +0200
Subject: [R] sampling vectors
In-Reply-To: <fca0140a7c6e0ddafffbc1519f87528d@earthlink.net>
References: <fca0140a7c6e0ddafffbc1519f87528d@earthlink.net>
Message-ID: <43421A4B.5080608@7d4.com>

Eric Pante a ??crit :

> Hello Listers,
> I am trying to sample a vector to create a new one of sample length, 
> witha  sum equal to the sum of the initial vector:
> initial = 10, 30, 10 (sum=50)
> sample example = 5, 35, 10 (sum=50) or 25, 15, 10  (sum=50), etc ...
> My problem is to control the sum, so it stays constant.

f0 = function()
{
s1 = 50;
for (i in 0:s1)
	{
	s2 = s1 - i;
	for (j in 0:s2)
		{
		s3 = s2 - j;
		print (c(i,j,s3));
		}
	}
}

(If I have well understood the question) ?
hih
Vincent



From senthil at www.cdfd.org.in  Tue Oct  4 13:33:15 2005
From: senthil at www.cdfd.org.in (M Senthil Kumar)
Date: Tue, 4 Oct 2005 04:33:15 -0700
Subject: [R] Getting eps into Word documents.
In-Reply-To: <43421184.4000701@gmx.ch>
Message-ID: <Pine.SGI.4.44.0510040418310.420370-100000@www.cdfd.org.in>

On Tue, 4 Oct 2005, Christoph Lehmann wrote:
<SNIP>
|.. I have to admit, that under linux I have found no way so far, to
|import an eps graphics into a word document (neither ooo writer, nor
|msword, running with wine).
</SNIP>

Hi,

There are lots of tools under linux, that can do the job of performing the
.eps conversion to several formats including ps, png, jpg, bmp, pdf, tiff,
targa, gif etc. For Eg, gimp, convert (from ImageMagick) and others.

Gimp is almost, but not quite entirely unlike Adobe Photoshop :) whereas
convert is command-line based, yet a powerful image interconversion tool.

The easiest way I feel, would be to convert .eps to one of the several
other compatible formats and then use them in M$-Word or OpenOffice.

HTH,

Senthil



From ndieckma at uoregon.edu  Tue Oct  4 08:29:15 2005
From: ndieckma at uoregon.edu (Nathan Dieckmann)
Date: Mon, 03 Oct 2005 23:29:15 -0700
Subject: [R] Problem reading in external data and assigning data.frames
	within R
Message-ID: <200510040629.j946TFke015135@smtp.uoregon.edu>


  Hey there,

    I apologize if this is an irritatingly simple question ... I'm a
new user.  I can't understand why R flips the sign of all data values
when reading in external text files (tab delimited or csv) with the
read.delim or read.csv functions.  The signs of data values also seem
to be flipped after assigning a new data.frame from within R (xnew <--
edit(data.frame()).  What am I doing wrong?

   Any help would be greatly appreciated.  Thanks in advance.

             -- Nate    

-----------------------------
Nathan Dieckmann
Department of Psychology
University of Oregon
Eugene, OR 97403
(541) 346-4963
ndieckma at darkwing.uoregon.edu



From dieter.menne at menne-biomed.de  Tue Oct  4 08:28:45 2005
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Tue, 4 Oct 2005 06:28:45 +0000 (UTC)
Subject: [R] Getting eps into Word documents.
References: <1128368796.5957.25.camel@localhost.localdomain>
	<XFMail.051003220023.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <loom.20051004T082249-16@post.gmane.org>

 <Ted.Harding <at> nessie.mcc.ac.uk> writes:

> Another option to consider, since she's doing her R work on Linux,
> is that recent versions of the ImageMagick program 'convert' have
> the capability to convert EPS into WMF (Windows Metafile; use
> file extension ".wmf" for 'convert') or EMF (Enhanced Metafile);
> use file extension ".emf". The gubbins is built in to a file
> "wmf.so" in the lib/ImageMagick tree.
> 
> Likewise, the program 'pstoedit' can do it (to ".wmf" or ".emf"),
> using library /usr/local/lib/pstoedit/libp2edrvwmf.so (on my machine).

I am using pstoedit for ps/emf for all my work, and it works nicely. There is 
one catch, though: If you plot any data that should be clipped (e.g. when 
setting xlim/ylim), pictures are nice in ps, but the clipped points turn up 
again in emf. This can make for nasty effect in panel plots where suddenly data 
turn up again in the wrong panel.

According to the author of pstoedit, this is a feature (i.e. bug) in emf that 
cannot easily be corrected. Only workaround: clip data sets manually.

Dieter



From e.catchpole at adfa.edu.au  Tue Oct  4 08:57:02 2005
From: e.catchpole at adfa.edu.au (ecatchpole)
Date: Tue, 04 Oct 2005 16:57:02 +1000
Subject: [R] sampling vectors
In-Reply-To: <fca0140a7c6e0ddafffbc1519f87528d@earthlink.net>
References: <fca0140a7c6e0ddafffbc1519f87528d@earthlink.net>
Message-ID: <434227BE.7060309@adfa.edu.au>

Eric,

If you want samples of size 3 from 0:50, with sum==50, this seems to do 
the job (with apologies to those who really know how to program in R):

tot <- 50
ii <- 0
aa <- list()
for(i in 0:tot){
    for(j in 0:(tot-i)){
       k <- tot-i-j
       ii <- ii+1
       aa[[ii]] <- list(i=i,j=j,k=k)
    }
}

aa[sample(ii, 4)] # for a sample of 4.

If you want a sample of size n from x[1],...x[N], such that the sample 
sum is T, then that is much trickier!

Ted.

On 04/10/05 07:31,  Eric Pante wrote,:
> Hello Listers,
> 
> I am trying to sample a vector to create a new one of sample length, 
> witha  sum equal to the sum of the initial vector:
> 
> initial = 10, 30, 10 (sum=50)
> sample example = 5, 35, 10 (sum=50) or 25, 15, 10  (sum=50), etc ...
> 
> My problem is to control the sum, so it stays constant.
> Any suggestions would be very helpful !
> 
> Thank you in advance,
> Eric
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Dr E.A. Catchpole
Visiting Fellow
Univ of New South Wales at ADFA, Canberra, Australia
and University of Kent, Canterbury, England
- www.ma.adfa.edu.au/~eac
- fax: +61 2 6268 8786		
- ph:  +61 2 6268 8895



From e.catchpole at adfa.edu.au  Tue Oct  4 09:00:34 2005
From: e.catchpole at adfa.edu.au (ecatchpole)
Date: Tue, 04 Oct 2005 17:00:34 +1000
Subject: [R] Problem reading in external data and assigning data.frames
 within R
In-Reply-To: <200510040629.j946TFke015135@smtp.uoregon.edu>
References: <200510040629.j946TFke015135@smtp.uoregon.edu>
Message-ID: <43422892.4040702@adfa.edu.au>

Try

xnew <- edit(data.frame())

Ted.


On 04/10/05 16:29,  Nathan Dieckmann wrote,:
>   Hey there,
> 
>     I apologize if this is an irritatingly simple question ... I'm a
> new user.  I can't understand why R flips the sign of all data values
> when reading in external text files (tab delimited or csv) with the
> read.delim or read.csv functions.  The signs of data values also seem
> to be flipped after assigning a new data.frame from within R (xnew <--
> edit(data.frame()).  What am I doing wrong?
> 
>    Any help would be greatly appreciated.  Thanks in advance.
> 
>              -- Nate    
> 
> -----------------------------
> Nathan Dieckmann
> Department of Psychology
> University of Oregon
> Eugene, OR 97403
> (541) 346-4963
> ndieckma at darkwing.uoregon.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Dr E.A. Catchpole
Visiting Fellow
Univ of New South Wales at ADFA, Canberra, Australia
and University of Kent, Canterbury, England
- www.ma.adfa.edu.au/~eac
- fax: +61 2 6268 8786		
- ph:  +61 2 6268 8895



From ripley at stats.ox.ac.uk  Tue Oct  4 09:09:27 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 4 Oct 2005 08:09:27 +0100 (BST)
Subject: [R] Getting eps into Word documents.
In-Reply-To: <1128375845.5957.64.camel@localhost.localdomain>
References: <XFMail.051003220023.Ted.Harding@nessie.mcc.ac.uk>
	<1128375845.5957.64.camel@localhost.localdomain>
Message-ID: <Pine.LNX.4.61.0510040804130.28395@gannet.stats>

On Mon, 3 Oct 2005, Marc Schwartz (via MN) wrote:

> On Mon, 2005-10-03 at 22:00 +0100, Ted Harding wrote:
>> Rolf (& Marc)
>>
>> On 03-Oct-05 Marc Schwartz (via MN) wrote:
>>> On Mon, 2005-10-03 at 16:31 -0300, Rolf Turner wrote:
>>>> A student in one of my courses has asked me about getting R graphics
>>>> output (under Linux) into a Word document.  I.e. she wants to do her
>>>> R thing under Linux, but then do her word processing using Word.
>>>>
>>>> Scanning around the r-help archives I encountered an inquiry about
>>>> this topic --- eps into Word documents --- from Paul Johnson but
>>>> found no replies to it.  I tried contacting him but the email address
>>>> in the archives appeared not to be valid.  Does anyone know a
>>>> satisfactory solution to the problem of including a graphic which
>>>> exists in the form of a *.eps (encapsulated postscript) file into a
>>>> Word document.  If so, would you be willing to share it with me and
>>>> my student?
>>>>
>>>> If so, please be gentle in your explanation.  I am not myself (repeat
>>>> ***NOT***) a user of Word!
>>>
>>> Hehe...  :-)
>>>
>>> Rolf, just use the guidance provided in ?postscript. In the details
>>> section it indicates:
>>>
>>>      The postscript produced by R is EPS (_Encapsulated PostScript_)
>>>      compatible, and can be included into other documents, e.g., into
>>>      LaTeX, using '\includegraphics{<filename>}'.  For use in this way
>>>      you will probably want to set 'horizontal = FALSE, onefile =
>>>      FALSE, paper = "special"'.
>>>
>>> So use something like the following:
>>>
>>>
>>> postscript("RPlot.eps", height = 4, width = 4,
>>>            horizontal = FALSE, onefile = FALSE,
>>>            paper = "special")
>>>
>>> plot(1:5)
>>>
>>> dev.off()
>>>
>>>
>>> You can then import the .eps file into Word or most other such
>>> applications that can import encapsulated postscript files.
>>>
>>> The recent versions of Word will also automatically generate a
>>> bitmapped preview of the plot upon import.  BTW, OO.org 2.0,
>>> which is in late beta testing now, also generates EPS preview
>>> images upon import.
>>>
>>> The key to doing this successfully is using the arguments to
>>> postscript() as defined above. I have never had a problem with this.
>>>
>>> More information is available from MS here:
>>>
>>> http://support.microsoft.com/?kbid=290362
>>>
>>> HTH,
>>>
>>> Marc Schwartz
>>
>> This suggestion could be problematic in that
>
> Ted,
>
>> a) According to the MS web site above, it applies to recent Word
>>    (Office 2002/2003) or possibly earlier "depending on installed
>>    graphics filters".
>
> The Word EPS filter has been around for some time. I recall using it
> years ago. Note that it is listed on that site in both categories of
> filters for some reason.  In the older versions of Word, there was no
> preview image generated, hence you ended up with a box/frame place
> holder of sorts, unless you added a preview image before importing.

We've been using this route for more than a decade (on both Windows and 
Classic MacOS).  You can use GSView, Photoshop, ... to add a preview if 
you desire.

> That being said, one does need to install the import filters from the
> Office CD, which may not be part of the default settings on all prior
> versions. It may require going back into the Office set up program to
> install them.
>
>> b) It won't work anyway if printed to a non-PostScript printer.
>
> True, which is the case irrespective of Word/Windows. If you don't have
> a PS printer locally or accessible via network, you can always install a
> PS printer driver and print to a file, which can then be printed by a
> third party if required.
>
> If one has ps2pdf/Ghostscript available, you can also convert the PS
> file to PDF and then print it via Acrobat or other PDF viewers.
>
>> If either of these applies to Rolf's student, she could have problems.
>>
>> [Just to add my own "disclaimer": the only version of Word I'm in
>> any position to ever touch, and then only if driven to, belongs
>> to Office 98; and I'm sure that this doesn't know a thing about
>> PostScript!]
>>
>> Another option to consider, since she's doing her R work on Linux,
>> is that recent versions of the ImageMagick program 'convert' have
>> the capability to convert EPS into WMF (Windows Metafile; use
>> file extension ".wmf" for 'convert') or EMF (Enhanced Metafile);
>> use file extension ".emf". The gubbins is built in to a file
>> "wmf.so" in the lib/ImageMagick tree.
>>
>> Likewise, the program 'pstoedit' can do it (to ".wmf" or ".emf"),
>> using library /usr/local/lib/pstoedit/libp2edrvwmf.so (on my machine).
>>
>> Most Linux distributions these days come with ImageMagick and
>> pstoedit. If not already installed in the machine she's using it
>> should be straightforward to get this dome.
>>
>> Hoping this helps,
>> Ted.
>
> Ted, the critical issue with doing the WMF/EMF conversion on Linux is
> that the libEMF stuff generates lousy quality (and visually bitmapped)
> output. I have tried it in the past and gave up, staying with EPS/PDF
> formats for vector graphics. If one wants to convert the EPS file to
> WMF/EMF, it is best done on Windows using native Windows drivers, rather
> than on Linux.

Even then, there are problems.  Word has several known problems with the 
way it handles imported wmf/emf files (including those produced by R's 
win.metafile).  These include text losing orientation, lines changing 
width and ugly behaviour of dashed lines.  One or another of these seem to 
hit most of our people's attempts to go this route.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From FredeA.Togersen at agrsci.dk  Tue Oct  4 09:51:41 2005
From: FredeA.Togersen at agrsci.dk (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Tue, 4 Oct 2005 09:51:41 +0200
Subject: [R] spline.des
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC037258FC@DJFPOST01.djf.agrsci.dk>


Hey

The function spline.des is in the splines package. You need to do 

library(splines)

before you have the full functionality of the fda package.


Best regards
Frede Aakmann T??gersen
 

 

> -----Oprindelig meddelelse-----
> Fra: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] P?? vegne af lforzani
> Sendt: 3. oktober 2005 22:28
> Til: Douglas Bates; Horacio Montenegro
> Cc: r-help at stat.math.ethz.ch
> Emne: [R] spline.des
> 
> Hello, I am using library fda and I can not run a lot of 
> functions because I receive the error:
> 
> Error in bsplineS(evalarg, breaks, norder, nderiv) : 
>         couldn't find function "spline.des"
> 
> 
> do you know how I can fix that? Thnaks. Liliana
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From ligges at statistik.uni-dortmund.de  Tue Oct  4 09:59:34 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 04 Oct 2005 09:59:34 +0200
Subject: [R] spline.des
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC037258FC@DJFPOST01.djf.agrsci.dk>
References: <C83C5E3DEEE97E498B74729A33F6EAEC037258FC@DJFPOST01.djf.agrsci.dk>
Message-ID: <43423666.8040606@statistik.uni-dortmund.de>

Frede Aakmann T??gersen wrote:
> Hey
> 
> The function spline.des is in the splines package. You need to do 
> 
> library(splines)
> 
> before you have the full functionality of the fda package.

So this is obviously a bug in fda: it should at least depend/suggest the 
"splines" package, should try to load it, and give an appropriate error 
message if splines is required but not available for the case in question.

Uwe Ligges


> 
> Best regards
> Frede Aakmann T??gersen
>  
> 
>  
> 
> 
>>-----Oprindelig meddelelse-----
>>Fra: r-help-bounces at stat.math.ethz.ch 
>>[mailto:r-help-bounces at stat.math.ethz.ch] P?? vegne af lforzani
>>Sendt: 3. oktober 2005 22:28
>>Til: Douglas Bates; Horacio Montenegro
>>Cc: r-help at stat.math.ethz.ch
>>Emne: [R] spline.des
>>
>>Hello, I am using library fda and I can not run a lot of 
>>functions because I receive the error:
>>
>>Error in bsplineS(evalarg, breaks, norder, nderiv) : 
>>        couldn't find function "spline.des"
>>
>>
>>do you know how I can fix that? Thnaks. Liliana
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From bitwrit at ozemail.com.au  Tue Oct  4 20:45:46 2005
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Tue, 04 Oct 2005 18:45:46 +0000
Subject: [R] heatmap
Message-ID: <4342CDDA.4070309@ozemail.com.au>

Andrea Zangrando wrote:
 > Hi,
 > i created a graph with heatmap(sma) function:
 >
 > heatmap(dataHeat(x))
 >
 > and I wish to change the gradation of colors from blue to red, how could
 > i do?
 > Using "heatmap(dataHeat(x), col=c(2,4))" i will use only 2 colors
 > without gradation.
 >
The color.gradient function in the plotrix package returns a sequence of 
interpolated colors between any two starting colors or incomplete 
sequences of primaries.

I noticed that a function named ramp (in the base package?) was 
mentioned, but I could not find it. If there is a function equivalent to 
color.gradient, I would like to know about it, as I try to avoid 
duplicating functions.

Jim



From Roger.Bivand at nhh.no  Tue Oct  4 10:58:52 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 4 Oct 2005 10:58:52 +0200 (CEST)
Subject: [R] heatmap
In-Reply-To: <4342CDDA.4070309@ozemail.com.au>
Message-ID: <Pine.LNX.4.44.0510041056500.32258-100000@reclus.nhh.no>

On Tue, 4 Oct 2005, Jim Lemon wrote:

> Andrea Zangrando wrote:
>  > Hi,
>  > i created a graph with heatmap(sma) function:
>  >
>  > heatmap(dataHeat(x))
>  >
>  > and I wish to change the gradation of colors from blue to red, how could
>  > i do?
>  > Using "heatmap(dataHeat(x), col=c(2,4))" i will use only 2 colors
>  > without gradation.
>  >
> The color.gradient function in the plotrix package returns a sequence of 
> interpolated colors between any two starting colors or incomplete 
> sequences of primaries.
> 
> I noticed that a function named ramp (in the base package?) was 
> mentioned, but I could not find it. If there is a function equivalent to 
> color.gradient, I would like to know about it, as I try to avoid 
> duplicating functions.

see ?colorRamp and look at:

> colorRampPalette
function (colors, ...) 
{
    ramp <- colorRamp(colors, ...)
    function(n) {
        x <- ramp(seq(0, 1, length = n))
        rgb(x[, 1], x[, 2], x[, 3], max = 255)
    }
}

to see where it comes from. The colorRamp/colorRampPalette combination is 
quite remarkable and lots of fun ...

Roger

> 
> Jim
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From res90sx5 at verizon.net  Tue Oct  4 18:02:58 2005
From: res90sx5 at verizon.net (Daniel Nordlund)
Date: Tue, 04 Oct 2005 09:02:58 -0700
Subject: [R] sampling vectors
In-Reply-To: <434227BE.7060309@adfa.edu.au>
Message-ID: <0INT001ULVT3K5ZH@vms046.mailsrvcs.net>

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch]
> On Behalf Of ecatchpole
> Sent: Monday, October 03, 2005 11:57 PM
> To: Eric Pante
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] sampling vectors
> 
> Eric,
> 
> If you want samples of size 3 from 0:50, with sum==50, this seems to do
> the job (with apologies to those who really know how to program in R):
> 
> tot <- 50
> ii <- 0
> aa <- list()
> for(i in 0:tot){
>     for(j in 0:(tot-i)){
>        k <- tot-i-j
>        ii <- ii+1
>        aa[[ii]] <- list(i=i,j=j,k=k)
>     }
> }
> 
> aa[sample(ii, 4)] # for a sample of 4.
> 
> If you want a sample of size n from x[1],...x[N], such that the sample
> sum is T, then that is much trickier!
> 
> Ted.
> 
> On 04/10/05 07:31,  Eric Pante wrote,:
> > Hello Listers,
> >
> > I am trying to sample a vector to create a new one of sample length,
> > witha  sum equal to the sum of the initial vector:
> >
> > initial = 10, 30, 10 (sum=50)
> > sample example = 5, 35, 10 (sum=50) or 25, 15, 10  (sum=50), etc ...
> >
> > My problem is to control the sum, so it stays constant.
> > Any suggestions would be very helpful !
> >
> > Thank you in advance,
> > Eric
> >

Eric,

Here is another solution, which allows vectors of different lengths and sums.

vectorSample <- function(vec) {
  tot<-sum(vec)
  Len<-length(vec)
  v < -rep(0,Len)
  for(i in Len:2) {
    UL <- tot - sum(v) - i + 1
    v[i]<-sample(1:UL,1)
    } 
  v[1] <- tot - sum(v)
  v
  }

 vectorSample( c(10,30,10) )

Hope this helps,

Dan Nordlund
Bothell, WA



From karin.lagesen at medisin.uio.no  Tue Oct  4 11:24:04 2005
From: karin.lagesen at medisin.uio.no (Karin Lagesen)
Date: Tue, 04 Oct 2005 11:24:04 +0200
Subject: [R] boxplot statistics
Message-ID: <ypx6irwdiqiz.fsf@uracil.uio.no>


I have read and reread the boxplot and the boxplot stats page, and I
still cannot understand how and what boxplot shows. I realize that
this might be due to me not knowing enough statistics, but anyway...

First, how does boxplot determine the size of the box? And is the line
inside the box the mean or the median (or something completely
different?) And how does it determine how long out the whiskers should
go?

Also, the boxplot.stats page talks about "hinges", what are those?  
"The two "hinges" are versions of the first and third quartile, i.e.,
close to 'quantile(x, c(1,3)/4)'."

Thankyou very much.

Karin
-- 
Karin Lagesen, PhD student
karin.lagesen at medisin.uio.no
http://www.cmbn.no/rognes/



From jari.haukka at geneos.fi  Tue Oct  4 11:55:35 2005
From: jari.haukka at geneos.fi (Jari Haukka)
Date: Tue, 04 Oct 2005 12:55:35 +0300
Subject: [R] (no subject)
Message-ID: <5.2.0.9.0.20051004122730.02ffc150@pop.song.fi>

Hello All,

While trying to install Matrix package following error message came out:


/usr/bin/ld: cannot find -lblas-3
collect2: ld returned 1 exit status
make: *** [Matrix.so] Error 1
ERROR: compilation failed for package 'Matrix'
** Removing '/usr/lib/R/library/Matrix'
** Restoring previous '/usr/lib/R/library/Matrix'


It seems that someting is missing. Have anybody idea where we can find this 
missing piece?
We have Debian Linux.



Jari Haukka



From jari.haukka at geneos.fi  Tue Oct  4 11:56:58 2005
From: jari.haukka at geneos.fi (Jari Haukka)
Date: Tue, 04 Oct 2005 12:56:58 +0300
Subject: [R] Problem with Matrix package
Message-ID: <5.2.0.9.0.20051004125615.030127c0@pop.song.fi>

Hello All,

While trying to install Matrix package following error message came out:


/usr/bin/ld: cannot find -lblas-3
collect2: ld returned 1 exit status
make: *** [Matrix.so] Error 1
ERROR: compilation failed for package 'Matrix'
** Removing '/usr/lib/R/library/Matrix'
** Restoring previous '/usr/lib/R/library/Matrix'


It seems that someting is missing. Have anybody idea where we can find this 
missing piece?
We have Debian Linux.


Jari Haukka



From petr.pikal at precheza.cz  Tue Oct  4 12:08:54 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 04 Oct 2005 12:08:54 +0200
Subject: [R] boxplot statistics
In-Reply-To: <ypx6irwdiqiz.fsf@uracil.uio.no>
Message-ID: <434270D6.405.F276AD@localhost>

Hi

Try to find some textbook about statistics. You can get many 
explanations just by finding "boxplot" by e.g. Google and reading 
whot you found.

And of course you can get some information from help pages you 
mentioned.

coef: this determines how far the plot "whiskers" extend out from
          the box.  If 'coef' is positive, the whiskers extend to the
											^^^^^^^^^^^^^^^^^
          most extreme data point which is no more than 'coef' times
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
          the length of the box away from the box. A value of zero
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
          causes the whiskers to extend to the data extremes (and no
          outliers be returned).

HTH
Petr



On 4 Oct 2005 at 11:24, Karin Lagesen wrote:

To:             	r-help at r-project.org
From:           	Karin Lagesen <karin.lagesen at medisin.uio.no>
Date sent:      	Tue, 04 Oct 2005 11:24:04 +0200
Subject:        	[R] boxplot statistics

> 
> I have read and reread the boxplot and the boxplot stats page, and I
> still cannot understand how and what boxplot shows. I realize that
> this might be due to me not knowing enough statistics, but anyway...
> 
> First, how does boxplot determine the size of the box? And is the line
> inside the box the mean or the median (or something completely
> different?) And how does it determine how long out the whiskers should
> go?
> 
> Also, the boxplot.stats page talks about "hinges", what are those? 
> "The two "hinges" are versions of the first and third quartile, i.e.,
> close to 'quantile(x, c(1,3)/4)'."
> 
> Thankyou very much.
> 
> Karin
> -- 
> Karin Lagesen, PhD student
> karin.lagesen at medisin.uio.no
> http://www.cmbn.no/rognes/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From Roger.Bivand at nhh.no  Tue Oct  4 12:22:10 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 4 Oct 2005 12:22:10 +0200 (CEST)
Subject: [R] boxplot statistics
In-Reply-To: <ypx6irwdiqiz.fsf@uracil.uio.no>
Message-ID: <Pine.LNX.4.44.0510041216501.32258-100000@reclus.nhh.no>

On Tue, 4 Oct 2005, Karin Lagesen wrote:

> 
> I have read and reread the boxplot and the boxplot stats page, and I
> still cannot understand how and what boxplot shows. I realize that
> this might be due to me not knowing enough statistics, but anyway...
> 
> First, how does boxplot determine the size of the box? And is the line
> inside the box the mean or the median (or something completely
> different?) And how does it determine how long out the whiskers should
> go?
> 
> Also, the boxplot.stats page talks about "hinges", what are those?  
> "The two "hinges" are versions of the first and third quartile, i.e.,
> close to 'quantile(x, c(1,3)/4)'."
> 
> Thankyou very much.

The reference on the help page is:

     Chambers, J. M., Cleveland, W. S., Kleiner, B. and Tukey, P. A.
     (1983) _Graphical Methods for Data Analysis._  Wadsworth &
     Brooks/Cole.

and a search in BIBSYS suggests that a copy is in your university library:

 author = Chambers and title word = Graphical and material type = Books

The references are there to suggest where to look for the information you 
asked for.

> 
> Karin
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From jholtman at gmail.com  Tue Oct  4 12:54:25 2005
From: jholtman at gmail.com (jim holtman)
Date: Tue, 4 Oct 2005 06:54:25 -0400
Subject: [R] newbie questions - looping through hierarchial datafille
In-Reply-To: <OF918EDC88.BF1AA4B2-ONCA257090.0003341B-CA257090.00035B10@poyry.fi>
References: <OF918EDC88.BF1AA4B2-ONCA257090.0003341B-CA257090.00035B10@poyry.fi>
Message-ID: <644e1f320510040354n6727468p2ad3b743b4353417@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051004/4571890f/attachment.pl

From Graham.Williams at togaware.com  Tue Oct  4 13:02:36 2005
From: Graham.Williams at togaware.com (Graham Williams)
Date: Tue, 4 Oct 2005 21:02:36 +1000
Subject: [R] boxplot statistics
In-Reply-To: <ypx6irwdiqiz.fsf@uracil.uio.no>
References: <ypx6irwdiqiz.fsf@uracil.uio.no>
Message-ID: <20051004110236.GA1178@athene.togaware.com>

Received Tue 04 Oct 2005  7:26pm +1000 from Karin Lagesen:
> 
> I have read and reread the boxplot and the boxplot stats page, and I
> still cannot understand how and what boxplot shows. I realize that
> this might be due to me not knowing enough statistics, but anyway...
> 
> First, how does boxplot determine the size of the box? And is the line
> inside the box the mean or the median (or something completely
> different?) And how does it determine how long out the whiskers should
> go?
> 
> Also, the boxplot.stats page talks about "hinges", what are those?  
> "The two "hinges" are versions of the first and third quartile, i.e.,
> close to 'quantile(x, c(1,3)/4)'."

Wikipedia has a reasonable description

	   http://en.wikipedia.org/wiki/Boxplot

Regards



From rvaradha at jhsph.edu  Tue Oct  4 13:03:58 2005
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Tue, 4 Oct 2005 07:03:58 -0400
Subject: [R] sampling vectors
Message-ID: <E619BDBD99B4F74D9DCA32F43BE926714C74B8@XCH-VN02.sph.ad.jhsph.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051004/b3e849a7/attachment.pl

From rvaradha at jhsph.edu  Tue Oct  4 13:09:14 2005
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Tue, 4 Oct 2005 07:09:14 -0400
Subject: [R] sampling vectors
Message-ID: <E619BDBD99B4F74D9DCA32F43BE926714C74B9@XCH-VN02.sph.ad.jhsph.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051004/edf3325c/attachment.pl

From je_lemaitre at hotmail.com  Tue Oct  4 13:16:33 2005
From: je_lemaitre at hotmail.com (=?iso-8859-1?B?Suly9G1lIExlbWHudHJl?=)
Date: Tue, 4 Oct 2005 07:16:33 -0400
Subject: [R] Repeated measure Generalized Linear Mixed Model (glmm) ?
Message-ID: <BAY103-DAV6DEEF9AB988879EA51CAE90830@phx.gbl>

Dear all,

I want to know the probability of dying in a trap as a function of habitat
variables for a metapopulation of voles sampled in 44 stations. 
My dataset is as follow:
Station		tag number	dead	habitat1	habitat2
1		1		yes	20		26
1		2		no	20		26
2		3		no	15		16
..

As far as I know, I should use a mixed-model as:
glmmPQL<-(fixed = dead~habitat1+habitat2, random = ~1|station, family =
binomial) in the MASS library.
However, some vole individuals were recaptured (but it is not a study
designed for capture-mark-recapture!!!) therefore, I have for example, the
4th vole:
Station		tag number	dead	habitat1	habitat2
3		4		no	10		12
3		4		yes	10		12

Someone suggested me to use glmm with repeated measures with the number of
tag as the variable to repeat. Apparently, it is possible to do this in SAS.

QUESTIONS : 
1) Is this also possible to do this in R, and if yes, could you please tell
me how?
2) Is this a valid way to analyse this data, and if not, could someone
please put me in the right way?


Thank you very very much to all in advance

J??r??me Lema??tre

??tudiant au doctorat
Universit?? Laval
Qu??bec, QC  G1K 7P4



From maechler at stat.math.ethz.ch  Tue Oct  4 14:11:43 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 4 Oct 2005 14:11:43 +0200
Subject: [R] Problem with Matrix package
In-Reply-To: <5.2.0.9.0.20051004125615.030127c0@pop.song.fi>
References: <5.2.0.9.0.20051004125615.030127c0@pop.song.fi>
Message-ID: <17218.29055.457495.136066@stat.math.ethz.ch>


>>>>> "Jari" == Jari Haukka <jari.haukka at geneos.fi>
>>>>>     on Tue, 04 Oct 2005 12:56:58 +0300 writes:

    Jari> Hello All, While trying to install Matrix package
    Jari> following error message came out:

    Jari> /usr/bin/ld: cannot find -lblas-3
    Jari> collect2: ld returned 1 exit status
    Jari> make: *** [Matrix.so] Error 1
    Jari> ERROR: compilation failed for package 'Matrix'
    Jari> ** Removing '/usr/lib/R/library/Matrix'
    Jari> ** Restoring previous '/usr/lib/R/library/Matrix'

Matrix has in src/Makefile

PKG_LIBS = ${LAPACK_LIBS} ${BLAS_LIBS}

and quite a few other packages have the same or a very similar
thing in their src/Makevars or src/Makefile.

Both these variables are defined by your R installation.
And it seems are definitely defined wrongly for your environment.

Try (in a shell)
    grep LAPACK_LIBS `R RHOME`/etc/Makeconf
    grep BLAS_LIBS `R RHOME`/etc/Makeconf
to see their values
I'm sure the '-lblas-3' above is in one of them.

    Jari> It seems that someting is missing. Have anybody idea where we can find this 
    Jari> missing piece?

there are several debian packages for BLAS/LAPACK etc.
I do wonder how you got to an R installation with LAPACK_LIBS or
BLAS_LIBS that don't match the things available on your machine.

    Jari> We have Debian Linux.

Yes, and an installation of R (which one?)
that's not "correct" in the above sense.

How was it installed?

Regards,
Martin Maechler, ETH Zurich



From andrea.zangrando at unipd.it  Tue Oct  4 15:00:27 2005
From: andrea.zangrando at unipd.it (Andrea Zangrando)
Date: Tue, 04 Oct 2005 15:00:27 +0200
Subject: [R] heatmap ordered list
Message-ID: <43427CEB.2060904@unipd.it>

Hi,
another problem on heatmaps... after generating the graph with

myBlRd <- colorRampPalette(c("blue", "red"))
heatmap(dataHeat[Top100, ], col=myBlRd(15))

i need to retrieve the row names' list ordered by the dendrogram.
I tried with   "rownames(data)[Top100]"   but the list is not ordered 
(as i can see in the generated picture). Any tips?

Tnx
AZ

-- 
Andrea Zangrando - Ph.D. Student

University of Padova
Department of Pediatrics
Laboratory of Pediatric OncoHematology
Via Giustiniani, 3
35128 Padova - Italy
Phone: +39 049 8211457
Fax: +39 049 8211456
Email:   andrea.zangrando at unipd.it



From rbaer at atsu.edu  Tue Oct  4 15:38:31 2005
From: rbaer at atsu.edu (Robert Baer)
Date: Tue, 4 Oct 2005 08:38:31 -0500
Subject: [R] Getting eps into Word documents.
References: <XFMail.051003220023.Ted.Harding@nessie.mcc.ac.uk>
	<1128375845.5957.64.camel@localhost.localdomain>
Message-ID: <006101c5c8e8$e9182a10$6d0d010a@BigBaer>

> > On 03-Oct-05 Marc Schwartz (via MN) wrote:
> > > On Mon, 2005-10-03 at 16:31 -0300, Rolf Turner wrote:
> > >> A student in one of my courses has asked me about getting R graphics
> > >> output (under Linux) into a Word document.  I.e. she wants to do her
> > >> R thing under Linux, but then do her word processing using Word.
--------------snip--------------
> > > So use something like the following:
> > >
> > >
> > > postscript("RPlot.eps", height = 4, width = 4,
> > >            horizontal = FALSE, onefile = FALSE,
> > >            paper = "special")
> > >
> > > plot(1:5)
> > >
> > > dev.off()
> > >
> > >
> > > You can then import the .eps file into Word or most other such
> > > applications that can import encapsulated postscript files.

-------------snip----------------
> > > More information is available from MS here:
> > >
> > > http://support.microsoft.com/?kbid=290362
> > >
> > > HTH,
> > >
> > > Marc Schwartz
----------snip-----------
> > b) It won't work anyway if printed to a non-PostScript printer.
>
> True, which is the case irrespective of Word/Windows. If you don't have
> a PS printer locally or accessible via network, you can always install a
> PS printer driver and print to a file, which can then be printed by a
> third party if required.
>
Well, as a lowly Windows and Office user, I most often right click on R
grahics, cut to clipboard, and paste into Word.   So one possiblility is for
the student to install R on her own machine (Windows or Mac?).

But I just tried Marc's suggestion, and it looks VERY VIABLE to me.  I
generated the graph from his code snippet and used "Insert picture from
file" in Word 2003 to place the graphic in a Word document.  I then tried
printing on both an HP 4100 TN laserjet and an HP 960c deskjet.  The image
printed perfectly on both printers with crisp lines and text that apprear to
be vector-based not degraded bitmapped representations.  Certainly worth the
student trying.

HTH,
Rob Baer



From p.dalgaard at biostat.ku.dk  Tue Oct  4 16:07:38 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 04 Oct 2005 16:07:38 +0200
Subject: [R] Problem reading in external data and assigning data.frames
	within R
In-Reply-To: <200510040629.j946TFke015135@smtp.uoregon.edu>
References: <200510040629.j946TFke015135@smtp.uoregon.edu>
Message-ID: <x2mzlpv0id.fsf@viggo.kubism.ku.dk>

Nathan Dieckmann <ndieckma at uoregon.edu> writes:

>   Hey there,
> 
>     I apologize if this is an irritatingly simple question ... I'm a
> new user.  I can't understand why R flips the sign of all data values
> when reading in external text files (tab delimited or csv) with the
> read.delim or read.csv functions.  The signs of data values also seem
> to be flipped after assigning a new data.frame from within R (xnew <--

If you think the assignment operator is "<--", then that could well be
the cause....

> edit(data.frame()).  What am I doing wrong?
> 
>    Any help would be greatly appreciated.  Thanks in advance.
> 
>              -- Nate    


-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From rolf at math.unb.ca  Tue Oct  4 16:35:50 2005
From: rolf at math.unb.ca (Rolf Turner)
Date: Tue, 4 Oct 2005 11:35:50 -0300 (ADT)
Subject: [R] Getting eps into Word --- thanks.
Message-ID: <200510041435.j94EZofI026174@erdos.math.unb.ca>


Many thanks to all who responded to my inquiry about getting
(R-generated) *.eps files into a Word document.  I have passed
the suggestions on to my student in the hope that at least
one of them will work for her.

Thanks again.

			cheers,

				Rolf Turner



From kevinvol2002 at yahoo.com  Tue Oct  4 17:26:31 2005
From: kevinvol2002 at yahoo.com (Hai Lin)
Date: Tue, 4 Oct 2005 08:26:31 -0700 (PDT)
Subject: [R] lmList error message
Message-ID: <20051004152631.6251.qmail@web32411.mail.mud.yahoo.com>

It seems a problem sending this out. I am resending
it.

Hello Rs,

After running lmList, I've gotten an error message
"Error in lm.fit(x, y, offset = offset, singular.ok =
singular.ok, ...) : NA/NaN/Inf in foreign function
call (arg 4)"  I'm not able to understand what it
means.  Could anyone help me with it?  

Thanks all in advance.

Kevin 

### commands and output ###

##########################
lm.S <- lmList(Log2CM ~~ Strain | reporterID,
data=data.tall, pool=F)

> length(levels(data.tall$reporterID))
[1] 6513

> levels(data.tall$Strain)
[1] "WT" "KO"

>datatall[1:20,]
Log2CM reporterID Strain
3.430192973 IMAGE:1260690 KO
6.420003752 IMAGE:481703 KO
-2.135514971 IMAGE:1432976 KO
-2.321928095 IMAGE:959862 KO
1.370837695 IMAGE:1038124 KO
1.063264893 IMAGE:519411 KO
2.378511623 IMAGE:2101947 KO
-0.688055994 IMAGE:1260374 KO
1.389946518 IMAGE:522799 KO
-0.565199246 IMAGE:480815 KO
0.979962247 IMAGE:1430827 KO
-2.273018494 IMAGE:658095 KO
1.581642142 IMAGE:314290 KO
-0.857980995 IMAGE:1478681 KO
-1.894506871 IMAGE:1260277 KO
-0.804869659 IMAGE:480596 KO
-1.451988635 IMAGE:652861 KO
6.208242769 IMAGE:1038010 KO
5.951626379 IMAGE:519074 KO
-0.237394585 IMAGE:960834 KO



From HStevens at MUOhio.edu  Tue Oct  4 17:30:45 2005
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Tue, 4 Oct 2005 11:30:45 -0400
Subject: [R] Repeated crashes on Mac
Message-ID: <3F287540-EA6C-47E6-9FED-BD4D955EC28E@MUOhio.edu>

Hi Folks,
R v. 2.1.1, Mac OS 10.4.2

I am just know getting repeated crashes when I try to edit script  
files. I have the base package plus odesolve open.
I have rebooted and still have problems. below I append the error  
messages from the R console on the crash and also attached a single   
text file containing  two different Crash reports generated  
automatically by some application in the OS (Tiger 10.4.2) for  
reporting to Apple.

 From the R console:
2005-10-04 11:26:11.080 R[534] *** -[NSCFDictionary set]: selector  
not recognized [self = 0x6eca1d0]
2005-10-04 11:26:11.080 R[534] *** -[NSCFDictionary set]: selector  
not recognized [self = 0x6eca1d0]
2005-10-04 11:26:11.378 R[534] *** -[NSCFDictionary set]: selector  
not recognized [self = 0x6eca1d0]
2005-10-04 11:26:11.378 R[534] *** -[NSCFDictionary set]: selector  
not recognized [self = 0x6eca1d0]
2005-10-04 11:26:11.506 R[534] *** -[NSCFDictionary set]: selector  
not recognized [self = 0x6eca1d0]
2005-10-04 11:26:11.506 R[534] *** -[NSCFDictionary set]: selector  
not recognized [self = 0x6eca1d0]
2005-10-04 11:26:11.658 R[534] *** -[NSCFDictionary set]: selector  
not recognized [self = 0x6eca1d0]
2005-10-04 11:26:11.658 R[534] *** -[NSCFDictionary set]: selector  
not recognized [self = 0x6eca1d0]
2005-10-04 11:26:11.795 R[534] *** -[NSCFDictionary set]: selector  
not recognized [self = 0x6eca1d0]
2005-10-04 11:26:11.795 R[534] *** -[NSCFDictionary set]: selector  
not recognized [self = 0x6eca1d0]
2005-10-04 11:26:13.454 R[534] *** -[NSCFDictionary set]: selector  
not recognized [self = 0x6eca1d0]
2005-10-04 11:26:13.454 R[534] *** -[NSCFDictionary set]: selector  
not recognized [self = 0x6eca1d0]
2005-10-04 11:26:14.574 R[534] *** -[NSCFDictionary set]: selector  
not recognized [self = 0x6eca1d0]
2005-10-04 11:26:14.574 R[534] *** -[NSCFDictionary set]: selector  
not recognized [self = 0x6eca1d0]
2005-10-04 11:26:15.531 R[534] *** -[NSCFDictionary set]: selector  
not recognized [self = 0x6eca1d0]
2005-10-04 11:26:15.531 R[534] *** -[NSCFDictionary set]: selector  
not recognized [self = 0x6eca1d0]
 >

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Mac Crash Report.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051004/320d2130/MacCrashReport.txt
-------------- next part --------------
Any thoughts?

Thanks,

Hank Stevens


Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"


From tlumley at u.washington.edu  Tue Oct  4 18:11:59 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 4 Oct 2005 09:11:59 -0700 (PDT)
Subject: [R] boxplot statistics
In-Reply-To: <ypx6irwdiqiz.fsf@uracil.uio.no>
References: <ypx6irwdiqiz.fsf@uracil.uio.no>
Message-ID: <Pine.LNX.4.63a.0510040858570.5842@homer23.u.washington.edu>

On Tue, 4 Oct 2005, Karin Lagesen wrote:
>
> First, how does boxplot determine the size of the box? And is the line
> inside the box the mean or the median (or something completely
> different?) And how does it determine how long out the whiskers should
> go?

Part of the problem is that there are lots of different definitions of the 
quartiles (quantile() has 9 of them). If the number of observations is one 
more than a multiple of 4 then all the definitions agree, otherwise they 
are slightly different.

For the case where the number of observations is one more than a multiple 
of 4 the line in the middle is the median, the ends of the box are the 
upper and lower quartiles, and the whiskers extend to the furthest point 
that is within 1.5 box lengths from the end of the box.

When the number of observations is not one more than a multiple of four 
this is all still true, but you have to be careful about which definition 
of "quartile" you mean, for which you can read either the book referenced on 
the help page, or the code.

 	-thomas



From maechler at stat.math.ethz.ch  Tue Oct  4 18:26:07 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 4 Oct 2005 18:26:07 +0200
Subject: [R] Sending messages twice to R-help {was ... lmList error ...}
In-Reply-To: <20051004152631.6251.qmail@web32411.mail.mud.yahoo.com>
References: <20051004152631.6251.qmail@web32411.mail.mud.yahoo.com>
Message-ID: <17218.44319.198800.976959@stat.math.ethz.ch>

>>>>> "Hai" == Hai Lin <kevinvol2002 at yahoo.com>
>>>>>     on Tue, 4 Oct 2005 08:26:31 -0700 (PDT) writes:

    Hai> It seems a problem sending this out. 

why do you think so??
It was sent out to more than 3000 potential readers alright.

    Hai> I am resending it.

which is not really polite to all the r-help readers...

and will probably rather decrease than increase the probability
that it gets answered.

    Hai> Hello Rs,

  {now who will think she / he  was meant by 'R' ? ;-) }

Note that you didn't follow the posting guide at all,
and this is the most probable reason your e-mail wasn't
answered.

Regards,
Martin Maechler

Appended at the very end of every R-help posting and hence
yours, too:

    Hai> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From maechler at stat.math.ethz.ch  Tue Oct  4 18:28:19 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 4 Oct 2005 18:28:19 +0200
Subject: [R] heatmap ordered list
In-Reply-To: <43427CEB.2060904@unipd.it>
References: <43427CEB.2060904@unipd.it>
Message-ID: <17218.44451.559354.760103@stat.math.ethz.ch>

>>>>> "Andrea" == Andrea Zangrando <andrea.zangrando at unipd.it>
>>>>>     on Tue, 04 Oct 2005 15:00:27 +0200 writes:

    Andrea> Hi,
    Andrea> another problem on heatmaps... after generating the graph with

    Andrea> myBlRd <- colorRampPalette(c("blue", "red"))
    Andrea> heatmap(dataHeat[Top100, ], col=myBlRd(15))

    Andrea> i need to retrieve the row names' list ordered by the dendrogram.
    Andrea> I tried with   "rownames(data)[Top100]"   but the list is not ordered 
    Andrea> (as i can see in the generated picture). Any tips?

Main tip :  do read the help page for functions you are using.
2nd  tip :  There's a section called  "Value:"
3rd  tip :  hence use
	    r <- heatmap(...) ## and work with 'r'

Regards,
Martin Maechler, ETH Zurich



From ericpante at earthlink.net  Tue Oct  4 17:47:09 2005
From: ericpante at earthlink.net (Eric Pante)
Date: Tue, 4 Oct 2005 11:47:09 -0400
Subject: [R] sampling vectors
In-Reply-To: <0INT001ULVT3K5ZH@vms046.mailsrvcs.net>
References: <0INT001ULVT3K5ZH@vms046.mailsrvcs.net>
Message-ID: <57bb90c8f0966982b56cd10fa2c8d676@earthlink.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051004/7ba733fc/attachment.pl

From jsandblom at gmail.com  Tue Oct  4 18:42:26 2005
From: jsandblom at gmail.com (Johan Sandblom)
Date: Tue, 4 Oct 2005 18:42:26 +0200
Subject: [R] Problem with Matrix package
In-Reply-To: <5.2.0.9.0.20051004125615.030127c0@pop.song.fi>
References: <5.2.0.9.0.20051004125615.030127c0@pop.song.fi>
Message-ID: <97a06f070510040942l19e2a534y@mail.gmail.com>

Hi, if it is not essential to build the package by yourselves, why not use
the Debian package r-cran-matrix instead.

HTH, Johan Sandblom

2005/10/4, Jari Haukka <jari.haukka at geneos.fi>:
> Hello All,
>
> While trying to install Matrix package following error message came out:
>
>
> /usr/bin/ld: cannot find -lblas-3
> collect2: ld returned 1 exit status
> make: *** [Matrix.so] Error 1
> ERROR: compilation failed for package 'Matrix'
> ** Removing '/usr/lib/R/library/Matrix'
> ** Restoring previous '/usr/lib/R/library/Matrix'
>
>
> It seems that someting is missing. Have anybody idea where we can find this
> missing piece?
> We have Debian Linux.
>
>
> Jari Haukka
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>


--
Johan Sandblom  N8, MRC, Karolinska sjh
t +46851776108  17176 Stockholm
m +46735521477  Sweden
"What is wanted is not the will to believe, but the
will to find out, which is the exact opposite"
- Bertrand Russell



From pauljohn at ku.edu  Tue Oct  4 19:10:51 2005
From: pauljohn at ku.edu (Paul Johnson)
Date: Tue, 04 Oct 2005 12:10:51 -0500
Subject: [R] Select varying LS digits in long numbers?
In-Reply-To: <XFMail.050929184531.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.050929184531.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <4342B79B.2070902@ku.edu>

Maybe this is just the brute force you want to avoid, but it works to 
coerce the integer into a string, and then back to a number.  Could 
reduce number of lines by nesting functions, of course.

y <- 1234131431
n <- 3
ychar <- as.character(y)
ydigits <- nchar(ychar)
result <- as.numeric ( substr(ychar, ydigits- n +1, ydigits) )

pj

(Ted Harding) wrote:
> Hi Folks,
> 
> I'm trying to find a neat solution to an apparently simple
> problem, but one which turns out to be a bit more intricate
> and tricky than one might expect.
> 
> Suppose I have numbers given to a large number of digits.
> For example
> 
>   1234567021
> 
> where (though I don't know this beforehand) only the last
> 3 digits will be varying (and all 3 will vary).
> 
> What I want is, give a vector x of such numbers, to extract
> the minimal set of final digits which will include the varying
> digits (i.e. in this case the last 3 digits). And there may be
> a decimal point somewhere along the line (though again I won't
> know where, nor whether).
> 



-- 
Paul E. Johnson                       email: pauljohn at ku.edu
Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
1541 Lilac Lane, Rm 504
University of Kansas                  Office: (785) 864-9086
Lawrence, Kansas 66044-3177           FAX: (785) 864-5700



From rolf at math.unb.ca  Tue Oct  4 19:07:25 2005
From: rolf at math.unb.ca (Rolf Turner)
Date: Tue, 4 Oct 2005 14:07:25 -0300 (ADT)
Subject: [R] Dots in function names
In-Reply-To: <x2y85eidwn.fsf@turmalin.kubism.ku.dk>
Message-ID: <Pine.GSO.4.33.0510041404280.429-100000@erdos.math.unb.ca>


Peter Dalgaard wrote:

>
> Well, come the S4 revolution and dots will cause trouble no more...
>

Yes but an infinite number of other things will cause infinitely more
trouble. God save us from S4.

				cheers,

					Rolf Turner



From tlumley at u.washington.edu  Tue Oct  4 19:30:46 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 4 Oct 2005 10:30:46 -0700 (PDT)
Subject: [R] help with loading National Comorbidity Survey
In-Reply-To: <BIG-REDwQG3Y2lQXW2c00000618@bigred.datagrove.com>
References: <BIG-REDwQG3Y2lQXW2c00000618@bigred.datagrove.com>
Message-ID: <Pine.LNX.4.63a.0510041019170.5842@homer23.u.washington.edu>

On Sat, 1 Oct 2005, Jim Hurd wrote:
>
> Which provides data in DTA  (STATA), XPT (SAS), and POR (SPSS) formats all
> of which I have tried to read with the foreign package but I am not able to
> load any of them. I have 2 gb of RAM, but R crashes when the memory gets
> just over 1 GB. I am using Windows version 2.1.1. The size of the DTA file
> is 48 MB; the xpt file is 188 MB.
>

If you mean the NCS 1 data file from that link (da06694-0001.dta) then I 
don't have this problem.

I have been able to load in the .dta file under Windows on a computer with 
1Gb of RAM.  The maximum memory use was about 350Mb.  It was very slow -- 
about half an hour.  This is because the processing of missing values and 
of factor levels is very inefficient in read.dta when dealing with very 
wide data frames. It makes calls to [.data.frame, [<-.data.frame, etc, for 
each column and so the time is probably quadratic in the number of 
columns.

The call to .External that does the actual reading took less than 1% of 
the time. If you only want a hundred or so of the 3000 variables it may be 
worth just using that .External() call to read the data, then subset it 
and then work out how to apply the factor levels and so on.

read.dta clearly needs a different algorithm to handle very wide data sets 
efficiently.

 	-thomas



From rolf at math.unb.ca  Tue Oct  4 19:34:44 2005
From: rolf at math.unb.ca (Rolf Turner)
Date: Tue, 4 Oct 2005 14:34:44 -0300 (ADT)
Subject: [R] User error (was arima.sim bug?)
In-Reply-To: <Pine.LNX.4.61.0510021528520.17389@gannet.stats>
Message-ID: <Pine.GSO.4.33.0510041429550.429-100000@erdos.math.unb.ca>


Brian Ripley wrote (in response to S. E. Kemp):

> > I am using the arima.sim function to generate some AR time series.
> > However, the function does not seem to produce exactly the same time
> > series when I specify the innov parameter. For example
	<snip>
> > Given the fact that I have provided the innovations shouldn't the time
> > series be exactly the same?
>
> No.  Hint: where does the randomness for the burn-in come from?

	What then, pray tell, is the point of having the
	``innov'' argument at all?

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From mschwartz at mn.rr.com  Tue Oct  4 19:42:17 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Tue, 04 Oct 2005 12:42:17 -0500
Subject: [R] Getting eps into Word documents.
In-Reply-To: <006101c5c8e8$e9182a10$6d0d010a@BigBaer>
References: <XFMail.051003220023.Ted.Harding@nessie.mcc.ac.uk>
	<1128375845.5957.64.camel@localhost.localdomain>
	<006101c5c8e8$e9182a10$6d0d010a@BigBaer>
Message-ID: <1128447737.25322.21.camel@localhost.localdomain>

On Tue, 2005-10-04 at 08:38 -0500, Robert Baer wrote:
> > > On 03-Oct-05 Marc Schwartz (via MN) wrote:
> > > > On Mon, 2005-10-03 at 16:31 -0300, Rolf Turner wrote:
> > > >> A student in one of my courses has asked me about getting R graphics
> > > >> output (under Linux) into a Word document.  I.e. she wants to do her
> > > >> R thing under Linux, but then do her word processing using Word.
> --------------snip--------------
> > > > So use something like the following:
> > > >
> > > >
> > > > postscript("RPlot.eps", height = 4, width = 4,
> > > >            horizontal = FALSE, onefile = FALSE,
> > > >            paper = "special")
> > > >
> > > > plot(1:5)
> > > >
> > > > dev.off()
> > > >
> > > >
> > > > You can then import the .eps file into Word or most other such
> > > > applications that can import encapsulated postscript files.
> 
> -------------snip----------------
> > > > More information is available from MS here:
> > > >
> > > > http://support.microsoft.com/?kbid=290362
> > > >
> > > > HTH,
> > > >
> > > > Marc Schwartz
> ----------snip-----------
> > > b) It won't work anyway if printed to a non-PostScript printer.
> >
> > True, which is the case irrespective of Word/Windows. If you don't have
> > a PS printer locally or accessible via network, you can always install a
> > PS printer driver and print to a file, which can then be printed by a
> > third party if required.
> >
> Well, as a lowly Windows and Office user, I most often right click on R
> grahics, cut to clipboard, and paste into Word.   So one possiblility is for
> the student to install R on her own machine (Windows or Mac?).
> 
> But I just tried Marc's suggestion, and it looks VERY VIABLE to me.  I
> generated the graph from his code snippet and used "Insert picture from
> file" in Word 2003 to place the graphic in a Word document.  I then tried
> printing on both an HP 4100 TN laserjet and an HP 960c deskjet.  The image
> printed perfectly on both printers with crisp lines and text that apprear to
> be vector-based not degraded bitmapped representations.  Certainly worth the
> student trying.


Glad to hear that worked for you.

I do think that the majority of problems with importing EPS files from R
into other applications (Word, Powerpoint, Writer, Impress, etc.) are
due to not properly configuring the postscript() arguments that are on
the help page. 

I should also note that beyond plots, I use this same approach for
putting LaTeX tables into these documents as well. There are times where
I need create one or more nicely formatted tables for inclusion in
another document, to then be used by someone else.

I generate the LaTeX preamble, document and table code using R, then
run:

  latex FileName.tex
  dvips -E FileName -o FileName.ps

where the '-E' option to dvips attempts to create an EPS output file
with a tight bounding box. The result is a single EPS file with the
table (much like the plot example) ready for import.

I had been using 'epstool' to create the image preview, but now that
OO.org 2.0 has included this automatically upon import (as do the latest
versions of Word), this step is no longer required.

In this way, I can use R to create reproducible and publication ready
tables for use by others in their documents, in situations where they
are not (or cannot) use LaTeX for the entire document.

HTH,

Marc



From kevinvol2002 at yahoo.com  Tue Oct  4 20:14:04 2005
From: kevinvol2002 at yahoo.com (Hai Lin)
Date: Tue, 4 Oct 2005 11:14:04 -0700 (PDT)
Subject: [R] Sending messages twice to R-help {was ... lmList error ...}
In-Reply-To: <17218.44319.198800.976959@stat.math.ethz.ch>
Message-ID: <20051004181404.75129.qmail@web32414.mail.mud.yahoo.com>

Hello Martin and R users,

Thanks for your advice. Sorry disturbing some of you.


Kevin

--- Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> "Hai" == Hai Lin <kevinvol2002 at yahoo.com>
> >>>>>     on Tue, 4 Oct 2005 08:26:31 -0700 (PDT)
> writes:
> 
>     Hai> It seems a problem sending this out. 
> 
> why do you think so??
> It was sent out to more than 3000 potential readers
> alright.
> 
>     Hai> I am resending it.
> 
> which is not really polite to all the r-help
> readers...
> 
> and will probably rather decrease than increase the
> probability
> that it gets answered.
> 
>     Hai> Hello Rs,
> 
>   {now who will think she / he  was meant by 'R' ?
> ;-) }
> 
> Note that you didn't follow the posting guide at
> all,
> and this is the most probable reason your e-mail
> wasn't
> answered.
> 
> Regards,
> Martin Maechler
> 
> Appended at the very end of every R-help posting and
> hence
> yours, too:
> 
>     Hai> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
>



From statsfay at hotmail.com  Tue Oct  4 20:23:33 2005
From: statsfay at hotmail.com (Gao Fay)
Date: Tue, 04 Oct 2005 14:23:33 -0400
Subject: [R] Help ...
Message-ID: <BAY104-F3966F4CE4982F8C70BC63ED0830@phx.gbl>

Hi there,

When I run the following, why does it give a error like that?

> res2<-array(0,c(5,4,12488,1000))
Error: cannot allocate vector of size 1951250 Kb

Thank you for helping me.
Fay



From andy_liaw at merck.com  Tue Oct  4 20:28:10 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 4 Oct 2005 14:28:10 -0400
Subject: [R] Help ...
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED4C8@usctmx1106.merck.com>

It's because you've asked R to create an object of size 5 * 4 * 12488 *
1000 * 8 bytes, or 1905.5 MB, and R failed to get that much memory from
the operating system.

Andy

> From: Gao Fay
> 
> Hi there,
> 
> When I run the following, why does it give a error like that?
> 
> > res2<-array(0,c(5,4,12488,1000))
> Error: cannot allocate vector of size 1951250 Kb
> 
> Thank you for helping me.
> Fay
> 
>



From helprhelp at gmail.com  Tue Oct  4 20:51:11 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Tue, 4 Oct 2005 13:51:11 -0500
Subject: [R] missing handling
In-Reply-To: <644e1f3205092712027fc34712@mail.gmail.com>
References: <cdf81783050927111745d66647@mail.gmail.com>
	<644e1f3205092712027fc34712@mail.gmail.com>
Message-ID: <cdf817830510041151o6e9fab83xa456848439aab09c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051004/98137c5a/attachment.pl

From elvis at xlsolutions-corp.com  Tue Oct  4 20:52:16 2005
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Tue, 04 Oct 2005 11:52:16 -0700
Subject: [R] Cours***Seattle***R/Splus Advanced Programming, November 2005
Message-ID: <20051004115216.a108dc04937c07ba67766dad37185406.1b63697c9c.wbe@email.email.secureserver.net>

XSolutions Corp (www.xlsolutions-corp.com) is proud to announce
our  November, 2005 "Advanced R/Splus programming" in Seattle

www.xlsolutions-corp.com/Radv.htm

********* Seattle ------------------------ November 10th-11th, 2005

Ask for group discount and reserve your seat Now  (payment due after
the class)

Email Sue Turner:  sue at xlsolutions-corp.com

Course Outline:

- Overview of R/S fundamentals: Syntax and Semantics
- Class and Inheritance in R/S-Plus
- Concepts, Construction and good use of language objects
- Coercion and efficiency
- Object-oriented programming in R and S-Plus
- Advanced manipulation tools: Parse, Deparse, Substitute, etc.
- How to fully take advantage of Vectorization
- Generic and Method Functions; S4 (S-Plus 6)
- Search path, databases and frames Visibility
- Working with large objects
- Handling Properly Recursion and iterative calculations
- Managing loops; For (S-Plus) and for() loops
- Consequences of Lazy Evaluation
- Efficient Code practices for large computations
- Memory management and Resource monitoring
- Writing R/S-Plus functions to call compiled code
- Writing and debugging compiled code for R/S-Plus system
- Connecting R/S-Plus to External Data Sources
- Understanding the structure of model fitting functions in R/S-Plus
- Designing and Packaging efficiently a new model function

It'll also deal with lots of S-Plus efficiency issues and any special
topics
from participants is welcome.

Please let us know if you and your colleagues are interested in this
class
to take advantage of group discount.  Register now to secure your seat
in this
course!

Cheers,

Elvis Miller, PhD
Manager Training.
XLSolutions Corporation
206 686 1578
www.xlsolutions-corp.com



From JAROSLAW.W.TUSZYNSKI at saic.com  Tue Oct  4 21:04:57 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Tue, 4 Oct 2005 15:04:57 -0400 
Subject: [R] Animation of Mandelbrot Set
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD503F00DE2@us-arlington-0668.mail.saic.com>

Hi,

I was playing with Mandelbrot sets and come up with the following code, I
thought I would share: 

library(fields)  # for tim.colors
library(caTools) # for write.gif
m = 400          # grid size
C = complex( real=rep(seq(-1.8,0.6, length.out=m), each=m ), 
             imag=rep(seq(-1.2,1.2, length.out=m),      m ) )
C = matrix(C,m,m)
Z = 0
X = array(0, c(m,m,20))
for (k in 1:20) {
  Z = Z^2+C
  X[,,k] = exp(-abs(Z))
}
image(X[,,k], col=tim.colors(256)) # show final image in R
write.gif(X, "Mandelbrot.gif", col=tim.colors(256), delay=100)
# drop "Mandelbrot.gif" file from current directory on any web brouser to
see the animation

 Jarek 
====================================================\==== 
 Jarek Tuszynski, PhD.                           o / \ 
 Science Applications International Corporation  <\__,|  
 (703) 676-4192                                   ">  \ 
 Jaroslaw.W.Tuszynski at saic.com                     `   \



From p.murrell at auckland.ac.nz  Tue Oct  4 21:35:11 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 05 Oct 2005 08:35:11 +1300
Subject: [R] grob questions
References: <971536df0510022237v7b91c484g2cb998321d192d5b@mail.gmail.com>
Message-ID: <4342D96F.1020907@stat.auckland.ac.nz>

Hi


Gabor Grothendieck wrote:
> If I run the following example from:
> http://www.stat.auckland.ac.nz/~paul/grid/doc/grobs.pdf
> 
> 
>>grid.newpage()
>>pushViewport(viewport(w = 0.5, h = 0.5))
>>myplot <- gTree(name = "myplot", children = gList(rectGrob(name = "box",
> 
> + gp = gpar(col = "grey")), xaxisGrob(name = "xaxis")))
> 
>>grid.draw(myplot)
>>grid.edit("myplot::xaxis", at = 1:10/11)
>>grid.edit("myplot::xaxis::labels", label = round(1:10/11, 2))
>>grid.edit("myplot::xaxis::labels", y = unit(-1, "lines"))
> 
> 
> then
> 
> 
>>str(myplot$children$xaxis)
> 
> 
> lists 'at' but not the 'labels'.
> 
> yet if I do this then the labels are listed:
> 
> 
>>xx <- xaxisGrob(name = "myX", at = 1:10)
>>childNames(xx)
> 
> [1] "major"  "ticks"  "labels"
> 
> 
> 1. How do I get to labels in the first case?


First, if the xaxisGrob has at=NULL then it calculates its tick-marks at 
drawing time (based on the viewport it gets drawn in).  So it does not 
store any labels (it doesn't know what they are until it gets drawn). If 
you specify a non-NULL 'at' then the axis creates labels.

Second, grid grobs are standard R objects (copy-on-modify) so the object 
'myplot' is not the same object that is being modified by the calls to 
grid.edit().  grid.edit() destructively modifies a copy of the grob that 
grid has stored on its display list;  you refer to the appropriate grob 
via its name (not via an R object).  By comparison, editGrob() takes a 
grob and returns a modified copy of the grob, for example ...

myplot <- editGrob(myplot, at = 1:10/11)

The naming scheme for grid functions is:  grid.<*>() functions for 
producing or working with graphical *output* (drawing grobs or working 
with grobs that have been drawn) and <*>Grob() functions for working 
(off-screen) with grobs.


> 2. Is there a better construct than myplot$children$xaxis?


The getGrob(), editGrob(), etc functions for working with grobs (and 
sub-grobs) off-screen and grid.get(), grid.edit(), etc for working with 
graphical output.

"Recent changes in grid graphics". R News, 5(1):12-20, May 2005 
describes this some more.

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From ripley at stats.ox.ac.uk  Tue Oct  4 21:35:47 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 4 Oct 2005 20:35:47 +0100 (BST)
Subject: [R] missing handling
In-Reply-To: <cdf817830510041151o6e9fab83xa456848439aab09c@mail.gmail.com>
References: <cdf81783050927111745d66647@mail.gmail.com>
	<644e1f3205092712027fc34712@mail.gmail.com>
	<cdf817830510041151o6e9fab83xa456848439aab09c@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0510042001320.12433@gannet.stats>

On Tue, 4 Oct 2005, Weiwei Shi wrote:

> Hi, Jim:
> I tried your code and get the following error:
> trn1<-read.table('trn1.svm', header=F, na.string='.', sep='|')
> Med<-apply(trn1, 2, median, na.rm=T)
> Ind<-which(is.na(trn1), arr.ind=T)
> trn1[Ind]<-Med[Ind[,'col']]
> Error in "[<-.data.frame"(`*tmp*`, Ind, value = c(1.00802124455,
> 1.00802124455, :
> only logical matrix subscripts are allowed in replacement
>
>
> I cannot figure out why.

Read the help for "[<-.data.frame" to be told the answer.

A data frame (as given by read.table) is not a matrix, as the example 
presumably was.  Indexing whole matrices at once is efficient, but it 
hides loops for data frames.

You will not do better than looping over columns for a data frame, but you 
certainly do not need to loop over rows which is very inefficient. 
Something like

trn2 <- trn1
for(i in names(trn2)) {
     Med <- median(trn2[[i]], na.rm = TRUE)
     trn2[i, is.na(trn2[[i]])] <- Med
}


>
> Thanks for help,
>
> On 9/27/05, jim holtman <jholtman at gmail.com> wrote:
>>
>> Use 'which(...arr.ind=T)'
>> > x.1
>> [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
>> [1,] 6 10 3 4 10 7 9 8 4 10
>> [2,] 8 7 4 7 4 8 3 NA 3 4
>> [3,] 7 7 10 10 3 5 3 2 2 2
>> [4,] 3 4 5 10 10 2 6 9 4 5
>> [5,] 3 5 9 5 6 NA 3 NA 6 7
>> [6,] 9 6 10 5 10 4 2 10 NA 5
>> [7,] 5 2 5 10 3 7 6 4 6 8
>> [8,] 2 6 1 8 9 2 7 8 3 8
>> [9,] 9 1 4 9 8 10 2 NA 1 7
>> [10,] 2 4 8 7 NA 4 3 NA 5 5
>>> x.4
>> [1] 5.5 5.5 5.0 7.5 8.0 5.0 3.0 8.0 4.0 6.0
>>> Med <- apply(x.1, 2, median, na.rm=T) # get median
>>> Ind <- which(is.na(x.1), arr.ind=T) # determine which are NA
>>> x.1[Ind] <- Med[Ind[,'col']] # replace with median
>>> x.1
>> [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
>> [1,] 6 10 3 4 10 7 9 8 4 10
>> [2,] 8 7 4 7 4 8 3 8 3 4
>> [3,] 7 7 10 10 3 5 3 2 2 2
>> [4,] 3 4 5 10 10 2 6 9 4 5
>> [5,] 3 5 9 5 6 5 3 8 6 7
>> [6,] 9 6 10 5 10 4 2 10 4 5
>> [7,] 5 2 5 10 3 7 6 4 6 8
>> [8,] 2 6 1 8 9 2 7 8 3 8
>> [9,] 9 1 4 9 8 10 2 8 1 7
>> [10,] 2 4 8 7 8 4 3 8 5 5
>>>
>>
>>
>>  On 9/27/05, Weiwei Shi <helprhelp at gmail.com> wrote:
>>
>>> Hi,
>>> I have the following codes to replace missing using median, assuming
>>> missing
>>> only occurs on continuous variables:
>>>
>>> trn1<-read.table('trn1.fv', header=F, na.string='.', sep='|')
>>>
>>> # median
>>> m.trn1<-sapply(1:ncol(trn1), function(i) median(trn1[,i], na.rm=T))
>>>
>>> #replace
>>> trn2<-trn1
>>> for (each in 1:nrow(trn1)){
>>> index.missing=which(is.na(trn1[each,]))
>>> trn2[each,]<-replace(trn1[each,], index.missing, m.trn1[index.missing])
>>> }
>>>
>>>
>>> Anyone can suggest some ways to improve it since replacing 10 takes 1.5sec:
>>>> system.time(for (each in 1:10){index.missing=which(is.na
>>> (trn1[each,]));
>>> trn2[each,]<-replace(trn1[each,], index.missing, m.trn1[index.missing
>>> ]);})
>>> [1] 1.53 0.00 1.53 0.00 0.00
>>>
>>>
>>> Another general question is
>>> are there some packages in R doing missing handling?
>>>
>>> Thanks,
>>>
>>> --
>>> Weiwei Shi, Ph.D
>>>
>>> "Did you always know?"
>>> "No, I did not. But I believed..."
>>> ---Matrix III
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide!
>>> http://www.R-project.org/posting-guide.html
>>>
>>
>>
>>
>> --
>> Jim Holtman
>> Cincinnati, OH
>> +1 513 247 0281
>>
>> What the problem you are trying to solve?
>
>
>
>
> --
> Weiwei Shi, Ph.D
>
> "Did you always know?"
> "No, I did not. But I believed..."
> ---Matrix III
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From goff at nawwal.org  Tue Oct  4 21:37:07 2005
From: goff at nawwal.org (Matt Goff)
Date: Tue, 04 Oct 2005 11:37:07 -0800
Subject: [R] Joining Dataframes
Message-ID: <op.sx4zf50bz9djk1@relay.pair.com>


I am attempting to join several dataframes that summarize sampling effort  
for different samples into one large data.frame/table.
I have looked at the merge command, but have not been clever enough to  
figure out how to get it to do what I want.

A simplified example of what I am trying to do:

The dataframes I have look like this (they were generated using the table  
command)

species1.effort
            site1   site2   site3
date1     5        5       5
date2     4        5       5
date3     4        5       5

species2.effort
            site1   site2   site3
date1     7        8        6
date3     8        7        8
date4     8        8        8

I would like to join these into a table that looks something like this:

Effort
             sp1.site1  sp1.site2  sp1.site3  sp2.site1  sp2.site2   
sp2.site2
date1         5               5          5             7              
8            6
date2         4               5          5            NA           
NA         NA
date3         4               5           5           8              
7             8
date4         NA           NA        NA         8            8              
8


I have many more dates and species, but I assume whatever method works for  
this small example, would work for larger cases.

Thanks,
Matt Goff



From francoisromain at free.fr  Tue Oct  4 21:43:59 2005
From: francoisromain at free.fr (Romain Francois)
Date: Tue, 04 Oct 2005 21:43:59 +0200
Subject: [R] Animation of Mandelbrot Set
In-Reply-To: <CA0BCF3BED56294AB91E3AD74B849FD503F00DE2@us-arlington-0668.mail.saic.com>
References: <CA0BCF3BED56294AB91E3AD74B849FD503F00DE2@us-arlington-0668.mail.saic.com>
Message-ID: <4342DB7F.9080506@free.fr>

Nice !!

Le 04.10.2005 21:04, Tuszynski, Jaroslaw W. a ??crit :

>Hi,
>
>I was playing with Mandelbrot sets and come up with the following code, I
>thought I would share: 
>
>library(fields)  # for tim.colors
>library(caTools) # for write.gif
>m = 400          # grid size
>C = complex( real=rep(seq(-1.8,0.6, length.out=m), each=m ), 
>             imag=rep(seq(-1.2,1.2, length.out=m),      m ) )
>C = matrix(C,m,m)
>Z = 0
>X = array(0, c(m,m,20))
>for (k in 1:20) {
>  Z = Z^2+C
>  X[,,k] = exp(-abs(Z))
>}
>image(X[,,k], col=tim.colors(256)) # show final image in R
>write.gif(X, "Mandelbrot.gif", col=tim.colors(256), delay=100)
># drop "Mandelbrot.gif" file from current directory on any web brouser to
>see the animation
>
> Jarek 
>====================================================\==== 
> Jarek Tuszynski, PhD.                           o / \ 
> Science Applications International Corporation  <\__,|  
> (703) 676-4192                                   ">  \ 
> Jaroslaw.W.Tuszynski at saic.com                     `   \
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>
-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~
~~~~~~      Romain FRANCOIS - http://addictedtor.free.fr         ~~~~~~
~~~~        Etudiant  ISUP - CS3 - Industrie et Services           ~~~~
~~                http://www.isup.cicrp.jussieu.fr/                  ~~
~~~~           Stagiaire INRIA Futurs - Equipe SELECT              ~~~~
~~~~~~   http://www.inria.fr/recherche/equipes/select.fr.html    ~~~~~~
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~



From deepayan.sarkar at gmail.com  Tue Oct  4 21:45:34 2005
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 4 Oct 2005 14:45:34 -0500
Subject: [R] pdf plotting of splom
In-Reply-To: <87y85agc2m.fsf@gmail.com>
References: <873bnihrb3.fsf@gmail.com> <87y85agc2m.fsf@gmail.com>
Message-ID: <eb555e660510041245w11419bd4weebf70855b03942@mail.gmail.com>

On 10/3/05, Sebastian Luque <spluque at gmail.com> wrote:
> Sebastian Luque <spluque at gmail.com> wrote:
>
> [...]
>
> > pdf("splom-test.pdf", family = "Times", bg = "white")
>
> [...]
>
> Silly me, it occurred to me to check more carefully that bg argument,
> which does something different in xyplot (namely, give a background to the
> figure region, not the plot region as it seems to in this case).
>
> So, removing that bg argument was the answer.  Sorry.

This was a bug nonetheless (which shouldn't have had any effect unless
you are using a recent r-devel), which has been fixed in the r-devel
version of lattice.

Deepayan



From ggrothendieck at gmail.com  Tue Oct  4 22:05:34 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 4 Oct 2005 16:05:34 -0400
Subject: [R] grob questions
In-Reply-To: <4342D96F.1020907@stat.auckland.ac.nz>
References: <971536df0510022237v7b91c484g2cb998321d192d5b@mail.gmail.com>
	<4342D96F.1020907@stat.auckland.ac.nz>
Message-ID: <971536df0510041305t2ca9fb1fk51099dc92e6d70e3@mail.gmail.com>

On 10/4/05, Paul Murrell <p.murrell at auckland.ac.nz> wrote:
> Hi
>
>
> Gabor Grothendieck wrote:
> > If I run the following example from:
> > http://www.stat.auckland.ac.nz/~paul/grid/doc/grobs.pdf
> >
> >
> >>grid.newpage()
> >>pushViewport(viewport(w = 0.5, h = 0.5))
> >>myplot <- gTree(name = "myplot", children = gList(rectGrob(name = "box",
> >
> > + gp = gpar(col = "grey")), xaxisGrob(name = "xaxis")))
> >
> >>grid.draw(myplot)
> >>grid.edit("myplot::xaxis", at = 1:10/11)
> >>grid.edit("myplot::xaxis::labels", label = round(1:10/11, 2))
> >>grid.edit("myplot::xaxis::labels", y = unit(-1, "lines"))
> >
> >
> > then
> >
> >
> >>str(myplot$children$xaxis)
> >
> >
> > lists 'at' but not the 'labels'.
> >
> > yet if I do this then the labels are listed:
> >
> >
> >>xx <- xaxisGrob(name = "myX", at = 1:10)
> >>childNames(xx)
> >
> > [1] "major"  "ticks"  "labels"
> >
> >
> > 1. How do I get to labels in the first case?
>
>
> First, if the xaxisGrob has at=NULL then it calculates its tick-marks at
> drawing time (based on the viewport it gets drawn in).  So it does not
> store any labels (it doesn't know what they are until it gets drawn). If
> you specify a non-NULL 'at' then the axis creates labels.
>
> Second, grid grobs are standard R objects (copy-on-modify) so the object
> 'myplot' is not the same object that is being modified by the calls to
> grid.edit().  grid.edit() destructively modifies a copy of the grob that
> grid has stored on its display list;  you refer to the appropriate grob
> via its name (not via an R object).  By comparison, editGrob() takes a
> grob and returns a modified copy of the grob, for example ...

Just one clarification.  What is the scope of names?
In a recent post

  https://www.stat.math.ethz.ch/pipermail/r-help/2005-October/078653.html
  https://www.stat.math.ethz.ch/pipermail/r-help/2005-October/078656.html

it seems that one had to use absolute paths and that seems to be the
case here too where as mkondrin pointed out earlier in this thread

  https://www.stat.math.ethz.ch/pipermail/r-help/2005-October/078635.html

that get.grid("myplot::xaxis::labels")$label works.

Its not clear to me whether names:

- must be in absolute paths
- can be relative to some position under some conditions
- are global across all grob names in use and can be referred to directly
as long as they are unique among all grobs defined so far.

It seems absolute path names work but I am not sure whether the
other possibilities can work under some conditions too.

Also what the scope of viewports?   Absolute path? Relative path?
Global names?  Does it work the same way?  I think at least
absolute and relative paths are avalable here but could you confirm
my understanding and whether the situation is the same for
viewports and grobs?

(In the Windows, and analogously in UNIX, file system one can write
\usr\myname or position oneself to \usr using cd and then refer to
myname in a relative way:

cd \usr
dir myname
)

Thanks.



From NordlDJ at dshs.wa.gov  Tue Oct  4 22:07:24 2005
From: NordlDJ at dshs.wa.gov (Nordlund, Dan)
Date: Tue, 4 Oct 2005 13:07:24 -0700
Subject: [R] sampling vectors
Message-ID: <592E8923DB6EA348BE8E33FCAADEFFFC13EED7CF@dshs-exch2.dshs.wa.lcl>

Eric,


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-
> bounces at stat.math.ethz.ch] On Behalf Of Eric Pante
> Sent: Tuesday, October 04, 2005 8:47 AM
> To: Daniel Nordlund
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] sampling vectors
> 
> Hi Dan,
> 
> I just tried your code with long vectors, and the sampling stops to be
> random. Do you see any reason why this is ?
> 
> examples:
> 
> ex = c(30,13,9,8,7,7,7,6,6,5,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1)
> 
>  > vectorSample(ex)
>   [1]  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  3  1  7
> 6
> [24]  4  2 75
>  > vectorSample(ex)
>   [1]  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  1  1  1  2
> 11
> [24]  7  8 67
>  >

Eric,

Probably because I failed to provide a complete solution.  I had a couple
questions while I was writing this that I didn't get clarified. One, the
code needs to be slightly modified if you want to allow vector elements to
be zero.  I required each element to be >= 1.  Two, I did not reorder the
elements in the vector.  Larger counts are more likely early in the process
than late in the process (since the partial sum is approaching the original
total).  I just placed the counts in the vector result in reverse order of
when they were obtained.

The fix to the "randomness" is simple.  Just return sample(v) instead of v
as the function result (see below).  If you want to allow zero elements I
think you can just change the lower limit on the sampling to be 0 rather
than 1 (not thoroughly tested)

vectorSample <- function(vec) {
  tot<-sum(vec)
  Len<-length(vec)
  v <-rep(0,Len)
  for(i in Len:2) {
    UL <- tot - sum(v) - i + 1
    v[i]<-sample(1:UL,1) 
    #change preceding statement to 
    #    v[i]<-sample(0:UL,1)
    #if you want to allow zeros
    }
  v[1] <- tot - sum(v)
  sample(v) #return vector in random order
  }

Dan Nordlund
Bothell, WA



From wilkening at censix.com  Tue Oct  4 22:35:30 2005
From: wilkening at censix.com (Soren Wilkening)
Date: Tue, 04 Oct 2005 22:35:30 +0200
Subject: [R] TRAMO-SEATS methodology
Message-ID: <4342E792.9070207@censix.com>

Dear Colleagues

would someone know a suitable online-source for information
regarding the TRAMO SEATS method for time series ?
(an alternative to X12 ARIMA and earlier ARIMAs used by the US census 
bureau)

Cheers

-- 
-----------------------------

Soren Wilkening
Principal Consultant

phone: +49-30-96080121
wilkening at censix.com

CENSIX Consulting
Statistics, Surveys, Censuses
http://www.censix.com



From macq at llnl.gov  Tue Oct  4 22:36:57 2005
From: macq at llnl.gov (Don MacQueen)
Date: Tue, 4 Oct 2005 13:36:57 -0700
Subject: [R] missing handling
In-Reply-To: <Pine.LNX.4.61.0510042001320.12433@gannet.stats>
References: <cdf81783050927111745d66647@mail.gmail.com>
	<644e1f3205092712027fc34712@mail.gmail.com>
	<cdf817830510041151o6e9fab83xa456848439aab09c@mail.gmail.com>
	<Pine.LNX.4.61.0510042001320.12433@gannet.stats>
Message-ID: <p0621020dbf689743353b@[128.115.153.6]>

At 8:35 PM +0100 10/4/05, Prof Brian Ripley wrote:
>On Tue, 4 Oct 2005, Weiwei Shi wrote:
>
>>  Hi, Jim:
>>  I tried your code and get the following error:
>>  trn1<-read.table('trn1.svm', header=F, na.string='.', sep='|')
>>  Med<-apply(trn1, 2, median, na.rm=T)
>>  Ind<-which(is.na(trn1), arr.ind=T)
>>  trn1[Ind]<-Med[Ind[,'col']]
>>  Error in "[<-.data.frame"(`*tmp*`, Ind, value = c(1.00802124455,
>>  1.00802124455, :
>>  only logical matrix subscripts are allowed in replacement
>>
>>
>>  I cannot figure out why.
>
>Read the help for "[<-.data.frame" to be told the answer.
>
>A data frame (as given by read.table) is not a matrix, as the example
>presumably was.  Indexing whole matrices at once is efficient, but it
>hides loops for data frames.
>
>You will not do better than looping over columns for a data frame, but you
>certainly do not need to loop over rows which is very inefficient.
>Something like
>
>trn2 <- trn1
>for(i in names(trn2)) {
>      Med <- median(trn2[[i]], na.rm = TRUE)
>      trn2[i, is.na(trn2[[i]])] <- Med
>}
>

But exchange the indices:

    trn2[ is.na(trn2[[i]]) , i] <- Med


>  >
>>  Thanks for help,
>>
>>  On 9/27/05, jim holtman <jholtman at gmail.com> wrote:
>>>
>>>  Use 'which(...arr.ind=T)'
>>>  > x.1
>>>  [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
>>>  [1,] 6 10 3 4 10 7 9 8 4 10
>>>  [2,] 8 7 4 7 4 8 3 NA 3 4
>>>  [3,] 7 7 10 10 3 5 3 2 2 2
>>>  [4,] 3 4 5 10 10 2 6 9 4 5
>>>  [5,] 3 5 9 5 6 NA 3 NA 6 7
>>>  [6,] 9 6 10 5 10 4 2 10 NA 5
>>>  [7,] 5 2 5 10 3 7 6 4 6 8
>>>  [8,] 2 6 1 8 9 2 7 8 3 8
>>>  [9,] 9 1 4 9 8 10 2 NA 1 7
>>>  [10,] 2 4 8 7 NA 4 3 NA 5 5
>>>>  x.4
>>>  [1] 5.5 5.5 5.0 7.5 8.0 5.0 3.0 8.0 4.0 6.0
>>>>  Med <- apply(x.1, 2, median, na.rm=T) # get median
>>>>  Ind <- which(is.na(x.1), arr.ind=T) # determine which are NA
>>>>  x.1[Ind] <- Med[Ind[,'col']] # replace with median
>>>>  x.1
>>>  [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
>>>  [1,] 6 10 3 4 10 7 9 8 4 10
>>>  [2,] 8 7 4 7 4 8 3 8 3 4
>>>  [3,] 7 7 10 10 3 5 3 2 2 2
>>>  [4,] 3 4 5 10 10 2 6 9 4 5
>>>  [5,] 3 5 9 5 6 5 3 8 6 7
>>>  [6,] 9 6 10 5 10 4 2 10 4 5
>>>  [7,] 5 2 5 10 3 7 6 4 6 8
>>>  [8,] 2 6 1 8 9 2 7 8 3 8
>>>  [9,] 9 1 4 9 8 10 2 8 1 7
>>>  [10,] 2 4 8 7 8 4 3 8 5 5
>>>>
>>>
>>>
>>>   On 9/27/05, Weiwei Shi <helprhelp at gmail.com> wrote:
>>>
>>>>  Hi,
>>>>  I have the following codes to replace missing using median, assuming
>  >>> missing
>  >>> only occurs on continuous variables:
>  >>>
>  >>> trn1<-read.table('trn1.fv', header=F, na.string='.', sep='|')
>  >>>
>  >>> # median
>  >>> m.trn1<-sapply(1:ncol(trn1), function(i) median(trn1[,i], na.rm=T))
>>>>
>>>>  #replace
>>>>  trn2<-trn1
>>>>  for (each in 1:nrow(trn1)){
>>>>  index.missing=which(is.na(trn1[each,]))
>>>>  trn2[each,]<-replace(trn1[each,], index.missing, m.trn1[index.missing])
>>>>  }
>>>>
>>>>
>>>>  Anyone can suggest some ways to improve it since replacing 10 
>>>>takes 1.5sec:
>>>>>  system.time(for (each in 1:10){index.missing=which(is.na
>>>>  (trn1[each,]));
>>>>  trn2[each,]<-replace(trn1[each,], index.missing, m.trn1[index.missing
>>>>  ]);})
>>>>  [1] 1.53 0.00 1.53 0.00 0.00
>>>>
>>>>
>>>>  Another general question is
>>>>  are there some packages in R doing missing handling?
>>>>
>>>>  Thanks,
>>>>
>>>>  --
>>>>  Weiwei Shi, Ph.D
>>>>
>>>>  "Did you always know?"
>>>>  "No, I did not. But I believed..."
>>>>  ---Matrix III
>>>>
>>>>  [[alternative HTML version deleted]]
>>>>
>>>>  ______________________________________________
>>>>  R-help at stat.math.ethz.ch mailing list
>>>>  https://stat.ethz.ch/mailman/listinfo/r-help
>>>>  PLEASE do read the posting guide!
>>>>  http://www.R-project.org/posting-guide.html
>>>>
>>>
>>>
>>>
>>>  --
>>>  Jim Holtman
>>>  Cincinnati, OH
>>>  +1 513 247 0281
>>>
>>>  What the problem you are trying to solve?
>>
>>
>>
>>
>>  --
>>  Weiwei Shi, Ph.D
>>
>>  "Did you always know?"
>>  "No, I did not. But I believed..."
>>  ---Matrix III
>>
>>	[[alternative HTML version deleted]]
>>
>>  ______________________________________________
>>  R-help at stat.math.ethz.ch mailing list
>>  https://stat.ethz.ch/mailman/listinfo/r-help
>  > PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html
>>
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From pausas at gmail.com  Tue Oct  4 22:38:25 2005
From: pausas at gmail.com (juli g. pausas)
Date: Tue, 4 Oct 2005 22:38:25 +0200
Subject: [R] repeated measures with random effects
Message-ID: <a17009720510041338n367be9fbi@mail.gmail.com>

Dear all,
I'm interested in analysing a reapeated measure desing where plant
height (H) was measured 3 times (Time). The experimental design
include 2 fixed factor (say A and B) in which A is nested in B, and a
random factor (C, the plot), using the aov().

So my first idea would be something like:

aov(H ~ B * A %in% B * Time + Error(id) )

where id is the factor coded for the repeated subjects.
But my question is how to include the random factor C ?

Any help would be appreciated. Thanks

Juli


--
Juli G. Pausas
CEAM & UA
http://www.ceam.es/lass/pausas.htm



From p.murrell at auckland.ac.nz  Tue Oct  4 22:50:16 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 05 Oct 2005 09:50:16 +1300
Subject: [R] grob questions
References: <971536df0510022237v7b91c484g2cb998321d192d5b@mail.gmail.com>	
	<4342D96F.1020907@stat.auckland.ac.nz>
	<971536df0510041305t2ca9fb1fk51099dc92e6d70e3@mail.gmail.com>
Message-ID: <4342EB08.2060403@stat.auckland.ac.nz>

Hi


Gabor Grothendieck wrote:
> On 10/4/05, Paul Murrell <p.murrell at auckland.ac.nz> wrote:
> 
>>Hi
>>
>>
>>Gabor Grothendieck wrote:
>>
>>>If I run the following example from:
>>>http://www.stat.auckland.ac.nz/~paul/grid/doc/grobs.pdf
>>>
>>>
>>>
>>>>grid.newpage()
>>>>pushViewport(viewport(w = 0.5, h = 0.5))
>>>>myplot <- gTree(name = "myplot", children = gList(rectGrob(name = "box",
>>>
>>>+ gp = gpar(col = "grey")), xaxisGrob(name = "xaxis")))
>>>
>>>
>>>>grid.draw(myplot)
>>>>grid.edit("myplot::xaxis", at = 1:10/11)
>>>>grid.edit("myplot::xaxis::labels", label = round(1:10/11, 2))
>>>>grid.edit("myplot::xaxis::labels", y = unit(-1, "lines"))
>>>
>>>
>>>then
>>>
>>>
>>>
>>>>str(myplot$children$xaxis)
>>>
>>>
>>>lists 'at' but not the 'labels'.
>>>
>>>yet if I do this then the labels are listed:
>>>
>>>
>>>
>>>>xx <- xaxisGrob(name = "myX", at = 1:10)
>>>>childNames(xx)
>>>
>>>[1] "major"  "ticks"  "labels"
>>>
>>>
>>>1. How do I get to labels in the first case?
>>
>>
>>First, if the xaxisGrob has at=NULL then it calculates its tick-marks at
>>drawing time (based on the viewport it gets drawn in).  So it does not
>>store any labels (it doesn't know what they are until it gets drawn). If
>>you specify a non-NULL 'at' then the axis creates labels.
>>
>>Second, grid grobs are standard R objects (copy-on-modify) so the object
>>'myplot' is not the same object that is being modified by the calls to
>>grid.edit().  grid.edit() destructively modifies a copy of the grob that
>>grid has stored on its display list;  you refer to the appropriate grob
>>via its name (not via an R object).  By comparison, editGrob() takes a
>>grob and returns a modified copy of the grob, for example ...
> 
> 
> Just one clarification.  What is the scope of names?
> In a recent post
> 
>   https://www.stat.math.ethz.ch/pipermail/r-help/2005-October/078653.html
>   https://www.stat.math.ethz.ch/pipermail/r-help/2005-October/078656.html
> 
> it seems that one had to use absolute paths and that seems to be the
> case here too where as mkondrin pointed out earlier in this thread
> 
>   https://www.stat.math.ethz.ch/pipermail/r-help/2005-October/078635.html
> 
> that get.grid("myplot::xaxis::labels")$label works.
> 
> Its not clear to me whether names:
> 
> - must be in absolute paths
> - can be relative to some position under some conditions
> - are global across all grob names in use and can be referred to directly
> as long as they are unique among all grobs defined so far.
> 
> It seems absolute path names work but I am not sure whether the
> other possibilities can work under some conditions too.
> 
> Also what the scope of viewports?   Absolute path? Relative path?
> Global names?  Does it work the same way?  I think at least
> absolute and relative paths are avalable here but could you confirm
> my understanding and whether the situation is the same for
> viewports and grobs?
> 
> (In the Windows, and analogously in UNIX, file system one can write
> \usr\myname or position oneself to \usr using cd and then refer to
> myname in a relative way:
> 
> cd \usr
> dir myname
> )


The distinction is not between "relative" or "absolute" paths, but 
between "strict" and "not strict" paths.

Matching a path always *starts* from your current "position" (so in that 
sense it is always "relative" and never "absolute").  When working with 
viewports, there is a current viewport tree and it is possible to be in 
different positions within that tree --- via [push|down|up]Viewport() 
--- so a path may have different meanings depending on where you are. 
(The seekViewport() function is sort of absolute because it always 
starts from the root of the viewport tree, but a non-strict 
seekViewport() [see below] behaves quite differently from an absolute 
filesystem directory path.)  When working with grobs, you tend to always 
be at the "top" or "root".  You are either: working off-screen with a 
single specific grob (gTree) so you are always at the top of that gTree; 
  or working with the grid display list, in which case you have a list 
of grobs and gTrees, which are searched one after the other.

The functions that take paths for grobs, such as grid.edit(), and for 
viewports, such as downViewport(), have an argument 'strict' which 
controls whether the path should be matched from the current position or 
whether the search can start from the current position and we'll match 
the path if it occurs anywhere below the current position.  (There are 
also 'grep' and 'global' arguments so you can get multiple matches where 
it makes sense.)

In some cases, grid has to make use of a path on its own, without 
knowing explicitly whether the path is strict (e.g., when you specify a 
path in a 'vp' slot).  In those cases, grid interprets the path as 
strict (so that, for example, grid has some chance of undoing the 
navigation down to a viewport).

Regarding uniqueness of names, all viewports *which share the same 
parent viewport* must have unique names (same for grobs).  You can, 
however, have several grobs with the same name on the display list. 
i.e., the following produces two separate grobs on the display list

grid.rect(name="rect")
grid.rect(name="rect")

Does that make things any clearer?

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From macq at llnl.gov  Tue Oct  4 22:51:26 2005
From: macq at llnl.gov (Don MacQueen)
Date: Tue, 4 Oct 2005 13:51:26 -0700
Subject: [R] Joining Dataframes
In-Reply-To: <op.sx4zf50bz9djk1@relay.pair.com>
References: <op.sx4zf50bz9djk1@relay.pair.com>
Message-ID: <p0621020ebf6898ab8997@[128.115.153.6]>

It appears that you want to match rows by date. It also looks like 
your date information is in the row names, only, if the layout of 
your example can be trusted.

The help for merge says this:
     "By default the data frames are merged on the columns with names 
they both have..."
but the column you want to merge by, date, is not in either 
dataframe. So, obviously, it can't merge on date. Also, since your 
example has other columns with the same name that you do not want to 
merge on, you will have to tell it explicitly what columns to use for 
the merge.

So, assuming I've interpreted your example correctly, try this:
   (1) get your dates into a column
   (2) use the 'by' argument of merge to force it to merge on date only.

            merge(species1.effort, species2.effort, by='date')


-Don



At 11:37 AM -0800 10/4/05, Matt Goff wrote:
>I am attempting to join several dataframes that summarize sampling effort 
>for different samples into one large data.frame/table.
>I have looked at the merge command, but have not been clever enough to 
>figure out how to get it to do what I want.
>
>A simplified example of what I am trying to do:
>
>The dataframes I have look like this (they were generated using the table 
>command)
>
>species1.effort
>             site1   site2   site3
>date1     5        5       5
>date2     4        5       5
>date3     4        5       5
>
>species2.effort
>             site1   site2   site3
>date1     7        8        6
>date3     8        7        8
>date4     8        8        8
>
>I would like to join these into a table that looks something like this:
>
>Effort
>              sp1.site1  sp1.site2  sp1.site3  sp2.site1  sp2.site2  
>sp2.site2
>date1         5               5          5             7             
>8            6
>date2         4               5          5            NA          
>NA         NA
>date3         4               5           5           8             
>7             8
>date4         NA           NA        NA         8            8             
>8
>
>
>I have many more dates and species, but I assume whatever method works for 
>this small example, would work for larger cases.
>
>Thanks,
>Matt Goff
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From lijun.wang19 at spcorp.com  Tue Oct  4 22:51:45 2005
From: lijun.wang19 at spcorp.com (Wang, Lijun (SPRI 19))
Date: Tue, 4 Oct 2005 16:51:45 -0400
Subject: [R] The error message in package Mix
Message-ID: <D69CD3EF3CFD734B986324648BD545D50CF81B@KENMSG27.us.schp.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051004/2e8eeda2/attachment.pl

From helprhelp at gmail.com  Tue Oct  4 23:33:39 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Tue, 4 Oct 2005 16:33:39 -0500
Subject: [R] generalized linear model and missing handling
Message-ID: <cdf817830510041433r76c119bchdac56a7ec6918ca@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051004/0e03e909/attachment.pl

From dlvanbrunt at gmail.com  Tue Oct  4 23:44:27 2005
From: dlvanbrunt at gmail.com (David L. Van Brunt, Ph.D.)
Date: Tue, 4 Oct 2005 16:44:27 -0500
Subject: [R] "Survey" package and NAMCS data... unsure of specification
Message-ID: <d332d3e10510041444x92a49d1nab313886b969bd83@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051004/1f3c9bad/attachment.pl

From helprhelp at gmail.com  Tue Oct  4 23:50:55 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Tue, 4 Oct 2005 16:50:55 -0500
Subject: [R] generalized linear model and missing handling
In-Reply-To: <cdf817830510041433r76c119bchdac56a7ec6918ca@mail.gmail.com>
References: <cdf817830510041433r76c119bchdac56a7ec6918ca@mail.gmail.com>
Message-ID: <cdf817830510041450w55ede940l7d5dd78d1bcd11c1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051004/b6de591b/attachment.pl

From ripley at stats.ox.ac.uk  Wed Oct  5 00:22:36 2005
From: ripley at stats.ox.ac.uk (Brian D Ripley)
Date: Tue, 4 Oct 2005 23:22:36 +0100 (BST)
Subject: [R] User error (was arima.sim bug?)
In-Reply-To: <Pine.GSO.4.33.0510041429550.429-100000@erdos.math.unb.ca>
Message-ID: <Pine.GSO.4.31.0510042318260.23485-100000@markov.stats>

On Tue, 4 Oct 2005, Rolf Turner wrote:

>
> Brian Ripley wrote (in response to S. E. Kemp):
>
> > > I am using the arima.sim function to generate some AR time series.
> > > However, the function does not seem to produce exactly the same time
> > > series when I specify the innov parameter. For example
> 	<snip>
> > > Given the fact that I have provided the innovations shouldn't the time
> > > series be exactly the same?
> >
> > No.  Hint: where does the randomness for the burn-in come from?
>
> 	What then, pray tell, is the point of having the
> 	``innov'' argument at all?

To allow non-Gaussian innovations, in particular for use in bootstrapping
time series.  (This started life in package boot and is used in
example(tsboot).)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From park at hcs.ufl.edu  Wed Oct  5 01:06:35 2005
From: park at hcs.ufl.edu (park)
Date: Tue, 4 Oct 2005 19:06:35 -0400
Subject: [R] Need help on  ARIMA (time series analysis)
Message-ID: <000401c5c938$44d13500$6a2de380@hcs.ufl.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051004/bd8bee12/attachment.pl

From naiara at mail.utexas.edu  Wed Oct  5 01:12:59 2005
From: naiara at mail.utexas.edu (Naiara S. Pinto)
Date: Tue, 4 Oct 2005 18:12:59 -0500 (CDT)
Subject: [R] Rcmdr and scatter3d
Message-ID: <51936.129.116.71.233.1128467579.squirrel@129.116.71.233>

Hi folks,

I'd like to use scatter3d (which is in R commander) to plot more than one
dataset in the same graph, each dataset with a different color. The kind
of stuff you would do with "holdon" in Matlab.

I read a recent message that was posted to this list with a similar
problem, but I couldn't understand the reply. Could someone give me one
example? How do you plot subgroups using scatter3d?

Thanks a lot!

Naiara.


--------------------------------------------
Naiara S. Pinto
Ecology, Evolution and Behavior
1 University Station A6700
Austin, TX, 78712



From tlumley at u.washington.edu  Wed Oct  5 01:21:14 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 4 Oct 2005 16:21:14 -0700 (PDT)
Subject: [R] "Survey" package and NAMCS data... unsure of specification
In-Reply-To: <d332d3e10510041444x92a49d1nab313886b969bd83@mail.gmail.com>
References: <d332d3e10510041444x92a49d1nab313886b969bd83@mail.gmail.com>
Message-ID: <Pine.LNX.4.63a.0510041611530.5842@homer23.u.washington.edu>

On Tue, 4 Oct 2005, David L. Van Brunt, Ph.D. wrote:

> Hello, all.
>
> I wanted to use the "survey" package to analyze data from the National
> Ambulatory Medical Care Survey, and am having some difficulty translating
> the analysis keywords from one package (Stata) to the other (R). The data
> were collected using a multistage probability sampling, and there are
> variables included to identify the sampling units and weights. Documentation
> from the NAMCS describes this for Stata as follows (note the variable names
> in the data are in caps):
>
> The pweight (PATWT), strata (CSTRATM), and PSU (CPSUM) are set with the
> svyset command as
> follows:
> svyset pweight PATWT
> svyset strata CSTRATM
> svyset psu CPSUM
>

Supposing your data frame is called 'namcs'

dnamcs <- svydesign(id=~CPSUM, strata=~CSTRATM, weight=~PATWT, data=namcs)

or perhaps

dnamcs <- svydesign(id=~CPSUM, strata=~CSTRATM, weight=~PATWT,
                       data=namcs, nest=TRUE)

(nest=TRUE is needed if CPSUM repeats the same values in different 
strata).

Also, if you have access to design variables for the multistage design you 
can use them (but it probably won't make much difference). There's a very 
brief example using the National Health Interview Study at
  http://faculty.washington.edu/tlumley/survey/example-twostage.html


 	-thomas



From ggrothendieck at gmail.com  Wed Oct  5 02:32:09 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 4 Oct 2005 20:32:09 -0400
Subject: [R] grob questions
In-Reply-To: <4342EB08.2060403@stat.auckland.ac.nz>
References: <971536df0510022237v7b91c484g2cb998321d192d5b@mail.gmail.com>
	<4342D96F.1020907@stat.auckland.ac.nz>
	<971536df0510041305t2ca9fb1fk51099dc92e6d70e3@mail.gmail.com>
	<4342EB08.2060403@stat.auckland.ac.nz>
Message-ID: <971536df0510041732n19b099bidba8e17a8f98c77e@mail.gmail.com>

On 10/4/05, Paul Murrell <p.murrell at auckland.ac.nz> wrote:
> Hi
>
>
> Gabor Grothendieck wrote:
> > On 10/4/05, Paul Murrell <p.murrell at auckland.ac.nz> wrote:
> >
> >>Hi
> >>
> >>
> >>Gabor Grothendieck wrote:
> >>
> >>>If I run the following example from:
> >>>http://www.stat.auckland.ac.nz/~paul/grid/doc/grobs.pdf
> >>>
> >>>
> >>>
> >>>>grid.newpage()
> >>>>pushViewport(viewport(w = 0.5, h = 0.5))
> >>>>myplot <- gTree(name = "myplot", children = gList(rectGrob(name = "box",
> >>>
> >>>+ gp = gpar(col = "grey")), xaxisGrob(name = "xaxis")))
> >>>
> >>>
> >>>>grid.draw(myplot)
> >>>>grid.edit("myplot::xaxis", at = 1:10/11)
> >>>>grid.edit("myplot::xaxis::labels", label = round(1:10/11, 2))
> >>>>grid.edit("myplot::xaxis::labels", y = unit(-1, "lines"))
> >>>
> >>>
> >>>then
> >>>
> >>>
> >>>
> >>>>str(myplot$children$xaxis)
> >>>
> >>>
> >>>lists 'at' but not the 'labels'.
> >>>
> >>>yet if I do this then the labels are listed:
> >>>
> >>>
> >>>
> >>>>xx <- xaxisGrob(name = "myX", at = 1:10)
> >>>>childNames(xx)
> >>>
> >>>[1] "major"  "ticks"  "labels"
> >>>
> >>>
> >>>1. How do I get to labels in the first case?
> >>
> >>
> >>First, if the xaxisGrob has at=NULL then it calculates its tick-marks at
> >>drawing time (based on the viewport it gets drawn in).  So it does not
> >>store any labels (it doesn't know what they are until it gets drawn). If
> >>you specify a non-NULL 'at' then the axis creates labels.
> >>
> >>Second, grid grobs are standard R objects (copy-on-modify) so the object
> >>'myplot' is not the same object that is being modified by the calls to
> >>grid.edit().  grid.edit() destructively modifies a copy of the grob that
> >>grid has stored on its display list;  you refer to the appropriate grob
> >>via its name (not via an R object).  By comparison, editGrob() takes a
> >>grob and returns a modified copy of the grob, for example ...
> >
> >
> > Just one clarification.  What is the scope of names?
> > In a recent post
> >
> >   https://www.stat.math.ethz.ch/pipermail/r-help/2005-October/078653.html
> >   https://www.stat.math.ethz.ch/pipermail/r-help/2005-October/078656.html
> >
> > it seems that one had to use absolute paths and that seems to be the
> > case here too where as mkondrin pointed out earlier in this thread
> >
> >   https://www.stat.math.ethz.ch/pipermail/r-help/2005-October/078635.html
> >
> > that get.grid("myplot::xaxis::labels")$label works.
> >
> > Its not clear to me whether names:
> >
> > - must be in absolute paths
> > - can be relative to some position under some conditions
> > - are global across all grob names in use and can be referred to directly
> > as long as they are unique among all grobs defined so far.
> >
> > It seems absolute path names work but I am not sure whether the
> > other possibilities can work under some conditions too.
> >
> > Also what the scope of viewports?   Absolute path? Relative path?
> > Global names?  Does it work the same way?  I think at least
> > absolute and relative paths are avalable here but could you confirm
> > my understanding and whether the situation is the same for
> > viewports and grobs?
> >
> > (In the Windows, and analogously in UNIX, file system one can write
> > \usr\myname or position oneself to \usr using cd and then refer to
> > myname in a relative way:
> >
> > cd \usr
> > dir myname
> > )
>
>
> The distinction is not between "relative" or "absolute" paths, but
> between "strict" and "not strict" paths.
>
> Matching a path always *starts* from your current "position" (so in that
> sense it is always "relative" and never "absolute").  When working with
> viewports, there is a current viewport tree and it is possible to be in
> different positions within that tree --- via [push|down|up]Viewport()
> --- so a path may have different meanings depending on where you are.
> (The seekViewport() function is sort of absolute because it always
> starts from the root of the viewport tree, but a non-strict
> seekViewport() [see below] behaves quite differently from an absolute
> filesystem directory path.)  When working with grobs, you tend to always
> be at the "top" or "root".  You are either: working off-screen with a
> single specific grob (gTree) so you are always at the top of that gTree;
>  or working with the grid display list, in which case you have a list
> of grobs and gTrees, which are searched one after the other.
>
> The functions that take paths for grobs, such as grid.edit(), and for
> viewports, such as downViewport(), have an argument 'strict' which
> controls whether the path should be matched from the current position or
> whether the search can start from the current position and we'll match
> the path if it occurs anywhere below the current position.  (There are
> also 'grep' and 'global' arguments so you can get multiple matches where
> it makes sense.)
>
> In some cases, grid has to make use of a path on its own, without
> knowing explicitly whether the path is strict (e.g., when you specify a
> path in a 'vp' slot).  In those cases, grid interprets the path as
> strict (so that, for example, grid has some chance of undoing the
> navigation down to a viewport).
>
> Regarding uniqueness of names, all viewports *which share the same
> parent viewport* must have unique names (same for grobs).  You can,
> however, have several grobs with the same name on the display list.
> i.e., the following produces two separate grobs on the display list
>
> grid.rect(name="rect")
> grid.rect(name="rect")
>
> Does that make things any clearer?
>


That certainly helps although some examples would be nice.

1. I understand that in the original example:

	grid.newpage()
	pushViewport(viewport(w = 0.5, h = 0.5))
	myplot <- gTree(name = "myplot",
	  children = gList(rectGrob(name = "box", gp = gpar(col = "grey")),
		  xaxisGrob(name = "xaxis")))
	grid.draw(myplot)
	grid.edit("myplot::xaxis", at = 1:10/11)
	grid.edit("myplot::xaxis::labels", label = round(1:10/11, 2))
	grid.edit("myplot::xaxis::labels", y = unit(-1, "lines"))

we can do this:

	grid.get("myplot::xaxis::labels")$label

and without specifying complete paths it can be done like this:

	get.grid("labels")$label

so I am ok on this one.


2.  But going back to:

 https://www.stat.math.ethz.ch/pipermail/r-help/2005-October/078653.html
 https://www.stat.math.ethz.ch/pipermail/r-help/2005-October/078656.html

I see you mention that vp= is always strict so is there a way to
do this somehow:

library(grid)
vp <- vpTree(
	viewport(layout=grid.layout(2,2), name="layout"),
	children=vpList(
		viewport(layout.pos.col = 1, layout.pos.row=1, name="tl"),
		viewport(layout.pos.col = 2, layout.pos.row=2, name="br")
	)
)

grobs <- gList(
	rectGrob(vp=vpPath("layout","tl")),
	textGrob("Top left", vp=vpPath("layout","tl")),
	textGrob("Bottom right", vp=vpPath("layout","br"))
)

grid.draw(gTree(childrenvp=vp, children = grobs))

without repeating "layout" three times in the definition of the
grobs object?



From jfox at mcmaster.ca  Wed Oct  5 03:18:56 2005
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 4 Oct 2005 21:18:56 -0400
Subject: [R] Rcmdr and scatter3d
In-Reply-To: <51936.129.116.71.233.1128467579.squirrel@129.116.71.233>
Message-ID: <20051005011855.GJVD28424.tomts25-srv.bellnexxia.net@JohnDesktop8300>

Dear Naiara,

Combine the data sets and differentiate among them with a factor. Then use
the groups argument to scatter3d (see ?scatter3d). If you're using the R
Commander to make the plot, the 3D scatterplot dialog box as a plot by
groups button. You can also fit colour-coded regression surfaces by group.

I've appended a new version of the scatter3d function, not yet in the Rcmdr
package, which will also plot data ellipsoids (for the whole data set or by
groups).

I hope this helps,
 John

----------- snip --------------

ellipsoid <- function(center=c(0, 0, 0), radius=1, shape=diag(3), n=30){
# adapted from the shapes3d demo in the rgl package
  degvec <- seq(0, 2*pi, length=n)
  ecoord2 <- function(p) c(cos(p[1])*sin(p[2]), sin(p[1])*sin(p[2]),
cos(p[2]))
  v <- t(apply(expand.grid(degvec,degvec), 1, ecoord2))
  v <- center + radius * t(v %*% chol(shape))
  v <- rbind(v, rep(1,ncol(v))) 
  e <- expand.grid(1:(n-1), 1:n)
  i1 <- apply(e, 1, function(z) z[1] + n*(z[2] - 1))
  i2 <- i1 + 1
  i3 <- (i1 + n - 1) %% n^2 + 1
  i4 <- (i2 + n - 1) %% n^2 + 1
  i <- rbind(i1, i2, i4, i3)
  qmesh3d(v, i)
  }

scatter3d <- function(x, y, z, xlab=deparse(substitute(x)),
ylab=deparse(substitute(y)),
    zlab=deparse(substitute(z)), revolutions=0, bg.col=c("white", "black"), 
    axis.col=if (bg.col == "white") "black" else "white",
    surface.col=c("blue", "green", "orange", "magenta", "cyan", "red",
"yellow", "gray"),
    neg.res.col="red", pos.res.col="green", point.col="yellow",
    text.col=axis.col, grid.col=if (bg.col == "white") "black" else "gray",
    fogtype=c("exp2", "linear", "exp", "none"),
    residuals=(length(fit) == 1), surface=TRUE, fill=TRUE, grid=TRUE,
grid.lines=26,
    df.smooth=NULL, df.additive=NULL,
    sphere.size=1, threshold=0.01, speed=1, fov=60,
    fit="linear", groups=NULL, parallel=TRUE, ellipsoid=FALSE, level=0.5, 
    model.summary=FALSE){
    require(rgl)
    require(mgcv)
    summaries <- list()
    if ((!is.null(groups)) && (nlevels(groups) > length(surface.col))) 
        stop(sprintf(
            gettextRcmdr("Number of groups (%d) exceeds number of colors
(%d)."),
            nlevels(groups), length(surface.col)))
    if ((!is.null(groups)) && (!is.factor(groups))) 
        stop(gettextRcmdr("groups variable must be a factor."))
    bg.col <- match.arg(bg.col)
    fogtype <- match.arg(fogtype)
    if ((length(fit) > 1) && residuals && surface)
        stop(gettextRcmdr("cannot plot both multiple surfaces and
residuals"))
    xlab  # cause these arguments to be evaluated
    ylab
    zlab
    rgl.clear()
    rgl.viewpoint(fov=fov)
    rgl.bg(col=bg.col, fogtype=fogtype)
    valid <- if (is.null(groups)) complete.cases(x, y, z)
        else complete.cases(x, y, z, groups)
    x <- x[valid]
    y <- y[valid]
    z <- z[valid]
    if (!is.null(groups)) groups <- groups[valid]
    x <- (x - min(x))/(max(x) - min(x))
    y <- (y - min(y))/(max(y) - min(y))
    z <- (z - min(z))/(max(z) - min(z))
    size <- sphere.size*((100/length(x))^(1/3))*0.015
    if (is.null(groups)){
        if (size > threshold) rgl.spheres(x, y, z, color=point.col,
radius=size)
            else rgl.points(x, y, z, color=point.col)
            }
    else {
        if (size > threshold) rgl.spheres(x, y, z, 
            color=surface.col[as.numeric(groups)], radius=size)
        else rgl.points(x, y, z, color=surface.col[as.numeric(groups)])
        }
    rgl.lines(c(0,1), c(0,0), c(0,0), color=axis.col)
    rgl.lines(c(0,0), c(0,1), c(0,0), color=axis.col)
    rgl.lines(c(0,0), c(0,0), c(0,1), color=axis.col)
    rgl.texts(1, 0, 0, xlab, adj=1, color=text.col)
    rgl.texts(0, 1, 0, ylab, adj=1, color=text.col)
    rgl.texts(0, 0, 1, zlab, adj=1, color=text.col)
    if (ellipsoid) {
        dfn <- 3
        if (is.null(groups)){
            dfd <- length(x) - 1
            radius <- sqrt(dfn * qf(level, dfn, dfd))
            ellips <- ellipsoid(center=c(mean(x), mean(y), mean(z)), 
                shape=cov(cbind(x,y,z)), radius=radius)
            if (fill) shade3d(ellips, col=surface.col[1], alpha=0.1,
lit=FALSE)
            if (grid) wire3d(ellips, col=surface.col[1], lit=FALSE)
            }
        else{
            levs <- levels(groups)
            for (j in 1:length(levs)){
                group <- levs[j]
                select.obs <- groups == group
                xx <- x[select.obs]
                yy <- y[select.obs]
                zz <- z[select.obs]
                dfd <- length(xx) - 1
                radius <- sqrt(dfn * qf(level, dfn, dfd))
                ellips <- ellipsoid(center=c(mean(xx), mean(yy), mean(zz)), 
                    shape=cov(cbind(xx,yy,zz)), radius=radius)
                if (fill) shade3d(ellips, col=surface.col[j], alpha=0.1,
lit=FALSE)
                if (grid) wire3d(ellips, col=surface.col[j], lit=FALSE)
                coords <- ellips$vb[, which.max(ellips$vb[1,])]
                if (!surface) rgl.texts(coords[1] + 0.05, coords[2],
coords[3], group, 
                    col=surface.col[j])
                }
            }
        }               
    if (surface){
        vals <- seq(0, 1, length=grid.lines)
        dat <- expand.grid(x=vals, z=vals)
        for (i in 1:length(fit)){
            f <- match.arg(fit[i], c("linear", "quadratic", "smooth",
"additive"))
            if (is.null(groups)){
                mod <- switch(f,
                    linear = lm(y ~ x + z),
                    quadratic = lm(y ~ (x + z)^2 + I(x^2) + I(z^2)),
                    smooth = if (is.null(df.smooth)) gam(y ~ s(x, z))
                        else gam(y ~ s(x, z, fx=TRUE, k=df.smooth)),
                    additive = if (is.null(df.additive)) gam(y ~ s(x) +
s(z))
                        else gam(y ~ s(x, fx=TRUE, k=df.additive[1]+1) +
                            s(z, fx=TRUE, k=(rev(df.additive+1)[1]+1)))
                    )
                if (model.summary) summaries[[f]] <- summary(mod)
                yhat <- matrix(predict(mod, newdata=dat), grid.lines,
grid.lines)
                if (fill) rgl.surface(vals, vals, yhat,
color=surface.col[i], 
                    alpha=0.5, lit=FALSE)
                if(grid) rgl.surface(vals, vals, yhat, color=if (fill)
grid.col 
                    else surface.col[i], alpha=0.5, lit=FALSE,
front="lines", back="lines")
                if (residuals){
                    n <- length(y)
                    fitted <- fitted(mod)
                    colors <- ifelse(residuals(mod) > 0, pos.res.col,
neg.res.col)
                    rgl.lines(as.vector(rbind(x,x)),
as.vector(rbind(y,fitted)), 
                        as.vector(rbind(z,z)),
color=as.vector(rbind(colors,colors)))
                    }
                }
            else{
                if (parallel){
                    mod <- switch(f,
                        linear = lm(y ~ x + z + groups),
                        quadratic = lm(y ~ (x + z)^2 + I(x^2) + I(z^2) +
groups),
                        smooth = if (is.null(df.smooth)) gam(y ~ s(x, z) +
groups)
                            else gam(y ~ s(x, z, fx=TRUE, k=df.smooth) +
groups),
                        additive = if (is.null(df.additive)) gam(y ~ s(x) +
s(z) + groups)
                            else gam(y ~ s(x, fx=TRUE, k=df.additive[1]+1) +
                                s(z, fx=TRUE, k=(rev(df.additive+1)[1]+1)) +
groups)
                        )
                    if (model.summary) summaries[[f]] <- summary(mod)
                    levs <- levels(groups)
                    for (j in 1:length(levs)){
                        group <- levs[j]
                        select.obs <- groups == group
                        yhat <- matrix(predict(mod, newdata=cbind(dat,
groups=group)), 
                            grid.lines, grid.lines)
                        if (fill) rgl.surface(vals, vals, yhat,
color=surface.col[j], 
                            alpha=0.5, lit=FALSE)
                        if (grid) rgl.surface(vals, vals, yhat, color=if
(fill) grid.col 
                            else surface.col[j], alpha=0.5, lit=FALSE, 
                                front="lines", back="lines")
                        rgl.texts(0, predict(mod, newdata=data.frame(x=0,
z=0, 
                            groups=group)), 0,
                            paste(group, " "), adj=1, color=surface.col[j])
                        if (residuals){
                            yy <- y[select.obs]
                            xx <- x[select.obs]
                            zz <- z[select.obs]
                            fitted <- fitted(mod)[select.obs]
                            rgl.lines(as.vector(rbind(xx,xx)), 
                                as.vector(rbind(yy,fitted)),
as.vector(rbind(zz,zz)),
                                col=surface.col[j])
                            }
                        }
                    }
                else {
                    levs <- levels(groups)
                    for (j in 1:length(levs)){
                        group <- levs[j]
                        select.obs <- groups == group
                        mod <- switch(f,
                            linear = lm(y ~ x + z, subset=select.obs),
                            quadratic = lm(y ~ (x + z)^2 + I(x^2) + I(z^2), 
                                    subset=select.obs),
                            smooth = if (is.null(df.smooth)) gam(y ~ s(x,
z), 
                                    subset=select.obs)
                                else gam(y ~ s(x, z, fx=TRUE, k=df.smooth), 
                                    subset=select.obs),
                            additive = if (is.null(df.additive)) gam(y ~
s(x) + s(z), 
                                    subset=select.obs)
                                else gam(y ~ s(x, fx=TRUE,
k=df.additive[1]+1) +
                                    s(z, fx=TRUE,
k=(rev(df.additive+1)[1]+1)), 
                                    subset=select.obs)
                            )
                        if (model.summary) 
                            summaries[[paste(f, ".", group, sep="")]] <-
summary(mod)
                        yhat <- matrix(predict(mod, newdata=dat),
grid.lines, grid.lines)
                        if (fill) rgl.surface(vals, vals, yhat,
color=surface.col[j], 
                            alpha=0.5, lit=FALSE)
                        if (grid) rgl.surface(vals, vals, yhat, color=if
(fill) grid.col 
                            else surface.col[j], alpha=0.5, lit=FALSE, 
                                front="lines", back="lines")
                        rgl.texts(0, predict(mod, 
                            newdata=data.frame(x=0, z=0, groups=group)), 0,
                            paste(group, " "), adj=1, color=surface.col[j])
                        if (residuals){
                            yy <- y[select.obs]
                            xx <- x[select.obs]
                            zz <- z[select.obs]
                            fitted <- fitted(mod)
                            rgl.lines(as.vector(rbind(xx,xx)),
as.vector(rbind(yy,fitted)), 
                                as.vector(rbind(zz,zz)),
                                col=surface.col[j])
                            }
                        }
                    }
                }
            }
        }
    if (revolutions > 0) {
        for (i in 1:revolutions){
            for (angle in seq(1, 360, length=360/speed))
rgl.viewpoint(-angle, fov=fov)
            }
        }
    if (model.summary) return(summaries) else return(invisible(NULL))
    }


--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Naiara S. Pinto
> Sent: Tuesday, October 04, 2005 6:13 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Rcmdr and scatter3d
> 
> Hi folks,
> 
> I'd like to use scatter3d (which is in R commander) to plot 
> more than one dataset in the same graph, each dataset with a 
> different color. The kind of stuff you would do with "holdon" 
> in Matlab.
> 
> I read a recent message that was posted to this list with a 
> similar problem, but I couldn't understand the reply. Could 
> someone give me one example? How do you plot subgroups using 
> scatter3d?
> 
> Thanks a lot!
> 
> Naiara.
> 
> 
> --------------------------------------------
> Naiara S. Pinto
> Ecology, Evolution and Behavior
> 1 University Station A6700
> Austin, TX, 78712
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From edd at debian.org  Wed Oct  5 03:31:51 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 4 Oct 2005 20:31:51 -0500
Subject: [R] TRAMO-SEATS methodology
In-Reply-To: <4342E792.9070207@censix.com>
References: <4342E792.9070207@censix.com>
Message-ID: <17219.11527.394789.676152@basebud.nulle.part>


On 4 October 2005 at 22:35, Soren Wilkening wrote:
| Dear Colleagues
| 
| would someone know a suitable online-source for information
| regarding the TRAMO SEATS method for time series ?
| (an alternative to X12 ARIMA and earlier ARIMAs used by the US census 
| bureau)

Google is your friend -- It's been a while but the last time I looked I found
documents both at the Bank of Spain's website (where A Maravall is or was)
and as I recall some code at EuroStat (by former students of his).

Also, Gretl has an interface to tramo-seats. See
http://gretl.sourceforge.net/tramo/tramo-seats.html

Gruesse, Dirk

-- 
Statistics: The (futile) attempt to offer certainty about uncertainty.
         -- Roger Koenker, 'Dictionary of Received Ideas of Statistics'



From p.murrell at auckland.ac.nz  Wed Oct  5 03:50:13 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 05 Oct 2005 14:50:13 +1300
Subject: [R] grob questions
References: <971536df0510022237v7b91c484g2cb998321d192d5b@mail.gmail.com>	
	<4342D96F.1020907@stat.auckland.ac.nz>	
	<971536df0510041305t2ca9fb1fk51099dc92e6d70e3@mail.gmail.com>	
	<4342EB08.2060403@stat.auckland.ac.nz>
	<971536df0510041732n19b099bidba8e17a8f98c77e@mail.gmail.com>
Message-ID: <43433155.6020307@stat.auckland.ac.nz>

Hi


Gabor Grothendieck wrote:
> On 10/4/05, Paul Murrell <p.murrell at auckland.ac.nz> wrote:
> 
>>Hi
>>
>>
>>Gabor Grothendieck wrote:
>>
>>>On 10/4/05, Paul Murrell <p.murrell at auckland.ac.nz> wrote:
>>>
>>>
>>>>Hi
>>>>
>>>>
>>>>Gabor Grothendieck wrote:
>>>>
>>>>
>>>>>If I run the following example from:
>>>>>http://www.stat.auckland.ac.nz/~paul/grid/doc/grobs.pdf
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>>grid.newpage()
>>>>>>pushViewport(viewport(w = 0.5, h = 0.5))
>>>>>>myplot <- gTree(name = "myplot", children = gList(rectGrob(name = "box",
>>>>>
>>>>>+ gp = gpar(col = "grey")), xaxisGrob(name = "xaxis")))
>>>>>
>>>>>
>>>>>
>>>>>>grid.draw(myplot)
>>>>>>grid.edit("myplot::xaxis", at = 1:10/11)
>>>>>>grid.edit("myplot::xaxis::labels", label = round(1:10/11, 2))
>>>>>>grid.edit("myplot::xaxis::labels", y = unit(-1, "lines"))
>>>>>
>>>>>
>>>>>then
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>>str(myplot$children$xaxis)
>>>>>
>>>>>
>>>>>lists 'at' but not the 'labels'.
>>>>>
>>>>>yet if I do this then the labels are listed:
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>>xx <- xaxisGrob(name = "myX", at = 1:10)
>>>>>>childNames(xx)
>>>>>
>>>>>[1] "major"  "ticks"  "labels"
>>>>>
>>>>>
>>>>>1. How do I get to labels in the first case?
>>>>
>>>>
>>>>First, if the xaxisGrob has at=NULL then it calculates its tick-marks at
>>>>drawing time (based on the viewport it gets drawn in).  So it does not
>>>>store any labels (it doesn't know what they are until it gets drawn). If
>>>>you specify a non-NULL 'at' then the axis creates labels.
>>>>
>>>>Second, grid grobs are standard R objects (copy-on-modify) so the object
>>>>'myplot' is not the same object that is being modified by the calls to
>>>>grid.edit().  grid.edit() destructively modifies a copy of the grob that
>>>>grid has stored on its display list;  you refer to the appropriate grob
>>>>via its name (not via an R object).  By comparison, editGrob() takes a
>>>>grob and returns a modified copy of the grob, for example ...
>>>
>>>
>>>Just one clarification.  What is the scope of names?
>>>In a recent post
>>>
>>>  https://www.stat.math.ethz.ch/pipermail/r-help/2005-October/078653.html
>>>  https://www.stat.math.ethz.ch/pipermail/r-help/2005-October/078656.html
>>>
>>>it seems that one had to use absolute paths and that seems to be the
>>>case here too where as mkondrin pointed out earlier in this thread
>>>
>>>  https://www.stat.math.ethz.ch/pipermail/r-help/2005-October/078635.html
>>>
>>>that get.grid("myplot::xaxis::labels")$label works.
>>>
>>>Its not clear to me whether names:
>>>
>>>- must be in absolute paths
>>>- can be relative to some position under some conditions
>>>- are global across all grob names in use and can be referred to directly
>>>as long as they are unique among all grobs defined so far.
>>>
>>>It seems absolute path names work but I am not sure whether the
>>>other possibilities can work under some conditions too.
>>>
>>>Also what the scope of viewports?   Absolute path? Relative path?
>>>Global names?  Does it work the same way?  I think at least
>>>absolute and relative paths are avalable here but could you confirm
>>>my understanding and whether the situation is the same for
>>>viewports and grobs?
>>>
>>>(In the Windows, and analogously in UNIX, file system one can write
>>>\usr\myname or position oneself to \usr using cd and then refer to
>>>myname in a relative way:
>>>
>>>cd \usr
>>>dir myname
>>>)
>>
>>
>>The distinction is not between "relative" or "absolute" paths, but
>>between "strict" and "not strict" paths.
>>
>>Matching a path always *starts* from your current "position" (so in that
>>sense it is always "relative" and never "absolute").  When working with
>>viewports, there is a current viewport tree and it is possible to be in
>>different positions within that tree --- via [push|down|up]Viewport()
>>--- so a path may have different meanings depending on where you are.
>>(The seekViewport() function is sort of absolute because it always
>>starts from the root of the viewport tree, but a non-strict
>>seekViewport() [see below] behaves quite differently from an absolute
>>filesystem directory path.)  When working with grobs, you tend to always
>>be at the "top" or "root".  You are either: working off-screen with a
>>single specific grob (gTree) so you are always at the top of that gTree;
>> or working with the grid display list, in which case you have a list
>>of grobs and gTrees, which are searched one after the other.
>>
>>The functions that take paths for grobs, such as grid.edit(), and for
>>viewports, such as downViewport(), have an argument 'strict' which
>>controls whether the path should be matched from the current position or
>>whether the search can start from the current position and we'll match
>>the path if it occurs anywhere below the current position.  (There are
>>also 'grep' and 'global' arguments so you can get multiple matches where
>>it makes sense.)
>>
>>In some cases, grid has to make use of a path on its own, without
>>knowing explicitly whether the path is strict (e.g., when you specify a
>>path in a 'vp' slot).  In those cases, grid interprets the path as
>>strict (so that, for example, grid has some chance of undoing the
>>navigation down to a viewport).
>>
>>Regarding uniqueness of names, all viewports *which share the same
>>parent viewport* must have unique names (same for grobs).  You can,
>>however, have several grobs with the same name on the display list.
>>i.e., the following produces two separate grobs on the display list
>>
>>grid.rect(name="rect")
>>grid.rect(name="rect")
>>
>>Does that make things any clearer?
>>
> 
> 
> 
> That certainly helps although some examples would be nice.
> 
> 1. I understand that in the original example:
> 
> 	grid.newpage()
> 	pushViewport(viewport(w = 0.5, h = 0.5))
> 	myplot <- gTree(name = "myplot",
> 	  children = gList(rectGrob(name = "box", gp = gpar(col = "grey")),
> 		  xaxisGrob(name = "xaxis")))
> 	grid.draw(myplot)
> 	grid.edit("myplot::xaxis", at = 1:10/11)
> 	grid.edit("myplot::xaxis::labels", label = round(1:10/11, 2))
> 	grid.edit("myplot::xaxis::labels", y = unit(-1, "lines"))
> 
> we can do this:
> 
> 	grid.get("myplot::xaxis::labels")$label
> 
> and without specifying complete paths it can be done like this:
> 
> 	get.grid("labels")$label
> 
> so I am ok on this one.
> 
> 
> 2.  But going back to:
> 
>  https://www.stat.math.ethz.ch/pipermail/r-help/2005-October/078653.html
>  https://www.stat.math.ethz.ch/pipermail/r-help/2005-October/078656.html
> 
> I see you mention that vp= is always strict so is there a way to
> do this somehow:
> 
> library(grid)
> vp <- vpTree(
> 	viewport(layout=grid.layout(2,2), name="layout"),
> 	children=vpList(
> 		viewport(layout.pos.col = 1, layout.pos.row=1, name="tl"),
> 		viewport(layout.pos.col = 2, layout.pos.row=2, name="br")
> 	)
> )
> 
> grobs <- gList(
> 	rectGrob(vp=vpPath("layout","tl")),
> 	textGrob("Top left", vp=vpPath("layout","tl")),
> 	textGrob("Bottom right", vp=vpPath("layout","br"))
> )
> 
> grid.draw(gTree(childrenvp=vp, children = grobs))
> 
> without repeating "layout" three times in the definition of the
> grobs object?


How about ... ?

vptop <- viewport(layout=grid.layout(2,2), name="layout")
vpbelow <- vpList(viewport(layout.pos.col = 1,
                            layout.pos.row=1, name="tl"),
                   viewport(layout.pos.col = 2,
                            layout.pos.row=2, name="br"))

grobs <- gTree(childrenvp=vptop,
                children=gList(gTree(vp="layout",
                  childrenvp=vpbelow,
                  children=gList(
                    rectGrob(vp="tl"),
                    textGrob("Top left", vp="tl"),
                    textGrob("Bottom right", vp="br")))))

grid.draw(grobs)

... or ... ?

vp <- vpTree(viewport(layout=grid.layout(2,2), name="layout"),
              children=
              vpList(viewport(layout.pos.col = 1,
                              layout.pos.row=1, name="tl"),
                     viewport(layout.pos.col = 2,
                              layout.pos.row=2, name="br")))

grobs <- gTree(childrenvp=vp,
                children=gList(gTree(vp="layout",
                  children=gList(
                    rectGrob(vp="tl"),
                    textGrob("Top left", vp="tl"),
                    textGrob("Bottom right", vp="br")))))

grid.draw(grobs)

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From e.catchpole at adfa.edu.au  Wed Oct  5 03:55:13 2005
From: e.catchpole at adfa.edu.au (ecatchpole)
Date: Wed, 05 Oct 2005 11:55:13 +1000
Subject: [R] Rcmdr and scatter3d
In-Reply-To: <20051005011855.GJVD28424.tomts25-srv.bellnexxia.net@JohnDesktop8300>
References: <20051005011855.GJVD28424.tomts25-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <43433281.6050609@adfa.edu.au>

Niara,

Alternatively, instead of scatter3d, the analogy to "hold on" in Matlab 
is to use plot() for the first set of data, then points() for the 
remainder. See

?plot
?points

Ted.

On 05/10/05 11:18,  John Fox wrote,:
> Dear Naiara,
> 
> Combine the data sets and differentiate among them with a factor. Then use
> the groups argument to scatter3d (see ?scatter3d). If you're using the R
> Commander to make the plot, the 3D scatterplot dialog box as a plot by
> groups button. You can also fit colour-coded regression surfaces by group.
> 
> I've appended a new version of the scatter3d function, not yet in the Rcmdr
> package, which will also plot data ellipsoids (for the whole data set or by
> groups).
> 
> I hope this helps,
>  John
> 
> ----------- snip --------------

> --------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> 905-525-9140x23604
> http://socserv.mcmaster.ca/jfox 
> -------------------------------- 
> 
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch 
>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Naiara S. Pinto
>>Sent: Tuesday, October 04, 2005 6:13 PM
>>To: r-help at stat.math.ethz.ch
>>Subject: [R] Rcmdr and scatter3d
>>
>>Hi folks,
>>
>>I'd like to use scatter3d (which is in R commander) to plot 
>>more than one dataset in the same graph, each dataset with a 
>>different color. The kind of stuff you would do with "holdon" 
>>in Matlab.
>>
>>I read a recent message that was posted to this list with a 
>>similar problem, but I couldn't understand the reply. Could 
>>someone give me one example? How do you plot subgroups using 
>>scatter3d?
>>
>>Thanks a lot!
>>
>>Naiara.
>>
>>
>>--------------------------------------------
>>Naiara S. Pinto
>>Ecology, Evolution and Behavior
>>1 University Station A6700
>>Austin, TX, 78712
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Dr E.A. Catchpole
Visiting Fellow
Univ of New South Wales at ADFA, Canberra, Australia
and University of Kent, Canterbury, England
- www.ma.adfa.edu.au/~eac
- fax: +61 2 6268 8786		
- ph:  +61 2 6268 8895



From E.Catchpole at adfa.edu.au  Wed Oct  5 04:13:15 2005
From: E.Catchpole at adfa.edu.au (ecatchpole)
Date: Wed, 05 Oct 2005 12:13:15 +1000
Subject: [R] sampling vectors
In-Reply-To: <592E8923DB6EA348BE8E33FCAADEFFFC13EED7CF@dshs-exch2.dshs.wa.lcl>
References: <592E8923DB6EA348BE8E33FCAADEFFFC13EED7CF@dshs-exch2.dshs.wa.lcl>
Message-ID: <434336BB.5070705@adfa.edu.au>

Eric,

Following on from Ravi's suggestion, try

ex <- c(30,13,9,8,7,7,7,6,6,5,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1)
tot <- sum(ex)
N <- length(ex)
rmultinom(n=3, size=tot, prob=rep(1,N))

Ted.

On 05/10/05 06:07,  Nordlund, Dan wrote,:
> Eric,
> 
> 
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-
>>bounces at stat.math.ethz.ch] On Behalf Of Eric Pante
>>Sent: Tuesday, October 04, 2005 8:47 AM
>>To: Daniel Nordlund
>>Cc: r-help at stat.math.ethz.ch
>>Subject: Re: [R] sampling vectors
>>
>>Hi Dan,
>>
>>I just tried your code with long vectors, and the sampling stops to be
>>random. Do you see any reason why this is ?
>>
>>examples:
>>
>>ex = c(30,13,9,8,7,7,7,6,6,5,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1)
>>
>> > vectorSample(ex)
>>  [1]  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  3  1  7
>>6
>>[24]  4  2 75
>> > vectorSample(ex)
>>  [1]  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  1  1  1  2
>>11
>>[24]  7  8 67
>> >
> 
> Eric,
> 
> Probably because I failed to provide a complete solution.  I had a couple
> questions while I was writing this that I didn't get clarified. One, the
> code needs to be slightly modified if you want to allow vector elements to
> be zero.  I required each element to be >= 1.  Two, I did not reorder the
> elements in the vector.  Larger counts are more likely early in the process
> than late in the process (since the partial sum is approaching the original
> total).  I just placed the counts in the vector result in reverse order of
> when they were obtained.
> 
> The fix to the "randomness" is simple.  Just return sample(v) instead of v
> as the function result (see below).  If you want to allow zero elements I
> think you can just change the lower limit on the sampling to be 0 rather
> than 1 (not thoroughly tested)
> 
> vectorSample <- function(vec) {
>   tot<-sum(vec)
>   Len<-length(vec)
>   v <-rep(0,Len)
>   for(i in Len:2) {
>     UL <- tot - sum(v) - i + 1
>     v[i]<-sample(1:UL,1) 
>     #change preceding statement to 
>     #    v[i]<-sample(0:UL,1)
>     #if you want to allow zeros
>     }
>   v[1] <- tot - sum(v)
>   sample(v) #return vector in random order
>   }
> 
> Dan Nordlund
> Bothell, WA
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Dr E.A. Catchpole
Visiting Fellow
Univ of New South Wales at ADFA, Canberra, Australia
and University of Kent, Canterbury, England
- www.ma.adfa.edu.au/~eac
- fax: +61 2 6268 8786		
- ph:  +61 2 6268 8895



From uttam.phulwale at tcs.com  Wed Oct  5 08:28:56 2005
From: uttam.phulwale at tcs.com (uttam.phulwale@tcs.com)
Date: Wed, 5 Oct 2005 11:58:56 +0530
Subject: [R] prediction with nnet function for regression in R
Message-ID: <OF0FEF0117.A08C63DE-ON65257091.0022BF72-65257091.00232A42@tcs.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051005/de1e40b7/attachment.pl

From ripley at stats.ox.ac.uk  Wed Oct  5 08:44:24 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 Oct 2005 07:44:24 +0100 (BST)
Subject: [R] prediction with nnet function for regression in R
In-Reply-To: <OF0FEF0117.A08C63DE-ON65257091.0022BF72-65257091.00232A42@tcs.com>
References: <OF0FEF0117.A08C63DE-ON65257091.0022BF72-65257091.00232A42@tcs.com>
Message-ID: <Pine.LNX.4.61.0510050742430.21395@gannet.stats>

On Wed, 5 Oct 2005 uttam.phulwale at tcs.com wrote:

>
> Hi,
> Good Day Everybody.....
> Can anybody help me....
> I am working with R ...and i am using nnet() function for regression, but
> after trained model, i m getting all predictions as 0.999999 or 1.0000,
> why is so, i dont understand?

As a guess, you failed to specify linear output units.  But as you have 
not shown us what you did do, we can only guess.

> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

please do.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From lozalojo at jcyl.es  Wed Oct  5 10:02:32 2005
From: lozalojo at jcyl.es (=?iso-8859-1?Q?Jos=E9_Eugenio_Lozano_Alonso?=)
Date: Wed, 5 Oct 2005 10:02:32 +0200
Subject: [R] Advice on Spatial Statistics
Message-ID: <000001c5c983$23f78550$77a5100a@JSNSC52P418>


Hello,

I have point spatial information (information linked to points on a
map), and I'd like to make inferences on the full extent of my zone. I
know the Kriging method, but I also know that it seems to be obsolete
and new approaches have been given.

I'd appreciate any advice on readings about all these methods on Spatial
Statistics, books, papers or articles.

Thanks in advance,
Jose Lozano



From lami at faunalia.it  Wed Oct  5 10:06:34 2005
From: lami at faunalia.it (Leonardo Lami)
Date: Wed, 5 Oct 2005 10:06:34 +0200
Subject: [R] Fisher's discriminant functions
In-Reply-To: <433C4CE8.20106@redcotel.bo>
References: <20050929150455.24592.qmail@web25411.mail.ukl.yahoo.com>
	<433C4CE8.20106@redcotel.bo>
Message-ID: <200510051006.34782.lami@faunalia.it>

Hi,
I have the same problem.
I found a solution but I think there is something of more simple and correct.

I take a group and I put 0 the values of the other group, after I use the 
function "glm" to abtain the  Fisher's discriminant function for this group.
I repeat the same for all the groups.

Some times ago i try to make the same query but without results.

Best wishes
Leonardo

Alle 22:22, gioved?? 29 settembre 2005, Kjetil Holuerson ha scritto:
> This are in various packages, you could have a look at
> ade4 (on CRAN).
>
> Kjetil
>
> C NL wrote:
> > Hi everyone,
> >
> >   I'm trying to solve a problem about how to get the
> > Fisher's discriminant functions of a "lda" (linear
> > discriminant analysis) object, I mean, the object
> > obtained from doing "lda(formula, data)" function of
> > the package MASS in R-project. This object gives me
> > the canonical linear functions (n-1 coefficients
> > matrix of n groups at least), and only with this
> > information I could predict the group of an
> > observation data using the "predict" function. But
> > what I need is the Fisher's discriminant functions (n
> > coefficients matrix of n groups) in order to classify
> > my future data.
> >
> >    The object "predict" gives me only the following
> > attributes "x", "posterior" and "class", but none of
> > them are the coefficients matrix of the Fisher's
> > discriminant functions, and the reason why I'm not
> > using the "predict" function for my predictions is
> > because the time spent is very high for what I'm
> > expecting, about 0.5 seconds while I can obtain this
> > prediction with the Fisher's discriminant functions
> > faster.
> >
> >    So, I don't know if there's a package which I can
> > use to obtain the mentioned coefficients matrix of the
> > Fisher's discriminant functions.
> >
> >    I anyone can help, I would appreciate it greatly.
> >
> > Thank you and regards.
> >
> >    Carlos Niharra L??pez
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
>
> --
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
Leonardo Lami
lami at faunalia.it            www.faunalia.it
Via Colombo 3 - 51010 Massa e Cozzile (PT), Italy   Tel: (+39)349-1310164
GPG key @: hkp://wwwkeys.pgp.net http://www.pgp.net/wwwkeys.html
https://www.biglumber.com



From jonathan.williams at pharmacology.oxford.ac.uk  Wed Oct  5 11:46:54 2005
From: jonathan.williams at pharmacology.oxford.ac.uk (Jonathan Williams)
Date: Wed, 5 Oct 2005 10:46:54 +0100
Subject: [R] problem accumulating array within a function over loops
Message-ID: <NGBBKJEMOMLJFCOIEGCECEIAJOAA.jonathan.williams@pharm.ox.ac.uk>

Dear R helpers,

I am having trouble with an array inside a loop.

I wish to accumulate the results of a function in an array within
the function, over several loops of a program outside the function.

The problem is that the array seems to re-set at every entry to the
function. Here is an example, so you can see what I mean.

########################################################################
#First, I declare the array and loop control variables
maxrun=3; a=array(NA, c(3,5)); run=0

# Then I define the function "testf"
testf=function(x,y){
print(paste('Run:',run)) #check that the function knows about "run"
a[run,1:3]=runif(3); a[run,4]=x; a[run,5]=y #collect numbers into array "a"
print(paste("Row", run, "of a:")); print(a[run,]) #check what row 'run' of
"a" contains
print("Whole of a:"); print(a) # check what all of "a" contains
}

#Finally, I loop through "testf" maxrun occasions
for (run in 1:maxrun) testf(run,run*10)
#########################################################################

Here is the output:-

[1] "Run: 1"
[1] "Row 1 of a:"
[1]  0.4637560  0.8872455  0.6421500  1.0000000 10.0000000
[1] "Whole of a:"
          [,1]      [,2]    [,3] [,4] [,5]
[1,] 0.4637560 0.8872455 0.64215    1   10
[2,]        NA        NA      NA   NA   NA
[3,]        NA        NA      NA   NA   NA
[1] "Run: 2"
[1] "Row 2 of a:"
[1]  0.4841261  0.8835118  0.9862266  2.0000000 20.0000000
[1] "Whole of a:"
          [,1]      [,2]      [,3] [,4] [,5]
[1,]        NA        NA        NA   NA   NA
[2,] 0.4841261 0.8835118 0.9862266    2   20
[3,]        NA        NA        NA   NA   NA
[1] "Run: 3"
[1] "Row 3 of a:"
[1]  0.7638856  0.6667588  0.6102928  3.0000000 30.0000000
[1] "Whole of a:"
          [,1]      [,2]      [,3] [,4] [,5]
[1,]        NA        NA        NA   NA   NA
[2,]        NA        NA        NA   NA   NA
[3,] 0.7638856 0.6667588 0.6102928    3   30

You can see that array a correctly collects the numbers at each loop.
But, each successive loop loses the contents of previous loops. I am
hoping to keep the results of each successive loop in "a", so that
after maxrun runs, "a" looks like:-

          [,1]      [,2]    [,3]   [,4] [,5]
[1,] 0.4637560 0.8872455 0.64215      1   10
[2,] 0.4841261 0.8835118 0.9862266    2   20
[3,] 0.7638856 0.6667588 0.6102928    3   30

(I have made this by cutting and pasting from the above output, to show
what I hoped testf would produce).

I am sure I must be making a simple but fundamental error. Would
someone be so kind as to show me what this is and how to correct it?
I have struggled with it for over an hour, without success!!!!!
I am running R 2.1.1 on a Windows 2000 machine.

Thanks, in advance, for your help,

Jonathan Williams



From dimitris.rizopoulos at med.kuleuven.be  Wed Oct  5 11:57:26 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Wed, 5 Oct 2005 11:57:26 +0200
Subject: [R] problem accumulating array within a function over loops
References: <NGBBKJEMOMLJFCOIEGCECEIAJOAA.jonathan.williams@pharm.ox.ac.uk>
Message-ID: <015d01c5c993$308d9dd0$0540210a@www.domain>

try it this way:

a <- array(NA, c(3, 5))
for(i in 1:nrow(a))
    a[i, ] <- c(runif(3), i, i * 10)
a


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Jonathan Williams" 
<jonathan.williams at pharmacology.oxford.ac.uk>
To: "Ethz. Ch" <r-help at stat.math.ethz.ch>
Sent: Wednesday, October 05, 2005 11:46 AM
Subject: [R] problem accumulating array within a function over loops


> Dear R helpers,
>
> I am having trouble with an array inside a loop.
>
> I wish to accumulate the results of a function in an array within
> the function, over several loops of a program outside the function.
>
> The problem is that the array seems to re-set at every entry to the
> function. Here is an example, so you can see what I mean.
>
> ########################################################################
> #First, I declare the array and loop control variables
> maxrun=3; a=array(NA, c(3,5)); run=0
>
> # Then I define the function "testf"
> testf=function(x,y){
> print(paste('Run:',run)) #check that the function knows about "run"
> a[run,1:3]=runif(3); a[run,4]=x; a[run,5]=y #collect numbers into 
> array "a"
> print(paste("Row", run, "of a:")); print(a[run,]) #check what row 
> 'run' of
> "a" contains
> print("Whole of a:"); print(a) # check what all of "a" contains
> }
>
> #Finally, I loop through "testf" maxrun occasions
> for (run in 1:maxrun) testf(run,run*10)
> #########################################################################
>
> Here is the output:-
>
> [1] "Run: 1"
> [1] "Row 1 of a:"
> [1]  0.4637560  0.8872455  0.6421500  1.0000000 10.0000000
> [1] "Whole of a:"
>          [,1]      [,2]    [,3] [,4] [,5]
> [1,] 0.4637560 0.8872455 0.64215    1   10
> [2,]        NA        NA      NA   NA   NA
> [3,]        NA        NA      NA   NA   NA
> [1] "Run: 2"
> [1] "Row 2 of a:"
> [1]  0.4841261  0.8835118  0.9862266  2.0000000 20.0000000
> [1] "Whole of a:"
>          [,1]      [,2]      [,3] [,4] [,5]
> [1,]        NA        NA        NA   NA   NA
> [2,] 0.4841261 0.8835118 0.9862266    2   20
> [3,]        NA        NA        NA   NA   NA
> [1] "Run: 3"
> [1] "Row 3 of a:"
> [1]  0.7638856  0.6667588  0.6102928  3.0000000 30.0000000
> [1] "Whole of a:"
>          [,1]      [,2]      [,3] [,4] [,5]
> [1,]        NA        NA        NA   NA   NA
> [2,]        NA        NA        NA   NA   NA
> [3,] 0.7638856 0.6667588 0.6102928    3   30
>
> You can see that array a correctly collects the numbers at each 
> loop.
> But, each successive loop loses the contents of previous loops. I am
> hoping to keep the results of each successive loop in "a", so that
> after maxrun runs, "a" looks like:-
>
>          [,1]      [,2]    [,3]   [,4] [,5]
> [1,] 0.4637560 0.8872455 0.64215      1   10
> [2,] 0.4841261 0.8835118 0.9862266    2   20
> [3,] 0.7638856 0.6667588 0.6102928    3   30
>
> (I have made this by cutting and pasting from the above output, to 
> show
> what I hoped testf would produce).
>
> I am sure I must be making a simple but fundamental error. Would
> someone be so kind as to show me what this is and how to correct it?
> I have struggled with it for over an hour, without success!!!!!
> I am running R 2.1.1 on a Windows 2000 machine.
>
> Thanks, in advance, for your help,
>
> Jonathan Williams
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From ripley at stats.ox.ac.uk  Wed Oct  5 12:03:39 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 Oct 2005 11:03:39 +0100 (BST)
Subject: [R] Fisher's discriminant functions
In-Reply-To: <200510051006.34782.lami@faunalia.it>
References: <20050929150455.24592.qmail@web25411.mail.ukl.yahoo.com>
	<433C4CE8.20106@redcotel.bo> <200510051006.34782.lami@faunalia.it>
Message-ID: <Pine.LNX.4.61.0510051055550.23906@gannet.stats>

On Wed, 5 Oct 2005, Leonardo Lami wrote:

> Hi,
> I have the same problem.
> I found a solution but I think there is something of more simple and correct.
>
> I take a group and I put 0 the values of the other group, after I use the
> function "glm" to abtain the  Fisher's discriminant function for this group.
> I repeat the same for all the groups.

Which family in glm?  There is a way to do Fisher's LDF by least-squares 
regression, but some further computations are required.  The details are 
in section 3.2 of my PRNN book.

lda() does do Fisher's discriminant function, but note Fisher only did 
this for 2 groups and 1 function.  The predict method evaluates the LDF, 
so just look at the code to see how it does it (you need to be careful 
about a lot of details to maintain accuracy).

>
> Some times ago i try to make the same query but without results.
>
> Best wishes
> Leonardo
>
> Alle 22:22, gioved? 29 settembre 2005, Kjetil Holuerson ha scritto:
>> This are in various packages, you could have a look at
>> ade4 (on CRAN).
>>
>> Kjetil
>>
>> C NL wrote:
>>> Hi everyone,
>>>
>>>   I'm trying to solve a problem about how to get the
>>> Fisher's discriminant functions of a "lda" (linear
>>> discriminant analysis) object, I mean, the object
>>> obtained from doing "lda(formula, data)" function of
>>> the package MASS in R-project. This object gives me
>>> the canonical linear functions (n-1 coefficients
>>> matrix of n groups at least), and only with this
>>> information I could predict the group of an
>>> observation data using the "predict" function. But
>>> what I need is the Fisher's discriminant functions (n
>>> coefficients matrix of n groups) in order to classify
>>> my future data.
>>>
>>>    The object "predict" gives me only the following
>>> attributes "x", "posterior" and "class", but none of
>>> them are the coefficients matrix of the Fisher's
>>> discriminant functions, and the reason why I'm not
>>> using the "predict" function for my predictions is
>>> because the time spent is very high for what I'm
>>> expecting, about 0.5 seconds while I can obtain this
>>> prediction with the Fisher's discriminant functions
>>> faster.
>>>
>>>    So, I don't know if there's a package which I can
>>> use to obtain the mentioned coefficients matrix of the
>>> Fisher's discriminant functions.
>>>
>>>    I anyone can help, I would appreciate it greatly.
>>>
>>> Thank you and regards.
>>>
>>>    Carlos Niharra L?pez
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide!
>>> http://www.R-project.org/posting-guide.html
>>
>> --
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>
> -- 
> Leonardo Lami
> lami at faunalia.it            www.faunalia.it
> Via Colombo 3 - 51010 Massa e Cozzile (PT), Italy   Tel: (+39)349-1310164
> GPG key @: hkp://wwwkeys.pgp.net http://www.pgp.net/wwwkeys.html
> https://www.biglumber.com
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From vincent at 7d4.com  Wed Oct  5 12:10:26 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Wed, 05 Oct 2005 12:10:26 +0200
Subject: [R] problem accumulating array within a function over loops
In-Reply-To: <NGBBKJEMOMLJFCOIEGCECEIAJOAA.jonathan.williams@pharm.ox.ac.uk>
References: <NGBBKJEMOMLJFCOIEGCECEIAJOAA.jonathan.williams@pharm.ox.ac.uk>
Message-ID: <4343A692.7070804@7d4.com>

Jonathan Williams a ??crit :

> maxrun=3; a=array(NA, c(3,5)); run=0
> 
> testf=function(x,y){
> print(paste('Run:',run)) #check that the function knows about "run"
> a[run,1:3]=runif(3); a[run,4]=x; a[run,5]=y #collect numbers into array "a"
> }

a outside testf is a "global variable".
a inside testf is a "local variable", ie a variable local to testf().
They are not the same.

As far as I remember, to assign a global variable from inside a
function you have to use the <-- operator.

(By the way, for 2dim arrays, there is also matrix().)

hih
Vincent



From sara at gmesintra.com  Wed Oct  5 12:16:46 2005
From: sara at gmesintra.com (Sara Mouro)
Date: Wed, 5 Oct 2005 11:16:46 +0100
Subject: [R] mathgraph - inputs allowed?
Message-ID: <200510051016.j95AGpMT011284@hypatia.math.ethz.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051005/d4415cd6/attachment.pl

From r.hankin at noc.soton.ac.uk  Wed Oct  5 12:19:43 2005
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Wed, 5 Oct 2005 11:19:43 +0100
Subject: [R] eliminate t() and %*% using crossprod() and solve(A,b)
Message-ID: <3AB630BF-6287-4E31-BBF3-544B970DEDFA@soc.soton.ac.uk>

Hi

I have a square matrix Ainv of size N-by-N where N ~  1000
I have a rectangular matrix H of size N by n where n ~ 4.
I have a vector d of length N.

I need   X  = solve(t(H) %*% Ainv %*% H) %*% t(H) %*% Ainv %*% d

and

H %*% X.

It is possible to rewrite X in the recommended crossprod way:

X <-  solve(quad.form(Ainv, H), crossprod(crossprod(Ainv, H), d))

where quad.form() is a little function that evaluates a quadratic form:

  quad.form <- function (M, x){
         jj <- crossprod(M, x)
         return(drop(crossprod(jj, jj)))
}


QUESTION:

how  to calculate

H %*% X

in the recommended crossprod way?  (I don't want to take a transpose
because t() is expensive, and I know that %*% is slow).





--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From jiruse at gfk.cz  Wed Oct  5 13:12:24 2005
From: jiruse at gfk.cz (=?iso-8859-2?Q?JIRU=A9E_Marek?=)
Date: Wed, 5 Oct 2005 13:12:24 +0200
Subject: [R] Labeling the theme of shp file in R
Message-ID: <A0431FCEE62E1D43897161C2300DAF9EE7A0@LEO.gfk.bbc>


Dear R-users,

I am using the package maptools to draw a shp file in R with a function Map2poly() without problem. I would appreciate to know how can I add the labels of the objects in the map.
Thank you for any advice.

library(maptools)
try <- read.shape(system.file("data shp/okresy.shp", package="maptools"))
mappolys <- Map2poly(try,quiet=FALSE)
plot(mappolys)

Marek Jiruse
Data Production Specialist
GfK Praha, s.r.o.
Geologick?? 2
CZ - 152 00 Praha 5
tel.: +420 296 555  694
fax: +420 251 815 800
e-mail: jiruse at gfk.cz
http://www.gfk.cz



From fcombes at gmail.com  Wed Oct  5 13:45:57 2005
From: fcombes at gmail.com (Florence Combes)
Date: Wed, 5 Oct 2005 13:45:57 +0200
Subject: [R] Joining Dataframes
In-Reply-To: <p0621020ebf6898ab8997@128.115.153.6>
References: <op.sx4zf50bz9djk1@relay.pair.com>
	<p0621020ebf6898ab8997@128.115.153.6>
Message-ID: <73dae3060510050445u5be53dabm101932251109fda0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051005/9eb2d1eb/attachment.pl

From ripley at stats.ox.ac.uk  Wed Oct  5 13:50:27 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 Oct 2005 12:50:27 +0100 (BST)
Subject: [R] eliminate t() and %*% using crossprod() and solve(A,b)
In-Reply-To: <3AB630BF-6287-4E31-BBF3-544B970DEDFA@soc.soton.ac.uk>
References: <3AB630BF-6287-4E31-BBF3-544B970DEDFA@soc.soton.ac.uk>
Message-ID: <Pine.LNX.4.61.0510051220100.24974@gannet.stats>

On Wed, 5 Oct 2005, Robin Hankin wrote:

> I have a square matrix Ainv of size N-by-N where N ~  1000
> I have a rectangular matrix H of size N by n where n ~ 4.
> I have a vector d of length N.
>
> I need   X  = solve(t(H) %*% Ainv %*% H) %*% t(H) %*% Ainv %*% d
>
> and
>
> H %*% X.
>
> It is possible to rewrite X in the recommended crossprod way:
>
> X <-  solve(quad.form(Ainv, H), crossprod(crossprod(Ainv, H), d))
>
> where quad.form() is a little function that evaluates a quadratic form:
>
>  quad.form <- function (M, x){
>         jj <- crossprod(M, x)
>         return(drop(crossprod(jj, jj)))
> }

That is not the same thing: it gives t(H) %*% Ainv %*% t(Ainv) %*% H .

> QUESTION:
>
> how  to calculate
>
> H %*% X
>
> in the recommended crossprod way?  (I don't want to take a transpose
> because t() is expensive, and I know that %*% is slow).

Have you some data to support your claims?  Here I find (for random 
matrices of the dimensions given on a machine with a fast BLAS)

> system.time(for(i in 1:100) t(H) %*% Ainv)
[1] 2.19 0.01 2.21 0.00 0.00
> system.time(for(i in 1:100) crossprod(H, Ainv))
[1] 1.33 0.00 1.33 0.00 0.00

so each is quite fast and the difference is not great.  However, that is 
not comparing %*% with crossprod, but t & %*% with crossprod.

I get

> system.time(for(i in 1:1000) H %*% X)
[1] 0.05 0.01 0.06 0.00 0.00

which is hardly 'slow' (60 us for %*%), especially compared to forming X 
in

> system.time({X  = solve(t(H) %*% Ainv %*% H) %*% t(H) %*% Ainv %*% d})
[1] 0.04 0.00 0.04 0.00 0.00

I would probably have written

> system.time({X <- solve(crossprod(H, Ainv %*% H), crossprod(crossprod(Ainv, H), d))})
1] 0.03 0.00 0.03 0.00 0.00

which is faster and does give the same answer.

[BTW, I used 2.2.0-beta which defaults to gcFirst=TRUE.]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sourceforge at metrak.com  Wed Oct  5 14:19:09 2005
From: sourceforge at metrak.com (sosman)
Date: Wed, 05 Oct 2005 22:19:09 +1000
Subject: [R] multiple line plots
Message-ID: <4343C4BD.2070304@metrak.com>

I have some data in a CSV file:

time,pos,t,tl
15:23:44:350,M1_01,4511,1127
15:23:44:350,M1_02,4514,1128
15:23:44:350,M1_03,4503,1125
...
15:23:44:491,M2_01,4500,1125
15:23:44:491,M2_02,4496,1124
15:23:44:491,M2_03,4516,1129
...
15:23:44:710,M3_01,4504,1126
15:23:44:710,M3_02,4516,1129
15:23:44:710,M3_03,4498,1124
...

Each pos (eg M1_01) is an independent time series.  I would like to plot 
each time series as lines on a single plot and I wondered if there was 
something more straight forward than I was attempting.

I got as far as:

fname = 't100.csv'
t = read.csv(fname)
tpos = split(t, t$pos)
plot(tpos[["M1_01"]]$t, type='l')
for (p in names(tpos)) {
     lines(tpos[[p]]$t)
}

which seems to work but then I got stuck on how to make each line a 
different colour and figured that there might a be a one liner R command 
to do what I want.

Any tips would be appreciated.



From cg.pettersson at evp.slu.se  Wed Oct  5 15:10:18 2005
From: cg.pettersson at evp.slu.se (CG Pettersson)
Date: Wed, 05 Oct 2005 15:10:18 +0200
Subject: [R] Analyses of covariation with lme() or lm()
Message-ID: <4343D0BA.8030103@evp.slu.se>

Hello all!

I have a problem that calls for a better understanding, than mine, of 
how lme() uses the random part of the call.

The dataset consists of eleven field trials (Trial) with three 
replicates (Block) and four fertiliser treatments (Treat). Analysing for 
  example yield with lme() is easy:

m1 <- lme(Yield ~ Treat, data=data,
           random =~1| Trial/Block)

giving estimates of Treat effects with good significances. If I compare 
m1 with the model without any random structure:

m2 <- lm(Yield ~ Treat, data=data),
m1 is, naturally, much better than m2. So far so good.

Now I have one (1) measure from each Trial, of soil factors weather and 
such, that I want to evaluate. Remember: only one value of the covariate 
for each Trial. The suggestion I have got from my local guru is to base 
this in m1 like:

m3 <- lme(Yield ~ Treat + Cov1 + Treat:Cov1, data=data,
           random =~1| Trial/Block)

thus giving a model where the major random factor (Trial) is represented 
  both as a (1) measure of Cov1 in the fixed part and by itself in the 
random part. Trying the simpler call:

m4 <- lm(Yield ~ Treat + Cov1 + Treat:Cov1, data=data)

gives back basically the same fixed effects as m3, but with better 
significances for Cov1. Tested with anova(m3,m4) naturally gives the 
answer that m3 is better than m4. Ok, what about dealing with Trial in 
the fixed call? :

m5 <- lm(Yield ~ Trial + Treat + Cov1 + Treat:Cov1, data=data)

lm() swallows this, but silently moves out Cov1 from the analysis, an 
action that feels very logical to me.

My guru says that using the random call secures you from overestimating 
the p-values of the covariate. I fear that the risk is as big that you 
underestimate them with the same action. Working on a paper, I naturally 
want to be able to do some sort of discussion on the impact of 
covariates... ;-)

What is the wise solution? Or, if this is trying to make other people do 
my homework, could anyone tell me where the homework is? (I??ve got both 
Pinhiero & Bates and MASS as well as some others in the bookshelf.)

Cheers
/CG

-- 
CG Pettersson MSci. PhD.Stud.
Swedish University of Agricultural Sciences (SLU)
Dep. of Crop Production Ecology (VPE).
http://www.slu.se/
cg.pettersson at evp.slu.se



From MSchwartz at mn.rr.com  Wed Oct  5 14:48:59 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Wed, 05 Oct 2005 07:48:59 -0500
Subject: [R] multiple line plots
In-Reply-To: <4343C4BD.2070304@metrak.com>
References: <4343C4BD.2070304@metrak.com>
Message-ID: <1128516539.5576.21.camel@localhost.localdomain>

On Wed, 2005-10-05 at 22:19 +1000, sosman wrote:
> I have some data in a CSV file:
> 
> time,pos,t,tl
> 15:23:44:350,M1_01,4511,1127
> 15:23:44:350,M1_02,4514,1128
> 15:23:44:350,M1_03,4503,1125
> ...
> 15:23:44:491,M2_01,4500,1125
> 15:23:44:491,M2_02,4496,1124
> 15:23:44:491,M2_03,4516,1129
> ...
> 15:23:44:710,M3_01,4504,1126
> 15:23:44:710,M3_02,4516,1129
> 15:23:44:710,M3_03,4498,1124
> ...
> 
> Each pos (eg M1_01) is an independent time series.  I would like to plot 
> each time series as lines on a single plot and I wondered if there was 
> something more straight forward than I was attempting.
> 
> I got as far as:
> 
> fname = 't100.csv'
> t = read.csv(fname)
> tpos = split(t, t$pos)
> plot(tpos[["M1_01"]]$t, type='l')
> for (p in names(tpos)) {
>      lines(tpos[[p]]$t)
> }
> 
> which seems to work but then I got stuck on how to make each line a 
> different colour and figured that there might a be a one liner R command 
> to do what I want.
> 
> Any tips would be appreciated.


See the examples in ?plot.ts for some approaches.

You will need to review ?ts to create time series objects from your data
to be used in plot.ts().

Another approach, which is not specific to time series, is ?matplot.

HTH,

Marc Schwartz



From r.hankin at noc.soton.ac.uk  Wed Oct  5 15:08:05 2005
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Wed, 5 Oct 2005 14:08:05 +0100
Subject: [R] eliminate t() and %*% using crossprod() and solve(A,b)
In-Reply-To: <Pine.LNX.4.61.0510051220100.24974@gannet.stats>
References: <3AB630BF-6287-4E31-BBF3-544B970DEDFA@soc.soton.ac.uk>
	<Pine.LNX.4.61.0510051220100.24974@gannet.stats>
Message-ID: <7BEA48C2-F10E-4453-BDDB-3EE3B78BBB5B@soc.soton.ac.uk>


On 5 Oct 2005, at 12:15, Dimitris Rizopoulos wrote:

> Hi Robin,
>
> I've been playing with your question, but I think these two lines  
> are not equivalent:
>
> N <- 1000
> n <- 4
> Ainv <- matrix(rnorm(N * N), N, N)
> H <- matrix(rnorm(N * n), N, n)
> d <- rnorm(N)
> quad.form <- function (M, x){
>         jj <- crossprod(M, x)
>         return(drop(crossprod(jj, jj)))
> }
>
>
> X0 <- solve(t(H) %*% Ainv %*% H) %*% t(H) %*% Ainv %*% d
> X1 <- solve(quad.form(Ainv, H), crossprod(crossprod(Ainv, H), d))
> all.equal(X0, X1) # not TRUE
>
>
> which is the one you want to compute?
>


These are not exactly equivalent, but:


Ainv <- matrix(rnorm(1e6),1e3,1e3)
H <- matrix(rnorm(4000),ncol=4)
d <- rnorm(1000)

X0 <- solve(t(H) %*% Ainv %*% H) %*% t(H) %*% Ainv %*% d
X1 <- solve(quad.form(Ainv, H), crossprod(crossprod(Ainv, H), d))
X0 - X1
               [,1]
[1,]  4.884981e-15
[2,]  3.663736e-15
[3,] -5.107026e-15
[4,]  5.717649e-15

which is pretty close.



On 5 Oct 2005, at 12:50, Prof Brian Ripley wrote:
>
>> QUESTION:
>>
>> how  to calculate
>>
>> H %*% X
>>
>> in the recommended crossprod way?  (I don't want to take a transpose
>> because t() is expensive, and I know that %*% is slow).
>>
>
> Have you some data to support your claims?  Here I find (for random
> matrices of the dimensions given on a machine with a fast BLAS)
>
>

I couldn't supply any performance data because I couldn't figure out the
correct R commands to calculate H %*% X  without using %*% or t()!

I was just wondering if there were a way to calculate

H %*% solve(t(H) %*% Ainv %*% H) %*% t(H) %*% Ainv %*% d

without using t() or %*%.  And there doesn't seem to be (my original
question didn't make it clear that I don't have X precalculated).

My take-home lesson from Brian Ripley is that H %*% X is fast
--but this is only useful to me if one has X precalculated, and in
general I don't.   But this discussion suggests to me that it might be
a good idea to change my routines and calculate X anyway.

thanks again Prof Ripley and Dimitris Rizopoulos


very best wishes

Robin



>> system.time(for(i in 1:100) t(H) %*% Ainv)
>>
> [1] 2.19 0.01 2.21 0.00 0.00
>
>> system.time(for(i in 1:100) crossprod(H, Ainv))
>>
> [1] 1.33 0.00 1.33 0.00 0.00
>
> so each is quite fast and the difference is not great.  However,  
> that is
> not comparing %*% with crossprod, but t & %*% with crossprod.
>
> I get
>
>
>> system.time(for(i in 1:1000) H %*% X)
>>
> [1] 0.05 0.01 0.06 0.00 0.00
>
> which is hardly 'slow' (60 us for %*%), especially compared to  
> forming X
> in
>
>
>> system.time({X  = solve(t(H) %*% Ainv %*% H) %*% t(H) %*% Ainv %*%  
>> d})
>>
> [1] 0.04 0.00 0.04 0.00 0.00
>
> I would probably have written
>
>
>> system.time({X <- solve(crossprod(H, Ainv %*% H), crossprod 
>> (crossprod(Ainv, H), d))})
>>
> 1] 0.03 0.00 0.03 0.00 0.00
>
> which is faster and does give the same answer.
>
> [BTW, I used 2.2.0-beta which defaults to gcFirst=TRUE.]
>
> -- 





--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From jfox at mcmaster.ca  Wed Oct  5 15:17:20 2005
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 5 Oct 2005 09:17:20 -0400
Subject: [R] Rcmdr and scatter3d
In-Reply-To: <43433281.6050609@adfa.edu.au>
Message-ID: <20051005131719.OYQX25800.tomts13-srv.bellnexxia.net@JohnDesktop8300>

Dear Ted,

I assumed that since Naiara was using scatter3d(), he wants a 3D dynamic
scatterplot. He could add points (actually, spheres) to the rgl graph
produced by scatter3d() -- the analog of plot() followed by points() for a
2D graph -- but doing so would be much more work than plotting by groups.

Regards,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: ecatchpole [mailto:e.catchpole at adfa.edu.au] 
> Sent: Tuesday, October 04, 2005 8:55 PM
> To: John Fox
> Cc: 'Naiara S. Pinto'; r-help at stat.math.ethz.ch
> Subject: Re: [R] Rcmdr and scatter3d
> 
> Niara,
> 
> Alternatively, instead of scatter3d, the analogy to "hold on" 
> in Matlab is to use plot() for the first set of data, then 
> points() for the remainder. See
> 
> ?plot
> ?points
> 
> Ted.
> 
> On 05/10/05 11:18,  John Fox wrote,:
> > Dear Naiara,
> > 
> > Combine the data sets and differentiate among them with a 
> factor. Then 
> > use the groups argument to scatter3d (see ?scatter3d). If 
> you're using 
> > the R Commander to make the plot, the 3D scatterplot dialog 
> box as a 
> > plot by groups button. You can also fit colour-coded 
> regression surfaces by group.
> > 
> > I've appended a new version of the scatter3d function, not 
> yet in the 
> > Rcmdr package, which will also plot data ellipsoids (for the whole 
> > data set or by groups).
> > 
> > I hope this helps,
> >  John
> > 
> > ----------- snip --------------
> 
> > --------------------------------
> > John Fox
> > Department of Sociology
> > McMaster University
> > Hamilton, Ontario
> > Canada L8S 4M4
> > 905-525-9140x23604
> > http://socserv.mcmaster.ca/jfox
> > --------------------------------
> > 
> >>-----Original Message-----
> >>From: r-help-bounces at stat.math.ethz.ch 
> >>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Naiara S. Pinto
> >>Sent: Tuesday, October 04, 2005 6:13 PM
> >>To: r-help at stat.math.ethz.ch
> >>Subject: [R] Rcmdr and scatter3d
> >>
> >>Hi folks,
> >>
> >>I'd like to use scatter3d (which is in R commander) to plot 
> more than 
> >>one dataset in the same graph, each dataset with a different color. 
> >>The kind of stuff you would do with "holdon"
> >>in Matlab.
> >>
> >>I read a recent message that was posted to this list with a similar 
> >>problem, but I couldn't understand the reply. Could someone give me 
> >>one example? How do you plot subgroups using scatter3d?
> >>
> >>Thanks a lot!
> >>
> >>Naiara.
> >>
> >>
> >>--------------------------------------------
> >>Naiara S. Pinto
> >>Ecology, Evolution and Behavior
> >>1 University Station A6700
> >>Austin, TX, 78712
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide! 
> >>http://www.R-project.org/posting-guide.html
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> 
> 
> --
> Dr E.A. Catchpole
> Visiting Fellow
> Univ of New South Wales at ADFA, Canberra, Australia and 
> University of Kent, Canterbury, England
> - www.ma.adfa.edu.au/~eac
> - fax: +61 2 6268 8786		
> - ph:  +61 2 6268 8895



From vincent at 7d4.com  Wed Oct  5 15:21:35 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Wed, 05 Oct 2005 15:21:35 +0200
Subject: [R] multiple line plots
In-Reply-To: <4343C4BD.2070304@metrak.com>
References: <4343C4BD.2070304@metrak.com>
Message-ID: <4343D35F.20507@7d4.com>

sosman a ??crit :

lines() has a color argument

from the online help :
?lines
lines(x, y = NULL, type = "l", col = par("col"),...



From chabotd at globetrotter.net  Wed Oct  5 15:21:42 2005
From: chabotd at globetrotter.net (Denis Chabot)
Date: Wed, 05 Oct 2005 09:21:42 -0400
Subject: [R]  testing non-linear component in mgcv:gam
In-Reply-To: <mailman.10.1128506401.6195.r-help@stat.math.ethz.ch>
References: <mailman.10.1128506401.6195.r-help@stat.math.ethz.ch>
Message-ID: <CC98AE00-3F2B-4DFA-8D5C-8D9E28D8C9E0@globetrotter.net>

Hi,

I need further help with my GAMs. Most models I test are very  
obviously non-linear. Yet, to be on the safe side, I report the  
significance of the smooth (default output of mgcv's summary.gam) and  
confirm it deviates significantly from linearity.

I do the latter by fitting a second model where the same predictor is  
entered without the s(), and then use anova.gam to compare the two. I  
thought this was the equivalent of the default output of anova.gam  
using package gam instead of mgcv.

I wonder if this procedure is correct because one of my models  
appears to be linear. In fact mgcv estimates df to be exactly 1.0 so  
I could have stopped there. However I inadvertently repeated the  
procedure outlined above. I would have thought in this case the  
anova.gam comparing the smooth and the linear fit would for sure have  
been not significant. To my surprise, P was 6.18e-09!

Am I doing something wrong when I attempt to confirm the non- 
parametric part a smoother is significant? Here is my example case  
where the relationship does appear to be linear:

library(mgcv)
> This is mgcv 1.3-7
Temp <- c(-1.38, -1.12, -0.88, -0.62, -0.38, -0.12, 0.12, 0.38, 0.62,  
0.88, 1.12,
            1.38, 1.62, 1.88, 2.12, 2.38, 2.62, 2.88, 3.12, 3.38,  
3.62, 3.88,
            4.12, 4.38, 4.62, 4.88, 5.12, 5.38, 5.62, 5.88, 6.12,  
6.38, 6.62, 6.88,
            7.12, 8.38, 13.62)
N.sets <- c(2, 6, 3, 9, 26, 15, 34, 21, 30, 18, 28, 27, 27, 29, 31,  
22, 26, 24, 23,
             15, 25, 24, 27, 19, 26, 24, 22, 13, 10, 2, 5, 3, 1, 1,  
1, 1, 1)
wm.sed <- c(0.000000000, 0.016129032, 0.000000000, 0.062046512,  
0.396459596, 0.189082949,
             0.054757925, 0.142810440, 0.168005168, 0.180804428,  
0.111439628, 0.128799505,
             0.193707937, 0.105921610, 0.103497845, 0.028591837,  
0.217894389, 0.020535469,
             0.080389068, 0.105234450, 0.070213450, 0.050771363,  
0.042074434, 0.102348837,
             0.049748344, 0.019100478, 0.005203125, 0.101711864,  
0.000000000, 0.000000000,
             0.014808824, 0.000000000, 0.222000000, 0.167000000,  
0.000000000, 0.000000000,
             0.000000000)

sed.gam <- gam(wm.sed~s(Temp),weight=N.sets)
summary.gam(sed.gam)
> Family: gaussian
> Link function: identity
>
> Formula:
> wm.sed ~ s(Temp)
>
> Parametric coefficients:
>             Estimate Std. Error t value Pr(>|t|)
> (Intercept)  0.08403    0.01347   6.241 3.73e-07 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Approximate significance of smooth terms:
>         edf Est.rank     F  p-value
> s(Temp)   1        1 13.95 0.000666 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> R-sq.(adj) =  0.554   Deviance explained = 28.5%
> GCV score = 0.09904   Scale est. = 0.093686  n = 37

# testing non-linear contribution
sed.lin <- gam(wm.sed~Temp,weight=N.sets)
summary.gam(sed.lin)
> Family: gaussian
> Link function: identity
>
> Formula:
> wm.sed ~ Temp
>
> Parametric coefficients:
>              Estimate Std. Error t value Pr(>|t|)
> (Intercept)  0.162879   0.019847   8.207 1.14e-09 ***
> Temp        -0.023792   0.006369  -3.736 0.000666 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
> R-sq.(adj) =  0.554   Deviance explained = 28.5%
> GCV score = 0.09904   Scale est. = 0.093686  n = 37
anova.gam(sed.lin, sed.gam, test="F")
> Analysis of Deviance Table
>
> Model 1: wm.sed ~ Temp
> Model 2: wm.sed ~ s(Temp)
>    Resid. Df Resid. Dev         Df  Deviance      F   Pr(>F)
> 1 3.5000e+01      3.279
> 2 3.5000e+01      3.279 5.5554e-10 2.353e-11 0.4521 6.18e-09 ***


Thanks in advance,


Denis Chabot



From allan_sta_staff_sci_main_uct at mail.uct.ac.za  Wed Oct  5 15:31:52 2005
From: allan_sta_staff_sci_main_uct at mail.uct.ac.za (allan_sta_staff_sci_main_uct@mail.uct.ac.za)
Date: Wed, 05 Oct 2005 15:31:52 +0200
Subject: [R] (no subject)
Message-ID: <1128519112.4343d5c8e312f@webmail.uct.ac.za>

hi all

why does the following not work???

this was someone elses code and i couldnt explain why it doesn't work.

m=matrix(c(0,0),2,1)
v=matrix(c(1,0,0,1),2,2)

Y=function(X1,X2,mu=m,V=v)
{
	X=matrix(c(X1,X2),2,1)
	a=(1/((2*pi)*sqrt(det(V))))*exp((-0.5)*(t(X-mu)%*%solve(V)%*%(X-mu)))
	a[1]
}

x1=seq(-1,1)
x2=x1

Z=outer(x1,x2,FUN="Y",mu=m,V=v)

persp(x1,x2,Z)




my code:

BINORMAL<-function(varx=1,vary=1,covxy=0,meanx=0,meany=0)
{
	#the following function plots the density of a bi variate normal distribution

	covXY<-matrix(c(varx,covxy,covxy,vary),2,2)
	A<-solve(covXY)

	#up<-max(meanx+4*varx^.5,meanx-4*varx^.5,meany+4*vary^.5,meany-4*vary^.5)
	#x <- seq(-up,up,length=50)
	#y <- x

	x <- seq(meanx-3*varx^.5,meanx+3*varx^.5,length=50)
	y <- seq(meany-3*vary^.5,meany+3*vary^.5,length=50)

	f <- function(x,y,...)
	{
		detA<-det(A)
		quadForm<-A[1,1]*(x-meanx)^2+2*A[1,2]*(x-meanx)*(y-meany)+A[2,2]*(y-meany)^2
		K<-sqrt(detA)/(2*pi)
		exp(-0.5*quadForm)*K
	}

	z <- outer(x, y, f)

	par(mfrow=c(1,2))
	persp(x, y, z,theta = 30, phi = 30,col="white",main="BI-VARIATE NORMAL
DISTRIBUTION")
	contour(x,y,z,main=paste("xy plot, corr(X,Y)= ",(covxy/(varx*vary)^.5)))

	print("NOTE -sqrt(varx*vary)<=covxy<=sqrt(varx*vary)")
	#print(A)
}
BINORMAL(varx=1,vary=1,covxy=0,meanx=0,meany=0)

thanx

/allan



From fisher at lumi.latrobe.edu.au  Wed Oct  5 15:31:58 2005
From: fisher at lumi.latrobe.edu.au (Prof. Paul R. Fisher)
Date: Wed, 05 Oct 2005 23:31:58 +1000
Subject: [R] transparent surface in rgl
Message-ID: <4343D5CE.50804@lumi.latrobe.edu.au>

Hi all
I am a complete newbie to this list (just subscribed) and a newcomer to 
R (an S user from olden times). I have been using scatter3d to create a 
3d scatter plot with surface. The graphic is created within the rgl 
package and I have used rgl.postscript to export it so I can generate a 
publication quality image. My problem is that the plotted surface is no 
longer transparent in the postscript output ie. the rgl.spheres that are 
behind the surface disappear in the postscript image. Can't seem to find 
any info on this anywhere. Am I doing something wrong? Is there an easy fix?

Anyway, thanks.
Hope I've not broken some netiquette rule sending this.

Cheers,
Paul Fisher.
-- 
Prof. Paul R. Fisher,
Chair in Microbiology,
La Trobe University,
VIC 3086,
AUSTRALIA.

Tel. + 61 3 9479 2229
Fax. + 61 3 9479 1222
Email. fisher at lumi.latrobe.edu.au
Web. http://www.latrobe.edu.au/mcbg/my.html



From dimitris.rizopoulos at med.kuleuven.be  Wed Oct  5 15:37:59 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Wed, 5 Oct 2005 15:37:59 +0200
Subject: [R] eliminate t() and %*% using crossprod() and solve(A,b)
References: <3AB630BF-6287-4E31-BBF3-544B970DEDFA@soc.soton.ac.uk><Pine.LNX.4.61.0510051220100.24974@gannet.stats>
	<7BEA48C2-F10E-4453-BDDB-3EE3B78BBB5B@soc.soton.ac.uk>
Message-ID: <009601c5c9b2$00638150$0540210a@www.domain>

an alternative is to use X2 below, which seems to be a little bit 
faster:

N <- 1000
n <- 4
Ainv <- matrix(rnorm(N * N), N, N)
H <- matrix(rnorm(N * n), N, n)
d <- rnorm(N)
quad.form <- function (M, x){
         jj <- crossprod(M, x)
         return(drop(crossprod(jj, jj)))
}

#######################
#######################

invisible({gc(); gc(); gc()})
system.time(for(i in 1:200){
    X0 <- solve(t(H) %*% Ainv %*% H) %*% t(H) %*% Ainv %*% d
}, gcFirst = TRUE)


invisible({gc(); gc(); gc()})
system.time(for(i in 1:200){
    X1 <- solve(quad.form(Ainv, H), crossprod(crossprod(Ainv, H), d))
}, gcFirst = TRUE)


invisible({gc(); gc(); gc()})
system.time(for(i in 1:200){
    tH.Ainv <- crossprod(H, Ainv)
    X2 <-  solve(tH.Ainv %*% H) %*% colSums(t(tH.Ainv) * d)
}, gcFirst = TRUE)


all.equal(X0, X1)
all.equal(X0, X2)


I hope this helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Robin Hankin" <r.hankin at noc.soton.ac.uk>
To: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
Cc: "RHelp" <r-help at stat.math.ethz.ch>; "Robin Hankin" 
<r.hankin at noc.soton.ac.uk>
Sent: Wednesday, October 05, 2005 3:08 PM
Subject: Re: [R] eliminate t() and %*% using crossprod() and 
solve(A,b)


>
> On 5 Oct 2005, at 12:15, Dimitris Rizopoulos wrote:
>
>> Hi Robin,
>>
>> I've been playing with your question, but I think these two lines
>> are not equivalent:
>>
>> N <- 1000
>> n <- 4
>> Ainv <- matrix(rnorm(N * N), N, N)
>> H <- matrix(rnorm(N * n), N, n)
>> d <- rnorm(N)
>> quad.form <- function (M, x){
>>         jj <- crossprod(M, x)
>>         return(drop(crossprod(jj, jj)))
>> }
>>
>>
>> X0 <- solve(t(H) %*% Ainv %*% H) %*% t(H) %*% Ainv %*% d
>> X1 <- solve(quad.form(Ainv, H), crossprod(crossprod(Ainv, H), d))
>> all.equal(X0, X1) # not TRUE
>>
>>
>> which is the one you want to compute?
>>
>
>
> These are not exactly equivalent, but:
>
>
> Ainv <- matrix(rnorm(1e6),1e3,1e3)
> H <- matrix(rnorm(4000),ncol=4)
> d <- rnorm(1000)
>
> X0 <- solve(t(H) %*% Ainv %*% H) %*% t(H) %*% Ainv %*% d
> X1 <- solve(quad.form(Ainv, H), crossprod(crossprod(Ainv, H), d))
> X0 - X1
>               [,1]
> [1,]  4.884981e-15
> [2,]  3.663736e-15
> [3,] -5.107026e-15
> [4,]  5.717649e-15
>
> which is pretty close.
>
>
>
> On 5 Oct 2005, at 12:50, Prof Brian Ripley wrote:
>>
>>> QUESTION:
>>>
>>> how  to calculate
>>>
>>> H %*% X
>>>
>>> in the recommended crossprod way?  (I don't want to take a 
>>> transpose
>>> because t() is expensive, and I know that %*% is slow).
>>>
>>
>> Have you some data to support your claims?  Here I find (for random
>> matrices of the dimensions given on a machine with a fast BLAS)
>>
>>
>
> I couldn't supply any performance data because I couldn't figure out 
> the
> correct R commands to calculate H %*% X  without using %*% or t()!
>
> I was just wondering if there were a way to calculate
>
> H %*% solve(t(H) %*% Ainv %*% H) %*% t(H) %*% Ainv %*% d
>
> without using t() or %*%.  And there doesn't seem to be (my original
> question didn't make it clear that I don't have X precalculated).
>
> My take-home lesson from Brian Ripley is that H %*% X is fast
> --but this is only useful to me if one has X precalculated, and in
> general I don't.   But this discussion suggests to me that it might 
> be
> a good idea to change my routines and calculate X anyway.
>
> thanks again Prof Ripley and Dimitris Rizopoulos
>
>
> very best wishes
>
> Robin
>
>
>
>>> system.time(for(i in 1:100) t(H) %*% Ainv)
>>>
>> [1] 2.19 0.01 2.21 0.00 0.00
>>
>>> system.time(for(i in 1:100) crossprod(H, Ainv))
>>>
>> [1] 1.33 0.00 1.33 0.00 0.00
>>
>> so each is quite fast and the difference is not great.  However,
>> that is
>> not comparing %*% with crossprod, but t & %*% with crossprod.
>>
>> I get
>>
>>
>>> system.time(for(i in 1:1000) H %*% X)
>>>
>> [1] 0.05 0.01 0.06 0.00 0.00
>>
>> which is hardly 'slow' (60 us for %*%), especially compared to
>> forming X
>> in
>>
>>
>>> system.time({X  = solve(t(H) %*% Ainv %*% H) %*% t(H) %*% Ainv %*%
>>> d})
>>>
>> [1] 0.04 0.00 0.04 0.00 0.00
>>
>> I would probably have written
>>
>>
>>> system.time({X <- solve(crossprod(H, Ainv %*% H), crossprod
>>> (crossprod(Ainv, H), d))})
>>>
>> 1] 0.03 0.00 0.03 0.00 0.00
>>
>> which is faster and does give the same answer.
>>
>> [BTW, I used 2.2.0-beta which defaults to gcFirst=TRUE.]
>>
>> -- 
>
>
>
>
>
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton
> European Way, Southampton SO14 3ZH, UK
>  tel  023-8059-7743
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From andy_liaw at merck.com  Wed Oct  5 15:38:56 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 5 Oct 2005 09:38:56 -0400
Subject: [R] testing non-linear component in mgcv:gam
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED4CE@usctmx1106.merck.com>

I think you probably should state more clearly the goal of your
analysis.  In such situation, estimation and hypothesis testing are
quite different.  The procedure that gives you the `best' estimate is
not necessarily the `best' for testing linearity of components.  If your
goal is estimation/prediction, why test linearity of components?  If the
goal is testing linearity, then you probably need to find the procedure
that gives you a good test, rather than relying on what gam() gives you.

Just my $0.02...

Andy

> From: Denis Chabot
> 
> Hi,
> 
> I need further help with my GAMs. Most models I test are very  
> obviously non-linear. Yet, to be on the safe side, I report the  
> significance of the smooth (default output of mgcv's 
> summary.gam) and  
> confirm it deviates significantly from linearity.
> 
> I do the latter by fitting a second model where the same 
> predictor is  
> entered without the s(), and then use anova.gam to compare 
> the two. I  
> thought this was the equivalent of the default output of anova.gam  
> using package gam instead of mgcv.
> 
> I wonder if this procedure is correct because one of my models  
> appears to be linear. In fact mgcv estimates df to be exactly 1.0 so  
> I could have stopped there. However I inadvertently repeated the  
> procedure outlined above. I would have thought in this case the  
> anova.gam comparing the smooth and the linear fit would for 
> sure have  
> been not significant. To my surprise, P was 6.18e-09!
> 
> Am I doing something wrong when I attempt to confirm the non- 
> parametric part a smoother is significant? Here is my example case  
> where the relationship does appear to be linear:
> 
> library(mgcv)
> > This is mgcv 1.3-7
> Temp <- c(-1.38, -1.12, -0.88, -0.62, -0.38, -0.12, 0.12, 
> 0.38, 0.62,  
> 0.88, 1.12,
>             1.38, 1.62, 1.88, 2.12, 2.38, 2.62, 2.88, 3.12, 3.38,  
> 3.62, 3.88,
>             4.12, 4.38, 4.62, 4.88, 5.12, 5.38, 5.62, 5.88, 6.12,  
> 6.38, 6.62, 6.88,
>             7.12, 8.38, 13.62)
> N.sets <- c(2, 6, 3, 9, 26, 15, 34, 21, 30, 18, 28, 27, 27, 29, 31,  
> 22, 26, 24, 23,
>              15, 25, 24, 27, 19, 26, 24, 22, 13, 10, 2, 5, 3, 1, 1,  
> 1, 1, 1)
> wm.sed <- c(0.000000000, 0.016129032, 0.000000000, 0.062046512,  
> 0.396459596, 0.189082949,
>              0.054757925, 0.142810440, 0.168005168, 0.180804428,  
> 0.111439628, 0.128799505,
>              0.193707937, 0.105921610, 0.103497845, 0.028591837,  
> 0.217894389, 0.020535469,
>              0.080389068, 0.105234450, 0.070213450, 0.050771363,  
> 0.042074434, 0.102348837,
>              0.049748344, 0.019100478, 0.005203125, 0.101711864,  
> 0.000000000, 0.000000000,
>              0.014808824, 0.000000000, 0.222000000, 0.167000000,  
> 0.000000000, 0.000000000,
>              0.000000000)
> 
> sed.gam <- gam(wm.sed~s(Temp),weight=N.sets)
> summary.gam(sed.gam)
> > Family: gaussian
> > Link function: identity
> >
> > Formula:
> > wm.sed ~ s(Temp)
> >
> > Parametric coefficients:
> >             Estimate Std. Error t value Pr(>|t|)
> > (Intercept)  0.08403    0.01347   6.241 3.73e-07 ***
> > ---
> > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >
> > Approximate significance of smooth terms:
> >         edf Est.rank     F  p-value
> > s(Temp)   1        1 13.95 0.000666 ***
> > ---
> > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >
> > R-sq.(adj) =  0.554   Deviance explained = 28.5%
> > GCV score = 0.09904   Scale est. = 0.093686  n = 37
> 
> # testing non-linear contribution
> sed.lin <- gam(wm.sed~Temp,weight=N.sets)
> summary.gam(sed.lin)
> > Family: gaussian
> > Link function: identity
> >
> > Formula:
> > wm.sed ~ Temp
> >
> > Parametric coefficients:
> >              Estimate Std. Error t value Pr(>|t|)
> > (Intercept)  0.162879   0.019847   8.207 1.14e-09 ***
> > Temp        -0.023792   0.006369  -3.736 0.000666 ***
> > ---
> > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >
> >
> > R-sq.(adj) =  0.554   Deviance explained = 28.5%
> > GCV score = 0.09904   Scale est. = 0.093686  n = 37
> anova.gam(sed.lin, sed.gam, test="F")
> > Analysis of Deviance Table
> >
> > Model 1: wm.sed ~ Temp
> > Model 2: wm.sed ~ s(Temp)
> >    Resid. Df Resid. Dev         Df  Deviance      F   Pr(>F)
> > 1 3.5000e+01      3.279
> > 2 3.5000e+01      3.279 5.5554e-10 2.353e-11 0.4521 6.18e-09 ***
> 
> 
> Thanks in advance,
> 
> 
> Denis Chabot
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From jfox at mcmaster.ca  Wed Oct  5 15:45:03 2005
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 5 Oct 2005 09:45:03 -0400
Subject: [R] testing non-linear component in mgcv:gam
In-Reply-To: <CC98AE00-3F2B-4DFA-8D5C-8D9E28D8C9E0@globetrotter.net>
Message-ID: <20051005134502.NDQD26550.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Denis,

Take a closer look at the anova table: The models provide identical fits to
the data. The differences in degrees of freedom and deviance between the two
models are essentially zero, 5.5554e-10 and 2.353e-11 respectively.

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Denis Chabot
> Sent: Wednesday, October 05, 2005 8:22 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] testing non-linear component in mgcv:gam
> 
> Hi,
> 
> I need further help with my GAMs. Most models I test are very 
> obviously non-linear. Yet, to be on the safe side, I report 
> the significance of the smooth (default output of mgcv's 
> summary.gam) and confirm it deviates significantly from linearity.
> 
> I do the latter by fitting a second model where the same 
> predictor is entered without the s(), and then use anova.gam 
> to compare the two. I thought this was the equivalent of the 
> default output of anova.gam using package gam instead of mgcv.
> 
> I wonder if this procedure is correct because one of my 
> models appears to be linear. In fact mgcv estimates df to be 
> exactly 1.0 so I could have stopped there. However I 
> inadvertently repeated the procedure outlined above. I would 
> have thought in this case the anova.gam comparing the smooth 
> and the linear fit would for sure have been not significant. 
> To my surprise, P was 6.18e-09!
> 
> Am I doing something wrong when I attempt to confirm the non- 
> parametric part a smoother is significant? Here is my example 
> case where the relationship does appear to be linear:
> 
> library(mgcv)
> > This is mgcv 1.3-7
> Temp <- c(-1.38, -1.12, -0.88, -0.62, -0.38, -0.12, 0.12, 
> 0.38, 0.62, 0.88, 1.12,
>             1.38, 1.62, 1.88, 2.12, 2.38, 2.62, 2.88, 3.12, 
> 3.38, 3.62, 3.88,
>             4.12, 4.38, 4.62, 4.88, 5.12, 5.38, 5.62, 5.88, 
> 6.12, 6.38, 6.62, 6.88,
>             7.12, 8.38, 13.62)
> N.sets <- c(2, 6, 3, 9, 26, 15, 34, 21, 30, 18, 28, 27, 27, 
> 29, 31, 22, 26, 24, 23,
>              15, 25, 24, 27, 19, 26, 24, 22, 13, 10, 2, 5, 3, 
> 1, 1, 1, 1, 1) wm.sed <- c(0.000000000, 0.016129032, 
> 0.000000000, 0.062046512, 0.396459596, 0.189082949,
>              0.054757925, 0.142810440, 0.168005168, 
> 0.180804428, 0.111439628, 0.128799505,
>              0.193707937, 0.105921610, 0.103497845, 
> 0.028591837, 0.217894389, 0.020535469,
>              0.080389068, 0.105234450, 0.070213450, 
> 0.050771363, 0.042074434, 0.102348837,
>              0.049748344, 0.019100478, 0.005203125, 
> 0.101711864, 0.000000000, 0.000000000,
>              0.014808824, 0.000000000, 0.222000000, 
> 0.167000000, 0.000000000, 0.000000000,
>              0.000000000)
> 
> sed.gam <- gam(wm.sed~s(Temp),weight=N.sets)
> summary.gam(sed.gam)
> > Family: gaussian
> > Link function: identity
> >
> > Formula:
> > wm.sed ~ s(Temp)
> >
> > Parametric coefficients:
> >             Estimate Std. Error t value Pr(>|t|)
> > (Intercept)  0.08403    0.01347   6.241 3.73e-07 ***
> > ---
> > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >
> > Approximate significance of smooth terms:
> >         edf Est.rank     F  p-value
> > s(Temp)   1        1 13.95 0.000666 ***
> > ---
> > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >
> > R-sq.(adj) =  0.554   Deviance explained = 28.5%
> > GCV score = 0.09904   Scale est. = 0.093686  n = 37
> 
> # testing non-linear contribution
> sed.lin <- gam(wm.sed~Temp,weight=N.sets)
> summary.gam(sed.lin)
> > Family: gaussian
> > Link function: identity
> >
> > Formula:
> > wm.sed ~ Temp
> >
> > Parametric coefficients:
> >              Estimate Std. Error t value Pr(>|t|)
> > (Intercept)  0.162879   0.019847   8.207 1.14e-09 ***
> > Temp        -0.023792   0.006369  -3.736 0.000666 ***
> > ---
> > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >
> >
> > R-sq.(adj) =  0.554   Deviance explained = 28.5%
> > GCV score = 0.09904   Scale est. = 0.093686  n = 37
> anova.gam(sed.lin, sed.gam, test="F")
> > Analysis of Deviance Table
> >
> > Model 1: wm.sed ~ Temp
> > Model 2: wm.sed ~ s(Temp)
> >    Resid. Df Resid. Dev         Df  Deviance      F   Pr(>F)
> > 1 3.5000e+01      3.279
> > 2 3.5000e+01      3.279 5.5554e-10 2.353e-11 0.4521 6.18e-09 ***
> 
> 
> Thanks in advance,
> 
> 
> Denis Chabot
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From jfox at mcmaster.ca  Wed Oct  5 15:49:05 2005
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 5 Oct 2005 09:49:05 -0400
Subject: [R] transparent surface in rgl
In-Reply-To: <4343D5CE.50804@lumi.latrobe.edu.au>
Message-ID: <20051005134904.PFUI25800.tomts13-srv.bellnexxia.net@JohnDesktop8300>

Dear Paul,

I don't have experience with rgl.postscript(), which is relatively new, but
find that the png graphs produced by rgl.snapshot() are of reasonably good
quality and preserve transparency. Perhaps the developers of the rgl package
can shed more light on the matter.

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Prof. 
> Paul R. Fisher
> Sent: Wednesday, October 05, 2005 8:32 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] transparent surface in rgl
> 
> Hi all
> I am a complete newbie to this list (just subscribed) and a 
> newcomer to R (an S user from olden times). I have been using 
> scatter3d to create a 3d scatter plot with surface. The 
> graphic is created within the rgl package and I have used 
> rgl.postscript to export it so I can generate a publication 
> quality image. My problem is that the plotted surface is no 
> longer transparent in the postscript output ie. the 
> rgl.spheres that are behind the surface disappear in the 
> postscript image. Can't seem to find any info on this 
> anywhere. Am I doing something wrong? Is there an easy fix?
> 
> Anyway, thanks.
> Hope I've not broken some netiquette rule sending this.
> 
> Cheers,
> Paul Fisher.
> --
> Prof. Paul R. Fisher,
> Chair in Microbiology,
> La Trobe University,
> VIC 3086,
> AUSTRALIA.
> 
> Tel. + 61 3 9479 2229
> Fax. + 61 3 9479 1222
> Email. fisher at lumi.latrobe.edu.au
> Web. http://www.latrobe.edu.au/mcbg/my.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ggrothendieck at gmail.com  Wed Oct  5 15:54:04 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 5 Oct 2005 09:54:04 -0400
Subject: [R] multiple line plots
In-Reply-To: <4343C4BD.2070304@metrak.com>
References: <4343C4BD.2070304@metrak.com>
Message-ID: <971536df0510050654g493a3e02n4c001c2b42c84008@mail.gmail.com>

Assuming, as in your example, that you want to plot your
series against 1, 2, 3, ...  first form a ts series, my.series,
and then plot it using the col= argument:

	my.series <- do.call("cbind", lapply(tpos, ts))
	m <- ncol(my.series)
	ts.plot(my.series, col = 1:m)

Another possibility is to use col = rainbow(m) in the last line.


On 10/5/05, sosman <sourceforge at metrak.com> wrote:
> I have some data in a CSV file:
>
> time,pos,t,tl
> 15:23:44:350,M1_01,4511,1127
> 15:23:44:350,M1_02,4514,1128
> 15:23:44:350,M1_03,4503,1125
> ...
> 15:23:44:491,M2_01,4500,1125
> 15:23:44:491,M2_02,4496,1124
> 15:23:44:491,M2_03,4516,1129
> ...
> 15:23:44:710,M3_01,4504,1126
> 15:23:44:710,M3_02,4516,1129
> 15:23:44:710,M3_03,4498,1124
> ...
>
> Each pos (eg M1_01) is an independent time series.  I would like to plot
> each time series as lines on a single plot and I wondered if there was
> something more straight forward than I was attempting.
>
> I got as far as:
>
> fname = 't100.csv'
> t = read.csv(fname)
> tpos = split(t, t$pos)
> plot(tpos[["M1_01"]]$t, type='l')
> for (p in names(tpos)) {
>     lines(tpos[[p]]$t)
> }
>
> which seems to work but then I got stuck on how to make each line a
> different colour and figured that there might a be a one liner R command
> to do what I want.
>
> Any tips would be appreciated.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From murdoch at stats.uwo.ca  Wed Oct  5 15:57:12 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 05 Oct 2005 09:57:12 -0400
Subject: [R] transparent surface in rgl
In-Reply-To: <4343D5CE.50804@lumi.latrobe.edu.au>
References: <4343D5CE.50804@lumi.latrobe.edu.au>
Message-ID: <4343DBB8.6050701@stats.uwo.ca>

On 10/5/2005 9:31 AM, Prof. Paul R. Fisher wrote:
> Hi all
> I am a complete newbie to this list (just subscribed) and a newcomer to 
> R (an S user from olden times). I have been using scatter3d to create a 
> 3d scatter plot with surface. The graphic is created within the rgl 
> package and I have used rgl.postscript to export it so I can generate a 
> publication quality image. My problem is that the plotted surface is no 
> longer transparent in the postscript output ie. the rgl.spheres that are 
> behind the surface disappear in the postscript image. Can't seem to find 
> any info on this anywhere. Am I doing something wrong? Is there an easy fix?

I think Postscript doesn't support transparency (or at least the version 
of Postscript that the rgl.postcript function targets doesn't support 
it).  You may have to export a bitmapped format using the rgl.snapshot() 
function.  If your original window is very large this may give you good 
enough quality.

Duncan Murdoch



From vincent at 7d4.com  Wed Oct  5 16:00:30 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Wed, 05 Oct 2005 16:00:30 +0200
Subject: [R] transparent surface in rgl
In-Reply-To: <4343D5CE.50804@lumi.latrobe.edu.au>
References: <4343D5CE.50804@lumi.latrobe.edu.au>
Message-ID: <4343DC7E.90304@7d4.com>

Prof. Paul R. Fisher a ??crit :

> ... My problem is that the plotted surface is no 
> longer transparent in the postscript output ie. the rgl.spheres that are 
> behind the surface disappear in the postscript image. Can't seem to find 
> any info on this anywhere. Am I doing something wrong? Is there an easy fix?

Hi,
for many graphical function, eg bmp()
there is a bg argument (background)
which you can set to "transparent".
Or you can directly use:
par(bg="transparent")
Have a look if this doesn't work.
hih
Vincent



From chabotd at globetrotter.net  Wed Oct  5 16:08:44 2005
From: chabotd at globetrotter.net (Denis Chabot)
Date: Wed, 05 Oct 2005 10:08:44 -0400
Subject: [R] testing non-linear component in mgcv:gam
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED4CE@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED4CE@usctmx1106.merck.com>
Message-ID: <5E079CE5-0521-43B1-94B9-EEBADD0E39E5@globetrotter.net>

Fair enough, Andy. I thought I was getting both predictive ability  
and confirmation that the phenomenon I was studying was not linear. I  
have two projects, in one prediction is the goal and I don't really  
need to test linearity. In the second I needed to confirm a cycle was  
taking place and I thought my procedure did this. There was no  
theoretical reason to anticipate the shape of the cycle, so GAM was  
an appealing methodology.

Denis

Le 05-10-05 ?? 09:38, Liaw, Andy a ??crit :

> I think you probably should state more clearly the goal of your
> analysis.  In such situation, estimation and hypothesis testing are
> quite different.  The procedure that gives you the `best' estimate is
> not necessarily the `best' for testing linearity of components.  If  
> your
> goal is estimation/prediction, why test linearity of components?   
> If the
> goal is testing linearity, then you probably need to find the  
> procedure
> that gives you a good test, rather than relying on what gam() gives  
> you.
>
> Just my $0.02...
>
> Andy
>
>
>> From: Denis Chabot
>>
>> Hi,
>>
>> I need further help with my GAMs. Most models I test are very
>> obviously non-linear. Yet, to be on the safe side, I report the
>> significance of the smooth (default output of mgcv's
>> summary.gam) and
>> confirm it deviates significantly from linearity.
>>
>> I do the latter by fitting a second model where the same
>> predictor is
>> entered without the s(), and then use anova.gam to compare
>> the two. I
>> thought this was the equivalent of the default output of anova.gam
>> using package gam instead of mgcv.
>>
>> I wonder if this procedure is correct because one of my models
>> appears to be linear. In fact mgcv estimates df to be exactly 1.0 so
>> I could have stopped there. However I inadvertently repeated the
>> procedure outlined above. I would have thought in this case the
>> anova.gam comparing the smooth and the linear fit would for
>> sure have
>> been not significant. To my surprise, P was 6.18e-09!
>>
>> Am I doing something wrong when I attempt to confirm the non-
>> parametric part a smoother is significant? Here is my example case
>> where the relationship does appear to be linear:
>>
>> library(mgcv)
>>
>>> This is mgcv 1.3-7
>>>
>> Temp <- c(-1.38, -1.12, -0.88, -0.62, -0.38, -0.12, 0.12,
>> 0.38, 0.62,
>> 0.88, 1.12,
>>             1.38, 1.62, 1.88, 2.12, 2.38, 2.62, 2.88, 3.12, 3.38,
>> 3.62, 3.88,
>>             4.12, 4.38, 4.62, 4.88, 5.12, 5.38, 5.62, 5.88, 6.12,
>> 6.38, 6.62, 6.88,
>>             7.12, 8.38, 13.62)
>> N.sets <- c(2, 6, 3, 9, 26, 15, 34, 21, 30, 18, 28, 27, 27, 29, 31,
>> 22, 26, 24, 23,
>>              15, 25, 24, 27, 19, 26, 24, 22, 13, 10, 2, 5, 3, 1, 1,
>> 1, 1, 1)
>> wm.sed <- c(0.000000000, 0.016129032, 0.000000000, 0.062046512,
>> 0.396459596, 0.189082949,
>>              0.054757925, 0.142810440, 0.168005168, 0.180804428,
>> 0.111439628, 0.128799505,
>>              0.193707937, 0.105921610, 0.103497845, 0.028591837,
>> 0.217894389, 0.020535469,
>>              0.080389068, 0.105234450, 0.070213450, 0.050771363,
>> 0.042074434, 0.102348837,
>>              0.049748344, 0.019100478, 0.005203125, 0.101711864,
>> 0.000000000, 0.000000000,
>>              0.014808824, 0.000000000, 0.222000000, 0.167000000,
>> 0.000000000, 0.000000000,
>>              0.000000000)
>>
>> sed.gam <- gam(wm.sed~s(Temp),weight=N.sets)
>> summary.gam(sed.gam)
>>
>>> Family: gaussian
>>> Link function: identity
>>>
>>> Formula:
>>> wm.sed ~ s(Temp)
>>>
>>> Parametric coefficients:
>>>             Estimate Std. Error t value Pr(>|t|)
>>> (Intercept)  0.08403    0.01347   6.241 3.73e-07 ***
>>> ---
>>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>>
>>> Approximate significance of smooth terms:
>>>         edf Est.rank     F  p-value
>>> s(Temp)   1        1 13.95 0.000666 ***
>>> ---
>>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>>
>>> R-sq.(adj) =  0.554   Deviance explained = 28.5%
>>> GCV score = 0.09904   Scale est. = 0.093686  n = 37
>>>
>>
>> # testing non-linear contribution
>> sed.lin <- gam(wm.sed~Temp,weight=N.sets)
>> summary.gam(sed.lin)
>>
>>> Family: gaussian
>>> Link function: identity
>>>
>>> Formula:
>>> wm.sed ~ Temp
>>>
>>> Parametric coefficients:
>>>              Estimate Std. Error t value Pr(>|t|)
>>> (Intercept)  0.162879   0.019847   8.207 1.14e-09 ***
>>> Temp        -0.023792   0.006369  -3.736 0.000666 ***
>>> ---
>>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>>
>>>
>>> R-sq.(adj) =  0.554   Deviance explained = 28.5%
>>> GCV score = 0.09904   Scale est. = 0.093686  n = 37
>>>
>> anova.gam(sed.lin, sed.gam, test="F")
>>
>>> Analysis of Deviance Table
>>>
>>> Model 1: wm.sed ~ Temp
>>> Model 2: wm.sed ~ s(Temp)
>>>    Resid. Df Resid. Dev         Df  Deviance      F   Pr(>F)
>>> 1 3.5000e+01      3.279
>>> 2 3.5000e+01      3.279 5.5554e-10 2.353e-11 0.4521 6.18e-09 ***
>>>
>>
>>
>> Thanks in advance,
>>
>>
>> Denis Chabot
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>>
>>
>
>
> ---------------------------------------------------------------------- 
> --------
> Notice:  This e-mail message, together with any attachments,  
> contains information of Merck & Co., Inc. (One Merck Drive,  
> Whitehouse Station, New Jersey, USA 08889), and/or its affiliates  
> (which may be known outside the United States as Merck Frosst,  
> Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be  
> confidential, proprietary copyrighted and/or legally privileged. It  
> is intended solely for the use of the individual or entity named on  
> this message.  If you are not the intended recipient, and have  
> received this message in error, please notify us immediately by  
> reply e-mail and then delete it from your system.
> ---------------------------------------------------------------------- 
> --------
>



From chabotd at globetrotter.net  Wed Oct  5 16:04:15 2005
From: chabotd at globetrotter.net (Denis Chabot)
Date: Wed, 05 Oct 2005 10:04:15 -0400
Subject: [R] testing non-linear component in mgcv:gam
In-Reply-To: <20051005134502.NDQD26550.tomts20-srv.bellnexxia.net@JohnDesktop8300>
References: <20051005134502.NDQD26550.tomts20-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <C5D5EFC2-85E3-4886-835C-7C24B2950D07@globetrotter.net>

Hi John,

Le 05-10-05 ?? 09:45, John Fox a ??crit :

> Dear Denis,
>
> Take a closer look at the anova table: The models provide identical  
> fits to
> the data. The differences in degrees of freedom and deviance  
> between the two
> models are essentially zero, 5.5554e-10 and 2.353e-11 respectively.
>
> I hope this helps,
>  John
This is one of my difficulties. In some examples I found on the web,  
the difference in deviance is compared directly against the chi- 
squared distribution. But my y variable has a very small range  
(between 0 and 0.5, most of the time) so the difference in deviance  
is always very small and if I compared it against the chi-squared  
distribution as I have seen done in examples, the non-linear  
component would always be not significant. Yet it is (with one  
exception), tested with both mgcv:gam and gam:gam. I think the  
examples I have read were wrong in this regard, the "scale" factor  
seen in mgcv output seems to intervene. But exactly how is still  
mysterious to me and I hesitate to judge the size of the deviance  
difference myself.

I agree it is near zero in my example. I guess I need to have more  
experience with these models to better interpret the output...

Denis
>
>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Denis Chabot
>> Sent: Wednesday, October 05, 2005 8:22 AM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] testing non-linear component in mgcv:gam
>>
>> Hi,
>>
>> I need further help with my GAMs. Most models I test are very
>> obviously non-linear. Yet, to be on the safe side, I report
>> the significance of the smooth (default output of mgcv's
>> summary.gam) and confirm it deviates significantly from linearity.
>>
>> I do the latter by fitting a second model where the same
>> predictor is entered without the s(), and then use anova.gam
>> to compare the two. I thought this was the equivalent of the
>> default output of anova.gam using package gam instead of mgcv.
>>
>> I wonder if this procedure is correct because one of my
>> models appears to be linear. In fact mgcv estimates df to be
>> exactly 1.0 so I could have stopped there. However I
>> inadvertently repeated the procedure outlined above. I would
>> have thought in this case the anova.gam comparing the smooth
>> and the linear fit would for sure have been not significant.
>> To my surprise, P was 6.18e-09!
>>
>> Am I doing something wrong when I attempt to confirm the non-
>> parametric part a smoother is significant? Here is my example
>> case where the relationship does appear to be linear:
>>
>> library(mgcv)
>>
>>> This is mgcv 1.3-7
>>>
>> Temp <- c(-1.38, -1.12, -0.88, -0.62, -0.38, -0.12, 0.12,
>> 0.38, 0.62, 0.88, 1.12,
>>             1.38, 1.62, 1.88, 2.12, 2.38, 2.62, 2.88, 3.12,
>> 3.38, 3.62, 3.88,
>>             4.12, 4.38, 4.62, 4.88, 5.12, 5.38, 5.62, 5.88,
>> 6.12, 6.38, 6.62, 6.88,
>>             7.12, 8.38, 13.62)
>> N.sets <- c(2, 6, 3, 9, 26, 15, 34, 21, 30, 18, 28, 27, 27,
>> 29, 31, 22, 26, 24, 23,
>>              15, 25, 24, 27, 19, 26, 24, 22, 13, 10, 2, 5, 3,
>> 1, 1, 1, 1, 1) wm.sed <- c(0.000000000, 0.016129032,
>> 0.000000000, 0.062046512, 0.396459596, 0.189082949,
>>              0.054757925, 0.142810440, 0.168005168,
>> 0.180804428, 0.111439628, 0.128799505,
>>              0.193707937, 0.105921610, 0.103497845,
>> 0.028591837, 0.217894389, 0.020535469,
>>              0.080389068, 0.105234450, 0.070213450,
>> 0.050771363, 0.042074434, 0.102348837,
>>              0.049748344, 0.019100478, 0.005203125,
>> 0.101711864, 0.000000000, 0.000000000,
>>              0.014808824, 0.000000000, 0.222000000,
>> 0.167000000, 0.000000000, 0.000000000,
>>              0.000000000)
>>
>> sed.gam <- gam(wm.sed~s(Temp),weight=N.sets)
>> summary.gam(sed.gam)
>>
>>> Family: gaussian
>>> Link function: identity
>>>
>>> Formula:
>>> wm.sed ~ s(Temp)
>>>
>>> Parametric coefficients:
>>>             Estimate Std. Error t value Pr(>|t|)
>>> (Intercept)  0.08403    0.01347   6.241 3.73e-07 ***
>>> ---
>>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>>
>>> Approximate significance of smooth terms:
>>>         edf Est.rank     F  p-value
>>> s(Temp)   1        1 13.95 0.000666 ***
>>> ---
>>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>>
>>> R-sq.(adj) =  0.554   Deviance explained = 28.5%
>>> GCV score = 0.09904   Scale est. = 0.093686  n = 37
>>>
>>
>> # testing non-linear contribution
>> sed.lin <- gam(wm.sed~Temp,weight=N.sets)
>> summary.gam(sed.lin)
>>
>>> Family: gaussian
>>> Link function: identity
>>>
>>> Formula:
>>> wm.sed ~ Temp
>>>
>>> Parametric coefficients:
>>>              Estimate Std. Error t value Pr(>|t|)
>>> (Intercept)  0.162879   0.019847   8.207 1.14e-09 ***
>>> Temp        -0.023792   0.006369  -3.736 0.000666 ***
>>> ---
>>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>>
>>>
>>> R-sq.(adj) =  0.554   Deviance explained = 28.5%
>>> GCV score = 0.09904   Scale est. = 0.093686  n = 37
>>>
>> anova.gam(sed.lin, sed.gam, test="F")
>>
>>> Analysis of Deviance Table
>>>
>>> Model 1: wm.sed ~ Temp
>>> Model 2: wm.sed ~ s(Temp)
>>>    Resid. Df Resid. Dev         Df  Deviance      F   Pr(>F)
>>> 1 3.5000e+01      3.279
>>> 2 3.5000e+01      3.279 5.5554e-10 2.353e-11 0.4521 6.18e-09 ***
>>>
>>
>>
>> Thanks in advance,
>>
>>
>> Denis Chabot
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>
>



From tlumley at u.washington.edu  Wed Oct  5 16:45:03 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 5 Oct 2005 07:45:03 -0700 (PDT)
Subject: [R] (no subject)
In-Reply-To: <1128519112.4343d5c8e312f@webmail.uct.ac.za>
References: <1128519112.4343d5c8e312f@webmail.uct.ac.za>
Message-ID: <Pine.LNX.4.63a.0510050744200.31857@homer21.u.washington.edu>

On Wed, 5 Oct 2005, allan_sta_staff_sci_main_uct at mail.uct.ac.za wrote:

> hi all
>
> why does the following not work???
>
> this was someone elses code and i couldnt explain why it doesn't work.

I think this is a case of FAQ 7.17: Why does outer() behave strangely with 
my function?

 	-thomas

> m=matrix(c(0,0),2,1)
> v=matrix(c(1,0,0,1),2,2)
>
> Y=function(X1,X2,mu=m,V=v)
> {
> 	X=matrix(c(X1,X2),2,1)
> 	a=(1/((2*pi)*sqrt(det(V))))*exp((-0.5)*(t(X-mu)%*%solve(V)%*%(X-mu)))
> 	a[1]
> }
>
> x1=seq(-1,1)
> x2=x1
>
> Z=outer(x1,x2,FUN="Y",mu=m,V=v)
>
> persp(x1,x2,Z)
>
>
>
>
> my code:
>
> BINORMAL<-function(varx=1,vary=1,covxy=0,meanx=0,meany=0)
> {
> 	#the following function plots the density of a bi variate normal distribution
>
> 	covXY<-matrix(c(varx,covxy,covxy,vary),2,2)
> 	A<-solve(covXY)
>
> 	#up<-max(meanx+4*varx^.5,meanx-4*varx^.5,meany+4*vary^.5,meany-4*vary^.5)
> 	#x <- seq(-up,up,length=50)
> 	#y <- x
>
> 	x <- seq(meanx-3*varx^.5,meanx+3*varx^.5,length=50)
> 	y <- seq(meany-3*vary^.5,meany+3*vary^.5,length=50)
>
> 	f <- function(x,y,...)
> 	{
> 		detA<-det(A)
> 		quadForm<-A[1,1]*(x-meanx)^2+2*A[1,2]*(x-meanx)*(y-meany)+A[2,2]*(y-meany)^2
> 		K<-sqrt(detA)/(2*pi)
> 		exp(-0.5*quadForm)*K
> 	}
>
> 	z <- outer(x, y, f)
>
> 	par(mfrow=c(1,2))
> 	persp(x, y, z,theta = 30, phi = 30,col="white",main="BI-VARIATE NORMAL
> DISTRIBUTION")
> 	contour(x,y,z,main=paste("xy plot, corr(X,Y)= ",(covxy/(varx*vary)^.5)))
>
> 	print("NOTE -sqrt(varx*vary)<=covxy<=sqrt(varx*vary)")
> 	#print(A)
> }
> BINORMAL(varx=1,vary=1,covxy=0,meanx=0,meany=0)
>
> thanx
>
> /allan
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From dlvanbrunt at gmail.com  Wed Oct  5 16:59:00 2005
From: dlvanbrunt at gmail.com (David L. Van Brunt, Ph.D.)
Date: Wed, 5 Oct 2005 09:59:00 -0500
Subject: [R] "Survey" package and NAMCS data... unsure of specification
In-Reply-To: <Pine.LNX.4.63a.0510041611530.5842@homer23.u.washington.edu>
References: <d332d3e10510041444x92a49d1nab313886b969bd83@mail.gmail.com>
	<Pine.LNX.4.63a.0510041611530.5842@homer23.u.washington.edu>
Message-ID: <d332d3e10510050759w7c7e9e32o135b362884f2dc01@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051005/c74685ca/attachment.pl

From ripley at stats.ox.ac.uk  Wed Oct  5 17:10:58 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 Oct 2005 16:10:58 +0100 (BST)
Subject: [R] transparent surface in rgl
In-Reply-To: <4343DBB8.6050701@stats.uwo.ca>
References: <4343D5CE.50804@lumi.latrobe.edu.au>
	<4343DBB8.6050701@stats.uwo.ca>
Message-ID: <Pine.LNX.4.61.0510051556450.32141@gannet.stats>

On Wed, 5 Oct 2005, Duncan Murdoch wrote:

> On 10/5/2005 9:31 AM, Prof. Paul R. Fisher wrote:
>> Hi all
>> I am a complete newbie to this list (just subscribed) and a newcomer to
>> R (an S user from olden times). I have been using scatter3d to create a
>> 3d scatter plot with surface. The graphic is created within the rgl
>> package and I have used rgl.postscript to export it so I can generate a
>> publication quality image. My problem is that the plotted surface is no
>> longer transparent in the postscript output ie. the rgl.spheres that are
>> behind the surface disappear in the postscript image. Can't seem to find
>> any info on this anywhere. Am I doing something wrong? Is there an easy fix?
>
> I think Postscript doesn't support transparency (or at least the version
> of Postscript that the rgl.postcript function targets doesn't support
> it).  You may have to export a bitmapped format using the rgl.snapshot()
> function.  If your original window is very large this may give you good
> enough quality.

Common PostScript (level 2) does not support either full or partial 
transparency (and I guess partial transparency is meant here or the 
surface could just not be plotted).  It would be good to have a rgl.pdf 
which did.  These days PDF is the `portable PostScript' and since version 
1.4 has had alpha-channel supoort.

Ref:

http://en.wikipedia.org/wiki/Transparent_pixels#Transparency_in_PostScript


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From murdoch at stats.uwo.ca  Wed Oct  5 17:33:47 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 05 Oct 2005 11:33:47 -0400
Subject: [R] transparent surface in rgl
In-Reply-To: <Pine.LNX.4.61.0510051556450.32141@gannet.stats>
References: <4343D5CE.50804@lumi.latrobe.edu.au>
	<4343DBB8.6050701@stats.uwo.ca>
	<Pine.LNX.4.61.0510051556450.32141@gannet.stats>
Message-ID: <4343F25B.6040609@stats.uwo.ca>

On 10/5/2005 11:10 AM, Prof Brian Ripley wrote:
> On Wed, 5 Oct 2005, Duncan Murdoch wrote:
> 
>> On 10/5/2005 9:31 AM, Prof. Paul R. Fisher wrote:
>>> Hi all
>>> I am a complete newbie to this list (just subscribed) and a newcomer to
>>> R (an S user from olden times). I have been using scatter3d to create a
>>> 3d scatter plot with surface. The graphic is created within the rgl
>>> package and I have used rgl.postscript to export it so I can generate a
>>> publication quality image. My problem is that the plotted surface is no
>>> longer transparent in the postscript output ie. the rgl.spheres that are
>>> behind the surface disappear in the postscript image. Can't seem to find
>>> any info on this anywhere. Am I doing something wrong? Is there an easy fix?
>>
>> I think Postscript doesn't support transparency (or at least the version
>> of Postscript that the rgl.postcript function targets doesn't support
>> it).  You may have to export a bitmapped format using the rgl.snapshot()
>> function.  If your original window is very large this may give you good
>> enough quality.
> 
> Common PostScript (level 2) does not support either full or partial 
> transparency (and I guess partial transparency is meant here or the 
> surface could just not be plotted).  It would be good to have a rgl.pdf 
> which did.  These days PDF is the `portable PostScript' and since version 
> 1.4 has had alpha-channel supoort.
> 
> Ref:
> 
> http://en.wikipedia.org/wiki/Transparent_pixels#Transparency_in_PostScript
> 
> 

The library we use (GL2PS) apparently supports PDF output, and that's 
one of the format options for rgl.postscript(), so maybe we already do 
support that.  I haven't tried it.

Duncan Murdoch



From spencer.graves at pdf.com  Wed Oct  5 17:51:25 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 05 Oct 2005 10:51:25 -0500
Subject: [R] Problem reading in external data and assigning data.frames
 within R
In-Reply-To: <200510040629.j946TFke015135@smtp.uoregon.edu>
References: <200510040629.j946TFke015135@smtp.uoregon.edu>
Message-ID: <4343F67D.1010808@pdf.com>

(xnew <-- edit(data.frame()).

is equivalent to:

(xnew <-(- edit(data.frame())).

make sense?
spencer graves

Nathan Dieckmann wrote:

>   Hey there,
> 
>     I apologize if this is an irritatingly simple question ... I'm a
> new user.  I can't understand why R flips the sign of all data values
> when reading in external text files (tab delimited or csv) with the
> read.delim or read.csv functions.  The signs of data values also seem
> to be flipped after assigning a new data.frame from within R (xnew <--
> edit(data.frame()).  What am I doing wrong?
> 
>    Any help would be greatly appreciated.  Thanks in advance.
> 
>              -- Nate    
> 
> -----------------------------
> Nathan Dieckmann
> Department of Psychology
> University of Oregon
> Eugene, OR 97403
> (541) 346-4963
> ndieckma at darkwing.uoregon.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From pgreen at umich.edu  Wed Oct  5 17:54:45 2005
From: pgreen at umich.edu (Paul E. Green)
Date: Wed, 5 Oct 2005 11:54:45 -0400
Subject: [R] output a sequence of plots
Message-ID: <001201c5c9c5$1ed12350$62bbd38d@adsroot.itcs.umich.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051005/d0a82be8/attachment.pl

From jfox at mcmaster.ca  Wed Oct  5 18:12:15 2005
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 5 Oct 2005 12:12:15 -0400
Subject: [R] testing non-linear component in mgcv:gam
In-Reply-To: <C5D5EFC2-85E3-4886-835C-7C24B2950D07@globetrotter.net>
Message-ID: <20051005161213.IOPP26102.tomts10-srv.bellnexxia.net@JohnDesktop8300>

Dear Denis,

The chi-square test is formed in analogy to what's done for a GLM: The
difference in residual deviance for the nested models is divided by the
estimated scale parameter -- i.e., the estimated error variance for a model
with normal errors. Otherwise, as you point out, the test would be dependent
upon the scale of the response.

John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Denis Chabot
> Sent: Wednesday, October 05, 2005 9:04 AM
> To: John Fox
> Cc: R list
> Subject: Re: [R] testing non-linear component in mgcv:gam
> 
> Hi John,
> 
> Le 05-10-05 ?? 09:45, John Fox a ??crit :
> 
> > Dear Denis,
> >
> > Take a closer look at the anova table: The models provide identical 
> > fits to the data. The differences in degrees of freedom and 
> deviance 
> > between the two models are essentially zero, 5.5554e-10 and 
> 2.353e-11 
> > respectively.
> >
> > I hope this helps,
> >  John
> This is one of my difficulties. In some examples I found on 
> the web, the difference in deviance is compared directly 
> against the chi- squared distribution. But my y variable has 
> a very small range (between 0 and 0.5, most of the time) so 
> the difference in deviance is always very small and if I 
> compared it against the chi-squared distribution as I have 
> seen done in examples, the non-linear component would always 
> be not significant. Yet it is (with one exception), tested 
> with both mgcv:gam and gam:gam. I think the examples I have 
> read were wrong in this regard, the "scale" factor seen in 
> mgcv output seems to intervene. But exactly how is still 
> mysterious to me and I hesitate to judge the size of the 
> deviance difference myself.
> 
> I agree it is near zero in my example. I guess I need to have 
> more experience with these models to better interpret the output...
> 
> Denis
> >
> >
> >> -----Original Message-----
> >> From: r-help-bounces at stat.math.ethz.ch 
> >> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Denis Chabot
> >> Sent: Wednesday, October 05, 2005 8:22 AM
> >> To: r-help at stat.math.ethz.ch
> >> Subject: [R] testing non-linear component in mgcv:gam
> >>
> >> Hi,
> >>
> >> I need further help with my GAMs. Most models I test are very 
> >> obviously non-linear. Yet, to be on the safe side, I report the 
> >> significance of the smooth (default output of mgcv's
> >> summary.gam) and confirm it deviates significantly from linearity.
> >>
> >> I do the latter by fitting a second model where the same 
> predictor is 
> >> entered without the s(), and then use anova.gam to compare 
> the two. I 
> >> thought this was the equivalent of the default output of anova.gam 
> >> using package gam instead of mgcv.
> >>
> >> I wonder if this procedure is correct because one of my models 
> >> appears to be linear. In fact mgcv estimates df to be 
> exactly 1.0 so 
> >> I could have stopped there. However I inadvertently repeated the 
> >> procedure outlined above. I would have thought in this case the 
> >> anova.gam comparing the smooth and the linear fit would 
> for sure have 
> >> been not significant.
> >> To my surprise, P was 6.18e-09!
> >>
> >> Am I doing something wrong when I attempt to confirm the non- 
> >> parametric part a smoother is significant? Here is my example case 
> >> where the relationship does appear to be linear:
> >>
> >> library(mgcv)
> >>
> >>> This is mgcv 1.3-7
> >>>
> >> Temp <- c(-1.38, -1.12, -0.88, -0.62, -0.38, -0.12, 0.12, 
> 0.38, 0.62, 
> >> 0.88, 1.12,
> >>             1.38, 1.62, 1.88, 2.12, 2.38, 2.62, 2.88, 3.12, 3.38, 
> >> 3.62, 3.88,
> >>             4.12, 4.38, 4.62, 4.88, 5.12, 5.38, 5.62, 5.88, 6.12, 
> >> 6.38, 6.62, 6.88,
> >>             7.12, 8.38, 13.62)
> >> N.sets <- c(2, 6, 3, 9, 26, 15, 34, 21, 30, 18, 28, 27, 
> 27, 29, 31, 
> >> 22, 26, 24, 23,
> >>              15, 25, 24, 27, 19, 26, 24, 22, 13, 10, 2, 5, 
> 3, 1, 1, 
> >> 1, 1, 1) wm.sed <- c(0.000000000, 0.016129032, 0.000000000, 
> >> 0.062046512, 0.396459596, 0.189082949,
> >>              0.054757925, 0.142810440, 0.168005168, 0.180804428, 
> >> 0.111439628, 0.128799505,
> >>              0.193707937, 0.105921610, 0.103497845, 0.028591837, 
> >> 0.217894389, 0.020535469,
> >>              0.080389068, 0.105234450, 0.070213450, 0.050771363, 
> >> 0.042074434, 0.102348837,
> >>              0.049748344, 0.019100478, 0.005203125, 0.101711864, 
> >> 0.000000000, 0.000000000,
> >>              0.014808824, 0.000000000, 0.222000000, 0.167000000, 
> >> 0.000000000, 0.000000000,
> >>              0.000000000)
> >>
> >> sed.gam <- gam(wm.sed~s(Temp),weight=N.sets)
> >> summary.gam(sed.gam)
> >>
> >>> Family: gaussian
> >>> Link function: identity
> >>>
> >>> Formula:
> >>> wm.sed ~ s(Temp)
> >>>
> >>> Parametric coefficients:
> >>>             Estimate Std. Error t value Pr(>|t|)
> >>> (Intercept)  0.08403    0.01347   6.241 3.73e-07 ***
> >>> ---
> >>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >>>
> >>> Approximate significance of smooth terms:
> >>>         edf Est.rank     F  p-value
> >>> s(Temp)   1        1 13.95 0.000666 ***
> >>> ---
> >>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >>>
> >>> R-sq.(adj) =  0.554   Deviance explained = 28.5%
> >>> GCV score = 0.09904   Scale est. = 0.093686  n = 37
> >>>
> >>
> >> # testing non-linear contribution
> >> sed.lin <- gam(wm.sed~Temp,weight=N.sets)
> >> summary.gam(sed.lin)
> >>
> >>> Family: gaussian
> >>> Link function: identity
> >>>
> >>> Formula:
> >>> wm.sed ~ Temp
> >>>
> >>> Parametric coefficients:
> >>>              Estimate Std. Error t value Pr(>|t|)
> >>> (Intercept)  0.162879   0.019847   8.207 1.14e-09 ***
> >>> Temp        -0.023792   0.006369  -3.736 0.000666 ***
> >>> ---
> >>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >>>
> >>>
> >>> R-sq.(adj) =  0.554   Deviance explained = 28.5%
> >>> GCV score = 0.09904   Scale est. = 0.093686  n = 37
> >>>
> >> anova.gam(sed.lin, sed.gam, test="F")
> >>
> >>> Analysis of Deviance Table
> >>>
> >>> Model 1: wm.sed ~ Temp
> >>> Model 2: wm.sed ~ s(Temp)
> >>>    Resid. Df Resid. Dev         Df  Deviance      F   Pr(>F)
> >>> 1 3.5000e+01      3.279
> >>> 2 3.5000e+01      3.279 5.5554e-10 2.353e-11 0.4521 6.18e-09 ***
> >>>
> >>
> >>
> >> Thanks in advance,
> >>
> >>
> >> Denis Chabot
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list 
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide!
> >> http://www.R-project.org/posting-guide.html
> >>
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From vincent at 7d4.com  Wed Oct  5 18:13:56 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Wed, 05 Oct 2005 18:13:56 +0200
Subject: [R] output a sequence of plots
In-Reply-To: <001201c5c9c5$1ed12350$62bbd38d@adsroot.itcs.umich.edu>
References: <001201c5c9c5$1ed12350$62bbd38d@adsroot.itcs.umich.edu>
Message-ID: <4343FBC4.4000206@7d4.com>

Paul E. Green a ??crit :

> ... Any solutions that would
> save me from repeating this code 120 times? Can I
> pass arguments inside quotes? Can I write a function
> to do this?

as a toy example, with some of the usable functions :
(see ?dir)

fct00 = function()
{
rep0 = "data";	
fichier = dir(rep0, pattern="*.emf");
nbfichiers = length(fichier);

for (i in 1:nbfichiers)
	{
#	do the job
	}
}



From johnrbtj at ipaisley.com  Wed Oct  5 18:20:40 2005
From: johnrbtj at ipaisley.com (Philip Schneider)
Date: Wed, 5 Oct 2005 12:20:40 -0400
Subject: [R] Hiring people for great job from home
Message-ID: <665902638547.524626319451@ipaisley.com>

Sehr geehrte Frau/Herr, send


Suchen Sie eine Arbeit? hard

Eine der besten Finanzgesellschaften in Osteuropa freut sich sehr 
darauf,
Ihnen eine ausgezeichnete Arbeit vorzuschlagen, die wirklich ein gro?es
Einkommen erm?glicht!! Sie sollen nichts investieren oder keine Waren
kaufen, um bei uns zu arbeiten. art

Kein Geld anzufangen? told


?ber uns:

Real Capitalz Finance Company, Litauen wurde im Jahre 1995 von einer
Gruppe der Antiquit?texperten gestiftet. Bis heute hat sich die
Gesellschaft aus einer kleinen Firma mit 7 Mitarbeitern zu einer
internationalen Gruppe mit einigen Vertretungen in verschiednen L?ndern
der Welt entwickelt. Heute sind wir nicht nur mit der 
Antiquit?tshandlung
besch?ftigt, sondern organisieren auch internationale Ausstellungen,
Seminare, Toure und viele andere Veranstaltungen. F?r mehr 
Informationen:
http://www.trustbizjob.com


Unsere Arbeitsstellen:

Jetzt macht die Klientschaft der Gesellschaft weltweite
Finanztransaktionen, einschlie?lich Australien, aber wegen der
ungen?genden Vollkommenheit des australischen Bankservicen haben wir
einige Schwierigkeiten bei der Reorganisation und Transformation 
unseres
Gesch?fts. Deswegen haben wir uns entschieden, Zweigstellen zu 
errichten,
und dazu brauchen wir Mitarbeiter aus Australien. Wir suchen
Finanzassistenten, die die Zahlungen der Kunden erhalten werden. Wir
schlagen Fernarbeit vor, aber wenn wir in Australien Zweigstellen
errichten, haben Sie dann die M?glichkeit auch im Office zu arbeiten. chance

Wir suchen Finanzassistenten, die die Bezahlung der Kunden durch
Bankanweisung akzeptieren werden. Wegen der Mangelhaftigkeit des
Banksystems, haben australische Partner von unseren Kunden einige
Schwierigkeiten mit Bankanweisungen und Schecks in Osteuropa.  surf

Sie k?nnen 10% Kommission von jeder Bankanweisung bekommen, die mit
unserem Gesch?ft zu tun hat. Das ?brige ist an unseren Vertreter zu 
senden
durch Western Union Service. Alle Western Union Geb?hre werden von uns
bezahlt. Im Durchschnitt werden Sie 2,000 US Dollars pro Woche 
bekommen. inside

Wir glauben, dass Sie bei unserer Gesellschaft gute Perspektiven f?r 
die
Zukunft finden und Vieles erreichen k?nnen. Wenn unser Vorschlag f?r 
Sie
interessant ist, bitte schicken Sie ein E-Mail an unser HR-Office. Wir
werden gern Ihre Fragen beantworten. provide

Wenn Sie bereit sind mit uns zu arbeiten, bitte registrieren Sie sich 
an
unsrer Website um personale Account f?r unsere Website zu bekommen. In 
24
Stunden nach der Registration auf Web werden Sie einen Vertrag von uns 
bei
E-Mail bekommen und wir beginnen mit Ihnen zu arbeiten. own

Mit freundlichen Gr?sse high
WorldWide Company Lithuania big
contact at realjob-inworld.com



From mschwartz at mn.rr.com  Mon Oct  3 22:58:34 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Mon, 03 Oct 2005 15:58:34 -0500
Subject: [R] spline.des
In-Reply-To: <200510032028.j93KS6Af012861@saturn.software.umn.edu>
References: <200510032028.j93KS6Af012861@saturn.software.umn.edu>
Message-ID: <1128373114.5957.38.camel@localhost.localdomain>

On Mon, 2005-10-03 at 15:28 -0500, lforzani wrote:
> Hello, I am using library fda and I can not run a lot of functions because
> I receive the error:
> 
> Error in bsplineS(evalarg, breaks, norder, nderiv) : 
>         couldn't find function "spline.des"
> 
> 
> do you know how I can fix that? Thnaks. Liliana


spline.des() is in the 'splines' package, installed with the basic R
distribution. It appears that bsplineS() has a dependency on this not
otherwise referenced in the fda package documentation. Looks like fda
has not been updated in some time as well.

I have cc'd Jim Ramsay on this reply as an FYI.

You probably need a:

  library(splines)

before calling your code above.


HTH,

Marc Schwartz



From murdoch at stats.uwo.ca  Wed Oct  5 20:12:05 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 05 Oct 2005 14:12:05 -0400
Subject: [R] transparent surface in rgl
In-Reply-To: <4343F25B.6040609@stats.uwo.ca>
References: <4343D5CE.50804@lumi.latrobe.edu.au>	<4343DBB8.6050701@stats.uwo.ca>	<Pine.LNX.4.61.0510051556450.32141@gannet.stats>
	<4343F25B.6040609@stats.uwo.ca>
Message-ID: <43441775.5080907@stats.uwo.ca>

On 10/5/2005 11:33 AM, Duncan Murdoch wrote:
> On 10/5/2005 11:10 AM, Prof Brian Ripley wrote:
>> On Wed, 5 Oct 2005, Duncan Murdoch wrote:
>> 
>>> On 10/5/2005 9:31 AM, Prof. Paul R. Fisher wrote:
>>>> Hi all
>>>> I am a complete newbie to this list (just subscribed) and a newcomer to
>>>> R (an S user from olden times). I have been using scatter3d to create a
>>>> 3d scatter plot with surface. The graphic is created within the rgl
>>>> package and I have used rgl.postscript to export it so I can generate a
>>>> publication quality image. My problem is that the plotted surface is no
>>>> longer transparent in the postscript output ie. the rgl.spheres that are
>>>> behind the surface disappear in the postscript image. Can't seem to find
>>>> any info on this anywhere. Am I doing something wrong? Is there an easy fix?
>>>
>>> I think Postscript doesn't support transparency (or at least the version
>>> of Postscript that the rgl.postcript function targets doesn't support
>>> it).  You may have to export a bitmapped format using the rgl.snapshot()
>>> function.  If your original window is very large this may give you good
>>> enough quality.
>> 
>> Common PostScript (level 2) does not support either full or partial 
>> transparency (and I guess partial transparency is meant here or the 
>> surface could just not be plotted).  It would be good to have a rgl.pdf 
>> which did.  These days PDF is the `portable PostScript' and since version 
>> 1.4 has had alpha-channel supoort.
>> 
>> Ref:
>> 
>> http://en.wikipedia.org/wiki/Transparent_pixels#Transparency_in_PostScript
>> 
>> 
> 
> The library we use (GL2PS) apparently supports PDF output, and that's 
> one of the format options for rgl.postscript(), so maybe we already do 
> support that.  I haven't tried it.
> 

I've just checked, and currently transparency isn't supported even with 
PDF output.  I tried updating the version of GL2PS and turning on 
transparency support, but so far no luck at all.

If anyone wants to follow up on this I think it would be a nice 
addition, but otherwise, I think the PNG output is the best we can do.

Duncan Murdoch



From helprhelp at gmail.com  Wed Oct  5 21:26:54 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Wed, 5 Oct 2005 14:26:54 -0500
Subject: [R] pca in dimension reduction
Message-ID: <cdf817830510051226w11eafc43v47c573e94223f6c7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051005/0c2a7443/attachment.pl

From chabotd at globetrotter.net  Wed Oct  5 22:32:36 2005
From: chabotd at globetrotter.net (Denis Chabot)
Date: Wed, 05 Oct 2005 16:32:36 -0400
Subject: [R] testing non-linear component in mgcv:gam
In-Reply-To: <20051005134502.NDQD26550.tomts20-srv.bellnexxia.net@JohnDesktop8300>
References: <20051005134502.NDQD26550.tomts20-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <01DD3C25-9071-421B-9240-EE015021D69C@globetrotter.net>

Thank you everyone for your help, but my introduction to GAM is  
turning my brain to mush. I thought the one part of the output I  
understood the best was r-sq (adj), but now even this is becoming foggy.

In my original message I mentioned a gam fit that turns out to be a  
linear fit. By curiosity I analysed it with a linear predictor only  
with mgcv package, and then as a linear model. The output was  
identical in both, but the r-sq (adj) was 0.55 in mgcv and 0.26 in  
lm. In lm I hope that my interpretation that 26% of the variance in y  
is explained by the linear relationship with x is valid. Then what  
does r2 mean in mgcv?

Denis
 > summary.gam(lin)

Family: gaussian
Link function: identity

Formula:
wm.sed ~ Temp

Parametric coefficients:
              Estimate Std. Error t value Pr(>|t|)
(Intercept)  0.162879   0.019847   8.207 1.14e-09 ***
Temp        -0.023792   0.006369  -3.736 0.000666 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


R-sq.(adj) =  0.554   Deviance explained = 28.5%
GCV score = 0.09904   Scale est. = 0.093686  n = 37


 > summary(sed.true.lin)

Call:
lm(formula = wm.sed ~ Temp, weights = N.sets)

Residuals:
     Min      1Q  Median      3Q     Max
-0.6138 -0.1312 -0.0325  0.1089  1.1449

Coefficients:
              Estimate Std. Error t value Pr(>|t|)
(Intercept)  0.162879   0.019847   8.207 1.14e-09 ***
Temp        -0.023792   0.006369  -3.736 0.000666 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.3061 on 35 degrees of freedom
Multiple R-Squared: 0.285,    Adjusted R-squared: 0.2646
F-statistic: 13.95 on 1 and 35 DF,  p-value: 0.000666


Le 05-10-05 à 09:45, John Fox a écrit :

> Dear Denis,
>
> Take a closer look at the anova table: The models provide identical  
> fits to
> the data. The differences in degrees of freedom and deviance  
> between the two
> models are essentially zero, 5.5554e-10 and 2.353e-11 respectively.
>
> I hope this helps,
>  John
>
> --------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> 905-525-9140x23604
> http://socserv.mcmaster.ca/jfox
> --------------------------------
>
>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Denis Chabot
>> Sent: Wednesday, October 05, 2005 8:22 AM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] testing non-linear component in mgcv:gam
>>
>> Hi,
>>
>> I need further help with my GAMs. Most models I test are very
>> obviously non-linear. Yet, to be on the safe side, I report
>> the significance of the smooth (default output of mgcv's
>> summary.gam) and confirm it deviates significantly from linearity.
>>
>> I do the latter by fitting a second model where the same
>> predictor is entered without the s(), and then use anova.gam
>> to compare the two. I thought this was the equivalent of the
>> default output of anova.gam using package gam instead of mgcv.
>>
>> I wonder if this procedure is correct because one of my
>> models appears to be linear. In fact mgcv estimates df to be
>> exactly 1.0 so I could have stopped there. However I
>> inadvertently repeated the procedure outlined above. I would
>> have thought in this case the anova.gam comparing the smooth
>> and the linear fit would for sure have been not significant.
>> To my surprise, P was 6.18e-09!
>>
>> Am I doing something wrong when I attempt to confirm the non-
>> parametric part a smoother is significant? Here is my example
>> case where the relationship does appear to be linear:
>>
>> library(mgcv)
>>
>>> This is mgcv 1.3-7
>>>
>> Temp <- c(-1.38, -1.12, -0.88, -0.62, -0.38, -0.12, 0.12,
>> 0.38, 0.62, 0.88, 1.12,
>>             1.38, 1.62, 1.88, 2.12, 2.38, 2.62, 2.88, 3.12,
>> 3.38, 3.62, 3.88,
>>             4.12, 4.38, 4.62, 4.88, 5.12, 5.38, 5.62, 5.88,
>> 6.12, 6.38, 6.62, 6.88,
>>             7.12, 8.38, 13.62)
>> N.sets <- c(2, 6, 3, 9, 26, 15, 34, 21, 30, 18, 28, 27, 27,
>> 29, 31, 22, 26, 24, 23,
>>              15, 25, 24, 27, 19, 26, 24, 22, 13, 10, 2, 5, 3,
>> 1, 1, 1, 1, 1) wm.sed <- c(0.000000000, 0.016129032,
>> 0.000000000, 0.062046512, 0.396459596, 0.189082949,
>>              0.054757925, 0.142810440, 0.168005168,
>> 0.180804428, 0.111439628, 0.128799505,
>>              0.193707937, 0.105921610, 0.103497845,
>> 0.028591837, 0.217894389, 0.020535469,
>>              0.080389068, 0.105234450, 0.070213450,
>> 0.050771363, 0.042074434, 0.102348837,
>>              0.049748344, 0.019100478, 0.005203125,
>> 0.101711864, 0.000000000, 0.000000000,
>>              0.014808824, 0.000000000, 0.222000000,
>> 0.167000000, 0.000000000, 0.000000000,
>>              0.000000000)
>>
>> sed.gam <- gam(wm.sed~s(Temp),weight=N.sets)
>> summary.gam(sed.gam)
>>
>>> Family: gaussian
>>> Link function: identity
>>>
>>> Formula:
>>> wm.sed ~ s(Temp)
>>>
>>> Parametric coefficients:
>>>             Estimate Std. Error t value Pr(>|t|)
>>> (Intercept)  0.08403    0.01347   6.241 3.73e-07 ***
>>> ---
>>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>>
>>> Approximate significance of smooth terms:
>>>         edf Est.rank     F  p-value
>>> s(Temp)   1        1 13.95 0.000666 ***
>>> ---
>>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>>
>>> R-sq.(adj) =  0.554   Deviance explained = 28.5%
>>> GCV score = 0.09904   Scale est. = 0.093686  n = 37
>>>
>>
>> # testing non-linear contribution
>> sed.lin <- gam(wm.sed~Temp,weight=N.sets)
>> summary.gam(sed.lin)
>>
>>> Family: gaussian
>>> Link function: identity
>>>
>>> Formula:
>>> wm.sed ~ Temp
>>>
>>> Parametric coefficients:
>>>              Estimate Std. Error t value Pr(>|t|)
>>> (Intercept)  0.162879   0.019847   8.207 1.14e-09 ***
>>> Temp        -0.023792   0.006369  -3.736 0.000666 ***
>>> ---
>>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>>
>>>
>>> R-sq.(adj) =  0.554   Deviance explained = 28.5%
>>> GCV score = 0.09904   Scale est. = 0.093686  n = 37
>>>
>> anova.gam(sed.lin, sed.gam, test="F")
>>
>>> Analysis of Deviance Table
>>>
>>> Model 1: wm.sed ~ Temp
>>> Model 2: wm.sed ~ s(Temp)
>>>    Resid. Df Resid. Dev         Df  Deviance      F   Pr(>F)
>>> 1 3.5000e+01      3.279
>>> 2 3.5000e+01      3.279 5.5554e-10 2.353e-11 0.4521 6.18e-09 ***
>>>
>>
>>
>> Thanks in advance,
>>
>>
>> Denis Chabot
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>
>



From gunter.berton at gene.com  Wed Oct  5 22:40:28 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 5 Oct 2005 13:40:28 -0700
Subject: [R] pca in dimension reduction
In-Reply-To: <cdf817830510051226w11eafc43v47c573e94223f6c7@mail.gmail.com>
Message-ID: <200510052040.j95KeS2v008885@compton.gene.com>

?princomp  ?prcomp give examples

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Weiwei Shi
> Sent: Wednesday, October 05, 2005 12:27 PM
> To: r-help
> Subject: [R] pca in dimension reduction
> 
> Hi, there:
> I am wondering if anyone here can provide an example using pca doing
> dimension reduction for a dataset.
> The dataset can be n*q (n>=q or n<=q).
> 
> As to dimension reduction, are there other implementations 
> for like ICA,
> Isomap, Locally Linear Embedding...
> 
> Thanks,
> 
> weiwei
> 
> --
> Weiwei Shi, Ph.D
> 
> "Did you always know?"
> "No, I did not. But I believed..."
> ---Matrix III
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From macq at llnl.gov  Wed Oct  5 22:42:30 2005
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 5 Oct 2005 13:42:30 -0700
Subject: [R] output a sequence of plots
In-Reply-To: <001201c5c9c5$1ed12350$62bbd38d@adsroot.itcs.umich.edu>
References: <001201c5c9c5$1ed12350$62bbd38d@adsroot.itcs.umich.edu>
Message-ID: <p06210204bf69e9c08bbb@[128.115.153.6]>

Something similar to this
(but I haven't tested)

mydf <- data.frame(xx=rnorm(100), yy=rnorm(100), zz=rnorm(100))

for (nm in names(mydf)) {

   fnm <- file.path('c:',paste(nm,'.emf',sep=''))
   cat('Creating histogram in file',fnm,'\n')
   win.metafile( filename=fnm)
   hist(mydf[[nm]])                                          # or 
hist(mydf[,nm])
   dev.off()

}

-Don

At 11:54 AM -0400 10/5/05, Paul E. Green wrote:
>I can output two histograms of variables
>AXFILTERED and AZPTOP as follows:
>
>win.metafile(filename="C:/AXFILTERED.emf",pointsize=12)
>hist(AXFILTERED,breaks=40)
>dev.off()
>
>win.metafile(filename="C:/AZPTOP.emf",pointsize=12)
>hist(AZPTOP,breaks=40)
>dev.off()
>
>But, I actually have a dataframe of 120 variables that I
>would like histograms of. Any solutions that would
>save me from repeating this code 120 times? Can I
>pass arguments inside quotes? Can I write a function
>to do this?
>
>Paul Green
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From jfox at mcmaster.ca  Wed Oct  5 23:01:58 2005
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 5 Oct 2005 17:01:58 -0400
Subject: [R] testing non-linear component in mgcv:gam
In-Reply-To: <01DD3C25-9071-421B-9240-EE015021D69C@globetrotter.net>
Message-ID: <20051005210157.KZTV26102.tomts10-srv.bellnexxia.net@JohnDesktop8300>

Dear Denis,

You got me: I would have thought from ?summary.gam that this would be the
same as the adjusted R^2 for a linear model. Note, however, that the
percentage of deviance explained checks with the R^2 from the linear model,
as expected.

Maybe you should address this question to the package author.

Regards,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: Denis Chabot [mailto:chabotd at globetrotter.net] 
> Sent: Wednesday, October 05, 2005 3:33 PM
> To: John Fox
> Cc: R list
> Subject: Re: [R] testing non-linear component in mgcv:gam
> 
> Thank you everyone for your help, but my introduction to GAM 
> is turning my brain to mush. I thought the one part of the 
> output I understood the best was r-sq (adj), but now even 
> this is becoming foggy.
> 
> In my original message I mentioned a gam fit that turns out 
> to be a linear fit. By curiosity I analysed it with a linear 
> predictor only with mgcv package, and then as a linear model. 
> The output was identical in both, but the r-sq (adj) was 0.55 
> in mgcv and 0.26 in lm. In lm I hope that my interpretation 
> that 26% of the variance in y is explained by the linear 
> relationship with x is valid. Then what does r2 mean in mgcv?
> 
> Denis
>  > summary.gam(lin)
> 
> Family: gaussian
> Link function: identity
> 
> Formula:
> wm.sed ~ Temp
> 
> Parametric coefficients:
>               Estimate Std. Error t value Pr(>|t|)
> (Intercept)  0.162879   0.019847   8.207 1.14e-09 ***
> Temp        -0.023792   0.006369  -3.736 0.000666 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> 
> R-sq.(adj) =  0.554   Deviance explained = 28.5%
> GCV score = 0.09904   Scale est. = 0.093686  n = 37
> 
> 
>  > summary(sed.true.lin)
> 
> Call:
> lm(formula = wm.sed ~ Temp, weights = N.sets)
> 
> Residuals:
>      Min      1Q  Median      3Q     Max
> -0.6138 -0.1312 -0.0325  0.1089  1.1449
> 
> Coefficients:
>               Estimate Std. Error t value Pr(>|t|)
> (Intercept)  0.162879   0.019847   8.207 1.14e-09 ***
> Temp        -0.023792   0.006369  -3.736 0.000666 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Residual standard error: 0.3061 on 35 degrees of freedom
> Multiple R-Squared: 0.285,    Adjusted R-squared: 0.2646
> F-statistic: 13.95 on 1 and 35 DF,  p-value: 0.000666
> 
> 
> Le 05-10-05 ?? 09:45, John Fox a ??crit :
> 
> > Dear Denis,
> >
> > Take a closer look at the anova table: The models provide identical 
> > fits to the data. The differences in degrees of freedom and 
> deviance 
> > between the two models are essentially zero, 5.5554e-10 and 
> 2.353e-11 
> > respectively.
> >
> > I hope this helps,
> >  John
> >
> > --------------------------------
> > John Fox
> > Department of Sociology
> > McMaster University
> > Hamilton, Ontario
> > Canada L8S 4M4
> > 905-525-9140x23604
> > http://socserv.mcmaster.ca/jfox
> > --------------------------------
> >
> >
> >> -----Original Message-----
> >> From: r-help-bounces at stat.math.ethz.ch 
> >> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Denis Chabot
> >> Sent: Wednesday, October 05, 2005 8:22 AM
> >> To: r-help at stat.math.ethz.ch
> >> Subject: [R] testing non-linear component in mgcv:gam
> >>
> >> Hi,
> >>
> >> I need further help with my GAMs. Most models I test are very 
> >> obviously non-linear. Yet, to be on the safe side, I report the 
> >> significance of the smooth (default output of mgcv's
> >> summary.gam) and confirm it deviates significantly from linearity.
> >>
> >> I do the latter by fitting a second model where the same 
> predictor is 
> >> entered without the s(), and then use anova.gam to compare 
> the two. I 
> >> thought this was the equivalent of the default output of anova.gam 
> >> using package gam instead of mgcv.
> >>
> >> I wonder if this procedure is correct because one of my models 
> >> appears to be linear. In fact mgcv estimates df to be 
> exactly 1.0 so 
> >> I could have stopped there. However I inadvertently repeated the 
> >> procedure outlined above. I would have thought in this case the 
> >> anova.gam comparing the smooth and the linear fit would 
> for sure have 
> >> been not significant.
> >> To my surprise, P was 6.18e-09!
> >>
> >> Am I doing something wrong when I attempt to confirm the non- 
> >> parametric part a smoother is significant? Here is my example case 
> >> where the relationship does appear to be linear:
> >>
> >> library(mgcv)
> >>
> >>> This is mgcv 1.3-7
> >>>
> >> Temp <- c(-1.38, -1.12, -0.88, -0.62, -0.38, -0.12, 0.12, 
> 0.38, 0.62, 
> >> 0.88, 1.12,
> >>             1.38, 1.62, 1.88, 2.12, 2.38, 2.62, 2.88, 3.12, 3.38, 
> >> 3.62, 3.88,
> >>             4.12, 4.38, 4.62, 4.88, 5.12, 5.38, 5.62, 5.88, 6.12, 
> >> 6.38, 6.62, 6.88,
> >>             7.12, 8.38, 13.62)
> >> N.sets <- c(2, 6, 3, 9, 26, 15, 34, 21, 30, 18, 28, 27, 
> 27, 29, 31, 
> >> 22, 26, 24, 23,
> >>              15, 25, 24, 27, 19, 26, 24, 22, 13, 10, 2, 5, 
> 3, 1, 1, 
> >> 1, 1, 1) wm.sed <- c(0.000000000, 0.016129032, 0.000000000, 
> >> 0.062046512, 0.396459596, 0.189082949,
> >>              0.054757925, 0.142810440, 0.168005168, 0.180804428, 
> >> 0.111439628, 0.128799505,
> >>              0.193707937, 0.105921610, 0.103497845, 0.028591837, 
> >> 0.217894389, 0.020535469,
> >>              0.080389068, 0.105234450, 0.070213450, 0.050771363, 
> >> 0.042074434, 0.102348837,
> >>              0.049748344, 0.019100478, 0.005203125, 0.101711864, 
> >> 0.000000000, 0.000000000,
> >>              0.014808824, 0.000000000, 0.222000000, 0.167000000, 
> >> 0.000000000, 0.000000000,
> >>              0.000000000)
> >>
> >> sed.gam <- gam(wm.sed~s(Temp),weight=N.sets)
> >> summary.gam(sed.gam)
> >>
> >>> Family: gaussian
> >>> Link function: identity
> >>>
> >>> Formula:
> >>> wm.sed ~ s(Temp)
> >>>
> >>> Parametric coefficients:
> >>>             Estimate Std. Error t value Pr(>|t|)
> >>> (Intercept)  0.08403    0.01347   6.241 3.73e-07 ***
> >>> ---
> >>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >>>
> >>> Approximate significance of smooth terms:
> >>>         edf Est.rank     F  p-value
> >>> s(Temp)   1        1 13.95 0.000666 ***
> >>> ---
> >>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >>>
> >>> R-sq.(adj) =  0.554   Deviance explained = 28.5%
> >>> GCV score = 0.09904   Scale est. = 0.093686  n = 37
> >>>
> >>
> >> # testing non-linear contribution
> >> sed.lin <- gam(wm.sed~Temp,weight=N.sets)
> >> summary.gam(sed.lin)
> >>
> >>> Family: gaussian
> >>> Link function: identity
> >>>
> >>> Formula:
> >>> wm.sed ~ Temp
> >>>
> >>> Parametric coefficients:
> >>>              Estimate Std. Error t value Pr(>|t|)
> >>> (Intercept)  0.162879   0.019847   8.207 1.14e-09 ***
> >>> Temp        -0.023792   0.006369  -3.736 0.000666 ***
> >>> ---
> >>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >>>
> >>>
> >>> R-sq.(adj) =  0.554   Deviance explained = 28.5%
> >>> GCV score = 0.09904   Scale est. = 0.093686  n = 37
> >>>
> >> anova.gam(sed.lin, sed.gam, test="F")
> >>
> >>> Analysis of Deviance Table
> >>>
> >>> Model 1: wm.sed ~ Temp
> >>> Model 2: wm.sed ~ s(Temp)
> >>>    Resid. Df Resid. Dev         Df  Deviance      F   Pr(>F)
> >>> 1 3.5000e+01      3.279
> >>> 2 3.5000e+01      3.279 5.5554e-10 2.353e-11 0.4521 6.18e-09 ***
> >>>
> >>
> >>
> >> Thanks in advance,
> >>
> >>
> >> Denis Chabot
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list 
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide!
> >> http://www.R-project.org/posting-guide.html
> >>
> >
> >
>



From helprhelp at gmail.com  Wed Oct  5 23:06:06 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Wed, 5 Oct 2005 16:06:06 -0500
Subject: [R] pca in dimension reduction
In-Reply-To: <200510052040.j95KeS2v008885@compton.gene.com>
References: <cdf817830510051226w11eafc43v47c573e94223f6c7@mail.gmail.com>
	<200510052040.j95KeS2v008885@compton.gene.com>
Message-ID: <cdf817830510051406n6d6e0b66k80a22d7b581c9679@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051005/a623024d/attachment.pl

From tpapp at Princeton.EDU  Wed Oct  5 23:36:43 2005
From: tpapp at Princeton.EDU (Tamas K Papp)
Date: Wed, 5 Oct 2005 17:36:43 -0400
Subject: [R] mapply for matrices
Message-ID: <20051005213643.GA5173@tpapp.student.princeton.edu>

Hi,

I have a matrix A and a vector b, and would like to apply a function
f(a,b) to the rows of A and the elements of b.  Eg

A <- matrix(1:4,2,2)
b <- c(5,7)
f <- function(a,b) {sum(a)*b}

myapply(f,A=A,b=b)

would give

(1+3)*5 = 20
(2+4)*7 = 42

I found mapply, but it does not work for matrices.  How could I do
this without loops?  The above is just a toy example, the problem I am
using this for has larger matrices, and f is a computation that does
not handle vectors.

One thing I thought of is

sapply(seq(along=b),function(i,A,b){f(A[i,],b[i])},A=A,b=b)

but this is not very elegant.  I checked the archives and found nothing.

Thank you,

Tamas

-- 
Bayesian statistics is difficult in the sense that thinking is difficult.
--Donald A. Berry, American Statistician 51:242 (1997)



From jingli71 at yahoo.com  Thu Oct  6 00:19:39 2005
From: jingli71 at yahoo.com (Claire Lee)
Date: Wed, 5 Oct 2005 15:19:39 -0700 (PDT)
Subject: [R] problem in installing a package
Message-ID: <20051005221939.92114.qmail@web60211.mail.yahoo.com>

I'm using R in Windows XP. I created a package myself.
I've used R CMD check to check it. Everything seems OK
except the latex. I get the error message:
* checking bbHist-manual.tex ... ERROR
LaTeX errors when creating DVI version.
This typically indicates Rd problems.

I ignored it because I didn't want to submit it to
CRAN.

Then I tried to use R CMD INSTALL to install it. First
I get: 
"mv: cannot move `c:/PROGRA~1/R/rw2011/library/bbHist'
to `c:/PROGRA~1/R/rw2011/library/00LOCK/bbHist
': Permission denied" 

and a bunch of making DLL errors.  Then when I tried a
second time, I get:

open(c:/progra~1/r/rw2011/library/bbHist/DESCRIPTION):
No such file or directory

I can see a 00LOCK directory is created in the
c:/PROGRA~1/R/rw2011/library directory. Any idea why
this is happening?

Thanks.

Claire



From gunter.berton at gene.com  Thu Oct  6 00:28:29 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 5 Oct 2005 15:28:29 -0700
Subject: [R] mapply for matrices
In-Reply-To: <20051005213643.GA5173@tpapp.student.princeton.edu>
Message-ID: <200510052228.j95MSUPZ022275@hertz.gene.com>

At the risk of being dense or R-ically incorrect, why do it without loops
when it is natural and easy to do it with them? More to the point:

1. vectorization speeds things up

2. apply commands are basically looping, not vectorization. Their advantage
is coding transparency, not speed

Flog me if you will ...

(of course constructs like sapply(index,function(index, A,b)...,A=A,b=b )
always work -- but why bother? )

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Tamas K Papp
> Sent: Wednesday, October 05, 2005 2:37 PM
> To: R-help mailing list
> Subject: [R] mapply for matrices
> 
> Hi,
> 
> I have a matrix A and a vector b, and would like to apply a function
> f(a,b) to the rows of A and the elements of b.  Eg
> 
> A <- matrix(1:4,2,2)
> b <- c(5,7)
> f <- function(a,b) {sum(a)*b}
> 
> myapply(f,A=A,b=b)
> 
> would give
> 
> (1+3)*5 = 20
> (2+4)*7 = 42
> 
> I found mapply, but it does not work for matrices.  How could I do
> this without loops?  The above is just a toy example, the problem I am
> using this for has larger matrices, and f is a computation that does
> not handle vectors.
> 
> One thing I thought of is
> 
> sapply(seq(along=b),function(i,A,b){f(A[i,],b[i])},A=A,b=b)
> 
> but this is not very elegant.  I checked the archives and 
> found nothing.
> 
> Thank you,
> 
> Tamas
> 
> -- 
> Bayesian statistics is difficult in the sense that thinking 
> is difficult.
> --Donald A. Berry, American Statistician 51:242 (1997)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ggrothendieck at gmail.com  Thu Oct  6 01:58:37 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 5 Oct 2005 19:58:37 -0400
Subject: [R] mapply for matrices
In-Reply-To: <20051005213643.GA5173@tpapp.student.princeton.edu>
References: <20051005213643.GA5173@tpapp.student.princeton.edu>
Message-ID: <971536df0510051658l621bef6cj3ee476ba65826738@mail.gmail.com>

Try this:

   mapply(f, split(A, 1:nrow(A)), b)


On 10/5/05, Tamas K Papp <tpapp at princeton.edu> wrote:
> Hi,
>
> I have a matrix A and a vector b, and would like to apply a function
> f(a,b) to the rows of A and the elements of b.  Eg
>
> A <- matrix(1:4,2,2)
> b <- c(5,7)
> f <- function(a,b) {sum(a)*b}
>
> myapply(f,A=A,b=b)
>
> would give
>
> (1+3)*5 = 20
> (2+4)*7 = 42
>
> I found mapply, but it does not work for matrices.  How could I do
> this without loops?  The above is just a toy example, the problem I am
> using this for has larger matrices, and f is a computation that does
> not handle vectors.
>
> One thing I thought of is
>
> sapply(seq(along=b),function(i,A,b){f(A[i,],b[i])},A=A,b=b)
>
> but this is not very elegant.  I checked the archives and found nothing.
>
> Thank you,
>
> Tamas
>
> --
> Bayesian statistics is difficult in the sense that thinking is difficult.
> --Donald A. Berry, American Statistician 51:242 (1997)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From klebyn at yahoo.com.br  Thu Oct  6 02:05:18 2005
From: klebyn at yahoo.com.br (klebyn)
Date: Wed, 05 Oct 2005 22:05:18 -0200
Subject: [R] playing with R: make a animated GIF file...
Message-ID: <43446A3E.2020207@yahoo.com.br>


Hello all


I am playing with R for to make a animated GIF.

any suggestions, improvements are welcome :-)

case somebody could help me, i thanks!


Cleber N. Borges ( klebyn )




my objective:

(steps TODO)

-------------------
1) to save PNG files;

----->  i don't know the best way to make this;


2) transform the PNG files into GIF files (easy! no problem!  ... i 
think ...)


3) reload the GiF files in R and use the caTools package to make a 
animated GIF.

------------------

############################   the code

########  reverse the STRING

strReverse <- function(x) sapply(lapply(strsplit(x, NULL), rev), paste, 
collapse="")

########  logotype to animate

yourLogo =    "Is Nice to play with R-package       "

logoWidth = 1.5
logoHeight = 2.5

L = nchar(yourLogo)

TrigSplit = 360 / L

yourLogo = strReverse(yourLogo)

posx = numeric(L)
posy = numeric(L)

for( i in 0:L){
posx[i] = logoHeight * sin(i * TrigSplit * pi / 180)
posy[i] = logoWidth *  cos(i * TrigSplit * pi / 180)
}

max_x = max(posx)*1.1
max_y = max(posy)*3

min_x = min(posx)*1.1
min_y = min(posy)*3


cex = 2/(posy + 2)

idx = 1:L


for(j in 1:L-1) {

###################file = paste("CQM_",j,".png",sep="")

###################png(filename=file, bg="transparent")

plot(0,t='n', xlim=c(min_x,max_x), ylim=c(min_y,max_y), axes=FALSE, 
ann=FALSE, font=3  )

for( i in 1:L){text(x=posx[i], y=posy[i], 
labels=substr(yourLogo,idx[i],idx[i]), col='blue', cex=cex[i] ) }

idx = (append(idx[L],idx))[1:L]

Sys.sleep(0.2)

###################dev.off()
}

##############  final code



From ggrothendieck at gmail.com  Thu Oct  6 03:37:50 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 5 Oct 2005 21:37:50 -0400
Subject: [R] Animation of Mandelbrot Set
In-Reply-To: <CA0BCF3BED56294AB91E3AD74B849FD503F00DE2@us-arlington-0668.mail.saic.com>
References: <CA0BCF3BED56294AB91E3AD74B849FD503F00DE2@us-arlington-0668.mail.saic.com>
Message-ID: <971536df0510051837o33210c46hd73ea81f33f8ced7@mail.gmail.com>

This probably has nothing to do with your software but on my Windows
XP system I just get a static image on Internet Explorer with the
animated GIF but with Firefox and the same GIF the animation comes
out as expected.


On 10/4/05, Tuszynski, Jaroslaw W. <JAROSLAW.W.TUSZYNSKI at saic.com> wrote:
> Hi,
>
> I was playing with Mandelbrot sets and come up with the following code, I
> thought I would share:
>
> library(fields)  # for tim.colors
> library(caTools) # for write.gif
> m = 400          # grid size
> C = complex( real=rep(seq(-1.8,0.6, length.out=m), each=m ),
>             imag=rep(seq(-1.2,1.2, length.out=m),      m ) )
> C = matrix(C,m,m)
> Z = 0
> X = array(0, c(m,m,20))
> for (k in 1:20) {
>  Z = Z^2+C
>  X[,,k] = exp(-abs(Z))
> }
> image(X[,,k], col=tim.colors(256)) # show final image in R
> write.gif(X, "Mandelbrot.gif", col=tim.colors(256), delay=100)
> # drop "Mandelbrot.gif" file from current directory on any web brouser to
> see the animation
>
>  Jarek
> ====================================================\====
>  Jarek Tuszynski, PhD.                           o / \
>  Science Applications International Corporation  <\__,|
>  (703) 676-4192                                   ">  \
>  Jaroslaw.W.Tuszynski at saic.com                     `   \
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From dunn at usq.edu.au  Thu Oct  6 04:06:12 2005
From: dunn at usq.edu.au (Peter Dunn)
Date: Thu, 06 Oct 2005 12:06:12 +1000
Subject: [R] R/S-Plus equivalent to Genstat "predict": predictions over
 "averages" of covariates
Message-ID: <43448694.4030201@usq.edu.au>

Hi all

I'm doing some things with a colleague comparing different
sorts of models.  My colleague has fitted a number of glms in
Genstat (which I have never used), while the glm I have
been using is only available for R.

He has a spreadsheet of fitted means from each of his models
obtained from using the Genstat "predict" function.  For
example, suppose we fit the model of the type
    glm.out <- glm( y ~ factor(F1) + factor(F2) + X1 + poly(X2,2) +
       poly(X3,2), family=...)

Then he produces a table like this (made up, but similar):

F1(level1)	12.2
F1(level2)	14.2
F1(level3)	15.3
F2(level1)	10.3
F2(level2)	9.1
X1=0		10.2
X1=0.5		10.4
X1=1 		10.4
X1=1.5		10.5
X1=2		10.9
X1=2.5		11.9
X1=3		11.8
X2=0		12.0
X2=0.5		12.2
X2=1 		12.5
X2=1.5		12.9	
X2=2		13.0
X2=2.5		13.1
X2=3		13.5

Each of the numbers are a predicted mean.  So when X1=0, on average
we predict an outcome of 10.2.

To obtain these figures in Genstat, he uses the Genstat "predict"
function.  When I asked for an explanation of how it was done (ie to
make the "predictions", what values of the other covariates were used) I
was told:

> So, for a one-dimensional table of fitted means for any factor (or
> variate), all other variates are set to their average values; and the
> factor constants (including the first, at zero) are given a weighted
> average depending on their respective numbers of observations.

So for quantitative variables (such as pH), one uses the mean pH in the
data set when making the predictions.  Reasonable anmd easy.

But for categorical variables (like Month), he implies we use a weighted
average of the fitted coefficients for all the months, depending on the
proportion of times those factor levels appear in the data.

(I hope I explained that OK...)

Is there an equivalent way in R or S-Plus of doing this?  I have to do
it for a number of sites and species, so an automated way would be
useful.  I have tried searching to no avail (but may not be searching
on the correct terms), and tried hard-coding something myself
as yet unsuccessfully:  The  poly  terms and the use of the weighted
averaging over the factor levels are proving a bit too much for my
limited skills.

Any assistance appreciated.  (Any clarification of what I mean can be
provided if I have not been clear.)

Thanks, as always.

P.

 > version
          _
platform i386-pc-linux-gnu
arch     i386
os       linux-gnu
system   i386, linux-gnu
status
major    2
minor    1.0
year     2005
month    04
day      18
language R
 >



-- 
Dr Peter Dunn  |  Senior Lecturer in Statistics
Faculty of Sciences, University of Southern Queensland
   Web:    http://www.sci.usq.edu.au/staff/dunn
   Email:  dunn <at> usq.edu.au
CRICOS:  QLD 00244B |  NSW 02225M |  VIC 02387D |  WA 02521C



From blomsp at ozemail.com.au  Thu Oct  6 04:09:37 2005
From: blomsp at ozemail.com.au (Simon Blomberg)
Date: Thu, 06 Oct 2005 12:09:37 +1000
Subject: [R] newbie questions - looping through hierarchial  datafille
In-Reply-To: <OF918EDC88.BF1AA4B2-ONCA257090.0003341B-CA257090.00035B10@
	poyry.fi>
References: <OF918EDC88.BF1AA4B2-ONCA257090.0003341B-CA257090.00035B10@poyry.fi>
Message-ID: <6.2.1.2.0.20051006115450.01d83008@mail.ozemail.com.au>

Well I haven't seen any replies to this, so I have had a stab at the 
problem of getting the data into a data frame.

The approach I took was to break up the data into a list, and then fill in 
a matrix, row by row, "filling down" a la spreadsheet style when necessary, 
taking advantage of the ordering of the data. Then coercing to a 
data.frame. Maybe not a very portable/general solution, but it appears to work.

list.to.data.frame <- function () {
filecon <- file(file.choose()) # open a data file
dat <- strsplit(readLines(filecon, n=-1), split=" ") # read all the data 
into a list,
                                         # 1 line per element, each element is
                                         # a character vector of data 
(variable length)
resultvec <- matrix(rep(NA, 16), nrow=1) # results will be stored here

filldown <- function (x) {
# cluge to simulate fill-down of a vector, spreadsheet style
         if(all(is.na(x)) || all(!is.na(x))) x else {
         last <- min(which(is.na(x)))
         x[last:length(x)] <- x[last-1]
         x
         }
}

#loop through the data
for (vec in dat) {
         f <- switch(vec[1], # what kind of field are we dealing with?
                 "A" = c(vec[-1], rep(NA, 15)),
                 "X" = c(NA, vec[-1], rep(NA, 12)),
                 "P" = c(rep(NA,4), vec[-1], rep(NA, 8)),
                 "T" = c(rep(NA, 8), vec[-1], rep(NA, 6)),
                 "L" = c(rep(NA, 10), vec[-1], rep(NA, 3)),
                 "F" = c(rep(NA, 13), vec[-1]))
         if (any(is.na(resultvec[nrow(resultvec), which(!is.na(f))])))
         # slot the data into the appropriate column
         resultvec[nrow(resultvec),] <- 
ifelse(is.na(resultvec[nrow(resultvec),]), f,
         resultvec[nrow(resultvec),]) else
         # if the row is full, start a new one
         resultvec <- rbind(resultvec, f)
         # if we are at the end of a row, fill down and start a new row
         if (vec[1] == "F") resultvec <- rbind(apply(resultvec, 2, 
filldown), rep(NA, 16))
         }

# coerce to a data frame, and get rid of the last empty row
res <- as.data.frame(resultvec[-nrow(resultvec),], row.names=NULL)
# set column names
names(res) <- c("Inventory", "Stratum_no", "Total", "Ye", "Plot_no", "age", 
"slope",
"species", "tree_no", "frequency", "leader",  "diameter", "height", 
"start_height",
"finish_height", "feature")
#return the result
res
}

Cheers,

Simon.


At 10:36 AM 4/10/2005, you wrote:
>Dear List,
>
>Im new to R - making a transition from SAS. I have a space delimited file
>with the following structure. Each line in the datafile is identified by
>the first letter.
>
>A = Inventory (Inventory)
>X = Stratum (Stratum_no Total Ye=year established)
>P = Plot (Plot_no age slope= species)
>T = Tree (tree_no frequency)
>L = Leader (leader diameter height)
>F = Feature (start_height finish_height feature)
>
>On each of these lines there are some 'line specific' variables (in
>brackets). The data is hierarchical in nature - A feature belongs to a
>leader, a leader belongs to a tree, a tree belongs to a plot, a plot
>belongs to a stratum, a stratum belongs to inventory. There are many
>features in a tree. Many trees in a plot etc.
>
>In SAS I would read in the data in a procedural way using first. and last.
>variables to work out where inventories/stratums/plots/trees  finished and
>started so I could create summary statistics for each of them. For
>example, how many plots in a stratum? How many trees in a plot? An example
>of the sas code I would (not checked for errors!!!). If anybody could give
>me some idea on what the right approach in R would be for a similar
>analysis it would be greatly appreciated.
>
>regards Andrew
>
>
>Data datafile;
>infile 'test.txt';
>input @1 tag $1. @@;
>retain inventory stratum plot tree leader;
>if tag = 'A' then input @3 inventory $.;
>if tag = 'X' then input @3 stratum_no $. total $. yearest $. ;
>if tag = 'P' then input @3 plot_no $. age $. slope $. species $;
>if tag = 'T' then input @3 tree_no $. frequency  ;
>if tag = 'L' then input @3 leader_no $ diameter  height  ;
>if tag = 'F' then input @3 start $ finish $ feature $;
>if tag = 'F' then output;
>run;
>proc sort data = datafile;
>by inventory stratum_no  plot_no  tree_no  leader_no;
>
>* calculate mean dbh in each plot
>data dbh
>set datafile;
>by inventory stratum_no  plot_no  tree_no leader_no
>if first.leader_no then output;
>
>proc summary data = diameter;
>by inventory stratum plot tree;
>var diameter;
>output out = mean mean=;
>run;
>
>A BENALLA_1
>X 1 10 YE=1985
>P 1 20.25 slope=14 SPP:P.RAD
>T 1 25
>L 0 28.5 21.3528
>F 0 21.3528 SFNSW_DIC:P
>F 21.3528 100 SFNSW_DIC:P
>T 2 25
>L 0 32 23.1
>F 0 6.5 SFNSW_DIC:A
>F 6.5 23.1 SFNSW_DIC:C
>F 23.1 100 SFNSW_DIC:C
>T 3 25
>L 0 39.5 22.2407
>F 0 4.7 SFNSW_DIC:A
>F 4.7 6.7 SFNSW_DIC:C
>P 2 20.25 slope=13 SPP:P.RAD
>T 1 25
>L 0 38 22.1474
>F 0 1 SFNSW_DIC:G
>F 1 2.3 SFNSW_DIC:A
>T 1001 25
>L 0 38 22.1474
>F 0 1 SFNSW_DIC:G
>F 1 2.3 SFNSW_DIC:A
>T 2 25
>L 0 32.5 21.7386
>F 0 2 SFNSW_DIC:A
>F 2 3.3 SFNSW_DIC:G
>F 3.3 10.4 SFNSW_DIC:C
>X 2 10 YE=1985
>P 1 20.25 slope=14 SPP:P.RAD
>T 1 25
>L 0 28.5 21.3528
>F 0 21.3528 SFNSW_DIC:P
>F 21.3528 100 SFNSW_DIC:P
>T 2 25
>L 0 32 23.1
>F 0 6.5 SFNSW_DIC:A
>F 6.5 23.1 SFNSW_DIC:C
>F 23.1 100 SFNSW_DIC:C
>T 3 25
>L 0 39.5 22.2407
>F 0 4.7 SFNSW_DIC:A
>F 4.7 6.7 SFNSW_DIC:C
>P 2 20.25 slope=13 SPP:P.RAD
>T 1 25
>L 0 38 22.1474
>F 0 1 SFNSW_DIC:G
>F 1 2.3 SFNSW_DIC:A
>T 1001 25
>L 0 38 22.1474
>F 0 1 SFNSW_DIC:G
>F 1 2.3 SFNSW_DIC:A
>T 2 25
>L 0 32.5 21.7386
>F 0 2 SFNSW_DIC:A
>F 2 3.3 SFNSW_DIC:G
>F 3.3 10.4 SFNSW_DIC:C
>
>
>
>
>         [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Simon Blomberg, B.Sc.(Hons.), Ph.D, M.App.Stat.
Centre for Resource and Environmental Studies
The Australian National University
Canberra ACT 0200
Australia
T: +61 2 6125 7800 email: Simon.Blomberg_at_anu.edu.au
F: +61 2 6125 0757
CRICOS Provider # 00120C



From baer at stanford.edu  Thu Oct  6 04:43:54 2005
From: baer at stanford.edu (Paul Baer)
Date: Wed, 5 Oct 2005 20:43:54 -0600
Subject: [R] Changing the value of variables passed to functions as arguments
Message-ID: <p0623091cbf6a3eb01a36@[192.168.1.102]>

Is it possible to write functions in such a way that, rather than 
having to write "a=function(a)", one can just write "function(a)" and 
have the variable passed as the argument be modified?

My real interest here is being able to invoke the editor by writing 
"ed(filename)" rather than filename=edit(filename).

Thanks,

--Paul



From ggrothendieck at gmail.com  Thu Oct  6 05:01:34 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 5 Oct 2005 23:01:34 -0400
Subject: [R] Changing the value of variables passed to functions as
	arguments
In-Reply-To: <p0623091cbf6a3eb01a36@192.168.1.102>
References: <p0623091cbf6a3eb01a36@192.168.1.102>
Message-ID: <971536df0510052001x64e79f1bx62d3e69d37b9a419@mail.gmail.com>

Check out:

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/38536.html

On 10/5/05, Paul Baer <baer at stanford.edu> wrote:
> Is it possible to write functions in such a way that, rather than
> having to write "a=function(a)", one can just write "function(a)" and
> have the variable passed as the argument be modified?
>
> My real interest here is being able to invoke the editor by writing
> "ed(filename)" rather than filename=edit(filename).
>
> Thanks,
>
> --Paul
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Charles.Annis at StatisticalEngineering.com  Thu Oct  6 05:12:36 2005
From: Charles.Annis at StatisticalEngineering.com (Charles Annis, P.E.)
Date: Wed, 5 Oct 2005 23:12:36 -0400
Subject: [R] Animation of Mandelbrot Set
In-Reply-To: <971536df0510051837o33210c46hd73ea81f33f8ced7@mail.gmail.com>
Message-ID: <200510060312.j963Cds2010607@hypatia.math.ethz.ch>

Works well with both IE and Firefox on my 2 year old DELL WinXP machine.

Charles Annis, P.E.

Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFax:  614-455-3265
http://www.StatisticalEngineering.com
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Gabor Grothendieck
Sent: Wednesday, October 05, 2005 9:38 PM
To: Tuszynski, Jaroslaw W.
Cc: (r-help at stat.math.ethz.ch.)
Subject: Re: [R] Animation of Mandelbrot Set

This probably has nothing to do with your software but on my Windows
XP system I just get a static image on Internet Explorer with the
animated GIF but with Firefox and the same GIF the animation comes
out as expected.


On 10/4/05, Tuszynski, Jaroslaw W. <JAROSLAW.W.TUSZYNSKI at saic.com> wrote:
> Hi,
>
> I was playing with Mandelbrot sets and come up with the following code, I
> thought I would share:
>
> library(fields)  # for tim.colors
> library(caTools) # for write.gif
> m = 400          # grid size
> C = complex( real=rep(seq(-1.8,0.6, length.out=m), each=m ),
>             imag=rep(seq(-1.2,1.2, length.out=m),      m ) )
> C = matrix(C,m,m)
> Z = 0
> X = array(0, c(m,m,20))
> for (k in 1:20) {
>  Z = Z^2+C
>  X[,,k] = exp(-abs(Z))
> }
> image(X[,,k], col=tim.colors(256)) # show final image in R
> write.gif(X, "Mandelbrot.gif", col=tim.colors(256), delay=100)
> # drop "Mandelbrot.gif" file from current directory on any web brouser to
> see the animation
>
>  Jarek
> ====================================================\====
>  Jarek Tuszynski, PhD.                           o / \
>  Science Applications International Corporation  <\__,|
>  (703) 676-4192                                   ">  \
>  Jaroslaw.W.Tuszynski at saic.com                     `   \
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From uttam.phulwale at tcs.com  Thu Oct  6 06:11:52 2005
From: uttam.phulwale at tcs.com (uttam.phulwale@tcs.com)
Date: Thu, 6 Oct 2005 09:41:52 +0530
Subject: [R] how to handle missing values in the data?
Message-ID: <OF3E0A297B.CB69EC03-ON65257092.00163457-65257092.00169D6A@tcs.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051006/329d1978/attachment.pl

From maj at stats.waikato.ac.nz  Thu Oct  6 06:59:46 2005
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Thu, 06 Oct 2005 17:59:46 +1300
Subject: [R] R for teaching multivariate statistics (Summary)
Message-ID: <4344AF42.8040700@stats.waikato.ac.nz>

Greetings all

I promised a summary of the responses that I got to my question:

"Next year I will be teaching a third year course in applied statistics 
about 1/3 of which is multivariate statistics. I would be interested in 
hearing experiences from those who have taught multivariate statistics 
using R. Especially I am interested in the textbook that you used or 
recommended."

There were not many replies, so my task is easy!

Peter Dunn mentioned the new book by Brian Everitt, "An R and S-Plus 
Companion to Multivariate Analysis" which he had yet to see. Someone 
else has it out on loan here so I have not seen it either.

Peter has been using Bryan Manly's book but finds that it is expensive 
and describes different algorithms to those used in R.

Brian Ripley drew attention to Chapters 11 and 12 of MASS.

Pierre Bady pointed out the material on the website "Enseignements de 
Statistique en Biologie" http://pbil.univ-lyon1.fr/R/enseignement.html
by A.B. Dufour, D. Chessel & J.R. Lobry. I hope to explore this some 
more when I get back to higher bandwidth.

Pat Altham has a wealth of material on her web site, especially
http://www.statslab.cam.ac.uk/~pat/misc.ps
and
http://www.statslab.cam.ac.uk/~pat/AppMultNotes.ps.gz

Many thanks to these respondants for their help.

Murray Jorgensen
-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441    Mobile 021 1395 862



From vincent at 7d4.com  Thu Oct  6 08:08:16 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Thu, 06 Oct 2005 08:08:16 +0200
Subject: [R] playing with R: make a animated GIF file...
In-Reply-To: <43446A3E.2020207@yahoo.com.br>
References: <43446A3E.2020207@yahoo.com.br>
Message-ID: <4344BF50.8000303@7d4.com>

klebyn a ??crit :

> my objective:
> 1) to save PNG files;
> ----->  i don't know the best way to make this;

?png
(also bmp(), jpg() available)
hih



From ligges at statistik.uni-dortmund.de  Thu Oct  6 08:47:23 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 06 Oct 2005 08:47:23 +0200
Subject: [R] problem in installing a package
In-Reply-To: <20051005221939.92114.qmail@web60211.mail.yahoo.com>
References: <20051005221939.92114.qmail@web60211.mail.yahoo.com>
Message-ID: <4344C87B.3080107@statistik.uni-dortmund.de>

Claire Lee wrote:

> I'm using R in Windows XP. I created a package myself.
> I've used R CMD check to check it. Everything seems OK
> except the latex. I get the error message:
> * checking bbHist-manual.tex ... ERROR
> LaTeX errors when creating DVI version.
> This typically indicates Rd problems.
> 
> I ignored it because I didn't want to submit it to
> CRAN.
> 
> Then I tried to use R CMD INSTALL to install it. First
> I get: 
> "mv: cannot move `c:/PROGRA~1/R/rw2011/library/bbHist'
> to `c:/PROGRA~1/R/rw2011/library/00LOCK/bbHist
> ': Permission denied" 
>
> and a bunch of making DLL errors.  Then when I tried a
> second time, I get:
> 
> open(c:/progra~1/r/rw2011/library/bbHist/DESCRIPTION):
> No such file or directory
> 
> I can see a 00LOCK directory is created in the
> c:/PROGRA~1/R/rw2011/library directory. Any idea why
> this is happening?

No, information is still too sparse, unfortunately.
Do you have full write access?
The 00LOCK directory is used to save the older package in order to be 
able to restore it if a new installtion fails.
Something went wrong and you have to remove it manually now, I guess.

Uwe Ligges




> Thanks.
> 
> Claire
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From uttam.phulwale at tcs.com  Thu Oct  6 09:13:54 2005
From: uttam.phulwale at tcs.com (uttam.phulwale@tcs.com)
Date: Thu, 6 Oct 2005 12:43:54 +0530
Subject: [R] how to use  tune.knn() for dataset with missing values
Message-ID: <OFFF81FCF6.7F3FF78A-ON65257092.0026AF81-65257092.002747DA@tcs.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051006/d58dba97/attachment.pl

From p.dalgaard at biostat.ku.dk  Thu Oct  6 09:26:15 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 06 Oct 2005 09:26:15 +0200
Subject: [R] Changing the value of variables passed to functions as
	arguments
In-Reply-To: <p0623091cbf6a3eb01a36@[192.168.1.102]>
References: <p0623091cbf6a3eb01a36@[192.168.1.102]>
Message-ID: <x2y857f6nc.fsf@turmalin.kubism.ku.dk>

Paul Baer <baer at stanford.edu> writes:

> Is it possible to write functions in such a way that, rather than 
> having to write "a=function(a)", one can just write "function(a)" and 
> have the variable passed as the argument be modified?
> 
> My real interest here is being able to invoke the editor by writing 
> "ed(filename)" rather than filename=edit(filename).

You might want to check out fix()...

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From Marjo.Pyy-Martikainen at stat.fi  Thu Oct  6 10:33:00 2005
From: Marjo.Pyy-Martikainen at stat.fi (Pyy-Martikainen Marjo)
Date: 6 Oct 2005 11:33:00 +0300
Subject: [R] Testing strata by covariate interactions in coxph
Message-ID: <JA8AAAAAAnjfpAABYQABU5AQ2thU@postila.stat.fi>

Dear list members,

I am working with a Cox ph model for the duration of unemployment. The event of
interest
in my analysis is getting employed. I have various background variables
explaining this
event: age, sex, education etc. I have multiple unemployment spells per person.
I use a model with person-specific frailty terms in order to take into account
the correlation of spells by the same person.

The persons can be divided into 3 groups, say A, B and C. I am interested to
see whether there are differences between estimated covariate effects between
the groups. Therefore
I specify a model  with strata by covariate interactions. I would like to
conduct a Wald test
for the null hypothesis "no differences between any covariate effects in the 3
groups".
This is similar to the example by Therneau & Grambsch in their book "Modeling
survival data. Extending the Cox model", p. 47, except that I have interactions
with many covariates that I would like to test jointly (and a frailty term).
In S-plus there seems to be a function waldtest that does the job. Is there
anything similar in R that I could use?

Here is the code for my model. The covariates are a subset of all the
covariates that I use.

fit=coxph(Surv(tykesto,
tyoll)~nainen*strata(group)+I(ika-mean(ika))*strata(group)
+I(ika2-mean(ika2))*strata(group)+keski*strata(group)+korkea*strata(group)
+frailty(hnro),data=coxdata)

tyoll2   =1, if event "getting employed" has occurred,  0 otherwise
nainen = 1, if female 0 otherwise
ika      = age in years at the start of the spell
ika2    =  age squared
keski  =1, if secondary education, 0 otherwise
korkea=1, if higher education, 0 otherwise
hnro    = person identifier
group  = group identifier

Thank you in advance for any help.

Marjo Pyy-Martikainen



From sourceforge at metrak.com  Thu Oct  6 10:39:02 2005
From: sourceforge at metrak.com (sosman)
Date: Thu, 06 Oct 2005 18:39:02 +1000
Subject: [R] multiple line plots
In-Reply-To: <1128516539.5576.21.camel@localhost.localdomain>
References: <4343C4BD.2070304@metrak.com>
	<1128516539.5576.21.camel@localhost.localdomain>
Message-ID: <4344E2A6.6050800@metrak.com>

Marc Schwartz wrote:
 > On Wed, 2005-10-05 at 22:19 +1000, sosman wrote:
 >
 >>I have some data in a CSV file:
 >>
 >>time,pos,t,tl
 >>15:23:44:350,M1_01,4511,1127
 >>15:23:44:350,M1_02,4514,1128
 >>15:23:44:350,M1_03,4503,1125
 >>...
 >>15:23:44:491,M2_01,4500,1125
 >>15:23:44:491,M2_02,4496,1124
 >>15:23:44:491,M2_03,4516,1129
 >>...
 >>15:23:44:710,M3_01,4504,1126
 >>15:23:44:710,M3_02,4516,1129
 >>15:23:44:710,M3_03,4498,1124
 >>...
 >>
 >>Each pos (eg M1_01) is an independent time series.  I would like to plot
 >>each time series as lines on a single plot and I wondered if there was
 >>something more straight forward than I was attempting.
 >>
 >>I got as far as:
 >>
 >>fname = 't100.csv'
 >>t = read.csv(fname)
 >>tpos = split(t, t$pos)
 >>plot(tpos[["M1_01"]]$t, type='l')
 >>for (p in names(tpos)) {
 >>     lines(tpos[[p]]$t)
 >>}
 >>
 >>which seems to work but then I got stuck on how to make each line a
 >>different colour and figured that there might a be a one liner R command
 >>to do what I want.
 >>
 >>Any tips would be appreciated.
 >
 >
 >
 > See the examples in ?plot.ts for some approaches.
 >
 > You will need to review ?ts to create time series objects from your data
 > to be used in plot.ts().
 >
 > Another approach, which is not specific to time series, is ?matplot.

The matplot example looks like the go.

The example data didn't really show the grouping and even though I
mentioned time series, simply plotting the t values as an ordered
sequence is fine for this application (sorry about the red herring).

The dataset below is what I should have shown:

     pos    t
1 M1_01 4511
2 M1_02 4514
3 M1_03 4503
4 M1_01 4500
5 M1_02 4496
6 M1_03 4516
7 M1_01 4504
8 M1_02 4516
9 M1_03 4498

So what I ended up with was:

# Make a wide data set
tw = unstack(t, t ~ pos)
# Results in a list since not all series the same length
# Find the shortest dataset
len = min(sapply(tw, length))

setlen = function(l, newlen) { length(l) = newlen }
# Not sure why this did not work
#sapply(tw, setlen, len)

for (n in names(tw)) {
     length(tw[[n]]) = len
}
matplot(data.frame(tw), type='l')

Apart from flying a bit blind, I obtained the plot I was after.

thanks



From morten.lindow at gmail.com  Thu Oct  6 10:43:08 2005
From: morten.lindow at gmail.com (Morten Lindow)
Date: Thu, 6 Oct 2005 10:43:08 +0200
Subject: [R] --gui none problem
Message-ID: <188a160d0510060143oe160cci6f69d4ccea45070@mail.gmail.com>

Hi,

As part of a batch process I run R with option --gui none.

This works nicely on one maching running
Version 1.9.0 Under development (unstable) (2004-03-06)

but on another machine using the newer Version 2.1.0  (2005-04-18) I
get the following fatal error message:

"ERROR: unknown GUI none"

Does anyone know if this is a bug or a problem with the installation?


--
Morten Lindow,
Bioinformatics Centre, University of Copenhagen
phone: +45 3532 1348



From Luc.Vereecken at chem.kuleuven.ac.be  Thu Oct  6 11:23:25 2005
From: Luc.Vereecken at chem.kuleuven.ac.be (Luc Vereecken)
Date: Thu, 06 Oct 2005 11:23:25 +0200
Subject: [R] --gui none problem
In-Reply-To: <188a160d0510060143oe160cci6f69d4ccea45070@mail.gmail.com>
References: <188a160d0510060143oe160cci6f69d4ccea45070@mail.gmail.com>
Message-ID: <6.2.3.4.0.20051006112144.04192a88@arrhenius.chem.kuleuven.ac.be>

Version 2.x no longer has a -gui=none option. Running BATCH jobs 
supposedly disables a gui though.

Luc Vereecken

At 10:43 AM 10/6/2005, Morten Lindow wrote:
>Hi,
>
>As part of a batch process I run R with option --gui none.
>
>This works nicely on one maching running
>Version 1.9.0 Under development (unstable) (2004-03-06)
>
>but on another machine using the newer Version 2.1.0  (2005-04-18) I
>get the following fatal error message:
>
>"ERROR: unknown GUI none"
>
>Does anyone know if this is a bug or a problem with the installation?
>
>
>--
>Morten Lindow,
>Bioinformatics Centre, University of Copenhagen
>phone: +45 3532 1348
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From ripley at stats.ox.ac.uk  Thu Oct  6 12:02:33 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 Oct 2005 11:02:33 +0100 (BST)
Subject: [R] --gui none problem
In-Reply-To: <6.2.3.4.0.20051006112144.04192a88@arrhenius.chem.kuleuven.ac.be>
Message-ID: <Pine.GSO.4.31.0510061049350.2035-100000@toucan.stats>

On Thu, 6 Oct 2005, Luc Vereecken wrote:

> Version 2.x no longer has a -gui=none option. Running BATCH jobs
> supposedly disables a gui though.

There is no --gui=none option in 2.1.x (but there is in 2.0.x).

The gui is not disabled in 2.1.x either according to the help page nor in
practice (although using an actual GUI without an operator in attendance
is not in general sensible, and any error will terminate R).

Here is the NEWS item for R 2.1.0

    o   BATCH on Unix no longer sets --gui="none" as the X11 module
        is only loaded if needed.


Try R CMD BATCH --gui=tk (Should be Tk, but that was a buglet in 2.1.x).


>
> Luc Vereecken
>
> At 10:43 AM 10/6/2005, Morten Lindow wrote:
> >Hi,
> >
> >As part of a batch process I run R with option --gui none.
> >
> >This works nicely on one maching running
> >Version 1.9.0 Under development (unstable) (2004-03-06)
> >
> >but on another machine using the newer Version 2.1.0  (2005-04-18) I
> >get the following fatal error message:
> >
> >"ERROR: unknown GUI none"
> >
> >Does anyone know if this is a bug or a problem with the installation?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Oct  6 12:04:41 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 Oct 2005 11:04:41 +0100 (BST)
Subject: [R] multiple line plots
In-Reply-To: <4344E2A6.6050800@metrak.com>
Message-ID: <Pine.GSO.4.31.0510061103360.2035-100000@toucan.stats>

> # Not sure why this did not work
> #sapply(tw, setlen, len)

It probably did, but you discarded the result.  Try

tw <- sapply(tw, setlen, len)


On Thu, 6 Oct 2005, sosman wrote:

> Marc Schwartz wrote:
>  > On Wed, 2005-10-05 at 22:19 +1000, sosman wrote:
>  >
>  >>I have some data in a CSV file:
>  >>
>  >>time,pos,t,tl
>  >>15:23:44:350,M1_01,4511,1127
>  >>15:23:44:350,M1_02,4514,1128
>  >>15:23:44:350,M1_03,4503,1125
>  >>...
>  >>15:23:44:491,M2_01,4500,1125
>  >>15:23:44:491,M2_02,4496,1124
>  >>15:23:44:491,M2_03,4516,1129
>  >>...
>  >>15:23:44:710,M3_01,4504,1126
>  >>15:23:44:710,M3_02,4516,1129
>  >>15:23:44:710,M3_03,4498,1124
>  >>...
>  >>
>  >>Each pos (eg M1_01) is an independent time series.  I would like to plot
>  >>each time series as lines on a single plot and I wondered if there was
>  >>something more straight forward than I was attempting.
>  >>
>  >>I got as far as:
>  >>
>  >>fname = 't100.csv'
>  >>t = read.csv(fname)
>  >>tpos = split(t, t$pos)
>  >>plot(tpos[["M1_01"]]$t, type='l')
>  >>for (p in names(tpos)) {
>  >>     lines(tpos[[p]]$t)
>  >>}
>  >>
>  >>which seems to work but then I got stuck on how to make each line a
>  >>different colour and figured that there might a be a one liner R command
>  >>to do what I want.
>  >>
>  >>Any tips would be appreciated.
>  >
>  >
>  >
>  > See the examples in ?plot.ts for some approaches.
>  >
>  > You will need to review ?ts to create time series objects from your data
>  > to be used in plot.ts().
>  >
>  > Another approach, which is not specific to time series, is ?matplot.
>
> The matplot example looks like the go.
>
> The example data didn't really show the grouping and even though I
> mentioned time series, simply plotting the t values as an ordered
> sequence is fine for this application (sorry about the red herring).
>
> The dataset below is what I should have shown:
>
>      pos    t
> 1 M1_01 4511
> 2 M1_02 4514
> 3 M1_03 4503
> 4 M1_01 4500
> 5 M1_02 4496
> 6 M1_03 4516
> 7 M1_01 4504
> 8 M1_02 4516
> 9 M1_03 4498
>
> So what I ended up with was:
>
> # Make a wide data set
> tw = unstack(t, t ~ pos)
> # Results in a list since not all series the same length
> # Find the shortest dataset
> len = min(sapply(tw, length))
>
> setlen = function(l, newlen) { length(l) = newlen }
> # Not sure why this did not work
> #sapply(tw, setlen, len)
>
> for (n in names(tw)) {
>      length(tw[[n]]) = len
> }
> matplot(data.frame(tw), type='l')
>
> Apart from flying a bit blind, I obtained the plot I was after.
>
> thanks
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mdehollander at gmail.com  Thu Oct  6 12:23:24 2005
From: mdehollander at gmail.com (Mattias de Hollander)
Date: Thu, 6 Oct 2005 12:23:24 +0200
Subject: [R] Compare two distance matrices
Message-ID: <e3f8e9a00510060323x1824657et76b4d6c94c2177c0@mail.gmail.com>

Hi all,

I am trying to compare two distance matrices with R. I would like to
create a XY plot of these matrices and do some linear regression on
it. But, I am a bit new to R, so i have a few questions (I searched in
the documentation with no success).
The first problem is loading a distance matrix into R. This matrix is
the output of a the Phylip program Protdist and lookes like this:
    5
n_crassa    0.000000  0.690737  0.895257  0.882576  2.365386
c_neufor    0.690737  0.000000  0.956910  0.979988  2.103041
a_thaliana  0.895257  0.956910  0.000000  1.003668  2.724847
pompep      0.882576  0.979988  1.003668  0.000000  2.065202
s_cerevis   2.365386  2.103041  2.724847  2.065202  0.000000
    5
n_crassa    0.000000  0.739560  0.933986  0.861644  2.207467
c_neufor    0.739560  0.000000  0.988779  0.925168  1.941141
a_thaliana  0.933986  0.988779  0.000000  1.007803  2.415320
pompep      0.861644  0.925168  1.007803  0.000000  2.394490
s_cerevis   2.207467  1.941141  2.415320  2.394490  0.000000
.....

I tried with the scan() function to load the files, but with no
success. How should i load in these files?

Second i saw there is package for distance matrices
(http://stat.ethz.ch/R-manual/R-devel/library/stats/html/dist.html). I
thought of using as.dist() to convert the files to a R dist matrix. I
have not been able to try this, because the first step didn't succeed.

Is this the right approach, or is there any other way of comparing
distance matrices with R?



From kate at few.vu.nl  Thu Oct  6 12:57:17 2005
From: kate at few.vu.nl (Katharine Mullen)
Date: Thu, 6 Oct 2005 12:57:17 +0200 (CEST)
Subject: [R]  playing with R: make a animated GIF file...
In-Reply-To: <mailman.11.1128592801.28547.r-help@stat.math.ethz.ch>
References: <mailman.11.1128592801.28547.r-help@stat.math.ethz.ch>
Message-ID: <Pine.GSO.4.56.0510061224040.13780@laurel.few.vu.nl>


you could first make the frames to put together in R, then outside of R
glue the frames into a gif.

eg:

frames<-10
for(i in 1:frames) {
      jpeg(paste("ani_", i, ".jpg", sep = ""))
      plot(1:10,1:10, col = i)
      dev.off()
}

then use an image editing program to glue the jpgs together -- eg free and
crossplatform imagemagick (www.imagemagick.org).
under linux and once imagemagick is installed, the command

$ convert -delay 10 ani_*.jpg animation.gif

makes a looping animated gif `animation.gif' with 10/100 sec. between
frame flips.

----
Katharine Mullen
Department of Physics and Astronomy
Faculty of Sciences
Vrije Universiteit
de Boelelaan 1081
1081 HV Amsterdam
The Netherlands
room: T.1.06
tel: +31 205987870
fax: +31 205987992
e-mail: kate at nat.vu.nl
http://www.nat.vu.nl/~kate/



From anette at geoplus.dk  Thu Oct  6 13:13:04 2005
From: anette at geoplus.dk (=?iso-8859-1?Q?Anette_N=F8rgaard?=)
Date: Thu, 6 Oct 2005 13:13:04 +0200
Subject: [R] Interpolation in time
Message-ID: <000001c5ca66$ebeab670$7ad0e182@anette>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051006/209f836a/attachment.pl

From kate at few.vu.nl  Thu Oct  6 13:14:11 2005
From: kate at few.vu.nl (Katharine Mullen)
Date: Thu, 6 Oct 2005 13:14:11 +0200 (CEST)
Subject: [R]  eliminate t() and %*% using crossprod() and solve(A,b)
In-Reply-To: <mailman.11.1128592801.28547.r-help@stat.math.ethz.ch>
References: <mailman.11.1128592801.28547.r-help@stat.math.ethz.ch>
Message-ID: <Pine.GSO.4.56.0510061308540.13780@laurel.few.vu.nl>

you might want to see

Douglas Bates. Least squares calculations in R. R News,
4(1):17-20, June 2004.   http://CRAN.R-project.org/doc/Rnews/

he gives some rules of thumb, eg

use solve(A,b) not solve(A) %*% b
use crossprod(X) not t(X) %*% X
use crossprod(X,y) not t(X) y

----
Katharine Mullen
Department of Physics and Astronomy
Faculty of Sciences
Vrije Universiteit
de Boelelaan 1081
1081 HV Amsterdam
The Netherlands
room: T.1.06
tel: +31 205987870
fax: +31 205987992
e-mail: kate at nat.vu.nl
http://www.nat.vu.nl/~kate/



From ecoinformatics at gmail.com  Thu Oct  6 13:22:30 2005
From: ecoinformatics at gmail.com (ecoinfo)
Date: Thu, 6 Oct 2005 13:22:30 +0200
Subject: [R] Animation of Mandelbrot Set
In-Reply-To: <CA0BCF3BED56294AB91E3AD74B849FD503F00DE2@us-arlington-0668.mail.saic.com>
References: <CA0BCF3BED56294AB91E3AD74B849FD503F00DE2@us-arlington-0668.mail.saic.com>
Message-ID: <15f8e67d0510060422o6bf6b1dbr10f61a10e6fef7e6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051006/1bd14bc5/attachment.pl

From p.dalgaard at biostat.ku.dk  Thu Oct  6 13:45:43 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 06 Oct 2005 13:45:43 +0200
Subject: [R] R-2.2.0 is released
Message-ID: <x2slve3m3c.fsf@viggo.kubism.ku.dk>


I've rolled up R-2.2.0.tar.gz a short while ago. This version contains
several changes and additions, mostly incremental. See the full list
of changes below.

You can get it from

http://cran.r-project.org/src/base/R-2/R-2.2.0.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you. Binaries
for various platforms will appear in due course.
 
There is also a version split for floppies. 

        For the R Core Team

        Peter Dalgaard

These are the md5sums for the freshly created files, in case you wish
to check that they are uncorrupted:

94d55d512a9ba36caa9b7df079bae19f  COPYING
d8045f3b8f929c1cb29a1e3fd737b499  COPYING.LIB
043a28ec5378bfaba88e4fb34f805980  FAQ
70447ae7f2c35233d3065b004aa4f331  INSTALL
5209c94d85a195fb92cdf796912a732b  NEWS
88bbd6781faedc788a1cbd434194480c  ONEWS
4f004de59e24a52d0f500063b4603bcb  OONEWS
6bddf439ae417a48bd31892996ea111c  R-2.2.0.tar.gz
f8763b77147796b3adf52045183ee0c3  R-2.2.0.tar.gz-split.aa
ba00cb5ff9c3e82038c3b3abcce60855  R-2.2.0.tar.gz-split.ab
9668413beca51736390b63afa489b2f1  R-2.2.0.tar.gz-split.ac
b19e3a225a66b50e14671f1bb36e1d07  R-2.2.0.tar.gz-split.ad
2465e208aab735e20d1efee7c72f6c23  R-2.2.0.tar.gz-split.ae
903f37e74de637e71ef619c5801f719e  R-2.2.0.tar.gz-split.af
46502602ec014ba2f261ed6c81811ea6  R-2.2.0.tar.gz-split.ag
58d5e7d99ec15388687f2a7dca78b647  R-2.2.0.tar.gz-split.ah
d8c2356d0e3e650b5bfc92e5ee22a91d  R-2.2.0.tar.gz-split.ai
cabdf55568d9f90115faaaf18cddfa07  R-2.2.0.tar.gz-split.aj
56a780cdec835c5c598f8dfc0738f7f3  README
020479f381d5f9038dcb18708997f5da  RESOURCES

Here is the relevant bit of the NEWS file:


		CHANGES IN R VERSION 2.2.0


USER-VISIBLE CHANGES

    o	plot(<lm object>) uses a new default 'which = 5'
    	for the fourth panel when 'which' is not specified.

    o	The SVN revision number will appear after the date in the
	welcome message.  The date shown is now the date of the last
	change to the sources rather than the date the sources were
	prepared.

    o	is.null(expression()) now returns FALSE.  Only NULL gives TRUE
	in is.null().

    o	graphics::xy.coords, xyz.coords and n2mfrow have been moved to
	the grDevices name space (to be available for grid as well).

	graphics::boxplot.stats, contourLines, nclass.*, and chull
	have been moved to the grDevices name space.  The C code
	underlying chull() has been moved to package grDevices.

    o	split(x, f), split<-() and unsplit() now by default split by all
	levels of a factor f, even when some are empty.
	Use split(x, f, drop = TRUE) if you want the old behavior of
	dropping empty levels.	split() and split<-() are S3 generic
	functions with new arguments 'drop' and '...' and all methods now
	should have 'drop' and '...' arguments as well.

    o	The default for 'allowEscapes' in both read.table() and scan()
	has been changed to FALSE.

    o	The default for 'gcFirst' in system.time() is now TRUE.


NEW FEATURES

    o	.Platform has a new component 'path.sep', the separator used
	between paths in environment variables such as PATH and TEXINPUTS.

    o   anova.mlm() now handles the single-model case.

    o	Hexadecimal values are now allowed for as.numeric() and
	as.integer() on all platforms, and as integer constants in R code.

    o	attach() now prints an information message when objects are
	masked on the search path by or from a newly attached database.

    o	axis() now returns 'at' positions.

    o   axis() has a new argument 'hadj' to control horizontal
	adjustment of labels.

    o	axis.Date() and axis.POSIXct() now accept a 'labels' argument
	(contributed by Gavin Simpson).

    o	barplot() now has arguments 'log = ""' and 'add = FALSE'
	(as in barplot2() from package 'gplots').

    o	baseenv() has been added, to return the base environment.  This
    	is currently still NULL, but will change in a future release.

    o   boxplot() now responds to supplying 'yaxs' (via bxp()).
	(Wish of PR#8072.)

    o	capabilities() has a new component 'NLS'.

    o	cbind() and rbind() now react to 'deparse.level' = {0,1,2}
	(as in another system not unlike R).

    o	Experimental versions of cbind() and rbind() in methods package,
	based on new generic function cbind2(x,y) and rbind2().	 This will
	allow the equivalent of S4 methods for cbind() and rbind() ---
	currently only after an explicit activation call, see ?cbind2.

    o	New functions cdplot() and spineplot() for conditional density
        plots and spine plots or spinograms.  Spine plots are now used
        instead of bar plots for x-y scatterplots where y is a factor.

    o	checkDocFiles() in package 'tools' now checks for bad \usage
	lines (syntactically invalid R code).

    o   The nonparametric variants of cor.test() now behave better in
	the presence of ties. The "spearman" method uses the asymptotic
	approximation in that case, and the "kendall" method likewise,
	but adds a correction for ties (this is not necessary in the
	Spearman case).

    o	The X11 dataentry() now has support for X Input Methods
	(contributed by Ei-ji Nakama).

    o	density() is now an S3 generic where density.default() {former
	density()} has new argument 'weights' for specifying observation
	masses different than the default 1/N -- based on a suggestion and
	code from Adrian Baddeley.

    o	download.packages() now carries on if it encounters a download
	error (e.g. a repository with a corrupt index).

    o	dump() now skips missing objects with a warning rather than
	throw an error.

    o   Added "POSIXlt" methods for duplicated() and unique().

    o	Function encoded_text_to_latex() in package tools translates
	Latin 1,2,9 and UTF-8 encoded character vectors to LaTeX
	escape sequences where appropriate.

    o	encodeString() allows justify = "none" for consistency with
	format.default().  Some argument names have been lengthened
	for clarity.

    o	file(), fifo() and pipe() now (if possible) report a reason
        if they fail to open a connection.

    o	format.default() now has a 'width' argument, and 'justify' can
	now centre character strings.

	format.default() has new arguments 'na.encode' to control
	whether NA character strings are encoded (true by default),
	and 'scientific' to control the use of fixed/scientific
	notation for real/complex numbers.

	How format() works on a list is now documented, and uses
	arguments consistently with their usage on an atomic vector.

    o	format.info() now has a 'digits' argument, and is documented
	to work for all atomic vectors (it used to work for all but
	raw vectors.).

    o	New function glob2rx() for translating `wildcard' aka `globbing'
	to regular expressions.

    o	There is a new function gregexpr() which generalizes regexpr()
        to search for all matches in each of the input strings (not
        just the first match).

    o	[g]sub() now have a 'useBytes' argument like grep() and regexpr().

    o	[g]sub(perl = TRUE) support \L and \U in the replacement.

    o   iconv() has been moved from 'utils' to 'base'.

    o	identify()'s default method has additional arguments 'atpen'
	and 'tolerance' (following S).

    o	KalmanForecast() and KalmanLike() now have an optional argument
	fast=FALSE to prevent their arguments being modified.

    o	Exact p-values are available in ks.test() for the one-sided and
	two-sided one-sample Kolmogorov-Smirnov tests.

    o	labels() now has a method for "dist" objects (replacing that
	for names() which was withdrawn in 2.1.0).

    o	library() now explicitly checks for the existence of
	directories in 'lib.loc': this avoids some warning messages.

    o	loadNamespace(keep.source=) now applies only to that namespace
	and not others it might load to satisfy imports: this is now
	consistent with library().

    o	match.arg() has a new argument 'several.ok = FALSE'.

    o	max.col() has a new argument for non-random behavior in the
	case of ties.

    o   memory.profile() now uses the type names returned by typeof()
	and no longer has two unlabelled entries.

    o	methods() now warns if it appears to have been called on a
	non-generic function.

    o	The default mosaicplot() method by default draws grey boxes.

    o	nlminb(), similar to that in S-PLUS, added to package 'stats'.

    o	New algorithm "port" (the nl2sol algorithm available in the
	Port library on netlib) added to the nls() function in the
	'stats' package.

    o	object.size() now supports more types, including external
	pointers and weak references.

    o	options() now returns its result in alphabetical order, and is
	documented more comprehensively and accurately.  (Now all
	options used in base R are documented, including
	platform-specific ones.)

	Some options are now set in the package which makes use of
	them (grDevices, stats or utils) if not already set when the
	package is loaded.

    o	New option("OutDec") to set the decimal point for output conversions.

    o	New option("add.smooth") to add smoothers to a plot, currently
	only used by plot.lm().

    o	pie() has new optional arguments 'clockwise' and 'init.angle'.

    o	plot.lm() has two new plots (for 'which' = 5 or 6), plotting
	residuals or cook distances versus (transformed) leverages - unless
	these are constant.  Further, the new argument 'add.smooth' adds a
	loess smoother to the point plots by default, and 'qqline = TRUE'
	adds a qqline() to the normal plot.
	The default for 'sub.caption' has been improved for long calls.

    o	R.home() has been expanded to return the paths to components
	(which can as from this version be installed elsewhere).

    o   readbin() and writeBin() now support raw vectors as well as
	filenames and connections.

    o	read.dcf() can now read gzipped files.

    o	read.table() now passes 'allowEscapes' to scan().

    o	sample(x, size, prob, replace = TRUE) now uses a faster
	algorithm if there are many reasonably probable values.  (This
	does mean the results will be different from earlier versions
	of R.)  The speedup is modest unless 'x' is very large _and_
	'prob' is very diffuse so that thousands of distinct values
	will be generated with an appreciable frequency.

    o	scatter.smooth() now works a bit more like other plotting
	functions (e.g., accepts a data frame for argument 'x').
	Improvements suggested by Kevin Wright.

    o	signif() on complex numbers now rounds jointly to give the
	requested number of digits in the larger component, not
	independently for each component.

    o	New generic function simulate() in the 'stats' package with
	methods for some classes of fitted models.

    o	smooth.spline() has a new argument 'keep.data' which allows to
	provide residuals() and fitted() methods for smoothing splines.

    o	Attempting source(file, chdir=TRUE) with a URL or connection
	for 'file' now gives a warning and ignores 'chdir'.

    o	source() closes its input file after parsing it rather than
	after executing the commands, as used to happen prior to
	2.1.0.  (This is probably only significant on Windows where
	the file is locked for a much shorter time.)

    o	split(), split<-(), unsplit() now have a new argument 'drop = FALSE',
	by default not dropping empty levels; this is *not* back compatible.

    o	sprintf() now supports asterisk `*' width or precision
	specification (but not both) as well as `*1$' to `*99$'.  Also the
	handling of `%' as conversion specification terminator is now
	left to the system and doesn't affect following specifications.

    o	The plot method for stl() now allows the colour of the range
	bars to be set (default unchanged at "light gray").

    o	Added tclServiceMode() function to the tcltk package to allow
	updating to be suspended.

    o	terms.formula() no longer allows '.' in a formula unless there
	is a (non-empty) 'data' argument or 'allowDotAsName = TRUE' is
	supplied.  We have found several cases where 'data' had not
	been passed down to terms() and so '.' was interpreted as a
	single variable leading to incorrect results.

    o	New functions trans3d(), the 3D -> 2D utility from persp()'s
	example, and extendrange(), both in package 'grDevices'.

    o	TukeyHSD() now returns p-values adjusted for multiple comparisons
	(based on a patch contributed by Fernando Henrique Ferraz P. da Rosa).

    o	New functions URLencode() and URLdecode(), particularly for use
	with file:// URLs.  These are used by e.g. browse.env(),
	download.file(), download.packages() and various help() print
	methods.

    o	Functions utf8ToInt() and intToUtf8() to work with UTF-8
	encoded character strings (irrespective of locale or OS-level
	UTF-8 support).

    o	[dqp]wilcox and wilcox.test work better with one very large sample
	size and an extreme first argument.

    o	write() has a new argument 'sep'.

    o	write.csv[2] now also support row.names = FALSE.



    o	The specification of the substitutions done when processing
	Renviron files is more liberal: see ?Startup.  It now
	accepts forms like R_LIBS=${HOME}/Rlibrary:${WORKGRP}/R/lib .

    o	Added recommendation that packages have an overview man page
	<pkg>-package.Rd, and the promptPackage() function to create a
	skeleton version.

    o	Replacement indexing of a data frame by a logical matrix index
	containing NAs is allowed in a few more cases, in particular
	always when the replacement value has length one.

    o	Conversion of .Rd files to latex now handles encoding more
	comprehensively, including some support for UTF-8.

    o	The internal regex code has been upgraded to glibc-2.3.5.
	Apart from a number of bug fixes, this should be somewhat
	faster, especially in UTF-8 locales.

    o	PCRE has been updated to version 6.2.

    o	zlib has been updated to version 1.2.3.

    o	bzip2 has been updated to version 1.0.3.

    o	Complex arithmetic is now done by C99 complex types where
	supported.  This is likely to boost performance, but is
	subject to the accuracy with which it has been implemented.

    o	The printing of complex numbers has changed, handling numbers
	as a whole rather than in two parts.  So both real and
	imaginary parts are shown to the same accuracy, with the
	'digits' parameter referring to the accuracy of the larger
	component, and both components are shown in fixed or
	scientific notation (unless one is entirely zero when it is
	always shown in fixed notation).

    o	Error messages from .C() and .Fortran(), and from parsing errors,
	are now more informative.

    o	The date and date-time functions work better with dates more
	than 5000 years away from 1970-01-01 (by making dubious
	assumptions about the calendar in use).

    o	There is now a traditional Chinese translation, and a much more
	extensive Russian translation.


DEPRECATED & DEFUNCT

    o	Capability "IEEE754" is defunct.

    o	loadURL() is defunct: use load(url()).

    o	delay() is defunct: use delayedAssign() instead.

    o	The 'CRAN' argument to update.packages(), old.packages(),
	new.packages(), download.packages() and install.packages() is
	defunct in favour of 'repos'.

    o	write.table0() is deprecated in favour of the much faster
	write.table().

    o	format.char() is deprecated in favour of format.default().

    o	R_HOME/etc/Rprofile is no longer looked for if
	R_HOME/etc/Rprofile.site does not exist.  (This has been
	undocumented since R 1.4.0.)

    o	CRAN.packages() is deprecated in favour of available.packages().

    o	Rd.sty no longer processes pre-2.0.0 conversions containing \Link.

    o	The stubs for the defunct device GNOME/gnome have been removed.

    o	print.matrix() (which has been identical to print.default since
	R 1.7.0) has been removed.


INSTALLATION

    o	LDFLAGS now defaults to -L/usr/local/lib64 on most Linux
	64-bit OSes (but not ia64).  The use of lib/lib64 can be
	overridden by the new variable LIBnn.

    o	The default installation directory is now ${prefix}/${LIBnn}/R,
	/usr/local/lib64/R on most 64-bit Linux OSes and /usr/local/lib/R
	elsewhere.

    o	The places where the doc, include and share directory trees are
	installed can be specified independently: see the R-admin manual.

    o	We now test for wctrans_t, as apparently some broken OSes have
	wctrans but not wctrans_t (which is required by the relevant
	standards) .

    o	Any external BLAS found is now tested to see if the complex
	routine zdotu works correctly: this provides a compatibility
	test of compiler return conventions.

    o	Installation without NLS is now cleaner, and does not install
	any message catalogues.

    o	src/modules/lapack/dlamc.f is now compiled with -ffloat-store
	if f2c/gcc are used, as well as if g77 is used.

    o	All the Fortran code has been checked to be fully F77
	compliant so there are no longer any warnings from F95
	compilers such as gfortran.

    o	The (not-recommended) options --with-system-zlib,
	--with-system-bzlib and -with-system-pcre now have 'system' in
	the name.

    o	If a Java runtime environment is detected at configure time
	its library path is appended to LD_LIBRARY_PATH or equivalent.
	New Java-related variables JAVA_HOME (path to JRE/JDK), JAVA_PROG
	(path to Java interpreter), JAVA_LD_PATH (Java library path)
	and JAVA_LIBS (flags to link against JNI) are made available
	in Makeconf.

    o	Ei-ji Nakama was contributed a patch for FPU control with the
	Intel compilers on ix86 Linux.


MAC OS X INSTALLATION

    o	--with-blas="-framework vecLib" --with-lapack and
	--with-aqua are now the default configure options.

    o	The default framework version name was changed to not contain
	the patch level (i.e. it is now 2.2 instead of 2.2.0).  Also
	it can be overridden at configure time by setting FW_VERSION
	to the desired name.

    o	The Rmath stand-alone library is now correctly installed inside
	the R.framework if R was configured as a framework.  In
	addition, make install-Rmath-framework will install a
	stand-alone Rmath framework in /Library/Frameworks (unless
	overridden by RMATH_FRAMEWORK_DIR specifying full framework
	path and name including the .framework extension).


PACKAGE INSTALLATION

    o	The encoding for a packages' 00Index.html is chosen from the
	Encoding: field (if any) of the DESCRIPTION file and from the
	\encoding{} fields of any Rd files with non-ASCII titles.
	If there are conflicts, first-found wins with a warning.

    o	R_HOME/doc/html/packages.html is now remade by R not Perl code.
	This may result in small changes in layout and a change in
	encoding (to UTF-8 where supported).

    o	The return value of new.packages() is now updated for any
	packages which may be installed.

    o	available.packages() will read a compressed PACKAGES.gz file in
	preference to PACKAGES if available on the repository: this
	will reduce considerably the download time on a dialup connection.

	The downloaded information about a repository is cached for the
	current R session.

    o	The information about library trees found by
	installed.packages() is cached for the current session, and
	updated only if the modification date of the top-level
	directory has been changed.

    o	A data index is now installed for a package with a 'data' dir
	but no 'man' dir (even though it will have undocumented data objects).

    o	contrib.url path for type="mac.binary" has changed from
	bin/macosx/<version> to	bin/macosx/<arch>/contrib/<version>
	where <arch> corresponds to R.version$arch


UTILITIES

    o	checkFF() used by R CMD check has since R 2.0.0 not reported
	missing PACKAGE arguments when testing installed packages with
	namespaces.  It now

	- treats installed and source packages in the same way.

	- reports missing arguments unless they are in a function in
	  the namespace with a useDynLib declaration (as the
	  appropriate DLL for such calls can be searched for).

    o	Rd2dvi sets the encoding(s) used appropriately.	 If UTF-8
	encoding is used, latex >= 2003/12/01 is required.

    o	codoc() allows help files named pkg_name-defunct.Rd to have
	undocumented arguments (and not just base-defunct.Rd).


C-LEVEL FACILITIES

    o	C function massdist() {called from density()} has new argument
	'xmass' (= weights).

    o	Raw vectors passed to .C() are now passed as unsigned char *
	rather than as SEXPs.  (Wish of Keith Frost, PR#7853)

    o	The search for symbols in a .C/.Call/... call without a
	package argument now searches for an enclosing namespace and
	so finds functions defined within functions in a namespace.

    o	R_max_col() has new (5th) argument '*ties_meth' allowing
	non-random behavior in the case of ties.

    o	The header files have been rationalized: the BLAS routine
	LSAME is now declared in BLAS.h not Linpack.h, Applic.h no
	longer duplicates routines from Linpack.h, and Applic.h is
	divided into API and non-API sections.

    o   memory.c has been instrumented so that Valgrind can track R's
        internal memory management.  To use this, configure using
               --with-valgrind-instrumentation=level
        where level is 1 or 2.  Both levels will find more bugs with
        gctorture(TRUE).  Level 2 makes Valgrind run extremely slowly.

    o	Some support for raw vectors has been added to Rdefines.h.

    o	R_BaseEnv has been added, to refer to the base environment.
    	This is currently equal to R_NilValue, but it will change in
    	a future release.


BUG FIXES

    o	%/% has been adjusted to make x == (x %% y) + y * ( x %/% y )
	more likely in cases when extended-precision registers were
	interfering.

    o	Operations on POSIXct objects (such as seq(), max() and
	subsetting) try harder to preserve time zones and warn if
	inconsistent time zones are used.

    o	as.function.default() no longer asks for a bug report when
	given an invalid body. (PR#1880, PR#7535, PR#7702)

    o	Hershey fonts and grid output (and therefore lattice output)
	now rescale correctly in fit-to-window resizing on a Windows
	graphics device.  Line widths also scale now.

    o	Plotmath has more support for multibyte characters (contributed
	by Ei-ji Nakama).

    o	The X11() device now hints the window manager so that decorations
	appear reliably under e.g. the GNOME WM	 (contributed
	by Ei-ji Nakama).

    o	Subsetting a matrix or an array as a vector used to attempt to
	use the row names to name the result, even though the
	array might be longer than the row names.  Now this is only
	done for 1D arrays when it is done in all cases, even matrix
	indexing.  (Tidies up after the fix to PR#937.)

    o	Constants in mathlib are declared 'const static double' to
	avoid performance issues with the Intel Itanium compiler.

    o	The parser checks the format of numeric constants more
	thoroughly so for example '123E-' is no longer valid.

    o	contourLines() no longer requires an open device (used to
	start a device unnecessarily).	Fix suggested by Barry Rowlingson.

    o	capabilities() used partial matching but was not documented
	to: it no longer does so.

    o	kernel(1,0) printed wrongly;  kernel(<name-string>, *) now returns
	a named kernel in all cases; plot(kernel(.),..) is more flexible.

    o	qgamma(1,s) didn't give +Inf for some s.

    o	installed.packages() and download.packages() now always
	return a matrix as documented, possibly with 0 rows (rather than
	a 0-length character vector or NULL).

    o	Arithmetic operations on data frames no longer coerce the
	names to syntatically valid names.

    o	Units are now properly recycled in grid layouts
	when 'widths' or 'heights' are shorter than the number of
	columns or rows (PR#8014).

    o	DF <- data.frame(A=1:2, B=3:4); DF[1, 1:3] <- NULL gave a wrong
	error message.

    o	spline()/spinefun()'s C code had a memory access buglet which
	never lead to incorrect results.  (PR#8030)

    o	sum() was promoting logical arguments to double not integer
	(as min() and other members of its group do).

    o   loess() had a bug causing it to occasionally miscalculate
        standard errors (PR#7956).  Reported by Benjamin Tyner, fixed
        by Berwin Turlach.

    o	library(keep.source=) was ignored if the package had a
	namespace (the setting of options("keep.source.pkgs") was
	always used).

    o	hist.POSIXct() and hist.Date() now respect par("xaxt").

    o	The 'vfont' argument was not supported correctly in title(),
	mtext(), and axis().  The 'vfont' argument is superseded by
	the par(family=) approach introduced in 2.0.0.  This bug-fix
	just updates the warning messages and documentation to
	properly reflect the new order of things.

    o	The C-level function PrintGenericVector could overflow if
	asked to print a length-1 character vector of several thousand
	characters.  This could happen when printing a list matrix,
	and was fatal up to 2.1.1 and silently truncated in 2.1.1 patched.

    o	What happened for proc.time() and system.time() on
	(Unix-alike) systems which do not support timing was
	incorrectly documented.  (They both exist but throw an error.)
	Further, systen.time() would give an error in its on.exit
	expression.

    o	weighted.residuals() now does sensible things for glm() fits:
	in particular it now agrees with an lm() fit for a Gaussian glm()
	fit.  (PR#7961).

    o   The 'lm' and 'glm' methods for add1() took the weights and
	offset from the original fit, and so gave errors in the
	(dubious) usage where the upper scope resulted in a smaller
	number of cases to fit (e.g. by omitting missing values in new
	variables).  (PR#8049)

    o	demo() had a 'device' argument that did nothing (although it
	was documented to): it has been removed.

    o	Setting new levels on a factor dropped all existing
	attributes, including class "ordered".

    o	format.default(justify="none") now by default converts NA
	character strings, as the other values always did.

    o	format.info() often gave a different field width from format()
	for character vectors (e.g. including missing values or
	non-printable characters).

    o	axis() now ensures that if 'labels' are supplied as character
	strings or expressions then 'at' is also supplied (since the
	calculated value for 'at' can change under resizing).

    o	Defining S4 methods for "[" had resulted in changed behavior of S3
	dispatch in a very rare case which no longer happens.

    o	Fixed segfault when PostScript font loading fails, e.g., when
	R is unable to find afm files (reported by Ivo Welch).

    o	R CMD BATCH <file> now also works when <file> does not end in a
	newline on Unix-alike platforms.

    o   terms.formula() got confused if the 'data' argument was a list with
	non-syntactic names.

    o	prompt() and hence package.skeleton() now produce *.Rd files that
	give no errors (but warnings) when not edited, much more often.

    o	promptClass() and promptMethods() now also escape "%" e.g. in '%*%'
	and the latter gives a message about the file written.

    o	wilcox.test() now warns when conf.level is set higher than
	achievable, preventing errors (PR#3666) and incorrect answers
	with extremely small sample sizes.

    o	The default (protection pointer) stack size (the default for
	'--max-ppsize') has been increased from 10000 to 50000 in order to
	match the increased default options("expressions") (in R 2.1.0).

    o	The R front-end was expecting --gui=tk not Tk as documented,
	and rejecting --gui=X11.

    o	Rdconv -t latex protected only the first << and >> in a chunk
	against conversion to guillemets.

    o	callNextMethod() and callGeneric() have fixes related to
	handling arguments.

    o	ls.diag() now works for fits with missing data. (PR#8139)

    o	window.default() had an incorrect tolerance and so sometimes
	created too short a series if 'start' or 'end' were zero.

    o   Some (fairly pointless) cases of reshape left a
        temporary id variable in the result (PR#8152)

    o	R CMD build used 'tar xhf' which is invalid on FreeBSD systems
	(and followed tar chf, so there could be no symbolic links in
	the tarball).

    o	Subassignment of length zero vectors to NULL gave garbage
    	answers. (PR#8157)

    o	Automatic coercion of raw vectors to lists was missing, so for a
	list (or data frame) z, z[["a"]] <- raw_vector did not work
	and now does.  This also affected DF$a <- raw_vector for a
	data frame DF.

    o	The internal code for commandArgs() was missing PROTECTs.

    o	The width for strwrap() was used as one less than specified.

    o	R CMD INSTALL was not cleaning up after an unsuccessful
	install of a non-bundle which was not already installed.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907

_______________________________________________
R-announce at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce



From roger.bos at gmail.com  Thu Oct  6 14:14:42 2005
From: roger.bos at gmail.com (roger bos)
Date: Thu, 6 Oct 2005 08:14:42 -0400
Subject: [R] Animation of Mandelbrot Set
In-Reply-To: <CA0BCF3BED56294AB91E3AD74B849FD503F00DE2@us-arlington-0668.mail.saic.com>
References: <CA0BCF3BED56294AB91E3AD74B849FD503F00DE2@us-arlington-0668.mail.saic.com>
Message-ID: <1db726800510060514x7c77883iad53ba36d30d1c5f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051006/93cd71a6/attachment.pl

From I.Visser at uva.nl  Thu Oct  6 14:19:23 2005
From: I.Visser at uva.nl (Ingmar Visser)
Date: Thu, 06 Oct 2005 14:19:23 +0200
Subject: [R] Animation of Mandelbrot Set
In-Reply-To: <1db726800510060514x7c77883iad53ba36d30d1c5f@mail.gmail.com>
Message-ID: <BF6AE2EB.8BDF%I.Visser@uva.nl>

The binary version of caTools on CRAN (1.0) does not have the write.gif
function but the source version (1.4) does ...
hth, ingmar

> From: roger bos <roger.bos at gmail.com>
> Reply-To: roger bos <roger.bos at gmail.com>
> Date: Thu, 6 Oct 2005 08:14:42 -0400
> To: "Tuszynski, Jaroslaw W." <JAROSLAW.W.TUSZYNSKI at saic.com>
> Cc: "\(r-help at stat.math.ethz.ch.\)" <r-help at stat.math.ethz.ch>
> Subject: Re: [R] Animation of Mandelbrot Set
> 
> Anyone know why I would get an Error: couldn't find function "write.gif"
> despite loading library(caTools) with no errors in R 2.1.1 under XP?



From JAROSLAW.W.TUSZYNSKI at saic.com  Thu Oct  6 14:23:05 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Thu, 6 Oct 2005 08:23:05 -0400 
Subject: [R] playing with R: make a animated GIF file...
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD503FD2CFF@us-arlington-0668.mail.saic.com>

See write.gif function in caTools.

Jarek 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of klebyn
Sent: Wednesday, October 05, 2005 8:05 PM
To: r-help at stat.math.ethz.ch
Subject: [R] playing with R: make a animated GIF file...


Hello all


I am playing with R for to make a animated GIF.

any suggestions, improvements are welcome :-)

case somebody could help me, i thanks!


Cleber N. Borges ( klebyn )




my objective:

(steps TODO)

-------------------
1) to save PNG files;

----->  i don't know the best way to make this;


2) transform the PNG files into GIF files (easy! no problem!  ... i think
...)


3) reload the GiF files in R and use the caTools package to make a 
animated GIF.

------------------

############################   the code

########  reverse the STRING

strReverse <- function(x) sapply(lapply(strsplit(x, NULL), rev), paste, 
collapse="")

########  logotype to animate

yourLogo =    "Is Nice to play with R-package       "

logoWidth = 1.5
logoHeight = 2.5

L = nchar(yourLogo)

TrigSplit = 360 / L

yourLogo = strReverse(yourLogo)

posx = numeric(L)
posy = numeric(L)

for( i in 0:L){
posx[i] = logoHeight * sin(i * TrigSplit * pi / 180)
posy[i] = logoWidth *  cos(i * TrigSplit * pi / 180)
}

max_x = max(posx)*1.1
max_y = max(posy)*3

min_x = min(posx)*1.1
min_y = min(posy)*3


cex = 2/(posy + 2)

idx = 1:L


for(j in 1:L-1) {

###################file = paste("CQM_",j,".png",sep="")

###################png(filename=file, bg="transparent")

plot(0,t='n', xlim=c(min_x,max_x), ylim=c(min_y,max_y), axes=FALSE, 
ann=FALSE, font=3  )

for( i in 1:L){text(x=posx[i], y=posy[i], 
labels=substr(yourLogo,idx[i],idx[i]), col='blue', cex=cex[i] ) }

idx = (append(idx[L],idx))[1:L]

Sys.sleep(0.2)

###################dev.off()
}

##############  final code

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From jholtman at gmail.com  Thu Oct  6 14:26:26 2005
From: jholtman at gmail.com (jim holtman)
Date: Thu, 6 Oct 2005 08:26:26 -0400
Subject: [R] Interpolation in time
In-Reply-To: <000001c5ca66$ebeab670$7ad0e182@anette>
References: <000001c5ca66$ebeab670$7ad0e182@anette>
Message-ID: <644e1f320510060526g41bd93f7s503d5e722f1ec9a2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051006/45727c0d/attachment.pl

From JAROSLAW.W.TUSZYNSKI at saic.com  Thu Oct  6 14:31:15 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Thu, 6 Oct 2005 08:31:15 -0400 
Subject: [R] Animation of Mandelbrot Set
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD503FD2D0F@us-arlington-0668.mail.saic.com>

http://cran.r-project.org/src/contrib/Descriptions/caTools.html has current
versions (1.4) of both source and binary.  

 Jarek 
====================================================\==== 
 Jarek Tuszynski, PhD.                           o / \ 
 Science Applications International Corporation  <\__,|  
 (703) 676-4192                                   ">  \ 
 Jaroslaw.W.Tuszynski at saic.com                     `   \ 



-----Original Message-----
From: I.Visser at uva.nl [mailto:I.Visser at uva.nl] 
Sent: Thursday, October 06, 2005 8:19 AM
To: roger bos; Tuszynski, Jaroslaw W.
Cc: (r-help at stat.math.ethz.ch.)
Subject: Re: [R] Animation of Mandelbrot Set

The binary version of caTools on CRAN (1.0) does not have the write.gif
function but the source version (1.4) does ...
hth, ingmar

> From: roger bos <roger.bos at gmail.com>
> Reply-To: roger bos <roger.bos at gmail.com>
> Date: Thu, 6 Oct 2005 08:14:42 -0400
> To: "Tuszynski, Jaroslaw W." <JAROSLAW.W.TUSZYNSKI at saic.com>
> Cc: "\(r-help at stat.math.ethz.ch.\)" <r-help at stat.math.ethz.ch>
> Subject: Re: [R] Animation of Mandelbrot Set
> 
> Anyone know why I would get an Error: couldn't find function "write.gif"
> despite loading library(caTools) with no errors in R 2.1.1 under XP?



From roger.bos at gmail.com  Thu Oct  6 14:34:50 2005
From: roger.bos at gmail.com (roger bos)
Date: Thu, 6 Oct 2005 08:34:50 -0400
Subject: [R] modeling language for optimization problems
In-Reply-To: <Pine.LNX.4.61.0510031905030.18893@gannet.stats>
References: <355C35514FEAC9458F75947F5270974D076D06@usctmx1103.merck.com>
	<Pine.LNX.4.61.0510031529370.4535@gannet.stats>
	<1db726800510031009q3350e2d6h88e41cdbfc6c60f6@mail.gmail.com>
	<Pine.LNX.4.61.0510031905030.18893@gannet.stats>
Message-ID: <1db726800510060534nccbf8d4t85e6b48b208454de@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051006/799ae5e8/attachment.pl

From david.meyer at wu-wien.ac.at  Thu Oct  6 16:37:12 2005
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Thu, 6 Oct 2005 16:37:12 +0200
Subject: [R]  how to use  tune.knn() for dataset with missing values
Message-ID: <20051006163712.7340e11b.david.meyer@wu-wien.ac.at>


Well, since knn() can't handle incomplete data as it says, you can
choose to either omit incomplete observations (e.g., using na.omit()),
or to impute the data if the conditions are met (missingness at random,
...); see, e.g.,  packages cat, mix, norm, and e1071 for that.

HTH,
David

------------------------

Hi Everybody,

i again have the problem in using tune.knn(), its giving an error saying

missing values are not allowed.... again here is the script for 
BreastCancer Data,

library(e1071)
library(mda)

trdata<-data.frame(train,row.names=NULL)
attach(trdata)

xtr <- subset(trdata, select = -Class)
ytr <- Class

bestpara <-tune.knn(xtr,ytr, k = 1:25, tunecontrol =
tune.control(sampling 
= "cross"))

and here i got the mentioned error.

can anybody help me in this regard...

Thanks & Regards,

Uttam Phulwale
Tata Consultancy Services Limited
Mailto: uttam.phulwale at tcs.com
Website: http://www.tcs.com



From bady at univ-lyon1.fr  Thu Oct  6 14:39:27 2005
From: bady at univ-lyon1.fr (bady@univ-lyon1.fr)
Date: Thu, 06 Oct 2005 14:39:27 +0200
Subject: [R] Compare two distance matrices
In-Reply-To: <e3f8e9a00510060323x1824657et76b4d6c94c2177c0@mail.gmail.com>
References: <e3f8e9a00510060323x1824657et76b4d6c94c2177c0@mail.gmail.com>
Message-ID: <1128602367.43451affc2602@webmail.univ-lyon1.fr>

Hi, hi all,



> I am trying to compare two distance matrices with R. I would like to
> create a XY plot of these matrices and do some linear regression on
> it. But, I am a bit new to R, so i have a few questions (I searched in
> the documentation with no success).
> The first problem is loading a distance matrix into R. This matrix is
> the output of a the Phylip program Protdist and lookes like this:
> I tried with the scan() function to load the files, but with no
> success. How should i load in these files? ....
>


you can separately load each matrix with two text files.

require(ade4)
mat1 <- read.table("mat1.txt")
nam1 <- mat1[,1]
mat1 <- mat1[,-1]
row.names(mat1) <- names(mat1) <- nam1
mat2 <- read.table("mat2.txt")
nam2 <- mat2[,1]
mat2 <- mat2[,-1]
row.names(mat2) <- names(mat2) <- nam2

dist1 <- mat2dist(mat1)
dist2 <- mat2dist(mat2)

# with mat1:
# n_crassa    0.000000  0.690737  0.895257  0.882576  2.365386
# c_neufor    0.690737  0.000000  0.956910  0.979988  2.103041
# a_thaliana  0.895257  0.956910  0.000000  1.003668  2.724847
# pompep      0.882576  0.979988  1.003668  0.000000  2.065202
# s_cerevis   2.365386  2.103041  2.724847  2.065202  0.000000

# and mat2:
# n_crassa    0.000000  0.739560  0.933986  0.861644  2.207467
# c_neufor    0.739560  0.000000  0.988779  0.925168  1.941141
# a_thaliana  0.933986  0.988779  0.000000  1.007803  2.415320
# pompep      0.861644  0.925168  1.007803  0.000000  2.394490
# s_cerevis   2.207467  1.941141  2.415320  2.394490  0.000000

I think that it?s the more simple solution, NOT the optimal solution. Maybe,
there is an interface to read Phylip file in Bioconductor project(?).

To transform matrix to dist, you can use the function mat2dist of the library
ade4 (see example)

To compare 2 distances matrices, there are many possibility  ! For example, if
the distances matrices are Euclidian, you can used directly principal
coordinate analyses (dudi.pco), and co-inertia analysis or procuste
analysis,etc ...

# examples:


# Data preparation
require(ade4)
mat1 <- read.table("mat1.txt")
nam1 <- mat1[,1]
mat1 <- mat1[,-1]
row.names(mat1) <- names(mat1) <- nam1
mat2 <- read.table("mat2.txt")
nam2 <- mat2[,1]
mat2 <- mat2[,-1]
row.names(mat2) <- names(mat2) <- nam2

? mat2dist
dist1 <- mat2dist(mat1)
dist2 <- mat2dist(mat2)

dist1
dist2

is.euclid(dist1)
is.euclid(dist2)
# cool the distances matrices are euclidian :)

# to compare the 2 matrices
# example 1 :  mantel test
? mantel.randtest
mt1 <- mantel.randtest(dist1,dist2,nrepet=10)
plot(mt1)

# Example 2: coefficient of vectorial correlation (Escoufier, 1973)
? RVdist.randtest
RV1 <- RVdist.randtest(dist1,dist2,nrepet=10)
plot(RV1)

# Example 3: coinertia analysis
?dudi.pco
# ?cmdscale
?coinertia
?randtest.coinertia

pco1 <- dudi.pco(dist1,nf=3,scannf=F)
pco2 <- dudi.pco(dist2,nf=3,scannf=F)
co1 <- coinertia(pco1,pco2,nf=3,scannf=F)
plot(co1)
testco1 <-randtest.coinertia(co1,nrepet=10)
plot(testco1)

# Example 4: procuste analysis
? procuste
? procuste.randtest
pco1 <- dudi.pco(dist1,nf=3,scannf=F)
pco2 <- dudi.pco(dist2,nf=3,scannf=F)
proc1 <- procuste(pco1$tab,pco2$tab)
plot(proc1)
testproc1 <-procuste.randtest(pco1$tab,pco2$tab,nrepet=10)
plot(testproc1)

....

the choice depend to your outcome.


hopes this help


P.BADY



From roger.bos at gmail.com  Thu Oct  6 14:39:31 2005
From: roger.bos at gmail.com (roger bos)
Date: Thu, 6 Oct 2005 08:39:31 -0400
Subject: [R] Animation of Mandelbrot Set
In-Reply-To: <CA0BCF3BED56294AB91E3AD74B849FD503FD2D0F@us-arlington-0668.mail.saic.com>
References: <CA0BCF3BED56294AB91E3AD74B849FD503FD2D0F@us-arlington-0668.mail.saic.com>
Message-ID: <1db726800510060539q23194cbev903326eb5b52a4c3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051006/f6a54ddc/attachment.pl

From jfox at mcmaster.ca  Thu Oct  6 14:43:46 2005
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 6 Oct 2005 08:43:46 -0400
Subject: [R] R/S-Plus equivalent to Genstat "predict": predictions over
	"averages" of covariates
In-Reply-To: <43448694.4030201@usq.edu.au>
Message-ID: <20051006124344.VTWH26550.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Peter,

See the effects package, described in
<http://www.jstatsoft.org/counter.php?id=75&url=v08/i15/effect-displays-revi
sed.pdf>.

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Peter Dunn
> Sent: Wednesday, October 05, 2005 9:06 PM
> To: R-help mailing list
> Subject: [R] R/S-Plus equivalent to Genstat "predict": 
> predictions over "averages" of covariates
> 
> Hi all
> 
> I'm doing some things with a colleague comparing different 
> sorts of models.  My colleague has fitted a number of glms in 
> Genstat (which I have never used), while the glm I have been 
> using is only available for R.
> 
> He has a spreadsheet of fitted means from each of his models 
> obtained from using the Genstat "predict" function.  For 
> example, suppose we fit the model of the type
>     glm.out <- glm( y ~ factor(F1) + factor(F2) + X1 + poly(X2,2) +
>        poly(X3,2), family=...)
> 
> Then he produces a table like this (made up, but similar):
> 
> F1(level1)	12.2
> F1(level2)	14.2
> F1(level3)	15.3
> F2(level1)	10.3
> F2(level2)	9.1
> X1=0		10.2
> X1=0.5		10.4
> X1=1 		10.4
> X1=1.5		10.5
> X1=2		10.9
> X1=2.5		11.9
> X1=3		11.8
> X2=0		12.0
> X2=0.5		12.2
> X2=1 		12.5
> X2=1.5		12.9	
> X2=2		13.0
> X2=2.5		13.1
> X2=3		13.5
> 
> Each of the numbers are a predicted mean.  So when X1=0, on 
> average we predict an outcome of 10.2.
> 
> To obtain these figures in Genstat, he uses the Genstat "predict"
> function.  When I asked for an explanation of how it was done 
> (ie to make the "predictions", what values of the other 
> covariates were used) I was told:
> 
> > So, for a one-dimensional table of fitted means for any factor (or 
> > variate), all other variates are set to their average 
> values; and the 
> > factor constants (including the first, at zero) are given a 
> weighted 
> > average depending on their respective numbers of observations.
> 
> So for quantitative variables (such as pH), one uses the mean 
> pH in the data set when making the predictions.  Reasonable anmd easy.
> 
> But for categorical variables (like Month), he implies we use 
> a weighted average of the fitted coefficients for all the 
> months, depending on the proportion of times those factor 
> levels appear in the data.
> 
> (I hope I explained that OK...)
> 
> Is there an equivalent way in R or S-Plus of doing this?  I 
> have to do it for a number of sites and species, so an 
> automated way would be useful.  I have tried searching to no 
> avail (but may not be searching on the correct terms), and 
> tried hard-coding something myself as yet unsuccessfully:  
> The  poly  terms and the use of the weighted averaging over 
> the factor levels are proving a bit too much for my limited skills.
> 
> Any assistance appreciated.  (Any clarification of what I 
> mean can be provided if I have not been clear.)
> 
> Thanks, as always.
> 
> P.
> 
>  > version
>           _
> platform i386-pc-linux-gnu
> arch     i386
> os       linux-gnu
> system   i386, linux-gnu
> status
> major    2
> minor    1.0
> year     2005
> month    04
> day      18
> language R
>  >
> 
> 
> 
> --
> Dr Peter Dunn  |  Senior Lecturer in Statistics Faculty of 
> Sciences, University of Southern Queensland
>    Web:    http://www.sci.usq.edu.au/staff/dunn
>    Email:  dunn <at> usq.edu.au
> CRICOS:  QLD 00244B |  NSW 02225M |  VIC 02387D |  WA 02521C
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From kjetil at redcotel.bo  Thu Oct  6 05:38:42 2005
From: kjetil at redcotel.bo (Kjetil Holuerson)
Date: Wed, 05 Oct 2005 23:38:42 -0400
Subject: [R] R/S-Plus equivalent to Genstat "predict": predictions over
 "averages" of covariates
In-Reply-To: <43448694.4030201@usq.edu.au>
References: <43448694.4030201@usq.edu.au>
Message-ID: <43449C42.1010701@redcotel.bo>

check out the effects package on CRAN.

Kjetil


Peter Dunn wrote:
> Hi all
> 
> I'm doing some things with a colleague comparing different
> sorts of models.  My colleague has fitted a number of glms in
> Genstat (which I have never used), while the glm I have
> been using is only available for R.
> 
> He has a spreadsheet of fitted means from each of his models
> obtained from using the Genstat "predict" function.  For
> example, suppose we fit the model of the type
>     glm.out <- glm( y ~ factor(F1) + factor(F2) + X1 + poly(X2,2) +
>        poly(X3,2), family=...)
> 
> Then he produces a table like this (made up, but similar):
> 
> F1(level1)	12.2
> F1(level2)	14.2
> F1(level3)	15.3
> F2(level1)	10.3
> F2(level2)	9.1
> X1=0		10.2
> X1=0.5		10.4
> X1=1 		10.4
> X1=1.5		10.5
> X1=2		10.9
> X1=2.5		11.9
> X1=3		11.8
> X2=0		12.0
> X2=0.5		12.2
> X2=1 		12.5
> X2=1.5		12.9	
> X2=2		13.0
> X2=2.5		13.1
> X2=3		13.5
> 
> Each of the numbers are a predicted mean.  So when X1=0, on average
> we predict an outcome of 10.2.
> 
> To obtain these figures in Genstat, he uses the Genstat "predict"
> function.  When I asked for an explanation of how it was done (ie to
> make the "predictions", what values of the other covariates were used) I
> was told:
> 
>> So, for a one-dimensional table of fitted means for any factor (or
>> variate), all other variates are set to their average values; and the
>> factor constants (including the first, at zero) are given a weighted
>> average depending on their respective numbers of observations.
> 
> So for quantitative variables (such as pH), one uses the mean pH in the
> data set when making the predictions.  Reasonable anmd easy.
> 
> But for categorical variables (like Month), he implies we use a weighted
> average of the fitted coefficients for all the months, depending on the
> proportion of times those factor levels appear in the data.
> 
> (I hope I explained that OK...)
> 
> Is there an equivalent way in R or S-Plus of doing this?  I have to do
> it for a number of sites and species, so an automated way would be
> useful.  I have tried searching to no avail (but may not be searching
> on the correct terms), and tried hard-coding something myself
> as yet unsuccessfully:  The  poly  terms and the use of the weighted
> averaging over the factor levels are proving a bit too much for my
> limited skills.
> 
> Any assistance appreciated.  (Any clarification of what I mean can be
> provided if I have not been clear.)
> 
> Thanks, as always.
> 
> P.
> 
>  > version
>           _
> platform i386-pc-linux-gnu
> arch     i386
> os       linux-gnu
> system   i386, linux-gnu
> status
> major    2
> minor    1.0
> year     2005
> month    04
> day      18
> language R
>  >
> 
> 
> 



--



From bernarduse1 at yahoo.fr  Thu Oct  6 15:11:09 2005
From: bernarduse1 at yahoo.fr (Marc Bernard)
Date: Thu, 6 Oct 2005 15:11:09 +0200 (CEST)
Subject: [R] Singular matrix
Message-ID: <20051006131109.38467.qmail@web25802.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051006/b07e9f99/attachment.pl

From fcombes at gmail.com  Thu Oct  6 15:14:59 2005
From: fcombes at gmail.com (Florence Combes)
Date: Thu, 6 Oct 2005 15:14:59 +0200
Subject: [R] factor : how does it work ?
Message-ID: <73dae3060510060614k63dd003dlcb37e2568e18f66a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051006/352cfa35/attachment.pl

From murdoch at stats.uwo.ca  Thu Oct  6 15:36:28 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 06 Oct 2005 09:36:28 -0400
Subject: [R] factor : how does it work ?
In-Reply-To: <73dae3060510060614k63dd003dlcb37e2568e18f66a@mail.gmail.com>
References: <73dae3060510060614k63dd003dlcb37e2568e18f66a@mail.gmail.com>
Message-ID: <4345285C.5010307@stats.uwo.ca>

On 10/6/2005 9:14 AM, Florence Combes wrote:
> Dear all,
> 
> I try for long to understand exactly what is the factor type and especially
> how it works, but it seems too difficult for me....
> I read paragraphs about it, and I understand quite well what it is (I think)
> but I still can't figure how to deal with.
> Especially these 2 mysteries (for me) :
> 
> 1st when I make a dataframe (with the as.data.frame() or the data.frame()
> commands) from vectors, it seems that some "columns" of the dataframe (which
> where vectors) are factors and some not, but I didn't find an explanation
> for which become factor and which don't.
> (I know I can use I() to avoid the factor transformaton but I think it is
> not an optimal solution to avoid the factor type just because I don't kno
> how to deal with)

This is described in the ?data.frame man page:  "Character variables 
passed to 'data.frame' are converted to factor columns unless protected 
by 'I'."

> 2d I can't manage to deal with factors, so when I have some, I transform
> them in vectors (with levels()), but I think I miss the power and utility of
> the factor type ?

levels() is not the conversion you want.  That lists all the levels, but 
it doesn't tell you how they correspond to individual observations.  For 
example,

 > df <- data.frame(x=1:3, y=c('a','b','a'))
 > df
   x y
1 1 a
2 2 b
3 3 a
 > levels(df$y)
[1] "a" "b"

If you need to convert back to character values, use as.character():

 > as.character(df$y)
[1] "a" "b" "a"

For many purposes, you can ignore the fact that your data is stored as a 
factor instead of a character vector.  There are a few differences:

  1. You can't compare the levels of a factor unless you declared it to 
be ordered:

 > df$y[1] > df$y[2]
[1] NA
Warning message:
 > not meaningful for factors in: Ops.factor(df$y[1], df$y[2])

but

 > df$y <- ordered(df$y)
 > df$y[1] > df$y[2]
[1] FALSE

However, you need to watch out here: the comparison is done by the order 
of the factors, not an alphabetic comparison of their names:

 > levels(df$y) <- c("before", "after")
 > df
   x      y
1 1 before
2 2  after
3 3 before
 > df$y[1] > df$y[2]
[1] FALSE


  2. as.integer() works differently on factors:  it gets the position in 
the levels vector.  For example,

 > as.integer(df$y)
[1] 1 2 1
 > as.integer(as.character(df$y))
[1] NA NA NA
Warning message:
NAs introduced by coercion

There are other differences, but these are the two main ones that are 
likely to cause you trouble.

Duncan Murdoch



From andy_liaw at merck.com  Thu Oct  6 15:41:16 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 6 Oct 2005 09:41:16 -0400
Subject: [R] Singular matrix
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED4D9@usctmx1106.merck.com>

Don't you have the dimension of x backward?  Try:

> set.seed(1)
> x <- matrix(rnorm(50, 3, 3), 10, 5)
> vinv <- solve(crossprod(x))
> vinv
             [,1]         [,2]         [,3]         [,4]         [,5]
[1,]  0.019918251 -0.006247646  0.006600209  0.003687249 -0.018670806
[2,] -0.006247646  0.018121025 -0.014815905 -0.005647350  0.003434065
[3,]  0.006600209 -0.014815905  0.023411617 -0.002250342 -0.003258960
[4,]  0.003687249 -0.005647350 -0.002250342  0.025168959 -0.020070844
[5,] -0.018670806  0.003434065 -0.003258960 -0.020070844  0.039593016

If you really have 5 cases and 10 variables, the covariance matrix will
have to be singular.

Andy

> From: Marc Bernard
> 
> Dear All,
>  
> I have written the  following programs  to find a 
> non-singular (10*10) covariance matrix.
> Here  is the program:
>  
> nitems <- 10
> 
> x <- array(rnorm(5*nitems,3,3), c(5,nitems))
> 
> sigma <- t(x)%*%x
> 
> inverse <- try(solve(sigma), TRUE)
> 
>  
> 
> while(inherits(inverse, "try-error")) 
> 
> {
> 
> x <- array(rnorm(5*nitems,3,3), c(5,nitems))
> 
> sigma <- t(x)%*%x
> 
> inverse <- try(solve(sigma), TRUE)
> 
> }
> 
>  
> 
> The loop doesn't stop ...  This means that  no "non-singular" 
> matrix was found!!!
> 
> some thing wrong !!
> 
>  
> 
> Thanks a lot for any reply
> 
>  
> 
> Bernard
> 
>  
> 
>  
> 
>  
> 
> 
> 		
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From dimitris.rizopoulos at med.kuleuven.be  Thu Oct  6 15:45:49 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Thu, 6 Oct 2005 15:45:49 +0200
Subject: [R] Singular matrix
References: <20051006131109.38467.qmail@web25802.mail.ukl.yahoo.com>
Message-ID: <00e601c5ca7c$42dc0c80$0540210a@www.domain>

'x' is a rank 5 matrix from which you want to create a rank 10 
crossproduct! Try the following instead:

x <- array(rnorm(100 * nitems, 3, 3), c(100, nitems))
sigma <- crossprod(x)

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Marc Bernard" <bernarduse1 at yahoo.fr>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, October 06, 2005 3:11 PM
Subject: [R] Singular matrix


> Dear All,
>
> I have written the  following programs  to find a non-singular 
> (10*10) covariance matrix.
> Here  is the program:
>
> nitems <- 10
>
> x <- array(rnorm(5*nitems,3,3), c(5,nitems))
>
> sigma <- t(x)%*%x
>
> inverse <- try(solve(sigma), TRUE)
>
>
>
> while(inherits(inverse, "try-error"))
>
> {
>
> x <- array(rnorm(5*nitems,3,3), c(5,nitems))
>
> sigma <- t(x)%*%x
>
> inverse <- try(solve(sigma), TRUE)
>
> }
>
>
>
> The loop doesn't stop ...  This means that  no "non-singular" matrix 
> was found!!!
>
> some thing wrong !!
>
>
>
> Thanks a lot for any reply
>
>
>
> Bernard
>
>
>
>
>
>
>
>
>
> ---------------------------------
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From owzar001 at mc.duke.edu  Thu Oct  6 16:08:22 2005
From: owzar001 at mc.duke.edu (Kouros Owzar)
Date: Thu, 6 Oct 2005 10:08:22 -0400
Subject: [R] Kouros Owzar is out
Message-ID: <OF72CB15BE.44A8BA8C-ON85257092.004DABDA-85257092.004DABDA@notes.duke.edu>


I will be out of the office starting  10/05/2005 and will not return until
10/07/2005.



From anette at geoplus.dk  Thu Oct  6 16:10:15 2005
From: anette at geoplus.dk (=?iso-8859-1?Q?Anette_N=F8rgaard?=)
Date: Thu, 6 Oct 2005 16:10:15 +0200
Subject: [R]  Interpolation in time
Message-ID: <000501c5ca7f$aca52a90$7ad0e182@anette>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051006/428bd6fc/attachment.pl

From maechler at stat.math.ethz.ch  Thu Oct  6 16:17:37 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 6 Oct 2005 16:17:37 +0200
Subject: [R] Kouros Owzar is out
In-Reply-To: <OF72CB15BE.44A8BA8C-ON85257092.004DABDA-85257092.004DABDA@notes.duke.edu>
References: <OF72CB15BE.44A8BA8C-ON85257092.004DABDA-85257092.004DABDA@notes.duke.edu>
Message-ID: <17221.12801.618767.119327@stat.math.ethz.ch>

Well, cool,
why do you need to tell this to more than 3000 readers of R-help ??

    Kouros> I will be out of the office starting  10/05/2005 and will not return until
    Kouros> 10/07/2005.

    Kouros> ______________________________________________
    Kouros> R-help at stat.math.ethz.ch mailing list
    Kouros> https://stat.ethz.ch/mailman/listinfo/r-help
    Kouros> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


PLEASE !!!!!!!!!!!!



From Achim.Zeileis at wu-wien.ac.at  Thu Oct  6 16:17:57 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Thu, 6 Oct 2005 16:17:57 +0200
Subject: [R] Interpolation in time
In-Reply-To: <000501c5ca7f$aca52a90$7ad0e182@anette>
References: <000501c5ca7f$aca52a90$7ad0e182@anette>
Message-ID: <20051006161757.1a5a2647.Achim.Zeileis@wu-wien.ac.at>

On Thu, 6 Oct 2005 16:10:15 +0200 Anette N??rgaard wrote:

> This is exactly what I requested, thank you!! However I do actually
> have several columns in my data sheet where I need to do the same
> thing, then how do I come about that?

Look at na.approx() in package zoo.
Best,
Z
  
> e.g.
>  
> yr<-c(rep(2000,14))
> doy<-c(16:29)
> dat1<-c(3.2,NA,NA,NA,NA,NA,NA,5.1,NA,NA,NA,NA,NA,4.6)
> dat2<-c(2.2,NA,NA,NA,NA,NA,NA,6.1,NA,NA,NA,NA,NA,4.2)
> dat3<-c(3.4,NA,NA,NA,NA,NA,NA,4.1,NA,NA,NA,NA,NA,4.7)
> ta<-cbind(yr,doy,dat1,dat2,dat3)
>  
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From ggrothendieck at gmail.com  Thu Oct  6 16:19:32 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 6 Oct 2005 10:19:32 -0400
Subject: [R] Interpolation in time
In-Reply-To: <000001c5ca66$ebeab670$7ad0e182@anette>
References: <000001c5ca66$ebeab670$7ad0e182@anette>
Message-ID: <971536df0510060719r235e62a2n8b2be500e4efc45c@mail.gmail.com>

Is doy intended to represent the number of days since the beginning
of the year?  In that case convert the first two columns to class Date
and interpolate using approx.  See ?approx for variations:

tt <- as.Date(paste(yr, 1, 1, sep = "-")) + doy - 1
ta[,"dat"] <- approx(tt, dat, tt)$y

Even better would be to create an irregular time series object.

library(zoo)
tt <- as.Date(paste(yr, 1, 1, sep = "-")) + doy - 1
ta.z <- na.approx(zoo(dat, tt))

Now ta.z is a zoo object representing your time series. coredata(ta.z)
is the data and time(ta.z) are the dates.  See:

library(zoo)
vignette("zoo")

for more info.




On 10/6/05, Anette N??rgaard <anette at geoplus.dk> wrote:
> Can anybody help me write a code on the following data example, which
> fills out all NA values by using a linear interpolation with the two
> closest values?
>
> Doy is day of year (%j).
>
> Code example:
> yr<-c(rep(2000,14))
> doy<-c(16:29)
> dat<-c(3.2,NA,NA,NA,NA,NA,NA,5.1,NA,NA,NA,NA,NA,4.6)
> ta<-cbind(yr,doy,dat)
>
> ta
>      yr doy dat
>  [1,] 2000  16 3.2
>  [2,] 2000  17  NA
>  [3,] 2000  18  NA
>  [4,] 2000  19  NA
>  [5,] 2000  20  NA
>  [6,] 2000  21  NA
>  [7,] 2000  22  NA
>  [8,] 2000  23 5.1
>  [9,] 2000  24  NA
> [10,] 2000  25  NA
> [11,] 2000  26  NA
> [12,] 2000  27  NA
> [13,] 2000  28  NA
> [14,] 2000  29 4.6
>
> Anette Norgaard
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From fcombes at gmail.com  Thu Oct  6 16:20:08 2005
From: fcombes at gmail.com (Florence Combes)
Date: Thu, 6 Oct 2005 16:20:08 +0200
Subject: [R] factor : how does it work ?
In-Reply-To: <73dae3060510060651l3e512d2bq1bc6a8d0274a5e09@mail.gmail.com>
References: <73dae3060510060614k63dd003dlcb37e2568e18f66a@mail.gmail.com>
	<4345285C.5010307@stats.uwo.ca>
	<73dae3060510060651l3e512d2bq1bc6a8d0274a5e09@mail.gmail.com>
Message-ID: <73dae3060510060720n5357f90fj32c55ee7765f436a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051006/7d53b7a1/attachment.pl

From murdoch at stats.uwo.ca  Thu Oct  6 16:32:37 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 06 Oct 2005 10:32:37 -0400
Subject: [R] factor : how does it work ?
In-Reply-To: <73dae3060510060720n5357f90fj32c55ee7765f436a@mail.gmail.com>
References: <73dae3060510060614k63dd003dlcb37e2568e18f66a@mail.gmail.com>	
	<4345285C.5010307@stats.uwo.ca>	
	<73dae3060510060651l3e512d2bq1bc6a8d0274a5e09@mail.gmail.com>
	<73dae3060510060720n5357f90fj32c55ee7765f436a@mail.gmail.com>
Message-ID: <43453585.8070204@stats.uwo.ca>

On 10/6/2005 10:20 AM, Florence Combes wrote:
>> > > 2d I can't manage to deal with factors, so when I have some, I
>> transform
>> > > them in vectors (with levels()), but I think I miss the power and
>> utility
>> > of
>> > > the factor type ?
>> >
>> > levels() is not the conversion you want.
> 
> 
> in fact I use
> 'as.numeric(levels(f))[f]'
> (from the ?factor description)

That will only work if the levels have names that can be converted to 
numbers.  In the example below, the levels are "a" and "b", so you'll 
get NA values if you try this.
> 
> That lists all the levels, but
>> > it doesn't tell you how they correspond to individual observations. For
>> > example,
>> >
>> > > df <- data.frame(x=1:3, y=c('a','b','a'))
>> > > df
>> > x y
>> > 1 1 a
>> > 2 2 b
>> > 3 3 a
>> > > levels(df$y)
>> > [1] "a" "b"
>> >
>> > If you need to convert back to character values, use as.character():
>> >
>> > > as.character(df$y)
>> > [1] "a" "b" "a"
> 
> 
> got it.
> 
> 
>> > 1. You can't compare the levels of a factor unless you declared it to
>> > be ordered:
>> >
>> > > df$y[1] > df$y[2]
>> > [1] NA
>> > Warning message:
>> > > not meaningful for factors in: Ops.factor(df$y[1], df$y[2])
>> >
>> > but
>> >
>> > > df$y <- ordered(df$y)
>> > > df$y[1] > df$y[2]
>> > [1] FALSE
>> >
>> > However, you need to watch out here: the comparison is done by the order
>> > of the factors
> 
> 
> I am sorry I don't understand this.
> here you compare the position of a in the factor and the position of b in
> the factor ?

It's the position of "a" in the levels() vector that is being compared. 
  I declared that the factor had ordered levels, and R interprets that 
to mean that the first level is less than the second level, etc.  This 
is useful if you want to use meaningful names for ordered categories. 
Comparison will be by the order of the categories, not by the name you 
chose.

Duncan Murdoch

> 
> , not an alphabetic comparison of their names:
>> >
>> > > levels(df$y) <- c("before", "after")
>> > > df
>> > x y
>> > 1 1 before
>> > 2 2 after
>> > 3 3 before
>> > > df$y[1] > df$y[2]
>> > [1] FALSE
> 
> 
> best regards,
> 
> florence.
>



From fcombes at gmail.com  Thu Oct  6 16:50:12 2005
From: fcombes at gmail.com (Florence Combes)
Date: Thu, 6 Oct 2005 16:50:12 +0200
Subject: [R] factor : how does it work ?
In-Reply-To: <43453585.8070204@stats.uwo.ca>
References: <73dae3060510060614k63dd003dlcb37e2568e18f66a@mail.gmail.com>
	<4345285C.5010307@stats.uwo.ca>
	<73dae3060510060651l3e512d2bq1bc6a8d0274a5e09@mail.gmail.com>
	<73dae3060510060720n5357f90fj32c55ee7765f436a@mail.gmail.com>
	<43453585.8070204@stats.uwo.ca>
Message-ID: <73dae3060510060750h3b0b344fqa8f131888fd11f82@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051006/abd6a143/attachment.pl

From ggrothendieck at gmail.com  Thu Oct  6 16:55:41 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 6 Oct 2005 10:55:41 -0400
Subject: [R] Interpolation in time
In-Reply-To: <000501c5ca7f$aca52a90$7ad0e182@anette>
References: <000501c5ca7f$aca52a90$7ad0e182@anette>
Message-ID: <971536df0510060755u60a6bae6pae37f6b08395f7b@mail.gmail.com>

na.approx(zoo(ta[,-seq(2)], tt))

where tt is as before.


On 10/6/05, Anette N??rgaard <anette at geoplus.dk> wrote:
> This is exactly what I requested, thank you!! However I do actually have
> several columns in my data sheet where I need to do the same thing, then
> how do I come about that?
>
> e.g.
>
> yr<-c(rep(2000,14))
> doy<-c(16:29)
> dat1<-c(3.2,NA,NA,NA,NA,NA,NA,5.1,NA,NA,NA,NA,NA,4.6)
> dat2<-c(2.2,NA,NA,NA,NA,NA,NA,6.1,NA,NA,NA,NA,NA,4.2)
> dat3<-c(3.4,NA,NA,NA,NA,NA,NA,4.1,NA,NA,NA,NA,NA,4.7)
> ta<-cbind(yr,doy,dat1,dat2,dat3)
>
>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From murdoch at stats.uwo.ca  Thu Oct  6 16:57:45 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 06 Oct 2005 10:57:45 -0400
Subject: [R] factor : how does it work ?
In-Reply-To: <73dae3060510060750h3b0b344fqa8f131888fd11f82@mail.gmail.com>
References: <73dae3060510060614k63dd003dlcb37e2568e18f66a@mail.gmail.com>	
	<4345285C.5010307@stats.uwo.ca>	
	<73dae3060510060651l3e512d2bq1bc6a8d0274a5e09@mail.gmail.com>	
	<73dae3060510060720n5357f90fj32c55ee7765f436a@mail.gmail.com>	
	<43453585.8070204@stats.uwo.ca>
	<73dae3060510060750h3b0b344fqa8f131888fd11f82@mail.gmail.com>
Message-ID: <43453B69.5090008@stats.uwo.ca>

On 10/6/2005 10:50 AM, Florence Combes wrote:
> a last question, and thanks a million for your patience and your
> explanations ...
> 
> 
> I tried with a df called "merged" and a column named "Pcc_0h_A" (which is
> numeric values):
> 
>> length(as.vector(merged$Pcc_0h_A))
> [1] 12202
>>as.numeric(as.vector(merged$Pcc_0h_A)[1:10])
> [1] 12.276 11.958 14.098 13.843 12.451 11.745 NA NA NA NA
>> ord<-ordered(merged$Pcc_0h_A)
>> length(ord)
> [1] 12202
>> ord[1:10]
> [1] 12.276 11.958 14.098 13.843 12.451 11.745 <NA> <NA> <NA> <NA>
> 5386 Levels: 10.001 < 10.002 < 10.003 < 10.005 < 10.006 < 10.010 < ... <
> 9.999
> 
> here I have <NA> instead of NA because ord is a factor and the notation is
> different ?

I can't tell what's going on here.  Since you are only showing me 
converted values of each column (as.vector(), as.numeric(), ordered(), 
etc.) I can't tell what the original looked like.

A useful way to get an overview of a dataframe is to look at the results 
of three function calls:

head(merged)    # list the first few rows
str(merged)	# describe the structure of the dataframe
summary(merged) # summarize the data in each of the columns.

Duncan Murdoch
> 
>> length(as.numeric(merged$Pcc_0h_A))
> [1] 12202
>> as.numeric(merged$Pcc_0h_A[1:10])
> [1] 1812 1547 3308 3114 1960 1370 NA NA NA NA
> 
> are these the levels names converted into numbers ? I don't think because
> levels are like 10.001, 10.002 etc and 1812, 1547 etc are not in this form.
> 
> thanks a million
> 
> florence;
> 
> 
> 
> 
> On 10/6/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>
>> On 10/6/2005 10:20 AM, Florence Combes wrote:
>> >> > > 2d I can't manage to deal with factors, so when I have some, I
>> >> transform
>> >> > > them in vectors (with levels()), but I think I miss the power and
>> >> utility
>> >> > of
>> >> > > the factor type ?
>> >> >
>> >> > levels() is not the conversion you want.
>> >
>> >
>> > in fact I use
>> > 'as.numeric(levels(f))[f]'
>> > (from the ?factor description)
>>
>> That will only work if the levels have names that can be converted to
>> numbers. In the example below, the levels are "a" and "b", so you'll
>> get NA values if you try this.
>> >
>> > That lists all the levels, but
>> >> > it doesn't tell you how they correspond to individual observations.
>> For
>> >> > example,
>> >> >
>> >> > > df <- data.frame(x=1:3, y=c('a','b','a'))
>> >> > > df
>> >> > x y
>> >> > 1 1 a
>> >> > 2 2 b
>> >> > 3 3 a
>> >> > > levels(df$y)
>> >> > [1] "a" "b"
>> >> >
>> >> > If you need to convert back to character values, use as.character():
>> >> >
>> >> > > as.character(df$y)
>> >> > [1] "a" "b" "a"
>> >
>> >
>> > got it.
>> >
>> >
>> >> > 1. You can't compare the levels of a factor unless you declared it to
>> >> > be ordered:
>> >> >
>> >> > > df$y[1] > df$y[2]
>> >> > [1] NA
>> >> > Warning message:
>> >> > > not meaningful for factors in: Ops.factor(df$y[1], df$y[2])
>> >> >
>> >> > but
>> >> >
>> >> > > df$y <- ordered(df$y)
>> >> > > df$y[1] > df$y[2]
>> >> > [1] FALSE
>> >> >
>> >> > However, you need to watch out here: the comparison is done by the
>> order
>> >> > of the factors
>> >
>> >
>> > I am sorry I don't understand this.
>> > here you compare the position of a in the factor and the position of b
>> in
>> > the factor ?
>>
>> It's the position of "a" in the levels() vector that is being compared.
>> I declared that the factor had ordered levels, and R interprets that
>> to mean that the first level is less than the second level, etc. This
>> is useful if you want to use meaningful names for ordered categories.
>> Comparison will be by the order of the categories, not by the name you
>> chose.
>>
>> Duncan Murdoch
>>
>> >
>> > , not an alphabetic comparison of their names:
>> >> >
>> >> > > levels(df$y) <- c("before", "after")
>> >> > > df
>> >> > x y
>> >> > 1 1 before
>> >> > 2 2 after
>> >> > 3 3 before
>> >> > > df$y[1] > df$y[2]
>> >> > [1] FALSE
>> >
>> >
>> > best regards,
>> >
>> > florence.
>> >
>>
>>
>



From fcombes at gmail.com  Thu Oct  6 17:08:17 2005
From: fcombes at gmail.com (Florence Combes)
Date: Thu, 6 Oct 2005 17:08:17 +0200
Subject: [R] factor : how does it work ?
In-Reply-To: <43453B69.5090008@stats.uwo.ca>
References: <73dae3060510060614k63dd003dlcb37e2568e18f66a@mail.gmail.com>
	<4345285C.5010307@stats.uwo.ca>
	<73dae3060510060651l3e512d2bq1bc6a8d0274a5e09@mail.gmail.com>
	<73dae3060510060720n5357f90fj32c55ee7765f436a@mail.gmail.com>
	<43453585.8070204@stats.uwo.ca>
	<73dae3060510060750h3b0b344fqa8f131888fd11f82@mail.gmail.com>
	<43453B69.5090008@stats.uwo.ca>
Message-ID: <73dae3060510060808g58c2ae9di3a9d5a3372329dc6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051006/81b20149/attachment.pl

From maechler at stat.math.ethz.ch  Thu Oct  6 17:19:40 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 6 Oct 2005 17:19:40 +0200
Subject: [R] Use crossprod() instead of t(x) %*% x !
In-Reply-To: <20051006131109.38467.qmail@web25802.mail.ukl.yahoo.com>
References: <20051006131109.38467.qmail@web25802.mail.ukl.yahoo.com>
Message-ID: <17221.16524.531395.361111@stat.math.ethz.ch>

>>>>> "Marc" == Marc Bernard <bernarduse1 at yahoo.fr>
>>>>>     on Thu, 6 Oct 2005 15:11:09 +0200 (CEST) writes:

...........
	  
    Marc> Here  is the program:
 
    Marc> nitems <- 10
    Marc> x <- array(rnorm(5*nitems,3,3), c(5,nitems))
    Marc> sigma <- t(x)%*%x

    Marc> inverse <- try(solve(sigma), TRUE)

.............

Just a side remark on your code above:

You should learn about and use
crossprod(x) rather than   t(x) %*% x 
because of a
 1) more efficient implementation
 2) more accurate  implementation

The exact details depends on the (accelerated/optimized or not)
version BLAS/Lapack your version of R is using and also on the
kind of matrices.

Further note, that for  
	 crossprod(t(X)) == X %*% t(X)
LAPACK also provides a direc version 
to which the 'Matrix' package interfaces via function
   tcrossprod()
which in particular also works *fast* for some of the sparse
matrix classes.

	
Martin Maechler, ETH Zurich



From fernando.espindola at ifop.cl  Thu Oct  6 17:29:00 2005
From: fernando.espindola at ifop.cl (=?iso-8859-1?Q?Fernando_Esp=EDndola?=)
Date: Thu, 6 Oct 2005 11:29:00 -0400
Subject: [R] Simple question.....
Message-ID: <27004DDE1590B344855CF773E1D019F115C017@postino.ifop.cl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051006/9a3cfc0c/attachment.pl

From andy_liaw at merck.com  Thu Oct  6 17:32:37 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 6 Oct 2005 11:32:37 -0400
Subject: [R] boxplot statistics
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED4DB@usctmx1106.merck.com>

> From: Graham Williams
> 
> Received Tue 04 Oct 2005  7:26pm +1000 from Karin Lagesen:
> > 
> > I have read and reread the boxplot and the boxplot stats page, and I
> > still cannot understand how and what boxplot shows. I realize that
> > this might be due to me not knowing enough statistics, but anyway...
> > 
> > First, how does boxplot determine the size of the box? And 
> is the line
> > inside the box the mean or the median (or something completely
> > different?) And how does it determine how long out the 
> whiskers should
> > go?
> > 
> > Also, the boxplot.stats page talks about "hinges", what are those?  
> > "The two "hinges" are versions of the first and third 
> quartile, i.e.,
> > close to 'quantile(x, c(1,3)/4)'."
> 
> Wikipedia has a reasonable description
> 
>	   http://en.wikipedia.org/wiki/Boxplot

... but not quite accurate.  If I'm not mistaken, boxplots are based on
Tukey's letter values.  Here's one description of what they are:

http://www.math.yorku.ca/SCS/Courses/eda/eda1.html#H2_32:1.2

Andy



From andy_liaw at merck.com  Thu Oct  6 17:34:02 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 6 Oct 2005 11:34:02 -0400
Subject: [R] Simple question.....
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED4DC@usctmx1106.merck.com>

See ?get.

Andy

> From: Fernando Esp??ndola
> 
> 
> Hi all user R,
> 
> My simple question is...I have a vector of names of predictors, 
> 
> text<-c("datem","cola","eslom")...I try to plot the model 
> with this predictor in sequence loop....,  
> for(i in 1:3){
> png(paste("fig_",i,sep=""))
> plot(preplot.gam(mod9)[[i]],se=T,rug=F,main="",xaxt="n",ylab="
> ",xlab="")
> axis(1,as.numeric(text[i]),as.character(text[i]),cex.axis=.9)
> dev.off()
> }
> 
> But the line with function axis get error
> 
> Error in axis(side, at, labels, tick, line, pos, outer, font, 
> vfont, lty,  :
>         no locations are finite
> 
> I put in shell text[i] give "datem", I try to erase the "", 
> can not search what is the function to erase this character 
> (""). Samebody can help me to erase "", when put the 
> predictor without "", datem, there not problem....
> 
> Thank for all  
> 
> 
> Fernando Espindola R.
> Division Investigacion Pesquera
> Instituto de Fomento Pesquero
> Blanco 839
> Valparaiso - CHILE
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From jingli71 at yahoo.com  Thu Oct  6 17:56:52 2005
From: jingli71 at yahoo.com (Claire Lee)
Date: Thu, 6 Oct 2005 08:56:52 -0700 (PDT)
Subject: [R] problem with installing a package
In-Reply-To: <mailman.11.1128592801.28547.r-help@stat.math.ethz.ch>
Message-ID: <20051006155652.77052.qmail@web60216.mail.yahoo.com>

I do have full access to that directory. I have the
bbHist package in c:/PROGRA~1/R/rw2011/library/bbHist
directory. Then under the library directory I did
check and build. Here's what I got:

$ R CMD check bbHist
* checking for working latex ... OK
* using log directory
'c:/progra~1/r/rw2011/library/bbHist.Rcheck'
* using R version 2.1.1, 2005-06-20
* checking for file 'bbHist/DESCRIPTION' ... OK
* this is package 'bbHist' version '0.1-1'
* checking if this is a source package ... WARNING
Subdirectory 'bbHist/src' contains object files.

installing R.css in
c:/progra~1/r/rw2011/library/bbHist.Rcheck


---------- Making package bbHist ------------
  adding build stamp to DESCRIPTION
  making DLL ...
  ... DLL made
  installing DLL
  installing R files
  installing man source files
  installing indices
  installing help
 >>> Building/Updating help pages for package 'bbHist'
     Formats: text html latex example chm
  bbHist                            text    html   
latex   example chm
Microsoft HTML Help Compiler 4.74.8702

Compiling
c:\progra~1\r\rw2011\library\bbHist\chm\bbHist.chm


Compile time: 0 minutes, 0 seconds
2       Topics
2       Local links
0       Internet links
1       Graphic


Created
c:\progra~1\r\rw2011\library\bbHist\chm\bbHist.chm,
21,741 bytes
Compression increased file by 9,099 bytes.
  adding MD5 sums

* DONE (bbHist)

* checking package directory ... OK
* checking for portable file names ... OK
* checking DESCRIPTION meta-information ... OK
* checking package dependencies ... OK
* checking index information ... OK
* checking package subdirectories ... OK
* checking R files for syntax errors ... OK
* checking R files for library.dynam ... OK
* checking S3 generic/method consistency ... OK
* checking replacement functions ... OK
* checking foreign function calls ... WARNING
Foreign function calls without 'PACKAGE' argument:
.C("getBBData", ...)
See section 'System and foreign language interfaces'
of the 'Writing R
Extensions' manual.
* checking Rd files ... OK
* checking for missing documentation entries ... OK
* checking for code/documentation mismatches ... OK
* checking Rd \usage sections ... OK
* checking for CRLF line endings in C/C++/Fortran
sources/headers ... WARNING
Found the following sources/headers with CRLF line
endings:
  src/bbapi.h
  src/bbunix.h
  src/rbb.c
Some Unix compilers require LF line endings.
* creating bbHist-Ex.R ... OK
* checking examples ... OK
* creating bbHist-manual.tex ... OK
* checking bbHist-manual.tex ... ERROR
LaTeX errors when creating DVI version.
This typically indicates Rd problems.

$ R CMD build bbHist
* checking for file 'bbHist/DESCRIPTION' ... OK
* preparing 'bbHist':
* checking DESCRIPTION meta-information ... OK
* cleaning src
* removing junk files
* checking for LF line-endings in source files
    file 'bbHist/src/bbapi.h' had CRLF line endings
    file 'bbHist/src/bbunix.h' had CRLF line endings
    file 'bbHist/src/rbb.c' had CRLF line endings
* checking for empty directories
* building 'bbHist_0.1-1.tar.gz'

And then when I do R CMD INSTALL bbHist, I get 

open(c:/progra~1/r/rw2011/library/bbHist/DESCRIPTION):
No such file or directory


The bbHist directory is removed and a 00LOCK directory
is created. What I don't understand is if INSTALL
removed the bbHist directory, why is it stilling
looking for the DESCRIPTION file in that diretory? I'm
really puzzled. If anyone has any idea, please let me
know. Thanks.


> Date: Thu, 06 Oct 2005 08:47:23 +0200
> From: Uwe Ligges <ligges at statistik.uni-dortmund.de>
> Subject: Re: [R] problem in installing a package
> To: Claire Lee <jingli71 at yahoo.com>
> Cc: r-help at stat.math.ethz.ch
> Message-ID:
> <4344C87B.3080107 at statistik.uni-dortmund.de>
> Content-Type: text/plain; charset=us-ascii;
> format=flowed
> 
> Claire Lee wrote:
> 
> > I'm using R in Windows XP. I created a package
> myself.
> > I've used R CMD check to check it. Everything
> seems OK
> > except the latex. I get the error message:
> > * checking bbHist-manual.tex ... ERROR
> > LaTeX errors when creating DVI version.
> > This typically indicates Rd problems.
> > 
> > I ignored it because I didn't want to submit it to
> > CRAN.
> > 
> > Then I tried to use R CMD INSTALL to install it.
> First
> > I get: 
> > "mv: cannot move
> `c:/PROGRA~1/R/rw2011/library/bbHist'
> > to `c:/PROGRA~1/R/rw2011/library/00LOCK/bbHist
> > ': Permission denied" 
> >
> > and a bunch of making DLL errors.  Then when I
> tried a
> > second time, I get:
> > 
> >
>
open(c:/progra~1/r/rw2011/library/bbHist/DESCRIPTION):
> > No such file or directory
> > 
> > I can see a 00LOCK directory is created in the
> > c:/PROGRA~1/R/rw2011/library directory. Any idea
> why
> > this is happening?
> 
> No, information is still too sparse, unfortunately.
> Do you have full write access?
> The 00LOCK directory is used to save the older
> package in order to be 
> able to restore it if a new installtion fails.
> Something went wrong and you have to remove it
> manually now, I guess.
> 
> Uwe Ligges
> 
> 
> 
> 
> > Thanks.
> > 
> > Claire
> >



From ligges at statistik.uni-dortmund.de  Thu Oct  6 18:08:59 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 06 Oct 2005 18:08:59 +0200
Subject: [R] problem with installing a package
In-Reply-To: <20051006155652.77052.qmail@web60216.mail.yahoo.com>
References: <20051006155652.77052.qmail@web60216.mail.yahoo.com>
Message-ID: <43454C1B.1040907@statistik.uni-dortmund.de>

Claire Lee wrote:

> I do have full access to that directory. I have the
> bbHist package in c:/PROGRA~1/R/rw2011/library/bbHist
> directory. Then under the library directory I did
> check and build. Here's what I got:


Now I understand:

You *must not* have the sources in that library!
You want to install from some *other arbitrary* source directory *into* 
the library mentioned above.

Uwe Ligges




> 
> $ R CMD check bbHist
> * checking for working latex ... OK
> * using log directory
> 'c:/progra~1/r/rw2011/library/bbHist.Rcheck'
> * using R version 2.1.1, 2005-06-20
> * checking for file 'bbHist/DESCRIPTION' ... OK
> * this is package 'bbHist' version '0.1-1'
> * checking if this is a source package ... WARNING
> Subdirectory 'bbHist/src' contains object files.
> 
> installing R.css in
> c:/progra~1/r/rw2011/library/bbHist.Rcheck
> 
> 
> ---------- Making package bbHist ------------
>   adding build stamp to DESCRIPTION
>   making DLL ...
>   ... DLL made
>   installing DLL
>   installing R files
>   installing man source files
>   installing indices
>   installing help
>  >>> Building/Updating help pages for package 'bbHist'
>      Formats: text html latex example chm
>   bbHist                            text    html   
> latex   example chm
> Microsoft HTML Help Compiler 4.74.8702
> 
> Compiling
> c:\progra~1\r\rw2011\library\bbHist\chm\bbHist.chm
> 
> 
> Compile time: 0 minutes, 0 seconds
> 2       Topics
> 2       Local links
> 0       Internet links
> 1       Graphic
> 
> 
> Created
> c:\progra~1\r\rw2011\library\bbHist\chm\bbHist.chm,
> 21,741 bytes
> Compression increased file by 9,099 bytes.
>   adding MD5 sums
> 
> * DONE (bbHist)
> 
> * checking package directory ... OK
> * checking for portable file names ... OK
> * checking DESCRIPTION meta-information ... OK
> * checking package dependencies ... OK
> * checking index information ... OK
> * checking package subdirectories ... OK
> * checking R files for syntax errors ... OK
> * checking R files for library.dynam ... OK
> * checking S3 generic/method consistency ... OK
> * checking replacement functions ... OK
> * checking foreign function calls ... WARNING
> Foreign function calls without 'PACKAGE' argument:
> .C("getBBData", ...)
> See section 'System and foreign language interfaces'
> of the 'Writing R
> Extensions' manual.
> * checking Rd files ... OK
> * checking for missing documentation entries ... OK
> * checking for code/documentation mismatches ... OK
> * checking Rd \usage sections ... OK
> * checking for CRLF line endings in C/C++/Fortran
> sources/headers ... WARNING
> Found the following sources/headers with CRLF line
> endings:
>   src/bbapi.h
>   src/bbunix.h
>   src/rbb.c
> Some Unix compilers require LF line endings.
> * creating bbHist-Ex.R ... OK
> * checking examples ... OK
> * creating bbHist-manual.tex ... OK
> * checking bbHist-manual.tex ... ERROR
> LaTeX errors when creating DVI version.
> This typically indicates Rd problems.
> 
> $ R CMD build bbHist
> * checking for file 'bbHist/DESCRIPTION' ... OK
> * preparing 'bbHist':
> * checking DESCRIPTION meta-information ... OK
> * cleaning src
> * removing junk files
> * checking for LF line-endings in source files
>     file 'bbHist/src/bbapi.h' had CRLF line endings
>     file 'bbHist/src/bbunix.h' had CRLF line endings
>     file 'bbHist/src/rbb.c' had CRLF line endings
> * checking for empty directories
> * building 'bbHist_0.1-1.tar.gz'
> 
> And then when I do R CMD INSTALL bbHist, I get 
> 
> open(c:/progra~1/r/rw2011/library/bbHist/DESCRIPTION):
> No such file or directory
> 
> 
> The bbHist directory is removed and a 00LOCK directory
> is created. What I don't understand is if INSTALL
> removed the bbHist directory, why is it stilling
> looking for the DESCRIPTION file in that diretory? I'm
> really puzzled. If anyone has any idea, please let me
> know. Thanks.
> 
> 
> 
>>Date: Thu, 06 Oct 2005 08:47:23 +0200
>>From: Uwe Ligges <ligges at statistik.uni-dortmund.de>
>>Subject: Re: [R] problem in installing a package
>>To: Claire Lee <jingli71 at yahoo.com>
>>Cc: r-help at stat.math.ethz.ch
>>Message-ID:
>><4344C87B.3080107 at statistik.uni-dortmund.de>
>>Content-Type: text/plain; charset=us-ascii;
>>format=flowed
>>
>>Claire Lee wrote:
>>
>>
>>>I'm using R in Windows XP. I created a package
>>
>>myself.
>>
>>>I've used R CMD check to check it. Everything
>>
>>seems OK
>>
>>>except the latex. I get the error message:
>>>* checking bbHist-manual.tex ... ERROR
>>>LaTeX errors when creating DVI version.
>>>This typically indicates Rd problems.
>>>
>>>I ignored it because I didn't want to submit it to
>>>CRAN.
>>>
>>>Then I tried to use R CMD INSTALL to install it.
>>
>>First
>>
>>>I get: 
>>>"mv: cannot move
>>
>>`c:/PROGRA~1/R/rw2011/library/bbHist'
>>
>>>to `c:/PROGRA~1/R/rw2011/library/00LOCK/bbHist
>>>': Permission denied" 
>>>
>>>and a bunch of making DLL errors.  Then when I
>>
>>tried a
>>
>>>second time, I get:
>>>
>>>
>>
> open(c:/progra~1/r/rw2011/library/bbHist/DESCRIPTION):
> 
>>>No such file or directory
>>>
>>>I can see a 00LOCK directory is created in the
>>>c:/PROGRA~1/R/rw2011/library directory. Any idea
>>
>>why
>>
>>>this is happening?
>>
>>No, information is still too sparse, unfortunately.
>>Do you have full write access?
>>The 00LOCK directory is used to save the older
>>package in order to be 
>>able to restore it if a new installtion fails.
>>Something went wrong and you have to remove it
>>manually now, I guess.
>>
>>Uwe Ligges
>>
>>
>>
>>
>>
>>>Thanks.
>>>
>>>Claire
>>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From maechler at stat.math.ethz.ch  Thu Oct  6 18:10:33 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 6 Oct 2005 18:10:33 +0200
Subject: [R] Compare two distance matrices
In-Reply-To: <1128602367.43451affc2602@webmail.univ-lyon1.fr>
References: <e3f8e9a00510060323x1824657et76b4d6c94c2177c0@mail.gmail.com>
	<1128602367.43451affc2602@webmail.univ-lyon1.fr>
Message-ID: <17221.19577.463128.122194@stat.math.ethz.ch>

>>>>> "bady" == bady  <bady at univ-lyon1.fr>
>>>>>     on Thu, 06 Oct 2005 14:39:27 +0200 writes:

    bady> Hi, hi all,
    >> I am trying to compare two distance matrices with R. I would like to
    >> create a XY plot of these matrices and do some linear regression on
    >> it. But, I am a bit new to R, so i have a few questions (I searched in
    >> the documentation with no success).
    >> The first problem is loading a distance matrix into R. This matrix is
    >> the output of a the Phylip program Protdist and lookes like this:
    >> I tried with the scan() function to load the files, but with no
    >> success. How should i load in these files? ....
    >> 

    bady> you can separately load each matrix with two text files.

    bady> require(ade4)
    bady> mat1 <- read.table("mat1.txt")
    bady> nam1 <- mat1[,1]
    bady> mat1 <- mat1[,-1]
    bady> row.names(mat1) <- names(mat1) <- nam1
    bady> mat2 <- read.table("mat2.txt")
    bady> nam2 <- mat2[,1]
    bady> mat2 <- mat2[,-1]
    bady> row.names(mat2) <- names(mat2) <- nam2

    bady> dist1 <- mat2dist(mat1)
    bady> dist2 <- mat2dist(mat2)

but I don't see why you would need an extra package "ade4" and
its "extra - function"  mat2dist().


when the 'stats' package already provides the function
as.dist(.)  {the help page of which was mentioned by the
original poster}.


Here is a reproducible example showing how I think as.dist()
works sufficiently:

> (m <- toeplitz(round(rnorm(6),2)))
      [,1]  [,2]  [,3]  [,4]  [,5]  [,6]
[1,] -0.42 -0.78 -0.42 -2.24  0.74  1.31
[2,] -0.78 -0.42 -0.78 -0.42 -2.24  0.74
[3,] -0.42 -0.78 -0.42 -0.78 -0.42 -2.24
[4,] -2.24 -0.42 -0.78 -0.42 -0.78 -0.42
[5,]  0.74 -2.24 -0.42 -0.78 -0.42 -0.78
[6,]  1.31  0.74 -2.24 -0.42 -0.78 -0.42
> as.dist(m)
      1     2     3     4     5
2 -0.78                        
3 -0.42 -0.78                  
4 -2.24 -0.42 -0.78            
5  0.74 -2.24 -0.42 -0.78      
6  1.31  0.74 -2.24 -0.42 -0.78
> ## it also works for data frames {if really needed}:
> dm <- as.data.frame(m)
> as.dist(dm)
      1     2     3     4     5
2 -0.78                        
3 -0.42 -0.78                  
4 -2.24 -0.42 -0.78            
5  0.74 -2.24 -0.42 -0.78      
6  1.31  0.74 -2.24 -0.42 -0.78
>



From uofiowa at gmail.com  Thu Oct  6 18:25:32 2005
From: uofiowa at gmail.com (Omar Lakkis)
Date: Thu, 6 Oct 2005 12:25:32 -0400
Subject: [R] isdst
Message-ID: <3f87cc6d0510060925r7629c97difaa7e00217f74b0d@mail.gmail.com>

Can someone, please, explain the difference is results below (notice
the isdst value)

> unlist(as.POSIXlt('2005-7-1'))
  sec   min  hour  mday   mon  year  wday  yday isdst
    0     0     0     1     6   105     5   181     1
> unlist(as.POSIXlt(as.Date('2005-7-1')))
  sec   min  hour  mday   mon  year  wday  yday isdst
    0     0     0     1     6   105     5   181     0



From tlumley at u.washington.edu  Thu Oct  6 18:25:29 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 6 Oct 2005 09:25:29 -0700 (PDT)
Subject: [R] Testing strata by covariate interactions in coxph
In-Reply-To: <JA8AAAAAAnjfpAABYQABU5AQ2thU@postila.stat.fi>
References: <JA8AAAAAAnjfpAABYQABU5AQ2thU@postila.stat.fi>
Message-ID: <Pine.LNX.4.63a.0510060923480.29173@homer24.u.washington.edu>

On Thu, 6 Oct 2005, Pyy-Martikainen Marjo wrote:

> I specify a model  with strata by covariate interactions. I would like to
> conduct a Wald test
> for the null hypothesis "no differences between any covariate effects in the 3
> groups".

The "survey" package has a function regTermTest (which isn't specific to 
survey models -- it works on anything with vcov() and coef() methods).


 	-thomas



From ggrothendieck at gmail.com  Thu Oct  6 18:47:59 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 6 Oct 2005 12:47:59 -0400
Subject: [R] isdst
In-Reply-To: <3f87cc6d0510060925r7629c97difaa7e00217f74b0d@mail.gmail.com>
References: <3f87cc6d0510060925r7629c97difaa7e00217f74b0d@mail.gmail.com>
Message-ID: <971536df0510060947m394ab36drfa7bd039d1959e1a@mail.gmail.com>

See the Avoiding Errors section of the Help Desk article
in R News 4/1.


On 10/6/05, Omar Lakkis <uofiowa at gmail.com> wrote:
> Can someone, please, explain the difference is results below (notice
> the isdst value)
>
> > unlist(as.POSIXlt('2005-7-1'))
>  sec   min  hour  mday   mon  year  wday  yday isdst
>    0     0     0     1     6   105     5   181     1
> > unlist(as.POSIXlt(as.Date('2005-7-1')))
>  sec   min  hour  mday   mon  year  wday  yday isdst
>    0     0     0     1     6   105     5   181     0
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From davison at uchicago.edu  Thu Oct  6 18:54:25 2005
From: davison at uchicago.edu (Dan Davison)
Date: Thu, 6 Oct 2005 11:54:25 -0500 (CDT)
Subject: [R] blank graphics window while R is working
Message-ID: <Pine.GSO.4.62.0510061101150.7974@harper.uchicago.edu>

Dear R-help,

When R starts to execute some code, all the graphics windows 
associated with that R session go blank, and remain blank until the R 
prompt returns.

I am using the "ion" window manager 
(http://modeemi.cs.tut.fi/~tuomov/ion/) under Debian linux.

I notice that under the gnome desktop environment with Fedora Core 4 
linux, the graphics windows retain their images while R evaluates. Does 
anyone else experience this problem or know of any solution, or is this 
just an incompatibility between R and my (presumably somewhat uncommon) 
window manager?


Thanks a lot,

Dan

p.s. the problem remains whether R is run via ESS or not.

> version
          _
platform i386-pc-linux-gnu
arch     i386
os       linux-gnu
system   i386, linux-gnu
status
major    2
minor    1.0
year     2005
month    04
day      18
language R



From ripley at stats.ox.ac.uk  Thu Oct  6 19:05:48 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 Oct 2005 18:05:48 +0100 (BST)
Subject: [R] isdst
In-Reply-To: <3f87cc6d0510060925r7629c97difaa7e00217f74b0d@mail.gmail.com>
References: <3f87cc6d0510060925r7629c97difaa7e00217f74b0d@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0510061759590.25193@gannet.stats>

On Thu, 6 Oct 2005, Omar Lakkis wrote:

> Can someone, please, explain the difference is results below (notice
> the isdst value)

Timezones.  (That is carefully documented on the help page for 
as.POSIXlt.)

>> unlist(as.POSIXlt('2005-7-1'))
>  sec   min  hour  mday   mon  year  wday  yday isdst
>    0     0     0     1     6   105     5   181     1

This is midnight on 2005-07-01 in your timezone, which presumably does 
have DST and it was in force then.

>> unlist(as.POSIXlt(as.Date('2005-7-1')))
>  sec   min  hour  mday   mon  year  wday  yday isdst
>    0     0     0     1     6   105     5   181     0

This is midnight on 2005-07-01 in UTC (which does not have DST).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Oct  6 19:10:50 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 Oct 2005 18:10:50 +0100 (BST)
Subject: [R] blank graphics window while R is working
In-Reply-To: <Pine.GSO.4.62.0510061101150.7974@harper.uchicago.edu>
References: <Pine.GSO.4.62.0510061101150.7974@harper.uchicago.edu>
Message-ID: <Pine.LNX.4.61.0510061806520.25193@gannet.stats>

Your R is an obselete version.  There are some changes in 2.2.0 which 
affect the hinting given to X11 WMs, so please try the current version of 
R. (I know it had only recently been released, but the posting guide 
refers you to the development versions.)

I don't know if this will solve it (I have never met the problem) but do 
know that we will not patch obselete versions.


On Thu, 6 Oct 2005, Dan Davison wrote:

> Dear R-help,
>
> When R starts to execute some code, all the graphics windows
> associated with that R session go blank, and remain blank until the R
> prompt returns.
>
> I am using the "ion" window manager
> (http://modeemi.cs.tut.fi/~tuomov/ion/) under Debian linux.
>
> I notice that under the gnome desktop environment with Fedora Core 4
> linux, the graphics windows retain their images while R evaluates. Does
> anyone else experience this problem or know of any solution, or is this
> just an incompatibility between R and my (presumably somewhat uncommon)
> window manager?
>
>
> Thanks a lot,
>
> Dan
>
> p.s. the problem remains whether R is run via ESS or not.
>
>> version
>          _
> platform i386-pc-linux-gnu
> arch     i386
> os       linux-gnu
> system   i386, linux-gnu
> status
> major    2
> minor    1.0
> year     2005
> month    04
> day      18
> language R

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From HStevens at MUOhio.edu  Thu Oct  6 19:12:33 2005
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Thu, 6 Oct 2005 13:12:33 -0400
Subject: [R] R Cocoa GUI syntax color bug?
Message-ID: <82B10A66-5E57-490B-A148-826F2DE0EA5C@MUOhio.edu>

I am running R 2.1.1 and R Cocoa GUI 1.12(1622) on a Mac Dual G5 with  
OS 10.4.2

Anytime I try to use the syntax color preference for the built-in  
editor, R crashes within a few minutes of working on a file. What  
information can I provide that might facilitate investigation of this?

Thank you,
Hank Stevens

Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"



From br44114 at gmail.com  Thu Oct  6 19:46:27 2005
From: br44114 at gmail.com (bogdan romocea)
Date: Thu, 6 Oct 2005 13:46:27 -0400
Subject: [R] boxplot statistics
Message-ID: <8d5a36350510061046w6fad11f7i2060b093795786fe@mail.gmail.com>

A related comment - don't rely (too much) on boxplots. They show only
a few things, which may be limiting in many cases and completely
misleading in others. Here are a couple of suggestions for plots which
you may find more useful than the standard box plots:
	- figure 3.27 from http://www.stat.auckland.ac.nz/~paul/RGraphics/chapter3.html
	- violin plots (see package vioplot) - density plots - histograms
	- box-percentile plots (bpplot from Hmisc)
	- quantile plots
	- if comparing 2 distributions, qq plots, quantile-difference plots,
mean-difference plots etc.


> -----Original Message-----
> From: Karin Lagesen [mailto:karin.lagesen at medisin.uio.no]
> Sent: Tuesday, October 04, 2005 5:24 AM
> To: r-help at r-project.org
> Subject: [R] boxplot statistics
>
>
>
> I have read and reread the boxplot and the boxplot stats page, and I
> still cannot understand how and what boxplot shows. I realize that
> this might be due to me not knowing enough statistics, but anyway...
>
> First, how does boxplot determine the size of the box? And is the line
> inside the box the mean or the median (or something completely
> different?) And how does it determine how long out the whiskers should
> go?
>
> Also, the boxplot.stats page talks about "hinges", what are those?
> "The two "hinges" are versions of the first and third quartile, i.e.,
> close to 'quantile(x, c(1,3)/4)'."
>
> Thankyou very much.
>
> Karin
> --
> Karin Lagesen, PhD student
> karin.lagesen at medisin.uio.no
> http://www.cmbn.no/rognes/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From jhorn at bu.edu  Thu Oct  6 20:31:22 2005
From: jhorn at bu.edu (Jason Horn)
Date: Thu, 6 Oct 2005 14:31:22 -0400
Subject: [R] circular statistics plotting
Message-ID: <FC773528-8C26-4093-A846-9CBFA5C29104@bu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051006/f18fc595/attachment.pl

From dray at biomserv.univ-lyon1.fr  Thu Oct  6 20:33:25 2005
From: dray at biomserv.univ-lyon1.fr (Stephane Dray)
Date: Thu, 06 Oct 2005 20:33:25 +0200
Subject: [R] Compare two distance matrices
In-Reply-To: <17221.19577.463128.122194@stat.math.ethz.ch>
References: <e3f8e9a00510060323x1824657et76b4d6c94c2177c0@mail.gmail.com>
	<1128602367.43451affc2602@webmail.univ-lyon1.fr>
	<17221.19577.463128.122194@stat.math.ethz.ch>
Message-ID: <1128623605.43456df5d9238@webmail.univ-lyon1.fr>

You are right,

in the help page of mat2dist, dist2mat we found:

mat2dist and dist2mat are local copies of as.dist and as.matrix.dist of mva.

now these functions are in stats. We have to check it.

Thanks.


Quoting Martin Maechler <maechler at stat.math.ethz.ch>:

> >>>>> "bady" == bady  <bady at univ-lyon1.fr>
> >>>>>     on Thu, 06 Oct 2005 14:39:27 +0200 writes:
>
>     bady> Hi, hi all,
>     >> I am trying to compare two distance matrices with R. I would like to
>     >> create a XY plot of these matrices and do some linear regression on
>     >> it. But, I am a bit new to R, so i have a few questions (I searched in
>     >> the documentation with no success).
>     >> The first problem is loading a distance matrix into R. This matrix is
>     >> the output of a the Phylip program Protdist and lookes like this:
>     >> I tried with the scan() function to load the files, but with no
>     >> success. How should i load in these files? ....
>     >>
>
>     bady> you can separately load each matrix with two text files.
>
>     bady> require(ade4)
>     bady> mat1 <- read.table("mat1.txt")
>     bady> nam1 <- mat1[,1]
>     bady> mat1 <- mat1[,-1]
>     bady> row.names(mat1) <- names(mat1) <- nam1
>     bady> mat2 <- read.table("mat2.txt")
>     bady> nam2 <- mat2[,1]
>     bady> mat2 <- mat2[,-1]
>     bady> row.names(mat2) <- names(mat2) <- nam2
>
>     bady> dist1 <- mat2dist(mat1)
>     bady> dist2 <- mat2dist(mat2)
>
> but I don't see why you would need an extra package "ade4" and
> its "extra - function"  mat2dist().
>
>
> when the 'stats' package already provides the function
> as.dist(.)  {the help page of which was mentioned by the
> original poster}.
>
>
> Here is a reproducible example showing how I think as.dist()
> works sufficiently:
>
> > (m <- toeplitz(round(rnorm(6),2)))
>       [,1]  [,2]  [,3]  [,4]  [,5]  [,6]
> [1,] -0.42 -0.78 -0.42 -2.24  0.74  1.31
> [2,] -0.78 -0.42 -0.78 -0.42 -2.24  0.74
> [3,] -0.42 -0.78 -0.42 -0.78 -0.42 -2.24
> [4,] -2.24 -0.42 -0.78 -0.42 -0.78 -0.42
> [5,]  0.74 -2.24 -0.42 -0.78 -0.42 -0.78
> [6,]  1.31  0.74 -2.24 -0.42 -0.78 -0.42
> > as.dist(m)
>       1     2     3     4     5
> 2 -0.78
> 3 -0.42 -0.78
> 4 -2.24 -0.42 -0.78
> 5  0.74 -2.24 -0.42 -0.78
> 6  1.31  0.74 -2.24 -0.42 -0.78
> > ## it also works for data frames {if really needed}:
> > dm <- as.data.frame(m)
> > as.dist(dm)
>       1     2     3     4     5
> 2 -0.78
> 3 -0.42 -0.78
> 4 -2.24 -0.42 -0.78
> 5  0.74 -2.24 -0.42 -0.78
> 6  1.31  0.74 -2.24 -0.42 -0.78
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>


-- 
Stephane DRAY



From fcombes at gmail.com  Thu Oct  6 20:50:27 2005
From: fcombes at gmail.com (Florence Combes)
Date: Thu, 6 Oct 2005 20:50:27 +0200
Subject: [R] [BioC] (no subject)
In-Reply-To: <e441d0b4a1da032bf52e3fb6010c378b@gci.ac.uk>
References: <e441d0b4a1da032bf52e3fb6010c378b@gci.ac.uk>
Message-ID: <73dae3060510061150p5c6de8f6lde2174933f17a0a4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051006/3d9da50b/attachment.pl

From rxg218 at psu.edu  Thu Oct  6 20:57:35 2005
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Thu, 06 Oct 2005 14:57:35 -0400
Subject: [R] a question about LMS and what constitutes outliers
Message-ID: <1128625055.10920.23.camel@blue.chem.psu.edu>

Hi,
  I have been using the lqs function with method='lms'. However the
results I get are a little different from the results noted by Rousseeuw
& Leroy (Robust Regression and Outlier Detection) and I was wondering
how to use these results for outlier detection.

I'm using the stackloss dataset, for which the original Rousseeuw et al.
program points out that observations 1,2,3,4 and 21 are outliers.

This conslusion is arrived at by testing whether the residual is greater
than 2.5 * standard error

Netx I ran lqs as:

m <- lqs(stackloss[,-4], stackloss[,4], method='lms', control=list
(psamp=4, nsamp='exact', adjust=TRUE))

(I ran it exhaustively since that was how I ran the original program
from Rousseeuw)

The coefficients obtained from lqs() are more or less identical to that
obtained by the original program. However the scale estimates do not
match. I assume that this would be becuase of the per sample
adjustments.

Now if I want to decide whether an observation is an outlier I use the
condition

which( abs(m$resid) > 2.5 * m$scale[1] )

and this gives me

 1  2  3  4  8 13 14 20 21
 1  2  3  4  8 13 14 20 21

Now, it includes the original outliers as noted by Rousseuw, but also 4
extra ones. From a plot of the residuals I can see obs 13,14,20 possibly
being regarded as outliers but 8 seems a stretch.

I tried evaluating the above condition with m$scale[2] but I get the
same result. I also tried running lqs() with adjust=FALSE in which case
using the above condition obs 1,2,3,4,13,20,21 are regarded as outliers.

So my questions are

1) Am I correct in using the above condition to determine whether an
observation is an outlier?

2) If so, is it correct that lqs() will detect more outliers than noted
by the original book/program?

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
After an instrument has been assembled, extra components will be found
on the bench.



From stwitt at wisc.edu  Thu Oct  6 21:38:51 2005
From: stwitt at wisc.edu (Suzanne Witt)
Date: Thu, 06 Oct 2005 14:38:51 -0500
Subject: [R] data.frame error using sem package
Message-ID: <39C2778B-EC95-40FB-B593-369CAAD0BBDA@wisc.edu>

I keep getting this error when I try to use the sem package.  I and  
another person who has successfully used the sem package for similar  
analysis (fMRI effective connectivity) cannot figure out what is  
wrong with my code.  I would appreciate any suggestions.

The error message:

Error in data.frame(object$coeff, se, z, 2 * (1 - pnorm(abs(z))),  
par.code) :
     arguments imply differing number of rows: 6, 0
In addition: Warning message:
Could not compute QR decomposition of Hessian.
Optimization probably did not converge.
in: sem.default(ram = ram, S = S, N = N, param.names = pars,  
var.names = vars,


Thank you,

Suzanne



From ligges at statistik.uni-dortmund.de  Thu Oct  6 21:49:05 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 06 Oct 2005 21:49:05 +0200
Subject: [R] data.frame error using sem package
In-Reply-To: <39C2778B-EC95-40FB-B593-369CAAD0BBDA@wisc.edu>
References: <39C2778B-EC95-40FB-B593-369CAAD0BBDA@wisc.edu>
Message-ID: <43457FB1.8050400@statistik.uni-dortmund.de>

Suzanne Witt wrote:
> I keep getting this error when I try to use the sem package.  I and  
> another person who has successfully used the sem package for similar  
> analysis (fMRI effective connectivity) cannot figure out what is  
> wrong with my code.  I would appreciate any suggestions.


It is almost impossible to help if you do not specify a toy example that 
shows how you produced that error message.
Please read the psoting guide which tells you how to specify such 
examples most appropriately in order to get a good answer.

Uwe Ligges



> The error message:
> 
> Error in data.frame(object$coeff, se, z, 2 * (1 - pnorm(abs(z))),  
> par.code) :
>      arguments imply differing number of rows: 6, 0
> In addition: Warning message:
> Could not compute QR decomposition of Hessian.
> Optimization probably did not converge.
> in: sem.default(ram = ram, S = S, N = N, param.names = pars,  
> var.names = vars,
> 
> 
> Thank you,
> 
> Suzanne
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Thu Oct  6 21:54:30 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 06 Oct 2005 21:54:30 +0200
Subject: [R] circular statistics plotting
In-Reply-To: <FC773528-8C26-4093-A846-9CBFA5C29104@bu.edu>
References: <FC773528-8C26-4093-A846-9CBFA5C29104@bu.edu>
Message-ID: <434580F6.5040406@statistik.uni-dortmund.de>

Jason Horn wrote:

> Hi all,
> 
> I'm new to the list here, and I have what I think is a simple  
> question.  Using the "circular" package, is there a way to plot the  
> mean and variance on top of a rose diagram or other plot of the data?


The package seems to be very well designed:
I did not know anything about this package at the time reading your 
question. Reading the help page and trying out the first example, it 
took me less than a minute to figure it out (hence I wonder why you 
haven't?). From the example:

   library(circular)
   x <- circular(runif(50, 0, 2*pi))
   rose.diag(x, bins = 18, main = 'Uniform Data')
   ## plot the mean:
   points(mean(x), col = "red")

Uwe Ligges




> Thanks in advance...
> 
> - Jason
> 
> 
> Jason Horn
> Boston University Department of Biology
> 5 Cumington Street  Boston, MA 02215
> 
> jhorn at bu.edu
> office: 617 353 6987
> cell: 401 588 2766
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From stwitt at wisc.edu  Thu Oct  6 21:54:42 2005
From: stwitt at wisc.edu (Suzanne Witt)
Date: Thu, 06 Oct 2005 14:54:42 -0500
Subject: [R] data.frame error using sem package
Message-ID: <2A5095FE-AC17-4DA1-A61E-6887DB90459F@wisc.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051006/26ed15c9/attachment.pl

From jfox at mcmaster.ca  Thu Oct  6 22:47:45 2005
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 6 Oct 2005 16:47:45 -0400
Subject: [R] data.frame error using sem package
In-Reply-To: <2A5095FE-AC17-4DA1-A61E-6887DB90459F@wisc.edu>
Message-ID: <20051006204746.DBOO21470.tomts22-srv.bellnexxia.net@JohnDesktop8300>

Dear Suzanne,

Take a look at your model specification:

> p.ram
     [,1]            [,2]            [,3]
[1,] "LM1 -> LSMA"   "LM1 -> LSMA"   NA  
[2,] "LSMA -> RSMA"  "LSMA -> RSMA"  NA  
[3,] "RSMA -> RM1"   "RSMA -> RM1"   NA  
[4,] "LSMA <-> LSMA" "LSMA <-> LSMA" NA  
[5,] "RSMA <-> RSMA" "RSMA <-> RSMA" NA  
[6,] "RM1 <-> RM1"   "RM1 <-> RM1"   NA  
> 

This matrix should have three columns, the first giving the path, the second
the name of the corresponding parameter, and the third the start value for
the parameter (or NA if you want sem() to compute a start value). You've
apparently left out the parameter names. Please see the sem examples for
details and the paper at
<http://socserv.socsci.mcmaster.ca/jfox/sem-package.pdf>.

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Suzanne Witt
> Sent: Thursday, October 06, 2005 2:55 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] data.frame error using sem package
> 
> I am trying to use sem to measure effective connectivity 
> among four brain regions.  I have pasted the code that I am 
> trying to run since that seems easier than trying to come up 
> with another example.
> 
> The input data is time series data taken from SPM; they are each
> 1x121 columns of numbers.  I get the error either when I 
> source the whole code, or if I enter it line by line when I 
> go to get the summary.
> 
> Thanks,
> 
> Suzanne
> 
> library(sem)
> 
> # Load the region timecourses.
> 
> lsma1 <- read.table("/Users/witt/parkinsons/rmrkm010905/R_files/
> 010905_lcomf_LSMA.dat")
> rsma1 <- read.table("/Users/witt/parkinsons/rmrkm010905/R_files/
> 010905_lcomf_RSMA.dat")
> lmc1 <- read.table("/Users/witt/parkinsons/rmrkm010905/R_files/
> 010905_lcomf_LM1.dat")
> rmc1 <- read.table("/Users/witt/parkinsons/rmrkm010905/R_files/
> 010905_lcomf_RM1.dat")
> 
> # Combine all the timecourses from each session into a single 
> data frame and name the columns appropriately.
> 
> lcomf <- cbind(lsma1, rsma1, lmc1, rmc1)
> names(lcomf) <- c("LSMA", "RSMA", "LM1", "RM1")
> 
> # Type this at the command line to see a summary of your data
> 
> str(lcomf)
> 
> # Set up the structural equation model.
> 
> p.ram <<- matrix(c( 'LM1 -> LSMA', 'LM1 -> LSMA', NA,
>              'LSMA -> RSMA', 'LSMA -> RSMA', NA,
>              'RSMA -> RM1', 'RSMA -> RM1', NA,
>              'LSMA <-> LSMA', 'LSMA <-> LSMA', NA,
>              'RSMA <-> RSMA', 'RSMA <-> RSMA', NA,
>              'RM1 <-> RM1', 'RM1 <-> RM1', NA),
>                  ncol = 3, byrow = TRUE)
> 
> # Tell which variables are exogenous ('fixed').
> 
> p.fixed <- c('LM1')
> 
> # Do the fitting for session 1.
> 
> C <- cor(lcomf)
> nt <- dim(lcomf)[1]
> #attach(lcomf)
> lcomf.results <- sem(p.ram, C, nt, obs.variables = 
> rownames(C), fixed.x = p.fixed)
> 
> # Check out the results using the summary function
> 
> summary(lcomf.results)
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From karine.poitrineau at univ-tours.fr  Thu Oct  6 23:10:23 2005
From: karine.poitrineau at univ-tours.fr (Karine Poitrineau)
Date: Thu, 06 Oct 2005 23:10:23 +0200
Subject: [R] Replicated goodness-of-fit test
Message-ID: <6.1.1.1.0.20051006215200.027e8298@rabelais.univ-tours.fr>


Dear all,

I am facing a problem that seems to me more tricky now that it did at first 
sight.
I have a collection of data which consist in frequency distributions: 6 
patches had been proposed to female insects (for oviposition), 3 of them 
corresponding to one treatment (A), the other 3 to another treatment (B). 
The results are the number of patches that have been chosen for oviposition 
by each female (0 to 3 patches can be used for oviposition, for each 
treatment). Thus, the experiment is replicated (each female's choice is a 
replication).
I am interested in testing if females do prefer one treatment to the other 
(if they oviposit preferently on one sort of patch), i.e. testing the 
goodness of fit of my data to an equal ratio of oviposition on patches A and B.

I intended to use the replicated goodness-of-fit test (G-statistic) 
described in Sokal & Rohlf (1981): this test seemed accurate for such data...
But a first problem is that some frequencies in my data set are = 0... I 
wonder if an x->( x + 1) transformation could be reasonnably performed to 
permit the taking of ln(X) in calculations.
Moreover, low frequencies (less than 5) are usually reported as a problem 
for G-tests, and because my females had only the choice to oviposit on 6 
patches (3 for treatment A, 3 for treatment B), I have indeed low frequencies!

Do you know another way to perform such an analysis, more accurate in my 
case (or do you thing a G-test could nevertheless be used)?
I hope my explanations were comprehensible, and if it isn't the case, don't 
hesitate to ask for more.

Thanks for your reply
Kind regards,

Karine



From francoisromain at free.fr  Thu Oct  6 23:23:12 2005
From: francoisromain at free.fr (francoisromain@free.fr)
Date: Thu, 06 Oct 2005 23:23:12 +0200
Subject: [R] boxplot statistics
In-Reply-To: <8d5a36350510061046w6fad11f7i2060b093795786fe@mail.gmail.com>
References: <8d5a36350510061046w6fad11f7i2060b093795786fe@mail.gmail.com>
Message-ID: <1128633792.434595c0b7fc8@imp1-g19.free.fr>

Selon bogdan romocea <br44114 at gmail.com>:

> A related comment - don't rely (too much) on boxplots. They show only
> a few things, which may be limiting in many cases and completely
> misleading in others. Here are a couple of suggestions for plots which
> you may find more useful than the standard box plots:
> 	- figure 3.27 from
> http://www.stat.auckland.ac.nz/~paul/RGraphics/chapter3.html
> 	- violin plots (see package vioplot) - density plots - histograms
> 	- box-percentile plots (bpplot from Hmisc)
> 	- quantile plots
> 	- if comparing 2 distributions, qq plots, quantile-difference plots,
> mean-difference plots etc.

Hi,

HDR (highest density regions) boxplots are interresting.
See http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=102


Romain

> > -----Original Message-----
> > From: Karin Lagesen [mailto:karin.lagesen at medisin.uio.no]
> > Sent: Tuesday, October 04, 2005 5:24 AM
> > To: r-help at r-project.org
> > Subject: [R] boxplot statistics
> >
> >
> >
> > I have read and reread the boxplot and the boxplot stats page, and I
> > still cannot understand how and what boxplot shows. I realize that
> > this might be due to me not knowing enough statistics, but anyway...
> >
> > First, how does boxplot determine the size of the box? And is the line
> > inside the box the mean or the median (or something completely
> > different?) And how does it determine how long out the whiskers should
> > go?
> >
> > Also, the boxplot.stats page talks about "hinges", what are those?
> > "The two "hinges" are versions of the first and third quartile, i.e.,
> > close to 'quantile(x, c(1,3)/4)'."
> >
> > Thankyou very much.
> >
> > Karin
> > --
> > Karin Lagesen, PhD student
> > karin.lagesen at medisin.uio.no
> > http://www.cmbn.no/rognes/



From chrisb at fcdarwin.org.ec  Thu Oct  6 16:19:27 2005
From: chrisb at fcdarwin.org.ec (Chris Buddenhagen)
Date: Thu, 6 Oct 2005 08:19:27 -0600
Subject: [R] error bars on xy plots and barplots and histograms
Message-ID: <000001c5ca80$f5a011a0$4c01a8c0@Chris>

Dear all

I have yet to find code for making and showing error bars. Is there some
idea that the simple presentation of confidence intervals is not " good
statistics"?

Any leads appreciated.

Chris Buddenhagen, Botany Department, Charles Darwin Research Station, Santa
Cruz,Galapagos. Mail: Charles Darwin Foundation, Casilla 17-01-3891 Avenida
6 de Diciembre N36-109 y Pasaje California Quito, ECUADOR
 






______________________________________________________________________
EL CONTENIDO DE ESTE MENSAJE ES DE ABSOLUTA RESPONSABILIDAD DEL AUTOR.
FUNDACION CHARLES DARWIN
WWW.DARWINFOUNDATION.ORG



From A.Robinson at ms.unimelb.edu.au  Fri Oct  7 02:33:40 2005
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 7 Oct 2005 10:33:40 +1000
Subject: [R] error bars on xy plots and barplots and histograms
In-Reply-To: <000001c5ca80$f5a011a0$4c01a8c0@Chris>
References: <000001c5ca80$f5a011a0$4c01a8c0@Chris>
Message-ID: <20051007003340.GE83097@ms.unimelb.edu.au>

Chris,

computation of confidence intervals is left to the user.  Showing them
can be achieved using the arrows() function.

I hope that this helps,

Andrew

On Thu, Oct 06, 2005 at 08:19:27AM -0600, Chris Buddenhagen wrote:
> Dear all
> 
> I have yet to find code for making and showing error bars. Is there some
> idea that the simple presentation of confidence intervals is not " good
> statistics"?
> 
> Any leads appreciated.
> 
> Chris Buddenhagen, Botany Department, Charles Darwin Research Station, Santa
> Cruz,Galapagos. Mail: Charles Darwin Foundation, Casilla 17-01-3891 Avenida
> 6 de Diciembre N36-109 y Pasaje California Quito, ECUADOR
>  
> 
> 
> 
> 
> 
> 
> ______________________________________________________________________
> EL CONTENIDO DE ESTE MENSAJE ES DE ABSOLUTA RESPONSABILIDAD DEL AUTOR.
> FUNDACION CHARLES DARWIN
> WWW.DARWINFOUNDATION.ORG
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Andrew Robinson
Senior Lecturer in Statistics                       Tel: +61-3-8344-9763
Department of Mathematics and Statistics            Fax: +61-3-8344-4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au



From spencer.graves at pdf.com  Fri Oct  7 02:37:45 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 06 Oct 2005 17:37:45 -0700
Subject: [R] Different sings for correlations in OLS and TSA
In-Reply-To: <4312D204.9050000@web.de>
References: <4312D204.9050000@web.de>
Message-ID: <4345C359.4080704@pdf.com>

	  I haven't seen a reply to this, so I will offer a comment:

	  It looks to me like the correlation you question is the correlation 
between the estimated intercept and slope of the gls regression line. 
This is different from the correlation between ts.mar and ts.anr.  To 
understand this, consider the following addition to your script:

plot(ts.mar, ts.anr)
# The intercept and slope are negative
# because the mean of ts.mar is positive.

fit3a <- gls(ts.anr ~ I(ts.mar-1000),correlation = 
corARMA(value=c(mod3$coef[1],mod3$coef[2]),p=2))
summary(fit3a)

<snip>
  Correlation:
                  (Intr)
I(ts.mar - 1000) 0.988

# The estimated slope is the same
# in fit3 and fit3a
# but the sign of the correlation between
# intercept and slope has changed.

	  I hope this response still interests you, even though it comes well 
over a month after your post.  You are to commended for providing a 
good, reasonably complete example.  If it had been shorter, it might 
have received more comments sooner.

	  If this does not answer your question or you have another, please let 
us know.

	  spencer graves

Michael Tiemann wrote:

> Dear list,
> 
> I am trying to re-analyse something. I do have two time series, one
> of which (ts.mar) might help explaining the other (ts.anr). In the
> original analysis, no-one seems to have cared about the data being 
> time-series and they just did OLS. This yielded a strong positive
> correlation.
> I want to know if this correlation is still as strong when the 
> autocorrelations are taken into account. There are autocorrelations, so
> I model the data with arima() to get the parameters and fit it with
> gls(). So far, the code seems to work fine, but what puzzles me is that 
> I get different sings: the gls-fit yields a strong negative correlation.
> This shouldn't be so, so I suspect I am doing something wrong.
> 
> Here is my code:
> 
> # this is my data
> ts.mar<-ts(c(431.3,438,389.7,353.3,354.6,371.8,397.7,438.5,467.9,505.7,574.7,644.7,667.8,616.4,509.6,447,413.1,384.1),start=1980,freq=1) 
> 
> ts.anr<-ts(c(104.1,102.4,97.9,96.2,95.1,95.1,97.9,101.6,105.9,111.1,117.9,121.3,121.8,114.2,107.6,105.1,101.9,98.6),start=1980,freq=1) 
> 
> # to find autocorrelations via (p)acf's and mle I do:
> fun.tsa.mle<-function(x){
> par(mfrow=c(3,1))
> acf(x)
> pacf(x)
> # AR model is estimated
> m1<- ar.mle(x)
> # An estimation of the unexplained portion of variance
> m1.1<-m1$var.pred
> # plot the function
> plot(x)
> # Give a printout
> print(m1)
> print("unexplained portion of variance:")
> print(m1.1)
> print("Mean:")
> print(m1$x.mean)
> par(mfrow=c(1,1))
> }
> #now, the autocorrelations should be consistent with following processes:
> fun.tsa.mle(ts.mar)      #following DAAG a p=2 AR
> fun.tsa.mle(ts.anr)      #following DAAG a p=2 AR
> #I need to know, wether ts.anr can be explained with ts.mar, so
> #according to ar.mle:
> mod3<-arima(ts.anr,order=c(2,0,0),xreg=ts.mar,transform.pars=TRUE)
> fit3 <- gls(ts.anr ~ ts.mar,correlation = 
> corARMA(value=c(mod3$coef[1],mod3$coef[2]),p=2))
> summary(fit3)
> ts.plot(ts.anr,fit3$fitted,col=1:2)
> #the puzzling bit is the negative correlation. It ought to be positive, 
> I think.
> #a simple OLS (this is what the people before me have done) yields
> test3<-ols(ts.anr~ts.mar)
> test3 #with a positive correlation. Why?
> 
> 
> Where is the mistake? Up to now, I just thought time-series analyses 
> would correct parameters and estimations, but simply changing signs?
> 
> Appreciating your help and suggestions,
> 
> Michael.
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From spencer.graves at pdf.com  Fri Oct  7 03:02:32 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 06 Oct 2005 18:02:32 -0700
Subject: [R] Inverse autocorrelation function?
In-Reply-To: <20051001014056.22981.qmail@web33103.mail.mud.yahoo.com>
References: <20051001014056.22981.qmail@web33103.mail.mud.yahoo.com>
Message-ID: <4345C928.2010007@pdf.com>

Dear Dr. Hartley:

	  RSiteSearch("Inverse autocorrelation function") produced 11 hits, 
none of which seemed to relate to your question.  If you have a 
reasonable algorithm for computing the IACF, it might not be difficult 
to program in R.  If you have compiled code, e.g., C++ or Fortran, it 
might not be difficult to link to it.

	  Googling for "inverse autocorrelation function led me to an article 
"On Autoregressive Model Identification" Ette Harrison Etuk 
(www.jos.nu/Articles/abstract.asp?article=42113) which compares IACF and 
PACF, concluding (a) neither is consistently more powerful than the 
other, but "On the whole the partial autocorrelation function exhibits 
better performance."

	  Conclusions:

	  (1) R does not seem to have an IACF function, unless the IACF is 
identical to something else that R has under a different name.

	  (2) "The R Project for Stastical Computing" is NOT a completed 
product but a project perpetually under renewal and extension.  As such, 
it has many contributed packages and is happy to accept more.

	  Spencer Graves

David Hartley wrote:

> In time series analysis it is helpful to plot the
> autocorrelation function (ACF), partial
> autocorrelation function (PACF), and the inverse
> autocorrelation function (IACF). The stats library
> provides the ability to compute and plot the ACF and
> PACF, but I cannot find an [R] procedure to compute
> and plot the IACF. Is there one? 
> 
> Best regards, 
> 
> David Hartley, PhD
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From maj at stats.waikato.ac.nz  Fri Oct  7 04:11:23 2005
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Fri, 07 Oct 2005 15:11:23 +1300
Subject: [R] Error in integrate
Message-ID: <4345D94B.70405@stats.waikato.ac.nz>

I'm using R 2.0.1 under Windows XP. I get the following message when I 
run the code listed below. I don't seem to have any problems using the 
function "slice" outside "integrate".

Error in integrate(slice, 0, Inf, , , , , , , a, b) * delta :
         non-numeric argument to binary operator

[ By the way, I'm trying to evaluate a two-dimensional integral by 
slicing it up into one-dimensional bits which I will loop over to evaluate.]

Here's the code:

mu <- 0.3
sig2 <- 0.01
alpha <- 20
beta <- 15.75
rho <- 0.1
k <- 1/(rho^2.5*gamma(rho)^2*sqrt(2*pi*sig2))

slice <- function(w,a,b)
{
  g <- w^(1/rho)
  g1 <- w1^(1/rho)
  h <- g1^a*g^b
  E <- -(y-rho*mu -g1/alpha + g/beta)^2/(2*sig2*rho)
  k*h*exp(E- g1 - g)
}

hi <- 10
delta <- 0.05
grid <- seq(delta/2,hi,delta)
y <- -0.3
a <- 0
b <- 0
m <- length(grid)
A <- rep(0,m)
j <- 0

for (w1 in grid)
{
  j <- j+1
  A[j] <- integrate(slice,0,Inf,,,,,,,a,b)*delta
  cat(A[j],"\n")
}


-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441    Mobile 021 1395 862



From ray at mcs.vuw.ac.nz  Fri Oct  7 04:37:17 2005
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Fri, 7 Oct 2005 15:37:17 +1300 (NZDT)
Subject: [R] Error in integrate
Message-ID: <200510070237.j972bH2Y008093@tahi.mcs.vuw.ac.nz>

Murray Jorgensen <maj at stats.waikato.ac.nz> wrote:

> I'm using R 2.0.1 under Windows XP. I get the following message when I 
> run the code listed below. I don't seem to have any problems using the 
> function "slice" outside "integrate".
> 
> Error in integrate(slice, 0, Inf, , , , , , , a, b) * delta :
>          non-numeric argument to binary operator
> 
RTFM!  Integrate returns:
Value:

     A list of class '"integrate"' with components
     :
     :

You need:
A[j] <- integrate(slice,0,Inf,,,,,,,a,b)$value*delta

Ray



From f.harrell at vanderbilt.edu  Fri Oct  7 04:45:02 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Thu, 06 Oct 2005 22:45:02 -0400
Subject: [R] error bars on xy plots and barplots and histograms
In-Reply-To: <20051007003340.GE83097@ms.unimelb.edu.au>
References: <000001c5ca80$f5a011a0$4c01a8c0@Chris>
	<20051007003340.GE83097@ms.unimelb.edu.au>
Message-ID: <4345E12E.5030500@vanderbilt.edu>

Andrew Robinson wrote:
> Chris,
> 
> computation of confidence intervals is left to the user.  Showing them
> can be achieved using the arrows() function.
> 
> I hope that this helps,
> 
> Andrew

Also do ?xYplot after installing the Hmisc package. -Frank

> 
> On Thu, Oct 06, 2005 at 08:19:27AM -0600, Chris Buddenhagen wrote:
> 
>>Dear all
>>
>>I have yet to find code for making and showing error bars. Is there some
>>idea that the simple presentation of confidence intervals is not " good
>>statistics"?
>>
>>Any leads appreciated.
>>
>>Chris Buddenhagen, Botany Department, Charles Darwin Research Station, Santa
>>Cruz,Galapagos. Mail: Charles Darwin Foundation, Casilla 17-01-3891 Avenida
>>6 de Diciembre N36-109 y Pasaje California Quito, ECUADOR
>> 
>>
>>
>>
>>
>>
>>
>>______________________________________________________________________
>>EL CONTENIDO DE ESTE MENSAJE ES DE ABSOLUTA RESPONSABILIDAD DEL AUTOR.
>>FUNDACION CHARLES DARWIN
>>WWW.DARWINFOUNDATION.ORG
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From maechler at stat.math.ethz.ch  Fri Oct  7 09:21:30 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 7 Oct 2005 09:21:30 +0200
Subject: [R] The R Graph Gallery {was  boxplot statistics}
In-Reply-To: <1128633792.434595c0b7fc8@imp1-g19.free.fr>
References: <8d5a36350510061046w6fad11f7i2060b093795786fe@mail.gmail.com>
	<1128633792.434595c0b7fc8@imp1-g19.free.fr>
Message-ID: <17222.8698.164809.696145@stat.math.ethz.ch>

>>>>> "Romain" == Romain Francois <francoisromain at free.fr>
>>>>>     on Thu, 06 Oct 2005 23:23:12 +0200 writes:

    Romain> Selon bogdan romocea <br44114 at gmail.com>:
    >> A related comment - don't rely (too much) on boxplots. They show only
    >> a few things, which may be limiting in many cases and completely
    >> misleading in others. Here are a couple of suggestions for plots which
    >> you may find more useful than the standard box plots:
    >> - figure 3.27 from
    >> http://www.stat.auckland.ac.nz/~paul/RGraphics/chapter3.html
    >> - violin plots (see package vioplot) - density plots - histograms
    >> - box-percentile plots (bpplot from Hmisc)
    >> - quantile plots
    >> - if comparing 2 distributions, qq plots, quantile-difference plots,
    >> mean-difference plots etc.

    Romain> Hi,

    Romain> HDR (highest density regions) boxplots are interresting.
    Romain> See http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=102
Let me take the opportunity to thank Romain
for setting up and maintaining the R Graph Gallery.

This is really a cool website for R users. 
He'd get my number one vote for "R website of the year"!

Martin Maechler, ETH Zurich



From mdehollander at gmail.com  Fri Oct  7 09:31:34 2005
From: mdehollander at gmail.com (Mattias de Hollander)
Date: Fri, 7 Oct 2005 09:31:34 +0200
Subject: [R] Compare two distance matrices
In-Reply-To: <17221.19577.463128.122194@stat.math.ethz.ch>
References: <e3f8e9a00510060323x1824657et76b4d6c94c2177c0@mail.gmail.com>
	<1128602367.43451affc2602@webmail.univ-lyon1.fr>
	<17221.19577.463128.122194@stat.math.ethz.ch>
Message-ID: <e3f8e9a00510070031t75280720m7fb4c7f89ac0e587@mail.gmail.com>

Hi all,

Thanks for the quick response. I see the ade4 package in not needed
for distance matrix computation, but as far i can see you need it for
comparing two distance matrices. In the stats package i can't find any
similiar functions like mantel.randtest or RVdist.randtest of the ade4
package. So i think this package is still needed if i would like to
make a scatter plot of the matrices. Or should i manualy compare these
matrices with a loop for example and make a plot of this?

On 10/6/05, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> >>>>> "bady" == bady  <bady at univ-lyon1.fr>
> >>>>>     on Thu, 06 Oct 2005 14:39:27 +0200 writes:
>
>     bady> Hi, hi all,
>     >> I am trying to compare two distance matrices with R. I would like to
>     >> create a XY plot of these matrices and do some linear regression on
>     >> it. But, I am a bit new to R, so i have a few questions (I searched in
>     >> the documentation with no success).
>     >> The first problem is loading a distance matrix into R. This matrix is
>     >> the output of a the Phylip program Protdist and lookes like this:
>     >> I tried with the scan() function to load the files, but with no
>     >> success. How should i load in these files? ....
>     >>
>
>     bady> you can separately load each matrix with two text files.
>
>     bady> require(ade4)
>     bady> mat1 <- read.table("mat1.txt")
>     bady> nam1 <- mat1[,1]
>     bady> mat1 <- mat1[,-1]
>     bady> row.names(mat1) <- names(mat1) <- nam1
>     bady> mat2 <- read.table("mat2.txt")
>     bady> nam2 <- mat2[,1]
>     bady> mat2 <- mat2[,-1]
>     bady> row.names(mat2) <- names(mat2) <- nam2
>
>     bady> dist1 <- mat2dist(mat1)
>     bady> dist2 <- mat2dist(mat2)
>
> but I don't see why you would need an extra package "ade4" and
> its "extra - function"  mat2dist().
>
>
> when the 'stats' package already provides the function
> as.dist(.)  {the help page of which was mentioned by the
> original poster}.
>
>
> Here is a reproducible example showing how I think as.dist()
> works sufficiently:
>
> > (m <- toeplitz(round(rnorm(6),2)))
>       [,1]  [,2]  [,3]  [,4]  [,5]  [,6]
> [1,] -0.42 -0.78 -0.42 -2.24  0.74  1.31
> [2,] -0.78 -0.42 -0.78 -0.42 -2.24  0.74
> [3,] -0.42 -0.78 -0.42 -0.78 -0.42 -2.24
> [4,] -2.24 -0.42 -0.78 -0.42 -0.78 -0.42
> [5,]  0.74 -2.24 -0.42 -0.78 -0.42 -0.78
> [6,]  1.31  0.74 -2.24 -0.42 -0.78 -0.42
> > as.dist(m)
>       1     2     3     4     5
> 2 -0.78
> 3 -0.42 -0.78
> 4 -2.24 -0.42 -0.78
> 5  0.74 -2.24 -0.42 -0.78
> 6  1.31  0.74 -2.24 -0.42 -0.78
> > ## it also works for data frames {if really needed}:
> > dm <- as.data.frame(m)
> > as.dist(dm)
>       1     2     3     4     5
> 2 -0.78
> 3 -0.42 -0.78
> 4 -2.24 -0.42 -0.78
> 5  0.74 -2.24 -0.42 -0.78
> 6  1.31  0.74 -2.24 -0.42 -0.78
> >
>
>



From petr.pikal at precheza.cz  Fri Oct  7 09:33:56 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 07 Oct 2005 09:33:56 +0200
Subject: [R] factor : how does it work ?
In-Reply-To: <73dae3060510060808g58c2ae9di3a9d5a3372329dc6@mail.gmail.com>
References: <43453B69.5090008@stats.uwo.ca>
Message-ID: <43464104.5386.65E91C@localhost>

Hi

it seems that the problem is why you got all your numerics 
converted to factors. If taken from some spreadsheet there could 
have been some unnoticed ***spaces*** in blank cells which 
turned the numeric column into factor column.

HTH
Petr


On 6 Oct 2005 at 17:08, Florence Combes wrote:

Date sent:      	Thu, 6 Oct 2005 17:08:17 +0200
From:           	Florence Combes <fcombes at gmail.com>
To:             	Duncan Murdoch <murdoch at stats.uwo.ca>, r-help at stat.math.ethz.ch
Subject:        	Re: [R] factor : how does it work ?
Send reply to:  	Florence Combes <fcombes at gmail.com>
	<mailto:r-help-request at stat.math.ethz.ch?subject=unsubscribe>
	<mailto:r-help-request at stat.math.ethz.ch?subject=subscribe>

> > head(merged)
> ID Name Pcc_0h_A Pcc_0h_swapped_A
> 3302 301495 Q0010_01 |Q0010||Hypothetical ORF 12.276 11.716
> 6943 309175 Q0010_01 |Q0010||Hypothetical ORF 11.958 11.271
> 14065 298935 Q0017_01 |Q0017||Hypothetical ORF 14.098 13.122
> 6420 306615 Q0017_01 |Q0017||Hypothetical ORF 13.843 13.061
> 5066 296375 Q0032_01 |Q0032||Hypothetical ORF 12.451 11.467
> 12707 304055 Q0032_01 |Q0032||Hypothetical ORF 11.745 11.482
> Pcc_0h_M Pcc_0h_swapped_M
> 3302 -0.249 0.316
> 6943 -0.115 0.780
> 14065 -0.053 0.263
> 6420 0.009 0.323
> 5066 0.015 0.687
> 12707 0.074 0.768
> 
> > str(merged)
> `data.frame': 12202 obs. of 6 variables:
> $ ID : Factor w/ 12202 levels "295080","295081",..: 5076 11177 3046
> 9147 1009 7110 5136 11237 3106 9207 ... ..- attr(*, "names")= chr
> "3302" "6943" "14065" "6420" ... $ Name : Factor w/ 6101 levels
> "Q0010_01 ..",..: 1 1 2 2 3 3 4 4 5 5 ... ..- attr(*, "names")= chr
> "3302" "6943" "14065" "6420" ... $ Pcc_0h_A : Factor w/ 5386 levels
> "10.001","10.002",..: 1812 1547 3308 3114 1960 1370 NA NA NA NA ...
> ..- attr(*, "names")= chr "3302" "6943" "14065" "6420" ... $
> Pcc_0h_swapped_A: Factor w/ 5082 levels "10.001","10.002",..: 1256 885
> 2533 2477 1051 1064 NA NA NA NA ... ..- attr(*, "names")= chr "3302"
> "6943" "14065" "6420" ... $ Pcc_0h_M : Factor w/ 1940 levels "
> 0.000"," 0.001",..: 499 231 107 18 30 148 NA NA NA NA ... ..- attr(*,
> "names")= chr "3302" "6943" "14065" "6420" ... $ Pcc_0h_swapped_M:
> Factor w/ 2343 levels " 0.000"," 0.001",..: 632 1453 526 646 1319 1434
> NA NA NA NA ... ..- attr(*, "names")= chr "3302" "6943" "14065" "6420"
> ...
> 
> 
> 
> > > a last question, and thanks a million for your patience and your
> > > explanations ...
> > >
> > >
> > > I tried with a df called "merged" and a column named "Pcc_0h_A"
> > > (which
> > is
> > > numeric values):
> > >
> > >> length(as.vector(merged$Pcc_0h_A))
> > > [1] 12202
> > >>as.numeric(as.vector(merged$Pcc_0h_A)[1:10])
> > > [1] 12.276 11.958 14.098 13.843 12.451 11.745 NA NA NA NA
> > >> ord<-ordered(merged$Pcc_0h_A)
> > >> length(ord)
> > > [1] 12202
> > >> ord[1:10]
> > > [1] 12.276 11.958 14.098 13.843 12.451 11.745 <NA> <NA> <NA> <NA>
> > > 5386 Levels: 10.001 < 10.002 < 10.003 < 10.005 < 10.006 < 10.010 <
> > > ... < 9.999
> > >
> > > here I have <NA> instead of NA because ord is a factor and the
> > > notation
> > is
> > > different ?
> >
> > >
> > >> length(as.numeric(merged$Pcc_0h_A))
> > > [1] 12202
> > >> as.numeric(merged$Pcc_0h_A[1:10])
> > > [1] 1812 1547 3308 3114 1960 1370 NA NA NA NA
> > >
> > > are these the levels names converted into numbers ? I don't think
> > because
> > > levels are like 10.001, 10.002 etc and 1812, 1547 etc are not in
> > > this
> > form.
> 
> 
> 
> with the str(merged) value I guess that 1812, 1547 etc are a sort of
> rank , am I right ?
> 
> >
> > > thanks a million
> > >
> > > florence;
> > >
> >
> >
> 
>  [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From bady at univ-lyon1.fr  Fri Oct  7 09:36:20 2005
From: bady at univ-lyon1.fr (bady@univ-lyon1.fr)
Date: Fri, 07 Oct 2005 09:36:20 +0200
Subject: [R] Compare two distance matrices
In-Reply-To: <17221.19577.463128.122194@stat.math.ethz.ch>
References: <e3f8e9a00510060323x1824657et76b4d6c94c2177c0@mail.gmail.com>
	<1128602367.43451affc2602@webmail.univ-lyon1.fr>
	<17221.19577.463128.122194@stat.math.ethz.ch>
Message-ID: <1128670580.434625749b942@webmail.univ-lyon1.fr>

hi,


> but I don't see why you would need an extra package "ade4" and
> its "extra - function"  mat2dist().
> when the 'stats' package already provides the function
> as.dist(.)  {the help page of which was mentioned by the
> original poster}.

it's just a matter of habit and it's just a proposition.
I prefer use mat2dist, it?s MY choice.

the world is cruel ....
for one problem, there are very often several solutions :(
I'm sorry :)


P.BADY



From r.hankin at noc.soton.ac.uk  Fri Oct  7 09:39:50 2005
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Fri, 7 Oct 2005 08:39:50 +0100
Subject: [R] R-2.2.0 compilation problem
Message-ID: <CF6F9C30-F443-4500-8626-CED64683A6B5@soc.soton.ac.uk>

Hi

I tried to compile R-2.2.0 just now.  configure worked fine, but  
compilation stopped with

[snip]
src/include -I/sw/include -I/usr/local/include -DHAVE_CONFIG_H  -fno- 
common  -g -O2 -c util.c -o util.lo
gcc -I../../src/extra/zlib -I../../src/extra/bzip2 -I../../src/extra/ 
pcre  -no-cpp-precomp -I. -I../../src/include -I../../src/include -I/ 
sw/include -I/usr/local/include -DHAVE_CONFIG_H  -fno-common  -g -O2 - 
c version.c -o version.lo
gcc -I../../src/extra/zlib -I../../src/extra/bzip2 -I../../src/extra/ 
pcre  -no-cpp-precomp -I. -I../../src/include -I../../src/include -I/ 
sw/include -I/usr/local/include -DHAVE_CONFIG_H  -fno-common  -g -O2 - 
c vfonts.c -o vfonts.lo
g77  -fno-common  -g -O2 -c xxxpr.f -o xxxpr.lo
gcc -dynamiclib -L/sw/lib -L/usr/local/lib -dynamiclib -install_name  
libR.dylib -compatibility_version 2.2.0  -current_version 2.2.0  - 
headerpad_max_install_names -o libR.dylib  Rembedded.lo  
CConverters.lo CommandLineArgs.lo Rdynload.lo Renviron.lo RNG.lo  
apply.lo arithmetic.lo apse.lo array.lo attrib.lo base.lo bind.lo  
builtin.lo character.lo coerce.lo colors.lo complex.lo connections.lo  
context.lo cov.lo cum.lo dcf.lo datetime.lo debug.lo deparse.lo  
deriv.lo dotcode.lo dounzip.lo dstruct.lo duplicate.lo engine.lo  
envir.lo errors.lo eval.lo format.lo fourier.lo gevents.lo gram.lo  
gram-ex.lo graphics.lo identical.lo internet.lo iosupport.lo  
lapack.lo list.lo logic.lo main.lo mapply.lo match.lo memory.lo  
model.lo names.lo objects.lo optim.lo optimize.lo options.lo par.lo  
paste.lo pcre.lo platform.lo plot.lo plot3d.lo plotmath.lo print.lo  
printarray.lo printvector.lo printutils.lo qsort.lo random.lo  
regex.lo registration.lo relop.lo saveload.lo scan.lo seq.lo  
serialize.lo size.lo sort.lo source.lo split.lo sprintf.lo startup.lo  
subassign.lo subscript.lo subset.lo summary.lo sysutils.lo unique.lo  
util.lo version.lo vfonts.lo xxxpr.lo `ls ../appl/*.lo ../nmath/ 
*.lo ../unix/*.lo  2>/dev/null` -framework vecLib -L/usr/local/lib/ 
gcc/powerpc-apple-darwin7.9.0/3.4.4 -lg2c -lgcc_s -lSystem  ../extra/ 
zlib/libz.a ../extra/bzip2/libbz2.a ../extra/pcre/libpcre.a  -lintl - 
liconv -lreadline  -lm -liconv
ld: warning multiple definitions of symbol _xerbla_
print.lo definition of _xerbla_ in section (__TEXT,__text)
/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/ 
vecLib.framework/Versions/A/libBLAS.dylib(single module) definition  
of _xerbla_
ld: warning multiple definitions of symbol _locale_charset
/sw/lib/libiconv.dylib(localcharset.o) definition of _locale_charset
/sw/lib/libintl.dylib(localcharset.lo) definition of _locale_charset
ld: warning multiple definitions of symbol _signgam
../nmath/lgamma.lo definition of _signgam in section (__DATA,__common)
/usr/lib/gcc/powerpc-apple-darwin8/4.0.0/../../../libSystem.dylib 
(gamma9.o) definition of _signgam
ld: Undefined symbols:
restFP
saveFP
/usr/bin/libtool: internal link edit command failed
make[3]: *** [libR.dylib] Error 1
make[2]: *** [R] Error 2
make[1]: *** [R] Error 1
make: *** [R] Error 1
octopus:~/scratch/R-2.2.0%


Any suggestions anyone?



 > R.Version()
$platform
[1] "powerpc-apple-darwin7.9.0"

$arch
[1] "powerpc"

$os
[1] "darwin7.9.0"

$system
[1] "powerpc, darwin7.9.0"

$status
[1] "Patched"

$major
[1] "2"

$minor
[1] "1.0"

$year
[1] "2005"

$month
[1] "05"

$day
[1] "12"

$language
[1] "R"

 >

--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From francoisromain at free.fr  Fri Oct  7 09:43:00 2005
From: francoisromain at free.fr (Romain Francois)
Date: Fri, 07 Oct 2005 09:43:00 +0200
Subject: [R] The R Graph Gallery {was  boxplot statistics}
In-Reply-To: <17222.8698.164809.696145@stat.math.ethz.ch>
References: <8d5a36350510061046w6fad11f7i2060b093795786fe@mail.gmail.com>	<1128633792.434595c0b7fc8@imp1-g19.free.fr>
	<17222.8698.164809.696145@stat.math.ethz.ch>
Message-ID: <43462704.4000300@free.fr>

Le 07.10.2005 09:21, Martin Maechler a ??crit :

>>>>>>"Romain" == Romain Francois <francoisromain at free.fr>
>>>>>>    on Thu, 06 Oct 2005 23:23:12 +0200 writes:
>>>>>>            
>>>>>>
>
>    Romain> Selon bogdan romocea <br44114 at gmail.com>:
>    >> A related comment - don't rely (too much) on boxplots. They show only
>    >> a few things, which may be limiting in many cases and completely
>    >> misleading in others. Here are a couple of suggestions for plots which
>    >> you may find more useful than the standard box plots:
>    >> - figure 3.27 from
>    >> http://www.stat.auckland.ac.nz/~paul/RGraphics/chapter3.html
>    >> - violin plots (see package vioplot) - density plots - histograms
>    >> - box-percentile plots (bpplot from Hmisc)
>    >> - quantile plots
>    >> - if comparing 2 distributions, qq plots, quantile-difference plots,
>    >> mean-difference plots etc.
>
>    Romain> Hi,
>
>    Romain> HDR (highest density regions) boxplots are interresting.
>    Romain> See http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=102
>Let me take the opportunity to thank Romain
>for setting up and maintaining the R Graph Gallery.
>
>This is really a cool website for R users. 
>He'd get my number one vote for "R website of the year"!
>
>Martin Maechler, ETH Zurich
>  
>
Wouaw,

Thank you really very much Martin. It's a great honour.

Let me thank you back and all the useRs and developeRs for making such 
an amazing software. I never knew statistics without R. It certainly was 
a sad world. Also I would like to thank Eric Lecoutre who did a lot for 
the design of the gallery in the first place.

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~
~~~~~~      Romain FRANCOIS - http://addictedtor.free.fr         ~~~~~~
~~~~        Etudiant  ISUP - CS3 - Industrie et Services           ~~~~
~~                http://www.isup.cicrp.jussieu.fr/                  ~~
~~~~           Stagiaire INRIA Futurs - Equipe SELECT              ~~~~
~~~~~~   http://www.inria.fr/recherche/equipes/select.fr.html    ~~~~~~
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~



From jarioksa at sun3.oulu.fi  Fri Oct  7 09:56:17 2005
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Fri, 07 Oct 2005 10:56:17 +0300
Subject: [R] Compare two distance matrices
In-Reply-To: <e3f8e9a00510070031t75280720m7fb4c7f89ac0e587@mail.gmail.com>
References: <e3f8e9a00510060323x1824657et76b4d6c94c2177c0@mail.gmail.com>
	<1128602367.43451affc2602@webmail.univ-lyon1.fr>
	<17221.19577.463128.122194@stat.math.ethz.ch>
	<e3f8e9a00510070031t75280720m7fb4c7f89ac0e587@mail.gmail.com>
Message-ID: <1128671778.16183.29.camel@biol102145.oulu.fi>

On Fri, 2005-10-07 at 09:31 +0200, Mattias de Hollander wrote:
> Hi all,
> 
> Thanks for the quick response. I see the ade4 package in not needed
> for distance matrix computation, but as far i can see you need it for
> comparing two distance matrices. In the stats package i can't find any
> similiar functions like mantel.randtest or RVdist.randtest of the ade4
> package. So i think this package is still needed if i would like to
> make a scatter plot of the matrices. Or should i manualy compare these
> matrices with a loop for example and make a plot of this?

To plot two dissimilarity structures d1 and d2 in base R, you can use
command

plot(d1, d2)

For a plot() command, the dissimilarity structure looks like a vector.

Dissimilarity structure means a result that you can get from as.dist()
or directly from dist() function or any other alternative implementation
of dissimilarity functions giving compliant results.

For Mantel tests you may need ade4 (or some other package that has the
same test).

cheers, jari oksanen
-- 
Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/



From jukka.ruohonen at helsinki.fi  Fri Oct  7 10:00:29 2005
From: jukka.ruohonen at helsinki.fi (jukka ruohonen)
Date: Fri,  7 Oct 2005 11:00:29 +0300
Subject: [R] panel data unit root tests
Message-ID: <1128672029.43462b1d4d2d6@www2.helsinki.fi>

Hi,

The question is as follows: has anyone coded panel data unit root tests 
with R? Even the "first generation" tests (see e.g. Levin & Lin 1993; 
Pesaran, & Smith & Im 1996; Maddala & Wu 1999) would be sufficient for my 
needs. To my understanding, these are rather easy to code, but as I have 
taken just my first steps in coding with R, existing code would save me 
from a lot of trouble & time.


With regards,

Jukka Ruohonen
University of Helsinki


References:

Levin, A. & Lin, C.F. (1993): Unit Root Tests in Panel Data. 
ftp://weber.ucsd.edu/pub/econlib/dpapers/ucsd9356.pdf

Maddala, G.S. & Wu, S. (1999): A Comparative Study of Unit Roots Tests with 
Panel Data and a New Simple Test. Oxford Bulleting of Economics and 
Statistics. Special Issue 61, 631-652.

Pesaran, M.H. & Smith, R. & Im, K.S. (1996): Dynamic Linear Models for 
Heterogenous Panels. In: Matyas, L. & Sevestre, P. (eds.): The Econometrics 
of Panel Data: a Handbook of the Theory with Applications, second edition, 
pp. 145-195.



From vdemart1 at tin.it  Fri Oct  7 10:02:24 2005
From: vdemart1 at tin.it (Vittorio)
Date: Fri, 7 Oct 2005 09:02:24 +0100 (GMT+01:00)
Subject: [R] finding missing lines...
Message-ID: <14490893.1128672144113.JavaMail.root@pswm11.cp.tin.it>

Take this as an example:

> a=data.frame(col1=c(1,2,3,4,5), col2=c
("my","beloved","daughter","son","wife"))
> b=data.frame(col1=c(1,2,4), 
col2=c("my","beloved","son"))
> a
  col1     col2
1    1       my
2    
2  beloved
3    3 daughter
4    4      son
5    5     wife
> b
  
col1    col2
1    1      my
2    2 beloved
3    4     son

As you can 
see in b is equal to a with exception of lines of a with col1= 3 and 
col1=5 that are missing.

How can I obtain a third dataframe made of 
the missing lines only, e.g.

> c
  col1     col2
1    3 daughter
2    
5     wife

Ciao
Vittorio



From dimitris.rizopoulos at med.kuleuven.be  Fri Oct  7 10:21:09 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Fri, 7 Oct 2005 10:21:09 +0200
Subject: [R] finding missing lines...
References: <14490893.1128672144113.JavaMail.root@pswm11.cp.tin.it>
Message-ID: <00cc01c5cb18$122845d0$0540210a@www.domain>

try this (presuming that you want to find the missing lines based on 
the 2nd column of the data frames):

a[!a$col2 %in% b$col2, ]


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Vittorio" <vdemart1 at tin.it>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, October 07, 2005 10:02 AM
Subject: [R] finding missing lines...


> Take this as an example:
>
>> a=data.frame(col1=c(1,2,3,4,5), col2=c
> ("my","beloved","daughter","son","wife"))
>> b=data.frame(col1=c(1,2,4),
> col2=c("my","beloved","son"))
>> a
>  col1     col2
> 1    1       my
> 2
> 2  beloved
> 3    3 daughter
> 4    4      son
> 5    5     wife
>> b
>
> col1    col2
> 1    1      my
> 2    2 beloved
> 3    4     son
>
> As you can
> see in b is equal to a with exception of lines of a with col1= 3 and
> col1=5 that are missing.
>
> How can I obtain a third dataframe made of
> the missing lines only, e.g.
>
>> c
>  col1     col2
> 1    3 daughter
> 2
> 5     wife
>
> Ciao
> Vittorio
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From ripley at stats.ox.ac.uk  Fri Oct  7 10:32:22 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 Oct 2005 09:32:22 +0100 (BST)
Subject: [R] R-2.2.0 compilation problem [on MacOS X]
In-Reply-To: <CF6F9C30-F443-4500-8626-CED64683A6B5@soc.soton.ac.uk>
References: <CF6F9C30-F443-4500-8626-CED64683A6B5@soc.soton.ac.uk>
Message-ID: <Pine.LNX.4.61.0510070923280.25888@gannet.stats>

On Fri, 7 Oct 2005, Robin Hankin wrote:

> Hi
>
> I tried to compile R-2.2.0 just now.

On MacOS X.

> configure worked fine, but
> compilation stopped with

Please ask MacOS-specific questions on the r-sig-mac list.

(Missing RestFP, SaveFP.)

I believe this is well-known and indicates an incompatible mixture of 
compilers from different sources: just Google for RestFP.  See e.g.

https://stat.ethz.ch/pipermail/r-sig-mac/2005-July/002052.html
http://tolstoy.newcastle.edu.au/~rking/R/help/05/06/7345.html

I doubt if it has anything to do with R 2.2.0.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From fcombes at gmail.com  Fri Oct  7 11:46:32 2005
From: fcombes at gmail.com (Florence Combes)
Date: Fri, 7 Oct 2005 11:46:32 +0200
Subject: [R] finding missing lines...
In-Reply-To: <14490893.1128672144113.JavaMail.root@pswm11.cp.tin.it>
References: <14490893.1128672144113.JavaMail.root@pswm11.cp.tin.it>
Message-ID: <73dae3060510070246h1632e4cfrf49dd4faece34377@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051007/cd1a44f0/attachment.pl

From david.reitter at gmail.com  Fri Oct  7 12:26:09 2005
From: david.reitter at gmail.com (David Reitter)
Date: Fri, 7 Oct 2005 11:26:09 +0100
Subject: [R] Text in Boxes?
Message-ID: <9C73BD1D-CC18-49A6-B2E5-04385A3D1F09@gmail.com>

It's probably a beginner's question:

How do I show text in boxes?
That is, can I specify a background color for text output with text() ?

The following doesn't work as I would expect:

text(labels="123", 50, 0.5, bg="green")

I've experimented with legend(),which will make the box too wide, and  
also with rect(), which doesn't know the extent of the text shown.

The concrete application for this is are multiple time series shown  
in different colors, and I'd like to show the boxed text (with the  
appropriate colors) right next to (the maximum of) each time series  
in the diagram. Color text is hard to read, so I'd like nice colored  
boxes around black text.

Thanks for your help :)



From john.maindonald at anu.edu.au  Fri Oct  7 12:44:14 2005
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 7 Oct 2005 20:44:14 +1000
Subject: [R] R/S-Plus equivalent to Genstat "predict"
In-Reply-To: <mailman.8.1128679200.29073.r-help@stat.math.ethz.ch>
References: <mailman.8.1128679200.29073.r-help@stat.math.ethz.ch>
Message-ID: <B9E1D7F4-C882-4A43-B825-D39F86C54BB0@anu.edu.au>

As an alternative to the effects package, try predict() with  
type="terms"
JM

On 7 Oct 2005, at 8:00 PM, Peter Dunn wrote:

> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Peter Dunn
> Sent: Wednesday, October 05, 2005 9:06 PM
> To: R-help mailing list
> Subject: [R] R/S-Plus equivalent to Genstat "predict":
> predictions over "averages" of covariates
>
> Hi all
>
> I'm doing some things with a colleague comparing different
> sorts of models.  My colleague has fitted a number of glms in
> Genstat (which I have never used), while the glm I have been
> using is only available for R.
>
> He has a spreadsheet of fitted means from each of his models
> obtained from using the Genstat "predict" function.  For
> example, suppose we fit the model of the type
>     glm.out <- glm( y ~ factor(F1) + factor(F2) + X1 + poly(X2,2) +
>        poly(X3,2), family=...)
>
> Then he produces a table like this (made up, but similar):
>
> F1(level1)    12.2
> F1(level2)    14.2
> F1(level3)    15.3
> F2(level1)    10.3
> F2(level2)    9.1
> X1=0        10.2
> X1=0.5        10.4
> X1=1         10.4
> X1=1.5        10.5
> X1=2        10.9
> X1=2.5        11.9
> X1=3        11.8
> X2=0        12.0
> X2=0.5        12.2
> X2=1         12.5
> X2=1.5        12.9
> X2=2        13.0
> X2=2.5        13.1
> X2=3        13.5
>
> Each of the numbers are a predicted mean.  So when X1=0, on
> average we predict an outcome of 10.2.
>
> To obtain these figures in Genstat, he uses the Genstat "predict"
> function.  When I asked for an explanation of how it was done
> (ie to make the "predictions", what values of the other
> covariates were used) I was told:
>
>
>> So, for a one-dimensional table of fitted means for any factor (or
>> variate), all other variates are set to their average
>>
> values; and the
>
>> factor constants (including the first, at zero) are given a
>>
> weighted
>
>> average depending on their respective numbers of observations.
>>
>
> So for quantitative variables (such as pH), one uses the mean
> pH in the data set when making the predictions.  Reasonable anmd easy.
>
> But for categorical variables (like Month), he implies we use
> a weighted average of the fitted coefficients for all the
> months, depending on the proportion of times those factor
> levels appear in the data.
>
> (I hope I explained that OK...)
>
> Is there an equivalent way in R or S-Plus of doing this?  I
> have to do it for a number of sites and species, so an
> automated way would be useful.  I have tried searching to no
> avail (but may not be searching on the correct terms), and
> tried hard-coding something myself as yet unsuccessfully:
> The  poly  terms and the use of the weighted averaging over
> the factor levels are proving a bit too much for my limited skills.
>
> Any assistance appreciated.  (Any clarification of what I
> mean can be provided if I have not been clear.)
>
> Thanks, as always.
>
> P.



From B.Rowlingson at lancaster.ac.uk  Fri Oct  7 13:38:06 2005
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 07 Oct 2005 12:38:06 +0100
Subject: [R] Text in Boxes?
In-Reply-To: <9C73BD1D-CC18-49A6-B2E5-04385A3D1F09@gmail.com>
References: <9C73BD1D-CC18-49A6-B2E5-04385A3D1F09@gmail.com>
Message-ID: <43465E1E.6090901@lancaster.ac.uk>

David Reitter wrote:

> text(labels="123", 50, 0.5, bg="green")
> 
> I've experimented with legend(),which will make the box too wide, and  
> also with rect(), which doesn't know the extent of the text shown.
> 

  strwidth and strheight know!

  here's a quickie - adjust to your specifications:

textBox <- function(x,y,text,bg,xpad=.1,ypad=1){

   w=strwidth(text)+xpad*strwidth(text)
   h=strheight(text)+ypad*strheight(text)

   rect(x-w/2,y-h/2,x+w/2,y+h/2,col=bg)
   text(x,y,text)
}

  plot(1:10)
  textBox(7,7,'Hello World This is a test','green',ypad=1)

  - possible tweaks may involve text-alignment (look at the 'adj' 
parameter of 'par()'), changing the text colour etc etc!

Baz



From rchandler at forwild.umass.edu  Fri Oct  7 13:47:24 2005
From: rchandler at forwild.umass.edu (Richard Chandler)
Date: Fri,  7 Oct 2005 07:47:24 -0400
Subject: [R] AIC in lmer
Message-ID: <1128685644.4346604c1960d@mail-www2.oit.umass.edu>

Hello all,

Is AIC calculated incorrectly in lmer? It appears as though it uses
AIC = -2*logLik - 2*#parms, instead of -2*LogLik + 2*#parms? Below is
output from one of many models I have tried:

Generalized linear mixed model fit using PQL 
Formula: cswa ~ pcov.ess1k + (1 | year) 
   Data: ptct50.5 
 Family: poisson(log link)
      AIC    BIC    logLik deviance
 224.8466 219.19 -114.4233 228.8466
Random effects:
     Groups        Name    Variance    Std.Dev. 
       year (Intercept)   0.0062643    0.079147 
# of obs: 125, groups: year, 2

Estimated scale (compare to 1)  1.277183 

Fixed effects:
              Estimate Std. Error  z value Pr(>|z|)
(Intercept) -0.1059628  0.1283976 -0.82527   0.4092
pcov.ess1k   0.0101182  0.0093962  1.07683   0.2816


A snip of my data:

      cswa pcov.ess250 year
  [1,]    4        7.14 2004
  [2,]    4       19.26 2003
  [3,]    1        3.66 2004

I'm using R 2.1.1 with Windows XP.

Thanks,
Richard

-- 
Richard Chandler
Department of Natural Resources Conservation
UMass Amherst
(413)545-1237



From jwcasl at gmail.com  Fri Oct  7 14:05:18 2005
From: jwcasl at gmail.com (John Chen)
Date: Fri, 7 Oct 2005 08:05:18 -0400
Subject: [R] permutational Kolmogorov-Smirnov p-value for paired data
Message-ID: <e24e12f50510070505r61cbfdcet30410e473003443d@mail.gmail.com>

Dear List,

I am new to R and find it very powerful. I would like to compute the
permutational p-value for paired data using Kolmogorov-Smirnov, but
the built-in ks.test does not have this option, unlike the t.test
which has a paired=TRUE flag. Has someone written a library or a
routine that does this? Alternatively, if someone could show me how to
do pair-wise permutations in R, then I can compute the ks statistic
for each permutation, that'll work too. Thank you!

John



From christian.strunk-extern at hsh-nordbank.com  Fri Oct  7 14:15:27 2005
From: christian.strunk-extern at hsh-nordbank.com (christian.strunk-extern@hsh-nordbank.com)
Date: Fri, 7 Oct 2005 14:15:27 +0200
Subject: [R] Troubleshooting with "gpd" (Fit generalized pareto model)
Message-ID: <OF6B1669D4.2856514F-ONC1257093.0041EB1F-C1257093.0043539F@no-response2.priv>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051007/8d10b917/attachment.pl

From bitwrit at ozemail.com.au  Sat Oct  8 00:50:23 2005
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Fri, 07 Oct 2005 22:50:23 +0000
Subject: [R] Text in Boxes?
In-Reply-To: <9C73BD1D-CC18-49A6-B2E5-04385A3D1F09@gmail.com>
References: <9C73BD1D-CC18-49A6-B2E5-04385A3D1F09@gmail.com>
Message-ID: <4346FBAF.2000506@ozemail.com.au>

David Reitter wrote:
> It's probably a beginner's question:
> 
> How do I show text in boxes?
> That is, can I specify a background color for text output with text() ?
> 
> The following doesn't work as I would expect:
> 
> text(labels="123", 50, 0.5, bg="green")
> 
> I've experimented with legend(),which will make the box too wide, and  
> also with rect(), which doesn't know the extent of the text shown.
> 
> The concrete application for this is are multiple time series shown  
> in different colors, and I'd like to show the boxed text (with the  
> appropriate colors) right next to (the maximum of) each time series  
> in the diagram. Color text is hard to read, so I'd like nice colored  
> boxes around black text.
> 
Have a look at the plotrix package, particularly "textbox" and 
"boxed.labels". I would like to know if there are any enhancements you 
could suggest, as I am close to uploading the next version.

Jim



From cg.pettersson at evp.slu.se  Fri Oct  7 14:57:22 2005
From: cg.pettersson at evp.slu.se (=?iso-8859-1?Q?Carl-G=F6ran_Pettersson?=)
Date: Fri, 7 Oct 2005 14:57:22 +0200 (CEST)
Subject: [R] The mathematics inside lme()
Message-ID: <62942.62.119.38.100.1128689842.squirrel@webmail.slu.se>

Hello all!

Consider a dataset with a grouping structure, Group (factor)
Several treatments, Treat (factor)
Some sort of yield, Yield (numeric)
Something, possibly important, measured for each group; GroupCov (numeric)

To look for fixed effects from Treat on Yield, a first attempt could be:

m1 <- lm(Yield ~ Treat)

which gives, in a symmetric situation, the same estimated fixed effects as:

m2 <- lme(Yield ~ Treat,
          random =~1| Group)

but m2 is a much better model with safer significances.

Now I want to evaluate GroupCov as a covariate to Treat. I can then start
with either m1 or m2 as base, but what is most correct when GroupCov has
only one value for each Group?

m3 <- lm(Yield ~ Treat + GroupCov + Treat:GroupCov)

gives the same fixed effects as

m4 <- lme(Yield ~ Treat + GroupCov + Treat:GroupCov,
          random =~1| Group)

but this time the prob.values for GroupCov is much stronger in m3 than in
m4. Needless to say, anova(m3,m4) tells that m4 is a better *model* than
m3. But is it better for my purpose? Trying an old-fashioned style model
with only fixed effects? (Don??t shout at me, it is only a dirty test of
the system):

m5 <- lm(Yield ~ Group + Treat + GroupCov + Treat:GroupCov)

is accepted by lm() but here GroupCov is silently removed from the
analysis by lm(). I accept this removal, but I get even more suspicious
that something fishy is going on in m4. My gut-feeling is that m3 is the
right starting point but I have got a general recommendation always to
start with m4-type calls when evaluating numeric covariates. I need one
(or two) "doctor second opinion" on this.

How is the mathematics inside lme() working? Is some part of the variation
I want to catch as an effect from GroupCov already removed by the random
call, or why do I get better significances in the pure fixed call? Could
these sigificances be some sort of artefact?

Cheers
/CG

PS.
I sent basically this question, but in a more special case and with
another header, to the list two days ago. Nobody was interested, hopefully
this is more tasty ;-)
DS.


-- 
CG Pettersson, MSci, PhD Stud.
Swedish University of Agricultural Sciences (SLU)
Dep. of Crop Production Ekology. Box 7043.
SE-750 07 Uppsala, Sweden
cg.pettersson at evp.slu.se



From olivier.eterradossi at ema.fr  Fri Oct  7 15:21:23 2005
From: olivier.eterradossi at ema.fr (Olivier ETERRADOSSI)
Date: Fri, 07 Oct 2005 15:21:23 +0200
Subject: [R] R version 2.01.1, Crimson Editor and the "one" from nowhere
Message-ID: <43467653.3070701@ema.fr>

Dear List....
sorry to bother you R-gurus with such an "unstatistical" question... but 
I face a problem using Crimson Editor with R 2.01.1 that I never had 
using R 2.00.1.
I already posted on the Crimson Editor forum but it seems to be VERY few 
R-users there....

I successfully used R v2.00.1until now (under Windows XP professionnal, 
version 2002, Service Pack 2, P4 processor CPU 1.8 GHz), together with 
Crimson Editor.
This editor is "linked" to R using three files (TpR.exe, R.SPC and R.KEYS).
I recently upgraded to R 2.01.1.
I kept using my old TpR.exe, R.SPC and R.KEYS, because I did not find 
any new files on the Crimson Editor "Release" web page.
When I now launch a script, instead of getting my old, well known prompt :
 > source("C:/Program Files/R/fooscript.txt")
I get :
 > 1source("C:/Program Files/R/fooscript.txt")
with a "1" in front of the line.... and of course R  greets me with a 
"syntax error" message.
Then I have to remove the "1" by hand (pretty prehistoric, ...and does 
not work if  my script is meant to launch other scripts during the 
night....)
I cannot figure where this "1" comes from !!
Did some of you already encountered this problem, and how did you get 
rid of it ?
Thanks a lot, have a nice week-end. Olivier

-- 
Olivier ETERRADOSSI
Ma??tre-Assistant
CMGD / Equipe "Propri??t??s Psycho-Sensorielles des Mat??riaux"
Ecole des Mines d'Al??s
H??lioparc, 2 av. P. Angot, F-64053 PAU CEDEX 9
tel: +33 (0)5.59.30.54.25
fax: +33 (0)5.59.30.63.68
http://www.ema.fr



From tokkass at yahoo.com  Fri Oct  7 15:35:29 2005
From: tokkass at yahoo.com (toka tokas)
Date: Fri, 7 Oct 2005 06:35:29 -0700 (PDT)
Subject: [R] builiding R from sources
Message-ID: <20051007133529.53829.qmail@web35307.mail.mud.yahoo.com>

Dear R users,

I've been trying to build R from sources (in Windows) using Dr. Goto's BLAS,
unsuccessfully! I've followed the instructions in Section 3.1.2-3.1.3 of "R
Installation and Administration" manual (but maybe I did something wrong), but I
keep receiving the following error:

-- initially I get --

make: ./Rpwd.exe: Command not found
make[1]: ./Rpwd.exe: Command not found

...

DR_DLL_BUILD -c arithmetic.c -o arithmetic.o
arithmetic.c: In function 'do.math1':
arithmetic.c:886: error: 'expm1' undeclared (first use in this function)
arithmetic.c:886: error: (Each undeclared identifier is reported only once
arithmetic.c:886: error: for each function it appears in.)
make[4]: *** [arithmetic.o] Error 1
make[3]: *** [rlibs] Error 2
make[2]: *** [../../bin/R.dll] Error 2
make[1]: *** [rbuild] Error 2
make: *** [all] Error 2


any help is greatly appreciated!

Thanks in advance,
tokas



From Lorenz.Gygax at fat.admin.ch  Fri Oct  7 15:39:43 2005
From: Lorenz.Gygax at fat.admin.ch (Lorenz.Gygax@fat.admin.ch)
Date: Fri, 7 Oct 2005 15:39:43 +0200 
Subject: [R] The mathematics inside lme()
Message-ID: <BF74FADD4B44554CA7E53D0B5242CD6A034FF090@evd-s7014.bk.evdad.admin.ch>

> Now I want to evaluate GroupCov as a covariate to Treat. I 
> can then start with either m1 or m2 as base, but what is most
> correct when GroupCov has only one value for each Group?
> 
> m3 <- lm(Yield ~ Treat + GroupCov + Treat:GroupCov)
> 
> gives the same fixed effects as
> 
> m4 <- lme(Yield ~ Treat + GroupCov + Treat:GroupCov,
>           random =~1| Group)
> 
> but this time the prob.values for GroupCov is much stronger 
> in m3 than in m4. Needless to say, anova(m3,m4) tells that m4
> is a better *model* than m3. But is it better for my purpose?

Well, I do not actually know what your purpose is ...
... but in my oppinion the second model is much better (and I am tempted to
say the first one is wrong).

The crucial point here is that there is only one value of GroupCov in each
Group. Thus the number of replications that provide degrees of freedom for
the effect of GroupCov is the number of groups. m4 adjusts for this fact,
has a lower df for the GroupCov and thus a lower p-value.

In m3, you model as if all your observations are independent for all
variables. This is actually the case for none but may become more visible
for GroupCov because this variable is constant for all units within group
(and thus this value is certainly not independent).

Cheers, Lorenz
- 
Lorenz Gygax, Dr. sc. nat.
Centre for proper housing of ruminants and pigs
Swiss Federal Veterinary Office
agroscope FAT T??nikon, CH-8356 Ettenhausen / Switzerland



From dmbates at gmail.com  Fri Oct  7 15:47:59 2005
From: dmbates at gmail.com (Douglas Bates)
Date: Fri, 7 Oct 2005 08:47:59 -0500
Subject: [R] AIC in lmer
In-Reply-To: <1128685644.4346604c1960d@mail-www2.oit.umass.edu>
References: <1128685644.4346604c1960d@mail-www2.oit.umass.edu>
Message-ID: <40e66e0b0510070647h230013f6s321abe0e798d14ab@mail.gmail.com>

The calculation is being done in

                  print(data.frame(AIC = AIC(llik), BIC = BIC(llik),
                               logLik = c(llik),
                               deviance = -2*llik,
                               row.names = ""))

where llik is defined as

              llik <- object at logLik

so the important question is whether the logLik slot has the correct
values for the number of parameters.

By the way, why are you calculating a random effect for year when you
only have two years of data? The estimate of the variance of that
random effect will have almost no precision.

On 10/7/05, Richard Chandler <rchandler at forwild.umass.edu> wrote:
> Hello all,
>
> Is AIC calculated incorrectly in lmer? It appears as though it uses
> AIC = -2*logLik - 2*#parms, instead of -2*LogLik + 2*#parms? Below is
> output from one of many models I have tried:
>
> Generalized linear mixed model fit using PQL
> Formula: cswa ~ pcov.ess1k + (1 | year)
>    Data: ptct50.5
>  Family: poisson(log link)
>       AIC    BIC    logLik deviance
>  224.8466 219.19 -114.4233 228.8466
> Random effects:
>      Groups        Name    Variance    Std.Dev.
>        year (Intercept)   0.0062643    0.079147
> # of obs: 125, groups: year, 2
>
> Estimated scale (compare to 1)  1.277183
>
> Fixed effects:
>               Estimate Std. Error  z value Pr(>|z|)
> (Intercept) -0.1059628  0.1283976 -0.82527   0.4092
> pcov.ess1k   0.0101182  0.0093962  1.07683   0.2816
>
>
> A snip of my data:
>
>       cswa pcov.ess250 year
>   [1,]    4        7.14 2004
>   [2,]    4       19.26 2003
>   [3,]    1        3.66 2004
>
> I'm using R 2.1.1 with Windows XP.
>
> Thanks,
> Richard
>
> --
> Richard Chandler
> Department of Natural Resources Conservation
> UMass Amherst
> (413)545-1237
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Fri Oct  7 16:05:38 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 Oct 2005 15:05:38 +0100 (BST)
Subject: [R] builiding R from sources
In-Reply-To: <20051007133529.53829.qmail@web35307.mail.mud.yahoo.com>
References: <20051007133529.53829.qmail@web35307.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.61.0510071458280.5716@gannet.stats>

Please tell us which version of R.

If this is 2.2.0 (I think it is) you need to review the tools you are 
using, as mingw-runtime-3.8 is required.  (It says so explicitly in that 
manual, and that is the current version of that package.)

For R-patched you will also need a recent enough version of binutils (the 
ones mentioned in those places are recent enough).

NB: Dr Goto's BLAS is no longer available for Windows, and it seems it is 
not going to be in future.  For Linux it is now available for academic use 
only.

On Fri, 7 Oct 2005, toka tokas wrote:

> Dear R users,
>
> I've been trying to build R from sources (in Windows) using Dr. Goto's BLAS,
> unsuccessfully! I've followed the instructions in Section 3.1.2-3.1.3 of "R
> Installation and Administration" manual (but maybe I did something wrong), but I
> keep receiving the following error:
>
> -- initially I get --
>
> make: ./Rpwd.exe: Command not found
> make[1]: ./Rpwd.exe: Command not found

That is just a warning, I think.

> ...
>
> DR_DLL_BUILD -c arithmetic.c -o arithmetic.o
> arithmetic.c: In function 'do.math1':
> arithmetic.c:886: error: 'expm1' undeclared (first use in this function)
> arithmetic.c:886: error: (Each undeclared identifier is reported only once
> arithmetic.c:886: error: for each function it appears in.)
> make[4]: *** [arithmetic.o] Error 1
> make[3]: *** [rlibs] Error 2
> make[2]: *** [../../bin/R.dll] Error 2
> make[1]: *** [rbuild] Error 2
> make: *** [all] Error 2

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andreas.cordes at stud.uni-goettingen.de  Fri Oct  7 16:11:56 2005
From: andreas.cordes at stud.uni-goettingen.de (Andreas Cordes)
Date: Fri, 07 Oct 2005 16:11:56 +0200
Subject: [R] missing values in step procedure
Message-ID: <4346822C.8020100@stud.uni-goettingen.de>

Hi,
I have the problem that for the step procedure stops due to missing 
values. There are no options in Step or stepAIC to handle missing 
values. Is there any way to run stepwise modelselection in R in an 
automated way in this case?

Here is the last step before it stops. Hope someone knows. Best regards, 
Andreas

Step:  AIC= 1999.16
 EF ~ SF120_KS + SF120_PS + HADA0 + SOZU0 + LVEDD + logPROBNP + 
    ALTER + SD0_01 + ASE_UK + DS140POS + RSQSICH0 + SD0_01:ASE_UK + 
    SD0_01:DS140POS + SD0_01:RSQSICH0 + ASE_UK:DS140POS + 
ASE_UK:RSQSICH0 + 
    DS140POS:RSQSICH0 + SD0_01:ASE_UK:RSQSICH0 + 
SD0_01:DS140POS:RSQSICH0 + 
    ASE_UK:DS140POS:RSQSICH0

                           Df Sum of Sq     RSS     AIC
- SOZU0                     1       3.0 25356.0  1997.2
- HADA0                     1       7.6 25360.6  1997.3
- ALTER                     1      13.0 25365.9  1997.4
- SF120_PS                  1      14.7 25367.6  1997.5
- ASE_UK:DS140POS:RSQSICH0  1      20.1 25373.1  1997.6
- SD0_01:DS140POS:RSQSICH0  1      44.8 25397.7  1998.0
- SD0_01:ASE_UK:RSQSICH0    1      54.4 25407.4  1998.2
<none>                                  25352.9  1999.2
- LVEDD                     1     382.2 25735.1  2004.6
- SF120_KS                  1     476.4 25829.3  2006.4
- logPROBNP                 1     891.9 26244.9  2014.4
Error in step(mod2, direction = "back") :
        number of rows in use has changed: remove missing values?



From david.reitter at gmail.com  Fri Oct  7 16:22:17 2005
From: david.reitter at gmail.com (David Reitter)
Date: Fri, 7 Oct 2005 15:22:17 +0100
Subject: [R] Text in Boxes?
In-Reply-To: <4346FBAF.2000506@ozemail.com.au>
References: <9C73BD1D-CC18-49A6-B2E5-04385A3D1F09@gmail.com>
	<4346FBAF.2000506@ozemail.com.au>
Message-ID: <ACA2631F-D47B-41F4-91F0-77BEE212323A@gmail.com>


On 7 Oct 2005, at 23:50, Jim Lemon wrote:
>>
> Have a look at the plotrix package, particularly "textbox" and  
> "boxed.labels". I would like to know if there are any enhancements  
> you could suggest, as I am close to uploading the next version.

Great, that's what I needed.

thigmophobe.labels would have been even better, but too bad it  
doesn't combine with boxed.labels.

Also, for boxed.labels I wonder why the parameter for the color is  
"col" instead of "bg" - because with "col", I'd like to set the color  
of the text, which I have to do with a par(col= ...) before the call  
to boxed.labels right now.

For the padding, I suggest extra parameters that allow padding  
independent of the width/height of the box to allow for a constant  
padding of, say, 2pt.

Thanks also to Jari Oksanen and Barry Rowlingson for your hints -  
strwidth is useful!

From ripley at stats.ox.ac.uk  Fri Oct  7 16:35:17 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 Oct 2005 15:35:17 +0100 (BST)
Subject: [R] missing values in step procedure
In-Reply-To: <4346822C.8020100@stud.uni-goettingen.de>
References: <4346822C.8020100@stud.uni-goettingen.de>
Message-ID: <Pine.LNX.4.61.0510071532400.10272@gannet.stats>

On Fri, 7 Oct 2005, Andreas Cordes wrote:

> I have the problem that for the step procedure stops due to missing
> values. There are no options in Step or stepAIC to handle missing
> values. Is there any way to run stepwise modelselection in R in an
> automated way in this case?

Try the hint it gives you, or see the help page (which covers this in a 
warning with an explanation).

[...]

> Error in step(mod2, direction = "back") :
>        number of rows in use has changed: remove missing values?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From JAROSLAW.W.TUSZYNSKI at saic.com  Fri Oct  7 16:40:07 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Fri, 7 Oct 2005 10:40:07 -0400 
Subject: [R] The R Graph Gallery {was  boxplot statistics}
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD503FD3740@us-arlington-0668.mail.saic.com>

I agree with Martin "R Graph Gallery" has a lot of neat stuff.

I also think there should be a on CRAN website a list of "R websites". And
in a perfect world one of the search engines scope would get extended to
search them all.

 Jarek 
====================================================\==== 
 Jarek Tuszynski, PhD.                           o / \ 
 Science Applications International Corporation  <\__,|  
 (703) 676-4192                                   ">  \ 
 Jaroslaw.W.Tuszynski at saic.com                     `   \ 



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] 
Sent: Friday, October 07, 2005 3:22 AM
To: francoisromain at free.fr
Cc: R-help at stat.math.ethz.ch; karin.lagesen at medisin.uio.no; bogdan romocea
Subject: [R] The R Graph Gallery {was boxplot statistics}

>>>>> "Romain" == Romain Francois <francoisromain at free.fr>
>>>>>     on Thu, 06 Oct 2005 23:23:12 +0200 writes:

    Romain> Selon bogdan romocea <br44114 at gmail.com>:
    >> A related comment - don't rely (too much) on boxplots. They show only
    >> a few things, which may be limiting in many cases and completely
    >> misleading in others. Here are a couple of suggestions for plots
which
    >> you may find more useful than the standard box plots:
    >> - figure 3.27 from
    >> http://www.stat.auckland.ac.nz/~paul/RGraphics/chapter3.html
    >> - violin plots (see package vioplot) - density plots - histograms
    >> - box-percentile plots (bpplot from Hmisc)
    >> - quantile plots
    >> - if comparing 2 distributions, qq plots, quantile-difference plots,
    >> mean-difference plots etc.

    Romain> Hi,

    Romain> HDR (highest density regions) boxplots are interresting.
    Romain> See
http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=102
Let me take the opportunity to thank Romain for setting up and maintaining
the R Graph Gallery.

This is really a cool website for R users. 
He'd get my number one vote for "R website of the year"!

Martin Maechler, ETH Zurich

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From carotenuto at igb.cnr.it  Fri Oct  7 16:36:49 2005
From: carotenuto at igb.cnr.it (carotenuto@igb.cnr.it)
Date: Fri,  7 Oct 2005 16:36:49 +0200
Subject: [R] Differentially expressed gene list
Message-ID: <1128695809.43468801d6216@mail.igb.cnr.it>



Hi,when I perform SAM on  my array data(siggenes)I have some problems in 
retrieving the separate lists of up regulated and down regulated genes.
When I write:
fold<-function(x){                                
gruppi<-split(x,controllo)
geni1<-abs(mean(gruppi[[2]])-mean(gruppi[[1]]))
return(geni1)
}
fold<-esApply(expr.contr.tratt.4,1,fold)
filtro.geni.4_prova<-expr.contr.tratt.4[which(fold>=1),]
filtro.geni.4_prova

everything is working well and I can obtain the correct HTML output,but if I 
write the same using fold change<1 to obtain downregulated genes,I have the 
following  warning message:

###Warning messages:
####1: the condition has length > 1 and only the first element will be used in: 
if (!nchar(text <- getText(object))) return("") 
####2: the condition has length > 1 and only the first element will be used in: 
if (!nchar(text <- getText(object))) return("") 
####3: the condition has length > 1 and only the first element will be used in: 
if (!nchar(text <- getText(object))) return("") 
####4: the condition has length > 1 and only the first element will be used in: 
if (!nchar(text <- getText(object))) return("") 
####5: the condition has length > 1 and only the first element will be used in: 
if (!nchar(text <- getText(object))) return("")

Where is the mistake?
Thank you for your help
Sara



From subianto at gmail.com  Fri Oct  7 17:12:11 2005
From: subianto at gmail.com (Muhammad Subianto)
Date: Fri, 07 Oct 2005 17:12:11 +0200
Subject: [R] make some possible neighbourhoods
Message-ID: <4346904B.8090308@gmail.com>

Dear all,
I want to make some possible neighbourhoods in dataset below,
   V1 <- c(0,1,2,3)
   V2 <- c(0,1)
   V3 <- c(0,1,2)
   V4 <- c(0,1,2,3,4)
and then I have a domain which the number of each variables.
For dataset above a domain,
   domains <- c(3,1,2,4)
To create the neighbourhoods I choice one point from all possible point 
in dataset. I take one random point, for instance:
   point <- c(2,1,0,0)
To produce the neighbourhoods I run like this (see a code below):
   neighb2(point,domains)
 >   neighb2(point,domains)
Error: subscript out of bounds
 >

Try one random point again,
   point2 <- c(2,0,1,3)
   neighb2(point2,domains)
 >   neighb2(point2,domains)
Error: subscript out of bounds
 >

but if I choice a random point,
 >  point1 <- c(0,1,1,0)
 >   neighb2(point1,domains)
       [,1] [,2] [,3] [,4]
  [1,]    1    0    1    0
  [2,]    1    2    1    0
  [3,]    1    3    1    0
  [4,]    2    0    1    0
  [5,]    2    2    1    0
...
[65,]    0    1    3    3
[66,]    0    1    4    3
[67,]    0    1    0    4
[68,]    0    1    2    4
[69,]    0    1    3    4
[70,]    0    1    4    4
 >
it's OK.

I am not sure where I am mistake.
I believe it is the problem of the code.
How should I fix this problem.
Thanks in advance for any help.

Best regards,
Muhammad Subianto

Here is a code:

neighb2 <- function(point,domains) {
   nn2 <- sum(domains)*(sum(domains)-1)
   nvar <- length(point)
   neighb <- matrix(nrow=nn2,ncol=nvar)
   k <- 1
   for (i in 1:nvar) {
        restvars <- 1:nvar
        restvars <- restvars[-i]
        for (j in restvars) {
             values1 <- values2 <- 0:domains[i]
             values1 <- values1[-(point[i]+1)]
             values2 <- values2[-(point[j]+1)]
             for (m in values1) {
                  for (n in values2) {
                       neigh <- point
                       neigh[i] <- m
                       neigh[j] <- n
                       neighb[k,] <- neigh
                       k <- k+1
                  }
             }
        }
   }
   unique(neighb)
   }



From vmuggeo at dssm.unipa.it  Fri Oct  7 17:23:00 2005
From: vmuggeo at dssm.unipa.it (vito muggeo)
Date: Fri, 07 Oct 2005 17:23:00 +0200
Subject: [R] AIC in lmer
In-Reply-To: <1128685644.4346604c1960d@mail-www2.oit.umass.edu>
References: <1128685644.4346604c1960d@mail-www2.oit.umass.edu>
Message-ID: <434692D4.5040900@dssm.unipa.it>

Hi,
my reply just concerns the usage of AIC in mixed models and not the lmer 
package.

The "standard" AIC is actually unconditional.

Vaida and Blanchard (2003, Proceeding 19 IWSM,101-105) discuss that a 
"conditional" version should be more appropriate in a mixed framework.

I don't whether the paper has been pubblished elsewhere.

regards,
vito




Richard Chandler wrote:
> Hello all,
> 
> Is AIC calculated incorrectly in lmer? It appears as though it uses
> AIC = -2*logLik - 2*#parms, instead of -2*LogLik + 2*#parms? Below is
> output from one of many models I have tried:
> 
> Generalized linear mixed model fit using PQL 
> Formula: cswa ~ pcov.ess1k + (1 | year) 
>    Data: ptct50.5 
>  Family: poisson(log link)
>       AIC    BIC    logLik deviance
>  224.8466 219.19 -114.4233 228.8466
> Random effects:
>      Groups        Name    Variance    Std.Dev. 
>        year (Intercept)   0.0062643    0.079147 
> # of obs: 125, groups: year, 2
> 
> Estimated scale (compare to 1)  1.277183 
> 
> Fixed effects:
>               Estimate Std. Error  z value Pr(>|z|)
> (Intercept) -0.1059628  0.1283976 -0.82527   0.4092
> pcov.ess1k   0.0101182  0.0093962  1.07683   0.2816
> 
> 
> A snip of my data:
> 
>       cswa pcov.ess250 year
>   [1,]    4        7.14 2004
>   [2,]    4       19.26 2003
>   [3,]    1        3.66 2004
> 
> I'm using R 2.1.1 with Windows XP.
> 
> Thanks,
> Richard
> 

-- 
====================================
Vito M.R. Muggeo
Dip.to Sc Statist e Matem `Vianelli'
Universit?? di Palermo
viale delle Scienze, edificio 13
90121 Palermo - ITALY
tel: 091 6626240
fax: 091 485726/485612



From afshart at exchange.sba.miami.edu  Fri Oct  7 17:46:31 2005
From: afshart at exchange.sba.miami.edu (Afshartous, David)
Date: Fri, 7 Oct 2005 11:46:31 -0400
Subject: [R] index question
Message-ID: <6BCB4D493A447546A8126F24332056E8F28BAE@school1.business.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051007/f0e6fdf8/attachment.pl

From nlemeur at fhcrc.org  Fri Oct  7 17:54:34 2005
From: nlemeur at fhcrc.org (Nolwenn LeMeur)
Date: Fri, 7 Oct 2005 08:54:34 -0700 (PDT)
Subject: [R] index question
In-Reply-To: <6BCB4D493A447546A8126F24332056E8F28BAE@school1.business.edu>
References: <6BCB4D493A447546A8126F24332056E8F28BAE@school1.business.edu>
Message-ID: <Pine.LNX.4.61.0510070853360.22400@vole.fhcrc.org>

Hi,
how about group.label.new[c(junk,8:10)]

Nolwenn  

**************************************
Nolwenn Le Meur, PhD
Fred Hutchinson Cancer Research Center
Computational Biology
1100 Fairview Ave. N., M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

On Fri, 7 Oct 2005, Afshartous, David wrote:

> 
> 
> All,
> I'm having a problem selecting directly from a vector.  I've written ways to do this
> indirectly, but I'd rather do it directly and didn't see this in the manual.
> 
> Essentially, I have:
> 
> > group.label.new
>  [1]  7  9  6  1 10  4  8  3  2  5
> > junk
> [1] 1 2
> > group.label.new[junk && 8:10]
>  [1]  7  9  6  1 10  4  8  3  2  5
> 
> I'd like to select the elements indexed by "junk" and also the 8th through 10th elements, which
> clearly isn't the result I'm getting.  Any help appreciated, and please reply directly to 
> afshar at miami.edu
> 
> cheers,
> dave
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From dgiunchi at discau.unipi.it  Fri Oct  7 17:48:44 2005
From: dgiunchi at discau.unipi.it (Dimitri Giunchi)
Date: Fri, 7 Oct 2005 15:48:44 +0000 (UTC)
Subject: [R] problems with loess
Message-ID: <loom.20051007T172840-178@post.gmane.org>

Hi all,

I was unable to obtained a smoothed line using the loess function.
I used the following code reported in the examples of R documentation:

cars.lo <- loess(dist ~ speed, cars)

Then I tried to plot both the data and the smoothed line

plot(cars)
lines(cars.lo)

but what I obtained is simply a broken line joining all the data points.
I tried with different spans, but the results did not change.


Does anyone know what's going wrong? 


Thanks

Dimitri




platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    2.0    




-- 
Dimitri Giunchi
Dipartimento di Etologia Ecologia Evoluzione
UniversitÃ  di Pisa
Via A. Volta 6
56126 Pisa
ITALY
Tel: +39 050 2219036
Fax: +39 050 24653



From ripley at stats.ox.ac.uk  Fri Oct  7 18:14:58 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 Oct 2005 17:14:58 +0100 (BST)
Subject: [R] problems with loess
In-Reply-To: <loom.20051007T172840-178@post.gmane.org>
References: <loom.20051007T172840-178@post.gmane.org>
Message-ID: <Pine.LNX.4.61.0510071712310.31649@gannet.stats>

On Fri, 7 Oct 2005, Dimitri Giunchi wrote:

> Hi all,
> I was unable to obtained a smoothed line using the loess function.I used the following code reported in the examples of R documentation:
> cars.lo <- loess(dist ~ speed, cars)
> Then I tried to plot both the data and the smoothed line
> plot(cars)lines(cars.lo)
> but what I obtained is simply a broken line joining all the data points.I tried with different spans, but the results did not change.
>
> Does anyone know what's going wrong?

Yes. lines(cars.lo) plots the original data stored in the loess fit.

You need to predict, or use scatter.smooth to do it for you.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From lassana.koita at aviation-civile.gouv.fr  Fri Oct  7 18:35:18 2005
From: lassana.koita at aviation-civile.gouv.fr (KOITA Lassana - STAC/ACE)
Date: Fri, 7 Oct 2005 18:35:18 +0200
Subject: [R] Troubleshooting with "gpd" (Fit generalized pareto model)
Message-ID: <OFFD7AADB0.8714B5C9-ONC1257093.0059CA44@aviation-civile.gouv.fr>





Hi, Christian
you must sort all data in data1, for using "gpd( ...) " function.
So try this following code :

library(evir)
data1 <- rgpd(1000, xi= -1.5, mu=1000, beta=100)
out <- gpd(sort(data1), threshold = 1060)
out

Have a good week end!


Lassana KOITA
Service Technique de l'Aviation Civile (STAC)
Direction G??n??rale de l'Aviation Civile (DGAC), France
Tel: 01 49 56 80 60
Fax: 01 49 56 82 14
@: Lassana.Koita at aviation-civile.gouv.fr



                                                                                                                                               
                      christian.strunk-extern at hsh-n                                                                                            
                      ordbank.com                       Pour :   r-help at stat.math.ethz.ch                                                      
                                                        cc :                                                                                   
                      Envoy?? par :                      Objet :  [R] Troubleshooting with "gpd" (Fit generalized pareto model)                 
                      r-help-bounces at stat.math.ethz                                                                                            
                      .ch                                                                                                                      
                                                                                                                                               
                                                                                                                                               
                      07/10/2005 14:15                                                                                                         
                                                                                                                                               
                                                                                                                                               




Up to now, I have recognized problems with "gpd(..)", the function from
the package "evir"
I think that all these functions that estimate the parameters xi, beta for
the GPD
by given threshold mu use the function "optim(..)"  ( gpd, fitgpd, ...)
"Error" example:

data1 <- rgpd(1000, xi= -1.5, mu=1000, beta=100)

so the created poinnts take place in  about (1000, 1070).
Now I want to estimate xi and beta by given threshold =1060,

out <- gpd(data1, threshold=1060)      and this causes an error in
"optim".

My questions are
(1)     Is there a more secure way the get the MLE estimators for a GPD by
given threshold and dataset?
(2)     If we only have 10 errors in a for-loop where we want to calculate
the MLE estimators for 100 different
        thresholds; how can I get the for-loop work unitl the end of the
moving index ?
        (try, tryCatch dosen??t work)

Thanks, Christian Strunk.



________________________________________________________________________________________


Diese Nachricht kann vertrauliche Informationen enthalten. Sollten Sie
nicht der vorgesehene Empf??nger sein, so bitten wir Sie, den Absender
unverz??glich zu informieren und die E-Mail zu l??schen. Jeder unbefugte
Zugriff oder unbefugte Weiterleitung, die Fertigung einer Kopie, die
Ver??ffentlichung oder sonstige in diesem Zusammenhang stehende Handlung ist
untersagt. Da wir nicht die Echtheit oder Vollst??ndigkeit der in dieser
Nachricht enthaltenen Informationen garantieren k??nnen, schlie??en wir die
rechtliche Verbindlichkeit der vorstehenden Erkl??rungen und ??u??erungen aus.

This message may contain confidential information. If you ar...{{dropped}}

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From peterm at andrew.cmu.edu  Fri Oct  7 18:49:40 2005
From: peterm at andrew.cmu.edu (Peter Muhlberger)
Date: Fri, 07 Oct 2005 12:49:40 -0400
Subject: [R] Matrix calculations in R--erroneous?
In-Reply-To: <mailman.9.1128679200.29073.r-help@stat.math.ethz.ch>
Message-ID: <BF6C1F64.E0AE%peterm@andrew.cmu.edu>

Does anyone know how -log(x) can equal 743 but -log(x+0)=Inf?  That's what
the following stream of calculations suggest:

Browse[2]> -log (   1e-323+yMat2 - yMat1 * logitShape(matrix(parsList$Xs,
nrow = numXs, ncol=numOfCurves), matrix(means, nrow = numXs,
ncol=numOfCurves, byrow=TRUE), matrix(sigmas, nrow = numXs,
ncol=numOfCurves, byrow=TRUE))   )[5,9]
[1] Inf

Yet:

Browse[2]> logitShape(matrix(parsList$Xs, nrow = numXs, ncol=numOfCurves),
matrix(means, nrow = numXs, ncol=numOfCurves, byrow=TRUE), matrix(sigmas,
nrow = numXs, ncol=numOfCurves, byrow=TRUE))[5,9]
[1] 1

So, the logitShape component equals 1.

Browse[2]> yMat1[5,9]
[1] 1

So yMat1[5,9]*logitShape()[5,9]=1

Browse[2]> yMat2[5,9]
[1] 1

So, yMat2[5,9]-yMat1[5,9]*logitShape()[5,9]=0

Browse[2]> -log (   1e-323)
[1] 743.7469

So, -log( 1e-323)=743 while -log( 1e-323+0)=Inf ?

Any idea of a neat way to get around this?  Even if I put in 1e-50 I still
get Inf.  I deliberately included 1e-323 to insure the function didn't go to
infinity.

Peter



From tlumley at u.washington.edu  Fri Oct  7 19:12:30 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 7 Oct 2005 10:12:30 -0700 (PDT)
Subject: [R] Matrix calculations in R--erroneous?
In-Reply-To: <BF6C1F64.E0AE%peterm@andrew.cmu.edu>
References: <BF6C1F64.E0AE%peterm@andrew.cmu.edu>
Message-ID: <Pine.LNX.4.63a.0510071010050.7832@homer21.u.washington.edu>

On Fri, 7 Oct 2005, Peter Muhlberger wrote:

> Does anyone know how -log(x) can equal 743 but -log(x+0)=Inf?  That's what
> the following stream of calculations suggest:
>
> Browse[2]> -log (   1e-323+yMat2 - yMat1 * logitShape(matrix(parsList$Xs,
> nrow = numXs, ncol=numOfCurves), matrix(means, nrow = numXs,
> ncol=numOfCurves, byrow=TRUE), matrix(sigmas, nrow = numXs,
> ncol=numOfCurves, byrow=TRUE))   )[5,9]
> [1] Inf
>
> Yet:
>
> Browse[2]> logitShape(matrix(parsList$Xs, nrow = numXs, ncol=numOfCurves),
> matrix(means, nrow = numXs, ncol=numOfCurves, byrow=TRUE), matrix(sigmas,
> nrow = numXs, ncol=numOfCurves, byrow=TRUE))[5,9]
> [1] 1
>
> So, the logitShape component equals 1.

to within 2e-16

> Browse[2]> yMat1[5,9]
> [1] 1
>
> So yMat1[5,9]*logitShape()[5,9]=1

to within 2e-16

> Browse[2]> yMat2[5,9]
> [1] 1

to within 2e-16

> So, yMat2[5,9]-yMat1[5,9]*logitShape()[5,9]=0

to within a few parts in 10^16

You haven't actually shown us yMat2[5,9]-yMat1[5,9]*logitShape()[5,9], 
though

> Browse[2]> -log (   1e-323)
> [1] 743.7469
>
> So, -log( 1e-323)=743 while -log( 1e-323+0)=Inf ?
>

If "0" is really of the order of 1e-16 then this isn't surprising. If the 
only point of 1e-323 is as a guard value for 0 then use max(1e-323, 
yMat2[5,9]-yMat1[5,9]*logitShape()[5,9])


 	-thomas



From roebuck at wotan.mdacc.tmc.edu  Fri Oct  7 19:22:49 2005
From: roebuck at wotan.mdacc.tmc.edu (Paul Roebuck)
Date: Fri, 7 Oct 2005 12:22:49 -0500 (CDT)
Subject: [R] sscanf equivalent
Message-ID: <Pine.OSF.4.58.0510071156580.212100@wotan.mdacc.tmc.edu>

I have a data file from which I need to read portions of
data but data location/quantity can change from file to file.
I wrote some code and have a working solution but it seems
wasteful to have to do it this way. Here's the contrived
incomplete code.

    datalines <- readLines(datafile.pathname)
    # marker will appear on line preceding and following
    # actual data
    offset.data <- grep("marker", datalines)
    datalines <- NULL

    # grab first column of each assoc dataline
    data <- scan(datafile.pathname,
                 what = numeric(0),
                 skip = offset.data[1],
                 nlines = offset.data[2]-offset.data[1]-1,
                 flush = TRUE,
                 multi.line = FALSE,
                 quiet = TRUE)
    # output is vector of values

Originally wrote code to parse data from 'datalines'
using sub and strsplit methods but it was woefully slower
and more complex than using scan method. What is desired
is a means of invoking method like scan but with existing
data instead of filename.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From ripley at stats.ox.ac.uk  Fri Oct  7 19:39:46 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 Oct 2005 18:39:46 +0100 (BST)
Subject: [R] sscanf equivalent
In-Reply-To: <Pine.OSF.4.58.0510071156580.212100@wotan.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0510071156580.212100@wotan.mdacc.tmc.edu>
Message-ID: <Pine.LNX.4.61.0510071839120.32476@gannet.stats>

Why not use a text connection?

On Fri, 7 Oct 2005, Paul Roebuck wrote:

> I have a data file from which I need to read portions of
> data but data location/quantity can change from file to file.
> I wrote some code and have a working solution but it seems
> wasteful to have to do it this way. Here's the contrived
> incomplete code.
>
>    datalines <- readLines(datafile.pathname)
>    # marker will appear on line preceding and following
>    # actual data
>    offset.data <- grep("marker", datalines)
>    datalines <- NULL
>
>    # grab first column of each assoc dataline
>    data <- scan(datafile.pathname,
>                 what = numeric(0),
>                 skip = offset.data[1],
>                 nlines = offset.data[2]-offset.data[1]-1,
>                 flush = TRUE,
>                 multi.line = FALSE,
>                 quiet = TRUE)
>    # output is vector of values
>
> Originally wrote code to parse data from 'datalines'
> using sub and strsplit methods but it was woefully slower
> and more complex than using scan method. What is desired
> is a means of invoking method like scan but with existing
> data instead of filename.
>
> ----------------------------------------------------------
> SIGSIG -- signature too long (core dumped)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dusa.adrian at gmail.com  Fri Oct  7 18:44:49 2005
From: dusa.adrian at gmail.com (Adrian DUSA)
Date: Fri, 7 Oct 2005 19:44:49 +0300
Subject: [R] returning a modified fix()-ed dataframe
Message-ID: <200510071944.49134.adi@roda.ro>


Dear all,

In order to ease the transition from SPSS to R for some of my colleagues, I am 
trying to create a function which would show the variables and their labels 
(if those exist), using function "label" in package Hmisc.

A toy example would be this:

my.data <- data.frame(age=c(24,35,28), gender=c("Male", "Female", "Male"))
require(Hmisc)
label(my.data$age) <- "Respondent's age"
label(my.data$gender) <- "Responent's gender"

variables <- function(x) {
        dataf <- data.frame(variable=NA, label=NA)
        varlab <- NA
        for (i in 1:length(names(x))) {
                dataf[i,1] <- names(x)[i]
                dataf[i,2] <- label(x[,i])
                varlab[i] <- label(x[,i])
        }
        fix(dataf)
        # I assume this would return a modified dataf
        for (i in which(varlab != dataf[,2])) {
                label(x[,i]) <- dataf[i,2]
        }
}

Now, say during fix() one modified "Responent's gender" into "Respondent's 
gender" (the previous missed a "d"). The trouble I'm having is to return the 
modified object, with the modified labels. It should be easy, I feel it, but 
I just can't get it.

Thank you in advance,
Adrian

-- 
Adrian DUSA
Romanian Social Data Archive
1, Schitu Magureanu Bd
050025 Bucharest sector 5
Romania
Tel./Fax: +40 21 3126618 \
          +40 21 3120210 / int.101



From sundar.dorai-raj at pdf.com  Fri Oct  7 19:55:38 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Fri, 07 Oct 2005 12:55:38 -0500
Subject: [R] returning a modified fix()-ed dataframe
In-Reply-To: <200510071944.49134.adi@roda.ro>
References: <200510071944.49134.adi@roda.ro>
Message-ID: <4346B69A.6000307@pdf.com>



Adrian DUSA wrote:
> Dear all,
> 
> In order to ease the transition from SPSS to R for some of my colleagues, I am 
> trying to create a function which would show the variables and their labels 
> (if those exist), using function "label" in package Hmisc.
> 
> A toy example would be this:
> 
> my.data <- data.frame(age=c(24,35,28), gender=c("Male", "Female", "Male"))
> require(Hmisc)
> label(my.data$age) <- "Respondent's age"
> label(my.data$gender) <- "Responent's gender"
> 
> variables <- function(x) {
>         dataf <- data.frame(variable=NA, label=NA)
>         varlab <- NA
>         for (i in 1:length(names(x))) {
>                 dataf[i,1] <- names(x)[i]
>                 dataf[i,2] <- label(x[,i])
>                 varlab[i] <- label(x[,i])
>         }
>         fix(dataf)
>         # I assume this would return a modified dataf
>         for (i in which(varlab != dataf[,2])) {
>                 label(x[,i]) <- dataf[i,2]
>         }
> }
> 
> Now, say during fix() one modified "Responent's gender" into "Respondent's 
> gender" (the previous missed a "d"). The trouble I'm having is to return the 
> modified object, with the modified labels. It should be easy, I feel it, but 
> I just can't get it.
> 
> Thank you in advance,
> Adrian
> 

Hi, Adrian,

You need to assign "fix(dataf)" to something:

my.data <- data.frame(age=c(24,35,28), gender=c("Male", "Female", "Male"))
require(Hmisc)
label(my.data$age) <- "Respondent's age"
label(my.data$gender) <- "Responent's gender"

variables <- function(x) {
   dataf <- data.frame(variable=NA, label=NA)
   varlab <- NA
   for (i in 1:length(names(x))) {
     dataf[i,1] <- names(x)[i]
     dataf[i,2] <- label(x[,i])
     varlab[i] <- label(x[,i])
   }
   dataf <- fix(dataf)
   # I assume this would return a modified dataf
   for (i in which(varlab != dataf[,2])) {
     label(x[,i]) <- dataf[i,2]
   }
   # don't forget to return dataf
   dataf
}

variables(my.data)

HTH,

--sundar



From afshart at exchange.sba.miami.edu  Fri Oct  7 20:03:09 2005
From: afshart at exchange.sba.miami.edu (Afshartous, David)
Date: Fri, 7 Oct 2005 14:03:09 -0400
Subject: [R] function agruments
Message-ID: <6BCB4D493A447546A8126F24332056E8F28BB2@school1.business.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051007/cb5c7cff/attachment.pl

From dusa.adrian at gmail.com  Fri Oct  7 19:12:17 2005
From: dusa.adrian at gmail.com (Adrian DUSA)
Date: Fri, 7 Oct 2005 20:12:17 +0300
Subject: [R] returning a modified fix()-ed dataframe
In-Reply-To: <4346B69A.6000307@pdf.com>
References: <200510071944.49134.adi@roda.ro> <4346B69A.6000307@pdf.com>
Message-ID: <200510072012.17652.adi@roda.ro>

On Friday 07 October 2005 20:55, Sundar Dorai-Raj wrote:
> Adrian DUSA wrote:
> > [...snip...]
>
> Hi, Adrian,
>
> You need to assign "fix(dataf)" to something:
>
> my.data <- data.frame(age=c(24,35,28), gender=c("Male", "Female", "Male"))
> require(Hmisc)
> label(my.data$age) <- "Respondent's age"
> label(my.data$gender) <- "Responent's gender"
>
> variables <- function(x) {
>    dataf <- data.frame(variable=NA, label=NA)
>    varlab <- NA
>    for (i in 1:length(names(x))) {
>      dataf[i,1] <- names(x)[i]
>      dataf[i,2] <- label(x[,i])
>      varlab[i] <- label(x[,i])
>    }
>    dataf <- fix(dataf)
>    # I assume this would return a modified dataf
>    for (i in which(varlab != dataf[,2])) {
>      label(x[,i]) <- dataf[i,2]
>    }
>    # don't forget to return dataf
>    dataf
> }
>
> variables(my.data)
>
> HTH,
>
> --sundar

Hi Sundar,

Hm... the new function correctly returns (and prints) dataf but I need to 
return my.data... 
I also thought about returning my.data, but if this would be a large 
dataframe, printing it wouldn't be so nice.
Basically, I would need to somehow silently return the input (modified) 
dataframe.

Also, I now have another related two questions:
1. is it possible to "edit" the contents of a cell when using fix() ? In order 
to change a letter one would have to change the whole string.
2. is it possible to change the width of a column?

Thank you,
Adrian

-- 
Adrian DUSA
Romanian Social Data Archive
1, Schitu Magureanu Bd
050025 Bucharest sector 5
Romania
Tel./Fax: +40 21 3126618 \
          +40 21 3120210 / int.101



From sundar.dorai-raj at pdf.com  Fri Oct  7 20:22:22 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Fri, 07 Oct 2005 13:22:22 -0500
Subject: [R] returning a modified fix()-ed dataframe
In-Reply-To: <200510072012.17652.adi@roda.ro>
References: <200510071944.49134.adi@roda.ro> <4346B69A.6000307@pdf.com>
	<200510072012.17652.adi@roda.ro>
Message-ID: <4346BCDE.9010904@pdf.com>



Adrian DUSA wrote:
> On Friday 07 October 2005 20:55, Sundar Dorai-Raj wrote:
> 
>>Adrian DUSA wrote:
>>
>>>[...snip...]
>>
>>Hi, Adrian,
>>
>>You need to assign "fix(dataf)" to something:
>>
>>my.data <- data.frame(age=c(24,35,28), gender=c("Male", "Female", "Male"))
>>require(Hmisc)
>>label(my.data$age) <- "Respondent's age"
>>label(my.data$gender) <- "Responent's gender"
>>
>>variables <- function(x) {
>>   dataf <- data.frame(variable=NA, label=NA)
>>   varlab <- NA
>>   for (i in 1:length(names(x))) {
>>     dataf[i,1] <- names(x)[i]
>>     dataf[i,2] <- label(x[,i])
>>     varlab[i] <- label(x[,i])
>>   }
>>   dataf <- fix(dataf)
>>   # I assume this would return a modified dataf
>>   for (i in which(varlab != dataf[,2])) {
>>     label(x[,i]) <- dataf[i,2]
>>   }
>>   # don't forget to return dataf
>>   dataf
>>}
>>
>>variables(my.data)
>>
>>HTH,
>>
>>--sundar
> 
> 
> Hi Sundar,
> 
> Hm... the new function correctly returns (and prints) dataf but I need to 
> return my.data... 
> I also thought about returning my.data, but if this would be a large 
> dataframe, printing it wouldn't be so nice.
> Basically, I would need to somehow silently return the input (modified) 
> dataframe.
> 

Then assign the return of "variables" back to my.data.

my.data <- variables(my.data)

My guess is you want to have your function fix my.data without having to 
reassign it. The answer to that question is most likely a road you do 
not want to travel. Otherwise, try searching the archives for "assign 
reference" for some clues.

> Also, I now have another related two questions:
> 1. is it possible to "edit" the contents of a cell when using fix() ? In order 
> to change a letter one would have to change the whole string.

Double-click on the field.

> 2. is it possible to change the width of a column?
> 

Right-click on the column then select auto-size column. Or left-click on 
a column line and drag to desired width.

View the Help from right-clicking for other options.

> Thank you,
> Adrian
> 

Your welcome,

--sundar



From 2bingho at stanford.edu  Fri Oct  7 20:29:58 2005
From: 2bingho at stanford.edu (Bing Ho)
Date: Fri,  7 Oct 2005 11:29:58 -0700
Subject: [R] (no subject)
Message-ID: <1128709798.4346bea68518a@webmail.stanford.edu>



Hello,

I noticed that the README found in /bin/windows/contrib/ATLAS indicates that
the ATLAS version is 3.4.1. According to the ATLAS sourceforge site, 3.6.0
the latest stable version.

Does anybody know if the ATLAS Rblas.dll are 3.4.1 or 3.6.0, and if they are
not the latest version, is there a technical reason why they have not been
updated?

Thank you,
Bing Ho



From dusa.adrian at gmail.com  Fri Oct  7 19:32:13 2005
From: dusa.adrian at gmail.com (Adrian DUSA)
Date: Fri, 7 Oct 2005 20:32:13 +0300
Subject: [R] returning a modified fix()-ed dataframe
In-Reply-To: <4346BCDE.9010904@pdf.com>
References: <200510071944.49134.adi@roda.ro> <200510072012.17652.adi@roda.ro>
	<4346BCDE.9010904@pdf.com>
Message-ID: <200510072032.13397.adi@roda.ro>

On Friday 07 October 2005 21:22, Sundar Dorai-Raj wrote:
> [...snip...]
>
> My guess is you want to have your function fix my.data without having to
> reassign it. The answer to that question is most likely a road you do
> not want to travel. Otherwise, try searching the archives for "assign
> reference" for some clues.

Unfortunately, this is the road I was looking for :)
I'll have a look on the archives on that, thanks for the tip.


> > Also, I now have another related two questions:
> > 1. is it possible to "edit" the contents of a cell when using fix() ? In
> > order to change a letter one would have to change the whole string.
>
> Double-click on the field.
>
> > 2. is it possible to change the width of a column?
>
> Right-click on the column then select auto-size column. Or left-click on
> a column line and drag to desired width.

Oh, silly me. I knew this works under Windows, but I should have specified I 
run R under Linux (Kubuntu 5.04, KDE). And I also knew that the Linux 
interface is not as developed as the Windows one, so it's probably not 
possible yet.

Thanks for everything,
Adrian

-- 
Adrian DUSA
Romanian Social Data Archive
1, Schitu Magureanu Bd
050025 Bucharest sector 5
Romania
Tel./Fax: +40 21 3126618 \
          +40 21 3120210 / int.101



From gunter.berton at gene.com  Fri Oct  7 20:37:36 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Fri, 7 Oct 2005 11:37:36 -0700
Subject: [R] function agruments
In-Reply-To: <6BCB4D493A447546A8126F24332056E8F28BB2@school1.business.edu>
Message-ID: <200510071837.j97IbblO019831@faraday.gene.com>

It's trivial -- and many R functions do this. ?outer,?sapply for example.

Once can also return a function. ?approxfun for example

Trivial example that shows how to use ... to pass in extra arguments to fun

chooseFun<-function(dat=1:10,fun=mean,...)fun(dat,...)
chooseFun()
x<-rnorm(100)
chooseFun(x,median)
chooseFun(x,hist)
chooseFun(x,hist,col='gray')

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Afshartous, David
> Sent: Friday, October 07, 2005 11:03 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] function agruments
> 
> All,
> 
> When defining the arguments of a function, is it possible to 
> supply a function as 
> an argument?  If so, how is this introduced into the function 
> code as well?
> 
> For example, in the body of the function I have:
> 
> 	result = function(x)
> 
> and I'd like to supply either function.1 or function.2.
> 
> Please reply directly to afshar at miami.edu
> 
> Thanks!
> Dave
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From tim_smith_666 at yahoo.com  Fri Oct  7 20:48:06 2005
From: tim_smith_666 at yahoo.com (Tim Smith)
Date: Fri, 7 Oct 2005 11:48:06 -0700 (PDT)
Subject: [R] Applying a function to each element of an array
Message-ID: <20051007184806.22225.qmail@web35002.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051007/507f9db3/attachment.pl

From h.wickham at gmail.com  Fri Oct  7 21:11:04 2005
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 7 Oct 2005 14:11:04 -0500
Subject: [R] The R Graph Gallery {was boxplot statistics}
In-Reply-To: <CA0BCF3BED56294AB91E3AD74B849FD503FD3740@us-arlington-0668.mail.saic.com>
References: <CA0BCF3BED56294AB91E3AD74B849FD503FD3740@us-arlington-0668.mail.saic.com>
Message-ID: <f8e6ff050510071211w2e05c632xa6a6819dfaeefca1@mail.gmail.com>

> I also think there should be a on CRAN website a list of "R websites". And
> in a perfect world one of the search engines scope would get extended to
> search them all.

It's quite possible to set up your own: have a look at http://rollyo.com/

Hadley



From JAROSLAW.W.TUSZYNSKI at saic.com  Fri Oct  7 21:17:46 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Fri, 7 Oct 2005 15:17:46 -0400 
Subject: [R] Applying a function to each element of an array
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD504095AB1@us-arlington-0668.mail.saic.com>

I suspect that loop would be the fastest since it would have the least
memory overhead. You do not want to have too many internal copies of
7000x7000 matrices.

 Jarek 
====================================================\==== 
 Jarek Tuszynski, PhD.                           o / \ 
 Science Applications International Corporation  <\__,|  
 (703) 676-4192                                   ">  \ 
 Jaroslaw.W.Tuszynski at saic.com                     `   \ 

 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Tim Smith
Sent: Friday, October 07, 2005 2:48 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Applying a function to each element of an array

Hi,
 
I have a 7000x7000 matrix, and each element is an integer. For each element,
I want to apply the function :
 
wt <- 0
 for(q in 1:count){
 wt <- wt + 0.5^(q-1)
}
 
I get the value of 'count' from the elements in the matrix , and want to
store the corresponding 'wt' value for that element.
 
I suppose I could loop through the matrix, and apply the function to each
element but this would take a really really long time. Are there any quicker
ways to get the same result?
 
many thanks,
 
Tim

		
---------------------------------


	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From gunter.berton at gene.com  Fri Oct  7 21:21:01 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Fri, 7 Oct 2005 12:21:01 -0700
Subject: [R] Applying a function to each element of an array
In-Reply-To: <20051007184806.22225.qmail@web35002.mail.mud.yahoo.com>
Message-ID: <200510071921.j97JL2VX019132@compton.gene.com>

Well, since Sum(i=1 to i-n) =n*(n+1)/2, your loop simply gives
1/4*count*(count-1).
So if your matrix is A, A*(A-1)/4 is about the quickest way to get your
answer I think.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Tim Smith
> Sent: Friday, October 07, 2005 11:48 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Applying a function to each element of an array
> 
> Hi,
>  
> I have a 7000x7000 matrix, and each element is an integer. 
> For each element, I want to apply the function :
>  
> wt <- 0
>  for(q in 1:count){
>  wt <- wt + 0.5^(q-1)
> }
>  
> I get the value of 'count' from the elements in the matrix , 
> and want to store the corresponding 'wt' value for that element.
>  
> I suppose I could loop through the matrix, and apply the 
> function to each element but this would take a really really 
> long time. Are there any quicker ways to get the same result?
>  
> many thanks,
>  
> Tim
> 
> 		
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From Seeliger.Curt at epamail.epa.gov  Fri Oct  7 21:17:57 2005
From: Seeliger.Curt at epamail.epa.gov (Seeliger.Curt@epamail.epa.gov)
Date: Fri, 07 Oct 2005 12:17:57 -0700
Subject: [R] Assign references
Message-ID: <OFB06B73E6.1C271C52-ON88257093.0068486B-88257093.006A046D@epamail.epa.gov>

Folks,

I've run into trouble while writing functions that I hope will create
and modify a dataframe or two.  To that end I've written a toy function
that simply sets a couple of variables (well, tries but fails).
Searching the archives, Thomas Lumley recently explained the <<-
operator, showing that it was necessary for x and y to exist prior to
the function call, but I haven't the faintest why this isn't working:

> myFunk<-function(a,b,foo,bar) {foo<<-a+b; bar<<-a*b;}
> x<-0; y<-0;
> myFunk(4,5,x,y)
> x<-0; y<-0;
> myFunk(4,5,x,y)
> x
[1] 0
> y
[1] 0

What (no doubt simple) reason is there for x and y not changing?

Thank you,
cur
--
Curt Seeliger, Data Ranger
CSC, EPA/WED contractor
541/754-4638
seeliger.curt at epa.gov



From ripley at stats.ox.ac.uk  Fri Oct  7 21:28:17 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 Oct 2005 20:28:17 +0100 (BST)
Subject: [R] Applying a function to each element of an array
In-Reply-To: <20051007184806.22225.qmail@web35002.mail.mud.yahoo.com>
References: <20051007184806.22225.qmail@web35002.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.61.0510072020020.5853@gannet.stats>

If A is the matrix the answer is 2*(1 - 2^(-A)), which took about 10secs 
for an example of your size.

>From \sum_{i=1}^n x^{1-i} = (1-x^{-n})/(1-x), E & OE.

On Fri, 7 Oct 2005, Tim Smith wrote:

> I have a 7000x7000 matrix, and each element is an integer. For each 
> element, I want to apply the function :
>
> wt <- 0
> for(q in 1:count){
> wt <- wt + 0.5^(q-1)
> }
>
> I get the value of 'count' from the elements in the matrix , and want to 
> store the corresponding 'wt' value for that element.
>
> I suppose I could loop through the matrix, and apply the function to 
> each element but this would take a really really long time. Are there 
> any quicker ways to get the same result?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Oct  7 21:42:17 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 Oct 2005 20:42:17 +0100 (BST)
Subject: [R] Applying a function to each element of an array
In-Reply-To: <Pine.LNX.4.61.0510072020020.5853@gannet.stats>
References: <20051007184806.22225.qmail@web35002.mail.mud.yahoo.com>
	<Pine.LNX.4.61.0510072020020.5853@gannet.stats>
Message-ID: <Pine.LNX.4.61.0510072035570.5853@gannet.stats>

On Fri, 7 Oct 2005, Prof Brian Ripley wrote:

> If A is the matrix the answer is 2*(1 - 2^(-A)), which took about 10secs
> for an example of your size.
>
>> From \sum_{i=1}^n x^{1-i} = (1-x^{-n})/(1-x), E & OE.

NB: I have assumed n >= 1 here, as people nornally do when using 1:count.


> On Fri, 7 Oct 2005, Tim Smith wrote:
>
>> I have a 7000x7000 matrix, and each element is an integer. For each
>> element, I want to apply the function :
>>
>> wt <- 0
>> for(q in 1:count){
>> wt <- wt + 0.5^(q-1)
>> }
>>
>> I get the value of 'count' from the elements in the matrix , and want to
>> store the corresponding 'wt' value for that element.
>>
>> I suppose I could loop through the matrix, and apply the function to
>> each element but this would take a really really long time. Are there
>> any quicker ways to get the same result?
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gunter.berton at gene.com  Fri Oct  7 22:12:42 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Fri, 7 Oct 2005 13:12:42 -0700
Subject: [R] Applying a function to each element of an array
In-Reply-To: <Pine.LNX.4.61.0510072034450.5853@gannet.stats>
Message-ID: <200510072012.j97KCgHs026098@faraday.gene.com>

Oops -- quite right, Brian. Interesting, as I stared at it for some time.

Sigh... now what **WAS** I looking for in the refrigerator?

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
 

> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
> Sent: Friday, October 07, 2005 12:36 PM
> To: Berton Gunter
> Cc: 'Tim Smith'
> Subject: Re: [R] Applying a function to each element of an array
> 
> On Fri, 7 Oct 2005, Berton Gunter wrote:
> 
> > Well, since Sum(i=1 to i-n) =n*(n+1)/2, your loop simply gives
> > 1/4*count*(count-1).
> > So if your matrix is A, A*(A-1)/4 is about the quickest way 
> to get your
> > answer I think.
> 
> I think Bert has read ^ as *.
> 
> >
> > -- Bert Gunter
> > Genentech Non-Clinical Statistics
> > South San Francisco, CA
> >
> > "The business of the statistician is to catalyze the 
> scientific learning
> > process."  - George E. P. Box
> >
> >
> >
> >> -----Original Message-----
> >> From: r-help-bounces at stat.math.ethz.ch
> >> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Tim Smith
> >> Sent: Friday, October 07, 2005 11:48 AM
> >> To: r-help at stat.math.ethz.ch
> >> Subject: [R] Applying a function to each element of an array
> >>
> >> Hi,
> >>
> >> I have a 7000x7000 matrix, and each element is an integer.
> >> For each element, I want to apply the function :
> >>
> >> wt <- 0
> >>  for(q in 1:count){
> >>  wt <- wt + 0.5^(q-1)
> >> }
> >>
> >> I get the value of 'count' from the elements in the matrix ,
> >> and want to store the corresponding 'wt' value for that element.
> >>
> >> I suppose I could loop through the matrix, and apply the
> >> function to each element but this would take a really really
> >> long time. Are there any quicker ways to get the same result?
> >>
> >> many thanks,
> >>
> >> Tim
> >>
> >>
> >> ---------------------------------
> >>
> >>
> >> 	[[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide!
> >> http://www.R-project.org/posting-guide.html
> >>
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From pmuhl830 at gmail.com  Fri Oct  7 22:28:42 2005
From: pmuhl830 at gmail.com (Peter Muhlberger)
Date: Fri, 07 Oct 2005 16:28:42 -0400
Subject: [R] Matrix calculations in R--erroneous?
In-Reply-To: <Pine.LNX.4.63a.0510071010050.7832@homer21.u.washington.edu>
Message-ID: <BF6C52BA.11E3B%pmuhl830@gmail.com>

Hi Thomas:  Thanks!  Yes, the function
(yMat2[5,9]-yMat1[5,9]*logitShape()[5,9]) appears to be producing a value of
-1.102216e-16 rather than 0.  I would have thought it would approach 0 from
above given that all input values are at or above zero, but evidently not.

The max function won't do the trick because I need the entire matrix.  I
could do one cell at a time, but this is part of a ML routine that needs to
be evaluated hundreds of thousands of times, so I can't afford to slow it
down that much.

I guess I can add 1e-15 rather than e-323, but wonder what that might end up
doing to my estimates.  Guess I'll find out.

Cheers,  Peter

On 10/7/05 1:12 PM, "Thomas Lumley" <tlumley at u.washington.edu> wrote:

> On Fri, 7 Oct 2005, Peter Muhlberger wrote:
> 
>> Does anyone know how -log(x) can equal 743 but -log(x+0)=Inf?  That's what
>> the following stream of calculations suggest:
>> 
>> Browse[2]> -log (   1e-323+yMat2 - yMat1 * logitShape(matrix(parsList$Xs,
>> nrow = numXs, ncol=numOfCurves), matrix(means, nrow = numXs,
>> ncol=numOfCurves, byrow=TRUE), matrix(sigmas, nrow = numXs,
>> ncol=numOfCurves, byrow=TRUE))   )[5,9]
>> [1] Inf
>> 
>> Yet:
>> 
>> Browse[2]> logitShape(matrix(parsList$Xs, nrow = numXs, ncol=numOfCurves),
>> matrix(means, nrow = numXs, ncol=numOfCurves, byrow=TRUE), matrix(sigmas,
>> nrow = numXs, ncol=numOfCurves, byrow=TRUE))[5,9]
>> [1] 1
>> 
>> So, the logitShape component equals 1.
> 
> to within 2e-16
> 
>> Browse[2]> yMat1[5,9]
>> [1] 1
>> 
>> So yMat1[5,9]*logitShape()[5,9]=1
> 
> to within 2e-16
> 
>> Browse[2]> yMat2[5,9]
>> [1] 1
> 
> to within 2e-16
> 
>> So, yMat2[5,9]-yMat1[5,9]*logitShape()[5,9]=0
> 
> to within a few parts in 10^16
> 
> You haven't actually shown us yMat2[5,9]-yMat1[5,9]*logitShape()[5,9],
> though
> 
>> Browse[2]> -log (   1e-323)
>> [1] 743.7469
>> 
>> So, -log( 1e-323)=743 while -log( 1e-323+0)=Inf ?
>> 
> 
> If "0" is really of the order of 1e-16 then this isn't surprising. If the
> only point of 1e-323 is as a guard value for 0 then use max(1e-323,
> yMat2[5,9]-yMat1[5,9]*logitShape()[5,9])
> 
> 
> -thomas
> 
>



From pburns at pburns.seanet.com  Fri Oct  7 22:29:13 2005
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Fri, 07 Oct 2005 21:29:13 +0100
Subject: [R] Applying a function to each element of an array
In-Reply-To: <20051007184806.22225.qmail@web35002.mail.mud.yahoo.com>
References: <20051007184806.22225.qmail@web35002.mail.mud.yahoo.com>
Message-ID: <4346DA99.1080000@pburns.seanet.com>

If there weren't an analytic solution to your problem,
then you could build a vector of the answers from 1
to the maximum in the matrix.  Call that 'wtvec'.  Then:

ans <- array(NA, dim(A), dimnames(A))
ans[] <- wtvec[as.vector(A)]

should get you what you want.


Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Tim Smith wrote:

>Hi,
> 
>I have a 7000x7000 matrix, and each element is an integer. For each element, I want to apply the function :
> 
>wt <- 0
> for(q in 1:count){
> wt <- wt + 0.5^(q-1)
>}
> 
>I get the value of 'count' from the elements in the matrix , and want to store the corresponding 'wt' value for that element.
> 
>I suppose I could loop through the matrix, and apply the function to each element but this would take a really really long time. Are there any quicker ways to get the same result?
> 
>many thanks,
> 
>Tim
>
>		
>---------------------------------
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>



From ripley at stats.ox.ac.uk  Fri Oct  7 22:45:40 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 Oct 2005 21:45:40 +0100 (BST)
Subject: [R] Applying a function to each element of an array
In-Reply-To: <4346DA99.1080000@pburns.seanet.com>
References: <20051007184806.22225.qmail@web35002.mail.mud.yahoo.com>
	<4346DA99.1080000@pburns.seanet.com>
Message-ID: <Pine.LNX.4.61.0510072142330.12785@gannet.stats>

On Fri, 7 Oct 2005, Patrick Burns wrote:

> If there weren't an analytic solution to your problem,
> then you could build a vector of the answers from 1
> to the maximum in the matrix.  Call that 'wtvec'.  Then:
>
> ans <- array(NA, dim(A), dimnames(A))
> ans[] <- wtvec[as.vector(A)]
>
> should get you what you want.

Well, we don't actually know 'count' is >= 1.  I almost suggested this, 
but suppose the counts were in billions?

It's a good solution for a small set of continguous values.  If there is a 
small set of values, do a two-step lookup using e.g. match to find the 
enumeration of the values.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jlmcgarv at sfu.ca  Fri Oct  7 23:04:05 2005
From: jlmcgarv at sfu.ca (jlmcgarv@sfu.ca)
Date: Fri, 07 Oct 2005 14:04:05 -0700
Subject: [R] cor() function, method="spearman"
Message-ID: <200510072104.j97L45oi004028@rm-rstar.sfu.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051007/0ed458f6/attachment.pl

From rvaradha at jhsph.edu  Fri Oct  7 23:05:06 2005
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Fri, 7 Oct 2005 17:05:06 -0400
Subject: [R] Applying a function to each element of an array
In-Reply-To: <4346DA99.1080000@pburns.seanet.com>
Message-ID: <OWA-2NGDQ6on7gz3FB100016f78@owa-2.sph.ad.jhsph.edu>

The sum in the loop is simply:  2 - (0.5)^count.  

So you don't need this loop.  As "count" gets large, the sum approaches 2.

Ravi.

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-
> bounces at stat.math.ethz.ch] On Behalf Of Patrick Burns
> Sent: Friday, October 07, 2005 4:29 PM
> To: Tim Smith
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Applying a function to each element of an array
> 
> If there weren't an analytic solution to your problem,
> then you could build a vector of the answers from 1
> to the maximum in the matrix.  Call that 'wtvec'.  Then:
> 
> ans <- array(NA, dim(A), dimnames(A))
> ans[] <- wtvec[as.vector(A)]
> 
> should get you what you want.
> 
> 
> Patrick Burns
> patrick at burns-stat.com
> +44 (0)20 8525 0696
> http://www.burns-stat.com
> (home of S Poetry and "A Guide for the Unwilling S User")
> 
> Tim Smith wrote:
> 
> >Hi,
> >
> >I have a 7000x7000 matrix, and each element is an integer. For each
> element, I want to apply the function :
> >
> >wt <- 0
> > for(q in 1:count){
> > wt <- wt + 0.5^(q-1)
> >}
> >
> >I get the value of 'count' from the elements in the matrix , and want to
> store the corresponding 'wt' value for that element.
> >
> >I suppose I could loop through the matrix, and apply the function to each
> element but this would take a really really long time. Are there any
> quicker ways to get the same result?
> >
> >many thanks,
> >
> >Tim
> >
> >
> >---------------------------------
> >
> >
> >	[[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! http://www.R-project.org/posting-
> guide.html
> >
> >
> >
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-
> guide.html



From spencer.graves at pdf.com  Fri Oct  7 23:55:59 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 07 Oct 2005 14:55:59 -0700
Subject: [R] Matrix calculations in R--erroneous?
In-Reply-To: <BF6C52BA.11E3B%pmuhl830@gmail.com>
References: <BF6C52BA.11E3B%pmuhl830@gmail.com>
Message-ID: <4346EEEF.7090705@pdf.com>

	  Rather than adding 1e-15 to all numbers, I suggest you simply make 
that the floor.  (Or use .Machine$double.eps or 2*.Machine$double.eps in 
place of 1e-15.)

	  Another alternative that may or may not apply in your case is to 
develop an asymptotic expansion for the log(likelihood) for the small 
numbers.  I've had good success with this kind of method.  For example, 
consider the Box-Cox transformation:

	  bc(y, b) = (y^b-1)/b

	  What do we do with b = 0?  We can test for b = 0 and replace those 
cases by the limit log(y).  However, it is numerically more stable to 
use the following:

	  bc(y, b) = ifelse(abs(b*log(y))>.Machine$double.eps, 
(expm1(b*log(y))/b, log(y)).

	  I don't have time to study your example to see if I could see 
anything like this that could be done, but I think there should be a 
good chance of finding something like this.  Of course, if there are 
only very few 0's, then it hardly matters.  However, if there are quite 
a few, then you need something like this.

	  hope this helps.
	  spencer graves

Peter Muhlberger wrote:

> Hi Thomas:  Thanks!  Yes, the function
> (yMat2[5,9]-yMat1[5,9]*logitShape()[5,9]) appears to be producing a value of
> -1.102216e-16 rather than 0.  I would have thought it would approach 0 from
> above given that all input values are at or above zero, but evidently not.
> 
> The max function won't do the trick because I need the entire matrix.  I
> could do one cell at a time, but this is part of a ML routine that needs to
> be evaluated hundreds of thousands of times, so I can't afford to slow it
> down that much.
> 
> I guess I can add 1e-15 rather than e-323, but wonder what that might end up
> doing to my estimates.  Guess I'll find out.
> 
> Cheers,  Peter
> 
> On 10/7/05 1:12 PM, "Thomas Lumley" <tlumley at u.washington.edu> wrote:
> 
> 
>>On Fri, 7 Oct 2005, Peter Muhlberger wrote:
>>
>>
>>>Does anyone know how -log(x) can equal 743 but -log(x+0)=Inf?  That's what
>>>the following stream of calculations suggest:
>>>
>>>Browse[2]> -log (   1e-323+yMat2 - yMat1 * logitShape(matrix(parsList$Xs,
>>>nrow = numXs, ncol=numOfCurves), matrix(means, nrow = numXs,
>>>ncol=numOfCurves, byrow=TRUE), matrix(sigmas, nrow = numXs,
>>>ncol=numOfCurves, byrow=TRUE))   )[5,9]
>>>[1] Inf
>>>
>>>Yet:
>>>
>>>Browse[2]> logitShape(matrix(parsList$Xs, nrow = numXs, ncol=numOfCurves),
>>>matrix(means, nrow = numXs, ncol=numOfCurves, byrow=TRUE), matrix(sigmas,
>>>nrow = numXs, ncol=numOfCurves, byrow=TRUE))[5,9]
>>>[1] 1
>>>
>>>So, the logitShape component equals 1.
>>
>>to within 2e-16
>>
>>
>>>Browse[2]> yMat1[5,9]
>>>[1] 1
>>>
>>>So yMat1[5,9]*logitShape()[5,9]=1
>>
>>to within 2e-16
>>
>>
>>>Browse[2]> yMat2[5,9]
>>>[1] 1
>>
>>to within 2e-16
>>
>>
>>>So, yMat2[5,9]-yMat1[5,9]*logitShape()[5,9]=0
>>
>>to within a few parts in 10^16
>>
>>You haven't actually shown us yMat2[5,9]-yMat1[5,9]*logitShape()[5,9],
>>though
>>
>>
>>>Browse[2]> -log (   1e-323)
>>>[1] 743.7469
>>>
>>>So, -log( 1e-323)=743 while -log( 1e-323+0)=Inf ?
>>>
>>
>>If "0" is really of the order of 1e-16 then this isn't surprising. If the
>>only point of 1e-323 is as a guard value for 0 then use max(1e-323,
>>yMat2[5,9]-yMat1[5,9]*logitShape()[5,9])
>>
>>
>>-thomas
>>
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From dhiren22 at hotmail.com  Sat Oct  8 00:01:41 2005
From: dhiren22 at hotmail.com (Dhiren DSouza)
Date: Fri, 07 Oct 2005 18:01:41 -0400
Subject: [R]  matrix operation
Message-ID: <BAY102-F28F62969DBE260059CB484D3840@phx.gbl>

Hello:

I have a matrix 'dat' with 2 columns.

I have the following code:

for (i in 1:nrows(dat))
{
  if (dat[i,1] < dat[i,2])
    {
      dat[i,2]<-0
    }

   else
   {
     dat[i,2]<-1
   }


Is there a way to accomplish this without the for loop?

Thank you.

-Dhiren



From Walter.Leite at coe.ufl.edu  Sat Oct  8 00:18:45 2005
From: Walter.Leite at coe.ufl.edu (Leite,Walter)
Date: Fri, 7 Oct 2005 18:18:45 -0400
Subject: [R] question about ways to solve nonlinear system
Message-ID: <FCCB21C198A64341A78B24E06AE7C8D3031B2E9E@coe-exchange01.ad.ufl.edu>

Dear R users


I am trying to write an R function to solve for a,b,c in the following
system of equations, given any value of x1, x2 and x3:
b^2 + 6*b*a + 2*c^2 + 15*a^2 = x1
2*c*(b^2 + 24*b*a + 105*a^2 + 2) = x2
24*(b*a + c^2*(1 + b^2 + 28*b*a) + a*(12 + 48 *b*a + 141*c^2 + 225*a^2))
=x3

Could you give me suggestions about which R function(s) I can use to
solve this problem and how I should use these functions? 
Thank you very much for your assistance,

Walter Leite



From Achim.Zeileis at wu-wien.ac.at  Sat Oct  8 00:17:52 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Sat, 8 Oct 2005 00:17:52 +0200
Subject: [R] matrix operation
In-Reply-To: <BAY102-F28F62969DBE260059CB484D3840@phx.gbl>
References: <BAY102-F28F62969DBE260059CB484D3840@phx.gbl>
Message-ID: <20051008001752.02bae3c6.Achim.Zeileis@wu-wien.ac.at>

On Fri, 07 Oct 2005 18:01:41 -0400 Dhiren DSouza wrote:

> Hello:
> 
> I have a matrix 'dat' with 2 columns.
> 
> I have the following code:
> 
> for (i in 1:nrows(dat))
> {
>   if (dat[i,1] < dat[i,2])
>     {
>       dat[i,2]<-0
>     }
> 
>    else
>    {
>      dat[i,2]<-1
>    }
> 
> Is there a way to accomplish this without the for loop?

For this setting
  dat[,2] <- as.numeric(dat[,1] >= dat[,2])
seems to work.

For more complicated tasks look at ifelse().

hth,
Z


> Thank you.
> 
> -Dhiren
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From tplate at acm.org  Sat Oct  8 00:35:59 2005
From: tplate at acm.org (Tony Plate)
Date: Fri, 07 Oct 2005 16:35:59 -0600
Subject: [R] Assign references
In-Reply-To: <OFB06B73E6.1C271C52-ON88257093.0068486B-88257093.006A046D@epamail.epa.gov>
References: <OFB06B73E6.1C271C52-ON88257093.0068486B-88257093.006A046D@epamail.epa.gov>
Message-ID: <4346F84F.4020902@acm.org>

Looking at what objects exist after the call to myFunk() should give you 
a clue as to what happened:

 > remove(list=objects())
 > myFunk<-function(a,b,foo,bar) {foo<<-a+b; bar<<-a*b;}
 > x<-0; y<-0;
 > myFunk(4,5,x,y)
 > x
[1] 0
 > y
[1] 0
 > objects()
[1] "bar"    "foo"    "myFunk" "x"      "y"
 > bar
[1] 20
 > foo
[1] 9
 >

I suspect that you might have slightly misinterpreted Thomas Lumely's 
explanations of how the <<- operator works in different situations (the 
LHS must exist if you are assigning using a replacement operator, e.g., 
as in "foo[1] <<- ...", but not when you are assigning the whole object 
as in "foo <<- ...").

But I really would suggest careful consideration of what might be the 
best way to approach your problem -- modifying global data from within a 
function is not the standard way of using R.  Unless you are very 
careful about how you do it, it is likely to cause headaches for 
yourself and/or others down the road (because R is just not intended to 
be used that way).

The standard way of doing this sort of thing in R is to modify a local 
copy of the dataframe and return that, or if you have to return several 
dataframes, then return a list of dataframes.

-- Tony Plate

Seeliger.Curt at epamail.epa.gov wrote:
> Folks,
> 
> I've run into trouble while writing functions that I hope will create
> and modify a dataframe or two.  To that end I've written a toy function
> that simply sets a couple of variables (well, tries but fails).
> Searching the archives, Thomas Lumley recently explained the <<-
> operator, showing that it was necessary for x and y to exist prior to
> the function call, but I haven't the faintest why this isn't working:
> 
> 
>>myFunk<-function(a,b,foo,bar) {foo<<-a+b; bar<<-a*b;}
>>x<-0; y<-0;
>>myFunk(4,5,x,y)
>>x<-0; y<-0;
>>myFunk(4,5,x,y)
>>x
> 
> [1] 0
> 
>>y
> 
> [1] 0
> 
> What (no doubt simple) reason is there for x and y not changing?
> 
> Thank you,
> cur
> --
> Curt Seeliger, Data Ranger
> CSC, EPA/WED contractor
> 541/754-4638
> seeliger.curt at epa.gov
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From itsme_410 at yahoo.com  Sat Oct  8 00:51:44 2005
From: itsme_410 at yahoo.com (Globe Trotter)
Date: Fri, 7 Oct 2005 15:51:44 -0700 (PDT)
Subject: [R] trouble installing AnalyzeFMRI package: please help
Message-ID: <20051007225144.80532.qmail@web54506.mail.yahoo.com>

Hi,

Tried to install AnalyzeFMRI on Linux (FC-4) and got the following:

> install.packages("AnalyzeFMRI")
trying URL
'http://rh-mirror.linux.iastate.edu/CRAN/src/contrib/AnalyzeFMRI_1.1-4.tar.gz'
Content type 'application/x-gzip' length 308066 bytes
opened URL
==================================================
downloaded 300Kb

* Installing *source* package 'AnalyzeFMRI' ...
checking for gcc... gcc
checking for C compiler default output file name... configure: error: C
compiler cannot create executables
See `config.log' for more details.
ERROR: configuration failed for package 'AnalyzeFMRI'

The downloaded packages are in
        /tmp/Rtmpo14023/downloaded_packages
Warning message:
installation of package 'AnalyzeFMRI' had non-zero exit status in:
install.packages("AnalyzeFMRI") 

Can someone please help?

Many thanks and best wishes!



From gunter.berton at gene.com  Sat Oct  8 01:15:41 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Fri, 7 Oct 2005 16:15:41 -0700
Subject: [R] trouble installing AnalyzeFMRI package: please help
In-Reply-To: <20051007225144.80532.qmail@web54506.mail.yahoo.com>
Message-ID: <200510072315.j97NFgCv014658@meitner.gene.com>

Standard answers:

1) Is your version of R up to date?
2) Is the package version up to date?
3) Contact the package maintainer.

BTW, I believe that list etiquette is to provide your real name.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Globe Trotter
> Sent: Friday, October 07, 2005 3:52 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] trouble installing AnalyzeFMRI package: please help
> 
> Hi,
> 
> Tried to install AnalyzeFMRI on Linux (FC-4) and got the following:
> 
> > install.packages("AnalyzeFMRI")
> trying URL
> 'http://rh-mirror.linux.iastate.edu/CRAN/src/contrib/AnalyzeFM
> RI_1.1-4.tar.gz'
> Content type 'application/x-gzip' length 308066 bytes
> opened URL
> ==================================================
> downloaded 300Kb
> 
> * Installing *source* package 'AnalyzeFMRI' ...
> checking for gcc... gcc
> checking for C compiler default output file name... 
> configure: error: C
> compiler cannot create executables
> See `config.log' for more details.
> ERROR: configuration failed for package 'AnalyzeFMRI'
> 
> The downloaded packages are in
>         /tmp/Rtmpo14023/downloaded_packages
> Warning message:
> installation of package 'AnalyzeFMRI' had non-zero exit status in:
> install.packages("AnalyzeFMRI") 
> 
> Can someone please help?
> 
> Many thanks and best wishes!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From itsme_410 at yahoo.com  Sat Oct  8 01:39:10 2005
From: itsme_410 at yahoo.com (Globe Trotter)
Date: Fri, 7 Oct 2005 16:39:10 -0700 (PDT)
Subject: [R] trouble installing AnalyzeFMRI package: please help
In-Reply-To: <200510072315.j97NFgCv014658@meitner.gene.com>
Message-ID: <20051007233911.17119.qmail@web54515.mail.yahoo.com>

Hi,

Many thanks! I was able to install other packages so I will contact the package
maintainer if I can figure out who he is. Any clues?

I use this Yahoo! e-mail address as a junk e-mail address since the archives
contain the complete e-mail address (no anti-spam measures taken) so I do not
include my real name.

It would be nice if the R-archivers stripped e-mail addresses from posters (or
messed it up) so that spider programs would not be able to get it.

Many thanks and best wishes,
GT

--- Berton Gunter <gunter.berton at gene.com> wrote:

> Standard answers:
> 
> 1) Is your version of R up to date?
> 2) Is the package version up to date?
> 3) Contact the package maintainer.
> 
> BTW, I believe that list etiquette is to provide your real name.
> 
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
>  
> "The business of the statistician is to catalyze the scientific learning
> process."  - George E. P. Box
>  
>  
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Globe Trotter
> > Sent: Friday, October 07, 2005 3:52 PM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] trouble installing AnalyzeFMRI package: please help
> > 
> > Hi,
> > 
> > Tried to install AnalyzeFMRI on Linux (FC-4) and got the following:
> > 
> > > install.packages("AnalyzeFMRI")
> > trying URL
> > 'http://rh-mirror.linux.iastate.edu/CRAN/src/contrib/AnalyzeFM
> > RI_1.1-4.tar.gz'
> > Content type 'application/x-gzip' length 308066 bytes
> > opened URL
> > ==================================================
> > downloaded 300Kb
> > 
> > * Installing *source* package 'AnalyzeFMRI' ...
> > checking for gcc... gcc
> > checking for C compiler default output file name... 
> > configure: error: C
> > compiler cannot create executables
> > See `config.log' for more details.
> > ERROR: configuration failed for package 'AnalyzeFMRI'
> > 
> > The downloaded packages are in
> >         /tmp/Rtmpo14023/downloaded_packages
> > Warning message:
> > installation of package 'AnalyzeFMRI' had non-zero exit status in:
> > install.packages("AnalyzeFMRI") 
> > 
> > Can someone please help?
> > 
> > Many thanks and best wishes!
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> 
> 
>



From SinghJatinder at PRAIntl.com  Sat Oct  8 01:40:29 2005
From: SinghJatinder at PRAIntl.com (Singh, Jatinder)
Date: Fri, 7 Oct 2005 16:40:29 -0700
Subject: [R] Converting PROC NLMIXED code to NLME
Message-ID: <FDD0F83B87BB0A4CA4CC8919C1502BFC045E9351@vicexchange.prant.praintl.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051007/66674fbf/attachment.pl

From kjetil at redcotel.bo  Fri Oct  7 21:24:47 2005
From: kjetil at redcotel.bo (Kjetil Holuerson)
Date: Fri, 07 Oct 2005 15:24:47 -0400
Subject: [R] Applying a function to each element of an array
In-Reply-To: <20051007184806.22225.qmail@web35002.mail.mud.yahoo.com>
References: <20051007184806.22225.qmail@web35002.mail.mud.yahoo.com>
Message-ID: <4346CB7F.5090907@redcotel.bo>

Tim Smith wrote:
> Hi,
>  
> I have a 7000x7000 matrix, and each element is an integer. For each element, I want to apply the function :
>  
> wt <- 0
>  for(q in 1:count){
>  wt <- wt + 0.5^(q-1)
> }
>  

This is not a function!  Maybe you want

helper <- function(count) sum(0.5^((1:count)-1))

> I get the value of 'count' from the elements in the matrix , and want to store the corresponding 'wt' value for that element.
>  
> I suppose I could loop through the matrix, and apply the function to each element but this would take a really really long time. Are there any quicker ways to get the same result?
>  
> many thanks,

mapply(helper, yourmat)

gives you the elements of the matrix, as a vector. So you only must 
reassemble as a matrix:

n <- nrow(yourmat)
p <- ncol(yourmat)
matrix( mapply(helper, yourmat), n, p)

Kjetil

>  
> Tim
> 
> 		
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 



--



From p.dalgaard at biostat.ku.dk  Sat Oct  8 10:18:26 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 08 Oct 2005 10:18:26 +0200
Subject: [R] cor() function, method="spearman"
In-Reply-To: <200510072104.j97L45oi004028@rm-rstar.sfu.ca>
References: <200510072104.j97L45oi004028@rm-rstar.sfu.ca>
Message-ID: <x264s8mnfx.fsf@turmalin.kubism.ku.dk>

jlmcgarv at sfu.ca writes:

> Hello,
> 
> Does anyone know if the cor function, when method = "spearman", returns a correlation coefficient corrected for any ties in the ranks of the data?  I have data with quite a few ties and am thinking that I should use a calculation of the coefficient corrected for ties, but before I try and code this calculation myself, I thought I should check whether or not cor() automatically does this.
> 
> Thank you!
> Joanna McGarvie

The tie-corrected spearman correlation is the correlation of the
tie-corrected ranks, so yes, it does do that. 

Previous versions of R had an issue with p-values in cor.test, where
it used the exact distribution of the test for non-tied data, even
when ties were present. This was straightened out in 2.2.0, where it
now uses an asymptotic formula instead.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Sat Oct  8 10:29:21 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 08 Oct 2005 10:29:21 +0200
Subject: [R] Converting PROC NLMIXED code to NLME
In-Reply-To: <FDD0F83B87BB0A4CA4CC8919C1502BFC045E9351@vicexchange.prant.praintl.local>
References: <FDD0F83B87BB0A4CA4CC8919C1502BFC045E9351@vicexchange.prant.praintl.local>
Message-ID: <x21x2wmmxq.fsf@turmalin.kubism.ku.dk>

"Singh, Jatinder" <SinghJatinder at PRAIntl.com> writes:

> Hi,
> 
> I am trying to convert the following NLMIXED code to NLME, but am
> running into problems concerning 'Singularity in backsolve'. As I am new
> to R/S-Plus, I thought I may be missing something in the NLME code.

Which version of R and NLME? R 2.2.0 ships with a version where the
internal optimizer is changed to nlminb(). As I understand it, this
was in response to reports where code that worked in S-PLUS refused to
work in R.

 
> NLMIXED
> ***********
> proc nlmixed data=kidney.kidney;
> parms delta=0.03 gamma=1.1 b1=-0.003 b2=-1.2 b3=0.09 b4=0.35 b5=-1.43
> varu=0.5;
> eta=b1*age+b2*sex+b3*gn+b4*an+b5*pkn+u;
> hazard=eta+log(delta)+log(gamma)+(gamma-1)*log(rtime);
> survivor=(-exp(eta))*delta*(rtime**gamma);
> ll=(event*hazard)+survivor;
> model rtime ~ general(ll);
> random u~normal(0,varu) subject=patient out=frailty;
> run;
> 
> NLME
> ********
> kidney.nlme<-nlme(model=rtime~
> (event*
> ((b1*age+b2*sex+b3*gn+b4*an+b5*pkn+u)+log(delta)+log(gamma)+(gamma-1)*lo
> g(rtime))
> +((-exp(b1*age+b2*sex+b3*gn+b4*an+b5*pkn+u))*delta*(rtime**gamma))
> ),
> fixed=list(delta~1,gamma~1,b1~1,b2~1,b3~1,b4~1,b5~1),
> random=u~1|patient,
> start=c(delta=0.03,gamma=1.1,b1=-0.003,b2=-1.2,b3=0.09,b4=0.35,b5=-1.43)
> ,
> data=(kidney),
> method="ML",
> na.action=na.include
> )
> 
> Error in NLME
> *************
> > traceback()
> 11: eval(action, sys.parent())
> 10: doErrorAction("Problem in .C(\"fit_nlme\",: Singularity in
> backsolve", 1000)
> 9: .C("fit_nlme",
> 8: nlme(model = rtime ~ (event * ((b1 * age + b2 * sex + b3 * gn + b4 *
> an + b5 *
> 7: NULL
> 6: nlme.formula(model = rtime ~ (event * ((b1 * age + b2 * sex + b3 * gn
> + b4 *
> 5: eval(i, local)
> 4: source(auto.print = auto.print, exprs = substitute(exprs.literal))
> 3: script.run(exprs.literal = {
> 2: eval(expression(script.run(exprs.literal = {
> 1: 
> Message: Problem in .C("fit_nlme",: Singularity in backsolve 
> 
> I am actually trying to fit a parametric model to the kidney catheter
> data and compare NLMIXED with NLME. I am aware that COXPH and SURVREG
> are also available with a frailty element added in, but wanted to fit
> the likelihood model as above for a direct comparison.
> 
> Cheers,
> 
> Jindi
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From tura at centroin.com.br  Sat Oct  8 10:34:25 2005
From: tura at centroin.com.br (Bernardo Rangel Tura)
Date: Sat, 08 Oct 2005 05:34:25 -0300
Subject: [R] missing values in step procedure
Message-ID: <6.1.2.0.2.20051008053401.038e3ad0@centroin.com.br>

At 11:11 7/10/2005, you wrote:

>Hi,
>I have the problem that for the step procedure stops due to missing
>values. There are no options in Step or stepAIC to handle missing
>values. Is there any way to run stepwise modelselection in R in an
>automated way in this case?
>
>Here is the last step before it stops. Hope someone knows. Best regards,
>Andreas
>
>Step:  AIC= 1999.16
>  EF ~ SF120_KS + SF120_PS + HADA0 + SOZU0 + LVEDD + logPROBNP +
>     ALTER + SD0_01 + ASE_UK + DS140POS + RSQSICH0 + SD0_01:ASE_UK +
>     SD0_01:DS140POS + SD0_01:RSQSICH0 + ASE_UK:DS140POS +
>ASE_UK:RSQSICH0 +
>     DS140POS:RSQSICH0 + SD0_01:ASE_UK:RSQSICH0 +
>SD0_01:DS140POS:RSQSICH0 +
>     ASE_UK:DS140POS:RSQSICH0
>
>                            Df Sum of Sq     RSS     AIC
>- SOZU0                     1       3.0 25356.0  1997.2
>- HADA0                     1       7.6 25360.6  1997.3
>- ALTER                     1      13.0 25365.9  1997.4
>- SF120_PS                  1      14.7 25367.6  1997.5
>- ASE_UK:DS140POS:RSQSICH0  1      20.1 25373.1  1997.6
>- SD0_01:DS140POS:RSQSICH0  1      44.8 25397.7  1998.0
>- SD0_01:ASE_UK:RSQSICH0    1      54.4 25407.4  1998.2
><none>                                  25352.9  1999.2
>- LVEDD                     1     382.2 25735.1  2004.6
>- SF120_KS                  1     476.4 25829.3  2006.4
>- logPROBNP                 1     891.9 26244.9  2014.4
>Error in step(mod2, direction = "back") :
>         number of rows in use has changed: remove missing values?

Andreas

Try

data<-na.omit(original database) before you run step() or stepAIC()




Bernardo Rangel Tura, MD, MSc
National Institute of Cardiology Laranjeiras
Rio de Janeiro Brazil  


--



From tura at centroin.com.br  Sat Oct  8 10:57:52 2005
From: tura at centroin.com.br (Bernardo Rangel Tura)
Date: Sat, 08 Oct 2005 05:57:52 -0300
Subject: [R] Converting PROC NLMIXED code to NLME
In-Reply-To: <FDD0F83B87BB0A4CA4CC8919C1502BFC045E9351@vicexchange.prant
	.praintl.local>
References: <FDD0F83B87BB0A4CA4CC8919C1502BFC045E9351@vicexchange.prant.praintl.local>
Message-ID: <6.1.2.0.2.20051008055138.038436a0@centroin.com.br>

At 20:40 7/10/2005, Singh, Jatinder wrote:
>NLME
>********
>kidney.nlme<-nlme(model=rtime~
>(event*
>((b1*age+b2*sex+b3*gn+b4*an+b5*pkn+u)+log(delta)+log(gamma)+(gamma-1)*lo
>g(rtime))
>+((-exp(b1*age+b2*sex+b3*gn+b4*an+b5*pkn+u))*delta*(rtime**gamma))
>),
>fixed=list(delta~1,gamma~1,b1~1,b2~1,b3~1,b4~1,b5~1),
>random=u~1|patient,
>start=c(delta=0.03,gamma=1.1,b1=-0.003,b2=-1.2,b3=0.09,b4=0.35,b5=-1.43)
>,
>data=(kidney),
>method="ML",
>na.action=na.include
>)

Hi!

Try change "na.action=na.include" for "na.action=na.omit"

The singularity occurs because the fixed effects matrix is not of full rank 
due to the unused factor levels.




Bernardo Rangel Tura, MD, MSc
National Institute of Cardiology Laranjeiras
Rio de Janeiro Brazil 


--



From samrobertsmith at yahoo.com  Sat Oct  8 11:22:15 2005
From: samrobertsmith at yahoo.com (Sam R. Smith)
Date: Sat, 8 Oct 2005 02:22:15 -0700 (PDT)
Subject: [R] color for points
Message-ID: <20051008092215.88531.qmail@web30601.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051008/a0354cf3/attachment.pl

From pburns at pburns.seanet.com  Sat Oct  8 11:22:39 2005
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sat, 08 Oct 2005 10:22:39 +0100
Subject: [R] Assign references
In-Reply-To: <OFDF6CE636.7D3D7BCD-ON88257093.0081F707-88257093.00824BB1@epamail.epa.gov>
References: <OFDF6CE636.7D3D7BCD-ON88257093.0081F707-88257093.00824BB1@epamail.epa.gov>
Message-ID: <43478FDF.9030601@pburns.seanet.com>

Seeliger.Curt at epamail.epa.gov wrote:

>Patrick,
>
>I'll have to check your S poetry, it's not clear why 'changing things
>invisibly' is a bad thing in R, but is OK in C.  Perhaps the answer lies
>therein.
>  
>

I think Tony's reply has the main part of the answer.  R is
designed as a functional language -- meaning, essentially,
that side effects don't happen except for assignment.  The
"<<-" operator (and 'assign') are compromises from that
ideal. 

In C it is standard practice to pass by reference and that is
a great deal of its power.  In R it is standard practice not to
have to worry about objects being changed behind your
back -- that freedom is a part of the power of R.

On the surface this looks contradictory -- one of the two
approaches must be the better way.  But the two languages
have different uses.  C computes extremely efficiently in terms
of having operations that closely match the machine.  R computes
efficiently by having operations that closely match how people
think.

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

>I'd considered returning a sequence, but it seems more straight forward
>to be able to pass the arguments by reference.  The difficulty in doing
>this in R points to a philosophical point which thus far has eluded me.
>Certainly more thinking is in order.
>
>Thanks for your help on this,
>cur
>
>--
>Curt Seeliger, Data Ranger
>CSC, EPA/WED contractor
>541/754-4638
>seeliger.curt at epa.gov
>
>Patrick Burns <pburns at pburns.seanet.com> wrote on 10/07/2005 01:23:07
>PM:
>
>  
>
>>Because the function is using 'foo' and 'bar' as the global
>>variables, not 'x' and 'y'.  What you might have missed from
>>Thomas's statement (if I can take some liberties) is that you
>>almost surely don't want to do that -- it is bad style because
>>it changes things invisibly.  S Poetry has more on that.
>>
>>Better is:
>>
>>myFunk <- function(a, b) {
>>    x <- a + b
>>    y <- a * b
>>    list(x=x, y=y)
>>}
>>
>>xy <- myFunk(4, 5)
>>x <- xy$x
>>y <- xy$y
>>
>>
>>Patrick Burns
>>patrick at burns-stat.com
>>+44 (0)20 8525 0696
>>http://www.burns-stat.com
>>(home of S Poetry and "A Guide for the Unwilling S User")
>>
>>Seeliger.Curt at epamail.epa.gov wrote:
>>
>>    
>>
>>>Folks,
>>>
>>>I've run into trouble while writing functions that I hope will create
>>>and modify a dataframe or two.  To that end I've written a toy
>>>      
>>>
>function
>  
>
>>>that simply sets a couple of variables (well, tries but fails).
>>>Searching the archives, Thomas Lumley recently explained the <<-
>>>operator, showing that it was necessary for x and y to exist prior to
>>>the function call, but I haven't the faintest why this isn't working:
>>>
>>>
>>>
>>>      
>>>
>>>>myFunk<-function(a,b,foo,bar) {foo<<-a+b; bar<<-a*b;}
>>>>x<-0; y<-0;
>>>>myFunk(4,5,x,y)
>>>>x<-0; y<-0;
>>>>myFunk(4,5,x,y)
>>>>x
>>>>
>>>>
>>>>        
>>>>
>>>[1] 0
>>>
>>>
>>>      
>>>
>>>>y
>>>>
>>>>
>>>>        
>>>>
>>>[1] 0
>>>
>>>What (no doubt simple) reason is there for x and y not changing?
>>>
>>>Thank you,
>>>cur
>>>--
>>>Curt Seeliger, Data Ranger
>>>CSC, EPA/WED contractor
>>>541/754-4638
>>>seeliger.curt at epa.gov
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide!
>>>      
>>>
>http://www.R-project.org/posting-guide.html
>  
>
>>>
>>>
>>>
>>>      
>>>
>
>
>
>
>  
>



From samrobertsmith at yahoo.com  Sat Oct  8 11:29:33 2005
From: samrobertsmith at yahoo.com (Sam R. Smith)
Date: Sat, 8 Oct 2005 02:29:33 -0700 (PDT)
Subject: [R] square and points on the same figure
Message-ID: <20051008092933.74616.qmail@web30606.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051008/6385dc7f/attachment.pl

From vincent at 7d4.com  Sat Oct  8 11:35:14 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Sat, 08 Oct 2005 11:35:14 +0200
Subject: [R] color for points
In-Reply-To: <20051008092215.88531.qmail@web30601.mail.mud.yahoo.com>
References: <20051008092215.88531.qmail@web30601.mail.mud.yahoo.com>
Message-ID: <434792D2.1070903@7d4.com>

Sam R. Smith a ??crit :

> Hi,
> I have the following code to randomly generate the points:
> csr <-function(n=60){
> x=runif(n)
> y=runif(n)
> f=cbind(x,y)
> }
> plot(csr())
>  
> I wonder how to code to make the first twenty points to be BLUE; second twenty points to be RED; the last twenty points to be GREEN?

mynewfct = function(n=60)
{
x=runif(n)
y=runif(n)
f=cbind(x,y)
plot(f[1:20] , col='blue');
par(new=T);
plot(f[21:40] , col='red');
par(new=T);
plot(f[41:60] , col='green');
}

hih



From phgrosjean at sciviews.org  Sat Oct  8 11:36:02 2005
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Sat, 08 Oct 2005 11:36:02 +0200
Subject: [R] R version 2.01.1, Crimson Editor and the "one" from nowhere
In-Reply-To: <43467653.3070701@ema.fr>
References: <43467653.3070701@ema.fr>
Message-ID: <43479302.2070005@sciviews.org>

Hello Olivier,

The problem prob ably comes from TpR.exe. It first sends Alt-w 1 before 
the command, to make sure the console is the active window. You should 
try to switch R in SDI mode, which is definitely the best mode for 
running R side-by-side with a text editor. Tell me if it solves the problem.
Best,

Philippe Grosjean

..............................................<??}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons-Hainaut University, Pentagone (3D08)
( ( ( ( (    Academie Universitaire Wallonie-Bruxelles
  ) ) ) ) )   8, av du Champ de Mars, 7000 Mons, Belgium
( ( ( ( (
  ) ) ) ) )   phone: + 32.65.37.34.97, fax: + 32.65.37.30.54
( ( ( ( (    email: Philippe.Grosjean at umh.ac.be
  ) ) ) ) )
( ( ( ( (    web:   http://www.umh.ac.be/~econum
  ) ) ) ) )          http://www.sciviews.org
( ( ( ( (
..............................................................

Olivier ETERRADOSSI wrote:
> Dear List....
> sorry to bother you R-gurus with such an "unstatistical" question... but 
> I face a problem using Crimson Editor with R 2.01.1 that I never had 
> using R 2.00.1.
> I already posted on the Crimson Editor forum but it seems to be VERY few 
> R-users there....
> 
> I successfully used R v2.00.1until now (under Windows XP professionnal, 
> version 2002, Service Pack 2, P4 processor CPU 1.8 GHz), together with 
> Crimson Editor.
> This editor is "linked" to R using three files (TpR.exe, R.SPC and R.KEYS).
> I recently upgraded to R 2.01.1.
> I kept using my old TpR.exe, R.SPC and R.KEYS, because I did not find 
> any new files on the Crimson Editor "Release" web page.
> When I now launch a script, instead of getting my old, well known prompt :
>  > source("C:/Program Files/R/fooscript.txt")
> I get :
>  > 1source("C:/Program Files/R/fooscript.txt")
> with a "1" in front of the line.... and of course R  greets me with a 
> "syntax error" message.
> Then I have to remove the "1" by hand (pretty prehistoric, ...and does 
> not work if  my script is meant to launch other scripts during the 
> night....)
> I cannot figure where this "1" comes from !!
> Did some of you already encountered this problem, and how did you get 
> rid of it ?
> Thanks a lot, have a nice week-end. Olivier
>



From vincent at 7d4.com  Sat Oct  8 11:43:36 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Sat, 08 Oct 2005 11:43:36 +0200
Subject: [R] square and points on the same figure
In-Reply-To: <20051008092933.74616.qmail@web30606.mail.mud.yahoo.com>
References: <20051008092933.74616.qmail@web30606.mail.mud.yahoo.com>
Message-ID: <434794C8.5050604@7d4.com>

?rect
(and don't forget par(new=T))
hih



From phgrosjean at sciviews.org  Sat Oct  8 11:42:36 2005
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Sat, 08 Oct 2005 11:42:36 +0200
Subject: [R] R version 2.01.1, Crimson Editor and the "one" from nowhere
In-Reply-To: <43467653.3070701@ema.fr>
References: <43467653.3070701@ema.fr>
Message-ID: <4347948C.4010204@sciviews.org>

... OK, I have spot the problem: TpR.exe expects RGui running in 
English. Shortcut for the Windows menu is Alt-w, which is what it sends 
to R. Then, it sends "1", meaning, activate first window (the console). 
You have probably RGui running in French, or in another language. In 
French the menu is called "Fen??tres", with the corresponding shortcut 
being Alt-n. Consequently, the menu is not triggered and the "1" is send 
to the command line.

Two solutions to continue using TpR.exe with R 2.1.1 or more:
1) Switch R in SDI mode,
2) Use RGui in MDI mode, but in English.

The third solution is to patch TpR.exe, which I will not do, because I 
need to program a separate command for each different language of R!
Best,

Philippe Grosjean

..............................................<??}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons-Hainaut University, Pentagone (3D08)
( ( ( ( (    Academie Universitaire Wallonie-Bruxelles
  ) ) ) ) )   8, av du Champ de Mars, 7000 Mons, Belgium
( ( ( ( (
  ) ) ) ) )   phone: + 32.65.37.34.97, fax: + 32.65.37.30.54
( ( ( ( (    email: Philippe.Grosjean at umh.ac.be
  ) ) ) ) )
( ( ( ( (    web:   http://www.umh.ac.be/~econum
  ) ) ) ) )          http://www.sciviews.org
( ( ( ( (
..............................................................

Olivier ETERRADOSSI wrote:
> Dear List....
> sorry to bother you R-gurus with such an "unstatistical" question... but 
> I face a problem using Crimson Editor with R 2.01.1 that I never had 
> using R 2.00.1.
> I already posted on the Crimson Editor forum but it seems to be VERY few 
> R-users there....
> 
> I successfully used R v2.00.1until now (under Windows XP professionnal, 
> version 2002, Service Pack 2, P4 processor CPU 1.8 GHz), together with 
> Crimson Editor.
> This editor is "linked" to R using three files (TpR.exe, R.SPC and R.KEYS).
> I recently upgraded to R 2.01.1.
> I kept using my old TpR.exe, R.SPC and R.KEYS, because I did not find 
> any new files on the Crimson Editor "Release" web page.
> When I now launch a script, instead of getting my old, well known prompt :
>  > source("C:/Program Files/R/fooscript.txt")
> I get :
>  > 1source("C:/Program Files/R/fooscript.txt")
> with a "1" in front of the line.... and of course R  greets me with a 
> "syntax error" message.
> Then I have to remove the "1" by hand (pretty prehistoric, ...and does 
> not work if  my script is meant to launch other scripts during the 
> night....)
> I cannot figure where this "1" comes from !!
> Did some of you already encountered this problem, and how did you get 
> rid of it ?
> Thanks a lot, have a nice week-end. Olivier
>



From ccatj at web.de  Sat Oct  8 11:50:31 2005
From: ccatj at web.de (Christian Jones)
Date: Sat, 08 Oct 2005 11:50:31 +0200
Subject: [R] keeping interaction terms
Message-ID: <366015540@web.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051008/ef0d5a4b/attachment.pl

From samrobertsmith at yahoo.com  Sat Oct  8 12:02:10 2005
From: samrobertsmith at yahoo.com (Sam R. Smith)
Date: Sat, 8 Oct 2005 03:02:10 -0700 (PDT)
Subject: [R] square and points on the same figure
Message-ID: <20051008100210.85814.qmail@web30604.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051008/ae1cd0dc/attachment.pl

From jholtman at gmail.com  Sat Oct  8 12:21:20 2005
From: jholtman at gmail.com (jim holtman)
Date: Sat, 8 Oct 2005 06:21:20 -0400
Subject: [R] color for points
In-Reply-To: <20051008092215.88531.qmail@web30601.mail.mud.yahoo.com>
References: <20051008092215.88531.qmail@web30601.mail.mud.yahoo.com>
Message-ID: <644e1f320510080321r72212c9dv6e2c093d47d9fe5a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051008/545d8eb4/attachment.pl

From ccleland at optonline.net  Sat Oct  8 12:23:34 2005
From: ccleland at optonline.net (Chuck Cleland)
Date: Sat, 08 Oct 2005 06:23:34 -0400
Subject: [R] square and points on the same figure
In-Reply-To: <20051008100210.85814.qmail@web30604.mail.mud.yahoo.com>
References: <20051008100210.85814.qmail@web30604.mail.mud.yahoo.com>
Message-ID: <43479E26.7000103@optonline.net>

Sam R. Smith wrote:
> Hi,
> I have the following code to 
> randomly generate the 
> points:
> csr <-function(n=60){
> x=runif(n)
> y=runif(n)
> f=cbind(x,y)
> }
> plot(csr())
> 
> I wonder how to code to draw a square centering on 0.5,0.5; with the length of each side to be 0.3 on the same figure with these plotted points?

?symbols

symbols(x=0.5, y=0.5, squares=c(0.3), add=TRUE)

> Thanks,
> Sam
> 
> 
> 		
> ---------------------------------
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From samrobertsmith at yahoo.com  Sat Oct  8 12:57:36 2005
From: samrobertsmith at yahoo.com (Sam R. Smith)
Date: Sat, 8 Oct 2005 03:57:36 -0700 (PDT)
Subject: [R] square and points on the same figure
In-Reply-To: <43479E26.7000103@optonline.net>
Message-ID: <20051008105736.91311.qmail@web30602.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051008/f05e4f4d/attachment.pl

From ccleland at optonline.net  Sat Oct  8 13:24:30 2005
From: ccleland at optonline.net (Chuck Cleland)
Date: Sat, 08 Oct 2005 07:24:30 -0400
Subject: [R] square and points on the same figure
In-Reply-To: <20051008105736.91311.qmail@web30602.mail.mud.yahoo.com>
References: <20051008105736.91311.qmail@web30602.mail.mud.yahoo.com>
Message-ID: <4347AC6E.40905@optonline.net>

Sam R. Smith wrote:
> after typing
> symbols(x=0.5, y=0.5, squares=c(0.3), add=TRUE)
> it works.
> I want to add one more using different length such as
> symbols(x=0.5, y=0.5, squares=c(0.15), add=TRUE)
> but this square did not show.

Specify both (all) squares in the same call to symbols:

csr <-function(n=60){
x=runif(n)
y=runif(n)
f=cbind(x,y)
}
plot(csr())

symbols(x=c(0.5, 0.5), y=c(0.5, 0.5), squares=c(0.30,0.15), add=TRUE)

> Chuck Cleland <ccleland at optonline.net> wrote:
> Sam R. Smith wrote:
> 
>>Hi,
>>I have the following code to 
>>randomly generate the 
>>points:
>>csr <-function(n=60){
>>x=runif(n)
>>y=runif(n)
>>f=cbind(x,y)
>>}
>>plot(csr())
>>
>>I wonder how to code to draw a square centering on 0.5,0.5; with the length of each side to be 0.3 on the same figure with these plotted points?
> 
> 
> ?symbols
> 
> symbols(x=0.5, y=0.5, squares=c(0.3), add=TRUE)
> 
> 
>>Thanks,
>>Sam
>>
>>
>>
>>---------------------------------
>>
>>[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
> 


-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From j_brindle at hotmail.com  Sat Oct  8 14:07:33 2005
From: j_brindle at hotmail.com (Jim Brindle)
Date: Sat, 8 Oct 2005 08:07:33 -0400
Subject: [R] Two-factor ANOVA Help
Message-ID: <BAY20-DAV4A70AB516FFC9B9BB8EE480870@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051008/106c04d1/attachment.pl

From f.harrell at vanderbilt.edu  Sat Oct  8 14:30:14 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sat, 08 Oct 2005 08:30:14 -0400
Subject: [R] keeping interaction terms
In-Reply-To: <366015540@web.de>
References: <366015540@web.de>
Message-ID: <4347BBD6.5090504@vanderbilt.edu>

Your note is formatted strangely.  You seem to be using Microsoft - 
please tell your software to send plain text e-mails - Microsoft doesn't 
own plain ASCII text format, at least not yet (have they applied for a 
patent for it?).


Christian Jones wrote:
> 
> Hello,<?xml:namespace prefix = o ns = "urn:schemas-microsoft-com:office:office" /><o:p></o:p>
> 
> while doing my thesis in habitat modelling I??ve come across a problem with interaction terms. My question concerns the usage of interaction terms for linear regression modelling with R. If an interaction-term (predictor) is chosen for a multiple model, then, according to <?xml:namespace prefix = st1 ns = "urn:schemas-microsoft-com:office:smarttags" /><st1:place w:st="on">Crawley</st1:place> its single term has to be added to the multiple model: lrm(N~a*b+a+b).<o:p></o:p>
> 
> This nearly always leads to high correlation rates between the interaction term a*b and its single term a or b. With regards to the law of colinearity modelling should not include correlated variables with an Spearman index >0,7. Does this mean that the interaction term has to be discarded or can the variables stay within the model when correlated? I do not necessarily want to do a PCA on this issue.<o:p></o:p>
> 
> Thanks for helping<o:p></o:p>
> 
> Christian<o:p></o:p>

Your query opens up many issues.  First, the statement that a main 
effect has to be added if an interaction term is chosen assumes that an 
interaction has meaning without adjustment for main effects.  This is 
not the case.  The hierarchy principle needs to be executed in a forward 
manner.  Second, you are implying that you are not fitting a single 
pre-specified model but are doing variable selection based on p-values. 
  This creates a host of problems.  Third, you imply that correlations 
between main effects and interactions are not to be tolerated.  Again 
this is not the case.  It is a fact of life that we must accomodate. 
[Some people like to center main effects to reduce this correlation but 
that is an artificial and not helpful approach.]

Frank


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From maechler at stat.math.ethz.ch  Sat Oct  8 15:12:48 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 8 Oct 2005 15:12:48 +0200
Subject: [R] obfuscated identity
In-Reply-To: <20051007233911.17119.qmail@web54515.mail.yahoo.com>
References: <200510072315.j97NFgCv014658@meitner.gene.com>
	<20051007233911.17119.qmail@web54515.mail.yahoo.com>
Message-ID: <17223.50640.27988.707545@stat.math.ethz.ch>

>>>>> "Globe" == Globe Trotter <itsme_410 at yahoo.com>
>>>>>     on Fri, 7 Oct 2005 16:39:10 -0700 (PDT) writes:

	  .....

    Globe> I use this Yahoo! e-mail address as a junk e-mail
    Globe> address since the archives contain the complete
    Globe> e-mail address (no anti-spam measures taken) so I do
    Globe> not include my real name.

  [there are many different archives and some do some anti-spam measures..
   to strip or obfuscate e-mail addresses before mail is sent
   out, is really not an option!]

    Globe> It would be nice if the R-archivers stripped e-mail
    Globe> addresses from posters (or messed it up) so that
    Globe> spider programs would not be able to get it.

  (yes, but *all* of them would have to do it; and do it so
   smartly that smart address collecting software cannot
   regenerate it; ... )

    Globe> Many thanks and best wishes, GT

and you still don't tell us who you are!

Bert's remark was very much on point:  Using a yahoo or gmail or
... e-mail address is one thing; but then we'd expect at least a
full name (and often affiliation) as "signature".
It not only netiquette, it's real life etiquette to not send
anonymous letters....

Martin Maechler, ETH Zurich



From talda at hotmail.com  Sat Oct  8 15:15:19 2005
From: talda at hotmail.com (nawaf b)
Date: Sat, 8 Oct 2005 09:15:19 -0400
Subject: [R] Warning: condition has length > 1
Message-ID: <BAY102-DAV15E5D27A02E3383C0B0DB6B3870@phx.gbl>

Hi -

I was wondering if anyone came across a problem such as mine! I was trying
to create a user-defined function, however, the results from calling the
function are unexpected!

When passing X parameter as a single value variable (x<-c(3)), everything
works fine. However, when passing a parameter as a vector with multiple
values (as the case in my code), the 'if condition' is only executed once!

Here is my code:
> x
[1]  0.3  1.0  0.7 22.0
> myfunction<-function(x)
+ {
+ if (x>=1) 0
+ else x^2
+ }
> myfunction(x)
[1]   0.09   1.00   0.49 484.00
Warning message:
the condition has length > 1 and only the first element will be used in: if
(x >= 1) 0 else x^2 
>

Is there a way to overcome this issue? Can you please explain what
modifications to the code I need to accommodate to make it work.

Thanks,

Nawaf



From Ted.Harding at nessie.mcc.ac.uk  Sat Oct  8 15:14:55 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 08 Oct 2005 14:14:55 +0100 (BST)
Subject: [R] keeping interaction terms
In-Reply-To: <366015540@web.de>
Message-ID: <XFMail.051008141455.Ted.Harding@nessie.mcc.ac.uk>

Adding a bit to Frank Harrell's good comments.

1. Regarding HTML infection: I rolled up my sleeves, washed
   my hands carefully, took a fine sharp knife, cut it all
   out, and then sowed up the incisions.

2. For the rest, see below.

On 08-Oct-05 Christian Jones wrote:
> Hello,
> 
> while doing my thesis in habitat modelling I??ve come across a
> problem with interaction terms. My question concerns the usage
> of interaction terms for linear regression modelling with R.
> If an interaction-term (predictor) is chosen for a multiple model,
> then, according to Crawley its single term has to be added to the
> multiple model: lrm(N~a*b+a+b).
> 
> This nearly always leads to high correlation rates between the
> interaction term a*b and its single term a or b. With regards to
> the law of colinearity modelling should not include correlated
> variables with an Spearman index >0,7. Does this mean that the
> interaction term has to be discarded or can the variables stay
> within the model when correlated?
> I do not necessarily want to do a PCA on this issue.

There's more than a suggestion in your statements that you tend
to be drawn along by people's prescriptions. Instead, try to
think simply about it.

If, after fitting "a+b", you make a "significant difference" by
further including "a:b", then the interaction between a and b
matters, even if you observe high correlations. The latter should
not lead you to ignore the former.

How much it matters is of course another question. You could
examine this, in R, by comparing the predicted values from the
"a+b" model with the predicted values from the "a*b" model.
Though they will be different, you will have to judge whether
the amount of difference is large enough to be of real importance
in your application. (It is possible to get highly "significant"
results, i.e. small P-values, from small effects).

Even if it does matter, in real terms, you are left with the
fundamental difficulty, indicated by Frank, that interpreting
interaction between variables a and b is simple only when the
variables a and b are orthogonal in the data (either by accident
or by design). If they are non-orthogonal, then you have to
think carefully about how to interpret it, and this does depend
on what it all means.

Maybe we could help more with this if we knew more about your
investigation (perhaps off-list, if you prefer).

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 08-Oct-05                                       Time: 14:14:48
------------------------------ XFMail ------------------------------



From ccleland at optonline.net  Sat Oct  8 15:23:44 2005
From: ccleland at optonline.net (Chuck Cleland)
Date: Sat, 08 Oct 2005 09:23:44 -0400
Subject: [R] Warning: condition has length > 1
In-Reply-To: <BAY102-DAV15E5D27A02E3383C0B0DB6B3870@phx.gbl>
References: <BAY102-DAV15E5D27A02E3383C0B0DB6B3870@phx.gbl>
Message-ID: <4347C860.8070808@optonline.net>

nawaf b wrote:
> Hi -
> 
> I was wondering if anyone came across a problem such as mine! I was trying
> to create a user-defined function, however, the results from calling the
> function are unexpected!
> 
> When passing X parameter as a single value variable (x<-c(3)), everything
> works fine. However, when passing a parameter as a vector with multiple
> values (as the case in my code), the 'if condition' is only executed once!
> 
> Here is my code:
> 
>>x
> 
> [1]  0.3  1.0  0.7 22.0
> 
>>myfunction<-function(x)
> 
> + {
> + if (x>=1) 0
> + else x^2
> + }

?ifelse

myfunction <- function(x){ifelse(x >= 1, 0, x^2)}

 > myfunction(c(.3, 1, .7, 22))
[1] 0.09 0.00 0.49 0.00

>>myfunction(x)
> 
> [1]   0.09   1.00   0.49 484.00
> Warning message:
> the condition has length > 1 and only the first element will be used in: if
> (x >= 1) 0 else x^2 
> 
> 
> Is there a way to overcome this issue? Can you please explain what
> modifications to the code I need to accommodate to make it work.
> 
> Thanks,
> 
> Nawaf
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From ggrothendieck at gmail.com  Sat Oct  8 15:24:29 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 8 Oct 2005 09:24:29 -0400
Subject: [R] Warning: condition has length > 1
In-Reply-To: <BAY102-DAV15E5D27A02E3383C0B0DB6B3870@phx.gbl>
References: <BAY102-DAV15E5D27A02E3383C0B0DB6B3870@phx.gbl>
Message-ID: <971536df0510080624l4d4041a2nbfe31310b6e7fc65@mail.gmail.com>

ifelse(x >= 1, 0, x^2)

or

(x >= 1) * x^2

Also, you might need x > (1 - e) where e is some small number since your
numbers may not be exact.



On 10/8/05, nawaf b <talda at hotmail.com> wrote:
> Hi -
>
> I was wondering if anyone came across a problem such as mine! I was trying
> to create a user-defined function, however, the results from calling the
> function are unexpected!
>
> When passing X parameter as a single value variable (x<-c(3)), everything
> works fine. However, when passing a parameter as a vector with multiple
> values (as the case in my code), the 'if condition' is only executed once!
>
> Here is my code:
> > x
> [1]  0.3  1.0  0.7 22.0
> > myfunction<-function(x)
> + {
> + if (x>=1) 0
> + else x^2
> + }
> > myfunction(x)
> [1]   0.09   1.00   0.49 484.00
> Warning message:
> the condition has length > 1 and only the first element will be used in: if
> (x >= 1) 0 else x^2
> >
>
> Is there a way to overcome this issue? Can you please explain what
> modifications to the code I need to accommodate to make it work.
>
> Thanks,
>
> Nawaf
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Roger.Bivand at nhh.no  Sat Oct  8 15:24:56 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 8 Oct 2005 15:24:56 +0200 (CEST)
Subject: [R] Warning: condition has length > 1
In-Reply-To: <BAY102-DAV15E5D27A02E3383C0B0DB6B3870@phx.gbl>
Message-ID: <Pine.LNX.4.44.0510081522260.2960-100000@reclus.nhh.no>

On Sat, 8 Oct 2005, nawaf b wrote:

> Hi -
> 
> I was wondering if anyone came across a problem such as mine! I was trying
> to create a user-defined function, however, the results from calling the
> function are unexpected!
> 
> When passing X parameter as a single value variable (x<-c(3)), everything
> works fine. However, when passing a parameter as a vector with multiple
> values (as the case in my code), the 'if condition' is only executed once!
> 
> Here is my code:
> > x
> [1]  0.3  1.0  0.7 22.0
> > myfunction<-function(x)
> + {
> + if (x>=1) 0
> + else x^2
> + }
> > myfunction(x)
> [1]   0.09   1.00   0.49 484.00
> Warning message:
> the condition has length > 1 and only the first element will be used in: if
> (x >= 1) 0 else x^2 
> >
> 
> Is there a way to overcome this issue? Can you please explain what
> modifications to the code I need to accommodate to make it work.

> myfunction<-function(x)
+ ifelse(x>=1, 0, x^2)
> x <- c(0.3, 1.0, 0.7, 22.0)
> myfunction(x)
[1] 0.09 0.00 0.49 0.00

ifelse() is vectorised, but if() only looks at the first element in x 
before deciding what to do - so if the condition is longer, the rest gets 
ignored.

> 
> Thanks,
> 
> Nawaf
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ggrothendieck at gmail.com  Sat Oct  8 15:25:04 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 8 Oct 2005 09:25:04 -0400
Subject: [R] Warning: condition has length > 1
In-Reply-To: <971536df0510080624l4d4041a2nbfe31310b6e7fc65@mail.gmail.com>
References: <BAY102-DAV15E5D27A02E3383C0B0DB6B3870@phx.gbl>
	<971536df0510080624l4d4041a2nbfe31310b6e7fc65@mail.gmail.com>
Message-ID: <971536df0510080625u649dabe3mf41584da248b516a@mail.gmail.com>

On 10/8/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> ifelse(x >= 1, 0, x^2)
>
> or
>
> (x >= 1) * x^2

Sorry, that should have been (x < 1) * x^2

>
> Also, you might need x > (1 - e) where e is some small number since your
> numbers may not be exact.
>
>
>
> On 10/8/05, nawaf b <talda at hotmail.com> wrote:
> > Hi -
> >
> > I was wondering if anyone came across a problem such as mine! I was trying
> > to create a user-defined function, however, the results from calling the
> > function are unexpected!
> >
> > When passing X parameter as a single value variable (x<-c(3)), everything
> > works fine. However, when passing a parameter as a vector with multiple
> > values (as the case in my code), the 'if condition' is only executed once!
> >
> > Here is my code:
> > > x
> > [1]  0.3  1.0  0.7 22.0
> > > myfunction<-function(x)
> > + {
> > + if (x>=1) 0
> > + else x^2
> > + }
> > > myfunction(x)
> > [1]   0.09   1.00   0.49 484.00
> > Warning message:
> > the condition has length > 1 and only the first element will be used in: if
> > (x >= 1) 0 else x^2
> > >
> >
> > Is there a way to overcome this issue? Can you please explain what
> > modifications to the code I need to accommodate to make it work.
> >
> > Thanks,
> >
> > Nawaf
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>



From chabotd at globetrotter.net  Sat Oct  8 15:28:50 2005
From: chabotd at globetrotter.net (Denis Chabot)
Date: Sat, 08 Oct 2005 09:28:50 -0400
Subject: [R]  how to control ticks in plots with yasp or xasp
In-Reply-To: <mailman.10.1128506401.6195.r-help@stat.math.ethz.ch>
References: <mailman.10.1128506401.6195.r-help@stat.math.ethz.ch>
Message-ID: <EF4C19CB-AB0B-4A61-827C-9A491C11DCC7@globetrotter.net>

Hi,

A few times I tried to control the number and position of tick marks  
in plots with the yasp or xasp parameters. For example, a y axis was  
drawn by default with tick marks at 0, 20, 40, 80 and 100. I tried to  
get tick marks every 10 by adding

yasp=(0, 100, 10)

but this had no effect at all. I know I can draw the axis and tick  
marks manually, but often this simple option would suffice if I could  
understand how to make it work.

Thanks in advance,

Denis Chabot



From ggrothendieck at gmail.com  Sat Oct  8 16:15:13 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 8 Oct 2005 10:15:13 -0400
Subject: [R] Two-factor ANOVA Help
In-Reply-To: <BAY20-DAV4A70AB516FFC9B9BB8EE480870@phx.gbl>
References: <BAY20-DAV4A70AB516FFC9B9BB8EE480870@phx.gbl>
Message-ID: <971536df0510080715v543e61e8tdf22f2a1f4505a9a@mail.gmail.com>

On 10/8/05, Jim Brindle <j_brindle at hotmail.com> wrote:
> Hello,
>
> I am trying to perform a two-factor ANOVA analysis using a blocking design with "Vol" as the response variable.  My intent is to have "Rater" treated as the treatment variable and the "Pipe" treated as the blocking variable.  I am reading and preparing my dataset using the following three lines of code:
>
> values <- read.table("filename", header=TRUE)
> attach(values)
> values = data.frame(values)
>
> The dataset is the following:
>
> Pipe Rater Volume
> 1    A       5.129
> 1    B       5.296
> 1    C       4.679
> 1    D       4.776
> 2    A       8.519
> 2    B       8.482
> 2    C       7.659
> 2    D       7.798
> 3    A       13.769
> 3    B       14.621
> 3    C       12.418
> 3    D       13.189
>
> Below there are 2 versions which I've used to run my analysis.
>
> Option #1:
>
> g <- lm(Volume ~ factor(Rater) + factor(Pipe), values)
> print(anova(g))
>
> Option #2:
>
> Rater <- as.factor(Rater)
> Pipe <- as.factor(Pipe)
> g <- lm(Volume ~ Rater + Pipe, values)
> print(anova(g))
>
>
> A couple of questions I have are:
>
> 1.  I thought that option #1 and option #2 would have given me the same results and they don't appear to.  The only difference (to me) is how I have specified the factors used in the model.  However, there appears to be something else I am missing and I was just wondering if anyone has any insight as to which is the correct way to code this analysis?

Note that values, as returned from read.table, is already a data frame
and Rater is already a factor so you only need to convert Pipe to a
factor:

values <- read.table("filename.dat", header = TRUE)

# shows classes of columns among other things
# note that Rater is already a factor and values is already a data frame
str(g)

# convert Pipe to a factor
values$Pipe <- factor(values$Pipe)
g <- lm(Volume ~., values)
g

>
> 2.  Unless otherwise specified is there a particular reference level that R uses by default - for example in this case, the second treatment level (Rater B)?

By default R uses treatment contrasts and uses the first level as the baseline.
You can change this using contrasts and contr.treatment.

 e.g. To use treatment effects on Pipe with level 2 as the baseline:

contrasts(values$Pipe) <- contr.treatment(3, base = 2)
g2 <- lm(Volume ~., values)
g2

>
> 3.  Is there a good reference someone can point me to for more insight on the two-factor ANOVA analysis with R?
>

See ?read.table, ?contrasts, ?contr.treatment



From ggrothendieck at gmail.com  Sat Oct  8 16:20:17 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 8 Oct 2005 10:20:17 -0400
Subject: [R] Two-factor ANOVA Help
In-Reply-To: <971536df0510080715v543e61e8tdf22f2a1f4505a9a@mail.gmail.com>
References: <BAY20-DAV4A70AB516FFC9B9BB8EE480870@phx.gbl>
	<971536df0510080715v543e61e8tdf22f2a1f4505a9a@mail.gmail.com>
Message-ID: <971536df0510080720u4e5367dy59bc6316d571aad9@mail.gmail.com>

On 10/8/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> On 10/8/05, Jim Brindle <j_brindle at hotmail.com> wrote:
> > Hello,
> >
> > I am trying to perform a two-factor ANOVA analysis using a blocking design with "Vol" as the response variable.  My intent is to have "Rater" treated as the treatment variable and the "Pipe" treated as the blocking variable.  I am reading and preparing my dataset using the following three lines of code:
> >
> > values <- read.table("filename", header=TRUE)
> > attach(values)
> > values = data.frame(values)
> >
> > The dataset is the following:
> >
> > Pipe Rater Volume
> > 1    A       5.129
> > 1    B       5.296
> > 1    C       4.679
> > 1    D       4.776
> > 2    A       8.519
> > 2    B       8.482
> > 2    C       7.659
> > 2    D       7.798
> > 3    A       13.769
> > 3    B       14.621
> > 3    C       12.418
> > 3    D       13.189
> >
> > Below there are 2 versions which I've used to run my analysis.
> >
> > Option #1:
> >
> > g <- lm(Volume ~ factor(Rater) + factor(Pipe), values)
> > print(anova(g))
> >
> > Option #2:
> >
> > Rater <- as.factor(Rater)
> > Pipe <- as.factor(Pipe)
> > g <- lm(Volume ~ Rater + Pipe, values)
> > print(anova(g))
> >
> >
> > A couple of questions I have are:
> >
> > 1.  I thought that option #1 and option #2 would have given me the same results and they don't appear to.  The only difference (to me) is how I have specified the factors used in the model.  However, there appears to be something else I am missing and I was just wondering if anyone has any insight as to which is the correct way to code this analysis?
>
> Note that values, as returned from read.table, is already a data frame
> and Rater is already a factor so you only need to convert Pipe to a
> factor:
>
> values <- read.table("filename.dat", header = TRUE)
>
> # shows classes of columns among other things
> # note that Rater is already a factor and values is already a data frame
> str(g)
>
> # convert Pipe to a factor
> values$Pipe <- factor(values$Pipe)
> g <- lm(Volume ~., values)
> g
>
> >
> > 2.  Unless otherwise specified is there a particular reference level that R uses by default - for example in this case, the second treatment level (Rater B)?
>
> By default R uses treatment contrasts and uses the first level as the baseline.
> You can change this using contrasts and contr.treatment.
>
>  e.g. To use treatment effects on Pipe with level 2 as the baseline:
>
> contrasts(values$Pipe) <- contr.treatment(3, base = 2)
> g2 <- lm(Volume ~., values)
> g2
>
> >
> > 3.  Is there a good reference someone can point me to for more insight on the two-factor ANOVA analysis with R?
> >
>
> See ?read.table, ?contrasts, ?contr.treatment
>

One more point.  In your #2 the second argument to lm is specified
as values so that's where lm will look for the variables.  The Rater
and Pipe defined immediately above that line will never be found since
those variables will already have been found in the values data frame.



From MSchwartz at mn.rr.com  Sat Oct  8 17:16:38 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Sat, 08 Oct 2005 10:16:38 -0500
Subject: [R] how to control ticks in plots with yasp or xasp
In-Reply-To: <EF4C19CB-AB0B-4A61-827C-9A491C11DCC7@globetrotter.net>
References: <mailman.10.1128506401.6195.r-help@stat.math.ethz.ch>
	<EF4C19CB-AB0B-4A61-827C-9A491C11DCC7@globetrotter.net>
Message-ID: <1128784599.4108.19.camel@localhost.localdomain>

On Sat, 2005-10-08 at 09:28 -0400, Denis Chabot wrote:
> Hi,
> 
> A few times I tried to control the number and position of tick marks  
> in plots with the yasp or xasp parameters. For example, a y axis was  
> drawn by default with tick marks at 0, 20, 40, 80 and 100. I tried to  
> get tick marks every 10 by adding
> 
> yasp=(0, 100, 10)
> 
> but this had no effect at all. I know I can draw the axis and tick  
> marks manually, but often this simple option would suffice if I could  
> understand how to make it work.
> 
> Thanks in advance,
> 
> Denis Chabot


I suspect that one problem you are having is that there is no
par("xasp") or par("yasp")....unless these are typos and you are trying
to use par("xaxp") and par("yaxp")?

There is an 'asp' argument to some of the plot functions (ie.
plot.default), but this has a different intention.

par("xaxp") and par("yaxp") are not listed as read only pars in ?par,
however, I cannot recall an instance where R does not overwrite the user
settings during the calculation of the axes, whether passed as arguments
to a plot function or set a priori via a par() call.

If you want explicit control over the tick marks, you will need to use
axis(), perhaps in combination with axTicks(), after using 'xaxt = "n"'
and/or 'yaxt = "n"' in the plot call, depending upon the circumstances.

HTH,

Marc Schwartz



From peterm at andrew.cmu.edu  Sat Oct  8 17:17:03 2005
From: peterm at andrew.cmu.edu (Peter Muhlberger)
Date: Sat, 08 Oct 2005 11:17:03 -0400
Subject: [R] Matrix calculations in R--erroneous?
In-Reply-To: <4346EEEF.7090705@pdf.com>
Message-ID: <BF6D5B2F.E0C1%peterm@andrew.cmu.edu>


Hi Spencer:  Thanks!  This gives me a number of other ways of thinking about
this problem.  My one concern is that these approaches would also run into
some difficulties with how long it takes to calculate.  I'm interested not
in a single value but a matrix of over 300k values that has to be recomputed
more than a million times.  If I had to apply ifelse or floor to each of
these, it might take too long.  I'll have to see.

Peter

On 10/7/05 5:55 PM, "Spencer Graves" <spencer.graves at pdf.com> wrote:

>  Rather than adding 1e-15 to all numbers, I suggest you simply make
> that the floor.  (Or use .Machine$double.eps or 2*.Machine$double.eps in
> place of 1e-15.)
> 
>  Another alternative that may or may not apply in your case is to
> develop an asymptotic expansion for the log(likelihood) for the small
> numbers.  I've had good success with this kind of method.  For example,
> consider the Box-Cox transformation:
> 
>  bc(y, b) = (y^b-1)/b
> 
>  What do we do with b = 0?  We can test for b = 0 and replace those
> cases by the limit log(y).  However, it is numerically more stable to
> use the following:
> 
>  bc(y, b) = ifelse(abs(b*log(y))>.Machine$double.eps,
> (expm1(b*log(y))/b, log(y)).
> 
>  I don't have time to study your example to see if I could see
> anything like this that could be done, but I think there should be a
> good chance of finding something like this.  Of course, if there are
> only very few 0's, then it hardly matters.  However, if there are quite
> a few, then you need something like this.
> 
>  hope this helps.
>  spencer graves



From br44114 at gmail.com  Sat Oct  8 17:26:26 2005
From: br44114 at gmail.com (bogdan romocea)
Date: Sat, 8 Oct 2005 11:26:26 -0400
Subject: [R] add leading 0s to %d from png() {was Automatic creation of file
	names}
Message-ID: <8d5a36350510080826k4f594b59xf7ef5fbc5420e061@mail.gmail.com>

Dear useRs,

Is there a way to 'properly' format %d when plotting more than one
page on png()? 'Properly' means to me with leading 0s, so that the
PNGs become easy to navigate in a file/image browser. Lacking a better
solution I ended up using the code below, but would much prefer
something like
   png("test_%d.png",bg="white",width=1000,height=700)
where %d could be formatted like
   formatC(%d,digits=0,wid=3,flag="0",mode="integer")

Thank you,
b.

#---works, but is rather complicated---
pngno <- 0 ; i <- 1
for (w in 1:53) {
  if (i %in% c(4*0:100+1)) {
    pngno <- pngno + 1
    png(paste("test_",formatC(pngno,digits=0,wid=4,flag="0",mode="integer"),
      ".png",sep=""),bg="white",width=1000,height=750)
    par(mfrow=c(2,2),mai=c(4,5,3,2)/10,omi=c(0.2,0,0,0),
      cex.axis=1,cex.main=1.2)
    }
  plot(1:10,main=w)
  if (i %in% c(4*1:100)) dev.off()
  i <- i+1
  }
dev.off()


>From: Mike Prager <Mike.Prager <at> noaa.gov>
>Subject: Re: [R] Automatic creation of file names
>Newsgroups: gmane.comp.lang.r.general
>Date: 2005-09-22 14:51:54 GMT (2 weeks, 1 day, 23 hours and 55 minutes ago)
>
>Walter --
>
>P.S.  The advantage of using formatC over pasting the digits (1:1000)
>directly is that when one uses leading zeroes, as in the formatC example
>shown, the resulting filenames will sort into proper order.
>
>...MHP
>
>You can use paste() with something like
>
> formatC(number,digits=0,wid=3,flag="0")
>
>(where number is your loop index) to generate the filenames.
>
>on 9/22/2005 10:21 AM Leite,Walter said the following:
>
>>I have a question about how to save to the hard drive the one thousand
>>datasets I generated in a simulation. ://www.R-project.org/posting-guide.html



From chabotd at globetrotter.net  Sat Oct  8 17:29:27 2005
From: chabotd at globetrotter.net (Denis Chabot)
Date: Sat, 08 Oct 2005 11:29:27 -0400
Subject: [R] how to control ticks in plots with yasp or xasp
In-Reply-To: <1128784599.4108.19.camel@localhost.localdomain>
References: <mailman.10.1128506401.6195.r-help@stat.math.ethz.ch>
	<EF4C19CB-AB0B-4A61-827C-9A491C11DCC7@globetrotter.net>
	<1128784599.4108.19.camel@localhost.localdomain>
Message-ID: <9E3101AD-998E-43A9-A2FA-EC79DC3FE389@globetrotter.net>

Oops, Mark, bad typo indeed.

But yaxp is what I had in my R program and it did not help.

I did obtain control over my tick marks by drawing them myself, as  
you suggest. But I was curious as to how to use yaxp since the help  
on "par" gives it as a possible way of controlling ticks. Maybe it  
should be removed from the help file?

Thanks for your help,

Denis
Le 05-10-08 ?? 11:16, Marc Schwartz a ??crit :

> On Sat, 2005-10-08 at 09:28 -0400, Denis Chabot wrote:
>
>> Hi,
>>
>> A few times I tried to control the number and position of tick marks
>> in plots with the yasp or xasp parameters. For example, a y axis was
>> drawn by default with tick marks at 0, 20, 40, 80 and 100. I tried to
>> get tick marks every 10 by adding
>>
>> yasp=(0, 100, 10)
>>
>> but this had no effect at all. I know I can draw the axis and tick
>> marks manually, but often this simple option would suffice if I could
>> understand how to make it work.
>>
>> Thanks in advance,
>>
>> Denis Chabot
>>
>
>
> I suspect that one problem you are having is that there is no
> par("xasp") or par("yasp")....unless these are typos and you are  
> trying
> to use par("xaxp") and par("yaxp")?
>
> There is an 'asp' argument to some of the plot functions (ie.
> plot.default), but this has a different intention.
>
> par("xaxp") and par("yaxp") are not listed as read only pars in ?par,
> however, I cannot recall an instance where R does not overwrite the  
> user
> settings during the calculation of the axes, whether passed as  
> arguments
> to a plot function or set a priori via a par() call.
>
> If you want explicit control over the tick marks, you will need to use
> axis(), perhaps in combination with axTicks(), after using 'xaxt =  
> "n"'
> and/or 'yaxt = "n"' in the plot call, depending upon the  
> circumstances.
>
> HTH,
>
> Marc Schwartz
>
>
>



From nmi13 at ext.canterbury.ac.nz  Sat Oct  8 17:31:06 2005
From: nmi13 at ext.canterbury.ac.nz (nmi13)
Date: Sun, 09 Oct 2005 04:31:06 +1300
Subject: [R] request
Message-ID: <43492270@webmail>

Dear All,

Can someone please tell me if there is a provision in R to fit a random 
coefficient multinomial logistic regression.

Thanks in advance for your help and suggestions.

Regards
Murthy.N.M



From ripley at stats.ox.ac.uk  Sat Oct  8 17:37:40 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 8 Oct 2005 16:37:40 +0100 (BST)
Subject: [R] how to control ticks in plots with yasp or xasp
In-Reply-To: <1128784599.4108.19.camel@localhost.localdomain>
References: <mailman.10.1128506401.6195.r-help@stat.math.ethz.ch>
	<EF4C19CB-AB0B-4A61-827C-9A491C11DCC7@globetrotter.net>
	<1128784599.4108.19.camel@localhost.localdomain>
Message-ID: <Pine.LNX.4.61.0510081631370.5376@gannet.stats>

On Sat, 8 Oct 2005, Marc Schwartz wrote:

> On Sat, 2005-10-08 at 09:28 -0400, Denis Chabot wrote:
>> Hi,
>>
>> A few times I tried to control the number and position of tick marks
>> in plots with the yasp or xasp parameters. For example, a y axis was
>> drawn by default with tick marks at 0, 20, 40, 80 and 100. I tried to
>> get tick marks every 10 by adding
>>
>> yasp=(0, 100, 10)
>>
>> but this had no effect at all. I know I can draw the axis and tick
>> marks manually, but often this simple option would suffice if I could
>> understand how to make it work.
>>
>> Thanks in advance,
>>
>> Denis Chabot
>
>
> I suspect that one problem you are having is that there is no
> par("xasp") or par("yasp")....unless these are typos and you are trying
> to use par("xaxp") and par("yaxp")?

In any case, (0, 100, 10) is invalid syntax, and c(0, 100, 10) is needed.

> There is an 'asp' argument to some of the plot functions (ie.
> plot.default), but this has a different intention.
>
> par("xaxp") and par("yaxp") are not listed as read only pars in ?par,
> however, I cannot recall an instance where R does not overwrite the user
> settings during the calculation of the axes, whether passed as arguments
> to a plot function or set a priori via a par() call.

Really?  Try

> plot(1:100, xaxt="n")
> par(xaxp=c(0, 50, 5))  # the value is reset at each plot
> axis(1)

for how it works (but not inline, which is probably a bug).

> If you want explicit control over the tick marks, you will need to use
> axis(), perhaps in combination with axTicks(), after using 'xaxt = "n"'
> and/or 'yaxt = "n"' in the plot call, depending upon the circumstances.

That is usually as easy.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sat Oct  8 17:41:39 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 8 Oct 2005 16:41:39 +0100 (BST)
Subject: [R] add leading 0s to %d from png() {was Automatic creation of
 file names}
In-Reply-To: <8d5a36350510080826k4f594b59xf7ef5fbc5420e061@mail.gmail.com>
References: <8d5a36350510080826k4f594b59xf7ef5fbc5420e061@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0510081638260.5376@gannet.stats>

The example on the png help page, "Rplot%03d.png", _is_ what you want.
(More details are on ?postscript.)

formatC() is an S/R peculiarity: sprintf() is the cross-language way to do 
this sort of thing.

On Sat, 8 Oct 2005, bogdan romocea wrote:

> Dear useRs,
>
> Is there a way to 'properly' format %d when plotting more than one
> page on png()? 'Properly' means to me with leading 0s, so that the
> PNGs become easy to navigate in a file/image browser. Lacking a better
> solution I ended up using the code below, but would much prefer
> something like
>   png("test_%d.png",bg="white",width=1000,height=700)
> where %d could be formatted like
>   formatC(%d,digits=0,wid=3,flag="0",mode="integer")
>
> Thank you,
> b.
>
> #---works, but is rather complicated---
> pngno <- 0 ; i <- 1
> for (w in 1:53) {
>  if (i %in% c(4*0:100+1)) {
>    pngno <- pngno + 1
>    png(paste("test_",formatC(pngno,digits=0,wid=4,flag="0",mode="integer"),
>      ".png",sep=""),bg="white",width=1000,height=750)
>    par(mfrow=c(2,2),mai=c(4,5,3,2)/10,omi=c(0.2,0,0,0),
>      cex.axis=1,cex.main=1.2)
>    }
>  plot(1:10,main=w)
>  if (i %in% c(4*1:100)) dev.off()
>  i <- i+1
>  }
> dev.off()
>
>
>> From: Mike Prager <Mike.Prager <at> noaa.gov>
>> Subject: Re: [R] Automatic creation of file names
>> Newsgroups: gmane.comp.lang.r.general
>> Date: 2005-09-22 14:51:54 GMT (2 weeks, 1 day, 23 hours and 55 minutes ago)
>>
>> Walter --
>>
>> P.S.  The advantage of using formatC over pasting the digits (1:1000)
>> directly is that when one uses leading zeroes, as in the formatC example
>> shown, the resulting filenames will sort into proper order.
>>
>> ...MHP
>>
>> You can use paste() with something like
>>
>> formatC(number,digits=0,wid=3,flag="0")
>>
>> (where number is your loop index) to generate the filenames.
>>
>> on 9/22/2005 10:21 AM Leite,Walter said the following:
>>
>>> I have a question about how to save to the hard drive the one thousand
>>> datasets I generated in a simulation. ://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Sat Oct  8 17:56:58 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 08 Oct 2005 17:56:58 +0200
Subject: [R] how to control ticks in plots with yasp or xasp
In-Reply-To: <9E3101AD-998E-43A9-A2FA-EC79DC3FE389@globetrotter.net>
References: <mailman.10.1128506401.6195.r-help@stat.math.ethz.ch>
	<EF4C19CB-AB0B-4A61-827C-9A491C11DCC7@globetrotter.net>
	<1128784599.4108.19.camel@localhost.localdomain>
	<9E3101AD-998E-43A9-A2FA-EC79DC3FE389@globetrotter.net>
Message-ID: <x2oe60knn9.fsf@turmalin.kubism.ku.dk>

Denis Chabot <chabotd at globetrotter.net> writes:

> Oops, Mark, bad typo indeed.
> 
> But yaxp is what I had in my R program and it did not help.
> 
> I did obtain control over my tick marks by drawing them myself, as  
> you suggest. But I was curious as to how to use yaxp since the help  
> on "par" gives it as a possible way of controlling ticks. Maybe it  
> should be removed from the help file?

plot(1)
par("xaxp")
par(xaxp=c(.6,1.4,8))
axis(3)

So it does do something...

 
> Thanks for your help,
> 
> Denis
> Le 05-10-08 ?? 11:16, Marc Schwartz a ??crit :
> 
> > On Sat, 2005-10-08 at 09:28 -0400, Denis Chabot wrote:
> >
> >> Hi,
> >>
> >> A few times I tried to control the number and position of tick marks
> >> in plots with the yasp or xasp parameters. For example, a y axis was
> >> drawn by default with tick marks at 0, 20, 40, 80 and 100. I tried to
> >> get tick marks every 10 by adding
> >>
> >> yasp=(0, 100, 10)
> >>
> >> but this had no effect at all. I know I can draw the axis and tick
> >> marks manually, but often this simple option would suffice if I could
> >> understand how to make it work.
> >>
> >> Thanks in advance,
> >>
> >> Denis Chabot
> >>
> >
> >
> > I suspect that one problem you are having is that there is no
> > par("xasp") or par("yasp")....unless these are typos and you are  
> > trying
> > to use par("xaxp") and par("yaxp")?
> >
> > There is an 'asp' argument to some of the plot functions (ie.
> > plot.default), but this has a different intention.
> >
> > par("xaxp") and par("yaxp") are not listed as read only pars in ?par,
> > however, I cannot recall an instance where R does not overwrite the  
> > user
> > settings during the calculation of the axes, whether passed as  
> > arguments
> > to a plot function or set a priori via a par() call.
> >
> > If you want explicit control over the tick marks, you will need to use
> > axis(), perhaps in combination with axTicks(), after using 'xaxt =  
> > "n"'
> > and/or 'yaxt = "n"' in the plot call, depending upon the  
> > circumstances.
> >
> > HTH,
> >
> > Marc Schwartz
> >
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From MSchwartz at mn.rr.com  Sat Oct  8 17:58:49 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Sat, 08 Oct 2005 10:58:49 -0500
Subject: [R] how to control ticks in plots with yasp or xasp
In-Reply-To: <Pine.LNX.4.61.0510081631370.5376@gannet.stats>
References: <mailman.10.1128506401.6195.r-help@stat.math.ethz.ch>
	<EF4C19CB-AB0B-4A61-827C-9A491C11DCC7@globetrotter.net>
	<1128784599.4108.19.camel@localhost.localdomain>
	<Pine.LNX.4.61.0510081631370.5376@gannet.stats>
Message-ID: <1128787129.4108.34.camel@localhost.localdomain>

On Sat, 2005-10-08 at 16:37 +0100, Prof Brian Ripley wrote:
> On Sat, 8 Oct 2005, Marc Schwartz wrote:
> 
> > On Sat, 2005-10-08 at 09:28 -0400, Denis Chabot wrote:
> >> Hi,
> >>
> >> A few times I tried to control the number and position of tick marks
> >> in plots with the yasp or xasp parameters. For example, a y axis was
> >> drawn by default with tick marks at 0, 20, 40, 80 and 100. I tried to
> >> get tick marks every 10 by adding
> >>
> >> yasp=(0, 100, 10)
> >>
> >> but this had no effect at all. I know I can draw the axis and tick
> >> marks manually, but often this simple option would suffice if I could
> >> understand how to make it work.
> >>
> >> Thanks in advance,
> >>
> >> Denis Chabot
> >
> >
> > I suspect that one problem you are having is that there is no
> > par("xasp") or par("yasp")....unless these are typos and you are trying
> > to use par("xaxp") and par("yaxp")?
> 
> In any case, (0, 100, 10) is invalid syntax, and c(0, 100, 10) is needed.

Indeed.

> > There is an 'asp' argument to some of the plot functions (ie.
> > plot.default), but this has a different intention.
> >
> > par("xaxp") and par("yaxp") are not listed as read only pars in ?par,
> > however, I cannot recall an instance where R does not overwrite the user
> > settings during the calculation of the axes, whether passed as arguments
> > to a plot function or set a priori via a par() call.
> 
> Really?  Try
> 
> > plot(1:100, xaxt="n")
> > par(xaxp=c(0, 50, 5))  # the value is reset at each plot
> > axis(1)
> 
> for how it works (but not inline, which is probably a bug).

Ah....I had not thought about that 'par'ticular combination...  ;-)

Hence, not R.O.  So it must be used _after_ a plot call, which makes
sense.

I had reached for my copy of Paul's book and on page 96 (last paragraph
in section 3.4.5 on Axes), he suggests using the approach I elucidate
below with axTicks(). I thought he might have some other ideas and that
I was missing something. This is also referenced on page 70, third
paragraph in section 3.2.5 on Axes.

> > If you want explicit control over the tick marks, you will need to use
> > axis(), perhaps in combination with axTicks(), after using 'xaxt = "n"'
> > and/or 'yaxt = "n"' in the plot call, depending upon the circumstances.
> 
> That is usually as easy.

Agreed.

Thanks,

Marc



From ajayshah at mayin.org  Sat Oct  8 18:38:49 2005
From: ajayshah at mayin.org (Ajay Narottam Shah)
Date: Sat, 8 Oct 2005 22:08:49 +0530
Subject: [R] Rpart -- using predict() when missing data is present?
Message-ID: <20051008163849.GT444@lubyanka.local>

I am doing

> library(rpart)
> m <- rpart("y ~ x", D[insample,])
> D[outsample,]
            y           x
8  0.78391922 0.579025591
9  0.06629211          NA
10         NA 0.001593063
>   p <- predict(m, newdata=D[9,])
Error in model.frame(formula, rownames, variables, varnames, extras, extranames,  : 
	invalid result from na.action

How do I persuade him to give me NA since x is NA?

I looked at ?predict.rpart but didn't find any mention about NAs.

(In this problem, I can easily do it manually, but this is a part of
something bigger where I want him to be able to gracefully handle
prediction requests involving NA).

-- 
Ajay Shah                                                   Consultant
ajayshah at mayin.org                      Department of Economic Affairs
http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi



From chabotd at globetrotter.net  Sat Oct  8 18:17:50 2005
From: chabotd at globetrotter.net (Denis Chabot)
Date: Sat, 08 Oct 2005 12:17:50 -0400
Subject: [R] how to control ticks in plots with yasp or xasp
In-Reply-To: <1128787129.4108.34.camel@localhost.localdomain>
References: <mailman.10.1128506401.6195.r-help@stat.math.ethz.ch>
	<EF4C19CB-AB0B-4A61-827C-9A491C11DCC7@globetrotter.net>
	<1128784599.4108.19.camel@localhost.localdomain>
	<Pine.LNX.4.61.0510081631370.5376@gannet.stats>
	<1128787129.4108.34.camel@localhost.localdomain>
Message-ID: <670BD00B-F077-4780-A003-12F1FBC30DCE@globetrotter.net>

Hi, sorry about the bad syntax, though the right syntax would not  
have worked either, according to your tests (Mark, Brian, Peter).

Anyway it is too finicky, I will draw them myself. For instance,

plot(1:100, xaxt="n")
par(xaxp=c(0, 100, 10))  # the value is reset at each plot
axis(1)

Placed tick marks at intervals at 0, 10, ..., 100, as expected, but  
did not place a label under 100...

Thanks for the answers, usufull as always,

Denis


Le 05-10-08 ?? 11:58, Marc Schwartz a ??crit :

> On Sat, 2005-10-08 at 16:37 +0100, Prof Brian Ripley wrote:
>
>> On Sat, 8 Oct 2005, Marc Schwartz wrote:
>>
>>
>>> On Sat, 2005-10-08 at 09:28 -0400, Denis Chabot wrote:
>>>
>>>> Hi,
>>>>
>>>> A few times I tried to control the number and position of tick  
>>>> marks
>>>> in plots with the yasp or xasp parameters. For example, a y axis  
>>>> was
>>>> drawn by default with tick marks at 0, 20, 40, 80 and 100. I  
>>>> tried to
>>>> get tick marks every 10 by adding
>>>>
>>>> yasp=(0, 100, 10)
>>>>
>>>> but this had no effect at all. I know I can draw the axis and tick
>>>> marks manually, but often this simple option would suffice if I  
>>>> could
>>>> understand how to make it work.
>>>>
>>>> Thanks in advance,
>>>>
>>>> Denis Chabot
>>>>
>>>
>>>
>>> I suspect that one problem you are having is that there is no
>>> par("xasp") or par("yasp")....unless these are typos and you are  
>>> trying
>>> to use par("xaxp") and par("yaxp")?
>>>
>>
>> In any case, (0, 100, 10) is invalid syntax, and c(0, 100, 10) is  
>> needed.
>>
>
> Indeed.
>
>
>>> There is an 'asp' argument to some of the plot functions (ie.
>>> plot.default), but this has a different intention.
>>>
>>> par("xaxp") and par("yaxp") are not listed as read only pars in ? 
>>> par,
>>> however, I cannot recall an instance where R does not overwrite  
>>> the user
>>> settings during the calculation of the axes, whether passed as  
>>> arguments
>>> to a plot function or set a priori via a par() call.
>>>
>>
>> Really?  Try
>>
>>
>>> plot(1:100, xaxt="n")
>>> par(xaxp=c(0, 50, 5))  # the value is reset at each plot
>>> axis(1)
>>>
>>
>> for how it works (but not inline, which is probably a bug).
>>
>
> Ah....I had not thought about that 'par'ticular combination...  ;-)
>
> Hence, not R.O.  So it must be used _after_ a plot call, which makes
> sense.
>
> I had reached for my copy of Paul's book and on page 96 (last  
> paragraph
> in section 3.4.5 on Axes), he suggests using the approach I elucidate
> below with axTicks(). I thought he might have some other ideas and  
> that
> I was missing something. This is also referenced on page 70, third
> paragraph in section 3.2.5 on Axes.
>
>
>>> If you want explicit control over the tick marks, you will need  
>>> to use
>>> axis(), perhaps in combination with axTicks(), after using 'xaxt  
>>> = "n"'
>>> and/or 'yaxt = "n"' in the plot call, depending upon the  
>>> circumstances.
>>>
>>
>> That is usually as easy.
>>
>
> Agreed.
>
> Thanks,
>
> Marc
>
>
>



From ripley at stats.ox.ac.uk  Sat Oct  8 19:21:50 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 8 Oct 2005 18:21:50 +0100 (BST)
Subject: [R] how to control ticks in plots with yasp or xasp
In-Reply-To: <670BD00B-F077-4780-A003-12F1FBC30DCE@globetrotter.net>
References: <mailman.10.1128506401.6195.r-help@stat.math.ethz.ch>
	<EF4C19CB-AB0B-4A61-827C-9A491C11DCC7@globetrotter.net>
	<1128784599.4108.19.camel@localhost.localdomain>
	<Pine.LNX.4.61.0510081631370.5376@gannet.stats>
	<1128787129.4108.34.camel@localhost.localdomain>
	<670BD00B-F077-4780-A003-12F1FBC30DCE@globetrotter.net>
Message-ID: <Pine.LNX.4.61.0510081813370.6666@gannet.stats>

On Sat, 8 Oct 2005, Denis Chabot wrote:

> Hi, sorry about the bad syntax, though the right syntax would not have worked 
> either, according to your tests (Mark, Brian, Peter).

It DOES work according to my tests!  (Do give us the credit for testing 
our advice:  we would appreciate your showing equal care.)

> Anyway it is too finicky, I will draw them myself. For instance,
>
> plot(1:100, xaxt="n")
> par(xaxp=c(0, 100, 10))  # the value is reset at each plot
> axis(1)
>
> Placed tick marks at intervals at 0, 10, ..., 100, as expected, but did not 
> place a label under 100...

Does for me (2.2.0, Windows and X11 on Linux).  Might the text be clipped 
on your unnamed device, so you need to set xpd?  (If so, it will be 
clipped however you try to do this, and is an unrelated local problem.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From chabotd at globetrotter.net  Sat Oct  8 19:36:48 2005
From: chabotd at globetrotter.net (Denis Chabot)
Date: Sat, 08 Oct 2005 13:36:48 -0400
Subject: [R] how to control ticks in plots with yasp or xasp
In-Reply-To: <Pine.LNX.4.61.0510081813370.6666@gannet.stats>
References: <mailman.10.1128506401.6195.r-help@stat.math.ethz.ch>
	<EF4C19CB-AB0B-4A61-827C-9A491C11DCC7@globetrotter.net>
	<1128784599.4108.19.camel@localhost.localdomain>
	<Pine.LNX.4.61.0510081631370.5376@gannet.stats>
	<1128787129.4108.34.camel@localhost.localdomain>
	<670BD00B-F077-4780-A003-12F1FBC30DCE@globetrotter.net>
	<Pine.LNX.4.61.0510081813370.6666@gannet.stats>
Message-ID: <FBDF7E84-A403-4B5B-9A75-FA1C7CA07F31@globetrotter.net>

Hi Brian,
Le 05-10-08 ?? 13:21, Prof Brian Ripley a ??crit :

> On Sat, 8 Oct 2005, Denis Chabot wrote:
>
>
>> Hi, sorry about the bad syntax, though the right syntax would not  
>> have worked either, according to your tests (Mark, Brian, Peter).
>>
>
> It DOES work according to my tests!  (Do give us the credit for  
> testing our advice:  we would appreciate your showing equal care.)

I am very sorry, I did not express myself properly. I do appreciate  
your help, and I did take the time to test your solution. What I  
meant was that even if I had use the proper syntax, i.e. yaxp=c 
(10,100,10) instead of y=(10,100,10) [actually in my program I had  
used it but I was careless when I composed the message], it would not  
have worked because you demonstrated that it has to be used within a  
"par" statement, which I had not done. Therefore my attempt was  
doomed. I did not mean there was no way to make yaxp work, so I  
apologize if you think I take your advice lightly, and I cannot state  
strongly enough that it is not the case at all.
>
>
>> Anyway it is too finicky, I will draw them myself. For instance,
>>
>> plot(1:100, xaxt="n")
>> par(xaxp=c(0, 100, 10))  # the value is reset at each plot
>> axis(1)
>>
>> Placed tick marks at intervals at 0, 10, ..., 100, as expected,  
>> but did not place a label under 100...
>>
>
> Does for me (2.2.0, Windows and X11 on Linux).  Might the text be  
> clipped on your unnamed device, so you need to set xpd?  (If so, it  
> will be clipped however you try to do this, and is an unrelated  
> local problem.)
>
>
This is strange.

I work on Mac OS X, so the default device is quartz. Label 100 is  
shown without clipping if plot without changing xaxp. But just in  
case I made more space at the right of the graph with

par(mai=c(0.7, 0.7, 0.5, 0.5))
plot(1:100, xaxt="n")
par(xaxp=c(0, 100, 10))  # the value is reset at each plot
axis(1)

and the 100 does not appear. If I run this again:
plot(1:100, xaxt="n")
axis(1)

I'm back with R's default axis and the 100 is present. Anyone on a  
Mac wants to try?

Denis


> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From ripley at stats.ox.ac.uk  Sat Oct  8 20:07:32 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 8 Oct 2005 19:07:32 +0100 (BST)
Subject: [R] Rpart -- using predict() when missing data is present?
In-Reply-To: <20051008163849.GT444@lubyanka.local>
References: <20051008163849.GT444@lubyanka.local>
Message-ID: <Pine.LNX.4.61.0510081835560.6948@gannet.stats>

On Sat, 8 Oct 2005, Ajay Narottam Shah wrote:

> I am doing
>
>> library(rpart)
>> m <- rpart("y ~ x", D[insample,])
>> D[outsample,]
>            y           x
> 8  0.78391922 0.579025591
> 9  0.06629211          NA
> 10         NA 0.001593063
>>   p <- predict(m, newdata=D[9,])
> Error in model.frame(formula, rownames, variables, varnames, extras, extranames,  :
> 	invalid result from na.action
>
> How do I persuade him to give me NA since x is NA?

I think the point is to do something sensible!  One x prediction problems 
are not what rpart is designed to do, and the default na.action (na.rpart) 
fails in that case.  (The author forgot drop=F.)

> I looked at ?predict.rpart but didn't find any mention about NAs.

How about ?rpart ?  That does.

> (In this problem, I can easily do it manually, but this is a part of
> something bigger where I want him to be able to gracefully handle
> prediction requests involving NA).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wang at math.s.chiba-u.ac.jp  Sun Oct  9 01:09:51 2005
From: wang at math.s.chiba-u.ac.jp (Jinfang Wang)
Date: Sun, 9 Oct 2005 08:09:51 +0900
Subject: [R] quasi-random vector according to an independent graph
References: <355C35514FEAC9458F75947F5270974D076CFA@usctmx1103.merck.com>
Message-ID: <003a01c5cc5d$63254960$030ba8c0@IBM4D6040982F0>

Hi



I was waiting for more advices and prepared to summarize to reduce the mail 
traffic. I got two answers (I realize that my explanation was definitely 
insufficient).



Thanks Reid & Spencer !?The link http://www.r-project.org/gR/ was helpful, 
although it does not directly answer my question.



I think I have got some idea to do what I want. When I have a more or less 
satisfactory solution I will report to the list to share (if I think it is 
worthwhile).



Jinfang Wang







----- Original Message ----- 
From: "Huntsinger, Reid" <reid_huntsinger at merck.com>
To: "'Spencer Graves'" <spencer.graves at pdf.com>; "Jinfang Wang" 
<wang at math.s.chiba-u.ac.jp>
Cc: <r-help at stat.math.ethz.ch>
Sent: Friday, September 30, 2005 2:00 AM
Subject: RE: [R] quasi-random vector according to an independent graph


> Might the "graphical models in R" packages be of interest?
> http://www.r-project.org/gR/
>
> Reid Huntsinger
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Spencer Graves
> Sent: Thursday, September 29, 2005 11:43 AM
> To: Jinfang Wang
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] quasi-random vector according to an independent graph
>
>
>   Are you still interested in a reply to this post?  I have not seen
>
> any.  If you are, it might help if you were more specific, e.g.,
> following the posting guide "www.R-project.org/posting-guide.html".  I'm
> not certain what you mean by "a joint distribution defined by an
> independent graph", and my efforts using "RSiteSearch" exposed several
> things that might be useful but none that seemed to me to be obvious
> answers to your question.
>
>   Sorry I could not be more helpful.
>   spencer graves
>
> Jinfang Wang wrote:
>
>> Dear R-users,
>>
>> Is anyone aware of any function/package for generating a random vector
> from
>> a joint distribution defined by an independent graph? Or I have to work 
>> it
>
>> out myself?
>>
>> Thanks.
>>
>> Jinfang
>>
>> ------------------------------
>> Jinfang Wang, Associate Professor
>> Chiba University, Japan
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>
> -- 
> Spencer Graves, PhD
> Senior Development Engineer
> PDF Solutions, Inc.
> 333 West San Carlos Street Suite 700
> San Jose, CA 95110, USA
>
> spencer.graves at pdf.com
> www.pdf.com <http://www.pdf.com>
> Tel:  408-938-4420
> Fax: 408-280-7915
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>
>
>
> ------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any attachment...{{dropped}}



From spencer.graves at pdf.com  Sun Oct  9 01:58:42 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 08 Oct 2005 16:58:42 -0700
Subject: [R] quasi-random vector according to an independent graph
In-Reply-To: <003a01c5cc5d$63254960$030ba8c0@IBM4D6040982F0>
References: <355C35514FEAC9458F75947F5270974D076CFA@usctmx1103.merck.com>
	<003a01c5cc5d$63254960$030ba8c0@IBM4D6040982F0>
Message-ID: <43485D32.3050301@pdf.com>

Hi, Jihfang:

	  Definitely, please report to the list when you think you "have a more
or less satisfactory solution".  The archives are searchable, and your
comments might help someone else.  They might also provoke useful
suggestions of other things you might try that might provide even better
solutions.

	  Also, if you get stuck in the process, please report to the list your
progress and where you are stuck.

	  Good Luck,
	  spencer graves

Jinfang Wang wrote:
> Hi
> 
> 
> 
> I was waiting for more advices and prepared to summarize to reduce the 
> mail traffic. I got two answers (I realize that my explanation was 
> definitely insufficient).
> 
> 
> 
> Thanks Reid & Spencer !?The link http://www.r-project.org/gR/ was 
> helpful, although it does not directly answer my question.
> 
> 
> 
> I think I have got some idea to do what I want. When I have a more or 
> less satisfactory solution I will report to the list to share (if I 
> think it is worthwhile).
> 
> 
> 
> Jinfang Wang
> 
> 
> 
> 
> 
> 
> 
> ----- Original Message ----- From: "Huntsinger, Reid" 
> <reid_huntsinger at merck.com>
> To: "'Spencer Graves'" <spencer.graves at pdf.com>; "Jinfang Wang" 
> <wang at math.s.chiba-u.ac.jp>
> Cc: <r-help at stat.math.ethz.ch>
> Sent: Friday, September 30, 2005 2:00 AM
> Subject: RE: [R] quasi-random vector according to an independent graph
> 
> 
>> Might the "graphical models in R" packages be of interest?
>> http://www.r-project.org/gR/
>>
>> Reid Huntsinger
>>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Spencer Graves
>> Sent: Thursday, September 29, 2005 11:43 AM
>> To: Jinfang Wang
>> Cc: r-help at stat.math.ethz.ch
>> Subject: Re: [R] quasi-random vector according to an independent graph
>>
>>
>>   Are you still interested in a reply to this post?  I have not seen
>>
>> any.  If you are, it might help if you were more specific, e.g.,
>> following the posting guide "www.R-project.org/posting-guide.html".  I'm
>> not certain what you mean by "a joint distribution defined by an
>> independent graph", and my efforts using "RSiteSearch" exposed several
>> things that might be useful but none that seemed to me to be obvious
>> answers to your question.
>>
>>   Sorry I could not be more helpful.
>>   spencer graves
>>
>> Jinfang Wang wrote:
>>
>>> Dear R-users,
>>>
>>> Is anyone aware of any function/package for generating a random vector
>>
>> from
>>
>>> a joint distribution defined by an independent graph? Or I have to 
>>> work it
>>
>>
>>> out myself?
>>>
>>> Thanks.
>>>
>>> Jinfang
>>>
>>> ------------------------------
>>> Jinfang Wang, Associate Professor
>>> Chiba University, Japan
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide!
>>
>> http://www.R-project.org/posting-guide.html
>>
>> -- 
>> Spencer Graves, PhD
>> Senior Development Engineer
>> PDF Solutions, Inc.
>> 333 West San Carlos Street Suite 700
>> San Jose, CA 95110, USA
>>
>> spencer.graves at pdf.com
>> www.pdf.com <http://www.pdf.com>
>> Tel:  408-938-4420
>> Fax: 408-280-7915
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>>
>>
>> ------------------------------------------------------------------------------ 
>>
>> Notice:  This e-mail message, together with any attachments, contains 
>> information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, 
>> New Jersey, USA 08889), and/or its affiliates (which may be known 
>> outside the United States as Merck Frosst, Merck Sharp & Dohme or MSD 
>> and in Japan, as Banyu) that may be confidential, proprietary 
>> copyrighted and/or legally privileged. It is intended solely for the 
>> use of the individual or entity named on this message.  If you are not 
>> the intended recipient, and have received this message in error, 
>> please notify us immediately by reply e-mail and then delete it from 
>> your system.
>> ------------------------------------------------------------------------------ 
>>
>>
>>
> 
> 

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From hodgess at gator.dt.uh.edu  Sun Oct  9 05:16:35 2005
From: hodgess at gator.dt.uh.edu (Erin Hodgess)
Date: Sat, 8 Oct 2005 22:16:35 -0500
Subject: [R]  lm.ridge
Message-ID: <200510090316.j993GZ4E003594@gator.dt.uh.edu>

Dear R People:

I have a question about the lm.ridge function, please.

In the example, there is one set of output values in the "select"
function but another in the comment section.

Am I missing something please?


R Version 2.1.1 Windows

Thanks,
Sincerely,
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
mailto: hodgess at gator.uhd.edu



From sourceforge at metrak.com  Sun Oct  9 07:30:42 2005
From: sourceforge at metrak.com (sosman)
Date: Sun, 09 Oct 2005 15:30:42 +1000
Subject: [R] Warning: condition has length > 1
In-Reply-To: <BAY102-DAV15E5D27A02E3383C0B0DB6B3870@phx.gbl>
References: <BAY102-DAV15E5D27A02E3383C0B0DB6B3870@phx.gbl>
Message-ID: <4348AB02.7010602@metrak.com>

nawaf b wrote:
> Hi -
> 
> I was wondering if anyone came across a problem such as mine! I was trying
> to create a user-defined function, however, the results from calling the
> function are unexpected!
> 
> When passing X parameter as a single value variable (x<-c(3)), everything
> works fine. However, when passing a parameter as a vector with multiple
> values (as the case in my code), the 'if condition' is only executed once!
> 
> Here is my code:
> 
>>x
> 
> [1]  0.3  1.0  0.7 22.0
> 
>>myfunction<-function(x)
> 
> + {
> + if (x>=1) 0
> + else x^2
> + }
> 
>>myfunction(x)
> 
> [1]   0.09   1.00   0.49 484.00
> Warning message:
> the condition has length > 1 and only the first element will be used in: if
> (x >= 1) 0 else x^2 
> 
> 
> Is there a way to overcome this issue? Can you please explain what
> modifications to the code I need to accommodate to make it work.

I am going to go out on a limb here (I don't know much about R) but I'm 
not sure it has anything to do with that fact that you have defined a 
function.

It seems to me that "if (x > 1) {...}" expects a scalar and if x is not 
a scalar, it will use the first value.  To apply your function to each 
element, check out the help for sapply (eg ?sapply).  I am guessing the 
solution is something like sapply(x, myfunction) but don't quote me.

paul sorenson



From w.northcott at unsw.edu.au  Sun Oct  9 07:45:04 2005
From: w.northcott at unsw.edu.au (Bill Northcott)
Date: Sun, 9 Oct 2005 15:45:04 +1000
Subject: [R] R-2.2.0 compilation problem
In-Reply-To: <mailman.9.1128679200.29073.r-help@stat.math.ethz.ch>
References: <mailman.9.1128679200.29073.r-help@stat.math.ethz.ch>
Message-ID: <37446094-3B7F-4D8A-9D5A-476563D3FC78@unsw.edu.au>

On 07/10/2005, at 8:00 PM, Robin Hankin wrote:
> I tried to compile R-2.2.0 just now.  configure worked fine, but
> compilation stopped with


>
> ld: Undefined symbols:
> restFP
> saveFP
> /usr/bin/libtool: internal link edit command failed
> make[3]: *** [libR.dylib] Error 1
> make[2]: *** [R] Error 2
> make[1]: *** [R] Error 1
> make: *** [R] Error 1
> octopus:~/scratch/R-2.2.0%

This has been written up many times already.  It would be nice if it  
was in the documentation.

g77 can only be used with gcc-3.x and earlier.  The default compiler  
on Tiger is gcc-4.

All you need to do to build with g77 on Tiger is use the command
sudo gcc_select 3.3
which will make gcc-3.3 the default compiler and it will all work.

Bill Northcott



From A.Robinson at ms.unimelb.edu.au  Sun Oct  9 07:49:08 2005
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sun, 9 Oct 2005 15:49:08 +1000
Subject: [R] Warning: condition has length > 1
In-Reply-To: <4348AB02.7010602@metrak.com>
References: <BAY102-DAV15E5D27A02E3383C0B0DB6B3870@phx.gbl>
	<4348AB02.7010602@metrak.com>
Message-ID: <20051009054908.GF57718@ms.unimelb.edu.au>

ifelse() should work too.

Andrew

On Sun, Oct 09, 2005 at 03:30:42PM +1000, sosman wrote:
> nawaf b wrote:
> > Hi -
> > 
> > I was wondering if anyone came across a problem such as mine! I was trying
> > to create a user-defined function, however, the results from calling the
> > function are unexpected!
> > 
> > When passing X parameter as a single value variable (x<-c(3)), everything
> > works fine. However, when passing a parameter as a vector with multiple
> > values (as the case in my code), the 'if condition' is only executed once!
> > 
> > Here is my code:
> > 
> >>x
> > 
> > [1]  0.3  1.0  0.7 22.0
> > 
> >>myfunction<-function(x)
> > 
> > + {
> > + if (x>=1) 0
> > + else x^2
> > + }
> > 
> >>myfunction(x)
> > 
> > [1]   0.09   1.00   0.49 484.00
> > Warning message:
> > the condition has length > 1 and only the first element will be used in: if
> > (x >= 1) 0 else x^2 
> > 
> > 
> > Is there a way to overcome this issue? Can you please explain what
> > modifications to the code I need to accommodate to make it work.
> 
> I am going to go out on a limb here (I don't know much about R) but I'm 
> not sure it has anything to do with that fact that you have defined a 
> function.
> 
> It seems to me that "if (x > 1) {...}" expects a scalar and if x is not 
> a scalar, it will use the first value.  To apply your function to each 
> element, check out the help for sapply (eg ?sapply).  I am guessing the 
> solution is something like sapply(x, myfunction) but don't quote me.
> 
> paul sorenson
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Andrew Robinson
Senior Lecturer in Statistics                       Tel: +61-3-8344-9763
Department of Mathematics and Statistics            Fax: +61-3-8344-4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au



From roebuck at wotan.mdacc.tmc.edu  Sun Oct  9 09:36:38 2005
From: roebuck at wotan.mdacc.tmc.edu (Paul Roebuck)
Date: Sun, 9 Oct 2005 02:36:38 -0500 (CDT)
Subject: [R] sscanf equivalent
In-Reply-To: <Pine.LNX.4.61.0510071839120.32476@gannet.stats>
References: <Pine.OSF.4.58.0510071156580.212100@wotan.mdacc.tmc.edu>
	<Pine.LNX.4.61.0510071839120.32476@gannet.stats>
Message-ID: <Pine.OSF.4.58.0510090058280.95993@wotan.mdacc.tmc.edu>

On Fri, 7 Oct 2005, Prof Brian Ripley wrote:

> On Fri, 7 Oct 2005, Paul Roebuck wrote:
>
> > I have a data file from which I need to read portions of
> > data but data location/quantity can change from file to file.
> > I wrote some code and have a working solution but it seems
> > wasteful to have to do it this way. Here's the contrived
> > incomplete code.
> >
> >    datalines <- readLines(datafile.pathname)
> >    # marker will appear on line preceding and following
> >    # actual data
> >    offset.data <- grep("marker", datalines)
> >    datalines <- NULL
> >
> >    # grab first column of each assoc dataline
> >    data <- scan(datafile.pathname,
> >                 what = numeric(0),
> >                 skip = offset.data[1],
> >                 nlines = offset.data[2]-offset.data[1]-1,
> >                 flush = TRUE,
> >                 multi.line = FALSE,
> >                 quiet = TRUE)
> >    # output is vector of values
> >
> > Originally wrote code to parse data from 'datalines'
> > using sub and strsplit methods but it was woefully slower
> > and more complex than using scan method. What is desired
> > is a means of invoking method like scan but with existing
> > data instead of filename.
>
> Why not use a text connection?

I tried that but result was far slower than the method above.

R> file.info(datafile.pathname)$size
[1] 944850
R> system.time(datalines<-readLines(datafile.pathname), TRUE)[3]
[1] 0.59
R> length(datalines)
[1] 67931
R> system.time(tconn<-textConnection(datalines), TRUE)[3]
[1] 52.97

Once a textConnection object was created, the scan method
invocation using it took less than half the time of the
corresponding filename-based invocation. Problem is that
this was only taking a second to perform the scan using
the filename-based invocation. And since grep method doesn't
accept textConnection as argument, I still require the
otherwise unused 'datalines' variable and its associated
memory. Even if grep supported such, the timing increased
even more not having the variable.

R> system.time(tconn<-textConnection(readLines(datafile.pathname)), TRUE)[3]
[1] 66.61


Any other thoughts?


# R version 2.1.1, 2005-06-20, powerpc-apple-darwin7.9.0

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From bioconductor.cn at gmail.com  Sun Oct  9 11:26:55 2005
From: bioconductor.cn at gmail.com (Xiao Shi)
Date: Sun, 9 Oct 2005 17:26:55 +0800
Subject: [R] How to get the remaining vector after sampling a subset?
Message-ID: <cedaa40b0510090226x3d2d3242ua12d5dc1431203eb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051009/46643779/attachment.pl

From sundar.dorai-raj at pdf.com  Sun Oct  9 11:41:46 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Sun, 09 Oct 2005 04:41:46 -0500
Subject: [R] How to get the remaining vector after sampling a subset?
In-Reply-To: <cedaa40b0510090226x3d2d3242ua12d5dc1431203eb@mail.gmail.com>
References: <cedaa40b0510090226x3d2d3242ua12d5dc1431203eb@mail.gmail.com>
Message-ID: <4348E5DA.1040103@pdf.com>



Xiao Shi wrote:
> Hi ,
> I have a vector,for example,
> x=rnorm(100)
> Then i rendom choose 20 of them.
> chosen=sample(x,20).
> And i want to get the remain values in x.
> Is there a quick way to go?
> 
> Thanks in advance.
> 
> 	[[alternative HTML version deleted]]
> 

How about:

x <- rnorm(100)
y <- sample(x, 20)
z <- x[!x %in% y]

But probably a safer way is to sample the indicies:

x <- rnorm(100)
w <- sample(length(x), 20)
y <- x[w]
z <- x[-w]

HTH,

--sundar



From dimitris.rizopoulos at med.kuleuven.be  Sun Oct  9 11:45:59 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Sun, 9 Oct 2005 11:45:59 +0200
Subject: [R] How to get the remaining vector after sampling a subset?
References: <cedaa40b0510090226x3d2d3242ua12d5dc1431203eb@mail.gmail.com>
Message-ID: <014501c5ccb6$40e34ec0$0540210a@www.domain>

one way is to use:

x[!x %in% chosen]


I hope it helps.

Best,
Dimitris


----- Original Message ----- 
From: "Xiao Shi" <bioconductor.cn at gmail.com>
To: <r-help at stat.math.ethz.ch>
Sent: Sunday, October 09, 2005 11:26 AM
Subject: [R] How to get the remaining vector after sampling a subset?


> Hi ,
> I have a vector,for example,
> x=rnorm(100)
> Then i rendom choose 20 of them.
> chosen=sample(x,20).
> And i want to get the remain values in x.
> Is there a quick way to go?
>
> Thanks in advance.
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From ripley at stats.ox.ac.uk  Sun Oct  9 13:37:34 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 9 Oct 2005 12:37:34 +0100 (BST)
Subject: [R] lm.ridge
In-Reply-To: <200510090316.j993GZ4E003594@gator.dt.uh.edu>
References: <200510090316.j993GZ4E003594@gator.dt.uh.edu>
Message-ID: <Pine.LNX.4.61.0510091236470.32664@gannet.stats>

On Sat, 8 Oct 2005, Erin Hodgess wrote:

> Dear R People:
>
> I have a question about the lm.ridge function, please.
>
> In the example, there is one set of output values in the "select"
> function but another in the comment section.
>
> Am I missing something please?

The values in the examples were computed in S-PLUS.  Apparently the 
dataset in R is not the same as that in S-PLUS.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kb2qzv at poczta.wp.pl  Sun Oct  9 15:53:17 2005
From: kb2qzv at poczta.wp.pl (Benedict P. Barszcz)
Date: Sun, 9 Oct 2005 15:53:17 +0200
Subject: [R] Rmetrics fMultivar how to?
Message-ID: <200510091553.17893.kb2qzv@poczta.wp.pl>

Hi Everybody,
I am a total beginner at this so please bear with me.
I downloaded by hand the file WIG20.txt (Warsaw Stock Exchange Index of 20 
most important stocks). The format is this:

Name,Date,Open,High,Low,Close,Volume 
WIG20,19940414,1000.00,1000.00,1000.00,1000.00,71600.000 
WIG20,19940418,1050.50,1050.50,1050.50,1050.50,99950.000 
WIG20,19940419,1124.90,1124.90,1124.90,1124.90,138059.000 
WIG20,19940421,1304.80,1304.80,1304.80,1304.80,154151.000 
WIG20,19940425,1350.10,1350.10,1350.10,1350.10,228438.000 
WIG20,19940426,1216.20,1216.20,1216.20,1216.20,16618.000 
WIG20,19940428,1096.70,1096.70,1096.70,1096.70,32685.000 
WIG20,19940505,1138.10,1138.10,1138.10,1138.10,113777.000 
WIG20,19940506,1077.60,1077.60,1077.60,1077.60,137910.000 
WIG20,19940509,1035.60,1035.60,1035.60,1035.60,97091.000

I read the data in with this command:

>tabelka = read.table("/home/kb2qzv/WIG20.txt",sep=",",header=TRUE)

And I can see that 'tabelka' has 2840 rows in it which is correct (this many 
sessions since the Exchange started operating).
Now I would like to utilize some of the functions available from RMetrics and 
see how useful they might be. I can image that one way to know this would be 
to plot a candlestick chart of the wig20 index and below it a TA indicator, 
like one of these:

macdTA      MACD Indicator
cdsTA     MACD Signal Line
cdoTA      MACD Oscillator
vohlTA High/Low Volatility

Trouble is there is no easy way (for me as a beginner) to start with.
Questions:
A) how to plot a candlestick chart with my data?
there seems to be no 'type=candlestick' parameter in plot() function.

B) how to create a second pane where an indicator can be drawn.

thanks for any answers or tips.


-- 
Benedict

Cyfrowy klucz publiczny / Digital public key 
http://agrypa1.atspace.com/klucze/kb2qzv_wp.pl-public.asc



From bernarduse1 at yahoo.fr  Sun Oct  9 16:32:10 2005
From: bernarduse1 at yahoo.fr (Marc Bernard)
Date: Sun, 9 Oct 2005 16:32:10 +0200 (CEST)
Subject: [R] background color of xyplot
Message-ID: <20051009143210.4425.qmail@web25809.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051009/aa6cb10c/attachment.pl

From 042045003 at fudan.edu.cn  Sun Oct  9 17:00:59 2005
From: 042045003 at fudan.edu.cn (ronggui)
Date: Sun, 09 Oct 2005 23:00:59 +0800
Subject: [R] background color of xyplot
Message-ID: <0IO300LT4L85BP@mail.fudan.edu.cn>

 see ?trellis.device

> trellis.device(color=F)
>  Depth <- equal.count(quakes$depth, number=8, overlap=.1)
>      xyplot(lat ~ long | Depth, data = quakes)


will get what you want.
	

======= 2005-10-09 22:32:10 ÄúÔÚÀ´ÐÅÖÐÐ´µÀ£º=======

>Dear All, 
> 
>I am wondering if there is a way to change the color  of  the panels of  the  xyplot  (lattice package) from "gray" to "white"  ......  Because the  printing  of the xyplot's graph is not  visible with the gray color ... I've seen the xyplot help  but without any success
> 
> 
>Thanks  lot in advance, 
> 
> 
>Bernard, 
> 
> 
>
>		
>---------------------------------
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

= = = = = = = = = = = = = = = = = = = =
			


 

2005-10-09

------
Deparment of Sociology
Fudan University



From vincent.goulet at act.ulaval.ca  Sun Oct  9 17:45:33 2005
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Sun, 09 Oct 2005 11:45:33 -0400
Subject: [R] color for points
In-Reply-To: <434792D2.1070903@7d4.com>
References: <20051008092215.88531.qmail@web30601.mail.mud.yahoo.com>
	<434792D2.1070903@7d4.com>
Message-ID: <200510091145.34211.vincent.goulet@act.ulaval.ca>

Le 8 Octobre 2005 05:35, vincent at 7d4.com a ??crit??:
> Sam R. Smith a ??crit :
> > Hi,
> > I have the following code to randomly generate the points:
> > csr <-function(n=60){
> > x=runif(n)
> > y=runif(n)
> > f=cbind(x,y)
> > }
> > plot(csr())
> >
> > I wonder how to code to make the first twenty points to be BLUE; second
> > twenty points to be RED; the last twenty points to be GREEN?
>
> mynewfct = function(n=60)
> {
> x=runif(n)
> y=runif(n)
> f=cbind(x,y)
> plot(f[1:20] , col='blue');
> par(new=T);
> plot(f[21:40] , col='red');
> par(new=T);
> plot(f[41:60] , col='green');
> }
>
> hih

This function will plot 60 points, no matter the value of argument 'n'. 
Building also on Jim Holtman's comment, may I rather suggest

csr <- function(n=60)
{
	x <- cbind(runif(n), runif(n))
	plot(x, col=rep(c("blue", "red", "green"), each=20, length.out=n))
	x   # why not return the values...
}

HTH

-- 
  Vincent Goulet, Professeur agr??g??
  ??cole d'actuariat
  Universit?? Laval, Qu??bec 
  Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca



From spencer.graves at pdf.com  Sun Oct  9 18:05:03 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 09 Oct 2005 09:05:03 -0700
Subject: [R] Glmm for multiple outcomes
In-Reply-To: <023301c5b7bb$5ccb4580$adca01a3@optima.ox.ac.uk>
References: <023301c5b7bb$5ccb4580$adca01a3@optima.ox.ac.uk>
Message-ID: <43493FAF.8070005@pdf.com>

Does the following help:

n.subjects <- 3
J <- 4
K <- 5
n.ijk <- rep(2, each=n.subjects*J*K)

x <- rep(1:K, n.subjects, each=J)

subj <- factor(rep(1:n.subjects, each=K*J))

sa.subject <- 1
sb.subject <- 1

set.seed(2)
a.subj <- rep(sa.subject*rnorm(n.subjects), each=K*J)
b.subj <- rep(sb.subject*rnorm(n.subjects), each=K*J)

Z <- a.subj+b.subj*x

library(boot)
Y <- (rbinom(n.subjects*K*J, n.ijk, inv.logit(Z))
          /n.ijk)

Dat <- data.frame(subj=subj, x=x, y=Y)

library(lme4)

fit <- lmer(y~x+(x|subj), Dat)
Linear mixed-effects model fit by REML
Formula: y ~ x + (x | subj)
    Data: Dat
       AIC      BIC    logLik MLdeviance REMLdeviance
  51.63172 64.19779 -19.81586    33.1066     39.63172
Random effects:
  Groups   Name        Variance  Std.Dev. Corr
  subj     (Intercept) 0.0446346 0.211269
           x           0.0032613 0.057108 1.000
  Residual             0.0879438 0.296553
# of obs: 60, groups: subj, 3

Fixed effects:
              Estimate Std. Error DF t value Pr(>|t|)
(Intercept)  0.350000   0.151459 58  2.3109  0.02442 *
x            0.033333   0.042661 58  0.7814  0.43777
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

	  spencer graves

Abderrahim Oulhaj wrote:

> Dear All,
> 
> I wonder if there is an efficient way to fit the  generalized linear mixed model  for multivariate outcomes.
> 
> More specifically, Suppose that for a given subject i and at a  given time j we observe a multivariate  outcome Yij = (Y_ij1, Y_ij2, ..., Y_ijK). 
>  where Y_ijk is a binomial(n_ijk, p_ijk). 
> 
> One way to jointly model  the data is to use the following specification:
> 
> g(p_ijk) = beta_0k + b_0ik + (beta_1k + b_1ik)*x_ijk  with k = 1,2 ...., K , g is a specified link function and (b_0ik,b_1ik) k=1,...K are random effects ...
> 
>  I my case, the glmmPQL converges only  and give good results when k is less than 3 (i.e. for a small number of random effects). I also used the gee (generalized estimating equations) to estimate the fixed effects and the same probleme ariseed with k.
> 
> Is there any help?
> 
> Thank you in advance, 
>  
> Abderrahim Oulhaj
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From dlvanbrunt at gmail.com  Sun Oct  9 21:14:50 2005
From: dlvanbrunt at gmail.com (David L. Van Brunt, Ph.D.)
Date: Sun, 9 Oct 2005 14:14:50 -0500
Subject: [R] Insert value from same column of another row (lag across
	observations)
Message-ID: <d332d3e10510091214h649a067fl1a8dab54326619f2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051009/f1ac016f/attachment.pl

From justin_bem at yahoo.fr  Sun Oct  9 22:15:41 2005
From: justin_bem at yahoo.fr (justin bem)
Date: Sun, 9 Oct 2005 22:15:41 +0200 (CEST)
Subject: [R] enter a survey design in survey2.9
Message-ID: <20051009201541.38902.qmail@web25702.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051009/a3ab9be6/attachment.pl

From MSchwartz at mn.rr.com  Sun Oct  9 23:44:35 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Sun, 09 Oct 2005 16:44:35 -0500
Subject: [R] Insert value from same column of another row (lag
	across	observations)
In-Reply-To: <d332d3e10510091214h649a067fl1a8dab54326619f2@mail.gmail.com>
References: <d332d3e10510091214h649a067fl1a8dab54326619f2@mail.gmail.com>
Message-ID: <1128894276.4108.78.camel@localhost.localdomain>

On Sun, 2005-10-09 at 14:14 -0500, David L. Van Brunt, Ph.D. wrote:
> I know I've done this before, but it's been a while and I can't find quite
> what I need in the help files or archives.
> 
> I have a text field in a very large data frame. I'd like to add a column
> that represents the value from an existing field, from the next record (the
> data are sorted). I'm trying to represent "what happens tomorrow", so the
> "today" row would have an "NA" value (unknown).
> 
> So if x is:
> > x
> [,1]
> [1,] "today"
> [2,] "yesterday"
> [3,] "the day before"
> [4,] "two days before"
> 
> any y is
> > cbind(x,c(1,2,3,4))
> [,1] [,2]
> [1,] "today" "1"
> [2,] "yesterday" "2"
> [3,] "the day before" "3"
> [4,] "two days before" "4"
> 
> 
> z should become
> 
> [,1] [,2] [,3]
> [1,] "today" "1" "NA"
> [2,] "yesterday" "2" "1"
> [3,] "the day before" "3" "2"
> [4,] "two days before" "4" "3"
> 
> I've tried
> z<-cbind(y,c("NA",y[-1,2]))
> 
> but I get
> [1,] "today" "1" "NA"
> [2,] "yesterday" "2" "2"
> [3,] "the day before" "3" "3"
> [4,] "two days before" "4" "4"
> 
> So the "lagging" doesn't work.
> 
> Any ideas?


You are close, but you are eliminating the first value in y[, 2] by
using '-1' rather than the last:

> z <- cbind(y, c(NA, y[-nrow(y), 2]))

> z
     [,1]              [,2] [,3]
[1,] "today"           "1"  NA
[2,] "yesterday"       "2"  "1"
[3,] "the day before"  "3"  "2"
[4,] "two days before" "4"  "3"

Do not quote the NA, as "NA" is a character vector, as opposed to a
missing value indicator. See ?NA for more information.

HTH,

Marc Schwartz



From spencer.graves at pdf.com  Mon Oct 10 00:15:30 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 09 Oct 2005 15:15:30 -0700
Subject: [R] Error using a data frame as the "start" parameter in mle()
In-Reply-To: <Pine.GSO.4.52.0509291658190.20685@sun49>
References: <Pine.GSO.4.52.0509291658190.20685@sun49>
Message-ID: <43499682.7040107@pdf.com>

	  I will attempt a brief comment on this post, as I've seen no replies. 
  It's difficult to comment on this, as you do not really provide enough 
information to permit someone like me to understand your problem.  Only 
one portion of this problem is the fact that I can't find your function 
"mle" in one of the standard libraries, and I don't know if it is part 
of a contributed library or something you wrote.

	  However, I've encountered problems roughly like what you describe, 
and I've solved them in three different ways:

	  (a) Making a local copy inside the wrapper function and then pass to 
the standard function like "mle" only arguments locally defined.

	  (b) Using "assign"  with (I think) something like "pos=0".  I don't 
remember exactly for that, and the help file for "assign" and several 
searches with RSiteSearch didn't help me.  If you want to try this, I 
suggest you look for information on "lexical scoping" with "assign", etc.

	  (c) Passing additional references via "..." if "mle" has such in its 
function definition.

	  If you still would like more help from this group, PLEASE do read the 
posting guide (www.R-project.org/posting-guide.html).  I believe people 
who follow that guide on average get more useful answers quicker.

	  Viel Gl??ck!
	  spencer graves

Coryn Bailer-Jones wrote:

> Dear R-Users,
> 
> I am trying to use mle() to optimize two (or more) parameters, but I want
> to specify those parmeters in a data frame rather than having to spell
> them out separately in the "start" variable of mle().
> 
> My call is
> 
> 
>>mle(negll, start=list(aps=init), fixed=list(measphot=newphot,
> 
>     formod=formod, Nbands=Nbands), method="BFGS")
> 
> where negll is a function I have written which uses the function
> predict.loess(). negll works fine when called directly. The parameter I am
> trying to optimize, "aps", is a data frame containing two parameters, e.g.
> 
> 
>>init
> 
>   teff logg
> 1 8000  4.5
> 
> When I run mle I get the following error message
> 
> Error in predict.loess(formod[[band]], aps) :
>         Argument "aps" is missing, with no default
> 
> As negll does work fine, I presume I am incorrectly passing "aps" into
> mle(). Note that mle() works fine if I rewrite negll to work on a scalar
> "aps" and then I use start=list(aps=500), for example. Can anyone help me
> with this?
> 
> Incidentally, I am only using a data frame for "aps" because I am using
> loess(), and this seems to require a formula with named variables in a
> data frame (here "logg" and "teff"). I can't get it work with arrays:
> 
> 
>>temp <- loess(formula = photd[, band] ~ gridaps[, 1] * gridaps[, 2])
>>predict(temp, c(4,8000))
> 
> Error in predict.loess(temp, c(4, 8000)) :
>         newdata does not contain the variables needed
> 
> Thanks in advance for any clues.
> 
> Coryn.
> 
> ---------------------------------------------------------------------------
> Coryn Bailer-Jones                    calj at mpia-hd.mpg.de
> Max-Planck-Institut fuer Astronomie   http://www.mpia-hd.mpg.de/homes/calj/
> Koenigstuhl 17                        tel: +49 6221 528-224        (direct)
> D-69117 Heidelberg                         +49 6221 528-0       (reception)
> Germany                               fax: +49 6221 528-246
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From tlumley at u.washington.edu  Mon Oct 10 03:30:12 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 9 Oct 2005 18:30:12 -0700 (PDT)
Subject: [R] Matrix calculations in R--erroneous?
In-Reply-To: <BF6C52BA.11E3B%pmuhl830@gmail.com>
References: <BF6C52BA.11E3B%pmuhl830@gmail.com>
Message-ID: <Pine.LNX.4.63a.0510091829450.21581@homer22.u.washington.edu>

On Fri, 7 Oct 2005, Peter Muhlberger wrote:
>
> The max function won't do the trick because I need the entire matrix.  I
> could do one cell at a time, but this is part of a ML routine that needs to
> be evaluated hundreds of thousands of times, so I can't afford to slow it
> down that much.

pmax, then?

 	-thomas



From debarr at mitre.org  Mon Oct 10 03:43:40 2005
From: debarr at mitre.org (DeBarr, Dave)
Date: Sun, 9 Oct 2005 21:43:40 -0400
Subject: [R] acf.plot() question
Message-ID: <F6F74E57C281CD42B4FBFB3ADF85B29B716E94@IMCSRV2.MITRE.ORG>

When I run the "acf()" function using the "acf(ts.union(mdeaths,
fdeaths))" example, the "acf()" function calls the "acf.plot()"
function to generate this plot...
http://members.cox.net/ddebarr/images/acf_example.png

The plot in the lower right-hand corner is labeled "fdeaths & mdeaths",
but the negative lags appear to belong to "mdeaths & fdeaths" [which
correspond to the positive lags of "fdeaths & mdeaths"].

Am I missing something, or should the plot in the lower right-hand
corner be labeled "mdeaths & fdeaths" (instead of "fdeaths & mdeaths")?

Note: The unit of measure for the lags is years.

> autocorrelation <- function(x, y, lags) {
+     n <- length(x)
+     x.bar <- mean(x)
+     y.bar <- mean(y)
+     c <- array(0, length(lags))
+     i <- 1
+     for (t in lags) {
+         s <- seq(max(1, 1 - t), min(n - t, n))
+         c[i] <- sum((x[s + t] - x.bar) * (y[s] - y.bar)) / n
+         i <- i + 1
+     }
+     x.sd <- sqrt(sum((x - x.bar) ^ 2) / n)
+     y.sd <- sqrt(sum((y - y.bar) ^ 2) / n)
+     return(c / (x.sd * y.sd))
+ }
> autocorrelation(mdeaths, fdeaths, -15:15)
 [1]  0.015054983  0.365626026  0.615427121  0.708206289  0.621895801
 [6]  0.340005447 -0.024534195 -0.381671430 -0.611793479 -0.677803477
[11] -0.604031174 -0.349468396  0.019759425  0.405200639  0.744309322
[16]  0.976241251  0.735668532  0.364241839 -0.010675725 -0.382920620
[21] -0.622386979 -0.688538519 -0.610583980 -0.383338305 -0.018112073
[26]  0.391983088  0.656592111  0.721397236  0.639104375  0.361352626
[31] -0.003385423
> autocorrelation(fdeaths, mdeaths, -15:15)
 [1] -0.003385423  0.361352626  0.639104375  0.721397236  0.656592111
 [6]  0.391983088 -0.018112073 -0.383338305 -0.610583980 -0.688538519
[11] -0.622386979 -0.382920620 -0.010675725  0.364241839  0.735668532
[16]  0.976241251  0.744309322  0.405200639  0.019759425 -0.349468396
[21] -0.604031174 -0.677803477 -0.611793479 -0.381671430 -0.024534195
[26]  0.340005447  0.621895801  0.708206289  0.615427121  0.365626026
[31]  0.015054983



From mjf at ansto.gov.au  Mon Oct 10 04:02:14 2005
From: mjf at ansto.gov.au (FISCHER, Matthew)
Date: Mon, 10 Oct 2005 12:02:14 +1000
Subject: [R] greek symbols using pch
Message-ID: <283982AD9F3CD211B3AC00A0C983032F11443674@paradise.ansto.gov.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051010/5b1240d6/attachment.pl

From gd340 at uow.edu.au  Mon Oct 10 04:26:47 2005
From: gd340 at uow.edu.au (Gareth Davies)
Date: Mon, 10 Oct 2005 12:26:47 +1000 (EST)
Subject: [R] possible bug in image() ??
Message-ID: <20051010122647.ATN14197@minerva.its.uow.edu.au>

Hi everyone. 
The function image() seems not to be correctly plotting some 
matrices that I give it. (Iâ€™m using R 2.1.1)   
The following code creates a matrix (denoted x) with 1500 
rows and 3 columns, with all entries 0 or 1, and then plots 
the image of this matrix.

 cc=runif(n=1500,min=0.1,max=1.2)
 ccc=ceiling(cc-1)
 dd=runif(n=1500,min=0.1,max=1.2)
 ddd=ceiling(dd-1)
 ee=runif(n=1500,min=0.1,max=1.2)
 eee=ceiling(ee-1)
 x=matrix(data=c(ccc,ddd,eee),nrow=1500)
 image(x)

..where the first column in x  (vector ccc) is depicted 
horizontally along the bottom of the image. However, when I 
overplot the non-zero elements of the vectors ccc, ddd and 
eee onto their respective horizontal positions on the 
image,..

 points(seq(0,1,1/(1500-1)),(ccc)^-1*0)
points(seq(0,1,1/(1500-1)),(ddd)^-1*0.5)
 points(seq(0,1,1/(1500-1)),(eee)^-1*1)


 â€¦the locations of the 1â€™s in image do not always match the 
locations of the 1â€™s in ccc,ddd, and eee (although they are 
mostly correct). Do other people find this problem?? I've 
tried with other matrices, and the results only seem in 
error when the matrix is large, say with more than 1000 
rows. 

Cheers, Gareth Davies



From MSchwartz at mn.rr.com  Mon Oct 10 04:34:57 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Sun, 09 Oct 2005 21:34:57 -0500
Subject: [R] greek symbols using pch
In-Reply-To: <283982AD9F3CD211B3AC00A0C983032F11443674@paradise.ansto.gov.au>
References: <283982AD9F3CD211B3AC00A0C983032F11443674@paradise.ansto.gov.au>
Message-ID: <1128911697.4108.95.camel@localhost.localdomain>

On Mon, 2005-10-10 at 12:02 +1000, FISCHER, Matthew wrote:
> 
> Hi R-users,
> 
>     In a plot, can I specify pch to be a greek symbol? (I looked at
> show.pch() in the Hmisc package but couldn't see the right symbols in there).
> If not, I guess I can get around this using text(x,y,expression()).
> 
> cheers!,
> 
> Matt.


You will need to use text() in order to plot greek characters as
plotting symbols.

The 'pch' argument (or par("pch")) must be a single character or an
integer specifying one of the symbols as seen in ?points or as you noted
in Frank's show.pch().

See ?plotmath for more information on plotting mathematical expressions.

HTH,

Marc Schwartz



From samrobertsmith at yahoo.com  Mon Oct 10 05:27:28 2005
From: samrobertsmith at yahoo.com (Sam R. Smith)
Date: Sun, 9 Oct 2005 20:27:28 -0700 (PDT)
Subject: [R] plot
Message-ID: <20051010032729.32773.qmail@web30612.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051009/f69227c8/attachment.pl

From Murraypu at aimnsw.com.au  Mon Oct 10 06:25:42 2005
From: Murraypu at aimnsw.com.au (Murray Pung)
Date: Mon, 10 Oct 2005 14:25:42 +1000
Subject: [R] plot
Message-ID: <3028F4C4647C9043B870276E28C69FD60134363E@syd05.aimnsw.com.au>

Select History > Recording.

You can see previous plots using 'page up'.

Murray

-----Original Message-----
From: Sam R. Smith [mailto:samrobertsmith at yahoo.com]
Sent: Monday, 10 October 2005 1:27 PM
To: r-help at stat.math.ethz.ch
Subject: [R] plot


After I made a new plot, the old plot can not be found. How can I check all the plots I have made?


		
---------------------------------

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From bernd.weiss at uni-koeln.de  Mon Oct 10 07:24:24 2005
From: bernd.weiss at uni-koeln.de (Bernd Weiss)
Date: Mon, 10 Oct 2005 07:24:24 +0200
Subject: [R] sqlFetch on MySQL-DB
Message-ID: <434A1728.20015.834113@localhost>

Dear all,

I successfully set up a local MySQL-database. Connecting via RODBC is 
not problem, the same in fetching 3 of 4 tables. But trying to 
connect to table 4 fails. 

> author<-sqlFetch(test,"author")
Error in fromchar(unclass(x)) : character string is not in a standard 
unambiguous format

In principle I understand that error message, but I don't know any 
solution. 

Thanks for any help,

Bernd


> version
         _                           
platform i386-pc-mingw32             
arch     i386                        
os       mingw32                     
system   i386, mingw32               
status   Under development (unstable)
major    2                           
minor    3.0                         
year     2005                        
month    10                          
day      06                          
svn rev  35759                       
language R



From samrobertsmith at yahoo.com  Mon Oct 10 07:35:30 2005
From: samrobertsmith at yahoo.com (Sam R. Smith)
Date: Sun, 9 Oct 2005 22:35:30 -0700 (PDT)
Subject: [R] line
Message-ID: <20051010053530.56101.qmail@web30612.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051009/29322301/attachment.pl

From samrobertsmith at yahoo.com  Mon Oct 10 07:37:44 2005
From: samrobertsmith at yahoo.com (Sam R. Smith)
Date: Sun, 9 Oct 2005 22:37:44 -0700 (PDT)
Subject: [R] line
In-Reply-To: <20051010053530.56101.qmail@web30612.mail.mud.yahoo.com>
Message-ID: <20051010053744.84393.qmail@web30611.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051009/0840a9eb/attachment.pl

From ozric at web.de  Mon Oct 10 07:51:00 2005
From: ozric at web.de (christian schulz)
Date: Mon, 10 Oct 2005 07:51:00 +0200
Subject: [R] sqlFetch on MySQL-DB
In-Reply-To: <434A1728.20015.834113@localhost>
References: <434A1728.20015.834113@localhost>
Message-ID: <434A0144.706@web.de>

Hi,

there is a problem with the type of  attributes - is it varchar!?
IMHO you should play a bit with different type's in mysql and the 
consequence in R.

I recognize "similar" problems with RMySQL, if you have  variables with 
type decimal in mysql
you get numerics in chr. But it's possible to change the decimal in  
double  (mysql) to get num in R.

regards, Christian


>Dear all,
>
>I successfully set up a local MySQL-database. Connecting via RODBC is 
>not problem, the same in fetching 3 of 4 tables. But trying to 
>connect to table 4 fails. 
>
>  
>
>>author<-sqlFetch(test,"author")
>>    
>>
>Error in fromchar(unclass(x)) : character string is not in a standard 
>unambiguous format
>
>In principle I understand that error message, but I don't know any 
>solution. 
>
>Thanks for any help,
>
>Bernd
>
>
>  
>
>>version
>>    
>>
>         _                           
>platform i386-pc-mingw32             
>arch     i386                        
>os       mingw32                     
>system   i386, mingw32               
>status   Under development (unstable)
>major    2                           
>minor    3.0                         
>year     2005                        
>month    10                          
>day      06                          
>svn rev  35759                       
>language R
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>



From vincent at 7d4.com  Mon Oct 10 08:17:05 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Mon, 10 Oct 2005 08:17:05 +0200
Subject: [R] possible bug in image() ??
In-Reply-To: <20051010122647.ATN14197@minerva.its.uow.edu.au>
References: <20051010122647.ATN14197@minerva.its.uow.edu.au>
Message-ID: <434A0761.4010902@7d4.com>

Gareth Davies a Ã©crit :

> Hi everyone. 
> The function image() seems not to be correctly plotting some 
> matrices that I give it. (Iâ€™m using R 2.1.1)   
> ..where the first column in x  (vector ccc) is depicted 
> horizontally along the bottom of the image. 

Hello,
here's a way to have an image according the usual view.

timage = function(M)
{
M1 = M;
for (i in 1:nrow(M)) M1[i,] = M[nrow(M)-i+1,];
image(t(M1));
}

hih



From pekar at sci.muni.cz  Mon Oct 10 08:59:33 2005
From: pekar at sci.muni.cz (pekar@sci.muni.cz)
Date: Mon, 10 Oct 2005 08:59:33 +0200 (MEST)
Subject: [R] (no subject)
Message-ID: <1263.147.251.26.133.1128927573.squirrel@elanor.sci.muni.cz>

Hello,
Can anybody tell me, please, how to get a matrix of SE of differences (or
any SE) from a GLM object? Both model.tables and se.contrast work only for
ANOVA objects. I remember there was a "disp s" directive in GLIM package.
I would need something like that.

Many thanks.
Wishes,
Stano Pekar



From domenico.cozzetto at uniroma1.it  Mon Oct 10 09:06:59 2005
From: domenico.cozzetto at uniroma1.it (Domenico Cozzetto)
Date: Mon, 10 Oct 2005 09:06:59 +0200
Subject: [R] details about lm()
Message-ID: <BHEOLDJKKPGKLNNLPCLMAEODCBAA.domenico.cozzetto@uniroma1.it>

Dear all,
I'd like to get a linear regression of some data, and impose that the line
goes through a given point P. I've tried to use the lm() method in the
package "stats", but I wasn't able to specify the coordinates of the point
P. Maybe I should use another method?
I also have another question: How does lm() choose the point through which
the output straight line goes in order to compute the values of its slope
and intercept?

I would be very grateful if anyone could help me.
Domenico

*********************************************

Domenico Cozzetto
Biocomputing group
Department of Biochemical Sciences
"A. Rossi Fanelli"
University of Rome "La Sapienza"
P.le Aldo Moro, 5 - 00185 Rome
Tel: +39 06 49690276
Fax: +39 06 4400062
URL: http://cassandra.bio.uniroma1.it/~cozzetto/



From tastard at cict.fr  Mon Oct 10 09:09:03 2005
From: tastard at cict.fr (Emmanuelle TASTARD)
Date: Mon, 10 Oct 2005 09:09:03 +0200
Subject: [R] interpretation output glmmPQL
Message-ID: <001701c5cd69$7f5a1f40$e2697882@st226edb>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051010/cfa9b6ca/attachment.pl

From olivier.eterradossi at ema.fr  Mon Oct 10 09:18:52 2005
From: olivier.eterradossi at ema.fr (Olivier ETERRADOSSI)
Date: Mon, 10 Oct 2005 09:18:52 +0200
Subject: [R] R version 2.01.1, Crimson Editor and the "one" from nowhere
References: <43467653.3070701@ema.fr> <4347948C.4010204@sciviews.org>
Message-ID: <434A15DC.20205@ema.fr>

Thanks a lot, really, Philippe, for this explanation... and sorry for 
taking some of your time.
Of course your guess is right : I turned to French (and "forgot" to 
tell...). So I'll use your second suggestion (turn to english in MDI).
Once again this list works amazingly well !
Olivier

Philippe Grosjean a ??crit:

> ... OK, I have spot the problem: TpR.exe expects RGui running in 
> English. Shortcut for the Windows menu is Alt-w, which is what it 
> sends to R. Then, it sends "1", meaning, activate first window (the 
> console). You have probably RGui running in French, or in another 
> language. In French the menu is called "Fen??tres", with the 
> corresponding shortcut being Alt-n. Consequently, the menu is not 
> triggered and the "1" is send to the command line.
>
> Two solutions to continue using TpR.exe with R 2.1.1 or more:
> 1) Switch R in SDI mode,
> 2) Use RGui in MDI mode, but in English.
>
> The third solution is to patch TpR.exe, which I will not do, because I 
> need to program a separate command for each different language of R!
> Best,
>
> Philippe Grosjean
>
> ..............................................<??}))><........
>  ) ) ) ) )
> ( ( ( ( (    Prof. Philippe Grosjean
>  ) ) ) ) )
> ( ( ( ( (    Numerical Ecology of Aquatic Systems
>  ) ) ) ) )   Mons-Hainaut University, Pentagone (3D08)
> ( ( ( ( (    Academie Universitaire Wallonie-Bruxelles
>  ) ) ) ) )   8, av du Champ de Mars, 7000 Mons, Belgium
> ( ( ( ( (
>  ) ) ) ) )   phone: + 32.65.37.34.97, fax: + 32.65.37.30.54
> ( ( ( ( (    email: Philippe.Grosjean at umh.ac.be
>  ) ) ) ) )
> ( ( ( ( (    web:   http://www.umh.ac.be/~econum
>  ) ) ) ) )          http://www.sciviews.org
> ( ( ( ( (
> ..............................................................
>
> Olivier ETERRADOSSI wrote:
>
>> Dear List....
>> sorry to bother you R-gurus with such an "unstatistical" question... 
>> but I face a problem using Crimson Editor with R 2.01.1 that I never 
>> had using R 2.00.1.
>> I already posted on the Crimson Editor forum but it seems to be VERY 
>> few R-users there....
>>
>> I successfully used R v2.00.1until now (under Windows XP 
>> professionnal, version 2002, Service Pack 2, P4 processor CPU 1.8 
>> GHz), together with Crimson Editor.
>> This editor is "linked" to R using three files (TpR.exe, R.SPC and 
>> R.KEYS).
>> I recently upgraded to R 2.01.1.
>> I kept using my old TpR.exe, R.SPC and R.KEYS, because I did not find 
>> any new files on the Crimson Editor "Release" web page.
>> When I now launch a script, instead of getting my old, well known 
>> prompt :
>>  > source("C:/Program Files/R/fooscript.txt")
>> I get :
>>  > 1source("C:/Program Files/R/fooscript.txt")
>> with a "1" in front of the line.... and of course R  greets me with a 
>> "syntax error" message.
>> Then I have to remove the "1" by hand (pretty prehistoric, ...and 
>> does not work if  my script is meant to launch other scripts during 
>> the night....)
>> I cannot figure where this "1" comes from !!
>> Did some of you already encountered this problem, and how did you get 
>> rid of it ?
>> Thanks a lot, have a nice week-end. Olivier
>>
>
>

-- 
Olivier ETERRADOSSI
Ma??tre-Assistant
CMGD / Equipe "Propri??t??s Psycho-Sensorielles des Mat??riaux"
Ecole des Mines d'Al??s
H??lioparc, 2 av. P. Angot, F-64053 PAU CEDEX 9
tel: +33 (0)5.59.30.54.25
fax: +33 (0)5.59.30.63.68
http://www.ema.fr



From ripley at stats.ox.ac.uk  Mon Oct 10 09:41:29 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 10 Oct 2005 08:41:29 +0100 (BST)
Subject: [R] sqlFetch on MySQL-DB
In-Reply-To: <434A1728.20015.834113@localhost>
References: <434A1728.20015.834113@localhost>
Message-ID: <Pine.LNX.4.61.0510100837130.457@gannet.stats>

On Mon, 10 Oct 2005, Bernd Weiss wrote:

> I successfully set up a local MySQL-database. Connecting via RODBC is
> not problem, the same in fetching 3 of 4 tables. But trying to
> connect to table 4 fails.
>
>> author<-sqlFetch(test,"author")
> Error in fromchar(unclass(x)) : character string is not in a standard
> unambiguous format

Try traceback() after an error that is lacking context: it would have 
helped.

> In principle I understand that error message, but I don't know any
> solution.

You have a date or datetime or timestamp column that is not in a format R 
recognizes.  Use argument 'as.is' to bring it across as character.  See 
?sqlGetResults (referenced from ?sqlFetch).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Mon Oct 10 09:48:16 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 10 Oct 2005 09:48:16 +0200
Subject: [R] possible bug in image() ??
In-Reply-To: <20051010122647.ATN14197@minerva.its.uow.edu.au>
References: <20051010122647.ATN14197@minerva.its.uow.edu.au>
Message-ID: <434A1CC0.6020906@statistik.uni-dortmund.de>

I guess what you see is the limited resolution of your screen rather 
than a bug in R.
Try to produce a reliably image, e.g. some pdf file:

pdf("test.pdf")
   cc=runif(n=1500,min=0.1,max=1.2)
   ccc=ceiling(cc-1)
   dd=runif(n=1500,min=0.1,max=1.2)
   ddd=ceiling(dd-1)
   ee=runif(n=1500,min=0.1,max=1.2)
   eee=ceiling(ee-1)
   x=matrix(data=c(ccc,ddd,eee),nrow=1500)
   image(x)
   points(seq(0,1,1/(1500-1)),(ccc)^-1*0, pch=".")
   points(seq(0,1,1/(1500-1)),(ddd)^-1*0.5, pch=".")
   points(seq(0,1,1/(1500-1)),(eee)^-1*1, pch=".")
dev.off()

and zoom in now ....


Uwe Ligges



Gareth Davies wrote:

> Hi everyone. 
> The function image() seems not to be correctly plotting some 
> matrices that I give it. (Iâ€™m using R 2.1.1)   
> The following code creates a matrix (denoted x) with 1500 
> rows and 3 columns, with all entries 0 or 1, and then plots 
> the image of this matrix.
> 
>  cc=runif(n=1500,min=0.1,max=1.2)
>  ccc=ceiling(cc-1)
>  dd=runif(n=1500,min=0.1,max=1.2)
>  ddd=ceiling(dd-1)
>  ee=runif(n=1500,min=0.1,max=1.2)
>  eee=ceiling(ee-1)
>  x=matrix(data=c(ccc,ddd,eee),nrow=1500)
>  image(x)
> 
> ..where the first column in x  (vector ccc) is depicted 
> horizontally along the bottom of the image. However, when I 
> overplot the non-zero elements of the vectors ccc, ddd and 
> eee onto their respective horizontal positions on the 
> image,..
> 
>  points(seq(0,1,1/(1500-1)),(ccc)^-1*0)
> points(seq(0,1,1/(1500-1)),(ddd)^-1*0.5)
>  points(seq(0,1,1/(1500-1)),(eee)^-1*1)
> 
> 
>  â€¦the locations of the 1â€™s in image do not always match the 
> locations of the 1â€™s in ccc,ddd, and eee (although they are 
> mostly correct). Do other people find this problem?? I've 
> tried with other matrices, and the results only seem in 
> error when the matrix is large, say with more than 1000 
> rows. 
> 
> Cheers, Gareth Davies
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Mon Oct 10 09:59:53 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 10 Oct 2005 09:59:53 +0200
Subject: [R] ATLAS version for Rblas.dll under Windows; was: (no subject)
In-Reply-To: <1128709798.4346bea68518a@webmail.stanford.edu>
References: <1128709798.4346bea68518a@webmail.stanford.edu>
Message-ID: <434A1F79.3050402@statistik.uni-dortmund.de>

Bing Ho wrote:

> Hello,
> 
> I noticed that the README found in /bin/windows/contrib/ATLAS indicates that
> the ATLAS version is 3.4.1. According to the ATLAS sourceforge site, 3.6.0
> the latest stable version.
> 
> Does anybody know if the ATLAS Rblas.dll are 3.4.1 or 3.6.0, and if they are
> not the latest version, is there a technical reason why they have not been
> updated?

Version is as indicated 3.4.1.
The reason is that nobody had a reason to build updated versions.

If you are volunteering to build Rblas.dll files based on new ATLAS 
versions for various platforms such as P2, P3, P4, Xeon, AthlonXP, 
Athlon64 (32-bit), you are welocme to contribute, of course.

Uwe Ligges


> Thank you,
> Bing Ho
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Allan at STATS.uct.ac.za  Mon Oct 10 10:06:51 2005
From: Allan at STATS.uct.ac.za (Clark Allan)
Date: Mon, 10 Oct 2005 10:06:51 +0200
Subject: [R] R: integration problem
Message-ID: <434A211B.B87991C6@STATS.uct.ac.za>

hi all 

an integration problem. i would like an exact or good approximation for
the following, but i do not want to use a computer. any suggestions:


integral of exp(b*x)/sqrt(1-x^2)

where "b" is a constant greater than or equal to 0
and
the integral runs from 0 to 1


any help would be apreciated

/
allan

From vincent at 7d4.com  Mon Oct 10 10:09:22 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Mon, 10 Oct 2005 10:09:22 +0200
Subject: [R] details about lm()
In-Reply-To: <BHEOLDJKKPGKLNNLPCLMAEODCBAA.domenico.cozzetto@uniroma1.it>
References: <BHEOLDJKKPGKLNNLPCLMAEODCBAA.domenico.cozzetto@uniroma1.it>
Message-ID: <434A21B2.6020106@7d4.com>

Domenico Cozzetto a ??crit :

> Dear all,
> I'd like to get a linear regression of some data, and impose that the line
> goes through a given point P. I've tried to use the lm() method in the
> package "stats", but I wasn't able to specify the coordinates of the point
> P. Maybe I should use another method?

add directly P in your data is also a way



From Lorenz.Gygax at fat.admin.ch  Mon Oct 10 10:21:50 2005
From: Lorenz.Gygax at fat.admin.ch (Lorenz.Gygax@fat.admin.ch)
Date: Mon, 10 Oct 2005 10:21:50 +0200
Subject: [R] interpretation output glmmPQL
Message-ID: <BF74FADD4B44554CA7E53D0B5242CD6A034FF098@evd-s7014.bk.evdad.admin.ch>


> We study the effect of several variables on fruit set for 44 
> individuals (plants). For each individual, we have the number
> of fruits, the number of flowers and a value for each variable.
> ...
> - Glm does not take account of the correlation between the
> flowers of a unique individual. So we would like to add a 
> random effect 'individual' but the model2 (here after) gives an
> output similar to the one of model1 for estimated coefficients
> and p-values. 
> ...
> Does it mean that there is no individual effect or is my model
> not good (number of groups (individuals)=number of observations,
> is it possible?).

If you have only one observation per indiviudal plant, how could there be
dependence within the plant? This would only make sense if your observations
were the individual flowers. Data on those could be correlated within plant
and then a random term for the plant is meaningful.

Cheers, Lorenz
- 
Lorenz Gygax
Centre for proper housing of ruminants and pigs
Swiss Federal Veterinary Office
agroscope FAT T??nikon, CH-8356 Ettenhausen / Switzerland



From ligges at statistik.uni-dortmund.de  Mon Oct 10 10:55:12 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 10 Oct 2005 10:55:12 +0200
Subject: [R] details about lm()
In-Reply-To: <434A21B2.6020106@7d4.com>
References: <BHEOLDJKKPGKLNNLPCLMAEODCBAA.domenico.cozzetto@uniroma1.it>
	<434A21B2.6020106@7d4.com>
Message-ID: <434A2C70.7010209@statistik.uni-dortmund.de>

vincent at 7d4.com wrote:

> Domenico Cozzetto a ??crit :
> 
> 
>>Dear all,
>>I'd like to get a linear regression of some data, and impose that the line
>>goes through a given point P. I've tried to use the lm() method in the
>>package "stats", but I wasn't able to specify the coordinates of the point
>>P. Maybe I should use another method?
> 
> 
> add directly P in your data is also a way

No!

Please, both of you, consult a basic textbook on linear regression.

You can transform the data (linear) so that P becomes (0,0), after that 
  you can estimate the slope without intercept by specifying
  lm(y ~ x - 1)
The slope estimate is still valid while your intercept can be calculated 
afterwards.

Uwe Ligges


> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From RKrug at sun.ac.za  Mon Oct 10 10:56:54 2005
From: RKrug at sun.ac.za (Rainer M. Krug)
Date: Mon, 10 Oct 2005 10:56:54 +0200
Subject: [R] Show Progress in loop
Message-ID: <434A2CD6.1080409@sun.ac.za>

Hi

I have a loop which is doing time consuming calculations and I would 
like to be able to have some feedback on where it is in it's 
calculations. I tried to simply show the counter variable in the loop, 
but id doesn't work as all display seems to be delayed until the loop is 
completed. Is there any way of displaying the progress of a loop?

Rainer

The loop:

for (i in 2:Result$NoSims)
{
	ppp <- runifpoint(Result$NoPlants)
	K <- Kest(ppp)
	Result$LSim[i,] <- sqrt(K$iso / pi) - K$r
	CM <- (Result$LSim[i,] * Result$LSim[i,]) / abs(K$r[2] - K$r[1])
	Result$SigCM[i] <- sum(CM, na.rm=TRUE)
	i  #<========================Doesn't display in the loop
}

-- 
Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
Biology (UCT)

Department of Conservation Ecology
University of Stellenbosch
Matieland 7602
South Africa



From p.dalgaard at biostat.ku.dk  Mon Oct 10 11:00:18 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Oct 2005 11:00:18 +0200
Subject: [R] Show Progress in loop
In-Reply-To: <434A2CD6.1080409@sun.ac.za>
References: <434A2CD6.1080409@sun.ac.za>
Message-ID: <x2psqdkaql.fsf@viggo.kubism.ku.dk>

"Rainer M. Krug" <RKrug at sun.ac.za> writes:

> Hi
> 
> I have a loop which is doing time consuming calculations and I would 
> like to be able to have some feedback on where it is in it's 
> calculations. I tried to simply show the counter variable in the loop, 
> but id doesn't work as all display seems to be delayed until the loop is 
> completed. Is there any way of displaying the progress of a loop?
> 
> Rainer
> 
> The loop:
> 
> for (i in 2:Result$NoSims)
> {
> 	ppp <- runifpoint(Result$NoPlants)
> 	K <- Kest(ppp)
> 	Result$LSim[i,] <- sqrt(K$iso / pi) - K$r
> 	CM <- (Result$LSim[i,] * Result$LSim[i,]) / abs(K$r[2] - K$r[1])
> 	Result$SigCM[i] <- sum(CM, na.rm=TRUE)
> 	i  #<========================Doesn't display in the loop
> }

Just print(i) and if on Windows, remember to unset output buffering. 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ligges at statistik.uni-dortmund.de  Mon Oct 10 11:06:11 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 10 Oct 2005 11:06:11 +0200
Subject: [R] question about ways to solve nonlinear system
In-Reply-To: <FCCB21C198A64341A78B24E06AE7C8D3031B2E9E@coe-exchange01.ad.ufl.edu>
References: <FCCB21C198A64341A78B24E06AE7C8D3031B2E9E@coe-exchange01.ad.ufl.edu>
Message-ID: <434A2F03.30304@statistik.uni-dortmund.de>

Leite,Walter wrote:

> Dear R users
> 
> 
> I am trying to write an R function to solve for a,b,c in the following
> system of equations, given any value of x1, x2 and x3:
> b^2 + 6*b*a + 2*c^2 + 15*a^2 = x1
> 2*c*(b^2 + 24*b*a + 105*a^2 + 2) = x2
> 24*(b*a + c^2*(1 + b^2 + 28*b*a) + a*(12 + 48 *b*a + 141*c^2 + 225*a^2))
> =x3
> 
> Could you give me suggestions about which R function(s) I can use to
> solve this problem and how I should use these functions? 
> Thank you very much for your assistance,
> 
> Walter Leite
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


R itself cannot calculate symbolically (which is what you want to do it 
in this case, I guess), "just" numerically.

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Mon Oct 10 11:09:55 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 10 Oct 2005 11:09:55 +0200
Subject: [R] Show Progress in loop
In-Reply-To: <434A2CD6.1080409@sun.ac.za>
References: <434A2CD6.1080409@sun.ac.za>
Message-ID: <434A2FE3.3040209@statistik.uni-dortmund.de>

Rainer M. Krug wrote:

> Hi
> 
> I have a loop which is doing time consuming calculations and I would 
> like to be able to have some feedback on where it is in it's 
> calculations. I tried to simply show the counter variable in the loop, 
> but id doesn't work as all display seems to be delayed until the loop is 
> completed. Is there any way of displaying the progress of a loop?
> 
> Rainer
> 
> The loop:
> 
> for (i in 2:Result$NoSims)
> {
> 	ppp <- runifpoint(Result$NoPlants)
> 	K <- Kest(ppp)
> 	Result$LSim[i,] <- sqrt(K$iso / pi) - K$r
> 	CM <- (Result$LSim[i,] * Result$LSim[i,]) / abs(K$r[2] - K$r[1])
> 	Result$SigCM[i] <- sum(CM, na.rm=TRUE)
> 	i  #<========================Doesn't display in the loop
> }
> 


- Update your console (I guess you are on Windows?) by using 
flush.console().
- You might want to measure time consumption, hence see ?Rprof.
- Save some more time by moving as much as possible out of your loop by 
doing it in a vectorized way (I don't know all the functions you are 
using, hence cannot make any further recommendations).

Uwe Ligges



From RKrug at sun.ac.za  Mon Oct 10 11:08:45 2005
From: RKrug at sun.ac.za (Rainer M. Krug)
Date: Mon, 10 Oct 2005 11:08:45 +0200
Subject: [R] Show Progress in loop
In-Reply-To: <x2psqdkaql.fsf@viggo.kubism.ku.dk>
References: <434A2CD6.1080409@sun.ac.za> <x2psqdkaql.fsf@viggo.kubism.ku.dk>
Message-ID: <434A2F9D.1000308@sun.ac.za>

I put print(i) in the loop instead of i, but it still only prints (in 
the Windows R GUI) i after it finished the calculations.
I guess it might be due to the output buffering you mentioned - but how 
do I unset it?

Rainer

Peter Dalgaard wrote:
> "Rainer M. Krug" <RKrug at sun.ac.za> writes:
> 
> 
>>Hi
>>
>>I have a loop which is doing time consuming calculations and I would 
>>like to be able to have some feedback on where it is in it's 
>>calculations. I tried to simply show the counter variable in the loop, 
>>but id doesn't work as all display seems to be delayed until the loop is 
>>completed. Is there any way of displaying the progress of a loop?
>>
>>Rainer
>>
>>The loop:
>>
>>for (i in 2:Result$NoSims)
>>{
>>	ppp <- runifpoint(Result$NoPlants)
>>	K <- Kest(ppp)
>>	Result$LSim[i,] <- sqrt(K$iso / pi) - K$r
>>	CM <- (Result$LSim[i,] * Result$LSim[i,]) / abs(K$r[2] - K$r[1])
>>	Result$SigCM[i] <- sum(CM, na.rm=TRUE)
>>	i  #<========================Doesn't display in the loop
>>}
> 
> 
> Just print(i) and if on Windows, remember to unset output buffering. 
> 



-- 
NEW TELEPHONE NUMBER
Tel:		+27 - (0)72 808 2975 (w)

Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
Biology (UCT)

Department of Conservation Ecology
University of Stellenbosch
Matieland 7602
South Africa

Tel:		+27 - (0)72 808 2975 (w)
Fax:		+27 - (0)21 808 3304
Cell:		+27 - (0)83 9479 042

email:	RKrug at sun.ac.za
       	Rainer at krugs.de



From ligges at statistik.uni-dortmund.de  Mon Oct 10 11:11:47 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 10 Oct 2005 11:11:47 +0200
Subject: [R] R: integration problem
In-Reply-To: <434A211B.B87991C6@STATS.uct.ac.za>
References: <434A211B.B87991C6@STATS.uct.ac.za>
Message-ID: <434A3053.6080203@statistik.uni-dortmund.de>

Clark Allan wrote:

> hi all 
> 
> an integration problem. i would like an exact or good approximation for
> the following, but i do not want to use a computer. any suggestions:
> 
> 
> integral of exp(b*x)/sqrt(1-x^2)
>

Sounds like the problem of integrating the Gaussian density...

Uwe Ligges


> where "b" is a constant greater than or equal to 0
> and
> the integral runs from 0 to 1
> 
> 
> any help would be apreciated
> 
> /
> allan
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From RKrug at sun.ac.za  Mon Oct 10 11:13:48 2005
From: RKrug at sun.ac.za (Rainer M. Krug)
Date: Mon, 10 Oct 2005 11:13:48 +0200
Subject: [R] Show Progress in loop
In-Reply-To: <434A2FE3.3040209@statistik.uni-dortmund.de>
References: <434A2CD6.1080409@sun.ac.za>
	<434A2FE3.3040209@statistik.uni-dortmund.de>
Message-ID: <434A30CC.40002@sun.ac.za>

Thanks - flush.console() did the trick.

As you might guess, I am quite new to R. I like the idea of vectorizing 
the calculation, but I guess it is not possible in this case - I will 
ask in a new thread.

Thanks,

Rainer


Uwe Ligges wrote:
> Rainer M. Krug wrote:
> 
>> Hi
>>
>> I have a loop which is doing time consuming calculations and I would 
>> like to be able to have some feedback on where it is in it's 
>> calculations. I tried to simply show the counter variable in the loop, 
>> but id doesn't work as all display seems to be delayed until the loop 
>> is completed. Is there any way of displaying the progress of a loop?
>>
>> Rainer
>>
>> The loop:
>>
>> for (i in 2:Result$NoSims)
>> {
>>     ppp <- runifpoint(Result$NoPlants)
>>     K <- Kest(ppp)
>>     Result$LSim[i,] <- sqrt(K$iso / pi) - K$r
>>     CM <- (Result$LSim[i,] * Result$LSim[i,]) / abs(K$r[2] - K$r[1])
>>     Result$SigCM[i] <- sum(CM, na.rm=TRUE)
>>     i  #<========================Doesn't display in the loop
>> }
>>
> 
> 
> - Update your console (I guess you are on Windows?) by using 
> flush.console().
> - You might want to measure time consumption, hence see ?Rprof.
> - Save some more time by moving as much as possible out of your loop by 
> doing it in a vectorized way (I don't know all the functions you are 
> using, hence cannot make any further recommendations).
> 
> Uwe Ligges



-- 
NEW TELEPHONE NUMBER
Tel:		+27 - (0)72 808 2975 (w)

Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
Biology (UCT)

Department of Conservation Ecology
University of Stellenbosch
Matieland 7602
South Africa

Tel:		+27 - (0)72 808 2975 (w)
Fax:		+27 - (0)21 808 3304
Cell:		+27 - (0)83 9479 042

email:	RKrug at sun.ac.za
       	Rainer at krugs.de



From RKrug at sun.ac.za  Mon Oct 10 11:16:22 2005
From: RKrug at sun.ac.za (Rainer M. Krug)
Date: Mon, 10 Oct 2005 11:16:22 +0200
Subject: [R] Vectorizing loop
Message-ID: <434A3166.2020900@sun.ac.za>

Hi

I have the following loop and would like to vectorize it. Any ideas if 
it is possible?

Thanks,

Rainer

Tha Loop:

for (i in 2:Result$NoSims)
{
	ppp <- runifpoint(Result$NoPlants)
	K <- Kest(ppp)
	Result$LSim[i,] <- sqrt(K$iso / pi) - K$r
	CM <- (Result$LSim[i,] * Result$LSim[i,]) / abs(K$r[2] - K$r[1])
	Result$SigCM[i] <- sum(CM, na.rm=TRUE)
	print(i)
	flush.console()
}








-- 
NEW TELEPHONE NUMBER
Tel:		+27 - (0)72 808 2975 (w)

Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
Biology (UCT)

Department of Conservation Ecology
University of Stellenbosch
Matieland 7602
South Africa

Tel:		+27 - (0)72 808 2975 (w)
Fax:		+27 - (0)21 808 3304
Cell:		+27 - (0)83 9479 042

email:	RKrug at sun.ac.za
       	Rainer at krugs.de



From phgrosjean at sciviews.org  Mon Oct 10 11:17:46 2005
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Mon, 10 Oct 2005 11:17:46 +0200
Subject: [R] Show Progress in loop
In-Reply-To: <434A2CD6.1080409@sun.ac.za>
References: <434A2CD6.1080409@sun.ac.za>
Message-ID: <434A31BA.8020609@sciviews.org>

Hello,

You must explicitly use print(), show() on an object -here, use 
print(i)- in a loop or alternatively, use cat() to display string like:
cat("loop", i, "\n")

With RGui under Windows, there is another subtility: if you have turn on 
'Misc -> Buffered output' (it is ON by default), all output are delayed 
until the end of the command processing. You need to use flush.console() 
to tell to print i immediatelly within a loop. The best synthax is 
(since the command is only usable under Windows):
 > for (i in 1:10) {
 >	print(i)	# You must use print explicitly within a loop
 >	# or, better, use: cat("loop", i, "\n")
 >	# Next command is to overcome buffered output in RGui
 >	if (.Platform$OS.type == "windows") flush.console()
 >	# Next command simulates a "long" process (taking 1 sec)
 >	Sys.sleep(1)
 >	# ... your loop code here...
 > }

Alternatively, you can use the progress() function in svMisc package 
(SciViews bundle). Load svMisc and look at its online help... you have 
several examples of use.
 > library(svMisc)
 > ?progress

Best,

Philippe Grosjean

..............................................<??}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons-Hainaut University, Pentagone (3D08)
( ( ( ( (    Academie Universitaire Wallonie-Bruxelles
  ) ) ) ) )   8, av du Champ de Mars, 7000 Mons, Belgium
( ( ( ( (
  ) ) ) ) )   phone: + 32.65.37.34.97, fax: + 32.65.37.30.54
( ( ( ( (    email: Philippe.Grosjean at umh.ac.be
  ) ) ) ) )
( ( ( ( (    web:   http://www.umh.ac.be/~econum
  ) ) ) ) )          http://www.sciviews.org
( ( ( ( (
..............................................................

Rainer M. Krug wrote:
> Hi
> 
> I have a loop which is doing time consuming calculations and I would 
> like to be able to have some feedback on where it is in it's 
> calculations. I tried to simply show the counter variable in the loop, 
> but id doesn't work as all display seems to be delayed until the loop is 
> completed. Is there any way of displaying the progress of a loop?
> 
> Rainer
> 
> The loop:
> 
> for (i in 2:Result$NoSims)
> {
> 	ppp <- runifpoint(Result$NoPlants)
> 	K <- Kest(ppp)
> 	Result$LSim[i,] <- sqrt(K$iso / pi) - K$r
> 	CM <- (Result$LSim[i,] * Result$LSim[i,]) / abs(K$r[2] - K$r[1])
> 	Result$SigCM[i] <- sum(CM, na.rm=TRUE)
> 	i  #<========================Doesn't display in the loop
> }
>



From p.dalgaard at biostat.ku.dk  Mon Oct 10 11:22:07 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Oct 2005 11:22:07 +0200
Subject: [R] Show Progress in loop
In-Reply-To: <434A2F9D.1000308@sun.ac.za>
References: <434A2CD6.1080409@sun.ac.za> <x2psqdkaql.fsf@viggo.kubism.ku.dk>
	<434A2F9D.1000308@sun.ac.za>
Message-ID: <x264s5k9q8.fsf@viggo.kubism.ku.dk>

"Rainer M. Krug" <RKrug at sun.ac.za> writes:

> I put print(i) in the loop instead of i, but it still only prints (in 
> the Windows R GUI) i after it finished the calculations.
> I guess it might be due to the output buffering you mentioned - but how 
> do I unset it?

Using the user friendly interface... (it's on one of the top menus),
or, as Uwe suggested, stick in flush.console() after the print(i).

        -p
 
> Rainer
> 
> Peter Dalgaard wrote:
> > "Rainer M. Krug" <RKrug at sun.ac.za> writes:
> > 
> > 
> >>Hi
> >>
> >>I have a loop which is doing time consuming calculations and I would 
> >>like to be able to have some feedback on where it is in it's 
> >>calculations. I tried to simply show the counter variable in the loop, 
> >>but id doesn't work as all display seems to be delayed until the loop is 
> >>completed. Is there any way of displaying the progress of a loop?
> >>
> >>Rainer
> >>
> >>The loop:
> >>
> >>for (i in 2:Result$NoSims)
> >>{
> >>	ppp <- runifpoint(Result$NoPlants)
> >>	K <- Kest(ppp)
> >>	Result$LSim[i,] <- sqrt(K$iso / pi) - K$r
> >>	CM <- (Result$LSim[i,] * Result$LSim[i,]) / abs(K$r[2] - K$r[1])
> >>	Result$SigCM[i] <- sum(CM, na.rm=TRUE)
> >>	i  #<========================Doesn't display in the loop
> >>}
> > 
> > 
> > Just print(i) and if on Windows, remember to unset output buffering. 
> > 
> 
> 
> 
> -- 
> NEW TELEPHONE NUMBER
> Tel:		+27 - (0)72 808 2975 (w)
> 
> Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
> Biology (UCT)
> 
> Department of Conservation Ecology
> University of Stellenbosch
> Matieland 7602
> South Africa
> 
> Tel:		+27 - (0)72 808 2975 (w)
> Fax:		+27 - (0)21 808 3304
> Cell:		+27 - (0)83 9479 042
> 
> email:	RKrug at sun.ac.za
>        	Rainer at krugs.de
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From vincent at 7d4.com  Mon Oct 10 11:25:51 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Mon, 10 Oct 2005 11:25:51 +0200
Subject: [R] Show Progress in loop
In-Reply-To: <434A2CD6.1080409@sun.ac.za>
References: <434A2CD6.1080409@sun.ac.za>
Message-ID: <434A339F.40507@7d4.com>

Rainer M. Krug a ??crit :

> Hi
> I have a loop which is doing time consuming calculations and I would 
> like to be able to have some feedback on where it is in it's 
> calculations. I tried to simply show the counter variable in the loop, 
> but id doesn't work as all display seems to be delayed until the loop is 
> completed. Is there any way of displaying the progress of a loop?
> 
> for (i in 2:Result$NoSims)
> {
> 	...
> 	i  #<========================Doesn't display in the loop
> }
> 

Hi,
for your last line, use :

print(i);
flush.console();  #<====== now displays in the loop

hih



From ernesto at ipimar.pt  Mon Oct 10 11:37:14 2005
From: ernesto at ipimar.pt (ernesto)
Date: Mon, 10 Oct 2005 10:37:14 +0100
Subject: [R] Show Progress in loop
In-Reply-To: <434A2CD6.1080409@sun.ac.za>
References: <434A2CD6.1080409@sun.ac.za>
Message-ID: <434A364A.2040102@ipimar.pt>

Rainer M. Krug wrote:

>Hi
>
>I have a loop which is doing time consuming calculations and I would 
>like to be able to have some feedback on where it is in it's 
>calculations. I tried to simply show the counter variable in the loop, 
>but id doesn't work as all display seems to be delayed until the loop is 
>completed. Is there any way of displaying the progress of a loop?
>
>Rainer
>
>The loop:
>
>for (i in 2:Result$NoSims)
>{
>	ppp <- runifpoint(Result$NoPlants)
>	K <- Kest(ppp)
>	Result$LSim[i,] <- sqrt(K$iso / pi) - K$r
>	CM <- (Result$LSim[i,] * Result$LSim[i,]) / abs(K$r[2] - K$r[1])
>	Result$SigCM[i] <- sum(CM, na.rm=TRUE)
>	i  #<========================Doesn't display in the loop
>}
>
>  
>
Hi,

You can simply include a command like

cat("loop: " , i, "\n")

inside your loop.

EJ



From ripley at stats.ox.ac.uk  Mon Oct 10 12:48:56 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 10 Oct 2005 11:48:56 +0100 (BST)
Subject: [R] Show Progress in loop
In-Reply-To: <434A31BA.8020609@sciviews.org>
References: <434A2CD6.1080409@sun.ac.za> <434A31BA.8020609@sciviews.org>
Message-ID: <Pine.LNX.4.61.0510101146350.4023@gannet.stats>

On Mon, 10 Oct 2005, Philippe Grosjean wrote:

> Hello,
>
> You must explicitly use print(), show() on an object -here, use
> print(i)- in a loop or alternatively, use cat() to display string like:
> cat("loop", i, "\n")
>
> With RGui under Windows, there is another subtility: if you have turn on
> 'Misc -> Buffered output' (it is ON by default), all output are delayed
> until the end of the command processing. You need to use flush.console()
> to tell to print i immediatelly within a loop. The best synthax is
> (since the command is only usable under Windows):

Not so: all systems have it.  It is also useful on MacOS X.  All this is 
on the help page.

This is in the rw-FAQ: it seems we have lost the convention of not 
answering FAQs but referring people to the appropriate FAQ.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From i.j.gallagher at sms.ed.ac.uk  Mon Oct 10 13:20:32 2005
From: i.j.gallagher at sms.ed.ac.uk (Iain Gallagher)
Date: Mon, 10 Oct 2005 12:20:32 +0100
Subject: [R] plot - no main title and missing abscissa value
Message-ID: <434A4E80.9010204@sms.ed.ac.uk>

Hi all.

I have defined a plot thus:

par(mar=c(5,5,4,5),las=1, xpd=NA)
plot(Day, Ym1Imp, ylim=c(0,100), type="b", bty="l", main="Ym1 
Expression", cex=1.3, xaxt="n", yaxt="n") #plot implant data
axis(side=1, at=c(0,1,3,5,7,10,14,21), labels=c(0,1,3,5,7,10,14,21)) # 
label x axis
mtext("Day", side =1, at=10, line=3, cex=1.2) # title x axis

The problem with this graph is that the main title is missing and so is 
the digit "1" at the abscissa position 1 - although the other abscissa 
labels are all there as defined in the "axis" call.

Can anyone shed anylight on why this is? I'm using R 2.1 on OS X.

Thanks

Iain


-- 
Iain Gallagher
Institute for Infection & Immunology Research
Ashworth Laboratories
Kings Buildings
University of Edinburgh
Edinburgh
EH9 3JT
UK

(+44) 0131 651 3630



From rlittle at ula.ve  Mon Oct 10 13:59:14 2005
From: rlittle at ula.ve (Roy Little)
Date: Mon, 10 Oct 2005 07:59:14 -0400
Subject: [R] text(x,y,greek character)
Message-ID: <434A5792.9010001@ula.ve>

Dear list,
I would like to plot points with two types of labels, one at the data 
point (the name of the point) and another offset a bit with another 
factor which is either of the two greek characters alpha or beta. I have 
tried to get the routine to plot a greek character with expression() or 
with substitute() and have not yet had any success.  The following only 
plots the word in english in plain text. Here is my subroutine and data:

---------------------------------------------------
vmat<-as.matrix(read.table("vmat"))
Xm<-vmat[1:22,1:20]
hemd<-read.table("threehem",header=T)
Ym<-as.matrix(hemd[,2])
gvdw.pls<-plsr(Ym ~ Xm,6,method="kernelpls")
rsltv<-predict(gvdw.pls,comps=6)
plot(Ym,rsltv,type="n",xlab="Actividad + 
Biol??gica",xlim=c(4.6,6),ylim=c(4.8,6),ylab=" Act. + 
Biol.(Pred.)",main="QSAR Ligaci??n de Derivados de la Artemisina con + 
Hemina",sub="Descriptores de Coeficientes VdW")

text(Ym,rsltv,labels=threehem$cpd)
text(Ym,rsltv,labels=hemd$type,adj=c(0,-1))
---------------------------------------------
threehem:
"cpd" "ba" "deox" "ox" "hemin" "type"
"1" 1 4.89 -5.32 -5.11 -5.18 alpha
"2" 2 4.89 -5.12 -4.92 -5.12 beta
"3" 3 5.41 -5.62 -5.41 -5.56 alpha
"4" 4 5.47 -5.34 -5.09 -5.3 beta
"5" 5 5.21 -5.41 -5.12 -5.36 beta
"6" 6 5.28 -5.44 -5.14 -5.39 beta
"7" 7 5.16 -5.47 -5.17 -5.39 beta
"8" 8 4.8 -5.43 -5.03 -5.41 beta
"9" 9 4.92 -5.17 -4.9 -5.12 beta
"10" 10 5.02 -5.29 -4.94 -5.35 beta
"11" 11 5.18 -5.72 -5.38 -5.68 alpha
"12" 12 5.44 -5.53 -5.39 -5.66 alpha
"13" 13 5.71 -5.93 -5.64 -5.86 alpha
"14" 14 5.74 -6.01 -5.78 -5.91 alpha
"15" 15 5.75 -5.79 -5.61 -5.71 alpha
"16" 16 5.87 -5.97 -5.67 -5.94 alpha
"17" 17 5.37 NA NA -6.49 alpha
"18" 18 5.75 NA NA -6.5 alpha
"19" 19 5.04 -5.26 NA -5.17 beta
"20" 20 4.89 -5.04 -4.75 -4.98 beta
"21" 21 5.81 -5.71 NA -5.87 alpha
"22" 22 5.62 -6.11 NA -6.23 alpha
----------------------------------
I have included the Xm matrix of predictors as an attachment.
Thank you very much for your help.

Roy Little
Dept. Chem.
Facultad de Ciencias
Universidad de los Andes
M??rida, Venezuela

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: vmat
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051010/894900e0/vmat.pl

From ligges at statistik.uni-dortmund.de  Mon Oct 10 14:07:36 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 10 Oct 2005 14:07:36 +0200
Subject: [R] plot - no main title and missing abscissa value
In-Reply-To: <434A4E80.9010204@sms.ed.ac.uk>
References: <434A4E80.9010204@sms.ed.ac.uk>
Message-ID: <434A5988.2030601@statistik.uni-dortmund.de>

Iain Gallagher wrote:

> Hi all.
> 
> I have defined a plot thus:
> 
> par(mar=c(5,5,4,5),las=1, xpd=NA)
> plot(Day, Ym1Imp, ylim=c(0,100), type="b", bty="l", main="Ym1 
> Expression", cex=1.3, xaxt="n", yaxt="n") #plot implant data
> axis(side=1, at=c(0,1,3,5,7,10,14,21), labels=c(0,1,3,5,7,10,14,21)) # 
> label x axis
> mtext("Day", side =1, at=10, line=3, cex=1.2) # title x axis
> 
> The problem with this graph is that the main title is missing and so is 
> the digit "1" at the abscissa position 1 - although the other abscissa 
> labels are all there as defined in the "axis" call.
> 
> Can anyone shed anylight on why this is? I'm using R 2.1 on OS X.


We cannot reproduce your example due to lack of the data, hence cannot 
help very much. I can only guess that the number at the x-axis is left 
out for space reasons, but don't know what happens with your title.

Please read the posting guide which suggests to specify a minimal toy 
example that shows your problem.

Uwe Ligges


> Thanks
> 
> Iain
> 
>



From JAROSLAW.W.TUSZYNSKI at saic.com  Mon Oct 10 14:22:11 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Mon, 10 Oct 2005 08:22:11 -0400
Subject: [R] matrix operation
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD504095D61@us-arlington-0668.mail.saic.com>

 There a re a few ways to do it without loop. Here is one:
 
 dat = matrix(runif(100), 50,2)
 dat[,1] = dat[,1] >= dat[,2]

 Jarek 
====================================================\==== 
 Jarek Tuszynski, PhD.                           o / \ 
 Science Applications International Corporation  <\__,|  
 (703) 676-4192                                   ">  \ 
 Jaroslaw.W.Tuszynski at saic.com                     `   \ 



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] 
Sent: Friday, October 07, 2005 6:02 PM
To: r-help at stat.math.ethz.ch
Subject: [R] matrix operation

Hello:

I have a matrix 'dat' with 2 columns.

I have the following code:

for (i in 1:nrows(dat))
{
  if (dat[i,1] < dat[i,2])
    {
      dat[i,2]<-0
    }

   else
   {
     dat[i,2]<-1
   }


Is there a way to accomplish this without the for loop?

Thank you.

-Dhiren

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From i.j.gallagher at sms.ed.ac.uk  Mon Oct 10 14:34:08 2005
From: i.j.gallagher at sms.ed.ac.uk (Iain Gallagher)
Date: Mon, 10 Oct 2005 13:34:08 +0100
Subject: [R] plot - no main title and missing abscissa value
Message-ID: <434A5FC0.7030400@sms.ed.ac.uk>

Hi. Sorry (esp to Uwe for the repeated messages!)

Here is the data and my code in full. Thanks for the
help.

Data.

Day	Ym1Imp	Ym1sham	Semimp	Semsham
0	5.78	5.78	1.22	1.36
1	44.36	42.1	16.26	18.83
3	38.39	14.66	18.02	2.86
5	57.76	1.03	15.28	0.29
7	72.93	2.71	18.6	1.06
10	48.57	4.61	11.26	5.21
14	74.08	1.53	9.66	0.11
21	73.86	0.14	7.2	0.02


Code

ym<- read.table("ym1expression.csv", header=T,
sep="\t", quote="\"") #read in ym data
attach(ym)# make data visible to R
par(mar=c(5,5,4,5),las=1, xpd=NA)
x<- c(0,1,3,5,7,10,14,21)
plot(Day, Ym1Imp, ylim=c(0,100), type="b", bty="l",
main="Ym1 Expression", cex=1.3, xaxt="n", yaxt="n")
#plot implant data
axis(side=1, at=c(0,1,3,5,7,10,14,21),
labels=c(0,1,3,5,7,10,14,21)) # label x axis
mtext("Day", side =1, at=10, line=3, cex=1.2) # title
x axis
mtext("AU", side=2, at=50, line=3, cex=1.2)# y axis
title
axis(side=2, at=c(0, 25, 50, 75, 100),
labels=expression("0", "25", "50", "75", "100")) #
label y axis
arrows(x, Ym1Imp-Semimp, x, Ym1Imp+Semimp, code=3,
angle=90, length=0.1)# place error bars
points(Day, Ym1sham, type="b", pch=16, cex=1.3)# plot
sham data
arrows(x, Ym1sham-Semsham, x, Ym1sham+Semsham, code=3,
angle=90, length=0.1)# plot sham error bars
legend(20, 60, legend="Implant", pch=1, lty=1,
bty="n")# implant legend
legend(20, 50, legend="Sham", pch=16, lty=1, bty="n")#
sham legend

Iain

-- 
Iain Gallagher
Institute for Infection & Immunology Research
Ashworth Laboratories
Kings Buildings
University of Edinburgh
Edinburgh
EH9 3JT
UK

(+44) 0131 651 3630



From dieter.menne at menne-biomed.de  Mon Oct 10 14:31:58 2005
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Mon, 10 Oct 2005 12:31:58 +0000 (UTC)
Subject: [R] glm contrasts (was: no subject)
References: <1263.147.251.26.133.1128927573.squirrel@elanor.sci.muni.cz>
Message-ID: <loom.20051010T142804-731@post.gmane.org>

 <pekar <at> sci.muni.cz> writes:

> Can anybody tell me, please, how to get a matrix of SE of differences (or
> any SE) from a GLM object? Both model.tables and se.contrast work only for
> ANOVA objects. I remember there was a "disp s" directive in GLIM package.
> I would need something like that.


estimable in bundle gregmisc (package gmodels) should do this.

(Kiebitzers: Hope I got the bundle/package/library definition correct)

Please use a meaningful subject line next time.

Dieter



From andy_liaw at merck.com  Mon Oct 10 15:00:45 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 10 Oct 2005 09:00:45 -0400
Subject: [R] Vectorizing loop
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED4EE@usctmx1106.merck.com>

Not unless we know what runifpoint() and Kest() are.  AFAIK these are not
part of base R.  If you use functions from add-on packages, please state
them so as not to leave others guessing.  (This is in the Posting Guide,
which you were asked to read.)

Andy

> From: Rainer M. Krug
> 
> Hi
> 
> I have the following loop and would like to vectorize it. Any 
> ideas if 
> it is possible?
> 
> Thanks,
> 
> Rainer
> 
> Tha Loop:
> 
> for (i in 2:Result$NoSims)
> {
> 	ppp <- runifpoint(Result$NoPlants)
> 	K <- Kest(ppp)
> 	Result$LSim[i,] <- sqrt(K$iso / pi) - K$r
> 	CM <- (Result$LSim[i,] * Result$LSim[i,]) / abs(K$r[2] - K$r[1])
> 	Result$SigCM[i] <- sum(CM, na.rm=TRUE)
> 	print(i)
> 	flush.console()
> }
> 
> 
> 
> 
> 
> 
> 
> 
> -- 
> NEW TELEPHONE NUMBER
> Tel:		+27 - (0)72 808 2975 (w)
> 
> Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
> Biology (UCT)
> 
> Department of Conservation Ecology
> University of Stellenbosch
> Matieland 7602
> South Africa
> 
> Tel:		+27 - (0)72 808 2975 (w)
> Fax:		+27 - (0)21 808 3304
> Cell:		+27 - (0)83 9479 042
> 
> email:	RKrug at sun.ac.za
>        	Rainer at krugs.de
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From RKrug at sun.ac.za  Mon Oct 10 15:12:05 2005
From: RKrug at sun.ac.za (Rainer M. Krug)
Date: Mon, 10 Oct 2005 15:12:05 +0200
Subject: [R] Vectorizing loop
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED4EE@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED4EE@usctmx1106.merck.com>
Message-ID: <434A68A5.5070506@sun.ac.za>

Sorry

runifpoint() and Kest are from the package spatstat

Rainer

Liaw, Andy wrote:
> Not unless we know what runifpoint() and Kest() are.  AFAIK these are not
> part of base R.  If you use functions from add-on packages, please state
> them so as not to leave others guessing.  (This is in the Posting Guide,
> which you were asked to read.)
> 
> Andy
> 
> 
>>From: Rainer M. Krug
>>
>>Hi
>>
>>I have the following loop and would like to vectorize it. Any 
>>ideas if 
>>it is possible?
>>
>>Thanks,
>>
>>Rainer
>>
>>Tha Loop:
>>
>>for (i in 2:Result$NoSims)
>>{
>>	ppp <- runifpoint(Result$NoPlants)
>>	K <- Kest(ppp)
>>	Result$LSim[i,] <- sqrt(K$iso / pi) - K$r
>>	CM <- (Result$LSim[i,] * Result$LSim[i,]) / abs(K$r[2] - K$r[1])
>>	Result$SigCM[i] <- sum(CM, na.rm=TRUE)
>>	print(i)
>>	flush.console()
>>}



From MSchwartz at mn.rr.com  Mon Oct 10 15:26:58 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Mon, 10 Oct 2005 08:26:58 -0500
Subject: [R] text(x,y,greek character)
In-Reply-To: <434A5792.9010001@ula.ve>
References: <434A5792.9010001@ula.ve>
Message-ID: <1128950818.4108.118.camel@localhost.localdomain>

On Mon, 2005-10-10 at 07:59 -0400, Roy Little wrote:
> Dear list,
> I would like to plot points with two types of labels, one at the data 
> point (the name of the point) and another offset a bit with another 
> factor which is either of the two greek characters alpha or beta. I have 
> tried to get the routine to plot a greek character with expression() or 
> with substitute() and have not yet had any success.  The following only 
> plots the word in english in plain text. Here is my subroutine and data:
> 
> ---------------------------------------------------
> vmat<-as.matrix(read.table("vmat"))
> Xm<-vmat[1:22,1:20]
> hemd<-read.table("threehem",header=T)
> Ym<-as.matrix(hemd[,2])
> gvdw.pls<-plsr(Ym ~ Xm,6,method="kernelpls")
> rsltv<-predict(gvdw.pls,comps=6)
> plot(Ym,rsltv,type="n",xlab="Actividad + 
> BiolÃ³gica",xlim=c(4.6,6),ylim=c(4.8,6),ylab=" Act. + 
> Biol.(Pred.)",main="QSAR LigaciÃ³n de Derivados de la Artemisina con + 
> Hemina",sub="Descriptores de Coeficientes VdW")
> 
> text(Ym,rsltv,labels=threehem$cpd)
> text(Ym,rsltv,labels=hemd$type,adj=c(0,-1))
> ---------------------------------------------

<snip of data>

I believe I have a solution for you, but you may want to consider the
presentation, as it gets a bit busy. Perhaps consider using two colors
for the numeric text, where each color represents either alpha or beta
and then indicate this in a legend.

This could be done using:

cols <- ifelse(hemd$type == "alpha", "red", "blue")
text(Ym,rsltv,labels=hemd$cpd, col = cols)
legend("topleft", 
       legend = c(expression(alpha), expression(beta)), 
       fill = c("red", "blue"))


Also, two notes:

1. If you are going to use a function that is not in the base R
distribution, please indicate this so that folks can help without having
to search. In this case, the plsr() function is in the pls package,
which required a library(pls) before using your code.


2. The line: 

  text(Ym,rsltv,labels=threehem$cpd)

should be:

  text(Ym,rsltv,labels=hemd$cpd)


Here is a solution:

   greek <- parse(text = as.character(hemd$type))

   text(Ym, rsltv, labels = greek, adj=c(0, -1))

hemd$type is a factor, so it needs to be converted to a character vector
before being able to be used as an expression. Using parse() then
converts the character vector to an expression. The result of the first
line is:

> greek
expression(alpha, beta, alpha, beta, beta, beta, beta, beta, 
    beta, beta, alpha, alpha, alpha, alpha, alpha, alpha, alpha, 
    alpha, beta, beta, alpha, alpha)

Thus, 'greek' can be used in text() as an expression.

HTH,

Marc Schwartz



From vincent at 7d4.com  Mon Oct 10 15:48:53 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Mon, 10 Oct 2005 15:48:53 +0200
Subject: [R] details about lm()
In-Reply-To: <434A2C70.7010209@statistik.uni-dortmund.de>
References: <BHEOLDJKKPGKLNNLPCLMAEODCBAA.domenico.cozzetto@uniroma1.it>
	<434A21B2.6020106@7d4.com>
	<434A2C70.7010209@statistik.uni-dortmund.de>
Message-ID: <434A7145.8070207@7d4.com>

Uwe Ligges a ??crit :

> vincent at 7d4.com wrote:
> 
>> Domenico Cozzetto a ??crit :
>>
>>> Dear all,
>>> I'd like to get a linear regression of some data, and impose that the 
>>> line
>>> goes through a given point P. I've tried to use the lm() method in the
>>> package "stats", but I wasn't able to specify the coordinates of the 
>>> point P. Maybe I should use another method?
>>
>> add directly P in your data is also a way
> 
> No!

Sorry indeed for my not at all rigourous answer.
Adding P in the data set will indeed not force the regression line
to pass through P (P will only be one more points of the cloud,
adding P will "attract" the regression line, not more.)

I did make this answer because I'm yet working with very small data
sets, and adding P (in more than one exemplar when needed in order to
give it more weight), is a fast, (a bit ugly I agree), way to do.
But on the kind of data I use, it works good enough.
I should have add this precision. Apologies.

> Please, both of you, consult a basic textbook on linear regression.

If you have a good reference or link in mind,
I would thank you.

> You can transform the data (linear) so that P becomes (0,0), after that 
> you can estimate the slope without intercept by specifying
> lm(y ~ x - 1)
> The slope estimate is still valid while your intercept can be calculated 
> afterwards.

Sorry for my lack of knowledge, but will the above trick really force
the regression line to pass through P ?
adding (0,0) in this new system of coordinates isn't it equivalent to 
add P to the dataset in the original system ?

If my question is too basic and/or too stupid, just give it a rest.

Vincent



From rreal at banxico.org.mx  Mon Oct 10 15:53:18 2005
From: rreal at banxico.org.mx (Real Miranda Rigoberto)
Date: Mon, 10 Oct 2005 08:53:18 -0500
Subject: [R] Question about Survey Package
Message-ID: <FFCAFB9D54380A4C99FFF518010CD05EA146C2@BMCORREO2K3.banxico.org.mx>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051010/2ef7d848/attachment.pl

From dejongroel at gmail.com  Mon Oct 10 16:16:46 2005
From: dejongroel at gmail.com (Roel de Jong)
Date: Mon, 10 Oct 2005 16:16:46 +0200
Subject: [R] lmer / variance-covariance matrix random effects
Message-ID: <434A77CE.80207@gmail.com>

Hello,

has someone written by chance a function to extract the 
variance-covariance matrix from a lmer-object? I've noticed the VarCorr 
function, but it gives unhandy output.

Regards,
	Roel de Jong



From ligges at statistik.uni-dortmund.de  Mon Oct 10 16:20:50 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 10 Oct 2005 16:20:50 +0200
Subject: [R] details about lm()
In-Reply-To: <434A7145.8070207@7d4.com>
References: <BHEOLDJKKPGKLNNLPCLMAEODCBAA.domenico.cozzetto@uniroma1.it>
	<434A21B2.6020106@7d4.com>
	<434A2C70.7010209@statistik.uni-dortmund.de>
	<434A7145.8070207@7d4.com>
Message-ID: <434A78C2.2080802@statistik.uni-dortmund.de>

vincent at 7d4.com wrote:

> Uwe Ligges a ??crit :
> 
>> vincent at 7d4.com wrote:
>>
>>> Domenico Cozzetto a ??crit :
>>>
>>>> Dear all,
>>>> I'd like to get a linear regression of some data, and impose that 
>>>> the line
>>>> goes through a given point P. I've tried to use the lm() method in the
>>>> package "stats", but I wasn't able to specify the coordinates of the 
>>>> point P. Maybe I should use another method?
>>>
>>>
>>> add directly P in your data is also a way
>>
>>
>> No!
> 
> 
> Sorry indeed for my not at all rigourous answer.
> Adding P in the data set will indeed not force the regression line
> to pass through P (P will only be one more points of the cloud,
> adding P will "attract" the regression line, not more.)
> 
> I did make this answer because I'm yet working with very small data
> sets, and adding P (in more than one exemplar when needed in order to
> give it more weight), is a fast, (a bit ugly I agree), way to do.
> But on the kind of data I use, it works good enough.
> I should have add this precision. Apologies.
> 
>> Please, both of you, consult a basic textbook on linear regression.
> 
> 
> If you have a good reference or link in mind,
> I would thank you.

E.g., among several other, the great comprehensive books by John Fox are 
really well written and easy to understand ...


>> You can transform the data (linear) so that P becomes (0,0), after 
>> that you can estimate the slope without intercept by specifying
>> lm(y ~ x - 1)
>> The slope estimate is still valid while your intercept can be 
>> calculated afterwards.
> 
> 
> Sorry for my lack of knowledge, but will the above trick really force
> the regression line to pass through P ?
> adding (0,0) in this new system of coordinates isn't it equivalent to 
> add P to the dataset in the original system ?

Well, you do not add that point, but transform the others:
Say you have (let's make a very simple 1-D example) points P_i = (x_i, 
y_i), and P = (x_0, y_0). Then calculate for all i:

   P'_i = (x_i - x_0, y_i - y_0)

Now you can calculate a regression without any Intercept by

   lm(y ~ x - 1)

You got the slope now and the Intercept is 0 so far for P'.

After that, you can re-transform to get the real data's intercept:

   Intercept = -(slope * x_0) + y_0


Uwe Ligges




> If my question is too basic and/or too stupid, just give it a rest.
> 
> Vincent



From jhorn at bu.edu  Mon Oct 10 16:25:13 2005
From: jhorn at bu.edu (Jason Horn)
Date: Mon, 10 Oct 2005 10:25:13 -0400
Subject: [R] R.app window size
Message-ID: <FDACC4A2-6A7F-4CAD-8C2A-D998F0967968@bu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051010/ea667610/attachment.pl

From br44114 at gmail.com  Mon Oct 10 16:33:44 2005
From: br44114 at gmail.com (bogdan romocea)
Date: Mon, 10 Oct 2005 10:33:44 -0400
Subject: [R] decreasing performance of for() loop
Message-ID: <8d5a36350510100733w73f73c27l861eff5a2312bcf2@mail.gmail.com>

Dear useRs,

I'm wondering why the for() loop below runs slower as it progresses.
On a Win XP box, the iterations at the beginning run much faster than
those at the end:
1%, iteration 2000, 10:10:16
2%, iteration 4000, 10:10:17
3%, iteration 6000, 10:10:17
98%, iteration 196000, 10:24:04
99%, iteration 198000, 10:24:24
100%, iteration 200000, 10:24:38

Is there something that can be done about this?  Would such a loop run
faster in C/C++/Fortran?

Thank you,
b.

#---sample code
loop.progress <- function(loop,iterations,steps,toprint=NULL)
{
marks <- c(1,floor(iterations/steps)*(1:steps))
if (loop %in% marks) {
	if (is.null(toprint)) prt <- loop else prt <- toprint
	cat(paste(round((which(marks == loop)-1)*(100/steps),0),"%, iteration ",
		prt,", ",format(Sys.time(),"%H:%M:%S"),sep=""),"\n")
	}		
}
#---loop that runs slower and slower
test <- runif(200000)
out <- vector(mode="numeric")
lg <- 30
for (i in (lg+1):length(test))
	{
	loop.progress(i,length(test),100)	
	out[i] <- sum(test[(i-lg):i])
	}



From afshart at exchange.sba.miami.edu  Mon Oct 10 16:37:56 2005
From: afshart at exchange.sba.miami.edu (Afshartous, David)
Date: Mon, 10 Oct 2005 10:37:56 -0400
Subject: [R] wildcards and removing variables
Message-ID: <6BCB4D493A447546A8126F24332056E8F28BBF@school1.business.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051010/8cf8fb62/attachment.pl

From br44114 at gmail.com  Mon Oct 10 16:40:27 2005
From: br44114 at gmail.com (bogdan romocea)
Date: Mon, 10 Oct 2005 10:40:27 -0400
Subject: [R] decreasing performance of for() loop
In-Reply-To: <8d5a36350510100733w73f73c27l861eff5a2312bcf2@mail.gmail.com>
References: <8d5a36350510100733w73f73c27l861eff5a2312bcf2@mail.gmail.com>
Message-ID: <8d5a36350510100740s21d06638m265ba270557c113f@mail.gmail.com>

Nevermind, I found the fix. Declaring the length for out eliminates
the performance decrease,
   out <- vector(mode="numeric",length=length(test))


On 10/10/05, bogdan romocea <br44114 at gmail.com> wrote:
> Dear useRs,
>
> I'm wondering why the for() loop below runs slower as it progresses.
> On a Win XP box, the iterations at the beginning run much faster than
> those at the end:
> 1%, iteration 2000, 10:10:16
> 2%, iteration 4000, 10:10:17
> 3%, iteration 6000, 10:10:17
> 98%, iteration 196000, 10:24:04
> 99%, iteration 198000, 10:24:24
> 100%, iteration 200000, 10:24:38
>
> Is there something that can be done about this?  Would such a loop run
> faster in C/C++/Fortran?
>
> Thank you,
> b.
>
> #---sample code
> loop.progress <- function(loop,iterations,steps,toprint=NULL)
> {
> marks <- c(1,floor(iterations/steps)*(1:steps))
> if (loop %in% marks) {
>         if (is.null(toprint)) prt <- loop else prt <- toprint
>         cat(paste(round((which(marks == loop)-1)*(100/steps),0),"%, iteration ",
>                 prt,", ",format(Sys.time(),"%H:%M:%S"),sep=""),"\n")
>         }
> }
> #---loop that runs slower and slower
> test <- runif(200000)
> out <- vector(mode="numeric")
> lg <- 30
> for (i in (lg+1):length(test))
>         {
>         loop.progress(i,length(test),100)
>         out[i] <- sum(test[(i-lg):i])
>         }
>



From mschwartz at mn.rr.com  Mon Oct 10 16:54:05 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Mon, 10 Oct 2005 09:54:05 -0500
Subject: [R] wildcards and removing variables
In-Reply-To: <6BCB4D493A447546A8126F24332056E8F28BBF@school1.business.edu>
References: <6BCB4D493A447546A8126F24332056E8F28BBF@school1.business.edu>
Message-ID: <1128956045.5190.4.camel@localhost.localdomain>

On Mon, 2005-10-10 at 10:37 -0400, Afshartous, David wrote:
> 	All,
> 
> 	Is there are a wildcard in R for varible names as in unix?  For example,
> 
> 	rm(results*)
> 
> 	to remove all variable or function names that begin w/ "results"?  
> 
> 	cheers,
> 	Dave
> 	ps - please respond directly to afshar at miami.edu 


See ?ls, which has a 'pattern' argument, enabling the use of Regex to
define the objects to be listed and subsequently removed using rm().

You can then use something like:

  rm(list = ls(pattern = "\\bresults."))

HTH,

Marc Schwartz



From bernd.weiss at uni-koeln.de  Mon Oct 10 16:58:27 2005
From: bernd.weiss at uni-koeln.de (Bernd Weiss)
Date: Mon, 10 Oct 2005 16:58:27 +0200
Subject: [R] sqlFetch on MySQL-DB
In-Reply-To: <434A0144.706@web.de>
References: <434A1728.20015.834113@localhost>
Message-ID: <434A9DB3.7663.4E9956@localhost>

Am 10 Oct 2005 um 7:51 hat christian schulz geschrieben:

> Hi,
> 
> there is a problem with the type of  attributes - is it varchar!? IMHO
> you should play a bit with different type's in mysql and the
> consequence in R.
> 
> I recognize "similar" problems with RMySQL, if you have  variables
> with type decimal in mysql you get numerics in chr. But it's possible
> to change the decimal in  double  (mysql) to get num in R.

Thanks to Christian Schulz and Prof. Ripley for their valuable 
suggestions. The use of

	author<-sqlFetch(test,"author",as.is=17)

does the job without any problems.

Bernd



From jsandblom at gmail.com  Mon Oct 10 16:59:42 2005
From: jsandblom at gmail.com (Johan Sandblom)
Date: Mon, 10 Oct 2005 16:59:42 +0200
Subject: [R] wildcards and removing variables
In-Reply-To: <1128956045.5190.4.camel@localhost.localdomain>
References: <6BCB4D493A447546A8126F24332056E8F28BBF@school1.business.edu>
	<1128956045.5190.4.camel@localhost.localdomain>
Message-ID: <97a06f070510100759r7cccd180y@mail.gmail.com>

rm() can take a list of object names as an argument and ls(pattern='^results')
gives such a list. So

rm(ls(pattern='^results'))

would remove all objects that are matched by the regular expression, that is all
that begin with 'results'

HTH, Johan

2005/10/10, Marc Schwartz (via MN) <mschwartz at mn.rr.com>:
> On Mon, 2005-10-10 at 10:37 -0400, Afshartous, David wrote:
> >       All,
> >
> >       Is there are a wildcard in R for varible names as in unix?  For example,
> >
> >       rm(results*)
> >
> >       to remove all variable or function names that begin w/ "results"?
> >
> >       cheers,
> >       Dave
> >       ps - please respond directly to afshar at miami.edu
>
>
> See ?ls, which has a 'pattern' argument, enabling the use of Regex to
> define the objects to be listed and subsequently removed using rm().
>
> You can then use something like:
>
>   rm(list = ls(pattern = "\\bresults."))
>
> HTH,
>
> Marc Schwartz
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>


--
Johan Sandblom  N8, MRC, Karolinska sjh
t +46851776108  17176 Stockholm
m +46735521477  Sweden
"What is wanted is not the will to believe, but the
will to find out, which is the exact opposite"
- Bertrand Russell



From ggrothendieck at gmail.com  Mon Oct 10 17:00:03 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 10 Oct 2005 11:00:03 -0400
Subject: [R] wildcards and removing variables
In-Reply-To: <1128956045.5190.4.camel@localhost.localdomain>
References: <6BCB4D493A447546A8126F24332056E8F28BBF@school1.business.edu>
	<1128956045.5190.4.camel@localhost.localdomain>
Message-ID: <971536df0510100800ob19fb61r9eb4cf85c97a3dd7@mail.gmail.com>

On 10/10/05, Marc Schwartz (via MN) <mschwartz at mn.rr.com> wrote:
> On Mon, 2005-10-10 at 10:37 -0400, Afshartous, David wrote:
> >       All,
> >
> >       Is there are a wildcard in R for varible names as in unix?  For example,
> >
> >       rm(results*)
> >
> >       to remove all variable or function names that begin w/ "results"?
> >
> >       cheers,
> >       Dave
> >       ps - please respond directly to afshar at miami.edu
>
>
> See ?ls, which has a 'pattern' argument, enabling the use of Regex to
> define the objects to be listed and subsequently removed using rm().
>
> You can then use something like:
>
>  rm(list = ls(pattern = "\\bresults."))

Also, in R 2.2.0 (or look in sfsmisc package for older versions of R)
you can use glob2rx to get shell-style wildcards (aka globbing):

ls(pattern = glob2rx("results*"))



From ripley at stats.ox.ac.uk  Mon Oct 10 17:01:43 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 10 Oct 2005 16:01:43 +0100 (BST)
Subject: [R] wildcards and removing variables
In-Reply-To: <1128956045.5190.4.camel@localhost.localdomain>
References: <6BCB4D493A447546A8126F24332056E8F28BBF@school1.business.edu>
	<1128956045.5190.4.camel@localhost.localdomain>
Message-ID: <Pine.LNX.4.61.0510101559140.13292@gannet.stats>

On Mon, 10 Oct 2005, Marc Schwartz (via MN) wrote:

> On Mon, 2005-10-10 at 10:37 -0400, Afshartous, David wrote:
>> 	All,
>>
>> 	Is there are a wildcard in R for varible names as in unix?  For example,
>>
>> 	rm(results*)
>>
>> 	to remove all variable or function names that begin w/ "results"?
>>
>> 	cheers,
>> 	Dave
>> 	ps - please respond directly to afshar at miami.edu
>
>
> See ?ls, which has a 'pattern' argument, enabling the use of Regex to
> define the objects to be listed and subsequently removed using rm().
>
> You can then use something like:
>
>  rm(list = ls(pattern = "\\bresults."))

One new feature of R-2.2.0 is glob2rx, which converts wildcards to regexps 
for you. E.g.

rm(list = ls(pattern = glob2rc("results*")))

(I think if does it a little better, as that trailing dot is not I think 
correct: result* matches result.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rpeng at jhsph.edu  Mon Oct 10 17:03:15 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon, 10 Oct 2005 11:03:15 -0400
Subject: [R] wildcards and removing variables
In-Reply-To: <6BCB4D493A447546A8126F24332056E8F28BBF@school1.business.edu>
References: <6BCB4D493A447546A8126F24332056E8F28BBF@school1.business.edu>
Message-ID: <434A82B3.7010500@jhsph.edu>

In R 2.2.0, there is the function 'glob2rx()' which can be used for this 
purpose.  As in

rm(list = ls(pattern = glob2rx("results*")))

-roger

Afshartous, David wrote:
> 	All,
> 
> 	Is there are a wildcard in R for varible names as in unix?  For example,
> 
> 	rm(results*)
> 
> 	to remove all variable or function names that begin w/ "results"?  
> 
> 	cheers,
> 	Dave
> 	ps - please respond directly to afshar at miami.edu 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/



From mschwartz at mn.rr.com  Mon Oct 10 17:08:47 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Mon, 10 Oct 2005 10:08:47 -0500
Subject: [R] wildcards and removing variables
In-Reply-To: <Pine.LNX.4.61.0510101559140.13292@gannet.stats>
References: <6BCB4D493A447546A8126F24332056E8F28BBF@school1.business.edu>
	<1128956045.5190.4.camel@localhost.localdomain>
	<Pine.LNX.4.61.0510101559140.13292@gannet.stats>
Message-ID: <1128956927.5190.13.camel@localhost.localdomain>

On Mon, 2005-10-10 at 16:01 +0100, Prof Brian Ripley wrote:
> On Mon, 10 Oct 2005, Marc Schwartz (via MN) wrote:
> 
> > On Mon, 2005-10-10 at 10:37 -0400, Afshartous, David wrote:
> >> 	All,
> >>
> >> 	Is there are a wildcard in R for varible names as in unix?  For example,
> >>
> >> 	rm(results*)
> >>
> >> 	to remove all variable or function names that begin w/ "results"?
> >>
> >> 	cheers,
> >> 	Dave
> >> 	ps - please respond directly to afshar at miami.edu
> >
> >
> > See ?ls, which has a 'pattern' argument, enabling the use of Regex to
> > define the objects to be listed and subsequently removed using rm().
> >
> > You can then use something like:
> >
> >  rm(list = ls(pattern = "\\bresults."))
> 
> One new feature of R-2.2.0 is glob2rx, which converts wildcards to regexps 
> for you. E.g.
> 
> rm(list = ls(pattern = glob2rc("results*")))
> 
> (I think if does it a little better, as that trailing dot is not I think 
> correct: result* matches result.)

Thanks to both Gabor and Prof. Ripley for pointing out the use of
glob2rc(). One of the new features I had forgotten about since reading
NEWS.

On the trailing dot, I was just in the process of drafting a follow up
after realizing my error, since as you point out, 'results' would not be
matched in that case.

Thanks,

Marc



From efg at stowers-institute.org  Mon Oct 10 17:12:02 2005
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Mon, 10 Oct 2005 10:12:02 -0500
Subject: [R] greek symbols using pch
References: <283982AD9F3CD211B3AC00A0C983032F11443674@paradise.ansto.gov.au>
Message-ID: <die0c3$5ti$1@sea.gmane.org>

"FISCHER, Matthew" <mjf at ansto.gov.au> wrote in message
news:283982AD9F3CD211B3AC00A0C983032F11443674 at paradise.ansto.gov.au...

>     In a plot, can I specify pch to be a greek symbol? (I looked at
> show.pch() in the Hmisc package but couldn't see the right symbols in
there).
> If not, I guess I can get around this using text(x,y,expression()).

I'm not sure where this is explained very well.  Having ?font give a clue
about this would be nice.

Use font=5, the symbol font.  To see what's in font=5:

par(font=5, las=1)
plot(0:15,0:15,type="n",ylim=c(15,0),
  main="Symbols in Font=5",
  xlab="", ylab="",xaxt="n", yaxt="n")
axis(BOTTOM<-1, at=0:15, 1:16)
axis(LEFT  <-2, at=0:15)
abline(v=0.5 + 0:14,
       h=0.5 + 0:14, col="grey", lty="dotted")

# pch index of any cell is 16*row + column
for(i in 0:255)
{
  x <- i %%16;
  y <- i %/% 16;
  points(x,y,pch=i+1)
}

The Greek letters are from 65 to 90 and 97 to 122 in this font.

Here are random points with Greek letters as the plot character:

par(font=5)
# Use Greek letter for plot characters from font=5
plot(0:1, 0:1, axes=F, type="n", xlab="", ylab="",
  main="Greek plotting characters")
box()
points(runif(100), runif(100), pch=c(65:90, 97:122))

--
efg
Earl F. Glynn
Scientific Programmer
Stowers Institute for Medical Research



From I.Visser at uva.nl  Mon Oct 10 17:20:18 2005
From: I.Visser at uva.nl (Ingmar Visser)
Date: Mon, 10 Oct 2005 17:20:18 +0200
Subject: [R] passing char to Fortran routine
Message-ID: <BF705352.8EE1%I.Visser@uva.nl>

Hello all,

I am using an existing Fortran routine that takes a single character string
as argument. The routine echoes the argument that I provide. When working on
OS X 3.9 there seems to be no problem, ie the Fortran routine nicely echoes
my argument. However, I compiled the same package on a PC (using all the
tools provided in the R for windows faq), and the routine only echoes the
first letter of each character string that I pass on to it.

My questions are: 
1) Is this somehow compiler specific?
2) Should I explicitly provide the Fortran routine with the length of the
character string? 
3) I am at a loss as to what is happening here, so any hint is welcome (-;

The call to the Fortran routine is as follows:

.Fortran("npoptn",as.character(opt),PACKAGE="depmix")

where opt is a character string such as opt="Iteration limit = 100"

best, ingmar



From iaingallagher at btopenworld.com  Mon Oct 10 17:21:24 2005
From: iaingallagher at btopenworld.com (Iain Gallagher)
Date: Mon, 10 Oct 2005 16:21:24 +0100
Subject: [R] plot - no main title and missing abscissa value
Message-ID: <434A86F4.90507@btopenworld.com>

For anyone who's looked at my previously posted problem I have managed 
to solve the missing graph title by removing the main="Graph Title" call 
from my plot definition and adding a line defining the graph title as a 
"title" call.

i.e. from

 >plot(Day, Ym1Imp, ylim=c(0,100), type="b", bty="l", main="Ym1 
Expression", cex=1.3, xaxt="n", yaxt="n") #plot implant data

to

 >plot(Day, Ym1Imp, ylim=c(0,100), type="b", bty="l",  cex=1.3, 
xaxt="n", yaxt="n") #plot implant data

 >title(main="Ym1 Expression")# add title

which for some reason works.

Still have the missing abscissa value though :-(

Iain



From gunter.berton at gene.com  Mon Oct 10 17:25:16 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Mon, 10 Oct 2005 08:25:16 -0700
Subject: [R] trouble installing AnalyzeFMRI package: please help
In-Reply-To: <20051007233911.17119.qmail@web54515.mail.yahoo.com>
Message-ID: <200510101525.j9AFPH0B015489@volta.gene.com>

> maintainer if I can figure out who he is. Any clues?
> 

Try reading the docs! library(help='AnalyzeFMRI')

-- Bert Gunter



From roebuck at wotan.mdacc.tmc.edu  Mon Oct 10 17:26:41 2005
From: roebuck at wotan.mdacc.tmc.edu (Paul Roebuck)
Date: Mon, 10 Oct 2005 10:26:41 -0500 (CDT)
Subject: [R] R.app window size
In-Reply-To: <FDACC4A2-6A7F-4CAD-8C2A-D998F0967968@bu.edu>
References: <FDACC4A2-6A7F-4CAD-8C2A-D998F0967968@bu.edu>
Message-ID: <Pine.OSF.4.58.0510101018110.182219@wotan.mdacc.tmc.edu>

On Mon, 10 Oct 2005, Jason Horn wrote:

> This is a question for any of you who use R.app (OS X).  Is there any
> way to resize the quartz plot window from within R?  I know that you
> can resize the window by dragging the corner of the window, and fro
> the preferences panel.  But is there a way to specify the window size
> from the console?  I want to specify the size of the plot window from
> inside an R function.

You had a problem with the width & height arguments?
Probably best to use device independent method for scripting.

    grdev <- function(...) {
        get(getOption("device"))(...)
    }

    grdev(width = 7.8, height = 5.8)
    #quartz(width = 7.8, height = 5.8)


----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From ripley at stats.ox.ac.uk  Mon Oct 10 17:35:12 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 10 Oct 2005 16:35:12 +0100 (BST)
Subject: [R] passing char to Fortran routine
In-Reply-To: <BF705352.8EE1%I.Visser@uva.nl>
References: <BF705352.8EE1%I.Visser@uva.nl>
Message-ID: <Pine.LNX.4.61.0510101633130.13760@gannet.stats>

> PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html

Programming questions are appropriate for R-devel, as it says there.

The issue is OS-specific, but we don't see what your Fortran code is.
If you send a reproducible example to the R-devel list, people may be able 
to suggest what the problem is.

On Mon, 10 Oct 2005, Ingmar Visser wrote:

> Hello all,
>
> I am using an existing Fortran routine that takes a single character string
> as argument. The routine echoes the argument that I provide. When working on
> OS X 3.9 there seems to be no problem, ie the Fortran routine nicely echoes
> my argument. However, I compiled the same package on a PC (using all the
> tools provided in the R for windows faq), and the routine only echoes the
> first letter of each character string that I pass on to it.
>
> My questions are:
> 1) Is this somehow compiler specific?
> 2) Should I explicitly provide the Fortran routine with the length of the
> character string?
> 3) I am at a loss as to what is happening here, so any hint is welcome (-;
>
> The call to the Fortran routine is as follows:
>
> .Fortran("npoptn",as.character(opt),PACKAGE="depmix")
>
> where opt is a character string such as opt="Iteration limit = 100"

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From goedman at mac.com  Mon Oct 10 17:37:33 2005
From: goedman at mac.com (Rob J Goedman)
Date: Mon, 10 Oct 2005 08:37:33 -0700
Subject: [R] R.app window size
In-Reply-To: <FDACC4A2-6A7F-4CAD-8C2A-D998F0967968@bu.edu>
References: <FDACC4A2-6A7F-4CAD-8C2A-D998F0967968@bu.edu>
Message-ID: <EC7BCF72-C61F-40F8-BCE4-3D5339C6D6EE@mac.com>

Jason,

?quartz lists the options, e.g.

quartz(width=6, height=7, pointsize=24)

All from the console.

A better alias for these questions is R-Sig-Mac (r-sig- 
mac at stat.math.ethz.ch).

Rob


On Oct 10, 2005, at 7:25 AM, Jason Horn wrote:

> Hi all,
>
> This is a question for any of you who use R.app (OS X).  Is there any
> way to resize the quartz plot window from within R?  I know that you
> can resize the window by dragging the corner of the window, and fro
> the preferences panel.  But is there a way to specify the window size
> from the console?  I want to specify the size of the plot window from
> inside an R function.
>
> Also a related question:  I notice that text does not resize
> proportionately - it stays the same size when you resize the window.
> Can this be controlled from the console as well?  Is there a way to
> make text resize proportionately with window size?
>
> Thanks,
>
> - Jason
>
>
> Jason Horn
> Boston University Department of Biology
> 5 Cumington Street  Boston, MA 02215
>
> jhorn at bu.edu
> office: 617 353 6987
> cell: 401 588 2766
>
>
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting- 
> guide.html
>



From rvaradha at jhsph.edu  Mon Oct 10 17:44:28 2005
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Mon, 10 Oct 2005 11:44:28 -0400
Subject: [R] R: integration problem
In-Reply-To: <434A211B.B87991C6@STATS.uct.ac.za>
Message-ID: <OWA-2QNbk768VF4dtHA000171f4@owa-2.sph.ad.jhsph.edu>

Hi,

If your limits were to be from -1 to +1 (instead of lower limit being 0),
your integral is:

pi * I_0(b)

Where I_0 is the modified Bessel's function of the zeroth order.  

If it is from 0 to 1, then there is no closed form (the integrand is not
symmetric about 0). You must evaluate the integral with exp(a*cos(t)) as the
integrand from 0 to pi/2.

Hope this is helpful,
Ravi.


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-
> bounces at stat.math.ethz.ch] On Behalf Of Clark Allan
> Sent: Monday, October 10, 2005 4:07 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] R: integration problem
> 
> hi all
> 
> an integration problem. i would like an exact or good approximation for
> the following, but i do not want to use a computer. any suggestions:
> 
> 
> integral of exp(b*x)/sqrt(1-x^2)
> 
> where "b" is a constant greater than or equal to 0
> and
> the integral runs from 0 to 1
> 
> 
> any help would be apreciated
> 
> /
> allan



From j.van_den_hoff at fz-rossendorf.de  Mon Oct 10 17:47:11 2005
From: j.van_den_hoff at fz-rossendorf.de (joerg van den hoff)
Date: Mon, 10 Oct 2005 17:47:11 +0200
Subject: [R] problem with  lapply(x, subset,
	...) and  variable select argument
Message-ID: <434A8CFF.5070300@fz-rossendorf.de>

I need to extract identically named columns from several data frames in 
a list. the column name is a variable (i.e. not known in advance). the 
whole thing occurs within a function body. I'd like to use lapply with a
variable 'select' argument.


example:

tt <- function (n) {
    x <- list(data.frame(a=1,b=2), data.frame(a=3,b=4))
    for (xx in x) print(subset(xx, select = n))   ### works
    print (lapply(x, subset, select = a))   ### works
    print (lapply(x, subset, select = "a"))  ### works
    print (lapply(x, subset, select = n))  ### does not work as intended
}
n = "b"
tt("a")  #works (but selects not the intended column)
rm(n)
tt("a")   #no longer works in the lapply call including variable 'n'


question: how  can I enforce evaluation of the variable n such that
the lapply call works? I suspect it has something to do with eval and
specifying the correct evaluation frame, but how? ....


many thanks

joerg



From vincent at 7d4.com  Mon Oct 10 17:38:38 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Mon, 10 Oct 2005 17:38:38 +0200
Subject: [R] details about lm()
In-Reply-To: <434A78C2.2080802@statistik.uni-dortmund.de>
References: <BHEOLDJKKPGKLNNLPCLMAEODCBAA.domenico.cozzetto@uniroma1.it>
	<434A21B2.6020106@7d4.com>
	<434A2C70.7010209@statistik.uni-dortmund.de>
	<434A7145.8070207@7d4.com>
	<434A78C2.2080802@statistik.uni-dortmund.de>
Message-ID: <434A8AFE.7060401@7d4.com>

Uwe Ligges a ??crit :

> vincent at 7d4.com wrote:
>> Sorry for my lack of knowledge, but will the above trick really force
>> the regression line to pass through P ?
>> adding (0,0) in this new system of coordinates isn't it equivalent to 
>> add P to the dataset in the original system ?
> 
> Well, you do not add that point, but transform the others:
> Say you have (let's make a very simple 1-D example) points P_i = (x_i, 
> y_i), and P = (x_0, y_0). Then calculate for all i:
>   P'_i = (x_i - x_0, y_i - y_0)
> Now you can calculate a regression without any Intercept by
>   lm(y ~ x - 1)
> You got the slope now and the Intercept is 0 so far for P'.
> After that, you can re-transform to get the real data's intercept:
>   Intercept = -(slope * x_0) + y_0

Thank you very much for the kind answer and for your time.
(I'll read that carefully and take my rule, pencil and R).
Vincent



From tlumley at u.washington.edu  Mon Oct 10 17:58:25 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 10 Oct 2005 08:58:25 -0700 (PDT)
Subject: [R] Question about Survey Package
In-Reply-To: <FFCAFB9D54380A4C99FFF518010CD05EA146C2@BMCORREO2K3.banxico.org.mx>
References: <FFCAFB9D54380A4C99FFF518010CD05EA146C2@BMCORREO2K3.banxico.org.mx>
Message-ID: <Pine.LNX.4.63a.0510100836550.11948@homer24.u.washington.edu>

On Mon, 10 Oct 2005, Real Miranda Rigoberto wrote:

> I have a question referring to the calculation of variance estimation of 
> the survey package
>
> I need to estimate the variance for different Domains but for a 
> stratified sampling desing in several stages. Särndal et al (1992), CAP 
> 10, makes reference to this problem.
>
> My question is if it is possible by means of "survey package" to obtain 
> these calculations, and if it follows the methodology raised by Särndal 
> or another author.
>

Yes, it is possible.

The computations for totals are based on the use of domain indicator 
variables when computing variances, as in Sarndal et al (1992), and the 
handling of multistage sampling is as in chapter 4.4 of that book. The 
computations for statistics other than totals are based on estimating the 
total of a suitable estimating function and then solving the estimating 
equation.

In fact, for domain means there are three equivalent ways to compute the 
estimator and its variance, and one of the package tests checks that these 
give the same answer

With the data set from example(mu284) we could compute the mean for the 
completely artificial domain id2>1 by
     svymean(~y1, subset(dmu284, id2>1))
The subset() function knows how to handle survey designs to give correct domain 
estimation.

This is equivalent to two more obviously correct estimators based on the 
whole sample: a regression estimator
     summary(svyglm(y1~factor(id2>1)+0, design=dmu284)
and to a ratio estimator
     svyratio(~as.numeric(y1*(id2>1)), ~as.numeric(id2>1), design=dmu284)

All three give the same mean estimator and standard error.

 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

From tastard at cict.fr  Mon Oct 10 18:25:01 2005
From: tastard at cict.fr (Emmanuelle TASTARD)
Date: Mon, 10 Oct 2005 18:25:01 +0200
Subject: [R] RE :  interpretation output glmmPQL
In-Reply-To: <BF74FADD4B44554CA7E53D0B5242CD6A034FF098@evd-s7014.bk.evdad.admin.ch>
Message-ID: <004301c5cdb7$2d097170$e2697882@st226edb>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051010/6c7b31e4/attachment.pl

From tlumley at u.washington.edu  Mon Oct 10 19:22:37 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 10 Oct 2005 10:22:37 -0700 (PDT)
Subject: [R] problem with  lapply(x, subset,
 ...) and  variable select argument
In-Reply-To: <434A8CFF.5070300@fz-rossendorf.de>
References: <434A8CFF.5070300@fz-rossendorf.de>
Message-ID: <Pine.LNX.4.63a.0510101021440.11948@homer24.u.washington.edu>

On Mon, 10 Oct 2005, joerg van den hoff wrote:

> I need to extract identically named columns from several data frames in
> a list. the column name is a variable (i.e. not known in advance). the
> whole thing occurs within a function body. I'd like to use lapply with a
> variable 'select' argument.

You would probably be better off using "[" rather than subset().

tt <- function (n) {
     x <- list(data.frame(a=1,b=2), data.frame(a=3,b=4))
     print(lapply(x,"[",n))
}

seems to do what you want.

 	-thomas

> example:
>
> tt <- function (n) {
>    x <- list(data.frame(a=1,b=2), data.frame(a=3,b=4))
>    for (xx in x) print(subset(xx, select = n))   ### works
>    print (lapply(x, subset, select = a))   ### works
>    print (lapply(x, subset, select = "a"))  ### works
>    print (lapply(x, subset, select = n))  ### does not work as intended
> }
> n = "b"
> tt("a")  #works (but selects not the intended column)
> rm(n)
> tt("a")   #no longer works in the lapply call including variable 'n'
>
>
> question: how  can I enforce evaluation of the variable n such that
> the lapply call works? I suspect it has something to do with eval and
> specifying the correct evaluation frame, but how? ....
>
>
> many thanks
>
> joerg
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From ggrothendieck at gmail.com  Mon Oct 10 19:27:14 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 10 Oct 2005 13:27:14 -0400
Subject: [R] problem with lapply(x, subset,
	...) and variable select argument
In-Reply-To: <434A8CFF.5070300@fz-rossendorf.de>
References: <434A8CFF.5070300@fz-rossendorf.de>
Message-ID: <971536df0510101027u5a6160f9t9a3809d75eb76a3e@mail.gmail.com>

The problem is that subset looks into its parent frame but in this
case the parent frame is not the environment in tt but the environment
in lapply since tt does not call subset directly but rather lapply does.

Try this which is similar except we have added the line beginning
with environment before the print statement.

tt <- function (n) {
   x <- list(data.frame(a=1,b=2), data.frame(a=3,b=4))
   environment(lapply) <- environment()
   print(lapply(x, subset, select = n))
}

n <- "b"
tt("a")

What this does is create a new version of lapply whose
parent is the environment in tt.


On 10/10/05, joerg van den hoff <j.van_den_hoff at fz-rossendorf.de> wrote:
> I need to extract identically named columns from several data frames in
> a list. the column name is a variable (i.e. not known in advance). the
> whole thing occurs within a function body. I'd like to use lapply with a
> variable 'select' argument.
>
>
> example:
>
> tt <- function (n) {
>    x <- list(data.frame(a=1,b=2), data.frame(a=3,b=4))
>    for (xx in x) print(subset(xx, select = n))   ### works
>    print (lapply(x, subset, select = a))   ### works
>    print (lapply(x, subset, select = "a"))  ### works
>    print (lapply(x, subset, select = n))  ### does not work as intended
> }
> n = "b"
> tt("a")  #works (but selects not the intended column)
> rm(n)
> tt("a")   #no longer works in the lapply call including variable 'n'
>
>
> question: how  can I enforce evaluation of the variable n such that
> the lapply call works? I suspect it has something to do with eval and
> specifying the correct evaluation frame, but how? ....
>
>
> many thanks
>
> joerg
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From mkimpel at iupui.edu  Mon Oct 10 21:54:32 2005
From: mkimpel at iupui.edu (Kimpel, Mark William)
Date: Mon, 10 Oct 2005 14:54:32 -0500
Subject: [R] R on a supercomputer
Message-ID: <2E6C5260C7C387449A96DF46EE76313C0236A140@iu-mssg-mbx02.exchange.iu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051010/96c9d730/attachment.pl

From HStevens at MUOhio.edu  Mon Oct 10 21:57:09 2005
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Mon, 10 Oct 2005 15:57:09 -0400
Subject: [R] Under-dispersion - a stats question?
Message-ID: <E415F473-DCB4-4E3B-B50C-ABDB09C7E20F@MUOhio.edu>

Hello all:
I frequently have glm models in which the residual variance is much  
lower than the residual degrees of freedom (e.g. Res.Dev=30.5, Res.DF  
= 82). Is it appropriate for me to use a quasipoisson error  
distribution and test it with an F distribution? It seems to me that  
I could stand to gain a much-reduced standard error if I let the  
procedure estimate my dispersion factor (which is what I assume the  
quasi- distributions do).

Thank you for any input at all.

Hank

Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"



From tplate at acm.org  Mon Oct 10 22:39:07 2005
From: tplate at acm.org (Tony Plate)
Date: Mon, 10 Oct 2005 14:39:07 -0600
Subject: [R] R on a supercomputer
In-Reply-To: <2E6C5260C7C387449A96DF46EE76313C0236A140@iu-mssg-mbx02.exchange.iu.edu>
References: <2E6C5260C7C387449A96DF46EE76313C0236A140@iu-mssg-mbx02.exchange.iu.edu>
Message-ID: <434AD16B.6020800@acm.org>

In general, R is not written in such a way that data remain in cache. 
However, R can use optimized BLAS libraries, and these are.   So if your 
version of R is compiled to use an optimized BLAS library appropriate to 
the machine (e.g., ATLAS, or Prof. Goto's Blas), AND a considerable 
amount of the computation done in your R program involves basic linear 
algebra (matrix multiplication, etc.), then you might see a good speedup.

-- Tony Plate

Kimpel, Mark William wrote:
> I am using R with Bioconductor to perform analyses on large datasets
> using bootstrap methods. In an attempt to speed up my work, I have
> inquired about using our local supercomputer and asked the administrator
> if he thought R would run faster on our parallel network. I received the
> following reply:
> 
>  
> 
>  
> 
> "The second benefit is that the processors have large caches. 
> 
> Briefly, everything is loaded into cache before going into the
> processor.  With large caches, there is less movement of data between
> memory and cache, and this can save quite a bit of time.  Indeed, when
> programmers optimize code they usually think about how to do things to
> keep data in cache as long as possible. 
> 
>   Whether you would receive any benefit from larger cache depends on how
> R is written. If it's written such that  data remain in cache, the
> speed-up could be considerable, but I have no way to predict it."
> 
>  
> 
> My question is, "is R written such that data remain in cache?" 
> 
>  
> 
> Thanks,
> 
>  
> 
>  
> 
> Mark W. Kimpel MD 
> 
>  
> 
> Indiana University School of Medicine
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From p.dalgaard at biostat.ku.dk  Mon Oct 10 22:56:32 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Oct 2005 22:56:32 +0200
Subject: [R] Under-dispersion - a stats question?
In-Reply-To: <E415F473-DCB4-4E3B-B50C-ABDB09C7E20F@MUOhio.edu>
References: <E415F473-DCB4-4E3B-B50C-ABDB09C7E20F@MUOhio.edu>
Message-ID: <x2mzlh851b.fsf@turmalin.kubism.ku.dk>

"Martin Henry H. Stevens" <HStevens at muohio.edu> writes:

> Hello all:
> I frequently have glm models in which the residual variance is much  
> lower than the residual degrees of freedom (e.g. Res.Dev=30.5, Res.DF  
> = 82). Is it appropriate for me to use a quasipoisson error  
> distribution and test it with an F distribution? It seems to me that  
> I could stand to gain a much-reduced standard error if I let the  
> procedure estimate my dispersion factor (which is what I assume the  
> quasi- distributions do).
> 
> Thank you for any input at all.

I don't think it is safe to say anything general about this without
knowledge of the model and the subject matter. Residual deviances can
be terribly misleading. Consider for instance this:

y <- c(0,1); w <- c(50,50)
summary(glm(y~1, binomial, weights=w))
y1 <- .5; w1 <- 100
summary(glm(y1~1, binomial, weights=w1))

Notice that coeff. and s.e. is exactly the same, but not the residual
deviances.

Now, in the first case, did the zeros and ones sort themselves into
two completely separated groups, or was that just because data was
given pre-tabulated? 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ligges at statistik.uni-dortmund.de  Mon Oct 10 23:09:43 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 10 Oct 2005 23:09:43 +0200
Subject: [R] plot - no main title and missing abscissa value
In-Reply-To: <434A5FC0.7030400@sms.ed.ac.uk>
References: <434A5FC0.7030400@sms.ed.ac.uk>
Message-ID: <434AD897.3030606@statistik.uni-dortmund.de>

Iain Gallagher wrote:

> Hi. Sorry (esp to Uwe for the repeated messages!)
> 
> Here is the data and my code in full. Thanks for the
> help.
> 
> Data.
> 
> Day	Ym1Imp	Ym1sham	Semimp	Semsham
> 0	5.78	5.78	1.22	1.36
> 1	44.36	42.1	16.26	18.83
> 3	38.39	14.66	18.02	2.86
> 5	57.76	1.03	15.28	0.29
> 7	72.93	2.71	18.6	1.06
> 10	48.57	4.61	11.26	5.21
> 14	74.08	1.53	9.66	0.11
> 21	73.86	0.14	7.2	0.02
> 
> 
> Code
> 
> ym<- read.table("ym1expression.csv", header=T,
> sep="\t", quote="\"") #read in ym data
> attach(ym)# make data visible to R
> par(mar=c(5,5,4,5),las=1, xpd=NA)
> x<- c(0,1,3,5,7,10,14,21)
> plot(Day, Ym1Imp, ylim=c(0,100), type="b", bty="l",
> main="Ym1 Expression", cex=1.3, xaxt="n", yaxt="n")
> #plot implant data
> axis(side=1, at=c(0,1,3,5,7,10,14,21),
> labels=c(0,1,3,5,7,10,14,21)) # label x axis
> mtext("Day", side =1, at=10, line=3, cex=1.2) # title
> x axis
> mtext("AU", side=2, at=50, line=3, cex=1.2)# y axis
> title
> axis(side=2, at=c(0, 25, 50, 75, 100),
> labels=expression("0", "25", "50", "75", "100")) #
> label y axis
> arrows(x, Ym1Imp-Semimp, x, Ym1Imp+Semimp, code=3,
> angle=90, length=0.1)# place error bars
> points(Day, Ym1sham, type="b", pch=16, cex=1.3)# plot
> sham data
> arrows(x, Ym1sham-Semsham, x, Ym1sham+Semsham, code=3,
> angle=90, length=0.1)# plot sham error bars
> legend(20, 60, legend="Implant", pch=1, lty=1,
> bty="n")# implant legend
> legend(20, 50, legend="Sham", pch=16, lty=1, bty="n")#
> sham legend
> 
> Iain
> 


Three points:

1. The main title appears for me under the Windows device. I really 
wonder why you do not see it, this seems to be quite a strange device 
dependence I would not expect in this case.
Since you told us you have "R 2.1", we do not know exactly what you have 
got - there is no such version. There are versions R-2.0.1, R-2.1.0 and 
R-2.1.1, though. Anyway, you told us you found a workaround.


2. In order to re-plot the axis labels, you should specify  xlab=NA, 
ylab=NA in your call to plot() as in:
plot(Day, Ym1Imp, ylim=c(0,100), type="b", bty="l", xlab=NA, ylab=NA,
     main="Ym1 Expression", cex=1.3, xaxt="n", yaxt="n")

3. As I have already guessed, the axis annotation of the tick at 
position 1 is left out because R thinks there is not enough space left.
You can workaround this point by making the label appear separately as in:
axis(side=1, at=c(0,3,5,7,10,14,21))
axis(1, 1)

Uwe Ligges



From wjwest at CLEMSON.EDU  Mon Oct 10 23:16:07 2005
From: wjwest at CLEMSON.EDU (Bill West)
Date: Mon, 10 Oct 2005 17:16:07 -0400
Subject: [R] Has anyone written scripts to read CPS data?
Message-ID: <200510102116.j9ALG71b013072@CLEMSON.EDU>

Hello,
  Has anyone ever written the R code that would extract data from the CPS
March Supplements?

If not, I'll give it a go.

--Bill



From N.L.Pace at m.cc.utah.edu  Tue Oct 11 00:53:17 2005
From: N.L.Pace at m.cc.utah.edu (Nathan Leon Pace, MD, MStat)
Date: Mon, 10 Oct 2005 16:53:17 -0600
Subject: [R] labels of a conditioning variable in xyplot
Message-ID: <64580E2E-E75C-46D2-A904-839F35F3282B@utah.edu>

I am running R 2.1.1 on a Mac g5 under Mac OS 10.4.2.

I have an xyplot with a single conditioning variable (8 levels) .

Here is the code for the conditioning variable used in the formula  
argument of xyplot:

       factor(
         drugauthoryear,
         levels = c(
           'bupicapogna1999',
           'levobenhamou2003',
           'ropicapogna1999',
           'ropipolley1999',
           'bupipolley1999',
           'levopolley2003',
           'ropibenhamou2003',
           'ropipolley2003'
         ),
         labels = c(
           'Bupi. Reference 2.',
           'Levo. Reference 4.',
           'Ropi. Reference 2.',
           'Ropi. Reference 3.',
           'Bupi. Reference 3.',
           'Levo. Reference 5.',
           'Ropi. Reference 4.',
           'Ropi. Reference 5.'
           )
       )


The object is not created and I get the following error message:

Error in do.call("pmax", lapply(cond, is.na)) :
     symbol print-name too long

When I delete the labels vector, the code runs without difficulty.

Any thoughts on this error message?

Thanks,

Nathan



From gunter.berton at gene.com  Tue Oct 11 01:14:11 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Mon, 10 Oct 2005 16:14:11 -0700
Subject: [R] labels of a conditioning variable in xyplot
In-Reply-To: <64580E2E-E75C-46D2-A904-839F35F3282B@utah.edu>
Message-ID: <200510102314.j9ANEBbZ013951@compton.gene.com>

> Error in do.call("pmax", lapply(cond, is.na)) :
>      symbol print-name too long
> 
> When I delete the labels vector, the code runs without difficulty.
> 
> Any thoughts on this error message?

Yes ... the labels are too long to be printed in the space available. Use
shorter labels. For example, remove "Reference" or abbreviate it to "Ref" ,
as it provides no unique identifying info anyway.

(Am I missing something? -- I would have thought this was obvious)

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Nathan 
> Leon Pace, MD, MStat
> Sent: Monday, October 10, 2005 3:53 PM
> To: r-help at stat.math.ethz.ch
> Cc: Nathan Leon Pace, MD, MStat
> Subject: [R] labels of a conditioning variable in xyplot
> 
> I am running R 2.1.1 on a Mac g5 under Mac OS 10.4.2.
> 
> I have an xyplot with a single conditioning variable (8 levels) .
> 
> Here is the code for the conditioning variable used in the formula  
> argument of xyplot:
> 
>        factor(
>          drugauthoryear,
>          levels = c(
>            'bupicapogna1999',
>            'levobenhamou2003',
>            'ropicapogna1999',
>            'ropipolley1999',
>            'bupipolley1999',
>            'levopolley2003',
>            'ropibenhamou2003',
>            'ropipolley2003'
>          ),
>          labels = c(
>            'Bupi. Reference 2.',
>            'Levo. Reference 4.',
>            'Ropi. Reference 2.',
>            'Ropi. Reference 3.',
>            'Bupi. Reference 3.',
>            'Levo. Reference 5.',
>            'Ropi. Reference 4.',
>            'Ropi. Reference 5.'
>            )
>        )
> 
> 
> The object is not created and I get the following error message:
> 
> Error in do.call("pmax", lapply(cond, is.na)) :
>      symbol print-name too long
> 
> When I delete the labels vector, the code runs without difficulty.
> 
> Any thoughts on this error message?
> 
> Thanks,
> 
> Nathan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From N.L.Pace at m.cc.utah.edu  Tue Oct 11 01:50:18 2005
From: N.L.Pace at m.cc.utah.edu (Nathan Leon Pace, MD, MStat)
Date: Mon, 10 Oct 2005 17:50:18 -0600
Subject: [R] labels of a conditioning variable in xyplot
In-Reply-To: <200510102314.j9ANEBbZ013951@compton.gene.com>
References: <200510102314.j9ANEBbZ013951@compton.gene.com>
Message-ID: <7D5DD6A3-1589-4EB4-A4D5-FC40832F90A2@utah.edu>

This error is a curious one.

When I remove the labels vector, the names of the levels are printed  
by default in the strip without difficulty.

The names of the levels have lengths of 14 to 16 characters.

My labels had length 18 characters.

When I reduce the labels to length 10 characters (as you suggest), I  
get the same error message and no object is created.

Nathan


On Oct 10, 2005, at 17:14, Berton Gunter wrote:

>> Error in do.call("pmax", lapply(cond, is.na)) :
>>      symbol print-name too long
>>
>> When I delete the labels vector, the code runs without difficulty.
>>
>> Any thoughts on this error message?
>>
>
> Yes ... the labels are too long to be printed in the space  
> available. Use
> shorter labels. For example, remove "Reference" or abbreviate it to  
> "Ref" ,
> as it provides no unique identifying info anyway.
>
> (Am I missing something? -- I would have thought this was obvious)
>
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
>
> "The business of the statistician is to catalyze the scientific  
> learning
> process."  - George E. P. Box
>
>
>
>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Nathan
>> Leon Pace, MD, MStat
>> Sent: Monday, October 10, 2005 3:53 PM
>> To: r-help at stat.math.ethz.ch
>> Cc: Nathan Leon Pace, MD, MStat
>> Subject: [R] labels of a conditioning variable in xyplot
>>
>> I am running R 2.1.1 on a Mac g5 under Mac OS 10.4.2.
>>
>> I have an xyplot with a single conditioning variable (8 levels) .
>>
>> Here is the code for the conditioning variable used in the formula
>> argument of xyplot:
>>
>>        factor(
>>          drugauthoryear,
>>          levels = c(
>>            'bupicapogna1999',
>>            'levobenhamou2003',
>>            'ropicapogna1999',
>>            'ropipolley1999',
>>            'bupipolley1999',
>>            'levopolley2003',
>>            'ropibenhamou2003',
>>            'ropipolley2003'
>>          ),
>>          labels = c(
>>            'Bupi. Reference 2.',
>>            'Levo. Reference 4.',
>>            'Ropi. Reference 2.',
>>            'Ropi. Reference 3.',
>>            'Bupi. Reference 3.',
>>            'Levo. Reference 5.',
>>            'Ropi. Reference 4.',
>>            'Ropi. Reference 5.'
>>            )
>>        )
>>
>>
>> The object is not created and I get the following error message:
>>
>> Error in do.call("pmax", lapply(cond, is.na)) :
>>      symbol print-name too long
>>
>> When I delete the labels vector, the code runs without difficulty.
>>
>> Any thoughts on this error message?
>>
>> Thanks,
>>
>> Nathan
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting- 
> guide.html
>



From richard.hedger at bio.ulaval.ca  Tue Oct 11 01:50:56 2005
From: richard.hedger at bio.ulaval.ca (Richard Hedger)
Date: Mon, 10 Oct 2005 19:50:56 -0400
Subject: [R] Writing to a file with fixed precision
Message-ID: <00b501c5cdf5$7595cb80$b6cecb84@nom5n6hnfuv31a>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051010/67a3557b/attachment.pl

From cyau at buckinstitute.org  Tue Oct 11 02:04:21 2005
From: cyau at buckinstitute.org (Christina Yau)
Date: Mon, 10 Oct 2005 17:04:21 -0700
Subject: [R] iterative output to file by row
Message-ID: <C7CAAAC7D2D14C409367E8D9026C1D781B2052@inverness.buckcenter.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051010/77c8297a/attachment.pl

From gunter.berton at gene.com  Tue Oct 11 02:04:43 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Mon, 10 Oct 2005 17:04:43 -0700
Subject: [R] labels of a conditioning variable in xyplot
In-Reply-To: <7D5DD6A3-1589-4EB4-A4D5-FC40832F90A2@utah.edu>
Message-ID: <200510110004.j9B04hqM009893@faraday.gene.com>


Well -- that **IS** curious. It sounds to me like a software bug or a typo
somewhere (are all your little "'"s OK?), but now you exceed my modest
expertise -- especially on a Mac (which apparently can be curious little
devils at times).

Deepayan -- where are you?

Cheers,
Bert 
 

> -----Original Message-----
> From: Nathan Leon Pace, MD, MStat [mailto:N.L.Pace at m.cc.utah.edu] 
> Sent: Monday, October 10, 2005 4:50 PM
> To: Berton Gunter; r-help at stat.math.ethz.ch
> Cc: Nathan Leon Pace, MD, MStat
> Subject: Re: [R] labels of a conditioning variable in xyplot
> 
> This error is a curious one.
> 
> When I remove the labels vector, the names of the levels are printed  
> by default in the strip without difficulty.
> 
> The names of the levels have lengths of 14 to 16 characters.
> 
> My labels had length 18 characters.
> 
> When I reduce the labels to length 10 characters (as you suggest), I  
> get the same error message and no object is created.
> 
> Nathan
> 
> 
> On Oct 10, 2005, at 17:14, Berton Gunter wrote:
> 
> >> Error in do.call("pmax", lapply(cond, is.na)) :
> >>      symbol print-name too long
> >>
> >> When I delete the labels vector, the code runs without difficulty.
> >>
> >> Any thoughts on this error message?
> >>
> >
> > Yes ... the labels are too long to be printed in the space  
> > available. Use
> > shorter labels. For example, remove "Reference" or 
> abbreviate it to  
> > "Ref" ,
> > as it provides no unique identifying info anyway.
> >
> > (Am I missing something? -- I would have thought this was obvious)
> >
> > -- Bert Gunter
> > Genentech Non-Clinical Statistics
> > South San Francisco, CA
> >
> > "The business of the statistician is to catalyze the scientific  
> > learning
> > process."  - George E. P. Box
> >
> >
> >
> >
> >> -----Original Message-----
> >> From: r-help-bounces at stat.math.ethz.ch
> >> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Nathan
> >> Leon Pace, MD, MStat
> >> Sent: Monday, October 10, 2005 3:53 PM
> >> To: r-help at stat.math.ethz.ch
> >> Cc: Nathan Leon Pace, MD, MStat
> >> Subject: [R] labels of a conditioning variable in xyplot
> >>
> >> I am running R 2.1.1 on a Mac g5 under Mac OS 10.4.2.
> >>
> >> I have an xyplot with a single conditioning variable (8 levels) .
> >>
> >> Here is the code for the conditioning variable used in the formula
> >> argument of xyplot:
> >>
> >>        factor(
> >>          drugauthoryear,
> >>          levels = c(
> >>            'bupicapogna1999',
> >>            'levobenhamou2003',
> >>            'ropicapogna1999',
> >>            'ropipolley1999',
> >>            'bupipolley1999',
> >>            'levopolley2003',
> >>            'ropibenhamou2003',
> >>            'ropipolley2003'
> >>          ),
> >>          labels = c(
> >>            'Bupi. Reference 2.',
> >>            'Levo. Reference 4.',
> >>            'Ropi. Reference 2.',
> >>            'Ropi. Reference 3.',
> >>            'Bupi. Reference 3.',
> >>            'Levo. Reference 5.',
> >>            'Ropi. Reference 4.',
> >>            'Ropi. Reference 5.'
> >>            )
> >>        )
> >>
> >>
> >> The object is not created and I get the following error message:
> >>
> >> Error in do.call("pmax", lapply(cond, is.na)) :
> >>      symbol print-name too long
> >>
> >> When I delete the labels vector, the code runs without difficulty.
> >>
> >> Any thoughts on this error message?
> >>
> >> Thanks,
> >>
> >> Nathan
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide!
> >> http://www.R-project.org/posting-guide.html
> >>
> >>
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting- 
> > guide.html
> >
> 
>



From MSchwartz at mn.rr.com  Tue Oct 11 03:07:24 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Mon, 10 Oct 2005 20:07:24 -0500
Subject: [R] Writing to a file with fixed precision
In-Reply-To: <00b501c5cdf5$7595cb80$b6cecb84@nom5n6hnfuv31a>
References: <00b501c5cdf5$7595cb80$b6cecb84@nom5n6hnfuv31a>
Message-ID: <1128992844.4115.11.camel@localhost.localdomain>

On Mon, 2005-10-10 at 19:50 -0400, Richard Hedger wrote:
> Hi,
> I'm trying to ouput to a filled with a fixed precision:
> eg. if I have data x=c(1.0,1.4,2.0), I want to be able to ouput the following to a file:
> 1.00000000000000
> 1.40000000000000
> 2.00000000000000
> I was wondering if there was a function to do this in R?
> Thanks,
> Richard

It is possible that someone has written such a function somewhere.

However, this is relatively easy using write.table(). You just need to
pre-format the numeric values prior to writing to the file:

write.table(sprintf("%.14f", x), "data.txt", col.names = FALSE,
            row.names = FALSE, quote = FALSE)

Using sprintf(), we force the floats to have 14 decimal places.
sprintf() outputs character vectors, so we remove the quoting of the
resultant character vectors and don't write column/row names.

Note that if 'x' is a matrix, using sprintf() will return a vector. So
you might want to use the following instead to retain the dims:

> x
     [,1] [,2] [,3] [,4]
[1,]    1    4    7   10
[2,]    2    5    8   11
[3,]    3    6    9   12

> x.fmt <- apply(x, 1, function(x) sprintf("%.14f", x))

> x.fmt
     [,1]                [,2]                [,3]               
[1,] "1.00000000000000"  "2.00000000000000"  "3.00000000000000" 
[2,] "4.00000000000000"  "5.00000000000000"  "6.00000000000000" 
[3,] "7.00000000000000"  "8.00000000000000"  "9.00000000000000" 
[4,] "10.00000000000000" "11.00000000000000" "12.00000000000000"

> write.table(x.fmt, "data.txt", col.names = FALSE, row.names = FALSE,
              quote = FALSE)


If needed, you can of course change the default delimiter from a " " to
another character in write.table().

See ?write.table and ?sprintf.

HTH,

Marc Schwartz



From spencer.graves at pdf.com  Tue Oct 11 03:41:37 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 10 Oct 2005 18:41:37 -0700
Subject: [R] Multiple expressions, when using substitute()
In-Reply-To: <AA4E55C3-34AF-491F-8F22-38F3441A1725@anu.edu.au>
References: <AA4E55C3-34AF-491F-8F22-38F3441A1725@anu.edu.au>
Message-ID: <434B1851.3030501@pdf.com>

	  Have you received a reply to this post?  I couldn't find one, and I 
couldn't find a solution, even though one must exist.  I can get the 
substitute to work in "main" but not "legend":

B <- 2:3
eB <- substitute(y==a*x^b, list(a=B[1], b=B[2]))
plot(1:2, 1:2, main=eB)

	  You should be able to construct it using "mtext", but I couldn't get 
the desired result using legend.

	  hope this helps.
	  spencer graves

John Maindonald wrote:

> expression() accepts multiple expressions as arguments, thus:
> 
> plot(1:2, 1:2)
> legend("topleft",
>                expression(y == a * x^b,
>                                     "where "* paste(y=="wood; ",  
> x=="dbh")))
> 
> Is there a way to do this when values are to be substituted
> for a and b? i.e., the first element of the legend argument
> to legend() becomes, effectively:
>    substitute(y == a * x^b, list(a = B[1], b=B[2]))
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Bioinformation Science, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From MSchwartz at mn.rr.com  Tue Oct 11 04:23:21 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Mon, 10 Oct 2005 21:23:21 -0500
Subject: [R] iterative output to file by row
In-Reply-To: <C7CAAAC7D2D14C409367E8D9026C1D781B2052@inverness.buckcenter.org>
References: <C7CAAAC7D2D14C409367E8D9026C1D781B2052@inverness.buckcenter.org>
Message-ID: <1128997401.4115.22.camel@localhost.localdomain>

On Mon, 2005-10-10 at 17:04 -0700, Christina Yau wrote:
> Hi,

> I'm sort of a newbie to using R to deal with array data.  I'm trying to
> create a simple filtering function, which outputs only the rows of a
> data frame that satisfies a specific criterion.  I've set up an
> iterative loop to apply the condition to each row.  I can create a new
> matrix and use rbind to fill it in row by row in the loop, before
> writing the whole matrix to file.  But it seems really inefficient,
> especially considering my very large dataset.  In fact, I'm worried it
> will cause memory problems if I run the function on the full data set.

> Each row is from a data frame and is associated with a row name and a
> column name.   I'm wondering if there's a way to write each row that
> satisfy the condition to file within the iterative loop directly, while
> keeping the data structure.  I've read the help on the 'cat' function;
> but I'm still not entirely sure how to use it in my situation, or if it
> is the correctly function to use.  Any advice will be greatly
> appreciated.


If you can do it with the full dataset, you are probably better off
using subset() to select the rows that meet your criteria and then use
write.table() to write the resultant smaller data frame to a file.

Alternatively, if you do need to do this within the loop, you can use
write.table() with the 'append' argument set to TRUE, so that each new
row from the data frame that meets your criteria gets added to the
existing file, rather than overwriting it. This will be a little slower,
since each time write.table() is called, it opens the file, writes the
line and closes the file, so there is some file I/O overhead.

You don't need to create a new matrix in the loop, just pass the
resultant single row of your subsetting operation to write.table().

See ?subset and ?write.table for more information.

HTH,

Marc Schwartz



From KKIII at Indiana.Edu  Tue Oct 11 06:38:09 2005
From: KKIII at Indiana.Edu (Ken Kelley)
Date: Mon, 10 Oct 2005 23:38:09 -0500
Subject: [R] Sometimes having problems finding a minimum using optim(),
 optimize(), and nlm() (while searching for noncentral F parameters)
Message-ID: <434B41B1.6000305@Indiana.Edu>

Hi everyone.

I have a problem that I have been unable to determine either the best 
way to proceed and why the methods I'm trying to use sometimes fail. I'm 
using the pf() function in an optimization function to find a 
noncentrality parameter that leads to a specific value at a specified 
quantile. My goal is to have a general function that returns the 
noncentrality parameter that leads to a given value at a defined 
quantile. For example, with 5 and 200 degrees of freedom, what 
noncentrality parameter has at its .975 quantile a value of 4 (it is 
3.0725 by the way)? The code I've written, using three different methods 
works great at times, but at other times it fails (sometimes all 
sometimes not). It isn't even that the functions I'm trying to write 
fail, but the reason they sometimes fail and sometimes do not is what is 
really bothering me; I simply don't understand why the functions at 
times stop the iterative process of minimization and return what the 
function believes to be a successful convergence value (e.g., optim() 
sometimes returns a 0 stating successful convergence when it clearly is 
not).

I'm using three function [optim(), optimize(), and nlm()] to try and 
accomplish the same goal (which was stated above). I believe that they 
should all return the same value, and at times they do just that, but at 
other times the methods return inappropriate results. I'll paste my code 
that illustrates an example where all is well and one where things fail.

Is there are easier way to do what I'm trying to accomplish? The analog 
in SAS of what I'm trying to come up with is FNONCT.

#Begin code
##################################################################
# Define necessary values.
F.value <- 4
tol <- 1e-8
df.1 <- 5
df.2 <- 200
alpha.lower <- .025
maxit<-1000

# The function to be minimized. Here we are looking for the noncentral
# value, 'Lambda', that has at its .975 quantile 'F.value'.
Low.Lim.NC.F <- function(Lambda, alpha.lower, F.value, df.1, df.2)
{
abs(pf(q=F.value, df1=df.1, df2=df.2, ncp=Lambda) - (1-alpha.lower))
# This will be near zero when an appropriate Lambda value is found.
# The Lambda value that leads to a solution of zero is the noncentrality
# value that has at its .975 quantile a value of 'F.value'.
}

# Use the quantile from a central F distribution as a minimum.
LL.0 <- qf(p=alpha.lower, df1=df.1, df2=df.2)

optim(par=LL.0, fn=Low.Lim.NC.F,
method="L-BFGS-B", # Others return the same result usually.
lower=LL.0, upper = Inf, control = list(maxit=maxit, reltol=1e-10), 
hessian = FALSE, alpha.lower=alpha.lower, F.value=F.value, df.1=df.1, 
df.2=df.2)

# Try to accomplish the same task with a different R function.
optimize(f=Low.Lim.NC.F, lower=LL.0, upper=50, maximum=FALSE, tol=tol, 
alpha.lower=alpha.lower, F.value=F.value, df.1=df.1, df.2=df.2)

# Try to accomplish the same task with a different R function.
nlm(f=Low.Lim.NC.F, p=LL.0, fscale=1,
print.level = 0, ndigit=12, gradtol = 1e-6,
stepmax = max(1000 * sqrt(sum((LL.0/10)^2)), 1000),
steptol = 1e-6, iterlim = 1000, check.analyticals = TRUE, 
alpha.lower=alpha.lower, F.value=F.value, df.1=df.1, df.2=df.2)

# The answer in each case is 3.0725. Thus, a noncentral F with
# 5 and 200 df with a noncentrality parameter 3.0725 has at its .975
# quantile a value of 4 (this has been verified in another software).

# But, suppose we triple the F.value to 12 and rerun the code.

F.value <- 12

# The function to be minimized. Here we are looking for the noncentral
# value, 'Lambda', that has at its .975 quantile 'F.value'.
Low.Lim.NC.F <- function(Lambda, alpha.lower, F.value, df.1, df.2)
{
abs(pf(q=F.value, df1=df.1, df2=df.2, ncp=Lambda) - (1-alpha.lower))
}

# Use the quantile from a central F distribution as a minimum.
LL.0 <- qf(p=alpha.lower, df1=df.1, df2=df.2)

optim(par=LL.0, fn=Low.Lim.NC.F,
method="L-BFGS-B",  # Others return the same result usually. 
  lower=LL.0, upper = Inf, control = list(maxit=maxit, reltol=1e-10), 
hessian = FALSE, alpha.lower=alpha.lower, F.value=F.value, df.1=df.1, 
df.2=df.2)

# Try to accomplish the same task with a different R function.
optimize(f=Low.Lim.NC.F, lower=LL.0, upper=500, maximum=FALSE, tol=tol, 
alpha.lower=alpha.lower, F.value=F.value, df.1=df.1, df.2=df.2)

# Try to accomplish the same task with a different R function.
nlm(f=Low.Lim.NC.F, p=LL.0, fscale=1,
gradtol = 1e-6, stepmax = max(1000 * sqrt(sum((LL.0/10)^2)), 1000),
steptol = 1e-6, iterlim = 1000, check.analyticals = TRUE, 
alpha.lower=alpha.lower, F.value=F.value, df.1=df.1, df.2=df.2)

# Now only optimize() works and optim() and nlm() both return the
# same (wrong) answer. Why would the function stop when the
# minimized value was .025 (when it should stop when the value is
# very close to zero)?

# But, optimize() isn't always the answer either, because if the
# upper limit is too large, the function will fail.
# For example, changing the upper limit of optimize in
# this example to 1000 leads to a failure.
##################################################################
#End Code

Am I going about this the best, or even a reasonable, way? Are there 
other functions I'm missing that would be more appropriate given what 
I'm trying to do? Any help would most certainly be appreciated.

Thanks,
Ken

-- 
Ken Kelley, Ph.D.
Inquiry Methodology Program
Indiana University
201 North Rose Avenue, Room 4004
Bloomington, Indiana 47405
http://www.indiana.edu/~kenkel



From e.catchpole at adfa.edu.au  Tue Oct 11 07:25:16 2005
From: e.catchpole at adfa.edu.au (ecatchpole)
Date: Tue, 11 Oct 2005 15:25:16 +1000
Subject: [R] greek symbols using pch
In-Reply-To: <die0c3$5ti$1@sea.gmane.org>
References: <283982AD9F3CD211B3AC00A0C983032F11443674@paradise.ansto.gov.au>
	<die0c3$5ti$1@sea.gmane.org>
Message-ID: <434B4CBC.6000006@adfa.edu.au>

On 11/10/05 01:12,  Earl F. Glynn wrote,:
> "FISCHER, Matthew" <mjf at ansto.gov.au> wrote in message
> news:283982AD9F3CD211B3AC00A0C983032F11443674 at paradise.ansto.gov.au...
> 
>>    In a plot, can I specify pch to be a greek symbol? (I looked at
>>show.pch() in the Hmisc package but couldn't see the right symbols in
> there).
>>If not, I guess I can get around this using text(x,y,expression()).
> 
> I'm not sure where this is explained very well.  Having ?font give a clue
> about this would be nice.
> 
> Use font=5, the symbol font.  To see what's in font=5:
> 
> par(font=5, las=1)
> plot(0:15,0:15,type="n",ylim=c(15,0),
>   main="Symbols in Font=5",
>   xlab="", ylab="",xaxt="n", yaxt="n")
> axis(BOTTOM<-1, at=0:15, 1:16)
> axis(LEFT  <-2, at=0:15)
> abline(v=0.5 + 0:14,
>        h=0.5 + 0:14, col="grey", lty="dotted")
> 
> # pch index of any cell is 16*row + column
> for(i in 0:255)
> {
>   x <- i %%16;
>   y <- i %/% 16;
>   points(x,y,pch=i+1)
> }

When I execute this code, I get a calligraphic R or P occurring with all 
of the nifty characters, e.g. \clubsuit. For example

par(font=5, las=1)
plot(0:1, 0:1, type="n")
points(.5, .5, pch=167)

This occurs on screen and in postscript() output. And with R2.1.0 and 
R2.2.0. Is this a bug?

Ted.

 > R.Version()
$platform
[1] "i686-pc-linux-gnu"

$arch
[1] "i686"

$os
[1] "linux-gnu"

$system
[1] "i686, linux-gnu"

$status
[1] ""

$major
[1] "2"

$minor
[1] "2.0"

$year
[1] "2005"

$month
[1] "10"

$day
[1] "06"

$"svn rev"
[1] "35749"

$language
[1] "R"



-- 
Dr E.A. Catchpole
Visiting Fellow
Univ of New South Wales at ADFA, Canberra, Australia
and University of Kent, Canterbury, England
- www.ma.adfa.edu.au/~eac
- fax: +61 2 6268 8786		
- ph:  +61 2 6268 8895



From ggrothendieck at gmail.com  Tue Oct 11 07:27:43 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 11 Oct 2005 01:27:43 -0400
Subject: [R] Sometimes having problems finding a minimum using optim(),
	optimize(), and nlm() (while searching for noncentral F parameters)
In-Reply-To: <434B41B1.6000305@Indiana.Edu>
References: <434B41B1.6000305@Indiana.Edu>
Message-ID: <971536df0510102227o322c70acy2c506dbae857c65a@mail.gmail.com>

I haven't look at your code but here a couple of things to try:

1. try using the square of the difference rather than the absolute value
as your objective so that your objective is differentiable.

2. your objective function may be relatively flat in which case it will be
difficult to get a precise answer.   plot your objective function to see and
try transforming the variable being optimized, e.g. 1/lambda, and then
plotting that to see if its less flat in the region of interest.


On 10/11/05, Ken Kelley <KKIII at indiana.edu> wrote:
> Hi everyone.
>
> I have a problem that I have been unable to determine either the best
> way to proceed and why the methods I'm trying to use sometimes fail. I'm
> using the pf() function in an optimization function to find a
> noncentrality parameter that leads to a specific value at a specified
> quantile. My goal is to have a general function that returns the
> noncentrality parameter that leads to a given value at a defined
> quantile. For example, with 5 and 200 degrees of freedom, what
> noncentrality parameter has at its .975 quantile a value of 4 (it is
> 3.0725 by the way)? The code I've written, using three different methods
> works great at times, but at other times it fails (sometimes all
> sometimes not). It isn't even that the functions I'm trying to write
> fail, but the reason they sometimes fail and sometimes do not is what is
> really bothering me; I simply don't understand why the functions at
> times stop the iterative process of minimization and return what the
> function believes to be a successful convergence value (e.g., optim()
> sometimes returns a 0 stating successful convergence when it clearly is
> not).
>
> I'm using three function [optim(), optimize(), and nlm()] to try and
> accomplish the same goal (which was stated above). I believe that they
> should all return the same value, and at times they do just that, but at
> other times the methods return inappropriate results. I'll paste my code
> that illustrates an example where all is well and one where things fail.
>
> Is there are easier way to do what I'm trying to accomplish? The analog
> in SAS of what I'm trying to come up with is FNONCT.
>
> #Begin code
> ##################################################################
> # Define necessary values.
> F.value <- 4
> tol <- 1e-8
> df.1 <- 5
> df.2 <- 200
> alpha.lower <- .025
> maxit<-1000
>
> # The function to be minimized. Here we are looking for the noncentral
> # value, 'Lambda', that has at its .975 quantile 'F.value'.
> Low.Lim.NC.F <- function(Lambda, alpha.lower, F.value, df.1, df.2)
> {
> abs(pf(q=F.value, df1=df.1, df2=df.2, ncp=Lambda) - (1-alpha.lower))
> # This will be near zero when an appropriate Lambda value is found.
> # The Lambda value that leads to a solution of zero is the noncentrality
> # value that has at its .975 quantile a value of 'F.value'.
> }
>
> # Use the quantile from a central F distribution as a minimum.
> LL.0 <- qf(p=alpha.lower, df1=df.1, df2=df.2)
>
> optim(par=LL.0, fn=Low.Lim.NC.F,
> method="L-BFGS-B", # Others return the same result usually.
> lower=LL.0, upper = Inf, control = list(maxit=maxit, reltol=1e-10),
> hessian = FALSE, alpha.lower=alpha.lower, F.value=F.value, df.1=df.1,
> df.2=df.2)
>
> # Try to accomplish the same task with a different R function.
> optimize(f=Low.Lim.NC.F, lower=LL.0, upper=50, maximum=FALSE, tol=tol,
> alpha.lower=alpha.lower, F.value=F.value, df.1=df.1, df.2=df.2)
>
> # Try to accomplish the same task with a different R function.
> nlm(f=Low.Lim.NC.F, p=LL.0, fscale=1,
> print.level = 0, ndigit=12, gradtol = 1e-6,
> stepmax = max(1000 * sqrt(sum((LL.0/10)^2)), 1000),
> steptol = 1e-6, iterlim = 1000, check.analyticals = TRUE,
> alpha.lower=alpha.lower, F.value=F.value, df.1=df.1, df.2=df.2)
>
> # The answer in each case is 3.0725. Thus, a noncentral F with
> # 5 and 200 df with a noncentrality parameter 3.0725 has at its .975
> # quantile a value of 4 (this has been verified in another software).
>
> # But, suppose we triple the F.value to 12 and rerun the code.
>
> F.value <- 12
>
> # The function to be minimized. Here we are looking for the noncentral
> # value, 'Lambda', that has at its .975 quantile 'F.value'.
> Low.Lim.NC.F <- function(Lambda, alpha.lower, F.value, df.1, df.2)
> {
> abs(pf(q=F.value, df1=df.1, df2=df.2, ncp=Lambda) - (1-alpha.lower))
> }
>
> # Use the quantile from a central F distribution as a minimum.
> LL.0 <- qf(p=alpha.lower, df1=df.1, df2=df.2)
>
> optim(par=LL.0, fn=Low.Lim.NC.F,
> method="L-BFGS-B",  # Others return the same result usually.
>  lower=LL.0, upper = Inf, control = list(maxit=maxit, reltol=1e-10),
> hessian = FALSE, alpha.lower=alpha.lower, F.value=F.value, df.1=df.1,
> df.2=df.2)
>
> # Try to accomplish the same task with a different R function.
> optimize(f=Low.Lim.NC.F, lower=LL.0, upper=500, maximum=FALSE, tol=tol,
> alpha.lower=alpha.lower, F.value=F.value, df.1=df.1, df.2=df.2)
>
> # Try to accomplish the same task with a different R function.
> nlm(f=Low.Lim.NC.F, p=LL.0, fscale=1,
> gradtol = 1e-6, stepmax = max(1000 * sqrt(sum((LL.0/10)^2)), 1000),
> steptol = 1e-6, iterlim = 1000, check.analyticals = TRUE,
> alpha.lower=alpha.lower, F.value=F.value, df.1=df.1, df.2=df.2)
>
> # Now only optimize() works and optim() and nlm() both return the
> # same (wrong) answer. Why would the function stop when the
> # minimized value was .025 (when it should stop when the value is
> # very close to zero)?
>
> # But, optimize() isn't always the answer either, because if the
> # upper limit is too large, the function will fail.
> # For example, changing the upper limit of optimize in
> # this example to 1000 leads to a failure.
> ##################################################################
> #End Code
>
> Am I going about this the best, or even a reasonable, way? Are there
> other functions I'm missing that would be more appropriate given what
> I'm trying to do? Any help would most certainly be appreciated.
>
> Thanks,
> Ken
>
> --
> Ken Kelley, Ph.D.
> Inquiry Methodology Program
> Indiana University
> 201 North Rose Avenue, Room 4004
> Bloomington, Indiana 47405
> http://www.indiana.edu/~kenkel
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From cjosephlu at gmail.com  Tue Oct 11 07:42:13 2005
From: cjosephlu at gmail.com (Joe)
Date: Tue, 11 Oct 2005 13:42:13 +0800
Subject: [R] Is this correct?
Message-ID: <69fb45ec0510102242n506b1e8q@mail.gmail.com>

Dear userR,

With the following results, are they correct or acceptable?

> x <- c(1.4, 1.2, 2.8)
> sum(x)
[1] 5.4
> sum(x) == 5.4
[1] FALSE
> (1.4 + 1.2 + 2.8) - 5.4
[1] -8.881784e-16
> (1.4 + 1.2) - 2.6
[1] -4.440892e-16
> 2.6 - 1.5 - 1.1
[1] 0

> version
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    2.0
year     2005
month    10
day      06
svn rev  35749
language R

What can I do to correct them if they are not correct?
Thanks!
--
C. Joseph Lu
Department of Statistics
National Cheng-Kung University
Tainan, Taiwan, ROC



From e.catchpole at adfa.edu.au  Tue Oct 11 07:57:58 2005
From: e.catchpole at adfa.edu.au (ecatchpole)
Date: Tue, 11 Oct 2005 15:57:58 +1000
Subject: [R] Is this correct?
In-Reply-To: <69fb45ec0510102242n506b1e8q@mail.gmail.com>
References: <69fb45ec0510102242n506b1e8q@mail.gmail.com>
Message-ID: <434B5466.6060406@adfa.edu.au>

See the R FAQ list, section 7. Why doesn't R think these numbers are equal?

Ted.

On 11/10/05 15:42,  Joe wrote,:
> Dear userR,
> 
> With the following results, are they correct or acceptable?
> 
>>x <- c(1.4, 1.2, 2.8)
>>sum(x)
> [1] 5.4
>>sum(x) == 5.4
> [1] FALSE
>>(1.4 + 1.2 + 2.8) - 5.4
> [1] -8.881784e-16
>>(1.4 + 1.2) - 2.6
> [1] -4.440892e-16
>>2.6 - 1.5 - 1.1
> [1] 0
> 
>>version
>          _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    2.0
> year     2005
> month    10
> day      06
> svn rev  35749
> language R
> 
> What can I do to correct them if they are not correct?
> Thanks!
> --
> C. Joseph Lu
> Department of Statistics
> National Cheng-Kung University
> Tainan, Taiwan, ROC
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Dr E.A. Catchpole
Visiting Fellow
Univ of New South Wales at ADFA, Canberra, Australia
and University of Kent, Canterbury, England
- www.ma.adfa.edu.au/~eac
- fax: +61 2 6268 8786		
- ph:  +61 2 6268 8895



From vincent at 7d4.com  Tue Oct 11 08:29:11 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Tue, 11 Oct 2005 08:29:11 +0200
Subject: [R] Is this correct?
In-Reply-To: <69fb45ec0510102242n506b1e8q@mail.gmail.com>
References: <69fb45ec0510102242n506b1e8q@mail.gmail.com>
Message-ID: <434B5BB7.5010207@7d4.com>

Joe a ??crit :

> Dear userR,
> With the following results, are they correct or acceptable?
> What can I do to correct them if they are not correct?

http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f

see also
?round

hih



From ripley at stats.ox.ac.uk  Tue Oct 11 09:36:08 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Oct 2005 08:36:08 +0100 (BST)
Subject: [R] greek symbols using pch
In-Reply-To: <434B4CBC.6000006@adfa.edu.au>
References: <283982AD9F3CD211B3AC00A0C983032F11443674@paradise.ansto.gov.au>
	<die0c3$5ti$1@sea.gmane.org> <434B4CBC.6000006@adfa.edu.au>
Message-ID: <Pine.LNX.4.61.0510110742380.13144@gannet.stats>

This is now well off the topic of the subject line, but I am afraid some 
misinformation has been propagated (and that is the `bug').

There _are_ bugs in the code shown: the postscript fonts support 32:255, 
not 1:256, and pch:0:31 are not taken from the font.  It seems an 
uninformed modification of the code in ?postscript.


What locale are you in?  That's something bug.report() gives and the 
posting guide asks for (because it often matters).

The code given works (albeit with warnings) in an 8-bit locale, but it 
often will not work in a multi-byte locale. In particular it does not work 
in a UTF-8 locale for a postcript() device.

The help page for points() does point out clearly

      In a multi-byte locale
      such as UTF-8, numeric values of \code{pch} greater than or equal to
      32 specify a Unicode code point.

Thus in UTF-8, pch=167 should be interpreted as a Unicode code point, and 
that is not a Greek symbol.

The problem for postscript() (and X11()) is that the standard font=5 is 
not encoded in the locale's encoding but Adobe Symbol, so supplying 
Unicode characters is unsupported.

I think R is working as documented here, but the piece of documentation 
about font=5 is in a different place (it is driver-specific).

Internationalization support for the postscript() driver is work in 
progress (more features will appear in 2.3.0), but at present all you can 
expect to work in a UTF-8 locale are ISO Latin-1 characters, and symbols 
via plotmath.

(I am aware of a few things that are not quite right in the Unicode 
support: some are being fixed for 2.3.0.)


On Tue, 11 Oct 2005, ecatchpole wrote:

> On 11/10/05 01:12,  Earl F. Glynn wrote,:
>> "FISCHER, Matthew" <mjf at ansto.gov.au> wrote in message
>> news:283982AD9F3CD211B3AC00A0C983032F11443674 at paradise.ansto.gov.au...
>>
>>>    In a plot, can I specify pch to be a greek symbol? (I looked at
>>> show.pch() in the Hmisc package but couldn't see the right symbols in
>> there).
>>> If not, I guess I can get around this using text(x,y,expression()).
>>
>> I'm not sure where this is explained very well.  Having ?font give a clue
>> about this would be nice.
>>
>> Use font=5, the symbol font.  To see what's in font=5:
>>
>> par(font=5, las=1)
>> plot(0:15,0:15,type="n",ylim=c(15,0),
>>   main="Symbols in Font=5",
>>   xlab="", ylab="",xaxt="n", yaxt="n")
>> axis(BOTTOM<-1, at=0:15, 1:16)
>> axis(LEFT  <-2, at=0:15)
>> abline(v=0.5 + 0:14,
>>        h=0.5 + 0:14, col="grey", lty="dotted")
>>
>> # pch index of any cell is 16*row + column
>> for(i in 0:255)
>> {
>>   x <- i %%16;
>>   y <- i %/% 16;
>>   points(x,y,pch=i+1)
>> }
>
> When I execute this code, I get a calligraphic R or P occurring with all
> of the nifty characters, e.g. \clubsuit. For example
>
> par(font=5, las=1)
> plot(0:1, 0:1, type="n")
> points(.5, .5, pch=167)
>
> This occurs on screen and in postscript() output. And with R2.1.0 and
> R2.2.0. Is this a bug?
>
> Ted.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Oct 11 09:42:50 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Oct 2005 08:42:50 +0100 (BST)
Subject: [R] Writing to a file with fixed precision
In-Reply-To: <1128992844.4115.11.camel@localhost.localdomain>
References: <00b501c5cdf5$7595cb80$b6cecb84@nom5n6hnfuv31a>
	<1128992844.4115.11.camel@localhost.localdomain>
Message-ID: <Pine.LNX.4.61.0510110839010.13144@gannet.stats>

On Mon, 10 Oct 2005, Marc Schwartz wrote:

> On Mon, 2005-10-10 at 19:50 -0400, Richard Hedger wrote:
>> Hi,
>> I'm trying to ouput to a filled with a fixed precision:
>> eg. if I have data x=c(1.0,1.4,2.0), I want to be able to ouput the following to a file:
>> 1.00000000000000
>> 1.40000000000000
>> 2.00000000000000
>> I was wondering if there was a function to do this in R?
>> Thanks,
>> Richard
>
> It is possible that someone has written such a function somewhere.

It's called format().

x <- c(1.0,1.4,2.0)
write(format(x, nsmall=14))

does this.

> However, this is relatively easy using write.table(). You just need to
> pre-format the numeric values prior to writing to the file:
>
> write.table(sprintf("%.14f", x), "data.txt", col.names = FALSE,
>            row.names = FALSE, quote = FALSE)
>
> Using sprintf(), we force the floats to have 14 decimal places.
> sprintf() outputs character vectors, so we remove the quoting of the
> resultant character vectors and don't write column/row names.
>
> Note that if 'x' is a matrix, using sprintf() will return a vector. So
> you might want to use the following instead to retain the dims:
>
>> x
>     [,1] [,2] [,3] [,4]
> [1,]    1    4    7   10
> [2,]    2    5    8   11
> [3,]    3    6    9   12
>
>> x.fmt <- apply(x, 1, function(x) sprintf("%.14f", x))
>
>> x.fmt
>     [,1]                [,2]                [,3]
> [1,] "1.00000000000000"  "2.00000000000000"  "3.00000000000000"
> [2,] "4.00000000000000"  "5.00000000000000"  "6.00000000000000"
> [3,] "7.00000000000000"  "8.00000000000000"  "9.00000000000000"
> [4,] "10.00000000000000" "11.00000000000000" "12.00000000000000"
>
>> write.table(x.fmt, "data.txt", col.names = FALSE, row.names = FALSE,
>              quote = FALSE)
>
>
> If needed, you can of course change the default delimiter from a " " to
> another character in write.table().
>
> See ?write.table and ?sprintf.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ggrothendieck at gmail.com  Tue Oct 11 09:43:01 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 11 Oct 2005 03:43:01 -0400
Subject: [R] aligning column of xyplots and removing space between them
Message-ID: <971536df0510110043w2e4a47b5le0f43b03871e91a4@mail.gmail.com>

The code below displays three graphs in three rows and one column but:

1. I want to remove the space between the graphs (I tried playing with position=
arg to print.trellis but it seems quite difficult to get the right
values and all
my attempts had space between them or had overlapping graphs.  Is
there a better way to do this?

2. the widths of the plots are not the same even though I specified the same
xlim= to them all.  How do I make them the same?

3. how do I get rid of the ticks at the top of the bottom plot?

4. the bottom graph is supposed to plot 1:3 against itself but the third
point is not showing even though I specified ylim = c(0,3).  Must
I specify ylim = c(0,3+1) or is there a better way?


Here is the code (its a modified version of some code that I previously
posted regarding a different question):

### everything from here to the grid.newpage line is just
### to set up the viewports for the graphs so you
### can just go to the comment that says
### 'relevant part starts here'

library(grid)
library(lattice)
trellis.par.set(theme = col.whitebg())

grid.newpage()

pushLayout <- function(nr, nc, ..., name="layout") {
  pushViewport(viewport(layout=grid.layout(nr, nc, ...), name=name))
  for (i in 1:nr) {
    for (j in 1:nc) {
      pushViewport(viewport(layout.pos.row=i, layout.pos.col=j))
      upViewport()
    }
  }
  upViewport()
}

with.vpPath <-
with.viewport <- function(data, expr, ...) {
      # if data is a vpPath it cannot be ROOT since NULL will not dispatch here
      depth <- if (data$name == "ROOT") 0 else downViewport(data$name)
      result <- eval.parent(substitute(expr))
      upViewport(depth)
      invisible(result)
}

grid.newpage()

# n and nr are number of cells and rows
n <- nr <- 3
nc <- 1  # must be 1

heights <- unit(c(2, rep(1, nr-1)), "null")
downViewport(pushLayout(nr, nc, heights = heights))

vpt <- current.vpTree(all = FALSE)

### relevant part starts here
#########################

xlab <- main <- function(x) if (x) "v"
for(k in 1:n) with(vpt$children[[k]],
        print( xyplot(v ~ v, list(v = 1:k), xlab = xlab(k == n),
	xlim = c(0,n), ylim = c(0,n), main = main(k == 1),
	scales = list(x = list(draw = k == n), y = list(alternating = 3))),
	newpage = FALSE)
)



From Alexander.Ploner at meb.ki.se  Tue Oct 11 10:04:54 2005
From: Alexander.Ploner at meb.ki.se (Alexander Ploner)
Date: Tue, 11 Oct 2005 10:04:54 +0200
Subject: [R] Q: Suggestions for long-term data/program storage policy?
Message-ID: <58EEE8D3-A8AF-41DC-B821-A12CE05C1580@meb.ki.se>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051011/2730d245/attachment.pl

From hyasrebi at yahoo.com  Tue Oct 11 10:10:40 2005
From: hyasrebi at yahoo.com (Haleh Yasrebi)
Date: Tue, 11 Oct 2005 01:10:40 -0700 (PDT)
Subject: [R] knn
Message-ID: <20051011081040.23909.qmail@web32915.mail.mud.yahoo.com>

Hello,
Why do I get doubt (NA) in the factor of test
classification even if I fix l (minimum vote)? By
setting l, no doubt should be occurred.

Look forward to your reply

Haleh



From j.van_den_hoff at fz-rossendorf.de  Tue Oct 11 10:18:24 2005
From: j.van_den_hoff at fz-rossendorf.de (joerg van den hoff)
Date: Tue, 11 Oct 2005 10:18:24 +0200
Subject: [R] problem with lapply(x, subset,
	...) and variable select argument
In-Reply-To: <971536df0510101027u5a6160f9t9a3809d75eb76a3e@mail.gmail.com>
References: <434A8CFF.5070300@fz-rossendorf.de>
	<971536df0510101027u5a6160f9t9a3809d75eb76a3e@mail.gmail.com>
Message-ID: <434B7550.8060402@fz-rossendorf.de>

Gabor Grothendieck wrote:
> The problem is that subset looks into its parent frame but in this
> case the parent frame is not the environment in tt but the environment
> in lapply since tt does not call subset directly but rather lapply does.
> 
> Try this which is similar except we have added the line beginning
> with environment before the print statement.
> 
> tt <- function (n) {
>    x <- list(data.frame(a=1,b=2), data.frame(a=3,b=4))
>    environment(lapply) <- environment()
>    print(lapply(x, subset, select = n))
> }
> 
> n <- "b"
> tt("a")
> 
> What this does is create a new version of lapply whose
> parent is the environment in tt.
> 
> 
> On 10/10/05, joerg van den hoff <j.van_den_hoff at fz-rossendorf.de> wrote:
> 
>>I need to extract identically named columns from several data frames in
>>a list. the column name is a variable (i.e. not known in advance). the
>>whole thing occurs within a function body. I'd like to use lapply with a
>>variable 'select' argument.
>>
>>
>>example:
>>
>>tt <- function (n) {
>>   x <- list(data.frame(a=1,b=2), data.frame(a=3,b=4))
>>   for (xx in x) print(subset(xx, select = n))   ### works
>>   print (lapply(x, subset, select = a))   ### works
>>   print (lapply(x, subset, select = "a"))  ### works
>>   print (lapply(x, subset, select = n))  ### does not work as intended
>>}
>>n = "b"
>>tt("a")  #works (but selects not the intended column)
>>rm(n)
>>tt("a")   #no longer works in the lapply call including variable 'n'
>>
>>
>>question: how  can I enforce evaluation of the variable n such that
>>the lapply call works? I suspect it has something to do with eval and
>>specifying the correct evaluation frame, but how? ....
>>
>>
>>many thanks
>>
>>joerg
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
> 

many thanks to thomas and gabor for their help. both solutions solve my 
problem perfectly.

but just as an attempt to improve my understanding of the inner workings 
of R (similar problems are sure to come up ...) two more question:

1.
why does the call of the "[" function (thomas' solution) behave 
different from "subset" in that the look up of the variable "n" works 
without providing lapply with the current environment (which is nice)?

2.
using 'subset' in this context becomes more cumbersome, if sapply is 
used. it seems that than I need
...
environment(sapply) <- environment(lapply) <- environment()
sapply(x, subset, select = n))
...
to get it working (and that means you must know, that sapply uses 
lapply). or can I somehow avoid the additional explicit definition of 
the lapply-environment?


again: many thanks

joerg



From i.j.gallagher at sms.ed.ac.uk  Tue Oct 11 10:28:30 2005
From: i.j.gallagher at sms.ed.ac.uk (Iain Gallagher)
Date: Tue, 11 Oct 2005 09:28:30 +0100
Subject: [R] plot - no main title and missing abscissa value
In-Reply-To: <434AD897.3030606@statistik.uni-dortmund.de>
References: <434A5FC0.7030400@sms.ed.ac.uk>
	<434AD897.3030606@statistik.uni-dortmund.de>
Message-ID: <434B77AE.8010703@sms.ed.ac.uk>

Thanks Uwe.

The R version I'm using is 2.1.1 on Mac OS 10.3.9

I was going to try and replicate this on a linux system at home but have 
not had the time so far. I'll let you know how it goes.


Iain

Uwe Ligges wrote:

> Iain Gallagher wrote:
>
>> Hi. Sorry (esp to Uwe for the repeated messages!)
>>
>> Here is the data and my code in full. Thanks for the
>> help.
>>
>> Data.
>>
>> Day    Ym1Imp    Ym1sham    Semimp    Semsham
>> 0    5.78    5.78    1.22    1.36
>> 1    44.36    42.1    16.26    18.83
>> 3    38.39    14.66    18.02    2.86
>> 5    57.76    1.03    15.28    0.29
>> 7    72.93    2.71    18.6    1.06
>> 10    48.57    4.61    11.26    5.21
>> 14    74.08    1.53    9.66    0.11
>> 21    73.86    0.14    7.2    0.02
>>
>>
>> Code
>>
>> ym<- read.table("ym1expression.csv", header=T,
>> sep="\t", quote="\"") #read in ym data
>> attach(ym)# make data visible to R
>> par(mar=c(5,5,4,5),las=1, xpd=NA)
>> x<- c(0,1,3,5,7,10,14,21)
>> plot(Day, Ym1Imp, ylim=c(0,100), type="b", bty="l",
>> main="Ym1 Expression", cex=1.3, xaxt="n", yaxt="n")
>> #plot implant data
>> axis(side=1, at=c(0,1,3,5,7,10,14,21),
>> labels=c(0,1,3,5,7,10,14,21)) # label x axis
>> mtext("Day", side =1, at=10, line=3, cex=1.2) # title
>> x axis
>> mtext("AU", side=2, at=50, line=3, cex=1.2)# y axis
>> title
>> axis(side=2, at=c(0, 25, 50, 75, 100),
>> labels=expression("0", "25", "50", "75", "100")) #
>> label y axis
>> arrows(x, Ym1Imp-Semimp, x, Ym1Imp+Semimp, code=3,
>> angle=90, length=0.1)# place error bars
>> points(Day, Ym1sham, type="b", pch=16, cex=1.3)# plot
>> sham data
>> arrows(x, Ym1sham-Semsham, x, Ym1sham+Semsham, code=3,
>> angle=90, length=0.1)# plot sham error bars
>> legend(20, 60, legend="Implant", pch=1, lty=1,
>> bty="n")# implant legend
>> legend(20, 50, legend="Sham", pch=16, lty=1, bty="n")#
>> sham legend
>>
>> Iain
>>
>
>
> Three points:
>
> 1. The main title appears for me under the Windows device. I really 
> wonder why you do not see it, this seems to be quite a strange device 
> dependence I would not expect in this case.
> Since you told us you have "R 2.1", we do not know exactly what you 
> have got - there is no such version. There are versions R-2.0.1, 
> R-2.1.0 and R-2.1.1, though. Anyway, you told us you found a workaround.
>
>
> 2. In order to re-plot the axis labels, you should specify  xlab=NA, 
> ylab=NA in your call to plot() as in:
> plot(Day, Ym1Imp, ylim=c(0,100), type="b", bty="l", xlab=NA, ylab=NA,
>     main="Ym1 Expression", cex=1.3, xaxt="n", yaxt="n")
>
> 3. As I have already guessed, the axis annotation of the tick at 
> position 1 is left out because R thinks there is not enough space left.
> You can workaround this point by making the label appear separately as 
> in:
> axis(side=1, at=c(0,3,5,7,10,14,21))
> axis(1, 1)
>
> Uwe Ligges
>
>


-- 
Iain Gallagher
Institute for Infection & Immunology Research
Ashworth Laboratories
Kings Buildings
University of Edinburgh
Edinburgh
EH9 3JT
UK

(+44) 0131 651 3630



From john.maindonald at anu.edu.au  Tue Oct 11 10:35:19 2005
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Tue, 11 Oct 2005 18:35:19 +1000
Subject: [R] Multiple expressions, when using substitute()
In-Reply-To: <434B1851.3030501@pdf.com>
References: <AA4E55C3-34AF-491F-8F22-38F3441A1725@anu.edu.au>
	<434B1851.3030501@pdf.com>
Message-ID: <1010AA51-DF1B-4FAC-BD20-B7988711A827@anu.edu.au>

Yes, I did get a very helpful reply from Marc Schwartz.  I have
had substitute() working in legend(), when the legend argument
has length one.  The challenge was to find some way to do the
equivalent of substitute() when several expressions appear in
parallel, as may be required for legend().

The trick is to use bquote() to do the substitution.  The resulting
quoted expression (of mode "call") can then be an element in a
list, along with other quoted (or bquoted) expressions.   The
list elements, when passed to expression() via the args
argument of do.call(), become unquoted expressions.

Note that bquote() uses a syntax for the substitution of variables
that is different from that used by substitute().  It would be useful
to include some such example as below on the help page for
bquote():


library(DAAG)
Acmena <- subset(rainforest, species="Acmena")
plot(wood~dbh, data=Acmena)
Acmena.lm <- lm(log(wood) ~ log(dbh), data=Acmena)
b <- round(coef(Acmena.lm), 3)
arg1 <- bquote(italic(y) == .(A) * italic(x)^.(B),
                    list(A=b[1], B=b[2]))
arg2 <- quote("where " * italic(y) * "=wood; " *
                           italic(x) * "=dbh")
legend("topleft", legend=do.call("expression", c(arg1, arg2)),
                bty="n")

John Maindonald.


On 11 Oct 2005, at 11:41 AM, Spencer Graves wrote:


>       Have you received a reply to this post?  I couldn't find one,  
> and I couldn't find a solution, even though one must exist.  I can  
> get the substitute to work in "main" but not "legend":
>
> B <- 2:3
> eB <- substitute(y==a*x^b, list(a=B[1], b=B[2]))
> plot(1:2, 1:2, main=eB)
>
>       You should be able to construct it using "mtext", but I  
> couldn't get the desired result using legend.
>
>       hope this helps.
>       spencer graves
>
> John Maindonald wrote:
>
>
>
>> expression() accepts multiple expressions as arguments, thus:
>> plot(1:2, 1:2)
>> legend("topleft",
>>                expression(y == a * x^b,
>>                                     "where "* paste(y=="wood; ",   
>> x=="dbh")))
>> Is there a way to do this when values are to be substituted
>> for a and b? i.e., the first element of the legend argument
>> to legend() becomes, effectively:
>>    substitute(y == a * x^b, list(a = B[1], b=B[2]))
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Bioinformation Science, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting- 
>> guide.html
>>
>>
>
> -- 
> Spencer Graves, PhD
> Senior Development Engineer
> PDF Solutions, Inc.
> 333 West San Carlos Street Suite 700
> San Jose, CA 95110, USA
>
> spencer.graves at pdf.com
> www.pdf.com <http://www.pdf.com>
> Tel:  408-938-4420
> Fax: 408-280-7915
>
>



John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Bioinformation Science, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.



From E.Catchpole at adfa.edu.au  Tue Oct 11 10:44:40 2005
From: E.Catchpole at adfa.edu.au (ecatchpole)
Date: Tue, 11 Oct 2005 18:44:40 +1000
Subject: [R] font=5 (Was: greek symbols using pch)
In-Reply-To: <Pine.LNX.4.61.0510110742380.13144@gannet.stats>
References: <283982AD9F3CD211B3AC00A0C983032F11443674@paradise.ansto.gov.au>
	<die0c3$5ti$1@sea.gmane.org> <434B4CBC.6000006@adfa.edu.au>
	<Pine.LNX.4.61.0510110742380.13144@gannet.stats>
Message-ID: <434B7B78.6020603@adfa.edu.au>

Thanks for that. Very instructive, and much appreciated.

And sorry, yes, I strayed well off the original topic. The Greek symbols 
  come out fine with font=5 in my locale,
Locale:
LC_CTYPE=en_GB.UTF-8;
LC_NUMERIC=C;
LC_TIME=en_GB.UTF-8;

I was interested in some of the other nice characters, for example 
\infty and \partial, that appear in the table, but with a calligraphic R 
attached to them. But plotmath() works fine, so I'm happy.

Ted.

On 11/10/05 17:36,  Prof Brian Ripley wrote,:
> This is now well off the topic of the subject line, but I am afraid some 
> misinformation has been propagated (and that is the `bug').
> 
> There _are_ bugs in the code shown: the postscript fonts support 32:255, 
> not 1:256, and pch:0:31 are not taken from the font.  It seems an 
> uninformed modification of the code in ?postscript.
> 
> 
> What locale are you in?  That's something bug.report() gives and the 
> posting guide asks for (because it often matters).
> 
> The code given works (albeit with warnings) in an 8-bit locale, but it 
> often will not work in a multi-byte locale. In particular it does not 
> work in a UTF-8 locale for a postcript() device.
> 
> The help page for points() does point out clearly
> 
>      In a multi-byte locale
>      such as UTF-8, numeric values of \code{pch} greater than or equal to
>      32 specify a Unicode code point.
> 
> Thus in UTF-8, pch=167 should be interpreted as a Unicode code point, 
> and that is not a Greek symbol.
> 
> The problem for postscript() (and X11()) is that the standard font=5 is 
> not encoded in the locale's encoding but Adobe Symbol, so supplying 
> Unicode characters is unsupported.
> 
> I think R is working as documented here, but the piece of documentation 
> about font=5 is in a different place (it is driver-specific).
> 
> Internationalization support for the postscript() driver is work in 
> progress (more features will appear in 2.3.0), but at present all you 
> can expect to work in a UTF-8 locale are ISO Latin-1 characters, and 
> symbols via plotmath.
> 
> (I am aware of a few things that are not quite right in the Unicode 
> support: some are being fixed for 2.3.0.)
> 
> 
> On Tue, 11 Oct 2005, ecatchpole wrote:
> 
>> On 11/10/05 01:12,  Earl F. Glynn wrote,:
>>> "FISCHER, Matthew" <mjf at ansto.gov.au> wrote in message
>>> news:283982AD9F3CD211B3AC00A0C983032F11443674 at paradise.ansto.gov.au...
>>>
>>>>    In a plot, can I specify pch to be a greek symbol? (I looked at
>>>> show.pch() in the Hmisc package but couldn't see the right symbols in
>>> there).
>>>> If not, I guess I can get around this using text(x,y,expression()).
>>>
>>> I'm not sure where this is explained very well.  Having ?font give a 
>>> clue
>>> about this would be nice.
>>>
>>> Use font=5, the symbol font.  To see what's in font=5:
>>>
>>> par(font=5, las=1)
>>> plot(0:15,0:15,type="n",ylim=c(15,0),
>>>   main="Symbols in Font=5",
>>>   xlab="", ylab="",xaxt="n", yaxt="n")
>>> axis(BOTTOM<-1, at=0:15, 1:16)
>>> axis(LEFT  <-2, at=0:15)
>>> abline(v=0.5 + 0:14,
>>>        h=0.5 + 0:14, col="grey", lty="dotted")
>>>
>>> # pch index of any cell is 16*row + column
>>> for(i in 0:255)
>>> {
>>>   x <- i %%16;
>>>   y <- i %/% 16;
>>>   points(x,y,pch=i+1)
>>> }
>>
>> When I execute this code, I get a calligraphic R or P occurring with all
>> of the nifty characters, e.g. \clubsuit. For example
>>
>> par(font=5, las=1)
>> plot(0:1, 0:1, type="n")
>> points(.5, .5, pch=167)
>>
>> This occurs on screen and in postscript() output. And with R2.1.0 and
>> R2.2.0. Is this a bug?
>>
>> Ted.
> 


-- 
Dr E.A. Catchpole
Visiting Fellow
Univ of New South Wales at ADFA, Canberra, Australia
and University of Kent, Canterbury, England
- www.ma.adfa.edu.au/~eac
- fax: +61 2 6268 8786		
- ph:  +61 2 6268 8895



From dimitris.rizopoulos at med.kuleuven.be  Tue Oct 11 10:57:39 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Tue, 11 Oct 2005 10:57:39 +0200
Subject: [R] problem with lapply(x, subset,
	...) and variable select argument
References: <434A8CFF.5070300@fz-rossendorf.de><971536df0510101027u5a6160f9t9a3809d75eb76a3e@mail.gmail.com>
	<434B7550.8060402@fz-rossendorf.de>
Message-ID: <00e501c5ce41$d558f460$0540210a@www.domain>

As Gabor said, the issue here is that subset.data.frame() evaluates 
the value of the `select' argument in the parent.frame(); Thus, if you 
create a local function within lapply() (or sapply()) it works:

tt <- function (n) {
    x <- list(data.frame(a = 1, b = 2), data.frame(a = 3, b = 4))
    print(lapply(x, function(y, n) subset(y, select = n), n = n))
    print(sapply(x, function(y, n) subset(y, select = n), n = n))
}

tt("a")


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm



----- Original Message ----- 
From: "joerg van den hoff" <j.van_den_hoff at fz-rossendorf.de>
To: "Gabor Grothendieck" <ggrothendieck at gmail.com>; "Thomas Lumley" 
<tlumley at u.washington.edu>
Cc: "r-help" <r-help at stat.math.ethz.ch>
Sent: Tuesday, October 11, 2005 10:18 AM
Subject: Re: [R] problem with lapply(x, subset,...) and variable 
select argument


> Gabor Grothendieck wrote:
>> The problem is that subset looks into its parent frame but in this
>> case the parent frame is not the environment in tt but the 
>> environment
>> in lapply since tt does not call subset directly but rather lapply 
>> does.
>>
>> Try this which is similar except we have added the line beginning
>> with environment before the print statement.
>>
>> tt <- function (n) {
>>    x <- list(data.frame(a=1,b=2), data.frame(a=3,b=4))
>>    environment(lapply) <- environment()
>>    print(lapply(x, subset, select = n))
>> }
>>
>> n <- "b"
>> tt("a")
>>
>> What this does is create a new version of lapply whose
>> parent is the environment in tt.
>>
>>
>> On 10/10/05, joerg van den hoff <j.van_den_hoff at fz-rossendorf.de> 
>> wrote:
>>
>>>I need to extract identically named columns from several data 
>>>frames in
>>>a list. the column name is a variable (i.e. not known in advance). 
>>>the
>>>whole thing occurs within a function body. I'd like to use lapply 
>>>with a
>>>variable 'select' argument.
>>>
>>>
>>>example:
>>>
>>>tt <- function (n) {
>>>   x <- list(data.frame(a=1,b=2), data.frame(a=3,b=4))
>>>   for (xx in x) print(subset(xx, select = n))   ### works
>>>   print (lapply(x, subset, select = a))   ### works
>>>   print (lapply(x, subset, select = "a"))  ### works
>>>   print (lapply(x, subset, select = n))  ### does not work as 
>>> intended
>>>}
>>>n = "b"
>>>tt("a")  #works (but selects not the intended column)
>>>rm(n)
>>>tt("a")   #no longer works in the lapply call including variable 
>>>'n'
>>>
>>>
>>>question: how  can I enforce evaluation of the variable n such that
>>>the lapply call works? I suspect it has something to do with eval 
>>>and
>>>specifying the correct evaluation frame, but how? ....
>>>
>>>
>>>many thanks
>>>
>>>joerg
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! 
>>>http://www.R-project.org/posting-guide.html
>>>
>>
>>
>
> many thanks to thomas and gabor for their help. both solutions solve 
> my
> problem perfectly.
>
> but just as an attempt to improve my understanding of the inner 
> workings
> of R (similar problems are sure to come up ...) two more question:
>
> 1.
> why does the call of the "[" function (thomas' solution) behave
> different from "subset" in that the look up of the variable "n" 
> works
> without providing lapply with the current environment (which is 
> nice)?
>
> 2.
> using 'subset' in this context becomes more cumbersome, if sapply is
> used. it seems that than I need
> ...
> environment(sapply) <- environment(lapply) <- environment()
> sapply(x, subset, select = n))
> ...
> to get it working (and that means you must know, that sapply uses
> lapply). or can I somehow avoid the additional explicit definition 
> of
> the lapply-environment?
>
>
> again: many thanks
>
> joerg
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From sourceforge at metrak.com  Tue Oct 11 11:02:49 2005
From: sourceforge at metrak.com (sosman)
Date: Tue, 11 Oct 2005 19:02:49 +1000
Subject: [R] Q: Suggestions for long-term data/program storage policy?
In-Reply-To: <58EEE8D3-A8AF-41DC-B821-A12CE05C1580@meb.ki.se>
References: <58EEE8D3-A8AF-41DC-B821-A12CE05C1580@meb.ki.se>
Message-ID: <434B7FB9.9020802@metrak.com>

Alexander Ploner wrote:
> Dear list,
> 
> we are a statistical/epidemiological departement that - after a few  
> years of rapid growth - finally is getting around to formulate a  
> general data storage and retention policy - mainly to ensure that we  
> can reproduce results from published papers/theses easier in the  
> future, but also with the hope that we get more synergy between  
> related projects.
> 
> We have formulated what we feel is a reasonable draft, requiring  
> basically that the raw data, all programs to create derived data  
> sets, and the analysis programs are stored and documented in a  
> uniform manner, regardless of the analysis software used. The minimum  
> data retention we are aiming for is 10 years, and the format for the  
> raw data is quite sane (either flat ASCII or real
> 
> Given the rapid devlopment cycle of R, this suggests that at the very  
> least all non-base packages used in the analysis are stored together  
> with each project. I have basically two questions:
> 
> 1) Are old R versions (binaries/sources) going to be available on  
> CRAN indefinitely?
> 
> 2) Is .RData a reasonable file format for long term storage?
> 
> I would also be very grateful for any other suggestions, comments or  
> links for setting up and implementing such a storage policy (R- 
> specific or otherwise).

I am coming more from a software development angle but you might want to 
take a look at subversion for versioning your projects.  For non-geeky 
types, TortoiseSVN has a point and click interface.

It handles binary files efficiently and you can easily go back and get 
earlier versions of your projects.

http://subversion.tigris.org/



From p.dalgaard at biostat.ku.dk  Tue Oct 11 11:36:05 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 11 Oct 2005 11:36:05 +0200
Subject: [R] problem with lapply(x, subset,
	...) and variable select argument
In-Reply-To: <00e501c5ce41$d558f460$0540210a@www.domain>
References: <434A8CFF.5070300@fz-rossendorf.de>
	<971536df0510101027u5a6160f9t9a3809d75eb76a3e@mail.gmail.com>
	<434B7550.8060402@fz-rossendorf.de>
	<00e501c5ce41$d558f460$0540210a@www.domain>
Message-ID: <x2slv81jlm.fsf@viggo.kubism.ku.dk>

"Dimitris Rizopoulos" <dimitris.rizopoulos at med.kuleuven.be> writes:

> As Gabor said, the issue here is that subset.data.frame() evaluates 
> the value of the `select' argument in the parent.frame(); Thus, if you 
> create a local function within lapply() (or sapply()) it works:

It's more complicated than that: It evaluates the select argument in a
named list with names duplicating those of the data frame, and *then*
in parent.frame. This is convenient for command line use, because you
can specify ranges of variables as in

  dfsub <- subset(dfr,select=c(sex:treat, x_pre:x_24))

but it is quite risky to try and do this inside a function - if you're
passing in a variable, the result depends on whether there is a
variable of the same name in the data frame! You can probably get
around it using substitute() constructions, but I think it is safer to
avoid using functions with nonstandard semantics inside functions.
 
 
> tt <- function (n) {
>     x <- list(data.frame(a = 1, b = 2), data.frame(a = 3, b = 4))
>     print(lapply(x, function(y, n) subset(y, select = n), n = n))
>     print(sapply(x, function(y, n) subset(y, select = n), n = n))
> }
> 
> tt("a")
> 
> 
> I hope it helps.
> 
> Best,
> Dimitris
> 
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
> 
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/(0)16/336899
> Fax: +32/(0)16/337015
> Web: http://www.med.kuleuven.be/biostat/
>      http://www.student.kuleuven.be/~m0390867/dimitris.htm
> 
> 
> 
> ----- Original Message ----- 
> From: "joerg van den hoff" <j.van_den_hoff at fz-rossendorf.de>
> To: "Gabor Grothendieck" <ggrothendieck at gmail.com>; "Thomas Lumley" 
> <tlumley at u.washington.edu>
> Cc: "r-help" <r-help at stat.math.ethz.ch>
> Sent: Tuesday, October 11, 2005 10:18 AM
> Subject: Re: [R] problem with lapply(x, subset,...) and variable 
> select argument
> 
> 
> > Gabor Grothendieck wrote:
> >> The problem is that subset looks into its parent frame but in this
> >> case the parent frame is not the environment in tt but the 
> >> environment
> >> in lapply since tt does not call subset directly but rather lapply 
> >> does.
> >>
> >> Try this which is similar except we have added the line beginning
> >> with environment before the print statement.
> >>
> >> tt <- function (n) {
> >>    x <- list(data.frame(a=1,b=2), data.frame(a=3,b=4))
> >>    environment(lapply) <- environment()
> >>    print(lapply(x, subset, select = n))
> >> }
> >>
> >> n <- "b"
> >> tt("a")
> >>
> >> What this does is create a new version of lapply whose
> >> parent is the environment in tt.
> >>
> >>
> >> On 10/10/05, joerg van den hoff <j.van_den_hoff at fz-rossendorf.de> 
> >> wrote:
> >>
> >>>I need to extract identically named columns from several data 
> >>>frames in
> >>>a list. the column name is a variable (i.e. not known in advance). 
> >>>the
> >>>whole thing occurs within a function body. I'd like to use lapply 
> >>>with a
> >>>variable 'select' argument.
> >>>
> >>>
> >>>example:
> >>>
> >>>tt <- function (n) {
> >>>   x <- list(data.frame(a=1,b=2), data.frame(a=3,b=4))
> >>>   for (xx in x) print(subset(xx, select = n))   ### works
> >>>   print (lapply(x, subset, select = a))   ### works
> >>>   print (lapply(x, subset, select = "a"))  ### works
> >>>   print (lapply(x, subset, select = n))  ### does not work as 
> >>> intended
> >>>}
> >>>n = "b"
> >>>tt("a")  #works (but selects not the intended column)
> >>>rm(n)
> >>>tt("a")   #no longer works in the lapply call including variable 
> >>>'n'
> >>>
> >>>
> >>>question: how  can I enforce evaluation of the variable n such that
> >>>the lapply call works? I suspect it has something to do with eval 
> >>>and
> >>>specifying the correct evaluation frame, but how? ....
> >>>
> >>>
> >>>many thanks
> >>>
> >>>joerg
> >>>
> >>>______________________________________________
> >>>R-help at stat.math.ethz.ch mailing list
> >>>https://stat.ethz.ch/mailman/listinfo/r-help
> >>>PLEASE do read the posting guide! 
> >>>http://www.R-project.org/posting-guide.html
> >>>
> >>
> >>
> >
> > many thanks to thomas and gabor for their help. both solutions solve 
> > my
> > problem perfectly.
> >
> > but just as an attempt to improve my understanding of the inner 
> > workings
> > of R (similar problems are sure to come up ...) two more question:
> >
> > 1.
> > why does the call of the "[" function (thomas' solution) behave
> > different from "subset" in that the look up of the variable "n" 
> > works
> > without providing lapply with the current environment (which is 
> > nice)?
> >
> > 2.
> > using 'subset' in this context becomes more cumbersome, if sapply is
> > used. it seems that than I need
> > ...
> > environment(sapply) <- environment(lapply) <- environment()
> > sapply(x, subset, select = n))
> > ...
> > to get it working (and that means you must know, that sapply uses
> > lapply). or can I somehow avoid the additional explicit definition 
> > of
> > the lapply-environment?
> >
> >
> > again: many thanks
> >
> > joerg
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> 
> 
> Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Tue Oct 11 12:14:15 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Oct 2005 11:14:15 +0100 (BST)
Subject: [R] knn
In-Reply-To: <20051011081040.23909.qmail@web32915.mail.mud.yahoo.com>
References: <20051011081040.23909.qmail@web32915.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.61.0510111106530.15465@gannet.stats>

Please do read the posting guide and supply a reproducible example as it 
asks.  Here it matters critically what you mean by `fix l' (to what 
value?).

Is this knn in package class?  Have you read the help page?  Have you read 
the references (especially the first)?

On Tue, 11 Oct 2005, Haleh Yasrebi wrote:

> Why do I get doubt (NA) in the factor of test
> classification even if I fix l (minimum vote)? By
> setting l, no doubt should be occurred.

That is completely opposite to what the help page for knn in package class 
says happens, so why do you think so?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From murdoch at stats.uwo.ca  Tue Oct 11 12:44:48 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 11 Oct 2005 06:44:48 -0400
Subject: [R] Is this correct?
In-Reply-To: <69fb45ec0510102242n506b1e8q@mail.gmail.com>
References: <69fb45ec0510102242n506b1e8q@mail.gmail.com>
Message-ID: <434B97A0.5050409@stats.uwo.ca>

Joe wrote:
> Dear userR,
> 
> With the following results, are they correct or acceptable?

Yes.  See the FAQ:

7.31 Why doesn't R think these numbers are equal?

The only numbers that can be represented exactly in R's numeric type are 
integers and fractions whose denominator is a power of 2. Other numbers 
have to be rounded to (typically) 53 binary digits accuracy. As a 
result, two floating point numbers will not reliably be equal unless 
they have been computed by the same algorithm, and not always even then. 
For example

      R> a <- sqrt(2)
      R> a * a == 2
      [1] FALSE
      R> a * a - 2
      [1] 4.440892e-16

The function all.equal() compares two objects using a numeric tolerance 
of .Machine$double.eps ^ 0.5. If you want much greater accuracy than 
this you will need to consider error propagation carefully.

For more information, see e.g. David Goldberg (1991), ?What Every 
Computer Scientist Should Know About Floating-Point Arithmetic?, ACM 
Computing Surveys, 23/1, 5?48, also available via 
http://docs.sun.com/source/806-3568/ncg_goldberg.html.

> 
> 
>>x <- c(1.4, 1.2, 2.8)
>>sum(x)
> 
> [1] 5.4
> 
>>sum(x) == 5.4
> 
> [1] FALSE
> 
>>(1.4 + 1.2 + 2.8) - 5.4
> 
> [1] -8.881784e-16
> 
>>(1.4 + 1.2) - 2.6
> 
> [1] -4.440892e-16
> 
>>2.6 - 1.5 - 1.1
> 
> [1] 0
> 
> 
>>version
> 
>          _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    2.0
> year     2005
> month    10
> day      06
> svn rev  35749
> language R
> 
> What can I do to correct them if they are not correct?
> Thanks!
> --
> C. Joseph Lu
> Department of Statistics
> National Cheng-Kung University
> Tainan, Taiwan, ROC
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From murdoch at stats.uwo.ca  Tue Oct 11 12:54:32 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 11 Oct 2005 06:54:32 -0400
Subject: [R] Q: Suggestions for long-term data/program storage policy?
In-Reply-To: <58EEE8D3-A8AF-41DC-B821-A12CE05C1580@meb.ki.se>
References: <58EEE8D3-A8AF-41DC-B821-A12CE05C1580@meb.ki.se>
Message-ID: <434B99E8.3070001@stats.uwo.ca>

Alexander Ploner wrote:
> Dear list,
> 
> we are a statistical/epidemiological departement that - after a few  
> years of rapid growth - finally is getting around to formulate a  
> general data storage and retention policy - mainly to ensure that we  
> can reproduce results from published papers/theses easier in the  
> future, but also with the hope that we get more synergy between  
> related projects.
> 
> We have formulated what we feel is a reasonable draft, requiring  
> basically that the raw data, all programs to create derived data  
> sets, and the analysis programs are stored and documented in a  
> uniform manner, regardless of the analysis software used. The minimum  
> data retention we are aiming for is 10 years, and the format for the  
> raw data is quite sane (either flat ASCII or real
> 
> Given the rapid devlopment cycle of R, this suggests that at the very  
> least all non-base packages used in the analysis are stored together  
> with each project. I have basically two questions:
> 
> 1) Are old R versions (binaries/sources) going to be available on  
> CRAN indefinitely?

I think sources will be, binaries much less reliably.  (I just 
discovered that one or two of the old Windows binaries are corrupted; 
I'm not sure I'll be able to find good copies.)

> 2) Is .RData a reasonable file format for long term storage?

I think the intention is that it will be supported in future versions of 
R, but storing data in a binary format is risky.  What if you don't use 
R in 5 years?  You would find it a lot easier to decode text format 
files in another package than .RData format.

The other advantage of text format is that it works very well with 
version control systems like Subversion or CVS.  You can see several 
versions of the file, see comments on why changes were made, etc.

Duncan Murdoch
> 
> I would also be very grateful for any other suggestions, comments or  
> links for setting up and implementing such a storage policy (R- 
> specific or otherwise).
> 
> Thank you for your time,
> 
> alexander
> 
> 
> Alexander.Ploner at meb.ki.se
> Medical Epidemiology & Biostatistics
> Karolinska Institutet, Stockholm
> Tel: ++46-8-524-82329
> Fax: ++46-8-31 49 75
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From sdavis2 at mail.nih.gov  Tue Oct 11 13:01:23 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 11 Oct 2005 07:01:23 -0400
Subject: [R] R on a supercomputer
In-Reply-To: <2E6C5260C7C387449A96DF46EE76313C0236A140@iu-mssg-mbx02.exchange.iu.edu>
Message-ID: <BF7113C3.102EB%sdavis2@mail.nih.gov>

On 10/10/05 3:54 PM, "Kimpel, Mark William" <mkimpel at iupui.edu> wrote:

> I am using R with Bioconductor to perform analyses on large datasets
> using bootstrap methods. In an attempt to speed up my work, I have
> inquired about using our local supercomputer and asked the administrator
> if he thought R would run faster on our parallel network. I received the
> following reply:
> 
> 
> 
> 
> 
> "The second benefit is that the processors have large caches.
> 
> Briefly, everything is loaded into cache before going into the
> processor.  With large caches, there is less movement of data between
> memory and cache, and this can save quite a bit of time.  Indeed, when
> programmers optimize code they usually think about how to do things to
> keep data in cache as long as possible.
> 
> Whether you would receive any benefit from larger cache depends on how
> R is written. If it's written such that  data remain in cache, the
> speed-up could be considerable, but I have no way to predict it."
> 
> 
> 
> My question is, "is R written such that data remain in cache?"

Using the cluster model (which may or may not be what you are calling a
supercomputer--I don't know the exact terminology here), jobs that involve
repetitive, independent tasks like computing statistics on bootstrap
replicates can benefit from parallelization IF the "I/O" associated with
running the single replicate does not outweigh the benefit of using multiple
processors.  For example, if you are running 10000 replicates and each takes
1 ms, then you have a 10 second job on a single processor.  One could
envision spreading that same process over 1000 processors and doing the job
in 10 ms, but if one counts the I/O (network, moving into cache, etc.) which
could take 1 second per batch of replicates (for example), then that job
will take AT LEAST 10 seconds with 1000 processors, also.  However, if the
same computation takes 1 second per replicate, then the whole job takes
10,000 seconds on a single processor, but only about 11 seconds on the 1000
processors (approximately).  This rationale is only approximate, but I hope
it shows the point.

We have begun to use a 60-node linux cluster for some of our work (also
microarray-based) and use MPI/snow with very nice results for multiple
independent, long-running tasks.  Snow is VERY easy to use, but one could
also drop back to the Rmpi if needed, to have finer-grain control over the
parallelization process.

As for how caching behaviors come into it and how R without "parallelized"
R-code would perform, I can't really comment; my experience is limited to
the "cluster" model with parallelized R-code.

Sean



From ripley at stats.ox.ac.uk  Tue Oct 11 13:04:38 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Oct 2005 12:04:38 +0100 (BST)
Subject: [R] Q: Suggestions for long-term data/program storage policy?
In-Reply-To: <58EEE8D3-A8AF-41DC-B821-A12CE05C1580@meb.ki.se>
References: <58EEE8D3-A8AF-41DC-B821-A12CE05C1580@meb.ki.se>
Message-ID: <Pine.LNX.4.61.0510111115020.15465@gannet.stats>

On Tue, 11 Oct 2005, Alexander Ploner wrote:

> we are a statistical/epidemiological departement that - after a few
> years of rapid growth - finally is getting around to formulate a
> general data storage and retention policy - mainly to ensure that we
> can reproduce results from published papers/theses easier in the
> future, but also with the hope that we get more synergy between
> related projects.
>
> We have formulated what we feel is a reasonable draft, requiring
> basically that the raw data, all programs to create derived data
> sets, and the analysis programs are stored and documented in a
> uniform manner, regardless of the analysis software used. The minimum
> data retention we are aiming for is 10 years, and the format for the
> raw data is quite sane (either flat ASCII or real

You are intending to retain copies of the OS used and hardware too?
The results depend far more on those than you apparently realize.

> Given the rapid devlopment cycle of R,

I think you will find your OS changes as fast: all those security updates 
potentially affect your results.

> this suggests that at the very least all non-base packages used in the 
> analysis are stored together with each project. I have basically two 
> questions:
>
> 1) Are old R versions (binaries/sources) going to be available on
> CRAN indefinitely?

Not binaries.  The intention is that source files be available, but they 
could become corrupted (as it seems the Windows binary has for a past 
version).

> 2) Is .RData a reasonable file format for long term storage?

I would say not, as it is almost impossible to recover from any corruption 
in such a file.  We like to have long-term data in a human-readable 
printout, with a print copy, and also store some checksums.

> I would also be very grateful for any other suggestions, comments or
> links for setting up and implementing such a storage policy (R-
> specific or otherwise).

You need to consider the medium on which you are going to store the 
archive.  We currrently use CD-R (and not tapes as those are less 
compatible across drives -- we have two identical drives currently but do 
not expect either to last 10 years), and check them annually -- I guess we 
will re-write to another medium after much less than 10 years.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sdavis2 at mail.nih.gov  Tue Oct 11 13:11:14 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 11 Oct 2005 07:11:14 -0400
Subject: [R] Q: Suggestions for long-term data/program storage policy?
In-Reply-To: <434B99E8.3070001@stats.uwo.ca>
Message-ID: <BF711612.102F1%sdavis2@mail.nih.gov>

On 10/11/05 6:54 AM, "Duncan Murdoch" <murdoch at stats.uwo.ca> wrote:

> Alexander Ploner wrote:
>> Dear list,
>> 
>> we are a statistical/epidemiological departement that - after a few
>> years of rapid growth - finally is getting around to formulate a
>> general data storage and retention policy - mainly to ensure that we
>> can reproduce results from published papers/theses easier in the
>> future, but also with the hope that we get more synergy between
>> related projects.
>> I would also be very grateful for any other suggestions, comments or
>> links for setting up and implementing such a storage policy (R-
>> specific or otherwise).

I would also consider a relational database (such as mysql or postgres) for
your data warehousing.  These products (particularly postgres) are designed
with data integrity first-and-foremost.  Data formats can change over time,
but the data can be easily extracted from the database to match the needs at
hand.  Data generated at different times can be easily mined and combined as
needed.  The data backup process is fairly straightforward.  R already
integrates with several relational database systems, so an integrated
solution can be defined if one so desires.  Look at RMySQL, Rdbi, and
RdbiPgSQL for how to integrate R with MySQL and Postgres.

Sean



From abderrahim.oulhaj at pharmacology.oxford.ac.uk  Tue Oct 11 13:35:52 2005
From: abderrahim.oulhaj at pharmacology.oxford.ac.uk (Abderrahim Oulhaj)
Date: Tue, 11 Oct 2005 12:35:52 +0100
Subject: [R] random effects are mixture of normals
Message-ID: <00ee01c5ce57$efc04900$adca01a3@optima.ox.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051011/187b4d38/attachment.pl

From MSchwartz at mn.rr.com  Tue Oct 11 14:36:38 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Tue, 11 Oct 2005 07:36:38 -0500
Subject: [R] Writing to a file with fixed precision
In-Reply-To: <Pine.LNX.4.61.0510110839010.13144@gannet.stats>
References: <00b501c5cdf5$7595cb80$b6cecb84@nom5n6hnfuv31a>
	<1128992844.4115.11.camel@localhost.localdomain>
	<Pine.LNX.4.61.0510110839010.13144@gannet.stats>
Message-ID: <1129034198.4115.36.camel@localhost.localdomain>

On Tue, 2005-10-11 at 08:42 +0100, Prof Brian Ripley wrote:
> On Mon, 10 Oct 2005, Marc Schwartz wrote:
> 
> > On Mon, 2005-10-10 at 19:50 -0400, Richard Hedger wrote:
> >> Hi,
> >> I'm trying to ouput to a filled with a fixed precision:
> >> eg. if I have data x=c(1.0,1.4,2.0), I want to be able to ouput the following to a file:
> >> 1.00000000000000
> >> 1.40000000000000
> >> 2.00000000000000
> >> I was wondering if there was a function to do this in R?
> >> Thanks,
> >> Richard
> >
> > It is possible that someone has written such a function somewhere.
> 
> It's called format().
> 
> x <- c(1.0,1.4,2.0)
> write(format(x, nsmall=14))
> 
> does this.

Indeed. Sorry, I was not clear in my use of words. I was thinking along
the lines of a single function call such as:

  write.fmt(x, file = "data.txt", ndigits = 14)

It would of course be easy enough to create such a wrapper using
existing functions.

I was aware of format(), but for some reason had in the back of my mind
that the use of 'nsmall' was not consistent in the decimal place output
based upon prior experience.

The result of which led me to use the vectorized formatC() to control
such output. I then shifted to using sprintf(), when in 2.1.0, it was
vectorized.

Using format() also adds the benefit of having methods for matrices,
etc., as opposed to sprintf().

Thanks,

Marc



From andy_liaw at merck.com  Tue Oct 11 14:54:42 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 11 Oct 2005 08:54:42 -0400
Subject: [R] Vectorizing loop
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED4F5@usctmx1106.merck.com>

I don't have anything specific to say.  Only the following suggestion:

Try and find out where in the code most of the time is spent.  R has nice
tools for that.  See ?Rprof.  If it's runifpoint() and Kest() that are
taking most of the computing time, you may not be able to do much better.

Andy

> From: Rainer M. Krug
> 
> Sorry
> 
> runifpoint() and Kest are from the package spatstat
> 
> Rainer
> 
> Liaw, Andy wrote:
> > Not unless we know what runifpoint() and Kest() are.  AFAIK 
> these are not
> > part of base R.  If you use functions from add-on packages, 
> please state
> > them so as not to leave others guessing.  (This is in the 
> Posting Guide,
> > which you were asked to read.)
> > 
> > Andy
> > 
> > 
> >>From: Rainer M. Krug
> >>
> >>Hi
> >>
> >>I have the following loop and would like to vectorize it. Any 
> >>ideas if 
> >>it is possible?
> >>
> >>Thanks,
> >>
> >>Rainer
> >>
> >>Tha Loop:
> >>
> >>for (i in 2:Result$NoSims)
> >>{
> >>	ppp <- runifpoint(Result$NoPlants)
> >>	K <- Kest(ppp)
> >>	Result$LSim[i,] <- sqrt(K$iso / pi) - K$r
> >>	CM <- (Result$LSim[i,] * Result$LSim[i,]) / abs(K$r[2] - K$r[1])
> >>	Result$SigCM[i] <- sum(CM, na.rm=TRUE)
> >>	print(i)
> >>	flush.console()
> >>}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From gregory.r.warnes at pfizer.com  Tue Oct 11 15:55:48 2005
From: gregory.r.warnes at pfizer.com (Warnes, Gregory R)
Date: Tue, 11 Oct 2005 09:55:48 -0400
Subject: [R] glm contrasts (was: no subject)
Message-ID: <915D2D65A9986440A277AC5C98AA466F01863480@groamrexm02.amer.pfizer.com>

> estimable in bundle gregmisc (package gmodels) should do this.
> 
> (Kiebitzers: Hope I got the bundle/package/library definition correct)

FWIW, we tried gregmisc as a bundle, but it proved to be too much of a pain,
so all of the component packages are now separately provided.

The 'gremgisc' package now simply depends on the individual components.
Thus, 

	install.package('gregmisc',depend=TRUE) 

will get all of the packages.


-Greg
----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From rab45+ at pitt.edu  Tue Oct 11 16:01:19 2005
From: rab45+ at pitt.edu (Rick Bilonick)
Date: Tue, 11 Oct 2005 10:01:19 -0400
Subject: [R] Hmisc latex function
Message-ID: <1129039280.3048.7.camel@localhost.localdomain>

I'm using R 2.2.0 on an up-to-date version of Fedora Core 4 with the
latest version of Hmisc. When I run an example from the latex function I
get the following:

> x <- matrix(1:6, nrow=2, dimnames=list(c('a','b'),c('c','d','enLine
2')))
> x
  c d enLine 2
a 1 3        5
b 2 4        6
> latex(x)   # creates x.tex in working directory
sh: line 0: cd: â€œ/tmp/Rtmpl10983â€: No such file or directory
This is pdfeTeX, Version 3.141592-1.21a-2.2 (Web2C 7.5.4)
entering extended mode
! I can't find file `â€œ/tmp/Rtmpl10983/file643c9869â€'.
<*> â€œ/tmp/Rtmpl10983/file643c9869â€

Please type another input file name: q
(/usr/share/texmf/tex/latex/tools/q.tex
LaTeX2e <2003/12/01>
Babel <v3.8d> and hyphenation patterns for american, french, german,
ngerman, b
ahasa, basque, bulgarian, catalan, croatian, czech, danish, dutch,
esperanto, e
stonian, finnish, greek, icelandic, irish, italian, latin, magyar,
norsk, polis
h, portuges, romanian, russian, serbian, slovak, slovene, spanish,
swedish, tur
kish, ukrainian, nohyphenation, loaded.
File ignored
xdvi-motif.bin: Fatal error: /tmp/Rtmpl10983/file643c9869.dvi: No such
file.


How can I fix this?

Rick B.



From tlumley at u.washington.edu  Tue Oct 11 16:31:00 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 11 Oct 2005 07:31:00 -0700 (PDT)
Subject: [R] problem with lapply(x, subset,
 ...) and variable select argument
In-Reply-To: <434B7550.8060402@fz-rossendorf.de>
References: <434A8CFF.5070300@fz-rossendorf.de>
	<971536df0510101027u5a6160f9t9a3809d75eb76a3e@mail.gmail.com>
	<434B7550.8060402@fz-rossendorf.de>
Message-ID: <Pine.LNX.4.63a.0510110725030.27917@homer24.u.washington.edu>

On Tue, 11 Oct 2005, joerg van den hoff wrote:
> many thanks to thomas and gabor for their help. both solutions solve my 
> problem perfectly.
>
> but just as an attempt to improve my understanding of the inner workings of R 
> (similar problems are sure to come up ...) two more question:
>
> 1.
> why does the call of the "[" function (thomas' solution) behave different 
> from "subset" in that the look up of the variable "n" works without providing 
> lapply with the current environment (which is nice)?

"[" behaves like nearly all functions in R: the value of the argument is 
passed.   subset() does some tricky things to subvert the usual argument 
passing.  Quite a few of the modelling functions do similar tricky things, 
and they do sometimes get confused when passed as arguments to another 
function.

> 2.
> using 'subset' in this context becomes more cumbersome, if sapply is used. it 
> seems that than I need
> ...
> environment(sapply) <- environment(lapply) <- environment()
> sapply(x, subset, select = n))
> ...
> to get it working (and that means you must know, that sapply uses lapply). or 
> can I somehow avoid the additional explicit definition of the 
> lapply-environment?

You really don't want to go around playing with environment() on 
functions. That way lies madness.  Use subset at the command line and [ or 
[[ in programming.  I don't think I have ever set environment() on a 
function (only on formulas).


 	-thomas



From ggrothendieck at gmail.com  Tue Oct 11 16:36:39 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 11 Oct 2005 10:36:39 -0400
Subject: [R] problem with lapply(x, subset,
	...) and variable select argument
In-Reply-To: <00e501c5ce41$d558f460$0540210a@www.domain>
References: <434A8CFF.5070300@fz-rossendorf.de>
	<971536df0510101027u5a6160f9t9a3809d75eb76a3e@mail.gmail.com>
	<434B7550.8060402@fz-rossendorf.de>
	<00e501c5ce41$d558f460$0540210a@www.domain>
Message-ID: <971536df0510110736o54a9256dw28aa31c02d644ae8@mail.gmail.com>

Just one simple shortening of DR's solution:

tt <- function (n) {
   x <- list(data.frame(a=1,b=2), data.frame(a=3,b=4))
   print(sapply(x, function(...) subset(...), select = n))
}

n <- "b"
tt("a")


On 10/11/05, Dimitris Rizopoulos <dimitris.rizopoulos at med.kuleuven.be> wrote:
> As Gabor said, the issue here is that subset.data.frame() evaluates
> the value of the `select' argument in the parent.frame(); Thus, if you
> create a local function within lapply() (or sapply()) it works:
>
> tt <- function (n) {
>    x <- list(data.frame(a = 1, b = 2), data.frame(a = 3, b = 4))
>    print(lapply(x, function(y, n) subset(y, select = n), n = n))
>    print(sapply(x, function(y, n) subset(y, select = n), n = n))
> }
>
> tt("a")
>
>
> I hope it helps.
>
> Best,
> Dimitris
>
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
>
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/(0)16/336899
> Fax: +32/(0)16/337015
> Web: http://www.med.kuleuven.be/biostat/
>     http://www.student.kuleuven.be/~m0390867/dimitris.htm
>
>
>
> ----- Original Message -----
> From: "joerg van den hoff" <j.van_den_hoff at fz-rossendorf.de>
> To: "Gabor Grothendieck" <ggrothendieck at gmail.com>; "Thomas Lumley"
> <tlumley at u.washington.edu>
> Cc: "r-help" <r-help at stat.math.ethz.ch>
> Sent: Tuesday, October 11, 2005 10:18 AM
> Subject: Re: [R] problem with lapply(x, subset,...) and variable
> select argument
>
>
> > Gabor Grothendieck wrote:
> >> The problem is that subset looks into its parent frame but in this
> >> case the parent frame is not the environment in tt but the
> >> environment
> >> in lapply since tt does not call subset directly but rather lapply
> >> does.
> >>
> >> Try this which is similar except we have added the line beginning
> >> with environment before the print statement.
> >>
> >> tt <- function (n) {
> >>    x <- list(data.frame(a=1,b=2), data.frame(a=3,b=4))
> >>    environment(lapply) <- environment()
> >>    print(lapply(x, subset, select = n))
> >> }
> >>
> >> n <- "b"
> >> tt("a")
> >>
> >> What this does is create a new version of lapply whose
> >> parent is the environment in tt.
> >>
> >>
> >> On 10/10/05, joerg van den hoff <j.van_den_hoff at fz-rossendorf.de>
> >> wrote:
> >>
> >>>I need to extract identically named columns from several data
> >>>frames in
> >>>a list. the column name is a variable (i.e. not known in advance).
> >>>the
> >>>whole thing occurs within a function body. I'd like to use lapply
> >>>with a
> >>>variable 'select' argument.
> >>>
> >>>
> >>>example:
> >>>
> >>>tt <- function (n) {
> >>>   x <- list(data.frame(a=1,b=2), data.frame(a=3,b=4))
> >>>   for (xx in x) print(subset(xx, select = n))   ### works
> >>>   print (lapply(x, subset, select = a))   ### works
> >>>   print (lapply(x, subset, select = "a"))  ### works
> >>>   print (lapply(x, subset, select = n))  ### does not work as
> >>> intended
> >>>}
> >>>n = "b"
> >>>tt("a")  #works (but selects not the intended column)
> >>>rm(n)
> >>>tt("a")   #no longer works in the lapply call including variable
> >>>'n'
> >>>
> >>>
> >>>question: how  can I enforce evaluation of the variable n such that
> >>>the lapply call works? I suspect it has something to do with eval
> >>>and
> >>>specifying the correct evaluation frame, but how? ....
> >>>
> >>>
> >>>many thanks
> >>>
> >>>joerg
> >>>
> >>>______________________________________________
> >>>R-help at stat.math.ethz.ch mailing list
> >>>https://stat.ethz.ch/mailman/listinfo/r-help
> >>>PLEASE do read the posting guide!
> >>>http://www.R-project.org/posting-guide.html
> >>>
> >>
> >>
> >
> > many thanks to thomas and gabor for their help. both solutions solve
> > my
> > problem perfectly.
> >
> > but just as an attempt to improve my understanding of the inner
> > workings
> > of R (similar problems are sure to come up ...) two more question:
> >
> > 1.
> > why does the call of the "[" function (thomas' solution) behave
> > different from "subset" in that the look up of the variable "n"
> > works
> > without providing lapply with the current environment (which is
> > nice)?
> >
> > 2.
> > using 'subset' in this context becomes more cumbersome, if sapply is
> > used. it seems that than I need
> > ...
> > environment(sapply) <- environment(lapply) <- environment()
> > sapply(x, subset, select = n))
> > ...
> > to get it working (and that means you must know, that sapply uses
> > lapply). or can I somehow avoid the additional explicit definition
> > of
> > the lapply-environment?
> >
> >
> > again: many thanks
> >
> > joerg
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
>
>
> Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Marco.Giannitrapani at shell.com  Tue Oct 11 16:51:37 2005
From: Marco.Giannitrapani at shell.com (Giannitrapani, Marco GSUK-GSSC)
Date: Tue, 11 Oct 2005 15:51:37 +0100
Subject: [R] probs in installing packages with R 2.2.0
Message-ID: <DC768C412F1C394192A8108281818F2B029A44EA@wyt-s-019.europe.shell.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051011/09c2a5f6/attachment.pl

From ripley at stats.ox.ac.uk  Tue Oct 11 17:00:15 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Oct 2005 16:00:15 +0100 (BST)
Subject: [R] probs in installing packages with R 2.2.0
In-Reply-To: <DC768C412F1C394192A8108281818F2B029A44EA@wyt-s-019.europe.shell.com>
References: <DC768C412F1C394192A8108281818F2B029A44EA@wyt-s-019.europe.shell.com>
Message-ID: <Pine.LNX.4.61.0510111556280.15770@gannet.stats>

I expect you need to set a proxy.  This is covered in the rw-FAQ that we 
do ask you to read before posting. See the item

 	The internet download functions fail.


On Tue, 11 Oct 2005, Giannitrapani, Marco GSUK-GSSC wrote:

> Dear R users.
>
> I was wondering if you could help me with this error message I get when I try to install packages.
>
> I just installed R (the latest version, R 2.2.0) on my laptop (windows), and I was trying to install packages intwo ways:
>
> 1)  Packages > Install Package(s)...
>
> 2) Packages > Install Package(s) from local zip files...
>
> , but in both ways I get the following error message:
>
> Warning: unable to access index for repository http://cran.uk.r-project.org/bin/windows/contrib/2.2
> Warning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/2.2
> Error in install.packages(NULL, .libPaths()[1], dependencies = TRUE, type = type) :
>        no packages were specified
>
> PS: I try selecting my CRAN mirror from different parts (UK, USA, ...), but it doesn't work
>
> Any idea, what is wrong with that?
>
> Should I install something before installing packages?
>
> Thanks in advance for your help!
>
> Cheers,
>
> Marco
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From spencer.graves at pdf.com  Tue Oct 11 17:08:14 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 11 Oct 2005 08:08:14 -0700
Subject: [R] Multiple expressions, when using substitute()
In-Reply-To: <1010AA51-DF1B-4FAC-BD20-B7988711A827@anu.edu.au>
References: <AA4E55C3-34AF-491F-8F22-38F3441A1725@anu.edu.au>
	<434B1851.3030501@pdf.com>
	<1010AA51-DF1B-4FAC-BD20-B7988711A827@anu.edu.au>
Message-ID: <434BD55E.9000202@pdf.com>

Thanks.  spencer graves

John Maindonald wrote:
> Yes, I did get a very helpful reply from Marc Schwartz.  I have
> had substitute() working in legend(), when the legend argument
> has length one.  The challenge was to find some way to do the
> equivalent of substitute() when several expressions appear in
> parallel, as may be required for legend().
> 
> The trick is to use bquote() to do the substitution.  The resulting
> quoted expression (of mode "call") can then be an element in a
> list, along with other quoted (or bquoted) expressions.   The
> list elements, when passed to expression() via the args
> argument of do.call(), become unquoted expressions.
> 
> Note that bquote() uses a syntax for the substitution of variables
> that is different from that used by substitute().  It would be useful
> to include some such example as below on the help page for
> bquote():
> 
> 
> library(DAAG)
> Acmena <- subset(rainforest, species="Acmena")
> plot(wood~dbh, data=Acmena)
> Acmena.lm <- lm(log(wood) ~ log(dbh), data=Acmena)
> b <- round(coef(Acmena.lm), 3)
> arg1 <- bquote(italic(y) == .(A) * italic(x)^.(B),
>                    list(A=b[1], B=b[2]))
> arg2 <- quote("where " * italic(y) * "=wood; " *
>                           italic(x) * "=dbh")
> legend("topleft", legend=do.call("expression", c(arg1, arg2)),
>                bty="n")
> 
> John Maindonald.
> 
> 
> On 11 Oct 2005, at 11:41 AM, Spencer Graves wrote:
> 
> 
>>       Have you received a reply to this post?  I couldn't find one,  
>> and I couldn't find a solution, even though one must exist.  I can  
>> get the substitute to work in "main" but not "legend":
>>
>> B <- 2:3
>> eB <- substitute(y==a*x^b, list(a=B[1], b=B[2]))
>> plot(1:2, 1:2, main=eB)
>>
>>       You should be able to construct it using "mtext", but I  
>> couldn't get the desired result using legend.
>>
>>       hope this helps.
>>       spencer graves
>>
>> John Maindonald wrote:
>>
>>
>>
>>> expression() accepts multiple expressions as arguments, thus:
>>> plot(1:2, 1:2)
>>> legend("topleft",
>>>                expression(y == a * x^b,
>>>                                     "where "* paste(y=="wood; ",   
>>> x=="dbh")))
>>> Is there a way to do this when values are to be substituted
>>> for a and b? i.e., the first element of the legend argument
>>> to legend() becomes, effectively:
>>>    substitute(y == a * x^b, list(a = B[1], b=B[2]))
>>> John Maindonald             email: john.maindonald at anu.edu.au
>>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>>> Centre for Bioinformation Science, Room 1194,
>>> John Dedman Mathematical Sciences Building (Building 27)
>>> Australian National University, Canberra ACT 0200.
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! http://www.R-project.org/posting- 
>>> guide.html
>>>
>>>
>>
>> -- 
>> Spencer Graves, PhD
>> Senior Development Engineer
>> PDF Solutions, Inc.
>> 333 West San Carlos Street Suite 700
>> San Jose, CA 95110, USA
>>
>> spencer.graves at pdf.com
>> www.pdf.com <http://www.pdf.com>
>> Tel:  408-938-4420
>> Fax: 408-280-7915
>>
>>
> 
> 
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Bioinformation Science, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> 

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From dray at biomserv.univ-lyon1.fr  Tue Oct 11 17:18:51 2005
From: dray at biomserv.univ-lyon1.fr (=?ISO-8859-1?Q?St=E9phane_Dray?=)
Date: Tue, 11 Oct 2005 17:18:51 +0200
Subject: [R] Sweave and Rnews
Message-ID: <434BD7DB.7090708@biomserv.univ-lyon1.fr>

Hello list,

I am writing a paper for Rnews. I use Sweave to do it. I did not find 
information about writing a paper for Rnews using Sweave and have some 
questions:
- Is there a problem to use the environment 'Sinput' in the place of 
'example' or 'smallexample'. It works fine but perhaps there are some 
technical/editorial problems ?
- I have some long lines of code in schunk. I did not find any way to 
cut them in the Rnw file and they appear out of the column in the dvi 
file. The only solution I found is to cut these lines in the tex file 
generated by Sweave. Is there a more elegant and automatic solution to 
this problem?

Thanks in advance.

-- 
St??phane DRAY (dray at biomserv.univ-lyon1.fr )
Laboratoire BBE-CNRS-UMR-5558, Univ. C. Bernard - Lyon I
43, Bd du 11 Novembre 1918, 69622 Villeurbanne Cedex, France
Tel: 33 4 72 43 27 57       Fax: 33 4 72 43 13 88
http://www.steph280.freesurf.fr/



From sara at gmesintra.com  Tue Oct 11 17:27:21 2005
From: sara at gmesintra.com (Sara Mouro)
Date: Tue, 11 Oct 2005 16:27:21 +0100
Subject: [R] Set Covering Problem (SCP) (in mathgraphs)
Message-ID: <200510111527.j9BFRJ49013439@hypatia.math.ethz.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051011/b657fde6/attachment.pl

From efg at stowers-institute.org  Tue Oct 11 17:23:24 2005
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Tue, 11 Oct 2005 10:23:24 -0500
Subject: [R] font=5 (Was: greek symbols using pch)
References: <283982AD9F3CD211B3AC00A0C983032F11443674@paradise.ansto.gov.au><die0c3$5ti$1@sea.gmane.org>
	<434B4CBC.6000006@adfa.edu.au><Pine.LNX.4.61.0510110742380.13144@gannet.stats>
	<434B7B78.6020603@adfa.edu.au>
Message-ID: <digldd$bnr$1@sea.gmane.org>

"ecatchpole" <E.Catchpole at adfa.edu.au> wrote in message
news:434B7B78.6020603 at adfa.edu.au...
> Thanks for that. Very instructive, and much appreciated.
>
> And sorry, yes, I strayed well off the original topic. The Greek symbols
>   come out fine with font=5 in my locale,
> Locale:
> LC_CTYPE=en_GB.UTF-8;
> LC_NUMERIC=C;
> LC_TIME=en_GB.UTF-8;
>
> I was interested in some of the other nice characters, for example
> \infty and \partial, that appear in the table, but with a calligraphic R
> attached to them. But plotmath() works fine, so I'm happy.

I performed some tests with font=5 on both Linux and Windows using
source("font5.R"), which is shown below, and then calling the Font5Test()
function.

Consistent results were seen with devices X11, png, and jpeg under either
Linux  (R 2.1.1) or Windows (R 2.2.0) in my locale.  Oddly, both the pdf and
postscript devices create 2 pages of output with the first page the expected
table and a second unexpected page with only the "clubs suite" symbol (167)
in the middle of the plot. I'd call this a bug, but I guess I haven't read
all the documentation about this yet.

efg
Earl F. Glynn
Scientific Programmer
Stowers Institute for Medical Research


font5.R
======

ShowFont5 <- function()
{
  oldpar <- par(font=5, las=1)
  plot(0:1, 0:1, type="n")
  points(.5, .5, pch=167)
  par(font=5, las=1)
  plot(0:15,0:15,type="n",ylim=c(15,0),
    main="Symbols in Font=5",
    xlab="", ylab="",xaxt="n", yaxt="n")
  axis(BOTTOM<-1, at=0:15)
  axis(LEFT  <-2, at=0:15, 16*0:15)
  abline(v=0.5 + 0:14,
         h=0.5 + 0:14, col="grey", lty="dotted")
  # pch index of any cell is 16*row + column
  for(i in 0:255)
  {
    x <- i %%16;
    y <- i %/% 16;
    points(x,y,pch=i)
  }
  par(oldpar)
}

Font5Test <- function()
{
  X11()
  ShowFont5()
  dev.off()

  pdf("font5.pdf")
  ShowFont5()
  dev.off()

  png("font5.png")
  ShowFont5()
  dev.off()

  jpeg("font5.jpg")
  ShowFont5()
  dev.off()

  postscript("font5.ps")
  ShowFont5()
  dev.off()

}


Linux Test
=======
> Sys.getlocale()
[1] "C"

> R.Version()
$platform
[1] "x86_64-unknown-linux-gnu"

$arch
[1] "x86_64"

$os
[1] "linux-gnu"

$system
[1] "x86_64, linux-gnu"

$status
[1] ""

$major
[1] "2"

$minor
[1] "1.1"

$year
[1] "2005"

$month
[1] "06"

$day
[1] "20"

$language
[1] "R"



Windows Test
==========
> Sys.getlocale()
[1] "LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252"

> R.Version()
$platform
[1] "i386-pc-mingw32"

$arch
[1] "i386"

$os
[1] "mingw32"

$system
[1] "i386, mingw32"

$status
[1] ""

$major
[1] "2"

$minor
[1] "2.0"

$year
[1] "2005"

$month
[1] "10"

$day
[1] "06"

$"svn rev"
[1] "35749"

$language
[1] "R"



From vincent.goulet at act.ulaval.ca  Tue Oct 11 17:42:35 2005
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Tue, 11 Oct 2005 11:42:35 -0400
Subject: [R] Sweave and Rnews
In-Reply-To: <434BD7DB.7090708@biomserv.univ-lyon1.fr>
References: <434BD7DB.7090708@biomserv.univ-lyon1.fr>
Message-ID: <200510111142.35756.vincent.goulet@act.ulaval.ca>

Le 11 Octobre 2005 11:18, St??phane Dray a ??crit??:
> - I have some long lines of code in schunk. I did not find any way to
> cut them in the Rnw file and they appear out of the column in the dvi
> file. The only solution I found is to cut these lines in the tex file
> generated by Sweave. Is there a more elegant and automatic solution to
> this problem?

See the Sweave FAQ:

http://www.ci.tuwien.ac.at/~leisch/Sweave/FAQ.html#x1-16000A.14

-- 
  Vincent Goulet, Professeur agr??g??
  ??cole d'actuariat
  Universit?? Laval, Qu??bec 
  Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca



From gunter.berton at gene.com  Tue Oct 11 18:09:30 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Tue, 11 Oct 2005 09:09:30 -0700
Subject: [R] Q: Suggestions for long-term data/program storage policy?
In-Reply-To: <Pine.LNX.4.61.0510111115020.15465@gannet.stats>
Message-ID: <200510111609.j9BG9W2n008922@ohm.gene.com>

A general comment. 

As usual, Brian is right on target. Indeed, this has been written,
conferenced, agonized, kvetched,  etc. about extensively in the computer
science community (and no doubt, among many others ... like accountants). I
seem to remember reading a Scientific American Magazine article (or was it
Science) about 10-15 years ago. As Brian says, it's not only application
versions, applications, OS's -- but even hardware that goes obsolete. Do you
have any data on 5 1/4" floppies from appications written for CP/M running
on an Intel 8080? Think of poor banks, drug companies -- or the census
bureau -- who have to keep their data forever. I sometimes wonder if all
these bits and bytes will fill up all the earth's storage eventually? :-)

Anyway, you might try researching this in the CS literature to see what the
strategy du jour is for this.

Cheers,

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Prof 
> Brian Ripley
> Sent: Tuesday, October 11, 2005 4:05 AM
> To: Alexander Ploner
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Q: Suggestions for long-term data/program 
> storage policy?
> 
> On Tue, 11 Oct 2005, Alexander Ploner wrote:
> 
> > we are a statistical/epidemiological departement that - after a few
> > years of rapid growth - finally is getting around to formulate a
> > general data storage and retention policy - mainly to ensure that we
> > can reproduce results from published papers/theses easier in the
> > future, but also with the hope that we get more synergy between
> > related projects.
> >
> > We have formulated what we feel is a reasonable draft, requiring
> > basically that the raw data, all programs to create derived data
> > sets, and the analysis programs are stored and documented in a
> > uniform manner, regardless of the analysis software used. 
> The minimum
> > data retention we are aiming for is 10 years, and the format for the
> > raw data is quite sane (either flat ASCII or real
> 
> You are intending to retain copies of the OS used and hardware too?
> The results depend far more on those than you apparently realize.
> 
> > Given the rapid devlopment cycle of R,
> 
> I think you will find your OS changes as fast: all those 
> security updates 
> potentially affect your results.
> 
> > this suggests that at the very least all non-base packages 
> used in the 
> > analysis are stored together with each project. I have 
> basically two 
> > questions:
> >
> > 1) Are old R versions (binaries/sources) going to be available on
> > CRAN indefinitely?
> 
> Not binaries.  The intention is that source files be 
> available, but they 
> could become corrupted (as it seems the Windows binary has for a past 
> version).
> 
> > 2) Is .RData a reasonable file format for long term storage?
> 
> I would say not, as it is almost impossible to recover from 
> any corruption 
> in such a file.  We like to have long-term data in a human-readable 
> printout, with a print copy, and also store some checksums.
> 
> > I would also be very grateful for any other suggestions, comments or
> > links for setting up and implementing such a storage policy (R-
> > specific or otherwise).
> 
> You need to consider the medium on which you are going to store the 
> archive.  We currrently use CD-R (and not tapes as those are less 
> compatible across drives -- we have two identical drives 
> currently but do 
> not expect either to last 10 years), and check them annually 
> -- I guess we 
> will re-write to another medium after much less than 10 years.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From jsorkin at grecc.umaryland.edu  Tue Oct 11 18:11:57 2005
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Tue, 11 Oct 2005 12:11:57 -0400
Subject: [R] Two factor (or more) non-parametric comparison of means
Message-ID: <s34bac35.047@medicine.umaryland.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051011/defe12bf/attachment.pl

From mth_man at yahoo.com  Tue Oct 11 18:21:39 2005
From: mth_man at yahoo.com (Daniel Pick)
Date: Tue, 11 Oct 2005 09:21:39 -0700 (PDT)
Subject: [R] Logistic Regression using glm
Message-ID: <20051011162139.52546.qmail@web50201.mail.yahoo.com>

Hello everyone,
   I am currently teaching an intermediate stats.
course at UCSD Extension using R.  We are using
Venables and Ripley as the primary text for the
course, with Freund & Wilson's Statistical Methods as
a secondary reference.
   I recently gave a homework assignment on logistic
regression, and I had a question about glm.  Let n be
the number of trials, p be the estimated sample
proportion, and w be the standard binomial weights
n*p*(1-p).  If you perform
output <- glm(p ~ x, family = binomial, weights = n)
you get a different result than if you perform the
logit transformation manually on p and perform
output <- lm(logit(p) ~ x, weights = w),
where logit(p) is either obtained from R with
qlogis(p) or from a manual computation of ln(p/1-p).

The difference seems to me to be too large to be
roundoff error.  The only thing I can guess is that
the application of the weights in glm is different
than in a manual computation.  Can anyone explain the
difference in results?  


Daniel Pick 
Principal 
Daniel Pick Scientific Software Consulting 
San Diego, CA 
E-Mail: mth_man at yahoo.com



From jsandblom at gmail.com  Tue Oct 11 18:22:05 2005
From: jsandblom at gmail.com (Johan Sandblom)
Date: Tue, 11 Oct 2005 18:22:05 +0200
Subject: [R] Two factor (or more) non-parametric comparison of means
In-Reply-To: <s34bac35.047@medicine.umaryland.edu>
References: <s34bac35.047@medicine.umaryland.edu>
Message-ID: <97a06f070510110922r607458een@mail.gmail.com>

?kruskal.test

2005/10/11, John Sorkin <jsorkin at grecc.umaryland.edu>:
> Can anyone suggest a good non-parametric test, and an R implementation of the test,  that allows for two or more factors? Wilcoxon signed rank allows for only one.
> Thanks,
> John
>
> John Sorkin M.D., Ph.D.
> Chief, Biostatistics and Informatics
> Baltimore VA Medical Center GRECC and
> University of Maryland School of Medicine Claude Pepper OAIC
>
> University of Maryland School of Medicine
> Division of Gerontology
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
>
> 410-605-7119
> -- NOTE NEW EMAIL ADDRESS:
> jsorkin at grecc.umaryland.edu
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>


--
Johan Sandblom  N8, MRC, Karolinska sjh
t +46851776108  17176 Stockholm
m +46735521477  Sweden
"What is wanted is not the will to believe, but the
will to find out, which is the exact opposite"
- Bertrand Russell



From mschwartz at mn.rr.com  Tue Oct 11 18:45:07 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Tue, 11 Oct 2005 11:45:07 -0500
Subject: [R] Two factor (or more) non-parametric comparison of means
In-Reply-To: <97a06f070510110922r607458een@mail.gmail.com>
References: <s34bac35.047@medicine.umaryland.edu>
	<97a06f070510110922r607458een@mail.gmail.com>
Message-ID: <1129049107.4233.55.camel@localhost.localdomain>

I suspect that John may be looking for ?friedman.test, which I believe
will allow for a two-way non-parametric test.

kruskal.test() will perform a non-parametric test on two or more samples
(or factor levels) as a generalization of wilcox.test() for one or two
samples (or factor levels).

HTH,

Marc Schwartz

On Tue, 2005-10-11 at 18:22 +0200, Johan Sandblom wrote:
> ?kruskal.test
> 
> 2005/10/11, John Sorkin <jsorkin at grecc.umaryland.edu>:
> > Can anyone suggest a good non-parametric test, and an R
> implementation of the test,  that allows for two or more factors?
> Wilcoxon signed rank allows for only one.
> > Thanks,
> > John



From mschwartz at mn.rr.com  Tue Oct 11 18:59:07 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Tue, 11 Oct 2005 11:59:07 -0500
Subject: [R] Hmisc latex function
In-Reply-To: <1129039280.3048.7.camel@localhost.localdomain>
References: <1129039280.3048.7.camel@localhost.localdomain>
Message-ID: <1129049947.4233.66.camel@localhost.localdomain>

On Tue, 2005-10-11 at 10:01 -0400, Rick Bilonick wrote:
> I'm using R 2.2.0 on an up-to-date version of Fedora Core 4 with the
> latest version of Hmisc. When I run an example from the latex function I
> get the following:
> 
> > x <- matrix(1:6, nrow=2, dimnames=list(c('a','b'),c('c','d','enLine
> 2')))
> > x
>   c d enLine 2
> a 1 3        5
> b 2 4        6
> > latex(x)   # creates x.tex in working directory
> sh: line 0: cd: â€œ/tmp/Rtmpl10983â€: No such file or directory
> This is pdfeTeX, Version 3.141592-1.21a-2.2 (Web2C 7.5.4)
> entering extended mode
> ! I can't find file `â€œ/tmp/Rtmpl10983/file643c9869â€'.
> <*> â€œ/tmp/Rtmpl10983/file643c9869â€
> 
> Please type another input file name: q
> (/usr/share/texmf/tex/latex/tools/q.tex
> LaTeX2e <2003/12/01>
> Babel <v3.8d> and hyphenation patterns for american, french, german,
> ngerman, b
> ahasa, basque, bulgarian, catalan, croatian, czech, danish, dutch,
> esperanto, e
> stonian, finnish, greek, icelandic, irish, italian, latin, magyar,
> norsk, polis
> h, portuges, romanian, russian, serbian, slovak, slovene, spanish,
> swedish, tur
> kish, ukrainian, nohyphenation, loaded.
> File ignored
> xdvi-motif.bin: Fatal error: /tmp/Rtmpl10983/file643c9869.dvi: No such
> file.
> 
> 
> How can I fix this?
> 
> Rick B.

I get the same results, also on FC4 with R 2.2.0.

I am cc:ing Frank here for his input, but a quick review of the code and
created files suggests that there may be conflict between the locations
of some of the resultant files during the latex system call. Some files
appear in a temporary R directory, while others appear in the current R
working directory.

For example, if I enter the full filename:
 
  /tmp/RtmpC12100/file643c9869.tex

at the latex prompt, I get:

> latex(x)
sh: line 0: cd: â€œ/tmp/RtmpC12100â€: No such file or directory
This is pdfeTeX, Version 3.141592-1.21a-2.2 (Web2C 7.5.4)
entering extended mode
! I can't find file `â€œ/tmp/RtmpC12100/file643c9869â€'.
<*> â€œ/tmp/RtmpC12100/file643c9869â€

Please type another input file name: *** loading the extensions
datasource
/tmp/RtmpC12100/file643c9869.tex
(/tmp/RtmpC12100/file643c9869.tex
LaTeX2e <2003/12/01>
Babel <v3.8d> and hyphenation patterns for american, french, german,
ngerman, b
ahasa, basque, bulgarian, catalan, croatian, czech, danish, dutch,
esperanto, e
stonian, finnish, greek, icelandic, irish, italian, latin, magyar,
norsk, polis
h, portuges, romanian, russian, serbian, slovak, slovene, spanish,
swedish, tur
kish, ukrainian, nohyphenation, loaded.
(/usr/share/texmf/tex/latex/base/report.cls
Document Class: report 2004/02/16 v1.4f Standard LaTeX document class
(/usr/share/texmf/tex/latex/base/size10.clo))
(/usr/share/texmf/tex/latex/geometry/geometry.sty
(/usr/share/texmf/tex/latex/graphics/keyval.sty)
(/usr/share/texmf/tex/latex/geometry/geometry.cfg))
No file file643c9869.aux.
[1] (./file643c9869.aux) )
Output written on file643c9869.dvi (1 page, 368 bytes).
Transcript written on file643c9869.log.
xdvi-motif.bin: Fatal error: /tmp/RtmpC12100/file643c9869.dvi: No such
file.


The temporary .tex file is present, but the .dvi, .aux and .log files
are created in the current working R directory.

HTH,

Marc Schwartz



From lassana.koita at aviation-civile.gouv.fr  Tue Oct 11 18:54:18 2005
From: lassana.koita at aviation-civile.gouv.fr (KOITA Lassana - STAC/ACE)
Date: Tue, 11 Oct 2005 18:54:18 +0200
Subject: [R] Problems with plot function
Message-ID: <OF63F80873.69B89EC4-ONC1257097.005C401A@aviation-civile.gouv.fr>





Hello  all  R   users,
My simulation function works correctly, but I have problems with plot
function. You will find the following code using it.
Thank you for your help
##################################################"

simulation <- function(k, n){

conc <- seq(0,10,by=0.5)
#choixg <- seq(1, length(conc))
choixg <- rep(0,length(conc))
for (i in 1:length(conc)){
    choixg[i] <- (k + conc[i])^2/((k+conc[i])^n + (k+1)^n)

    }
   return(choixg)

}
simulation(5,1)

plot(conc, choixg, main ="fonction de choix", col= "blue", pch=20,
xlab = " concentration", ylab="proba de choisir la gauche")
##########################################################

Lassana KOITA
Service Technique de l'Aviation Civile (STAC)
Direction G??n??rale de l'Aviation Civile (DGAC)
Tel: 01 49 56 80 60
Fax: 01 49 56 82 14
http://www.stac.aviation-civile.gouv.fr



From Iyue.Sung at lm.mmc.com  Tue Oct 11 19:06:21 2005
From: Iyue.Sung at lm.mmc.com (Sung, Iyue)
Date: Tue, 11 Oct 2005 13:06:21 -0400
Subject: [R] Logistic Regression using glm
Message-ID: <B01A505EA0E3124998DF4661D313B20601116027@mmci-bos03fs01.mmci.ad.root>

You're fitting two different models.

The latter is saying: logit(p)=x+e, where e is a normal error, so that
logit(p) is normal.
"lm" fits a Linear Model, which uses normal error.

The former says that p is Bernoulli; and p~Bernoulli does not imply
logit(p) is normal.
A Generalized Linear Model has different options for specifying the
random component.

Agresti's "Categorical Data Analysis" lays out the details very well.

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Daniel Pick
> Sent: Tuesday, October 11, 2005 12:22 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Logistic Regression using glm
> 
> Hello everyone,
>    I am currently teaching an intermediate stats.
> course at UCSD Extension using R.  We are using Venables and 
> Ripley as the primary text for the course, with Freund & 
> Wilson's Statistical Methods as a secondary reference.
>    I recently gave a homework assignment on logistic 
> regression, and I had a question about glm.  Let n be the 
> number of trials, p be the estimated sample proportion, and w 
> be the standard binomial weights n*p*(1-p).  If you perform 
> output <- glm(p ~ x, family = binomial, weights = n) you get 
> a different result than if you perform the logit 
> transformation manually on p and perform output <- 
> lm(logit(p) ~ x, weights = w), where logit(p) is either 
> obtained from R with
> qlogis(p) or from a manual computation of ln(p/1-p).
> 
> The difference seems to me to be too large to be roundoff 
> error.  The only thing I can guess is that the application of 
> the weights in glm is different than in a manual computation. 
>  Can anyone explain the difference in results?  
> 
> 
> Daniel Pick
> Principal
> Daniel Pick Scientific Software Consulting San Diego, CA
> E-Mail: mth_man at yahoo.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> --------------------------------------------------------------
> --------------
> This e-mail and any attachments may be confidential or\ > ...{{dropped}}



From tlumley at u.washington.edu  Tue Oct 11 19:13:13 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 11 Oct 2005 10:13:13 -0700 (PDT)
Subject: [R] Logistic Regression using glm
In-Reply-To: <20051011162139.52546.qmail@web50201.mail.yahoo.com>
References: <20051011162139.52546.qmail@web50201.mail.yahoo.com>
Message-ID: <Pine.LNX.4.63a.0510111012340.31500@homer24.u.washington.edu>


One of these is modelling the mean of the logit of p, the other is 
modelling the logit of the mean of p.  They aren't the same.

 	-thomas

On Tue, 11 Oct 2005, Daniel Pick wrote:

> Hello everyone,
>   I am currently teaching an intermediate stats.
> course at UCSD Extension using R.  We are using
> Venables and Ripley as the primary text for the
> course, with Freund & Wilson's Statistical Methods as
> a secondary reference.
>   I recently gave a homework assignment on logistic
> regression, and I had a question about glm.  Let n be
> the number of trials, p be the estimated sample
> proportion, and w be the standard binomial weights
> n*p*(1-p).  If you perform
> output <- glm(p ~ x, family = binomial, weights = n)
> you get a different result than if you perform the
> logit transformation manually on p and perform
> output <- lm(logit(p) ~ x, weights = w),
> where logit(p) is either obtained from R with
> qlogis(p) or from a manual computation of ln(p/1-p).
>
> The difference seems to me to be too large to be
> roundoff error.  The only thing I can guess is that
> the application of the weights in glm is different
> than in a manual computation.  Can anyone explain the
> difference in results?
>
>
> Daniel Pick
> Principal
> Daniel Pick Scientific Software Consulting
> San Diego, CA
> E-Mail: mth_man at yahoo.com
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From jerk_alert at hotmail.com  Tue Oct 11 19:29:01 2005
From: jerk_alert at hotmail.com (Ken Termiso)
Date: Tue, 11 Oct 2005 17:29:01 +0000
Subject: [R] Any way to add to data frame saved as .rData file?
Message-ID: <BAY101-F27EB3FBDE44DCDA6A04D7AE8780@phx.gbl>

Hi all,

I've got a script that generates a few moderate-size data frames, and then 
puts them together into one big data frame at the end in order to write that 
data frame to disk, so that it may be re-opened later on...

I'm trying to trim down memory requirements in this script, so I was 
wondering if there was any way to append to a data frame already saved on 
disk (just like appending to a text file)..all the data frames here have 
identical row names; what I want to do is to tack on additional columns to a 
data frame stored in the working directory...

Alternatively, is there another data structure that would allow me to do 
this (and could preferably be converted to a data frame) ?

Thanks in advance,
Ken



From jason at 109valentine.com  Tue Oct 11 19:42:37 2005
From: jason at 109valentine.com (Jason Horn)
Date: Tue, 11 Oct 2005 13:42:37 -0400
Subject: [R] non-zero sequence of numbers
Message-ID: <F90C5E92-5A4F-4533-B5B4-E33A5D92B728@109valentine.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051011/ca861210/attachment.pl

From p.dalgaard at biostat.ku.dk  Tue Oct 11 19:46:52 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 11 Oct 2005 19:46:52 +0200
Subject: [R] Two factor (or more) non-parametric comparison of means
In-Reply-To: <1129049107.4233.55.camel@localhost.localdomain>
References: <s34bac35.047@medicine.umaryland.edu>
	<97a06f070510110922r607458een@mail.gmail.com>
	<1129049107.4233.55.camel@localhost.localdomain>
Message-ID: <x264s42bg3.fsf@turmalin.kubism.ku.dk>

"Marc Schwartz (via MN)" <mschwartz at mn.rr.com> writes:

> I suspect that John may be looking for ?friedman.test, which I believe
> will allow for a two-way non-parametric test.

You could be right, but you could also be wrong... It depends quite a
bit on what is meant by a "two-factor  comparison of means". If he
literally means means (!), then a permutation test (permuting within
levels of the other factor) could be appropriate. It also makes a
difference whether there's a single replication or more per cell in
the cross-classification.

> kruskal.test() will perform a non-parametric test on two or more samples
> (or factor levels) as a generalization of wilcox.test() for one or two
> samples (or factor levels).
> 
> HTH,
> 
> Marc Schwartz
> 
> On Tue, 2005-10-11 at 18:22 +0200, Johan Sandblom wrote:
> > ?kruskal.test
> > 
> > 2005/10/11, John Sorkin <jsorkin at grecc.umaryland.edu>:
> > > Can anyone suggest a good non-parametric test, and an R
> > implementation of the test,  that allows for two or more factors?
> > Wilcoxon signed rank allows for only one.
> > > Thanks,
> > > John
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From mschwartz at mn.rr.com  Tue Oct 11 19:54:12 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Tue, 11 Oct 2005 12:54:12 -0500
Subject: [R] Two factor (or more) non-parametric comparison of means
In-Reply-To: <x264s42bg3.fsf@turmalin.kubism.ku.dk>
References: <s34bac35.047@medicine.umaryland.edu>
	<97a06f070510110922r607458een@mail.gmail.com>
	<1129049107.4233.55.camel@localhost.localdomain>
	<x264s42bg3.fsf@turmalin.kubism.ku.dk>
Message-ID: <1129053252.4233.75.camel@localhost.localdomain>

Peter,

Good points all around.

Hopefully John will provide further clarification.

Best regards,

Marc

On Tue, 2005-10-11 at 19:46 +0200, Peter Dalgaard wrote:
> "Marc Schwartz (via MN)" <mschwartz at mn.rr.com> writes:
> 
> > I suspect that John may be looking for ?friedman.test, which I believe
> > will allow for a two-way non-parametric test.
> 
> You could be right, but you could also be wrong... It depends quite a
> bit on what is meant by a "two-factor  comparison of means". If he
> literally means means (!), then a permutation test (permuting within
> levels of the other factor) could be appropriate. It also makes a
> difference whether there's a single replication or more per cell in
> the cross-classification.
> 
> > kruskal.test() will perform a non-parametric test on two or more samples
> > (or factor levels) as a generalization of wilcox.test() for one or two
> > samples (or factor levels).
> > 
> > HTH,
> > 
> > Marc Schwartz
> > 
> > On Tue, 2005-10-11 at 18:22 +0200, Johan Sandblom wrote:
> > > ?kruskal.test
> > > 
> > > 2005/10/11, John Sorkin <jsorkin at grecc.umaryland.edu>:
> > > > Can anyone suggest a good non-parametric test, and an R
> > > implementation of the test,  that allows for two or more factors?
> > > Wilcoxon signed rank allows for only one.
> > > > Thanks,
> > > > John
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > 
>



From p.dalgaard at biostat.ku.dk  Tue Oct 11 19:54:35 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 11 Oct 2005 19:54:35 +0200
Subject: [R] non-zero sequence of numbers
In-Reply-To: <F90C5E92-5A4F-4533-B5B4-E33A5D92B728@109valentine.com>
References: <F90C5E92-5A4F-4533-B5B4-E33A5D92B728@109valentine.com>
Message-ID: <x21x2s2b38.fsf@turmalin.kubism.ku.dk>

Jason Horn <jason at 109valentine.com> writes:

> Can anyone think of a way to create a pretty() sequence that excludes  
> zero?  Or a way to remove the zero from a sequence after using pretty()?

The former is rather hard because zero is generally considered just
about the prettiest number around...

As for the latter, something like s <- pretty(x); s <- s[s!=0]
or maybe s[zapsmall(s) != 0].

 
> Thanks,
> 
> - Jason
> 
> 
> Jason Horn
> Boston University Department of Biology
> 5 Cumington Street  Boston, MA 02215
> 
> jhorn at bu.edu
> office: 617 353 6987
> cell: 401 588 2766
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From jan.sabee at gmail.com  Tue Oct 11 20:22:01 2005
From: jan.sabee at gmail.com (Jan Sabee)
Date: Tue, 11 Oct 2005 20:22:01 +0200
Subject: [R] Need help write a function
Message-ID: <96507a8e0510111122wf3c1022jf25a8da08c76643a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051011/7a6c6444/attachment.pl

From michel.friesenhahn.b at bayer.com  Tue Oct 11 20:22:53 2005
From: michel.friesenhahn.b at bayer.com (Michel Friesenhahn)
Date: Tue, 11 Oct 2005 11:22:53 -0700
Subject: [R] Reading # in file with read.csv
Message-ID: <OFBACE163D.50D4BAEF-ON88257097.006437C3-88257097.0064F8FC@bayer.com>


I'm using read.csv to read in a csv file containing '#' characters.  For
example, say I'm reading the following file (test.csv):

var1,var2,var3
a,b,c
d,e#,f
g,h,i

It outputs:

> read.csv("Raw Data\\test.csv")
  var1 var2 var3
1    a    b    c
2    d    e
3    g    h    i
Warning message:
incomplete final line found by readTableHeader on 'Raw Data\test.csv'

read.csv appears to be treating '#' as a comment even in input data.  Is there a
way to turn this interpretation off?

Thanks,

Mike



From Scott.Waichler at pnl.gov  Tue Oct 11 20:23:36 2005
From: Scott.Waichler at pnl.gov (Waichler, Scott R)
Date: Tue, 11 Oct 2005 11:23:36 -0700
Subject: [R] How to get aspect ratio as output from from plot()
Message-ID: <7E4C06F49D6FEB49BE4B60E5FC92ED7A02D069F3@pnlmse35.pnl.gov>


Is there a way to get the aspect ratio as output from a plot() call or
something similar in the base graphics system?  I would like to note
vertical exaggeration on an elevation profile.

Thanks,
Scott Waichler
Pacific Northwest National Laboratory
scott.waichler at pnl.gov



From helprhelp at gmail.com  Tue Oct 11 20:27:33 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Tue, 11 Oct 2005 13:27:33 -0500
Subject: [R] a problem in random forest
Message-ID: <cdf817830510111127l477f3c19j70853b3c41ac54f5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051011/11934ae2/attachment.pl

From sundar.dorai-raj at pdf.com  Tue Oct 11 20:31:10 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 11 Oct 2005 13:31:10 -0500
Subject: [R] Reading # in file with read.csv
In-Reply-To: <OFBACE163D.50D4BAEF-ON88257097.006437C3-88257097.0064F8FC@bayer.com>
References: <OFBACE163D.50D4BAEF-ON88257097.006437C3-88257097.0064F8FC@bayer.com>
Message-ID: <434C04EE.9010702@pdf.com>



Michel Friesenhahn wrote:
> I'm using read.csv to read in a csv file containing '#' characters.  For
> example, say I'm reading the following file (test.csv):
> 
> var1,var2,var3
> a,b,c
> d,e#,f
> g,h,i
> 
> It outputs:
> 
> 
>>read.csv("Raw Data\\test.csv")
> 
>   var1 var2 var3
> 1    a    b    c
> 2    d    e
> 3    g    h    i
> Warning message:
> incomplete final line found by readTableHeader on 'Raw Data\test.csv'
> 
> read.csv appears to be treating '#' as a comment even in input data.  Is there a
> way to turn this interpretation off?
> 


 From ?read.csv:

comment.char: character: a character vector of length one containing a
           single character or an empty string.  Use '""' to turn off
           the interpretation of comments altogether.

Thus, you should use:

read.csv("Raw Data\\test.csv", comment.char = "")

--sundar



From helprhelp at gmail.com  Tue Oct 11 20:32:50 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Tue, 11 Oct 2005 13:32:50 -0500
Subject: [R] a problem in random forest
In-Reply-To: <cdf817830510111127l477f3c19j70853b3c41ac54f5@mail.gmail.com>
References: <cdf817830510111127l477f3c19j70853b3c41ac54f5@mail.gmail.com>
Message-ID: <cdf817830510111132w45edb9fbpbc69b22a606afdeb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051011/8277a6f5/attachment.pl

From sundar.dorai-raj at pdf.com  Tue Oct 11 20:35:08 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 11 Oct 2005 13:35:08 -0500
Subject: [R] Need help write a function
In-Reply-To: <96507a8e0510111122wf3c1022jf25a8da08c76643a@mail.gmail.com>
References: <96507a8e0510111122wf3c1022jf25a8da08c76643a@mail.gmail.com>
Message-ID: <434C05DC.50406@pdf.com>



Jan Sabee wrote:
> Dear all,
> I am still learning R with write a small function for my self.
> I was wondering if someone can help me to write a R function formula below:
> Z_k (x) = \sum_{i=0}^{i=k} \binom{n}{i} (m-1)^i
> Thanks a million in advance,
> 
> Sincerely,
> Jan Sabee
> 

(This smells like a homework problem.)

What is "m"? Your Z_k is a function of "x" and there is no "x" on the RHS.

Are you trying to re-write "pbinom"?

--sundar



From michel.friesenhahn.b at bayer.com  Tue Oct 11 20:40:43 2005
From: michel.friesenhahn.b at bayer.com (Michel Friesenhahn)
Date: Tue, 11 Oct 2005 11:40:43 -0700
Subject: [R] Reading # in file with read.csv
Message-ID: <OF2E5F1F9C.8583F88D-ON88257097.00667255-88257097.00669AFC@bayer.com>


Never mind on my previous question below.  read.csv("Raw
Data\\test.csv",comment.char="") does it.

Mike


I'm using read.csv to read in a csv file containing '#' characters.  For
example, say I'm reading the following file (test.csv):

var1,var2,var3
a,b,c
d,e#,f
g,h,i

It outputs:

> read.csv("Raw Data\\test.csv")
  var1 var2 var3
1    a    b    c
2    d    e
3    g    h    i
Warning message:
incomplete final line found by readTableHeader on 'Raw Data\test.csv'

read.csv appears to be treating '#' as a comment even in input data.  Is there a
way to turn this interpretation off?

Thanks,

Mike



From sundar.dorai-raj at pdf.com  Tue Oct 11 20:44:01 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 11 Oct 2005 13:44:01 -0500
Subject: [R] How to get aspect ratio as output from from plot()
In-Reply-To: <7E4C06F49D6FEB49BE4B60E5FC92ED7A02D069F3@pnlmse35.pnl.gov>
References: <7E4C06F49D6FEB49BE4B60E5FC92ED7A02D069F3@pnlmse35.pnl.gov>
Message-ID: <434C07F1.9080607@pdf.com>



Waichler, Scott R wrote:
> Is there a way to get the aspect ratio as output from a plot() call or
> something similar in the base graphics system?  I would like to note
> vertical exaggeration on an elevation profile.
> 
> Thanks,
> Scott Waichler
> Pacific Northwest National Laboratory
> scott.waichler at pnl.gov
> 

Hi, Scott,

Perhaps this will work for you?

plot(1:10)
w <- par("pin")[1]/diff(par("usr")[1:2])
h <- par("pin")[2]/diff(par("usr")[3:4])
asp <- w/h

HTH,

--sundar



From greg.snow at ihc.com  Tue Oct 11 20:46:30 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Tue, 11 Oct 2005 12:46:30 -0600
Subject: [R] permutational Kolmogorov-Smirnov p-value for paired data
Message-ID: <s34bb45b.052@lp-msg1.co.ihc.com>

Here is one way to do a paired permutation test:

perm1 <- function(x,y){
	rb <- rbinom(length(x),1,0.5)
	xp <- ifelse(rb==1, x, y)
	yp <- ifelse(rb==1, y, x)
	ks.test(xp,yp)$statistic
}

my.x <- rnorm(100)
my.y <- my.x + rnorm(100, 0.2, 0.1)

mystat <- ks.test(my.x,my.y)$statistic

out <- replicate(1000, perm1(my.x,my.y) )
hist(out)
abline(v=mystat)
mean(out > mystat)


hope this helps,

Greg Snow, Ph.D.
Statistical Data Center, LDS Hospital
Intermountain Health Care
greg.snow at ihc.com
(801) 408-8111

>>> John Chen <jwcasl at gmail.com> 10/07/05 06:05AM >>>
Dear List,

I am new to R and find it very powerful. I would like to compute the
permutational p-value for paired data using Kolmogorov-Smirnov, but
the built-in ks.test does not have this option, unlike the t.test
which has a paired=TRUE flag. Has someone written a library or a
routine that does this? Alternatively, if someone could show me how to
do pair-wise permutations in R, then I can compute the ks statistic
for each permutation, that'll work too. Thank you!

John

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Tue Oct 11 21:25:00 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 11 Oct 2005 21:25:00 +0200
Subject: [R] Reading # in file with read.csv
In-Reply-To: <OFBACE163D.50D4BAEF-ON88257097.006437C3-88257097.0064F8FC@bayer.com>
References: <OFBACE163D.50D4BAEF-ON88257097.006437C3-88257097.0064F8FC@bayer.com>
Message-ID: <x2wtkj26wj.fsf@turmalin.kubism.ku.dk>

Michel Friesenhahn <michel.friesenhahn.b at bayer.com> writes:

> I'm using read.csv to read in a csv file containing '#' characters.  For
> example, say I'm reading the following file (test.csv):
> 
> var1,var2,var3
> a,b,c
> d,e#,f
> g,h,i
> 
> It outputs:
> 
> > read.csv("Raw Data\\test.csv")
>   var1 var2 var3
> 1    a    b    c
> 2    d    e
> 3    g    h    i
> Warning message:
> incomplete final line found by readTableHeader on 'Raw Data\test.csv'
> 
> read.csv appears to be treating '#' as a comment even in input data.  Is there a
> way to turn this interpretation off?

comment.char=""

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From Scott.Waichler at pnl.gov  Tue Oct 11 21:41:37 2005
From: Scott.Waichler at pnl.gov (Waichler, Scott R)
Date: Tue, 11 Oct 2005 12:41:37 -0700
Subject: [R] How to get aspect ratio as output from from plot()
Message-ID: <7E4C06F49D6FEB49BE4B60E5FC92ED7A02D06AA3@pnlmse35.pnl.gov>


Sundar,

> Perhaps this will work for you?
> 
> plot(1:10)
> w <- par("pin")[1]/diff(par("usr")[1:2])
> h <- par("pin")[2]/diff(par("usr")[3:4])
> asp <- w/h

Thank you for your help.  For vertical exaggeration I will make a slight
change to make it more intuitive (for me):

w <- diff(par("usr")[1:2]) / par("pin")[1]  # plot units per inch
horizontal axis
h <- diff(par("usr")[3:4]) / par("pin")[2]  # plot units per inch
vertical axis
vertical.exaggeration <- w/h

Scott Waichler



From tlenaert at ulb.ac.be  Tue Oct 11 22:15:11 2005
From: tlenaert at ulb.ac.be (Tom Lenaerts)
Date: Tue, 11 Oct 2005 22:15:11 +0200
Subject: [R] problems with levelplot and contourplot
Message-ID: <8083cdb6868eaf3a92a46bea613e066d@ulb.ac.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051011/5a4d0180/attachment.pl

From sundar.dorai-raj at pdf.com  Tue Oct 11 22:26:19 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 11 Oct 2005 15:26:19 -0500
Subject: [R] problems with levelplot and contourplot
In-Reply-To: <8083cdb6868eaf3a92a46bea613e066d@ulb.ac.be>
References: <8083cdb6868eaf3a92a46bea613e066d@ulb.ac.be>
Message-ID: <434C1FEB.4080807@pdf.com>



Tom Lenaerts wrote:
> Hello,
> 
> 
> Using the following code i want to make a level or contourplot of some  
> data that I produced
> 
> library(grid);library(lattice);

No need to explicitly load "grid". This is done when attaching 
"lattice". Also, you do not need any ";" at the end of any lines.

> mydata <- read.table("avgee.dat");
> mymat <- as.matrix(mydata);
> mymat <-t(mymat)
> vals<-as.vector(mymat);
> conc<-c(0.0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5);
> a<- c(0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1, 2.5,5.0,  
> 7.5,10, 25, 50, 75, 100);
> grid<-expand.grid(x=conc, y=a);
> levelplot(vals ~ conc * a, grid, region=TRUE, cuts=20);

Don't you mean

levelplot(vals ~ x * y, grid, region=TRUE, cuts=20)

Your data.frame "grid" has columns "x" and "y", not "conc" and "a".

> 
> When I do this get a blank output window and the following warnings
> 
> Warning messages:
> 1: longer object length
> 	is not a multiple of shorter object length in: is.na(x) | is.na(y)
> 2: longer object length
> 	is not a multiple of shorter object length in: id.na | is.na(var)
> 3: longer object length
> 	is not a multiple of shorter object length in: id & if  
> (is.shingle(var)) ((var >= levels(var)[[cond.current.level[i]]][1]) &
>  >
> 
> I've examined this mailinglist and the web and tried the examples other  
> people suggested.  They seem to work.
> Yet, my code seems the same as
> 
> a <-1:10
>   b <-11:20
>   j <- rnorm(100)
>   grid<-expand.grid(a = a, b = b)
>   levelplot(j~a*b, grid)
> 
> (from a previous mail)
> 
> 
> and it does not work.
> 
> Can anybody tell me what I'm doing wrong?  Furthermore as you ight  
> notice the data in a is in log-scale so I want the y-axis of the plot  
> in logscale.
> 

To print y in log-scale, add the following:

levelplot(..., scale = list(y = list(log = TRUE)))

HTH,

--sundar



From helprhelp at gmail.com  Tue Oct 11 22:29:07 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Tue, 11 Oct 2005 15:29:07 -0500
Subject: [R] an error in my using of nnet
Message-ID: <cdf817830510111329h37170664vf2f563f2b1b1df98@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051011/f0a7b499/attachment.pl

From tlenaert at ulb.ac.be  Tue Oct 11 22:35:11 2005
From: tlenaert at ulb.ac.be (Tom Lenaerts)
Date: Tue, 11 Oct 2005 22:35:11 +0200
Subject: [R] problems with levelplot and contourplot
In-Reply-To: <434C1FEB.4080807@pdf.com>
References: <8083cdb6868eaf3a92a46bea613e066d@ulb.ac.be>
	<434C1FEB.4080807@pdf.com>
Message-ID: <533d53cba9e0e7df69b2493a2e5643a3@ulb.ac.be>

Dear Sundar

Thanks a lot, this resolves the problem of the warning messages.

Yet it does not produce the plot: I only get a blank Quartz panel (i'm 
using R on Mac OS X 1.3).  I attached the file and the corrected code.

Maybe it is a problem of the data?

library(lattice);
mydata <- read.table("avgee.dat");
mymat <- as.matrix(mydata);
mymat <-t(mymat)
vals<-as.vector(mymat);
conc<-c(0.0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5);
a<- c(0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1, 2.5,5.0, 
7.5,10, 25, 50, 75, 100);
grid<-expand.grid(x=conc, y=a);
levelplot(vals ~ x * y, grid, region=TRUE, cuts=20,scale = list(y = 
list(log = TRUE)));

-------------- next part --------------


Thanks in advance

Tom


------------------------------------------------------------------------ 
-------------------------
Tom Lenaerts (tlenaert at ulb.ac.be)                   
http://www.tomlenaerts.tk/
Postdoc Researcher @ IRIDIA-Universite Libre de Bruxelles-Belgium
Guest Professor @ DINF-Vrije Uiversiteit Brussel-Belgium
On 11 Oct 2005, at 22:26, Sundar Dorai-Raj wrote:

> scale = list(y = list(log = TRUE))

From murdoch at stats.uwo.ca  Tue Oct 11 22:38:31 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 11 Oct 2005 16:38:31 -0400
Subject: [R] Any way to add to data frame saved as .rData file?
In-Reply-To: <BAY101-F27EB3FBDE44DCDA6A04D7AE8780@phx.gbl>
References: <BAY101-F27EB3FBDE44DCDA6A04D7AE8780@phx.gbl>
Message-ID: <434C22C7.4010209@stats.uwo.ca>

Ken Termiso wrote:
> Hi all,
> 
> I've got a script that generates a few moderate-size data frames, and then 
> puts them together into one big data frame at the end in order to write that 
> data frame to disk, so that it may be re-opened later on...
> 
> I'm trying to trim down memory requirements in this script, so I was 
> wondering if there was any way to append to a data frame already saved on 
> disk (just like appending to a text file)..all the data frames here have 
> identical row names; what I want to do is to tack on additional columns to a 
> data frame stored in the working directory...

No, I don't think so.
> 
> Alternatively, is there another data structure that would allow me to do 
> this (and could preferably be converted to a data frame) ?

I'd put the extra columns in their own data frame, and save that to disk 
(use dates/times/process ids or some other unique identifier in the 
filenames to distinguish them).  When you need access to a mixture of 
columns, load (or source, depending how you did the save) the columns 
you need, and cbind them together into one big data frame.

If you are concerned about memory requirements when producing the 
pieces, watch out that you don't write out so much data that you'll 
never have enough memory to load all you need at once.

Duncan Murdoch



From murdoch at stats.uwo.ca  Tue Oct 11 22:42:39 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 11 Oct 2005 16:42:39 -0400
Subject: [R] Q: Suggestions for long-term data/program storage policy?
In-Reply-To: <200510111609.j9BG9W2n008922@ohm.gene.com>
References: <200510111609.j9BG9W2n008922@ohm.gene.com>
Message-ID: <434C23BF.501@stats.uwo.ca>

Berton Gunter wrote:
> A general comment. 
> 
> As usual, Brian is right on target. Indeed, this has been written,
> conferenced, agonized, kvetched,  etc. about extensively in the computer
> science community (and no doubt, among many others ... like accountants). I
> seem to remember reading a Scientific American Magazine article (or was it
> Science) about 10-15 years ago. As Brian says, it's not only application
> versions, applications, OS's -- but even hardware that goes obsolete. Do you
> have any data on 5 1/4" floppies from appications written for CP/M running
> on an Intel 8080? Think of poor banks, drug companies -- or the census
> bureau -- who have to keep their data forever. I sometimes wonder if all
> these bits and bytes will fill up all the earth's storage eventually? :-)
> 
> Anyway, you might try researching this in the CS literature to see what the
> strategy du jour is for this.

Now that journals are becoming electronic, librarians are also very 
concerned with this problem, and they tend to have very long term 
storage goals.

Duncan Murdoch
> 
> Cheers,
> 
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
>  
> "The business of the statistician is to catalyze the scientific learning
> process."  - George E. P. Box
>  
>  
> 
> 
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch 
>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Prof 
>>Brian Ripley
>>Sent: Tuesday, October 11, 2005 4:05 AM
>>To: Alexander Ploner
>>Cc: r-help at stat.math.ethz.ch
>>Subject: Re: [R] Q: Suggestions for long-term data/program 
>>storage policy?
>>
>>On Tue, 11 Oct 2005, Alexander Ploner wrote:
>>
>>
>>>we are a statistical/epidemiological departement that - after a few
>>>years of rapid growth - finally is getting around to formulate a
>>>general data storage and retention policy - mainly to ensure that we
>>>can reproduce results from published papers/theses easier in the
>>>future, but also with the hope that we get more synergy between
>>>related projects.
>>>
>>>We have formulated what we feel is a reasonable draft, requiring
>>>basically that the raw data, all programs to create derived data
>>>sets, and the analysis programs are stored and documented in a
>>>uniform manner, regardless of the analysis software used. 
>>
>>The minimum
>>
>>>data retention we are aiming for is 10 years, and the format for the
>>>raw data is quite sane (either flat ASCII or real
>>
>>You are intending to retain copies of the OS used and hardware too?
>>The results depend far more on those than you apparently realize.
>>
>>
>>>Given the rapid devlopment cycle of R,
>>
>>I think you will find your OS changes as fast: all those 
>>security updates 
>>potentially affect your results.
>>
>>
>>>this suggests that at the very least all non-base packages 
>>
>>used in the 
>>
>>>analysis are stored together with each project. I have 
>>
>>basically two 
>>
>>>questions:
>>>
>>>1) Are old R versions (binaries/sources) going to be available on
>>>CRAN indefinitely?
>>
>>Not binaries.  The intention is that source files be 
>>available, but they 
>>could become corrupted (as it seems the Windows binary has for a past 
>>version).
>>
>>
>>>2) Is .RData a reasonable file format for long term storage?
>>
>>I would say not, as it is almost impossible to recover from 
>>any corruption 
>>in such a file.  We like to have long-term data in a human-readable 
>>printout, with a print copy, and also store some checksums.
>>
>>
>>>I would also be very grateful for any other suggestions, comments or
>>>links for setting up and implementing such a storage policy (R-
>>>specific or otherwise).
>>
>>You need to consider the medium on which you are going to store the 
>>archive.  We currrently use CD-R (and not tapes as those are less 
>>compatible across drives -- we have two identical drives 
>>currently but do 
>>not expect either to last 10 years), and check them annually 
>>-- I guess we 
>>will re-write to another medium after much less than 10 years.
>>
>>-- 
>>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>University of Oxford,             Tel:  +44 1865 272861 (self)
>>1 South Parks Road,                     +44 1865 272866 (PA)
>>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From deepayan.sarkar at gmail.com  Tue Oct 11 22:42:31 2005
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 11 Oct 2005 15:42:31 -0500
Subject: [R] aligning column of xyplots and removing space between them
In-Reply-To: <971536df0510110043w2e4a47b5le0f43b03871e91a4@mail.gmail.com>
References: <971536df0510110043w2e4a47b5le0f43b03871e91a4@mail.gmail.com>
Message-ID: <eb555e660510111342i4b909fcaqdee1097346344a3f@mail.gmail.com>

On 10/11/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> The code below displays three graphs in three rows and one column but:
>
> 1. I want to remove the space between the graphs (I tried playing with position=
> arg to print.trellis but it seems quite difficult to get the right
> values and all
> my attempts had space between them or had overlapping graphs.  Is
> there a better way to do this?

Define

theme.novpadding <- list(layout.heights =
    list(top.padding = 0,
         main.key.padding = 0,
         key.axis.padding = 0,
         axis.xlab.padding = 0,
         xlab.key.padding = 0,
         key.sub.padding = 0,
         bottom.padding = 0))

and then add

par.settings = theme.novpadding

to all your xyplot calls.

> 2. the widths of the plots are not the same even though I specified the same
> xlim= to them all.  How do I make them the same?

They seem to be the same for me, but they might be different if the
y-axis labels are different. See the 'panel.width' argument in
?print.trellis.


> 3. how do I get rid of the ticks at the top of the bottom plot?

add

scales = list(x = list(relation = "free"))

> 4. the bottom graph is supposed to plot 1:3 against itself but the third
> point is not showing even though I specified ylim = c(0,3).  Must
> I specify ylim = c(0,3+1) or is there a better way?

There's no better way. This behaviour is intentionally different from
base graphics.

Here's a modified version of the last part of your code:

grid.newpage()

# n and nr are number of cells and rows
n <- nr <- 3
nc <- 1  # must be 1

heights <- unit(c(2, rep(1, nr-1)), "null")
downViewport(pushLayout(nr, nc, heights = heights))

vpt <- current.vpTree(all = FALSE)

### relevant part starts here
#########################

xlab <- main <- function(x) if (x) "v"
for(k in 1:n) with(vpt$children[[k]],
       print( xyplot(v ~ v, list(v = 1:k), xlab = xlab(k == n),
       xlim = c(0,n), ylim = c(0,n), main = main(k == 1),
       par.settings = theme.novpadding,
       scales = list(x = list(draw = k == n, relation = "free", c(1, 0)),
                         y = list(alternating = 3))),
       newpage = FALSE, panel.width = list(x = 4, units = "inches"))
)

-Deepayan



From tlenaert at ulb.ac.be  Tue Oct 11 22:53:38 2005
From: tlenaert at ulb.ac.be (Tom Lenaerts)
Date: Tue, 11 Oct 2005 22:53:38 +0200
Subject: [R] problems with levelplot and contourplot
In-Reply-To: <434C1FEB.4080807@pdf.com>
References: <8083cdb6868eaf3a92a46bea613e066d@ulb.ac.be>
	<434C1FEB.4080807@pdf.com>
Message-ID: <ad3388a32cc5339c3f62cb24d5d9390f@ulb.ac.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051011/2e282ff9/attachment.pl

From sundar.dorai-raj at pdf.com  Tue Oct 11 23:09:22 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 11 Oct 2005 16:09:22 -0500
Subject: [R] problems with levelplot and contourplot
In-Reply-To: <ad3388a32cc5339c3f62cb24d5d9390f@ulb.ac.be>
References: <8083cdb6868eaf3a92a46bea613e066d@ulb.ac.be>
	<434C1FEB.4080807@pdf.com>
	<ad3388a32cc5339c3f62cb24d5d9390f@ulb.ac.be>
Message-ID: <434C2A02.10205@pdf.com>


Tom Lenaerts wrote:
> I have to correct my previous reply.
> 
> The changes you propose work The strange thing is that if I upload the 
> R-script to
> produce the plot from file using
> 
> source("/Users/tomlenaerts/Programming/ObjC/Tools/AllEE/build/EEcont.R")
> 
> The script does not work.
> 
> When I copy-past the script myself into the R-window and execute things 
> work ok.
> Any explanation for this?
> 

Yes. See FAQ 7.22.

--sundar

> Tom
> 
> ------------------------------------------------------------------------------------------------- 
> 
> Tom Lenaerts (tlenaert at ulb.ac.be) http://www.tomlenaerts.tk/
> Postdoc Researcher @ IRIDIA-Universite Libre de Bruxelles-Belgium
> Guest Professor @ DINF-Vrije Uiversiteit Brussel-Belgium
> On 11 Oct 2005, at 22:26, Sundar Dorai-Raj wrote:
> 
> 
> 
>     Tom Lenaerts wrote:
> 
>         Hello,
>         Using the following code i want to make a level or contourplot
>         of some data that I produced
>         library(grid);library(lattice);
> 
> 
>     No need to explicitly load "grid". This is done when attaching
>     "lattice". Also, you do not need any ";" at the end of any lines.
> 
>         mydata <- read.table("avgee.dat");
>         mymat <- as.matrix(mydata);
>         mymat <-t(mymat)
>         vals<-as.vector(mymat);
>         conc<-c(0.0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5);
>         a<- c(0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1,
>         2.5,5.0, 7.5,10, 25, 50, 75, 100);
>         grid<-expand.grid(x=conc, y=a);
>         levelplot(vals ~ conc * a, grid, region=TRUE, cuts=20);
> 
> 
>     Don't you mean
> 
>     levelplot(vals ~ x * y, grid, region=TRUE, cuts=20)
> 
>     Your data.frame "grid" has columns "x" and "y", not "conc" and "a".
> 
>         When I do this get a blank output window and the following warnings
>         Warning messages:
>         1: longer object length
>         is not a multiple of shorter object length in: is.na(x) | is.na(y)
>         2: longer object length
>         is not a multiple of shorter object length in: id.na | is.na(var)
>         3: longer object length
>         is not a multiple of shorter object length in: id & if
>         (is.shingle(var)) ((var >=
>         levels(var)[[cond.current.level[i]]][1]) &
>          >
>         I've examined this mailinglist and the web and tried the
>         examples other people suggested. They seem to work.
>         Yet, my code seems the same as
>         a <-1:10
>         b <-11:20
>         j <- rnorm(100)
>         grid<-expand.grid(a = a, b = b)
>         levelplot(j~a*b, grid)
>         (from a previous mail)
>         and it does not work.
>         Can anybody tell me what I'm doing wrong? Furthermore as you
>         ight notice the data in a is in log-scale so I want the y-axis
>         of the plot in logscale.
> 
> 
>     To print y in log-scale, add the following:
> 
>     levelplot(..., scale = list(y = list(log = TRUE)))
> 
>     HTH,
> 
>     --sundar
>



From David.Brahm at geodecapital.com  Tue Oct 11 23:25:52 2005
From: David.Brahm at geodecapital.com (Brahm, David)
Date: Tue, 11 Oct 2005 17:25:52 -0400
Subject: [R] non-zero sequence of numbers
Message-ID: <4DD6F8B8782D584FABF50BF3A32B03D801A2BC7C@MSGBOSCLF2WIN.DMN1.FMR.COM>

Jason Horn <jason at 109valentine.com> wrote:
> Can anyone think of a way to create a pretty() sequence that excludes

> zero?

You could use except(pretty(x), 0), if you first defined the (quite
useful) set-operation function:

  R> except <- function(a,b) unique(a[!match(a, b, 0)])

(Consider this a plug to add "except" to the "union", "intersect",
etc., family of set operations.)

-- David Brahm (brahm at alum.mit.edu)



From ligges at statistik.uni-dortmund.de  Tue Oct 11 23:35:48 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 11 Oct 2005 23:35:48 +0200
Subject: [R] Problems with plot function
In-Reply-To: <OF63F80873.69B89EC4-ONC1257097.005C401A@aviation-civile.gouv.fr>
References: <OF63F80873.69B89EC4-ONC1257097.005C401A@aviation-civile.gouv.fr>
Message-ID: <434C3034.3020509@statistik.uni-dortmund.de>

KOITA Lassana - STAC/ACE wrote:

> 
> 
> 
> Hello  all  R   users,
> My simulation function works correctly, but I have problems with plot
> function. You will find the following code using it.
> Thank you for your help
> ##################################################"
> 
> simulation <- function(k, n){
> 
> conc <- seq(0,10,by=0.5)
> #choixg <- seq(1, length(conc))
> choixg <- rep(0,length(conc))
> for (i in 1:length(conc)){
>     choixg[i] <- (k + conc[i])^2/((k+conc[i])^n + (k+1)^n)
> 
>     }
>    return(choixg)
> 
> }
> simulation(5,1)


Please read the manuals!
The objects "conc" and "choixg" ar local to your function "simulation"...

If you return

   return(list(choixg=choixg, conc=conc))

from your function, then you can plot as follows:

   simResult <- simulation(5,1)

   with(simResult,
     plot(conc, choixg, main ="fonction de choix",
       col= "blue", pch=20, xlab = " concentration",
       ylab="proba de choisir la gauche"))


Uwe Ligges


> plot(conc, choixg, main ="fonction de choix", col= "blue", pch=20,
> xlab = " concentration", ylab="proba de choisir la gauche")
> ##########################################################
> 
> Lassana KOITA
> Service Technique de l'Aviation Civile (STAC)
> Direction G??n??rale de l'Aviation Civile (DGAC)
> Tel: 01 49 56 80 60
> Fax: 01 49 56 82 14
> http://www.stac.aviation-civile.gouv.fr
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Tue Oct 11 23:40:12 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 11 Oct 2005 23:40:12 +0200
Subject: [R] an error in my using of nnet
In-Reply-To: <cdf817830510111329h37170664vf2f563f2b1b1df98@mail.gmail.com>
References: <cdf817830510111329h37170664vf2f563f2b1b1df98@mail.gmail.com>
Message-ID: <434C313C.4020704@statistik.uni-dortmund.de>

Weiwei Shi wrote:

> Hi, there:
> I am trying nnet as followed:
> 
>>mg.nnet<-nnet(x=trn3[,r.v[1:100]], y=trn3[,209], size=5, decay = 5e-4,
> 
> maxit = 200)
> # weights: 511
> initial value 13822.108453
> iter 10 value 7408.169201
> iter 20 value 7362.201934
> iter 30 value 7361.669408
> iter 40 value 7361.294379
> iter 50 value 7361.045190
> final value 7361.038121
> converged
> Error in y - tmp : non-numeric argument to binary operator
> 
> Please help!


Please ask appropriately (we pointed you to the posting guide dozens of 
times now)!

- We do neither have trn3 nor r.v
- Which function nnet() are we talking about? Do you meant the one from 
package nnet in the VR bundle?
- Which version of R and nnet are we talking about?
- What about trying to debug yourself in a first step? E.g. a 
traceback() might give you (and us) some first hints what is going on.

Uwe Ligges






> Thanks,
> 
> Weiwei
> 
> --
> Weiwei Shi, Ph.D
> 
> "Did you always know?"
> "No, I did not. But I believed..."
> ---Matrix III
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From kjetil at redcotel.bo  Tue Oct 11 23:16:34 2005
From: kjetil at redcotel.bo (Kjetil Holuerson)
Date: Tue, 11 Oct 2005 17:16:34 -0400
Subject: [R] Under-dispersion - a stats question?
In-Reply-To: <E415F473-DCB4-4E3B-B50C-ABDB09C7E20F@MUOhio.edu>
References: <E415F473-DCB4-4E3B-B50C-ABDB09C7E20F@MUOhio.edu>
Message-ID: <434C2BB2.3060108@redcotel.bo>

Martin Henry H. Stevens wrote:
> Hello all:
> I frequently have glm models in which the residual variance is much  
> lower than the residual degrees of freedom (e.g. Res.Dev=30.5, Res.DF  
> = 82). Is it appropriate for me to use a quasipoisson error  
> distribution and test it with an F distribution? It seems to me that  
> I could stand to gain a much-reduced standard error if I let the  
> procedure estimate my dispersion factor (which is what I assume the  
> quasi- distributions do).
> 

I did'nt see an answer to this. maybe you could treat as a
quasimodel, but first you should ask why there is underdispersion.

Underdispersion could arise if you have dependent responses, for 
instance, competition (say, between plants) could produce 
underdispersion. Then you would be better off changing to an appropriate
model. maybe you could post more about your experimental setup?

Kjetil

> Thank you for any input at all.
> 
> Hank
> 
> Dr. Martin Henry H. Stevens, Assistant Professor
> 338 Pearson Hall
> Botany Department
> Miami University
> Oxford, OH 45056
> 
> Office: (513) 529-4206
> Lab: (513) 529-4262
> FAX: (513) 529-4243
> http://www.cas.muohio.edu/~stevenmh/
> http://www.muohio.edu/ecology/
> http://www.muohio.edu/botany/
> "E Pluribus Unum"
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 



--



From ripley at stats.ox.ac.uk  Wed Oct 12 00:01:47 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Oct 2005 23:01:47 +0100 (BST)
Subject: [R] Under-dispersion - a stats question?
In-Reply-To: <E415F473-DCB4-4E3B-B50C-ABDB09C7E20F@MUOhio.edu>
References: <E415F473-DCB4-4E3B-B50C-ABDB09C7E20F@MUOhio.edu>
Message-ID: <Pine.LNX.4.61.0510111154130.15977@gannet.stats>

On Mon, 10 Oct 2005, Martin Henry H. Stevens wrote:

> Hello all:
> I frequently have glm models in which the residual variance is much
> lower than the residual degrees of freedom (e.g. Res.Dev=30.5, Res.DF
> = 82). Is it appropriate for me to use a quasipoisson error
> distribution and test it with an F distribution? It seems to me that
> I could stand to gain a much-reduced standard error if I let the
> procedure estimate my dispersion factor (which is what I assume the
> quasi- distributions do).
>
> Thank you for any input at all.

This usually indicates a deviation from the large-sample theory because of 
small counts.  See e.g. MASS4 p.208.  Then estimator

 	residual variance
 	-----------------
     residual degrees of freedom

is unreliable.  If the better methods discuss there confirm 
under-dispersion, then you probably have some form of negative correlation 
and need to look at your experimental setup.  (But it is usually are false 
alarm.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From helprhelp at gmail.com  Wed Oct 12 00:04:19 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Tue, 11 Oct 2005 17:04:19 -0500
Subject: [R] an error in my using of nnet
In-Reply-To: <434C313C.4020704@statistik.uni-dortmund.de>
References: <cdf817830510111329h37170664vf2f563f2b1b1df98@mail.gmail.com>
	<434C313C.4020704@statistik.uni-dortmund.de>
Message-ID: <cdf817830510111504y4f79e04er48d126ad3ae04f33@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051011/ca772502/attachment.pl

From David.Duffy at qimr.edu.au  Tue Oct 11 23:56:33 2005
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 12 Oct 2005 07:56:33 +1000 (EST)
Subject: [R]  Sometimes having problems finding a minimum using optim(),
 optimize(), and nlm() (while searching for noncentral F parameters)
In-Reply-To: <mailman.11.1129024801.1790.r-help@stat.math.ethz.ch>
References: <mailman.11.1129024801.1790.r-help@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.58.0510120733150.32423@orpheus.qimr.edu.au>

Ken Kelley <KKIII at Indiana.Edu> wrote

>
>
> I have a problem that I have been unable to determine either the best
> way to proceed and why the methods I'm trying to use sometimes fail. I'm
> using the pf() function in an optimization function to find a
> noncentrality parameter that leads to a specific value at a specified
> quantile.
[SNIP]
> I'm using three function [optim(), optimize(), and nlm()] to try and
> accomplish the same goal (which was stated above). I believe that they
> should all return the same value, and at times they do just that, but at
> other times the methods return inappropriate results. I'll paste my code
> that illustrates an example where all is well and one where things fail.
>

Perhaps uniroot() might be better
 Low.Lim.NC.F <- function(Lambda, alpha.lower, F.value, df.1, df.2) {
    pf(q=F.value, df1=df.1, df2=df.2, ncp=Lambda) - (1-alpha.lower)
 }
 uniroot(Low.Lim.NC.F, interval=c(0,50000), alpha.lower=0.025, df.1=5,
 df.2=200, F.value=12)

If you plot your example, the gradients are much steeper from above than
below, so nlm() works when the starting value is say 50.  In addition,
underflow in pf for more extreme values of lambda affect these more
general search algorithms.


| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From quantpm at yahoo.com  Wed Oct 12 01:26:08 2005
From: quantpm at yahoo.com (t c)
Date: Tue, 11 Oct 2005 16:26:08 -0700 (PDT)
Subject: [R] adding 1 month to a date
Message-ID: <20051011232608.60377.qmail@web35013.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051011/b54f3fca/attachment.pl

From p.murrell at auckland.ac.nz  Wed Oct 12 01:30:09 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 12 Oct 2005 12:30:09 +1300
Subject: [R] Sweave and Rnews
References: <434BD7DB.7090708@biomserv.univ-lyon1.fr>
Message-ID: <434C4B01.1040303@stat.auckland.ac.nz>

Hi


St??phane Dray wrote:
> Hello list,
> 
> I am writing a paper for Rnews. I use Sweave to do it. I did not find 
> information about writing a paper for Rnews using Sweave and have some 
> questions:
> - Is there a problem to use the environment 'Sinput' in the place of 
> 'example' or 'smallexample'. It works fine but perhaps there are some 
> technical/editorial problems ?


Sweave commands/environments are fine thanks.
We can handle them without any hassle.

Paul
(as member of R News editorial board)


> - I have some long lines of code in schunk. I did not find any way to 
> cut them in the Rnw file and they appear out of the column in the dvi 
> file. The only solution I found is to cut these lines in the tex file 
> generated by Sweave. Is there a more elegant and automatic solution to 
> this problem?
> 
> Thanks in advance.
> 


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From sharm071 at tc.umn.edu  Wed Oct 12 01:51:52 2005
From: sharm071 at tc.umn.edu (Ratnendra Sharma)
Date: Tue, 11 Oct 2005 18:51:52 -0500
Subject: [R] R data import
Message-ID: <434C5018.7070404@tc.umn.edu>

Hello,

I hope all is well. I've gone through and searched just about all the 
manuals, faqs, contribs available on the data import/export process and 
have not found any answer to a specific question. Hopefully, I will be 
able to fall back upon the valuable expertise in mailing list. Here goes:

How can I import SPECIFIC columns of data in a fixed width file? E.g. I 
have a fwf with 40 variables ranging from 1 to 10 characters and at any 
given time, need only a few to analyze, like so:
 <age: 2 char ><sex: 1 char><morning: 1 char><location: 3 
char>......<family: 9 char><tagged: date>.......<weight at capture: 4 
char><length at capture: 7 char>etc.
which looks something like:
02M1LOS...xxcanidae011289.....10001291412


In essence I am looking for functionality similar to the SAS 
pointer/informat method. I would appreciate any help anyone would be 
able to give!

Thanks so much for your help.

best,
Ratnendra Sharma
U Minn



From sharm071 at tc.umn.edu  Wed Oct 12 01:55:34 2005
From: sharm071 at tc.umn.edu (Ratnendra Sharma)
Date: Tue, 11 Oct 2005 18:55:34 -0500
Subject: [R] R and SAS pointer/informat functionality
Message-ID: <434C50F6.4020904@tc.umn.edu>

Hello,

I hope all is well. I've gone through and searched just about all the 
manuals, faqs, contribs available on the data import/export process and 
have not found any answer to a specific question. Hopefully, I will be 
able to fall back upon the valuable expertise in mailing list. Here goes:

How can I import SPECIFIC columns of data in a fixed width file? E.g. I 
have a fwf with 40 variables ranging from 1 to 10 characters and at any 
given time, need only a few to analyze, like so:
<age: 2 char ><sex: 1 char><morning: 1 char><location: 3 
char>......<family: 9 char><tagged: date>.......<weight at capture: 4 
char><length at capture: 7 char>etc.
which looks something like:
02M1LOS...xxcanidae011289.....10001291412


In essence I am looking for functionality similar to the SAS 
pointer/informat method. I would appreciate any help anyone would be 
able to give!

Thanks so much for your help.

best,
Ratnendra Sharma
U Minn



From deepayan.sarkar at gmail.com  Wed Oct 12 03:00:07 2005
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 11 Oct 2005 20:00:07 -0500
Subject: [R] aligning column of xyplots and removing space between them
In-Reply-To: <971536df0510111644o1d4be22fn4b1db8d2b87bb305@mail.gmail.com>
References: <971536df0510110043w2e4a47b5le0f43b03871e91a4@mail.gmail.com>
	<eb555e660510111342i4b909fcaqdee1097346344a3f@mail.gmail.com>
	<971536df0510111644o1d4be22fn4b1db8d2b87bb305@mail.gmail.com>
Message-ID: <eb555e660510111800v323d0a1bxc1ed65be23a19a0a@mail.gmail.com>

On 10/11/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Thanks.  That works although the alignment is still not perfect.
> I am attaching the saved image in both .png and .emf formats
> so you can see what I mean.  Its not far off but its noticeable.
>
> In .emf format a portion of the bounding box does not come out
> either and it comes out bluish rather than white.  Not sure if such
> attachments can survive the list but I have sent you a copy too just
> in case.

[I have no way to easily view the emf file, but] I can't see any
reason for the misalignment in the PNG file (other than a driver or
rendering bug). Do you see it in PDF output as well?

Deepayan



From spencer.graves at pdf.com  Wed Oct 12 02:54:43 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 11 Oct 2005 17:54:43 -0700
Subject: [R] need suggestion about building formual
In-Reply-To: <200510012245.29338.qsb@nlbmol.ibp.ac.cn>
References: <200509281428.38761.qsb@nlbmol.ibp.ac.cn> <433C35CF.50007@pdf.com>
	<200510012245.29338.qsb@nlbmol.ibp.ac.cn>
Message-ID: <434C5ED3.80207@pdf.com>

	  Have you considered writing a function to do the complex math and 
then calling nls referring to that function?  Consider the following 
(not tried):

expg <- function(a., x, G0, R, T){
	exp((a.[1]+(a.[2]*x)^(1/2)-G0)/(R*T))
}

mynls<-nls(formula=y~expg(a.=c(a, b), x=x, G0=G0, R=R, T=T),
       data=mydata,...)

	  If "nls" stops prematurely, I then write another function, "SSE" to 
compute the sum of squares of deviations from y and then ask "optim" to 
minimize "SSE", using "hessian=TRUE".  If you try this and have trouble 
making it work, please send another post.

	  spencer graves

Simple wrote:

> Thanks for your kind respond. Although the answer didn't solve my question 
> clearly,maybe I still not understand the art of R.
> 
> I'm sorry that I had not talked the problem clearly, maybe a example with more 
> detail will be suitable as suggested in the the posting guide.
>  
> In function fitting program, such as Sigmaplot, a fitting formula, can be  
> write in separate form:
> G=a+(b*x)^(1/2)
> k=exp((G-G0)/(R*T))
> fit k to y
> 
> of course,in R's nls, can write as:
> mynls<-nls(formula=y~exp((a+(b*x)^(1/2)-G0)/(R*T)),data=mydata,...)
> 
> In this example, the formula is simple and acceptable. However, when the 
> formula is more complexity,writing all in one formula,the readability will be 
> damaged.So I'm looking for a way to write simple and readable code in this 
> situation.   
> 
>   
> Spencer Graves wrote:
> 
>>	  I'm not certain what you are asking.
>>
>>	  You can build expressions in R as character strings and then execute
>>them.  Example:
>>
>>expr <- paste("two <-", 1, "+", 1)
>>eval(parse(text=expr))
>>two
>>
>>	  If this does not answer your question, PLEASE do read the posting
>>guide, "www.R-project.org/posting-guide.html".  It can help increase the
>>chances of a quick and useful reply.
>>
>>	  spencer graves
>>
>>Simple wrote:
>>
>>>hi,
>>>I'm an newbie for R,I want do some fitting in R.
>>>
>>>I wander if it is possible to write a few of equations but only one
>>>formual when fitting
>>>
>>>Currently,My problem is,in R, is there methods combination a few
>>>equations into one formual?
>>>For example,
>>>y=f1(k);
>>>k=f2(t);
>>>t=f3(x);
>>>although it is certain that the can be equations turn into one formual as
>>>y~f(x),but write such a complexity string make me painful.
>>>
>>>I have searched the web and found out there were only examples with one
>>>formual.any suggestion?
>>>
>>>I hope that I have omit something.
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From spencer.graves at pdf.com  Wed Oct 12 03:04:30 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 11 Oct 2005 18:04:30 -0700
Subject: [R] "symbol print-name too long"
In-Reply-To: <6BCB4D493A447546A8126F24332056E8F28B71@school1.business.edu>
References: <6BCB4D493A447546A8126F24332056E8F28B71@school1.business.edu>
Message-ID: <434C611E.6020706@pdf.com>

	  Have you received a reply or otherwise resolved this issue?  If no, 
have you tried to construct the simplest possible example that comes to 
your mind.  Sometimes in the course of trying that, I often figure out 
what the error message means.  If you try this without getting the 
answer yourself, please send the resulting simple example to this list. 
  If someone reading your email can copy a few lines of code from your 
message into R and get the same problem, you are more likely to get a 
quick, informative reply.  (Please also specify which version of R on 
which platform.)

	  spencer graves

Afshartous, David wrote:

> All, 
> 
> I've coded a function and it works manually if I copy it line by line into R.
> However, when I try to "load" (copy and paste) the entire function into 
> R, I get the following error after the listed line of code:
> 
> + N.j.list = lapply(rej.hyp, length)   
> Error: symbol print-name too long
> 
> Does anyone you know what this error means?  Strangely, when I copy the 
> same line verbatim into R manually apart from the whole function, 
> no error message results.
> 
> I've checked the manuals and don't see anything RE print-name too long.  I also 
> tried google and saw an old message on this error message, but it doesn't seem to
> apply here.
> 
> Thanks,
> Dave
> ps - please respond directly to dafshartous at yahoo.com please.
> 
> 
> David Afshartous, PhD
> University of Miami
> Department of Management Science
> School of Business
> Coral Gables, FL 33124
> phone: 305-284-8005
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From MSchwartz at mn.rr.com  Wed Oct 12 03:31:03 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Tue, 11 Oct 2005 20:31:03 -0500
Subject: [R] R and SAS pointer/informat functionality
In-Reply-To: <434C50F6.4020904@tc.umn.edu>
References: <434C50F6.4020904@tc.umn.edu>
Message-ID: <1129080663.3510.4.camel@localhost.localdomain>

On Tue, 2005-10-11 at 18:55 -0500, Ratnendra Sharma wrote:
> Hello,
> 
> I hope all is well. I've gone through and searched just about all the 
> manuals, faqs, contribs available on the data import/export process and 
> have not found any answer to a specific question. Hopefully, I will be 
> able to fall back upon the valuable expertise in mailing list. Here goes:
> 
> How can I import SPECIFIC columns of data in a fixed width file? E.g. I 
> have a fwf with 40 variables ranging from 1 to 10 characters and at any 
> given time, need only a few to analyze, like so:
> <age: 2 char ><sex: 1 char><morning: 1 char><location: 3 
> char>......<family: 9 char><tagged: date>.......<weight at capture: 4 
> char><length at capture: 7 char>etc.
> which looks something like:
> 02M1LOS...xxcanidae011289.....10001291412
> 
> 
> In essence I am looking for functionality similar to the SAS 
> pointer/informat method. I would appreciate any help anyone would be 
> able to give!
> 
> Thanks so much for your help.
> 
> best,
> Ratnendra Sharma
> U Minn

You just about answered the question yourself in your second paragraph
('fwf')....

See ?read.fwf and note the Details section regarding the use of negative
numbers for the 'widths' argument to skip columns.

HTH,

Marc Schwartz
<Greetings from Eden Prairie>



From fparlamis at mac.com  Wed Oct 12 04:07:33 2005
From: fparlamis at mac.com (Parlamis Franklin)
Date: Tue, 11 Oct 2005 16:07:33 -1000
Subject: [R] bug checking
Message-ID: <1BA44AD2-08B5-4A7F-8B2A-AF8397DF45AF@mac.com>

I have observed the following behavior, wondering if it is a bug  
before I submit a report.

I am using the plot function with call:  plot(X, Y,  
col="red", . . . ) where X is an object that inherits from classes  
'dates' and 'times' (created with the 'dates' function from package  
'chron') and y is a numeric vector.  The color red is applied to the  
area from the first to the last tick mark on the x axis (even if I  
don't set col="red" and only set, say col.main="red").

If instead of feeding the function X, I feed it unclass(X) or  
as.vector(X) the red color is not applied to the area between the  
first and last ticks on the x axis.

Is this a bug, or just a consequence of there not being a plot method  
for the class I am trying to feed the function?

Franklin Parlamis



From MSchwartz at mn.rr.com  Wed Oct 12 04:15:46 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Tue, 11 Oct 2005 21:15:46 -0500
Subject: [R] adding 1 month to a date
In-Reply-To: <20051011232608.60377.qmail@web35013.mail.mud.yahoo.com>
References: <20051011232608.60377.qmail@web35013.mail.mud.yahoo.com>
Message-ID: <1129083346.3510.11.camel@localhost.localdomain>

On Tue, 2005-10-11 at 16:26 -0700, t c wrote:
> Within an R dataset, I have a date field called date_.  (The dates are
> in the format YYYY-MM-DD, e.g. 1995-12-01.)

> How can I add or subtract 1 month from this date, to get 1996-01-01 or
> 1995-11-01.

There might be an easier way to do this, but using seq.Date(), you can
increment or decrement from a Time 0 by months:

Add 1 month:

This takes your Time 0, generates a 2 element sequence (which begins
with Time 0) and then takes the second element:

> seq(as.Date("1995-12-01"), by = "month", length = 2)[2]
[1] "1996-01-01"



Subtract 1 month:

Same as above, but we use 'by = "-1 month"' and take the second element:

> seq(as.Date("1995-12-01"), by = "-1 month", length = 2)[2]
[1] "1995-11-01"


See ?as.Date and ?seq.Date for more information. The former function is
used to convert from a character vector to a Date class object. Note
that in your case, the date format is consistent with the default. Pay
attention to the 'format' argument in as.Date() if your dates should be
in other formats.

HTH,

Marc Schwartz



From u9370004 at cc.kmu.edu.tw  Wed Oct 12 04:23:11 2005
From: u9370004 at cc.kmu.edu.tw (Chun-Ying Lee)
Date: Wed, 12 Oct 2005 10:23:11 +0800
Subject: [R] monte carlo simulation
Message-ID: <20051012013941.M50588@cc.kmu.edu.tw>

Dear R user:
  I wonder if it is possible to run monte carlo simulation 
with dse2 package(MonteCarloSimulations function) using ordinary 
differential equation. How do I define the model? Or if there are any 
functions which can run monte carlo simulation using ordinary differential 
equation. Please give me some comments. Thanks in advance!!



From MSchwartz at mn.rr.com  Wed Oct 12 04:47:22 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Tue, 11 Oct 2005 21:47:22 -0500
Subject: [R] bug checking
In-Reply-To: <1BA44AD2-08B5-4A7F-8B2A-AF8397DF45AF@mac.com>
References: <1BA44AD2-08B5-4A7F-8B2A-AF8397DF45AF@mac.com>
Message-ID: <1129085243.3510.21.camel@localhost.localdomain>

On Tue, 2005-10-11 at 16:07 -1000, Parlamis Franklin wrote:
> I have observed the following behavior, wondering if it is a bug  
> before I submit a report.
> 
> I am using the plot function with call:  plot(X, Y,  
> col="red", . . . ) where X is an object that inherits from classes  
> 'dates' and 'times' (created with the 'dates' function from package  
> 'chron') and y is a numeric vector.  The color red is applied to the  
> area from the first to the last tick mark on the x axis (even if I  
> don't set col="red" and only set, say col.main="red").
> 
> If instead of feeding the function X, I feed it unclass(X) or  
> as.vector(X) the red color is not applied to the area between the  
> first and last ticks on the x axis.
> 
> Is this a bug, or just a consequence of there not being a plot method  
> for the class I am trying to feed the function?
> 
> Franklin Parlamis

As per the Posting Guide, it would be immensely helpful in the attempt
to help you, if you would provide the exact code you are using and some
sample data here, so that we can exactly replicate what you are
experiencing.

Lacking that, it would be difficult to assist as we can only guess. It
does sound like there is an _appropriate_ change in the plot method
behavior as a direct consequence of your modifying the class of the
argument(s), which is of course how methods are dispatched. Thus, if I
were to guess, this is not a bug.

I would however, certainly recommend that you submit an example here to
confirm the behavior, before you post a bug report, as that would avoid
a more energetic response.

Marc Schwartz



From spencer.graves at pdf.com  Wed Oct 12 05:11:30 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 11 Oct 2005 20:11:30 -0700
Subject: [R] ML optimization question--unidimensional unfolding scaling
In-Reply-To: <BF66F1B0.11DC0%pmuhl830@gmail.com>
References: <BF66F1B0.11DC0%pmuhl830@gmail.com>
Message-ID: <434C7EE2.9040605@pdf.com>

	  There may be a few problems where ML (or more generally Bayes) fails 
to give sensible answers, but they are relatively rare.

	  What is your likelihood?  How many parameters are you trying to 
estimate?

	  Are you using constrained or unconstrained optimization?  If 
constrained, I suggest you remove the constraints by appropriate 
transformation.  When considering alternative transformations, I 
consider (a) what makes physical sense, and (b) which transformation 
produces a log likelihood that is more close to being parabolic.

	  Hou are you calling "optim"?  Have you tried all "SANN" as well as 
"Nelder-Mead", "BFGS", and "CG"?  If you are using constrained 
optimization, I suggest you move the constraints to Inf by appropriate 
transformation and use the other methods, as I just suggested.

	  If you would still like more suggestions from this group, please 
provide more detail -- but as tersely as possible.  The posting guide 
is, I believe, quite useful (www.R-project.org/posting-guide.html).

	  spencer graves

Peter Muhlberger wrote:

> I'm trying to put together an R routine to conduct unidimensional unfolding
> scaling analysis using maximum likelihood.  My problem is that ML
> optimization will get stuck at latent scale points that are far from
> optimal.  The point optimizes on one of the observed variables but not
> others and for ML to move away from this 'local optimum', it has to move in
> a direction in which the likelihood is decreasing, which it won't.
> 
> It's not hard to know where to look for a more optimal value--it'll be just
> on the other side of the mean of a curve.  So, I can find better values, but
> these values need to be fed back into ML for continued optimization.
> Problem is, optim or nlm don't allow me to feed them new values for
> parameters and in any event ML will likely choke w/ parameters jumping
> around.  
> 
> One solution I've thought of is to restart optim or nlm w/ the new values
> whenever a point jumps.  Is there any good way to get optim or nlm to
> prematurely terminate, return control to the calling program, while
> retaining a copy of the estimates?
> 
> Perhaps ML isn't the best approach for this kind of problem.  Suggestions
> welcome!
> 
> Cheers,
> Peter
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From spencer.graves at pdf.com  Wed Oct 12 05:54:34 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 11 Oct 2005 20:54:34 -0700
Subject: [R] log4j
In-Reply-To: <3f87cc6d0510031252w6151bafaiefdef29297a1963f@mail.gmail.com>
References: <3f87cc6d0510031252w6151bafaiefdef29297a1963f@mail.gmail.com>
Message-ID: <434C88FA.6070602@pdf.com>

	  I just got 145 hits from RSiteSearch("debugger").  Does this help?

	  spencer graves

Omar Lakkis wrote:

> Is there a log4j, or similar, package for R?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From fparlamis at mac.com  Wed Oct 12 06:02:09 2005
From: fparlamis at mac.com (Parlamis Franklin)
Date: Tue, 11 Oct 2005 18:02:09 -1000
Subject: [R] bug checking
In-Reply-To: <1129085243.3510.21.camel@localhost.localdomain>
References: <1BA44AD2-08B5-4A7F-8B2A-AF8397DF45AF@mac.com>
	<1129085243.3510.21.camel@localhost.localdomain>
Message-ID: <3DA00485-7B82-4658-B523-5955734103E8@mac.com>

## Code was long, so I simplified it by creating vectors from scratch  
so it would run as is.  Putative "bug" is still evidenced on the x axis

discount.factors.dates <- seq.dates(from="09/30/2005", to="09/30/2035")
rates<-seq(4.4, 5.2, by=0.0025);
plot(discount.factors.dates[1:length(rates)], rates,
      pch=18, las=1, bty="n",
      col="red", col.main="red",
      xlab="Date", ylab="Rate",
      ylim=c(min(rates)-(max(rates)-min(rates))/10,max(rates)+(max 
(rates)-min(rates))/10))

## This is the output:

-------------- next part --------------
A non-text attachment was scrubbed...
Name: plot.pdf
Type: application/pdf
Size: 27928 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20051011/231037f1/plot.pdf
-------------- next part --------------

## Hopefully you all see the red x axis.

## I am running R Cocoa GUI 1.1.2 with R 2.1.1 framework on a dual  
proc 2.7 Ghz Power Mac.  A Quartz device is opened when 'plot' is  
called.  X11User and X11SDK are installed on t he computer, as well  
as xCode 2.1 (in case that's relevant).


On Oct 11, 2005, at 4:47 PM, Marc Schwartz wrote:

> On Tue, 2005-10-11 at 16:07 -1000, Parlamis Franklin wrote:
>
>> I have observed the following behavior, wondering if it is a bug
>> before I submit a report.
>>
>> I am using the plot function with call:  plot(X, Y,
>> col="red", . . . ) where X is an object that inherits from classes
>> 'dates' and 'times' (created with the 'dates' function from package
>> 'chron') and y is a numeric vector.  The color red is applied to the
>> area from the first to the last tick mark on the x axis (even if I
>> don't set col="red" and only set, say col.main="red").
>>
>> If instead of feeding the function X, I feed it unclass(X) or
>> as.vector(X) the red color is not applied to the area between the
>> first and last ticks on the x axis.
>>
>> Is this a bug, or just a consequence of there not being a plot method
>> for the class I am trying to feed the function?
>>
>> Franklin Parlamis
>>
>
> As per the Posting Guide, it would be immensely helpful in the attempt
> to help you, if you would provide the exact code you are using and  
> some
> sample data here, so that we can exactly replicate what you are
> experiencing.
>
> Lacking that, it would be difficult to assist as we can only guess. It
> does sound like there is an _appropriate_ change in the plot method
> behavior as a direct consequence of your modifying the class of the
> argument(s), which is of course how methods are dispatched. Thus, if I
> were to guess, this is not a bug.
>
> I would however, certainly recommend that you submit an example  
> here to
> confirm the behavior, before you post a bug report, as that would  
> avoid
> a more energetic response.
>
> Marc Schwartz
>
>
>


From MSchwartz at mn.rr.com  Wed Oct 12 06:34:29 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Tue, 11 Oct 2005 23:34:29 -0500
Subject: [R] bug checking
In-Reply-To: <3DA00485-7B82-4658-B523-5955734103E8@mac.com>
References: <1BA44AD2-08B5-4A7F-8B2A-AF8397DF45AF@mac.com>
	<1129085243.3510.21.camel@localhost.localdomain>
	<3DA00485-7B82-4658-B523-5955734103E8@mac.com>
Message-ID: <1129091669.3510.42.camel@localhost.localdomain>

Thanks for the code and the clarifications, including the PDF file.

Yes, I can replicate the behavior here (R 2.2.0 on FC4) and I am cc:ing
Kurt Hornik, who ported chron to R and is the chron package maintainer.

It appears that the "culprit" is the argument 'col = "red"', which
towards the end of plot.times() is used as follows:

...
    else if (x.times)
        axis.times(1, x, simplify = simplify, labels = TRUE,
            adj = adj, col = col, cex = cex, font = font,
            las = las, lab = lab, mgp = mgp, tcl = tcl)
...

Thus, if the 'x' data is of class 'times', the above code is used and
the color of the axis line and tick marks are set to "red" as per the
'col' argument to axis(), which axis.times() ultimately calls.

This results in the behavior that you are seeing, where both the plot
symbols/lines and the axis are colored the same.

This does sound like a bug and Kurt can comment better on this.

HTH,

Marc Schwartz


On Tue, 2005-10-11 at 18:02 -1000, Parlamis Franklin wrote:
> ## Code was long, so I simplified it by creating vectors from scratch  
> so it would run as is.  Putative "bug" is still evidenced on the x axis
> 
> discount.factors.dates <- seq.dates(from="09/30/2005", to="09/30/2035")
> rates<-seq(4.4, 5.2, by=0.0025);
> plot(discount.factors.dates[1:length(rates)], rates,
>       pch=18, las=1, bty="n",
>       col="red", col.main="red",
>       xlab="Date", ylab="Rate",
>       ylim=c(min(rates)-(max(rates)-min(rates))/10,max(rates)+(max 
> (rates)-min(rates))/10))
> 
> ## This is the output:
> 
> ## Hopefully you all see the red x axis.
> 
> ## I am running R Cocoa GUI 1.1.2 with R 2.1.1 framework on a dual  
> proc 2.7 Ghz Power Mac.  A Quartz device is opened when 'plot' is  
> called.  X11User and X11SDK are installed on t he computer, as well  
> as xCode 2.1 (in case that's relevant).
> 
> 
> On Oct 11, 2005, at 4:47 PM, Marc Schwartz wrote:
> 
> > On Tue, 2005-10-11 at 16:07 -1000, Parlamis Franklin wrote:
> >
> >> I have observed the following behavior, wondering if it is a bug
> >> before I submit a report.
> >>
> >> I am using the plot function with call:  plot(X, Y,
> >> col="red", . . . ) where X is an object that inherits from classes
> >> 'dates' and 'times' (created with the 'dates' function from package
> >> 'chron') and y is a numeric vector.  The color red is applied to the
> >> area from the first to the last tick mark on the x axis (even if I
> >> don't set col="red" and only set, say col.main="red").
> >>
> >> If instead of feeding the function X, I feed it unclass(X) or
> >> as.vector(X) the red color is not applied to the area between the
> >> first and last ticks on the x axis.
> >>
> >> Is this a bug, or just a consequence of there not being a plot method
> >> for the class I am trying to feed the function?
> >>
> >> Franklin Parlamis
> >>
> >
> > As per the Posting Guide, it would be immensely helpful in the attempt
> > to help you, if you would provide the exact code you are using and  
> > some
> > sample data here, so that we can exactly replicate what you are
> > experiencing.
> >
> > Lacking that, it would be difficult to assist as we can only guess. It
> > does sound like there is an _appropriate_ change in the plot method
> > behavior as a direct consequence of your modifying the class of the
> > argument(s), which is of course how methods are dispatched. Thus, if I
> > were to guess, this is not a bug.
> >
> > I would however, certainly recommend that you submit an example  
> > here to
> > confirm the behavior, before you post a bug report, as that would  
> > avoid
> > a more energetic response.
> >
> > Marc Schwartz
> >
> >
> >
>



From jarioksa at sun3.oulu.fi  Wed Oct 12 07:10:47 2005
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Wed, 12 Oct 2005 08:10:47 +0300
Subject: [R] Under-dispersion - a stats question?
In-Reply-To: <434C2BB2.3060108@redcotel.bo>
References: <E415F473-DCB4-4E3B-B50C-ABDB09C7E20F@MUOhio.edu>
	<434C2BB2.3060108@redcotel.bo>
Message-ID: <1129093847.14213.4.camel@biol102145.oulu.fi>

On Tue, 2005-10-11 at 17:16 -0400, Kjetil Holuerson wrote:
> Martin Henry H. Stevens wrote:
> > Hello all:
> > I frequently have glm models in which the residual variance is much  
> > lower than the residual degrees of freedom (e.g. Res.Dev=30.5, Res.DF  
> > = 82). Is it appropriate for me to use a quasipoisson error  
> > distribution and test it with an F distribution? It seems to me that  
> > I could stand to gain a much-reduced standard error if I let the  
> > procedure estimate my dispersion factor (which is what I assume the  
> > quasi- distributions do).
> > 
> 
> I did'nt see an answer to this. maybe you could treat as a
> quasimodel, but first you should ask why there is underdispersion.
> 
> Underdispersion could arise if you have dependent responses, for 
> instance, competition (say, between plants) could produce 
> underdispersion. Then you would be better off changing to an appropriate
> model. maybe you could post more about your experimental setup?
> 
Some ecologists from Bergen, Norway, suggest using quasipoisson with its
underdispersed residual error (while I wouldn't do that). However, it
indeed would be useful to know a bit more about the setup, like the type
of dependent variable. If the dependent variable happens to be the
number of species (like it's been in some papers by MHHS), this
certainly is *not* Poisson nor quasi-Poisson nor in the exponential
family, although it so often is modelled. I've often seen that species
richness (number of species -- or in R-speak 'tokens' -- in a
collection) is underdispersed to Poisson, and for a good reason. Even
there I'd play safe and use poisson() instead of underdispersed
quasipoisson(). 

cheers, jari oksanen
-- 
Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
Ph. +358 8 5531526, cell +358 40 5136529, fax +358 8 5531061
email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/



From E.Catchpole at adfa.edu.au  Wed Oct 12 07:18:50 2005
From: E.Catchpole at adfa.edu.au (ecatchpole)
Date: Wed, 12 Oct 2005 15:18:50 +1000
Subject: [R] font=5 (Was: greek symbols using pch)
In-Reply-To: <digldd$bnr$1@sea.gmane.org>
References: <283982AD9F3CD211B3AC00A0C983032F11443674@paradise.ansto.gov.au>
	<die0c3$5ti$1@sea.gmane.org> <434B4CBC.6000006@adfa.edu.au>
	<Pine.LNX.4.61.0510110742380.13144@gannet.stats>
	<434B7B78.6020603@adfa.edu.au> <digldd$bnr$1@sea.gmane.org>
Message-ID: <434C9CBA.2090901@adfa.edu.au>

Earl,

I don't think that's a bug. Try

pdf("font5.pdf", onefile=FALSE)

and similarly for postscript().

Ted.


On 12/10/05 01:23,  Earl F. Glynn wrote,:
> "ecatchpole" <E.Catchpole at adfa.edu.au> wrote in message
> news:434B7B78.6020603 at adfa.edu.au...
>>Thanks for that. Very instructive, and much appreciated.
>>
>>And sorry, yes, I strayed well off the original topic. The Greek symbols
>>  come out fine with font=5 in my locale,
>>Locale:
>>LC_CTYPE=en_GB.UTF-8;
>>LC_NUMERIC=C;
>>LC_TIME=en_GB.UTF-8;
>>
>>I was interested in some of the other nice characters, for example
>>\infty and \partial, that appear in the table, but with a calligraphic R
>>attached to them. But plotmath() works fine, so I'm happy.
> 
> I performed some tests with font=5 on both Linux and Windows using
> source("font5.R"), which is shown below, and then calling the Font5Test()
> function.
> 
> Consistent results were seen with devices X11, png, and jpeg under either
> Linux  (R 2.1.1) or Windows (R 2.2.0) in my locale.  Oddly, both the pdf and
> postscript devices create 2 pages of output with the first page the expected
> table and a second unexpected page with only the "clubs suite" symbol (167)
> in the middle of the plot. I'd call this a bug, but I guess I haven't read
> all the documentation about this yet.
> 
> efg
> Earl F. Glynn
> Scientific Programmer
> Stowers Institute for Medical Research
> 
> 
> font5.R
> ======
> 
> ShowFont5 <- function()
> {
>   oldpar <- par(font=5, las=1)
>   plot(0:1, 0:1, type="n")
>   points(.5, .5, pch=167)
>   par(font=5, las=1)
>   plot(0:15,0:15,type="n",ylim=c(15,0),
>     main="Symbols in Font=5",
>     xlab="", ylab="",xaxt="n", yaxt="n")
>   axis(BOTTOM<-1, at=0:15)
>   axis(LEFT  <-2, at=0:15, 16*0:15)
>   abline(v=0.5 + 0:14,
>          h=0.5 + 0:14, col="grey", lty="dotted")
>   # pch index of any cell is 16*row + column
>   for(i in 0:255)
>   {
>     x <- i %%16;
>     y <- i %/% 16;
>     points(x,y,pch=i)
>   }
>   par(oldpar)
> }
> 
> Font5Test <- function()
> {
>   X11()
>   ShowFont5()
>   dev.off()
> 
>   pdf("font5.pdf")
>   ShowFont5()
>   dev.off()
> 
>   png("font5.png")
>   ShowFont5()
>   dev.off()
> 
>   jpeg("font5.jpg")
>   ShowFont5()
>   dev.off()
> 
>   postscript("font5.ps")
>   ShowFont5()
>   dev.off()
> 
> }
> 
> 
> Linux Test
> =======
>>Sys.getlocale()
> [1] "C"
> 
>>R.Version()
> $platform
> [1] "x86_64-unknown-linux-gnu"
> 
> $arch
> [1] "x86_64"
> 
> $os
> [1] "linux-gnu"
> 
> $system
> [1] "x86_64, linux-gnu"
> 
> $status
> [1] ""
> 
> $major
> [1] "2"
> 
> $minor
> [1] "1.1"
> 
> $year
> [1] "2005"
> 
> $month
> [1] "06"
> 
> $day
> [1] "20"
> 
> $language
> [1] "R"
> 
> 
> 
> Windows Test
> ==========
>>Sys.getlocale()
> [1] "LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> States.1252;LC_MONETARY=English_United
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252"
> 
>>R.Version()
> $platform
> [1] "i386-pc-mingw32"
> 
> $arch
> [1] "i386"
> 
> $os
> [1] "mingw32"
> 
> $system
> [1] "i386, mingw32"
> 
> $status
> [1] ""
> 
> $major
> [1] "2"
> 
> $minor
> [1] "2.0"
> 
> $year
> [1] "2005"
> 
> $month
> [1] "10"
> 
> $day
> [1] "06"
> 
> $"svn rev"
> [1] "35749"
> 
> $language
> [1] "R"
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Dr E.A. Catchpole
Visiting Fellow
Univ of New South Wales at ADFA, Canberra, Australia
and University of Kent, Canterbury, England
- www.ma.adfa.edu.au/~eac
- fax: +61 2 6268 8786		
- ph:  +61 2 6268 8895



From blindglobe at gmail.com  Wed Oct 12 07:56:02 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Wed, 12 Oct 2005 07:56:02 +0200
Subject: [R] log4j
In-Reply-To: <434C88FA.6070602@pdf.com>
References: <3f87cc6d0510031252w6151bafaiefdef29297a1963f@mail.gmail.com>
	<434C88FA.6070602@pdf.com>
Message-ID: <1abe3fa90510112256i795f6cb3k1ce6fcb32a38749e@mail.gmail.com>

no, there isn't a general logging package.

On 10/12/05, Spencer Graves <spencer.graves at pdf.com> wrote:
>           I just got 145 hits from RSiteSearch("debugger").  Does this help?
>
>           spencer graves
>
> Omar Lakkis wrote:
>
> > Is there a log4j, or similar, package for R?
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
> --
> Spencer Graves, PhD
> Senior Development Engineer
> PDF Solutions, Inc.
> 333 West San Carlos Street Suite 700
> San Jose, CA 95110, USA
>
> spencer.graves at pdf.com
> www.pdf.com <http://www.pdf.com>
> Tel:  408-938-4420
> Fax: 408-280-7915
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>


--
best,
-tony

blindglobe at gmail.com
Muttenz, Switzerland.
"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).



From alex.park1 at ntlworld.com  Wed Oct 12 08:44:53 2005
From: alex.park1 at ntlworld.com (alex.park1@ntlworld.com)
Date: Wed, 12 Oct 2005 7:44:53 +0100
Subject: [R] General note on help list...
Message-ID: <20051012064453.EBMC6564.aamta09-winn.ispmail.ntl.com@smtp.ntlworld.com>

R-Helpers

I am just getting started with R and am learning the basics.

I have 'Introductory Statistics with R' by Dalgaard and decided to join this help forum too.

At present, I am receiving approx. 40 posts per day regarding R queries by various list members. Is there any way to turn that feature off such that I only receive responses to my questions?

Once I learn the basics then I will benefit from reading other members questions...but for now it is more confusing for me than helpful.

I appreciate any guidance...

Regards


Alex

-----------------------------------------
Email sent from www.ntlworld.com
Virus-checked using McAfee(R) Software 
Visit www.ntlworld.com/security for more information



From petr.pikal at precheza.cz  Wed Oct 12 08:48:09 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 12 Oct 2005 08:48:09 +0200
Subject: [R] Problems with plot function
In-Reply-To: <OF63F80873.69B89EC4-ONC1257097.005C401A@aviation-civile.gouv.fr>
Message-ID: <434CCDC9.23440.2FD358@localhost>

Hi

Just a small modification. You has to return also conc.

simulation <- function(k, n){

conc <- seq(0,10,by=0.5)
#choixg <- seq(1, length(conc))
choixg <- rep(0,length(conc))
for (i in 1:length(conc)){
    choixg[i] <- (k + conc[i])^2/((k+conc[i])^n + (k+1)^n)

    }
   return(data.frame(choixg, conc))

}
mydf<-simulation(5,1)

plot(mydf$conc, mydf$choixg, main ="fonction de choix", col= 
"blue", pch=20,
xlab = " concentration", ylab="proba de choisir la gauche")


HTH
Petr

On 11 Oct 2005 at 18:54, KOITA Lassana - STAC/ACE wrote:

To:             	r-help at stat.math.ethz.ch
From:           	"KOITA Lassana - STAC/ACE" <lassana.koita at aviation-civile.gouv.fr>
Date sent:      	Tue, 11 Oct 2005 18:54:18 +0200
Subject:        	[R] Problems with plot function

> 
> 
> 
> 
> Hello  all  R   users,
> My simulation function works correctly, but I have problems with plot
> function. You will find the following code using it. Thank you for
> your help ##################################################"
> 
> simulation <- function(k, n){
> 
> conc <- seq(0,10,by=0.5)
> #choixg <- seq(1, length(conc))
> choixg <- rep(0,length(conc))
> for (i in 1:length(conc)){
>     choixg[i] <- (k + conc[i])^2/((k+conc[i])^n + (k+1)^n)
> 
>     }
>    return(choixg)
> 
> }
> simulation(5,1)
> 
> plot(conc, choixg, main ="fonction de choix", col= "blue", pch=20,
> xlab = " concentration", ylab="proba de choisir la gauche")
> ##########################################################
> 
> Lassana KOITA
> Service Technique de l'Aviation Civile (STAC)
> Direction G??n??rale de l'Aviation Civile (DGAC)
> Tel: 01 49 56 80 60
> Fax: 01 49 56 82 14
> http://www.stac.aviation-civile.gouv.fr
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From fparlamis at mac.com  Wed Oct 12 09:06:27 2005
From: fparlamis at mac.com (Parlamis Franklin)
Date: Tue, 11 Oct 2005 21:06:27 -1000
Subject: [R] bug checking
In-Reply-To: <1129091669.3510.42.camel@localhost.localdomain>
References: <1BA44AD2-08B5-4A7F-8B2A-AF8397DF45AF@mac.com>
	<1129085243.3510.21.camel@localhost.localdomain>
	<3DA00485-7B82-4658-B523-5955734103E8@mac.com>
	<1129091669.3510.42.camel@localhost.localdomain>
Message-ID: <0FB151DB-E7F3-4CE0-A4E0-1D8E1DCA216E@mac.com>

Thanks all for following up.  I'll consider the bug "filed."

I should note for the record that if 'col="red"' is replaced in my  
code by 'col.main="red"' the x axis is still made red.

I'll use the workaround for now (for which thanks).  Even with little  
things like this, plotting from the command line in R is orders  
better than dragging a bunch of frames around an Excel window.

On Oct 11, 2005, at 6:34 PM, Marc Schwartz wrote:

> Thanks for the code and the clarifications, including the PDF file.
>
> Yes, I can replicate the behavior here (R 2.2.0 on FC4) and I am  
> cc:ing
> Kurt Hornik, who ported chron to R and is the chron package  
> maintainer.
>
> It appears that the "culprit" is the argument 'col = "red"', which
> towards the end of plot.times() is used as follows:
>
> ...
>     else if (x.times)
>         axis.times(1, x, simplify = simplify, labels = TRUE,
>             adj = adj, col = col, cex = cex, font = font,
>             las = las, lab = lab, mgp = mgp, tcl = tcl)
> ...
>
> Thus, if the 'x' data is of class 'times', the above code is used and
> the color of the axis line and tick marks are set to "red" as per the
> 'col' argument to axis(), which axis.times() ultimately calls.
>
> This results in the behavior that you are seeing, where both the plot
> symbols/lines and the axis are colored the same.
>
> This does sound like a bug and Kurt can comment better on this.
>
> HTH,
>
> Marc Schwartz
>
>
> On Tue, 2005-10-11 at 18:02 -1000, Parlamis Franklin wrote:
>
>> ## Code was long, so I simplified it by creating vectors from scratch
>> so it would run as is.  Putative "bug" is still evidenced on the x  
>> axis
>>
>> discount.factors.dates <- seq.dates(from="09/30/2005",  
>> to="09/30/2035")
>> rates<-seq(4.4, 5.2, by=0.0025);
>> plot(discount.factors.dates[1:length(rates)], rates,
>>       pch=18, las=1, bty="n",
>>       col="red", col.main="red",
>>       xlab="Date", ylab="Rate",
>>       ylim=c(min(rates)-(max(rates)-min(rates))/10,max(rates)+(max
>> (rates)-min(rates))/10))
>>
>> ## This is the output:
>>
>> ## Hopefully you all see the red x axis.
>>
>> ## I am running R Cocoa GUI 1.1.2 with R 2.1.1 framework on a dual
>> proc 2.7 Ghz Power Mac.  A Quartz device is opened when 'plot' is
>> called.  X11User and X11SDK are installed on t he computer, as well
>> as xCode 2.1 (in case that's relevant).
>>
>>
>> On Oct 11, 2005, at 4:47 PM, Marc Schwartz wrote:
>>
>>
>>> On Tue, 2005-10-11 at 16:07 -1000, Parlamis Franklin wrote:
>>>
>>>
>>>> I have observed the following behavior, wondering if it is a bug
>>>> before I submit a report.
>>>>
>>>> I am using the plot function with call:  plot(X, Y,
>>>> col="red", . . . ) where X is an object that inherits from classes
>>>> 'dates' and 'times' (created with the 'dates' function from package
>>>> 'chron') and y is a numeric vector.  The color red is applied to  
>>>> the
>>>> area from the first to the last tick mark on the x axis (even if I
>>>> don't set col="red" and only set, say col.main="red").
>>>>
>>>> If instead of feeding the function X, I feed it unclass(X) or
>>>> as.vector(X) the red color is not applied to the area between the
>>>> first and last ticks on the x axis.
>>>>
>>>> Is this a bug, or just a consequence of there not being a plot  
>>>> method
>>>> for the class I am trying to feed the function?
>>>>
>>>> Franklin Parlamis
>>>>
>>>>
>>>
>>> As per the Posting Guide, it would be immensely helpful in the  
>>> attempt
>>> to help you, if you would provide the exact code you are using and
>>> some
>>> sample data here, so that we can exactly replicate what you are
>>> experiencing.
>>>
>>> Lacking that, it would be difficult to assist as we can only  
>>> guess. It
>>> does sound like there is an _appropriate_ change in the plot method
>>> behavior as a direct consequence of your modifying the class of the
>>> argument(s), which is of course how methods are dispatched. Thus,  
>>> if I
>>> were to guess, this is not a bug.
>>>
>>> I would however, certainly recommend that you submit an example
>>> here to
>>> confirm the behavior, before you post a bug report, as that would
>>> avoid
>>> a more energetic response.
>>>
>>> Marc Schwartz
>>>
>>>
>>>
>>>
>>
>>
>
>



From Murraypu at aimnsw.com.au  Wed Oct 12 09:11:21 2005
From: Murraypu at aimnsw.com.au (Murray Pung)
Date: Wed, 12 Oct 2005 17:11:21 +1000
Subject: [R] General note on help list...
Message-ID: <3028F4C4647C9043B870276E28C69FD601343695@syd05.aimnsw.com.au>

I believe if you unsubscribe from the list, but send any questions to the address r-help at stat.math.ethz.ch, that should work, assuming those who respond to you question include your email address as well as the mailing list address in their reply (which I think is usually the case).

Murray

-----Original Message-----
From: alex.park1 at ntlworld.com [mailto:alex.park1 at ntlworld.com]
Sent: Wednesday, 12 October 2005 4:45 PM
To: r-help at stat.math.ethz.ch
Subject: [R] General note on help list...


R-Helpers

I am just getting started with R and am learning the basics.

I have 'Introductory Statistics with R' by Dalgaard and decided to join this help forum too.

At present, I am receiving approx. 40 posts per day regarding R queries by various list members. Is there any way to turn that feature off such that I only receive responses to my questions?

Once I learn the basics then I will benefit from reading other members questions...but for now it is more confusing for me than helpful.

I appreciate any guidance...

Regards


Alex

-----------------------------------------
Email sent from www.ntlworld.com
Virus-checked using McAfee(R) Software 
Visit www.ntlworld.com/security for more information

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From tliu at fhcrc.org  Wed Oct 12 09:57:57 2005
From: tliu at fhcrc.org (Ting-Yuan Liu)
Date: Wed, 12 Oct 2005 00:57:57 -0700 (PDT)
Subject: [R] problem in installing a package
In-Reply-To: <20051005221939.92114.qmail@web60211.mail.yahoo.com>
References: <20051005221939.92114.qmail@web60211.mail.yahoo.com>
Message-ID: <Pine.LNX.4.61.0510120053290.26072@jade.fhcrc.org>


Hi Claire,

For the R CMD check error... It seems that you used some special 
characters, such as "_", in your Rd files so that Latex can not handle 
them.  Try to add the escape charatcer "\" before these special 
characters.

HTH,
Ting-Yuan

On Wed, 5 Oct 2005, Claire Lee wrote:

> I'm using R in Windows XP. I created a package myself.
> I've used R CMD check to check it. Everything seems OK
> except the latex. I get the error message:
> * checking bbHist-manual.tex ... ERROR
> LaTeX errors when creating DVI version.
> This typically indicates Rd problems.
> 
> I ignored it because I didn't want to submit it to
> CRAN.
> 
> Then I tried to use R CMD INSTALL to install it. First
> I get: 
> "mv: cannot move `c:/PROGRA~1/R/rw2011/library/bbHist'
> to `c:/PROGRA~1/R/rw2011/library/00LOCK/bbHist
> ': Permission denied" 
> 
> and a bunch of making DLL errors.  Then when I tried a
> second time, I get:
> 
> open(c:/progra~1/r/rw2011/library/bbHist/DESCRIPTION):
> No such file or directory
> 
> I can see a 00LOCK directory is created in the
> c:/PROGRA~1/R/rw2011/library directory. Any idea why
> this is happening?
> 
> Thanks.
> 
> Claire
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From astrzelczak at ps.pl  Wed Oct 12 11:04:49 2005
From: astrzelczak at ps.pl (astrzelczak@ps.pl)
Date: Wed, 12 Oct 2005 11:04:49 +0200
Subject: [R] step.gam and number of tested smooth functions
Message-ID: <1129107889.434cd1b11c59e@www.ps.pl>


Hi,

I'm working with step.gam in gam package. I'm interested both in spline and
lowess functions and when I define all the models that I'm interested in I get
something like that:

> gam.object.ALC<-gam(X143S~ALC,data=dane,family=binomial)
>
step.gam.ALC<-step.gam(gam.object.ALC,scope=list("ALC"=~1+ALC+s(ALC,2)+s(ALC,3)+s(ALC,4)+s(ALC,6)+s(ALC,8)+lo(ALC,degree=1,span=.5)+lo(ALC,degree=2,span=.5)+lo(ALC,degree=1,span=.25)+lo(ALC,degree=2,span=.25)))
Start:  X143S ~ ALC; AIC= 104.0815
Trial:  X143S ~  1; AIC= 111.1054
Trial:  X143S ~  s(ALC, 2); AIC= 103.3325
Step :  X143S ~ s(ALC, 2) ; AIC= 103.3325

Trial:  X143S ~  s(ALC, 3); AIC= 102.9598
Step :  X143S ~ s(ALC, 3) ; AIC= 102.9598

Trial:  X143S ~  s(ALC, 4); AIC= 102.2103
Step :  X143S ~ s(ALC, 4) ; AIC= 102.2103

Trial:  X143S ~  s(ALC, 6); AIC= 102.4548

I have impression that the algorithm stops when the next trial gives higher AIC
without examining further functions. When I deleted some of the spline functions
that were worse than s(ALC,4) I got:

 >
step.gam.ALC<-step.gam(gam.object.ALC,scope=list("ALC"=~1+ALC++s(ALC,4)+lo(ALC,degree=1,span=.5)+lo(ALC,degree=2,span=.5)+lo(ALC,degree=1,span=.25)+lo(ALC,degree=2,span=.25)))
Start:  X143S ~ ALC; AIC= 104.0815
Trial:  X143S ~  1; AIC= 111.1054
Trial:  X143S ~  s(ALC, 4); AIC= 102.2103
Step :  X143S ~ s(ALC, 4) ; AIC= 102.2103

Trial:  X143S ~  lo(ALC, degree = 1, span = 0.5); AIC= 99.8127
Step :  X143S ~ lo(ALC, degree = 1, span = 0.5) ; AIC= 99.8127

Trial:  X143S ~  lo(ALC, degree = 2, span = 0.5); AIC= 100.5275

Lowess turned out to be better in this situation. Is there any way to examine
all the models without stopping when AIC is higher in the next trial? Or maybe
manual handling is the only solution?

thanks for help in advance

Agnieszka Strzelczak



From ripley at stats.ox.ac.uk  Wed Oct 12 11:20:42 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 Oct 2005 10:20:42 +0100 (BST)
Subject: [R] step.gam and number of tested smooth functions
In-Reply-To: <1129107889.434cd1b11c59e@www.ps.pl>
References: <1129107889.434cd1b11c59e@www.ps.pl>
Message-ID: <Pine.LNX.4.61.0510121018520.24329@gannet.stats>

step.gam is a tricky function to use correctly.  You will need to consult 
the original documentation (in Chambers & Hastie ca 1992) or ask the 
package author for help.

BTW, it uses loess not lowess.

On Wed, 12 Oct 2005 astrzelczak at ps.pl wrote:

>
> Hi,
>
> I'm working with step.gam in gam package. I'm interested both in spline and
> lowess functions and when I define all the models that I'm interested in I get
> something like that:
>
>> gam.object.ALC<-gam(X143S~ALC,data=dane,family=binomial)
>>
> step.gam.ALC<-step.gam(gam.object.ALC,scope=list("ALC"=~1+ALC+s(ALC,2)+s(ALC,3)+s(ALC,4)+s(ALC,6)+s(ALC,8)+lo(ALC,degree=1,span=.5)+lo(ALC,degree=2,span=.5)+lo(ALC,degree=1,span=.25)+lo(ALC,degree=2,span=.25)))
> Start:  X143S ~ ALC; AIC= 104.0815
> Trial:  X143S ~  1; AIC= 111.1054
> Trial:  X143S ~  s(ALC, 2); AIC= 103.3325
> Step :  X143S ~ s(ALC, 2) ; AIC= 103.3325
>
> Trial:  X143S ~  s(ALC, 3); AIC= 102.9598
> Step :  X143S ~ s(ALC, 3) ; AIC= 102.9598
>
> Trial:  X143S ~  s(ALC, 4); AIC= 102.2103
> Step :  X143S ~ s(ALC, 4) ; AIC= 102.2103
>
> Trial:  X143S ~  s(ALC, 6); AIC= 102.4548
>
> I have impression that the algorithm stops when the next trial gives higher AIC
> without examining further functions. When I deleted some of the spline functions
> that were worse than s(ALC,4) I got:
>
> >
> step.gam.ALC<-step.gam(gam.object.ALC,scope=list("ALC"=~1+ALC++s(ALC,4)+lo(ALC,degree=1,span=.5)+lo(ALC,degree=2,span=.5)+lo(ALC,degree=1,span=.25)+lo(ALC,degree=2,span=.25)))
> Start:  X143S ~ ALC; AIC= 104.0815
> Trial:  X143S ~  1; AIC= 111.1054
> Trial:  X143S ~  s(ALC, 4); AIC= 102.2103
> Step :  X143S ~ s(ALC, 4) ; AIC= 102.2103
>
> Trial:  X143S ~  lo(ALC, degree = 1, span = 0.5); AIC= 99.8127
> Step :  X143S ~ lo(ALC, degree = 1, span = 0.5) ; AIC= 99.8127
>
> Trial:  X143S ~  lo(ALC, degree = 2, span = 0.5); AIC= 100.5275
>
> Lowess turned out to be better in this situation. Is there any way to examine
> all the models without stopping when AIC is higher in the next trial? Or maybe
> manual handling is the only solution?
>
> thanks for help in advance
>
> Agnieszka Strzelczak
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gmbegnis at yahoo.it  Wed Oct 12 11:55:13 2005
From: gmbegnis at yahoo.it (giacomo moro)
Date: Wed, 12 Oct 2005 11:55:13 +0200 (CEST)
Subject: [R] arima with R
Message-ID: <20051012095513.71091.qmail@web25708.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051012/26e5a84a/attachment.pl

From Camarda at demogr.mpg.de  Wed Oct 12 12:31:49 2005
From: Camarda at demogr.mpg.de (Camarda, Carlo Giovanni)
Date: Wed, 12 Oct 2005 12:31:49 +0200
Subject: [R] Historical England and Wales Shape Files
Message-ID: <8B08A3A1EA7AAC41BE24C750338754E6C0C0B8@HERMES.demogr.mpg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051012/54f40cea/attachment.pl

From HStevens at muohio.edu  Wed Oct 12 12:40:30 2005
From: HStevens at muohio.edu (Martin Henry H. Stevens)
Date: Wed, 12 Oct 2005 06:40:30 -0400
Subject: [R] Under-dispersion - a stats question?
In-Reply-To: <1129093847.14213.4.camel@biol102145.oulu.fi>
References: <E415F473-DCB4-4E3B-B50C-ABDB09C7E20F@MUOhio.edu>
	<434C2BB2.3060108@redcotel.bo>
	<1129093847.14213.4.camel@biol102145.oulu.fi>
Message-ID: <D8D069B7-A656-4F52-88BE-9A010D0C2E2A@muohio.edu>

Hello all:
Thank you for you interest.

This text of this email  is in the attached "R-help.r" file.
The R script is in "R-helpscript.r".
The data set is "wk6trial.csv".
-------------- next part --------------

One of my students has performed a laboratory experiment with petri  
dishes containing hundreds of  species of bacteria, and six species  
each of algae and ciliated protozoans. Our goal was to examine the  
effects of nutrient concentration and dish size on the number of  
species of each group remaining after six weeks.

I attached the data set and some code for the algae analysis.

We had four dish sizes (factor), seven nutrient concentrations  
(continuous), and three replicates of each unique treatment  
combination, for a total n = 84.

Our response variables were (i) the number of bacterial species  
(0-400 species, modeled with quasipoisson), (ii) the proportion of  
algae species (out of six initial species - modeled with binomial)  
and (iii) the proportion of protozoan species (out of six initial  
species - modeled with binomial). For algae and protozoans, we  
modeled the proportion of species rather than the raw number because  
in each case we were constrained by the design to have between 0 and  
6 species. I discussed this with a local statistician, and he thought  
it made sense.

Each of these response variables is the combined result of both  
unknown species' responses to treatments as well as the unknown  
interactions among species. Further, these three responses are  
themselves interdependent to some degree. For instance, the number  
and identity of protozoan species may influence the number of  
bacterial species. Nonetheless, it is common practice in ecology to  
model the number of species of a group (or its logarithm)  with a  
univariate model assuming either a normal or Poisson error  
distribution. I would HAPPILY learn better.

While modeling these groups, I consulted a few texts (Neter et al.  
1996, Venables and Ripley 2002, Dalgaard 2002, Crawley 2002, Fox  
2002) and attempted to follow standard procedures laid out in these  
books.

For the algae and the protozoans, I began with a binomial model,

glm(cbind(AS, 6-AS) ~ Nutrients + I(Nutrients^2) + Size +
             Nutrients:Size + I(Nutrients^2):Size, data=dat,  
family=binomial)

where AS is the number of algae species in a dish. I retained this  
family upon observation that the residual dev. / residual DF was (for  
algae) = 0.19. I minimized the model by hand based on the F tests  
(not the treatment contrast coefficients, after V&R p. 197 - Hauck  
and Donner 1977) and using step() and found that the only significant  
treatment was a linear effect of nutrient concentration. I examined  
the qq plot, the resid ~ fitted plot, and Cook's distances and  
everything looked fine.

When I repeated this with quasibinomial, it estimated the dispersion  
parameter (0.19), I found that both Size and Nutrients were  
significant (no interaction).

So,... my orignal question to the list was, is it appropriate to  
model and fit the error distribution with quasi- functions if  
dispersion seems much less than 1.0?

Now I am unclear how to evaluate under-dispersion (even after  
consulting V&R 2002, p. 208-209).

Upon reading through this, if you made it this far, you may have lots  
of other comments as well, and I truly hope to become better educated  
as a result!

BTW, I modeled the bacteria with a quasipoisson (dispersion = 91!).  
Perhaps a negative binomial would have been better?

Many thanks for your inputs,
Hank Stevens




On Oct 12, 2005, at 1:10 AM, Jari Oksanen wrote:

> On Tue, 2005-10-11 at 17:16 -0400, Kjetil Holuerson wrote:
>
>> Martin Henry H. Stevens wrote:
>>
>>> Hello all:
>>> I frequently have glm models in which the residual variance is much
>>> lower than the residual degrees of freedom (e.g. Res.Dev=30.5,  
>>> Res.DF
>>> = 82). Is it appropriate for me to use a quasipoisson error
>>> distribution and test it with an F distribution? It seems to me that
>>> I could stand to gain a much-reduced standard error if I let the
>>> procedure estimate my dispersion factor (which is what I assume the
>>> quasi- distributions do).
>>>
>>>
>>
>> I did'nt see an answer to this. maybe you could treat as a
>> quasimodel, but first you should ask why there is underdispersion.
>>
>> Underdispersion could arise if you have dependent responses, for
>> instance, competition (say, between plants) could produce
>> underdispersion. Then you would be better off changing to an  
>> appropriate
>> model. maybe you could post more about your experimental setup?
>>
>>
> Some ecologists from Bergen, Norway, suggest using quasipoisson  
> with its
> underdispersed residual error (while I wouldn't do that). However, it
> indeed would be useful to know a bit more about the setup, like the  
> type
> of dependent variable. If the dependent variable happens to be the
> number of species (like it's been in some papers by MHHS), this
> certainly is *not* Poisson nor quasi-Poisson nor in the exponential
> family, although it so often is modelled. I've often seen that species
> richness (number of species -- or in R-speak 'tokens' -- in a
> collection) is underdispersed to Poisson, and for a good reason. Even
> there I'd play safe and use poisson() instead of underdispersed
> quasipoisson().
>
> cheers, jari oksanen
> -- 
> Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
> Ph. +358 8 5531526, cell +358 40 5136529, fax +358 8 5531061
> email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/
>
>

Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"


From 042045003 at fudan.edu.cn  Wed Oct 12 12:40:49 2005
From: 042045003 at fudan.edu.cn (ronggui)
Date: Wed, 12 Oct 2005 18:40:49 +0800
Subject: [R] arima with R
Message-ID: <0IO8001HGT6LPB@mail.fudan.edu.cn>

armaFit in package "fSeries " will give the result in details.
	

======= 2005-10-12 17:55:13 ÄúÔÚÀ´ÐÅÖÐÐ´µÀ£º=======

>Hi,
>I'm using R for some arima models. In the past I used for arima models Rats and Tsp. Using the R arima function, I get only the statistics sigma^2 and log likelihood; with Rats and Tsp it is possible to obtain more statistics, such as R, R square, Durbin Watson, standard error, etc. 
>Is it possible using R to have the statistics mentioned?
>My best regards,
>                                  Giacomo
>
>
>		
>---------------------------------
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

= = = = = = = = = = = = = = = = = = = =
			


 

2005-10-12

------
Deparment of Sociology
Fudan University

My new mail addres is ronggui.huang at gmail.com
Blog:http://sociology.yculblog.com



From br44114 at gmail.com  Wed Oct 12 14:13:17 2005
From: br44114 at gmail.com (bogdan romocea)
Date: Wed, 12 Oct 2005 08:13:17 -0400
Subject: [R] adding 1 month to a date
Message-ID: <8d5a36350510120513u1d32f44dwee638095dd90cd28@mail.gmail.com>

Simple addition and subtraction works as well:
  as.Date("1995/12/01",format="%Y/%m/%d") + 30
If you have datetime values you can use
  strptime("1995-12-01 08:00:00",format="%Y-%m-%d %H:%M:%S") + 30*24*3600
where 30*24*3600 = 30 days expressed in seconds.


> -----Original Message-----
> From: Marc Schwartz [mailto:MSchwartz at mn.rr.com]
> Sent: Tuesday, October 11, 2005 10:16 PM
> To: t c
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] adding 1 month to a date
>
>
> On Tue, 2005-10-11 at 16:26 -0700, t c wrote:
> > Within an R dataset, I have a date field called date_.
> (The dates are
> > in the format YYYY-MM-DD, e.g. 1995-12-01.)
>
> > How can I add or subtract 1 month from this date, to get
> 1996-01-01 or
> > 1995-11-01.
>
> There might be an easier way to do this, but using seq.Date(), you can
> increment or decrement from a Time 0 by months:
>
> Add 1 month:
>
> This takes your Time 0, generates a 2 element sequence (which begins
> with Time 0) and then takes the second element:
>
> > seq(as.Date("1995-12-01"), by = "month", length = 2)[2]
> [1] "1996-01-01"
>
>
>
> Subtract 1 month:
>
> Same as above, but we use 'by = "-1 month"' and take the
> second element:
>
> > seq(as.Date("1995-12-01"), by = "-1 month", length = 2)[2]
> [1] "1995-11-01"
>
>
> See ?as.Date and ?seq.Date for more information. The former
> function is
> used to convert from a character vector to a Date class object. Note
> that in your case, the date format is consistent with the default. Pay
> attention to the 'format' argument in as.Date() if your dates
> should be
> in other formats.
>
> HTH,
>
> Marc Schwartz
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Wed Oct 12 14:23:10 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 Oct 2005 13:23:10 +0100 (BST)
Subject: [R] adding 1 month to a date
In-Reply-To: <8d5a36350510120513u1d32f44dwee638095dd90cd28@mail.gmail.com>
References: <8d5a36350510120513u1d32f44dwee638095dd90cd28@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0510121320450.9181@gannet.stats>

On Wed, 12 Oct 2005, bogdan romocea wrote:

> Simple addition and subtraction works as well:
>  as.Date("1995/12/01",format="%Y/%m/%d") + 30
> If you have datetime values you can use
>  strptime("1995-12-01 08:00:00",format="%Y-%m-%d %H:%M:%S") + 30*24*3600
> where 30*24*3600 = 30 days expressed in seconds.

Sorry, not in general, as a month is not generally of 30 days (including 
in your example).

seq.Date is a good way to do this.

>
>
>> -----Original Message-----
>> From: Marc Schwartz [mailto:MSchwartz at mn.rr.com]
>> Sent: Tuesday, October 11, 2005 10:16 PM
>> To: t c
>> Cc: r-help at stat.math.ethz.ch
>> Subject: Re: [R] adding 1 month to a date
>>
>>
>> On Tue, 2005-10-11 at 16:26 -0700, t c wrote:
>>> Within an R dataset, I have a date field called date_.
>> (The dates are
>>> in the format YYYY-MM-DD, e.g. 1995-12-01.)
>>
>>> How can I add or subtract 1 month from this date, to get
>> 1996-01-01 or
>>> 1995-11-01.
>>
>> There might be an easier way to do this, but using seq.Date(), you can
>> increment or decrement from a Time 0 by months:
>>
>> Add 1 month:
>>
>> This takes your Time 0, generates a 2 element sequence (which begins
>> with Time 0) and then takes the second element:
>>
>>> seq(as.Date("1995-12-01"), by = "month", length = 2)[2]
>> [1] "1996-01-01"
>>
>>
>>
>> Subtract 1 month:
>>
>> Same as above, but we use 'by = "-1 month"' and take the
>> second element:
>>
>>> seq(as.Date("1995-12-01"), by = "-1 month", length = 2)[2]
>> [1] "1995-11-01"
>>
>>
>> See ?as.Date and ?seq.Date for more information. The former
>> function is
>> used to convert from a character vector to a Date class object. Note
>> that in your case, the date format is consistent with the default. Pay
>> attention to the 'format' argument in as.Date() if your dates
>> should be
>> in other formats.
>>
>> HTH,
>>
>> Marc Schwartz
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From MSchwartz at mn.rr.com  Wed Oct 12 14:31:03 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Wed, 12 Oct 2005 07:31:03 -0500
Subject: [R] bug checking
In-Reply-To: <0FB151DB-E7F3-4CE0-A4E0-1D8E1DCA216E@mac.com>
References: <1BA44AD2-08B5-4A7F-8B2A-AF8397DF45AF@mac.com>
	<1129085243.3510.21.camel@localhost.localdomain>
	<3DA00485-7B82-4658-B523-5955734103E8@mac.com>
	<1129091669.3510.42.camel@localhost.localdomain>
	<0FB151DB-E7F3-4CE0-A4E0-1D8E1DCA216E@mac.com>
Message-ID: <1129120263.3510.66.camel@localhost.localdomain>

Three additional comments:

1. The same phenomena occurs on the y axis if the x and y values are
reversed.

2. I neglected to mention this last night (my time), but given that
"chron" is not part of the base R distribution, the proper procedure for
actually filing a bug against the package would be to contact the
author/maintainer (Kurt) and not to file a bug in the main R bug
tracking system.

3. The problem with 'col.main' is I believe a result of this argument
being passed as part of the "..." arguments to plot.times(). Hence you
end up with partial matching of the argument here, so "col.main" is
operated upon in the same fashion as "col".

HTH,

Marc Schwartz


On Tue, 2005-10-11 at 21:06 -1000, Parlamis Franklin wrote:
> Thanks all for following up.  I'll consider the bug "filed."
> 
> I should note for the record that if 'col="red"' is replaced in my  
> code by 'col.main="red"' the x axis is still made red.
> 
> I'll use the workaround for now (for which thanks).  Even with little  
> things like this, plotting from the command line in R is orders  
> better than dragging a bunch of frames around an Excel window.
> 
> On Oct 11, 2005, at 6:34 PM, Marc Schwartz wrote:
> 
> > Thanks for the code and the clarifications, including the PDF file.
> >
> > Yes, I can replicate the behavior here (R 2.2.0 on FC4) and I am  
> > cc:ing
> > Kurt Hornik, who ported chron to R and is the chron package  
> > maintainer.
> >
> > It appears that the "culprit" is the argument 'col = "red"', which
> > towards the end of plot.times() is used as follows:
> >
> > ...
> >     else if (x.times)
> >         axis.times(1, x, simplify = simplify, labels = TRUE,
> >             adj = adj, col = col, cex = cex, font = font,
> >             las = las, lab = lab, mgp = mgp, tcl = tcl)
> > ...
> >
> > Thus, if the 'x' data is of class 'times', the above code is used and
> > the color of the axis line and tick marks are set to "red" as per the
> > 'col' argument to axis(), which axis.times() ultimately calls.
> >
> > This results in the behavior that you are seeing, where both the plot
> > symbols/lines and the axis are colored the same.
> >
> > This does sound like a bug and Kurt can comment better on this.
> >
> > HTH,
> >
> > Marc Schwartz
> >
> >
> > On Tue, 2005-10-11 at 18:02 -1000, Parlamis Franklin wrote:
> >
> >> ## Code was long, so I simplified it by creating vectors from scratch
> >> so it would run as is.  Putative "bug" is still evidenced on the x  
> >> axis
> >>
> >> discount.factors.dates <- seq.dates(from="09/30/2005",  
> >> to="09/30/2035")
> >> rates<-seq(4.4, 5.2, by=0.0025);
> >> plot(discount.factors.dates[1:length(rates)], rates,
> >>       pch=18, las=1, bty="n",
> >>       col="red", col.main="red",
> >>       xlab="Date", ylab="Rate",
> >>       ylim=c(min(rates)-(max(rates)-min(rates))/10,max(rates)+(max
> >> (rates)-min(rates))/10))
> >>
> >> ## This is the output:
> >>
> >> ## Hopefully you all see the red x axis.
> >>
> >> ## I am running R Cocoa GUI 1.1.2 with R 2.1.1 framework on a dual
> >> proc 2.7 Ghz Power Mac.  A Quartz device is opened when 'plot' is
> >> called.  X11User and X11SDK are installed on t he computer, as well
> >> as xCode 2.1 (in case that's relevant).
> >>
> >>
> >> On Oct 11, 2005, at 4:47 PM, Marc Schwartz wrote:
> >>
> >>
> >>> On Tue, 2005-10-11 at 16:07 -1000, Parlamis Franklin wrote:
> >>>
> >>>
> >>>> I have observed the following behavior, wondering if it is a bug
> >>>> before I submit a report.
> >>>>
> >>>> I am using the plot function with call:  plot(X, Y,
> >>>> col="red", . . . ) where X is an object that inherits from classes
> >>>> 'dates' and 'times' (created with the 'dates' function from package
> >>>> 'chron') and y is a numeric vector.  The color red is applied to  
> >>>> the
> >>>> area from the first to the last tick mark on the x axis (even if I
> >>>> don't set col="red" and only set, say col.main="red").
> >>>>
> >>>> If instead of feeding the function X, I feed it unclass(X) or
> >>>> as.vector(X) the red color is not applied to the area between the
> >>>> first and last ticks on the x axis.
> >>>>
> >>>> Is this a bug, or just a consequence of there not being a plot  
> >>>> method
> >>>> for the class I am trying to feed the function?
> >>>>
> >>>> Franklin Parlamis
> >>>>
> >>>>
> >>>
> >>> As per the Posting Guide, it would be immensely helpful in the  
> >>> attempt
> >>> to help you, if you would provide the exact code you are using and
> >>> some
> >>> sample data here, so that we can exactly replicate what you are
> >>> experiencing.
> >>>
> >>> Lacking that, it would be difficult to assist as we can only  
> >>> guess. It
> >>> does sound like there is an _appropriate_ change in the plot method
> >>> behavior as a direct consequence of your modifying the class of the
> >>> argument(s), which is of course how methods are dispatched. Thus,  
> >>> if I
> >>> were to guess, this is not a bug.
> >>>
> >>> I would however, certainly recommend that you submit an example
> >>> here to
> >>> confirm the behavior, before you post a bug report, as that would
> >>> avoid
> >>> a more energetic response.
> >>>
> >>> Marc Schwartz
> >>>
> >>>
> >>>
> >>>
> >>
> >>
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Jan.Conrad at cern.ch  Wed Oct 12 14:31:53 2005
From: Jan.Conrad at cern.ch (Jan Conrad)
Date: Wed, 12 Oct 2005 14:31:53 +0200
Subject: [R] Newbie problem with read.table
Message-ID: <F90815CCA365774CB9D111C18A6917DF46BB3E@cernxchg17.cern.ch>

Hi R,
 I have a seemingly simple problem. I have a table in following format
(tab seperated)

   Njets NBjets	NElec	  NMuon   Meff	HT	  HT3j	HE	  Aplan
Plan	       
1  4     3	 	2       0       366.278 253.642 87.7473   1385
0.0124566   0.376712       
2  3     1      	1       0       235.19  157.688 18.2852
574.253 0.00064187  0.00528814 

I read in with:

> ttbar<-read.table("test2.dat",header=TRUE)


> ttbar
  Njets NBjets NElec NMuon    Meff      HT    HT3j       HE      Aplan
1     4      3     2     0 366.278 253.642 87.7473 1385.000 0.01245660
2     3      1     1     0 235.190 157.688 18.2852  574.253 0.00064187
        Plan
1 0.37671200
2 0.00528814,

 i.e.. the table is split after 9 variables. How come ?

Thanks,
Jan



From MSchwartz at mn.rr.com  Wed Oct 12 14:37:49 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Wed, 12 Oct 2005 07:37:49 -0500
Subject: [R] adding 1 month to a date
In-Reply-To: <Pine.LNX.4.61.0510121320450.9181@gannet.stats>
References: <8d5a36350510120513u1d32f44dwee638095dd90cd28@mail.gmail.com>
	<Pine.LNX.4.61.0510121320450.9181@gannet.stats>
Message-ID: <1129120670.3510.73.camel@localhost.localdomain>

Thanks to Prof. Ripley for pointing this out.

One of the approaches that I had considered here was to set up a vector
of the number of days in each month (adjusting of course for leap
years), and use "day arithmetic" to add/subtract the appropriate number
of days.

However, it was easier to use seq.Date() and to further consider putting
a wrapper around it to make it yet even easier to use.

Marc

On Wed, 2005-10-12 at 13:23 +0100, Prof Brian Ripley wrote:
> On Wed, 12 Oct 2005, bogdan romocea wrote:
> 
> > Simple addition and subtraction works as well:
> >  as.Date("1995/12/01",format="%Y/%m/%d") + 30
> > If you have datetime values you can use
> >  strptime("1995-12-01 08:00:00",format="%Y-%m-%d %H:%M:%S") + 30*24*3600
> > where 30*24*3600 = 30 days expressed in seconds.
> 
> Sorry, not in general, as a month is not generally of 30 days (including 
> in your example).
> 
> seq.Date is a good way to do this.
> 
> >
> >
> >> -----Original Message-----
> >> From: Marc Schwartz [mailto:MSchwartz at mn.rr.com]
> >> Sent: Tuesday, October 11, 2005 10:16 PM
> >> To: t c
> >> Cc: r-help at stat.math.ethz.ch
> >> Subject: Re: [R] adding 1 month to a date
> >>
> >>
> >> On Tue, 2005-10-11 at 16:26 -0700, t c wrote:
> >>> Within an R dataset, I have a date field called date_.
> >> (The dates are
> >>> in the format YYYY-MM-DD, e.g. 1995-12-01.)
> >>
> >>> How can I add or subtract 1 month from this date, to get
> >> 1996-01-01 or
> >>> 1995-11-01.
> >>
> >> There might be an easier way to do this, but using seq.Date(), you can
> >> increment or decrement from a Time 0 by months:
> >>
> >> Add 1 month:
> >>
> >> This takes your Time 0, generates a 2 element sequence (which begins
> >> with Time 0) and then takes the second element:
> >>
> >>> seq(as.Date("1995-12-01"), by = "month", length = 2)[2]
> >> [1] "1996-01-01"
> >>
> >>
> >>
> >> Subtract 1 month:
> >>
> >> Same as above, but we use 'by = "-1 month"' and take the
> >> second element:
> >>
> >>> seq(as.Date("1995-12-01"), by = "-1 month", length = 2)[2]
> >> [1] "1995-11-01"
> >>
> >>
> >> See ?as.Date and ?seq.Date for more information. The former
> >> function is
> >> used to convert from a character vector to a Date class object. Note
> >> that in your case, the date format is consistent with the default. Pay
> >> attention to the 'format' argument in as.Date() if your dates
> >> should be
> >> in other formats.
> >>
> >> HTH,
> >>
> >> Marc Schwartz



From JAROSLAW.W.TUSZYNSKI at saic.com  Wed Oct 12 14:47:52 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Wed, 12 Oct 2005 08:47:52 -0400
Subject: [R] Questions about readBin function (Was: dec2bin?)
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD50419B045@us-arlington-0668.mail.saic.com>

Hi,

The latest version of R had some changes to functions "readbin() and
writeBin() [which] now support raw vectors as well as filenames and
connections.". As a result I am working on retiring "raw2bin" and "bin2raw"
functions from "caTools" package which do exactly the same. Thanks to Prof.
Ripley for bringing this change to my attention.

Which brings me to my question: how to use readBin function to read the
whole file or vector "con" and not just requested number of elements (n)
from it? In other words what to do if I do not know what to set argument "n"
to ("The (maximal) number of records to be read"), and want to read all
records?  

So far the simplest solution I found is to measure vector length (or file
size) of "con" and set n to length()%/%size. Which gets quite messy if
"size" is not provided and have to be deduced from "what" (see code below).
Am I missing something? Is there an easier way to read the whole file or
vector? Shouldn't that be the default?

readBin(con, what, n = 1, size = NA, signed = TRUE, endian =
.Platform$endian)

bin2raw = function(x, ...) writeBin(x, raw(), ...) # old bin2raw can be
easily written using curent writeBin

raw2bin = function(r, what, size=NA, ...)
{
  TypeList = c("logical", "integer", "double", "complex", "character",
"raw", 
               "numeric", "int")
  if (!is.character(what) || length(what) != 1 || !(what %in% TypeList)) 
    what <- typeof(what)
  if (!is.vector(r) || mode(r) == "list") 
    stop("raw2bin: 'r' has to be vector of type 'raw'")
  if (what=="raw") return(r)
  if (!is.na(size)) nBits=size 
  else nBits = switch(match(typeof(x), TypeList), 4, 4, 8, 16, 2, 1, 8, 4) 
  n = length(r)
  if (n%%nBits) 
    stop("raw2bin: number of elements in 'r' is not multiple of 'size'")
  x = readBin(r, what, n = n%/%nBits, size=size, ...)
  return (x)
}

 Jarek 
====================================================\==== 
 Jarek Tuszynski, PhD.                           o / \ 
 Science Applications International Corporation  <\__,|  
 (703) 676-4192                                   ">  \ 
 Jaroslaw.W.Tuszynski at saic.com                     `   \



From MSchwartz at mn.rr.com  Wed Oct 12 14:48:53 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Wed, 12 Oct 2005 07:48:53 -0500
Subject: [R] Newbie problem with read.table
In-Reply-To: <F90815CCA365774CB9D111C18A6917DF46BB3E@cernxchg17.cern.ch>
References: <F90815CCA365774CB9D111C18A6917DF46BB3E@cernxchg17.cern.ch>
Message-ID: <1129121334.3510.83.camel@localhost.localdomain>

On Wed, 2005-10-12 at 14:31 +0200, Jan Conrad wrote:
> Hi R,
>  I have a seemingly simple problem. I have a table in following format
> (tab seperated)
> 
>    Njets NBjets	NElec	  NMuon   Meff	HT	  HT3j	HE	  Aplan
> Plan	       
> 1  4     3	 	2       0       366.278 253.642 87.7473   1385
> 0.0124566   0.376712       
> 2  3     1      	1       0       235.19  157.688 18.2852
> 574.253 0.00064187  0.00528814 
> 
> I read in with:
> 
> > ttbar<-read.table("test2.dat",header=TRUE)
> 
> 
> > ttbar
>   Njets NBjets NElec NMuon    Meff      HT    HT3j       HE      Aplan
> 1     4      3     2     0 366.278 253.642 87.7473 1385.000 0.01245660
> 2     3      1     1     0 235.190 157.688 18.2852  574.253 0.00064187
>         Plan
> 1 0.37671200
> 2 0.00528814,
> 
>  i.e.. the table is split after 9 variables. How come ?
> 
> Thanks,
> Jan

As per ?read.table, the default delimiter is 'sep = ""', which is any
"whitespace".

Hence, if your file is tab delimited, you need to modify your call to:

  ttbar <- read.table("test2.dat", header = TRUE, sep = "\t")

HTH,

Marc Schwartz



From Roger.Bivand at nhh.no  Wed Oct 12 14:56:03 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 12 Oct 2005 14:56:03 +0200 (CEST)
Subject: [R] Newbie problem with read.table
In-Reply-To: <F90815CCA365774CB9D111C18A6917DF46BB3E@cernxchg17.cern.ch>
Message-ID: <Pine.LNX.4.44.0510121447120.20018-100000@reclus.nhh.no>

On Wed, 12 Oct 2005, Jan Conrad wrote:

> Hi R,
>  I have a seemingly simple problem. I have a table in following format
> (tab seperated)
> 
>    Njets NBjets	NElec	  NMuon   Meff	HT	  HT3j	HE	  Aplan
> Plan	       
> 1  4     3	 	2       0       366.278 253.642 87.7473   1385
> 0.0124566   0.376712       
> 2  3     1      	1       0       235.19  157.688 18.2852
> 574.253 0.00064187  0.00528814 
> 
> I read in with:
> 
> > ttbar<-read.table("test2.dat",header=TRUE)
> 
> 
> > ttbar
>   Njets NBjets NElec NMuon    Meff      HT    HT3j       HE      Aplan
> 1     4      3     2     0 366.278 253.642 87.7473 1385.000 0.01245660
> 2     3      1     1     0 235.190 157.688 18.2852  574.253 0.00064187
>         Plan
> 1 0.37671200
> 2 0.00528814,
> 
>  i.e.. the table is split after 9 variables. How come ?

> options("width")
$width
[1] 80

says what the width of your console is. Columns beyond this get wrapped 
gently (not each row by itself) - it can be set different values if you 
choose - try:

ow <- options("width")
options(width=40)
options("width")
ttbar
options(ow)
options("width")

So this is just the print function for data.frame objects doing its unsung
job. A very useful function for looking at things when they don't seem to
be what you think is str(), which concisely says what the structure of an
object is, so str(ttbar)  should tell you that it is a data frame of 10
variables and 2 observations.

> 
> Thanks,
> Jan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From levin001 at 123mail.cl  Wed Oct 12 14:56:23 2005
From: levin001 at 123mail.cl (Peyuco Porras Porras .)
Date: Wed, 12 Oct 2005 09:56:23 -0300
Subject: [R] Model parameterization / Factor Levels
Message-ID: <48d940948d6cfd.48d6cfd48d9409@123mail.cl>

Dear R users; 

I'm looking for some hint about how to deal with the following situation: 

Response = Y 
Factor A = levels: 0, 1 
Factor B = levels: 0, 1 
Factor C = levels: 1,2,3,4 

Model: Logistic 3-parms. 
where th1~1+A+C, th2~1+C; th3~1 

For 'simplicity' (for me) I'm using the SAS contrast parameterization. 

The output looks like 

Beta p-value 
th1.(Intercept) 550 <0.000 
th1.A1 -15 <0.000 
th1.B1 5 <0.032 
th1.C1 -12 <0.001 
th1.C2 -5 0.022 
th1.C3 -3 0.222 
th2.(Intercept) ...... 

......etc 

if we look at the results, we may conclude that level 3 for Factor C is not 
statiscally significant. The question is: How can I remove this level of this factor 
from the analysis? Let's say that the final results looks like 

Model: Logistic 3-parms. 
where th1~1+A+C, th2~1+C; th3~1, but C with levels 1,2 and 4 only 

Beta p-value 
th1.(Intercept) 560 <0.000 
th1.A1 -15 <0.000 
th1.B1 5 <0.032 
th1.C1 -15 <0.001 
th1.C2 -8 0.031 
th2.(Intercept) ...... 

......etc 


I tried replacing Factor C by 4 different columns, say FACTORC_1, FACTOR_C2, 
FACTOR_C3, and FACTOR_C4 each one of them with 0 or 1, and the model I tried was 

f1<-nlme(Y~SSlogis(X,th1,th2,th3)|Subject,fixed=list(th1~A+B+FACTORC_1+FACTOR_C2, etc 

but, as I expected, the model can't be solved 

I will appreciate any help



From rpeng at jhsph.edu  Wed Oct 12 14:56:49 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 12 Oct 2005 08:56:49 -0400
Subject: [R] Questions about readBin function (Was: dec2bin?)
In-Reply-To: <CA0BCF3BED56294AB91E3AD74B849FD50419B045@us-arlington-0668.mail.saic.com>
References: <CA0BCF3BED56294AB91E3AD74B849FD50419B045@us-arlington-0668.mail.saic.com>
Message-ID: <434D0811.5040506@jhsph.edu>

I think you can use 'seek()' here, but it may not be completely reliable on all 
platforms.

-roger

Tuszynski, Jaroslaw W. wrote:
> Hi,
> 
> The latest version of R had some changes to functions "readbin() and
> writeBin() [which] now support raw vectors as well as filenames and
> connections.". As a result I am working on retiring "raw2bin" and "bin2raw"
> functions from "caTools" package which do exactly the same. Thanks to Prof.
> Ripley for bringing this change to my attention.
> 
> Which brings me to my question: how to use readBin function to read the
> whole file or vector "con" and not just requested number of elements (n)
> from it? In other words what to do if I do not know what to set argument "n"
> to ("The (maximal) number of records to be read"), and want to read all
> records?  
> 
> So far the simplest solution I found is to measure vector length (or file
> size) of "con" and set n to length()%/%size. Which gets quite messy if
> "size" is not provided and have to be deduced from "what" (see code below).
> Am I missing something? Is there an easier way to read the whole file or
> vector? Shouldn't that be the default?
> 
> readBin(con, what, n = 1, size = NA, signed = TRUE, endian =
> .Platform$endian)
> 
> bin2raw = function(x, ...) writeBin(x, raw(), ...) # old bin2raw can be
> easily written using curent writeBin
> 
> raw2bin = function(r, what, size=NA, ...)
> {
>   TypeList = c("logical", "integer", "double", "complex", "character",
> "raw", 
>                "numeric", "int")
>   if (!is.character(what) || length(what) != 1 || !(what %in% TypeList)) 
>     what <- typeof(what)
>   if (!is.vector(r) || mode(r) == "list") 
>     stop("raw2bin: 'r' has to be vector of type 'raw'")
>   if (what=="raw") return(r)
>   if (!is.na(size)) nBits=size 
>   else nBits = switch(match(typeof(x), TypeList), 4, 4, 8, 16, 2, 1, 8, 4) 
>   n = length(r)
>   if (n%%nBits) 
>     stop("raw2bin: number of elements in 'r' is not multiple of 'size'")
>   x = readBin(r, what, n = n%/%nBits, size=size, ...)
>   return (x)
> }
> 
>  Jarek 
> ====================================================\==== 
>  Jarek Tuszynski, PhD.                           o / \ 
>  Science Applications International Corporation  <\__,|  
>  (703) 676-4192                                   ">  \ 
>  Jaroslaw.W.Tuszynski at saic.com                     `   \
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/



From JAROSLAW.W.TUSZYNSKI at saic.com  Wed Oct 12 15:02:55 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Wed, 12 Oct 2005 09:02:55 -0400
Subject: [R] R data import
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD50419B07F@us-arlington-0668.mail.saic.com>

A few suggestions:
- read.fwf function sounds like what you need, but I have never used it so I
am not sure
- use readLines and manually extract needed positions and convert them to
numbers 

 Jarek 
====================================================\==== 
 Jarek Tuszynski, PhD.                           o / \ 
 Science Applications International Corporation  <\__,|  
 (703) 676-4192                                   ">  \ 
 Jaroslaw.W.Tuszynski at saic.com                     `   \ 



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] 
Sent: Tuesday, October 11, 2005 7:52 PM
To: r-help at stat.math.ethz.ch
Subject: [R] R data import

Hello,

I hope all is well. I've gone through and searched just about all the
manuals, faqs, contribs available on the data import/export process and have
not found any answer to a specific question. Hopefully, I will be able to
fall back upon the valuable expertise in mailing list. Here goes:

How can I import SPECIFIC columns of data in a fixed width file? E.g. I have
a fwf with 40 variables ranging from 1 to 10 characters and at any given
time, need only a few to analyze, like so:
 <age: 2 char ><sex: 1 char><morning: 1 char><location: 3 
char>......<family: 9 char><tagged: date>.......<weight at capture: 4 
char><length at capture: 7 char>etc.
which looks something like:
02M1LOS...xxcanidae011289.....10001291412


In essence I am looking for functionality similar to the SAS
pointer/informat method. I would appreciate any help anyone would be able to
give!

Thanks so much for your help.

best,
Ratnendra Sharma
U Minn

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From Roger.Bivand at nhh.no  Wed Oct 12 15:07:24 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 12 Oct 2005 15:07:24 +0200 (CEST)
Subject: [R] Historical England and Wales Shape Files
In-Reply-To: <8B08A3A1EA7AAC41BE24C750338754E6C0C0B8@HERMES.demogr.mpg.de>
Message-ID: <Pine.LNX.4.44.0510121457550.20018-100000@reclus.nhh.no>

On Wed, 12 Oct 2005, Camarda, Carlo Giovanni wrote:

> Dear R-user,
> I would like to apply spatial statistics on some historical data, in
> particular from 1850 to 1900 by registration district of England and
> Wales.
> I have searched in the R-archive, but unsuccessfully.
> Do you know whether R contains those shape files? Or where would be
> possible to download and use in R?

None of the contributed packages to R contain such shapefiles. I'm afraid 
you have to find them first yourself. From:

http://edina.ac.uk/ukborders/description/data_by_country.shtml

boundary data appear to be available for 1871, 1881, and 1911 for these
units, if you have permission to use that service.



> Thanks in advance,
> Carlo Giovanni Camarda
> 
> 
> +++++
> This mail has been sent through the MPI for Demographic Rese...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From MSchwartz at mn.rr.com  Wed Oct 12 15:13:54 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Wed, 12 Oct 2005 08:13:54 -0500
Subject: [R] Newbie problem with read.table
In-Reply-To: <Pine.LNX.4.44.0510121447120.20018-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0510121447120.20018-100000@reclus.nhh.no>
Message-ID: <1129122834.3510.94.camel@localhost.localdomain>

On Wed, 2005-10-12 at 14:56 +0200, Roger Bivand wrote:
> On Wed, 12 Oct 2005, Jan Conrad wrote:
> 
> > Hi R,
> >  I have a seemingly simple problem. I have a table in following format
> > (tab seperated)
> > 
> >    Njets NBjets	NElec	  NMuon   Meff	HT	  HT3j	HE	  Aplan
> > Plan	       
> > 1  4     3	 	2       0       366.278 253.642 87.7473   1385
> > 0.0124566   0.376712       
> > 2  3     1      	1       0       235.19  157.688 18.2852
> > 574.253 0.00064187  0.00528814 
> > 
> > I read in with:
> > 
> > > ttbar<-read.table("test2.dat",header=TRUE)
> > 
> > 
> > > ttbar
> >   Njets NBjets NElec NMuon    Meff      HT    HT3j       HE      Aplan
> > 1     4      3     2     0 366.278 253.642 87.7473 1385.000 0.01245660
> > 2     3      1     1     0 235.190 157.688 18.2852  574.253 0.00064187
> >         Plan
> > 1 0.37671200
> > 2 0.00528814,
> > 
> >  i.e.. the table is split after 9 variables. How come ?
> 
> > options("width")
> $width
> [1] 80
> 
> says what the width of your console is. Columns beyond this get wrapped 
> gently (not each row by itself) - it can be set different values if you 
> choose - try:
> 
> ow <- options("width")
> options(width=40)
> options("width")
> ttbar
> options(ow)
> options("width")
> 
> So this is just the print function for data.frame objects doing its unsung
> job. A very useful function for looking at things when they don't seem to
> be what you think is str(), which concisely says what the structure of an
> object is, so str(ttbar)  should tell you that it is a data frame of 10
> variables and 2 observations.

Thanks to Roger for this clarification. I took the splitting of the
variables to be a consequence of the delimiter and not just a benign
consequence of the printed output (at least I presume this is the proper
interpretation of Jan's problem.)

The tab character is of course included in "whitespace"....using "\t"
explicitly would be helpful if there is embedded whitespace (other than
a tab) within a field.

Marc
<Off to get another cup of coffee....>



From Jan.Conrad at cern.ch  Wed Oct 12 15:16:06 2005
From: Jan.Conrad at cern.ch (Jan Conrad)
Date: Wed, 12 Oct 2005 15:16:06 +0200
Subject: [R] Newbie problem with read.table
Message-ID: <F90815CCA365774CB9D111C18A6917DF46BB42@cernxchg17.cern.ch>

Thank you all for your answers. Yes, indeed it was only a printing
problem (in fact I had tried
the \t option before without sucess).

My first interaction with R (and the R help), I must say I am impressed.


Best,

Jan

-----Original Message-----
From: Marc Schwartz [mailto:MSchwartz at mn.rr.com] 
Sent: Wednesday, October 12, 2005 3:14 PM
To: Roger.Bivand at nhh.no
Cc: Jan Conrad; r-help at stat.math.ethz.ch
Subject: Re: [R] Newbie problem with read.table


On Wed, 2005-10-12 at 14:56 +0200, Roger Bivand wrote:
> On Wed, 12 Oct 2005, Jan Conrad wrote:
> 
> > Hi R,
> >  I have a seemingly simple problem. I have a table in following 
> > format (tab seperated)
> > 
> >    Njets NBjets	NElec	  NMuon   Meff	HT	  HT3j	HE
Aplan
> > Plan	       
> > 1  4     3	 	2       0       366.278 253.642 87.7473   1385
> > 0.0124566   0.376712       
> > 2  3     1      	1       0       235.19  157.688 18.2852
> > 574.253 0.00064187  0.00528814
> > 
> > I read in with:
> > 
> > > ttbar<-read.table("test2.dat",header=TRUE)
> > 
> > 
> > > ttbar
> >   Njets NBjets NElec NMuon    Meff      HT    HT3j       HE
Aplan
> > 1     4      3     2     0 366.278 253.642 87.7473 1385.000
0.01245660
> > 2     3      1     1     0 235.190 157.688 18.2852  574.253
0.00064187
> >         Plan
> > 1 0.37671200
> > 2 0.00528814,
> > 
> >  i.e.. the table is split after 9 variables. How come ?
> 
> > options("width")
> $width
> [1] 80
> 
> says what the width of your console is. Columns beyond this get 
> wrapped
> gently (not each row by itself) - it can be set different values if
you 
> choose - try:
> 
> ow <- options("width")
> options(width=40)
> options("width")
> ttbar
> options(ow)
> options("width")
> 
> So this is just the print function for data.frame objects doing its 
> unsung job. A very useful function for looking at things when they 
> don't seem to be what you think is str(), which concisely says what 
> the structure of an object is, so str(ttbar)  should tell you that it 
> is a data frame of 10 variables and 2 observations.

Thanks to Roger for this clarification. I took the splitting of the
variables to be a consequence of the delimiter and not just a benign
consequence of the printed output (at least I presume this is the proper
interpretation of Jan's problem.)

The tab character is of course included in "whitespace"....using "\t"
explicitly would be helpful if there is embedded whitespace (other than
a tab) within a field.

Marc
<Off to get another cup of coffee....>



From charles.dupont at vanderbilt.edu  Wed Oct 12 15:33:57 2005
From: charles.dupont at vanderbilt.edu (Charles Dupont)
Date: Wed, 12 Oct 2005 08:33:57 -0500
Subject: [R] Hmisc latex function
In-Reply-To: <1129049947.4233.66.camel@localhost.localdomain>
References: <1129039280.3048.7.camel@localhost.localdomain>
	<1129049947.4233.66.camel@localhost.localdomain>
Message-ID: <434D10C5.6080601@vanderbilt.edu>

Marc Schwartz (via MN) wrote:
> On Tue, 2005-10-11 at 10:01 -0400, Rick Bilonick wrote:
> 
>>I'm using R 2.2.0 on an up-to-date version of Fedora Core 4 with the
>>latest version of Hmisc. When I run an example from the latex function I
>>get the following:
>>
>>
>>>x <- matrix(1:6, nrow=2, dimnames=list(c('a','b'),c('c','d','enLine
>>
>>2')))
>>
>>>x
>>
>>  c d enLine 2
>>a 1 3        5
>>b 2 4        6
>>
>>>latex(x)   # creates x.tex in working directory
>>
>>sh: line 0: cd: â€œ/tmp/Rtmpl10983â€: No such file or directory
>>This is pdfeTeX, Version 3.141592-1.21a-2.2 (Web2C 7.5.4)
>>entering extended mode
>>! I can't find file `â€œ/tmp/Rtmpl10983/file643c9869â€'.
>><*> â€œ/tmp/Rtmpl10983/file643c9869â€
>>
>>Please type another input file name: q
>>(/usr/share/texmf/tex/latex/tools/q.tex
>>LaTeX2e <2003/12/01>
>>Babel <v3.8d> and hyphenation patterns for american, french, german,
>>ngerman, b
>>ahasa, basque, bulgarian, catalan, croatian, czech, danish, dutch,
>>esperanto, e
>>stonian, finnish, greek, icelandic, irish, italian, latin, magyar,
>>norsk, polis
>>h, portuges, romanian, russian, serbian, slovak, slovene, spanish,
>>swedish, tur
>>kish, ukrainian, nohyphenation, loaded.
>>File ignored
>>xdvi-motif.bin: Fatal error: /tmp/Rtmpl10983/file643c9869.dvi: No such
>>file.
>>
>>
>>How can I fix this?
>>
>>Rick B.
> 
> 
> I get the same results, also on FC4 with R 2.2.0.
> 
> I am cc:ing Frank here for his input, but a quick review of the code and
> created files suggests that there may be conflict between the locations
> of some of the resultant files during the latex system call. Some files
> appear in a temporary R directory, while others appear in the current R
> working directory.
> 
> For example, if I enter the full filename:
>  
>   /tmp/RtmpC12100/file643c9869.tex
> 
> at the latex prompt, I get:
> 
> 
>>latex(x)
> 
> sh: line 0: cd: â€œ/tmp/RtmpC12100â€: No such file or directory
> This is pdfeTeX, Version 3.141592-1.21a-2.2 (Web2C 7.5.4)
> entering extended mode
> ! I can't find file `â€œ/tmp/RtmpC12100/file643c9869â€'.
> <*> â€œ/tmp/RtmpC12100/file643c9869â€
> 
> Please type another input file name: *** loading the extensions
> datasource
> /tmp/RtmpC12100/file643c9869.tex
> (/tmp/RtmpC12100/file643c9869.tex
> LaTeX2e <2003/12/01>
> Babel <v3.8d> and hyphenation patterns for american, french, german,
> ngerman, b
> ahasa, basque, bulgarian, catalan, croatian, czech, danish, dutch,
> esperanto, e
> stonian, finnish, greek, icelandic, irish, italian, latin, magyar,
> norsk, polis
> h, portuges, romanian, russian, serbian, slovak, slovene, spanish,
> swedish, tur
> kish, ukrainian, nohyphenation, loaded.
> (/usr/share/texmf/tex/latex/base/report.cls
> Document Class: report 2004/02/16 v1.4f Standard LaTeX document class
> (/usr/share/texmf/tex/latex/base/size10.clo))
> (/usr/share/texmf/tex/latex/geometry/geometry.sty
> (/usr/share/texmf/tex/latex/graphics/keyval.sty)
> (/usr/share/texmf/tex/latex/geometry/geometry.cfg))
> No file file643c9869.aux.
> [1] (./file643c9869.aux) )
> Output written on file643c9869.dvi (1 page, 368 bytes).
> Transcript written on file643c9869.log.
> xdvi-motif.bin: Fatal error: /tmp/RtmpC12100/file643c9869.dvi


Hmmmm,  It works for me.  Interesting.

It almost looks like the temp dir is not being created, but thats not 
possible because R does that.  It might be a Unicode issue with you 
system shell.  Can you run this statement in R

sys(paste('cd',dQuote(tempdir()),";",
"echo Hello BOB > test.test",
";","cat test.test"))


What version of Hmisc are you using?  What local are you using?

Charles

-- 
Charles Dupont	Computer System Analyst		School of Medicine
		Department of Biostatistics	Vanderbilt University



From afshart at exchange.sba.miami.edu  Wed Oct 12 15:58:28 2005
From: afshart at exchange.sba.miami.edu (Afshartous, David)
Date: Wed, 12 Oct 2005 09:58:28 -0400
Subject: [R] "symbol print-name too long"
Message-ID: <6BCB4D493A447546A8126F24332056E8F28BEF@school1.business.edu>

Spencer,
Thanks for your reply.  Yes, I finally resolved the issue.
One of the archive e-mails on this topic suggested looking 
for a the symbol ' and I mistakenly searched for the symbol ` to
no avail ... finally I found the symbol ' which was in a
very inconspicuous place.
Thanks,
Dave

-----Original Message-----
From: Spencer Graves [mailto:spencer.graves at pdf.com]
Sent: Tuesday, October 11, 2005 9:05 PM
To: Afshartous, David
Cc: r-help at stat.math.ethz.ch; dafshartous at yahoo.com
Subject: Re: [R] "symbol print-name too long"


	  Have you received a reply or otherwise resolved this issue?  If no, 
have you tried to construct the simplest possible example that comes to 
your mind.  Sometimes in the course of trying that, I often figure out 
what the error message means.  If you try this without getting the 
answer yourself, please send the resulting simple example to this list. 
  If someone reading your email can copy a few lines of code from your 
message into R and get the same problem, you are more likely to get a 
quick, informative reply.  (Please also specify which version of R on 
which platform.)

	  spencer graves

Afshartous, David wrote:

> All, 
> 
> I've coded a function and it works manually if I copy it line by line into R.
> However, when I try to "load" (copy and paste) the entire function into 
> R, I get the following error after the listed line of code:
> 
> + N.j.list = lapply(rej.hyp, length)   
> Error: symbol print-name too long
> 
> Does anyone you know what this error means?  Strangely, when I copy the 
> same line verbatim into R manually apart from the whole function, 
> no error message results.
> 
> I've checked the manuals and don't see anything RE print-name too long.  I also 
> tried google and saw an old message on this error message, but it doesn't seem to
> apply here.
> 
> Thanks,
> Dave
> ps - please respond directly to dafshartous at yahoo.com please.
> 
> 
> David Afshartous, PhD
> University of Miami
> Department of Management Science
> School of Business
> Coral Gables, FL 33124
> phone: 305-284-8005
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From rab45 at pitt.edu  Wed Oct 12 16:32:51 2005
From: rab45 at pitt.edu (Rick Bilonick)
Date: Wed, 12 Oct 2005 10:32:51 -0400
Subject: [R] Hmisc latex function
In-Reply-To: <434D10C5.6080601@vanderbilt.edu>
References: <1129039280.3048.7.camel@localhost.localdomain>
	<1129049947.4233.66.camel@localhost.localdomain>
	<434D10C5.6080601@vanderbilt.edu>
Message-ID: <434D1E93.5090807@pitt.edu>

Charles Dupont wrote:

> Marc Schwartz (via MN) wrote:
>
>> On Tue, 2005-10-11 at 10:01 -0400, Rick Bilonick wrote:
>>
>>> I'm using R 2.2.0 on an up-to-date version of Fedora Core 4 with the
>>> latest version of Hmisc. When I run an example from the latex 
>>> function I
>>> get the following:
>>>
>>>
>>>> x <- matrix(1:6, nrow=2, dimnames=list(c('a','b'),c('c','d','enLine
>>>
>>>
>>> 2')))
>>>
>>>> x
>>>
>>>
>>>  c d enLine 2
>>> a 1 3        5
>>> b 2 4        6
>>>
>>>> latex(x)   # creates x.tex in working directory
>>>
>>>
>>> sh: line 0: cd: â€œ/tmp/Rtmpl10983â€: No such file or directory
>>> This is pdfeTeX, Version 3.141592-1.21a-2.2 (Web2C 7.5.4)
>>> entering extended mode
>>> ! I can't find file `â€œ/tmp/Rtmpl10983/file643c9869â€'.
>>> <*> â€œ/tmp/Rtmpl10983/file643c9869â€
>>>
>>> Please type another input file name: q
>>> (/usr/share/texmf/tex/latex/tools/q.tex
>>> LaTeX2e <2003/12/01>
>>> Babel <v3.8d> and hyphenation patterns for american, french, german,
>>> ngerman, b
>>> ahasa, basque, bulgarian, catalan, croatian, czech, danish, dutch,
>>> esperanto, e
>>> stonian, finnish, greek, icelandic, irish, italian, latin, magyar,
>>> norsk, polis
>>> h, portuges, romanian, russian, serbian, slovak, slovene, spanish,
>>> swedish, tur
>>> kish, ukrainian, nohyphenation, loaded.
>>> File ignored
>>> xdvi-motif.bin: Fatal error: /tmp/Rtmpl10983/file643c9869.dvi: No such
>>> file.
>>>
>>>
>>> How can I fix this?
>>>
>>> Rick B.
>>
>>
>>
>> I get the same results, also on FC4 with R 2.2.0.
>>
>> I am cc:ing Frank here for his input, but a quick review of the code and
>> created files suggests that there may be conflict between the locations
>> of some of the resultant files during the latex system call. Some files
>> appear in a temporary R directory, while others appear in the current R
>> working directory.
>>
>> For example, if I enter the full filename:
>>  
>>   /tmp/RtmpC12100/file643c9869.tex
>>
>> at the latex prompt, I get:
>>
>>
>>> latex(x)
>>
>>
>> sh: line 0: cd: â€œ/tmp/RtmpC12100â€: No such file or directory
>> This is pdfeTeX, Version 3.141592-1.21a-2.2 (Web2C 7.5.4)
>> entering extended mode
>> ! I can't find file `â€œ/tmp/RtmpC12100/file643c9869â€'.
>> <*> â€œ/tmp/RtmpC12100/file643c9869â€
>>
>> Please type another input file name: *** loading the extensions
>> datasource
>> /tmp/RtmpC12100/file643c9869.tex
>> (/tmp/RtmpC12100/file643c9869.tex
>> LaTeX2e <2003/12/01>
>> Babel <v3.8d> and hyphenation patterns for american, french, german,
>> ngerman, b
>> ahasa, basque, bulgarian, catalan, croatian, czech, danish, dutch,
>> esperanto, e
>> stonian, finnish, greek, icelandic, irish, italian, latin, magyar,
>> norsk, polis
>> h, portuges, romanian, russian, serbian, slovak, slovene, spanish,
>> swedish, tur
>> kish, ukrainian, nohyphenation, loaded.
>> (/usr/share/texmf/tex/latex/base/report.cls
>> Document Class: report 2004/02/16 v1.4f Standard LaTeX document class
>> (/usr/share/texmf/tex/latex/base/size10.clo))
>> (/usr/share/texmf/tex/latex/geometry/geometry.sty
>> (/usr/share/texmf/tex/latex/graphics/keyval.sty)
>> (/usr/share/texmf/tex/latex/geometry/geometry.cfg))
>> No file file643c9869.aux.
>> [1] (./file643c9869.aux) )
>> Output written on file643c9869.dvi (1 page, 368 bytes).
>> Transcript written on file643c9869.log.
>> xdvi-motif.bin: Fatal error: /tmp/RtmpC12100/file643c9869.dvi
>
>
>
> Hmmmm,  It works for me.  Interesting.
>
> It almost looks like the temp dir is not being created, but thats not 
> possible because R does that.  It might be a Unicode issue with you 
> system shell.  Can you run this statement in R
>
> sys(paste('cd',dQuote(tempdir()),";",
> "echo Hello BOB > test.test",
> ";","cat test.test"))
>
>
> What version of Hmisc are you using?  What local are you using?
>
> Charles
>
I'm using Hmisc 3.0-7 (2005-09-15). I did an update.packages right after 
installing R 2.2.0. Here is the output I get:

sh: line 0: c: "/tmp/RtmpSp4207": No such file or directory
[1] "Hello BOB"

Thanks.

Rick B.



From apries at ufl.edu  Wed Oct 12 17:01:45 2005
From: apries at ufl.edu (Alexander J. Pries)
Date: Wed, 12 Oct 2005 11:01:45 -0400
Subject: [R] Variance explained in regression trees?
Message-ID: <200510121501.j9CF1jLX021866@smtp.ufl.edu>

I apologize for what may be novice questions but I am new to program R and
need a bit of assistance. I am using R to create regression trees to explain
how various environmental predictors influence coastal dune loss as a result
of hurricane activity. 

First question is as follows; how do I interpret the complexity plots that
the rpart package will produce. What do the X and Y axis represent (e.g.,
X-val relative error and cp). My understanding is that "cp" is similar to a
complexity penalty for having a tree with many branches when a simpler one
would be just as robust. How can I use the values and error bars to
interpret what is the "optimal" sized tree?

My other question is as follows; other statistical packages (I'm thinking
specifically of DTREG) that build regression trees are able to produce a
model summary that explains initial variance, amount of variance explained
by the tree, and unexplained variance. From this information, an estimated
R-sqr is calculated that provides some indication of how well the tree
"fits."

Does R produce, or have the ability, to produce information like this? If
anyone has specifics on how I might be able to evaluate the fit of my
regression trees.

Thank you in advance for any helpful guidance!

Alex Pries

--------------------
Alexander Pries
Graduate Student
Wildlife Ecology and Conservation
University of Florida
P.O. Box 110430
Gainesville, FL 32605
apries at ufl.edu
http://plaza.ufl.edu/apries
(352) 246-9621



From p.dalgaard at biostat.ku.dk  Wed Oct 12 16:59:53 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 12 Oct 2005 16:59:53 +0200
Subject: [R] Hmisc latex function
In-Reply-To: <434D10C5.6080601@vanderbilt.edu>
References: <1129039280.3048.7.camel@localhost.localdomain>
	<1129049947.4233.66.camel@localhost.localdomain>
	<434D10C5.6080601@vanderbilt.edu>
Message-ID: <x2slv6lr12.fsf@viggo.kubism.ku.dk>

Charles Dupont <charles.dupont at vanderbilt.edu> writes:

> Hmmmm,  It works for me.  Interesting.
> 
> It almost looks like the temp dir is not being created, but thats not 
> possible because R does that.  It might be a Unicode issue with you 
> system shell.  Can you run this statement in R

It's a Unicode issue alright. dQuote is intended for textual output,
and in UTF-8 locales it will use Unicode codepoints 0x201c and 0x201d,
which the shell is not expected to make head or tails of.

The help page would have told you, and pointed you to shQuote() as
well...
 
> sys(paste('cd',dQuote(tempdir()),";",
> "echo Hello BOB > test.test",
> ";","cat test.test"))
> 
> 
> What version of Hmisc are you using?  What local are you using?
> 
> Charles
> 
> -- 
> Charles Dupont	Computer System Analyst		School of Medicine
> 		Department of Biostatistics	Vanderbilt University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From david.whiting at ncl.ac.uk  Wed Oct 12 17:06:57 2005
From: david.whiting at ncl.ac.uk (David Whiting)
Date: Wed, 12 Oct 2005 16:06:57 +0100
Subject: [R] Hmisc latex function
In-Reply-To: <434D10C5.6080601@vanderbilt.edu>
References: <1129039280.3048.7.camel@localhost.localdomain>	<1129049947.4233.66.camel@localhost.localdomain>
	<434D10C5.6080601@vanderbilt.edu>
Message-ID: <434D2691.3020609@ncl.ac.uk>

Charles Dupont wrote:
[...]

> 
> 
> Hmmmm,  It works for me.  Interesting.
> 
> It almost looks like the temp dir is not being created, but thats not 
> possible because R does that.  It might be a Unicode issue with you 
> system shell.  Can you run this statement in R
> 
> sys(paste('cd',dQuote(tempdir()),";",
> "echo Hello BOB > test.test",
> ";","cat test.test"))
> 
> 
> What version of Hmisc are you using?  What local are you using?
> 
> Charles
> 

I've had similar problems latex() which I tracked down to dQuote() that
I think are related to unicode and locales on Ubuntu 5.04. I think the
problem is with Ubuntu (because I get funny little boxes now and then
with various applications), but have not managed to get my head around
unicode sufficiently well to be able to write a sensible post about this
or work out how to fix it. My current way of getting around this in R is
to change the locale:

> Sys.getlocale()
[1]
"LC_CTYPE=en_GB.UTF-8;LC_NUMERIC=C;LC_TIME=en_GB.UTF-8;LC_COLLATE=en_GB.UTF-8;LC_MONETARY=en_GB.UTF-8;LC_MESSAGES=en_GB.UTF-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C"
> tempdir()
[1] "/tmp/RtmpWL64Z2"
> dQuote(tempdir())
[1] "Ã¢Â€Âœ/tmp/RtmpWL64Z2Ã¢Â€Â"  [I get funny little boxes here]
> Sys.setlocale("LC_CTYPE", "C")
[1] "C"
> Sys.getlocale()
[1]
"LC_CTYPE=C;LC_NUMERIC=C;LC_TIME=en_GB.UTF-8;LC_COLLATE=en_GB.UTF-8;LC_MONETARY=en_GB.UTF-8;LC_MESSAGES=en_GB.UTF-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C"
> dQuote(tempdir())
[1] "\"/tmp/RtmpWL64Z2\"" [No funny boxes this time]
>
> version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    2
minor    1.1
year     2005
month    06
day      20
language R
>

[Hmmm, I need to update my R installation]

-- 
David Whiting
School of Clinical Medical Sciences, The Medical School
University of Newcastle upon Tyne, NE2 4HH, UK.



From lassana.koita at aviation-civile.gouv.fr  Wed Oct 12 17:00:31 2005
From: lassana.koita at aviation-civile.gouv.fr (KOITA Lassana - STAC/ACE)
Date: Wed, 12 Oct 2005 17:00:31 +0200
Subject: [R] loop for plot function
Message-ID: <OF965A4B14.98300EE1-ONC1257098.005232E6@aviation-civile.gouv.fr>





Hello all R users,
I would like to add another loop to my following R code ( it works for the
moment correctly) , which will be able to me to vary n (see the code) from
1 to 4 or 5.
And I also would like apply the plot function in this case, eg all four or
five figures in the same graphic (n= 1, 2, ..., 4 ou 5)
I have tested one, but unsuccessfully.
I need you to solve this problems

Thank you


###########################################################################"

simulation <- function(k, n){

conc <- seq(0,100,by=0.5)
#choixg <- seq(1, length(conc))
choixg <- rep(0,length(conc))
for (i in 1:length(conc)){
    choixg[i] <- (k + conc[i])^n/((k+conc[i])^n + (k+1)^n)

    }
   #return(data.frame(choixg, conc))
   return(list(choixg=choixg, conc = conc))

}

#choixg <- simulation(5,2)
#mydf<-simulation(5,1)
simResult <- simulation (5,5)
#plot(mydf$conc, log10(1-mydf$choixg), main ="fonction de choix", col=
#"blue", pch=20,
#xlab = " concentration", ylab="proba de choisir la gauche")

plot(simResult$conc, log10(1-simResult$choixg), main ="fonction de choix",
col=
"blue", pch=20, lwd = 3,
xlab = " concentration", ylab="proba de choisir la gauche")

lines(simResult$conc, log10(1-simResult$choixg), col= "red", lwd = 3)

#cbind(simResult$conc, simResult$choixg, format(Sys.time(),"%H:%M:%S"))

Lassana KOITA
Etude S??curit?? et Exploitation a??roportuaires / Aerodrome Safety &
Statistical analysis
Service Technique de l'Aviation Civile (STAC) / Civil Aviation Technical
Department
Direction G??n??rale de l'Aviation Civile (DGAC) / French Civil Aviation
Tel: 01 49 56 80 60
Fax: 01 49 56 82 14
E-mail: Lassana.Koita at aviation-civile.gouv.fr



From mschwartz at mn.rr.com  Wed Oct 12 17:13:31 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Wed, 12 Oct 2005 10:13:31 -0500
Subject: [R] Hmisc latex function
In-Reply-To: <434D10C5.6080601@vanderbilt.edu>
References: <1129039280.3048.7.camel@localhost.localdomain>
	<1129049947.4233.66.camel@localhost.localdomain>
	<434D10C5.6080601@vanderbilt.edu>
Message-ID: <1129130011.4641.13.camel@localhost.localdomain>

On Wed, 2005-10-12 at 08:33 -0500, Charles Dupont wrote:
> Marc Schwartz (via MN) wrote:
> > On Tue, 2005-10-11 at 10:01 -0400, Rick Bilonick wrote:
> > 
> >>I'm using R 2.2.0 on an up-to-date version of Fedora Core 4 with the
> >>latest version of Hmisc. When I run an example from the latex function I
> >>get the following:
> >>
> >>
> >>>x <- matrix(1:6, nrow=2, dimnames=list(c('a','b'),c('c','d','enLine
> >>
> >>2')))
> >>
> >>>x
> >>
> >>  c d enLine 2
> >>a 1 3        5
> >>b 2 4        6
> >>
> >>>latex(x)   # creates x.tex in working directory
> >>
> >>sh: line 0: cd: â€œ/tmp/Rtmpl10983â€: No such file or directory
> >>This is pdfeTeX, Version 3.141592-1.21a-2.2 (Web2C 7.5.4)
> >>entering extended mode
> >>! I can't find file `â€œ/tmp/Rtmpl10983/file643c9869â€'.
> >><*> â€œ/tmp/Rtmpl10983/file643c9869â€
> >>
> >>Please type another input file name: q
> >>(/usr/share/texmf/tex/latex/tools/q.tex
> >>LaTeX2e <2003/12/01>
> >>Babel <v3.8d> and hyphenation patterns for american, french, german,
> >>ngerman, b
> >>ahasa, basque, bulgarian, catalan, croatian, czech, danish, dutch,
> >>esperanto, e
> >>stonian, finnish, greek, icelandic, irish, italian, latin, magyar,
> >>norsk, polis
> >>h, portuges, romanian, russian, serbian, slovak, slovene, spanish,
> >>swedish, tur
> >>kish, ukrainian, nohyphenation, loaded.
> >>File ignored
> >>xdvi-motif.bin: Fatal error: /tmp/Rtmpl10983/file643c9869.dvi: No such
> >>file.
> >>
> >>
> >>How can I fix this?
> >>
> >>Rick B.
> > 
> > 
> > I get the same results, also on FC4 with R 2.2.0.
> > 
> > I am cc:ing Frank here for his input, but a quick review of the code and
> > created files suggests that there may be conflict between the locations
> > of some of the resultant files during the latex system call. Some files
> > appear in a temporary R directory, while others appear in the current R
> > working directory.
> > 
> > For example, if I enter the full filename:
> >  
> >   /tmp/RtmpC12100/file643c9869.tex
> > 
> > at the latex prompt, I get:
> > 
> > 
> >>latex(x)
> > 
> > sh: line 0: cd: â€œ/tmp/RtmpC12100â€: No such file or directory
> > This is pdfeTeX, Version 3.141592-1.21a-2.2 (Web2C 7.5.4)
> > entering extended mode
> > ! I can't find file `â€œ/tmp/RtmpC12100/file643c9869â€'.
> > <*> â€œ/tmp/RtmpC12100/file643c9869â€
> > 
> > Please type another input file name: *** loading the extensions
> > datasource
> > /tmp/RtmpC12100/file643c9869.tex
> > (/tmp/RtmpC12100/file643c9869.tex
> > LaTeX2e <2003/12/01>
> > Babel <v3.8d> and hyphenation patterns for american, french, german,
> > ngerman, b
> > ahasa, basque, bulgarian, catalan, croatian, czech, danish, dutch,
> > esperanto, e
> > stonian, finnish, greek, icelandic, irish, italian, latin, magyar,
> > norsk, polis
> > h, portuges, romanian, russian, serbian, slovak, slovene, spanish,
> > swedish, tur
> > kish, ukrainian, nohyphenation, loaded.
> > (/usr/share/texmf/tex/latex/base/report.cls
> > Document Class: report 2004/02/16 v1.4f Standard LaTeX document class
> > (/usr/share/texmf/tex/latex/base/size10.clo))
> > (/usr/share/texmf/tex/latex/geometry/geometry.sty
> > (/usr/share/texmf/tex/latex/graphics/keyval.sty)
> > (/usr/share/texmf/tex/latex/geometry/geometry.cfg))
> > No file file643c9869.aux.
> > [1] (./file643c9869.aux) )
> > Output written on file643c9869.dvi (1 page, 368 bytes).
> > Transcript written on file643c9869.log.
> > xdvi-motif.bin: Fatal error: /tmp/RtmpC12100/file643c9869.dvi
> 
> 
> Hmmmm,  It works for me.  Interesting.
> 
> It almost looks like the temp dir is not being created, but thats not 
> possible because R does that.  It might be a Unicode issue with you 
> system shell.  Can you run this statement in R
> 
> sys(paste('cd',dQuote(tempdir()),";",
> "echo Hello BOB > test.test",
> ";","cat test.test"))
> 
> 
> What version of Hmisc are you using?  What local are you using?
> 
> Charles

Hmisc version 3.0-7, Dated 2005-09-15, which is the latest according to
CRAN.

> sys(paste('cd',dQuote(tempdir()),";",
+ "echo Hello BOB > test.test",
+ ";","cat test.test"))
sh: line 0: cd: â€œ/tmp/RtmpGY5553â€: No such file or directory
[1] "Hello BOB"


>From a bash console:

$ cd /tmp/RtmpGY5553
$ pwd
/tmp/RtmpGY5553


$ locale
LANG=en_US.UTF-8
LC_CTYPE="en_US.UTF-8"
LC_NUMERIC="en_US.UTF-8"
LC_TIME="en_US.UTF-8"
LC_COLLATE="en_US.UTF-8"
LC_MONETARY="en_US.UTF-8"
LC_MESSAGES="en_US.UTF-8"
LC_PAPER="en_US.UTF-8"
LC_NAME="en_US.UTF-8"
LC_ADDRESS="en_US.UTF-8"
LC_TELEPHONE="en_US.UTF-8"
LC_MEASUREMENT="en_US.UTF-8"
LC_IDENTIFICATION="en_US.UTF-8"
LC_ALL=


On the creation of the sys() call, it looks like the backquotes are
causing the problem:

> paste('cd',dQuote(tempdir()))
[1] "cd â€œ/tmp/RtmpGY5553â€"


>From a bash shell:

$ cd â€œ/tmp/RtmpGY5553â€
bash: cd: â€œ/tmp/RtmpGY5553â€: No such file or directory
$ cd "/tmp/RtmpGY5553"
$ pwd
/tmp/RtmpGY5553


According to ?dQuote:

By default, sQuote and dQuote provide undirectional ASCII quotation
style. In a UTF-8 locale (see l10n_info), the Unicode directional quotes
are used.

The See Also points to "shQuote for quoting OS commands."


HTH,

Marc



From efg at stowers-institute.org  Wed Oct 12 17:12:31 2005
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Wed, 12 Oct 2005 10:12:31 -0500
Subject: [R] font=5 (Was: greek symbols using pch)
References: <283982AD9F3CD211B3AC00A0C983032F11443674@paradise.ansto.gov.au><die0c3$5ti$1@sea.gmane.org>
	<434B4CBC.6000006@adfa.edu.au><Pine.LNX.4.61.0510110742380.13144@gannet.stats><434B7B78.6020603@adfa.edu.au>
	<digldd$bnr$1@sea.gmane.org> <434C9CBA.2090901@adfa.edu.au>
Message-ID: <dij950$5nl$1@sea.gmane.org>

"ecatchpole" <E.Catchpole at adfa.edu.au> wrote in message
news:434C9CBA.2090901 at adfa.edu.au...
> Earl,
>
> I don't think that's a bug. Try
>
> pdf("font5.pdf", onefile=FALSE)
>
> and similarly for postscript().

Mea culpa. The onefile=FALSE wasn't necessary (and caused Ghostscript not to
open the postscript file).

The 2nd page was caused by an erroneous second plot statement in ShowFont5,
which I put there for a one time test and then I failed to remove it.  I was
getting two pages because I had two plot statements.  Sorry for the
confusion.

All works fine with this code, which has only one plot statement, even with
postscript and pdf files:

ShowFont5 <- function()
{
  oldpar <- par(font=5, las=1)
  plot(0:15,0:15,type="n",ylim=c(15,0),
    main="Symbols in Font=5",
    xlab="", ylab="",xaxt="n", yaxt="n")
  axis(BOTTOM<-1, at=0:15)
  axis(LEFT  <-2, at=0:15, 16*0:15)
  abline(v=0.5 + 0:14,
         h=0.5 + 0:14, col="grey", lty="dotted")
  for(i in 0:255)
  {
    x <- i %%16;
    y <- i %/% 16;
    points(x,y,pch=i)
  }
  par(oldpar)
}


efg



From charles.dupont at vanderbilt.edu  Wed Oct 12 17:31:31 2005
From: charles.dupont at vanderbilt.edu (Charles Dupont)
Date: Wed, 12 Oct 2005 10:31:31 -0500
Subject: [R] Hmisc latex function
In-Reply-To: <x2slv6lr12.fsf@viggo.kubism.ku.dk>
References: <1129039280.3048.7.camel@localhost.localdomain>	<1129049947.4233.66.camel@localhost.localdomain>	<434D10C5.6080601@vanderbilt.edu>
	<x2slv6lr12.fsf@viggo.kubism.ku.dk>
Message-ID: <434D2C53.5000005@vanderbilt.edu>

Peter Dalgaard wrote:
> Charles Dupont <charles.dupont at vanderbilt.edu> writes:
> 
> 
>>Hmmmm,  It works for me.  Interesting.
>>
>>It almost looks like the temp dir is not being created, but thats not 
>>possible because R does that.  It might be a Unicode issue with you 
>>system shell.  Can you run this statement in R
> 
> 
> It's a Unicode issue alright. dQuote is intended for textual output,
> and in UTF-8 locales it will use Unicode codepoints 0x201c and 0x201d,
> which the shell is not expected to make head or tails of.
> 
> The help page would have told you, and pointed you to shQuote() as
> well...
>  
> 


Well There be the problem.

First I have heard about shQuote.  When I last looked at the help file 
it didn't have the shQuote entry.

For a temporary fix source the attached file after loading the Hmisc 
library.  I will fix this in source for the next version.


-- 
Charles Dupont	Computer System Analyst		School of Medicine
		Department of Biostatistics	Vanderbilt University
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: latex.s
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051012/90ab4705/latex.pl

From jporzak at gmail.com  Wed Oct 12 18:04:59 2005
From: jporzak at gmail.com (Jim Porzak)
Date: Wed, 12 Oct 2005 09:04:59 -0700
Subject: [R] adding 1 month to a date
In-Reply-To: <2a9c000c0510120854m76e5e233q2810167cdca966e6@mail.gmail.com>
References: <8d5a36350510120513u1d32f44dwee638095dd90cd28@mail.gmail.com>
	<Pine.LNX.4.61.0510121320450.9181@gannet.stats>
	<1129120670.3510.73.camel@localhost.localdomain>
	<2a9c000c0510120854m76e5e233q2810167cdca966e6@mail.gmail.com>
Message-ID: <2a9c000c0510120904u638019a5lfd84f3741df53631@mail.gmail.com>

 OTOH,

 > seq(as.Date("2004-01-31"), by = "month", length = 14)
  [1] "2004-01-31" "2004-03-02" "2004-03-31" "2004-05-01" "2004-05-31"
  [6] "2004-07-01" "2004-07-31" "2004-08-31" "2004-10-01" "2004-10-31"
 [11] "2004-12-01" "2004-12-31" "2005-01-31" "2005-03-03"

 I would prefer to see dates forced to be within each month, not
 "leaking" into next month.

 IOW:
  [1] "2004-01-31" "2004-02-29" "2004-03-31" "2004-04-30" "2004-05-31", etc


 --
 Jim Porzak
 Loyalty Matrix Inc.
 San Francisco, CA


> On 10/12/05, Marc Schwartz <MSchwartz at mn.rr.com> wrote:
> > Thanks to Prof. Ripley for pointing this out.
> >
> > One of the approaches that I had considered here was to set up a vector
> > of the number of days in each month (adjusting of course for leap
> > years), and use "day arithmetic" to add/subtract the appropriate number
> > of days.
> >
> > However, it was easier to use seq.Date() and to further consider putting
> > a wrapper around it to make it yet even easier to use.
> >
> > Marc
> >
> > On Wed, 2005-10-12 at 13:23 +0100, Prof Brian Ripley wrote:
> > > On Wed, 12 Oct 2005, bogdan romocea wrote:
> > >
> > > > Simple addition and subtraction works as well:
> > > >  as.Date("1995/12/01",format="%Y/%m/%d") + 30
> > > > If you have datetime values you can use
> > > >  strptime("1995-12-01 08:00:00",format="%Y-%m-%d %H:%M:%S") + 30*24*3600
> > > > where 30*24*3600 = 30 days expressed in seconds.
> > >
> > > Sorry, not in general, as a month is not generally of 30 days (including
> > > in your example).
> > >
> > > seq.Date is a good way to do this.
> > >
> > > >
> > > >
> > > >> -----Original Message-----
> > > >> From: Marc Schwartz [mailto:MSchwartz at mn.rr.com]
> > > >> Sent: Tuesday, October 11, 2005 10:16 PM
> > > >> To: t c
> > > >> Cc: r-help at stat.math.ethz.ch
> > > >> Subject: Re: [R] adding 1 month to a date
> > > >>
> > > >>
> > > >> On Tue, 2005-10-11 at 16:26 -0700, t c wrote:
> > > >>> Within an R dataset, I have a date field called date_.
> > > >> (The dates are
> > > >>> in the format YYYY-MM-DD, e.g. 1995-12-01.)
> > > >>
> > > >>> How can I add or subtract 1 month from this date, to get
> > > >> 1996-01-01 or
> > > >>> 1995-11-01.
> > > >>
> > > >> There might be an easier way to do this, but using seq.Date(), you can
> > > >> increment or decrement from a Time 0 by months:
> > > >>
> > > >> Add 1 month:
> > > >>
> > > >> This takes your Time 0, generates a 2 element sequence (which begins
> > > >> with Time 0) and then takes the second element:
> > > >>
> > > >>> seq(as.Date("1995-12-01"), by = "month", length = 2)[2]
> > > >> [1] "1996-01-01"
> > > >>
> > > >>
> > > >>
> > > >> Subtract 1 month:
> > > >>
> > > >> Same as above, but we use 'by = "-1 month"' and take the
> > > >> second element:
> > > >>
> > > >>> seq(as.Date("1995-12-01"), by = "-1 month", length = 2)[2]
> > > >> [1] "1995-11-01"
> > > >>
> > > >>
> > > >> See ?as.Date and ?seq.Date for more information. The former
> > > >> function is
> > > >> used to convert from a character vector to a Date class object. Note
> > > >> that in your case, the date format is consistent with the default. Pay
> > > >> attention to the 'format' argument in as.Date() if your dates
> > > >> should be
> > > >> in other formats.
> > > >>
> > > >> HTH,
> > > >>
> > > >> Marc Schwartz
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>



From drf5n at maplepark.com  Wed Oct 12 18:50:22 2005
From: drf5n at maplepark.com (David Forrest)
Date: Wed, 12 Oct 2005 11:50:22 -0500 (CDT)
Subject: [R] adding 1 month to a date
In-Reply-To: <2a9c000c0510120904u638019a5lfd84f3741df53631@mail.gmail.com>
References: <8d5a36350510120513u1d32f44dwee638095dd90cd28@mail.gmail.com>
	<Pine.LNX.4.61.0510121320450.9181@gannet.stats>
	<1129120670.3510.73.camel@localhost.localdomain>
	<2a9c000c0510120854m76e5e233q2810167cdca966e6@mail.gmail.com>
	<2a9c000c0510120904u638019a5lfd84f3741df53631@mail.gmail.com>
Message-ID: <Pine.LNX.4.58.0510121147190.24069@maplepark.com>

On Wed, 12 Oct 2005, Jim Porzak wrote:

>  OTOH,
>
>  > seq(as.Date("2004-01-31"), by = "month", length = 14)
>   [1] "2004-01-31" "2004-03-02" "2004-03-31" "2004-05-01" "2004-05-31"
>   [6] "2004-07-01" "2004-07-31" "2004-08-31" "2004-10-01" "2004-10-31"
>  [11] "2004-12-01" "2004-12-31" "2005-01-31" "2005-03-03"
>
>  I would prefer to see dates forced to be within each month, not
>  "leaking" into next month.
>
>  IOW:
>   [1] "2004-01-31" "2004-02-29" "2004-03-31" "2004-04-30" "2004-05-31", etc

It depends how you intend "1 month after 2004-01-31".  Is the the same
number of days before the beginning of the next month or after the end of
the stated month?

   seq(as.Date("2004-02-01"), by = "month", length = 14)-1

   [1] "2004-01-31" "2004-02-29" "2004-03-31" "2004-04-30" "2004-05-31"

Dave
-- 
 Dr. David Forrest
 drf at vims.edu                                    (804)684-7900w
 drf5n at maplepark.com                             (804)642-0662h
                                   http://maplepark.com/~drf5n/



From staggs at mail.ahc.umn.edu  Wed Oct 12 18:57:33 2005
From: staggs at mail.ahc.umn.edu (Rod Staggs)
Date: Wed, 12 Oct 2005 11:57:33 -0500
Subject: [R] Memory allocation
Message-ID: <BF72AAAD.72EE%staggs@ahc.umn.edu>

I am trying to work with 75 affymetrix U133plus2 chips and am running into
memory allocation errors when trying to merge or convert probe level data to
expression values.

I keep getting - Error: cannot allocate vector of size 561011 Kb and that is
simply with a data subset.

Is there a way around this limitation?

-- 
Rodney A. Staggs
Cancer Center Informatics Shared Resource
425 Delaware St S.E. MMC 806
University of Minnesota
Minneapolis, MN  55455
 
Office: Room B532 Mayo
Telephone: (612)624-2445
Email: stagg004 at umn.edu



From jmacdon at med.umich.edu  Wed Oct 12 19:23:23 2005
From: jmacdon at med.umich.edu (James W. MacDonald)
Date: Wed, 12 Oct 2005 13:23:23 -0400
Subject: [R] Memory allocation
In-Reply-To: <BF72AAAD.72EE%staggs@ahc.umn.edu>
References: <BF72AAAD.72EE%staggs@ahc.umn.edu>
Message-ID: <434D468B.2090507@med.umich.edu>

Rod Staggs wrote:
> I am trying to work with 75 affymetrix U133plus2 chips and am running into
> memory allocation errors when trying to merge or convert probe level data to
> expression values.

You don't say what package(s) you are using to do this, but assuming you 
are using the affy package, this is not the correct list - you should be 
using the BioC list (bioconductor at stat.math.ethz.ch).

To answer your question, there are several possibilities.

1.) Get more RAM (if on windows, start R with --max-mem-size=<amount of 
RAM>)

2.) Use justRMA()

3.) If on Windows, switch to *nix. The memory allocation is better, so 
you can analyze more chips with the same amount of RAM. Probably the 
easisest way to do this is with Quantian, which runs off a CD.


Best,

Jim



> 
> I keep getting - Error: cannot allocate vector of size 561011 Kb and that is
> simply with a data subset.
> 
> Is there a way around this limitation?
> 


-- 
James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623



From hastie at stanford.edu  Wed Oct 12 19:30:04 2005
From: hastie at stanford.edu (Trevor Hastie)
Date: Wed, 12 Oct 2005 10:30:04 -0700
Subject: [R] step.gam- question
In-Reply-To: <1129111378.434cdf523b630@www.ps.pl>
References: <1129111378.434cdf523b630@www.ps.pl>
Message-ID: <434D481C.3060000@stanford.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051012/d9ef23ec/attachment.pl

From gunter.berton at gene.com  Wed Oct 12 19:47:40 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 12 Oct 2005 10:47:40 -0700
Subject: [R] Nonclinical Biostatistics Job Opening at Genentech in South San
	Francisco, CA
Message-ID: <200510121747.j9CHlees009846@compton.gene.com>

I hope that this job posting does not offend anyone. My sincere apologies if
it is inappropriate -- blame me, not my company. 

-- Bert Gunter
Genentech Nonclinical Statistics
South San Francisco, CA
 


Genentech has an opening for a fulltime position in its nonclinical
biostatistics department, located in South San Francisco, CA.

The nonclinical group currently consists of  seven MS and PhD level
statisticians and mathematicians who work with approximately 800 scientists,
engineers, and others in drug discovery, preclinical testing, process and
product development, manufacturing,  and quality control, among other areas
- essentially everything but clinical trials. Statistical activities are
commensurately diverse. Some "typical" ones are design and analysis of
animal testing for drug efficacy, pharmacokinetics, and toxicity; microarray
experiment design and data analysis; bioanalytical assay development; and
optimization of robust antibody fermentation and purification processes.

We are seeking individuals with a broad knowledge of statistical methodology
who are eager to work in an exciting collaborative environment to apply
their knowledge to drug discovery and development. Because we are a science
driven company on the cutting edge of technology, we also expect our members
to devote effort to learning about and staying current with our science and
technology so that they can better communicate and work with our scientists.
Basic qualifications that we seek include:

> MS or PhD in statistics or closely related discipline

>  Broad and deep understanding of statistical experimental design and
analysis   techniques, particularly in the areas of linear models and
regression

> Excellent problem-solving abilities

> Familiarity with statistical software packages such as SAS, R, S-Plus,
MATLAB

> Strong interpersonal skills 

> Ability to function effectively on interdisciplinary project teams

> Excellent oral and written communication skills		

> Experience teaching statistics or working as a statistical consultant

If you are interested in joining us, please email your CV and a cover letter
to Dr. David Giltinan,  giltinan.david at gene.com  .

Genentech, the founder of the biotechnology industry, has a 25-year track
record of translating the promise of biotechnology to medicines that help
seriously ill patients. The company is perennially rated among the
industry's most innovative and one of the best to work for. This strong
commitment to scientific research has  resulted in an unprecedented sequence
of successful clinical trials, an excellent pipeline, and remarkable growth.
To learn more, please go to  http://www.gene.com/gene/index.jsp



From quantpm at yahoo.com  Wed Oct 12 19:50:11 2005
From: quantpm at yahoo.com (t c)
Date: Wed, 12 Oct 2005 10:50:11 -0700 (PDT)
Subject: [R] adding 1 month to a date
In-Reply-To: <971536df0510111654w506afd0coa0d18a2b966827cf@mail.gmail.com>
Message-ID: <20051012175011.34602.qmail@web35015.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051012/b10c9569/attachment.pl

From quantpm at yahoo.com  Wed Oct 12 19:52:37 2005
From: quantpm at yahoo.com (t c)
Date: Wed, 12 Oct 2005 10:52:37 -0700 (PDT)
Subject: [R] adding 1 month to a date
Message-ID: <20051012175237.13842.qmail@web35013.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051012/70f04597/attachment.pl

From quantpm at yahoo.com  Wed Oct 12 20:10:13 2005
From: quantpm at yahoo.com (t c)
Date: Wed, 12 Oct 2005 11:10:13 -0700 (PDT)
Subject: [R] functions available for use with aggregate?
Message-ID: <20051012181013.27903.qmail@web35011.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051012/ceb6a44a/attachment.pl

From sundar.dorai-raj at pdf.com  Wed Oct 12 20:18:57 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 12 Oct 2005 13:18:57 -0500
Subject: [R] functions available for use with aggregate?
In-Reply-To: <20051012181013.27903.qmail@web35011.mail.mud.yahoo.com>
References: <20051012181013.27903.qmail@web35011.mail.mud.yahoo.com>
Message-ID: <434D5391.1030705@pdf.com>



t c wrote:
> What are the functions available for use with ?aggregate??  Where can a reference to them be found?
> 
>  

Since aggregate is a S3 generic, you can use

methods(aggregate)

to see what objects have an "aggregate" method. For me, I have the 
following:

 > methods(aggregate)
[1] aggregate.data.frame aggregate.default    aggregate.frm*
[4] aggregate.ts

    Non-visible functions are asterisked
 >

See ?methods for more details.

HTH,

--sundar



From quantpm at yahoo.com  Wed Oct 12 20:43:44 2005
From: quantpm at yahoo.com (t c)
Date: Wed, 12 Oct 2005 11:43:44 -0700 (PDT)
Subject: [R] R training/"tutor"
Message-ID: <20051012184345.39198.qmail@web35002.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051012/d267502c/attachment.pl

From nflynn at ualberta.ca  Wed Oct 12 20:54:18 2005
From: nflynn at ualberta.ca (nflynn@ualberta.ca)
Date: Wed, 12 Oct 2005 12:54:18 -0600
Subject: [R] Mixed model for negative binomial distribution  (glmm.ADMB)
Message-ID: <20051012125418.lphfwph1lgc0ckgg@webmail.ualberta.ca>

Dear R-list,

I thought that I would let some of you know of a free R package, glmm.ADMB, that
can handle mixed models for overdispersed and zero-inflated count data
(negativebinomial and poisson).
It was built using AD Model Builder software (Otter Research) for random effects
modeling and is available (for free and runs in R) at:

 http://otter-rsch.com/admbre/examples/glmmadmb/glmmADMB.html

I have been using this package for a split plot design along streams
(my  M.Sc thesis).  My response data was best described by a negative binomial
distribution (without zero-inflation) (beaver dam counts).

The model worked very well for my dataset and appeared to handle the
random effect (stream section).  Although I only had one random effect, 
glmm.ADMB can handle at least two nested random effects.  The output and
functions  available in glmm.ADMB are similar to those available in GLM.

One of my criteria for a mixed-model was that is provided the correct estimate
of the log-likelihood so that I could use an information theoretic approach for
 model selection, based on AIC values.  To my knowledge the maximum likelihood 
estimate for glmm.ADMB is appropriate for AIC model selection (*see comment
below), unlike glmmPQL.

Other packages that correctly estimate the log likelihood estimate,
such  as, Lindsey??s Repeated Measures Package (glmm)  and glmmML
do not accept the negative binomial family.  However glmm and glmmML do
accept the poisson family to describe the distribution of the response variable,
which may be adequate for modeling negative binomial data. The glmmML does not
allow for more than one random effect but glmmADMB is more flexible, in terms
of both random effects (allows nesting) and model output.

If any of you try glmm.ADMB, I would be very interested in your
feedback, especially in the realm of model verification, i.e. how is
the random effect really being handled.

You can also contact the creators at otter at otter-rsch.com.  I found
them to be very helpful in explaining their software, both its benefits and 
limitations. They have also run some tests comparing glmm.ADMB to other 
software packages like SAS NLMIXED and arrived at similar solutions.

If any of you are interested in my model comparisons (glmm.admb,
glmm and glmmML)  I can send you some of my test data and results.

 Best Regards, Nadele Flynn

 *  "maximizing is the approximate likelihood obtained by integrating
    out the random effects via the laplace approximation."
  (Otter Research Ltd)  This is not the exact maximum likelihood
   estimate, but I accepted any small error in the estimate and used
   it to calculate AIC values.



From quantpm at yahoo.com  Wed Oct 12 21:01:56 2005
From: quantpm at yahoo.com (t c)
Date: Wed, 12 Oct 2005 12:01:56 -0700 (PDT)
Subject: [R] Correlation, by date, of two variables?
Message-ID: <20051012190156.87281.qmail@web35008.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051012/de9d8581/attachment.pl

From bbi68 at u.washington.edu  Wed Oct 12 21:08:56 2005
From: bbi68 at u.washington.edu (byoung-inn bai)
Date: Wed, 12 Oct 2005 12:08:56 -0700 (PDT)
Subject: [R] linear mixed effect model with ordered logit/probit link?
Message-ID: <Pine.A41.4.63a.0510121145320.59634@dante76.u.washington.edu>

Hello,

I'm working on the multiple categorical data (5-points scale) using linear 
mixed effect model and wondering if anyone knows about or works on the 
linear mixed effect model with ordered logit or probit link.
I found that the "lmer" function in R is very flexible and supports 
various models, but not ordered logit/probit models. I may conduct my 
analysis by turning my DVs into nested dichotonomies, but just wonder if 
there is anyway that I can do this without transforming my DVs. Any help 
or suggestion will be greatly appreciated.

Thanks,

Byoung-Inn



Byoung-Inn Bai
Ph.D. Candidate
University of Washington
Department of Political Science
Box 353530
e-mail: bbi68 at u.washington.edu



From arturo.coral at gmail.com  Wed Oct 12 22:03:08 2005
From: arturo.coral at gmail.com (Arturo Coral Alamo)
Date: Wed, 12 Oct 2005 15:03:08 -0500
Subject: [R] linear mixed effect model with ordered logit/probit link?
In-Reply-To: <Pine.A41.4.63a.0510121145320.59634@dante76.u.washington.edu>
References: <Pine.A41.4.63a.0510121145320.59634@dante76.u.washington.edu>
Message-ID: <ed2fd5230510121303s45364b7ema1f29e5714596f2a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051012/4daea6bd/attachment.pl

From mschwartz at mn.rr.com  Wed Oct 12 22:22:30 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Wed, 12 Oct 2005 15:22:30 -0500
Subject: [R] Correlation, by date, of two variables?
In-Reply-To: <20051012190156.87281.qmail@web35008.mail.mud.yahoo.com>
References: <20051012190156.87281.qmail@web35008.mail.mud.yahoo.com>
Message-ID: <1129148550.4641.66.camel@localhost.localdomain>

On Wed, 2005-10-12 at 12:01 -0700, t c wrote:
> I have a dataset with three variables: date, var1, var2

> How can I calculate the correlation, by date, between var1 and var2?
> 
> e.g.
> 
> 
> date    var1    var2
> 1/1/2001    5    4
> 1/1/2001    8    5
> 1/1/2001    9    7
> 
>  
> 
> 2/1/2001    7    2
> 2/1/2001    2    1
> 2/1/2001    4    6
> 
>  
> 
> 3/1/2001    3    5
> 3/1/2001    4    3
> 3/1/2001    6    9
> 3/1/2001    7    -1
> 
>  
> 
> the results I want:
> 1/1/2001 0.891042111
> 2/1/2001 0.075093926
> 3/1/2001 -0.263117406

t c,

Given your series of posts here, I would highly recommend that before
you consider spending money on a tutor or other similar resource, you
take the time to read the freely available documentation that both R
Core and useRs have kindly provided to the Community. The R Core manuals
are all available with your downloaded installation of R and/or from the
main R web site under Documentation as are the Contributed documents.
You will find that your time will be well invested in that effort.

If you read the Posting Guide for the e-mail lists, a link to which is
provided at the bottom of every e-mail that comes through, you will find
an excellent guide to the resources that are available to assist you in
using R.

Trying to learn R (as with any technical endeavor) without reading at
least a basic set of the growing list of documents, books and
publications on R is going to be problematic.

A hint for you here:

See ?by, ?tapply, ?split and ?lapply for guidance on how to generate
summary statistics on subsets of data.

HTH,

Marc Schwartz



From deepayan.sarkar at gmail.com  Wed Oct 12 22:40:23 2005
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Wed, 12 Oct 2005 15:40:23 -0500
Subject: [R] aligning column of xyplots and removing space between them
In-Reply-To: <971536df0510111820g19d584e9yec274cb3608a82d1@mail.gmail.com>
References: <971536df0510110043w2e4a47b5le0f43b03871e91a4@mail.gmail.com>
	<eb555e660510111342i4b909fcaqdee1097346344a3f@mail.gmail.com>
	<971536df0510111644o1d4be22fn4b1db8d2b87bb305@mail.gmail.com>
	<eb555e660510111800v323d0a1bxc1ed65be23a19a0a@mail.gmail.com>
	<971536df0510111820g19d584e9yec274cb3608a82d1@mail.gmail.com>
Message-ID: <eb555e660510121340s4d836728y6dc0a3d7ed6c69a9@mail.gmail.com>

On 10/11/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> On 10/11/05, Deepayan Sarkar <deepayan.sarkar at gmail.com> wrote:
> > On 10/11/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > > Thanks.  That works although the alignment is still not perfect.
> > > I am attaching the saved image in both .png and .emf formats
> > > so you can see what I mean.  Its not far off but its noticeable.
> > >
> > > In .emf format a portion of the bounding box does not come out
> > > either and it comes out bluish rather than white.  Not sure if such
> > > attachments can survive the list but I have sent you a copy too just
> > > in case.
> >
> > [I have no way to easily view the emf file, but] I can't see any
> > reason for the misalignment in the PNG file (other than a driver or
> > rendering bug). Do you see it in PDF output as well?
>
> Yes, it can be seen on the PDF version too (see attached).

Right. Looks like the horizontal paddings are to blame now. The
defaults are in terms of  "snpc" units, which produce different
physical units. The simplest workaround is to set them to 0 too, e.g.

theme.novpadding <-
  list(layout.heights =
       list(top.padding = 0,
	    main.key.padding = 0,
	    key.axis.padding = 0,
	    axis.xlab.padding = 0,
	    xlab.key.padding = 0,
	    key.sub.padding = 0,
	    bottom.padding = 0),
       layout.widths =
       list(left.padding = 0,
	    key.ylab.padding = 0,
	    ylab.axis.padding = 0,
	    axis.key.padding = 0,
	    right.padding = 0))

-Deepayan



From ggrothendieck at gmail.com  Wed Oct 12 18:26:50 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 12 Oct 2005 12:26:50 -0400
Subject: [R] adding 1 month to a date
In-Reply-To: <2a9c000c0510120904u638019a5lfd84f3741df53631@mail.gmail.com>
References: <8d5a36350510120513u1d32f44dwee638095dd90cd28@mail.gmail.com>
	<Pine.LNX.4.61.0510121320450.9181@gannet.stats>
	<1129120670.3510.73.camel@localhost.localdomain>
	<2a9c000c0510120854m76e5e233q2810167cdca966e6@mail.gmail.com>
	<2a9c000c0510120904u638019a5lfd84f3741df53631@mail.gmail.com>
Message-ID: <971536df0510120926l52a3697ey7b0d5639325f2ca8@mail.gmail.com>

The chron package will do that:

> library(chron)
> seq(chron("01/31/00"), by = "months", len = 2)[2]
[1] 02/29/00


On 10/12/05, Jim Porzak <jporzak at gmail.com> wrote:
>  OTOH,
>
>  > seq(as.Date("2004-01-31"), by = "month", length = 14)
>  [1] "2004-01-31" "2004-03-02" "2004-03-31" "2004-05-01" "2004-05-31"
>  [6] "2004-07-01" "2004-07-31" "2004-08-31" "2004-10-01" "2004-10-31"
>  [11] "2004-12-01" "2004-12-31" "2005-01-31" "2005-03-03"
>
>  I would prefer to see dates forced to be within each month, not
>  "leaking" into next month.
>
>  IOW:
>  [1] "2004-01-31" "2004-02-29" "2004-03-31" "2004-04-30" "2004-05-31", etc
>
>
>  --
>  Jim Porzak
>  Loyalty Matrix Inc.
>  San Francisco, CA
>
>
> > On 10/12/05, Marc Schwartz <MSchwartz at mn.rr.com> wrote:
> > > Thanks to Prof. Ripley for pointing this out.
> > >
> > > One of the approaches that I had considered here was to set up a vector
> > > of the number of days in each month (adjusting of course for leap
> > > years), and use "day arithmetic" to add/subtract the appropriate number
> > > of days.
> > >
> > > However, it was easier to use seq.Date() and to further consider putting
> > > a wrapper around it to make it yet even easier to use.
> > >
> > > Marc
> > >
> > > On Wed, 2005-10-12 at 13:23 +0100, Prof Brian Ripley wrote:
> > > > On Wed, 12 Oct 2005, bogdan romocea wrote:
> > > >
> > > > > Simple addition and subtraction works as well:
> > > > >  as.Date("1995/12/01",format="%Y/%m/%d") + 30
> > > > > If you have datetime values you can use
> > > > >  strptime("1995-12-01 08:00:00",format="%Y-%m-%d %H:%M:%S") + 30*24*3600
> > > > > where 30*24*3600 = 30 days expressed in seconds.
> > > >
> > > > Sorry, not in general, as a month is not generally of 30 days (including
> > > > in your example).
> > > >
> > > > seq.Date is a good way to do this.
> > > >
> > > > >
> > > > >
> > > > >> -----Original Message-----
> > > > >> From: Marc Schwartz [mailto:MSchwartz at mn.rr.com]
> > > > >> Sent: Tuesday, October 11, 2005 10:16 PM
> > > > >> To: t c
> > > > >> Cc: r-help at stat.math.ethz.ch
> > > > >> Subject: Re: [R] adding 1 month to a date
> > > > >>
> > > > >>
> > > > >> On Tue, 2005-10-11 at 16:26 -0700, t c wrote:
> > > > >>> Within an R dataset, I have a date field called date_.
> > > > >> (The dates are
> > > > >>> in the format YYYY-MM-DD, e.g. 1995-12-01.)
> > > > >>
> > > > >>> How can I add or subtract 1 month from this date, to get
> > > > >> 1996-01-01 or
> > > > >>> 1995-11-01.
> > > > >>
> > > > >> There might be an easier way to do this, but using seq.Date(), you can
> > > > >> increment or decrement from a Time 0 by months:
> > > > >>
> > > > >> Add 1 month:
> > > > >>
> > > > >> This takes your Time 0, generates a 2 element sequence (which begins
> > > > >> with Time 0) and then takes the second element:
> > > > >>
> > > > >>> seq(as.Date("1995-12-01"), by = "month", length = 2)[2]
> > > > >> [1] "1996-01-01"
> > > > >>
> > > > >>
> > > > >>
> > > > >> Subtract 1 month:
> > > > >>
> > > > >> Same as above, but we use 'by = "-1 month"' and take the
> > > > >> second element:
> > > > >>
> > > > >>> seq(as.Date("1995-12-01"), by = "-1 month", length = 2)[2]
> > > > >> [1] "1995-11-01"
> > > > >>
> > > > >>
> > > > >> See ?as.Date and ?seq.Date for more information. The former
> > > > >> function is
> > > > >> used to convert from a character vector to a Date class object. Note
> > > > >> that in your case, the date format is consistent with the default. Pay
> > > > >> attention to the 'format' argument in as.Date() if your dates
> > > > >> should be
> > > > >> in other formats.
> > > > >>
> > > > >> HTH,
> > > > >>
> > > > >> Marc Schwartz
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > >
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ggrothendieck at gmail.com  Wed Oct 12 01:54:42 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 11 Oct 2005 19:54:42 -0400
Subject: [R] adding 1 month to a date
In-Reply-To: <20051011232608.60377.qmail@web35013.mail.mud.yahoo.com>
References: <20051011232608.60377.qmail@web35013.mail.mud.yahoo.com>
Message-ID: <971536df0510111654w506afd0coa0d18a2b966827cf@mail.gmail.com>

Try this:

seq(as.Date("2005-01-15"), len = 2, by = "month")[2]

or here is another approach:

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/61570.html

On 10/11/05, t c <quantpm at yahoo.com> wrote:
>
> Within an R dataset, I have a date field called "date_".  (The dates are in the format "YYYY-MM-DD", e.g. "1995-12-01".)
>
>
>
> How can I add or subtract "1 month" from this date, to get "1996-01-01" or " "1995-11-01".
>
>
>
>
>
> ---------------------------------
>
>        [[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>



From wzhao6898 at gmail.com  Wed Oct 12 23:04:39 2005
From: wzhao6898 at gmail.com (David Zhao)
Date: Wed, 12 Oct 2005 14:04:39 -0700
Subject: [R] running JPEG device on R 1.9.1 using xvfb-run on Linux
Message-ID: <4e6115a50510121404t3e9ae86ds59c7298b86da8442@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051012/6b81e95a/attachment.pl

From davison at uchicago.edu  Wed Oct 12 23:04:50 2005
From: davison at uchicago.edu (Dan Davison)
Date: Wed, 12 Oct 2005 16:04:50 -0500 (CDT)
Subject: [R] How to install R 2.2.0 Debian 'unstable' package in otherwise
 'sarge' system
Message-ID: <Pine.GSO.4.62.0510121542520.6573@harper.uchicago.edu>

I would like to install the latest version of R (the statistical computing 
software). This is package r-base version 2.2.0 and is in the debian 
'unstable' repository. Otherwise my system has 'sarge' packages, including 
r-base 2.1.0. What is the best way to do this? If I don't want to upgrade 
to unstable, must I compile R myself, or is there some way to install this 
as a debian package?

I have tried:

(i) pointing /etc/apt/sources.list at unstable, apt-get updating and then 
apt-get install r-base. This results in

[... full output at bottom of email ...]

E: This installation run will require temporarily removing the essential
package e2fsprogs due to a Conflicts/Pre-Depends loop. This is often bad,
but if you really want to do it, activate the APT::Force-LoopBreak option.
E: Internal Error, Could not early remove e2fsprogs

which scares me into desisting with this course of action.

(ii) apt-get install -t unstable r-base, but it replies that 
r-base is already the newest version. Have I not invoked this command 
correctly, or does the -t switch not do what I was thinking it did?


Thanks very much for any help,

Dan


dd:/home/dan# apt-get install r-base
Reading Package Lists... Done
Building Dependency Tree... Done
The following extra packages will be installed:
   e2fslibs e2fsprogs gcc-3.4-base libblkid1 libc6 libc6-dev libg2c0 
libgcc1 libss2
   libuuid1 locales r-base-core r-base-dev r-recommended
Suggested packages:
   gpart parted e2fsck-static glibc-doc ess libpaper-utils
The following NEW packages will be installed:
   e2fslibs gcc-3.4-base libblkid1 libss2 libuuid1
The following packages will be upgraded:
   e2fsprogs libc6 libc6-dev libg2c0 libgcc1 locales r-base r-base-core 
r-base-dev
   r-recommended
10 upgraded, 5 newly installed, 0 to remove and 536 not upgraded.
Need to get 0B/21.4MB of archives.
After unpacking 5886kB of additional disk space will be used.
Do you want to continue? [Y/n] Y
E: This installation run will require temporarily removing the essential 
package e2fsprogs due to a Conflicts/Pre-Depends loop. This is often bad, 
but if you really want to do it, activate the APT::Force-LoopBreak option.
E: Internal Error, Could not early remove e2fsprogs



From ggrothendieck at gmail.com  Wed Oct 12 20:27:42 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 12 Oct 2005 14:27:42 -0400
Subject: [R] adding 1 month to a date
In-Reply-To: <20051012175237.13842.qmail@web35013.mail.mud.yahoo.com>
References: <20051012175237.13842.qmail@web35013.mail.mud.yahoo.com>
Message-ID: <971536df0510121127k15c4163fy135409452e17cd74@mail.gmail.com>

Try this. Note that mapply strips off the class which is why we
set up dd with the correct class and then just replaced the values.

# test data
d <- as.Date("2005-1-1") + seq(0,90,30)

# calculations, dd is the result
next.month <- function(x) seq(x, len = 2, by = "months")[2]
dd <- d
dd[] <- mapply(next.month, dd)


On 10/12/05, t c <quantpm at yahoo.com> wrote:
> Thanks.  How do I use this to calculate a new variable (e.g."data$next_month") from an existing variable (e.g."Data$date_").
>
> I tried : <data$next_month<-seq(as.Date(data$date_), len = 2, by = "month")[2]>,
>
> but get the following error message:   "Error in seq.Date(as.Date(data$date), len = 2, by = "1 month") : 'from' must be of length 1"
>
> Thanks.
>
>
>
> Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Try this:
>
> seq(as.Date("2005-01-15"), len = 2, by = "month")[2]
>
> or here is another approach:
>
> http://finzi.psych.upenn.edu/R/Rhelp02a/archive/61570.html
>
> On 10/11/05, t c wrote:
> >
> > Within an R dataset, I have a date field called "date_". (The dates are in the format "YYYY-MM-DD", e.g. "1995-12-01".)
> >
> >
> >
> > How can I add or subtract "1 month" from this date, to get "1996-01-01" or " "1995-11-01".
> >
> >
> >
> >
> >
> > ---------------------------------
> >
> > [[alternative HTML version deleted]]
> >
> >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> >
>
>
> ---------------------------------
>
>
>
> ---------------------------------
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From brian_cade at usgs.gov  Wed Oct 12 23:31:48 2005
From: brian_cade at usgs.gov (Brian S Cade)
Date: Wed, 12 Oct 2005 15:31:48 -0600
Subject: [R] subsetting with by() or other function??
Message-ID: <OF24A1F3EF.A88ED662-ON87257098.007596FF-87257098.0076A7DD@usgs.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051012/1c284bc2/attachment.pl

From cts at debian.org  Wed Oct 12 23:41:43 2005
From: cts at debian.org (Christian T. Steigies)
Date: Wed, 12 Oct 2005 23:41:43 +0200
Subject: [R] How to install R 2.2.0 Debian 'unstable' package in
	otherwise 'sarge' system
In-Reply-To: <Pine.GSO.4.62.0510121542520.6573@harper.uchicago.edu>
References: <Pine.GSO.4.62.0510121542520.6573@harper.uchicago.edu>
Message-ID: <20051012214143.GA29357@gleep.debian.net>

On Wed, Oct 12, 2005 at 04:04:50PM -0500, Dan Davison wrote:
> I would like to install the latest version of R (the statistical computing 
> software). This is package r-base version 2.2.0 and is in the debian 
> 'unstable' repository. Otherwise my system has 'sarge' packages, including 
> r-base 2.1.0. What is the best way to do this? If I don't want to upgrade 
> to unstable, must I compile R myself, or is there some way to install this 
> as a debian package?

http://cran.r-project.org/doc/FAQ/R-FAQ.html#Are-there-Unix-binaries-for-R_003f

I haven't build 2.2.0 yet, but I will probably do it next weekend. R 2.1.1
is available and you should be able to install it without too many problems
(you might have to remove a lot of r-cran packages which I all put into the
r-recommended package for the backport, I'll try to fix that for the next
version).

Christian



From ggrothendieck at gmail.com  Wed Oct 12 03:20:31 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 11 Oct 2005 21:20:31 -0400
Subject: [R] aligning column of xyplots and removing space between them
In-Reply-To: <eb555e660510111800v323d0a1bxc1ed65be23a19a0a@mail.gmail.com>
References: <971536df0510110043w2e4a47b5le0f43b03871e91a4@mail.gmail.com>
	<eb555e660510111342i4b909fcaqdee1097346344a3f@mail.gmail.com>
	<971536df0510111644o1d4be22fn4b1db8d2b87bb305@mail.gmail.com>
	<eb555e660510111800v323d0a1bxc1ed65be23a19a0a@mail.gmail.com>
Message-ID: <971536df0510111820g19d584e9yec274cb3608a82d1@mail.gmail.com>

On 10/11/05, Deepayan Sarkar <deepayan.sarkar at gmail.com> wrote:
> On 10/11/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > Thanks.  That works although the alignment is still not perfect.
> > I am attaching the saved image in both .png and .emf formats
> > so you can see what I mean.  Its not far off but its noticeable.
> >
> > In .emf format a portion of the bounding box does not come out
> > either and it comes out bluish rather than white.  Not sure if such
> > attachments can survive the list but I have sent you a copy too just
> > in case.
>
> [I have no way to easily view the emf file, but] I can't see any
> reason for the misalignment in the PNG file (other than a driver or
> rendering bug). Do you see it in PDF output as well?

Yes, it can be seen on the PDF version too (see attached).
-------------- next part --------------
A non-text attachment was scrubbed...
Name: test.pdf
Type: application/pdf
Size: 8860 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20051011/d11d31df/test.pdf

From ggrothendieck at gmail.com  Wed Oct 12 06:30:01 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 12 Oct 2005 00:30:01 -0400
Subject: [R] bug checking
In-Reply-To: <3DA00485-7B82-4658-B523-5955734103E8@mac.com>
References: <1BA44AD2-08B5-4A7F-8B2A-AF8397DF45AF@mac.com>
	<1129085243.3510.21.camel@localhost.localdomain>
	<3DA00485-7B82-4658-B523-5955734103E8@mac.com>
Message-ID: <971536df0510112130s2d11faadw17959b7b6b635d5@mail.gmail.com>

Yes, its a bug.  The calls to axis.times in plot.times use the same
col variable as the points do.  This shows it more compactly:

library(chron)
x <- seq.dates(from="09/30/2005", len = 10)
plot(x, 1:10, col = "red")

A workaround would be to plot the X axis separately:

plot(x, 1:10, col = "red", xaxt = "n")
axis.times(1, x)

or use plot.Date:

library(zoo)  # needed for as.Date.numeric
plot(as.Date(as.numeric(x)), 1:length(x), col = "red")



On 10/12/05, Parlamis Franklin <fparlamis at mac.com> wrote:
> ## Code was long, so I simplified it by creating vectors from scratch
> so it would run as is.  Putative "bug" is still evidenced on the x axis
>
> discount.factors.dates <- seq.dates(from="09/30/2005", to="09/30/2035")
> rates<-seq(4.4, 5.2, by=0.0025);
> plot(discount.factors.dates[1:length(rates)], rates,
>      pch=18, las=1, bty="n",
>      col="red", col.main="red",
>      xlab="Date", ylab="Rate",
>      ylim=c(min(rates)-(max(rates)-min(rates))/10,max(rates)+(max
> (rates)-min(rates))/10))
>
> ## This is the output:
>
>
>
>
> ## Hopefully you all see the red x axis.
>
> ## I am running R Cocoa GUI 1.1.2 with R 2.1.1 framework on a dual
> proc 2.7 Ghz Power Mac.  A Quartz device is opened when 'plot' is
> called.  X11User and X11SDK are installed on t he computer, as well
> as xCode 2.1 (in case that's relevant).
>
>
> On Oct 11, 2005, at 4:47 PM, Marc Schwartz wrote:
>
> > On Tue, 2005-10-11 at 16:07 -1000, Parlamis Franklin wrote:
> >
> >> I have observed the following behavior, wondering if it is a bug
> >> before I submit a report.
> >>
> >> I am using the plot function with call:  plot(X, Y,
> >> col="red", . . . ) where X is an object that inherits from classes
> >> 'dates' and 'times' (created with the 'dates' function from package
> >> 'chron') and y is a numeric vector.  The color red is applied to the
> >> area from the first to the last tick mark on the x axis (even if I
> >> don't set col="red" and only set, say col.main="red").
> >>
> >> If instead of feeding the function X, I feed it unclass(X) or
> >> as.vector(X) the red color is not applied to the area between the
> >> first and last ticks on the x axis.
> >>
> >> Is this a bug, or just a consequence of there not being a plot method
> >> for the class I am trying to feed the function?
> >>
> >> Franklin Parlamis
> >>
> >
> > As per the Posting Guide, it would be immensely helpful in the attempt
> > to help you, if you would provide the exact code you are using and
> > some
> > sample data here, so that we can exactly replicate what you are
> > experiencing.
> >
> > Lacking that, it would be difficult to assist as we can only guess. It
> > does sound like there is an _appropriate_ change in the plot method
> > behavior as a direct consequence of your modifying the class of the
> > argument(s), which is of course how methods are dispatched. Thus, if I
> > were to guess, this is not a bug.
> >
> > I would however, certainly recommend that you submit an example
> > here to
> > confirm the behavior, before you post a bug report, as that would
> > avoid
> > a more energetic response.
> >
> > Marc Schwartz
> >
> >
> >
>
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>



From srh3 at ualberta.ca  Wed Oct 12 23:57:36 2005
From: srh3 at ualberta.ca (Steven Hamblin)
Date: Wed, 12 Oct 2005 15:57:36 -0600
Subject: [R] Problem with a barplot...
Message-ID: <BF72E2F0.1CE0%srh3@ualberta.ca>

Hello,

I'm having a bit of a problem with a plot, and I'm hoping that someone might
be able to help.  I'm running the R Cocoa Gui v1.12 on OS X 10.4.2, and I'm
doing a stacked bar plot.  The plot itself is quite simple:

barplot(as.matrix(s.strats.in),main="Strategy when strong", col=strat.col)

where s.strats.in is a matrix with a number of rows that define the height
of each stacked bar.  However, ever since I expanded the number of columns
from 100 to 500, the borders of the bars are overwhelming the plot (the bars
are proportionally smaller, and thus the colours are getting muddied by the
black borders).  Changing the border colour doesn't help at all, and I was
hoping that there was a way to remove the borders of the bars (i.e. have
each bar snug right up against the next).  I've tried varying any parameter
that seems to have the slightest relation, but no luck.

Can someone point how to remove the borders or perhaps suggest an equivalent
way to do this with another function?  I would appreciate any and all help.

Cheers,

Steven Hamblin
-- 
Master of Arts student
Department of Psychology, University of Alberta.
Office: P-319F, Biological Sciences
Phone:  492-6681  e-mail: srh3 at ualberta.ca



From edd at debian.org  Thu Oct 13 00:03:43 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 12 Oct 2005 17:03:43 -0500
Subject: [R] How to install R 2.2.0 Debian 'unstable' package in
	otherwise 'sarge' system
In-Reply-To: <Pine.GSO.4.62.0510121542520.6573@harper.uchicago.edu>
References: <Pine.GSO.4.62.0510121542520.6573@harper.uchicago.edu>
Message-ID: <20051012220343.GA12499@eddelbuettel.com>

Dan,

First off, there is even a r-sig-debian list in the universe of R mailing
lists (c.f. the R FAQ). That probably provides a more focused readership
than the union of r-help (where many won't know Debian) and debian-user
(where many won't know R).

On Wed, Oct 12, 2005 at 04:04:50PM -0500, Dan Davison wrote:
> I would like to install the latest version of R (the statistical computing 
> software). This is package r-base version 2.2.0 and is in the debian 
> 'unstable' repository. Otherwise my system has 'sarge' packages, including 
> r-base 2.1.0. What is the best way to do this? 

Short answers: 

i) In general, and especially between 'testing' and 'unstable', use
apt-pinning, explained in the apt-howto packages, esp apt-howto-en for
English; and on various places across the Net; try Google'ing for
apt-pinning.

That way you get the option of installing selected parts of unstable without
being forced to upgrade wholesale.  Myself and countless other have used
this for years between testing and unstable.  However, I am not so sure how
well it works between stable and unstable. It may work now as stable is
fairly recent, but may fail further down the road.

ii) In this particular case, and as explained in the R FAQ, the CRAN
archives have an apt-get'able section for Debian stable. However, Christian,
the (CC'ed) maintainer of this backport was traveling between conferences in
the US and has not yet provided R 2.2.0 (which was released less than a week
ago, after all).  It should appear shortly.

> to unstable, must I compile R myself, or is there some way to install this 
> as a debian package?

You can also recompile locally using one of two ways:

iii) as a local Debian package, and apt-get source makes that almost automatic
(provided you have source URIs in /etc/apt/sources.list, and that the
Build-Depends are actually satisfiable under Debian stable), or

iv) as non-Debian compile into /usr/local

If you're in a hurry, iv) is your way.  If you're intrigued by iii), try it.
If you can wait a few days, ii) is probably your best bet.

> I have tried:
> 
> (i) pointing /etc/apt/sources.list at unstable, apt-get updating and then 
> apt-get install r-base. This results in
> 
> [... full output at bottom of email ...]
> 
> E: This installation run will require temporarily removing the essential
> package e2fsprogs due to a Conflicts/Pre-Depends loop. This is often bad,
> but if you really want to do it, activate the APT::Force-LoopBreak option.
> E: Internal Error, Could not early remove e2fsprogs
> 
> which scares me into desisting with this course of action.

I'd agree. Don't force things against warnings like this.

> (ii) apt-get install -t unstable r-base, but it replies that 
> r-base is already the newest version. Have I not invoked this command 
> correctly, or does the -t switch not do what I was thinking it did?

Did you run 'apt-get update' after altering /etc/apt/sources.list ?

Try 'apt-cache policy r-base-core' which will tell you about the versions it
knows, where they are from, and how they are prioritized (aka "pinned").

> Thanks very much for any help,

Pleasure. Let me know in private mail if this is clear enough, and we could
even follow up on a local phone call.

Greetings from across town to Hyde Park,  Dirk


> 
> Dan
> 
> 
> dd:/home/dan# apt-get install r-base
> Reading Package Lists... Done
> Building Dependency Tree... Done
> The following extra packages will be installed:
>    e2fslibs e2fsprogs gcc-3.4-base libblkid1 libc6 libc6-dev libg2c0 
> libgcc1 libss2
>    libuuid1 locales r-base-core r-base-dev r-recommended
> Suggested packages:
>    gpart parted e2fsck-static glibc-doc ess libpaper-utils
> The following NEW packages will be installed:
>    e2fslibs gcc-3.4-base libblkid1 libss2 libuuid1
> The following packages will be upgraded:
>    e2fsprogs libc6 libc6-dev libg2c0 libgcc1 locales r-base r-base-core 
> r-base-dev
>    r-recommended
> 10 upgraded, 5 newly installed, 0 to remove and 536 not upgraded.
> Need to get 0B/21.4MB of archives.
> After unpacking 5886kB of additional disk space will be used.
> Do you want to continue? [Y/n] Y
> E: This installation run will require temporarily removing the essential 
> package e2fsprogs due to a Conflicts/Pre-Depends loop. This is often bad, 
> but if you really want to do it, activate the APT::Force-LoopBreak option.
> E: Internal Error, Could not early remove e2fsprogs
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Statistics: The (futile) attempt to offer certainty about uncertainty.
         -- Roger Koenker, 'Dictionary of Received Ideas of Statistics'



From tschoenhoff at gmail.com  Thu Oct 13 00:06:12 2005
From: tschoenhoff at gmail.com (=?ISO-8859-1?Q?Thomas_Sch=F6nhoff?=)
Date: Thu, 13 Oct 2005 00:06:12 +0200
Subject: [R] How to install R 2.2.0 Debian 'unstable' package in
	otherwise 'sarge' system
In-Reply-To: <20051012214143.GA29357@gleep.debian.net>
References: <Pine.GSO.4.62.0510121542520.6573@harper.uchicago.edu>
	<20051012214143.GA29357@gleep.debian.net>
Message-ID: <5ad2dec0510121506s7b05b1fdg@mail.gmail.com>

Hi,

2005/10/12, Christian T. Steigies <cts at debian.org>:
> On Wed, Oct 12, 2005 at 04:04:50PM -0500, Dan Davison wrote:
> > I would like to install the latest version of R (the statistical computing
> > software). This is package r-base version 2.2.0 and is in the debian
> > 'unstable' repository. Otherwise my system has 'sarge' packages, including
> > r-base 2.1.0. What is the best way to do this? If I don't want to upgrade
> > to unstable, must I compile R myself, or is there some way to install this
> > as a debian package?
>
> http://cran.r-project.org/doc/FAQ/R-FAQ.html#Are-there-Unix-binaries-for-R_003f

I used the line proposed in this linked document (cut and paste) and
got an error of missformed line by apt get. Anything wrong with this?
>
> I haven't build 2.2.0 yet, but I will probably do it next weekend. R 2.1.1
> is available and you should be able to install it without too many problems
> (you might have to remove a lot of r-cran packages which I all put into the
> r-recommended package for the backport, I'll try to fix that for the next
> version).

Regards
Thomas



From kjetil at kjernsmo.net  Thu Oct 13 00:06:37 2005
From: kjetil at kjernsmo.net (Kjetil Kjernsmo)
Date: Thu, 13 Oct 2005 00:06:37 +0200
Subject: [R] How to install R 2.2.0 Debian 'unstable' package in
	otherwise 'sarge' system
In-Reply-To: <Pine.GSO.4.62.0510121542520.6573@harper.uchicago.edu>
References: <Pine.GSO.4.62.0510121542520.6573@harper.uchicago.edu>
Message-ID: <200510130006.39596.kjetil@kjernsmo.net>

On onsdag 12 oktober 2005, 23:04, Dan Davison wrote:
> What is the best way to do this? If I don't want to upgrade
> to unstable, must I compile R myself, or is there some way to install
> this as a debian package?

Then, I'd recommend using the R's own backports, this line would 
probably do the trick:
deb http://cran.us.r-project.org/bin/linux/debian stable/
and allthough it isn't there yet, it'll probably be there soon.

However, I played with apt-build the other day, and produced my own 
build. It was quite fun, so reading up on apt-build can be a nice 
exercise.

Cheers,

Kjetil
-- 
Kjetil Kjernsmo
Programmer / Astrophysicist / Ski-orienteer / Orienteer / Mountaineer
kjetil at kjernsmo.net   
Homepage: http://www.kjetil.kjernsmo.net/     OpenPGP KeyID: 6A6A0BBC



From bitwrit at ozemail.com.au  Thu Oct 13 10:12:18 2005
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Thu, 13 Oct 2005 08:12:18 +0000
Subject: [R] Problem with a barplot...
In-Reply-To: <BF72E2F0.1CE0%srh3@ualberta.ca>
References: <BF72E2F0.1CE0%srh3@ualberta.ca>
Message-ID: <434E16E2.9090007@ozemail.com.au>

Steven Hamblin wrote:
> Hello,
> 
> I'm having a bit of a problem with a plot, and I'm hoping that someone might
> be able to help.  I'm running the R Cocoa Gui v1.12 on OS X 10.4.2, and I'm
> doing a stacked bar plot.  The plot itself is quite simple:
> 
> barplot(as.matrix(s.strats.in),main="Strategy when strong", col=strat.col)
> 
> where s.strats.in is a matrix with a number of rows that define the height
> of each stacked bar.  However, ever since I expanded the number of columns
> from 100 to 500, the borders of the bars are overwhelming the plot (the bars
> are proportionally smaller, and thus the colours are getting muddied by the
> black borders).  Changing the border colour doesn't help at all, and I was
> hoping that there was a way to remove the borders of the bars (i.e. have
> each bar snug right up against the next).  I've tried varying any parameter
> that seems to have the slightest relation, but no luck.
> 
> Can someone point how to remove the borders or perhaps suggest an equivalent
> way to do this with another function?  I would appreciate any and all help.
> 
Hi Steven,

Try border=NA (not explained in the barplot help page, but elsewhere).

Jim



From ggrothendieck at gmail.com  Wed Oct 12 01:44:28 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 11 Oct 2005 19:44:28 -0400
Subject: [R] aligning column of xyplots and removing space between them
In-Reply-To: <eb555e660510111342i4b909fcaqdee1097346344a3f@mail.gmail.com>
References: <971536df0510110043w2e4a47b5le0f43b03871e91a4@mail.gmail.com>
	<eb555e660510111342i4b909fcaqdee1097346344a3f@mail.gmail.com>
Message-ID: <971536df0510111644o1d4be22fn4b1db8d2b87bb305@mail.gmail.com>

Thanks.  That works although the alignment is still not perfect.
I am attaching the saved image in both .png and .emf formats
so you can see what I mean.  Its not far off but its noticeable.

In .emf format a portion of the bounding box does not come out
either and it comes out bluish rather than white.  Not sure if such
attachments can survive the list but I have sent you a copy too just
in case.

Regards.

P.S. My R version is the following:

> packageDescription("lattice")$Version
[1] "0.12-10"
> R.version; R.version.string
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status   alpha
major    2
minor    2.0
year     2005
month    09
day      20
svn rev  35632
language R
[1] "R version 2.2.0, 2005-09-20"


On 10/11/05, Deepayan Sarkar <deepayan.sarkar at gmail.com> wrote:
> On 10/11/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > The code below displays three graphs in three rows and one column but:
> >
> > 1. I want to remove the space between the graphs (I tried playing with position=
> > arg to print.trellis but it seems quite difficult to get the right
> > values and all
> > my attempts had space between them or had overlapping graphs.  Is
> > there a better way to do this?
>
> Define
>
> theme.novpadding <- list(layout.heights =
>    list(top.padding = 0,
>         main.key.padding = 0,
>         key.axis.padding = 0,
>         axis.xlab.padding = 0,
>         xlab.key.padding = 0,
>         key.sub.padding = 0,
>         bottom.padding = 0))
>
> and then add
>
> par.settings = theme.novpadding
>
> to all your xyplot calls.
>
> > 2. the widths of the plots are not the same even though I specified the same
> > xlim= to them all.  How do I make them the same?
>
> They seem to be the same for me, but they might be different if the
> y-axis labels are different. See the 'panel.width' argument in
> ?print.trellis.
>
>
> > 3. how do I get rid of the ticks at the top of the bottom plot?
>
> add
>
> scales = list(x = list(relation = "free"))
>
> > 4. the bottom graph is supposed to plot 1:3 against itself but the third
> > point is not showing even though I specified ylim = c(0,3).  Must
> > I specify ylim = c(0,3+1) or is there a better way?
>
> There's no better way. This behaviour is intentionally different from
> base graphics.
>
> Here's a modified version of the last part of your code:
>
> grid.newpage()
>
> # n and nr are number of cells and rows
> n <- nr <- 3
> nc <- 1  # must be 1
>
> heights <- unit(c(2, rep(1, nr-1)), "null")
> downViewport(pushLayout(nr, nc, heights = heights))
>
> vpt <- current.vpTree(all = FALSE)
>
> ### relevant part starts here
> #########################
>
> xlab <- main <- function(x) if (x) "v"
> for(k in 1:n) with(vpt$children[[k]],
>       print( xyplot(v ~ v, list(v = 1:k), xlab = xlab(k == n),
>       xlim = c(0,n), ylim = c(0,n), main = main(k == 1),
>       par.settings = theme.novpadding,
>       scales = list(x = list(draw = k == n, relation = "free", c(1, 0)),
>                         y = list(alternating = 3))),
>       newpage = FALSE, panel.width = list(x = 4, units = "inches"))
> )
>
> -Deepayan
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: test.png
Type: image/png
Size: 6728 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20051011/2d9f6cc8/test.png

From madhukishore_madhu04 at yahoo.com  Thu Oct 13 00:20:42 2005
From: madhukishore_madhu04 at yahoo.com (Madhu Kishore)
Date: Wed, 12 Oct 2005 15:20:42 -0700 (PDT)
Subject: [R] Can R functions be implented in Matlab
Message-ID: <20051012222043.91499.qmail@web53308.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051012/154707bd/attachment.pl

From jennydawson1122 at hotmail.com  Thu Oct 13 00:33:53 2005
From: jennydawson1122 at hotmail.com (Jenny Dawson)
Date: Wed, 12 Oct 2005 15:33:53 -0700
Subject: [R] forcing a variable in a model
Message-ID: <BAY16-F298B3C98E5489C6FAB5700B97B0@phx.gbl>

I am interested in using polymars in R.  I will be inputting 10 X variables 
and my outcome Y variable.  I want to make sure my final model includes X1 
and any additional variables (X2-X10) chosen with the data adaptive 
regression technique.  Is this possible with polymars?

In addition, if I use the step() finction after a lm() function, can I force 
one variable to be in the final model?  I tried using the scope argument in 
the step() command, but had no luck.  I set my upper equal to my full model 
and was not sure how I tell R that my lower model must have X1 in the model.


Thank you in advance,
Jenny



From spencer.graves at pdf.com  Thu Oct 13 00:49:11 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 12 Oct 2005 15:49:11 -0700
Subject: [R] functions available for use with aggregate?
In-Reply-To: <434D5391.1030705@pdf.com>
References: <20051012181013.27903.qmail@web35011.mail.mud.yahoo.com>
	<434D5391.1030705@pdf.com>
Message-ID: <434D92E7.70206@pdf.com>

	  1.  There is also "aggregate.zoo" in the "zoo" package.

	  2.  If your question is which functions can be used for the "FUN" 
argument, you can write your own.  For example:

 > set.seed(1)
 > tstDF <- data.frame(x=rep(1:4, e=2),
+                     y=rnorm(8))
 > aggregate(tstDF[2], tstDF[1],
+           function(z)max(z)/min(z))
   x          y
1 1 -0.2931474
2 2 -1.9090787
3 3 -0.4016093
4 4  1.5147327
 >
	  spencer graves

Sundar Dorai-Raj wrote:

> 
> t c wrote:
> 
>>What are the functions available for use with ?aggregate??  Where can a reference to them be found?
>>
>> 
> 
> 
> Since aggregate is a S3 generic, you can use
> 
> methods(aggregate)
> 
> to see what objects have an "aggregate" method. For me, I have the 
> following:
> 
>  > methods(aggregate)
> [1] aggregate.data.frame aggregate.default    aggregate.frm*
> [4] aggregate.ts
> 
>     Non-visible functions are asterisked
>  >
> 
> See ?methods for more details.
> 
> HTH,
> 
> --sundar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From Ted.Harding at nessie.mcc.ac.uk  Thu Oct 13 00:56:34 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 12 Oct 2005 23:56:34 +0100 (BST)
Subject: [R] Can R functions be implented in Matlab
In-Reply-To: <20051012222043.91499.qmail@web53308.mail.yahoo.com>
Message-ID: <XFMail.051012235634.Ted.Harding@nessie.mcc.ac.uk>

On 12-Oct-05 Madhu Kishore wrote:
> Hi,
>      I am Madhu Kishore a Graduate student at University of Texas at El
> Paso in Electrical Engineering.  I am using R language for Normality
> tests and my doubt is can implements the R functions in Matlab.  I
> expect to hear from you soon.
> Madhu kishore.

Some of the simpler R functions could be implemented in MatLab with
equivalent effect; in particular, anything which depends mainly on
straightforward array (especially matrix and vector) calculations
should not be too difficult. You are also likely to find MatLab
functions which implement many of the computations in various
normality tests directly, so you should not need to rewrite these;
just use the MatLab functions.

However, don't even think of emulating anything extensive from R
in MatLab! Not only would you ever finish your studies, you would
probably never finish you R->MatLab project. They are quite
different programming languages, and even something as basic
as getting MatLab to emulate the R command

  summary(lm(y ~ A*B))

would be a major task if undertaken from scratch.

Why not just use one or the other, whichever best suits your
purpose of the moment?

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 12-Oct-05                                       Time: 23:55:45
------------------------------ XFMail ------------------------------



From ggrothendieck at gmail.com  Thu Oct 13 01:04:32 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 12 Oct 2005 19:04:32 -0400
Subject: [R] Can R functions be implented in Matlab
In-Reply-To: <20051012222043.91499.qmail@web53308.mail.yahoo.com>
References: <20051012222043.91499.qmail@web53308.mail.yahoo.com>
Message-ID: <971536df0510121604w35d84fcei6e39c087f567c321@mail.gmail.com>

The following might help:

http://cran.r-project.org/doc/contrib/R-and-octave-2.txt

On 10/12/05, Madhu Kishore <madhukishore_madhu04 at yahoo.com> wrote:
> Hi,
>     I am Madhu Kishore a Graduate student at University of Texas at El Paso in Electrical Engineering.  I am using R language for Normality tests and my doubt is can implements the R functions in Matlab.  I expect to hear from you soon.
> Madhu kishore.
>
>
> ---------------------------------
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From srh3 at ualberta.ca  Thu Oct 13 01:15:14 2005
From: srh3 at ualberta.ca (Steven Hamblin)
Date: Wed, 12 Oct 2005 17:15:14 -0600
Subject: [R] Problem with a barplot...
In-Reply-To: <434E16E2.9090007@ozemail.com.au>
Message-ID: <BF72F522.1CE9%srh3@ualberta.ca>

Jim,

Thanks for the suggestion!  It worked great.  (I wonder why that isn't
documented in the help file for barplot...seems logical to me.  <shrug>)

Cheers,

Steven Hamblin
-- 
Master of Arts student
Department of Psychology, University of Alberta.
Office: P-319F, Biological Sciences
Phone:  492-6681  e-mail: srh3 at ualberta.ca


On 10/13/05 2:12 AM, "Jim Lemon" <bitwrit at ozemail.com.au> wrote:

> Steven Hamblin wrote:
>> Hello,
>> 
>> I'm having a bit of a problem with a plot, and I'm hoping that someone might
>> be able to help.  I'm running the R Cocoa Gui v1.12 on OS X 10.4.2, and I'm
>> doing a stacked bar plot.  The plot itself is quite simple:
>> 
>> barplot(as.matrix(s.strats.in),main="Strategy when strong", col=strat.col)
>> 
>> where s.strats.in is a matrix with a number of rows that define the height
>> of each stacked bar.  However, ever since I expanded the number of columns
>> from 100 to 500, the borders of the bars are overwhelming the plot (the bars
>> are proportionally smaller, and thus the colours are getting muddied by the
>> black borders).  Changing the border colour doesn't help at all, and I was
>> hoping that there was a way to remove the borders of the bars (i.e. have
>> each bar snug right up against the next).  I've tried varying any parameter
>> that seems to have the slightest relation, but no luck.
>> 
>> Can someone point how to remove the borders or perhaps suggest an equivalent
>> way to do this with another function?  I would appreciate any and all help.
>> 
> Hi Steven,
> 
> Try border=NA (not explained in the barplot help page, but elsewhere).
> 
> Jim
>



From tonyyangsxz_chn at yahoo.com  Thu Oct 13 03:26:52 2005
From: tonyyangsxz_chn at yahoo.com (Zhao Yang)
Date: Wed, 12 Oct 2005 18:26:52 -0700 (PDT)
Subject: [R] About Qusi-Monte carlo program
Message-ID: <20051013012652.78696.qmail@web35514.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051012/a121b6ee/attachment.pl

From jhainm at fas.harvard.edu  Thu Oct 13 03:52:30 2005
From: jhainm at fas.harvard.edu (Jens Hainmueller)
Date: Wed, 12 Oct 2005 21:52:30 -0400
Subject: [R] Optim with two constraints
Message-ID: <200510130152.j9D1qWWF023834@us20.unix.fas.harvard.edu>

Hi R-list,

I am new to optimization in R and would appreciate help on the following
question. I would like to minimize the following function using two
constraints:

######
fn <- function(par,H,F){
      
     fval <- 0.5 * t(par) %*% H %*% par + F%*% par
     fval  
  
  }

# matrix H is (n by k)
# matrix F is (n by 1) 
# par is a (n by 1) set of weights 

# I need two constraints:
# 1. each element in par needs to be between 0 and 1
# 2. sum(par)=1 i.e. the elements in par need to sum to 1

## I try to use optim
res <- optim(c(runif(16),fn, method="L-BFGS-B", H=H, F=f
,control=list(fnscale=-1), lower=0, upper=1)
######

If I understand this correctly, using L-BFGS-B with lower=0 and upper=1
should take care of constraint 1 (box constraints). What I am lacking is the
skill to include constraint no 2.

I guess I could solve this by reparametrization but I am not sure how
exactly. I could not find (i.e. wasn't able to infer) the answer to this in
the archives despite the many comments on optim and constrained optimization
(sorry if I missed it there). I am using version 2.1.1 under windows XP.

Thank you very much.

Jens



From unung at enciety.com  Thu Oct 13 04:11:29 2005
From: unung at enciety.com (Unung Istopo Hartanto)
Date: Thu, 13 Oct 2005 09:11:29 +0700
Subject: [R] R Linux Live On CD
Message-ID: <1129169489.2976.24.camel@IT05>

Dear UseR,

We've build R live on CD, you can download R iso in :

http://kambing.vlsm.org/debian-cd/renceity/

or

http://mirror.eepis-its.edu/pub/linux-iso/renciety/renciety-15092005.iso

Thanks for all R project teams and we receive your critics and suggests.

Regards,
-- 
Unung Istopo Hartanto
------------------------------------------------
ENCIETY Business Consult
Jl. Manyar Tirtoyoso Utara V/7
Telp. +62-31-5992340, Fax. +62-31-5994230
www.enciety.com



From duncan at wald.ucdavis.edu  Thu Oct 13 05:55:45 2005
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Wed, 12 Oct 2005 20:55:45 -0700
Subject: [R] Can R functions be implented in Matlab
In-Reply-To: <971536df0510121604w35d84fcei6e39c087f567c321@mail.gmail.com>
References: <20051012222043.91499.qmail@web53308.mail.yahoo.com>
	<971536df0510121604w35d84fcei6e39c087f567c321@mail.gmail.com>
Message-ID: <434DDAC1.8080502@wald.ucdavis.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1



And additionally, there is an R-Matlab interface that may work
for you. Currently it only works for Unix.

  http://www.omegahat.org/RMatlab

 D.


Gabor Grothendieck wrote:
> The following might help:
> 
> http://cran.r-project.org/doc/contrib/R-and-octave-2.txt
> 
> On 10/12/05, Madhu Kishore <madhukishore_madhu04 at yahoo.com> wrote:
> 
>>Hi,
>>    I am Madhu Kishore a Graduate student at University of Texas at El Paso in Electrical Engineering.  I am using R language for Normality tests and my doubt is can implements the R functions in Matlab.  I expect to hear from you soon.
>>Madhu kishore.
>>
>>
>>---------------------------------
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

- --
Duncan Temple Lang                duncan at wald.ucdavis.edu
Department of Statistics          work:  (530) 752-4782
371 Kerr Hall                     fax:   (530) 752-7099
One Shields Ave.
University of California at Davis
Davis, CA 95616, USA
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.2 (Darwin)
Comment: Using GnuPG with Thunderbird - http://enigmail.mozdev.org

iD8DBQFDTdrB9p/Jzwa2QP4RAqEMAJ4nY2wbnmmeUcJauJYklMxeGdYGsQCdGl8t
GxyYThnHgflC3GbnBdVYdBE=
=pSzz
-----END PGP SIGNATURE-----



From ripley at stats.ox.ac.uk  Thu Oct 13 08:29:05 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 13 Oct 2005 07:29:05 +0100 (BST)
Subject: [R] running JPEG device on R 1.9.1 using xvfb-run on Linux
In-Reply-To: <4e6115a50510121404t3e9ae86ds59c7298b86da8442@mail.gmail.com>
References: <4e6115a50510121404t3e9ae86ds59c7298b86da8442@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0510130722190.28998@gannet.stats>

On Wed, 12 Oct 2005, David Zhao wrote:

> Does anybody have experience in running jpeg device using xvfb-run on
> linux? I've been having sporadic problem with: /usr/X11/bin/xvfb-run
> /usr/bin/R --no-save < Rinput.txt, with error saying: error in X11
> connection. Especially when I run it from a perl script.

Not sure what `xvfb-run on Linux' is, as it is not on my Linux (FC3).
If you Google it you will find a number of problems reported on Debian 
lists.  Here I would suspect timing.

What I do is to run Xvfb on screen 5 by

Xvfb :5 &
setenv DISPLAY :5

and do not have a problem with the jpeg() or png() devices.  I do have a 
problem with the rgl() package, but then I often do on-screen (on both 32- 
and even more so 64-bit FC3).

> Is there a better way of doing this? or how can I fix the problem.

You really should update your R.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Oct 13 08:40:06 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 13 Oct 2005 07:40:06 +0100 (BST)
Subject: [R] About Qusi-Monte carlo program
In-Reply-To: <20051013012652.78696.qmail@web35514.mail.mud.yahoo.com>
References: <20051013012652.78696.qmail@web35514.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.61.0510130734300.28998@gannet.stats>

I suspect you mean `Quasi-Monte Carlo', but that is used to do integration 
not simulation.

Using help.search led ne to

LowDiscrepancy(fOptions)
                         Low Discrepancy Sequences
QUnif(sfsmisc)          Quasi Randum Numbers via Halton Sequences

both of which generate the integration points for Quasi-Monte Carlo.


On Wed, 12 Oct 2005, Zhao Yang wrote:

> Dear Listers;
>
> Does anybody has experience in doing simulation via Qusi-Monte carlo in 
> R or S-plus, if so, could you like to send a small copy of your program 
> to me, I appreciate and thanks in advance!!
>
> Frankly speaking, I am struggling to write this kind of program, while I 
> could not figure out, painful!!!!!
>
> Best regards,
> Tony

> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

PLEASE do, and not send HTML mail as it asks.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Oct 13 08:46:08 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 13 Oct 2005 07:46:08 +0100 (BST)
Subject: [R] Optim with two constraints
In-Reply-To: <200510130152.j9D1qWWF023834@us20.unix.fas.harvard.edu>
References: <200510130152.j9D1qWWF023834@us20.unix.fas.harvard.edu>
Message-ID: <Pine.LNX.4.61.0510130740230.28998@gannet.stats>

This is actually quadratic programming, so why do you want to use optim()?
There are packages specifically for QP, e.g. quadprog.

A more general approach is to eliminate one variable, which gives you an 
inequality constrained problem in n-1 variables to which you could apply 
contrOptim().  Other re-parametrizations (e.g. of weights as a 
log-linear model) will work provided none of the parameters are going to 
be zero at the optimum (one cannot be one without all the others being 
zero).

On Wed, 12 Oct 2005, Jens Hainmueller wrote:

> Hi R-list,
>
> I am new to optimization in R and would appreciate help on the following
> question. I would like to minimize the following function using two
> constraints:
>
> ######
> fn <- function(par,H,F){
>
>     fval <- 0.5 * t(par) %*% H %*% par + F%*% par
>     fval
>
>  }
>
> # matrix H is (n by k)
> # matrix F is (n by 1)
> # par is a (n by 1) set of weights
>
> # I need two constraints:
> # 1. each element in par needs to be between 0 and 1
> # 2. sum(par)=1 i.e. the elements in par need to sum to 1
>
> ## I try to use optim
> res <- optim(c(runif(16),fn, method="L-BFGS-B", H=H, F=f
> ,control=list(fnscale=-1), lower=0, upper=1)
> ######
>
> If I understand this correctly, using L-BFGS-B with lower=0 and upper=1
> should take care of constraint 1 (box constraints). What I am lacking is the
> skill to include constraint no 2.
>
> I guess I could solve this by reparametrization but I am not sure how
> exactly. I could not find (i.e. wasn't able to infer) the answer to this in
> the archives despite the many comments on optim and constrained optimization
> (sorry if I missed it there). I am using version 2.1.1 under windows XP.
>
> Thank you very much.
>
> Jens
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From john.maindonald at anu.edu.au  Thu Oct 13 09:10:00 2005
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 13 Oct 2005 17:10:00 +1000
Subject: [R] arima: warning when fixing MA parameters.
Message-ID: <BC8BB8E6-FCEE-4E76-9090-67819A5B3984@anu.edu.au>

I am puzzled by the warning message in the output below.  It appears
whether or not I fit the seasonal term (but the precise point of doing
this was to fit what is effectively a second seasonal term).  Is there
some deep reason why AR parameters
("Warning message: some AR parameters were fixed: ...")
should somehow intrude into the fitting of a model that has only MA  
terms?

 > library(DAAG)
 > attach(bomsoi)
 > # The following is fine:
 > arima(avrain, order=c(0,0,4), seasonal=list(order=c(0,0,1),  
period=12),
+  fixed=c(NA,0,0,NA,NA,NA))
.....
 > # The following generates a warning message
 > arima(avrain, order=c(0,0,4), seasonal=list(order=c(0,0,1),  
period=12),
+  fixed=c(0,0,0,NA,NA,NA))

Call:
arima(x = avrain, order = c(0, 0, 4), seasonal = list(order = c(0, 0,  
1), period = 12),
     fixed = c(0, 0, 0, NA, NA, NA))

Coefficients:
       ma1  ma2  ma3     ma4     sma1  intercept
         0    0    0  0.0357  -0.1061   456.6675
s.e.    0    0    0  0.1015   0.0886     7.6997

sigma^2 estimated as 6849:  log likelihood = -595.23,  aic = 1198.46
Warning message:
some AR parameters were fixed: setting transform.pars = FALSE in:  
arima(avrain, order = c(0, 0, 4), seasonal = list(order = c(0,


John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Bioinformation Science, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.



From tchur at optusnet.com.au  Thu Oct 13 09:56:36 2005
From: tchur at optusnet.com.au (Tim Churches)
Date: Thu, 13 Oct 2005 17:56:36 +1000
Subject: [R] running JPEG device on R 1.9.1 using xvfb-run on Linux
In-Reply-To: <Pine.LNX.4.61.0510130722190.28998@gannet.stats>
References: <4e6115a50510121404t3e9ae86ds59c7298b86da8442@mail.gmail.com>
	<Pine.LNX.4.61.0510130722190.28998@gannet.stats>
Message-ID: <434E1334.3030104@optusnet.com.au>

Prof Brian Ripley wrote:
> On Wed, 12 Oct 2005, David Zhao wrote:
> 
> 
>>Does anybody have experience in running jpeg device using xvfb-run on
>>linux? I've been having sporadic problem with: /usr/X11/bin/xvfb-run
>>/usr/bin/R --no-save < Rinput.txt, with error saying: error in X11
>>connection. Especially when I run it from a perl script.
> 
> 
> Not sure what `xvfb-run on Linux' is, as it is not on my Linux (FC3).
> If you Google it you will find a number of problems reported on Debian 
> lists.  Here I would suspect timing.
> 
> What I do is to run Xvfb on screen 5 by
> 
> Xvfb :5 &
> setenv DISPLAY :5
> 
> and do not have a problem with the jpeg() or png() devices.  I do have a 
> problem with the rgl() package, but then I often do on-screen (on both 32- 
> and even more so 64-bit FC3).

For R-embedded-in-Python (via RPy) on a Web server, we have been using a
Python programme to automatically start Xvfb if it is not already
running. You can find a copy of the programme in the NetEpi-Analysis
tarball available at
http://sourceforge.net/project/showfiles.php?group_id=123700

The tricky bit is managing the permissions for the Xvfb session,
particularly in a Web server context - you need to take care. However,
this use of Xvfb has been perfectly reliable (on Red Hat Enterprise
Linux 2.1 and 3 with R2.0 and R 2.1)
> 
>>Is there a better way of doing this? or how can I fix the problem.
> 
> You really should update your R.

Yes. We now use GDD, which is an alternative R graphics driver for
raster graphics (Jpeg and PNG), available via CRAN. It allows R to
directly generate jpeg and png files on a Linux or Unix machine without
the need for an X server to be running (not even Xvfb). The quality of
the output is also better than the standard R X11/png/jpeg graphics
device due to the use of anti-aliased fonts by GDD. Earlier versions of
GDD were a bit buggy, but so far we have found the latest version
(0.1.7) to be fine. It is a bit fiddly to install all the libraries it
requires as well as  the recommended (no-cost) Microsoft TrueType fonts,
but the effort is worth it. Many thanks to Simon Urbanek for his work on
GDD.

Tim C



From herodote at oreka.com  Thu Oct 13 11:26:36 2005
From: herodote at oreka.com (=?iso-8859-1?Q?herodote@oreka.com?=)
Date: Thu, 13 Oct 2005 10:26:36 +0100
Subject: [R] =?iso-8859-1?q?drawing_against_a_date?=
Message-ID: <IOAKWC$A24FE83BF17B2070E56B0D4D01E655E3@oreka.com>

hy all

I wish to draw a graph against a date,
I have a set of date like this DD/MM/YYYY, corresponding to it a set of integer , i wish to draw on x side the dates (the space between the dates have to be constant, not based on the time between 2 dates but on the number of dates) and on y side the integers.

Do i have to make a tricky function under R ?

I've search the help for graphical functions but my poor english seems to make me missing the solution...

thks for your help
guillaume.



From rob.foxall at bbsrc.ac.uk  Thu Oct 13 12:03:09 2005
From: rob.foxall at bbsrc.ac.uk (rob foxall (IFR))
Date: Thu, 13 Oct 2005 11:03:09 +0100
Subject: [R] Help with Matrix package
Message-ID: <1CF0B26CECD746438AE02DBF7DDE1C7B020A5BA5@ifre2knas1.ifrxp.bbsrc.reserved>

Hello all,
	A colleague at work set me the challenge to convert some MATLAB
code into R, to see which is faster. We'd seen that benchmark comparing
MATLAB 6.5 to R1.90 (and others), and so I thought that I should be able
to get roughly comparable speeds. The code has lots of multiplications
of matrixes, transposes, and MATLAB's "repmat". I did the code
conversion, and R was about 6 times slower, so I had a closer look at
the benchmark comparison and it seems that I should be using the
"Matrix" package.
	Is there any dummies-level help available for this package? I am
struggling even to apply simple functions such as "sum" and "mean" to
matrixes constructed from this class (not that I need to yet), and more
importantly "kronecker", to convert from "repmat". (The help for
"kronecker" from the Matrix package doesn't seem to mention kronecker,
so I am a bit stuck). Any guidance greatly accepted -- I have read the
overview, looked through the various Matrix-listed functions, and
unsuccessfully tried searching R-help.

Using R version 2.2.0, windows xp.

Cheers,
	Rob.



From subianto at gmail.com  Thu Oct 13 12:19:47 2005
From: subianto at gmail.com (Muhammad Subianto)
Date: Thu, 13 Oct 2005 12:19:47 +0200
Subject: [R] expand.grid problem
Message-ID: <434E34C3.2030707@gmail.com>

Hi all,
I want to make all possible combination from dataset below:
  V1   <- c(0,1,2)
  V2   <- c(0,1)
  V3   <- c(0,1)
  V4   <- c(0,1)
  V5   <- c(0,1)
  V6   <- c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)
  V7   <- c(0,1,2,3,4,5,6)
  V8   <- c(0,1)
  V9   <- c(0,1)
  V10  <- c(0,1)
  V11  <- c(0,1)
  V12  <- c(0,1)
  V13  <- c(0,1)
  V14  <- c(0,1)
  V15  <- c(0,1,2,3,4,5,6,7,8,9)
  V16  <- c(0,1,2,3,4,5,6)
  V17  <- c(0,1,2,3,4,5,6,7,8)
  V18  <- c(0,1,2,3,4,5)
  V19  <- c(0,1)
  V20  <- c(0,1,2,3,4,5,6,7)

When run expand.grid I found a problem:
 >   all.V  <- 
expand.grid(V1,V2,V3,V4,V5,V6,V7,V8,V9,V10,V11,V12,V13,V14,V15,V16,V17,V18,V19,V20)
Error in rep.int(rep.int(x, rep.int(rep.fac, nx)), orep) :
        invalid number of copies in rep()
In addition: Warning message:
NAs introduced by coercion
 >  

Then I try to reduce:
 >   all.V.miss  <- 
expand.grid(V1,V2,V3,V4,V5,V7,V8,V9,V10,V11,V17,V18,V19,V20)  
Error: cannot allocate vector of size 36288 Kb
 >
What is that? Is this about memory or I must run on machine 64bit?

Regards, Muhammad Subianto
P4 2.0GHz 512MB RAM

 > R.version$platform
[1] "i686-redhat-linux-gnu"
 > R.version$major
[1] "2"
 > R.version$minor
[1] "1.1"
 > R.version$year
[1] "2005"
 > R.version$month
[1] "06"
 > R.version$language
[1] "R"



From ripley at stats.ox.ac.uk  Thu Oct 13 12:27:45 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 13 Oct 2005 11:27:45 +0100 (BST)
Subject: [R] =?iso-8859-1?q?drawing_against_a_date?=
In-Reply-To: <IOAKWC$A24FE83BF17B2070E56B0D4D01E655E3@oreka.com>
References: <IOAKWC$A24FE83BF17B2070E56B0D4D01E655E3@oreka.com>
Message-ID: <Pine.LNX.4.61.0510131125100.4207@gannet.stats>

On Thu, 13 Oct 2005, herodote at oreka.com wrote:

> hy all
>
> I wish to draw a graph against a date, I have a set of date like this 
> DD/MM/YYYY, corresponding to it a set of integer , i wish to draw on x 
> side the dates (the space between the dates have to be constant, not 
> based on the time between 2 dates but on the number of dates) and on y 
> side the integers.
>
> Do i have to make a tricky function under R ?
>
> I've search the help for graphical functions but my poor english seems 
> to make me missing the solution...

First convert your dates to R's date format by as.Date, then see ?plot.Date.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Oct 13 12:32:30 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 13 Oct 2005 11:32:30 +0100 (BST)
Subject: [R] Help with Matrix package
In-Reply-To: <1CF0B26CECD746438AE02DBF7DDE1C7B020A5BA5@ifre2knas1.ifrxp.bbsrc.reserved>
References: <1CF0B26CECD746438AE02DBF7DDE1C7B020A5BA5@ifre2knas1.ifrxp.bbsrc.reserved>
Message-ID: <Pine.LNX.4.61.0510131128080.4207@gannet.stats>

The first thing is to ensure that you are using an optimized BLAS.  On 
Windows, use Goto's BLAS if you have it (is not currently available and 
redistribution is not allowed) or one of the pre-built ATLAS-based 
Rblas.dll on CRAN or (best of all) optimize your own build of ATLAS.

The Matrix package depends on an optimized BLAS even more crucially than 
base R.

On Thu, 13 Oct 2005, rob foxall (IFR) wrote:

> Hello all,
> 	A colleague at work set me the challenge to convert some MATLAB
> code into R, to see which is faster. We'd seen that benchmark comparing
> MATLAB 6.5 to R1.90 (and others), and so I thought that I should be able
> to get roughly comparable speeds. The code has lots of multiplications
> of matrixes, transposes, and MATLAB's "repmat". I did the code
> conversion, and R was about 6 times slower, so I had a closer look at
> the benchmark comparison and it seems that I should be using the
> "Matrix" package.
> 	Is there any dummies-level help available for this package? I am
> struggling even to apply simple functions such as "sum" and "mean" to
> matrixes constructed from this class (not that I need to yet), and more
> importantly "kronecker", to convert from "repmat". (The help for
> "kronecker" from the Matrix package doesn't seem to mention kronecker,
> so I am a bit stuck). Any guidance greatly accepted -- I have read the
> overview, looked through the various Matrix-listed functions, and
> unsuccessfully tried searching R-help.
>
> Using R version 2.2.0, windows xp.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rob.foxall at bbsrc.ac.uk  Thu Oct 13 12:39:12 2005
From: rob.foxall at bbsrc.ac.uk (rob foxall (IFR))
Date: Thu, 13 Oct 2005 11:39:12 +0100
Subject: [R] Help with Matrix package
Message-ID: <1CF0B26CECD746438AE02DBF7DDE1C7B0237006D@ifre2knas1.ifrxp.bbsrc.reserved>

Thanks Prof. Ripley for your prompt reply. With regards to Rblas.dll my
current situation is that I have taken the Rblas.dll from CRAN:
contrib/ATLAS/P4/, and replaced the default Rblas.dll in my R /bin with
this one.

Cheers,
	Rob.

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: 13 October 2005 11:33
To: rob foxall (IFR)
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Help with Matrix package

The first thing is to ensure that you are using an optimized BLAS.  On 
Windows, use Goto's BLAS if you have it (is not currently available and 
redistribution is not allowed) or one of the pre-built ATLAS-based 
Rblas.dll on CRAN or (best of all) optimize your own build of ATLAS.

The Matrix package depends on an optimized BLAS even more crucially than

base R.

On Thu, 13 Oct 2005, rob foxall (IFR) wrote:

> Hello all,
> 	A colleague at work set me the challenge to convert some MATLAB
> code into R, to see which is faster. We'd seen that benchmark
comparing
> MATLAB 6.5 to R1.90 (and others), and so I thought that I should be
able
> to get roughly comparable speeds. The code has lots of multiplications
> of matrixes, transposes, and MATLAB's "repmat". I did the code
> conversion, and R was about 6 times slower, so I had a closer look at
> the benchmark comparison and it seems that I should be using the
> "Matrix" package.
> 	Is there any dummies-level help available for this package? I am
> struggling even to apply simple functions such as "sum" and "mean" to
> matrixes constructed from this class (not that I need to yet), and
more
> importantly "kronecker", to convert from "repmat". (The help for
> "kronecker" from the Matrix package doesn't seem to mention kronecker,
> so I am a bit stuck). Any guidance greatly accepted -- I have read the
> overview, looked through the various Matrix-listed functions, and
> unsuccessfully tried searching R-help.
>
> Using R version 2.2.0, windows xp.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From lassana.koita at aviation-civile.gouv.fr  Thu Oct 13 12:47:27 2005
From: lassana.koita at aviation-civile.gouv.fr (KOITA Lassana - STAC/ACE)
Date: Thu, 13 Oct 2005 12:47:27 +0200
Subject: [R] problems with loop and plot function
Message-ID: <OF027D6B89.BD6953F1-ONC1257099.003A1567@aviation-civile.gouv.fr>





Hi all R users,

I have problems with my second loop for drawing the three curves in the
same graphic. I need help please

Thank you in advance

#########################################################################

simulation <- function(k, n){

conc <- seq(0,100,by=0.5)
#choixg <- seq(1, length(conc))
choixg <- rep(0,length(conc))
for (i in 1:length(conc)){
    choixg[i] <- (k + conc[i])^n/((k+conc[i])^n + (k+1)^n)

    }
   #return(data.frame(choixg, conc))
   return(list(choixg=choixg, conc = conc))
}
#cbind(simResult$conc, simResult$choixg, format(Sys.time(),"%H:%M:%S"))

for( n in c(1,3,5)) {
 x <- NULL; y <- NULL
 simResult <- simulation (5,n)
 conc <- simResult$conc
 choixg <- simResult$choixg
 prin("n");  print(c(k=5, n))
 points(conc, log10(1-choixg), main ="fonction de choix", col= n, pch=20,
lwd = 3,
xlab = " concentration", ylab="proba de choisir la gauche", type="l")
}


#########################################################################


Lassana KOITA
Etude S??curit?? et Exploitation a??roportuaires / Aerodrome Safety &
Statistical analysis
Service Technique de l'Aviation Civile (STAC) / Civil Aviation Technical
Department
Direction G??n??rale de l'Aviation Civile (DGAC) / French Civil Aviation
Tel: 01 49 56 80 60
Fax: 01 49 56 82 14
E-mail: Lassana.Koita at aviation-civile.gouv.fr



From petr.pikal at precheza.cz  Thu Oct 13 13:33:40 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 13 Oct 2005 13:33:40 +0200
Subject: [R] problems with loop and plot function
In-Reply-To: <OF027D6B89.BD6953F1-ONC1257099.003A1567@aviation-civile.gouv.fr>
Message-ID: <434E6234.4818.855915@localhost>

Hi

you forgot to plot something before adding points (and actually 
you wanted lines).

plot(conc, log10(1-choixg), main ="fonction de choix", col= n,
pch=20,
lwd = 3,
xlab = " concentration", ylab="proba de choisir la gauche", type="n")

for( n in c(1,3,5)) {
 x <- NULL; y <- NULL
 simResult <- simulation (5,n)
 conc <- simResult$conc
 choixg <- simResult$choixg
 print("n");  print(c(k=5, n)) ### what is this???
 lines(conc, log10(1-choixg))
}

Isn't it time to read some introductory texts?
:-)


HTH
Petr

On 13 Oct 2005 at 12:47, KOITA Lassana - STAC/ACE wrote:

To:             	R-help at stat.math.ethz.ch
From:           	"KOITA Lassana - STAC/ACE" <lassana.koita at aviation-civile.gouv.fr>
Date sent:      	Thu, 13 Oct 2005 12:47:27 +0200
Subject:        	[R] problems with loop and plot function

> 
> 
> 
> 
> Hi all R users,
> 
> I have problems with my second loop for drawing the three curves in
> the same graphic. I need help please
> 
> Thank you in advance
> 
> ######################################################################
> ###
> 
> simulation <- function(k, n){
> 
> conc <- seq(0,100,by=0.5)
> #choixg <- seq(1, length(conc))
> choixg <- rep(0,length(conc))
> for (i in 1:length(conc)){
>     choixg[i] <- (k + conc[i])^n/((k+conc[i])^n + (k+1)^n)
> 
>     }
>    #return(data.frame(choixg, conc))
>    return(list(choixg=choixg, conc = conc))
> }
> #cbind(simResult$conc, simResult$choixg,
> #format(Sys.time(),"%H:%M:%S"))
> 
> for( n in c(1,3,5)) {
>  x <- NULL; y <- NULL
>  simResult <- simulation (5,n)
>  conc <- simResult$conc
>  choixg <- simResult$choixg
>  prin("n");  print(c(k=5, n))
>  points(conc, log10(1-choixg), main ="fonction de choix", col= n,
>  pch=20,
> lwd = 3,
> xlab = " concentration", ylab="proba de choisir la gauche", type="l")
> }
> 
> 
> ######################################################################
> ###
> 
> 
> Lassana KOITA
> Etude S??curit?? et Exploitation a??roportuaires / Aerodrome Safety &
> Statistical analysis Service Technique de l'Aviation Civile (STAC) /
> Civil Aviation Technical Department Direction G??n??rale de l'Aviation
> Civile (DGAC) / French Civil Aviation Tel: 01 49 56 80 60 Fax: 01 49
> 56 82 14 E-mail: Lassana.Koita at aviation-civile.gouv.fr
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From plummer at iarc.fr  Thu Oct 13 13:45:50 2005
From: plummer at iarc.fr (Martyn Plummer)
Date: Thu, 13 Oct 2005 13:45:50 +0200
Subject: [R] expand.grid problem
In-Reply-To: <434E34C3.2030707@gmail.com>
References: <434E34C3.2030707@gmail.com>
Message-ID: <1129203950.8120.5.camel@seurat>

On Thu, 2005-10-13 at 12:19 +0200, Muhammad Subianto wrote:
> Hi all,
> I want to make all possible combination from dataset below:
>   V1   <- c(0,1,2)
>   V2   <- c(0,1)
>   V3   <- c(0,1)
>   V4   <- c(0,1)
>   V5   <- c(0,1)
>   V6   <- c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)
>   V7   <- c(0,1,2,3,4,5,6)
>   V8   <- c(0,1)
>   V9   <- c(0,1)
>   V10  <- c(0,1)
>   V11  <- c(0,1)
>   V12  <- c(0,1)
>   V13  <- c(0,1)
>   V14  <- c(0,1)
>   V15  <- c(0,1,2,3,4,5,6,7,8,9)
>   V16  <- c(0,1,2,3,4,5,6)
>   V17  <- c(0,1,2,3,4,5,6,7,8)
>   V18  <- c(0,1,2,3,4,5)
>   V19  <- c(0,1)
>   V20  <- c(0,1,2,3,4,5,6,7)
> 
> When run expand.grid I found a problem:
>  >   all.V  <- 
> expand.grid(V1,V2,V3,V4,V5,V6,V7,V8,V9,V10,V11,V12,V13,V14,V15,V16,V17,V18,V19,V20)
> Error in rep.int(rep.int(x, rep.int(rep.fac, nx)), orep) :
>         invalid number of copies in rep()
> In addition: Warning message:
> NAs introduced by coercion
>  >  
> 
> Then I try to reduce:
>  >   all.V.miss  <- 
> expand.grid(V1,V2,V3,V4,V5,V7,V8,V9,V10,V11,V17,V18,V19,V20)  
> Error: cannot allocate vector of size 36288 Kb
>  >
> What is that? Is this about memory or I must run on machine 64bit?
> 
> Regards, Muhammad Subianto
> P4 2.0GHz 512MB RAM

It's all about memory.  In your first example, you are trying to create
a data frame with 20 columns and 54 billion (thousand million) rows.
Just to store this amount of data as an array of doubles you would need
8 terabytes of memory. You are being a bit optimistic trying to do it
with only 500 Megabytes.

Martyn


>  > R.version$platform
> [1] "i686-redhat-linux-gnu"
>  > R.version$major
> [1] "2"
>  > R.version$minor
> [1] "1.1"
>  > R.version$year
> [1] "2005"
>  > R.version$month
> [1] "06"
>  > R.version$language
> [1] "R"


-----------------------------------------------------------------------
This message and its attachments are strictly confidential. ...{{dropped}}



From subianto at gmail.com  Thu Oct 13 14:20:45 2005
From: subianto at gmail.com (Muhammad Subianto)
Date: Thu, 13 Oct 2005 14:20:45 +0200
Subject: [R] expand.grid problem
In-Reply-To: <1129203950.8120.5.camel@seurat>
References: <434E34C3.2030707@gmail.com> <1129203950.8120.5.camel@seurat>
Message-ID: <diljet$urq$1@sea.gmane.org>

Dear all, Martyn Plummer and Jim Holtman (offlist) thanks you for quick 
respons. Now I understand. I need more machine and memory.
Thanks a lot.
Muhammad Subianto
--- 20 columns and 54 billion rows?  O:-)

On this day 13/10/2005 01:45 PM, Martyn Plummer wrote:
> 
> 
> It's all about memory.  In your first example, you are trying to create
> a data frame with 20 columns and 54 billion (thousand million) rows.
> Just to store this amount of data as an array of doubles you would need
> 8 terabytes of memory. You are being a bit optimistic trying to do it
> with only 500 Megabytes.
> 
> Martyn
> 
>



From dmbates at gmail.com  Thu Oct 13 15:49:39 2005
From: dmbates at gmail.com (Douglas Bates)
Date: Thu, 13 Oct 2005 08:49:39 -0500
Subject: [R] Help with Matrix package
In-Reply-To: <1CF0B26CECD746438AE02DBF7DDE1C7B020A5BA5@ifre2knas1.ifrxp.bbsrc.reserved>
References: <1CF0B26CECD746438AE02DBF7DDE1C7B020A5BA5@ifre2knas1.ifrxp.bbsrc.reserved>
Message-ID: <40e66e0b0510130649k2b9ca8c1qa350e53a38eb9e54@mail.gmail.com>

The Matrix package is under active development and the documentation
has not caught up with the code.  Examples of usage can be found in
the tests subdirectory of the source package.  At present we are
concentrating on the class hierarchy and writing methods and test
cases for those methods.  Because everything is in a state of flux we
have not created the simple introductory document.

The benchmark examples were all simple examples that, for the most
part, required just one function call.  What you are doing sounds more
realistic.

On 10/13/05, rob foxall (IFR) <rob.foxall at bbsrc.ac.uk> wrote:
> Hello all,
>         A colleague at work set me the challenge to convert some MATLAB
> code into R, to see which is faster. We'd seen that benchmark comparing
> MATLAB 6.5 to R1.90 (and others), and so I thought that I should be able
> to get roughly comparable speeds. The code has lots of multiplications
> of matrixes, transposes, and MATLAB's "repmat". I did the code
> conversion, and R was about 6 times slower, so I had a closer look at
> the benchmark comparison and it seems that I should be using the
> "Matrix" package.
>         Is there any dummies-level help available for this package? I am
> struggling even to apply simple functions such as "sum" and "mean" to
> matrixes constructed from this class (not that I need to yet), and more
> importantly "kronecker", to convert from "repmat". (The help for
> "kronecker" from the Matrix package doesn't seem to mention kronecker,
> so I am a bit stuck). Any guidance greatly accepted -- I have read the
> overview, looked through the various Matrix-listed functions, and
> unsuccessfully tried searching R-help.
>
> Using R version 2.2.0, windows xp.
>
> Cheers,
>         Rob.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Luisr at frs.fo  Thu Oct 13 15:50:54 2005
From: Luisr at frs.fo (Luis Ridao Cruz)
Date: Thu, 13 Oct 2005 14:50:54 +0100
Subject: [R] apply and plot
Message-ID: <s34e7456.043@ffdata.setur.fo>

R-help,

I use the code below to plot some data by applying "apply" function.
But I don't know how I can get the argument "type" or "col" on the
"plot" function to distinguish the different lines
in the graph:

apply ( my.data, 2, function ( x ) lines ( dimnames ( my.data ) [[1]] ,
x ) )


Thank you in advance



From murdoch at stats.uwo.ca  Thu Oct 13 15:55:18 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 13 Oct 2005 09:55:18 -0400
Subject: [R] Removing and restoring factor levels
Message-ID: <434E6746.1000402@stats.uwo.ca>

I'm doing a big slow computation, and profiling shows that it is 
spending a lot of time in match(), apparently because I have code like

x %in% listofxvals

Both x and listofxvals are factors with the same levels, so I could 
probably speed this up by stripping off the levels and just treating 
them as integer vectors, then restoring the levels at the end.

What is the safest way to do this?  I am worried that at some point x 
and listofxvals will *not* have the same levels, and the optimization 
will give the wrong answer.  So I need code that guarantees they have 
the same coding.

I think this works, where "master" is a factor with the master list of 
levels (guaranteed to be a superset of the levels of x and listofxvals), 
but can anyone spot anything that might go wrong?

# Strip the levels
x <- as.integer( factor(x), levels = levels(master) )

# Restore the levels
x <- structure( x, levels = levels(master), class = "factor" )

Thanks for any advice...

Duncan Murdoch



From justin_bem at yahoo.fr  Thu Oct 13 16:04:29 2005
From: justin_bem at yahoo.fr (justin bem)
Date: Thu, 13 Oct 2005 16:04:29 +0200 (CEST)
Subject: [R] RCMD help
Message-ID: <20051013140430.86129.qmail@web25706.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051013/e902cd3c/attachment.pl

From murdoch at stats.uwo.ca  Thu Oct 13 16:02:54 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 13 Oct 2005 10:02:54 -0400
Subject: [R] Removing and restoring factor levels (TYPO CORRECTED)
Message-ID: <434E690E.6060504@stats.uwo.ca>

Sorry, a typo in my previous message (parens in the wrong place in the 
conversion).

Here it is corrected:

I'm doing a big slow computation, and profiling shows that it is
spending a lot of time in match(), apparently because I have code like

x %in% listofxvals

Both x and listofxvals are factors with the same levels, so I could
probably speed this up by stripping off the levels and just treating
them as integer vectors, then restoring the levels at the end.

What is the safest way to do this?  I am worried that at some point x
and listofxvals will *not* have the same levels, and the optimization
will give the wrong answer.  So I need code that guarantees they have
the same coding.

I think this works, where "master" is a factor with the master list of
levels (guaranteed to be a superset of the levels of x and listofxvals),
but can anyone spot anything that might go wrong?

# Strip the levels
x <- as.integer( factor(x, levels = levels(master) ) )

# Restore the levels
x <- structure( x, levels = levels(master), class = "factor" )

Thanks for any advice...

Duncan Murdoch



From richard.nixon at mrc-bsu.cam.ac.uk  Thu Oct 13 16:07:57 2005
From: richard.nixon at mrc-bsu.cam.ac.uk (Richard Nixon)
Date: Thu, 13 Oct 2005 15:07:57 +0100
Subject: [R] nlme gls() error
Message-ID: <434E6A3D.1050101@mrc-bsu.cam.ac.uk>

Hello

I'm fitting a gls model with a variance-covariance structure and an 
getting an error message I don't understand

I'm using gls() from the nlme library with the structure defined by

correlation = corSymm(form = ~1|Subject), weights = varIdent(form=~1|strata)

I get the error

Error in recalc.corSymm(object[[i]], conLin) :
    NA/NaN/Inf in foreign function call (arg 1)

My dependent variable is highly positively skewed and has with many zero 
value.

Any ideas as to the cause of the error? Could I play around with any of 
the  glsControl values to help out?

Thanks
Richard

-- 
Dr. Richard Nixon, MRC Biostatistics Unit, Cambridge, UK
http://www.mrc-bsu.cam.ac.uk/personal/richard



From andreas.cordes at stud.uni-goettingen.de  Thu Oct 13 16:13:07 2005
From: andreas.cordes at stud.uni-goettingen.de (Andreas Cordes)
Date: Thu, 13 Oct 2005 16:13:07 +0200
Subject: [R] varimax rotation difference between R and SPSS
Message-ID: <434E6B73.6090209@stud.uni-goettingen.de>

Hi,
I am puzzeled with a differing result of princomp in R and FACTOR in 
SPSS. Regarding the amount of explained Variance, the two results are 
the same. However, the loadings differ substantially, in the unrotated 
as well as in the rotated form.
In both cases correlation matrices are analyzed. The sums of the squared 
components is one in both programs.
Maybe there is an obvious reason, but I somehow fail to see it.

Best Regards
Andreas

This is the output generated by R:

pc<-princomp(dat[,-c(1,2)],cor=T)
 > pc$loadings[,1:2]
             Comp.1     Comp.2
DS140_01 -0.2040579 -0.3837623
DS140_02  0.2351527 -0.3241166
DS140_03 -0.1391408 -0.3864510
DS140_04  0.2784596 -0.2512202
DS140_05  0.2823365 -0.2779157
DS140_06  0.2928942  0.1218132
DS140_07  0.2601528 -0.1162116
DS140_08  0.2737338  0.2811998
DS140_09  0.3012719 -0.1714994
DS140_10  0.2653410  0.3159160
DS140_11  0.2590944  0.2347922
DS140_12  0.2837112 -0.2653533
DS140_13  0.3246268 -0.2187217
DS140_14  0.2896170  0.2190227
 > varimax(pc$loadings[,1:2])
$loadings

Loadings:
         Comp.1 Comp.2
DS140_01        -0.424
DS140_02  0.390      
DS140_03  0.146 -0.384
DS140_04  0.375      
DS140_05  0.395      
DS140_06  0.143  0.283
DS140_07  0.273      
DS140_08         0.392
DS140_09  0.340      
DS140_10         0.413
DS140_11         0.347
DS140_12  0.388      
DS140_13  0.389      
DS140_14         0.355

               Comp.1 Comp.2
SS loadings     1.000  1.000
Proportion Var  0.071  0.071
Cumulative Var  0.071  0.143

$rotmat
           [,1]      [,2]
[1,]  0.7585207 0.6516489
[2,] -0.6516489 0.7585207


This is the output generated by SPSS

Call:

FACTOR
  /VARIABLES ds140_01 ds140_02 ds140_03 ds140_04 ds140_05 ds140_06 ds140_07
  ds140_08 ds140_09 ds140_10 ds140_11 ds140_12 ds140_13 ds140_14  /MISSING
  LISTWISE /ANALYSIS ds140_01 ds140_02 ds140_03 ds140_04 ds140_05 ds140_06
  ds140_07 ds140_08 ds140_09 ds140_10 ds140_11 ds140_12 ds140_13 ds140_14
  /PRINT INITIAL EXTRACTION ROTATION
  /FORMAT BLANK(.10)
  /CRITERIA MINEIGEN(1) ITERATE(25)
  /EXTRACTION PC
  /CRITERIA ITERATE(25)
  /ROTATION VARIMAX
  /METHOD=CORRELATION .

unrotaded loadings
DS140_01    -0,472589983    0,56095286
DS140_02    0,54460413    0,47376757
DS140_03    -0,322244458    0,564883041
DS140_04    0,644901386    0,367213521
DS140_05    0,653880049    0,406234844
DS140_06    0,678331281    -0,178056681
DS140_07    0,602503396    0,169868767
DS140_08    0,633956607    -0,411035327
DS140_09    0,697733664    0,250684012
DS140_10    0,614519123    -0,461780638
DS140_11    0,60005226    -0,3432004
DS140_12    0,657063717    0,387872152
DS140_13    0,751822595    0,319709742
DS140_14    0,670741388    -0,320149821

rotated lodings

DS140_01                             -0,733417555
DS140_02    0,721512351     
DS140_03    0,108433988    -0,641230389
DS140_04    0,731634009    0,124319125
DS140_05    0,763297939     
DS140_06    0,412130295    0,567438215
DS140_07    0,573827679    0,250175009
DS140_08    0,230223944    0,719616533
DS140_09    0,698707567    0,2479566
DS140_10    0,183040757    0,746572965
DS140_11    0,246954311    0,645649128
DS140_12    0,754130666    0,11603651
DS140_13    0,78428374    0,228802423
DS140_14    0,316255625    0,672586274

rotation matrix

    1    2
1    0,773826782    0,633397277
2    0,633397277    -0,773826782



From jerk_alert at hotmail.com  Thu Oct 13 16:14:01 2005
From: jerk_alert at hotmail.com (Ken Termiso)
Date: Thu, 13 Oct 2005 14:14:01 +0000
Subject: [R] Any way to add to data frame saved as .rData file?
In-Reply-To: <434C22C7.4010209@stats.uwo.ca>
Message-ID: <BAY101-F4004FBA7B85859ABF465CAE87A0@phx.gbl>


>
>I'd put the extra columns in their own data frame, and save that to disk 
>(use dates/times/process ids or some other unique identifier in the 
>filenames to distinguish them).  When you need access to a mixture of 
>columns, load (or source, depending how you did the save) the columns you 
>need, and cbind them together into one big data frame.
>
>If you are concerned about memory requirements when producing the pieces, 
>watch out that you don't write out so much data that you'll never have 
>enough memory to load all you need at once.
>
>Duncan Murdoch


hmm...maybe i should just be dumping to a text file instead of a data 
frame..is there any way (without using a real SQL database) in R to create a 
file that i can selectively load certain columns from?

if not, maybe i should break the data frame up into pieces (as you 
suggested) and create a separate file that keeps track of which columns are 
stored in which files (like a hashtable) and just load the small file of 
keys each time i need to load something..

whaddya think??



From arturo.coral at gmail.com  Thu Oct 13 16:31:05 2005
From: arturo.coral at gmail.com (Arturo Coral Alamo)
Date: Thu, 13 Oct 2005 09:31:05 -0500
Subject: [R] Problem whit a piece of program
Message-ID: <ed2fd5230510130731i1bb9d778ie228205e1283f0f8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051013/6a6170af/attachment.pl

From Roger.Bivand at nhh.no  Thu Oct 13 16:40:32 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 13 Oct 2005 16:40:32 +0200 (CEST)
Subject: [R] RCMD help
In-Reply-To: <20051013140430.86129.qmail@web25706.mail.ukl.yahoo.com>
Message-ID: <Pine.LNX.4.44.0510131635490.20724-100000@reclus.nhh.no>

On Thu, 13 Oct 2005, justin bem wrote:

> Hi dears,
> I have difficulty to build a package !
> I use Windows XP HOME, with and Intel PVI 2.66Ghz processor and 512MB of memory

You need to review Appendix F of the R Installation and Administration
manual, and be sure you have installed the Windows toolset, and modified
your PATH setting. The explanations look long, but are complete and do
work. The "sh" that Windows is looking for, is among the tools you should 
have installed and put in your PATH, so it looks as though this is your 
difficulty.

> I use RCMD check pyra1 and I got this :
> * using log directory 'C:/DOCS/R/pyra1.Rcheck'
> * using 
> * checking for file 'pyra1/DESCRIPTION' ... OK
> * checking extension type ... Package
> * this is package 'pyra1' version '1.0'
> * checking if this is a source package ... OK
>  ERROR
> Installation failed.
> Then I use RCMD build --binary pyra1 and in my shell I Got :
> * checking for file 'pyra1/DESCRIPTION' ... OK
> * preparing 'pyra1':
> * checking DESCRIPTION meta-information ...'sh' is not recognized as an internal or external command,
> operable program or batch file.
> * cleaning src
> * removing junk files
> 'sh' is not recognized as an internal or external command,
> operable program or batch file.
> 'sh' is not recognized as an internal or external command,
> operable program or batch file.
> Error: cannot open file 'pyra1/DESCRIPTION' for reading
>  
> does 'sh' refer to shell ? does I need to install any other program to build package ?
> Sincerly.
> 
> 		
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From jarioksa at sun3.oulu.fi  Thu Oct 13 16:44:55 2005
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Thu, 13 Oct 2005 17:44:55 +0300
Subject: [R] varimax rotation difference between R and SPSS
In-Reply-To: <434E6B73.6090209@stud.uni-goettingen.de>
References: <434E6B73.6090209@stud.uni-goettingen.de>
Message-ID: <1129214696.30482.64.camel@biol102145.oulu.fi>

On Thu, 2005-10-13 at 16:13 +0200, Andreas Cordes wrote:
> Hi,
> I am puzzeled with a differing result of princomp in R and FACTOR in 
> SPSS. Regarding the amount of explained Variance, the two results are 
> the same. However, the loadings differ substantially, in the unrotated 
> as well as in the rotated form.
> In both cases correlation matrices are analyzed. The sums of the squared 
> components is one in both programs.

Not in the data that you pasted in your message. After reading in the
data I get from the non-rotated R solution:

> colSums(rpc^2)
V2 V3
 1  1

And the non-rotated SPSS solutions gives:

> colSums(spc^2)
      V2       V3
5.363671 2.136624

After normalizing the SPSS pc's, the solutions are identical (within
numerical accuracy) after reversing the sign of second pc.

I don't want to look at the data full of holes, like the loadings from
varimax rotation. However, it seems that the raw solutions are
identical.

cheers, jari oksanen

-- 
Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland



From kevin.thorpe at utoronto.ca  Thu Oct 13 16:48:44 2005
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Thu, 13 Oct 2005 10:48:44 -0400
Subject: [R] Problem whit a piece of program
In-Reply-To: <ed2fd5230510130731i1bb9d778ie228205e1283f0f8@mail.gmail.com>
References: <ed2fd5230510130731i1bb9d778ie228205e1283f0f8@mail.gmail.com>
Message-ID: <434E73CC.6050905@utoronto.ca>

Arturo Coral Alamo wrote:
> Hi friends, I'm beginning in R and I have simple question.
> 
> I have this piece of my program and how you see, that's ok (whit > num<-
> 0.002)
> 
> num<-0.002 # ok, but not when I change whit num<-0... ?
> factor1<-1;
> while(1)
> {
> if (num*factor1<1)
> factor1<-factor1*10
> else
> {
> print("out ok!!");
> break;
> }
> }
> 
> [1] "out ok!!"
> 
> 
> but when I change (whit > num<-0) R show this:

Since num==0, num*factor1 is always 0 and so the loop never terminates 
and factor1 grows without bound becoming Inf.

> Error in if (num * factor1 < 1) factor1 <- factor1 * 10 else { :
> missing value where TRUE/FALSE needed
> 
> 
> I can't understand that error, can somebody help me, please
> thanks in advance
>  Jac


-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Department of Public Health Sciences
Faculty of Medicine, University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.946.8081  Fax: 416.946.3297



From p.dalgaard at biostat.ku.dk  Thu Oct 13 17:00:53 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 13 Oct 2005 17:00:53 +0200
Subject: [R] varimax rotation difference between R and SPSS
In-Reply-To: <434E6B73.6090209@stud.uni-goettingen.de>
References: <434E6B73.6090209@stud.uni-goettingen.de>
Message-ID: <x2slv54g2i.fsf@viggo.kubism.ku.dk>

Andreas Cordes <andreas.cordes at stud.uni-goettingen.de> writes:

> Hi,
> I am puzzeled with a differing result of princomp in R and FACTOR in 
> SPSS. Regarding the amount of explained Variance, the two results are 
> the same. However, the loadings differ substantially, in the unrotated 
> as well as in the rotated form.
> In both cases correlation matrices are analyzed. The sums of the squared 
> components is one in both programs.
> Maybe there is an obvious reason, but I somehow fail to see it.

I get 

> SPSS.res/ R.res
         V2        V3
1  2.315960 -1.461720
2  2.315960 -1.461720
3  2.315960 -1.461720
4  2.315960 -1.461720
5  2.315960 -1.461720
6  2.315960 -1.461719
7  2.315960 -1.461720
8  2.315960 -1.461720
9  2.315960 -1.461719
10 2.315960 -1.461720
11 2.315960 -1.461720
12 2.315960 -1.461720
13 2.315960 -1.461719
14 2.315960 -1.461720

which I presume is part of the puzzle. I don't think varimax() wants
its loadings normalized like they are in loadings(princomp())
(after all, it was designed for factanal(), not princomp()), and I
wouldn't be the least surprised if the $sdev components of princomp()
were related to  2.315960 and 1.461720.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From jerk_alert at hotmail.com  Thu Oct 13 17:24:04 2005
From: jerk_alert at hotmail.com (Ken Termiso)
Date: Thu, 13 Oct 2005 15:24:04 +0000
Subject: [R] Any way to add to data frame saved as .rData file?
Message-ID: <BAY101-F37ACF15E5B822BB88F2DA2E87A0@phx.gbl>

ugh!

scan(what=   does this...

thx anyway,



From tonyyangsxz_chn at yahoo.com  Thu Oct 13 17:33:27 2005
From: tonyyangsxz_chn at yahoo.com (Zhao Yang)
Date: Thu, 13 Oct 2005 08:33:27 -0700 (PDT)
Subject: [R] About Qusi-Monte carlo program
In-Reply-To: <Pine.LNX.4.61.0510130734300.28998@gannet.stats>
Message-ID: <20051013153327.53600.qmail@web35515.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051013/49ed444a/attachment.pl

From brian_cade at usgs.gov  Thu Oct 13 17:48:16 2005
From: brian_cade at usgs.gov (Brian S Cade)
Date: Thu, 13 Oct 2005 09:48:16 -0600
Subject: [R] subsetting with by() or other function??
In-Reply-To: <73dae3060510130434v24d3f1e1ja4f9ea4aab0b4ac8@mail.gmail.com>
Message-ID: <OFD24F1C17.1FE8701E-ON87257099.00559388-87257099.0057346A@usgs.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051013/702a3d7a/attachment.pl

From mschwartz at mn.rr.com  Thu Oct 13 18:22:15 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Thu, 13 Oct 2005 11:22:15 -0500
Subject: [R] apply and plot
In-Reply-To: <s34e7456.043@ffdata.setur.fo>
References: <s34e7456.043@ffdata.setur.fo>
Message-ID: <1129220535.5531.20.camel@localhost.localdomain>

On Thu, 2005-10-13 at 14:50 +0100, Luis Ridao Cruz wrote:
> R-help,
> 
> I use the code below to plot some data by applying "apply" function.
> But I don't know how I can get the argument "type" or "col" on the
> "plot" function to distinguish the different lines
> in the graph:
> 
> apply ( my.data, 2, function ( x ) lines ( dimnames ( my.data ) [[1]] ,
> x ) )
> 
> 
> Thank you in advance


Rather than trying the use the construct above, take a look at ?matlines
and/or ?matplot (both on the same help page with ?matpoints.)

I think that you will find these purposefully designed functions better
suited to what I believe you are trying to do here.

HTH,

Marc Schwartz



From brian_cade at usgs.gov  Thu Oct 13 18:57:32 2005
From: brian_cade at usgs.gov (Brian S Cade)
Date: Thu, 13 Oct 2005 10:57:32 -0600
Subject: [R] subsetting with by() or other function??
In-Reply-To: <006801c5d00f$d9c4b000$0540210a@www.domain>
Message-ID: <OFDD13AB5E.A71C0271-ON87257099.005CD2A0-87257099.005D8BEC@usgs.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051013/69bd739e/attachment.pl

From murdoch at stats.uwo.ca  Thu Oct 13 19:04:24 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 13 Oct 2005 13:04:24 -0400
Subject: [R] RCMD help
In-Reply-To: <20051013140430.86129.qmail@web25706.mail.ukl.yahoo.com>
References: <20051013140430.86129.qmail@web25706.mail.ukl.yahoo.com>
Message-ID: <434E9398.7090304@stats.uwo.ca>

On 10/13/2005 10:04 AM, justin bem wrote:
> Hi dears,
> I have difficulty to build a package !
> I use Windows XP HOME, with and Intel PVI 2.66Ghz processor and 512MB of memory
> I use RCMD check pyra1 and I got this :
> * using log directory 'C:/DOCS/R/pyra1.Rcheck'
> * using 
> * checking for file 'pyra1/DESCRIPTION' ... OK
> * checking extension type ... Package
> * this is package 'pyra1' version '1.0'
> * checking if this is a source package ... OK
>  ERROR
> Installation failed.
> Then I use RCMD build --binary pyra1 and in my shell I Got :
> * checking for file 'pyra1/DESCRIPTION' ... OK
> * preparing 'pyra1':
> * checking DESCRIPTION meta-information ...'sh' is not recognized as an internal or external command,
> operable program or batch file.
> * cleaning src
> * removing junk files
> 'sh' is not recognized as an internal or external command,
> operable program or batch file.
> 'sh' is not recognized as an internal or external command,
> operable program or batch file.
> Error: cannot open file 'pyra1/DESCRIPTION' for reading
>  
> does 'sh' refer to shell ? does I need to install any other program to build package ?

Yes, you need the R toolset.  See an appendix in the installation and 
administration manual from R 2.2.0 for the details.

Duncan Murdoch



From vincent.goulet at act.ulaval.ca  Thu Oct 13 19:06:32 2005
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Thu, 13 Oct 2005 13:06:32 -0400
Subject: [R] How to install R 2.2.0 Debian 'unstable' package in
	otherwise 'sarge' system
In-Reply-To: <20051012220343.GA12499@eddelbuettel.com>
References: <Pine.GSO.4.62.0510121542520.6573@harper.uchicago.edu>
	<20051012220343.GA12499@eddelbuettel.com>
Message-ID: <200510131306.32098.vincent.goulet@act.ulaval.ca>

Le 12 Octobre 2005 18:03, Dirk Eddelbuettel a ??crit??:
> i) In general, and especially between 'testing' and 'unstable', use
> apt-pinning, explained in the apt-howto packages, esp apt-howto-en for
> English; and on various places across the Net; try Google'ing for
> apt-pinning.

Dear Dirk,

I'll jump in because I've been wondering how to do this for some time. 

Is there any way to pin a whole series of packages using wildcards? I can 
otherwise pin r-base and r-recommended, but the packages they depend on will 
not be pinned themselves. 

It thus seems the only way to have 'unstable' R packages on my 'testing' 
system is to list them all in /etc/apt/preferences. It is neither convenient 
nor "safe" since I will eventually miss unlisted packages.

Thanks in advance!

-- 
  Vincent Goulet, Associate Professor
  ??cole d'actuariat
  Universit?? Laval, Qu??bec 
  Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca



From mschwartz at mn.rr.com  Thu Oct 13 19:07:55 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Thu, 13 Oct 2005 12:07:55 -0500
Subject: [R] Removing and restoring factor levels (TYPO CORRECTED)
In-Reply-To: <434E690E.6060504@stats.uwo.ca>
References: <434E690E.6060504@stats.uwo.ca>
Message-ID: <1129223276.5531.46.camel@localhost.localdomain>

On Thu, 2005-10-13 at 10:02 -0400, Duncan Murdoch wrote:
> Sorry, a typo in my previous message (parens in the wrong place in the 
> conversion).
> 
> Here it is corrected:
> 
> I'm doing a big slow computation, and profiling shows that it is
> spending a lot of time in match(), apparently because I have code like
> 
> x %in% listofxvals
> 
> Both x and listofxvals are factors with the same levels, so I could
> probably speed this up by stripping off the levels and just treating
> them as integer vectors, then restoring the levels at the end.
> 
> What is the safest way to do this?  I am worried that at some point x
> and listofxvals will *not* have the same levels, and the optimization
> will give the wrong answer.  So I need code that guarantees they have
> the same coding.
> 
> I think this works, where "master" is a factor with the master list of
> levels (guaranteed to be a superset of the levels of x and listofxvals),
> but can anyone spot anything that might go wrong?
> 
> # Strip the levels
> x <- as.integer( factor(x, levels = levels(master) ) )
> 
> # Restore the levels
> x <- structure( x, levels = levels(master), class = "factor" )
> 
> Thanks for any advice...
> 
> Duncan Murdoch

Duncan,

With the predicate that 'master' has the full superset of all possible
factor levels defined, it would seem that this would be a reasonable way
to go.

This approach would also seem to eliminate whatever overhead is
encountered as a result of the coercion of 'x' as a factor to a
character vector, which is done by match().

One question I have is, what is the advantage of using structure()
versus:

   x <- factor(x, levels = levels(master))

?

Thanks,

Marc



From h.wickham at gmail.com  Thu Oct 13 19:23:38 2005
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 13 Oct 2005 12:23:38 -0500
Subject: [R] Getting ... as an unevaluated list
Message-ID: <f8e6ff050510131023p2bf79732lc6321a262a33ee6c@mail.gmail.com>

Hi,

I'm trying to get ...as a list of unevaluated arguments, ie. 
substitute(list(...)) gives me an unevaluated list of the arguments,
but I want a list of the unevaluated arguments.

My attempts so far:

(function(...) substitute(...))(a=1, b=a)  # Only returns first

(function(...) substitute(list(...)))(a=1, b=a) # Unevaluated list,
not list of unevaluated

(function(...) expression(...))(a=1, b=a)

(function(...) eval(expression(...)))(a=1, b=a)  # Error in eval(expr,
envir, enclos) : ... used in an incorrect context

(function(...) substitute(expression(...), list(...)))(a=1, b=a) #
Error in (function(...) substitute(expression(...), list(...)))(a = 1,
 : Object "a" not found

What I actually want: list(1, a)

Can anyone offer any suggestions?

Thanks,

Hadley



From ggrothendieck at gmail.com  Thu Oct 13 19:32:34 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 13 Oct 2005 13:32:34 -0400
Subject: [R] Getting ... as an unevaluated list
In-Reply-To: <f8e6ff050510131023p2bf79732lc6321a262a33ee6c@mail.gmail.com>
References: <f8e6ff050510131023p2bf79732lc6321a262a33ee6c@mail.gmail.com>
Message-ID: <971536df0510131032i57d10d81n9b309f153a726259@mail.gmail.com>

Try this:

cl <- as.list(match.call())


On 10/13/05, hadley wickham <h.wickham at gmail.com> wrote:
> Hi,
>
> I'm trying to get ...as a list of unevaluated arguments, ie.
> substitute(list(...)) gives me an unevaluated list of the arguments,
> but I want a list of the unevaluated arguments.
>
> My attempts so far:
>
> (function(...) substitute(...))(a=1, b=a)  # Only returns first
>
> (function(...) substitute(list(...)))(a=1, b=a) # Unevaluated list,
> not list of unevaluated
>
> (function(...) expression(...))(a=1, b=a)
>
> (function(...) eval(expression(...)))(a=1, b=a)  # Error in eval(expr,
> envir, enclos) : ... used in an incorrect context
>
> (function(...) substitute(expression(...), list(...)))(a=1, b=a) #
> Error in (function(...) substitute(expression(...), list(...)))(a = 1,
>  : Object "a" not found
>
> What I actually want: list(1, a)
>
> Can anyone offer any suggestions?
>
> Thanks,
>
> Hadley
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From jan.sabee at gmail.com  Thu Oct 13 19:47:35 2005
From: jan.sabee at gmail.com (Jan Sabee)
Date: Thu, 13 Oct 2005 19:47:35 +0200
Subject: [R] How to generate for one vector matrix
Message-ID: <96507a8e0510131047x4de9acebkaa1d40e38d63d3b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051013/d184654f/attachment.pl

From p.dalgaard at biostat.ku.dk  Thu Oct 13 19:59:49 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 13 Oct 2005 19:59:49 +0200
Subject: [R] Getting ... as an unevaluated list
In-Reply-To: <971536df0510131032i57d10d81n9b309f153a726259@mail.gmail.com>
References: <f8e6ff050510131023p2bf79732lc6321a262a33ee6c@mail.gmail.com>
	<971536df0510131032i57d10d81n9b309f153a726259@mail.gmail.com>
Message-ID: <x2achde1re.fsf@turmalin.kubism.ku.dk>

Gabor Grothendieck <ggrothendieck at gmail.com> writes:

> Try this:
> 
> cl <- as.list(match.call())

or match.call(expand.dots=FALSE)$"..."
 
> 
> On 10/13/05, hadley wickham <h.wickham at gmail.com> wrote:
> > Hi,
> >
> > I'm trying to get ...as a list of unevaluated arguments, ie.
> > substitute(list(...)) gives me an unevaluated list of the arguments,
> > but I want a list of the unevaluated arguments.
> >
> > My attempts so far:
> >
> > (function(...) substitute(...))(a=1, b=a)  # Only returns first
> >
> > (function(...) substitute(list(...)))(a=1, b=a) # Unevaluated list,
> > not list of unevaluated
> >
> > (function(...) expression(...))(a=1, b=a)
> >
> > (function(...) eval(expression(...)))(a=1, b=a)  # Error in eval(expr,
> > envir, enclos) : ... used in an incorrect context
> >
> > (function(...) substitute(expression(...), list(...)))(a=1, b=a) #
> > Error in (function(...) substitute(expression(...), list(...)))(a = 1,
> >  : Object "a" not found
> >
> > What I actually want: list(1, a)
> >
> > Can anyone offer any suggestions?
> >
> > Thanks,
> >
> > Hadley
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From murdoch at stats.uwo.ca  Thu Oct 13 20:31:09 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 13 Oct 2005 14:31:09 -0400
Subject: [R] Removing and restoring factor levels (TYPO CORRECTED)
In-Reply-To: <1129223276.5531.46.camel@localhost.localdomain>
References: <434E690E.6060504@stats.uwo.ca>
	<1129223276.5531.46.camel@localhost.localdomain>
Message-ID: <434EA7ED.1010706@stats.uwo.ca>

On 10/13/2005 1:07 PM, Marc Schwartz (via MN) wrote:
> On Thu, 2005-10-13 at 10:02 -0400, Duncan Murdoch wrote:
>> Sorry, a typo in my previous message (parens in the wrong place in the 
>> conversion).
>> 
>> Here it is corrected:
>> 
>> I'm doing a big slow computation, and profiling shows that it is
>> spending a lot of time in match(), apparently because I have code like
>> 
>> x %in% listofxvals
>> 
>> Both x and listofxvals are factors with the same levels, so I could
>> probably speed this up by stripping off the levels and just treating
>> them as integer vectors, then restoring the levels at the end.
>> 
>> What is the safest way to do this?  I am worried that at some point x
>> and listofxvals will *not* have the same levels, and the optimization
>> will give the wrong answer.  So I need code that guarantees they have
>> the same coding.
>> 
>> I think this works, where "master" is a factor with the master list of
>> levels (guaranteed to be a superset of the levels of x and listofxvals),
>> but can anyone spot anything that might go wrong?
>> 
>> # Strip the levels
>> x <- as.integer( factor(x, levels = levels(master) ) )
>> 
>> # Restore the levels
>> x <- structure( x, levels = levels(master), class = "factor" )
>> 
>> Thanks for any advice...
>> 
>> Duncan Murdoch
> 
> Duncan,
> 
> With the predicate that 'master' has the full superset of all possible
> factor levels defined, it would seem that this would be a reasonable way
> to go.
> 
> This approach would also seem to eliminate whatever overhead is
> encountered as a result of the coercion of 'x' as a factor to a
> character vector, which is done by match().
> 
> One question I have is, what is the advantage of using structure()
> versus:
> 
>    x <- factor(x, levels = levels(master))
> 
> ?

That one doesn't work.  What "factor(x, levels=levels(master))" says is 
to convert x to a factor, coding the values in it according the levels 
in master.  But at this point x has values which are integers, so  they 
won't match the levels of master, which are probably character strings.

For example:

 > master <- factor(letters)
 > print(x <- factor(letters[1:3]))
[1] a b c
Levels: a b c
 > print(x <- as.integer( factor(x, levels = levels(master) ) ) )
[1] 1 2 3
 > print(x <- factor(x, levels = levels(master)))
[1] <NA> <NA> <NA>
Levels: a b c d e f g h i j k l m n o p q r s t u v w x y z

I get NA's at the end because the values 1,2,3 aren't in the vector of 
factor levels (which are the lowercase letters).

Duncan Murdoch



From mschwartz at mn.rr.com  Thu Oct 13 20:45:21 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Thu, 13 Oct 2005 13:45:21 -0500
Subject: [R] Removing and restoring factor levels (TYPO CORRECTED)
In-Reply-To: <434EA7ED.1010706@stats.uwo.ca>
References: <434E690E.6060504@stats.uwo.ca>
	<1129223276.5531.46.camel@localhost.localdomain>
	<434EA7ED.1010706@stats.uwo.ca>
Message-ID: <1129229121.5531.96.camel@localhost.localdomain>

On Thu, 2005-10-13 at 14:31 -0400, Duncan Murdoch wrote:
> On 10/13/2005 1:07 PM, Marc Schwartz (via MN) wrote:
> > On Thu, 2005-10-13 at 10:02 -0400, Duncan Murdoch wrote:
> >> Sorry, a typo in my previous message (parens in the wrong place in the 
> >> conversion).
> >> 
> >> Here it is corrected:
> >> 
> >> I'm doing a big slow computation, and profiling shows that it is
> >> spending a lot of time in match(), apparently because I have code like
> >> 
> >> x %in% listofxvals
> >> 
> >> Both x and listofxvals are factors with the same levels, so I could
> >> probably speed this up by stripping off the levels and just treating
> >> them as integer vectors, then restoring the levels at the end.
> >> 
> >> What is the safest way to do this?  I am worried that at some point x
> >> and listofxvals will *not* have the same levels, and the optimization
> >> will give the wrong answer.  So I need code that guarantees they have
> >> the same coding.
> >> 
> >> I think this works, where "master" is a factor with the master list of
> >> levels (guaranteed to be a superset of the levels of x and listofxvals),
> >> but can anyone spot anything that might go wrong?
> >> 
> >> # Strip the levels
> >> x <- as.integer( factor(x, levels = levels(master) ) )
> >> 
> >> # Restore the levels
> >> x <- structure( x, levels = levels(master), class = "factor" )
> >> 
> >> Thanks for any advice...
> >> 
> >> Duncan Murdoch
> > 
> > Duncan,
> > 
> > With the predicate that 'master' has the full superset of all possible
> > factor levels defined, it would seem that this would be a reasonable way
> > to go.
> > 
> > This approach would also seem to eliminate whatever overhead is
> > encountered as a result of the coercion of 'x' as a factor to a
> > character vector, which is done by match().
> > 
> > One question I have is, what is the advantage of using structure()
> > versus:
> > 
> >    x <- factor(x, levels = levels(master))
> > 
> > ?
> 
> That one doesn't work.  What "factor(x, levels=levels(master))" says is 
> to convert x to a factor, coding the values in it according the levels 
> in master.  But at this point x has values which are integers, so  they 
> won't match the levels of master, which are probably character strings.
> 
> For example:
> 
>  > master <- factor(letters)
>  > print(x <- factor(letters[1:3]))
> [1] a b c
> Levels: a b c
>  > print(x <- as.integer( factor(x, levels = levels(master) ) ) )
> [1] 1 2 3
>  > print(x <- factor(x, levels = levels(master)))
> [1] <NA> <NA> <NA>
> Levels: a b c d e f g h i j k l m n o p q r s t u v w x y z
> 
> I get NA's at the end because the values 1,2,3 aren't in the vector of 
> factor levels (which are the lowercase letters).

As opposed to:

> print(x <- structure(x, levels = levels(master), class = "factor" ))
[1] a b c
Levels: a b c d e f g h i j k l m n o p q r s t u v w x y z


OK.  Makes sense. Thanks for the clarification.

Marc



From greg.snow at ihc.com  Thu Oct 13 20:53:10 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Thu, 13 Oct 2005 12:53:10 -0600
Subject: [R] Any way to add to data frame saved as .rData file?
Message-ID: <s34e58d8.056@lp-msg1.co.ihc.com>

Have you looked at the g.data package?  It might be useful 
(but may still require some redesign of your dataset).

Greg Snow, Ph.D.
Statistical Data Center, LDS Hospital
Intermountain Health Care
greg.snow at ihc.com
(801) 408-8111

>>> "Ken Termiso" <jerk_alert at hotmail.com> 10/13/05 08:14AM >>>

>
>I'd put the extra columns in their own data frame, and save that to
disk 
>(use dates/times/process ids or some other unique identifier in the 
>filenames to distinguish them).  When you need access to a mixture of

>columns, load (or source, depending how you did the save) the columns
you 
>need, and cbind them together into one big data frame.
>
>If you are concerned about memory requirements when producing the
pieces, 
>watch out that you don't write out so much data that you'll never have

>enough memory to load all you need at once.
>
>Duncan Murdoch


hmm...maybe i should just be dumping to a text file instead of a data 
frame..is there any way (without using a real SQL database) in R to
create a 
file that i can selectively load certain columns from?

if not, maybe i should break the data frame up into pieces (as you 
suggested) and create a separate file that keeps track of which columns
are 
stored in which files (like a hashtable) and just load the small file
of 
keys each time i need to load something..

whaddya think??

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From h.wickham at gmail.com  Thu Oct 13 21:11:30 2005
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 13 Oct 2005 14:11:30 -0500
Subject: [R] Getting ... as an unevaluated list
In-Reply-To: <x2achde1re.fsf@turmalin.kubism.ku.dk>
References: <f8e6ff050510131023p2bf79732lc6321a262a33ee6c@mail.gmail.com>
	<971536df0510131032i57d10d81n9b309f153a726259@mail.gmail.com>
	<x2achde1re.fsf@turmalin.kubism.ku.dk>
Message-ID: <f8e6ff050510131211l58261a10uad851beb25f9c855@mail.gmail.com>

Perfect!  Thanks Peter and Gabor.

Hadley

On 13 Oct 2005 19:59:49 +0200, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> Gabor Grothendieck <ggrothendieck at gmail.com> writes:
>
> > Try this:
> >
> > cl <- as.list(match.call())
>
> or match.call(expand.dots=FALSE)$"..."
>
> >
> > On 10/13/05, hadley wickham <h.wickham at gmail.com> wrote:
> > > Hi,
> > >
> > > I'm trying to get ...as a list of unevaluated arguments, ie.
> > > substitute(list(...)) gives me an unevaluated list of the arguments,
> > > but I want a list of the unevaluated arguments.
> > >
> > > My attempts so far:
> > >
> > > (function(...) substitute(...))(a=1, b=a)  # Only returns first
> > >
> > > (function(...) substitute(list(...)))(a=1, b=a) # Unevaluated list,
> > > not list of unevaluated
> > >
> > > (function(...) expression(...))(a=1, b=a)
> > >
> > > (function(...) eval(expression(...)))(a=1, b=a)  # Error in eval(expr,
> > > envir, enclos) : ... used in an incorrect context
> > >
> > > (function(...) substitute(expression(...), list(...)))(a=1, b=a) #
> > > Error in (function(...) substitute(expression(...), list(...)))(a = 1,
> > >  : Object "a" not found
> > >
> > > What I actually want: list(1, a)
> > >
> > > Can anyone offer any suggestions?
> > >
> > > Thanks,
> > >
> > > Hadley
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>
> --
>    O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
>



From gchappi at gmail.com  Thu Oct 13 21:14:24 2005
From: gchappi at gmail.com (Hans-Peter)
Date: Thu, 13 Oct 2005 21:14:24 +0200
Subject: [R] aggregate slow with many rows - alternative?
Message-ID: <47fce0650510131214k5eeaaf41m@mail.gmail.com>

Hi,

I use the code below to aggregate / cnt my test data. It works fine,
but the problem is with my real data (33'000 rows) where the function
is really slow (nothing happened in half an hour).

Does anybody know of other functions that I could use?

Thanks,
Hans-Peter

--------------
dat <- data.frame( Datum  = c( 32586, 32587, 32587, 32625, 32656,
32656, 32656, 32672, 32672, 32699 ),
              FischerID = c( 58395, 58395, 58395, 88434, 89953, 89953,
89953, 64395, 62896, 62870 ),
              Anzahl = c( 2, 2, 1, 1, 2, 1, 7, 1, 1, 2 ) )
f <- function(x) data.frame( Datum = x[1,1], FischerID = x[1,2],
Anzahl = sum( x[,3] ), Cnt = dim( x )[1] )
t.a <- do.call("rbind", by(dat, dat[,1:2], f))   # slow for 33'000 rows
t.a <- t.a[order( t.a[,1], t.a[,2] ),]

  # show data
dat
t.a



From mschwartz at mn.rr.com  Thu Oct 13 21:15:16 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Thu, 13 Oct 2005 14:15:16 -0500
Subject: [R] How to generate for one vector matrix
In-Reply-To: <96507a8e0510131047x4de9acebkaa1d40e38d63d3b@mail.gmail.com>
References: <96507a8e0510131047x4de9acebkaa1d40e38d63d3b@mail.gmail.com>
Message-ID: <1129230916.5531.110.camel@localhost.localdomain>

On Thu, 2005-10-13 at 19:47 +0200, Jan Sabee wrote:
> Is there any routine to generate for one vector matrix.
> If I have X I want to generate start from zero to maximum value each vector.
> 
> For example, I have a vector x = (4,2,3,1,4)
> I want to generate n=6 times, for 4, start 0 to 4, then 2 start 0 to 2, ect.
> 
> The result something like this:
> 
> generate(x,n=6)
> 1,1,2,1,4
> 1,2,3,0,3
> 4,0,1,1,1
> 3,1,0,1,4
> 0,0,3,0,0
> 4,1,3,0,4
> 
> Could anyone help me. Thanks.
> Regards,
> Jan Sabee


If I am properly understanding what you are doing here, you have an
initial vector of values. You want to create a matrix, whose columns are
the result of random sampling with replacement from the initial vector
'n' times, where the sampling space for each column "i" is from 0:x[i]?

If correct, this should do it:

> x <- c(4, 2, 3, 1, 4)

> x
[1] 4 2 3 1 4

> sapply(x, function(x) sample(0:x, 6, replace = TRUE))
     [,1] [,2] [,3] [,4] [,5]
[1,]    4    2    1    1    2
[2,]    3    0    0    0    0
[3,]    1    2    0    1    3
[4,]    4    2    1    1    1
[5,]    3    1    3    1    0
[6,]    0    1    1    1    0


Just replace '6' in the sample() arguments with the 'n' you require.

See ?sapply and ?sample.

HTH,

Marc Schwartz



From ecoinformatics at gmail.com  Thu Oct 13 21:26:07 2005
From: ecoinformatics at gmail.com (ecoinfo)
Date: Thu, 13 Oct 2005 21:26:07 +0200
Subject: [R] How to generate for one vector matrix
In-Reply-To: <96507a8e0510131047x4de9acebkaa1d40e38d63d3b@mail.gmail.com>
References: <96507a8e0510131047x4de9acebkaa1d40e38d63d3b@mail.gmail.com>
Message-ID: <15f8e67d0510131226x1cdf05a4x56de15ae08ab75e6@mail.gmail.com>

A not-so-clever solution:

n <- 6
x <- c(4,2,3,1,4)
y <- matrix(0, nrow=n, ncol=length(x))
for (i in 1:n){
for (j in 1:length(x)){
y[i,j] <- round(runif(1,min=0,max=x[j]))}}

Hope it helps
Xiaohua

On 10/13/05, Jan Sabee <jan.sabee at gmail.com> wrote:
> Is there any routine to generate for one vector matrix.
> If I have X I want to generate start from zero to maximum value each vector.
>
> For example, I have a vector x = (4,2,3,1,4)
> I want to generate n=6 times, for 4, start 0 to 4, then 2 start 0 to 2, ect.
>
> The result something like this:
>
> generate(x,n=6)
> 1,1,2,1,4
> 1,2,3,0,3
> 4,0,1,1,1
> 3,1,0,1,4
> 0,0,3,0,0
> 4,1,3,0,4
>
> Could anyone help me. Thanks.
> Regards,
> Jan Sabee
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>


--
Xiaohua Dai, Dr.
Postdoc in elephant-vegetation ecosystem simulation
Centre for Systems Research, Durban Institute of Technology
P.O.Box 953, Durban 4000, South Africa



From pbaer at berkeley.edu  Thu Oct 13 21:40:51 2005
From: pbaer at berkeley.edu (Paul Baer)
Date: Thu, 13 Oct 2005 13:40:51 -0600
Subject: [R] reading matrix objects into a list
Message-ID: <p06230909bf7467c02023@[192.168.1.102]>

OK, I've tried to be a good citizen and use the searchable archives, 
but with three search strings I haven't found the answer to what must 
really be a simple question.

I want to create a list of objects from a set of matrices (in this 
case, 300x300). Suppose the first matrix is A. I tried:

>  x=as.list(A)

But it I get a list of length 90,000

>  length(x)
[1] 90000

instead of length 1, which is what I expected.

What's the simple trick I'm missing?

Thanks,

--Paul



From reid_huntsinger at merck.com  Thu Oct 13 21:57:54 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Thu, 13 Oct 2005 15:57:54 -0400
Subject: [R] reading matrix objects into a list
Message-ID: <355C35514FEAC9458F75947F5270974D076D17@usctmx1103.merck.com>

Try 

x <- list(A)

instead. Coercion (as.list) sees A as a vector of length 90,000 (forgetting
the "dim" attribute) and assumes you want to make it a "generic vector",
which conceptually just changes its mode to "list", whereas "list"
constructs a list with entries you pass as arguments.

Reid Huntsinger

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Paul Baer
Sent: Thursday, October 13, 2005 3:41 PM
To: r-help at stat.math.ethz.ch
Subject: [R] reading matrix objects into a list


OK, I've tried to be a good citizen and use the searchable archives, 
but with three search strings I haven't found the answer to what must 
really be a simple question.

I want to create a list of objects from a set of matrices (in this 
case, 300x300). Suppose the first matrix is A. I tried:

>  x=as.list(A)

But it I get a list of length 90,000

>  length(x)
[1] 90000

instead of length 1, which is what I expected.

What's the simple trick I'm missing?

Thanks,

--Paul

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From otter at otter-rsch.com  Thu Oct 13 22:19:24 2005
From: otter at otter-rsch.com (dave fournier)
Date: Thu, 13 Oct 2005 13:19:24 -0700
Subject: [R] Do Users of Nonlinear Mixed Effects Models Know Whether Their
 Software Really Works?
Message-ID: <434EC14C.3000608@otter-rsch.com>

           Do Users of Nonlinear Mixed Effects Models Know

                  Whether Their Software Really Works?


   Lesaffre et. al. (Appl. Statist. (2001) 50, Part3, pp 325-335)
   analyzed
   some simple clinical trials data using a logistic random effects
   model. Several packages and methods MIXOR, SAS NLMIXED were employed.
   They reported obtaining very different parameter estimates and
   P values for the log-likelihood with the different packages and
   methods. We thought it  would be interesting to revisit this example
   using the AD Model Builder random effects module which we feel is
   the most stable software available for this problem at this time.

              http://otter-rsch.com/admodel.htm

   You can get Table 2 from Lesaffre et al at

           http://otter-rsch.com/downloads/other/lesaffre.pdf

   The data and more information are available
   from the publisher.

           http://www.blackwellpublishers.co.uk/rss/Volumes/Cv50p3.htm

   We considered three questions:

     1.) What are the  estimates using the Laplace approximation
         for integrating out the random effects.

     2.) What are the exact MLE's.

     3.) How well does hypothesis testing (likelihood-ratio) using
         the Laplace approximation compare with the exact MLE's.

   We first fit the data using ADMB-RE's Laplace approximation
   option.

   Laplace approximation estimates:

      # Number of parameters = 4  log-likelihood = -629.817
                       value      std dev  P value
            b_1     -2.3321e+00 7.6973e-01  < 0.0024
            b_2     -6.8795e-01 6.6185e-01    0.298
            b_3     -4.6134e-01 4.0000e-02  < 0.001
          sigma      4.5738e+00 7.0970e-01


    The parameter of interest here the treatment effect b_2 which is the
   parameter reported in Lesaffre et. al.

    To calculate the exact MLE we fit the model using 100 point adaptive
    Gaussian integration. The ADMB-RE results were:

    Gaussian integration estimates:

      # Number of parameters = 4  log-likelihood = -627.481

          name         value      std dev    P value
           b_1     -1.4463e+00 4.2465e-01   < 0.001
           b_2     -5.2225e-01 5.5716e-01     0.348
           b_3     -4.5150e-01 3.6663e-02   < 0.001
         sigma      4.0137e+00 3.8083e-01

   Of the estimates reported in Lesaffre et al. in table 2 only the
   50 point quadrature for the program MIXOR appear to be correct
   for both the log-likelihood value and the parameter estimates
   while the authors concluded that the SAS NLMIXED parameter estimates
   they obtained were correct.  So even though these authors were looking
   for pathological behaviour and were presumably very careful, and their
   paper was presumably peer-reviewed, they came to the wrong conclusion
   using SAS NLMIXED.

   How do we know that our exact MLE's are correct? To confirm our
   results we used our parameter estimates as initial values in the SAS
   NLMIXED procedure using 100 point adaptive quadrature. The procedure
   returned our values, that is it agreed that these are the maximum
   likelihood estimates.  However we verified that to get these estimates
   from the SAS NLMIXED procedure one must begin with fairly good
   starting values. In contrast the ADMB-RE procedure is very insensitive
   to the starting values used. Our conclusion is that while SAS NLMIXED
   might work for this very simple problem it probably begins to break
   down when the problem is a bit more difficult.

   The ADMB-RE software is more stable because it calculates exact higher
   oreder derivatives by automatic differentiation for use in its
   optimization procedure and calculations while other packages do not.

   Gauss-Hermite integration for the random effects can
   be used for this model because the Hessian for the random effects is
   diagonal which permits one dimensional integration over the random
   effects to great accuracy.  However this procedure does not scale well
   to problems where the Hessian is not diagonal.  Suppose that it takes
   a 20 point quadrature to obtain reliable parameter estimates with a
   diagonal Hessian.  Then with a block diagonal Hessian where the blocks
   are of size 4x4 it would take 160,000 points.

   Results using R

   We fit the model using what appear to be the currently available
   procedures in R.  The two routines lmer (lme4 package) and glmmPQL
   (MASS library) were tried.

   The call


     >>   lmer(y ~ treat + time + (1|subject),data=lesaffre,family=binomial)

   resulted in a warning message from lme4() but both routines produced
   the same results.

     Generalized linear mixed model fit using PQL
     Formula: y ~ treat + time + (1 | subject)
        Data: lesaffre
      Family: binomial(logit link)
           AIC      BIC    logLik deviance
      1305.859 1333.628 -647.9295 1295.859
     Random effects:
          Groups        Name    Variance    Std.Dev.
         subject (Intercept)      6.8059      2.6088
     # of obs: 1908, groups: subject, 294
     Estimated scale (compare to 1)  0.9091945
     Fixed effects:
                  Estimate Std. Error  z value Pr(>|z|)
     (Intercept) -0.626214   0.264996  -2.3631  0.01812 *
     treat       -0.304660   0.360866  -0.8442  0.39853
     time        -0.346605   0.026666 -12.9979  < 2e-16 ***
     sigma        2.608
     ---
     Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
     Warning message:
     optim or nlminb returned message ERROR:
     ABNORMAL_TERMINATION_IN_LNSRCH
      in: LMEopt(x = mer, value = cv)


   The R routine correctly identifies the treatment effect as not
   significant. However the parameter estimates are poor.


   Likelihood Ratio Testing

   Accurate calculation of the log-likelihood value is desirable so that
   hypothesis testing can be carried out using likelihood ratio tests.

   However as noted above the use of Gaussian integration is not
   practical for  many nonlinear mixed models. We were interested in
   seeing how well the use of the approximate log-likelihood values
   produced by ADMB-RE's Laplace approximation option would perform.

   We consider the alternative model with an extra interaction term
   (b_4) from  Lesaffre et al.

   Here are the results for the laplace approximation:

     # Number of parameters = 5  log-likelihood = -627.809
         name       value      std dev       P vlaue
         b_1      -2.5233e+00 7.8829e-01    < 0.002
         b_2      -3.0702e-01 6.8996e-01      0.655
         b_3      -4.0009e-01 4.7059e-02    < 0.001
         b_4      -1.3726e-01 6.9586e-02      0.044
        sigma      4.5783e+00 7.2100e-01

   and the exact parameter estimates by 100 point  Gaussian
   integration.


     # Number of parameters = 5  log-likelihood = -625.398
         name       value      std dev       P value
          b_1     -1.6183e+00 4.3427e-01    < 0.001
          b_2     -1.6077e-01 5.8394e-01      0.783
          b_3     -3.9100e-01 4.4380e-02    < 0.001
          b_4     -1.3679e-01 6.8013e-02      0.044
         sigma     4.0131e+00 3.8044e-01

    The log-likelihood differences are 2.01 for the Laplace
    approximation and 2.08 for Gaussian integration.
    Since the 95% point for hypothesis testing is 1.92
    use of either model results in acceptance of the interaction
    term.

   Conclusions

   With the exception of AD Model Builder random effect module none of
   the packages tested appear to function reliably for this problem.
   SAS NLMIXED  was  beginning to exhibit symptoms of instability which
   would probably render it unreliable on more difficult problems.  We
   can see no reason for using "quasi-likelihoods" to fit nonlinear
   mixed models when ADMB-RE can fit the models by maximum likelihood
   with all the advantages that ensue.

   Note

   We realize that there are many other packages out there. We would
   welcome results for other packages. If we can find a serious
   competitor to AD Model Builder then we could move on to comparing
   the relative performance on more difficult models.

        Cheers,

        Dave Fournier

-- 
David A. Fournier
P.O. Box 2040,
Sidney, B.C. V8l 3s3
Canada
http://otter-rsch.com


-- 
Internal Virus Database is out-of-date.



From kb2qzv at poczta.wp.pl  Thu Oct 13 22:09:21 2005
From: kb2qzv at poczta.wp.pl (Benedict P. Barszcz)
Date: Thu, 13 Oct 2005 22:09:21 +0200
Subject: [R] Linux Enciety Live CD screenshot
Message-ID: <200510132209.21965.kb2qzv@poczta.wp.pl>

Hi all,
Here is a screenshot of the live cd someone mentioned here on the list.
I lanched it under the virtual pc qemu. the first thing that appears is th 
R-php 0.99  in a firefox window (not shown on the screenshot).

http://img449.imageshack.us/my.php?image=encietylivecd1fc.png
-- 
Benedict

Cyfrowy klucz publiczny / Digital public key 
http://agrypa1.atspace.com/klucze/kb2qzv_wp.pl-public.asc



From jan.sabee at gmail.com  Thu Oct 13 22:22:59 2005
From: jan.sabee at gmail.com (Jan Sabee)
Date: Thu, 13 Oct 2005 22:22:59 +0200
Subject: [R] How to generate for one vector matrix
In-Reply-To: <96507a8e0510131047x4de9acebkaa1d40e38d63d3b@mail.gmail.com>
References: <96507a8e0510131047x4de9acebkaa1d40e38d63d3b@mail.gmail.com>
Message-ID: <96507a8e0510131322t197120f5l274eafdd643c2cb9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051013/d2a3ded7/attachment.pl

From brian_cade at usgs.gov  Thu Oct 13 22:28:58 2005
From: brian_cade at usgs.gov (Brian S Cade)
Date: Thu, 13 Oct 2005 14:28:58 -0600
Subject: [R] subsetting data frame using by() or tapply() or other
Message-ID: <OFB92558E8.783DC4FA-ON87257099.006E295D-87257099.0070E72B@usgs.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051013/d5ef60ce/attachment.pl

From pmuhl830 at gmail.com  Thu Oct 13 22:30:48 2005
From: pmuhl830 at gmail.com (Peter Muhlberger)
Date: Thu, 13 Oct 2005 16:30:48 -0400
Subject: [R] ML optimization question--unidimensional unfolding scaling
In-Reply-To: <434C7EE2.9040605@pdf.com>
Message-ID: <BF743C38.11F1D%pmuhl830@gmail.com>

Hi Spencer:  Thanks for your interest!  Also, the posting guide was helpful.

I think my problem might be solved if I could find a way to terminate nlm or
optim runs from within the user-given minimization function they call.
Optimization is unconstrained.

I'm essentially using normal like curves that translate observed values on a
set of variables (one curve per variable) into latent unfolded values.  The
observed values are on the Y-axis & the latent (hence parameters to be
estimated) are on the X-axis.  The problem is that there are two points into
which an observed value can map on a curve--one on either side of the curve
mean.  Only one of these values actually will be optimal for all observed
variables, but it's easy to show that most estimation methods will get stuck
on the non-optimal value if they find that one first.  Moving away from that
point, the likelihood gets a whole lot worse before the routine will 'see'
the optimal point on the other side of the normal curve.

SANN might work, but I kind of wonder how useful it'd be in estimating
hundreds of parameters--thanks to that latent scale.

My (possibly harebrained) thought for how to estimate this unfolding using
some gradient-based method would be to run through some iterations and then
check to see whether a better solution exists on the 'other side' of the
normal curves.  If it does, replace those parameters with the better ones.
Because this causes the likelihood to jump, I'd probably have to start the
estimation process over again (maybe).  But, I see no way from within the
minimization function called by NLM or optim to tell NLM or optim to
terminate its current run.  I could make the algorithm recursive, but that
eats up resources & will probably have to be terminated w/ an error.

Peter


On 10/11/05 11:11 PM, "Spencer Graves" <spencer.graves at pdf.com> wrote:

>  There may be a few problems where ML (or more generally Bayes) fails
> to give sensible answers, but they are relatively rare.
> 
>  What is your likelihood?  How many parameters are you trying to
> estimate?
> 
>  Are you using constrained or unconstrained optimization?  If
> constrained, I suggest you remove the constraints by appropriate
> transformation.  When considering alternative transformations, I
> consider (a) what makes physical sense, and (b) which transformation
> produces a log likelihood that is more close to being parabolic.
> 
>  Hou are you calling "optim"?  Have you tried all "SANN" as well as
> "Nelder-Mead", "BFGS", and "CG"?  If you are using constrained
> optimization, I suggest you move the constraints to Inf by appropriate
> transformation and use the other methods, as I just suggested.
> 
>  If you would still like more suggestions from this group, please
> provide more detail -- but as tersely as possible.  The posting guide
> is, I believe, quite useful (www.R-project.org/posting-guide.html).
> 
>  spencer graves



From ripley at stats.ox.ac.uk  Thu Oct 13 22:57:34 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 13 Oct 2005 21:57:34 +0100 (BST)
Subject: [R] Do Users of Nonlinear Mixed Effects Models Know Whether
 Their Software Really Works?
In-Reply-To: <434EC14C.3000608@otter-rsch.com>
References: <434EC14C.3000608@otter-rsch.com>
Message-ID: <Pine.LNX.4.61.0510132157060.9857@gannet.stats>

On Thu, 13 Oct 2005, dave fournier wrote:

> Internal Virus Database is out-of-date.

Talk about not being careful!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mschwartz at mn.rr.com  Thu Oct 13 23:04:00 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Thu, 13 Oct 2005 16:04:00 -0500
Subject: [R] subsetting data frame using by() or tapply() or other
In-Reply-To: <OFB92558E8.783DC4FA-ON87257099.006E295D-87257099.0070E72B@usgs.gov>
References: <OFB92558E8.783DC4FA-ON87257099.006E295D-87257099.0070E72B@usgs.gov>
Message-ID: <1129237441.6062.5.camel@localhost.localdomain>

On Thu, 2005-10-13 at 14:28 -0600, Brian S Cade wrote:
> Ok so I see the problem that I'm having creating a new variable (LAG1DBC) 
> in the example data transformation below is that tapply() is creating a 
> list that is not dimensionally consistent with the data frame (data).  So 
> how do I go from the list output of tapply() to create a dimensionally 
> consistent vector that can create the new variable in my original data 
> frame?  I've been trying to use a function like
> data$LAG1DBC <- tapply(data$DBC, data$LOCID, function(x) c(NA, 
> x[-length(x)]))
> which creates a list of dimension much smaller than the nrows in data. And 
> I've tried things like using as.data.frame.array() or as.data.frame.list() 
> in front of tapply() and still have the same problem.  I know this can't 
> be that unusual of a data manipulation and that someone has to have done 
> similar things before.
> 
> I want to go from something like this:
> 
>        LOCID  POPULATION  YEAR        DBC
> 1      algb-1           A 1992 0.70451575
> 2      algb-1           A 1993 0.59506851
> 3      algb-1           A 1997 0.84837544
> 4      algb-1           A 1998 0.50283182
> 5      algb-1           A 2000 0.91242707
> 6      algb-2           A 1992 0.09747155
> 7      algb-2           A 1993 0.84772253
> 8      algb-2           A 1997 0.43974081
> 9      algb-2           A 1998 0.83108544
> 10     algb-2           A 2000 0.22291192
> 11     algb-3           A 1992 0.44234175
> 12     algb-3           A 1993 0.54089534
> 5680 taylr-73           B 2001 0.43918082
> 5681 taylr-73           B 2002 0.34694427
> 5682 taylr-73           B 2003 3.35619190
> 5683 taylr-73           B 2004 0.71575815
> 5684 taylr-73           B 2005 0.42038506
> 5685 taylr-74           B 1992 3.88410354
> 5686 taylr-74           B 1993 3.32472557
> 5687 taylr-74           B 1994 3.29861501
> 5688 taylr-74           B 1996 0.48153827
> 5689 taylr-74           B 1997 3.63570636
> 5690 taylr-74           B 1998 1.94630194
> 
> to something like this:
> 
>        LOCID  POPULATION  YEAR        DBC LAG1DBC
> 1      algb-1           A 1992 0.70451575       NA 
> 2      algb-1           A 1993 0.59506851 0.70451575
> 3      algb-1           A 1997 0.84837544       0.59506851
> 4      algb-1           A 1998 0.50283182 0.84837544
> 5      algb-1           A 2000 0.91242707       0.50283182
> 6      algb-2           A 1992 0.09747155       NA
> 7      algb-2           A 1993 0.84772253 0.09747155
> 8      algb-2           A 1997 0.43974081       0.84772253
> 9      algb-2           A 1998 0.83108544       0.43974081
> 10     algb-2           A 2000 0.22291192       0.83108544
> 11     algb-3           A 1992 0.44234175       NA
> 12     algb-3           A 1993 0.54089534       0.44234175
> 5680 taylr-73           B 2001 0.43918082       NA
> 5681 taylr-73           B 2002 0.34694427       0.43918082
> 5682 taylr-73           B 2003 3.35619190       0.34694427
> 5683 taylr-73           B 2004 0.71575815       3.35619190
> 5684 taylr-73           B 2005 0.42038506       0.71575815
> 5685 taylr-74           B 1992 3.88410354       NA
> 5686 taylr-74           B 1993 3.32472557       3.88410354
> 5687 taylr-74           B 1994 3.29861501       3.32472557
> 5688 taylr-74           B 1996 0.48153827       3.29861501
> 5689 taylr-74           B 1997 3.63570636       0.48153827
> 5690 taylr-74           B 1998 1.94630194       3.63570636
> 
> Brian

Brian,

Use unlist():

> data$LAG1DBC <- unlist(tapply(data$DBC, data$LOCID, 
                         function(x) c(NA, x[-length(x)])))

> data
        LOCID POPULATION YEAR        DBC    LAG1DBC
1      algb-1          A 1992 0.70451575         NA
2      algb-1          A 1993 0.59506851 0.70451575
3      algb-1          A 1997 0.84837544 0.59506851
4      algb-1          A 1998 0.50283182 0.84837544
5      algb-1          A 2000 0.91242707 0.50283182
6      algb-2          A 1992 0.09747155         NA
7      algb-2          A 1993 0.84772253 0.09747155
8      algb-2          A 1997 0.43974081 0.84772253
9      algb-2          A 1998 0.83108544 0.43974081
10     algb-2          A 2000 0.22291192 0.83108544
11     algb-3          A 1992 0.44234175         NA
12     algb-3          A 1993 0.54089534 0.44234175
5680 taylr-73          B 2001 0.43918082         NA
5681 taylr-73          B 2002 0.34694427 0.43918082
5682 taylr-73          B 2003 3.35619190 0.34694427
5683 taylr-73          B 2004 0.71575815 3.35619190
5684 taylr-73          B 2005 0.42038506 0.71575815
5685 taylr-74          B 1992 3.88410354         NA
5686 taylr-74          B 1993 3.32472557 3.88410354
5687 taylr-74          B 1994 3.29861501 3.32472557
5688 taylr-74          B 1996 0.48153827 3.29861501
5689 taylr-74          B 1997 3.63570636 0.48153827
5690 taylr-74          B 1998 1.94630194 3.63570636

HTH,

Marc Schwartz



From grazzi at sssup.it  Thu Oct 13 23:14:38 2005
From: grazzi at sssup.it (Marco Grazzi)
Date: Thu, 13 Oct 2005 17:14:38 -0400
Subject: [R] shell scripts in R
Message-ID: <200510131714.38811.grazzi@sssup.it>


Hi,

How can I execute some scripts from within R.
I have a large data file which I process (for instance with gawk, but not 
only) before performing some statistics.
I would like to do this in R, so that I do not have to save many data files 
and then making analysis on them (which proved to be unefficient)

Thank you

Marco Grazzi



From ggrothendieck at gmail.com  Thu Oct 13 23:19:36 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 13 Oct 2005 17:19:36 -0400
Subject: [R] shell scripts in R
In-Reply-To: <200510131714.38811.grazzi@sssup.it>
References: <200510131714.38811.grazzi@sssup.it>
Message-ID: <971536df0510131419t35c775a2xe40745890320b9b5@mail.gmail.com>

Look at the example that uses gawk and pipe in:

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/59815.html

On 10/13/05, Marco Grazzi <grazzi at sssup.it> wrote:
>
> Hi,
>
> How can I execute some scripts from within R.
> I have a large data file which I process (for instance with gawk, but not
> only) before performing some statistics.
> I would like to do this in R, so that I do not have to save many data files
> and then making analysis on them (which proved to be unefficient)
>
> Thank you
>
> Marco Grazzi
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From A.Robinson at ms.unimelb.edu.au  Thu Oct 13 23:25:53 2005
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 14 Oct 2005 07:25:53 +1000
Subject: [R] shell scripts in R
In-Reply-To: <200510131714.38811.grazzi@sssup.it>
References: <200510131714.38811.grazzi@sssup.it>
Message-ID: <20051013212553.GE52360@ms.unimelb.edu.au>

Marco,

use the system command.

?system

I hope that this helps,

Andrew

On Thu, Oct 13, 2005 at 05:14:38PM -0400, Marco Grazzi wrote:
> 
> Hi,
> 
> How can I execute some scripts from within R.
> I have a large data file which I process (for instance with gawk, but not 
> only) before performing some statistics.
> I would like to do this in R, so that I do not have to save many data files 
> and then making analysis on them (which proved to be unefficient)
> 
> Thank you
> 
> Marco Grazzi
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Andrew Robinson
Senior Lecturer in Statistics                       Tel: +61-3-8344-9763
Department of Mathematics and Statistics            Fax: +61-3-8344-4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au



From samrobertsmith at yahoo.com  Thu Oct 13 23:33:10 2005
From: samrobertsmith at yahoo.com (Sam R. Smith)
Date: Thu, 13 Oct 2005 14:33:10 -0700 (PDT)
Subject: [R] function
Message-ID: <20051013213310.98277.qmail@web30601.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051013/46846af6/attachment.pl

From kb2qzv at poczta.onet.pl  Fri Oct 14 00:04:52 2005
From: kb2qzv at poczta.onet.pl (Benedykt P. Barszcz)
Date: Fri, 14 Oct 2005 00:04:52 +0200
Subject: [R] shell scripts in R
In-Reply-To: <20051013212553.GE52360@ms.unimelb.edu.au>
References: <200510131714.38811.grazzi@sssup.it>
	<20051013212553.GE52360@ms.unimelb.edu.au>
Message-ID: <200510140004.52685.kb2qzv@poczta.onet.pl>

Dnia czwartek, 13 pa??dziernika 2005 23:25, Andrew Robinson napisa??:
> Marco,
>
> use the system command.
>
> ?system
>
> I hope that this helps,

system(ls, intern = FALSE, ignore.stderr = TRUE)
Error in as.character(args[[i]]) : cannot coerce to vector

In fact it ignores the stderr !
-- 
pozdrawiam,
Benedykt

Cyfrowy klucz publiczny / Digital public key 
http://agrypa1.atspace.com/klucze/kb2qzv_onet-public.asc



From chrisb at fcdarwin.org.ec  Thu Oct 13 23:20:04 2005
From: chrisb at fcdarwin.org.ec (Chris Buddenhagen)
Date: Thu, 13 Oct 2005 15:20:04 -0600
Subject: [R] high resolution images for publication
Message-ID: <005d01c5d03b$e0cfa680$4c01a8c0@Chris>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051013/6da88be3/attachment.pl

From sundar.dorai-raj at pdf.com  Fri Oct 14 00:13:14 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 13 Oct 2005 17:13:14 -0500
Subject: [R] shell scripts in R
In-Reply-To: <200510140004.52685.kb2qzv@poczta.onet.pl>
References: <200510131714.38811.grazzi@sssup.it>	<20051013212553.GE52360@ms.unimelb.edu.au>
	<200510140004.52685.kb2qzv@poczta.onet.pl>
Message-ID: <434EDBFA.5080706@pdf.com>



Benedykt P. Barszcz wrote:
> Dnia czwartek, 13 pa??dziernika 2005 23:25, Andrew Robinson napisa??:
> 
>>Marco,
>>
>>use the system command.
>>
>>?system
>>
>>I hope that this helps,
> 
> 
> system(ls, intern = FALSE, ignore.stderr = TRUE)
> Error in as.character(args[[i]]) : cannot coerce to vector
> 
> In fact it ignores the stderr !


Don't you mean system("ls")? See ?system.

Arguments:

command: the system command to be invoked, as a string.

--sundar



From mschwartz at mn.rr.com  Fri Oct 14 00:14:03 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Thu, 13 Oct 2005 17:14:03 -0500
Subject: [R] shell scripts in R
In-Reply-To: <200510140004.52685.kb2qzv@poczta.onet.pl>
References: <200510131714.38811.grazzi@sssup.it>
	<20051013212553.GE52360@ms.unimelb.edu.au>
	<200510140004.52685.kb2qzv@poczta.onet.pl>
Message-ID: <1129241643.6062.9.camel@localhost.localdomain>

On Fri, 2005-10-14 at 00:04 +0200, Benedykt P. Barszcz wrote:
> Dnia czwartek, 13 paÅºdziernika 2005 23:25, Andrew Robinson napisaÅ‚:
> > Marco,
> >
> > use the system command.
> >
> > ?system
> >
> > I hope that this helps,
> 
> system(ls, intern = FALSE, ignore.stderr = TRUE)
> Error in as.character(args[[i]]) : cannot coerce to vector
> 
> In fact it ignores the stderr !

As per ?system:

command      the system command to be invoked, as a string.

Thus,

 system("ls", intern = FALSE, ignore.stderr = TRUE)


HTH,

Marc Schwartz



From A.Robinson at ms.unimelb.edu.au  Fri Oct 14 00:17:36 2005
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 14 Oct 2005 08:17:36 +1000
Subject: [R] shell scripts in R
Message-ID: <20051013221736.GJ52360@ms.unimelb.edu.au>

Benedykt,

No, there is no ls object in your workspace.  Try this:

system("ls", intern = FALSE, ignore.stderr = TRUE)

Andrew

On Fri, Oct 14, 2005 at 12:04:52AM +0200, Benedykt P. Barszcz wrote:
> Dnia czwartek, 13 pa?dziernika 2005 23:25, Andrew Robinson napisa?:
> > Marco,
> >
> > use the system command.
> >
> > ?system
> >
> > I hope that this helps,
> 
> system(ls, intern = FALSE, ignore.stderr = TRUE)
> Error in as.character(args[[i]]) : cannot coerce to vector
> 
> In fact it ignores the stderr !
> -- 
> pozdrawiam,
> Benedykt
> 
> Cyfrowy klucz publiczny / Digital public key 
> http://agrypa1.atspace.com/klucze/kb2qzv_onet-public.asc
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Andrew Robinson
Senior Lecturer in Statistics                       Tel: +61-3-8344-9763
Department of Mathematics and Statistics            Fax: +61-3-8344-4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au



From A.Robinson at ms.unimelb.edu.au  Fri Oct 14 00:28:43 2005
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 14 Oct 2005 08:28:43 +1000
Subject: [R] Do Users of Nonlinear Mixed Effects Models Know Whether
	Their Software Really Works?
In-Reply-To: <434EC14C.3000608@otter-rsch.com>
References: <434EC14C.3000608@otter-rsch.com>
Message-ID: <20051013222843.GK52360@ms.unimelb.edu.au>

Dave,

that's an interesting start for a comparison.  Let me point out some
ways that you might construct a compelling argument.  Of course, these
aren't exhaustive, and others may well provide further depth.

1) If I understand correctly, you're trying to estimate parameters
   from a real dataset.  Why not try a simulated dataset, where you
   know exactly what the true values (and parameter distributions)
   are?

2) Furthermore, an argument from one dataset isn't very
   convincing. The sample size for inference is too small.  Why not
   repeat this procedure many times, sampling from the same base
   model? 

3) Then, you could also vary the structure of the underlying model
   systematically, and assess the comparison of fits as a function of
   the underlying model/dataset nexus.

4) Next, a problem with the example (as I understand it) is that
   although you've computed what you call exact MLE's, I think that
   they're exact when conditioned on the model.  Are they very robust
   to model misspecification?  (I mean beyond large-sample theory).

5) Finally, of course, then making the scripts available for forsenic
   investigations.

Cheers,

Andrew

On Thu, Oct 13, 2005 at 01:19:24PM -0700, dave fournier wrote:
>            Do Users of Nonlinear Mixed Effects Models Know
> 
>                   Whether Their Software Really Works?
> 

-- 
Andrew Robinson
Senior Lecturer in Statistics                       Tel: +61-3-8344-9763
Department of Mathematics and Statistics            Fax: +61-3-8344-4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au



From mschwartz at mn.rr.com  Fri Oct 14 00:33:22 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Thu, 13 Oct 2005 17:33:22 -0500
Subject: [R] high resolution images for publication
In-Reply-To: <005d01c5d03b$e0cfa680$4c01a8c0@Chris>
References: <005d01c5d03b$e0cfa680$4c01a8c0@Chris>
Message-ID: <1129242802.6062.20.camel@localhost.localdomain>

On Thu, 2005-10-13 at 15:20 -0600, Chris Buddenhagen wrote:
> Dear all

> I am using R to produce ordinations library(vegan) and the plot function
> produced looks great on the screen but when I send it to jpg or pdf or eps
> the resolution is not so good. Can you tell me how to get high resolution
> images out of R for publication?

It would be helpful to see the actual code that you are using, as is
asked for in the Posting Guide.

For publication, it would be rare to want to use a bitmapped format such
as jpg/png.

pdf and eps are vector based formats and would be generally preferred
over the above.

I can only hazard a guess to consider that perhaps your height and width
arguments for pdf() and/or postscript() are not set properly, as there
are no other resolution based settings for those formats. By design, the
output resolution is target device dependent.

Please provide the code that you are using and we can respond with more
specific guidance.

HTH,

Marc Schwartz



From kb2qzv at poczta.wp.pl  Fri Oct 14 00:39:59 2005
From: kb2qzv at poczta.wp.pl (Benedict P. Barszcz)
Date: Fri, 14 Oct 2005 00:39:59 +0200
Subject: [R] shell scripts in R
In-Reply-To: <434EDBFA.5080706@pdf.com>
References: <200510131714.38811.grazzi@sssup.it>
	<200510140004.52685.kb2qzv@poczta.onet.pl>
	<434EDBFA.5080706@pdf.com>
Message-ID: <200510140039.59852.kb2qzv@poczta.wp.pl>

Dnia pi??tek, 14 pa??dziernika 2005 00:13, Sundar Dorai-Raj napisa??:

> Don't you mean system("ls")? See ?system.
>
> Arguments:
>
> command: the system command to be invoked, as a string.

This is the kind of obstacles a newbie has to overcome. Whoeve is writing the 
documentation for R, please do not attempt to save on bytes. Life would be so 
much more pleasureable.... if only it would say "as a quoted string". Jee.


-- 
Benedict

Cyfrowy klucz publiczny / Digital public key 
http://agrypa1.atspace.com/klucze/kb2qzv_wp.pl-public.asc



From michaell.taylor at boxwoodmeans.com  Fri Oct 14 00:49:23 2005
From: michaell.taylor at boxwoodmeans.com (Michaell Taylor)
Date: Thu, 13 Oct 2005 17:49:23 -0500
Subject: [R] Maps package, coloration
Message-ID: <1129243763.16105.40.camel@fry>




I am having some trouble getting the colors correct on county maps using
the maps package.  I have a data.frame that contains coloration data for
every county -- it also contains a variable 'mapm' which fits the
'state,county' format used in the mapping package.  

I use this to define colors from a range of 1:100.  The problem is that
the colors seem good for some states/counties, but random for others.
It is almost as if the index has been scrambled, but I find that the
ordering is fine in the data.frame.

I am completely confused, any guidance as to what simple thing that I am
missing here. Any suggestions greatly appreciated.


data(countyMapEnv)
all.names <- map('county',namesonly=T)
all.names1 <- data.frame(mapm=all.names, col=NA,ordin=1:length
(all.names))  
# created a dataframe, to be sure of the 
#	order, I include a variable 'ordin' to index later

# next I merge in the data to use for coloration
# the merge works well, with every element matched
t <- merge(final[,c('PVar','mapm')],all.names1)
# check order once more (redundant perhaps, but I was desperate)
t <- t[order(t$ordin),]

# a little accounting for the colors
t$PVar <- (t$PVar-min(t$PVar,na.rm=T))/(max(t$PVar,na.rm=T)-min(t
$PVar,na.rm=T))
t$col <- round((((t$PVar*100)-100)*-1),0)

# t$col is now a collection of integers from 1 to 100

# again, redundancy out of desperation.
matchm <- match.map('county',t$mapm,exact=T,warn=T)

# define colors with the heat.map palette
color <- heat.colors(100)[t$col[matchm]]
# alternative (also not working)
color <- heat.colors(100)[t$col]

# use the colors to fill the map
map('county',fill=T,col=color)


Michaell Taylor


-- 
================
Michaell Taylor, Phd
Principal

Boxwood Means, Inc
Two Stamford Landing
Suite 100
68 Southfield Avenue
Stamford, CT 06902

(T) 203-653-4100



From brian_cade at usgs.gov  Fri Oct 14 00:54:02 2005
From: brian_cade at usgs.gov (Brian S Cade)
Date: Thu, 13 Oct 2005 16:54:02 -0600
Subject: [R] subsetting data frame using by() or tapply() or other
In-Reply-To: <1129237441.6062.5.camel@localhost.localdomain>
Message-ID: <OF94EFA3E8.25F5A7BE-ON87257099.007D9D0D-87257099.007E2F72@usgs.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051013/60208456/attachment.pl

From otter at otter-rsch.com  Fri Oct 14 01:07:07 2005
From: otter at otter-rsch.com (dave fournier)
Date: Thu, 13 Oct 2005 16:07:07 -0700
Subject: [R] Re : Do Users of Nonlinear Mixed Effects Models Know Whether
 Their Software Really Works?
Message-ID: <434EE89B.2040502@otter-rsch.com>


Actually one can download a working verssion of our software for free.
So anyonme can verify these results.
It is restricted by needing a network connection to get permission to
operate and is for evaluation only.  The current version does not have 
the Gauss Hermite
integration which I put in to find the true value for this comparison,
but it will soon. In addition we have made our
poisson - negative binomial zero inflated mixed model software for R
freely available.

   http://otter-rsch.com/admbre/admbre.html

-- 
David A. Fournier
P.O. Box 2040,
Sidney, B.C. V8l 3s3
Canada
http://otter-rsch.com


--



From vincent.goulet at act.ulaval.ca  Fri Oct 14 01:28:14 2005
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Thu, 13 Oct 2005 19:28:14 -0400
Subject: [R] shell scripts in R
In-Reply-To: <200510140039.59852.kb2qzv@poczta.wp.pl>
References: <200510131714.38811.grazzi@sssup.it> <434EDBFA.5080706@pdf.com>
	<200510140039.59852.kb2qzv@poczta.wp.pl>
Message-ID: <200510131928.14494.vincent.goulet@act.ulaval.ca>

Le 13 Octobre 2005 18:39, Benedict P. Barszcz a ??crit??:
> Dnia pi??tek, 14 pa??dziernika 2005 00:13, Sundar Dorai-Raj napisa??:
> > Don't you mean system("ls")? See ?system.
> >
> > Arguments:
> >
> > command: the system command to be invoked, as a string.
>
> This is the kind of obstacles a newbie has to overcome. Whoeve is writing
> the documentation for R, please do not attempt to save on bytes. Life would
> be so much more pleasureable.... if only it would say "as a quoted string".
> Jee.

In 'system(ls)', 'ls' would be any object, whereas in 'system("ls")', it is a 
string. Specifying "quoted string" would be redundant. (True R wizard can 
correct me if I,m not accurate.)

When I first encountered R's man pages, I thought they were rather sparse 
compared to those of S-Plus. Now I find they are just to the point and so 
much easier to consult!

-- 
  Vincent Goulet, Professeur agr??g??
  ??cole d'actuariat
  Universit?? Laval, Qu??bec 
  Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca



From MSchwartz at mn.rr.com  Fri Oct 14 02:07:07 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Thu, 13 Oct 2005 19:07:07 -0500
Subject: [R] shell scripts in R
In-Reply-To: <200510140039.59852.kb2qzv@poczta.wp.pl>
References: <200510131714.38811.grazzi@sssup.it>
	<200510140004.52685.kb2qzv@poczta.onet.pl> <434EDBFA.5080706@pdf.com>
	<200510140039.59852.kb2qzv@poczta.wp.pl>
Message-ID: <1129248428.4770.3.camel@localhost.localdomain>

On Fri, 2005-10-14 at 00:39 +0200, Benedict P. Barszcz wrote:
> Dnia piÄ…tek, 14 paÅºdziernika 2005 00:13, Sundar Dorai-Raj napisaÅ‚:
> 
> > Don't you mean system("ls")? See ?system.
> >
> > Arguments:
> >
> > command: the system command to be invoked, as a string.
> 
> This is the kind of obstacles a newbie has to overcome. Whoeve is writing the 
> documentation for R, please do not attempt to save on bytes. Life would be so 
> much more pleasureable.... if only it would say "as a quoted string". Jee.

The phrase "quoted string" in my mind is redundant.

If you had taken the time to review the 3 examples provided on the same
page, you would have seen that all three show the use of quotes around
the command and indeed two of the three use the 'ls' command
specifically.

Marc Schwartz



From A.Robinson at ms.unimelb.edu.au  Fri Oct 14 02:09:56 2005
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 14 Oct 2005 10:09:56 +1000
Subject: [R] shell scripts in R
In-Reply-To: <200510140039.59852.kb2qzv@poczta.wp.pl>
References: <200510131714.38811.grazzi@sssup.it>
	<200510140004.52685.kb2qzv@poczta.onet.pl>
	<434EDBFA.5080706@pdf.com> <200510140039.59852.kb2qzv@poczta.wp.pl>
Message-ID: <20051014000956.GA69859@ms.unimelb.edu.au>

First I have to correct myself; there probably is an ls object in your
workspace, but it's a function.

Second I have to suggest you should try to run the example code in the
help file.  Surely this would clarify that the string has to be
quoted?

t1 <- system("who", TRUE)

I'm not so sure that it's a question of saving bytes as a question of
assuming that people will try reasonable avenues.

Cheers

Andrew

On Fri, Oct 14, 2005 at 12:39:59AM +0200, Benedict P. Barszcz wrote:
> Dnia pi?tek, 14 pa?dziernika 2005 00:13, Sundar Dorai-Raj napisa?:
> 
> > Don't you mean system("ls")? See ?system.
> >
> > Arguments:
> >
> > command: the system command to be invoked, as a string.
> 
> This is the kind of obstacles a newbie has to overcome. Whoeve is writing the 
> documentation for R, please do not attempt to save on bytes. Life would be so 
> much more pleasureable.... if only it would say "as a quoted string". Jee.
> 
> 
> -- 
> Benedict
> 
> Cyfrowy klucz publiczny / Digital public key 
> http://agrypa1.atspace.com/klucze/kb2qzv_wp.pl-public.asc
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Andrew Robinson
Senior Lecturer in Statistics                       Tel: +61-3-8344-9763
Department of Mathematics and Statistics            Fax: +61-3-8344-4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au



From ggrothendieck at gmail.com  Fri Oct 14 02:29:18 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 13 Oct 2005 20:29:18 -0400
Subject: [R] aggregate slow with many rows - alternative?
In-Reply-To: <47fce0650510131214k5eeaaf41m@mail.gmail.com>
References: <47fce0650510131214k5eeaaf41m@mail.gmail.com>
Message-ID: <971536df0510131729u7c8668dfy8d397b88722de1ff@mail.gmail.com>

Convert dat to a matrix and see if working with the
matrix instead of a data frame speeds things up
enough.

On 10/13/05, Hans-Peter <gchappi at gmail.com> wrote:
> Hi,
>
> I use the code below to aggregate / cnt my test data. It works fine,
> but the problem is with my real data (33'000 rows) where the function
> is really slow (nothing happened in half an hour).
>
> Does anybody know of other functions that I could use?
>
> Thanks,
> Hans-Peter
>
> --------------
> dat <- data.frame( Datum  = c( 32586, 32587, 32587, 32625, 32656,
> 32656, 32656, 32672, 32672, 32699 ),
>              FischerID = c( 58395, 58395, 58395, 88434, 89953, 89953,
> 89953, 64395, 62896, 62870 ),
>              Anzahl = c( 2, 2, 1, 1, 2, 1, 7, 1, 1, 2 ) )
> f <- function(x) data.frame( Datum = x[1,1], FischerID = x[1,2],
> Anzahl = sum( x[,3] ), Cnt = dim( x )[1] )
> t.a <- do.call("rbind", by(dat, dat[,1:2], f))   # slow for 33'000 rows
> t.a <- t.a[order( t.a[,1], t.a[,2] ),]
>
>  # show data
> dat
> t.a
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From f.harrell at vanderbilt.edu  Fri Oct 14 04:59:52 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Thu, 13 Oct 2005 21:59:52 -0500
Subject: [R] aggregate slow with many rows - alternative?
In-Reply-To: <971536df0510131729u7c8668dfy8d397b88722de1ff@mail.gmail.com>
References: <47fce0650510131214k5eeaaf41m@mail.gmail.com>
	<971536df0510131729u7c8668dfy8d397b88722de1ff@mail.gmail.com>
Message-ID: <434F1F28.3070109@vanderbilt.edu>

Gabor Grothendieck wrote:
> Convert dat to a matrix and see if working with the
> matrix instead of a data frame speeds things up
> enough.

In the Hmisc package the asNumericMatrix and matrix2dataFrame functions 
facilite this.

Also look at the summarize and mApply functions in Hmisc, which can be 
quite fast.

Frank Harrell



From edd at debian.org  Fri Oct 14 05:04:32 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 13 Oct 2005 22:04:32 -0500
Subject: [R] How to install R 2.2.0 Debian 'unstable' package
	in	otherwise 'sarge' system
In-Reply-To: <200510131306.32098.vincent.goulet@act.ulaval.ca>
References: <Pine.GSO.4.62.0510121542520.6573@harper.uchicago.edu>
	<20051012220343.GA12499@eddelbuettel.com>
	<200510131306.32098.vincent.goulet@act.ulaval.ca>
Message-ID: <17231.8256.61429.150197@basebud.nulle.part>


Vincent,

On 13 October 2005 at 13:06, Vincent Goulet wrote:
| Le 12 Octobre 2005 18:03, Dirk Eddelbuettel a ??crit??:
| > i) In general, and especially between 'testing' and 'unstable', use
| > apt-pinning, explained in the apt-howto packages, esp apt-howto-en for
| > English; and on various places across the Net; try Google'ing for
| > apt-pinning.
| 
| Dear Dirk,
| 
| I'll jump in because I've been wondering how to do this for some time. 
| 
| Is there any way to pin a whole series of packages using wildcards? I can 
| otherwise pin r-base and r-recommended, but the packages they depend on will 
| not be pinned themselves. 
| 
| It thus seems the only way to have 'unstable' R packages on my 'testing' 
| system is to list them all in /etc/apt/preferences. It is neither convenient 
| nor "safe" since I will eventually miss unlisted packages.

Good question, and I don't have an answer.  This may be a question for
debian-user ...  On my machines, I have a local archive containing my builds
for Debian so I get packages such as R and the r-cran-* packages from there.

Amicalement,  Dirk

-- 
Statistics: The (futile) attempt to offer certainty about uncertainty.
         -- Roger Koenker, 'Dictionary of Received Ideas of Statistics'



From samrobertsmith at yahoo.com  Fri Oct 14 09:21:36 2005
From: samrobertsmith at yahoo.com (Sam R. Smith)
Date: Fri, 14 Oct 2005 00:21:36 -0700 (PDT)
Subject: [R] Fortran?
Message-ID: <20051014072136.90774.qmail@web30603.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051014/d37c3a78/attachment.pl

From Roger.Bivand at nhh.no  Fri Oct 14 09:32:34 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 14 Oct 2005 09:32:34 +0200 (CEST)
Subject: [R] Fortran?
In-Reply-To: <20051014072136.90774.qmail@web30603.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.44.0510140930490.29736-100000@reclus.nhh.no>

On Fri, 14 Oct 2005, Sam R. Smith wrote:

> In a package, i type a function name and got the following message:
> ...
>  tmp <- .Fortran("master", x = as.double(x), y = as.double(y), 
>             sort = as.logical(sort), rw = as.double(rw), npd = as.integer(npd), 
>             ntot = as.integer(ntot), nadj = integer(tadj), madj = as.integer(madj), 
>             ind = integer(npd), tx = double(npd), ty = double(npd), 
>             ilist = integer(npd), eps = as.double(eps), delsgs = double(tdel), 
>             ndel = as.integer(ndel), delsum = double(ntdel), 
>             dirsgs = double(tdir), ndir = as.integer(ndir), dirsum = double(ntdir), 
>             nerror = integer(1))
> ...
> does it mean this function is using something from FORTRAN?

You have asked twice. Please:

PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

When uncertain what a function does, type help(function_name), or 
?function_name, here ?.Fortran, for the answer to your question.

> Thanks a lot!
> 
> 
> 
> 		
> ---------------------------------
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From p.dalgaard at biostat.ku.dk  Fri Oct 14 09:34:43 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 Oct 2005 09:34:43 +0200
Subject: [R] Fortran?
In-Reply-To: <20051014072136.90774.qmail@web30603.mail.mud.yahoo.com>
References: <20051014072136.90774.qmail@web30603.mail.mud.yahoo.com>
Message-ID: <x2psq84kmk.fsf@turmalin.kubism.ku.dk>

"Sam R. Smith" <samrobertsmith at yahoo.com> writes:

> In a package, i type a function name and got the following message:
> ...
>  tmp <- .Fortran("master", x = as.double(x), y = as.double(y), 
>             sort = as.logical(sort), rw = as.double(rw), npd = as.integer(npd), 
>             ntot = as.integer(ntot), nadj = integer(tadj), madj = as.integer(madj), 
>             ind = integer(npd), tx = double(npd), ty = double(npd), 
>             ilist = integer(npd), eps = as.double(eps), delsgs = double(tdel), 
>             ndel = as.integer(ndel), delsum = double(ntdel), 
>             dirsgs = double(tdir), ndir = as.integer(ndir), dirsum = double(ntdir), 
>             nerror = integer(1))
> ...
> does it mean this function is using something from FORTRAN?

Well, it's using a binary object that was compiled from FORTRAN code.

The sources for the package will contain the actual human-readable
code. For more details (likely more than you can handle at this
point...), look in the Writing R Extensions manual.

> Thanks a lot!

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From Matthias.Templ at statistik.gv.at  Fri Oct 14 10:34:06 2005
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Fri, 14 Oct 2005 10:34:06 +0200
Subject: [R] aggregate slow with many rows - alternative?
Message-ID: <83536658864BC243BE3C06D7E936ABD5027BAC7F@xchg1.statistik.local>

Hi,

Yesterday, I have analysed data with 160000 rows and 10 columns. 
Aggregation would be impossible with a data frame format, but when converting it to a matrix with *numeric* entries (check, if the variables are of class numeric!) the computation needs only 7 seconds on a Pentium III. I??m sadly to say, that this is also slow in comparsion with the proc summary in SAS (less than one second), but the code is much more elegant in R!

Best,
Matthias


> Hi,
> 
> I use the code below to aggregate / cnt my test data. It 
> works fine, but the problem is with my real data (33'000 
> rows) where the function is really slow (nothing happened in 
> half an hour).
> 
> Does anybody know of other functions that I could use?
> 
> Thanks,
> Hans-Peter
> 
> --------------
> dat <- data.frame( Datum  = c( 32586, 32587, 32587, 32625, 
> 32656, 32656, 32656, 32672, 32672, 32699 ),
>               FischerID = c( 58395, 58395, 58395, 88434, 
> 89953, 89953, 89953, 64395, 62896, 62870 ),
>               Anzahl = c( 2, 2, 1, 1, 2, 1, 7, 1, 1, 2 ) )
> f <- function(x) data.frame( Datum = x[1,1], FischerID = 
> x[1,2], Anzahl = sum( x[,3] ), Cnt = dim( x )[1] )
> t.a <- do.call("rbind", by(dat, dat[,1:2], f))   # slow for 
> 33'000 rows
> t.a <- t.a[order( t.a[,1], t.a[,2] ),]
> 
>   # show data
> dat
> t.a
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read 
> the posting guide! http://www.R-project.org/posting-guide.html
>



From Christoph.Scherber at uni-jena.de  Fri Oct 14 10:39:11 2005
From: Christoph.Scherber at uni-jena.de (Christoph Scherber)
Date: Fri, 14 Oct 2005 10:39:11 +0200
Subject: [R] dataframe (matrix) multiplication
Message-ID: <434F6EAF.4050105@uni-jena.de>

Dear R users,

Suppose I have 2 parts of a dataframe, say

ABCD
2143
3245
2154

(the real dataframe is 160 columns with each 120 rows)

and I want to multiply every element in [,A:B] with every element in [,C:D];
What is the most elegant way to do this?

I??ve been thinking of converting [,A:B] to a matrix, and then 
multiplying it with the inverse of [,C:D]; would that be correct?

The result should look like

E;F
8;3
12;10
10;4

Thanks very much for any suggestions
Christoph



From pwolf at wiwi.uni-bielefeld.de  Fri Oct 14 10:59:21 2005
From: pwolf at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Fri, 14 Oct 2005 10:59:21 +0200
Subject: [R] dataframe (matrix) multiplication
In-Reply-To: <434F6EAF.4050105@uni-jena.de>
References: <434F6EAF.4050105@uni-jena.de>
Message-ID: <434F7369.2000304@wiwi.uni-bielefeld.de>

where is the problem?

input:
A<-c(2,3,2); B<-c(1,2,1); C<-c(4,4,5); D<-c(3,5,4)
df<-data.frame(A,B,C,D)
c1<-1:2; c2<-3:4
df[,c1]*df[,c2]

output:
   A  B
1  8  3
2 12 10
3 10  4

Peter Wolf


Christoph Scherber wrote:
>Dear R users,
>
>Suppose I have 2 parts of a dataframe, say
>
>ABCD
>2143
>3245
>2154
>
>(the real dataframe is 160 columns with each 120 rows)
>
>and I want to multiply every element in [,A:B] with every element in [,C:D];
>What is the most elegant way to do this?
>
>I??ve been thinking of converting [,A:B] to a matrix, and then 
>multiplying it with the inverse of [,C:D]; would that be correct?
>
>The result should look like
>
>E;F
>8;3
>12;10
>10;4
>
>Thanks very much for any suggestions
>Christoph
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From jholtman at gmail.com  Fri Oct 14 11:23:12 2005
From: jholtman at gmail.com (jim holtman)
Date: Fri, 14 Oct 2005 05:23:12 -0400
Subject: [R] aggregate slow with many rows - alternative?
In-Reply-To: <83536658864BC243BE3C06D7E936ABD5027BAC7F@xchg1.statistik.local>
References: <83536658864BC243BE3C06D7E936ABD5027BAC7F@xchg1.statistik.local>
Message-ID: <644e1f320510140223j49cefd4tf1c6606be68022a1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051014/bbd7722d/attachment.pl

From sara at gmesintra.com  Fri Oct 14 11:44:34 2005
From: sara at gmesintra.com (Sara Mouro)
Date: Fri, 14 Oct 2005 10:44:34 +0100
Subject: [R] zip package
Message-ID: <200510140944.j9E9iXbL023577@hypatia.math.ethz.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051014/a2974e26/attachment.pl

From ripley at stats.ox.ac.uk  Fri Oct 14 12:26:02 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 14 Oct 2005 11:26:02 +0100 (BST)
Subject: [R] arima: warning when fixing MA parameters.
In-Reply-To: <BC8BB8E6-FCEE-4E76-9090-67819A5B3984@anu.edu.au>
References: <BC8BB8E6-FCEE-4E76-9090-67819A5B3984@anu.edu.au>
Message-ID: <Pine.LNX.4.61.0510141121470.22047@gannet.stats>

It's a bug: the code has 1:arma[1], i.e. 1:0.  Replace by 
seq(length=arma[1]).

On Thu, 13 Oct 2005, John Maindonald wrote:

> I am puzzled by the warning message in the output below.  It appears
> whether or not I fit the seasonal term (but the precise point of doing
> this was to fit what is effectively a second seasonal term).  Is there
> some deep reason why AR parameters
> ("Warning message: some AR parameters were fixed: ...")
> should somehow intrude into the fitting of a model that has only MA
> terms?
>
> > library(DAAG)
> > attach(bomsoi)
> > # The following is fine:
> > arima(avrain, order=c(0,0,4), seasonal=list(order=c(0,0,1),
> period=12),
> +  fixed=c(NA,0,0,NA,NA,NA))
> .....
> > # The following generates a warning message
> > arima(avrain, order=c(0,0,4), seasonal=list(order=c(0,0,1),
> period=12),
> +  fixed=c(0,0,0,NA,NA,NA))
>
> Call:
> arima(x = avrain, order = c(0, 0, 4), seasonal = list(order = c(0, 0,
> 1), period = 12),
>     fixed = c(0, 0, 0, NA, NA, NA))
>
> Coefficients:
>       ma1  ma2  ma3     ma4     sma1  intercept
>         0    0    0  0.0357  -0.1061   456.6675
> s.e.    0    0    0  0.1015   0.0886     7.6997
>
> sigma^2 estimated as 6849:  log likelihood = -595.23,  aic = 1198.46
> Warning message:
> some AR parameters were fixed: setting transform.pars = FALSE in:
> arima(avrain, order = c(0, 0, 4), seasonal = list(order = c(0,
>
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Bioinformation Science, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gchappi at gmail.com  Fri Oct 14 12:30:37 2005
From: gchappi at gmail.com (Hans-Peter)
Date: Fri, 14 Oct 2005 12:30:37 +0200
Subject: [R] aggregate slow with many rows - alternative?
In-Reply-To: <644e1f320510140223j49cefd4tf1c6606be68022a1@mail.gmail.com>
References: <83536658864BC243BE3C06D7E936ABD5027BAC7F@xchg1.statistik.local>
	<644e1f320510140223j49cefd4tf1c6606be68022a1@mail.gmail.com>
Message-ID: <47fce0650510140330q215bb7ben@mail.gmail.com>

Many thanks for all your answers. Converting to a matrix didn't help,
I tried with Hmisc but didn't get anywhere (different summary
functions, multiple levels).

2005/10/14, jim holtman <jholtman at gmail.com>:
> Here is the way that I would do it.  Using 'lapply' to process the list and create a matrix

[snip]

Wow! That's a wonderful suggestion, Your code works just fine with my
data (takes 11 seconds). Thanks a lot, I couldn't have written such
code (reading some help entries now...).

Hans-Peter



From jsorkin at grecc.umaryland.edu  Fri Oct 14 12:31:51 2005
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Fri, 14 Oct 2005 06:31:51 -0400
Subject: [R] zip package
Message-ID: <s34f5100.016@medicine.umaryland.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051014/1658301d/attachment.pl

From ligges at statistik.uni-dortmund.de  Fri Oct 14 12:49:10 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 14 Oct 2005 12:49:10 +0200
Subject: [R] zip package
In-Reply-To: <200510140944.j9E9iXbL023577@hypatia.math.ethz.ch>
References: <200510140944.j9E9iXbL023577@hypatia.math.ethz.ch>
Message-ID: <434F8D26.8030504@statistik.uni-dortmund.de>

Sara Mouro wrote:

> 	Dear all
> 
> 	I can not understand how to install the package lpsolve_1.1.9.zip
> 
> 	I have read the FAQ and the help pages carefully, but it still not
> clear for me.
> 
> 	I have tried the following (and obtained the respective error
> messages):
> 
> 	
> 
>>install.packages("c:/ProgramFiles/R/rw2011/library/lpSolve_1.1.9",destdir="
> 
> c:/ProgramFiles/R/rw2011/library/lpSolve")
> 	Mensagem de aviso:
> 			no package 'c:/Program
> Files/R/rw2011/library/lpSolve_1.1.9' at the repositories in:
> download.packages(pkgs, destdir = tmpd, available = available,  
> 
> 	
> 
>>install.packages("lpSolve_1.1.9",destdir="c:/ProgramFiles/R/rw2011/library/
> 
> lpSolve")
> 	Erro em download.packages(pkgs, destdir = tmpd, available =
> available,  : 
> 	        'destdir' is not a directory
> 
> 	>install.packages("lpSolve_1.1.9",destdir=NULL)
> 	Mensagem de aviso:
> 			no package 'lpSolve_1.1.9' at the repositories in:
> download.packages(pkgs, destdir = tmpd, available = available,  
> 
> 	Could you please tell me how to do that or when can I find a simple
> example of that kind of installation?
> 
> 	Thank you so much and sorry for such basic question.
> 
> 	Sara Mouro
> 
> 	[[alternative HTML version deleted]]


For example in the help pages, the manuals, the FAQ, and some R News 
article in the R Help Desk.

Anyway, you simply want to say
    install.packages("lpSolve")
to get a copy installed from CRAN or
   install.packages("C:/Path/to/Zip/File/Package_Version.zip", repos = NULL)

to install a binary package you already got on your harddisk.

Uwe Ligges


> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Allan at STATS.uct.ac.za  Fri Oct 14 13:06:03 2005
From: Allan at STATS.uct.ac.za (Clark Allan)
Date: Fri, 14 Oct 2005 13:06:03 +0200
Subject: [R] R: source
Message-ID: <434F911B.41DF85F2@STATS.uct.ac.za>

hi all

i have a quick question

i would like to use the source command but i keep on getting an error

eg

source("c:/research file/model.txt")



the problem seems to be because of the space in the file name but this
is how windows references the folder name.  

i dont want to change the folder name

??/


allan

From jfox at mcmaster.ca  Fri Oct 14 13:06:29 2005
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 14 Oct 2005 07:06:29 -0400
Subject: [R] zip package
In-Reply-To: <200510140944.j9E9iXbL023577@hypatia.math.ethz.ch>
Message-ID: <20051014110629.HKGQ21026.tomts16-srv.bellnexxia.net@JohnDesktop8300>

Dear Sara,

It looks to me as if there are three problems here: (1) Is the zip file for
the package really at "c:/ProgramFiles/R/rw2011/library/lpSolve_1.1.9"? That
is, isn't there a space in "Program Files"? (2) You have to specify
repos=NULL to install from a local zip file, as ?install.packages tells you.
(3) You don't seem to be using the destdir argument correctly; you can omit
it.

Why not avoid all this and just use the R for Windows menus: Packages ->
Install package(s) from local zip files?

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Sara Mouro
> Sent: Friday, October 14, 2005 4:45 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] zip package
> 
> 	Dear all
> 
> 	I can not understand how to install the package 
> lpsolve_1.1.9.zip
> 
> 	I have read the FAQ and the help pages carefully, but 
> it still not clear for me.
> 
> 	I have tried the following (and obtained the respective error
> messages):
> 
> 	
> >install.packages("c:/ProgramFiles/R/rw2011/library/lpSolve_1.
1.9",destdir="
> c:/ProgramFiles/R/rw2011/library/lpSolve")
> 	Mensagem de aviso:
> 			no package 'c:/Program
> Files/R/rw2011/library/lpSolve_1.1.9' at the repositories in:
> download.packages(pkgs, destdir = tmpd, available = available,  
> 
> 	
> >install.packages("lpSolve_1.1.9",destdir="c:/ProgramFiles/R/r
w2011/libr
> >ary/
> lpSolve")
> 	Erro em download.packages(pkgs, destdir = tmpd, 
> available = available,  : 
> 	        'destdir' is not a directory
> 
> 	>install.packages("lpSolve_1.1.9",destdir=NULL)
> 	Mensagem de aviso:
> 			no package 'lpSolve_1.1.9' at the 
> repositories in:
> download.packages(pkgs, destdir = tmpd, available = available,  
> 
> 	Could you please tell me how to do that or when can I 
> find a simple example of that kind of installation?
> 
> 	Thank you so much and sorry for such basic question.
> 
> 	Sara Mouro
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From HDoran at air.org  Fri Oct 14 13:13:22 2005
From: HDoran at air.org (Doran, Harold)
Date: Fri, 14 Oct 2005 07:13:22 -0400
Subject: [R] R: source
Message-ID: <88EAF3512A55DF46B06B1954AEF73F740A31CC0E@dc1ex2.air.org>

Use file.choose() instead

> source(file.choose())

This will open a dialogue box and might be easier for you to find your
file. 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Clark Allan
Sent: Friday, October 14, 2005 7:06 AM
To: r-help at stat.math.ethz.ch
Subject: [R] R: source

hi all

i have a quick question

i would like to use the source command but i keep on getting an error

eg

source("c:/research file/model.txt")



the problem seems to be because of the space in the file name but this
is how windows references the folder name.  

i dont want to change the folder name

??/


allan



From p.dalgaard at biostat.ku.dk  Fri Oct 14 13:15:12 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 Oct 2005 13:15:12 +0200
Subject: [R] zip package
In-Reply-To: <434F8D26.8030504@statistik.uni-dortmund.de>
References: <200510140944.j9E9iXbL023577@hypatia.math.ethz.ch>
	<434F8D26.8030504@statistik.uni-dortmund.de>
Message-ID: <x2ll0wtkn3.fsf@viggo.kubism.ku.dk>

Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:

> Sara Mouro wrote:
> 
> > 	Dear all
> > 
> > 	I can not understand how to install the package lpsolve_1.1.9.zip
> > 
> > 	I have read the FAQ and the help pages carefully, but it still not
> > clear for me.
> > 
> > 	I have tried the following (and obtained the respective error
> > messages):
> > 
> > 	
> > 
> >>install.packages("c:/ProgramFiles/R/rw2011/library/lpSolve_1.1.9",destdir="
> > 
> > c:/ProgramFiles/R/rw2011/library/lpSolve")
> > 	Mensagem de aviso:
> > 			no package 'c:/Program
> > Files/R/rw2011/library/lpSolve_1.1.9' at the repositories in:
> > download.packages(pkgs, destdir = tmpd, available = available,  
> > 
> > 	
> > 
> >>install.packages("lpSolve_1.1.9",destdir="c:/ProgramFiles/R/rw2011/library/
> > 
> > lpSolve")
> > 	Erro em download.packages(pkgs, destdir = tmpd, available =
> > available,  : 
> > 	        'destdir' is not a directory
> > 
> > 	>install.packages("lpSolve_1.1.9",destdir=NULL)
> > 	Mensagem de aviso:
> > 			no package 'lpSolve_1.1.9' at the repositories in:
> > download.packages(pkgs, destdir = tmpd, available = available,  
> > 
> > 	Could you please tell me how to do that or when can I find a simple
> > example of that kind of installation?
> > 
> > 	Thank you so much and sorry for such basic question.
> > 
> > 	Sara Mouro
> > 
> > 	[[alternative HTML version deleted]]
> 
> 
> For example in the help pages, the manuals, the FAQ, and some R News 
> article in the R Help Desk.
> 
> Anyway, you simply want to say
>     install.packages("lpSolve")
> to get a copy installed from CRAN or
>    install.packages("C:/Path/to/Zip/File/Package_Version.zip", repos = NULL)
> 
> to install a binary package you already got on your harddisk.
> 
> Uwe Ligges

Or maybe use the user-friendly menu entry "Install package from local
ZIP file" in the Packages menu??


-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From liuwensui at gmail.com  Fri Oct 14 13:28:44 2005
From: liuwensui at gmail.com (Wensui Liu)
Date: Fri, 14 Oct 2005 07:28:44 -0400
Subject: [R] fast and stable way to read data in R
Message-ID: <1115a2b00510140428s588ffbecy436973fef03de3e3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051014/b9935005/attachment.pl

From ripley at stats.ox.ac.uk  Fri Oct 14 14:49:19 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 14 Oct 2005 13:49:19 +0100 (BST)
Subject: [R] fast and stable way to read data in R
In-Reply-To: <1115a2b00510140428s588ffbecy436973fef03de3e3@mail.gmail.com>
References: <1115a2b00510140428s588ffbecy436973fef03de3e3@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0510141336000.29017@gannet.stats>

On Fri, 14 Oct 2005, Wensui Liu wrote:

> Dear useRs,
>
> I am wondering what is the most fast and stable way to read data (pretty
> large) into R. Right now, the methods I could think of are:
> 1) use read.table to read *.csv or *txt
> 2) use RODBC to read excel or access
>
> But I don't know which is better.

Depends on the data and how large is `pretty large'.

If your data are numeric, 2) will be faster as you will avoid
numeric->character->numeric conversions.  If your data are to be factors,
1) might be as fast.

However, both are pretty much instantaneous unless you have millions 
of items to read (and Excel is unlikely to cope well with such numbers).
I just tested reading 1 million numbers from an 18Mb file in 3s with 
read.table().

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Hans.Skaug at mi.uib.no  Fri Oct 14 14:55:59 2005
From: Hans.Skaug at mi.uib.no (Hans Julius Skaug)
Date: Fri, 14 Oct 2005 14:55:59 +0200
Subject: [R] Do Users of Nonlinear Mixed Effects Models Know Whether Their
	Software Really Works?
Message-ID: <5BCBA62ECB426A47AE66567CDF930F9829196A@HUGIN.uib.no>


Dear Andrew and R-list,

I guess Fournier is addressing the properties of the numerical routines
underlying the various packages, not the statistical properties of the MLE itself.
For this purpose using a small tricky dataset makes sense. Clearly,
a true unique MLE exists (except in pathological cases), defined
as the maximizer of the marginal likelihood, evaluated using perfect precision numerical integration.
Since all the packages are aiming at calculating the MLE, it makes sense to compare them 
on this ground. I think the point in Lesaffre et al is that the default settings of many packages may 
give you something very different from the true MLE.


best regards,

hans


> 1) If I understand correctly, you're trying to estimate parameters
>    from a real dataset.  Why not try a simulated dataset, where you
>    know exactly what the true values (and parameter distributions)
>    are?
> 
> 2) Furthermore, an argument from one dataset isn't very
>    convincing. The sample size for inference is too small.  Why not
>    repeat this procedure many times, sampling from the same base
>    model? 
> 
> 3) Then, you could also vary the structure of the underlying model
>    systematically, and assess the comparison of fits as a function of
>    the underlying model/dataset nexus.
> 
> 4) Next, a problem with the example (as I understand it) is that
>    although you've computed what you call exact MLE's, I think that
>    they're exact when conditioned on the model.  Are they very robust
>    to model misspecification?  (I mean beyond large-sample theory).
> 
> 5) Finally, of course, then making the scripts available for forsenic
>    investigations.
> 
> Cheers,
> 
> Andrew

_____________________________
Hans Julius Skaug

Department of Mathematics
University of Bergen
Johannes Brunsgate 12
5008 Bergen
Norway
ph. (+47) 55 58 48 61



From ggrothendieck at gmail.com  Fri Oct 14 15:25:46 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 14 Oct 2005 09:25:46 -0400
Subject: [R] R: source
In-Reply-To: <434F911B.41DF85F2@STATS.uct.ac.za>
References: <434F911B.41DF85F2@STATS.uct.ac.za>
Message-ID: <971536df0510140625k78ab5565te9b532a2f828c648@mail.gmail.com>

On 10/14/05, Clark Allan <Allan at stats.uct.ac.za> wrote:
> hi all
>
> i have a quick question
>
> i would like to use the source command but i keep on getting an error
>
> eg
>
> source("c:/research file/model.txt")
>
>
>
> the problem seems to be because of the space in the file name but this
> is how windows references the folder name.

I am able to source files from folders whose names have a space
in them so I suspect you have the path or filename wrong.  I am using
Windows XP with R 2.2.0.  The file.choose suggestion already given
will work around that or you may wish to double check it
using dir/b/s/p from the Windows console.

>
> i dont want to change the folder name
>



From tamir at imp.univie.ac.at  Fri Oct 14 15:33:05 2005
From: tamir at imp.univie.ac.at (Ido M. Tamir)
Date: Fri, 14 Oct 2005 15:33:05 +0200
Subject: [R] extracting from data frame multiple times
Message-ID: <200510141533.05657.tamir@imp.univie.ac.at>

Hello,
i am trying to subset a dataframe multiple times:
something like:

stats <- by(df, list(items), ttestData)

ttestData <- function(df){
    t.test( df[,c(2,3,4), df[,c(5,6,7)]
}

While this works for small data, it is to slow for my
actual data: 500000 rows dataframe with 
about 135000 different indices, subsetting the
dataframe into chunks of 5 on average.

Do you have any suggestions how I could speed this up?

I tried changing to call by reference with
the package ref, but by does not like that.

Thank you very much in advance
Ido Tamir



From dushoff at eno.princeton.edu  Fri Oct 14 16:03:24 2005
From: dushoff at eno.princeton.edu (Jonathan Dushoff)
Date: Fri, 14 Oct 2005 10:03:24 -0400 (EDT)
Subject: [R] mtext: rotating text
In-Reply-To: <mailman.9.1129284001.26624.r-help@stat.math.ethz.ch>
References: <mailman.9.1129284001.26624.r-help@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.61.0510140954210.302@tahawus.Princeton.EDU>

Recently, I was trying to make an inward-facing label for a vertical
axis on the right-hand side of a plot.  The inward-facing label was
required by a journal.  I searched R-help, but the only solution I found
was to use text, which requires fiddling with the x-coordinate for each
plot.  What would have been perfect is a way to rotate text in mtext.

I had a similar problem trying to use mtext to put a vertical label on a
vertical axis with horizontal tick labels.  

Jonathan Dushoff



From ligges at statistik.uni-dortmund.de  Fri Oct 14 16:17:34 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 14 Oct 2005 16:17:34 +0200
Subject: [R] mtext: rotating text
In-Reply-To: <Pine.LNX.4.61.0510140954210.302@tahawus.Princeton.EDU>
References: <mailman.9.1129284001.26624.r-help@stat.math.ethz.ch>
	<Pine.LNX.4.61.0510140954210.302@tahawus.Princeton.EDU>
Message-ID: <434FBDFE.3060805@statistik.uni-dortmund.de>

Jonathan Dushoff wrote:

> Recently, I was trying to make an inward-facing label for a vertical
> axis on the right-hand side of a plot.  The inward-facing label was
> required by a journal.  I searched R-help, but the only solution I found
> was to use text, which requires fiddling with the x-coordinate for each
> plot.  What would have been perfect is a way to rotate text in mtext.

Indeed, so we can expect a contribution?


> I had a similar problem trying to use mtext to put a vertical label on a
> vertical axis with horizontal tick labels.  

plot(1:10, las=1)
mtext("Hello", 2)

or using par():

opar <- par(las=1)
plot(1:10)
par(opar)
mtext("Hello", 2)


Uwe Ligges


> Jonathan Dushoff
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Emmanuel.Maroye at kae.com  Fri Oct 14 16:22:35 2005
From: Emmanuel.Maroye at kae.com (Emmanuel Maroye)
Date: Fri, 14 Oct 2005 15:22:35 +0100
Subject: [R] R & OLAP engines, an integration?
Message-ID: <BFFAAAFD2B7DBC479BC6A1A9B8CABBA098FC20@london02.kae.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: -- not available on request of Emmanuel Maroye

From tlumley at u.washington.edu  Fri Oct 14 16:38:22 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 14 Oct 2005 07:38:22 -0700 (PDT)
Subject: [R] extracting from data frame multiple times
In-Reply-To: <200510141533.05657.tamir@imp.univie.ac.at>
References: <200510141533.05657.tamir@imp.univie.ac.at>
Message-ID: <Pine.LNX.4.63a.0510140731050.12372@homer24.u.washington.edu>

On Fri, 14 Oct 2005, Ido M. Tamir wrote:

> Hello,
> i am trying to subset a dataframe multiple times:
> something like:
>
> stats <- by(df, list(items), ttestData)
>
> ttestData <- function(df){
>    t.test( df[,c(2,3,4), df[,c(5,6,7)]
> }
>
> While this works for small data, it is to slow for my
> actual data: 500000 rows dataframe with
> about 135000 different indices, subsetting the
> dataframe into chunks of 5 on average.
>
> Do you have any suggestions how I could speed this up?

The first step is to find out what is too slow, using Rprof().  It may be 
the t.test or it may be the by().

If it is the by() you could put the numeric data into two matrices
   x1<-df[,2:4]
   x2<-df[,5:7]
order them so that the same "item" entries were adjacent, compute the 
start and end indices for each group, and do something like
lapply(1:howevermany, function(i) t.test(x1[start[i]:end[i],],x2[start[i]:end[i]))
Even just turning df into a matrix might help

If it is the repeated t.test() calls that are too slow you need to speed 
them up.  You can probably rowsum() to compute means and variances for all 
the t-tests at once.

 	-thomas



From macq at llnl.gov  Fri Oct 14 16:42:08 2005
From: macq at llnl.gov (Don MacQueen)
Date: Fri, 14 Oct 2005 07:42:08 -0700
Subject: [R] shell scripts in R
In-Reply-To: <200510140039.59852.kb2qzv@poczta.wp.pl>
References: <200510131714.38811.grazzi@sssup.it>
	<200510140004.52685.kb2qzv@poczta.onet.pl>	<434EDBFA.5080706@pdf.com>
	<200510140039.59852.kb2qzv@poczta.wp.pl>
Message-ID: <p06210201bf7571e17df2@[128.115.153.6]>

But,
    > foo <- 'ls'
   > system(foo)
is valid.

Is foo a "string" or a "quoted string"?
Without a doubt, it is the former. But I don't see any quote marks in

    system(foo)

-Don

At 12:39 AM +0200 10/14/05, Benedict P. Barszcz wrote:
>Dnia pi??tek, 14 pa??dziernika 2005 00:13, Sundar Dorai-Raj napisa??:
>
>>  Don't you mean system("ls")? See ?system.
>>
>>  Arguments:
>>
>>  command: the system command to be invoked, as a string.
>
>This is the kind of obstacles a newbie has to overcome. Whoeve is writing the
>documentation for R, please do not attempt to save on bytes. Life would be so
>much more pleasureable.... if only it would say "as a quoted string". Jee.
>
>
>--
>Benedict
>
>Cyfrowy klucz publiczny / Digital public key
>http://agrypa1.atspace.com/klucze/kb2qzv_wp.pl-public.asc
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From jporzak at gmail.com  Fri Oct 14 17:32:48 2005
From: jporzak at gmail.com (Jim Porzak)
Date: Fri, 14 Oct 2005 08:32:48 -0700
Subject: [R] R & OLAP engines, an integration?
In-Reply-To: <BFFAAAFD2B7DBC479BC6A1A9B8CABBA098FC20@london02.kae.local>
References: <BFFAAAFD2B7DBC479BC6A1A9B8CABBA098FC20@london02.kae.local>
Message-ID: <2a9c000c0510140832l6ed73071q32abe7ccfd953ea9@mail.gmail.com>

Hi Emmanuel,

We are doing some work along these lines. See www.OpenI.org for
details of our open souce OLAP solution & contact our CTO, Sandeep
Giri (via link on that site), for details. We haven't released any R
integration yet, but we are doing some things internally & it is on
the OpenI development roadmap.

I think OLAP definitely needs integration with some hard analytics.
Sure, our business analysts are very comfortable moving around in OLAP
space & come up with some amazing insights, but OLAP just provides
simple counts, sums etc. No sense of estimated errors or tests of
significance. And, of course, no advanced techniques.

One technical point, some methods would require a "drill-through" to
the underlying data set. For example, while a mosaic plot can be
generated from a 2-dimensional OLAP result table, generating a box
plot corresponding to a OLAP bar chart (my personal favorite) needs
the raw data points.

We welcome everyone interested in this idea to join in the discussion
& effort. The OpenI forum
http://sourceforge.net/forum/?group_id=142873 is probably a better
place than here.


On 10/14/05, Emmanuel Maroye <Emmanuel.Maroye at kae.com> wrote:
> Hi.
>
> I am a consultant at KAE: Marketing Intelligence (http://www.kae.co.uk) working on market evaluation and forecasting.  Working on large datasets I am looking for a solution to use R on datasets stored in an OLAP engine (like MIS Alea, Applix TM1 or Mondrian).  Have you ever heard about such a solution?
>
> The idea is to apply R methods directly on data stored in an OLAP.  The results being part of the OLAP as well (results write back)...
>
> Thanks in advance.
>
> Best regards,
>
> Emmanuel
>
>
>
>
> _____________________________________
> Emmanuel Maroye
>
> kae: marketing intelligence
> 209 - 215 Blackfriars Road
> London SE1 8NL
> United Kingdom
> D +44 20 7960  3358
> M +44 7914 010 728
> F +44 20 7960  3301
> E emmanuel.maroye at kae.co.uk
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>


--
HTH,
Jim Porzak
Loyalty Matrix Inc.
San Francisco, CA



From 042045003 at fudan.edu.cn  Fri Oct 14 17:32:54 2005
From: 042045003 at fudan.edu.cn (ronggui)
Date: Fri, 14 Oct 2005 23:32:54 +0800
Subject: [R] question about ?list
Message-ID: <0IOC00EJSW1FFD@mail.fudan.edu.cn>

the help page says:

 'is.list' returns 'TRUE' iff its argument is a 'list' _or_ a
     'pairlist' of 'length' > 0, whereas 'is.pairlist' only returns
     'TRUE' in the latter case.

does the "latter case" mean a 'pairlist' of 'length' > 0? 

but 
> is.pairlist(pairlist())
[1] TRUE
> length(pairlist())
[1] 0

what the help page exactly means?

	



 				


2005-10-14

------
Deparment of Sociology
Fudan University

My new mail addres is ronggui.huang at gmail.com
Blog:http://sociology.yculblog.com



From ym at climpact.com  Fri Oct 14 17:33:40 2005
From: ym at climpact.com (Yves Magliulo)
Date: 14 Oct 2005 17:33:40 +0200
Subject: [R] shell scripts in R
In-Reply-To: <200510140039.59852.kb2qzv@poczta.wp.pl>
References: <200510131714.38811.grazzi@sssup.it>
	<200510140004.52685.kb2qzv@poczta.onet.pl> <434EDBFA.5080706@pdf.com>
	<200510140039.59852.kb2qzv@poczta.wp.pl>
Message-ID: <1129304020.5142.72.camel@new-york.climpact.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051014/28a2f663/attachment.pl

From abunn at whrc.org  Fri Oct 14 17:52:39 2005
From: abunn at whrc.org (Andy Bunn)
Date: Fri, 14 Oct 2005 11:52:39 -0400
Subject: [R] Which cex to change in a trellis plot
Message-ID: <NEBBIPHDAMMOKDKPOFFIIEDBDLAA.abunn@whrc.org>

Given:


foo <- data.frame(bar = rnorm(100),
                  fac1 = factor(rep(1:2, 50)),
                  fac2 =
factor(c(rep(c("a","b","SomethingReallyReallyReallyLong"), 33),"a")))
bwplot(bar~fac1|fac2, data = foo)

How do I change the size of the text for fac2? I need to make the
"SomethingReallyReallyReallyLong" label fit in the postscript device.
Changing the cex from 1 to 0.8 (to match $axis.text$cex) will do it. Which
trellis setting is it?

Thanks, Andy



From HSun at dtcc.com  Fri Oct 14 17:55:40 2005
From: HSun at dtcc.com (Heng Sun)
Date: Fri, 14 Oct 2005 11:55:40 -0400
Subject: [R] run many linear regressions against the same independent
	variables in batch
Message-ID: <OF98CEFDD9.E459D732-ON8525709A.004E835D-8525709A.00577F97@dtcc.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051014/45dc40b3/attachment.pl

From SinghJatinder at PRAIntl.com  Fri Oct 14 17:57:08 2005
From: SinghJatinder at PRAIntl.com (Singh, Jatinder)
Date: Fri, 14 Oct 2005 08:57:08 -0700
Subject: [R] Converting PROC NLMIXED code to NLME
Message-ID: <FDD0F83B87BB0A4CA4CC8919C1502BFC045E9372@vicexchange.prant.praintl.local>

Hi Peter,

Apologies - I ran the script using S-Plus 6.2. I am happy to run it in R, but my feeling is that there may be something wrong with the code itself. I have included the dataset and script, in case you can help.

Jindi Singh. 


Jatinder Singh
Senior Manager, Analysis and Reporting
PRA International
300-730 View Street
Victoria, B.C. V8W 3Y7
Tel: 250-483-4416
Fax: 250 483 4588
http://www.prainternational.com 
e-mail: singhjatinder at praintl.com

-----Original Message-----
From: pd at pubhealth.ku.dk [mailto:pd at pubhealth.ku.dk] On Behalf Of Peter Dalgaard
Sent: Saturday, October 08, 2005 1:29 AM
To: Singh, Jatinder
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Converting PROC NLMIXED code to NLME

"Singh, Jatinder" <SinghJatinder at PRAIntl.com> writes:

> Hi,
> 
> I am trying to convert the following NLMIXED code to NLME, but am 
> running into problems concerning 'Singularity in backsolve'. As I am 
> new to R/S-Plus, I thought I may be missing something in the NLME code.

Which version of R and NLME? R 2.2.0 ships with a version where the internal optimizer is changed to nlminb(). As I understand it, this was in response to reports where code that worked in S-PLUS refused to work in R.

 
> NLMIXED
> ***********
> proc nlmixed data=kidney.kidney;
> parms delta=0.03 gamma=1.1 b1=-0.003 b2=-1.2 b3=0.09 b4=0.35 b5=-1.43 
> varu=0.5; eta=b1*age+b2*sex+b3*gn+b4*an+b5*pkn+u;
> hazard=eta+log(delta)+log(gamma)+(gamma-1)*log(rtime);
> survivor=(-exp(eta))*delta*(rtime**gamma);
> ll=(event*hazard)+survivor;
> model rtime ~ general(ll);
> random u~normal(0,varu) subject=patient out=frailty; run;
> 
> NLME
> ********
> kidney.nlme<-nlme(model=rtime~
> (event*
> ((b1*age+b2*sex+b3*gn+b4*an+b5*pkn+u)+log(delta)+log(gamma)+(gamma-1)*
> lo
> g(rtime))
> +((-exp(b1*age+b2*sex+b3*gn+b4*an+b5*pkn+u))*delta*(rtime**gamma))
> ),
> fixed=list(delta~1,gamma~1,b1~1,b2~1,b3~1,b4~1,b5~1),
> random=u~1|patient,
> start=c(delta=0.03,gamma=1.1,b1=-0.003,b2=-1.2,b3=0.09,b4=0.35,b5=-1.4
> 3)
> ,
> data=(kidney),
> method="ML",
> na.action=na.include
> )
> 
> Error in NLME
> *************
> > traceback()
> 11: eval(action, sys.parent())
> 10: doErrorAction("Problem in .C(\"fit_nlme\",: Singularity in 
> backsolve", 1000)
> 9: .C("fit_nlme",
> 8: nlme(model = rtime ~ (event * ((b1 * age + b2 * sex + b3 * gn + b4 
> * an + b5 *
> 7: NULL
> 6: nlme.formula(model = rtime ~ (event * ((b1 * age + b2 * sex + b3 * 
> gn
> + b4 *
> 5: eval(i, local)
> 4: source(auto.print = auto.print, exprs = substitute(exprs.literal))
> 3: script.run(exprs.literal = {
> 2: eval(expression(script.run(exprs.literal = {
> 1: 
> Message: Problem in .C("fit_nlme",: Singularity in backsolve
> 
> I am actually trying to fit a parametric model to the kidney catheter 
> data and compare NLMIXED with NLME. I am aware that COXPH and SURVREG 
> are also available with a frailty element added in, but wanted to fit 
> the likelihood model as above for a direct comparison.
> 
> Cheers,
> 
> Jindi
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907

From ggrothendieck at gmail.com  Fri Oct 14 18:05:24 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 14 Oct 2005 12:05:24 -0400
Subject: [R] run many linear regressions against the same independent
	variables in batch
In-Reply-To: <OF98CEFDD9.E459D732-ON8525709A.004E835D-8525709A.00577F97@dtcc.com>
References: <OF98CEFDD9.E459D732-ON8525709A.004E835D-8525709A.00577F97@dtcc.com>
Message-ID: <971536df0510140905x6ff1d45h1b5c70beaa1cc5c5@mail.gmail.com>

This runs a regression of each column (except the first)
of matrix state.x77 against the first:

lm(state.x77[,-1] ~ state.x77[,1])

On 10/14/05, Heng Sun <HSun at dtcc.com> wrote:
> R function
> lm(response ~ term)
> allows me to run a linear regression on a single response vector. For
> example, I have recent one year historical prices for a stock and S&P
> index. I can run regression of the stock prices (as response vector)
> against the S&P index prices (as term vector).
>
> Now assume I have 1000 stocks to run the above regressions (against the
> same S&P index prices). The only way I know is that I write a loop. Within
> each loop I do the regression for one stock price.
>
> Is there a batch method to run the 1000 regressions in one shot? Note that
> this functionality is available in SAS (the SAS procedure "reg").
>
> Actually, some times we run such regressions for about 300K securities.
> Performing regressions in loop takes a long time. On the contrary, running
> on SAS is much faster.
>
> Thank you in advance.
>
> Heng Sun
> 212-855-5754
>
> Director
> Quantitative Risk
> Depository Trust and Clearing Corporation
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From sara at gmesintra.com  Fri Oct 14 18:05:41 2005
From: sara at gmesintra.com (Sara Mouro)
Date: Fri, 14 Oct 2005 17:05:41 +0100
Subject: [R] arguments of lpSolve
Message-ID: <200510141605.j9EG5nrS019552@hypatia.math.ethz.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051014/b6645fbe/attachment.pl

From reid_huntsinger at merck.com  Fri Oct 14 18:05:29 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Fri, 14 Oct 2005 12:05:29 -0400
Subject: [R] run many linear regressions against the same independent
 variables in batch
Message-ID: <355C35514FEAC9458F75947F5270974D076D20@usctmx1103.merck.com>

I have always used lsfit() for this, but have been told that lm() is
preferred, and I note the help for lm() states

 If 'response' is a matrix a linear model is fitted separately by
     least-squares to each column of the matrix.

Reid Huntsinger




-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Heng Sun
Sent: Friday, October 14, 2005 11:56 AM
To: r-help at stat.math.ethz.ch
Subject: [R] run many linear regressions against the same independent
variables in batch


R function 
lm(response ~ term)
allows me to run a linear regression on a single response vector. For 
example, I have recent one year historical prices for a stock and S&P 
index. I can run regression of the stock prices (as response vector) 
against the S&P index prices (as term vector).

Now assume I have 1000 stocks to run the above regressions (against the 
same S&P index prices). The only way I know is that I write a loop. Within 
each loop I do the regression for one stock price.

Is there a batch method to run the 1000 regressions in one shot? Note that 
this functionality is available in SAS (the SAS procedure "reg").

Actually, some times we run such regressions for about 300K securities. 
Performing regressions in loop takes a long time. On the contrary, running 
on SAS is much faster.

Thank you in advance.

Heng Sun
212-855-5754

Director
Quantitative Risk
Depository Trust and Clearing Corporation

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From HStevens at MUOhio.edu  Fri Oct 14 18:37:01 2005
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Fri, 14 Oct 2005 12:37:01 -0400
Subject: [R] lattice with predicted values
Message-ID: <AD762D1D-1B22-42A4-9155-11BB5DA837F2@MUOhio.edu>

Dear lattice wizards,

I am trying to figure out how to plot predicted values in xyplot,  
where the intercept, but not the slope, varies among conditioning  
factor levels. I am sure it involves the groups, but I have been  
unsuccessful in my search in Pinhiero and Bate, in the help files, or  
in the archive, or in my attempts on my own.

My example follows:

FACT is a factor with levels a,b,c
COV is the covariate

mod ~ lm(Y ~ COV + FACT)


#The following draws the right predictions if the relation is the  
same for all factor levels, but I can't figure out how to have the  
same slopes but different intercepts.

# Function to draw predictions in xyplot

panel.predfinal <- function(mod, x, y) {
     xfit <- seq(min(x), max(x), length=21)
     yfit <- predict(mod, newdata=data.frame(COV=xfit))
     llines(xfit,yfit,lty=1) }

xyplot(Y ~ COV | FACT,
             panel=function(x,y,groups,subscripts){
             panel.xyplot(x,y)
             panel.predfinal(mod,x,y) }

I would be very grateful for pointers (books, chapters, pages,  
archives) that might have an example of an xyplot in which something  
(like the slope) is constant, and something else (like the  
intercepts) varies by factor level.
Cheers,
Hank

Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"



From HSun at dtcc.com  Fri Oct 14 18:51:03 2005
From: HSun at dtcc.com (Heng Sun)
Date: Fri, 14 Oct 2005 12:51:03 -0400
Subject: [R] run many linear regressions against the same independent
 variables in batch
In-Reply-To: <971536df0510140905x6ff1d45h1b5c70beaa1cc5c5@mail.gmail.com>
Message-ID: <OFB423377D.8181555F-ON8525709A.005C5D96-8525709A.005C9197@dtcc.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051014/b2bb806e/attachment.pl

From pbaer at berkeley.edu  Fri Oct 14 18:55:31 2005
From: pbaer at berkeley.edu (Paul Baer)
Date: Fri, 14 Oct 2005 10:55:31 -0600
Subject: [R] Setting working directory interactively within a function
Message-ID: <p06230902bf7593197e20@[192.168.1.102]>

Is there anyway to have a function prompt the user for a working 
directory, equivalent to file.choose()?

--Paul



From admin at biostatistic.de  Fri Oct 14 19:07:19 2005
From: admin at biostatistic.de (Knut Krueger)
Date: Fri, 14 Oct 2005 19:07:19 +0200
Subject: [R] high resolution images for publication
In-Reply-To: <005d01c5d03b$e0cfa680$4c01a8c0@Chris>
References: <005d01c5d03b$e0cfa680$4c01a8c0@Chris>
Message-ID: <434FE5C7.7060102@biostatistic.de>



Chris Buddenhagen schrieb:

>Dear all
>
> 
>
>I am using R to produce ordinations library(vegan) and the plot function
>produced looks great on the screen but when I send it to jpg or pdf or eps
>the resolution is not so good. Can you tell me how to get high resolution
>images out of R for publication?
>

I tried to fix that problem weeks ago.
The journal wants Tiff files in high resolution or EPS files - no PS files.
The best solution was to use the postscript files from the R graphic
device (right mouse save as postscript)
After this I converted the files with Ghostscript and GSViev in a
suitable file format.
and after the submission was ready I tried to submit the postscript file
... It worked better than all the other.

Maybe you should also try to use the PS-files.In our case we were ale to
look to a PDF file after sending the file whether the submission is ok
or not.
And if it was ok the submission was sent to the journal.

Therefore I tried all graphic formats before the regular submission.

Regards Knut

with regards
Knut Krueger
http://www.biostatistic.de



From gunter.berton at gene.com  Fri Oct 14 19:08:31 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Fri, 14 Oct 2005 10:08:31 -0700
Subject: [R] Setting working directory interactively within a function
In-Reply-To: <p06230902bf7593197e20@[192.168.1.102]>
Message-ID: <200510141708.j9EH8V5Y001712@volta.gene.com>

?setwd
e.g. setwd(file.choose())

BTW, you could have found this on your own via help.search('working
directory') . Base R has quite good docs -- you should try them first.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Paul Baer
> Sent: Friday, October 14, 2005 9:56 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Setting working directory interactively within a function
> 
> Is there anyway to have a function prompt the user for a working 
> directory, equivalent to file.choose()?
> 
> --Paul
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From murdoch at stats.uwo.ca  Fri Oct 14 19:16:01 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 14 Oct 2005 13:16:01 -0400
Subject: [R] Setting working directory interactively within a function
In-Reply-To: <p06230902bf7593197e20@[192.168.1.102]>
References: <p06230902bf7593197e20@[192.168.1.102]>
Message-ID: <434FE7D1.3040507@stats.uwo.ca>

On 10/14/2005 12:55 PM, Paul Baer wrote:
> Is there anyway to have a function prompt the user for a working 
> directory, equivalent to file.choose()?

It's relatively easy to get a text prompt, but I don't think we've got a 
function that's equivalent to the Windows menu item "File|Change 
dir...".  We probably should.

Duncan Murdoch



From greg.snow at ihc.com  Fri Oct 14 19:17:13 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Fri, 14 Oct 2005 11:17:13 -0600
Subject: [R] shell scripts in R
Message-ID: <s34f93e5.020@lp-msg1.co.ihc.com>

>>>> Marc Schwartz <MSchwartz at mn.rr.com> 10/13/05 06:07PM >>>
>On Fri, 2005-10-14 at 00:39 +0200, Benedict P. Barszcz wrote:
>> Dnia piatek, 14 pazdziernika 2005 00:13, Sundar Dorai-Raj napisal:
>> 
>> > Don't you mean system("ls")? See ?system.
>> >
>> > Arguments:
>> >
>> > command: the system command to be invoked, as a string.
>> 
>> This is the kind of obstacles a newbie has to overcome. Whoeve is
writing the 
>> documentation for R, please do not attempt to save on bytes. Life
would be so 
>> much more pleasureable.... if only it would say "as a quoted
string". Jee.
>
>The phrase "quoted string" in my mind is redundant.

It is also inaccurate, after all you could do the following:

> tmp <- paste(letters[ c(12,19)], collapse='')
> system(tmp,show=T)

here tmp is a string and works, but quoting it would break 
things.


Greg Snow, Ph.D.
Statistical Data Center, LDS Hospital
Intermountain Health Care
greg.snow at ihc.com
(801) 408-8111



From murdoch at stats.uwo.ca  Fri Oct 14 19:24:13 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 14 Oct 2005 13:24:13 -0400
Subject: [R] Setting working directory interactively within a function
In-Reply-To: <200510141708.j9EH8V5Y001712@volta.gene.com>
References: <200510141708.j9EH8V5Y001712@volta.gene.com>
Message-ID: <434FE9BD.3020709@stats.uwo.ca>

On 10/14/2005 1:08 PM, Berton Gunter wrote:
> ?setwd
> e.g. setwd(file.choose())
> 
> BTW, you could have found this on your own via help.search('working
> directory') . Base R has quite good docs -- you should try them first.
> 
> -- Bert Gunter

That won't work in Windows, where the dialogs don't consider directories 
to be files so won't return them.

As far as I know no platform lets you setwd() to a file (even though 
this might make sense:  setwd("foo") could mean change to foo if it's a 
directory, to the directory it's in if it's a file).

Duncan Murdoch



From anthony.staines at gmail.com  Fri Oct 14 19:43:35 2005
From: anthony.staines at gmail.com (Anthony Staines)
Date: Fri, 14 Oct 2005 18:43:35 +0100
Subject: [R] Predicting classification error from rpart
Message-ID: <6d3975af0510141043s37ed2a90o@mail.gmail.com>

Hi,

I think I'm missing something very obvious, but I am missing it, so I
would be very grateful for help. I'm using rpart to analyse data on
skull base morphology, essentially predicting sex from one or several
skull base measurements. The sex of the people whose skulls are being
studied is known, and lives as a factor (M,F) in the data. I want to
get back predictions of gender, and particularly misclassification
rates.

rpart produces output like this :-

> printcp(rpart.LFM)
Classification tree:                                      
rpart(formula = Sex ~ LFM, data = Brides2)
Variables actually used in tree construction:  LFM
Root node error: 44/104 = 0.42308                n= 104

        CP nsplit rel error  xerror    xstd
1 0.227273      0   1.00000 1.00000 0.11451
2 0.113636      1   0.77273 0.95455 0.11372
3 0.022727      2   0.65909 0.95455 0.11372
4 0.010000      5   0.59091 0.95455 0.11372
>

Presumably 'root node error' and 'rel error' are something to do with
error but what? 'Root node error ' seems to be some sort of deviance,
and I have no idea what 'rel error' is. the tree library does produce
a simple estimate of misclassification, but rpart doesn't seem to.

Any ideas?

Thanks,
Anthony Staines
--
Dr. Anthony Staines, Senior Lecturer in Epidemiology.
School  of Public Health and Population Sciences, UCD, Earlsfort
Terrace, Dublin 2, Ireland.
Tel:- +353 1 716 7345. Fax:- +353 1 716 7407 Mobile:- +353 86 606 9713
Web:- http://phm.ucd.ie



From abunn at whrc.org  Fri Oct 14 19:53:23 2005
From: abunn at whrc.org (Andy Bunn)
Date: Fri, 14 Oct 2005 13:53:23 -0400
Subject: [R] Predicting classification error from rpart
In-Reply-To: <6d3975af0510141043s37ed2a90o@mail.gmail.com>
Message-ID: <NEBBIPHDAMMOKDKPOFFICEDGDLAA.abunn@whrc.org>

Anthony. Look at ?predict.rpart, I think this might be the kind of table you
are looking for.

     data(iris)
     sub <- c(sample(1:50, 25), sample(51:100, 25), sample(101:150, 25))
     fit <- rpart(Species ~ ., data=iris, subset=sub)
     fit
     table(predict(fit, iris[-sub,], type="class"), iris[-sub, "Species"])

HTH, Andy

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Anthony Staines
> Sent: Friday, October 14, 2005 1:44 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Predicting classification error from rpart
>
>
> Hi,
>
> I think I'm missing something very obvious, but I am missing it, so I
> would be very grateful for help. I'm using rpart to analyse data on
> skull base morphology, essentially predicting sex from one or several
> skull base measurements. The sex of the people whose skulls are being
> studied is known, and lives as a factor (M,F) in the data. I want to
> get back predictions of gender, and particularly misclassification
> rates.
>
> rpart produces output like this :-
>
> > printcp(rpart.LFM)
> Classification tree:
> rpart(formula = Sex ~ LFM, data = Brides2)
> Variables actually used in tree construction:  LFM
> Root node error: 44/104 = 0.42308                n= 104
>
>         CP nsplit rel error  xerror    xstd
> 1 0.227273      0   1.00000 1.00000 0.11451
> 2 0.113636      1   0.77273 0.95455 0.11372
> 3 0.022727      2   0.65909 0.95455 0.11372
> 4 0.010000      5   0.59091 0.95455 0.11372
> >
>
> Presumably 'root node error' and 'rel error' are something to do with
> error but what? 'Root node error ' seems to be some sort of deviance,
> and I have no idea what 'rel error' is. the tree library does produce
> a simple estimate of misclassification, but rpart doesn't seem to.
>
> Any ideas?
>
> Thanks,
> Anthony Staines
> --
> Dr. Anthony Staines, Senior Lecturer in Epidemiology.
> School  of Public Health and Population Sciences, UCD, Earlsfort
> Terrace, Dublin 2, Ireland.
> Tel:- +353 1 716 7345. Fax:- +353 1 716 7407 Mobile:- +353 86 606 9713
> Web:- http://phm.ucd.ie
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From arnab at myrealbox.com  Fri Oct 14 19:56:51 2005
From: arnab at myrealbox.com (Arnab mukherji)
Date: Fri, 14 Oct 2005 17:56:51 +0000
Subject: [R] Sweave +RWinEdt
Message-ID: <1129312611.c7f5effcarnab@myrealbox.com>

Hi!

I was just reading Uwe Ligges write up on extending R-WinEdt for Sweave from 2003; I was wondering if there were updates on it? Are people seriously thiking about it? 

I really use WinEdt a lot, and for not just R, and hence this kind of extension would be really cool for a whole range people.

Just thought I put in a word for it in case this project is dormat, or people are thinking about if its something worth doing or not.

Arnab



From gunter.berton at gene.com  Fri Oct 14 19:59:57 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Fri, 14 Oct 2005 10:59:57 -0700
Subject: [R] Setting working directory interactively within a function
In-Reply-To: <p06230905bf759f6d61bf@[192.168.1.102]>
Message-ID: <200510141800.j9EHxvXn013336@hertz.gene.com>

Oops. Thanks, all. Egg on my face. I forgot about that little detail (on
Windows, anyway).

However, you can still do it via dirname(file.choose()) to get the
directory, on Windows,anyway, right? If that isn't implemented on another
platform, than you could mimic the dirname() code by using gsub() to trim
off the last file part of the path to get your directory.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: Paul Baer [mailto:pbaer at berkeley.edu] 
> Sent: Friday, October 14, 2005 10:48 AM
> To: Berton Gunter
> Subject: RE: [R] Setting working directory interactively 
> within a function
> 
> Hi Berton -I did check the docs first and tried this soloution, but 
> unfortunately on a Mac this doesn't work - you get a file choice 
> dialogue box, but it doesn't allow you to open (select) a directory, 
> only to choose a file. I suppose I should have noted this in my email.
> 
> Thanks,
> 
> --Paul
> 
> >?setwd
> >e.g. setwd(file.choose())
> >
> >BTW, you could have found this on your own via help.search('working
> >directory') . Base R has quite good docs -- you should try 
> them first.
> >
> >-- Bert Gunter
> >Genentech Non-Clinical Statistics
> >South San Francisco, CA
> >
> >"The business of the statistician is to catalyze the 
> scientific learning
> >process."  - George E. P. Box
> >
> >
> >
> >>  -----Original Message-----
> >>  From: r-help-bounces at stat.math.ethz.ch
> >>  [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Paul Baer
> >>  Sent: Friday, October 14, 2005 9:56 AM
> >>  To: r-help at stat.math.ethz.ch
> >>  Subject: [R] Setting working directory interactively 
> within a function
> >>
> >>  Is there anyway to have a function prompt the user for a working
> >>  directory, equivalent to file.choose()?
> >>
> >>  --Paul
> >>
> >>  ______________________________________________
> >>  R-help at stat.math.ethz.ch mailing list
> >>  https://stat.ethz.ch/mailman/listinfo/r-help
> >>  PLEASE do read the posting guide!
> >>  http://www.R-project.org/posting-guide.html
> >>
> 
>



From ggrothendieck at gmail.com  Fri Oct 14 20:02:29 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 14 Oct 2005 14:02:29 -0400
Subject: [R] Setting working directory interactively within a function
In-Reply-To: <p06230902bf7593197e20@192.168.1.102>
References: <p06230902bf7593197e20@192.168.1.102>
Message-ID: <971536df0510141102w1c3b2fbep9c8f900493f17f7f@mail.gmail.com>

library(tcltk)
setwd(tclvalue(tkchooseDirectory()))

On 10/14/05, Paul Baer <pbaer at berkeley.edu> wrote:
> Is there anyway to have a function prompt the user for a working
> directory, equivalent to file.choose()?



From ligges at statistik.uni-dortmund.de  Fri Oct 14 20:12:00 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 14 Oct 2005 20:12:00 +0200
Subject: [R] Sweave +RWinEdt
In-Reply-To: <1129312611.c7f5effcarnab@myrealbox.com>
References: <1129312611.c7f5effcarnab@myrealbox.com>
Message-ID: <434FF4F0.6030801@statistik.uni-dortmund.de>

Arnab mukherji wrote:

> Hi!
> 
> I was just reading Uwe Ligges write up on extending R-WinEdt for Sweave from 2003; I was wondering if there were updates on it? Are people seriously thiking about it? 
> 
> I really use WinEdt a lot, and for not just R, and hence this kind of extension would be really cool for a whole range people.
> 
> Just thought I put in a word for it in case this project is dormat, or people are thinking about if its something worth doing or not.
> 
> Arnab
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


Hmm, this project is still on my ToDo list, and I have received at elast 
one contribution that is a promising first idea but needs some adaptions.
Unfortunately, it is of such a low priority that I don't think I will do 
anything within the next 6 months on this project, but as always: 
further contributions are welcome, of course.

Uwe Ligges



From michel.friesenhahn.b at bayer.com  Fri Oct 14 21:31:05 2005
From: michel.friesenhahn.b at bayer.com (Michel Friesenhahn)
Date: Fri, 14 Oct 2005 12:31:05 -0700
Subject: [R] Fw: Setting working directory interactively within a function
Message-ID: <OF357F6F67.1AA338AE-ON8825709A.006AE006-8825709A.006B3718@bayer.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051014/7a044b90/attachment.pl

From webuser at globe.gov  Fri Oct 14 21:57:55 2005
From: webuser at globe.gov (Web User)
Date: Fri, 14 Oct 2005 13:57:55 -0600
Subject: [R] Beginner plot and map questions
Message-ID: <43500DC3.40106@globe.gov>

Hi,

I have not been able to find answers to these questions in the FAQs, 
manuals, or R-help archives.  If answers are available somewhere, please 
direct me to them.

1.) Is there a way to convert a table (e.g. represented as a data frame) 
to a function, specifying which columns are input and which column is 
output?  It would seem that this would be useful for plotting 
experimental results, since e.g. contour(x, y, f) requires f to be a 
function.

2.) If x is longitude and y is latitude, then I would think that 
contour(x, y, f) could be used to create a contour map with equally 
spaced latitude and longitude.  And I've seen that the "maps" and 
"mapproj" packages can be used to create maps in different projections.
a.) Once a base map is created and experimental data is projected to fit 
the base map, how is it added onto the map?
b.) Is there a way to combine the contouring and projection 
functionality to get contour maps in any of the supported projections?

3.) What algorithm is used by the contour() function?  Are there any 
parameters that can be changed, such as radius of interest for a data 
point to affect a grid point?

Thanks for any help or references.



From deepayan.sarkar at gmail.com  Fri Oct 14 23:16:19 2005
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 14 Oct 2005 16:16:19 -0500
Subject: [R] Which cex to change in a trellis plot
In-Reply-To: <NEBBIPHDAMMOKDKPOFFIIEDBDLAA.abunn@whrc.org>
References: <NEBBIPHDAMMOKDKPOFFIIEDBDLAA.abunn@whrc.org>
Message-ID: <eb555e660510141416y1f4e7775s1abd82e5a923dbbf@mail.gmail.com>

On 10/14/05, Andy Bunn <abunn at whrc.org> wrote:
> Given:
>
>
> foo <- data.frame(bar = rnorm(100),
>                   fac1 = factor(rep(1:2, 50)),
>                   fac2 =
> factor(c(rep(c("a","b","SomethingReallyReallyReallyLong"), 33),"a")))
> bwplot(bar~fac1|fac2, data = foo)
>
> How do I change the size of the text for fac2? I need to make the
> "SomethingReallyReallyReallyLong" label fit in the postscript device.
> Changing the cex from 1 to 0.8 (to match $axis.text$cex) will do it. Which
> trellis setting is it?

bwplot(bar~fac1|fac2, data = foo, par.strip.text = list(cex = .8))

Defaults are taken from trellis.par.get("add.text").

Deepayan



From deepayan.sarkar at gmail.com  Fri Oct 14 23:24:22 2005
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 14 Oct 2005 16:24:22 -0500
Subject: [R] lattice with predicted values
In-Reply-To: <AD762D1D-1B22-42A4-9155-11BB5DA837F2@MUOhio.edu>
References: <AD762D1D-1B22-42A4-9155-11BB5DA837F2@MUOhio.edu>
Message-ID: <eb555e660510141424y5a6cec5cq42fe3031911700ed@mail.gmail.com>

On 10/14/05, Martin Henry H. Stevens <HStevens at muohio.edu> wrote:
> Dear lattice wizards,
>
> I am trying to figure out how to plot predicted values in xyplot,
> where the intercept, but not the slope, varies among conditioning
> factor levels. I am sure it involves the groups, but I have been
> unsuccessful in my search in Pinhiero and Bate, in the help files, or
> in the archive, or in my attempts on my own.
>
> My example follows:
>
> FACT is a factor with levels a,b,c
> COV is the covariate
>
> mod ~ lm(Y ~ COV + FACT)
>
>
> #The following draws the right predictions if the relation is the
> same for all factor levels, but I can't figure out how to have the
> same slopes but different intercepts.
>
> # Function to draw predictions in xyplot
>
> panel.predfinal <- function(mod, x, y) {
>      xfit <- seq(min(x), max(x), length=21)
>      yfit <- predict(mod, newdata=data.frame(COV=xfit))
>      llines(xfit,yfit,lty=1) }
>
> xyplot(Y ~ COV | FACT,
>              panel=function(x,y,groups,subscripts){
>              panel.xyplot(x,y)
>              panel.predfinal(mod,x,y) }

A not very satisfactory (but probably good enough for linear fits) is

pred <- predict(mod)

xyplot(Y ~ COV | FACT, pred = pred,
       panel = function(x, y, pred, subscripts, ...) {
           panel.xyplot(x,y,...)
           llines(x, pred[subscripts], ...)
       })

Deepayan



From rmedel at fcab.cl  Sat Oct 15 01:14:05 2005
From: rmedel at fcab.cl (Rodrigo Medel)
Date: Fri, 14 Oct 2005 19:14:05 -0400
Subject: [R] Question about Boxplots
Message-ID: <005901c5d114$f8f257b0$42050059@fcab.cl>

Hello,
I'm a new R user and I like to ask somethig about boxplots.
Is it possible to manipulate the Y axis scale? for instance if the default 
scale was from 1 to 7, is it possible to change it to 1 to 10?
Thanks!


Rodrigo Medel P.



From dhiren22 at hotmail.com  Sat Oct 15 00:33:53 2005
From: dhiren22 at hotmail.com (Dhiren DSouza)
Date: Fri, 14 Oct 2005 18:33:53 -0400
Subject: [R]  subset selection for glm
Message-ID: <BAY102-F20330A648E387A724FD675D37D0@phx.gbl>

Hello:

Are there any libraries that will do a subset selection for glm's?  I looked 
through leaps, but seems like it is specifically for linear regressions.  
Thank you.

-Dhiren



From gunter.berton at gene.com  Sat Oct 15 00:37:45 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Fri, 14 Oct 2005 15:37:45 -0700
Subject: [R] Question about Boxplots
In-Reply-To: <005901c5d114$f8f257b0$42050059@fcab.cl>
Message-ID: <200510142237.j9EMbjT6007699@hertz.gene.com>

?par
?plot.default

In particular you want to set the ylim parameter. However, note that the
axis drawing procedures try to choose "pretty" axis labels. These can be
changed by using low level tools -- see ?axis.

Please also read "An Introduction to R" and other relevant docs before
posting. Base R is very well documented and you will find answers for many
questions readily available in its man pages. Also check the CRAN website
for other reference material and books that you may find useful in learning
R.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Rodrigo Medel
> Sent: Friday, October 14, 2005 4:14 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Question about Boxplots
> 
> Hello,
> I'm a new R user and I like to ask somethig about boxplots.
> Is it possible to manipulate the Y axis scale? for instance 
> if the default 
> scale was from 1 to 7, is it possible to change it to 1 to 10?
> Thanks!
> 
> 
> Rodrigo Medel P.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From joseclaudio.faria at terra.com.br  Sat Oct 15 01:34:13 2005
From: joseclaudio.faria at terra.com.br (Jose Claudio Faria)
Date: Fri, 14 Oct 2005 20:34:13 -0300
Subject: [R] Help with lattice, regressions and respective lines
Message-ID: <43504075.1070308@terra.com.br>

# Dear R list,
#
# I'm needing help with lattice, regression and respective lines.
# My data is below:

bra  = gl(2, 24, label = c('c', 's'))
em   = rep(gl(3, 8,  label = c('po', 'pov', 'ce')), 2)
tem  = rep(c(0, 0, 30, 30, 60, 60, 90, 90), 6)
tem2 = tem^2
r    = rep(1:2, 24)
y    = c(40.58, 44.85, 32.55, 35.68, 64.86, 51.95, 42.52, 52.21,
          40.58, 44.85, 33.46, 46.09, 12.75, 18.01, 16.82, 13.69,
          40.58, 44.85, 34.45, 29.89, 34.91, 28.10, 27.52, 22.24,
          48.68, 47.25, 45.58, 45.33, 41.03, 51.20, 45.85, 54.45,
          48.68, 47.25, 19.88, 19.67, 16.20, 13.49, 13.75, 18.80,
          48.68, 47.25, 42.19, 39.91, 34.69, 34.11, 32.74, 34.24)

Df = data.frame(bra, em, tem, tem2, r, y)

# Regressions
attach(Df)
   Dfs1=subset(Df, (bra=='s' & em=='pov'), select=c(bra, em, tem, tem2, r, y))
   Dfs1
   rlin1=lm(y ~ tem + tem2, data=Dfs1)
   summary(rlin1)

   Dfs2=subset(Df, (bra=='s' & em=='po'), select=c(bra, em, tem, r, y))
   Dfs2
   rlin2=lm(y ~ tem, data=Dfs2)
   summary(rlin2)

   Dfs3=subset(Df, (bra=='s' & em=='ce'), select=c(bra, em, tem, tem2, r, y))
   Dfs3
   rlin3=lm(y ~ tem + tem2, data=Dfs3)
   summary(rlin3)
detach(Df)

# I would like to plot with lattice 'y ~ tem | em',
# with the panels ('po', 'pov' and 'ce'),
# and the its respective regressions lines:
# a) linear for panel 'po' or better, without line;
# b) quadratic for 'pov' and 'ce'

# Is it possible? Could somebody hel me?

# I'm trying:
library(lattice)
attach(Df)
   Dfs=subset(Df, bra=='s', select=c(bra, em, tem, y))
   Dfs
   xyplot(y ~ tem | em,
          data = Dfs, ylim=c(10, 60), xlim=c(-10, 110),
          ylab='y', xlab='Time, days',
          layout = c(3,1))
detach(Df)

TIA,
-- 
Jose Claudio Faria
Brasil/Bahia/UESC/DCET
Estatistica Experimental/Prof. Adjunto
mails:
  joseclaudio.faria at terra.com.br
  jc_faria at uesc.br
  jc_faria at uol.com.br
tel: 73-3634.2779



From A.Robinson at ms.unimelb.edu.au  Sat Oct 15 03:15:10 2005
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sat, 15 Oct 2005 11:15:10 +1000
Subject: [R] Do Users of Nonlinear Mixed Effects Models Know Whether
	Their Software Really Works?
In-Reply-To: <5BCBA62ECB426A47AE66567CDF930F9829196A@HUGIN.uib.no>
References: <5BCBA62ECB426A47AE66567CDF930F9829196A@HUGIN.uib.no>
Message-ID: <20051015011510.GZ52360@ms.unimelb.edu.au>

Dear Hans,

these are interesting points.  I guess that I'm approaching it from
the point of view of a decision: I'd be more comfortable using a
fitting routine that has stability under a wide range of identifiable
circumstances. Obtaining the MLE exactly in any instance is a function
of the data and the model.  So, to me, obtaining it well in one
instance is less interesting than obtaining it well in a wide array of
instances. 

In short, I guess that I'm connecting the numerical routines with the
actual data, in the sense that that's what they operate on, and
therefore the statistical properties of the overall approach.  Perhaps
I'm being naive!

Cheers,

Andrew

On Fri, Oct 14, 2005 at 02:55:59PM +0200, Hans Julius Skaug wrote:
> 
> Dear Andrew and R-list,
> 
> I guess Fournier is addressing the properties of the numerical routines
> underlying the various packages, not the statistical properties of the MLE itself.
> For this purpose using a small tricky dataset makes sense. Clearly,
> a true unique MLE exists (except in pathological cases), defined
> as the maximizer of the marginal likelihood, evaluated using perfect precision numerical integration.
> Since all the packages are aiming at calculating the MLE, it makes sense to compare them 
> on this ground. I think the point in Lesaffre et al is that the default settings of many packages may 
> give you something very different from the true MLE.
> 
> 
> best regards,
> 
> hans
> 
> 
> > 1) If I understand correctly, you're trying to estimate parameters
> >    from a real dataset.  Why not try a simulated dataset, where you
> >    know exactly what the true values (and parameter distributions)
> >    are?
> > 
> > 2) Furthermore, an argument from one dataset isn't very
> >    convincing. The sample size for inference is too small.  Why not
> >    repeat this procedure many times, sampling from the same base
> >    model? 
> > 
> > 3) Then, you could also vary the structure of the underlying model
> >    systematically, and assess the comparison of fits as a function of
> >    the underlying model/dataset nexus.
> > 
> > 4) Next, a problem with the example (as I understand it) is that
> >    although you've computed what you call exact MLE's, I think that
> >    they're exact when conditioned on the model.  Are they very robust
> >    to model misspecification?  (I mean beyond large-sample theory).
> > 
> > 5) Finally, of course, then making the scripts available for forsenic
> >    investigations.
> > 
> > Cheers,
> > 
> > Andrew
> 
> _____________________________
> Hans Julius Skaug
> 
> Department of Mathematics
> University of Bergen
> Johannes Brunsgate 12
> 5008 Bergen
> Norway
> ph. (+47) 55 58 48 61
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Andrew Robinson
Senior Lecturer in Statistics                       Tel: +61-3-8344-9763
Department of Mathematics and Statistics            Fax: +61-3-8344-4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au



From junxu06 at gmail.com  Sat Oct 15 04:48:06 2005
From: junxu06 at gmail.com (jun xu)
Date: Fri, 14 Oct 2005 21:48:06 -0500
Subject: [R] batch file execution
Message-ID: <8ee3db370510141948o3bb91048h282bbc36b23336c5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051014/435ce1e2/attachment.pl

From vincent at 7d4.com  Sat Oct 15 05:08:54 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Sat, 15 Oct 2005 05:08:54 +0200
Subject: [R] Beginner plot and map questions
In-Reply-To: <43500DC3.40106@globe.gov>
References: <43500DC3.40106@globe.gov>
Message-ID: <435072C6.6050102@7d4.com>

Web User a ??crit :

> 1.) Is there a way to convert a table (e.g. represented as a data frame) 
> to a function, specifying which columns are input and which column is 
> output?  It would seem that this would be useful for plotting 
> experimental results, since e.g. contour(x, y, f) requires f to be a 
> function.

I think on something rather ugly.
Hopefully somebody will propose a more elegant solution.

1/ store your data in a global array myexpresults[,]
2/ define f(x,y) as
f function(x,y) {return(myexpresults[x,y]);};

x,y are integers and f is discrete in the above case.
But if you want to allow x,y continuous,
you can also interpolate in f() with the grid results
the nearest from (x,y).

You can also do it without a global, by reading your table directly
in f(), but this will demand to reread the table each time f is called
which may be rather impracticable.



From sourceforge at metrak.com  Sat Oct 15 06:24:56 2005
From: sourceforge at metrak.com (sosman)
Date: Sat, 15 Oct 2005 14:24:56 +1000
Subject: [R] batch file execution
In-Reply-To: <8ee3db370510141948o3bb91048h282bbc36b23336c5@mail.gmail.com>
References: <8ee3db370510141948o3bb91048h282bbc36b23336c5@mail.gmail.com>
Message-ID: <43508498.6040202@metrak.com>

jun xu wrote:
> I am new to R and really like to get a handle of basics in short period of
> time. What I am trying to do is get myself a list of must-do's (read in
> data, batch execution, delimiters, basic modeling commands) in R as in Stata
> or SAS. I am just wondering how to execute a R batch file in RGui. Suppose I
> have a script file (like do file in stata, or sas file in SAS) under
> c:\whatever.R, how can I execute it using commands (not drop down menu) in
> RGui? In stata, would be something like

If I am not mistaken the command is:
 > source("whatever.R")

>  do c:\whatever.do
>  How about in R. I tried the "R CMD BATCH('h:/whatever.R'), but it didn't
> work. Any help would be greatly appreciated.

paul sorenson



From ligges at statistik.uni-dortmund.de  Sat Oct 15 10:58:33 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 15 Oct 2005 10:58:33 +0200
Subject: [R] batch file execution
In-Reply-To: <43508498.6040202@metrak.com>
References: <8ee3db370510141948o3bb91048h282bbc36b23336c5@mail.gmail.com>
	<43508498.6040202@metrak.com>
Message-ID: <4350C4B9.4000809@statistik.uni-dortmund.de>

sosman wrote:
> jun xu wrote:
> 
>>I am new to R and really like to get a handle of basics in short period of
>>time. What I am trying to do is get myself a list of must-do's (read in
>>data, batch execution, delimiters, basic modeling commands) in R as in Stata
>>or SAS. I am just wondering how to execute a R batch file in RGui. Suppose I
>>have a script file (like do file in stata, or sas file in SAS) under
>>c:\whatever.R, how can I execute it using commands (not drop down menu) in
>>RGui? In stata, would be something like
> 
> 
> If I am not mistaken the command is:
>  > source("whatever.R")

... or source("c:/whatever.R") if "c:\" is not your current working 
directory.

> 
>> do c:\whatever.do
>> How about in R. I tried the "R CMD BATCH('h:/whatever.R'), but it didn't
>>work. Any help would be greatly appreciated.


R CMD BATCH has to be executed from the Windows shell (looks like you 
are running this OS) rather than from within R with the Syntax (if 
called from c:\ and R is in your PATH):
R CMD BATCH whatever.R

Uwe Ligges



> 
> paul sorenson
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Roger.Bivand at nhh.no  Sat Oct 15 11:38:45 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 15 Oct 2005 11:38:45 +0200 (CEST)
Subject: [R] Beginner plot and map questions
In-Reply-To: <43500DC3.40106@globe.gov>
Message-ID: <Pine.LNX.4.44.0510151038490.1108-100000@reclus.nhh.no>

(OFF TOPIC) Although not mentioned in our exellent posting guide:

http://www.r-project.org/posting-guide.html

or Eric Raymond's excellent advice refered to in the posting guide:

http://www.catb.org/~esr/faqs/smart-questions.html

I personally often find it difficult to formulate a sensible reply to 
questions posted without a real user name and affiliation. I can 
appreciate that people posting to the list come from different generations 
and "cultures", and may not feel comfortable in saying who they are on the 
list.

I would, though, appeal to posters to give those who try to reply to 
questions at least a little help, by including an informative signature 
block. 

For want of a better name:

Dear Web User,

On Fri, 14 Oct 2005, Web User wrote:

> Hi,
> 
> I have not been able to find answers to these questions in the FAQs, 
> manuals, or R-help archives.  If answers are available somewhere, please 
> direct me to them.
> 
> 1.) Is there a way to convert a table (e.g. represented as a data frame) 
> to a function, specifying which columns are input and which column is 
> output?  It would seem that this would be useful for plotting 
> experimental results, since e.g. contour(x, y, f) requires f to be a 
> function.

You are not refering to the contour() method in the graphics package, 
which does not take an f= argument. Its third argument is z, which is a 
matrix of surface values on a grid. If your x and y vectors represent 
something other than required by the default contour() method, you must 
interpolate to such a grid first, for example using the interp() function 
in the akima package, or in some other way. As far as I am aware, R and 
contributed packages cannot compute contours directly from irregularly 
spaced (x,y,z) values. If your question relates to a contributed package, 
please say so.

> 
> 2.) If x is longitude and y is latitude, then I would think that 
> contour(x, y, f) could be used to create a contour map with equally 
> spaced latitude and longitude.  And I've seen that the "maps" and 
> "mapproj" packages can be used to create maps in different projections.
> a.) Once a base map is created and experimental data is projected to fit 
> the base map, how is it added onto the map?

It depends what kind of data, but note that the map() function in the maps 
package plots in coordinates transformed to the plotting device when 
projection is used. Without projection, map() plots and returns long/lat 
coordinates, but note that the y axis is stretched in relation to the x 
axis depending on the mean latitude of the map.

> b.) Is there a way to combine the contouring and projection 
> functionality to get contour maps in any of the supported projections?
> 

Using the contourLines() function, you can extract the lines in the 
coordinates given by the x and y grid sequences. You can also in principle 
project them too, and will be able to co-register them on the plot made by 
map(). 

If you are not bound to use the maps package for plotting and projection,
I would suggest that you look at the sp package on CRAN, and the spproj
and spmaps packages on http://r-spatial.sourceforge.net/R as a possible
alternatives. Then you can access coastline data from maps, convert
contourLines() output to a SpatialLinesDataFrame with the sp function
contourLines2SLDF(), and project both using the transform() methods in
spproj (after setting the correct projection strings for the spatial
objects).

> 3.) What algorithm is used by the contour() function?  Are there any 
> parameters that can be changed, such as radius of interest for a data 
> point to affect a grid point?

Please see ?contour: Becker, R. A., Chambers, J. M. and Wilks, A. R. 
(1988) _The New S Language_. Wadsworth & Brooks/Cole; but see also:

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/12366.html

in which Ross Ihaka writes:

"The handling of the "crossing case" in R is an implementation of that in
Cleveland's "Visualizing Data" (one of the "for-the-record" sections).
I don't think the algorithm permits crossings."

which seems authoritative, of course, the code is the complete 
documentation.

> 
> Thanks for any help or references.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From 042045003 at fudan.edu.cn  Sat Oct 15 12:20:25 2005
From: 042045003 at fudan.edu.cn (ronggui)
Date: Sat, 15 Oct 2005 18:20:25 +0800
Subject: [R] batch file execution
Message-ID: <0IOE00MFBC8EKH@mail.fudan.edu.cn>

if we have set the path of R to the   Environment Variables,things will be much convenient.

from  Start -> Settings -> Control Panel -> System -> Advanced -> Environment Variables

Now we are the Environment Variables window, we will only need to pay attention to the lower window for  System variables. Click on the Path Variable and then click on Edit... Add ;"path\of\R" to the path.(for me,the path of R is E:\Program Files\R\R-2.2.0\bin),note that each path is seperate by ";" and the path itself is not quoted by "".

then
1,run cmd (start--run and type cmd then hit enter);
2,in the Windows shell,type  R CMD BATCH infile [outfile]
	

======= 2005-10-15 16:58:33 ÄúÔÚÀ´ÐÅÖÐÐ´µÀ£º=======

>sosman wrote:
>> jun xu wrote:
>> 
>>>I am new to R and really like to get a handle of basics in short period of
>>>time. What I am trying to do is get myself a list of must-do's (read in
>>>data, batch execution, delimiters, basic modeling commands) in R as in Stata
>>>or SAS. I am just wondering how to execute a R batch file in RGui. Suppose I
>>>have a script file (like do file in stata, or sas file in SAS) under
>>>c:\whatever.R, how can I execute it using commands (not drop down menu) in
>>>RGui? In stata, would be something like
>> 
>> 
>> If I am not mistaken the command is:
>>  > source("whatever.R")
>
>... or source("c:/whatever.R") if "c:\" is not your current working 
>directory.
>
>> 
>>> do c:\whatever.do
>>> How about in R. I tried the "R CMD BATCH('h:/whatever.R'), but it didn't
>>>work. Any help would be greatly appreciated.
>
>
>R CMD BATCH has to be executed from the Windows shell (looks like you 
>are running this OS) rather than from within R with the Syntax (if 
>called from c:\ and R is in your PATH):
>R CMD BATCH whatever.R
>
>Uwe Ligges
>
>
>
>> 
>> paul sorenson
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

= = = = = = = = = = = = = = = = = = = =
			


 

2005-10-15

------
Deparment of Sociology
Fudan University

My new mail addres is ronggui.huang at gmail.com
Blog:http://sociology.yculblog.com



From tschoenhoff at gmail.com  Sat Oct 15 12:55:50 2005
From: tschoenhoff at gmail.com (=?ISO-8859-1?Q?Thomas_Sch=F6nhoff?=)
Date: Sat, 15 Oct 2005 12:55:50 +0200
Subject: [R] subset selection for glm
In-Reply-To: <BAY102-F20330A648E387A724FD675D37D0@phx.gbl>
References: <BAY102-F20330A648E387A724FD675D37D0@phx.gbl>
Message-ID: <5ad2dec0510150355n62a188ddx@mail.gmail.com>

Hello Dhiren,

2005/10/15, Dhiren DSouza <dhiren22 at hotmail.com>:
> Hello:
>
> Are there any libraries that will do a subset selection for glm's?  I looked
> through leaps, but seems like it is specifically for linear regressions.


?subset should tell you. AFAIK, subset function is not depend on a
special statistical procedure, but on types of datasets: vectors,
matrices or data frames, as the related help page says.
>From ?glm help page:

 All of 'weights', 'subset', 'offset', 'etastart' and 'mustart' are
     evaluated in the same way as variables in 'formula', that is first
     in 'data' and then in the environment of 'formula'



If you want a more secific answer to your question it would be very
helpful to see a toy example of yours.

The posting guide (at the bottom of every mail ) is very helpful to
set up clear questions which likely increase your chance to get more
helpful responses from the list.

Thomas



From HStevens at muohio.edu  Sat Oct 15 13:35:29 2005
From: HStevens at muohio.edu (Hank Stevens)
Date: Sat, 15 Oct 2005 07:35:29 -0400
Subject: [R] use of NA's
In-Reply-To: <1123241457.3951.6.camel@localhost.localdomain>
References: <BAY105-F266B2ACC8BE026E011E774D0C70@phx.gbl>	<1123240259.3951.1.camel@localhost.localdomain>
	<1123241457.3951.6.camel@localhost.localdomain>
Message-ID: <4350E981.5090704@muohio.edu>

Hi Tom,
You need to use the is.na test rather then the test x==NA because the 
latter is not defined.

d<-c(0,2,3,2,0,3,4,0,0,0,0,0)
d.mat<-matrix(data=d,nrow=4,ncol=3,byrow=TRUE)
d.mat[d.mat==0]<-NA
for(i in 1:length(d.mat[1,])){
d.mat[,i][is.na(d.mat[,i])] <- mean(d.mat[,i],na.rm=TRUE)
}

Hank

tom wright wrote:

>Can someone please explain why this works: 
>
>  
>
>>>d<-c(0,2,3,2,0,3,4,0,0,0,0,0)
>>>d.mat<-matrix(data=d,nrow=4,ncol=3,byrow=TRUE)
>>>for(i in 1:length(d.mat[1,])){
>>>      
>>>
>>+ d.mat[,i][d.mat[,i]==0]<-mean(d.mat[,i][d.mat[,i]>0])
>>+ }
>>    
>>
>
>Whereas: 
>
>  
>
>>d<-c(0,2,3,2,0,3,4,0,0,0,0,0)
>>d.mat<-matrix(data=d,nrow=4,ncol=3,byrow=TRUE)
>>d.mat[d.mat==0]<-NA
>>for(i in 1:length(d.mat[1,])){
>>    
>>
>+ d.mat[,i][d.mat[,i]==NA]<-mean(d.mat[,i],na.rm=TRUE)
>+ }
>dosnt
>
>Thanks
>Tom
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>



From r-help at stat.math.ethz.ch  Sat Oct 15 16:52:54 2005
From: r-help at stat.math.ethz.ch (Dennis Ewing)
Date: Sat, 15 Oct 2005 10:52:54 -0400
Subject: [R] Your order (#gzmgss-R-help)
Message-ID: <3810033794.4361150301@hypatia.math.ethz.ch>


   Ciialis  Softt  Tabss  actts up to 36 houurs! Simplyy disollve halff a
   tablet underr youur tonngue 15 minuutes beforee s.ex.

       Alll orderrs willl be processed and dispatched withiin 24hrs.
                         100 pills - 1.98 per 10m.g
                              [1]Reaad more! 
                         look out theese cheap tabs

    I believe in only one thing: liberty but I do not believe in liberty
                  enough to want to force it upon anyone.

References

   1. http://uk.geocities.com/Salli32002Christina48517/


From jiesheng at bioteam.net  Sat Oct 15 17:29:00 2005
From: jiesheng at bioteam.net (jiesheng zhang)
Date: Sat, 15 Oct 2005 23:29:00 +0800
Subject: [R] write R extenesion issue
Message-ID: <4351203C.5090506@bioteam.net>

Hi, all
I am trying to write a R package. I was able to build and install the 
package with no problem.
However, I got this error when I try to load the library by calling 
library("btRRTest");
------------------error message in loading---------
 > library("btRRTest")
Error in library("btRRTest") : 'btRRTest' is not a valid package -- 
installed < 2.0.0?
---------------------------------
--------build message-----------
ason at jasonportal:~/tmp2> R CMD build --force btRRTest
* checking for file 'btRRTest/DESCRIPTION' ... OK
* preparing 'btRRTest':
* checking DESCRIPTION meta-information ... OK
* cleaning src
* checking whether 'INDEX' is up-to-date ... NO
* overwriting 'INDEX' as '--force' was given
* removing junk files
* checking for LF line-endings in source files
* checking for empty directories
* building 'btRRTest_0.0.1.tar.gz'
---------------------------------
-------install message-------
jasonportal:/home/jason/tmp2 # R CMD INSTALL btRRTest_0.0.1.tar.gz
* Installing *binary* package 'btRRTest' ...
* DONE (btRRTest)
----------------------


Can anyone tell me what are the possible causes for this error? Where 
should I start to look?

Thanks

-jason



From gmbegnis at yahoo.it  Sat Oct 15 17:33:40 2005
From: gmbegnis at yahoo.it (giacomo moro)
Date: Sat, 15 Oct 2005 17:33:40 +0200 (CEST)
Subject: [R] regression using a lagged dependent variable as explanatory
	variable
Message-ID: <20051015153340.76759.qmail@web25707.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051015/1cff3e7a/attachment.pl

From jiesheng at bioteam.net  Sat Oct 15 17:45:12 2005
From: jiesheng at bioteam.net (jiesheng zhang)
Date: Sat, 15 Oct 2005 23:45:12 +0800
Subject: [R] write R extenesion issue
In-Reply-To: <4351203C.5090506@bioteam.net>
References: <4351203C.5090506@bioteam.net>
Message-ID: <43512408.20203@bioteam.net>

My package structure is very simple.
I attached it here.
Any help is appreciated.
-ason

jiesheng zhang wrote:
> Hi, all
> I am trying to write a R package. I was able to build and install the 
> package with no problem.
> However, I got this error when I try to load the library by calling 
> library("btRRTest");
> ------------------error message in loading---------
>  > library("btRRTest")
> Error in library("btRRTest") : 'btRRTest' is not a valid package -- 
> installed < 2.0.0?
> ---------------------------------
> --------build message-----------
> ason at jasonportal:~/tmp2> R CMD build --force btRRTest
> * checking for file 'btRRTest/DESCRIPTION' ... OK
> * preparing 'btRRTest':
> * checking DESCRIPTION meta-information ... OK
> * cleaning src
> * checking whether 'INDEX' is up-to-date ... NO
> * overwriting 'INDEX' as '--force' was given
> * removing junk files
> * checking for LF line-endings in source files
> * checking for empty directories
> * building 'btRRTest_0.0.1.tar.gz'
> ---------------------------------
> -------install message-------
> jasonportal:/home/jason/tmp2 # R CMD INSTALL btRRTest_0.0.1.tar.gz
> * Installing *binary* package 'btRRTest' ...
> * DONE (btRRTest)
> ----------------------
> 
> 
> Can anyone tell me what are the possible causes for this error? Where 
> should I start to look?
> 
> Thanks
> 
> -jason
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

From junxu06 at gmail.com  Sat Oct 15 17:35:18 2005
From: junxu06 at gmail.com (jun xu)
Date: Sat, 15 Oct 2005 10:35:18 -0500
Subject: [R] batch file execution
In-Reply-To: <4350C4B9.4000809@statistik.uni-dortmund.de>
References: <8ee3db370510141948o3bb91048h282bbc36b23336c5@mail.gmail.com>
	<43508498.6040202@metrak.com>
	<4350C4B9.4000809@statistik.uni-dortmund.de>
Message-ID: <8ee3db370510150835x7d271dc2k2f31ed783f4a5771@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051015/664ae424/attachment.pl

From jiesheng at bioteam.net  Sat Oct 15 17:57:56 2005
From: jiesheng at bioteam.net (jiesheng zhang)
Date: Sat, 15 Oct 2005 23:57:56 +0800
Subject: [R] write R extenesion issue
In-Reply-To: <43512408.20203@bioteam.net>
References: <4351203C.5090506@bioteam.net> <43512408.20203@bioteam.net>
Message-ID: <43512704.1060108@bioteam.net>

I found my attachment was discarded.
My R package structure lis listed here
-----------------------------
btRRTest
	DESCRIPTION
		Package: btRRTest
		Version: 0.0.1
		Date: 2005-10-15
		Title: a test remote R exeuction
		Author: jiesheng at bioteam.net
		Maintainer: jason zhang<jiesheng at bioteam.net>
		Depends: R (>= 1.8.0)
		Description: the remote execution of R call
		License: GPL version 2
		URL: http://www.bioteam.net
		Built: R 2.1.1; i686-pc-linux-gnu; 2005-09-20 00:07:19; unix
		Packaged: Sat Oct 15 23:42:11 2005; root
	INDEX
		btRRTestOut             serialize all
		btRRTestInt             unserialize all and execute
	R/btRRTest.R
		.First.lib <- function (lib, pkg)
		{
		    #library.dynam("btRRTest", pkg, lib)
		    print(c("first.lib", pkg, lib))
		}

		btRRTestOut<-function(x)
		{
         		#.Call("btRRTestOut", substitute(x), rho=sys.frame(-1), 
PACKAGE="btRRTest");
         		print("btRRTestOut");
		}

		btRRTestIn<-function()
		{
         		#.Call("btRRTestIn",  PACKAGE="btRRTest");
         		print("btRRTestIn");
		}

----------------------------

-jason


jiesheng zhang wrote:
> My package structure is very simple.
> I attached it here.
> Any help is appreciated.
> -ason
> 
> jiesheng zhang wrote:
>> Hi, all
>> I am trying to write a R package. I was able to build and install the 
>> package with no problem.
>> However, I got this error when I try to load the library by calling 
>> library("btRRTest");
>> ------------------error message in loading---------
>>  > library("btRRTest")
>> Error in library("btRRTest") : 'btRRTest' is not a valid package -- 
>> installed < 2.0.0?
>> ---------------------------------
>> --------build message-----------
>> ason at jasonportal:~/tmp2> R CMD build --force btRRTest
>> * checking for file 'btRRTest/DESCRIPTION' ... OK
>> * preparing 'btRRTest':
>> * checking DESCRIPTION meta-information ... OK
>> * cleaning src
>> * checking whether 'INDEX' is up-to-date ... NO
>> * overwriting 'INDEX' as '--force' was given
>> * removing junk files
>> * checking for LF line-endings in source files
>> * checking for empty directories
>> * building 'btRRTest_0.0.1.tar.gz'
>> ---------------------------------
>> -------install message-------
>> jasonportal:/home/jason/tmp2 # R CMD INSTALL btRRTest_0.0.1.tar.gz
>> * Installing *binary* package 'btRRTest' ...
>> * DONE (btRRTest)
>> ----------------------
>>
>>
>> Can anyone tell me what are the possible causes for this error? Where 
>> should I start to look?
>>
>> Thanks
>>
>> -jason
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ggrothendieck at gmail.com  Sat Oct 15 17:50:01 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 15 Oct 2005 11:50:01 -0400
Subject: [R] regression using a lagged dependent variable as explanatory
	variable
In-Reply-To: <20051015153340.76759.qmail@web25707.mail.ukl.yahoo.com>
References: <20051015153340.76759.qmail@web25707.mail.ukl.yahoo.com>
Message-ID: <971536df0510150850i7def0b2fwd7233ef601a83363@mail.gmail.com>

Create time series from your data and then use lm with
the dyn or dynlm package (as lm does not support time
series directly).  With the dyn package you just preface
lm with dyn$ and then use lm as usual:

library(dyn)
yt <- ts(y)
xt <- ts(x)
dyn$lm(yt ~ xt + lag(yt, -1))

After loading dyn try this for more info:

package?dyn


On 10/15/05, giacomo moro <gmbegnis at yahoo.it> wrote:
> Hi,
> I would like to regress y (dependent variable) on x (independent variable) and y(-1).
> I have create the y(-1) variable in this way:  ly<-lag(y, -1)
> Now if I do the following regression  lm (y ~ x + ly) the results I obtain are not correct.
> Can someone tell me the code to use in R in order to perform a regression using as explanatory variable a lagged dependent variable?
> My best regards,
>                    Giacomo
>
>
> ---------------------------------
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From 042045003 at fudan.edu.cn  Sat Oct 15 17:54:36 2005
From: 042045003 at fudan.edu.cn (ronggui)
Date: Sat, 15 Oct 2005 23:54:36 +0800
Subject: [R] how to import such data to R?
Message-ID: <0IOE0081IRPE90@mail.fudan.edu.cn>

It seems my last post  not sent successfully ,so I post again.

-------------
the data file has such structure:

     1992       6245         49          .          .         20          1
        0          0   8.739536          0          .          .          .
        .          .          .          .          .            "alabama"
        .          0          .
     1993       7677         58          .          .         15          1
        0          0   8.945984          1          .          0   .2064476
       -5          0          .          0   8.739536            "alabama"
        9          0          0
     1992      13327         57         36         58         16          0
        0          0   9.497547          0         47          .          .
        .          .          .          0          .            "arizona"
        .          0          .
     1993      19860         57         36         58         16          1
        1          0   9.896463          1         47          0   .3989162
        0          1          0          1   9.497547            "arizona"
        0          1          1
     1992      10422         37         28         58         20          0
        0          0   9.251675          0         43          .          .
        .          .          .         -1          .      "arizona state"
        .          0          .

------snip-----

the data descriptions is:

variable names:

year      apps      top25     ver500    mth500    stufac    bowl      btitle   
finfour   lapps     d93       avg500    cfinfour  clapps    cstufac   cbowl    
cavg500   cbtitle   lapps_1   school    ctop25    bball     cbball    

  Obs:   118

  1. year                     1992 or 1993
  2. apps                     # applics for admission
  3. top25                    perc frosh class in 25th high sch percen
  4. ver500                   perc frosh >= 500 on verbal SAT
  5. mth500                   perc frosh >= 500 on math SAT
  6. stufac                   student-faculty ratio
  7. bowl                     = 1 if bowl game in prev year
  8. btitle                   = 1 if men's cnf chmps prev year
  9. finfour                  = 1 if men's final 4 prev year
 10. lapps                    log(apps)
 11. d93                      =1 if year = 1993
 12. avg500                   (ver500+mth500)/2
 13. cfinfour                 change in finfour
 14. clapps                   change in lapps
 15. cstufac                  change in stufac
 16. cbowl                    change in bowl
 17. cavg500                  change in avg500
 18. cbtitle                  change in btitle
 19. lapps_1                  lapps lagged
 20. school                   university name
 21. ctop25                   change in top25
 22. bball                    =1 if btitle or finfour
 23. cbball                   change in bball


so the each four lines represent  one case,can some variables are numeric and some are character.
I though the scan can read it in ,but it seems somewhat tricky as the mixed type of variables.any suggestions?
		


2005-10-15

------
Deparment of Sociology
Fudan University

My new mail addres is ronggui.huang at gmail.com
Blog:http://sociology.yculblog.com



From ccatj at web.de  Sat Oct 15 18:00:18 2005
From: ccatj at web.de (Christian Jones)
Date: Sat, 15 Oct 2005 18:00:18 +0200
Subject: [R] generating response curves
Message-ID: <372496002@web.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051015/4c1757ea/attachment.pl

From Achim.Zeileis at wu-wien.ac.at  Sat Oct 15 18:04:10 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Sat, 15 Oct 2005 18:04:10 +0200 (CEST)
Subject: [R] regression using a lagged dependent variable as explanatory
 variable
In-Reply-To: <20051015153340.76759.qmail@web25707.mail.ukl.yahoo.com>
References: <20051015153340.76759.qmail@web25707.mail.ukl.yahoo.com>
Message-ID: <Pine.LNX.4.58.0510151801540.2446@thorin.ci.tuwien.ac.at>

On Sat, 15 Oct 2005, giacomo moro wrote:

> Hi,
> I would like to regress y (dependent variable) on x (independent variable) and y(-1).
> I have create the y(-1) variable in this way:  ly<-lag(y, -1)
> Now if I do the following regression  lm (y ~ x + ly) the results I obtain are not correct.

The reason is that lm() itself does not match time series by their time
attribute (and apart from the "tsp" attribute x and lag(x, -1) are the
same vector). On ?lm there is a description what you could do to create a
time series and then apply lm().
As Gabor already wrote, there are two convenience interfaces available in
the packages dyn and dynlm.
Z

> Can someone tell me the code to use in R in order to perform a regression using as explanatory variable a lagged dependent variable?
> My best regards,
>                     Giacomo
>
>
> ---------------------------------
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ggrothendieck at gmail.com  Sat Oct 15 18:28:50 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 15 Oct 2005 12:28:50 -0400
Subject: [R] grid.edit problem
Message-ID: <971536df0510150928s2a8a6935k33470e74d169f832@mail.gmail.com>

I am having a problem in editing a grob.  It works ok if I try to
shift the grob using npc coordinates but if I do the same thing
using native coordinates the grob disappears.  What is wrong?


library(grid)
grid.newpage()

# create viewport
pushViewport(viewport(xscale = c(100,200), name = "X"))

# draw vertical line
grid.lines(150, 0:1, default.units = "native",  name = "L")

# move line 25% of the way to the right. Works ok.
grid.edit("L", x = grid.get("L")$x + unit(0.25, "npc"))


# but now repeat it shifting it using native coordinates
########################################################

# remove line and draw a new line where the original one was
grid.remove("L")
grid.lines(150, 0:1, default.units = "native",  name = "L")

# move line 25% of the way to the right but use native coordiantes
#### line disappears !!!!!!!!!
grid.edit("L", x = grid.get("L")$x + unit(25, "native"))



From ggrothendieck at gmail.com  Sat Oct 15 18:32:36 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 15 Oct 2005 12:32:36 -0400
Subject: [R] grid.edit problem
In-Reply-To: <971536df0510150928s2a8a6935k33470e74d169f832@mail.gmail.com>
References: <971536df0510150928s2a8a6935k33470e74d169f832@mail.gmail.com>
Message-ID: <971536df0510150932u4ee34a3awa57f5fa8cf19f6d7@mail.gmail.com>

Sorry, forgot to mention my system:

> R.version.string # XP
[1] "R version 2.2.0, 2005-09-20"



On 10/15/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> I am having a problem in editing a grob.  It works ok if I try to
> shift the grob using npc coordinates but if I do the same thing
> using native coordinates the grob disappears.  What is wrong?
>
>
> library(grid)
> grid.newpage()
>
> # create viewport
> pushViewport(viewport(xscale = c(100,200), name = "X"))
>
> # draw vertical line
> grid.lines(150, 0:1, default.units = "native",  name = "L")
>
> # move line 25% of the way to the right. Works ok.
> grid.edit("L", x = grid.get("L")$x + unit(0.25, "npc"))
>
>
> # but now repeat it shifting it using native coordinates
> ########################################################
>
> # remove line and draw a new line where the original one was
> grid.remove("L")
> grid.lines(150, 0:1, default.units = "native",  name = "L")
>
> # move line 25% of the way to the right but use native coordiantes
> #### line disappears !!!!!!!!!
> grid.edit("L", x = grid.get("L")$x + unit(25, "native"))
>



From MSchwartz at mn.rr.com  Sat Oct 15 18:43:37 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Sat, 15 Oct 2005 11:43:37 -0500
Subject: [R] how to import such data to R?
In-Reply-To: <0IOE0081IRPE90@mail.fudan.edu.cn>
References: <0IOE0081IRPE90@mail.fudan.edu.cn>
Message-ID: <1129394617.5518.14.camel@localhost.localdomain>

On Sat, 2005-10-15 at 23:54 +0800, ronggui wrote:
> It seems my last post  not sent successfully ,so I post again.
> 
> -------------
> the data file has such structure:
> 
>      1992       6245         49          .          .         20          1
>         0          0   8.739536          0          .          .          .
>         .          .          .          .          .            "alabama"
>         .          0          .
>      1993       7677         58          .          .         15          1
>         0          0   8.945984          1          .          0   .2064476
>        -5          0          .          0   8.739536            "alabama"
>         9          0          0
>      1992      13327         57         36         58         16          0
>         0          0   9.497547          0         47          .          .
>         .          .          .          0          .            "arizona"
>         .          0          .
>      1993      19860         57         36         58         16          1
>         1          0   9.896463          1         47          0   .3989162
>         0          1          0          1   9.497547            "arizona"
>         0          1          1
>      1992      10422         37         28         58         20          0
>         0          0   9.251675          0         43          .          .
>         .          .          .         -1          .      "arizona state"
>         .          0          .
> 
> ------snip-----
> 
> the data descriptions is:
> 
> variable names:
> 
> year      apps      top25     ver500    mth500    stufac    bowl      btitle   
> finfour   lapps     d93       avg500    cfinfour  clapps    cstufac   cbowl    
> cavg500   cbtitle   lapps_1   school    ctop25    bball     cbball    
> 
>   Obs:   118
> 
>   1. year                     1992 or 1993
>   2. apps                     # applics for admission
>   3. top25                    perc frosh class in 25th high sch percen
>   4. ver500                   perc frosh >= 500 on verbal SAT
>   5. mth500                   perc frosh >= 500 on math SAT
>   6. stufac                   student-faculty ratio
>   7. bowl                     = 1 if bowl game in prev year
>   8. btitle                   = 1 if men's cnf chmps prev year
>   9. finfour                  = 1 if men's final 4 prev year
>  10. lapps                    log(apps)
>  11. d93                      =1 if year = 1993
>  12. avg500                   (ver500+mth500)/2
>  13. cfinfour                 change in finfour
>  14. clapps                   change in lapps
>  15. cstufac                  change in stufac
>  16. cbowl                    change in bowl
>  17. cavg500                  change in avg500
>  18. cbtitle                  change in btitle
>  19. lapps_1                  lapps lagged
>  20. school                   university name
>  21. ctop25                   change in top25
>  22. bball                    =1 if btitle or finfour
>  23. cbball                   change in bball
> 
> 
> so the each four lines represent  one case,can some variables are numeric and some are character.
> I though the scan can read it in ,but it seems somewhat tricky as the mixed type of variables.any suggestions?

There may be an easier way, but here is one possible approach:

First, use scan to read in the data. Set the 'what' argument to a list
of atomic data types, based upon your specs above. Also, set the
'na.names' argument to '.'.

This will read in the multiple lines for each record, into a single
record based upon there being 23 elements per record. That is based upon
'length(what)'.  Note also the 'multi.line' argument in scan().

data <- scan("data.txt", 
             what = c(rep(list(numeric(0)), 19), 
                      list(character(0)), 
                      rep(list(numeric(0)), 3)), 
             na.strings = ".")


'data' is now a list of values, where each list element is a proper
column from your original data file. Now use as.data.frame(), which will
take each list element and turn it into a column in a data frame.
preserving the data types.

data <- as.data.frame(data)


Now, read in the column names for the data frame from a text file,
containing your field names above, and set the data frame column names
to these.

Names <- scan("names.txt", what = character(0))
names(data) <- Names


Now review the structure of 'data':

> data
  year  apps top25 ver500 mth500 stufac bowl btitle finfour    lapps
1 1992  6245    49     NA     NA     20    1      0       0 8.739536
2 1993  7677    58     NA     NA     15    1      0       0 8.945984
3 1992 13327    57     36     58     16    0      0       0 9.497547
4 1993 19860    57     36     58     16    1      1       0 9.896463
5 1992 10422    37     28     58     20    0      0       0 9.251675
  d93 avg500 cfinfour    clapps cstufac cbowl cavg500 cbtitle  lapps_1
1   0     NA       NA        NA      NA    NA      NA      NA       NA
2   1     NA        0 0.2064476      -5     0      NA       0 8.739536
3   0     47       NA        NA      NA    NA      NA       0       NA
4   1     47        0 0.3989162       0     1       0       1 9.497547
5   0     43       NA        NA      NA    NA      NA      -1       NA
         school ctop25 bball cbball
1       alabama     NA     0     NA
2       alabama      9     0      0
3       arizona     NA     0     NA
4       arizona      0     1      1
5 arizona state     NA     0     NA


HTH,

Marc Schwartz



From MSchwartz at mn.rr.com  Sat Oct 15 18:48:10 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Sat, 15 Oct 2005 11:48:10 -0500
Subject: [R] how to import such data to R?
In-Reply-To: <1129394617.5518.14.camel@localhost.localdomain>
References: <0IOE0081IRPE90@mail.fudan.edu.cn>
	<1129394617.5518.14.camel@localhost.localdomain>
Message-ID: <1129394890.5518.16.camel@localhost.localdomain>

On Sat, 2005-10-15 at 11:43 -0500, Marc Schwartz wrote:

> There may be an easier way, but here is one possible approach:
> 
> First, use scan to read in the data. Set the 'what' argument to a list
> of atomic data types, based upon your specs above. Also, set the
> 'na.names' argument to '.'.

Ack....that should of course read 'na.strings', not 'na.names'...

Marc



From ligges at statistik.uni-dortmund.de  Sat Oct 15 19:03:30 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 15 Oct 2005 19:03:30 +0200
Subject: [R] batch file execution
In-Reply-To: <8ee3db370510150835x7d271dc2k2f31ed783f4a5771@mail.gmail.com>
References: <8ee3db370510141948o3bb91048h282bbc36b23336c5@mail.gmail.com>	
	<43508498.6040202@metrak.com>	
	<4350C4B9.4000809@statistik.uni-dortmund.de>
	<8ee3db370510150835x7d271dc2k2f31ed783f4a5771@mail.gmail.com>
Message-ID: <43513662.6000900@statistik.uni-dortmund.de>

jun xu wrote:

> Thanks for all your (ronggui, *Uwe Ligges , **sosman) *help. I got it
> through using source. I know R has gone through all those lines, but I
> didn't get results of what I would if I use drop-down menu and click "run
> all" under edit after I open a script file? Basically, nothing hasspens
> except that no error message. My codes are very simple,
> 
> help(lm)
> library(foreign)
> mydta <-read.dta('h:/data/binlfp2.dta')
> mydta[1:5,]

Don't forget to print():

print(mydta[1:5,])

Uwe Ligges



> 
> Are the log results saved somewhere else automatically? Thanks again.
> 
> On 10/15/05, Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:
> 
>>sosman wrote:
>>
>>>jun xu wrote:
>>>
>>>
>>>>I am new to R and really like to get a handle of basics in short period
>>
>>of
>>
>>>>time. What I am trying to do is get myself a list of must-do's (read in
>>>>data, batch execution, delimiters, basic modeling commands) in R as in
>>
>>Stata
>>
>>>>or SAS. I am just wondering how to execute a R batch file in RGui.
>>
>>Suppose I
>>
>>>>have a script file (like do file in stata, or sas file in SAS) under
>>>>c:\whatever.R, how can I execute it using commands (not drop down menu)
>>
>>in
>>
>>>>RGui? In stata, would be something like
>>>
>>>
>>>If I am not mistaken the command is:
>>>
>>>>source("whatever.R")
>>
>>... or source("c:/whatever.R") if "c:\" is not your current working
>>directory.
>>
>>
>>>>do c:\whatever.do
>>>>How about in R. I tried the "R CMD BATCH('h:/whatever.R'), but it
>>
>>didn't
>>
>>>>work. Any help would be greatly appreciated.
>>
>>
>>R CMD BATCH has to be executed from the Windows shell (looks like you
>>are running this OS) rather than from within R with the Syntax (if
>>called from c:\ and R is in your PATH):
>>R CMD BATCH whatever.R
>>
>>Uwe Ligges
>>
>>
>>
>>
>>>paul sorenson
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide!
>>
>>http://www.R-project.org/posting-guide.html
>>
>>
>>
> 
>



From murdoch at stats.uwo.ca  Sat Oct 15 19:03:53 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 15 Oct 2005 13:03:53 -0400
Subject: [R] write R extenesion issue
In-Reply-To: <43512704.1060108@bioteam.net>
References: <4351203C.5090506@bioteam.net> <43512408.20203@bioteam.net>
	<43512704.1060108@bioteam.net>
Message-ID: <43513679.5020406@stats.uwo.ca>

jiesheng zhang wrote:
> I found my attachment was discarded.
> My R package structure lis listed here
> -----------------------------
> btRRTest
> 	DESCRIPTION
> 		Package: btRRTest
> 		Version: 0.0.1
> 		Date: 2005-10-15
> 		Title: a test remote R exeuction
> 		Author: jiesheng at bioteam.net
> 		Maintainer: jason zhang<jiesheng at bioteam.net>
> 		Depends: R (>= 1.8.0)
> 		Description: the remote execution of R call
> 		License: GPL version 2
> 		URL: http://www.bioteam.net
> 		Built: R 2.1.1; i686-pc-linux-gnu; 2005-09-20 00:07:19; unix
> 		Packaged: Sat Oct 15 23:42:11 2005; root

Is this from your source directory?  You shouldn't have the Built and 
Packaged lines in your source.

If this is from the directory where it was installed, never mind, unless 
those two directories are the same:  in which case the advice is "don't 
do that".  Keep your installed copies separate from the source.

The error message you saw

> Error in library("btRRTest") : 'btRRTest' is not a valid package -- 
> installed < 2.0.0?

indicates that the "Meta/package.rds" file is missing from your 
installed package subdirectory, but it's hard to guess why.

Duncan Murdoch



From p.dalgaard at biostat.ku.dk  Sat Oct 15 19:06:30 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 15 Oct 2005 19:06:30 +0200
Subject: [R] write R extenesion issue
In-Reply-To: <43512704.1060108@bioteam.net>
References: <4351203C.5090506@bioteam.net> <43512408.20203@bioteam.net>
	<43512704.1060108@bioteam.net>
Message-ID: <x2mzlak8vd.fsf@turmalin.kubism.ku.dk>

jiesheng zhang <jiesheng at bioteam.net> writes:

> I found my attachment was discarded.
> My R package structure lis listed here
> -----------------------------
> btRRTest
> 	DESCRIPTION
> 		Package: btRRTest
> 		Version: 0.0.1
> 		Date: 2005-10-15
> 		Title: a test remote R exeuction
> 		Author: jiesheng at bioteam.net
> 		Maintainer: jason zhang<jiesheng at bioteam.net>
> 		Depends: R (>= 1.8.0)
> 		Description: the remote execution of R call
> 		License: GPL version 2
> 		URL: http://www.bioteam.net
> 		Built: R 2.1.1; i686-pc-linux-gnu; 2005-09-20 00:07:19; unix

I don't think you want to have a Built: field in a source package.
Apparently, you are getting the package installed as a binary package
even though it isn't.   

> 		Packaged: Sat Oct 15 23:42:11 2005; root
> 	INDEX
> 		btRRTestOut             serialize all
> 		btRRTestInt             unserialize all and execute
> 	R/btRRTest.R
> 		.First.lib <- function (lib, pkg)
> 		{
> 		    #library.dynam("btRRTest", pkg, lib)
> 		    print(c("first.lib", pkg, lib))
> 		}
> 
> 		btRRTestOut<-function(x)
> 		{
>          		#.Call("btRRTestOut", substitute(x), rho=sys.frame(-1), 
> PACKAGE="btRRTest");
>          		print("btRRTestOut");
> 		}
> 
> 		btRRTestIn<-function()
> 		{
>          		#.Call("btRRTestIn",  PACKAGE="btRRTest");
>          		print("btRRTestIn");
> 		}
> 
> ----------------------------
> 
> -jason
> 
> 
> jiesheng zhang wrote:
> > My package structure is very simple.
> > I attached it here.
> > Any help is appreciated.
> > -ason
> > 
> > jiesheng zhang wrote:
> >> Hi, all
> >> I am trying to write a R package. I was able to build and install the 
> >> package with no problem.
> >> However, I got this error when I try to load the library by calling 
> >> library("btRRTest");
> >> ------------------error message in loading---------
> >>  > library("btRRTest")
> >> Error in library("btRRTest") : 'btRRTest' is not a valid package -- 
> >> installed < 2.0.0?
> >> ---------------------------------
> >> --------build message-----------
> >> ason at jasonportal:~/tmp2> R CMD build --force btRRTest
> >> * checking for file 'btRRTest/DESCRIPTION' ... OK
> >> * preparing 'btRRTest':
> >> * checking DESCRIPTION meta-information ... OK
> >> * cleaning src
> >> * checking whether 'INDEX' is up-to-date ... NO
> >> * overwriting 'INDEX' as '--force' was given
> >> * removing junk files
> >> * checking for LF line-endings in source files
> >> * checking for empty directories
> >> * building 'btRRTest_0.0.1.tar.gz'
> >> ---------------------------------
> >> -------install message-------
> >> jasonportal:/home/jason/tmp2 # R CMD INSTALL btRRTest_0.0.1.tar.gz
> >> * Installing *binary* package 'btRRTest' ...
> >> * DONE (btRRTest)
> >> ----------------------
> >>
> >>
> >> Can anyone tell me what are the possible causes for this error? Where 
> >> should I start to look?
> >>
> >> Thanks
> >>
> >> -jason
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide! 
> >> http://www.R-project.org/posting-guide.html
> > 
> > ------------------------------------------------------------------------
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Sat Oct 15 19:08:46 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 15 Oct 2005 18:08:46 +0100 (BST)
Subject: [R] write R extenesion issue
In-Reply-To: <43512704.1060108@bioteam.net>
References: <4351203C.5090506@bioteam.net> <43512408.20203@bioteam.net>
	<43512704.1060108@bioteam.net>
Message-ID: <Pine.LNX.4.61.0510151806060.9854@gannet.stats>

Here is the cause:

>> * Installing *binary* package 'btRRTest' ...
                  ^^^^^^

However, you have a source package, and you have an invalid DESCRIPTION 
file containing a Built: line.

Please read `Writing R Extensions' and check you are following the rules 
it lays down (as in this respect at least you are not).


On Sat, 15 Oct 2005, jiesheng zhang wrote:

> I found my attachment was discarded.
> My R package structure lis listed here
> -----------------------------
> btRRTest
> 	DESCRIPTION
> 		Package: btRRTest
> 		Version: 0.0.1
> 		Date: 2005-10-15
> 		Title: a test remote R exeuction
> 		Author: jiesheng at bioteam.net
> 		Maintainer: jason zhang<jiesheng at bioteam.net>
> 		Depends: R (>= 1.8.0)
> 		Description: the remote execution of R call
> 		License: GPL version 2
> 		URL: http://www.bioteam.net
> 		Built: R 2.1.1; i686-pc-linux-gnu; 2005-09-20 00:07:19; unix
> 		Packaged: Sat Oct 15 23:42:11 2005; root
> 	INDEX
> 		btRRTestOut             serialize all
> 		btRRTestInt             unserialize all and execute
> 	R/btRRTest.R
> 		.First.lib <- function (lib, pkg)
> 		{
> 		    #library.dynam("btRRTest", pkg, lib)
> 		    print(c("first.lib", pkg, lib))
> 		}
>
> 		btRRTestOut<-function(x)
> 		{
>         		#.Call("btRRTestOut", substitute(x), rho=sys.frame(-1),
> PACKAGE="btRRTest");
>         		print("btRRTestOut");
> 		}
>
> 		btRRTestIn<-function()
> 		{
>         		#.Call("btRRTestIn",  PACKAGE="btRRTest");
>         		print("btRRTestIn");
> 		}
>
> ----------------------------
>
> -jason
>
>
> jiesheng zhang wrote:
>> My package structure is very simple.
>> I attached it here.
>> Any help is appreciated.
>> -ason
>>
>> jiesheng zhang wrote:
>>> Hi, all
>>> I am trying to write a R package. I was able to build and install the
>>> package with no problem.
>>> However, I got this error when I try to load the library by calling
>>> library("btRRTest");
>>> ------------------error message in loading---------
>>> > library("btRRTest")
>>> Error in library("btRRTest") : 'btRRTest' is not a valid package --
>>> installed < 2.0.0?
>>> ---------------------------------
>>> --------build message-----------
>>> ason at jasonportal:~/tmp2> R CMD build --force btRRTest
>>> * checking for file 'btRRTest/DESCRIPTION' ... OK
>>> * preparing 'btRRTest':
>>> * checking DESCRIPTION meta-information ... OK
>>> * cleaning src
>>> * checking whether 'INDEX' is up-to-date ... NO
>>> * overwriting 'INDEX' as '--force' was given
>>> * removing junk files
>>> * checking for LF line-endings in source files
>>> * checking for empty directories
>>> * building 'btRRTest_0.0.1.tar.gz'
>>> ---------------------------------
>>> -------install message-------
>>> jasonportal:/home/jason/tmp2 # R CMD INSTALL btRRTest_0.0.1.tar.gz
>>> * Installing *binary* package 'btRRTest' ...
>>> * DONE (btRRTest)
>>> ----------------------
>>>
>>>
>>> Can anyone tell me what are the possible causes for this error? Where
>>> should I start to look?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From MSchwartz at mn.rr.com  Sat Oct 15 19:10:35 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Sat, 15 Oct 2005 12:10:35 -0500
Subject: [R] generating response curves
In-Reply-To: <372496002@web.de>
References: <372496002@web.de>
Message-ID: <1129396235.5518.18.camel@localhost.localdomain>

On Sat, 2005-10-15 at 18:00 +0200, Christian Jones wrote:
> 
> Hello 
> does anyone know how to visualize a response curve based on a
> regression model with lines rather than dots. Having a large number of
> parameters the following formula is to time consuming. Perhaps a built
> in function exists to speed up the process.
> 
> Model1<-a~b
> #Setting the scale extent
> min(area)
> max(area)
> avals<-seq(0,10,.1)
> # generating the plot
> plot(area,incidence, las=1)
> lines(avals,predict(model4,list(area=avals),type="response"))
> 
> Thanks in advance
> Christian


Did you review the example in ?predict.lm?

HTH,

Marc Schwartz



From dhiren22 at hotmail.com  Sat Oct 15 19:21:53 2005
From: dhiren22 at hotmail.com (Dhiren DSouza)
Date: Sat, 15 Oct 2005 13:21:53 -0400
Subject: [R]  subset selection for glm
Message-ID: <BAY102-F257594B73F97FCD0A6D04DD37C0@phx.gbl>

I posted a message earlier about subset selection.

I have a data set with 50 variables x1, x2, .... x50

x50 is a binary response variable that I would like to predict.  Is there a 
library I could use to do an exhaustive search for a subset 
(forward/backward subset selection) of variables to include in the 
regression model.  Any help would be greatly appreciated.

-D



From ripley at stats.ox.ac.uk  Sat Oct 15 19:49:50 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 15 Oct 2005 18:49:50 +0100 (BST)
Subject: [R] subset selection for glm
In-Reply-To: <BAY102-F257594B73F97FCD0A6D04DD37C0@phx.gbl>
References: <BAY102-F257594B73F97FCD0A6D04DD37C0@phx.gbl>
Message-ID: <Pine.LNX.4.61.0510151837400.3833@gannet.stats>

On Sat, 15 Oct 2005, Dhiren DSouza wrote:

> I posted a message earlier about subset selection.
>
> I have a data set with 50 variables x1, x2, .... x50
>
> x50 is a binary response variable that I would like to predict.  Is there a
> library I could use to do an exhaustive search for a subset
> (forward/backward subset selection) of variables to include in the
> regression model.  Any help would be greatly appreciated.

?step  (as surely help.search() would have shown you), and btw, that is 
not an `exhaustive search' procedure.

Frank Harrell has posted repeatedly on the dangers of unthinking use of 
such a procedure -- if he does not chime in now, please do look at his 
posts (and if you have access to it, his book).  You have not told us 
*why* you want to do variable selection (which is a more accurate name for 
what you are calling `subset' selection), and for most purposes it is not 
a good idea.


Let me second Roger Bivand's comment earlier today:

> I would, though, appeal to posters to give those who try to reply to
> questions at least a little help, by including an informative signature
> block.

I know that several helpers are quite unlikely to offer help to someone 
sending an unsigned letter, for that is what not using a real user name 
and affiliation amounts to.  So, PLEASE give your credentials -- this 
forum is a free (to the recipients) technical support forum, and that is a 
privilege that should be respected.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ff809 at ncf.ca  Sat Oct 15 20:35:36 2005
From: ff809 at ncf.ca (Brian Lunergan)
Date: Sat, 15 Oct 2005 14:35:36 -0400
Subject: [R] Your order (#gzmgss-R-help) Is somebody's machine infected
 to zombie this trash??
In-Reply-To: <3810033794.4361150301@hypatia.math.ethz.ch>
References: <3810033794.4361150301@hypatia.math.ethz.ch>
Message-ID: <43514BF8.8060301@ncf.ca>

Dennis Ewing wrote:
>    Ciialis  Softt  Tabss  actts up to 36 houurs! Simplyy disollve halff a
>    tablet underr youur tonngue 15 minuutes beforee s.ex.
> 
>        Alll orderrs willl be processed and dispatched withiin 24hrs.
>                          100 pills - 1.98 per 10m.g
>                               [1]Reaad more! 
>                          look out theese cheap tabs
> 
>     I believe in only one thing: liberty but I do not believe in liberty
>                   enough to want to force it upon anyone.
> 
> References
> 
>    1. http://uk.geocities.com/Salli32002Christina48517/

I've marked this as junk in Thunderbird. Is somebody's machine infected
to zombie this internet trash to the list??

-- 
Brian Lunergan
Nepean, Ontario
Canada


---
avast! Antivirus: Outbound message clean.
Virus Database (VPS): 0541-3, 2005-10-14
Tested on: 15/10/05 2:35:38 PM
avast! is copyright (c) 2000-2003 ALWIL Software.
http://www.avast.com



From hodgess at gator.dt.uh.edu  Sat Oct 15 22:53:55 2005
From: hodgess at gator.dt.uh.edu (Erin Hodgess)
Date: Sat, 15 Oct 2005 15:53:55 -0500
Subject: [R]  TRAMO-SEATS confusion?
Message-ID: <200510152053.j9FKrtIv000567@gator.dt.uh.edu>

Dear R People:

When looking at the previous postings regarding TRAMO-SEATS,
I am somewhat puzzled.

Is it true that we CANNOT replicate TRAMO-SEATS because of 
licensing or ownership issues, please?

If not, would anyone be interested in an R version of it, please?

Thanks,
Sincerely,
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
mailto: hodgess at gator.uhd.edu



From edd at debian.org  Sat Oct 15 23:41:17 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 15 Oct 2005 16:41:17 -0500
Subject: [R] TRAMO-SEATS confusion?
In-Reply-To: <200510152053.j9FKrtIv000567@gator.dt.uh.edu>
References: <200510152053.j9FKrtIv000567@gator.dt.uh.edu>
Message-ID: <17233.30589.391163.901195@basebud.nulle.part>


Erin,

On 15 October 2005 at 15:53, Erin Hodgess wrote:
| When looking at the previous postings regarding TRAMO-SEATS,
| I am somewhat puzzled.
| 
| Is it true that we CANNOT replicate TRAMO-SEATS because of 
| licensing or ownership issues, please?

Could you please 

i)  define 'replicate', and 

ii) cite any licenses to back up this claim, or simply show us what you
    find so confusing.

I suspect that you are misinterpreting this, and that tramo-seats is indeed
"simply" closed-source software that you can get re-distributed in binary
form (e.g. from the gretl website, see below), but not in source. 

| If not, would anyone be interested in an R version of it, please?

A couple of years ago I toyed with both the US Census' X12-ARIMA procedure
and its tramo-seats alternative by Maravall et al.  Given how atrociously
'1960s' the X12-ARIMA interface is, I toyed with building an R frontend given
that you get the Fortran code to X12-ARIMA straight from the Census site .
But then something else came up and I never pursued this ...

The closest I know to using x12 and/or tramo-seats from somewhat saner and
more modern software is via Allin Cottrell's gretl (cf http://gretl.sf.net).
And per my suggestion a few years back, Allin even hacked a 'gretl to R'
interface [ via mucking with ~/.Rprofile which isn't pretty but that is
another story ... ]

Hope this helps,  Dirk

| 
| Thanks,
| Sincerely,
| Erin Hodgess
| Associate Professor
| Department of Computer and Mathematical Sciences
| University of Houston - Downtown
| mailto: hodgess at gator.uhd.edu
| 
| ______________________________________________
| R-help at stat.math.ethz.ch mailing list
| https://stat.ethz.ch/mailman/listinfo/r-help
| PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Statistics: The (futile) attempt to offer certainty about uncertainty.
         -- Roger Koenker, 'Dictionary of Received Ideas of Statistics'



From aliscla at yahoo.com  Sun Oct 16 00:02:26 2005
From: aliscla at yahoo.com (Werner Bier)
Date: Sat, 15 Oct 2005 15:02:26 -0700 (PDT)
Subject: [R] solve() versus ginv()
Message-ID: <20051015220226.44205.qmail@web61225.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051015/2c0f97af/attachment.pl

From cottrell at wfu.edu  Sun Oct 16 05:06:27 2005
From: cottrell at wfu.edu (Allin Cottrell)
Date: Sat, 15 Oct 2005 23:06:27 -0400 (EDT)
Subject: [R] TRAMO-SEATS confusion?
In-Reply-To: <17233.30589.391163.901195@basebud.nulle.part>
References: <200510152053.j9FKrtIv000567@gator.dt.uh.edu>
	<17233.30589.391163.901195@basebud.nulle.part>
Message-ID: <Pine.LNX.4.64.0510152251590.31671@ricardo.ecn.wfu.edu>

On Sat, 15 Oct 2005, Dirk Eddelbuettel wrote:

> The closest I know to using x12 and/or tramo-seats from somewhat 
> saner and more modern software is via Allin Cottrell's gretl (cf 
> http://gretl.sf.net). And per my suggestion a few years back, 
> Allin even hacked a 'gretl to R' interface [ via mucking with 
> ~/.Rprofile which isn't pretty but that is another story ... ]

It's a few years since I concentrated on this, but my recollection 
is that the authors of TRAMO/SEATS were willing to grant access to 
the source to me as a developer, but I was not free to redistribute 
the source.  I was, however, able to produce working binaries for 
Linux and win32.

With both TRAMO/SEATS and X-12-ARIMA, it would be nice to be able to 
produce a "librified" version (i.e. code that can be called as a 
library from R or gretl or whatever), but from my point of view the 
binding constraint is that these programs are written in rather 
old-fashioned Fortran.  I tried, briefly, hacking on the T/S code to 
relax the fixed-memory constraint of no more than 600 observations, 
but found I was just breaking stuff so I stopped.

For gretl, I ended up accepting that T/S and X12A would remain as 
stand-along programs.  Gretl takes user input and sets up the 
command lines for these programs (both of which have rather 
byzantine command-line options), then parses the output files and 
feeds the relevant information back home.

If anyone would like to see how I approached this, look at tramo*.c 
in the "plugin" directory of the gretl code base.

http://cvs1.sourceforge.net/viewcvs.py/gretl/gretl/plugin/

Allin Cottrell



From rlist.10.phftt at xoxy.net  Sun Oct 16 05:34:29 2005
From: rlist.10.phftt at xoxy.net (rlist.10.phftt@xoxy.net)
Date: Sat, 15 Oct 2005 23:34:29 -0400
Subject: [R] Animated lissajous
Message-ID: <4351CA45.8020508@yahoo.com>

Here's some code to make lissajous dance.  I've attached a small sample 
GIF.

Cheers,
Rob Steele
robsteele at yahoo dot com



plot.lissajous = function(omega.x, omega.y, delta = 0, num.thetas = 200)
{
   thetas = seq(0, 2 * pi, length = num.thetas)
   xs = sin(omega.x * thetas + delta)
   ys = cos(omega.y * thetas)
   plot(xs, ys, type = 'l', lwd = 3, ann = FALSE, axes = FALSE)
}


## Show one.
par(mar = c(2, 2, 2, 2))
plot.lissajous(4, 3)

## Animate it.
while (TRUE) {
   for (delta in seq(0, 2 * pi, length = 120)) {
       plot.lissajous(4, 3, delta)
       Sys.sleep(1 / 30)
   }
}


## Show a bunch.
par(mar = c(1, 1, 1, 1))
par(mfrow = c(length(omega.xs), length(omega.ys)))
for (omega.x in 1:5) {
   for (omega.y in 1:5) {
       plot.lissajous(omega.x, omega.y, deltas[i])
   }
}

## Animate them.  (Requires ImageMagick.)
num.frames = 120
image.dir = 'images'

if (! file.exists(image.dir)) {
   dir.create(image.dir)
}

deltas = seq(0, 2 * pi, length = num.frames)

for (i in 1 : length(deltas)) {
   png(file = file.path(image.dir, sprintf('img-%03d.png', i)))
   par(mar = c(1, 1, 1, 1))
   par(mfrow = c(length(omega.xs), length(omega.ys)))
   for (omega.x in 1:5) {
       for (omega.y in 1:5) {
           plot.lissajous(omega.x, omega.y, deltas[i])
       }
   }
   dev.off()
}

## This ImageMagick command combines the image files into a GIF animation:
# convert -delay 3 images/*.png images/animation.gif

From rlist.10.phftt at xoxy.net  Sun Oct 16 05:48:46 2005
From: rlist.10.phftt at xoxy.net (rlist.10.phftt@xoxy.net)
Date: Sat, 15 Oct 2005 23:48:46 -0400
Subject: [R] Animated lissajous
Message-ID: <4351CD9E.7090506@yahoo.com>

Oh my goodness how did that bug creep in there.  Ignore that last post 
and try this instead.

Rob Steele
robsteele at yahoo dot com


plot.lissajous = function(omega.x, omega.y, delta = 0, num.thetas = 200)
{
   thetas = seq(0, 2 * pi, length = num.thetas)
   xs = sin(omega.x * thetas + delta)
   ys = cos(omega.y * thetas)
   plot(xs, ys, type = 'l', lwd = 3, ann = FALSE, axes = FALSE)
}


## Show one.
par(mar = c(2, 2, 2, 2))
plot.lissajous(4, 3)

## Animate it.
while (TRUE) {
   for (delta in seq(0, 2 * pi, length = 120)) {
       plot.lissajous(4, 3, delta)
       Sys.sleep(1 / 30)
   }
}


## Show a bunch.
num.frames = 120
omega.xs = 1:5
omega.ys = 1:5
deltas = seq(0, 2 * pi, length = num.frames)

par(mar = c(1, 1, 1, 1))
par(mfrow = c(5, 5))
for (omega.x in omega.xs) {
   for (omega.y in omega.ys) {
       plot.lissajous(omega.x, omega.y)
   }
}

## Animate them.
image.dir = 'images'

if (! file.exists(image.dir)) {
   dir.create(image.dir)
}

for (i in 1 : length(deltas)) {
   png(file = file.path(image.dir, sprintf('img-%03d.png', i)))
   par(mar = c(1, 1, 1, 1))
   par(mfrow = c(length(omega.xs), length(omega.ys)))
   for (omega.x in 1:5) {
       for (omega.y in 1:5) {
           plot.lissajous(omega.x, omega.y, deltas[i])
       }
   }
   dev.off()
}

## This ImageMagick command displays the image files in rapid succession
## to animate them:
# animate -delay 2 images/*.png

## This ImageMagick command combines the image files into a GIF animation:
# convert -delay 3 images/*.png images/animation.gif



From leaflovesun at yahoo.ca  Sun Oct 16 07:29:44 2005
From: leaflovesun at yahoo.ca (Leaf Sun)
Date: Sat, 15 Oct 2005 22:29:44 -0700
Subject: [R] Sorting a data frame by one of the variables
Message-ID: <200510160430.j9G4U76i021168@hypatia.math.ethz.ch>


Dear all,

I have a date frame like this:

X   Y   Z
22	24	4.3
2.3	3.4	5.3
.....
....
57.2	23.4	34

What my purpose is: to sort the data frame by either X, Y or Z.
sample output is (sorted by X) :

X   Y   Z
2.3  3.4  5.3
.....
......
22 24  4.3
...
57.2  23.4  34

I have no idea how to use sort, order or rank functions. Please help me out.
Thanks!

Leaf



From ggrothendieck at gmail.com  Sun Oct 16 06:59:56 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 16 Oct 2005 00:59:56 -0400
Subject: [R] Sorting a data frame by one of the variables
In-Reply-To: <200510160430.j9G4U76i021168@hypatia.math.ethz.ch>
References: <200510160430.j9G4U76i021168@hypatia.math.ethz.ch>
Message-ID: <971536df0510152159j21d4da63o4f238371d7a0f215@mail.gmail.com>

Try

RSiteSearch("sort data.frame")
?order
RSiteSearch("sort.data.frame")


On 10/16/05, Leaf Sun <leaflovesun at yahoo.ca> wrote:
>
> Dear all,
>
> I have a date frame like this:
>
> X   Y   Z
> 22      24      4.3
> 2.3     3.4     5.3
> .....
> ....
> 57.2    23.4    34
>
> What my purpose is: to sort the data frame by either X, Y or Z.
> sample output is (sorted by X) :
>
> X   Y   Z
> 2.3  3.4  5.3
> .....
> ......
> 22 24  4.3
> ...
> 57.2  23.4  34
>
> I have no idea how to use sort, order or rank functions. Please help me out.
> Thanks!
>
> Leaf
>
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>



From 042045003 at fudan.edu.cn  Sun Oct 16 08:38:59 2005
From: 042045003 at fudan.edu.cn (ronggui)
Date: Sun, 16 Oct 2005 14:38:59 +0800
Subject: [R] Sorting a data frame by one of the variables
Message-ID: <0IOF00E2FWNEAH@mail.fudan.edu.cn>


FAQ 7.23 How can I sort the rows of a data frame?

To sort the rows within a data frame, with respect to the values in one or more of the columns, simply use order(). 

	

======= 2005-10-16 13:29:44 ÄúÔÚÀ´ÐÅÖÐÐ´µÀ£º=======

>
>Dear all,
>
>I have a date frame like this:
>
>X   Y   Z
>22	24	4.3
>2.3	3.4	5.3
>.....
>....
>57.2	23.4	34
>
>What my purpose is: to sort the data frame by either X, Y or Z.
>sample output is (sorted by X) :
>
>X   Y   Z
>2.3  3.4  5.3
>.....
>......
>22 24  4.3
>...
>57.2  23.4  34
>
>I have no idea how to use sort, order or rank functions. Please help me out.
>Thanks!
>
>Leaf
>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

= = = = = = = = = = = = = = = = = = = =
			


 

2005-10-16

------
Deparment of Sociology
Fudan University

My new mail addres is ronggui.huang at gmail.com
Blog:http://sociology.yculblog.com



From p.dalgaard at biostat.ku.dk  Sun Oct 16 09:23:07 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 16 Oct 2005 09:23:07 +0200
Subject: [R] solve() versus ginv()
In-Reply-To: <20051015220226.44205.qmail@web61225.mail.yahoo.com>
References: <20051015220226.44205.qmail@web61225.mail.yahoo.com>
Message-ID: <x23bn2j57o.fsf@turmalin.kubism.ku.dk>

Werner Bier <aliscla at yahoo.com> writes:

> Dear All,
>  
> While inverting a matrix the following error appears on my console:
>  
> Error in solve.default(my_matrix) : Lapack routine dgesv: system is exactly singular
>  
> With this respect, I have been replacing the solve() function with ginv(): the Moore-Penrose generalized inverse of a matrix. 
>  
> These are the questions I would like to ask you:
>  
> 1. Would you also replace solve() with ginv() in these scenarios and using R? 
> 2. Or is there something I should take care by using ginv() you would suggest me please? 

Well, generalized inverses work by setting 1/0 == 0, broadly speaking.
If the system has a zero eigenvalue, the r.h.s. is projected onto the
span of the matrix. (In the symmetric, positive semidefinite case,
anyway).

In statistical terms, this means that there is a direction along which
you have no information on your parameters (infinite s.e.), and the
g.inv. solves this by assuming that the effect in that direction is
zero (with zero s.e.!). This can be a sensible thing to do, but I
wouldn't be happy about having the choice made for me automatically...

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ligges at statistik.uni-dortmund.de  Sun Oct 16 12:04:36 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 16 Oct 2005 12:04:36 +0200
Subject: [R] Your order (#gzmgss-R-help) Is somebody's machine infected
 to zombie this trash??
In-Reply-To: <43514BF8.8060301@ncf.ca>
References: <3810033794.4361150301@hypatia.math.ethz.ch>
	<43514BF8.8060301@ncf.ca>
Message-ID: <435225B4.5000002@statistik.uni-dortmund.de>

Brian Lunergan wrote:
> Dennis Ewing wrote:
> 
>>   Ciialis  Softt  Tabss  actts up to 36 houurs! Simplyy disollve halff a
>>   tablet underr youur tonngue 15 minuutes beforee s.ex.
>>
>>       Alll orderrs willl be processed and dispatched withiin 24hrs.
>>                         100 pills - 1.98 per 10m.g
>>                              [1]Reaad more! 
>>                         look out theese cheap tabs
>>
>>    I believe in only one thing: liberty but I do not believe in liberty
>>                  enough to want to force it upon anyone.
>>
>>References
>>
>>   1. http://uk.geocities.com/Salli32002Christina48517/
> 
> 
> I've marked this as junk in Thunderbird. Is somebody's machine infected
> to zombie this internet trash to the list??
> 

Please don't waste even more bandwidth in discussions on spam!!!
(why do you blame the R-help subscribers?)
Please read the posting guide!

The follwing must be said in this context (and is not a waste of bandwidth):

Many thanks to Martin Maechler for managing this list (as well as the 
others!) in such a perfect manner and keeping it almost free of spam!

Uwe Ligges



From reilly at stat.auckland.ac.nz  Sun Oct 16 12:13:51 2005
From: reilly at stat.auckland.ac.nz (James Reilly)
Date: Sun, 16 Oct 2005 23:13:51 +1300
Subject: [R] enter a survey design in survey2.9
In-Reply-To: <20051009201541.38902.qmail@web25702.mail.ukl.yahoo.com>
References: <20051009201541.38902.qmail@web25702.mail.ukl.yahoo.com>
Message-ID: <435227DF.1020609@stat.auckland.ac.nz>


svydesign needs to be told what data frame to use, via the data= argument.

I get a slightly different error message from you:
Error in eval(expr, envir, enclos) : object "subdiv" not found
but this may be because I'm using survey version 3.3.1, not 2.9. There
are several new features (listed at
http://faculty.washington.edu/tlumley/survey/NEWS) so you may want to
upgrade.


On 10/10/2005 9:15 a.m., justin bem wrote:
> Hi dears,
>  
> I expect that Mr Thomas Lumley will read this message.
> I have data from a complexe stratified survey. The population is divide in 12 regions and a region consist to and urban area and rural one. there to region just with urbain area.
>  
> stratification variable is a combinaison of region and area type (urban/rural)
>  
> In rural area, subdivision are sample with probabilties proporionnal to size in population then enuration area are sample in selected division and finally households are selected in those EA.
>  
> In urban area, EA are directly selected and finally household are selected.
> to schematise we have:
>  
> (12 regions)
>      each region is divised in two regions / Urbain and rural. this are strata
>            in Rural : PSU are subdivision , SSU are EA and TSU are households
>            in Urban : PSU are EA , SSU are households.
>  
> I use svydesign function as follow :
> esi<-svydesign(id=~subdiv+EA+HHID,strata=~REGION+AREATYP,fpc=~FPC1+FPC2FPC3,weig=~pw,nest=T)
> FPC1: number of subdivision in each strata
> FPC2: number of EA in each subdivision
> FPC3: number of HH in each EA.
> pw : sampling weights
>  
> but I have this error message : erron in data.frame(strata, 1:i,...) I dont understand why !
> Can someone help me ?
>  
> Sincerly.
>  
>                                                              
>  
>  
> 
> 		
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
James Reilly
Department of Statistics, University of Auckland
Private Bag 92019, Auckland, New Zealand



From HStevens at muohio.edu  Sun Oct 16 13:32:50 2005
From: HStevens at muohio.edu (Hank Stevens)
Date: Sun, 16 Oct 2005 07:32:50 -0400
Subject: [R] How to get to the varable in a list
In-Reply-To: <433DB8BF.3E0E22C7@uhnres.utoronto.ca>
References: <433DB8BF.3E0E22C7@uhnres.utoronto.ca>
Message-ID: <43523A62.2030607@muohio.edu>

Hi Lisa,
Try the following -- there are probably better solutions, but these seem 
to work.
Hank Stevens
Miami University
Oxford, OH, USA

a <- vector("list",3)
names(a) <- 1:3
a[[1]] <- data.frame(x1=3,x2=1)
a[[2]] <- data.frame(x1=c(3,3),x2=c(2,2))

a[[3]] <- data.frame(x1=c(3,3), x2=c(3,3))
a

unlist(sapply(a, function(x) x$x1 ))
unlist(sapply(a, function(x) x[,1] ))

Lisa Wang wrote:

>Hello,
>
>I have a list "lis" as the following:
>
>$"1"
>  x1 x2
>4  3  1
>
>$"2"
>  x1 x2
>3  3  2
>5  3  2
>
>$"3"
>  x1 x2
>2  3  3
>6  3  3
>
>How do I get the x1 varible?  for example ss"1"
>
>  
>
>------------------------------------------------------------------------
>
>This e-mail may contain confidential and/or privileged information for the sole use of the intended recipient. Any review or distribution by anyone other than the person for whom it was originally intended is strictly prohibited. If you have received this e-mail in error, please contact the sender and delete all copies. Opinions, conclusions or other information contained in this e-mail may not be that of the organization.
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From jiesheng at bioteam.net  Sun Oct 16 13:56:15 2005
From: jiesheng at bioteam.net (jiesheng zhang)
Date: Sun, 16 Oct 2005 19:56:15 +0800
Subject: [R] write R extenesion issue
In-Reply-To: <43513679.5020406@stats.uwo.ca>
References: <4351203C.5090506@bioteam.net> <43512408.20203@bioteam.net>
	<43512704.1060108@bioteam.net> <43513679.5020406@stats.uwo.ca>
Message-ID: <43523FDF.7050706@bioteam.net>

Hi, duncan
I remove the built and packaged line from DESCRIPTION and install from 
source. It worked right now

Thanks
-jason

Duncan Murdoch wrote:
> jiesheng zhang wrote:
>> I found my attachment was discarded.
>> My R package structure lis listed here
>> -----------------------------
>> btRRTest
>>     DESCRIPTION
>>         Package: btRRTest
>>         Version: 0.0.1
>>         Date: 2005-10-15
>>         Title: a test remote R exeuction
>>         Author: jiesheng at bioteam.net
>>         Maintainer: jason zhang<jiesheng at bioteam.net>
>>         Depends: R (>= 1.8.0)
>>         Description: the remote execution of R call
>>         License: GPL version 2
>>         URL: http://www.bioteam.net
>>         Built: R 2.1.1; i686-pc-linux-gnu; 2005-09-20 00:07:19; unix
>>         Packaged: Sat Oct 15 23:42:11 2005; root
> 
> Is this from your source directory?  You shouldn't have the Built and 
> Packaged lines in your source.
> 
> If this is from the directory where it was installed, never mind, unless 
> those two directories are the same:  in which case the advice is "don't 
> do that".  Keep your installed copies separate from the source.
> 
> The error message you saw
> 
>> Error in library("btRRTest") : 'btRRTest' is not a valid package -- 
>> installed < 2.0.0?
> 
> indicates that the "Meta/package.rds" file is missing from your 
> installed package subdirectory, but it's hard to guess why.
> 
> Duncan Murdoch
>



From jiesheng at bioteam.net  Sun Oct 16 14:18:43 2005
From: jiesheng at bioteam.net (jiesheng zhang)
Date: Sun, 16 Oct 2005 20:18:43 +0800
Subject: [R] where is Defn.h and implementation
In-Reply-To: <43523FDF.7050706@bioteam.net>
References: <4351203C.5090506@bioteam.net>
	<43512408.20203@bioteam.net>	<43512704.1060108@bioteam.net>
	<43513679.5020406@stats.uwo.ca> <43523FDF.7050706@bioteam.net>
Message-ID: <43524523.8030503@bioteam.net>

Hi, all

I am in the process of writing my first R extesion package.

One of my function uses StrToInternal function(I copy it from other 
extension package). I noticed the StrToInternal was defined in "Defn.h". 
I have two questions:
1)should "Defn.h"  be under $R_HOME/include. I could not find it in any 
file under $R_HOME/include.
2)Where is the implementation for the functions defined in the "Defn.h"? 
Where dynamic library should I link to for the StrToInternal implementation?

When I load my extension and library, I got this error
-------------------------------
 > library("btRRTest")
Error in dyn.load(x, as.logical(local), as.logical(now)) :
         unable to load shared library 
'/common/apps/lib/R/library/btRRTest/libs/btRRTest.so':
   /common/apps/lib/R/library/btRRTest/libs/btRRTest.so: undefined 
symbol: StrToInternal
Error in library("btRRTest") : .First.lib failed for 'btRRTest'
--------------------------------

My package is compiled during installation like this
--------------------------------
jasonportal:/home/jason/tmp2 # R CMD INSTALL btRRTest
* Installing *source* package 'btRRTest' ...
** libs
gcc -I/common/apps/lib/R/include  -I/usr/local/include   -fPIC  -g -O2 
-c btRRtest.c -o btRRtest.o
gcc -I/common/apps/lib/R/include  -I/usr/local/include   -fPIC  -g -O2 
-c client.c -o client.o
gcc -I/common/apps/lib/R/include  -I/usr/local/include   -fPIC  -g -O2 
-c pack.c -o pack.o
gcc -I/common/apps/lib/R/include  -I/usr/local/include   -fPIC  -g -O2 
-c rpack.c -o rpack.o
rpack.c: In function `my_remove':
rpack.c:23: warning: assignment makes pointer from integer without a cast
rpack.c: In function `CreateDataPacket':
rpack.c:156: warning: assignment makes pointer from integer without a cast
rpack.c: In function `convertDataPacketToVariable':
rpack.c:229: warning: assignment makes pointer from integer without a cast
rpack.c: In function `setDataPacketToEnv':
rpack.c:256: warning: assignment makes pointer from integer without a cast
gcc -I/common/apps/lib/R/include  -I/usr/local/include   -fPIC  -g -O2 
-c util.c -o util.o
gcc -I/common/apps/lib/R/include  -I/usr/local/include   -fPIC  -g -O2 
-c worker.c -o worker.o
gcc -shared -L/usr/local/lib -o btRRTest.so btRRtest.o client.o pack.o 
rpack.o util.o worker.o
** R
No man pages found in package 'btRRTest'
** building package indices ...
* DONE (btRRTest)
--------------------------------

Help is appreciated.

-jason



From iaingallagher at btopenworld.com  Sun Oct 16 14:33:53 2005
From: iaingallagher at btopenworld.com (Iain Gallagher)
Date: Sun, 16 Oct 2005 13:33:53 +0100
Subject: [R] asking the user for data
Message-ID: <435248B1.5060604@btopenworld.com>

Hello everyone.

How do I get R to ask users for data to be entered? Specifically I want 
to ask for a z score to be entered (the user would look this up in a 
table) and then use the entered data to compute a Dunn's post-hoc test 
(post kruskal.test).

I've tried the "ask" function but it's not recognised - maybe I don't 
have to appropriate libary installed. A pointer to the right one would 
be appreciated.

e.g  >z <-ask(message="Please enter the z value for" x)

Any help would be gratefully received.

Thanks

Iain Gallagher
Institiute for Infection and Immunology Research
Edinburgh University



From jfox at mcmaster.ca  Sun Oct 16 14:56:53 2005
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 16 Oct 2005 08:56:53 -0400
Subject: [R] asking the user for data
In-Reply-To: <435248B1.5060604@btopenworld.com>
Message-ID: <20051016125652.ZCRU26967.tomts5-srv.bellnexxia.net@JohnDesktop8300>

Dear Iain,

There's an ask() function in the sm package that does what you want, but
you'll have to compose your message properly: ask(paste("Please enter the z
value for", x))

Alternatively, eval(parse(text=readline(paste("Please enter the z value for
", x, ": ", sep="")))) will do what you want, as would
as.numeric(readline(paste("Please enter the z value for ", x, ": ",
sep=""))).

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Iain Gallagher
> Sent: Sunday, October 16, 2005 7:34 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] asking the user for data
> 
> Hello everyone.
> 
> How do I get R to ask users for data to be entered? 
> Specifically I want to ask for a z score to be entered (the 
> user would look this up in a
> table) and then use the entered data to compute a Dunn's 
> post-hoc test (post kruskal.test).
> 
> I've tried the "ask" function but it's not recognised - maybe 
> I don't have to appropriate libary installed. A pointer to 
> the right one would be appreciated.
> 
> e.g  >z <-ask(message="Please enter the z value for" x)
> 
> Any help would be gratefully received.
> 
> Thanks
> 
> Iain Gallagher
> Institiute for Infection and Immunology Research Edinburgh University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ccleland at optonline.net  Sun Oct 16 15:06:08 2005
From: ccleland at optonline.net (Chuck Cleland)
Date: Sun, 16 Oct 2005 09:06:08 -0400
Subject: [R] asking the user for data
In-Reply-To: <435248B1.5060604@btopenworld.com>
References: <435248B1.5060604@btopenworld.com>
Message-ID: <43525040.6020503@optonline.net>

library(sm)
 > z <- ask(message="Please enter the z value for")
Please enter the z value for: 1.96
 > z
[1] 1.96

   I found this using RSiteSearch("ask", restrict="functions") .

Iain Gallagher wrote:
> Hello everyone.
> 
> How do I get R to ask users for data to be entered? Specifically I want 
> to ask for a z score to be entered (the user would look this up in a 
> table) and then use the entered data to compute a Dunn's post-hoc test 
> (post kruskal.test).
> 
> I've tried the "ask" function but it's not recognised - maybe I don't 
> have to appropriate libary installed. A pointer to the right one would 
> be appreciated.
> 
> e.g  >z <-ask(message="Please enter the z value for" x)
> 
> Any help would be gratefully received.
> 
> Thanks
> 
> Iain Gallagher
> Institiute for Infection and Immunology Research
> Edinburgh University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From ggrothendieck at gmail.com  Sun Oct 16 15:13:06 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 16 Oct 2005 09:13:06 -0400
Subject: [R] asking the user for data
In-Reply-To: <435248B1.5060604@btopenworld.com>
References: <435248B1.5060604@btopenworld.com>
Message-ID: <971536df0510160613n41752256qaad6a1d8269d0f21@mail.gmail.com>

Use readline for a text dialog or use tkentry from the tcltk package
as shown in the Edit Box example at:
   http://bioinf.wehi.edu.au/~wettenhall/RTclTkExamples/

On Windows other possibilities exist as well: winDialogString
and in package svDialog there is guiDlg .

Also check out qnorm .

On 10/16/05, Iain Gallagher <iaingallagher at btopenworld.com> wrote:
> Hello everyone.
>
> How do I get R to ask users for data to be entered? Specifically I want
> to ask for a z score to be entered (the user would look this up in a
> table) and then use the entered data to compute a Dunn's post-hoc test
> (post kruskal.test).
>
> I've tried the "ask" function but it's not recognised - maybe I don't
> have to appropriate libary installed. A pointer to the right one would
> be appreciated.
>
> e.g  >z <-ask(message="Please enter the z value for" x)
>
> Any help would be gratefully received.
>
> Thanks
>
> Iain Gallagher
> Institiute for Infection and Immunology Research
> Edinburgh University
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From wilks at dial.pipex.com  Sun Oct 16 15:54:03 2005
From: wilks at dial.pipex.com (John Wilkinson (pipex))
Date: Sun, 16 Oct 2005 14:54:03 +0100
Subject: [R] Sorting a data frame by one of the variables
Message-ID: <JCEIJNOHMNBPLMGFDHNDOEBMCBAA.wilks@dial.pipex.com>

Leaf,

using your example data as 'dat' below --

 dat<-read.table("clipboard",header=T)
 dat
     X    Y    Z
1 22.0 24.0  4.3
2  2.3  3.4  5.3
3 57.2 23.4 34.0

#to order the data frame by say X (for column 1)--

dat1<-dat[order(dat[,1]),]
 dat1
     X    Y    Z
2  2.3  3.4  5.3
1 22.0 24.0  4.3
3 57.2 23.4 34.0

--------------------------------------------
By way of interest if you wanted to order EVERY  column
in ascending order then you could do a loop ---

# to order  all cols of dat by rows (ascending)

dat2<-dat
 for (i in 1:3) dat2[,i]<-dat[order(dat[,i]),i]
 dat2
     X    Y    Z
1  2.3  3.4  4.3
2 22.0 23.4  5.3
3 57.2 24.0 34.0
------------------------------------------------

I hope that helps,

John


=====================================================
"Leaf Sun" wrote---

Dear all,

I have a date frame like this:

X   Y   Z
22	24	4.3
2.3	3.4	5.3
.....
....
57.2	23.4	34

What my purpose is: to sort the data frame by either X, Y or Z.
sample output is (sorted by X) :

X   Y   Z
2.3  3.4  5.3
.....
......
22 24  4.3
...
57.2  23.4  34

I have no idea how to use sort, order or rank functions. Please help me out.
Thanks!



From ripley at stats.ox.ac.uk  Sun Oct 16 16:13:34 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 16 Oct 2005 15:13:34 +0100 (BST)
Subject: [R] where is Defn.h and implementation
In-Reply-To: <43524523.8030503@bioteam.net>
References: <4351203C.5090506@bioteam.net> <43512408.20203@bioteam.net>
	<43512704.1060108@bioteam.net> <43513679.5020406@stats.uwo.ca>
	<43523FDF.7050706@bioteam.net> <43524523.8030503@bioteam.net>
Message-ID: <Pine.LNX.4.61.0510161500050.27435@gannet.stats>

On Sun, 16 Oct 2005, jiesheng zhang wrote:

> I am in the process of writing my first R extesion package.

Have you read our posting guide?  Please ask C programming questions on 
the apppropriate list -- R-devel.

Have you read `Writing R Extensions'?  It does cover this topic with 
copious warnings against what you are asking to do.

> One of my function uses StrToInternal function(I copy it from other
> extension package).

Which package is that?  Please avoid copying from packages which use
internal headers (and they probably do not work).

> I noticed the StrToInternal was defined in "Defn.h".
> I have two questions:
> 1)should "Defn.h"  be under $R_HOME/include. I could not find it in any
> file under $R_HOME/include.

No.  It is an internal header.  You could have read the Makefiles to see 
that it is not an exported header.

> 2)Where is the implementation for the functions defined in the "Defn.h"?

Almost always in src/main/*.c.

> Where dynamic library should I link to for the StrToInternal implementation?

None, you should not be calling functions not documented in `Writing R 
Extensions', and you certainly should not be asking for technical support 
to do so.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From spencer.graves at pdf.com  Sun Oct 16 18:44:24 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 16 Oct 2005 09:44:24 -0700
Subject: [R] TRAMO-SEATS confusion?
In-Reply-To: <Pine.LNX.4.64.0510152251590.31671@ricardo.ecn.wfu.edu>
References: <200510152053.j9FKrtIv000567@gator.dt.uh.edu>	<17233.30589.391163.901195@basebud.nulle.part>
	<Pine.LNX.4.64.0510152251590.31671@ricardo.ecn.wfu.edu>
Message-ID: <43528368.1050705@pdf.com>

LICENSING AND OWNERSHIP

	  CRAN wants the source code for any contributed package, both for 
security reasons (protection against viruses) and for consistency wiht 
the GNU license, which requires distributors of software using GNU 
software to extend the GNU restrictions to their derivative software. 
I'm not an attorney, but it is my understanding that anyone contribiting 
a package to interface with TRAMO-SEATS would have to submit their 
source code, but not that for TRAMO-SEATS.  The user would be required 
to install separately TRAMO-SEATS.

WOULD ANYONE BE INTERESTED IN AN R DISTRIBUTION?

       I don't know this software, but time series analysis is an 
important topic, and I'd be shocked if no one else would be interested. 
  An interface would make it easier for (a) users of TRAMO-SEATS to 
migrate into R and (b) R users to explore the capabilities of TRAMO-SEATS.

       spencer graves
p.s.  Sundar Dorai-Raj and I are planning to develop a package to 
accompany Ruey Tsay (2005) Analysis of Financial Time Series, 2nd ed. 
(Wiley).  As part of this effort, we plan to invite people to send us R 
code for how they would reproduce various analyses in that book. 
Submissions would become part of the "FinTS" package, and might further 
contribute to comparisons of alternative R packages for time series.

Allin Cottrell wrote:
> On Sat, 15 Oct 2005, Dirk Eddelbuettel wrote:
> 
> 
>>The closest I know to using x12 and/or tramo-seats from somewhat 
>>saner and more modern software is via Allin Cottrell's gretl (cf 
>>http://gretl.sf.net). And per my suggestion a few years back, 
>>Allin even hacked a 'gretl to R' interface [ via mucking with 
>>~/.Rprofile which isn't pretty but that is another story ... ]
> 
> 
> It's a few years since I concentrated on this, but my recollection 
> is that the authors of TRAMO/SEATS were willing to grant access to 
> the source to me as a developer, but I was not free to redistribute 
> the source.  I was, however, able to produce working binaries for 
> Linux and win32.
> 
> With both TRAMO/SEATS and X-12-ARIMA, it would be nice to be able to 
> produce a "librified" version (i.e. code that can be called as a 
> library from R or gretl or whatever), but from my point of view the 
> binding constraint is that these programs are written in rather 
> old-fashioned Fortran.  I tried, briefly, hacking on the T/S code to 
> relax the fixed-memory constraint of no more than 600 observations, 
> but found I was just breaking stuff so I stopped.
> 
> For gretl, I ended up accepting that T/S and X12A would remain as 
> stand-along programs.  Gretl takes user input and sets up the 
> command lines for these programs (both of which have rather 
> byzantine command-line options), then parses the output files and 
> feeds the relevant information back home.
> 
> If anyone would like to see how I approached this, look at tramo*.c 
> in the "plugin" directory of the gretl code base.
> 
> http://cvs1.sourceforge.net/viewcvs.py/gretl/gretl/plugin/
> 
> Allin Cottrell
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From otter at otter-rsch.com  Sun Oct 16 19:20:40 2005
From: otter at otter-rsch.com (dave fournier)
Date: Sun, 16 Oct 2005 10:20:40 -0700
Subject: [R]  TRAMO-SEATS confusion?
Message-ID: <43528BE8.8060601@otter-rsch.com>

Hi,

For what its worth I had to hack some horrendous old
FORTRAN which I could not come close to understanding.
The main issue was to allow dynmically allocated arrays.
What I did was to run it through f2c to produce C++
code. Then I verified that it still worked. After that I replaced
the pointers with a vector class with optional bounds checking with an 
overloaded [] operator so that all the old code would still compile.
Then I just checked out all the bounds violations until everything
worked and I was done.

     Dave

-- 
David A. Fournier
P.O. Box 2040,
Sidney, B.C. V8l 3s3
Canada
http://otter-rsch.com


--



From robertlesliedv at portercapital.com  Sun Oct 16 19:31:31 2005
From: robertlesliedv at portercapital.com (Robert Leslie)
Date: Sun, 16 Oct 2005 17:31:31 +0000
Subject: [R] Climb Aboard the Small Cap Gravy Train
Message-ID: <AKBOKHECKGGLNJNPPBPLLIABNLAB.robertlesliedv@portercapital.com>

Newsletter - October Issue, 2005 


In October's issue we are going to profile a 
company involved in the Red Hot homeland 
security sector, also recently entering the 
 Oil/Energy Industry! This company's st0ck is very 
much undervalued considering the potential of the 
industry and the position of the company. 
(The perfect time to get in) 


This small treasure is: VNBL (Vinoble, Inc.) 


The st0ck is trading at only O.O7 - O.09 cents and 
we expect it could hit $0.25 - $0.30 by early 
November. 


Huge PR campaign expected this week so grab as 
much as you can up to $0.20 range.  We all know 
it's the big announcements that make these small 
gems move. 

===================================================
Company: VNBL (Vinoble, Inc.) 

St0ck Symbol: VNBL . OB 

Current Price: $O.O7


We expect the price to go to $O.12 in next 2-3 days 
We expect the price to go to $O.25 in next 3 weeks. 
====================================================

About the company: 


Vinoble, Inc. is a holding company, which is 
identifying and acquiring operational business 
opportunities in the areas of homeland security, 
security information systems, and other security 
services to provide long term growth for its 
shareholders.  Vinoble believes that the opportunity 
to build a successful business in the security sector 
is unprecedented. 


The terror attacks on the United States on 
September 11, 20O1 have changed the security 
landscape for the foreseeable future. Both physical 
and logical security have become paramount for all 
industry segments, especially in the banking, 
healthcare and government sectors. While the focus 
for Vinoble is on North America, the opportunity 
for security services is worldwide. According to 
Giga, a wholly owned subsidiary of Forrester 
Research, worldwide demand for information 
security products and services is set to eclipse $46B 
by 2O05. 


Vinoble intends to capitalize on the dramatic 
growth in the security market by delivering 
professional services, security products, security 
training, and managed security services. In pursuit 
of this objective, Vinoble has assembled a highly 
qualified team of security professionals offering a 
full range of security services. Through Vinoble's 
consulting services and integrated delivery 
solutions, Vinoble will help organizations protect 
key assets including persons, property, information, 
brand, and reputation. 


Why we believe VNBL will give big returns on 
investment: 


* At this time much of VNBL's focus is on RFID 
(Radio frequency identification) technology.  This 
is technology which uses tiny sensors to transmit 
information about a person or object wirelessly. 


* VNBL is developing a form of RFID technology 
which allows companies and governments to 
wirelessly track their assets and resources.  Such 
technology has HUGE potential in the protection 
and transportation of materials designated "High 
Risk" were they to fall into the wrong hands. 


* VNBL works on integration of the two afore 
mentioned systems in order to create "High Security 
Space" in locales where it is deemed necessary. 
Locations which may take advantage of such 
systems are airports, sea ports, mines, nuclear 
facilities, and more. 


***N E W S*** 


Vinoble to Enter the Oil and Gas Sector 


MALIBU, Calif.--(BUSINESS WIRE)--Sept. 6, 2005-- 
Vinoble, Inc. (OTCBB:VNBL - News), a holding company 
seeking to identify long-term growth opportunities in 
the areas of homeland security, security information 
systems, and other security services is pleased to 
announce the Company's management is in the final 
evaluation and negotiation on a highly prospective 
oil and gas project which is expected to be completed 
in the near future. 


Vinoble announced its intent to 
offer products and services that will assist in the 
automation of the identification and control of 
equipment, assets, tools, and the related processes 
used in the Oil Gas and Petrochemical industries. 


As with other RF based technology applications, RFID 
can also provide the safe transit of materials by 
only the authorized handler, and limit the entry of 
personnel to specific locations. Ensuring personnel 
safety is essential, should there be an emergency at 
a facility, RFID tags would enable the customer to 
track and evaluate its employee's safety and/or 
danger. This application technology requires product 
and hardware that can operate in harsh and 
potentially hazardous conditions while giving 
valuable safety to the resources and assets that are 
vital to the customer. RFID can also assist the 
customer's supply chain by tracking oil, gas, and 
chemical products from extraction to refining to the 
sale at the retail level. 


We believe that this is great news for VNBL.  Just at 
the time when more domestic oil operations are 
starting up, VNBL comes in with a great product. 


Go VNBL!!! 


Go read all the newest PRs on this exciting company! 
This is one to watch Monday and Especially Tuesday! 
Put it on your Radar Screen Now! 
Please watch this one trade all week! 


_________________________________________ 


Information within this email contains "f0rward 
lo0king st4tements" within the meaning of Section 
27A of the Securities Act of 1933 and Section 21B 
of the Securities Exchange Act of 1934. Any 
statements that express or involve discussions with 
respect to predictions, goals, expectations, beliefs, 
plans, projections, objectives,assumptions or future 
events or performance are notstatements of historical 
fact and may be "f0rwardlo0king st4tements." f0rward 
lo0king st4tements are based on expectations, 
estimates and projections at the time 
the statements are made that involve a number of 
risks and uncertainties which could cause actual 
results or events to differ materially from those 
presently anticipated. f0rwardlo0king st4tements 
in this action may be identified through the use of 
words such as:"projects", "foresee", "expects", 
"estimates," "believes," "understands" "will," "part of: 
"anticipates," or that by statements indicating 
certain actions "may," "could," or "might" occur. 
All information provided within this email 
pertaining to invest1ng, st0c.ks, securities must be 
understood as information provided and not 
investment advice.Emerging Equity Alert advises all 
readers and subscribers to seek advice from a 
registered professional securities representative before 
deciding to trade in st0c.ks featured within this 
email. None of the material within this report shall 
be construed as any kind of investment advice. 
Please have in mind that the interpretation of the 
writer of this newsletter about the news published 
by the company does not represent the company 
official statement and in fact may differ from the 
real meaning of what the news release meant to say. 
Look at the news release by yourself and judge by 
yourself about the details in it.



From spencer.graves at pdf.com  Sun Oct 16 20:59:39 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 16 Oct 2005 11:59:39 -0700
Subject: [R] repeated measures with random effects
In-Reply-To: <a17009720510041338n367be9fbi@mail.gmail.com>
References: <a17009720510041338n367be9fbi@mail.gmail.com>
Message-ID: <4352A31B.4010409@pdf.com>

	  Have you tried 'RSiteSearch("repeated measures with random 
effects")'?  I just got 74 hits, some of which might interest you.

	  Also, have you reviewed Pinheiro and Bates (2000) Mixed-Effects 
Models in S and S-Plus (Springer)?  This book, the lme function in 
library(nlme) and the more recent lmer and lme4 / Matrix packages, are 
to my knowledge the state of the art in this area.

	  In addition, have you read the posting guide 
(www.R-project.org/posting-guide.html)?  People who follow that guide, I 
believe, tend to get quicker, more useful replies.  In particular, I've 
looked at your post several times since it appeared and each time 
decided not to reply, because I didn't have the time I thought it would 
take to offer a useful reply.  If you had included more complete example 
that I could have copied into R and tried -- possibly with alternatives 
-- in less than, say, 40 seconds, I might have more useful comments for 
you and might have replied sooner.

	  spencer graves

juli g. pausas wrote:
> Dear all,
> I'm interested in analysing a reapeated measure desing where plant
> height (H) was measured 3 times (Time). The experimental design
> include 2 fixed factor (say A and B) in which A is nested in B, and a
> random factor (C, the plot), using the aov().
> 
> So my first idea would be something like:
> 
> aov(H ~ B * A %in% B * Time + Error(id) )
> 
> where id is the factor coded for the repeated subjects.
> But my question is how to include the random factor C ?
> 
> Any help would be appreciated. Thanks
> 
> Juli
> 
> 
> --
> Juli G. Pausas
> CEAM & UA
> http://www.ceam.es/lass/pausas.htm
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From p.murrell at auckland.ac.nz  Sun Oct 16 22:01:49 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Mon, 17 Oct 2005 09:01:49 +1300
Subject: [R] grid.edit problem
References: <971536df0510150928s2a8a6935k33470e74d169f832@mail.gmail.com>
Message-ID: <4352B1AD.8020103@stat.auckland.ac.nz>

Hi


Gabor Grothendieck wrote:
> I am having a problem in editing a grob.  It works ok if I try to
> shift the grob using npc coordinates but if I do the same thing
> using native coordinates the grob disappears.  What is wrong?
> 
> 
> library(grid)
> grid.newpage()
> 
> # create viewport
> pushViewport(viewport(xscale = c(100,200), name = "X"))
> 
> # draw vertical line
> grid.lines(150, 0:1, default.units = "native",  name = "L")
> 
> # move line 25% of the way to the right. Works ok.
> grid.edit("L", x = grid.get("L")$x + unit(0.25, "npc"))
> 
> 
> # but now repeat it shifting it using native coordinates
> ########################################################
> 
> # remove line and draw a new line where the original one was
> grid.remove("L")
> grid.lines(150, 0:1, default.units = "native",  name = "L")
> 
> # move line 25% of the way to the right but use native coordiantes
> #### line disappears !!!!!!!!!
> grid.edit("L", x = grid.get("L")$x + unit(25, "native"))


This is due to the fact that the *location* unit(25, "native") is very 
different from the *location* unit(.25, "npc").   In your example, the 
former actually corresponds to unit(-.75, "npc").

What you appear to be trying to do is add a *dimension* (width) unit(25, 
"native"), which corresponds to a *dimension* unit(.25, "npc"), to the 
original *location* unit(150, "native").  Problem is, the 'x' component 
of a  "line" is interpreted as a location so your unit(25, "native") is 
interpreted as a location.

This issue is described in one of the small grid doc's at 
http://www.stat.auckland.ac.nz/~paul/grid/doc/locndimn.pdf

A (rather verbose) way of specifying your goal is the following ...

grid.edit("L", x = grid.get("L")$x +
                    # Convert a width into a location
                    convertUnit(unit(25, "native"), "native",
                                "x", "dimension", "x", "location"))

... or, if you know you are only dealing with "native" (data) values, 
you could add them together before using them to specify a location ...

x <- 150 + 25
grid.edit("L", x = unit(x, "native"))

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From dvumani at hotmail.com  Fri Oct  7 14:59:34 2005
From: dvumani at hotmail.com (Vumani Dlamini)
Date: Fri, 07 Oct 2005 12:59:34 +0000
Subject: [R] finding roots of a polynomial
Message-ID: <BAY110-F16E77EC71A2A93401F9FD5A3840@phx.gbl>

Dear listers,
I am trying to find the root of a polynomial of the form,
       a+bx+cx^2+dx^3+ex^5+...=0
where a,b,c,d,e are known.
I have looked at "quadprog" without any success.
Regards, Vumani



From r4stat at gmail.com  Sun Oct  9 23:56:04 2005
From: r4stat at gmail.com (Steven T.)
Date: Sun, 9 Oct 2005 17:56:04 -0400
Subject: [R] boxplot: how to display x-labels vertically
Message-ID: <58ae3dc70510091456m2c761b44l283e4544d98e3ae6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051009/fa2e20e2/attachment.pl

From spencer.graves at pdf.com  Mon Oct 10 03:09:31 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 09 Oct 2005 18:09:31 -0700
Subject: [R] plot.augPred sorted and labelled according second factor
In-Reply-To: <5677.1128013471@www21.gmx.net>
References: <5677.1128013471@www21.gmx.net>
Message-ID: <4349BF4B.2040006@pdf.com>

Hi, Christoph:

	  Have you received a satisfactory reply to this?  If no, you might 
wish to consider the following;  with a few more hours, I could probably 
produce what you seem to be asking.  If you try something further, 
please ping the authors and maintainers for augPred and xyplot (whom I 
have cc'ed on this).

	  From methods(class="augPred"), I learned that there was a nonvisible 
function "plot.augPred".  From getAnywhere("plot.augPred"), I could see 
the definition of that function.  It basically consisted of a call the 
"xyplot", which I tried to modify to produce what you seemed to be 
requesting.

	  Your request seems reasonably clear and concise, and it should have 
(I think) a relatively simple solution, but I can't find it at the moment.

	  Good Luck,
	  spencer graves

Christoph Lehmann wrote:

> Hi
> 
> using this code example:
> 
> library(nlme)
> fm1 <- lme(Orthodont, random = ~1)
> plot(augPred(fm1))
> 
> is there any way to have the plots in each cell labelled and ordered
> according to Orthodont$Sex? I.e. in addition to the bar with the label for
> Orthodont$Subject there is another bar labelling the Sex of the subject?
> 
> thanks a lot
> 
> christoph
> 
> --
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From renata at lipe.com.br  Mon Oct 10 16:23:25 2005
From: renata at lipe.com.br (Renata)
Date: Mon, 10 Oct 2005 11:23:25 -0300
Subject: [R] SEM with dichotomous indicators
Message-ID: <200510101423.j9AENX2P014243@hypatia.math.ethz.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051010/be0ed3c6/attachment.pl

From as1524933 at sapo.pt  Tue Oct 11 17:38:16 2005
From: as1524933 at sapo.pt (Miguel Ribeiro)
Date: Tue, 11 Oct 2005 16:38:16 +0100
Subject: [R] STATIS
Message-ID: <000c01c5ce79$dbc6a300$3c3a9b52@migueliybzmmj5>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051011/7df8cd33/attachment.pl

From p.dalgaard at biostat.ku.dk  Wed Oct 12 19:35:33 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 12 Oct 2005 19:35:33 +0200
Subject: [R] Hmisc latex function
In-Reply-To: <434D2C53.5000005@vanderbilt.edu>
References: <1129039280.3048.7.camel@localhost.localdomain>
	<1129049947.4233.66.camel@localhost.localdomain>
	<434D10C5.6080601@vanderbilt.edu> <x2slv6lr12.fsf@viggo.kubism.ku.dk>
	<434D2C53.5000005@vanderbilt.edu>
Message-ID: <x2ll0yy6xm.fsf@turmalin.kubism.ku.dk>

Charles Dupont <charles.dupont at vanderbilt.edu> writes:

> For a temporary fix source the attached file after loading the Hmisc
> library.  I will fix this in source for the next version.

Or, slightly shorter but somewhat dirtier:

 evalq(dQuote <- shQuote, environment(latex))


-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From trainerneeded64 at yahoo.com  Wed Oct 12 19:37:15 2005
From: trainerneeded64 at yahoo.com (trainer or consultant needed)
Date: Wed, 12 Oct 2005 10:37:15 -0700 (PDT)
Subject: [R] looking for a consultant/trainer with expertise in R
Message-ID: <20051012173715.76122.qmail@web34915.mail.mud.yahoo.com>

We are looking for a consultant/trainer with expertise
in R.  (Ideally, the person will also be familiar with
?Microsoft SQL?). Training can be by phone, email,
instant messenger and/or in person.  (We are located
in San Francisco.) 
  
Please respond to trainerneeded64 at yahoo.com if 
interested.



		
__________________________________ 

Access over 1 million songs. Try it free.



From pls at mevik.net  Tue Oct 11 10:55:07 2005
From: pls at mevik.net (=?iso-8859-1?q?Ron_Wehrens_and_Bj=F8rn-Helge_Mevik?=)
Date: Tue, 11 Oct 2005 10:55:07 +0200
Subject: [R] [R-pkgs] pls version 1.1-0
Message-ID: <m0mzlgmo0k.fsf@bar.nemo-project.org>

Version 1.1-0 of the pls package is now available on CRAN.

The pls package implements partial least squares regression (PLSR) and
principal component regression (PCR).  Features of the package include

- Several plsr algorithms: orthogonal scores, kernel pls and simpls
- Flexible cross-validation
- A formula interface, with traditional methods like predict, coef,
  plot and summary
- Functions for extraction of scores and loadings, and calculation of
  (R)MSEP and R2
- A simple multiplicative scatter correction (msc) implementation
- Functions for plotting predictions, validation statistics,
  coefficients, scores, loadings, biplots and correlation loadings.

The main changes since 1.0-3 are

- mvr, mvrCv and predict.mvr now has builtin support for scaling of X.
- A new function stdize for explicit centering and/or scaling.
- Correlation loadings plot (corrplot).
- New argument `varnames' in coefplot, to label the x tick marks with the
  variable names.
- loadingplot, coefplot and plot.mvrVal can now display legends, with the
  argument 'legendpos'.

See CHANGES in the sources for all changes.


-- 
Bj??rn-Helge Mevik and Ron Wehrens

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From ripley at stats.ox.ac.uk  Sun Oct 16 22:26:13 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 16 Oct 2005 21:26:13 +0100 (BST)
Subject: [R] finding roots of a polynomial
In-Reply-To: <BAY110-F16E77EC71A2A93401F9FD5A3840@phx.gbl>
References: <BAY110-F16E77EC71A2A93401F9FD5A3840@phx.gbl>
Message-ID: <Pine.LNX.4.61.0510162125150.6550@gannet.stats>

?polyroot, and watch that x^4 appears to be missing.

On Fri, 7 Oct 2005, Vumani Dlamini wrote:

> Dear listers,
> I am trying to find the root of a polynomial of the form,
>       a+bx+cx^2+dx^3+ex^5+...=0
> where a,b,c,d,e are known.
> I have looked at "quadprog" without any success.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sun Oct 16 22:30:10 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 16 Oct 2005 21:30:10 +0100 (BST)
Subject: [R] boxplot: how to display x-labels vertically
In-Reply-To: <58ae3dc70510091456m2c761b44l283e4544d98e3ae6@mail.gmail.com>
References: <58ae3dc70510091456m2c761b44l283e4544d98e3ae6@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0510162128090.6550@gannet.stats>

On Sun, 9 Oct 2005, Steven T. wrote:

> I need to draw a boxplot for a dataset consisting about 60 groups, the
> problems is by default the x labels are drawn horizontally, so it is
> impossible to display the names of all 60 groups. However, if the labels are
> drawn vertically, it should be possible to display all names.
>
> How can this be done?

Please read An Introduction to R, section 12.4.  You are looking for 
parameter 'las'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ggrothendieck at gmail.com  Sun Oct 16 22:41:33 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 16 Oct 2005 16:41:33 -0400
Subject: [R] grid.edit problem
In-Reply-To: <4352B1AD.8020103@stat.auckland.ac.nz>
References: <971536df0510150928s2a8a6935k33470e74d169f832@mail.gmail.com>
	<4352B1AD.8020103@stat.auckland.ac.nz>
Message-ID: <971536df0510161341o7ab384f0w243aba92a1e0fc66@mail.gmail.com>

Thanks, again.  I see its basically an origin problem so that, for
example, this would have worked too:

grid.edit("L", x = grid.get("L")$x + unit(10, "native") - unit(0, "native"))

By the way, could unit.c, unit.rep and unit.length
be named c.unit, rep.unit and length.unit (since
then they would just be methods of the respective
S3 generics and no new names would need to be
introduced or remembered).


On 10/16/05, Paul Murrell <p.murrell at auckland.ac.nz> wrote:
> Hi
>
>
> Gabor Grothendieck wrote:
> > I am having a problem in editing a grob.  It works ok if I try to
> > shift the grob using npc coordinates but if I do the same thing
> > using native coordinates the grob disappears.  What is wrong?
> >
> >
> > library(grid)
> > grid.newpage()
> >
> > # create viewport
> > pushViewport(viewport(xscale = c(100,200), name = "X"))
> >
> > # draw vertical line
> > grid.lines(150, 0:1, default.units = "native",  name = "L")
> >
> > # move line 25% of the way to the right. Works ok.
> > grid.edit("L", x = grid.get("L")$x + unit(0.25, "npc"))
> >
> >
> > # but now repeat it shifting it using native coordinates
> > ########################################################
> >
> > # remove line and draw a new line where the original one was
> > grid.remove("L")
> > grid.lines(150, 0:1, default.units = "native",  name = "L")
> >
> > # move line 25% of the way to the right but use native coordiantes
> > #### line disappears !!!!!!!!!
> > grid.edit("L", x = grid.get("L")$x + unit(25, "native"))
>
>
> This is due to the fact that the *location* unit(25, "native") is very
> different from the *location* unit(.25, "npc").   In your example, the
> former actually corresponds to unit(-.75, "npc").
>
> What you appear to be trying to do is add a *dimension* (width) unit(25,
> "native"), which corresponds to a *dimension* unit(.25, "npc"), to the
> original *location* unit(150, "native").  Problem is, the 'x' component
> of a  "line" is interpreted as a location so your unit(25, "native") is
> interpreted as a location.
>
> This issue is described in one of the small grid doc's at
> http://www.stat.auckland.ac.nz/~paul/grid/doc/locndimn.pdf
>
> A (rather verbose) way of specifying your goal is the following ...
>
> grid.edit("L", x = grid.get("L")$x +
>                    # Convert a width into a location
>                    convertUnit(unit(25, "native"), "native",
>                                "x", "dimension", "x", "location"))
>
> ... or, if you know you are only dealing with "native" (data) values,
> you could add them together before using them to specify a location ...
>
> x <- 150 + 25
> grid.edit("L", x = unit(x, "native"))
>
> Paul
> --
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
>
>



From spencer.graves at pdf.com  Sun Oct 16 22:42:53 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 16 Oct 2005 13:42:53 -0700
Subject: [R] Need help on  ARIMA (time series analysis)
In-Reply-To: <000401c5c938$44d13500$6a2de380@hcs.ufl.edu>
References: <000401c5c938$44d13500$6a2de380@hcs.ufl.edu>
Message-ID: <4352BB4D.4060406@pdf.com>

	  Have you received a reply to this post?  I have not seen one.  If you 
would still like some suggestions from this group, please provide more 
detail on your question, as requested in the posting guide 
(www.R-project.org/posting-guide.html), including which version of R 
under which operating system.

	  If I understand your post, you have two questions:  (1) the error 
message and (2) the need for a loop.

	  Regarding the error message, I can not replicate it.  The message 
suggests a series that is nonstationary.  However, I don't get that 
message from 'arima(1:50, order=c(1,0,1))', which is clearly 
nonstationary.  What's in the file "C:\\R\\arima.R"?  Can you replicate 
the error without using a "source" command?

	  Regarding the need for a loop, I'm sorry, but I don't know enough 
about time series in R to answer your question.  I'm currently studying 
Venables and Ripley (2002) Modern Applied Statistics with S, 4th ed. 
(Springer), ch. 14.  If you are not familiar with this book, I highly 
recommend it.  Ch. 14 is on time series.  If you would like more 
comments on your question regarding a loop, I suggest you rephrase your 
question in terms of a standard example like "lh", fitting to, e.g., 
windows of length 30 in this series of 48 observations, explaining also 
very briefly what you are trying to accomplish with the loop.

	  spencer graves

park wrote:
> Hi, 
>  
> I am so novice in using R. I have some problems in my R script below
> which fits time series data and predict it one-step ahead.  Here is a
> brief explanation on what I try to achieve
>  
> Th16k is time series data (500 data points). The size of window for
> fitting and predicting is 50 (data points). As you can easily discover
> from my code,  (fixed) window is moving/sliding to get next one-step
> ahead prediction. The predicted value will be saved in pth.
>  
> The problem is,  every time I execute following script, I got error
> saying 
>  
> 
>>source("C:\\R\\arima.R")
> 
> Error in arima(temp, order = c(1, 0, 1)) : 
>         non-stationary AR part from CSS
>  
> I think there should be better way to achieve this goal without using
> for loop.  If you can share your knowledge, please advise me!!! :-)
>  
> <-----------------------------------------------------------------------
> ----------------------------->
> w <- 50
> pth <- th16k[1:w]
> limit <- length(th16k)-w
> for (i in 1:limit) {
>       ws <- i
>       we <- i+w-1
>       temp <- th16k[ws:we]
>       fit <- arima(temp, order=c(1, 0, 1))
>       pred <- predict(fit, n.ahead=1)
>       pth[i+w] <- pred$pred
> }
> plot(pth)
> <-----------------------------------------------------------------------
> ----------------------------->
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From tring at gvdnet.dk  Sun Oct 16 22:40:17 2005
From: tring at gvdnet.dk (Troels Ring)
Date: Sun, 16 Oct 2005 22:40:17 +0200
Subject: [R] measurement error model - "simple" linear regression
Message-ID: <6.2.3.4.0.20051016220408.051d08e0@home.gvdnet.dk>

Dear friends, I found the thread on this subject this summer but 
wonder whether it has been taken any further. I have an important 
medical problem where X is computed from a three independent and 
complicated measurements (exchangeable sodium and potassium and total 
body water - i.e. X = (Nae+Ke)/TBW ) and Y is serum sodium 
concentration (all data in Edelman, JCI 1958). I have the individual 
data in the paper (but have not yet had time to enter it) and Edelman 
et al in fact reported measurement errors for most individual items. 
Edelman and coworkers made a linear regression of Y on X and now I 
would like to ascertain the importance of the fact that X was 
measured with error for the utility of the formula in clinical 
practice (since I believe it is being misused by ignoring this fact - 
and more). I found in Neter, Wasserman and Kutner 3. ed a general 
discussion of the problem - but would very much like a more recent 
presentation if available and application in R.

Best wishes

Troels Ring
Aalborg, Denmark



From spencer.graves at pdf.com  Sun Oct 16 22:59:08 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 16 Oct 2005 13:59:08 -0700
Subject: [R] acf.plot() question
In-Reply-To: <F6F74E57C281CD42B4FBFB3ADF85B29B716E94@IMCSRV2.MITRE.ORG>
References: <F6F74E57C281CD42B4FBFB3ADF85B29B716E94@IMCSRV2.MITRE.ORG>
Message-ID: <4352BF1C.5020500@pdf.com>

	  Have you received a reply to this?  I haven't seen one.  If not, you 
might have received a quicker reply if you had noted that the example 
came from ch. 14 of Venables and Ripley (2002) Modern applied Statistics 
with S, 4th ed. (Springer, pp. 390-391, to be precise).

	  You ask about the "plot in the lower right-hand corner", which as I 
read it is labeled "fdeaths".  I assume you are asking why the 
upper-right is labeled "mdeaths and fdeaths" and the lower-left "fdeaths 
and mdeaths", especially since the lags in the lower left are negative. 
  I agree that it might make more sense, since the lower left lags are 
negative, to have the label in the lower left the same as in the upper 
right.  However, it doesn't disturb me greatly as it is.

	  spencer graves

DeBarr, Dave wrote:
> When I run the "acf()" function using the "acf(ts.union(mdeaths,
> fdeaths))" example, the "acf()" function calls the "acf.plot()"
> function to generate this plot...
> http://members.cox.net/ddebarr/images/acf_example.png
> 
> The plot in the lower right-hand corner is labeled "fdeaths & mdeaths",
> but the negative lags appear to belong to "mdeaths & fdeaths" [which
> correspond to the positive lags of "fdeaths & mdeaths"].
> 
> Am I missing something, or should the plot in the lower right-hand
> corner be labeled "mdeaths & fdeaths" (instead of "fdeaths & mdeaths")?
> 
> Note: The unit of measure for the lags is years.
> 
> 
>>autocorrelation <- function(x, y, lags) {
> 
> +     n <- length(x)
> +     x.bar <- mean(x)
> +     y.bar <- mean(y)
> +     c <- array(0, length(lags))
> +     i <- 1
> +     for (t in lags) {
> +         s <- seq(max(1, 1 - t), min(n - t, n))
> +         c[i] <- sum((x[s + t] - x.bar) * (y[s] - y.bar)) / n
> +         i <- i + 1
> +     }
> +     x.sd <- sqrt(sum((x - x.bar) ^ 2) / n)
> +     y.sd <- sqrt(sum((y - y.bar) ^ 2) / n)
> +     return(c / (x.sd * y.sd))
> + }
> 
>>autocorrelation(mdeaths, fdeaths, -15:15)
> 
>  [1]  0.015054983  0.365626026  0.615427121  0.708206289  0.621895801
>  [6]  0.340005447 -0.024534195 -0.381671430 -0.611793479 -0.677803477
> [11] -0.604031174 -0.349468396  0.019759425  0.405200639  0.744309322
> [16]  0.976241251  0.735668532  0.364241839 -0.010675725 -0.382920620
> [21] -0.622386979 -0.688538519 -0.610583980 -0.383338305 -0.018112073
> [26]  0.391983088  0.656592111  0.721397236  0.639104375  0.361352626
> [31] -0.003385423
> 
>>autocorrelation(fdeaths, mdeaths, -15:15)
> 
>  [1] -0.003385423  0.361352626  0.639104375  0.721397236  0.656592111
>  [6]  0.391983088 -0.018112073 -0.383338305 -0.610583980 -0.688538519
> [11] -0.622386979 -0.382920620 -0.010675725  0.364241839  0.735668532
> [16]  0.976241251  0.744309322  0.405200639  0.019759425 -0.349468396
> [21] -0.604031174 -0.677803477 -0.611793479 -0.381671430 -0.024534195
> [26]  0.340005447  0.621895801  0.708206289  0.615427121  0.365626026
> [31]  0.015054983
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From ggrothendieck at gmail.com  Sun Oct 16 23:05:34 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 16 Oct 2005 17:05:34 -0400
Subject: [R] Need help on ARIMA (time series analysis)
In-Reply-To: <4352BB4D.4060406@pdf.com>
References: <000401c5c938$44d13500$6a2de380@hcs.ufl.edu>
	<4352BB4D.4060406@pdf.com>
Message-ID: <971536df0510161405o7ec2b84fxa5445e14f566d88f@mail.gmail.com>

Regarding the loop, the code below:

>       ws <- i
>       we <- i+w-1
>       temp <- th16k[ws:we]

can be written as:

  temp <- th16k[seq(i, length = w)]

or you can get rid of the loop entirely using embed
or  using running in package gtools or rapply in the zoo package.


> park wrote:
> > Hi,
> >
> > I am so novice in using R. I have some problems in my R script below
> > which fits time series data and predict it one-step ahead.  Here is a
> > brief explanation on what I try to achieve
> >
> > Th16k is time series data (500 data points). The size of window for
> > fitting and predicting is 50 (data points). As you can easily discover
> > from my code,  (fixed) window is moving/sliding to get next one-step
> > ahead prediction. The predicted value will be saved in pth.
> >
> > The problem is,  every time I execute following script, I got error
> > saying
> >
> >
> >>source("C:\\R\\arima.R")
> >
> > Error in arima(temp, order = c(1, 0, 1)) :
> >         non-stationary AR part from CSS
> >
> > I think there should be better way to achieve this goal without using
> > for loop.  If you can share your knowledge, please advise me!!! :-)
> >
> > <-----------------------------------------------------------------------
> > ----------------------------->
> > w <- 50
> > pth <- th16k[1:w]
> > limit <- length(th16k)-w
> > for (i in 1:limit) {
> >       ws <- i
> >       we <- i+w-1
> >       temp <- th16k[ws:we]
> >       fit <- arima(temp, order=c(1, 0, 1))
> >       pred <- predict(fit, n.ahead=1)
> >       pth[i+w] <- pred$pred
> > }
> > plot(pth)
> > <-----------------------------------------------------------------------
> > ----------------------------->
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
> --
> Spencer Graves, PhD
> Senior Development Engineer
> PDF Solutions, Inc.
> 333 West San Carlos Street Suite 700
> San Jose, CA 95110, USA
>
> spencer.graves at pdf.com
> www.pdf.com <http://www.pdf.com>
> Tel:  408-938-4420
> Fax: 408-280-7915
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From p.murrell at auckland.ac.nz  Sun Oct 16 23:35:16 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Mon, 17 Oct 2005 10:35:16 +1300
Subject: [R] grid.edit problem
References: <971536df0510150928s2a8a6935k33470e74d169f832@mail.gmail.com>	<4352B1AD.8020103@stat.auckland.ac.nz>
	<971536df0510161341o7ab384f0w243aba92a1e0fc66@mail.gmail.com>
Message-ID: <4352C794.9030302@stat.auckland.ac.nz>

Hi


Gabor Grothendieck wrote:
> Thanks, again.  I see its basically an origin problem so that, for
> example, this would have worked too:
> 
> grid.edit("L", x = grid.get("L")$x + unit(10, "native") - unit(0, "native"))


Right.
And your solution might be easier for people to read and write too :)


> By the way, could unit.c, unit.rep and unit.length
> be named c.unit, rep.unit and length.unit (since
> then they would just be methods of the respective
> S3 generics and no new names would need to be
> introduced or remembered).


Yes, for rep() and length()  (I think the original functions were 
written when the corresponding base functions were not generic).

c() is a bit harder because of its ... argument.  If all of the ... 
arguments are units it could work, but the result of c(1, unit(...)) 
would be a very nasty mess.

Paul


> On 10/16/05, Paul Murrell <p.murrell at auckland.ac.nz> wrote:
> 
>>Hi
>>
>>
>>Gabor Grothendieck wrote:
>>
>>>I am having a problem in editing a grob.  It works ok if I try to
>>>shift the grob using npc coordinates but if I do the same thing
>>>using native coordinates the grob disappears.  What is wrong?
>>>
>>>
>>>library(grid)
>>>grid.newpage()
>>>
>>># create viewport
>>>pushViewport(viewport(xscale = c(100,200), name = "X"))
>>>
>>># draw vertical line
>>>grid.lines(150, 0:1, default.units = "native",  name = "L")
>>>
>>># move line 25% of the way to the right. Works ok.
>>>grid.edit("L", x = grid.get("L")$x + unit(0.25, "npc"))
>>>
>>>
>>># but now repeat it shifting it using native coordinates
>>>########################################################
>>>
>>># remove line and draw a new line where the original one was
>>>grid.remove("L")
>>>grid.lines(150, 0:1, default.units = "native",  name = "L")
>>>
>>># move line 25% of the way to the right but use native coordiantes
>>>#### line disappears !!!!!!!!!
>>>grid.edit("L", x = grid.get("L")$x + unit(25, "native"))
>>
>>
>>This is due to the fact that the *location* unit(25, "native") is very
>>different from the *location* unit(.25, "npc").   In your example, the
>>former actually corresponds to unit(-.75, "npc").
>>
>>What you appear to be trying to do is add a *dimension* (width) unit(25,
>>"native"), which corresponds to a *dimension* unit(.25, "npc"), to the
>>original *location* unit(150, "native").  Problem is, the 'x' component
>>of a  "line" is interpreted as a location so your unit(25, "native") is
>>interpreted as a location.
>>
>>This issue is described in one of the small grid doc's at
>>http://www.stat.auckland.ac.nz/~paul/grid/doc/locndimn.pdf
>>
>>A (rather verbose) way of specifying your goal is the following ...
>>
>>grid.edit("L", x = grid.get("L")$x +
>>                   # Convert a width into a location
>>                   convertUnit(unit(25, "native"), "native",
>>                               "x", "dimension", "x", "location"))
>>
>>... or, if you know you are only dealing with "native" (data) values,
>>you could add them together before using them to specify a location ...
>>
>>x <- 150 + 25
>>grid.edit("L", x = unit(x, "native"))
>>
>>Paul
>>--
>>Dr Paul Murrell
>>Department of Statistics
>>The University of Auckland
>>Private Bag 92019
>>Auckland
>>New Zealand
>>64 9 3737599 x85392
>>paul at stat.auckland.ac.nz
>>http://www.stat.auckland.ac.nz/~paul/
>>
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From jfox at mcmaster.ca  Sun Oct 16 23:50:01 2005
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 16 Oct 2005 17:50:01 -0400
Subject: [R] SEM with dichotomous indicators
In-Reply-To: <200510101423.j9AENX2P014243@hypatia.math.ethz.ch>
Message-ID: <web-106787682@cgpsrv2.cis.mcmaster.ca>

Dear Renata,

You can do this by combining the sem() and boot.sem() functions in the
sem package with hetcor() in the polycor package; boot.sem() computes
standard errors for parameter estimates by bootstrapping.

See ?boot.sem for an example of a confirmatory factor-analysis model
with ordinal indicators. See ?sem for many examples of
structural-equation models with latent variables. Just combine the two.
Note that a dichotomous indicator is in effect a two-category ordinal
variable and may be handled as such. For example, the polychoric
correlation between two dichtomous variables is just their tetrachoric
correlation.

I hope this helps,
 John 

On Mon, 10 Oct 2005 11:23:25 -0300
 "Renata" <renata at lipe.com.br> wrote:
> Hello,
> 
>  
> 
> I'd like to know if there is a way to fit a Structural equation model
> with
> dichotomous indicators (ex: problem with a phone solved/ or not)
> having
> effects on a ordinal variable.
> 
> How I do that using R?
> 
> Do you have an example with the code in R that you can send to me?
> 
>  
> 
> Thanks a lot! 
> 
> Renata Estrella
> 
> UFRJ, Brasil, Rio de Janeiro
> 
>  
> 
>  
> 
> Renata Leite Estrella
> 
> Assistente de Pesquisa
> 
> (21) 3978-8888 Ramal  8841
> 
> www.lipe.com.br
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/



From taskletter at cox.net  Mon Oct 17 00:34:29 2005
From: taskletter at cox.net (taskletter)
Date: Sun, 16 Oct 2005 15:34:29 -0700
Subject: [R] Error in lazyLoadDBfetch
Message-ID: <001201c5d2a1$c5d0cbd0$6401a8c0@dignan>

R was working fine for a while.  However, now after I get some data from the 
web and try to "write", "write.table" or "save.image", I get this error:

Error in lazyLoadDBfetch(key, datafile, compressed, envhook) : file open 
failed

I may have downloaded additional packages in between the time it worked, and 
now when it doesn't work, but other than that I cannot think of any change 
that would cause this error.

Any help appreciated -- thanks!

atm



From A.Robinson at ms.unimelb.edu.au  Mon Oct 17 02:32:05 2005
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Mon, 17 Oct 2005 10:32:05 +1000
Subject: [R] measurement error model - "simple" linear regression
In-Reply-To: <6.2.3.4.0.20051016220408.051d08e0@home.gvdnet.dk>
References: <6.2.3.4.0.20051016220408.051d08e0@home.gvdnet.dk>
Message-ID: <20051017003205.GF16628@ms.unimelb.edu.au>

Dear Troels,

you might try McArdle, Limnol. Oceanogr., 48(3), 2003, 1363-1366 for
some reading, and the pls package (newly updated) for tools.

(I apologize if this information replicates previous postings, but
Googling R-help McArdle 2005 draws a blank so I think I'm on safe
ground!)

Good luck!

Andrew

On Sun, Oct 16, 2005 at 10:40:17PM +0200, Troels Ring wrote:
> Dear friends, I found the thread on this subject this summer but 
> wonder whether it has been taken any further. I have an important 
> medical problem where X is computed from a three independent and 
> complicated measurements (exchangeable sodium and potassium and total 
> body water - i.e. X = (Nae+Ke)/TBW ) and Y is serum sodium 
> concentration (all data in Edelman, JCI 1958). I have the individual 
> data in the paper (but have not yet had time to enter it) and Edelman 
> et al in fact reported measurement errors for most individual items. 
> Edelman and coworkers made a linear regression of Y on X and now I 
> would like to ascertain the importance of the fact that X was 
> measured with error for the utility of the formula in clinical 
> practice (since I believe it is being misused by ignoring this fact - 
> and more). I found in Neter, Wasserman and Kutner 3. ed a general 
> discussion of the problem - but would very much like a more recent 
> presentation if available and application in R.
> 
> Best wishes
> 
> Troels Ring
> Aalborg, Denmark
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Andrew Robinson
Senior Lecturer in Statistics                       Tel: +61-3-8344-9763
Department of Mathematics and Statistics            Fax: +61-3-8344-4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au



From stich at uni-hohenheim.de  Mon Oct 17 02:50:59 2005
From: stich at uni-hohenheim.de (stich@uni-hohenheim.de)
Date: Mon, 17 Oct 2005 02:50:59 +0200
Subject: [R] stack overflow using step()
Message-ID: <1129510259.4352f5730e59b@webmail.uni-hohenheim.de>

Hi,
I'm using step() for forward regression with 680 main effects and the
correspomding 230860 interactions. However, the calculation is stopped with the
message:
Error: protect(): stack overflow

How can I specify the maximum size of the pointer protection stack when running
R not from command line but in an emacs-subwindow?

How can I perform these calculations when the maximum value accepted is 100000?
Thanks,
Benjamin



From wcai11 at hotmail.com  Mon Oct 17 05:02:48 2005
From: wcai11 at hotmail.com (Weijie Cai)
Date: Sun, 16 Oct 2005 23:02:48 -0400
Subject: [R] stepwise on generlized linear model
Message-ID: <BAY103-F386BB859E320FEEA445462D37E0@phx.gbl>

Hi-

Can anybody give me a quick answer that whether step() can be directly 
applied to a glm model including both continuous variables and categorical 
variables (by factor())? Maybe my data is not suitable, I applied step() on 
my glm object and did not get any reduction (i.e., returned full model).

Can gl1ce() in lasso2 deal with glm model with both type variables?

Thanks,
WC



From kbeath at efs.mq.edu.au  Mon Oct 17 09:09:52 2005
From: kbeath at efs.mq.edu.au (Ken Beath)
Date: Mon, 17 Oct 2005 17:09:52 +1000
Subject: [R] Multiple Legends on a densityplot
Message-ID: <BA652F3D-6764-4D0A-B0D5-A95B378AC138@efs.mq.edu.au>

I am trying to obtain multiple legends on a densityplot, using the  
legend parameter. I am trying the following code, with just one  
legend at the moment, which doesn't work. I get

Error in valid.data(rep(units, length.out = length(x)), data) :
     No 'grob' supplied for 'grobwidth' unit

Fixable or better method ? What I need is a separate legend for each  
panel.

densityplot(~lclassprob | cov,
     groups=group,
     main='Density Plot for Covariates',
     xlab='Class probability (Logistic)',
     plot.points=FALSE,
     layout=c(1,6),
     legend=list(inside=list(corner=c(0,0),x=0, y=0, fun=simpleKey,
         args=list(text= c("Yes","No"), points = FALSE,
           rectangles = FALSE,
           lines = TRUE))),
     data=newcapsCov2)



From dray at biomserv.univ-lyon1.fr  Mon Oct 17 09:23:28 2005
From: dray at biomserv.univ-lyon1.fr (=?ISO-8859-1?Q?St=E9phane_Dray?=)
Date: Mon, 17 Oct 2005 09:23:28 +0200
Subject: [R] STATIS
In-Reply-To: <000c01c5ce79$dbc6a300$3c3a9b52@migueliybzmmj5>
References: <000c01c5ce79$dbc6a300$3c3a9b52@migueliybzmmj5>
Message-ID: <43535170.6090502@biomserv.univ-lyon1.fr>

Please,
send your question to the ade4 list. Be more precise on your problem.

http://pbil.univ-lyon1.fr/ADE-4/adelist.html

Miguel Ribeiro wrote:

>Hi, i'm having trouble using Statis in ADE4 package.
>I want to study a matrix with 18x414...could any body help me?!?!'
>
>Urgent
>
>Thanks
>
>Miguel Ribeiro
>Portugal
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>


-- 
St??phane DRAY (dray at biomserv.univ-lyon1.fr )
Laboratoire BBE-CNRS-UMR-5558, Univ. C. Bernard - Lyon I
43, Bd du 11 Novembre 1918, 69622 Villeurbanne Cedex, France
Tel: 33 4 72 43 27 57       Fax: 33 4 72 43 13 88
http://www.steph280.freesurf.fr/



From ripley at stats.ox.ac.uk  Mon Oct 17 09:23:51 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 17 Oct 2005 08:23:51 +0100 (BST)
Subject: [R] stack overflow using step()
In-Reply-To: <1129510259.4352f5730e59b@webmail.uni-hohenheim.de>
References: <1129510259.4352f5730e59b@webmail.uni-hohenheim.de>
Message-ID: <Pine.LNX.4.61.0510170810260.29359@gannet.stats>

Please note the message is about the protect stack, and not the `stack'. 
The message you quote did not come from a current version of R (and you 
have not told us what version you are using, as asked in the posting 
guide).

On Mon, 17 Oct 2005 stich at uni-hohenheim.de wrote:

> Hi,
> I'm using step() for forward regression with 680 main effects and the
> correspomding 230860 interactions.

Hmm.  How many data points?  step() only tries 1000 steps by default.

> However, the calculation is stopped with the message:
> Error: protect(): stack overflow
>
> How can I specify the maximum size of the pointer protection stack when running
> R not from command line but in an emacs-subwindow?

Ask ESS questions on the ESS list please, as the FAQ does ask you.

> How can I perform these calculations when the maximum value accepted is 
> 100000?

which is a lot larger than the default value (which depends on your 
unstated R version).

Without a lot more information it is unclear why the protection stack is 
being used up.  Please show us the last few lines of the output.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Oct 17 09:41:56 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 17 Oct 2005 08:41:56 +0100 (BST)
Subject: [R] Error in lazyLoadDBfetch
In-Reply-To: <001201c5d2a1$c5d0cbd0$6401a8c0@dignan>
References: <001201c5d2a1$c5d0cbd0$6401a8c0@dignan>
Message-ID: <Pine.LNX.4.61.0510170827350.29359@gannet.stats>

What version of R is this?  That error message does not exist in current 
versions of R as far as I can see (nor has it since 2.0.1).  So I believe 
the advice in the posting guide applies:

   If you are using an old version of R and think it does not work
   properly, upgrade.

In earlier versions of R it indicated an OS critical error, in one case 
reported here a failing hard disc.

On Sun, 16 Oct 2005, taskletter wrote:

> R was working fine for a while.  However, now after I get some data from the
> web and try to "write", "write.table" or "save.image", I get this error:
>
> Error in lazyLoadDBfetch(key, datafile, compressed, envhook) : file open
> failed
>
> I may have downloaded additional packages in between the time it worked, and
> now when it doesn't work, but other than that I cannot think of any change
> that would cause this error.
>
> Any help appreciated -- thanks!
>
> atm
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From petr.pikal at precheza.cz  Mon Oct 17 10:26:14 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 17 Oct 2005 10:26:14 +0200
Subject: [R] Help with lattice, regressions and respective lines
In-Reply-To: <43504075.1070308@terra.com.br>
Message-ID: <43537C46.8444.90B828@localhost>

Hi

You are looking for functions

panel.*
especially panel.lmline, but I wondered if you can use linear for one 
panel and quadratic for other panels. You could use a structure 
provided in examples in xyplot help page to try to achieve what 
you want. I do not have instant solution to your problem, maybe 
somebody does :-)

HTH
Petr


On 14 Oct 2005 at 20:34, Jose Claudio Faria wrote:

Date sent:      	Fri, 14 Oct 2005 20:34:13 -0300
From:           	Jose Claudio Faria <joseclaudio.faria at terra.com.br>
Organization:   	UESC
To:             	"r-help at stat.math.ethz.ch" <r-help at stat.math.ethz.ch>
Subject:        	[R] Help with lattice, regressions and respective lines
Send reply to:  	joseclaudio.faria at terra.com.br
	<mailto:r-help-request at stat.math.ethz.ch?subject=unsubscribe>
	<mailto:r-help-request at stat.math.ethz.ch?subject=subscribe>

> # Dear R list,
> #
> # I'm needing help with lattice, regression and respective lines. My
> # data is below:
> 
> bra  = gl(2, 24, label = c('c', 's'))
> em   = rep(gl(3, 8,  label = c('po', 'pov', 'ce')), 2)
> tem  = rep(c(0, 0, 30, 30, 60, 60, 90, 90), 6)
> tem2 = tem^2
> r    = rep(1:2, 24)
> y    = c(40.58, 44.85, 32.55, 35.68, 64.86, 51.95, 42.52, 52.21,
>           40.58, 44.85, 33.46, 46.09, 12.75, 18.01, 16.82, 13.69,
>           40.58, 44.85, 34.45, 29.89, 34.91, 28.10, 27.52, 22.24,
>           48.68, 47.25, 45.58, 45.33, 41.03, 51.20, 45.85, 54.45,
>           48.68, 47.25, 19.88, 19.67, 16.20, 13.49, 13.75, 18.80,
>           48.68, 47.25, 42.19, 39.91, 34.69, 34.11, 32.74, 34.24)
> 
> Df = data.frame(bra, em, tem, tem2, r, y)
> 
> # Regressions
> attach(Df)
>    Dfs1=subset(Df, (bra=='s' & em=='pov'), select=c(bra, em, tem,
>    tem2, r, y)) Dfs1 rlin1=lm(y ~ tem + tem2, data=Dfs1)
>    summary(rlin1)
> 
>    Dfs2=subset(Df, (bra=='s' & em=='po'), select=c(bra, em, tem, r,
>    y)) Dfs2 rlin2=lm(y ~ tem, data=Dfs2) summary(rlin2)
> 
>    Dfs3=subset(Df, (bra=='s' & em=='ce'), select=c(bra, em, tem, tem2,
>    r, y)) Dfs3 rlin3=lm(y ~ tem + tem2, data=Dfs3) summary(rlin3)
> detach(Df)
> 
> # I would like to plot with lattice 'y ~ tem | em',
> # with the panels ('po', 'pov' and 'ce'),
> # and the its respective regressions lines:
> # a) linear for panel 'po' or better, without line;
> # b) quadratic for 'pov' and 'ce'
> 
> # Is it possible? Could somebody hel me?
> 
> # I'm trying:
> library(lattice)
> attach(Df)
>    Dfs=subset(Df, bra=='s', select=c(bra, em, tem, y))
>    Dfs
>    xyplot(y ~ tem | em,
>           data = Dfs, ylim=c(10, 60), xlim=c(-10, 110),
>           ylab='y', xlab='Time, days',
>           layout = c(3,1))
> detach(Df)
> 
> TIA,
> -- 
> Jose Claudio Faria
> Brasil/Bahia/UESC/DCET
> Estatistica Experimental/Prof. Adjunto
> mails:
>   joseclaudio.faria at terra.com.br
>   jc_faria at uesc.br
>   jc_faria at uol.com.br
> tel: 73-3634.2779
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From iaingallagher at btopenworld.com  Mon Oct 17 10:30:12 2005
From: iaingallagher at btopenworld.com (Iain Gallagher)
Date: Mon, 17 Oct 2005 09:30:12 +0100
Subject: [R] Dunn's post hoc test
Message-ID: <43536114.8050407@btopenworld.com>

Hi Everyone.

I am rather new to R and I've been trying to implement a function to 
carry out the above test. For a couple of days now I've been stuck on 
how to generate average rank differences.

Say I have a vector of average ranks:

averank<- c(2,5,9,12)

I would like to subtract averank[1] from averank[2], averank[1] and 
averank[2] from averank[3] and averank[1], averank[2] and averank[3] 
from averank[4] etc (I know the syntax is wrong here... it's just for 
illustration) but I can't work out how to do it.

Ideally I would like to generate an array showing the differences 
between the average ranks so I could tell at a glance which ones were 
greater than my critical value

I've been looking at loops etc but it's a little beyond me at the 
moment. Thanks for any suggestions.

Iain Gallagher
IIIR
Edinburgh University



From 042045003 at fudan.edu.cn  Sat Oct 15 09:57:42 2005
From: 042045003 at fudan.edu.cn (ronggui)
Date: Sat, 15 Oct 2005 15:57:42 +0800
Subject: [R] how to import such data to R?
Message-ID: <0IOE00CI55MKL4@mail.fudan.edu.cn>

the data file has such structure:

     1992       6245         49          .          .         20          1
        0          0   8.739536          0          .          .          .
        .          .          .          .          .            "alabama"
        .          0          .
     1993       7677         58          .          .         15          1
        0          0   8.945984          1          .          0   .2064476
       -5          0          .          0   8.739536            "alabama"
        9          0          0
     1992      13327         57         36         58         16          0
        0          0   9.497547          0         47          .          .
        .          .          .          0          .            "arizona"
        .          0          .
     1993      19860         57         36         58         16          1
        1          0   9.896463          1         47          0   .3989162
        0          1          0          1   9.497547            "arizona"
        0          1          1
     1992      10422         37         28         58         20          0
        0          0   9.251675          0         43          .          .
        .          .          .         -1          .      "arizona state"
        .          0          .

------snip-----

the data descriptions is:

variable names:

year      apps      top25     ver500    mth500    stufac    bowl      btitle   
finfour   lapps     d93       avg500    cfinfour  clapps    cstufac   cbowl    
cavg500   cbtitle   lapps_1   school    ctop25    bball     cbball    

  Obs:   118

  1. year                     1992 or 1993
  2. apps                     # applics for admission
  3. top25                    perc frosh class in 25th high sch percen
  4. ver500                   perc frosh >= 500 on verbal SAT
  5. mth500                   perc frosh >= 500 on math SAT
  6. stufac                   student-faculty ratio
  7. bowl                     = 1 if bowl game in prev year
  8. btitle                   = 1 if men's cnf chmps prev year
  9. finfour                  = 1 if men's final 4 prev year
 10. lapps                    log(apps)
 11. d93                      =1 if year = 1993
 12. avg500                   (ver500+mth500)/2
 13. cfinfour                 change in finfour
 14. clapps                   change in lapps
 15. cstufac                  change in stufac
 16. cbowl                    change in bowl
 17. cavg500                  change in avg500
 18. cbtitle                  change in btitle
 19. lapps_1                  lapps lagged
 20. school                   university name
 21. ctop25                   change in top25
 22. bball                    =1 if btitle or finfour
 23. cbball                   change in bball


so the each four lines represent  one case,can some variables are numeric and some are character.
I though the scan can read it in ,but it seems somewhat tricky as the mixed type of variables.any suggestions?

the attachmen is the raw data and the description of the data. 				


2005-10-15

------
Deparment of Sociology
Fudan University

My new mail addres is ronggui.huang at gmail.com
Blog:http://sociology.yculblog.com

From HStevens at MUOhio.edu  Mon Oct 17 10:56:20 2005
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Mon, 17 Oct 2005 04:56:20 -0400
Subject: [R] Dunn's post hoc test
In-Reply-To: <43536114.8050407@btopenworld.com>
References: <43536114.8050407@btopenworld.com>
Message-ID: <9FBA56F7-1F7D-42F3-8C61-484F13F58428@MUOhio.edu>

I don't know Dunn's rank test, but the following substracts each of  
the sums of averanks from the next rank.

cumsum(averank)[-length(averank)] - averank[-1]

Hank

On Oct 17, 2005, at 4:30 AM, Iain Gallagher wrote:

> Hi Everyone.
>
> I am rather new to R and I've been trying to implement a function to
> carry out the above test. For a couple of days now I've been stuck on
> how to generate average rank differences.
>
> Say I have a vector of average ranks:
>
> averank<- c(2,5,9,12)
>
> I would like to subtract averank[1] from averank[2], averank[1] and
> averank[2] from averank[3] and averank[1], averank[2] and averank[3]
> from averank[4] etc (I know the syntax is wrong here... it's just for
> illustration) but I can't work out how to do it.
>
> Ideally I would like to generate an array showing the differences
> between the average ranks so I could tell at a glance which ones were
> greater than my critical value
>
> I've been looking at loops etc but it's a little beyond me at the
> moment. Thanks for any suggestions.
>
> Iain Gallagher
> IIIR
> Edinburgh University
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting- 
> guide.html
>

Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"



From ripley at stats.ox.ac.uk  Mon Oct 17 11:03:18 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 17 Oct 2005 10:03:18 +0100 (BST)
Subject: [R] stepwise on generlized linear model
In-Reply-To: <BAY103-F386BB859E320FEEA445462D37E0@phx.gbl>
References: <BAY103-F386BB859E320FEEA445462D37E0@phx.gbl>
Message-ID: <Pine.LNX.4.61.0510171002220.29359@gannet.stats>

On Sun, 16 Oct 2005, Weijie Cai wrote:

> Can anybody give me a quick answer that whether step() can be directly
> applied to a glm model including both continuous variables and categorical
> variables (by factor())? Maybe my data is not suitable, I applied step() on
> my glm object and did not get any reduction (i.e., returned full model).

Yes, it can.  There are examples in e.g. MASS4.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Oct 17 11:13:24 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 17 Oct 2005 10:13:24 +0100 (BST)
Subject: [R] question about ?list
In-Reply-To: <0IOC00EJSW1FFD@mail.fudan.edu.cn>
References: <0IOC00EJSW1FFD@mail.fudan.edu.cn>
Message-ID: <Pine.LNX.4.61.0510171005550.29359@gannet.stats>

The help page means exactly what it says, but the English is too subtle 
and I have reworded it.

I have no idea why you are interested in pairlists (they are hardly used 
at user-visible level these days).  The point is that pairlist() is NULL 
and so strictly not a pairlist at all (try typeof() on it).  However, 
is.pairlist(NULL) is true for historical reasons.

On Fri, 14 Oct 2005, ronggui wrote:

> the help page says:
>
> 'is.list' returns 'TRUE' iff its argument is a 'list' _or_ a
>     'pairlist' of 'length' > 0, whereas 'is.pairlist' only returns
>     'TRUE' in the latter case.
>
> does the "latter case" mean a 'pairlist' of 'length' > 0?
>
> but
>> is.pairlist(pairlist())
> [1] TRUE
>> length(pairlist())
> [1] 0
>
> what the help page exactly means?
>
> 2005-10-14
>
> ------
> Deparment of Sociology
> Fudan University

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wmwang at gmail.com  Mon Oct 17 11:21:53 2005
From: wmwang at gmail.com (Weimin Wang)
Date: Mon, 17 Oct 2005 11:21:53 +0200
Subject: [R]  Do anybody know when JGR for R 2.2 release?
Message-ID: <6a88388a0510170221o2edf11b5x98a95d81d3529f5a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051017/e637267b/attachment.pl

From jonathan.williams at pharmacology.oxford.ac.uk  Mon Oct 17 11:32:20 2005
From: jonathan.williams at pharmacology.oxford.ac.uk (Jonathan Williams)
Date: Mon, 17 Oct 2005 10:32:20 +0100
Subject: [R] how to find indices of particular array elements
Message-ID: <NGBBKJEMOMLJFCOIEGCEGEIPJOAA.jonathan.williams@pharm.ox.ac.uk>

Dear R helpers,

I have a largish matrix (1300 x 1300) and I wish to find the row and column
numbers that identify particular elements whose values I know in advance
(for example, the row and column numbers for the maximum value of the
matrix).

I have looked in the help manual and found the functions 'row' and 'col' for
finding the indices of a matrix. But, I can't figure out how to use them to
obtain the indices of the matrix element with maximum value, despite over an
hour of trying!

Many thanks for your help,

Jonathan Williams



From ecoinformatics at gmail.com  Mon Oct 17 11:39:37 2005
From: ecoinformatics at gmail.com (ecoinfo)
Date: Mon, 17 Oct 2005 11:39:37 +0200
Subject: [R] how to find indices of particular array elements
In-Reply-To: <NGBBKJEMOMLJFCOIEGCEGEIPJOAA.jonathan.williams@pharm.ox.ac.uk>
References: <NGBBKJEMOMLJFCOIEGCEGEIPJOAA.jonathan.williams@pharm.ox.ac.uk>
Message-ID: <15f8e67d0510170239q64fcccfcp8ef0220feebde5d@mail.gmail.com>

How about the function which?

?which

On 10/17/05, Jonathan Williams
<jonathan.williams at pharmacology.oxford.ac.uk> wrote:
> Dear R helpers,
>
> I have a largish matrix (1300 x 1300) and I wish to find the row and column
> numbers that identify particular elements whose values I know in advance
> (for example, the row and column numbers for the maximum value of the
> matrix).
>
> I have looked in the help manual and found the functions 'row' and 'col' for
> finding the indices of a matrix. But, I can't figure out how to use them to
> obtain the indices of the matrix element with maximum value, despite over an
> hour of trying!
>
> Many thanks for your help,
>
> Jonathan Williams
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>


--
Xiaohua Dai, Dr.
--------------------------------------------------------------------------------
* Postdoctoral in elephant-tree ecosystem simulation
---------------------------------------------------------------------------------
Centre for Systems Research, Durban Institute of Technology
P.O.Box 953, Durban 4000, South Africa
Tel: +27-31-2042737(O) Fax: +27-31-2042736(O)
Mobile: +27-723682954



From HStevens at MUOhio.edu  Mon Oct 17 12:26:13 2005
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Mon, 17 Oct 2005 06:26:13 -0400
Subject: [R] Help with lattice, regressions and respective lines
In-Reply-To: <43504075.1070308@terra.com.br>
References: <43504075.1070308@terra.com.br>
Message-ID: <865FC376-5D68-4BB7-988F-99A9FA7C863F@MUOhio.edu>

Hi Jose,
I am just beginning to plumb the depths of lattice, but perhaps my  
recent experience can help.
I recently figured out (with encouragement from the list) how to plot  
predicted values from a model into the appropriate panel. I am  
certain that what I have done can be done better, but the following  
appears to work for me.

Imagine the model
mod <- lm(Y ~ A + B)
where A is continuous and B is a factor.

I created a new function to use in the panel

panel.modfinal <- function(mod, x, y, subscripts, groups)
     xfit <- seq(min(x), max(x), length=21)
     b <- factor( rep(levels(mod$data$B), rep(21,4)) )
     yfit <- predict(mod, newdata=data.frame(A=rep(xfit,4), B=b) ) 
[b==unique(groups[subscripts] ) ]
     llines(xfit,yfit,lty=1) }

I then plot the data and the fitted lines with constant slope and  
unique intercepts:

xyplot(Y ~ A | B, groups=B,
             panel=function(x,y, subscripts,groups){
             panel.xyplot(x,y)
             panel.modfinal(mod,x,y,subscripts,groups) } ).

"groups" seems to identify a variable that you want pass to a panel  
or legend/key function, and subscripts seems to identify the rows  
used in each panel.

I hope the above is correct and doesn't thereby mislead you, but it  
seems to work for me.

Hank Stevens

On Oct 14, 2005, at 7:34 PM, Jose Claudio Faria wrote:

> # Dear R list,
> #
> # I'm needing help with lattice, regression and respective lines.
> # My data is below:
>
> bra  = gl(2, 24, label = c('c', 's'))
> em   = rep(gl(3, 8,  label = c('po', 'pov', 'ce')), 2)
> tem  = rep(c(0, 0, 30, 30, 60, 60, 90, 90), 6)
> tem2 = tem^2
> r    = rep(1:2, 24)
> y    = c(40.58, 44.85, 32.55, 35.68, 64.86, 51.95, 42.52, 52.21,
>           40.58, 44.85, 33.46, 46.09, 12.75, 18.01, 16.82, 13.69,
>           40.58, 44.85, 34.45, 29.89, 34.91, 28.10, 27.52, 22.24,
>           48.68, 47.25, 45.58, 45.33, 41.03, 51.20, 45.85, 54.45,
>           48.68, 47.25, 19.88, 19.67, 16.20, 13.49, 13.75, 18.80,
>           48.68, 47.25, 42.19, 39.91, 34.69, 34.11, 32.74, 34.24)
>
> Df = data.frame(bra, em, tem, tem2, r, y)
>
> # Regressions
> attach(Df)
>    Dfs1=subset(Df, (bra=='s' & em=='pov'), select=c(bra, em, tem,  
> tem2, r, y))
>    Dfs1
>    rlin1=lm(y ~ tem + tem2, data=Dfs1)
>    summary(rlin1)
>
>    Dfs2=subset(Df, (bra=='s' & em=='po'), select=c(bra, em, tem, r,  
> y))
>    Dfs2
>    rlin2=lm(y ~ tem, data=Dfs2)
>    summary(rlin2)
>
>    Dfs3=subset(Df, (bra=='s' & em=='ce'), select=c(bra, em, tem,  
> tem2, r, y))
>    Dfs3
>    rlin3=lm(y ~ tem + tem2, data=Dfs3)
>    summary(rlin3)
> detach(Df)
>
> # I would like to plot with lattice 'y ~ tem | em',
> # with the panels ('po', 'pov' and 'ce'),
> # and the its respective regressions lines:
> # a) linear for panel 'po' or better, without line;
> # b) quadratic for 'pov' and 'ce'
>
> # Is it possible? Could somebody hel me?
>
> # I'm trying:
> library(lattice)
> attach(Df)
>    Dfs=subset(Df, bra=='s', select=c(bra, em, tem, y))
>    Dfs
>    xyplot(y ~ tem | em,
>           data = Dfs, ylim=c(10, 60), xlim=c(-10, 110),
>           ylab='y', xlab='Time, days',
>           layout = c(3,1))
> detach(Df)
>
> TIA,
> -- 
> Jose Claudio Faria
> Brasil/Bahia/UESC/DCET
> Estatistica Experimental/Prof. Adjunto
> mails:
>   joseclaudio.faria at terra.com.br
>   jc_faria at uesc.br
>   jc_faria at uol.com.br
> tel: 73-3634.2779
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting- 
> guide.html
>

Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"



From jfox at mcmaster.ca  Mon Oct 17 12:55:52 2005
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 17 Oct 2005 06:55:52 -0400
Subject: [R] how to import such data to R?
In-Reply-To: <0IOE00CI55MKL4@mail.fudan.edu.cn>
Message-ID: <web-106810866@cgpsrv2.cis.mcmaster.ca>

Dear ronggui,

I didn't find any attachments, but using the data lines in your
message, and assuming that . represents missing data, the following
appears to do what you want:

as.data.frame(scan("c:/temp/ronggui.txt", 
    list(year=1, apps=1, top25=1, ver500=1, 
        mth500=1, stufac=1, bowl=1, btitle=1, finfour=1, lapps=1,
d93=1, 
        avg500=1, cfinfour=1, clapps=1, cstufac=1, cbowl=1, cavg500=1,
 
        cbtitle=1, lapps_1=1, school="", ctop25=1, bball=1, cbball=1,),
        na.strings="."))

See ?scan for details.

I hope this helps,
 John

On Sat, 15 Oct 2005 15:57:42 +0800
 ronggui <042045003 at fudan.edu.cn> wrote:
> the data file has such structure:
> 
>      1992       6245         49          .          .         20
>          1
>         0          0   8.739536          0          .          .
>          .
>         .          .          .          .          .
>            "alabama"
>         .          0          .
>      1993       7677         58          .          .         15
>          1
>         0          0   8.945984          1          .          0
>   .2064476
>        -5          0          .          0   8.739536
>            "alabama"
>         9          0          0
>      1992      13327         57         36         58         16
>          0
>         0          0   9.497547          0         47          .
>          .
>         .          .          .          0          .
>            "arizona"
>         .          0          .
>      1993      19860         57         36         58         16
>          1
>         1          0   9.896463          1         47          0
>   .3989162
>         0          1          0          1   9.497547
>            "arizona"
>         0          1          1
>      1992      10422         37         28         58         20
>          0
>         0          0   9.251675          0         43          .
>          .
>         .          .          .         -1          .      "arizona
> state"
>         .          0          .
> 
> ------snip-----
> 
> the data descriptions is:
> 
> variable names:
> 
> year      apps      top25     ver500    mth500    stufac    bowl
>      btitle   
> finfour   lapps     d93       avg500    cfinfour  clapps    cstufac
>   cbowl    
> cavg500   cbtitle   lapps_1   school    ctop25    bball     cbball
>    
> 
>   Obs:   118
> 
>   1. year                     1992 or 1993
>   2. apps                     # applics for admission
>   3. top25                    perc frosh class in 25th high sch
> percen
>   4. ver500                   perc frosh >= 500 on verbal SAT
>   5. mth500                   perc frosh >= 500 on math SAT
>   6. stufac                   student-faculty ratio
>   7. bowl                     = 1 if bowl game in prev year
>   8. btitle                   = 1 if men's cnf chmps prev year
>   9. finfour                  = 1 if men's final 4 prev year
>  10. lapps                    log(apps)
>  11. d93                      =1 if year = 1993
>  12. avg500                   (ver500+mth500)/2
>  13. cfinfour                 change in finfour
>  14. clapps                   change in lapps
>  15. cstufac                  change in stufac
>  16. cbowl                    change in bowl
>  17. cavg500                  change in avg500
>  18. cbtitle                  change in btitle
>  19. lapps_1                  lapps lagged
>  20. school                   university name
>  21. ctop25                   change in top25
>  22. bball                    =1 if btitle or finfour
>  23. cbball                   change in bball
> 
> 
> so the each four lines represent  one case,can some variables are
> numeric and some are character.
> I though the scan can read it in ,but it seems somewhat tricky as the
> mixed type of variables.any suggestions?
> 
> the attachmen is the raw data and the description of the data. 				
> 
> 
> 2005-10-15
> 
> ------
> Deparment of Sociology
> Fudan University
> 
> My new mail addres is ronggui.huang at gmail.com
> Blog:http://sociology.yculblog.com

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/



From HStevens at MUOhio.edu  Mon Oct 17 13:05:55 2005
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Mon, 17 Oct 2005 07:05:55 -0400
Subject: [R] Help with lattice,
	regressions and respective lines - Correction
In-Reply-To: <865FC376-5D68-4BB7-988F-99A9FA7C863F@MUOhio.edu>
References: <43504075.1070308@terra.com.br>
	<865FC376-5D68-4BB7-988F-99A9FA7C863F@MUOhio.edu>
Message-ID: <3795BEC5-EFBA-4FA5-9ABA-38E10FC751BD@MUOhio.edu>

Hi Jose,
I need to make a small correction in my code -
mod$data$B works for glm objects, but not lm or aov objects. For  
those use, mod$model$B.



On Oct 17, 2005, at 6:26 AM, Martin Henry H. Stevens wrote:

> Hi Jose,
> I am just beginning to plumb the depths of lattice, but perhaps my
> recent experience can help.
> I recently figured out (with encouragement from the list) how to plot
> predicted values from a model into the appropriate panel. I am
> certain that what I have done can be done better, but the following
> appears to work for me.
>
> Imagine the model
> mod <- lm(Y ~ A + B)
> where A is continuous and B is a factor.
>
> I created a new function to use in the panel
>
> panel.modfinal <- function(mod, x, y, subscripts, groups)
>      xfit <- seq(min(x), max(x), length=21)
>      b <- factor( rep(levels(mod$data$B), rep(21,4)) )
>      yfit <- predict(mod, newdata=data.frame(A=rep(xfit,4), B=b) )
> [b==unique(groups[subscripts] ) ]
>      llines(xfit,yfit,lty=1) }
>
> I then plot the data and the fitted lines with constant slope and
> unique intercepts:
>
> xyplot(Y ~ A | B, groups=B,
>              panel=function(x,y, subscripts,groups){
>              panel.xyplot(x,y)
>              panel.modfinal(mod,x,y,subscripts,groups) } ).
>
> "groups" seems to identify a variable that you want pass to a panel
> or legend/key function, and subscripts seems to identify the rows
> used in each panel.
>
> I hope the above is correct and doesn't thereby mislead you, but it
> seems to work for me.
>
> Hank Stevens
>
> On Oct 14, 2005, at 7:34 PM, Jose Claudio Faria wrote:
>
>
>> # Dear R list,
>> #
>> # I'm needing help with lattice, regression and respective lines.
>> # My data is below:
>>
>> bra  = gl(2, 24, label = c('c', 's'))
>> em   = rep(gl(3, 8,  label = c('po', 'pov', 'ce')), 2)
>> tem  = rep(c(0, 0, 30, 30, 60, 60, 90, 90), 6)
>> tem2 = tem^2
>> r    = rep(1:2, 24)
>> y    = c(40.58, 44.85, 32.55, 35.68, 64.86, 51.95, 42.52, 52.21,
>>           40.58, 44.85, 33.46, 46.09, 12.75, 18.01, 16.82, 13.69,
>>           40.58, 44.85, 34.45, 29.89, 34.91, 28.10, 27.52, 22.24,
>>           48.68, 47.25, 45.58, 45.33, 41.03, 51.20, 45.85, 54.45,
>>           48.68, 47.25, 19.88, 19.67, 16.20, 13.49, 13.75, 18.80,
>>           48.68, 47.25, 42.19, 39.91, 34.69, 34.11, 32.74, 34.24)
>>
>> Df = data.frame(bra, em, tem, tem2, r, y)
>>
>> # Regressions
>> attach(Df)
>>    Dfs1=subset(Df, (bra=='s' & em=='pov'), select=c(bra, em, tem,
>> tem2, r, y))
>>    Dfs1
>>    rlin1=lm(y ~ tem + tem2, data=Dfs1)
>>    summary(rlin1)
>>
>>    Dfs2=subset(Df, (bra=='s' & em=='po'), select=c(bra, em, tem, r,
>> y))
>>    Dfs2
>>    rlin2=lm(y ~ tem, data=Dfs2)
>>    summary(rlin2)
>>
>>    Dfs3=subset(Df, (bra=='s' & em=='ce'), select=c(bra, em, tem,
>> tem2, r, y))
>>    Dfs3
>>    rlin3=lm(y ~ tem + tem2, data=Dfs3)
>>    summary(rlin3)
>> detach(Df)
>>
>> # I would like to plot with lattice 'y ~ tem | em',
>> # with the panels ('po', 'pov' and 'ce'),
>> # and the its respective regressions lines:
>> # a) linear for panel 'po' or better, without line;
>> # b) quadratic for 'pov' and 'ce'
>>
>> # Is it possible? Could somebody hel me?
>>
>> # I'm trying:
>> library(lattice)
>> attach(Df)
>>    Dfs=subset(Df, bra=='s', select=c(bra, em, tem, y))
>>    Dfs
>>    xyplot(y ~ tem | em,
>>           data = Dfs, ylim=c(10, 60), xlim=c(-10, 110),
>>           ylab='y', xlab='Time, days',
>>           layout = c(3,1))
>> detach(Df)
>>
>> TIA,
>> -- 
>> Jose Claudio Faria
>> Brasil/Bahia/UESC/DCET
>> Estatistica Experimental/Prof. Adjunto
>> mails:
>>   joseclaudio.faria at terra.com.br
>>   jc_faria at uesc.br
>>   jc_faria at uol.com.br
>> tel: 73-3634.2779
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-
>> guide.html
>>
>>
>
> Dr. Martin Henry H. Stevens, Assistant Professor
> 338 Pearson Hall
> Botany Department
> Miami University
> Oxford, OH 45056
>
> Office: (513) 529-4206
> Lab: (513) 529-4262
> FAX: (513) 529-4243
> http://www.cas.muohio.edu/~stevenmh/
> http://www.muohio.edu/ecology/
> http://www.muohio.edu/botany/
> "E Pluribus Unum"
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting- 
> guide.html
>

Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"



From tmlammail at yahoo.com  Mon Oct 17 13:29:00 2005
From: tmlammail at yahoo.com (Martin Lam)
Date: Mon, 17 Oct 2005 04:29:00 -0700 (PDT)
Subject: [R] how to find indices of particular array elements
In-Reply-To: <NGBBKJEMOMLJFCOIEGCEGEIPJOAA.jonathan.williams@pharm.ox.ac.uk>
Message-ID: <20051017112900.29602.qmail@web40504.mail.yahoo.com>

# create a 4x4 matrix with random values
smallmatrix = matrix(runif(16)*10, ncol = 4, nrow = 4)

# get the row and column number of the item in the
matrix with the highest value
which(smallmatrix == max(smallmatrix), arr.ind = 1)

HTH,

Martin

--- Jonathan Williams
<jonathan.williams at pharmacology.oxford.ac.uk> wrote:

> Dear R helpers,
> 
> I have a largish matrix (1300 x 1300) and I wish to
> find the row and column
> numbers that identify particular elements whose
> values I know in advance
> (for example, the row and column numbers for the
> maximum value of the
> matrix).
> 
> I have looked in the help manual and found the
> functions 'row' and 'col' for
> finding the indices of a matrix. But, I can't figure
> out how to use them to
> obtain the indices of the matrix element with
> maximum value, despite over an
> hour of trying!
> 
> Many thanks for your help,
> 
> Jonathan Williams
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 



		
__________________________________ 

Access over 1 million songs. Try it free.



From kynn at panix.com  Mon Oct 17 13:36:48 2005
From: kynn at panix.com (kynn@panix.com)
Date: Mon, 17 Oct 2005 07:36:48 -0400 (EDT)
Subject: [R] ISO R-programming docs/refs
Message-ID: <200510171136.j9HBama09031@panix3.panix.com>





In my job I write custom computer programs for data analysis, which
are used in our company's consulting business.  Whenever I've needed
statistical analyses I've coded the algorithms myself, but my boss
wants me to start learning and using R, to speed up development.

I am very reluctuant to do this because I can't find adequate
*programming* documentation for R (though I can find a lot of
inadequate documentation).  As far as I can tell, the R documentation
may be adequate for end-users who don't plan to do much programming
(if any at all), but it is completely unacceptable from the standpoint
of programming.

In a couple of simple exploratory projects I have been reduced to
programming by *trial and error*.  For example, I just spent a couple
of fruitless hours trying to find information on how to modify a list
(all my ***guesses*** have failed; they either produce results
different from what I want, or generate errors such as "replacing
element in non-existent column").  How much fundamental basic can one
get in the documentation of a programming language than this sort of
information?[1]  This is just one of many examples.  My R code is filled
with crude hacks that I don't understand, and that I stumbled upon in
blind scrambles to get my code to work.  How can I possible stand by
the results of my R scripts if they are the product of sheer
guesswork?

I even bought the R Reference Manual, vols. 1 and 2, and deeply regret
it, since they are nothing other than a hardcopy of the online manual
pages[1].  This is no substitute for a reference of the R language and
how to program it.

Is my impression correct that R is simply not well-documented enough
for serious programming?  Have I missed a key reference to programming
R?  To those of you who do a lot of programming in R (other than those
who are members of the R Development team, of course): what references
do you consult on questions about the programming language itself (as
opposed to this or that library function)?

Thanks!

kj

[1] A massive tome that I have called S-Plus 2000 Programmer's guide
has *nothing* on the subject.  Unbelievable!  900 pages and not a word
on how one modifies a basic data type.

[2] This, BTW, was a *big* waste of money.  I'm all for supporting
open source development, and often buy hardcopy manuals of free
software precisely for this reason, but for what I got in return for
my 100 USD, I'd been far better off sending directly to the R
Foundation the pittance that the publishers of the manual pass on to
it.

P.S. I'm aware of Introduction to R; this is OK as a tutorial,
particularly for end users, but by itself utterly inadequate as a
reference to the R language.



From 042045003 at fudan.edu.cn  Mon Oct 17 14:09:15 2005
From: 042045003 at fudan.edu.cn (ronggui)
Date: Mon, 17 Oct 2005 20:09:15 +0800
Subject: [R] ISO R-programming docs/refs
Message-ID: <0IOI00KYN6LUB4@mail.fudan.edu.cn>

R Language Definition

Writing R Extensions

1988 S book (the "Blue Book") 

1992 S book (the "White Book")

S programing

Programing with data £¨about S4£©

	

======= 2005-10-17 19:36:48 ÄúÔÚÀ´ÐÅÖÐÐ´µÀ£º=======

>
>
>
>
>In my job I write custom computer programs for data analysis, which
>are used in our company's consulting business.  Whenever I've needed
>statistical analyses I've coded the algorithms myself, but my boss
>wants me to start learning and using R, to speed up development.
>
>I am very reluctuant to do this because I can't find adequate
>*programming* documentation for R (though I can find a lot of
>inadequate documentation).  As far as I can tell, the R documentation
>may be adequate for end-users who don't plan to do much programming
>(if any at all), but it is completely unacceptable from the standpoint
>of programming.
>
>In a couple of simple exploratory projects I have been reduced to
>programming by *trial and error*.  For example, I just spent a couple
>of fruitless hours trying to find information on how to modify a list
>(all my ***guesses*** have failed; they either produce results
>different from what I want, or generate errors such as "replacing
>element in non-existent column").  How much fundamental basic can one
>get in the documentation of a programming language than this sort of
>information?[1]  This is just one of many examples.  My R code is filled
>with crude hacks that I don't understand, and that I stumbled upon in
>blind scrambles to get my code to work.  How can I possible stand by
>the results of my R scripts if they are the product of sheer
>guesswork?
>
>I even bought the R Reference Manual, vols. 1 and 2, and deeply regret
>it, since they are nothing other than a hardcopy of the online manual
>pages[1].  This is no substitute for a reference of the R language and
>how to program it.
>
>Is my impression correct that R is simply not well-documented enough
>for serious programming?  Have I missed a key reference to programming
>R?  To those of you who do a lot of programming in R (other than those
>who are members of the R Development team, of course): what references
>do you consult on questions about the programming language itself (as
>opposed to this or that library function)?
>
>Thanks!
>
>kj
>
>[1] A massive tome that I have called S-Plus 2000 Programmer's guide
>has *nothing* on the subject.  Unbelievable!  900 pages and not a word
>on how one modifies a basic data type.
>
>[2] This, BTW, was a *big* waste of money.  I'm all for supporting
>open source development, and often buy hardcopy manuals of free
>software precisely for this reason, but for what I got in return for
>my 100 USD, I'd been far better off sending directly to the R
>Foundation the pittance that the publishers of the manual pass on to
>it.
>
>P.S. I'm aware of Introduction to R; this is OK as a tutorial,
>particularly for end users, but by itself utterly inadequate as a
>reference to the R language.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

= = = = = = = = = = = = = = = = = = = =
			


 

2005-10-17

------
Deparment of Sociology
Fudan University

My new mail addres is ronggui.huang at gmail.com
Blog:http://sociology.yculblog.com



From subianto at gmail.com  Mon Oct 17 14:34:33 2005
From: subianto at gmail.com (Muhammad Subianto)
Date: Mon, 17 Oct 2005 14:34:33 +0200
Subject: [R] a max value for each column
Message-ID: <43539A59.4020702@gmail.com>

Dear R-list

I have a dataset like below (points), how can I produce a max value for 
each column. I need a result like (I hope my eye correct):

       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
  [1,]   21    1   10   99   14   19    6    9    5     8     5     7

This is a small dataset from 10000 row.
 > points
       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
  [1,]   21    0    9   16    1   11    5    2    5     8     2     5
  [2,]   19    1   10   93    7    0    0    4    1     6     5     1
  [3,]   13    0    4   30    5    7    1    1    5     6     3     6
  [4,]    5    1    9   61    6   19    2    9    5     1     1     6
  [5,]    2    1    1   99    1   18    1    3    2     8     1     2
  [6,]    7    0    5   45   14    4    6    5    1     6     5     6
  [7,]    0    0    6   89   14    3    2    0    3     7     2     6
  [8,]   15    0    1   30   14   17    3    2    3     3     3     5
  [9,]   14    0    5   28    8   10    1    6    5     2     3     6
[10,]   12    1    4   65    6    2    4    1    4     4     4     7
[11,]   14    1    1    3   12   10    5    7    4     3     3     4
[12,]   15    0    1   55    7    7    1    5    3     7     0     2
[13,]   14    0    5    4    7   11    2    0    4     2     2     3
[14,]   13    0    6   94    6    2    4    9    3     4     0     3
[15,]   21    1    5   79   14   14    6    3    5     6     5     6
 >



From Matthias.Templ at statistik.gv.at  Mon Oct 17 14:44:08 2005
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Mon, 17 Oct 2005 14:44:08 +0200
Subject: [R] a max value for each column
Message-ID: <83536658864BC243BE3C06D7E936ABD5027BAC88@xchg1.statistik.local>

apply(points, 2, max) 
Should do the job.

For details look at ?apply

Best,
Matthias

> 
> Dear R-list
> 
> I have a dataset like below (points), how can I produce a max 
> value for 
> each column. I need a result like (I hope my eye correct):
> 
>        [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
>   [1,]   21    1   10   99   14   19    6    9    5     8     5     7
> 
> This is a small dataset from 10000 row.
>  > points
>        [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
>   [1,]   21    0    9   16    1   11    5    2    5     8     2     5
>   [2,]   19    1   10   93    7    0    0    4    1     6     5     1
>   [3,]   13    0    4   30    5    7    1    1    5     6     3     6
>   [4,]    5    1    9   61    6   19    2    9    5     1     1     6
>   [5,]    2    1    1   99    1   18    1    3    2     8     1     2
>   [6,]    7    0    5   45   14    4    6    5    1     6     5     6
>   [7,]    0    0    6   89   14    3    2    0    3     7     2     6
>   [8,]   15    0    1   30   14   17    3    2    3     3     3     5
>   [9,]   14    0    5   28    8   10    1    6    5     2     3     6
> [10,]   12    1    4   65    6    2    4    1    4     4     4     7
> [11,]   14    1    1    3   12   10    5    7    4     3     3     4
> [12,]   15    0    1   55    7    7    1    5    3     7     0     2
> [13,]   14    0    5    4    7   11    2    0    4     2     2     3
> [14,]   13    0    6   94    6    2    4    9    3     4     0     3
> [15,]   21    1    5   79   14   14    6    3    5     6     5     6
>  >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read 
> the posting guide! http://www.R-project.org/posting-guide.html
>



From Max.Kuhn at pfizer.com  Mon Oct 17 14:52:49 2005
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Mon, 17 Oct 2005 08:52:49 -0400
Subject: [R]  ISO R-programming docs/refs
Message-ID: <71257D09F114DA4A8E134DEAC70F25D302885639@groamrexm03.amer.pfizer.com>

KJ,

>In my job I write custom computer programs for data analysis, which
>are used in our company's consulting business.  Whenever I've needed
>statistical analyses I've coded the algorithms myself, but my boss
>wants me to start learning and using R, to speed up development.
>

I'm curious as to what language you usually use. That might help us 
help you in terms of language differences.

>I am very reluctuant to do this because I can't find adequate
>*programming* documentation for R (though I can find a lot of
>inadequate documentation).  As far as I can tell, the R documentation
>may be adequate for end-users who don't plan to do much programming
>(if any at all), but it is completely unacceptable from the standpoint
>of programming.
>

While I would agree that almost every statistical programming language
spend more time on context-specific information (e.g. here's the code
to get a regression line) than good coding practices (program design
and layout), I think that you've misjudged the documentation. 

Sources to learn (in no particular order):

1). S programming by Venables and Ripley, especially section 7.7

2). The code itself! Download the sources from cran (I believe the 
   installed packages have comments stripped). There is a ton of code 
   out there and you will learn just as much from the great code 
   examples as you will from the bad ones (and there are some bad ones).

3). The manuals at http://cran.r-project.org/manuals.html. For example,
   your list subscripting solution is plainly demonstrated in section 6.1:
   
    "Thus if Lst is the name of a list with four components, these may
    be individually referred to as Lst[[1]], Lst[[2]] ..."

4). Package vignettes. There are many packages with doc directories
   with pdf documents that explain some of the nuances of the 
   package. This will help you learn the language.
   
5). For "questions about the programming language itself" it would
   seem like the R Language Definition manual might go a long way.
   
6). This list already contains many answers to common questions

7). Misc web sites:

   - the site listed in http://www.bioconductor.org/workshops/
     typically have sections for an introduction to R

   - Dr. Harrell's site at 
     http://biostat.mc.vanderbilt.edu/twiki/bin/view/Main/

   - JHU's statistical computing class:
     http://www.biostat.jhsph.edu/~bcaffo/statcomp/

   - google 

8). R news, http://cran.r-project.org/doc/Rnews, has two sections
   that may be of interest "Programmer's Niche: nifty hints for 
   programming in R (or S)" and "Hints for newcomers: Explaining 
   sides of R that might not be so obvious from reading the manuals 
   and FAQs."

9). The useR conferences have presentations that might be of interest
   to you: http://www.ci.tuwien.ac.at/Conferences/useR-2004/. I
   would check out the keynote lecture by Martin M??chler.
   
>In a couple of simple exploratory projects I have been reduced to
>programming by *trial and error*.  For example, I just spent a couple
>of fruitless hours trying to find information on how to modify a list
>(all my ***guesses*** have failed; they either produce results
>different from what I want, or generate errors such as "replacing
>element in non-existent column").  How much fundamental basic can one
>get in the documentation of a programming language than this sort of
>information?[1]  This is just one of many examples.  My R code is filled
>with crude hacks that I don't understand, and that I stumbled upon in
>blind scrambles to get my code to work.  How can I possible stand by
>the results of my R scripts if they are the product of sheer
>guesswork?
>

Remember that R is a language created, maintain and grown by
volunteers. 

There is no company that pays people to write copious amounts 
of documentation (like SAS, S-Plus, Java etc). I think that if you 
are going to use R, you should accept the limitations that you 
perceive - and honestly, I don't think that you've put enough effort 
into learning it. 

If you do get stuck, search R-help, read the posting guide, 
compose an email with a very specific question, read the posting 
guide again and send it in. 

(and since they are volunteers, you should also be nice to them.)

>I even bought the R Reference Manual, vols. 1 and 2, and deeply regret
<snip>

Max Kuhn
Associate Director 
Nonclinical Statistics
Pfizer Global R&D

----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From subianto at gmail.com  Mon Oct 17 14:58:03 2005
From: subianto at gmail.com (Muhammad Subianto)
Date: Mon, 17 Oct 2005 14:58:03 +0200
Subject: [R] a max value for each column
In-Reply-To: <43539A59.4020702@gmail.com>
References: <43539A59.4020702@gmail.com>
Message-ID: <43539FDB.4020206@gmail.com>

Acchhh.... very easy, time to drink a cup of coffe, but ....
Thank you for your all.

apply(points, 2, max)

Best regards, Muhammad Subianto

On this day 17/10/2005 02:34 PM, Muhammad Subianto wrote:
> Dear R-list
> 
> I have a dataset like below (points), how can I produce a max value for 
> each column. I need a result like (I hope my eye correct):
> 
>        [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
>   [1,]   21    1   10   99   14   19    6    9    5     8     5     7
> 
> This is a small dataset from 10000 row.
>  > points
>        [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
>   [1,]   21    0    9   16    1   11    5    2    5     8     2     5
>   [2,]   19    1   10   93    7    0    0    4    1     6     5     1
>   [3,]   13    0    4   30    5    7    1    1    5     6     3     6
>   [4,]    5    1    9   61    6   19    2    9    5     1     1     6
>   [5,]    2    1    1   99    1   18    1    3    2     8     1     2
>   [6,]    7    0    5   45   14    4    6    5    1     6     5     6
>   [7,]    0    0    6   89   14    3    2    0    3     7     2     6
>   [8,]   15    0    1   30   14   17    3    2    3     3     3     5
>   [9,]   14    0    5   28    8   10    1    6    5     2     3     6
> [10,]   12    1    4   65    6    2    4    1    4     4     4     7
> [11,]   14    1    1    3   12   10    5    7    4     3     3     4
> [12,]   15    0    1   55    7    7    1    5    3     7     0     2
> [13,]   14    0    5    4    7   11    2    0    4     2     2     3
> [14,]   13    0    6   94    6    2    4    9    3     4     0     3
> [15,]   21    1    5   79   14   14    6    3    5     6     5     6
>  >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Bernhard_Pfaff at fra.invesco.com  Mon Oct 17 14:58:43 2005
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Mon, 17 Oct 2005 13:58:43 +0100
Subject: [R] COM objects with early bindings in R
Message-ID: <25D1C2585277D311B9A20000F6CCC71B0719ADA3@DEFRAEX02>


Dear list member,

I am using the packages RDCOMClient and SWinTypeLibs and try to import a COM
object (created in Delphi) in R that is of type 'early binding' instead of
late 'late binding'. Is there a possibility to do this in R?

Currently, the following returns an error message:

l1 = LoadTypeLib("c:\\Programme\\INVESCO\\QaCalendar\\Calendar.dll")
print(getTypeLibTypes(l1))
      IQaCalPeriodicInit            QaCalPeriodic            IQaSeriesInit 
              "dispatch"                "coclass"               "dispatch" 
                QaSeries                _QaSerLib                 QaSerLib 
               "coclass"               "dispatch"                "coclass" 
      IQaCalSporadicInit            QaCalSporadic           _QaCalendarLib 
              "dispatch"                "coclass"               "dispatch" 
           QaCalendarLib QaCalendarIntersectRules          QaDistanceRules 
               "coclass"                   "enum"                   "enum" 
createCOMSClass(l1[["QaSerLib"]], "test")
Error in generateOperators(libEntry, className) : 
	invalid subscript type  

Any help, pointers or a working example is much appreciated.

Best Regards,
Bernhard

platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    1.1            
year     2005           
month    06             
day      20             
language R



From petr.pikal at precheza.cz  Mon Oct 17 15:01:45 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 17 Oct 2005 15:01:45 +0200
Subject: [R] ISO R-programming docs/refs
In-Reply-To: <200510171136.j9HBama09031@panix3.panix.com>
Message-ID: <4353BCD9.9470.18CFFB6@localhost>


   Hi

   I do not make "programs" in R to be available for others to use. But I
   **do**  analyse data and make some conclusions from such analysis. And
   if  I  have  to analyse the same data every (day, week, month, year) I
   prepare  a "program" (function or several functions) to be able in few
   strokes or in batch mode to do my whole analysis repeatedly.

   I find documentation provided and suggested quite satisfactory and, if
   I am lost, I always can ask this list.

   So if you want to do programs for others I do not have opinion and you
   need not read the rest of this.

   But if the second aspect is what you want, (you have data and you want
   to do an analysis) I am pretty sure that you just missed the basics of
   data manipulation in R.

   I learned BASIC (quite long ago), used punched paper tapes for storing
   data  and did some programming in various languages (although I am not
   a  programmer)  and the main difference I perceive is extensive use of
   operations  on  whole  objects  in  R. Forget to do for-next cycle for
   simple filling some data vector or matrix (at least most of the time).

   read  data  ->  modify,  subset  them  -> issue a build in or prepared
   function  and  store results in some object -> use another function on
   this  object  to  find out some other features of the object or simply
   make some plotting....etc.

   So  you  need  to  learn  the  language  and  bear  in  mind that many
   statistical  analysis is pre-programmed in it and its packages. But it
   of course depends on if you really want to learn it or not.

   If you don't nobody can help you.

   I found particularly useful:

   zoonek2.free.fr/UNIX/48_R/02.html

   www.ku.edu/~pauljohn/R/Rtips.html

   www.psych.upenn.edu/~baron/refcard.pdf

   Using R for Data Analysis and Graphics

   Introduction, Code and Commentary

   J H Maindonald

   http://www.ats.ucla.edu/stat/R/sk/books_usingr.htm

   And of course many other specific documentation, mentioned in CRAN.

   Best regards

   Petr

   On 17 Oct 2005 at 7:36, kynn at panix.com wrote:

   Date sent:                Mon, 17 Oct 2005 07:36:48 -0400 (EDT)

   From:                       <kynn at panix.com>

   To:                           r-help at stat.math.ethz.ch

   Subject:                    [R] ISO R-programming docs/refs

   >

   >

   >

   >

   > In my job I write custom computer programs for data analysis, which

   > are used in our company's consulting business.  Whenever I've needed

   > statistical analyses I've coded the algorithms myself, but my boss

   > wants me to start learning and using R, to speed up development.

   >

   > I am very reluctuant to do this because I can't find adequate

   > *programming* documentation for R (though I can find a lot of

   >   inadequate   documentation).    As  far  as  I  can  tell,  the  R
   documentation

   > may be adequate for end-users who don't plan to do much programming

   >  (if  any  at  all),  but  it  is  completely  unacceptable from the
   standpoint

   > of programming.

   >

   > In a couple of simple exploratory projects I have been reduced to

   >  programming  by  *trial  and  error*.   For example, I just spent a
   couple

   >  of  fruitless  hours  trying to find information on how to modify a
   list

   > (all my ***guesses*** have failed; they either produce results

   > different from what I want, or generate errors such as "replacing

   >  element  in  non-existent column").  How much fundamental basic can
   one

   > get in the documentation of a programming language than this sort of

   > information?[1]  This is just one of many examples.  My R code is

   > filled with crude hacks that I don't understand, and that I stumbled

   > upon in blind scrambles to get my code to work.  How can I possible

   >  stand  by  the  results  of my R scripts if they are the product of
   sheer

   > guesswork?

   >

   >  I  even  bought  the  R Reference Manual, vols. 1 and 2, and deeply
   regret

   >  it,  since  they  are  nothing  other than a hardcopy of the online
   manual

   >  pages[1].   This is no substitute for a reference of the R language
   and

   > how to program it.

   >

   > Is my impression correct that R is simply not well-documented enough

   >  for  serious  programming?   Have  I  missed  a  key  reference  to
   programming

   >  R?   To  those  of you who do a lot of programming in R (other than
   those

   >  who  are  members  of  the  R  Development  team,  of course): what
   references

   >  do  you  consult on questions about the programming language itself
   (as

   > opposed to this or that library function)?

   >

   > Thanks!

   >

   > kj

   >

   > [1] A massive tome that I have called S-Plus 2000 Programmer's guide

   >  has  *nothing*  on the subject.  Unbelievable!  900 pages and not a
   word

   > on how one modifies a basic data type.

   >

   > [2] This, BTW, was a *big* waste of money.  I'm all for supporting

   > open source development, and often buy hardcopy manuals of free

   > software precisely for this reason, but for what I got in return for

   > my 100 USD, I'd been far better off sending directly to the R

   > Foundation the pittance that the publishers of the manual pass on to

   > it.

   >

   > P.S. I'm aware of Introduction to R; this is OK as a tutorial,

   > particularly for end users, but by itself utterly inadequate as a

   > reference to the R language.

   >

   > ______________________________________________

   > R-help at stat.math.ethz.ch mailing list

   > https://stat.ethz.ch/mailman/listinfo/r-help

   > PLEASE do read the posting guide!

   > http://www.R-project.org/posting-guide.html

   Petr Pikal

   petr.pikal at precheza.cz


From taskletter at cox.net  Mon Oct 17 15:05:46 2005
From: taskletter at cox.net (taskletter)
Date: Mon, 17 Oct 2005 06:05:46 -0700
Subject: [R] Error in lazyLoadDBfetch
References: <001201c5d2a1$c5d0cbd0$6401a8c0@dignan>
	<Pine.LNX.4.61.0510170827350.29359@gannet.stats>
Message-ID: <003d01c5d31b$7d2b61e0$6401a8c0@dignan>

Upgrading worked.  Thanks!


----- Original Message ----- 
From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
To: "taskletter" <taskletter at cox.net>
Cc: <r-help at stat.math.ethz.ch>
Sent: Monday, October 17, 2005 12:41 AM
Subject: Re: [R] Error in lazyLoadDBfetch


What version of R is this?  That error message does not exist in current
versions of R as far as I can see (nor has it since 2.0.1).  So I believe
the advice in the posting guide applies:

   If you are using an old version of R and think it does not work
   properly, upgrade.

In earlier versions of R it indicated an OS critical error, in one case
reported here a failing hard disc.

On Sun, 16 Oct 2005, taskletter wrote:

> R was working fine for a while.  However, now after I get some data from 
> the
> web and try to "write", "write.table" or "save.image", I get this error:
>
> Error in lazyLoadDBfetch(key, datafile, compressed, envhook) : file open
> failed
>
> I may have downloaded additional packages in between the time it worked, 
> and
> now when it doesn't work, but other than that I cannot think of any change
> that would cause this error.
>
> Any help appreciated -- thanks!
>
> atm
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bhs2 at mevik.net  Mon Oct 17 15:08:08 2005
From: bhs2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Mon, 17 Oct 2005 15:08:08 +0200
Subject: [R] ISO R-programming docs/refs
References: <200510171136.j9HBama09031@panix3.panix.com>
Message-ID: <m0zmp8z3yf.fsf@bar.nemo-project.org>

[A lot of polite and constructive critique deleted]

> Is my impression correct that R is simply not well-documented enough
> for serious programming?

No.

> Have I missed a key reference to programming R?

Yes.

How about reading the text that R displays when it starts (and follow
its suggestions)?  Or visiting the canonical web site for R
(http://www.r-project.org/)?  Or consulting question 2.7 in the R FAQ
("2.7 What documentation exists for R?")  Or reading the posting guide
for the list (http://www.R-project.org/posting-guide.html)?

All four methods would (presumably) quickly have led you to manuals
such as "the R Language Definition", "Writing R Extensions" and "R
Data Import/Export", and given references to books on programming S
and/or R.

-- 
Bj??rn-Helge Mevik



From ernesto at ipimar.pt  Mon Oct 17 16:07:27 2005
From: ernesto at ipimar.pt (ernesto)
Date: Mon, 17 Oct 2005 15:07:27 +0100
Subject: [R] [R-sig-Geo] rGeo vs. gstat
In-Reply-To: <F07A3234E1CDF74399E254240638883001E80948@bernina.fibl.ch>
References: <F07A3234E1CDF74399E254240638883001E80948@bernina.fibl.ch>
Message-ID: <4353B01F.9010104@ipimar.pt>

Schlatter Christian wrote:

>Dear list members
>
> 
>
>I'm very new to R but a little informed about geostatistics. 
>
>As I was looking for possibilities of geostatistical analysis in R I encountered at least two very interesting packages: 
>
> 
>
>Rgeo and gstat
>
> 
>
>And of course I'm wondering now about the one which fits better my needs which are the comparison of spatial data (insect parasitism rates) for different fields in which we collected data. 
>
> 
>
>Best wishes
>
> 
>
>Christian  
>
> 
>
>  
>

Hi,

Take a look at http://r-spatial.sourceforge.net/

Regards

EJ



From m.ballardini at ior-forli.it  Mon Oct 17 16:17:09 2005
From: m.ballardini at ior-forli.it (Michela Ballardini)
Date: Mon, 17 Oct 2005 16:17:09 +0200
Subject: [R] x axis
Message-ID: <000e01c5d325$765ca180$0200a8c0@Michela>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051017/7ac5c051/attachment.pl

From afshart at exchange.sba.miami.edu  Mon Oct 17 16:45:48 2005
From: afshart at exchange.sba.miami.edu (Afshartous, David)
Date: Mon, 17 Oct 2005 10:45:48 -0400
Subject: [R] memory.size
Message-ID: <6BCB4D493A447546A8126F24332056E8027C87C6@school1.business.edu>


All,
In the help for memory.size, there is:

Details:

     Command-line flag '--max-mem-size' sets the maximum value of
     obtainable memory (including a very small amount of housekeeping
     overhead).

How does one implement a command-line flag in order to set the max for memory?

cheers,
dave
ps - please respond directly to afshar at mimai.edu



From ym at climpact.com  Mon Oct 17 16:48:01 2005
From: ym at climpact.com (Yves Magliulo)
Date: 17 Oct 2005 16:48:01 +0200
Subject: [R] x axis
In-Reply-To: <000e01c5d325$765ca180$0200a8c0@Michela>
References: <000e01c5d325$765ca180$0200a8c0@Michela>
Message-ID: <1129560481.13293.91.camel@new-york.climpact.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051017/f97c5085/attachment.pl

From xurxosanz at yahoo.es  Mon Oct 17 16:51:54 2005
From: xurxosanz at yahoo.es (Jorge Gaspar Sanz Salinas)
Date: Mon, 17 Oct 2005 16:51:54 +0200
Subject: [R] y axis in histograms
Message-ID: <4353BA8A.2040200@yahoo.es>

Hi all,

This is my first post, I hope you will help me.

I've some data to present with histograms. I have few values with almost 99% of 
the frequencies (thousands) and some other values with low frequencies (below 
one hundred) that I want to emphasize. I think if I could present the logarithms 
of the frequencies, these could be presented in a more convenient way, but I 
don't know how to deal with this.

Thanks, and sorry for my English
-- 
Jorge Gaspar Sanz Salinas
Ingeniero en Geodesia y Cartograf??a
xurxosanz [en] yahoo [punto] es



From ligges at statistik.uni-dortmund.de  Mon Oct 17 16:56:55 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 17 Oct 2005 16:56:55 +0200
Subject: [R] memory.size
In-Reply-To: <6BCB4D493A447546A8126F24332056E8027C87C6@school1.business.edu>
References: <6BCB4D493A447546A8126F24332056E8027C87C6@school1.business.edu>
Message-ID: <4353BBB7.80402@statistik.uni-dortmund.de>

Afshartous, David wrote:

> All,
> In the help for memory.size, there is:
> 
> Details:
> 
>      Command-line flag '--max-mem-size' sets the maximum value of
>      obtainable memory (including a very small amount of housekeeping
>      overhead).
> 
> How does one implement a command-line flag in order to set the max for memory?


Either use memory.limit() in R or start R with, e.g.,
   RGui --max-mem-size=1400M
in order to get a max. of 1400Mb of memory...

Uwe Ligges


> cheers,
> dave
> ps - please respond directly to afshar at mimai.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From mschwartz at mn.rr.com  Mon Oct 17 17:18:42 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Mon, 17 Oct 2005 10:18:42 -0500
Subject: [R] y axis in histograms
In-Reply-To: <4353BA8A.2040200@yahoo.es>
References: <4353BA8A.2040200@yahoo.es>
Message-ID: <1129562322.5916.18.camel@localhost.localdomain>

On Mon, 2005-10-17 at 16:51 +0200, Jorge Gaspar Sanz Salinas wrote:
> Hi all,
> 
> This is my first post, I hope you will help me.
> 
> I've some data to present with histograms. I have few values with almost 99% of 
> the frequencies (thousands) and some other values with low frequencies (below 
> one hundred) that I want to emphasize. I think if I could present the logarithms 
> of the frequencies, these could be presented in a more convenient way, but I 
> don't know how to deal with this.
> 
> Thanks, and sorry for my English


If you are plotting the counts, you should probably look at barplot(),
which as of R version 2.2.0 supports log scale axes (ie. log = "y").

See ?barplot for more information.

HTH,

Marc Schwartz



From Malcolm.Price at bristol.ac.uk  Mon Oct 17 17:51:31 2005
From: Malcolm.Price at bristol.ac.uk (MJ Price, Social Medicine)
Date: Mon, 17 Oct 2005 16:51:31 +0100
Subject: [R] Relative Risk and Confidence Intervals
Message-ID: <97722171.1129567891@epi-pc64.epi.bris.ac.uk>

Dear all,

Despite searching the fullrefman file I have been unable to locate a 
function to calculate the relative risk and confidence intervals from a 
simple 2 by 2 contingency table. Can anyone tell me how this is done.

Thanks in advance

Malcolm

----------------------
MJ Price, Social Medicine
epmjp at bristol.ac.uk



From aragon at berkeley.edu  Mon Oct 17 18:10:01 2005
From: aragon at berkeley.edu (Tomas Aragon)
Date: Mon, 17 Oct 2005 09:10:01 -0700 (PDT)
Subject: [R] Relative Risk and Confidence Intervals
In-Reply-To: <97722171.1129567891@epi-pc64.epi.bris.ac.uk>
Message-ID: <20051017161002.42567.qmail@web82010.mail.mud.yahoo.com>

--- "MJ Price, Social Medicine" <Malcolm.Price at bristol.ac.uk> wrote:
> Dear all,
> 
> Despite searching the fullrefman file I have been unable to locate a 
> function to calculate the relative risk and confidence intervals from
> a simple 2 by 2 contingency table. Can anyone tell me how this is
> done.
> 
> Thanks in advance
> 
> Malcolm
> 
> ----------------------
> MJ Price, Social Medicine
> epmjp at bristol.ac.uk

Malcolm, Install the 'epitools' package and use the 'epitab' function,
and use method="riskratio"

Tomas
http://www.epitools.net
http://www.medepi.net/aragon/



From uofiowa at gmail.com  Mon Oct 17 18:16:35 2005
From: uofiowa at gmail.com (Omar Lakkis)
Date: Mon, 17 Oct 2005 12:16:35 -0400
Subject: [R] as.POSIXct before and after 1970
Message-ID: <3f87cc6d0510170916t70268cd8yf8cf645b1eb72c80@mail.gmail.com>

Can someone, please, explain the difference in as.POSIXct results
before 1970 and on and after 1970 as illustrated below.

After 1970, the use of 'EST' or "EST+5EDT' as the timezone does not
affect the result of asPOSIXct, but before 1970 on 10/28 the results
are different.

> as.POSIXct('1970-10-29', tz='EST')+1
[1] "1970-10-29 00:00:01 EST"
> as.POSIXct('1970-10-29', tz='EST+5EDT')+1
[1] "1970-10-29 00:00:01 EST"

> as.POSIXct('1969-10-29', tz='EST')+1
[1] "1969-10-29 00:00:01 EST"
> as.POSIXct('1969-10-29', tz='EST+5EDT')+1
[1] "1969-10-28 23:00:01 EST"



From aliscla at yahoo.com  Mon Oct 17 18:57:27 2005
From: aliscla at yahoo.com (Werner Bier)
Date: Mon, 17 Oct 2005 09:57:27 -0700 (PDT)
Subject: [R] From using ginv()
In-Reply-To: <1129562322.5916.18.camel@localhost.localdomain>
Message-ID: <20051017165727.29182.qmail@web61224.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051017/92ce942f/attachment.pl

From moconnell at insightful.com  Mon Oct 17 19:35:09 2005
From: moconnell at insightful.com (Michael O'Connell)
Date: Mon, 17 Oct 2005 13:35:09 -0400
Subject: [R] Insightful Announces: "R and S-PLUS- Panel Discussion" at 9th
	Annual 2005 User Conference
Message-ID: <61D7107976B46045BFCAA8BD301E829526178F@nc.insightful.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051017/bf6410b2/attachment.pl

From blindglobe at gmail.com  Mon Oct 17 19:52:49 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Mon, 17 Oct 2005 19:52:49 +0200
Subject: [R] Insightful Announces: "R and S-PLUS- Panel Discussion" at
	9th Annual 2005 User Conference
In-Reply-To: <61D7107976B46045BFCAA8BD301E829526178F@nc.insightful.com>
References: <61D7107976B46045BFCAA8BD301E829526178F@nc.insightful.com>
Message-ID: <1abe3fa90510171052q538c36eeub66eecfe4cf1544c@mail.gmail.com>

But who is on the panel?

On 10/17/05, Michael O'Connell <moconnell at insightful.com> wrote:
> Event: 2005 Insightful User Conference
>
> Dates: Oct 26-27, 2005
>
> Location: Princeton, NJ
>
> URL: http://www.insightful.com/news_events/2005uc/ for details on pricing,
> hotel accommodations and to register for this event.
>
>
>
> The Insightful 2005 User Conference is being held October 26th-27th in
> Princeton, NJ. This year's conference focuses on the techniques and
> methodologies pivotal to the increased demand for statistics in business
> organizations. The conference program will include presentations by S-PLUS
> experts from market-leading companies such as Novartis, Procter & Gamble,
> Amgen, and MCI.
>
>
>
> Of particular interest to subscribers to r-help is the panel discussion on
> future plans for compatibility between S-PLUS and R. The panel discussion is
> on the topic "Ensuring Compatibility and Portability Between the Two Prime
> Dialects of the S Language". Martin DeBono from Insightful will moderate a
> panel of experts in both S-PLUS and R to discuss plans for a common packaging
> system and tools to make it easy to convert R packages to S-PLUS. There will
> also be broader discussion about how the users of each dialect can coordinate
> efforts to create a vibrant community focused on the continued advancement of
> the S Language.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>


--
best,
-tony

blindglobe at gmail.com
Muttenz, Switzerland.
"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).



From ripley at stats.ox.ac.uk  Mon Oct 17 20:06:25 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 17 Oct 2005 19:06:25 +0100 (BST)
Subject: [R] as.POSIXct before and after 1970
In-Reply-To: <3f87cc6d0510170916t70268cd8yf8cf645b1eb72c80@mail.gmail.com>
References: <3f87cc6d0510170916t70268cd8yf8cf645b1eb72c80@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0510171902240.890@gannet.stats>

Your OS is?  I cannot reproduce this on any of mine.

Sone OSes do not support dates before 1970, which would explain the 
difference.  R then has to guess when summer time ended in 1969, and I 
suspect something is happening inconsistently.

Also, "EST" is not a real-world POSIX timezone and may well not be 
implemented fully.

On Mon, 17 Oct 2005, Omar Lakkis wrote:

> Can someone, please, explain the difference in as.POSIXct results
> before 1970 and on and after 1970 as illustrated below.
>
> After 1970, the use of 'EST' or "EST+5EDT' as the timezone does not
> affect the result of asPOSIXct, but before 1970 on 10/28 the results
> are different.
>
>> as.POSIXct('1970-10-29', tz='EST')+1
> [1] "1970-10-29 00:00:01 EST"
>> as.POSIXct('1970-10-29', tz='EST+5EDT')+1
> [1] "1970-10-29 00:00:01 EST"
>
>> as.POSIXct('1969-10-29', tz='EST')+1
> [1] "1969-10-29 00:00:01 EST"
>> as.POSIXct('1969-10-29', tz='EST+5EDT')+1
> [1] "1969-10-28 23:00:01 EST"
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ptr2003 at columbia.edu  Mon Oct 17 20:09:27 2005
From: ptr2003 at columbia.edu (ptr2003@columbia.edu)
Date: Mon, 17 Oct 2005 14:09:27 -0400
Subject: [R] pdIdnot / logLik in glmmPQL
Message-ID: <1129572567.4353e8d7630f5@cubmail.cc.columbia.edu>

Dear R users,

I have been using the pdMat class "pdIdnot" (from the mgcv
package)instead of "pdIdent" to avoid overflow in GLMM fits with
the MASS package function glmmPQL, of the following form:

fit1 <- glmmPQL(fixed=y0~-1+xx0, random=list(gp=pdIdent(~-1+zz0)),
                      family=binomial) # vulnerable to overflow
fit2 <- glmmPQL(fixed=y0~-1+xx0, random=list(gp=pdIdnot(~-1+zz0)),
                      family=binomial) # overflow-proof

In instances in which fit1 does *not* lead to overflow, the result
sometimes differs from fit2.  This leads me to two questions.

1. Does anyone have any thoughts on what might cause such a
discrepancy?

2. Given two discrepant fits, I would like a way to choose the
better one.  If my reading of Breslow and Clayton's 1993 paper
(specifically, their equation 12) is correct, at convergence, the
profile quasilikelihood should be approximately equal to the log
likelihood from the last linear mixed model fit by the algorithm. 
If so, the $logLik component of the lme object produced by glmmPQL
should approximate the quasilikelihood I am trying to maximize.  In
short: according to this argument, the glmmPQL fit with higher
"logLik" should be the better one.

And yet, some previous postings seem to indicate that the "logLik"
of an object produced by glmmPQL cannot be interpreted in terms of
likelihood, quasi or otherwise.  If the above made sense (or even
if not), is there anyone who could kindly speak to this point?

Any help with either of the above questions would be greatly
appreciated.

Phil Reiss
PhD candidate, Dept. of Biostatistics
Columbia University, New York
ptr2003 at columbia.edu



From JAROSLAW.W.TUSZYNSKI at saic.com  Mon Oct 17 21:07:57 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Mon, 17 Oct 2005 15:07:57 -0400
Subject: [R] Animated lissajous
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD5043724E1@us-arlington-0668.mail.saic.com>

 
Pretty neat. 

Jarek 
====================================================\==== 
 Jarek Tuszynski, PhD.                           o / \ 
 Science Applications International Corporation  <\__,|  
 (703) 676-4192                                   ">  \ 
 Jaroslaw.W.Tuszynski at saic.com                     `   \ 



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
rlist.10.phftt at xoxy.net
Sent: Saturday, October 15, 2005 11:34 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Animated lissajous

Here's some code to make lissajous dance.  I've attached a small sample GIF.

Cheers,
Rob Steele
robsteele at yahoo dot com



plot.lissajous = function(omega.x, omega.y, delta = 0, num.thetas = 200) {
   thetas = seq(0, 2 * pi, length = num.thetas)
   xs = sin(omega.x * thetas + delta)
   ys = cos(omega.y * thetas)
   plot(xs, ys, type = 'l', lwd = 3, ann = FALSE, axes = FALSE) }


## Show one.
par(mar = c(2, 2, 2, 2))
plot.lissajous(4, 3)

## Animate it.
while (TRUE) {
   for (delta in seq(0, 2 * pi, length = 120)) {
       plot.lissajous(4, 3, delta)
       Sys.sleep(1 / 30)
   }
}


## Show a bunch.
par(mar = c(1, 1, 1, 1))
par(mfrow = c(length(omega.xs), length(omega.ys))) for (omega.x in 1:5) {
   for (omega.y in 1:5) {
       plot.lissajous(omega.x, omega.y, deltas[i])
   }
}

## Animate them.  (Requires ImageMagick.) num.frames = 120 image.dir =
'images'

if (! file.exists(image.dir)) {
   dir.create(image.dir)
}

deltas = seq(0, 2 * pi, length = num.frames)

for (i in 1 : length(deltas)) {
   png(file = file.path(image.dir, sprintf('img-%03d.png', i)))
   par(mar = c(1, 1, 1, 1))
   par(mfrow = c(length(omega.xs), length(omega.ys)))
   for (omega.x in 1:5) {
       for (omega.y in 1:5) {
           plot.lissajous(omega.x, omega.y, deltas[i])
       }
   }
   dev.off()
}

## This ImageMagick command combines the image files into a GIF animation:
# convert -delay 3 images/*.png images/animation.gif



From iaingallagher at btopenworld.com  Mon Oct 17 21:29:38 2005
From: iaingallagher at btopenworld.com (IAIN GALLAGHER)
Date: Mon, 17 Oct 2005 20:29:38 +0100 (BST)
Subject: [R] Dunn's post hoc test
In-Reply-To: <9FBA56F7-1F7D-42F3-8C61-484F13F58428@MUOhio.edu>
Message-ID: <20051017192938.83713.qmail@web86703.mail.ukl.yahoo.com>

Thanks for your reply Hank. It's not really what I'm
after (though it's good to know).

For the test ( as described in Statistics for the
Biosciences by W. Gardiner. Prentice Hall, 1997) I
have to rank my groups, calculate the average rank,
then subtratc each average rank from every other. Any
value greater than the test statistic is significant.

eg average rank difference table:

   2     5     8    9
---|------------------  
2  -     3     6    7  
   |
5  -     -     3    4 
   |
8  -     -     -    1  
   |
9  -     -     -    -  
   |

I can't get my head around writing an algorithm for
this if I have a vector of average ranks eg averank<-
c(2,5,8,9).

I know I can address the vector by index and that this
is probably the correct route but I can't get the
indexing algorithm right! 

I'm sure someone will point out somethng simple and
I'll kick myself but the help would be appreciated. 

Thanks again.

Iain Gallagher

--- "Martin Henry H. Stevens" <HStevens at MUOhio.edu>
wrote:

> I don't know Dunn's rank test, but the following
> substracts each of  
> the sums of averanks from the next rank.
> 
> cumsum(averank)[-length(averank)] - averank[-1]
> 
> Hank
> 
> On Oct 17, 2005, at 4:30 AM, Iain Gallagher wrote:
> 
> > Hi Everyone.
> >
> > I am rather new to R and I've been trying to
> implement a function to
> > carry out the above test. For a couple of days now
> I've been stuck on
> > how to generate average rank differences.
> >
> > Say I have a vector of average ranks:
> >
> > averank<- c(2,5,9,12)
> >
> > I would like to subtract averank[1] from
> averank[2], averank[1] and
> > averank[2] from averank[3] and averank[1],
> averank[2] and averank[3]
> > from averank[4] etc (I know the syntax is wrong
> here... it's just for
> > illustration) but I can't work out how to do it.
> >
> > Ideally I would like to generate an array showing
> the differences
> > between the average ranks so I could tell at a
> glance which ones were
> > greater than my critical value
> >
> > I've been looking at loops etc but it's a little
> beyond me at the
> > moment. Thanks for any suggestions.
> >
> > Iain Gallagher
> > IIIR
> > Edinburgh University
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting- 
> > guide.html
> >
> 
> Dr. Martin Henry H. Stevens, Assistant Professor
> 338 Pearson Hall
> Botany Department
> Miami University
> Oxford, OH 45056
> 
> Office: (513) 529-4206
> Lab: (513) 529-4262
> FAX: (513) 529-4243
> http://www.cas.muohio.edu/~stevenmh/
> http://www.muohio.edu/ecology/
> http://www.muohio.edu/botany/
> "E Pluribus Unum"
> 
>



From Chai.High at mayo.edu  Mon Oct 17 21:45:09 2005
From: Chai.High at mayo.edu (Chai, High S.)
Date: Mon, 17 Oct 2005 14:45:09 -0500
Subject: [R] Ordinal GEE model
Message-ID: <4B7BAAA18A11954BB15D4070D91E69134DCB4D@excsrv75.mayo.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051017/53339f2f/attachment.pl

From rbaer at atsu.edu  Mon Oct 17 23:12:47 2005
From: rbaer at atsu.edu (Robert Baer)
Date: Mon, 17 Oct 2005 16:12:47 -0500
Subject: [R] Dunn's post hoc test
References: <20051017192938.83713.qmail@web86703.mail.ukl.yahoo.com>
Message-ID: <014b01c5d35f$86805b80$6d0d010a@BigBaer>

I think Martin told you the basic approach to the indexing:

averank<-sort(sample(1:100,25,replace=TRUE))
averank[-1] - averank[-length(averank)]
 [1]  1  1  6  3  4 14  1  1  8  1  2  6  5  4 10  0  3  2  1 11  1  1  2  0
averank
 [1]  4  5  6 12 15 19 33 34 35 43 44 46 52 57 61 71 71 74 76 77 88 89 90 92
92


----- Original Message ----- 
From: "IAIN GALLAGHER" <iaingallagher at btopenworld.com>
To: "Martin Henry H. Stevens" <HStevens at MUOhio.edu>
Cc: <r-help at stat.math.ethz.ch>
Sent: Monday, October 17, 2005 2:29 PM
Subject: Re: [R] Dunn's post hoc test


> Thanks for your reply Hank. It's not really what I'm
> after (though it's good to know).
>
> For the test ( as described in Statistics for the
> Biosciences by W. Gardiner. Prentice Hall, 1997) I
> have to rank my groups, calculate the average rank,
> then subtratc each average rank from every other. Any
> value greater than the test statistic is significant.
>
> eg average rank difference table:
>
>    2     5     8    9
> ---|------------------ 
> 2  -     3     6    7
>    |
> 5  -     -     3    4
>    |
> 8  -     -     -    1
>    |
> 9  -     -     -    -
>    |
>
> I can't get my head around writing an algorithm for
> this if I have a vector of average ranks eg averank<-
> c(2,5,8,9).
>
> I know I can address the vector by index and that this
> is probably the correct route but I can't get the
> indexing algorithm right!
>
> I'm sure someone will point out somethng simple and
> I'll kick myself but the help would be appreciated.
>
> Thanks again.
>
> Iain Gallagher
>
> --- "Martin Henry H. Stevens" <HStevens at MUOhio.edu>
> wrote:
>
> > I don't know Dunn's rank test, but the following
> > substracts each of
> > the sums of averanks from the next rank.
> >
> > cumsum(averank)[-length(averank)] - averank[-1]
> >
> > Hank
> >
> > On Oct 17, 2005, at 4:30 AM, Iain Gallagher wrote:
> >
> > > Hi Everyone.
> > >
> > > I am rather new to R and I've been trying to
> > implement a function to
> > > carry out the above test. For a couple of days now
> > I've been stuck on
> > > how to generate average rank differences.
> > >
> > > Say I have a vector of average ranks:
> > >
> > > averank<- c(2,5,9,12)
> > >
> > > I would like to subtract averank[1] from
> > averank[2], averank[1] and
> > > averank[2] from averank[3] and averank[1],
> > averank[2] and averank[3]
> > > from averank[4] etc (I know the syntax is wrong
> > here... it's just for
> > > illustration) but I can't work out how to do it.
> > >
> > > Ideally I would like to generate an array showing
> > the differences
> > > between the average ranks so I could tell at a
> > glance which ones were
> > > greater than my critical value
> > >
> > > I've been looking at loops etc but it's a little
> > beyond me at the
> > > moment. Thanks for any suggestions.
> > >
> > > Iain Gallagher
> > > IIIR
> > > Edinburgh University
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-
> > > guide.html
> > >
> >
> > Dr. Martin Henry H. Stevens, Assistant Professor
> > 338 Pearson Hall
> > Botany Department
> > Miami University
> > Oxford, OH 45056
> >
> > Office: (513) 529-4206
> > Lab: (513) 529-4262
> > FAX: (513) 529-4243
> > http://www.cas.muohio.edu/~stevenmh/
> > http://www.muohio.edu/ecology/
> > http://www.muohio.edu/botany/
> > "E Pluribus Unum"
> >
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From duncan at wald.ucdavis.edu  Mon Oct 17 23:21:39 2005
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Mon, 17 Oct 2005 14:21:39 -0700
Subject: [R] COM objects with early bindings in R
In-Reply-To: <25D1C2585277D311B9A20000F6CCC71B0719ADA3@DEFRAEX02>
References: <25D1C2585277D311B9A20000F6CCC71B0719ADA3@DEFRAEX02>
Message-ID: <435415E3.7010303@wald.ucdavis.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


[It is best to ask these questions on the omega-help at omegahat.org
mailing list or directly to me as the maintainer of the code.]

There are new versions of the RDCOM packages. They are not
officially released because I haven't had time yet.
But they are available from

 http://www.omegahat.org/Prerelease/


The function generateInterface() is now used to create a better
collection of code than the old createCOMSClass() function.

Then something along the following lines (depending on your taste)
will do create the interface code.  If you want events, set events =
TRUE.  You can output the result into a directory and many files or
a single file or text connection depending on what you want (i.e.
package or direct use).


library(SWinTypeLibs)

library(RDCOMClient)
library(RDCOMServer)

library(RDCOMEvents)

	
e = COMCreate("Excel.Application")
options(error=recover)	

lib = LoadTypeLib(e)	

# Generate the code to interface to ALL the classes.
tmp = generateInterface(lib, "Workbooks", events = FALSE)

out = writeCode(tmp, "ExcelCode.S")


I'd love some feedback.





Pfaff, Bernhard Dr. wrote:
> Dear list member,
> 
> I am using the packages RDCOMClient and SWinTypeLibs and try to import a COM
> object (created in Delphi) in R that is of type 'early binding' instead of
> late 'late binding'. Is there a possibility to do this in R?
> 
> Currently, the following returns an error message:
> 
> l1 = LoadTypeLib("c:\\Programme\\INVESCO\\QaCalendar\\Calendar.dll")
> print(getTypeLibTypes(l1))
>       IQaCalPeriodicInit            QaCalPeriodic            IQaSeriesInit 
>               "dispatch"                "coclass"               "dispatch" 
>                 QaSeries                _QaSerLib                 QaSerLib 
>                "coclass"               "dispatch"                "coclass" 
>       IQaCalSporadicInit            QaCalSporadic           _QaCalendarLib 
>               "dispatch"                "coclass"               "dispatch" 
>            QaCalendarLib QaCalendarIntersectRules          QaDistanceRules 
>                "coclass"                   "enum"                   "enum" 
> createCOMSClass(l1[["QaSerLib"]], "test")
> Error in generateOperators(libEntry, className) : 
> 	invalid subscript type  
> 
> Any help, pointers or a working example is much appreciated.
> 
> Best Regards,
> Bernhard
> 
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    2              
> minor    1.1            
> year     2005           
> month    06             
> day      20             
> language R
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

- --
Duncan Temple Lang                duncan at wald.ucdavis.edu
Department of Statistics          work:  (530) 752-4782
371 Kerr Hall                     fax:   (530) 752-7099
One Shields Ave.
University of California at Davis
Davis, CA 95616, USA
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.2 (Darwin)
Comment: Using GnuPG with Thunderbird - http://enigmail.mozdev.org

iD4DBQFDVBXi9p/Jzwa2QP4RAkO/AJwM9F5zIfobp68N7dNprm+xFtBurQCYx4Le
5MQipX6lXIRc5N9wTzJFvw==
=vlry
-----END PGP SIGNATURE-----



From rbaer at atsu.edu  Tue Oct 18 00:26:32 2005
From: rbaer at atsu.edu (Robert Baer)
Date: Mon, 17 Oct 2005 17:26:32 -0500
Subject: [R] Dunn's post hoc test
References: <20051017192938.83713.qmail@web86703.mail.ukl.yahoo.com>
Message-ID: <018f01c5d369$d406cf10$6d0d010a@BigBaer>

I think I misunderstood your follow-up question.  Try this:

> averank<-sort(sample(1:100,10,replace=TRUE))
> x=matrix(nrow=length(averank),ncol=length(averank))
> for (i in 1:length(averank)){
+ for (j in 1:length(averank)){
+ x[i,j] <- averank[i] - averank[j]
+ }}
> x
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]    0  -14  -15  -16  -16  -23  -37  -51  -67   -79
 [2,]   14    0   -1   -2   -2   -9  -23  -37  -53   -65
 [3,]   15    1    0   -1   -1   -8  -22  -36  -52   -64
 [4,]   16    2    1    0    0   -7  -21  -35  -51   -63
 [5,]   16    2    1    0    0   -7  -21  -35  -51   -63
 [6,]   23    9    8    7    7    0  -14  -28  -44   -56
 [7,]   37   23   22   21   21   14    0  -14  -30   -42
 [8,]   51   37   36   35   35   28   14    0  -16   -28
 [9,]   67   53   52   51   51   44   30   16    0   -12
[10,]   79   65   64   63   63   56   42   28   12     0
> averank
 [1] 15 29 30 31 31 38 52 66 82 94



----- Original Message ----- 
From: "IAIN GALLAGHER" <iaingallagher at btopenworld.com>
To: "Martin Henry H. Stevens" <HStevens at MUOhio.edu>
Cc: <r-help at stat.math.ethz.ch>
Sent: Monday, October 17, 2005 2:29 PM
Subject: Re: [R] Dunn's post hoc test


> Thanks for your reply Hank. It's not really what I'm
> after (though it's good to know).
>
> For the test ( as described in Statistics for the
> Biosciences by W. Gardiner. Prentice Hall, 1997) I
> have to rank my groups, calculate the average rank,
> then subtratc each average rank from every other. Any
> value greater than the test statistic is significant.
>
> eg average rank difference table:
>
>    2     5     8    9
> ---|------------------ 
> 2  -     3     6    7
>    |
> 5  -     -     3    4
>    |
> 8  -     -     -    1
>    |
> 9  -     -     -    -
>    |
>
> I can't get my head around writing an algorithm for
> this if I have a vector of average ranks eg averank<-
> c(2,5,8,9).
>
> I know I can address the vector by index and that this
> is probably the correct route but I can't get the
> indexing algorithm right!
>
> I'm sure someone will point out somethng simple and
> I'll kick myself but the help would be appreciated.
>
> Thanks again.
>
> Iain Gallagher
>
> --- "Martin Henry H. Stevens" <HStevens at MUOhio.edu>
> wrote:
>
> > I don't know Dunn's rank test, but the following
> > substracts each of
> > the sums of averanks from the next rank.
> >
> > cumsum(averank)[-length(averank)] - averank[-1]
> >
> > Hank
> >
> > On Oct 17, 2005, at 4:30 AM, Iain Gallagher wrote:
> >
> > > Hi Everyone.
> > >
> > > I am rather new to R and I've been trying to
> > implement a function to
> > > carry out the above test. For a couple of days now
> > I've been stuck on
> > > how to generate average rank differences.
> > >
> > > Say I have a vector of average ranks:
> > >
> > > averank<- c(2,5,9,12)
> > >
> > > I would like to subtract averank[1] from
> > averank[2], averank[1] and
> > > averank[2] from averank[3] and averank[1],
> > averank[2] and averank[3]
> > > from averank[4] etc (I know the syntax is wrong
> > here... it's just for
> > > illustration) but I can't work out how to do it.
> > >
> > > Ideally I would like to generate an array showing
> > the differences
> > > between the average ranks so I could tell at a
> > glance which ones were
> > > greater than my critical value
> > >
> > > I've been looking at loops etc but it's a little
> > beyond me at the
> > > moment. Thanks for any suggestions.
> > >
> > > Iain Gallagher
> > > IIIR
> > > Edinburgh University
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-
> > > guide.html
> > >
> >
> > Dr. Martin Henry H. Stevens, Assistant Professor
> > 338 Pearson Hall
> > Botany Department
> > Miami University
> > Oxford, OH 45056
> >
> > Office: (513) 529-4206
> > Lab: (513) 529-4262
> > FAX: (513) 529-4243
> > http://www.cas.muohio.edu/~stevenmh/
> > http://www.muohio.edu/ecology/
> > http://www.muohio.edu/botany/
> > "E Pluribus Unum"
> >
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From h.wickham at gmail.com  Tue Oct 18 00:31:39 2005
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 17 Oct 2005 17:31:39 -0500
Subject: [R] Dunn's post hoc test
In-Reply-To: <018f01c5d369$d406cf10$6d0d010a@BigBaer>
References: <20051017192938.83713.qmail@web86703.mail.ukl.yahoo.com>
	<018f01c5d369$d406cf10$6d0d010a@BigBaer>
Message-ID: <f8e6ff050510171531h5db58c7bn50a52b690f8a2910@mail.gmail.com>

Or more simply:

averank<-sort(sample(1:100,10,replace=TRUE))
outer(averank, averank, "-")

Hadley

On 10/17/05, Robert Baer <rbaer at atsu.edu> wrote:
> I think I misunderstood your follow-up question.  Try this:
>
> > averank<-sort(sample(1:100,10,replace=TRUE))
> > x=matrix(nrow=length(averank),ncol=length(averank))
> > for (i in 1:length(averank)){
> + for (j in 1:length(averank)){
> + x[i,j] <- averank[i] - averank[j]
> + }}
> > x
>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
>  [1,]    0  -14  -15  -16  -16  -23  -37  -51  -67   -79
>  [2,]   14    0   -1   -2   -2   -9  -23  -37  -53   -65
>  [3,]   15    1    0   -1   -1   -8  -22  -36  -52   -64
>  [4,]   16    2    1    0    0   -7  -21  -35  -51   -63
>  [5,]   16    2    1    0    0   -7  -21  -35  -51   -63
>  [6,]   23    9    8    7    7    0  -14  -28  -44   -56
>  [7,]   37   23   22   21   21   14    0  -14  -30   -42
>  [8,]   51   37   36   35   35   28   14    0  -16   -28
>  [9,]   67   53   52   51   51   44   30   16    0   -12
> [10,]   79   65   64   63   63   56   42   28   12     0
> > averank
>  [1] 15 29 30 31 31 38 52 66 82 94
>
>
>
> ----- Original Message -----
> From: "IAIN GALLAGHER" <iaingallagher at btopenworld.com>
> To: "Martin Henry H. Stevens" <HStevens at MUOhio.edu>
> Cc: <r-help at stat.math.ethz.ch>
> Sent: Monday, October 17, 2005 2:29 PM
> Subject: Re: [R] Dunn's post hoc test
>
>
> > Thanks for your reply Hank. It's not really what I'm
> > after (though it's good to know).
> >
> > For the test ( as described in Statistics for the
> > Biosciences by W. Gardiner. Prentice Hall, 1997) I
> > have to rank my groups, calculate the average rank,
> > then subtratc each average rank from every other. Any
> > value greater than the test statistic is significant.
> >
> > eg average rank difference table:
> >
> >    2     5     8    9
> > ---|------------------
> > 2  -     3     6    7
> >    |
> > 5  -     -     3    4
> >    |
> > 8  -     -     -    1
> >    |
> > 9  -     -     -    -
> >    |
> >
> > I can't get my head around writing an algorithm for
> > this if I have a vector of average ranks eg averank<-
> > c(2,5,8,9).
> >
> > I know I can address the vector by index and that this
> > is probably the correct route but I can't get the
> > indexing algorithm right!
> >
> > I'm sure someone will point out somethng simple and
> > I'll kick myself but the help would be appreciated.
> >
> > Thanks again.
> >
> > Iain Gallagher
> >
> > --- "Martin Henry H. Stevens" <HStevens at MUOhio.edu>
> > wrote:
> >
> > > I don't know Dunn's rank test, but the following
> > > substracts each of
> > > the sums of averanks from the next rank.
> > >
> > > cumsum(averank)[-length(averank)] - averank[-1]
> > >
> > > Hank
> > >
> > > On Oct 17, 2005, at 4:30 AM, Iain Gallagher wrote:
> > >
> > > > Hi Everyone.
> > > >
> > > > I am rather new to R and I've been trying to
> > > implement a function to
> > > > carry out the above test. For a couple of days now
> > > I've been stuck on
> > > > how to generate average rank differences.
> > > >
> > > > Say I have a vector of average ranks:
> > > >
> > > > averank<- c(2,5,9,12)
> > > >
> > > > I would like to subtract averank[1] from
> > > averank[2], averank[1] and
> > > > averank[2] from averank[3] and averank[1],
> > > averank[2] and averank[3]
> > > > from averank[4] etc (I know the syntax is wrong
> > > here... it's just for
> > > > illustration) but I can't work out how to do it.
> > > >
> > > > Ideally I would like to generate an array showing
> > > the differences
> > > > between the average ranks so I could tell at a
> > > glance which ones were
> > > > greater than my critical value
> > > >
> > > > I've been looking at loops etc but it's a little
> > > beyond me at the
> > > > moment. Thanks for any suggestions.
> > > >
> > > > Iain Gallagher
> > > > IIIR
> > > > Edinburgh University
> > > >
> > > > ______________________________________________
> > > > R-help at stat.math.ethz.ch mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-
> > > > guide.html
> > > >
> > >
> > > Dr. Martin Henry H. Stevens, Assistant Professor
> > > 338 Pearson Hall
> > > Botany Department
> > > Miami University
> > > Oxford, OH 45056
> > >
> > > Office: (513) 529-4206
> > > Lab: (513) 529-4262
> > > FAX: (513) 529-4243
> > > http://www.cas.muohio.edu/~stevenmh/
> > > http://www.muohio.edu/ecology/
> > > http://www.muohio.edu/botany/
> > > "E Pluribus Unum"
> > >
> > >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From machuanxiang at 126.com  Tue Oct 18 04:10:23 2005
From: machuanxiang at 126.com (=?gb2312?B?wu20q8/j?=)
Date: Tue, 18 Oct 2005 10:10:23 +0800 (CST)
Subject: [R] help
Message-ID: <4354598F.000092.32405@m61.126.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051018/e39fe445/attachment.pl

From xprt.wannabe at gmail.com  Tue Oct 18 04:42:25 2005
From: xprt.wannabe at gmail.com (xpRt.wannabe)
Date: Mon, 17 Oct 2005 21:42:25 -0500
Subject: [R] A two-part question about box-percentile plots,
	bpplot(): (1) yaxt="n" doesn't seem to work (2) how to display mean
	values
Message-ID: <a4fecdd70510171942s2d450c6dvc39a3fb4fe5cafc@mail.gmail.com>

Dear List,

I have a two-part question related to bpplot(), a box-percentile plot
function in the Hmisc package.

Take the example given in the Help for bpplot(), for instance.

(1) How does one set but not draw the y-axis?  What I did was,
bpplot(... , yaxt="n"), but that apparently does not work (though it
works for boxplot()).

(2) How does one display the mean value of each variable inside each
respective box-percentile box?  The following is what I did but to no
avail:

> bpplot(x1, x2, x3)
> points(1:1, mean(x1), pch = "1")
> points(1:1, mean(x2), pch = "2")
> points(1:1, mean(x3), pch = "3")

Your help is much appreciated.

platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    1.0
year     2005
month    04
day      18
language R



From ssim at lic.co.nz  Tue Oct 18 16:32:15 2005
From: ssim at lic.co.nz (ssim@lic.co.nz)
Date: 18-Oct-2005 16:32:15 ZE12
Subject: [R] Re : Seperate timestamp data into date and time
Message-ID: <200510180332.j9I3WJwO008572@hypatia.math.ethz.ch>


Dear R list,

I am reading in text file data prepared in Access database by someone. One
of the field contains timestamp data, how can I separate the timestamp data
into two varaibles: date and time. Can I specify the field is in timestamp
format when I first reading in ?

My reading in data are as below:

449  LWT  22/10/2003 15:43:00  441  143
449  LWT  17/11/2003 15:25:00  421  169
449  LWT  14/11/2003 15:04:00  454  166
449  LWT   17/12/2003 5:55:00  428  199
449  LWT   7/12/2003 15:28:00  452  189
449  LWT  15/11/2003 15:20:00  457  167

Thanks in advance.
Stella



From blindglobe at gmail.com  Tue Oct 18 06:14:01 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Tue, 18 Oct 2005 06:14:01 +0200
Subject: [R] Insightful Announces: "R and S-PLUS- Panel Discussion" at
	9th Annual 2005 User Conference
In-Reply-To: <1abe3fa90510171052q538c36eeub66eecfe4cf1544c@mail.gmail.com>
References: <61D7107976B46045BFCAA8BD301E829526178F@nc.insightful.com>
	<1abe3fa90510171052q538c36eeub66eecfe4cf1544c@mail.gmail.com>
Message-ID: <1abe3fa90510172114y2a662aear343402cb779c0bdc@mail.gmail.com>

So the answer seems to be Insightful folks and industry folks.

On 10/17/05, A.J. Rossini <blindglobe at gmail.com> wrote:
> But who is on the panel?
>
> On 10/17/05, Michael O'Connell <moconnell at insightful.com> wrote:
> > Event: 2005 Insightful User Conference
> >
> > Dates: Oct 26-27, 2005
> >
> > Location: Princeton, NJ
> >
> > URL: http://www.insightful.com/news_events/2005uc/ for details on pricing,
> > hotel accommodations and to register for this event.
> >
> >
> >
> > The Insightful 2005 User Conference is being held October 26th-27th in
> > Princeton, NJ. This year's conference focuses on the techniques and
> > methodologies pivotal to the increased demand for statistics in business
> > organizations. The conference program will include presentations by S-PLUS
> > experts from market-leading companies such as Novartis, Procter & Gamble,
> > Amgen, and MCI.
> >
> >
> >
> > Of particular interest to subscribers to r-help is the panel discussion on
> > future plans for compatibility between S-PLUS and R. The panel discussion is
> > on the topic "Ensuring Compatibility and Portability Between the Two Prime
> > Dialects of the S Language". Martin DeBono from Insightful will moderate a
> > panel of experts in both S-PLUS and R to discuss plans for a common packaging
> > system and tools to make it easy to convert R packages to S-PLUS. There will
> > also be broader discussion about how the users of each dialect can coordinate
> > efforts to create a vibrant community focused on the continued advancement of
> > the S Language.
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> >
>
>
> --
> best,
> -tony
>
> blindglobe at gmail.com
> Muttenz, Switzerland.
> "Commit early,commit often, and commit in a repository from which we can easily
> roll-back your mistakes" (AJR, 4Jan05).
>


--
best,
-tony

blindglobe at gmail.com
Muttenz, Switzerland.
"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).



From edd at debian.org  Tue Oct 18 06:15:12 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 17 Oct 2005 23:15:12 -0500
Subject: [R] Re : Seperate timestamp data into date and time
In-Reply-To: <200510180332.j9I3WJwO008572@hypatia.math.ethz.ch>
References: <200510180332.j9I3WJwO008572@hypatia.math.ethz.ch>
Message-ID: <17236.30416.461788.100811@basebud.nulle.part>


On 18 October 2005 at 16:32, ssim at lic.co.nz wrote:
| I am reading in text file data prepared in Access database by someone. One
| of the field contains timestamp data, how can I separate the timestamp data
| into two varaibles: date and time. Can I specify the field is in timestamp
| format when I first reading in ?
| 
| My reading in data are as below:
| 
| 449  LWT  22/10/2003 15:43:00  441  143
| 449  LWT  17/11/2003 15:25:00  421  169
| 449  LWT  14/11/2003 15:04:00  454  166
| 449  LWT   17/12/2003 5:55:00  428  199
| 449  LWT   7/12/2003 15:28:00  452  189
| 449  LWT  15/11/2003 15:20:00  457  167

You probably don't want to split it into date and time, but rather read it
into R's DateTimeClasses which encompass both:

Let's assign the time to a variable:
> datetimes <- c("22/10/2003 15:43:00", "17/11/2003 15:25:00", "14/11/2003 15:04:00", "17/12/2003 5:55:00", "7/12/2003 15:28:00", "15/11/2003 15:20:00")
> datetimes
[1] "22/10/2003 15:43:00" "17/11/2003 15:25:00" "14/11/2003 15:04:00"
[4] "17/12/2003 5:55:00"  "7/12/2003 15:28:00"  "15/11/2003 15:20:00"

and then read them using the strptime() function with a matching argument:

> parsed <- strptime(datetimes, "%d/%m/%Y %H:%M:%S")
> parsed
[1] "2003-10-22 15:43:00" "2003-11-17 15:25:00" "2003-11-14 15:04:00"
[4] "2003-12-17 05:55:00" "2003-12-07 15:28:00" "2003-11-15 15:20:00"

That gives time objects:

> class(parsed)
[1] "POSIXt"  "POSIXlt"

The time classes are very, very powerful. They may also appear to be
confusing, so make sure you really the available documentation, incl some R
News articles, the help pages etc pp

These time objects can be formatted any way you want them:

> format(parsed, "%d/%m/%y")
[1] "22/10/03" "17/11/03" "14/11/03" "17/12/03" "07/12/03" "15/11/03"
> format(parsed, "%H:%M")
[1] "15:43" "15:25" "15:04" "05:55" "15:28" "15:20"
 
Hope this helps, Dirk

-- 
Statistics: The (futile) attempt to offer certainty about uncertainty.
         -- Roger Koenker, 'Dictionary of Received Ideas of Statistics'



From kovacs at primal.ucdavis.edu  Tue Oct 18 06:29:12 2005
From: kovacs at primal.ucdavis.edu (Kent Kovacs)
Date: Mon, 17 Oct 2005 21:29:12 -0700
Subject: [R] vector memory
Message-ID: <5.1.0.14.2.20051017212746.02a018c0@primal.ucdavis.edu>


Hi,

I am running a generalized additive semi-parametric regression with five 
non-parametric variables, and I get the error "vector memory exhausted 
(limit reached?)". Do you know how to increase vector memory in R?

Kent



From f.harrell at vanderbilt.edu  Tue Oct 18 06:35:26 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Mon, 17 Oct 2005 23:35:26 -0500
Subject: [R] A two-part question about box-percentile plots,
 bpplot(): (1) yaxt="n" doesn't seem to work (2) how to display
 mean	values
In-Reply-To: <a4fecdd70510171942s2d450c6dvc39a3fb4fe5cafc@mail.gmail.com>
References: <a4fecdd70510171942s2d450c6dvc39a3fb4fe5cafc@mail.gmail.com>
Message-ID: <43547B8E.60404@vanderbilt.edu>

xpRt.wannabe wrote:
> Dear List,
> 
> I have a two-part question related to bpplot(), a box-percentile plot
> function in the Hmisc package.
> 
> Take the example given in the Help for bpplot(), for instance.
> 
> (1) How does one set but not draw the y-axis?  What I did was,
> bpplot(... , yaxt="n"), but that apparently does not work (though it
> works for boxplot()).

Try doing par(yaxt="n") before bpplot.

> 
> (2) How does one display the mean value of each variable inside each
> respective box-percentile box?  The following is what I did but to no
> avail:
> 
> 
>>bpplot(x1, x2, x3)
>>points(1:1, mean(x1), pch = "1")
>>points(1:1, mean(x2), pch = "2")
>>points(1:1, mean(x3), pch = "3")

w <- bpplot(x1, x2, x3)
points(w[1],mean(x1))
points(w[2],mean(x2))
etc.

Better may be to use bwplot(..., panel=panel.bpplot) which shows the 
mean automatically with a dot.  By default it doesn't show all the 
percentiles.

Frank

> 
> 
> Your help is much appreciated.
> 
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    1.0
> year     2005
> month    04
> day      18
> language R
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From vheijst at few.eur.nl  Tue Oct 18 06:54:10 2005
From: vheijst at few.eur.nl (vheijst@few.eur.nl)
Date: Tue, 18 Oct 2005 06:54:10 +0200 (MEST)
Subject: [R] Memory problems with large dataset in rpart
Message-ID: <1272.212.238.166.215.1129611250.squirrel@webmail.eur.nl>

Dear helpers,

I am a Dutch student from the Erasmus University. For my Bachelor thesis I
have written a script in R using boosting by means of classification and
regression trees. This script uses the function the predefined function
rpart. My input file consists of about 4000 vectors each having 2210
dimensions. In the third iteration R complains of a lack of memory,
although in each iteration every variable is removed from the memory. Thus
the first two iterations run without any problems.

My computer runs on Windows XP and has 1 gigabye of internal memory.
I tried R using more memory by refiguring the swap files as memtioned in
the FAQ (/3gb), but I didn't succeed in making this work.
The command round(memory.limit()/1048576.0, 2) gives 1023.48

If such an increase of memory can not succeed, perhaps the size of the
rpart object could be reduced by not storing unnecessary information.
The rpart function call is (the calls of FALSE is to try to reduce the
size of the fit object):
fit <- rpart(price ~ ., data = trainingset,
control=rpart.control(maxdepth=2,cp=0.001),model=FALSE,x=FALSE,y=FALSE)

This fit object is later called in 2 predict functions, for example:
predict(fit,newdata=sample)

Can anybody please help me by letting R use more memory (for example swap)
or can anybody help me reducing the size of the fit object?

Kind regards
Dennis van Heijst
Student Informatics & Economics
Erasmus University Rotterdam
The Netherlands



From p.connolly at hortresearch.co.nz  Tue Oct 18 06:56:59 2005
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Tue, 18 Oct 2005 17:56:59 +1300
Subject: [R] high resolution images for publication
In-Reply-To: <1129242802.6062.20.camel@localhost.localdomain>
References: <005d01c5d03b$e0cfa680$4c01a8c0@Chris> 
	<1129242802.6062.20.camel@localhost.localdomain>
Message-ID: <20051018045659.GH18619@hortresearch.co.nz>

On Thu, 13-Oct-2005 at 05:33PM -0500, Marc Schwartz (via MN) wrote:

|> On Thu, 2005-10-13 at 15:20 -0600, Chris Buddenhagen wrote:
|> > Dear all
|> 
|> > I am using R to produce ordinations library(vegan) and the plot function
|> > produced looks great on the screen but when I send it to jpg or pdf or eps
|> > the resolution is not so good. Can you tell me how to get high resolution
|> > images out of R for publication?
|> 
|> It would be helpful to see the actual code that you are using, as is
|> asked for in the Posting Guide.
|> 
|> For publication, it would be rare to want to use a bitmapped format such
|> as jpg/png.

300 dpi PNGs work quite well in my experience, and not many will take
PDF.  It helps if you know what size they're to end up and make plots
accordingly to avoid any need to resize.  JPGs are good for
photographs, but not for line work.

|> 
|> pdf and eps are vector based formats and would be generally preferred
|> over the above.

For publishers who insist on TIFF format, it should be noted that
despite the fact that they're very large, they compress well and can
be decompressed by the publisher.

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From sumantab at ambaresearch.com  Tue Oct 18 07:38:55 2005
From: sumantab at ambaresearch.com (Sumanta Basak)
Date: Tue, 18 Oct 2005 11:08:55 +0530
Subject: [R] FIGARCH
Message-ID: <14850601FF012647A90A5DB31F96DB371D1703@INBLRDC01.BANG.irpvl.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051018/611dd920/attachment.pl

From Kiermeier.Andreas at saugov.sa.gov.au  Tue Oct 18 08:02:51 2005
From: Kiermeier.Andreas at saugov.sa.gov.au (Kiermeier, Andreas (PIRSA - SARDI))
Date: Tue, 18 Oct 2005 15:32:51 +0930
Subject: [R] Lattice graphics strip labels for shingles
Message-ID: <5801DF3664AC854AA3CC2DB83E718D3005FB2D4B@sagemsg0006.sagemsmrd01.sa.gov.au>

Dear all,

back in 2002 Martin Henry H. Stevens wrote
(https://stat.ethz.ch/pipermail/r-help/2002-May/019851.html)

> How do I control the text in strips? Specifically, I want to put in the 
> ranges generated in shingle(x) where x is continuous.

with an answer from Deepyan Sarkar (see strip.new towards the end of this
message).  I assume that the answer worked back then, but I've tried to
implement it today, with little success.  I think that it may have to do
with namespaces - but I'm not sure.

Here is the code I used after creating the strip.new function (in
.GlobalEnv).

> x1 <- rnorm(100)
> x2 <- rnorm(100)
> x3 <- rnorm(100)
> 
> br <- matrix(c(seq(-3, 3, by=0.5), seq(-3, 3, by=0.5)+0.5), ncol=2,
byrow=FALSE)
> 
> x3.sh <- shingle(x3, intervals=br)
> 
> xyplot(x1 ~ x2 | x3.sh,
+        strip=function(shingle.intervals,...)
+        strip.new(shingle.intervals=br, ...))
Error in strip.new(shingle.intervals = br, ...) : 
	couldn't find function "grid.rect"

I realize that there have been changes in strip.default since then, but even
attempting to create my own (modified) version of it (in .GlobalEnv) comes
up with a similar error, namely

Error in strip.default(shingle.intervals = br, ...) : 
	couldn't find function "pushViewport"

Any help would be greatly appreciated - please reply directly to me as I am
not currently on the list.

Regards,

Andreas



strip.new <-
    function(which.given,
             which.panel,
             var.name,
             factor.levels,
             shingle.intervals,
             strip.names = c(FALSE, TRUE),
             style = 1,
             bg = trellis.par.get("strip.background")$col[which.given],
             fg = trellis.par.get("strip.shingle")$col[which.given],
             par.strip.text = trellis.par.get("add.text"))
{
    name <- var.name[which.given]
    level <- which.panel[which.given]
    strip.names <- rep(strip.names, length = 2)
    
    if (is.null(factor.levels)) { # means this is a  shingle, as opposed to
a  
     
                                  ## factor
        if (is.null(shingle.intervals)) 
           stop("both factor.levels and shingle.intervals cannot be NULL")

        strip.names <- strip.names[2]
        grid.rect(gp = gpar(fill=bg))
        t <- range(shingle.intervals)
        r <- (range(shingle.intervals[level,])-t[1])/diff(t)
        grid.rect(x = unit(r%*%c(.5,.5),"npc"), width = unit(diff(r),"npc"),
                  gp = gpar(col=fg, fill=fg))
        if (strip.names) grid.text(label = paste(shingle.intervals[level,1],
                                   shingle.intervals[level, 2], sep = ' ,
'),
                                   gp = gpar(col = par.strip.text$col,
                                   font = par.strip.text$font,
                                   fontsize = par.strip.text$cex *
                                   current.viewport()$gp$fontsize))
        
        grid.rect()
    }
    else strip.default(which.given,
                       which.panel,
                       var.name,
                       factor.levels = factor.levels,
                       shingle.intervals = shingle.intervals,
                       strip.names,
                       style,
                       bg,
                       fg,
                       par.strip.text)
}



_____________________________
Dr Andreas Kiermeier
Statistician
SARDI FOOD SAFETY PROGRAM

33 Flemington Street
Glenside   SA   5065
Ph:	+61 8 8207 7884
Fax:	+61 8 8207 7854
Mob:	0423 028 565

Email: Kiermeier.Andreas at saugov.sa.gov.au
_____________________________

The information in this e-mail and attachments (if any) may be confidential
and/or legally privileged. If you are not the intended recipient, any
disclosure, copying, distribution or action taken is prohibited. SARDI, The
South Australian Research and Development Institute, is the research
division of Primary Industries and Resources (SA)



From ripley at stats.ox.ac.uk  Tue Oct 18 08:50:39 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Oct 2005 07:50:39 +0100 (BST)
Subject: [R] Memory problems with large dataset in rpart
In-Reply-To: <1272.212.238.166.215.1129611250.squirrel@webmail.eur.nl>
References: <1272.212.238.166.215.1129611250.squirrel@webmail.eur.nl>
Message-ID: <Pine.LNX.4.61.0510180742030.13607@gannet.stats>

Looks like you have missed the section in the rw-FAQ entitled

     2.9 There seems to be a limit on the memory it uses!

and not set --max-mem-size (which defaults to 1Gb on your system).

However, it looks like your problem is memory fragmentation, and trying to 
run 1Gb tasks in a 2Gb address space is intrinsically a problem to which 
the only solution is a 64-bit version of R.

BTW, /3GB is nothing whatsoever to do with `swap files': if both OS and 
application are configured correctly it increases the user address space 
*for that process* to /3GB (whereas swap space is shared between 
processes).

On Tue, 18 Oct 2005 vheijst at few.eur.nl wrote:

> Dear helpers,
>
> I am a Dutch student from the Erasmus University. For my Bachelor thesis I
> have written a script in R using boosting by means of classification and
> regression trees. This script uses the function the predefined function
> rpart. My input file consists of about 4000 vectors each having 2210
> dimensions. In the third iteration R complains of a lack of memory,
> although in each iteration every variable is removed from the memory. Thus
> the first two iterations run without any problems.
>
> My computer runs on Windows XP and has 1 gigabye of internal memory.
> I tried R using more memory by refiguring the swap files as memtioned in
> the FAQ (/3gb), but I didn't succeed in making this work.
> The command round(memory.limit()/1048576.0, 2) gives 1023.48
>
> If such an increase of memory can not succeed, perhaps the size of the
> rpart object could be reduced by not storing unnecessary information.
> The rpart function call is (the calls of FALSE is to try to reduce the
> size of the fit object):
> fit <- rpart(price ~ ., data = trainingset,
> control=rpart.control(maxdepth=2,cp=0.001),model=FALSE,x=FALSE,y=FALSE)
>
> This fit object is later called in 2 predict functions, for example:
> predict(fit,newdata=sample)
>
> Can anybody please help me by letting R use more memory (for example swap)
> or can anybody help me reducing the size of the fit object?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rhancock at email.arizona.edu  Tue Oct 18 09:41:26 2005
From: rhancock at email.arizona.edu (Roeland Hancock)
Date: Tue, 18 Oct 2005 00:41:26 -0700
Subject: [R] RMySQL problems
Message-ID: <64701BA5-A1F4-40B4-9129-53180EE395D4@email.arizona.edu>

I get the following error trying to connect to a MySQL database:

 > library(RMySQL)
Loading required package: DBI
 > drv<-dbDriver("MySQL")
 > con<-dbConnect(drv, user="hothand", password=xxx,  
host="localhost", dbname="hh03");
Error in mysqlNewConnection(drv, ...) : RS-DBI driver: (could not  
connect hothand at localhost on dbname "hh03"
)

This script worked a few days ago, and I haven't made any system  
changes since then. I can connect to mysql from php and the mysql  
console. I've also reinstalled the DBI and RMySQL packages, to no avail.

Any suggestions?

Thanks in advance.


 > version
          _
platform powerpc-apple-darwin7.9.0
arch     powerpc
os       darwin7.9.0
system   powerpc, darwin7.9.0
status
major    2
minor    1.1
year     2005
month    06
day      20
language R

DBI version 0.1-9
RMySQL 0.5-5

/usr/local/mysql/bin/mysql  Ver 12.22 Distrib 4.0.25, for apple- 
darwin7.9.0 (powerpc)



From ecoinformatics at gmail.com  Tue Oct 18 10:50:41 2005
From: ecoinformatics at gmail.com (ecoinfo)
Date: Tue, 18 Oct 2005 10:50:41 +0200
Subject: [R] Ways to speed up R code?
Message-ID: <15f8e67d0510180150h6302721fr188417beed2fbb38@mail.gmail.com>

Hi R-users:

Yesterday I ran a R code for 9 hours and it did not show any sign to
stop. Then I interrupted it and found it had completed 82.5%.

This morning I decided to wait for another 11 hours to see what will
happen. Wait a minute, I heard that transforming data.frame to matrix
will make R code faster. Then I made the modification in my R code.
Oooh, the new code finished within 30 minutes!!

Are there any other tips to speed up R program? Or someone could
indicate me some documents or websites on R code optimization?

#OS: Win XP, CPU: Pentium IV, 3.20G, Memory: 1G
#for() loop: 1000*1616*3*41, 3 data.frames (dim = c(1616,5), c(1616),
c(1616) respectively)

Thanks in advance,
Xiaohua

--
Xiaohua Dai, Dr.
--------------------------------------------------------------------------------
* Postdoctoral in elephant-tree ecosystem simulation
---------------------------------------------------------------------------------
Centre for Systems Research, Durban Institute of Technology
P.O.Box 953, Durban 4000, South Africa
Tel: +27-31-2042737(O) Fax: +27-31-2042736(O)
Mobile: +27-723682954
Publications: http://www.getcited.org/?MBR=11061629



From ozric at web.de  Tue Oct 18 11:04:17 2005
From: ozric at web.de (Christian Schulz)
Date: Tue, 18 Oct 2005 11:04:17 +0200
Subject: [R] RMySQL problems
In-Reply-To: <64701BA5-A1F4-40B4-9129-53180EE395D4@email.arizona.edu>
References: <64701BA5-A1F4-40B4-9129-53180EE395D4@email.arizona.edu>
Message-ID: <4354BA91.3020109@web.de>

Hi,

i have recently same problems, but when i  add a new user without 
password  it works, but i could
not recognize why the user with password didn't work. After a new mysql  
(Win-XP mysqll 5.0.13 rc )
installation it works normal.

regards, christian

DBI version 0.1-9
RMySQL 0.5-5

         _             
platform i386-pc-mingw32
arch     i386          
os       mingw32       
system   i386, mingw32 
status   Patched       
major    2             
minor    1.1           
year     2005          
month    09            
day      07            
language R           

I use


>I get the following error trying to connect to a MySQL database:
>
> > library(RMySQL)
>Loading required package: DBI
> > drv<-dbDriver("MySQL")
> > con<-dbConnect(drv, user="hothand", password=xxx,  
>host="localhost", dbname="hh03");
>Error in mysqlNewConnection(drv, ...) : RS-DBI driver: (could not  
>connect hothand at localhost on dbname "hh03"
>)
>
>This script worked a few days ago, and I haven't made any system  
>changes since then. I can connect to mysql from php and the mysql  
>console. I've also reinstalled the DBI and RMySQL packages, to no avail.
>
>Any suggestions?
>
>Thanks in advance.
>
>
> > version
>          _
>platform powerpc-apple-darwin7.9.0
>arch     powerpc
>os       darwin7.9.0
>system   powerpc, darwin7.9.0
>status
>major    2
>minor    1.1
>year     2005
>month    06
>day      20
>language R
>
>DBI version 0.1-9
>RMySQL 0.5-5
>
>/usr/local/mysql/bin/mysql  Ver 12.22 Distrib 4.0.25, for apple- 
>darwin7.9.0 (powerpc)
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>



From bhs2 at mevik.net  Tue Oct 18 11:19:44 2005
From: bhs2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Tue, 18 Oct 2005 11:19:44 +0200
Subject: [R] Insightful Announces: "R and S-PLUS- Panel Discussion" at
 9th Annual 2005 User Conference
In-Reply-To: <61D7107976B46045BFCAA8BD301E829526178F@nc.insightful.com>
	(Michael O'Connell's message of "Mon, 17 Oct 2005 13:35:09 -0400")
References: <61D7107976B46045BFCAA8BD301E829526178F@nc.insightful.com>
Message-ID: <m08xwruqq7.fsf@bar.nemo-project.org>

Michael O'Connell wrote:

> tools to make it easy to convert R packages to S-PLUS.

Not the other way around as well?

-- 
Bj??rn-Helge Mevik



From murdoch at stats.uwo.ca  Tue Oct 18 11:45:02 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 18 Oct 2005 05:45:02 -0400
Subject: [R] Ways to speed up R code?
In-Reply-To: <15f8e67d0510180150h6302721fr188417beed2fbb38@mail.gmail.com>
References: <15f8e67d0510180150h6302721fr188417beed2fbb38@mail.gmail.com>
Message-ID: <4354C41E.8030107@stats.uwo.ca>

ecoinfo wrote:
> Hi R-users:
> 
> Yesterday I ran a R code for 9 hours and it did not show any sign to
> stop. Then I interrupted it and found it had completed 82.5%.
> 
> This morning I decided to wait for another 11 hours to see what will
> happen. Wait a minute, I heard that transforming data.frame to matrix
> will make R code faster. Then I made the modification in my R code.
> Oooh, the new code finished within 30 minutes!!
> 
> Are there any other tips to speed up R program? Or someone could
> indicate me some documents or websites on R code optimization?
> 
> #OS: Win XP, CPU: Pentium IV, 3.20G, Memory: 1G
> #for() loop: 1000*1616*3*41, 3 data.frames (dim = c(1616,5), c(1616),
> c(1616) respectively)

- As you found, indexing operations on matrices are much faster than on 
dataframes.

- Avoid growing allocations:  calculate the size you need, then allocate 
it all at once.

- Vectorize calculations.

- Use Rprof() to identify where your code is spending its time, and 
concentrate your efforts on that area.  Perhaps translate some essential 
routines into compiled C or Fortran.

- For a smaller improvement that might not suit your application, 
convert factors to their numeric codes.

- Break up long calculations into smaller pieces, so you can write out 
intermediate values.  This doesn't necessarily speed it up, but it lets 
you stop and restart the calculation.  It may also make it more suited 
to running on a cluster of computers instead of just one.

- Limit your use of memory so you don't end up using a swap file.  Do 
this by only keeping objects that will be used later, removing others. 
(With the size of objects you were working with this may not be an issue.)

Duncan Murdoch



From tschoenhoff at gmail.com  Tue Oct 18 12:17:34 2005
From: tschoenhoff at gmail.com (=?ISO-8859-1?Q?Thomas_Sch=F6nhoff?=)
Date: Tue, 18 Oct 2005 12:17:34 +0200
Subject: [R] Ways to speed up R code?
In-Reply-To: <15f8e67d0510180150h6302721fr188417beed2fbb38@mail.gmail.com>
References: <15f8e67d0510180150h6302721fr188417beed2fbb38@mail.gmail.com>
Message-ID: <5ad2dec0510180317j12b21a35v@mail.gmail.com>

Hello,


2005/10/18, ecoinfo <ecoinformatics at gmail.com>:
> Hi R-users:
>
> Yesterday I ran a R code for 9 hours and it did not show any sign to
> stop. Then I interrupted it and found it had completed 82.5%.
>
> This morning I decided to wait for another 11 hours to see what will
> happen. Wait a minute, I heard that transforming data.frame to matrix
> will make R code faster. Then I made the modification in my R code.
> Oooh, the new code finished within 30 minutes!!
>
> Are there any other tips to speed up R program? Or someone could
> indicate me some documents or websites on R code optimization?
>
> #OS: Win XP, CPU: Pentium IV, 3.20G, Memory: 1G
> #for() loop: 1000*1616*3*41, 3 data.frames (dim = c(1616,5), c(1616),
> c(1616) respectively)
>

RSiteSearch("speed up R code") gives 346 hits, so this problem has
been discussed on this list some time before. Maybe something worth to
pay attention to?


regards
Thomas



From Sebastian.Leuzinger at unibas.ch  Tue Oct 18 12:19:34 2005
From: Sebastian.Leuzinger at unibas.ch (Sebastian Leuzinger)
Date: Tue, 18 Oct 2005 12:19:34 +0200
Subject: [R] change factor labels
Message-ID: <200510181219.35232.Sebastian.Leuzinger@unibas.ch>

it must be terribly simple, can someone quickly help me?

test <- data.frame(y=c(1:10), x=as.factor(c(rep("a",5),rep("b",5))))

how can i change the factor labels from "a" and "b" to for example "u"  and 
"v"?

i don't succeed with factor()

thanks a lot

------------------------------------------------
Sebastian Leuzinger
Institute of Botany, University of Basel



From dimitris.rizopoulos at med.kuleuven.be  Tue Oct 18 12:39:14 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Tue, 18 Oct 2005 12:39:14 +0200
Subject: [R] change factor labels
References: <200510181219.35232.Sebastian.Leuzinger@unibas.ch>
Message-ID: <001901c5d3d0$2f481a80$0540210a@www.domain>

one way is to use:

levels(test$x) <- c("u", "v")


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Sebastian Leuzinger" <Sebastian.Leuzinger at unibas.ch>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, October 18, 2005 12:19 PM
Subject: [R] change factor labels


> it must be terribly simple, can someone quickly help me?
>
> test <- data.frame(y=c(1:10), x=as.factor(c(rep("a",5),rep("b",5))))
>
> how can i change the factor labels from "a" and "b" to for example 
> "u"  and
> "v"?
>
> i don't succeed with factor()
>
> thanks a lot
>
> ------------------------------------------------
> Sebastian Leuzinger
> Institute of Botany, University of Basel
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From ecoinformatics at gmail.com  Tue Oct 18 13:14:18 2005
From: ecoinformatics at gmail.com (ecoinfo)
Date: Tue, 18 Oct 2005 13:14:18 +0200
Subject: [R] Ways to speed up R code?
In-Reply-To: <5ad2dec0510180317j12b21a35v@mail.gmail.com>
References: <15f8e67d0510180150h6302721fr188417beed2fbb38@mail.gmail.com>
	<5ad2dec0510180317j12b21a35v@mail.gmail.com>
Message-ID: <15f8e67d0510180414w1c689bd6vbbf7e9bbee74756b@mail.gmail.com>

RSiteSearch("speed up R code")
== search for a page having the words (speed, up, R, and code)
surely R is found everywhere.
Although there are some useful archives, many of them are not.
Furthermore, I need a general instruction instead of pieces (e.g.
Patrick's book and Duncan's rules)

If I use "speed up R code" as a phrase, then only one not-very-useful hit.

Thanks,
Xiaohua



On 10/18/05, Thomas Sch??nhoff <tschoenhoff at gmail.com> wrote:
> Hello,
>
>
> 2005/10/18, ecoinfo <ecoinformatics at gmail.com>:
> > Hi R-users:
> >
> > Yesterday I ran a R code for 9 hours and it did not show any sign to
> > stop. Then I interrupted it and found it had completed 82.5%.
> >
> > This morning I decided to wait for another 11 hours to see what will
> > happen. Wait a minute, I heard that transforming data.frame to matrix
> > will make R code faster. Then I made the modification in my R code.
> > Oooh, the new code finished within 30 minutes!!
> >
> > Are there any other tips to speed up R program? Or someone could
> > indicate me some documents or websites on R code optimization?
> >
> > #OS: Win XP, CPU: Pentium IV, 3.20G, Memory: 1G
> > #for() loop: 1000*1616*3*41, 3 data.frames (dim = c(1616,5), c(1616),
> > c(1616) respectively)
> >
>
> RSiteSearch("speed up R code") gives 346 hits, so this problem has
> been discussed on this list some time before. Maybe something worth to
> pay attention to?
>
>
> regards
> Thomas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ecoinformatics at gmail.com  Tue Oct 18 13:19:41 2005
From: ecoinformatics at gmail.com (ecoinfo)
Date: Tue, 18 Oct 2005 13:19:41 +0200
Subject: [R] Ways to speed up R code?
In-Reply-To: <15f8e67d0510180414w1c689bd6vbbf7e9bbee74756b@mail.gmail.com>
References: <15f8e67d0510180150h6302721fr188417beed2fbb38@mail.gmail.com>
	<5ad2dec0510180317j12b21a35v@mail.gmail.com>
	<15f8e67d0510180414w1c689bd6vbbf7e9bbee74756b@mail.gmail.com>
Message-ID: <15f8e67d0510180419yf535044j678983f4e60127cf@mail.gmail.com>

Sorry for my poor English. One sentence in my last emails should be
"Furthermore, I need a general instruction (e.g. Patrick's book and
Duncan's rules) instead of pieces". Hope I was not misunderstood.

Thanks for Patrick and Duncan's useful replies.
Xiaohua

On 10/18/05, ecoinfo <ecoinformatics at gmail.com> wrote:
> RSiteSearch("speed up R code")
> == search for a page having the words (speed, up, R, and code)
> surely R is found everywhere.
> Although there are some useful archives, many of them are not.
> Furthermore, I need a general instruction instead of pieces (e.g.
> Patrick's book and Duncan's rules)
>
> If I use "speed up R code" as a phrase, then only one not-very-useful hit.
>
> Thanks,
> Xiaohua
>
>
>
> On 10/18/05, Thomas Sch??nhoff <tschoenhoff at gmail.com> wrote:
> > Hello,
> >
> >
> > 2005/10/18, ecoinfo <ecoinformatics at gmail.com>:
> > > Hi R-users:
> > >
> > > Yesterday I ran a R code for 9 hours and it did not show any sign to
> > > stop. Then I interrupted it and found it had completed 82.5%.
> > >
> > > This morning I decided to wait for another 11 hours to see what will
> > > happen. Wait a minute, I heard that transforming data.frame to matrix
> > > will make R code faster. Then I made the modification in my R code.
> > > Oooh, the new code finished within 30 minutes!!
> > >
> > > Are there any other tips to speed up R program? Or someone could
> > > indicate me some documents or websites on R code optimization?
> > >
> > > #OS: Win XP, CPU: Pentium IV, 3.20G, Memory: 1G
> > > #for() loop: 1000*1616*3*41, 3 data.frames (dim = c(1616,5), c(1616),
> > > c(1616) respectively)
> > >
> >
> > RSiteSearch("speed up R code") gives 346 hits, so this problem has
> > been discussed on this list some time before. Maybe something worth to
> > pay attention to?
> >
> >
> > regards
> > Thomas
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>



From pburns at pburns.seanet.com  Tue Oct 18 13:25:03 2005
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Tue, 18 Oct 2005 12:25:03 +0100
Subject: [R] Ways to speed up R code?
In-Reply-To: <15f8e67d0510180419yf535044j678983f4e60127cf@mail.gmail.com>
References: <15f8e67d0510180150h6302721fr188417beed2fbb38@mail.gmail.com>	<5ad2dec0510180317j12b21a35v@mail.gmail.com>	<15f8e67d0510180414w1c689bd6vbbf7e9bbee74756b@mail.gmail.com>
	<15f8e67d0510180419yf535044j678983f4e60127cf@mail.gmail.com>
Message-ID: <4354DB8F.4000604@pburns.seanet.com>

What might be most likely for misunderstanding is "Patrick's book"
since my message was private.  The book is S Poetry.

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

ecoinfo wrote:

>Sorry for my poor English. One sentence in my last emails should be
>"Furthermore, I need a general instruction (e.g. Patrick's book and
>Duncan's rules) instead of pieces". Hope I was not misunderstood.
>
>Thanks for Patrick and Duncan's useful replies.
>Xiaohua
>
>On 10/18/05, ecoinfo <ecoinformatics at gmail.com> wrote:
>  
>
>>RSiteSearch("speed up R code")
>>== search for a page having the words (speed, up, R, and code)
>>surely R is found everywhere.
>>Although there are some useful archives, many of them are not.
>>Furthermore, I need a general instruction instead of pieces (e.g.
>>Patrick's book and Duncan's rules)
>>
>>If I use "speed up R code" as a phrase, then only one not-very-useful hit.
>>
>>Thanks,
>>Xiaohua
>>
>>
>>
>>On 10/18/05, Thomas Sch??nhoff <tschoenhoff at gmail.com> wrote:
>>    
>>
>>>Hello,
>>>
>>>
>>>2005/10/18, ecoinfo <ecoinformatics at gmail.com>:
>>>      
>>>
>>>>Hi R-users:
>>>>
>>>>Yesterday I ran a R code for 9 hours and it did not show any sign to
>>>>stop. Then I interrupted it and found it had completed 82.5%.
>>>>
>>>>This morning I decided to wait for another 11 hours to see what will
>>>>happen. Wait a minute, I heard that transforming data.frame to matrix
>>>>will make R code faster. Then I made the modification in my R code.
>>>>Oooh, the new code finished within 30 minutes!!
>>>>
>>>>Are there any other tips to speed up R program? Or someone could
>>>>indicate me some documents or websites on R code optimization?
>>>>
>>>>#OS: Win XP, CPU: Pentium IV, 3.20G, Memory: 1G
>>>>#for() loop: 1000*1616*3*41, 3 data.frames (dim = c(1616,5), c(1616),
>>>>c(1616) respectively)
>>>>
>>>>        
>>>>
>>>RSiteSearch("speed up R code") gives 346 hits, so this problem has
>>>been discussed on this list some time before. Maybe something worth to
>>>pay attention to?
>>>
>>>
>>>regards
>>>Thomas
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>
>>>      
>>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>



From tmlammail at yahoo.com  Tue Oct 18 14:21:58 2005
From: tmlammail at yahoo.com (Martin Lam)
Date: Tue, 18 Oct 2005 05:21:58 -0700 (PDT)
Subject: [R]  How  to speed up R code?
In-Reply-To: <15f8e67d0510180150h6302721fr188417beed2fbb38@mail.gmail.com>
Message-ID: <20051018122158.21583.qmail@web40522.mail.yahoo.com>

Hi,

I have written a piece of code, which is a variant of
the random forest (rf) package algorithm, entirely in
R. I know that some of the code in the rf package is
written in c or c++. The problem is that the execution
of my code in R takes a lot of time. To give you an
example, the building and testing of data set with
20,000 instances using the random forest function from
the rf package takes a few minutes while 'my' random
forest's execution time is around 5 hours. So, I
wonder if there are some ways to speed up the
execution time. 

I've read in a similar post that using matrix instead
of data.frame would actually speed up the R code. The
format of my read-in data set is a "list", would the
data set in matrix format (using as.matrix) be better?

Thanks in advance,

Martin



From murdoch at stats.uwo.ca  Tue Oct 18 14:39:23 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 18 Oct 2005 08:39:23 -0400
Subject: [R] How  to speed up R code?
In-Reply-To: <20051018122158.21583.qmail@web40522.mail.yahoo.com>
References: <20051018122158.21583.qmail@web40522.mail.yahoo.com>
Message-ID: <4354ECFB.8010504@stats.uwo.ca>

Martin Lam wrote:
> Hi,
> 
> I have written a piece of code, which is a variant of
> the random forest (rf) package algorithm, entirely in
> R. I know that some of the code in the rf package is
> written in c or c++. The problem is that the execution
> of my code in R takes a lot of time. To give you an
> example, the building and testing of data set with
> 20,000 instances using the random forest function from
> the rf package takes a few minutes while 'my' random
> forest's execution time is around 5 hours. So, I
> wonder if there are some ways to speed up the
> execution time. 
> 
> I've read in a similar post that using matrix instead
> of data.frame would actually speed up the R code. The
> format of my read-in data set is a "list", would the
> data set in matrix format (using as.matrix) be better?

One piece of advice I forgot to give to Xiaohua:  try it! You can 
probably write slow code using *either* matrices or lists.  You need to 
identify what is slow, and fix it.

Duncan Murdoch



From ecoinformatics at gmail.com  Tue Oct 18 14:42:14 2005
From: ecoinformatics at gmail.com (ecoinfo)
Date: Tue, 18 Oct 2005 14:42:14 +0200
Subject: [R]  Ways to speed up R code?
In-Reply-To: <15f8e67d0510180517q5d288b9ck748d4dcee4551d89@mail.gmail.com>
References: <15f8e67d0510180150h6302721fr188417beed2fbb38@mail.gmail.com>
	<5ad2dec0510180317j12b21a35v@mail.gmail.com>
	<15f8e67d0510180414w1c689bd6vbbf7e9bbee74756b@mail.gmail.com>
	<5ad2dec0510180429i7b670e0bw@mail.gmail.com>
	<15f8e67d0510180517q5d288b9ck748d4dcee4551d89@mail.gmail.com>
Message-ID: <15f8e67d0510180542g36c36a99ia118ce062140657e@mail.gmail.com>

Hi,

I should read R-help archives more carefully.

According to your link, I searched in Google and found another pdf:

http://www.demog.berkeley.edu/~boe/Rstuff/R-fundamentalsLumleyBates/R-fundamentalsLumleyBates.pdf

Thanks for your advice,
Xiaohua

On 10/18/05, Thomas Sch??nhoff <tschoenhoff at gmail.com> wrote:
> Hi,
>
> well exactly the  wording as suggest in my post gives me the same help
> as done by Duncan! It's actually the tip Douglas Bates gave to someone
> else, using Rprofile for that issue....
>
> http://finzi.psych.upenn.edu/R/Rhelp02a/archive/58935.html
>
> 2005/10/18, ecoinfo <ecoinformatics at gmail.com>:
> > RSiteSearch("speed up R code")
> > == search for a page having the words (speed, up, R, and code)
> > surely R is found everywhere.
> > Although there are some useful archives, many of them are not.
> > Furthermore, I need a general instruction instead of pieces (e.g.
> > Patrick's book and Duncan's rules)
> >
> > If I use "speed up R code" as a phrase, then only one not-very-useful hit.
>
>



From sibylle.matthes at zdv.uni-tuebingen.de  Tue Oct 18 15:04:47 2005
From: sibylle.matthes at zdv.uni-tuebingen.de (Sibylle Matthes)
Date: Tue, 18 Oct 2005 15:04:47 +0200 (CEST)
Subject: [R] problems with device drivers postscript() and pdf()
Message-ID: <Pine.LNX.4.63.0510181445390.20092@u-003-scfe01.c-cluster.uni-tuebingen.de>


Dear R-help,
We are using the Platform AMD 64 Bit Opteron.
Our operating system is SUSE LINUX ENTERPRISESERVER SLES9.0
We are using R version 2.2.0 .
This is our problem:
None of the device drivers postscript() or pdf() is opening, e.g.
the following message is coming:
postscript("splines-Ex.ps")
Fehler in postscript("splines-Ex.ps") : unable to start device 
PostScript
Zus????tzlich: Warning message:
cannot open 'postscript' file argument 'splines-Ex.ps'

with regards
    Sibylle Matthes


From 042045003 at fudan.edu.cn  Tue Oct 18 15:13:35 2005
From: 042045003 at fudan.edu.cn (ronggui)
Date: Tue, 18 Oct 2005 21:13:35 +0800
Subject: [R] The meaning of functional language
Message-ID: <0IOK00G4Y492EA@mail.fudan.edu.cn>

It's often heard that the S language is a  functional language.But What's the exact meaning of this termology in the context of S language?
	



 				


2005-10-18

------
Deparment of Sociology
Fudan University


Blog:http://sociology.yculblog.com



From lisas at salford-systems.com  Tue Oct 18 15:15:38 2005
From: lisas at salford-systems.com (Lisa Solomon)
Date: Tue, 18 Oct 2005 06:15:38 -0700
Subject: [R] Data Mining Conference, Southern California, March 2006
Message-ID: <4354F57A.2060807@salford-systems.com>

SALFORD SYSTEMS DATA MINING CONFERENCE 2006
San Diego, California, March 29-31, 2006
Focusing on the Contributions of Data Mining to Solving Real-World 
Challenges

Business, Biomedical and Environmental Real-World Case Study Presentations

TOPICS INCLUDE:
Credit Risk Modeling; Targeted Marketing and Campaign Optimization; New 
Methods for Personalization; Analytical CRM; Fraud Detection; Military 
Applications; Crime Analysis; Drug Discovery; Data Analysis Related to 
Insurance, Epidemiology, Clinical Medicine, Proteomics and Genomics, 
Mass Spectrometry and Demographic Data; Tools for "Tall and Wide" Data

State-of-the-Art Research from Leading Academic Institutions

**A Commemoration and Celebration of the Lifetime Achievements of Data 
Mining Visionary and World-Renowned Statistician Leo Breiman

PRE-CONFERENCE TRAINING
Sharpen your expertise!
In-depth courses available for attendees who are new to data mining.

REGISTER NOW!
http://www.salforddatamining.com/docs/regform06.pdf

CONFERENCE PROGRAM:
http://www.salforddatamining.com/program-sd.htm

GREAT NETWORKING OPPORTUNITY
Attendees at Prior Conferences Included:
The International Monetary Fund, Barnes and Noble, Pfizer, Union Bank, 
Wells Fargo, Ciphergen, Stanford Linear Accelerator, Johns Hopkins 
Medical School, UC Berkeley, Cold Spring Harbor Laboratory, Novartis, 
Columbia University School of Public Health, Harvard Medical School, 
HSBC, International Steel Group(Bethlehem Steel), Cap Gemini, AT&T 
Labs-Research, PricewaterhouseCoopers

Sincerely,
Lisa Solomon



From hades at aurix.plus.com  Tue Oct 18 15:22:05 2005
From: hades at aurix.plus.com (Hades)
Date: Tue, 18 Oct 2005 14:22:05 +0100
Subject: [R] Classification tree data structure
Message-ID: <200510181320.j9IDKkKb017401@hypatia.math.ethz.ch>

Hi there,

I am growing classification trees using the 'tree' package add-on to R.

I would like to convert the 'R' output to the SAS format used by Salford Systems' commercial CART software in order to interface with some 
other software.

My question is:
How can I parse the R tree data structure in order to infer the tree structure?   The 'tree' class has a member '$frame' which gives the splits at 
each node, but as far as I can see does not specify the daughter nodes.   Is this information accessible through the interface to class 'tree' or 
do I need to dive into the C code?

Alternatively, is there an existing add-on which does this?  I gather functions exist to read SAS code but I haven't seen anything which writes it.

Thanks in advance,

Maria



From Roger.Bivand at nhh.no  Tue Oct 18 15:22:43 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 18 Oct 2005 15:22:43 +0200 (CEST)
Subject: [R] problems with device drivers postscript() and pdf()
In-Reply-To: <Pine.LNX.4.63.0510181445390.20092@u-003-scfe01.c-cluster.uni-tuebingen.de>
Message-ID: <Pine.LNX.4.44.0510181519520.17274-100000@reclus.nhh.no>

On Tue, 18 Oct 2005, Sibylle Matthes wrote:

> 
> Dear R-help,
> We are using the Platform AMD 64 Bit Opteron.
> Our operating system is SUSE LINUX ENTERPRISESERVER SLES9.0
> We are using R version 2.2.0 .
> This is our problem:
> None of the device drivers postscript() or pdf() is opening, e.g.
> the following message is coming:
> postscript("splines-Ex.ps")
> Fehler in postscript("splines-Ex.ps") : unable to start device 
> PostScript
> Zus????tzlich: Warning message:
> cannot open 'postscript' file argument 'splines-Ex.ps'
> 

As far as I can see, you are trying to write 'splines-Ex.ps' in a 
directory where you do not have write access. Check getwd(), and move with 
setwd() to a directory you can write to, or give a full path to such a 
directory.

Look at:

getwd()
system("ls -l ..")

to see the permissions of your working directory.

> with regards
>     Sibylle Matthes
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Malcolm.Price at bristol.ac.uk  Tue Oct 18 15:27:44 2005
From: Malcolm.Price at bristol.ac.uk (MJ Price, Social Medicine)
Date: Tue, 18 Oct 2005 14:27:44 +0100
Subject: [R] Efficient ways of finding functions and Breslow-Day test for
 homogeneity of the odds ratio
Message-ID: <8397484.1129645664@epi-pc64.epi.bris.ac.uk>

Dear all,

I have been trying to find a function to calculate the Breslow-Day test for 
homogeneity of the odds ratio in R. I know the test can be preformed in SAS 
but i was wondering if anyone could help me to perform this in r.

In addition i have the fullrefman file to search for functions in the basic 
R packages, does anyone have any suggestions of an efficient way of 
searching for functions in the other add-on packages on the website?

Thanks in advance

Malcolm



From h.wickham at gmail.com  Tue Oct 18 16:15:36 2005
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 18 Oct 2005 09:15:36 -0500
Subject: [R] The meaning of functional language
In-Reply-To: <0IOK00G4Y492EA@mail.fudan.edu.cn>
References: <0IOK00G4Y492EA@mail.fudan.edu.cn>
Message-ID: <f8e6ff050510180715l43660ee4h629730fd62cbbaed@mail.gmail.com>

> It's often heard that the S language is a  functional language.But What's the exact meaning of this termology in the context of S language?

For general computer science definitions, wikipedia is normally useful:
http://en.wikipedia.org/wiki/Functional_language

Hadley



From fisher at plessthan.com  Tue Oct 18 16:11:36 2005
From: fisher at plessthan.com (Dennis Fisher)
Date: Tue, 18 Oct 2005 07:11:36 -0700
Subject: [R] Subsetting a list
In-Reply-To: <mailman.13.1129629601.29332.r-help@stat.math.ethz.ch>
References: <mailman.13.1129629601.29332.r-help@stat.math.ethz.ch>
Message-ID: <8834D050-C381-4300-8A0C-54D806EFC941@plessthan.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051018/c2ebbdc9/attachment.pl

From r_schneid at hotmail.com  Tue Oct 18 16:24:02 2005
From: r_schneid at hotmail.com (Robert Schneider)
Date: Tue, 18 Oct 2005 10:24:02 -0400
Subject: [R] AR(1) with NLME
Message-ID: <BAY110-DAV7A19D678B677CB463A3519C710@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051018/1875e64b/attachment.pl

From murdoch at stats.uwo.ca  Tue Oct 18 16:27:14 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 18 Oct 2005 10:27:14 -0400
Subject: [R] Subsetting a list
In-Reply-To: <8834D050-C381-4300-8A0C-54D806EFC941@plessthan.com>
References: <mailman.13.1129629601.29332.r-help@stat.math.ethz.ch>
	<8834D050-C381-4300-8A0C-54D806EFC941@plessthan.com>
Message-ID: <43550642.3090108@stats.uwo.ca>

On 10/18/2005 10:11 AM, Dennis Fisher wrote:
> Colleagues,
> 
> I have created a list in the following manner:
>      TEST    <- list(c("A1", "A2"), c("B1", "B2"), c("C1", "C2"))
> 
> I now want to delete one element from the list, e.g., the third.  The  
> command
>      TEST[[3]]
> yields (as expected):
>      [1] "C1" "C2"
> 
> The command
>      TEST[[-3]]
> yields:
>      Error: attempt to select more than one element
> 
> How can I accomplish delete one or more elements from this list?

TEST[-3]

does what you want.  In general, single brackets say you want the answer 
to be a list, double brackets say you want to extract the element.

Duncan Murdoch



From reid_huntsinger at merck.com  Tue Oct 18 16:27:54 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Tue, 18 Oct 2005 10:27:54 -0400
Subject: [R] Subsetting a list
Message-ID: <355C35514FEAC9458F75947F5270974D076D36@usctmx1103.merck.com>

You have to use "[" instead of "[[" to return a sub-list.

Reid Huntsinger

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Dennis Fisher
Sent: Tuesday, October 18, 2005 10:12 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Subsetting a list


Colleagues,

I have created a list in the following manner:
     TEST    <- list(c("A1", "A2"), c("B1", "B2"), c("C1", "C2"))

I now want to delete one element from the list, e.g., the third.  The  
command
     TEST[[3]]
yields (as expected):
     [1] "C1" "C2"

The command
     TEST[[-3]]
yields:
     Error: attempt to select more than one element

How can I accomplish delete one or more elements from this list?

I am running R2.2.0 on a Linux platform.

Dennis

Dennis Fisher MD
P < (The "P Less Than" Company)
Phone: 1-866-PLessThan (1-866-753-7784)
Fax: 1-415-564-2220
www.PLessThan.com



	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ernesto at ipimar.pt  Tue Oct 18 16:30:59 2005
From: ernesto at ipimar.pt (ernesto)
Date: Tue, 18 Oct 2005 15:30:59 +0100
Subject: [R] Subsetting a list
In-Reply-To: <8834D050-C381-4300-8A0C-54D806EFC941@plessthan.com>
References: <mailman.13.1129629601.29332.r-help@stat.math.ethz.ch>
	<8834D050-C381-4300-8A0C-54D806EFC941@plessthan.com>
Message-ID: <43550723.7000004@ipimar.pt>

Dennis Fisher wrote:

>Colleagues,
>
>I have created a list in the following manner:
>     TEST    <- list(c("A1", "A2"), c("B1", "B2"), c("C1", "C2"))
>
>I now want to delete one element from the list, e.g., the third.  The  
>command
>     TEST[[3]]
>yields (as expected):
>     [1] "C1" "C2"
>
>The command
>     TEST[[-3]]
>yields:
>     Error: attempt to select more than one element
>
>How can I accomplish delete one or more elements from this list?
>
>I am running R2.2.0 on a Linux platform.
>
>Dennis
>
>Dennis Fisher MD
>P < (The "P Less Than" Company)
>Phone: 1-866-PLessThan (1-866-753-7784)
>Fax: 1-415-564-2220
>www.PLessThan.com
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>

TEST[[3]] <- NULL

Lists are not subsetable like data.frames or arrays, see the manuals.

EJ



From dimitris.rizopoulos at med.kuleuven.be  Tue Oct 18 16:34:05 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Tue, 18 Oct 2005 16:34:05 +0200
Subject: [R] Subsetting a list
References: <mailman.13.1129629601.29332.r-help@stat.math.ethz.ch>
	<8834D050-C381-4300-8A0C-54D806EFC941@plessthan.com>
Message-ID: <016a01c5d3f0$fdab4940$0540210a@www.domain>

you need single brackets, i.e.,

TEST <- list(c("A1", "A2"), c("B1", "B2"), c("C1", "C2"))
TEST[-c(1, 3)]

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Dennis Fisher" <fisher at plessthan.com>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, October 18, 2005 4:11 PM
Subject: [R] Subsetting a list


> Colleagues,
>
> I have created a list in the following manner:
>     TEST    <- list(c("A1", "A2"), c("B1", "B2"), c("C1", "C2"))
>
> I now want to delete one element from the list, e.g., the third. 
> The
> command
>     TEST[[3]]
> yields (as expected):
>     [1] "C1" "C2"
>
> The command
>     TEST[[-3]]
> yields:
>     Error: attempt to select more than one element
>
> How can I accomplish delete one or more elements from this list?
>
> I am running R2.2.0 on a Linux platform.
>
> Dennis
>
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone: 1-866-PLessThan (1-866-753-7784)
> Fax: 1-415-564-2220
> www.PLessThan.com
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From tchur at optushome.com.au  Tue Oct 18 16:39:56 2005
From: tchur at optushome.com.au (Tim Churches)
Date: Wed, 19 Oct 2005 00:39:56 +1000
Subject: [R] Efficient ways of finding functions and Breslow-Day test
 for homogeneity of the odds ratio
In-Reply-To: <8397484.1129645664@epi-pc64.epi.bris.ac.uk>
References: <8397484.1129645664@epi-pc64.epi.bris.ac.uk>
Message-ID: <4355093C.7010808@optushome.com.au>

MJ Price, Social Medicine wrote:
> I have been trying to find a function to calculate the Breslow-Day test for 
> homogeneity of the odds ratio in R. I know the test can be preformed in SAS 
> but i was wondering if anyone could help me to perform this in r.

I don't recall seeing the Breslow-Day test anywhere in an R package, but
the VCD package (available via CRAN) has a function called woolf_test()
to calculate Woolf's test for homogeneity of ORs.

Tim C



From arturo.coral at gmail.com  Tue Oct 18 16:47:14 2005
From: arturo.coral at gmail.com (Arturo Coral Alamo)
Date: Tue, 18 Oct 2005 09:47:14 -0500
Subject: [R] Subsetting a list
In-Reply-To: <8834D050-C381-4300-8A0C-54D806EFC941@plessthan.com>
References: <mailman.13.1129629601.29332.r-help@stat.math.ethz.ch>
	<8834D050-C381-4300-8A0C-54D806EFC941@plessthan.com>
Message-ID: <ed2fd5230510180747v192dd1bewaf50dc3b0d614d90@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051018/ae36c550/attachment.pl

From mschwartz at mn.rr.com  Tue Oct 18 17:00:56 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Tue, 18 Oct 2005 10:00:56 -0500
Subject: [R] Efficient ways of finding functions and Breslow-Day
	test	for homogeneity of the odds ratio
In-Reply-To: <8397484.1129645664@epi-pc64.epi.bris.ac.uk>
References: <8397484.1129645664@epi-pc64.epi.bris.ac.uk>
Message-ID: <1129647656.5251.8.camel@localhost.localdomain>

On Tue, 2005-10-18 at 14:27 +0100, MJ Price, Social Medicine wrote:
> Dear all,
> 
> I have been trying to find a function to calculate the Breslow-Day test for 
> homogeneity of the odds ratio in R. I know the test can be preformed in SAS 
> but i was wondering if anyone could help me to perform this in r.
> 
> In addition i have the fullrefman file to search for functions in the basic 
> R packages, does anyone have any suggestions of an efficient way of 
> searching for functions in the other add-on packages on the website?
> 
> Thanks in advance
> 
> Malcolm

RSiteSearch("Breslow"), which will perform a search of the e-mail list
archives and other online documentation, reveals this post:

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/50202.html

which in turn leads to this code:

http://www.math.montana.edu/~jimrc/classes/stat524/Rcode/breslowday.test.r


There is also code for the Woolf test in ?mantelhaen.test

Further searches can be conducted using help.search("Keyword"), which
will search your installed set of packages.

See ?help.search and ?RSiteSearch for more help on these.

HTH,

Marc Schwartz



From mendes.richard at gmail.com  Tue Oct 18 17:13:20 2005
From: mendes.richard at gmail.com (richard mendes)
Date: Tue, 18 Oct 2005 17:13:20 +0200
Subject: [R] p-value calculation
Message-ID: <5c5fa360510180813l6acea88fl92adfd54dccc4f43@mail.gmail.com>

hello everybody

i'm very new at using R so probably this is a very stupid question.
I have a problem calculating a p-value. When i do this with excel i
can use the method CHIDIST for 1.2654 with 1 freedom degree i get the
answer 0.261

i just want to do the same thing in R but i can't find a method.
can somebody help me

friendly regards

richard



From greg.snow at ihc.com  Tue Oct 18 17:19:16 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Tue, 18 Oct 2005 09:19:16 -0600
Subject: [R] Lattice graphics strip labels for shingles
Message-ID: <s354be2a.030@lp-msg1.co.ihc.com>

Does the strip.shingle function in the TeachingDemos package do what you
want?

Greg Snow, Ph.D.
Statistical Data Center, LDS Hospital
Intermountain Health Care
greg.snow at ihc.com
(801) 408-8111

>>> "Kiermeier, Andreas (PIRSA - SARDI)"
<Kiermeier.Andreas at saugov.sa.gov.au> 10/18/05 12:02AM >>>
Dear all,

back in 2002 Martin Henry H. Stevens wrote
(https://stat.ethz.ch/pipermail/r-help/2002-May/019851.html)

> How do I control the text in strips? Specifically, I want to put in
the 
> ranges generated in shingle(x) where x is continuous.

with an answer from Deepyan Sarkar (see strip.new towards the end of
this
message).  I assume that the answer worked back then, but I've tried
to
implement it today, with little success.  I think that it may have to
do
with namespaces - but I'm not sure.

Here is the code I used after creating the strip.new function (in
.GlobalEnv).

> x1 <- rnorm(100)
> x2 <- rnorm(100)
> x3 <- rnorm(100)
> 
> br <- matrix(c(seq(-3, 3, by=0.5), seq(-3, 3, by=0.5)+0.5), ncol=2,
byrow=FALSE)
> 
> x3.sh <- shingle(x3, intervals=br)
> 
> xyplot(x1 ~ x2 | x3.sh,
+        strip=function(shingle.intervals,...)
+        strip.new(shingle.intervals=br, ...))
Error in strip.new(shingle.intervals = br, ...) : 
	couldn't find function "grid.rect"

I realize that there have been changes in strip.default since then, but
even
attempting to create my own (modified) version of it (in .GlobalEnv)
comes
up with a similar error, namely

Error in strip.default(shingle.intervals = br, ...) : 
	couldn't find function "pushViewport"

Any help would be greatly appreciated - please reply directly to me as
I am
not currently on the list.

Regards,

Andreas



strip.new <-
    function(which.given,
             which.panel,
             var.name,
             factor.levels,
             shingle.intervals,
             strip.names = c(FALSE, TRUE),
             style = 1,
             bg =
trellis.par.get("strip.background")$col[which.given],
             fg = trellis.par.get("strip.shingle")$col[which.given],
             par.strip.text = trellis.par.get("add.text"))
{
    name <- var.name[which.given]
    level <- which.panel[which.given]
    strip.names <- rep(strip.names, length = 2)
    
    if (is.null(factor.levels)) { # means this is a  shingle, as
opposed to
a  
     
                                  ## factor
        if (is.null(shingle.intervals)) 
           stop("both factor.levels and shingle.intervals cannot be
NULL")

        strip.names <- strip.names[2]
        grid.rect(gp = gpar(fill=bg))
        t <- range(shingle.intervals)
        r <- (range(shingle.intervals[level,])-t[1])/diff(t)
        grid.rect(x = unit(r%*%c(.5,.5),"npc"), width =
unit(diff(r),"npc"),
                  gp = gpar(col=fg, fill=fg))
        if (strip.names) grid.text(label =
paste(shingle.intervals[level,1],
                                   shingle.intervals[level, 2], sep = '
,
'),
                                   gp = gpar(col = par.strip.text$col,
                                   font = par.strip.text$font,
                                   fontsize = par.strip.text$cex *
                                   current.viewport()$gp$fontsize))
        
        grid.rect()
    }
    else strip.default(which.given,
                       which.panel,
                       var.name,
                       factor.levels = factor.levels,
                       shingle.intervals = shingle.intervals,
                       strip.names,
                       style,
                       bg,
                       fg,
                       par.strip.text)
}



_____________________________
Dr Andreas Kiermeier
Statistician
SARDI FOOD SAFETY PROGRAM

33 Flemington Street
Glenside   SA   5065
Ph:	+61 8 8207 7884
Fax:	+61 8 8207 7854
Mob:	0423 028 565

Email: Kiermeier.Andreas at saugov.sa.gov.au 
_____________________________

The information in this e-mail and attachments (if any) may be
confidential
and/or legally privileged. If you are not the intended recipient, any
disclosure, copying, distribution or action taken is prohibited. SARDI,
The
South Australian Research and Development Institute, is the research
division of Primary Industries and Resources (SA)

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From mschwartz at mn.rr.com  Tue Oct 18 17:23:08 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Tue, 18 Oct 2005 10:23:08 -0500
Subject: [R] p-value calculation
In-Reply-To: <5c5fa360510180813l6acea88fl92adfd54dccc4f43@mail.gmail.com>
References: <5c5fa360510180813l6acea88fl92adfd54dccc4f43@mail.gmail.com>
Message-ID: <1129648988.5251.24.camel@localhost.localdomain>

On Tue, 2005-10-18 at 17:13 +0200, richard mendes wrote:
> hello everybody
> 
> i'm very new at using R so probably this is a very stupid question.
> I have a problem calculating a p-value. When i do this with excel i
> can use the method CHIDIST for 1.2654 with 1 freedom degree i get the
> answer 0.261
> 
> i just want to do the same thing in R but i can't find a method.
> can somebody help me
> 
> friendly regards
> 
> richard


> pchisq(1.2654, 1, lower.tail = FALSE)
[1] 0.2606314

See ?pchisq for more information.

You might also want to read Chapter 8 "Probability Distributions" in "An
Introduction To R", available with your R installation or from the
Documentation links on the main R web site.

HTH,

Marc Schwartz



From KINLEY_ROBERT at Lilly.com  Tue Oct 18 17:23:06 2005
From: KINLEY_ROBERT at Lilly.com (Robert Kinley)
Date: Tue, 18 Oct 2005 16:23:06 +0100
Subject: [R] p-value calculation
In-Reply-To: <5c5fa360510180813l6acea88fl92adfd54dccc4f43@mail.gmail.com>
Message-ID: <OFA9A211C9.29E6544C-ON8025709E.00546E81-8025709E.0054839B@EliLilly.lilly.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051018/23aed1df/attachment.pl

From 042045003 at fudan.edu.cn  Tue Oct 18 17:26:38 2005
From: 042045003 at fudan.edu.cn (ronggui)
Date: Tue, 18 Oct 2005 23:26:38 +0800
Subject: [R] p-value calculation
Message-ID: <0IOK00EMJAERSF@mail.fudan.edu.cn>

> pchisq(1.2654,df=1,low=F)
[1] 0.2606314


======= 2005-10-18 23:13:20 ÄúÔÚÀ´ÐÅÖÐÐ´µÀ£º=======

>hello everybody
>
>i'm very new at using R so probably this is a very stupid question.
>I have a problem calculating a p-value. When i do this with excel i
>can use the method CHIDIST for 1.2654 with 1 freedom degree i get the
>answer 0.261
>
>i just want to do the same thing in R but i can't find a method.
>can somebody help me
>
>friendly regards
>
>richard
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

= = = = = = = = = = = = = = = = = = = =
			


 

2005-10-18

------
Deparment of Sociology
Fudan University

My new mail addres is ronggui.huang at gmail.com
Blog:http://sociology.yculblog.com



From p.dalgaard at biostat.ku.dk  Tue Oct 18 17:31:27 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 18 Oct 2005 17:31:27 +0200
Subject: [R] p-value calculation
In-Reply-To: <5c5fa360510180813l6acea88fl92adfd54dccc4f43@mail.gmail.com>
References: <5c5fa360510180813l6acea88fl92adfd54dccc4f43@mail.gmail.com>
Message-ID: <x2k6ga9700.fsf@viggo.kubism.ku.dk>

richard mendes <mendes.richard at gmail.com> writes:

> hello everybody
> 
> i'm very new at using R so probably this is a very stupid question.
> I have a problem calculating a p-value. When i do this with excel i
> can use the method CHIDIST for 1.2654 with 1 freedom degree i get the
> answer 0.261
> 
> i just want to do the same thing in R but i can't find a method.
> can somebody help me

> 1-pchisq(1.2654,1)
[1] 0.2606314

or

> pchisq(1.2654,1,lower.tail=FALSE)
[1] 0.2606314

 
> friendly regards
> 
> richard
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From NordlDJ at dshs.wa.gov  Tue Oct 18 17:34:15 2005
From: NordlDJ at dshs.wa.gov (Nordlund, Dan)
Date: Tue, 18 Oct 2005 08:34:15 -0700
Subject: [R] p-value calculation
Message-ID: <592E8923DB6EA348BE8E33FCAADEFFFC13EED7DA@dshs-exch2.dshs.wa.lcl>

Look at ?pchisq

Daniel Nordlund
Bothell, WA

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-
> bounces at stat.math.ethz.ch] On Behalf Of richard mendes
> Sent: Tuesday, October 18, 2005 8:13 AM
> To: R-help at stat.math.ethz.ch
> Subject: [R] p-value calculation
> 
> hello everybody
> 
> i'm very new at using R so probably this is a very stupid question.
> I have a problem calculating a p-value. When i do this with excel i
> can use the method CHIDIST for 1.2654 with 1 freedom degree i get the
> answer 0.261
> 
> i just want to do the same thing in R but i can't find a method.
> can somebody help me
> 
> friendly regards
> 
> richard
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-
> guide.html



From macq at llnl.gov  Tue Oct 18 17:35:37 2005
From: macq at llnl.gov (Don MacQueen)
Date: Tue, 18 Oct 2005 08:35:37 -0700
Subject: [R] p-value calculation
In-Reply-To: <5c5fa360510180813l6acea88fl92adfd54dccc4f43@mail.gmail.com>
References: <5c5fa360510180813l6acea88fl92adfd54dccc4f43@mail.gmail.com>
Message-ID: <p06210201bf7ac5f37507@[128.115.153.6]>

>  1-pchisq(1.2654,1)
[1] 0.2606314

-Don

At 5:13 PM +0200 10/18/05, richard mendes wrote:
>hello everybody
>
>i'm very new at using R so probably this is a very stupid question.
>I have a problem calculating a p-value. When i do this with excel i
>can use the method CHIDIST for 1.2654 with 1 freedom degree i get the
>answer 0.261
>
>i just want to do the same thing in R but i can't find a method.
>can somebody help me
>
>friendly regards
>
>richard
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From herodote at oreka.com  Tue Oct 18 17:37:13 2005
From: herodote at oreka.com (=?iso-8859-1?Q?herodote@oreka.com?=)
Date: Tue, 18 Oct 2005 16:37:13 +0100
Subject: [R] =?iso-8859-1?q?hist_of_dates?=
Message-ID: <IOKBE1$2072623373BDE0E0730678AEB2990627@oreka.com>

Hi all

I wish to draw an histogram... with dates but the following append, i don't know where is the problem, help(hist.Date) works and i don't see any usefull information on what i'm doing wrong...

> hist.Date(dt_cycles)
Error: couldn't find function "hist.Date"
> hist.date(dt_cycles)
Error: couldn't find function "hist.date"
> cycles
[1]  7  1  2  5 14  5
> dt_cycles
  dates_releves cycles
1    2005-07-01      7
2    2005-07-04      1
3    2005-07-06      2
4    2005-07-11      5
5    2005-07-25     14
6    2005-07-27      5
> dates_releves<-as.Date(dates_releves)
> hist(dates_releves,cycles)
Error in hist.Date(dates_releves, cycles) :
        invalid specification of 'breaks'
> hist(dates_releves~cycles)
Error in hist.default(dates_releves ~ cycles) :
        'x' must be numeric
>

Any ideas would be great...
thks
guillaume.



From tlumley at u.washington.edu  Tue Oct 18 18:12:11 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 18 Oct 2005 09:12:11 -0700 (PDT)
Subject: [R] Efficient ways of finding functions and Breslow-Day test
 for homogeneity of the odds ratio
In-Reply-To: <4355093C.7010808@optushome.com.au>
References: <8397484.1129645664@epi-pc64.epi.bris.ac.uk>
	<4355093C.7010808@optushome.com.au>
Message-ID: <Pine.LNX.4.63a.0510180911290.30016@homer24.u.washington.edu>

On Wed, 19 Oct 2005, Tim Churches wrote:

> MJ Price, Social Medicine wrote:
>> I have been trying to find a function to calculate the Breslow-Day test for
>> homogeneity of the odds ratio in R. I know the test can be preformed in SAS
>> but i was wondering if anyone could help me to perform this in r.
>
> I don't recall seeing the Breslow-Day test anywhere in an R package, but
> the VCD package (available via CRAN) has a function called woolf_test()
> to calculate Woolf's test for homogeneity of ORs.
>

Both the (almost identical) meta-analysis packages also compute Woolf's test.

 	-thomas



From ripley at stats.ox.ac.uk  Tue Oct 18 18:18:39 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Oct 2005 17:18:39 +0100 (BST)
Subject: [R] Classification tree data structure
In-Reply-To: <200510181320.j9IDKkKb017401@hypatia.math.ethz.ch>
References: <200510181320.j9IDKkKb017401@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.61.0510181715160.21944@gannet.stats>

On Tue, 18 Oct 2005, Hades wrote:

> Hi there,
>
> I am growing classification trees using the 'tree' package add-on to R.
>
> I would like to convert the 'R' output to the SAS format used by Salford Systems' commercial CART software in order to interface with some
> other software.
>
> My question is:

> How can I parse the R tree data structure in order to infer the tree 
> structure?  The 'tree' class has a member '$frame' which gives the 
> splits at each node, but as far as I can see does not specify the 
> daughter nodes.  Is this information accessible through the interface to 
> class 'tree' or do I need to dive into the C code?

The daughter nodes of n are 2n and 2n+1.  The print method, print.tree, is 
written entirely in R and shows you how to parse the tree (and you can see 
the pattern of the numbers from its result).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From hades at aurix.plus.com  Tue Oct 18 18:25:20 2005
From: hades at aurix.plus.com (Hades)
Date: Tue, 18 Oct 2005 17:25:20 +0100
Subject: [R] Classification tree data structure
Message-ID: <200510181624.j9IGO47a003509@hypatia.math.ethz.ch>


   
 That's most helpful.  Thank you very much for your time.
   Best regards,
   Maria
   On  Tue  Oct  18 17:18 , Prof Brian Ripley <ripley at stats.ox.ac.uk> se   nt:
   

     On Tue, 18 Oct 2005,      > Hi there,
     >
     >  I  am  growing  classification  trees using the 'tree' p     add-on to R.
     >
     >  I  would like to convert the 'R' output to the SAS fo     by  Salford Systems' commercial CART software in order to interfac     e with some
     > other software.
     >
     > My question is:
     > How can I parse the R tree data structure in order t     tree
     >  structure?  The 'tree' class has a member '$frame' wh     the
     >  splits  at each node, but as far as I can see does no     the
     >  daughter  nodes.  Is  this  information accessible throu     interface to
     > class 'tree' or do I need to dive into the C code?
     The  daughter  nodes  of  n  are  2n  and  2n+1.  The print method,
     print.tree,  is  <     parse the tree (and you can see      the pattern of the numbers from its result).
     --
     Brian D. Ripley, [1]ripley at stats.ox.ac.uk
     Professor of Applied Statistics, [2]http     ://www.stats.ox.ac.uk/~ripley/
     University of Oxford, Tel: +44 1865 272861 (self)
     1 South Parks Road, +44 1865 272866 (PA)
     Oxford OX1 3TG, UK Fax: +44 1865 272595

   
   
References

   1. 3D"javascript:top.opencompose('ripley at stats.ox.ac.   2. file://localhost/tmp/3D"parse.pl?redirect=http%3A%2F%

From gunter.berton at gene.com  Tue Oct 18 18:25:59 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Tue, 18 Oct 2005 09:25:59 -0700
Subject: [R] hist of dates
Message-ID: <200510181626.j9IGPxCH013895@ohm.gene.com>


hist.Date is not exported from its namespace. Try RSiteSearch('namespace')
to learn more about this (look for the R News article).

As you saw, hist() will dispatch hist.Date() when it is given a date-time
argument. Read the docs again -- you failed to specify the breaks = ...
argument properly.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> herodote at oreka.com
> Sent: Tuesday, October 18, 2005 8:37 AM
> To: r-help
> Subject: [R] hist of dates
> 
> Hi all
> 
> I wish to draw an histogram... with dates but the following 
> append, i don't know where is the problem, help(hist.Date) 
> works and i don't see any usefull information on what i'm 
> doing wrong...
> 
> > hist.Date(dt_cycles)
> Error: couldn't find function "hist.Date"
> > hist.date(dt_cycles)
> Error: couldn't find function "hist.date"
> > cycles
> [1]  7  1  2  5 14  5
> > dt_cycles
>   dates_releves cycles
> 1    2005-07-01      7
> 2    2005-07-04      1
> 3    2005-07-06      2
> 4    2005-07-11      5
> 5    2005-07-25     14
> 6    2005-07-27      5
> > dates_releves<-as.Date(dates_releves)
> > hist(dates_releves,cycles)
> Error in hist.Date(dates_releves, cycles) :
>         invalid specification of 'breaks'
> > hist(dates_releves~cycles)
> Error in hist.default(dates_releves ~ cycles) :
>         'x' must be numeric
> >
> 
> Any ideas would be great...
> thks
> guillaume.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Tue Oct 18 18:30:04 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Oct 2005 17:30:04 +0100 (BST)
Subject: [R] =?iso-8859-1?q?hist_of_dates?=
In-Reply-To: <IOKBE1$2072623373BDE0E0730678AEB2990627@oreka.com>
References: <IOKBE1$2072623373BDE0E0730678AEB2990627@oreka.com>
Message-ID: <Pine.LNX.4.61.0510181723040.21944@gannet.stats>

Pleae see ?hist.Date for how to use it, as you usage is nothing like the 
examples there.

However, I suspect you do not want a histogram but a barplot, as in

   with(dt_cycles, barplot(cycles, names=as.character(dates_releves)))

(You may want to adjust the font size or date format.

On Tue, 18 Oct 2005, herodote at oreka.com wrote:

> Hi all
>
> I wish to draw an histogram... with dates but the following append, i 
> don't know where is the problem, help(hist.Date) works and i don't see 
> any usefull information on what i'm doing wrong...
>
>> hist.Date(dt_cycles)
> Error: couldn't find function "hist.Date"
>> hist.date(dt_cycles)
> Error: couldn't find function "hist.date"
>> cycles
> [1]  7  1  2  5 14  5
>> dt_cycles
>  dates_releves cycles
> 1    2005-07-01      7
> 2    2005-07-04      1
> 3    2005-07-06      2
> 4    2005-07-11      5
> 5    2005-07-25     14
> 6    2005-07-27      5
>> dates_releves<-as.Date(dates_releves)
>> hist(dates_releves,cycles)
> Error in hist.Date(dates_releves, cycles) :
>        invalid specification of 'breaks'
>> hist(dates_releves~cycles)
> Error in hist.default(dates_releves ~ cycles) :
>        'x' must be numeric
>>
>
> Any ideas would be great...
> thks
> guillaume.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From arajendr at orca.st.usm.edu  Tue Oct 18 18:52:33 2005
From: arajendr at orca.st.usm.edu (Arunkumar R)
Date: Tue, 18 Oct 2005 11:52:33 -0500 (CDT)
Subject: [R] Installing Bioconductor on R
Message-ID: <Pine.LNX.4.64.0510181151210.2525@orca_login1.st.usm.edu>

hi all,
           Am new to R. I am having problems installing Bioconductor package in 
R on fedora core 4 running on AMD64 bit machine.

this is the error message I get :

gcc -shared -L/usr/local/lib -o affyPLM.so avg_log.o biweight.o 
chipbackground.o common_types.o do_PLMrlm.o do_PLMrma.o do_PLMthreestep.o 
idealmismatch.o LESN.o lm.o lm_threestep.o log_avg.o matrix_functions.o 
median_logPM.o medianPM.o medianpolish.o nthLargestPM.o PLM_modelmatrix.o 
preprocess.o psi_fns.o qnorm.o qnorm_probeset.o rlm_anova.o rlm.o rlm_PLM.o 
rlm_se.o rlm_threestep.o rma_background2.o rma_common.o rma_PLM.o 
rmaPLM_pseudo.o SCAB.o scaling.o threestep.o threestep_common.o threestep_PLM.o 
threestep_summary.o threestep_summary_methods.o transfns.o 
weightedkerneldensity.o -L/usr/lib64/R/lib -lRlapack -lblas -L/usr/lib64/R/lib 
-lR
/usr/bin/ld: cannot find -lblas
collect2: ld returned 1 exit status
make: *** [affyPLM.so] Error 1
ERROR: compilation failed for package 'affyPLM'
** Removing '/usr/lib64/R/library/affyPLM'
** Restoring previous '/usr/lib64/R/library/affyPLM'

The downloaded packages are in
         /tmp/RtmpY18969/downloaded_packages
Warning message:
installation of package 'affyPLM' had non-zero exit status in: 
install.packages(pkgs = c("affy", "affydata", "affyPLM", "annaffy",

I get these error messages after I type these commands on R :

source("http://www.bioconductor.org/biocLite.R")
biocLite()

when I search for blas , I get this :

$ locate blas | grep so
/usr/lib/libgslcblas.so.0
/usr/lib/libgslcblas.so.0.0.0
/usr/lib64/libblas.so.3.0
/usr/lib64/libblas.so.3.0.3
/usr/lib64/libblas.so.3

do I need to install blas or make some changes in the configuration file in the 
bioconductor package.

Thanks
Arun



From chxma at capitalbio.com  Tue Oct 18 03:59:12 2005
From: chxma at capitalbio.com (=?gb2312?B?wu20q8/j?=)
Date: Tue, 18 Oct 2005 09:59:12 +0800
Subject: [R] bayesian network
Message-ID: <329602008.00703@eyou.net>

r-help-request£¬ÄúºÃ£¡

	    Hello!
 I am a R user. recently,I am using Bayesian Network to inference posterior.but,I don't know how to input prior probability and inference posterior.I tried "prob" function,but fail.Can you help me? Thanks!  


ChuanXiang Ma

¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡
 				

¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡
¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡chxma at capitalbio.com
¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡2005-10-18



From JAROSLAW.W.TUSZYNSKI at saic.com  Tue Oct 18 19:30:55 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Tue, 18 Oct 2005 13:30:55 -0400
Subject: [R] Efficient ways of finding functions and Breslow-Day test
	for homogeneity of the odds ratio
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD504372C32@us-arlington-0668.mail.saic.com>

Try "Breslow OR Breslowday filetype:R -robol" search in Google.

 Jarek 
====================================================\==== 
 Jarek Tuszynski, PhD.                           o / \ 
 Science Applications International Corporation  <\__,|  
 (703) 676-4192                                   ">  \ 
 Jaroslaw.W.Tuszynski at saic.com                     `   \ 



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of MJ Price, Social
Medicine
Sent: Tuesday, October 18, 2005 9:28 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Efficient ways of finding functions and Breslow-Day test for
homogeneity of the odds ratio

Dear all,

I have been trying to find a function to calculate the Breslow-Day test for
homogeneity of the odds ratio in R. I know the test can be preformed in SAS
but i was wondering if anyone could help me to perform this in r.

In addition i have the fullrefman file to search for functions in the basic
R packages, does anyone have any suggestions of an efficient way of
searching for functions in the other add-on packages on the website?

Thanks in advance

Malcolm

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From kerryrekky at yahoo.com  Tue Oct 18 19:45:50 2005
From: kerryrekky at yahoo.com (Cunningham Kerry)
Date: Tue, 18 Oct 2005 10:45:50 -0700 (PDT)
Subject: [R] predictive interval in nlme
Message-ID: <20051018174550.62991.qmail@web51806.mail.yahoo.com>

Suppose I have the following data:

y x id
44 0 104
48 58 104
48 55 204
47 105 204
41 275 206
18 67 209
.......

I fit the model

>fit=lme(y~x+I(x^2),random=~1|id)

Now I want to make a prediction plot:

>time=seq(0,300,len=100)
>plot(predict(fit,data.frame(x=time),level=0))

Very fine. It gives me the prediction curve based on
the model. My further request is to make a confidence
bands around the curve. I guess I can derive its
mathematical form analytically and implement it
myself. But I just hope some experts can point out one
simple way in R to avoid my redundant work.

Thanks!



From p.dalgaard at biostat.ku.dk  Tue Oct 18 19:55:22 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 18 Oct 2005 19:55:22 +0200
Subject: [R] Installing Bioconductor on R
In-Reply-To: <Pine.LNX.4.64.0510181151210.2525@orca_login1.st.usm.edu>
References: <Pine.LNX.4.64.0510181151210.2525@orca_login1.st.usm.edu>
Message-ID: <x2d5m2zp4l.fsf@viggo.kubism.ku.dk>

Arunkumar R <arajendr at orca.st.usm.edu> writes:

> hi all,
>            Am new to R. I am having problems installing Bioconductor package in 
> R on fedora core 4 running on AMD64 bit machine.

Where did you get your R and which version? This is not happening to
me with R-2.2.0 from Fedora Extras:

gcc -shared -L/usr/local/lib64 -o affyPLM.so avg_log.o biweight.o
chipbackground.o common_types.o do_PLMrlm.o do_PLMrma.o
do_PLMthreestep.o idealmismatch.o LESN.o lm.o lm_threestep.o log_avg.o
matrix_functions.o median_logPM.o medianPM.o medianpolish.o
nthLargestPM.o PLM_modelmatrix.o preprocess.o psi_fns.o qnorm.o
qnorm_probeset.o rlm_anova.o rlm.o rlm_PLM.o rlm_se.o rlm_threestep.o
rma_background2.o rma_common.o rma_PLM.o rmaPLM_pseudo.o SCAB.o
scaling.o threestep.o threestep_common.o threestep_PLM.o
threestep_summary.o threestep_summary_methods.o transfns.o
weightedkerneldensity.o -L/usr/lib64/R/lib -lRlapack
-L/usr/lib64/R/lib -lR 
** R 
** inst
..etc..


> this is the error message I get :
> 
> gcc -shared -L/usr/local/lib -o affyPLM.so avg_log.o biweight.o 
> chipbackground.o common_types.o do_PLMrlm.o do_PLMrma.o do_PLMthreestep.o 
> idealmismatch.o LESN.o lm.o lm_threestep.o log_avg.o matrix_functions.o 
> median_logPM.o medianPM.o medianpolish.o nthLargestPM.o PLM_modelmatrix.o 
> preprocess.o psi_fns.o qnorm.o qnorm_probeset.o rlm_anova.o rlm.o rlm_PLM.o 
> rlm_se.o rlm_threestep.o rma_background2.o rma_common.o rma_PLM.o 
> rmaPLM_pseudo.o SCAB.o scaling.o threestep.o threestep_common.o threestep_PLM.o 
> threestep_summary.o threestep_summary_methods.o transfns.o 
> weightedkerneldensity.o -L/usr/lib64/R/lib -lRlapack -lblas -L/usr/lib64/R/lib 
> -lR
> /usr/bin/ld: cannot find -lblas
> collect2: ld returned 1 exit status
> make: *** [affyPLM.so] Error 1
> ERROR: compilation failed for package 'affyPLM'
> ** Removing '/usr/lib64/R/library/affyPLM'
> ** Restoring previous '/usr/lib64/R/library/affyPLM'
> 
> The downloaded packages are in
>          /tmp/RtmpY18969/downloaded_packages
> Warning message:
> installation of package 'affyPLM' had non-zero exit status in: 
> install.packages(pkgs = c("affy", "affydata", "affyPLM", "annaffy",
> 
> I get these error messages after I type these commands on R :
> 
> source("http://www.bioconductor.org/biocLite.R")
> biocLite()
> 
> when I search for blas , I get this :
> 
> $ locate blas | grep so
> /usr/lib/libgslcblas.so.0
> /usr/lib/libgslcblas.so.0.0.0
> /usr/lib64/libblas.so.3.0
> /usr/lib64/libblas.so.3.0.3
> /usr/lib64/libblas.so.3
> 
> do I need to install blas or make some changes in the configuration file in the 
> bioconductor package.
> 
> Thanks
> Arun
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From Camarda at demogr.mpg.de  Tue Oct 18 20:03:09 2005
From: Camarda at demogr.mpg.de (Camarda, Carlo Giovanni)
Date: Tue, 18 Oct 2005 20:03:09 +0200
Subject: [R] Solid and dotted lines saving an xyplot
Message-ID: <8B08A3A1EA7AAC41BE24C750338754E6C0C0E6@HERMES.demogr.mpg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051018/e4caf814/attachment.pl

From elvis at xlsolutions-corp.com  Tue Oct 18 20:12:55 2005
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Tue, 18 Oct 2005 11:12:55 -0700
Subject: [R] R/Splus  Courses *** Las Vegas and San Francisco,
	In November 2005
Message-ID: <20051018111255.a108dc04937c07ba67766dad37185406.7d8692dcb5.wbe@email.secureserver.net>

 XLSolutions Corporation (www.xlsolutions-corp.com) is proud to
announce  2-day "R/S-plus Fundamentals and Programming
Techniques" .
www.xlsolutions-corp.com/Rfund.htm


**** San Francisco ------------------------ October 31st - November 1st,
 2005
**** Las Vegas ----------------------------- November 7th - 8th, 2005

Reserve your seat now at the early bird rates!
Payment due AFTER the class

Course Description:

This two-day beginner to intermediate R/S-plus course focuses on a
broad spectrum of topics, from reading raw data to a comparison of R
and S. We will learn the essentials of data manipulation, graphical
visualization and R/S-plus programming. We will explore statistical
data analysis tools,including graphics with data sets. How to enhance
your plots, build your own packages (librairies) and connect via
ODBC,etc.
We will perform some statistical modeling and fit linear regression
models. Participants are encouraged to bring data for interactive
sessions

With the following outline:

- An Overview of R and S
- Data Manipulation and Graphics
- Using Lattice Graphics
- A Comparison of R and S-Plus
- How can R Complement SAS?
- Writing Functions
- Avoiding Loops
- Vectorization
- Statistical Modeling
- Project Management
- Techniques for Effective use of R and S
- Enhancing Plots
- Using High-level Plotting Functions
- Building and Distributing Packages (libraries)
- Connecting; ODBC, Rweb, Orca via sockets and via Rjava

Interested in R/Splus Advanced course? email us.

Email us for group discounts.
Email Sue Turner: sue at xlsolutions-corp.com
Phone: 206-686-1578
Visit us: www.xlsolutions-corp.com/training.htm
Please let us know if you and your colleagues are interested in this
classto take advantage of group discount. Register now to secure your
seat!

Interested in R/Splus Advanced course? email us.


Cheers,
Elvis Miller, PhD
Manager Training.
XLSolutions Corporation
206 686 1578
www.xlsolutions-corp.com
elvis at xlsolutions-corp.com



From cormaggio at gmail.com  Tue Oct 18 20:46:19 2005
From: cormaggio at gmail.com (Cormac Lawler)
Date: Tue, 18 Oct 2005 19:46:19 +0100
Subject: [R] loading packages - mac user
Message-ID: <e3930910510181146x2d6fd70avcc887d6259f08e54@mail.gmail.com>

Hi,
I'm using a Mac, I've downloaded R (base), and I'm trying to download
the package R Commander. I thought I had already done this (both from
the web and from within R) but it doesn't seem to be working - it's
not there as a "search()" reveals. However, there are plenty of files
on my system linked with Rcmdr - located in
HD>Library>Frameworks>R.framework>Versions>2.1.1>Resources>Library>Rcmdr.
Is it simply in the wrong location to use it? The other possibility is
that I keep getting a tcltk error whenever I try to load up the
package from the Package Manager from within R - and when I try to
upload the tcltk package, this also gives the same error [1]. I also
get a "Couldn't launch application" error whenever I try to launch the
X11.app.

This is probably so basic it's staring me in the eyes, but I need your
help please. I'd be happy to give any extra info you need.

Thanks
Cormac

[1] Loading required package: tcltk
Loading Tcl/Tk interface ... Error in dyn.load(x, as.logical(local),
as.logical(now)) :
	unable to load shared library
'/Library/Frameworks/R.framework/Resources/library/tcltk/libs/tcltk.so':
  dlcompat: dyld: /Applications/R.app/Contents/MacOS/R can't open
library: /usr/local/lib/libtk8.4.dylib  (No such file or directory,
errno = 2)
In addition: Warning messages:
1: cannot create HTML package index in: make.packages.html()
2: cannot create HTML package index in: make.packages.html()
Error: .onLoad failed in 'loadNamespace' for 'tcltk'
Error: package 'tcltk' could not be loaded



From ripley at stats.ox.ac.uk  Tue Oct 18 20:55:48 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Oct 2005 19:55:48 +0100 (BST)
Subject: [R] Solid and dotted lines saving an xyplot
In-Reply-To: <8B08A3A1EA7AAC41BE24C750338754E6C0C0E6@HERMES.demogr.mpg.de>
References: <8B08A3A1EA7AAC41BE24C750338754E6C0C0E6@HERMES.demogr.mpg.de>
Message-ID: <Pine.LNX.4.61.0510181948130.6034@gannet.stats>

You are not `saving' an xyplot, but re-plotting on a different device.

Different trellis devices have different default settings: you did not 
mention that the backgound had changed from grey to white (but it has).

Try trellis.device(color=FALSE) to get on screen what you see on paper, or 
use trellis.par.set() (of superpose.line$lty, I believe) to control just 
this single aspect of the plot.

On Tue, 18 Oct 2005, Camarda, Carlo Giovanni wrote:

> Dear R-users,
> I would a small problem saving a graph with postscript after using
> xyplot.
> Whereas in the R-screen the two lines are solid, once the image is saved
> as .eps file the second lines (blue in the following example) is dotted.
> Here there is a simple example.
> Thanks in advance for your help,
> Carlo Giovanni Camarda
>
> # creating data
> a1 <- sort(runif(10))
> a2 <- sort(runif(10))
> a3 <- sort(runif(10))
> a4 <- sort(runif(10))
> a <- c(a1,a2,a3,a4)
> b1 <- sort(runif(10))
> b2 <- sort(runif(10))
> b3 <- sort(runif(10))
> b4 <- sort(runif(10))
> b <- c(b1,b2,b3,b4)
> c <- rep(1:10,4)
> d <- rep(1:4, each=10)
> # creating a dataset
> df <- data.frame("a"=a,"b"=b,"c"=c,"d"=d)
> # plotting in R (look the solid lines)
> xyplot(a + b ~ c | d, data = df, col=c("red", "blue"), type="l",
> layout=c(2,2))
> # saving somewhere (one solid and one dotted line)
> postscript("example.eps")
> xyplot(a + b ~ c | d, data = df, col=c("red", "blue"), type="l",
> layout=c(2,2))
> dev.off()
>
>
>
> +++++
> This mail has been sent through the MPI for Demographic Rese...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From grenyer at virginia.edu  Tue Oct 18 20:59:41 2005
From: grenyer at virginia.edu (Rich Grenyer)
Date: Tue, 18 Oct 2005 14:59:41 -0400
Subject: [R] Peculiar behaviour subtracting from named numeric vector
In-Reply-To: <4354DB8F.4000604@pburns.seanet.com>
References: <15f8e67d0510180150h6302721fr188417beed2fbb38@mail.gmail.com>	<5ad2dec0510180317j12b21a35v@mail.gmail.com>	<15f8e67d0510180414w1c689bd6vbbf7e9bbee74756b@mail.gmail.com>
	<15f8e67d0510180419yf535044j678983f4e60127cf@mail.gmail.com>
	<4354DB8F.4000604@pburns.seanet.com>
Message-ID: <8e3bfc69f5581d86043acaeaa5e0c45f@virginia.edu>

Hi - I'm just puzzling over something R's been doing when subtracting a 
constant from a named numeric vector. I hope this isn't anything 
embarrassingly simple, but I've tried and failed the usual searches. 
For the last item in my vector, 40-21=19, but 40-40 = 7.105E-15 . If I 
replace the last item of the vector explicitly with 40 (i.e. 
goodtimees[21]<-40), then 40-40=0. I presume that this means the last 
item in the vector is not 40, but 40 + 7.105E-15. This is possible 
(goodtimees is the output of a function in an R addon package - it 
should be at the same precision as the input to that function, but 
there could be a problem with it, perhaps) but either way, why isn't 
the true value showing when the vector is displayed? Is there a more 
deep-rooted problem?

Thanks in advance...

Rich


 > goodtimees
   -1   -2   -3   -4   -5   -6   -7   -8  -28  -48  -93  -96 -152 -163 
-164 -167 -168 -169 -177 -188 -189
98.1 86.8 77.9 76.3 70.6 61.1 53.6 51.5 47.5 43.8 41.7 72.3 41.8 65.3 
49.4 61.1 54.9 43.0 44.9 53.0 40.0

 > str(goodtimees)
  Named num [1:21] 98.1 86.8 77.9 76.3 70.6 ...
  - attr(*, "names")= chr [1:21] "-1" "-2" "-3" "-4" ...

 > goodtimees-21
   -1   -2   -3   -4   -5   -6   -7   -8  -28  -48  -93  -96 -152 -163 
-164 -167 -168 -169 -177 -188 -189
77.1 65.8 56.9 55.3 49.6 40.1 32.6 30.5 26.5 22.8 20.7 51.3 20.8 44.3 
28.4 40.1 33.9 22.0 23.9 32.0 19.0

 > goodtimees-40
           -1           -2           -3           -4           -5        
    -6           -7           -8
5.810000e+01 4.680000e+01 3.790000e+01 3.630000e+01 3.060000e+01 
2.110000e+01 1.360000e+01 1.150000e+01
          -28          -48          -93          -96         -152        
  -163         -164         -167
7.500000e+00 3.800000e+00 1.700000e+00 3.230000e+01 1.800000e+00 
2.530000e+01 9.400000e+00 2.110000e+01
         -168         -169         -177         -188         -189
1.490000e+01 3.000000e+00 4.900000e+00 1.300000e+01 7.105427e-15

 > version
          _
platform powerpc-apple-darwin7.9.0
arch     powerpc
os       darwin7.9.0
system   powerpc, darwin7.9.0
status
major    2
minor    1.1
year     2005
month    06
day      20
language R



--------------------
Rich Grenyer, Ph.D.
Biology Department - University of Virginia
Gilmer Hall
Charlottesville, Virginia
VA 22904
United States of America

tel: (+1) 434 982 5629
fax: (+1) 434 982 5626
http://faculty.virginia.edu/gittleman/rich



From sundar.dorai-raj at pdf.com  Tue Oct 18 21:14:01 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 18 Oct 2005 14:14:01 -0500
Subject: [R] Peculiar behaviour subtracting from named numeric vector
In-Reply-To: <8e3bfc69f5581d86043acaeaa5e0c45f@virginia.edu>
References: <15f8e67d0510180150h6302721fr188417beed2fbb38@mail.gmail.com>	<5ad2dec0510180317j12b21a35v@mail.gmail.com>	<15f8e67d0510180414w1c689bd6vbbf7e9bbee74756b@mail.gmail.com>	<15f8e67d0510180419yf535044j678983f4e60127cf@mail.gmail.com>	<4354DB8F.4000604@pburns.seanet.com>
	<8e3bfc69f5581d86043acaeaa5e0c45f@virginia.edu>
Message-ID: <43554979.2040505@pdf.com>

Hi, Rich,

This comes up so much it is FAQ 7.31.

http://cran.r-project.org/doc/FAQ/R-FAQ.html

--sundar

Rich Grenyer wrote:
> Hi - I'm just puzzling over something R's been doing when subtracting a 
> constant from a named numeric vector. I hope this isn't anything 
> embarrassingly simple, but I've tried and failed the usual searches. 
> For the last item in my vector, 40-21=19, but 40-40 = 7.105E-15 . If I 
> replace the last item of the vector explicitly with 40 (i.e. 
> goodtimees[21]<-40), then 40-40=0. I presume that this means the last 
> item in the vector is not 40, but 40 + 7.105E-15. This is possible 
> (goodtimees is the output of a function in an R addon package - it 
> should be at the same precision as the input to that function, but 
> there could be a problem with it, perhaps) but either way, why isn't 
> the true value showing when the vector is displayed? Is there a more 
> deep-rooted problem?
> 
> Thanks in advance...
> 
> Rich
> 
> 
>  > goodtimees
>    -1   -2   -3   -4   -5   -6   -7   -8  -28  -48  -93  -96 -152 -163 
> -164 -167 -168 -169 -177 -188 -189
> 98.1 86.8 77.9 76.3 70.6 61.1 53.6 51.5 47.5 43.8 41.7 72.3 41.8 65.3 
> 49.4 61.1 54.9 43.0 44.9 53.0 40.0
> 
>  > str(goodtimees)
>   Named num [1:21] 98.1 86.8 77.9 76.3 70.6 ...
>   - attr(*, "names")= chr [1:21] "-1" "-2" "-3" "-4" ...
> 
>  > goodtimees-21
>    -1   -2   -3   -4   -5   -6   -7   -8  -28  -48  -93  -96 -152 -163 
> -164 -167 -168 -169 -177 -188 -189
> 77.1 65.8 56.9 55.3 49.6 40.1 32.6 30.5 26.5 22.8 20.7 51.3 20.8 44.3 
> 28.4 40.1 33.9 22.0 23.9 32.0 19.0
> 
>  > goodtimees-40
>            -1           -2           -3           -4           -5        
>     -6           -7           -8
> 5.810000e+01 4.680000e+01 3.790000e+01 3.630000e+01 3.060000e+01 
> 2.110000e+01 1.360000e+01 1.150000e+01
>           -28          -48          -93          -96         -152        
>   -163         -164         -167
> 7.500000e+00 3.800000e+00 1.700000e+00 3.230000e+01 1.800000e+00 
> 2.530000e+01 9.400000e+00 2.110000e+01
>          -168         -169         -177         -188         -189
> 1.490000e+01 3.000000e+00 4.900000e+00 1.300000e+01 7.105427e-15
> 
>  > version
>           _
> platform powerpc-apple-darwin7.9.0
> arch     powerpc
> os       darwin7.9.0
> system   powerpc, darwin7.9.0
> status
> major    2
> minor    1.1
> year     2005
> month    06
> day      20
> language R
> 
> 
> 
> --------------------
> Rich Grenyer, Ph.D.
> Biology Department - University of Virginia
> Gilmer Hall
> Charlottesville, Virginia
> VA 22904
> United States of America
> 
> tel: (+1) 434 982 5629
> fax: (+1) 434 982 5626
> http://faculty.virginia.edu/gittleman/rich
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From cbehr at edesigndynamics.com  Tue Oct 18 21:19:24 2005
From: cbehr at edesigndynamics.com (Chris Behr)
Date: Tue, 18 Oct 2005 15:19:24 -0400
Subject: [R] sample size determination
Message-ID: <EBECLABIMNBHDFCEHCFHOEBBCEAA.cbehr@edesigndynamics.com>

Hello,

I am a new user of R and trying to assess the sample size for data that is
being collected on water quality at sites across a wide geographic region. A
preliminary set of data has been collected and I would like to use it to
assess whether we are collecting enough data and in the right places.

A factorial approach was initially used to characterize sites by well type,
latrine type, distance between well and latrine, and ecological region.
Altogether the basic structure has:

3 types of wells
3 types of latrines
4 distance categories
13 regions

We define a ?site-type? as: a well-latrine-distance combination. There are
36 of these. A number of replicates (between 1 and 4) of the 36 site-types
are included in the set of sites in each of the 13 regions. Some regions
have more replicates than others due to complexity in the region. In total
there are 936 sites.

At this point, I have an ANOVA model with water quality measures and only
(these) categorical data. I want to know if I am collecting enough samples
(given alpha and beta levels) to see if there are effects for wells,
latrines, distances, and region (independently), as well as interactions for
well-distance, well-latrine, and well-region. I would like to also perform a
power analysis to allow the power vary with sample size.

I am working my way through various texts and help functions but thought I
would see if anyone else has learned how to do this already.

I would appreciate any and all guidance.

Best wishes, Chris

Christopher Behr
Principal Analyst

eDesign Dynamics
www.edesigndynamics.com

4024 Calvert St. NW
Washington DC 20007
(202) 298-6437 (t/f)
(551) 998-4823 (c)



From Cameron.Guenther at MyFWC.com  Tue Oct 18 21:20:48 2005
From: Cameron.Guenther at MyFWC.com (Guenther, Cameron)
Date: Tue, 18 Oct 2005 15:20:48 -0400
Subject: [R]  Repeating lines in a data frame
Message-ID: <BA6FF017E924044A9BF748AFAEEA6F304C8627@FWC-TLEX3.fwc.state.fl.us>

Hello,
I have a much larger dataset that is similar in form to:
 year species length count
 1998       1    150     1
 1998       2    200     1
 1998       3    250     2
 1999       1    150     3
 1999       2    200     4
 1999       3    250     5
 2000       1    150     1
 2000       2    200     1
 2000       3    250     1
 2001       1    150     2
 2001       2    200     3
 2001       3    250     1
 2002       1    150     1
 2002       2    200     2
 2002       3    250     3

What I want is to have a line of data for each year x species x length
group combination
I would like the ouput to be:

Year species length count
1998       1    150     1
1998       2    200     1
1998       3    250     1
1998       3    250     1
1999       1    150     1
1999       1    150     1
1999       1    150     1
1999       2    200     1
.
.
.

Can anyone help me with a for statement of a function that can
accomplish this?
Thanks

Cameron Guenther 
Associate Research Scientist
FWC/FWRI, Marine Fisheries Research
100 8th Avenue S.E.
St. Petersburg, FL 33701
(727)896-8626 Ext. 4305
cameron.guenther at myfwc.com



From cormaggio at gmail.com  Tue Oct 18 21:35:39 2005
From: cormaggio at gmail.com (Cormac Lawler)
Date: Tue, 18 Oct 2005 20:35:39 +0100
Subject: [R] loading packages - mac user
In-Reply-To: <200510181858.j9IIwMeI003908@ohm.gene.com>
References: <e3930910510181146x2d6fd70avcc887d6259f08e54@mail.gmail.com>
	<200510181858.j9IIwMeI003908@ohm.gene.com>
Message-ID: <e3930910510181235g49df3712o7556e735222d9461@mail.gmail.com>

In the Mac version, there is no Packages>Load Packages as there is in
the PC version - instead there is the Package manager, which rejects
my attempts to download Rcmdr (it loads other packages ok, like boot,
graphics etc.) That was the error message I pasted at the end of my
mail - this makes me think that there is possibly some interference
with what I've already downloaded(?). Trying to work from the main
console, but I can't find a comprehensive, easy to understand list of
commands..
Cormac

On 10/18/05, Berton Gunter <gunter.berton at gene.com> wrote:
> You need to load it into R, I think. ?load -- or probably there is a menu
> item in the interface under "Packages" (there is in the Windows version,
> anyway).
>
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
>
> "The business of the statistician is to catalyze the scientific learning
> process."  - George E. P. Box
>
>
>
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Cormac Lawler
> > Sent: Tuesday, October 18, 2005 11:46 AM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] loading packages - mac user
> >
> > Hi,
> > I'm using a Mac, I've downloaded R (base), and I'm trying to download
> > the package R Commander. I thought I had already done this (both from
> > the web and from within R) but it doesn't seem to be working - it's
> > not there as a "search()" reveals. However, there are plenty of files
> > on my system linked with Rcmdr - located in
> > HD>Library>Frameworks>R.framework>Versions>2.1.1>Resources>Lib
> > rary>Rcmdr.
> > Is it simply in the wrong location to use it? The other possibility is
> > that I keep getting a tcltk error whenever I try to load up the
> > package from the Package Manager from within R - and when I try to
> > upload the tcltk package, this also gives the same error [1]. I also
> > get a "Couldn't launch application" error whenever I try to launch the
> > X11.app.
> >
> > This is probably so basic it's staring me in the eyes, but I need your
> > help please. I'd be happy to give any extra info you need.
> >
> > Thanks
> > Cormac
> >
> > [1] Loading required package: tcltk
> > Loading Tcl/Tk interface ... Error in dyn.load(x, as.logical(local),
> > as.logical(now)) :
> >       unable to load shared library
> > '/Library/Frameworks/R.framework/Resources/library/tcltk/libs/
> > tcltk.so':
> >   dlcompat: dyld: /Applications/R.app/Contents/MacOS/R can't open
> > library: /usr/local/lib/libtk8.4.dylib  (No such file or directory,
> > errno = 2)
> > In addition: Warning messages:
> > 1: cannot create HTML package index in: make.packages.html()
> > 2: cannot create HTML package index in: make.packages.html()
> > Error: .onLoad failed in 'loadNamespace' for 'tcltk'
> > Error: package 'tcltk' could not be loaded
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
>
>
>



From quantpm at yahoo.com  Tue Oct 18 21:45:37 2005
From: quantpm at yahoo.com (t c)
Date: Tue, 18 Oct 2005 12:45:37 -0700 (PDT)
Subject: [R] getting an aggregate count,
	and adding it to a dataset as a new column
In-Reply-To: <5ad2dec0510180317j12b21a35v@mail.gmail.com>
Message-ID: <20051018194537.60214.qmail@web35010.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051018/167fa808/attachment.pl

From cbehr at edesigndynamics.com  Tue Oct 18 21:50:14 2005
From: cbehr at edesigndynamics.com (Chris Behr)
Date: Tue, 18 Oct 2005 15:50:14 -0400
Subject: [R] sample size determination
Message-ID: <EBECLABIMNBHDFCEHCFHCEBECEAA.cbehr@edesigndynamics.com>

Hello,

I am a new user of R and trying to assess the sample size for data that is
being collected on water quality at sites across a wide geographic region. A
preliminary set of data has been collected and I would like to use it to
assess whether we are collecting enough data and in the right places.

A factorial approach was initially used to characterize sites by well type,
latrine type, distance between well and latrine, and ecological region.
Altogether the basic structure has:

3 types of wells
3 types of latrines
4 distance categories
13 regions

We define a ?site-type? as: a well-latrine-distance combination. There are
36 of these. A number of replicates (between 1 and 4) of the 36 site-types
are included in the set of sites in each of the 13 regions. Some regions
have more replicates than others due to complexity in the region. In total
there are 936 sites.

At this point, I have an ANOVA model with water quality measures and only
(these) categorical data. I want to know if I am collecting enough samples
(given alpha and beta levels) to see if there are effects for wells,
latrines, distances, and region (independently), as well as interactions for
well-distance, well-latrine, and well-region. I would like to also perform a
power analysis to allow the power vary with sample size.

I am working my way through various texts and help functions but thought I
would see if anyone else has learned how to do this already.

I would appreciate any and all guidance.

Best wishes, Chris

Christopher Behr
Principal Analyst

eDesign Dynamics
www.edesigndynamics.com
Christopher Behr
Principal Analyst

eDesign Dynamics
www.edesigndynamics.com

4024 Calvert St. NW
Washington DC 20007
(202) 298-6437 (t/f)
(551) 998-4823 (c)



From HStevens at MUOhio.edu  Tue Oct 18 21:51:47 2005
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Tue, 18 Oct 2005 15:51:47 -0400
Subject: [R] Repeating lines in a data frame
In-Reply-To: <BA6FF017E924044A9BF748AFAEEA6F304C8627@FWC-TLEX3.fwc.state.fl.us>
References: <BA6FF017E924044A9BF748AFAEEA6F304C8627@FWC-TLEX3.fwc.state.fl.us>
Message-ID: <0BBC293C-9575-42EA-8910-7BBC2DFE9768@MUOhio.edu>

See ?order, e.g.,
(a <- expand.grid(1998:2000,1:2,1:3))
attach(a)
(b <- a[order(Var1,Var3,Var2),])

Hank


On Oct 18, 2005, at 3:20 PM, Guenther, Cameron wrote:

> Hello,
> I have a much larger dataset that is similar in form to:
>  year species length count
>  1998       1    150     1
>  1998       2    200     1
>  1998       3    250     2
>  1999       1    150     3
>  1999       2    200     4
>  1999       3    250     5
>  2000       1    150     1
>  2000       2    200     1
>  2000       3    250     1
>  2001       1    150     2
>  2001       2    200     3
>  2001       3    250     1
>  2002       1    150     1
>  2002       2    200     2
>  2002       3    250     3
>
> What I want is to have a line of data for each year x species x length
> group combination
> I would like the ouput to be:
>
> Year species length count
> 1998       1    150     1
> 1998       2    200     1
> 1998       3    250     1
> 1998       3    250     1
> 1999       1    150     1
> 1999       1    150     1
> 1999       1    150     1
> 1999       2    200     1
> .
> .
> .
>
> Can anyone help me with a for statement of a function that can
> accomplish this?
> Thanks
>
> Cameron Guenther
> Associate Research Scientist
> FWC/FWRI, Marine Fisheries Research
> 100 8th Avenue S.E.
> St. Petersburg, FL 33701
> (727)896-8626 Ext. 4305
> cameron.guenther at myfwc.com
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting- 
> guide.html
>

Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"



From HStevens at MUOhio.edu  Tue Oct 18 22:09:26 2005
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Tue, 18 Oct 2005 16:09:26 -0400
Subject: [R] sample size determination
In-Reply-To: <EBECLABIMNBHDFCEHCFHCEBECEAA.cbehr@edesigndynamics.com>
References: <EBECLABIMNBHDFCEHCFHCEBECEAA.cbehr@edesigndynamics.com>
Message-ID: <BB3FF9BF-0889-4417-9B54-374823C04895@MUOhio.edu>

?power.anova.test is designed for 1 way models. I would be intrigued  
to found out more about power in complicated designs. Do look into  
the archives at
http://finzi.psych.upenn.edu/search.html
  In the past, I used power.t.test on individual model coefficients,  
though I am not sure it was correct.
Hank Stevens

On Oct 18, 2005, at 3:50 PM, Chris Behr wrote:

> Hello,
>
> I am a new user of R and trying to assess the sample size for data  
> that is
> being collected on water quality at sites across a wide geographic  
> region. A
> preliminary set of data has been collected and I would like to use  
> it to
> assess whether we are collecting enough data and in the right places.
>
> A factorial approach was initially used to characterize sites by  
> well type,
> latrine type, distance between well and latrine, and ecological  
> region.
> Altogether the basic structure has:
>
> 3 types of wells
> 3 types of latrines
> 4 distance categories
> 13 regions
>
> We define a ?site-type? as: a well-latrine-distance combination.  
> There are
> 36 of these. A number of replicates (between 1 and 4) of the 36  
> site-types
> are included in the set of sites in each of the 13 regions. Some  
> regions
> have more replicates than others due to complexity in the region.  
> In total
> there are 936 sites.
>
> At this point, I have an ANOVA model with water quality measures  
> and only
> (these) categorical data. I want to know if I am collecting enough  
> samples
> (given alpha and beta levels) to see if there are effects for wells,
> latrines, distances, and region (independently), as well as  
> interactions for
> well-distance, well-latrine, and well-region. I would like to also  
> perform a
> power analysis to allow the power vary with sample size.
>
> I am working my way through various texts and help functions but  
> thought I
> would see if anyone else has learned how to do this already.
>
> I would appreciate any and all guidance.
>
> Best wishes, Chris
>
> Christopher Behr
> Principal Analyst
>
> eDesign Dynamics
> www.edesigndynamics.com
> Christopher Behr
> Principal Analyst
>
> eDesign Dynamics
> www.edesigndynamics.com
>
> 4024 Calvert St. NW
> Washington DC 20007
> (202) 298-6437 (t/f)
> (551) 998-4823 (c)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting- 
> guide.html
>

Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"



From peteoutside at yahoo.com  Tue Oct 18 22:09:38 2005
From: peteoutside at yahoo.com (Pete Cap)
Date: Tue, 18 Oct 2005 13:09:38 -0700 (PDT)
Subject: [R] Altering domain & range in an interactive plot using tcl/tk
Message-ID: <20051018200939.13056.qmail@web52408.mail.yahoo.com>

List,

I am trying to create a simulated spectrum analyzer in
R.  The user gets as output a power spectrum (plot of
power vs. time).

I want the user to be able to change the center
frequency (midpoint between xMin and xMax) and window
size (distance from xMin to xMax) using sliders in
tkrplot.  This will allow the user to scroll left and
right and "zoom" in and out.

I can get the sliders to appear just fine.  If I
manipulate the sliders, then drop from the plot window
back down to the interactive prompt and call
tkrreplot, then plot updates.  How can I get this to
happen automatically (e.g. every time you move the
slider, the plot updates)?

Thanks in advance,
Pete

PS: If anyone has any tips on the UI please feel free
to offer those as well.



From tlumley at u.washington.edu  Tue Oct 18 22:13:32 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 18 Oct 2005 13:13:32 -0700 (PDT)
Subject: [R] loading packages - mac user
In-Reply-To: <e3930910510181146x2d6fd70avcc887d6259f08e54@mail.gmail.com>
References: <e3930910510181146x2d6fd70avcc887d6259f08e54@mail.gmail.com>
Message-ID: <Pine.LNX.4.63a.0510181310040.30016@homer24.u.washington.edu>

On Tue, 18 Oct 2005, Cormac Lawler wrote:

> Hi,
> I'm using a Mac, I've downloaded R (base), and I'm trying to download
> the package R Commander. I thought I had already done this (both from
> the web and from within R) but it doesn't seem to be working - it's
> not there as a "search()" reveals.

You need to load it (with the Package Manager) as well as download it, but 
that isn't the only isuue

>However, there are plenty of files
> on my system linked with Rcmdr - located in
> HD>Library>Frameworks>R.framework>Versions>2.1.1>Resources>Library>Rcmdr.
> Is it simply in the wrong location to use it? The other possibility is
> that I keep getting a tcltk error whenever I try to load up the
> package from the Package Manager from within R - and when I try to
> upload the tcltk package, this also gives the same error [1].

Yes, Rcmdr needs the tcltk package, so this would explain the problem. The 
error message below suggests that Tcl/Tk is not on your system.

  I also
> get a "Couldn't launch application" error whenever I try to launch the
> X11.app.

Both for this and for working out why Tcl/Tk isn't installed you might be 
better off trying R-sig-mac rather than r-help

 	-thomas

> This is probably so basic it's staring me in the eyes, but I need your
> help please. I'd be happy to give any extra info you need.
>
> Thanks
> Cormac
>
> [1] Loading required package: tcltk
> Loading Tcl/Tk interface ... Error in dyn.load(x, as.logical(local),
> as.logical(now)) :
> 	unable to load shared library
> '/Library/Frameworks/R.framework/Resources/library/tcltk/libs/tcltk.so':
>  dlcompat: dyld: /Applications/R.app/Contents/MacOS/R can't open
> library: /usr/local/lib/libtk8.4.dylib  (No such file or directory,
> errno = 2)
> In addition: Warning messages:
> 1: cannot create HTML package index in: make.packages.html()
> 2: cannot create HTML package index in: make.packages.html()
> Error: .onLoad failed in 'loadNamespace' for 'tcltk'
> Error: package 'tcltk' could not be loaded
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From xprt.wannabe at gmail.com  Tue Oct 18 22:18:42 2005
From: xprt.wannabe at gmail.com (xpRt.wannabe)
Date: Tue, 18 Oct 2005 15:18:42 -0500
Subject: [R] Another question related to box-percentile plot,
	bpplot(): How to color the "box" or middle half of the data
Message-ID: <a4fecdd70510181318n615a41a1v4dab1c696f44b37a@mail.gmail.com>

Dear List,

A follow-up question related to bpplot() of the Hmisc package: How does
one
color the "box" , or the middle half of the data, of a box-percentile
plot?
bpplot(... , col="lightgray") apparently does not work, though
boxplot(...
, col="lightgray") works.

With much appreciation,

platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    1.0
year     2005
month    04
day      18
language R



From june0821 at email.unc.edu  Tue Oct 18 22:32:58 2005
From: june0821 at email.unc.edu (Jungyeon Yoon)
Date: Tue, 18 Oct 2005 16:32:58 -0400 (EDT)
Subject: [R] biplot.default
Message-ID: <Pine.A41.4.44+UNC.0510181627140.36468-100000@login1.isis.unc.edu>

Hi,

I've been trying to understand biplot. From
getAnywhere(biplot.default), I could get the source code. However, there
is one line that did make sense to me. It's the second line from the
bottom.

arrow(0, 0, y[,1]*0.8, y[,2]*0.8, col = col[2],....)

I don't understand why there is a multiplication by 0.8 for y.

Thanks.



From kutchbhihosakatahai at yahoo.de  Tue Oct 18 20:22:16 2005
From: kutchbhihosakatahai at yahoo.de (Christian Zinsmeister)
Date: Tue, 18 Oct 2005 19:22:16 +0100 (BST)
Subject: [R] Defining range of x and y axis in pairs()
Message-ID: <20051018182217.47680.qmail@web25608.mail.ukl.yahoo.com>

Hi,

I have a problem to define the range of x and y axis in pairs() for my
scatterplots. In low-level plots I can specify that by providing xlim
and ylim. This also works for pairs() even if warnings tell me that it
doesn't (see below). 

But if I add upper.panel and/or lower.panel it doesn't work - I get an
error message saying that there's an error in "upper.panel
(as.vector(x[, j]), as.vector(x[, i]), ...)"!? 

I know that (according to ?pairs) graphical parameters can be passed to
pairs() and xlim/ylim are *not* graphical parameters - I just wonder
why it anyway works in the first case. 

Can anyway tell me how to adjust my pairs statement either using
xlim/ylim in a different way or by using totally different options?
(I'm a newbie to R)


# This works!
pairs(x, panel=points, xlim=c(-2,2));

# This one doesn't work
pairs(x, panel=points, xlim=c(-2,2), lower.panel=panel.cor,
upper.panel=panel.smooth);

# this is the function for lower.panel
    panel.cor <- function(x, y)
    {
        usr <- par("usr"); on.exit(par(usr))
        par(usr = c(0, 1, 0, 1))
        txt <- cov(x, y, use="pairwise.complete.obs");
        text(0.5, 0.5, txt);}
   }

Thanks!



From tchur at optushome.com.au  Tue Oct 18 22:47:23 2005
From: tchur at optushome.com.au (Tim Churches)
Date: Wed, 19 Oct 2005 06:47:23 +1000
Subject: [R] Efficient ways of finding functions and Breslow-Day	test
 for homogeneity of the odds ratio
In-Reply-To: <1129647656.5251.8.camel@localhost.localdomain>
References: <8397484.1129645664@epi-pc64.epi.bris.ac.uk>
	<1129647656.5251.8.camel@localhost.localdomain>
Message-ID: <43555F5B.2090204@optushome.com.au>

Marc Schwartz (via MN) wrote:

> There is also code for the Woolf test in ?mantelhaen.test

Is there? How is it obtained? The documentation on mantelhaen.test in R
2.2.0 contains a note: "Currently, no inference on homogeneity of the
odds ratios is performed." and a quick scan of the source code for the
function didn't reveal any meantion of Woolf's test.

Tim C



From jholtman at gmail.com  Tue Oct 18 22:48:51 2005
From: jholtman at gmail.com (jim holtman)
Date: Tue, 18 Oct 2005 16:48:51 -0400
Subject: [R] Repeating lines in a data frame
In-Reply-To: <BA6FF017E924044A9BF748AFAEEA6F304C8627@FWC-TLEX3.fwc.state.fl.us>
References: <BA6FF017E924044A9BF748AFAEEA6F304C8627@FWC-TLEX3.fwc.state.fl.us>
Message-ID: <644e1f320510181348v7c7855b7sf4c73075d48b8157@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051018/66cc29ef/attachment.pl

From sundar.dorai-raj at pdf.com  Tue Oct 18 22:56:41 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 18 Oct 2005 15:56:41 -0500
Subject: [R] Repeating lines in a data frame
In-Reply-To: <BA6FF017E924044A9BF748AFAEEA6F304C8627@FWC-TLEX3.fwc.state.fl.us>
References: <BA6FF017E924044A9BF748AFAEEA6F304C8627@FWC-TLEX3.fwc.state.fl.us>
Message-ID: <43556189.8010305@pdf.com>



Guenther, Cameron wrote:
> Hello,
> I have a much larger dataset that is similar in form to:
>  year species length count
>  1998       1    150     1
>  1998       2    200     1
>  1998       3    250     2
>  1999       1    150     3
>  1999       2    200     4
>  1999       3    250     5
>  2000       1    150     1
>  2000       2    200     1
>  2000       3    250     1
>  2001       1    150     2
>  2001       2    200     3
>  2001       3    250     1
>  2002       1    150     1
>  2002       2    200     2
>  2002       3    250     3
> 
> What I want is to have a line of data for each year x species x length
> group combination
> I would like the ouput to be:
> 
> Year species length count
> 1998       1    150     1
> 1998       2    200     1
> 1998       3    250     1
> 1998       3    250     1
> 1999       1    150     1
> 1999       1    150     1
> 1999       1    150     1
> 1999       2    200     1
> .
> .
> .
> 
> Can anyone help me with a for statement of a function that can
> accomplish this?


How about:

r <- rep(row.names(x), x$count)
y <- x[r, ]
y$count <- rep(1, nrow(y))

where `x' is your data.frame. This will also create new row.names what 
show where the duplicates are.

HTH,

--sundar



From dsmith at insightful.com  Tue Oct 18 22:57:59 2005
From: dsmith at insightful.com (David Smith)
Date: Tue, 18 Oct 2005 13:57:59 -0700
Subject: [R] Packages in R and in S-PLUS
Message-ID: <EDAC416B87ECCA44BEAB4D0CF48034EF860560@se2kexch01.insightful.com>

Bj??rn-Helge Mevik writes:
> > tools to make it easy to convert R packages to S-PLUS.
> 
> Not the other way around as well?

Actually, we'll be discussing tools to make packages in general that can work
in both S-PLUS and R, and also how to make some S-PLUS-only libraries
available in an open-source environment as well as working with package
authors to port R packages to work in S-PLUS.

We'll be discussing this in detail at the S-PLUS User Conference, but I'd
also welcome any thoughts package authors and package users might have about
making packages widely available in both S-PLUS and R environments.  I'll
summarize emails sent to me to this list.

# David Smith

-- 
David M Smith <dsmith at insightful.com>
Product Manager, Insightful Corp, Seattle WA
Tel: +1 (206) 802 2360
Fax: +1 (206) 283 6310

Insightful 2005 User Conference
Princeton, NJ, Oct. 26-27, 2005
Don't miss the keynote by Dr. William Meeker
Special Pricing: $199 commercial/$99 academic
www.insightful.com/news_events/2005uc

> -----Original Message-----
> From: Bj??rn-Helge Mevik [mailto:bhs2 at mevik.net]
> Sent: Tuesday, October 18, 2005 2:20 AM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] Insightful Announces: "R and S-PLUS- Panel 
> Discussion"
> at9th Annual 2005 User Conference
> 
> 
> Michael O'Connell wrote:
> 
> > tools to make it easy to convert R packages to S-PLUS.
> 
> Not the other way around as well?
> 
> -- 
> Bj??rn-Helge Mevik
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From mschwartz at mn.rr.com  Tue Oct 18 22:58:19 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Tue, 18 Oct 2005 15:58:19 -0500
Subject: [R] Efficient ways of finding functions and
	Breslow-Day	test	for homogeneity of the odds ratio
In-Reply-To: <43555F5B.2090204@optushome.com.au>
References: <8397484.1129645664@epi-pc64.epi.bris.ac.uk>
	<1129647656.5251.8.camel@localhost.localdomain>
	<43555F5B.2090204@optushome.com.au>
Message-ID: <1129669099.5251.57.camel@localhost.localdomain>

On Wed, 2005-10-19 at 06:47 +1000, Tim Churches wrote:
> Marc Schwartz (via MN) wrote:
> 
> > There is also code for the Woolf test in ?mantelhaen.test
> 
> Is there? How is it obtained? The documentation on mantelhaen.test in R
> 2.2.0 contains a note: "Currently, no inference on homogeneity of the
> odds ratios is performed." and a quick scan of the source code for the
> function didn't reveal any meantion of Woolf's test.
> 
> Tim C


Review the code in the examples on the cited help page...

:-)

HTH,

Marc



From ripley at stats.ox.ac.uk  Tue Oct 18 23:21:00 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Oct 2005 22:21:00 +0100 (BST)
Subject: [R] biplot.default
In-Reply-To: <Pine.A41.4.44+UNC.0510181627140.36468-100000@login1.isis.unc.edu>
References: <Pine.A41.4.44+UNC.0510181627140.36468-100000@login1.isis.unc.edu>
Message-ID: <Pine.LNX.4.61.0510182219340.17162@gannet.stats>

On Tue, 18 Oct 2005, Jungyeon Yoon wrote:

> I've been trying to understand biplot. From
> getAnywhere(biplot.default), I could get the source code. However, there
> is one line that did make sense to me. It's the second line from the
> bottom.
>
> arrow(0, 0, y[,1]*0.8, y[,2]*0.8, col = col[2],....)
>
> I don't understand why there is a multiplication by 0.8 for y.

Try it without to see. It is to help the aesthetics of the plot.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ed_wolfrum at nrel.gov  Tue Oct 18 23:26:33 2005
From: ed_wolfrum at nrel.gov (Wolfrum, Ed)
Date: Tue, 18 Oct 2005 15:26:33 -0600
Subject: [R] Finding code for R functions
Message-ID: <9228D7EC9A32594191AA7530DB5314491FBADD@mail-3a.nrel.gov>

Greetings,

I am trying to figure out how to find the source code for R functions. I
am specifically interested in finding the code for the "prcomp"
function. I know that typing the function name without parenthesis will
lead to the code (or to a .Internal or .FORTRAN or .C  call). However, I
don't really understand what is going on. For example, typing "mean"
gives a "UseMethod" response, while typing "mean.default" give the
actual code:

> mean
function (x, ...) 
UseMethod("mean")
<environment: namespace:base>

> mean.default
function (x, trim = 0, na.rm = FALSE, ...) 
---SNIP---
}
<environment: namespace:base>

Why is this? What does "mean.default" mean? I tried the same thing with
"prcomp". With the stats package loaded, I cannot get to the source code
for "prcomp".

> require(stats)
[1] TRUE
> prcomp
function (x, ...) 
UseMethod("prcomp")
<environment: namespace:stats>
> prcomp.default
Error: object "prcomp.default" not found
 
How do I find the prcomp code? Are there general rules for finding the
source code for functions that I should know?

Thanks in Advance,

Edward J. Wolfrum, Ph.D.
National Renewable Energy Laboratory
Golden, Colorado



From ripley at stats.ox.ac.uk  Tue Oct 18 23:28:24 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Oct 2005 22:28:24 +0100 (BST)
Subject: [R] Defining range of x and y axis in pairs()
In-Reply-To: <20051018182217.47680.qmail@web25608.mail.ukl.yahoo.com>
References: <20051018182217.47680.qmail@web25608.mail.ukl.yahoo.com>
Message-ID: <Pine.LNX.4.61.0510182221560.17162@gannet.stats>

Your panel function is missing a ... argument, hence the difference in the 
two cases.

As to why it works, as someone once said, it does `for some value of 
"work"'.  Amongst the many places xlim gets passed is one that set the 
scale on each panel.  Another place it gets sent is to your panel 
function.

On Tue, 18 Oct 2005, Christian Zinsmeister wrote:

> Hi,
>
> I have a problem to define the range of x and y axis in pairs() for my
> scatterplots. In low-level plots I can specify that by providing xlim
> and ylim. This also works for pairs() even if warnings tell me that it
> doesn't (see below).
>
> But if I add upper.panel and/or lower.panel it doesn't work - I get an
> error message saying that there's an error in "upper.panel
> (as.vector(x[, j]), as.vector(x[, i]), ...)"!?
                                          ^^^
> I know that (according to ?pairs) graphical parameters can be passed to
> pairs() and xlim/ylim are *not* graphical parameters - I just wonder
> why it anyway works in the first case.
>
> Can anyway tell me how to adjust my pairs statement either using
> xlim/ylim in a different way or by using totally different options?
> (I'm a newbie to R)
>
>
> # This works!
> pairs(x, panel=points, xlim=c(-2,2));
>
> # This one doesn't work
> pairs(x, panel=points, xlim=c(-2,2), lower.panel=panel.cor,
> upper.panel=panel.smooth);
>
> # this is the function for lower.panel
>    panel.cor <- function(x, y)
>    {
>        usr <- par("usr"); on.exit(par(usr))
>        par(usr = c(0, 1, 0, 1))
>        txt <- cov(x, y, use="pairwise.complete.obs");
>        text(0.5, 0.5, txt);}
>   }
>
> Thanks!
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gunter.berton at gene.com  Tue Oct 18 23:38:38 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Tue, 18 Oct 2005 14:38:38 -0700
Subject: [R] Finding code for R functions
In-Reply-To: <9228D7EC9A32594191AA7530DB5314491FBADD@mail-3a.nrel.gov>
Message-ID: <200510182138.j9ILcc5D015536@faraday.gene.com>

See chapter 5 on object oriented programming in the R language definition
manual. Also the  ?UseMethod man page. These will explain R's (S3) method
dispatch procedures.

Finally, search on CRAN for the R New newsletter article on namespaces,
which is where you'll find info on why you can't "see" certain functions.
See ?getAnywhere to learn how to see code for functions in namespaces.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Wolfrum, Ed
> Sent: Tuesday, October 18, 2005 2:27 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Finding code for R functions
> 
> Greetings,
> 
> I am trying to figure out how to find the source code for R 
> functions. I
> am specifically interested in finding the code for the "prcomp"
> function. I know that typing the function name without 
> parenthesis will
> lead to the code (or to a .Internal or .FORTRAN or .C  call). 
> However, I
> don't really understand what is going on. For example, typing "mean"
> gives a "UseMethod" response, while typing "mean.default" give the
> actual code:
> 
> > mean
> function (x, ...) 
> UseMethod("mean")
> <environment: namespace:base>
> 
> > mean.default
> function (x, trim = 0, na.rm = FALSE, ...) 
> ---SNIP---
> }
> <environment: namespace:base>
> 
> Why is this? What does "mean.default" mean? I tried the same 
> thing with
> "prcomp". With the stats package loaded, I cannot get to the 
> source code
> for "prcomp".
> 
> > require(stats)
> [1] TRUE
> > prcomp
> function (x, ...) 
> UseMethod("prcomp")
> <environment: namespace:stats>
> > prcomp.default
> Error: object "prcomp.default" not found
>  
> How do I find the prcomp code? Are there general rules for finding the
> source code for functions that I should know?
> 
> Thanks in Advance,
> 
> Edward J. Wolfrum, Ph.D.
> National Renewable Energy Laboratory
> Golden, Colorado
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From pburns at pburns.seanet.com  Tue Oct 18 23:40:09 2005
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Tue, 18 Oct 2005 22:40:09 +0100
Subject: [R] The meaning of functional language
In-Reply-To: <0IOK00G4Y492EA@mail.fudan.edu.cn>
References: <0IOK00G4Y492EA@mail.fudan.edu.cn>
Message-ID: <43556BB9.5080509@pburns.seanet.com>

ronggui wrote:

>It's often heard that the S language is a  functional language.But What's the exact meaning of this termology in the context of S language?
>  
>

Here's the idea. If you have:

x <- 1:10
f <- function(y) { x <- sin(y / 2); x + y}
f(-3:3)

then the 'x' inside 'f' does not wipe out your top-level 'x'
when 'f' is called.

Operationally it means that objects are only changed via
the assignment operator. (This is not strictly true, but other
vehicles, such as '<<-', are generally considered bad style.)

The reason for wanting this behavior is so that you don't need
to worry about objects getting invisibly changed while you
are analyzing some data, or whatever it is that you are doing.
That is, the language was designed to be human efficient, while
sacrificing some machine efficiency.

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")



From gunter.berton at gene.com  Wed Oct 19 00:37:25 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Tue, 18 Oct 2005 15:37:25 -0700
Subject: [R] The meaning of functional language
In-Reply-To: <43556BB9.5080509@pburns.seanet.com>
Message-ID: <200510182237.j9IMbPA3021325@hertz.gene.com>

'functional'  languages derive from LISP and the lamda-calculus. These are
standard topics in CS computer language courses. You can look them up in
Wikipedia, or Google for other sources.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Patrick Burns
> Sent: Tuesday, October 18, 2005 2:40 PM
> To: ronggui
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] The meaning of functional language
> 
> ronggui wrote:
> 
> >It's often heard that the S language is a  functional 
> language.But What's the exact meaning of this termology in 
> the context of S language?
> >  
> >
> 
> Here's the idea. If you have:
> 
> x <- 1:10
> f <- function(y) { x <- sin(y / 2); x + y}
> f(-3:3)
> 
> then the 'x' inside 'f' does not wipe out your top-level 'x'
> when 'f' is called.
> 
> Operationally it means that objects are only changed via
> the assignment operator. (This is not strictly true, but other
> vehicles, such as '<<-', are generally considered bad style.)
> 
> The reason for wanting this behavior is so that you don't need
> to worry about objects getting invisibly changed while you
> are analyzing some data, or whatever it is that you are doing.
> That is, the language was designed to be human efficient, while
> sacrificing some machine efficiency.
> 
> Patrick Burns
> patrick at burns-stat.com
> +44 (0)20 8525 0696
> http://www.burns-stat.com
> (home of S Poetry and "A Guide for the Unwilling S User")
> 
>



From murdoch at stats.uwo.ca  Wed Oct 19 01:00:02 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 18 Oct 2005 19:00:02 -0400
Subject: [R] Finding code for R functions
In-Reply-To: <9228D7EC9A32594191AA7530DB5314491FBADD@mail-3a.nrel.gov>
References: <9228D7EC9A32594191AA7530DB5314491FBADD@mail-3a.nrel.gov>
Message-ID: <43557E72.5080508@stats.uwo.ca>

Wolfrum, Ed wrote:
> Greetings,
> 
> I am trying to figure out how to find the source code for R functions. I
> am specifically interested in finding the code for the "prcomp"
> function. I know that typing the function name without parenthesis will
> lead to the code (or to a .Internal or .FORTRAN or .C  call). However, I
> don't really understand what is going on. For example, typing "mean"
> gives a "UseMethod" response, while typing "mean.default" give the
> actual code:
> 
> 
>>mean
> 
> function (x, ...) 
> UseMethod("mean")
> <environment: namespace:base>
> 
>>mean.default
> 
> function (x, trim = 0, na.rm = FALSE, ...) 
> ---SNIP---
> }
> <environment: namespace:base>
> 
> Why is this? What does "mean.default" mean? I tried the same thing with
> "prcomp". With the stats package loaded, I cannot get to the source code
> for "prcomp".
> 
> 
>>require(stats)
> 
> [1] TRUE
> 
>>prcomp
> 
> function (x, ...) 
> UseMethod("prcomp")
> <environment: namespace:stats>

That is the source for prcomp.  It's a one-liner, that says to call the 
prcomp method for whatever type of x you're passing in.  As Bert said, 
you need to read up on methods.

> 
>>prcomp.default
> 
> Error: object "prcomp.default" not found

Notice that prcomp lives in "namespace:stats"?  That's the first place 
to look for prcomp methods.  Besides getAnywhere which Bert suggested, 
you can try

stats:::prcomp.default

to see the method.  (Methods aren't necessarily in the same namespace as 
the generic, but that's the most common place for them.)

Duncan Murdoch
>  
> How do I find the prcomp code? Are there general rules for finding the
> source code for functions that I should know?
> 
> Thanks in Advance,
> 
> Edward J. Wolfrum, Ph.D.
> National Renewable Energy Laboratory
> Golden, Colorado
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From tchur at optushome.com.au  Wed Oct 19 01:00:27 2005
From: tchur at optushome.com.au (Tim Churches)
Date: Wed, 19 Oct 2005 09:00:27 +1000
Subject: [R] Efficient ways of finding functions and Breslow-Day
 test	for homogeneity of the odds ratio
Message-ID: <200510182300.j9IN0RPb000712@mail14.syd.optusnet.com.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051019/6af389e8/attachment.pl

From Robert.McGehee at geodecapital.com  Wed Oct 19 01:04:36 2005
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Tue, 18 Oct 2005 19:04:36 -0400
Subject: [R] cbind/rbind and NULL
Message-ID: <67DCA285A2D7754280D3B8E88EB548020C9466DE@MSGBOSCLB2WIN.DMN1.FMR.COM>

I'm trying to understand why I can rbind but not cbind dataframes to
NULLs.

	For 'cbind' ('rbind'), vectors of zero length (including 'NULL')
     are ignored unless the result would have zero rows (columns),  for
     S compatibility. (Zero-extent matrices do not occur in S3 and are
     not ignored in R.)

Since NULL is a vector of length 0, should it not be ignored for both
cbind and rbind? If not, then shouldn't it fail for the same reason for
both functions?

> data(USArrests)
> rbind(USArrests, NULL)
               Murder Assault UrbanPop Rape
Alabama          13.2     236       58 21.2
Alaska           10.0     263       48 44.5
...

> cbind(USarrests, NULL)
Error in data.frame(..., check.names = FALSE) : 
        arguments imply differing number of rows: 50, 0

Also, cbinding vectors works:
> cbind(USArrests[,1], NULL)
      [,1]
 [1,] 13.2
 [2,] 10.0
 [3,]  8.1

But not if USArrests is a dataframe:

> cbind(USArrests[,1, drop = FALSE], NULL)
Error in data.frame(..., check.names = FALSE) : 
        arguments imply differing number of rows: 50, 0

Thanks, 
Robert


> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    2.0            
year     2005           
month    10             
day      06             
svn rev  35749          
language R              
>



From nautix at u.washington.edu  Wed Oct 19 01:47:26 2005
From: nautix at u.washington.edu (Brian Haney)
Date: Tue, 18 Oct 2005 16:47:26 -0700
Subject: [R] JGR help.search
Message-ID: <4355898E.3080203@u.washington.edu>

If there is a better forum for JGR questions, please redirect me.

Whenever I try to open the help browser in JGR (by clicking on Help -> R
Help, or by entering help() or help.start() at the console), it pops
open a window complaining that a path was not found and that help will
not be available, followed (after ack of the first) by another window
that complains along the lines "URL Error:
/tmp/Rtmpk7DtNG/.R/doc/html/packages.html (No such file or directory)"

After acknowledgement of the second window a help browser opens but
seems to have no content.  Searching on the word "list" opens a new tab
attached to an empty page.

I expected the help browser to open without complains and offer a series
of topics and links by which to peruse the help files.

I am ever so grateful for any insight that may be offered.

-- 
Brian Haney, Software Engineer & UNIX Systems Administrator
University of Washington, Dept of Biostatistics



From alexisjdiamond at gmail.com  Wed Oct 19 05:18:07 2005
From: alexisjdiamond at gmail.com (Alexis Diamond)
Date: Tue, 18 Oct 2005 23:18:07 -0400
Subject: [R] ipop (kernlab) gives pars < lower bound ?
Message-ID: <67be2ce30510182018i3dd40c2xcaf675a3801ead81@mail.gmail.com>

hi everyone,

ipop very quickly and accurately identifies the correct parameters in
a toy dataset i built, but when i use ipop on the real dataset i get
values for the parameters  " primal(res) "  that are less than zero,
even though i specify zero for the lower bound :  l = rep(0,
length(c)) , where length(c) is the number of parameters i'm trying to
identify.

the parameters are not A LOT less than zero-- they're close to zero,
but still too large a problem to ignore. (eg., i get a value X1 =
-0.006 -- it wouldn't be a problem if X1 was btw -1 e-5 and zero, but
it's not.)
can anyone suggest a remedy?

i'm wondering if this could be caused by where i've set my "range" and
my "bound".  i've played a little with range, but it hasn't helped.  i
don't know how to use "bound"-- i don't understand the info on "bound"
on the ipop Rhelp page.
"sigf" is at default 7 sig figs, and the negative numbers are not
within that threshold of zero.

i'm also wondering if this problem could be related to the warning
messages i receive when i run ipop :

Warning:
number of columns of result
       not a multiple of vector length (arg 2) in: rbind(rho, tau, alpha, nu)

i get this warning message in both the toy dataset and the real
dataset, though as i mentioned i only get negative (illegal) parameter
values with the real dataset.
i don't know why i get this message, or what to do about it.

any advice is very much appreciated!

alexis



From spencer.graves at pdf.com  Wed Oct 19 05:55:26 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 18 Oct 2005 20:55:26 -0700
Subject: [R] Analyses of covariation with lme() or lm()
In-Reply-To: <4343D0BA.8030103@evp.slu.se>
References: <4343D0BA.8030103@evp.slu.se>
Message-ID: <4355C3AE.7020105@pdf.com>

	  Trial consumes 10 degrees of freedom as a fixed effect in m5 but only 
1 degree of freedom as a random effect in m1 and m3.  The 11 different 
Trials are NOT 11 different, completely unrelated entities wiht no 
relation to one another, as assumed by m5.  They are 11 different 
instances of more or less the same thing, with variations, as assumed by 
m1 and m3.

	  Models m2 and m4 are not plausible, because they assume you have 
3*4*11 independent observations.  This is almost certainly wrong, as 
substantiated by your comparisons of m1 with m2 and m3 with m4.  In 
fact, the concept of an independent observation breaks down in this 
context, because you have, in essence, at least 11 but definitely less 
than 3*4*11;  the exact number of "independent observations" to be used 
for an F test, etc., is not easy to define.  However, it seems clear 
that m5 makes no more sense than m2 and m4.

	  Does this help?

	  spencer graves

CG Pettersson wrote:
> Hello all!
> 
> I have a problem that calls for a better understanding, than mine, of 
> how lme() uses the random part of the call.
> 
> The dataset consists of eleven field trials (Trial) with three 
> replicates (Block) and four fertiliser treatments (Treat). Analysing for 
>   example yield with lme() is easy:
> 
> m1 <- lme(Yield ~ Treat, data=data,
>            random =~1| Trial/Block)
> 
> giving estimates of Treat effects with good significances. If I compare 
> m1 with the model without any random structure:
> 
> m2 <- lm(Yield ~ Treat, data=data),
> m1 is, naturally, much better than m2. So far so good.
> 
> Now I have one (1) measure from each Trial, of soil factors weather and 
> such, that I want to evaluate. Remember: only one value of the covariate 
> for each Trial. The suggestion I have got from my local guru is to base 
> this in m1 like:
> 
> m3 <- lme(Yield ~ Treat + Cov1 + Treat:Cov1, data=data,
>            random =~1| Trial/Block)
> 
> thus giving a model where the major random factor (Trial) is represented 
>   both as a (1) measure of Cov1 in the fixed part and by itself in the 
> random part. Trying the simpler call:
> 
> m4 <- lm(Yield ~ Treat + Cov1 + Treat:Cov1, data=data)
> 
> gives back basically the same fixed effects as m3, but with better 
> significances for Cov1. Tested with anova(m3,m4) naturally gives the 
> answer that m3 is better than m4. Ok, what about dealing with Trial in 
> the fixed call? :
> 
> m5 <- lm(Yield ~ Trial + Treat + Cov1 + Treat:Cov1, data=data)
> 
> lm() swallows this, but silently moves out Cov1 from the analysis, an 
> action that feels very logical to me.
> 
> My guru says that using the random call secures you from overestimating 
> the p-values of the covariate. I fear that the risk is as big that you 
> underestimate them with the same action. Working on a paper, I naturally 
> want to be able to do some sort of discussion on the impact of 
> covariates... ;-)
> 
> What is the wise solution? Or, if this is trying to make other people do 
> my homework, could anyone tell me where the homework is? (I??ve got both 
> Pinhiero & Bates and MASS as well as some others in the bookshelf.)
> 
> Cheers
> /CG
> 

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From arun.raj at gmail.com  Wed Oct 19 06:06:59 2005
From: arun.raj at gmail.com (arun r)
Date: Tue, 18 Oct 2005 23:06:59 -0500
Subject: [R] Installing Bioconductor on R
In-Reply-To: <x2d5m2zp4l.fsf@viggo.kubism.ku.dk>
References: <Pine.LNX.4.64.0510181151210.2525@orca_login1.st.usm.edu>
	<x2d5m2zp4l.fsf@viggo.kubism.ku.dk>
Message-ID: <314913e80510182106h513ec53an3c5811e0005b263d@mail.gmail.com>

On 18 Oct 2005 19:55:22 +0200, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> Arunkumar R <arajendr at orca.st.usm.edu> writes:
>
> > hi all,
> >            Am new to R. I am having problems installing Bioconductor package in
> > R on fedora core 4 running on AMD64 bit machine.
>
> Where did you get your R and which version? This is not happening to
> me with R-2.2.0 from Fedora Extras:

Thanks, for the response, after I upgraded R to 2.2.0 , I was able to
install Bioconductor package .



From alexisjdiamond at gmail.com  Wed Oct 19 06:11:30 2005
From: alexisjdiamond at gmail.com (Alexis Diamond)
Date: Wed, 19 Oct 2005 00:11:30 -0400
Subject: [R] ipop (kernlab) gives pars < lower bound ?
In-Reply-To: <67be2ce30510182018i3dd40c2xcaf675a3801ead81@mail.gmail.com>
References: <67be2ce30510182018i3dd40c2xcaf675a3801ead81@mail.gmail.com>
Message-ID: <67be2ce30510182111n5d4b0f57i509ab0e1e7d992f6@mail.gmail.com>

hi again,

i have fixed some of the problems i emailed about previously-- the
answer is to fiddle with the "margin" variable.  but new problems have
arisen: when i set the "margin" variable appropriately to preclude
negative values, i get the following error message:

Error in drop(.Call("La_dgesv", a, as matrix(b), tol, PACKAGE = "base")) :
system is comptuationally singular: reciprocal condition number = 1.57163 e-16

and i was wondering if there's anything i can do about it, or if my
data is just not good for this problem.

also, i am still curious about
(1) how to use ipop's "bound" argument

(2) what should i make of the warning message discussed below?

thanks again,

alexis

On 10/18/05, Alexis Diamond <alexisjdiamond at gmail.com> wrote:
> hi everyone,
>
> ipop very quickly and accurately identifies the correct parameters in
> a toy dataset i built, but when i use ipop on the real dataset i get
> values for the parameters  " primal(res) "  that are less than zero,
> even though i specify zero for the lower bound :  l = rep(0,
> length(c)) , where length(c) is the number of parameters i'm trying to
> identify.
>
> the parameters are not A LOT less than zero-- they're close to zero,
> but still too large a problem to ignore. (eg., i get a value X1 =
> -0.006 -- it wouldn't be a problem if X1 was btw -1 e-5 and zero, but
> it's not.)
> can anyone suggest a remedy?
>
> i'm wondering if this could be caused by where i've set my "range" and
> my "bound".  i've played a little with range, but it hasn't helped.  i
> don't know how to use "bound"-- i don't understand the info on "bound"
> on the ipop Rhelp page.
> "sigf" is at default 7 sig figs, and the negative numbers are not
> within that threshold of zero.
>
> i'm also wondering if this problem could be related to the warning
> messages i receive when i run ipop :
>
> Warning:
> number of columns of result
>        not a multiple of vector length (arg 2) in: rbind(rho, tau, alpha, nu)
>
> i get this warning message in both the toy dataset and the real
> dataset, though as i mentioned i only get negative (illegal) parameter
> values with the real dataset.
> i don't know why i get this message, or what to do about it.
>
> any advice is very much appreciated!
>
> alexis
>



From Narcyz.Ghinea at swsahs.nsw.gov.au  Wed Oct 19 06:55:18 2005
From: Narcyz.Ghinea at swsahs.nsw.gov.au (Narcyz Ghinea)
Date: Wed, 19 Oct 2005 14:55:18 +1000
Subject: [R] Lists and Binary Operators.
Message-ID: <588D8BDAAC0BEB4B82DA2CC5AEBA899C3F7A1C@isdex001.intra.swsahs.nsw.gov.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051019/6e53dd54/attachment.pl

From ripley at stats.ox.ac.uk  Wed Oct 19 07:53:45 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Oct 2005 06:53:45 +0100 (BST)
Subject: [R] Lists and Binary Operators.
In-Reply-To: <588D8BDAAC0BEB4B82DA2CC5AEBA899C3F7A1C@isdex001.intra.swsahs.nsw.gov.au>
References: <588D8BDAAC0BEB4B82DA2CC5AEBA899C3F7A1C@isdex001.intra.swsahs.nsw.gov.au>
Message-ID: <Pine.LNX.4.61.0510190638400.26702@gannet.stats>

On Wed, 19 Oct 2005, Narcyz Ghinea wrote:

>
> Dear R Users,
>
> Any insights into why the following occurs would be helpful....
>
> Firstly:
>
> #Evaluating proportions
> p<-as.list(rep(0,times=length(n))) #creating object of appropriate size.
> for(j in 1:length(n)){
> for(k in 1:length(n[[j]])){
> p[[j]][[k]]<- (s[[j]][[k]]/n[[j]][k])}} # 31 x k x num_samples(dim)
> where k varies
>
> The list object s[[j]][[k]] has 3 levels, j, k, and i. j represents the
> review number, k the study number in that review, and i is the number of
> simulations in that study.  n[[j]][k] is also a list object with 2
> levels that represents the number of patients in study k of review j.
>
> When I run this the following error message occurs:
>
> Error: more elements supplied than there are to replace.
>
> However, if I make the simple adjustment p[[j]][[k]]<-
> list(s[[j]][[k]]/n[[j]][k]) it works fine! If anyone knows why please
> let me know. I couldn't get the answer from reading the "list" help.

Hmm.  Take a look at p: it is a list of numerical items of length 1, and 
you are trying to replace p[[j]][[k]], a single element in a numeric 
vector, by a numeric vector of length > 1.

I think you need to set p up properly, most likely as a copy of s.

> Secondly:
>
> #Evaluating weights.
> w<-as.list(rep(0,times=length(n))) #creating object of appropriate size.
> for(j in 1:length(n)){
> for(k in 1:length(n[[j]])){
> w[[j]][[k]]<- (1/(p[[j]][[k]]*n[[j]][k]*(1-p[[j]][[k]])))}} # 31 x k x
> num_samples(dim) where k varies
>
> When I run this section of the code, if gives the same error message as
> the previous one. When I try to solve it using the "list" function
> again, instead it gives a different error message:
>
> Error in p[[j]][[k]] * n[[j]][k] : non-numeric argument to binary
> operator
>
> The error message is straightforward but what I can't understand is why
> an error trying to calculate  p[[j]][[k]]*n[[j]][k] in the second case,
> but no such problem evaluating s[[j]][[k]]/n[[j]][k] in the first case,
> even though they are objects of the same type and sizes?

Have you verified that claim?  I think p[[j]][[k]] is a list, which is 
what you assigned there, and s[[j]][[k]] is a numeric vector.

Compare str(p) to str(s).

> How can I get rid of the second error? I have tried converting the
> p[[j]][[k]] vector into the numeric type but it won't allow it.

Had you quoted the error message your mistake would have been much more 
obvious.  I suspect it says

     (list) object cannot be coerced to 'double'

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From roy.werkman at asml.com  Wed Oct 19 08:31:06 2005
From: roy.werkman at asml.com (Roy Werkman)
Date: Wed, 19 Oct 2005 08:31:06 +0200
Subject: [R] Generating data with a certain correlation length
Message-ID: <E53188659C2369479DD42DE3728142B605E087@NLVDHX84.sn-eu.asml.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051019/b12df15b/attachment.pl

From jarioksa at sun3.oulu.fi  Wed Oct 19 09:08:41 2005
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Wed, 19 Oct 2005 10:08:41 +0300
Subject: [R] Forum of Mac questions (Was:  loading packages - mac user)
In-Reply-To: <Pine.LNX.4.63a.0510181310040.30016@homer24.u.washington.edu>
References: <e3930910510181146x2d6fd70avcc887d6259f08e54@mail.gmail.com>
	<Pine.LNX.4.63a.0510181310040.30016@homer24.u.washington.edu>
Message-ID: <1129705721.30365.11.camel@biol102145.oulu.fi>

On Tue, 2005-10-18 at 13:13 -0700, Thomas Lumley wrote:

> Both for this and for working out why Tcl/Tk isn't installed you might be 
> better off trying R-sig-mac rather than r-help
> 

This is a very common piece of advice. However, this is not what you
would imagine if you read the description of R-SIG-mac on the R home
page:

R-SIG-Mac R Special Interest Group on Mac Development

This is very similar to the description of R-devel:

This list is intended for questions and discussion about code
development in R.

And that description is even more intimidating when you read further:

Questions likely to prompt discussion unintelligible to non-programmers
or topics that are too technical for R-help's audience should go to
R-devel

Would it make sense to change the description of R-SIG-mac so that it
would welcome question on R usage in Mac, instead of being a "Mac
Devolepment" forum that sounds like being "unintelligible to
non-programmers"?

cheers, jari oksanen
-- 
Jari Oksanen <jarioksa at sun3.oulu.fi>



From ripley at stats.ox.ac.uk  Wed Oct 19 09:58:20 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Oct 2005 08:58:20 +0100 (BST)
Subject: [R] Forum of Mac questions (Was:  loading packages - mac user)
In-Reply-To: <1129705721.30365.11.camel@biol102145.oulu.fi>
References: <e3930910510181146x2d6fd70avcc887d6259f08e54@mail.gmail.com>
	<Pine.LNX.4.63a.0510181310040.30016@homer24.u.washington.edu>
	<1129705721.30365.11.camel@biol102145.oulu.fi>
Message-ID: <Pine.LNX.4.61.0510190849350.31876@gannet.stats>

On Wed, 19 Oct 2005, Jari Oksanen wrote:

> On Tue, 2005-10-18 at 13:13 -0700, Thomas Lumley wrote:
>
>> Both for this and for working out why Tcl/Tk isn't installed you might be
>> better off trying R-sig-mac rather than r-help
>>
>
> This is a very common piece of advice. However, this is not what you
> would imagine if you read the description of R-SIG-mac on the R home
> page:

It is not actually on the R home page or even on www.r-project.org.  I 
think you mean

https://stat.ethz.ch/mailman/listinfo/r-sig-mac

This arises because the purpose of the list has changed from

   R Special Interest Group on Macintosh Development and Porting, both for
   MacOS 8.6 - 9.x and MacOS X

I think a wording like R-sig-debian namely

   R Special Interest Group for MacOS X ports of R

would be better.

> R-SIG-Mac R Special Interest Group on Mac Development
>
> This is very similar to the description of R-devel:
>
> This list is intended for questions and discussion about code
> development in R.
>
> And that description is even more intimidating when you read further:
>
> Questions likely to prompt discussion unintelligible to non-programmers
> or topics that are too technical for R-help's audience should go to
> R-devel
>
> Would it make sense to change the description of R-SIG-mac so that it
> would welcome question on R usage in Mac, instead of being a "Mac
> Devolepment" forum that sounds like being "unintelligible to
> non-programmers"?

Which seems quite reasonable to me.  The topics which provoke this 
response usually are questions unintelligible except to Mac 
sysadmins/programmers and definitely `too technical for R-help's 
audience'.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Assa.Yeroslaviz at uni-duesseldorf.de  Wed Oct 19 10:15:41 2005
From: Assa.Yeroslaviz at uni-duesseldorf.de (Assa Yeroslaviz)
Date: Wed, 19 Oct 2005 10:15:41 +0200
Subject: [R] Unix proxy and firewall problems
Message-ID: <1129709740.435600ad015c0@mail.rz.uni-duesseldorf.de>

I was trying to install R on a unix server. Because of a firewall i can't
install biocLite for working with Bioconductor.

With windows it wasn't a problem. I used the option '--internet2' to bypass the
firewall.
I don't have any idea, how to do it with unix.
I tried to set my proxy
>Sys.putenv("http_proxy"="http...:8080")
>Sys.getenv("http_proxy")
                http_proxy
"http://...:8080"
http://by-cache.bayer-ag.com:8080/
but than by try to use the source command to download the bioC.R script I'm
getting the message:
>source("http:/bioconductor.org/getBioC.R")
Error in file(file, "r", encoding = encoding) :
        unable to open connection
In addition: Warning message:
cannot open file 'http:/bioconductor.org/getBioC.R'


Is there a possibility to change the proxy setting after the programm is already
running or do i need to do it before?

THX

Assa



--
Assa Yeroslaviz
Loetzenerstr. 15
51373 Leverkusen



From amsa36060 at yahoo.com  Wed Oct 19 10:49:48 2005
From: amsa36060 at yahoo.com (Amir Safari)
Date: Wed, 19 Oct 2005 01:49:48 -0700 (PDT)
Subject: [R] Wavelet recunstruction
Message-ID: <20051019084948.45427.qmail@web60422.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051019/9ce10c83/attachment.pl

From ripley at stats.ox.ac.uk  Wed Oct 19 10:52:11 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Oct 2005 09:52:11 +0100 (BST)
Subject: [R] Unix proxy and firewall problems
In-Reply-To: <1129709740.435600ad015c0@mail.rz.uni-duesseldorf.de>
References: <1129709740.435600ad015c0@mail.rz.uni-duesseldorf.de>
Message-ID: <Pine.LNX.4.61.0510190947001.32559@gannet.stats>

>From ?download.file

      These environment variables must be set before the download code
      is first used: they cannot be altered later by calling
      'Sys.putenv'.

Also, Sys.putenv("http_proxy"="http...:8080") sets that to the value
in "" and not the value of a variable named that: for the latter you must 
use `` quoting.  This is I suspect the actual failure cause.

On Wed, 19 Oct 2005, Assa Yeroslaviz wrote:

> I was trying to install R on a unix server. Because of a firewall i can't
> install biocLite for working with Bioconductor.

> With windows it wasn't a problem. I used the option '--internet2' to bypass the
> firewall.
> I don't have any idea, how to do it with unix.
> I tried to set my proxy
>> Sys.putenv("http_proxy"="http...:8080")
>> Sys.getenv("http_proxy")
>                http_proxy
> "http://...:8080"
> http://by-cache.bayer-ag.com:8080/
> but than by try to use the source command to download the bioC.R script I'm
> getting the message:
>> source("http:/bioconductor.org/getBioC.R")
> Error in file(file, "r", encoding = encoding) :
>        unable to open connection
> In addition: Warning message:
> cannot open file 'http:/bioconductor.org/getBioC.R'
>
>
> Is there a possibility to change the proxy setting after the programm is already
> running or do i need to do it before?
>
> THX
>
> Assa
>
>
>
> --
> Assa Yeroslaviz
> Loetzenerstr. 15
> 51373 Leverkusen
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From amsa36060 at yahoo.com  Wed Oct 19 10:57:02 2005
From: amsa36060 at yahoo.com (Amir Safari)
Date: Wed, 19 Oct 2005 01:57:02 -0700 (PDT)
Subject: [R] Wavelet reconstruction
Message-ID: <20051019085702.45629.qmail@web60412.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051019/dfa9ae38/attachment.pl

From krankenversicherung at help.ch  Wed Oct 19 10:54:34 2005
From: krankenversicherung at help.ch (krankenversicherung@help.ch)
Date: Wed, 19 Oct 2005 10:54:34 +0200
Subject: [R] www.krankenversicherung.ch News - Krankenkassen - Information
	Newsletter
Message-ID: <200510191105578.SM06600@195.141.204.149>

Guten Tag
 
Die Krankenkassen-Praemien 2006 sind bereit zum Vergleichen!

Gerne informieren wir Sie ueber die aktuellen Sparmoeglichkeiten fuer das Jahr 2006.


>>> VERGLEICHEN SIE JETZT
Unter http://vergleich.krankenversicherung.ch vergleichen Sie Ihre Praemien fuer das Jahr 2006.


>>> PRAEMIEN DES MARKTLEADERS
Die Helsana und Ihre Partner-Kassen finden Sie im Helsana-Vergleich unter 
http://helsanapraemien.krankenversicherung.ch .
Profitieren Sie jetzt von den attraktiven Praemien und erhalten Sie innert Sekunden
Ihre persoenliche Offerte via E-Mail zugestellt.


>>> VOTING - BEWERTEN SIE JETZT IHRE KRANKENKASSE
Bewerten Sie jetzt Ihre Krankenkasse unter http://voting.krankenversicherung.ch


>>> WETTBEWERB - GEWINNEN SIE EINE REISE
100 Sofortpreise und eine Flugreise sind zu gewinnen unter 
http://wettbewerb.krankenversicherung.ch . Viel Glueck!


>>> KUENDIGUNGSTERMIN
Nicht vergessen! Der Kuendigungstermin fuer die Grundversicherung ist der 30.11.2005.


>>> NAECHSTE INFORMATION
Gerne zeigen wir Ihnen im November den aktuellen Trend und informieren Sie mit den aktuellsten 
News.


>>> INFORMATION - Kein Spam
Sie erhalten diesen Newsletter aufgrund einer Bestellung oder Eintrages auf 
www.krankenversicherung.ch oder www.help.ch. Sie koennen diesen Newsletter jederzeit sofort 
abbestellen mit Nutzung des untenstehenden Links.
 
 
>>> ABMELDUNG
http://www.krankenversicherung.ch/unsubscribe.cfm



Mit freundlichen Gruessen und viel Erfolg beim Wettbewerb
www.krankenversicherung.ch und www.help.ch
 
Ihr Newsletter-Team

___________________________________________________________________

Die Schweizer Firmen-Suchmaschine
HELP Searchengines AG - Badenerstrasse 75 - 8004 Zuerich
www.help.ch  -  www.firmenscout.ch  -  www.produktesuche.ch
mailto:info at help.ch



From subianto at gmail.com  Wed Oct 19 11:58:11 2005
From: subianto at gmail.com (Muhammad Subianto)
Date: Wed, 19 Oct 2005 11:58:11 +0200
Subject: [R] error open .RData
Message-ID: <435618B3.4070800@gmail.com>

Dear R-list,
I have a problem to open my R workspace.
When I try to open my file .Rdata with double-clik on windows explore I 
get the error like this:

Error in load(name, envir = .GlobalEnv) : error reading from connection

and on windows error:

Fatal error: unable to restore saved data in .RData

I try with,

 > load("CaseStudyHouseID50.RData", .GlobalEnv)
Error in load("CaseStudyHouseID50.RData", .GlobalEnv) :
         error reading from connection
 >

 > load("CaseStudyHouseID50.RData")
Error in load("CaseStudyHouseID50.RData") :
         error reading from connection
 >

I have done to save my R workspace like this:
################################################################################
   save(list = ls(all=TRUE),
        file = "CaseStudyHouseID50.RData")
################################################################################

What is wrong?
Is there anyway to open .RData?

Regards, Muhammad Subianto

 > R.version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    2.0
year     2005
month    10
day      06
svn rev  35749
language R
 >



From m.ballardini at ior-forli.it  Wed Oct 19 12:09:07 2005
From: m.ballardini at ior-forli.it (Michela Ballardini)
Date: Wed, 19 Oct 2005 12:09:07 +0200
Subject: [R] forrest plot
Message-ID: <000a01c5d495$251ab4d0$0200a8c0@Michela>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051019/6568c90a/attachment.pl

From viudez_ant at gva.es  Wed Oct 19 12:05:29 2005
From: viudez_ant at gva.es (Toni =?iso-8859-1?q?Vi=FAdez?=)
Date: Wed, 19 Oct 2005 12:05:29 +0200
Subject: [R] Access to matrix values from labels
Message-ID: <200510191205.29718.viudez_ant@gva.es>

Hi everybody:
I've a output interpolation matrix files, and my question is if are there 
anybody that could tell me how access to particular values of this matrix 
from labels.
Thnaks in advance.
-- 
########################################
	   Antoni Vi??dez Mora	
    Dept. Din??mica de Contaminantes
	    Fundaci??n CEAM
        Paterna (Valencia)-Spain
        tel: 961318190. ext: 216
 e-mail: toni at ceam.es  viudez_ant at gva.es
########################################



From petr.pikal at precheza.cz  Wed Oct 19 12:21:59 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 19 Oct 2005 12:21:59 +0200
Subject: [R] error open .RData
In-Reply-To: <435618B3.4070800@gmail.com>
Message-ID: <43563A67.12375.6D6ADD@localhost>

Hi

Your .Rdata file is probably corrupted. Unless you have a working 
copy of it elsewhere or sources of your data together with history 
of your commands you are probably in deep trouble .Rdata is a 
binary format and it is not recommended to safe and reliable saving 
of your work as you have only limited, if any, possibilities to 
recover it if anything goes wrong.

I usually have all my important source data in txt or xls format and 
I frequently save history in separate files (on daily basis or 
sometimes several times a day) to be able to repeat everything I 
have done.

Cheers
Petr


On 19 Oct 2005 at 11:58, Muhammad Subianto wrote:

Date sent:      	Wed, 19 Oct 2005 11:58:11 +0200
From:           	Muhammad Subianto <subianto at gmail.com>
To:             	r-help at stat.math.ethz.ch
Subject:        	[R] error open .RData

> Dear R-list,
> I have a problem to open my R workspace.
> When I try to open my file .Rdata with double-clik on windows explore
> I get the error like this:
> 
> Error in load(name, envir = .GlobalEnv) : error reading from
> connection
> 
> and on windows error:
> 
> Fatal error: unable to restore saved data in .RData
> 
> I try with,
> 
>  > load("CaseStudyHouseID50.RData", .GlobalEnv)
> Error in load("CaseStudyHouseID50.RData", .GlobalEnv) :
>          error reading from connection
>  >
> 
>  > load("CaseStudyHouseID50.RData")
> Error in load("CaseStudyHouseID50.RData") :
>          error reading from connection
>  >
> 
> I have done to save my R workspace like this:
> ######################################################################
> ##########
>    save(list = ls(all=TRUE),
>         file = "CaseStudyHouseID50.RData")
> ######################################################################
> ##########
> 
> What is wrong?
> Is there anyway to open .RData?
> 
> Regards, Muhammad Subianto
> 
>  > R.version
>           _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    2.0
> year     2005
> month    10
> day      06
> svn rev  35749
> language R
>  >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From sumantab at ambaresearch.com  Wed Oct 19 12:13:18 2005
From: sumantab at ambaresearch.com (Sumanta Basak)
Date: Wed, 19 Oct 2005 15:43:18 +0530
Subject: [R] FIGARCH
Message-ID: <14850601FF012647A90A5DB31F96DB371D1940@INBLRDC01.BANG.irpvl.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051019/ae67d045/attachment.pl

From wilks at dial.pipex.com  Wed Oct 19 13:00:53 2005
From: wilks at dial.pipex.com (John Wilkinson (pipex))
Date: Wed, 19 Oct 2005 12:00:53 +0100
Subject: [R] Subsetting a list
Message-ID: <JCEIJNOHMNBPLMGFDHNDMECCCBAA.wilks@dial.pipex.com>

Dennis ----

Try 

>  TEST[-3]
[[1]]
[1] "A1" "A2"

[[2]]
[1] "B1" "B2"

for removing more than one element from the list (say 2 & 3) --

> TEST[-c(2,3)]
[[1]]
[1] "A1" "A2"

HTH

John

Dennis Fisher wrote---

Colleagues,

I have created a list in the following manner:
     TEST    <- list(c("A1", "A2"), c("B1", "B2"), c("C1", "C2"))

I now want to delete one element from the list, e.g., the third.  The  
command
     TEST[[3]]
yields (as expected):
     [1] "C1" "C2"

The command
     TEST[[-3]]
yields:
     Error: attempt to select more than one element

How can I accomplish delete one or more elements from this list?

I am running R2.2.0 on a Linux platform.

Dennis



From maechler at stat.math.ethz.ch  Wed Oct 19 13:36:03 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 19 Oct 2005 13:36:03 +0200
Subject: [R] Forum of Mac questions (Was:  loading packages - mac user)
In-Reply-To: <Pine.LNX.4.61.0510190849350.31876@gannet.stats>
References: <e3930910510181146x2d6fd70avcc887d6259f08e54@mail.gmail.com>
	<Pine.LNX.4.63a.0510181310040.30016@homer24.u.washington.edu>
	<1129705721.30365.11.camel@biol102145.oulu.fi>
	<Pine.LNX.4.61.0510190849350.31876@gannet.stats>
Message-ID: <17238.12195.762893.454964@stat.math.ethz.ch>

>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Wed, 19 Oct 2005 08:58:20 +0100 (BST) writes:

    BDR> On Wed, 19 Oct 2005, Jari Oksanen wrote:
    >> On Tue, 2005-10-18 at 13:13 -0700, Thomas Lumley wrote:
    >> 
    >>> Both for this and for working out why Tcl/Tk isn't
    >>> installed you might be better off trying R-sig-mac
    >>> rather than r-help
    >>> 
    >>  This is a very common piece of advice. However, this is
    >> not what you would imagine if you read the description of
    >> R-SIG-mac on the R home page:

    BDR> It is not actually on the R home page or even on
    BDR> www.r-project.org.  I think you mean

    BDR> https://stat.ethz.ch/mailman/listinfo/r-sig-mac

    BDR> This arises because the purpose of the list has changed
    BDR> from

    BDR>    R Special Interest Group on Macintosh Development
    BDR> and Porting, both for MacOS 8.6 - 9.x and MacOS X

    BDR> I think a wording like R-sig-debian namely

    BDR>    R Special Interest Group for MacOS X ports of R

    BDR> would be better.

yes, thank you both  ---- IFF this is really the intention.

Stefano Iacus is the maintainer (and initiator) of the list
and should say (and maybe ask on the R-SIG-Mac list) what he 
(and the subscribers) really wants.

    >> R-SIG-Mac R Special Interest Group on Mac Development
    >> 
    >> This is very similar to the description of R-devel:
    >> 
    >> This list is intended for questions and discussion about
    >> code development in R.
    >> 
    >> And that description is even more intimidating when you
    >> read further:
    >> 
    >> Questions likely to prompt discussion unintelligible to
    >> non-programmers or topics that are too technical for
    >> R-help's audience should go to R-devel
    >> 
    >> Would it make sense to change the description of
    >> R-SIG-mac so that it would welcome question on R usage in
    >> Mac, instead of being a "Mac Devolepment" forum that
    >> sounds like being "unintelligible to non-programmers"?

    BDR> Which seems quite reasonable to me.  The topics which
    BDR> provoke this response usually are questions
    BDR> unintelligible except to Mac sysadmins/programmers and
    BDR> definitely `too technical for R-help's audience'.

I agree.  We shouldn't let R users on the Mac think that all
their questions should go to R-SIG-Mac.
Regular R questions should continue to come to R-help (or
R-devel) just as per the posting guide.

Martin Maechler


    BDR> -- Brian D. Ripley, ripley at stats.ox.ac.uk Professor of
    BDR> Applied Statistics, http://www.stats.ox.ac.uk/~ripley/
    BDR> University of Oxford, Tel: +44 1865 272861 (self) 1
    BDR> South Parks Road, +44 1865 272866 (PA) Oxford OX1 3TG,
    BDR> UK Fax: +44 1865 272595



From tschoenhoff at gmail.com  Wed Oct 19 13:56:02 2005
From: tschoenhoff at gmail.com (=?ISO-8859-1?Q?Thomas_Sch=F6nhoff?=)
Date: Wed, 19 Oct 2005 13:56:02 +0200
Subject: [R] forrest plot
In-Reply-To: <000a01c5d495$251ab4d0$0200a8c0@Michela>
References: <000a01c5d495$251ab4d0$0200a8c0@Michela>
Message-ID: <5ad2dec0510190456r2b1eb12s@mail.gmail.com>

Hello,

2005/10/19, Michela Ballardini <m.ballardini at ior-forli.it>:
> Hi,
>
> can you tel me how can I make a Forrest Plot with R?
> It is possible and easy or are there a more practical free software available?

Maybe this will help you to find an answer:

http://finzi.psych.upenn.edu/R/library/rmeta/html/metaplot.html


regards
Thomas



From subianto at gmail.com  Wed Oct 19 14:13:56 2005
From: subianto at gmail.com (Muhammad Subianto)
Date: Wed, 19 Oct 2005 14:13:56 +0200
Subject: [R] error open .RData
In-Reply-To: <43563A67.12375.6D6ADD@localhost>
References: <435618B3.4070800@gmail.com> <43563A67.12375.6D6ADD@localhost>
Message-ID: <43563884.1020205@gmail.com>


 > Your .Rdata file is probably corrupted.

I will investigate. Thanks for you info.
Because of my file .RData very large about 75MB.
Best wishes, Muhammad Subianto

On this day 19/10/2005 12:21 PM, Petr Pikal wrote:
> Hi
> 
> Your .Rdata file is probably corrupted. Unless you have a working 
> copy of it elsewhere or sources of your data together with history 
> of your commands you are probably in deep trouble .Rdata is a 
> binary format and it is not recommended to safe and reliable saving 
> of your work as you have only limited, if any, possibilities to 
> recover it if anything goes wrong.
> 
> I usually have all my important source data in txt or xls format and 
> I frequently save history in separate files (on daily basis or 
> sometimes several times a day) to be able to repeat everything I 
> have done.
> 
> Cheers
> Petr
> 
> 
> On 19 Oct 2005 at 11:58, Muhammad Subianto wrote:
> 
> Date sent:      	Wed, 19 Oct 2005 11:58:11 +0200
> From:           	Muhammad Subianto <subianto at gmail.com>
> To:             	r-help at stat.math.ethz.ch
> Subject:        	[R] error open .RData
> 
> 
>>Dear R-list,
>>I have a problem to open my R workspace.
>>When I try to open my file .Rdata with double-clik on windows explore
>>I get the error like this:
>>
>>Error in load(name, envir = .GlobalEnv) : error reading from
>>connection
>>
>>and on windows error:
>>
>>Fatal error: unable to restore saved data in .RData
>>
>>I try with,
>>
>> > load("CaseStudyHouseID50.RData", .GlobalEnv)
>>Error in load("CaseStudyHouseID50.RData", .GlobalEnv) :
>>         error reading from connection
>> >
>>
>> > load("CaseStudyHouseID50.RData")
>>Error in load("CaseStudyHouseID50.RData") :
>>         error reading from connection
>> >
>>
>>I have done to save my R workspace like this:
>>######################################################################
>>##########
>>   save(list = ls(all=TRUE),
>>        file = "CaseStudyHouseID50.RData")
>>######################################################################
>>##########
>>
>>What is wrong?
>>Is there anyway to open .RData?
>>
>>Regards, Muhammad Subianto
>>
>> > R.version
>>          _
>>platform i386-pc-mingw32
>>arch     i386
>>os       mingw32
>>system   i386, mingw32
>>status
>>major    2
>>minor    2.0
>>year     2005
>>month    10
>>day      06
>>svn rev  35749
>>language R
>> >
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
>>http://www.R-project.org/posting-guide.html
> 
> 
> Petr Pikal
> petr.pikal at precheza.cz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From tastard at cict.fr  Wed Oct 19 14:19:51 2005
From: tastard at cict.fr (Emmanuelle TASTARD)
Date: Wed, 19 Oct 2005 14:19:51 +0200
Subject: [R] anova with models from glmmPQL
Message-ID: <000101c5d4a7$67adfd90$e2697882@st226edb>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051019/28a91e83/attachment.pl

From David.Ruau at rwth-aachen.de  Wed Oct 19 14:37:32 2005
From: David.Ruau at rwth-aachen.de (David Ruau)
Date: Wed, 19 Oct 2005 14:37:32 +0200
Subject: [R] Error in opening .RData containing a genefilter object
Message-ID: <72131c540e78c62ddfa7214d081a01bb@rwth-aachen.de>

Hi,
I discover that when I save a workspace containing a genefilter (pkg 
from Bioconductor) object I cannot open no more after. I have to 
restore the .RData file from a backup to be able to start R again.
I didn't upgrade to Version 2.2 but I'm not sure that it will solve the 
problem.
Did anyone have encounter the same problem?
Below is a short r session to reproduce the error:
...
[Previously saved workspace restored]

 > library(genefilter)
Loading required package: Biobase
Loading required package: tools
Welcome to Bioconductor
          Vignettes contain introductory material.  To view,
          simply type: openVignette()
          For details on reading vignettes, see
          the openVignette help page.
Loading required package: survival
Loading required package: splines
 > f1 <- kOverA(5, 60)
 > q()
Save workspace image? [y/n/c]: y
[computer:admin]$ r

R : Copyright 2005, The R Foundation for Statistical Computing
Version 2.1.1  (2005-06-20), ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

Error in .initContents() : couldn't find function "isGeneric"
Error: .onLoad failed in 'loadNamespace' for 'Biobase'
Fatal error: unable to restore saved data in .RData

[gaia:admin]$
-------
I am working under OS X 10.3.9.

David



From mathematician4 at hotmail.com  Wed Oct 19 14:38:24 2005
From: mathematician4 at hotmail.com (Emanuele Mazzola)
Date: Wed, 19 Oct 2005 12:38:24 +0000
Subject: [R] Help needed with ks.test
Message-ID: <BAY107-F329BF92FE644A0CB5545D69A700@phx.gbl>

Hello to everybody,

I'd like to submit a problem I'm dealing with, and I can't get an answer to 
by myself.
I have to test if my data come from a specific probability distribution, of 
which I know the analytic form both of the p.d.f. and the c.d.f.
Namely, it is the hypoexponential distribution, sum of two exponentials with 
different parameters.
Is there any way I can manage the task with ks.test?
It's not straightforward to compute the inverse of the c.d.f in order to 
simulate data from that distribution...

Thank you very much in advance for your kind answers!
See you
EM



From liuwensui at gmail.com  Wed Oct 19 14:47:25 2005
From: liuwensui at gmail.com (Wensui Liu)
Date: Wed, 19 Oct 2005 08:47:25 -0400
Subject: [R] how to test poisson distribution
Message-ID: <1115a2b00510190547m43fc1d0dle9c6bf1e9ea5bf4a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051019/9b6a31b6/attachment.pl

From f_bresson at yahoo.fr  Wed Oct 19 14:54:37 2005
From: f_bresson at yahoo.fr (Florent Bresson)
Date: Wed, 19 Oct 2005 14:54:37 +0200 (CEST)
Subject: [R] Problem with na in nls
Message-ID: <20051019125437.38788.qmail@web26807.mail.ukl.yahoo.com>

I'm trying to run a nls on a subset of a data.frame.
In the subset, one observation is NA. So I drop the
observation but when I ask for :

>sm  <-  nls(machin$revcum ~
Lc.singh(machin$popcum,p), start=list(p=c(2,3)))

I get :

Erreur dans parse(file, n, text, prompt) : syntax
error in "~ "

If I put some value for the non available observation
instead of droping it, it works. So what's the problem ?



From murdoch at stats.uwo.ca  Wed Oct 19 15:03:50 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 19 Oct 2005 09:03:50 -0400
Subject: [R] Error in opening .RData containing a genefilter object
In-Reply-To: <72131c540e78c62ddfa7214d081a01bb@rwth-aachen.de>
References: <72131c540e78c62ddfa7214d081a01bb@rwth-aachen.de>
Message-ID: <43564436.7060302@stats.uwo.ca>

On 10/19/2005 8:37 AM, David Ruau wrote:
> Hi,
> I discover that when I save a workspace containing a genefilter (pkg 
> from Bioconductor) object I cannot open no more after. I have to 
> restore the .RData file from a backup to be able to start R again.
> I didn't upgrade to Version 2.2 but I'm not sure that it will solve the 
> problem.
> Did anyone have encounter the same problem?
> Below is a short r session to reproduce the error:
> ...
> [Previously saved workspace restored]
> 
>  > library(genefilter)
> Loading required package: Biobase
> Loading required package: tools
> Welcome to Bioconductor
>           Vignettes contain introductory material.  To view,
>           simply type: openVignette()
>           For details on reading vignettes, see
>           the openVignette help page.
> Loading required package: survival
> Loading required package: splines
>  > f1 <- kOverA(5, 60)
>  > q()
> Save workspace image? [y/n/c]: y
> [computer:admin]$ r
> 
> R : Copyright 2005, The R Foundation for Statistical Computing
> Version 2.1.1  (2005-06-20), ISBN 3-900051-07-0
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for a HTML browser interface to help.
> Type 'q()' to quit R.
> 
> Error in .initContents() : couldn't find function "isGeneric"
> Error: .onLoad failed in 'loadNamespace' for 'Biobase'
> Fatal error: unable to restore saved data in .RData

Looks like it might be a bug in Biobase.  I'd first confirm that it 
happens in a current release of R, then post again to the Bioconductor list.

Duncan Murdoch



From francoisromain at free.fr  Wed Oct 19 15:11:22 2005
From: francoisromain at free.fr (Romain Francois)
Date: Wed, 19 Oct 2005 15:11:22 +0200
Subject: [R] forrest plot
In-Reply-To: <5ad2dec0510190456r2b1eb12s@mail.gmail.com>
References: <000a01c5d495$251ab4d0$0200a8c0@Michela>
	<5ad2dec0510190456r2b1eb12s@mail.gmail.com>
Message-ID: <435645FA.6060806@free.fr>

Le 19.10.2005 13:56, Thomas Schönhoff a écrit :

>Hello,
>
>2005/10/19, Michela Ballardini <m.ballardini at ior-forli.it>:
>  
>
>>Hi,
>>
>>can you tel me how can I make a Forrest Plot with R?
>>It is possible and easy or are there a more practical free software available?
>>    
>>
>
>Maybe this will help you to find an answer:
>
>http://finzi.psych.upenn.edu/R/library/rmeta/html/metaplot.html
>
>
>regards
>Thomas
>  
>
Hello Thomas,

Pretty interresting. You just pointed to a good candidate for r graph 
gallery.
A 3D plot of that kind can be done with the scatterplot3d package.

See Figure 5 page 14 of :
Ligges, U., and Maechler, M. (2003): Scatterplot3d – an R Package for 
Visualizing Multivariate Data. /Journal of Statistical Software/ 8(11), 
1–20. http://www.jstatsoft.org/

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~
~~~~~~      Romain FRANCOIS - http://addictedtor.free.fr         ~~~~~~
~~~~        Etudiant  ISUP - CS3 - Industrie et Services           ~~~~
~~                http://www.isup.cicrp.jussieu.fr/                  ~~
~~~~           Stagiaire INRIA Futurs - Equipe SELECT              ~~~~
~~~~~~   http://www.inria.fr/recherche/equipes/select.fr.html    ~~~~~~
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~



From rpeng at jhsph.edu  Wed Oct 19 15:14:31 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 19 Oct 2005 09:14:31 -0400
Subject: [R] Finding code for R functions
In-Reply-To: <9228D7EC9A32594191AA7530DB5314491FBADD@mail-3a.nrel.gov>
References: <9228D7EC9A32594191AA7530DB5314491FBADD@mail-3a.nrel.gov>
Message-ID: <435646B7.5040306@jhsph.edu>

If you're really interested in reading the source for functions and aren't 
interested in tracking down various methods (possibly hidden in namespaces) at 
the R prompt, I think it's much easier to download the R source code from CRAN 
and go through the original source files.

-roger

Wolfrum, Ed wrote:
> Greetings,
> 
> I am trying to figure out how to find the source code for R functions. I
> am specifically interested in finding the code for the "prcomp"
> function. I know that typing the function name without parenthesis will
> lead to the code (or to a .Internal or .FORTRAN or .C  call). However, I
> don't really understand what is going on. For example, typing "mean"
> gives a "UseMethod" response, while typing "mean.default" give the
> actual code:
> 
> 
>>mean
> 
> function (x, ...) 
> UseMethod("mean")
> <environment: namespace:base>
> 
>>mean.default
> 
> function (x, trim = 0, na.rm = FALSE, ...) 
> ---SNIP---
> }
> <environment: namespace:base>
> 
> Why is this? What does "mean.default" mean? I tried the same thing with
> "prcomp". With the stats package loaded, I cannot get to the source code
> for "prcomp".
> 
> 
>>require(stats)
> 
> [1] TRUE
> 
>>prcomp
> 
> function (x, ...) 
> UseMethod("prcomp")
> <environment: namespace:stats>
> 
>>prcomp.default
> 
> Error: object "prcomp.default" not found
>  
> How do I find the prcomp code? Are there general rules for finding the
> source code for functions that I should know?
> 
> Thanks in Advance,
> 
> Edward J. Wolfrum, Ph.D.
> National Renewable Energy Laboratory
> Golden, Colorado
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/



From mcardeal at ufba.br  Wed Oct 19 15:26:50 2005
From: mcardeal at ufba.br (Carlos Mauricio Cardeal Mendes)
Date: Wed, 19 Oct 2005 10:26:50 -0300
Subject: [R] npmc package
Message-ID: <4356499A.6040604@ufba.br>

Hi

Does anyone know where is the package: npmc (Nonparametric Multiple 
Comparisons).

I found the reference on R Site Search, but not the package itself on 
CRAN as suggested.

Thanks

Mauricio



From ligges at statistik.uni-dortmund.de  Wed Oct 19 15:48:52 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 19 Oct 2005 15:48:52 +0200
Subject: [R] npmc package
In-Reply-To: <4356499A.6040604@ufba.br>
References: <4356499A.6040604@ufba.br>
Message-ID: <43564EC4.7090407@statistik.uni-dortmund.de>

Carlos Mauricio Cardeal Mendes wrote:

> Hi
> 
> Does anyone know where is the package: npmc (Nonparametric Multiple 
> Comparisons).
> 
> I found the reference on R Site Search, but not the package itself on 
> CRAN as suggested.

The packages is "ORPHANED" and removed from the CRAN main repository. 
You can get older versions from the archives, though:

your-CRAN-mirror/src/contrib/Archive/N/npmc_1.0-1.tar.gz

Uwe Ligges

> Thanks
> 
> Mauricio
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From francoisromain at free.fr  Wed Oct 19 15:58:51 2005
From: francoisromain at free.fr (Romain Francois)
Date: Wed, 19 Oct 2005 15:58:51 +0200
Subject: [R] forrest plot
In-Reply-To: <435645FA.6060806@free.fr>
References: <000a01c5d495$251ab4d0$0200a8c0@Michela>	<5ad2dec0510190456r2b1eb12s@mail.gmail.com>
	<435645FA.6060806@free.fr>
Message-ID: <4356511B.2000909@free.fr>

Le 19.10.2005 15:11, Romain Francois a écrit :

>Le 19.10.2005 13:56, Thomas Schönhoff a écrit :
>
>>Hello,
>>
>>2005/10/19, Michela Ballardini <m.ballardini at ior-forli.it>:
>>
>>>i,
>>>
>>>can you tel me how can I make a Forrest Plot with R?
>>>It is possible and easy or are there a more practical free software available?
>>>      
>>>
>>Maybe this will help you to find an answer:
>>
>>http://finzi.psych.upenn.edu/R/library/rmeta/html/metaplot.html
>>
>>
>>regards
>>Thomas
>> 
>>
>>    
>>
>Hello Thomas,
>
>Pretty interresting. You just pointed to a good candidate for r graph 
>gallery.
>(..)
>  
>
Included. I just added :
R> par(lend="square")
so it is nicer. Maybe a change to make in the function code ?

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~
~~~~~~      Romain FRANCOIS - http://addictedtor.free.fr         ~~~~~~
~~~~        Etudiant  ISUP - CS3 - Industrie et Services           ~~~~
~~                http://www.isup.cicrp.jussieu.fr/                  ~~
~~~~           Stagiaire INRIA Futurs - Equipe SELECT              ~~~~
~~~~~~   http://www.inria.fr/recherche/equipes/select.fr.html    ~~~~~~
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~



From Lorenz.Gygax at fat.admin.ch  Wed Oct 19 16:07:03 2005
From: Lorenz.Gygax at fat.admin.ch (Lorenz.Gygax@fat.admin.ch)
Date: Wed, 19 Oct 2005 16:07:03 +0200
Subject: [R] anova with models from glmmPQL
Message-ID: <BF74FADD4B44554CA7E53D0B5242CD6A034FF0C6@evd-s7014.bk.evdad.admin.ch>

> I try to compare some models obtained from glmmPQL.
>  
> model1 <-
> glmmPQL(y~red*yellow+I(red^2)+I(yellow^2)+densite8+I(densite8^
> 2)+freq8_4
> +I(freq8_4^2), random=~1|num, binomial);
> model2 <-
> glmmPQL(y~red*yellow+I(red^2)+I(yellow^2)+densite8+I(densite8^
> 2)+freq8_4
> , random=~1|num, binomial);
> anova(model1, model2)

You try to compare models that differ in their fixed parts. This is not
possible with the default method 'REML'. This would only be possible if you
fitted your models using method 'ML' (see Pinheiro & Bates, 2000).

In addition, if I understood a remark by Jos?? Pinheiro during one of his
courses correctly, the anova comparisons are not save with a distribution
other than normal. Thus, one should rely on the function intervals () to see
whether confidence intervals of the parameters overlap zero or not. Perhaps
someone else can comment on this issue?

Regards, Lorenz
- 
Lorenz Gygax
Centre for proper housing of ruminants and pigs
Swiss Federal Veterinary Office
agroscope FAT T??nikon, CH-8356 Ettenhausen / Switzerland



From maechler at stat.math.ethz.ch  Wed Oct 19 16:09:56 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 19 Oct 2005 16:09:56 +0200
Subject: [R] ... Job Openings .. on R-help
In-Reply-To: <200510121747.j9CHlees009846@compton.gene.com>
References: <200510121747.j9CHlees009846@compton.gene.com>
Message-ID: <17238.21428.799579.524508@stat.math.ethz.ch>

>>>>> "BertG" == Berton Gunter <gunter.berton at gene.com>
>>>>>     on Wed, 12 Oct 2005 10:47:40 -0700 writes:

    BertG> I hope that this job posting does not offend
    BertG> anyone. My sincere apologies if it is inappropriate
    BertG> -- blame me, not my company.

since you ask for it .. ;-)

    BertG> -- Bert Gunter
    BertG> Genentech Nonclinical Statistics
    BertG> South San Francisco, CA
 

    >> Genentech has an opening 
    >> <...................>
    >> <...................>
    >> <...................>

a job advertisement with a word count of  (50 352 2486) [lines,words,chars]
which is a bit too long, but ok,
but with a final paragraph which can be read as a blatant
advertisement for your company.  That (last paragraph) was not
appropriate in my opinion.

People have contacted me (as mailing list maintainer) and asked
about the appropriateness of such postings, and I've usually
explained that it is ok, as long as it remains short, is
explicitly related to R, to the
point, and refers to a URL for further information.

Hence Bert's add was close to the target.

The other anonymous add which only gave an "anonymous" e-mail
address for contact (see above; of course we really should
e-bomb it :-) was *VERY* inappropriate though.

Martin Maechler, ETH Zurich
as R mailing lists maintainer.



From David.Ruau at rwth-aachen.de  Wed Oct 19 16:39:12 2005
From: David.Ruau at rwth-aachen.de (David Ruau)
Date: Wed, 19 Oct 2005 16:39:12 +0200
Subject: [R] Error in opening .RData containing a genefilter object
In-Reply-To: <Pine.LNX.4.61.0510191453250.4451@gannet.stats>
References: <72131c540e78c62ddfa7214d081a01bb@rwth-aachen.de>
	<43564436.7060302@stats.uwo.ca>
	<Pine.LNX.4.61.0510191453250.4451@gannet.stats>
Message-ID: <2267c70f4c972381ffae4e559392e573@rwth-aachen.de>

Thanks a lot Professor Ripley, it works that way.
I will upgrade to v 2.2 one day when I have time and see if it still 
happen.

David

On Oct 19, 2005, at 15:58, Prof Brian Ripley wrote:

> On Wed, 19 Oct 2005, Duncan Murdoch wrote:
>
>> On 10/19/2005 8:37 AM, David Ruau wrote:
>>> Hi,
>>> I discover that when I save a workspace containing a genefilter (pkg
>>> from Bioconductor) object I cannot open no more after. I have to
>>> restore the .RData file from a backup to be able to start R again.
>>> I didn't upgrade to Version 2.2 but I'm not sure that it will solve 
>>> the
>>> problem.
>>> Did anyone have encounter the same problem?
>>> Below is a short r session to reproduce the error:
>>> ...
>>> [Previously saved workspace restored]
>>>
>>> > library(genefilter)
>>> Loading required package: Biobase
>>> Loading required package: tools
>>> Welcome to Bioconductor
>>>           Vignettes contain introductory material.  To view,
>>>           simply type: openVignette()
>>>           For details on reading vignettes, see
>>>           the openVignette help page.
>>> Loading required package: survival
>>> Loading required package: splines
>>> > f1 <- kOverA(5, 60)
>>> > q()
>>> Save workspace image? [y/n/c]: y
>>> [computer:admin]$ r
>>>
>>> R : Copyright 2005, The R Foundation for Statistical Computing
>>> Version 2.1.1  (2005-06-20), ISBN 3-900051-07-0
>>>
>>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>>> You are welcome to redistribute it under certain conditions.
>>> Type 'license()' or 'licence()' for distribution details.
>>>
>>> R is a collaborative project with many contributors.
>>> Type 'contributors()' for more information and
>>> 'citation()' on how to cite R or R packages in publications.
>>>
>>> Type 'demo()' for some demos, 'help()' for on-line help, or
>>> 'help.start()' for a HTML browser interface to help.
>>> Type 'q()' to quit R.
>>>
>>> Error in .initContents() : couldn't find function "isGeneric"
>>> Error: .onLoad failed in 'loadNamespace' for 'Biobase'
>>> Fatal error: unable to restore saved data in .RData
>>
>> Looks like it might be a bug in Biobase.  I'd first confirm that it
>> happens in a current release of R, then post again to the 
>> Bioconductor list.
>
> Something in that workspace requires the Biobase namespace, and that 
> needs to import the methods namespace.  It does not in the version I 
> have.
>
> A solution is to use R --vanilla and then load(".RData").
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From christophleuchtner at web.de  Wed Oct 19 16:42:37 2005
From: christophleuchtner at web.de (Christoph Leuchtner)
Date: Wed, 19 Oct 2005 16:42:37 +0200
Subject: [R] schoenfeld residuals in the cox.zph function
Message-ID: <1630337503@web.de>


To R-project help

I work with a clinical dataset including about 27,000 patients and I wanted to do some model diagnostics on cox regression models with frailty effects (for every patient). But in this case the cox.zph function did not work. I always got the following error message:

Fehler in residuals.coxph(fit, "schoenfeld") :
        NA/NaN/Inf in externem Funktionsaufruf (arg 5)

Does anyone know what's wrong? I did the same without using frailty effects and everything was o.k. What could I do?



From tlumley at u.washington.edu  Wed Oct 19 16:43:55 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 19 Oct 2005 07:43:55 -0700 (PDT)
Subject: [R] forrest plot
In-Reply-To: <435645FA.6060806@free.fr>
References: <000a01c5d495$251ab4d0$0200a8c0@Michela>
	<5ad2dec0510190456r2b1eb12s@mail.gmail.com>
	<435645FA.6060806@free.fr>
Message-ID: <Pine.LNX.4.63a.0510190732530.6870@homer22.u.washington.edu>

On Wed, 19 Oct 2005, Romain Francois wrote:
> Pretty interresting. You just pointed to a good candidate for r graph
> gallery.

There is an example on the R home page, and has been for some time. I have 
an improved version based on grid code by Paul Murrell, but it's not on a 
nearby computer.  The other meta-analysis package also has a forest-plot 
function.

Incidentally, I was just motivated to track down whether it is "Forrest" 
or "forest" [ie for\^et], as I had assumed. Both spellings appear on 
meta-analyses, even in the top medical journals (which, unlike most 
academic journals, have moderately aggresive copy-editors).  A feedback 
archive for the  Cochrane Collaboration style guide says

"The plot was not called a forest plot in print for some time, and the
  origins of this title are obscured by history and myth. At the September
  1990 meeting of the breast cancer overview, Richard Peto jokingly
  mentioned the the plot was named after the breast cancer researcher Pat
  Forrest, and, at times, the names has been spelt forrest plot.
  However, the phrase actually originates from the idea that the typical
  plot appears as a forest of lines.
  Lewis S, Clarke M. Forest plots: trying to see the wood and the trees.
  BMJ 2001;322:1479-80."


 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From r.hankin at noc.soton.ac.uk  Wed Oct 19 16:55:20 2005
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Wed, 19 Oct 2005 15:55:20 +0100
Subject: [R] diag() problem
Message-ID: <1A0E77A8-077D-4D20-BAA2-CB388A899363@soc.soton.ac.uk>

Hi

I have a matrix "u", for which diag() gives an error:

u <- structure(c(5.42334674128216, -2.31319389204264, -5.83059042218476,
  -1.64112369640695, -2.31319389212801, 3.22737617646609,  
1.85200668021569,
  -0.57102273078531, -5.83059042231881, 1.85200668008156,  
11.9488923894962,
  -3.5525537165941, -1.64112369587405, -0.571022730886046,  
-3.55255371755604,
  10.0989829379577), .Dim = c(4, 4), .Dimnames = list(c("constant",
  NA, NA, NA), c("constant", NA, NA, NA)))

 > u
           constant       <NA>      <NA>       <NA>
constant  5.423347 -2.3131939 -5.830590 -1.6411237
<NA>     -2.313194  3.2273762  1.852007 -0.5710227
<NA>     -5.830590  1.8520067 11.948892 -3.5525537
<NA>     -1.641124 -0.5710227 -3.552554 10.0989829
 > is.matrix(u)
[1] TRUE
 > diag(u)
Error in if (is.list(nms) && !any(sapply(nms, is.null)) && all((nm <-  
nms[[1]][1:m]) ==  :
     missing value where TRUE/FALSE needed

 >


What's going on here?




 > R.version
          _
platform powerpc-apple-darwin8.2.0
arch     powerpc
os       darwin8.2.0
system   powerpc, darwin8.2.0
status
major    2
minor    2.0
year     2005
month    10
day      06
svn rev  35749
language R
 >




--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From fcombes at gmail.com  Wed Oct 19 16:56:38 2005
From: fcombes at gmail.com (Florence Combes)
Date: Wed, 19 Oct 2005 16:56:38 +0200
Subject: [R] Problem with na in nls
In-Reply-To: <20051019125437.38788.qmail@web26807.mail.ukl.yahoo.com>
References: <20051019125437.38788.qmail@web26807.mail.ukl.yahoo.com>
Message-ID: <73dae3060510190756m1117d1f3lfeb0684ecd53f0f2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051019/ca5e1cb5/attachment.pl

From maechler at stat.math.ethz.ch  Wed Oct 19 17:09:01 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 19 Oct 2005 17:09:01 +0200
Subject: [R] Subsetting a list
In-Reply-To: <43550723.7000004@ipimar.pt>
References: <mailman.13.1129629601.29332.r-help@stat.math.ethz.ch>
	<8834D050-C381-4300-8A0C-54D806EFC941@plessthan.com>
	<43550723.7000004@ipimar.pt>
Message-ID: <17238.24973.55147.771104@stat.math.ethz.ch>

>>>>> "Jose" == Jos?? Ernesto Jardim <ernesto at ipimar.pt>
>>>>>     on Tue, 18 Oct 2005 15:30:59 +0100 writes:

    Jose> Dennis Fisher wrote:
    >> Colleagues,
    >> 
    >> I have created a list in the following manner:
    >> TEST    <- list(c("A1", "A2"), c("B1", "B2"), c("C1", "C2"))
    >> 
    >> I now want to delete one element from the list, e.g., the third.  The  
    >> command
    >> TEST[[3]]
    >> yields (as expected):
    >> [1] "C1" "C2"
    >> 
    >> The command
    >> TEST[[-3]]
    >> yields:
    >> Error: attempt to select more than one element
    >> 
    >> How can I accomplish delete one or more elements from this list?
    >> 
    >> I am running R2.2.0 on a Linux platform.
    >> 
    >> Dennis
    >> 

    Jose> TEST[[3]] <- NULL

    Jose> Lists are not subsetable like data.frames or arrays, see the manuals.

yes, they are, almost, see other replies and "the manuals" :

Lists can have 'dim' attributes and hence be treated as arrays;
Note that this is pretty rarely used and not too well supported
by some tools, one could say even 'print()' :

> set.seed(0); L0 <- L <- lapply(rpois(12, lambda=3), seq); dim(L) <- 3:4; L
     [,1]      [,2]      [,3]      [,4]     
[1,] Integer,5 Integer,3 Integer,5 Integer,3
[2,] Integer,2 Integer,5 Integer,6 1        
[3,] Integer,2 Integer,2 Integer,4 Integer,2
> str(L)
List of 12
 $ : int [1:5] 1 2 3 4 5
 $ : int [1:2] 1 2
 $ : int [1:2] 1 2
 $ : int [1:3] 1 2 3
 $ : int [1:5] 1 2 3 4 5
 $ : int [1:2] 1 2
 $ : int [1:5] 1 2 3 4 5
 $ : int [1:6] 1 2 3 4 5 6
 $ : int [1:4] 1 2 3 4
 $ : int [1:3] 1 2 3
 $ : int 1
 $ : int [1:2] 1 2
 - attr(*, "dim")= int [1:2] 3 4
> L[2,3]
[[1]]
[1] 1 2 3 4 5 6

> L[-(1:10)] ## treated matrix ``as vector''
[[1]]
[1] 1

[[2]]
[1] 1 2



From rvaradha at jhsph.edu  Wed Oct 19 17:13:37 2005
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Wed, 19 Oct 2005 11:13:37 -0400
Subject: [R] diag() problem
In-Reply-To: <1A0E77A8-077D-4D20-BAA2-CB388A899363@soc.soton.ac.uk>
Message-ID: <OWA-2pTSA0ni0fQ0D9o00018a62@owa-2.sph.ad.jhsph.edu>

It has to do with the "NA"s in dimnames, but I don't know why this is a
problem.  If you either got rid of dimnames or assigned actual names, this
works fine.

Ravi.

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-
> bounces at stat.math.ethz.ch] On Behalf Of Robin Hankin
> Sent: Wednesday, October 19, 2005 10:55 AM
> To: RHelp
> Subject: [R] diag() problem
> 
> Hi
> 
> I have a matrix "u", for which diag() gives an error:
> 
> u <- structure(c(5.42334674128216, -2.31319389204264, -5.83059042218476,
>   -1.64112369640695, -2.31319389212801, 3.22737617646609,
> 1.85200668021569,
>   -0.57102273078531, -5.83059042231881, 1.85200668008156,
> 11.9488923894962,
>   -3.5525537165941, -1.64112369587405, -0.571022730886046,
> -3.55255371755604,
>   10.0989829379577), .Dim = c(4, 4), .Dimnames = list(c("constant",
>   NA, NA, NA), c("constant", NA, NA, NA)))
> 
>  > u
>            constant       <NA>      <NA>       <NA>
> constant  5.423347 -2.3131939 -5.830590 -1.6411237
> <NA>     -2.313194  3.2273762  1.852007 -0.5710227
> <NA>     -5.830590  1.8520067 11.948892 -3.5525537
> <NA>     -1.641124 -0.5710227 -3.552554 10.0989829
>  > is.matrix(u)
> [1] TRUE
>  > diag(u)
> Error in if (is.list(nms) && !any(sapply(nms, is.null)) && all((nm <-
> nms[[1]][1:m]) ==  :
>      missing value where TRUE/FALSE needed
> 
>  >
> 
> 
> What's going on here?
> 
> 
> 
> 
>  > R.version
>           _
> platform powerpc-apple-darwin8.2.0
> arch     powerpc
> os       darwin8.2.0
> system   powerpc, darwin8.2.0
> status
> major    2
> minor    2.0
> year     2005
> month    10
> day      06
> svn rev  35749
> language R
>  >
> 
> 
> 
> 
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton
> European Way, Southampton SO14 3ZH, UK
>   tel  023-8059-7743
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-
> guide.html



From murdoch at stats.uwo.ca  Wed Oct 19 17:15:21 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 19 Oct 2005 11:15:21 -0400
Subject: [R] diag() problem
In-Reply-To: <1A0E77A8-077D-4D20-BAA2-CB388A899363@soc.soton.ac.uk>
References: <1A0E77A8-077D-4D20-BAA2-CB388A899363@soc.soton.ac.uk>
Message-ID: <43566309.7090808@stats.uwo.ca>

On 10/19/2005 10:55 AM, Robin Hankin wrote:
> Hi
> 
> I have a matrix "u", for which diag() gives an error:
> 
> u <- structure(c(5.42334674128216, -2.31319389204264, -5.83059042218476,
>   -1.64112369640695, -2.31319389212801, 3.22737617646609,  
> 1.85200668021569,
>   -0.57102273078531, -5.83059042231881, 1.85200668008156,  
> 11.9488923894962,
>   -3.5525537165941, -1.64112369587405, -0.571022730886046,  
> -3.55255371755604,
>   10.0989829379577), .Dim = c(4, 4), .Dimnames = list(c("constant",
>   NA, NA, NA), c("constant", NA, NA, NA)))
> 
>  > u
>            constant       <NA>      <NA>       <NA>
> constant  5.423347 -2.3131939 -5.830590 -1.6411237
> <NA>     -2.313194  3.2273762  1.852007 -0.5710227
> <NA>     -5.830590  1.8520067 11.948892 -3.5525537
> <NA>     -1.641124 -0.5710227 -3.552554 10.0989829
>  > is.matrix(u)
> [1] TRUE
>  > diag(u)
> Error in if (is.list(nms) && !any(sapply(nms, is.null)) && all((nm <-  
> nms[[1]][1:m]) ==  :
>      missing value where TRUE/FALSE needed
> 
>  >
> 
> 
> What's going on here?

It's trying to check whether the row names match the column names, in 
which case it will assign those names to the diagonal elements.  But the 
writer didn't figure someone would have NA names, so the test

all((nm <- nms[[1]][1:m]) == nms[[2]][1:m])

fails.

It could be "fixed" by putting "na.rm=TRUE" into the all(), but that's 
probably not right:

 > all(c(1, NA) == c(1, 2), na.rm = TRUE)
[1] TRUE

I think we want to wrap the values in "paste", to convert to non-missing 
characters.  That would be

all(paste((nm <- nms[[1]][1:m])) == paste(nms[[2]][1:m]))

and would give

 > diag(u)
  constant      <NA>      <NA>      <NA>
  5.423347  3.227376 11.948892 10.098983

Any objections to me committing this change?

Duncan Murdoch



From murdoch at stats.uwo.ca  Wed Oct 19 17:22:05 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 19 Oct 2005 11:22:05 -0400
Subject: [R] diag() problem
In-Reply-To: <1A0E77A8-077D-4D20-BAA2-CB388A899363@soc.soton.ac.uk>
References: <1A0E77A8-077D-4D20-BAA2-CB388A899363@soc.soton.ac.uk>
Message-ID: <4356649D.4030005@stats.uwo.ca>

> On 10/19/2005 10:55 AM, Robin Hankin wrote:
> 
>>> Hi
>>> 
>>> I have a matrix "u", for which diag() gives an error:
>>> 
>>> u <- structure(c(5.42334674128216, -2.31319389204264, -5.83059042218476,
>>>   -1.64112369640695, -2.31319389212801, 3.22737617646609,  
>>> 1.85200668021569,
>>>   -0.57102273078531, -5.83059042231881, 1.85200668008156,  
>>> 11.9488923894962,
>>>   -3.5525537165941, -1.64112369587405, -0.571022730886046,  
>>> -3.55255371755604,
>>>   10.0989829379577), .Dim = c(4, 4), .Dimnames = list(c("constant",
>>>   NA, NA, NA), c("constant", NA, NA, NA)))
>>> 
>>>  > u
>>>            constant       <NA>      <NA>       <NA>
>>> constant  5.423347 -2.3131939 -5.830590 -1.6411237
>>> <NA>     -2.313194  3.2273762  1.852007 -0.5710227
>>> <NA>     -5.830590  1.8520067 11.948892 -3.5525537
>>> <NA>     -1.641124 -0.5710227 -3.552554 10.0989829
>>>  > is.matrix(u)
>>> [1] TRUE
>>>  > diag(u)
>>> Error in if (is.list(nms) && !any(sapply(nms, is.null)) && all((nm <-  
>>> nms[[1]][1:m]) ==  :
>>>      missing value where TRUE/FALSE needed
>>> 
>>>  >
>>> 
>>> 
>>> What's going on here?
> 
> 
> It's trying to check whether the row names match the column names, in 
> which case it will assign those names to the diagonal elements.  But the 
> writer didn't figure someone would have NA names, so the test
> 
> all((nm <- nms[[1]][1:m]) == nms[[2]][1:m])
> 
> fails.
> 
> It could be "fixed" by putting "na.rm=TRUE" into the all(), but that's 
> probably not right:
> 
>  > all(c(1, NA) == c(1, 2), na.rm = TRUE)
> [1] TRUE
> 
> I think we want to wrap the values in "paste", to convert to non-missing 
> characters.  That would be
> 
> all(paste((nm <- nms[[1]][1:m])) == paste(nms[[2]][1:m]))
> 
> and would give
> 
>  > diag(u)
>   constant      <NA>      <NA>      <NA>
>   5.423347  3.227376 11.948892 10.098983
> 
> Any objections to me committing this change?

I object:  it can't tell the difference between the name "NA" and a 
missing name.  A better fix is to wrap the all() in isTRUE().  This 
leaves the names off the result (since we don't know if the rownames and 
colnames match).

Duncan Murdoch



From lizzylaws at yahoo.com  Wed Oct 19 17:27:06 2005
From: lizzylaws at yahoo.com (Elizabeth Lawson)
Date: Wed, 19 Oct 2005 08:27:06 -0700 (PDT)
Subject: [R] nlme  Singularity in backsolve at level 0, block 1
Message-ID: <20051019152706.20153.qmail@web32111.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051019/447d0bd0/attachment.pl

From ripley at stats.ox.ac.uk  Wed Oct 19 17:37:57 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Oct 2005 16:37:57 +0100 (BST)
Subject: [R] diag() problem
In-Reply-To: <43566309.7090808@stats.uwo.ca>
References: <1A0E77A8-077D-4D20-BAA2-CB388A899363@soc.soton.ac.uk>
	<43566309.7090808@stats.uwo.ca>
Message-ID: <Pine.LNX.4.61.0510191633030.18811@gannet.stats>

On Wed, 19 Oct 2005, Duncan Murdoch wrote:

> On 10/19/2005 10:55 AM, Robin Hankin wrote:
>> Hi
>>
>> I have a matrix "u", for which diag() gives an error:
>>
>> u <- structure(c(5.42334674128216, -2.31319389204264, -5.83059042218476,
>>   -1.64112369640695, -2.31319389212801, 3.22737617646609,
>> 1.85200668021569,
>>   -0.57102273078531, -5.83059042231881, 1.85200668008156,
>> 11.9488923894962,
>>   -3.5525537165941, -1.64112369587405, -0.571022730886046,
>> -3.55255371755604,
>>   10.0989829379577), .Dim = c(4, 4), .Dimnames = list(c("constant",
>>   NA, NA, NA), c("constant", NA, NA, NA)))
>>
>> > u
>>            constant       <NA>      <NA>       <NA>
>> constant  5.423347 -2.3131939 -5.830590 -1.6411237
>> <NA>     -2.313194  3.2273762  1.852007 -0.5710227
>> <NA>     -5.830590  1.8520067 11.948892 -3.5525537
>> <NA>     -1.641124 -0.5710227 -3.552554 10.0989829
>> > is.matrix(u)
>> [1] TRUE
>> > diag(u)
>> Error in if (is.list(nms) && !any(sapply(nms, is.null)) && all((nm <-
>> nms[[1]][1:m]) ==  :
>>      missing value where TRUE/FALSE needed
>>
>> >
>>
>>
>> What's going on here?
>
> It's trying to check whether the row names match the column names, in
> which case it will assign those names to the diagonal elements.  But the
> writer didn't figure someone would have NA names, so the test
>
> all((nm <- nms[[1]][1:m]) == nms[[2]][1:m])
>
> fails.
>
> It could be "fixed" by putting "na.rm=TRUE" into the all(), but that's
> probably not right:
>
> > all(c(1, NA) == c(1, 2), na.rm = TRUE)
> [1] TRUE
>
> I think we want to wrap the values in "paste", to convert to non-missing
> characters.  That would be
>
> all(paste((nm <- nms[[1]][1:m])) == paste(nms[[2]][1:m]))
>
> and would give
>
> > diag(u)
>  constant      <NA>      <NA>      <NA>
>  5.423347  3.227376 11.948892 10.098983
>
> Any objections to me committing this change?

Yes, you don't want <NA> to match "NA".

If you think NA names should match, use identical.   Otherwise (and I 
think this would be more consistent with other parts of R), do something
like

eq <- (nm <- nms[[1]][1:m]) == nms[[2]][1:m]
if(all(!is.na(eq) && eq)) ...

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From murdoch at stats.uwo.ca  Wed Oct 19 18:20:47 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 19 Oct 2005 12:20:47 -0400
Subject: [R] diag() problem
In-Reply-To: <Pine.LNX.4.61.0510191633030.18811@gannet.stats>
References: <1A0E77A8-077D-4D20-BAA2-CB388A899363@soc.soton.ac.uk>	<43566309.7090808@stats.uwo.ca>
	<Pine.LNX.4.61.0510191633030.18811@gannet.stats>
Message-ID: <4356725F.6020704@stats.uwo.ca>

On 10/19/2005 11:37 AM, Prof Brian Ripley wrote:
> On Wed, 19 Oct 2005, Duncan Murdoch wrote:
> 
>> On 10/19/2005 10:55 AM, Robin Hankin wrote:
>>> Hi
>>>
>>> I have a matrix "u", for which diag() gives an error:
>>>
>>> u <- structure(c(5.42334674128216, -2.31319389204264, -5.83059042218476,
>>>   -1.64112369640695, -2.31319389212801, 3.22737617646609,
>>> 1.85200668021569,
>>>   -0.57102273078531, -5.83059042231881, 1.85200668008156,
>>> 11.9488923894962,
>>>   -3.5525537165941, -1.64112369587405, -0.571022730886046,
>>> -3.55255371755604,
>>>   10.0989829379577), .Dim = c(4, 4), .Dimnames = list(c("constant",
>>>   NA, NA, NA), c("constant", NA, NA, NA)))
>>>
>>> > u
>>>            constant       <NA>      <NA>       <NA>
>>> constant  5.423347 -2.3131939 -5.830590 -1.6411237
>>> <NA>     -2.313194  3.2273762  1.852007 -0.5710227
>>> <NA>     -5.830590  1.8520067 11.948892 -3.5525537
>>> <NA>     -1.641124 -0.5710227 -3.552554 10.0989829
>>> > is.matrix(u)
>>> [1] TRUE
>>> > diag(u)
>>> Error in if (is.list(nms) && !any(sapply(nms, is.null)) && all((nm <-
>>> nms[[1]][1:m]) ==  :
>>>      missing value where TRUE/FALSE needed
>>>
>>> >
>>>
>>>
>>> What's going on here?
>>
>> It's trying to check whether the row names match the column names, in
>> which case it will assign those names to the diagonal elements.  But the
>> writer didn't figure someone would have NA names, so the test
>>
>> all((nm <- nms[[1]][1:m]) == nms[[2]][1:m])
>>
>> fails.
>>
>> It could be "fixed" by putting "na.rm=TRUE" into the all(), but that's
>> probably not right:
>>
>> > all(c(1, NA) == c(1, 2), na.rm = TRUE)
>> [1] TRUE
>>
>> I think we want to wrap the values in "paste", to convert to non-missing
>> characters.  That would be
>>
>> all(paste((nm <- nms[[1]][1:m])) == paste(nms[[2]][1:m]))
>>
>> and would give
>>
>> > diag(u)
>>  constant      <NA>      <NA>      <NA>
>>  5.423347  3.227376 11.948892 10.098983
>>
>> Any objections to me committing this change?
> 
> Yes, you don't want <NA> to match "NA".
> 
> If you think NA names should match, use identical.   Otherwise (and I 
> think this would be more consistent with other parts of R), do something
> like
> 
> eq <- (nm <- nms[[1]][1:m]) == nms[[2]][1:m]
> if(all(!is.na(eq) && eq)) ...
> 

I agree with your objection; I realized the same thing just after I 
posted my original.  The solution I came up with was putting the all() 
in isTRUE().  I think that achieves an identical result to your solution.

Can you see any reason to prefer one over the other?

Duncan Murdoch



From deepayan.sarkar at gmail.com  Wed Oct 19 18:56:08 2005
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Wed, 19 Oct 2005 11:56:08 -0500
Subject: [R] Lattice graphics strip labels for shingles
In-Reply-To: <5801DF3664AC854AA3CC2DB83E718D3005FB2D4B@sagemsg0006.sagemsmrd01.sa.gov.au>
References: <5801DF3664AC854AA3CC2DB83E718D3005FB2D4B@sagemsg0006.sagemsmrd01.sa.gov.au>
Message-ID: <eb555e660510190956o1b76656frb26a6c80bc7fcb3e@mail.gmail.com>

On 10/18/05, Kiermeier, Andreas (PIRSA - SARDI)
<Kiermeier.Andreas at saugov.sa.gov.au> wrote:
> Dear all,
>
> back in 2002 Martin Henry H. Stevens wrote
> (https://stat.ethz.ch/pipermail/r-help/2002-May/019851.html)
>
> > How do I control the text in strips? Specifically, I want to put in the
> > ranges generated in shingle(x) where x is continuous.
>
> with an answer from Deepyan Sarkar (see strip.new towards the end of this
> message).  I assume that the answer worked back then, but I've tried to
> implement it today, with little success.  I think that it may have to do
> with namespaces - but I'm not sure.

It does have to do with namespaces. grid.rect etc are in the grid
namespace which is not attached when you are calling strip.new. The
simplest solution is to attach it first, e.g. by

library(grid)

(or put 'require(grid)' inside strip.new).

Deepayan



From tschoenhoff at gmail.com  Wed Oct 19 18:59:52 2005
From: tschoenhoff at gmail.com (=?ISO-8859-1?Q?Thomas_Sch=F6nhoff?=)
Date: Wed, 19 Oct 2005 18:59:52 +0200
Subject: [R] how to test poisson distribution
In-Reply-To: <1115a2b00510190547m43fc1d0dle9c6bf1e9ea5bf4a@mail.gmail.com>
References: <1115a2b00510190547m43fc1d0dle9c6bf1e9ea5bf4a@mail.gmail.com>
Message-ID: <5ad2dec0510190959i3d048622i@mail.gmail.com>

Hi,


2005/10/19, Wensui Liu <liuwensui at gmail.com>:
> Dear All,
>
> I am wonderng how to test whether the data follows poisson distribution.
>
> Thank you so much!

Did you notice the PDF on distribution tests using R by Vito Ricci,
its found at CRAN in the docs contrib section, called "FITTING
DISTRIBUTIONS WITH R"

Maybe this could be of some help for you, especially look at page 7
(poisson dsitribution example).



From gunter.berton at gene.com  Wed Oct 19 19:18:02 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 19 Oct 2005 10:18:02 -0700
Subject: [R] how to test poisson distribution
In-Reply-To: <5ad2dec0510190959i3d048622i@mail.gmail.com>
Message-ID: <200510191718.j9JHI2lM000133@hertz.gene.com>

To be pedantic (I'm feeling cranky today):

One can never test "whether the data follow ["data" is plural] a Poisson
distribution" -- only whether there is sufficient evidence to cast that
assumption into doubt. Perhaps a better shorthand is "whether the data are
consistent with Poisonness" . This correctly leaves open the possibility
that the data are consistent with lots of other distribution-nesses, too. I
welcome alternatives, perhaps privately to reduce the list noise level.

(And,yes, I'm sure that Thomas knows this perfectly well).

I do think that we should be a bit less sloppy about such things even here,
lest we continue to promulgate already widespread misunderstandings, even at
the cost of slightly increased bandwidth. After all, precision is supposed
to be a major concern or ours.

As I've been cranky, others are free to return the favor. Sauce for the
goose ...

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Thomas 
> Sch??nhoff
> Sent: Wednesday, October 19, 2005 10:00 AM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] how to test poisson distribution
> 
> Hi,
> 
> 
> 2005/10/19, Wensui Liu <liuwensui at gmail.com>:
> > Dear All,
> >
> > I am wonderng how to test whether the data follows poisson 
> distribution.
> >
> > Thank you so much!
> 
> Did you notice the PDF on distribution tests using R by Vito Ricci,
> its found at CRAN in the docs contrib section, called "FITTING
> DISTRIBUTIONS WITH R"
> 
> Maybe this could be of some help for you, especially look at page 7
> (poisson dsitribution example).
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From rrc at fct.unl.pt  Wed Oct 19 19:27:00 2005
From: rrc at fct.unl.pt (Rui Cardoso)
Date: Wed, 19 Oct 2005 18:27:00 +0100
Subject: [R] matching two plots
Message-ID: <6.1.0.6.0.20051019181914.00ba82f8@pop.si.fct.unl.pt>

Hi,

I have a problem about graphics. I would like to plot two graphs: a barplot 
and curve. Here is the code:

 > barplot(dpois(0:45,20),xlim=c(0,45),names=0:45)
 > curve(dnorm(x,20,sqrt(20)),from=0,to=45,add=T)

Both graphs are drawn in the same figure, however the scale in both graphs 
dooes not match. For some reason the second plot is shifted to left. I 
think there is a problem concerning the axis scale.

Thanks a lot.

Rui



From Achim.Zeileis at wu-wien.ac.at  Wed Oct 19 19:31:26 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Wed, 19 Oct 2005 19:31:26 +0200
Subject: [R] how to test poisson distribution
In-Reply-To: <200510191718.j9JHI2lM000133@hertz.gene.com>
References: <5ad2dec0510190959i3d048622i@mail.gmail.com>
	<200510191718.j9JHI2lM000133@hertz.gene.com>
Message-ID: <20051019193126.0909e4c3.Achim.Zeileis@wu-wien.ac.at>

On Wed, 19 Oct 2005 10:18:02 -0700 Berton Gunter wrote:

> To be pedantic (I'm feeling cranky today):
> 
> One can never test "whether the data follow ["data" is plural] a
> Poisson distribution" -- only whether there is sufficient evidence to
> cast that assumption into doubt. Perhaps a better shorthand is
> "whether the data are consistent with Poisonness" . This correctly
> leaves open the possibility that the data are consistent with lots of
> other distribution-nesses, too. I welcome alternatives, perhaps
> privately to reduce the list noise level.

...now that Berton mentioned `checking distribution-nesses': the
function distplot() in the package vcd implements various plots for
distribution-nesses that can be used for graphical checking. Ord_plot()
is made for a similar purpose.
Finally, there is also a function goodfit() that computes
goodness-of-fit tests for such hypotheses.

All three functions are written following Chapter 2 `Fitting and
Graphing Discrete Distributions' in Michael Friendly's book `Visualizing
Categorical Data'.

hth,
Z

> (And,yes, I'm sure that Thomas knows this perfectly well).
> 
> I do think that we should be a bit less sloppy about such things even
> here, lest we continue to promulgate already widespread
> misunderstandings, even at the cost of slightly increased bandwidth.
> After all, precision is supposed to be a major concern or ours.
> 
> As I've been cranky, others are free to return the favor. Sauce for
> the goose ...
> 
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
>  
> "The business of the statistician is to catalyze the scientific
> learning process."  - George E. P. Box
>  
>  
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Thomas 
> > Sch??nhoff
> > Sent: Wednesday, October 19, 2005 10:00 AM
> > To: r-help at stat.math.ethz.ch
> > Subject: Re: [R] how to test poisson distribution
> > 
> > Hi,
> > 
> > 
> > 2005/10/19, Wensui Liu <liuwensui at gmail.com>:
> > > Dear All,
> > >
> > > I am wonderng how to test whether the data follows poisson 
> > distribution.
> > >
> > > Thank you so much!
> > 
> > Did you notice the PDF on distribution tests using R by Vito Ricci,
> > its found at CRAN in the docs contrib section, called "FITTING
> > DISTRIBUTIONS WITH R"
> > 
> > Maybe this could be of some help for you, especially look at page 7
> > (poisson dsitribution example).
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From vincent.goulet at act.ulaval.ca  Wed Oct 19 19:45:16 2005
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Wed, 19 Oct 2005 13:45:16 -0400
Subject: [R] Subsetting a list
In-Reply-To: <17238.24973.55147.771104@stat.math.ethz.ch>
References: <mailman.13.1129629601.29332.r-help@stat.math.ethz.ch>
	<43550723.7000004@ipimar.pt>
	<17238.24973.55147.771104@stat.math.ethz.ch>
Message-ID: <200510191345.16851.vincent.goulet@act.ulaval.ca>

Le 19 Octobre 2005 11:09, Martin Maechler a ??crit??:

[...]

> Lists can have 'dim' attributes and hence be treated as arrays;

For me, this is an amazing feature that I discovered almost by accident (I 
tried it an it worked)! This creates a sort of three-dimensional object --- 
much like an array --- where the third dimension is of varying length. Wow.

I agree, though, that the result of 'print' on such an object is not crystal 
clear (but does make sense).

[...]

-- 
  Vincent Goulet, Associate Professor
  ??cole d'actuariat
  Universit?? Laval, Qu??bec 
  Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca



From mcardeal at ufba.br  Wed Oct 19 20:11:32 2005
From: mcardeal at ufba.br (Carlos Mauricio Cardeal Mendes)
Date: Wed, 19 Oct 2005 15:11:32 -0300
Subject: [R] npmc package
In-Reply-To: <43564EC4.7090407@statistik.uni-dortmund.de>
References: <4356499A.6040604@ufba.br>
	<43564EC4.7090407@statistik.uni-dortmund.de>
Message-ID: <43568C54.2060000@ufba.br>

So, is there another package to substitute those functions described on 
"ORPHANED" npmc package ?

Regards,
Mauricio
Brazil

Uwe Ligges escreveu:

> Carlos Mauricio Cardeal Mendes wrote:
>
>> Hi
>>
>> Does anyone know where is the package: npmc (Nonparametric Multiple 
>> Comparisons).
>>
>> I found the reference on R Site Search, but not the package itself on 
>> CRAN as suggested.
>
>
> The packages is "ORPHANED" and removed from the CRAN main repository. 
> You can get older versions from the archives, though:
>
> your-CRAN-mirror/src/contrib/Archive/N/npmc_1.0-1.tar.gz
>
> Uwe Ligges
>
>> Thanks
>>
>> Mauricio
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>
>
>
>
>



From chrysopa at gmail.com  Wed Oct 19 20:53:07 2005
From: chrysopa at gmail.com (Ronaldo Reis-Jr.)
Date: Wed, 19 Oct 2005 16:53:07 -0200
Subject: [R] how to compare a null model with a model with NAs?
Message-ID: <200510191653.07420.chrysopa@gmail.com>

Hi,

I make a model:

m.null <- glm(y~1)

m.comp <- glm(y~x1+x2+x3)

I try make a anova like this

anova(m.null,m.comp,test="F")

The result:

Erro em anova.glmlist(c(list(object), dotargs), dispersion = dispersion,  : 
    models were not all fitted to the same size of dataset

The problem is that I have some NAs in x1, x2 and x3 and is not teh same row 
fo NAs. How to set is in a null model without I need to remove these rows?

Thansk
Ronaldo
-- 
Quem cedo madruga, fica com sono o dia todo.
--
|>   // | \\   [***********************************]
|   ( ??   ?? )  [Ronaldo Reis J??nior                ]
|>      V      [UFV/DBA-Entomologia                ]
|    /     \   [36570-000 Vi??osa - MG              ]
|>  /(.''`.)\  [Fone: 31-3899-4007                 ]
|  /(: :'  :)\ [chrysopa at insecta.ufv.br            ]
|>/ (`. `'` ) \[ICQ#: 5692561 | LinuxUser#: 205366 ]
|    ( `-  )   [***********************************]
|>>  _/   \_Powered by GNU/Debian Woody/Sarge



From mbock at Environcorp.com  Wed Oct 19 20:53:46 2005
From: mbock at Environcorp.com (Mike Bock)
Date: Wed, 19 Oct 2005 13:53:46 -0500
Subject: [R] Range plots (lattice or base?)
Message-ID: <AA564451B2A8A147B653D20C3E481D62D5455E@emloop02.environchicago.environ.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051019/0514be4d/attachment.pl

From p.murrell at auckland.ac.nz  Wed Oct 19 21:03:59 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Thu, 20 Oct 2005 08:03:59 +1300
Subject: [R] Range plots (lattice or base?)
References: <AA564451B2A8A147B653D20C3E481D62D5455E@emloop02.environchicago.environ.local>
Message-ID: <4356989F.4070103@stat.auckland.ac.nz>

Hi


Mike Bock wrote:
> I am looking to create what I would call a "simple variation" on the
> boxplot. What I would like to do is to be able to plot the upper and
> lower confidence limits as the "box" and the 10th and 90th percentile as
> the whiskers. What I have done is write the code to create a dataframe,
> the columns of which are the mean, sd, 10th percentile, 90th percentile,
> lower confidence limit of the mean, and upper confidence limit of the
> mean, the rows are the groups. I have exported this to excel and get the
> graph I want by using the stock graphs in excel that plot open, close,
> high and low but I would much prefer to do this in R for reason too
> numerous to enumerate.
> 
> I have looked high and low and even took a brief look at the bwplot code
> in the lattice package.  Given my experience level it would take quite a
> while for me to modify the bwplot code to get what I want and create a
> new graph type, assuming I could get it to work at all. Does anyone know
> of an easier way to get what I want, with and example? Lattice, grid,
> base, whatever, I don't especially care what tools I need to use. My
> only constrante is that I feed it the values required as a dataframe
> rather than calculate it on the fly so if we change our minds about UCL
> method or percentiles there is no problem.


Can you put the Excel-generated version up somewhere for us to see the 
final output you want?  Then we could make some specific suggestions.

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From nepossiver at yahoo.com  Wed Oct 19 21:24:30 2005
From: nepossiver at yahoo.com (Horacio Montenegro)
Date: Wed, 19 Oct 2005 12:24:30 -0700 (PDT)
Subject: [R] error open .RData
In-Reply-To: <435618B3.4070800@gmail.com>
Message-ID: <20051019192431.69462.qmail@web50614.mail.yahoo.com>


     hi

     It seems that, in some cases, saving a .RData
containing objects from some packages and later trying
to start R (or load the .RData) before loading the
package could cause this error. See

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/46910.html

     If the .RData contains objects from some specific
packages, try loading the package first and then load
the .RData file.

     Also, RSiteSearch(".RData corrupted") results in
lots of hits.

     hope this helps,
         horacio montenegro

--- Muhammad Subianto <subianto at gmail.com> wrote:

> Dear R-list,
> I have a problem to open my R workspace.
> When I try to open my file .Rdata with double-clik
> on windows explore I 
> get the error like this:
> 
> Error in load(name, envir = .GlobalEnv) : error
> reading from connection
> 
> and on windows error:
> 
> Fatal error: unable to restore saved data in .RData
> 
> I try with,
> 
>  > load("CaseStudyHouseID50.RData", .GlobalEnv)
> Error in load("CaseStudyHouseID50.RData",
> .GlobalEnv) :
>          error reading from connection
>  >
> 
>  > load("CaseStudyHouseID50.RData")
> Error in load("CaseStudyHouseID50.RData") :
>          error reading from connection
>  >
> 
> I have done to save my R workspace like this:
>
################################################################################
>    save(list = ls(all=TRUE),
>         file = "CaseStudyHouseID50.RData")
>
################################################################################
> 
> What is wrong?
> Is there anyway to open .RData?
> 
> Regards, Muhammad Subianto
> 
>



From mbock at Environcorp.com  Wed Oct 19 21:25:15 2005
From: mbock at Environcorp.com (Mike Bock)
Date: Wed, 19 Oct 2005 14:25:15 -0500
Subject: [R] Range plots (lattice or base?)
Message-ID: <AA564451B2A8A147B653D20C3E481D62D2B9C9@emloop02.environchicago.environ.local>


The first example on this page is pretty close to what I want, but the
x-axis would be a category (like location), and the true range
anotations are left out. I don't; have a place to post but can e-mail a
pdf of my excel version by request.


http://www.stockcharts.com/education/IndicatorAnalysis/indic_ATR.html

Mike


> -----Original Message-----
> From: Paul Murrell [mailto:p.murrell at auckland.ac.nz] 
> Sent: Wednesday, October 19, 2005 3:04 PM
> To: Mike Bock
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Range plots (lattice or base?)
> 
> 
> Hi
> 
Delete orginal message for brevity
> 
> Can you put the Excel-generated version up somewhere for us 
> to see the 
> final output you want?  Then we could make some specific suggestions.
> 
> Paul
> -- 
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
> 
>



From greg.snow at ihc.com  Wed Oct 19 21:28:39 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Wed, 19 Oct 2005 13:28:39 -0600
Subject: [R] Range plots (lattice or base?)
Message-ID: <s3564a1e.035@lp-msg1.co.ihc.com>

Using base graphics you can use the bxp function.  This is what 
boxplot calls to do the actual plotting.  Look at the return value
for boxplot in the help for boxplot to see the form of the data
that needs to be passed to bxp (also look at the help for bxp)
You could write a simple function that takes your data frame
and extracts the appropriate numbers into a matrix within a list
to pass to bxp.

hope this helps,

Greg Snow, Ph.D.
Statistical Data Center, LDS Hospital
Intermountain Health Care
greg.snow at ihc.com
(801) 408-8111

>>> "Mike Bock" <mbock at Environcorp.com> 10/19/05 12:53PM >>>
I am looking to create what I would call a "simple variation" on the
boxplot. What I would like to do is to be able to plot the upper and
lower confidence limits as the "box" and the 10th and 90th percentile
as
the whiskers. What I have done is write the code to create a
dataframe,
the columns of which are the mean, sd, 10th percentile, 90th
percentile,
lower confidence limit of the mean, and upper confidence limit of the
mean, the rows are the groups. I have exported this to excel and get
the
graph I want by using the stock graphs in excel that plot open, close,
high and low but I would much prefer to do this in R for reason too
numerous to enumerate.

I have looked high and low and even took a brief look at the bwplot
code
in the lattice package.  Given my experience level it would take quite
a
while for me to modify the bwplot code to get what I want and create a
new graph type, assuming I could get it to work at all. Does anyone
know
of an easier way to get what I want, with and example? Lattice, grid,
base, whatever, I don't especially care what tools I need to use. My
only constrante is that I feed it the values required as a dataframe
rather than calculate it on the fly so if we change our minds about
UCL
method or percentiles there is no problem.

Thanks in advance,
Mike


Michael Bock PhD
ENVIRON International Corporation
136 Commerical Street, Suite 402
Portland, ME 04101
phone: not active yet
fax: not active yet


	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From deepayan.sarkar at gmail.com  Wed Oct 19 21:34:02 2005
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Wed, 19 Oct 2005 14:34:02 -0500
Subject: [R] Range plots (lattice or base?)
In-Reply-To: <AA564451B2A8A147B653D20C3E481D62D5455E@emloop02.environchicago.environ.local>
References: <AA564451B2A8A147B653D20C3E481D62D5455E@emloop02.environchicago.environ.local>
Message-ID: <eb555e660510191234x5ff2d590yc45ad7865d58ef61@mail.gmail.com>



On 10/19/05, Mike Bock <mbock at environcorp.com> wrote:
> I am looking to create what I would call a "simple variation" on the
> boxplot. What I would like to do is to be able to plot the upper and
> lower confidence limits as the "box" and the 10th and 90th percentile as
> the whiskers. What I have done is write the code to create a dataframe,
> the columns of which are the mean, sd, 10th percentile, 90th percentile,
> lower confidence limit of the mean, and upper confidence limit of the
> mean, the rows are the groups. I have exported this to excel and get the
> graph I want by using the stock graphs in excel that plot open, close,
> high and low but I would much prefer to do this in R for reason too
> numerous to enumerate.
> 
> I have looked high and low and even took a brief look at the bwplot code
> in the lattice package.  Given my experience level it would take quite a
> while for me to modify the bwplot code to get what I want and create a
> new graph type, assuming I could get it to work at all. Does anyone know
> of an easier way to get what I want, with and example? Lattice, grid,
> base, whatever, I don't especially care what tools I need to use. My
> only constrante is that I feed it the values required as a dataframe
> rather than calculate it on the fly so if we change our minds about UCL
> method or percentiles there is no problem.

Is your UCL method guaranteed to work separately on groups (e.g. if the s.d. is estimated per group) or does it share information across groups (e.g. some sort of pooled estimate of s.d.)? In the former case, you could try writing a replacement for boxplot.stats and use that in panel.bwplot.

Deepayan



From francoisromain at free.fr  Wed Oct 19 21:46:07 2005
From: francoisromain at free.fr (Romain Francois)
Date: Wed, 19 Oct 2005 21:46:07 +0200
Subject: [R] matching two plots
In-Reply-To: <6.1.0.6.0.20051019181914.00ba82f8@pop.si.fct.unl.pt>
References: <6.1.0.6.0.20051019181914.00ba82f8@pop.si.fct.unl.pt>
Message-ID: <4356A27F.2050205@free.fr>

Le 19.10.2005 19:27, Rui Cardoso a ??crit :

>Hi,
>
>I have a problem about graphics. I would like to plot two graphs: a barplot 
>and curve. Here is the code:
>
> > barplot(dpois(0:45,20),xlim=c(0,45),names=0:45)
> > curve(dnorm(x,20,sqrt(20)),from=0,to=45,add=T)
>
>Both graphs are drawn in the same figure, however the scale in both graphs 
>dooes not match. For some reason the second plot is shifted to left. I 
>think there is a problem concerning the axis scale.
>
>Thanks a lot.
>
>Rui
>  
>
Hello,

The problem is barplot. To see that :

R> (barplot(dpois(0:45,20),xlim=c(0,45),names=0:45))
R> axis(3)

Try something like :

R> plot(0:45, dpois(0:45,20), type="h", lwd=4, col="gray")
R> curve(dnorm(x,20,sqrt(20)),from=0,to=45,add=T)

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~
~~~~~~      Romain FRANCOIS - http://francoisromain.free.fr      ~~~~~~
~~~~~~~~           Doctorant INRIA Futurs / EDF                ~~~~~~~~
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~



From mschwartz at mn.rr.com  Wed Oct 19 22:16:34 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Wed, 19 Oct 2005 15:16:34 -0500
Subject: [R] matching two plots
In-Reply-To: <6.1.0.6.0.20051019181914.00ba82f8@pop.si.fct.unl.pt>
References: <6.1.0.6.0.20051019181914.00ba82f8@pop.si.fct.unl.pt>
Message-ID: <1129752994.15504.49.camel@localhost.localdomain>

On Wed, 2005-10-19 at 18:27 +0100, Rui Cardoso wrote:
> Hi,
> 
> I have a problem about graphics. I would like to plot two graphs: a barplot 
> and curve. Here is the code:
> 
>  > barplot(dpois(0:45,20),xlim=c(0,45),names=0:45)
>  > curve(dnorm(x,20,sqrt(20)),from=0,to=45,add=T)
> 
> Both graphs are drawn in the same figure, however the scale in both graphs 
> dooes not match. For some reason the second plot is shifted to left. I 
> think there is a problem concerning the axis scale.
> 
> Thanks a lot.
> 
> Rui


This came up this past summer and Gabor and I had a couple of different
approaches to the solution. You can see the posts here:

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/57431.html

and

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/57432.html


Using my approach with barplot(), what you need to do is to set the
'space' argument to 0 so that there is no space between the bars. This
will then place the bar centers at increments of 0.5, in your case
seq(0.5, 45.5, 5).

Knowing this, you can then adjust the x axis position in curve() by +0.5
to coincide with the bars. So you end up with this:

barplot(dpois(0:45, 20), names = 0:45, space = 0, ylim = c(0, .1))
curve(dnorm(x, 20 + 0.5, sqrt(20)), add = TRUE)

HTH,

Marc Schwartz



From Gary.Nelson at state.ma.us  Wed Oct 19 22:16:29 2005
From: Gary.Nelson at state.ma.us (Nelson, Gary (FWE))
Date: Wed, 19 Oct 2005 16:16:29 -0400
Subject: [R] Automatic rounding of values after factors ,
	converted to numeric, are multipled by a real number
Message-ID: <74BDE31AFD6EC54DB026E6CD11FF0A7E124724@ES-MSG-008.es.govt.state.ma.us>

I am wondering if someone would have any suggestion about my issue?


I have the following code:

wgts<-aggregate(subset(lendata,select=c(Length)),list(lendata$Cruise,len
data$Station,lendata$Region,lendata$Total),mean)
wgts<-wgts[order(wgts$Group.3,wgts$Group.1,wgts$Group.1),]
names(wgts)<-c("Cruise","Station","Region","Total","MLen")
wgts$Total<-as.numeric(levels(wgts$Total))[wgts$Total]
wgts$swmean<-with(wgts,wgts$Total*wgts$MLen) 

When I run it, I get:
   Cruise Station Region Total     MLen swmean
3    2350     256      1     2 70.50000    141
5    2350     254      1     3 73.33333    220
6    2350     287      1     3 65.66667    197
9    2350     232      1     4 75.25000    301
10   2350     294      1     4 56.00000    224
12   2350     301      1     5 70.20000    351
14   2350     316      1     6 67.33333    404
15   2350     255      1     7 55.00000    385
17   2350     285      1     8 73.50000    588
19   2350     212      1    10 57.50000    575
20   2350     250      1    10 61.50000    615
27   2350     221      1    24 95.29167   2287
33   2350     229      1    35 55.62857   1947
37   2350     293      1    47 53.82979   2530
38   2350     203      1    50 55.54000   2777
39   2350     248      1    55 63.30909   3482
41   2350     246      1    63 95.82540   6037
42   2350     265      1    68 55.54412   3777
43   2350     251      1    82 62.60976   5134
44   2350     234      1    85 57.21176   4863

Every value is correct except that the "swmean"s are rounded and I can't
get values with the decimals fractions.  I have tried as.double and have
change the options(digits=7), but nothing seems to work. I have spent
several hours combing manuals and archives. 

Any suggestions would be appreciated.
************************************************************************
*
Gary A. Nelson
Massachusetts Division of Marine Fisheries
30 Emerson Avenue
Gloucester, MA 01930
Phone: (978) 282-0308 x114
Fax: (617) 727-3337
Email: Gary.Nelson at state.ma.us



From alexander.antonyuk at wolfson.oxford.ac.uk  Wed Oct 19 14:00:18 2005
From: alexander.antonyuk at wolfson.oxford.ac.uk (Alexander Antonyuk)
Date: Wed, 19 Oct 2005 13:00:18 +0100
Subject: [R] Weights in survReg
Message-ID: <0c0101c5d4a4$ac680370$86d301a3@stats.ox.ac.uk>

Dear R users,

I am trying to find out what the function survReg does exactly with the 
Weights parameters. I looked in Terry Therneau documentations and other 
places and couldn't find anything. I tried to make an analogy with weighted 
OLS and assumed that the scale parameter Sigma in the accelerated 
failure-time model log(Time)= X*betas +Sigma*E, is of the form Sigma(i) = 
Sigma/Weights(i).

Can anyone confirm that or point me in the direction where I can find out 
for sure?

Thank you,
Sasha



From stefano.iacus at unimi.it  Wed Oct 19 19:18:16 2005
From: stefano.iacus at unimi.it (stefano iacus)
Date: Wed, 19 Oct 2005 19:18:16 +0200
Subject: [R] Forum of Mac questions (Was:  loading packages - mac user)
In-Reply-To: <17238.12195.762893.454964@stat.math.ethz.ch>
References: <e3930910510181146x2d6fd70avcc887d6259f08e54@mail.gmail.com>
	<Pine.LNX.4.63a.0510181310040.30016@homer24.u.washington.edu>
	<1129705721.30365.11.camel@biol102145.oulu.fi>
	<Pine.LNX.4.61.0510190849350.31876@gannet.stats>
	<17238.12195.762893.454964@stat.math.ethz.ch>
Message-ID: <A5F3D3B2-FCE5-458B-9E01-4638BE0A067F@unimi.it>


On 19/ott/05, at 13:36, Martin Maechler wrote:

>>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>>     on Wed, 19 Oct 2005 08:58:20 +0100 (BST) writes:
>>>>>>
>
>     BDR> On Wed, 19 Oct 2005, Jari Oksanen wrote:
>
>>> On Tue, 2005-10-18 at 13:13 -0700, Thomas Lumley wrote:
>>>
>>>
>>>> Both for this and for working out why Tcl/Tk isn't
>>>> installed you might be better off trying R-sig-mac
>>>> rather than r-help
>>>>
>>>>
>>>  This is a very common piece of advice. However, this is
>>> not what you would imagine if you read the description of
>>> R-SIG-mac on the R home page:
>>>
>
>     BDR> It is not actually on the R home page or even on
>     BDR> www.r-project.org.  I think you mean
>
>     BDR> https://stat.ethz.ch/mailman/listinfo/r-sig-mac
>
>     BDR> This arises because the purpose of the list has changed
>     BDR> from
>
>     BDR>    R Special Interest Group on Macintosh Development
>     BDR> and Porting, both for MacOS 8.6 - 9.x and MacOS X
>
>     BDR> I think a wording like R-sig-debian namely
>
>     BDR>    R Special Interest Group for MacOS X ports of R

Brian's definition  seems appropriate to me nowadays

and the (extended) disclaimer should include both development issues  
specific to OS X (ports, etc) and user feedback on R.app GUI (we  
don't want R.app bugs go into the R-bugs list), but NOT general R- 
help topics which should go to R-help indeed.

I think we should keep the devel part in R-sig-Mac.

I'm including Simon Urbanek and waiting for some reaction before  
"taking actions" on R-sig-mac.

stefano


>
>     BDR> would be better.
>
> yes, thank you both  ---- IFF this is really the intention.
>
> Stefano Iacus is the maintainer (and initiator) of the list
> and should say (and maybe ask on the R-SIG-Mac list) what he
> (and the subscribers) really wants.
>
>
>>> R-SIG-Mac R Special Interest Group on Mac Development
>>>
>>> This is very similar to the description of R-devel:
>>>
>>> This list is intended for questions and discussion about
>>> code development in R.
>>>
>>> And that description is even more intimidating when you
>>> read further:
>>>
>>> Questions likely to prompt discussion unintelligible to
>>> non-programmers or topics that are too technical for
>>> R-help's audience should go to R-devel
>>>
>>> Would it make sense to change the description of
>>> R-SIG-mac so that it would welcome question on R usage in
>>> Mac, instead of being a "Mac Devolepment" forum that
>>> sounds like being "unintelligible to non-programmers"?
>>>
>
>     BDR> Which seems quite reasonable to me.  The topics which
>     BDR> provoke this response usually are questions
>     BDR> unintelligible except to Mac sysadmins/programmers and
>     BDR> definitely `too technical for R-help's audience'.
>
> I agree.  We shouldn't let R users on the Mac think that all
> their questions should go to R-SIG-Mac.
> Regular R questions should continue to come to R-help (or
> R-devel) just as per the posting guide.
>
> Martin Maechler
>
>
>     BDR> -- Brian D. Ripley, ripley at stats.ox.ac.uk Professor of
>     BDR> Applied Statistics, http://www.stats.ox.ac.uk/~ripley/
>     BDR> University of Oxford, Tel: +44 1865 272861 (self) 1
>     BDR> South Parks Road, +44 1865 272866 (PA) Oxford OX1 3TG,
>     BDR> UK Fax: +44 1865 272595
>
>
> !DSPAM:43562fae226121420620285!
>
>



From tim_smith_666 at yahoo.com  Wed Oct 19 22:36:19 2005
From: tim_smith_666 at yahoo.com (Tim Smith)
Date: Wed, 19 Oct 2005 13:36:19 -0700 (PDT)
Subject: [R] clustering algorithm detail
Message-ID: <20051019203619.84167.qmail@web35002.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051019/1bfd3799/attachment.pl

From p.dalgaard at biostat.ku.dk  Wed Oct 19 22:45:13 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 19 Oct 2005 22:45:13 +0200
Subject: [R] Automatic rounding of values after factors ,
	converted to numeric, are multipled by a real number
In-Reply-To: <74BDE31AFD6EC54DB026E6CD11FF0A7E124724@ES-MSG-008.es.govt.state.ma.us>
References: <74BDE31AFD6EC54DB026E6CD11FF0A7E124724@ES-MSG-008.es.govt.state.ma.us>
Message-ID: <x2fyqx8cdi.fsf@turmalin.kubism.ku.dk>

"Nelson, Gary (FWE)" <Gary.Nelson at state.ma.us> writes:

> I am wondering if someone would have any suggestion about my issue?
> 
> 
> I have the following code:
> 
> wgts<-aggregate(subset(lendata,select=c(Length)),list(lendata$Cruise,len
> data$Station,lendata$Region,lendata$Total),mean)
> wgts<-wgts[order(wgts$Group.3,wgts$Group.1,wgts$Group.1),]
> names(wgts)<-c("Cruise","Station","Region","Total","MLen")
> wgts$Total<-as.numeric(levels(wgts$Total))[wgts$Total]
> wgts$swmean<-with(wgts,wgts$Total*wgts$MLen) 
> 
> When I run it, I get:
>    Cruise Station Region Total     MLen swmean
> 3    2350     256      1     2 70.50000    141
> 5    2350     254      1     3 73.33333    220
> 6    2350     287      1     3 65.66667    197
> 9    2350     232      1     4 75.25000    301
> 10   2350     294      1     4 56.00000    224
> 12   2350     301      1     5 70.20000    351
> 14   2350     316      1     6 67.33333    404
> 15   2350     255      1     7 55.00000    385
> 17   2350     285      1     8 73.50000    588
> 19   2350     212      1    10 57.50000    575
> 20   2350     250      1    10 61.50000    615
> 27   2350     221      1    24 95.29167   2287
> 33   2350     229      1    35 55.62857   1947
> 37   2350     293      1    47 53.82979   2530
> 38   2350     203      1    50 55.54000   2777
> 39   2350     248      1    55 63.30909   3482
> 41   2350     246      1    63 95.82540   6037
> 42   2350     265      1    68 55.54412   3777
> 43   2350     251      1    82 62.60976   5134
> 44   2350     234      1    85 57.21176   4863
> 
> Every value is correct except that the "swmean"s are rounded and I can't
> get values with the decimals fractions.  I have tried as.double and have
> change the options(digits=7), but nothing seems to work. I have spent
> several hours combing manuals and archives. 

as far as I can see, the issue is that Total*MLen just *are* pretty
close to being integers, e.g.

> 4863/85
[1] 57.21176

> z <- x$Total*x$MLen
> z - round(z)
 [1]  0.00000 -0.00001  0.00001  0.00000  0.00000  0.00000 -0.00002  0.00000
 [9]  0.00000  0.00000  0.00000  0.00008 -0.00005  0.00013  0.00000 -0.00005
[17]  0.00020  0.00016  0.00032 -0.00040

 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From alexisjdiamond at gmail.com  Wed Oct 19 22:47:27 2005
From: alexisjdiamond at gmail.com (Alexis Diamond)
Date: Wed, 19 Oct 2005 16:47:27 -0400
Subject: [R] Optim with two constraints
In-Reply-To: <200510191751.j9JHpuiY001621@us17.unix.fas.harvard.edu>
References: <200510191751.j9JHpuiY001621@us17.unix.fas.harvard.edu>
Message-ID: <67be2ce30510191347y1e40754fv14f56aaa1f09328a@mail.gmail.com>

Hello,

I have a follow-up from Jens's question and Professor Ripley's response.

Jens wants to do quadratic optimization with 2 constraints:

> > > # I need two constraints:
> > > # 1. each element in par needs to be between 0 and 1
> > >  # 2. sum(par)=1, i.e. the elements in par need to sum to 1

how does one set both constraints in quadprog, per Prof. Ripley's suggestion?

i know how to get quadprog to handle the second constraint, but not
BOTH, since quadprog only takes as inputs the constraint matrix "A"
and constraint vector "b"--
unlike in "ipop" (kernlab), there is no additional option for box constraints.

apologies if i am not seeing something obvious here.

thanks in advance,

alexis

On 10/19/05, Jens Hainmueller <jhainm at fas.harvard.edu> wrote:
>
>
> > -----Urspr??ngliche Nachricht-----
> > Von: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> > Gesendet: Thursday, October 13, 2005 2:46 AM
> > An: Jens Hainmueller
> > Cc: r-help at stat.math.ethz.ch
> > Betreff: Re: [R] Optim with two constraints
> >
> > This is actually quadratic programming, so why do you want to
> > use optim()?
> > There are packages specifically for QP, e.g. quadprog.
> >
> > A more general approach is to eliminate one variable, which
> > gives you an inequality constrained problem in n-1 variables
> > to which you could apply contrOptim().  Other
> > re-parametrizations (e.g. of weights as a log-linear model)
> > will work provided none of the parameters are going to be
> > zero at the optimum (one cannot be one without all the others
> > being zero).
> >
> > On Wed, 12 Oct 2005, Jens Hainmueller wrote:
> >
> > > Hi R-list,
> > >
> > > I am new to optimization in R and would appreciate help on the
> > > following question. I would like to minimize the following function
> > > using two
> > > constraints:
> > >
> > > ######
> > > fn <- function(par,H,F){
> > >
> > >     fval <- 0.5 * t(par) %*% H %*% par + F%*% par
> > >     fval
> > >
> > >  }
> > >
> > > # matrix H is (n by k)
> > > # matrix F is (n by 1)
> > > # par is a (n by 1) set of weights
> > >
> > > # I need two constraints:
> > > # 1. each element in par needs to be between 0 and 1 # 2.
> > sum(par)=1
> > > i.e. the elements in par need to sum to 1
> > >
> > > ## I try to use optim
> > > res <- optim(c(runif(16),fn, method="L-BFGS-B", H=H, F=f
> > > ,control=list(fnscale=-1), lower=0, upper=1) ######
> > >
> > > If I understand this correctly, using L-BFGS-B with lower=0 and
> > > upper=1 should take care of constraint 1 (box constraints).
> > What I am
> > > lacking is the skill to include constraint no 2.
> > >
> > > I guess I could solve this by reparametrization but I am
> > not sure how
> > > exactly. I could not find (i.e. wasn't able to infer) the answer to
> > > this in the archives despite the many comments on optim and
> > > constrained optimization (sorry if I missed it there). I am
> > using version 2.1.1 under windows XP.
> > >
> > > Thank you very much.
> > >
> > > Jens
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> > >
> >
> > --
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
>
>



From chrish at stats.ucl.ac.uk  Wed Oct 19 22:53:06 2005
From: chrish at stats.ucl.ac.uk (Christian Hennig)
Date: Wed, 19 Oct 2005 21:53:06 +0100 (BST)
Subject: [R] clustering algorithm detail
In-Reply-To: <20051019203619.84167.qmail@web35002.mail.mud.yahoo.com>
References: <20051019203619.84167.qmail@web35002.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.58.0510192152380.7921@egon.stats.ucl.ac.uk>

Have you tried as.dist(distmat)?

Christian

On Wed, 19 Oct 2005, Tim Smith wrote:

> Hi all,
>
> I wanted to run the hclust (or any other clustering algorithm) on a distance matrix. I have formed the distance matrix as:
>
> distmat:
>
>         a        b         c         d        e
> a    0.00    0.96    1.60    1.60    1.68
> b    0.96    0.00    0.96    1.80    2.64
> c   1.60    0.96    0.00    0.84    1.80
> d   1.60    1.80    0.84    0.00    0.96
> e   1.68    2.64    1.80    0.96    0.00
>
> Now, I would like to run a clustering algorithm on it. I tried:
>
> newclust = hclust(distmat)
>
> and got the following error:
>
> Error in if (n < 2) stop("Must have n >= 2 objects to cluster") :
>         argument is of length zero
>
> I understand that the documentation says that the matrix ' d: a dissimilarity structure as produced by 'dist''. Does that mean that I need to convert it into a lower triangle matrix? I also tried:
>
> newclust = hclust(vech(distmat))
>
> but this gave a similar error. Where am I going wrong?
>
>
> Also, will hclust be able to handle 'NA' in the dissimilarity matrix?
>
> many thanks,
>
>
> Tim
>
>
>
>
> ---------------------------------
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

*** --- ***
Christian Hennig
University College London, Department of Statistical Science
Gower St., London WC1E 6BT, phone +44 207 679 1698
chrish at stats.ucl.ac.uk, www.homepages.ucl.ac.uk/~ucakche



From je_lemaitre at hotmail.com  Wed Oct 19 23:25:31 2005
From: je_lemaitre at hotmail.com (=?iso-8859-1?B?Suly9G1lIExlbWHudHJl?=)
Date: Wed, 19 Oct 2005 17:25:31 -0400
Subject: [R] sqlQuery and string selection
Message-ID: <BAY103-DAV172CD27B221B63BB3C544690700@phx.gbl>

Dear alls,

Could someone tell me how to select a subset of string observations (e.g.
"females" in a sex column) with sqlQuery in the RODBC library?

Indeed, I'm trying to select a subset of observations on my access database
with:

female<-sqlQuery(mychannel,"SELECT Micromammiferes.sex
FROM Micromammiferes
WHERE (((Micromammiferes.sex)="females"));")

The sql works well in access but in R, I keep getting:

Error: syntax error.

Any help would be very appreciated,

Thanks a lot

J??r??me Lema??tre
Ph.D. student
D??partment of biology,
University Laval
Quebec, Canada



From mario.aignertorres at gmail.com  Wed Oct 19 23:34:09 2005
From: mario.aignertorres at gmail.com (Mario Aigner-Torres)
Date: Wed, 19 Oct 2005 19:34:09 -0200
Subject: [R] adding error bars to lattice plots
Message-ID: <af34d0c00510191434v23e2be42v493570589417deec@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051019/ebe11aee/attachment.pl

From ichristie at gmail.com  Wed Oct 19 23:49:06 2005
From: ichristie at gmail.com (Israel Christie)
Date: Wed, 19 Oct 2005 17:49:06 -0400
Subject: [R] Filter design in R?
Message-ID: <4356BF52.4080606@gmail.com>

Dr. Williams,
I ran across your inquiry on one of the R-help mailing lists regarding 
digital filter design and implementation. I found no response to your 
email in the archives and was wondering if you were able to find anything.

Thanks,
Israel

-- 

Israel Christie, Ph.D.
Email: ichristie at gmail.com
Phone: 865.766.0214
Mobile: 865.406.4615



From paul at metrak.com  Thu Oct 20 00:04:41 2005
From: paul at metrak.com (paul sorenson)
Date: Thu, 20 Oct 2005 08:04:41 +1000
Subject: [R] sqlQuery and string selection
In-Reply-To: <BAY103-DAV172CD27B221B63BB3C544690700@phx.gbl>
References: <BAY103-DAV172CD27B221B63BB3C544690700@phx.gbl>
Message-ID: <4356C2F9.5080209@metrak.com>

J??r??me Lema??tre wrote:
> Dear alls,
> 
> Could someone tell me how to select a subset of string observations (e.g.
> "females" in a sex column) with sqlQuery in the RODBC library?
> 
> Indeed, I'm trying to select a subset of observations on my access database
> with:
> 
> female<-sqlQuery(mychannel,"SELECT Micromammiferes.sex
> FROM Micromammiferes
> WHERE (((Micromammiferes.sex)="females"));")
> 
> The sql works well in access but in R, I keep getting:
> 
> Error: syntax error.

R is likely to have problems with nested quote characters.

Ie:

x = "SELECT Micromammiferes.sex FROM Micromammiferes WHERE 
(((Micromammiferes.sex)="females"));"

also results in a syntax error (my mailer split the line).



From sourceforge at metrak.com  Thu Oct 20 00:05:59 2005
From: sourceforge at metrak.com (paul sorenson (sosman))
Date: Thu, 20 Oct 2005 08:05:59 +1000
Subject: [R] sqlQuery and string selection
In-Reply-To: <BAY103-DAV172CD27B221B63BB3C544690700@phx.gbl>
References: <BAY103-DAV172CD27B221B63BB3C544690700@phx.gbl>
Message-ID: <4356C347.1070806@metrak.com>

(sorry if a duplicate pops through ...)
J??r??me Lema??tre wrote:
> Dear alls,
> 
> Could someone tell me how to select a subset of string observations (e.g.
> "females" in a sex column) with sqlQuery in the RODBC library?
> 
> Indeed, I'm trying to select a subset of observations on my access database
> with:
> 
> female<-sqlQuery(mychannel,"SELECT Micromammiferes.sex
> FROM Micromammiferes
> WHERE (((Micromammiferes.sex)="females"));")
> 
> The sql works well in access but in R, I keep getting:
> 
> Error: syntax error.

Most computer software has problems with nested quote characters.

Ie:

 > x = "SELECT Micromammiferes.sex FROM Micromammiferes WHERE
(((Micromammiferes.sex)="females"));"

also results in a syntax error (my mailer split the line).



From gunter.berton at gene.com  Thu Oct 20 00:19:18 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 19 Oct 2005 15:19:18 -0700
Subject: [R] adding error bars to lattice plots
In-Reply-To: <af34d0c00510191434v23e2be42v493570589417deec@mail.gmail.com>
Message-ID: <200510192219.j9JMJIEo018489@ohm.gene.com>

?llines, lsegments and the like can be used in the panel functions to draw
any sort of error bar that you can compute from the x,y,... data of the
panel.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Mario 
> Aigner-Torres
> Sent: Wednesday, October 19, 2005 2:34 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] adding error bars to lattice plots
> 
> Dear R-Users,
> 
> how to include error bars within lattice?
> How should the panel = function(x,y,...){
> looks like?
> Does panel.arrows works here as well?
> 
> I appreciate any help on this.
> 
> Regards,
> 
> Mario AT
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Thu Oct 20 00:22:34 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Oct 2005 23:22:34 +0100 (BST)
Subject: [R] sqlQuery and string selection
In-Reply-To: <BAY103-DAV172CD27B221B63BB3C544690700@phx.gbl>
References: <BAY103-DAV172CD27B221B63BB3C544690700@phx.gbl>
Message-ID: <Pine.LNX.4.61.0510192314250.1880@gannet.stats>

The syntax error is that you have unescaped quotes inside quotes.
You also do not need a semicolon, nor to refer to columns in this
table.column form.  Try

'select sex from Micromammiferes where sex="females"'

(I suspect you do not need quotes, but keep forgetting the quirks of
various DBMSs.)

On Wed, 19 Oct 2005, J?r?me Lema?tre wrote:

> Dear alls,
>
> Could someone tell me how to select a subset of string observations (e.g.
> "females" in a sex column) with sqlQuery in the RODBC library?
>
> Indeed, I'm trying to select a subset of observations on my access database
> with:
>
> female<-sqlQuery(mychannel,"SELECT Micromammiferes.sex
> FROM Micromammiferes
> WHERE (((Micromammiferes.sex)="females"));")
>
> The sql works well in access but in R, I keep getting:
>
> Error: syntax error.
>
> Any help would be very appreciated,
>
> Thanks a lot
>
> J?r?me Lema?tre
> Ph.D. student
> D?partment of biology,
> University Laval
> Quebec, Canada
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Thu Oct 20 00:29:24 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Oct 2005 23:29:24 +0100 (BST)
Subject: [R] Weights in survReg
In-Reply-To: <0c0101c5d4a4$ac680370$86d301a3@stats.ox.ac.uk>
References: <0c0101c5d4a4$ac680370$86d301a3@stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.61.0510192323460.1880@gannet.stats>

Sasha,

This is R, which has survreg with weights (no caps).  You can find out for 
sure from the source code, but the help file says these are `observation 
weights'. I take that to mean weight=2 says `I have two cases like this' 
in forming the likelihood.  The C code says `case weights', the usual term 
for that meaning.


On Wed, 19 Oct 2005, Alexander Antonyuk wrote:

> Dear R users,
>
> I am trying to find out what the function survReg does exactly with the
> Weights parameters. I looked in Terry Therneau documentations and other
> places and couldn't find anything. I tried to make an analogy with weighted
> OLS and assumed that the scale parameter Sigma in the accelerated
> failure-time model log(Time)= X*betas +Sigma*E, is of the form Sigma(i) =
> Sigma/Weights(i).
>
> Can anyone confirm that or point me in the direction where I can find out
> for sure?
>
> Thank you,
> Sasha

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tchur at optushome.com.au  Thu Oct 20 00:46:11 2005
From: tchur at optushome.com.au (Tim Churches)
Date: Thu, 20 Oct 2005 08:46:11 +1000
Subject: [R] mid-p CIs for common odds ratio
Message-ID: <200510192246.j9JMkBdr009047@mail11.syd.optusnet.com.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051020/9624e10c/attachment.pl

From mtb954 at gmail.com  Thu Oct 20 01:50:03 2005
From: mtb954 at gmail.com (mtb954@gmail.com)
Date: Wed, 19 Oct 2005 17:50:03 -0600
Subject: [R] Plotting more than one series on the same graph
Message-ID: <e40d78ce0510191650x324323e9la49c6fa2707c03b9@mail.gmail.com>

I'm new to R and have searched for help and consulted the the pdf
manuals, but I can't seem to figure out how to plot more than one
series on the same graph.

I've tried using multiple par(new=TRUE) statements such as

>plot(series1, ci.type="line", col="red", lwd=2, ci.lty=0, ci.col="red")
>par(new=TRUE)
>plot(series2, ci.type="line", col="green", lwd=2, ci.lty=0, ci.col="green")
>par(new=TRUE)
>plot(series3, ci.type="line", col="blue", lwd=2, ci.lty=0, ci.col="blue")

and this does plot the three series on one graph, but makes a mess of
the y-axis.

There must be a more elegant solution.

Also, I wonder why the final series (series 3) doesn't plot until I
manually hit <enter>?

Thanks for any help, Mark



From sundar.dorai-raj at pdf.com  Thu Oct 20 02:00:31 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 19 Oct 2005 19:00:31 -0500
Subject: [R] Plotting more than one series on the same graph
In-Reply-To: <e40d78ce0510191650x324323e9la49c6fa2707c03b9@mail.gmail.com>
References: <e40d78ce0510191650x324323e9la49c6fa2707c03b9@mail.gmail.com>
Message-ID: <4356DE1F.4080500@pdf.com>



mtb954 at gmail.com wrote:
> I'm new to R and have searched for help and consulted the the pdf
> manuals, but I can't seem to figure out how to plot more than one
> series on the same graph.
> 
> I've tried using multiple par(new=TRUE) statements such as
> 
> 
>>plot(series1, ci.type="line", col="red", lwd=2, ci.lty=0, ci.col="red")
>>par(new=TRUE)
>>plot(series2, ci.type="line", col="green", lwd=2, ci.lty=0, ci.col="green")
>>par(new=TRUE)
>>plot(series3, ci.type="line", col="blue", lwd=2, ci.lty=0, ci.col="blue")
> 
> 
> and this does plot the three series on one graph, but makes a mess of
> the y-axis.
> 
> There must be a more elegant solution.
> 
> Also, I wonder why the final series (series 3) doesn't plot until I
> manually hit <enter>?
> 
> Thanks for any help, Mark
> 

Hi, Mark,

In general, see ?lines. However, your use of "ci.type" suggests you're 
using ?plot.acf, which may require you describe what you are trying to 
do in more detail.

Thanks,

--sundar



From aavram at mac.com  Thu Oct 20 02:09:08 2005
From: aavram at mac.com (Avram Aelony)
Date: Wed, 19 Oct 2005 17:09:08 -0700
Subject: [R] creating a derived variable in a data frame
Message-ID: <4319997.1129766948260.JavaMail.aavram@mac.com>

Hello,

I have read through the manuals and can't seem to find an answer.

I have a categorical, character variable that has hundreds of values.  I want to group the existing values of this variable into a new, derived (categorical) variable by applying conditions to the values in the data.

For example, suppose I have a data frame with variables: date, country, x, y, and z.  

x,y,z are numeric and country is a 2-digit character string.  I want to create a new derived variable named "continent" that would also exist in the data frame. The Continent variable would have values of "Asia", "Europe", "North America", etc...   

How would this best be done for a large dataset (>10MB) ?  
I have tried many variations on following without success (note in a real example I would have a longer list of countries and continent values):

> mydata$continent <- mydata[ mydata$country==list('US','CA','MX'), ] -> "North America"

I have read about factors, but I am not sure how they apply here.  

Can anyone help me with the syntax?  I am sure it is trivial and a common thing to do.
The ultimate goal is to compute percentages of x by continent.

Thanks for any help in advance.

-Avram



From je_lemaitre at hotmail.com  Thu Oct 20 02:58:25 2005
From: je_lemaitre at hotmail.com (=?iso-8859-1?B?Suly9G1lIExlbWHudHJl?=)
Date: Wed, 19 Oct 2005 20:58:25 -0400
Subject: [R] RE :  sqlQuery and string selection
In-Reply-To: <Pine.LNX.4.61.0510192314250.1880@gannet.stats>
Message-ID: <BAY103-DAV2277673F94AFF460C547590730@phx.gbl>

Dear Prof Ripley,

I tried what you suggested and it worked perfectly well! 
I also appreciated your corrections about my SQL formulation. However, it
seems that quotes are indeed needed to get string observations (but my
access software is in french...).
Finally, do you think that it might be worth to add an example for sqlQuery
using string variables in a later version of RODBC, just in case others
encounter the same problem as me?

I thank you very much for your help,


J??r??me Lema??tre
Ph.D. student
D??partment of biology,
University Laval
Quebec, Canada


-----Message d'origine-----
De??: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Envoy????: 19 octobre 2005 18:23
????: J??r??me Lema??tre
Cc??: R-help at stat.math.ethz.ch
Objet??: Re: [R] sqlQuery and string selection

The syntax error is that you have unescaped quotes inside quotes.
You also do not need a semicolon, nor to refer to columns in this
table.column form.  Try

'select sex from Micromammiferes where sex="females"'

(I suspect you do not need quotes, but keep forgetting the quirks of
various DBMSs.)

On Wed, 19 Oct 2005, J??r??me Lema??tre wrote:

> Dear alls,
>
> Could someone tell me how to select a subset of string observations (e.g.
> "females" in a sex column) with sqlQuery in the RODBC library?
>
> Indeed, I'm trying to select a subset of observations on my access
database
> with:
>
> female<-sqlQuery(mychannel,"SELECT Micromammiferes.sex
> FROM Micromammiferes
> WHERE (((Micromammiferes.sex)="females"));")
>
> The sql works well in access but in R, I keep getting:
>
> Error: syntax error.
>
> Any help would be very appreciated,
>
> Thanks a lot
>
> J??r??me Lema??tre
> Ph.D. student
> D??partment of biology,
> University Laval
> Quebec, Canada
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From 042045003 at fudan.edu.cn  Thu Oct 20 03:00:23 2005
From: 042045003 at fudan.edu.cn (ronggui)
Date: Thu, 20 Oct 2005 09:00:23 +0800
Subject: [R] creating a derived variable in a data frame
Message-ID: <0IOM00DXXVN4SM@mail.fudan.edu.cn>

I suggest you use the recode function in car package to do your job.
	

======= 2005-10-20 08:09:08 ÄúÔÚÀ´ÐÅÖÐÐ´µÀ£º=======

>Hello,
>
>I have read through the manuals and can't seem to find an answer.
>
>I have a categorical, character variable that has hundreds of values.  I want to group the existing values of this variable into a new, derived (categorical) variable by applying conditions to the values in the data.
>
>For example, suppose I have a data frame with variables: date, country, x, y, and z.  
>
>x,y,z are numeric and country is a 2-digit character string.  I want to create a new derived variable named "continent" that would also exist in the data frame. The Continent variable would have values of "Asia", "Europe", "North America", etc...   
>
>How would this best be done for a large dataset (>10MB) ?  
>I have tried many variations on following without success (note in a real example I would have a longer list of countries and continent values):
>
>> mydata$continent <- mydata[ mydata$country==list('US','CA','MX'), ] -> "North America"
>
>I have read about factors, but I am not sure how they apply here.  
>
>Can anyone help me with the syntax?  I am sure it is trivial and a common thing to do.
>The ultimate goal is to compute percentages of x by continent.
>
>Thanks for any help in advance.
>
>-Avram
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

= = = = = = = = = = = = = = = = = = = =
			


 

2005-10-20

------
Deparment of Sociology
Fudan University

My new mail addres is ronggui.huang at gmail.com
Blog:http://sociology.yculblog.com



From ripley at stats.ox.ac.uk  Thu Oct 20 08:26:31 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Oct 2005 07:26:31 +0100 (BST)
Subject: [R] RE :  sqlQuery and string selection
In-Reply-To: <BAY103-DAV2277673F94AFF460C547590730@phx.gbl>
References: <BAY103-DAV2277673F94AFF460C547590730@phx.gbl>
Message-ID: <Pine.LNX.4.61.0510200725590.7483@gannet.stats>

On Wed, 19 Oct 2005, J?r?me Lema?tre wrote:

> Dear Prof Ripley,
>
> I tried what you suggested and it worked perfectly well!
> I also appreciated your corrections about my SQL formulation. However, it
> seems that quotes are indeed needed to get string observations (but my
> access software is in french...).
> Finally, do you think that it might be worth to add an example for sqlQuery
> using string variables in a later version of RODBC, just in case others
> encounter the same problem as me?

No, such things are DBMS-specific.

>
> I thank you very much for your help,
>
>
> J?r?me Lema?tre
> Ph.D. student
> D?partment of biology,
> University Laval
> Quebec, Canada
>
>
> -----Message d'origine-----
> De?: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Envoy??: 19 octobre 2005 18:23
> ??: J?r?me Lema?tre
> Cc?: R-help at stat.math.ethz.ch
> Objet?: Re: [R] sqlQuery and string selection
>
> The syntax error is that you have unescaped quotes inside quotes.
> You also do not need a semicolon, nor to refer to columns in this
> table.column form.  Try
>
> 'select sex from Micromammiferes where sex="females"'
>
> (I suspect you do not need quotes, but keep forgetting the quirks of
> various DBMSs.)
>
> On Wed, 19 Oct 2005, J?r?me Lema?tre wrote:
>
>> Dear alls,
>>
>> Could someone tell me how to select a subset of string observations (e.g.
>> "females" in a sex column) with sqlQuery in the RODBC library?
>>
>> Indeed, I'm trying to select a subset of observations on my access
> database
>> with:
>>
>> female<-sqlQuery(mychannel,"SELECT Micromammiferes.sex
>> FROM Micromammiferes
>> WHERE (((Micromammiferes.sex)="females"));")
>>
>> The sql works well in access but in R, I keep getting:
>>
>> Error: syntax error.
>>
>> Any help would be very appreciated,
>>
>> Thanks a lot
>>
>> J?r?me Lema?tre
>> Ph.D. student
>> D?partment of biology,
>> University Laval
>> Quebec, Canada
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From tschoenhoff at gmail.com  Thu Oct 20 09:34:32 2005
From: tschoenhoff at gmail.com (=?ISO-8859-1?Q?Thomas_Sch=F6nhoff?=)
Date: Thu, 20 Oct 2005 09:34:32 +0200
Subject: [R] how to test poisson distribution
In-Reply-To: <200510191718.j9JHI2lM000133@hertz.gene.com>
References: <5ad2dec0510190959i3d048622i@mail.gmail.com>
	<200510191718.j9JHI2lM000133@hertz.gene.com>
Message-ID: <5ad2dec0510200034j245da050t@mail.gmail.com>

Hello Gunter,

2005/10/19, Berton Gunter <gunter.berton at gene.com>:
> To be pedantic (I'm feeling cranky today):
>
> One can never test "whether the data follow ["data" is plural] a Poisson
> distribution" -- only whether there is sufficient evidence to cast that
> assumption into doubt. Perhaps a better shorthand is "whether the data are
> consistent with Poisonness" . This correctly leaves open the possibility
> that the data are consistent with lots of other distribution-nesses, too.
> welcome alternatives, perhaps privately to reduce the list noise level.
>
> (And,yes, I'm sure that Thomas knows this perfectly well).

I'm agree with this. But, my understanding of this thread underlying
question was: "Where might I find some advice to deal with
distributions in R".

So I pointed to Vito Riccis paper on distribution fitting, which also
points to issues of testing/fitting distributions in a Newbie
accessible way, taking beginners to basics insights handling issues
like this in GNU R.

Well, that said I think pointing at sources like this might help
drecreasing, at least a bit of noise on this list.
 Lots of work and sweat have gone into creating such docs, so why not
use them? They're aiming at Newbies using R and offer at the same time
slight glances upon the topic itself.
 Well, I am relying on former dicussions on this topic on this list,
keyword "spoon feeding versus self-helping based on docs".
>
> I do think that we should be a bit less sloppy about such things even here,
> lest we continue to promulgate already widespread misunderstandings, even at
> the cost of slightly increased bandwidth. After all, precision is supposed
> to be a major concern or ours.

Yes, again you are correct here, slopyness isn't very helpful here! I
will take this more into account posting here next time!



sincerely

Thomas



From meinhard.ploner at soundinvest.net  Thu Oct 20 10:27:43 2005
From: meinhard.ploner at soundinvest.net (Meinhard Ploner)
Date: Thu, 20 Oct 2005 10:27:43 +0200
Subject: [R] strange behaviour of memory management
References: <6DC66EC7-1CF3-46A6-B860-38C33E14F279@gmx.net>
Message-ID: <8B05DED1-A7EE-4666-BD13-7751DD80F21C@soundinvest.net>

Hi all!
My system: R 2.1.1, Mac OS X 10.4.2.

I have a very memory-consuming job for R, consisting of a function  
calling some other functions, working often with matrices of size  
100.000 x 300. If I call the job directly after starting R the job  
takes overall 40min, however only 7min of process time. I assume the  
large difference is through memory-handling which doesn't count as  
process time. If i start the job after I make some shorter runs, some  
programming, then the job stops by reaching a memory limit. It seems  
that R doesn't release all the memory even if it don't adds global  
objects.

Further I'm interesited if for a UNIX-derivate like Mac OS X gc() or  
rm(localObjects) (used in local functions) make any difference/ 
advantage??

Best
Meinhard Ploner
Erste Bank



From m.ballardini at ior-forli.it  Thu Oct 20 10:40:27 2005
From: m.ballardini at ior-forli.it (Michela Ballardini)
Date: Thu, 20 Oct 2005 10:40:27 +0200
Subject: [R] forrest plot
References: <000a01c5d495$251ab4d0$0200a8c0@Michela>
	<5ad2dec0510190456r2b1eb12s@mail.gmail.com>
Message-ID: <000301c5d551$ec934970$0200a8c0@Michela>

Excuse me, but I can't use your commands because I have R 2.2.0 and I 
haven't rmeta package.

I don't try rmeta in R 2.2.0, can you tell me how can I do?

Thank you
Michela



----- Original Message ----- 
From: "Thomas Sch??nhoff" <tschoenhoff at gmail.com>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, October 19, 2005 1:56 PM
Subject: Re: [R] forrest plot


> Hello,
>
> 2005/10/19, Michela Ballardini <m.ballardini at ior-forli.it>:
>> Hi,
>>
>> can you tel me how can I make a Forrest Plot with R?
>> It is possible and easy or are there a more practical free software 
>> available?
>
> Maybe this will help you to find an answer:
>
> http://finzi.psych.upenn.edu/R/library/rmeta/html/metaplot.html
>
>
> regards
> Thomas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Thu Oct 20 10:51:46 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Oct 2005 09:51:46 +0100 (BST)
Subject: [R] strange behaviour of memory management
In-Reply-To: <8B05DED1-A7EE-4666-BD13-7751DD80F21C@soundinvest.net>
References: <6DC66EC7-1CF3-46A6-B860-38C33E14F279@gmx.net>
	<8B05DED1-A7EE-4666-BD13-7751DD80F21C@soundinvest.net>
Message-ID: <Pine.LNX.4.61.0510200941570.8831@gannet.stats>

On Thu, 20 Oct 2005, Meinhard Ploner wrote:

> Hi all!
> My system: R 2.1.1, Mac OS X 10.4.2.
>
> I have a very memory-consuming job for R, consisting of a function
> calling some other functions, working often with matrices of size
> 100.000 x 300. If I call the job directly after starting R the job
> takes overall 40min, however only 7min of process time. I assume the
> large difference is through memory-handling which doesn't count as
> process time. If i start the job after I make some shorter runs, some
> programming, then the job stops by reaching a memory limit. It seems
> that R doesn't release all the memory even if it don't adds global
> objects.

What is the message?  Most often this happens not because memory is not 
available but because contiguous memory is not available.  You have only 
3Gb (or less) of process address space, and that can get fragmented enough 
not to find holes for objects of about 240Mb each (assuming numerical 
matrices).

> Further I'm interesited if for a UNIX-derivate like Mac OS X gc() or
> rm(localObjects) (used in local functions) make any difference/
> advantage??

gc() unlikely (R has probably already tried that, but we haven't seen the 
message).  rm(localObjects): yes it can help, even for small objects.

If my guess is right, the real answer is a 64-bit OS.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From m.ballardini at ior-forli.it  Thu Oct 20 10:52:46 2005
From: m.ballardini at ior-forli.it (Michela Ballardini)
Date: Thu, 20 Oct 2005 10:52:46 +0200
Subject: [R] forrest plot
Message-ID: <000601c5d553$a4e52650$0200a8c0@Michela>

I just resolve the problem.

Thank you and sorry

Mic



----- Original Message ----- 
From: "Michela Ballardini" <m.ballardini at ior-forli.it>
To: "Thomas Sch??nhoff" <tschoenhoff at gmail.com>; <r-help at stat.math.ethz.ch>
Sent: Thursday, October 20, 2005 10:40 AM
Subject: Re: [R] forrest plot


> Excuse me, but I can't use your commands because I have R 2.2.0 and I 
> haven't rmeta package.
>
> I don't try rmeta in R 2.2.0, can you tell me how can I do?
>
> Thank you
> Michela
>
>
>
> ----- Original Message ----- 
> From: "Thomas Sch??nhoff" <tschoenhoff at gmail.com>
> To: <r-help at stat.math.ethz.ch>
> Sent: Wednesday, October 19, 2005 1:56 PM
> Subject: Re: [R] forrest plot
>
>
>> Hello,
>>
>> 2005/10/19, Michela Ballardini <m.ballardini at ior-forli.it>:
>>> Hi,
>>>
>>> can you tel me how can I make a Forrest Plot with R?
>>> It is possible and easy or are there a more practical free software 
>>> available?
>>
>> Maybe this will help you to find an answer:
>>
>> http://finzi.psych.upenn.edu/R/library/rmeta/html/metaplot.html
>>
>>
>> regards
>> Thomas
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>



From petr.pikal at precheza.cz  Thu Oct 20 11:07:38 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 20 Oct 2005 11:07:38 +0200
Subject: [R] forrest plot
In-Reply-To: <000301c5d551$ec934970$0200a8c0@Michela>
Message-ID: <43577A7A.11235.54FB0FE@localhost>

Hi

As far as I can see rmeta package is available for download via 
CRAN. So what you have to do is download a package, install it 
to appropriate directory and make it available by library(rmeta).

And maybe you find useful also download "An introduction to R" 
or other basic documentation and read it.

HTH
Petr


On 20 Oct 2005 at 10:40, Michela Ballardini wrote:

From:           	"Michela Ballardini" <m.ballardini at ior-forli.it>
To:             	Thomas Sch??nhoff <tschoenhoff at gmail.com>,
	<r-help at stat.math.ethz.ch>
Date sent:      	Thu, 20 Oct 2005 10:40:27 +0200
Subject:        	Re: [R] forrest plot

> Excuse me, but I can't use your commands because I have R 2.2.0 and I
> haven't rmeta package.
> 
> I don't try rmeta in R 2.2.0, can you tell me how can I do?
> 
> Thank you
> Michela
> 
> 
> 
> ----- Original Message ----- 
> From: "Thomas Sch??nhoff" <tschoenhoff at gmail.com>
> To: <r-help at stat.math.ethz.ch>
> Sent: Wednesday, October 19, 2005 1:56 PM
> Subject: Re: [R] forrest plot
> 
> 
> > Hello,
> >
> > 2005/10/19, Michela Ballardini <m.ballardini at ior-forli.it>:
> >> Hi,
> >>
> >> can you tel me how can I make a Forrest Plot with R?
> >> It is possible and easy or are there a more practical free software
> >> available?
> >
> > Maybe this will help you to find an answer:
> >
> > http://finzi.psych.upenn.edu/R/library/rmeta/html/metaplot.html
> >
> >
> > regards
> > Thomas
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From vdooren at rulsfb.leidenuniv.nl  Thu Oct 20 11:25:51 2005
From: vdooren at rulsfb.leidenuniv.nl (Tom Van Dooren)
Date: Thu, 20 Oct 2005 11:25:51 +0200
Subject: [R] different F test in drop1 and anova
Message-ID: <4357629F.3070104@rulsfb.leidenuniv.nl>

Hi,
I was wondering why anova() and drop1() give different tail 
probabilities for F tests.
I guess overdispersion is calculated differently in the following 
example, but why?
Thanks for any advice,
Tom

For example:

 > x<-c(2,3,4,5,6)
 > y<-c(0,1,0,0,1)
 > b1<-glm(y~x,binomial)
 > b2<-glm(y~1,binomial)
 > drop1(b1,test="F")
Single term deletions

Model:
y ~ x
       Df Deviance     AIC F value  Pr(F)
<none>      6.3024 10.3024              
x       1   6.7301  8.7301  0.2036 0.6824
Warning message:
F test assumes quasibinomial family in: drop1.glm(b1, test = "F")
 > anova(b2,b1,test="F")
Analysis of Deviance Table

Model 1: y ~ 1
Model 2: y ~ x
  Resid. Df Resid. Dev Df Deviance      F Pr(>F)
1         4     6.7301                         
2         3     6.3024  1   0.4277 0.4277 0.5131
 >



From r.hankin at noc.soton.ac.uk  Thu Oct 20 11:39:15 2005
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Thu, 20 Oct 2005 10:39:15 +0100
Subject: [R] partial match gotcha
Message-ID: <9AD1C9DF-99D8-42B6-8886-67E37E599529@soc.soton.ac.uk>

Hi

The following gotcha took me a long time to catch:

f <- function(x, main0="red", ...){
   par(col.axis=main0)
   plot(x,...)
}

f(1:10,main="title here")
f(1:10,main="title here",main0="blue")


I can't quite succinctly summarize why the second case works but the  
first one
doesn't.




--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From vito_ricci at yahoo.com  Thu Oct 20 12:13:50 2005
From: vito_ricci at yahoo.com (Vito Ricci)
Date: Thu, 20 Oct 2005 12:13:50 +0200 (CEST)
Subject: [R] Help needed with ks.test
Message-ID: <20051020101350.97636.qmail@web36102.mail.mud.yahoo.com>

Ciao Emanuele,

you could give a look to this contribute on fitting
distributions with R, maybe it could be helpful to
you:

http://cran.r-project.org/doc/contrib/Ricci-distributions-it.pdf

Regards,

Vito


Emanuele Mazzola  wrote

Hello to everybody,

I'd like to submit a problem I'm dealing with, and I
can't get an answer to 
by myself.
I have to test if my data come from a specific
probability distribution, of 
which I know the analytic form both of the p.d.f. and
the c.d.f.
Namely, it is the hypoexponential distribution, sum of
two exponentials with 
different parameters.
Is there any way I can manage the task with ks.test?
It's not straightforward to compute the inverse of the
c.d.f in order to 
simulate data from that distribution...

Thank you very much in advance for your kind answers!
See you
EM


Diventare costruttori di soluzioni
Became solutions' constructors

"The business of the statistician is to catalyze 
the scientific learning process."  
George E. P. Box

"Statistical thinking will one day be as necessary for efficient citizenship as the ability to read and write"
H. G. Wells

Top 10 reasons to become a Statistician

     1. Deviation is considered normal
     2. We feel complete and sufficient
     3. We are 'mean' lovers
     4. Statisticians do it discretely and continuously
     5. We are right 95% of the time
     6. We can legally comment on someone's posterior distribution
     7. We may not be normal, but we are transformable
     8. We never have to say we are certain
     9. We are honestly significantly different
    10. No one wants our jobs


Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese  http://www.modugno.it/archivio/palesesanto_spirito/



From andreas.zankl at gmail.com  Thu Oct 20 12:36:03 2005
From: andreas.zankl at gmail.com (Andreas Zankl)
Date: Thu, 20 Oct 2005 12:36:03 +0200
Subject: [R] how to set environment variables?
Message-ID: <a06230903bf7d22411b07@[155.105.162.16]>

The help file of the R bitmap function says that I have to set the 
environment variable R_GSCMD to the path of my Ghostscript 
installation. How do I set this variable (either by commandline or in 
R.app for Mac)? Sorry if this sounds like a very basic question, but 
I could not find the answer anywhere else.

Many thanks
Andreas

-- 

--------------------------
Andreas Zankl, MD
Division of Molecular Pediatrics
Clinique Infantile 02/50
CHUV
Avenue Pierre Decker 2
CH-1011 Lausanne
Switzerland
Phone: +41-21-3143778
Fax: +41-21-3143546
Email: andreas.zankl at gmail.com



From m.ballardini at ior-forli.it  Thu Oct 20 12:39:12 2005
From: m.ballardini at ior-forli.it (Michela Ballardini)
Date: Thu, 20 Oct 2005 12:39:12 +0200
Subject: [R] forrest plot
Message-ID: <000801c5d562$84816130$0200a8c0@Michela>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051020/b3391e41/attachment.pl

From david.meyer at wu-wien.ac.at  Thu Oct 20 09:29:45 2005
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Thu, 20 Oct 2005 09:29:45 +0200
Subject: [R] [R-pkgs] vcd package 0.9-5 released
Message-ID: <20051020092945.7ba1dc7a.david.meyer@wu-wien.ac.at>


Dear useRs,

a new version of the vcd package (0.9-5) is now available from CRAN.

Apart from (a lot of) bug fixes, it includes the following new features
(some of them have 'silently' been included in previous bug fix
releases):

* Improved documentation:

  - an introductory vignette on the strucplot framework (including
    mosaic, association and sieve plots)
  - special vignettes on using/extending shading and labeling functions

* New function spine() for spinograms and spine plots

* New function cd_plot() for conditional density plots 

* New function cotabplot() for visualizing conditional independence in a
  trellis-like layout, providing panel functions for association,
  mosaic, and sieve plots

* Sieve plots are now integrated in the strucplot framework, sieve()
  replaces sieveplot()

* Extended support for 'structable' objects (textual representation of
  mosaic plots):

  - structable objects can be used as input for mosaic(), sieve(), and
    assoc()
  - extract ("[") and replacement ("[<-") functions are available (old
    "[[" method removed)
  - methods for t(), dim(), as.matrix(), as.vector(), as.table(), etc.
    are available

* New panel function pairs_diagonal_text() for pairs()

* The alternative legend function legend_fixed() now looks more similar
  to the legend of mosaicplot() in base R

Comments are more then welcome!

David, Achim, Kurt.

PS: If you like modern art, try out demo(mondrian)! :)


-- 
Dr. David Meyer
Department of Information Systems and Operations

Vienna University of Economics and Business Administration
Augasse 2-6, A-1090 Wien, Austria, Europe
Fax: +43-1-313 36x746 
Tel: +43-1-313 36x4393
HP:  http://wi.wu-wien.ac.at/~meyer/

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From naomi at isoft.fr  Thu Oct 20 13:14:05 2005
From: naomi at isoft.fr (Naomi Berdugo)
Date: Thu, 20 Oct 2005 13:14:05 +0200
Subject: [R] information about Loess
Message-ID: <832674AC670E49478BDE1CA8CADC0EE61FC5A8@wserver.isoft.fr>

Hello,

I'm currently using a tool that provides a Loess fitting, but I obtained results that are slightly different from those provided by R implementation of the Loess. That's why I would like to know if you could give me a source (bibliography or web) that explains in a clear way each step of the algorithm, with the possible options to choose, etc.. in order for me to understand those differences.

Thank you,

Naomi Berdugo.



From 042045003 at fudan.edu.cn  Thu Oct 20 13:19:54 2005
From: 042045003 at fudan.edu.cn (ronggui)
Date: Thu, 20 Oct 2005 19:19:54 +0800
Subject: [R] information about Loess
Message-ID: <0ION00817OBQPH@mail.fudan.edu.cn>

?loess


	
References
W.S. Cleveland, E. Grosse and W.M. Shyu (1992) Local regression models. Chapter 8 of Statistical Models in S eds J.M. Chambers and T.J. Hastie, Wadsworth & Brooks/Cole.


======= 2005-10-20 19:14:05 ÄúÔÚÀ´ÐÅÖÐÐ´µÀ£º=======

>Hello,
>
>I'm currently using a tool that provides a Loess fitting, but I obtained results that are slightly different from those provided by R implementation of the Loess. That's why I would like to know if you could give me a source (bibliography or web) that explains in a clear way each step of the algorithm, with the possible options to choose, etc.. in order for me to understand those differences.
>
>Thank you,
>
>Naomi Berdugo.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

= = = = = = = = = = = = = = = = = = = =
			


 

2005-10-20

------
Deparment of Sociology
Fudan University

My new mail addres is ronggui.huang at gmail.com
Blog:http://sociology.yculblog.com



From ripley at stats.ox.ac.uk  Thu Oct 20 13:31:11 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Oct 2005 12:31:11 +0100 (BST)
Subject: [R] different F test in drop1 and anova
In-Reply-To: <4357629F.3070104@rulsfb.leidenuniv.nl>
References: <4357629F.3070104@rulsfb.leidenuniv.nl>
Message-ID: <Pine.LNX.4.61.0510201227160.10800@gannet.stats>

On Thu, 20 Oct 2005, Tom Van Dooren wrote:

> Hi,
> I was wondering why anova() and drop1() give different tail
> probabilities for F tests.
> I guess overdispersion is calculated differently in the following
> example, but why?

Because of the warning.  You are using both inappropriately.

drop1.glm guesses you meant quasibinomial and tells you.

anova.glm guesses you mean the Chisq test (F with infinite denominator df)
and does not tell you.


> Thanks for any advice,
> Tom
>
> For example:
>
> > x<-c(2,3,4,5,6)
> > y<-c(0,1,0,0,1)
> > b1<-glm(y~x,binomial)
> > b2<-glm(y~1,binomial)
> > drop1(b1,test="F")
> Single term deletions
>
> Model:
> y ~ x
>       Df Deviance     AIC F value  Pr(F)
> <none>      6.3024 10.3024
> x       1   6.7301  8.7301  0.2036 0.6824
> Warning message:
> F test assumes quasibinomial family in: drop1.glm(b1, test = "F")
> > anova(b2,b1,test="F")
> Analysis of Deviance Table
>
> Model 1: y ~ 1
> Model 2: y ~ x
>  Resid. Df Resid. Dev Df Deviance      F Pr(>F)
> 1         4     6.7301
> 2         3     6.3024  1   0.4277 0.4277 0.5131
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Oct 20 13:40:31 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Oct 2005 12:40:31 +0100 (BST)
Subject: [R] partial match gotcha
In-Reply-To: <9AD1C9DF-99D8-42B6-8886-67E37E599529@soc.soton.ac.uk>
References: <9AD1C9DF-99D8-42B6-8886-67E37E599529@soc.soton.ac.uk>
Message-ID: <Pine.LNX.4.61.0510201234161.10800@gannet.stats>

On Thu, 20 Oct 2005, Robin Hankin wrote:

> Hi
>
> The following gotcha took me a long time to catch:
>
> f <- function(x, main0="red", ...){
>   par(col.axis=main0)
>   plot(x,...)
> }
>
> f(1:10,main="title here")
> f(1:10,main="title here",main0="blue")
>
>
> I can't quite succinctly summarize why the second case works but the
> first one
> doesn't.


You need to write

f <- function(x, ..., main0="red"){
   par(col.axis=main0)
   plot(x,...)
}

See e.g. S Programming p.40 or the Draft R Language Definition (section 
'Argument matching').  Yes, it is a trap for the unwary, which is why 
knowing the exact rules is important.

Inserting print(match.call()) can help: in your first case it gives
f(x = 1:10, main0 = "title here")

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From berwin at maths.uwa.edu.au  Thu Oct 20 13:49:35 2005
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Thu, 20 Oct 2005 19:49:35 +0800
Subject: [R] Optim with two constraints
In-Reply-To: <67be2ce30510191347y1e40754fv14f56aaa1f09328a@mail.gmail.com>
References: <200510191751.j9JHpuiY001621@us17.unix.fas.harvard.edu>
	<67be2ce30510191347y1e40754fv14f56aaa1f09328a@mail.gmail.com>
Message-ID: <17239.33871.692803.898092@bossiaea.maths.uwa.edu.au>

>>>>> "AD" == Alexis Diamond <alexisjdiamond at gmail.com> writes:

    AD> I have a follow-up from Jens's question and Professor Ripley's
    AD> response.

    AD> Jens wants to do quadratic optimization with 2 constraints:

    >> > > # I need two constraints:
    >> > > # 1. each element in par needs to be between 0 and 1
    >> > > # 2. sum(par)=1, i.e. the elements in par need to sum to 1

    AD> how does one set both constraints in quadprog, per
    AD> Prof. Ripley's suggestion?  i know how to get quadprog to
    AD> handle the second constraint,
The first is actually not one constraint but 2*k constraints, where k
is the number of elements in "par".  But there is quite some
redundancy in this set of equation.  It suffices to constrain each
element to be bigger or equal to 0 and that they should sum to 1.  If
these constraints are fulfilled, then each element must be less or
equal to one.

    AD> but not BOTH, since quadprog only takes as inputs the
    AD> constraint matrix "A" and constraint vector "b"--
So what stops you from coding the k constraints from 1.) in the form
that quadprog requires them?  From memory, i.e. untested:

m <- length(par)
Amat <- cbind(rep(1,m), diag(m))
bvec <- c(1,rep(0,m))
meq <- 1

solve.QP(Dmat, dvec, Amat, bvec, meq)

    AD> unlike in "ipop" (kernlab), there is no additional option for
    AD> box constraints.
Well, the problems that I had (and still have) usually don't involve
box constraints, but I see that other people use them again and again.
So probably it would be a good idea to implement them...  But, more
importantly, would be to implement Powell's modifications of the
Goldfarb-Idnani algorithm to make it numerically more robust...  Oh,
yeah, and a warm start option from a feasible point would be nice
too....  Probably all in a future version which should be released
sometime before Xmas 20xx. :)

    AD> apologies if i am not seeing something obvious here.
Apologies accepted. :)

Cheers,

        Berwin



From ripley at stats.ox.ac.uk  Thu Oct 20 13:51:24 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Oct 2005 12:51:24 +0100 (BST)
Subject: [R] how to set environment variables?
In-Reply-To: <a06230903bf7d22411b07@[155.105.162.16]>
References: <a06230903bf7d22411b07@[155.105.162.16]>
Message-ID: <Pine.LNX.4.61.0510201241000.10800@gannet.stats>

On Thu, 20 Oct 2005, Andreas Zankl wrote:

> The help file of the R bitmap function says that I have to set the
> environment variable R_GSCMD to the path of my Ghostscript
> installation.

Actually, it does not say that.  It says you _can_ specify the path to 
your executable (not the installation) that way. It will work without 
doing so if the executable 'gs' (on a Unix-alike) is on your path, which 
it normally is on Unix-alikes.

> How do I set this variable (either by commandline or in
> R.app for Mac)? Sorry if this sounds like a very basic question, but
> I could not find the answer anywhere else.

?Sys.putenv for how to do it from R.  help.search("environment variable") 
got me there.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Gary.Nelson at state.ma.us  Thu Oct 20 14:27:34 2005
From: Gary.Nelson at state.ma.us (Nelson, Gary (FWE))
Date: Thu, 20 Oct 2005 08:27:34 -0400
Subject: [R] Automatic rounding of values after factors ,
	converted to numeric, are multipled by a real number
Message-ID: <74BDE31AFD6EC54DB026E6CD11FF0A7E96519A@ES-MSG-008.es.govt.state.ma.us>

Peter,

Thank you for your response. I knew how close the values are to integers, but I still don't understand why I don't  have control over how the numbers are displayed (rounded or not)?

Thanks again,

Gary Nelson.

-----Original Message-----
From: pd at pubhealth.ku.dk [mailto:pd at pubhealth.ku.dk] On Behalf Of Peter Dalgaard
Sent: Wednesday, October 19, 2005 3:45 PM
To: Nelson, Gary (FWE)
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Automatic rounding of values after factors , converted to numeric, are multipled by a real number


"Nelson, Gary (FWE)" <Gary.Nelson at state.ma.us> writes:

> I am wondering if someone would have any suggestion about my issue?
> 
> 
> I have the following code:
> 
> wgts<-aggregate(subset(lendata,select=c(Length)),list(lendata$Cruise,l
> en
> data$Station,lendata$Region,lendata$Total),mean)
> wgts<-wgts[order(wgts$Group.3,wgts$Group.1,wgts$Group.1),]
> names(wgts)<-c("Cruise","Station","Region","Total","MLen")
> wgts$Total<-as.numeric(levels(wgts$Total))[wgts$Total]
> wgts$swmean<-with(wgts,wgts$Total*wgts$MLen) 
> 
> When I run it, I get:
>    Cruise Station Region Total     MLen swmean
> 3    2350     256      1     2 70.50000    141
> 5    2350     254      1     3 73.33333    220
> 6    2350     287      1     3 65.66667    197
> 9    2350     232      1     4 75.25000    301
> 10   2350     294      1     4 56.00000    224
> 12   2350     301      1     5 70.20000    351
> 14   2350     316      1     6 67.33333    404
> 15   2350     255      1     7 55.00000    385
> 17   2350     285      1     8 73.50000    588
> 19   2350     212      1    10 57.50000    575
> 20   2350     250      1    10 61.50000    615
> 27   2350     221      1    24 95.29167   2287
> 33   2350     229      1    35 55.62857   1947
> 37   2350     293      1    47 53.82979   2530
> 38   2350     203      1    50 55.54000   2777
> 39   2350     248      1    55 63.30909   3482
> 41   2350     246      1    63 95.82540   6037
> 42   2350     265      1    68 55.54412   3777
> 43   2350     251      1    82 62.60976   5134
> 44   2350     234      1    85 57.21176   4863
> 
> Every value is correct except that the "swmean"s are rounded and I 
> can't get values with the decimals fractions.  I have tried as.double 
> and have change the options(digits=7), but nothing seems to work. I 
> have spent several hours combing manuals and archives.

as far as I can see, the issue is that Total*MLen just *are* pretty close to being integers, e.g.

> 4863/85
[1] 57.21176

> z <- x$Total*x$MLen
> z - round(z)
 [1]  0.00000 -0.00001  0.00001  0.00000  0.00000  0.00000 -0.00002  0.00000  [9]  0.00000  0.00000  0.00000  0.00008 -0.00005  0.00013  0.00000 -0.00005 [17]  0.00020  0.00016  0.00032 -0.00040

 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From Maia.Berman at cebc.cnrs.fr  Thu Oct 20 15:00:46 2005
From: Maia.Berman at cebc.cnrs.fr (=?ISO-8859-1?Q?Ma=EFa_Berman?=)
Date: Thu, 20 Oct 2005 15:00:46 +0200
Subject: [R] =?iso-8859-1?q?probl=E8me_d=27import_de_fichier?=
Message-ID: <435794FE.7030809@cebc.cnrs.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051020/83b0dcc0/attachment.pl

From Maia.Berman at cebc.cnrs.fr  Thu Oct 20 15:03:19 2005
From: Maia.Berman at cebc.cnrs.fr (=?ISO-8859-1?Q?Ma=EFa_Berman?=)
Date: Thu, 20 Oct 2005 15:03:19 +0200
Subject: [R] =?iso-8859-1?q?probl=E8me_d=27import_de_fichier?=
Message-ID: <43579597.5070508@cebc.cnrs.fr>


   hello!
   je  veux  importer  un  fichier de donnees excel que j'ai au prealable
   converti  en  fichier  txt  avec  separateurs tab, fichier de la forme
   entree simple (suite de colonnes contenant des variables).
   Voila ma ligne de commande :
   > poussins <- read.table("poussins.txt", header=T, sep="\t")
   et sa reponse
   Erreur  dans  scan(file = file, what = what, sep = sep, quote = quote,
   dec = dec,  :
           la ligne 15 n'avait pas 14 éléments
   De plus : Message d'avis :
   readTableHeader   a   trouvé   une   ligne   finale   incomplète  dans
   'poussins.txt'
   A l'aide!!!!
   merci


From andreas.zankl at gmail.com  Thu Oct 20 15:07:17 2005
From: andreas.zankl at gmail.com (Andreas Zankl)
Date: Thu, 20 Oct 2005 15:07:17 +0200
Subject: [R] how to set environment variables?
In-Reply-To: <Pine.LNX.4.61.0510201241000.10800@gannet.stats>
References: <a06230903bf7d22411b07@[155.105.162.16]>
	<Pine.LNX.4.61.0510201241000.10800@gannet.stats>
Message-ID: <a06230908bf7d44d535b8@[155.105.162.16]>

Thanks. Sys.putenv did work, however this has to be set every time I start R.

gs is on my path and works fine under Unix, but I get the following 
error when running bitmap (without setting R_GSCMD first):

/bin/sh: line 1: gs: command not found

I assume the problem is related to the fact that I am using the csh 
shell, while the new Mac OS X default shell is now bash. So I guess 
my .csh path settings are ignored by R calling bash. I solved the 
problem by adding my R_GSCMD settings to the Renviron file 
(R_GSCMD=${RGSCMD-'/sw/bin/gs'} in my case). Hope this helps anyone 
with the same problem.

Thanks again for your help!
Andreas



At 12:51 +0100 20.10.2005, Prof Brian Ripley wrote:
>On Thu, 20 Oct 2005, Andreas Zankl wrote:
>
>>The help file of the R bitmap function says that I have to set the
>>environment variable R_GSCMD to the path of my Ghostscript
>>installation.
>
>Actually, it does not say that.  It says you _can_ specify the path 
>to your executable (not the installation) that way. It will work 
>without doing so if the executable 'gs' (on a Unix-alike) is on your 
>path, which it normally is on Unix-alikes.
>
>>How do I set this variable (either by commandline or in
>>R.app for Mac)? Sorry if this sounds like a very basic question, but
>>I could not find the answer anywhere else.
>
>?Sys.putenv for how to do it from R.  help.search("environment 
>variable") got me there.
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595


-- 
PLEASE NOTE MY NEW EMAIL ADDRESS: ANDREAS.ZANKL at GMAIL.COM

--------------------------
Andreas Zankl, MD
Division of Molecular Pediatrics
Clinique Infantile 02/50
CHUV
Avenue Pierre Decker 2
CH-1011 Lausanne
Switzerland
Phone: +41-21-3143778
Fax: +41-21-3143546
Email: andreas.zankl at gmail.com



From Luisr at frs.fo  Thu Oct 20 15:23:48 2005
From: Luisr at frs.fo (Luis Ridao Cruz)
Date: Thu, 20 Oct 2005 14:23:48 +0100
Subject: [R] String manipulation
Message-ID: <s357a879.072@ffdata.setur.fo>

R-help,

I have a data frame which contains a character string column that is
something like;

II11
II18
II23
III1
III13
III16
III19
III2
III7
IV10
IV11
IV12
IX16
IX4
V12
V18
V2
V20
V23
V4
VII14
VII18
VII21
VII26
VII28
VII33
VII4
VII48
VII5
....
....
....

I want to apply a function (e.g mean) by grouping according to the
roman part of the string, i.e,

by I
by V
by VII
...
...
and so on.

I have looked at string manipulation functions (grep, pmatch,,,) but I
can't really get it the way I want.
Can anyone help?

Thanks in advance.



From mbock at Environcorp.com  Thu Oct 20 15:44:49 2005
From: mbock at Environcorp.com (Mike Bock)
Date: Thu, 20 Oct 2005 08:44:49 -0500
Subject: [R] Range plots (lattice or base?)
Message-ID: <AA564451B2A8A147B653D20C3E481D62D54560@emloop02.environchicago.environ.local>

I have gotten what I want by following Deepayan's advice. I have written
the following replacement for boxplot.stats. When I run bwplot, I get
exactly what I want. This function is lacking sufficient error checking
but here it is. The bootstrapping makes it a bit slow. What I would like
to do is write a new function (ciplot) that stores the original
boxplot.stats fucntion, replaces it with my new stats function, calls
bwplot, and then return boxplot.stats to its original.


boxplot.stats <-function (x,coef = 1.5, do.conf=TRUE, do.out=TRUE) {
Mean <- mean(x,na.rm = TRUE)
Sd <- sd(x,na.rm = TRUE)
lp <- (quantile(x,0.10, na.rm = TRUE)[[1]])
up <- (quantile(x,0.90, na.rm = TRUE) [[1]])
sizen <- sum(!is.na(x))
lci <- 0
uci <- 0
if (sizen > 5)
 {CI <- try((boot.ci(boot(x, function(x,i) mean(x[i]), R = 5000)
           ,conf = c(0.95),
           type = c("norm")))$normal[-1])
 lci <- CI[1]
 uci <- CI[2]}
lconf <- 0
uconf <- 0
stats <- c(lp,lci,Mean,uci,up)
n<-sizen
conf <-c(lconf,uconf)
result <- list(stats = stats,n=n,conf=conf,out = NA)
return(result)
}




> -----Original Message-----
> From: Deepayan Sarkar [mailto:deepayan.sarkar at gmail.com] 
> Sent: Wednesday, October 19, 2005 3:34 PM
> To: Mike Bock
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: Range plots (lattice or base?)
> 
> 
> 
> 
> On 10/19/05, Mike Bock <mbock at environcorp.com> wrote:
> > I am looking to create what I would call a "simple 
> variation" on the 
> > boxplot. What I would like to do is to be able to plot the 
> upper and 
> > lower confidence limits as the "box" and the 10th and 90th 
> percentile 
> > as the whiskers. What I have done is write the code to create a 
> > dataframe, the columns of which are the mean, sd, 10th percentile, 
> > 90th percentile, lower confidence limit of the mean, and upper 
> > confidence limit of the mean, the rows are the groups. I 
> have exported 
> > this to excel and get the graph I want by using the stock graphs in 
> > excel that plot open, close, high and low but I would much 
> prefer to 
> > do this in R for reason too numerous to enumerate.
> > 
> > I have looked high and low and even took a brief look at the bwplot 
> > code in the lattice package.  Given my experience level it 
> would take 
> > quite a while for me to modify the bwplot code to get what 
> I want and 
> > create a new graph type, assuming I could get it to work at 
> all. Does 
> > anyone know of an easier way to get what I want, with and example? 
> > Lattice, grid, base, whatever, I don't especially care what tools I 
> > need to use. My only constrante is that I feed it the 
> values required 
> > as a dataframe rather than calculate it on the fly so if we 
> change our 
> > minds about UCL method or percentiles there is no problem.
> 
> Is your UCL method guaranteed to work separately on groups 
> (e.g. if the s.d. is estimated per group) or does it share 
> information across groups (e.g. some sort of pooled estimate 
> of s.d.)? In the former case, you could try writing a 
> replacement for boxplot.stats and use that in panel.bwplot.
> 
> Deepayan
>



From dimitris.rizopoulos at med.kuleuven.be  Thu Oct 20 15:56:42 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Thu, 20 Oct 2005 15:56:42 +0200
Subject: [R] String manipulation
References: <s357a879.072@ffdata.setur.fo>
Message-ID: <009201c5d57e$19cbcf30$0540210a@www.domain>

you could use "gsub()", i.e.,

strg <- c("II11", "II18", "II23", "III1", "III13", "III16", "III19", 
"III2", "III7", "IV10", "IV11", "IV12")
#########
x <- as.numeric(gsub("[^0-9]", "", strg))
y <- gsub("[0-9]", "", strg)
tapply(x, y, mean)


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Luis Ridao Cruz" <Luisr at frs.fo>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, October 20, 2005 3:23 PM
Subject: [R] String manipulation


> R-help,
>
> I have a data frame which contains a character string column that is
> something like;
>
> II11
> II18
> II23
> III1
> III13
> III16
> III19
> III2
> III7
> IV10
> IV11
> IV12
> IX16
> IX4
> V12
> V18
> V2
> V20
> V23
> V4
> VII14
> VII18
> VII21
> VII26
> VII28
> VII33
> VII4
> VII48
> VII5
> ....
> ....
> ....
>
> I want to apply a function (e.g mean) by grouping according to the
> roman part of the string, i.e,
>
> by I
> by V
> by VII
> ...
> ...
> and so on.
>
> I have looked at string manipulation functions (grep, pmatch,,,) but 
> I
> can't really get it the way I want.
> Can anyone help?
>
> Thanks in advance.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From jfox at mcmaster.ca  Thu Oct 20 15:54:28 2005
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 20 Oct 2005 09:54:28 -0400
Subject: [R] String manipulation
In-Reply-To: <s357a879.072@ffdata.setur.fo>
Message-ID: <20051020135427.CYWA26550.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Luis,

How about gsub("[0-9]", "",  x) ? This assumes that x contains the character
data and not a factor, as would usually be the case in a data frame. If the
variable is really a factor, then use as.character(x) in the call to gsub().

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Luis Ridao Cruz
> Sent: Thursday, October 20, 2005 8:24 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] String manipulation
> 
> R-help,
> 
> I have a data frame which contains a character string column 
> that is something like;
> 
> II11
> II18
> II23
> III1
> III13
> III16
> III19
> III2
> III7
> IV10
> IV11
> IV12
> IX16
> IX4
> V12
> V18
> V2
> V20
> V23
> V4
> VII14
> VII18
> VII21
> VII26
> VII28
> VII33
> VII4
> VII48
> VII5
> ....
> ....
> ....
> 
> I want to apply a function (e.g mean) by grouping according 
> to the roman part of the string, i.e,
> 
> by I
> by V
> by VII
> ...
> ...
> and so on.
> 
> I have looked at string manipulation functions (grep, 
> pmatch,,,) but I can't really get it the way I want.
> Can anyone help?
> 
> Thanks in advance.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From m.ballardini at ior-forli.it  Thu Oct 20 15:55:48 2005
From: m.ballardini at ior-forli.it (Michela Ballardini)
Date: Thu, 20 Oct 2005 15:55:48 +0200
Subject: [R] forrest plot
Message-ID: <000f01c5d57d$fa231a80$0200a8c0@Michela>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051020/dc62fa79/attachment.pl

From subianto at gmail.com  Thu Oct 20 15:59:24 2005
From: subianto at gmail.com (Muhammad Subianto)
Date: Thu, 20 Oct 2005 15:59:24 +0200
Subject: [R] search a value in variables dataset
Message-ID: <4357A2BC.2010305@gmail.com>

Dear R-list,
I have a dataset, say (the real dataset is 20 columns,110200 rows).

 > my.reducedID
       V1 V2 V3 V4 V5 V6 V7  V8  V9
  [1,]  1  0  0  1 14  3  1   0   2
  [2,]  2  0  0  1 14  3  1   0   2
  [3,]  0  1  0  1 14  2  1   0   2
  [4,]  0  0  1  1 14  3  1   0   2
  [5,]  0  1  1  0 14  2  1   0   2
  [6,]  0  0  0  1 14  3  1   0   2
  [7,]  0  0  0  1  0  3  1   0   2
  [8,]  0  0  0  1  1  3  1   0   2
  [9,]  0  0  0  1  2  3  1   0   2
[10,]  0  0  0  1  3  3  1   0   2
[11,]  0  0  0  1  4  3  1   0   2
[12,]  0  0  0  1  5  3  1   0   2
[13,]  0  0  0  1  6  3  1   0   2
[14,]  0  0  0  1  7  3  1   0   2
[15,]  0  0  0  1  8  3  1   0   2
[16,]  0  0  0  1  9  3  1   0   2
[17,]  0  0  0  1 10  3  1   0   2
[18,]  0  0  0  1 11  3  1   0   2
[19,]  0  0  0  1 12  3  1   0   2
[20,]  0  0  0  1 13  3  1   0   2
[21,]  0  0  0  1 15  3  1   0   2
[22,]  0  0  0  1 16  3  1   0   2
[23,]  0  0  0  1 17  3  1   0   2
[24,]  0  0  0  1 18  3  1   0   2
[25,]  0  0  0  1 19  3  1   0   2
[26,]  0  0  0  1 20  3  1   0   2
[27,]  0  0  0  1 14  0  1   0   2
[28,]  0  0  0  1 14  1  1   0   2
[29,]  0  0  0  1 14  2  1   0   2
[30,]  0  0  0  1 14  4  1   0   2
 >

I want to search a value in variables, say V1=0, V5=14 and V6=2.
The result should look like
       V1 V2 V3 V4 V5 V6 V7  V8  V9
  [3,]  0  1  0  1 14  2  1   0   2
  [5,]  0  1  1  0 14  2  1   0   2
[29,]  0  0  0  1 14  2  1   0   2

I can do this with: my.reducedID[c(3,5,29),]
Because I have very large dataset I can not make this manual.
Then I need the ID of row did not change, I mean like,
[3,]
[5,]
[29,]
In dataset this is about ID our customers.
I was wondering if anyone give me a trick to make simple.
Thanks you very much for any suggestions.

Best, Muhammad Subianto



From Manuel.Schneider at eawag.ch  Thu Oct 20 16:01:19 2005
From: Manuel.Schneider at eawag.ch (Schneider, Manuel)
Date: Thu, 20 Oct 2005 16:01:19 +0200
Subject: [R] Attributing values to matrix according to names
Message-ID: <744893FCE2B96241BD15C17F2F8649E105DD3F@EA-MAIL.eawag.wroot.emp-eaw.ch>

Dear R-helpers

Apologies for the basic question, but I just got stuck:

I would like to write values from a vector into array cells with the
same names

> count[1:10]
10010 10014 10015 10017 10030 10080 10100 10230 10250 10280 
    0     0     0     0     0     1     1     0     2     0 

>data[1:10,,1]
      [,1] [,2] [,3] [,4] [,5] 
10010   NA   NA   NA   NA   NA   
10014   NA   NA   NA   NA   NA   
10015   NA   NA   NA   NA   NA   
10016   NA   NA   NA   NA   NA   
10017   NA   NA   NA   NA   NA   
10100   NA   NA   NA   NA   NA   
10140   NA   NA   NA   NA   NA   
10150   NA   NA   NA   NA   NA   
10160   NA   NA   NA   NA   NA   
10170   NA   NA   NA   NA   NA   

> length(count)
[1] 2842

> dim(data)
[1] 4667   5   10

My operation should result in

>data[1:10,,1]
      [,1] [,2] [,3] [,4] [,5] 
10010    0   NA   NA   NA   NA   
10014    0   NA   NA   NA   NA  
10015    0   NA   NA   NA   NA   
10016   NA   NA   NA   NA   NA   
10017    0   NA   NA   NA   NA  
10100    1   NA   NA   NA   NA  
10140   NA   NA   NA   NA   NA   
10150   NA   NA   NA   NA   NA   
10160   NA   NA   NA   NA   NA   
10170   NA   NA   NA   NA   NA   

> data["10014",1,1]<-count["10014"]
works but

> data["names(count)",1,1]<-count["names(count)"] 
Fails with Error: indexing outside limits.

Many thanks for any help

Manuel



From Maia.Berman at cebc.cnrs.fr  Thu Oct 20 16:10:51 2005
From: Maia.Berman at cebc.cnrs.fr (=?ISO-8859-1?Q?Ma=EFa_Berman?=)
Date: Thu, 20 Oct 2005 16:10:51 +0200
Subject: [R] =?iso-8859-1?q?=5BFwd=3A_probl=E8me_d=27import_de_fichier=5D?=
Message-ID: <4357A56B.8090109@cebc.cnrs.fr>

merci probl??me r??solu!!!



From p.dalgaard at biostat.ku.dk  Thu Oct 20 16:20:10 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 20 Oct 2005 16:20:10 +0200
Subject: [R] Automatic rounding of values after factors ,
	converted to numeric, are multipled by a real number
In-Reply-To: <74BDE31AFD6EC54DB026E6CD11FF0A7E96519A@ES-MSG-008.es.govt.state.ma.us>
References: <74BDE31AFD6EC54DB026E6CD11FF0A7E96519A@ES-MSG-008.es.govt.state.ma.us>
Message-ID: <x2ek6g6zj9.fsf@viggo.kubism.ku.dk>

"Nelson, Gary (FWE)" <Gary.Nelson at state.ma.us> writes:

> Peter,
> 
> Thank you for your response. I knew how close the values are to
> integers, but I still don't understand why I don't have control over
> how the numbers are displayed (rounded or not)?

It's all in the conventions. The digits in print() and friends are
significant digits, so we first round to that many significant digits,
then discard trailing zeros, which is why

> 12.500001
[1] 12.5
> 12.50001
[1] 12.50001

The exception is that we do not discard significant digits to the left
of the decimal point, unless we are using scientific notation

> print(12345678,digits=2)
[1] 1.2e+07
> print(12345678,digits=5)
[1] 12345678

(the "scipen" options controls the logic for switching notation).

For finer control we have the formatC function:

> format(1234.00001,digits=9) # same thing as with print()
[1] "1234.00001"
> format(1234.00001,digits=8)
[1] "1234"
> formatC(1234.00001,digits=5,format="f")
[1] "1234.00001"
> formatC(1234.00001,digits=4,format="f")
[1] "1234.0000"


-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Thu Oct 20 16:29:10 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 20 Oct 2005 16:29:10 +0200
Subject: [R] Attributing values to matrix according to names
In-Reply-To: <744893FCE2B96241BD15C17F2F8649E105DD3F@EA-MAIL.eawag.wroot.emp-eaw.ch>
References: <744893FCE2B96241BD15C17F2F8649E105DD3F@EA-MAIL.eawag.wroot.emp-eaw.ch>
Message-ID: <x2ach46z49.fsf@viggo.kubism.ku.dk>

"Schneider, Manuel" <Manuel.Schneider at eawag.ch> writes:

> > data["10014",1,1]<-count["10014"]
> works but
> 
> > data["names(count)",1,1]<-count["names(count)"] 
> Fails with Error: indexing outside limits.

Well, you don't have a row named "names(count)" now do you? Try
dropping the quotes.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From 042045003 at fudan.edu.cn  Thu Oct 20 16:29:07 2005
From: 042045003 at fudan.edu.cn (ronggui)
Date: Thu, 20 Oct 2005 22:29:07 +0800
Subject: [R] search a value in variables dataset
Message-ID: <0ION009W5X320H@mail.fudan.edu.cn>

use logical index.

> my.reducedID<-read.table(file.choose())
> head(my.reducedID)
     V1 V2 V3 V4 V5 V6 V7 V8 V9
[1,]  1  0  0  1 14  3  1  0  2
[2,]  2  0  0  1 14  3  1  0  2
[3,]  0  1  0  1 14  2  1  0  2
[4,]  0  0  1  1 14  3  1  0  2
[5,]  0  1  1  0 14  2  1  0  2
[6,]  0  0  0  1 14  3  1  0  2
> attach(my.reducedID)
> my.reducedID[(V1==0 & V5==14 & V6==2),]
      V1 V2 V3 V4 V5 V6 V7 V8 V9
[3,]   0  1  0  1 14  2  1  0  2
[5,]   0  1  1  0 14  2  1  0  2
[29,]  0  0  0  1 14  2  1  0  2


======= 2005-10-20 21:59:24 ÄúÔÚÀ´ÐÅÖÐÐ´µÀ£º=======

>Dear R-list,
>I have a dataset, say (the real dataset is 20 columns,110200 rows).
>
> > my.reducedID
>       V1 V2 V3 V4 V5 V6 V7  V8  V9
>  [1,]  1  0  0  1 14  3  1   0   2
>  [2,]  2  0  0  1 14  3  1   0   2
>  [3,]  0  1  0  1 14  2  1   0   2
>  [4,]  0  0  1  1 14  3  1   0   2
>  [5,]  0  1  1  0 14  2  1   0   2
>  [6,]  0  0  0  1 14  3  1   0   2
>  [7,]  0  0  0  1  0  3  1   0   2
>  [8,]  0  0  0  1  1  3  1   0   2
>  [9,]  0  0  0  1  2  3  1   0   2
>[10,]  0  0  0  1  3  3  1   0   2
>[11,]  0  0  0  1  4  3  1   0   2
>[12,]  0  0  0  1  5  3  1   0   2
>[13,]  0  0  0  1  6  3  1   0   2
>[14,]  0  0  0  1  7  3  1   0   2
>[15,]  0  0  0  1  8  3  1   0   2
>[16,]  0  0  0  1  9  3  1   0   2
>[17,]  0  0  0  1 10  3  1   0   2
>[18,]  0  0  0  1 11  3  1   0   2
>[19,]  0  0  0  1 12  3  1   0   2
>[20,]  0  0  0  1 13  3  1   0   2
>[21,]  0  0  0  1 15  3  1   0   2
>[22,]  0  0  0  1 16  3  1   0   2
>[23,]  0  0  0  1 17  3  1   0   2
>[24,]  0  0  0  1 18  3  1   0   2
>[25,]  0  0  0  1 19  3  1   0   2
>[26,]  0  0  0  1 20  3  1   0   2
>[27,]  0  0  0  1 14  0  1   0   2
>[28,]  0  0  0  1 14  1  1   0   2
>[29,]  0  0  0  1 14  2  1   0   2
>[30,]  0  0  0  1 14  4  1   0   2
> >
>
>I want to search a value in variables, say V1=0, V5=14 and V6=2.
>The result should look like
>       V1 V2 V3 V4 V5 V6 V7  V8  V9
>  [3,]  0  1  0  1 14  2  1   0   2
>  [5,]  0  1  1  0 14  2  1   0   2
>[29,]  0  0  0  1 14  2  1   0   2
>
>I can do this with: my.reducedID[c(3,5,29),]
>Because I have very large dataset I can not make this manual.
>Then I need the ID of row did not change, I mean like,
>[3,]
>[5,]
>[29,]
>In dataset this is about ID our customers.
>I was wondering if anyone give me a trick to make simple.
>Thanks you very much for any suggestions.
>
>Best, Muhammad Subianto
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

= = = = = = = = = = = = = = = = = = = =
			


 

2005-10-20

------
Deparment of Sociology
Fudan University

My new mail addres is ronggui.huang at gmail.com
Blog:http://sociology.yculblog.com



From ligges at statistik.uni-dortmund.de  Thu Oct 20 16:41:33 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 20 Oct 2005 16:41:33 +0200
Subject: [R] Attributing values to matrix according to names
In-Reply-To: <744893FCE2B96241BD15C17F2F8649E105DD3F@EA-MAIL.eawag.wroot.emp-eaw.ch>
References: <744893FCE2B96241BD15C17F2F8649E105DD3F@EA-MAIL.eawag.wroot.emp-eaw.ch>
Message-ID: <4357AC9D.3040309@statistik.uni-dortmund.de>

Schneider, Manuel wrote:

> Dear R-helpers
> 
> Apologies for the basic question, but I just got stuck:
> 
> I would like to write values from a vector into array cells with the
> same names
> 
> 
>>count[1:10]
> 
> 10010 10014 10015 10017 10030 10080 10100 10230 10250 10280 
>     0     0     0     0     0     1     1     0     2     0 
> 
> 
>>data[1:10,,1]
> 
>       [,1] [,2] [,3] [,4] [,5] 
> 10010   NA   NA   NA   NA   NA   
> 10014   NA   NA   NA   NA   NA   
> 10015   NA   NA   NA   NA   NA   
> 10016   NA   NA   NA   NA   NA   
> 10017   NA   NA   NA   NA   NA   
> 10100   NA   NA   NA   NA   NA   
> 10140   NA   NA   NA   NA   NA   
> 10150   NA   NA   NA   NA   NA   
> 10160   NA   NA   NA   NA   NA   
> 10170   NA   NA   NA   NA   NA   
> 
> 
>>length(count)
> 
> [1] 2842
> 
> 
>>dim(data)
> 
> [1] 4667   5   10
> 
> My operation should result in
> 
> 
>>data[1:10,,1]
> 
>       [,1] [,2] [,3] [,4] [,5] 
> 10010    0   NA   NA   NA   NA   
> 10014    0   NA   NA   NA   NA  
> 10015    0   NA   NA   NA   NA   
> 10016   NA   NA   NA   NA   NA   
> 10017    0   NA   NA   NA   NA  
> 10100    1   NA   NA   NA   NA  
> 10140   NA   NA   NA   NA   NA   
> 10150   NA   NA   NA   NA   NA   
> 10160   NA   NA   NA   NA   NA   
> 10170   NA   NA   NA   NA   NA   
> 
> 
>>data["10014",1,1]<-count["10014"]
> 
> works but
> 
> 
>>data["names(count)",1,1]<-count["names(count)"] 

You mean

  data[names(count),1,1] <- count[names(count)]

without the quotes ...


Uwe Ligges



> Fails with Error: indexing outside limits.
> 
> Many thanks for any help
> 
> Manuel
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Thu Oct 20 16:50:07 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 20 Oct 2005 16:50:07 +0200
Subject: [R] search a value in variables dataset
In-Reply-To: <4357A2BC.2010305@gmail.com>
References: <4357A2BC.2010305@gmail.com>
Message-ID: <4357AE9F.2050706@statistik.uni-dortmund.de>

Muhammad Subianto wrote:

> Dear R-list,
> I have a dataset, say (the real dataset is 20 columns,110200 rows).
> 
>  > my.reducedID
>        V1 V2 V3 V4 V5 V6 V7  V8  V9
>   [1,]  1  0  0  1 14  3  1   0   2
>   [2,]  2  0  0  1 14  3  1   0   2
>   [3,]  0  1  0  1 14  2  1   0   2
>   [4,]  0  0  1  1 14  3  1   0   2
>   [5,]  0  1  1  0 14  2  1   0   2
>   [6,]  0  0  0  1 14  3  1   0   2
>   [7,]  0  0  0  1  0  3  1   0   2
>   [8,]  0  0  0  1  1  3  1   0   2
>   [9,]  0  0  0  1  2  3  1   0   2
> [10,]  0  0  0  1  3  3  1   0   2
> [11,]  0  0  0  1  4  3  1   0   2
> [12,]  0  0  0  1  5  3  1   0   2
> [13,]  0  0  0  1  6  3  1   0   2
> [14,]  0  0  0  1  7  3  1   0   2
> [15,]  0  0  0  1  8  3  1   0   2
> [16,]  0  0  0  1  9  3  1   0   2
> [17,]  0  0  0  1 10  3  1   0   2
> [18,]  0  0  0  1 11  3  1   0   2
> [19,]  0  0  0  1 12  3  1   0   2
> [20,]  0  0  0  1 13  3  1   0   2
> [21,]  0  0  0  1 15  3  1   0   2
> [22,]  0  0  0  1 16  3  1   0   2
> [23,]  0  0  0  1 17  3  1   0   2
> [24,]  0  0  0  1 18  3  1   0   2
> [25,]  0  0  0  1 19  3  1   0   2
> [26,]  0  0  0  1 20  3  1   0   2
> [27,]  0  0  0  1 14  0  1   0   2
> [28,]  0  0  0  1 14  1  1   0   2
> [29,]  0  0  0  1 14  2  1   0   2
> [30,]  0  0  0  1 14  4  1   0   2
>  >
> 
> I want to search a value in variables, say V1=0, V5=14 and V6=2.
> The result should look like
>        V1 V2 V3 V4 V5 V6 V7  V8  V9
>   [3,]  0  1  0  1 14  2  1   0   2
>   [5,]  0  1  1  0 14  2  1   0   2
> [29,]  0  0  0  1 14  2  1   0   2
> 
> I can do this with: my.reducedID[c(3,5,29),]
> Because I have very large dataset I can not make this manual.
> Then I need the ID of row did not change, I mean like,
> [3,]
> [5,]
> [29,]
> In dataset this is about ID our customers.
> I was wondering if anyone give me a trick to make simple.
> Thanks you very much for any suggestions.

Without having tested:
   with(my.reducedID, rownames(V1==0 & V5==14 & V6==2))

Uwe Ligges

> Best, Muhammad Subianto
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From HStevens at MUOhio.edu  Thu Oct 20 16:47:30 2005
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Thu, 20 Oct 2005 10:47:30 -0400
Subject: [R] creating a derived variable in a data frame
In-Reply-To: <4319997.1129766948260.JavaMail.aavram@mac.com>
References: <4319997.1129766948260.JavaMail.aavram@mac.com>
Message-ID: <55624207-F829-48B7-8819-DB871708CDBF@MUOhio.edu>

Hi Avram-
How many countries do you have?
I would do it the following way because it is simple and I don't know  
any better, even if it is  absurdly painstaking.

#Step 1
mydata$continent <- factor(NA, levels=c("NoAm","Euro"))

#Steps 2 a-z
mydata$continent[mydata$country=="US" |
                                 mydata$country=="CA" |
                                mydata$country=="MX" ]  <- "NoAm"

#Repeat for all countries and continents.

Hank


On Oct 19, 2005, at 8:09 PM, Avram Aelony wrote:

> Hello,
>
> I have read through the manuals and can't seem to find an answer.
>
> I have a categorical, character variable that has hundreds of  
> values.  I want to group the existing values of this variable into  
> a new, derived (categorical) variable by applying conditions to the  
> values in the data.
>
> For example, suppose I have a data frame with variables: date,  
> country, x, y, and z.
>
> x,y,z are numeric and country is a 2-digit character string.  I  
> want to create a new derived variable named "continent" that would  
> also exist in the data frame. The Continent variable would have  
> values of "Asia", "Europe", "North America", etc...
>
> How would this best be done for a large dataset (>10MB) ?
> I have tried many variations on following without success (note in  
> a real example I would have a longer list of countries and  
> continent values):
>
>
>> mydata$continent <- mydata[ mydata$country==list 
>> ('US','CA','MX'), ] -> "North America"
>>
>
> I have read about factors, but I am not sure how they apply here.
>
> Can anyone help me with the syntax?  I am sure it is trivial and a  
> common thing to do.
> The ultimate goal is to compute percentages of x by continent.
>
> Thanks for any help in advance.
>
> -Avram
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting- 
> guide.html
>

Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"



From andy_liaw at merck.com  Thu Oct 20 16:58:09 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 20 Oct 2005 10:58:09 -0400
Subject: [R] how to set environment variables?
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED514@usctmx1106.merck.com>

See the first paragraph of ?Startup.

Andy

> From: Andreas Zankl
> 
> Thanks. Sys.putenv did work, however this has to be set every 
> time I start R.
> 
> gs is on my path and works fine under Unix, but I get the following 
> error when running bitmap (without setting R_GSCMD first):
> 
> /bin/sh: line 1: gs: command not found
> 
> I assume the problem is related to the fact that I am using the csh 
> shell, while the new Mac OS X default shell is now bash. So I guess 
> my .csh path settings are ignored by R calling bash. I solved the 
> problem by adding my R_GSCMD settings to the Renviron file 
> (R_GSCMD=${RGSCMD-'/sw/bin/gs'} in my case). Hope this helps anyone 
> with the same problem.
> 
> Thanks again for your help!
> Andreas
> 
> 
> 
> At 12:51 +0100 20.10.2005, Prof Brian Ripley wrote:
> >On Thu, 20 Oct 2005, Andreas Zankl wrote:
> >
> >>The help file of the R bitmap function says that I have to set the
> >>environment variable R_GSCMD to the path of my Ghostscript
> >>installation.
> >
> >Actually, it does not say that.  It says you _can_ specify the path 
> >to your executable (not the installation) that way. It will work 
> >without doing so if the executable 'gs' (on a Unix-alike) is on your 
> >path, which it normally is on Unix-alikes.
> >
> >>How do I set this variable (either by commandline or in
> >>R.app for Mac)? Sorry if this sounds like a very basic question, but
> >>I could not find the answer anywhere else.
> >
> >?Sys.putenv for how to do it from R.  help.search("environment 
> >variable") got me there.
> >
> >--
> >Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >University of Oxford,             Tel:  +44 1865 272861 (self)
> >1 South Parks Road,                     +44 1865 272866 (PA)
> >Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> 
> -- 
> PLEASE NOTE MY NEW EMAIL ADDRESS: ANDREAS.ZANKL at GMAIL.COM
> 
> --------------------------
> Andreas Zankl, MD
> Division of Molecular Pediatrics
> Clinique Infantile 02/50
> CHUV
> Avenue Pierre Decker 2
> CH-1011 Lausanne
> Switzerland
> Phone: +41-21-3143778
> Fax: +41-21-3143546
> Email: andreas.zankl at gmail.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From 042045003 at fudan.edu.cn  Thu Oct 20 17:04:47 2005
From: 042045003 at fudan.edu.cn (ronggui)
Date: Thu, 20 Oct 2005 23:04:47 +0800
Subject: [R] search a value in variables dataset
Message-ID: <0ION0074HYQIMK@mail.fudan.edu.cn>

use logical index.

> my.reducedID<-read.table(file.choose())
> head(my.reducedID)
     V1 V2 V3 V4 V5 V6 V7 V8 V9
[1,]  1  0  0  1 14  3  1  0  2
[2,]  2  0  0  1 14  3  1  0  2
[3,]  0  1  0  1 14  2  1  0  2
[4,]  0  0  1  1 14  3  1  0  2
[5,]  0  1  1  0 14  2  1  0  2
[6,]  0  0  0  1 14  3  1  0  2
> attach(my.reducedID)
> my.reducedID[(V1==0 & V5==14 & V6==2),]
      V1 V2 V3 V4 V5 V6 V7 V8 V9
[3,]   0  1  0  1 14  2  1  0  2
[5,]   0  1  1  0 14  2  1  0  2
[29,]  0  0  0  1 14  2  1  0  2


======= 2005-10-20 21:59:24 ÄúÔÚÀ´ÐÅÖÐÐ´µÀ£º=======

>Dear R-list,
>I have a dataset, say (the real dataset is 20 columns,110200 rows).
>
> > my.reducedID
>       V1 V2 V3 V4 V5 V6 V7  V8  V9
>  [1,]  1  0  0  1 14  3  1   0   2
>  [2,]  2  0  0  1 14  3  1   0   2
>  [3,]  0  1  0  1 14  2  1   0   2
>  [4,]  0  0  1  1 14  3  1   0   2
>  [5,]  0  1  1  0 14  2  1   0   2
>  [6,]  0  0  0  1 14  3  1   0   2
>  [7,]  0  0  0  1  0  3  1   0   2
>  [8,]  0  0  0  1  1  3  1   0   2
>  [9,]  0  0  0  1  2  3  1   0   2
>[10,]  0  0  0  1  3  3  1   0   2
>[11,]  0  0  0  1  4  3  1   0   2
>[12,]  0  0  0  1  5  3  1   0   2
>[13,]  0  0  0  1  6  3  1   0   2
>[14,]  0  0  0  1  7  3  1   0   2
>[15,]  0  0  0  1  8  3  1   0   2
>[16,]  0  0  0  1  9  3  1   0   2
>[17,]  0  0  0  1 10  3  1   0   2
>[18,]  0  0  0  1 11  3  1   0   2
>[19,]  0  0  0  1 12  3  1   0   2
>[20,]  0  0  0  1 13  3  1   0   2
>[21,]  0  0  0  1 15  3  1   0   2
>[22,]  0  0  0  1 16  3  1   0   2
>[23,]  0  0  0  1 17  3  1   0   2
>[24,]  0  0  0  1 18  3  1   0   2
>[25,]  0  0  0  1 19  3  1   0   2
>[26,]  0  0  0  1 20  3  1   0   2
>[27,]  0  0  0  1 14  0  1   0   2
>[28,]  0  0  0  1 14  1  1   0   2
>[29,]  0  0  0  1 14  2  1   0   2
>[30,]  0  0  0  1 14  4  1   0   2
> >
>
>I want to search a value in variables, say V1=0, V5=14 and V6=2.
>The result should look like
>       V1 V2 V3 V4 V5 V6 V7  V8  V9
>  [3,]  0  1  0  1 14  2  1   0   2
>  [5,]  0  1  1  0 14  2  1   0   2
>[29,]  0  0  0  1 14  2  1   0   2
>
>I can do this with: my.reducedID[c(3,5,29),]
>Because I have very large dataset I can not make this manual.
>Then I need the ID of row did not change, I mean like,
>[3,]
>[5,]
>[29,]
>In dataset this is about ID our customers.
>I was wondering if anyone give me a trick to make simple.
>Thanks you very much for any suggestions.
>
>Best, Muhammad Subianto
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

= = = = = = = = = = = = = = = = = = = =
			


 

2005-10-20

------
Deparment of Sociology
Fudan University

My new mail addres is ronggui.huang at gmail.com
Blog:http://sociology.yculblog.com



From mschwartz at mn.rr.com  Thu Oct 20 17:05:06 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Thu, 20 Oct 2005 10:05:06 -0500
Subject: [R] Automatic rounding of values after factors ,
	converted to	numeric, are multipled by a real number
In-Reply-To: <x2ek6g6zj9.fsf@viggo.kubism.ku.dk>
References: <74BDE31AFD6EC54DB026E6CD11FF0A7E96519A@ES-MSG-008.es.govt.state.ma.us>
	<x2ek6g6zj9.fsf@viggo.kubism.ku.dk>
Message-ID: <1129820706.6015.12.camel@localhost.localdomain>

On Thu, 2005-10-20 at 16:20 +0200, Peter Dalgaard wrote:
> "Nelson, Gary (FWE)" <Gary.Nelson at state.ma.us> writes:
> 
> > Peter,
> > 
> > Thank you for your response. I knew how close the values are to
> > integers, but I still don't understand why I don't have control over
> > how the numbers are displayed (rounded or not)?
> 
> It's all in the conventions. The digits in print() and friends are
> significant digits, so we first round to that many significant digits,
> then discard trailing zeros, which is why
> 
> > 12.500001
> [1] 12.5
> > 12.50001
> [1] 12.50001
> 
> The exception is that we do not discard significant digits to the left
> of the decimal point, unless we are using scientific notation
> 
> > print(12345678,digits=2)
> [1] 1.2e+07
> > print(12345678,digits=5)
> [1] 12345678
> 
> (the "scipen" options controls the logic for switching notation).
> 
> For finer control we have the formatC function:
> 
> > format(1234.00001,digits=9) # same thing as with print()
> [1] "1234.00001"
> > format(1234.00001,digits=8)
> [1] "1234"
> > formatC(1234.00001,digits=5,format="f")
> [1] "1234.00001"
> > formatC(1234.00001,digits=4,format="f")
> [1] "1234.0000"


Also, sprintf():

> sprintf("%.9f", 1234.00001)
[1] "1234.000010000"

> sprintf("%.4f", 1234.00001)
[1] "1234.0000"

> sprintf("%12.4f", 1234.00001)
[1] "   1234.0000"


HTH,

Marc Schwartz



From Manuel.Schneider at eawag.ch  Thu Oct 20 17:07:56 2005
From: Manuel.Schneider at eawag.ch (Schneider, Manuel)
Date: Thu, 20 Oct 2005 17:07:56 +0200
Subject: [R] Attributing values to matrix according to names
Message-ID: <744893FCE2B96241BD15C17F2F8649E105DD48@EA-MAIL.eawag.wroot.emp-eaw.ch>

Dear Peter and Uwe

Thanks for your suggestions.
However, 
> data[names(count),1,1] <- count[names(count)] 
Still gives the indexing problem, guess because not all element of count can be found in data.

Found a way round this by 
> temp<-rep(NA, times=as.numeric(names(count[length(count)])))
> temp[as.numeric(names(count))]<-count
> rwname<-rownames(data)
> for (i in 1:dim(data)[1]) data[i,1,1]<-temp[as.numeric(rwname[i])]
What works for me but I am convinced there is a far more elegant way.

Kind regards

Manuel

-----Original Message-----
From: pd at pubhealth.ku.dk [mailto:pd at pubhealth.ku.dk] On Behalf Of Peter Dalgaard
Sent: Thursday, October 20, 2005 4:29 PM
To: Schneider, Manuel
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Attributing values to matrix according to names

"Schneider, Manuel" <Manuel.Schneider at eawag.ch> writes:

> > data["10014",1,1]<-count["10014"]
> works but
> 
> > data["names(count)",1,1]<-count["names(count)"]
> Fails with Error: indexing outside limits.

Well, you don't have a row named "names(count)" now do you? Try
dropping the quotes.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From greg.snow at ihc.com  Thu Oct 20 17:12:37 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Thu, 20 Oct 2005 09:12:37 -0600
Subject: [R] information about Loess
Message-ID: <s3575f98.088@lp-msg1.co.ihc.com>

The loess.demo function in the TeachingDemos package may help you
understand what is going on.  Note that the default for loess in R does
an additional spline smooth/interpolation which may explain small
differences from other tools.

Greg Snow, Ph.D.
Statistical Data Center, LDS Hospital
Intermountain Health Care
greg.snow at ihc.com
(801) 408-8111

>>> "Naomi Berdugo" <naomi at isoft.fr> 10/20/05 05:14AM >>>
Hello,

I'm currently using a tool that provides a Loess fitting, but I
obtained results that are slightly different from those provided by R
implementation of the Loess. That's why I would like to know if you
could give me a source (bibliography or web) that explains in a clear
way each step of the algorithm, with the possible options to choose,
etc.. in order for me to understand those differences.

Thank you,

Naomi Berdugo.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Thu Oct 20 17:25:12 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 20 Oct 2005 17:25:12 +0200
Subject: [R] Attributing values to matrix according to names
In-Reply-To: <744893FCE2B96241BD15C17F2F8649E105DD48@EA-MAIL.eawag.wroot.emp-eaw.ch>
References: <744893FCE2B96241BD15C17F2F8649E105DD48@EA-MAIL.eawag.wroot.emp-eaw.ch>
Message-ID: <x264rs6wiv.fsf@viggo.kubism.ku.dk>

"Schneider, Manuel" <Manuel.Schneider at eawag.ch> writes:

> Dear Peter and Uwe
> 
> Thanks for your suggestions.
> However, 
> > data[names(count),1,1] <- count[names(count)] 
> Still gives the indexing problem, guess because not all element of count can be found in data.

Perhaps something like

nm <- names(count)
nm <- intersect(nm,dimnames(data)[[1]]) # or rownames(data)
data[nm,1,1] <- count[nm]
 
> Found a way round this by 
> > temp<-rep(NA, times=as.numeric(names(count[length(count)])))
> > temp[as.numeric(names(count))]<-count
> > rwname<-rownames(data)
> > for (i in 1:dim(data)[1]) data[i,1,1]<-temp[as.numeric(rwname[i])]
> What works for me but I am convinced there is a far more elegant way.
> 
> Kind regards
> 
> Manuel
> 
> -----Original Message-----
> From: pd at pubhealth.ku.dk [mailto:pd at pubhealth.ku.dk] On Behalf Of Peter Dalgaard
> Sent: Thursday, October 20, 2005 4:29 PM
> To: Schneider, Manuel
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Attributing values to matrix according to names
> 
> "Schneider, Manuel" <Manuel.Schneider at eawag.ch> writes:
> 
> > > data["10014",1,1]<-count["10014"]
> > works but
> > 
> > > data["names(count)",1,1]<-count["names(count)"]
> > Fails with Error: indexing outside limits.
> 
> Well, you don't have a row named "names(count)" now do you? Try
> dropping the quotes.
> 
> -- 
>    O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ccatj at web.de  Thu Oct 20 17:31:21 2005
From: ccatj at web.de (Christian Jones)
Date: Thu, 20 Oct 2005 17:31:21 +0200
Subject: [R] having scaling problems with a histogram
Message-ID: <376648927@web.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051020/f2e7d9f1/attachment.pl

From subianto at gmail.com  Thu Oct 20 17:32:57 2005
From: subianto at gmail.com (Muhammad Subianto)
Date: Thu, 20 Oct 2005 17:32:57 +0200
Subject: [R] search a value in variables dataset
In-Reply-To: <4357A2BC.2010305@gmail.com>
References: <4357A2BC.2010305@gmail.com>
Message-ID: <4357B8A9.7000207@gmail.com>

Dear All,
Perfect. Thanks you very much for your help.

Best, Muhammad Subianto


 >>my.reducedID<-read.table(file.choose())
 >>head(my.reducedID)
 >
 >     V1 V2 V3 V4 V5 V6 V7 V8 V9
 >[1,]  1  0  0  1 14  3  1  0  2
 >[2,]  2  0  0  1 14  3  1  0  2
 >[3,]  0  1  0  1 14  2  1  0  2
 >[4,]  0  0  1  1 14  3  1  0  2
 >[5,]  0  1  1  0 14  2  1  0  2
 >[6,]  0  0  0  1 14  3  1  0  2
 >
 >>attach(my.reducedID)
 >>my.reducedID[(V1==0 & V5==14 & V6==2),]
 >
 >      V1 V2 V3 V4 V5 V6 V7 V8 V9
 >[3,]   0  1  0  1 14  2  1  0  2
 >[5,]   0  1  1  0 14  2  1  0  2
 >[29,]  0  0  0  1 14  2  1  0  2
 >

######## OR ##########

 >my.reducedID[ my.reducedID[,1]==0 & my.reducedID[,5]==14 &
 >my.reducedID[,6]==2, ]
 >


On this day 20/10/2005 03:59 PM, Muhammad Subianto wrote:
> Dear R-list,
> I have a dataset, say (the real dataset is 20 columns,110200 rows).
> 
>  > my.reducedID
>        V1 V2 V3 V4 V5 V6 V7  V8  V9
>   [1,]  1  0  0  1 14  3  1   0   2
>   [2,]  2  0  0  1 14  3  1   0   2
>   [3,]  0  1  0  1 14  2  1   0   2
>   [4,]  0  0  1  1 14  3  1   0   2
>   [5,]  0  1  1  0 14  2  1   0   2
>   [6,]  0  0  0  1 14  3  1   0   2
>   [7,]  0  0  0  1  0  3  1   0   2
>   [8,]  0  0  0  1  1  3  1   0   2
>   [9,]  0  0  0  1  2  3  1   0   2
> [10,]  0  0  0  1  3  3  1   0   2
> [11,]  0  0  0  1  4  3  1   0   2
> [12,]  0  0  0  1  5  3  1   0   2
> [13,]  0  0  0  1  6  3  1   0   2
> [14,]  0  0  0  1  7  3  1   0   2
> [15,]  0  0  0  1  8  3  1   0   2
> [16,]  0  0  0  1  9  3  1   0   2
> [17,]  0  0  0  1 10  3  1   0   2
> [18,]  0  0  0  1 11  3  1   0   2
> [19,]  0  0  0  1 12  3  1   0   2
> [20,]  0  0  0  1 13  3  1   0   2
> [21,]  0  0  0  1 15  3  1   0   2
> [22,]  0  0  0  1 16  3  1   0   2
> [23,]  0  0  0  1 17  3  1   0   2
> [24,]  0  0  0  1 18  3  1   0   2
> [25,]  0  0  0  1 19  3  1   0   2
> [26,]  0  0  0  1 20  3  1   0   2
> [27,]  0  0  0  1 14  0  1   0   2
> [28,]  0  0  0  1 14  1  1   0   2
> [29,]  0  0  0  1 14  2  1   0   2
> [30,]  0  0  0  1 14  4  1   0   2
>  >
> 
> I want to search a value in variables, say V1=0, V5=14 and V6=2.
> The result should look like
>        V1 V2 V3 V4 V5 V6 V7  V8  V9
>   [3,]  0  1  0  1 14  2  1   0   2
>   [5,]  0  1  1  0 14  2  1   0   2
> [29,]  0  0  0  1 14  2  1   0   2
> 
> I can do this with: my.reducedID[c(3,5,29),]
> Because I have very large dataset I can not make this manual.
> Then I need the ID of row did not change, I mean like,
> [3,]
> [5,]
> [29,]
> In dataset this is about ID our customers.
> I was wondering if anyone give me a trick to make simple.
> Thanks you very much for any suggestions.
> 
> Best, Muhammad Subianto
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From maechler at stat.math.ethz.ch  Thu Oct 20 17:35:22 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 20 Oct 2005 17:35:22 +0200
Subject: [R] npmc package
In-Reply-To: <43568C54.2060000@ufba.br>
References: <4356499A.6040604@ufba.br>
	<43564EC4.7090407@statistik.uni-dortmund.de>
	<43568C54.2060000@ufba.br>
Message-ID: <17239.47418.376571.347771@stat.math.ethz.ch>

>>>>> "Carlos" == Carlos Mauricio Cardeal Mendes <mcardeal at ufba.br>
>>>>>     on Wed, 19 Oct 2005 15:11:32 -0300 writes:

    Carlos> So, is there another package to substitute those
    Carlos> functions described on "ORPHANED" npmc package ?

May be not.
But nobody stops you from becoming the new maintainer of the
package, fix it such that it passes 'R CMD check' (for R-2.2.0)
and resubmit it to CRAN; so it won't be orphaned anymore ...

    Carlos> Regards,
    Carlos> Mauricio
    Carlos> Brazil

Regards,
Martin Maechler, ETH Zurich

    Carlos> Uwe Ligges escreveu:

    >> Carlos Mauricio Cardeal Mendes wrote:
    >> 
    >>> Hi
    >>> 
    >>> Does anyone know where is the package: npmc (Nonparametric Multiple 
    >>> Comparisons).
    >>> 
    >>> I found the reference on R Site Search, but not the package itself on 
    >>> CRAN as suggested.
    >> 
    >> 
    >> The packages is "ORPHANED" and removed from the CRAN main repository. 
    >> You can get older versions from the archives, though:
    >> 
    >> your-CRAN-mirror/src/contrib/Archive/N/npmc_1.0-1.tar.gz
    >> 
    >> Uwe Ligges
    >> 
    >>> Thanks
    >>> 
    >>> Mauricio
    >>>



From greg.snow at ihc.com  Thu Oct 20 17:37:12 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Thu, 20 Oct 2005 09:37:12 -0600
Subject: [R] creating a derived variable in a data frame
Message-ID: <s357655e.062@lp-msg1.co.ihc.com>

>>>> "Martin Henry H. Stevens" <HStevens at MUOhio.edu> 10/20/05 08:47AM
>>>
>Hi Avram-
>How many countries do you have?
>I would do it the following way because it is simple and I don't know 

>any better, even if it is  absurdly painstaking.
>
>#Step 1
>mydata$continent <- factor(NA, levels=c("NoAm","Euro"))
>
>#Steps 2 a-z
>mydata$continent[mydata$country=="US" |
>                                 mydata$country=="CA" |
>                                mydata$country=="MX" ]  <- "NoAm"

A shorter alternative to the above is to use %in% like:

mydata$continent[ mydata$country %in% c("US","CA","MX") ] <- "NoAm"

You could also create a new data frame with 2 columns for the country
and 
corresponding continent, then merge this with your data (see ?merge).

>
>#Repeat for all countries and continents.
>
>Hank
>
>
>On Oct 19, 2005, at 8:09 PM, Avram Aelony wrote:
>
>> Hello,
>>
>> I have read through the manuals and can't seem to find an answer.
>>
>> I have a categorical, character variable that has hundreds of  
>> values.  I want to group the existing values of this variable into 

>> a new, derived (categorical) variable by applying conditions to the 

>> values in the data.
>>
>> For example, suppose I have a data frame with variables: date,  
>> country, x, y, and z.
>>
>> x,y,z are numeric and country is a 2-digit character string.  I  
>> want to create a new derived variable named "continent" that would 

>> also exist in the data frame. The Continent variable would have  
>> values of "Asia", "Europe", "North America", etc...
>>
>> How would this best be done for a large dataset (>10MB) ?
>> I have tried many variations on following without success (note in 

>> a real example I would have a longer list of countries and  
>> continent values):
>>
>>
>>> mydata$continent <- mydata[ mydata$country==list 
>>> ('US','CA','MX'), ] -> "North America"
>>>
>>
>> I have read about factors, but I am not sure how they apply here.
>>
>> Can anyone help me with the syntax?  I am sure it is trivial and a 

>> common thing to do.
>> The ultimate goal is to compute percentages of x by continent.
>>
>> Thanks for any help in advance.
>>
>> -Avram
>


Greg Snow, Ph.D.
Statistical Data Center, LDS Hospital
Intermountain Health Care
greg.snow at ihc.com
(801) 408-8111



From 042045003 at fudan.edu.cn  Thu Oct 20 17:55:58 2005
From: 042045003 at fudan.edu.cn (ronggui)
Date: Thu, 20 Oct 2005 23:55:58 +0800
Subject: [R] search a value in variables dataset
Message-ID: <0IOO0078Q13TXR@mail.fudan.edu.cn>



======= 2005-10-20 22:50:07 ÄúÔÚÀ´ÐÅÖÐÐ´µÀ£º=======

>Muhammad Subianto wrote:
>
>> Dear R-list,
>> I have a dataset, say (the real dataset is 20 columns,110200 rows).
>> 
>>  > my.reducedID
>>        V1 V2 V3 V4 V5 V6 V7  V8  V9
>>   [1,]  1  0  0  1 14  3  1   0   2
>>   [2,]  2  0  0  1 14  3  1   0   2
>>   [3,]  0  1  0  1 14  2  1   0   2
>>   [4,]  0  0  1  1 14  3  1   0   2
>>   [5,]  0  1  1  0 14  2  1   0   2
>>   [6,]  0  0  0  1 14  3  1   0   2
>>   [7,]  0  0  0  1  0  3  1   0   2
>>   [8,]  0  0  0  1  1  3  1   0   2
>>   [9,]  0  0  0  1  2  3  1   0   2
>> [10,]  0  0  0  1  3  3  1   0   2
>> [11,]  0  0  0  1  4  3  1   0   2
>> [12,]  0  0  0  1  5  3  1   0   2
>> [13,]  0  0  0  1  6  3  1   0   2
>> [14,]  0  0  0  1  7  3  1   0   2
>> [15,]  0  0  0  1  8  3  1   0   2
>> [16,]  0  0  0  1  9  3  1   0   2
>> [17,]  0  0  0  1 10  3  1   0   2
>> [18,]  0  0  0  1 11  3  1   0   2
>> [19,]  0  0  0  1 12  3  1   0   2
>> [20,]  0  0  0  1 13  3  1   0   2
>> [21,]  0  0  0  1 15  3  1   0   2
>> [22,]  0  0  0  1 16  3  1   0   2
>> [23,]  0  0  0  1 17  3  1   0   2
>> [24,]  0  0  0  1 18  3  1   0   2
>> [25,]  0  0  0  1 19  3  1   0   2
>> [26,]  0  0  0  1 20  3  1   0   2
>> [27,]  0  0  0  1 14  0  1   0   2
>> [28,]  0  0  0  1 14  1  1   0   2
>> [29,]  0  0  0  1 14  2  1   0   2
>> [30,]  0  0  0  1 14  4  1   0   2
>>  >
>> 
>> I want to search a value in variables, say V1=0, V5=14 and V6=2.
>> The result should look like
>>        V1 V2 V3 V4 V5 V6 V7  V8  V9
>>   [3,]  0  1  0  1 14  2  1   0   2
>>   [5,]  0  1  1  0 14  2  1   0   2
>> [29,]  0  0  0  1 14  2  1   0   2
>> 
>> I can do this with: my.reducedID[c(3,5,29),]
>> Because I have very large dataset I can not make this manual.
>> Then I need the ID of row did not change, I mean like,
>> [3,]
>> [5,]
>> [29,]
>> In dataset this is about ID our customers.
>> I was wondering if anyone give me a trick to make simple.
>> Thanks you very much for any suggestions.
>
>Without having tested:
>   with(my.reducedID, rownames(V1==0 & V5==14 & V6==2))
>
It doesn't work.
> with(my.reducedID, rownames(V1==0 & V5==14 & V6==2))
NULL

But the following does
> my.reducedID[with(my.reducedID, (V1==0 & V5==14 & V6==2)),]
      V1 V2 V3 V4 V5 V6 V7 V8 V9
[3,]   0  1  0  1 14  2  1  0  2
[5,]   0  1  1  0 14  2  1  0  2
[29,]  0  0  0  1 14  2  1  0  2

>Uwe Ligges
>
>> Best, Muhammad Subianto
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

= = = = = = = = = = = = = = = = = = = =
			


 

2005-10-20

------
Deparment of Sociology
Fudan University

My new mail addres is ronggui.huang at gmail.com
Blog:http://sociology.yculblog.com



From valdar at well.ox.ac.uk  Thu Oct 20 18:13:58 2005
From: valdar at well.ox.ac.uk (William Valdar)
Date: Thu, 20 Oct 2005 17:13:58 +0100 (BST)
Subject: [R] survreg anova: problem with indirect invocation
In-Reply-To: <mailman.13.1129802402.23915.r-help@stat.math.ethz.ch>
References: <mailman.13.1129802402.23915.r-help@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.63.0510201640070.6866@zeon.well.ox.ac.uk>

Dear R help,

I've encountered a problem with survreg's anova(). I am currently 
writing general code to fit a variety of models using different fitting 
functions. Here's a simple example of what I'm trying to do:

---begin code---

# general function to analyse data
analyse.data <- function(formula, FUN, data, ...)
{
     fit <- FUN(formula, data=data, ...)
     anova(fit)
}

---end code---

In theory I should be able to call analyse.data() specifying FUN as I 
please. In practice FUN=lm and FUN=glm work but FUN=survreg does not. 
For example:

---begin code---

library(survival)

data <- data.frame(
         y = rexp(100, rate=1),
         status = rbinom(100,1,prob=0.8),
         x = rnorm(100))

# analyse as lm
formula <- as.formula("y ~ x")
analyse.data(formula, FUN=lm, data=data)
# works!

# analyse as glm
formula <- as.formula("y ~ x")
analyse.data(formula, FUN=glm, data=data, family="Gamma")
# works!

# analyse as survival
formula <- as.formula("Surv(y, status) ~ x")
analyse.data(formula, survreg, data=data)
# Error in eval(expr, envir, enclos) : couldn't find function "FUN"

# check survival works outside function
fit <- survreg(formula, data)
anova(fit)
# works!

---end code---

I suspect this is something to do with parent frames in anova.survreg(). 
However, although R mentions anova.survreg on traceback(), the code for 
this function seems not to be viewable.

I couldn't find any other positings about this. Any suggestions?

Note: I am using R version 2.1.1 and "survival" package version 2.18.

Many thanks,

William

=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
Dr William Valdar               ++44 (0)1865 287 717
Wellcome Trust Centre           valdar at well.ox.ac.uk
for Human Genetics, Oxford      www.well.ox.ac.uk/~valdar



From twood at fortmasoncapital.com  Thu Oct 20 18:15:44 2005
From: twood at fortmasoncapital.com (Thomas Wood)
Date: Thu, 20 Oct 2005 09:15:44 -0700
Subject: [R] Optim with two constraints
Message-ID: <4357C2B0.5030109@fortmasoncapital.com>


   Alexis,
   WIKI:
   You  create  the  box  constraints with two inequality constraints for
   each  element.    Suppose  that you have five elements, and your upper
   bound is .33, and your lower bound is 0.   Then quadprog would require
   constraints as:
   A[1,]=(1,0,0,0,0)    b=(0)
   A[2,]=(-1,0,0,0,0)   b=(-.33)
   A[3,]=(0,1,0,0,0)     b=(0)
   A[4,]=(0,-1,0,0,0)      b=(-.33)
   .....and so on.
   The  syntax  is  not  quite correct but you get the picture.  Remember
   that   quadprog   distinguishes   between   equality   and  inequality
   constraints,  and  these must be inequality constraints.  The trick to
   the  upper  bound  is to multiply the constraint by -1 (as indicated),
   which  effectively translates the constraint from a <= constraint into
   the >= type of constraint required by quadprog.
   Regards,
   Tom
   Alexis Diamond wrote:

   I  have  a  follow-up  from  Jens's  question  and  Professor Ripley's
   response. Jens wants to do quadratic optimization with 2 constraints:

> > > # I need two constraints:
> > > # 1. each element in par needs to be between 0 and 1
> > >  # 2. sum(par)=1, i.e. the elements in par need to sum to 1
        

how does one set both constraints in quadprog, per Prof. Ripley's suggestion?

i know how to get quadprog to handle the second constraint, but not
BOTH, since quadprog only takes as inputs the constraint matrix "A"
and constraint vector "b"--
unlike in "ipop" (kernlab), there is no additional option for box constraints.

apologies if i am not seeing something obvious here.

thanks in advance,

alexis

  

   --

   Tom Wood
   Fort Mason Capital
   456 Montgomery Street 22nd Floor
   San Francisco, CA 94104
   Direct: 415-249-3387
   Fax: 415-249-3389
   [1]twood at fortmasoncapital.com

References

   1. mailto:twood at fortmasoncapital.com


From andrea.johnson at roche.com  Thu Oct 20 18:21:00 2005
From: andrea.johnson at roche.com (Johnson, Andrea)
Date: Thu, 20 Oct 2005 09:21:00 -0700
Subject: [R] creating a derived variable in a data frame
Message-ID: <635EC88D70B3C940940C031CE764D8D001005E47@rpbmsem01.nala.roche.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051020/7e552a28/attachment.pl

From rbaer at atsu.edu  Thu Oct 20 18:35:40 2005
From: rbaer at atsu.edu (Robert Baer)
Date: Thu, 20 Oct 2005 11:35:40 -0500
Subject: [R] forrest plot
References: <000f01c5d57d$fa231a80$0200a8c0@Michela>
Message-ID: <00ec01c5d594$4ec274d0$6d0d010a@BigBaer>

Try:
metaplot(mn=c(-0.28174,-0.71444,-0.12375,-0.12426,-0.30011,-0.45058,-0.07324
),se=c(0.20766,0.42691,0.26366,0.30357,0.31819,0.28636,0.37758),xlab="HR and
95%CI",logeffect=T,xaxt="n",xlim=c(-1.7,1.7))

axis(side=1,at=c(0.2,0.3,0.6,1.0,1.4,2.0,3.0,5.4),labels=c(0.2,0.3,0.6,1.0,1
4,2.0,3.0,5.4))

Rob
____________________________
Robert W. Baer, Ph.D.
Associate Professor
Department of Physiology
A. T. Still University of Health Science
800 W. Jefferson St.
Kirksville, MO 63501-1497 USA
----- Original Message ----- 
From: "Michela Ballardini" <m.ballardini at ior-forli.it>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, October 20, 2005 8:55 AM
Subject: [R] forrest plot


Hello
I'm trying to plot hazard risk values using the function metaplot with
 the specifications:

metaplot(mn=c(-0.28174,-0.71444,-0.12375,-0.12426,-0.30011,-0.45058,-0.07324
),se=c(0.20766,0.42691,0.26366,0.30357,0.31819,0.28636,0.37758),xlab="HR and
95%CI",logeffect=T,xaxt="n")

axis(side=1,at=c(0,0.2,0.4,0.6,0.8,1.0,1.2,1.4,1.6,1.8,2.0),labels=c(0,0.2,0
4,0.6,0.8,1.0,1.2,1.4,1.6,1.8,2.0))



However, in the plot the x axis is on a log scale and tends to overextend
the left end of the axis. How can I transform the x-scale on a linear scale
with equidistant points?


Thank you very much for your attenction

Mic

**************************************
Dr.ssa Michela Ballardini
Unit?? di Biostatistica e Sperimentazioni Cliniche
c/o Osp. Morgagni-Pierantoni - Pad. Valsalva
Via Forlanini, 34
47100 Forl??
Tel 0543-731836
Tel/Fax 0543-731612
**************************************


[[alternative HTML version deleted]]




----------------------------------------------------------------------------
----


> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From lamac_k at hotmail.com  Thu Oct 20 18:47:34 2005
From: lamac_k at hotmail.com (lamack lamack)
Date: Thu, 20 Oct 2005 16:47:34 +0000
Subject: [R] select only the numeric variables
Message-ID: <BAY113-F9A150699945F1E811CFDE99730@phx.gbl>

Dear all, how can I select only the numeric (or character) variables from a
date.frame?

Best regards



From mario.aignertorres at gmail.com  Thu Oct 20 18:52:09 2005
From: mario.aignertorres at gmail.com (Mario Aigner-Torres)
Date: Thu, 20 Oct 2005 14:52:09 -0200
Subject: [R] adding error bars to lattice plots
In-Reply-To: <200510192219.j9JMJIEo018489@ohm.gene.com>
References: <af34d0c00510191434v23e2be42v493570589417deec@mail.gmail.com>
	<200510192219.j9JMJIEo018489@ohm.gene.com>
Message-ID: <af34d0c00510200952u54663a70o73e6f115622b58c8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051020/f9b2993f/attachment.pl

From ahertel at atmos.uiuc.edu  Thu Oct 20 19:03:16 2005
From: ahertel at atmos.uiuc.edu (Anne Hertel)
Date: Thu, 20 Oct 2005 12:03:16 -0500
Subject: [R] Cross-correlation function
Message-ID: <web-7143020@atmos.uiuc.edu>

Hello All,

I'm having trouble with the ccf() function. I am trying to do cross-correlation between two time-series, but I keep getting an error message I don't know what to do with. This what I type and the error message I get:

> ccf(ts(mod[,1]),ts(mod[,2]),na.action='na.exclude',type='cor')
Error in "colnames<-"(`*tmp*`, value = c("ts(mod[, 1])", "ts(mod[, 2])" : 
        attempt to set colnames on object with less than two dimensions

Can anybody see what is wrong and what I need to do different?

Thanks,
Anne Hertel


------------------------------------------------------------
Anne M. K. Hertel
Grad. Student & Research Assistant
Department of Atmospheric Sciences
University of Illinois at Urbana-Champaign
Annex II, room 204
Phone: (217) 333 6296



From uofiowa at gmail.com  Thu Oct 20 19:18:43 2005
From: uofiowa at gmail.com (Omar Lakkis)
Date: Thu, 20 Oct 2005 13:18:43 -0400
Subject: [R] suppress messages on loading its
Message-ID: <3f87cc6d0510201018w56e0a39bp8d0bb2b9965b0afa@mail.gmail.com>

On loading the package: its, I get the "Creating a new generic
function for" messages below even when I wrap the call with
capture.output. Is there a way to suppress these messages?

> dummy=capture.output( library(its) )
Creating a new generic function for 'names' in 'its'
Creating a new generic function for 'names<-' in 'its'
Creating a new generic function for 'print' in 'its'
Creating a new generic function for 'start' in 'its'
Creating a new generic function for 'end' in 'its'
Creating a new generic function for 'summary' in 'its'
Creating a new generic function for 'diff' in 'its'
Creating a new generic function for 'union' in 'its'
Creating a new generic function for 'intersect' in 'its'



From tom at maladmin.com  Thu Oct 20 15:26:05 2005
From: tom at maladmin.com (tom wright)
Date: Thu, 20 Oct 2005 09:26:05 -0400
Subject: [R] Filter design in R?
In-Reply-To: <4356BF52.4080606@gmail.com>
References: <4356BF52.4080606@gmail.com>
Message-ID: <1129814765.6835.32.camel@localhost.localdomain>

On Wed, 2005-19-10 at 17:49 -0400, Israel Christie wrote:
> Dr. Williams,
> I ran across your inquiry on one of the R-help mailing lists regarding 
> digital filter design and implementation. I found no response to your 
> email in the archives and was wondering if you were able to find anything.
> 
> Thanks,
> Israel

I'm not Dr Williams, but I've been doing some work on filter design
recently. I'm also no expert in this area but I found some very useful
resources, primarily the online book "The scientist and engineers guide
to digital signal processing" http://www.dspguide.com

I came up with some code for generating simple highpass; low pass and
bandpass filters, the filters can be applied using the filter() function


Since I'm no expert here I'd really appreciate any comment from people
who know more than me about these techniques.

Regards
Tom

> ================== BEGIN USAGE CODE==================
> t<-c(1:1000)/1000     #timeline 1KHz
> s1<-sin(2*pi*t*3)     #3Hz waveform
> s2<-sin(2*pi*t*5)     #5Hz waveform
> s3<-sin(2*pi*t*10)    #10Hz waveform
> 
> stot<-s1+s2+s3                #complex waveform
> 
> plot(stot,type='l')
> 
> #create the filter, the longer it is the better cutoff
> #length must be an even number
> f<-calcbpfilt(length=900,samplerate=1000,lowfreq=7,highfreq=4) 
> 
> sfilt<-filter(stot,f,circular=TRUE)   #apply the filter
> 
> lines(sfilt,type='l',col='red')               
> #only the 5Hz freq should be let through
> 
> ================== END USAGE CODE==================
==============BEGIN CODE=================
calclpfilt<-function(length,fc){
    
    t<-c(0:length+1)
    for (val in t){
        if(val-length/2==0){
            f[val]<-as.numeric(2*pi*fc)
        }else{

f[val]<-as.numeric(sin(2*pi*fc*(val-length/2))/(val-length/2))
        }
        f[val]=as.numeric(f[val])*(0.54-0.46*cos(2*pi*val/length))
    }
    #f<-convolve(f,f)
    #normalise filter

    filt.total<-sum(as.numeric(f))
    f<-as.numeric(f)/filt.total
}

calcbpfilt<-function(length,samplerate,lowfreq,highfreq){
    f.low<-list()
    f.high<-list()

    fc.low<-1/(samplerate/lowfreq)
    fc.high<-1/(samplerate/highfreq)

    t<-c(0:length+1)

#calculate the lowpass filter
    for (val in t){
        if(val-length/2==0){
            f.low[val]<-as.numeric(2*pi*fc.low)
        }else{

f.low[val]<-as.numeric(sin(2*pi*fc.low*(val-length/2))/(val-length/2))
        }

f.low[val]=as.numeric(f.low[val])*(0.54-0.46*cos(2*pi*val/length))
    }
    #f<-convolve(f,f)
    #normalise filter

    filt.total<-sum(as.numeric(f.low))
    f.low<-as.numeric(f.low)/filt.total

#calculate the second filter
    for (val in t){
        if(val-length/2==0){
            f.high[val]<-as.numeric(2*pi*fc.high)
        }else{

f.high[val]<-as.numeric(sin(2*pi*fc.high*(val-length/2))/(val-length/2))
        }

f.high[val]=as.numeric(f.high[val])*(0.54-0.46*cos(2*pi*val/length))
    }
    #f<-convolve(f,f)
    #normalise filter

    filt.total<-sum(as.numeric(f.high))
    f.high<-as.numeric(f.high)/filt.total

#invert the high filter to make it high pass

    f.high<-0-f.high
    f.high[length/2]<-f.high[length/2]+1

#add lowpass filterkernal and highpass filter kernel
#makes band reject filter
    f.bandreject<-f.low+f.high

#make band pass by spectral inversion
    f.bandpass<-0-f.bandreject
    f.bandpass[length/2]<-f.bandpass[length/2]+1
    f.bandpass
}
==============END CODE=================



From chrysopa at gmail.com  Thu Oct 20 19:33:18 2005
From: chrysopa at gmail.com (Ronaldo Reis-Jr.)
Date: Thu, 20 Oct 2005 15:33:18 -0200
Subject: [R] lmer and grouping fators
Message-ID: <200510201533.18954.chrysopa@gmail.com>

Hi,

I make this model using lme

m.lme <- lme(Glycogen~Treatment,random=~1|rTrt/Liver)

How to make this using lmer?

I try

> m.lmer <- lmer(Glycogen~Treatment+(1|rTrt/Liver))
Erro em lmer(Glycogen ~ Treatment + (1 | rTrt/Liver)) : 
	entry 0 in matrix[0,0] has row 2147483647 and column 2147483647
Al??m disso: Mensagem de aviso:
/ not meaningful for factors in: Ops.factor(rTrt, Liver) 

lmer dont accept / for make nesting or splitplot analysis?

Thanks

Ronaldo

ps. where I can find more lmer documentation?
-- 
The Eiffel Tower <--> Feel hotter wife
                -- anagrama
--
|>   // | \\   [***********************************]
|   ( ??   ?? )  [Ronaldo Reis J??nior                ]
|>      V      [UFV/DBA-Entomologia                ]
|    /     \   [36570-000 Vi??osa - MG              ]
|>  /(.''`.)\  [Fone: 31-3899-4007                 ]
|  /(: :'  :)\ [chrysopa at insecta.ufv.br            ]
|>/ (`. `'` ) \[ICQ#: 5692561 | LinuxUser#: 205366 ]
|    ( `-  )   [***********************************]
|>>  _/   \_Powered by GNU/Debian Woody/Sarge



From lizzylaws at yahoo.com  Thu Oct 20 19:37:19 2005
From: lizzylaws at yahoo.com (Elizabeth Lawson)
Date: Thu, 20 Oct 2005 10:37:19 -0700 (PDT)
Subject: [R] goodfit par estimates
Message-ID: <20051020173719.90392.qmail@web32113.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051020/d87a6037/attachment.pl

From andreas.zankl at gmail.com  Thu Oct 20 19:55:52 2005
From: andreas.zankl at gmail.com (Andreas Zankl)
Date: Thu, 20 Oct 2005 19:55:52 +0200
Subject: [R] how to set environment variables?
In-Reply-To: <Pine.LNX.4.61.0510201604380.19384@gannet.stats>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED514@usctmx1106.merck.com>
	<Pine.LNX.4.61.0510201604380.19384@gannet.stats>
Message-ID: <a06230902bf7d89b97341@[10.0.1.4]>

Renviron is in an odd places on Macs:
/Library/Frameworks/R.framework/Versions/2.1.1/Resources/etc/Renviron

As suggested in ?Startup, I added the R_GSCMD variable to 
Renviron.site instead.

Thanks for your help
Andreas



>
>
>>See the first paragraph of ?Startup.
>
>If this is literally `Renviron' (not ~/.Renviron or Renviron.site) 
>see also the Note in that help file.
>
>>
>>Andy
>>
>>>From: Andreas Zankl
>>>
>>>Thanks. Sys.putenv did work, however this has to be set every
>>>time I start R.
>>>
>>>gs is on my path and works fine under Unix, but I get the following
>>>error when running bitmap (without setting R_GSCMD first):
>>>
>>>/bin/sh: line 1: gs: command not found
>>>
>>>I assume the problem is related to the fact that I am using the csh
>>>shell, while the new Mac OS X default shell is now bash. So I guess
>>>my .csh path settings are ignored by R calling bash. I solved the
>>>problem by adding my R_GSCMD settings to the Renviron file
>>>(R_GSCMD=${RGSCMD-'/sw/bin/gs'} in my case). Hope this helps anyone
>>>with the same problem.
>>>
>>>Thanks again for your help!
>>>Andreas
>>>
>>>
>>>
>>>At 12:51 +0100 20.10.2005, Prof Brian Ripley wrote:
>>>>On Thu, 20 Oct 2005, Andreas Zankl wrote:
>>>>
>>>>>The help file of the R bitmap function says that I have to set the
>>>>>environment variable R_GSCMD to the path of my Ghostscript
>>>>>installation.
>>>>
>>>>Actually, it does not say that.  It says you _can_ specify the path
>>>>to your executable (not the installation) that way. It will work
>>>>without doing so if the executable 'gs' (on a Unix-alike) is on your
>>>>path, which it normally is on Unix-alikes.
>>>>
>>>>>How do I set this variable (either by commandline or in
>>>>>R.app for Mac)? Sorry if this sounds like a very basic question, but
>>>>>I could not find the answer anywhere else.
>>>>
>>>>?Sys.putenv for how to do it from R.  help.search("environment
>>>>variable") got me there.
>>>>
>>>>--
>>>>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>>>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>>>University of Oxford,             Tel:  +44 1865 272861 (self)
>>>>1 South Parks Road,                     +44 1865 272866 (PA)
>>>>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>>
>>>
>>>--
>>>PLEASE NOTE MY NEW EMAIL ADDRESS: ANDREAS.ZANKL at GMAIL.COM
>>>
>>>--------------------------
>>>Andreas Zankl, MD
>>>Division of Molecular Pediatrics
>>>Clinique Infantile 02/50
>>>CHUV
>>>Avenue Pierre Decker 2
>>>CH-1011 Lausanne
>>>Switzerland
>>>Phone: +41-21-3143778
>>>Fax: +41-21-3143546
>>>Email: andreas.zankl at gmail.com
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide!
>>>http://www.R-project.org/posting-guide.html
>>>
>>
>>
>>------------------------------------------------------------------------------
>>Notice:  This e-mail message, together with any attachments, 
>>contains information of Merck & Co., Inc. (One Merck Drive, 
>>Whitehouse Station, New Jersey, USA 08889), and/or its affiliates 
>>(which may be known outside the United States as Merck Frosst, 
>>Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be 
>>confidential, proprietary copyrighted and/or legally privileged. It 
>>is intended solely for the use of the individual or entity named on 
>>this message.  If you are not the intended recipient, and have 
>>received this message in error, please notify us immediately by 
>>reply e-mail and then delete it from your system.
>>------------------------------------------------------------------------------
>>
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tlumley at u.washington.edu  Thu Oct 20 20:19:53 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 20 Oct 2005 11:19:53 -0700 (PDT)
Subject: [R] forrest plot
In-Reply-To: <000f01c5d57d$fa231a80$0200a8c0@Michela>
References: <000f01c5d57d$fa231a80$0200a8c0@Michela>
Message-ID: <Pine.LNX.4.63a.0510201034290.28674@homer22.u.washington.edu>


metaplot() will not currently do asymmetric confidence intervals, which 
seems to be what you want.  I'm making a revised version based on Paul 
Murrell's grid example at
   http://www.stat.auckland.ac.nz/~paul/RGraphics/examples-table.png
which will be more flexible.

 	-thomas

On Thu, 20 Oct 2005, Michela Ballardini wrote:

> Hello
> I'm trying to plot hazard risk values using the function metaplot with
> the specifications:
>
> metaplot(mn=c(-0.28174,-0.71444,-0.12375,-0.12426,-0.30011,-0.45058,-0.07324),se=c(0.20766,0.42691,0.26366,0.30357,0.31819,0.28636,0.37758),xlab="HR and 95%CI",logeffect=T,xaxt="n")
>
> axis(side=1,at=c(0,0.2,0.4,0.6,0.8,1.0,1.2,1.4,1.6,1.8,2.0),labels=c(0,0.2,0.4,0.6,0.8,1.0,1.2,1.4,1.6,1.8,2.0))
>
>
>
> However, in the plot the x axis is on a log scale and tends to overextend the left end of the axis. How can I transform the x-scale on a linear scale with equidistant points?
>
>
> Thank you very much for your attenction
>
> Mic
>
> **************************************
> Dr.ssa Michela Ballardini
> Unità di Biostatistica e Sperimentazioni Cliniche
> c/o Osp. Morgagni-Pierantoni - Pad. Valsalva
> Via Forlanini, 34
> 47100 Forlì
> Tel 0543-731836
> Tel/Fax 0543-731612
> **************************************
>
>
> 	[[alternative HTML version deleted]]
>
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

From ccleland at optonline.net  Thu Oct 20 20:25:34 2005
From: ccleland at optonline.net (Chuck Cleland)
Date: Thu, 20 Oct 2005 14:25:34 -0400
Subject: [R] select only the numeric variables
In-Reply-To: <BAY113-F9A150699945F1E811CFDE99730@phx.gbl>
References: <BAY113-F9A150699945F1E811CFDE99730@phx.gbl>
Message-ID: <4357E11E.9090203@optonline.net>

library(MASS)
anorexia[,sapply(anorexia, is.numeric)]

lamack lamack wrote:
> Dear all, how can I select only the numeric (or character) variables from a
> date.frame?
> 
> Best regards
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From sundar.dorai-raj at pdf.com  Thu Oct 20 20:25:13 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 20 Oct 2005 13:25:13 -0500
Subject: [R] select only the numeric variables
In-Reply-To: <BAY113-F9A150699945F1E811CFDE99730@phx.gbl>
References: <BAY113-F9A150699945F1E811CFDE99730@phx.gbl>
Message-ID: <4357E109.6040904@pdf.com>



lamack lamack wrote:
> Dear all, how can I select only the numeric (or character) variables from a
> date.frame?
> 
> Best regards
> 

Try:

x[sapply(x, is.numeric)]

x[sapply(x, is.character)]

where `x' is your data.frame.

--sundar



From maustin at amgen.com  Thu Oct 20 20:31:37 2005
From: maustin at amgen.com (Austin, Matt)
Date: Thu, 20 Oct 2005 11:31:37 -0700
Subject: [R] adding error bars to lattice plots
Message-ID: <E7D5AB4811D20B489622AABA9C53859109DAD311@teal-exch.amgen.com>

Have you looked at xYplot and panel.xYplot from Dr. Harrell's Hmisc package?

--Matt

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Mario
> Aigner-Torres
> Sent: Thursday, October 20, 2005 9:52 AM
> To: Berton Gunter; r-help at stat.math.ethz.ch
> Subject: Re: [R] adding error bars to lattice plots
> 
> 
> Thanks Bert!
> 
> I have right now a dataset that looks like this:
> 
> > tail(partition, 3)
> element run logfO2 TC buffer xAn sdXan Di Disigma
> 416 Al 36 -0.68 1180 AIR 0.734 0.007 2.10 0.02
> 417 Ca 36 -0.68 1180 AIR 0.734 0.007 1.29 0.02
> 418 Na 36 -0.68 1180 AIR 0.734 0.007 1.16 0.06
> 
> Basicaly I would like to insert error bars into a xyplot like this
> 
> > xyplot(log10(Di) ~ TC | element.ord, groups=buffer.ord, #pch=16,
> + #subset=no1140,
> + data=partition,
> + auto.key=list(columns=3),
> + )
> 
> How could llines, lsegments or perhaps panel.arrows look like?
> 
> I appreciate any help on this.
> 
> Best regards,
> 
> Mario
> 
> 
> On 10/19/05, Berton Gunter <gunter.berton at gene.com> wrote:
> >
> > ?llines, lsegments and the like can be used in the panel 
> functions to draw
> > any sort of error bar that you can compute from the x,y,... 
> data of the
> > panel.
> >
> > -- Bert Gunter
> > Genentech Non-Clinical Statistics
> > South San Francisco, CA
> >
> > "The business of the statistician is to catalyze the 
> scientific learning
> > process." - George E. P. Box
> >
> >
> >
> > > -----Original Message-----
> > > From: r-help-bounces at stat.math.ethz.ch
> > > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Mario
> > > Aigner-Torres
> > > Sent: Wednesday, October 19, 2005 2:34 PM
> > > To: r-help at stat.math.ethz.ch
> > > Subject: [R] adding error bars to lattice plots
> > >
> > > Dear R-Users,
> > >
> > > how to include error bars within lattice?
> > > How should the panel = function(x,y,...){
> > > looks like?
> > > Does panel.arrows works here as well?
> > >
> > > I appreciate any help on this.
> > >
> > > Regards,
> > >
> > > Mario AT
> > >
> > > [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> > >
> >
> >
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html



From vdooren at rulsfb.leidenuniv.nl  Thu Oct 20 20:33:47 2005
From: vdooren at rulsfb.leidenuniv.nl (Tom Van Dooren)
Date: Thu, 20 Oct 2005 20:33:47 +0200
Subject: [R] different F test in drop1 and anova
In-Reply-To: <Pine.LNX.4.61.0510201227160.10800@gannet.stats>
References: <4357629F.3070104@rulsfb.leidenuniv.nl>
	<Pine.LNX.4.61.0510201227160.10800@gannet.stats>
Message-ID: <4357E30B.4060909@rulsfb.leidenuniv.nl>

Hi Brian,
well I wanted a test based on quasibinomial...
Does it work like this then?:

x<-gl(3,2)
y<-c(0,1,0,0,1,1)

# quasibinomial models #
########################

qb1<-glm(y~x,quasibinomial)
qb2<-glm(y~1,quasibinomial)

qbdev<-(qb2$dev-qb1$dev)

qbdev # deviance I

qbdev/(qb2$df.res-qb1$df.res)/(qb1$dev /qb1$df.res) # deviance ratio II

qbdev/summary(qb1)$disp # scaled deviance III

qbdev/(qb2$df.res-qb1$df.res)/summary(qb1)$disp # scaled deviance IV


anova(qb2,qb1,test="Chisq") # Chisq test based on I
drop1(qb1,test="F") # F test, based on II
drop1(qb1,test="Chisq") # Chisq test, based on III
anova(qb2,qb1,test="F") # F test, based on IV

# binomial models #
###################

b1<-glm(y~x,binomial)
b2<-glm(y~1,binomial)

bdev<-(b2$dev-b1$dev)

bdev # deviance I

bdev/(b2$df.res-b1$df.res)/(b1$dev /b1$df.res) # deviance ratio II


drop1(b1,test="Chisq") # Chisq test, based on I
anova(b2,b1,test="Chisq") # Chisq test based on I
anova(b2,b1,test="F") # Chisq test, based on I
drop1(b1,test="F") # F test, based on II


Cheers, Tom

PS: thanks Tord ;)



From sabolk at hotmail.com  Thu Oct 20 20:46:25 2005
From: sabolk at hotmail.com (Keith Sabol)
Date: Thu, 20 Oct 2005 14:46:25 -0400
Subject: [R] Boxplot labels
Message-ID: <BAY114-F2314BD8A62D7DE6D0F1502D7730@phx.gbl>

I am creating boxplots from a dataframe and would like to add to the 
standard output a marker representing the value from a particular row in the 
dataframe.

.....And I apologize if the solution is as trivial as it seems it should be.

Thanks for any assistance.

Keith



From gerifalte28 at hotmail.com  Thu Oct 20 21:29:45 2005
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Thu, 20 Oct 2005 19:29:45 +0000
Subject: [R] goodfit par estimates
In-Reply-To: <20051020173719.90392.qmail@web32113.mail.mud.yahoo.com>
Message-ID: <BAY103-F259CD820740387555D5FA3A6730@phx.gbl>

Are you trying to obtain the MLE parameter estimates?  If so, in your 
example you just need to use fit$par.

Cheers

Francisco


>From: Elizabeth Lawson <lizzylaws at yahoo.com>
>To: r-help at stat.math.ethz.ch
>Subject: [R] goodfit par estimates
>Date: Thu, 20 Oct 2005 10:37:19 -0700 (PDT)
>
>Hey,
>
>Does anyone know if there is a way to get back from goodfit what it 
>estimated the parameters to be?
>
>I used the code
>
>fit<-goodfit(round(data$PLX_NRX),type="nbinomial"
>
>and got a pretty good fit.  I could not however duplicate this good fit 
>with any parameter estimates that I had.
>
>Any ideas???
>
>Thanks,
>
>Elizabeth Lawson
>
>
>---------------------------------
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From dimitrijoe at ipea.gov.br  Thu Oct 20 21:40:10 2005
From: dimitrijoe at ipea.gov.br (Dimitri Szerman)
Date: Thu, 20 Oct 2005 17:40:10 -0200
Subject: [R] spliting an integer
Message-ID: <02ec01c5d5ae$187c9210$5814020a@thesahajamach>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051020/ffdc43b5/attachment.pl

From ripley at stats.ox.ac.uk  Thu Oct 20 21:59:19 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Oct 2005 20:59:19 +0100 (BST)
Subject: [R] suppress messages on loading its
In-Reply-To: <3f87cc6d0510201018w56e0a39bp8d0bb2b9965b0afa@mail.gmail.com>
References: <3f87cc6d0510201018w56e0a39bp8d0bb2b9965b0afa@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0510202056020.26068@gannet.stats>

Those messages mean it has not been installed correctly -- they should 
occur during installation only.

They are written to the message connection, which capture.output does not 
mess with (but sink can).

On Thu, 20 Oct 2005, Omar Lakkis wrote:

> On loading the package: its, I get the "Creating a new generic
> function for" messages below even when I wrap the call with
> capture.output. Is there a way to suppress these messages?
>
>> dummy=capture.output( library(its) )
> Creating a new generic function for 'names' in 'its'
> Creating a new generic function for 'names<-' in 'its'
> Creating a new generic function for 'print' in 'its'
> Creating a new generic function for 'start' in 'its'
> Creating a new generic function for 'end' in 'its'
> Creating a new generic function for 'summary' in 'its'
> Creating a new generic function for 'diff' in 'its'
> Creating a new generic function for 'union' in 'its'
> Creating a new generic function for 'intersect' in 'its'

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mschwartz at mn.rr.com  Thu Oct 20 22:29:59 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Thu, 20 Oct 2005 15:29:59 -0500
Subject: [R] having scaling problems with a histogram
In-Reply-To: <376648927@web.de>
References: <376648927@web.de>
Message-ID: <1129840199.6015.87.camel@localhost.localdomain>

On Thu, 2005-10-20 at 17:31 +0200, Christian Jones wrote:
> 
> Hello,<?xml:namespace prefix = o ns =
> "urn:schemas-microsoft-com:office:office" /><o:p></o:p>
> 
> I would like to create a histogram from a data collumn consisting of 4
> classes (0; 0.05;0.5;25;75). Due to the difference in scale the
> classes 0;0.05 and 0.5 are displayed within one combined bin by
> default with the code:Hist(x, scale="percent", breaks="Sturges"). How
> can I display them all, or as unique classes, leaving out the rest of
> the x_axes scale? There was no enlightenment in the help function and
> the command : breaks=5 did not do the trick.<o:p></o:p>
> 
> Thanks in advance <o:p></o:p>
> 
> Chris<o:p></o:p>

I may be mis-understanding what you are doing here, but it sounds like
you should be using barplot() rather than hist(), which is referenced in
the "See Also" in ?hist. This would be preferred if you want individual
counts or proportions (or percents) from specific groups without
binning.

Where does the 'scale = "percent"' come from?  I don't recognize that
argument from the standard histogram plotting functions. 

Oh, wait a minute, just found it doing a search. The Hist() function is
in John Fox's Rcmdr. Please be sure to note this if you are using a
function from a contributed package. It saves time and increases the
likelihood of your getting a reply.

Also, I am guessing that the extraneous content here is the result of
using MS Word as your e-mail editor? Please use plain text only, which
is the defined format for this list and from reviewing the archive, has
been pointed out to you previously by Frank Harrell and Ted Harding.

HTH,

Marc Schwartz



From mschwartz at mn.rr.com  Thu Oct 20 22:41:13 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Thu, 20 Oct 2005 15:41:13 -0500
Subject: [R] Boxplot labels
In-Reply-To: <BAY114-F2314BD8A62D7DE6D0F1502D7730@phx.gbl>
References: <BAY114-F2314BD8A62D7DE6D0F1502D7730@phx.gbl>
Message-ID: <1129840874.6015.97.camel@localhost.localdomain>

On Thu, 2005-10-20 at 14:46 -0400, Keith Sabol wrote:
> I am creating boxplots from a dataframe and would like to add to the 
> standard output a marker representing the value from a particular row in the 
> dataframe.
> 
> .....And I apologize if the solution is as trivial as it seems it should be.
> 
> Thanks for any assistance.
> 
> Keith

Some example code would be helpful here.

However, some hints that I suspect will be helpful:

1. Unless you use the 'at' argument in boxplot(), the box center
positions are at integer values from 1:n, where n is the number of
groups. 

2. You can thus use the points() function to add symbols or the text()
function to add labels to the existing plot as you may require.
See ?points and/or ?text for more information.

HTH,

Marc Schwartz



From u08adh at hotmail.com  Thu Oct 20 22:44:39 2005
From: u08adh at hotmail.com (Andreas Hary)
Date: Thu, 20 Oct 2005 21:44:39 +0100
Subject: [R] Cross-correlation function
References: <web-7143020@atmos.uiuc.edu>
Message-ID: <BAY103-DAV4E50F28D15A06A16CEB14DF730@phx.gbl>

I have reproduced your error using the following

goo1 <- rnorm(100,0,1)
goo2 <- rnorm(100,0,1)
goo <- cbind(goo1,goo2)
goo[2,1] <- NA

ccf(ts(goo[,1]),ts(goo[,2]),na.action='na.exclude',type='cor')
Error in "colnames<-"(`*tmp*`, value = c("ts(goo[, 1])", "ts(goo[, 2])" :
        attempt to set colnames on object with less than two dimensions


ccf(ts(goo[,1]),ts(goo[,2]),type='cor')
Error in na.fail.default(ts.union(as.ts(x), as.ts(y))) :
        missing values in object

as desired, but

ccf(ts(goo[,1]),ts(goo[,2]),na.action=na.exclude,type='cor')

works fine for me, so removing the quotation marks around the na.exclude 
should do the trick.
Cheers,

Andreas


----- Original Message ----- 
From: "Anne Hertel" <ahertel at atmos.uiuc.edu>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, October 20, 2005 6:03 PM
Subject: [R] Cross-correlation function


> Hello All,
>
> I'm having trouble with the ccf() function. I am trying to do 
> cross-correlation between two time-series, but I keep getting an error 
> message I don't know what to do with. This what I type and the error 
> message I get:
>
>> ccf(ts(mod[,1]),ts(mod[,2]),na.action='na.exclude',type='cor')
> Error in "colnames<-"(`*tmp*`, value = c("ts(mod[, 1])", "ts(mod[, 2])" :
>        attempt to set colnames on object with less than two dimensions
>
> Can anybody see what is wrong and what I need to do different?
>
> Thanks,
> Anne Hertel
>
>
> ------------------------------------------------------------
> Anne M. K. Hertel
> Grad. Student & Research Assistant
> Department of Atmospheric Sciences
> University of Illinois at Urbana-Champaign
> Annex II, room 204
> Phone: (217) 333 6296
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ahertel at atmos.uiuc.edu  Thu Oct 20 22:49:10 2005
From: ahertel at atmos.uiuc.edu (Anne Hertel)
Date: Thu, 20 Oct 2005 15:49:10 -0500
Subject: [R] spliting an integer
In-Reply-To: <02ec01c5d5ae$187c9210$5814020a@thesahajamach>
Message-ID: <web-7143820@atmos.uiuc.edu>

Hi Dimitri,

You could write

> z <- trunc(x/10000)
> z
[1]  1 12  8
> y <- x-trunc(x/10000)*10000
> y
[1] 1999 2000 1997

And there you have it.

Cheers,
Anne Hertel


On Thu, 20 Oct 2005 17:40:10 -0200
 "Dimitri Szerman" <dimitrijoe at ipea.gov.br> wrote:
>Hi there,
>
>>From the vector X of integers,
>
>X = c(11999, 122000, 81997)
>
>I would like to make these two vectors:
>
>Z= c(1999, 2000, 1997)
>Y =c(1 , 12 , 8)
>
>That is, each entry of vector Z receives the four last digits of each entry of X, and Y receives "the rest".
>
>Any suggestions?
>
>Thanks in advance,
>
>Dimitri
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



------------------------------------------------------------
Anne M. K. Hertel
Grad. Student & Research Assistant
Department of Atmospheric Sciences
University of Illinois at Urbana-Champaign
Annex II, room 204
Phone: (217) 333 6296



From br44114 at gmail.com  Thu Oct 20 22:50:17 2005
From: br44114 at gmail.com (bogdan romocea)
Date: Thu, 20 Oct 2005 16:50:17 -0400
Subject: [R] Boxplot labels
Message-ID: <8d5a36350510201350i2271ec37ucd7480e9daefeea3@mail.gmail.com>

Here's one approach.

values <- c(rnorm(1000,-5,1),rnorm(1000,10,0.5))
boxplot(values)
text(1,0,labels="better use violin plots",col="red")
#------
require(vioplot)
vioplot(values)
text(1,0,labels="better than box plots",col="red",pos=4)


> -----Original Message-----
> From: Keith Sabol [mailto:sabolk at hotmail.com]
> Sent: Thursday, October 20, 2005 2:46 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Boxplot labels
>
>
> I am creating boxplots from a dataframe and would like to add to the
> standard output a marker representing the value from a
> particular row in the
> dataframe.
>
> .....And I apologize if the solution is as trivial as it
> seems it should be.
>
> Thanks for any assistance.
>
> Keith
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From sundar.dorai-raj at pdf.com  Thu Oct 20 22:50:16 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 20 Oct 2005 15:50:16 -0500
Subject: [R] spliting an integer
In-Reply-To: <02ec01c5d5ae$187c9210$5814020a@thesahajamach>
References: <02ec01c5d5ae$187c9210$5814020a@thesahajamach>
Message-ID: <43580308.4000202@pdf.com>



Dimitri Szerman wrote:
> Hi there,
> 
>>From the vector X of integers,
> 
> X = c(11999, 122000, 81997)
> 
> I would like to make these two vectors:
> 
> Z= c(1999, 2000, 1997)
> Y =c(1 , 12 , 8)
> 
> That is, each entry of vector Z receives the four last digits of each entry of X, and Y receives "the rest".
> 
> Any suggestions?
> 
> Thanks in advance,
> 
> Dimitri
> 	[[alternative HTML version deleted]]

Try:

X <- c(11999, 122000, 81997)
Y <- X %/% 10000
Z <- X - Y * 10000

See ?Arithmetic for more details.

HTH,

--sundar



From daya at LindaSpaces.com  Thu Oct 20 22:53:02 2005
From: daya at LindaSpaces.com (Daya Atapattu)
Date: Thu, 20 Oct 2005 16:53:02 -0400
Subject: [R] R package that Depends on "methods"
Message-ID: <435803AE.1070208@LindaSpaces.com>

I am trying to build a package that depends on "methods"
package.  I am getting an error "protection stack overflow"
at the INSTALL phase of  "check".  Can someone please
point me to a package that depends on "methods" so that
I can follow it?

-Daya



From mschwartz at mn.rr.com  Thu Oct 20 22:57:02 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Thu, 20 Oct 2005 15:57:02 -0500
Subject: [R] Boxplot labels
In-Reply-To: <1129840874.6015.97.camel@localhost.localdomain>
References: <BAY114-F2314BD8A62D7DE6D0F1502D7730@phx.gbl>
	<1129840874.6015.97.camel@localhost.localdomain>
Message-ID: <1129841822.6015.105.camel@localhost.localdomain>

On Thu, 2005-10-20 at 15:41 -0500, Marc Schwartz (via MN) wrote:
> On Thu, 2005-10-20 at 14:46 -0400, Keith Sabol wrote:
> > I am creating boxplots from a dataframe and would like to add to the 
> > standard output a marker representing the value from a particular row in the 
> > dataframe.
> > 
> > .....And I apologize if the solution is as trivial as it seems it should be.
> > 
> > Thanks for any assistance.
> > 
> > Keith
> 
> Some example code would be helpful here.
> 
> However, some hints that I suspect will be helpful:
> 
> 1. Unless you use the 'at' argument in boxplot(), the box center
> positions are at integer values from 1:n, where n is the number of
> groups. 
> 
> 2. You can thus use the points() function to add symbols or the text()
> function to add labels to the existing plot as you may require.
> See ?points and/or ?text for more information.


One other note to add here is that boxplot() will return a list which
contains various stats about your grouped data. This requires using the
form:

  stats <- boxplot(...)

Thus using the 'stats$group' and 'stats$out' components will give you
the x and y positions of any outliers. This will be helpful if these are
the values that you might want to identify

See the "Value" section in ?boxplot and ?boxplot.stats for more
information.

HTH,

Marc



From ripley at stats.ox.ac.uk  Thu Oct 20 23:12:09 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Oct 2005 22:12:09 +0100 (BST)
Subject: [R] different F test in drop1 and anova
In-Reply-To: <4357E30B.4060909@rulsfb.leidenuniv.nl>
References: <4357629F.3070104@rulsfb.leidenuniv.nl>
	<Pine.LNX.4.61.0510201227160.10800@gannet.stats>
	<4357E30B.4060909@rulsfb.leidenuniv.nl>
Message-ID: <Pine.LNX.4.61.0510202200120.7016@gannet.stats>

Yes, in essence although it is much easier to describe in words.

anova uses the Chisquared-based estimate of dispersion unless it is known.
drop1 uses the deviance-based estimate of dispersion unless it is known.

If the F tests are going to be approximately valid the dispersion 
estimators should be pretty similar, and when they are not the first _may_ 
be closer to chi-square-distributed.  However, as I recall it, when I 
learnt analysis of deviance using GLIM3, the drop1 approach was used.


On Thu, 20 Oct 2005, Tom Van Dooren wrote:

> Hi Brian,
> well I wanted a test based on quasibinomial...
> Does it work like this then?:
>
> x<-gl(3,2)
> y<-c(0,1,0,0,1,1)
>
> # quasibinomial models #
> ########################
>
> qb1<-glm(y~x,quasibinomial)
> qb2<-glm(y~1,quasibinomial)
>
> qbdev<-(qb2$dev-qb1$dev)
>
> qbdev # deviance I
>
> qbdev/(qb2$df.res-qb1$df.res)/(qb1$dev /qb1$df.res) # deviance ratio II
>
> qbdev/summary(qb1)$disp # scaled deviance III
>
> qbdev/(qb2$df.res-qb1$df.res)/summary(qb1)$disp # scaled deviance IV
>
>
> anova(qb2,qb1,test="Chisq") # Chisq test based on I
> drop1(qb1,test="F") # F test, based on II
> drop1(qb1,test="Chisq") # Chisq test, based on III
> anova(qb2,qb1,test="F") # F test, based on IV
>
> # binomial models #
> ###################
>
> b1<-glm(y~x,binomial)
> b2<-glm(y~1,binomial)
>
> bdev<-(b2$dev-b1$dev)
>
> bdev # deviance I
>
> bdev/(b2$df.res-b1$df.res)/(b1$dev /b1$df.res) # deviance ratio II
>
>
> drop1(b1,test="Chisq") # Chisq test, based on I
> anova(b2,b1,test="Chisq") # Chisq test based on I
> anova(b2,b1,test="F") # Chisq test, based on I
> drop1(b1,test="F") # F test, based on II
>
>
> Cheers, Tom
>
> PS: thanks Tord ;)
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ggrothendieck at gmail.com  Thu Oct 20 23:24:05 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 20 Oct 2005 17:24:05 -0400
Subject: [R] spliting an integer
In-Reply-To: <02ec01c5d5ae$187c9210$5814020a@thesahajamach>
References: <02ec01c5d5ae$187c9210$5814020a@thesahajamach>
Message-ID: <971536df0510201424o7407c12ajc6287a4815fa6ddd@mail.gmail.com>

On 10/20/05, Dimitri Szerman <dimitrijoe at ipea.gov.br> wrote:
> Hi there,
>
> >From the vector X of integers,
>
> X = c(11999, 122000, 81997)
>
> I would like to make these two vectors:
>
> Z= c(1999, 2000, 1997)
> Y =c(1 , 12 , 8)
>
> That is, each entry of vector Z receives the four last digits of each entry of X, and Y receives "the rest".
>

Some possibilities:

1. Use integer division and remainder (probably best solution):

	Y <- X %/% 10000
	Z <- X %% 10000

2. Convert to character and reduce to desired field:

	Y <- as.numeric(sub("....$", "", X))
	Z <- as.numeric(sub(".*(....)$", "\\1", X))

3. Insert a space between the two sets and read them in:

	read.table(textConnection(sub("(....)$", " \\1", X)),
		col.names = c("Y", "Z"))

4. Use encode at:

http://www.wiwi.uni-bielefeld.de/~wolf/software/R-wtools/decodeencode/decodeencode.rev

	encode(X, c(100, 10000))



From gunter.berton at gene.com  Thu Oct 20 23:25:20 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Thu, 20 Oct 2005 14:25:20 -0700
Subject: [R] spliting an integer
In-Reply-To: <02ec01c5d5ae$187c9210$5814020a@thesahajamach>
Message-ID: <200510202125.j9KLPKvC010830@faraday.gene.com>


Hint: 11999 = 11999%%1e4 + 1e4*(11999%/%1e4)

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Dimitri Szerman
> Sent: Thursday, October 20, 2005 12:40 PM
> To: R-Help
> Subject: [R] spliting an integer
> 
> Hi there,
> 
> >From the vector X of integers,
> 
> X = c(11999, 122000, 81997)
> 
> I would like to make these two vectors:
> 
> Z= c(1999, 2000, 1997)
> Y =c(1 , 12 , 8)
> 
> That is, each entry of vector Z receives the four last digits 
> of each entry of X, and Y receives "the rest".
> 
> Any suggestions?
> 
> Thanks in advance,
> 
> Dimitri
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From dgaich at hotmail.com  Thu Oct 20 22:03:42 2005
From: dgaich at hotmail.com (dgaich@hotmail.com)
Date: Thu, 20 Oct 2005 16:03:42 -0400
Subject: [R] Filter design in R?
References: <4356BF52.4080606@gmail.com>
Message-ID: <m3r7agq7kx.fsf@localhost.localdomain.i-did-not-set--mail-host-address--so-tickle-me>

Israel Christie <ichristie at gmail.com> writes:

> Dr. Williams,
> I ran across your inquiry on one of the R-help mailing lists regarding 
> digital filter design and implementation. I found no response to your 
> email in the archives and was wondering if you were able to find anything.
>

if you have mkfilter then something like 

> ?system
> foo <- system("mkfilter -Bu -Lp -o 2 -a 0.2 -l", T,T)

will give you coefficients for Butterworth Low pass 2nd order filter w cuttof at 0.2;
extract the coefficients from foo and feed it to filter.

Dragan Gajic



From p.dalgaard at biostat.ku.dk  Thu Oct 20 23:42:23 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 20 Oct 2005 23:42:23 +0200
Subject: [R] spliting an integer
In-Reply-To: <web-7143820@atmos.uiuc.edu>
References: <web-7143820@atmos.uiuc.edu>
Message-ID: <x2fyqvoog0.fsf@turmalin.kubism.ku.dk>

"Anne Hertel" <ahertel at atmos.uiuc.edu> writes:

> Hi Dimitri,
> 
> You could write
> 
> > z <- trunc(x/10000)
> > z
> [1]  1 12  8
> > y <- x-trunc(x/10000)*10000
> > y
> [1] 1999 2000 1997
> 
> And there you have it.

Er, we do have integer divide and remainder operators:

> X = c(11999, 122000, 81997)
> X %% 1e4
[1] 1999 2000 1997
> X %/% 1e4
[1]  1 12  8



> Cheers,
> Anne Hertel
> 
> 
> On Thu, 20 Oct 2005 17:40:10 -0200
>  "Dimitri Szerman" <dimitrijoe at ipea.gov.br> wrote:
> >Hi there,
> >
> >>From the vector X of integers,
> >
> >X = c(11999, 122000, 81997)
> >
> >I would like to make these two vectors:
> >
> >Z= c(1999, 2000, 1997)
> >Y =c(1 , 12 , 8)
> >
> >That is, each entry of vector Z receives the four last digits of each entry of X, and Y receives "the rest".
> >
> >Any suggestions?
> >
> >Thanks in advance,
> >
> >Dimitri
> >	[[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 
> 
> ------------------------------------------------------------
> Anne M. K. Hertel
> Grad. Student & Research Assistant
> Department of Atmospheric Sciences
> University of Illinois at Urbana-Champaign
> Annex II, room 204
> Phone: (217) 333 6296
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From kerryrekky at yahoo.com  Thu Oct 20 23:43:06 2005
From: kerryrekky at yahoo.com (Cunningham Kerry)
Date: Thu, 20 Oct 2005 14:43:06 -0700 (PDT)
Subject: [R] Fwd: predictive interval in nlme
Message-ID: <20051020214306.58117.qmail@web51804.mail.yahoo.com>

I sent out this message a couple of days ago. Yet
received no reply. 
There is a possibility that my description is not very
clear or example is not highly specific.
I am just wondering if anybody could point out (or
have seen) a similar function that can do this job for
lme model.
Thanks.
Note: forwarded message attached.



	
		
__________________________________ 

-------------- next part --------------
An embedded message was scrubbed...
From: unknown sender
Subject: no subject
Date: Tue, 18 Oct 2005 10:45:50 -0700 (PDT)
Size: 1006
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051020/93b1519e/attachment.mht

From jfox at mcmaster.ca  Fri Oct 21 00:23:59 2005
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 20 Oct 2005 18:23:59 -0400
Subject: [R] spliting an integer
In-Reply-To: <43580308.4000202@pdf.com>
Message-ID: <20051020222357.IBPQ26550.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Sundar and Dimitri,

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Sundar 
> Dorai-Raj
> Sent: Thursday, October 20, 2005 3:50 PM
> To: Dimitri Szerman
> Cc: R-Help
> Subject: Re: [R] spliting an integer
> 
> 
> 
> Dimitri Szerman wrote:
> > Hi there,
> > 
> >>From the vector X of integers,
> > 
> > X = c(11999, 122000, 81997)
> > 
> > I would like to make these two vectors:
> > 
> > Z= c(1999, 2000, 1997)
> > Y =c(1 , 12 , 8)
> > 
> > That is, each entry of vector Z receives the four last 
> digits of each entry of X, and Y receives "the rest".
> > 
> > Any suggestions?
> > 
> > Thanks in advance,
> > 
> > Dimitri
> > 	[[alternative HTML version deleted]]
> 
> Try:
> 
> X <- c(11999, 122000, 81997)
> Y <- X %/% 10000
> Z <- X - Y * 10000
> 

Or even

> X %% 10000
[1] 1999 2000 1997

Regards,
 John

> See ?Arithmetic for more details.
> 
> HTH,
> 
> --sundar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From tschoenhoff at gmail.com  Fri Oct 21 00:27:33 2005
From: tschoenhoff at gmail.com (=?ISO-8859-1?Q?Thomas_Sch=F6nhoff?=)
Date: Fri, 21 Oct 2005 00:27:33 +0200
Subject: [R] R package that Depends on "methods"
In-Reply-To: <435803AE.1070208@LindaSpaces.com>
References: <435803AE.1070208@LindaSpaces.com>
Message-ID: <5ad2dec0510201527n6dddb164y@mail.gmail.com>

Hello,


2005/10/20, Daya Atapattu <daya at lindaspaces.com>:
> I am trying to build a package that depends on "methods"
> package.  I am getting an error "protection stack overflow"
> at the INSTALL phase of  "check".  Can someone please
> point me to a package that depends on "methods" so that
> I can follow it?

When typing installed.packages() at your R console you might find what
you're looking for.
Try Foreign , DBI or FBasics packages, relying on methods

Good luck,

Thomas



From p.connolly at hortresearch.co.nz  Fri Oct 21 02:26:08 2005
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Fri, 21 Oct 2005 13:26:08 +1300
Subject: [R] Subsetting a list
In-Reply-To: <17238.24973.55147.771104@stat.math.ethz.ch>
References: <mailman.13.1129629601.29332.r-help@stat.math.ethz.ch> 
	<8834D050-C381-4300-8A0C-54D806EFC941@plessthan.com> 
	<43550723.7000004@ipimar.pt>
	<17238.24973.55147.771104@stat.math.ethz.ch>
Message-ID: <20051021002608.GK18619@hortresearch.co.nz>

On Wed, 19-Oct-2005 at 05:09PM +0200, Martin Maechler wrote:


|> Lists can have 'dim' attributes and hence be treated as arrays;
|> Note that this is pretty rarely used and not too well supported
|> by some tools, one could say even 'print()' :
|> 
|> > set.seed(0); L0 <- L <- lapply(rpois(12, lambda=3), seq); dim(L) <- 3:4; L
|>      [,1]      [,2]      [,3]      [,4]     
|> [1,] Integer,5 Integer,3 Integer,5 Integer,3
|> [2,] Integer,2 Integer,5 Integer,6 1        
|> [3,] Integer,2 Integer,2 Integer,4 Integer,2

for an occasion such as this, it can be clearer to do:

> transform(L)
             X1            X2               X3      X4
1 1, 2, 3, 4, 5       1, 2, 3    1, 2, 3, 4, 5 1, 2, 3
2          1, 2 1, 2, 3, 4, 5 1, 2, 3, 4, 5, 6       1
3          1, 2          1, 2       1, 2, 3, 4    1, 2


best


-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From Karen.Green at sanofi-aventis.com  Fri Oct 21 03:42:18 2005
From: Karen.Green at sanofi-aventis.com (Karen.Green@sanofi-aventis.com)
Date: Thu, 20 Oct 2005 21:42:18 -0400
Subject: [R] finite mixture model (2-component gaussian): plotting component
	gaussian components?
Message-ID: <3CB6B0EE6816B142859B24E77724A8B8F87D5B@sccsmxsusr05.pharma.aventis.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051020/47467542/attachment.pl

From spencer.graves at pdf.com  Fri Oct 21 03:43:11 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 20 Oct 2005 18:43:11 -0700
Subject: [R] panel data unit root tests
In-Reply-To: <1128672029.43462b1d4d2d6@www2.helsinki.fi>
References: <1128672029.43462b1d4d2d6@www2.helsinki.fi>
Message-ID: <435847AF.4030305@pdf.com>

	  Have you received a reply?  I haven't seen one.  RSiteSearch("panel 
data unit root test") produced another question on this but no answers 
that I saw.  RSiteSearch("unit root test") produced 75 hits with many 
useful.  RSiteSearch("panel data analysis") produced 75 hits, the first 
of which suggested the nlme package 
(http://finzi.psych.upenn.edu/R/Rhelp02a/archive/26962.html).  You could 
construct nested models to compare the corAR1 correlation structure with 
first differences.

	  hope this helps.
	  spencer graves

jukka ruohonen wrote:

> Hi,
> 
> The question is as follows: has anyone coded panel data unit root tests 
> with R? Even the "first generation" tests (see e.g. Levin & Lin 1993; 
> Pesaran, & Smith & Im 1996; Maddala & Wu 1999) would be sufficient for my 
> needs. To my understanding, these are rather easy to code, but as I have 
> taken just my first steps in coding with R, existing code would save me 
> from a lot of trouble & time.
> 
> 
> With regards,
> 
> Jukka Ruohonen
> University of Helsinki
> 
> 
> References:
> 
> Levin, A. & Lin, C.F. (1993): Unit Root Tests in Panel Data. 
> ftp://weber.ucsd.edu/pub/econlib/dpapers/ucsd9356.pdf
> 
> Maddala, G.S. & Wu, S. (1999): A Comparative Study of Unit Roots Tests with 
> Panel Data and a New Simple Test. Oxford Bulleting of Economics and 
> Statistics. Special Issue 61, 631-652.
> 
> Pesaran, M.H. & Smith, R. & Im, K.S. (1996): Dynamic Linear Models for 
> Heterogenous Panels. In: Matyas, L. & Sevestre, P. (eds.): The Econometrics 
> of Panel Data: a Handbook of the Theory with Applications, second edition, 
> pp. 145-195.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From close2ceo at yahoo.com  Fri Oct 21 04:08:02 2005
From: close2ceo at yahoo.com (Xiaodong Jin)
Date: Thu, 20 Oct 2005 19:08:02 -0700 (PDT)
Subject: [R] curve fit
Message-ID: <20051021020803.67950.qmail@web31211.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051020/51a9203a/attachment.pl

From jkawczak at uncc.edu  Fri Oct 21 04:15:24 2005
From: jkawczak at uncc.edu (Janusz Kawczak)
Date: Thu, 20 Oct 2005 22:15:24 -0400 (EDT)
Subject: [R] curve fit
In-Reply-To: <20051021020803.67950.qmail@web31211.mail.mud.yahoo.com>
References: <20051021020803.67950.qmail@web31211.mail.mud.yahoo.com>
Message-ID: <Pine.GSO.4.55.0510202213270.4311@is-sm1.uncc.edu>

There are infinitely (uncountably) many of them. Which one do you want?
jk/

On Thu, 20 Oct 2005, Xiaodong Jin wrote:

> How to obtain the FUNCTION for the following smooth curve?
> x 0    100 250 500 1000  4000
> y 1.8  1.2 1.02 0.99 0.97 0.85
>
> Thanks,
> SJ
>
>
> ---------------------------------
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From deepayan.sarkar at gmail.com  Fri Oct 21 05:12:47 2005
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 20 Oct 2005 22:12:47 -0500
Subject: [R] adding error bars to lattice plots
In-Reply-To: <af34d0c00510200952u54663a70o73e6f115622b58c8@mail.gmail.com>
References: <af34d0c00510191434v23e2be42v493570589417deec@mail.gmail.com>
	<200510192219.j9JMJIEo018489@ohm.gene.com>
	<af34d0c00510200952u54663a70o73e6f115622b58c8@mail.gmail.com>
Message-ID: <eb555e660510202012i79159a5cm4a50734386d94b3c@mail.gmail.com>

On 10/20/05, Mario Aigner-Torres <mario.aignertorres at gmail.com> wrote:
> Thanks Bert!
>
> I have right now a dataset that looks like this:
>
> > tail(partition, 3)
> element run logfO2 TC buffer xAn sdXan Di Disigma
> 416 Al 36 -0.68 1180 AIR 0.734 0.007 2.10 0.02
> 417 Ca 36 -0.68 1180 AIR 0.734 0.007 1.29 0.02
> 418 Na 36 -0.68 1180 AIR 0.734 0.007 1.16 0.06
>
> Basicaly I would like to insert error bars into a xyplot like this

How are your error bars defined?

> > xyplot(log10(Di) ~ TC | element.ord, groups=buffer.ord, #pch=16,
> + #subset=no1140,
> + data=partition,
> + auto.key=list(columns=3),
> + )
>
> How could llines, lsegments or perhaps panel.arrows look like?
>
> I appreciate any help on this.
>
> Best regards,
>
> Mario
>
>
> On 10/19/05, Berton Gunter <gunter.berton at gene.com> wrote:
> >
> > ?llines, lsegments and the like can be used in the panel functions to
> draw
> > any sort of error bar that you can compute from the x,y,... data of the
> > panel.
> >
> > -- Bert Gunter
> > Genentech Non-Clinical Statistics
> > South San Francisco, CA
> >
> > "The business of the statistician is to catalyze the scientific learning
> > process." - George E. P. Box
> >
> >
> >
> > > -----Original Message-----
> > > From: r-help-bounces at stat.math.ethz.ch
> > > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Mario
> > > Aigner-Torres
> > > Sent: Wednesday, October 19, 2005 2:34 PM
> > > To: r-help at stat.math.ethz.ch
> > > Subject: [R] adding error bars to lattice plots
> > >
> > > Dear R-Users,
> > >
> > > how to include error bars within lattice?
> > > How should the panel = function(x,y,...){
> > > looks like?
> > > Does panel.arrows works here as well?
> > >
> > > I appreciate any help on this.
> > >
> > > Regards,
> > >
> > > Mario AT
> > >
> > > [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> > >
> >
> >
> >
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From 042045003 at fudan.edu.cn  Fri Oct 21 05:19:48 2005
From: 042045003 at fudan.edu.cn (ronggui)
Date: Fri, 21 Oct 2005 11:19:48 +0800
Subject: [R] The behavior of match function
Message-ID: <0IOO00ILWWRN17@mail.fudan.edu.cn>

> x<-1:10
> y<-x+1e-20
> x
 [1]  1  2  3  4  5  6  7  8  9 10
> y
 [1]  1  2  3  4  5  6  7  8  9 10
> identical(x,y)
[1] FALSE
> match(x,y)
 [1]  1  2  3  4  5  6  7  8  9 10

What's the  principle the function use to determine if x match y?

Thank you!
 				


2005-10-21

------
Deparment of Sociology
Fudan University

My new mail addres is ronggui.huang at gmail.com
Blog:http://sociology.yculblog.com



From MSchwartz at mn.rr.com  Fri Oct 21 06:42:35 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Thu, 20 Oct 2005 23:42:35 -0500
Subject: [R] The behavior of match function
In-Reply-To: <0IOO00ILWWRN17@mail.fudan.edu.cn>
References: <0IOO00ILWWRN17@mail.fudan.edu.cn>
Message-ID: <1129869756.5505.24.camel@localhost.localdomain>

On Fri, 2005-10-21 at 11:19 +0800, ronggui wrote:
> > x<-1:10
> > y<-x+1e-20
> > x
>  [1]  1  2  3  4  5  6  7  8  9 10
> > y
>  [1]  1  2  3  4  5  6  7  8  9 10
> > identical(x,y)
> [1] FALSE
> > match(x,y)
>  [1]  1  2  3  4  5  6  7  8  9 10
> 
> What's the  principle the function use to determine if x match y?
> 
> Thank you!


In this case, you are comparing x (an integer) with y (a numeric):

> x <- 1:10
> y <- x + 1e-20

> class(x)
[1] "integer"
> class(y)
[1] "numeric"


Now:

> x == y
 [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE

works element-wise, because the differences between the values (1e-20)
are less than:

> .Machine$double.eps
[1] 2.220446e-16

which is the smallest positive float such that 1 plus that value != 1.
See ?.Machine for more information on that.

For the same reason:

> match(x, y)
 [1]  1  2  3  4  5  6  7  8  9 10

> x %in% y
 [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE

both work element-wise.


However, if you used the following for 'y':

> y <- x + 1e-15

Note the results now:

> x == y
 [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE

because you are now have differences that are greater than .Machine
$double.eps.


In general however, when comparing floats, you will want to use
all.equal():

> all.equal(x, y)
[1] TRUE

which compares the values within a specified level of tolerance.
See ?all.equal for more information and importantly note the use of
isTRUE() as well:

> isTRUE(all.equal(x, y))
[1] TRUE

Using isTRUE() in this way will result in a single TRUE or FALSE result
depending upon the comparison. If the differences happen to be outside
the tolerance level, you get something like the following:

> y <- x + 1e-5

> all.equal(x, y)
[1] "Mean relative  difference: 1.818182e-06"

which does not help if all you want is a single boolean result. Thus the
use of isTRUE() helps here:

> isTRUE(all.equal(x, y))
[1] FALSE


You should also read R FAQ 7.31 "Why doesn't R think these numbers are
equal?".

HTH,

Marc Schwartz



From ggrothendieck at gmail.com  Fri Oct 21 07:17:54 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 21 Oct 2005 01:17:54 -0400
Subject: [R] curve fit
In-Reply-To: <20051021020803.67950.qmail@web31211.mail.mud.yahoo.com>
References: <20051021020803.67950.qmail@web31211.mail.mud.yahoo.com>
Message-ID: <971536df0510202217nc6684ceh79af146e98d4e237@mail.gmail.com>

y ~ 1/(a + b*x^c) looks pretty good to me.

If we assume a starting value of c=1 then we can get
the starting values of a and b from lm(1/y ~ x) and
then do an nls fit.

On 10/20/05, Xiaodong Jin <close2ceo at yahoo.com> wrote:
> How to obtain the FUNCTION for the following smooth curve?
> x 0    100 250 500 1000  4000
> y 1.8  1.2 1.02 0.99 0.97 0.85
>
> Thanks,
> SJ
>
>
> ---------------------------------
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From grove001 at umn.edu  Fri Oct 21 08:03:42 2005
From: grove001 at umn.edu (William M. Grove)
Date: Fri, 21 Oct 2005 01:03:42 -0500
Subject: [R] Any package to perform HLM (PROC GENMOD) like logistic
 regression in R?
Message-ID: <6.2.3.4.2.20051021005928.034322f8@grove001.email.umn.edu>

I know there are very nice facilities in Pinhiero and Bates for doing 
HLM-type modeling for continuous dependent variables.  But I would 
like to be able to do repeated measures logistic regression, or LR on 
clustered observations (at least with exchangeable correlation 
structures, and preferably with more general choices of 
within-cluster correlation structures).  Have I missed seeing some 
package in R that will do this, more or less the way GENMOD does in 
SAS?  I have not found a package to do thus in my scanning thus far.

Regards,

Will Grove       |
Psychology Dept. |
U. of Minnesota  |
-----------------+

X-headers have PGP key info.; Call 612.625.1599 to verify key 
fingerprint before
accepting signed mail as authentic!



From ligges at statistik.uni-dortmund.de  Fri Oct 21 08:57:49 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 21 Oct 2005 08:57:49 +0200
Subject: [R] suppress messages on loading its
In-Reply-To: <Pine.LNX.4.61.0510202056020.26068@gannet.stats>
References: <3f87cc6d0510201018w56e0a39bp8d0bb2b9965b0afa@mail.gmail.com>
	<Pine.LNX.4.61.0510202056020.26068@gannet.stats>
Message-ID: <4358916D.9090206@statistik.uni-dortmund.de>

Prof Brian Ripley wrote:

> Those messages mean it has not been installed correctly -- they should 
> occur during installation only.
> 
> They are written to the message connection, which capture.output does not 
> mess with (but sink can).
> 
> On Thu, 20 Oct 2005, Omar Lakkis wrote:
> 
> 
>>On loading the package: its, I get the "Creating a new generic
>>function for" messages below even when I wrap the call with
>>capture.output. Is there a way to suppress these messages?
>>
>>
>>>dummy=capture.output( library(its) )
>>
>>Creating a new generic function for 'names' in 'its'
>>Creating a new generic function for 'names<-' in 'its'
>>Creating a new generic function for 'print' in 'its'
>>Creating a new generic function for 'start' in 'its'
>>Creating a new generic function for 'end' in 'its'
>>Creating a new generic function for 'summary' in 'its'
>>Creating a new generic function for 'diff' in 'its'
>>Creating a new generic function for 'union' in 'its'
>>Creating a new generic function for 'intersect' in 'its'
> 
> 


Another issue is that "its" currently does not pass the CRAN checks 
neither for R-release nor R-devel (but looks like it passes for 
R-patched since a couple of days now).

Uwe Ligges



From ripley at stats.ox.ac.uk  Fri Oct 21 10:18:39 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 21 Oct 2005 09:18:39 +0100 (BST)
Subject: [R] Any package to perform HLM (PROC GENMOD) like logistic
 regression in R?
In-Reply-To: <6.2.3.4.2.20051021005928.034322f8@grove001.email.umn.edu>
References: <6.2.3.4.2.20051021005928.034322f8@grove001.email.umn.edu>
Message-ID: <Pine.LNX.4.61.0510210857240.28610@gannet.stats>

On Fri, 21 Oct 2005, William M. Grove wrote:

> I know there are very nice facilities in Pinhiero and Bates for doing
> HLM-type modeling for continuous dependent variables.  But I would
> like to be able to do repeated measures logistic regression, or LR on
> clustered observations (at least with exchangeable correlation
> structures, and preferably with more general choices of
> within-cluster correlation structures).  Have I missed seeing some
> package in R that will do this, more or less the way GENMOD does in
> SAS?  I have not found a package to do thus in my scanning thus far.

Well, you will need to tell us what it is that SAS does (I do have SAS but 
my licence code needs renewing which shows how little I use it).

There are two approaches to repeated measures logistic regression, the 
subject-specific and population-average approach.  Your description sounds 
closer to the latter, for which see the packages gee and geepack.
But GLMMs (the subject-specific approach) are covered in a number of 
packages including MASS, lme4 and glmmML.

My belief is that PROC GENMOD uses the GEE approach, and I would not call 
that an HLM.  To add confusion, there seems to have been a stand-alone 
program called GENMOD which is referenced in HLM-fitting reviews.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Fri Oct 21 10:18:58 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 21 Oct 2005 10:18:58 +0200
Subject: [R] Subsetting a list
In-Reply-To: <20051021002608.GK18619@hortresearch.co.nz>
References: <mailman.13.1129629601.29332.r-help@stat.math.ethz.ch>
	<8834D050-C381-4300-8A0C-54D806EFC941@plessthan.com>
	<43550723.7000004@ipimar.pt>
	<17238.24973.55147.771104@stat.math.ethz.ch>
	<20051021002608.GK18619@hortresearch.co.nz>
Message-ID: <17240.42098.886055.899735@stat.math.ethz.ch>

>>>>> "PaCo" == Patrick Connolly <p.connolly at hortresearch.co.nz>
>>>>>     on Fri, 21 Oct 2005 13:26:08 +1300 writes:

    PaCo> On Wed, 19-Oct-2005 at 05:09PM +0200, Martin Maechler wrote:
    PaCo> |> Lists can have 'dim' attributes and hence be treated as arrays;
    PaCo> |> Note that this is pretty rarely used and not too well supported
    PaCo> |> by some tools, one could say even 'print()' :
    PaCo> |> 
    PaCo> |> > set.seed(0); L0 <- L <- lapply(rpois(12, lambda=3), seq); dim(L) <- 3:4; L
    PaCo> |>      [,1]      [,2]      [,3]      [,4]     
    PaCo> |> [1,] Integer,5 Integer,3 Integer,5 Integer,3
    PaCo> |> [2,] Integer,2 Integer,5 Integer,6 1        
    PaCo> |> [3,] Integer,2 Integer,2 Integer,4 Integer,2

    PaCo> for an occasion such as this, it can be clearer to do:

    >> transform(L)
    PaCo> X1            X2               X3      X4
    PaCo> 1 1, 2, 3, 4, 5       1, 2, 3    1, 2, 3, 4, 5 1, 2, 3
    PaCo> 2          1, 2 1, 2, 3, 4, 5 1, 2, 3, 4, 5, 6       1
    PaCo> 3          1, 2          1, 2       1, 2, 3, 4    1, 2

wow!  
Thank you Patrick!

Actually, that's identical to 

   data.frame(L)

which I honestly wouldn't have had expected to work for L.
Martin



From ym at climpact.com  Fri Oct 21 10:36:12 2005
From: ym at climpact.com (Yves Magliulo)
Date: 21 Oct 2005 10:36:12 +0200
Subject: [R] =?ISO-8859-1?Q?probl=E8me?= d'import de fichier
In-Reply-To: <435794FE.7030809@cebc.cnrs.fr>
References: <435794FE.7030809@cebc.cnrs.fr>
Message-ID: <1129883772.5337.14.camel@new-york.climpact.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051021/81e85d48/attachment.pl

From maechler at stat.math.ethz.ch  Fri Oct 21 11:22:29 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 21 Oct 2005 11:22:29 +0200
Subject: [R] R package that Depends on "methods"
In-Reply-To: <5ad2dec0510201527n6dddb164y@mail.gmail.com>
References: <435803AE.1070208@LindaSpaces.com>
	<5ad2dec0510201527n6dddb164y@mail.gmail.com>
Message-ID: <17240.45909.325487.987949@stat.math.ethz.ch>

>>>>> "Thomas" == Thomas Sch??nhoff <tschoenhoff at gmail.com>
>>>>>     on Fri, 21 Oct 2005 00:27:33 +0200 writes:

    Thomas> Hello,
    Thomas> 2005/10/20, Daya Atapattu <daya at lindaspaces.com>:
    >> I am trying to build a package that depends on "methods"
    >> package.  I am getting an error "protection stack overflow"
    >> at the INSTALL phase of  "check".  Can someone please
    >> point me to a package that depends on "methods" so that
    >> I can follow it?

    Thomas> When typing installed.packages() at your R console you might find what
    Thomas> you're looking for.
    Thomas> Try Foreign , DBI or FBasics packages, relying on methods

correctly spelled, that's
	  'foreign', 'DBI' or 'fBasics'.

I'd recommend 'foreign' because that's a recommended package and
hence available in all standard R installations.

Martin Maechler, ETH Zurich



From maechler at stat.math.ethz.ch  Fri Oct 21 11:33:03 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 21 Oct 2005 11:33:03 +0200
Subject: [R] Filter design in R?
In-Reply-To: <1129814765.6835.32.camel@localhost.localdomain>
References: <4356BF52.4080606@gmail.com>
	<1129814765.6835.32.camel@localhost.localdomain>
Message-ID: <17240.46543.610361.256399@stat.math.ethz.ch>

>>>>> "tom" == tom wright <tom at maladmin.com>
>>>>>     on Thu, 20 Oct 2005 09:26:05 -0400 writes:

    tom> On Wed, 2005-19-10 at 17:49 -0400, Israel Christie wrote:
    >> Dr. Williams,
    >> I ran across your inquiry on one of the R-help mailing lists regarding 
    >> digital filter design and implementation. I found no response to your 
    >> email in the archives and was wondering if you were able to find anything.
    >> 
    >> Thanks,
    >> Israel

    tom> I'm not Dr Williams, but I've been doing some work on filter design
    tom> recently. I'm also no expert in this area but I found some very useful
    tom> resources, primarily the online book "The scientist and engineers guide
    tom> to digital signal processing" http://www.dspguide.com

    tom> I came up with some code for generating simple highpass; low pass and
    tom> bandpass filters, the filters can be applied using the filter() function


    tom> Since I'm no expert here I'd really appreciate any comment from people
    tom> who know more than me about these techniques.

I'm neither Dr. Williams nor an expert in the ("engineer point of
view on") filter design.

Note however that R (in 'stats') , additionally to filter() 
has a function  kernel()  which is used to build some common
(non-recursive) filters and produce objects of (S3) class
"tskernel".
These were primarily designed for use in spectrum(), but should
be more generally useful, and could serve as an initial role
model for extention.

The "real" source is in
https://svn.R-project.org/R/trunk/src/library/stats/R/kernel.R

Martin Maechler

    tom> Regards
    tom> Tom

    >> ================== BEGIN USAGE CODE==================
    >> t<-c(1:1000)/1000     #timeline 1KHz
    >> s1<-sin(2*pi*t*3)     #3Hz waveform
    >> s2<-sin(2*pi*t*5)     #5Hz waveform
    >> s3<-sin(2*pi*t*10)    #10Hz waveform
    >> 
    >> stot<-s1+s2+s3                #complex waveform
    >> 
    >> plot(stot,type='l')
    >> 
    >> #create the filter, the longer it is the better cutoff
    >> #length must be an even number
    >> f<-calcbpfilt(length=900,samplerate=1000,lowfreq=7,highfreq=4) 
    >> 
    >> sfilt<-filter(stot,f,circular=TRUE)   #apply the filter
    >> 
    >> lines(sfilt,type='l',col='red')               
    >> #only the 5Hz freq should be let through
    >> 
    >> ================== END USAGE CODE==================
    tom> ==============BEGIN CODE=================
    tom> calclpfilt<-function(length,fc){
    
    tom> t<-c(0:length+1)
    tom> for (val in t){
    tom> if(val-length/2==0){
    tom> f[val]<-as.numeric(2*pi*fc)
    tom> }else{

    tom> f[val]<-as.numeric(sin(2*pi*fc*(val-length/2))/(val-length/2))
    tom> }
    tom> f[val]=as.numeric(f[val])*(0.54-0.46*cos(2*pi*val/length))
    tom> }
    tom> #f<-convolve(f,f)
    tom> #normalise filter

    tom> filt.total<-sum(as.numeric(f))
    tom> f<-as.numeric(f)/filt.total
    tom> }

    tom> calcbpfilt<-function(length,samplerate,lowfreq,highfreq){
    tom> f.low<-list()
    tom> f.high<-list()

    tom> fc.low<-1/(samplerate/lowfreq)
    tom> fc.high<-1/(samplerate/highfreq)

    tom> t<-c(0:length+1)

    tom> #calculate the lowpass filter
    tom> for (val in t){
    tom> if(val-length/2==0){
    tom> f.low[val]<-as.numeric(2*pi*fc.low)
    tom> }else{

    tom> f.low[val]<-as.numeric(sin(2*pi*fc.low*(val-length/2))/(val-length/2))
    tom> }

    tom> f.low[val]=as.numeric(f.low[val])*(0.54-0.46*cos(2*pi*val/length))
    tom> }
    tom> #f<-convolve(f,f)
    tom> #normalise filter

    tom> filt.total<-sum(as.numeric(f.low))
    tom> f.low<-as.numeric(f.low)/filt.total

    tom> #calculate the second filter
    tom> for (val in t){
    tom> if(val-length/2==0){
    tom> f.high[val]<-as.numeric(2*pi*fc.high)
    tom> }else{

    tom> f.high[val]<-as.numeric(sin(2*pi*fc.high*(val-length/2))/(val-length/2))
    tom> }

    tom> f.high[val]=as.numeric(f.high[val])*(0.54-0.46*cos(2*pi*val/length))
    tom> }
    tom> #f<-convolve(f,f)
    tom> #normalise filter

    tom> filt.total<-sum(as.numeric(f.high))
    tom> f.high<-as.numeric(f.high)/filt.total

    tom> #invert the high filter to make it high pass

    tom> f.high<-0-f.high
    tom> f.high[length/2]<-f.high[length/2]+1

    tom> #add lowpass filterkernal and highpass filter kernel
    tom> #makes band reject filter
    tom> f.bandreject<-f.low+f.high

    tom> #make band pass by spectral inversion
    tom> f.bandpass<-0-f.bandreject
    tom> f.bandpass[length/2]<-f.bandpass[length/2]+1
    tom> f.bandpass
    tom> }
    tom> ==============END CODE=================



From v.schlecht at arcor.de  Fri Oct 21 11:59:49 2005
From: v.schlecht at arcor.de (v.schlecht@arcor.de)
Date: Fri, 21 Oct 2005 11:59:49 +0200 (CEST)
Subject: [R] combinging "plots"
Message-ID: <13996470.1129888789079.JavaMail.ngmail@webmail-06.arcor-online.net>

If I have one set of points Line 1: {(0,0.87),(0.1,0.88),(0.2,0.89)} and another set of points {(0,0.75),(0.1,0.76),(0.2,0.77)} I can easily produce two separate diagrams:

x<-c(0,0.1,0.2)
y1<-c(0.87,0.88,0.89)
y2<-c(0.75,0.76,0.77)
p1<-plot(x,y1,type="b")
p2<-plot(x,y2,type="b")

But what can I do if I want ONE diagram, which contains bots lines so that they can be compared? In other words: How can I put both sets of points as parallel functions together into ONE and the same graph? How could I put any number of sets of points (perhaps y1,y2,...,y8) which belong to the same x into the same graph? 



Machen Sie aus 14 Cent spielend bis zu 100 Euro!
Die neue Gaming-Area von Arcor - ??ber 50 Onlinespiele im Angebot.
http://www.arcor.de/rd/emf-gaming-1



From m.ballardini at ior-forli.it  Fri Oct 21 12:13:34 2005
From: m.ballardini at ior-forli.it (Michela Ballardini)
Date: Fri, 21 Oct 2005 12:13:34 +0200
Subject: [R] forrest plot
References: <000f01c5d57d$fa231a80$0200a8c0@Michela>
	<Pine.LNX.4.63a.0510201034290.28674@homer22.u.washington.edu>
Message-ID: <000601c5d628$191cc940$0200a8c0@Michela>

Dear Thomas, thank you very much for the informations, I want just that one!

But how can I do? Can you tell me where can I try the commands to do that 
graphic?

Thank you a lot
Michela

**************************************
Dr.ssa Michela Ballardini
Unit?? di Biostatistica e Sperimentazioni Cliniche
c/o Osp. Morgagni-Pierantoni - Pad. Valsalva
Via Forlanini, 34
47100 Forl??
Tel 0543-731836
Tel/Fax 0543-731612
**************************************


----- Original Message ----- 
From: "Thomas Lumley" <tlumley at u.washington.edu>
To: "Michela Ballardini" <m.ballardini at ior-forli.it>
Cc: <r-help at stat.math.ethz.ch>
Sent: Thursday, October 20, 2005 8:19 PM
Subject: Re: [R] forrest plot



metaplot() will not currently do asymmetric confidence intervals, which
seems to be what you want.  I'm making a revised version based on Paul
Murrell's grid example at
   http://www.stat.auckland.ac.nz/~paul/RGraphics/examples-table.png
which will be more flexible.

  -thomas

On Thu, 20 Oct 2005, Michela Ballardini wrote:

> Hello
> I'm trying to plot hazard risk values using the function metaplot with
> the specifications:
>
> metaplot(mn=c(-0.28174,-0.71444,-0.12375,-0.12426,-0.30011,-0.45058,-0.07324),se=c(0.20766,0.42691,0.26366,0.30357,0.31819,0.28636,0.37758),xlab="HR 
> and 95%CI",logeffect=T,xaxt="n")
>
> axis(side=1,at=c(0,0.2,0.4,0.6,0.8,1.0,1.2,1.4,1.6,1.8,2.0),labels=c(0,0.2,0.4,0.6,0.8,1.0,1.2,1.4,1.6,1.8,2.0))
>
>
>
> However, in the plot the x axis is on a log scale and tends to overextend 
> the left end of the axis. How can I transform the x-scale on a linear 
> scale with equidistant points?
>
>
> Thank you very much for your attenction
>
> Mic
>
> **************************************
> Dr.ssa Michela Ballardini
> Unit?? di Biostatistica e Sperimentazioni Cliniche
> c/o Osp. Morgagni-Pierantoni - Pad. Valsalva
> Via Forlanini, 34
> 47100 Forl??
> Tel 0543-731836
> Tel/Fax 0543-731612
> **************************************
>
>
> [[alternative HTML version deleted]]
>
>

Thomas Lumley Assoc. Professor, Biostatistics
tlumley at u.washington.edu University of Washington, Seattle



From f.calboli at imperial.ac.uk  Fri Oct 21 13:02:27 2005
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Fri, 21 Oct 2005 12:02:27 +0100
Subject: [R] partial rank correlation coefficient
Message-ID: <1129892547.15713.85.camel@localhost.localdomain>

Hi All,

a colleague asked me if R has a function producing a Partial Rank
Correlation Coefficient, sensu Blower and Dowlatabadi 1994 [1].

I personally would not have a clue, and I could not find something like
that on the search page... although I would not be surprised if it's
there under a different name.

Incidentally, unfortunately the function, assuming it exists, is to be
fed to some MSc students. They are supposed to learn how to use R, but
are not supposed to know/understand what maths and stats are under the
bonnet of the test (I don't run the course, no comment). So the 'plan'
is to give them a lecture about models in epidemiology and sensitivity,
and then the punch line should be: 'and the PRCC can be asily done in R
using the function ???'.

Cheers,

Federico 

[1] S.M. Blower and H. Dowlatabadi, 1994. SENSITIVITY AND UNCERTAINTY
ANALYSIS OF COMPLEX-MODELS OF DISEASE TRANSMISSION - AN HIV MODEL, AS AN
EXAMPLE. International Statistical Review 62(2) 229-243. 


-- 
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St Mary's Campus
Norfolk Place, London W2 1PG

Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From petr.pikal at precheza.cz  Fri Oct 21 13:36:54 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 21 Oct 2005 13:36:54 +0200
Subject: [R] combinging "plots"
In-Reply-To: <13996470.1129888789079.JavaMail.ngmail@webmail-06.arcor-online.net>
Message-ID: <4358EEF6.2575.DB1E6B@localhost>

Hi

from 
?plot help page you can find see also
?points
?lines

If you have common x as you suggest by your example, matplot 
will make the desired result for you

matplot(x, cbind(y1,y2))

see
?matplot for details

HTH
Petr



On 21 Oct 2005 at 11:59, v.schlecht at arcor.de wrote:

Date sent:      	Fri, 21 Oct 2005 11:59:49 +0200 (CEST)
From:           	v.schlecht at arcor.de
To:             	r-help at stat.math.ethz.ch
Subject:        	[R] combinging "plots"

> If I have one set of points Line 1: {(0,0.87),(0.1,0.88),(0.2,0.89)}
> and another set of points {(0,0.75),(0.1,0.76),(0.2,0.77)} I can
> easily produce two separate diagrams:
> 
> x<-c(0,0.1,0.2)
> y1<-c(0.87,0.88,0.89)
> y2<-c(0.75,0.76,0.77)
> p1<-plot(x,y1,type="b")
> p2<-plot(x,y2,type="b")
> 
> But what can I do if I want ONE diagram, which contains bots lines so
> that they can be compared? In other words: How can I put both sets of
> points as parallel functions together into ONE and the same graph? How
> could I put any number of sets of points (perhaps y1,y2,...,y8) which
> belong to the same x into the same graph? 
> 
> 
> 
> Machen Sie aus 14 Cent spielend bis zu 100 Euro!
> Die neue Gaming-Area von Arcor - ??ber 50 Onlinespiele im Angebot.
> http://www.arcor.de/rd/emf-gaming-1
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From sdavis2 at mail.nih.gov  Fri Oct 21 13:53:18 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 21 Oct 2005 07:53:18 -0400
Subject: [R] Graph layout software
Message-ID: <BF7E4EEE.11331%sdavis2@mail.nih.gov>

This is a bit off-topic, but I thought I would ask.  What are folks
typically using for graph layout when drawing graph structures.  I have used
Rgraphviz for relatively small graphs (100 nodes or fewer) with nice
results.  However, quick google searches turn up a number of graph layout
packages that look to be perhaps a bit faster and more flexible for larger
graphs.  Also, has anyone used graph layout software that works in three
dimensions?

Sean



From ripley at stats.ox.ac.uk  Fri Oct 21 14:55:41 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 21 Oct 2005 13:55:41 +0100 (BST)
Subject: [R] Subsetting a list
In-Reply-To: <17240.42098.886055.899735@stat.math.ethz.ch>
References: <mailman.13.1129629601.29332.r-help@stat.math.ethz.ch>
	<8834D050-C381-4300-8A0C-54D806EFC941@plessthan.com>
	<43550723.7000004@ipimar.pt>
	<17238.24973.55147.771104@stat.math.ethz.ch>
	<20051021002608.GK18619@hortresearch.co.nz>
	<17240.42098.886055.899735@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.61.0510211349440.32281@gannet.stats>

On Fri, 21 Oct 2005, Martin Maechler wrote:

>>>>>> "PaCo" == Patrick Connolly <p.connolly at hortresearch.co.nz>
>>>>>>     on Fri, 21 Oct 2005 13:26:08 +1300 writes:
>
>    PaCo> On Wed, 19-Oct-2005 at 05:09PM +0200, Martin Maechler wrote:
>    PaCo> |> Lists can have 'dim' attributes and hence be treated as arrays;
>    PaCo> |> Note that this is pretty rarely used and not too well supported
>    PaCo> |> by some tools, one could say even 'print()' :
>    PaCo> |>
>    PaCo> |> > set.seed(0); L0 <- L <- lapply(rpois(12, lambda=3), seq); dim(L) <- 3:4; L
>    PaCo> |>      [,1]      [,2]      [,3]      [,4]
>    PaCo> |> [1,] Integer,5 Integer,3 Integer,5 Integer,3
>    PaCo> |> [2,] Integer,2 Integer,5 Integer,6 1
>    PaCo> |> [3,] Integer,2 Integer,2 Integer,4 Integer,2
>
>    PaCo> for an occasion such as this, it can be clearer to do:
>
>    >> transform(L)
>    PaCo> X1            X2               X3      X4
>    PaCo> 1 1, 2, 3, 4, 5       1, 2, 3    1, 2, 3, 4, 5 1, 2, 3
>    PaCo> 2          1, 2 1, 2, 3, 4, 5 1, 2, 3, 4, 5, 6       1
>    PaCo> 3          1, 2          1, 2       1, 2, 3, 4    1, 2
>
> wow!
> Thank you Patrick!
>
> Actually, that's identical to
>
>   data.frame(L)
>
> which I honestly wouldn't have had expected to work for L.

or even as.data.frame(L).

Now replace lambda=3 by lambda=30 and see which one is legible (let alone 
clearer).  I prefer the internal matrix printing in almost all cases.

It works for data frames because print.data.frame uses format.data.frame 
which uses format, and that's how format works on a list.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From r.hankin at noc.soton.ac.uk  Fri Oct 21 15:21:02 2005
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Fri, 21 Oct 2005 14:21:02 +0100
Subject: [R] [R-pkgs] new package bundle: onion
Message-ID: <A1292252-DF1B-427D-9AFF-B689E65E0DB6@soc.soton.ac.uk>

Dear List

I have just uploaded a new package, "onion", to CRAN.

It provides some functionality for manipulating and visualizing  
quaternions
and octonions.

All comments welcome!


enjoy


rksh


--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From leaflovesun at yahoo.ca  Fri Oct 21 16:59:17 2005
From: leaflovesun at yahoo.ca (Leaf Sun)
Date: Fri, 21 Oct 2005 22:59:17 +0800
Subject: [R] Finding the neighbors of the point
Message-ID: <200510211459.j9LExgnD030523@hypatia.math.ethz.ch>

Dear all,

I got point data of trees. I was wondering if anybody has experience in searching the neighbors within a specified distance efficiently.

X    Y     Z
99 	34	 65
98 	35	 29
98 	34	 28
99 	33	 33
98 	32	 23
99 	33	 21
99 	33	 22
99 	32	 24
99 	30	 23
    ...

What I want to do is :  searching for the neighbors with a distance R for each tree  & the neighbor must have a bigger  Z.


The data set is huge so the R-codes is working slowly when I search it without subset it. 

Any suggestion would be much appreciated!

Leaf



From helprhelp at gmail.com  Fri Oct 21 17:34:46 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Fri, 21 Oct 2005 10:34:46 -0500
Subject: [R] please recommend
Message-ID: <cdf817830510210834v2a81a67dl3b6c89fbe59b9d2e@mail.gmail.com>

Dear listers:

These days I am analyzing some microarray data and I am wondering if
there are some good books and references on the following topics: R,
data mining and microarray analysis.

I appolagize if this is a bit off topic..

Thanks for the recommendation!


--
Weiwei Shi, Ph.D

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III



From close2ceo at yahoo.com  Fri Oct 21 17:38:35 2005
From: close2ceo at yahoo.com (Xiaodong Jin)
Date: Fri, 21 Oct 2005 08:38:35 -0700 (PDT)
Subject: [R] change maxiter for nls
Message-ID: <20051021153836.70681.qmail@web31202.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051021/2d3f230a/attachment.pl

From jmacdon at med.umich.edu  Fri Oct 21 17:56:51 2005
From: jmacdon at med.umich.edu (James MacDonald)
Date: Fri, 21 Oct 2005 11:56:51 -0400
Subject: [R] [BioC] please recommend
Message-ID: <s358d796.038@med-gwia-01a.med.umich.edu>

Here is an excellent choice:

http://www.amazon.com/exec/obidos/tg/detail/-/0387251464/qid=1129910139/sr=8-1/ref=pd_bbs_1/002-2566394-3995236?v=glance&s=books&n=507846

Best,

Jim



James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623

>>> Weiwei Shi <helprhelp at gmail.com> 10/21/05 11:34 AM >>>
Dear listers:

These days I am analyzing some microarray data and I am wondering if
there are some good books and references on the following topics: R,
data mining and microarray analysis.

I appolagize if this is a bit off topic..

Thanks for the recommendation!


--
Weiwei Shi, Ph.D

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III

_______________________________________________
Bioconductor mailing list
Bioconductor at stat.math.ethz.ch 
https://stat.ethz.ch/mailman/listinfo/bioconductor



**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues.



From p.dalgaard at biostat.ku.dk  Fri Oct 21 17:59:11 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 21 Oct 2005 17:59:11 +0200
Subject: [R] change maxiter for nls
In-Reply-To: <20051021153836.70681.qmail@web31202.mail.mud.yahoo.com>
References: <20051021153836.70681.qmail@web31202.mail.mud.yahoo.com>
Message-ID: <x2ll0m7tf4.fsf@viggo.kubism.ku.dk>

Xiaodong Jin <close2ceo at yahoo.com> writes:

> I typed the following commands but it still use maxiter=50 after the 2nd command:
>  
> nls.control(maxiter = 1000)
> nls(......)
>  
> Thanks!


You need 

nlc <- nls.control(maxiter = 1000)
nls(..., control=nlc)

And yes, I suppose both help pages could be clearer about this...

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From gunter.berton at gene.com  Fri Oct 21 18:02:23 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Fri, 21 Oct 2005 09:02:23 -0700
Subject: [R] [BioC] please recommend
In-Reply-To: <s358d796.038@med-gwia-01a.med.umich.edu>
Message-ID: <200510211602.j9LG2NKJ018349@faraday.gene.com>


and this:
http://www.amazon.com/exec/obidos/tg/detail/-/1584883278/qid=1129910385/sr=2
-1/ref=pd_bbs_b_2_1/002-5914105-6054455?v=glance&s=books

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of James MacDonald
> Sent: Friday, October 21, 2005 8:57 AM
> To: helprhelp at gmail.com; R-help at stat.math.ethz.ch
> Cc: bioconductor at stat.math.ethz.ch
> Subject: Re: [R] [BioC] please recommend
> 
> Here is an excellent choice:
> 
> http://www.amazon.com/exec/obidos/tg/detail/-/0387251464/qid=1
> 129910139/sr=8-1/ref=pd_bbs_1/002-2566394-3995236?v=glance&s=b
> ooks&n=507846
> 
> Best,
> 
> Jim
> 
> 
> 
> James W. MacDonald
> Affymetrix and cDNA Microarray Core
> University of Michigan Cancer Center
> 1500 E. Medical Center Drive
> 7410 CCGC
> Ann Arbor MI 48109
> 734-647-5623
> 
> >>> Weiwei Shi <helprhelp at gmail.com> 10/21/05 11:34 AM >>>
> Dear listers:
> 
> These days I am analyzing some microarray data and I am wondering if
> there are some good books and references on the following topics: R,
> data mining and microarray analysis.
> 
> I appolagize if this is a bit off topic..
> 
> Thanks for the recommendation!
> 
> 
> --
> Weiwei Shi, Ph.D
> 
> "Did you always know?"
> "No, I did not. But I believed..."
> ---Matrix III
> 
> _______________________________________________
> Bioconductor mailing list
> Bioconductor at stat.math.ethz.ch 
> https://stat.ethz.ch/mailman/listinfo/bioconductor
> 
> 
> 
> **********************************************************
> Electronic Mail is not secure, may not be read every day, and 
> should not be used for urgent or sensitive issues.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From sara at gmesintra.com  Fri Oct 21 18:59:39 2005
From: sara at gmesintra.com (Sara Mouro)
Date: Fri, 21 Oct 2005 17:59:39 +0100
Subject: [R] using markstat
Message-ID: <200510211659.j9LGxlYG025458@hypatia.math.ethz.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051021/41b96e6f/attachment.pl

From marvena at tin.it  Fri Oct 21 20:13:57 2005
From: marvena at tin.it (Marco Venanzi)
Date: Fri, 21 Oct 2005 20:13:57 +0200
Subject: [R] read data from pdf file
Message-ID: <001801c5d66b$351dfe50$0501a8c0@nome65ff66cddf>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051021/7ca53ac7/attachment.pl

From E.Ng at bristol.ac.uk  Fri Oct 21 20:37:21 2005
From: E.Ng at bristol.ac.uk (Edmond Ng)
Date: Fri, 21 Oct 2005 19:37:21 +0100
Subject: [R] order of approximation used in glmmPQL
Message-ID: <1129919841.4359356111b00@webmail.bris.ac.uk>

Dear all, 

Could anyone let me know what order of approximation (first, second or 
higher order) is used in glmmPQL in the MASS library please? I have 
read the section on this wrapper command in Venables and Ripley but am 
not sure if the relevant information is there. 

Many thanks in advance. 

Best wishes,
Edmond


***************************
Edmond Ng 
Research Fellow
Graduate School of Education
35 Berkeley Square
Bristol
BS8 1JA
United Kingdom



From jan.sabee at gmail.com  Fri Oct 21 21:13:24 2005
From: jan.sabee at gmail.com (Jan Sabee)
Date: Fri, 21 Oct 2005 21:13:24 +0200
Subject: [R] make three plot to one plot
Message-ID: <96507a8e0510211213h50e0c31p1cbac965bcc9eb6c@mail.gmail.com>

Dear all,
I want to make three plot below to only one plot together with legend,
how can I do that?
I have tried with matplot function but I did not succeed.
Thanks for your help.
Sincerelly,
Jan Sabee

test.five.x <- c(0.02,0.05,0.07,0.09,0.10,0.12,0.13,0.14,0.16,0.17,0.20,0.21,0.34,0.40)
test.five.y <- c(18,12,17,12,3,15,1,5,1,1,3,10,15,10)
plot(test.five.x, test.five.y, type="l",lty=1, lwd=3, col='red')
legend(par('usr')[2], par('usr')[4], xjust=1,
      c('five'),
      lwd=3,
      lty=1,
      col=c('red'))
test.six.x <- c(0.03,0.05,0.07,0.08,0.09,0.10,0.12,0.13,0.14,0.15,0.17,0.18,0.21,0.22,0.24,0.33,0.39,0.43)
test.six.y <- c(8,32,14,21,3,8,11,14,11,21,16,14,10,21,1,2,13,19)
plot(test.six.x, test.six.y, type="l",lty=2, lwd=3, col='green')
legend(par('usr')[2], par('usr')[4], xjust=1,
      c('six'),
      lwd=3,
      lty=2,
      col=c('green'))
test.seven.x <-
c(0.04,0.05,0.08,0.09,0.10,0.12,0.13,0.14,0.16,0.17,0.19,0.21,0.22,0.24,0.29,0.32,0.38,0.40,0.46,0.50)
test.seven.y <-
c(18,135,240,42,63,128,215,267,127,36,21,23,223,12,66,96,12,26,64,159)
plot(test.seven.x, test.seven.y, type="l",lty=3, lwd=2, col='blue')
legend(par('usr')[2], par('usr')[4], xjust=1,
      c('seven'),
      lwd=3,
      lty=3,
      col=c('blue'))



From Ted.Harding at nessie.mcc.ac.uk  Fri Oct 21 21:07:36 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 21 Oct 2005 20:07:36 +0100 (BST)
Subject: [R] read data from pdf file
In-Reply-To: <001801c5d66b$351dfe50$0501a8c0@nome65ff66cddf>
Message-ID: <XFMail.051021200736.Ted.Harding@nessie.mcc.ac.uk>

On 21-Oct-05 Marco Venanzi wrote:
> Hi, I'm trying to read data from a PDF file.Is it possible to do it
> with R? Thanks,  Marco

Basically, No.

But you may be lucky with "copy&paste" using the mouse, from
the display generated in Acrobat Reader to a text file.

The basic procedure here is

1. Click on the "Text Select Tool" (a button usually marked with a "T");

2. Use the mouse to highlight the block of text you want to copy;

3. Depending on your operating system/graphics display: In Windows
   you have (IIRC) to go to "Edit"->""Copy"; in Unlix/Linux with
   X Windows do nothing;

4. "Paste" it into your text file, again as appropriate for your
   operating system.

However, you may not be lucky.

PDF can store its content in stange ways, and what may look on the
screen like contiguous and consecutive text is stored internally
in separate "blocks" (what PDF calls "objects"). And this can apply
even to little bits of text in a paragraph.

When you paste the marked text, it will go in in the order that
PDF finds the blocks in the file. As a result, your text file
may contain bits of text in random order.

This especially applies to things arranged in tables. But it
very much depends on the software that generated the PDF in
the first place.

Since often the data in a PDF file which you may want to copy
in this way will be tabular, you are likely to encounter this
problem!

You can tell this is going to happen when you use the mouse to
highlight the text you intend to copy: starting with the mouse
iin say the top LH corner, move it slowly towards the lower
RH corner of the block. If the highlighting jumps all over the
screen, and/or outside the area you are trying to highlight,
then this is what's happening.

In that case I have sometimes done it by copying lots of little
blocks, too small to provoke the effect. But this is very tedious.

There are other things one can try, such as printing from the
PDF file to a PostScript file, and then using a program like
ps2ascii (which can deal directly with PDF) or pstotext; but frankly
no such program is likely to make a good job of this, because of
the way PS and PDF work.

Sorry to appear unhelpful! But you may get somewhere.

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 21-Oct-05                                       Time: 20:07:17
------------------------------ XFMail ------------------------------



From tom at maladmin.com  Fri Oct 21 17:23:51 2005
From: tom at maladmin.com (tom wright)
Date: Fri, 21 Oct 2005 11:23:51 -0400
Subject: [R] locator
Message-ID: <1129908231.4222.1.camel@localhost.localdomain>

I'm trying to use the locator function on a drawing area with multiple
graphs par(mfrow=c(1,2))
Is it possible to identify which graph has been clicked?
thanks
tom



From tschoenhoff at gmail.com  Fri Oct 21 21:39:47 2005
From: tschoenhoff at gmail.com (=?ISO-8859-1?Q?Thomas_Sch=F6nhoff?=)
Date: Fri, 21 Oct 2005 21:39:47 +0200
Subject: [R] read data from pdf file
In-Reply-To: <XFMail.051021200736.Ted.Harding@nessie.mcc.ac.uk>
References: <001801c5d66b$351dfe50$0501a8c0@nome65ff66cddf>
	<XFMail.051021200736.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <5ad2dec0510211239uf4b301y@mail.gmail.com>

2005/10/21, Ted Harding <Ted.Harding at nessie.mcc.ac.uk>:
> On 21-Oct-05 Marco Venanzi wrote:
> > Hi, I'm trying to read data from a PDF file.Is it possible to do it
> > with R? Thanks,  Marco
>
> Basically, No.
>
> But you may be lucky with "copy&paste" using the mouse, from
> the display generated in Acrobat Reader to a text file.
>
> The basic procedure here is
>
> 1. Click on the "Text Select Tool" (a button usually marked with a "T");
>
> 2. Use the mouse to highlight the block of text you want to copy;
>
> 3. Depending on your operating system/graphics display: In Windows
>    you have (IIRC) to go to "Edit"->""Copy"; in Unlix/Linux with
>    X Windows do nothing;
>
> 4. "Paste" it into your text file, again as appropriate for your
>    operating system.
>
> However, you may not be lucky.
>
> PDF can store its content in stange ways, and what may look on the
> screen like contiguous and consecutive text is stored internally
> in separate "blocks" (what PDF calls "objects"). And this can apply
> even to little bits of text in a paragraph.
>
> When you paste the marked text, it will go in in the order that
> PDF finds the blocks in the file. As a result, your text file
> may contain bits of text in random order.
>
> This especially applies to things arranged in tables. But it
> very much depends on the software that generated the PDF in
> the first place.
>
> Since often the data in a PDF file which you may want to copy
> in this way will be tabular, you are likely to encounter this
> problem!
>
> You can tell this is going to happen when you use the mouse to
> highlight the text you intend to copy: starting with the mouse
> iin say the top LH corner, move it slowly towards the lower
> RH corner of the block. If the highlighting jumps all over the
> screen, and/or outside the area you are trying to highlight,
> then this is what's happening.
>
> In that case I have sometimes done it by copying lots of little
> blocks, too small to provoke the effect. But this is very tedious.
>
> There are other things one can try, such as printing from the
> PDF file to a PostScript file, and then using a program like
> ps2ascii (which can deal directly with PDF) or pstotext; but frankly
> no such program is likely to make a good job of this, because of
> the way PS and PDF work.
>
> Sorry to appear unhelpful! But you may get somewhere.

Hmm, if this doesn't work you should have a look to pdftolpe, which is
assumed to convert aribitrary PDF files to some LPE readable format.
LPE is a lightweight programmer's editor, that should be able save the
converted file into txt format.

I never used this myself, though. In case you are running Windows my
reply might not be of much help, sorry for that!

good luck

Thomas



From murdoch at stats.uwo.ca  Fri Oct 21 21:46:36 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 21 Oct 2005 15:46:36 -0400
Subject: [R] locator
In-Reply-To: <1129908231.4222.1.camel@localhost.localdomain>
References: <1129908231.4222.1.camel@localhost.localdomain>
Message-ID: <4359459C.9080308@stats.uwo.ca>

On 10/21/2005 11:23 AM, tom wright wrote:
> I'm trying to use the locator function on a drawing area with multiple
> graphs par(mfrow=c(1,2))
> Is it possible to identify which graph has been clicked?

locator() will return coordinates based on the active graph (typically 
the last one you drew), so you can work it out from that.
That is, convert from user coordinates to screen coordinates, and then 
work out the position from there:

getcell <- function(pts = locator()) {
   usr <- par("usr")
   plt <- par("plt")
   mfg <- par("mfg")

   x <- pts$x
   y <- pts$y

   # convert to 0-1 plot coordinates
   px <- (x-usr[1])/(usr[2]-usr[1])
   py <- (y-usr[3])/(usr[4]-usr[3])

   # convert to 0-1 frame coordinates
   fx <- plt[1] + px*(plt[2]-plt[1])
   fy <- plt[3] + py*(plt[4]-plt[3])

   # convert to a relative cell position
   cx <- floor(fx)
   cy <- floor(fy)

   # return the absolute cell position
   list(row = -cy+mfg[1],col = cx+mfg[2])
}



From tschoenhoff at gmail.com  Fri Oct 21 21:56:03 2005
From: tschoenhoff at gmail.com (=?ISO-8859-1?Q?Thomas_Sch=F6nhoff?=)
Date: Fri, 21 Oct 2005 21:56:03 +0200
Subject: [R] read data from pdf file
In-Reply-To: <5ad2dec0510211239uf4b301y@mail.gmail.com>
References: <001801c5d66b$351dfe50$0501a8c0@nome65ff66cddf>
	<XFMail.051021200736.Ted.Harding@nessie.mcc.ac.uk>
	<5ad2dec0510211239uf4b301y@mail.gmail.com>
Message-ID: <5ad2dec0510211256w4b0cbab7j@mail.gmail.com>

Hello again,


2005/10/21, Thomas Sch??nhoff <tschoenhoff at gmail.com>:
> 2005/10/21, Ted Harding <Ted.Harding at nessie.mcc.ac.uk>:
> > On 21-Oct-05 Marco Venanzi wrote:
> > > Hi, I'm trying to read data from a PDF file.Is it possible to do it
> > > with R? Thanks,  Marco

> Hmm, if this doesn't work you should have a look to pdftolpe, which is
> assumed to convert aribitrary PDF files to some LPE readable format.
> LPE is a lightweight programmer's editor, that should be able save the
> converted file into txt format.
>
> I never used this myself, though. In case you are running Windows my
> reply might not be of much help, sorry for that!

I've to correct myself: its pdftoipe, and ipe (I missed before that is
was IPE instead of LPE) is a graphical editor for drawing graphs in PS
and PDF. It can save files in XML but has problems to read in PDF
created by other programs according to its website:
http://ipe.compgeom.org/.


Thomas



From mschwartz at mn.rr.com  Fri Oct 21 22:02:32 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Fri, 21 Oct 2005 15:02:32 -0500
Subject: [R] make three plot to one plot
In-Reply-To: <96507a8e0510211213h50e0c31p1cbac965bcc9eb6c@mail.gmail.com>
References: <96507a8e0510211213h50e0c31p1cbac965bcc9eb6c@mail.gmail.com>
Message-ID: <1129924953.5534.33.camel@localhost.localdomain>

On Fri, 2005-10-21 at 21:13 +0200, Jan Sabee wrote:
> Dear all,
> I want to make three plot below to only one plot together with legend,
> how can I do that?
> I have tried with matplot function but I did not succeed.
> Thanks for your help.
> Sincerelly,
> Jan Sabee
> 
> test.five.x <- c(0.02,0.05,0.07,0.09,0.10,0.12,0.13,0.14,0.16,0.17,0.20,0.21,0.34,0.40)
> test.five.y <- c(18,12,17,12,3,15,1,5,1,1,3,10,15,10)
> plot(test.five.x, test.five.y, type="l",lty=1, lwd=3, col='red')
> legend(par('usr')[2], par('usr')[4], xjust=1,
>       c('five'),
>       lwd=3,
>       lty=1,
>       col=c('red'))
> test.six.x <- c(0.03,0.05,0.07,0.08,0.09,0.10,0.12,0.13,0.14,0.15,0.17,0.18,0.21,0.22,0.24,0.33,0.39,0.43)
> test.six.y <- c(8,32,14,21,3,8,11,14,11,21,16,14,10,21,1,2,13,19)
> plot(test.six.x, test.six.y, type="l",lty=2, lwd=3, col='green')
> legend(par('usr')[2], par('usr')[4], xjust=1,
>       c('six'),
>       lwd=3,
>       lty=2,
>       col=c('green'))
> test.seven.x <-
> c(0.04,0.05,0.08,0.09,0.10,0.12,0.13,0.14,0.16,0.17,0.19,0.21,0.22,0.24,0.29,0.32,0.38,0.40,0.46,0.50)
> test.seven.y <-
> c(18,135,240,42,63,128,215,267,127,36,21,23,223,12,66,96,12,26,64,159)
> plot(test.seven.x, test.seven.y, type="l",lty=3, lwd=2, col='blue')
> legend(par('usr')[2], par('usr')[4], xjust=1,
>       c('seven'),
>       lwd=3,
>       lty=3,
>       col=c('blue'))

Jan,

matplot() won't work well here, because you do not have common x axis
values across the three sets of data. Thus, you need to use plot() and
then lines().

Try this:

# First set up your data

test.five.x <- c(0.02,0.05,0.07,0.09,0.10,0.12,
                 0.13,0.14,0.16,0.17,0.20,0.21,
                 0.34,0.40)
test.five.y <- c(18,12,17,12,3,15,1,5,1,1,3,10,
                 15,10)

test.six.x <- c(0.03,0.05,0.07,0.08,0.09,0.10,
                0.12,0.13,0.14,0.15,0.17,0.18,
                0.21,0.22,0.24,0.33,0.39,0.43)
test.six.y <- c(8,32,14,21,3,8,11,14,11,21,16,
                14,10,21,1,2,13,19)

test.seven.x <- c(0.04,0.05,0.08,0.09,0.10,0.12,
                  0.13,0.14,0.16,0.17,0.19,0.21,
                  0.22,0.24,0.29,0.32,0.38,0.40,
                  0.46,0.50)
test.seven.y <- c(18,135,240,42,63,128,215,267,
                  127,36,21,23,223,12,66,96,12,
                  26,64,159)


# Now use plot to draw the first set of data
# The key here is to properly set to the x and y axis
# ranges ('xlim' and 'ylim') so that they are based
# upon all three sets of data.
# Note that I also set the x and y axis labels to "". You
# can adjust these and the plot title as you require.

plot(test.five.x, test.five.y, type="l",lty=1, lwd=3, col="red",
     xlim = range(test.five.x, test.six.x, test.seven.x),
     ylim = range(test.five.y, test.six.y, test.seven.y),
     xlab = "", ylab = "")


# Now use lines() to add the second and third sets of data

lines(test.six.x, test.six.y, lty=2, lwd=3, col="green")
lines(test.seven.x, test.seven.y, lty=3, lwd=2, col="blue")


# Now use legend(). Place it at the upper right hand corner
# and set the line types and colors to reflect the above

legend("topright", xjust = 1,
       legend = c("five", "six", "seven"),
       lwd = 3, lty = 1:3,
       col = c("red", "green", "blue"))


See ?lines for more information.

HTH,

Marc Schwartz



From tom at maladmin.com  Fri Oct 21 18:14:22 2005
From: tom at maladmin.com (tom wright)
Date: Fri, 21 Oct 2005 12:14:22 -0400
Subject: [R] locator
In-Reply-To: <4359459C.9080308@stats.uwo.ca>
References: <1129908231.4222.1.camel@localhost.localdomain>
	<4359459C.9080308@stats.uwo.ca>
Message-ID: <1129911262.4222.3.camel@localhost.localdomain>

Perfect, thankyou

On Fri, 2005-21-10 at 15:46 -0400, Duncan Murdoch wrote:
> On 10/21/2005 11:23 AM, tom wright wrote:
> > I'm trying to use the locator function on a drawing area with multiple
> > graphs par(mfrow=c(1,2))
> > Is it possible to identify which graph has been clicked?
> 
> locator() will return coordinates based on the active graph (typically 
> the last one you drew), so you can work it out from that.
> That is, convert from user coordinates to screen coordinates, and then 
> work out the position from there:
> 
> getcell <- function(pts = locator()) {
>    usr <- par("usr")
>    plt <- par("plt")
>    mfg <- par("mfg")
> 
>    x <- pts$x
>    y <- pts$y
> 
>    # convert to 0-1 plot coordinates
>    px <- (x-usr[1])/(usr[2]-usr[1])
>    py <- (y-usr[3])/(usr[4]-usr[3])
> 
>    # convert to 0-1 frame coordinates
>    fx <- plt[1] + px*(plt[2]-plt[1])
>    fy <- plt[3] + py*(plt[4]-plt[3])
> 
>    # convert to a relative cell position
>    cx <- floor(fx)
>    cy <- floor(fy)
> 
>    # return the absolute cell position
>    list(row = -cy+mfg[1],col = cx+mfg[2])
> }
>



From Roger.Bivand at nhh.no  Fri Oct 21 22:11:38 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 21 Oct 2005 22:11:38 +0200 (CEST)
Subject: [R] Finding the neighbors of the point
In-Reply-To: <200510211459.j9LExgnD030523@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.44.0510212157310.19619-100000@reclus.nhh.no>

On Fri, 21 Oct 2005, Leaf Sun wrote:

> Dear all,
> 
> I got point data of trees. I was wondering if anybody has experience in searching the neighbors within a specified distance efficiently.
> 
> X    Y     Z
> 99 	34	 65
> 98 	35	 29
> 98 	34	 28
> 99 	33	 33
> 98 	32	 23
> 99 	33	 21
> 99 	33	 22
> 99 	32	 24
> 99 	30	 23
>     ...
> 

> What I want to do is :  searching for the neighbors with a distance R
> for each tree & the neighbor must have a bigger Z.
> 
> 
> The data set is huge so the R-codes is working slowly when I search it
> without subset it.
> 

And huge is how big? For very large problems, you'll need a kd-tree or 
r-tree approach to divide up the point locations before making the spatial 
query (I think the retention of neighbours with a larger z is the final 
step). There do not seem to be such functions in R or contributed packages 
at present. If you are willing to collaborate, I can pass on a draft 
package corrected by Christian Sangiorgio for approximate nearest 
neighbours (an interface to ANN by David Mount and collaborators), but it 
isn't working yet. So an investment in time and some knowledge of C++ will 
be useful.

> Any suggestion would be much appreciated!
> 
> Leaf
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ggrothendieck at gmail.com  Fri Oct 21 22:21:24 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 21 Oct 2005 16:21:24 -0400
Subject: [R] make three plot to one plot
In-Reply-To: <96507a8e0510211213h50e0c31p1cbac965bcc9eb6c@mail.gmail.com>
References: <96507a8e0510211213h50e0c31p1cbac965bcc9eb6c@mail.gmail.com>
Message-ID: <971536df0510211321r59fcf70agac18f586dc563af7@mail.gmail.com>

# we can create a zoo object
library(zoo)
z <- merge(five = zoo(test.five.y, test.five.x),
	six = zoo(test.six.y, test.six.x),
	seven = zoo(test.seven.y, test.seven.x))

# and then plot it all in one go using na.approx to fill in generated NAs
plot(na.approx(z), plot.type = "single", xlab = "x", ylab = "y", ,col = 1:3)

# Finally add the legend
legend("topright", xjust = 1, lty = 1,
      legend = c("five", "six", "seven"),
      col = 1:3)



On 10/21/05, Jan Sabee <jan.sabee at gmail.com> wrote:
> Dear all,
> I want to make three plot below to only one plot together with legend,
> how can I do that?
> I have tried with matplot function but I did not succeed.
> Thanks for your help.
> Sincerelly,
> Jan Sabee
>
> test.five.x <- c(0.02,0.05,0.07,0.09,0.10,0.12,0.13,0.14,0.16,0.17,0.20,0.21,0.34,0.40)
> test.five.y <- c(18,12,17,12,3,15,1,5,1,1,3,10,15,10)
> plot(test.five.x, test.five.y, type="l",lty=1, lwd=3, col='red')
> legend(par('usr')[2], par('usr')[4], xjust=1,
>      c('five'),
>      lwd=3,
>      lty=1,
>      col=c('red'))
> test.six.x <- c(0.03,0.05,0.07,0.08,0.09,0.10,0.12,0.13,0.14,0.15,0.17,0.18,0.21,0.22,0.24,0.33,0.39,0.43)
> test.six.y <- c(8,32,14,21,3,8,11,14,11,21,16,14,10,21,1,2,13,19)
> plot(test.six.x, test.six.y, type="l",lty=2, lwd=3, col='green')
> legend(par('usr')[2], par('usr')[4], xjust=1,
>      c('six'),
>      lwd=3,
>      lty=2,
>      col=c('green'))
> test.seven.x <-
> c(0.04,0.05,0.08,0.09,0.10,0.12,0.13,0.14,0.16,0.17,0.19,0.21,0.22,0.24,0.29,0.32,0.38,0.40,0.46,0.50)
> test.seven.y <-
> c(18,135,240,42,63,128,215,267,127,36,21,23,223,12,66,96,12,26,64,159)
> plot(test.seven.x, test.seven.y, type="l",lty=3, lwd=2, col='blue')
> legend(par('usr')[2], par('usr')[4], xjust=1,
>      c('seven'),
>      lwd=3,
>      lty=3,
>      col=c('blue'))
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From nayeemquayum at gmail.com  Fri Oct 21 22:58:27 2005
From: nayeemquayum at gmail.com (Nayeem Quayum)
Date: Fri, 21 Oct 2005 14:58:27 -0600
Subject: [R] Help with SOM clustering package
Message-ID: <af6d2ccc0510211358u309dbc73gdabfcfe3a6566fc0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051021/bcd45abb/attachment.pl

From bolker at ufl.edu  Fri Oct 21 23:32:44 2005
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 21 Oct 2005 21:32:44 +0000 (UTC)
Subject: [R] peculiar matrices
Message-ID: <loom.20051021T231621-941@post.gmane.org>


As far as I can tell from reading The Fine Documentation
(R Language Definition and Intro to R), matrices are supposed
to be of homogeneous types.  Yet giving matrix() an inhomogeneous
list seems to work, although it produces a peculiar object:

v = list(1:3,4,5,"a")
m = matrix(v,nrow=2)
m

     [,1]      [,2]
[1,] Integer,3 5
[2,] 4         "a"


m[1,]

[[1]]
[1] 1 2 3

[[2]]
[1] 3

 (this is R 2.1.1, running under Linux)
  Should there be a check/error? Or is this just analogous to
the joke about going to the doctor and saying "it hurts when
I do this", and the doctor saying "well then, don't do that"?

  Ben Bolker



From tschoenhoff at gmail.com  Fri Oct 21 23:36:03 2005
From: tschoenhoff at gmail.com (=?ISO-8859-1?Q?Thomas_Sch=F6nhoff?=)
Date: Fri, 21 Oct 2005 23:36:03 +0200
Subject: [R] read data from pdf file
In-Reply-To: <5ad2dec0510211256w4b0cbab7j@mail.gmail.com>
References: <001801c5d66b$351dfe50$0501a8c0@nome65ff66cddf>
	<XFMail.051021200736.Ted.Harding@nessie.mcc.ac.uk>
	<5ad2dec0510211239uf4b301y@mail.gmail.com>
	<5ad2dec0510211256w4b0cbab7j@mail.gmail.com>
Message-ID: <5ad2dec0510211436r25241da6o@mail.gmail.com>

Hi,

2005/10/21, Thomas Sch??nhoff <tschoenhoff at gmail.com>:
> Hello again,
>
>
> 2005/10/21, Thomas Sch??nhoff <tschoenhoff at gmail.com>:
> > 2005/10/21, Ted Harding <Ted.Harding at nessie.mcc.ac.uk>:
> > > On 21-Oct-05 Marco Venanzi wrote:
> > > > Hi, I'm trying to read data from a PDF file.Is it possible to do it
> > > > with R? Thanks,  Marco
>
> > Hmm, if this doesn't work you should have a look to pdftolpe, which is
> > assumed to convert aribitrary PDF files to some LPE readable format.
> > LPE is a lightweight programmer's editor, that should be able save the
> > converted file into txt format.
> >
> > I never used this myself, though. In case you are running Windows my
> > reply might not be of much help, sorry for that!
>
> I've to correct myself: its pdftoipe, and ipe (I missed before that is
> was IPE instead of LPE) is a graphical editor for drawing graphs in PS
> and PDF. It can save files in XML but has problems to read in PDF
> created by other programs according to its website:
> http://ipe.compgeom.org/.

After looking up I finally found xpdf-utils which might help you to
convert PDF to text
At least I was able to convert a PDF file to text by typing:

pdftotext name.pdf

at the command line.

Maybe there will be some drawbacks related to the resulting text
format (manual adjustments required), but if there is no other way,
you should give it a shot.

regards

Thomas



From jan.sabee at gmail.com  Fri Oct 21 23:54:06 2005
From: jan.sabee at gmail.com (Jan Sabee)
Date: Fri, 21 Oct 2005 23:54:06 +0200
Subject: [R] make three plot to one plot
In-Reply-To: <96507a8e0510211213h50e0c31p1cbac965bcc9eb6c@mail.gmail.com>
References: <96507a8e0510211213h50e0c31p1cbac965bcc9eb6c@mail.gmail.com>
Message-ID: <96507a8e0510211454p26d4a9c6g3cdabeebfaf8d43c@mail.gmail.com>

Thanks to Marc and Gabor.
Have a nice weekend.
Best,
Jan Sabee

On 10/21/05, Jan Sabee <jan.sabee at gmail.com> wrote:
> Dear all,
> I want to make three plot below to only one plot together with legend,
> how can I do that?
> I have tried with matplot function but I did not succeed.
> Thanks for your help.
> Sincerelly,
> Jan Sabee
>
> test.five.x <- c(0.02,0.05,0.07,0.09,0.10,0.12,0.13,0.14,0.16,0.17,0.20,0.21,0.34,0.40)
> test.five.y <- c(18,12,17,12,3,15,1,5,1,1,3,10,15,10)
> plot(test.five.x, test.five.y, type="l",lty=1, lwd=3, col='red')
> legend(par('usr')[2], par('usr')[4], xjust=1,
>       c('five'),
>       lwd=3,
>       lty=1,
>       col=c('red'))
> test.six.x <- c(0.03,0.05,0.07,0.08,0.09,0.10,0.12,0.13,0.14,0.15,0.17,0.18,0.21,0.22,0.24,0.33,0.39,0.43)
> test.six.y <- c(8,32,14,21,3,8,11,14,11,21,16,14,10,21,1,2,13,19)
> plot(test.six.x, test.six.y, type="l",lty=2, lwd=3, col='green')
> legend(par('usr')[2], par('usr')[4], xjust=1,
>       c('six'),
>       lwd=3,
>       lty=2,
>       col=c('green'))
> test.seven.x <-
> c(0.04,0.05,0.08,0.09,0.10,0.12,0.13,0.14,0.16,0.17,0.19,0.21,0.22,0.24,0.29,0.32,0.38,0.40,0.46,0.50)
> test.seven.y <-
> c(18,135,240,42,63,128,215,267,127,36,21,23,223,12,66,96,12,26,64,159)
> plot(test.seven.x, test.seven.y, type="l",lty=3, lwd=2, col='blue')
> legend(par('usr')[2], par('usr')[4], xjust=1,
>       c('seven'),
>       lwd=3,
>       lty=3,
>       col=c('blue'))
>



From mschwartz at mn.rr.com  Fri Oct 21 23:56:18 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Fri, 21 Oct 2005 16:56:18 -0500
Subject: [R] peculiar matrices
In-Reply-To: <loom.20051021T231621-941@post.gmane.org>
References: <loom.20051021T231621-941@post.gmane.org>
Message-ID: <1129931779.5534.46.camel@localhost.localdomain>

On Fri, 2005-10-21 at 21:32 +0000, Ben Bolker wrote:
> As far as I can tell from reading The Fine Documentation
> (R Language Definition and Intro to R), matrices are supposed
> to be of homogeneous types.  Yet giving matrix() an inhomogeneous
> list seems to work, although it produces a peculiar object:
> 
> v = list(1:3,4,5,"a")
> m = matrix(v,nrow=2)
> m
> 
>      [,1]      [,2]
> [1,] Integer,3 5
> [2,] 4         "a"
> 
> 
> m[1,]
> 
> [[1]]
> [1] 1 2 3
> 
> [[2]]
> [1] 3
> 
>  (this is R 2.1.1, running under Linux)

Ben,

If you review the structure of 'm' note:

> str(m)
List of 4
 $ : int [1:3] 1 2 3
 $ : num 4
 $ : num 5
 $ : chr "a"
 - attr(*, "dim")= int [1:2] 2 2

that it is actually a list, even though:

> class(m)
[1] "matrix"


Also:

> mode(m)
[1] "list"

> typeof(m)
[1] "list"


If you remove the dim attributes, you get:

> dim(m) <- NULL
> m
[[1]]
[1] 1 2 3

[[2]]
[1] 4

[[3]]
[1] 5

[[4]]
[1] "a"


So I would argue that it is consistent with the documentation in that,
while the printed output is that of a matrix, it is a list, which of
course can handle heterogeneous data types.

This is Version 2.2.0 Patched (2005-10-20 r35979).


>   Should there be a check/error? Or is this just analogous to
> the joke about going to the doctor and saying "it hurts when
> I do this", and the doctor saying "well then, don't do that"?


Maybe more like:

"Doctor, my eye hurts when I drink my tea." and the doctor says, "Well,
remove the spoon from the cup before you drink."

;-)

Regards,

Marc Schwartz



From gunter.berton at gene.com  Sat Oct 22 00:03:11 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Fri, 21 Oct 2005 15:03:11 -0700
Subject: [R] peculiar matrices
In-Reply-To: <loom.20051021T231621-941@post.gmane.org>
Message-ID: <200510212203.j9LM3B6p015758@faraday.gene.com>

matrix coerces it's arguments to a single mode first. Try mode(m) -- iit's a
list (with a dim attribute). If you print each entry of m separately, you'll
find they're all lists.

As the docs say, if either of nrow or ncol aren't given, it tries to "infer"
what they should be from the data and other parameter. Haven't a clue what
the algorithm does, but given your data, it made a guess. What would you
have wanted it to give that makes any more sense?

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ben Bolker
> Sent: Friday, October 21, 2005 2:33 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] peculiar matrices
> 
> 
> As far as I can tell from reading The Fine Documentation
> (R Language Definition and Intro to R), matrices are supposed
> to be of homogeneous types.  Yet giving matrix() an inhomogeneous
> list seems to work, although it produces a peculiar object:
> 
> v = list(1:3,4,5,"a")
> m = matrix(v,nrow=2)
> m
> 
>      [,1]      [,2]
> [1,] Integer,3 5
> [2,] 4         "a"
> 
> 
> m[1,]
> 
> [[1]]
> [1] 1 2 3
> 
> [[2]]
> [1] 3
> 
>  (this is R 2.1.1, running under Linux)
>   Should there be a check/error? Or is this just analogous to
> the joke about going to the doctor and saying "it hurts when
> I do this", and the doctor saying "well then, don't do that"?
> 
>   Ben Bolker
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From efg at stowers-institute.org  Sat Oct 22 00:11:24 2005
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Fri, 21 Oct 2005 17:11:24 -0500
Subject: [R] R Programmer/Analyst
Message-ID: <djbp2c$1kp$1@sea.gmane.org>

From
http://www.stowers-institute.org/ScientistsSought/ScientistsSought.asp#positions

Programmer/Analyst

     The Stowers Institute for Medical Research has an opening for a
Programmer/Analyst to support scientific data analysis and assist with
computational biology tasks.

     Responsibilities include:
Developing and/or maintaining software for analyzing biological data,
typically using the R language.
Updating related software packages, as needed and documenting how packages
can be used with the existing computing infrastructure;
Developing solutions to computational biology problems and assisting with
scientific data analysis, especially with gene expression data;
Writing code to use existing software packages for data analysis; and
Monitoring changes in scientific software, especially R and Bioconductor
packages

     In addition to excellent communication skills, the successful candidate
will also have experience with Splus, R, Matlab, Maple, or Mathematica, and
experience with computational biology, scientific computing, numerical
analysis, multi-platform development (UNIX/Windows) databases, or web
programming.

     Minimum requirements include an undergraduate degree in science, math,
computer science, engineering, or a related field; at least one year of
programming experience, and experience with at least two languages such as
R, Python, Java, PERL, C#, C++ or C

Apply now:
http://www.stowers-institute.org/ScientistsSought/ScientistsSought.asp#resume

Stowers Institute for Medical Research
1000 East 50th Street
Kansas City, MO  64110
USA



From droberts at montana.edu  Sat Oct 22 00:09:50 2005
From: droberts at montana.edu (Dave Roberts)
Date: Fri, 21 Oct 2005 16:09:50 -0600
Subject: [R] read data from pdf file
In-Reply-To: <5ad2dec0510211436r25241da6o@mail.gmail.com>
References: <001801c5d66b$351dfe50$0501a8c0@nome65ff66cddf>	<XFMail.051021200736.Ted.Harding@nessie.mcc.ac.uk>	<5ad2dec0510211239uf4b301y@mail.gmail.com>	<5ad2dec0510211256w4b0cbab7j@mail.gmail.com>
	<5ad2dec0510211436r25241da6o@mail.gmail.com>
Message-ID: <4359672E.1090507@montana.edu>

In linux (and possibly other *nixes) you can view the file with xpdf and 
simply cut and paste it into another window (I use vi) and it's 
converted to ASCII text on the fly.  For large documents you might have 
to scroll quite a bit to convert the whole document, but this process 
has saved my neck a few times.  It does not work with acroread (the 
linux Acobat Reader program) however.

Dave Roberts

Thomas Sch??nhoff wrote:
> Hi,
> 
> 2005/10/21, Thomas Sch??nhoff <tschoenhoff at gmail.com>:
> 
>>Hello again,
>>
>>
>>2005/10/21, Thomas Sch??nhoff <tschoenhoff at gmail.com>:
>>
>>>2005/10/21, Ted Harding <Ted.Harding at nessie.mcc.ac.uk>:
>>>
>>>>On 21-Oct-05 Marco Venanzi wrote:
>>>>
>>>>>Hi, I'm trying to read data from a PDF file.Is it possible to do it
>>>>>with R? Thanks,  Marco
>>
>>>Hmm, if this doesn't work you should have a look to pdftolpe, which is
>>>assumed to convert aribitrary PDF files to some LPE readable format.
>>>LPE is a lightweight programmer's editor, that should be able save the
>>>converted file into txt format.
>>>
>>>I never used this myself, though. In case you are running Windows my
>>>reply might not be of much help, sorry for that!
>>
>>I've to correct myself: its pdftoipe, and ipe (I missed before that is
>>was IPE instead of LPE) is a graphical editor for drawing graphs in PS
>>and PDF. It can save files in XML but has problems to read in PDF
>>created by other programs according to its website:
>>http://ipe.compgeom.org/.
> 
> 
> After looking up I finally found xpdf-utils which might help you to
> convert PDF to text
> At least I was able to convert a PDF file to text by typing:
> 
> pdftotext name.pdf
> 
> at the command line.
> 
> Maybe there will be some drawbacks related to the resulting text
> format (manual adjustments required), but if there is no other way,
> you should give it a shot.
> 
> regards
> 
> Thomas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 
> 


--



From alanc at umit.maine.edu  Sat Oct 22 00:22:15 2005
From: alanc at umit.maine.edu (Alan Cobo-Lewis)
Date: Fri, 21 Oct 2005 18:22:15 -0400
Subject: [R] Any package to perform HLM (PROC GENMOD) like logistic
Message-ID: <fc.004c4d1923616947004c4d1923616947.23616ca2@umit.maine.edu>


I think you're looking for lmer( ... family="binomial" ) in package lme4 by Bates & Sarkar.

"William M. Grove" <grove001 at umn.edu> wrote:
>I know there are very nice facilities in Pinhiero and Bates for doing 
>HLM-type modeling for continuous dependent variables.  But I would 
>like to be able to do repeated measures logistic regression, or LR on 
>clustered observations

alan

--
Alan B. Cobo-Lewis, Ph.D.		(207) 581-3840 tel
Department of Psychology		(207) 581-6128 fax
University of Maine
Orono, ME 04469-5742     		alanc at maine.edu

http://www.umaine.edu/visualperception



From h.wickham at gmail.com  Sat Oct 22 00:42:18 2005
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 21 Oct 2005 17:42:18 -0500
Subject: [R] Generalised rbind/cbind
Message-ID: <f8e6ff050510211542k19758e1p916e0c214055c969@mail.gmail.com>

Dear list,

Is there a generalised form of rbind/cbind for combining
matrices/arrays into higher-D structures?  ie. if I have:

a <- matrix(2,2,2)
b <- matrix(3,2,2)

how can I get

array(rep(c(3,2), each=4), c(2,2,2))

?

It seems like this would be the job of a generalised abind function:
abind(a,b, along=1) == rbind(a,b)
abind(a,b, along=2) == cbind(a,b)
abind(a,b, along=3) ==array(rep(c(3,2), each=4), c(2,2,2))

Thanks,

Hadley



From MSchwartz at mn.rr.com  Sat Oct 22 01:16:00 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Fri, 21 Oct 2005 18:16:00 -0500
Subject: [R] Generalised rbind/cbind
In-Reply-To: <f8e6ff050510211542k19758e1p916e0c214055c969@mail.gmail.com>
References: <f8e6ff050510211542k19758e1p916e0c214055c969@mail.gmail.com>
Message-ID: <1129936560.4663.3.camel@localhost.localdomain>

On Fri, 2005-10-21 at 17:42 -0500, hadley wickham wrote:
> Dear list,
> 
> Is there a generalised form of rbind/cbind for combining
> matrices/arrays into higher-D structures?  ie. if I have:
> 
> a <- matrix(2,2,2)
> b <- matrix(3,2,2)
> 
> how can I get
> 
> array(rep(c(3,2), each=4), c(2,2,2))
> 
> ?
> 
> It seems like this would be the job of a generalised abind function:
> abind(a,b, along=1) == rbind(a,b)
> abind(a,b, along=2) == cbind(a,b)
> abind(a,b, along=3) ==array(rep(c(3,2), each=4), c(2,2,2))
> 
> Thanks,
> 
> Hadley

Hadley,

You just described the abind() function in the 'abind' package by Tony
Plate and Richard Heiberger.

HTH,

Marc Schwartz



From spencer.graves at pdf.com  Sat Oct 22 02:56:07 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 21 Oct 2005 17:56:07 -0700
Subject: [R] random coefficient multinomial logistic regression (was:
 "request")
In-Reply-To: <43492270@webmail>
References: <43492270@webmail>
Message-ID: <43598E27.5050000@pdf.com>

	  I haven't seen a reply to this post, so I just experimented with a 
few terms in R Site Search.  RSiteSearch("multinomial hierarchical 
model") produced 8 hits, the first of which was 
"http://finzi.psych.upenn.edu/R/library/bayesm/html/rhierMnlRwMixture.html". 


	  hope this helps.  spencer graves

nmi13 wrote:
> Dear All,
> 
> Can someone please tell me if there is a provision in R to fit a random 
> coefficient multinomial logistic regression.
> 
> Thanks in advance for your help and suggestions.
> 
> Regards
> Murthy.N.M
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From kjetil at redcotel.bo  Fri Oct 21 02:52:26 2005
From: kjetil at redcotel.bo (Kjetil Holuerson)
Date: Thu, 20 Oct 2005 20:52:26 -0400
Subject: [R] npmc package
In-Reply-To: <17239.47418.376571.347771@stat.math.ethz.ch>
References: <4356499A.6040604@ufba.br>	<43564EC4.7090407@statistik.uni-dortmund.de>	<43568C54.2060000@ufba.br>
	<17239.47418.376571.347771@stat.math.ethz.ch>
Message-ID: <43583BCA.7000509@redcotel.bo>

Martin Maechler wrote:
>>>>>> "Carlos" == Carlos Mauricio Cardeal Mendes <mcardeal at ufba.br>
>>>>>>     on Wed, 19 Oct 2005 15:11:32 -0300 writes:
> 
>     Carlos> So, is there another package to substitute those
>     Carlos> functions described on "ORPHANED" npmc package ?
> 
> May be not.
> But nobody stops you from becoming the new maintainer of the
> package, fix it such that it passes 'R CMD check' (for R-2.2.0)
> and resubmit it to CRAN; so it won't be orphaned anymore ...

I just looked, this package is now neither in the orphaned
subdirectory nor the main directory on CRAN ...

Kjetil

> 
>     Carlos> Regards,
>     Carlos> Mauricio
>     Carlos> Brazil
> 
> Regards,
> Martin Maechler, ETH Zurich
> 
>     Carlos> Uwe Ligges escreveu:
> 
>     >> Carlos Mauricio Cardeal Mendes wrote:
>     >> 
>     >>> Hi
>     >>> 
>     >>> Does anyone know where is the package: npmc (Nonparametric Multiple 
>     >>> Comparisons).
>     >>> 
>     >>> I found the reference on R Site Search, but not the package itself on 
>     >>> CRAN as suggested.
>     >> 
>     >> 
>     >> The packages is "ORPHANED" and removed from the CRAN main repository. 
>     >> You can get older versions from the archives, though:
>     >> 
>     >> your-CRAN-mirror/src/contrib/Archive/N/npmc_1.0-1.tar.gz
>     >> 
>     >> Uwe Ligges
>     >> 
>     >>> Thanks
>     >>> 
>     >>> Mauricio
>     >>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 



--



From kjetil at redcotel.bo  Fri Oct 21 22:27:08 2005
From: kjetil at redcotel.bo (Kjetil Holuerson)
Date: Fri, 21 Oct 2005 16:27:08 -0400
Subject: [R] npmc package
In-Reply-To: <17239.47418.376571.347771@stat.math.ethz.ch>
References: <4356499A.6040604@ufba.br>	<43564EC4.7090407@statistik.uni-dortmund.de>	<43568C54.2060000@ufba.br>
	<17239.47418.376571.347771@stat.math.ethz.ch>
Message-ID: <43594F1C.1010605@redcotel.bo>

Martin Maechler wrote:
>>>>>> "Carlos" == Carlos Mauricio Cardeal Mendes <mcardeal at ufba.br>
>>>>>>     on Wed, 19 Oct 2005 15:11:32 -0300 writes:
> 
>     Carlos> So, is there another package to substitute those
>     Carlos> functions described on "ORPHANED" npmc package ?
> 
> May be not.
> But nobody stops you from becoming the new maintainer of the

Just checked. This package is not  now in the ORPHANES
subdirectory, neither in the main CRAN  listing.

Kjetil

> package, fix it such that it passes 'R CMD check' (for R-2.2.0)
> and resubmit it to CRAN; so it won't be orphaned anymore ...
> 
>     Carlos> Regards,
>     Carlos> Mauricio
>     Carlos> Brazil
> 
> Regards,
> Martin Maechler, ETH Zurich
> 
>     Carlos> Uwe Ligges escreveu:
> 
>     >> Carlos Mauricio Cardeal Mendes wrote:
>     >> 
>     >>> Hi
>     >>> 
>     >>> Does anyone know where is the package: npmc (Nonparametric Multiple 
>     >>> Comparisons).
>     >>> 
>     >>> I found the reference on R Site Search, but not the package itself on 
>     >>> CRAN as suggested.
>     >> 
>     >> 
>     >> The packages is "ORPHANED" and removed from the CRAN main repository. 
>     >> You can get older versions from the archives, though:
>     >> 
>     >> your-CRAN-mirror/src/contrib/Archive/N/npmc_1.0-1.tar.gz
>     >> 
>     >> Uwe Ligges
>     >> 
>     >>> Thanks
>     >>> 
>     >>> Mauricio
>     >>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 



--



From ggrothendieck at gmail.com  Sat Oct 22 04:24:37 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 21 Oct 2005 22:24:37 -0400
Subject: [R] peculiar matrices
In-Reply-To: <loom.20051021T231621-941@post.gmane.org>
References: <loom.20051021T231621-941@post.gmane.org>
Message-ID: <971536df0510211924m48ea3b63m5b52dd61ccfddc0e@mail.gmail.com>

The reference manual of 2.2.0 says in section
2.2 that "Matrices and arrays are simply vectors
with the attribute dim and optionally dimnames."

Now earlier in section 2.1 it discusses vectors
and I think that that is where the confusing part lies.
Section 2.1 starts out saying that "Vectors
can be thought of as contiguous cells containing
homogeneous data." and that "R has six basic
('atomic') vector types: logical, integer, real,
complex, string (or character) and raw".   There
is no inkling yet that this is an incomplete
thought.

Its only later in the section that we find out that
atomic vectors are only one sort of vector: "Lists
are vectors, and the basic vector types are
referred to as atomic vectors where it is
necessary to exclude lists."

I think this section should be rewritten to
clearly state up front that there are atomic
vectors and generic vectors and then define each
of these.


On 10/21/05, Ben Bolker <bolker at ufl.edu> wrote:
>
> As far as I can tell from reading The Fine Documentation
> (R Language Definition and Intro to R), matrices are supposed
> to be of homogeneous types.  Yet giving matrix() an inhomogeneous
> list seems to work, although it produces a peculiar object:
>
> v = list(1:3,4,5,"a")
> m = matrix(v,nrow=2)
> m
>
>     [,1]      [,2]
> [1,] Integer,3 5
> [2,] 4         "a"
>
>
> m[1,]
>
> [[1]]
> [1] 1 2 3
>
> [[2]]
> [1] 3
>
>  (this is R 2.1.1, running under Linux)
>  Should there be a check/error? Or is this just analogous to
> the joke about going to the doctor and saying "it hurts when
> I do this", and the doctor saying "well then, don't do that"?
>
>  Ben Bolker
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From tomhopper at comcast.net  Sat Oct 22 04:34:11 2005
From: tomhopper at comcast.net (Thomas Hopper)
Date: Fri, 21 Oct 2005 22:34:11 -0400
Subject: [R] Sorting Numeric and Character Data
Message-ID: <9A9399C0-44E8-43FF-8CD3-FF1949979D1B@comcast.net>

Hello,

I have what seems like an easy question to answer, but I'm struggling  
with it.

I have a set of categorical data that I am reading in, looking  
something like:

"category" "result"
"A" .234
"B" .123
"C" .564
"D" -.452
"E" .112
"F" -.106

I'd like to plot this twice on two separate dot charts, once with the  
data ordered in ascending order by the "category" (character) column;  
the other graph ordered in descending order by the "result" (numeric)  
column.

My trouble is this: if I read this in as a data frame, I can order it  
using something like data[order(d3$result),], but the "category"  
column seems to get converted to an integer data type, which then  
plots as numbers rather than letters on the dotchart(). If I read it  
in as separate vector columns using scan() and copy-and-paste, I  
don't know how to order both vectors together (such that "A" and .234  
remain together).

Any help would be much appreciated.

Thanks,

Tom



From ggrothendieck at gmail.com  Sat Oct 22 04:46:28 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 21 Oct 2005 22:46:28 -0400
Subject: [R] Sorting Numeric and Character Data
In-Reply-To: <9A9399C0-44E8-43FF-8CD3-FF1949979D1B@comcast.net>
References: <9A9399C0-44E8-43FF-8CD3-FF1949979D1B@comcast.net>
Message-ID: <971536df0510211946y7d613fe3h1c2243d32e091c7c@mail.gmail.com>

Use read.table(myfile, header = TRUE, as.is = TRUE) where as.is=TRUE
causes read.table not to convert character data to factors.

On 10/21/05, Thomas Hopper <tomhopper at comcast.net> wrote:
> Hello,
>
> I have what seems like an easy question to answer, but I'm struggling
> with it.
>
> I have a set of categorical data that I am reading in, looking
> something like:
>
> "category" "result"
> "A" .234
> "B" .123
> "C" .564
> "D" -.452
> "E" .112
> "F" -.106
>
> I'd like to plot this twice on two separate dot charts, once with the
> data ordered in ascending order by the "category" (character) column;
> the other graph ordered in descending order by the "result" (numeric)
> column.
>
> My trouble is this: if I read this in as a data frame, I can order it
> using something like data[order(d3$result),], but the "category"
> column seems to get converted to an integer data type, which then
> plots as numbers rather than letters on the dotchart(). If I read it
> in as separate vector columns using scan() and copy-and-paste, I
> don't know how to order both vectors together (such that "A" and .234
> remain together).
>
> Any help would be much appreciated.
>
> Thanks,
>
> Tom
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Sat Oct 22 09:08:33 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 22 Oct 2005 08:08:33 +0100 (BST)
Subject: [R] peculiar matrices
In-Reply-To: <loom.20051021T231621-941@post.gmane.org>
References: <loom.20051021T231621-941@post.gmane.org>
Message-ID: <Pine.LNX.4.61.0510220747270.12355@gannet.stats>

Just to add to what others have said, don't confuse how an object is 
printed with its structure.  This must be intentional as the internal code 
has a specific section just to print list arrays/matrices.

?matrix has the first argument as

     data: an optional data vector.

and a list is a vector.


I did find the following incorrect statement in R-lang:

   As the elements of a vector or matrix must be of the same type there are
   multiple types of @code{NA} values.

That is missing `atomic' before `vector'.  Some parts of the R 
documentation were written before lists were vectors and so assume vectors 
are atomic, but instances of that assumption as rare nowadays.  If you 
find one, please report it.


On Fri, 21 Oct 2005, Ben Bolker wrote:

>
> As far as I can tell from reading The Fine Documentation
> (R Language Definition and Intro to R), matrices are supposed
> to be of homogeneous types.  Yet giving matrix() an inhomogeneous
> list seems to work, although it produces a peculiar object:
>
> v = list(1:3,4,5,"a")
> m = matrix(v,nrow=2)
> m
>
>     [,1]      [,2]
> [1,] Integer,3 5
> [2,] 4         "a"
>
>
> m[1,]
>
> [[1]]
> [1] 1 2 3
>
> [[2]]
> [1] 3
>
> (this is R 2.1.1, running under Linux)
>  Should there be a check/error? Or is this just analogous to
> the joke about going to the doctor and saying "it hurts when
> I do this", and the doctor saying "well then, don't do that"?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From karengreenphd at yahoo.com  Sat Oct 22 10:33:59 2005
From: karengreenphd at yahoo.com (Karen Green)
Date: Sat, 22 Oct 2005 01:33:59 -0700 (PDT)
Subject: [R] package mclust: cdens, EMclust?
Message-ID: <20051022083359.53595.qmail@web30705.mail.mud.yahoo.com>

Dear Knowledgeable R Community Members, 

Please excuse my ignorance -- I apologize in advance
if this is an easy question, but I am a bit stumped
and could use a little guidance regarding parameters
in 2 functions in the "mclust" package.

--------------------
PROBLEM DESCRIPTION
--------------------

I have a finite mixture modeling problem -- for
example, a 2-component gaussian mixture -- where the
components have a large overlap, and I am trying to
use the "mclust" package to solve this problem. 

I need to decompose that mixture into its 2 components
which will need to be plotted. 

-----------
QUESTIONS
-----------

What I don't know how to do is: 

(1) restrict the number of components to 2 in the
"EMclust" function 

(2) obtain and plot a component gaussian density 

Regarding (1), I think this should be the 'G' value
but the documentation is somewhat cryptic as regards
the format. Regarding (2), I think I need to use the
"cdens" function, but again the documentation is
somewhat cryptic. 

--------------------
SAMPLE CODE
--------------------

Here is a little test script to illustrate. (Note: my
real dataset will not have peaks this well separated,
but I needed to find a small example.) 

################## 
data(faithful) 
library(mclust) 

MyMixtureModel<-summary(EMclust(faithful$eruptions),faithful$eruptions)


attach(MyMixtureModel) 

mclust1Dplot(data=faithful$eruptions,z=z,mu=mu,sigmasq=sigmasq,pro=pro,ask=FALSE,type=c("density"))


do.call("mclust1Dplot",c(list(data=faithful$eruptions,ask=FALSE,type=c("density")),MyMixtureModel))


# plot components 
??? 
################## 

Any information you might be able to shed on this
would be very much appreciated. 

With appreciation for your help, 

Karen 
---
Karen M. Green, Ph.D.
Research Investigator
Drug Design Group
Sanofi Aventis Pharmaceuticals
Tucson, AZ
USA



From bartjoosen at hotmail.com  Sat Oct 22 10:38:48 2005
From: bartjoosen at hotmail.com (Bart Joosen)
Date: Sat, 22 Oct 2005 08:38:48 +0000
Subject: [R] Design of experiments: construction and calculation
Message-ID: <BAY111-F10756F55D131CBE867D715D8750@phx.gbl>

Hi All,

after searching a while on the R-project help archives, I found that I can 
construct factorial design with the conf.design package.

But now, how can I construct a design for 2 parameters at 3 levels and 1 
parameter at 2 levels?


And, maybe more important: how do I calculate the effects?

Thanks in advance

Bart



From ripley at stats.ox.ac.uk  Sat Oct 22 11:46:15 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 22 Oct 2005 10:46:15 +0100 (BST)
Subject: [R] npmc package
In-Reply-To: <43594F1C.1010605@redcotel.bo>
References: <4356499A.6040604@ufba.br>
	<43564EC4.7090407@statistik.uni-dortmund.de>
	<43568C54.2060000@ufba.br>
	<17239.47418.376571.347771@stat.math.ethz.ch>
	<43594F1C.1010605@redcotel.bo>
Message-ID: <Pine.LNX.4.61.0510221040050.9797@gannet.stats>

On Fri, 21 Oct 2005, Kjetil Holuerson wrote:

> Martin Maechler wrote:
>>>>>>> "Carlos" == Carlos Mauricio Cardeal Mendes <mcardeal at ufba.br>
>>>>>>>     on Wed, 19 Oct 2005 15:11:32 -0300 writes:
>>
>>     Carlos> So, is there another package to substitute those
>>     Carlos> functions described on "ORPHANED" npmc package ?
>>
>> May be not.
>> But nobody stops you from becoming the new maintainer of the
>
> Just checked. This package is not  now in the ORPHANES
> subdirectory, neither in the main CRAN  listing.

See http://cran.r-project.org/src/contrib/Archive/N/

The Orphaned (sic) subdirectory applies to packages dropped by the former 
maintainer which no longer pass R CMD check, and also to those where the 
CRAN maintainers are able to deduce it has been dropped.  Others which 
just fail without a positive indication of no active maintainer may end in 
the archive.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Sat Oct 22 11:52:49 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 22 Oct 2005 11:52:49 +0200
Subject: [R] npmc package
In-Reply-To: <43583BCA.7000509@redcotel.bo>
References: <4356499A.6040604@ufba.br>	<43564EC4.7090407@statistik.uni-dortmund.de>	<43568C54.2060000@ufba.br>
	<17239.47418.376571.347771@stat.math.ethz.ch>
	<43583BCA.7000509@redcotel.bo>
Message-ID: <435A0BF1.3000400@statistik.uni-dortmund.de>

Kjetil Holuerson wrote:
> Martin Maechler wrote:
> 
>>>>>>> "Carlos" == Carlos Mauricio Cardeal Mendes <mcardeal at ufba.br>
>>>>>>>     on Wed, 19 Oct 2005 15:11:32 -0300 writes:
>>
>>
>>     Carlos> So, is there another package to substitute those
>>     Carlos> functions described on "ORPHANED" npmc package ?
>>
>> May be not.
>> But nobody stops you from becoming the new maintainer of the
>> package, fix it such that it passes 'R CMD check' (for R-2.2.0)
>> and resubmit it to CRAN; so it won't be orphaned anymore ...
> 
> 
> I just looked, this package is now neither in the orphaned
> subdirectory nor the main directory on CRAN ...

Kjetil, yes, because nobody took over the package for more than half a 
year and the CRAN maintainer decided to delete it from the ORPHANED 
directory as well (not sure, but I think it has not passed the checks).
As already mentioned in an earlier post: The package is still in the 
Archive section of CRAN, though.

Uwe Liges


> Kjetil
> 
>>
>>     Carlos> Regards,
>>     Carlos> Mauricio
>>     Carlos> Brazil
>>
>> Regards,
>> Martin Maechler, ETH Zurich
>>
>>     Carlos> Uwe Ligges escreveu:
>>
>>     >> Carlos Mauricio Cardeal Mendes wrote:
>>     >>     >>> Hi
>>     >>>     >>> Does anyone know where is the package: npmc 
>> (Nonparametric Multiple     >>> Comparisons).
>>     >>>     >>> I found the reference on R Site Search, but not the 
>> package itself on     >>> CRAN as suggested.
>>     >>     >>     >> The packages is "ORPHANED" and removed from the 
>> CRAN main repository.     >> You can get older versions from the 
>> archives, though:
>>     >>     >> your-CRAN-mirror/src/contrib/Archive/N/npmc_1.0-1.tar.gz
>>     >>     >> Uwe Ligges
>>     >>     >>> Thanks
>>     >>>     >>> Mauricio
>>     >>>
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
>>
> 
> 
>



From rambam at bigpond.net.au  Sat Oct 22 12:31:55 2005
From: rambam at bigpond.net.au (rambam@bigpond.net.au)
Date: 22 Oct 2005 20:31:55 +1000
Subject: [R] reading data from a pdf
Message-ID: <87k6g56dwk.fsf@kafka.homenet>


> Hi, I'm trying to read data from a PDF file.Is it possible to do it
> with R? Thanks,  Marco

If cut and paste to a text file fails, try this:

pdftotext (from the xpdf project)

or

http://pdftohtml.sourceforge.net
pdftohtml is a utility which converts PDF files into HTML and
XML formats

In addition, pdftk, the command line pdf toolkit may be useful
http://www.accesspdf.com/pdftk/

-- 

Seek simplicity and mistrust it.
Alfred Whitehead

A witty saying proves nothing. 
Voltaire



From korbinian at vonblanckenburg.de  Sat Oct 22 14:07:58 2005
From: korbinian at vonblanckenburg.de (Korbinian von Blanckenburg)
Date: Sat, 22 Oct 2005 14:07:58 +0200
Subject: [R] simple question
Message-ID: <435A2B9E.9070800@vonblanckenburg.de>

Its just a simple question I guess:

I have a vector with missing information like 
x<-c(0,1,31,131,NA,133,NA,310,NA,112,3,1,2,93)

How can I make a vector like this no missing in it. I used the x[x<0] 
commabd and tried some more, with no success.

thx
Korbinian



From Kevin.Wang at maths.anu.edu.au  Sat Oct 22 14:14:38 2005
From: Kevin.Wang at maths.anu.edu.au (Ko-Kang Kevin Wang)
Date: Sat, 22 Oct 2005 22:14:38 +1000
Subject: [R] simple question
In-Reply-To: <435A2B9E.9070800@vonblanckenburg.de>
References: <435A2B9E.9070800@vonblanckenburg.de>
Message-ID: <435A2D2E.50400@maths.anu.edu.au>

Hi,

Korbinian von Blanckenburg wrote:
> Its just a simple question I guess:
> 
> I have a vector with missing information like 
> x<-c(0,1,31,131,NA,133,NA,310,NA,112,3,1,2,93)
> 
> How can I make a vector like this no missing in it. I used the x[x<0] 
> commabd and tried some more, with no success.

Try na.omit()

HTH,

Kevin

-- 
Ko-Kang Kevin Wang
PhD Student
Centre for Bioinformation Science
Building 27, Room 1004
Mathematical Sciences Institute (MSI)
Australian National University
Canberra, ACT 2601
Australia

Homepage: http://wwwmaths.anu.edu.au/~wangk/
Ph (W): +61-2-6125-2431
Ph (H): +61-2-6125-7488
Ph (M): +61-40-451-8301



From chrysopa at insecta.ufv.br  Sat Oct 22 14:25:12 2005
From: chrysopa at insecta.ufv.br (Ronaldo Reis-Jr.)
Date: Sat, 22 Oct 2005 10:25:12 -0200
Subject: [R] simple question
In-Reply-To: <435A2B9E.9070800@vonblanckenburg.de>
References: <435A2B9E.9070800@vonblanckenburg.de>
Message-ID: <200510221025.12438.chrysopa@insecta.ufv.br>

Em S??b 22 Out 2005 10:07, Korbinian von Blanckenburg escreveu:
> Its just a simple question I guess:
>
> I have a vector with missing information like
> x<-c(0,1,31,131,NA,133,NA,310,NA,112,3,1,2,93)
>
> How can I make a vector like this no missing in it. I used the x[x<0]
> commabd and tried some more, with no success.
>
> thx
> Korbinian
>

Hi,

try this:

x[is.na(x)==FALSE]

Inte
Ronaldo
-- 
There is a fly on your nose.
--
|>   // | \\   [***********************************]
|   ( ??   ?? )  [Ronaldo Reis J??nior                ]
|>      V      [UFV/DBA-Entomologia                ]
|    /     \   [36570-000 Vi??osa - MG              ]
|>  /(.''`.)\  [Fone: 31-3899-4007                 ]
|  /(: :'  :)\ [chrysopa at insecta.ufv.br            ]
|>/ (`. `'` ) \[ICQ#: 5692561 | LinuxUser#: 205366 ]
|    ( `-  )   [***********************************]
|>>  _/   \_Powered by GNU/Debian Woody/Sarge



From p.dalgaard at biostat.ku.dk  Sat Oct 22 14:50:33 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 22 Oct 2005 14:50:33 +0200
Subject: [R] simple question
In-Reply-To: <200510221025.12438.chrysopa@insecta.ufv.br>
References: <435A2B9E.9070800@vonblanckenburg.de>
	<200510221025.12438.chrysopa@insecta.ufv.br>
Message-ID: <x2y84lg1gm.fsf@turmalin.kubism.ku.dk>

"Ronaldo Reis-Jr." <chrysopa at insecta.ufv.br> writes:

> try this:
> 
> x[is.na(x)==FALSE]

<whinge>

x[!is.na(x)]

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From gwgilc at wm.edu  Sat Oct 22 16:05:04 2005
From: gwgilc at wm.edu (George W. Gilchrist)
Date: Sat, 22 Oct 2005 10:05:04 -0400
Subject: [R] Male and female symbols?
Message-ID: <2FED5980-3778-4A6E-9550-A07ECB4D7142@wm.edu>

Does anyone have an idea of how one might plot male and female  
symbols on a graph using R? Thanks!

..................................................................
George W. Gilchrist                        Email #1: gwgilc at wm.edu
Department of Biology, Box 8795          Email #2: kitesci at cox.net
College of William & Mary                    Phone: (757) 221-7751
Williamsburg, VA 23187-8795                    Fax: (757) 221-6483
http://gwgilc.people.wm.edu/



From ggrothendieck at gmail.com  Sat Oct 22 16:30:51 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 22 Oct 2005 10:30:51 -0400
Subject: [R] Male and female symbols?
In-Reply-To: <2FED5980-3778-4A6E-9550-A07ECB4D7142@wm.edu>
References: <2FED5980-3778-4A6E-9550-A07ECB4D7142@wm.edu>
Message-ID: <971536df0510220730t5f138ffau66eb8d67ced359b0@mail.gmail.com>

demo(Hershey)

On 10/22/05, George W. Gilchrist <gwgilc at wm.edu> wrote:
> Does anyone have an idea of how one might plot male and female
> symbols on a graph using R? Thanks!
>
> ..................................................................
> George W. Gilchrist                        Email #1: gwgilc at wm.edu
> Department of Biology, Box 8795          Email #2: kitesci at cox.net
> College of William & Mary                    Phone: (757) 221-7751
> Williamsburg, VA 23187-8795                    Fax: (757) 221-6483
> http://gwgilc.people.wm.edu/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Ted.Harding at nessie.mcc.ac.uk  Sat Oct 22 16:58:11 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 22 Oct 2005 15:58:11 +0100 (BST)
Subject: [R] Male and female symbols?
In-Reply-To: <2FED5980-3778-4A6E-9550-A07ECB4D7142@wm.edu>
Message-ID: <XFMail.051022155811.Ted.Harding@nessie.mcc.ac.uk>

On 22-Oct-05 George W. Gilchrist wrote:
> Does anyone have an idea of how one might plot male and female  
> symbols on a graph using R? Thanks!

Groping for an answer to this, I was led to run

  demo(Hershey)

and the screen "Special Escape Sequences" showed appropriate
symbols at

  \\VE

and

  \\MA

Maybe you can develop this for your needs.

(However, perhaps if you use these you should maintain a certain
distance between the male and female symbols, or you might get a
lot of noisy little subscripts ... ).

George's query somewhat leads on to a more general question:
Can one define one's own symbols for plotting?

For example -- though I'm not seriously saying I need this --
in a population study of faxes and rabbits surveyed over several
years, one might wish to plot the Rabbit population using tiny
rabbits as points, and foxes' heads for the Fox population.

(Given the data coordinates, I would have my own ways to do this;
but not in R).

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 22-Oct-05                                       Time: 15:55:41
------------------------------ XFMail ------------------------------



From ripley at stats.ox.ac.uk  Sat Oct 22 17:14:15 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 22 Oct 2005 16:14:15 +0100 (BST)
Subject: [R] Male and female symbols?
In-Reply-To: <2FED5980-3778-4A6E-9550-A07ECB4D7142@wm.edu>
References: <2FED5980-3778-4A6E-9550-A07ECB4D7142@wm.edu>
Message-ID: <Pine.LNX.4.61.0510221559130.5783@gannet.stats>

On Sat, 22 Oct 2005, George W. Gilchrist wrote:

> Does anyone have an idea of how one might plot male and female
> symbols on a graph using R? Thanks!

You don't tell us your platform and the answer depends on the platform.

They are Unicode points U+2642 and U+2640.  So if your system supports it, 
something like text(x, y, "\u2642") will work, as will
points(x, y, pch="\u2642").

Alternatively, look at the Hershey fonts, which have these and many other 
symbols (not necessarily of publication-quality though).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From spencer.graves at pdf.com  Sat Oct 22 18:52:18 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 22 Oct 2005 09:52:18 -0700
Subject: [R] Candlestick chart?  (was:  Rmetrics fMultivar how to?)
In-Reply-To: <200510091553.17893.kb2qzv@poczta.wp.pl>
References: <200510091553.17893.kb2qzv@poczta.wp.pl>
Message-ID: <435A6E42.6080306@pdf.com>

	  Have you received a reply?  I haven't seen one.  I thought I had seen 
something on "candlestick" charts, but I could not find it now.  I 
believe there is a capability like that, but perhaps under a different 
name.  If you would still like help from this group, please submit 
another post with brief but internally complete example as outlined in 
the posting guide (www.R-project.org/posting-guide.html) describing what 
you've tried and how it is inadequate.  For example, if you had provided 
the commands you used to download WIG20.txt, that would have made it 
easier for me to at least get the same data.  I know there are 
procedures in Rmetrics for downloading data, but I don't remember how to 
do it just now, and I don't have time at the moment to research that.

	  Good Luck,
	  spencer graves

Benedict P. Barszcz wrote:
> Hi Everybody,
> I am a total beginner at this so please bear with me.
> I downloaded by hand the file WIG20.txt (Warsaw Stock Exchange Index of 20 
> most important stocks). The format is this:
> 
> Name,Date,Open,High,Low,Close,Volume 
> WIG20,19940414,1000.00,1000.00,1000.00,1000.00,71600.000 
> WIG20,19940418,1050.50,1050.50,1050.50,1050.50,99950.000 
> WIG20,19940419,1124.90,1124.90,1124.90,1124.90,138059.000 
> WIG20,19940421,1304.80,1304.80,1304.80,1304.80,154151.000 
> WIG20,19940425,1350.10,1350.10,1350.10,1350.10,228438.000 
> WIG20,19940426,1216.20,1216.20,1216.20,1216.20,16618.000 
> WIG20,19940428,1096.70,1096.70,1096.70,1096.70,32685.000 
> WIG20,19940505,1138.10,1138.10,1138.10,1138.10,113777.000 
> WIG20,19940506,1077.60,1077.60,1077.60,1077.60,137910.000 
> WIG20,19940509,1035.60,1035.60,1035.60,1035.60,97091.000
> 
> I read the data in with this command:
> 
> 
>>tabelka = read.table("/home/kb2qzv/WIG20.txt",sep=",",header=TRUE)
> 
> 
> And I can see that 'tabelka' has 2840 rows in it which is correct (this many 
> sessions since the Exchange started operating).
> Now I would like to utilize some of the functions available from RMetrics and 
> see how useful they might be. I can image that one way to know this would be 
> to plot a candlestick chart of the wig20 index and below it a TA indicator, 
> like one of these:
> 
> macdTA      MACD Indicator
> cdsTA     MACD Signal Line
> cdoTA      MACD Oscillator
> vohlTA High/Low Volatility
> 
> Trouble is there is no easy way (for me as a beginner) to start with.
> Questions:
> A) how to plot a candlestick chart with my data?
> there seems to be no 'type=candlestick' parameter in plot() function.
> 
> B) how to create a second pane where an indicator can be drawn.
> 
> thanks for any answers or tips.
> 
> 

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From murdoch at stats.uwo.ca  Sat Oct 22 19:37:59 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 22 Oct 2005 13:37:59 -0400
Subject: [R] diag() problem
In-Reply-To: <4356725F.6020704@stats.uwo.ca>
References: <1A0E77A8-077D-4D20-BAA2-CB388A899363@soc.soton.ac.uk>	<43566309.7090808@stats.uwo.ca>	<Pine.LNX.4.61.0510191633030.18811@gannet.stats>
	<4356725F.6020704@stats.uwo.ca>
Message-ID: <435A78F7.8070306@stats.uwo.ca>

Duncan Murdoch wrote:
> On 10/19/2005 11:37 AM, Prof Brian Ripley wrote:
> 
>>On Wed, 19 Oct 2005, Duncan Murdoch wrote:
>>
>>
>>>On 10/19/2005 10:55 AM, Robin Hankin wrote:
>>>
>>>>Hi
>>>>
>>>>I have a matrix "u", for which diag() gives an error:
>>>>
>>>>u <- structure(c(5.42334674128216, -2.31319389204264, -5.83059042218476,
>>>>  -1.64112369640695, -2.31319389212801, 3.22737617646609,
>>>>1.85200668021569,
>>>>  -0.57102273078531, -5.83059042231881, 1.85200668008156,
>>>>11.9488923894962,
>>>>  -3.5525537165941, -1.64112369587405, -0.571022730886046,
>>>>-3.55255371755604,
>>>>  10.0989829379577), .Dim = c(4, 4), .Dimnames = list(c("constant",
>>>>  NA, NA, NA), c("constant", NA, NA, NA)))
>>>>
>>>>
>>>>>u
>>>>
>>>>           constant       <NA>      <NA>       <NA>
>>>>constant  5.423347 -2.3131939 -5.830590 -1.6411237
>>>><NA>     -2.313194  3.2273762  1.852007 -0.5710227
>>>><NA>     -5.830590  1.8520067 11.948892 -3.5525537
>>>><NA>     -1.641124 -0.5710227 -3.552554 10.0989829
>>>>
>>>>>is.matrix(u)
>>>>
>>>>[1] TRUE
>>>>
>>>>>diag(u)
>>>>
>>>>Error in if (is.list(nms) && !any(sapply(nms, is.null)) && all((nm <-
>>>>nms[[1]][1:m]) ==  :
>>>>     missing value where TRUE/FALSE needed
>>>>
>>>>
>>>>
>>>>What's going on here?
>>>
>>>It's trying to check whether the row names match the column names, in
>>>which case it will assign those names to the diagonal elements.  But the
>>>writer didn't figure someone would have NA names, so the test
>>>
>>>all((nm <- nms[[1]][1:m]) == nms[[2]][1:m])
>>>
>>>fails.
>>>
>>>It could be "fixed" by putting "na.rm=TRUE" into the all(), but that's
>>>probably not right:
>>>
>>>
>>>>all(c(1, NA) == c(1, 2), na.rm = TRUE)
>>>
>>>[1] TRUE
>>>
>>>I think we want to wrap the values in "paste", to convert to non-missing
>>>characters.  That would be
>>>
>>>all(paste((nm <- nms[[1]][1:m])) == paste(nms[[2]][1:m]))
>>>
>>>and would give
>>>
>>>
>>>>diag(u)
>>>
>>> constant      <NA>      <NA>      <NA>
>>> 5.423347  3.227376 11.948892 10.098983
>>>
>>>Any objections to me committing this change?
>>
>>Yes, you don't want <NA> to match "NA".
>>
>>If you think NA names should match, use identical.   Otherwise (and I 
>>think this would be more consistent with other parts of R), do something
>>like
>>
>>eq <- (nm <- nms[[1]][1:m]) == nms[[2]][1:m]
>>if(all(!is.na(eq) && eq)) ...
>>
> 
> 
> I agree with your objection; I realized the same thing just after I 
> posted my original.  The solution I came up with was putting the all() 
> in isTRUE().  I think that achieves an identical result to your solution.

I've just committed a fix for this to R-patched and R-devel.  I didn't 
end up using isTRUE(all( ... )), instead I used Martin's suggested 
identical( ... ), since that's consistent with match().  This has the 
effect that Robin's example looks like this:

 > diag(u)
  constant      <NA>      <NA>      <NA>
  5.423347  3.227376 11.948892 10.098983

Duncan Murdoch



From leaflovesun at yahoo.ca  Sat Oct 22 20:23:17 2005
From: leaflovesun at yahoo.ca (Leaf Sun)
Date: Sun, 23 Oct 2005 02:23:17 +0800
Subject: [R] Errors occured
Message-ID: <200510221824.j9MIO2Fj022955@hypatia.math.ethz.ch>

Hi all,

Has anybody have the experience in the errors:

Error in data.frame(..., check.names=FALSE): arguments imply differing number of rows: 343,15

This is the error occured in the middle of the program. I don't think the data frame has any problem, if there is problem with the program, why it happened in the middle?

Does anybody have such an experience? It seems so weird to me.

Thanks a lot!

Leaf



From tomhopper at comcast.net  Sat Oct 22 21:05:40 2005
From: tomhopper at comcast.net (Thomas Hopper)
Date: Sat, 22 Oct 2005 15:05:40 -0400
Subject: [R] Sorting Numeric and Character Data
In-Reply-To: <971536df0510211946y7d613fe3h1c2243d32e091c7c@mail.gmail.com>
References: <9A9399C0-44E8-43FF-8CD3-FF1949979D1B@comcast.net>
	<971536df0510211946y7d613fe3h1c2243d32e091c7c@mail.gmail.com>
Message-ID: <53B30FD0-8499-4660-93B9-AF09592C5C8C@comcast.net>

Thank you; that did it!

Regards,

Tom

On Oct 21, 2005, at 10:46 PM, Gabor Grothendieck wrote:

> Use read.table(myfile, header = TRUE, as.is = TRUE) where as.is=TRUE
> causes read.table not to convert character data to factors.
>
> On 10/21/05, Thomas Hopper <tomhopper at comcast.net> wrote:
>
>> Hello,
>>
>> I have what seems like an easy question to answer, but I'm struggling
>> with it.
>>
>> I have a set of categorical data that I am reading in, looking
>> something like:
>>
>> "category" "result"
>> "A" .234
>> "B" .123
>> "C" .564
>> "D" -.452
>> "E" .112
>> "F" -.106
>>
>> I'd like to plot this twice on two separate dot charts, once with the
>> data ordered in ascending order by the "category" (character) column;
>> the other graph ordered in descending order by the "result" (numeric)
>> column.
>>
>> My trouble is this: if I read this in as a data frame, I can order it
>> using something like data[order(d3$result),], but the "category"
>> column seems to get converted to an integer data type, which then
>> plots as numbers rather than letters on the dotchart(). If I read it
>> in as separate vector columns using scan() and copy-and-paste, I
>> don't know how to order both vectors together (such that "A" and .234
>> remain together).
>>
>> Any help would be much appreciated.
>>
>> Thanks,
>>
>> Tom
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting- 
>> guide.html
>>
>

---
"Do you realize the responsibility I carry? I?m the only person
  between Nixon and the White House."
                                   -John F. Kennedy



From Peter.Ruckdeschel at uni-bayreuth.de  Sat Oct 22 21:23:26 2005
From: Peter.Ruckdeschel at uni-bayreuth.de (Peter Ruckdeschel)
Date: Sat, 22 Oct 2005 21:23:26 +0200
Subject: [R] [R-pkgs] after package reorganization: version 1.6 of package
 "distr" available;
 new packages "distrEx", "distrSim", "distrTEst", "RandVar"
Message-ID: <435A91AE.4020109@uni-bayreuth.de>

After some reorganization, we would like to announce the availability
on CRAN of a new version (1.6) of our package "distr" as well as the
availabilty on CRAN of the new packages "distrEx", "distrSim",
"distrTEst", "RandVar".

-----------------------------------------------------------------------------------------
Changes from 1.5 to 1.6
-[former package "distr"] reorganization:
 we have split up our package distr into smaller units:
 * "distr" now only contains the (basic) classes and methods
           for distributions
 * "distrSim" requires "distr" and contains classes and methods
           for data / simulations formerly contained in "distr"
 * "distrTEst" requires "distr" and "distrSim" and contains
           classes and methods for evaluation of estimators
           at data / simulations formerly contained in "distr"
-[distrSim] under the hood: signature of method "simulate" adapted
            in order to prevent collision with corresponding method
            from the stats package
some more details to be found at
http://www.uni-bayreuth.de/departments/math/org/mathe7/DISTR
a more detailed manual is available at
http://www.uni-bayreuth.de/departments/math/org/mathe7/DISTR/distr.pdf

-additional packages by Matthias Kohl:
 * "distrEx" requires "distr" and contains some extensions to
           package "distr" (see later)
 * "RandVar" requires "distr" and "distrEx" and contains classes
           and methods for random variables (see later)
These two packages are described in some detail in Matthias' PhD Thesis
"Numerical Contributions to the Asymptotic Theory of Robustness", App. D
available on http://stamats.de/ThesisMKohl.pdf

-----------------------------------------------------------------------------------------
Short Descriptions
-----------------------------------------------------------------------------------------
Short Description of "distr":
"distr" is to provide a conceptual treatment of random variables
(r.v.'s) by means of S4--classes. A virtual mother class "Distribution"
is introduced.
All distributions of the "base" package are implemented as subclasses of
either "AbscontDistribution" or "DiscreteDistribution".

Using these classes, we also provide (default) methods to automatically
generate the image distributions under unary mathematical operations as
well as a general convolution algorithm.
-----------------------------------------------------------------------------------------
Short Description of "distrSim":
Classes and methods are provided for a standardized treatment of
simulations (also under contaminations) .
-----------------------------------------------------------------------------------------
Short Description of "distrTEst":
Classes and methods are provided for a standardized treatment of
the evaluation of statistical procedures (up to now only estimators)
at data/simulations
-----------------------------------------------------------------------------------------
Short Description of "distrEx":
This package provides some extensions to package "distr"
like:
* extreme value distribution classes,
*expectations
  +in the form E(X)  for the expectation of X where X is some
    distribution or
  +in the form E(X,f) for the expectation of f(X) where X is
     some distribution and f some function in X,
* truncated moments,
* distances between distributions
  (Hellinger, Kolmogorov, total variation, "convex contamination")
* lists of distributions,
* conditional distributions in factorized form 
* conditional expectations in factorized form
-----------------------------------------------------------------------------------------
Short Description of "RandVar":
This package introduces classes and methods for random
variables (understood as measurable mappings); in particular
groups Math and Arith as well as matrix multiplication  and
expectations are available so that quite general "regular" expressions
with random variables are possible.
-----------------------------------------------------------------------------------------
We look forward to receiving questions, comments and suggestions

Peter Ruckdeschel
Matthias Kohl
Thomas Stabla
Florian Camphausen
-----------------------------------------------------------------------------------------
DESCRIPTIONS
-----------------------------------------------------------------------------------------
Package: distr
Version: 1.6
Date: 2005-10-17
Title: distr
Authors: Peter Ruckdeschel <peter.ruckdeschel at uni-bayreuth.de>,
Matthias Kohl <matthias.kohl at uni-bayreuth.de>,
Thomas Stabla <statho3 at web.de>,
Florian Camphausen <fcampi at gmx.de>
Maintainer: Peter Ruckdeschel <peter.ruckdeschel at uni-bayreuth.de>
Description: S4 Classes for Distributions
Depends: R (>= 2.2.0), (versions for <=2.2.0, on URL cited below),
License: GPL version 2 or later
URL: http://www.uni-bayreuth.de/departments/math/org/mathe7/DISTR/
Reference:
http://www.uni-bayreuth.de/departments/math/org/mathe7/DISTR/distr.pdf
-----------------------------------------------------------------------------------------
Package: distrSim
Version: 1.6
Date: 2005-10-17
Title: Simulation classes based on package distr
Depends: R(>= 2.2.0), methods, graphics, setRNG, distr
Imports: stats
Authors: Peter Ruckdeschel <peter.ruckdeschel at uni-bayreuth.de>,
Matthias Kohl <matthias.kohl at uni-bayreuth.de>,
Thomas Stabla <statho3 at web.de>,
Florian Camphausen <fcampi at gmx.de>
Description: Simulation (S4-)classes based on package distr
Maintainer: Peter Ruckdeschel <Peter.Ruckdeschel at uni-bayreuth.de>
License: GPL (version 2 or later)
URL: http://www.uni-bayreuth.de/departments/math/org/mathe7/DISTR/
Reference:
http://www.uni-bayreuth.de/departments/math/org/mathe7/DISTR/distr.pdf
-----------------------------------------------------------------------------------------
Package: distrTEst
Version: 1.6
Date: 2005-10-17
Title: Estimation and Testing classes based on package distr
Depends: R(>= 2.2.0), methods, graphics, setRNG, distr, distrSim
Imports: stats
Authors: Peter Ruckdeschel <peter.ruckdeschel at uni-bayreuth.de>,
Matthias Kohl <matthias.kohl at uni-bayreuth.de>,
Thomas Stabla <statho3 at web.de>,
Florian Camphausen <fcampi at gmx.de>
Description: Evaluation (S4-)classes based on package distr for
evaluating
    procedures (estimators/tests) at data/simulation in a unified way.
Maintainer: Peter Ruckdeschel <Peter.Ruckdeschel at uni-bayreuth.de>
License: GPL (version 2 or later)
URL: http://www.uni-bayreuth.de/departments/math/org/mathe7/DISTR/
Reference:
http://www.uni-bayreuth.de/departments/math/org/mathe7/DISTR/distr.pdf
-----------------------------------------------------------------------------------------
Package: distrEx
Version: 0-4.1
Date: 2005-10-17
Title: Extensions of package distr
Description: Extensions of package distr and some additional functionality
Depends: R(>= 2.0.1), methods, distr, evd
Author: Matthias Kohl
Maintainer: Matthias Kohl <Matthias.Kohl at stamats.de>
License: GPL (version 2 or later)
URL: http://www.uni-bayreuth.de/departments/math/org/mathe7/DISTR/
Reference:  http://stamats.de/ThesisMKohl.pdf , App. D
-----------------------------------------------------------------------------------------
Package: RandVar
Version: 0.4-1
Date: 2005-10-17
Title: Implementation of random variables
Description: Implementation of random variables by means
    of S4 classes and methods
Depends: R (>= 2.0.1), methods, distr(>= 1.6), distrEx
Author: Matthias Kohl
Maintainer: Matthias Kohl <Matthias.Kohl at stamats.de>
License: GPL version 2 or later
URL: http://www.uni-bayreuth.de/departments/math/org/mathe7/DISTR/
Reference:  http://stamats.de/ThesisMKohl.pdf , App. D

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From ligges at statistik.uni-dortmund.de  Sat Oct 22 21:32:13 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 22 Oct 2005 21:32:13 +0200
Subject: [R] Errors occured
In-Reply-To: <200510221824.j9MIO2Fj022955@hypatia.math.ethz.ch>
References: <200510221824.j9MIO2Fj022955@hypatia.math.ethz.ch>
Message-ID: <435A93BD.7030202@statistik.uni-dortmund.de>

Leaf Sun wrote:
> Hi all,
> 
> Has anybody have the experience in the errors:
> 
> Error in data.frame(..., check.names=FALSE): arguments imply differing number of rows: 343,15
> 
> This is the error occured in the middle of the program. I don't think the data frame has any problem, if there is problem with the program, why it happened in the middle?
> 
> Does anybody have such an experience? It seems so weird to me.


Well, do you really think we can help if you do not tell us anything
about your code?
Please read the psoting guide cited below and try to reformulate your
question after that... given you have not already found a solution after
reading the guide.

Uwe Ligges



> Thanks a lot!
> 
> Leaf
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From jebyrnes at ucdavis.edu  Sat Oct 22 21:37:04 2005
From: jebyrnes at ucdavis.edu (Jarrett Byrnes)
Date: Sat, 22 Oct 2005 12:37:04 -0700
Subject: [R] Getting univariate information from a multivariate data set
Message-ID: <48c5a8919fddf22ccea5b744700bec68@ucdavis.edu>

A quick question that I've had only partial success in answering.  I 
have a multivariate dataset, and would like to extract some simple 
univariate information from it grouped by treatments, etc.  I am 
encountering two problems however
Note: I am importing my data with
my_data <- read.csv("/path/data.csv")

1) Scoping of unstack

If I attempt

sorted_data <- unstack(response, response ~ treatment, data=my_data)

I get

Error in unstack(response, response ~ treatment, data=my_data): Object 
response not found

However, if I first use attatch(my_data) and drop the data statement in 
unstack, I'm fine.  This is all well and good, but I often work with 
multiple data sets with similar column headings, and would rather not 
have to attach and detach over and over again.

2) getting the univariate data

Once, I attach, I find that I cannot then easily just use mean, sd, or 
anysuch, as

mean(sorted_data)

yields

argument is not numeric or logical: returning NA in: mean.default(a)

Nor does something like mean(sorted_data[1]) work - I thought perhaps 
breaking it down by treatment might help.


Thanks in advance for any help!

-Jarrett


----------------------------------------
Jarrett Byrnes
Population Biology Graduate Group, UC Davis
Bodega Marine Lab
707-875-1969
http://www-eve.ucdavis.edu/stachowicz/byrnes.shtml



From sourceforge at metrak.com  Sun Oct 23 01:12:00 2005
From: sourceforge at metrak.com (paul sorenson (sosman))
Date: Sun, 23 Oct 2005 09:12:00 +1000
Subject: [R] read data from pdf file
In-Reply-To: <001801c5d66b$351dfe50$0501a8c0@nome65ff66cddf>
References: <001801c5d66b$351dfe50$0501a8c0@nome65ff66cddf>
Message-ID: <435AC740.5010205@metrak.com>

Marco Venanzi wrote:
> Hi, I'm trying to read data from a PDF file.Is it possible to do it
> with R? Thanks,  Marco [[alternative HTML version deleted]]

Ghostview has at least one method for extracting the text from a PDF 
document.  In particular Text|Extract allows you to select pages for 
extraction.  This may or may not give the same result as pdftotext 
because I think that is ghostscript based.

Your mileage may vary when extracting tables from a PDF.

cheers



From gregory_gentlemen at yahoo.ca  Sun Oct 23 02:54:42 2005
From: gregory_gentlemen at yahoo.ca (Gregory Gentlemen)
Date: Sat, 22 Oct 2005 20:54:42 -0400 (EDT)
Subject: [R] factorizing many columns of a dataframe
Message-ID: <20051023005442.56188.qmail@web31208.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051022/c5623346/attachment.pl

From 042045003 at fudan.edu.cn  Sun Oct 23 06:05:22 2005
From: 042045003 at fudan.edu.cn (ronggui)
Date: Sun, 23 Oct 2005 12:05:22 +0800
Subject: [R] factorizing many columns of a dataframe
Message-ID: <0IOS007CAO7QBK@mail.fudan.edu.cn>

data frame is a special list.so you can use lapply to do it.

======= 2005-10-23 08:54:42 ÄúÔÚÀ´ÐÅÖÐÐ´µÀ£º=======

>Hi guys,
> 
>I have a large number of columns of a dataframe that I want to apply a common factorization to; the columns are all numeric and the factorization collapses some of these values into common groups (labels). How can I do this systematically?
>Is there an analog to sapply that can pass columns as vectors to FUN?
> 
>Thanks in advance,
>Gregory Gentlemen
>
>		
>---------------------------------
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

= = = = = = = = = = = = = = = = = = = =
			


 

2005-10-23

------
Deparment of Sociology
Fudan University

My new mail addres is ronggui.huang at gmail.com
Blog:http://sociology.yculblog.com



From 042045003 at fudan.edu.cn  Sun Oct 23 11:15:57 2005
From: 042045003 at fudan.edu.cn (ronggui)
Date: Sun, 23 Oct 2005 17:15:57 +0800
Subject: [R] question about technieque do with large computation
Message-ID: <0IOT0078F2LHBK@mail.fudan.edu.cn>

The green book tells:"The basic technique is classic :keep it simple ."A long ,complicated expression or function is less fravorable than" a relatively small computations that combines calls to a few other functions to perform its tasks."

But I don't get the point totally.Can anyone give me an example to make me understand this rules totally?

ps:
Is it mean that f1 is better than f2?  Thank you!


f1<-function(x){
n<-length(x)
s<-sum(x)
m<-s/n}

f2<-
function(x){
m<-sum(x)/length(x)} 				


2005-10-23

------
Deparment of Sociology
Fudan University

My new mail addres is ronggui.huang at gmail.com
Blog:http://sociology.yculblog.com



From dominic.senn at gmx.net  Sun Oct 23 11:28:24 2005
From: dominic.senn at gmx.net (Dominic Senn)
Date: Sun, 23 Oct 2005 11:28:24 +0200
Subject: [R] Probelms installing package RMySQL (Dominic Senn)
Message-ID: <000001c5d7b4$1e5c2e90$989e4954@dominic>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051023/c0fec66c/attachment.pl

From ripley at stats.ox.ac.uk  Sun Oct 23 12:36:30 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 23 Oct 2005 11:36:30 +0100 (BST)
Subject: [R] Probelms installing package RMySQL (Dominic Senn)
In-Reply-To: <000001c5d7b4$1e5c2e90$989e4954@dominic>
References: <000001c5d7b4$1e5c2e90$989e4954@dominic>
Message-ID: <Pine.LNX.4.61.0510231131400.10534@gannet.stats>

On Sun, 23 Oct 2005, Dominic Senn wrote:

> Hi
> I have R 2.2.0 and SUSE 10.0 installed. When I try to install the package
> RMySQL I get the error that the library "libz" could not be found. This is
> strange because I find the library "libz.so.1" in the directory "/usr/lib/".
>
> Can anybody help? Thanks a lot in advance, Dominic

We may be able to help if you tell us at what stage in the install process 
this happens and quote the exact message.

Note that you will need libz.so and not just libz.so.1, so it is likely 
you have a development RPM missing.  On FC3

gannet% rpm -q --whatprovides /usr/lib/libz.so
zlib-devel-1.2.1.2-3.fc3
gannet% rpm -q --whatprovides /usr/lib/libz.so.1
zlib-1.2.1.2-3.fc3



>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

PLEASE do, and not send HTML mail.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sourceforge at metrak.com  Sun Oct 23 13:52:21 2005
From: sourceforge at metrak.com (paul sorenson (sosman))
Date: Sun, 23 Oct 2005 21:52:21 +1000
Subject: [R] brewing stats
Message-ID: <435B7975.2090802@metrak.com>

I guess this isn't so much of a help request as a show-and-tell from a 
non-statistician homebrewer who has been fumbling around with R.  If 
nothing else it provides yet another data set.  I hope it is not out of 
line.

Anyway, the plots I have produced are at

	http://brewiki.org/BatchSparge#poll

The polling method is somewhat simple, its just one of those multiple 
choice style polls you can create on various web forums.

The poll was prompted by the ongoing claim from fly spargers that 
"their" method is more efficient, but I had never seen data to support 
that.  I thought maybe it was a bit of snobbery.

Maybe they are right.  However if I conveniently ignore that annoying 
bump on the left of the batch sparge histogram then the two groups start 
to look very similar.

I was going to go out on a limb and say I learn heaps from reading the 
posts here so please don't ruin my delusion too much if my output 
violates all principles of good statistics. OTOH if you can suggest 
other cool looking graphs please feel free.  The more difficult to 
pronounce the names are, the better :-)

The data set is (efficiency is the low end of its bin):

method	efficiency	count	source
fly	95	0	bb
fly	90	0	bb
fly	85	2	bb
fly	80	8	bb
fly	75	13	bb
fly	70	8	bb
fly	65	3	bb
fly	60	0	bb
fly	55	0	bb
batch	95	0	bb
batch	90	0	bb
batch	85	4	bb
batch	80	3	bb
batch	75	15	bb
batch	70	10	bb
batch	65	6	bb
batch	60	7	bb
batch	55	1	bb

And the R code:

# Crunch some stuff with brewboard (and similar polls).
# Data is already tabulated.

x = read.csv("SpargeEff.csv")

# Shift value to centre of bin
x$efficiency = x$efficiency + 2.5
# Ignore rows with no votes (NA), zeros are ok though
y = x[which(!is.na(x$count)),]
r = rep(row.names(y), y$count)
z = y[r,]
z$count = 1

par(mfrow=c(2,2))
barplot(table(z$method), main="number of responses")
barplot(table(z$method, z$efficiency), beside=T, legend=T, main="Mash 
efficiency by method", sub="paul sorenson 2005 brewiki.org")
boxplot(z$efficiency ~ z$method, main="Mash efficiency")
z.h = hist(z$efficiency, prob=T, main="Efficiencies,\n all methods 
combined", xlab="efficiency")
z.md = max(z.h$density)
lines(density(z$efficiency, bw=3.0), col='blue')
#qqnorm(x$efficiency)
t.test(efficiency ~ method, data=z)
#by(z, z$method, summary)
zs = split(z, z$method)
summary(zs$batch)
summary(zs$fly)

# fit a normal distribution
require(MASS)
z.fit = fitdistr(z$efficiency, 'normal')
q = 55:95 + 2.5
lines(q, dnorm(q, z.fit$estimate['mean'], z.fit$estimate['sd']), col='red')
legend('topleft', legend=c('density', 'fitted'), col=c('blue', 'red'), 
lwd=1, inset=0.05)

# Factor out lowball values.
z.f = z[which(z$efficiency >= 65),]
by(z.f, z.f$method, summary)



From dominic.senn at gmx.net  Sun Oct 23 15:08:05 2005
From: dominic.senn at gmx.net (Dominic Senn)
Date: Sun, 23 Oct 2005 15:08:05 +0200 (MEST)
Subject: [R] Fwd: WG:  Probelms installing package RMySQL (Dominic Senn)
References: <000001c5d7cc$7e479d90$43994954@dominic>
Message-ID: <5118.1130072885@www39.gmx.net>

Thanks for your speedy reply! Now it worked fine. After installing via Yast
the package  "mysql-devel" there was the library "libz.so" and afterwards I
could install RMySQL without errors. 


-----Urspr??ngliche Nachricht-----
Von: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Gesendet: Sunday, October 23, 2005 12:37 PM
An: Dominic Senn
Cc: r-help at stat.math.ethz.ch
Betreff: Re: [R] Probelms installing package RMySQL (Dominic Senn)


On Sun, 23 Oct 2005, Dominic Senn wrote:

> Hi
> I have R 2.2.0 and SUSE 10.0 installed. When I try to install the 
> package RMySQL I get the error that the library "libz" could not be 
> found. This is strange because I find the library "libz.so.1" in the 
> directory "/usr/lib/".
>
> Can anybody help? Thanks a lot in advance, Dominic

We may be able to help if you tell us at what stage in the install process 
this happens and quote the exact message.

Note that you will need libz.so and not just libz.so.1, so it is likely 
you have a development RPM missing.  On FC3

gannet% rpm -q --whatprovides /usr/lib/libz.so zlib-devel-1.2.1.2-3.fc3
gannet% rpm -q --whatprovides /usr/lib/libz.so.1 zlib-1.2.1.2-3.fc3



>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html

PLEASE do, and not send HTML mail.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595




-- 
Highspeed-Freiheit. Bei GMX superg??nstig, z.B. GMX DSL_Cityflat,



From v.schlecht at arcor.de  Sun Oct 23 15:19:33 2005
From: v.schlecht at arcor.de (v.schlecht@arcor.de)
Date: Sun, 23 Oct 2005 15:19:33 +0200 (CEST)
Subject: [R] Weighted Least Squares mit glm
Message-ID: <31125780.1130073573022.JavaMail.ngmail@webmail-01.arcor-online.net>

Hallo all,

I have a question concerning the weights used in the glm function.

I need to build a linear model (family=gaussian) with only one regressor. Sadly I have only 6 different sets:

y_i=alpha+beta*x_i , i=1,2,3,4,5.

i=1,2,3,4,5 has been observed 60 times, while i=6 has only been observed 30 times. This is why I wanted to use a weighted least squares approach instead of least squares. 

I used the weight w1<-c(1,1,1,1,1,0.5).

Can anybody tell me if this is correct?

THX. 

Machen Sie aus 14 Cent spielend bis zu 100 Euro!
Die neue Gaming-Area von Arcor - ??ber 50 Onlinespiele im Angebot.
http://www.arcor.de/rd/emf-gaming-1



From kjetil at redcotel.bo  Sat Oct 22 22:19:18 2005
From: kjetil at redcotel.bo (Kjetil Holuerson)
Date: Sat, 22 Oct 2005 16:19:18 -0400
Subject: [R] Design of experiments: construction and calculation
In-Reply-To: <BAY111-F10756F55D131CBE867D715D8750@phx.gbl>
References: <BAY111-F10756F55D131CBE867D715D8750@phx.gbl>
Message-ID: <435A9EC6.5010806@redcotel.bo>

Bart Joosen wrote:
> Hi All,
> 
> after searching a while on the R-project help archives, I found that I can 
> construct factorial design with the conf.design package.

Have a look at CRAN package AlgDesign

Kjetil

> 
> But now, how can I construct a design for 2 parameters at 3 levels and 1 
> parameter at 2 levels?
> 
> 
> And, maybe more important: how do I calculate the effects?
> 
> Thanks in advance
> 
> Bart
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 



--



From bolker at zoo.ufl.edu  Sun Oct 23 17:31:32 2005
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Sun, 23 Oct 2005 15:31:32 +0000 (UTC)
Subject: [R] peculiar matrices
References: <loom.20051021T231621-941@post.gmane.org>
	<Pine.LNX.4.61.0510220747270.12355@gannet.stats>
Message-ID: <loom.20051023T172935-132@post.gmane.org>


  thanks all; this makes sense now.  For what
it's worth, this came up in the context of
mapply(...,SIMPLIFY=TRUE), which returned a
matrix as requested, but an odd-looking one.

  cheers
    Ben Bolker



From ben.bob at gmail.com  Sun Oct 23 23:42:34 2005
From: ben.bob at gmail.com (Bo Peng)
Date: Sun, 23 Oct 2005 16:42:34 -0500
Subject: [R] dyn.load a f90 module.
Message-ID: <6ea7b5430510231442u7218acdek4f8ab4b3dbabd64b@mail.gmail.com>

Dear list,

Has there been any success in loading modules written in f90? I tried

% ifort -c myfile.f90
% R CMD SHLIB myfile.o
% R
dyn.load('myfile.so')
.Fortran('myfile')

I used intel (free) fortran compiler under linux. All commands run
successfully except that function myfile is not loaded. (Is there a
function/tool to list symbols in a .so file?)

Many thanks in advance.
Bo



From sourceforge at metrak.com  Sun Oct 23 23:55:05 2005
From: sourceforge at metrak.com (paul sorenson (sosman))
Date: Mon, 24 Oct 2005 07:55:05 +1000
Subject: [R] dyn.load a f90 module.
In-Reply-To: <6ea7b5430510231442u7218acdek4f8ab4b3dbabd64b@mail.gmail.com>
References: <6ea7b5430510231442u7218acdek4f8ab4b3dbabd64b@mail.gmail.com>
Message-ID: <435C06B9.80300@metrak.com>

Bo Peng wrote:
> Dear list,
> 
> Has there been any success in loading modules written in f90? I tried
> 
> % ifort -c myfile.f90
> % R CMD SHLIB myfile.o
> % R
> dyn.load('myfile.so')
> .Fortran('myfile')
> 
> I used intel (free) fortran compiler under linux. All commands run
> successfully except that function myfile is not loaded. (Is there a
> function/tool to list symbols in a .so file?)

If there are symbols present then unix 'nm' should show them to you.



From ben.bob at gmail.com  Mon Oct 24 00:28:34 2005
From: ben.bob at gmail.com (Bo Peng)
Date: Sun, 23 Oct 2005 15:28:34 -0700
Subject: [R] dyn.load a f90 module.
In-Reply-To: <435C06B9.80300@metrak.com>
References: <6ea7b5430510231442u7218acdek4f8ab4b3dbabd64b@mail.gmail.com>
	<435C06B9.80300@metrak.com>
Message-ID: <6ea7b5430510231528v10d21b64x5ef2a3dd2d6efaa6@mail.gmail.com>

> If there are symbols present then unix 'nm' should show them to you.

Interestingly:

% nm myfile.so
00000004fc T myfile_
% R
> dyn.load('myfile.so')
> is.loaded('myfile_')
[1] TRUE
> ..Fortran('myfile_')
Error in .Fortran('myfile_'):
  'Fortran" function name not in load table.

So, myfile_ is loaded but is not callable by R?

Bo



From murdoch at stats.uwo.ca  Mon Oct 24 00:47:31 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 23 Oct 2005 18:47:31 -0400
Subject: [R] dyn.load a f90 module.
In-Reply-To: <6ea7b5430510231528v10d21b64x5ef2a3dd2d6efaa6@mail.gmail.com>
References: <6ea7b5430510231442u7218acdek4f8ab4b3dbabd64b@mail.gmail.com>	<435C06B9.80300@metrak.com>
	<6ea7b5430510231528v10d21b64x5ef2a3dd2d6efaa6@mail.gmail.com>
Message-ID: <435C1303.4020504@stats.uwo.ca>

Bo Peng wrote:
>>If there are symbols present then unix 'nm' should show them to you.
> 
> 
> Interestingly:
> 
> % nm myfile.so
> 00000004fc T myfile_
> % R
> 
>>dyn.load('myfile.so')
>>is.loaded('myfile_')
> 
> [1] TRUE
> 
>>..Fortran('myfile_')
> 
> Error in .Fortran('myfile_'):
>   'Fortran" function name not in load table.
> 
> So, myfile_ is loaded but is not callable by R?

.Fortran automatically appends an underscore (on most platforms).  Try 
.Fortran('myfile') instead (or use .C('myfile_')).

Or update to the current release of R, which gives a more informative 
error message.

Duncan Murdoch



From jeff.a.ryan at gmail.com  Mon Oct 24 02:06:13 2005
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Sun, 23 Oct 2005 19:06:13 -0500
Subject: [R] Probelms installing package RMySQL (Dominic Senn)
In-Reply-To: <mailman.11.1130061601.17116.r-help@stat.math.ethz.ch>
References: <mailman.11.1130061601.17116.r-help@stat.math.ethz.ch>
Message-ID: <24946B16-ABC4-489A-A370-61A424CE4E48@gmail.com>

Make sure you have your environment variable LDFLAGS set to "-L/usr/ 
lib", otherwise I believe the linker doesn't look there.

You can check where R looks in the Makeconf file, under LDFLAGS.

Not too sure though - just slogged through building on a brand new  
Solaris box, and that was my problem. I am sure there are others who  
know FAR more than I.

jeff
On Oct 23, 2005, at 5:00 AM, r-help-request at stat.math.ethz.ch wrote:

> [R] Probelms installing package RMySQL (Dominic Senn)



From mario.aignertorres at gmail.com  Mon Oct 24 03:21:58 2005
From: mario.aignertorres at gmail.com (Mario Aigner-Torres)
Date: Sun, 23 Oct 2005 23:21:58 -0200
Subject: [R] adding error bars to lattice plots
In-Reply-To: <af34d0c00510210512u7e45ff65of5dea962857e088b@mail.gmail.com>
References: <af34d0c00510191434v23e2be42v493570589417deec@mail.gmail.com>
	<200510192219.j9JMJIEo018489@ohm.gene.com>
	<af34d0c00510200952u54663a70o73e6f115622b58c8@mail.gmail.com>
	<eb555e660510202012i79159a5cm4a50734386d94b3c@mail.gmail.com>
	<af34d0c00510210512u7e45ff65of5dea962857e088b@mail.gmail.com>
Message-ID: <af34d0c00510231821x1676b0f1v1e39479247dee5e2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051023/de3968e7/attachment.pl

From euna0 at dreamwiz.com  Mon Oct 24 03:55:32 2005
From: euna0 at dreamwiz.com (Eun A Kim)
Date: Mon, 24 Oct 2005 10:55:32 +0900 (GMT)
Subject: [R] GAM and AIC: How can I do??? please
Message-ID: <20051024015532.0000C00B01D902E9@pmail1.dreamwiz.com>


   Hello,  I'm a Korean researcher who have been started to learn the "R"
   package.

   I want to make gam model and AIC value of the model to compare several
   models.

   I did the GAM model, but there were error for AIC.

   SO, how can I do? pleas help me!!!



   I did like below;


   > a.fit <- gam(pi~ s(t1r), family = gaussian(link="log"))
   > summary(a.fit)


   Family: gaussian
   Link function: log

   Formula:
   pi ~ s(t1r)

   Parametric coefficients:
              Estimate  std. err.    t ratio    Pr(>|t|)
   constant   0.093105   0.005238      17.77    < 2.22e-16

   Approximate significance of smooth terms:
                 edf       chi.sq     p-value
   s(t1r)      1.833       24.153     0.00014213

   R-sq.(adj) =  0.435   Deviance explained = 47.1%
   GCV score = 0.0010938   Scale est. = 0.00099053  n = 30

   > AIC(a.fit)
   Error in logLik(object) : no applicable method for "logLik"


   Eun A Kim, MD, MPH, Ph.D
   Senior Researcher
   Occupational safety and Health Research Institute
   Korea Occupational Safety and Health Agency
   TEL : +82-32-510-0910, FAX: +82-32-518-0862
   Address:  34-4 Gusan-dong, Bupyung-Gu, Incheon city, 430-711, Republic
   of Korea
   Home Fax +82-(303)3111-0573
   [receive_check.cgi?sender=euna0 at dreamwiz.com&msgid=%3C20051024015532.0
   000C00B01D902E9 at pmail1.dreamwiz.com%3E&receiver=r-help at stat.math.ethz.
   ch&key=bd02e77f5ec97f754394e2adff337f11]


From 042045003 at fudan.edu.cn  Mon Oct 24 04:09:30 2005
From: 042045003 at fudan.edu.cn (ronggui)
Date: Mon, 24 Oct 2005 10:09:30 +0800
Subject: [R] GAM and AIC: How can I do??? please
Message-ID: <0IOU00JVXDIPGK@mail.fudan.edu.cn>


	

======= 2005-10-24 09:55:32 ÄúÔÚÀ´ÐÅÖÐÐ´µÀ£º=======

>
>   Hello,  I'm a Korean researcher who have been started to learn the "R"
>   package.
>
>   I want to make gam model and AIC value of the model to compare several
>   models.
>
>   I did the GAM model, but there were error for AIC.
>
>   SO, how can I do? pleas help me!!!
>
>
>
>   I did like below;
>
>
>   > a.fit <- gam(pi~ s(t1r), family = gaussian(link="log"))
>   > summary(a.fit)
>
>
>   Family: gaussian
>   Link function: log
>
>   Formula:
>   pi ~ s(t1r)
>
>   Parametric coefficients:
>              Estimate  std. err.    t ratio    Pr(>|t|)
>   constant   0.093105   0.005238      17.77    < 2.22e-16
>
>   Approximate significance of smooth terms:
>                 edf       chi.sq     p-value
>   s(t1r)      1.833       24.153     0.00014213
>
>   R-sq.(adj) =  0.435   Deviance explained = 47.1%
>   GCV score = 0.0010938   Scale est. = 0.00099053  n = 30

are you using the mgcv package?
if you are,just use a.fit$aic to get the aic.

>   > AIC(a.fit)
>   Error in logLik(object) : no applicable method for "logLik"
>
>
>   Eun A Kim, MD, MPH, Ph.D
>   Senior Researcher
>   Occupational safety and Health Research Institute
>   Korea Occupational Safety and Health Agency
>   TEL : +82-32-510-0910, FAX: +82-32-518-0862
>   Address:  34-4 Gusan-dong, Bupyung-Gu, Incheon city, 430-711, Republic
>   of Korea
>   Home Fax +82-(303)3111-0573
>   [receive_check.cgi?sender=euna0 at dreamwiz.com&msgid=%3C20051024015532.0
>   000C00B01D902E9 at pmail1.dreamwiz.com%3E&receiver=r-help at stat.math.ethz.
>   ch&key=bd02e77f5ec97f754394e2adff337f11]
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

= = = = = = = = = = = = = = = = = = = =
			


 

2005-10-24

------
Deparment of Sociology
Fudan University

My new mail addres is ronggui.huang at gmail.com
Blog:http://sociology.yculblog.com



From u9370004 at cc.kmu.edu.tw  Mon Oct 24 04:23:34 2005
From: u9370004 at cc.kmu.edu.tw (Chun-Ying Lee)
Date: Mon, 24 Oct 2005 10:23:34 +0800
Subject: [R] confine the value
Message-ID: <20051024021834.M50089@cc.kmu.edu.tw>

Dear R users:

  I wonder if it is possible to confine the value which 
"optim" optimized to be all positive. I use optim with 
method "Nelder-Mead". Please give me some comments.
Thanks in advance!!



From ggrothendieck at gmail.com  Mon Oct 24 04:33:22 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 23 Oct 2005 22:33:22 -0400
Subject: [R] confine the value
In-Reply-To: <20051024021834.M50089@cc.kmu.edu.tw>
References: <20051024021834.M50089@cc.kmu.edu.tw>
Message-ID: <971536df0510231933xc72f327rde326332e1203aad@mail.gmail.com>

If x is the variable being optimized replace it with x = z^2 and
optimize over z.  That will constraint x to be nonnegative.

On 10/23/05, Chun-Ying Lee <u9370004 at cc.kmu.edu.tw> wrote:
> Dear R users:
>
>  I wonder if it is possible to confine the value which
> "optim" optimized to be all positive. I use optim with
> method "Nelder-Mead". Please give me some comments.
> Thanks in advance!!



From mlz2+ at pitt.edu  Mon Oct 24 05:51:26 2005
From: mlz2+ at pitt.edu (mlz2+@pitt.edu)
Date: Sun, 23 Oct 2005 23:51:26 -0400 (EDT)
Subject: [R] In da.norm Error: NA/NaN/Inf in foreign function call (arg 2)
Message-ID: <4401.67.171.76.188.1130125886.squirrel@webmail.pitt.edu>

I am conducting a simulation study generating multivariate normal data,
deleting observations to create a
data set with missing values and then using multiple imputation via
da.norm in Schafer's norm package.

>From da.norm, I get the following error message: "Error: NA/NaN/Inf in
foreign function call (arg 2)"
The frequency of the error message seems to depend on the ratio of n to p
and the percent of missingness.
for example, n=50, p=5, 50% missing, it fails about 9 in 10 runs. For
n=100, p=3, 50% missing it fails
about 1 in 10 runs.

I suspected that near-singularity of the starting covariance matrix might
be to blame, but I found instances
where the error message occurred, but the covariance was invertible.

Any suggestions as to the reason for the error or an alterative way to
generate the imputations?
Sample code is included below.
Thanks,
Melissa

I am using R 2.2.0 with norm 1.0-9 on Windows XP Professional.

#Sample code:
library(norm)
n<-50
p<-5
prob.miss<-.5
#generate complete data
x<-matrix(rnorm(n*p),nrow=n)
#create missing data
for (j in 1:p)
{miss<-rbinom(n,1,prob.miss)
for (i in 1:n){if (miss[i]==1) x[i,j]<-NA}}
#create imputations
seed<-1234
rngseed(seed)
s <- prelim.norm(x)
thetahat <- em.norm(s,showits=F)
da.norm(s,thetahat,steps=1000,showits=F,return.ymis=TRUE)



From sncnt at macrogen.com  Mon Oct 24 07:31:59 2005
From: sncnt at macrogen.com (=?EUC-KR?B?sei068f2?=)
Date: Mon, 24 Oct 2005 14:31:59 +0900 (GMT+09:00)
Subject: [R] =?euc-kr?q?Lowess_Normalization_Parameter_Question?=
Message-ID: <-468920702.1130131919593.JavaMail.Administrator@macrogen.com>



Dear R Project Member

I'm sending this email for asking something about the analysis of normalization using sma package in R. 

While there are F for smoothing parameter and delta for Robust weight function and iteration for repeated number in lowess Normalization,

I'm just wondering if there is any parameters, in which numbers the each parameters are set up in general or standard sma packeage

Kim Dae Hyun, macrogen

From ripley at stats.ox.ac.uk  Mon Oct 24 08:34:40 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 24 Oct 2005 07:34:40 +0100 (BST)
Subject: [R] Probelms installing package RMySQL (Dominic Senn)
In-Reply-To: <24946B16-ABC4-489A-A370-61A424CE4E48@gmail.com>
References: <mailman.11.1130061601.17116.r-help@stat.math.ethz.ch>
	<24946B16-ABC4-489A-A370-61A424CE4E48@gmail.com>
Message-ID: <Pine.LNX.4.61.0510240730230.17253@gannet.stats>

On Sun, 23 Oct 2005, Jeff Ryan wrote:

> Make sure you have your environment variable LDFLAGS set to "-L/usr/
> lib", otherwise I believe the linker doesn't look there.

That is on the system default ld path on all known systems, including 
Solaris 8.

> You can check where R looks in the Makeconf file, under LDFLAGS.

Those are _additional_ places.

> Not too sure though - just slogged through building on a brand new
> Solaris box, and that was my problem. I am sure there are others who
> know FAR more than I.

Note that Dominic Senn had already replied to say this problem was solved: 
see

https://stat.ethz.ch/pipermail/r-help/2005-October/079897.html

>
> jeff
> On Oct 23, 2005, at 5:00 AM, r-help-request at stat.math.ethz.ch wrote:
>
>> [R] Probelms installing package RMySQL (Dominic Senn)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Mon Oct 24 09:49:00 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 24 Oct 2005 09:49:00 +0200
Subject: [R] GAM and AIC: How can I do??? please
In-Reply-To: <0IOU00JVXDIPGK@mail.fudan.edu.cn>
References: <0IOU00JVXDIPGK@mail.fudan.edu.cn>
Message-ID: <17244.37356.913522.67266@stat.math.ethz.ch>

>>>>> "ronggui" == ronggui  <042045003 at fudan.edu.cn>
>>>>>     on Mon, 24 Oct 2005 10:09:30 +0800 writes:

    ronggui> ======= 2005-10-24 09:55:32
    ronggui> ????????????????=======

    >>  Hello, I'm a Korean researcher who have been started to
    >> learn the "R" package.
    >> 
    >> I want to make gam model and AIC value of the model to
    >> compare several models.
    >> 
    >> I did the GAM model, but there were error for AIC.
    >> SO, how can I do? pleas help me!!!
    >> 
    >> 
    >> I did like below;

    >> 
    >> > a.fit <- gam(pi~ s(t1r), family = gaussian(link="log"))
    >> > summary(a.fit)

    >> >   Family: gaussian
    >> >   Link function: log
    >> >
    >> >   Formula:
    >> >   pi ~ s(t1r)
    >> >
    >> >   Parametric coefficients:
    >> >              Estimate  std. err.    t ratio    Pr(>|t|)
    >> >   constant   0.093105   0.005238      17.77    < 2.22e-16
    >> >
    >> >   Approximate significance of smooth terms:
    >> >                 edf       chi.sq     p-value
    >> >   s(t1r)      1.833       24.153     0.00014213
    >> >
    >> >   R-sq.(adj) =  0.435   Deviance explained = 47.1%
    >> >   GCV score = 0.0010938   Scale est. = 0.00099053  n = 30

    ronggui> are you using the mgcv package?  if you are,just
    ronggui> use a.fit$aic to get the aic.

hmm, yes, and no:

It's true what you say,  
BUT is not at all recommended in general:

You should use the generic AIC() function
rather than extracting components yourself.

This is a general priniciple:  If possible use  'extractor functions'
to work on objects rather then relying on internal
representations.

This is particularly relevant for fitted models:

Do use  residuals(.), fitted(.), LogLik(.), AIC(.), vcov(.) 
etc etc!


Now back to this problem:

    >> AIC(a.fit) 
    >> Error in logLik(object) : no applicable method for "logLik"

I can't reproduce this; Eun definitely needs to give more
details, since the following works fine:

> library(mgcv)
> x <- 1:50
> set.seed(1)
> y <- 2^(sin(x/10) + rnorm(50))
> a.fit <- gam(y ~ s(x), family = gaussian(link="log"))
> summary(a.fit)

Family: gaussian 
Link function: log 

Formula:
y ~ s(x)

Parametric coefficients:
            Estimate Std. Error t value Pr(>|t|)  
(Intercept)   0.3171     0.1251   2.535   0.0147 *
---
Signif. codes:  ..........{UTF-8 code}

Approximate significance of smooth terms:
       edf Est.rank    F p-value   
s(x) 2.858    9.000 3.07 0.00576 **
---
Signif. codes: ............

R-sq.(adj) =    0.4   Deviance explained = 43.5%
GCV score = 0.94391   Scale est. = 0.87107   n = 50

> AIC(a.fit)
[1] 140.6937
>



From tschoenhoff at gmail.com  Mon Oct 24 10:26:38 2005
From: tschoenhoff at gmail.com (=?ISO-8859-1?Q?Thomas_Sch=F6nhoff?=)
Date: Mon, 24 Oct 2005 10:26:38 +0200
Subject: [R] Strange update behavior of gregmisc
Message-ID: <5ad2dec0510240126w25667b68h@mail.gmail.com>

Hello,

I notice an odd behavior of gregmisc package when using
"update.packages()" via R --no-save (as root).
Every time I launch update.packages() gregmisc is repeatedly selected
for upgrade. Current available version of gregmisc is 2.08 according
to 'installed.packages()'. Despite I obviousely have already installed
the most up to date gregmisc,  gregmisc will be updated repeatedly?

No one seems to have noticed a similar behavior like this before
according to mail archive. All dependencies are seemingly meet and no
error messages occured, so I am kind of stuck to figure out what
happens here.
Here is my update session:

thomas# R --no-save

---------------------------------------------------------------------------------------
> update.packages()
--- Please select a CRAN mirror for use in this session ---
Loading Tcl/Tk interface ... done
gregmisc :
 Version 2.0.6 installed in /usr/lib/R/site-library
 Version 2.0.8 available at http://pangora.org/cran
Update (y/N/c)?  y
try URL 'http://pangora.org/cran/src/contrib/gregmisc_2.0.8.tar.gz'
Content type 'application/x-tar' length 901 bytes
URL opened
==================================================
downloaded 901 bytes

* Installing *source* package 'gregmisc' ...
No man pages found in package 'gregmisc'
** building package indices ...
* DONE (gregmisc)

The downloaded packages are in
        /tmp/Rtmp4Thydf/downloaded_packages
----------------------------------------------------------------------------------------------------------

When I relaunch 'update.packages()' the same as desribed above is
going to happen again?

Do I miss something?

regards

Thomas

My system (Debian Sarge):

platform i386-pc-linux-gnu
arch     i386
os       linux-gnu
system   i386, linux-gnu
status
major    2
minor    2.0
year     2005
month    10
day      06
svn rev  35749
language R



From r.hankin at noc.soton.ac.uk  Mon Oct 24 10:26:47 2005
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Mon, 24 Oct 2005 09:26:47 +0100
Subject: [R] [R-pkgs] new package bundle on CRAN:  BACCO
Message-ID: <4D8E1D88-AC4C-4B2B-837C-B3AFE94E6A5A@soc.soton.ac.uk>

Dear List

please find on CRAN a new R bundle, BACCO, for Bayesian analysis of
random functions, comprising two packages: emulator and calibrator.

Package calibrator implements:

?Bayesian calibration of computer models?, M. C. Kennedy and A.  
O'Hagan 2001. Journal of the Royal Statistical Society B, 63(3)  
pp425-464


and package emulator implements:
J. Oakley 2004. ?Estimating percentiles of uncertain computer code  
outputs?. Applied Statistics, 53(1), pp89-93.

J. Oakley and A. O'Hagan, 2002. ?Bayesian Inference for the  
Uncertainty Distribution of Computer Model Outputs?, Biometrika 89 
(4), pp769-784





The bundle is described in:

R. K. S. Hankin 2005. ?Introducing BACCO, an R bundle for Bayesian  
analysis of computer code output?, Journal of Statistical Software, 14 
(16)




enjoy


rksh

--

Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From uttam.phulwale at tcs.com  Mon Oct 24 10:48:40 2005
From: uttam.phulwale at tcs.com (uttam.phulwale@tcs.com)
Date: Mon, 24 Oct 2005 14:18:40 +0530
Subject: [R] Is 64-bit linux compatible version of 'R' available?
Message-ID: <OF2F4F6ECC.4C996C5A-ON652570A4.002F86BC-652570A4.002FE4AE@tcs.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051024/3f9a221c/attachment.pl

From B.Rowlingson at lancaster.ac.uk  Mon Oct 24 11:04:45 2005
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 24 Oct 2005 10:04:45 +0100
Subject: [R] Male and female symbols?
In-Reply-To: <XFMail.051022155811.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.051022155811.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <435CA3AD.5030402@lancaster.ac.uk>

(Ted Harding) wrote:

> For example -- though I'm not seriously saying I need this --
> in a population study of faxes and rabbits surveyed over several
> years, one might wish to plot the Rabbit population using tiny
> rabbits as points, and foxes' heads for the Fox population.

  I cant help thinking now of the graphic shown on the 'Brass Eye' 
comedy show on Animal Cruelty. Cue totally over-the-top 3d zooming 
barchart with mad lighting effects, and voice-over:

'If you plot "number of animals abused" against "what makes people 
cruel" versus "intelligence of either party", the pattern is so 
unreadable you might as well draw in a chain of fox heads on sticks.
And if you do that, an interesting thing happens: the word "cruel" 
starts flashing.'

  But seriously: you could load in an image with the pixmap package and 
plot with that:

library(pixmap)
x <- read.pnm(system.file("pictures/logo.ppm", package="pixmap")[1])
plot(1:10,type='n')
for(i in 1:10){addlogo(x,px=c(i-.2,i+.2),py=c(i-.2,i+.2))}

 From there to a chain of fox heads on sticks is a small step.

Baz



From idimakos at upatras.gr  Mon Oct 24 11:15:52 2005
From: idimakos at upatras.gr (=?iso-8859-7?Q?=C3=E9=DC=ED=ED=E7=F2_=C4=E7=EC=DC=EA=EF=F2?=)
Date: Mon, 24 Oct 2005 12:15:52 +0300 (EEST)
Subject: [R] Is 64-bit linux compatible version of 'R' available?
In-Reply-To: <OF2F4F6ECC.4C996C5A-ON652570A4.002F86BC-652570A4.002FE4AE@tcs.com>
References: <OF2F4F6ECC.4C996C5A-ON652570A4.002F86BC-652570A4.002FE4AE@tcs.com>
Message-ID: <53709.150.140.162.117.1130145352.squirrel@mail.upatras.gr>


On ??????, ?????????????????? 24, 2005 11:48, uttam.phulwale at tcs.com wrote:
>
> Hi,
> Is there any 64-bit compatible version of 'R' available?
>

There is of course the possibility that you can build your own version of
R by obtaining the source and compiling and optimizing for your own 64-bit
processor.

IKD
-- 
Ioannis C. Dimakos
University of Patras
Department of Elementary Education
Patras, GR-26500 GREECE
http://www.elemedu.upatras.gr/dimakos/
http://yannishome.port5.com/



From Roger.Bivand at nhh.no  Mon Oct 24 11:29:16 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 24 Oct 2005 11:29:16 +0200 (CEST)
Subject: [R] Errors occured
In-Reply-To: <200510221824.j9MIO2Fj022955@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.44.0510241126510.32683-100000@reclus.nhh.no>

On Sun, 23 Oct 2005, Leaf Sun wrote:

> Hi all,
> 
> Has anybody have the experience in the errors:
> 
> Error in data.frame(..., check.names=FALSE): arguments imply differing
> number of rows: 343,15
> 
> This is the error occured in the middle of the program. I don't think
> the data frame has any problem, if there is problem with the program,
> why it happened in the middle?

Further to Uwe's advice, looking at the traceback() output may give you an 
idea of what is going wrong, and if your script is adequately written, 
using debug() on the function in which the error occurs will let you 
examine what is being passed to data.frame() before the error happens.

> 
> Does anybody have such an experience? It seems so weird to me.
> 
> Thanks a lot!
> 
> Leaf
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From hin-tak.leung at cimr.cam.ac.uk  Mon Oct 24 11:33:15 2005
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 24 Oct 2005 10:33:15 +0100
Subject: [R] tk problem with R 2.2.0 on wine/linux
Message-ID: <435CAA5B.50906@cimr.cam.ac.uk>

Actually I am trying to run sciview-R and encounted some problems with
tk, and I thought I'll check the basic library(tcltk) functionallity,
just to be sure. Anybody seen that  '[tcl] bad window path name ".1".'
message before?

Prof. Philippe Grosjean: yes, I have managed to load most of
sciview-R under Wine, except the tcltk library!

===================
R : Copyright 2005, The R Foundation for Statistical Computing
Version 2.2.0  (2005-10-06 r35749)
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

   Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

 > library(tcltk)
Loading Tcl/Tk interface ... done
 > demo(tkdensity)


         demo(tkdensity)
         ---- ~~~~~~~~~

Type  <Return>   to start :

 > require(tcltk) || stop("tcltk support is absent")
[1] TRUE

 > require(graphics)
[1] TRUE

 > require(stats)
[1] TRUE

 > local({
     y <- NULL
     xlim <- NULL
     size <- tclVar(50.000000)
     dist <- tclVar(1.000000)
     kernel <- tclVar("gaussian")
     bw <- tclVar(1.000000)
     bw.sav <- 1.000000
     replot <- function(...) {
         if (is.null(y))
             re .... [TRUNCATED]
Error in structure(.External("dotTclObjv", objv, PACKAGE = "tcltk"), 
class = "tclObj") :
         [tcl] bad window path name ".1".
 > demo(tkttest)


         demo(tkttest)
         ---- ~~~~~~~

Type  <Return>   to start :

 > require(tcltk) || stop("tcltk support is absent")
[1] TRUE

 > require(stats)
[1] TRUE

 > local({
     dialog.t.test <- function() {
         tt <- tktoplevel()
         tkwm.title(tt, "t test")
         x.entry <- tkentry(tt, textvariable = xvar)
         y.entry <- tkentry(tt, textvariable = yvar)
         alt <- tclVar("two.sided")
         d .... [TRUNCATED]
******************************************************
  The source for this demo can be found in the file:
  C:/PROG~FBU/R/R-2_~MVR.0/library/tcltk/demo/tkttest.R
******************************************************
Error in structure(.External("dotTclObjv", objv, PACKAGE = "tcltk"), 
class = "tclObj") :
         [tcl] bad window path name ".2".
 >



From phgrosjean at sciviews.org  Mon Oct 24 12:02:05 2005
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Mon, 24 Oct 2005 12:02:05 +0200
Subject: [R] tk problem with R 2.2.0 on wine/linux
In-Reply-To: <435CAA5B.50906@cimr.cam.ac.uk>
References: <435CAA5B.50906@cimr.cam.ac.uk>
Message-ID: <435CB11D.1070809@sciviews.org>

Hello,

This is interresting. I think you did the big part of the job if 
SciViews-R is starting. tcltk is used independently from the rest of 
SciViews-R, for some dialog boxes and for R Commander. I think you 
should try now to run tcltk on the plain RGui.exe under wine. I guess it 
will eliminate various possible interferences... and then, if you 
succeed, go back to RGui + SciViews-R + tcltk under Wine.

Unfortunatelly, I cannot help you much here (except if I have some code 
to change for a better behaviour of SciViews-R under Wine).

For the use of tcltk with RGui.exe under Wine, the best person to 
contact is the tcltk maintainer, that is, Peter Dalgaard.

Best,

Philippe Grosjean

P.S.: What about the performances of R / SciViews-R under Wine???

..............................................<??}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons-Hainaut University, Pentagone (3D08)
( ( ( ( (    Academie Universitaire Wallonie-Bruxelles
  ) ) ) ) )   8, av du Champ de Mars, 7000 Mons, Belgium
( ( ( ( (
  ) ) ) ) )   phone: + 32.65.37.34.97, fax: + 32.65.37.30.54
( ( ( ( (    email: Philippe.Grosjean at umh.ac.be
  ) ) ) ) )
( ( ( ( (    web:   http://www.umh.ac.be/~econum
  ) ) ) ) )          http://www.sciviews.org
( ( ( ( (
..............................................................

Hin-Tak Leung wrote:
> Actually I am trying to run sciview-R and encounted some problems with
> tk, and I thought I'll check the basic library(tcltk) functionallity,
> just to be sure. Anybody seen that  '[tcl] bad window path name ".1".'
> message before?
> 
> Prof. Philippe Grosjean: yes, I have managed to load most of
> sciview-R under Wine, except the tcltk library!
> 
> ===================
> R : Copyright 2005, The R Foundation for Statistical Computing
> Version 2.2.0  (2005-10-06 r35749)
> ISBN 3-900051-07-0
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
>   Natural language support but running in an English locale
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for a HTML browser interface to help.
> Type 'q()' to quit R.
> 
> [Previously saved workspace restored]
> 
>  > library(tcltk)
> Loading Tcl/Tk interface ... done
>  > demo(tkdensity)
> 
> 
>         demo(tkdensity)
>         ---- ~~~~~~~~~
> 
> Type  <Return>   to start :
> 
>  > require(tcltk) || stop("tcltk support is absent")
> [1] TRUE
> 
>  > require(graphics)
> [1] TRUE
> 
>  > require(stats)
> [1] TRUE
> 
>  > local({
>     y <- NULL
>     xlim <- NULL
>     size <- tclVar(50.000000)
>     dist <- tclVar(1.000000)
>     kernel <- tclVar("gaussian")
>     bw <- tclVar(1.000000)
>     bw.sav <- 1.000000
>     replot <- function(...) {
>         if (is.null(y))
>             re .... [TRUNCATED]
> Error in structure(.External("dotTclObjv", objv, PACKAGE = "tcltk"), 
> class = "tclObj") :
>         [tcl] bad window path name ".1".
>  > demo(tkttest)
> 
> 
>         demo(tkttest)
>         ---- ~~~~~~~
> 
> Type  <Return>   to start :
> 
>  > require(tcltk) || stop("tcltk support is absent")
> [1] TRUE
> 
>  > require(stats)
> [1] TRUE
> 
>  > local({
>     dialog.t.test <- function() {
>         tt <- tktoplevel()
>         tkwm.title(tt, "t test")
>         x.entry <- tkentry(tt, textvariable = xvar)
>         y.entry <- tkentry(tt, textvariable = yvar)
>         alt <- tclVar("two.sided")
>         d .... [TRUNCATED]
> ******************************************************
>  The source for this demo can be found in the file:
>  C:/PROG~FBU/R/R-2_~MVR.0/library/tcltk/demo/tkttest.R
> ******************************************************
> Error in structure(.External("dotTclObjv", objv, PACKAGE = "tcltk"), 
> class = "tclObj") :
>         [tcl] bad window path name ".2".
>  >
> ====================================
> 
>



From gaelger at aept.ruhr-uni-bochum.de  Mon Oct 24 12:10:01 2005
From: gaelger at aept.ruhr-uni-bochum.de (=?ISO-8859-1?Q?Michael_G=E4lger?=)
Date: Mon, 24 Oct 2005 12:10:01 +0200
Subject: [R] locfit: simultaneous confidence band
Message-ID: <b20cdcaa95c8feb98e71d3ac172899f1@egw.aept.rub.de>

I'm using the package 'locfit' for nonparametric regression. This package
contains the function 'scb' to compute simultaneous confidence bands. 
The variance of the data is unknown. Up to now I compute a fit with
'locfit'. Afterwards an estimate of the residual variance is computed by the
function 'rv'. The weights in the 'scb'-function are set 1/sigma^2 to
compute the confidence band.
Is this procedure correct or is there any other way to compute confidence
bands with unknown variance?

Thanks very much for any help you can offer. 

Michael G??lger



From hin-tak.leung at cimr.cam.ac.uk  Mon Oct 24 12:33:41 2005
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 24 Oct 2005 11:33:41 +0100
Subject: [R] tk problem with R 2.2.0 on wine/linux
In-Reply-To: <435CB11D.1070809@sciviews.org>
References: <435CAA5B.50906@cimr.cam.ac.uk> <435CB11D.1070809@sciviews.org>
Message-ID: <435CB885.8090908@cimr.cam.ac.uk>

Philippe Grosjean wrote:
> Hello,
> 
> This is interresting. I think you did the big part of the job if 
> SciViews-R is starting. tcltk is used independently from the rest of 
> SciViews-R, for some dialog boxes and for R Commander. I think you 
> should try now to run tcltk on the plain RGui.exe under wine. I guess it 
> will eliminate various possible interferences... and then, if you 
> succeed, go back to RGui + SciViews-R + tcltk under Wine.

This is what I am trying to do - it seems to be some interaction to
the windows manager. I tried running "library(tcltk); demo(tkdensity)"
under native R on linux - it works, but on exit from R, I get a bunch of 
warning messages like this:

Warning messages:
1: X11 protocol error: BadWindow (invalid Window parameter)
2: X11 protocol error: BadWindow (invalid Window parameter)
3: X11 protocol error: BadWindow (invalid Window parameter)
4: X11 protocol error: BadWindow (invalid Window parameter)
5: X11 protocol error: BadWindow (invalid Window parameter)
6: X11 protocol error: BadWindow (invalid Window parameter)
7: X11 protocol error: BadWindow (invalid Window parameter)
8: X11 protocol error: BadWindow (invalid Window parameter)
9: X11 protocol error: BadWindow (invalid Window parameter)
10: X11 protocol error: BadWindow (invalid Window parameter)

So it seems the tcltk is doing something not quite correct, and
the problem is serious enough under wine to stop the whole thing.

> Unfortunatelly, I cannot help you much here (except if I have some code 
> to change for a better behaviour of SciViews-R under Wine).
> 
> For the use of tcltk with RGui.exe under Wine, the best person to 
> contact is the tcltk maintainer, that is, Peter Dalgaard.
> 
> Best,
> 
> Philippe Grosjean
> 
> P.S.: What about the performances of R / SciViews-R under Wine???

It is quite useable - I think screen refreshes and updates are 
significantly slower, so don't expect to do animations, but the Rgui
and Rconsole are not noticeably slower than native.

> 
> ..............................................<??}))><........
>  ) ) ) ) )
> ( ( ( ( (    Prof. Philippe Grosjean
>  ) ) ) ) )
> ( ( ( ( (    Numerical Ecology of Aquatic Systems
>  ) ) ) ) )   Mons-Hainaut University, Pentagone (3D08)
> ( ( ( ( (    Academie Universitaire Wallonie-Bruxelles
>  ) ) ) ) )   8, av du Champ de Mars, 7000 Mons, Belgium
> ( ( ( ( (
>  ) ) ) ) )   phone: + 32.65.37.34.97, fax: + 32.65.37.30.54
> ( ( ( ( (    email: Philippe.Grosjean at umh.ac.be
>  ) ) ) ) )
> ( ( ( ( (    web:   http://www.umh.ac.be/~econum
>  ) ) ) ) )          http://www.sciviews.org
> ( ( ( ( (
> ..............................................................
> 
> Hin-Tak Leung wrote:
> 
>> Actually I am trying to run sciview-R and encounted some problems with
>> tk, and I thought I'll check the basic library(tcltk) functionallity,
>> just to be sure. Anybody seen that  '[tcl] bad window path name ".1".'
>> message before?
>>
>> Prof. Philippe Grosjean: yes, I have managed to load most of
>> sciview-R under Wine, except the tcltk library!
>>
>> ===================
>> R : Copyright 2005, The R Foundation for Statistical Computing
>> Version 2.2.0  (2005-10-06 r35749)
>> ISBN 3-900051-07-0
>>
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>>
>>   Natural language support but running in an English locale
>>
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more information and
>> 'citation()' on how to cite R or R packages in publications.
>>
>> Type 'demo()' for some demos, 'help()' for on-line help, or
>> 'help.start()' for a HTML browser interface to help.
>> Type 'q()' to quit R.
>>
>> [Previously saved workspace restored]
>>
>>  > library(tcltk)
>> Loading Tcl/Tk interface ... done
>>  > demo(tkdensity)
>>
>>
>>         demo(tkdensity)
>>         ---- ~~~~~~~~~
>>
>> Type  <Return>   to start :
>>
>>  > require(tcltk) || stop("tcltk support is absent")
>> [1] TRUE
>>
>>  > require(graphics)
>> [1] TRUE
>>
>>  > require(stats)
>> [1] TRUE
>>
>>  > local({
>>     y <- NULL
>>     xlim <- NULL
>>     size <- tclVar(50.000000)
>>     dist <- tclVar(1.000000)
>>     kernel <- tclVar("gaussian")
>>     bw <- tclVar(1.000000)
>>     bw.sav <- 1.000000
>>     replot <- function(...) {
>>         if (is.null(y))
>>             re .... [TRUNCATED]
>> Error in structure(.External("dotTclObjv", objv, PACKAGE = "tcltk"), 
>> class = "tclObj") :
>>         [tcl] bad window path name ".1".
>>  > demo(tkttest)
>>
>>
>>         demo(tkttest)
>>         ---- ~~~~~~~
>>
>> Type  <Return>   to start :
>>
>>  > require(tcltk) || stop("tcltk support is absent")
>> [1] TRUE
>>
>>  > require(stats)
>> [1] TRUE
>>
>>  > local({
>>     dialog.t.test <- function() {
>>         tt <- tktoplevel()
>>         tkwm.title(tt, "t test")
>>         x.entry <- tkentry(tt, textvariable = xvar)
>>         y.entry <- tkentry(tt, textvariable = yvar)
>>         alt <- tclVar("two.sided")
>>         d .... [TRUNCATED]
>> ******************************************************
>>  The source for this demo can be found in the file:
>>  C:/PROG~FBU/R/R-2_~MVR.0/library/tcltk/demo/tkttest.R
>> ******************************************************
>> Error in structure(.External("dotTclObjv", objv, PACKAGE = "tcltk"), 
>> class = "tclObj") :
>>         [tcl] bad window path name ".2".
>>  >
>> ====================================
>>
>>
>



From Ted.Harding at nessie.mcc.ac.uk  Mon Oct 24 11:58:48 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 24 Oct 2005 10:58:48 +0100 (BST)
Subject: [R] Male and female symbols?
In-Reply-To: <435CA3AD.5030402@lancaster.ac.uk>
Message-ID: <XFMail.051024105848.Ted.Harding@nessie.mcc.ac.uk>

On 24-Oct-05 Barry Rowlingson wrote:
> (Ted Harding) wrote:
> 
>> For example -- though I'm not seriously saying I need this --
>> in a population study of faxes and rabbits surveyed over several
>> years, one might wish to plot the Rabbit population using tiny
>> rabbits as points, and foxes' heads for the Fox population.
> 
>   I cant help thinking now of the graphic shown on the 'Brass Eye' 
> comedy show on Animal Cruelty. Cue totally over-the-top 3d zooming 
> barchart with mad lighting effects, and voice-over:
> 
> 'If you plot "number of animals abused" against "what makes people 
> cruel" versus "intelligence of either party", the pattern is so 
> unreadable you might as well draw in a chain of fox heads on sticks.
> And if you do that, an interesting thing happens: the word "cruel" 
> starts flashing.'
> 
>   But seriously: you could load in an image with the pixmap package and
> plot with that:
> 
> library(pixmap)
> x <- read.pnm(system.file("pictures/logo.ppm", package="pixmap")[1])
> plot(1:10,type='n')
> for(i in 1:10){addlogo(x,px=c(i-.2,i+.2),py=c(i-.2,i+.2))}
> 
>  From there to a chain of fox heads on sticks is a small step.
> 
> Baz

Baz, We know what your day job is. But what's the other one,
I begin to wonder?

Cheers,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 24-Oct-05                                       Time: 10:52:33
------------------------------ XFMail ------------------------------



From ripley at stats.ox.ac.uk  Mon Oct 24 12:57:59 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 24 Oct 2005 11:57:59 +0100 (BST)
Subject: [R] Is 64-bit linux compatible version of 'R' available?
In-Reply-To: <OF2F4F6ECC.4C996C5A-ON652570A4.002F86BC-652570A4.002FE4AE@tcs.com>
References: <OF2F4F6ECC.4C996C5A-ON652570A4.002F86BC-652570A4.002FE4AE@tcs.com>
Message-ID: <Pine.LNX.4.61.0510241157190.10028@gannet.stats>

On Mon, 24 Oct 2005 uttam.phulwale at tcs.com wrote:

>
> Hi,
> Is there any 64-bit compatible version of 'R' available?

Yes.  See the R-admin manual for how to make one.  There are even 64-bit 
RPMs available.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From chrisgir69 at hotmail.fr  Mon Oct 24 13:44:58 2005
From: chrisgir69 at hotmail.fr (Christophe Girod)
Date: Mon, 24 Oct 2005 13:44:58 +0200
Subject: [R] Pb  with function taxo2phylog (package ade4)
Message-ID: <BAY110-F6A98514250C00EB902E45AA770@phx.gbl>

Hello

  I'm using the package ade4 to obtain classification from a .txt file. I 
use the following commands:
cronquist <- read.table("cronquist.txt", h = T, row.names = 8)
cronquist <- as.taxo(cronquist[7:1])
cro.phy <- taxo2phylog(cronquist)

in which cronquist.txt is a file with a classification of 218 genus of tree 
species from french Guiana.
We I try to use the function taxo2phylog, I obtain the following error 
message (in French) :
Erreur dans newick2phylog.addtools(res) : la longueur de 'dimnames' [2] 
n'est pas ??gale ?? l'??tendue du tableau
Error in newick2phylog.addtools(res) : length of dimnames[2] is not equal to 
length of frame

newick2phylog.addtools is a function that is called when taxo2phylog is 
called

when I want to know what is in dimnames[2] I obtain the names of my columns 
: none is missing.

I don't understand what's happening because I've already been using this 
function with other files and I  had no problem
Can someone help me?

Thanks

Christophe Girod

_________________________________________________________________
Apprenez ?? lutter contre le spam !



From dray at biomserv.univ-lyon1.fr  Mon Oct 24 14:04:00 2005
From: dray at biomserv.univ-lyon1.fr (=?ISO-8859-1?Q?St=E9phane_Dray?=)
Date: Mon, 24 Oct 2005 14:04:00 +0200
Subject: [R] Pb  with function taxo2phylog (package ade4)
In-Reply-To: <BAY110-F6A98514250C00EB902E45AA770@phx.gbl>
References: <BAY110-F6A98514250C00EB902E45AA770@phx.gbl>
Message-ID: <435CCDB0.60209@biomserv.univ-lyon1.fr>

Christophe,
please send emails related to this package to the ade4 list :

http://pbil.univ-lyon1.fr/ADE-4/adelist.html

Merci.

Christophe Girod wrote:

>Hello
>
>  I'm using the package ade4 to obtain classification from a .txt file. I 
>use the following commands:
>cronquist <- read.table("cronquist.txt", h = T, row.names = 8)
>cronquist <- as.taxo(cronquist[7:1])
>cro.phy <- taxo2phylog(cronquist)
>
>in which cronquist.txt is a file with a classification of 218 genus of tree 
>species from french Guiana.
>We I try to use the function taxo2phylog, I obtain the following error 
>message (in French) :
>Erreur dans newick2phylog.addtools(res) : la longueur de 'dimnames' [2] 
>n'est pas ??gale ?? l'??tendue du tableau
>Error in newick2phylog.addtools(res) : length of dimnames[2] is not equal to 
>length of frame
>
>newick2phylog.addtools is a function that is called when taxo2phylog is 
>called
>
>when I want to know what is in dimnames[2] I obtain the names of my columns 
>: none is missing.
>
>I don't understand what's happening because I've already been using this 
>function with other files and I  had no problem
>Can someone help me?
>
>Thanks
>
>Christophe Girod
>
>_________________________________________________________________
>Apprenez ?? lutter contre le spam !
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>


-- 
St??phane DRAY (dray at biomserv.univ-lyon1.fr )
Laboratoire BBE-CNRS-UMR-5558, Univ. C. Bernard - Lyon I
43, Bd du 11 Novembre 1918, 69622 Villeurbanne Cedex, France
Tel: 33 4 72 43 27 57       Fax: 33 4 72 43 13 88
http://www.steph280.freesurf.fr/



From ManuelPerera-Chang at fmc-ag.com  Mon Oct 24 14:38:23 2005
From: ManuelPerera-Chang at fmc-ag.com (ManuelPerera-Chang@fmc-ag.com)
Date: Mon, 24 Oct 2005 14:38:23 +0200
Subject: [R]   query on xtable(Sweave)
Message-ID: <OF2CBD7AC4.EEB447F3-ONC12570A4.003B916F-C12570A4.00456EF0@notes.fresenius.de>





Dear all,

I am exporting to latex a dataframe via xtable(Sweave). My dataframe
includes 4 rows and 4 columns. The first two rows containing real
values(e.g. a laboratory parameter's mean value), and the two rows at the
bottom containing only integers (number of cases).

using display=c('fg','fg','fg','fg') as an argument to xtable I tried to
reach my goal, of presenting the table with numbers formatted with decimal
paces in the upper rows, but with the numbers in the lower rows as integers
(without superfluous commas and decimal places), as shown in the example
below,
Example I:
A     B     C     D
0,52  2,52  0,35  3,63
3,52  6,25  3,62  6,36
11    12    15    16
14    15    16    18

or another example(II):

A     B     C     D
11,5  12,5  10,4  13,6
3,52  6,25  12,62 16,3
11    12    15    16
14    15    16    18


The command used was ...

trend_table<-xtable(trend.table,caption="Caption",display=c('fg','fg','fg','fg'),size='small')
trend_table

The R help on xtable states that "fg" displays 'digits' as number of
_significant_ digits. As a result no decimal places are shown in the last
two rows, as expected, but no decimal places are shown neither in the first
two rows, if the real value in the cell is greater than 10, and only 1
decimal place if the value in the cell is lower than 10.
Thus instead of example II, I got in Latex the following data:

A     B     C     D
12    13    10    14
3,5   6,3   13    16
11    12    15    16
14    15    16    18

 I would prefer to show 1 additional decimal  in both cases.Thus my
question is how to modify the setting for _significant_ digits(in xtable or
in Sweave??) in order to print values.

thanks for your help,

Manuel





Manuel



From sureshkaran at hotmail.com  Mon Oct 24 15:01:54 2005
From: sureshkaran at hotmail.com (Suresh Kumar Karanam)
Date: Mon, 24 Oct 2005 09:01:54 -0400
Subject: [R] Spearman's Rho Help!
Message-ID: <BAY103-F2195E0F6A82F0C778A4649B2770@phx.gbl>

Hi,
I have a dataset with four categories of data, the number of samples are not 
the same in each category. I want to find the Spearaman's Rho. Let me give 
an example.
x=(14.22770439,26.49420624,46.7277932,19.02550707,23.37379361,16.97789862,19.77100085,23.11270162,13.72929843,33.54430621,14.4756979,70.15811106,11.22789833,NA,NA,NA)
y=(143.2420241,45.24260203,62.13218994,27.79050219,27.41029595,191.2759927,141.1430225,234.1600259,37.69120463,156.332942,19.98579421,34.77930022,69.90888888,21.92539608,NA,NA)
z=(70.28027834,349.7838817,29.81811184,83.48042267,52.47989761,107.7110162,71.24609317,155.6580091,68.37158664,156.3179887,134.8930305,80.25242044,100.5309559,266.4470408,65.4934171,22.86950128)
v=(150.2099947,73.52000706,83.18122348,150.3240468,352.9101222,195.8919089,263.9489287,114.2090369,153.5000165,18.62309563,117.2399949,441.8981252,285.3369951,161.3959985,NA,NA)

I want to find the spearman's rho for this data. To my knowledge spearman's 
rho is for x vs. y or x vs. z or any combination. Is there a spearman's rho 
for the data all together (x y z v)? Please help!
Thanks a bunch.
suresh



From sw283 at maths.bath.ac.uk  Mon Oct 24 15:37:30 2005
From: sw283 at maths.bath.ac.uk (Simon Wood)
Date: Mon, 24 Oct 2005 14:37:30 +0100 (BST)
Subject: [R] testing non-linear component in mgcv:gam
In-Reply-To: <CC98AE00-3F2B-4DFA-8D5C-8D9E28D8C9E0@globetrotter.net>
References: <mailman.10.1128506401.6195.r-help@stat.math.ethz.ch>
	<CC98AE00-3F2B-4DFA-8D5C-8D9E28D8C9E0@globetrotter.net>
Message-ID: <Pine.LNX.4.56.0510241432330.21169@mars>

In this case the models being compared are really identical, and the
P-value is meaningless numerical noise.

If your main focus is hypothesis testing and you really need near exact
p-values, then do this sort of testing using unpenalized models. i.e.
don't have mgcv::gam estimate the EDF of the smooth, just use
`s(...,fx=TRUE)' to estimate it unpenalized. This gives horrible point
estimates and excellent p-values.

best,
Simon

> Hi,
>
> I need further help with my GAMs. Most models I test are very
> obviously non-linear. Yet, to be on the safe side, I report the
> significance of the smooth (default output of mgcv's summary.gam) and
> confirm it deviates significantly from linearity.
>
> I do the latter by fitting a second model where the same predictor is
> entered without the s(), and then use anova.gam to compare the two. I
> thought this was the equivalent of the default output of anova.gam
> using package gam instead of mgcv.
>
> I wonder if this procedure is correct because one of my models
> appears to be linear. In fact mgcv estimates df to be exactly 1.0 so
> I could have stopped there. However I inadvertently repeated the
> procedure outlined above. I would have thought in this case the
> anova.gam comparing the smooth and the linear fit would for sure have
> been not significant. To my surprise, P was 6.18e-09!
>
> Am I doing something wrong when I attempt to confirm the non-
> parametric part a smoother is significant? Here is my example case
> where the relationship does appear to be linear:
>
> library(mgcv)
> > This is mgcv 1.3-7
> Temp <- c(-1.38, -1.12, -0.88, -0.62, -0.38, -0.12, 0.12, 0.38, 0.62,
> 0.88, 1.12,
>             1.38, 1.62, 1.88, 2.12, 2.38, 2.62, 2.88, 3.12, 3.38,
> 3.62, 3.88,
>             4.12, 4.38, 4.62, 4.88, 5.12, 5.38, 5.62, 5.88, 6.12,
> 6.38, 6.62, 6.88,
>             7.12, 8.38, 13.62)
> N.sets <- c(2, 6, 3, 9, 26, 15, 34, 21, 30, 18, 28, 27, 27, 29, 31,
> 22, 26, 24, 23,
>              15, 25, 24, 27, 19, 26, 24, 22, 13, 10, 2, 5, 3, 1, 1,
> 1, 1, 1)
> wm.sed <- c(0.000000000, 0.016129032, 0.000000000, 0.062046512,
> 0.396459596, 0.189082949,
>              0.054757925, 0.142810440, 0.168005168, 0.180804428,
> 0.111439628, 0.128799505,
>              0.193707937, 0.105921610, 0.103497845, 0.028591837,
> 0.217894389, 0.020535469,
>              0.080389068, 0.105234450, 0.070213450, 0.050771363,
> 0.042074434, 0.102348837,
>              0.049748344, 0.019100478, 0.005203125, 0.101711864,
> 0.000000000, 0.000000000,
>              0.014808824, 0.000000000, 0.222000000, 0.167000000,
> 0.000000000, 0.000000000,
>              0.000000000)
>
> sed.gam <- gam(wm.sed~s(Temp),weight=N.sets)
> summary.gam(sed.gam)
> > Family: gaussian
> > Link function: identity
> >
> > Formula:
> > wm.sed ~ s(Temp)
> >
> > Parametric coefficients:
> >             Estimate Std. Error t value Pr(>|t|)
> > (Intercept)  0.08403    0.01347   6.241 3.73e-07 ***
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > Approximate significance of smooth terms:
> >         edf Est.rank     F  p-value
> > s(Temp)   1        1 13.95 0.000666 ***
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > R-sq.(adj) =  0.554   Deviance explained = 28.5%
> > GCV score = 0.09904   Scale est. = 0.093686  n = 37
>
> # testing non-linear contribution
> sed.lin <- gam(wm.sed~Temp,weight=N.sets)
> summary.gam(sed.lin)
> > Family: gaussian
> > Link function: identity
> >
> > Formula:
> > wm.sed ~ Temp
> >
> > Parametric coefficients:
> >              Estimate Std. Error t value Pr(>|t|)
> > (Intercept)  0.162879   0.019847   8.207 1.14e-09 ***
> > Temp        -0.023792   0.006369  -3.736 0.000666 ***
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> >
> > R-sq.(adj) =  0.554   Deviance explained = 28.5%
> > GCV score = 0.09904   Scale est. = 0.093686  n = 37
> anova.gam(sed.lin, sed.gam, test="F")
> > Analysis of Deviance Table
> >
> > Model 1: wm.sed ~ Temp
> > Model 2: wm.sed ~ s(Temp)
> >    Resid. Df Resid. Dev         Df  Deviance      F   Pr(>F)
> > 1 3.5000e+01      3.279
> > 2 3.5000e+01      3.279 5.5554e-10 2.353e-11 0.4521 6.18e-09 ***
>
>
> Thanks in advance,
>
>
> Denis Chabot
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From sw283 at maths.bath.ac.uk  Mon Oct 24 15:41:19 2005
From: sw283 at maths.bath.ac.uk (Simon Wood)
Date: Mon, 24 Oct 2005 14:41:19 +0100 (BST)
Subject: [R] testing non-linear component in mgcv:gam
In-Reply-To: <01DD3C25-9071-421B-9240-EE015021D69C@globetrotter.net>
References: <20051005134502.NDQD26550.tomts20-srv.bellnexxia.net@JohnDesktop8300>
	<01DD3C25-9071-421B-9240-EE015021D69C@globetrotter.net>
Message-ID: <Pine.LNX.4.56.0510241440120.21169@mars>

Looks like a bug in mgcv::summary.gam when the model is strictly
parametric... I'll take a look and fix it. thanks, Simon

>
> In my original message I mentioned a gam fit that turns out to be a
> linear fit. By curiosity I analysed it with a linear predictor only
> with mgcv package, and then as a linear model. The output was
> identical in both, but the r-sq (adj) was 0.55 in mgcv and 0.26 in
> lm. In lm I hope that my interpretation that 26% of the variance in y
> is explained by the linear relationship with x is valid. Then what
> does r2 mean in mgcv?
>
> Denis
>  > summary.gam(lin)
>
> Family: gaussian
> Link function: identity
>
> Formula:
> wm.sed ~ Temp
>
> Parametric coefficients:
>               Estimate Std. Error t value Pr(>|t|)
> (Intercept)  0.162879   0.019847   8.207 1.14e-09 ***
> Temp        -0.023792   0.006369  -3.736 0.000666 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
> R-sq.(adj) =  0.554   Deviance explained = 28.5%
> GCV score = 0.09904   Scale est. = 0.093686  n = 37
>
>
>  > summary(sed.true.lin)
>
> Call:
> lm(formula = wm.sed ~ Temp, weights = N.sets)
>
> Residuals:
>      Min      1Q  Median      3Q     Max
> -0.6138 -0.1312 -0.0325  0.1089  1.1449
>
> Coefficients:
>               Estimate Std. Error t value Pr(>|t|)
> (Intercept)  0.162879   0.019847   8.207 1.14e-09 ***
> Temp        -0.023792   0.006369  -3.736 0.000666 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Residual standard error: 0.3061 on 35 degrees of freedom
> Multiple R-Squared: 0.285,    Adjusted R-squared: 0.2646
> F-statistic: 13.95 on 1 and 35 DF,  p-value: 0.000666
>
>
> Le 05-10-05 ?? 09:45, John Fox a ??crit :
>
> > Dear Denis,
> >
> > Take a closer look at the anova table: The models provide identical
> > fits to
> > the data. The differences in degrees of freedom and deviance
> > between the two
> > models are essentially zero, 5.5554e-10 and 2.353e-11 respectively.
> >
> > I hope this helps,
> >  John
> >
> > --------------------------------
> > John Fox
> > Department of Sociology
> > McMaster University
> > Hamilton, Ontario
> > Canada L8S 4M4
> > 905-525-9140x23604
> > http://socserv.mcmaster.ca/jfox
> > --------------------------------
> >
> >
> >> -----Original Message-----
> >> From: r-help-bounces at stat.math.ethz.ch
> >> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Denis Chabot
> >> Sent: Wednesday, October 05, 2005 8:22 AM
> >> To: r-help at stat.math.ethz.ch
> >> Subject: [R] testing non-linear component in mgcv:gam
> >>
> >> Hi,
> >>
> >> I need further help with my GAMs. Most models I test are very
> >> obviously non-linear. Yet, to be on the safe side, I report
> >> the significance of the smooth (default output of mgcv's
> >> summary.gam) and confirm it deviates significantly from linearity.
> >>
> >> I do the latter by fitting a second model where the same
> >> predictor is entered without the s(), and then use anova.gam
> >> to compare the two. I thought this was the equivalent of the
> >> default output of anova.gam using package gam instead of mgcv.
> >>
> >> I wonder if this procedure is correct because one of my
> >> models appears to be linear. In fact mgcv estimates df to be
> >> exactly 1.0 so I could have stopped there. However I
> >> inadvertently repeated the procedure outlined above. I would
> >> have thought in this case the anova.gam comparing the smooth
> >> and the linear fit would for sure have been not significant.
> >> To my surprise, P was 6.18e-09!
> >>
> >> Am I doing something wrong when I attempt to confirm the non-
> >> parametric part a smoother is significant? Here is my example
> >> case where the relationship does appear to be linear:
> >>
> >> library(mgcv)
> >>
> >>> This is mgcv 1.3-7
> >>>
> >> Temp <- c(-1.38, -1.12, -0.88, -0.62, -0.38, -0.12, 0.12,
> >> 0.38, 0.62, 0.88, 1.12,
> >>             1.38, 1.62, 1.88, 2.12, 2.38, 2.62, 2.88, 3.12,
> >> 3.38, 3.62, 3.88,
> >>             4.12, 4.38, 4.62, 4.88, 5.12, 5.38, 5.62, 5.88,
> >> 6.12, 6.38, 6.62, 6.88,
> >>             7.12, 8.38, 13.62)
> >> N.sets <- c(2, 6, 3, 9, 26, 15, 34, 21, 30, 18, 28, 27, 27,
> >> 29, 31, 22, 26, 24, 23,
> >>              15, 25, 24, 27, 19, 26, 24, 22, 13, 10, 2, 5, 3,
> >> 1, 1, 1, 1, 1) wm.sed <- c(0.000000000, 0.016129032,
> >> 0.000000000, 0.062046512, 0.396459596, 0.189082949,
> >>              0.054757925, 0.142810440, 0.168005168,
> >> 0.180804428, 0.111439628, 0.128799505,
> >>              0.193707937, 0.105921610, 0.103497845,
> >> 0.028591837, 0.217894389, 0.020535469,
> >>              0.080389068, 0.105234450, 0.070213450,
> >> 0.050771363, 0.042074434, 0.102348837,
> >>              0.049748344, 0.019100478, 0.005203125,
> >> 0.101711864, 0.000000000, 0.000000000,
> >>              0.014808824, 0.000000000, 0.222000000,
> >> 0.167000000, 0.000000000, 0.000000000,
> >>              0.000000000)
> >>
> >> sed.gam <- gam(wm.sed~s(Temp),weight=N.sets)
> >> summary.gam(sed.gam)
> >>
> >>> Family: gaussian
> >>> Link function: identity
> >>>
> >>> Formula:
> >>> wm.sed ~ s(Temp)
> >>>
> >>> Parametric coefficients:
> >>>             Estimate Std. Error t value Pr(>|t|)
> >>> (Intercept)  0.08403    0.01347   6.241 3.73e-07 ***
> >>> ---
> >>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >>>
> >>> Approximate significance of smooth terms:
> >>>         edf Est.rank     F  p-value
> >>> s(Temp)   1        1 13.95 0.000666 ***
> >>> ---
> >>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >>>
> >>> R-sq.(adj) =  0.554   Deviance explained = 28.5%
> >>> GCV score = 0.09904   Scale est. = 0.093686  n = 37
> >>>
> >>
> >> # testing non-linear contribution
> >> sed.lin <- gam(wm.sed~Temp,weight=N.sets)
> >> summary.gam(sed.lin)
> >>
> >>> Family: gaussian
> >>> Link function: identity
> >>>
> >>> Formula:
> >>> wm.sed ~ Temp
> >>>
> >>> Parametric coefficients:
> >>>              Estimate Std. Error t value Pr(>|t|)
> >>> (Intercept)  0.162879   0.019847   8.207 1.14e-09 ***
> >>> Temp        -0.023792   0.006369  -3.736 0.000666 ***
> >>> ---
> >>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >>>
> >>>
> >>> R-sq.(adj) =  0.554   Deviance explained = 28.5%
> >>> GCV score = 0.09904   Scale est. = 0.093686  n = 37
> >>>
> >> anova.gam(sed.lin, sed.gam, test="F")
> >>
> >>> Analysis of Deviance Table
> >>>
> >>> Model 1: wm.sed ~ Temp
> >>> Model 2: wm.sed ~ s(Temp)
> >>>    Resid. Df Resid. Dev         Df  Deviance      F   Pr(>F)
> >>> 1 3.5000e+01      3.279
> >>> 2 3.5000e+01      3.279 5.5554e-10 2.353e-11 0.4521 6.18e-09 ***
> >>>
> >>
> >>
> >> Thanks in advance,
> >>
> >>
> >> Denis Chabot
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide!
> >> http://www.R-project.org/posting-guide.html
> >>
> >
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From f.harrell at vanderbilt.edu  Mon Oct 24 15:49:36 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Mon, 24 Oct 2005 08:49:36 -0500
Subject: [R] Spearman's Rho Help!
In-Reply-To: <BAY103-F2195E0F6A82F0C778A4649B2770@phx.gbl>
References: <BAY103-F2195E0F6A82F0C778A4649B2770@phx.gbl>
Message-ID: <435CE670.6030908@vanderbilt.edu>

Suresh Kumar Karanam wrote:
> Hi,
> I have a dataset with four categories of data, the number of samples are not 
> the same in each category. I want to find the Spearaman's Rho. Let me give 
> an example.
> x=(14.22770439,26.49420624,46.7277932,19.02550707,23.37379361,16.97789862,19.77100085,23.11270162,13.72929843,33.54430621,14.4756979,70.15811106,11.22789833,NA,NA,NA)
> y=(143.2420241,45.24260203,62.13218994,27.79050219,27.41029595,191.2759927,141.1430225,234.1600259,37.69120463,156.332942,19.98579421,34.77930022,69.90888888,21.92539608,NA,NA)
> z=(70.28027834,349.7838817,29.81811184,83.48042267,52.47989761,107.7110162,71.24609317,155.6580091,68.37158664,156.3179887,134.8930305,80.25242044,100.5309559,266.4470408,65.4934171,22.86950128)
> v=(150.2099947,73.52000706,83.18122348,150.3240468,352.9101222,195.8919089,263.9489287,114.2090369,153.5000165,18.62309563,117.2399949,441.8981252,285.3369951,161.3959985,NA,NA)
> 
> I want to find the spearman's rho for this data. To my knowledge spearman's 
> rho is for x vs. y or x vs. z or any combination. Is there a spearman's rho 
> for the data all together (x y z v)? Please help!
> Thanks a bunch.
> suresh
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

In the Hmisc package see rcorr

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From Christoph.Scherber at uni-jena.de  Mon Oct 24 16:55:39 2005
From: Christoph.Scherber at uni-jena.de (Christoph Scherber)
Date: Mon, 24 Oct 2005 16:55:39 +0200
Subject: [R] aggregating using several functions
Message-ID: <435CF5EB.5010208@uni-jena.de>

Dear R users,

I would like to aggregate a data frame using several functions at once 
(e.g., mean plus standard error).

How can I make this work using aggregate()?  The help file says scalar 
functions are needed; can anyone help?

Below is the code for my "meanse" function which I??d like to use like this:

aggregate(dataframe, list(factorA,factoB),meanse)

Thanks for your help!
Christoph





meanse<-function(x,...,na.rm=T){
if(na.rm)
x<-x[!is.na(x)]
m<-mean(x)
s<-sd(x)
l<-length(x)
serr<-s/sqrt(l)
return(data.frame(list("Mean"=m,"Std.Error"=serr)))
}



From gunter.berton at gene.com  Mon Oct 24 17:04:50 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Mon, 24 Oct 2005 08:04:50 -0700
Subject: [R] R Reference Card (especially useful for Newbies)
Message-ID: <200510241504.j9OF4odb011808@ohm.gene.com>

 

Newbies (and others!) may find useful the R Reference Card made available by
Tom Short and Rpad at http://www.rpad.org/Rpad/Rpad-refcard.pdf  or through
the "Contributed" link on CRAN (where some other reference cards are also
linked). It categorizes and organizes a bunch of R's basic, most used
functions so that they can be easily found. For example, paste() is under
the "Strings" heading and expand.grid() is under "Data Creation." For
newbies struggling to find the right R function as well as veterans who
can't quite remember the function name, it's very handy.
 
-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box



From jeaneid at chass.utoronto.ca  Mon Oct 24 17:04:07 2005
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Mon, 24 Oct 2005 11:04:07 -0400
Subject: [R] reading data from a pdf
In-Reply-To: <87k6g56dwk.fsf@kafka.homenet>
References: <87k6g56dwk.fsf@kafka.homenet>
Message-ID: <435CF7E7.3030001@chass.utoronto.ca>


Hi,

In my experience pdftotext did not do a very good job at this because it 
screws up the formatting of tables. This of course depends on what 
program the pdf document was originally constructed with. What I found 
most appealing is the use of cut and paste into xemacs or emacs and use 
M-x  canonically-space-region function. This  will eliminate any extra 
spaces. However if the pdf document was prepared through scanning and 
one uses a  character recognition program, then all is up in the air and 
the formatting of tables have to be done by hand.

Jean
rambam at bigpond.net.au wrote:

>>Hi, I'm trying to read data from a PDF file.Is it possible to do it
>>with R? Thanks,  Marco
>>    
>>
>
>If cut and paste to a text file fails, try this:
>
>pdftotext (from the xpdf project)
>
>or
>
>http://pdftohtml.sourceforge.net
>pdftohtml is a utility which converts PDF files into HTML and
>XML formats
>
>In addition, pdftk, the command line pdf toolkit may be useful
>http://www.accesspdf.com/pdftk/
>
>  
>



From poizot at cnam.fr  Mon Oct 24 17:07:09 2005
From: poizot at cnam.fr (Poizot Emmanuel)
Date: Mon, 24 Oct 2005 17:07:09 +0200
Subject: [R] Compilation package error
Message-ID: <435CF89D.70203@cnam.fr>

Dear all,
I tried to install gstat package and add the following compilation error :

------------------------>
* Installing *source* package 'gstat' ...
creating cache ./config.cache
checking for gcc... gcc
checking whether the C compiler (gcc  ) works... yes
checking whether the C compiler (gcc  ) is a cross-compiler... no
checking whether we are using GNU C... yes
checking whether gcc accepts -g... yes
checking how to run the C preprocessor... gcc -E
checking for AIX... no
checking for minix/config.h... no
checking for POSIXized ISC... no
checking for ANSI C header files... yes
checking for working const... yes
checking whether time.h and sys/time.h may both be included... yes
checking for 8-bit clean memcmp... yes
checking for vprintf... yes
checking for strstr... yes
checking for strtod... yes
checking for strtol... yes
checking for drand48... yes
checking for gettimeofday... yes
checking whether byte ordering is bigendian... no
checking for memory.h... yes
checking for ANSI C header files... (cached) yes
checking for gcc option to accept ANSI C...
checking for function prototypes... yes
checking for working const... (cached) yes
checking for complex.h... yes
checking for malloc.h... yes
checking for varargs.h... no
checking for size_t... yes
checking for working const... (cached) yes
checking whether byte ordering is bigendian... (cached) no
checking for u_int
computing machine epsilon(s)
gcc -o macheps ./src/meschach/dmacheps.c
gcc -o macheps ./src/meschach/fmacheps.c
computing M_MAX_INT
gcc -o maxint maxint.c
./src/meschach/maxint.c: In function 'main':
./src/meschach/maxint.c:37: warning: incompatible implicit declaration 
of built-in function 'printf'
checking char \\0 vs. float zeros
checking for bcopy... yes
checking for bzero... yes
checking for function prototypes
checking for function prototypes in structures
updating cache ./config.cache
creating ./config.status
creating makefile
creating src/config.h
creating src/machine.h
** libs
gcc -I/usr/lib/R/include   -mieee-with-inexact  -fPIC  -g -O2 -c block.c 
-o block.o
gcc -I/usr/lib/R/include   -mieee-with-inexact  -fPIC  -g -O2 -c 
chfactor.c -o chfactor.o
gcc -I/usr/lib/R/include   -mieee-with-inexact  -fPIC  -g -O2 -c copy.c 
-o copy.o
gcc -I/usr/lib/R/include   -mieee-with-inexact  -fPIC  -g -O2 -c data.c 
-o data.o
/tmp/ccXDZili.s: Messages de l'assembleur:
/tmp/ccXDZili.s:8032: ERREUR: Op??rande de relocalisation inconnue: 
!lituse_jsrdirect
make: *** [data.o] Erreur 1
ERROR: compilation failed for package 'gstat'
** Removing '/usr/local/lib/R/site-library/gstat'
** Restoring previous '/usr/local/lib/R/site-library/gstat'
------------------->

R run on a dec alpha station under Debian Sarge 64 bits (alpha version 
of course).
Compiler version is gcc 4.0.2.

Regards


------------------------------------------------
Emmanuel Poizot
Cnam/Intechmer
B.P. 324
50103 Cherbourg Cedex

Phone (Direct) : (00 33)(0)233887342
Fax : (00 33)(0)233887339
------------------------------------------------


From Karen.Green at sanofi-aventis.com  Mon Oct 24 17:37:53 2005
From: Karen.Green at sanofi-aventis.com (Karen.Green@sanofi-aventis.com)
Date: Mon, 24 Oct 2005 11:37:53 -0400
Subject: [R] finite mixture model (2-component gaussian): plotting
	component gaussian components?
Message-ID: <3CB6B0EE6816B142859B24E77724A8B801025499@sccsmxsusr05.pharma.aventis.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051024/a9493db8/attachment.pl

From f_bresson at yahoo.fr  Mon Oct 24 17:38:58 2005
From: f_bresson at yahoo.fr (Florent Bresson)
Date: Mon, 24 Oct 2005 17:38:58 +0200 (CEST)
Subject: [R] Implicit nonlinear equation
Message-ID: <20051024153859.19750.qmail@web26807.mail.ukl.yahoo.com>

I can't find a commande to solve an implicit nonlinear
equation. Does it exist please ?



From nayeemquayum at gmail.com  Mon Oct 24 17:42:57 2005
From: nayeemquayum at gmail.com (Nayeem Quayum)
Date: Mon, 24 Oct 2005 09:42:57 -0600
Subject: [R] SOM object manupulation
Message-ID: <af6d2ccc0510240842y714b8414r62c58c27eb1e40ea@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051024/2194fcf0/attachment.pl

From jerk_alert at hotmail.com  Mon Oct 24 18:29:08 2005
From: jerk_alert at hotmail.com (Ken Termiso)
Date: Mon, 24 Oct 2005 16:29:08 +0000
Subject: [R] Any way to add to data frame saved as .rData file?
In-Reply-To: <s34e58d8.054@lp-msg1.co.ihc.com>
Message-ID: <BAY101-F708248EA9898F2E10DA48E8770@phx.gbl>


thx everyone for your help...for simplicity, i elected to stay with a text 
file and transpose it so that each new row of data is really a column...in 
this transposed file, the header is really the row labels. the first cell 
has the name of the row labels ("RowID" in this case)...

here's code for what i ended up doing, in case anyone wants it (or wants to 
improve it) :


outfile <- mydata.txt

zz <- file(outfile, "w")

rowlabels <- c(1:10000)

cat(c("RowID", rowlabels, "\n"), file = zz, sep = "\t")   # make the first 
row of the file have the row labels

grep_text <- function(s)   # 's' is a unique string that is contained in the 
col or cols that you want
{
	temp_header <- scan(file = outfile, what = list("RowID"), flush = TRUE)
	temp_header <- unlist(temp_header)
	g <- grep(toString(s), temp_header)  # gives the row number in outfile with 
the data you want

	if(length(g)==1)
	{
		temp_file <- scan(file = outfile, what = character(), skip = g-1, nlines = 
1)  # temp_file = a vector
		temp_file <- temp_file[2:length(temp_file)]  # drop title
		temp_file <- as.numeric(temp_file)  # now this is num vector
		tf_df <- as.data.frame(temp_file)
	}

	if(length(g)>1)
	{
		for(i in 1:length(g))
		{
			temp_file <- scan(file = outfile, what = character(), skip = g[i]-1, 
nlines = 1)
			temp_file <- temp_file[2:length(temp_file)]  # drop title
			temp_file <- as.numeric(temp_file)  # now this is num vector

			if(i==1)
			{
				tf_df <- as.data.frame(temp_file)
			}

			if(i!=1)
			{
				tf_df[i] <- temp_file
			}
		}
	}

	return(tf_df)
}


you would use grep_text(s) to return a data frame with column titles 
contained in the string s...if i had a column named "Year05_population" in 
the "mydata.txt" file, to return a data frame named 'df' with only that one 
column titles "Year05_population" i would simply type :

outfile <- mydata.txt
df <- grep_text("Year05_population")



>From: "Greg Snow" <greg.snow at ihc.com>
>To: jerk_alert at hotmail.com,murdoch at stats.uwo.ca
>CC: gunter.berton at gene.com,r-help at stat.math.ethz.ch
>Subject: Re: [R] Any way to add to data frame saved as .rData file?
>Date: Thu, 13 Oct 2005 12:53:10 -0600
>
>Have you looked at the g.data package?  It might be useful
>(but may still require some redesign of your dataset).
>
>Greg Snow, Ph.D.
>Statistical Data Center, LDS Hospital
>Intermountain Health Care
>greg.snow at ihc.com
>(801) 408-8111
>
> >>> "Ken Termiso" <jerk_alert at hotmail.com> 10/13/05 08:14AM >>>
>
> >
> >I'd put the extra columns in their own data frame, and save that to
>disk
> >(use dates/times/process ids or some other unique identifier in the
> >filenames to distinguish them).  When you need access to a mixture of
>
> >columns, load (or source, depending how you did the save) the columns
>you
> >need, and cbind them together into one big data frame.
> >
> >If you are concerned about memory requirements when producing the
>pieces,
> >watch out that you don't write out so much data that you'll never have
>
> >enough memory to load all you need at once.
> >
> >Duncan Murdoch
>
>
>hmm...maybe i should just be dumping to a text file instead of a data
>frame..is there any way (without using a real SQL database) in R to
>create a
>file that i can selectively load certain columns from?
>
>if not, maybe i should break the data frame up into pieces (as you
>suggested) and create a separate file that keeps track of which columns
>are
>stored in which files (like a hashtable) and just load the small file
>of
>keys each time i need to load something..
>
>whaddya think??
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide!
>http://www.R-project.org/posting-guide.html
>



From KKIII at Indiana.Edu  Mon Oct 24 19:01:10 2005
From: KKIII at Indiana.Edu (Ken Kelley)
Date: Mon, 24 Oct 2005 12:01:10 -0500
Subject: [R] Problems with pf() with certain noncentral values/degrees of
 freedom combinations
Message-ID: <435D1356.5010600@Indiana.Edu>

Hello all.

It seems that the pf() function when used with noncentral parameters can 
behave badly at times. I've included some examples below, but what is 
happening is that with some combinations of df and ncp parameters, 
regardless of how large the quantile gets, the same probability value is 
returned. Upon first glance noncentral values greater than 200 may seem 
large, but they are in some contexts not large at all. The problems with 
pf() can thus have serious implications (for example, in the context of 
sample size planning).

I noticed that in in 1999 and 2000 issues with large degrees of freedom 
came about (PR#138), but I couldn't find the present issue reported 
anywhere.

Might there be a way to make the algorithm more stable? I'm not sure how 
difficult this issue might be to fix, but hopefully it won't be too bad 
and can be easily done. Any thoughts on a workaround until then?

Thanks,
Ken Kelley

# <Begin example code>
X <- seq(10, 600, 10)

# Gets stuck at .99135
############################
round(pf(X, 10, 1000, 225), 5)
round(pf(X, 10, 200, 225), 5)

round(pf(X, 5, 1000, 225), 5)
round(pf(X, 5, 200, 225), 5)

round(pf(X, 1, 1000, 225), 5)
round(pf(X, 1, 200, 225), 5)

# Gets stuck at .97035
############################
round(pf(X, 10, 1000, 250), 5)
round(pf(X, 10, 200, 250), 5)

round(pf(X, 5, 1000, 250), 5)
round(pf(X, 5, 200, 250), 5)

round(pf(X, 1, 1000, 250), 5)
round(pf(X, 1, 200, 250), 5)

# Gets stuck at .93539
############################
round(pf(X, 10, 1000, 275), 5)
round(pf(X, 10, 200, 275), 5)

round(pf(X, 5, 1000, 275), 5)
round(pf(X, 5, 200, 275), 5)

round(pf(X, 1, 1000, 275), 5)
round(pf(X, 1, 200, 275), 5)
# <end example code>

 > version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    2.0
year     2005
month    10
day      06
svn rev  35749
language R

-- 
Ken Kelley, Ph.D.
Inquiry Methodology Program
Indiana University
201 North Rose Avenue, Room 4004
Bloomington, Indiana 47405
http://www.indiana.edu/~kenkel



From ripley at stats.ox.ac.uk  Mon Oct 24 19:05:12 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 24 Oct 2005 18:05:12 +0100 (BST)
Subject: [R] Compilation package error
In-Reply-To: <435CF89D.70203@cnam.fr>
References: <435CF89D.70203@cnam.fr>
Message-ID: <Pine.LNX.4.61.0510241803220.30515@gannet.stats>

This is a compiler error, not an R package error.  Please ask on a 
suitable (Debian?) compiler list.

As a possible hint, when such things happen on Solaris it indicates a 
mis-installed gcc, missing the gnu binutils it depends on.

On Mon, 24 Oct 2005, Poizot Emmanuel wrote:

> Dear all,
> I tried to install gstat package and add the following compilation error :
>
> ------------------------>
> * Installing *source* package 'gstat' ...
> creating cache ./config.cache
> checking for gcc... gcc
> checking whether the C compiler (gcc  ) works... yes
> checking whether the C compiler (gcc  ) is a cross-compiler... no
> checking whether we are using GNU C... yes
> checking whether gcc accepts -g... yes
> checking how to run the C preprocessor... gcc -E
> checking for AIX... no
> checking for minix/config.h... no
> checking for POSIXized ISC... no
> checking for ANSI C header files... yes
> checking for working const... yes
> checking whether time.h and sys/time.h may both be included... yes
> checking for 8-bit clean memcmp... yes
> checking for vprintf... yes
> checking for strstr... yes
> checking for strtod... yes
> checking for strtol... yes
> checking for drand48... yes
> checking for gettimeofday... yes
> checking whether byte ordering is bigendian... no
> checking for memory.h... yes
> checking for ANSI C header files... (cached) yes
> checking for gcc option to accept ANSI C...
> checking for function prototypes... yes
> checking for working const... (cached) yes
> checking for complex.h... yes
> checking for malloc.h... yes
> checking for varargs.h... no
> checking for size_t... yes
> checking for working const... (cached) yes
> checking whether byte ordering is bigendian... (cached) no
> checking for u_int
> computing machine epsilon(s)
> gcc -o macheps ./src/meschach/dmacheps.c
> gcc -o macheps ./src/meschach/fmacheps.c
> computing M_MAX_INT
> gcc -o maxint maxint.c
> ./src/meschach/maxint.c: In function 'main':
> ./src/meschach/maxint.c:37: warning: incompatible implicit declaration of 
> built-in function 'printf'
> checking char \\0 vs. float zeros
> checking for bcopy... yes
> checking for bzero... yes
> checking for function prototypes
> checking for function prototypes in structures
> updating cache ./config.cache
> creating ./config.status
> creating makefile
> creating src/config.h
> creating src/machine.h
> ** libs
> gcc -I/usr/lib/R/include   -mieee-with-inexact  -fPIC  -g -O2 -c block.c -o 
> block.o
> gcc -I/usr/lib/R/include   -mieee-with-inexact  -fPIC  -g -O2 -c chfactor.c 
> -o chfactor.o
> gcc -I/usr/lib/R/include   -mieee-with-inexact  -fPIC  -g -O2 -c copy.c -o 
> copy.o
> gcc -I/usr/lib/R/include   -mieee-with-inexact  -fPIC  -g -O2 -c data.c -o 
> data.o
> /tmp/ccXDZili.s: Messages de l'assembleur:
> /tmp/ccXDZili.s:8032: ERREUR: Op?rande de relocalisation inconnue: 
> !lituse_jsrdirect
> make: *** [data.o] Erreur 1
> ERROR: compilation failed for package 'gstat'
> ** Removing '/usr/local/lib/R/site-library/gstat'
> ** Restoring previous '/usr/local/lib/R/site-library/gstat'
> ------------------->
>
> R run on a dec alpha station under Debian Sarge 64 bits (alpha version of 
> course).
> Compiler version is gcc 4.0.2.
>
> Regards
>
>
> ------------------------------------------------
> Emmanuel Poizot
> Cnam/Intechmer
> B.P. 324
> 50103 Cherbourg Cedex
>
> Phone (Direct) : (00 33)(0)233887342
> Fax : (00 33)(0)233887339
> ------------------------------------------------
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ligges at statistik.uni-dortmund.de  Mon Oct 24 19:06:59 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 24 Oct 2005 19:06:59 +0200
Subject: [R] question about technieque do with large computation
In-Reply-To: <0IOT0078F2LHBK@mail.fudan.edu.cn>
References: <0IOT0078F2LHBK@mail.fudan.edu.cn>
Message-ID: <435D14B3.8090402@statistik.uni-dortmund.de>

ronggui wrote:

> The green book tells:"The basic technique is classic :keep it simple ."A long ,complicated expression or function is less fravorable than" a relatively small computations that combines calls to a few other functions to perform its tasks."
> 
> But I don't get the point totally.Can anyone give me an example to make me understand this rules totally?
> 
> ps:
> Is it mean that f1 is better than f2?  Thank you!
> 
> 
> f1<-function(x){
> n<-length(x)
> s<-sum(x)
> m<-s/n}
> 
> f2<-
> function(x){
> m<-sum(x)/length(x)} 				


No, it means collecting sensible small parts of the code into separate
functions as in

f1 <- function(x, .....){
 x1 <- f1a(x, ......)
 x2 <- f1b(x1, .....)
 x3 <- f1a(x2, .....)
 f1c(x1, x2, x3, .....)
}

which is "better" than

f2 <- function(.....){
##
## many lines calculating stuff as in f1a
##
## many lines calculating stuff as in f1b
##
## many lines calculating stuff as in f1a
##
## many lines calculating stuff as in f1c
##
}


Uwe Ligges



> 
> 2005-10-23
> 
> ------
> Deparment of Sociology
> Fudan University
> 
> My new mail addres is ronggui.huang at gmail.com
> Blog:http://sociology.yculblog.com
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Mon Oct 24 19:12:57 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 24 Oct 2005 19:12:57 +0200
Subject: [R] Strange update behavior of gregmisc
In-Reply-To: <5ad2dec0510240126w25667b68h@mail.gmail.com>
References: <5ad2dec0510240126w25667b68h@mail.gmail.com>
Message-ID: <435D1619.1020405@statistik.uni-dortmund.de>

Googling for "gregmisc update" points us, e.g., to

http://tolstoy.newcastle.edu.au/~rking/R/devel/05/06/1140.html

Uwe Ligges



Thomas Sch??nhoff wrote:

> Hello,
> 
> I notice an odd behavior of gregmisc package when using
> "update.packages()" via R --no-save (as root).
> Every time I launch update.packages() gregmisc is repeatedly selected
> for upgrade. Current available version of gregmisc is 2.08 according
> to 'installed.packages()'. Despite I obviousely have already installed
> the most up to date gregmisc,  gregmisc will be updated repeatedly?
> 
> No one seems to have noticed a similar behavior like this before
> according to mail archive. All dependencies are seemingly meet and no
> error messages occured, so I am kind of stuck to figure out what
> happens here.
> Here is my update session:
> 
> thomas# R --no-save
> 
> ---------------------------------------------------------------------------------------
> 
>>update.packages()
> 
> --- Please select a CRAN mirror for use in this session ---
> Loading Tcl/Tk interface ... done
> gregmisc :
>  Version 2.0.6 installed in /usr/lib/R/site-library
>  Version 2.0.8 available at http://pangora.org/cran
> Update (y/N/c)?  y
> try URL 'http://pangora.org/cran/src/contrib/gregmisc_2.0.8.tar.gz'
> Content type 'application/x-tar' length 901 bytes
> URL opened
> ==================================================
> downloaded 901 bytes
> 
> * Installing *source* package 'gregmisc' ...
> No man pages found in package 'gregmisc'
> ** building package indices ...
> * DONE (gregmisc)
> 
> The downloaded packages are in
>         /tmp/Rtmp4Thydf/downloaded_packages
> ----------------------------------------------------------------------------------------------------------
> 
> When I relaunch 'update.packages()' the same as desribed above is
> going to happen again?
> 
> Do I miss something?
> 
> regards
> 
> Thomas
> 
> My system (Debian Sarge):
> 
> platform i386-pc-linux-gnu
> arch     i386
> os       linux-gnu
> system   i386, linux-gnu
> status
> major    2
> minor    2.0
> year     2005
> month    10
> day      06
> svn rev  35749
> language R
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From maarranz at tol-project.org  Mon Oct 24 20:22:41 2005
From: maarranz at tol-project.org (Miguel A. Arranz)
Date: Mon, 24 Oct 2005 20:22:41 +0200
Subject: [R] Compilation package error
In-Reply-To: <435CF89D.70203@cnam.fr>
References: <435CF89D.70203@cnam.fr>
Message-ID: <200510242022.41812.maarranz@tol-project.org>

Please, tell us more about the packages and libraries installed. I did compile  
and installed gstat on a machine running sid64 (unstable) with no problems. 
The only thing is that I did not compile with the -mieee-with-inexact switch.

Hope this helps.


On Monday 24 October 2005 17:07, Poizot Emmanuel wrote:
> Dear all,
> I tried to install gstat package and add the following compilation error :
>
> ------------------------>
> * Installing *source* package 'gstat' ...
> creating cache ./config.cache
> checking for gcc... gcc
> checking whether the C compiler (gcc  ) works... yes
> checking whether the C compiler (gcc  ) is a cross-compiler... no
> checking whether we are using GNU C... yes
> checking whether gcc accepts -g... yes
> checking how to run the C preprocessor... gcc -E
> checking for AIX... no
> checking for minix/config.h... no
> checking for POSIXized ISC... no
> checking for ANSI C header files... yes
> checking for working const... yes
> checking whether time.h and sys/time.h may both be included... yes
> checking for 8-bit clean memcmp... yes
> checking for vprintf... yes
> checking for strstr... yes
> checking for strtod... yes
> checking for strtol... yes
> checking for drand48... yes
> checking for gettimeofday... yes
> checking whether byte ordering is bigendian... no
> checking for memory.h... yes
> checking for ANSI C header files... (cached) yes
> checking for gcc option to accept ANSI C...
> checking for function prototypes... yes
> checking for working const... (cached) yes
> checking for complex.h... yes
> checking for malloc.h... yes
> checking for varargs.h... no
> checking for size_t... yes
> checking for working const... (cached) yes
> checking whether byte ordering is bigendian... (cached) no
> checking for u_int
> computing machine epsilon(s)
> gcc -o macheps ./src/meschach/dmacheps.c
> gcc -o macheps ./src/meschach/fmacheps.c
> computing M_MAX_INT
> gcc -o maxint maxint.c
> ./src/meschach/maxint.c: In function 'main':
> ./src/meschach/maxint.c:37: warning: incompatible implicit declaration
> of built-in function 'printf'
> checking char \\0 vs. float zeros
> checking for bcopy... yes
> checking for bzero... yes
> checking for function prototypes
> checking for function prototypes in structures
> updating cache ./config.cache
> creating ./config.status
> creating makefile
> creating src/config.h
> creating src/machine.h
> ** libs
> gcc -I/usr/lib/R/include   -mieee-with-inexact  -fPIC  -g -O2 -c block.c
> -o block.o
> gcc -I/usr/lib/R/include   -mieee-with-inexact  -fPIC  -g -O2 -c
> chfactor.c -o chfactor.o
> gcc -I/usr/lib/R/include   -mieee-with-inexact  -fPIC  -g -O2 -c copy.c
> -o copy.o
> gcc -I/usr/lib/R/include   -mieee-with-inexact  -fPIC  -g -O2 -c data.c
> -o data.o
> /tmp/ccXDZili.s: Messages de l'assembleur:
> /tmp/ccXDZili.s:8032: ERREUR: Op??rande de relocalisation inconnue:
> !lituse_jsrdirect
> make: *** [data.o] Erreur 1
> ERROR: compilation failed for package 'gstat'
> ** Removing '/usr/local/lib/R/site-library/gstat'
> ** Restoring previous '/usr/local/lib/R/site-library/gstat'
> ------------------->
>
> R run on a dec alpha station under Debian Sarge 64 bits (alpha version
> of course).
> Compiler version is gcc 4.0.2.
>
> Regards
>
>
> ------------------------------------------------
> Emmanuel Poizot
> Cnam/Intechmer
> B.P. 324
> 50103 Cherbourg Cedex
>
> Phone (Direct) : (00 33)(0)233887342
> Fax : (00 33)(0)233887339
> ------------------------------------------------

-- 
*************************
Miguel A. Arranz
Tol-Project
maarranz at tol-project.org



From kwright68 at gmail.com  Mon Oct 24 19:45:26 2005
From: kwright68 at gmail.com (Kevin Wright)
Date: Mon, 24 Oct 2005 12:45:26 -0500
Subject: [R] How to create a new data.frame with all possible observations
Message-ID: <adf71a630510241045y2a3a6d7fv1df3f84fe54f52d0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051024/5fbec750/attachment.pl

From lizzylaws at yahoo.com  Mon Oct 24 20:27:45 2005
From: lizzylaws at yahoo.com (Elizabeth Lawson)
Date: Mon, 24 Oct 2005 11:27:45 -0700 (PDT)
Subject: [R] Out of memory
Message-ID: <20051024182746.92338.qmail@web32105.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051024/006c547a/attachment.pl

From murdoch at stats.uwo.ca  Mon Oct 24 20:37:52 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 24 Oct 2005 14:37:52 -0400
Subject: [R] Out of memory
In-Reply-To: <20051024182746.92338.qmail@web32105.mail.mud.yahoo.com>
References: <20051024182746.92338.qmail@web32105.mail.mud.yahoo.com>
Message-ID: <435D2A00.2070600@stats.uwo.ca>

On 10/24/2005 2:27 PM, Elizabeth Lawson wrote:
> Hi,
>  
> I am using gamm and I run out of memory and R crashes.  I have tried to change the amount of memory in R using memory.limit as so far the largest it has allowed
> memory.limit(size=3072)
> still ahs this problem.
>  
> If I try to use max I get the following error
>> memory.limit(memory.size(max=TRUE))
> Error in memory.size(size) : don't be silly!: your machine has a 4Gb address limit
> 
>  
> Does anyone have any sugestions on how to get more memory ot R?

Notice that those functions report sizes in bytes, but memory.limit 
takes input in megabytes.  That's the reason for the "don't be silly" 
message.

To get more than 3 GB out of R, you're probably going to have to run a 
64 bit version.  The theoretical limit for 32 bit versions is 4 GB, but 
most OS's reserve 1-2 GB for themselves.

Duncan Murdoch



From LI at nsabp.pitt.edu  Mon Oct 24 20:41:35 2005
From: LI at nsabp.pitt.edu (Li, Jia)
Date: Mon, 24 Oct 2005 14:41:35 -0400
Subject: [R] Error in step() (or stepAIC) for Cox model
Message-ID: <D70CBC108DFBD446862A6E1F6F0B4A1557A3C0@nsabpmail>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051024/cf808391/attachment.pl

From tschoenhoff at gmail.com  Mon Oct 24 21:19:01 2005
From: tschoenhoff at gmail.com (=?ISO-8859-1?Q?Thomas_Sch=F6nhoff?=)
Date: Mon, 24 Oct 2005 21:19:01 +0200
Subject: [R] Strange update behavior of gregmisc
In-Reply-To: <435D1619.1020405@statistik.uni-dortmund.de>
References: <5ad2dec0510240126w25667b68h@mail.gmail.com>
	<435D1619.1020405@statistik.uni-dortmund.de>
Message-ID: <5ad2dec0510241219l35521e26q@mail.gmail.com>

Hello,

2005/10/24, Uwe Ligges <ligges at statistik.uni-dortmund.de>:
> Googling for "gregmisc update" points us, e.g., to
>
> http://tolstoy.newcastle.edu.au/~rking/R/devel/05/06/1140.html

Thanks, I totally missed that.

Thomas



From chrysopa at gmail.com  Mon Oct 24 21:56:29 2005
From: chrysopa at gmail.com (Ronaldo Reis-Jr.)
Date: Mon, 24 Oct 2005 17:56:29 -0200
Subject: [R] lme and lmer syntax
Message-ID: <200510241756.29319.chrysopa@gmail.com>

Hi,

I have this:

lme(y~x1+x2,random=~1|x1/x2)

How to make this random effect using lmer?

I try this:

lmer(y~x1+x2+(1|x1/x2)

But it dont work.

Any idea?

Thanks
Ronaldo
-- 
System halted!
--
|>   // | \\   [***********************************]
|   ( ??   ?? )  [Ronaldo Reis J??nior                ]
|>      V      [UFV/DBA-Entomologia                ]
|    /     \   [36570-000 Vi??osa - MG              ]
|>  /(.''`.)\  [Fone: 31-3899-4007                 ]
|  /(: :'  :)\ [chrysopa at insecta.ufv.br            ]
|>/ (`. `'` ) \[ICQ#: 5692561 | LinuxUser#: 205366 ]
|    ( `-  )   [***********************************]
|>>  _/   \_Powered by GNU/Debian Woody/Sarge



From ripley at stats.ox.ac.uk  Mon Oct 24 22:05:01 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 24 Oct 2005 21:05:01 +0100 (BST)
Subject: [R] Error in step() (or stepAIC) for Cox model
In-Reply-To: <D70CBC108DFBD446862A6E1F6F0B4A1557A3C0@nsabpmail>
References: <D70CBC108DFBD446862A6E1F6F0B4A1557A3C0@nsabpmail>
Message-ID: <Pine.LNX.4.61.0510242103140.13863@gannet.stats>

On Mon, 24 Oct 2005, Li, Jia wrote:

> Hello all,
>
> I am trying to use stepwise procedure to select covariates in Cox model
> and use bootstrap to repeat stepwise selection,  then record how many
> times  variables  are chosen by step() in bootstrap replications. When I
> use step() (or stepAIC) to do model selection, I got errors. Here is the
> part of my code
>
> for (j in 1:mm){    #<--mm=10
>
> for (b in 1:nrow(reg.bs)){ #<--bootstrap 10 times
>
> mi<-data.frame(tlfup,cen,complete(imp,j)) #<--completed data sets after
> MI
>
> in.star<-sample(1:n,n,replace=T) #<--to sample id number 1-1851.
>
> data.star<-mi[in.star,]
>
> M<-coxph(Surv(tlfup,cen)~mi$trt+mi$nodes+mi$htypeed1+mi$htypeed2+mi$ngra
> ded2+mi$agem40
>
> +mi$agem40sq+mi$er+mi$pr,data=data.star)
>
> reg.model<-step(M) #<--do stepwise selection
>
> reg.step[[b]]<-c((reg.model$coef)) #<-store selected variables
>
> chosen.vb[[b]]<-names(reg.step[[b]]) #<--store names of selected
> variables
>
> }
>
> tot.vb[[j]]<-c(unlist(chosen.vb))
>
> }
>
> Error in reg.step[[b]] : subscript out of bounds
>
>
> varibles<-unlist(tot.vb) #<--change to a vector
>
> table(varibles)           #<--how many times the names have been
> selected
>
> Error in sort(unique.default(x), na.last = TRUE) :
>        'x' must be atomic
>
>
> I figure the reason may be that when stepwise procedure selects the
> chosen model with no varibles, that is
>
> Start:  AIC= 12436.85
> Surv(tlfup, cen) ~ mi$trt + mi$nodes + mi$htypeed1 + mi$htypeed2 +
>    mi$ngraded2 + mi$agem40 + mi$agem40sq + mi$er + mi$pr
>
>              Df   AIC
> - mi$pr        1 12435
> - mi$trt       1 12435
> - mi$agem40sq  1 12435
> - mi$agem40    1 12435
> - mi$htypeed2  1 12435
> - mi$nodes     1 12435
> - mi$er        1 12436
> - mi$ngraded2  1 12436
> - mi$htypeed1  1 12436
> <none>           12437
>
> Step:  AIC= 12425.91
> Surv(tlfup, cen) ~ mi$htypeed1 + mi$ngraded2 + mi$er
>
>              Df   AIC
> - mi$er        1 12425
> - mi$ngraded2  1 12425
> - mi$htypeed1  1 12426
> <none>           12426
>
> Step:  AIC= 12424.77
> Surv(tlfup, cen) ~ 1
>
> then reg.model$coef dosen't exist anymore (am I right?), but I need to
> count the variables that are selected by step() in bootstrap
> replications, what should I do?

Specify the lower scope suitably.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From HDoran at air.org  Mon Oct 24 22:08:41 2005
From: HDoran at air.org (Doran, Harold)
Date: Mon, 24 Oct 2005 16:08:41 -0400
Subject: [R] lme and lmer syntax
Message-ID: <F5ED48890E2ACB468D0F3A64989D335ACDC1F0@dc1ex3.air.org>

Ronaldo

See the article on lmer pasted below for syntax. It is the only current source documenting the code. In lmer(), the nesting structure for the ranmdom effects is handled in a slightly different way. If your observations are nested as you note, then you can use

> lmer(y~x1 + x2 +(1|x1) + (1|x2), data)

@Article{Rnews:Bates:2005,
  author       = {Douglas Bates},
  title	       = {Fitting Linear Mixed Models in {R}},
  journal      = {R News},
  year	       = 2005,
  volume       = 5,
  number       = 1,
  pages	       = {27--30},
  month	       = {May},
  url	       = {http://CRAN.R-project.org/doc/Rnews/},
}

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ronaldo Reis-Jr.
Sent: Monday, October 24, 2005 3:56 PM
To: R-Help
Subject: [R] lme and lmer syntax

Hi,

I have this:

lme(y~x1+x2,random=~1|x1/x2)

How to make this random effect using lmer?

I try this:

lmer(y~x1+x2+(1|x1/x2)

But it dont work.

Any idea?

Thanks
Ronaldo
--
System halted!
--
|>   // | \\   [***********************************]
|   ( ??   ?? )  [Ronaldo Reis J??nior                ]
|>      V      [UFV/DBA-Entomologia                ]
|    /     \   [36570-000 Vi??osa - MG              ]
|>  /(.''`.)\  [Fone: 31-3899-4007                 ]
|  /(: :'  :)\ [chrysopa at insecta.ufv.br            ]
|>/ (`. `'` ) \[ICQ#: 5692561 | LinuxUser#: 205366 ]
|    ( `-  )   [***********************************]
|>>  _/   \_Powered by GNU/Debian Woody/Sarge

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From peter.robinson at charite.de  Mon Oct 24 22:32:48 2005
From: peter.robinson at charite.de (Dr. med. Peter Robinson)
Date: Mon, 24 Oct 2005 22:32:48 +0200 (CEST)
Subject: [R] Basic: setting resolution and size of an R graphic
Message-ID: <64018.84.190.251.65.1130185968.squirrel@webmail.charite.de>

Dear List,

I am sorry if this perhaps a too basic question, but I have not found an
answer in Google or in the R help system. I am trying to use R to do a
very simple analysis of some data (RT-PCR and Western analysis) with a
T-test and
to plot the results as a histogram with error bars. (I have pasted an
example script at the bottom of this mail).
In order to use this for publication, I would like to adjust the
resolution and size of the final image. However, even using file types
such as postscript or pdf that are vector based, I get rather bad-looking
results with
>pdf(file="test.pdf")
>source("script at bottom of mail")
>dev.off()

using either pdf or postscript or jpg devices.


Therefore I would like to ask the list, how to best produce a graphic from
the script below that would fit into one column of a published article and
have a high resolution (as eps, or failing that tiff or png)?
Thanks in advance for any advice,

Peter




## Western.R
## A script to display the results of quantitative Western blotting with 6
repeats each at three dosages.
## This particular script has data from stimulation of fibroblasts with M-wt.


# ----------   CONVENIENCE FUNCTIONS --------------------- #
## Define a simple function to draw the error bars.
makeBars <- function(x,mean,se){
	segments(x,mean - se/2,x,mean+se/2)
	segments(x-0.1,mean - se/2,x+0.1,mean - se/2)
	segments(x-0.1,mean + se/2,x+0.1,mean + se/2)
	}
##Define a simple function to write p values
writeP <- function(x,mean,se,pval) {
	if (pval >= 0.01) {
		# text(x, mean + se/2 + 0.25, sprintf('p=%.2f',pval),cex=1.5)
		text(x +0.05, mean + se/2 + 0.4, sprintf('*'),cex=1)
	} else {
		text(x +0.05, mean + se/2 + 0.4, sprintf('**'),cex=1)
		}
	}


## define function to draw entire group
## A,B,C refer to the x positions of the x,y,z observations
drawBarsAndPValueForGroup <-
function(A,B,C,x.mean,x.se,y.mean,y.se,z.mean,z.se,xy.pval,xz.pval) {
	makeBars(A,x.mean,x.se)
	makeBars(B,y.mean,y.se)
	makeBars(C,z.mean,z.se)
	writeP(B - 0.05, y.mean,y.se,xy.pval)
	writeP(C -0.05,z.mean,z.se,xz.pval)
}



## We will make a two part graphic
par(mfrow=c(1,2))

## X: 0
## y: 0.2 ??M
## z: 0.4 ??M

yTop <- 12  ## Limit for Y axis

##  ---  RT-PCR MMP1   --- ##

x <- c(0.8839034,0.42011158,0.65318013 , 0.88494528,1.900606, 1.2572536 )
x.mean <- mean(x)
x.se <-	sd(x) / sqrt(length(x))
y <- c(5.067579666,2.630677502,1.881902881,1.61994864,3.356066695 )
y.mean <- mean(y)
y.se <- sd(y)/ sqrt(length(y))
z <-
c(13.38923048,3.677270765,3.559984278,10.83628903,12.20110874,12.8957108)
z.mean <- mean(z)
z.se <- sd(z)/ sqrt(length(z))

## -- Do t test and calculate the p values -- ##
xy.t <- t.test(y,x, alternative=c("greater"),var.equal=TRUE)
xy.pval <- xy.t$p.value

xz.t <- t.test(z, x, alternative=c("greater"),var.equal=TRUE)
xz.pval <- xz.t$p.value


arr <- c(x.mean,y.mean,z.mean)
mat <- matrix(arr,nrow=3,byrow=F)


barplot(mat,  ## The data
	beside=TRUE, ## juxtapose values in each column rather than stacking them
	ylim=c(0,yTop), ## limits for y axis
	xlim=c(0,3),
	width=1,
	space=c(0,0.1),##space: the amount of space (as a fraction of the average
bar width)
                            ##  left before each bar. beside=TRUE, can be
given
			    ## by 2 numbers, the space between bars within a group
			    ## and space betweens bars of different groups
	names=c('0.0 ??M','0.2 ??M','0.4 ??M'),
	ylab='Relative Change',
      col=c('white'),
      cex.names=1,
	cex.axis=1,##cex.axis: expansion factor for numeric axis labels.
	cex.lab=1)

## First for the RT-PCR group
start <- 0.1
first <- start + 0.5
second <- start + 1.5
third <- start + 2.5

drawBarsAndPValueForGroup(first,second,third,x.mean,x.se,y.mean,y.se,z.mean,z.se,xy.pval,xz.pval)


##  --- Western MMP1 --- ##

x2 <- c(1.117373856,0.690266558,1.192359586 )
y2 <- c(3.53806369,3.895634049,6.653024511 )
z2 <- c(8.609814741,3.858564979,8.492977115)

x2.mean <- mean(x2)
x2.se <- sd(x2) / sqrt(length(x2))
y2.mean <- mean(y2)
y2.se <- sd(y2)/ sqrt(length(y2))
z2.mean <- mean(z2)
z2.se <- sd(z2)/ sqrt(length(2))

## -- Do t test and calculate the p values -- ##
xy2.t <- t.test(y2,x2, alternative=c("greater"),var.equal=TRUE)
xy2.pval <- xy2.t$p.value

xz2.t <- t.test(z2,x2,alternative=c("greater"),var.equal=TRUE)
xz2.pval <- xz2.t$p.value



arr <- c(x2.mean, y2.mean,z2.mean)
mat <- matrix(arr,nrow=3,byrow=F)

## mat now has the values of each type of experiment in individual columns




barplot(mat,  ## The date
	beside=TRUE, ## juxtapose values in each column rather than stacking them
	ylim=c(0,yTop), ## limits for y axis
	xlim=c(0,4),
	width=1,
	space=c(0,0.1),##space: the amount of space (as a fraction of the average
bar width)
                            ##  left before each bar. beside=TRUE, can be
given
			    ## by 2 numbers, the space between bars within a group
			    ## and space betweens bars of different groups
	names=c('0.0 ??M','0.2 ??M','0.4 ??M'),
	ylab='Relative Change',
      col=c('white'),
      cex.names=0.8,
	cex.axis=1, ##cex.axis: expansion factor for numeric axis labels.
	cex.lab=1)


first <- 0.6
second <- first + 1
third <- first + 2
drawBarsAndPValueForGroup(first,second,third,x2.mean,x2.se,y2.mean,y2.se,z2.mean,z2.se,xy2.pval,xz2.pval)



From bgreen at dyson.brisnet.org.au  Mon Oct 24 22:51:51 2005
From: bgreen at dyson.brisnet.org.au (Bob Green)
Date: Tue, 25 Oct 2005 06:51:51 +1000
Subject: [R] error messages in matrix multiplication
Message-ID: <5.1.0.14.0.20051025064426.02481650@pop3.brisnet.org.au>

Hello,

I am hoping for some advice on using R - my experience with statistical 
programs has been limited to SPSS.

I have been using a textual analysis program and wanted to add some rigour 
to making a choice between two models of self-reported cannabis effects. To 
do this, I need to compare the two resulting word co-occurence matrices. 
The program itself,doesn't offer this as an option and the person who wrote 
the program, told me where the numerical data was located and offered this 
advice:

"For two vectors a and b, the cosine similarity is: therefore cos   theta = 
a . b / magn(a)*magn(b) & that the formula is really identical   for 
matrices. The dot product (or inner product) is calculated by   multiplying 
each pair of corresponding elements from the two matrices,   and summing 
these products. Calculating the magnitude of a matrix is   really the same 
as a vector:  square each element of the matrix, sum the   squares, then 
take the square root of the sum."

I have been advised that when matrices are multiplied I should use %*%, 
whereas if I want a point estimate I omit the %.


I have tried to run syntax with and without the %, however my efforts at 
either syntax below (a) or syntax (b) remain unsuccessful.

With (a) I obtain the message - Warning message: Error in A %*% B : 
non-conformable arguments

With (b) I obtain the message - Warning message:NAs produced by integer 
overflow in: sum(A * A) * sum(B * B) :


(a) Matrix

testA <-read.table("c:\\matrixA.txt",header=T)
testB <-read.table("c:\\matrixB.txt",header=T)

A<-as.matrix(testA)
B<-as.matrix(testB)

cosineDissimilarity <- sum(A%*%B)/sqrt(sum(A%*%A)*sum(B%*%B))



(b) pointwise

testA <-read.table("c:\\matrixA.txt",header=T)
testB <-read.table("c:\\matrixB.txt",header=T)

A<-as.matrix(testA)
B<-as.matrix(testB)

cosineDissimilarity <- sum(A*B)/sqrt(sum(A*A)*sum(B*B))



Any suggestions are appreciated, regarding either the above logic about 
analysis selection or the necessary syntax.

regards

Bob



From mschwartz at mn.rr.com  Mon Oct 24 22:53:57 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Mon, 24 Oct 2005 15:53:57 -0500
Subject: [R] Basic: setting resolution and size of an R graphic
In-Reply-To: <64018.84.190.251.65.1130185968.squirrel@webmail.charite.de>
References: <64018.84.190.251.65.1130185968.squirrel@webmail.charite.de>
Message-ID: <1130187237.4216.130.camel@localhost.localdomain>

On Mon, 2005-10-24 at 22:32 +0200, Dr. med. Peter Robinson wrote:
> Dear List,
> 
> I am sorry if this perhaps a too basic question, but I have not found an
> answer in Google or in the R help system. I am trying to use R to do a
> very simple analysis of some data (RT-PCR and Western analysis) with a
> T-test and
> to plot the results as a histogram with error bars. (I have pasted an
> example script at the bottom of this mail).
> In order to use this for publication, I would like to adjust the
> resolution and size of the final image. However, even using file types
> such as postscript or pdf that are vector based, I get rather bad-looking
> results with
> >pdf(file="test.pdf")
> >source("script at bottom of mail")
> >dev.off()
> 
> using either pdf or postscript or jpg devices.
> 
> 
> Therefore I would like to ask the list, how to best produce a graphic from
> the script below that would fit into one column of a published article and
> have a high resolution (as eps, or failing that tiff or png)?
> Thanks in advance for any advice,
> 
> Peter

<Snip of code>

What OS are you on?

Running your example on FC4, I get the attached output for a pdf().

I suspect that on your OS, the height and width arguments are not
appropriate by default.

Thus, you may need to adjust your pdf (or postscript) function call to
explicitly specify larger height and width arguments.

Also note that to generate an EPS file, pay attention to the details
section of ?postscript, taking note of the 'onefile', 'horizontal' and
'paper' arguments and settings.

Also, check with your journal to see if they specify dimensions for such
graphics so that you can abide by their specs if provided. If they are
using LaTeX, there are means of specifying and/or adjusting the height
and/or width specs in the code based upon proportions of various
measures (ie. \includegraphics[width=0.9\textwidth]{GraphicsFile.eps} ).

HTH,

Marc Schwartz

-------------- next part --------------
A non-text attachment was scrubbed...
Name: test.pdf
Type: application/pdf
Size: 5321 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20051024/fbf70820/test.pdf

From greg.snow at ihc.com  Mon Oct 24 21:07:55 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Mon, 24 Oct 2005 13:07:55 -0600
Subject: [R] Male and female symbols?
Message-ID: <s35d0cc5.051@lp-msg1.co.ihc.com>

If you have image files of your plotting symbols (fox and rabbits) then
one
approach is to follow the example in the post at:
http://tolstoy.newcastle.edu.au/~rking/R/help/05/08/10890.html

hope this helps,

Greg Snow, Ph.D.
Statistical Data Center, LDS Hospital
Intermountain Health Care
greg.snow at ihc.com
(801) 408-8111

>>> Ted Harding <Ted.Harding at nessie.mcc.ac.uk> 10/22/05 08:58AM >>>

George's query somewhat leads on to a more general question:
Can one define one's own symbols for plotting?

For example -- though I'm not seriously saying I need this --
in a population study of faxes and rabbits surveyed over several
years, one might wish to plot the Rabbit population using tiny
rabbits as points, and foxes' heads for the Fox population.

(Given the data coordinates, I would have my own ways to do this;
but not in R).

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 22-Oct-05                                       Time: 15:55:41
------------------------------ XFMail ------------------------------

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From tate_sterling_avery at hotmail.com  Tue Oct 25 00:54:15 2005
From: tate_sterling_avery at hotmail.com (Tate Avery)
Date: Mon, 24 Oct 2005 18:54:15 -0400
Subject: [R] stepAIC formula upper limit guidelines
Message-ID: <BAY103-F1632BBB40F8EAAD1B0FA5AAE770@phx.gbl>

Hello,

I am attempting to refine an lm()-generated model using the stepAIC 
function.

My model has approximately 20 inputs and I am trying to determine the best 
upper limit scope for using those inputs.

My lower limit is "y ~ 1" and my original upper limit was "y ~ x1 + x2 + ... 
+ x20".

This is great start, but I am wondering if some other (more broad) upper 
limit would allow for combinations of inputs (examples: "x1*x3" or "x5/x7") 
before the coefficients are applied.

Specifically, I am trying to determine what syntax will give stepAIC the 
most flexibility to slice and dice my inputs as it searches for the best 
possible model.

Any details or references would be immensely appreciated.

Thank you,
Tate Avery



From mail at bymouth.com  Tue Oct 25 05:48:42 2005
From: mail at bymouth.com (Stephen Choularton)
Date: Tue, 25 Oct 2005 13:48:42 +1000
Subject: [R] selecting every nth item in the data
Message-ID: <002301c5d917$001d1bb0$9701a8c0@Tablet>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051025/557579ad/attachment.pl

From petr.pikal at precheza.cz  Tue Oct 25 06:45:59 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 25 Oct 2005 06:45:59 +0200
Subject: [R] selecting every nth item in the data
In-Reply-To: <002301c5d917$001d1bb0$9701a8c0@Tablet>
Message-ID: <435DD4A7.9563.1BD0D9@localhost>



On 25 Oct 2005 at 13:48, Stephen Choularton wrote:

From:           	"Stephen Choularton" <mail at bymouth.com>
To:             	"R Help" <r-help at stat.math.ethz.ch>
Date sent:      	Tue, 25 Oct 2005 13:48:42 +1000
Subject:        	[R] selecting every nth item in the data

> I want to make a glm and then use predict.  I have a fairly small
> sample (4000 cases) and I want to train on 90% and test on 10% but I
> want to do it in slices so I test on every 10th case and train on the
> others.  Is there some simple way to get these elements?

As glm accept subet you probably can use

test<-seq(1,4000,n)

glm(...., subset = test)

to select only n'th item or

glm(...., subset = -test)

to select all but n'th items.

or you can split the data freme by

mydf[test,] or mydf[-test,]

HTH
Petr



> 
> Stephen
> 
> -- 
> 
> 
> 
> 21/10/2005
> 
> 
>  [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From dlvanbrunt at gmail.com  Tue Oct 25 06:50:02 2005
From: dlvanbrunt at gmail.com (David L. Van Brunt, Ph.D.)
Date: Mon, 24 Oct 2005 23:50:02 -0500
Subject: [R] Examples of "classwt", "strata", and "sampsize" in randomForest?
Message-ID: <d332d3e10510242150o701a7f48n1238ee97cf072f6d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051024/d701c13d/attachment.pl

From ligges at statistik.uni-dortmund.de  Tue Oct 25 08:54:07 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 25 Oct 2005 08:54:07 +0200
Subject: [R] stepAIC formula upper limit guidelines
In-Reply-To: <BAY103-F1632BBB40F8EAAD1B0FA5AAE770@phx.gbl>
References: <BAY103-F1632BBB40F8EAAD1B0FA5AAE770@phx.gbl>
Message-ID: <435DD68F.1060001@statistik.uni-dortmund.de>

Tate Avery wrote:
> Hello,
> 
> I am attempting to refine an lm()-generated model using the stepAIC 
> function.
> 
> My model has approximately 20 inputs and I am trying to determine the best 
> upper limit scope for using those inputs.
> 
> My lower limit is "y ~ 1" and my original upper limit was "y ~ x1 + x2 + ... 
> + x20".
> 
> This is great start, but I am wondering if some other (more broad) upper 
> limit would allow for combinations of inputs (examples: "x1*x3" or "x5/x7") 
> before the coefficients are applied.


Are you really sure you want to try out all those combinations of 
variables? You will need an almost infinite number of observation to be 
sure you did not find anything just by chance ...

Uwe Ligges



> Specifically, I am trying to determine what syntax will give stepAIC the 
> most flexibility to slice and dice my inputs as it searches for the best 
> possible model.
> 
> Any details or references would be immensely appreciated.
> 
> Thank you,
> Tate Avery
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From peter.robinson at charite.de  Tue Oct 25 08:57:43 2005
From: peter.robinson at charite.de (Dr. med. Peter Robinson)
Date: Tue, 25 Oct 2005 08:57:43 +0200 (CEST)
Subject: [R] Basic: setting resolution and size of an R graphic
In-Reply-To: <1130187237.4216.130.camel@localhost.localdomain>
References: <64018.84.190.251.65.1130185968.squirrel@webmail.charite.de>
	<1130187237.4216.130.camel@localhost.localdomain>
Message-ID: <39640.192.168.220.201.1130223463.squirrel@webmail.charite.de>

Thanks Marc and Jim for the tips. The PDF file that I create with R looks
about the same as the one you created. However, I need to get the graphic
to be a certain size (300 pixels wide). I have been using the ImageMagick
program to do so for other graphics:

convert test.pdf -resize 300x300 out.pdf

then out.pdf looks rather poor (pixelly). The original image is too big.
ANy ideas?
Thanks a lot,Peter


Am Mo, 24.10.2005, 22:53, schrieb Marc Schwartz (via MN):
> On Mon, 2005-10-24 at 22:32 +0200, Dr. med. Peter Robinson wrote:
>
>> Dear List,
>>
>>
>> I am sorry if this perhaps a too basic question, but I have not found
>> an answer in Google or in the R help system. I am trying to use R to do
>> a very simple analysis of some data (RT-PCR and Western analysis) with a
>>  T-test and
>> to plot the results as a histogram with error bars. (I have pasted an
>> example script at the bottom of this mail). In order to use this for
>> publication, I would like to adjust the resolution and size of the final
>> image. However, even using file types such as postscript or pdf that are
>> vector based, I get rather bad-looking results with
>>> pdf(file="test.pdf") source("script at bottom of mail") dev.off()
>>
>> using either pdf or postscript or jpg devices.
>>
>>
>> Therefore I would like to ask the list, how to best produce a graphic
>> from the script below that would fit into one column of a published
>> article and have a high resolution (as eps, or failing that tiff or
>> png)? Thanks in advance for any advice,
>>
>>
>> Peter
>>
>
> <Snip of code>
>
>
> What OS are you on?
>
>
> Running your example on FC4, I get the attached output for a pdf().
>
>
> I suspect that on your OS, the height and width arguments are not
> appropriate by default.
>
> Thus, you may need to adjust your pdf (or postscript) function call to
> explicitly specify larger height and width arguments.
>
> Also note that to generate an EPS file, pay attention to the details
> section of ?postscript, taking note of the 'onefile', 'horizontal' and
> 'paper' arguments and settings.
>
>
> Also, check with your journal to see if they specify dimensions for such
> graphics so that you can abide by their specs if provided. If they are
> using LaTeX, there are means of specifying and/or adjusting the height
> and/or width specs in the code based upon proportions of various measures
> (ie. \includegraphics[width=0.9\textwidth]{GraphicsFile.eps} ).
>
>
> HTH,
>
>
> Marc Schwartz
>
>
>



From joostvanevert at gmail.com  Tue Oct 25 10:48:07 2005
From: joostvanevert at gmail.com (Joost van Evert)
Date: Tue, 25 Oct 2005 10:48:07 +0200
Subject: [R] Spearman's Rho Help!
In-Reply-To: <BAY103-F2195E0F6A82F0C778A4649B2770@phx.gbl>
References: <BAY103-F2195E0F6A82F0C778A4649B2770@phx.gbl>
Message-ID: <1130230087.17852.4.camel@inpc93.et.tudelft.nl>

On Mon, 2005-10-24 at 09:01 -0400, Suresh Kumar Karanam wrote:
> Hi,
> I have a dataset with four categories of data, the number of samples are not 
> the same in each category. I want to find the Spearaman's Rho. Let me give 
> an example.
> x=(14.22770439,26.49420624,46.7277932,19.02550707,23.37379361,16.97789862,19.77100085,23.11270162,13.72929843,33.54430621,14.4756979,70.15811106,11.22789833,NA,NA,NA)
> y=(143.2420241,45.24260203,62.13218994,27.79050219,27.41029595,191.2759927,141.1430225,234.1600259,37.69120463,156.332942,19.98579421,34.77930022,69.90888888,21.92539608,NA,NA)
> z=(70.28027834,349.7838817,29.81811184,83.48042267,52.47989761,107.7110162,71.24609317,155.6580091,68.37158664,156.3179887,134.8930305,80.25242044,100.5309559,266.4470408,65.4934171,22.86950128)
> v=(150.2099947,73.52000706,83.18122348,150.3240468,352.9101222,195.8919089,263.9489287,114.2090369,153.5000165,18.62309563,117.2399949,441.8981252,285.3369951,161.3959985,NA,NA)
> I want to find the spearman's rho for this data. To my knowledge spearman's 
> rho is for x vs. y or x vs. z or any combination. Is there a spearman's rho 
> for the data all together (x y z v)? Please help!
e.g.
cor(array(c(x,y,z,v),c(16,4)),use="pairwise")

The correlation function calculates by default spearman's rho and can
have an array as input. The use parameter determines how to handle NA's.
See ?cor

Joost



From sw283 at maths.bath.ac.uk  Tue Oct 25 11:01:10 2005
From: sw283 at maths.bath.ac.uk (Simon Wood)
Date: Tue, 25 Oct 2005 10:01:10 +0100 (BST)
Subject: [R] GAM and AIC: How can I do??? please
In-Reply-To: <20051024015532.0000C00B01D902E9@pmail1.dreamwiz.com>
References: <20051024015532.0000C00B01D902E9@pmail1.dreamwiz.com>
Message-ID: <Pine.LNX.4.56.0510250959330.12479@mars>

Please send R and mgcv version numbers, as I can't replicate this
problem. best, Simon


>
>    Hello,  I'm a Korean researcher who have been started to learn the "R"
>    package.
>
>    I want to make gam model and AIC value of the model to compare several
>    models.
>
>    I did the GAM model, but there were error for AIC.
>
>    SO, how can I do? pleas help me!!!
>
>
>
>    I did like below;
>
>
>    > a.fit <- gam(pi~ s(t1r), family = gaussian(link="log"))
>    > summary(a.fit)
>
>
>    Family: gaussian
>    Link function: log
>
>    Formula:
>    pi ~ s(t1r)
>
>    Parametric coefficients:
>               Estimate  std. err.    t ratio    Pr(>|t|)
>    constant   0.093105   0.005238      17.77    < 2.22e-16
>
>    Approximate significance of smooth terms:
>                  edf       chi.sq     p-value
>    s(t1r)      1.833       24.153     0.00014213
>
>    R-sq.(adj) =  0.435   Deviance explained = 47.1%
>    GCV score = 0.0010938   Scale est. = 0.00099053  n = 30
>
>    > AIC(a.fit)
>    Error in logLik(object) : no applicable method for "logLik"
>
>
>    Eun A Kim, MD, MPH, Ph.D
>    Senior Researcher
>    Occupational safety and Health Research Institute
>    Korea Occupational Safety and Health Agency
>    TEL : +82-32-510-0910, FAX: +82-32-518-0862
>    Address:  34-4 Gusan-dong, Bupyung-Gu, Incheon city, 430-711, Republic
>    of Korea
>    Home Fax +82-(303)3111-0573
>    [receive_check.cgi?sender=euna0 at dreamwiz.com&msgid=%3C20051024015532.0
>    000C00B01D902E9 at pmail1.dreamwiz.com%3E&receiver=r-help at stat.math.ethz.
>    ch&key=bd02e77f5ec97f754394e2adff337f11]
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From poizot at cnam.fr  Tue Oct 25 12:20:59 2005
From: poizot at cnam.fr (Poizot Emmanuel)
Date: Tue, 25 Oct 2005 12:20:59 +0200
Subject: [R] Compilationerror at installation of packages
Message-ID: <435E070B.1070905@cnam.fr>

Dear all,

I did post a message about problems on installing a package (gstat) 
which ends with a compilation error:

** libs
gcc -I/usr/lib/R/include   -mieee-with-inexact  -fPIC  -g -O2 -c block.c 
-o block.o
gcc -I/usr/lib/R/include   -mieee-with-inexact  -fPIC  -g -O2 -c 
chfactor.c -o chfactor.o
gcc -I/usr/lib/R/include   -mieee-with-inexact  -fPIC  -g -O2 -c copy.c 
-o copy.o
gcc -I/usr/lib/R/include   -mieee-with-inexact  -fPIC  -g -O2 -c data.c 
-o data.o
/tmp/ccB5viRU.s: Messages de l'assembleur:
/tmp/ccB5viRU.s:8032: ERREUR: Op??rande de relocalisation inconnue: 
!lituse_jsrdirect
make: *** [data.o] Erreur 1
ERROR: compilation failed for package 'gstat'

I tried an other package and have the same result.
The R installation is new so tha I have all the basic packages installed
I used gcc compiler :

Using built-in specs.
Target: alpha-linux-gnu
Configured with: ../src/configure -v 
--enable-languages=c,c++,java,f95,objc,treelang --prefix=/usr 
--enable-shared --with-system-zlib --libexecdir=/usr/lib 
--without-included-gettext --enable-threads=posix --enable-nls 
--program-suffix=-4.0 --enable-__cxa_atexit 
--enable-libstdcxx-allocator=mt --enable-clocale=gnu 
--enable-libstdcxx-debug --enable-java-gc=boehm --enable-java-awt=gtk 
--enable-gtk-cairo 
--with-java-home=/usr/lib/jvm/java-1.4.2-gcj-4.0-1.4.2.0/jre 
--enable-mpfr --disable-werror --enable-checking=release alpha-linux-gnu
Thread model: posix
gcc version 4.0.2 (Debian 4.0.2-2)

Regards
-- 


------------------------------------------------
Emmanuel Poizot
Cnam/Intechmer
B.P. 324
50103 Cherbourg Cedex

Phone (Direct) : (00 33)(0)233887342
Fax : (00 33)(0)233887339
------------------------------------------------


From roger.bos at gmail.com  Tue Oct 25 14:51:48 2005
From: roger.bos at gmail.com (roger bos)
Date: Tue, 25 Oct 2005 08:51:48 -0400
Subject: [R] Can anyone please tell me how to strip the white spaces from a
	character vector?
Message-ID: <1db726800510250551q1878866dt2c0111238a796b0b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051025/62ad66e2/attachment.pl

From MSchwartz at mn.rr.com  Tue Oct 25 14:59:08 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Tue, 25 Oct 2005 07:59:08 -0500
Subject: [R] Basic: setting resolution and size of an R graphic
In-Reply-To: <39640.192.168.220.201.1130223463.squirrel@webmail.charite.de>
References: <64018.84.190.251.65.1130185968.squirrel@webmail.charite.de>
	<1130187237.4216.130.camel@localhost.localdomain>
	<39640.192.168.220.201.1130223463.squirrel@webmail.charite.de>
Message-ID: <1130245149.7026.18.camel@localhost.localdomain>

If you specifically need the plot to have a dimension measured in
pixels, then you need to use a bitmapped format such as png and specify
the output to be the size you require:

  png("test.png", width = 300, height = 300, ...)
  DoYourPlotHere()
  dev.off()

Do this directly using the png() device, rather than trying to convert
the image format, which almost always introduces "noise".

Since you are using a bitmapped format, you will experience the tradeoff
with respect to the image quality (ie. pixelated) as compared to a
vector based format such as PDF or PS.

I would re-verify the requirements for the journal to which you are
submitting the article relative to what they need for image specs. It
seems unusual for a journal to request an image in this fashion, unless
it is a photograph where a jpg format may be preferred or perhaps for
online publication on a web page.

HTH,

Marc Schwartz

On Tue, 2005-10-25 at 08:57 +0200, Dr. med. Peter Robinson wrote:
> Thanks Marc and Jim for the tips. The PDF file that I create with R looks
> about the same as the one you created. However, I need to get the graphic
> to be a certain size (300 pixels wide). I have been using the ImageMagick
> program to do so for other graphics:
> 
> convert test.pdf -resize 300x300 out.pdf
> 
> then out.pdf looks rather poor (pixelly). The original image is too big.
> ANy ideas?
> Thanks a lot,Peter
> 
> 
> Am Mo, 24.10.2005, 22:53, schrieb Marc Schwartz (via MN):
> > On Mon, 2005-10-24 at 22:32 +0200, Dr. med. Peter Robinson wrote:
> >
> >> Dear List,
> >>
> >>
> >> I am sorry if this perhaps a too basic question, but I have not found
> >> an answer in Google or in the R help system. I am trying to use R to do
> >> a very simple analysis of some data (RT-PCR and Western analysis) with a
> >>  T-test and
> >> to plot the results as a histogram with error bars. (I have pasted an
> >> example script at the bottom of this mail). In order to use this for
> >> publication, I would like to adjust the resolution and size of the final
> >> image. However, even using file types such as postscript or pdf that are
> >> vector based, I get rather bad-looking results with
> >>> pdf(file="test.pdf") source("script at bottom of mail") dev.off()
> >>
> >> using either pdf or postscript or jpg devices.
> >>
> >>
> >> Therefore I would like to ask the list, how to best produce a graphic
> >> from the script below that would fit into one column of a published
> >> article and have a high resolution (as eps, or failing that tiff or
> >> png)? Thanks in advance for any advice,
> >>
> >>
> >> Peter
> >>
> >
> > <Snip of code>
> >
> >
> > What OS are you on?
> >
> >
> > Running your example on FC4, I get the attached output for a pdf().
> >
> >
> > I suspect that on your OS, the height and width arguments are not
> > appropriate by default.
> >
> > Thus, you may need to adjust your pdf (or postscript) function call to
> > explicitly specify larger height and width arguments.
> >
> > Also note that to generate an EPS file, pay attention to the details
> > section of ?postscript, taking note of the 'onefile', 'horizontal' and
> > 'paper' arguments and settings.
> >
> >
> > Also, check with your journal to see if they specify dimensions for such
> > graphics so that you can abide by their specs if provided. If they are
> > using LaTeX, there are means of specifying and/or adjusting the height
> > and/or width specs in the code based upon proportions of various measures
> > (ie. \includegraphics[width=0.9\textwidth]{GraphicsFile.eps} ).
> >
> >
> > HTH,
> >
> >
> > Marc Schwartz
> >
> >
> >
>



From sdavis2 at mail.nih.gov  Tue Oct 25 15:03:14 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 25 Oct 2005 09:03:14 -0400
Subject: [R] Can anyone please tell me how to strip the white
	spaces	from a character vector?
In-Reply-To: <1db726800510250551q1878866dt2c0111238a796b0b@mail.gmail.com>
Message-ID: <BF83A552.11B02%sdavis2@mail.nih.gov>

On 10/25/05 8:51 AM, "roger bos" <roger.bos at gmail.com> wrote:

> for example:
>> a$tic[1:10]
> [1] "AIR " "ABCB " "ABXA " "ACMR " "ADCT " "ADEX "
> [7] "ABM " "AFCE " "AG " "ATG "
> Can anyone please tell me how to strip the white spaces from a$tic?
> Thanks,
> Roger
> 
> [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

See ?gsub.

gsub(' ','',a$tic)

Sean



From cgb at datanalytics.com  Tue Oct 25 15:01:03 2005
From: cgb at datanalytics.com (cgb@datanalytics.com)
Date: Tue, 25 Oct 2005 15:01:03 +0200
Subject: [R] Can anyone please tell me how to strip the white
	spaces	from a character vector?
In-Reply-To: <1db726800510250551q1878866dt2c0111238a796b0b@mail.gmail.com>
References: <1db726800510250551q1878866dt2c0111238a796b0b@mail.gmail.com>
Message-ID: <20051025150103.zs2stkj239nlco08@webmail.datanalytics.com>

Quoting roger bos <roger.bos at gmail.com>:

> for example:
>> a$tic[1:10]
> [1] "AIR " "ABCB " "ABXA " "ACMR " "ADCT " "ADEX "
> [7] "ABM " "AFCE " "AG " "ATG "
> Can anyone please tell me how to strip the white spaces from a$tic?
> Thanks,
> Roger
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

> a <- c("ab ", "cd", "ef ")
> gsub(" ", "", a)
[1] "ab" "cd" "ef"

Carlos J. Gil Bellosta
http://www.datanalytics.com



From MSchwartz at mn.rr.com  Tue Oct 25 15:06:02 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Tue, 25 Oct 2005 08:06:02 -0500
Subject: [R] Can anyone please tell me how to strip the white
	spaces	from a character vector?
In-Reply-To: <1db726800510250551q1878866dt2c0111238a796b0b@mail.gmail.com>
References: <1db726800510250551q1878866dt2c0111238a796b0b@mail.gmail.com>
Message-ID: <1130245563.7026.24.camel@localhost.localdomain>

On Tue, 2005-10-25 at 08:51 -0400, roger bos wrote:
> for example:
> > a$tic[1:10]
> [1] "AIR " "ABCB " "ABXA " "ACMR " "ADCT " "ADEX "
> [7] "ABM " "AFCE " "AG " "ATG "
>  Can anyone please tell me how to strip the white spaces from a$tic?
>  Thanks,
>  Roger

Roger, 

See the next to last set of examples in ?sub.

> a <- c("ABM ", "AFCE ", "AG ", "ATG ")
> a
[1] "ABM "  "AFCE " "AG "   "ATG "

> a.new <- sub(' +$', '', a)
> a.new
[1] "ABM"  "AFCE" "AG"   "ATG"


Also, if this data was generated using read.table() or one of it's
variants, note the use of the 'strip.white' argument in ?read.table.

HTH,

Marc Schwartz



From francoisromain at free.fr  Tue Oct 25 15:09:59 2005
From: francoisromain at free.fr (Romain Francois)
Date: Tue, 25 Oct 2005 15:09:59 +0200
Subject: [R] Can anyone please tell me how to strip the white spaces
 from a	character vector?
In-Reply-To: <1db726800510250551q1878866dt2c0111238a796b0b@mail.gmail.com>
References: <1db726800510250551q1878866dt2c0111238a796b0b@mail.gmail.com>
Message-ID: <435E2EA7.1080601@free.fr>

Le 25.10.2005 14:51, roger bos a ??crit :

>for example:
>  
>
>>a$tic[1:10]
>>    
>>
>[1] "AIR " "ABCB " "ABXA " "ACMR " "ADCT " "ADEX "
>[7] "ABM " "AFCE " "AG " "ATG "
> Can anyone please tell me how to strip the white spaces from a$tic?
> Thanks,
> Roger
>  
>
gsub(' ','',a$tic)

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+



From roger.bos at gmail.com  Tue Oct 25 15:08:09 2005
From: roger.bos at gmail.com (roger bos)
Date: Tue, 25 Oct 2005 09:08:09 -0400
Subject: [R] Can anyone please tell me how to strip the white spaces
	from a character vector?
In-Reply-To: <1130245563.7026.24.camel@localhost.localdomain>
References: <1db726800510250551q1878866dt2c0111238a796b0b@mail.gmail.com>
	<1130245563.7026.24.camel@localhost.localdomain>
Message-ID: <1db726800510250608v66419a9fi899df1b6fe7d9b73@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051025/09147e34/attachment.pl

From wuming.gong at gmail.com  Tue Oct 25 15:10:12 2005
From: wuming.gong at gmail.com (Wuming Gong)
Date: Tue, 25 Oct 2005 21:10:12 +0800
Subject: [R] Can anyone please tell me how to strip the white spaces
	from a character vector?
In-Reply-To: <1db726800510250551q1878866dt2c0111238a796b0b@mail.gmail.com>
References: <1db726800510250551q1878866dt2c0111238a796b0b@mail.gmail.com>
Message-ID: <b428d06d0510250610k54b757f5n4c5e1366ba1a428a@mail.gmail.com>

Try trim() in gdata package.

Wuming

On 10/25/05, roger bos <roger.bos at gmail.com> wrote:
> for example:
> > a$tic[1:10]
> [1] "AIR " "ABCB " "ABXA " "ACMR " "ADCT " "ADEX "
> [7] "ABM " "AFCE " "AG " "ATG "
>  Can anyone please tell me how to strip the white spaces from a$tic?
>  Thanks,
>  Roger
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From dimitris.rizopoulos at med.kuleuven.be  Tue Oct 25 15:14:39 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Tue, 25 Oct 2005 15:14:39 +0200
Subject: [R] Can anyone please tell me how to strip the white spaces
	from acharacter vector?
References: <1db726800510250551q1878866dt2c0111238a796b0b@mail.gmail.com>
Message-ID: <01b201c5d966$0e0e0aa0$0540210a@www.domain>

one way is to use strsplit(), i.e.,

xx <- c("AIR ", "ABCB ", "ABXA ", "ACMR ", "ADCT ", "ADEX ")
unlist(strsplit(xx, " "))

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "roger bos" <roger.bos at gmail.com>
To: "(r-help at stat.math.ethz.ch.)" <R-help at stat.math.ethz.ch>
Sent: Tuesday, October 25, 2005 2:51 PM
Subject: [R] Can anyone please tell me how to strip the white spaces 
from acharacter vector?


> for example:
>> a$tic[1:10]
> [1] "AIR " "ABCB " "ABXA " "ACMR " "ADCT " "ADEX "
> [7] "ABM " "AFCE " "AG " "ATG "
> Can anyone please tell me how to strip the white spaces from a$tic?
> Thanks,
> Roger
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From ligges at statistik.uni-dortmund.de  Tue Oct 25 15:14:17 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 25 Oct 2005 15:14:17 +0200
Subject: [R] Can anyone please tell me how to strip the white spaces
 from a	character vector?
In-Reply-To: <1db726800510250551q1878866dt2c0111238a796b0b@mail.gmail.com>
References: <1db726800510250551q1878866dt2c0111238a796b0b@mail.gmail.com>
Message-ID: <435E2FA9.5070307@statistik.uni-dortmund.de>

roger bos wrote:

> for example:
> 
>>a$tic[1:10]
> 
> [1] "AIR " "ABCB " "ABXA " "ACMR " "ADCT " "ADEX "
> [7] "ABM " "AFCE " "AG " "ATG "
>  Can anyone please tell me how to strip the white spaces from a$tic?


Not beeing an expert for regular expressions, I'd try
    sub(" *$", "", sub("^ *", "", a$tic))
to strip from beginnings and ends but there may be far better approches.
In order to remove *all* blanks, try
    gsub(" ", "", a$tic)

Uwe Ligges


>  Thanks,
>  Roger
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ktiwari at bgc-jena.mpg.de  Tue Oct 25 15:14:33 2005
From: ktiwari at bgc-jena.mpg.de (Yogesh K. Tiwari)
Date: Tue, 25 Oct 2005 15:14:33 +0200
Subject: [R] how to increase the font size of axis  data
Message-ID: <435E2FB9.8000606@bgc-jena.mpg.de>

Hello R Users,

I am a new user to R.

When we make a simple plot then how to
increase the font size of the data at the
each axis.

Many thanks,

Kind regards,
Yogesh
-- 

===========================================
Yogesh Tiwari,
Max-Planck Institute for Biogeochemistry,
Hans-Knoell Strasse 10,
D-07745 Jena,
Germany

Office   : 0049 3641 576 376
Home     : 0049 3641 223 163
Fax      : 0049 3641 577 300
Cell     : 0049 1520 4591 008
e-mail   : yogesh.tiwari at bgc-jena.mpg.de



From ktiwari at bgc-jena.mpg.de  Tue Oct 25 15:19:33 2005
From: ktiwari at bgc-jena.mpg.de (Yogesh K. Tiwari)
Date: Tue, 25 Oct 2005 15:19:33 +0200
Subject: [R] how we can save the data computed in R
Message-ID: <435E30E5.5020202@bgc-jena.mpg.de>

Hello R Users,

How we can save any data which is computed in
side R . For example I am fitting a fourth
harmonic function on any time series data. We
can plot this function on each other with
timeseres data in R but suppose I want to
save this fitted function values as one
column  then how to do it.

Many thanks in advance,

Regards,
Yogesh

-- 

===========================================
Yogesh Tiwari,
Max-Planck Institute for Biogeochemistry,
Hans-Knoell Strasse 10,
D-07745 Jena,
Germany

Office   : 0049 3641 576 376
Home     : 0049 3641 223 163
Fax      : 0049 3641 577 300
Cell     : 0049 1520 4591 008
e-mail   : yogesh.tiwari at bgc-jena.mpg.de



From francoisromain at free.fr  Tue Oct 25 15:24:39 2005
From: francoisromain at free.fr (Romain Francois)
Date: Tue, 25 Oct 2005 15:24:39 +0200
Subject: [R] Basic: setting resolution and size of an R graphic
In-Reply-To: <1130245149.7026.18.camel@localhost.localdomain>
References: <64018.84.190.251.65.1130185968.squirrel@webmail.charite.de>	<1130187237.4216.130.camel@localhost.localdomain>	<39640.192.168.220.201.1130223463.squirrel@webmail.charite.de>
	<1130245149.7026.18.camel@localhost.localdomain>
Message-ID: <435E3217.8020605@free.fr>

Le 25.10.2005 14:59, Marc Schwartz a ??crit :

>If you specifically need the plot to have a dimension measured in
>pixels, then you need to use a bitmapped format such as png and specify
>the output to be the size you require:
>
>  png("test.png", width = 300, height = 300, ...)
>  DoYourPlotHere()
>  dev.off()
>
>Do this directly using the png() device, rather than trying to convert
>the image format, which almost always introduces "noise".
>
>Since you are using a bitmapped format, you will experience the tradeoff
>with respect to the image quality (ie. pixelated) as compared to a
>vector based format such as PDF or PS.
>
>I would re-verify the requirements for the journal to which you are
>submitting the article relative to what they need for image specs. It
>seems unusual for a journal to request an image in this fashion, unless
>it is a photograph where a jpg format may be preferred or perhaps for
>online publication on a web page.
>
>HTH,
>
>Marc Schwartz
>  
>
Hi folks,

I just would like to highlight the argument 'pointsize' of the png 
function.
For graphics in RGG i use pointsize=4 and i'm happy with it.

Romain

>On Tue, 2005-10-25 at 08:57 +0200, Dr. med. Peter Robinson wrote:
>  
>
>>Thanks Marc and Jim for the tips. The PDF file that I create with R looks
>>about the same as the one you created. However, I need to get the graphic
>>to be a certain size (300 pixels wide). I have been using the ImageMagick
>>program to do so for other graphics:
>>
>>convert test.pdf -resize 300x300 out.pdf
>>
>>then out.pdf looks rather poor (pixelly). The original image is too big.
>>ANy ideas?
>>Thanks a lot,Peter
>>
>>
>>Am Mo, 24.10.2005, 22:53, schrieb Marc Schwartz (via MN):
>>    
>>
>>>On Mon, 2005-10-24 at 22:32 +0200, Dr. med. Peter Robinson wrote:
>>>
>>>      
>>>
>>>>Dear List,
>>>>
>>>>
>>>>I am sorry if this perhaps a too basic question, but I have not found
>>>>an answer in Google or in the R help system. I am trying to use R to do
>>>>a very simple analysis of some data (RT-PCR and Western analysis) with a
>>>> T-test and
>>>>to plot the results as a histogram with error bars. (I have pasted an
>>>>example script at the bottom of this mail). In order to use this for
>>>>publication, I would like to adjust the resolution and size of the final
>>>>image. However, even using file types such as postscript or pdf that are
>>>>vector based, I get rather bad-looking results with
>>>>        
>>>>
>>>>>pdf(file="test.pdf") source("script at bottom of mail") dev.off()
>>>>>          
>>>>>
>>>>using either pdf or postscript or jpg devices.
>>>>
>>>>
>>>>Therefore I would like to ask the list, how to best produce a graphic
>>>>from the script below that would fit into one column of a published
>>>>article and have a high resolution (as eps, or failing that tiff or
>>>>png)? Thanks in advance for any advice,
>>>>
>>>>
>>>>Peter
>>>>
>>>>        
>>>>
>>><Snip of code>
>>>
>>>
>>>What OS are you on?
>>>
>>>
>>>Running your example on FC4, I get the attached output for a pdf().
>>>
>>>
>>>I suspect that on your OS, the height and width arguments are not
>>>appropriate by default.
>>>
>>>Thus, you may need to adjust your pdf (or postscript) function call to
>>>explicitly specify larger height and width arguments.
>>>
>>>Also note that to generate an EPS file, pay attention to the details
>>>section of ?postscript, taking note of the 'onefile', 'horizontal' and
>>>'paper' arguments and settings.
>>>
>>>
>>>Also, check with your journal to see if they specify dimensions for such
>>>graphics so that you can abide by their specs if provided. If they are
>>>using LaTeX, there are means of specifying and/or adjusting the height
>>>and/or width specs in the code based upon proportions of various measures
>>>(ie. \includegraphics[width=0.9\textwidth]{GraphicsFile.eps} ).
>>>
>>>
>>>HTH,
>>>
>>>
>>>Marc Schwartz
>>>      
>>>


-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+



From Cameron.Guenther at MyFWC.com  Tue Oct 25 15:28:57 2005
From: Cameron.Guenther at MyFWC.com (Guenther, Cameron)
Date: Tue, 25 Oct 2005 09:28:57 -0400
Subject: [R]  file size limit for importing SAS file
Message-ID: <BA6FF017E924044A9BF748AFAEEA6F304C8630@FWC-TLEX3.fwc.state.fl.us>

Does anyone know if there is a file size limit for inputting a SAS data
set?  The file size I am trying to import is 184 MB.
The code is:

>library("foreign")   
>  
> sashome<-"C:/Program Files/SAS Institute/SAS/V8"
> input.data<-read.ssd( file.path("G:/DATA/Cam/ECPATH/FIM"),"tbm_c", 
+        sascmd=file.path(sashome,"sas.exe") ) 

The return message is:

SAS failed.  SAS program at
C:\DOCUME~1\CAMERO~1.GUE\LOCALS~1\Temp\Rtmp17498\file11436.sas 
The log file will be file11436.log in the current directory
Warning message:
SAS return code was 2 in: read.ssd(file.path("G:/DATA/Cam/ECPATH/FIM"),
"tbm_c", sascmd = file.path(sashome,  
> 

Cameron Guenther 
Associate Research Scientist
FWC/FWRI, Marine Fisheries Research
100 8th Avenue S.E.
St. Petersburg, FL 33701
(727)896-8626 Ext. 4305
cameron.guenther at myfwc.com



From gregory.r.warnes at pfizer.com  Tue Oct 25 15:32:19 2005
From: gregory.r.warnes at pfizer.com (Warnes, Gregory R)
Date: Tue, 25 Oct 2005 09:32:19 -0400
Subject: [R] Can anyone please tell me how to strip the white spaces
	f	rom a character vector?
Message-ID: <915D2D65A9986440A277AC5C98AA466F0186351A@groamrexm02.amer.pfizer.com>


If you are interested in trimming leading and trailing whitespace (and not
interior whitespace), you can use the 'trim' function from the 'gdata'
package.

-G


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of roger bos
> Sent: Tuesday, October 25, 2005 8:52 AM
> To: (r-help at stat.math.ethz.ch.)
> Subject: [R] Can anyone please tell me how to strip the white spaces
> from a character vector?
> 
> 
> for example:
> > a$tic[1:10]
> [1] "AIR " "ABCB " "ABXA " "ACMR " "ADCT " "ADEX "
> [7] "ABM " "AFCE " "AG " "ATG "
>  Can anyone please tell me how to strip the white spaces from a$tic?
>  Thanks,
>  Roger
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From ManuelPerera-Chang at fmc-ag.com  Tue Oct 25 16:13:58 2005
From: ManuelPerera-Chang at fmc-ag.com (ManuelPerera-Chang@fmc-ag.com)
Date: Tue, 25 Oct 2005 16:13:58 +0200
Subject: [R] query on xtable output
Message-ID: <OF5198C877.C687789C-ONC12570A5.0046CFC0-C12570A5.004E2F64@notes.fresenius.de>





Dear all,
I am exporting to latex a matrix via xtable. My matrix includes e.g. 4 rows
and 4 columns. The first two rows containing real values(e.g. a laboratory
parameter's mean value), and the two rows at the bottom containing only
integers (number of cases).

>
mymat<-matrix(c(c(10.52,2.52,12.35,3.63),c(3.52,16.25,13.62,6.36),c(11,12,15,16),c(14,15,16,18)),4,4,byrow=TRUE)
> mymat
      [,1]  [,2]  [,3]  [,4]
[1,] 10.52  2.52 12.35  3.63
[2,]  3.52  6.25  3.62  6.36
[3,] 11.00 12.00 15.00 16.00
[4,] 14.00 15.00 16.00 18.00

>
trend_table<-xtable(mymat,caption="Caption",display=c('s','fg','fg','fg','fg'),size='small')

The R help on xtable states that "fg" displays 'digits' as number of
_significant_ digits. As a result no decimal places are shown in the last
two rows, as I wanted, but no decimal places are shown neither in the first
two rows, if the real value in the cell is greater than 10, and only 1
decimal place if the value in the cell is lower than 10.

Thus I got the following Latex output: ...

> trend_table

\begin{table}[ht]
\begin{center}
\begin{tabular}{rrrrr}
\hline
 & 1 & 2 & 3 & 4 \\
\hline
1 &  11 & 2.5 &  12 & 3.6 \\  I would like to have more decimal places here
e.g. 10.5 or 10.52 instead of 11.
2 & 3.5 &  16 &  14 & 6.4 \\
3 &  11 &  12 &  15 &  16 \\ This is what I expect, no commas and decimal
0-s for the number of cases.
4 &  14 &  15 &  16 &  18 \\
\hline
\end{tabular}
\caption{Caption}
\end{center}
\end{table}

 I would prefer to show 1 additional decimal  in both cases.

Thus my question is how to modify the setting for _significant_ digits(in
xtable??) in order to print the correctly formated values.

Sorry for reposting my question, ...

Thank you

Manuel



From ManuelPerera-Chang at fmc-ag.com  Tue Oct 25 16:34:04 2005
From: ManuelPerera-Chang at fmc-ag.com (ManuelPerera-Chang@fmc-ag.com)
Date: Tue, 25 Oct 2005 16:34:04 +0200
Subject: [R] how to increase the font size of axis  data
Message-ID: <OFAA197F00.BF324643-ONC12570A5.004ED1C1-C12570A5.00500652@notes.fresenius.de>





Hi Yogesh,

try modifying the graphical parameters like
> par(cex=2,cex.axis=1.2)
for graphs in base:

or for e.g. trellis graphs in the "lattice" package the trellis parameter??s
(try  ?trellis.par.get)

axis.text <- trellis.par.get("axis.text")
axis.text$cex <- 3.2
trellis.par.set("axis.text", axis.text)

BR,

Manuel


                                                                                                                                           
                      "Yogesh K. Tiwari"                                                                                                   
                      <ktiwari at bgc-jena.mpg        To:       r-help at stat.math.ethz.ch                                                      
                      .de>                         cc:                                                                                     
                      Sent by:                     Subject:  [R] how to increase the font size of axis  data                               
                      r-help-bounces at stat.m                                                                                                
                      ath.ethz.ch                                                                                                          
                                                                                                                                           
                                                                                                                                           
                      25.10.2005 15:14                                                                                                     
                                                                                                                                           
                                                                                                                                           




Hello R Users,

I am a new user to R.

When we make a simple plot then how to
increase the font size of the data at the
each axis.

Many thanks,

Kind regards,
Yogesh
--

===========================================
Yogesh Tiwari,
Max-Planck Institute for Biogeochemistry,
Hans-Knoell Strasse 10,
D-07745 Jena,
Germany

Office   : 0049 3641 576 376
Home     : 0049 3641 223 163
Fax      : 0049 3641 577 300
Cell     : 0049 1520 4591 008
e-mail   : yogesh.tiwari at bgc-jena.mpg.de

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From stecalza at tiscali.it  Tue Oct 25 16:42:27 2005
From: stecalza at tiscali.it (Stefano Calza)
Date: Tue, 25 Oct 2005 16:42:27 +0200
Subject: [R] Can anyone please tell me how to strip the white spaces
	from acharacter vector?
In-Reply-To: <01b201c5d966$0e0e0aa0$0540210a@www.domain>
References: <1db726800510250551q1878866dt2c0111238a796b0b@mail.gmail.com>
	<01b201c5d966$0e0e0aa0$0540210a@www.domain>
Message-ID: <20051025144227.GA11097@med.unibs.it>

What about

xx <- c("AIR ", "ABCB ", "ABXA ", "ACMR ", "ADCT ", "ADEX ","  AAA")

xx=gsub("[[:blank:]]","",xx)

Stefano

On Tue, Oct 25, 2005 at 03:14:39PM +0200, Dimitris Rizopoulos wrote:
<Dimitris>one way is to use strsplit(), i.e.,
<Dimitris>
<Dimitris>xx <- c("AIR ", "ABCB ", "ABXA ", "ACMR ", "ADCT ", "ADEX ")
<Dimitris>
<Dimitris>Best,
<Dimitris>Dimitris
<Dimitris>
<Dimitris>----
<Dimitris>Dimitris Rizopoulos
<Dimitris>Ph.D. Student
<Dimitris>Biostatistical Centre
<Dimitris>School of Public Health
<Dimitris>Catholic University of Leuven
<Dimitris>
<Dimitris>Address: Kapucijnenvoer 35, Leuven, Belgium
<Dimitris>Tel: +32/(0)16/336899
<Dimitris>Fax: +32/(0)16/337015
<Dimitris>Web: http://www.med.kuleuven.be/biostat/
<Dimitris>     http://www.student.kuleuven.be/~m0390867/dimitris.htm
<Dimitris>
<Dimitris>
<Dimitris>----- Original Message ----- 
<Dimitris>From: "roger bos" <roger.bos at gmail.com>
<Dimitris>To: "(r-help at stat.math.ethz.ch.)" <R-help at stat.math.ethz.ch>
<Dimitris>Sent: Tuesday, October 25, 2005 2:51 PM
<Dimitris>Subject: [R] Can anyone please tell me how to strip the white spaces 
<Dimitris>from acharacter vector?
<Dimitris>
<Dimitris>
<Dimitris>> for example:
<Dimitris>>> a$tic[1:10]
<Dimitris>> [1] "AIR " "ABCB " "ABXA " "ACMR " "ADCT " "ADEX "
<Dimitris>> [7] "ABM " "AFCE " "AG " "ATG "
<Dimitris>> Can anyone please tell me how to strip the white spaces from a$tic?
<Dimitris>> Thanks,
<Dimitris>> Roger
<Dimitris>>
<Dimitris>> [[alternative HTML version deleted]]
<Dimitris>>
<Dimitris>> ______________________________________________
<Dimitris>> R-help at stat.math.ethz.ch mailing list
<Dimitris>> https://stat.ethz.ch/mailman/listinfo/r-help
<Dimitris>> PLEASE do read the posting guide! 
<Dimitris>> http://www.R-project.org/posting-guide.html
<Dimitris>> 
<Dimitris>
<Dimitris>
<Dimitris>Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm
<Dimitris>
<Dimitris>______________________________________________
<Dimitris>R-help at stat.math.ethz.ch mailing list
<Dimitris>https://stat.ethz.ch/mailman/listinfo/r-help
<Dimitris>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From dimitrijoe at ipea.gov.br  Tue Oct 25 16:47:47 2005
From: dimitrijoe at ipea.gov.br (Dimitri Szerman)
Date: Tue, 25 Oct 2005 12:47:47 -0200
Subject: [R] Inf in regressions
Message-ID: <018401c5d973$13c39b60$5814020a@thesahajamach>

Hi,

Suppose I I wish to run

lm( y ~ x + z + log(w) )

where w assumes non-negative values. A problem arises when w=0, as log(0) 
= -Inf, and R doesn't accept that (as it "accepts" NA). Is there a way to 
tell R to do with -Inf the same it does with NA, i.e, to ignore it? ( 
Otherwise I have to do something like

w[w==0] <- NA

which doesn't hurt, but might be a bit incovenient sometimes.)

Thanks in advance.

Dimitri



From jukka.ruohonen at helsinki.fi  Tue Oct 25 16:57:07 2005
From: jukka.ruohonen at helsinki.fi (jukka ruohonen)
Date: Tue, 25 Oct 2005 17:57:07 +0300
Subject: [R] panel data unit root tests
Message-ID: <1130252227.435e47c38ed56@www2.helsinki.fi>

Thanks, that will certainly do the trick. I came across systemfit and sem -
packages that are useful in this respect as well.

Jukka Ruohonen
University of Helsinki


> Have you received a reply?  I haven't seen one.  RSiteSearch("panel 
> data unit root test") produced another question on this but no answers 
> that I saw.  RSiteSearch("unit root test") produced 75 hits with many 
> useful.  RSiteSearch("panel data analysis") produced 75 hits, the first 
> of which suggested the nlme package 
> (http://finzi.psych.upenn.edu/R/Rhelp02a/archive/26962.html).  You could
> construct nested models to compare the corAR1 correlation structure with
> first differences.
> 
> 	  hope this helps.
> 	  spencer graves
> 
> jukka ruohonen wrote:
> 
> > Hi,
> > 
> > The question is as follows: has anyone coded panel data unit root tests
> 
> > with R? Even the "first generation" tests (see e.g. Levin & Lin 1993; 
> > Pesaran, & Smith & Im 1996; Maddala & Wu 1999) would be sufficient for
> > my needs. To my understanding, these are rather easy to code, but as I
> > have taken just my first steps in coding with R, existing code would 
> > save me from a lot of trouble & time.
> > 
> > 
> > With regards,
> > 
> > Jukka Ruohonen
> > University of Helsinki
> > 
> > 
> > References:
> > 
> > Levin, A. & Lin, C.F. (1993): Unit Root Tests in Panel Data. 
> > ftp://weber.ucsd.edu/pub/econlib/dpapers/ucsd9356.pdf
> > 
> > Maddala, G.S. & Wu, S. (1999): A Comparative Study of Unit Roots Tests
> with 
> > Panel Data and a New Simple Test. Oxford Bulleting of Economics and 
> > Statistics. Special Issue 61, 631-652.
> > 
> > Pesaran, M.H. & Smith, R. & Im, K.S. (1996): Dynamic Linear Models for
> 
> > Heterogenous Panels. In: Matyas, L. & Sevestre, P. (eds.): The
> Econometrics 
> > of Panel Data: a Handbook of the Theory with Applications, second
> edition, 
> > pp. 145-195.
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> -- 
> Spencer Graves, PhD
> Senior Development Engineer
> PDF Solutions, Inc.
> 333 West San Carlos Street Suite 700
> San Jose, CA 95110, USA
> 
> spencer.graves at pdf.com
> www.pdf.com <http://www.pdf.com>
> Tel:  408-938-4420
> Fax: 408-280-7915



From dimitris.rizopoulos at med.kuleuven.be  Tue Oct 25 17:04:20 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Tue, 25 Oct 2005 17:04:20 +0200
Subject: [R] Inf in regressions
References: <018401c5d973$13c39b60$5814020a@thesahajamach>
Message-ID: <01fe01c5d975$60d044b0$0540210a@www.domain>

you could use:

lm( y ~ x + z + log(w), subset = w > 0)


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Dimitri Szerman" <dimitrijoe at ipea.gov.br>
To: "R-Help" <r-help at stat.math.ethz.ch>
Sent: Tuesday, October 25, 2005 4:47 PM
Subject: [R] Inf in regressions


> Hi,
>
> Suppose I I wish to run
>
> lm( y ~ x + z + log(w) )
>
> where w assumes non-negative values. A problem arises when w=0, as 
> log(0)
> = -Inf, and R doesn't accept that (as it "accepts" NA). Is there a 
> way to
> tell R to do with -Inf the same it does with NA, i.e, to ignore it? 
> (
> Otherwise I have to do something like
>
> w[w==0] <- NA
>
> which doesn't hurt, but might be a bit incovenient sometimes.)
>
> Thanks in advance.
>
> Dimitri
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From Patrick.Kuss at unibas.ch  Tue Oct 25 17:28:33 2005
From: Patrick.Kuss at unibas.ch (Patrick Kuss)
Date: Tue, 25 Oct 2005 17:28:33 +0200
Subject: [R] running AMOVA from spreadsheet genotype data
Message-ID: <1130254113.435e4f21534cb@webmail.unibas.ch>

Hi,

I plan to run amova in R from randomly generated subsets of my original dataset.
The structure of my data looks as below:

region <- rep(c("east","west"),each=8)
pop <- c(rep(1:4,each=4))
ind <- c(rep(1:4,4))
l.1 <- c(1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0)
l.2 <- sample(c(0,1),16,replace=T)
l.3 <- sample(c(0,1),16,replace=T)
l.4 <- sample(c(0,1),16,replace=T)
l.5 <- sample(c(0,1),16,replace=T)
l.6 <- sample(c(0,1),16,replace=T)
data <- data.frame(region,pop,ind,l.1,l.2,l.3,l.4,l.5,l.6)
data

Is there an easy way to generate amova style $samples, $distances, $structures
data.frames from my data subset?

Cheers

Patrick

--
Patrick Kuss
PhD-student
Institute of Botany
University of Basel
Sch??nbeinstr. 6
CH-4056 Basel
+41 61 267 2976



From ripley at stats.ox.ac.uk  Tue Oct 25 17:37:01 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 25 Oct 2005 16:37:01 +0100 (BST)
Subject: [R] Inf in regressions
In-Reply-To: <018401c5d973$13c39b60$5814020a@thesahajamach>
References: <018401c5d973$13c39b60$5814020a@thesahajamach>
Message-ID: <Pine.LNX.4.61.0510251632540.17539@gannet.stats>

Actually, R does not accept NA.  First, the action is from lm and not from 
the R base, and second, NAs are in fact deleted and not accepted.

Function lm() has a na.action argument which is by default na.omit.  You 
could easily make na_and_inf.omit and use it. You could also use
subset=(w > 0). The help pages are your friends here.

On Tue, 25 Oct 2005, Dimitri Szerman wrote:

> Suppose I I wish to run
>
> lm( y ~ x + z + log(w) )
>
> where w assumes non-negative values. A problem arises when w=0, as log(0)
> = -Inf, and R doesn't accept that (as it "accepts" NA). Is there a way to
> tell R to do with -Inf the same it does with NA, i.e, to ignore it? (
> Otherwise I have to do something like
>
> w[w==0] <- NA
>
> which doesn't hurt, but might be a bit incovenient sometimes.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Patrick.Kuss at unibas.ch  Tue Oct 25 17:53:53 2005
From: Patrick.Kuss at unibas.ch (Patrick Kuss)
Date: Tue, 25 Oct 2005 17:53:53 +0200
Subject: [R] running AMOVA from spreadsheet genotype data
Message-ID: <1130255633.435e5511e3834@webmail.unibas.ch>



----- Weitergeleitete Nachricht von Patrick Kuss <kuss at igor.urz.unibas.ch> -----
    Datum: Tue, 25 Oct 2005 17:28:33 +0200
    Von: Patrick Kuss <kuss at igor.urz.unibas.ch>
Antwort an: Patrick Kuss <kuss at igor.urz.unibas.ch>
 Betreff: running AMOVA from spreadsheet genotype data
      An: r-help at lists.R-project.org

Hi,

I plan to run AMOVA in R from randomly generated subsets of my original dataset.
The structure of my data looks as below:

region <- rep(c("east","west"),each=8)
pop <- c(rep(1:4,each=4))
ind <- c(rep(1:4,4))
l.1 <- c(1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0)
l.2 <- sample(c(0,1),16,replace=T)
l.3 <- sample(c(0,1),16,replace=T)
l.4 <- sample(c(0,1),16,replace=T)
l.5 <- sample(c(0,1),16,replace=T)
l.6 <- sample(c(0,1),16,replace=T)
data <- data.frame(region,pop,ind,l.1,l.2,l.3,l.4,l.5,l.6)
data

Is there an easy way to generate amova style $samples, $distances, $structures
data.frames from my data subset?

Cheers

Patrick

--
Patrick Kuss
PhD-student
Institute of Botany
University of Basel
Sch??nbeinstr. 6
CH-4056 Basel
+41 61 267 2976

----------------------------------------------------------------


----- Ende der weitergeleiteten Nachricht -----


--
Patrick Kuss
PhD-student
Institute of Botany
University of Basel
Sch??nbeinstr. 6
CH-4056 Basel
+41 61 267 2976



From p.dalgaard at biostat.ku.dk  Tue Oct 25 17:56:37 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 25 Oct 2005 17:56:37 +0200
Subject: [R] file size limit for importing SAS file
In-Reply-To: <BA6FF017E924044A9BF748AFAEEA6F304C8630@FWC-TLEX3.fwc.state.fl.us>
References: <BA6FF017E924044A9BF748AFAEEA6F304C8630@FWC-TLEX3.fwc.state.fl.us>
Message-ID: <x264rlvbd6.fsf@viggo.kubism.ku.dk>

"Guenther, Cameron" <Cameron.Guenther at myfwc.com> writes:

> Does anyone know if there is a file size limit for inputting a SAS data
> set?  The file size I am trying to import is 184 MB.
> The code is:
> 
> >library("foreign")   
> >  
> > sashome<-"C:/Program Files/SAS Institute/SAS/V8"
> > input.data<-read.ssd( file.path("G:/DATA/Cam/ECPATH/FIM"),"tbm_c", 
> +        sascmd=file.path(sashome,"sas.exe") ) 
> 
> The return message is:
> 
> SAS failed.  SAS program at
> C:\DOCUME~1\CAMERO~1.GUE\LOCALS~1\Temp\Rtmp17498\file11436.sas 
> The log file will be file11436.log in the current directory
> Warning message:
> SAS return code was 2 in: read.ssd(file.path("G:/DATA/Cam/ECPATH/FIM"),
> "tbm_c", sascmd = file.path(sashome,  
> > 

Well, the error says that SAS failed and that step should be quite
immune to size limitations. So what is inside that log file? 

This part looks dodgy:

...file.path("G:/DATA/Cam/ECPATH/FIM"),"tbm_c",...

Should "tbm_c" be inside the parens?

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From shaffer.jonathan at gmail.com  Tue Oct 25 17:59:14 2005
From: shaffer.jonathan at gmail.com (Jonathan Shaffer)
Date: Tue, 25 Oct 2005 11:59:14 -0400
Subject: [R] Syntax Question
Message-ID: <734eb1ff0510250859m2739f720lbb70ddcd4131421e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051025/e7193f60/attachment.pl

From gunter.berton at gene.com  Tue Oct 25 18:08:48 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Tue, 25 Oct 2005 09:08:48 -0700
Subject: [R] Syntax Question
In-Reply-To: <734eb1ff0510250859m2739f720lbb70ddcd4131421e@mail.gmail.com>
Message-ID: <200510251608.j9PG8mDQ012333@volta.gene.com>

Sounds like you need to debug the software yourself. ?traceback  ?browser
may help. See also Mark Bravington's debug package on CRAN.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Jonathan Shaffer
> Sent: Tuesday, October 25, 2005 8:59 AM
> To: R-help at stat.math.ethz.ch
> Subject: [R] Syntax Question
> 
> Hello,
>   I'm having some difficulty running Niels Waller's Maxcov 
> Hitmax program in
> the R console, and I was hoping you could provide me with 
> some assistance.
> When I attempt to run the analysis I receive the following message:
>   Indicators 1 3 & 2Error in if (del == 0 && to == 0) return(to) :
> missing value where TRUE/FALSE needed
>  I contacted Dr. Waller regarding this question but he was 
> unable to help
> me. Do you have any suggestions regarding how to overcome 
> this problem?
> Thank you for your time and consideration.
>  Best,
> Jonathan Shaffer
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From chrysopa at gmail.com  Tue Oct 25 18:21:20 2005
From: chrysopa at gmail.com (Ronaldo Reis-Jr.)
Date: Tue, 25 Oct 2005 14:21:20 -0200
Subject: [R] lme and lmer syntax
In-Reply-To: <F5ED48890E2ACB468D0F3A64989D335ACDC1F0@dc1ex3.air.org>
References: <F5ED48890E2ACB468D0F3A64989D335ACDC1F0@dc1ex3.air.org>
Message-ID: <200510251421.20756.chrysopa@gmail.com>

Em Seg 24 Out 2005 18:08, Doran, Harold escreveu:
> Ronaldo
>
> See the article on lmer pasted below for syntax. It is the only current
> source documenting the code. In lmer(), the nesting structure for the
> ranmdom effects is handled in a slightly different way. If your
> observations are nested as you note, then you can use
>
> > lmer(y~x1 + x2 +(1|x1) + (1|x2), data)
>
> @Article{Rnews:Bates:2005,
>   author       = {Douglas Bates},
>   title	       = {Fitting Linear Mixed Models in {R}},
>   journal      = {R News},
>   year	       = 2005,
>   volume       = 5,
>   number       = 1,
>   pages	       = {27--30},
>   month	       = {May},
>   url	       = {http://CRAN.R-project.org/doc/Rnews/},
> }
>

Hi,

I try this with a splitsplitplot example.

I make the correct model with aov, lme do compare with lmer.

But I cant make a correct model in lmer. Look that the aov and lme results are 
similars, but very different from lmer. In aov and lme is used the correct DF 
for each variable, in lmer it use a same DF for all? Denom=54.

What is my mistake?

Thanks
Ronaldo

----- Begin of example ------

> summary(splitplot)
     yield        block      irrigation   density   fertilizer
 Min.   : 60.00   A:18   control  :36   high  :24   N :24     
 1st Qu.: 86.00   B:18   irrigated:36   low   :24   NP:24     
 Median : 95.00   C:18                  medium:24   P :24     
 Mean   : 99.72   D:18                                        
 3rd Qu.:114.00                                               
 Max.   :136.00                                               
> 
> attach(splitplot)
> 
> m.aov <- 
aov(yield~irrigation*density*fertilizer+Error(block/irrigation/density/fertilizer))
> 
> summary(m.aov)

Error: block
          Df  Sum Sq Mean Sq F value Pr(>F)
Residuals  3 194.444  64.815               

Error: block:irrigation
           Df Sum Sq Mean Sq F value  Pr(>F)  
irrigation  1 8277.6  8277.6  17.590 0.02473 *
Residuals   3 1411.8   470.6                  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Error: block:irrigation:density
                   Df  Sum Sq Mean Sq F value  Pr(>F)  
density             2 1758.36  879.18  3.7842 0.05318 .
irrigation:density  2 2747.03 1373.51  5.9119 0.01633 *
Residuals          12 2787.94  232.33                  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Error: block:irrigation:density:fertilizer
                              Df  Sum Sq Mean Sq F value    Pr(>F)    
fertilizer                     2 1977.44  988.72 11.4493 0.0001418 ***
irrigation:fertilizer          2  953.44  476.72  5.5204 0.0081078 ** 
density:fertilizer             4  304.89   76.22  0.8826 0.4840526    
irrigation:density:fertilizer  4  234.72   58.68  0.6795 0.6106672    
Residuals                     36 3108.83   86.36                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
> 
> library(nlme)
> 
> m.lme <- lme(yield~irrigation*density*fertilizer,random=~1|
block/irrigation/density/fertilizer)
> 
> anova(m.lme)
                              numDF denDF   F-value p-value
(Intercept)                       1    36 2683.2245  <.0001
irrigation                        1     3   31.0269  0.0114
density                           2    12    3.7780  0.0534
fertilizer                        2    36   11.4490  0.0001
irrigation:density                2    12    5.9023  0.0164
irrigation:fertilizer             2    36    5.5203  0.0081
density:fertilizer                4    36    0.8826  0.4841
irrigation:density:fertilizer     4    36    0.6795  0.6107
> 
> library(lme4)
Loading required package: Matrix
Loading required package: lattice
> 
> g1 <- block:irrigation
> g2 <- block:irrigation:density
> g3 <- block:irrigation:density:fertilizer
> 
> m.lmer <- lmer(yield~irrigation*density*fertilizer+(1|g1)+(1|g2)+(1|g3))
> 
> anova(m.lmer)
Analysis of Variance Table
                              Df Sum Sq Mean Sq  Denom F value    Pr(>F)    
irrigation                     1 827.41  827.41  54.00 30.9203 8.546e-07 ***
density                        2 202.53  101.26  54.00  3.7842  0.028971 *  
fertilizer                     2 612.76  306.38  54.00 11.4493 7.159e-05 ***
irrigation:density             2 316.40  158.20  54.00  5.9120  0.004767 ** 
irrigation:fertilizer          2 295.45  147.72  54.00  5.5204  0.006586 ** 
density:fertilizer             4  94.48   23.62  54.00  0.8826  0.480561    
irrigation:density:fertilizer  4  72.73   18.18  54.00  0.6795  0.609157    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

----- End of example ------

-- 

A divis??o do trabalho ?? limitada pelo tamanho do mercado

--Adam Smith
--
|>   // | \\   [***********************************]
|   ( ??   ?? )  [Ronaldo Reis J??nior                ]
|>      V      [UFV/DBA-Entomologia                ]
|    /     \   [36570-000 Vi??osa - MG              ]
|>  /(.''`.)\  [Fone: 31-3899-4007                 ]
|  /(: :'  :)\ [chrysopa at insecta.ufv.br            ]
|>/ (`. `'` ) \[ICQ#: 5692561 | LinuxUser#: 205366 ]
|    ( `-  )   [***********************************]
|>>  _/   \_Powered by GNU/Debian Woody/Sarge



From redbeard at arrr.net  Tue Oct 25 19:15:40 2005
From: redbeard at arrr.net (Jarrett Byrnes)
Date: Tue, 25 Oct 2005 10:15:40 -0700
Subject: [R] Ryan's Q Post-Hoc for ANOVA
Message-ID: <e5b888bb33a6fdd03f82e553ae5f9809@arrr.net>

I'm using lm to run an ANOVA, and would like to use Ryan's Q as my 
post-hoc (as recommended by Day and Quinn, 1989, Ecological 
Monographs).  I can't seem to find any methods in the base stats 
package that implement this post-hoc.  Is there a good package of 
post-hoc methods out there, or has someone written a method for Ryan's 
Q previously?

Thanks!

-Jarrett



From HDoran at air.org  Tue Oct 25 19:24:44 2005
From: HDoran at air.org (Doran, Harold)
Date: Tue, 25 Oct 2005 13:24:44 -0400
Subject: [R] lme and lmer syntax
Message-ID: <F5ED48890E2ACB468D0F3A64989D335ACDC28C@dc1ex3.air.org>

There is an issue with implicit nesting in lmer. In your lme() model you nest block/irrigation/density/fertilizer. In lmer you need to do something like (I dind't include all of your variables, but I think the makes the point)

lmer(yield~irrigation*density*fertilizer+(1|fertilizer:density)+(1|density), data)

Which notes that fertilizer is nested in density. 

Try this and then compare the results. 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ronaldo Reis-Jr.
Sent: Tuesday, October 25, 2005 12:21 PM
To: R-Help
Subject: Re: [R] lme and lmer syntax

Em Seg 24 Out 2005 18:08, Doran, Harold escreveu:
> Ronaldo
>
> See the article on lmer pasted below for syntax. It is the only 
> current source documenting the code. In lmer(), the nesting structure 
> for the ranmdom effects is handled in a slightly different way. If 
> your observations are nested as you note, then you can use
>
> > lmer(y~x1 + x2 +(1|x1) + (1|x2), data)
>
> @Article{Rnews:Bates:2005,
>   author       = {Douglas Bates},
>   title	       = {Fitting Linear Mixed Models in {R}},
>   journal      = {R News},
>   year	       = 2005,
>   volume       = 5,
>   number       = 1,
>   pages	       = {27--30},
>   month	       = {May},
>   url	       = {http://CRAN.R-project.org/doc/Rnews/},
> }
>

Hi,

I try this with a splitsplitplot example.

I make the correct model with aov, lme do compare with lmer.

But I cant make a correct model in lmer. Look that the aov and lme results are similars, but very different from lmer. In aov and lme is used the correct DF for each variable, in lmer it use a same DF for all? Denom=54.

What is my mistake?

Thanks
Ronaldo

----- Begin of example ------

> summary(splitplot)
     yield        block      irrigation   density   fertilizer
 Min.   : 60.00   A:18   control  :36   high  :24   N :24     
 1st Qu.: 86.00   B:18   irrigated:36   low   :24   NP:24     
 Median : 95.00   C:18                  medium:24   P :24     
 Mean   : 99.72   D:18                                        
 3rd Qu.:114.00                                               
 Max.   :136.00                                               
> 
> attach(splitplot)
> 
> m.aov <-
aov(yield~irrigation*density*fertilizer+Error(block/irrigation/density/fertilizer))
> 
> summary(m.aov)

Error: block
          Df  Sum Sq Mean Sq F value Pr(>F)
Residuals  3 194.444  64.815               

Error: block:irrigation
           Df Sum Sq Mean Sq F value  Pr(>F) irrigation  1 8277.6  8277.6  17.590 0.02473 *
Residuals   3 1411.8   470.6                  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Error: block:irrigation:density
                   Df  Sum Sq Mean Sq F value  Pr(>F)  
density             2 1758.36  879.18  3.7842 0.05318 .
irrigation:density  2 2747.03 1373.51  5.9119 0.01633 *
Residuals          12 2787.94  232.33                  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Error: block:irrigation:density:fertilizer
                              Df  Sum Sq Mean Sq F value    Pr(>F)    
fertilizer                     2 1977.44  988.72 11.4493 0.0001418 ***
irrigation:fertilizer          2  953.44  476.72  5.5204 0.0081078 ** 
density:fertilizer             4  304.89   76.22  0.8826 0.4840526    
irrigation:density:fertilizer  4  234.72   58.68  0.6795 0.6106672    
Residuals                     36 3108.83   86.36                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
> 
> library(nlme)
> 
> m.lme <- lme(yield~irrigation*density*fertilizer,random=~1|
block/irrigation/density/fertilizer)
> 
> anova(m.lme)
                              numDF denDF   F-value p-value
(Intercept)                       1    36 2683.2245  <.0001
irrigation                        1     3   31.0269  0.0114
density                           2    12    3.7780  0.0534
fertilizer                        2    36   11.4490  0.0001
irrigation:density                2    12    5.9023  0.0164
irrigation:fertilizer             2    36    5.5203  0.0081
density:fertilizer                4    36    0.8826  0.4841
irrigation:density:fertilizer     4    36    0.6795  0.6107
> 
> library(lme4)
Loading required package: Matrix
Loading required package: lattice
> 
> g1 <- block:irrigation
> g2 <- block:irrigation:density
> g3 <- block:irrigation:density:fertilizer
> 
> m.lmer <- 
> lmer(yield~irrigation*density*fertilizer+(1|g1)+(1|g2)+(1|g3))
> 
> anova(m.lmer)
Analysis of Variance Table
                              Df Sum Sq Mean Sq  Denom F value    Pr(>F)    
irrigation                     1 827.41  827.41  54.00 30.9203 8.546e-07 ***
density                        2 202.53  101.26  54.00  3.7842  0.028971 *  
fertilizer                     2 612.76  306.38  54.00 11.4493 7.159e-05 ***
irrigation:density             2 316.40  158.20  54.00  5.9120  0.004767 ** 
irrigation:fertilizer          2 295.45  147.72  54.00  5.5204  0.006586 ** 
density:fertilizer             4  94.48   23.62  54.00  0.8826  0.480561    
irrigation:density:fertilizer  4  72.73   18.18  54.00  0.6795  0.609157    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

----- End of example ------

-- 

A divis??o do trabalho ?? limitada pelo tamanho do mercado

--Adam Smith
--
|>   // | \\   [***********************************]
|   ( ??   ?? )  [Ronaldo Reis J??nior                ]
|>      V      [UFV/DBA-Entomologia                ]
|    /     \   [36570-000 Vi??osa - MG              ]
|>  /(.''`.)\  [Fone: 31-3899-4007                 ]
|  /(: :'  :)\ [chrysopa at insecta.ufv.br            ]
|>/ (`. `'` ) \[ICQ#: 5692561 | LinuxUser#: 205366 ]
|    ( `-  )   [***********************************]
|>>  _/   \_Powered by GNU/Debian Woody/Sarge

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From lamac_k at hotmail.com  Tue Oct 25 19:30:32 2005
From: lamac_k at hotmail.com (lamack lamack)
Date: Tue, 25 Oct 2005 17:30:32 +0000
Subject: [R] survival frailty models
Message-ID: <BAY113-F269FA86ABA2819D237E6F699760@phx.gbl>

Dear all, someone could send me a introductory reference about Survival 
Frailty Models???

Thank you very much

_________________________________________________________________
Chegou o que faltava: MSN Acesso Gr??tis. Instale J??!



From mtb954 at gmail.com  Tue Oct 25 19:55:02 2005
From: mtb954 at gmail.com (mtb954@gmail.com)
Date: Tue, 25 Oct 2005 11:55:02 -0600
Subject: [R] Graphics window always overlaps console window!
Message-ID: <e40d78ce0510251055q49a01df8y72f369a4d08ed434@mail.gmail.com>

Does anyone know how I can set up R so that when I make a graphic, the
graphics window remains behind the console window? It's annoying to
have to reach for the mouse every time I want to type another line of
code (e.g., to add another line to the plot). Thanks.



From mschwartz at mn.rr.com  Tue Oct 25 20:07:43 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Tue, 25 Oct 2005 13:07:43 -0500
Subject: [R] Graphics window always overlaps console window!
In-Reply-To: <e40d78ce0510251055q49a01df8y72f369a4d08ed434@mail.gmail.com>
References: <e40d78ce0510251055q49a01df8y72f369a4d08ed434@mail.gmail.com>
Message-ID: <1130263663.4971.13.camel@localhost.localdomain>

On Tue, 2005-10-25 at 11:55 -0600, mtb954 at gmail.com wrote:
> Does anyone know how I can set up R so that when I make a graphic, the
> graphics window remains behind the console window? It's annoying to
> have to reach for the mouse every time I want to type another line of
> code (e.g., to add another line to the plot). Thanks.

What operating system?

Default window focus behavior is highly OS and even window manager
specific and is not an R issue.

Depending upon your OS and window manager, you may need to check the
documentation and/or do a Google search on "window focus" for further
information.

Another alternative, if you are on Windows, is to review Windows FAQ 5.4
"How do I move focus to a graphics window or the console?", but this is
a programmatic approach and not a means to affect default behavior.

HTH,

Marc Schwartz



From jukka.ruohonen at helsinki.fi  Tue Oct 25 20:08:37 2005
From: jukka.ruohonen at helsinki.fi (jukka ruohonen)
Date: Tue, 25 Oct 2005 21:08:37 +0300
Subject: [R]  panel data unit root tests
Message-ID: <1130263717.435e74a5a7e7e@www2.helsinki.fi>

Thanks, that will certainly do the trick. I came across systemfit and sem -
packages that are useful in this respect as well.

Jukka Ruohonen
University of Helsinki


> Have you received a reply?  I haven't seen one.  RSiteSearch("panel 
> data unit root test") produced another question on this but no answers 
> that I saw.  RSiteSearch("unit root test") produced 75 hits with many 
> useful.  RSiteSearch("panel data analysis") produced 75 hits, the first 
> of which suggested the nlme package 
> (http://finzi.psych.upenn.edu/R/Rhelp02a/archive/26962.html).  You could
> construct nested models to compare the corAR1 correlation structure with
> first differences.
> 
> 	  hope this helps.
> 	  spencer graves
> 
> jukka ruohonen wrote:
> 
> > Hi,
> > 
> > The question is as follows: has anyone coded panel data unit root tests
> 
> > with R? Even the "first generation" tests (see e.g. Levin & Lin 1993; 
> > Pesaran, & Smith & Im 1996; Maddala & Wu 1999) would be sufficient for
> > my needs. To my understanding, these are rather easy to code, but as I
> > have taken just my first steps in coding with R, existing code would 
> > save me from a lot of trouble & time.
> > 
> > 
> > With regards,
> > 
> > Jukka Ruohonen
> > University of Helsinki
> > 
> > 
> > References:
> > 
> > Levin, A. & Lin, C.F. (1993): Unit Root Tests in Panel Data. 
> > ftp://weber.ucsd.edu/pub/econlib/dpapers/ucsd9356.pdf
> > 
> > Maddala, G.S. & Wu, S. (1999): A Comparative Study of Unit Roots Tests
> with 
> > Panel Data and a New Simple Test. Oxford Bulleting of Economics and 
> > Statistics. Special Issue 61, 631-652.
> > 
> > Pesaran, M.H. & Smith, R. & Im, K.S. (1996): Dynamic Linear Models for
> 
> > Heterogenous Panels. In: Matyas, L. & Sevestre, P. (eds.): The
> Econometrics 
> > of Panel Data: a Handbook of the Theory with Applications, second
> edition, 
> > pp. 145-195.
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> -- 
> Spencer Graves, PhD
> Senior Development Engineer
> PDF Solutions, Inc.
> 333 West San Carlos Street Suite 700
> San Jose, CA 95110, USA
> 
> spencer.graves at pdf.com
> www.pdf.com <http://www.pdf.com>
> Tel:  408-938-4420
> Fax: 408-280-7915



From abunn at whrc.org  Tue Oct 25 20:12:12 2005
From: abunn at whrc.org (Andy Bunn)
Date: Tue, 25 Oct 2005 14:12:12 -0400
Subject: [R] Graphics window always overlaps console window!
In-Reply-To: <e40d78ce0510251055q49a01df8y72f369a4d08ed434@mail.gmail.com>
Message-ID: <NEBBIPHDAMMOKDKPOFFIKELLDLAA.abunn@whrc.org>

> Does anyone know how I can set up R so that when I make a graphic, the
> graphics window remains behind the console window? It's annoying to
> have to reach for the mouse every time I want to type another line of
> code (e.g., to add another line to the plot). Thanks.

What OS? In Windows with R GUI I use ctrl-Tab to cycle from the console, to
graphics, to help, etc.

-Andy



From mschwartz at mn.rr.com  Tue Oct 25 20:20:50 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Tue, 25 Oct 2005 13:20:50 -0500
Subject: [R] Graphics window always overlaps console window!
In-Reply-To: <1130263663.4971.13.camel@localhost.localdomain>
References: <e40d78ce0510251055q49a01df8y72f369a4d08ed434@mail.gmail.com>
	<1130263663.4971.13.camel@localhost.localdomain>
Message-ID: <1130264451.4971.22.camel@localhost.localdomain>

On Tue, 2005-10-25 at 13:07 -0500, Marc Schwartz (via MN) wrote:
> On Tue, 2005-10-25 at 11:55 -0600, mtb954 at gmail.com wrote:
> > Does anyone know how I can set up R so that when I make a graphic, the
> > graphics window remains behind the console window? It's annoying to
> > have to reach for the mouse every time I want to type another line of
> > code (e.g., to add another line to the plot). Thanks.
> 
> What operating system?
> 
> Default window focus behavior is highly OS and even window manager
> specific and is not an R issue.
> 
> Depending upon your OS and window manager, you may need to check the
> documentation and/or do a Google search on "window focus" for further
> information.
> 
> Another alternative, if you are on Windows, is to review Windows FAQ 5.4
> "How do I move focus to a graphics window or the console?", but this is
> a programmatic approach and not a means to affect default behavior.

Yet another approach which I just remembered is that (if on Windows) MS
offers a program called Tweak UI:

http://www.microsoft.com/windowsxp/downloads/powertoys/xppowertoys.mspx

as part of their Power Toys add-ons.

You might want to review that to see if there is a setting for the
handling of new window focus behavior.

HTH,

Marc



From ehlers at math.ucalgary.ca  Tue Oct 25 20:23:43 2005
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Tue, 25 Oct 2005 12:23:43 -0600
Subject: [R] Graphics window always overlaps console window!
In-Reply-To: <e40d78ce0510251055q49a01df8y72f369a4d08ed434@mail.gmail.com>
References: <e40d78ce0510251055q49a01df8y72f369a4d08ed434@mail.gmail.com>
Message-ID: <435E782F.9000406@math.ucalgary.ca>

mtb954 at gmail.com wrote:

> Does anyone know how I can set up R so that when I make a graphic, the
> graphics window remains behind the console window? It's annoying to
> have to reach for the mouse every time I want to type another line of
> code (e.g., to add another line to the plot). Thanks.

I don't see this behaviour on Windows XP, except when a graphics
window is first opened. And Ctrl-Tab toggles the windows. No mouse!

Peter Ehlers



From mtb954 at gmail.com  Tue Oct 25 20:28:55 2005
From: mtb954 at gmail.com (mtb954@gmail.com)
Date: Tue, 25 Oct 2005 12:28:55 -0600
Subject: [R] Graphics window always overlaps console window!
In-Reply-To: <e40d78ce0510251055q49a01df8y72f369a4d08ed434@mail.gmail.com>
References: <e40d78ce0510251055q49a01df8y72f369a4d08ed434@mail.gmail.com>
Message-ID: <e40d78ce0510251128k3241f7alee31d8c627f8651e@mail.gmail.com>

Thanks for your replies, I was unaware of these solutions.

On 10/25/05, mtb954 at gmail.com <mtb954 at gmail.com> wrote:
> Does anyone know how I can set up R so that when I make a graphic, the
> graphics window remains behind the console window? It's annoying to
> have to reach for the mouse every time I want to type another line of
> code (e.g., to add another line to the plot). Thanks.
>



From michael_graber at gmx.de  Tue Oct 25 21:44:57 2005
From: michael_graber at gmx.de (Michael Graber)
Date: Tue, 25 Oct 2005 21:44:57 +0200
Subject: [R] data.frame-question
Message-ID: <435E8B39.1020509@gmx.de>

Dear R-List,
I am very new to R and programming itself, so my question may be easy to 
answer for you.
I tried a lot and read through the manuals, but I still have the 
following problem:
I have 2 data-frames:
Number<-as.numeric (Number)
Name<-as.character (Name)
TAB1<-data.frame (Name,Number)
- it looks like this:-
Name Number
A 2
A 3
A 6
B 8
B 12
B 7
C 8
D 90
E 12
E 45
â€¦
Name_singular<-as.character (Name_singular)
TAB2<-data.frame (Name_singular)
# it looks like this:
Name_singular
A
B
C
D
E
-My result should be a data-frame, where the first column is 
Name_singular and the second column should be the sum of the numbers 
where Name ==Name_singular.-
For example:
TAB3:
Name_singular Sum
A 11
B 27
â€¦
- I tried it with for-loops, but I think there must be an easier way.-
I would be very grateful for your help,


Michael Graber



From jdillon at hsph.harvard.edu  Tue Oct 25 21:51:54 2005
From: jdillon at hsph.harvard.edu (Jennifer Dillon)
Date: Tue, 25 Oct 2005 15:51:54 -0400
Subject: [R] making an inicator variable
Message-ID: <20051025155154.jjkasnokgzgg8c0c@webmail.sph.harvard.edu>

Hello,

I am almost a total novice, and I am sure there must be an easy (and 
basic) way to turn a variable of 1's and 2's into a variable of zeros 
and ones.  This is in a data frame, but if I could do it with vectors, 
that's all I need.

Can someone tell me how?

Thanks so much,

Jen



From chrysopa at gmail.com  Tue Oct 25 21:56:07 2005
From: chrysopa at gmail.com (Ronaldo Reis-Jr.)
Date: Tue, 25 Oct 2005 17:56:07 -0200
Subject: [R] lme and lmer syntax
In-Reply-To: <F5ED48890E2ACB468D0F3A64989D335ACDC28C@dc1ex3.air.org>
References: <F5ED48890E2ACB468D0F3A64989D335ACDC28C@dc1ex3.air.org>
Message-ID: <200510251756.07418.chrysopa@gmail.com>

Em Ter 25 Out 2005 15:24, Doran, Harold escreveu:
> There is an issue with implicit nesting in lmer. In your lme() model you
> nest block/irrigation/density/fertilizer. In lmer you need to do something
> like (I dind't include all of your variables, but I think the makes the
> point)
>
> lmer(yield~irrigation*density*fertilizer+(1|fertilizer:density)+(1|density)
>, data)
>
> Which notes that fertilizer is nested in density.
>
> Try this and then compare the results.
>

It dont work.

I dont understand the basic output.

Independently of the nested model defined, the denom are 54.

My doubt, the denom in anova(lmer) table is the densDF in anova(lme) table?

I looking for a corrected DF for each nest variable, but it show a common DF 
for all variables.

Exist more documentation about lmer?

Thanks
Ronaldo
-- 
A primeira impress??o ?? a que fica, mas s?? se o toner for bom.
--
|>   // | \\   [***********************************]
|   ( ??   ?? )  [Ronaldo Reis J??nior                ]
|>      V      [UFV/DBA-Entomologia                ]
|    /     \   [36570-000 Vi??osa - MG              ]
|>  /(.''`.)\  [Fone: 31-3899-4007                 ]
|  /(: :'  :)\ [chrysopa at insecta.ufv.br            ]
|>/ (`. `'` ) \[ICQ#: 5692561 | LinuxUser#: 205366 ]
|    ( `-  )   [***********************************]
|>>  _/   \_Powered by GNU/Debian Woody/Sarge



From br44114 at gmail.com  Tue Oct 25 21:59:48 2005
From: br44114 at gmail.com (bogdan romocea)
Date: Tue, 25 Oct 2005 15:59:48 -0400
Subject: [R] data.frame-question
Message-ID: <8d5a36350510251259s1345321fi71e539bac62b1831@mail.gmail.com>

Welcome to R. See
   ?merge
then
   ?aggregate
or
   require(Hmisc)
   ?summarize
or
   ?by
You can probably find many examples in the archives, if needed.


> -----Original Message-----
> From: Michael Graber [mailto:michael_graber at gmx.de]
> Sent: Tuesday, October 25, 2005 3:45 PM
> To: R-Mailingliste
> Subject: [R] data.frame-question
>
>
> Dear R-List,
> I am very new to R and programming itself, so my question may
> be easy to
> answer for you.
> I tried a lot and read through the manuals, but I still have the
> following problem:
> I have 2 data-frames:
> Number<-as.numeric (Number)
> Name<-as.character (Name)
> TAB1<-data.frame (Name,Number)
> - it looks like this:-
> Name Number
> A 2
> A 3
> A 6
> B 8
> B 12
> B 7
> C 8
> D 90
> E 12
> E 45
> ?
> Name_singular<-as.character (Name_singular)
> TAB2<-data.frame (Name_singular)
> # it looks like this:
> Name_singular
> A
> B
> C
> D
> E
> -My result should be a data-frame, where the first column is
> Name_singular and the second column should be the sum of the numbers
> where Name ==Name_singular.-
> For example:
> TAB3:
> Name_singular Sum
> A 11
> B 27
> ?
> - I tried it with for-loops, but I think there must be an easier way.-
> I would be very grateful for your help,
>
>
> Michael Graber
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From gerifalte28 at hotmail.com  Tue Oct 25 22:34:29 2005
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Tue, 25 Oct 2005 20:34:29 +0000
Subject: [R] Can anyone please tell me how to strip the white spaces
	from acharacter
Message-ID: <BAY103-F281F26CA6CA29CAD9A308EA6760@phx.gbl>

I addition to all the many good options presented you can also use 
trimWhiteSpace{limma} which is just a higher level call to sub()

x=scan("clipboard", what="character")
Read 6 items
x
[1] "AIR "  "ABCB " "ABXA " "ACMR " "ADCT " "ADEX "

trimWhiteSpace(x)
[1] "AIR"  "ABCB" "ABXA" "ACMR" "ADCT" "ADEX"


Cheers

Francisco


>From: roger bos <roger.bos at gmail.com>
>To: "(r-help at stat.math.ethz.ch.)" <R-help at stat.math.ethz.ch>
>Subject: [R] Can anyone please tell me how to strip the white spaces from 
>acharacter vector?
>Date: Tue, 25 Oct 2005 08:51:48 -0400
>
>for example:
> > a$tic[1:10]
>[1] "AIR " "ABCB " "ABXA " "ACMR " "ADCT " "ADEX "
>[7] "ABM " "AFCE " "AG " "ATG "
>  Can anyone please tell me how to strip the white spaces from a$tic?
>  Thanks,
>  Roger
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From vincent.goulet at act.ulaval.ca  Tue Oct 25 22:34:37 2005
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Tue, 25 Oct 2005 16:34:37 -0400
Subject: [R] making an inicator variable
In-Reply-To: <20051025155154.jjkasnokgzgg8c0c@webmail.sph.harvard.edu>
References: <20051025155154.jjkasnokgzgg8c0c@webmail.sph.harvard.edu>
Message-ID: <200510251634.37434.vincent.goulet@act.ulaval.ca>

Le 25 Octobre 2005 15:51, Jennifer Dillon a ??crit??:
> Hello,
>
> I am almost a total novice, and I am sure there must be an easy (and
> basic) way to turn a variable of 1's and 2's into a variable of zeros
> and ones.  This is in a data frame, but if I could do it with vectors,
> that's all I need.
>
> Can someone tell me how?
>
> Thanks so much,
>
> Jen

What about

> x - 1

(where 'x' is a vector of 1's and 2's)?

-- 
  Vincent Goulet, Professeur agr??g??
  ??cole d'actuariat
  Universit?? Laval, Qu??bec 
  Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca



From LI at nsabp.pitt.edu  Tue Oct 25 22:41:47 2005
From: LI at nsabp.pitt.edu (Li, Jia)
Date: Tue, 25 Oct 2005 16:41:47 -0400
Subject: [R] One more about  Error in step() (or stepAIC) for Cox model
Message-ID: <D70CBC108DFBD446862A6E1F6F0B4A1557A457@nsabpmail>

Thank you for Prof.Ripley's suggestion. I fixed the program by adding a
lower scope, and the program ran, but I still got warning messages, and
don't know what is going on, would this affect my results?
...
Step:  AIC= 12337.74 
 Surv(tlfup, cen) ~ MI[[j]]$trt + MI[[j]]$agem40 + MI[[j]]$agem40sq +  
    mhtypeed1 + mhtypeed2 

                   Df   AIC
<none>                12338
- MI[[j]]$agem40sq  1 12338
- MI[[j]]$agem40    1 12339
- mhtypeed2         1 12353
- mhtypeed1         1 12365
There were 50 or more warnings (use warnings() to see the first 50)
Warning messages:
1: X matrix deemed to be singular; variable 8 9 in: coxph(Surv(tlfup,
cen) ~ MI[[j]]$trt + MI[[j]]$nodes + MI[[j]]$ngraded2 +   ...
2: X matrix deemed to be singular; variable 7 8 in: coxph(formula =
Surv(tlfup, cen) ~ MI[[j]]$nodes + MI[[j]]$ngraded2 +   ...
...
7: X matrix deemed to be singular; variable 7 8 in: coxph(formula =
Surv(tlfup, cen) ~ MI[[j]]$trt + MI[[j]]$nodes +   ...
8: X matrix deemed to be singular; variable 8 in: coxph(formula =
Surv(tlfup, cen) ~ MI[[j]]$trt + MI[[j]]$nodes +   ...
11: X matrix deemed to be singular; variable 7 in: coxph(formula =
Surv(tlfup, cen) ~ MI[[j]]$nodes + MI[[j]]$ngraded2 +   ...
...

Thanks,

Jia
-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: Monday, October 24, 2005 4:05 PM
To: Li, Jia
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Error in step() (or stepAIC) for Cox model

On Mon, 24 Oct 2005, Li, Jia wrote:

> Hello all,
>
> I am trying to use stepwise procedure to select covariates in Cox 
> model and use bootstrap to repeat stepwise selection,  then record how

> many times  variables  are chosen by step() in bootstrap replications.

> When I use step() (or stepAIC) to do model selection, I got errors. 
> Here is the part of my code
>
> for (j in 1:mm){    #<--mm=10
>
> for (b in 1:nrow(reg.bs)){ #<--bootstrap 10 times
>
> mi<-data.frame(tlfup,cen,complete(imp,j)) #<--completed data sets 
> after MI
>
> in.star<-sample(1:n,n,replace=T) #<--to sample id number 1-1851.
>
> data.star<-mi[in.star,]
>
> M<-coxph(Surv(tlfup,cen)~mi$trt+mi$nodes+mi$htypeed1+mi$htypeed2+mi$ng
> ra
> ded2+mi$agem40
>
> +mi$agem40sq+mi$er+mi$pr,data=data.star)
>
> reg.model<-step(M) #<--do stepwise selection
>
> reg.step[[b]]<-c((reg.model$coef)) #<-store selected variables
>
> chosen.vb[[b]]<-names(reg.step[[b]]) #<--store names of selected 
> variables
>
> }
>
> tot.vb[[j]]<-c(unlist(chosen.vb))
>
> }
>
> Error in reg.step[[b]] : subscript out of bounds
>
>
> varibles<-unlist(tot.vb) #<--change to a vector
>
> table(varibles)           #<--how many times the names have been
> selected
>
> Error in sort(unique.default(x), na.last = TRUE) :
>        'x' must be atomic
>
>
> I figure the reason may be that when stepwise procedure selects the 
> chosen model with no varibles, that is
>
> Start:  AIC= 12436.85
> Surv(tlfup, cen) ~ mi$trt + mi$nodes + mi$htypeed1 + mi$htypeed2 +
>    mi$ngraded2 + mi$agem40 + mi$agem40sq + mi$er + mi$pr
>
>              Df   AIC
> - mi$pr        1 12435
> - mi$trt       1 12435
> - mi$agem40sq  1 12435
> - mi$agem40    1 12435
> - mi$htypeed2  1 12435
> - mi$nodes     1 12435
> - mi$er        1 12436
> - mi$ngraded2  1 12436
> - mi$htypeed1  1 12436
> <none>           12437
>
> Step:  AIC= 12425.91
> Surv(tlfup, cen) ~ mi$htypeed1 + mi$ngraded2 + mi$er
>
>              Df   AIC
> - mi$er        1 12425
> - mi$ngraded2  1 12425
> - mi$htypeed1  1 12426
> <none>           12426
>
> Step:  AIC= 12424.77
> Surv(tlfup, cen) ~ 1
>
> then reg.model$coef dosen't exist anymore (am I right?), but I need to

> count the variables that are selected by step() in bootstrap 
> replications, what should I do?

Specify the lower scope suitably.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mark.lopresti at thomson.com  Tue Oct 25 22:47:19 2005
From: mark.lopresti at thomson.com (mark.lopresti@thomson.com)
Date: Tue, 25 Oct 2005 16:47:19 -0400
Subject: [R] Building Rmysql Source in Windows XP: DLLTOOL can't find DEF
	file
Message-ID: <43E5FDBDC08D2A4CABF40DEA64C570A0DF39E2@TFUSMDROCMBX01.ERF.THOMSON.COM>

Hello everyone,

I have a question regarding building the Rmysql packages from source in
Windows.  

I am currently using:   Windows XP, R-2.2.0, Mysql 3.23

I have installed all of the tools from Installation and Administration
and after following all the instructions to the letter, I compiled the
binary and installed R 2.2.0 from source with no issues.  This is the
first time I have compiled the source R and the first time I have
attempted building a package from source.  

When I read all of the RMySQL docs for creating the packages from
source, (Installation and Admin and all the 'readme' docs in the package
itself), there really seem to be only 2 basic instructions: 
1) Ensure the paths are correct in src/Makevars.win
2) re-import the DLL
3) and then build.

I ensure that my paths are correct in the src/Makevars.win file and then
the 2nd part of the instructions discusses "re-importing" the
libmysql.dll.

However, when I use the Dlltool in the correct Mysql directory
(c:\mysql\lib\opt) as directed, an error occurs below:

                   "dlltool: can't open the def file: Libmysql.def"

The "libmysql.def" file is located in the "c:\mysql\include\" directory
where PKG-CPPFLAGS is pointing. 

Question (1)------------ Do you know of why this is occurring and how
can I solve it?  
I could not find any documentation in Google or in the archives
regarding this error.  

Then finally, the last instructions uses "Rcmd build -binary RMySQL".  
Question (2)------------ In what directory is this windows command line
given?  Under R/src/gnuwin32/?

Thank you so much for your time and any suggestions would be greatly
appreciated.

Best,

Mark

Mark A. LoPresti
Senior Quantitative Analyst
Thomson Financial
Phone: 301-545-4630
Email: mark.lopresti at thomson.com
Web: www.thomson.com/financial



From liuwensui at gmail.com  Tue Oct 25 23:03:33 2005
From: liuwensui at gmail.com (Wensui Liu)
Date: Tue, 25 Oct 2005 17:03:33 -0400
Subject: [R] making an inicator variable
In-Reply-To: <20051025155154.jjkasnokgzgg8c0c@webmail.sph.harvard.edu>
References: <20051025155154.jjkasnokgzgg8c0c@webmail.sph.harvard.edu>
Message-ID: <1115a2b00510251403g6c19e422n9e14e603035a7ae6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051025/f6c9ff0c/attachment.pl

From michel.friesenhahn.b at bayer.com  Tue Oct 25 23:03:55 2005
From: michel.friesenhahn.b at bayer.com (Michel Friesenhahn)
Date: Tue, 25 Oct 2005 14:03:55 -0700
Subject: [R] Confidence Intervals for Mixed Effects
Message-ID: <OFFFF32B17.CCCC7801-ON882570A5.0072FEA4-882570A5.0073B740@bayer.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051025/21b0b7df/attachment.pl

From jahumada at usgs.gov  Tue Oct 25 23:05:16 2005
From: jahumada at usgs.gov (Jorge Ahumada)
Date: Tue, 25 Oct 2005 16:05:16 -0500
Subject: [R] solving ODE's in matrix form with lsoda()
Message-ID: <32EFCF8F-E62D-4E3C-9FA1-463F8F01098A@usgs.gov>

Hello there,

Suppose you want to solve the following system of ODE's (a simple  
Lotka-Volterra predator prey model)

dP/dt = beta*P*V - mu*P
dV/dt = r*V - beta*P*V

where P and V are the numbers of predators and prey. Now, this is  
easy to do, but suppose you have a system of equations like this,

dP1/dt = beta1*P1*V1 - mu1*P1
dP2/dt = beta2*P2*V2 - mu2*P2
dV1/dt = r1*V1 - beta1*P1*V1
dV2/dt = r1*V2 - beta1*P2*V2

System 1 and system 2 are independent but that doesn't need to be the  
case. Now can you specify this system in lsoda() as:

dP/dt = beta*P*V - mu*P
dV/dt = r*V - beta*P*V

but now the initial state variables are 1x2 vectors and the  
parameters beta, mu and r are also vectors of size 1x2:

y=c(10,20,10,20)
parms = matrix(c(0.05,0.1,0.2,0.05,0.1,0.2),nc=3,byrow=T)

model = function(times,y,parms) {
y=matrix(y,nc=2,byrow=T)
beta=parms[,1]; mu = parms[,2], r = parms[,3]

dP/dt = beta*P*V - mu*P
dV/dt = r*V - beta*P*V

list(c(dP/dt,dV/dt)

}

I tried this but it does not give me the right answer. lsoda() gives  
warnings and produces weird results..

thanks, Jorge



From ripley at stats.ox.ac.uk  Tue Oct 25 23:24:25 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 25 Oct 2005 22:24:25 +0100 (BST)
Subject: [R] Building Rmysql Source in Windows XP: DLLTOOL can't find
 DEF file
In-Reply-To: <43E5FDBDC08D2A4CABF40DEA64C570A0DF39E2@TFUSMDROCMBX01.ERF.THOMSON.COM>
References: <43E5FDBDC08D2A4CABF40DEA64C570A0DF39E2@TFUSMDROCMBX01.ERF.THOMSON.COM>
Message-ID: <Pine.LNX.4.61.0510252212430.1495@gannet.stats>

On Tue, 25 Oct 2005 mark.lopresti at thomson.com wrote:

> Hello everyone,
>
> I have a question regarding building the Rmysql packages from source in
> Windows.

Pretty esoteric, and the posting guide suggests you ask the maintainer.

> I am currently using:   Windows XP, R-2.2.0, Mysql 3.23

MySQL 3.23 is rather old: the layout may have changed.

> I have installed all of the tools from Installation and Administration
> and after following all the instructions to the letter, I compiled the
> binary and installed R 2.2.0 from source with no issues.  This is the
> first time I have compiled the source R and the first time I have
> attempted building a package from source.
>
> When I read all of the RMySQL docs for creating the packages from
> source, (Installation and Admin and all the 'readme' docs in the package
> itself), there really seem to be only 2 basic instructions:
> 1) Ensure the paths are correct in src/Makevars.win
> 2) re-import the DLL
> 3) and then build.
>
> I ensure that my paths are correct in the src/Makevars.win file and then
> the 2nd part of the instructions discusses "re-importing" the
> libmysql.dll.
>
> However, when I use the Dlltool in the correct Mysql directory
> (c:\mysql\lib\opt) as directed, an error occurs below:
>
>                   "dlltool: can't open the def file: Libmysql.def"
>
> The "libmysql.def" file is located in the "c:\mysql\include\" directory
> where PKG-CPPFLAGS is pointing.

But it is not an include file, and this is nothing to do with step 1 where 
you set PKG_CPPFLAGS (note spelling).

You need to give the path to it, somthing like

dlltool --dllname libmySQL.dll --def ..\..\include\LIBMYSQL.def 
--output-lib libmySQL.a  -k

> Question (1)------------ Do you know of why this is occurring and how
> can I solve it?
> I could not find any documentation in Google or in the archives
> regarding this error.
>
> Then finally, the last instructions uses "Rcmd build -binary RMySQL".
> Question (2)------------ In what directory is this windows command line
> given?  Under R/src/gnuwin32/?

The one with subdirectory RMySQL.  But you don't need to do this, just to 
install with

R CMD INSTALL RMySQL

as you are not distributing it.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jfox at mcmaster.ca  Tue Oct 25 23:30:16 2005
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 25 Oct 2005 17:30:16 -0400
Subject: [R] making an inicator variable
In-Reply-To: <20051025155154.jjkasnokgzgg8c0c@webmail.sph.harvard.edu>
Message-ID: <20051025213013.KQHQ25800.tomts13-srv.bellnexxia.net@JohnDesktop8300>

Dear Jen,

There are lots of different ways to do what you want -- you've already had
two suggestions -- but you might consider whether you really need to do it.
In particular, R will generate its own indicator variables (and other kinds
of contrasts) in linear and other statistical models (see Section 11 of the
Introduction to R manual that comes with R). It's hard to give really good
advice without knowing more about the context.

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jennifer Dillon
> Sent: Tuesday, October 25, 2005 2:52 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] making an inicator variable
> 
> Hello,
> 
> I am almost a total novice, and I am sure there must be an easy (and
> basic) way to turn a variable of 1's and 2's into a variable 
> of zeros and ones.  This is in a data frame, but if I could 
> do it with vectors, that's all I need.
> 
> Can someone tell me how?
> 
> Thanks so much,
> 
> Jen
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From acwarrie at csc.ncsu.edu  Tue Oct 25 23:57:10 2005
From: acwarrie at csc.ncsu.edu (Ajit Chakrapani Warrier)
Date: Tue, 25 Oct 2005 17:57:10 -0400
Subject: [R] Writing point pattern to a file
Message-ID: <435EAA36.2000906@csc.ncsu.edu>

Hi,

	I am trying to use the R package 'spatstat' for generating spatial 
poisson point process graphs. I can create a point pattern using the 
following commands:

	pp <- rpoispp(.01, win=owin(c(0,100),c(0,100)))

	and also view the resulting graph by:

	plot(pp)

	But how can I export the generated point pattern to an external file so 
that I could use it as input for some network simulation
programs ? Also, it seems that the generated graph is different on each 
invocation. Is there a way I could control this randomness, some seed 
perhaps.

Thanks in advance,
Ajit.
-- 
Ajit Chakrapani Warrier
------------------------------------------------------------
Graduate Student                     acwarrie at csc.ncsu.edu
Department of Computer Science       (919) 389 9737
North Carolina State University      www4.ncsu.edu/~acwarrie



From leaflovesun at yahoo.ca  Wed Oct 26 01:05:13 2005
From: leaflovesun at yahoo.ca (Leaf Sun)
Date: Tue, 25 Oct 2005 17:05:13 -0600
Subject: [R] Finding the neighbors of the point
Message-ID: <200510252309.j9PN9OOS013509@hypatia.math.ethz.ch>

Hi Roger and the list,

The package is working very well.   What surprised me most is the speed. As I mentioned in my previous emails,  I have to find the neighbors for around 200,000 individuals.  It took no more than 10 minutes for the function to finish the searching and returned enough information (ldnn, lnn).  As of the third dimension -Z,  I applied the code you sent to me, also worked very well. I only modified some condition that meets the requirement. This package is just great for such neighbor searching. 

Thank you very much and all the best!

Leaf

======= At 2005-10-25, 04:31:54 you wrote: =======

>On Mon, 24 Oct 2005, Leaf Sun wrote:
>
>> Running R 2.2.0 on winXP.  Computer P4 CPU 3.2G and 1G of RAM.
>
>Please try the attached Windows binary package. Look at the help page for 
>ann.dist(). It returns a list of three elements, the first, lnn, gives the 
>index numbers of the neighbours closer than maxdist. From there say you 
>have a vector z  where you want the neighbour relation to apply only when 
>z[i] < z[j], so
>
>res <- ann.dist(pts, maxdist=md)
>glist <- vector(mode="list", length=length(res$lnn))
>for (i in seq(along=res$lnn)) {
>  if (length(res$lnn[[i]]) > 0) { 
>    glist[[i]] <- ifelse(z[i] < z[res$lnn[[i]]], 1, 0) 
>  }
>}
>
>so glist tells you which to drop. Alternatively, you can drop them 
>straight away:
>
>res <- ann.dist(pts, maxdist=md)
>glist <- vector(mode="list", length=length(res$lnn))
>for (i in seq(along=res$lnn)) {
>  if (length(res$lnn[[i]]) > 0) {
>    glist[[i]] <- res$lnn[[i]]][z[i] < z[res$lnn[[i]]]]
>  }
>}
>
>(neither of these are tried, so the brackets may not match).
>
>Please let me know how you get on.
>
>Roger
>
>> 
>> ======= At 2005-10-24, 09:46:28 you wrote: =======
>> 
>> >On Mon, 24 Oct 2005, Leaf Sun wrote:
>> >
>> >> No, I mean I have to find the neighbors of 200,000 points.
>> >
>> >Your R version and OS - output of version on your machine?
>> >
>> >Roger
>> >
>> >
>> >>   
>> >> ======= At 2005-10-24, 03:30:41 you wrote: =======
>> >> 
>> >> >On Fri, 21 Oct 2005, Leaf Sun wrote:
>> >> >
>> >> >> Roger,
>> >> >> 
>> >> >> The data frame is of 200,000 by 15 elements.
>> >> >
>> >> >Do you mean that you need to find distances in 15 dimensions?
>> >> >
>> >> >Roger
>> >> >
>> >> >> 
>> >> >> I've learned some C, long time ago. But I guess I would understand the C codes. Thanks!
>> >> >> 
>> >> >> Leaf
>> >> >> 
>> >> >> ======= At 2005-10-21, 14:11:38 you wrote: =======
>> >> >> 
>> >> >> >On Fri, 21 Oct 2005, Leaf Sun wrote:
>> >> >> >
>> >> >> >> Dear all,
>> >> >> >> 
>> >> >> >> I got point data of trees. I was wondering if anybody has experience in searching the neighbors within a specified distance efficiently.
>> >> >> >> 
>> >> >> >> X    Y     Z
>> >> >> >> 99 	34	 65
>> >> >> >> 98 	35	 29
>> >> >> >> 98 	34	 28
>> >> >> >> 99 	33	 33
>> >> >> >> 98 	32	 23
>> >> >> >> 99 	33	 21
>> >> >> >> 99 	33	 22
>> >> >> >> 99 	32	 24
>> >> >> >> 99 	30	 23
>> >> >> >>     ...
>> >> >> >> 
>> >> >> >
>> >> >> >> What I want to do is :  searching for the neighbors with a distance R
>> >> >> >> for each tree & the neighbor must have a bigger Z.
>> >> >> >> 
>> >> >> >> 
>> >> >> >> The data set is huge so the R-codes is working slowly when I search it
>> >> >> >> without subset it.
>> >> >> >> 
>> >> >> >
>> >> >> >And huge is how big? For very large problems, you'll need a kd-tree or 
>> >> >> >r-tree approach to divide up the point locations before making the spatial 
>> >> >> >query (I think the retention of neighbours with a larger z is the final 
>> >> >> >step). There do not seem to be such functions in R or contributed packages 
>> >> >> >at present. If you are willing to collaborate, I can pass on a draft 
>> >> >> >package corrected by Christian Sangiorgio for approximate nearest 
>> >> >> >neighbours (an interface to ANN by David Mount and collaborators), but it 
>> >> >> >isn't working yet. So an investment in time and some knowledge of C++ will 
>> >> >> >be useful.
>> >> >> >
>> >> >> >> Any suggestion would be much appreciated!
>> >> >> >> 
>> >> >> >> Leaf
>> >> >> >> 
>> >> >> >> 
>> >> >> >
>> >> >> >-- 
>> >> >> >Roger Bivand
>> >> >> >Economic Geography Section, Department of Economics, Norwegian School of
>> >> >> >Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> >> >> >Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> >> >> >e-mail: Roger.Bivand at nhh.no
>> >> >> >
>> >> >> >
>> >> >> 
>> >> >> = = = = = = = = = = = = = = = = = = = =
>> >> >> 			
>> >> >> 
>> >> >> 
>> >> >> __________________________________________________
>> >> >> Do You Yahoo!?

>> >> >> http://mail.yahoo.com 
>> >> >> 
>> >> >
>> >> >-- 
>> >> >Roger Bivand
>> >> >Economic Geography Section, Department of Economics, Norwegian School of
>> >> >Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> >> >Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> >> >e-mail: Roger.Bivand at nhh.no
>> >> >
>> >> >.
>> >> 
>> >> = = = = = = = = = = = = = = = = = = = =
>> >> 			
>> >> Leaf Sun
>> >> leaflovesun at yahoo.ca
>> >> 2005-10-24
>> >> 
>> >> 
>> >> 
>> >> __________________________________________________
>> >> Do You Yahoo!?

>> >> http://mail.yahoo.com 
>> >> 
>> >
>> >-- 
>> >Roger Bivand
>> >Economic Geography Section, Department of Economics, Norwegian School of
>> >Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> >Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> >e-mail: Roger.Bivand at nhh.no
>> >
>> 
>> = = = = = = = = = = = = = = = = = = = =
>> 			
>> 
>> 
>> __________________________________________________
>> Do You Yahoo!?

>> http://mail.yahoo.com 
>> 
>
>-- 
>Roger Bivand
>Economic Geography Section, Department of Economics, Norwegian School of
>Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>e-mail: Roger.Bivand at nhh.no
>
>

= = = = = = = = = = = = = = = = = = = =



From lzhtom at hotmail.com  Wed Oct 26 03:52:32 2005
From: lzhtom at hotmail.com (zhihua li)
Date: Wed, 26 Oct 2005 01:52:32 +0000
Subject: [R] a silly question on index of a matrix
Message-ID: <BAY110-F105A75B4511F38DCFDA8D5C7690@phx.gbl>

Hi netters,

This is probably a silly question,but I can't find the answer after 
searching the R-help archives online. ok, I have a matrix. I know there is 
a "10" somewhere in it. Now I want to
know the index of the element "10" in this matrix. That is, if X[i,j]=10, I 
want to know
i and j. Is there a R function to do this? Just like the "find" function in 
matlab.

Thanks all!



From blomsp at ozemail.com.au  Wed Oct 26 04:19:41 2005
From: blomsp at ozemail.com.au (Simon Blomberg)
Date: Wed, 26 Oct 2005 12:19:41 +1000
Subject: [R] a silly question on index of a matrix
In-Reply-To: <BAY110-F105A75B4511F38DCFDA8D5C7690@phx.gbl>
References: <BAY110-F105A75B4511F38DCFDA8D5C7690@phx.gbl>
Message-ID: <6.2.1.2.0.20051026121805.04d6d348@mail.ozemail.com.au>

 > ?which
 > X <- matrix(2:10, nrow=3)
 > which(X == 10, arr.ind=TRUE)
      row col
[1,]   3   3

HTH,

simon.

At 11:52 AM 26/10/2005, you wrote:
>Hi netters,
>
>This is probably a silly question,but I can't find the answer after 
>searching the R-help archives online. ok, I have a matrix. I know there is 
>a "10" somewhere in it. Now I want to
>know the index of the element "10" in this matrix. That is, if X[i,j]=10, 
>I want to know
>i and j. Is there a R function to do this? Just like the "find" function 
>in matlab.
>
>Thanks all!
>
>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Simon Blomberg, B.Sc.(Hons.), Ph.D, M.App.Stat.
Centre for Resource and Environmental Studies
The Australian National University
Canberra ACT 0200
Australia
T: +61 2 6125 7800 email: Simon.Blomberg_at_anu.edu.au
F: +61 2 6125 0757
CRICOS Provider # 00120C



From jose.pinheiro at novartis.com  Wed Oct 26 04:46:01 2005
From: jose.pinheiro at novartis.com (jose.pinheiro@novartis.com)
Date: Tue, 25 Oct 2005 22:46:01 -0400
Subject: [R] Stat. Computing 2006 Chambers Award competition
Message-ID: <OF6753582B.45BD5451-ON852570A6.000F0F77-852570A6.000F356A@EU.novartis.net>

The Statistical Computing Section of the American Statistical
Association announces the competition for the John M. Chambers
Statistical Software Award. In 1998 the Association for Computing
Machinery presented its Software System Award to John Chambers for the
design and development of S. Dr. Chambers generously donated his
award to the Statistical Computing Section to endow an annual prize
for statistical software written by, or in collaboration with,
a current or recent student. Starting this year, teams of up to 3 people,
including at least one current or recent student, will be allowed to 
participate in the competition The prize carries with it a cash award 
of $1000, plus a substantial allowance for travel to the annual Joint 
Statistical
Meetings where the award will be presented. Enclosed below is the full
text of the award announcement. More details can be found at the Stat.
Computing Section website at http://www.statcomputing.org. 



Best Regards,

--Jos? Pinheiro

Awards Chair
ASA Statistical Computing Section
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: ChambersAward2006.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051025/8d5c62d6/ChambersAward2006.txt

From rramacha at utk.edu  Wed Oct 26 06:58:56 2005
From: rramacha at utk.edu (rramacha)
Date: Wed, 26 Oct 2005 00:58:56 -0400
Subject: [R] R- exp(-1000) ? - how to get R to give me an actual answer ?
Message-ID: <436A644E@webmail.utk.edu>

Dear All,

I am a novice user of the R software package. When I try and compute, 
exp(-1000) or exp(-2000), i get the answer as zero. Is there any way i can get 
R to compute the answer and give me an actual number ? ( by increasing the 
precision or any other method).

If I cannot get R to give me a number, can anybody give me some advice on how 
to manually compute this number ?

I would greatly appreciate your help on this issue.

Thanks
Ravi

Ravichandran "Ravi" Ramachandran

Graduate Teaching Assistant
Department of Statistics
The University of Tennessee,Knoxville
USA
E-mail  : ravi at utk.edu
Phone   : Official  - 865 - 974 - 2739 (Aconda Court)
          Residence - 865 - 946 - 5155
Webpage : http://web.utk.edu/~rramacha


" Space maybe the final frontier
  But its made in a Hollywood basement
                   - The Red Hot Chilli Peppers - 'Californication'

  Space maybe the final frontier
  But it can be 'replicated' in a Hollywood basement
                   - Me, after taking the Stat 573 class  
"


"Thank God every day when you get up that you have something to do that day which must be done whether you like it or not. Being forced to work and forced to do your best will breed in you temperance and self-control, diligence and strength of will"
                                                - Basil Carpenter



From BHunsicker at rfmd.com  Wed Oct 26 07:14:43 2005
From: BHunsicker at rfmd.com (Bill Hunsicker)
Date: Wed, 26 Oct 2005 01:14:43 -0400
Subject: [R] (no subject)
Message-ID: <3EA9CDD20D8E694F92C01B7BA7FC5AC8033FD503@mail.internal.rfmd.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051026/d1e6cc0e/attachment.pl

From ggrothendieck at gmail.com  Wed Oct 26 07:42:14 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 26 Oct 2005 01:42:14 -0400
Subject: [R] R- exp(-1000) ? - how to get R to give me an actual answer ?
In-Reply-To: <436A644E@webmail.utk.edu>
References: <436A644E@webmail.utk.edu>
Message-ID: <971536df0510252242hd3b5490o76334c076e831b76@mail.gmail.com>

Since log base 10 is log(x)/log(10) the exponent is:

	floor(log(exp(-1000))/log(10))
	= floor(-1000/log(10))

which in an R session gives:

	> floor(-1000/log(10))
	[1] -435

and the mantissa is:

	exp(-1000)/10^(-435)
	= exp(-1000)/exp(-435*log(10))
	= exp(-1000+435*log(10))

which in an R session gives:

	> exp(-1000+435*log(10))
	[1] 5.075959

Thus the answer is 5.075959e-435 though, of course,
we can't represent that directly on your computer.

We can double check this with yacas which is a free
computer algebra system that supports arbitrary
precision math:

   In> N(Exp(-1000))
   Out> 0.5075958898e-434




On 10/26/05, rramacha <rramacha at utk.edu> wrote:
> Dear All,
>
> I am a novice user of the R software package. When I try and compute,
> exp(-1000) or exp(-2000), i get the answer as zero. Is there any way i can get
> R to compute the answer and give me an actual number ? ( by increasing the
> precision or any other method).
>
> If I cannot get R to give me a number, can anybody give me some advice on how
> to manually compute this number ?
>
> I would greatly appreciate your help on this issue.
>
> Thanks
> Ravi
>
> Ravichandran "Ravi" Ramachandran
>
> Graduate Teaching Assistant
> Department of Statistics
> The University of Tennessee,Knoxville
> USA
> E-mail  : ravi at utk.edu
> Phone   : Official  - 865 - 974 - 2739 (Aconda Court)
>          Residence - 865 - 946 - 5155
> Webpage : http://web.utk.edu/~rramacha
>
>
> " Space maybe the final frontier
>  But its made in a Hollywood basement
>                   - The Red Hot Chilli Peppers - 'Californication'
>
>  Space maybe the final frontier
>  But it can be 'replicated' in a Hollywood basement
>                   - Me, after taking the Stat 573 class
> "
>
>
> "Thank God every day when you get up that you have something to do that day which must be done whether you like it or not. Being forced to work and forced to do your best will breed in you temperance and self-control, diligence and strength of will"
>                                                - Basil Carpenter
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ggrothendieck at gmail.com  Wed Oct 26 07:44:49 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 26 Oct 2005 01:44:49 -0400
Subject: [R] (no subject)
In-Reply-To: <3EA9CDD20D8E694F92C01B7BA7FC5AC8033FD503@mail.internal.rfmd.com>
References: <3EA9CDD20D8E694F92C01B7BA7FC5AC8033FD503@mail.internal.rfmd.com>
Message-ID: <971536df0510252244s1c51de92v1bc777a6f3b7969a@mail.gmail.com>

Check out axis.break in the plotrix package.

On 10/26/05, Bill Hunsicker <BHunsicker at rfmd.com> wrote:
> R-Help,
>
>
>
> I am trying to do simple plots of the characteristics of cellular
> phones.  I am values that fit along an axis that has many data points
> around 800 and 1800.  I am not interested in the "dead space' between
> the two clusters of data.
>
>
>
> I am not interested in a linear axis.  I would like to "cut out" the
> white space between the two pockets of data when plotting.  I have
> included a simple example of my data set.
>
>
>
> X          Y
>
> 801       1
>
> 802       4
>
> 803       2
>
> 1800     1
>
> 1801     5
>
> 1802     3
>
>
>
> Thank you in advance.
>
>
>
> Regards,
>
> Bill
>
>
>
>
>
> Bill Hunsicker
>
> RF Micro Devices
>
> 7625 Thorndike Road
>
> Greensboro, NC  27409
>
> 336-678-5260(W)
>
> 610-579-9985(M)
>
>
>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From blomsp at ozemail.com.au  Wed Oct 26 08:00:34 2005
From: blomsp at ozemail.com.au (Simon Blomberg)
Date: Wed, 26 Oct 2005 16:00:34 +1000
Subject: [R] R- exp(-1000) ? - how to get R to give me an actual answer ?
In-Reply-To: <971536df0510252242hd3b5490o76334c076e831b76@mail.gmail.com
 >
References: <436A644E@webmail.utk.edu>
	<971536df0510252242hd3b5490o76334c076e831b76@mail.gmail.com>
Message-ID: <6.2.1.2.0.20051026155508.01c1b610@mail.ozemail.com.au>

At 03:42 PM 26/10/2005, you wrote:

>We can double check this with yacas which is a free
>computer algebra system that supports arbitrary
>precision math:
>
>    In> N(Exp(-1000))
>    Out> 0.5075958898e-434

Or in Axiom, which is open source too:

numeric exp(-1000)

  0.50759588975494567653E-434 Type: Float




>On 10/26/05, rramacha <rramacha at utk.edu> wrote:
> > Dear All,
> >
> > I am a novice user of the R software package. When I try and compute,
> > exp(-1000) or exp(-2000), i get the answer as zero. Is there any way i 
> can get
> > R to compute the answer and give me an actual number ? ( by increasing the
> > precision or any other method).
> >
> > If I cannot get R to give me a number, can anybody give me some advice 
> on how
> > to manually compute this number ?
> >
> > I would greatly appreciate your help on this issue.
> >
> > Thanks
> > Ravi
> >
> > Ravichandran "Ravi" Ramachandran
> >
> > Graduate Teaching Assistant
> > Department of Statistics
> > The University of Tennessee,Knoxville
> > USA
> > E-mail  : ravi at utk.edu
> > Phone   : Official  - 865 - 974 - 2739 (Aconda Court)
> >          Residence - 865 - 946 - 5155
> > Webpage : http://web.utk.edu/~rramacha
> >
> >
> > " Space maybe the final frontier
> >  But its made in a Hollywood basement
> >                   - The Red Hot Chilli Peppers - 'Californication'
> >
> >  Space maybe the final frontier
> >  But it can be 'replicated' in a Hollywood basement
> >                   - Me, after taking the Stat 573 class
> > "
> >
> >
> > "Thank God every day when you get up that you have something to do that 
> day which must be done whether you like it or not. Being forced to work 
> and forced to do your best will breed in you temperance and self-control, 
> diligence and strength of will"
> >                                                - Basil Carpenter
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From marvena at tin.it  Wed Oct 26 09:16:43 2005
From: marvena at tin.it (Marco Venanzi)
Date: Wed, 26 Oct 2005 09:16:43 +0200
Subject: [R] replacement in a dataframe
Message-ID: <001001c5d9fd$383d6c70$0501a8c0@nome65ff66cddf>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051026/d506f7d5/attachment.pl

From TobiasBr at Taquanta.com  Wed Oct 26 09:20:23 2005
From: TobiasBr at Taquanta.com (Brandt, T. (Tobias))
Date: Wed, 26 Oct 2005 09:20:23 +0200
Subject: [R] data.frame-question
Message-ID: <A77412E534FCD248A93A81F37CC75B7A033F8BDE@waxbill.africa.nedcor.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051026/1514928e/attachment.pl

From ripley at stats.ox.ac.uk  Wed Oct 26 09:49:45 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 26 Oct 2005 08:49:45 +0100 (BST)
Subject: [R] replacement in a dataframe
In-Reply-To: <001001c5d9fd$383d6c70$0501a8c0@nome65ff66cddf>
References: <001001c5d9fd$383d6c70$0501a8c0@nome65ff66cddf>
Message-ID: <Pine.LNX.4.61.0510260844070.14840@gannet.stats>

On Wed, 26 Oct 2005, Marco Venanzi wrote:

> Hi,I want to replace some elements of a dataframe "a"J, using 2 index 
vectors ("x" and "y") and a vector of replacement ("z") of the same length 
of "x" and "y".
> I've tried a[cbind(x,y)]<-z, but it doesn't work.How can I do it in a 
> simply way?Thanks,

Only logical matrix indexing is supported for data frames: See 
?"[.data.frame".  So you need to create a logical matrix index. One way 
would be

aa <- is.na(a) # create a logical matrix of the same size
aa[] <- FALSE
aa[cbind(x,y)] <- TRUE
a[aa] <- z

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From B.Rowlingson at lancaster.ac.uk  Wed Oct 26 10:17:21 2005
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 26 Oct 2005 09:17:21 +0100
Subject: [R] Writing point pattern to a file
In-Reply-To: <435EAA36.2000906@csc.ncsu.edu>
References: <435EAA36.2000906@csc.ncsu.edu>
Message-ID: <435F3B91.5070209@lancaster.ac.uk>

Ajit Chakrapani Warrier wrote:

> 	pp <- rpoispp(.01, win=owin(c(0,100),c(0,100)))

> 	But how can I export the generated point pattern to an external file so 
> that I could use it as input for some network simulation
> programs ? 

  You can get the coordinates of a point-pattern object with the $x and 
$y components. You can write to a file with R's 'write.table' function. 
So make the $x and $y components into a matrix, and use write.table. 
Here I'll use some write.table options to make a fairly clean file, 
coordinates separated by commas, with no row names, and nothing stuck in 
quote marks:

write.table(file="ppxy.csv",cbind(pp$x,pp$y),sep=",",row.names=FALSE,col.names=c('x','y'),quote=FALSE)

 > Also, it seems that the generated graph is different on each
 > invocation. Is there a way I could control this randomness, some seed
 > perhaps.

See the help for 'set.seed' - type 'help(set.seed)'

Baz



From Rau at demogr.mpg.de  Wed Oct 26 10:43:45 2005
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Wed, 26 Oct 2005 10:43:45 +0200
Subject: [R] survival frailty models
Message-ID: <8B08A3A1EA7AAC41BE24C750338754E69FDEF8@HERMES.demogr.mpg.de>

Hi,

> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of lamack lamack
> Dear all, someone could send me a introductory reference 
> about Survival 
> Frailty Models???

what about this article:
@article{vaupel79,
	author={Vaupel, James W. and Manton, Kenneth G. and Stallard,
Eric},
	title={The Impact of Heterogeneity in Individual Frailty on the
Dynamics of Mortality},
	journal={Demography},
	volume={16},
	year={1979},
	pages={439--454}
} 

Best,
Roland

+++++
This mail has been sent through the MPI for Demographic Rese...{{dropped}}



From andylehnert at gmx.de  Wed Oct 26 11:03:37 2005
From: andylehnert at gmx.de (Andreas Lehnert)
Date: Wed, 26 Oct 2005 11:03:37 +0200 (MEST)
Subject: [R] creating a matrix of "objects"
Message-ID: <8928.1130317417@www38.gmx.net>


Dear R,

I??m really new to R, so it could be that my 
question is one of those "read the manual" ones.
But I did that and found nothing.

Problem: I need to get a "matrix" of "datapoints".
         Each datapoint has to contain tree attributes.

trials like:


make.LDmatrix <- function(nrbases){

b1 <- list(sum=NA, sqrsum=NA, hits=NA)
result <- list()

for(i in seq(1,nrbases)){
	for(j in seq(1,nrbases)){
		result[[i]][[j]] <- b1
}}
result
}



did not work because of a "out of bound" error.

It would be very kind if someone could help me with this.

Thanks, Andy

-- 
Highspeed-Freiheit. Bei GMX superg??nstig, z.B. GMX DSL_Cityflat,



From Marco.Giannitrapani at shell.com  Wed Oct 26 11:55:51 2005
From: Marco.Giannitrapani at shell.com (Giannitrapani, Marco GSUK-GSSC)
Date: Wed, 26 Oct 2005 10:55:51 +0100
Subject: [R] symbolic math
Message-ID: <DC768C412F1C394192A8108281818F2B029A4563@wyt-s-019.europe.shell.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051026/d0069ea1/attachment.pl

From chaix at u707.jussieu.fr  Wed Oct 26 12:06:24 2005
From: chaix at u707.jussieu.fr (Basile Chaix)
Date: Wed, 26 Oct 2005 12:06:24 +0200
Subject: [R] Survival analysis with COXPH
Message-ID: <20051026100230.3C8449BB53@mailer.b3e.jussieu.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051026/b66b98d6/attachment.pl

From Rau at demogr.mpg.de  Wed Oct 26 12:12:22 2005
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Wed, 26 Oct 2005 12:12:22 +0200
Subject: [R] symbolic math
Message-ID: <8B08A3A1EA7AAC41BE24C750338754E69FDEFB@HERMES.demogr.mpg.de>

Hi,


> -----Original Message-----
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Giannitrapani, Marco GSUK-GSSC
> Subject: [R] symbolic math
> 
> Does anyone knows if it exists a "symbolic math" package in 
> R, that allows to compute derivatives, integrals, etc.? 

Have a look at:
?D

> 
> Does exist a freeware version of Maple?

Not really a free version of Maple, but I use Maxima. You can find it
at:
http://maxima.sourceforge.net/

There you can do things like (just a simple, stupid example):
(%i1) diff(3*x^2,x);
(%o1) 				      6 x
(%i2) integrate(6*x, x);
	   						2
(%o2) 				     3 x
(%i3) 


(the spacing is a bit unfortunate in my email now)

Best, Roland

+++++
This mail has been sent through the MPI for Demographic Rese...{{dropped}}



From S.Pickett at exeter.ac.uk  Wed Oct 26 12:09:12 2005
From: S.Pickett at exeter.ac.uk (sp219)
Date: Wed, 26 Oct 2005 11:09:12 +0100
Subject: [R] Help: partial.cor significance test
Message-ID: <4365117E@minerva2.ex.ac.uk>

Hi,
I have been using the partial.cor function in Rcmdr but I was wondering if 
there is any easy way to get statistical significance tests (two tailed) along 
with the partial correlation coefficients?
Simon Pickett

Simon Pickett
Centre for Ecology and Conservation Biology
University of Exeter in Cornwall
Tremough Campus
Penryn 
Cornwall
TR10 9EZ UK
Tel: 01326371852



From foadi at ysbl.york.ac.uk  Wed Oct 26 12:20:13 2005
From: foadi at ysbl.york.ac.uk (James Foadi)
Date: Wed, 26 Oct 2005 11:20:13 +0100
Subject: [R] symbolic math
In-Reply-To: <DC768C412F1C394192A8108281818F2B029A4563@wyt-s-019.europe.shell.com>
References: <DC768C412F1C394192A8108281818F2B029A4563@wyt-s-019.europe.shell.com>
Message-ID: <200510261120.13934.foadi@ysbl.york.ac.uk>

On Wednesday 26 October 2005 10:55, Giannitrapani, Marco GSUK-GSSC wrote:
> Hi all!
>
> Does anyone knows if it exists a "symbolic math" package in R, that allows
> to compute derivatives, integrals, etc.?
>
> Does exist a freeware version of Maple?
>
> Cheers,
>
> Marco
>
I've just learned yesterday the use of "expressions" objects to compute 
derivatives. There might be functions for doing integrals as well.

1) define an expression using whatever symbol you like

example:

> exp1 <- expression(cos(x)+sin(y))

2) Use function D() to perform symbolic derivatives:

example:

> D(exp1,"x")
-sin(x)
> D(exp1,"y")
cos(x)

 You can find this stuff in "R for Beginners", by Emmanuel Paradis 
(http://www.r-project.org/)

Cheers,

J

-- 
Dr James Foadi PhD
York Structural Biology Laboratory (YSBL)
Department of Chemistry
University of York
Heslington
York YO10 5YW
UK



From dlucy at maths.ed.ac.uk  Wed Oct 26 12:23:26 2005
From: dlucy at maths.ed.ac.uk (David Lucy)
Date: Wed, 26 Oct 2005 11:23:26 +0100
Subject: [R] Dendrogram for many cases
Message-ID: <435F591E.9010902@maths.ed.ac.uk>

Dear All,

I have a cluster object based on a 
dissimilarity matrix from about 1,100 
cases and wish to know whether anyone 
can think  of any tips to display some 
form of graphical output which would 
give some sense of the similarity 
between the cases.

A standard form of dendrogram would be 
fine, but with so many cases the 
dendrogram on the standard devices 
(R-2.20 on NT4) is very compact in the 
x-dimension. I wonder whether there is 
any way that the dendrogram can be 
subdivided into discrete pieces?

Failing that, is there any other means 
of graphically representing the 
dissimilarity matrix. I am only 
interested in the low order 
dissimilarity rather than high order 
structure between these cases.

A further constraint is that the NT4 box 
is well bolted down in that it has no 
means by which data can be transfered 
to, or from it.

Cheers,

David.


#########################################
Dr. David Lucy
School of Mathematics
JCMB
King's Buildings
Edinburgh University
Edinburgh
EH9 3JZ

tel:    0131 650 5086
e-mail: dlucy at maths.ed.ac.uk
web:    http://www.maths.ed.ac.uk/~dlucy/
#########################################



From abitbol at sent.com  Wed Oct 26 12:48:38 2005
From: abitbol at sent.com (Jean-Louis Abitbol)
Date: Wed, 26 Oct 2005 12:48:38 +0200
Subject: [R] FYI Paris CRAN mirror out ?
Message-ID: <1130323718.1735.246047804@webmail.messagingengine.com>

Good day to all,

Just for info if this can be of any use to R maintainers the update
package through the France (Paris) CRAN mirror does not seem to work.
France (Lyon)  works fine though.

The Paris mirror used to work fine a while ago (can't remember exactly
when !). 

Here is a copy of today's session (but this has occured several times in
the past few days). 

 R : Copyright 2005, The R Foundation for Statistical Computing
Version 2.2.0  (2005-10-06 r35749)
ISBN 3-900051-07-0
.....
> update.packages(ask='graphics')
--- Please select a CRAN mirror for use in this session ---

Avis : unable to access index for repository
http://mirror.internet.tp/cran/bin/windows/contrib/2.2
> 

Not a major issue but I thought I should let you know.

Regards, Jean-Louis



From RRoa at fisheries.gov.fk  Wed Oct 26 12:30:41 2005
From: RRoa at fisheries.gov.fk (Ruben Roa)
Date: Wed, 26 Oct 2005 08:30:41 -0200
Subject: [R] symbolic math
Message-ID: <03DCBBA079F2324786E8715BE538968A3DC54D@FIGMAIL-CLUS01.FIG.FK>

> -----Original Message-----
> From:	r-help-bounces at stat.math.ethz.ch [SMTP:r-help-bounces at stat.math.ethz.ch] On Behalf Of Giannitrapani, Marco GSUK-GSSC
> Sent:	Wednesday, October 26, 2005 7:56 AM
> To:	r-help at stat.math.ethz.ch
> Subject:	[R] symbolic math
> 
> Hi all!
> 
> Does anyone knows if it exists a "symbolic math" package in R, that allows to compute derivatives, integrals, etc.? 
> 
> Does exist a freeware version of Maple?
> 
--------
I think Maxima is pretty cool:
http://maxima.sourceforge.net/
Ruben



From paulojus at est.ufpr.br  Wed Oct 26 13:59:30 2005
From: paulojus at est.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Wed, 26 Oct 2005 09:59:30 -0200 (BRST)
Subject: [R] symbolic math
In-Reply-To: <03DCBBA079F2324786E8715BE538968A3DC54D@FIGMAIL-CLUS01.FIG.FK>
References: <03DCBBA079F2324786E8715BE538968A3DC54D@FIGMAIL-CLUS01.FIG.FK>
Message-ID: <Pine.LNX.4.63.0510260958510.17893@est.ufpr.br>

Yet another option is "axiom"

In a debian-type linux:

apt-get install axiom


On Wed, 26 Oct 2005, Ruben Roa wrote:

>> -----Original Message-----
>> From:	r-help-bounces at stat.math.ethz.ch [SMTP:r-help-bounces at stat.math.ethz.ch] On Behalf Of Giannitrapani, Marco GSUK-GSSC
>> Sent:	Wednesday, October 26, 2005 7:56 AM
>> To:	r-help at stat.math.ethz.ch
>> Subject:	[R] symbolic math
>>
>> Hi all!
>>
>> Does anyone knows if it exists a "symbolic math" package in R, that allows to compute derivatives, integrals, etc.?
>>
>> Does exist a freeware version of Maple?
>>
> --------
> I think Maxima is pretty cool:
> http://maxima.sourceforge.net/
> Ruben
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>

Paulo Justiniano Ribeiro Jr
LEG (Laborat?rio de Estat?stica e Geoinforma??o)
Departamento de Estat?stica
Universidade Federal do Paran?
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 3361 3573
Fax: (+55) 41 3361 3141
e-mail: paulojus at est.ufpr.br
http://www.est.ufpr.br/~paulojus

From jfox at mcmaster.ca  Wed Oct 26 14:15:33 2005
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 26 Oct 2005 08:15:33 -0400
Subject: [R] Help: partial.cor significance test
In-Reply-To: <4365117E@minerva2.ex.ac.uk>
Message-ID: <20051026121530.UMAQ16985.tomts36-srv.bellnexxia.net@JohnDesktop8300>

Dear Simon,

The population partial correlation rho[12|3...p] is 0 when the regression
coefficient beta[2] for x[2] from the regression of x[1] on x[2] ... X[p] is
0. Thus, the usual t-test for a regression coefficient also tests that the
partial correlation is 0.

Now, the sample partial correlation r[12|3...p] = t/sqrt(t^2 + dfe)) where
dfe = n - p is the degrees of freedom for error and t is the t-statistic for
testing that beta[2] is 0, and thus t = sqrt(dfe*r^2[12|3...p]/(1 -
r^2[12|3...p])), so it is easy to compute the (unsigned) t-statistics from
the partial correlations.

Why one would want to do this, however, is another matter. What would one do
with a matrix of 2-sided p-values?

Regards,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of sp219
> Sent: Wednesday, October 26, 2005 5:09 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Help: partial.cor significance test
> 
> Hi,
> I have been using the partial.cor function in Rcmdr but I was 
> wondering if there is any easy way to get statistical 
> significance tests (two tailed) along with the partial 
> correlation coefficients?
> Simon Pickett
> 
> Simon Pickett
> Centre for Ecology and Conservation Biology University of 
> Exeter in Cornwall Tremough Campus Penryn Cornwall TR10 9EZ UK
> Tel: 01326371852
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From jan.wiener at tuebingen.mpg.de  Wed Oct 26 14:32:59 2005
From: jan.wiener at tuebingen.mpg.de (Jan Wiener)
Date: Wed, 26 Oct 2005 14:32:59 +0200
Subject: [R] another ANOVA/LM question
Message-ID: <435F777B.7040005@tuebingen.mpg.de>

Sorry for posting a possibly stupid question.

I am using aov() for calculating ANOVA as follows:

summary(aov(depVar~factor1*factor2+Error(subject/(factor1+factor2)), 
data=anovaAllData))

and usually all works fine.

How exactly the call has to look if I want to use lm() directly to 
obtain the same results.

The problem is that due to several reasons I am missing single data 
points such that I end up with an unbalanced design. From earlier 
posting I learned that lm() is the way to go in such cases.

However, I do not know how exactly the formula  including the error term 
has to look like for lm().

Hope that made sense,

Thanks in advance,
Jan



From nassar at noos.fr  Wed Oct 26 14:09:24 2005
From: nassar at noos.fr (Naji)
Date: Wed, 26 Oct 2005 14:09:24 +0200
Subject: [R] Pb encountered with demos
Message-ID: <BF853E94.76DC%nassar@noos.fr>

Hi all,


I've just installed R on my Mac & PC.
The base demo run fine.. But I'm encountering several pb with some packages
(installed using CRAN binaries using the menu)
- Lattice:
> demo(lattice,package='lattice')

    demo(lattice)
    ---- ~~~~~~~
Type  <Return>     to start :
> require(grid)
[1] TRUE
> old.prompt <- grid.prompt(TRUE)
> old.settings <- trellis.par.get()
Erreur dans eval.with.vis(expr, envir, enclos) :
    impossible de trouver la fonction "trellis.par.get"
- Zelig
> demo(poisson,package='Zelig')
    demo(poisson)
    ---- ~~~~~~~
Type  <Return>     to start :
> data(sanction)
> user.prompt()
Erreur dans eval.with.vis(expr, envir, enclos) :
    impossible de trouver la fonction "user.prompt"
De plus : Warning message:
data set 'sanction' not found in: data(sanction)

Is there something wrong in the settings?
Thanks helping me to fix this

Naji
 
Mac
platform powerpc-apple-darwin7.9.0
arch     powerpc   
os       darwin7.9.0
system   powerpc, darwin7.9.0
status             
major    2         
minor    2.0       
year     2005      
month    10        
day      06        
svn rev  35749     
language R         
PC
platform i386-pc-mingw32
arch     i386      
os       mingw32   
system   i386,mingw32
status             
major    2         
minor    2.0       
year     2005      
month    10        
day      06        
svn rev  35749     
language R



From ezhil02 at yahoo.com  Wed Oct 26 14:40:12 2005
From: ezhil02 at yahoo.com (A Ezhil)
Date: Wed, 26 Oct 2005 05:40:12 -0700 (PDT)
Subject: [R] Storing graphics output in PNG format.
Message-ID: <20051026124012.35486.qmail@web32110.mail.mud.yahoo.com>

Dear All,

How can I store hist() or any plot output graphics in
PNG format? I tried with bitmap() but not getting the
result. Appreciate your help on fixing this.

Thanks in Advance.

Regrads,
Ezhil



From sdavis2 at mail.nih.gov  Wed Oct 26 14:44:25 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Wed, 26 Oct 2005 08:44:25 -0400
Subject: [R] Storing graphics output in PNG format.
In-Reply-To: <20051026124012.35486.qmail@web32110.mail.mud.yahoo.com>
Message-ID: <BF84F269.11C95%sdavis2@mail.nih.gov>

On 10/26/05 8:40 AM, "A Ezhil" <ezhil02 at yahoo.com> wrote:

> Dear All,
> 
> How can I store hist() or any plot output graphics in
> PNG format? I tried with bitmap() but not getting the
> result. Appreciate your help on fixing this.

help.search('png')

Or

?png 

Gets you the answer.

png('file.png')
hist(x)
dev.off()

Sean



From mcardeal at ufba.br  Wed Oct 26 14:45:14 2005
From: mcardeal at ufba.br (Carlos Mauricio Cardeal Mendes)
Date: Wed, 26 Oct 2005 09:45:14 -0300
Subject: [R] correct rate
Message-ID: <435F7A5A.7090100@ufba.br>

Hi everone !

I know its not a epidemiologic or statistic list, but since I??m using R 
to solve related problems ... here it goes:

This is a code to solve the rate problem, but the real question is: 
what??s the correct way to calculate the period rate (3 years period put 
together)
The third option is quite different (middle period).
Any suggestions ?

Thanks
Mauricio, Brazil

# Example from Field epidemiology basics computer lab 1

# annual period rates (1989, 1990, 1991)

years <- 1989:1991
deaths <- c(125, 130, 131)
pop <- c(361975, 361401, 366613)

# rates and rates per 10.000 per year
rates <- deaths/pop
ratesf <- round(rates*10000,digits=2)
rates
ratesf

# to calculate the period rate we have 3 possibilities:

# 1) sum of deaths by sum of populations:

rates89_91_1 <- sum(deaths)/sum(pop)
rates89_91f_1 <- round(rates89_91_1*10000,digits=2)
rates89_91_1
rates89_91f_1

# 2) mean rates:

rates89_91_2 <- (rates[1]+rates[2]+rates[3])/3
rates89_91f_2 <- round(rates89_91_2*10000,digits=2)
rates89_91_2
rates89_91f_2

# 3) sum of deahts by middle population (1990):

rates89_91_3 <- (deaths[1]+deaths[2]+deaths[3])/pop[2]
rates89_91f_3 <- round(rates89_91_3*10000,digits=2)
rates89_91_3
rates89_91f_3



From ccleland at optonline.net  Wed Oct 26 14:47:10 2005
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 26 Oct 2005 08:47:10 -0400
Subject: [R] Storing graphics output in PNG format.
In-Reply-To: <20051026124012.35486.qmail@web32110.mail.mud.yahoo.com>
References: <20051026124012.35486.qmail@web32110.mail.mud.yahoo.com>
Message-ID: <435F7ACE.1050600@optonline.net>

?png

For example:

 > png("c:/myplot.png")
 > plot(rnorm(100))
 > dev.off()

A Ezhil wrote:
> Dear All,
> 
> How can I store hist() or any plot output graphics in
> PNG format? I tried with bitmap() but not getting the
> result. Appreciate your help on fixing this.
> 
> Thanks in Advance.
> 
> Regrads,
> Ezhil
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From francoisromain at free.fr  Wed Oct 26 14:54:38 2005
From: francoisromain at free.fr (Romain Francois)
Date: Wed, 26 Oct 2005 14:54:38 +0200
Subject: [R] Storing graphics output in PNG format.
In-Reply-To: <20051026124012.35486.qmail@web32110.mail.mud.yahoo.com>
References: <20051026124012.35486.qmail@web32110.mail.mud.yahoo.com>
Message-ID: <435F7C8E.3080109@free.fr>

Le 26.10.2005 14:40, A Ezhil a ??crit :

>Dear All,
>
>How can I store hist() or any plot output graphics in
>PNG format? I tried with bitmap() but not getting the
>result. Appreciate your help on fixing this.
>
>Thanks in Advance.
>
>Regrads,
>Ezhil
>  
>
Hi,

You should try png then.
?png
BTW, There is a link to png on the bitmap help page, so you were close 
to the target.

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+



From alanc at umit.maine.edu  Wed Oct 26 14:52:36 2005
From: alanc at umit.maine.edu (Alan Cobo-Lewis)
Date: Wed, 26 Oct 2005 08:52:36 -0400
Subject: [R] R-help Digest, Vol 32, Issue 26
In-Reply-To: <mailman.14.1130320801.9508.r-help@stat.math.ethz.ch>
References: <mailman.14.1130320801.9508.r-help@stat.math.ethz.ch>
Message-ID: <fc.004c4d19237bffcb3b9aca009bb85035.237c05c2@umit.maine.edu>

r-help at stat.math.ethz.ch on Wednesday, October 26, 2005 at 6:00 AM -0500 wrote:

Ronaldo,
Try Harold's suggestion. The df still won't agree, because lmer (at least in its current version) just puts an upper bound on the df. But that should be OK, because all those t tests are approximations anyways, and you can get better confidence
intervals (credible intervals, whatever) by using the mcmcsamp() function that works with lmer()
alan

>
"Doran, Harold" <HDoran at air.org> responded:
>
>
>>There is an issue with implicit nesting in lmer. In your lme() model you nest
>>block/irrigation/density/fertilizer. In lmer you need to do something like
>>(I dind't include all of your variables, but I think the makes the point)
>>
>>lmer(yield~irrigation*density*fertilizer+(1|fertilizer:density)+(1|density), data)
>>
>>Which notes that fertilizer is nested in density. 
>>
>>Try this and then compare the results. 
>
"Ronaldo Reis-Jr." <chrysopa at gmail.com>, wrote:
>
>>I make the correct model with aov, lme do compare with lmer.
>
>>But I cant make a correct model in lmer. Look that the aov and lme results are
>>similars, but very different from lmer. In aov and lme is used the correct DF
>>for each variable, in lmer it use a same DF for all? Denom=54.
>

--
Alan B. Cobo-Lewis, Ph.D.		(207) 581-3840 tel
Department of Psychology		(207) 581-6128 fax
University of Maine
Orono, ME 04469-5742     		alanc at maine.edu

http://www.umaine.edu/visualperception



From karin.lagesen at medisin.uio.no  Wed Oct 26 14:52:09 2005
From: karin.lagesen at medisin.uio.no (Karin Lagesen)
Date: Wed, 26 Oct 2005 14:52:09 +0200
Subject: [R] horizontal violin plots?
Message-ID: <ypx6sluoa1ae.fsf@uracil.uio.no>


I am trying to make horizontal violin plots. I have tried both vioplot
and simple.violinplot, but both of them seem to not be willing to take
the horizontal option. Is this correct, or am I just bungling it
somehow?

For instance, for vioplot (from the example shown, with the horizontal
modification):


> vioplot(bimodal,uniform,normal, horizontal=TRUE)
Error in median(data) : need numeric data
> 

Karin
-- 
Karin Lagesen, PhD student
karin.lagesen at medisin.uio.no
http://www.cmbn.no/rognes/



From wilks at dial.pipex.com  Wed Oct 26 15:05:57 2005
From: wilks at dial.pipex.com (John Wilkinson (pipex))
Date: Wed, 26 Oct 2005 14:05:57 +0100
Subject: [R] lme and lmer syntax
Message-ID: <JCEIJNOHMNBPLMGFDHNDOECKCBAA.wilks@dial.pipex.com>

Ronaldo,

According to Douglas Bates's paper in 'R' News, It would seem that the
correct model for nested split plot random effects with lmer , in your
example ,with x2 nested within x1, would be --

lmer(y~x1 + x2 +(1|x1)+(1|x1:x2))

Try it with your model any see how it compares with your aov and lme models,

John


m Seg 24 Out 2005 18:08, Doran, Harold escreveu:
> Ronaldo
>
> See the article on lmer pasted below for syntax. It is the only current
> source documenting the code. In lmer(), the nesting structure for the
> ranmdom effects is handled in a slightly different way. If your
> observations are nested as you note, then you can use
>
> > lmer(y~x1 + x2 +(1|x1) + (1|x2), data)
>
> @Article{Rnews:Bates:2005,
>   author       = {Douglas Bates},
>   title	       = {Fitting Linear Mixed Models in {R}},
>   journal      = {R News},
>   year	       = 2005,
>   volume       = 5,
>   number       = 1,
>   pages	       = {27--30},
>   month	       = {May},
>   url	       = {http://CRAN.R-project.org/doc/Rnews/},
> }
>

Hi,

I try this with a splitsplitplot example.

I make the correct model with aov, lme do compare with lmer.

But I cant make a correct model in lmer. Look that the aov and lme results
are
similars, but very different from lmer. In aov and lme is used the correct
DF
for each variable, in lmer it use a same DF for all? Denom=54.

What is my mistake?

Thanks
Ronaldo



From HDoran at air.org  Wed Oct 26 15:15:50 2005
From: HDoran at air.org (Doran, Harold)
Date: Wed, 26 Oct 2005 09:15:50 -0400
Subject: [R] R-help Digest, Vol 32, Issue 26
Message-ID: <F5ED48890E2ACB468D0F3A64989D335ACDC335@dc1ex3.air.org>

In addition to the response below, Doug Bates has talked about this on
this list previously. I did

> RSiteSearch('bates degrees of freedom lmer')

The first one that came up has Doug's response to this question as well

Harold
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Alan Cobo-Lewis
Sent: Wednesday, October 26, 2005 8:53 AM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] R-help Digest, Vol 32, Issue 26

r-help at stat.math.ethz.ch on Wednesday, October 26, 2005 at 6:00 AM -0500
wrote:

Ronaldo,
Try Harold's suggestion. The df still won't agree, because lmer (at
least in its current version) just puts an upper bound on the df. But
that should be OK, because all those t tests are approximations anyways,
and you can get better confidence intervals (credible intervals,
whatever) by using the mcmcsamp() function that works with lmer() alan

>
"Doran, Harold" <HDoran at air.org> responded:
>
>
>>There is an issue with implicit nesting in lmer. In your lme() model 
>>you nest block/irrigation/density/fertilizer. In lmer you need to do 
>>something like (I dind't include all of your variables, but I think 
>>the makes the point)
>>
>>lmer(yield~irrigation*density*fertilizer+(1|fertilizer:density)+(1|den
>>sity), data)
>>
>>Which notes that fertilizer is nested in density. 
>>
>>Try this and then compare the results. 
>
"Ronaldo Reis-Jr." <chrysopa at gmail.com>, wrote:
>
>>I make the correct model with aov, lme do compare with lmer.
>
>>But I cant make a correct model in lmer. Look that the aov and lme 
>>results are similars, but very different from lmer. In aov and lme is 
>>used the correct DF for each variable, in lmer it use a same DF for
all? Denom=54.
>

--
Alan B. Cobo-Lewis, Ph.D.		(207) 581-3840 tel
Department of Psychology		(207) 581-6128 fax
University of Maine
Orono, ME 04469-5742     		alanc at maine.edu

http://www.umaine.edu/visualperception

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From billthebrute at yahoo.fr  Wed Oct 26 15:17:34 2005
From: billthebrute at yahoo.fr (william ritchie)
Date: Wed, 26 Oct 2005 15:17:34 +0200 (CEST)
Subject: [R] hclust leaf color
Message-ID: <20051026131735.70489.qmail@web86807.mail.ukl.yahoo.com>

Hello everyone,

I wanted to know if it was possible to change the color of certain leaves in a
hclust object in order to make my graph more readable. I know I can color
certain groups but I would like to enter a vector telling the plot function
which leaves to color in which color.

Thanks in advance,

William.



From h.wickham at gmail.com  Wed Oct 26 15:19:18 2005
From: h.wickham at gmail.com (hadley wickham)
Date: Wed, 26 Oct 2005 08:19:18 -0500
Subject: [R] creating a matrix of "objects"
In-Reply-To: <8928.1130317417@www38.gmx.net>
References: <8928.1130317417@www38.gmx.net>
Message-ID: <f8e6ff050510260619n3e18edcay6890dd2271cbc67d@mail.gmail.com>

> Problem: I need to get a "matrix" of "datapoints".
>          Each datapoint has to contain tree attributes.

Have you tried:

m <- matrix(list(), nrbases, nrbases)

?  You would then index it using m[[i,j]].    A list is a basic
vector, so you can make a matrix with it, just as you can with a
vector of numbers.

Hadley



From wl at eimb.ru  Wed Oct 26 15:23:36 2005
From: wl at eimb.ru (Wladimir Eremeev)
Date: Wed, 26 Oct 2005 17:23:36 +0400
Subject: [R] Please, recommend a method to rank factors
Message-ID: <1618204398.20051026172336@eimb.ru>

Hello all.

I have several time series of several variables.
One of them is the result, and others are believed to be the factors,
influencing the result.
There is a correlation between the result and an each factor.
Those factors, in turn, are correlated to each other.

I need to build a table, which would show, say, that the result is most
dependent on factor 3; factor 1 has the second greatest effect on the
result, etc...

I've heard, there are several statistical methodics exist, which could
rank the factors, however, I was unable to find them.

Please, could you give me a clue, which method to use, in order to
build the ranking of the factors.

Thank you very much in advance.

---
Best regards,
Wladimir                mailto:wl at eimb.ru



From sara at gmesintra.com  Wed Oct 26 15:33:48 2005
From: sara at gmesintra.com (Sara Mouro)
Date: Wed, 26 Oct 2005 14:33:48 +0100
Subject: [R] Plots of Jest,Jdot, Jcross - legend?
Message-ID: <200510261333.j9QDXseB000400@hypatia.math.ethz.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051026/3e1fb810/attachment.pl

From francoisromain at free.fr  Wed Oct 26 15:41:28 2005
From: francoisromain at free.fr (Romain Francois)
Date: Wed, 26 Oct 2005 15:41:28 +0200
Subject: [R] horizontal violin plots?
In-Reply-To: <ypx6sluoa1ae.fsf@uracil.uio.no>
References: <ypx6sluoa1ae.fsf@uracil.uio.no>
Message-ID: <435F8788.90108@free.fr>

Le 26.10.2005 14:52, Karin Lagesen a ??crit :

>I am trying to make horizontal violin plots. I have tried both vioplot
>and simple.violinplot, but both of them seem to not be willing to take
>the horizontal option. Is this correct, or am I just bungling it
>somehow?
>
>For instance, for vioplot (from the example shown, with the horizontal
>modification):
>
>
>  
>
>>vioplot(bimodal,uniform,normal, horizontal=TRUE)
>>    
>>
>Error in median(data) : need numeric data
>  
>
>
>Karin
>  
>
Hello Karin,

the vioplot package only contains one function : vioplot of about only 
150 lines.
It won't be hard to look at that code and add an argument horizontal 
yourself. You just have to replace x by y and vice versa in all the 
lines, rect, ... calls. Maybe you can contribute it afterwards.

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+



From bill.shipley at usherbrooke.ca  Wed Oct 26 15:38:27 2005
From: bill.shipley at usherbrooke.ca (Bill Shipley)
Date: Wed, 26 Oct 2005 09:38:27 -0400
Subject: [R] help with a self-starting function in nonlinear least squares
	regression.
Message-ID: <001b01c5da32$8c24d050$9a1ad284@BIO041>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051026/0e6a2296/attachment.pl

From wsetzer at mindspring.com  Wed Oct 26 15:56:11 2005
From: wsetzer at mindspring.com (Woodrow Setzer)
Date: Wed, 26 Oct 2005 09:56:11 -0400 (GMT-04:00)
Subject: [R]  solving ODE's in matrix form with lsoda()
Message-ID: <8959038.1130334972142.JavaMail.root@mswamui-valley.atl.sa.earthlink.net>

Jorge,
If you'll send me details of the error messages, I'll see what I can do to help.  I notice in your posting there is a missing ')' in the next to last line of model, but no error message; I don't suppose that could have anything to do with it?
(send the details to my work email: setzer.woodrow AT epa DOT gov).

In general, I'm willing to help people trying to use lsoda, but it is generally better to email me directly (as the package author, as recommended in the posting guide) rather than through r-help.

Woody Setzer

Woodrow Setzer
National Center for Computational Toxicology
US Environmental Protection Agency
Research Triangle Park, NC 27711



From herodote at oreka.com  Wed Oct 26 16:01:06 2005
From: herodote at oreka.com (=?iso-8859-1?Q?herodote@oreka.com?=)
Date: Wed, 26 Oct 2005 15:01:06 +0100
Subject: [R] =?iso-8859-1?q?reading_big_data_frame?=
Message-ID: <IOZ09U$2A6E3CEE824946B4EE3AB35DC53A79A7@oreka.com>

hy all,

I'm under linux,
I have now a big file (45 m??ga bytes), this file is a line of header defining the names of the columns, the rows are only integers and there is 75 columns (and 239096 rows included the header).

Before working with this big file i was working with another one (1.7 m??ga bytes) , loading it with read.table("data.dat",h=T) (i've tested too with scan("data.dat",what="integer",skip=1)), there where no problems, it where taken approx 1 sec to load it into R.

but now with the big file R it seems that R stay stuck (i've wait more than 5 minutes and R don't come back from the read.table function, i've tested with scan("data.dat",what="integer",skip=1)). 

I say it stay stuck because i've spy R with the linux "top" command line, and R begin to take all my memory (no prob with that) and 100% of my cpu (no prob too), then after 3 or 4 minutes it take only 3% of cpu and the memory allocated to R is average 90%, but R never come back from these functions (or i haven't wait enough, and i need to give a result as speed as i can unfortunatly).

I've divided the size of the file by 2 , then it works (i've only tested with scan) but it is too slow...

Are there some solutions to load it in one piece?
Or have i to truncate the file and access it piece by piece?


thks all
guillaume.



From subianto at gmail.com  Wed Oct 26 16:18:13 2005
From: subianto at gmail.com (Muhammad Subianto)
Date: Wed, 26 Oct 2005 16:18:13 +0200
Subject: [R] How to convert time to days
Message-ID: <435F9025.10908@gmail.com>

Dear all,
I have ran a simulation in R.
This simulation was running about at least two days.
Here is below the result some part of my code about time result.
I don't understand about

Start time: Mon Oct 24, 2005  at  04:23:01 PM
 Finish time: Wed Oct 26, 2005  at  03:26:19 PM
    Run time: 1.960625 secs.

This is about two seconds or one day and nine hours?
Then, how could I convert to 1 day, 23 hours, ? minutes, ? seconds.
Thanks you very much for any suggestions.

Best wishes, Muhammad Subianto

 > 
################################################################################
 > # Begin of program and timestamp:
 >   cat(format(begin.time <- Sys.time(), "%a %b %d %X %Y") ,"\n")
Mon Oct 24 04:23:01 PM 2005
 >   cat("Start time:", secs <- format(begin.time, "%X"), "\n")
Start time: 04:23:01 PM
 >   cat("Sys.time:", begin.time <- Sys.time(), '\n')
Sys.time: 1130163781
 >
 >  
--- CODE SIMULATION ---
 >
 > # End of program and timestamp:
 >  cat("Sys.time:",end.time <- Sys.time(), '\n')
Sys.time: 1130333179
 >  cat("Run Time:",end.time-begin.time, 'secs.\n\n')
Run Time: 1.960625 secs.

 >  cat("Finish time:", secs <- format(end.time, "%X"), "\n")
Finish time: 03:26:19 PM
 >  cat(format(end.time <- Sys.time(), "%a %b %d %X %Y") ,"\n")
Wed Oct 26 03:26:19 PM 2005
 >
 >  cat("\n",
+      " Start time:", secs  <- format(begin.time, "%a %b %d, %Y  at  
%X"), "\n",
+      "Finish time:", secs <- format(end.time,   "%a %b %d, %Y  at  
%X"), "\n",
+      "   Run time:", end.time-begin.time, 'secs.\n\n')

  Start time: Mon Oct 24, 2005  at  04:23:01 PM
 Finish time: Wed Oct 26, 2005  at  03:26:19 PM
    Run time: 1.960625 secs.

 > 
###########################################################################



From wsetzer at mindspring.com  Wed Oct 26 16:18:54 2005
From: wsetzer at mindspring.com (Woodrow Setzer)
Date: Wed, 26 Oct 2005 10:18:54 -0400 (GMT-04:00)
Subject: [R]  solving ODE's in matrix form with lsoda()
Message-ID: <25882022.1130336334613.JavaMail.root@mswamui-chipeau.atl.sa.earthlink.net>

Just a followup.  I suppose you meant something like this:

library(odesolve)

y <- c(10, 20, 10, 20)
parms <- matrix(c(0.05, 0.1, 0.2, 0.05, 0.1, 0.2), nc=3, byrow=T)
 model <- function(times, y, parms) {
   P <- y[1:2]
   V <- y[3:4]
   beta <- parms[,1]
   mu <- parms[,2]
   r <- parms[,3]
   dPdT <- beta*P*V - mu*P
   dVdt <- r*V - beta*P*V
   list(c(dPdT, dVdt))
 }

out <- lsoda(y, times=(0:100), model, parms)

which gives the following output (for the first 8 time units) and no errors or warnings:

> source("C:/home/testode.R")
> out
       time          1            2           3            4
  [1,]    0 10.0000000 20.000000000 10.00000000 2.000000e+01
  [2,]    1 13.7603737 33.615668238  6.72208454 6.079882e+00
  [3,]    2 16.1560654 35.516702438  3.85780113 1.275331e+00
  [4,]    3 16.8730079 33.195852918  2.05089685 2.778086e-01
  [5,]    4 16.4682671 30.260712324  1.08485347 6.942984e-02
  [6,]    5 15.5186874 27.434895458  0.59474861 2.006117e-02
  [7,]    6 14.3655789 24.839030740  0.34399530 6.638867e-03
  [8,]    7 13.1757074 22.479990536  0.21106101 2.486824e-03
  [9,]    8 12.0240882 20.342411249  0.13733214 1.042244e-03

Perhaps you have some errors in your model code?

Woody

Woodrow Setzer
National Center for Computational Toxicology
US Environmental Protection Agency
Research Triangle Park, NC 27711



From francoisromain at free.fr  Wed Oct 26 16:27:36 2005
From: francoisromain at free.fr (Romain Francois)
Date: Wed, 26 Oct 2005 16:27:36 +0200
Subject: [R] hclust leaf color
In-Reply-To: <20051026131735.70489.qmail@web86807.mail.ukl.yahoo.com>
References: <20051026131735.70489.qmail@web86807.mail.ukl.yahoo.com>
Message-ID: <435F9258.3070304@free.fr>

Le 26.10.2005 15:17, william ritchie a ??crit :

>Hello everyone,
>
>I wanted to know if it was possible to change the color of certain leaves in a
>hclust object in order to make my graph more readable. I know I can color
>certain groups but I would like to enter a vector telling the plot function
>which leaves to color in which color.
>
>Thanks in advance,
>
>William.
>  
>
Hi William,

check these on RGG :
http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=79
http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=98

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+



From HStevens at muohio.edu  Wed Oct 26 16:43:00 2005
From: HStevens at muohio.edu (Martin Henry H. Stevens)
Date: Wed, 26 Oct 2005 10:43:00 -0400
Subject: [R] changing memory limits to speed up lsoda
Message-ID: <1467B320-C0F6-4611-9BD3-5AB1C0F8CEB8@muohio.edu>

Hi All,
I am running R 2.2.0 on Mac OS 10.4.2, dual G5 processors with 8 Gig  
RAM.
I am running a simulation with lsoda that requires ~378 s to complete  
one set of time intervals. I need to optimize the parameters, and so  
need to considerably speed up the simulation.
I have tried to figure out how to change the appropriate memory  
allocation and have search R help and Introductory information and  
the archives, but connot figure out how to allocate more to the right  
place.
I would greatly appreciate any pointers or tips or leads.
Thank you,
Hank Stevens


Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"



From RKrug at sun.ac.za  Wed Oct 26 16:46:06 2005
From: RKrug at sun.ac.za (Rainer M. Krug)
Date: Wed, 26 Oct 2005 16:46:06 +0200
Subject: [R] install.packages under SuSE 10 behind proxy, R 2.2.0 from source
Message-ID: <435F96AE.9030709@sun.ac.za>

Hi

I installed R 2.2.0 from source and want to use install.packages but it 
doesn't work.

http_proxy is set to http://proxy.sun.ac.za:3128

but it still can't connect to the repository.
The mirror is available, I can connect to it via the internet.

Any help welcome,

Rainer



-- 
NEW TELEPHONE NUMBER
Tel:		+27 - (0)72 808 2975 (w)

Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
Biology (UCT)

Department of Conservation Ecology
University of Stellenbosch
Matieland 7602
South Africa

Tel:		+27 - (0)72 808 2975 (w)
Fax:		+27 - (0)21 808 3304
Cell:		+27 - (0)83 9479 042

email:	RKrug at sun.ac.za
       	Rainer at krugs.de



From Setzer.Woodrow at epamail.epa.gov  Wed Oct 26 17:03:24 2005
From: Setzer.Woodrow at epamail.epa.gov (Setzer.Woodrow@epamail.epa.gov)
Date: Wed, 26 Oct 2005 11:03:24 -0400
Subject: [R] changing memory limits to speed up lsoda
In-Reply-To: <7510ABDD-BC48-4A99-9FDE-79F93D5AF082@muohio.edu>
Message-ID: <OFF7A7F3D3.11F3F167-ON852570A6.00524C7F-852570A6.0052B54A@epamail.epa.gov>

Hank,
I don't understand why you think memory is the problem, here.  I'd try
writing my model in C or Fortran (there is an example in the odesolve
package).  That speeds things up a lot, and is what I do with slow
systems.
R. Woodrow Setzer, Jr.
National Center for Computational Toxicology
US Environmental Protection Agency
Mail Drop B205-01/US EPA/RTP, NC 27711
Ph: (919) 541-0128    Fax: (919) 541-1194


                                                                        
             "Martin Henry H.                                           
             Stevens"                                                   
             <HStevens at muohio                                        To 
             .edu>                    Woodrow Setzer/RTP/USEPA/US at EPA   
                                                                     cc 
             10/26/2005 10:45                                           
             AM                                                 Subject 
                                      changing memory limits to speed   
                                      up lsoda                          
                                                                        
                                                                        
                                                                        
                                                                        
                                                                        
                                                                        




Hi Woody,
I sent this to r-help as well. Thanks in advance for any input.

I am running R 2.2.0 on Mac OS 10.4.2, dual G5 processors with 8 Gig
RAM.
I am running a simulation with lsoda that requires ~378 s to complete
one set of time intervals. I need to optimize the parameters, and so
need to considerably speed up the simulation.
I have tried to figure out how to change the appropriate memory
allocation and have search R help and Introductory information and
the archives, but connot figure out how to allocate more to the right
place.
I would greatly appreciate any pointers or tips or leads.

Thank you,
Hank Stevens


Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"



From maehlmann at wiso.uni-koeln.de  Tue Oct 25 17:50:32 2005
From: maehlmann at wiso.uni-koeln.de (=?iso-8859-1?Q?Thomas_M=E4hlmann?=)
Date: Tue, 25 Oct 2005 17:50:32 +0200
Subject: [R] Beginner question on apply()
Message-ID: <200510261548.RAA08113@wiso-5.wiso.Uni-Koeln.DE>

Dear all,

I am an beginner with R and I have a question concerning apply(). My problem
is as follows:

I have data on four variables (x1,x2,x3,x4) with missing values for x1 and
x2. 

> data[1:9,]
   x1 x2 x3 x4
1  NA NA 10  1
2  NA NA  8  3
3  NA NA 13  7
4   9  9  9  9
5  11 14 20 10
6  14 14 14 15
7   6  6  6  8
8   4  4  4 19
9  12 12 12  8
.....

I would like to replace the missing values by values sampled from the
conditional distribution p(x1,x2|x3,x4) of x1 and x2, given the observed
data on x3 and x4.
This conditional distribution is specified as a product of two normals:
p1(x1|x2,x3,x4)*p2(x2|x3,x4), where the mean of p1 is given by 
a1*x2+a2*x3+a4*x4 and for p2 the mean is b1*x3+b2*x4.(Note that the means
change for every observation)

I use Adaptive Rejection Metropolis Sampling (function arms() from package
HI) to draw values from p(x1,x2|x3,x4). My code is:

### Begin of function
> myfunction <- function() {

###  1. Step: Definition of my log density
log(p1(x1|x2,x3,x4)*p2(x2|x3,x4)), assuming values for (a1,a2,a3) and
(b1,b2)

> mylogdensity <- function(x){
+ log(prod(dnorm(x[1], mean=0.1*x[2]+0.4*x3+0.9*x4), dnorm(x[2],
mean=2*x3-3.1*x4)))}

###  2. Step: Drawing 1000 samples from this density

> y <- arms(c(0,0), mylogdensity, function(x) crossprod(x)<=1e6, 1000)

###  3. Step: replacing the missing values by the sampled values
 
> newdata <- data.frame(x1=y[,1], x2=y[,2], x3=rep(x3, 1000), x4=rep(x4,
1000))
}
### End of function


To apply this procedure to every observation (row) with missing data on x1
and x2, I use:

> ifelse(is.na(x1), apply(data, 1, myfunction), newdata <- dataframe(x1=x1,
x2=x2, x3=x3, x4=x4))

After this I get the error message

Error in FUN(newX[, i], ...) : unused argument(s) ( ...)


I have no idea about the meaning of this message and where the error is
(contained in the "ifelse"-statement or already in the definiton of
"myfunction"?)

Any help is highly appreciated!!

Best wishes,
Thomas


-------
Thomas M??hlmann
Department of Economics
University of Cologne
Albertus-Magnus Platz
50923 Koeln
Germany
Tel: (0049) +221-4702628
Fax: (0049) +221-4702305
Email: maehlmann at wiso.uni-koeln.de



From p.dalgaard at biostat.ku.dk  Wed Oct 26 17:57:55 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 26 Oct 2005 17:57:55 +0200
Subject: [R] help with a self-starting function in nonlinear least
	squares regression.
In-Reply-To: <001b01c5da32$8c24d050$9a1ad284@BIO041>
References: <001b01c5da32$8c24d050$9a1ad284@BIO041>
Message-ID: <x2ek68b798.fsf@viggo.kubism.ku.dk>

"Bill Shipley" <bill.shipley at usherbrooke.ca> writes:

> Hello.  I am having a problem setting up a self-starting function for
> use in nonlinear regression (and eventually in the mixed model version).
> The function is a non-rectangular hyperbola - called "NRhyperbola" -
> which is used for fitting leaf photosynthetic rate to light intensity.
> It has one independent variable (Irr) and four parameters (theta, Am,
> alpha and Rd).  I have created this to act as a self-starting function.
> The self-starting function seems to work (i.e. when I call "getInitial"
> it provides the initial values), but I can't get it to work when used
> within "nls".  Here is an example:
> 
>  
> 
> 1)
> 
> >
> getInitial(Photosynthese~NRhyperbola(Irr,theta,Am,alpha,Rd),data=lit.dat
> a[1:11,])
> 
>         theta            Am         alpha            Rd 
> 
>  0.5021546914  3.7466359015  0.0005743723 -3.0685671752
> 
>  
> 
> So, "getInitial" succeeds in extracting the initial values from the
> function.
> 
>  
> 
> 2)
> 
> >
> nls(Photosynthese~NRhyperbola(Irr,theta,Am,alpha,Rd),data=lit.data[1:11,
> ])
> 
> Error in eval(expr, envir, enclos) : Object "theta" not found
> 
>  
> 
> But the call to "nls" does not find the parameter theta, even though the
> call "getInitial" did find it and returned its initial value.
> 
>  
> 
> I am working from the Pinheiro & Bates book on mixed-effects models in S
> and S-PLUS.  According to that book (p. 346): "When nls is called
> without initial values for the parameters and a self-start model
> function is provided, nls calls getInitial to provide the initial
> values."
> 
>  
> 
> Two questions:
> 
>  
> 
> 1)       what am I doing wrong?

Not telling us how you created NRhyperbola....

 
> 2)       When a self-Starting model is called from within nlsList or
> nlme, is getInitial only called one (to get the values ignoring any
> hierarchical structure in the data) or is it called for each group?


Each group, it seems. Certainly, nlsList is just lapply'ing nls over
split(data, ...), and as far as I can see nlme starts off by running
nlsList. Then nlme.nlsList takes the median of the coefficients to get
the overall starting value. (Of course, you might as well have read
the code yourself...)

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From bill.shipley at usherbrooke.ca  Wed Oct 26 18:10:47 2005
From: bill.shipley at usherbrooke.ca (Bill Shipley)
Date: Wed, 26 Oct 2005 12:10:47 -0400
Subject: [R] self starting function for nonlinear least squares.
Message-ID: <004201c5da47$d44015b0$9a1ad284@BIO041>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051026/5ced1c31/attachment.pl

From forister at life.bio.sunysb.edu  Wed Oct 26 18:33:33 2005
From: forister at life.bio.sunysb.edu (Matthew Forister)
Date: Wed, 26 Oct 2005 12:33:33 -0400
Subject: [R] syntax for interactions in lme
Message-ID: <4a634fdeb98a537f25224a2c5b61ae83@life.bio.sunysb.edu>



Hello,

I am trying to make the switch from SAS, and I have a fairly elemental 
problem with syntax using the nlme package for analyzing mixed models.  
There was a previous question on this topic posted to this list, so I 
apologize for redundancy, but I didn't understand the advice given to 
that inquiry.  The model I want to run has the following factors:

Host (fixed)
Sire (random)
Dam nested within Sire (random)
Host * Sire (random)
Host * Dam within Sire (random)

So without the interactions I have:

hogmodel = lme(gain ~ host, random = ~1|sire/dam)

If I understand correctly, that "sire/dam" term gives me both Sire and 
Dam within Sire as random factors.  OK, so now I want to add the two 
interactions (listed above)...

In SAS, I would just enter them as random factors, but I can't seem to 
make that work.  I think I need to make a list that includes Sire/Dam, 
Host:Sire, and Host:Sire/Dam.  Two questions:

1) Is it sufficient to have simply Host:Sire/Dam in order to code for 
both interactions (host*sire and host*dam-within-sire)?

2) In any event, WHAT IS THE SYNTAX FOR MAKING A LIST OF RANDOM FACTORS?

I have looked in section 1.3 of Pinheiro&Bates, which was helpful, but 
I wasn't able to answer my question.  Thanks in advance, your help will 
keep me from running back to SAS!

--Matt



- - -
Matthew L Forister
Department of Ecology and Evolution
State University of New York at Stony Brook
650 Life Sciences Building
Stony Brook, New York 11794-5245
Email: forister at life.bio.sunysb.edu
Webpage: http://life.bio.sunysb.edu/~forister/
Lab phone: (631) 632-8609
Fax: (631) 632-7626
- - -



From dray at biomserv.univ-lyon1.fr  Wed Oct 26 18:48:46 2005
From: dray at biomserv.univ-lyon1.fr (=?ISO-8859-1?Q?St=E9phane_Dray?=)
Date: Wed, 26 Oct 2005 18:48:46 +0200
Subject: [R] sweave/help
Message-ID: <435FB36E.8090606@biomserv.univ-lyon1.fr>

Hello list,
I would like to know if it is possible to get output of help(foo) with 
Sweave.
If I insert ?foo in a chunk, the console give me the help but no output 
is obtained in the tex file.
Perhaps something to do with options ?

Thanks in advance !

-- 
St??phane DRAY (dray at biomserv.univ-lyon1.fr )
Laboratoire BBE-CNRS-UMR-5558, Univ. C. Bernard - Lyon I
43, Bd du 11 Novembre 1918, 69622 Villeurbanne Cedex, France
Tel: 33 4 72 43 27 57       Fax: 33 4 72 43 13 88
http://www.steph280.freesurf.fr/



From jerk_alert at hotmail.com  Wed Oct 26 19:07:39 2005
From: jerk_alert at hotmail.com (Ken Termiso)
Date: Wed, 26 Oct 2005 17:07:39 +0000
Subject: [R] Adding text to plot(dataframe)
Message-ID: <BAY101-F39AFCC4F761D2F48D02941E8690@phx.gbl>

Hello,

When using the plot(df) command, which scatter plots every variable of the 
df against every other variable, I would like to add text labels, but cannot 
find how to do this in this case so that every little sub-plot in the window 
has text labels on the points...

Any help would be much appreciated.

Thanks,
Ken



From vincent.goulet at act.ulaval.ca  Wed Oct 26 19:09:14 2005
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Wed, 26 Oct 2005 13:09:14 -0400
Subject: [R] sweave/help
In-Reply-To: <435FB36E.8090606@biomserv.univ-lyon1.fr>
References: <435FB36E.8090606@biomserv.univ-lyon1.fr>
Message-ID: <200510261309.14822.vincent.goulet@act.ulaval.ca>

Le 26 Octobre 2005 12:48, St??phane Dray a ??crit??:
> Hello list,
> I would like to know if it is possible to get output of help(foo) with
> Sweave.
> If I insert ?foo in a chunk, the console give me the help but no output
> is obtained in the tex file.
> Perhaps something to do with options ?
>
> Thanks in advance !

I don't know the answer to your exact question, but: why not simply \input the 
LaTeX version of the help page in your document?

-- 
  Vincent Goulet, Professeur agr??g??
  ??cole d'actuariat
  Universit?? Laval, Qu??bec 
  Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca



From br44114 at gmail.com  Wed Oct 26 19:14:39 2005
From: br44114 at gmail.com (bogdan romocea)
Date: Wed, 26 Oct 2005 13:14:39 -0400
Subject: [R] How to convert time to days
Message-ID: <8d5a36350510261014q73b3519fn7e935a093fd2c9c6@mail.gmail.com>

Those are obviously days, not seconds. A simple test would have
answered your question:
test <- strptime("20051026 15:26:19",format="%Y%m%d %H:%M:%S") -
    strptime("20051024 16:23:01",format="%Y%m%d %H:%M:%S")
class(test)
test
cat(test,"\n")

If you prefer you can use difftime for conversion:
difftime(strptime("20051026 15:26:19",format="%Y%m%d %H:%M:%S"),
    strptime("20051024 16:23:01",format="%Y%m%d %H:%M:%S"),units="hours")


> -----Original Message-----
> From: Muhammad Subianto [mailto:subianto at gmail.com]
> Sent: Wednesday, October 26, 2005 10:18 AM
> To: R-help at stat.math.ethz.ch
> Subject: [R] How to convert time to days
>
>
> Dear all,
> I have ran a simulation in R.
> This simulation was running about at least two days.
> Here is below the result some part of my code about time result.
> I don't understand about
>
> Start time: Mon Oct 24, 2005  at  04:23:01 PM
>  Finish time: Wed Oct 26, 2005  at  03:26:19 PM
>     Run time: 1.960625 secs.
>
> This is about two seconds or one day and nine hours?
> Then, how could I convert to 1 day, 23 hours, ? minutes, ? seconds.
> Thanks you very much for any suggestions.
>
> Best wishes, Muhammad Subianto
>
>  >
> ##############################################################
> ##################
>  > # Begin of program and timestamp:
>  >   cat(format(begin.time <- Sys.time(), "%a %b %d %X %Y") ,"\n")
> Mon Oct 24 04:23:01 PM 2005
>  >   cat("Start time:", secs <- format(begin.time, "%X"), "\n")
> Start time: 04:23:01 PM
>  >   cat("Sys.time:", begin.time <- Sys.time(), '\n')
> Sys.time: 1130163781
>  >
>  >
> --- CODE SIMULATION ---
>  >
>  > # End of program and timestamp:
>  >  cat("Sys.time:",end.time <- Sys.time(), '\n')
> Sys.time: 1130333179
>  >  cat("Run Time:",end.time-begin.time, 'secs.\n\n')
> Run Time: 1.960625 secs.
>
>  >  cat("Finish time:", secs <- format(end.time, "%X"), "\n")
> Finish time: 03:26:19 PM
>  >  cat(format(end.time <- Sys.time(), "%a %b %d %X %Y") ,"\n")
> Wed Oct 26 03:26:19 PM 2005
>  >
>  >  cat("\n",
> +      " Start time:", secs  <- format(begin.time, "%a %b %d, %Y  at
> %X"), "\n",
> +      "Finish time:", secs <- format(end.time,   "%a %b %d, %Y  at
> %X"), "\n",
> +      "   Run time:", end.time-begin.time, 'secs.\n\n')
>
>   Start time: Mon Oct 24, 2005  at  04:23:01 PM
>  Finish time: Wed Oct 26, 2005  at  03:26:19 PM
>     Run time: 1.960625 secs.
>
>  >
> ##############################################################
> #############
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From gunter.berton at gene.com  Wed Oct 26 19:22:18 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 26 Oct 2005 10:22:18 -0700
Subject: [R] Adding text to plot(dataframe)
In-Reply-To: <BAY101-F39AFCC4F761D2F48D02941E8690@phx.gbl>
Message-ID: <200510261722.j9QHMIE3007525@volta.gene.com>

As usual, please read the docs (?plot.data.frame)! There you will find a
link to pairs() among whose arguments is "panel" for writing your own panel
function. In this panel function you can use low level plotting and text
functions like points() and text() to customize what is plotted. Look at the
code for pairs to see how.

Alternatively, and better IMHO, is to use trellis plotting. ?splom (assuming
the lattice package is loaded).

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ken Termiso
> Sent: Wednesday, October 26, 2005 10:08 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Adding text to plot(dataframe)
> 
> Hello,
> 
> When using the plot(df) command, which scatter plots every 
> variable of the 
> df against every other variable, I would like to add text 
> labels, but cannot 
> find how to do this in this case so that every little 
> sub-plot in the window 
> has text labels on the points...
> 
> Any help would be much appreciated.
> 
> Thanks,
> Ken
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Wed Oct 26 20:12:30 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 26 Oct 2005 19:12:30 +0100 (BST)
Subject: [R] Pb encountered with demos
In-Reply-To: <BF853E94.76DC%nassar@noos.fr>
References: <BF853E94.76DC%nassar@noos.fr>
Message-ID: <Pine.LNX.4.61.0510261423130.18931@gannet.stats>

1) You do need to load the packages before doing this.  This is not 
supposed to be needed.

2) So these are bugs in the packages, so please report them to the package 
maintainers (and the posting guide suggest you contact them before 
posting).

On Wed, 26 Oct 2005, Naji wrote:

> Hi all,
>
>
> I've just installed R on my Mac & PC.
> The base demo run fine.. But I'm encountering several pb with some packages
> (installed using CRAN binaries using the menu)
> - Lattice:
>> demo(lattice,package='lattice')
>
>    demo(lattice)
>    ---- ~~~~~~~
> Type  <Return>     to start :
>> require(grid)
> [1] TRUE
>> old.prompt <- grid.prompt(TRUE)
>> old.settings <- trellis.par.get()
> Erreur dans eval.with.vis(expr, envir, enclos) :
>    impossible de trouver la fonction "trellis.par.get"
> - Zelig
>> demo(poisson,package='Zelig')
>    demo(poisson)
>    ---- ~~~~~~~
> Type  <Return>     to start :
>> data(sanction)
>> user.prompt()
> Erreur dans eval.with.vis(expr, envir, enclos) :
>    impossible de trouver la fonction "user.prompt"
> De plus : Warning message:
> data set 'sanction' not found in: data(sanction)
>
> Is there something wrong in the settings?
> Thanks helping me to fix this
>
> Naji
>
> Mac
> platform powerpc-apple-darwin7.9.0
> arch     powerpc
> os       darwin7.9.0
> system   powerpc, darwin7.9.0
> status
> major    2
> minor    2.0
> year     2005
> month    10
> day      06
> svn rev  35749
> language R
> PC
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386,mingw32
> status
> major    2
> minor    2.0
> year     2005
> month    10
> day      06
> svn rev  35749
> language R
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Antonio_Paredes at aphis.usda.gov  Wed Oct 26 20:28:05 2005
From: Antonio_Paredes at aphis.usda.gov (Antonio_Paredes@aphis.usda.gov)
Date: Wed, 26 Oct 2005 13:28:05 -0500
Subject: [R] (no subject)
Message-ID: <OF4B9B2490.22FAB1F4-ON862570A6.00650185-862570A6.00655875@aphis.usda.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051026/de65e8ee/attachment.pl

From clandry at fas.harvard.edu  Wed Oct 26 21:09:58 2005
From: clandry at fas.harvard.edu (Christian Landry)
Date: Wed, 26 Oct 2005 15:09:58 -0400
Subject: [R] AOV with repeated measures
Message-ID: <6.1.0.6.2.20051026150241.01b4de68@imap.fas.harvard.edu>

Dear R user,

I have a question on using R to analyze data with repeated measurements. I 
have 2 species with several strains (12) per species, each of which has 
been measured twice with for a given trait. No particular covariance, just 
two measures. Now I want to analyze the data with an ANOVA (aov) 
considering these repeated measures to get the MSq and SSq for the species 
and strain level. I would like to know how to write the ANOVA model in R. I 
have done the following:

aov(trait ~ species + strain/replicate)

Is it accurate?

Thanks a lot,

Christian



From macq at llnl.gov  Wed Oct 26 22:00:08 2005
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 26 Oct 2005 13:00:08 -0700
Subject: [R] How to convert time to days
In-Reply-To: <435F9025.10908@gmail.com>
References: <435F9025.10908@gmail.com>
Message-ID: <p06210203bf858f0d23ab@[128.115.153.6]>

The word "secs" appears in "Run time: 1.960625 secs" because you put 
it there in your cat() statement. It has nothing to do with the 
number itself.

Simply try typing

    end.time - begin.time

at the prompt, and see what you get.

Then see
   ?difftime
for more information. Example
    difftime(end.time,begin.time,units='hours')

To get the interval formatted as "1 day, 23 hours, x minutes, x 
seconds" you will have to do more work.

-Don

At 4:18 PM +0200 10/26/05, Muhammad Subianto wrote:
>Dear all,
>I have ran a simulation in R.
>This simulation was running about at least two days.
>Here is below the result some part of my code about time result.
>I don't understand about
>
>Start time: Mon Oct 24, 2005  at  04:23:01 PM
>  Finish time: Wed Oct 26, 2005  at  03:26:19 PM
>     Run time: 1.960625 secs.
>
>This is about two seconds or one day and nine hours?
>Then, how could I convert to 1 day, 23 hours, ? minutes, ? seconds.
>Thanks you very much for any suggestions.
>
>Best wishes, Muhammad Subianto
>
>  >
>################################################################################
>  > # Begin of program and timestamp:
>  >   cat(format(begin.time <- Sys.time(), "%a %b %d %X %Y") ,"\n")
>Mon Oct 24 04:23:01 PM 2005
>  >   cat("Start time:", secs <- format(begin.time, "%X"), "\n")
>Start time: 04:23:01 PM
>  >   cat("Sys.time:", begin.time <- Sys.time(), '\n')
>Sys.time: 1130163781
>  >
>  > 
>--- CODE SIMULATION ---
>  >
>  > # End of program and timestamp:
>  >  cat("Sys.time:",end.time <- Sys.time(), '\n')
>Sys.time: 1130333179
>  >  cat("Run Time:",end.time-begin.time, 'secs.\n\n')
>Run Time: 1.960625 secs.
>
>  >  cat("Finish time:", secs <- format(end.time, "%X"), "\n")
>Finish time: 03:26:19 PM
>  >  cat(format(end.time <- Sys.time(), "%a %b %d %X %Y") ,"\n")
>Wed Oct 26 03:26:19 PM 2005
>  >
>  >  cat("\n",
>+      " Start time:", secs  <- format(begin.time, "%a %b %d, %Y  at 
>%X"), "\n",
>+      "Finish time:", secs <- format(end.time,   "%a %b %d, %Y  at 
>%X"), "\n",
>+      "   Run time:", end.time-begin.time, 'secs.\n\n')
>
>   Start time: Mon Oct 24, 2005  at  04:23:01 PM
>  Finish time: Wed Oct 26, 2005  at  03:26:19 PM
>     Run time: 1.960625 secs.
>
>  >
>###########################################################################
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From orlando.rodriguez at uconn.edu  Wed Oct 26 22:27:48 2005
From: orlando.rodriguez at uconn.edu (Rodriguez, Orlando)
Date: Wed, 26 Oct 2005 16:27:48 -0400
Subject: [R] Population Projections
Message-ID: <86899F3233147C408FC4DB4A4518763F0282045B@EXCHANGEA.mgmt.ad.uconn.edu>

Is there an R Package for Population Projections?

Orlando J. Rodriguez
The Center for Population Research
University of Connecticut
Unit 2068
344 Mansfield Road
Storrs, CT 06269-2068
(860)486-9269
(860)486-6356 (f)
http://popcenter.uconn.edu



From aragon at berkeley.edu  Wed Oct 26 22:44:09 2005
From: aragon at berkeley.edu (Tomas Aragon)
Date: Wed, 26 Oct 2005 13:44:09 -0700 (PDT)
Subject: [R] Population Projections
In-Reply-To: <86899F3233147C408FC4DB4A4518763F0282045B@EXCHANGEA.mgmt.ad.uconn.edu>
Message-ID: <20051026204409.93560.qmail@web82007.mail.mud.yahoo.com>

--- "Rodriguez, Orlando" <orlando.rodriguez at uconn.edu> wrote:
> Is there an R Package for Population Projections?
> 
> Orlando J. Rodriguez
> The Center for Population Research
> University of Connecticut
> Unit 2068
> 344 Mansfield Road
> Storrs, CT 06269-2068
> (860)486-9269
> (860)486-6356 (f)
> http://popcenter.uconn.edu
> 

Visit Dept of Demography at UC Berkeley courses page:
http://www.demog.berkeley.edu/courses/

They use R and provide some code.
Tomas


Tomas Aragon, MD, DrPH
Tel: 510-847-9139 (mobile)
URL: http://www.idready.org



From nassar at noos.fr  Wed Oct 26 23:35:53 2005
From: nassar at noos.fr (Naji)
Date: Wed, 26 Oct 2005 23:35:53 +0200
Subject: [R] changing memory limits to speed up lsoda
In-Reply-To: <1467B320-C0F6-4611-9BD3-5AB1C0F8CEB8@muohio.edu>
Message-ID: <BF85C359.773A%nassar@noos.fr>

Martin,


For my simulations (same hardware with less memory).
- Optimize the code : using Narray, avoiding loops
- Installed distributed computations (PVM & RPVM tools are very easy to use,
many thanks to Simon Urbanek for his help)

Hope this will help
Best
Naji
Le 26/10/05 16:43, ????Martin Henry H. Stevens???? <HStevens at muohio.edu> a
??crit??:

> Hi All,
> I am running R 2.2.0 on Mac OS 10.4.2, dual G5 processors with 8 Gig
> RAM.
> I am running a simulation with lsoda that requires ~378 s to complete
> one set of time intervals. I need to optimize the parameters, and so
> need to considerably speed up the simulation.
> I have tried to figure out how to change the appropriate memory
> allocation and have search R help and Introductory information and
> the archives, but connot figure out how to allocate more to the right
> place.
> I would greatly appreciate any pointers or tips or leads.
> Thank you,
> Hank Stevens
> 
> 
> Dr. Martin Henry H. Stevens, Assistant Professor
> 338 Pearson Hall
> Botany Department
> Miami University
> Oxford, OH 45056
> 
> Office: (513) 529-4206
> Lab: (513) 529-4262
> FAX: (513) 529-4243
> http://www.cas.muohio.edu/~stevenmh/
> http://www.muohio.edu/ecology/
> http://www.muohio.edu/botany/
> "E Pluribus Unum"
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From gunter.berton at gene.com  Thu Oct 27 00:27:32 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 26 Oct 2005 15:27:32 -0700
Subject: [R] AOV with repeated measures
In-Reply-To: <6.1.0.6.2.20051026150241.01b4de68@imap.fas.harvard.edu>
Message-ID: <200510262227.j9QMRWxj010475@volta.gene.com>

As you have not yet received an **authoritative** answer, I'll attempt a
nonauthoritative one. Caveat emptor.

1. If strain is a fixed effect and you have but one exemplar of each strain
in species (which I assume is fixed) that is measured twice, measurement
error is all you have and a straightforward specification:

aov(y~species + strain %in% species) 

will do. It will also give a far too high false positive rate -- i.e. true
significance is much lower than advertised because measurement error is only
one small part of the true variability. You're missing the individual to
individual within strain*species component (if this is meaningful in your
context). In other words, the study design is flawed and the data analysis
will be too.

2. If strain is random

aov(trait~species + Error(species/strain))

is what you need. The within,replicate error is automatically added. 

Or even more simply: reduce the data to the average of the two measurements
and simply run aov(trait~species) on that, a oneway anova. Even with a few
missing replicates, this should be about right.

I would agree that documentation on the use of Error in aov seems
essentially nonexistent (AFAIK). Section 10.2 of Mass4 by Venables and
Ripley is about the best resource I know of. However, as the aov docs say,
if you're really in case 2, you're probably better off doing this with lme()
anyway. Partitioning SS is soooo 1960's when we have Doug Bates and friends
noodling away writing sophisticated likelihood optimization code for us.
Don't let his efforts be in vain, I say (or was that Abe? ...) .


-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Christian Landry
> Sent: Wednesday, October 26, 2005 12:10 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] AOV with repeated measures
> 
> Dear R user,
> 
> I have a question on using R to analyze data with repeated 
> measurements. I 
> have 2 species with several strains (12) per species, each of 
> which has 
> been measured twice with for a given trait. No particular 
> covariance, just 
> two measures. Now I want to analyze the data with an ANOVA (aov) 
> considering these repeated measures to get the MSq and SSq 
> for the species 
> and strain level. I would like to know how to write the ANOVA 
> model in R. I 
> have done the following:
> 
> aov(trait ~ species + strain/replicate)
> 
> Is it accurate?
> 
> Thanks a lot,
> 
> Christian
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From jebyrnes at ucdavis.edu  Thu Oct 27 00:57:59 2005
From: jebyrnes at ucdavis.edu (Jarrett Byrnes)
Date: Wed, 26 Oct 2005 15:57:59 -0700
Subject: [R] Post Hoc Groupings
Message-ID: <ec21198c0e093f6282b643291318190f@ucdavis.edu>

Quick question, as I attempt to learn R.  For post-hoc tests

1) Is there an easy function that will take, say the results of 
tukeyHSD and create a grouping table.  e.g., if I have treatments 1, 2, 
and 3, with 1 and 2 being statistically the same and 3 being different 
from both

Group	Treatment
A		1
A		2
B		3

2) I've been stumbling over the proper syntax for simple effects for a 
tukeyHSD test.  Is it

TukeyHSD(model.aov, "Treatment1", "Treatment2")
or
TukeyHSD(model, c("Treatment1", "Treatment2"))

or something else, as neither of those seem to really work.



From blomsp at ozemail.com.au  Thu Oct 27 02:18:57 2005
From: blomsp at ozemail.com.au (Simon Blomberg)
Date: Thu, 27 Oct 2005 10:18:57 +1000
Subject: [R] Population Projections
In-Reply-To: <20051026204409.93560.qmail@web82007.mail.mud.yahoo.com>
References: <86899F3233147C408FC4DB4A4518763F0282045B@EXCHANGEA.mgmt.ad.uconn.edu>
	<20051026204409.93560.qmail@web82007.mail.mud.yahoo.com>
Message-ID: <6.2.1.2.0.20051027101001.01d0fe38@mail.ozemail.com.au>

Depends what you want to do. Forming population projection matrices and 
doing the eigenanalysis to work out population growth rates, stable stage 
distributions, elasticities etc. is simple enough. Do you really need a 
package to do that? See ?eigen. What would you like to see in a population 
projection package?

Cheers,

Simon.

At 06:44 AM 27/10/2005, you wrote:
>--- "Rodriguez, Orlando" <orlando.rodriguez at uconn.edu> wrote:
> > Is there an R Package for Population Projections?
> >
> > Orlando J. Rodriguez
> > The Center for Population Research
> > University of Connecticut
> > Unit 2068
> > 344 Mansfield Road
> > Storrs, CT 06269-2068
> > (860)486-9269
> > (860)486-6356 (f)
> > http://popcenter.uconn.edu
> >
>
>Visit Dept of Demography at UC Berkeley courses page:
>http://www.demog.berkeley.edu/courses/
>
>They use R and provide some code.
>Tomas
>
>
>Tomas Aragon, MD, DrPH
>Tel: 510-847-9139 (mobile)
>URL: http://www.idready.org
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Simon Blomberg, B.Sc.(Hons.), Ph.D, M.App.Stat.
Centre for Resource and Environmental Studies
The Australian National University
Canberra ACT 0200
Australia
T: +61 2 6125 7800 email: Simon.Blomberg_at_anu.edu.au
F: +61 2 6125 0757
CRICOS Provider # 00120C



From ehlers at math.ucalgary.ca  Thu Oct 27 02:23:14 2005
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Wed, 26 Oct 2005 18:23:14 -0600
Subject: [R] Post Hoc Groupings
In-Reply-To: <ec21198c0e093f6282b643291318190f@ucdavis.edu>
References: <ec21198c0e093f6282b643291318190f@ucdavis.edu>
Message-ID: <43601DF2.9000802@math.ucalgary.ca>



Jarrett Byrnes wrote:
> Quick question, as I attempt to learn R.  For post-hoc tests
> 
> 1) Is there an easy function that will take, say the results of 
> tukeyHSD and create a grouping table.  e.g., if I have treatments 1, 2, 
> and 3, with 1 and 2 being statistically the same and 3 being different 
> from both
> 
> Group	Treatment
> A		1
> A		2
> B		3
> 
> 2) I've been stumbling over the proper syntax for simple effects for a 
> tukeyHSD test.  Is it
> 
> TukeyHSD(model.aov, "Treatment1", "Treatment2")
> or
> TukeyHSD(model, c("Treatment1", "Treatment2"))
> 
> or something else, as neither of those seem to really work.
> 

Re question 2, using the example in the help file:
fm1 <- aov(breaks ~ wool + tension, data = warpbreaks)
TukeyHSD(fm1, c("wool","tension"))

Note that "wool", "tension" must be factors.

[In the help file for TukeyHSD, argument 'which' is
defined as a "list" of terms. Maybe that should be changed
to a "character vector".]

Peter



From jebyrnes at ucdavis.edu  Thu Oct 27 02:35:12 2005
From: jebyrnes at ucdavis.edu (Jarrett Byrnes)
Date: Wed, 26 Oct 2005 17:35:12 -0700
Subject: [R] Post Hoc Groupings
In-Reply-To: <43601DF2.9000802@math.ucalgary.ca>
References: <ec21198c0e093f6282b643291318190f@ucdavis.edu>
	<43601DF2.9000802@math.ucalgary.ca>
Message-ID: <0a466f59ae59720a51ec39bd3ba33c59@ucdavis.edu>

Indeed, the following works as well
On Oct 26, 2005, at 5:23 PM, P Ehlers wrote:

> fm1 <- aov(breaks ~ wool*tension, data = warpbreaks)
> TukeyHSD(fm1, c("wool","tension", "wool:tension"))

However, when working with my own dataset,  I get the following errors. 
  I have some inkling this may be due to a slightly unbalanced sample 
size, but am uncertain of this.

 > rich.aov <- aov(X.open ~ Dock*Slip, data=dock_2004_data)
 > TukeyHSD(rich.aov, c("Dock", "Slip"))

Error in rep.int(n, length(means)) : unimplemented type 'NULL' in 'rep'
In addition: Warning messages:
1: non-factors ignored: Slip in: replications(paste("~", xx), data = mf)
2: non-factors ignored: Dock, Slip in: replications(paste("~", xx), 
data = mf)

I am pleased to know that these errors are not quite the



From michel.friesenhahn.b at bayer.com  Thu Oct 27 04:02:15 2005
From: michel.friesenhahn.b at bayer.com (Michel Friesenhahn)
Date: Wed, 26 Oct 2005 19:02:15 -0700
Subject: [R] Extracting Variance Components
Message-ID: <OFD24CE7A7.AC2259F9-ON882570A7.0009B29C-882570A7.000B3123@bayer.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051026/9425095e/attachment.pl

From mlyman at byu.edu  Thu Oct 27 04:35:59 2005
From: mlyman at byu.edu (Mark Lyman)
Date: Wed, 26 Oct 2005 20:35:59 -0600
Subject: [R] Post Hoc Groupings
In-Reply-To: <0a466f59ae59720a51ec39bd3ba33c59@ucdavis.edu>
References: <ec21198c0e093f6282b643291318190f@ucdavis.edu>
	<43601DF2.9000802@math.ucalgary.ca>
	<0a466f59ae59720a51ec39bd3ba33c59@ucdavis.edu>
Message-ID: <43603D0F.8030605@byu.edu>

Looking at the errors your code produces, it looks like you need to make 
Dock and Slip factors.

dock_2004_data$Dockf<-factor(dock_2004_data$Dock)

dock_2004_data$Slipf<-factor(dock_2004_data$Slip)

rich.aov <- aov(X.open ~ Dockf*Slipf, data=dock_2004_data)

TukeyHSD(rich.aov, c("Dockf", "Slipf"))


Jarrett Byrnes wrote:

>Indeed, the following works as well
>On Oct 26, 2005, at 5:23 PM, P Ehlers wrote:
>
>  
>
>>fm1 <- aov(breaks ~ wool*tension, data = warpbreaks)
>>TukeyHSD(fm1, c("wool","tension", "wool:tension"))
>>    
>>
>
>However, when working with my own dataset,  I get the following errors. 
>  I have some inkling this may be due to a slightly unbalanced sample 
>size, but am uncertain of this.
>
> > rich.aov <- aov(X.open ~ Dock*Slip, data=dock_2004_data)
> > TukeyHSD(rich.aov, c("Dock", "Slip"))
>
>Error in rep.int(n, length(means)) : unimplemented type 'NULL' in 'rep'
>In addition: Warning messages:
>1: non-factors ignored: Slip in: replications(paste("~", xx), data = mf)
>2: non-factors ignored: Dock, Slip in: replications(paste("~", xx), 
>data = mf)
>
>I am pleased to know that these errors are not quite the
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>



From jebyrnes at ucdavis.edu  Thu Oct 27 05:04:36 2005
From: jebyrnes at ucdavis.edu (Jarrett Byrnes)
Date: Wed, 26 Oct 2005 20:04:36 -0700
Subject: [R] Post Hoc Groupings
In-Reply-To: <43603D0F.8030605@byu.edu>
References: <ec21198c0e093f6282b643291318190f@ucdavis.edu>
	<43601DF2.9000802@math.ucalgary.ca>
	<0a466f59ae59720a51ec39bd3ba33c59@ucdavis.edu>
	<43603D0F.8030605@byu.edu>
Message-ID: <1037c327d162639d3c42ece01802e673@ucdavis.edu>

Indeed, that does it.  Odd.  I guess as Slip was a number, it needed to 
be categorized.  Interesting...

Not if only I can figure out how to get the TukeyHSD grouping table....

On Oct 26, 2005, at 7:35 PM, Mark Lyman wrote:

> Looking at the errors your code produces, it looks like you need to 
> make Dock and Slip factors.
>
> dock_2004_data$Dockf<-factor(dock_2004_data$Dock)
>
> dock_2004_data$Slipf<-factor(dock_2004_data$Slip)
>
> rich.aov <- aov(X.open ~ Dockf*Slipf, data=dock_2004_data)
>
> TukeyHSD(rich.aov, c("Dockf", "Slipf"))
>
>
> Jarrett Byrnes wrote:
>
>> Indeed, the following works as well
>> On Oct 26, 2005, at 5:23 PM, P Ehlers wrote:
>>
>>
>>> fm1 <- aov(breaks ~ wool*tension, data = warpbreaks)
>>> TukeyHSD(fm1, c("wool","tension", "wool:tension"))
>>>
>>
>> However, when working with my own dataset,  I get the following 
>> errors.  I have some inkling this may be due to a slightly unbalanced 
>> sample size, but am uncertain of this.
>>
>> > rich.aov <- aov(X.open ~ Dock*Slip, data=dock_2004_data)
>> > TukeyHSD(rich.aov, c("Dock", "Slip"))
>>
>> Error in rep.int(n, length(means)) : unimplemented type 'NULL' in 
>> 'rep'
>> In addition: Warning messages:
>> 1: non-factors ignored: Slip in: replications(paste("~", xx), data = 
>> mf)
>> 2: non-factors ignored: Dock, Slip in: replications(paste("~", xx), 
>> data = mf)
>>
>> I am pleased to know that these errors are not quite the
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
>>
>>
>



From BHunsicker at rfmd.com  Thu Oct 27 05:43:07 2005
From: BHunsicker at rfmd.com (Bill Hunsicker)
Date: Wed, 26 Oct 2005 23:43:07 -0400
Subject: [R] sorting of data
Message-ID: <3EA9CDD20D8E694F92C01B7BA7FC5AC8033FD617@mail.internal.rfmd.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051026/592c8e02/attachment.pl

From rajnmsu79 at gmail.com  Thu Oct 27 05:52:48 2005
From: rajnmsu79 at gmail.com (Raja Jayaraman)
Date: Wed, 26 Oct 2005 22:52:48 -0500
Subject: [R] Fitting of Non-Linear Diff Equations and Parameter Estimation
Message-ID: <a666434f0510262052n10f90ffeo1b9c1b4c7768e1ce@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051026/72f2a489/attachment.pl

From jporzak at gmail.com  Thu Oct 27 06:25:53 2005
From: jporzak at gmail.com (Jim Porzak)
Date: Wed, 26 Oct 2005 21:25:53 -0700
Subject: [R] sorting of data
In-Reply-To: <3EA9CDD20D8E694F92C01B7BA7FC5AC8033FD617@mail.internal.rfmd.com>
References: <3EA9CDD20D8E694F92C01B7BA7FC5AC8033FD617@mail.internal.rfmd.com>
Message-ID: <2a9c000c0510262125kdf628a7p21637d4150265e3c@mail.gmail.com>

One of the most useful functions:
?subset

as in

nsmSubData <- subset(nsmalldata, SESSIONID==7757513)


On 10/26/05, Bill Hunsicker <BHunsicker at rfmd.com> wrote:
> R-Help,
>
>
>
> I am trying to reduce at data set to rows where a specified value occurs
> in a specified value.  Below is a screen capture of Rgui:
>
>
>
> > nsmalldata <-read.csv("c:\\DATA\\UNITY\\\PASS0_DOWNFADE\\nsmall.csv")
>
> > nsmalldata
>
>    BOARDNUMBER SESSIONID MATRIXID ARRAYPOINT Temperature   PS1   PS2
> PS13 PS14 PS15
>
> 1        LB0DC      3043  7757513          1       -9999 -9999 -9999
> 3.6    5   -5
>
> 2        LB0DC      3043  7757515          1       -9999 -9999 -9999
> 3.6    5   -5
>
> 3        LB0DC      3043  7757517          1       -9999 -9999 -9999
> 3.6    5   -5
>
> 4        LB0DC      3043  7757520          1       -9999 -9999 -9999
> 3.6    5   -5
>
> 5        LB0DC      3043  7757522          1       -9999 -9999 -9999
> 3.6    5   -5
>
> 6        LB0DC      3043  7757524          1       -9999 -9999 -9999
> 3.6    5   -5
>
> 7        LB0DC      3043  7757526          1       -9999 -9999 -9999
> 3.6    5   -5
>
> 8        LB0DC      3043  7757528          1       -9999 -9999 -9999
> 3.6    5   -5
>
> 9        LB0DC      3043  7757531          1       -9999 -9999 -9999
> 3.6    5   -5
>
> 10       LB0DC      3043  7757533          1       -9999 -9999 -9999
> 3.6    5   -5
>
> 11       LB0DC      3043  7757535          1       -9999 -9999 -9999
> 3.6    5   -5
>
> 12       LB0DC      3043  7757537          1       -9999 -9999 -9999
> 3.6    5   -5
>
> 13       LB0DC      3043  7757540          1       -9999 -9999 -9999
> 3.6    5   -5
>
> 14       LB0DC      3043  7757542          1       -9999 -9999 -9999
> 3.6    5   -5
>
> 15       LB0DC      3043  7757544          1       -9999 -9999 -9999
> 3.6    5   -5
>
> 16       LB0DC      3043  7757547          1       -9999 -9999 -9999
> 3.6    5   -5
>
> 17       LB0DC      3043  7757549          1       -9999 -9999 -9999
> 3.6    5   -5
>
> 18       LB0DC      3043  7757551          1       -9999 -9999 -9999
> 3.6    5   -5
>
> 19       LB0DC      3043  7757554          1       -9999 -9999 -9999
> 3.6    5   -5
>
> 20       LB0DC      3043  7757556          1       -9999 -9999 -9999
> 3.6    5   -5
>
> >
>
>
>
> For Example
>
> I would like to reduce nsmalldata to only the rows where
> SESSIONID==7757513
>
> I have spent quite a bit of time with R manuals and still have not
> gotten there, can you help me?
>
>
>
> Thanks in advance.
>
>
>
> Regards,
>
> Bill
>
>
>
> Bill Hunsicker
>
> RF Micro Devices
>
> 7625 Thorndike Road
>
> Greensboro, NC  27409
>
> 336-678-5260(W)
>
> 610-579-9985(M)
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>


--
HTH,
Jim Porzak
Loyalty Matrix Inc.
San Francisco, CA



From dlvanbrunt at gmail.com  Thu Oct 27 06:30:52 2005
From: dlvanbrunt at gmail.com (David L. Van Brunt, Ph.D.)
Date: Wed, 26 Oct 2005 23:30:52 -0500
Subject: [R] Repost: Examples of "classwt", "strata",
	and "sampsize" in randomForest?
Message-ID: <d332d3e10510262130j5f7a850awefd59e1287fa48c7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051026/6037d0d4/attachment.pl

From ggrothendieck at gmail.com  Thu Oct 27 07:10:37 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 27 Oct 2005 01:10:37 -0400
Subject: [R] Repost: Examples of "classwt", "strata",
	and "sampsize" in randomForest?
In-Reply-To: <d332d3e10510262130j5f7a850awefd59e1287fa48c7@mail.gmail.com>
References: <d332d3e10510262130j5f7a850awefd59e1287fa48c7@mail.gmail.com>
Message-ID: <971536df0510262210ne66777y71d25a96d2656b24@mail.gmail.com>

See
http://finzi.psych.upenn.edu/R/Rhelp02a/archive/40898.html

On 10/27/05, David L. Van Brunt, Ph.D. <dlvanbrunt at gmail.com> wrote:
> Sorry for the repost, but I've really been looking, and can't find any
> syntax direction on this issue...
>
> Just browsing the documentation, and searching the list came up short... I
> have some unbalanced data and was wondering if, in a "0" v "1"
> classification forest, some combo of these options might yield better
> predictions when the proportion of one class is low (less than 10% in a
> sample of 2,000 observations).
>
> Not sure how to specify these terms... from the docs, we have:
>
> classwt: Priors of the classes. Need not add up to one. Ignored for
> regression.
>
> So is this something like "... classwt=c(.90,.10)" ? I didn't see the syntax
> demonstrated. Similar for "strata" and "sampsize" though there is a default
> for sampsize that makes sense... not sure how you would make "a vector of
> the length the number of strata", however....
>
> Pointers?
>
> --
> ---------------------------------------
> David L. Van Brunt, Ph.D.
> mailto:dlvanbrunt at gmail.com
>
> --
> ---------------------------------------
> David L. Van Brunt, Ph.D.
> mailto:dlvanbrunt at gmail.com
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Lorenz.Gygax at fat.admin.ch  Thu Oct 27 07:24:08 2005
From: Lorenz.Gygax at fat.admin.ch (Lorenz.Gygax@fat.admin.ch)
Date: Thu, 27 Oct 2005 07:24:08 +0200
Subject: [R] syntax for interactions in lme
Message-ID: <BF74FADD4B44554CA7E53D0B5242CD6A034FF0EB@evd-s7014.bk.evdad.admin.ch>

> Host (fixed)
> Sire (random)
> Dam nested within Sire (random)
> Host * Sire (random)
> Host * Dam within Sire (random)
> 
> So without the interactions I have:
> 
> hogmodel = lme(gain ~ host, random = ~1|sire/dam)
> 
> If I understand correctly, that "sire/dam" term gives me both 
> Sire and Dam within Sire as random factors.  OK, so now I want
> to add the two interactions (listed above)...

Correct, for the interactions write:

random = ~ host | sire/dam

an interaction between a fixed and a random term can be interpreted as a
variability in the fixed term for the different levels in the random term.
Thus the 1 (which stands for the intercept) is exchanged with the fixed
effect(s) with which interactions are of interest.

This is easy if all the hierarchical levels of a nested random effects go
into an interaction it is a bit more complicated if not. Say you only want
the interaction of host and dam but not sire:

random = list (~ 1 | sire, ~ host | dam)

Hope this helps (it can all be found in Pinheiro and Bates and on the help
pages).

Lorenz



From blomsp at ozemail.com.au  Thu Oct 27 07:25:27 2005
From: blomsp at ozemail.com.au (Simon Blomberg)
Date: Thu, 27 Oct 2005 15:25:27 +1000
Subject: [R] Extracting Variance Components
In-Reply-To: <OFD24CE7A7.AC2259F9-ON882570A7.0009B29C-882570A7.000B3123@
	bayer.com>
References: <OFD24CE7A7.AC2259F9-ON882570A7.0009B29C-882570A7.000B3123@bayer.com>
Message-ID: <7.0.0.10.0.20051027152350.019a21a0@ozemail.com.au>

?VarCorr

At 12:02 PM 27/10/2005, you wrote:
>Dear List,
>
>Is there a way to extract variance components from lmeObjects or
>summary.lme objects without using intervals()?  For my purposes I don't
>need the confidence intervals which I'm obtaining using parametric
>bootstrap.
>
>Thanks,
>
>Mike
>         [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Simon Blomberg, B.Sc.(Hons.), Ph.D, M.App.Stat.
Centre for Resource and Environmental Studies
The Australian National University
Canberra ACT 0200
Australia
T: +61 2 6125 7800 email: Simon.Blomberg_at_anu.edu.au
F: +61 2 6125 0757
CRICOS Provider # 00120C



From jacques.veslot at cirad.fr  Thu Oct 27 08:22:23 2005
From: jacques.veslot at cirad.fr (Jacques VESLOT)
Date: Thu, 27 Oct 2005 10:22:23 +0400
Subject: [R] F tests for random effect models
Message-ID: <4360721F.8020204@cirad.fr>

Dear R-users,

My question is how to get right F tests for random effects in random effect models (I hope this 
question has not been answered too many times yet - I didn't find an answer in rhelp archives).

My data are in mca2 (enc.) :

names(mca2)
[1] "Lignee"        "Pollinisateur" "Rendement"

dim(mca2)
[1] 100   3

replications(Rendement ~ Lignee * Pollinisateur, data = mca2)
               Lignee        Pollinisateur Lignee:Pollinisateur
                   20                   10                    2

Of course, summary(aov(Rendement ~ Pollinisateur * Lignee, data = mca2)) gives wrong tests of random 
effects. But, summary(aov1 <- aov(Rendement ~ Error(Pollinisateur * Lignee), data = mca2)) gives no 
test at all, and I have to do it like this :

tab1 <- matrix(unlist(summary(aov1)), nc=5, byrow=T)[,1:3]

Femp <- c(tab1[1:3, 3]/tab1[c(3,3,4), 3])

names(Femp) <- c("Pollinisateur", "Lignee", "Interaction")

1 - pf(Femp, tab1[1:3,1], tab1[c(3,3,4),1])

With "lme4" package (I did'nt succeed in writing a working formula with lme from "nlme" package), I 
can "see" standard deviations of random effects (but don't know how to find them) with :

library(lme4)
summary(lmer(Rendement ~ (1 |Pollinisateur) + (1 | Lignee) + (1 | Pollinisateur:Lignee), data=mca2))

but I can't get F tests.

Thanks in advance.

Best regards,

Jacques VESLOT




From TobiasBr at Taquanta.com  Thu Oct 27 08:47:45 2005
From: TobiasBr at Taquanta.com (Brandt, T. (Tobias))
Date: Thu, 27 Oct 2005 08:47:45 +0200
Subject: [R] data.frame-question]
Message-ID: <A77412E534FCD248A93A81F37CC75B7A033F8BE4@waxbill.africa.nedcor.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051027/c26c3da5/attachment.pl

From petr.pikal at precheza.cz  Thu Oct 27 09:18:57 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 27 Oct 2005 09:18:57 +0200
Subject: [R] data.frame-question]
In-Reply-To: <A77412E534FCD248A93A81F37CC75B7A033F8BE4@waxbill.africa.nedcor.net>
Message-ID: <43609B81.27467.A68CC7@localhost>

Hi

quite near

using aggregate it is possible to reach what you want

TAB3 <- with(TAB1, aggregate(Number, 
list("Name_singular"=Name), sum, na.rm=TRUE))

see
> str(TAB3)
`data.frame':   3 obs. of  2 variables:
 $ Name_singular: Factor w/ 3 levels "A","B","C": 1 2 3
 $ x            : num  3 5 0
>

HTH
Petr


On 27 Oct 2005 at 8:47, Brandt, T. (Tobias) wrote:

From:           	"Brandt, T. (Tobias)" <TobiasBr at taquanta.com>
To:             	"'Michael Graber'" <michael_graber at gmx.de>,
	"'r-help at stat.math.ethz.ch'" <r-help at stat.math.ethz.ch>
Date sent:      	Thu, 27 Oct 2005 08:47:45 +0200
Subject:        	Re: [R] data.frame-question]

> First a general comment on posting style, could you please be more
> specific about where the error occurs as without this it is very
> difficult to identify what the problem is.
> 
> Now concerning your problem.  When I tried the code I posted yesterday
> I thought it worked fine.  I've tried it again now and found that the
> data.frame TAB3 actually only has one column and the names "A", "B"
> etc are actually interpreted as the row names.  Since there is only
> one column the 'colnames(TAB3) <-' fails when you give it a vector
> with two components.  I think that if you display it without renaming
> the columns then it still displays the correct results though.  I also
> tested it with including NA's and it worked fine.  I'm quite a newbie
> myself so I don't know how you can't tell you how to return the result
> into a two column data.frame.
> 
> For completeness, here is the code I used to test.
> 
> > Name <- c(rep("A", 3), rep("B", 5), "C")
> > Number <- rep(1, 8)
> > Number[9] <- NA
> > TAB1 <- data.frame(Name, Number)
> > TAB1
>   Name Number
> 1    A      1
> 2    A      1
> 3    A      1
> 4    B      1
> 5    B      1
> 6    B      1
> 7    B      1
> 8    B      1
> 9    C     NA
> > TAB3 <- with(TAB1, tapply(Number, Name, sum, na.rm=TRUE))
> > TAB3
> A B C 
> 3 5 0 
> > TAB3 <- as.data.frame(TAB3)
> > TAB3
>   TAB3
> A    3
> B    5
> C    0
> > colnames(TAB3) <- c("Name_singular", "Sum")
> Error in "dimnames<-.data.frame"(`*tmp*`, value = list(c("A", "B", "C"
> : 
>         invalid 'dimnames' given for data frame
> > TAB3
>   TAB3
> A    3
> B    5
> C    0
> > str(TAB3)
> `data.frame':   3 obs. of  1 variable:
>  $ TAB3: num [, 1:3] 3 5 0
>   ..- attr(*, "dimnames")=List of 1
>   .. ..$ : chr  "A" "B" "C"
> > 
> > version
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    2              
> minor    2.0            
> year     2005           
> month    10             
> day      06             
> svn rev  35749          
> language R              
> 
> 
> 
> -----Original Message-----
> From: Michael Graber [mailto:michael_graber at gmx.de] 
> Sent: 27 October 2005 12:43 AM
> To: TobiasBr at Taquanta.com
> Subject: Re: Re: [R] data.frame-question]
> 
> This is what I am looking for, but I still get an error message, that
> my arguments are not of the same length. How can I avoid this error
> message? Maybe I should add, that there are also NA??s in the second
> column, but I tried to ignore them by na.rm=TRUE.
> 
> Thanks in advance,
> 
> Michael Graber
> 
> 
> 
> Michael Graber schrieb:
> 
> >
> >
> > --------------------------------------------------------------------
> > -- --
> >
> > Betreff:
> > RE: [R] data.frame-question
> > Von:
> > "Brandt, T. (Tobias)" <TobiasBr at Taquanta.com>
> > Datum:
> > Wed, 26 Oct 2005 09:20:23 +0200
> > An:
> > "'r-help at stat.math.ethz.ch'" <r-help at stat.math.ethz.ch>
> >
> > An:
> > "'r-help at stat.math.ethz.ch'" <r-help at stat.math.ethz.ch>
> > CC:
> > 'Michael Graber' <michael_graber at gmx.de>
> >
> >
> > Is
> >
> > TAB3 <- as.data.frame(with(TAB1, tapply(Number, Name, sum)))
> > colnames(TAB3) <- c("Name_singular", "Sum")
> >
> > what you are looking for?
> >
> >
> >
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Michael
> > Graber Sent: 25 October 2005 09:45 PM To: R-Mailingliste Subject:
> > [R] data.frame-question
> >
> > Dear R-List,
> > I am very new to R and programming itself, so my question may be
> > easy to answer for you. I tried a lot and read through the manuals,
> > but I still have the following problem: I have 2 data-frames:
> > Number<-as.numeric (Number) Name<-as.character (Name)
> > TAB1<-data.frame (Name,Number) - it looks like this:- Name Number A
> > 2 A 3 A 6 B 8 B 12 B 7 C 8 D 90 E 12 E 45 ...
> > Name_singular<-as.character (Name_singular) TAB2<-data.frame
> > (Name_singular) # it looks like this: Name_singular A B C D E -My
> > result should be a data-frame, where the first column is
> > Name_singular and the second column should be the sum of the numbers
> > where Name ==Name_singular.- For example:
> >
> > TAB3:
> > Name_singular Sum
> > A 11
> > B 27
> > ...
> > - I tried it with for-loops, but I think there must be an easier
> > way.- I would be very grateful for your help,
> >
> >
> > Michael Graber
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> >
> > --------------------------------------------------------------------
> > -- --
> >
> > Nedbank Limited Reg No 1951/000009/06
> > Directors: WAM Clewlow (Chairman)  Prof MM Katz (Vice-chairman)  ML
> > Ndlovu (Vice-chairman)  TA Boardman (Chief Executive) CJW Ball  MWT
> > Brown  RG Cottrell  BE Davison  N Dennis (British)  MA Enus-Brey 
> > Prof B de L Figaji  RM Head (British) RJ Khoza  JB Magwaza  ME
> > Mkwanazi  JVF Roberts (British)  CML Savage GT Serobe  JH Sutcliffe
> > (British) Company Secretary: GS Nienaber     16.08.2005
> >
> > This email and any accompanying attachments may contain confidential
> > and proprietary information.  This information is private and
> > protected by law and, accordingly, if you are not the intended
> > recipient, you are requested to delete this entire communication
> > immediately and are notified that any disclosure, copying or
> > distribution of or taking any action based on this information is
> > prohibited.
> >
> > Emails cannot be guaranteed to be secure or free of errors or
> > viruses.  The sender does not accept any liability or responsibility
> > for any interception, corruption, destruction, loss, late arrival or
> > incompleteness of or tampering or interference with any of the
> > information contained in this email or for its incorrect delivery or
> > non-delivery for whatsoever reason or for its effect on any
> > electronic device of the recipient.
> >
> > If verification of this email or any attachment is required, please
> > request a hard-copy version.
> >
> > --------------------------------------------------------------------
> > -- --
> 
> 
> ********************
> Nedbank Limited Reg No 1951/000009/06
> Directors: WAM Clewlow (Chairman)  Prof MM Katz (Vice-chairman)  ML
> Ndlovu (Vice-chairman)  TA Boardman (Chief Executive) CJW Ball  MWT
> Brown  RG Cottrell  BE Davison  N Dennis (British)  MA Enus-Brey  Prof
> B de L Figaji  RM Head (British) RJ Khoza  JB Magwaza  ME Mkwanazi 
> JVF Roberts (British)  CML Savage  GT Serobe  JH Sutcliffe (British)
> Company Secretary: GS Nienaber     16.08.2005
> 
> This email and any accompanying attachments may contain confidential
> and proprietary information.  This information is private and
> protected by law and, accordingly, if you are not the intended
> recipient, you are requested to delete this entire communication
> immediately and are notified that any disclosure, copying or
> distribution of or taking any action based on this information is
> prohibited.
> 
> Emails cannot be guaranteed to be secure or free of errors or viruses.
>  The sender does not accept any liability or responsibility for any
> interception, corruption, destruction, loss, late arrival or
> incompleteness of or tampering or interference with any of the
> information contained in this email or for its incorrect delivery or
> non-delivery for whatsoever reason or for its effect on any electronic
> device of the recipient.
> 
> If verification of this email or any attachment is required, please
> request a hard-copy version. ********************
> 
>  [[alternative HTML version deleted]]
> 
> 

Petr Pikal
petr.pikal at precheza.cz



From lee_poet at hotmail.com  Thu Oct 27 10:18:02 2005
From: lee_poet at hotmail.com (jinlong li)
Date: Thu, 27 Oct 2005 16:18:02 +0800
Subject: [R] how to predict with logistic model  in package logistf ?
Message-ID: <BAY104-F307DCA3B1F016EF46EFBDFF2680@phx.gbl>

dear community,
     I am a beginer in R , and can't predict with logistic model  in package 
logistf,
could anyone help me ? thanks !

the following is my command and result :

>library(logistf)
>data(sex2)
>fit<-logistf(case ~ age+oc+vic+vicl+vis+dia, data=sex2)
>predict(fit,newdata=sex2)
   Error in predict(fit, newdata = sex2) : no applicable method for 
"predict"



From jacques.veslot at cirad.fr  Thu Oct 27 12:13:38 2005
From: jacques.veslot at cirad.fr (Jacques VESLOT)
Date: Thu, 27 Oct 2005 14:13:38 +0400
Subject: [R] F tests for random effect models
In-Reply-To: <Pine.LNX.4.61.0510271023560.25304@gannet.stats>
References: <4360721F.8020204@cirad.fr>
	<Pine.LNX.4.61.0510271023560.25304@gannet.stats>
Message-ID: <4360A852.8050700@cirad.fr>

Sorry,

Actually I gave my data in an image file (.RData) - I've just checked my send emails.
Am I to give data in another format, such as text ? Here are they in text (.txt).

The output are :

 > summary(aov1 <- aov(Rendement ~ Error(Pollinisateur * Lignee), data = mca2)

Error: Pollinisateur
           Df  Sum Sq Mean Sq F value Pr(>F)
Residuals  9 11.9729  1.3303

Error: Lignee
           Df  Sum Sq Mean Sq F value Pr(>F)
Residuals  4 18.0294  4.5074

Error: Pollinisateur:Lignee
           Df Sum Sq Mean Sq F value Pr(>F)
Residuals 36 5.1726  0.1437

Error: Within
           Df Sum Sq Mean Sq F value Pr(>F)
Residuals 50 3.7950  0.0759


# F tests :

 > Femp <- c(tab1[1:3, 3]/tab1[c(3,3,4), 3])
 > names(Femp) <- c("Pollinisateur", "Lignee", "Interaction")
 > Femp
Pollinisateur        Lignee   Interaction
      9.258709     31.370027      1.893061

 > 1 - pf(Femp, tab1[1:3,1], tab1[c(3,3,4),1])
Pollinisateur        Lignee   Interaction
  4.230265e-07  2.773448e-11  1.841028e-02

# Standard deviation :

 > variances <- c(c(tab1[1:3, 3] - tab1[c(3,3,4), 3]) / c(2*5, 2*10, 2), tab1[4,3])
 > names(variances) <- c(names(Femp), "Residuelle")
 > variances
Pollinisateur        Lignee   Interaction    Residuelle
    0.11866389    0.21818333    0.03389167    0.07590000

# Using lmer :

 > library(lme4)
 > summary(lmer(Rendement ~ (1 |Pollinisateur) + (1 | Lignee) + (1 | Pollinisateur:Lignee), 		 
data=mca2))

Linear mixed-effects model fit by REML
Formula: Rendement ~ (1 | Pollinisateur) + (1 | Lignee) + (1 | Pollinisateur:Lignee)
    Data: mca2
       AIC      BIC    logLik MLdeviance REMLdeviance
  105.3845 118.4104 -47.69227   94.35162     95.38453
Random effects:
  Groups               Name        Variance Std.Dev.
  Pollinisateur:Lignee (Intercept) 0.033892 0.18410
  Pollinisateur        (Intercept) 0.118664 0.34448
  Lignee               (Intercept) 0.218183 0.46710
  Residual                         0.075900 0.27550
# of obs: 100, groups: Pollinisateur:Lignee, 50; Pollinisateur, 10; Lignee, 5

Fixed effects:
             Estimate Std. Error DF t value  Pr(>|t|)
(Intercept) 12.60100    0.23862 99  52.808 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1


Thanks,

Jacques VESLOT


Prof Brian Ripley a ?crit :
> Nothing was enclosed, nor was the output from summary.aov, so we are 
> left guessing.
> 
> On Thu, 27 Oct 2005, Jacques VESLOT wrote:
> 
>> Dear R-users,
>>
>> My question is how to get right F tests for random effects in random 
>> effect models (I hope this question has not been answered too many 
>> times yet - I didn't find an answer in rhelp archives).
>>
>> My data are in mca2 (enc.) :
>>
>> names(mca2)
>> [1] "Lignee"        "Pollinisateur" "Rendement"
>>
>> dim(mca2)
>> [1] 100   3
>>
>> replications(Rendement ~ Lignee * Pollinisateur, data = mca2)
>>              Lignee        Pollinisateur Lignee:Pollinisateur
>>                  20                   10                    2
>>
>> Of course, summary(aov(Rendement ~ Pollinisateur * Lignee, data = 
>> mca2)) gives wrong tests of random effects. But, summary(aov1 <- 
>> aov(Rendement ~ Error(Pollinisateur * Lignee), data = mca2)) gives no 
>> test at all, and I have to do it like this :
>>
>> tab1 <- matrix(unlist(summary(aov1)), nc=5, byrow=T)[,1:3]
>>
>> Femp <- c(tab1[1:3, 3]/tab1[c(3,3,4), 3])
>>
>> names(Femp) <- c("Pollinisateur", "Lignee", "Interaction")
>>
>> 1 - pf(Femp, tab1[1:3,1], tab1[c(3,3,4),1])
>>
>> With "lme4" package (I did'nt succeed in writing a working formula 
>> with lme from "nlme" package), I can "see" standard deviations of 
>> random effects (but don't know how to find them) with :
>>
>> library(lme4)
>> summary(lmer(Rendement ~ (1 |Pollinisateur) + (1 | Lignee) + (1 | 
>> Pollinisateur:Lignee), data=mca2))
>>
>> but I can't get F tests.
>>
>> Thanks in advance.
>>
>> Best regards,
>>
>> Jacques VESLOT
>>
>>
>>
>>
> 
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: mca2.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051027/ce7d42e4/mca2.txt

From RKrug at sun.ac.za  Thu Oct 27 12:30:55 2005
From: RKrug at sun.ac.za (Rainer M. Krug)
Date: Thu, 27 Oct 2005 12:30:55 +0200
Subject: [R] install.packages under SuSE 10 behind proxy,
 R 2.2.0 from source
In-Reply-To: <435F96AE.9030709@sun.ac.za>
References: <435F96AE.9030709@sun.ac.za>
Message-ID: <4360AC5F.4010209@sun.ac.za>

Hi

I figured it out.
if I use install.packages(..., method="wget") it works
but if I use the default method, it doesn't.


Rainer

Rainer M. Krug wrote:
> Hi
> 
> I installed R 2.2.0 from source and want to use install.packages but it 
> doesn't work.
> 
> http_proxy is set to http://proxy.sun.ac.za:3128
> 
> but it still can't connect to the repository.
> The mirror is available, I can connect to it via the internet.
> 
> Any help welcome,
> 
> Rainer
> 
> 
> 



-- 
NEW TELEPHONE NUMBER
Tel:		+27 - (0)72 808 2975 (w)

Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
Biology (UCT)

Department of Conservation Ecology
University of Stellenbosch
Matieland 7602
South Africa

Tel:		+27 - (0)72 808 2975 (w)
Fax:		+27 - (0)21 808 3304
Cell:		+27 - (0)83 9479 042

email:	RKrug at sun.ac.za
       	Rainer at krugs.de



From subianto at gmail.com  Thu Oct 27 13:03:15 2005
From: subianto at gmail.com (Muhammad Subianto)
Date: Thu, 27 Oct 2005 13:03:15 +0200
Subject: [R] How to convert time to days
In-Reply-To: <p06210203bf858f0d23ab@[128.115.153.6]>
References: <435F9025.10908@gmail.com> <p06210203bf858f0d23ab@[128.115.153.6]>
Message-ID: <4360B3F3.3020408@gmail.com>

Thanks to everyone for your help.
Yuup, this is my stupid word "secs" which I put there.
Usually I get to run simulation on my machine only a few seconds.
Now, I recode my timestamp, but still I don't know how to make
x days, x hours, x minutes, x seconds.

Best wishes, Muhammad Subianto

On this day 26/10/2005 10:00 PM, Don MacQueen wrote:
 > The word "secs" appears in "Run time: 1.960625 secs" because you put
 > it there in your cat() statement. It has nothing to do with the
 > number itself.
 >
 > Simply try typing
 >
 >     end.time - begin.time
 >
 > at the prompt, and see what you get.
 >
 > Then see
 >    ?difftime
 > for more information. Example
 >     difftime(end.time,begin.time,units='hours')
 >
 > To get the interval formatted as "1 day, 23 hours, x minutes, x
 > seconds" you will have to do more work.
 >
 > -Don
 >
 > At 4:18 PM +0200 10/26/05, Muhammad Subianto wrote:
 >
 >>Dear all,
 >>I have ran a simulation in R.
 >>This simulation was running about at least two days.
 >>Here is below the result some part of my code about time result.
 >>I don't understand about
 >>
 >>Start time: Mon Oct 24, 2005  at  04:23:01 PM
 >> Finish time: Wed Oct 26, 2005  at  03:26:19 PM
 >>    Run time: 1.960625 secs.
 >>
 >>This is about two seconds or one day and nine hours?
 >>Then, how could I convert to 1 day, 23 hours, ? minutes, ? seconds.
 >>Thanks you very much for any suggestions.
 >>
 >>Best wishes, Muhammad Subianto
 >>
 >> >
 >>################################################################################
 >> > # Begin of program and timestamp:
 >> >   cat(format(begin.time <- Sys.time(), "%a %b %d %X %Y") ,"\n")
 >>Mon Oct 24 04:23:01 PM 2005
 >> >   cat("Start time:", secs <- format(begin.time, "%X"), "\n")
 >>Start time: 04:23:01 PM
 >> >   cat("Sys.time:", begin.time <- Sys.time(), '\n')
 >>Sys.time: 1130163781
 >> >
 >> >
 >>--- CODE SIMULATION ---
 >> >
 >> > # End of program and timestamp:
 >> >  cat("Sys.time:",end.time <- Sys.time(), '\n')
 >>Sys.time: 1130333179
 >> >  cat("Run Time:",end.time-begin.time, 'secs.\n\n')
 >>Run Time: 1.960625 secs.
 >>
 >> >  cat("Finish time:", secs <- format(end.time, "%X"), "\n")
 >>Finish time: 03:26:19 PM
 >> >  cat(format(end.time <- Sys.time(), "%a %b %d %X %Y") ,"\n")
 >>Wed Oct 26 03:26:19 PM 2005
 >> >
 >> >  cat("\n",
 >>+      " Start time:", secs  <- format(begin.time, "%a %b %d, %Y  at
 >>%X"), "\n",
 >>+      "Finish time:", secs <- format(end.time,   "%a %b %d, %Y  at
 >>%X"), "\n",
 >>+      "   Run time:", end.time-begin.time, 'secs.\n\n')
 >>
 >>  Start time: Mon Oct 24, 2005  at  04:23:01 PM
 >> Finish time: Wed Oct 26, 2005  at  03:26:19 PM
 >>    Run time: 1.960625 secs.
 >>
 >> >
 >>###########################################################################
 >>
 >>______________________________________________
 >>R-help at stat.math.ethz.ch mailing list
 >>https://stat.ethz.ch/mailman/listinfo/r-help
 >>PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html
 >
 >
 >



From jan.wiener at tuebingen.mpg.de  Thu Oct 27 13:14:59 2005
From: jan.wiener at tuebingen.mpg.de (Jan Wiener)
Date: Thu, 27 Oct 2005 13:14:59 +0200
Subject: [R] aov() and lme()
Message-ID: <4360B6B3.30302@tuebingen.mpg.de>

Sorry for reposting, but even after extensive search I still did not 
find any answers.

using: 
summary(aov(pointErrorAbs~noOfSegments*turnAngle+Error(subj/(noOfSegments+turnAngle)), 
data=anovaAllData ))

with subj being a random factor and noOfSegments and turnAngle being 
fixed factors, I get the following results:

----------------------------------------------
Error: subj
           Df Sum Sq Mean Sq F value Pr(>F)
Residuals 17 246606   14506

Error: subj:noOfSegments
              Df  Sum Sq Mean Sq F value   Pr(>F)
noOfSegments  3  7806.6  2602.2  5.3257 0.002864 **
Residuals    51 24919.4   488.6
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Error: subj:turnAngle
           Df Sum Sq Mean Sq F value  Pr(>F)
turnAngle  5  14660    2932  3.1707 0.01131 *
Residuals 85  78600     925
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Error: Within
                         Df Sum Sq Mean Sq F value    Pr(>F)
noOfSegments:turnAngle  15  19637    1309  2.9135 0.0001711 ***
Residuals              687 308687     449
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
------------------------------------------------------------------

all is fine, and I get  exactly the same results as with unix anova.


No I trying to fit the same data with lme and using the following call:

anova(lme(fixed=pointErrorAbs~noOfSegments*turnAngle, random=~1|subj, 
data=anovaAllData))

Unfortunately the results are 'really' different from the aov() 
procedure (I guess I have the call wrong):

----------------------------------------------------
(Intercept)                1   823 42.10888  <.0001
noOfSegments               3   823  5.19549  0.0015
turnAngle                  5   823  5.85379  <.0001
noOfSegments:turnAngle    15   823  2.61373  0.0007
----------------------------------------------------

I, however, need a comparable method for lme(), because in a different 
data set I have single empty cells and can therefore not use aov().

does anyone know how to fit with lme() to obtain the same results (for 
this balanced data set) as with aov().

Thanks in advance,
Jan



From RKrug at sun.ac.za  Thu Oct 27 13:47:14 2005
From: RKrug at sun.ac.za (Rainer M. Krug)
Date: Thu, 27 Oct 2005 13:47:14 +0200
Subject: [R] tcltk package problems (R 2.2.0, SuSE 10)
Message-ID: <4360BE42.6030203@sun.ac.za>

Hi

I installed R 2.2.0 from source and I have the packages for tcl and tk 
installed on my system, but the package tcltk says, when I try to load 
the library tcltk: Tcl/Tk support is not available on this system.

Are there any settings / variables which I have to set so that R 
recognises that Tcl/Tk support is installed on the system?

Rainer


-- 
NEW TELEPHONE NUMBER
Tel:		+27 - (0)72 808 2975 (w)

Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
Biology (UCT)

Department of Conservation Ecology
University of Stellenbosch
Matieland 7602
South Africa

Tel:		+27 - (0)72 808 2975 (w)
Fax:		+27 - (0)21 808 3304
Cell:		+27 - (0)83 9479 042

email:	RKrug at sun.ac.za
       	Rainer at krugs.de



From paralax at hacker.lt  Thu Oct 27 14:44:19 2005
From: paralax at hacker.lt (pou)
Date: Thu, 27 Oct 2005 05:44:19 -0700
Subject: [R] Box.test
Message-ID: <001301c5daf4$2aaa0cb0$fefefe0a@laptop>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051027/2b45fb8f/attachment.pl

From vito_ricci at yahoo.com  Thu Oct 27 15:08:23 2005
From: vito_ricci at yahoo.com (Vito Ricci)
Date: Thu, 27 Oct 2005 15:08:23 +0200 (CEST)
Subject: [R] Box.test
Message-ID: <20051027130823.22315.qmail@web36106.mail.mud.yahoo.com>

Hi, 

Give a look to the help page: 
? Box.test
Compute the Box-Pierce or Ljung-Box test statistic for
examining the null hypothesis of independence in a
given time series.

See also:
http://finzi.psych.upenn.edu/R/Rhelp02a/archive/27265.html

Regards.

Vito


You wrote:

Does p-value on Box.test(data,lag=l) returns
probability, that

H0: cor(1)=cor(2)=..=cor(l)=0 holds?

 
Thanks.



Diventare costruttori di soluzioni
Became solutions' constructors

"The business of the statistician is to catalyze 
the scientific learning process."  
George E. P. Box

"Statistical thinking will one day be as necessary for efficient citizenship as the ability to read and write"
H. G. Wells

Top 10 reasons to become a Statistician

     1. Deviation is considered normal
     2. We feel complete and sufficient
     3. We are 'mean' lovers
     4. Statisticians do it discretely and continuously
     5. We are right 95% of the time
     6. We can legally comment on someone's posterior distribution
     7. We may not be normal, but we are transformable
     8. We never have to say we are certain
     9. We are honestly significantly different
    10. No one wants our jobs


Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese  http://www.modugno.it/archivio/palesesanto_spirito/



From rolf at math.unb.ca  Thu Oct 27 15:50:26 2005
From: rolf at math.unb.ca (Rolf Turner)
Date: Thu, 27 Oct 2005 10:50:26 -0300 (ADT)
Subject: [R] Puzzled over curve() syntax.
Message-ID: <200510271350.j9RDoQqh029780@erdos.math.unb.ca>

It's probably toadally elementary (and, like, duhhhhh) but
I can't figure out why the following doesn't work:

	curve(function(x){qnorm(x,4,25)},from=0,to=1)

I get the error:

	Error in xy.coords(x, y, xlabel, ylabel, log) : 
        'x' and 'y' lengths differ

But if I do

	foo <- function(x){qnorm(x,4,25)}
	curve(foo,from=0,to=1)

it goes like a train.

Also

	plot(function(x){qnorm(x,4,25)},from=0,to=1)

works just fine.

I'm using

 > version
         _                   
platform sparc-sun-solaris2.9
arch     sparc               
os       solaris2.9          
system   sparc, solaris2.9   
status                       
major    2                   
minor    2.0                 
year     2005                
month    10                  
day      06                  
svn rev  35749               
language R 

This is just idle curiousity I guess, but I would like to deepen my
understanding.  There's probably something about the ``expression''
concept that I'm not grokking here ....

Thanks for any insight.

			cheers,

				Rolf Turner
				rolf at math.unb.ca



From S.Pickett at exeter.ac.uk  Thu Oct 27 16:11:34 2005
From: S.Pickett at exeter.ac.uk (sp219)
Date: Thu, 27 Oct 2005 15:11:34 +0100
Subject: [R] help:simple bin problem histogram
Message-ID: <436BC871@minerva2.ex.ac.uk>

Hi,
I cannot seem to change the default binning settings for the x axis 
successfully using hist(). I have tried using axis() in conjunction with 
xaxt="n", but I keep getting the error message
Warning message:
parameter "vect" could not be set in high-level plot() function
can anyone help please?

Simon Pickett
Centre for Ecology and Conservation Biology
University of Exeter in Cornwall
Tremough Campus
Penryn 
Cornwall
TR10 9EZ UK
Tel: 01326371852



From murdoch at stats.uwo.ca  Thu Oct 27 16:29:38 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 27 Oct 2005 10:29:38 -0400
Subject: [R] Puzzled over curve() syntax.
In-Reply-To: <200510271350.j9RDoQqh029780@erdos.math.unb.ca>
References: <200510271350.j9RDoQqh029780@erdos.math.unb.ca>
Message-ID: <4360E452.1070505@stats.uwo.ca>

On 10/27/2005 9:50 AM, Rolf Turner wrote:
> It's probably toadally elementary (and, like, duhhhhh) but
> I can't figure out why the following doesn't work:
> 
> 	curve(function(x){qnorm(x,4,25)},from=0,to=1)
> 
> I get the error:
> 
> 	Error in xy.coords(x, y, xlabel, ylabel, log) : 
>         'x' and 'y' lengths differ
> 
> But if I do
> 
> 	foo <- function(x){qnorm(x,4,25)}
> 	curve(foo,from=0,to=1)
> 
> it goes like a train.
> 
> Also
> 
> 	plot(function(x){qnorm(x,4,25)},from=0,to=1)
> 
> works just fine.
> 
> I'm using
> 
>  > version
>          _                   
> platform sparc-sun-solaris2.9
> arch     sparc               
> os       solaris2.9          
> system   sparc, solaris2.9   
> status                       
> major    2                   
> minor    2.0                 
> year     2005                
> month    10                  
> day      06                  
> svn rev  35749               
> language R 
> 
> This is just idle curiousity I guess, but I would like to deepen my
> understanding.  There's probably something about the ``expression''
> concept that I'm not grokking here ....

It's the way curve is written (and documented, though perhaps a little 
obscurely).  If you debug it, you'll see that eventually your function 
gets assigned to a variable called "expr", and a nice list of values 
gets assigned to "x", then it tries to evaluate

  y <- eval(expr, envir = list(x = x), enclos = parent.frame())


But if you evaluate expr, you just get the function back, you don't call 
it.  The problem is that curve was written assuming you'd call it as

curve(qnorm(x,4,25),from=0,to=1)

in which case the expression "qnorm(x,4,25)" gets evaluated at those x 
values and things are fine.

I don't think this is a bug, but it might be worth fixing so your code 
works too.  It's a little tricky, because to know that you passed a 
function in, you probably want to evaluate it; but if you evaluate 
"qnorm(x,4,25)" before you've set up x, you'll get an error.

A fix is to add an additional else clause after the first test, namely

     else if (is.language(sexpr) && identical(sexpr[[1]], 
as.name("function"))) {
           expr <- substitute(do.call(expr, list(x)), list(expr=expr))
           if (is.null(ylab))
               ylab <- deparse(sexpr)
     }

but this still doesn't handle the case where you've given a more general 
expression that returns a function, e.g. picking one out of a list. 
You'll probably need another argument to distinguish the case of an 
expression returning y values from an expression returning a function, 
and I'm not sure that level of elaboration would really be a good idea.

Duncan Murdoch



From Qinghong.Li at rdmo.nestle.com  Thu Oct 27 16:33:29 2005
From: Qinghong.Li at rdmo.nestle.com (Li,Qinghong,ST.LOUIS,Molecular Biology)
Date: Thu, 27 Oct 2005 09:33:29 -0500
Subject: [R] comment code
Message-ID: <2BA2B7291D5DC6409FD53CB7C01F0D990183B6A5@usslre00.nestle.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051027/4607eb83/attachment.pl

From ripley at stats.ox.ac.uk  Thu Oct 27 16:54:56 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 27 Oct 2005 15:54:56 +0100 (BST)
Subject: [R] comment code
In-Reply-To: <2BA2B7291D5DC6409FD53CB7C01F0D990183B6A5@usslre00.nestle.com>
References: <2BA2B7291D5DC6409FD53CB7C01F0D990183B6A5@usslre00.nestle.com>
Message-ID: <Pine.LNX.4.61.0510271548500.8594@gannet.stats>

On Thu, 27 Oct 2005, Li,Qinghong,ST.LOUIS,Molecular Biology wrote:

> In R, can one comment out a block of code at once instead of using "#" 
> one line at a time? Say, in SAS, one can use /*....*/ to comment out 
> many lines.

Try RSiteSearch("comment multiple lines").

Note that R-aware editors can do this for you using #.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ym at climpact.com  Thu Oct 27 17:04:21 2005
From: ym at climpact.com (Yves Magliulo)
Date: 27 Oct 2005 17:04:21 +0200
Subject: [R] adding sequence for each value in a vector
Message-ID: <1130425461.4992.44.camel@new-york.climpact.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051027/a9a54d05/attachment.pl

From andy_liaw at merck.com  Thu Oct 27 17:15:00 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 27 Oct 2005 11:15:00 -0400
Subject: [R] adding sequence for each value in a vector
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED52E@usctmx1106.merck.com>

Here's one way:

> unlist(lapply(x, function(x) x:(x+9)))
 [1]   1   2   3   4   5   6   7   8   9  10  15  16  17  18  19  20  21  22
23  24
[21]  30  31  32  33  34  35  36  37  38  39  45  46  47  48  49  50  51  52
53  54
[41]  60  61  62  63  64  65  66  67  68  69  90  91  92  93  94  95  96  97
98  99
[61] 115 116 117 118 119 120 121 122 123 124

Andy 

> From: Yves Magliulo
> 
> hi, 
> 
> i have a vector like :
> 
> x<-c(1,15,30,45,60,90,115)
> 
> i know that step by step i have always more than 10  
> 
> min(diff(x)) >=11
> 
> i want to add for each value a sequence of value:value+9  
> result should be :
> 
> 1 2 3 4 5 6 7 8 9 10 15 16 17 18 19 20 21 22 23 24 30 31 
> (...) 39 45 46
> (...) 54 60 61 etc..
> 
> how can i do this without a loop (i'm sure there is a 
> "elegant" way like
> always with R but i can't find it this time!)
> 
> best, 
> 
> yves
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From lizzylaws at yahoo.com  Thu Oct 27 17:19:49 2005
From: lizzylaws at yahoo.com (Elizabeth Lawson)
Date: Thu, 27 Oct 2005 08:19:49 -0700 (PDT)
Subject: [R] how to predict with logistic model  in package logistf ?
In-Reply-To: <BAY104-F307DCA3B1F016EF46EFBDFF2680@phx.gbl>
Message-ID: <20051027151949.31784.qmail@web32110.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051027/5f69cf41/attachment.pl

From ggrothendieck at gmail.com  Thu Oct 27 17:21:56 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 27 Oct 2005 11:21:56 -0400
Subject: [R] adding sequence for each value in a vector
In-Reply-To: <1130425461.4992.44.camel@new-york.climpact.net>
References: <1130425461.4992.44.camel@new-york.climpact.net>
Message-ID: <971536df0510270821v72ae3267hef774118ed142617@mail.gmail.com>

On 27 Oct 2005 17:04:21 +0200, Yves Magliulo <ym at climpact.com> wrote:
> hi,
>
> i have a vector like :
>
> x<-c(1,15,30,45,60,90,115)
>
> i know that step by step i have always more than 10
>
> min(diff(x)) >=11
>
> i want to add for each value a sequence of value:value+9
> result should be :
>
> 1 2 3 4 5 6 7 8 9 10 15 16 17 18 19 20 21 22 23 24 30 31 (...) 39 45 46
> (...) 54 60 61 etc..
>
> how can i do this without a loop (i'm sure there is a "elegant" way like
> always with R but i can't find it this time!)

Try this:

c(outer(0:9, x, "+"))



From francoisromain at free.fr  Thu Oct 27 17:31:21 2005
From: francoisromain at free.fr (Romain Francois)
Date: Thu, 27 Oct 2005 17:31:21 +0200
Subject: [R] adding sequence for each value in a vector
In-Reply-To: <1130425461.4992.44.camel@new-york.climpact.net>
References: <1130425461.4992.44.camel@new-york.climpact.net>
Message-ID: <4360F2C9.5090904@free.fr>

Le 27.10.2005 17:04, Yves Magliulo a ??crit :

>hi, 
>
>i have a vector like :
>
>x<-c(1,15,30,45,60,90,115)
>
>i know that step by step i have always more than 10  
>
>min(diff(x)) >=11
>
>i want to add for each value a sequence of value:value+9  
>result should be :
>
>1 2 3 4 5 6 7 8 9 10 15 16 17 18 19 20 21 22 23 24 30 31 (...) 39 45 46
>(...) 54 60 61 etc..
>
>how can i do this without a loop (i'm sure there is a "elegant" way like
>always with R but i can't find it this time!)
>
>best, 
>
>yves
>  
>
Also :

R> rep(x, each=10) + 0:9

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+



From uofiowa at gmail.com  Thu Oct 27 17:47:19 2005
From: uofiowa at gmail.com (Omar Lakkis)
Date: Thu, 27 Oct 2005 11:47:19 -0400
Subject: [R] its dates masked by chron
Message-ID: <3f87cc6d0510270847p7f3ad04bkc5f6b183403d0cce@mail.gmail.com>

I built R 2.2.0 from source on my debian machine yesterday and updated
all packages. My problem is that "dates" function from its, that my
code heavely uses is now masked by "dates" from chron.
How can I specify tehat I want to use dates from its or how can I
prevent it from being masked?

> library(its)
Loading required package: Hmisc
Hmisc library by Frank E Harrell Jr

Type library(help='Hmisc'), ?Overview, or ?Hmisc.Overview')
to see overall documentation.

NOTE:Hmisc no longer redefines [.factor to drop unused levels when
subsetting.  To get the old behavior of Hmisc type dropUnusedLevels().

Attaching package: 'Hmisc'


        The following object(s) are masked from package:stats :

         ecdf


Attaching package: 'chron'


        The following object(s) are masked from package:its :

         dates



From dlvanbrunt at gmail.com  Thu Oct 27 17:54:32 2005
From: dlvanbrunt at gmail.com (David L. Van Brunt, Ph.D.)
Date: Thu, 27 Oct 2005 10:54:32 -0500
Subject: [R] Repost: Examples of "classwt", "strata",
	and "sampsize" in randomForest?
In-Reply-To: <971536df0510262210ne66777y71d25a96d2656b24@mail.gmail.com>
References: <d332d3e10510262130j5f7a850awefd59e1287fa48c7@mail.gmail.com>
	<971536df0510262210ne66777y71d25a96d2656b24@mail.gmail.com>
Message-ID: <d332d3e10510270854q72a091c4p6de62ece33a2acc5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051027/36c3c961/attachment.pl

From wilks at dial.pipex.com  Thu Oct 27 18:01:25 2005
From: wilks at dial.pipex.com (John Wilkinson (pipex))
Date: Thu, 27 Oct 2005 17:01:25 +0100
Subject: [R] Extracting Variance Components
Message-ID: <JCEIJNOHMNBPLMGFDHNDGECPCBAA.wilks@dial.pipex.com>

Mike,

use ---

VarCorr(lme.object)

or for a user friendly output use varcomp from the 'ape' package--

require(ape)
varcomp(lme.object)

varcomp also allows scaling of components to unity (*100 gives %)
and also allows for cumulative sum of components.

Note. varcomp doesn't work for lmer objects.

HTH,

John
--------------------------------------------------

Michel Friesenhahn wrote---------
 
Dear List,

Is there a way to extract variance components from lmeObjects or 
summary.lme objects without using intervals()?  For my purposes I don't 
need the confidence intervals which I'm obtaining using parametric 
bootstrap.

Thanks,

Mike



From helprhelp at gmail.com  Thu Oct 27 18:27:46 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Thu, 27 Oct 2005 11:27:46 -0500
Subject: [R] memory problem in handling large dataset
Message-ID: <cdf817830510270927n62bf7a7ei7fd3a28089f8439b@mail.gmail.com>

Dear Listers:
I have a question on handling large dataset. I searched R-Search and I
hope I can get more information as to my specific case.

First, my dataset has 1.7 billion observations and 350 variables,
among which, 300 are float and 50 are integers.
My system has 8 G memory, 64bit CPU, linux box. (currently, we don't
plan to buy more memory).

> R.version
         _
platform i686-redhat-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    2
minor    1.1
year     2005
month    06
day      20
language R


If I want to do some analysis for example like randomForest on a
dataset, how many max observations can I load to get the machine run
smoothly?

After figuring out that number, I want to do some sampling first, but
I did not find read.table or scan can do this. I guess I can load it
into mysql and then use RMySQL do the sampling or use python to subset
the data first. My question is, is there a way I can subsample
directly from file just using R?

Thanks,
--
Weiwei Shi, Ph.D

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III



From Rau at demogr.mpg.de  Thu Oct 27 18:32:11 2005
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Thu, 27 Oct 2005 18:32:11 +0200
Subject: [R] outer-question
Message-ID: <8B08A3A1EA7AAC41BE24C750338754E69FDF12@HERMES.demogr.mpg.de>

Dear all,

This is a rather lengthy message, but I don't know what I made wrong in
my real example since the simple code works.
I have two variables a, b and a function f for which I would like to
calculate all possible combinations of the values of a and b.
If f is multiplication, I would simply do:

a <- 1:5
b <- 1:5
outer(a,b)

## A bit more complicated is this:
f <- function(a,b,d) {
	return(a*b+(sum(d)))
}
additional <- runif(100)
outer(X=a, Y=b, FUN=f, d=additional)

## So far so good. But now my real example. I would like to plot the
## log-likelihood surface for two parameters alpha and beta of 
## a Gompertz distribution with given data

### I have a function to generate random-numbers from a
Gompertz-Distribution
### (using the 'inversion method')

random.gomp <- function(n, alpha, beta) {
            return( (log(1-(beta/alpha*log(1-runif(n)))))/beta)
}

## Now I generate some 'lifetimes'
no.people <- 1000
al <- 0.1
bet <- 0.1
lifetimes <- random.gomp(n=no.people, alpha=al, beta=bet)

### Since I neither have censoring nor truncation in this simple case,
### the log-likelihood should be simply the sum of the log of the
### the densities (following the parametrization of Klein/Moeschberger
### Survival Analysis, p. 38)

loggomp <- function(alphas, betas, timep) {
  return(sum(log(alphas) + betas*timep + (alphas/betas *
(1-exp(betas*timep)))))
}

### Now I thought I could obtain a matrix of the log-likelihood surface
### by specifying possible values for alpha and beta with the given
data.
### I was able to produce this matrix with two for-loops. But I thought
### I could use also 'outer' in this case.
### This is what I tried:

possible.alphas <- seq(from=0.05, to=0.15, length=30)
possible.betas <- seq(from=0.05, to=0.15, length=30)

outer(X=possible.alphas, Y=possible.betas, FUN=loggomp, timep=lifetimes)

### But the result is:
> outer(X=possible.alphas, Y=possible.betas, FUN=loggomp,
timep=lifetimes)
Error in outer(X = possible.alphas, Y = possible.betas, FUN = loggomp,
: 
        dim<- : dims [product 900] do not match the length of object [1]
In addition: Warning messages:
...

### Can somebody give me some hint where the problem is?
### I checked my definition of 'loggomp' but I thought this looks fine:
loggomp(alphas=possible.alphas[1], betas=possible.betas[1],
timep=lifetimes)
loggomp(alphas=possible.alphas[4], betas=possible.betas[10],
timep=lifetimes)
loggomp(alphas=possible.alphas[3], betas=possible.betas[11],
timep=lifetimes)               


### I'd appreciate any kind of advice.               
### Thanks a lot in advance.
### Roland
               

+++++
This mail has been sent through the MPI for Demographic Rese...{{dropped}}



From uofiowa at gmail.com  Thu Oct 27 18:36:05 2005
From: uofiowa at gmail.com (Omar Lakkis)
Date: Thu, 27 Oct 2005 12:36:05 -0400
Subject: [R] its dates masked by chron
In-Reply-To: <3f87cc6d0510270847p7f3ad04bkc5f6b183403d0cce@mail.gmail.com>
References: <3f87cc6d0510270847p7f3ad04bkc5f6b183403d0cce@mail.gmail.com>
Message-ID: <3f87cc6d0510270936y5f784285y3eea6928707135a4@mail.gmail.com>

To redescribe the problem; I need to use dates from its
its depends on Hmisc
Hmisc depends chron
dates in chron masks dates in its


---------- Forwarded message ----------
From: Omar Lakkis <uofiowa at gmail.com>
Date: Oct 27, 2005 11:47 AM
Subject: its dates masked by chron
To: r-help at stat.math.ethz.ch


I built R 2.2.0 from source on my debian machine yesterday and updated
all packages. My problem is that "dates" function from its, that my
code heavely uses is now masked by "dates" from chron.
How can I specify tehat I want to use dates from its or how can I
prevent it from being masked?

> library(its)
Loading required package: Hmisc
Hmisc library by Frank E Harrell Jr

Type library(help='Hmisc'), ?Overview, or ?Hmisc.Overview')
to see overall documentation.

NOTE:Hmisc no longer redefines [.factor to drop unused levels when
subsetting.  To get the old behavior of Hmisc type dropUnusedLevels().

Attaching package: 'Hmisc'


        The following object(s) are masked from package:stats :

         ecdf


Attaching package: 'chron'


        The following object(s) are masked from package:its :

         dates



From andy_liaw at merck.com  Thu Oct 27 18:37:40 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 27 Oct 2005 12:37:40 -0400
Subject: [R] Repost: Examples of "classwt", "strata",
 and "sampsize" i n randomForest?
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED52F@usctmx1106.merck.com>

"classwt" in the current version of the randomForest package doesn't work
too well.  (It's what was in version 3.x of the original Fortran code by
Breiman and Cutler, not the one in the new Fortran code.)  I'd advise
against using it.

"sampsize" and "strata" can be use in conjunction.  If "strata" is not
specified, the class labels will be used.  Take the iris data as an example:

randomForest(Species ~ ., iris, sampsize=c(10, 30, 10))

says to randomly draw 10, 30 and 10 from the three species (with
replacement) to grow each tree.  If you are unsure of the labels, use named
vector, e.g.,

randomForest(Species ~ ., iris, 
             sampsize=c(setosa=10, versicolor=30, virginica=10))

Now, if you want the stratified sampling to be done using a different
variable than the class labels; e.g., for multi-centered clinical trial
data, you want to draw the same number of patients per center to grow each
tree (I'm just making things up, not that that necessarily makes any sense),
you can do something like:

randomForest(..., strata=center, 
             sampsize=rep(min(table(center))), nlevels(center)))

which draws the same number of patients (minimum at any center) from each
center to grow each tree.

Hope that's clear.  Eventually all such things will be in the yet to be
written package vignette...

Andy


> From: David L. Van Brunt, Ph.D.
> 
> I have read both the help files and that article... the 
> article very nicely
> evaluates the value of dealing with unbalanced data, and the 
> help files show
> that you can, but offer no guidance in terms of how the 
> syntax should be
> specified. The "strata" and "classwt" clearly can be 
> specified, but it's not
> shown how to specify the values...
> 
> The examples do not include specifications of those terms, 
> and every guess
> I've made has generated an error....
> 
> 
> On 10/27/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> >
> > See
> > http://finzi.psych.upenn.edu/R/Rhelp02a/archive/40898.html
> >
> > On 10/27/05, David L. Van Brunt, Ph.D. <dlvanbrunt at gmail.com> wrote:
> > > Sorry for the repost, but I've really been looking, and 
> can't find any
> > > syntax direction on this issue...
> > >
> > > Just browsing the documentation, and searching the list 
> came up short...
> > I
> > > have some unbalanced data and was wondering if, in a "0" v "1"
> > > classification forest, some combo of these options might 
> yield better
> > > predictions when the proportion of one class is low (less 
> than 10% in a
> > > sample of 2,000 observations).
> > >
> > > Not sure how to specify these terms... from the docs, we have:
> > >
> > > classwt: Priors of the classes. Need not add up to one. 
> Ignored for
> > > regression.
> > >
> > > So is this something like "... classwt=c(.90,.10)" ? I 
> didn't see the
> > syntax
> > > demonstrated. Similar for "strata" and "sampsize" though 
> there is a
> > default
> > > for sampsize that makes sense... not sure how you would 
> make "a vector
> > of
> > > the length the number of strata", however....
> > >
> > > Pointers?
> > >
> > > --
> > > ---------------------------------------
> > > David L. Van Brunt, Ph.D.
> > > mailto:dlvanbrunt at gmail.com
> > >
> > > --
> > > ---------------------------------------
> > > David L. Van Brunt, Ph.D.
> > > mailto:dlvanbrunt at gmail.com
> > >
> > > [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > >
> >
> 
> 
> 
> --
> ---------------------------------------
> David L. Van Brunt, Ph.D.
> mailto:dlvanbrunt at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From gunter.berton at gene.com  Thu Oct 27 18:49:33 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Thu, 27 Oct 2005 09:49:33 -0700
Subject: [R] memory problem in handling large dataset
In-Reply-To: <cdf817830510270927n62bf7a7ei7fd3a28089f8439b@mail.gmail.com>
Message-ID: <200510271649.j9RGnXNA011300@volta.gene.com>

I think the general advice is that around 1/4 or 1/3 of your available
memory is about the largest data set that R can handle -- and often
considerably less depending upon what you do and how you do it (because R's
semantics require explicitly copying objects rather than passing pointers).
Fancy tricks using environments might enable you to do better, but that
requires advice from a true guru, which I ain't.

See ?connections, ?scan, ?seek  for reading in a file a chunk at a time from
a connection, thus enabling you to sample one line of data from each chunk,
say.

I suppose you could do this directly with repeated calls to scan() or
read.table() by skipping more and more lines at the beginning at each call,
but I assume that is horridly inefficient and would take forever.

HTH.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Weiwei Shi
> Sent: Thursday, October 27, 2005 9:28 AM
> To: r-help
> Subject: [R] memory problem in handling large dataset
> 
> Dear Listers:
> I have a question on handling large dataset. I searched R-Search and I
> hope I can get more information as to my specific case.
> 
> First, my dataset has 1.7 billion observations and 350 variables,
> among which, 300 are float and 50 are integers.
> My system has 8 G memory, 64bit CPU, linux box. (currently, we don't
> plan to buy more memory).
> 
> > R.version
>          _
> platform i686-redhat-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    2
> minor    1.1
> year     2005
> month    06
> day      20
> language R
> 
> 
> If I want to do some analysis for example like randomForest on a
> dataset, how many max observations can I load to get the machine run
> smoothly?
> 
> After figuring out that number, I want to do some sampling first, but
> I did not find read.table or scan can do this. I guess I can load it
> into mysql and then use RMySQL do the sampling or use python to subset
> the data first. My question is, is there a way I can subsample
> directly from file just using R?
> 
> Thanks,
> --
> Weiwei Shi, Ph.D
> 
> "Did you always know?"
> "No, I did not. But I believed..."
> ---Matrix III
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From vincent at 7d4.com  Thu Oct 27 19:00:10 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Thu, 27 Oct 2005 19:00:10 +0200
Subject: [R] how to write and read an array ?
Message-ID: <4361079A.1000502@7d4.com>

Hi,
Apologies if the question is too simple
but I didn't find the answer by myself.

I'm able to create a 3-dimensionnal array A
and to write it with write.table()
... but, after that, I don't find how to read it
with read.table() getting the right 3 dimensions.

I tried to use as.array(), to force the dim, etc
but it didn't work.
(It's probably obvious ... ?)

Thanks for your info or pointer.
Vincent



From p.dalgaard at biostat.ku.dk  Thu Oct 27 19:03:38 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 27 Oct 2005 19:03:38 +0200
Subject: [R] its dates masked by chron
In-Reply-To: <3f87cc6d0510270936y5f784285y3eea6928707135a4@mail.gmail.com>
References: <3f87cc6d0510270847p7f3ad04bkc5f6b183403d0cce@mail.gmail.com>
	<3f87cc6d0510270936y5f784285y3eea6928707135a4@mail.gmail.com>
Message-ID: <x2irviyjrp.fsf@turmalin.kubism.ku.dk>

Omar Lakkis <uofiowa at gmail.com> writes:

> To redescribe the problem; I need to use dates from its
> its depends on Hmisc
> Hmisc depends chron
> dates in chron masks dates in its

So use its::dates ...
 
> 
> ---------- Forwarded message ----------
> From: Omar Lakkis <uofiowa at gmail.com>
> Date: Oct 27, 2005 11:47 AM
> Subject: its dates masked by chron
> To: r-help at stat.math.ethz.ch
> 
> 
> I built R 2.2.0 from source on my debian machine yesterday and updated
> all packages. My problem is that "dates" function from its, that my
> code heavely uses is now masked by "dates" from chron.
> How can I specify tehat I want to use dates from its or how can I
> prevent it from being masked?
> 
> > library(its)
> Loading required package: Hmisc
> Hmisc library by Frank E Harrell Jr
> 
> Type library(help='Hmisc'), ?Overview, or ?Hmisc.Overview')
> to see overall documentation.
> 
> NOTE:Hmisc no longer redefines [.factor to drop unused levels when
> subsetting.  To get the old behavior of Hmisc type dropUnusedLevels().
> 
> Attaching package: 'Hmisc'
> 
> 
>         The following object(s) are masked from package:stats :
> 
>          ecdf
> 
> 
> Attaching package: 'chron'
> 
> 
>         The following object(s) are masked from package:its :
> 
>          dates
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From nali at umn.edu  Thu Oct 27 19:02:34 2005
From: nali at umn.edu (Na Li)
Date: Thu, 27 Oct 2005 12:02:34 -0500
Subject: [R] RSQLite problems
Message-ID: <29k6fy7v11.fsf@bass.biostat.umn.edu>


Hi, I'm experimenting with using (R)SQLite to do data management.  Here are
two little problems that I've encountered:

1. The presence of ',' in string values causes trouble since ',' is also the
   delimiter used in the SQL statement. 

2. A newline '\n' line attached to the last string value of each row. 

Some examples:

> library (RSQLite)
Loading required package: DBI
> sqlite <- dbDriver ("SQLite")
> db <- dbConnect (sqlite, dbname = "test.dbms")
> data (barley)
> dbWriteTable (db, "barley", barley, overwrite = TRUE)
[1] TRUE
> barley[1:3,]
     yield   variety year            site
1 27.00000 Manchuria 1931 University Farm
2 48.86667 Manchuria 1931          Waseca
3 27.43334 Manchuria 1931          Morris
> dbReadTable (db, "barley")[1:3,]
     yield   variety year__1              site
1 27.00000 Manchuria    1931 University Farm\n
2 48.86667 Manchuria    1931          Waseca\n
3 27.43334 Manchuria    1931          Morris\n

> barley$site <- as.character (barley$site)
> barley$site[1] <- "University, Farm"
> dbWriteTable (db, "barley", barley, overwrite = TRUE)
Error in sqliteWriteTable(conn, name, value, ...) : 
	RS-DBI driver: (RS_sqlite_import: /tmp/RtmpgSNaLn/rsdbi6a5d128c line 1
expected 5 columns of data but found 6)

I'm using RSQLite 0.4.0 with R 2.1.1 on Mac OS X.

Cheers,

Michael



From HDoran at air.org  Thu Oct 27 19:14:26 2005
From: HDoran at air.org (Doran, Harold)
Date: Thu, 27 Oct 2005 13:14:26 -0400
Subject: [R] F tests for random effect models
Message-ID: <F5ED48890E2ACB468D0F3A64989D335ACDC493@dc1ex3.air.org>

I think what you're looking for is in anova() 

> fm1 <- lmer(dv ~ IV ...)
> anova(fm1)



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jacques VESLOT
Sent: Thursday, October 27, 2005 2:22 AM
To: R-help at stat.math.ethz.ch
Subject: [R] F tests for random effect models

Dear R-users,

My question is how to get right F tests for random effects in random
effect models (I hope this question has not been answered too many times
yet - I didn't find an answer in rhelp archives).

My data are in mca2 (enc.) :

names(mca2)
[1] "Lignee"        "Pollinisateur" "Rendement"

dim(mca2)
[1] 100   3

replications(Rendement ~ Lignee * Pollinisateur, data = mca2)
               Lignee        Pollinisateur Lignee:Pollinisateur
                   20                   10                    2

Of course, summary(aov(Rendement ~ Pollinisateur * Lignee, data = mca2))
gives wrong tests of random effects. But, summary(aov1 <- aov(Rendement
~ Error(Pollinisateur * Lignee), data = mca2)) gives no test at all, and
I have to do it like this :

tab1 <- matrix(unlist(summary(aov1)), nc=5, byrow=T)[,1:3]

Femp <- c(tab1[1:3, 3]/tab1[c(3,3,4), 3])

names(Femp) <- c("Pollinisateur", "Lignee", "Interaction")

1 - pf(Femp, tab1[1:3,1], tab1[c(3,3,4),1])

With "lme4" package (I did'nt succeed in writing a working formula with
lme from "nlme" package), I can "see" standard deviations of random
effects (but don't know how to find them) with :

library(lme4)
summary(lmer(Rendement ~ (1 |Pollinisateur) + (1 | Lignee) + (1 |
Pollinisateur:Lignee), data=mca2))

but I can't get F tests.

Thanks in advance.

Best regards,

Jacques VESLOT



From tplate at acm.org  Thu Oct 27 19:19:47 2005
From: tplate at acm.org (Tony Plate)
Date: Thu, 27 Oct 2005 11:19:47 -0600
Subject: [R] outer-question
In-Reply-To: <8B08A3A1EA7AAC41BE24C750338754E69FDF12@HERMES.demogr.mpg.de>
References: <8B08A3A1EA7AAC41BE24C750338754E69FDF12@HERMES.demogr.mpg.de>
Message-ID: <43610C33.7090403@acm.org>

It looks like you didn't vectorize the function you gave "outer" in your 
longer example.

Consider your short example with a diagnostic printout:

 > a <- 1:3
 > b <- 1:4
 > f <- function(a,b,d) {
+     cat("In f:", length(a), length(b), "\n")
+     return(a*b+(sum(d)))
+ }
 > additional <- runif(100)
 > outer(X=a, Y=b, FUN=f, d=additional)
In f: 12 12
          [,1]     [,2]     [,3]     [,4]
[1,] 53.61985 54.61985 55.61985 56.61985
[2,] 54.61985 56.61985 58.61985 60.61985
[3,] 55.61985 58.61985 61.61985 64.61985
 >

Note that "f" is called only once, with vectors for "a" and "b".

-- Tony Plate

Rau, Roland wrote:
> Dear all,
> 
> This is a rather lengthy message, but I don't know what I made wrong in
> my real example since the simple code works.
> I have two variables a, b and a function f for which I would like to
> calculate all possible combinations of the values of a and b.
> If f is multiplication, I would simply do:
> 
> a <- 1:5
> b <- 1:5
> outer(a,b)
> 
> ## A bit more complicated is this:
> f <- function(a,b,d) {
> 	return(a*b+(sum(d)))
> }
> additional <- runif(100)
> outer(X=a, Y=b, FUN=f, d=additional)
> 
> ## So far so good. But now my real example. I would like to plot the
> ## log-likelihood surface for two parameters alpha and beta of 
> ## a Gompertz distribution with given data
> 
> ### I have a function to generate random-numbers from a
> Gompertz-Distribution
> ### (using the 'inversion method')
> 
> random.gomp <- function(n, alpha, beta) {
>             return( (log(1-(beta/alpha*log(1-runif(n)))))/beta)
> }
> 
> ## Now I generate some 'lifetimes'
> no.people <- 1000
> al <- 0.1
> bet <- 0.1
> lifetimes <- random.gomp(n=no.people, alpha=al, beta=bet)
> 
> ### Since I neither have censoring nor truncation in this simple case,
> ### the log-likelihood should be simply the sum of the log of the
> ### the densities (following the parametrization of Klein/Moeschberger
> ### Survival Analysis, p. 38)
> 
> loggomp <- function(alphas, betas, timep) {
>   return(sum(log(alphas) + betas*timep + (alphas/betas *
> (1-exp(betas*timep)))))
> }
> 
> ### Now I thought I could obtain a matrix of the log-likelihood surface
> ### by specifying possible values for alpha and beta with the given
> data.
> ### I was able to produce this matrix with two for-loops. But I thought
> ### I could use also 'outer' in this case.
> ### This is what I tried:
> 
> possible.alphas <- seq(from=0.05, to=0.15, length=30)
> possible.betas <- seq(from=0.05, to=0.15, length=30)
> 
> outer(X=possible.alphas, Y=possible.betas, FUN=loggomp, timep=lifetimes)
> 
> ### But the result is:
> 
>>outer(X=possible.alphas, Y=possible.betas, FUN=loggomp,
> 
> timep=lifetimes)
> Error in outer(X = possible.alphas, Y = possible.betas, FUN = loggomp,
> : 
>         dim<- : dims [product 900] do not match the length of object [1]
> In addition: Warning messages:
> ...
> 
> ### Can somebody give me some hint where the problem is?
> ### I checked my definition of 'loggomp' but I thought this looks fine:
> loggomp(alphas=possible.alphas[1], betas=possible.betas[1],
> timep=lifetimes)
> loggomp(alphas=possible.alphas[4], betas=possible.betas[10],
> timep=lifetimes)
> loggomp(alphas=possible.alphas[3], betas=possible.betas[11],
> timep=lifetimes)               
> 
> 
> ### I'd appreciate any kind of advice.               
> ### Thanks a lot in advance.
> ### Roland
>                
> 
> +++++
> This mail has been sent through the MPI for Demographic Rese...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From andy_liaw at merck.com  Thu Oct 27 19:21:00 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 27 Oct 2005 13:21:00 -0400
Subject: [R] memory problem in handling large dataset
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED532@usctmx1106.merck.com>

If my calculation is correct (very doubtful, sometimes), that's

> 1.7e9 * (300 * 8 + 50 * 4) / 1024^3
[1] 4116.446

or over 4 terabytes, just to store the data in memory.

To sample rows and read that into R, Bert's suggestion of using connections,
perhaps along with seek() for skipping ahead, would be what I'd try.  I had
try to do such things in Python as a chance to learn that language, but I
found operationally it's easier to maintain the project by doing everything
in one language, namely R, if possible.

Andy


> From: Berton Gunter
> 
> I think the general advice is that around 1/4 or 1/3 of your available
> memory is about the largest data set that R can handle -- and often
> considerably less depending upon what you do and how you do 
> it (because R's
> semantics require explicitly copying objects rather than 
> passing pointers).
> Fancy tricks using environments might enable you to do 
> better, but that
> requires advice from a true guru, which I ain't.
> 
> See ?connections, ?scan, ?seek  for reading in a file a chunk 
> at a time from
> a connection, thus enabling you to sample one line of data 
> from each chunk,
> say.
> 
> I suppose you could do this directly with repeated calls to scan() or
> read.table() by skipping more and more lines at the beginning 
> at each call,
> but I assume that is horridly inefficient and would take forever.
> 
> HTH.
> 
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
>  
> "The business of the statistician is to catalyze the 
> scientific learning
> process."  - George E. P. Box
>  
>  
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Weiwei Shi
> > Sent: Thursday, October 27, 2005 9:28 AM
> > To: r-help
> > Subject: [R] memory problem in handling large dataset
> > 
> > Dear Listers:
> > I have a question on handling large dataset. I searched 
> R-Search and I
> > hope I can get more information as to my specific case.
> > 
> > First, my dataset has 1.7 billion observations and 350 variables,
> > among which, 300 are float and 50 are integers.
> > My system has 8 G memory, 64bit CPU, linux box. (currently, we don't
> > plan to buy more memory).
> > 
> > > R.version
> >          _
> > platform i686-redhat-linux-gnu
> > arch     i686
> > os       linux-gnu
> > system   i686, linux-gnu
> > status
> > major    2
> > minor    1.1
> > year     2005
> > month    06
> > day      20
> > language R
> > 
> > 
> > If I want to do some analysis for example like randomForest on a
> > dataset, how many max observations can I load to get the machine run
> > smoothly?
> > 
> > After figuring out that number, I want to do some sampling 
> first, but
> > I did not find read.table or scan can do this. I guess I can load it
> > into mysql and then use RMySQL do the sampling or use 
> python to subset
> > the data first. My question is, is there a way I can subsample
> > directly from file just using R?
> > 
> > Thanks,
> > --
> > Weiwei Shi, Ph.D
> > 
> > "Did you always know?"
> > "No, I did not. But I believed..."
> > ---Matrix III
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From d.firth at warwick.ac.uk  Thu Oct 27 19:22:22 2005
From: d.firth at warwick.ac.uk (David Firth)
Date: Thu, 27 Oct 2005 18:22:22 +0100
Subject: [R] how to predict with logistic model  in package logistf ?
In-Reply-To: <BAY104-F307DCA3B1F016EF46EFBDFF2680@phx.gbl>
References: <BAY104-F307DCA3B1F016EF46EFBDFF2680@phx.gbl>
Message-ID: <d47bdfa337c14dbc63b319caab572105@warwick.ac.uk>

On 27 Oct 2005, at 09:18, jinlong li wrote:

> dear community,
>      I am a beginer in R , and can't predict with logistic model  in 
> package
> logistf,

Not exactly the answer to your question, but an alternative to the 
logistf package, which purports to do similar things, is brlr (which 
does provide a predict method).  Does this work for you?

   library(brlr)
   data(sex2)
   fit <- brlr(case ~ age + oc + vic + vicl + vis + dia, data = sex2)
   predict(fit, newdata = sex2)

David

> could anyone help me ? thanks !
>
> the following is my command and result :
>
>> library(logistf)
>> data(sex2)
>> fit<-logistf(case ~ age+oc+vic+vicl+vis+dia, data=sex2)
>> predict(fit,newdata=sex2)
>    Error in predict(fit, newdata = sex2) : no applicable method for
> "predict"
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From helprhelp at gmail.com  Thu Oct 27 19:24:56 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Thu, 27 Oct 2005 12:24:56 -0500
Subject: [R] memory problem in handling large dataset
In-Reply-To: <644e1f320510271006mc2b2bfj3954b2742bcb8edd@mail.gmail.com>
References: <cdf817830510270927n62bf7a7ei7fd3a28089f8439b@mail.gmail.com>
	<644e1f320510271006mc2b2bfj3954b2742bcb8edd@mail.gmail.com>
Message-ID: <cdf817830510271024l1e70cfe7u85a50769dd9cd7e6@mail.gmail.com>

Hi, Jim:
Thanks for the calculation. I think you won't mind if I cc the reply
to r-help too so that I can get more info.

I assume you use 4 bytes for integer and 8 bytes for float, so
300x8+50x4=2600 bytes for each observation, right?

I wish I could have 500x8 G memory :) just kidding.. definately,
sampling will be proceeded as the first step. Some feature selections
(filtering, mainly) will be applied. Accepting Berton's suggestion, I
will probably use python to do the sampling since whenever I have some
"slow" situations like this, python never fails me. (I am not saying R
is bad though)

I understand "I get what I pay" here.  But more information or
experience on R's handling large dataset (like using RMySQL) will be
appreciated.

regards,

Weiwei

On 10/27/05, jim holtman <jholtman at gmail.com> wrote:
> Based on the numbers that you  gave, if you wanted all the data in memory at
> once, you would need 4.4TB of memory, about 500X what you currently have.
> Each of you observation will require about 2,600 bytes of memory.  You
> probably don't want to have more than 25% for a single object since many of
> the algorithms make copies.  This would limit you to about 700,000
> observations at a time for processing.
>
> The real question is what are you trying to do with the data.  Can you
> partition the data and do analysis on the subsets?
>
>
> On 10/27/05, Weiwei Shi <helprhelp at gmail.com> wrote:
> >
> > Dear Listers:
> > I have a question on handling large dataset. I searched R-Search and I
> > hope I can get more information as to my specific case.
> >
> > First, my dataset has 1.7 billion observations and 350 variables,
> > among which, 300 are float and 50 are integers.
> > My system has 8 G memory, 64bit CPU, linux box. (currently, we don't
> > plan to buy more memory).
> >
> > > R.version
> >         _
> > platform i686-redhat-linux-gnu
> > arch     i686
> > os       linux-gnu
> > system   i686, linux-gnu
> > status
> > major    2
> > minor    1.1
> > year     2005
> > month    06
> > day      20
> > language R
> >
> >
> > If I want to do some analysis for example like randomForest on a
> > dataset, how many max observations can I load to get the machine run
> > smoothly?
> >
> > After figuring out that number, I want to do some sampling first, but
> > I did not find read.table or scan can do this. I guess I can load it
> > into mysql and then use RMySQL do the sampling or use python to subset
> > the data first. My question is, is there a way I can subsample
> > directly from file just using R?
> >
> > Thanks,
> > --
> > Weiwei Shi, Ph.D
> >
> > "Did you always know?"
> > "No, I did not. But I believed..."
> > ---Matrix III
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
>
>
>
> --
> Jim Holtman
> Cincinnati, OH
> +1 513 247 0281
>
> What the problem you are trying to solve?


--
Weiwei Shi, Ph.D

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III



From helprhelp at gmail.com  Thu Oct 27 19:27:25 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Thu, 27 Oct 2005 12:27:25 -0500
Subject: [R] memory problem in handling large dataset
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED532@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED532@usctmx1106.merck.com>
Message-ID: <cdf817830510271027w476bc95evd34de43986adf322@mail.gmail.com>

Dear Andy:
I think our emails crossed. But thanks as before.

Weiwei

On 10/27/05, Liaw, Andy <andy_liaw at merck.com> wrote:
> If my calculation is correct (very doubtful, sometimes), that's
>
> > 1.7e9 * (300 * 8 + 50 * 4) / 1024^3
> [1] 4116.446
>
> or over 4 terabytes, just to store the data in memory.
>
> To sample rows and read that into R, Bert's suggestion of using connections,
> perhaps along with seek() for skipping ahead, would be what I'd try.  I had
> try to do such things in Python as a chance to learn that language, but I
> found operationally it's easier to maintain the project by doing everything
> in one language, namely R, if possible.
>
> Andy
>
>
> > From: Berton Gunter
> >
> > I think the general advice is that around 1/4 or 1/3 of your available
> > memory is about the largest data set that R can handle -- and often
> > considerably less depending upon what you do and how you do
> > it (because R's
> > semantics require explicitly copying objects rather than
> > passing pointers).
> > Fancy tricks using environments might enable you to do
> > better, but that
> > requires advice from a true guru, which I ain't.
> >
> > See ?connections, ?scan, ?seek  for reading in a file a chunk
> > at a time from
> > a connection, thus enabling you to sample one line of data
> > from each chunk,
> > say.
> >
> > I suppose you could do this directly with repeated calls to scan() or
> > read.table() by skipping more and more lines at the beginning
> > at each call,
> > but I assume that is horridly inefficient and would take forever.
> >
> > HTH.
> >
> > -- Bert Gunter
> > Genentech Non-Clinical Statistics
> > South San Francisco, CA
> >
> > "The business of the statistician is to catalyze the
> > scientific learning
> > process."  - George E. P. Box
> >
> >
> >
> > > -----Original Message-----
> > > From: r-help-bounces at stat.math.ethz.ch
> > > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Weiwei Shi
> > > Sent: Thursday, October 27, 2005 9:28 AM
> > > To: r-help
> > > Subject: [R] memory problem in handling large dataset
> > >
> > > Dear Listers:
> > > I have a question on handling large dataset. I searched
> > R-Search and I
> > > hope I can get more information as to my specific case.
> > >
> > > First, my dataset has 1.7 billion observations and 350 variables,
> > > among which, 300 are float and 50 are integers.
> > > My system has 8 G memory, 64bit CPU, linux box. (currently, we don't
> > > plan to buy more memory).
> > >
> > > > R.version
> > >          _
> > > platform i686-redhat-linux-gnu
> > > arch     i686
> > > os       linux-gnu
> > > system   i686, linux-gnu
> > > status
> > > major    2
> > > minor    1.1
> > > year     2005
> > > month    06
> > > day      20
> > > language R
> > >
> > >
> > > If I want to do some analysis for example like randomForest on a
> > > dataset, how many max observations can I load to get the machine run
> > > smoothly?
> > >
> > > After figuring out that number, I want to do some sampling
> > first, but
> > > I did not find read.table or scan can do this. I guess I can load it
> > > into mysql and then use RMySQL do the sampling or use
> > python to subset
> > > the data first. My question is, is there a way I can subsample
> > > directly from file just using R?
> > >
> > > Thanks,
> > > --
> > > Weiwei Shi, Ph.D
> > >
> > > "Did you always know?"
> > > "No, I did not. But I believed..."
> > > ---Matrix III
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> > >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> >
>
>
> ------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any attachment...{{dropped}}



From gerifalte28 at hotmail.com  Thu Oct 27 19:31:24 2005
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Thu, 27 Oct 2005 17:31:24 +0000
Subject: [R] how to write and read an array ?
In-Reply-To: <4361079A.1000502@7d4.com>
Message-ID: <BAY103-F15974A786711692ABF2858A6680@phx.gbl>

check ?dput and ?dget

Cheers

Francisco

>From: vincent at 7d4.com
>To: r-help at stat.math.ethz.ch
>Subject: [R] how to write and read an array ?
>Date: Thu, 27 Oct 2005 19:00:10 +0200
>
>Hi,
>Apologies if the question is too simple
>but I didn't find the answer by myself.
>
>I'm able to create a 3-dimensionnal array A
>and to write it with write.table()
>... but, after that, I don't find how to read it
>with read.table() getting the right 3 dimensions.
>
>I tried to use as.array(), to force the dim, etc
>but it didn't work.
>(It's probably obvious ... ?)
>
>Thanks for your info or pointer.
>Vincent
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From nali at umn.edu  Thu Oct 27 19:34:13 2005
From: nali at umn.edu (Na Li)
Date: Thu, 27 Oct 2005 12:34:13 -0500
Subject: [R] encrypted RData file?
Message-ID: <dc3bmm7tka.fsf@bass.biostat.umn.edu>


Hi, I wonder if there is interest/intention to allow for encrypted .RData
files?  One can certainly do that outside R manually but that will leave a
decrypted RData file somewhere which one has to remember to delete.

Cheers,

Michael



From dlvanbrunt at gmail.com  Thu Oct 27 19:37:04 2005
From: dlvanbrunt at gmail.com (David L. Van Brunt, Ph.D.)
Date: Thu, 27 Oct 2005 12:37:04 -0500
Subject: [R] Repost: Examples of "classwt", "strata",
	and "sampsize" i n randomForest?
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED52F@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED52F@usctmx1106.merck.com>
Message-ID: <d332d3e10510271037r6e97a045k7fa464310093f447@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051027/62af78d6/attachment.pl

From deepayan.sarkar at gmail.com  Thu Oct 27 19:37:50 2005
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 27 Oct 2005 12:37:50 -0500
Subject: [R] adding error bars to lattice plots
In-Reply-To: <af34d0c00510200952u54663a70o73e6f115622b58c8@mail.gmail.com>
References: <af34d0c00510191434v23e2be42v493570589417deec@mail.gmail.com>
	<200510192219.j9JMJIEo018489@ohm.gene.com>
	<af34d0c00510200952u54663a70o73e6f115622b58c8@mail.gmail.com>
Message-ID: <eb555e660510271037j5303835bw4d687ccd077060eb@mail.gmail.com>

On 10/20/05, Mario Aigner-Torres <mario.aignertorres at gmail.com> wrote:

[...]

> I have right now a dataset that looks like this:
>
> > tail(partition, 3)
> element run logfO2 TC buffer xAn sdXan Di Disigma
> 416 Al 36 -0.68 1180 AIR 0.734 0.007 2.10 0.02
> 417 Ca 36 -0.68 1180 AIR 0.734 0.007 1.29 0.02
> 418 Na 36 -0.68 1180 AIR 0.734 0.007 1.16 0.06
>
> Basicaly I would like to insert error bars into a xyplot like this

[...]

Generally speaking, you need to pass some auxiliary variables to the
panel function. This is easy to do, since all unrecognized arguments
are passed to the panel function anyway. The trick is to figure out
inside the panel function which elements of these variables correspond
to the subset of data in that panel. This is done using the subscripts
argument. So, for example, you can define


prepanel.ci <- function(x, y, lx, ux, subscripts, ...)
{
    x <- as.numeric(x)
    lx <- as.numeric(lx[subscripts])
    ux <- as.numeric(ux[subscripts])
    list(xlim = range(x, ux, lx, finite = TRUE))
}


panel.ci <- function(x, y, lx, ux, subscripts, pch = 16, ...)
{
    x <- as.numeric(x)
    y <- as.numeric(y)
    lx <- as.numeric(lx[subscripts])
    ux <- as.numeric(ux[subscripts])
    panel.abline(h = unique(y), col = "grey")
    panel.arrows(lx, y, ux, y, col = 'black',
                 length = 0.25, unit = "native",
                 angle = 90, code = 3)
    panel.xyplot(x, y, pch = pch, ...)
}


and then add these to your call, supplying suitable values for lx and
ux (the vectors of lower and upper limits). The one glitch with this
approach is that unlike variables in the formula (and groups, which is
treated specially because of its ubiquity but  otherwise works on
exactly the same principle), lx and ly will not be evaluated in
'data'.  I like to use 'with' to get around this. Here's an example
with the singer data, it should be easy to translate to your example.

singer.split <-
    with(singer,
         split(height, voice.part))

singer.ucl <-
    sapply(singer.split,
           function(x) {
               st <- boxplot.stats(x)
               c(st$stats[3], st$conf)
           })

singer.ucl <- as.data.frame(t(singer.ucl))
names(singer.ucl) <- c("median", "lower", "upper")
singer.ucl$voice.part <-
    factor(rownames(singer.ucl),
           levels = rownames(singer.ucl))

## show the data frame
singer.ucl

with(singer.ucl,
     xyplot(voice.part ~ median,
            lx = lower, ux = upper,
            prepanel = prepanel.ci,
            panel = panel.ci))

-Deepayan



From aldeluis at usal.es  Thu Oct 27 19:40:20 2005
From: aldeluis at usal.es (Al)
Date: Thu, 27 Oct 2005 19:40:20 +0200
Subject: [R] Problems with source() function
Message-ID: <1130434820.14225.40.camel@trinity>

Hello list members!

I'm trying to enter some data in an R session using source() function
with an URL as argument. The data source is a PHP script located in an
apache web server and the data is a long list generated on-the-fly,
these are the initial lines:

groups<-list()
groups[['ENSMUST00000000001']]=c(52611,483683,147952,132170,297514,469248,291525,364037,469915,55472,280220,314688,415650,486875,440898,6781,497785) groups[['ENSMUST00000000003']]=c(416911,327120,425495,72272,297529,101933,371418,139034,318872,367204,237702) groups[['ENSMUST00000000028']]=c(199311,325400,184761,241988,376845,75052,67724,404240,439543,391057,393816) groups[['ENSMUST00000000031']]=c(402587,352900,139030,186068,463553,328881,74942,277085,301431,256149,410846) groups[['ENSMUST00000000033']]=c(12700,23908,11140,122358,389908,390084,383903,354007,457965,106395,131876) groups[['ENSMUST00000000049']]=c(59336,203239,101077,382882,327374,281549,212042,275594,361523,490934,240275) groups[['ENSMUST00000000056']]=c(409571,304584,394332,379699,13785,4260,288889,42538,304075,47734,485512,52501,328509,504846,334607,82566,250088,150240,16422,446551,314484,91878,124752,341638,379512,379890,319764,8019,59221,156508,362524,74001,149400) groups[['ENSMUST00000000058']]=c(26511,455190,466368,358528,268486,315461,149260,422804,137641,163718,352555)

The problem:
When I execute the command it apparently finish ok, without printed
errors but when I test the consistency of the data entered using the
command length() I always obtain different figures.

More facts:
When I source the data from a static file instead an url, the data is
fully entered and the length is always the same (20346 list elements).
It delays 30 secs to load.

When I source the data from the dynamic way, from an url, it delays 2
min. and always data is truncated.

Tried and miserably failed:
- Changed .Options$timeout from 60 to 300
- Using R --verbose is of no help, the data is silently truncated. 
- Changed the expression in which data is entered:
groups<-list(
'ENSMUST00000000001'=c(52611,483683,147952,132170,297514,469248,291525,364037,469915,55472,280220,314688,415650,486875,440898,6781,497785),
'ENSMUST00000000003'=c(416911,327120,425495,72272,297529,101933,371418,139034,318872,367204,237702)
...
)

Kind list members, is there some timeout I am missing? Some way to debug
the process? Some suggestion?

Sincerely, thank you!

Alberto de Luis
www.cicancer.org



From deepayan.sarkar at gmail.com  Thu Oct 27 19:42:52 2005
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 27 Oct 2005 12:42:52 -0500
Subject: [R] horizontal violin plots?
In-Reply-To: <ypx6sluoa1ae.fsf@uracil.uio.no>
References: <ypx6sluoa1ae.fsf@uracil.uio.no>
Message-ID: <eb555e660510271042u36240018p6d1a643fa7128c16@mail.gmail.com>

On 10/26/05, Karin Lagesen <karin.lagesen at medisin.uio.no> wrote:
>
> I am trying to make horizontal violin plots. I have tried both vioplot
> and simple.violinplot, but both of them seem to not be willing to take
> the horizontal option. Is this correct, or am I just bungling it
> somehow?
>
> For instance, for vioplot (from the example shown, with the horizontal
> modification):
>
>
> > vioplot(bimodal,uniform,normal, horizontal=TRUE)
> Error in median(data) : need numeric data

One possibility is to use lattice instead, see e.g.

library(lattice)
example(panel.violin)

HTH,
Deepayan



From duncan at wald.ucdavis.edu  Thu Oct 27 20:17:02 2005
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Thu, 27 Oct 2005 11:17:02 -0700
Subject: [R] encrypted RData file?
In-Reply-To: <dc3bmm7tka.fsf@bass.biostat.umn.edu>
References: <dc3bmm7tka.fsf@bass.biostat.umn.edu>
Message-ID: <4361199E.8060402@wald.ucdavis.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


Yes, it is of interest and was sitting on my todo list at
some time.  If you want to go ahead and provide code to do it,
that would be terrific.  There are other areas where encryption
would be good to have, so a general mechanism would be nice.

D.

Na Li wrote:
> Hi, I wonder if there is interest/intention to allow for encrypted .RData
> files?  One can certainly do that outside R manually but that will leave a
> decrypted RData file somewhere which one has to remember to delete.
> 
> Cheers,
> 
> Michael
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

- --
Duncan Temple Lang                duncan at wald.ucdavis.edu
Department of Statistics          work:  (530) 752-4782
371 Kerr Hall                     fax:   (530) 752-7099
One Shields Ave.
University of California at Davis
Davis, CA 95616, USA
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.2 (Darwin)
Comment: Using GnuPG with Thunderbird - http://enigmail.mozdev.org

iD8DBQFDYRme9p/Jzwa2QP4RAtdWAJ9xsBXYFpNQipw6szvSfcjuplCrHwCfe0iV
avTkVUUFlolKsNKZmGtCbFw=
=/JFv
-----END PGP SIGNATURE-----



From rpeng at jhsph.edu  Thu Oct 27 20:35:04 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 27 Oct 2005 14:35:04 -0400
Subject: [R] RSQLite problems
In-Reply-To: <29k6fy7v11.fsf@bass.biostat.umn.edu>
References: <29k6fy7v11.fsf@bass.biostat.umn.edu>
Message-ID: <43611DD8.1080903@jhsph.edu>

I encountered this too, and my limited investigation (both on the web and in R) 
was unable to find a work around.

-roger

Na Li wrote:
> Hi, I'm experimenting with using (R)SQLite to do data management.  Here are
> two little problems that I've encountered:
> 
> 1. The presence of ',' in string values causes trouble since ',' is also the
>    delimiter used in the SQL statement. 
> 
> 2. A newline '\n' line attached to the last string value of each row. 
> 
> Some examples:
> 
> 
>>library (RSQLite)
> 
> Loading required package: DBI
> 
>>sqlite <- dbDriver ("SQLite")
>>db <- dbConnect (sqlite, dbname = "test.dbms")
>>data (barley)
>>dbWriteTable (db, "barley", barley, overwrite = TRUE)
> 
> [1] TRUE
> 
>>barley[1:3,]
> 
>      yield   variety year            site
> 1 27.00000 Manchuria 1931 University Farm
> 2 48.86667 Manchuria 1931          Waseca
> 3 27.43334 Manchuria 1931          Morris
> 
>>dbReadTable (db, "barley")[1:3,]
> 
>      yield   variety year__1              site
> 1 27.00000 Manchuria    1931 University Farm\n
> 2 48.86667 Manchuria    1931          Waseca\n
> 3 27.43334 Manchuria    1931          Morris\n
> 
> 
>>barley$site <- as.character (barley$site)
>>barley$site[1] <- "University, Farm"
>>dbWriteTable (db, "barley", barley, overwrite = TRUE)
> 
> Error in sqliteWriteTable(conn, name, value, ...) : 
> 	RS-DBI driver: (RS_sqlite_import: /tmp/RtmpgSNaLn/rsdbi6a5d128c line 1
> expected 5 columns of data but found 6)
> 
> I'm using RSQLite 0.4.0 with R 2.1.1 on Mac OS X.
> 
> Cheers,
> 
> Michael
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/



From rpeng at jhsph.edu  Thu Oct 27 20:36:22 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 27 Oct 2005 14:36:22 -0400
Subject: [R] encrypted RData file?
In-Reply-To: <dc3bmm7tka.fsf@bass.biostat.umn.edu>
References: <dc3bmm7tka.fsf@bass.biostat.umn.edu>
Message-ID: <43611E26.7000407@jhsph.edu>

I would be interested in that, particularly with certain kinds of confidential data.

What was the approach you had in mind (if you in fact had one in mind)?

-roger

Na Li wrote:
> Hi, I wonder if there is interest/intention to allow for encrypted .RData
> files?  One can certainly do that outside R manually but that will leave a
> decrypted RData file somewhere which one has to remember to delete.
> 
> Cheers,
> 
> Michael
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/



From walton.green at yale.edu  Thu Oct 27 21:01:12 2005
From: walton.green at yale.edu (Walton A. Green)
Date: Thu, 27 Oct 2005 15:01:12 -0400 (EDT)
Subject: [R]  Dendrogram for many cases
In-Reply-To: <mailman.9.1130407201.30164.r-help@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.44.0510271012010.28812-100000@ares.its.yale.edu>


David,

Sounds as if you're looking for cut.dendrogram().

My solution (with c. 250 cases) has been to color the terminals so 
patterns can be seen even when there are too many terminals to label. I 
don't think you can do that easily with plot.hclust() or plot.dendrogram() 
so I posted a hacked version of plot.dendrogram() to R-devel last week. 
Subsequently I was also pointed to a package that does a better job of it 
than my hacked function. It's called A2R, and is not on CRAN but can be 
downloaded from: http://addictedtor.free.fr/packages.

Walton

> Date: Wed, 26 Oct 2005 11:23:26 +0100
> From: David Lucy <dlucy at maths.ed.ac.uk>
> Subject: [R] Dendrogram for many cases
> To: r-help at stat.math.ethz.ch
> Message-ID: <435F591E.9010902 at maths.ed.ac.uk>
> Content-Type: text/plain; charset=us-ascii; format=flowed
> 
> Dear All,
> 
> I have a cluster object based on a 
> dissimilarity matrix from about 1,100 
> cases and wish to know whether anyone 
> can think  of any tips to display some 
> form of graphical output which would 
> give some sense of the similarity 
> between the cases.
> 
> A standard form of dendrogram would be 
> fine, but with so many cases the 
> dendrogram on the standard devices 
> (R-2.20 on NT4) is very compact in the 
> x-dimension. I wonder whether there is 
> any way that the dendrogram can be 
> subdivided into discrete pieces?
> 
> Failing that, is there any other means 
> of graphically representing the 
> dissimilarity matrix. I am only 
> interested in the low order 
> dissimilarity rather than high order 
> structure between these cases.
> 
> A further constraint is that the NT4 box 
> is well bolted down in that it has no 
> means by which data can be transfered 
> to, or from it.
> 
> Cheers,
> 
> David.

######################## .signature ########################
# Walton A. Green                    walton.green at yale.edu #   
# 139 Caulkinstown Road     P. O. Box 208109, Yale Station #
# Sharon, Connecticut 06069   New Haven, Connecticut 06520 #
# (860) 364-5100                            (203) 640-8122 #
#################### 60 characters wide ####################



From wsetzer at mindspring.com  Thu Oct 27 20:46:05 2005
From: wsetzer at mindspring.com (Woodrow Setzer)
Date: Thu, 27 Oct 2005 18:46:05 +0000 (UTC)
Subject: [R] Fitting of Non-Linear Diff Equations and Parameter
	Estimation
References: <a666434f0510262052n10f90ffeo1b9c1b4c7768e1ce@mail.gmail.com>
Message-ID: <loom.20051027T204351-582@post.gmane.org>

Raja Jayaraman <rajnmsu79 <at> gmail.com> writes:

> 
> Hello Everybody,
> I am running R 2.2.0 with Windows XP
> i am trying to fit nonlinear differential equation to data sets which looks
> like this:
[SNIP]
>  and i need to fit these data to the following diff equation:
> dNdt=a*N-b*N*C, dCdt=N^2,
> Where a=birth rate, b=death rate and N= Current count, C= Cumulative Count.
> i need to fit the differential equation, solve and obtain parameters a,b.
> can someone help with this,
> Thanks
> Raj

Try looking at the package odesolve for solving the ode system.

Woody Setzer
National Center for Computational Toxicology
US EPA



From duncan at wald.ucdavis.edu  Thu Oct 27 21:35:00 2005
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Thu, 27 Oct 2005 12:35:00 -0700
Subject: [R] Problems with source() function
In-Reply-To: <1130434820.14225.40.camel@trinity>
References: <1130434820.14225.40.camel@trinity>
Message-ID: <43612BE4.7060408@wald.ucdavis.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


Does
  source(textConnection(readLines(url(http://...)))

give the correct answer. If not, what is being dropped
when you just use readLines() and look at the contents
of the download.

And how long is the longest line?


The RCurl package  (http://www.omegahat.org/RCurl) gives you a lot of
control in perform and processing HTTP requests, allowing
you to control the request, and read the body and the header of the
response.  It may be worth a try if things are getting frustrating.

 D.


Al wrote:
> Hello list members!
> 
> I'm trying to enter some data in an R session using source() function
> with an URL as argument. The data source is a PHP script located in an
> apache web server and the data is a long list generated on-the-fly,
> these are the initial lines:
> 
> groups<-list()
> groups[['ENSMUST00000000001']]=c(52611,483683,147952,132170,297514,469248,291525,364037,469915,55472,280220,314688,415650,486875,440898,6781,497785) groups[['ENSMUST00000000003']]=c(416911,327120,425495,72272,297529,101933,371418,139034,318872,367204,237702) groups[['ENSMUST00000000028']]=c(199311,325400,184761,241988,376845,75052,67724,404240,439543,391057,393816) groups[['ENSMUST00000000031']]=c(402587,352900,139030,186068,463553,328881,74942,277085,301431,256149,410846) groups[['ENSMUST00000000033']]=c(12700,23908,11140,122358,389908,390084,383903,354007,457965,106395,131876) groups[['ENSMUST00000000049']]=c(59336,203239,101077,382882,327374,281549,212042,275594,361523,490934,240275) groups[['ENSMUST00000000056']]=c(409571,304584,394332,379699,13785,4260,288889,42538,304075,47734,485512,52501,328509,504846,334607,82566,250088,150240,16422,446551,314484,91878,124752,341638,379512,379890,319764,8019,59221,156508,362524,74001,149400) groups[['ENSMUST00000000058']]=c(26511,4
5!
>  5190,466368,358528,268486,315461,149260,422804,137641,163718,352555)
> 
> The problem:
> When I execute the command it apparently finish ok, without printed
> errors but when I test the consistency of the data entered using the
> command length() I always obtain different figures.
> 
> More facts:
> When I source the data from a static file instead an url, the data is
> fully entered and the length is always the same (20346 list elements).
> It delays 30 secs to load.
> 
> When I source the data from the dynamic way, from an url, it delays 2
> min. and always data is truncated.
> 
> Tried and miserably failed:
> - Changed .Options$timeout from 60 to 300
> - Using R --verbose is of no help, the data is silently truncated. 
> - Changed the expression in which data is entered:
> groups<-list(
> 'ENSMUST00000000001'=c(52611,483683,147952,132170,297514,469248,291525,364037,469915,55472,280220,314688,415650,486875,440898,6781,497785),
> 'ENSMUST00000000003'=c(416911,327120,425495,72272,297529,101933,371418,139034,318872,367204,237702)
> ...
> )
> 
> Kind list members, is there some timeout I am missing? Some way to debug
> the process? Some suggestion?
> 
> Sincerely, thank you!
> 
> Alberto de Luis
> www.cicancer.org
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

- --
Duncan Temple Lang                duncan at wald.ucdavis.edu
Department of Statistics          work:  (530) 752-4782
371 Kerr Hall                     fax:   (530) 752-7099
One Shields Ave.
University of California at Davis
Davis, CA 95616, USA
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.2 (Darwin)
Comment: Using GnuPG with Thunderbird - http://enigmail.mozdev.org

iD8DBQFDYSvk9p/Jzwa2QP4RAsqfAJ98RNScQ7ea1/MAnt72R0VGZoXaEQCfZvyl
WNNN/HT1hx/Kix3KSp15XwM=
=VsDG
-----END PGP SIGNATURE-----



From worknit at gmail.com  Thu Oct 27 22:04:05 2005
From: worknit at gmail.com (Jon Savian)
Date: Thu, 27 Oct 2005 13:04:05 -0700
Subject: [R] installing Rmpi
Message-ID: <8d9f49590510271304r4536bd49l1ee067e375f244dd@mail.gmail.com>

Hello,

I've installed R on my RHEL3 cluster and I am trying to get Rmpi to
work properly.

R is installed using the following
./configure --prefix=/home/apps/R-2.2.0

I installed snow using
R CMD INSTALL /home/apps/snow

And finaly Rmpi
R CMD INSTALL /home/apps/Rmpi --configure-args=--with-mpi=/path/to/lam

There were no errors or warnings upon installation.  However when i
perform the test below i get an error message

R> library(snow)
R> cl <- makeCluster(2)

Rmpi version: 0.4-9
        Rmpi is an interface (wrapper) to MPI APIs
        with interactive R slave functionalities.
        See `library (help=Rmpi)' for details.
Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library
'/home/apps/R-2.2.0/lib/R/library/Rmpi/libs/Rmpi.so':
  libmpi.so.0: cannot open shared object file: No such file or directory
Error in dyn.unload(x) : dynamic/shared library
'/home/apps/R-2.2.0/lib/R/library/Rmpi/libs/Rmpi.so' was not loaded
Error in makeMPIcluster(spec, ...) : the `Rmpi' package is needed for
MPI clusters.

The Rmpi.so exists and the permissions are fine.  I also did a
lamboot, and its running in the backround fine as well.  Any
suggestions?

Thanks.



From ligges at statistik.uni-dortmund.de  Thu Oct 27 22:07:15 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 27 Oct 2005 22:07:15 +0200
Subject: [R] its dates masked by chron
In-Reply-To: <x2irviyjrp.fsf@turmalin.kubism.ku.dk>
References: <3f87cc6d0510270847p7f3ad04bkc5f6b183403d0cce@mail.gmail.com>	<3f87cc6d0510270936y5f784285y3eea6928707135a4@mail.gmail.com>
	<x2irviyjrp.fsf@turmalin.kubism.ku.dk>
Message-ID: <43613373.2040100@statistik.uni-dortmund.de>

Peter Dalgaard wrote:

> Omar Lakkis <uofiowa at gmail.com> writes:
> 
> 
>>To redescribe the problem; I need to use dates from its
>>its depends on Hmisc
>>Hmisc depends chron
>>dates in chron masks dates in its
> 
> 
> So use its::dates ...

... or ask the package maintainer (which might be a hard task: the 
package currently appears to be more or less unmaintained) to fix this 
probably unintended behaviour.

Uwe Ligges



> 
>>---------- Forwarded message ----------
>>From: Omar Lakkis <uofiowa at gmail.com>
>>Date: Oct 27, 2005 11:47 AM
>>Subject: its dates masked by chron
>>To: r-help at stat.math.ethz.ch
>>
>>
>>I built R 2.2.0 from source on my debian machine yesterday and updated
>>all packages. My problem is that "dates" function from its, that my
>>code heavely uses is now masked by "dates" from chron.
>>How can I specify tehat I want to use dates from its or how can I
>>prevent it from being masked?
>>
>>
>>>library(its)
>>
>>Loading required package: Hmisc
>>Hmisc library by Frank E Harrell Jr
>>
>>Type library(help='Hmisc'), ?Overview, or ?Hmisc.Overview')
>>to see overall documentation.
>>
>>NOTE:Hmisc no longer redefines [.factor to drop unused levels when
>>subsetting.  To get the old behavior of Hmisc type dropUnusedLevels().
>>
>>Attaching package: 'Hmisc'
>>
>>
>>        The following object(s) are masked from package:stats :
>>
>>         ecdf
>>
>>
>>Attaching package: 'chron'
>>
>>
>>        The following object(s) are masked from package:its :
>>
>>         dates
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
>



From ripley at stats.ox.ac.uk  Thu Oct 27 22:26:42 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 27 Oct 2005 21:26:42 +0100 (BST)
Subject: [R] its dates masked by chron
In-Reply-To: <43613373.2040100@statistik.uni-dortmund.de>
References: <3f87cc6d0510270847p7f3ad04bkc5f6b183403d0cce@mail.gmail.com>
	<3f87cc6d0510270936y5f784285y3eea6928707135a4@mail.gmail.com>
	<x2irviyjrp.fsf@turmalin.kubism.ku.dk>
	<43613373.2040100@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.61.0510272113470.22556@gannet.stats>

On Thu, 27 Oct 2005, Uwe Ligges wrote:

> Peter Dalgaard wrote:
>
>> Omar Lakkis <uofiowa at gmail.com> writes:
>>
>>
>>> To redescribe the problem; I need to use dates from its
>>> its depends on Hmisc
>>> Hmisc depends chron
>>> dates in chron masks dates in its
>>
>>
>> So use its::dates ...
>
> ... or ask the package maintainer (which might be a hard task: the
> package currently appears to be more or less unmaintained) to fix this
> probably unintended behaviour.

If he can reproduce it: I cannot.

Hmisc does not say it depends on chron according to its DESCRIPTION file,
so I don't see where the idea comes from.  A misreading of

http://cran.r-project.org/src/contrib/Descriptions/Hmisc.html ?

Certainly Hmisc does not load chron (or anything else) on any of my 
systems. Further, dependencies are loaded *before* the package in 
question.  After

> library(its)

I get

> search()
  [1] ".GlobalEnv"        "package:its"       "package:Hmisc"
  [4] "package:methods"   "package:stats"     "package:graphics"
  ...


One way out would be to load chron, Hmisc and then its in that order,
but are these really the current its (1.0.9) and Hmisc (3.0-7)?


>>> ---------- Forwarded message ----------
>>> From: Omar Lakkis <uofiowa at gmail.com>
>>> Date: Oct 27, 2005 11:47 AM
>>> Subject: its dates masked by chron
>>> To: r-help at stat.math.ethz.ch
>>>
>>>
>>> I built R 2.2.0 from source on my debian machine yesterday and updated
>>> all packages. My problem is that "dates" function from its, that my
>>> code heavely uses is now masked by "dates" from chron.
>>> How can I specify tehat I want to use dates from its or how can I
>>> prevent it from being masked?
>>>
>>>
>>>> library(its)
>>>
>>> Loading required package: Hmisc
>>> Hmisc library by Frank E Harrell Jr
>>>
>>> Type library(help='Hmisc'), ?Overview, or ?Hmisc.Overview')
>>> to see overall documentation.
>>>
>>> NOTE:Hmisc no longer redefines [.factor to drop unused levels when
>>> subsetting.  To get the old behavior of Hmisc type dropUnusedLevels().
>>>
>>> Attaching package: 'Hmisc'
>>>
>>>
>>>        The following object(s) are masked from package:stats :
>>>
>>>         ecdf
>>>
>>>
>>> Attaching package: 'chron'
>>>
>>>
>>>        The following object(s) are masked from package:its :
>>>
>>>         dates
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>
>>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From whit at twinfieldscapital.com  Thu Oct 27 22:44:24 2005
From: whit at twinfieldscapital.com (Whit Armstrong)
Date: Thu, 27 Oct 2005 16:44:24 -0400
Subject: [R] its dates masked by chron
Message-ID: <726FC6DD09DE1046AF81B499D70C3BCE264CF6@twinfields02.CORP.TWINFIELDSCAPITAL.COM>

Uwe,

It was unclear whether you were referring to chron or its as being
unmaintained.

I still maintain its, and I'm actually releasing a new version tonight
since Kurt has pointed out that the current version is failing package
checking.

It seems that both its and chron use namespaces.  I thought the intent
of namespaces was to prevent problems like this.

If there are namespace experts out there who can suggest a fix to this
problem, I'm happy to put it into the next release.

-Whit
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Uwe Ligges
> Sent: Thursday, October 27, 2005 4:07 PM
> To: Peter Dalgaard
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] its dates masked by chron
> 
> Peter Dalgaard wrote:
> 
> > Omar Lakkis <uofiowa at gmail.com> writes:
> > 
> > 
> >>To redescribe the problem; I need to use dates from its its 
> depends on 
> >>Hmisc Hmisc depends chron dates in chron masks dates in its
> > 
> > 
> > So use its::dates ...
> 
> ... or ask the package maintainer (which might be a hard task: the 
> package currently appears to be more or less unmaintained) to 
> fix this 
> probably unintended behaviour.
> 
> Uwe Ligges
> 
> 
> 
> > 
> >>---------- Forwarded message ----------
> >>From: Omar Lakkis <uofiowa at gmail.com>
> >>Date: Oct 27, 2005 11:47 AM
> >>Subject: its dates masked by chron
> >>To: r-help at stat.math.ethz.ch
> >>
> >>
> >>I built R 2.2.0 from source on my debian machine yesterday 
> and updated
> >>all packages. My problem is that "dates" function from its, that my
> >>code heavely uses is now masked by "dates" from chron.
> >>How can I specify tehat I want to use dates from its or how can I
> >>prevent it from being masked?
> >>
> >>
> >>>library(its)
> >>
> >>Loading required package: Hmisc
> >>Hmisc library by Frank E Harrell Jr
> >>
> >>Type library(help='Hmisc'), ?Overview, or ?Hmisc.Overview')
> >>to see overall documentation.
> >>
> >>NOTE:Hmisc no longer redefines [.factor to drop unused levels when
> >>subsetting.  To get the old behavior of Hmisc type 
> dropUnusedLevels().
> >>
> >>Attaching package: 'Hmisc'
> >>
> >>
> >>        The following object(s) are masked from package:stats :
> >>
> >>         ecdf
> >>
> >>
> >>Attaching package: 'chron'
> >>
> >>
> >>        The following object(s) are masked from package:its :
> >>
> >>         dates
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >>
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From jeroschh at ohsu.edu  Thu Oct 27 22:51:50 2005
From: jeroschh at ohsu.edu (Michael Jerosch-Herold)
Date: Thu, 27 Oct 2005 13:51:50 -0700
Subject: [R] AOV with repeated measures
Message-ID: <s360db7d.001@OHSU.EDU>

You probably need specify the repeated measures by using an "Error" term in aov for repeated measures:

aov(trait ~ species + strain + Error(species/strain))

Take a look at Ripley's book.

Treat above with caution: I am no expert, but the answer is in that direction...

Michael Jerosch-Herold



I have a question on using R to analyze data with repeated measurements. I 
have 2 species with several strains (12) per species, each of which has 
been measured twice with for a given trait. No particular covariance, just 
two measures. Now I want to analyze the data with an ANOVA (aov) 
considering these repeated measures to get the MSq and SSq for the species 
and strain level. I would like to know how to write the ANOVA model in R. I 
have done the following:

aov(trait ~ species + strain/replicate)

Is it accurate?

Thanks a lot,

Christian



From tom at maladmin.com  Thu Oct 27 18:57:34 2005
From: tom at maladmin.com (tom wright)
Date: Thu, 27 Oct 2005 12:57:34 -0400
Subject: [R] tree widget question
Message-ID: <1130432254.6271.1.camel@localhost.localdomain>

I'm trying to create an app using TclTk and R
Can someone please explain how I bind a click event to the tree widget
(http://bioinf.wehi.edu.au/~wettenhall/RTclTkExamples/TreeWidget.html)
Ideally I'd like to bind to particular elements in the tree but tkbind
doesnt seem to work.

thanks
tom



From bill.shipley at usherbrooke.ca  Thu Oct 27 22:57:20 2005
From: bill.shipley at usherbrooke.ca (Bill Shipley)
Date: Thu, 27 Oct 2005 16:57:20 -0400
Subject: [R] syntax of nlme with nesting
Message-ID: <002401c5db39$064919c0$9a1ad284@BIO041>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051027/6d3fbbf5/attachment.pl

From Soren.Hojsgaard at agrsci.dk  Thu Oct 27 23:08:50 2005
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Thu, 27 Oct 2005 23:08:50 +0200
Subject: [R] memory problem in handling large dataset
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED532@usctmx1106.merck.com>
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC03878061@DJFPOST01.djf.agrsci.dk>

An alternative could be to store data in a MySql database and then select a sample of the cases using the RODBC package.
Best
S??ren

________________________________

Fra: r-help-bounces at stat.math.ethz.ch p?? vegne af Liaw, Andy
Sendt: to 27-10-2005 19:21
Til: 'Berton Gunter'; 'Weiwei Shi'; 'r-help'
Emne: Re: [R] memory problem in handling large dataset



If my calculation is correct (very doubtful, sometimes), that's

> 1.7e9 * (300 * 8 + 50 * 4) / 1024^3
[1] 4116.446

or over 4 terabytes, just to store the data in memory.

To sample rows and read that into R, Bert's suggestion of using connections,
perhaps along with seek() for skipping ahead, would be what I'd try.  I had
try to do such things in Python as a chance to learn that language, but I
found operationally it's easier to maintain the project by doing everything
in one language, namely R, if possible.

Andy


> From: Berton Gunter
>
> I think the general advice is that around 1/4 or 1/3 of your available
> memory is about the largest data set that R can handle -- and often
> considerably less depending upon what you do and how you do
> it (because R's
> semantics require explicitly copying objects rather than
> passing pointers).
> Fancy tricks using environments might enable you to do
> better, but that
> requires advice from a true guru, which I ain't.
>
> See ?connections, ?scan, ?seek  for reading in a file a chunk
> at a time from
> a connection, thus enabling you to sample one line of data
> from each chunk,
> say.
>
> I suppose you could do this directly with repeated calls to scan() or
> read.table() by skipping more and more lines at the beginning
> at each call,
> but I assume that is horridly inefficient and would take forever.
>
> HTH.
>
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
> 
> "The business of the statistician is to catalyze the
> scientific learning
> process."  - George E. P. Box
> 
> 
>
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Weiwei Shi
> > Sent: Thursday, October 27, 2005 9:28 AM
> > To: r-help
> > Subject: [R] memory problem in handling large dataset
> >
> > Dear Listers:
> > I have a question on handling large dataset. I searched
> R-Search and I
> > hope I can get more information as to my specific case.
> >
> > First, my dataset has 1.7 billion observations and 350 variables,
> > among which, 300 are float and 50 are integers.
> > My system has 8 G memory, 64bit CPU, linux box. (currently, we don't
> > plan to buy more memory).
> >
> > > R.version
> >          _
> > platform i686-redhat-linux-gnu
> > arch     i686
> > os       linux-gnu
> > system   i686, linux-gnu
> > status
> > major    2
> > minor    1.1
> > year     2005
> > month    06
> > day      20
> > language R
> >
> >
> > If I want to do some analysis for example like randomForest on a
> > dataset, how many max observations can I load to get the machine run
> > smoothly?
> >
> > After figuring out that number, I want to do some sampling
> first, but
> > I did not find read.table or scan can do this. I guess I can load it
> > into mysql and then use RMySQL do the sampling or use
> python to subset
> > the data first. My question is, is there a way I can subsample
> > directly from file just using R?
> >
> > Thanks,
> > --
> > Weiwei Shi, Ph.D
> >
> > "Did you always know?"
> > "No, I did not. But I believed..."
> > ---Matrix III
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From nali at umn.edu  Thu Oct 27 23:15:08 2005
From: nali at umn.edu (Na Li)
Date: Thu, 27 Oct 2005 16:15:08 -0500
Subject: [R] encrypted RData file?
References: <dc3bmm7tka.fsf@bass.biostat.umn.edu>
	<4361199E.8060402@wald.ucdavis.edu>
Message-ID: <tl7jbyoe5f.fsf@bass.biostat.umn.edu>

On 27 Oct 2005, Duncan Temple Lang wrote:

> Yes, it is of interest and was sitting on my todo list at
> some time.  If you want to go ahead and provide code to do it,
> that would be terrific.  There are other areas where encryption
> would be good to have, so a general mechanism would be nice.
> 
> D.
> 
> Na Li wrote:
> > Hi, I wonder if there is interest/intention to allow for encrypted .RData
> > files?  One can certainly do that outside R manually but that will leave a
> > decrypted RData file somewhere which one has to remember to delete.
> > 

I was hoping someone has already done it.  ;-(

One possibility is to implement an interface package to gpgme library which
itself is an interface to GnuPG.  

But I'm not sure how the input of passphrase can be handled without using
clear text.

Michael



From worknit at gmail.com  Thu Oct 27 23:17:56 2005
From: worknit at gmail.com (Jon Savian)
Date: Thu, 27 Oct 2005 14:17:56 -0700
Subject: [R] installing Rmpi
In-Reply-To: <8d9f49590510271304r4536bd49l1ee067e375f244dd@mail.gmail.com>
References: <8d9f49590510271304r4536bd49l1ee067e375f244dd@mail.gmail.com>
Message-ID: <8d9f49590510271417g7c676e04ya597903f1f4d4104@mail.gmail.com>

not sure if this message sent the first time, sorry :)

---------- Forwarded message ----------
From: Jon Savian <worknit at gmail.com>
Date: Oct 27, 2005 1:04 PM
Subject: installing Rmpi
To: r-help at stat.math.ethz.ch


Hello,

I've installed R on my RHEL3 cluster and I am trying to get Rmpi to
work properly.

R is installed using the following
./configure --prefix=/home/apps/R-2.2.0

I installed snow using
R CMD INSTALL /home/apps/snow

And finaly Rmpi
R CMD INSTALL /home/apps/Rmpi --configure-args=--with-mpi=/path/to/lam

There were no errors or warnings upon installation.  However when i
perform the test below i get an error message

R> library(snow)
R> cl <- makeCluster(2)

Rmpi version: 0.4-9
        Rmpi is an interface (wrapper) to MPI APIs
        with interactive R slave functionalities.
        See `library (help=Rmpi)' for details.
Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library
'/home/apps/R-2.2.0/lib/R/library/Rmpi/libs/Rmpi.so':
  libmpi.so.0: cannot open shared object file: No such file or directory
Error in dyn.unload(x) : dynamic/shared library
'/home/apps/R-2.2.0/lib/R/library/Rmpi/libs/Rmpi.so' was not loaded
Error in makeMPIcluster(spec, ...) : the `Rmpi' package is needed for
MPI clusters.

The Rmpi.so exists and the permissions are fine.  I also did a
lamboot, and its running in the backround fine as well.  Any
suggestions?

Thanks.



From tlumley at u.washington.edu  Thu Oct 27 23:39:21 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 27 Oct 2005 14:39:21 -0700 (PDT)
Subject: [R] outer-question
In-Reply-To: <8B08A3A1EA7AAC41BE24C750338754E69FDF12@HERMES.demogr.mpg.de>
References: <8B08A3A1EA7AAC41BE24C750338754E69FDF12@HERMES.demogr.mpg.de>
Message-ID: <Pine.LNX.4.63a.0510271439070.23084@homer21.u.washington.edu>


You want FAQ 7.17 Why does outer() behave strangely with my function?

 	-thomas

On Thu, 27 Oct 2005, Rau, Roland wrote:

> Dear all,
>
> This is a rather lengthy message, but I don't know what I made wrong in
> my real example since the simple code works.
> I have two variables a, b and a function f for which I would like to
> calculate all possible combinations of the values of a and b.
> If f is multiplication, I would simply do:
>
> a <- 1:5
> b <- 1:5
> outer(a,b)
>
> ## A bit more complicated is this:
> f <- function(a,b,d) {
> 	return(a*b+(sum(d)))
> }
> additional <- runif(100)
> outer(X=a, Y=b, FUN=f, d=additional)
>
> ## So far so good. But now my real example. I would like to plot the
> ## log-likelihood surface for two parameters alpha and beta of
> ## a Gompertz distribution with given data
>
> ### I have a function to generate random-numbers from a
> Gompertz-Distribution
> ### (using the 'inversion method')
>
> random.gomp <- function(n, alpha, beta) {
>            return( (log(1-(beta/alpha*log(1-runif(n)))))/beta)
> }
>
> ## Now I generate some 'lifetimes'
> no.people <- 1000
> al <- 0.1
> bet <- 0.1
> lifetimes <- random.gomp(n=no.people, alpha=al, beta=bet)
>
> ### Since I neither have censoring nor truncation in this simple case,
> ### the log-likelihood should be simply the sum of the log of the
> ### the densities (following the parametrization of Klein/Moeschberger
> ### Survival Analysis, p. 38)
>
> loggomp <- function(alphas, betas, timep) {
>  return(sum(log(alphas) + betas*timep + (alphas/betas *
> (1-exp(betas*timep)))))
> }
>
> ### Now I thought I could obtain a matrix of the log-likelihood surface
> ### by specifying possible values for alpha and beta with the given
> data.
> ### I was able to produce this matrix with two for-loops. But I thought
> ### I could use also 'outer' in this case.
> ### This is what I tried:
>
> possible.alphas <- seq(from=0.05, to=0.15, length=30)
> possible.betas <- seq(from=0.05, to=0.15, length=30)
>
> outer(X=possible.alphas, Y=possible.betas, FUN=loggomp, timep=lifetimes)
>
> ### But the result is:
>> outer(X=possible.alphas, Y=possible.betas, FUN=loggomp,
> timep=lifetimes)
> Error in outer(X = possible.alphas, Y = possible.betas, FUN = loggomp,
> :
>        dim<- : dims [product 900] do not match the length of object [1]
> In addition: Warning messages:
> ...
>
> ### Can somebody give me some hint where the problem is?
> ### I checked my definition of 'loggomp' but I thought this looks fine:
> loggomp(alphas=possible.alphas[1], betas=possible.betas[1],
> timep=lifetimes)
> loggomp(alphas=possible.alphas[4], betas=possible.betas[10],
> timep=lifetimes)
> loggomp(alphas=possible.alphas[3], betas=possible.betas[11],
> timep=lifetimes)
>
>
> ### I'd appreciate any kind of advice.
> ### Thanks a lot in advance.
> ### Roland
>
>
> +++++
> This mail has been sent through the MPI for Demographic Rese...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From p.dalgaard at biostat.ku.dk  Thu Oct 27 23:47:09 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 27 Oct 2005 23:47:09 +0200
Subject: [R] tree widget question
In-Reply-To: <1130432254.6271.1.camel@localhost.localdomain>
References: <1130432254.6271.1.camel@localhost.localdomain>
Message-ID: <x2d5lqy6n6.fsf@turmalin.kubism.ku.dk>

tom wright <tom at maladmin.com> writes:

> I'm trying to create an app using TclTk and R
> Can someone please explain how I bind a click event to the tree widget
> (http://bioinf.wehi.edu.au/~wettenhall/RTclTkExamples/TreeWidget.html)
> Ideally I'd like to bind to particular elements in the tree but tkbind
> doesnt seem to work.

You need to study the docs for the Tree widget in the BWidget package,
e.g. via http://tcllib.sourceforge.net/BWman/Tree.html. 

I think that you can do something like

tcl(mytree, "bindText", "<Button-1>",
                         function(node)print(node)) 

(As multiple hints in the wording should tell you, this is completely
untested) 
-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From mikem at salter-point.com  Thu Oct 27 23:49:31 2005
From: mikem at salter-point.com (Mike Meyer)
Date: Thu, 27 Oct 2005 14:49:31 -0700
Subject: [R] How to manipulate an abitrary dimensioned array.
Message-ID: <43614B6B.4090500@salter-point.com>

If I have an n1 x n1 x 2 array X I can calculate, say,
X[,,1]/X[,,2].

If it is a 4 dimensional array then I want to be able to calculate
X[,,,1]/X[,,,2], and similarly for higher dimensions.

How can I write a function to do this in a general way without having to 
do a switch for each possible length(dim(X)).  So I want a function g 
that will take an arbitrary dimensioned array, X, and return 
X[,,,1]/X[,,,2], etc.   I know how to do this by turning X into a 
vector, then doing the division, then re-shaping as an array, but that 
doesn't seem very elegant.

What I think I am missing is how to paste/substitute/eval a bunch of 
commas into an array selection.

Thanks, --Mike

--
Mike Meyer,  Seattle WA



From mschwartz at mn.rr.com  Thu Oct 27 23:55:48 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Thu, 27 Oct 2005 16:55:48 -0500
Subject: [R] encrypted RData file?
In-Reply-To: <tl7jbyoe5f.fsf@bass.biostat.umn.edu>
References: <dc3bmm7tka.fsf@bass.biostat.umn.edu>
	<4361199E.8060402@wald.ucdavis.edu>
	<tl7jbyoe5f.fsf@bass.biostat.umn.edu>
Message-ID: <1130450148.4252.67.camel@localhost.localdomain>

On Thu, 2005-10-27 at 16:15 -0500, Na Li wrote:
> On 27 Oct 2005, Duncan Temple Lang wrote:
> 
> > Yes, it is of interest and was sitting on my todo list at
> > some time.  If you want to go ahead and provide code to do it,
> > that would be terrific.  There are other areas where encryption
> > would be good to have, so a general mechanism would be nice.
> > 
> > D.
> > 
> > Na Li wrote:
> > > Hi, I wonder if there is interest/intention to allow for encrypted .RData
> > > files?  One can certainly do that outside R manually but that will leave a
> > > decrypted RData file somewhere which one has to remember to delete.
> > > 
> 
> I was hoping someone has already done it.  ;-(
> 
> One possibility is to implement an interface package to gpgme library which
> itself is an interface to GnuPG.  
> 
> But I'm not sure how the input of passphrase can be handled without using
> clear text.
> 
> Michael

Seems to me that a better option would be to encrypt the full partition
such that (unless you write the files to a non-encrypted partition)
these issues are transparent. This would include the use of save(),
save.image() and write() type functions to save what was an encrypted
dataset/object to a unencrypted file.

Of course, you would also have to encrypt the swap and tmp partitions
(as appropriate) for similar reasons.

On Linuxen/Unixen, full encryption of partitions is available via
loopback devices and other mechanisms and some distros have this
available as a built-in option. I believe that the FC folks finally have
this on their list of functional additions for FC5. Windows of course
can do something similar.

The other consideration here, is that if R Core builds in some form of
encryption, there is the potential for import/export restrictions on
such technology since R is available via international CRAN mirrors. It
may be best to provide for a plug-in "encryption black box" of sorts, so
that folks can use a particular encryption schema that meets various
legal/regulatory requirements.

Of course, simply encrypting the file or even a complete partition has
to be considered within a larger security strategy (ie. network
security, physical access control, etc.) that meets a particular
functional requirement (such as HIPAA here in the U.S.)

HTH,

Marc Schwartz



From nali at umn.edu  Fri Oct 28 00:21:37 2005
From: nali at umn.edu (Na Li)
Date: Thu, 27 Oct 2005 17:21:37 -0500
Subject: [R] encrypted RData file?
In-Reply-To: <1130450148.4252.67.camel@localhost.localdomain> (Marc Schwartz's
	message of "Thu, 27 Oct 2005 16:55:48 -0500")
References: <dc3bmm7tka.fsf@bass.biostat.umn.edu>
	<4361199E.8060402@wald.ucdavis.edu>
	<tl7jbyoe5f.fsf@bass.biostat.umn.edu>
	<1130450148.4252.67.camel@localhost.localdomain>
Message-ID: <b13bmmob2m.fsf@bass.biostat.umn.edu>

On 27 Oct 2005, Marc Schwartz uttered the following:

> Seems to me that a better option would be to encrypt the full partition
> such that (unless you write the files to a non-encrypted partition)
> these issues are transparent. 

I actually do that on a Mac via an encrypted sparse disk image.  But I may
occasionally need transfer some files to other people or put it on a machine
without such support.  Also the encryption options are quite limited.

Michael



From gunter.berton at gene.com  Fri Oct 28 00:24:26 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Thu, 27 Oct 2005 15:24:26 -0700
Subject: [R] How to manipulate an abitrary dimensioned array.
In-Reply-To: <43614B6B.4090500@salter-point.com>
Message-ID: <200510272224.j9RMOQ5I019309@hertz.gene.com>

Why doesn't apply() already do what you want?

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Mike Meyer
> Sent: Thursday, October 27, 2005 2:50 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] How to manipulate an abitrary dimensioned array.
> 
> If I have an n1 x n1 x 2 array X I can calculate, say,
> X[,,1]/X[,,2].
> 
> If it is a 4 dimensional array then I want to be able to calculate
> X[,,,1]/X[,,,2], and similarly for higher dimensions.
> 
> How can I write a function to do this in a general way 
> without having to 
> do a switch for each possible length(dim(X)).  So I want a function g 
> that will take an arbitrary dimensioned array, X, and return 
> X[,,,1]/X[,,,2], etc.   I know how to do this by turning X into a 
> vector, then doing the division, then re-shaping as an array, 
> but that 
> doesn't seem very elegant.
> 
> What I think I am missing is how to paste/substitute/eval a bunch of 
> commas into an array selection.
> 
> Thanks, --Mike
> 
> --
> Mike Meyer,  Seattle WA
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From mikem at salter-point.com  Fri Oct 28 00:43:05 2005
From: mikem at salter-point.com (Mike Meyer)
Date: Thu, 27 Oct 2005 15:43:05 -0700
Subject: [R] How to manipulate an abitrary dimensioned array.
In-Reply-To: <200510272224.j9RMOQ5I019309@hertz.gene.com>
References: <200510272224.j9RMOQ5I019309@hertz.gene.com>
Message-ID: <436157F9.9070509@salter-point.com>

Thanks for the suggestion.
Perhaps I can see how to use apply to get the ratio, but say I also want 
to return X[,,,,1] in a general way.  Maybe I am being dense but I just 
don't see it --- probably as a result of too much Perl/Python/Java 
recently that is clouding my mind.

So can someone suggest a general function that will give me the last 
layer of an arbitrary dimensioned array?

Berton Gunter wrote:
> Why doesn't apply() already do what you want?
> 
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
>  
> "The business of the statistician is to catalyze the scientific learning
> process."  - George E. P. Box
>  
>  
> 
> 
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch 
>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Mike Meyer
>>Sent: Thursday, October 27, 2005 2:50 PM
>>To: r-help at stat.math.ethz.ch
>>Subject: [R] How to manipulate an abitrary dimensioned array.
>>
>>If I have an n1 x n1 x 2 array X I can calculate, say,
>>X[,,1]/X[,,2].
>>
>>If it is a 4 dimensional array then I want to be able to calculate
>>X[,,,1]/X[,,,2], and similarly for higher dimensions.
>>
>>How can I write a function to do this in a general way 
>>without having to 
>>do a switch for each possible length(dim(X)).  So I want a function g 
>>that will take an arbitrary dimensioned array, X, and return 
>>X[,,,1]/X[,,,2], etc.   I know how to do this by turning X into a 
>>vector, then doing the division, then re-shaping as an array, 
>>but that 
>>doesn't seem very elegant.
>>
>>What I think I am missing is how to paste/substitute/eval a bunch of 
>>commas into an array selection.
>>
>>Thanks, --Mike
>>
>>--
>>Mike Meyer,  Seattle WA
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 

Mike Meyer,  Seattle WA



From duncan at wald.ucdavis.edu  Fri Oct 28 00:09:56 2005
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Thu, 27 Oct 2005 15:09:56 -0700
Subject: [R] encrypted RData file?
In-Reply-To: <tl7jbyoe5f.fsf@bass.biostat.umn.edu>
References: <dc3bmm7tka.fsf@bass.biostat.umn.edu>	<4361199E.8060402@wald.ucdavis.edu>
	<tl7jbyoe5f.fsf@bass.biostat.umn.edu>
Message-ID: <43615034.30507@wald.ucdavis.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1



Na Li wrote:
> On 27 Oct 2005, Duncan Temple Lang wrote:
> 
> 
>>Yes, it is of interest and was sitting on my todo list at
>>some time.  If you want to go ahead and provide code to do it,
>>that would be terrific.  There are other areas where encryption
>>would be good to have, so a general mechanism would be nice.
>>
>>D.
>>
>>Na Li wrote:
>>
>>>Hi, I wonder if there is interest/intention to allow for encrypted .RData
>>>files?  One can certainly do that outside R manually but that will leave a
>>>decrypted RData file somewhere which one has to remember to delete.
>>>
> 
> 
> I was hoping someone has already done it.  ;-(

Me too.

> 
> One possibility is to implement an interface package to gpgme library which
> itself is an interface to GnuPG.  
> 
> But I'm not sure how the input of passphrase can be handled without using
> clear text.
> 


For the Unix-like operating systems, a simple thing that we can use is
to call gpg as a system program. When we save a file, we can put it in
R's temporary directory which is readable only by the owner of the R
process. Then we call gpg to encrypt it and put the resulting file in
the appropriate directory.
Similarly, when loading, we can decrypt into this "secure" area, load
the file in the usual way and throw away the decrypted version.

This is definitely the poor man's version and one that I don't like
as it uses the file system.  But it will get us around the import/export
  restrictions that Luke Tierney immediately raise with no problems.  It
is also the mechanism the gpg package in emacs uses (except they just
use the current directory, regardless of whether it is readable by
anyone else).  And I have just written a very simple prototype that does
this for R.


Interfacing to a library is the way to go, and I might get to that
soon, but it requires that we do it in a way that does not put any
encryption code into the R source.  I  can see 2 options off hand, but
some more thought is necessary.

And if anyone wants to volunteer to write this, that would be much
better than me doing it for a variety of different reasons.

> Michael
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

- --
Duncan Temple Lang                duncan at wald.ucdavis.edu
Department of Statistics          work:  (530) 752-4782
371 Kerr Hall                     fax:   (530) 752-7099
One Shields Ave.
University of California at Davis
Davis, CA 95616, USA
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.2 (Darwin)
Comment: Using GnuPG with Thunderbird - http://enigmail.mozdev.org

iD8DBQFDYVA09p/Jzwa2QP4RAoYHAJ4i4Nnd/XtNx2O+zrjxF1nxwYJ4egCfQV4Q
p1CaXFo1fiThNax7Afg9uco=
=j3Hw
-----END PGP SIGNATURE-----



From srini_iyyer_bio at yahoo.com  Fri Oct 28 01:08:48 2005
From: srini_iyyer_bio at yahoo.com (Srinivas Iyyer)
Date: Thu, 27 Oct 2005 16:08:48 -0700 (PDT)
Subject: [R] How to make labels on my dendrogam look more clear and visible
In-Reply-To: <436157F9.9070509@salter-point.com>
Message-ID: <20051027230848.82703.qmail@web31609.mail.mud.yahoo.com>

Dear group, 
 I have a matrix with readings for ~180 variables
observed in 240 conditions. 

I am doing a hierarchical clustering method (hclust)
by calculating eucledian distances among them. 

When I plot the dendrogram from hclust, all my
variables at the end of the branches are cluttered. I
cannot read them properly. 

I tried using :
> x11(width = 100, height = 70, pointsize = 10)
>plot(mydat.hcluster)


and also by

>x11(width = 1000, height = 300, pointsize = 10)
>plot(mydat.hcluster)

I could not make the dendrogram branches go wide and
make variables at the end of braches more legible. 


Can any one please help me to make a good diagram so
that I can see the lables at the end of branches more
clearly. 

Thank you. 

cheers
Sri



From gunter.berton at gene.com  Fri Oct 28 01:11:55 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Thu, 27 Oct 2005 16:11:55 -0700
Subject: [R] How to manipulate an abitrary dimensioned array.
In-Reply-To: <436157F9.9070509@salter-point.com>
Message-ID: <200510272311.j9RNBtRM027322@compton.gene.com>

Not sure what you're after, but the kth dimension of an array y can be
obtained as:
apply(y,k,c). Each column of the resulting matrix can then be dimensioned,
if you like, via dim(y)[-k] .

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: Mike Meyer [mailto:mikem at salter-point.com] 
> Sent: Thursday, October 27, 2005 3:43 PM
> To: Berton Gunter
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] How to manipulate an abitrary dimensioned array.
> 
> Thanks for the suggestion.
> Perhaps I can see how to use apply to get the ratio, but say 
> I also want 
> to return X[,,,,1] in a general way.  Maybe I am being dense 
> but I just 
> don't see it --- probably as a result of too much Perl/Python/Java 
> recently that is clouding my mind.
> 
> So can someone suggest a general function that will give me the last 
> layer of an arbitrary dimensioned array?
> 
> Berton Gunter wrote:
> > Why doesn't apply() already do what you want?
> > 
> > -- Bert Gunter
> > Genentech Non-Clinical Statistics
> > South San Francisco, CA
> >  
> > "The business of the statistician is to catalyze the 
> scientific learning
> > process."  - George E. P. Box
> >  
> >  
> > 
> > 
> >>-----Original Message-----
> >>From: r-help-bounces at stat.math.ethz.ch 
> >>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Mike Meyer
> >>Sent: Thursday, October 27, 2005 2:50 PM
> >>To: r-help at stat.math.ethz.ch
> >>Subject: [R] How to manipulate an abitrary dimensioned array.
> >>
> >>If I have an n1 x n1 x 2 array X I can calculate, say,
> >>X[,,1]/X[,,2].
> >>
> >>If it is a 4 dimensional array then I want to be able to calculate
> >>X[,,,1]/X[,,,2], and similarly for higher dimensions.
> >>
> >>How can I write a function to do this in a general way 
> >>without having to 
> >>do a switch for each possible length(dim(X)).  So I want a 
> function g 
> >>that will take an arbitrary dimensioned array, X, and return 
> >>X[,,,1]/X[,,,2], etc.   I know how to do this by turning X into a 
> >>vector, then doing the division, then re-shaping as an array, 
> >>but that 
> >>doesn't seem very elegant.
> >>
> >>What I think I am missing is how to paste/substitute/eval a 
> bunch of 
> >>commas into an array selection.
> >>
> >>Thanks, --Mike
> >>
> >>--
> >>Mike Meyer,  Seattle WA
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide! 
> >>http://www.R-project.org/posting-guide.html
> >>
> > 
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> -- 
> 
> Mike Meyer,  Seattle WA
> 
> 
>



From butchar.2 at osu.edu  Fri Oct 28 02:02:18 2005
From: butchar.2 at osu.edu (jon butchar)
Date: Thu, 27 Oct 2005 20:02:18 -0400
Subject: [R] How to make labels on my dendrogam look more clear and
 visible
In-Reply-To: <20051027230848.82703.qmail@web31609.mail.mud.yahoo.com>
References: <436157F9.9070509@salter-point.com>
	<20051027230848.82703.qmail@web31609.mail.mud.yahoo.com>
Message-ID: <20051027200218.70736885.butchar.2@osu.edu>

On Thu, 27 Oct 2005 16:08:48 -0700 (PDT)
Srinivas Iyyer <srini_iyyer_bio at yahoo.com> wrote:

> Dear group, 
>  I have a matrix with readings for ~180 variables
> observed in 240 conditions. 
> 
> I am doing a hierarchical clustering method (hclust)
> by calculating eucledian distances among them. 
> 
> When I plot the dendrogram from hclust, all my
> variables at the end of the branches are cluttered. I
> cannot read them properly. 
> 
> I tried using :
> > x11(width = 100, height = 70, pointsize = 10)
> >plot(mydat.hcluster)
> 
> 
> and also by
> 
> >x11(width = 1000, height = 300, pointsize = 10)
> >plot(mydat.hcluster)
> 
> I could not make the dendrogram branches go wide and
> make variables at the end of braches more legible. 
> 
> 
> Can any one please help me to make a good diagram so
> that I can see the lables at the end of branches more
> clearly. 
> 
> Thank you. 
> 
> cheers
> Sri
> 


I don't know if it'll help, but I've grown fond of postscript graphs.

For example...

> postscript("mydendogram.ps", height=800, width=2000, pointsize=[????])
> plot(mydendogram)
> dev.off()

gives me very clear print, and then the ps2pdf app can turn it into a pdf for e-mailing or import to a presentation.

jon b



From lee_poet at hotmail.com  Fri Oct 28 02:35:40 2005
From: lee_poet at hotmail.com (jinlong li)
Date: Fri, 28 Oct 2005 08:35:40 +0800
Subject: [R] how to predict with logistic model in package logistf ?
In-Reply-To: <20051027151949.31784.qmail@web32110.mail.mud.yahoo.com>
Message-ID: <BAY104-F76F4791A1D29491221246F26B0@phx.gbl>

fit$predict does print the fitted value for training data frame,

but what I want  is to apply the fitted model to new coming data.

maybe I can form the equation manually .

thank you!

jinlong


>From: Elizabeth Lawson <lizzylaws at yahoo.com>
>To: jinlong li <lee_poet at hotmail.com>
>CC: r-help at lists.R-project.org
>Subject: Re: [R] how to predict with logistic model  in package logistf ?
>Date: Thu, 27 Oct 2005 08:19:49 -0700 (PDT)
>
>Did you try fit$predict?
>
>Elizabeth Lawson
>
>jinlong li <lee_poet at hotmail.com> wrote:
>dear community,
>I am a beginer in R , and can't predict with logistic model in package
>logistf,
>could anyone help me ? thanks !
>
>the following is my command and result :
>
> >library(logistf)
> >data(sex2)
> >fit<-logistf(case ~ age+oc+vic+vicl+vis+dia, data=sex2)
> >predict(fit,newdata=sex2)
>Error in predict(fit, newdata = sex2) : no applicable method for
>"predict"
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html
>
>
>---------------------------------
>  Yahoo! FareChase - Search multiple travel sites in one click.



From kerryrekky at yahoo.com  Fri Oct 28 03:47:28 2005
From: kerryrekky at yahoo.com (Cunningham Kerry)
Date: Thu, 27 Oct 2005 18:47:28 -0700 (PDT)
Subject: [R] question about sm.density
Message-ID: <20051028014728.20086.qmail@web51815.mail.yahoo.com>

How can I draw a 95% contour in sm.density?

For example, 

y <- cbind(rnorm(50), rnorm(50))
     sm.density(y, display = "slice")

will give 25%, 50% and 75% contours automatically, but
no reference on other values.



From han at cs.wisc.edu  Fri Oct 28 04:05:18 2005
From: han at cs.wisc.edu (han@cs.wisc.edu)
Date: Thu, 27 Oct 2005 21:05:18 -0500 (CDT)
Subject: [R] MCMC in R
Message-ID: <1430.146.151.119.0.1130465118.squirrel@webmail.cs.wisc.edu>

Dear R-helpers,

Hi! All.
I'm doing a project which needs MCMC simulation.
I wonder whether there exists related packages in R.
The only one I know is a MCMCpack package.
What I want to do is implementing gibbs sampling and
Metropolis-Hastings Algorithm to get the posterior
of hierarchical bayesian models.
Thanks in advance.

Jun



From dj at research.bell-labs.com  Fri Oct 28 04:12:59 2005
From: dj at research.bell-labs.com (David James)
Date: Thu, 27 Oct 2005 22:12:59 -0400
Subject: [R] RSQLite problems
In-Reply-To: <29k6fy7v11.fsf@bass.biostat.umn.edu>
References: <29k6fy7v11.fsf@bass.biostat.umn.edu>
Message-ID: <20051028021259.GB24496@jessie.research.bell-labs.com>

Hi,

Thanks for reporting the two problems. I'm attaching a simple update
to two functions that will allow you to specify a different separator, 
e.g., using your example:

   dbWriteTable(con, "barley", barley, overwrite = TRUE, sep = ";")

This workaround still relies in dumping the data.frame into a temporary
file and then importing into SQLite, but using prepared statements (which
SQLite 3 supports) will require some more work.

I'll look into the problem with the trailing newline soon.

--
David

Na Li wrote:
> 
> Hi, I'm experimenting with using (R)SQLite to do data management.  Here are
> two little problems that I've encountered:
> 
> 1. The presence of ',' in string values causes trouble since ',' is also the
>    delimiter used in the SQL statement. 
> 
> 2. A newline '\n' line attached to the last string value of each row. 
> 
> Some examples:
> 
> > library (RSQLite)
> Loading required package: DBI
> > sqlite <- dbDriver ("SQLite")
> > db <- dbConnect (sqlite, dbname = "test.dbms")
> > data (barley)
> > dbWriteTable (db, "barley", barley, overwrite = TRUE)
> [1] TRUE
> > barley[1:3,]
>      yield   variety year            site
> 1 27.00000 Manchuria 1931 University Farm
> 2 48.86667 Manchuria 1931          Waseca
> 3 27.43334 Manchuria 1931          Morris
> > dbReadTable (db, "barley")[1:3,]
>      yield   variety year__1              site
> 1 27.00000 Manchuria    1931 University Farm\n
> 2 48.86667 Manchuria    1931          Waseca\n
> 3 27.43334 Manchuria    1931          Morris\n
> 
> > barley$site <- as.character (barley$site)
> > barley$site[1] <- "University, Farm"
> > dbWriteTable (db, "barley", barley, overwrite = TRUE)
> Error in sqliteWriteTable(conn, name, value, ...) : 
> 	RS-DBI driver: (RS_sqlite_import: /tmp/RtmpgSNaLn/rsdbi6a5d128c line 1
> expected 5 columns of data but found 6)
> 
> I'm using RSQLite 0.4.0 with R 2.1.1 on Mac OS X.
> 
> Cheers,
> 
> Michael
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-------------- next part --------------
"safe.write" <-
function (value, file, batch, ..., sep=",", eol="\n", quote.string = FALSE) 
{
    N <- nrow(value)
    if (N < 1) {
        warning("no rows in data.frame")
        return(NULL)
    }
    if (missing(batch) || is.null(batch)) 
        batch <- 10000
    else if (batch <= 0) 
        batch <- N
    from <- 1
    to <- min(batch, N)
    while (from <= N) {
        if (usingR()) 
            write.table(value[from:to, , drop = FALSE], file = file, 
                append = TRUE, quote = quote.string, sep = sep, 
                na = .SQLite.NA.string, row.names = FALSE, col.names = FALSE, 
                eol = eol, ...)
        else write.table(value[from:to, , drop = FALSE], file = file, 
            append = TRUE, quote.string = quote.string, sep = ",", 
            na = .SQLite.NA.string, dimnames.write = FALSE, end.of.row = "\n", 
            ...)
        from <- to + 1
        to <- min(to + batch, N)
    }
    invisible(NULL)
}

"sqliteWriteTable" <-
function (con, name, value, field.types, row.names = TRUE, overwrite = FALSE, 
    append = FALSE, ..., sep = ",") 
{
    if (overwrite && append) 
        stop("overwrite and append cannot both be TRUE")
    if (!is.data.frame(value)) 
        value <- as.data.frame(value)
    if (row.names) {
        value <- cbind(row.names(value), value)
        names(value)[1] <- "row.names"
    }
    if (missing(field.types) || is.null(field.types)) {
        field.types <- sapply(value, dbDataType, dbObj = con)
    }
    i <- match("row.names", names(field.types), nomatch = 0)
    if (i > 0) 
        field.types[i] <- dbDataType(con, field.types$row.names)
    names(field.types) <- make.db.names(con, names(field.types), 
        allow.keywords = F)
    if (length(dbListResults(con)) != 0) {
        new.con <- dbConnect(con)
        on.exit(dbDisconnect(new.con))
    }
    else {
        new.con <- con
    }
    if (dbExistsTable(con, name)) {
        if (overwrite) {
            if (!dbRemoveTable(con, name)) {
                warning(paste("table", name, "couldn't be overwritten"))
                return(FALSE)
            }
        }
        else if (!append) {
            warning(paste("table", name, "exists in database: aborting dbWriteTable"))
            return(FALSE)
        }
    }
    if (!dbExistsTable(con, name)) {
        sql1 <- paste("create table ", name, "\n(\n\t", sep = "")
        sql2 <- paste(paste(names(field.types), field.types), 
            collapse = ",\n\t", sep = "")
        sql3 <- "\n)\n"
        sql <- paste(sql1, sql2, sql3, sep = "")
        rs <- try(dbSendQuery(new.con, sql))
        if (inherits(rs, ErrorClass)) {
            warning("could not create table: aborting assignTable")
            return(FALSE)
        }
        else dbClearResult(rs)
    }
    fn <- tempfile("rsdbi")
    safe.write(value, file = fn, ..., sep=sep)
    on.exit(unlink(fn), add = TRUE)
    if (FALSE) {
        sql4 <- paste("COPY '", name, "' FROM '", fn, "' USING DELIMITERS ','", 
            sep = "")
        rs <- try(dbSendQuery(new.con, sql4))
        if (inherits(rs, ErrorClass)) {
            warning("could not load data into table")
            return(FALSE)
        }
        else dbClearResult(rs)
        TRUE
    }
    conId <- as(new.con, "integer")
    sep <- as.character(sep[1])
    .Call("RS_SQLite_importFile", conId, name, fn, sep, PACKAGE = "RSQLite")
}


From edd at debian.org  Fri Oct 28 04:58:00 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 27 Oct 2005 21:58:00 -0500
Subject: [R] its dates masked by chron
In-Reply-To: <3f87cc6d0510270847p7f3ad04bkc5f6b183403d0cce@mail.gmail.com>
References: <3f87cc6d0510270847p7f3ad04bkc5f6b183403d0cce@mail.gmail.com>
Message-ID: <17249.37816.839294.174538@basebud.nulle.part>


On 27 October 2005 at 11:47, Omar Lakkis wrote:
| I built R 2.2.0 from source on my debian machine yesterday and updated

FYI, Debian had 2.2.0 package for you to download for over a week. 

| all packages. My problem is that "dates" function from its, that my
| code heavely uses is now masked by "dates" from chron.
| How can I specify tehat I want to use dates from its or how can I
| prevent it from being masked?
| 
| > library(its)
| Loading required package: Hmisc
| Hmisc library by Frank E Harrell Jr
| 
| Type library(help='Hmisc'), ?Overview, or ?Hmisc.Overview')
| to see overall documentation.
| 
| NOTE:Hmisc no longer redefines [.factor to drop unused levels when
| subsetting.  To get the old behavior of Hmisc type dropUnusedLevels().
| 
| Attaching package: 'Hmisc'
| 
| 
|         The following object(s) are masked from package:stats :
| 
|          ecdf
| 
| 
| Attaching package: 'chron'
| 
| 
|         The following object(s) are masked from package:its :
| 
|          dates

I can't replicate that. Using the Debian packages for R, Hmisc and its:
edd at basebud:~> dpkg -l r-base-core r-cran-hmisc r-cran-its | grep "^ii" | cut -c-78
ii  r-base-core    2.2.0.final-2  GNU R core of statistical computing language
ii  r-cran-hmisc   3.0.7-1        GNU R miscellaneous functions by Frank Harre
ii  r-cran-its     1.0.9-1        GNU R package for handling irregular time se

I get the following (using --quiet to truncate the output):

edd at basebud:~> R --quiet
> library(its)
Loading required package: Hmisc
Hmisc library by Frank E Harrell Jr

Type library(help='Hmisc'), ?Overview, or ?Hmisc.Overview')
to see overall documentation.

NOTE:Hmisc no longer redefines [.factor to drop unused levels when
subsetting.  To get the old behavior of Hmisc type dropUnusedLevels().

Attaching package: 'Hmisc'


        The following object(s) are masked from package:stats :

         ecdf

>      


Hth, Dirk

-- 
Statistics: The (futile) attempt to offer certainty about uncertainty.
         -- Roger Koenker, 'Dictionary of Received Ideas of Statistics'



From bitwrit at ozemail.com.au  Fri Oct 28 15:21:50 2005
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Fri, 28 Oct 2005 13:21:50 +0000
Subject: [R] help:simple bin problem histogram
In-Reply-To: <436BC871@minerva2.ex.ac.uk>
References: <436BC871@minerva2.ex.ac.uk>
Message-ID: <436225EE.2010901@ozemail.com.au>

sp219 wrote:
> Hi,
> I cannot seem to change the default binning settings for the x axis 
> successfully using hist(). I have tried using axis() in conjunction with 
> xaxt="n", but I keep getting the error message
> Warning message:
> parameter "vect" could not be set in high-level plot() function
> can anyone help please?
> 
Hi Simon,

I didn't see a reply, but I think you want to use "breaks"

x<-sample(1:100,200,TRUE)
hist(x)
hist(x,breaks=seq(0,100,by=20))

Jim



From AnnisC at ASME.org  Fri Oct 28 05:19:36 2005
From: AnnisC at ASME.org (Charles Annis, P.E.)
Date: Thu, 27 Oct 2005 23:19:36 -0400
Subject: [R] How to make labels on my dendrogam look more clear and
	visible
In-Reply-To: <20051027200218.70736885.butchar.2@osu.edu>
Message-ID: <E1EVKmI-0006M5-Nw@smtpauth10.mail.atl.earthlink.net>

I feel a bit timid in asking this question:  Why create the PS?  Why not
create the pdf directly?

?pdf

You have lots of control over the size and other characteristics, and the
pdf can be used by MiKTeX to create a TeX -> pdf document containing your
graphic.

I'm running R 2.2.0 on a DELL WinXP machine.

Charles Annis, P.E.

Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFax:  614-455-3265
http://www.StatisticalEngineering.com
 
-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of jon butchar
Sent: Thursday, October 27, 2005 8:02 PM
To: Srinivas Iyyer
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] How to make labels on my dendrogam look more clear and
visible

On Thu, 27 Oct 2005 16:08:48 -0700 (PDT)
Srinivas Iyyer <srini_iyyer_bio at yahoo.com> wrote:

> Dear group, 
>  I have a matrix with readings for ~180 variables
> observed in 240 conditions. 
> 
> I am doing a hierarchical clustering method (hclust)
> by calculating eucledian distances among them. 
> 
> When I plot the dendrogram from hclust, all my
> variables at the end of the branches are cluttered. I
> cannot read them properly. 
> 
> I tried using :
> > x11(width = 100, height = 70, pointsize = 10)
> >plot(mydat.hcluster)
> 
> 
> and also by
> 
> >x11(width = 1000, height = 300, pointsize = 10)
> >plot(mydat.hcluster)
> 
> I could not make the dendrogram branches go wide and
> make variables at the end of braches more legible. 
> 
> 
> Can any one please help me to make a good diagram so
> that I can see the lables at the end of branches more
> clearly. 
> 
> Thank you. 
> 
> cheers
> Sri
> 


I don't know if it'll help, but I've grown fond of postscript graphs.

For example...

> postscript("mydendogram.ps", height=800, width=2000, pointsize=[????])
> plot(mydendogram)
> dev.off()

gives me very clear print, and then the ps2pdf app can turn it into a pdf
for e-mailing or import to a presentation.

jon b

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From sfalcon at fhcrc.org  Fri Oct 28 06:03:33 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 27 Oct 2005 21:03:33 -0700
Subject: [R] installing Rmpi
In-Reply-To: <8d9f49590510271304r4536bd49l1ee067e375f244dd@mail.gmail.com>
	(Jon Savian's message of "Thu, 27 Oct 2005 13:04:05 -0700")
References: <8d9f49590510271304r4536bd49l1ee067e375f244dd@mail.gmail.com>
Message-ID: <m2u0f22sq2.fsf@fhcrc.org>

On 27 Oct 2005, worknit at gmail.com wrote:
> Rmpi version: 0.4-9 Rmpi is an interface (wrapper) to MPI APIs with
> interactive R slave functionalities.  See `library (help=Rmpi)' for
> details.  Error in dyn.load(x, as.logical(local), as.logical(now)) :
> unable to load shared library
> '/home/apps/R-2.2.0/lib/R/library/Rmpi/libs/Rmpi.so': libmpi.so.0:
> cannot open shared object file: No such file or directory Error in
> dyn.unload(x) : dynamic/shared library

To help diagnose the issue, you might try calling ldd on Rmpi.so.
Perhaps the issue is that you need to add a path to LD_LIBRARY_PATH so
that the linker can find the mpi libs.

HTH,

+ seth



From samrobertsmith at yahoo.com  Fri Oct 28 07:20:47 2005
From: samrobertsmith at yahoo.com (Sam R. Smith)
Date: Thu, 27 Oct 2005 22:20:47 -0700 (PDT)
Subject: [R] inverse matrix
Message-ID: <20051028052047.6111.qmail@web30608.mail.mud.yahoo.com>

if solve(a,b) means to calculate an inverse matrix of
a with b, and i wonder why solve(a)%%b will get
different result?



From jacques.veslot at cirad.fr  Fri Oct 28 07:22:44 2005
From: jacques.veslot at cirad.fr (Jacques VESLOT)
Date: Fri, 28 Oct 2005 09:22:44 +0400
Subject: [R] F tests for random effect models
In-Reply-To: <F5ED48890E2ACB468D0F3A64989D335ACDC493@dc1ex3.air.org>
References: <F5ED48890E2ACB468D0F3A64989D335ACDC493@dc1ex3.air.org>
Message-ID: <4361B5A4.4040309@cirad.fr>

Thanks a lot, but :

 > anova(lmer(Rendement ~ (1 | Pollinisateur) + (1 | Lignee) + (1 | Pollinisateur : Lignee),
	data = mca2))
Analysis of Variance Table
Erreur dans ok[, -nc] : nombre de dimensions incorrect

It looks like working with at least one fixed effect but not with random effect models.


Jacques VESLOT



Doran, Harold a ??crit :
> I think what you're looking for is in anova() 
> 
> 
>>fm1 <- lmer(dv ~ IV ...)
>>anova(fm1)
> 
> 
> 
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jacques VESLOT
> Sent: Thursday, October 27, 2005 2:22 AM
> To: R-help at stat.math.ethz.ch
> Subject: [R] F tests for random effect models
> 
> Dear R-users,
> 
> My question is how to get right F tests for random effects in random
> effect models (I hope this question has not been answered too many times
> yet - I didn't find an answer in rhelp archives).
> 
> My data are in mca2 (enc.) :
> 
> names(mca2)
> [1] "Lignee"        "Pollinisateur" "Rendement"
> 
> dim(mca2)
> [1] 100   3
> 
> replications(Rendement ~ Lignee * Pollinisateur, data = mca2)
>                Lignee        Pollinisateur Lignee:Pollinisateur
>                    20                   10                    2
> 
> Of course, summary(aov(Rendement ~ Pollinisateur * Lignee, data = mca2))
> gives wrong tests of random effects. But, summary(aov1 <- aov(Rendement
> ~ Error(Pollinisateur * Lignee), data = mca2)) gives no test at all, and
> I have to do it like this :
> 
> tab1 <- matrix(unlist(summary(aov1)), nc=5, byrow=T)[,1:3]
> 
> Femp <- c(tab1[1:3, 3]/tab1[c(3,3,4), 3])
> 
> names(Femp) <- c("Pollinisateur", "Lignee", "Interaction")
> 
> 1 - pf(Femp, tab1[1:3,1], tab1[c(3,3,4),1])
> 
> With "lme4" package (I did'nt succeed in writing a working formula with
> lme from "nlme" package), I can "see" standard deviations of random
> effects (but don't know how to find them) with :
> 
> library(lme4)
> summary(lmer(Rendement ~ (1 |Pollinisateur) + (1 | Lignee) + (1 |
> Pollinisateur:Lignee), data=mca2))
> 
> but I can't get F tests.
> 
> Thanks in advance.
> 
> Best regards,
> 
> Jacques VESLOT
> 
> 
> 
> 
>



From ripley at stats.ox.ac.uk  Fri Oct 28 07:46:13 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 28 Oct 2005 06:46:13 +0100 (BST)
Subject: [R] question about sm.density
In-Reply-To: <20051028014728.20086.qmail@web51815.mail.yahoo.com>
References: <20051028014728.20086.qmail@web51815.mail.yahoo.com>
Message-ID: <Pine.LNX.4.61.0510280644350.30536@gannet.stats>

On Thu, 27 Oct 2005, Cunningham Kerry wrote:

> How can I draw a 95% contour in sm.density?
>
> For example,
>
> y <- cbind(rnorm(50), rnorm(50))
>     sm.density(y, display = "slice")
>
> will give 25%, 50% and 75% contours automatically, but
> no reference on other values.

See ?sm.options, the place to set such options.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From vincent at 7d4.com  Fri Oct 28 08:10:34 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Fri, 28 Oct 2005 08:10:34 +0200
Subject: [R] how to write and read an array ?
In-Reply-To: <BAY103-F15974A786711692ABF2858A6680@phx.gbl>
References: <BAY103-F15974A786711692ABF2858A6680@phx.gbl>
Message-ID: <4361C0DA.2040808@7d4.com>

Francisco J. Zagmutt a ??crit :

> check ?dput and ?dget

Thanks for the answer.
dput and dget work well (even if the internal data
writing is not as directly readable as with write.table())

(When I'll be grown-up with R, I'll write a write.3dtable()
function.)

Thanks.
Vincent



From samrobertsmith at yahoo.com  Fri Oct 28 08:31:54 2005
From: samrobertsmith at yahoo.com (Sam R. Smith)
Date: Thu, 27 Oct 2005 23:31:54 -0700 (PDT)
Subject: [R] equal
Message-ID: <20051028063154.26038.qmail@web30602.mail.mud.yahoo.com>

using the same a and b, why solve(a,b) get a 1 by n
matrix while solve(a)%*%b get a n by 1 matrix.
I thought they should be equal to each other...



From ligges at statistik.uni-dortmund.de  Fri Oct 28 08:38:05 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 28 Oct 2005 08:38:05 +0200
Subject: [R] its dates masked by chron
In-Reply-To: <726FC6DD09DE1046AF81B499D70C3BCE264CF6@twinfields02.CORP.TWINFIELDSCAPITAL.COM>
References: <726FC6DD09DE1046AF81B499D70C3BCE264CF6@twinfields02.CORP.TWINFIELDSCAPITAL.COM>
Message-ID: <4361C74D.8050100@statistik.uni-dortmund.de>

Whit Armstrong wrote:

> Uwe,
> 
> It was unclear whether you were referring to chron or its as being
> unmaintained.
> 
> I still maintain its, and I'm actually releasing a new version tonight
> since Kurt has pointed out that the current version is failing package
> checking.

Whit,

that's great!

I was waiting for an its update for quite some time now, you have never 
reacted to my automatically generated request to fix your package with 
R-2.2.0 release nor have you worked on the problem that causes a Warning 
in all current checks for R >= 2.2.0, hence I thought the package is 
rather unmaintained.


> It seems that both its and chron use namespaces.  I thought the intent
> of namespaces was to prevent problems like this.

I have to apologize (see Brian Ripley's reply), because I haven't tested 
myself that library(its) in fact does not cause chron to be loaded.
Hence Namespace stuff should be sufficient. I was just wondering why 
someone would use the same name for a function that is masked by a 
package that automatically is attached some microseconds after 
library(its) is called.

Best,
Uwe


> If there are namespace experts out there who can suggest a fix to this
> problem, I'm happy to put it into the next release.
> 
> -Whit
>  
> 
> 
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch 
>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Uwe Ligges
>>Sent: Thursday, October 27, 2005 4:07 PM
>>To: Peter Dalgaard
>>Cc: r-help at stat.math.ethz.ch
>>Subject: Re: [R] its dates masked by chron
>>
>>Peter Dalgaard wrote:
>>
>>
>>>Omar Lakkis <uofiowa at gmail.com> writes:
>>>
>>>
>>>
>>>>To redescribe the problem; I need to use dates from its its 
>>
>>depends on 
>>
>>>>Hmisc Hmisc depends chron dates in chron masks dates in its
>>>
>>>
>>>So use its::dates ...
>>
>>... or ask the package maintainer (which might be a hard task: the 
>>package currently appears to be more or less unmaintained) to 
>>fix this 
>>probably unintended behaviour.
>>
>>Uwe Ligges
>>
>>
>>
>>
>>>>---------- Forwarded message ----------
>>>>From: Omar Lakkis <uofiowa at gmail.com>
>>>>Date: Oct 27, 2005 11:47 AM
>>>>Subject: its dates masked by chron
>>>>To: r-help at stat.math.ethz.ch
>>>>
>>>>
>>>>I built R 2.2.0 from source on my debian machine yesterday 
>>
>>and updated
>>
>>>>all packages. My problem is that "dates" function from its, that my
>>>>code heavely uses is now masked by "dates" from chron.
>>>>How can I specify tehat I want to use dates from its or how can I
>>>>prevent it from being masked?
>>>>
>>>>
>>>>
>>>>>library(its)
>>>>
>>>>Loading required package: Hmisc
>>>>Hmisc library by Frank E Harrell Jr
>>>>
>>>>Type library(help='Hmisc'), ?Overview, or ?Hmisc.Overview')
>>>>to see overall documentation.
>>>>
>>>>NOTE:Hmisc no longer redefines [.factor to drop unused levels when
>>>>subsetting.  To get the old behavior of Hmisc type 
>>
>>dropUnusedLevels().
>>
>>>>Attaching package: 'Hmisc'
>>>>
>>>>
>>>>       The following object(s) are masked from package:stats :
>>>>
>>>>        ecdf
>>>>
>>>>
>>>>Attaching package: 'chron'
>>>>
>>>>
>>>>       The following object(s) are masked from package:its :
>>>>
>>>>        dates
>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide! 
>>
>>http://www.R-project.org/posting-guide.html
>>
>>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
> 
>



From samrobertsmith at yahoo.com  Fri Oct 28 09:06:40 2005
From: samrobertsmith at yahoo.com (Sam R. Smith)
Date: Fri, 28 Oct 2005 00:06:40 -0700 (PDT)
Subject: [R] solve error
Message-ID: <20051028070640.79227.qmail@web30604.mail.mud.yahoo.com>

> w
    [,1] [,2] [,3] [,4]
1:1  0.0  0.5  0.5  0.0
2:1  0.5  0.0  0.0  0.5
1:2  0.5  0.0  0.0  0.5
2:2  0.0  0.5  0.5  0.0

> solve(w)
Error in solve.default(w) : Lapack routine dgesv:
system is exactly singular

what does the error mean?



From dimitris.rizopoulos at med.kuleuven.be  Fri Oct 28 09:28:55 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Fri, 28 Oct 2005 09:28:55 +0200
Subject: [R] solve error
References: <20051028070640.79227.qmail@web30604.mail.mud.yahoo.com>
Message-ID: <00d601c5db91$411c9420$0540210a@www.domain>

it means that the matrix w is singular; check

all.equal(w[, 1], w[, 4])
all.equal(w[, 2], w[, 3])
# or
qr(w)$rank

you need linearly independent columns!


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Sam R. Smith" <samrobertsmith at yahoo.com>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, October 28, 2005 9:06 AM
Subject: [R] solve error


>> w
>    [,1] [,2] [,3] [,4]
> 1:1  0.0  0.5  0.5  0.0
> 2:1  0.5  0.0  0.0  0.5
> 1:2  0.5  0.0  0.0  0.5
> 2:2  0.0  0.5  0.5  0.0
>
>> solve(w)
> Error in solve.default(w) : Lapack routine dgesv:
> system is exactly singular
>
> what does the error mean?
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From p.dalgaard at biostat.ku.dk  Fri Oct 28 09:28:50 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 28 Oct 2005 09:28:50 +0200
Subject: [R] How to manipulate an abitrary dimensioned array.
In-Reply-To: <436157F9.9070509@salter-point.com>
References: <200510272224.j9RMOQ5I019309@hertz.gene.com>
	<436157F9.9070509@salter-point.com>
Message-ID: <x264ri2j7x.fsf@turmalin.kubism.ku.dk>

Mike Meyer <mikem at salter-point.com> writes:

> Thanks for the suggestion.
> Perhaps I can see how to use apply to get the ratio, but say I also want 
> to return X[,,,,1] in a general way.  Maybe I am being dense but I just 
> don't see it --- probably as a result of too much Perl/Python/Java 
> recently that is clouding my mind.

I think Berton was hinting at

   apply(X,5,"[",1)

(it does get trickier if you need X[,,2,,,1] or X[,,3:4,,,1:2] because
dimensions tend to get lost on the way into and out of the apply FUN
argument.)

In general, you can use do.call constructs, with TRUE for the missing
arguments (there seems to be no nice way to pass missing to do.call).
 
> So can someone suggest a general function that will give me the last 
> layer of an arbitrary dimensioned array?
> 
> Berton Gunter wrote:
> > Why doesn't apply() already do what you want?
> > 
> > -- Bert Gunter
> > Genentech Non-Clinical Statistics
> > South San Francisco, CA
> >  
> > "The business of the statistician is to catalyze the scientific learning
> > process."  - George E. P. Box
> >  
> >  
> > 
> > 
> >>-----Original Message-----
> >>From: r-help-bounces at stat.math.ethz.ch 
> >>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Mike Meyer
> >>Sent: Thursday, October 27, 2005 2:50 PM
> >>To: r-help at stat.math.ethz.ch
> >>Subject: [R] How to manipulate an abitrary dimensioned array.
> >>
> >>If I have an n1 x n1 x 2 array X I can calculate, say,
> >>X[,,1]/X[,,2].
> >>
> >>If it is a 4 dimensional array then I want to be able to calculate
> >>X[,,,1]/X[,,,2], and similarly for higher dimensions.
> >>
> >>How can I write a function to do this in a general way 
> >>without having to 
> >>do a switch for each possible length(dim(X)).  So I want a function g 
> >>that will take an arbitrary dimensioned array, X, and return 
> >>X[,,,1]/X[,,,2], etc.   I know how to do this by turning X into a 
> >>vector, then doing the division, then re-shaping as an array, 
> >>but that 
> >>doesn't seem very elegant.
> >>
> >>What I think I am missing is how to paste/substitute/eval a bunch of 
> >>commas into an array selection.
> >>
> >>Thanks, --Mike
> >>
> >>--
> >>Mike Meyer,  Seattle WA
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide! 
> >>http://www.R-project.org/posting-guide.html
> >>
> > 
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> -- 
> 
> Mike Meyer,  Seattle WA
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From Rau at demogr.mpg.de  Fri Oct 28 09:44:25 2005
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Fri, 28 Oct 2005 09:44:25 +0200
Subject: [R] outer-question
Message-ID: <8B08A3A1EA7AAC41BE24C750338754E69FDF14@HERMES.demogr.mpg.de>

Dear all,

a big thanks to Thomas Lumley, James Holtman and Tony Plate for their
answers. They all pointed in the same direction => I need a vectorized
function to be applied. Hence, I will try to work with a 'wrapper'
function as described in the FAQ.

Thanks again,
Roland


> -----Original Message-----
> From: Thomas Lumley [mailto:tlumley at u.washington.edu] 
> Sent: Thursday, October 27, 2005 11:39 PM
> To: Rau, Roland
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] outer-question
> 
> 
> You want FAQ 7.17 Why does outer() behave strangely with my function?
> 
>  	-thomas
> 
> On Thu, 27 Oct 2005, Rau, Roland wrote:
> 
> > Dear all,
> >
> > This is a rather lengthy message, but I don't know what I 
> made wrong in
> > my real example since the simple code works.
> > I have two variables a, b and a function f for which I would like to
> > calculate all possible combinations of the values of a and b.
> > If f is multiplication, I would simply do:
> >
> > a <- 1:5
> > b <- 1:5
> > outer(a,b)
> >
> > ## A bit more complicated is this:
> > f <- function(a,b,d) {
> > 	return(a*b+(sum(d)))
> > }
> > additional <- runif(100)
> > outer(X=a, Y=b, FUN=f, d=additional)
> >
> > ## So far so good. But now my real example. I would like to plot the
> > ## log-likelihood surface for two parameters alpha and beta of
> > ## a Gompertz distribution with given data
> >
> > ### I have a function to generate random-numbers from a
> > Gompertz-Distribution
> > ### (using the 'inversion method')
> >
> > random.gomp <- function(n, alpha, beta) {
> >            return( (log(1-(beta/alpha*log(1-runif(n)))))/beta)
> > }
> >
> > ## Now I generate some 'lifetimes'
> > no.people <- 1000
> > al <- 0.1
> > bet <- 0.1
> > lifetimes <- random.gomp(n=no.people, alpha=al, beta=bet)
> >
> > ### Since I neither have censoring nor truncation in this 
> simple case,
> > ### the log-likelihood should be simply the sum of the log of the
> > ### the densities (following the parametrization of 
> Klein/Moeschberger
> > ### Survival Analysis, p. 38)
> >
> > loggomp <- function(alphas, betas, timep) {
> >  return(sum(log(alphas) + betas*timep + (alphas/betas *
> > (1-exp(betas*timep)))))
> > }
> >
> > ### Now I thought I could obtain a matrix of the 
> log-likelihood surface
> > ### by specifying possible values for alpha and beta with the given
> > data.
> > ### I was able to produce this matrix with two for-loops. 
> But I thought
> > ### I could use also 'outer' in this case.
> > ### This is what I tried:
> >
> > possible.alphas <- seq(from=0.05, to=0.15, length=30)
> > possible.betas <- seq(from=0.05, to=0.15, length=30)
> >
> > outer(X=possible.alphas, Y=possible.betas, FUN=loggomp, 
> timep=lifetimes)
> >
> > ### But the result is:
> >> outer(X=possible.alphas, Y=possible.betas, FUN=loggomp,
> > timep=lifetimes)
> > Error in outer(X = possible.alphas, Y = possible.betas, FUN 
> = loggomp,
> > :
> >        dim<- : dims [product 900] do not match the length 
> of object [1]
> > In addition: Warning messages:
> > ...
> >
> > ### Can somebody give me some hint where the problem is?
> > ### I checked my definition of 'loggomp' but I thought this 
> looks fine:
> > loggomp(alphas=possible.alphas[1], betas=possible.betas[1],
> > timep=lifetimes)
> > loggomp(alphas=possible.alphas[4], betas=possible.betas[10],
> > timep=lifetimes)
> > loggomp(alphas=possible.alphas[3], betas=possible.betas[11],
> > timep=lifetimes)
> >
> >
> > ### I'd appreciate any kind of advice.
> > ### Thanks a lot in advance.
> > ### Roland
> >
> >
> > +++++
> > This mail has been sent through the MPI for Demographic 
> Rese...{{dropped}}
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >
> 
> Thomas Lumley			Assoc. Professor, Biostatistics
> tlumley at u.washington.edu	University of Washington, Seattle
> 

+++++
This mail has been sent through the MPI for Demographic Rese...{{dropped}}



From machuanxiang at 126.com  Fri Oct 28 10:06:31 2005
From: machuanxiang at 126.com (=?gb2312?B?wu20q8/j?=)
Date: Fri, 28 Oct 2005 16:06:31 +0800 (CST)
Subject: [R] how to amend a table in R workspace?
Message-ID: <4361DC07.0001B2.13225@m61.126.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051028/ba37014d/attachment.pl

From jan.wiener at tuebingen.mpg.de  Fri Oct 28 10:07:41 2005
From: jan.wiener at tuebingen.mpg.de (Jan Wiener)
Date: Fri, 28 Oct 2005 10:07:41 +0200
Subject: [R] 3d bar plot
Message-ID: <web-15526852@tuebingen.mpg.de>

Hi,

does anyone has a bar plot function that produces something
like this (I hope attachments work) ?

If not, I simply want to produce 3d bar plots.

Thanks in advance,
Jan

From ligges at statistik.uni-dortmund.de  Fri Oct 28 10:24:36 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 28 Oct 2005 10:24:36 +0200
Subject: [R] MCMC in R
In-Reply-To: <1430.146.151.119.0.1130465118.squirrel@webmail.cs.wisc.edu>
References: <1430.146.151.119.0.1130465118.squirrel@webmail.cs.wisc.edu>
Message-ID: <4361E044.1000304@statistik.uni-dortmund.de>

han at cs.wisc.edu wrote:

> Dear R-helpers,
> 
> Hi! All.
> I'm doing a project which needs MCMC simulation.
> I wonder whether there exists related packages in R.
> The only one I know is a MCMCpack package.
> What I want to do is implementing gibbs sampling and
> Metropolis-Hastings Algorithm to get the posterior
> of hierarchical bayesian models.
> Thanks in advance.


If you are on Windows, one idea might be to use CRAN package BRugs which 
in fact makes use of OpenBUGS - you have to use OpenBUGS syntax in your 
model file, though.
There is also JAGS (which runs also under Linux) by Martyn Plummer:
http://www-fis.iarc.fr/~martyn/software/jags/

Uwe Ligges




> Jun
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From andreas.zankl at gmail.com  Fri Oct 28 10:27:17 2005
From: andreas.zankl at gmail.com (Andreas Zankl)
Date: Fri, 28 Oct 2005 10:27:17 +0200
Subject: [R] axis scaling problem
Message-ID: <a06230904bf8790822359@[155.105.162.16]>

On the attached figure, I had to use ylim (0,3) to have enough space 
for the labels to be plotted. However, the values on the y-axis are 
never bigger than 1, so the axis labeling does not make much sense. 
Can I only get y-axis tick marks at 0 and 1 but still have the 
additional plotting space for the labels?

Thanks
Andreas

-- 

--------------------------
Andreas Zankl, MD
Division of Molecular Pediatrics
Clinique Infantile 02/50
CHUV
Avenue Pierre Decker 2
CH-1011 Lausanne
Switzerland
Phone: +41-21-3143778
Fax: +41-21-3143546
Email: andreas.zankl at gmail.com

From alxmilton at yahoo.it  Fri Oct 28 11:41:57 2005
From: alxmilton at yahoo.it (alessandro carletti)
Date: Fri, 28 Oct 2005 02:41:57 -0700 (PDT)
Subject: [R] clustering
Message-ID: <20051028094157.78516.qmail@web26606.mail.ukl.yahoo.com>

Hi everybody,
I'm performing a cluster analysis (pkg "cluster") on a
dataset which includes 15 variables: is there a way to
know how much each variable weighs on the final
clustering output?
Thanks

Alessandro



From hicham.zmarrou at creditfoncier.fr  Fri Oct 28 11:48:34 2005
From: hicham.zmarrou at creditfoncier.fr (ZMARROU HICHAM)
Date: Fri, 28 Oct 2005 11:48:34 +0200
Subject: [R]  Empirical distribution
Message-ID: <9199A2D77312E74D9DD31CB6218152565212D7@SREXBE10.cf.caisse-epargne.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051028/da86c34c/attachment.pl

From butchar.2 at osu.edu  Fri Oct 28 11:51:11 2005
From: butchar.2 at osu.edu (jon butchar)
Date: Fri, 28 Oct 2005 05:51:11 -0400
Subject: [R] How to make labels on my dendrogam look more clear and
 visible
In-Reply-To: <E1EVKmI-0006M5-Nw@smtpauth10.mail.atl.earthlink.net>
References: <20051027200218.70736885.butchar.2@osu.edu>
	<E1EVKmI-0006M5-Nw@smtpauth10.mail.atl.earthlink.net>
Message-ID: <20051028055111.21657f3d.butchar.2@osu.edu>

On Thu, 27 Oct 2005 23:19:36 -0400
"Charles Annis, P.E." <AnnisC at ASME.org> wrote:

> I feel a bit timid in asking this question:  Why create the PS?  Why not
> create the pdf directly?
> 
> ?pdf
> 
> You have lots of control over the size and other characteristics, and the
> pdf can be used by MiKTeX to create a TeX -> pdf document containing your
> graphic.
> 
> I'm running R 2.2.0 on a DELL WinXP machine.
> 
> Charles Annis, P.E.
> 
> Charles.Annis at StatisticalEngineering.com
> phone: 561-352-9699
> eFax:  614-455-3265
> http://www.StatisticalEngineering.com

I'm even more timid in answering...  I like to have .ps as my working files and .pdf as the finished(?) ones.  I'm using pdflatex (TeTeX) here, so yes it's definitely an extra step.  This way though, I can instantly see which files are part of a paper / presentation and (later, if needed) backtrack through the drafts to see why I chose those ones.

jon b



From pallier at lscp.ehess.fr  Fri Oct 28 12:39:27 2005
From: pallier at lscp.ehess.fr (Christophe Pallier)
Date: Fri, 28 Oct 2005 12:39:27 +0200
Subject: [R] aov() and lme()  (repeated measures and ANOVA)
In-Reply-To: <mailman.8.1130493601.6207.r-help@stat.math.ethz.ch>
References: <mailman.8.1130493601.6207.r-help@stat.math.ethz.ch>
Message-ID: <4361FFDF.3000700@lscp.ehess.fr>

Hello,


> Subject: [R] aov() and lme()
> From: Jan Wiener <jan.wiener at tuebingen.mpg.de>
> Date: Thu, 27 Oct 2005 13:14:59 +0200
> 
> Sorry for reposting, but even after extensive search I still did not 
> find any answers.
> 
> using: 
> summary(aov(pointErrorAbs~noOfSegments*turnAngle+Error(subj/(noOfSegments+turnAngle)), 
> data=anovaAllData ))
> 
> with subj being a random factor and noOfSegments and turnAngle being 
> fixed factors, I get the following results:
> 
> [...] 
> 
> No I trying to fit the same data with lme and using the following call:
> 
> anova(lme(fixed=pointErrorAbs~noOfSegments*turnAngle, random=~1|subj, 
> data=anovaAllData))
> 
> Unfortunately the results are 'really' different from the aov() 
> procedure (I guess I have the call wrong):
> 

Maybe the following post concerning repeated measures and ANOVA can help:

(from http://tolstoy.newcastle.edu.au/~rking/R/help/03b/7663.html)

 > $ anova(lme(DV ~ GROUP*TRIAL,random= ~1|SUB, correlation=corCompSymm() ))
 >
 >(TRIAL and GROUP are fixed factors)
 >
 >Actually, you do not need lme for to run a repeated measure anova.
 >You could use the aov function:
 >
 > $ summary(aov(DV~GROUP*TRIAL+Error(SUB/TRIAL)))
 >
 > ... yields the same results (when data are balanced)


Christophe Pallier
www.pallier.org



From anna.krechtchouk at cern.ch  Fri Oct 28 12:50:43 2005
From: anna.krechtchouk at cern.ch (Anna Kreshuk)
Date: Fri, 28 Oct 2005 12:50:43 +0200
Subject: [R] different types in quantile{stats}
Message-ID: <43620283.8080101@cern.ch>

Dear R-users,

I've been comparing different types used in quantile() function and I 
found a thing I don't understand.
When n*p[i] is less than 1, most types return the smallest vector 
element, while type 7 interpolates between the smallest and the second 
smallest element. Other types, that generally also use linear 
interpolation, don't do it.
Example:
 > inp
 [1] -0.762498  0.785960  1.588090  1.059290  0.022041  0.423641  0.992247
 [8] -0.240316 -0.231395  0.762765 -1.474740
 > quantile(inp, p, type=6)
     0.1%      0.5%        1%        2%        5%       10%       50%
-1.474740 -1.474740 -1.474740 -1.474740 -1.474740 -1.332292  0.423641
 > quantile(inp, p, type=7)
     0.1%      0.5%        1%        2%        5%       10%       50%
-1.467618 -1.439128 -1.403516 -1.332292 -1.118619 -0.762498  0.423641
 > quantile(inp, p, type=8)
     0.1%      0.5%        1%        2%        5%       10%       50%
-1.474740 -1.474740 -1.474740 -1.474740 -1.474740 -1.142360  0.423641

Is there an explanation to it? I couldn't find anything in the function 
description.

Thanks in advance,
Anna



From kate at few.vu.nl  Fri Oct 28 12:52:23 2005
From: kate at few.vu.nl (Katharine Mullen)
Date: Fri, 28 Oct 2005 12:52:23 +0200 (CEST)
Subject: [R] tcltk package problems (R 2.2.0, SuSE 10)
In-Reply-To: <mailman.9.1130493601.6207.r-help@stat.math.ethz.ch>
References: <mailman.9.1130493601.6207.r-help@stat.math.ethz.ch>
Message-ID: <Pine.GSO.4.56.0510281224230.15291@laurel.few.vu.nl>


i also had a problem getting 2.2.0 to work with tcltk on SuSE 10.0...
and with compiling R from source on SuSE 10.0.

on getting tcltk to work:

i ended up taking source for tcl and tk from
http://www.tcl.tk/software/tcltk/
and recompiling; once you unpack the tar.gz the install instructions are
in the directory /unix for both programs.  after that then

> capabilities()

shows tcltk is TRUE and it works fine.  i'm not sure if this was the
easiest solution, but it worked.

on getting SuSE 10 to compile R from source:  i was unable to use Yast to
get a fortran compiler and ended up recompiling gcc to include
gfortran from the source  (at e.g.
http://gcc.fyxm.net/releases/gcc-4.0.2/  )  if you want some more detailed
instructions feel free to mail me.

best regards and good luck.

----
Katharine Mullen
Department of Physics and Astronomy
Faculty of Sciences
Vrije Universiteit
de Boelelaan 1081
1081 HV Amsterdam
The Netherlands
room: T.1.06
tel: +31 205987870
fax: +31 205987992
e-mail: kate at nat.vu.nl
http://www.nat.vu.nl/~kate/



From eklein at usb.ve  Fri Oct 28 12:55:33 2005
From: eklein at usb.ve (Eduardo Klein)
Date: Fri, 28 Oct 2005 06:55:33 -0400
Subject: [R] line vector plots
Message-ID: <436203A5.6050100@usb.ve>

Hi,

I'm looking for the way to make vector plot over a time line. This plot, 
similar to the "feather plot" in Matlab, is a line in which every thick 
(a time value) one vector is drawn with its length proportional to one 
variable (wind speed, for example) and its direction to another (wind 
direction, for example). Any ideas?

Thanks, EKS

-- 

----------------------------
Eduardo Klein
Instituto de Tecnolog??a y Ciencias Marinas
Universidad Sim??n Bol??var
Caracas, Venezuela
ph/fax (58) (212) 906-3416



From marvena at tin.it  Fri Oct 28 12:57:52 2005
From: marvena at tin.it (Marco Venanzi)
Date: Fri, 28 Oct 2005 12:57:52 +0200
Subject: [R] errors handling
Message-ID: <001001c5dbae$71fa7900$0501a8c0@nome65ff66cddf>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051028/840e3ec3/attachment.pl

From sundar.dorai-raj at pdf.com  Fri Oct 28 12:59:01 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Fri, 28 Oct 2005 05:59:01 -0500
Subject: [R] inverse matrix
In-Reply-To: <20051028052047.6111.qmail@web30608.mail.mud.yahoo.com>
References: <20051028052047.6111.qmail@web30608.mail.mud.yahoo.com>
Message-ID: <43620475.9060208@pdf.com>



Sam R. Smith wrote:
> if solve(a,b) means to calculate an inverse matrix of
> a with b, and i wonder why solve(a)%%b will get
> different result?
> 

It does? Or perhaps your "%%" is not just a typo. It should be "%*%".

 > a <- matrix(rnorm(16), 4, 4)
 > b <- matrix(rnorm(4), 4, 1)
 > solve(a, b)
            [,1]
[1,] -0.8005768
[2,]  0.5913755
[3,] -1.8256012
[4,]  0.8973716
 > solve(a) %*% b
            [,1]
[1,] -0.8005768
[2,]  0.5913755
[3,] -1.8256012
[4,]  0.8973716

HTH,

--sundar



From jacques.veslot at cirad.fr  Fri Oct 28 13:22:21 2005
From: jacques.veslot at cirad.fr (Jacques VESLOT)
Date: Fri, 28 Oct 2005 15:22:21 +0400
Subject: [R] Random effect models
Message-ID: <436209ED.9010302@cirad.fr>

Dear R-users,

Sorry for reposting. I put it in another way :

I want to test random effects in this random effect model :
Rendement ~ Pollinisateur (random) + Lignee (random) + Pollinisateur:Lignee (random)

Of course :
summary(aov(Rendement ~ Pollinisateur * Lignee, data = mca2))
gives wrong tests for random effects.

But :
summary(aov1 <- aov(Rendement ~ Error(Pollinisateur * Lignee), data = mca2))
gives no test at all, and I have to do it with mean squares lying in summary(aov1).

With "lme4" package (I did'nt succeed in writing a working formula with lme from "nlme" package),
I can "see" standard deviations of random effects (I don't know how to find them) but I can't find F 
tests for random effects.

I only want to know if there is an easy way (a function ?) to do F tests for random effects in 
random effect models.

Thanks in advance.

Best regards,

Jacques VESLOT


Data and output are as follows :

 > head(mca2)
   Lignee Pollinisateur Rendement
1     L1            P1      13.4
2     L1            P1      13.3
3     L2            P1      12.4
4     L2            P1      12.6
5     L3            P1      12.7
6     L3            P1      13.0


 > names(mca2)
[1] "Lignee"        "Pollinisateur" "Rendement"

 > dim(mca2)
[1] 100   3

 > replications(Rendement ~ Lignee * Pollinisateur, data = mca2)
               Lignee        Pollinisateur Lignee:Pollinisateur
                   20                   10                    2

 > summary(aov1 <- aov(Rendement ~ Error(Pollinisateur * Lignee), data = mca2)

Error: Pollinisateur
           Df  Sum Sq Mean Sq F value Pr(>F)
Residuals  9 11.9729  1.3303

Error: Lignee
           Df  Sum Sq Mean Sq F value Pr(>F)
Residuals  4 18.0294  4.5074

Error: Pollinisateur:Lignee
           Df Sum Sq Mean Sq F value Pr(>F)
Residuals 36 5.1726  0.1437

Error: Within
           Df Sum Sq Mean Sq F value Pr(>F)
Residuals 50 3.7950  0.0759


# F tests :

 > Femp <- c(tab1[1:3, 3]/tab1[c(3,3,4), 3])
 > names(Femp) <- c("Pollinisateur", "Lignee", "Interaction")
 > Femp
Pollinisateur        Lignee   Interaction
      9.258709     31.370027      1.893061

 > 1 - pf(Femp, tab1[1:3,1], tab1[c(3,3,4),1])
Pollinisateur        Lignee   Interaction
  4.230265e-07  2.773448e-11  1.841028e-02

# Standard deviation :

 > variances <- c(c(tab1[1:3, 3] - tab1[c(3,3,4), 3]) / c(2*5, 2*10, 2), tab1[4,3])
 > names(variances) <- c(names(Femp), "Residuelle")
 > variances
Pollinisateur        Lignee   Interaction    Residuelle
    0.11866389    0.21818333    0.03389167    0.07590000

# Using lmer :

 > library(lme4)
 > lme1 <- lmer(Rendement ~ (1|Pollinisateur) + (1|Lignee) + (1|Pollinisateur:Lignee), data = mca2))
 > summary(lme1)
Linear mixed-effects model fit by REML
Formula: Rendement ~ (1 | Pollinisateur) + (1 | Lignee) + (1 | Pollinisateur:Lignee)
    Data: mca2
       AIC      BIC    logLik MLdeviance REMLdeviance
  105.3845 118.4104 -47.69227   94.35162     95.38453
Random effects:
  Groups               Name        Variance Std.Dev.
  Pollinisateur:Lignee (Intercept) 0.033892 0.18410
  Pollinisateur        (Intercept) 0.118664 0.34448
  Lignee               (Intercept) 0.218183 0.46710
  Residual                         0.075900 0.27550
# of obs: 100, groups: Pollinisateur:Lignee, 50; Pollinisateur, 10; Lignee, 5

Fixed effects:
             Estimate Std. Error DF t value  Pr(>|t|)
(Intercept) 12.60100    0.23862 99  52.808 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

 > anova(lme1)
Analysis of Variance Table
Erreur dans ok[, -nc] : nombre de dimensions incorrect



From p.dalgaard at biostat.ku.dk  Fri Oct 28 13:32:32 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 28 Oct 2005 13:32:32 +0200
Subject: [R] inverse matrix
In-Reply-To: <43620475.9060208@pdf.com>
References: <20051028052047.6111.qmail@web30608.mail.mud.yahoo.com>
	<43620475.9060208@pdf.com>
Message-ID: <x2irvhdghb.fsf@viggo.kubism.ku.dk>

Sundar Dorai-Raj <sundar.dorai-raj at pdf.com> writes:

> Sam R. Smith wrote:
> > if solve(a,b) means to calculate an inverse matrix of
> > a with b, and i wonder why solve(a)%%b will get
> > different result?
> > 
> 
> It does? Or perhaps your "%%" is not just a typo. It should be "%*%".
> 
>  > a <- matrix(rnorm(16), 4, 4)
>  > b <- matrix(rnorm(4), 4, 1)
>  > solve(a, b)
>             [,1]
> [1,] -0.8005768
> [2,]  0.5913755
> [3,] -1.8256012
> [4,]  0.8973716
>  > solve(a) %*% b
>             [,1]
> [1,] -0.8005768
> [2,]  0.5913755
> [3,] -1.8256012
> [4,]  0.8973716

I think the issue is this:

>  solve(a, b)
[1] -0.7251033 -0.3903765  0.3212044 -1.2969697
>  solve(a)%*% b
           [,1]
[1,] -0.7251033
[2,] -0.3903765
[3,]  0.3212044
[4,] -1.2969697

So b gets promoted to a column matrix in one case but not the other. 

This is slightly odd, but it's been that way "forever" and in S(-PLUS)
too, so I think it is unchangeable (it's the sort of thing that
there's a 99% chance that some people have actually been relying on). 

If you want a vector result from a matrix multiply, there's always
> drop(solve(a)%*% b)
[1] -0.7251033 -0.3903765  0.3212044 -1.2969697


-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ligges at statistik.uni-dortmund.de  Fri Oct 28 13:51:04 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 28 Oct 2005 13:51:04 +0200
Subject: [R] errors handling
In-Reply-To: <001001c5dbae$71fa7900$0501a8c0@nome65ff66cddf>
References: <001001c5dbae$71fa7900$0501a8c0@nome65ff66cddf>
Message-ID: <436210A8.7070406@statistik.uni-dortmund.de>

Marco Venanzi wrote:

> Hi, I have an index "i" that varies from 1 to n. For each value of this index I open a connection, e.g.
> 
> conness<-url(...)
> conness<-readLines(conness)
> 
> For certain values of "i" it occurs an error (Warning message: cannot open: HTTP status was `0 (null)' ) and the program flow ends. How can I ignore these errors, allowing the program to go on?

Please read the FAQs, in particular "How can I capture or ignore errors 
in a long simulation?"!

Uwe Ligges


> Thanks,
> 
>                    Marco
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Fri Oct 28 13:53:26 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 28 Oct 2005 13:53:26 +0200
Subject: [R] clustering
In-Reply-To: <20051028094157.78516.qmail@web26606.mail.ukl.yahoo.com>
References: <20051028094157.78516.qmail@web26606.mail.ukl.yahoo.com>
Message-ID: <43621136.70405@statistik.uni-dortmund.de>

alessandro carletti wrote:

> Hi everybody,
> I'm performing a cluster analysis (pkg "cluster") on a
> dataset which includes 15 variables: is there a way to
> know how much each variable weighs on the final
> clustering output?

What kind of cluster method?
Most cluster methods are based on some distance between observations (or 
clusters), hence not related to weights of variables.

Uwe Ligges





> Thanks
> 
> Alessandro
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From HDoran at air.org  Fri Oct 28 14:01:04 2005
From: HDoran at air.org (Doran, Harold)
Date: Fri, 28 Oct 2005 08:01:04 -0400
Subject: [R] Random effect models
Message-ID: <F5ED48890E2ACB468D0F3A64989D335ACDC548@dc1ex3.air.org>

Dear Jacques

I think your question is a little confusing, but let me take a stab at
what I think you're getting at. It seems you are trying to find the
statistical significance of a variance component in your lme model, and
not the significance of a fixed effect. If this is what you are looking
for you will not find this as standard output in lme or lmer. Not in
summary() or anova()

I don't know what you mean by "I can see the sd of ranodm effects but
you do not know how to find them"

Other software programs for mixed linear models do indeed provide this
as ouput, but not the mixed model functions in R. This topic has been
discussed often on this list and the package developer, Doug Bates, has
noted numerous times, with good empirical examples, why such a test may
potentially be misleading. Use the archives to study this rationale and
see the numerous threads on the topic.

Note that the standard deviations of the random effects are *not* the
standard errors of those variance components.

I also noticed you are loading the lme4 library and using lmer. You
should load Matrix, which has the most recent lmer function in that
package.

If I am mistaken, then please clarify and maybe someone else can help.

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jacques VESLOT
Sent: Friday, October 28, 2005 7:22 AM
To: R-help at stat.math.ethz.ch
Subject: [R] Random effect models

Dear R-users,

Sorry for reposting. I put it in another way :

I want to test random effects in this random effect model :
Rendement ~ Pollinisateur (random) + Lignee (random) +
Pollinisateur:Lignee (random)

Of course :
summary(aov(Rendement ~ Pollinisateur * Lignee, data = mca2)) gives
wrong tests for random effects.

But :
summary(aov1 <- aov(Rendement ~ Error(Pollinisateur * Lignee), data =
mca2)) gives no test at all, and I have to do it with mean squares lying
in summary(aov1).

With "lme4" package (I did'nt succeed in writing a working formula with
lme from "nlme" package), I can "see" standard deviations of random
effects (I don't know how to find them) but I can't find F tests for
random effects.

I only want to know if there is an easy way (a function ?) to do F tests
for random effects in random effect models.

Thanks in advance.

Best regards,

Jacques VESLOT


Data and output are as follows :

 > head(mca2)
   Lignee Pollinisateur Rendement
1     L1            P1      13.4
2     L1            P1      13.3
3     L2            P1      12.4
4     L2            P1      12.6
5     L3            P1      12.7
6     L3            P1      13.0


 > names(mca2)
[1] "Lignee"        "Pollinisateur" "Rendement"

 > dim(mca2)
[1] 100   3

 > replications(Rendement ~ Lignee * Pollinisateur, data = mca2)
               Lignee        Pollinisateur Lignee:Pollinisateur
                   20                   10                    2

 > summary(aov1 <- aov(Rendement ~ Error(Pollinisateur * Lignee), data =
mca2)

Error: Pollinisateur
           Df  Sum Sq Mean Sq F value Pr(>F) Residuals  9 11.9729
1.3303

Error: Lignee
           Df  Sum Sq Mean Sq F value Pr(>F) Residuals  4 18.0294
4.5074

Error: Pollinisateur:Lignee
           Df Sum Sq Mean Sq F value Pr(>F) Residuals 36 5.1726  0.1437

Error: Within
           Df Sum Sq Mean Sq F value Pr(>F) Residuals 50 3.7950  0.0759


# F tests :

 > Femp <- c(tab1[1:3, 3]/tab1[c(3,3,4), 3])  > names(Femp) <-
c("Pollinisateur", "Lignee", "Interaction")  > Femp
Pollinisateur        Lignee   Interaction
      9.258709     31.370027      1.893061

 > 1 - pf(Femp, tab1[1:3,1], tab1[c(3,3,4),1])
Pollinisateur        Lignee   Interaction
  4.230265e-07  2.773448e-11  1.841028e-02

# Standard deviation :

 > variances <- c(c(tab1[1:3, 3] - tab1[c(3,3,4), 3]) / c(2*5, 2*10, 2),
tab1[4,3])  > names(variances) <- c(names(Femp), "Residuelle")  >
variances
Pollinisateur        Lignee   Interaction    Residuelle
    0.11866389    0.21818333    0.03389167    0.07590000

# Using lmer :

 > library(lme4)
 > lme1 <- lmer(Rendement ~ (1|Pollinisateur) + (1|Lignee) +
(1|Pollinisateur:Lignee), data = mca2))  > summary(lme1) Linear
mixed-effects model fit by REML
Formula: Rendement ~ (1 | Pollinisateur) + (1 | Lignee) + (1 |
Pollinisateur:Lignee)
    Data: mca2
       AIC      BIC    logLik MLdeviance REMLdeviance
  105.3845 118.4104 -47.69227   94.35162     95.38453
Random effects:
  Groups               Name        Variance Std.Dev.
  Pollinisateur:Lignee (Intercept) 0.033892 0.18410
  Pollinisateur        (Intercept) 0.118664 0.34448
  Lignee               (Intercept) 0.218183 0.46710
  Residual                         0.075900 0.27550
# of obs: 100, groups: Pollinisateur:Lignee, 50; Pollinisateur, 10;
Lignee, 5

Fixed effects:
             Estimate Std. Error DF t value  Pr(>|t|)
(Intercept) 12.60100    0.23862 99  52.808 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

 > anova(lme1)
Analysis of Variance Table
Erreur dans ok[, -nc] : nombre de dimensions incorrect

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From aldeluis at usal.es  Fri Oct 28 14:31:14 2005
From: aldeluis at usal.es (Al)
Date: Fri, 28 Oct 2005 14:31:14 +0200
Subject: [R] Problems with source() function
In-Reply-To: <43612BE4.7060408@wald.ucdavis.edu>
References: <1130434820.14225.40.camel@trinity>
	<43612BE4.7060408@wald.ucdavis.edu>
Message-ID: <1130502674.24777.30.camel@trinity>

Thank you for your answer :)

I've tested your suggestion but without success. The remote load process
is truncated silently using

	source(textConnection(readLines(url(http://...)))

when look at the contents there's not a fixed point of break, is
different each time I execute the command. Therefore the dropped lines
are different every time. It seems the only constant is the time of the
interruption (1 min 55 secs in my system).

Loading the file in a browser (it loads always complete) and examining
the text, there's no apparent malformation in the rupture points.

The longest line is 669 chars and is perfectly loaded in remote and
local mode:

	> lineas <- readLines("transcripts_moe430a.R")
	> length(lineas)
	[1] 20347
	> max(nchar(lineas))
	[1] 669
	> which(nchar(lineas)==669)
	[1] 3241
	> lineas <- readLines(url
("http://10.10.10.3:83/probefinder/scripts/probegrouper.php?chip=moe430a&mode=transcript"))
	> length(lineas)
	[1] 7471
	> max(nchar(lineas))
	[1] 669
	> which(nchar(lineas)==669)
	[1] 3242

Apparently there's a timeout in the url() or some subordinated function.
I will try to use the RCurl package but, for educational purposes, I
prefer that the load process were managed in a simply way... with an
source() for example, in order to not overload alumni with tricky
methods...

Thank you again.

.....................
Alberto de Luis
Bioinformatics and Functional Genomics Lab
Cancer Research Center
Salamanca (Spain)
.....................

On Thu, 2005-10-27 at 12:35 -0700, Duncan Temple Lang wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
> 
> 
> Does
>   source(textConnection(readLines(url(http://...)))
> 
> give the correct answer. If not, what is being dropped
> when you just use readLines() and look at the contents
> of the download.
> 
> And how long is the longest line?
> 
> 
> The RCurl package  (http://www.omegahat.org/RCurl) gives you a lot of
> control in perform and processing HTTP requests, allowing
> you to control the request, and read the body and the header of the
> response.  It may be worth a try if things are getting frustrating.
> 
>  D.
> 
> 
> Al wrote:
> > Hello list members!
> > 
> > I'm trying to enter some data in an R session using source() function
> > with an URL as argument. The data source is a PHP script located in an
> > apache web server and the data is a long list generated on-the-fly,
> > these are the initial lines:
> > 
> > groups<-list()
> > groups[['ENSMUST00000000001']]=c(52611,483683,147952,132170,297514,469248,291525,364037,469915,55472,280220,314688,415650,486875,440898,6781,497785) groups[['ENSMUST00000000003']]=c(416911,327120,425495,72272,297529,101933,371418,139034,318872,367204,237702) groups[['ENSMUST00000000028']]=c(199311,325400,184761,241988,376845,75052,67724,404240,439543,391057,393816) groups[['ENSMUST00000000031']]=c(402587,352900,139030,186068,463553,328881,74942,277085,301431,256149,410846) groups[['ENSMUST00000000033']]=c(12700,23908,11140,122358,389908,390084,383903,354007,457965,106395,131876) groups[['ENSMUST00000000049']]=c(59336,203239,101077,382882,327374,281549,212042,275594,361523,490934,240275) groups[['ENSMUST00000000056']]=c(409571,304584,394332,379699,13785,4260,288889,42538,304075,47734,485512,52501,328509,504846,334607,82566,250088,150240,16422,446551,314484,91878,124752,341638,379512,379890,319764,8019,59221,156508,362524,74001,149400) groups[['ENSMUST00000000058']]=c(26511
 ,4
> 5!
> >  5190,466368,358528,268486,315461,149260,422804,137641,163718,352555)
> > 
> > The problem:
> > When I execute the command it apparently finish ok, without printed
> > errors but when I test the consistency of the data entered using the
> > command length() I always obtain different figures.
> > 
> > More facts:
> > When I source the data from a static file instead an url, the data is
> > fully entered and the length is always the same (20346 list elements).
> > It delays 30 secs to load.
> > 
> > When I source the data from the dynamic way, from an url, it delays 2
> > min. and always data is truncated.
> > 
> > Tried and miserably failed:
> > - Changed .Options$timeout from 60 to 300
> > - Using R --verbose is of no help, the data is silently truncated. 
> > - Changed the expression in which data is entered:
> > groups<-list(
> > 'ENSMUST00000000001'=c(52611,483683,147952,132170,297514,469248,291525,364037,469915,55472,280220,314688,415650,486875,440898,6781,497785),
> > 'ENSMUST00000000003'=c(416911,327120,425495,72272,297529,101933,371418,139034,318872,367204,237702)
> > ...
> > )
> > 
> > Kind list members, is there some timeout I am missing? Some way to debug
> > the process? Some suggestion?
> > 
> > Sincerely, thank you!
> > 
> > Alberto de Luis
> > www.cicancer.org
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> - --
> Duncan Temple Lang                duncan at wald.ucdavis.edu
> Department of Statistics          work:  (530) 752-4782
> 371 Kerr Hall                     fax:   (530) 752-7099
> One Shields Ave.
> University of California at Davis
> Davis, CA 95616, USA
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.2 (Darwin)
> Comment: Using GnuPG with Thunderbird - http://enigmail.mozdev.org
> 
> iD8DBQFDYSvk9p/Jzwa2QP4RAsqfAJ98RNScQ7ea1/MAnt72R0VGZoXaEQCfZvyl
> WNNN/HT1hx/Kix3KSp15XwM=
> =VsDG
> -----END PGP SIGNATURE-----



From MSchwartz at mn.rr.com  Fri Oct 28 14:43:33 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Fri, 28 Oct 2005 07:43:33 -0500
Subject: [R] 3d bar plot
In-Reply-To: <web-15526852@tuebingen.mpg.de>
References: <web-15526852@tuebingen.mpg.de>
Message-ID: <1130503413.12011.3.camel@localhost.localdomain>

On Fri, 2005-10-28 at 10:07 +0200, Jan Wiener wrote:
> Hi,
> 
> does anyone has a bar plot function that produces something
> like this (I hope attachments work) ?
> 
> If not, I simply want to produce 3d bar plots.
> 
> Thanks in advance,
> Jan

Other than perhaps the 'rgl' package I don't think so. In general, 3d
barplots are a bad way to present data (almost as bad as 3d exploding
pie charts...)

More information on 'rgl' is here:

http://rgl.neoscientists.org

and is available via CRAN.

HTH,

Marc Schwartz



From fcombes at gmail.com  Fri Oct 28 14:48:02 2005
From: fcombes at gmail.com (Florence Combes)
Date: Fri, 28 Oct 2005 14:48:02 +0200
Subject: [R] multiple graphs in the same ps file ?
Message-ID: <73dae3060510280548w3f90cee6ga134a7c0f1e8fad9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051028/328fb3f9/attachment.pl

From fcombes at gmail.com  Fri Oct 28 14:52:28 2005
From: fcombes at gmail.com (Florence Combes)
Date: Fri, 28 Oct 2005 14:52:28 +0200
Subject: [R] multiple graphs in the same ps file ? -- with ref.
Message-ID: <73dae3060510280552o2dc58ea1m7bf0420cb37be28f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051028/c603aeea/attachment.pl

From MSchwartz at mn.rr.com  Fri Oct 28 14:56:11 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Fri, 28 Oct 2005 07:56:11 -0500
Subject: [R] axis scaling problem
In-Reply-To: <a06230904bf8790822359@[155.105.162.16]>
References: <a06230904bf8790822359@[155.105.162.16]>
Message-ID: <1130504171.12011.12.camel@localhost.localdomain>

On Fri, 2005-10-28 at 10:27 +0200, Andreas Zankl wrote:
> On the attached figure, I had to use ylim (0,3) to have enough space 
> for the labels to be plotted. However, the values on the y-axis are 
> never bigger than 1, so the axis labeling does not make much sense. 
> Can I only get y-axis tick marks at 0 and 1 but still have the 
> additional plotting space for the labels?
> 
> Thanks
> Andreas

Your attachment did not come through and without either reproducible
code or the image, it would be difficult to provide specific
recommendations.

However, things to consider:

1. Reduce the size of the fonts for your axis labels to make more room.
See ?par and note the cex.axis parameter.

2. Consider using meaningful abbreviations for your labels to shorten
them.

3. Consider rotating the labels using par("las"). You will likely need
to adjust the plot margins using par("mar") as well to make room for the
rotated labels.

4. See R FAQ 7.27 "How can I create rotated axis labels?" which is a
method to enable axis labels rotated to something between horizontal and
vertical (ie. 45 degrees).

HTH,

Marc Schwartz



From MSchwartz at mn.rr.com  Fri Oct 28 15:01:44 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Fri, 28 Oct 2005 08:01:44 -0500
Subject: [R] multiple graphs in the same ps file ?
In-Reply-To: <73dae3060510280548w3f90cee6ga134a7c0f1e8fad9@mail.gmail.com>
References: <73dae3060510280548w3f90cee6ga134a7c0f1e8fad9@mail.gmail.com>
Message-ID: <1130504504.12011.15.camel@localhost.localdomain>

On Fri, 2005-10-28 at 14:48 +0200, Florence Combes wrote:
> Dear all,
> 
> I would like to be able to store multiple graphs in one ps or pdf file, but
> I cannot achieve this only if I don't shut the "postscript" device between
> the graphs.
> 
> here is what I managed to do :
> > postscript(file="test_graph.eps", onefile=TRUE)
> > plot(1:10)
> > plot(1:20)
> >
> > dev.off()
> ---------------------------------------------------------------------------
> 
> but when I try :
> 
> > postscript(file="test_graph.eps", onefile=TRUE)
> > plot(1:10)
> > dev.off
> [execution of another part of the code and then:]
> > plot(1:20)
> > dev.print(postscript, onefile=TRUE)
> > dev.off()
> 
> I only have one page in my file "test_graph.eps" which only contains the
> last graphics.
> 
> So I wonder : is it possible to reopen a ps or pdf file and to add data (I
> tried the "append=TRUE" option but without success) ?
> 
> Thanks a lot
> 
> Florence.

As per ?postscript the 'append' argument is _disregarded_. Please review
the help page more carefully.

If you want more than one plot per PS file, do not use dev.off() between
plots:

  postscript(file="test_graph.eps", onefile = TRUE)
  plot(1:5)
  barplot(1:5)
  dev.off()

HTH,

Marc Schwartz



From MSchwartz at mn.rr.com  Fri Oct 28 15:16:41 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Fri, 28 Oct 2005 08:16:41 -0500
Subject: [R] multiple graphs in the same ps file ? -- with ref.
In-Reply-To: <73dae3060510280552o2dc58ea1m7bf0420cb37be28f@mail.gmail.com>
References: <73dae3060510280552o2dc58ea1m7bf0420cb37be28f@mail.gmail.com>
Message-ID: <1130505401.12011.26.camel@localhost.localdomain>

On Fri, 2005-10-28 at 14:52 +0200, Florence Combes wrote:
> Sorry I put there the ref. :
> I am using R Version 2.0.1 on a Debian.
> Florence.

Definitely time to upgrade, as you are several versions behind. The
current version is 2.2.0.

Marc



From MSchwartz at mn.rr.com  Fri Oct 28 15:23:33 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Fri, 28 Oct 2005 08:23:33 -0500
Subject: [R] multiple graphs in the same ps file ?
In-Reply-To: <1130504504.12011.15.camel@localhost.localdomain>
References: <73dae3060510280548w3f90cee6ga134a7c0f1e8fad9@mail.gmail.com>
	<1130504504.12011.15.camel@localhost.localdomain>
Message-ID: <1130505813.12011.32.camel@localhost.localdomain>

On Fri, 2005-10-28 at 08:01 -0500, Marc Schwartz wrote:
> On Fri, 2005-10-28 at 14:48 +0200, Florence Combes wrote:
> > Dear all,
> > 
> > I would like to be able to store multiple graphs in one ps or pdf file, but
> > I cannot achieve this only if I don't shut the "postscript" device between
> > the graphs.
> > 
> > here is what I managed to do :
> > > postscript(file="test_graph.eps", onefile=TRUE)
> > > plot(1:10)
> > > plot(1:20)
> > >
> > > dev.off()
> > ---------------------------------------------------------------------------
> > 
> > but when I try :
> > 
> > > postscript(file="test_graph.eps", onefile=TRUE)
> > > plot(1:10)
> > > dev.off
> > [execution of another part of the code and then:]
> > > plot(1:20)
> > > dev.print(postscript, onefile=TRUE)
> > > dev.off()
> > 
> > I only have one page in my file "test_graph.eps" which only contains the
> > last graphics.
> > 
> > So I wonder : is it possible to reopen a ps or pdf file and to add data (I
> > tried the "append=TRUE" option but without success) ?
> > 
> > Thanks a lot
> > 
> > Florence.
> 
> As per ?postscript the 'append' argument is _disregarded_. Please review
> the help page more carefully.
> 
> If you want more than one plot per PS file, do not use dev.off() between
> plots:
> 
>   postscript(file="test_graph.eps", onefile = TRUE)
>   plot(1:5)
>   barplot(1:5)
>   dev.off()

One more clarification which I forgot to mention here.

If you want an EPS file (encapsulated postscript) for inclusion in
another document (ie. LaTeX or importing into another application), you
cannot have more than one page in the PS file and must use a postscript
call the looks something like this:

  postscript(file="test_graph.eps", onefile = FALSE, horizontal = FALSE,
             paper = "special", ...)

See the Details section of ?postscript for more information. The three
key arguments are 'onefile', 'horizontal' and 'paper'.

HTH,

Marc Schwartz



From ManuelPerera-Chang at fmc-ag.com  Fri Oct 28 15:31:38 2005
From: ManuelPerera-Chang at fmc-ag.com (ManuelPerera-Chang@fmc-ag.com)
Date: Fri, 28 Oct 2005 15:31:38 +0200
Subject: [R] splitting a character field in R
Message-ID: <OF55D63AFA.EFBFE72E-ONC12570A8.00485342-C12570A8.004A4F0F@notes.fresenius.de>





Dear R users,

I have a dataframe with one character field, and I would like to create two
new fields (columns) in my dataset, by spliting the existing character
field into two using an existing substring.

... something that in SAS I could solve e.g. combining substr(which I am
aware exist in R) and "index" for determining the position of the pattern
within the string.
e.g. if my dataframe is ...
A     B
1     dgabcrt
2     fgrtabc
3     sabcuuu

Then by splitting by substring "abc" I would get ...

A     B           B1    B2
1     dgabcrt     dg    rt
2     fgrtabc     fgrt
3     sabcuuu     s     uuu

Do you know how to do this basic string(dataframe) manipulation in R

Saludos,

Manuel



From elva_robinson at hotmail.com  Fri Oct 28 15:57:34 2005
From: elva_robinson at hotmail.com (Elva Robinson)
Date: Fri, 28 Oct 2005 13:57:34 +0000
Subject: [R] Missing Data?
In-Reply-To: <mailman.11850.1123678986.22818.r-help@stat.math.ethz.ch>
Message-ID: <BAY102-F20B84FC1A9F777DB4AA173846B0@phx.gbl>

I am using glmmPQL on a dataset which has no missing values:

antgl<-glmmPQL(SF~Proc*Min, random= ~1|Trial, family="binomial")

I get the error message:

iteration 1
Error in na.fail.default(list(invwt = c(1.36892171002990, 1.36680104392581,  
:
        missing values in object

I also get this error if na.action is set na.fail. If I set na.action to 
na.omit to ignore the (mythical) missing values, I get other error messages.

There are no missing values - I have used is.na(antgl) to check this. Can 
anyone explain why it seems to think there are?

Thanks



From sfalcon at fhcrc.org  Fri Oct 28 15:57:33 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Fri, 28 Oct 2005 06:57:33 -0700
Subject: [R] Problems with source() function
In-Reply-To: <1130502674.24777.30.camel@trinity> (Al's message of "Fri, 28 Oct
	2005 14:31:14 +0200")
References: <1130434820.14225.40.camel@trinity>
	<43612BE4.7060408@wald.ucdavis.edu>
	<1130502674.24777.30.camel@trinity>
Message-ID: <m2pspp2182.fsf@fhcrc.org>

On 28 Oct 2005, aldeluis at usal.es wrote:

> Thank you for your answer :)
>
> I've tested your suggestion but without success. The remote load
> process is truncated silently using
>
> 	source(textConnection(readLines(url(http://...)))
>
> when look at the contents there's not a fixed point of break, is
> different each time I execute the command. Therefore the dropped
> lines are different every time. It seems the only constant is the
> time of the interruption (1 min 55 secs in my system).

I'm not sure exactly what you are trying to accomplish, but I wonder
if either of the following two ideas would help you:

1. Instead of source(), consider loading the R code on the server side
   and then using save(..., compres=TRUE) to create a binary image.
   You can then feed that to the clients and have them use load().  

2. What happens if you gzip the code before sending and gunzip on the
   client side.  It may be less convenient, although supposedly there
   is a way to do the equivalent of gzfile(url(...)).

HTH,

+ seth



From jholtman at gmail.com  Fri Oct 28 16:00:36 2005
From: jholtman at gmail.com (jim holtman)
Date: Fri, 28 Oct 2005 10:00:36 -0400
Subject: [R] splitting a character field in R
In-Reply-To: <OF55D63AFA.EFBFE72E-ONC12570A8.00485342-C12570A8.004A4F0F@notes.fresenius.de>
References: <OF55D63AFA.EFBFE72E-ONC12570A8.00485342-C12570A8.004A4F0F@notes.fresenius.de>
Message-ID: <644e1f320510280700n34eacb8fy702d46f35f042d61@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051028/8996594b/attachment.pl

From buser at stat.math.ethz.ch  Fri Oct 28 16:01:05 2005
From: buser at stat.math.ethz.ch (Christoph Buser)
Date: Fri, 28 Oct 2005 16:01:05 +0200
Subject: [R] Random effect models
In-Reply-To: <436209ED.9010302@cirad.fr>
References: <436209ED.9010302@cirad.fr>
Message-ID: <17250.12065.575722.44519@stat.math.ethz.ch>

Dear Jacques

You may be interested in the answer of Doug Bates to another
post. The question is different, but in the answer there is a
part about testing if a variance component may be zero:

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/51080.html

Hope this helps.

Best regards,

Christoph Buser

--------------------------------------------------------------
Christoph Buser <buser at stat.math.ethz.ch>
Seminar fuer Statistik, LEO C13
ETH (Federal Inst. Technology)	8092 Zurich	 SWITZERLAND
phone: x-41-44-632-4673		fax: 632-1228
http://stat.ethz.ch/~buser/
--------------------------------------------------------------



Jacques VESLOT writes:
 > Dear R-users,
 > 
 > Sorry for reposting. I put it in another way :
 > 
 > I want to test random effects in this random effect model :
 > Rendement ~ Pollinisateur (random) + Lignee (random) + Pollinisateur:Lignee (random)
 > 
 > Of course :
 > summary(aov(Rendement ~ Pollinisateur * Lignee, data = mca2))
 > gives wrong tests for random effects.
 > 
 > But :
 > summary(aov1 <- aov(Rendement ~ Error(Pollinisateur * Lignee), data = mca2))
 > gives no test at all, and I have to do it with mean squares lying in summary(aov1).
 > 
 > With "lme4" package (I did'nt succeed in writing a working formula with lme from "nlme" package),
 > I can "see" standard deviations of random effects (I don't know how to find them) but I can't find F 
 > tests for random effects.
 > 
 > I only want to know if there is an easy way (a function ?) to do F tests for random effects in 
 > random effect models.
 > 
 > Thanks in advance.
 > 
 > Best regards,
 > 
 > Jacques VESLOT
 > 
 > 
 > Data and output are as follows :
 > 
 >  > head(mca2)
 >    Lignee Pollinisateur Rendement
 > 1     L1            P1      13.4
 > 2     L1            P1      13.3
 > 3     L2            P1      12.4
 > 4     L2            P1      12.6
 > 5     L3            P1      12.7
 > 6     L3            P1      13.0
 > 
 > 
 >  > names(mca2)
 > [1] "Lignee"        "Pollinisateur" "Rendement"
 > 
 >  > dim(mca2)
 > [1] 100   3
 > 
 >  > replications(Rendement ~ Lignee * Pollinisateur, data = mca2)
 >                Lignee        Pollinisateur Lignee:Pollinisateur
 >                    20                   10                    2
 > 
 >  > summary(aov1 <- aov(Rendement ~ Error(Pollinisateur * Lignee), data = mca2)
 > 
 > Error: Pollinisateur
 >            Df  Sum Sq Mean Sq F value Pr(>F)
 > Residuals  9 11.9729  1.3303
 > 
 > Error: Lignee
 >            Df  Sum Sq Mean Sq F value Pr(>F)
 > Residuals  4 18.0294  4.5074
 > 
 > Error: Pollinisateur:Lignee
 >            Df Sum Sq Mean Sq F value Pr(>F)
 > Residuals 36 5.1726  0.1437
 > 
 > Error: Within
 >            Df Sum Sq Mean Sq F value Pr(>F)
 > Residuals 50 3.7950  0.0759
 > 
 > 
 > # F tests :
 > 
 >  > Femp <- c(tab1[1:3, 3]/tab1[c(3,3,4), 3])
 >  > names(Femp) <- c("Pollinisateur", "Lignee", "Interaction")
 >  > Femp
 > Pollinisateur        Lignee   Interaction
 >       9.258709     31.370027      1.893061
 > 
 >  > 1 - pf(Femp, tab1[1:3,1], tab1[c(3,3,4),1])
 > Pollinisateur        Lignee   Interaction
 >   4.230265e-07  2.773448e-11  1.841028e-02
 > 
 > # Standard deviation :
 > 
 >  > variances <- c(c(tab1[1:3, 3] - tab1[c(3,3,4), 3]) / c(2*5, 2*10, 2), tab1[4,3])
 >  > names(variances) <- c(names(Femp), "Residuelle")
 >  > variances
 > Pollinisateur        Lignee   Interaction    Residuelle
 >     0.11866389    0.21818333    0.03389167    0.07590000
 > 
 > # Using lmer :
 > 
 >  > library(lme4)
 >  > lme1 <- lmer(Rendement ~ (1|Pollinisateur) + (1|Lignee) + (1|Pollinisateur:Lignee), data = mca2))
 >  > summary(lme1)
 > Linear mixed-effects model fit by REML
 > Formula: Rendement ~ (1 | Pollinisateur) + (1 | Lignee) + (1 | Pollinisateur:Lignee)
 >     Data: mca2
 >        AIC      BIC    logLik MLdeviance REMLdeviance
 >   105.3845 118.4104 -47.69227   94.35162     95.38453
 > Random effects:
 >   Groups               Name        Variance Std.Dev.
 >   Pollinisateur:Lignee (Intercept) 0.033892 0.18410
 >   Pollinisateur        (Intercept) 0.118664 0.34448
 >   Lignee               (Intercept) 0.218183 0.46710
 >   Residual                         0.075900 0.27550
 > # of obs: 100, groups: Pollinisateur:Lignee, 50; Pollinisateur, 10; Lignee, 5
 > 
 > Fixed effects:
 >              Estimate Std. Error DF t value  Pr(>|t|)
 > (Intercept) 12.60100    0.23862 99  52.808 < 2.2e-16 ***
 > ---
 > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
 > 
 >  > anova(lme1)
 > Analysis of Variance Table
 > Erreur dans ok[, -nc] : nombre de dimensions incorrect
 > 
 > ______________________________________________
 > R-help at stat.math.ethz.ch mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From fcombes at gmail.com  Fri Oct 28 16:01:55 2005
From: fcombes at gmail.com (Florence Combes)
Date: Fri, 28 Oct 2005 16:01:55 +0200
Subject: [R] splitting a character field in R
In-Reply-To: <OF55D63AFA.EFBFE72E-ONC12570A8.00485342-C12570A8.004A4F0F@notes.fresenius.de>
References: <OF55D63AFA.EFBFE72E-ONC12570A8.00485342-C12570A8.004A4F0F@notes.fresenius.de>
Message-ID: <73dae3060510280701p35253cb6md3a25fef8760a602@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051028/3e0f5801/attachment.pl

From rreiss at sciences.com  Fri Oct 28 16:22:51 2005
From: rreiss at sciences.com (Richard Reiss)
Date: Fri, 28 Oct 2005 10:22:51 -0400
Subject: [R] Uncensoring a dataset
Message-ID: <24B7390A8EDF9440BF68F966B17B53E406E19C@sii.sciences.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051028/06d1834f/attachment.pl

From ManuelPerera-Chang at fmc-ag.com  Fri Oct 28 16:38:34 2005
From: ManuelPerera-Chang at fmc-ag.com (ManuelPerera-Chang@fmc-ag.com)
Date: Fri, 28 Oct 2005 16:38:34 +0200
Subject: [R] splitting a character field in R
Message-ID: <OFC403C20F.59A2A469-ONC12570A8.00504977-C12570A8.00506FB3@notes.fresenius.de>





Hi Jim,

Thanks for your post, I was aware of strsplit, but really could not find
out how i could use it.

I tried like in your example ...

A<-c(1,2,3)
B<-c("dgabcrt","fgrtabc","sabcuuu")
C<-strsplit(B,"abc")
> C
[[1]]
[1] "dg" "rt"

[[2]]
[1] "fgrt"

[[3]]
[1] "s"   "uuu"

Which looks promissing, but here C is a list with three elements. But how
to create the two vectors I need from here, that is

("dg","fgrt", "s") and ("rt","","uuu")

(or how to get access to the substrings "rt" or "uuu").

Greetings

Manuel



                                                                                                                                 
                      jim holtman                                                                                                
                      <jholtman at gmail.c        To:       "ManuelPerera-Chang at fmc-ag.com" <ManuelPerera-Chang at fmc-ag.com>         
                      om>                      cc:       r-help at stat.math.ethz.ch                                                
                                               Subject:  Re: [R] splitting a character field in R                                
                      28.10.2005 16:00                                                                                           
                                                                                                                                 
                                                                                                                                 




> x <- 'dfabcxy'
> strsplit(x, 'abc')
[[1]]
[1] "df" "xy"


>




On 10/28/05, ManuelPerera-Chang at fmc-ag.com <ManuelPerera-Chang at fmc-ag.com >
wrote:




      Dear R users,

      I have a dataframe with one character field, and I would like to
      create two
      new fields (columns) in my dataset, by spliting the existing
      character
      field into two using an existing substring.

      ... something that in SAS I could solve e.g. combining substr(which I
      am
      aware exist in R) and "index" for determining the position of the
      pattern
      within the string.
      e.g. if my dataframe is ...
      A     B
      1     dgabcrt
      2     fgrtabc
      3     sabcuuu

      Then by splitting by substring "abc" I would get ...

      A     B           B1    B2
      1     dgabcrt     dg    rt
      2     fgrtabc     fgrt
      3     sabcuuu     s     uuu

      Do you know how to do this basic string(dataframe) manipulation in R

      Saludos,

      Manuel

      ______________________________________________
      R-help at stat.math.ethz.ch mailing list
      https://stat.ethz.ch/mailman/listinfo/r-help
      PLEASE do read the posting guide!
      http://www.R-project.org/posting-guide.html



--
Jim Holtman
Cincinnati, OH
+1 513 247 0281

What the problem you are trying to solve?



From rreiss at sciences.com  Fri Oct 28 16:41:40 2005
From: rreiss at sciences.com (Richard Reiss)
Date: Fri, 28 Oct 2005 10:41:40 -0400
Subject: [R] Uncensoring a dataset - resent
Message-ID: <24B7390A8EDF9440BF68F966B17B53E404112A@sii.sciences.com>



Does anyone know of an R package that I can use to uncensor a normal or
log-normal dataset?  I'm particularly interested in the MLE method of
Cohen (1959), "Simplified estimators for the normal distribution when
samples are single censored or truncated," Technometrics, 1(3), 217-237.
Of course, if there is anything better, I'd be glad to hear about that
too.


Thanks.

Rick



From ggrothendieck at gmail.com  Fri Oct 28 16:45:29 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 28 Oct 2005 10:45:29 -0400
Subject: [R] splitting a character field in R
In-Reply-To: <OFC403C20F.59A2A469-ONC12570A8.00504977-C12570A8.00506FB3@notes.fresenius.de>
References: <OFC403C20F.59A2A469-ONC12570A8.00504977-C12570A8.00506FB3@notes.fresenius.de>
Message-ID: <971536df0510280745o56f47cd1p4da447f5eefc5b4d@mail.gmail.com>

You could use:

data.frame(First = sub("abc.*", "", B), Second = sub(".*abc", "", B))

or if you want to prevent conversion to factors:

data.frame(First = I(sub("abc.*", "", B)), Second = I(sub(".*abc", "", B)))

On 10/28/05, ManuelPerera-Chang at fmc-ag.com
<ManuelPerera-Chang at fmc-ag.com> wrote:
>
>
>
>
> Hi Jim,
>
> Thanks for your post, I was aware of strsplit, but really could not find
> out how i could use it.
>
> I tried like in your example ...
>
> A<-c(1,2,3)
> B<-c("dgabcrt","fgrtabc","sabcuuu")
> C<-strsplit(B,"abc")
> > C
> [[1]]
> [1] "dg" "rt"
>
> [[2]]
> [1] "fgrt"
>
> [[3]]
> [1] "s"   "uuu"
>
> Which looks promissing, but here C is a list with three elements. But how
> to create the two vectors I need from here, that is
>
> ("dg","fgrt", "s") and ("rt","","uuu")
>
> (or how to get access to the substrings "rt" or "uuu").
>
> Greetings
>
> Manuel
>
>
>
>
>                      jim holtman
>                      <jholtman at gmail.c        To:       "ManuelPerera-Chang at fmc-ag.com" <ManuelPerera-Chang at fmc-ag.com>
>                      om>                      cc:       r-help at stat.math.ethz.ch
>                                               Subject:  Re: [R] splitting a character field in R
>                      28.10.2005 16:00
>
>
>
>
>
>
> > x <- 'dfabcxy'
> > strsplit(x, 'abc')
> [[1]]
> [1] "df" "xy"
>
>
> >
>
>
>
>
> On 10/28/05, ManuelPerera-Chang at fmc-ag.com <ManuelPerera-Chang at fmc-ag.com >
> wrote:
>
>
>
>
>      Dear R users,
>
>      I have a dataframe with one character field, and I would like to
>      create two
>      new fields (columns) in my dataset, by spliting the existing
>      character
>      field into two using an existing substring.
>
>      ... something that in SAS I could solve e.g. combining substr(which I
>      am
>      aware exist in R) and "index" for determining the position of the
>      pattern
>      within the string.
>      e.g. if my dataframe is ...
>      A     B
>      1     dgabcrt
>      2     fgrtabc
>      3     sabcuuu
>
>      Then by splitting by substring "abc" I would get ...
>
>      A     B           B1    B2
>      1     dgabcrt     dg    rt
>      2     fgrtabc     fgrt
>      3     sabcuuu     s     uuu
>
>      Do you know how to do this basic string(dataframe) manipulation in R
>
>      Saludos,
>
>      Manuel
>
>      ______________________________________________
>      R-help at stat.math.ethz.ch mailing list
>      https://stat.ethz.ch/mailman/listinfo/r-help
>      PLEASE do read the posting guide!
>      http://www.R-project.org/posting-guide.html
>
>
>
> --
> Jim Holtman
> Cincinnati, OH
> +1 513 247 0281
>
> What the problem you are trying to solve?
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From vincent at 7d4.com  Fri Oct 28 16:50:19 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Fri, 28 Oct 2005 16:50:19 +0200
Subject: [R] numeric index of a matrix column name ?
Message-ID: <43623AAB.5010407@7d4.com>

Dear All,

I have written the following small code in order to return
the numeric index of a given matrix column ascii name.
It works, but there is perhaps/probably a predefined function
which does that ?
If yes, thanks for pointing me to it.

# input  : a matrix M and a column ascii name
# output : the numeric index of the column
colnameindex = function(M , colname0)
{
colsnames = names(M[1,]);
theindex  = which(colsnames==colname0);
return(theindex);
}

Thanks
Vincent



From dimitris.rizopoulos at med.kuleuven.be  Fri Oct 28 16:54:24 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Fri, 28 Oct 2005 16:54:24 +0200
Subject: [R] splitting a character field in R
References: <OFC403C20F.59A2A469-ONC12570A8.00504977-C12570A8.00506FB3@notes.fresenius.de>
Message-ID: <009201c5dbcf$7c5585e0$0540210a@www.domain>

try the following:

A <- c("dgabcrt", "fgrtabc", "sabcuuu")
B <- strsplit(A, "abc")

x1 <- sapply(B, "[", 1); x1[is.na(x1)] <- ""
x2 <- sapply(B, "[", 2); x2[is.na(x2)] <- ""
x1
x2

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm



----- Original Message ----- 
From: <ManuelPerera-Chang at fmc-ag.com>
To: <jholtman at gmail.com>
Cc: <r-help at stat.math.ethz.ch>
Sent: Friday, October 28, 2005 4:38 PM
Subject: Re: [R] splitting a character field in R


>
>
>
>
> Hi Jim,
>
> Thanks for your post, I was aware of strsplit, but really could not 
> find
> out how i could use it.
>
> I tried like in your example ...
>
> A<-c(1,2,3)
> B<-c("dgabcrt","fgrtabc","sabcuuu")
> C<-strsplit(B,"abc")
>> C
> [[1]]
> [1] "dg" "rt"
>
> [[2]]
> [1] "fgrt"
>
> [[3]]
> [1] "s"   "uuu"
>
> Which looks promissing, but here C is a list with three elements. 
> But how
> to create the two vectors I need from here, that is
>
> ("dg","fgrt", "s") and ("rt","","uuu")
>
> (or how to get access to the substrings "rt" or "uuu").
>
> Greetings
>
> Manuel
>
>
>
>
>                      jim holtman
>                      <jholtman at gmail.c        To: 
> "ManuelPerera-Chang at fmc-ag.com" <ManuelPerera-Chang at fmc-ag.com>
>                      om>                      cc: 
> r-help at stat.math.ethz.ch
>                                               Subject:  Re: [R] 
> splitting a character field in R
>                      28.10.2005 16:00
>
>
>
>
>
>
>> x <- 'dfabcxy'
>> strsplit(x, 'abc')
> [[1]]
> [1] "df" "xy"
>
>
>>
>
>
>
>
> On 10/28/05, ManuelPerera-Chang at fmc-ag.com 
> <ManuelPerera-Chang at fmc-ag.com >
> wrote:
>
>
>
>
>      Dear R users,
>
>      I have a dataframe with one character field, and I would like 
> to
>      create two
>      new fields (columns) in my dataset, by spliting the existing
>      character
>      field into two using an existing substring.
>
>      ... something that in SAS I could solve e.g. combining 
> substr(which I
>      am
>      aware exist in R) and "index" for determining the position of 
> the
>      pattern
>      within the string.
>      e.g. if my dataframe is ...
>      A     B
>      1     dgabcrt
>      2     fgrtabc
>      3     sabcuuu
>
>      Then by splitting by substring "abc" I would get ...
>
>      A     B           B1    B2
>      1     dgabcrt     dg    rt
>      2     fgrtabc     fgrt
>      3     sabcuuu     s     uuu
>
>      Do you know how to do this basic string(dataframe) manipulation 
> in R
>
>      Saludos,
>
>      Manuel
>
>      ______________________________________________
>      R-help at stat.math.ethz.ch mailing list
>      https://stat.ethz.ch/mailman/listinfo/r-help
>      PLEASE do read the posting guide!
>      http://www.R-project.org/posting-guide.html
>
>
>
> --
> Jim Holtman
> Cincinnati, OH
> +1 513 247 0281
>
> What the problem you are trying to solve?
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From tlumley at u.washington.edu  Fri Oct 28 16:55:30 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 28 Oct 2005 07:55:30 -0700 (PDT)
Subject: [R] Uncensoring a dataset - resent
In-Reply-To: <24B7390A8EDF9440BF68F966B17B53E404112A@sii.sciences.com>
References: <24B7390A8EDF9440BF68F966B17B53E404112A@sii.sciences.com>
Message-ID: <Pine.LNX.4.63a.0510280754080.24691@homer21.u.washington.edu>

On Fri, 28 Oct 2005, Richard Reiss wrote:
>
> Does anyone know of an R package that I can use to uncensor a normal or
> log-normal dataset?  I'm particularly interested in the MLE method of
> Cohen (1959), "Simplified estimators for the normal distribution when
> samples are single censored or truncated," Technometrics, 1(3), 217-237.
> Of course, if there is anything better, I'd be glad to hear about that
> too.
>

survreg() in the survival package will fit censored normal and censored 
lognormal models.  If you fit a model with only an intercept this will 
estimate the mean and variance.

 	-thomas



From dimitris.rizopoulos at med.kuleuven.be  Fri Oct 28 17:00:19 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Fri, 28 Oct 2005 17:00:19 +0200
Subject: [R] numeric index of a matrix column name ?
References: <43623AAB.5010407@7d4.com>
Message-ID: <009d01c5dbd0$4ff0aa60$0540210a@www.domain>

probably you need

match(colname0, colnames(M))


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm



----- Original Message ----- 
From: <vincent at 7d4.com>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, October 28, 2005 4:50 PM
Subject: [R] numeric index of a matrix column name ?


> Dear All,
>
> I have written the following small code in order to return
> the numeric index of a given matrix column ascii name.
> It works, but there is perhaps/probably a predefined function
> which does that ?
> If yes, thanks for pointing me to it.
>
> # input  : a matrix M and a column ascii name
> # output : the numeric index of the column
> colnameindex = function(M , colname0)
> {
> colsnames = names(M[1,]);
> theindex  = which(colsnames==colname0);
> return(theindex);
> }
>
> Thanks
> Vincent
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From vincent at 7d4.com  Fri Oct 28 17:07:03 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Fri, 28 Oct 2005 17:07:03 +0200
Subject: [R] numeric index of a matrix column name ?
In-Reply-To: <009d01c5dbd0$4ff0aa60$0540210a@www.domain>
References: <43623AAB.5010407@7d4.com>
	<009d01c5dbd0$4ff0aa60$0540210a@www.domain>
Message-ID: <43623E97.5000405@7d4.com>

Dimitris Rizopoulos a ??crit :

> probably you need
> match(colname0, colnames(M))
> I hope it helps.
> Best,
> Dimitris

yes. (why do simple ...)
Thanks Dimitris.
Have a good we.
Vincent



From f.calboli at imperial.ac.uk  Fri Oct 28 17:12:15 2005
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Fri, 28 Oct 2005 16:12:15 +0100
Subject: [R] replacing a factor value in a data frame
Message-ID: <1130512335.15713.169.camel@localhost.localdomain>

Hi All,

I have the following problem, that's driving me mad.

I have a dataframe of factors, from a genetic scan of SNPs. I DO have
NAs in the dataframe, which would look like:

   V4 V5 V6 V7   V8   V9 V10
1  TT GG TT AC   AG   AG  TT
2  AT CC TT AA   AA   AA  TT
3  AT CC TT AC   AA <NA>  TT
4  TT CC TT AA   AA   AA  TT
5  AT CG TT CC   AA   AA  TT
6  TT CC TT AA   AA   AA  TT
7  AT CC TT CC <NA> <NA>  TT
8  TT CC TT AC   AG   AG  TT
9  AT CC TT CC   AG <NA>  TT
10 TT CC TT CC   GG   GG  TT


In the dataframe I have 1 column where one factor has been erroneosly
given alternative readings: CG and GC. 

I want to change the instances of GC to CG and I use the code:

data[data[,30]=="GC", 30] = "CG"

but get the error:
Error in "[<-.data.frame"(`*tmp*`, all[, 30] == "GC", 30
        missing values are not allowed in subscripted as

Any hints?

Cheers,

Federico

-- 
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St Mary's Campus
Norfolk Place, London W2 1PG

Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From jholtman at gmail.com  Fri Oct 28 17:15:42 2005
From: jholtman at gmail.com (jim holtman)
Date: Fri, 28 Oct 2005 11:15:42 -0400
Subject: [R] splitting a character field in R
In-Reply-To: <OFC403C20F.59A2A469-ONC12570A8.00504977-C12570A8.00506FB3@notes.fresenius.de>
References: <OFC403C20F.59A2A469-ONC12570A8.00504977-C12570A8.00506FB3@notes.fresenius.de>
Message-ID: <644e1f320510280815o513aca02m39739c513b1273ed@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051028/7b298dd2/attachment.pl

From p.dalgaard at biostat.ku.dk  Fri Oct 28 17:36:59 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 28 Oct 2005 17:36:59 +0200
Subject: [R] replacing a factor value in a data frame
In-Reply-To: <1130512335.15713.169.camel@localhost.localdomain>
References: <1130512335.15713.169.camel@localhost.localdomain>
Message-ID: <x21x25d55w.fsf@viggo.kubism.ku.dk>

Federico Calboli <f.calboli at imperial.ac.uk> writes:

> Hi All,
> 
> I have the following problem, that's driving me mad.
> 
> I have a dataframe of factors, from a genetic scan of SNPs. I DO have
> NAs in the dataframe, which would look like:
> 
>    V4 V5 V6 V7   V8   V9 V10
> 1  TT GG TT AC   AG   AG  TT
> 2  AT CC TT AA   AA   AA  TT
> 3  AT CC TT AC   AA <NA>  TT
> 4  TT CC TT AA   AA   AA  TT
> 5  AT CG TT CC   AA   AA  TT
> 6  TT CC TT AA   AA   AA  TT
> 7  AT CC TT CC <NA> <NA>  TT
> 8  TT CC TT AC   AG   AG  TT
> 9  AT CC TT CC   AG <NA>  TT
> 10 TT CC TT CC   GG   GG  TT
> 
> 
> In the dataframe I have 1 column where one factor has been erroneosly
> given alternative readings: CG and GC. 
> 
> I want to change the instances of GC to CG and I use the code:
> 
> data[data[,30]=="GC", 30] = "CG"
> 
> but get the error:
> Error in "[<-.data.frame"(`*tmp*`, all[, 30] == "GC", 30
>         missing values are not allowed in subscripted as
> 
> Any hints?


data[isTRUE(data[,30]=="GC"), 30] = "CG"

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Fri Oct 28 17:39:25 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 28 Oct 2005 16:39:25 +0100 (BST)
Subject: [R] replacing a factor value in a data frame
In-Reply-To: <1130512335.15713.169.camel@localhost.localdomain>
References: <1130512335.15713.169.camel@localhost.localdomain>
Message-ID: <Pine.LNX.4.61.0510281637250.24765@gannet.stats>

On Fri, 28 Oct 2005, Federico Calboli wrote:

> Hi All,
>
> I have the following problem, that's driving me mad.
>
> I have a dataframe of factors, from a genetic scan of SNPs. I DO have
> NAs in the dataframe, which would look like:
>
>   V4 V5 V6 V7   V8   V9 V10
> 1  TT GG TT AC   AG   AG  TT
> 2  AT CC TT AA   AA   AA  TT
> 3  AT CC TT AC   AA <NA>  TT
> 4  TT CC TT AA   AA   AA  TT
> 5  AT CG TT CC   AA   AA  TT
> 6  TT CC TT AA   AA   AA  TT
> 7  AT CC TT CC <NA> <NA>  TT
> 8  TT CC TT AC   AG   AG  TT
> 9  AT CC TT CC   AG <NA>  TT
> 10 TT CC TT CC   GG   GG  TT
>
>
> In the dataframe I have 1 column where one factor has been erroneosly
> given alternative readings: CG and GC.
>
> I want to change the instances of GC to CG and I use the code:
>
> data[data[,30]=="GC", 30] = "CG"
>
> but get the error:
> Error in "[<-.data.frame"(`*tmp*`, all[, 30] == "GC", 30
>        missing values are not allowed in subscripted as
>
> Any hints?

1) Use %in% not ==

2) (Better) As this is a factor, use levels<- to merge the levels.  See 
?levels.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From macq at llnl.gov  Fri Oct 28 18:04:33 2005
From: macq at llnl.gov (Don MacQueen)
Date: Fri, 28 Oct 2005 09:04:33 -0700
Subject: [R] Uncensoring a dataset - resent
In-Reply-To: <24B7390A8EDF9440BF68F966B17B53E404112A@sii.sciences.com>
References: <24B7390A8EDF9440BF68F966B17B53E404112A@sii.sciences.com>
Message-ID: <p06210202bf87fa1b3d03@[128.115.153.6]>

Although it doesn't implement the MLE, if you are looking at 
environmental data, I'd suggest looking at the R package NADA 
(available from CRAN). You could also contact Ed Frome at 
FromeEL at ornl.gov (http://www.csm.ornl.gov/~frome/index.html), and ask 
about his R functions for this -- not packaged, though.

-Don

At 10:41 AM -0400 10/28/05, Richard Reiss wrote:
>Does anyone know of an R package that I can use to uncensor a normal or
>log-normal dataset?  I'm particularly interested in the MLE method of
>Cohen (1959), "Simplified estimators for the normal distribution when
>samples are single censored or truncated," Technometrics, 1(3), 217-237.
>Of course, if there is anything better, I'd be glad to hear about that
>too.
>
>
>Thanks.
>
>Rick
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From aldeluis at usal.es  Fri Oct 28 18:07:17 2005
From: aldeluis at usal.es (Al)
Date: Fri, 28 Oct 2005 18:07:17 +0200
Subject: [R] Problems with source() function
In-Reply-To: <m2pspp2182.fsf@fhcrc.org>
References: <1130434820.14225.40.camel@trinity>
	<43612BE4.7060408@wald.ucdavi s.edu><1130502674.24777.30.camel@trinity>
	<m2pspp2182.fsf@fhcrc.org>
Message-ID: <1130515637.24777.52.camel@trinity>

I'm trying to feed data generated on-the-fly by a PHP script using R
function source(), passing the arguments in the URL, using GET method
("http://someserver.com/script.php?a=343&b=873"). If not on-the-fly, the
user has to wait more and get the data in more than one step.

I'm trying a one-step simple method but for some reason the source()
function truncates silently the data. I will try your suggestion of a
binary file if I can generate the gzip stream on-the-fly...

Thank you!

.....................
Alberto de Luis
Bioinformatics and Functional Genomics Lab
Cancer Research Center
Salamanca (Spain)
.....................

On Fri, 2005-10-28 at 06:57 -0700, Seth Falcon wrote:
> On 28 Oct 2005, aldeluis at usal.es wrote:
> 
> > Thank you for your answer :)
> >
> > I've tested your suggestion but without success. The remote load
> > process is truncated silently using
> >
> > 	source(textConnection(readLines(url(http://...)))
> >
> > when look at the contents there's not a fixed point of break, is
> > different each time I execute the command. Therefore the dropped
> > lines are different every time. It seems the only constant is the
> > time of the interruption (1 min 55 secs in my system).
> 
> I'm not sure exactly what you are trying to accomplish, but I wonder
> if either of the following two ideas would help you:
> 
> 1. Instead of source(), consider loading the R code on the server side
>    and then using save(..., compres=TRUE) to create a binary image.
>    You can then feed that to the clients and have them use load().  
> 
> 2. What happens if you gzip the code before sending and gunzip on the
>    client side.  It may be less convenient, although supposedly there
>    is a way to do the equivalent of gzfile(url(...)).
> 
> HTH,
> 
> + seth
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From droberts at montana.edu  Fri Oct 28 18:01:14 2005
From: droberts at montana.edu (Dave Roberts)
Date: Fri, 28 Oct 2005 10:01:14 -0600
Subject: [R] replacing a factor value in a data frame
In-Reply-To: <1130512335.15713.169.camel@localhost.localdomain>
References: <1130512335.15713.169.camel@localhost.localdomain>
Message-ID: <43624B4A.2020406@montana.edu>

Federico,

     There doesn't appear to be an instance of the value you want to 
change in your example, so I had to improvise.  Part of the problem may 
be that the dataframe is composed of factors, and it's not possible to 
convert the value of a factor to another value that's in the set of 
possible values, given by the levels() function.  So, if you want to 
change GC to CG, but CG does not already exist in the set of possible 
values you'll have to add it. E.g.

 > tmp <- data
 > levels(tmp[,30]) <- c(levels(data[,30]),'CG')

then, if the problem only occurs in one column it's an easy fix.

 > tmp[data=='GC'] <- 'CG'

If GC occurs in multiple columns you'll either have to change the levels 
for each column as I did just above, or work with a single column. 
Since you don't have 30 columns in your example, let's pretend you want 
to change all the instances of 'CC' in data$V5 to 'XX'

 > tmp <- data
 > levels(tmp$V5) <- c(levels(data$V5),'XX')
 > tmp$V5[data$V5=='CC'] <- 'XX'
 > tmp
    V4 V5 V6 V7   V8   V9 V10
1  TT GG TT AC   AG   AG  TT
2  AT XX TT AA   AA   AA  TT
3  AT XX TT AC   AA <NA>  TT
4  TT XX TT AA   AA   AA  TT
5  AT CG TT CC   AA   AA  TT
6  TT XX TT AA   AA   AA  TT
7  AT XX TT CC <NA> <NA>  TT
8  TT XX TT AC   AG   AG  TT
9  AT XX TT CC   AG <NA>  TT
10 TT XX TT CC   GG   GG  TT

Notice that the instances of 'CC' in tmp$V7 did not change.

HTH, Dave Roberts

Federico Calboli wrote:
> Hi All,
> 
> I have the following problem, that's driving me mad.
> 
> I have a dataframe of factors, from a genetic scan of SNPs. I DO have
> NAs in the dataframe, which would look like:
> 
>    V4 V5 V6 V7   V8   V9 V10
> 1  TT GG TT AC   AG   AG  TT
> 2  AT CC TT AA   AA   AA  TT
> 3  AT CC TT AC   AA <NA>  TT
> 4  TT CC TT AA   AA   AA  TT
> 5  AT CG TT CC   AA   AA  TT
> 6  TT CC TT AA   AA   AA  TT
> 7  AT CC TT CC <NA> <NA>  TT
> 8  TT CC TT AC   AG   AG  TT
> 9  AT CC TT CC   AG <NA>  TT
> 10 TT CC TT CC   GG   GG  TT
> 
> 
> In the dataframe I have 1 column where one factor has been erroneosly
> given alternative readings: CG and GC. 
> 
> I want to change the instances of GC to CG and I use the code:
> 
> data[data[,30]=="GC", 30] = "CG"
> 
> but get the error:
> Error in "[<-.data.frame"(`*tmp*`, all[, 30] == "GC", 30
>         missing values are not allowed in subscripted as
> 
> Any hints?
> 
> Cheers,
> 
> Federico
> 


-- 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
David W. Roberts                                     office 406-994-4548
Professor and Head                                      FAX 406-994-3190
Department of Ecology                         email droberts at montana.edu
Montana State University
Bozeman, MT 59717-3460



From florent.baty at unibas.ch  Fri Oct 28 18:01:14 2005
From: florent.baty at unibas.ch (Florent Baty)
Date: Fri, 28 Oct 2005 18:01:14 +0200
Subject: [R] Calling R functions from C
Message-ID: <43624B4A.5020107@unibas.ch>

Dear R users,

I read on the "Introduction to the .C Interface to R" by Peng & Leeuw 
(http://www.biostat.jhsph.edu/~rpeng/docs/interface.pdf) that it is 
possible to use a few R functions (such as "dnorm") within C by 
including the "Rmath.h" header file in your C code:
e.g.

#include <R.h>
#include <Rmath.h>
void kernel_smooth(double *x, int *n, double *xpts, int *nxpts,
double *h, double *result)
{
int i, j;
double d, ksum;
for(i=0; i < *nxpts; i++) {
ksum = 0;
for(j=0; j < *n; j++) {
d = xpts[i] - x[j];
ksum += dnorm(d / *h, 0, 1, 0);
}
result[i] = ksum / ((*n) * (*h));
}
}


In the manual "Writing R extensions" there is also a list of special 
functions which can be called in C.

I was wondering whether there is a way to call any other R functions 
similarly. Is there any documented exemple available somewhere?

Thanks a lot for your help,

Florent



From redbeard at arrr.net  Fri Oct 28 19:05:39 2005
From: redbeard at arrr.net (Jarrett Byrnes)
Date: Fri, 28 Oct 2005 10:05:39 -0700
Subject: [R] lm type of sums of squares
In-Reply-To: <43624B4A.5020107@unibas.ch>
References: <43624B4A.5020107@unibas.ch>
Message-ID: <3d4d412bc8dbe9aad20d766bdfa0e9ae@arrr.net>

I'm curious, I realize there are methods for Type II and III sums of 
squares, and yet, when I've been constructing models with lm, I've 
noticed that position of the term of the model has not mattered in 
terms of its p-value.  Does lm use sequential Type I sums of squares, 
or something else?

Thanks!

-Jarrett



From jfox at mcmaster.ca  Fri Oct 28 19:25:38 2005
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 28 Oct 2005 13:25:38 -0400
Subject: [R] lm type of sums of squares
In-Reply-To: <3d4d412bc8dbe9aad20d766bdfa0e9ae@arrr.net>
Message-ID: <web-108017079@cgpsrv2.cis.mcmaster.ca>

Dear Jarrett,

anova() gives sequential sums of squares (as ?anova.lm says). See
Anova() in the car package for something similar to Type II and III
sums of squares.

I hope this helps,
 John

On Fri, 28 Oct 2005 10:05:39 -0700
 Jarrett Byrnes <redbeard at arrr.net> wrote:
> I'm curious, I realize there are methods for Type II and III sums of 
> squares, and yet, when I've been constructing models with lm, I've 
> noticed that position of the term of the model has not mattered in 
> terms of its p-value.  Does lm use sequential Type I sums of squares,
> 
> or something else?
> 
> Thanks!
> 
> -Jarrett
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/



From andy_liaw at merck.com  Fri Oct 28 19:25:18 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 28 Oct 2005 13:25:18 -0400
Subject: [R] lm type of sums of squares
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED53C@usctmx1106.merck.com>

anova.lm() gives the sequential tests:

> set.seed(1)
> dat <- data.frame(y=rnorm(10), x1=runif(10), x2=runif(10))
> anova(lm(y ~ x1 + x2, dat))
Analysis of Variance Table

Response: y
          Df Sum Sq Mean Sq F value Pr(>F)
x1         1 1.1483  1.1483  2.0943 0.1911
x2         1 0.4972  0.4972  0.9068 0.3727
Residuals  7 3.8383  0.5483               
> anova(lm(y ~ x2 + x1, dat))
Analysis of Variance Table

Response: y
          Df Sum Sq Mean Sq F value Pr(>F)
x2         1 0.5165  0.5165  0.9419 0.3641
x1         1 1.1291  1.1291  2.0592 0.1944
Residuals  7 3.8383  0.5483               

The SS, F-stat, etc. would be invariant to order only if the terms are
orthogonal.


Andy


> From: Jarrett Byrnes
> 
> I'm curious, I realize there are methods for Type II and III sums of 
> squares, and yet, when I've been constructing models with lm, I've 
> noticed that position of the term of the model has not mattered in 
> terms of its p-value.  Does lm use sequential Type I sums of squares, 
> or something else?
> 
> Thanks!
> 
> -Jarrett
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From nali at umn.edu  Fri Oct 28 19:18:13 2005
From: nali at umn.edu (Na Li)
Date: Fri, 28 Oct 2005 12:18:13 -0500
Subject: [R] splitting a character field in R
References: <OFC403C20F.59A2A469-ONC12570A8.00504977-C12570A8.00506FB3@notes.fresenius.de>
Message-ID: <gipspplfvu.fsf@bass.biostat.umn.edu>

On 28 Oct 2005, ManuelPerera-Chang at fmc-ag.com wrote:

> A<-c(1,2,3)
> B<-c("dgabcrt","fgrtabc","sabcuuu")
> C<-strsplit(B,"abc")
> > C
> [[1]]
> [1] "dg" "rt"
> 
> [[2]]
> [1] "fgrt"
> 
> [[3]]
> [1] "s"   "uuu"
> 
> Which looks promissing, but here C is a list with three elements. But how
> to create the two vectors I need from here, that is
> 
> ("dg","fgrt", "s") and ("rt","","uuu")

To convert a list to a matrix

> do.call ("rbind", C)
     [,1]   [,2]  
[1,] "dg"   "rt"  
[2,] "fgrt" "fgrt"
[3,] "s"    "uuu" 

is good trick.  However, it doesn't work as intended here since the elements
of C have difference lengths.  It would be nice to have 'rbind' and 'cbind'
allow different ways of padding the vectors into the same length.

One work around is:

> sapply (C, function (x) x[1:2])
     [,1] [,2]   [,3] 
[1,] "dg" "fgrt" "s"  
[2,] "rt" NA     "uuu"

You may convert the NA's to "" if you want.

Michael



From jeff.breiwick at noaa.gov  Fri Oct 28 19:26:08 2005
From: jeff.breiwick at noaa.gov (J.M. Breiwick)
Date: Fri, 28 Oct 2005 10:26:08 -0700
Subject: [R] multiple boxplots
Message-ID: <djtmvh$oh4$1@sea.gmane.org>

Hello,

I want to plot 3 boxplots [ par(mfrow=c(3,1)) ] but the first one has 8 
groups, the 2nd has 7 and the third has 6. But I the groups to line up:

 1 2 3 4 5 6 7 8
   2 3 4 5 6 7 8
      3 4 5 6 7 8

where the numbers actually refer to years. I suspect I have to manipulate 
the function bxp(). Is there a relatively simple way to do this? Thanks for 
any help.

Jeff Breiwick
NMFS, Seattle



From mschwartz at mn.rr.com  Fri Oct 28 20:12:07 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Fri, 28 Oct 2005 13:12:07 -0500
Subject: [R] multiple boxplots
In-Reply-To: <djtmvh$oh4$1@sea.gmane.org>
References: <djtmvh$oh4$1@sea.gmane.org>
Message-ID: <1130523127.4557.45.camel@localhost.localdomain>

On Fri, 2005-10-28 at 10:26 -0700, J.M. Breiwick wrote:
> Hello,
> 
> I want to plot 3 boxplots [ par(mfrow=c(3,1)) ] but the first one has 8 
> groups, the 2nd has 7 and the third has 6. But I the groups to line up:
> 
>  1 2 3 4 5 6 7 8
>    2 3 4 5 6 7 8
>       3 4 5 6 7 8
> 
> where the numbers actually refer to years. I suspect I have to manipulate 
> the function bxp(). Is there a relatively simple way to do this? Thanks for 
> any help.
> 
> Jeff Breiwick
> NMFS, Seattle


Here is one approach. It is based upon using 2 principal concepts:

1. Create the first plot, save the plot region ranges from par("usr")
and then use this information for the two subsequent plots, where we use
the 'add = TRUE' argument.

2. Use the 'at' argument to specify the placement of the boxes in the
second and third plots to line up with the first.


So:

# Create our data.
dat <- rnorm(80)
years <- rep(1991:1998, each = 10)

# MyDF will be a data frame with two columns and we will use 
# this in the formula method for boxplot.
# The second and third plots will use subset()s of MyDF
MyDF <- cbind(dat, years)

# Set the plot matrix
par(mfrow = c(3, 1))

# Create the first boxplot and save par("usr")
boxplot(dat ~ years, MyDF)
usr <- par("usr")

# Now open a new plot, setting it's par("usr") to 
# match the first plot.
# Then use boxplot and set the boxes 'at' x pos 2:8
# and add it to the open plot
plot.new()
par(usr = usr)
boxplot(dat ~ years, subset(MyDF, years %in% 1992:1998),
        at = 2:8, add = TRUE)


# Rinse and repeat  ;-)
# Different subset and use 3:8 for 'at'
plot.new()
par(usr = usr)
boxplot(dat ~ years, subset(MyDF, years %in% 1993:1998),
        at = 3:8, add = TRUE)



Replace MyDF in the above with your actual datasets of course.

This would of course be a bit easier if one could set an 'xlim' argument
in boxplot(), but this is ignored by bxp().

HTH,

Marc Schwartz



From br44114 at gmail.com  Fri Oct 28 22:23:45 2005
From: br44114 at gmail.com (bogdan romocea)
Date: Fri, 28 Oct 2005 16:23:45 -0400
Subject: [R] clustering
Message-ID: <8d5a36350510281323s361ead5ch8c2a511fec19fdfb@mail.gmail.com>

Assuming you don't end up with too many clusters, you could take the
classification and use it as the target for a tree, random forest,
discriminant analysis or multinomial logistic regression. The random
forest may be the best option.


> -----Original Message-----
> From: alessandro carletti [mailto:alxmilton at yahoo.it]
> Sent: Friday, October 28, 2005 5:42 AM
> To: rHELP
> Subject: [R] clustering
>
>
> Hi everybody,
> I'm performing a cluster analysis (pkg "cluster") on a
> dataset which includes 15 variables: is there a way to
> know how much each variable weighs on the final
> clustering output?
> Thanks
>
> Alessandro
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From gerifalte28 at hotmail.com  Fri Oct 28 22:39:51 2005
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Fri, 28 Oct 2005 20:39:51 +0000
Subject: [R] question about sm.density
In-Reply-To: <20051028014728.20086.qmail@web51815.mail.yahoo.com>
Message-ID: <BAY103-F119B4289275F7125277D41A66B0@phx.gbl>

Please read the documentation before posting a question.  If you read the 
documentation for sm.density you will see that the argument props will do 
what you want. i.e.

y <- cbind(rnorm(50), rnorm(50))
sm.density(y, display = "slice", props=95)

Regards

Francisco

>From: Cunningham Kerry <kerryrekky at yahoo.com>
>To: r-help at stat.math.ethz.ch
>Subject: [R] question about sm.density
>Date: Thu, 27 Oct 2005 18:47:28 -0700 (PDT)
>
>How can I draw a 95% contour in sm.density?
>
>For example,
>
>y <- cbind(rnorm(50), rnorm(50))
>      sm.density(y, display = "slice")
>
>will give 25%, 50% and 75% contours automatically, but
>no reference on other values.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From francoisromain at free.fr  Fri Oct 28 23:18:24 2005
From: francoisromain at free.fr (Romain Francois)
Date: Fri, 28 Oct 2005 23:18:24 +0200
Subject: [R] 3d bar plot
In-Reply-To: <web-15526852@tuebingen.mpg.de>
References: <web-15526852@tuebingen.mpg.de>
Message-ID: <436295A0.4060208@free.fr>

Le 28.10.2005 10:07, Jan Wiener a ??crit :

>Hi,
>
>does anyone has a bar plot function that produces something
>like this (I hope attachments work) ?
>
>If not, I simply want to produce 3d bar plots.
>
>Thanks in advance,
>Jan
>  
>
Hi,

I didn't get the attachment. Maybe you didn't follow the posting guide 
which tells what attachments are ok.

scatterplot3d can generate somthing close to a 3D barplot.
see :
 http://www.jstatsoft.org/v08/i11/JSSs3d.pdf   page 11
 http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=116

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+



From tplate at acm.org  Fri Oct 28 23:13:52 2005
From: tplate at acm.org (Tony Plate)
Date: Fri, 28 Oct 2005 15:13:52 -0600
Subject: [R] unvectorized option for outer()
In-Reply-To: <8B08A3A1EA7AAC41BE24C750338754E69FDF14@HERMES.demogr.mpg.de>
References: <8B08A3A1EA7AAC41BE24C750338754E69FDF14@HERMES.demogr.mpg.de>
Message-ID: <43629490.9060204@acm.org>

[following on from a thread on R-help, but my post here seems more 
appropriate to R-devel]

Would a patch to make outer() work with non-vectorized functions be
considered?  It seems to come up moderately often on the list, which
probably indicates that many many people get bitten by the same
incorrect expectation, despite the documentation and the FAQ entry.  It
looks pretty simple to modify outer() appropriately: one extra function
argument and an if-then-else clause to call mapply(FUN, ...) instead of
calling FUN directly.

Here's a function demonstrating this:

outer2 <- function (X, Y, FUN = "*", ..., VECTORIZED=TRUE)
{
     no.nx <- is.null(nx <- dimnames(X <- as.array(X)))
     dX <- dim(X)
     no.ny <- is.null(ny <- dimnames(Y <- as.array(Y)))
     dY <- dim(Y)
     if (is.character(FUN) && FUN == "*") {
         robj <- as.vector(X) %*% t(as.vector(Y))
         dim(robj) <- c(dX, dY)
     }
     else {
         FUN <- match.fun(FUN)
         Y <- rep(Y, rep.int(length(X), length(Y)))
         if (length(X) > 0)
             X <- rep(X, times = ceiling(length(Y)/length(X)))
         if (VECTORIZED)
             robj <- FUN(X, Y, ...)
         else
             robj <- mapply(FUN, X, Y, MoreArgs=list(...))
         dim(robj) <- c(dX, dY)
     }
     if (no.nx)
         nx <- vector("list", length(dX))
     else if (no.ny)
         ny <- vector("list", length(dY))
     if (!(no.nx && no.ny))
         dimnames(robj) <- c(nx, ny)
     robj
}
# Some examples
f <- function(x, y, p=1) {cat("in f\n"); (x*y)^p}
outer2(1:2, 3:5, f, 2)
outer2(numeric(0), 3:5, f, 2)
outer2(1:2, numeric(0), f, 2)
outer2(1:2, 3:5, f, 2, VECTORIZED=F)
outer2(numeric(0), 3:5, f, 2, VECTORIZED=F)
outer2(1:2, numeric(0), f, 2, VECTORIZED=F)

# Output on examples
> f <- function(x, y, p=1) {cat("in f\n"); (x*y)^p}
> outer2(1:2, 3:5, f, 2)
in f
      [,1] [,2] [,3]
[1,]    9   16   25
[2,]   36   64  100
> outer2(numeric(0), 3:5, f, 2)
in f
      [,1] [,2] [,3]
> outer2(1:2, numeric(0), f, 2)
in f

[1,]
[2,]
> outer2(1:2, 3:5, f, 2, VECTORIZED=F)
in f
in f
in f
in f
in f
in f
      [,1] [,2] [,3]
[1,]    9   16   25
[2,]   36   64  100
> outer2(numeric(0), 3:5, f, 2, VECTORIZED=F)
      [,1] [,2] [,3]
> outer2(1:2, numeric(0), f, 2, VECTORIZED=F)

[1,]
[2,]
>

If a patch to add this feature would be considered, I'd be happy to
submit one (including documentation).  If so, and if there are any
potential traps I should bear in mind, please let me know!

-- Tony Plate

Rau, Roland wrote:
> Dear all,
> 
> a big thanks to Thomas Lumley, James Holtman and Tony Plate for their
> answers. They all pointed in the same direction => I need a vectorized
> function to be applied. Hence, I will try to work with a 'wrapper'
> function as described in the FAQ.
> 
> Thanks again,
> Roland
> 
> 
> 
>>-----Original Message-----
>>From: Thomas Lumley [mailto:tlumley at u.washington.edu] 
>>Sent: Thursday, October 27, 2005 11:39 PM
>>To: Rau, Roland
>>Cc: r-help at stat.math.ethz.ch
>>Subject: Re: [R] outer-question
>>
>>
>>You want FAQ 7.17 Why does outer() behave strangely with my function?
>>
>> 	-thomas
>>
>>On Thu, 27 Oct 2005, Rau, Roland wrote:
>>
>>
>>>Dear all,
>>>
>>>This is a rather lengthy message, but I don't know what I 
>>
>>made wrong in
>>
>>>my real example since the simple code works.
>>>I have two variables a, b and a function f for which I would like to
>>>calculate all possible combinations of the values of a and b.
>>>If f is multiplication, I would simply do:
>>>
>>>a <- 1:5
>>>b <- 1:5
>>>outer(a,b)
>>>
>>>## A bit more complicated is this:
>>>f <- function(a,b,d) {
>>>	return(a*b+(sum(d)))
>>>}
>>>additional <- runif(100)
>>>outer(X=a, Y=b, FUN=f, d=additional)
>>>
>>>## So far so good. But now my real example. I would like to plot the
>>>## log-likelihood surface for two parameters alpha and beta of
>>>## a Gompertz distribution with given data
>>>
>>>### I have a function to generate random-numbers from a
>>>Gompertz-Distribution
>>>### (using the 'inversion method')
>>>
>>>random.gomp <- function(n, alpha, beta) {
>>>           return( (log(1-(beta/alpha*log(1-runif(n)))))/beta)
>>>}
>>>
>>>## Now I generate some 'lifetimes'
>>>no.people <- 1000
>>>al <- 0.1
>>>bet <- 0.1
>>>lifetimes <- random.gomp(n=no.people, alpha=al, beta=bet)
>>>
>>>### Since I neither have censoring nor truncation in this 
>>
>>simple case,
>>
>>>### the log-likelihood should be simply the sum of the log of the
>>>### the densities (following the parametrization of 
>>
>>Klein/Moeschberger
>>
>>>### Survival Analysis, p. 38)
>>>
>>>loggomp <- function(alphas, betas, timep) {
>>> return(sum(log(alphas) + betas*timep + (alphas/betas *
>>>(1-exp(betas*timep)))))
>>>}
>>>
>>>### Now I thought I could obtain a matrix of the 
>>
>>log-likelihood surface
>>
>>>### by specifying possible values for alpha and beta with the given
>>>data.
>>>### I was able to produce this matrix with two for-loops. 
>>
>>But I thought
>>
>>>### I could use also 'outer' in this case.
>>>### This is what I tried:
>>>
>>>possible.alphas <- seq(from=0.05, to=0.15, length=30)
>>>possible.betas <- seq(from=0.05, to=0.15, length=30)
>>>
>>>outer(X=possible.alphas, Y=possible.betas, FUN=loggomp, 
>>
>>timep=lifetimes)
>>
>>>### But the result is:
>>>
>>>>outer(X=possible.alphas, Y=possible.betas, FUN=loggomp,
>>>
>>>timep=lifetimes)
>>>Error in outer(X = possible.alphas, Y = possible.betas, FUN 
>>
>>= loggomp,
>>
>>>:
>>>       dim<- : dims [product 900] do not match the length 
>>
>>of object [1]
>>
>>>In addition: Warning messages:
>>>...
>>>
>>>### Can somebody give me some hint where the problem is?
>>>### I checked my definition of 'loggomp' but I thought this 
>>
>>looks fine:
>>
>>>loggomp(alphas=possible.alphas[1], betas=possible.betas[1],
>>>timep=lifetimes)
>>>loggomp(alphas=possible.alphas[4], betas=possible.betas[10],
>>>timep=lifetimes)
>>>loggomp(alphas=possible.alphas[3], betas=possible.betas[11],
>>>timep=lifetimes)
>>>
>>>
>>>### I'd appreciate any kind of advice.
>>>### Thanks a lot in advance.
>>>### Roland
>>>
>>>
>>>+++++
>>>This mail has been sent through the MPI for Demographic 
>>
>>Rese...{{dropped}}
>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! 
>>
>>http://www.R-project.org/posting-guide.html
>>
>>Thomas Lumley			Assoc. Professor, Biostatistics
>>tlumley at u.washington.edu	University of Washington, Seattle
>>
> 
> 
> +++++
> This mail has been sent through the MPI for Demographic Research.  Should you receive a mail that is apparently from a MPI user without this text displayed, then the address has most likely been faked. If you are uncertain about the validity of this message, please check the mail header or ask your system administrator for assistance.
> 
>



From tplate at acm.org  Sat Oct 29 01:26:12 2005
From: tplate at acm.org (Tony Plate)
Date: Fri, 28 Oct 2005 17:26:12 -0600
Subject: [R] unvectorized option for outer()
In-Reply-To: <43629490.9060204@acm.org>
References: <8B08A3A1EA7AAC41BE24C750338754E69FDF14@HERMES.demogr.mpg.de>
	<43629490.9060204@acm.org>
Message-ID: <4362B394.30102@acm.org>

Apologies for the cross post.  I explicitly tried to avoid this but 
somehow r-help got tacked onto the end of the To: line without my 
realizing it.

-- Tony Plate

Tony Plate wrote:
> [following on from a thread on R-help, but my post here seems more 
> appropriate to R-devel]
> 
...



From leog at anicca-vijja.de  Sat Oct 29 02:45:08 2005
From: leog at anicca-vijja.de (=?ISO-8859-1?Q?Leo_G=FCrtler?=)
Date: Sat, 29 Oct 2005 02:45:08 +0200
Subject: [R] how to get colnames of a dataframe within a function called by
	'apply'
Message-ID: <4362C614.5060203@anicca-vijja.de>

Hello alltogether,

how is it possible to assign the colnames of a data.frame to a function 
called by apply, e.g. for labeling a plot?
Example: I want to plot several qqnorm-plots side by side and there 
should be a maintitle for each qqnorm-plot which is identical to the 
respective colname.
I checked, but the column which is processed by the function called by 
apply does not contain a colname (because by using str() it seems it is 
no column at this point, but just a e.g. numerical vector).
I also tried with colnames() from within the function, but was not 
successful to get the apropriate colname - either the whole string or 
just the first one.Thus it lacks of a counter that contains the number 
of the row which is processed.

Here is an example code:

<---snip--->

nv <- function(xno.na)
{
  par.or <- par(mfrow=c(3,3))
  qqnorm(xno.na, main="HERE SHOULD BE THE NAME OF THE COLUMN")
  qqline(xno.na, col="red")
  par(par.or)
  print(str(xno.na))
}

 > temp # just a part of the whole data.frame
        klarb1    klarb2 abarb laut skla1 skla2
a      NA 13.068182   7.5    4   0.5   0.5
b      NA  6.818182   9.0    6    NA   0.5
c      15.11628  6.818182  10.0    4   1.0   1.5
d      NA 18.181818  19.0    2   1.0   0.5

 > apply(temp,2,nv)

</---snip--->


Thanks a lot!

best wishes,

leo



From ggrothendieck at gmail.com  Sat Oct 29 04:25:23 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 28 Oct 2005 22:25:23 -0400
Subject: [R] how to get colnames of a dataframe within a function called
	by 'apply'
In-Reply-To: <4362C614.5060203@anicca-vijja.de>
References: <4362C614.5060203@anicca-vijja.de>
Message-ID: <971536df0510281925r3e3030d2s7453963f5acfee2f@mail.gmail.com>

Iterate over the column names rather than the columns themselves:

par.or <- par(mfrow=c(3,3))
nv <- function(name, data) {
	qqnorm(data[,name], main=name)
	qqline(data[,name], col="red")
	invisible()
}
sapply(colnames(temp), nv, data = temp)
par(par.or)


On 10/28/05, Leo G??rtler <leog at anicca-vijja.de> wrote:
> Hello alltogether,
>
> how is it possible to assign the colnames of a data.frame to a function
> called by apply, e.g. for labeling a plot?
> Example: I want to plot several qqnorm-plots side by side and there
> should be a maintitle for each qqnorm-plot which is identical to the
> respective colname.
> I checked, but the column which is processed by the function called by
> apply does not contain a colname (because by using str() it seems it is
> no column at this point, but just a e.g. numerical vector).
> I also tried with colnames() from within the function, but was not
> successful to get the apropriate colname - either the whole string or
> just the first one.Thus it lacks of a counter that contains the number
> of the row which is processed.
>
> Here is an example code:
>
> <---snip--->
>
> nv <- function(xno.na)
> {
>  par.or <- par(mfrow=c(3,3))
>  qqnorm(xno.na, main="HERE SHOULD BE THE NAME OF THE COLUMN")
>  qqline(xno.na, col="red")
>  par(par.or)
>  print(str(xno.na))
> }
>
>  > temp # just a part of the whole data.frame
>        klarb1    klarb2 abarb laut skla1 skla2
> a      NA 13.068182   7.5    4   0.5   0.5
> b      NA  6.818182   9.0    6    NA   0.5
> c      15.11628  6.818182  10.0    4   1.0   1.5
> d      NA 18.181818  19.0    2   1.0   0.5
>
>  > apply(temp,2,nv)
>
> </---snip--->
>
>
> Thanks a lot!
>
> best wishes,
>
> leo
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From patrick.giraudoux at univ-fcomte.fr  Sat Oct 29 09:36:23 2005
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sat, 29 Oct 2005 09:36:23 +0200
Subject: [R] LaTex error when creating DVI version when compiling package
Message-ID: <43632677.9030208@univ-fcomte.fr>

Dear Listers,

I got this message when compiling a package:

* creating pgirmess-manual.tex ... OK
* checking pgirmess-manual.text ... ERROR
LaTex errors when creating DVI version.
This typically indicates Rd problems.

The message is quite explicit but I struggled a lot before understanding 
that the trouble comes from a single file "selMod.rd" among 44 topics. 
Even though I have checked it ten times and even rewrite it on 
prompt(selMod), I cannot find out what is wrong with it.

Can somebody used with LaTex and the format of R *.rd file have a quick 
look to the attached contents and tell me if he can detect some obvious 
faulty writing?

Thanks in advance,

Patrick



\name{selMod}
\alias{selMod}
\alias{selMod.lm}
\alias{selMod.glm}
\alias{selMod.list}

\title{ Model selection according to information theoretic methods }
\description{
 Handles lm, glm and list of models lm, glm, lme and nlme objects and 
provides parameters to compare models according to Anderson et al. (1998)
}
\usage{
    selMod(aModel, Order = "AICc", ...) group method

    selMod.lm(aModel, Order = "AICc", dropNull = FALSE, selconv=TRUE, ...)
    selMod.list(aModel, Order = "AICc", ...)
}

\arguments{
  \item{aModel}{ a lm or glm model or a list of lm or glm models }
  \item{dropNull}{ if TRUE, drops the simplest model (e.g. 'y~1')  }
  \item{Order}{ if set to "AICc" (default) sort the models on this 
parameter, otherwise "AIC" is allowed }
  \item{selconv}{ if TRUE (default) keep the models for which 
convergence is obtained (glm object only) and with no anova singularity 
(lm and glm) }
  \item{...}{ other parameters to be passed as arguments (not used here) }
}

\details{
  This function provides parameters used in the information theoretic 
methods for model comparisons. lm and glm objects can be passed directly 
as the upper scope of term addition (all terms added).
  Every model from 'y~1' is computed adding one term at a time until the 
upper scope model is derived. A list of user specified lm, glm, lme or 
nlme objects can alternately be passed.
}

\value{
 A list with the following items:
  \item{AIC}{a data.frame including LL, the maximized log-likelihood; K 
the number of estimated parameters; N2K, number of observations/K; AIC, 
the Akaike index criterion; deltAIC, the difference between AIC and the 
lowest AIC value; w_i, the Akaike weights; AICc, the second order Akaike 
criterion; deltAICc, the difference between AICc and the lowest AICc 
value; w_ic, the AICc weights }
  \item{models}{the list of models}
}
\references{
    Anderson, D.R., Link, W.A., Johnson, D.H. and Burnham, K.P. (2001). 
Suggestions for presenting the results of data analyses. Journal of 
Wildlife Management, 65, 373-378; Burnham, K.P. and Anderson, D.R. 
(2002) Model Selection and Multimodel Inference: a Practical 
Information-Theoretic Approach, 2nd edn., Springer-Verlag, New York. 353 pp
 }
\author{ Patrick Giraudoux and David Pleydell: pgiraudo at univ-fcomte.fr, 
dpleydel at univ-fcomte.fr }

\seealso{ \code{\link{AIC}},\code{\link{logLik}} }
\examples{
 library(MASS)
 anorex.1 <- lm(Postwt ~ Prewt*Treat, data = anorexia)
 selMod(anorex.1)
 anorex.2 <- glm(Postwt ~ Prewt*Treat, family=gaussian,data = anorexia)
 selMod(anorex.2)
 anorex.3<-lm(Postwt ~ Prewt+Treat, data = anorexia)
 selMod(list(anorex.1,anorex.2,anorex.3))
}
\keyword{ models }



From Roger.Bivand at nhh.no  Sat Oct 29 10:45:44 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 29 Oct 2005 10:45:44 +0200 (CEST)
Subject: [R] LaTex error when creating DVI version when compiling package
In-Reply-To: <43632677.9030208@univ-fcomte.fr>
Message-ID: <Pine.LNX.4.44.0510291039400.5805-100000@reclus.nhh.no>

On Sat, 29 Oct 2005, Patrick Giraudoux wrote:

> Dear Listers,
> 
> I got this message when compiling a package:
> 
> * creating pgirmess-manual.tex ... OK
> * checking pgirmess-manual.text ... ERROR
> LaTex errors when creating DVI version.
> This typically indicates Rd problems.
> 
> The message is quite explicit but I struggled a lot before understanding 
> that the trouble comes from a single file "selMod.rd" among 44 topics. 
> Even though I have checked it ten times and even rewrite it on 
> prompt(selMod), I cannot find out what is wrong with it.
> 
> Can somebody used with LaTex and the format of R *.rd file have a quick 
> look to the attached contents and tell me if he can detect some obvious 
> faulty writing?

The general answer is to look through the (often very long) *.log file in 
the *.Rcheck directory until you find the problem. That will typically 
give you a line number in the *.tex file, which shows not only where the 
error occurred, but the *.log file entry often shows what it is. My 
typical errors are using LaTeX special symbols, and most often having 
unprotected $ and _. I see quite a lot of _ below in \value{}, so I'd try 
\_ there first.

Roger


> 
> Thanks in advance,
> 
> Patrick
> 
> 
> 
> \name{selMod}
> \alias{selMod}
> \alias{selMod.lm}
> \alias{selMod.glm}
> \alias{selMod.list}
> 
> \title{ Model selection according to information theoretic methods }
> \description{
>  Handles lm, glm and list of models lm, glm, lme and nlme objects and 
> provides parameters to compare models according to Anderson et al. (1998)
> }
> \usage{
>     selMod(aModel, Order = "AICc", ...) group method
> 
>     selMod.lm(aModel, Order = "AICc", dropNull = FALSE, selconv=TRUE, ...)
>     selMod.list(aModel, Order = "AICc", ...)
> }
> 
> \arguments{
>   \item{aModel}{ a lm or glm model or a list of lm or glm models }
>   \item{dropNull}{ if TRUE, drops the simplest model (e.g. 'y~1')  }
>   \item{Order}{ if set to "AICc" (default) sort the models on this 
> parameter, otherwise "AIC" is allowed }
>   \item{selconv}{ if TRUE (default) keep the models for which 
> convergence is obtained (glm object only) and with no anova singularity 
> (lm and glm) }
>   \item{...}{ other parameters to be passed as arguments (not used here) }
> }
> 
> \details{
>   This function provides parameters used in the information theoretic 
> methods for model comparisons. lm and glm objects can be passed directly 
> as the upper scope of term addition (all terms added).
>   Every model from 'y~1' is computed adding one term at a time until the 
> upper scope model is derived. A list of user specified lm, glm, lme or 
> nlme objects can alternately be passed.
> }
> 
> \value{
>  A list with the following items:
>   \item{AIC}{a data.frame including LL, the maximized log-likelihood; K 
> the number of estimated parameters; N2K, number of observations/K; AIC, 
> the Akaike index criterion; deltAIC, the difference between AIC and the 
> lowest AIC value; w_i, the Akaike weights; AICc, the second order Akaike 
> criterion; deltAICc, the difference between AICc and the lowest AICc 
> value; w_ic, the AICc weights }
>   \item{models}{the list of models}
> }
> \references{
>     Anderson, D.R., Link, W.A., Johnson, D.H. and Burnham, K.P. (2001). 
> Suggestions for presenting the results of data analyses. Journal of 
> Wildlife Management, 65, 373-378; Burnham, K.P. and Anderson, D.R. 
> (2002) Model Selection and Multimodel Inference: a Practical 
> Information-Theoretic Approach, 2nd edn., Springer-Verlag, New York. 353 pp
>  }
> \author{ Patrick Giraudoux and David Pleydell: pgiraudo at univ-fcomte.fr, 
> dpleydel at univ-fcomte.fr }
> 
> \seealso{ \code{\link{AIC}},\code{\link{logLik}} }
> \examples{
>  library(MASS)
>  anorex.1 <- lm(Postwt ~ Prewt*Treat, data = anorexia)
>  selMod(anorex.1)
>  anorex.2 <- glm(Postwt ~ Prewt*Treat, family=gaussian,data = anorexia)
>  selMod(anorex.2)
>  anorex.3<-lm(Postwt ~ Prewt+Treat, data = anorexia)
>  selMod(list(anorex.1,anorex.2,anorex.3))
> }
> \keyword{ models }
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From patrick.giraudoux at univ-fcomte.fr  Sat Oct 29 11:03:55 2005
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sat, 29 Oct 2005 11:03:55 +0200
Subject: [R] LaTex error when creating DVI version when compiling package
In-Reply-To: <17251.12173.426972.633185@bossiaea.maths.uwa.edu.au>
References: <43632677.9030208@univ-fcomte.fr>
	<17251.12173.426972.633185@bossiaea.maths.uwa.edu.au>
Message-ID: <43633AFB.9030105@univ-fcomte.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051029/cfb0969b/attachment.pl

From tmlammail at yahoo.com  Sat Oct 29 12:03:13 2005
From: tmlammail at yahoo.com (Martin Lam)
Date: Sat, 29 Oct 2005 03:03:13 -0700 (PDT)
Subject: [R]  How to print output during for loops?
Message-ID: <20051029100313.48427.qmail@web34711.mail.mud.yahoo.com>

Hi,

I was wondering, if it is possible to print out the
values of variables while you are in a for/while loop?
Like this for example:
  
for (i in 1:5) {
  i
}

So what I want is this as output in the console:
>1
>2
>3
>4
>5

Thanks in advance,

Martin



From bitwrit at ozemail.com.au  Sat Oct 29 23:16:43 2005
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Sat, 29 Oct 2005 21:16:43 +0000
Subject: [R] line vector plots
In-Reply-To: <436203A5.6050100@usb.ve>
References: <436203A5.6050100@usb.ve>
Message-ID: <4363E6BB.2020503@ozemail.com.au>

Eduardo Klein wrote:
> Hi,
> 
> I'm looking for the way to make vector plot over a time line. This plot, 
> similar to the "feather plot" in Matlab, is a line in which every thick 
> (a time value) one vector is drawn with its length proportional to one 
> variable (wind speed, for example) and its direction to another (wind 
> direction, for example). Any ideas?
> 
Hi Eduardo,

You may be interested in "polar.plot" or "clock24.plot" in the plotrix 
package.

Jim



From 042045003 at fudan.edu.cn  Sat Oct 29 13:16:30 2005
From: 042045003 at fudan.edu.cn (ronggui)
Date: Sat, 29 Oct 2005 19:16:30 +0800
Subject: [R] How to print output during for loops?
Message-ID: <0IP4006C1C6KZU@mail.fudan.edu.cn>

> for (i in 1:5) {
+ cat(paste(i,"\n"))
+ }
1 
2 
3 
4 
5 
> for (i in 1:5) {
+ print(i)
+ }
[1] 1
[1] 2
[1] 3
[1] 4
[1] 5
	

======= 2005-10-29 18:03:13 ÄúÔÚÀ´ÐÅÖÐÐ´µÀ£º=======

>Hi,
>
>I was wondering, if it is possible to print out the
>values of variables while you are in a for/while loop?
>Like this for example:
>  
>for (i in 1:5) {
>  i
>}
>
>So what I want is this as output in the console:
>>1
>>2
>>3
>>4
>>5
>
>Thanks in advance,
>
>Martin
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

= = = = = = = = = = = = = = = = = = = =
			


 

2005-10-29

------
Deparment of Sociology
Fudan University

My new mail addres is ronggui.huang at gmail.com
Blog:http://sociology.yculblog.com



From walton.green at yale.edu  Sat Oct 29 13:34:32 2005
From: walton.green at yale.edu (Walton A. Green)
Date: Sat, 29 Oct 2005 07:34:32 -0400 (EDT)
Subject: [R] dyn.load() error: bad external relocation length
In-Reply-To: <mailman.9.1130580001.5057.r-help@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.44.0510290650340.19876-100000@argos.its.yale.edu>


R-helpers,

Is there an easy way to call an external (C) program using .C or .Call 
without including the code in a package. I know how to do it using 
system(), but that doesn't seem to be a permanent or portable solution. 
Initially I tried:

.Call('filepath.to.c.function', arg1)

and got this error:

Error in .Call("filepath.to.c.function", "arg1",  : 
	"C" function name not in load table

So read the section on foreign language interfaces in the Writing R 
Extensions manual but when I tried:

dyn.load('filepath.to.c.function')

I got:

Error in dyn.load(x, as.logical(local), as.logical(now)) : 
	unable to load shared library 'filepath.to.c.function':
  dlopen(filepath.to.c.function, 6): bad external relocation length

Do you need to run R_registerRoutines before dyn.load()? I couldn't find 
any mention of this error on the web....

Walton

platform powerpc-apple-darwin7.9.0
arch     powerpc                  
os       darwin7.9.0              
system   powerpc, darwin7.9.0     
status                            
major    2                        
minor    1.1                      
year     2005                     
month    06                       
day      20                       
language R



From duncan at wald.ucdavis.edu  Sat Oct 29 15:49:14 2005
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Sat, 29 Oct 2005 06:49:14 -0700
Subject: [R] dyn.load() error: bad external relocation length
In-Reply-To: <Pine.LNX.4.44.0510290650340.19876-100000@argos.its.yale.edu>
References: <Pine.LNX.4.44.0510290650340.19876-100000@argos.its.yale.edu>
Message-ID: <43637DDA.5060606@wald.ucdavis.edu>

Hi Walton.

.C/.Call are interfaces to _compiled_ C routines in a dynamically
loaded library (DLL or DSO - shared object).  A progra
A program is often created from compiling C code into an executable.
We can call the executable via system, but we cannot access its routines 
via .C/.Call.

So, if you have C code, use R CMD SHLIB to compile it into a loadable
libray and use dyn.load() to load it. Putting the code in the src/ 
directory of a package makes the need to do this less explicit.

But if you want to use system(), again it can be done "portably" in a 
package.
Arrange that the package creates and puts the executable in
the package's installed area.  Arrange that the program is
put in, say, inst/bin within the package and then it will be installed 
into the bin/ directory of the package. Then you can access it with

    system.file("bin", "myProg", package = "myPackageName")

and you can use that in your call to system().

The down side is that you will have to ensure that the program is built
in a portable way. So if you won the C code, it is almost the same thing
as building a DLL and using .C/.Call.

HTH

   D.



Walton A. Green wrote:
> R-helpers,
> 
> Is there an easy way to call an external (C) program using .C or .Call 
> without including the code in a package. I know how to do it using 
> system(), but that doesn't seem to be a permanent or portable solution. 
> Initially I tried:
> 
> .Call('filepath.to.c.function', arg1)
> 
> and got this error:
> 
> Error in .Call("filepath.to.c.function", "arg1",  : 
> 	"C" function name not in load table
> 
> So read the section on foreign language interfaces in the Writing R 
> Extensions manual but when I tried:
> 
> dyn.load('filepath.to.c.function')
> 
> I got:
> 
> Error in dyn.load(x, as.logical(local), as.logical(now)) : 
> 	unable to load shared library 'filepath.to.c.function':
>   dlopen(filepath.to.c.function, 6): bad external relocation length
> 
> Do you need to run R_registerRoutines before dyn.load()? I couldn't find 
> any mention of this error on the web....
> 
> Walton
> 
> platform powerpc-apple-darwin7.9.0
> arch     powerpc                  
> os       darwin7.9.0              
> system   powerpc, darwin7.9.0     
> status                            
> major    2                        
> minor    1.1                      
> year     2005                     
> month    06                       
> day      20                       
> language R
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ggrothendieck at gmail.com  Sat Oct 29 16:30:35 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 29 Oct 2005 10:30:35 -0400
Subject: [R] splitting a character field in R
In-Reply-To: <971536df0510280745o56f47cd1p4da447f5eefc5b4d@mail.gmail.com>
References: <OFC403C20F.59A2A469-ONC12570A8.00504977-C12570A8.00506FB3@notes.fresenius.de>
	<971536df0510280745o56f47cd1p4da447f5eefc5b4d@mail.gmail.com>
Message-ID: <971536df0510290730m6dae562ey3935f53ab6247fd6@mail.gmail.com>

Here is one additional solution:

read.table(textConnection(sub("abc", " ", B)), fill = TRUE)

It also works if there are more than 2 fields.     If there can
be spaces in the lines then the sub should be modified to
translate "abc" to some unique character not appearing in
the lines and sep= should be added to the read.table call.
Also as.is=TRUE can be added to the read.table call if
its desired to return character rather than factor columns
and col.name= can be added to the read.table call if it
is desired to control the naming of the returned columns.

This solution will also work with more than two fields.


On 10/28/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> You could use:
>
> data.frame(First = sub("abc.*", "", B), Second = sub(".*abc", "", B))
>
> or if you want to prevent conversion to factors:
>
> data.frame(First = I(sub("abc.*", "", B)), Second = I(sub(".*abc", "", B)))
>
> On 10/28/05, ManuelPerera-Chang at fmc-ag.com
> <ManuelPerera-Chang at fmc-ag.com> wrote:
> >
> >
> >
> >
> > Hi Jim,
> >
> > Thanks for your post, I was aware of strsplit, but really could not find
> > out how i could use it.
> >
> > I tried like in your example ...
> >
> > A<-c(1,2,3)
> > B<-c("dgabcrt","fgrtabc","sabcuuu")
> > C<-strsplit(B,"abc")
> > > C
> > [[1]]
> > [1] "dg" "rt"
> >
> > [[2]]
> > [1] "fgrt"
> >
> > [[3]]
> > [1] "s"   "uuu"
> >
> > Which looks promissing, but here C is a list with three elements. But how
> > to create the two vectors I need from here, that is
> >
> > ("dg","fgrt", "s") and ("rt","","uuu")
> >
> > (or how to get access to the substrings "rt" or "uuu").
> >
> > Greetings
> >
> > Manuel
> >
> >
> >
> >
> >                      jim holtman
> >                      <jholtman at gmail.c        To:       "ManuelPerera-Chang at fmc-ag.com" <ManuelPerera-Chang at fmc-ag.com>
> >                      om>                      cc:       r-help at stat.math.ethz.ch
> >                                               Subject:  Re: [R] splitting a character field in R
> >                      28.10.2005 16:00
> >
> >
> >
> >
> >
> >
> > > x <- 'dfabcxy'
> > > strsplit(x, 'abc')
> > [[1]]
> > [1] "df" "xy"
> >
> >
> > >
> >
> >
> >
> >
> > On 10/28/05, ManuelPerera-Chang at fmc-ag.com <ManuelPerera-Chang at fmc-ag.com >
> > wrote:
> >
> >
> >
> >
> >      Dear R users,
> >
> >      I have a dataframe with one character field, and I would like to
> >      create two
> >      new fields (columns) in my dataset, by spliting the existing
> >      character
> >      field into two using an existing substring.
> >
> >      ... something that in SAS I could solve e.g. combining substr(which I
> >      am
> >      aware exist in R) and "index" for determining the position of the
> >      pattern
> >      within the string.
> >      e.g. if my dataframe is ...
> >      A     B
> >      1     dgabcrt
> >      2     fgrtabc
> >      3     sabcuuu
> >
> >      Then by splitting by substring "abc" I would get ...
> >
> >      A     B           B1    B2
> >      1     dgabcrt     dg    rt
> >      2     fgrtabc     fgrt
> >      3     sabcuuu     s     uuu
> >
> >      Do you know how to do this basic string(dataframe) manipulation in R
> >
> >      Saludos,
> >
> >      Manuel
> >
> >      ______________________________________________
> >      R-help at stat.math.ethz.ch mailing list
> >      https://stat.ethz.ch/mailman/listinfo/r-help
> >      PLEASE do read the posting guide!
> >      http://www.R-project.org/posting-guide.html
> >
> >
> >
> > --
> > Jim Holtman
> > Cincinnati, OH
> > +1 513 247 0281
> >
> > What the problem you are trying to solve?
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>



From jfox at mcmaster.ca  Sat Oct 29 21:13:28 2005
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 29 Oct 2005 15:13:28 -0400
Subject: [R] Problem with llines in lattice
Message-ID: <20051029191327.UHXX21026.tomts16-srv.bellnexxia.net@JohnDesktop8300>

Dear r-help list members,

I'm experiencing problems getting type="b" (or "o" or "c") to work in
llines(). Try, e.g., the following scaled-down example:

x <- factor(c("a", "b", "a", "b"))
y <- c(1,2,1,2)
z <- factor(c("A", "A", "B", "B"))
symbols <- 1:2
lines <- 1:2
colors <- 1:2
zvals <- levels(z)
xyplot(y~x|z, panel = function(x, y, subscripts, ...) {
    for (i in 1:length(zvals)) {
        sub <- z[subscripts] == zvals[i]
        llines(x[sub], y[sub], lwd = 2, type = "b", 
          col = colors[i], pch = symbols[i], lty = lines[i])
        }
    })
    
Only the lines (properly coloured with correct line types) appear, but no
symbols are plotted. On the other hand, if I call llines() with type="l" and
type="p" separately in the panel function, both lines and points appear:

xyplot(y~x|z, panel = function(x, y, subscripts, ...) {
    for (i in 1:length(zvals)) {
        sub <- z[subscripts] == zvals[i]
        llines(x[sub], y[sub], lwd = 2, type = "p", 
          col = colors[i], pch = symbols[i], lty = lines[i])
        llines(x[sub], y[sub], lwd = 2, type = "l", 
          col = colors[i], pch = symbols[i], lty = lines[i])
        }
    })
    
I've looked at both the documentation and code for llines() and lplot.xy(),
which llines() calls, and don't see the source of the problem.

I'm using R 2.2.0 under Windows XP. I'm pretty sure that this used to work,
but I got the same problem in R 2.1.1 when I tried it there.

Any help would be appreciated.

Thanks,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox



From mfgreene at bu.edu  Sat Oct 29 23:59:45 2005
From: mfgreene at bu.edu (Michael Greene)
Date: Sat, 29 Oct 2005 17:59:45 -0400
Subject: [R] RODBC Error
Message-ID: <55D7DA2A-B1B5-4160-AEF2-BC4C1AC96667@bu.edu>


Hello,

I'm using R 2.2.0 on a Mac and attempting to use the RODBC package to  
connect to a PostgreSQL server on the local network.  I can't tell  
whether my problem is in R, or in ODBC setup.

I got drivers from OpenLink, created a dsn and tested it using the  
iODBC application.  then I load the RODBC package, use this code and  
get the following error.  I tried with both the odbcConnect util and  
the odbcDriverConnect util.  I am able to connect to the database  
through other non-odbc based database programs from the Mac, so I  
know it's not a Postgres setting (like no tcp/ip connections or  
something).

 > library(RODBC)
 > channel <- odbcConnect("nfl",uid="postgres", pwd="xxx")
Warning messages:
1: [RODBC] ERROR: Could not SQLDriverConnect
2: ODBC connection failed in: odbcDriverConnect(st, case = case,  
believeNRows = believeNRows)
 >
 > channel2 <- odbcDriverConnect(connection="DSN=nfl, UID=postgres,  
PWD=vladdy79" )
Warning messages:
1: [RODBC] ERROR: state IM002, code 0, message [iODBC][Driver Manager] 
Data source name not found and no default driver specified. Driver  
could not be loaded
2: ODBC connection failed in: odbcDriverConnect(connection =  
"DSN=nfl, UID=postgres, PWD=xxx")


Does anyone have any suggestions?

Thanks,

Michael Greene



From deepayan.sarkar at gmail.com  Sun Oct 30 01:01:14 2005
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Sat, 29 Oct 2005 18:01:14 -0500
Subject: [R] Problem with llines in lattice
In-Reply-To: <20051029191327.UHXX21026.tomts16-srv.bellnexxia.net@JohnDesktop8300>
References: <20051029191327.UHXX21026.tomts16-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <eb555e660510291601k23711413i3607d24aaf33ce4c@mail.gmail.com>

On 10/29/05, John Fox <jfox at mcmaster.ca> wrote:
> Dear r-help list members,
>
> I'm experiencing problems getting type="b" (or "o" or "c") to work in
> llines(). Try, e.g., the following scaled-down example:
>
> x <- factor(c("a", "b", "a", "b"))
> y <- c(1,2,1,2)
> z <- factor(c("A", "A", "B", "B"))
> symbols <- 1:2
> lines <- 1:2
> colors <- 1:2
> zvals <- levels(z)
> xyplot(y~x|z, panel = function(x, y, subscripts, ...) {
>     for (i in 1:length(zvals)) {
>         sub <- z[subscripts] == zvals[i]
>         llines(x[sub], y[sub], lwd = 2, type = "b",
>           col = colors[i], pch = symbols[i], lty = lines[i])
>         }
>     })
>
> Only the lines (properly coloured with correct line types) appear, but no
> symbols are plotted.

It's bug in lplot.xy. Fortunately, panel.xyplot will do the same
thing, so you can use it instead of llines.

One comment: I'm not sure if this would work in your real application,
but for your toy example a more direct approach would be

xyplot(y ~ x | z, type = 'b', groups = z,
       col = colors, pch = symbols, lty = lines,
       lwd = 2)

-Deepayan



From ggrothendieck at gmail.com  Sun Oct 30 03:04:23 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 29 Oct 2005 22:04:23 -0400
Subject: [R] how to get colnames of a dataframe within a function called
	by 'apply'
In-Reply-To: <971536df0510281925r3e3030d2s7453963f5acfee2f@mail.gmail.com>
References: <4362C614.5060203@anicca-vijja.de>
	<971536df0510281925r3e3030d2s7453963f5acfee2f@mail.gmail.com>
Message-ID: <971536df0510291904v38471e05la283282fa86f9860@mail.gmail.com>

One other comment.  A for loop would seem to be
appropriate here since you are not using the result
of sapply anyways:

par.or <- par(mfrow = c(3,3))

for(n in colnames(temp)) {
  qqnorm(temp[,n], main = n)
  qqline(temp[,n], col = "red")
}

par(par.or)


On 10/28/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Iterate over the column names rather than the columns themselves:
>
> par.or <- par(mfrow=c(3,3))
> nv <- function(name, data) {
>        qqnorm(data[,name], main=name)
>        qqline(data[,name], col="red")
>        invisible()
> }
> sapply(colnames(temp), nv, data = temp)
> par(par.or)
>
>
> On 10/28/05, Leo G??rtler <leog at anicca-vijja.de> wrote:
> > Hello alltogether,
> >
> > how is it possible to assign the colnames of a data.frame to a function
> > called by apply, e.g. for labeling a plot?
> > Example: I want to plot several qqnorm-plots side by side and there
> > should be a maintitle for each qqnorm-plot which is identical to the
> > respective colname.
> > I checked, but the column which is processed by the function called by
> > apply does not contain a colname (because by using str() it seems it is
> > no column at this point, but just a e.g. numerical vector).
> > I also tried with colnames() from within the function, but was not
> > successful to get the apropriate colname - either the whole string or
> > just the first one.Thus it lacks of a counter that contains the number
> > of the row which is processed.
> >
> > Here is an example code:
> >
> > <---snip--->
> >
> > nv <- function(xno.na)
> > {
> >  par.or <- par(mfrow=c(3,3))
> >  qqnorm(xno.na, main="HERE SHOULD BE THE NAME OF THE COLUMN")
> >  qqline(xno.na, col="red")
> >  par(par.or)
> >  print(str(xno.na))
> > }
> >
> >  > temp # just a part of the whole data.frame
> >        klarb1    klarb2 abarb laut skla1 skla2
> > a      NA 13.068182   7.5    4   0.5   0.5
> > b      NA  6.818182   9.0    6    NA   0.5
> > c      15.11628  6.818182  10.0    4   1.0   1.5
> > d      NA 18.181818  19.0    2   1.0   0.5
> >
> >  > apply(temp,2,nv)
> >
> > </---snip--->
> >
> >
> > Thanks a lot!
> >
> > best wishes,
> >
> > leo
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>



From renukas at gmail.com  Sun Oct 30 05:00:29 2005
From: renukas at gmail.com (Renuka Sane)
Date: Sun, 30 Oct 2005 09:30:29 +0530
Subject: [R] question on adding confidence intervals
Message-ID: <f7dc8e940510292100w3cbb0ccfuc8ca8f1eb43cc894@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051030/73560558/attachment.pl

From ripley at stats.ox.ac.uk  Sun Oct 30 08:18:43 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 30 Oct 2005 07:18:43 +0000 (GMT)
Subject: [R] RODBC Error
In-Reply-To: <55D7DA2A-B1B5-4160-AEF2-BC4C1AC96667@bu.edu>
References: <55D7DA2A-B1B5-4160-AEF2-BC4C1AC96667@bu.edu>
Message-ID: <Pine.LNX.4.61.0510300715570.27132@gannet.stats>

On Sat, 29 Oct 2005, Michael Greene wrote:

>
> Hello,
>
> I'm using R 2.2.0 on a Mac and attempting to use the RODBC package to
> connect to a PostgreSQL server on the local network.  I can't tell
> whether my problem is in R, or in ODBC setup.

These are ODBC error reports, so the problem is in ODBC.

> I got drivers from OpenLink, created a dsn and tested it using the
> iODBC application.  then I load the RODBC package, use this code and
> get the following error.  I tried with both the odbcConnect util and
> the odbcDriverConnect util.  I am able to connect to the database
> through other non-odbc based database programs from the Mac, so I
> know it's not a Postgres setting (like no tcp/ip connections or
> something).

No, you don't.  I've see quite a few problems which were Postgresql (sic) 
settings affecting the ODBC driver.

> > library(RODBC)
> > channel <- odbcConnect("nfl",uid="postgres", pwd="xxx")
> Warning messages:
> 1: [RODBC] ERROR: Could not SQLDriverConnect
> 2: ODBC connection failed in: odbcDriverConnect(st, case = case,
> believeNRows = believeNRows)
> >
> > channel2 <- odbcDriverConnect(connection="DSN=nfl, UID=postgres,
> PWD=vladdy79" )
> Warning messages:
> 1: [RODBC] ERROR: state IM002, code 0, message [iODBC][Driver Manager]
> Data source name not found and no default driver specified. Driver
> could not be loaded
> 2: ODBC connection failed in: odbcDriverConnect(connection =
> "DSN=nfl, UID=postgres, PWD=xxx")


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From iaingallagher at btopenworld.com  Sun Oct 30 11:54:38 2005
From: iaingallagher at btopenworld.com (IAIN GALLAGHER)
Date: Sun, 30 Oct 2005 10:54:38 +0000 (GMT)
Subject: [R] How to print output during for loops?
In-Reply-To: <20051029100313.48427.qmail@web34711.mail.mud.yahoo.com>
Message-ID: <20051030105439.54663.qmail@web86708.mail.ukl.yahoo.com>

for (i in 1:5) {print(i)}

Cheers

Iain


--- Martin Lam <tmlammail at yahoo.com> wrote:

> Hi,
> 
> I was wondering, if it is possible to print out the
> values of variables while you are in a for/while
> loop?
> Like this for example:
>   
> for (i in 1:5) {
>   i
> }
> 
> So what I want is this as output in the console:
> >1
> >2
> >3
> >4
> >5
> 
> Thanks in advance,
> 
> Martin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From pauline12lv at yahoo.com.tw  Sun Oct 30 12:25:02 2005
From: pauline12lv at yahoo.com.tw (Yu-Lin)
Date: Sun, 30 Oct 2005 19:25:02 +0800 (CST)
Subject: [R] HOW TO WRITE A DOUBLE  EXPONENTIAL  FUNCTION
Message-ID: <20051030112502.67381.qmail@web53802.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051030/5cbf14bd/attachment.pl

From manuel.castejon at unileon.es  Sun Oct 30 12:33:51 2005
From: manuel.castejon at unileon.es (=?ISO-8859-1?Q?Manuel_Castej=F3n_Limas?=)
Date: Sun, 30 Oct 2005 12:33:51 +0100
Subject: [R] R moodle module
Message-ID: <4364AF9F.5020701@unileon.es>

Hello,
I have recently started to use moodle (a course management system) for 
my classes. It has turn out to be a very interesting tool. I woke up 
this morning wondering about the possibility of adding a module so that 
the students could use R without needing to install it, just using a 
server session into moodle.

I know that there are already several on-going projects about R and the 
web, but, the question is : Is anybody already developing such a module 
for moodle?

If the answer is no, I shall put it in my want-to-do list, although I 
can not promise any inmediate result due to may work overload.

Thanks in advance for your patience and your good efforts!

Best wishes,

Manuel Castej??n Limas 
E-mail: manuel.castejon at unileon.es
??rea de Proyectos de Ingenier??a
Departamento de Ingenier??a El??ctrica y Electr??nica
Universidad de Le??n
Spain

PS: You may read more about moodle at  http://moodle.org



From jfox at mcmaster.ca  Sun Oct 30 14:19:02 2005
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 30 Oct 2005 08:19:02 -0500
Subject: [R] Problem with llines in lattice
In-Reply-To: <eb555e660510291601k23711413i3607d24aaf33ce4c@mail.gmail.com>
Message-ID: <20051030131901.JHB21026.tomts16-srv.bellnexxia.net@JohnDesktop8300>

Dear Deepayan,

The application in which I encountered the problem is much more complicated,
so I'm not sure whether using groups will work there, but I'll give it a
try. 

Thanks for this,
 John

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Deepayan Sarkar
> Sent: Saturday, October 29, 2005 6:01 PM
> To: John Fox
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Problem with llines in lattice
> 
> On 10/29/05, John Fox <jfox at mcmaster.ca> wrote:
> > Dear r-help list members,
> >
> > I'm experiencing problems getting type="b" (or "o" or "c") 
> to work in 
> > llines(). Try, e.g., the following scaled-down example:
> >
> > x <- factor(c("a", "b", "a", "b"))
> > y <- c(1,2,1,2)
> > z <- factor(c("A", "A", "B", "B"))
> > symbols <- 1:2
> > lines <- 1:2
> > colors <- 1:2
> > zvals <- levels(z)
> > xyplot(y~x|z, panel = function(x, y, subscripts, ...) {
> >     for (i in 1:length(zvals)) {
> >         sub <- z[subscripts] == zvals[i]
> >         llines(x[sub], y[sub], lwd = 2, type = "b",
> >           col = colors[i], pch = symbols[i], lty = lines[i])
> >         }
> >     })
> >
> > Only the lines (properly coloured with correct line types) 
> appear, but 
> > no symbols are plotted.
> 
> It's bug in lplot.xy. Fortunately, panel.xyplot will do the 
> same thing, so you can use it instead of llines.
> 
> One comment: I'm not sure if this would work in your real 
> application, but for your toy example a more direct approach would be
> 
> xyplot(y ~ x | z, type = 'b', groups = z,
>        col = colors, pch = symbols, lty = lines,
>        lwd = 2)
> 
> -Deepayan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From walton.green at yale.edu  Sun Oct 30 15:36:06 2005
From: walton.green at yale.edu (Walton A. Green)
Date: Sun, 30 Oct 2005 09:36:06 -0500 (EST)
Subject: [R] dyn.load() error: bad external relocation length
In-Reply-To: <43637DDA.5060606@wald.ucdavis.edu>
Message-ID: <Pine.LNX.4.44.0510292026320.25979-100000@ajax.its.yale.edu>


Duncan,

Many thanks: R CMD SHLIB is proably what I was looking for....do you know 
where the most extensive documentation for that is located? I looked at 
the man page for R and R CMD SHLIP --help, but there wasn't much detail on 
how it works. Does it (or can it be configured to) run a makefile? (I have 
been compiling the C using a makefile written by someone else: the larger 
picture is that we're trying to write R wrappers for a bunch of C 
programs---my colleague is modifying the C---so eventually they'll be 
put in a package's /src directory, but for now I am just trying to test by 
making sure they can be called from R before putting them together in a 
package. So far I've just been using system(), which works fine on my 
machine, but all the packages I've looked at use .C()/.Call() in 
preference to system(), so I assume I should be learning how to use 
.C()/.Call()....

Thanks,
Walton

On Sat, 29 Oct 2005, Duncan Temple Lang wrote:

> Hi Walton.
> 
> .C/.Call are interfaces to _compiled_ C routines in a dynamically
> loaded library (DLL or DSO - shared object).  A progra
> A program is often created from compiling C code into an executable.
> We can call the executable via system, but we cannot access its routines 
> via .C/.Call.
> 
> So, if you have C code, use R CMD SHLIB to compile it into a loadable
> libray and use dyn.load() to load it. Putting the code in the src/ 
> directory of a package makes the need to do this less explicit.
> 
> But if you want to use system(), again it can be done "portably" in a 
> package.
> Arrange that the package creates and puts the executable in
> the package's installed area.  Arrange that the program is
> put in, say, inst/bin within the package and then it will be installed 
> into the bin/ directory of the package. Then you can access it with
> 
>     system.file("bin", "myProg", package = "myPackageName")
> 
> and you can use that in your call to system().
> 
> The down side is that you will have to ensure that the program is built
> in a portable way. So if you won the C code, it is almost the same thing
> as building a DLL and using .C/.Call.
> 
> HTH
> 
>    D.
> 
> 
> 
> Walton A. Green wrote:
> > R-helpers,
> > 
> > Is there an easy way to call an external (C) program using .C or .Call 
> > without including the code in a package. I know how to do it using 
> > system(), but that doesn't seem to be a permanent or portable solution. 
> > Initially I tried:
> > 
> > .Call('filepath.to.c.function', arg1)
> > 
> > and got this error:
> > 
> > Error in .Call("filepath.to.c.function", "arg1",  : 
> > 	"C" function name not in load table
> > 
> > So read the section on foreign language interfaces in the Writing R 
> > Extensions manual but when I tried:
> > 
> > dyn.load('filepath.to.c.function')
> > 
> > I got:
> > 
> > Error in dyn.load(x, as.logical(local), as.logical(now)) : 
> > 	unable to load shared library 'filepath.to.c.function':
> >   dlopen(filepath.to.c.function, 6): bad external relocation length
> > 
> > Do you need to run R_registerRoutines before dyn.load()? I couldn't find 
> > any mention of this error on the web....
> > 
> > Walton
> > 
> > platform powerpc-apple-darwin7.9.0
> > arch     powerpc                  
> > os       darwin7.9.0              
> > system   powerpc, darwin7.9.0     
> > status                            
> > major    2                        
> > minor    1.1                      
> > year     2005                     
> > month    06                       
> > day      20                       
> > language R
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

######################## .signature ########################
# Walton A. Green                    walton.green at yale.edu #   
# 139 Caulkinstown Road     P. O. Box 208109, Yale Station #
# Sharon, Connecticut 06069   New Haven, Connecticut 06520 #
# (860) 364-5100                            (203) 640-8122 #
#################### 60 characters wide ####################



From ripley at stats.ox.ac.uk  Sun Oct 30 16:45:32 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 30 Oct 2005 15:45:32 +0000 (GMT)
Subject: [R] dyn.load() error: bad external relocation length
In-Reply-To: <Pine.LNX.4.44.0510292026320.25979-100000@ajax.its.yale.edu>
References: <Pine.LNX.4.44.0510292026320.25979-100000@ajax.its.yale.edu>
Message-ID: <Pine.LNX.4.61.0510301541310.14536@gannet.stats>

Try `Writing R Extensions' (as referred to on the help page for SHLIB 
...).

On Sun, 30 Oct 2005, Walton A. Green wrote:

>
> Duncan,
>
> Many thanks: R CMD SHLIB is proably what I was looking for....do you know
> where the most extensive documentation for that is located? I looked at
> the man page for R and R CMD SHLIP --help, but there wasn't much detail on
> how it works. Does it (or can it be configured to) run a makefile? (I have
> been compiling the C using a makefile written by someone else: the larger
> picture is that we're trying to write R wrappers for a bunch of C
> programs---my colleague is modifying the C---so eventually they'll be
> put in a package's /src directory, but for now I am just trying to test by
> making sure they can be called from R before putting them together in a
> package. So far I've just been using system(), which works fine on my
> machine, but all the packages I've looked at use .C()/.Call() in
> preference to system(), so I assume I should be learning how to use
> .C()/.Call()....
>
> Thanks,
> Walton
>
> On Sat, 29 Oct 2005, Duncan Temple Lang wrote:
>
>> Hi Walton.
>>
>> .C/.Call are interfaces to _compiled_ C routines in a dynamically
>> loaded library (DLL or DSO - shared object).  A progra
>> A program is often created from compiling C code into an executable.
>> We can call the executable via system, but we cannot access its routines
>> via .C/.Call.
>>
>> So, if you have C code, use R CMD SHLIB to compile it into a loadable
>> libray and use dyn.load() to load it. Putting the code in the src/
>> directory of a package makes the need to do this less explicit.
>>
>> But if you want to use system(), again it can be done "portably" in a
>> package.
>> Arrange that the package creates and puts the executable in
>> the package's installed area.  Arrange that the program is
>> put in, say, inst/bin within the package and then it will be installed
>> into the bin/ directory of the package. Then you can access it with
>>
>>     system.file("bin", "myProg", package = "myPackageName")
>>
>> and you can use that in your call to system().
>>
>> The down side is that you will have to ensure that the program is built
>> in a portable way. So if you won the C code, it is almost the same thing
>> as building a DLL and using .C/.Call.
>>
>> HTH
>>
>>    D.
>>
>>
>>
>> Walton A. Green wrote:
>>> R-helpers,
>>>
>>> Is there an easy way to call an external (C) program using .C or .Call
>>> without including the code in a package. I know how to do it using
>>> system(), but that doesn't seem to be a permanent or portable solution.
>>> Initially I tried:
>>>
>>> .Call('filepath.to.c.function', arg1)
>>>
>>> and got this error:
>>>
>>> Error in .Call("filepath.to.c.function", "arg1",  :
>>> 	"C" function name not in load table
>>>
>>> So read the section on foreign language interfaces in the Writing R
>>> Extensions manual but when I tried:
>>>
>>> dyn.load('filepath.to.c.function')
>>>
>>> I got:
>>>
>>> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>>> 	unable to load shared library 'filepath.to.c.function':
>>>   dlopen(filepath.to.c.function, 6): bad external relocation length
>>>
>>> Do you need to run R_registerRoutines before dyn.load()? I couldn't find
>>> any mention of this error on the web....
>>>
>>> Walton
>>>
>>> platform powerpc-apple-darwin7.9.0
>>> arch     powerpc
>>> os       darwin7.9.0
>>> system   powerpc, darwin7.9.0
>>> status
>>> major    2
>>> minor    1.1
>>> year     2005
>>> month    06
>>> day      20
>>> language R
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>
> ######################## .signature ########################
> # Walton A. Green                    walton.green at yale.edu #
> # 139 Caulkinstown Road     P. O. Box 208109, Yale Station #
> # Sharon, Connecticut 06069   New Haven, Connecticut 06520 #
> # (860) 364-5100                            (203) 640-8122 #
> #################### 60 characters wide ####################
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From forister at life.bio.sunysb.edu  Sun Oct 30 17:02:31 2005
From: forister at life.bio.sunysb.edu (Matthew Forister)
Date: Sun, 30 Oct 2005 11:02:31 -0500
Subject: [R] Help with Subtracting an effect from a Mixed Model
Message-ID: <5c049bb37946ef4afc9fabec9b4a3fcb@life.bio.sunysb.edu>


Hi Everyone,

I posted a similar question about a week ago, but haven't gotten any 
replies -- I'm afraid that's because my previous question was too 
vague.  Let me try again with a more specific question, and I hope 
someone can help.  NOTE, I know I should be using the newer lme4 
package, I just haven't had a chance to update my version of R yet, so 
the question below relates to nmle.

I have data from a classical quantitative genetics experiment, with 33 
sires mated each to 2 dams, with 15 progeny from each dam raised on 5 
host plants (3 larvae per host).  So the model I would like to run has 
the following factors:
Host (fixed)
Sire (random)
Dam [nested within sire] (random)
Host * Sire (random interaction)
Host * Dam [nested within sire] (random interaction)

This is the code I am using for that complete model:
lme1=lme(gain~host,random=~host|sire/dam)
I would like to try the model with and without each of those random 
interactions (host*sire and host*dam-nested-within-sire).

WHAT IS THE SYNTAX FOR SUBTRACTING AN EFFECT FROM THE RANDOM STATEMENT?
I have tried:
lme1=lme(gain~host,random=~host|sire/dam-sire:host)
But I get an "Invalid formula for groups" error.
Alternatively, I tried reorganizing the code, so that the interaction 
would be left out.  But there is no way to take out host*sire while 
still leaving in host*dam nested within sire.

any help will be greatly appreciated!
Matt

- - -
Matthew L Forister
Department of Ecology and Evolution
State University of New York at Stony Brook
650 Life Sciences Building
Stony Brook, New York 11794-5245
Email: forister at life.bio.sunysb.edu
Webpage: http://life.bio.sunysb.edu/~forister/
Lab phone: (631) 632-8609
Fax: (631) 632-7626
- - -



From ccatj at web.de  Sun Oct 30 16:03:21 2005
From: ccatj at web.de (Christian Jones)
Date: Sun, 30 Oct 2005 17:03:21 +0200
Subject: [R] Problems with BIC (Bayesian Information Criterion)
Message-ID: <385432495@web.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051030/0b0a503c/attachment.pl

From thherbst1 at onlinehome.de  Sun Oct 30 17:05:47 2005
From: thherbst1 at onlinehome.de (Thomas Herbst)
Date: Sun, 30 Oct 2005 17:05:47 +0100
Subject: [R] Hilfeanfrage
Message-ID: <003001c5dd6b$cad5de20$0a01a8c0@privatrhv2a9x5>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051030/2530a22d/attachment.pl

From mfgreene at bu.edu  Sun Oct 30 17:08:28 2005
From: mfgreene at bu.edu (Michael Greene)
Date: Sun, 30 Oct 2005 11:08:28 -0500
Subject: [R] RODBC Error
In-Reply-To: <Pine.LNX.4.61.0510300715570.27132@gannet.stats>
References: <55D7DA2A-B1B5-4160-AEF2-BC4C1AC96667@bu.edu>
	<Pine.LNX.4.61.0510300715570.27132@gannet.stats>
Message-ID: <BEFABFC5-7DF9-4491-96E9-590028B1C5E6@bu.edu>

Is there a specific issue with connections using the RODBC package?   
I am able to use the same DSN/ODBC configuration to connect to the  
database using Microsoft Excel's MS Query tool, and using other  
drivers from other OSes (Windows).

Do I have to reference the driver directly in the odbcDriverConnect?   
I tried re-making the DSN with a different name, that didn't work  
either.



On Oct 30, 2005, at 2:18 AM, Prof Brian Ripley wrote:

> On Sat, 29 Oct 2005, Michael Greene wrote:
>
>
>>
>> Hello,
>>
>> I'm using R 2.2.0 on a Mac and attempting to use the RODBC package to
>> connect to a PostgreSQL server on the local network.  I can't tell
>> whether my problem is in R, or in ODBC setup.
>>
>
> These are ODBC error reports, so the problem is in ODBC.
>
>
>> I got drivers from OpenLink, created a dsn and tested it using the
>> iODBC application.  then I load the RODBC package, use this code and
>> get the following error.  I tried with both the odbcConnect util and
>> the odbcDriverConnect util.  I am able to connect to the database
>> through other non-odbc based database programs from the Mac, so I
>> know it's not a Postgres setting (like no tcp/ip connections or
>> something).
>>
>
> No, you don't.  I've see quite a few problems which were Postgresql  
> (sic) settings affecting the ODBC driver.
>
>
>> > library(RODBC)
>> > channel <- odbcConnect("nfl",uid="postgres", pwd="xxx")
>> Warning messages:
>> 1: [RODBC] ERROR: Could not SQLDriverConnect
>> 2: ODBC connection failed in: odbcDriverConnect(st, case = case,
>> believeNRows = believeNRows)
>> >
>> > channel2 <- odbcDriverConnect(connection="DSN=nfl, UID=postgres,
>> PWD=vladdy79" )
>> Warning messages:
>> 1: [RODBC] ERROR: state IM002, code 0, message [iODBC][Driver  
>> Manager]
>> Data source name not found and no default driver specified. Driver
>> could not be loaded
>> 2: ODBC connection failed in: odbcDriverConnect(connection =
>> "DSN=nfl, UID=postgres, PWD=xxx")
>>
>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From edd at debian.org  Sun Oct 30 18:13:27 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 30 Oct 2005 11:13:27 -0600
Subject: [R] Hilfeanfrage
In-Reply-To: <003001c5dd6b$cad5de20$0a01a8c0@privatrhv2a9x5>
References: <003001c5dd6b$cad5de20$0a01a8c0@privatrhv2a9x5>
Message-ID: <17252.65335.89687.294986@basebud.nulle.part>


Thomas,

On 30 October 2005 at 17:05, Thomas Herbst wrote:
| Sehr geehrtes R-TEAM!

The list operates in English as a casual look at the archives would have told
you.

| Wie Sie sehen, besteht die Variable "worldindex05r" aus 3 Spalten "V1, V2,
| V3". Rechnen kann R aber nur mit den numerischen Werten (V2, V3). Das ist
| mir klar!
| 
| Wie kann ich nun gezielt einzelne "V??s" ausw??hlen, z.b. f??r ein Histogramm?

[ Question was how to subset columns of a data.frame or matrix ]

You _really_ want to read 'An Introduction to R' -- which came with R
installation, or an equivalent manual. There are lots of them, the
http://www.r-project.org website and the mirrors of http://cran.r-project.org
carry a couple free pdf manuals.  As for your question:

    > skewness(worldindex05r[,c(V2,V3)])

is one of several ways to select specific columns.
 
| Wie kann ich einen Plot erstellen, z.B. mit V1 = Nur Datum auf der x-Achse
|  und  V2(Kurse) oder V3(log.Renditen aus V2 ) auf der y-Achse?`eee

[ How to plot x vs y ]

One of several ways to plot one variable against another is

    > plot(worldindex05r$V1, worldindex05r$V2)  

How to take logarithms is left as an exercise to the reader ...
 
| Dann w??rde ich noch gerne wissen, wo die LINEARE REGRESSION(einfach und 
| mehrfach) bei R zu finden ist?

[ Where is linear regression, simple and multiple ]

Had you read the manual, you would know that

    > help.search("linear regrqession")

can provide a first lead, which can often be complemented by

    > RSiteSearch("linear regression")

In this case you are out of luck because as statistics refers to this as a
'linear model', so

    > help(lm)

is what you need.

| Vielen Dank im voraus.

It's a pleasure, but you now owe it to yourself to a) read some of the
manuals and b) the posting guide for this list.  
 
| Thomas Herbst
| 
| 
| Ein kleiner Nachtrag meinerseits: Die Hilfen von R sind f??r
|  "Nicht-Mathematiker" eher schwer zu erschlie??en und sie liegen leider nur
|  in englischer Sprache vor, obwohl das Programm selbst mehrsprachig
|  ist. Warum?

[ R docs are hard for non-mathematicians, and missing in German ]

This is a _volunteer_ project. Feel free to close some of the gaps by
submitting a German language manual. I am sure someone would be glad a to
proofread it for you.

[ Statement about the state of the art, or lack thereof, in Banking deleted. ]

Yes, some of us work in the same industry.

Regards, Dirk

-- 
Statistics: The (futile) attempt to offer certainty about uncertainty.
         -- Roger Koenker, 'Dictionary of Received Ideas of Statistics'



From Rau at demogr.mpg.de  Sun Oct 30 18:25:38 2005
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Sun, 30 Oct 2005 18:25:38 +0100
Subject: [R] How to print output during for loops?
Message-ID: <8B08A3A1EA7AAC41BE24C750338754E69FDF1A@HERMES.demogr.mpg.de>

Hi,

 > -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Martin Lam
> 
> I was wondering, if it is possible to print out the
> values of variables while you are in a for/while loop?
> Like this for example:
>   
> for (i in 1:5) {
>   i
> }
> 

yes, should be possible:
for (i in 1:5) {
	print(i)
}

It might also help (assuming you work on MS Windows using RGui.exe) to
disable "buffered output" by pressing "CTRL+W". As you can see when
clicking on "Misc" in the toolbar, the default setting is "buffered
output". 

I hope this helps,
Roland

+++++
This mail has been sent through the MPI for Demographic Rese...{{dropped}}



From ligges at statistik.uni-dortmund.de  Sun Oct 30 21:36:43 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 30 Oct 2005 21:36:43 +0100
Subject: [R] Hilfeanfrage
In-Reply-To: <17252.65335.89687.294986@basebud.nulle.part>
References: <003001c5dd6b$cad5de20$0a01a8c0@privatrhv2a9x5>
	<17252.65335.89687.294986@basebud.nulle.part>
Message-ID: <43652EDB.2060306@statistik.uni-dortmund.de>

Dirk Eddelbuettel wrote:
> Thomas,
> 
> On 30 October 2005 at 17:05, Thomas Herbst wrote:
> | Sehr geehrtes R-TEAM!
> 
> The list operates in English as a casual look at the archives would have told
> you.
> 
> | Wie Sie sehen, besteht die Variable "worldindex05r" aus 3 Spalten "V1, V2,
> | V3". Rechnen kann R aber nur mit den numerischen Werten (V2, V3). Das ist
> | mir klar!
> | 
> | Wie kann ich nun gezielt einzelne "V??s" ausw??hlen, z.b. f??r ein Histogramm?
> 
> [ Question was how to subset columns of a data.frame or matrix ]
> 
> You _really_ want to read 'An Introduction to R' -- which came with R
> installation, or an equivalent manual. There are lots of them, the
> http://www.r-project.org website and the mirrors of http://cran.r-project.org
> carry a couple free pdf manuals.  As for your question:
> 
>     > skewness(worldindex05r[,c(V2,V3)])

Dirk, you forgot some quotes:

     skewness(worldindex05r[,c("V2","V3")])

Best,
Uwe



> is one of several ways to select specific columns.
>  
> | Wie kann ich einen Plot erstellen, z.B. mit V1 = Nur Datum auf der x-Achse
> |  und  V2(Kurse) oder V3(log.Renditen aus V2 ) auf der y-Achse?`eee
> 
> [ How to plot x vs y ]
> 
> One of several ways to plot one variable against another is
> 
>     > plot(worldindex05r$V1, worldindex05r$V2)  
> 
> How to take logarithms is left as an exercise to the reader ...
>  
> | Dann w??rde ich noch gerne wissen, wo die LINEARE REGRESSION(einfach und 
> | mehrfach) bei R zu finden ist?
> 
> [ Where is linear regression, simple and multiple ]
> 
> Had you read the manual, you would know that
> 
>     > help.search("linear regrqession")
> 
> can provide a first lead, which can often be complemented by
> 
>     > RSiteSearch("linear regression")
> 
> In this case you are out of luck because as statistics refers to this as a
> 'linear model', so
> 
>     > help(lm)
> 
> is what you need.
> 
> | Vielen Dank im voraus.
> 
> It's a pleasure, but you now owe it to yourself to a) read some of the
> manuals and b) the posting guide for this list.  
>  
> | Thomas Herbst
> | 
> | 
> | Ein kleiner Nachtrag meinerseits: Die Hilfen von R sind f??r
> |  "Nicht-Mathematiker" eher schwer zu erschlie??en und sie liegen leider nur
> |  in englischer Sprache vor, obwohl das Programm selbst mehrsprachig
> |  ist. Warum?
> 
> [ R docs are hard for non-mathematicians, and missing in German ]
> 
> This is a _volunteer_ project. Feel free to close some of the gaps by
> submitting a German language manual. I am sure someone would be glad a to
> proofread it for you.
> 
> [ Statement about the state of the art, or lack thereof, in Banking deleted. ]
> 
> Yes, some of us work in the same industry.
> 
> Regards, Dirk
>



From CHENJO at HELIX.MGH.HARVARD.EDU  Sun Oct 30 22:02:56 2005
From: CHENJO at HELIX.MGH.HARVARD.EDU (Chen, John W.,M.D.)
Date: Sun, 30 Oct 2005 16:02:56 -0500
Subject: [R] Permutational ks p-value for paired data
Message-ID: <3A2A879E523D9448AEE2168CE4D0C04901E99EE8@PHSXMB15.partners.org>

Dear List,

I am new to R. I would like to compute the permutational exact p-value for the
Kolmogorov-Smirnov test for paired data. Is there a routine that is available to
do this? Thanks.

John

--



From samrobertsmith at yahoo.com  Sun Oct 30 22:14:16 2005
From: samrobertsmith at yahoo.com (Robert)
Date: Sun, 30 Oct 2005 13:14:16 -0800 (PST)
Subject: [R] identity matrix
Message-ID: <20051030211416.16885.qmail@web30608.mail.mud.yahoo.com>

I found a very odd thing.
A matrix multiplied by its inverse matrix should be an
identity matrix.
But why the following thing happens?
<a%*%solve(a) is not an identity matrix>
> x%*%t(x)
       [,1]   [,2]  [,3]   [,4]   [,5]
[1,] 108.16  58.24 32.24  66.56 225.68
[2,]  58.24  31.36 17.36  35.84 121.52
[3,]  32.24  17.36  9.61  19.84  67.27
[4,]  66.56  35.84 19.84  40.96 138.88
[5,] 225.68 121.52 67.27 138.88 470.89
> a=x%*%t(x)
> solve(a)
              [,1]          [,2]          [,3]        
 [,4]          [,5]
[1,] -1.372649e+14  1.078492e+14 -2.553747e+14 
1.126842e+14  4.120191e+13
[2,] -1.174558e+14  1.543860e+14  2.323143e+14
-1.375074e+14  2.381809e+13
[3,] -3.062129e+14  6.914056e+14 -1.656744e+15 
7.007732e+14 -1.672741e+12
[4,]  1.761208e+14 -3.724017e+14  7.773835e+14
-2.156631e+14 -3.575351e+13
[5,]  8.789836e+13 -8.046912e+13  6.984285e+13
-5.502429e+13 -1.510937e+13
> a%*%solve(a)
           [,1]       [,2]      [,3]       [,4]     
[,5]
[1,]  2.0410156  1.4433594 -4.169922  0.4003906
1.2170410
[2,] -2.5146484  1.9208984 -1.84912w=1  1.1879883
1.1203613
[3,] -1.5356445 -0.8549805 -1.008789  0.4116211
0.6218872
[4,] -0.5898438 -0.2539063  3.592773  2.0351563
0.7849121
[5,]  1.5000000 -1.1289063 -2.070313 -0.4003906
2.1386719
>



From tlumley at u.washington.edu  Sun Oct 30 22:24:31 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 30 Oct 2005 13:24:31 -0800 (PST)
Subject: [R] identity matrix
In-Reply-To: <20051030211416.16885.qmail@web30608.mail.mud.yahoo.com>
References: <20051030211416.16885.qmail@web30608.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.63a.0510301320200.28148@homer23.u.washington.edu>

On Sun, 30 Oct 2005, Robert wrote:

> I found a very odd thing.
> A matrix multiplied by its inverse matrix should be an
> identity matrix.

Well, an invertible matrix multiplied by its inverse...

The matrix that you give (to two decimal places) is singular
> solve(a)
Error in solve.default(a) : system is computationally singular: reciprocal 
condition number = 3.25149e-20

Your matrix is slightly less singular, but the huge size of the elements 
in solve(a) shows that a%*%solve(a) will not be accurately computed.

There are limits to what you can do with only 15 digits accuracy.

 	-thomas


> But why the following thing happens?
> <a%*%solve(a) is not an identity matrix>
>> x%*%t(x)
>       [,1]   [,2]  [,3]   [,4]   [,5]
> [1,] 108.16  58.24 32.24  66.56 225.68
> [2,]  58.24  31.36 17.36  35.84 121.52
> [3,]  32.24  17.36  9.61  19.84  67.27
> [4,]  66.56  35.84 19.84  40.96 138.88
> [5,] 225.68 121.52 67.27 138.88 470.89
>> a=x%*%t(x)
>> solve(a)
>              [,1]          [,2]          [,3]
> [,4]          [,5]
> [1,] -1.372649e+14  1.078492e+14 -2.553747e+14
> 1.126842e+14  4.120191e+13
> [2,] -1.174558e+14  1.543860e+14  2.323143e+14
> -1.375074e+14  2.381809e+13
> [3,] -3.062129e+14  6.914056e+14 -1.656744e+15
> 7.007732e+14 -1.672741e+12
> [4,]  1.761208e+14 -3.724017e+14  7.773835e+14
> -2.156631e+14 -3.575351e+13
> [5,]  8.789836e+13 -8.046912e+13  6.984285e+13
> -5.502429e+13 -1.510937e+13
>> a%*%solve(a)
>           [,1]       [,2]      [,3]       [,4]
> [,5]
> [1,]  2.0410156  1.4433594 -4.169922  0.4003906
> 1.2170410
> [2,] -2.5146484  1.9208984 -1.84912w=1  1.1879883
> 1.1203613
> [3,] -1.5356445 -0.8549805 -1.008789  0.4116211
> 0.6218872
> [4,] -0.5898438 -0.2539063  3.592773  2.0351563
> 0.7849121
> [5,]  1.5000000 -1.1289063 -2.070313 -0.4003906
> 2.1386719
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From d.scott at auckland.ac.nz  Sun Oct 30 22:29:52 2005
From: d.scott at auckland.ac.nz (David Scott)
Date: Mon, 31 Oct 2005 10:29:52 +1300 (NZDT)
Subject: [R] identity matrix
In-Reply-To: <20051030211416.16885.qmail@web30608.mail.mud.yahoo.com>
References: <20051030211416.16885.qmail@web30608.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.60.0510311021120.13902@stat71.stat.auckland.ac.nz>

On Sun, 30 Oct 2005, Robert wrote:

> I found a very odd thing.
> A matrix multiplied by its inverse matrix should be an
> identity matrix.
> But why the following thing happens?
> <a%*%solve(a) is not an identity matrix>
>> x%*%t(x)
>       [,1]   [,2]  [,3]   [,4]   [,5]
> [1,] 108.16  58.24 32.24  66.56 225.68
> [2,]  58.24  31.36 17.36  35.84 121.52
> [3,]  32.24  17.36  9.61  19.84  67.27
> [4,]  66.56  35.84 19.84  40.96 138.88
> [5,] 225.68 121.52 67.27 138.88 470.89
>> a=x%*%t(x)
>> solve(a)
>              [,1]          [,2]          [,3]
> [,4]          [,5]
> [1,] -1.372649e+14  1.078492e+14 -2.553747e+14
> 1.126842e+14  4.120191e+13
> [2,] -1.174558e+14  1.543860e+14  2.323143e+14
> -1.375074e+14  2.381809e+13
> [3,] -3.062129e+14  6.914056e+14 -1.656744e+15
> 7.007732e+14 -1.672741e+12
> [4,]  1.761208e+14 -3.724017e+14  7.773835e+14
> -2.156631e+14 -3.575351e+13
> [5,]  8.789836e+13 -8.046912e+13  6.984285e+13
> -5.502429e+13 -1.510937e+13


All those e+13, e+14, e+15 values didn't ring any alarms for you?

What you are seeing is just the limits of accuracy of calculation on a 
computer.

Yes, A times A^{-1} is the identity when calculations are infinitely 
accurate, but there are limits on accuracy when using a computer.

Lots of other nice mathematical properties go out the window with floating 
point computation: it is not associative or distributive for starters.

Best do a bit of reading on floating point computation: the Wiki article 
is a readily available starting point:

http://en.wikipedia.org/wiki/Floating_point

David Scott

_________________________________________________________________
David Scott	Department of Statistics, Tamaki Campus
 		The University of Auckland, PB 92019
 		Auckland	NEW ZEALAND
Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
Email:	d.scott at auckland.ac.nz


Graduate Officer, Department of Statistics



From maj at stats.waikato.ac.nz  Mon Oct 31 01:38:28 2005
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Mon, 31 Oct 2005 13:38:28 +1300
Subject: [R] Downloading zip files
Message-ID: <43656784.6040700@stats.waikato.ac.nz>

I have not had a great amount of success installing/updating packages 
from the "Packages" menu of Rgui under Windows XL. (Except for 
installing from loacal zip files.)

But I am not asking for help in using these facilities because I prefer 
to keep a folder of package zip files. On the other hand I do find it 
tedious having to right-click "Save link as" on every individual file 
from CRAN.

I'm sure someone knows a faster way to do it.

Cheers,  Murray Jorgensen
-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441    Mobile 021 1395 862



From edd at debian.org  Mon Oct 31 01:56:55 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 30 Oct 2005 18:56:55 -0600
Subject: [R] Hilfeanfrage
In-Reply-To: <43652EDB.2060306@statistik.uni-dortmund.de>
References: <003001c5dd6b$cad5de20$0a01a8c0@privatrhv2a9x5>
	<17252.65335.89687.294986@basebud.nulle.part>
	<43652EDB.2060306@statistik.uni-dortmund.de>
Message-ID: <17253.27607.561399.912777@basebud.nulle.part>


On 30 October 2005 at 21:36, Uwe Ligges wrote:
| Dirk Eddelbuettel wrote:
| >     > skewness(worldindex05r[,c(V2,V3)])
| 
| Dirk, you forgot some quotes:
| 
|      skewness(worldindex05r[,c("V2","V3")])

Quite right. Thanks for catching that. Recurrent trouble with
non-reproducible examples...

Later, Dirk

-- 
Statistics: The (futile) attempt to offer certainty about uncertainty.
         -- Roger Koenker, 'Dictionary of Received Ideas of Statistics'



From MSchwartz at mn.rr.com  Mon Oct 31 02:08:39 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Sun, 30 Oct 2005 19:08:39 -0600
Subject: [R] Downloading zip files
In-Reply-To: <43656784.6040700@stats.waikato.ac.nz>
References: <43656784.6040700@stats.waikato.ac.nz>
Message-ID: <1130720919.4928.77.camel@localhost.localdomain>

On Mon, 2005-10-31 at 13:38 +1300, Murray Jorgensen wrote:
> I have not had a great amount of success installing/updating packages 
> from the "Packages" menu of Rgui under Windows XL. (Except for 
> installing from loacal zip files.)
> 
> But I am not asking for help in using these facilities because I prefer 
> to keep a folder of package zip files. On the other hand I do find it 
> tedious having to right-click "Save link as" on every individual file 
> from CRAN.
> 
> I'm sure someone knows a faster way to do it.
> 
> Cheers,  Murray Jorgensen

Murray, 

See ?install.packages for more information and also R Windows FAQ
section 4 on Packages.

On that same help page is download.packages() which will download, but
not install, packages into a target directory, if that is an option that
you prefer, since the ZIP files will generally consume less space then
actually installing them if not needed.

You can use install.packages() from the command line to install any CRAN
packages that are available and then use update.packages() to keep the
installed packages updated as they become available.

If you want to install all CRAN packages that you do not currently have
installed, you can use:

  install.packages(new.packages(), dependencies = TRUE)

All available CRAN packages that do not require third party libraries on
your system should be installed. I am not sure what the count on Windows
would be, but for me on Linux, including the base R packages, I end up
with 624 packages installed, which takes about 650 Mb.

HTH,

Marc Schwartz



From e.catchpole at adfa.edu.au  Mon Oct 31 02:11:17 2005
From: e.catchpole at adfa.edu.au (ecatchpole)
Date: Mon, 31 Oct 2005 12:11:17 +1100
Subject: [R] Downloading zip files
In-Reply-To: <43656784.6040700@stats.waikato.ac.nz>
References: <43656784.6040700@stats.waikato.ac.nz>
Message-ID: <43656F35.7070608@adfa.edu.au>

Well, there's downTHEMall, a Mozilla Firefox extension
(https://addons.mozilla.org/extensions/).

Ted.

On 31/10/05 11:38,  Murray Jorgensen wrote,:
> I have not had a great amount of success installing/updating packages 
> from the "Packages" menu of Rgui under Windows XL. (Except for 
> installing from loacal zip files.)
> 
> But I am not asking for help in using these facilities because I prefer 
> to keep a folder of package zip files. On the other hand I do find it 
> tedious having to right-click "Save link as" on every individual file 
> from CRAN.
> 
> I'm sure someone knows a faster way to do it.
> 
> Cheers,  Murray Jorgensen


-- 
Dr E.A. Catchpole
Visiting Fellow
Univ of New South Wales at ADFA, Canberra, Australia
and University of Kent, Canterbury, England
- www.ma.adfa.edu.au/~eac
- fax: +61 2 6268 8786		
- ph:  +61 2 6268 8895



From murdoch at stats.uwo.ca  Mon Oct 31 02:38:17 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 30 Oct 2005 20:38:17 -0500
Subject: [R] Downloading zip files
In-Reply-To: <43656784.6040700@stats.waikato.ac.nz>
References: <43656784.6040700@stats.waikato.ac.nz>
Message-ID: <43657589.6040606@stats.uwo.ca>

Murray Jorgensen wrote:
> I have not had a great amount of success installing/updating packages 
> from the "Packages" menu of Rgui under Windows XL. (Except for 
> installing from loacal zip files.)
> 
> But I am not asking for help in using these facilities because I prefer 
> to keep a folder of package zip files. On the other hand I do find it 
> tedious having to right-click "Save link as" on every individual file 
> from CRAN.
> 
> I'm sure someone knows a faster way to do it.

You probably want to use "wget".  I think a "recursive web suck" would 
suck down a whole directory from CRAN in one command:

wget -r -l1 http://cran.<mirror>.r-project.org/bin/windows/contrib/2.2/

will get all the contents of the Windows 2.2 binary directory, plus a 
bit of other junk.  You want the -l1 to limit yourself to things 
directly referenced on that page, otherwise you'll get all of CRAN.

wget is available in various places on the web; I forget where I got my 
copy.

I think there are options in various browsers to do the same thing, but 
I haven't used them.

Duncan Murdoch



From marc.kirchner at iwr.uni-heidelberg.de  Mon Oct 31 02:57:02 2005
From: marc.kirchner at iwr.uni-heidelberg.de (Marc Kirchner)
Date: Mon, 31 Oct 2005 01:57:02 +0000
Subject: [R] watershed transform
Message-ID: <20051031015657.GE4418@iwr.uni-heidelberg.de>

Omniscient r-help-subscriptors,

after consulting google quite extensively, this is my last resort: I am
in need of a watershed transform on large (sparse) 2D matrices and wonder if
someone out there has a readily implemented R version I could use - there
just is no point in reimplementing the wheel (GPL or similar is OK).

Thanks,
Marc

-- 
========================================================
Dipl. Inform. Med. Marc Kirchner
Interdisciplinary Centre for Scientific Computing (IWR)
Multidimensional Image Processing
INF 368
University of Heidelberg
D-69120 Heidelberg
Tel: ++49-6221-54 87 97
Fax: ++49-6221-54 88 50
marc.kirchner at iwr.uni-heidelberg.de

-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: Digital signature
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20051031/32eb83e6/attachment.bin

From spencer.graves at pdf.com  Mon Oct 31 03:57:12 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 30 Oct 2005 18:57:12 -0800
Subject: [R] lmer / variance-covariance matrix random effects
In-Reply-To: <434A77CE.80207@gmail.com>
References: <434A77CE.80207@gmail.com>
Message-ID: <43658808.7030000@pdf.com>

	  Have you received a reply to this post?  I haven't seen one.  I agree 
that VarCorr(lmer(...)) is "unhandy" if I want to do further 
computations with those numbers, which I often do.  The following solves 
that problem, at least for the example in the lmer VarCorr documentation:

fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy))
vc.lmer <- VarCorr(fm2)
str(vc.lmer) # to understand the structure

vc.lmer <- function(obj, sep=":"){
   vc <- show(VarCorr(obj))
   nR <- dim(vc)[1]
   nC <- dim(vc)[2]
   vc. <- as.numeric(vc[, nC-(1:0)])
   colNms <- dimnames(vc)[[2]][nC-(1:0)]
   vcNames <- vc[,1]
   if(nC>3)for(i in 2:(nC-2))
     vcNames <- paste(vcNames, vc[,i], sep=sep)
   VC <- array(vc., dim=c(nR, 2),
     dimnames=list(vcNames, colNms))
   VC
}

(tst <- vc.lmer(fm2))
                     Variance Std.Dev.
Subject:(Intercept)  627.507  25.0501
Subject:Days          35.858   5.9882
Residual:            653.589  25.5654

	  Hope this helps.
	  spencer graves

Roel de Jong wrote:

> Hello,
> 
> has someone written by chance a function to extract the 
> variance-covariance matrix from a lmer-object? I've noticed the VarCorr 
> function, but it gives unhandy output.
> 
> Regards,
> 	Roel de Jong
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From srini_iyyer_bio at yahoo.com  Mon Oct 31 07:56:39 2005
From: srini_iyyer_bio at yahoo.com (Srinivas Iyyer)
Date: Sun, 30 Oct 2005 22:56:39 -0800 (PST)
Subject: [R] Matrix operations please help
In-Reply-To: <43657589.6040606@stats.uwo.ca>
Message-ID: <20051031065639.74833.qmail@web31608.mail.mud.yahoo.com>

Dear Group, 

I have a matrix  (157 X 157 ) with correlation values.
I want to convert the unique elements into a long list
so that I can add an extra variable and plot them. 

Example:

      A   B   C   D 

alfa 1   0.3  0.8  -0.3

beta 0.2  1  -0.3  0.4

echo 0.9 -0.3  1   0.5

tang -0.5 0.5  0.4  1


I want to convert into this form:


alfa  A  1
alfa  B  0.3
alfa  C  0.8
alfa  D  -0.3
beta  A 0.2
beta  B 1
beta  C -0.3
beta  D 0.4
.......

and so on. 


I will add another variable afterwards:
var1  var2 corr   var3
alfa  A  1    grp1
alfa  B  0.3  grp1
alfa  C  0.8  grp2
alfa  D  -0.3 grp3
beta  A 0.2   grp3
beta  B 1     grp2
beta  C -0.3  grp1
beta  D 0.4   grp2
........ and so on....


I am sure there should be a way.. but I am completely
clueless.. 
Can any one help me please. 

thanks
srini



From ligges at statistik.uni-dortmund.de  Mon Oct 31 08:05:27 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 31 Oct 2005 08:05:27 +0100
Subject: [R] Matrix operations please help
In-Reply-To: <20051031065639.74833.qmail@web31608.mail.mud.yahoo.com>
References: <20051031065639.74833.qmail@web31608.mail.mud.yahoo.com>
Message-ID: <4365C237.7050201@statistik.uni-dortmund.de>

See ?reshape

Uwe Ligges


Srinivas Iyyer wrote:
> Dear Group, 
> 
> I have a matrix  (157 X 157 ) with correlation values.
> I want to convert the unique elements into a long list
> so that I can add an extra variable and plot them. 
> 
> Example:
> 
>       A   B   C   D 
> 
> alfa 1   0.3  0.8  -0.3
> 
> beta 0.2  1  -0.3  0.4
> 
> echo 0.9 -0.3  1   0.5
> 
> tang -0.5 0.5  0.4  1
> 
> 
> I want to convert into this form:
> 
> 
> alfa  A  1
> alfa  B  0.3
> alfa  C  0.8
> alfa  D  -0.3
> beta  A 0.2
> beta  B 1
> beta  C -0.3
> beta  D 0.4
> .......
> 
> and so on. 
> 
> 
> I will add another variable afterwards:
> var1  var2 corr   var3
> alfa  A  1    grp1
> alfa  B  0.3  grp1
> alfa  C  0.8  grp2
> alfa  D  -0.3 grp3
> beta  A 0.2   grp3
> beta  B 1     grp2
> beta  C -0.3  grp1
> beta  D 0.4   grp2
> ........ and so on....
> 
> 
> I am sure there should be a way.. but I am completely
> clueless.. 
> Can any one help me please. 
> 
> thanks
> srini
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From J.Fu at rug.nl  Mon Oct 31 09:18:20 2005
From: J.Fu at rug.nl (J.Fu)
Date: Mon, 31 Oct 2005 09:18:20 +0100
Subject: [R] nlme error message
Message-ID: <web-11223574@mail3.rug.nl>

Dear Friends,

I am seeking for any help on an error message in lme 
functions. I use mixed model to analyze a data with 
compound symmetric correlation structure. But I get an 
error message: "Error in corMatrix.corCompSymm(object) : 
NA/NaN/Inf in foreign function call (arg 1)". If I change 
the correlation structure to corAR1, then no error. I have 
no clue how to solve this problem. I would highly 
appreciate any help.
Thanks in advance and looking forward to any help.

JY


I attached my data and codes here:

# data: mytable
          mytrait myloc RIL
A1 0.590950330 0 1
A2 -0.315469846 -1 2
A3 -0.265690115 0 3
A4 0.342885046 0 4
A5 0.007613402 1 5
A6 0.285997884 0 6
A7 0.333841975 0 7
A8 -0.599817735 -1 8
A9 0.242621036 0 9
A10 0.518959588 1 10

cs<-corCompSymm(0.5, form=~1|RIL, fixed=T)
model<-lme(mytrait~myloc, data=mytable, random=~1|RIL, 
na.action=na.omit, correlation=cs)

Error in corMatrix.corCompSymm(object) : NA/NaN/Inf in 
foreign function call (arg 1)



From Jan.Verbesselt at biw.kuleuven.be  Mon Oct 31 09:58:52 2005
From: Jan.Verbesselt at biw.kuleuven.be (Jan Verbesselt)
Date: Mon, 31 Oct 2005 09:58:52 +0100
Subject: [R] how to optimise cross-correlation plot to study time lag
	between time-series?
Message-ID: <000001c5ddf9$50f5ac00$1145210a@agr.ad10.intern.kuleuven.ac.be>


Dear R-help,

How could a cross-correlation plot be optimized such that the relationship
between seasonal time-series can be studied?

We are working with strong seasonal time-series and derived a
cross-correlation plot to study the relationship between time-series. The
seasonal variation however strongly influences the cross-correlation plot
and the plot seems to be ?rather? symmetrical (max cross-correlation
coefficient occurs at lag 0). We would like to visualize the deviation from
the symmetrical shape such that the relationship between these two time
series can be studied. How can the symmetry be investigated by using a
cross-corr. plot (ccf())?

We tried the following:

    cross <- ccf(TS1, int.TS2, main= "")
    
    # produce the standard shape by correlating TS1 with TS1
    test <- ccf(TS1, TS1)

    # add the standard shape on the cross-correlation plot of TS1 with TS2

    plot(cross)
    par(new = T)
    plot(test$lag, test$acf, axes=F, xlab="", ylab="", col=2)
    
   
Is there another technique to visualize the difference from the symmetrical
shape? Is ts1 lagged vs. ts2?

Jan
(*Version R 2.2)


Ps. -We tried also ccf() after differencing and decompositioning but
seasonality remains in the residuals.
     -max cross-correlation mostly occurs at lag 0.


_______________________________________________________________________
Ir. Jan Verbesselt
Research Associate
Biosystems Department ~ M??-BIORES
Vital Decosterstraat 102, 3000 Leuven, Belgium
Tel: +32-16-329750???? Fax: +32-16-329760
http://gloveg.kuleuven.ac.be/
_______________________________________________________________________



Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From olaf.schenk at unibas.ch  Mon Oct 31 10:26:19 2005
From: olaf.schenk at unibas.ch (Olaf Schenk)
Date: Mon, 31 Oct 2005 10:26:19 +0100
Subject: [R] R-functions in C-Code
Message-ID: <4365E33B.7010908@unibas.ch>

Dear R users,

I would like to use several R functions from a C-code and I have read the "Introduction to the .C Interface to R". Unfortunately, my shared library with the C-code works only in cases where I use R-routines that are defined Rmath.h, eg.

*************************************
less test.c:
#include <R.h>
#include <Rinternals.h>
#include <Rmath.h>
void test(int *nrows, SEXP init,SEXP fac1, SEXP typeordi, SEXP bgratio)
{
        double sum = dnorm(1.0/1, 0, 1, 0);
}

Compiling and building shared library:
   gcc -I/usr/lib64/R/include -fPIC -O2 -c test.o test.c
   gcc -shared -L/usr/local/lib -o test.so test.o -L/usr/lib64/R/lib -lR
Calling R and loading test.so works fine:
   >dyn.load("test.so")
   >
*************************************

Now, I would like to use other R functions e.g. the mean function from
the base package:

*************************************
#include <R.h>
#include <Rinternals.h>
#include <Rmath.h>
void test(int *nrows, SEXP init,SEXP fac1, SEXP typeordi, SEXP bgratio)
{
        double sum = mean(1.0);
}

Compiling and building shared library:
   gcc -I/usr/lib64/R/include -fPIC -O2 -c test.o test.c
   gcc -shared -L/usr/local/lib -o test.so test.o -L/usr/lib64/R/lib -lR

Calling R and loading test.so results in an error:
   > dyn.load("test.so")
   Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library '/home/obc/test.so':


Any hint is welcome.

Olaf Schenk



From Roger.Bivand at nhh.no  Mon Oct 31 10:50:52 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 31 Oct 2005 10:50:52 +0100 (CET)
Subject: [R] R-functions in C-Code
In-Reply-To: <4365E33B.7010908@unibas.ch>
Message-ID: <Pine.LNX.4.44.0510311045450.17702-100000@reclus.nhh.no>

On Mon, 31 Oct 2005, Olaf Schenk wrote:

> Dear R users,
> 
> I would like to use several R functions from a C-code and I have read
> the "Introduction to the .C Interface to R". Unfortunately, my shared
> library with the C-code works only in cases where I use R-routines that
> are defined Rmath.h, eg.

Please see Chapter 5, the R API, and check which C functions are in the 
API. dnorm() is - though you've been lucky (or unlucky) because the 
arguments appear to agree. So your example seems to work.

However, the mean() function is an R function, not in the R API. For
executing R code from C, see Chapter 4, section 9, "Evaluating R
expressions from C".

> 
> *************************************
> less test.c:
> #include <R.h>
> #include <Rinternals.h>
> #include <Rmath.h>
> void test(int *nrows, SEXP init,SEXP fac1, SEXP typeordi, SEXP bgratio)
> {
>         double sum = dnorm(1.0/1, 0, 1, 0);
> }
> 
> Compiling and building shared library:
>    gcc -I/usr/lib64/R/include -fPIC -O2 -c test.o test.c
>    gcc -shared -L/usr/local/lib -o test.so test.o -L/usr/lib64/R/lib -lR
> Calling R and loading test.so works fine:
>    >dyn.load("test.so")
>    >
> *************************************
> 
> Now, I would like to use other R functions e.g. the mean function from
> the base package:
> 
> *************************************
> #include <R.h>
> #include <Rinternals.h>
> #include <Rmath.h>
> void test(int *nrows, SEXP init,SEXP fac1, SEXP typeordi, SEXP bgratio)
> {
>         double sum = mean(1.0);
> }
> 
> Compiling and building shared library:
>    gcc -I/usr/lib64/R/include -fPIC -O2 -c test.o test.c
>    gcc -shared -L/usr/local/lib -o test.so test.o -L/usr/lib64/R/lib -lR
> 
> Calling R and loading test.so results in an error:
>    > dyn.load("test.so")
>    Error in dyn.load(x, as.logical(local), as.logical(now)) :
>         unable to load shared library '/home/obc/test.so':
> 
> 
> Any hint is welcome.
> 
> Olaf Schenk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From samrobertsmith at yahoo.com  Mon Oct 31 11:22:05 2005
From: samrobertsmith at yahoo.com (Robert)
Date: Mon, 31 Oct 2005 02:22:05 -0800 (PST)
Subject: [R] significant test
Message-ID: <20051031102205.33334.qmail@web30614.mail.mud.yahoo.com>

I have two groups of data and want to test how the
mean of one group is significant different from the
mean of the other group of data.
which R function can be used?
Thanks.



From francoisromain at free.fr  Mon Oct 31 11:45:10 2005
From: francoisromain at free.fr (Romain Francois)
Date: Mon, 31 Oct 2005 11:45:10 +0100
Subject: [R] significant test
In-Reply-To: <20051031102205.33334.qmail@web30614.mail.mud.yahoo.com>
References: <20051031102205.33334.qmail@web30614.mail.mud.yahoo.com>
Message-ID: <4365F5B6.4050203@free.fr>

Le 31.10.2005 11:22, Robert a ??crit :

>I have two groups of data and want to test how the
>mean of one group is significant different from the
>mean of the other group of data.
>which R function can be used?
>Thanks.
>  
>
Hi,

t.test if you assume normality
wilcox.test otherwise

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+



From ripley at stats.ox.ac.uk  Mon Oct 31 13:45:10 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 31 Oct 2005 12:45:10 +0000 (GMT)
Subject: [R] significant test
In-Reply-To: <4365F5B6.4050203@free.fr>
References: <20051031102205.33334.qmail@web30614.mail.mud.yahoo.com>
	<4365F5B6.4050203@free.fr>
Message-ID: <Pine.LNX.4.61.0510311108070.14052@gannet.stats>

On Mon, 31 Oct 2005, Romain Francois wrote:

> Le 31.10.2005 11:22, Robert a ?crit :
>
>> I have two groups of data and want to test how the
>> mean of one group is significant different from the
>> mean of the other group of data.
>> which R function can be used?
>> Thanks.
>
> t.test if you assume normality
> wilcox.test otherwise

Sorry, no.  The Wilcoxon test does NOT test a difference in means: its 
null hypothesis is that the two samples came from the same continuous 
distribution, a much narrower assumption.  (It is sensitive to differences 
in variances, for example, and is probably closer to testing a difference 
in medians than means where the shapes of the two samples differ)

The Welch two-sample t-test does test exactly the null hypothesis stated 
under normality, and it is pretty insensitive to quite large departures 
from normality.  It is unlikely (but possible) that means are of primary 
interest in very-non-normal distributions.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From francoisromain at free.fr  Mon Oct 31 13:56:29 2005
From: francoisromain at free.fr (Romain Francois)
Date: Mon, 31 Oct 2005 13:56:29 +0100
Subject: [R] significant test
In-Reply-To: <Pine.LNX.4.61.0510311108070.14052@gannet.stats>
References: <20051031102205.33334.qmail@web30614.mail.mud.yahoo.com>
	<4365F5B6.4050203@free.fr>
	<Pine.LNX.4.61.0510311108070.14052@gannet.stats>
Message-ID: <4366147D.5030305@free.fr>

Le 31.10.2005 13:45, Prof Brian Ripley a ??crit :

> On Mon, 31 Oct 2005, Romain Francois wrote:
>
>> Le 31.10.2005 11:22, Robert a ??crit :
>>
>>> I have two groups of data and want to test how the
>>> mean of one group is significant different from the
>>> mean of the other group of data.
>>> which R function can be used?
>>> Thanks.
>>
>> t.test if you assume normality
>> wilcox.test otherwise
>
> Sorry, no.  

*I* should be sorry.
Thanks for the correction.

> The Wilcoxon test does NOT test a difference in means: its null 
> hypothesis is that the two samples came from the same continuous 
> distribution, a much narrower assumption.  (It is sensitive to 
> differences in variances, for example, and is probably closer to 
> testing a difference in medians than means where the shapes of the two 
> samples differ)
>
> The Welch two-sample t-test does test exactly the null hypothesis 
> stated under normality, and it is pretty insensitive to quite large 
> departures from normality.  It is unlikely (but possible) that means 
> are of primary interest in very-non-normal distributions.



-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+



From I.Visser at uva.nl  Mon Oct 31 14:38:08 2005
From: I.Visser at uva.nl (Ingmar Visser)
Date: Mon, 31 Oct 2005 14:38:08 +0100
Subject: [R] information matrix in random effects model
Message-ID: <BF8BDCD0.9ED3%I.Visser@uva.nl>


I use the lme function from the nlme library (or alternatively from the
Matrix library) to estimate a random effects model. Both functions return
the covariance matrix of the estimated parameters. I have the following
question: 
Is it possible to retrieve the information matrix of such a model (ie from
the fitted object)? In particular, the information matrix can be computed as
a sum of individual contributions:
Sum_i H_i = H,
where H_i are the contributions of each case to the Hessian matrix H.
Are these individual contributions computed somewhere in either of the
functions to estimate random effects models, and is it possible to extract
them somehow from the fitted objects?

ingmar
-- 
Ingmar Visser
Department of Psychology
Roetersstraat 15 (building A room 1009)
1018 WB Amsterdam
tel.: +31-20-5256735



From f_bresson at yahoo.fr  Mon Oct 31 14:47:32 2005
From: f_bresson at yahoo.fr (Florent Bresson)
Date: Mon, 31 Oct 2005 14:47:32 +0100 (CET)
Subject: [R] Applying a function to a vector
Message-ID: <20051031134733.19668.qmail@web26802.mail.ukl.yahoo.com>

I have defined a function to compute the value of a
beta distribution of the second kind (the existing
beta distribution of th stats package is the beta
distribution of the first kind). It works perfectly
for a single value, but I want to apply it to a vector
of 22 000 values. I can use a loop for the calculation
of each value but it runs very very slowly.
So, what can I change ?

Hers's the function : 
p <-  c(1,1)
y <-  1
z <-  1
truc  <-  function(y)  {y^(p[1]-1)/(1+y)^(p[1]+p[2])}
pbeta2  <-  function(z,p)
1/beta(p[1],p[2])*integrate(truc,0,z)$value

machin <- pbeta2(vector,p) just return a single value

Thanks for your help



From paulojus at est.ufpr.br  Mon Oct 31 15:05:41 2005
From: paulojus at est.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Mon, 31 Oct 2005 12:05:41 -0200 (BRST)
Subject: [R] Applying a function to a vector
In-Reply-To: <20051031134733.19668.qmail@web26802.mail.ukl.yahoo.com>
References: <20051031134733.19668.qmail@web26802.mail.ukl.yahoo.com>
Message-ID: <Pine.LNX.4.63.0510311205140.26318@est.ufpr.br>

Florent
have a look at:
> help(sapply)


On Mon, 31 Oct 2005, Florent Bresson wrote:

> I have defined a function to compute the value of a
> beta distribution of the second kind (the existing
> beta distribution of th stats package is the beta
> distribution of the first kind). It works perfectly
> for a single value, but I want to apply it to a vector
> of 22 000 values. I can use a loop for the calculation
> of each value but it runs very very slowly.
> So, what can I change ?
>
> Hers's the function :
> p <-  c(1,1)
> y <-  1
> z <-  1
> truc  <-  function(y)  {y^(p[1]-1)/(1+y)^(p[1]+p[2])}
> pbeta2  <-  function(z,p)
> 1/beta(p[1],p[2])*integrate(truc,0,z)$value
>
> machin <- pbeta2(vector,p) just return a single value
>
> Thanks for your help
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>

Paulo Justiniano Ribeiro Jr
LEG (Laborat?rio de Estat?stica e Geoinforma??o)
Departamento de Estat?stica
Universidade Federal do Paran?
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 3361 3573
Fax: (+55) 41 3361 3141
e-mail: paulojus at est.ufpr.br
http://www.est.ufpr.br/~paulojus

From f_bresson at yahoo.fr  Mon Oct 31 15:40:15 2005
From: f_bresson at yahoo.fr (Florent Bresson)
Date: Mon, 31 Oct 2005 15:40:15 +0100 (CET)
Subject: [R]  Applying a function to a vector
Message-ID: <20051031144015.64796.qmail@web26805.mail.ukl.yahoo.com>

I just have a try with sapply. The problem is that my
function pbeta2 has two parameters z and p (wich is a
vector of two parameters). If I use sapply , R returns
a message incicating that parameter p is missing. It
is a problem since both z and p are varying along my
data.frame.

>Florent
>have a look at:
> help(sapply)


>On Mon, 31 Oct 2005, Florent Bresson wrote:

>> beta distribution of the second kind (the existing
>> beta distribution of th stats package is the beta
>> distribution of the first kind). It works perfectly
>> for a single value, but I want to apply it to a
vector
>> of 22 000 values. I can use a loop for the
calculation
>> of each value but it runs very very slowly.
>> So, what can I change ?
>>
>> Here's the function :
>> p <-  c(1,1)
>> y <-  1
>> z <-  1
>> truc  <-  function(y) 
{y^(p[1]-1)/(1+y)^(p[1]+p[2])}
>> pbeta2  <-  function(z,p)
>> 1/beta(p[1],p[2])*integrate(truc,0,z)$value
>>
>> machin <- pbeta2(vector,p) just return a single
value
>>
>> Thanks for your help
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>>
>>

>Paulo Justiniano Ribeiro Jr
>LEG (Laborat??rio de Estat??stica e Geoinforma????o)
>Departamento de Estat??stica
>Universidade Federal do Paran??
>Caixa Postal 19.081
>CEP 81.531-990
>Curitiba, PR  -  Brasil
>Tel: (+55) 41 3361 3573
>Fax: (+55) 41 3361 3141
>e-mail: paulojus at est.ufpr.br
>http://www.est.ufpr.br/~paulojus



From tlumley at u.washington.edu  Mon Oct 31 16:10:36 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 31 Oct 2005 07:10:36 -0800 (PST)
Subject: [R] Applying a function to a vector
In-Reply-To: <20051031144015.64796.qmail@web26805.mail.ukl.yahoo.com>
References: <20051031144015.64796.qmail@web26805.mail.ukl.yahoo.com>
Message-ID: <Pine.LNX.4.63a.0510310703550.23714@homer22.u.washington.edu>

On Mon, 31 Oct 2005, Florent Bresson wrote:

> I just have a try with sapply. The problem is that my
> function pbeta2 has two parameters z and p (wich is a
> vector of two parameters). If I use sapply , R returns
> a message incicating that parameter p is missing. It
> is a problem since both z and p are varying along my
> data.frame.

You would need mapply().  It won't help, though.  Most of the time is 
presumably being spent in all the calls to integrate, so mapply() or 
sapply() won't be much faster than a loop.


According to Google, the VGAM R package 
http://www.stat.auckland.ac.nz/~yee/
claims to have the beta distributions of the second kind.


 	-thomas


>> Florent
>> have a look at:
>> help(sapply)
>
>
>> On Mon, 31 Oct 2005, Florent Bresson wrote:
>
>>> beta distribution of the second kind (the existing
>>> beta distribution of th stats package is the beta
>>> distribution of the first kind). It works perfectly
>>> for a single value, but I want to apply it to a
> vector
>>> of 22 000 values. I can use a loop for the
> calculation
>>> of each value but it runs very very slowly.
>>> So, what can I change ?
>>>
>>> Here's the function :
>>> p <-  c(1,1)
>>> y <-  1
>>> z <-  1
>>> truc  <-  function(y)
> {y^(p[1]-1)/(1+y)^(p[1]+p[2])}
>>> pbeta2  <-  function(z,p)
>>> 1/beta(p[1],p[2])*integrate(truc,0,z)$value
>>>
>>> machin <- pbeta2(vector,p) just return a single
> value
>>>
>>> Thanks for your help
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>>>
>>>
>
>> Paulo Justiniano Ribeiro Jr
>> LEG (Laborat?rio de Estat?stica e Geoinforma??o)
>> Departamento de Estat?stica
>> Universidade Federal do Paran?
>> Caixa Postal 19.081
>> CEP 81.531-990
>> Curitiba, PR  -  Brasil
>> Tel: (+55) 41 3361 3573
>> Fax: (+55) 41 3361 3141
>> e-mail: paulojus at est.ufpr.br
>> http://www.est.ufpr.br/~paulojus
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

From quantpm at yahoo.com  Mon Oct 31 16:37:55 2005
From: quantpm at yahoo.com (t c)
Date: Mon, 31 Oct 2005 07:37:55 -0800 (PST)
Subject: [R] getting last 2 charcters of a string, other "text" functions?
Message-ID: <20051031153755.80990.qmail@web35006.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051031/b902a396/attachment.pl

From ripley at stats.ox.ac.uk  Mon Oct 31 16:39:33 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 31 Oct 2005 15:39:33 +0000 (GMT)
Subject: [R] Applying a function to a vector
In-Reply-To: <Pine.LNX.4.63a.0510310703550.23714@homer22.u.washington.edu>
References: <20051031144015.64796.qmail@web26805.mail.ukl.yahoo.com>
	<Pine.LNX.4.63a.0510310703550.23714@homer22.u.washington.edu>
Message-ID: <Pine.LNX.4.61.0510311534190.30267@gannet.stats>

On Mon, 31 Oct 2005, Thomas Lumley wrote:

> On Mon, 31 Oct 2005, Florent Bresson wrote:
>
>> I just have a try with sapply. The problem is that my
>> function pbeta2 has two parameters z and p (wich is a
>> vector of two parameters). If I use sapply , R returns
>> a message incicating that parameter p is missing. It
>> is a problem since both z and p are varying along my
>> data.frame.
>
> You would need mapply().  It won't help, though.  Most of the time is 
> presumably being spent in all the calls to integrate, so mapply() or sapply() 
> won't be much faster than a loop.
>
>
> According to Google, the VGAM R package http://www.stat.auckland.ac.nz/~yee/
> claims to have the beta distributions of the second kind.

It has ML fitting for such distributions.

I think a reasonable answer is to make a function to approximate the 
indefinite integral via linear or spline interpolation.  Then you can 
replace 22,000 numerical integrations by interpolation from a few hundred 
values (at most).


>>> On Mon, 31 Oct 2005, Florent Bresson wrote:
>> 
>>>> beta distribution of the second kind (the existing
>>>> beta distribution of th stats package is the beta
>>>> distribution of the first kind). It works perfectly
>>>> for a single value, but I want to apply it to a
>> vector
>>>> of 22 000 values. I can use a loop for the
>> calculation
>>>> of each value but it runs very very slowly.
>>>> So, what can I change ?
>>>> 
>>>> Here's the function :
>>>> p <-  c(1,1)
>>>> y <-  1
>>>> z <-  1
>>>> truc  <-  function(y)
>> {y^(p[1]-1)/(1+y)^(p[1]+p[2])}
>>>> pbeta2  <-  function(z,p)
>>>> 1/beta(p[1],p[2])*integrate(truc,0,z)$value
>>>> 
>>>> machin <- pbeta2(vector,p) just return a single
>> value

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From cgb at datanalytics.com  Mon Oct 31 16:38:58 2005
From: cgb at datanalytics.com (Carlos J. Gil Bellosta)
Date: Mon, 31 Oct 2005 16:38:58 +0100
Subject: [R] Applying a function to a vector
In-Reply-To: <20051031144015.64796.qmail@web26805.mail.ukl.yahoo.com>
References: <20051031144015.64796.qmail@web26805.mail.ukl.yahoo.com>
Message-ID: <20051031163858.jvr5rhzmy8mkow0s@webmail.datanalytics.com>

You should then try apply. See ?apply.

For instance:


a <- matrix(c(1:10), 5, 2)
apply(a, 1, function(x) x[1] + 100 * x[2])

This way you can disaggregate the components of your input (that is not a
singleton) and use them inside your function separately.

Carlos J. Gil Bellosta
http://www.datanalytics.com

Quoting Florent Bresson <f_bresson at yahoo.fr>:

> I just have a try with sapply. The problem is that my
> function pbeta2 has two parameters z and p (wich is a
> vector of two parameters). If I use sapply , R returns
> a message incicating that parameter p is missing. It
> is a problem since both z and p are varying along my
> data.frame.



From ltorgo at liacc.up.pt  Mon Oct 31 16:46:24 2005
From: ltorgo at liacc.up.pt (=?iso-8859-1?q?Lu=EDs_Torgo?=)
Date: Mon, 31 Oct 2005 16:46:24 +0100
Subject: [R] Sweave (R?) font encoding problems
Message-ID: <200510311546.24883.ltorgo@liacc.up.pt>

Dear R list,

I'm having some problems with font encodings when using R+Sweave+Latex in my 
native language: Portuguese.

My environment:
Kubuntu 5.10 Linux
$> uname -a
Linux nassa 2.6.12-9-686 #1 Mon Oct 10 13:25:32 BST 2005 i686 GNU/Linux

R> R.version
         _                
platform i486-pc-linux-gnu
arch     i486             
os       linux-gnu        
system   i486, linux-gnu  
status                    
major    2                
minor    1.1              
year     2005             
month    06               
day      20               
language R  
R> Sys.getlocale()
[1] 
"LC_CTYPE=pt_PT.utf-8;LC_NUMERIC=C;LC_TIME=pt_PT.utf-8;LC_COLLATE=pt_PT.utf-8;LC_MONETARY=pt_PT.utf-8;LC_MESSAGES=pt_PT.utf-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C"
R> localeToCharset()
[1] "ISO8859-1"


Here is a small example trying to replicate my problems:

File:exp.Rnw
================================
\documentclass[10pt,twoside]{article}
\usepackage[dvips]{graphicx}
\usepackage[portuges]{babel}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}

\begin{document}

\section{Introdu????o}

Isto ?? uma experi??ncia.

\begin{figure}[b]
\centering
<<echo=false,fig=true,width=10,height=10>>=
barras(1)
@
\caption{Distribui????o dos valores percentuais.}
\label{fig:idade}
\end{figure}

\end{document}
=================================

The problem occurs when I Sweave this file using the command:
R> Sweave('exp.Rnw')

The generated exp.tex file gets these contents:
=================================
\documentclass[10pt,twoside]{article}
\usepackage[dvips]{graphicx}
\usepackage[portuges]{babel}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{/usr/lib/R/share/texmf/Sweave}
\begin{document}

\section{Introdu????????o}

Isto ???? uma experi????ncia.

\begin{figure}[b]
\centering
\includegraphics{exp-001}
\caption{Distribui????????o dos valores percentuais.}
\label{fig:idade}
\end{figure}

\end{document}
=================================

All Portuguese  characters were "spoiled".  So apparently the Sweave function 
is "translating" my original font encoding

I suspect that this is a problem related to the recent internationalization 
changes in R, as this same file/process was previously (around a year ago I 
think) working correctly for me.

I've read several documentation on these internationalization issues in R and 
browsed the mailing list. As a result, because initially I didn't have R 
working with the pt_PT.utf-8 locale, I've installed the PT language support 
package for my OS, expecting that this would solve the "problem".  Apparently 
I'm missing something else, so I wonder if someone could give me a hint on 
how to solve this.

Thanks,
Luis Torgo

-- 
Luis Torgo
    FEP/LIACC, University of Porto   Phone : (+351) 22 339 20 93
    Machine Learning Group           Fax   : (+351) 22 339 20 99
    R. de Ceuta, 118, 6o             email : ltorgo at liacc.up.pt
    4050-190 PORTO - PORTUGAL        WWW   : http://www.liacc.up.pt/~ltorgo



From ccleland at optonline.net  Mon Oct 31 16:48:00 2005
From: ccleland at optonline.net (Chuck Cleland)
Date: Mon, 31 Oct 2005 10:48:00 -0500
Subject: [R] getting last 2 charcters of a string,
	other "text" functions?
In-Reply-To: <20051031153755.80990.qmail@web35006.mail.mud.yahoo.com>
References: <20051031153755.80990.qmail@web35006.mail.mud.yahoo.com>
Message-ID: <43663CB0.3010900@optonline.net>

?nchar
?substr

rightmost <- function(x, y){substr(x, start=nchar(x) - (y - 1), 
stop=nchar(x))}

 > x <- c("asfef", "qwerty", "yuiop[", "b", "stuff.blah.yech")

 > rightmost(x, 2)
[1] "ef" "ty" "p[" "b"  "ch"

 > rightmost(x, 3)
[1] "fef" "rty" "op[" "b"   "ech"

t c wrote:
> I wish to obtain the right-most n characters of a character string?  What is the appropriate function?
> 
> 
> 		
> ---------------------------------
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From sundar.dorai-raj at pdf.com  Mon Oct 31 16:49:44 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Mon, 31 Oct 2005 09:49:44 -0600
Subject: [R] getting last 2 charcters of a string,
	other "text" functions?
In-Reply-To: <20051031153755.80990.qmail@web35006.mail.mud.yahoo.com>
References: <20051031153755.80990.qmail@web35006.mail.mud.yahoo.com>
Message-ID: <43663D18.1030605@pdf.com>



t c wrote:
> I wish to obtain the right-most n characters of a character string?  What is the appropriate function?
> 

See ?nchar ?substr

k <- 2
x <- "abcdef"
nc <- nchar(x)
substr(x, nc - k + 1, nc)

HTH,

--sundar



From cgb at datanalytics.com  Mon Oct 31 16:52:00 2005
From: cgb at datanalytics.com (Carlos J. Gil Bellosta)
Date: Mon, 31 Oct 2005 16:52:00 +0100
Subject: [R] getting last 2 charcters of a string,
	other "text"	functions?
In-Reply-To: <20051031153755.80990.qmail@web35006.mail.mud.yahoo.com>
References: <20051031153755.80990.qmail@web35006.mail.mud.yahoo.com>
Message-ID: <20051031165200.45mwdufla4o4g4ww@webmail.datanalytics.com>

gsub(".*(..)$", "\\1", "i only want the last two characters")

This is only a matter of finding the right regular expression. Use Google to
find a good tutorial on them.

Carlos J. Gil Bellosta
http://www.datanalytics.com


Quoting t c <quantpm at yahoo.com>:

> I wish to obtain the right-most n characters of a character string?  
> What is the appropriate function?
>
>
>
> ---------------------------------
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From tobias.verbeke at telenet.be  Mon Oct 31 17:01:56 2005
From: tobias.verbeke at telenet.be (Tobias Verbeke)
Date: Mon, 31 Oct 2005 17:01:56 +0100
Subject: [R] getting last 2 charcters of a string,
	other "text" functions?
In-Reply-To: <20051031153755.80990.qmail@web35006.mail.mud.yahoo.com>
References: <20051031153755.80990.qmail@web35006.mail.mud.yahoo.com>
Message-ID: <43663FF4.5020608@telenet.be>

t c wrote:

>I wish to obtain the right-most n characters of a character string?  What is the appropriate function?
>  
>
You could make one yourself:

rightmostn <- function(x, n){
  res <- substr(x, nchar(x)-n+1, nchar(x))
  return(res)
}
magic <- "hocuspocus"
rightmostn(magic, 5)
[1] "pocus"

HTH,
Tobias

>
>		
>---------------------------------
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>



From efg at stowers-institute.org  Mon Oct 31 16:59:10 2005
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Mon, 31 Oct 2005 09:59:10 -0600
Subject: [R] getting last 2 charcters of a string,
	other "text" functions?
References: <20051031153755.80990.qmail@web35006.mail.mud.yahoo.com>
Message-ID: <dk5f0f$ns2$1@sea.gmane.org>

"t c" <quantpm at yahoo.com> wrote in message
news:20051031153755.80990.qmail at web35006.mail.mud.yahoo.com...
> I wish to obtain the right-most n characters of a character string?  What
is the appropriate function?

substr will work:

> x <- c("abcd", "xyz")

> N <- 2
> substr(x, nchar(x)-N+1, nchar(x))
[1] "cd" "yz"

> N <- 3
> substr(x, nchar(x)-N+1, nchar(x))
[1] "bcd" "xyz"

efg



From f_bresson at yahoo.fr  Mon Oct 31 17:10:33 2005
From: f_bresson at yahoo.fr (Florent Bresson)
Date: Mon, 31 Oct 2005 17:10:33 +0100 (CET)
Subject: [R] Applying a function to a vector
In-Reply-To: <Pine.LNX.4.63a.0510310703550.23714@homer22.u.washington.edu>
Message-ID: <20051031161033.36672.qmail@web26806.mail.ukl.yahoo.com>

It works really faster with mapply. I just had to
change my fonction from pbeta2(z,p) with p=c(p1,p2) to
pbeta2(z,p1,p2). Thanks for the tip.

--- Thomas Lumley <tlumley at u.washington.edu> a ??crit :

> On Mon, 31 Oct 2005, Florent Bresson wrote:
> 
> > I just have a try with sapply. The problem is that
> my
> > function pbeta2 has two parameters z and p (wich
> is a
> > vector of two parameters). If I use sapply , R
> returns
> > a message incicating that parameter p is missing.
> It
> > is a problem since both z and p are varying along
> my
> > data.frame.
> 
> You would need mapply().  It won't help, though. 
> Most of the time is 
> presumably being spent in all the calls to
> integrate, so mapply() or 
> sapply() won't be much faster than a loop.
> 
> 
> According to Google, the VGAM R package 
> http://www.stat.auckland.ac.nz/~yee/
> claims to have the beta distributions of the second
> kind.
> 
> 
>  	-thomas
> 
> 
> >> Florent
> >> have a look at:
> >> help(sapply)
> >
> >
> >> On Mon, 31 Oct 2005, Florent Bresson wrote:
> >
> >>> beta distribution of the second kind (the
> existing
> >>> beta distribution of th stats package is the
> beta
> >>> distribution of the first kind). It works
> perfectly
> >>> for a single value, but I want to apply it to a
> > vector
> >>> of 22 000 values. I can use a loop for the
> > calculation
> >>> of each value but it runs very very slowly.
> >>> So, what can I change ?
> >>>
> >>> Here's the function :
> >>> p <-  c(1,1)
> >>> y <-  1
> >>> z <-  1
> >>> truc  <-  function(y)
> > {y^(p[1]-1)/(1+y)^(p[1]+p[2])}
> >>> pbeta2  <-  function(z,p)
> >>> 1/beta(p[1],p[2])*integrate(truc,0,z)$value
> >>>
> >>> machin <- pbeta2(vector,p) just return a single
> > value
> >>>
> >>> Thanks for your help
> >>>
> >>> ______________________________________________
> >>> R-help at stat.math.ethz.ch mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >>>
> >>>
> >
> >> Paulo Justiniano Ribeiro Jr
> >> LEG (Laborat??rio de Estat??stica e Geoinforma????o)
> >> Departamento de Estat??stica
> >> Universidade Federal do Paran??
> >> Caixa Postal 19.081
> >> CEP 81.531-990
> >> Curitiba, PR  -  Brasil
> >> Tel: (+55) 41 3361 3573
> >> Fax: (+55) 41 3361 3141
> >> e-mail: paulojus at est.ufpr.br
> >> http://www.est.ufpr.br/~paulojus
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
> 
> Thomas Lumley			Assoc. Professor, Biostatistics
> tlumley at u.washington.edu	University of Washington,
Seattle



From dschad at umich.edu  Mon Oct 31 17:12:17 2005
From: dschad at umich.edu (dschad@umich.edu)
Date: Mon, 31 Oct 2005 11:12:17 -0500
Subject: [R] How can I test temporal autocorrelation of binary data?
Message-ID: <20051031111217.bgrinc66vscso0o4@web.mail.umich.edu>

Hi,

I have a binary (o/1 - coded) data set and want to test it's autocorrelation
structure. Is that function implemented in R?
Can I use the ACF - funtion with binary data?

Thanks for your help,
Daniel



From ggrothendieck at gmail.com  Mon Oct 31 17:24:46 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 31 Oct 2005 11:24:46 -0500
Subject: [R] getting last 2 charcters of a string,
	other "text" functions?
In-Reply-To: <20051031165200.45mwdufla4o4g4ww@webmail.datanalytics.com>
References: <20051031153755.80990.qmail@web35006.mail.mud.yahoo.com>
	<20051031165200.45mwdufla4o4g4ww@webmail.datanalytics.com>
Message-ID: <971536df0510310824h92cfbf0k789cca6b6e31df26@mail.gmail.com>

Note that this one can be slightly simplified by using sub instead of gsub
(since you only will have one match anyways) and the $ is not needed
since .* will consume the maximal matching string:

sub(".*(..)", "\\1", mystring)


On 10/31/05, Carlos J. Gil Bellosta <cgb at datanalytics.com> wrote:
> gsub(".*(..)$", "\\1", "i only want the last two characters")
>
> This is only a matter of finding the right regular expression. Use Google to
> find a good tutorial on them.
>
> Carlos J. Gil Bellosta
> http://www.datanalytics.com
>
>
> Quoting t c <quantpm at yahoo.com>:
>
> > I wish to obtain the right-most n characters of a character string?
> > What is the appropriate function?
> >
> >
> >
> > ---------------------------------
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Qinghong.Li at rdmo.nestle.com  Mon Oct 31 17:26:11 2005
From: Qinghong.Li at rdmo.nestle.com (Li,Qinghong,ST.LOUIS,Molecular Biology)
Date: Mon, 31 Oct 2005 10:26:11 -0600
Subject: [R] write.table call
Message-ID: <2BA2B7291D5DC6409FD53CB7C01F0D990183B6AC@usslre00.nestle.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051031/ecf5f3b2/attachment.pl

From Friedrich.Leisch at tuwien.ac.at  Sat Oct 29 04:17:28 2005
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Sat, 29 Oct 2005 04:17:28 +0200
Subject: [R] Sweave (R?) font encoding problems
In-Reply-To: <200510311546.24883.ltorgo@liacc.up.pt>
References: <200510311546.24883.ltorgo@liacc.up.pt>
Message-ID: <17250.56248.201478.859496@celebrian.ci.tuwien.ac.at>

>>>>> On Mon, 31 Oct 2005 16:46:24 +0100,
>>>>> Lu??s Torgo (LT) wrote:

  > Dear R list,
  > I'm having some problems with font encodings when using R+Sweave+Latex in my 
  > native language: Portuguese.

  > My environment:
  > Kubuntu 5.10 Linux
  > $> uname -a
  > Linux nassa 2.6.12-9-686 #1 Mon Oct 10 13:25:32 BST 2005 i686 GNU/Linux

  R> R.version
  >          _                
  > platform i486-pc-linux-gnu
  > arch     i486             
  > os       linux-gnu        
  > system   i486, linux-gnu  
  > status                    
  > major    2                
  > minor    1.1              
  > year     2005             
  > month    06               
  > day      20               
  > language R  
  R> Sys.getlocale()
  > [1] 
  > "LC_CTYPE=pt_PT.utf-8;LC_NUMERIC=C;LC_TIME=pt_PT.utf-8;LC_COLLATE=pt_PT.utf-8;LC_MONETARY=pt_PT.utf-8;LC_MESSAGES=pt_PT.utf-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C"
  R> localeToCharset()
  > [1] "ISO8859-1"


  > Here is a small example trying to replicate my problems:

  > File:exp.Rnw
  > ================================
  > \documentclass[10pt,twoside]{article}
  > \usepackage[dvips]{graphicx}
  > \usepackage[portuges]{babel}
  > \usepackage[latin1]{inputenc}
  > \usepackage[T1]{fontenc}

You use a UTF-8 locale but load latin1 input encoding in latex -> that
cannot work.

Try

\usepackage[utf8]{inputenc}

and no special fontenc setting -> works for me for Austrian German.

HTH,

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f??r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit??t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra??e 8-10/1071
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch



From jeffrow51 at hotmail.com  Mon Oct 31 18:01:12 2005
From: jeffrow51 at hotmail.com (Jeff Row)
Date: Mon, 31 Oct 2005 12:01:12 -0500
Subject: [R] GLM
Message-ID: <BAY104-F34B15A7B62E3DAD90FDF2EAE6C0@phx.gbl>

Hello R-users,

I am a relatively new user of R and I have a question regarding glm. I want 
to run the function GLM on multiple individuals separately and then get 
means for summary statistics such as AIC and coef. Is there a way to do this 
in R without separately going through each individual and subsetting the 
dataset, getting the summary statistics and averaging them? For example, in 
the dataset below I would like to run the function:

>glm(Type~Dwater+Habitat, data=example, family=binomial())

on each individual separately and then get the average for the coef's Dwater 
and Habitat for the 3 individuals.

>example
   Individual Type Dwater Habitat
1           1    0     40       0
2           1    1     80       1
3           1    0     30       0
4           1    1     90       0
5           2    0     15       1
6           2    1     95       1
7           2    0     20       0
8           2    1     75       1
9           3    0     15       0
10          3    1     60       1
11          3    0     10       1
12          3    1     95       0

Thanks,

Jeff.



From p.dalgaard at biostat.ku.dk  Mon Oct 31 18:25:08 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 31 Oct 2005 18:25:08 +0100
Subject: [R] significant test
In-Reply-To: <Pine.LNX.4.61.0510311108070.14052@gannet.stats>
References: <20051031102205.33334.qmail@web30614.mail.mud.yahoo.com>
	<4365F5B6.4050203@free.fr>
	<Pine.LNX.4.61.0510311108070.14052@gannet.stats>
Message-ID: <x2ll09lhu3.fsf@viggo.kubism.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> Sorry, no.  The Wilcoxon test does NOT test a difference in means: its
> null hypothesis is that the two samples came from the same continuous
> distribution, a much narrower assumption.  (It is sensitive to
> differences in variances, for example, and is probably closer to
> testing a difference in medians than means where the shapes of the two
> samples differ)

Actually, it is quite easy to come up with examples where the median
is identical but Wilcoxon still comes out significant, most often if
the distribution has more than 50% zeros in both groups -- think
"functional impairment" or "alcohol consumption on a weekday". 
The distribution is not continuous in those cases, but wilcox.test
deals with the resulting ties. The test statistic is directly related
to the sign of the difference between a random observation from each
group, i.e. P(X > Y) / P(X != Y) which can be assumed to be 0.5 under
the null.


-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Mon Oct 31 18:26:01 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 31 Oct 2005 17:26:01 +0000 (GMT)
Subject: [R] Sweave (R?) font encoding problems
In-Reply-To: <200510311546.24883.ltorgo@liacc.up.pt>
References: <200510311546.24883.ltorgo@liacc.up.pt>
Message-ID: <Pine.LNX.4.61.0510311723220.31512@gannet.stats>

You are using UTF-8 and declaring latin1.  It is your use of UTF-8
that will have changed, not R.

On Mon, 31 Oct 2005, Lu?s Torgo wrote:

> Dear R list,
>
> I'm having some problems with font encodings when using R+Sweave+Latex in my
> native language: Portuguese.
>
> My environment:
> Kubuntu 5.10 Linux
> $> uname -a
> Linux nassa 2.6.12-9-686 #1 Mon Oct 10 13:25:32 BST 2005 i686 GNU/Linux
>
> R> R.version
>         _
> platform i486-pc-linux-gnu
> arch     i486
> os       linux-gnu
> system   i486, linux-gnu
> status
> major    2
> minor    1.1
> year     2005
> month    06
> day      20
> language R
> R> Sys.getlocale()
> [1]
> "LC_CTYPE=pt_PT.utf-8;LC_NUMERIC=C;LC_TIME=pt_PT.utf-8;LC_COLLATE=pt_PT.utf-8;LC_MONETARY=pt_PT.utf-8;LC_MESSAGES=pt_PT.utf-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C"
> R> localeToCharset()
> [1] "ISO8859-1"
>
>
> Here is a small example trying to replicate my problems:
>
> File:exp.Rnw
> ================================
> \documentclass[10pt,twoside]{article}
> \usepackage[dvips]{graphicx}
> \usepackage[portuges]{babel}
> \usepackage[latin1]{inputenc}
> \usepackage[T1]{fontenc}
>
> \begin{document}
>
> \section{Introdu??o}
>
> Isto ? uma experi?ncia.
>
> \begin{figure}[b]
> \centering
> <<echo=false,fig=true,width=10,height=10>>=
> barras(1)
> @
> \caption{Distribui??o dos valores percentuais.}
> \label{fig:idade}
> \end{figure}
>
> \end{document}
> =================================
>
> The problem occurs when I Sweave this file using the command:
> R> Sweave('exp.Rnw')
>
> The generated exp.tex file gets these contents:
> =================================
> \documentclass[10pt,twoside]{article}
> \usepackage[dvips]{graphicx}
> \usepackage[portuges]{babel}
> \usepackage[latin1]{inputenc}
> \usepackage[T1]{fontenc}
>
> \usepackage{/usr/lib/R/share/texmf/Sweave}
> \begin{document}
>
> \section{Introdu????o}
>
> Isto ?? uma experi??ncia.
>
> \begin{figure}[b]
> \centering
> \includegraphics{exp-001}
> \caption{Distribui????o dos valores percentuais.}
> \label{fig:idade}
> \end{figure}
>
> \end{document}
> =================================
>
> All Portuguese  characters were "spoiled".  So apparently the Sweave function
> is "translating" my original font encoding
>
> I suspect that this is a problem related to the recent internationalization
> changes in R, as this same file/process was previously (around a year ago I
> think) working correctly for me.
>
> I've read several documentation on these internationalization issues in R and
> browsed the mailing list. As a result, because initially I didn't have R
> working with the pt_PT.utf-8 locale, I've installed the PT language support
> package for my OS, expecting that this would solve the "problem".  Apparently
> I'm missing something else, so I wonder if someone could give me a hint on
> how to solve this.
>
> Thanks,
> Luis Torgo
>
> -- 
> Luis Torgo
>    FEP/LIACC, University of Porto   Phone : (+351) 22 339 20 93
>    Machine Learning Group           Fax   : (+351) 22 339 20 99
>    R. de Ceuta, 118, 6o             email : ltorgo at liacc.up.pt
>    4050-190 PORTO - PORTUGAL        WWW   : http://www.liacc.up.pt/~ltorgo
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From srini_iyyer_bio at yahoo.com  Mon Oct 31 18:31:06 2005
From: srini_iyyer_bio at yahoo.com (Srinivas Iyyer)
Date: Mon, 31 Oct 2005 09:31:06 -0800 (PST)
Subject: [R] Matrix operations please help
In-Reply-To: <20051031065639.74833.qmail@web31608.mail.mud.yahoo.com>
Message-ID: <20051031173107.2413.qmail@web31611.mail.mud.yahoo.com>

Dear Group, 
I am a novice R programmer with little statistical
background. I am a molecular biologist by training. 
 I generated a correlation matrix (157 X 157) for 157
variables. 
 
I want to selection only the unique values (values
that are either side of the diagnol).  I want these
unique correltaion values in a list. 

How can I do this. could any one help me please. 

thank you. 

sr



From spencer.graves at pdf.com  Mon Oct 31 18:57:28 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 31 Oct 2005 09:57:28 -0800
Subject: [R] linear mixed effect model with ordered logit/probit link?
In-Reply-To: <Pine.A41.4.63a.0510121145320.59634@dante76.u.washington.edu>
References: <Pine.A41.4.63a.0510121145320.59634@dante76.u.washington.edu>
Message-ID: <43665B08.10104@pdf.com>

	  Have you received a reply to this?  I haven't seen one.  I just tried 
several things with RSiteSearch.  Searching for "ordered logit" produced 
70 hits.  One of the first 10 indicate, "The CRAN package MCMCpack has 
at least ordered probit." 
(http://finzi.psych.upenn.edu/R/Rhelp02a/archive/38663.html)

	  I haven't used ordered probits or logits or MCMC, but it would seem 
to me that if MCMCpack has ordered probits, it surely should also be 
able to handle mixed effects.

	  If you would like further assistance from this listserve, I suggest 
you read the posting guide (www.R-project.org/posting-guide.html). 
Doing so might increase the chances of obtaining a useful reply quickly, 
especially if your question includes an extremely simple example in a 
few lines of R code that someone can copy from your email into R and 
test a few ideas in a minute or so.

	  Best Wishes,
	  spencer graves

byoung-inn bai wrote:

> Hello,
> 
> I'm working on the multiple categorical data (5-points scale) using linear 
> mixed effect model and wondering if anyone knows about or works on the 
> linear mixed effect model with ordered logit or probit link.
> I found that the "lmer" function in R is very flexible and supports 
> various models, but not ordered logit/probit models. I may conduct my 
> analysis by turning my DVs into nested dichotonomies, but just wonder if 
> there is anyway that I can do this without transforming my DVs. Any help 
> or suggestion will be greatly appreciated.
> 
> Thanks,
> 
> Byoung-Inn
> 
> 
> 
> Byoung-Inn Bai
> Ph.D. Candidate
> University of Washington
> Department of Political Science
> Box 353530
> e-mail: bbi68 at u.washington.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From jholtman at gmail.com  Mon Oct 31 19:00:29 2005
From: jholtman at gmail.com (jim holtman)
Date: Mon, 31 Oct 2005 13:00:29 -0500
Subject: [R] Matrix operations please help
In-Reply-To: <20051031173107.2413.qmail@web31611.mail.mud.yahoo.com>
References: <20051031065639.74833.qmail@web31608.mail.mud.yahoo.com>
	<20051031173107.2413.qmail@web31611.mail.mud.yahoo.com>
Message-ID: <644e1f320510311000k2b1aa95bj3cb8170735bdff03@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051031/2613168f/attachment.pl

From eklein at usb.ve  Mon Oct 31 19:24:48 2005
From: eklein at usb.ve (Eduardo Klein)
Date: Mon, 31 Oct 2005 13:24:48 -0500
Subject: [R] line vector plots
In-Reply-To: <4363E6BB.2020503@ozemail.com.au>
References: <436203A5.6050100@usb.ve> <4363E6BB.2020503@ozemail.com.au>
Message-ID: <43666170.5090805@usb.ve>

Hi Jim,

Thanks for the tip, but I really need the same polar chart but over a 
line no in a circle. I didn't find it on the plotrix package.

Regards, EKS


Jim Lemon wrote:
> Eduardo Klein wrote:
> 
>> Hi,
>>
>> I'm looking for the way to make vector plot over a time line. This 
>> plot, similar to the "feather plot" in Matlab, is a line in which 
>> every thick (a time value) one vector is drawn with its length 
>> proportional to one variable (wind speed, for example) and its 
>> direction to another (wind direction, for example). Any ideas?
>>
> Hi Eduardo,
> 
> You may be interested in "polar.plot" or "clock24.plot" in the plotrix 
> package.
> 
> Jim
> 
> 

-- 

----------------------------
Eduardo Klein
Instituto de Tecnolog??a y Ciencias Marinas
Universidad Sim??n Bol??var
Caracas, Venezuela
ph/fax (58) (212) 906-3416



From ggrothendieck at gmail.com  Mon Oct 31 19:28:32 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 31 Oct 2005 13:28:32 -0500
Subject: [R] line vector plots
In-Reply-To: <43666170.5090805@usb.ve>
References: <436203A5.6050100@usb.ve> <4363E6BB.2020503@ozemail.com.au>
	<43666170.5090805@usb.ve>
Message-ID: <971536df0510311028n3b164483gcfdadf6a203ea3f8@mail.gmail.com>

Not sure if this is what you are looking for but check out:
http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=80

On 10/31/05, Eduardo Klein <eklein at usb.ve> wrote:
> Hi Jim,
>
> Thanks for the tip, but I really need the same polar chart but over a
> line no in a circle. I didn't find it on the plotrix package.
>
> Regards, EKS
>
>
> Jim Lemon wrote:
> > Eduardo Klein wrote:
> >
> >> Hi,
> >>
> >> I'm looking for the way to make vector plot over a time line. This
> >> plot, similar to the "feather plot" in Matlab, is a line in which
> >> every thick (a time value) one vector is drawn with its length
> >> proportional to one variable (wind speed, for example) and its
> >> direction to another (wind direction, for example). Any ideas?
> >>
> > Hi Eduardo,
> >
> > You may be interested in "polar.plot" or "clock24.plot" in the plotrix
> > package.
> >
> > Jim
> >
> >
>
> --
>
> ----------------------------
> Eduardo Klein
> Instituto de Tecnolog??a y Ciencias Marinas
> Universidad Sim??n Bol??var
> Caracas, Venezuela
> ph/fax (58) (212) 906-3416
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From stratja at auburn.edu  Mon Oct 31 19:31:19 2005
From: stratja at auburn.edu (Jeffrey Stratford)
Date: Mon, 31 Oct 2005 12:31:19 -0600
Subject: [R] Import help (neophyte)
Message-ID: <s3660eab.026@TMIA1.AUBURN.EDU>

Hi, I have no experience with R and I'm finding the manuals a bit obtuse
and written as if I already understood R.  

I'm trying to import a csv file from a floppy and it's not working. The
code I'm using is 

read.table("F:\GEORGIA\species_richness\SR_use.csv", sep=",", header =
TRUE, row.names = 1) 

I'm assuming that this command is case sensitive so everything matches. 
 Is there something I'm missing?  

Thanks,

Jeff 


****************************************
Jeffrey A. Stratford, Ph.D.
Postdoctoral Associate
331 Funchess Hall
Department of Biological Sciences
Auburn University
Auburn, AL 36849
334-329-9198
FAX 334-844-9234
http://www.auburn.edu/~stratja



From tlumley at u.washington.edu  Mon Oct 31 19:39:10 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 31 Oct 2005 10:39:10 -0800 (PST)
Subject: [R] Import help (neophyte)
In-Reply-To: <s3660eab.026@TMIA1.AUBURN.EDU>
References: <s3660eab.026@TMIA1.AUBURN.EDU>
Message-ID: <Pine.LNX.4.63a.0510311038000.24405@homer22.u.washington.edu>

On Mon, 31 Oct 2005, Jeffrey Stratford wrote:

> Hi, I have no experience with R and I'm finding the manuals a bit obtuse
> and written as if I already understood R.
>
> I'm trying to import a csv file from a floppy and it's not working. The
> code I'm using is
>
> read.table("F:\GEORGIA\species_richness\SR_use.csv", sep=",", header =
> TRUE, row.names = 1)
>
> I'm assuming that this command is case sensitive so everything matches.
> Is there something I'm missing?

Yes. Your file path should be 
specified as "F:/GEORGIA/species_richness/SR_use.csv"
[or "F:\\GEORGIA\\species_richness\\SR_use.csv"]

 	-thomas



From Roger.Bivand at nhh.no  Mon Oct 31 19:42:40 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 31 Oct 2005 19:42:40 +0100 (CET)
Subject: [R] Import help (neophyte)
In-Reply-To: <s3660eab.026@TMIA1.AUBURN.EDU>
Message-ID: <Pine.LNX.4.44.0510311938420.17702-100000@reclus.nhh.no>

On Mon, 31 Oct 2005, Jeffrey Stratford wrote:

> Hi, I have no experience with R and I'm finding the manuals a bit obtuse
> and written as if I already understood R.  
> 
> I'm trying to import a csv file from a floppy and it's not working. The
> code I'm using is 
> 
> read.table("F:\GEORGIA\species_richness\SR_use.csv", sep=",", header =
> TRUE, row.names = 1) 
> 
> I'm assuming that this command is case sensitive so everything matches. 
>  Is there something I'm missing?  

PLEASE do read the posting guide! Without the error message you are 
seeing, help isn't possible (we can't see your screen, if we could, you 
should worry!). On Windows try to replace the file name with 
file.choose(), which will help you navigate to the file, but maybe that 
isn't your problem - without seeing the error message, we're none the 
wiser.

> 
> Thanks,
> 
> Jeff 
> 
> 
> ****************************************
> Jeffrey A. Stratford, Ph.D.
> Postdoctoral Associate
> 331 Funchess Hall
> Department of Biological Sciences
> Auburn University
> Auburn, AL 36849
> 334-329-9198
> FAX 334-844-9234
> http://www.auburn.edu/~stratja
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Mon Oct 31 19:45:10 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 31 Oct 2005 19:45:10 +0100 (CET)
Subject: [R] Import help (neophyte)
In-Reply-To: <s3660eab.026@TMIA1.AUBURN.EDU>
Message-ID: <Pine.LNX.4.44.0510311943130.17702-100000@reclus.nhh.no>

On Mon, 31 Oct 2005, Jeffrey Stratford wrote:

> Hi, I have no experience with R and I'm finding the manuals a bit obtuse
> and written as if I already understood R.  
> 
> I'm trying to import a csv file from a floppy and it's not working. The
> code I'm using is 
> 
> read.table("F:\GEORGIA\species_richness\SR_use.csv", sep=",", header =
> TRUE, row.names = 1) 

Further to my previous answer, also review R Windows FAQ 2.16, most likely 
your problem.

> 
> I'm assuming that this command is case sensitive so everything matches. 
>  Is there something I'm missing?  
> 
> Thanks,
> 
> Jeff 
> 
> 
> ****************************************
> Jeffrey A. Stratford, Ph.D.
> Postdoctoral Associate
> 331 Funchess Hall
> Department of Biological Sciences
> Auburn University
> Auburn, AL 36849
> 334-329-9198
> FAX 334-844-9234
> http://www.auburn.edu/~stratja
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From pburns at pburns.seanet.com  Mon Oct 31 19:49:44 2005
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Mon, 31 Oct 2005 18:49:44 +0000
Subject: [R] How can I test temporal autocorrelation of binary data?
In-Reply-To: <20051031111217.bgrinc66vscso0o4@web.mail.umich.edu>
References: <20051031111217.bgrinc66vscso0o4@web.mail.umich.edu>
Message-ID: <43666748.806@pburns.seanet.com>

If you mean you want to test that there is no autocorrelation,
then there is some information on using the Ljung-Box test on
such data in the working paper 'Robustness of the Ljung-Box
test and its rank equivalent' on the Burns Statistics website.

The executive summary is that the test seems to do okay as
long as one of the values is not too dominant.  What 'dominant'
means depends on the length of the series.

If some one has a better answer, I'm keen to hear it.


Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

dschad at umich.edu wrote:

>Hi,
>
>I have a binary (o/1 - coded) data set and want to test it's autocorrelation
>structure. Is that function implemented in R?
>Can I use the ACF - funtion with binary data?
>
>Thanks for your help,
>Daniel
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>



From murdoch at stats.uwo.ca  Mon Oct 31 19:51:10 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 31 Oct 2005 13:51:10 -0500
Subject: [R] Import help (neophyte)
In-Reply-To: <s3660eab.026@TMIA1.AUBURN.EDU>
References: <s3660eab.026@TMIA1.AUBURN.EDU>
Message-ID: <4366679E.1040205@stats.uwo.ca>

On 10/31/2005 1:31 PM, Jeffrey Stratford wrote:
> Hi, I have no experience with R and I'm finding the manuals a bit obtuse
> and written as if I already understood R.  
> 
> I'm trying to import a csv file from a floppy and it's not working. The
> code I'm using is 
> 
> read.table("F:\GEORGIA\species_richness\SR_use.csv", sep=",", header =
> TRUE, row.names = 1) 
> 
> I'm assuming that this command is case sensitive so everything matches. 
>  Is there something I'm missing?  

In R (as in C) the backslash is an escape character.  To have a 
backslash appear in your pathname, you need to double it.

Alternatively, just use a forward slash:

  read.table("F:/GEORGIA/species_richness/SR_use.csv", sep=",", header =
  TRUE, row.names = 1)

Duncan Murdoch



From ggrothendieck at gmail.com  Mon Oct 31 19:55:33 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 31 Oct 2005 13:55:33 -0500
Subject: [R] Matrix operations please help
In-Reply-To: <20051031173107.2413.qmail@web31611.mail.mud.yahoo.com>
References: <20051031065639.74833.qmail@web31608.mail.mud.yahoo.com>
	<20051031173107.2413.qmail@web31611.mail.mud.yahoo.com>
Message-ID: <971536df0510311055m5cd2d29aie18cf35fb79a837a@mail.gmail.com>

Try this:

# test data
mm <- cor(iris[,-5])
mm

# get upper triangle from matrix
mm[lower.tri(mm)]

# if you want it as a data frame with columns for row and column names
as.data.frame.table(mm)[lower.tri(mm),]


In either of the cases above you could substitute row(mm) > col(mm)
for lower.tri(mm) if you like.


On 10/31/05, Srinivas Iyyer <srini_iyyer_bio at yahoo.com> wrote:
> Dear Group,
> I am a novice R programmer with little statistical
> background. I am a molecular biologist by training.
>  I generated a correlation matrix (157 X 157) for 157
> variables.
>
> I want to selection only the unique values (values
> that are either side of the diagnol).  I want these
> unique correltaion values in a list.
>
> How can I do this. could any one help me please.
>
> thank you.
>
> sr
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From JAROSLAW.W.TUSZYNSKI at saic.com  Mon Oct 31 20:00:51 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Mon, 31 Oct 2005 14:00:51 -0500
Subject: [R] Sum of logical vector
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD5047A5B72@us-arlington-0668.mail.saic.com>

Hi,

Recently I was told by users of some of the function I wrote that they
experience crashes in places where logical vector was passed to sum
function. However on my computer those functions work just fine. After
closer look at documentation of function 'sum', I realized that it is
defined only for complex and numeric vectors, so I guess I was using
"undocumented feature". 

What I am trying to understand is why it works on some systems (my - Win XP,
from R-1.9.? to R-2.2.0) and does not work on other (unknown platform,
R-2.2.0):
- Is it that they have more methods of function "sum" defined and some other
function (maybe some package has "logical.sum" defined) is being used?
- Different operating systems will have different behavior for supporting
"undocumented features"?

Is there any way to automatically test your code for presence of unsupported
functions it uses?
Should function 'sum' produced warning/error, or convert logical to integer?

An Example code:

 repeats = function(x) return (sum(duplicated(x)) ) # how many numbers
repeat themselves in vector x?
 repeats( c(1:10, 3:14) )

 Jarek 
====================================================\==== 
 Jarek Tuszynski, PhD.                           o / \ 
 Science Applications International Corporation  <\__,|  
 (703) 676-4192                                   ">  \ 
 Jaroslaw.W.Tuszynski at saic.com                     `   \



From murdoch at stats.uwo.ca  Mon Oct 31 20:48:27 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 31 Oct 2005 14:48:27 -0500
Subject: [R] Sum of logical vector
In-Reply-To: <CA0BCF3BED56294AB91E3AD74B849FD5047A5B72@us-arlington-0668.mail.saic.com>
References: <CA0BCF3BED56294AB91E3AD74B849FD5047A5B72@us-arlington-0668.mail.saic.com>
Message-ID: <4366750B.5000005@stats.uwo.ca>

On 10/31/2005 2:00 PM, Tuszynski, Jaroslaw W. wrote:
> Hi,
> 
> Recently I was told by users of some of the function I wrote that they
> experience crashes in places where logical vector was passed to sum
> function. However on my computer those functions work just fine. After
> closer look at documentation of function 'sum', I realized that it is
> defined only for complex and numeric vectors, so I guess I was using
> "undocumented feature". 
> 
> What I am trying to understand is why it works on some systems (my - Win XP,
> from R-1.9.? to R-2.2.0) and does not work on other (unknown platform,
> R-2.2.0):
> - Is it that they have more methods of function "sum" defined and some other
> function (maybe some package has "logical.sum" defined) is being used?
> - Different operating systems will have different behavior for supporting
> "undocumented features"?
> 
> Is there any way to automatically test your code for presence of unsupported
> functions it uses?
> Should function 'sum' produced warning/error, or convert logical to integer?
> 
> An Example code:
> 
>  repeats = function(x) return (sum(duplicated(x)) ) # how many numbers
> repeat themselves in vector x?
>  repeats( c(1:10, 3:14) )

You should always be able to sum a logical vector, because it will be 
coerced to numeric when needed.  The crashes are being caused by 
something else. Get your users to tell you exact error messages and you 
should be able to diagnose it.

Duncan Murdoch



From 2bingho at stanford.edu  Mon Oct 31 20:54:48 2005
From: 2bingho at stanford.edu (Bing Ho)
Date: Mon, 31 Oct 2005 11:54:48 -0800
Subject: [R] Problem using reshape with missing values in idvar
Message-ID: <6.2.5.6.2.20051031104423.02b0af38@wheresmymailserver.com>

Hello everybody,

I have been recently using reshape to convert "long" data to "wide" 
data. Everything was going well until I reached some problematic 
datasets. It has taken me a couple of weeks to finally figure out 
what might be happening.

The problem is reproducible with test cases, and on two versions of R 
(Windows 2.2.0 and x86-64 Fedora Core 3 R 2.2.0).

The data started out in Microsoft Excel 2003 before being saved as a 
.csv file. The data stores the records of study participants which 
may return a variable number of times for follow up (between one to 
several dozen follow up visits). The research staff would start a row 
of data for each study participant, and each follow up visit would be 
row underneath the previous row for that study participant. Because 
of the variable nature of follow up, many fields will be "NA" since 
some participants may have only one study.

A sample is as follows (note that the ID appears consecutively for 
each follow up, or in other words, all the ID are grouped chronologically)
ID  DOB  GENDER  ETHNICITY  TESTDATE TESTRESULT
1 1/1/1900 1 1 1/1/2005 100
1 1/1/1900 1 1 1/2/2005 110
2 8/1/1930 2 1 2/1/2005 80
3 12/1/1990 2 2 3/1/2005 200
3 12/1/1990 2 2 3/2/2005 205
3 12/1/1990 2 2 3/3/2005 220

My code is as follows:
df <- read.csv("df.csv")  # Read .csv file into R
df.tt <- sequence(rle(df$ID)$length)  # Create a sequence vector tt 
based on the number of times ID appears
# Then reshape from long into wide format, with only the time-varying 
variables repeated
df_wide <- reshape(cbind(df.tt,df), 
idvar("ID","DOB","GENDER","ETHNICITY"), timevar="tt",direction="wide")

This testcase works fine.

Now taking a similar test case, with some missing values in the 
idvar, like so,
ID  DOB  GENDER  ETHNICITY  TESTDATE TESTRESULT
1 1/1/1900 1 1 1/1/2005 100
1 1/1/1900 1 1 1/2/2005 110
2 8/1/1930 NA NA 2/1/2005 80
3 12/1/1990 NA NA 3/1/2005 200
3 12/1/1990 NA NA 3/2/2005 205
3 12/1/1990 NA NA 3/3/2005 220

Will result with a wide dataframe that only has id 1 and 2 (3 is dropped).

It took me some time to figure out that missing values in idvar will 
result in the problem. As long as the idvar does not have any missing 
values, all works out well.

Is there a way to use reshape to handle missing values in the idvar? 
I'm just trying to avoid unnecessary expansion of my dataset with the 
reshape command by holding the six dozen or so demographic variables 
in my actual datasets constant.

Thank you for your help!



From jfox at mcmaster.ca  Mon Oct 31 21:21:13 2005
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 31 Oct 2005 15:21:13 -0500
Subject: [R] GLM
In-Reply-To: <BAY104-F34B15A7B62E3DAD90FDF2EAE6C0@phx.gbl>
Message-ID: <20051031202112.TCGY26550.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Jeff,

One way to do this is with by():

summaries <- by(example, Individual, function(data){ 
    mod <- glm(Type~Dwater+Habitat, data=data, family=binomial)
    list(AIC=AIC(mod), coef=coef(mod))
    })
    
sapply(summaries, function(x) x$coef)
rowMeans(sapply(summaries, function(x) x$coef))
sapply(summaries, function(x) x$AIC)

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jeff Row
> Sent: Monday, October 31, 2005 12:01 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] GLM
> 
> Hello R-users,
> 
> I am a relatively new user of R and I have a question 
> regarding glm. I want to run the function GLM on multiple 
> individuals separately and then get means for summary 
> statistics such as AIC and coef. Is there a way to do this in 
> R without separately going through each individual and 
> subsetting the dataset, getting the summary statistics and 
> averaging them? For example, in the dataset below I would 
> like to run the function:
> 
> >glm(Type~Dwater+Habitat, data=example, family=binomial())
> 
> on each individual separately and then get the average for 
> the coef's Dwater and Habitat for the 3 individuals.
> 
> >example
>    Individual Type Dwater Habitat
> 1           1    0     40       0
> 2           1    1     80       1
> 3           1    0     30       0
> 4           1    1     90       0
> 5           2    0     15       1
> 6           2    1     95       1
> 7           2    0     20       0
> 8           2    1     75       1
> 9           3    0     15       0
> 10          3    1     60       1
> 11          3    0     10       1
> 12          3    1     95       0
> 
> Thanks,
> 
> Jeff.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From d.scott at auckland.ac.nz  Mon Oct 31 21:55:38 2005
From: d.scott at auckland.ac.nz (David Scott)
Date: Tue, 1 Nov 2005 09:55:38 +1300 (NZDT)
Subject: [R] Help with try or tryCatch
Message-ID: <Pine.LNX.4.61.0511010940290.28280@stat12.stat.auckland.ac.nz>


I am having trouble with try and tryCatch.

I have read the documentation but I just don't get it.

Here is what I am trying to do. I am testing a function which has a number 
of parameters. I want to test it for different values of the parameters 
and I have some loops, in the middle of which is a test of the function. 
Sometimes the routine fails and so I have put the bit that might fail 
inside try(). I would like to keep running through the loops when that 
happens, but the whole computation stops. I have read in the documentation 
about restarts and seen that there is a pre-established restart which 
jumps to the top level, and I am guessing that that is what is happening. 
What I can't see is how to get the computation to restart from the error 
and just continue through the loop.

Any suggestions or pointers would be most welcome.

David Scott

_________________________________________________________________
David Scott	Department of Statistics, Tamaki Campus
 		The University of Auckland, PB 92019
 		Auckland	NEW ZEALAND
Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
Email:	d.scott at auckland.ac.nz


Graduate Officer, Department of Statistics



From roger.dungan at canterbury.ac.nz  Mon Oct 31 22:23:43 2005
From: roger.dungan at canterbury.ac.nz (Roger Dungan)
Date: Tue, 01 Nov 2005 10:23:43 +1300
Subject: [R] Still a bug with NA in sd() or var()?
Message-ID: <7C773F4D89C83147A023704E9E78103704AC49B2@cantwe.canterbury.ac.nz>

Dear R-users,

Running R 2.1.1 in WindowsXP, there seems to be a 'bug' in sd()
If
>x<-c(1,2,3,NA,5)
>mean(x) 
[1] NA

But 
>sd(x) 
Or
>var(x)
give
Error in var(x, na.rm = na.rm) : missing observations in cov/cor

There are obvious work-rounds, like
>sd(x, is.na(x)==F)
which gives the result (with error message)
[1] 1.707825
Warning message:
the condition has length > 1 and only the first element will be used in:
if (na.rm) "complete.obs" else "all.obs"

or

>y<-subset(x, is.na(x)==F)
>sd(y)
[1] 1.707825

Am I missing something, or is this a problem with sd()? Why does mean(x)
give a simple NA, but var(x) requires some additional work? There was
some previous discussion in r-help about this for R v 1.6.0, with
mention of a fix for 1.6.1. 

Dr Roger Dungan
School of Biological Sciences
University of Cantebury
Christchurch, New Zealand
ph +64 3 366 7001 ext. 4848
fax +64 3 364 2590



From JAROSLAW.W.TUSZYNSKI at saic.com  Mon Oct 31 22:30:58 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Mon, 31 Oct 2005 16:30:58 -0500
Subject: [R] Still a bug with NA in sd() or var()?
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD5047A5DDB@us-arlington-0668.mail.saic.com>

Try:

> sd (x,na.rm=TRUE)
[1] 1.707825

 Jarek 
====================================================\==== 
 Jarek Tuszynski, PhD.                           o / \ 
 Science Applications International Corporation  <\__,|  
 (703) 676-4192                                   ">  \ 
 Jaroslaw.W.Tuszynski at saic.com                     `   \ 

 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Roger Dungan
Sent: Monday, October 31, 2005 4:24 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Still a bug with NA in sd() or var()?

Dear R-users,

Running R 2.1.1 in WindowsXP, there seems to be a 'bug' in sd() If
>x<-c(1,2,3,NA,5)
>mean(x)
[1] NA

But 
>sd(x) 
Or
>var(x)
give
Error in var(x, na.rm = na.rm) : missing observations in cov/cor

There are obvious work-rounds, like
>sd(x, is.na(x)==F)
which gives the result (with error message)
[1] 1.707825
Warning message:
the condition has length > 1 and only the first element will be used in:
if (na.rm) "complete.obs" else "all.obs"

or

>y<-subset(x, is.na(x)==F)
>sd(y)
[1] 1.707825

Am I missing something, or is this a problem with sd()? Why does mean(x)
give a simple NA, but var(x) requires some additional work? There was
some previous discussion in r-help about this for R v 1.6.0, with
mention of a fix for 1.6.1. 

Dr Roger Dungan
School of Biological Sciences
University of Cantebury
Christchurch, New Zealand
ph +64 3 366 7001 ext. 4848
fax +64 3 364 2590

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From marcelodamasceno at gmail.com  Mon Oct 31 22:32:13 2005
From: marcelodamasceno at gmail.com (Marcelo Damasceno)
Date: Mon, 31 Oct 2005 19:32:13 -0200
Subject: [R] Build R package with shared library
Message-ID: <a55593730510311332k53e881e7n93861f3ed228bd34@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051031/edc72175/attachment.pl

From Robert.McGehee at geodecapital.com  Mon Oct 31 22:32:35 2005
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Mon, 31 Oct 2005 16:32:35 -0500
Subject: [R] Help with try or tryCatch
Message-ID: <67DCA285A2D7754280D3B8E88EB548020C9466FA@MSGBOSCLB2WIN.DMN1.FMR.COM>

It sounds like you want `try` with the argument `silent = TRUE`. This
will allow you to keep running your program without errors. If you want
to check if the line had an error, you can error control by seeing if
the class of the resulting object is "try-error". For example, let's say
I wanted to make an error-proof `plus` function, such that trying "a" +
2 would result in NA instead of an error.

newPlus <- function(x, y) {
	answer <- try(x + y, silent = TRUE)
	if (class(answer) == "try-error") return(NA) else return(answer)
}

> newPlus(1, 2)
[1] 3
> newPlus("a", 2)
[1] NA

tryCatch is generally useful when one wants to run a script that may
contain errors, and regardless of whether errors are encountered
tryCatch will run a `finally` script after the main script completes.
This is extremely helpful, for instance, if your primary script creates
some auxiliary connections or temporary files that you want to clean
up/delete after the main script finishes, whether there was an error or
not.

Hope this helps, 
Robert

-----Original Message-----
From: David Scott [mailto:d.scott at auckland.ac.nz] 
Sent: Monday, October 31, 2005 3:56 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Help with try or tryCatch



I am having trouble with try and tryCatch.

I have read the documentation but I just don't get it.

Here is what I am trying to do. I am testing a function which has a
number 
of parameters. I want to test it for different values of the parameters 
and I have some loops, in the middle of which is a test of the function.

Sometimes the routine fails and so I have put the bit that might fail 
inside try(). I would like to keep running through the loops when that 
happens, but the whole computation stops. I have read in the
documentation 
about restarts and seen that there is a pre-established restart which 
jumps to the top level, and I am guessing that that is what is
happening. 
What I can't see is how to get the computation to restart from the error

and just continue through the loop.

Any suggestions or pointers would be most welcome.

David Scott

_________________________________________________________________
David Scott	Department of Statistics, Tamaki Campus
 		The University of Auckland, PB 92019
 		Auckland	NEW ZEALAND
Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
Email:	d.scott at auckland.ac.nz


Graduate Officer, Department of Statistics

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From maustin at amgen.com  Mon Oct 31 22:37:41 2005
From: maustin at amgen.com (Austin, Matt)
Date: Mon, 31 Oct 2005 13:37:41 -0800
Subject: [R] Still a bug with NA in sd() or var()?
Message-ID: <E7D5AB4811D20B489622AABA9C53859109DAD378@teal-exch.amgen.com>

The behavior is actually documented in the var() help file (?var), although
it's not clear that this would be the behavior if you just read ?sd.  sd()
does call var if you look at the code, so the behavior should not be
unexpected.

--Matt

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Roger Dungan
> Sent: Monday, October 31, 2005 1:24 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Still a bug with NA in sd() or var()?
> 
> 
> Dear R-users,
> 
> Running R 2.1.1 in WindowsXP, there seems to be a 'bug' in sd()
> If
> >x<-c(1,2,3,NA,5)
> >mean(x) 
> [1] NA
> 
> But 
> >sd(x) 
> Or
> >var(x)
> give
> Error in var(x, na.rm = na.rm) : missing observations in cov/cor
> 
> There are obvious work-rounds, like
> >sd(x, is.na(x)==F)
> which gives the result (with error message)
> [1] 1.707825
> Warning message:
> the condition has length > 1 and only the first element will 
> be used in:
> if (na.rm) "complete.obs" else "all.obs"
> 
> or
> 
> >y<-subset(x, is.na(x)==F)
> >sd(y)
> [1] 1.707825
> 
> Am I missing something, or is this a problem with sd()? Why 
> does mean(x)
> give a simple NA, but var(x) requires some additional work? There was
> some previous discussion in r-help about this for R v 1.6.0, with
> mention of a fix for 1.6.1. 
> 
> Dr Roger Dungan
> School of Biological Sciences
> University of Cantebury
> Christchurch, New Zealand
> ph +64 3 366 7001 ext. 4848
> fax +64 3 364 2590
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html



From neo27 at t-online.de  Mon Oct 31 23:14:07 2005
From: neo27 at t-online.de (Mark Hempelmann)
Date: Mon, 31 Oct 2005 23:14:07 +0100
Subject: [R] nls() fit to Kahnemann/ Tversky function
Message-ID: <4366972F.1090909@t-online.de>

Dear WizaRds,

     I would like to fit a curve to ten points with nls() for one 
unknown parameter gamma in the Kahnemann/ Tversky function, but somehow 
it won't work and I am unable to locate my mistake.

p.kum <- seq(0.1,1, by=0.1)
felt.prob.kum <- c(0.16, 0.23, 0.36, 0.49, 0.61, 0.71, 0.85, 0.89, 0.95, 
1) ## how to find a function that fits these points nicely?
plot(p.kum, felt.prob.kum) ## looks a little like an "S"

gamma <- rep(0.5, 10)
nls.dataframe <- data.frame(p.kum,felt.prob.kum, gamma)

nls.kurve <- nls( formula = felt.prob.kum ~ 
p.kum^gamma/(p.kum^gamma+(1-p.kum)^gamma)^(1/gamma), data=nls.dataframe, 
start=c(gamma=gamma), algorithm="plinear" )

summary(nls.kurve)

gives: Error in La.chol2inv(x, size) : 'size' cannot exceed nrow(x) = 10

     If I go with the Gauss-Newton algorithm I get an singular gradient 
matrix error, so I tried the Golub-Pereyra algorithm for partially 
linear least-squares.

     It also seems the nls model tries to find ten different gammas, but 
I want only one single gamma parameter for the function. I appreciate 
your help and support. Thank you.

sol lucet omnibus
Mark Hempelmann



From tplate at acm.org  Mon Oct 31 23:30:22 2005
From: tplate at acm.org (Tony Plate)
Date: Mon, 31 Oct 2005 15:30:22 -0700
Subject: [R] Still a bug with NA in sd() or var()?
In-Reply-To: <7C773F4D89C83147A023704E9E78103704AC49B2@cantwe.canterbury.ac.nz>
References: <7C773F4D89C83147A023704E9E78103704AC49B2@cantwe.canterbury.ac.nz>
Message-ID: <43669AFE.8020001@acm.org>

Roger Dungan wrote:
> [snip]>
> There are obvious work-rounds, like
> 
>>sd(x, is.na(x)==F)
> 
> which gives the result (with error message)
> [1] 1.707825
> Warning message:
> the condition has length > 1 and only the first element will be used in:
> if (na.rm) "complete.obs" else "all.obs"
> 

What you are doing here looks very odd to me -- you are passing a vector 
of logicals as the value for the argument na.rm.  This is odd because 
na.rm should be just a single logical value, not a vector of the same 
length as x (hence the warning message).  Only the first element of that 
vector is used, so you are passing essentially a random value.  By luck, 
in your example, the first element was T, which is why you got a value 
of 1.707825 as the result, and not NA.  The rest might fall into place 
when this understanding is cleared up.

-- Tony Plate



From rsingh at MIT.EDU  Mon Oct 31 23:52:09 2005
From: rsingh at MIT.EDU (Rohit Singh)
Date: Mon, 31 Oct 2005 17:52:09 -0500 (EST)
Subject: [R] why does glm.predict give values over 1 ?
Message-ID: <Pine.GSO.4.58L.0510311737430.10652@mass-toolpike.mit.edu>

Hi,

 This is a newbie question. I have been using glm to perform some logistic
regression. However, if I take the fitted parameters (as part of the glm
object) and pass them on the glm.predict function, for some test cases I
am getting predicted values that are a little over 1.  This is a bit
puzzling for me, because my understanding was that these numbers are
probabilities and so should be between 0 and 1.


Thanks a lot! I'd appreciate any help you could provide.

-rohit



From apjaworski at mmm.com  Mon Oct 31 23:52:26 2005
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Mon, 31 Oct 2005 16:52:26 -0600
Subject: [R] nls() fit to Kahnemann/ Tversky function
In-Reply-To: <4366972F.1090909@t-online.de>
Message-ID: <OF85F1D098.D6F01EA0-ON862570AB.007CDCBB-862570AB.007DA6B1@mmm.com>

Mark,

The parameter of your model (gamma) should not be a part of the dataframe.
In addition, the start argument should be a named list.

Something like this works

nls.dataframe <- data.frame(p.kum,felt.prob.kum)
nls.kurve <- nls( formula = felt.prob.kum ~
p.kum^gamma/(p.kum^gamma+(1-p.kum)^gamma)^(1/gamma), data=nls.dataframe,
start=list(gamma=.5), trace=TRUE) # trace shows convergence of the
algorithm.

but the fit is not very good as the fitted gamma is essentially 1.

Hope this helps,

Andy

__________________________________
Andy Jaworski
518-1-01
Process Laboratory
3M Corporate Research Laboratory
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


                                                                           
             Mark Hempelmann                                               
             <neo27 at t-online.d                                             
             e>                                                         To 
             Sent by:                  r-help at stat.math.ethz.ch            
             r-help-bounces at st                                          cc 
             at.math.ethz.ch                                               
                                                                   Subject 
                                       [R] nls() fit to Kahnemann/ Tversky 
             10/31/2005 04:14          function                            
             PM                                                            
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           




Dear WizaRds,

     I would like to fit a curve to ten points with nls() for one
unknown parameter gamma in the Kahnemann/ Tversky function, but somehow
it won't work and I am unable to locate my mistake.

p.kum <- seq(0.1,1, by=0.1)
felt.prob.kum <- c(0.16, 0.23, 0.36, 0.49, 0.61, 0.71, 0.85, 0.89, 0.95,
1) ## how to find a function that fits these points nicely?
plot(p.kum, felt.prob.kum) ## looks a little like an "S"

gamma <- rep(0.5, 10)
nls.dataframe <- data.frame(p.kum,felt.prob.kum, gamma)

nls.kurve <- nls( formula = felt.prob.kum ~
p.kum^gamma/(p.kum^gamma+(1-p.kum)^gamma)^(1/gamma), data=nls.dataframe,
start=c(gamma=gamma), algorithm="plinear" )

summary(nls.kurve)

gives: Error in La.chol2inv(x, size) : 'size' cannot exceed nrow(x) = 10

     If I go with the Gauss-Newton algorithm I get an singular gradient
matrix error, so I tried the Golub-Pereyra algorithm for partially
linear least-squares.

     It also seems the nls model tries to find ten different gammas, but
I want only one single gamma parameter for the function. I appreciate
your help and support. Thank you.

sol lucet omnibus
Mark Hempelmann

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From maustin at amgen.com  Mon Oct 31 23:56:04 2005
From: maustin at amgen.com (Austin, Matt)
Date: Mon, 31 Oct 2005 14:56:04 -0800
Subject: [R] why does glm.predict give values over 1 ?
Message-ID: <E7D5AB4811D20B489622AABA9C53859109DAD37F@teal-exch.amgen.com>

If you left the type argument to the predict method then your predictions
are on the log-odds scale.  Try using the type='response' in the predict
method for glm.

--Matt

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Rohit Singh
> Sent: Monday, October 31, 2005 2:52 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] why does glm.predict give values over 1 ?
> 
> 
> Hi,
> 
>  This is a newbie question. I have been using glm to perform 
> some logistic
> regression. However, if I take the fitted parameters (as part 
> of the glm
> object) and pass them on the glm.predict function, for some 
> test cases I
> am getting predicted values that are a little over 1.  This is a bit
> puzzling for me, because my understanding was that these numbers are
> probabilities and so should be between 0 and 1.
> 
> 
> Thanks a lot! I'd appreciate any help you could provide.
> 
> -rohit
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From brian_pfeng at yahoo.com  Mon Oct 31 05:17:00 2005
From: brian_pfeng at yahoo.com (Brian pfeng)
Date: Sun, 30 Oct 2005 22:17:00 -0600 (CST)
Subject: [R] Daily Time serie
Message-ID: <20051031041700.19510.qmail@web30801.mail.mud.yahoo.com>

I am working with a daily series of time of financial
and not character like defining the frequency in R. In
addition gustaria me who R took into account the
worked Days. Nobody orientacion well is received Thanks



From fuyaonv at hotmail.com  Tue Oct 25 21:16:13 2005
From: fuyaonv at hotmail.com (Lynette Sun)
Date: Tue, 25 Oct 2005 19:16:13 +0000
Subject: [R] exponential convolution (different lembdas)?
In-Reply-To: <435E782F.9000406@math.ucalgary.ca>
Message-ID: <BAY102-F24B97E9B6662FC88E23EDCB3760@phx.gbl>

Anyone knows how to realize multiple exponential(different lembdas) 
convolutons in R or where I can find the final equation? Thanks.

Best,
Lynette



From gunter.berton at gene.com  Fri Oct 28 00:22:58 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Thu, 27 Oct 2005 15:22:58 -0700
Subject: [R] encrypted RData file?
In-Reply-To: <1130450148.4252.67.camel@localhost.localdomain>
Message-ID: <200510272223.j9RMMwi7007838@faraday.gene.com>

May I suggest that further discussion of this issue be directed to R-Devel.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Marc 
> Schwartz (via MN)
> Sent: Thursday, October 27, 2005 2:56 PM
> To: Roger D. Peng; Na Li
> Cc: r-help at stat.math.ethz.ch; Duncan Temple Lang
> Subject: Re: [R] encrypted RData file?
> 
> On Thu, 2005-10-27 at 16:15 -0500, Na Li wrote:
> > On 27 Oct 2005, Duncan Temple Lang wrote:
> > 
> > > Yes, it is of interest and was sitting on my todo list at
> > > some time.  If you want to go ahead and provide code to do it,
> > > that would be terrific.  There are other areas where encryption
> > > would be good to have, so a general mechanism would be nice.
> > > 
> > > D.
> > > 
> > > Na Li wrote:
> > > > Hi, I wonder if there is interest/intention to allow 
> for encrypted .RData
> > > > files?  One can certainly do that outside R manually 
> but that will leave a
> > > > decrypted RData file somewhere which one has to 
> remember to delete.
> > > > 
> > 
> > I was hoping someone has already done it.  ;-(
> > 
> > One possibility is to implement an interface package to 
> gpgme library which
> > itself is an interface to GnuPG.  
> > 
> > But I'm not sure how the input of passphrase can be handled 
> without using
> > clear text.
> > 
> > Michael
> 
> Seems to me that a better option would be to encrypt the full 
> partition
> such that (unless you write the files to a non-encrypted partition)
> these issues are transparent. This would include the use of save(),
> save.image() and write() type functions to save what was an encrypted
> dataset/object to a unencrypted file.
> 
> Of course, you would also have to encrypt the swap and tmp partitions
> (as appropriate) for similar reasons.
> 
> On Linuxen/Unixen, full encryption of partitions is available via
> loopback devices and other mechanisms and some distros have this
> available as a built-in option. I believe that the FC folks 
> finally have
> this on their list of functional additions for FC5. Windows of course
> can do something similar.
> 
> The other consideration here, is that if R Core builds in some form of
> encryption, there is the potential for import/export restrictions on
> such technology since R is available via international CRAN 
> mirrors. It
> may be best to provide for a plug-in "encryption black box" 
> of sorts, so
> that folks can use a particular encryption schema that meets various
> legal/regulatory requirements.
> 
> Of course, simply encrypting the file or even a complete partition has
> to be considered within a larger security strategy (ie. network
> security, physical access control, etc.) that meets a particular
> functional requirement (such as HIPAA here in the U.S.)
> 
> HTH,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From family.feng at gmail.com  Fri Oct 28 22:43:26 2005
From: family.feng at gmail.com (Jun Feng)
Date: Fri, 28 Oct 2005 16:43:26 -0400
Subject: [R] Lars/lasso help
Message-ID: <cd4d96730510281343i1c7a1ebdu@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051028/da4f220c/attachment.pl

From edd at debian.org  Mon Oct 31 04:12:03 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 30 Oct 2005 21:12:03 -0600
Subject: [R] [R-pkgs] New version of RQuantLib
Message-ID: <17253.35715.443094.418346@basebud.nulle.part>


A new version of RQuantLib has been uploaded to CRAN a few days ago (and
should be available at http://cran.r-project.org and all mirrors). Debian
binaries are also available.

Among the new features in version 0.2.0, all of which are due to excellent
contributions by Dominick Samperi, are
- new functions for Fixed Income support:
   * DiscountCurve for discount / forward / zero curve construction
   * BermudanSwaption provding several QuantLib pricers for Swaptions
- new internal R / C++ interface class RCpp
- Windows binary packages on CRAN 

Windows users can now install RQuantLib via the menu just like any other
package.  Debian users can still say 'apt-get install r-cran-rquantlib'. All
others can compile manually (which still requires Boost and QuantLib
headers).

We also have an experimental OpenGL demo of option analytics visualisation
via the rgl package.  However, there are some concerns over stability,
especially on platforms with ATI graphics card.  If you want to try it, do
 
> library(RQuantLib)
> source(url("http://basebud.nulle.part/~edd/code/rquantlib/OptionSurfaces.R"))

and let us know how it worked (or not) and what your platform is. We still
would like to release this in an upcoming revision.  A more fail-safe way,
using animated gifs of the demo's output, is available at

     http://dirk.eddelbuettel.com/code/rquantlib-rgl.html

Special thanks to Dominick Sapieri for the new code and all his testing and
building help, and to Uwe Ligges for help with the Windows binaries.

With best regards, Dirk

-- 
Statistics: The (futile) attempt to offer certainty about uncertainty.
         -- Roger Koenker, 'Dictionary of Received Ideas of Statistics'

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From drcarbon at gmail.com  Mon Oct 31 18:03:34 2005
From: drcarbon at gmail.com (Dr Carbon)
Date: Mon, 31 Oct 2005 12:03:34 -0500
Subject: [R] question about precision, floor, and powers of two.
Message-ID: <e89bb7ac0510310903m77d159e6nb9f2e7188ff82d90@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20051031/07132091/attachment.pl

From jmbucci at stat.ucla.edu  Fri Oct 28 01:23:19 2005
From: jmbucci at stat.ucla.edu (jmbucci@stat.ucla.edu)
Date: Thu, 27 Oct 2005 16:23:19 -0700 (PDT)
Subject: [R] Optim function
Message-ID: <1491.164.67.201.106.1130455399.squirrel@164.67.201.106>

Hello,

Is there a general procedure when using the the optim function("BFGS") to
only output the converging value (i.e. final par value) rather than all
the other output?

Thank you.



From u08adh at hotmail.com  Mon Oct 31 23:47:52 2005
From: u08adh at hotmail.com (Andreas Hary)
Date: Mon, 31 Oct 2005 22:47:52 -0000
Subject: [R] How can I test temporal autocorrelation of binary data?
References: <20051031111217.bgrinc66vscso0o4@web.mail.umich.edu>
	<43666748.806@pburns.seanet.com>
Message-ID: <BAY103-DAV3F08DEC2DB615F6AD75D8DF6C0@phx.gbl>

Since the data is dichotomous already, the nonparametric 'runs test' might 
be appropriate, though I am ignorant as to its properties (power in 
particular).

help(runs.test,package=tseries)

Regards,

Andreas



----- Original Message ----- 
From: "Patrick Burns" <pburns at pburns.seanet.com>
To: <dschad at umich.edu>
Cc: <r-help at stat.math.ethz.ch>
Sent: Monday, October 31, 2005 6:49 PM
Subject: Re: [R] How can I test temporal autocorrelation of binary data?


> If you mean you want to test that there is no autocorrelation,
> then there is some information on using the Ljung-Box test on
> such data in the working paper 'Robustness of the Ljung-Box
> test and its rank equivalent' on the Burns Statistics website.
>
> The executive summary is that the test seems to do okay as
> long as one of the values is not too dominant.  What 'dominant'
> means depends on the length of the series.
>
> If some one has a better answer, I'm keen to hear it.
>
>
> Patrick Burns
> patrick at burns-stat.com
> +44 (0)20 8525 0696
> http://www.burns-stat.com
> (home of S Poetry and "A Guide for the Unwilling S User")
>
> dschad at umich.edu wrote:
>
>>Hi,
>>
>>I have a binary (o/1 - coded) data set and want to test it's 
>>autocorrelation
>>structure. Is that function implemented in R?
>>Can I use the ACF - funtion with binary data?
>>
>>Thanks for your help,
>>Daniel
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
>>
>>
>>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



