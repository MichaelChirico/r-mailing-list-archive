From drhosini at hotmail.com  Sun Dec  1 07:58:57 2002
From: drhosini at hotmail.com (Moustafa ElHousinie)
Date: Sun, 01 Dec 2002 06:58:57 +0000
Subject: No subject
Message-ID: <F138raUMTzFm15k4R9x00006311@hotmail.com>


Dear Lister
I need to perform Generalized estimating equations on some data. Has 'R' any 
function or routine to do it? (GEE is same as GLM but with correlated y's)
Thanks in advance
Mostafa




_________________________________________________________________
Protect your PC - get McAfee.com VirusScan Online 
http://clinic.mcafee.com/clinic/ibuy/campaign.asp?cid=3963

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Ko-Kang at xtra.co.nz  Sun Dec  1 09:57:40 2002
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Sun, 1 Dec 2002 21:57:40 +1300
Subject: [R] Re: GEE
References: <F138raUMTzFm15k4R9x00006311@hotmail.com>
Message-ID: <001d01c29917$b6b5a3d0$212658db@kwan022>

Hi,

I think there exist a gee package (have a look at CRAN), is it what you
want?

Cheers,

Kevin

------------------------------------------------
Ko-Kang Kevin Wang
Post Graduate PGDipSci Student
Department of Statistics
University of Auckland
New Zealand
www.stat.auckland.ac.nz/~kwan022

----- Original Message -----
From: "Moustafa ElHousinie"
<drhosini at hotmail.com>
To: "r-help" <r-help at stat.math.ethz.ch>
Sent: Sunday, December 01, 2002 7:58 PM


>
> Dear Lister
> I need to perform Generalized estimating equations on some data. Has 'R'
any
> function or routine to do it? (GEE is same as GLM but with correlated y's)
> Thanks in advance
> Mostafa
>
>
>
>
> _________________________________________________________________
> Protect your PC - get McAfee.com VirusScan Online
> http://clinic.mcafee.com/clinic/ibuy/campaign.asp?cid=3963
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:
r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._



********************************************
Viralock... Zero Escape for Email Viruses... http://www.viralock.com


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From sabs2002 at mail.com  Sun Dec  1 21:56:35 2002
From: sabs2002 at mail.com (Barrister Sanni Kaloma Alli)
Date: Sun, 1 Dec 2002 12:56:35 -0800
Subject: [R] Business Proposal (Urgent)
Message-ID: <E18ISaf-0000AI-00@bernie.ethz.ch>

November 28, 2002

From: Barrister Sanni Kaloma Ali (SAN)
email: absanni at excite.com

To: The Managing Director/CEO,

Sir,

You must not be surprised at the receipt of this message.  Indeed you must
realize that there is always the hidden hand of providence in the affairs
of men and that we are only pencils in the hands of the Almighty Creator
of the Universe.

The truth is this: After more than three years of incarceration at the
Kirikiri Maximum Security Prisons in Lagos Nigeria, the eldest son of the
late Nigerian Military Head of State (General Sani Abacha) was released by
the Federal Authorities on September 23, 2002. Mr. Mohammed Abacha was
being held because his late father was said to have embezzled more than
$3billion (Three Billion United States Dollars) when he was Nigeria's Head
of State.

Mr. Mohammed was released after reaching an agreement with the incumbent
Nigerian President to refund about Two Billion Dollars ($2billion) to the
Federal Government. 

The government has so far succeeded in recovering the sum of $3.2 billion
dollars from a Swiss Bank Account belonging to the Abachas. As at six
months ago, they recovered the sum of $565 million dollars, and on the
11th of November 2001, another $395 million dollars was recovered due to
the co-operation of the Swiss Banks.  These facts can be confirmed from
the Nigerian Embassy in your country or you can request for the March 2000
edition of the Newsweek magazine or CNN/BBC publications on Abacha.

I, Alhaji Kaloma Ali, was the Minister of Solid Minerals under the
government of the late General Sani Abacha, and also one of the main
Attorneys who defended Mohammed Abacha during the period of his travails
in the hands of the Federal Government.  As such, I am barred by the
Federal Authorities from traveling out of the Country.

I am consulting you on behalf of my client, Mr. Mohammed Abacha who has
mandated me to urgently look for a foreigner (partner) with large business
to help us immediately move and receive an approximate amount of about
$21.5 million dollars (Twenty One million, Five Hundred Thousand United
States Dollars) into any account comfortable to you.  The account required
for this project can be either personal or corporate.  But it must be an
offshore account that you have total control over. Your area of
specialization will not be a hindrance to the successful execution of this
transaction.

This fund was moved under diplomatic cover and has since been deposited in
a private Security Company, which I cannot disclose to you now for obvious
security reasons.  It was tagged as official consignment belonging to a
foreign affiliate and placed in a crate, tagged antique; thereby making
the consignment safe, and the actual content undisclosed to the Security
Company.

All I want you to do is to receive the said amount in your name and invest
it on behalf of my client's family who shall be a partner (under
anonymity) in whatever business venture you feel is viable. All
documentation regarding this transaction is in my possession and a power
of attorney to transact this business shall be given to you by my client. 

In the light of the above, I am soliciting your assistance and partnership
to move this fund out of the Security Company, as you and I stand to
benefit immensely from this transaction.

After due consultation and approval from my client, we have both agreed
that 20 percent of the fund will be given to you for your assistance.  

Please contact me if you would be interested in assisting, after which I
would reveal further details of this whole operation to you.

Most sincerely

Barrister Sanni Kaloma Ali (SAN)

NB. You may wish to visit the websites below for further confirmation.
http://allafrica.com/stories/200203180074.html
http://www.time.com/time/europe/magazine/2000/27/swiss.html
http://www.transnationale.org/anglais/sources/tiersmonde/dirigeants__abacha.
htm
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From toth at host.sk  Sun Dec  1 16:30:04 2002
From: toth at host.sk (Milan Toth)
Date: Sun, 1 Dec 2002 16:30:04 +0100
Subject: No subject
Message-ID: <20021201163004.A3767@localhost.localdomain>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sun Dec  1 17:19:21 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun, 1 Dec 2002 16:19:21 +0000 (GMT)
Subject: [R] Re: your mail
In-Reply-To: <F138raUMTzFm15k4R9x00006311@hotmail.com>
Message-ID: <Pine.LNX.4.31.0212010813370.1571-100000@gannet.stats>

On Sun, 1 Dec 2002, Moustafa ElHousinie wrote:

> I need to perform Generalized estimating equations on some data. Has 'R' any
> function or routine to do it? (GEE is same as GLM but with correlated y's)
> Thanks in advance

Take a look at the R FAQ or search on CRAN.  There are packages gee and
geepack on CRAN, and you can also find YAGS on Vince Carey's site (and as
Windows version on that area of CRAN).

There are even examples from gee and yags in MASS4 (aka Venables & Ripley,
2002) and hence in the MASS/scripts directory.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rolf at math.unb.ca  Sun Dec  1 19:19:32 2002
From: rolf at math.unb.ca (Rolf Turner)
Date: Sun, 1 Dec 2002 14:19:32 -0400 (AST)
Subject: [R] Quasi-bug in boxplot().
Message-ID: <200212011819.OAA18740@gelfand.math.unb.ca>


There seems to be a problem with partial matching of argument names
in boxplot(), in respect of the "horizontal" argument.  I don't
recall seeing this issue discussed previously.  My apologies if I am
being redundant.  (A scan of CRAN revealed that someone had
experienced problems with the "horizontal" argument, but he was
spelling it out in full, so that was a different issue.)

If I execute

	> x <- rnorm(100)
	> tmp <- boxplot(x,plot=FALSE)
	> bxp(tmp,horiz=TRUE)

I get the horizontal boxplot that I wanted.  However if I go
straight for it, as in

	> boxplot(x,horiz=TRUE)

I get the warning message:

parameter "horiz" couldn't be set in high-level plot() function

and get a vertical boxplot.

I traced the warning down to the parameter "horiz" being passed to
the title() function, which naturally didn't like it.

I finally figured out that what is happening is that there is a little
dodge at the start of boxplot.default() whereby arguments get bundled
into a list called ``pars'', which gets passed on to bxp().
It seems that since "horiz" doesn't match "horizontal" EXACTLY, it
gets bundled into ``pars'' and hence gets handed on to title()
which can't use it and ignored in the body of bxp() where it could
be used.

Things work OK if one says

	> boxplot(x,horizontal=TRUE)

i.e. spelling out ``horizontal'' in full rather than trying to use
``partial argument matching''.

However it seems to me that partial argument matching ***ought*** to
work --- i.e. it ought to be possible to make it work --- in such
a context.  Am I suffering from a misapprehension?

				cheers,

					Rolf Turner
					rolf at math.unb.ca
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From james-chapman at uiowa.edu  Sun Dec  1 20:23:19 2002
From: james-chapman at uiowa.edu (James Chapman)
Date: Sun, 1 Dec 2002 20:23:19 +0100 (MET)
Subject: [R] Date: Sun, 1 Dec 2002 13:23:04 -0600
Message-ID: <000201c2996f$12ade100$a5f5d90c@universihf1nvk>


Hi,

I've run into a bit of a problem with using the RMySQL library. I've
been attempting to create a temporary table in a MySQL database and then
perform a SELECT with a WHEREs clause on the table. In effect perform a
SELECT with a subSELECT. 

The problem is that it never seems to be able to find the table after I
create it. I've been using the dbSendQuery method to create the table
since this seems to be the one too use for sending all forms of SQL
commands.

Is it possible that MySQL is dropping the temporary table every time a
new dbSendQuery is run? Or (more likely) am I using the library
improperly.

Thanks,

James

... asset pricing is paradoxical. On the one hand, the theory is so 
persuasive that it is widely believed to be correct, to the point that 
business, government and even jurisdiction appeal to it. Yet there is 
little evidence that the theory explains the past, let alone that it 
predicts the future. 
	---The Paradox of Asset Pricing
        	by Peter Bossaerts
 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hi_ono2001 at ybb.ne.jp  Sun Dec  1 20:17:18 2002
From: hi_ono2001 at ybb.ne.jp (Hisaji Ono)
Date: Mon, 2 Dec 2002 04:17:18 +0900
Subject: [R] About building R1.6.1 on Cygwin 
References: <Pine.LNX.4.31.0211301803550.29637-100000@gannet.stats>
Message-ID: <002e01c2996e$43bac0c0$118001db@webgis>

Thank you very much for your answers, Professor Ripley & Assistant Professor
Rossini.




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Katarina.Domijan at agresearch.co.nz  Sun Dec  1 20:41:08 2002
From: Katarina.Domijan at agresearch.co.nz (Domijan, Katarina)
Date: Mon, 2 Dec 2002 08:41:08 +1300
Subject: [R] Multiple graphics windows
Message-ID: <B99280700701C242B0D5DA396EDB1D9C029CC572@ruby.agresearch.co.nz>

Hi,

Is it possible to have multiple graphics windows in R? I am running a
function that plots  12  graphs and currently I'm using 
par(mfrow=c(3,4),..) etc but ideally I would like to have the output in
separate graphics windows.

Thanks,

Katarina

=======================================================================
Attention: The information contained in this message and/or attachments
from AgResearch Limited is intended only for the persons or entities
to which it is addressed and may contain confidential and/or privileged
material. Any review, retransmission, dissemination or other use of, or
taking of any action in reliance upon, this information by persons or
entities other than the intended recipients is prohibited by AgResearch
Limited. If you have received this message in error, please notify the
sender immediately.
=======================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sun Dec  1 20:40:14 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Sun, 1 Dec 2002 19:40:14 +0000 (GMT)
Subject: [R] Quasi-bug in boxplot().
In-Reply-To: <200212011819.OAA18740@gelfand.math.unb.ca>
Message-ID: <Pine.GSO.4.44.0212011937150.26369-100000@auk.stats>

On Sun, 1 Dec 2002, Rolf Turner wrote:

>
> There seems to be a problem with partial matching of argument names
> in boxplot(), in respect of the "horizontal" argument.  I don't
> recall seeing this issue discussed previously.  My apologies if I am
> being redundant.  (A scan of CRAN revealed that someone had
> experienced problems with the "horizontal" argument, but he was
> spelling it out in full, so that was a different issue.)
>
> If I execute
>
> 	> x <- rnorm(100)
> 	> tmp <- boxplot(x,plot=FALSE)
> 	> bxp(tmp,horiz=TRUE)
>
> I get the horizontal boxplot that I wanted.  However if I go
> straight for it, as in
>
> 	> boxplot(x,horiz=TRUE)
>
> I get the warning message:
>
> parameter "horiz" couldn't be set in high-level plot() function
>
> and get a vertical boxplot.
>
> I traced the warning down to the parameter "horiz" being passed to
> the title() function, which naturally didn't like it.
>
> I finally figured out that what is happening is that there is a little
> dodge at the start of boxplot.default() whereby arguments get bundled
> into a list called ``pars'', which gets passed on to bxp().
> It seems that since "horiz" doesn't match "horizontal" EXACTLY, it
> gets bundled into ``pars'' and hence gets handed on to title()
> which can't use it and ignored in the body of bxp() where it could
> be used.
>
> Things work OK if one says
>
> 	> boxplot(x,horizontal=TRUE)
>
> i.e. spelling out ``horizontal'' in full rather than trying to use
> ``partial argument matching''.
>
> However it seems to me that partial argument matching ***ought*** to
> work --- i.e. it ought to be possible to make it work --- in such
> a context.  Am I suffering from a misapprehension?

It is defined *not* to work.  The call is

     boxplot(x, ..., range = 1.5, width = NULL, varwidth = FALSE,
             notch = FALSE, outline = TRUE, names, boxwex = 0.8, plot = TRUE,
             border = par("fg"), col = NULL, log = "", pars = NULL,
             horizontal = FALSE, add = FALSE, at = NULL)

and argument after ... are not partially matched.

See, e.g. `S Programming' p.40.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rolf at math.unb.ca  Sun Dec  1 21:29:15 2002
From: rolf at math.unb.ca (Rolf Turner)
Date: Sun, 1 Dec 2002 16:29:15 -0400 (AST)
Subject: [R] Quasi-bug in boxplot().
Message-ID: <200212012029.QAA20889@gelfand.math.unb.ca>


In response to my comment

>  > However it seems to me that partial argument matching ***ought*** to
>  > work --- i.e. it ought to be possible to make it work --- in such
>  > a context.  Am I suffering from a misapprehension?

Brian Ripley wrote

>  It is defined *not* to work.  The call is
>  
>       boxplot(x, ..., range = 1.5, width = NULL, varwidth = FALSE,
>               notch = FALSE, outline = TRUE, names, boxwex = 0.8, plot = TRUE,
>               border = par("fg"), col = NULL, log = "", pars = NULL,
>               horizontal = FALSE, add = FALSE, at = NULL)
>  
>  and argument after ... are not partially matched.
>  
>  See, e.g. `S Programming' p.40.

O.K. That's clear enough now.  But ***WHY***?  I.e. why structure the
arguments of boxplot() in this way?  I.e. why put the ... argument
before everything but x, so that partial matching cannot be used on
the rest of the arguments?

					cheers,

						Rolf Turner

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Sun Dec  1 21:43:11 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 01 Dec 2002 21:43:11 +0100
Subject: [R] Multiple graphics windows
In-Reply-To: <B99280700701C242B0D5DA396EDB1D9C029CC572@ruby.agresearch.co.nz>
References: <B99280700701C242B0D5DA396EDB1D9C029CC572@ruby.agresearch.co.nz>
Message-ID: <x2el91v5b4.fsf@biostat.ku.dk>

"Domijan, Katarina" <Katarina.Domijan at agresearch.co.nz> writes:

> Hi,
> 
> Is it possible to have multiple graphics windows in R? I am running a
> function that plots  12  graphs and currently I'm using 
> par(mfrow=c(3,4),..) etc but ideally I would like to have the output in
> separate graphics windows.

Easy. Try "X11();X11()" or "windows();windows()" depending on your
platform, and read help(dev.cur) etc.

> =======================================================================
> Attention: The information contained in this message and/or attachments
> from AgResearch Limited is intended only for the persons or entities
> to which it is addressed and may contain confidential and/or privileged
> material. 

Yeah, it'll stay between us and the readers...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Sun Dec  1 22:03:34 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 01 Dec 2002 22:03:34 +0100
Subject: [R] Quasi-bug in boxplot().
In-Reply-To: <200212012029.QAA20889@gelfand.math.unb.ca>
References: <200212012029.QAA20889@gelfand.math.unb.ca>
Message-ID: <x2adjpv4d5.fsf@biostat.ku.dk>

Rolf Turner <rolf at math.unb.ca> writes:

> >  It is defined *not* to work.  The call is
> >  
> >       boxplot(x, ..., range = 1.5, width = NULL, varwidth = FALSE,
> >               notch = FALSE, outline = TRUE, names, boxwex = 0.8, plot = TRUE,
> >               border = par("fg"), col = NULL, log = "", pars = NULL,
> >               horizontal = FALSE, add = FALSE, at = NULL)
> >  
> >  and argument after ... are not partially matched.
> >  
> >  See, e.g. `S Programming' p.40.
> 
> O.K. That's clear enough now.  But ***WHY***?  I.e. why structure the
> arguments of boxplot() in this way?  I.e. why put the ... argument
> before everything but x, so that partial matching cannot be used on
> the rest of the arguments?

Not quite sure about boxplot.default. In boxplot.formula however,
there's a subset argument that will cause some grief if partially
matched. One other side effect of putting arguments after ... is that
it prevents positional matching, which might be the point in
boxplot.default -- avoid coding like boxplot(x, 1.5, NULL, TRUE, TRUE)
and the ensuing complaints if the argument order gets reshuffled.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Kris.Nackaerts at agr.kuleuven.ac.be  Sun Dec  1 23:20:20 2002
From: Kris.Nackaerts at agr.kuleuven.ac.be (Kris Nackaerts)
Date: Sun,  1 Dec 2002 23:20:20 +0100
Subject: [R] Logistic regression
Message-ID: <1038781219.3dea8b2400fc6@webmail.kuleuven.ac.be>

Hi,

I can't figure out how to get the P-values out of the summery of a logistic
regression. I used:

logit.out <- glm(...)

and then I should be able to extract just the P values for the coefficients.

Any idea?

Kris

-- 
------------------------------------------------------------------------
 
 http://perswww.kuleuven.ac.be/~u0027178/VCard/mycard.php?name=krisn
 
------------------------------------------------------------------------
 Minds are like parachutes, they only work when open
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From vograno at arbitrade.com  Mon Dec  2 01:47:03 2002
From: vograno at arbitrade.com (Vadim Ogranovich)
Date: Sun, 1 Dec 2002 18:47:03 -0600 
Subject: [R] readLines() changes mode of connection
Message-ID: <AFD78192EC49D311BFAE00902798AB8F23DC12@jupiter.arbitrade.com>

Hi,

It seems like reading a line from a gzfile() connection changes the mode of
the connection from text to binary (it also alters "can write", in case it
matters). The following transcript, produced on RedHat 7.1, demonstrates
this "feature" (note the evolution of file$text). Is this expected?

Thanks, Vadim


> file <- gzfile("foo.gz")
file <- gzfile("foo.gz")
> summary(file)
summary(file)
$description
[1] "foo.gz"

$class
[1] "gzfile"

$mode
[1] "rb6"

$text
[1] "text"

$opened
[1] "closed"

$"can read"
[1] "yes"

$"can write"
[1] "yes"

> hdr <- readLines(file, 1)
hdr <- readLines(file, 1)
> summary(file)
summary(file)
$description
[1] "foo.gz"

$class
[1] "gzfile"

$mode
[1] "rb6"

$text
[1] "binary"

$opened
[1] "closed"

$"can read"
[1] "yes"

$"can write"
[1] "no"



-------------------------------------------------- 
DISCLAIMER 
This e-mail, and any attachments thereto, is intended only for use by the
addressee(s) named herein and may contain legally privileged and/or
confidential information.  If you are not the intended recipient of this
e-mail, you are hereby notified that any dissemination, distribution or
copying of this e-mail, and any attachments thereto, is strictly prohibited.
If you have received this e-mail in error, please immediately notify me and
permanently delete the original and any copy of any e-mail and any printout
thereof. 

E-mail transmission cannot be guaranteed to be secure or error-free.  The
sender therefore does not accept liability for any errors or omissions in
the contents of this message which arise as a result of e-mail transmission.

NOTICE regarding privacy and confidentiality 

Knight Trading Group may, at its discretion, monitor and review the content
of all e-mail communications. 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pauljohn at ku.edu  Mon Dec  2 02:43:22 2002
From: pauljohn at ku.edu (Paul Johnson)
Date: Sun, 01 Dec 2002 19:43:22 -0600
Subject: [R] Logistic Regression with 9 classes
References: <1038497980.3de638bc0ffb1@webmail.sapo.pt>
Message-ID: <3DEABABA.3090103@ku.edu>

Hope this helps:

Your approach depends on your statistical theory.

If the 9 categories are ordered, the ordinal logistic (or probit) model 
is called for.  The first publication I know of that proposed it was R D 
McKelvey and W Zavoina.   A statistical model for the analysis of 
ordinal level dependent variables.Journal of Mathematical Sociology, 
4:103-120, 1975.

The idea is that the probability of falling into one category depends on
z=XB+e,
where e is either logistic or Normal, depending on your taste. THe 
resulting estimates give you estimates of B as well as 8 "thresholds" 
which divide the "z scale" into sections and relate to the predicted 
outcome for the categories.

For that, the MASS packages has polr.


If the 9 categories are unordered, then some other statistical model 
altogether is needed. One I know of is often called a multinomial model, 
where you set one category as the baseline and then estimate the impact 
of the variables to differentiate them from the baseline.  For 9 
cagegories, you'd end up with 8 models, of the sort

ln(Pj/P0) = Xbj, j=1,...8.

In MASS, the function multinom is for that purpose, but I have not tried it.

Luis Silva wrote:
> Hello!
> 
> I need to classify a data set with 19 variables and 9 classes 
> using Logistic Regression(on R).
> I know that when we have only 2 classes we can use glm() to 
> estimate the coefficients of the model. But I don?t understand 
> how can I do a classification task with Logistic Regression on 
> a data set with 9 classes! 
> Does anybody know how can I estimate these coefficients (of a 
> model with 9 classes) on R?
> 
> Thank you!
> Janete
>


-- 
Paul E. Johnson                       email: pauljohn at ukans.edu
Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
University of Kansas                  Office: (785) 864-9086
Lawrence, Kansas 66045                FAX: (785) 864-5700

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From h_m_ at po.harenet.ne.jp  Mon Dec  2 03:42:50 2002
From: h_m_ at po.harenet.ne.jp (Hiroto Miyoshi)
Date: Mon, 2 Dec 2002 11:42:50 +0900
Subject: [R] how to make help files available in R 1.61 
Message-ID: <006101c299ac$827ab660$0500a8c0@miyoshi>

Dear R-users
I installed R-1.6.1 from 8 mini-disk files.
However, help files (html version) cannot be available.
Could anyone tell me how to install them properly?
Setup program does not show any error 
message while installing the files.
Sincerely

Hiroto
-----------------------
Hiroto Miyoshi
????
h_m_ at po.harenet.ne.jp

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Mon Dec  2 05:01:43 2002
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 01 Dec 2002 23:01:43 -0500
Subject: [R] Logistic regression
In-Reply-To: <1038781219.3dea8b2400fc6@webmail.kuleuven.ac.be>
Message-ID: <5.1.0.14.2.20021201225954.01dd2ea0@mcmail.cis.mcmaster.ca>

Dear Kris,

At 11:20 PM 12/1/2002 +0100, you wrote:
>Hi,
>
>I can't figure out how to get the P-values out of the summery of a logistic
>regression. I used:
>
>logit.out <- glm(...)
>
>and then I should be able to extract just the P values for the coefficients.
>
>Any idea?

The easiest way is probably to compute the summary and extract the p-values 
from that: summary(logit.out)$coefficients[,4].

I hope that this helps,
  John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jasont at indigoindustrial.co.nz  Mon Dec  2 05:34:14 2002
From: jasont at indigoindustrial.co.nz (jasont@indigoindustrial.co.nz)
Date: Mon, 2 Dec 2002 04:34:14 GMT
Subject: [R] Regular Expressionsionism
Message-ID: <E18IiHe-0000qQ-00@grunt5.ihug.co.nz>

> "Derek Eder" <Derek.Eder at neuro.gu.se> writes:
..
> > ... Using a regular expression in the "pattern" argument to 
> > list.files() to restrict the return to filenames which
> > contain both "Elstim" and "post".  E.g.,
> > 
> > >list.files()
> > ... 
> > [133] "J30710_Control_msa_amplitude_5_25_s1-
30w.pre"                                    
               
> > [134] "J30710_Elstim_msa_amplitude_5_25_s1-
30w.post"                                    
               
> > [135] "J30710_Elstim_msa_amplitude_5_25_s1-
30w.pre"                                     
               
> > [136] "J30712_Control_msa_amplitude_5_25_s1-41_44-
46_48w.post"                          
               
> > [137] "J30712_Control_msa_amplitude_5_25_s1-41_44-
46_48w.pre"                           
               
> > [138] "J30712_Elstim_msa_amplitude_5_25_s1-17_19-
43_45_48w.post"                        
               
> >                                        
> > I have not found the key to generating the logical AND equivalent of 
the "|" OR infix
operator, a 
> > proxy for the simpleton's dream:  my.list.files(pattern="*Elstim" 
& "*post") 

In this case, the quick and (very) dirty method I'd also use is:

grep("Elstim",grep("post",list.files()))

generalising that via recursion to match an arbitrary number of REs 
and "&" and "|" operators is left as an excercise.... 

Cheers

Jason

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Mon Dec  2 08:53:05 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 02 Dec 2002 08:53:05 +0100
Subject: [R] how to make help files available in R 1.61
References: <006101c299ac$827ab660$0500a8c0@miyoshi>
Message-ID: <3DEB1161.34218115@statistik.uni-dortmund.de>



Hiroto Miyoshi wrote:
> 
> Dear R-users
> I installed R-1.6.1 from 8 mini-disk files.
> However, help files (html version) cannot be available.
> Could anyone tell me how to install them properly?
> Setup program does not show any error
> message while installing the files.
> Sincerely
> 
> Hiroto

Only compiled html files are included in the "mini" distribution. To get
the html files you either have to get the "full" binary distribution
(rw1061.exe is recent) or compile from sources or compile from sources.

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Dec  2 09:14:50 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 2 Dec 2002 08:14:50 +0000 (GMT)
Subject: [R] readLines() *does not* change mode of connection
In-Reply-To: <AFD78192EC49D311BFAE00902798AB8F23DC12@jupiter.arbitrade.com>
Message-ID: <Pine.LNX.4.31.0212020809120.1625-100000@gannet.stats>

The `text' field is *not* the mode: look at your own output.

This is expected.  In your first output the connection has not been
opened.  You asked provisionally for a binary mode, but this is
provisional until the connection has actually been opened.
readLines does open the connection.

The fields of a connection are not documented.

On Sun, 1 Dec 2002, Vadim Ogranovich wrote:

> Hi,
>
> It seems like reading a line from a gzfile() connection changes the mode of
> the connection from text to binary (it also alters "can write", in case it
> matters). The following transcript, produced on RedHat 7.1, demonstrates
> this "feature" (note the evolution of file$text). Is this expected?
>
> Thanks, Vadim
>
>
> > file <- gzfile("foo.gz")
> file <- gzfile("foo.gz")
> > summary(file)
> summary(file)
> $description
> [1] "foo.gz"
>
> $class
> [1] "gzfile"
>
> $mode
> [1] "rb6"
>
> $text
> [1] "text"
>
> $opened
> [1] "closed"
>
> $"can read"
> [1] "yes"
>
> $"can write"
> [1] "yes"
>
> > hdr <- readLines(file, 1)
> hdr <- readLines(file, 1)
> > summary(file)
> summary(file)
> $description
> [1] "foo.gz"
>
> $class
> [1] "gzfile"
>
> $mode
> [1] "rb6"
>
> $text
> [1] "binary"
>
> $opened
> [1] "closed"
>
> $"can read"
> [1] "yes"
>
> $"can write"
> [1] "no"
>
>
>
> --------------------------------------------------
> DISCLAIMER
> This e-mail, and any attachments thereto, is intended only for use by the
> addressee(s) named herein and may contain legally privileged and/or
> confidential information.  If you are not the intended recipient of this
> e-mail, you are hereby notified that any dissemination, distribution or
> copying of this e-mail, and any attachments thereto, is strictly prohibited.
> If you have received this e-mail in error, please immediately notify me and
> permanently delete the original and any copy of any e-mail and any printout
> thereof.
>
> E-mail transmission cannot be guaranteed to be secure or error-free.  The
> sender therefore does not accept liability for any errors or omissions in
> the contents of this message which arise as a result of e-mail transmission.
>
> NOTICE regarding privacy and confidentiality
>
> Knight Trading Group may, at its discretion, monitor and review the content
> of all e-mail communications.
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ozric at web.de  Mon Dec  2 08:51:09 2002
From: ozric at web.de (Christian Schulz)
Date: Mon, 2 Dec 2002 08:51:09 +0100
Subject: [R] advanced tabulation
Message-ID: <000701c299d7$9499c900$d4b707d5@c5c9i0>

i make me thoughts about a  "advanced tabulation"  package similar to
commercial software products like Quantum or Wincross.

Before i'm beginning to fight with coding - is in the mailing-List anybody
doing something similar in the past and have a good starting point
and/or suggestions for me ?

My purpose ist to define for a dataset  headers (i.e. sex,age-groupes..)
which should write in the colums of a landscape table and percentage all
other
variables ( rows) dependence to the header category !?

P.S. The first attempts sure more easy than
the possibilities in wincross  .......

http://www.skim.nl/software/images/WC-banners.gif
http://www.skim.nl/software/images/WC-tables.gif

many thanks for advance & regards,
Christian

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._



From maechler at stat.math.ethz.ch  Mon Dec  2 10:35:11 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon Dec  2 10:35:11 2002
Subject: [R] R-help moved to mailman
Message-ID: <15851.10524.314512.404704@gargle.gargle.HOWL>

I have now moved the last (and largest!) R mailing list from
majordomo to [procmail + mailman].
This also ends the life of "R-help-digest" which is now part of
"R-help", each such subscriber having a [digest] flag set.

Have a look at the Web interface at
http://www.stat.math.ethz.ch/mailman/listinfo/r-help/

You need password to modify your subscription.
You should all get it sent to you in a few hours (as a monthly
reminder the first of each month), but can always get it sent by
requiring it through the web interface -- you need to know the
exact e-mail address you are subscribed as for all that.

Finally, note that the sender is now 
"r-help-admin at stat..." instead of "owner-R-help at ..."

---
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From fharrell at virginia.edu  Mon Dec  2 12:57:06 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Mon Dec  2 12:57:06 2002
Subject: [R] Logistic Regression with 9 classes
In-Reply-To: <3DEABABA.3090103@ku.edu>
References: <1038497980.3de638bc0ffb1@webmail.sapo.pt>
	<3DEABABA.3090103@ku.edu>
Message-ID: <20021202065704.60a40d47.fharrell@virginia.edu>

On Sun, 01 Dec 2002 19:43:22 -0600
Paul Johnson <pauljohn at ku.edu> wrote:

> Hope this helps:
> 
> Your approach depends on your statistical theory.
> 
> If the 9 categories are ordered, the ordinal logistic (or probit) model 
> is called for.  The first publication I know of that proposed it was R D 
> McKelvey and W Zavoina.   A statistical model for the analysis of 
> ordinal level dependent variables.Journal of Mathematical Sociology, 
> 4:103-120, 1975.

One small correction Paul.  An earlier paper developing the proportional odds model is

@ARTICLE{wal67,
  author = {Walker, S. H. and Duncan, D. B.},
  year = 1967,
  title = {Estimation of the probability of an event as a function of several
          independent variables},
  journal = Biometrika,
  volume = 54,
  pages = {167-178},
  annote = {logistic model; ordinal logistic model}
}

Frank

> 
> The idea is that the probability of falling into one category depends on
> z=XB+e,
> where e is either logistic or Normal, depending on your taste. THe 
> resulting estimates give you estimates of B as well as 8 "thresholds" 
> which divide the "z scale" into sections and relate to the predicted 
> outcome for the categories.
> 
> For that, the MASS packages has polr.
> 
> 
> If the 9 categories are unordered, then some other statistical model 
> altogether is needed. One I know of is often called a multinomial model, 
> where you set one category as the baseline and then estimate the impact 
> of the variables to differentiate them from the baseline.  For 9 
> cagegories, you'd end up with 8 models, of the sort
> 
> ln(Pj/P0) = Xbj, j=1,...8.
> 
> In MASS, the function multinom is for that purpose, but I have not tried it.
> 
> Luis Silva wrote:
> > Hello!
> > 
> > I need to classify a data set with 19 variables and 9 classes 
> > using Logistic Regression(on R).
> > I know that when we have only 2 classes we can use glm() to 
> > how can I do a classification task with Logistic Regression on 
> > a data set with 9 classes! 
> > Does anybody know how can I estimate these coefficients (of a 
> > model with 9 classes) on R?
> > 
> > Thank you!
> > Janete
> >
> 
> 
> -- 
> Paul E. Johnson                       email: pauljohn at ukans.edu
> Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
> University of Kansas                  Office: (785) 864-9086
> Lawrence, Kansas 66045                FAX: (785) 864-5700
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From fharrell at virginia.edu  Mon Dec  2 13:03:05 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Mon Dec  2 13:03:05 2002
Subject: [R] advanced tabulation
In-Reply-To: <000701c299d7$9499c900$d4b707d5@c5c9i0>
References: <000701c299d7$9499c900$d4b707d5@c5c9i0>
Message-ID: <20021202070037.405d5b3d.fharrell@virginia.edu>

On Mon, 2 Dec 2002 08:51:09 +0100
Christian Schulz <ozric at web.de> wrote:

> i make me thoughts about a  "advanced tabulation"  package similar to
> commercial software products like Quantum or Wincross.
> 
> Before i'm beginning to fight with coding - is in the mailing-List anybody
> doing something similar in the past and have a good starting point
> and/or suggestions for me ?
> 
> My purpose ist to define for a dataset  headers (i.e. sex,age-groupes..)
> which should write in the colums of a landscape table and percentage all
> other
> variables ( rows) dependence to the header category !?
> 
> P.S. The first attempts sure more easy than
> the possibilities in wincross  .......
> 
> http://www.skim.nl/software/images/WC-banners.gif
> http://www.skim.nl/software/images/WC-tables.gif
> 
> many thanks for advance & regards,
> Christian
> 

summary(columnvariable ~ rowvar1+rowvar2+...., method='reverse') will do what you want, if you are interested in separate summaries for each row variable.  This uses the summary.formula function in the Hmisc library (http://hesweb1.med.virginia.edu/biostat/s/Hmisc.html) for which there are plot, print, and latex methods for formatting the output.  For 2-way cross-classified summaries see method='cross'.
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From mpiktas at delfi.lt  Mon Dec  2 13:40:08 2002
From: mpiktas at delfi.lt (Mpiktas)
Date: Mon Dec  2 13:40:08 2002
Subject: [R] Computation time differences between Linux and Windows
Message-ID: <1038832357.855.5.camel@mpiktas>

Hi,

Today I came accros a very interesting thing. I was asked how much time
it takes for R to calculate the product of two large matrices. So I
generated two 2000x2000 matrices of random normal numbers and measured
the time with function system.time

m1 <- matrix(rnorm(2000*2000),2000)
m2 <- matrix(rnorm(2000*2000),2000)
system.time(m3 <- m1%*%m2)

and it produced

46.47  0.36 47.68  0.00  0.00

on Debian GNU/Linux Woody, R 1.6.1 computer. The same three lines on the
same computer but under Windows 2000 and R 1.5.1 I got

550.23   0.40 552.97     NA     NA

So to calculate the product of two matrices it takes approximately 10
times more on Windows than on Linux. 

Is this a bug or a feature?

The same operation in Matlab 5.3 on Windows 2000 took approximately 300
seconds and in Octave 2.0.16.92 (i386-pc-linux-gnu) on Linux about 550
seconds. I tried to keep minimum processes running during the
computations.

I suspect the answer to this is different memory management accros
different programs and platforms. Am I right?

Thanks for any help

Sincerely,

Vaidotas Zemlys



From ripley at stats.ox.ac.uk  Mon Dec  2 14:03:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Dec  2 14:03:03 2002
Subject: [R] Computation time differences between Linux and Windows
In-Reply-To: <1038832357.855.5.camel@mpiktas>
Message-ID: <Pine.LNX.4.31.0212021252070.10311-100000@gannet.stats>

On 2 Dec 2002, Mpiktas wrote:

> Today I came accros a very interesting thing. I was asked how much time

Really?  You have a real application for repeatedly multiplying random
matrices and nothing else?

> it takes for R to calculate the product of two large matrices. So I
> generated two 2000x2000 matrices of random normal numbers and measured
> the time with function system.time
>
> m1 <- matrix(rnorm(2000*2000),2000)
> m2 <- matrix(rnorm(2000*2000),2000)
> system.time(m3 <- m1%*%m2)
>
> and it produced
>
> 46.47  0.36 47.68  0.00  0.00
>
> on Debian GNU/Linux Woody, R 1.6.1 computer. The same three lines on the
> same computer but under Windows 2000 and R 1.5.1 I got
>
> 550.23   0.40 552.97     NA     NA
>
> So to calculate the product of two matrices it takes approximately 10
> times more on Windows than on Linux.
>
> Is this a bug or a feature?

Most likely your own misunderstanding.  Your Debian installation will be
using an optimized BLAS (probably the only pre-compiled distribution that
does by default), and I don't suppose that you used an optimized BLAS for
Windows (although they are available on CRAN for the common chips).

It is bad practice to compare the current version of R on one system with
an obselete one on another, as well as to compare ones with different
degrees of tuning.

> The same operation in Matlab 5.3 on Windows 2000 took approximately 300
> seconds and in Octave 2.0.16.92 (i386-pc-linux-gnu) on Linux about 550
> seconds. I tried to keep minimum processes running during the
> computations.
>
> I suspect the answer to this is different memory management accros
> different programs and platforms. Am I right?

Not at this size of matrix.

BLAS makes a big difference to simple computations, but little to real
problems done in R.  Simple `benchmarks' can be seriously misleading. In
fact, for this one R was actually slowed down for users without a fast
BLAS to allow the speed-up using ATLAS (the default on Debian).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Mon Dec  2 14:15:09 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon Dec  2 14:15:09 2002
Subject: [R] Quasi-bug in boxplot().
In-Reply-To: <x2adjpv4d5.fsf@biostat.ku.dk>
References: <200212012029.QAA20889@gelfand.math.unb.ca>
	<x2adjpv4d5.fsf@biostat.ku.dk>
Message-ID: <15851.23727.448128.321674@gargle.gargle.HOWL>

>>>>> "PD" == Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk>
>>>>>     on 01 Dec 2002 22:03:34 +0100 writes:

    PD> Rolf Turner <rolf at math.unb.ca> writes:
    >> >  It is defined *not* to work.  The call is
    >> >  
    >> >       boxplot(x, ..., range = 1.5, width = NULL, varwidth = FALSE,
    >> >               notch = FALSE, outline = TRUE, names, boxwex = 0.8, plot = TRUE,
    >> >               border = par("fg"), col = NULL, log = "", pars = NULL,
    >> >               horizontal = FALSE, add = FALSE, at = NULL)
    >> >  
    >> >  and argument after ... are not partially matched.
    >> >  
    >> >  See, e.g. `S Programming' p.40.
    >> 
    >> O.K. That's clear enough now.  But ***WHY***?  I.e. why structure the
    >> arguments of boxplot() in this way?  I.e. why put the ... argument
    >> before everything but x, so that partial matching cannot be used on
    >> the rest of the arguments?

    PD> Not quite sure about boxplot.default. 
I'm sure there:
How else should calls like

    boxplot(rnorm(100), rt(100,df=10), rt(110, df = 4), rcauchy(120))

work?  And these should work if only for S backcompatibility.
Martin

    PD> In boxplot.formula however,
    PD> there's a subset argument that will cause some grief if partially
    PD> matched. One other side effect of putting arguments after ... is that
    PD> it prevents positional matching, which might be the point in
    PD> boxplot.default -- avoid coding like boxplot(x, 1.5, NULL, TRUE, TRUE)
    PD> and the ensuing complaints if the argument order gets reshuffled.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From Bill.Shipley at Usherbrooke.ca  Mon Dec  2 14:27:03 2002
From: Bill.Shipley at Usherbrooke.ca (Bill Shipley)
Date: Mon Dec  2 14:27:03 2002
Subject: [R] code for maximum entropy formalism
Message-ID: <5.1.1.6.0.20021202082119.00b05c20@courrier.usherbrooke.ca>

Hello.  The "maximum entropy formalism" is a general method of choosing the 
probability distribution that has maximum entropy, subject to constraints 
on its moments.  Does anyone have code for performing this (for discrete 
and for continuous distributions)?
Thanks.

Bill Shipley
Departement de biologie
Universite de Sherbrooke
Sherbrooke (Quebec) CANADA J1K 2R9
Bill.Shipley at USherbrooke.ca
http://callisto.si.usherb.ca:8080/bshipley/



From dj at research.bell-labs.com  Mon Dec  2 14:56:03 2002
From: dj at research.bell-labs.com (David James)
Date: Mon Dec  2 14:56:03 2002
Subject: [R] Date: Sun, 1 Dec 2002 13:23:04 -0600
In-Reply-To: <000201c2996f$12ade100$a5f5d90c@universihf1nvk>; from james-chapman@uiowa.edu on Sun, Dec 01, 2002 at 08:23:19PM +0100
References: <000201c2996f$12ade100$a5f5d90c@universihf1nvk>
Message-ID: <20021202085522.A16907@jessie.research.bell-labs.com>

Hi James,

Yes, it's possible to define TEMPORARY tables using RMySQL, but you
need to be aware that TEMPORARY tables are by default in-memory
and always thread-specific (a TEMPORARY table created in one
connection/thread is not visible outside that thread/connection).
In addition, in version of MySQL prior to 4.0 you find the following
warning (Appendix A.6.3, MySQL

   "You can't use temporary tables more than once in the same query.
   For example, the following doesn't work:

     SELECT * from temporary_table, temprary_table as t1;

   We plan to fix the above in 4.0."

Make sure you use dbSendQuery() over the same connection (this will ensure
the queries are handled by the same thread in the MySQL server). [dbGetQuery()
opens an extra connection if the current connection has a pending result set.]

--
David

James Chapman wrote:
> 
> Hi,
> 
> I've run into a bit of a problem with using the RMySQL library. I've
> been attempting to create a temporary table in a MySQL database and then
> perform a SELECT with a WHEREs clause on the table. In effect perform a
> SELECT with a subSELECT. 
> 
> The problem is that it never seems to be able to find the table after I
> create it. I've been using the dbSendQuery method to create the table
> since this seems to be the one too use for sending all forms of SQL
> commands.
> 
> Is it possible that MySQL is dropping the temporary table every time a
> new dbSendQuery is run? Or (more likely) am I using the library
> improperly.
> 
> Thanks,
> 
> James
> 
> ... asset pricing is paradoxical. On the one hand, the theory is so 
> persuasive that it is widely believed to be correct, to the point that 
> business, government and even jurisdiction appeal to it. Yet there is 
> little evidence that the theory explains the past, let alone that it 
> predicts the future. 
> 	---The Paradox of Asset Pricing
>         	by Peter Bossaerts
>  
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._



From AlessandroSemeria at cramont.it  Mon Dec  2 15:32:02 2002
From: AlessandroSemeria at cramont.it (AlessandroSemeria@cramont.it)
Date: Mon Dec  2 15:32:02 2002
Subject: [R] gene ontology association
Message-ID: <OF2EE8FE01.E45A77A3-ONC1256C83.004F43CD@tomware.it>

Hello! I don't know if there is some R-package able
to associate  ontology  to a long list of UniGene Name (a txt-tab file or
an XML file), or
if the best way is a Perl script.
Some suggestion? Thanks!

A. S.



From rgentlem at jimmy.harvard.edu  Mon Dec  2 15:43:06 2002
From: rgentlem at jimmy.harvard.edu (Robert Gentleman)
Date: Mon Dec  2 15:43:06 2002
Subject: [R] gene ontology association
In-Reply-To: <OF2EE8FE01.E45A77A3-ONC1256C83.004F43CD@tomware.it>; from AlessandroSemeria@cramont.it on Mon, Dec 02, 2002 at 03:34:02PM +0100
References: <OF2EE8FE01.E45A77A3-ONC1256C83.004F43CD@tomware.it>
Message-ID: <20021202094236.C21326@jimmy.harvard.edu>

On Mon, Dec 02, 2002 at 03:34:02PM +0100, AlessandroSemeria at cramont.it wrote:
> Hello! I don't know if there is some R-package able
> to associate  ontology  to a long list of UniGene Name (a txt-tab file or
> an XML file), or
> if the best way is a Perl script.
> Some suggestion? Thanks!

 It depends on where the UniGene names come from and whether we have
 already done a mapping (for example if they were from some commonly
 used Affymetrix chips then it would be relatively easy). If not, you
 need to do the mapping - what is easiest depends on what you know,
 for me R is usually easier than Perl for many others it goes the
 other way...but really, you need to be a bit more specific about what
 you are trying to do if you want anyone to help you.


> 
> A. S.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
+---------------------------------------------------------------------------+
| Robert Gentleman                 phone : (617) 632-5250                   |
| Associate Professor              fax:   (617)  632-2444                   |
| Department of Biostatistics      office: M1B20
| Harvard School of Public Health  email: rgentlem at jimmy.dfci.harvard.edu   |
+---------------------------------------------------------------------------+



From klaus.abberger at uni-konstanz.de  Mon Dec  2 17:13:11 2002
From: klaus.abberger at uni-konstanz.de (Klaus Abberger)
Date: Mon Dec  2 17:13:11 2002
Subject: [R] Monte Carlo chisq test
Message-ID: <000601c29a18$7055f7d0$83462286@hermes>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021202/9b282e8e/attachment.pl

From rue at jimmy.harvard.edu  Mon Dec  2 17:15:29 2002
From: rue at jimmy.harvard.edu (Montse Rue)
Date: Mon Dec  2 17:15:29 2002
Subject: [R] Confidence interval for predictions in mixed effects models
References: <20021202145503.21301.17456.Mailman@hypatia.math.ethz.ch>
Message-ID: <3DEB75F1.4255F36F@jimmy.harvard.edu>

Hi,

I would like to know if I can obtain confidence intervals for predictions when
using nlme.

Thanks!

Montse Rue
Research Scientist
Dana-Farber Cancer Institute
Boston, MA



From bates at stat.wisc.edu  Mon Dec  2 17:45:03 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon Dec  2 17:45:03 2002
Subject: [R] Confidence interval for predictions in mixed effects models
In-Reply-To: <3DEB75F1.4255F36F@jimmy.harvard.edu>
References: <20021202145503.21301.17456.Mailman@hypatia.math.ethz.ch>
	<3DEB75F1.4255F36F@jimmy.harvard.edu>
Message-ID: <6risycqsk1.fsf@bates5.stat.wisc.edu>

Montse Rue <rue at jimmy.harvard.edu> writes:

> I would like to know if I can obtain confidence intervals for
> predictions when using nlme.

There is no pre-defined function to do that.  If you are predicting
based on the fixed-effects terms only (i.e. the "population"
predictions) you could use the standard errors of those parameters to
calculate a standard error of your predicted mean response.  If you
are predicting for observed values of the grouping variable(s) it
would be much more difficult to get standard errors of the mean
response.  If I recall correctly the conditional standard deviations
of the conditional modes of the random effects are not passed back to
R from the C code.



From vograno at arbitrade.com  Mon Dec  2 17:58:03 2002
From: vograno at arbitrade.com (Vadim Ogranovich)
Date: Mon Dec  2 17:58:03 2002
Subject: [R] plotting ts: overlaying different years
Message-ID: <AFD78192EC49D311BFAE00902798AB8F23DC15@jupiter.arbitrade.com>

Hi,

I have a time series given as a couple of vectors: one of POSIXt dates and
the other of values. I am looking for a seasonal pattern and I want to plot
annual segments of the series aligned by months. For example if my data
spans Jan-96 - Dec-97 I want  to have two graphs on a single plot as
functions of day of the year. How can I do this?

Thanks, Vadim

-------------------------------------------------- 
DISCLAIMER 
This e-mail, and any attachments thereto, is intended only for use by the
addressee(s) named herein and may contain legally privileged and/or
confidential information.  If you are not the intended recipient of this
e-mail, you are hereby notified that any dissemination, distribution or
copying of this e-mail, and any attachments thereto, is strictly prohibited.
If you have received this e-mail in error, please immediately notify me and
permanently delete the original and any copy of any e-mail and any printout
thereof. 

E-mail transmission cannot be guaranteed to be secure or error-free.  The
sender therefore does not accept liability for any errors or omissions in
the contents of this message which arise as a result of e-mail transmission.

NOTICE regarding privacy and confidentiality 

Knight Trading Group may, at its discretion, monitor and review the content
of all e-mail communications.



From matej at ceplovi.cz  Mon Dec  2 19:37:05 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Mon Dec  2 19:37:05 2002
Subject: [R] Crawley's book on S-Plus and one strangeness
Message-ID: <20021202183343.GA2401@komensky.surfbest.net>

Hi,

I have got to my hands an excellent book by Michael J. Crawley
``Statistical Computing: An Introduction to Data Analysis using
S-Plus'' (John Wiley & Sons, Ltd, ISBN 0-471-56040-5). Its beauty
for me is in the fact, that it is more of ``An Introduction to
Data Analysis'' than ``using S-Plus'', but I guess that it may be
of interest for many others.

Most of the examples in the book are however taken from S-Plus
and using datasets provided with it. Is there anywhere a copy of
these datasets available for R?

And one small question aside: I was very much surprised (in this
book as well as on this list) how many times people use
sqrt(var(x)) when what they want to say (IMHO) is sd(x). Is it
just a macho way to show that I understand more complicated
things, or is there any real difference between the two?

Have a nice day,

	Matej

-- 
Matej Cepl, matej at ceplovi.cz,
Finger: 89EF 4BC6 288A BF43 1BAB  25C3 E09F EF25 D964 84AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
 
Science is meaningless because it gives no answer to our
question, the only question important to us: ``What shall we do
and how shall we live?''
    -- Lev Nikolaevich Tolstoy



From bates at stat.wisc.edu  Mon Dec  2 19:59:03 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon Dec  2 19:59:03 2002
Subject: [R] Crawley's book on S-Plus and one strangeness
In-Reply-To: <20021202183343.GA2401@komensky.surfbest.net>
References: <20021202183343.GA2401@komensky.surfbest.net>
Message-ID: <6ry978b641.fsf@bates5.stat.wisc.edu>

matej at ceplovi.cz (Matej Cepl) writes:

> I have got to my hands an excellent book by Michael J. Crawley
> ``Statistical Computing: An Introduction to Data Analysis using
> S-Plus'' (John Wiley & Sons, Ltd, ISBN 0-471-56040-5). Its beauty
> for me is in the fact, that it is more of ``An Introduction to
> Data Analysis'' than ``using S-Plus'', but I guess that it may be
> of interest for many others.

> Most of the examples in the book are however taken from S-Plus
> and using datasets provided with it. Is there anywhere a copy of
> these datasets available for R?

Can you be more specific?  Which datasets?

> And one small question aside: I was very much surprised (in this
> book as well as on this list) how many times people use
> sqrt(var(x)) when what they want to say (IMHO) is sd(x). Is it
> just a macho way to show that I understand more complicated
> things, or is there any real difference between the two?

The var function was available in S long before the sd function was
introduced and many 'old-timers' instinctively use sqrt(var(x)) rather
than sd(x).  The sd function ends up calling sqrt(var(x, na.rm =
na.rm)) when argument x is a vector.



From ripley at stats.ox.ac.uk  Mon Dec  2 20:06:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Dec  2 20:06:03 2002
Subject: [R] Crawley's book on S-Plus and one strangeness
In-Reply-To: <20021202183343.GA2401@komensky.surfbest.net>
Message-ID: <Pine.LNX.4.31.0212021855420.19001-100000@gannet.stats>

On Mon, 2 Dec 2002, Matej Cepl wrote:

> I have got to my hands an excellent book by Michael J. Crawley
> ``Statistical Computing: An Introduction to Data Analysis using
> S-Plus'' (John Wiley & Sons, Ltd, ISBN 0-471-56040-5). Its beauty
> for me is in the fact, that it is more of ``An Introduction to
> Data Analysis'' than ``using S-Plus'', but I guess that it may be
> of interest for many others.

> Most of the examples in the book are however taken from S-Plus
> and using datasets provided with it. Is there anywhere a copy of
> these datasets available for R?

They are not in S-PLUS.  They are Crawley's own, but he does not
say where they are.  Recently I managed to find them via the publisher's
web site, which links to

http://www.bio.ic.ac.uk/research/mjcraw/statcomp/

> And one small question aside: I was very much surprised (in this
> book as well as on this list) how many times people use
> sqrt(var(x)) when what they want to say (IMHO) is sd(x). Is it
> just a macho way to show that I understand more complicated
> things, or is there any real difference between the two?

sd(x) does not exist in S.  There is stdev(x) in more recent versions of
S-PLUS.  You need a better introductory guide!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From matej at ceplovi.cz  Mon Dec  2 22:29:06 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Mon Dec  2 22:29:06 2002
Subject: [R] Crawley's book on S-Plus and one strangeness
In-Reply-To: <Pine.LNX.4.31.0212021855420.19001-100000@gannet.stats>
References: <20021202183343.GA2401@komensky.surfbest.net> <Pine.LNX.4.31.0212021855420.19001-100000@gannet.stats>
Message-ID: <20021202212342.GB820@komensky.surfbest.net>

ripley at stats.ox.ac.uk wrote:
> They are not in S-PLUS.  They are Crawley's own, but he does not
> say where they are.  Recently I managed to find them via the publisher's
> web site, which links to
> 
> http://www.bio.ic.ac.uk/research/mjcraw/statcomp/

Thanks a lot!

> sd(x) does not exist in S.  There is stdev(x) in more recent
> versions of S-PLUS.  You need a better introductory guide!

Sorry, Crawley mentions stdev(x).

Matej

-- 
Matej Cepl, matej at ceplovi.cz,
Finger: 89EF 4BC6 288A BF43 1BAB  25C3 E09F EF25 D964 84AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
 
There's a long-standing bug relating to the x86 architecture that
allows you to install Windows.
    -- Matthew D. Fuller



From matej at ceplovi.cz  Mon Dec  2 22:33:13 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Mon Dec  2 22:33:13 2002
Subject: [R] Crawley's book on S-Plus and one strangeness
In-Reply-To: <6ry978b641.fsf@bates5.stat.wisc.edu>
References: <20021202183343.GA2401@komensky.surfbest.net> <6ry978b641.fsf@bates5.stat.wisc.edu>
Message-ID: <20021202211854.GA820@komensky.surfbest.net>

Douglas Bates wrote:
> Can you be more specific?  Which datasets?
> 
> > And one small question aside: I was very much surprised (in this
> > book as well as on this list) how many times people use
> > sqrt(var(x)) when what they want to say (IMHO) is sd(x). Is it
> > just a macho way to show that I understand more complicated
> > things, or is there any real difference between the two?

There is a big number of them (the book has 761 pages and no CD,
so all data used are I suppose from S-Plus), but let's make
a couple of examples:

	* blowfly -- ``The Australian ecologist A.J.Nicholson reared
	  blofly larvae on pieces of liver in laboratory culture for
	  almost 7 years'' ... used for analysis of cyclicity and acf
	  function,
	* rats -- data from Sokal and Rohlf (1995) describing an
	  experiment with three treatments to six rats; used for ANOVA
	* regression -- weight of caterpillars relates to the tannin
	  content of their diet
	* etc. I really do not think, that six pages long list makes
	  any difference.

> The var function was available in S long before the sd function was
> introduced and many 'old-timers' instinctively use sqrt(var(x)) rather
> than sd(x).  The sd function ends up calling sqrt(var(x, na.rm =
> na.rm)) when argument x is a vector.

I see.

Matej

-- 
Matej Cepl, matej at ceplovi.cz,
Finger: 89EF 4BC6 288A BF43 1BAB  25C3 E09F EF25 D964 84AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
 
The law, in its majestic equality, forbids the rich as well as
the poor to sleep under bridges, to beg in the streets, and to
steal bread.
    -- Anatole France



From mingliz at surfbest.net  Tue Dec  3 01:09:03 2002
From: mingliz at surfbest.net (mingliz@surfbest.net)
Date: Tue Dec  3 01:09:03 2002
Subject: [R] Is there plan to make R multithread?
Message-ID: <20021203000846.8600113613A@server12.safepages.com>

Hello R Pioneers,
 I sometimes use R on a dual CPU PC runing Linux and find that only 1 CPU is used even when no other user/process competes for resources.  Can we make R uses both CPUs to have the job done sooner?  I know this is probably asking too much for something that is free.  Has anyone else thought about it?  Thanks.
Ming Chow



From kjetilh at umsanet.edu.bo  Tue Dec  3 01:13:02 2002
From: kjetilh at umsanet.edu.bo (kjetil halvorsen)
Date: Tue Dec  3 01:13:02 2002
Subject: [R] Monte Carlo chisq test
References: <000601c29a18$7055f7d0$83462286@hermes>
Message-ID: <3DEBF52A.B2256E23@umsanet.edu.bo>

Hola!

simulate.p.value=TRUE uset the patefielf algorithm (translated to C).
The reference is 

Patefield,W. M. (1981) An efficient method of generating r * c tables
with given row and column totals (algorithm AS 159). A?pplied Statistics
30, 91-97.

This reference should have been included in the help file!

As to small sample properties, I know of no references, but to do a
small-scall simulation in R should be fast. 

Kjetil Halvorsen


Klaus Abberger wrote:
> 
> Dear all,
> 
> I have a question about the chisq.test command. As an option one can
> chose the computation of p-values by Monte-Carlo simulation
> (simulate.p.value=T). Is there any documentation available how this
> calculations are done and how this simulation based test behaves in
> small samples?
> 
> Thanks
> 
> Klaus Abberger
> 
> University of Konstanz, Germany
> 
>         [[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From rossini at blindglobe.net  Tue Dec  3 01:23:03 2002
From: rossini at blindglobe.net (A.J. Rossini)
Date: Tue Dec  3 01:23:03 2002
Subject: [R] Is there plan to make R multithread?
In-Reply-To: <20021203000846.8600113613A@server12.safepages.com>
References: <20021203000846.8600113613A@server12.safepages.com>
Message-ID: <87fztg6jff.fsf@jeeves.blindglobe.net>

>>>>> "mingliz" == mingliz  <mingliz at surfbest.net> writes:

    mingliz> Hello R Pioneers, I sometimes use R on a dual CPU PC
    mingliz> runing Linux and find that only 1 CPU is used even when
    mingliz> no other user/process competes for resources.  Can we
    mingliz> make R uses both CPUs to have the job done sooner?  I
    mingliz> know this is probably asking too much for something that
    mingliz> is free.  Has anyone else thought about it?  Thanks.
    mingliz> Ming Chow

Search the mailing list for past discussions on this topic.  The short
answer is no you can't do it.  The long answer is yes, you can do it
with a bit of programming (using PVM/MPI and SNOW).

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)



From p.connolly at hortresearch.co.nz  Tue Dec  3 02:57:03 2002
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Tue Dec  3 02:57:03 2002
Subject: [R] Common keys on separate lattice plots
Message-ID: <20021203015632.GB24300@hortresearch.co.nz>

In 'normal' plotting, by using text(.... outer = TRUE), I can set a
title that can refer to multiple plots.

I'm trying to achieve a similar effect with several trellis objects
with which I wish to use a common key.  I can only think of
complicated ways of achieving such an end by using a separate grid
graphic which didn't have any plot, but text only.

Is there something more elegant?

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From edd at debian.org  Tue Dec  3 03:34:03 2002
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue Dec  3 03:34:03 2002
Subject: [R] Is there plan to make R multithread?
In-Reply-To: <87fztg6jff.fsf@jeeves.blindglobe.net>
References: <20021203000846.8600113613A@server12.safepages.com> <87fztg6jff.fsf@jeeves.blindglobe.net>
Message-ID: <20021203023313.GA22525@sonny.eddelbuettel.com>

On Mon, Dec 02, 2002 at 04:21:56PM -0800, A.J. Rossini wrote:
> >>>>> "mingliz" == mingliz  <mingliz at surfbest.net> writes:
> 
>     mingliz> Hello R Pioneers, I sometimes use R on a dual CPU PC
>     mingliz> runing Linux and find that only 1 CPU is used even when
>     mingliz> no other user/process competes for resources.  Can we
>     mingliz> make R uses both CPUs to have the job done sooner?  I
>     mingliz> know this is probably asking too much for something that
>     mingliz> is free.  Has anyone else thought about it?  Thanks.
>     mingliz> Ming Chow
> 
> Search the mailing list for past discussions on this topic.  The short
> answer is no you can't do it.  The long answer is yes, you can do it
> with a bit of programming (using PVM/MPI and SNOW).

Also see http://developer.r-project.org and e.g. the bullet point

#  Luke's notes on threading, GUI, and asynchronous IO issues. Some of the
reference links are messed up; the full references are in the BibTeX file.
Duncan also has a set of notes on threading.

with its links.

Dirk

-- 
Prediction is very difficult, especially about the future. 
				             -- Niels Bohr



From deepayan at stat.wisc.edu  Tue Dec  3 04:55:03 2002
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue Dec  3 04:55:03 2002
Subject: [R] Common keys on separate lattice plots
In-Reply-To: <20021203015632.GB24300@hortresearch.co.nz>
References: <20021203015632.GB24300@hortresearch.co.nz>
Message-ID: <200212022154.51164.deepayan@stat.wisc.edu>

On Monday 02 December 2002 07:56 pm, Patrick Connolly wrote:
> In 'normal' plotting, by using text(.... outer = TRUE), I can set a
> title that can refer to multiple plots.
>
> I'm trying to achieve a similar effect with several trellis objects
> with which I wish to use a common key.  I can only think of
> complicated ways of achieving such an end by using a separate grid
> graphic which didn't have any plot, but text only.
>
> Is there something more elegant?

I'm guessing that you are positioning your plots by calling print.trellis 
explicitly with the position/split argument. Once these are complete, the 
whole plotting region should be the default viewport, so you could simply use 
grid.text to write your title. for example,

foo <- xyplot(...)

print(foo, position = c(0,0,.5,.8), more = TRUE)
print(foo, position = c(.5,0,1,.8), more = FALSE)
grid.text("Title", x = .5, y = .9) 

If by key you mean a legend (as produced by 'key' in a lattice call), you 
could use something like

draw.key(key = list(rect = list(col = 1:3)), 
         draw = TRUE, 
         vp = viewport(x=.5, y=.9))  

In either case, you would have to position the initial plots so that enough 
space is left.

Hope that helps.

-Deepayan



From jarioksa at sun3.oulu.fi  Tue Dec  3 07:12:03 2002
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Tue Dec  3 07:12:03 2002
Subject: [R] Crawley's book on S-Plus and one strangeness 
In-Reply-To: Message from <ripley@stats.ox.ac.uk> 
   of "Mon, 02 Dec 2002 19:05:45 GMT." <Pine.LNX.4.31.0212021855420.19001-100000@gannet.stats> 
Message-ID: <200212030611.gB36BMR13234@pc112145.oulu.fi>

ripley at stats.ox.ac.uk said:
> You need a better introductory guide!

Than Crawley? (Was this an instant book review?)

cheers, jari oksanen
-- 
Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
Ph. +358 8 5531526, cell +358 40 5136529, fax +358 8 5531061
email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/



From maj at stats.waikato.ac.nz  Tue Dec  3 08:53:02 2002
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Tue Dec  3 08:53:02 2002
Subject: [R] Array multiplication
Message-ID: <3DEC5C66.5000505@stats.waikato.ac.nz>

I wanted a sort of matrix product of an array and a matrix.
As there does not seem to be any array multiplication apart from outer() 
I proceeded as follows:

lambda <- array(0, c(n,m,d))
# stuff omitted
# zed is an n by m matrix
#
# \lamb.star_{ik}
lamb.star <- matrix(0, nrow=n, ncol=d)
for (i in 1:n) {
   for (k in 1:d) {
     for (j in 1:m) {
       lamb.star[i,k] = lamb.star[i,k] + lambda[i,j,k]*zed[i,j]
     }
   }
}

# or, alternatively,

lamb.star <- matrix(0, nrow=n, ncol=d)
for (i in 1:n) {
    lamb.star[i,] = zed[i,]%*%lambda[i,,]
}

I wanted to do some timings, but system.time() seems not to work on 
compound statements.
	
system.time({
for (i in 1:n) {
   for (k in 1:d) {
     for (j in 1:m) {
       lamb.star[i,k] = lamb.star[i,k] + lambda[i,j,k]*zed[i,j]
     }
   }
}
)}

gives a syntax error.  I suppose there is a much smarter way to do this 
sort of stuff and that somebody will show me?

Murray

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home     Mobile 021 395 862



From ripley at stats.ox.ac.uk  Tue Dec  3 10:08:39 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Dec  3 10:08:39 2002
Subject: [R] Is there plan to make R multithread?
In-Reply-To: <20021203023313.GA22525@sonny.eddelbuettel.com>
Message-ID: <Pine.LNX.4.31.0212030701160.28922-100000@gannet.stats>

Tony and Dirk have answered the question in the subject.  However, making
R multithreaded will not of itself make it run faster on a dual CPU
machine, the rather different question in the body of the message.
That would happen for most uses of R only if the inner computations were
able to make use of multiple threads and processors.  That means either
reprogramming them yourself (Tony's answer) or using different versions of
e.g. the linear algebra routines.   We do hope in due course to allow
multi-threaded BLAS routines, but there are problems at present (see the
R-admin.texi manual).

I use a dual-CPU machine all the time (I am writing this on one).  My
experience is that few programs run faster because of two CPUs (you need
many more to make multi-processing really worthwhile), but doing several
things at once is beneficial.  E.g,, there is a background R job running
now that has been running for a couple of days and unlike single-CPU
machines I notice no difference in response to the keyboard.

On Mon, 2 Dec 2002, Dirk Eddelbuettel wrote:

> On Mon, Dec 02, 2002 at 04:21:56PM -0800, A.J. Rossini wrote:
> > >>>>> "mingliz" == mingliz  <mingliz at surfbest.net> writes:
> >
> >     mingliz> Hello R Pioneers, I sometimes use R on a dual CPU PC
> >     mingliz> runing Linux and find that only 1 CPU is used even when
> >     mingliz> no other user/process competes for resources.  Can we
> >     mingliz> make R uses both CPUs to have the job done sooner?  I
> >     mingliz> know this is probably asking too much for something that
> >     mingliz> is free.  Has anyone else thought about it?  Thanks.
> >     mingliz> Ming Chow
> >
> > Search the mailing list for past discussions on this topic.  The short
> > answer is no you can't do it.  The long answer is yes, you can do it
> > with a bit of programming (using PVM/MPI and SNOW).
>
> Also see http://developer.r-project.org and e.g. the bullet point
>
> #  Luke's notes on threading, GUI, and asynchronous IO issues. Some of the
> reference links are messed up; the full references are in the BibTeX file.
> Duncan also has a set of notes on threading.
>
> with its links.

and that is aimed more at running several R tasks `at once' in a single
session.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maj at stats.waikato.ac.nz  Tue Dec  3 10:11:37 2002
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Tue Dec  3 10:11:37 2002
Subject: [R] Array multiplication
Message-ID: <3DEC6C52.9060004@stats.waikato.ac.nz>

I have just noticed that a couple of ='s should be <-'s in my question.

Repeating everything with the corrections made does not resolve my 
questions.
-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home     Mobile 021 395 862



From p.dalgaard at biostat.ku.dk  Tue Dec  3 10:35:23 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue Dec  3 10:35:23 2002
Subject: [R] Array multiplication
In-Reply-To: <3DEC5C66.5000505@stats.waikato.ac.nz>
References: <3DEC5C66.5000505@stats.waikato.ac.nz>
Message-ID: <x2bs43e9h2.fsf@biostat.ku.dk>

Murray Jorgensen <maj at stats.waikato.ac.nz> writes:

> I wanted to do some timings, but system.time() seems not to work on
> compound statements.
> 	
> system.time({
> for (i in 1:n) {
>    for (k in 1:d) {
>      for (j in 1:m) {
>        lamb.star[i,k] = lamb.star[i,k] + lambda[i,j,k]*zed[i,j]
>      }
>    }
> }
> )}
> 
> gives a syntax error.  I suppose there is a much smarter way to do
> this sort of stuff and that somebody will show me?

Ending that with "})" instead should get rid of the syntax error....

There is a "tensor" package on CRAN that would seem to be designed for
these types of operations.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Tue Dec  3 10:40:20 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue Dec  3 10:40:20 2002
Subject: [R] Monte Carlo chisq test
In-Reply-To: <3DEBF52A.B2256E23@umsanet.edu.bo>
References: <000601c29a18$7055f7d0$83462286@hermes>
	<3DEBF52A.B2256E23@umsanet.edu.bo>
Message-ID: <x2fztfe9xr.fsf@biostat.ku.dk>

kjetil halvorsen <kjetilh at umsanet.edu.bo> writes:

> Hola!
> 
> simulate.p.value=TRUE uset the patefielf algorithm (translated to C).
> The reference is 
> 
> Patefield,W. M. (1981) An efficient method of generating r * c tables
> with given row and column totals (algorithm AS 159). A?pplied Statistics
> 30, 91-97.
> 
> This reference should have been included in the help file!
> 
> As to small sample properties, I know of no references, but to do a
> small-scall simulation in R should be fast. 

The title of the paper has an important bit of information, though.
It's a conditional simulation, so the small sample behaviour should be
similar to the Fisher test if you simulate long enough, except of
course that this uses the chisquare statistic rather than the log
likelihood. The variant where you enumerate all possibilities instead
of simulating is implemented in recent versions of SAS, so a look in
the SAS manuals might be informative.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From chunlou at yahoo.com  Tue Dec  3 10:56:07 2002
From: chunlou at yahoo.com (Chunlou Yung)
Date: Tue Dec  3 10:56:07 2002
Subject: [R] Plotting Speed: R vs Octave
In-Reply-To: <20021202070037.405d5b3d.fharrell@virginia.edu>
Message-ID: <NCBBKDNFIKJKKCFELNNMKENIDCAA.chunlou@yahoo.com>

Just curious. Why is the 3D plot of Octave so much faster than R's? Like,
Octave's mesh vs R's persp or lattice's wireframe.

Thanks.



From rjporter at mindspring.com  Tue Dec  3 13:08:03 2002
From: rjporter at mindspring.com (Bob Porter)
Date: Tue Dec  3 13:08:03 2002
Subject: [R] last plot vanishes
Message-ID: <00ab01c29b8c$fcfa3d20$6501a8c0@HydePark>

I intermittently lose the last plot in a series of plots to the win.graph
window.  I have History enabled and ordinarily can access graphs using pageup
and pagedown.  Every now and then, the last plot is visible when it plots, but
if I bringtotop and pageup and then pagedown the last plot is missing.  The prob
is erratic and mystifying.  I'm using 1.6 on W2k, gig ram.  This happens with
simple and with complex graphs and does not seem related to the number of plots
in history.

BTW, how do I list graphs in the history from the command line?

Thanks
Bob Porter, Tampa



From arv at ono.com  Tue Dec  3 13:14:10 2002
From: arv at ono.com (antonio rodriguez)
Date: Tue Dec  3 13:14:10 2002
Subject: [R] missing values and svd
Message-ID: <000b01c29ac5$cf8db280$0300a8c0@ono>

Dear All,

Is it possible to manage a svd analysis within a matrix containing NA
values. If not how do I could overcome this problem.

Thanks in advance

Antonio



From ripley at stats.ox.ac.uk  Tue Dec  3 14:53:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Dec  3 14:53:03 2002
Subject: [R] missing values and svd
In-Reply-To: <000b01c29ac5$cf8db280$0300a8c0@ono>
Message-ID: <Pine.LNX.4.31.0212031350320.31998-100000@gannet.stats>

On Tue, 3 Dec 2002, antonio rodriguez wrote:

> Is it possible to manage a svd analysis within a matrix containing NA
> values.

The answer is full of NAs, so little use.

> If not how do I could overcome this problem.

What problem?  I.e. why do you want to do this?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Ted.Harding at nessie.mcc.ac.uk  Tue Dec  3 14:59:33 2002
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue Dec  3 14:59:33 2002
Subject: [R] R v/s S-plus
In-Reply-To: <15805.50746.995826.666539@gargle.gargle.HOWL>
Message-ID: <XFMail.021130094601.Ted.Harding@nessie.mcc.ac.uk>

On 28-Oct-02 David Brahm wrote:
> I'm attaching my personal list of differences (which has shrunk
> considerably since I posted it here a year ago).
> [snip]
> Functions missing from S-Plus:
> - strsplit, sub, gsub, chartr, formatC

I have found that the useful R function 'gl' does not seem to be
present in S-Plus (version 6, 2001), though something similar can
be achieved with 'rep', present in both R and S.

Have I missed something?
Best wishes to all,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 30-Nov-02                                       Time: 09:46:01
------------------------------ XFMail ------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._



From runjac at hotmail.com  Tue Dec  3 15:50:04 2002
From: runjac at hotmail.com (Rune)
Date: Tue Dec  3 15:50:04 2002
Subject: [R] Bisection in R
Message-ID: <BAY1-DAV16C6HixqDCZ00002fe2@hotmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021203/321cf82b/attachment.pl

From p.dalgaard at biostat.ku.dk  Tue Dec  3 16:32:02 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue Dec  3 16:32:02 2002
Subject: [R] Bisection in R
In-Reply-To: <BAY1-DAV16C6HixqDCZ00002fe2@hotmail.com>
References: <BAY1-DAV16C6HixqDCZ00002fe2@hotmail.com>
Message-ID: <x2r8czrudk.fsf@biostat.ku.dk>

"Rune" <runjac at hotmail.com> writes:

> Hi R-users,
> Is it possible to make a bisection in R?

As in "zero-finding" (see uniroot()) or just "cutting something in
two" (in which case, what)?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From kjhealy at arizona.edu  Tue Dec  3 16:41:03 2002
From: kjhealy at arizona.edu (Kieran Healy)
Date: Tue Dec  3 16:41:03 2002
Subject: [R] configure fails on Mac OS 10.2.2
In-Reply-To: <068806E3-03D8-11D7-9F34-000393860F3C@stat.ucla.edu>
References: <068806E3-03D8-11D7-9F34-000393860F3C@stat.ucla.edu>
Message-ID: <1038608181.8116.1.camel@fiachra.soc.arizona.edu>

Hi -

thanks, that was the problem. I had the  right version of fink, but the
apt-get binary packages may be out of date for 10.2.2. I compiled g77
from source (sudo fink install g77) and R compiled fine after that.

Kieran

On Fri, 2002-11-29 at 13:20, Jan de Leeuw wrote:
> Make sure you have the OS X 10.2 version of fink. See their
> Jaguar pages for instructions. Make sure
> 
> g77 -v
> gcc -v
> 
> are both based on gcc version 3.1
> 
> 
> On Friday, November 29, 2002, at 11:38 AM, Kieran Healy wrote:
> 
> > Hi -
> >
> > I'm trying to build R 1.6.1 on a Powerbook running Macintosh 10.2.2  
> > with
> > the most recent software update. The latest version of the developer  
> > tools
> > is installed. I have also installed g77 and f2c from fink (the binary
> > versions, using apt-get).
> >
> > ./configure fails with the following error:
> >
> >> checking for dummy main to link with Fortran 77 libraries... unknown
> >> configure: error: linking to Fortran libraries from C fails
> >
> > I also tried using ./configure F77=f2c, which gives this error:
> >
> >> configure: WARNING: unknown Fortran 77 name-mangling scheme
> >> configure: error: cannot use Fortran
> >
> > I know R can build on OS X --- what am I missing or doing wrong?  
> > Perhaps
> > my Fortran compilers are not the right versions? Would getting them  
> > using
> > "fink install" make a difference (as opposed to "apt-get install")?
> >
> > Thanks,
> >
> > Kieran
> >
> > --
> > Kieran Healy, http://www.u.arizona.edu/~kjhealy
> > Asst Professor, Sociology Dept, University of Arizona.
> >
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
> > .-.-.-.-.-
> > r-help mailing list -- Read  
> > http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To:  
> > r-help-request at stat.math.ethz.ch
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
> > ._._._._
> >
> >
> ===
> Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
> Editor: Journal of Multivariate Analysis, Journal of Statistical  
> Software
> US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
> phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
> homepage: http://gifi.stat.ucla.edu
>    
> ------------------------------------------------------------------------ 
> -------------------------
>            No matter where you go, there you are. --- Buckaroo Banzai
>                     http://gifi.stat.ucla.edu/sounds/nomatter.au
>    
> ------------------------------------------------------------------------ 
> -------------------------
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-- 
Kieran Healy, http://www.u.arizona.edu/~kjhealy.
Asst Professor, Sociology Dept, University of Arizona.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._



From deleeuw at stat.ucla.edu  Tue Dec  3 16:46:39 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Tue Dec  3 16:46:39 2002
Subject: [R] configure fails on Mac OS 10.2.2
In-Reply-To: <Pine.SOL.4.44.0211291225350.13491-100000@ptah.u.arizona.edu>
Message-ID: <068806E3-03D8-11D7-9F34-000393860F3C@stat.ucla.edu>

Make sure you have the OS X 10.2 version of fink. See their
Jaguar pages for instructions. Make sure

g77 -v
gcc -v

are both based on gcc version 3.1


On Friday, November 29, 2002, at 11:38 AM, Kieran Healy wrote:

> Hi -
>
> I'm trying to build R 1.6.1 on a Powerbook running Macintosh 10.2.2  
> with
> the most recent software update. The latest version of the developer  
> tools
> is installed. I have also installed g77 and f2c from fink (the binary
> versions, using apt-get).
>
> ./configure fails with the following error:
>
>> checking for dummy main to link with Fortran 77 libraries... unknown
>> configure: error: linking to Fortran libraries from C fails
>
> I also tried using ./configure F77=f2c, which gives this error:
>
>> configure: WARNING: unknown Fortran 77 name-mangling scheme
>> configure: error: cannot use Fortran
>
> I know R can build on OS X --- what am I missing or doing wrong?  
> Perhaps
> my Fortran compilers are not the right versions? Would getting them  
> using
> "fink install" make a difference (as opposed to "apt-get install")?
>
> Thanks,
>
> Kieran
>
> --
> Kieran Healy, http://www.u.arizona.edu/~kjhealy
> Asst Professor, Sociology Dept, University of Arizona.
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.- 
> .-.-.-.-.-
> r-help mailing list -- Read  
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:  
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
> ._._._._
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._



From Ted.Harding at nessie.mcc.ac.uk  Tue Dec  3 17:02:03 2002
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue Dec  3 17:02:03 2002
Subject: [R] missing values and svd
In-Reply-To: <000b01c29ac5$cf8db280$0300a8c0@ono>
Message-ID: <XFMail.021203152704.Ted.Harding@nessie.mcc.ac.uk>

On 03-Dec-02 antonio rodriguez wrote:
> Dear All,
> 
> Is it possible to manage a svd analysis within a matrix containing NA
> values. If not how do I could overcome this problem.

Surely, mathematically speaking the SVD (which is a mathematical
operation, not a statistical analysis) of a matrix with missing
values is undefined.

There are two obvious options for how to proceed, though, if you
find yourself in that situation because of missing data.

1) Strike out the rows and columns with missing values, and just
use the reduced matrix.

2) "Fill in" the missing values in the data by some imputation
procedure and then proceed as if you had complete data. This
could be done by entering the expected values of the missing
data given the known ("complete") data, but it makes more sense
to proceed as follows.

For imputation, you will probably want to evaluate the uncertainty
associated with the imputed values, for which one approach could
be multiple imputation: Impute by sampling from an estimated
distribution of missing values given the complete data, evaluate
the SVD for that sample, then repeat the whole process until you
have enough data from the simulation to infer the distribution
of variability in the SVD.

In any case, imputation requires care in the selection of the
model used for the missing data.

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 03-Dec-02                                       Time: 15:27:04
------------------------------ XFMail ------------------------------



From xu at mathens.u-psud.fr  Tue Dec  3 17:10:07 2002
From: xu at mathens.u-psud.fr (XU)
Date: Tue Dec  3 17:10:07 2002
Subject: [R] how can i get the graphic in my window?
Message-ID: <Pine.LNX.4.31.0212031659110.15862-100000@pc00.mathens.u-psud.fr>

dear sir,
  i am trying make a simple GUI to R with GTK--, could you tell me
to show the graphic which is made by R, what  shall i do?
  i find two ways, one is save the graphic as a file(.ps),then let
GTK read it; another is let it be shown in my window directly, using
somethings like "pipe".  but how to realize these actions?
  thank you for your help!
                                    xu



From edd at debian.org  Tue Dec  3 17:23:06 2002
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue Dec  3 17:23:06 2002
Subject: [R] how can i get the graphic in my window?
Message-ID: <E18JFoK-0000mj-00@sonny.eddelbuettel.com>

> dear sir,
>   i am trying make a simple GUI to R with GTK--, could you tell me
> to show the graphic which is made by R, what  shall i do?
>   i find two ways, one is save the graphic as a file(.ps),then let
> GTK read it; another is let it be shown in my window directly, using
> somethings like "pipe".  but how to realize these actions?
>   thank you for your help!

You probably want to look at the CRAN (cran.r-project.org) package  
gtkDevice  as well as the Omegahat (www.omegahat.org) package RGtk.

Both are also available as Debian packages, if that happened to be your
platform.  

Amicalement,  Dirk

-- 
According to the latest figures, 43% of all signatures are totally worthless.



From matej at ceplovi.cz  Tue Dec  3 17:28:08 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Tue Dec  3 17:28:08 2002
Subject: [R] Crawley's book on S-Plus and one strangeness
In-Reply-To: <200212030611.gB36BMR13234@pc112145.oulu.fi>
References: <Pine.LNX.4.31.0212021855420.19001-100000@gannet.stats> <200212030611.gB36BMR13234@pc112145.oulu.fi>
Message-ID: <20021203162210.GB2037@komensky.surfbest.net>

Jari Oksanen wrote:
> > You need a better introductory guide!
> 
> Than Crawley? (Was this an instant book review?)

BTW, I really do not want to say anything against the book, which
is excellent in my newbie's humble(?) opinion.

Matej

-- 
Matej Cepl, matej at ceplovi.cz,
Finger: 89EF 4BC6 288A BF43 1BAB  25C3 E09F EF25 D964 84AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
 
Opinions founded on prejudice are always sustained with the
greatest violence.
    -- Hebrew Proverb



From kjetilh at umsanet.edu.bo  Tue Dec  3 17:52:03 2002
From: kjetilh at umsanet.edu.bo (kjetil halvorsen)
Date: Tue Dec  3 17:52:03 2002
Subject: [R] R-help moved to mailman
References: <15851.10524.314512.404704@gargle.gargle.HOWL>
Message-ID: <3DECDFA4.3DD4287B@umsanet.edu.bo>

Hola!

The R home page have a mailing list page, which dowesnt seem to be
up-to-date whit respect to this new system. Maybe it should refer to the
web page given below?

Kjetil Halvorsen

Martin Maechler wrote:
> 
> I have now moved the last (and largest!) R mailing list from
> majordomo to [procmail + mailman].
> This also ends the life of "R-help-digest" which is now part of
> "R-help", each such subscriber having a [digest] flag set.
> 
> Have a look at the Web interface at
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help/
> 
> You need password to modify your subscription.
> You should all get it sent to you in a few hours (as a monthly
> reminder the first of each month), but can always get it sent by
> requiring it through the web interface -- you need to know the
> exact e-mail address you are subscribed as for all that.
> 
> Finally, note that the sender is now
> "r-help-admin at stat..." instead of "owner-R-help at ..."
> 
> ---
> Martin Maechler <maechler at stat.math.ethz.ch>    http://stat.ethz.ch/~maechler/
> Seminar fuer Statistik, ETH-Zentrum  LEO C16    Leonhardstr. 27
> ETH (Federal Inst. Technology)  8092 Zurich     SWITZERLAND
> phone: x-41-1-632-3408          fax: ...-1228                   <><
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From chunlou at yahoo.com  Tue Dec  3 19:53:02 2002
From: chunlou at yahoo.com (Chunlou Yung)
Date: Tue Dec  3 19:53:02 2002
Subject: [R] Plotting Speed: R vs Octave
In-Reply-To: <51F9C42DA15CD311BD220008C707D81906FFC94A@usrymx10.merck.com>
Message-ID: <NCBBKDNFIKJKKCFELNNMIENLDCAA.chunlou@yahoo.com>

Thank you. Guess it's a plausible explanation.

> -----Original Message-----
> From: Liaw, Andy [mailto:andy_liaw at merck.com]
> Sent: Tuesday, December 03, 2002 08:05 AM
> To: 'Chunlou Yung'
> Subject: RE: [R] Plotting Speed: R vs Octave
> 
> 
> If I'm not mistaken, Octave does not have its own graphics system, but
> rather rely on gnuplot, which is entirely in C.  Lattice/Grid in 
> R, however,
> have a large chunk of the code written in R, for trellis 
> displays.  There's
> always price to be paid for the flexibility: try doing a simple 
> trellis plot
> in gnuplot/octave: it's not there.
> 
> Andy
> 
> -----Original Message-----
> From: Chunlou Yung [mailto:chunlou at yahoo.com]
> Sent: Tuesday, December 03, 2002 4:52 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Plotting Speed: R vs Octave
> 
> 
> 
> Just curious. Why is the 3D plot of Octave so much faster than R's? Like,
> Octave's mesh vs R's persp or lattice's wireframe.
> 
> Thanks.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
> ------------------------------------------------------------------
> ------------
> Notice:  This e-mail message, together with any attachments, 
> contains information of Merck & Co., Inc. (Whitehouse Station, 
> New Jersey, USA) that may be confidential, proprietary 
> copyrighted and/or legally privileged, and is intended solely for 
> the use of the individual or entity named in this message.  If 
> you are not the intended recipient, and have received this 
> message in error, please immediately return this by e-mail and 
> then delete it.
> 
> ==================================================================
> ============



From cfrangak at jhsph.edu  Tue Dec  3 20:21:06 2002
From: cfrangak at jhsph.edu (Constantine Frangakis)
Date: Tue Dec  3 20:21:06 2002
Subject: [R] data level for stepwise
Message-ID: <Pine.GSO.4.10.10212031404320.18108-100000@biosun14>

This may be of interest to R users.

The command step () for stepwise regression, which asks for
an object like lm(formula, data=mydata), apparently is looking for
``mydata'' in the global environment, not the environment at which
step() is called. That is, when step is called
from inside another function in which the data that step() calls has also
been updated inside that function, step() does not use the most recently
updated data, but instead looks outside the function. (This problem does
not happen for the lm function). Although the problem can be solved by
using the assign function, to avoid potential bugs it would be useful to
know which functions like step() do this.

C Frangakis



From deepayan at stat.wisc.edu  Tue Dec  3 20:42:02 2002
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue Dec  3 20:42:02 2002
Subject: [R] Plotting Speed: R vs Octave
In-Reply-To: <NCBBKDNFIKJKKCFELNNMIENLDCAA.chunlou@yahoo.com>
References: <NCBBKDNFIKJKKCFELNNMIENLDCAA.chunlou@yahoo.com>
Message-ID: <200212031343.07923.deepayan@stat.wisc.edu>

On Tuesday 03 December 2002 12:54 pm, Chunlou Yung wrote:
> Thank you. Guess it's a plausible explanation.
>
> > -----Original Message-----
> > From: Liaw, Andy [mailto:andy_liaw at merck.com]
> > Sent: Tuesday, December 03, 2002 08:05 AM
> > To: 'Chunlou Yung'
> > Subject: RE: [R] Plotting Speed: R vs Octave
> >
> >
> > If I'm not mistaken, Octave does not have its own graphics system, but
> > rather rely on gnuplot, which is entirely in C.  Lattice/Grid in
> > R, however,
> > have a large chunk of the code written in R, for trellis
> > displays.  There's
> > always price to be paid for the flexibility: try doing a simple
> > trellis plot
> > in gnuplot/octave: it's not there.

Also, wireframe code is currently far from optimized (it makes a separate R 
level function call to draw each quadrilateral). It would be more interesting 
to know why (and how much) persp is slower.

> > Andy
> >
> > -----Original Message-----
> > From: Chunlou Yung [mailto:chunlou at yahoo.com]
> > Sent: Tuesday, December 03, 2002 4:52 AM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] Plotting Speed: R vs Octave
> >
> >
> >
> > Just curious. Why is the 3D plot of Octave so much faster than R's? Like,
> > Octave's mesh vs R's persp or lattice's wireframe.
> >
> > Thanks.



From Sonia.Bauer at noaa.gov  Tue Dec  3 21:51:06 2002
From: Sonia.Bauer at noaa.gov (Sonia Bauer)
Date: Tue Dec  3 21:51:06 2002
Subject: [R] terribly naive question
Message-ID: <3DED1951.6B589C05@noaa.gov>

Dear R-Representative:
I am very new to R and I have to admit that I am not the cleverest of
users.  So, please bear with me.  I have installed R on my Mac OS 8.6.
I am interested in eventually using the packages -- many useful ones
have been downloaded with the basic R software.  I have looked through
some of the manuals, however, I have not yet found how to access the
commands in these packages.  I am assuming there are ways to include the
functions available in these packages in some kind of path.  I have used
UNIX and I use my Mac mainly as a word processor, but would like to
learn R on the Mac and perhaps later for research, possibly on a new
Mac.  So, my question is, what kind of set up is required for me to use
these packages?
Sorry for such an inane question, but I've decided that you will be able
to help me much more quickly than I am able to find what I need at this
point.
Thank you VERY MUCH.
Sincerely,
Sonia Bauer
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Sonia.Bauer.vcf
Type: text/x-vcard
Size: 257 bytes
Desc: Card for Sonia Bauer
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20021203/9e1d9154/Sonia.Bauer.vcf

From ozric at web.de  Tue Dec  3 22:12:02 2002
From: ozric at web.de (Christian Schulz)
Date: Tue Dec  3 22:12:02 2002
Subject: [R] advanced tabulation
References: <000701c299d7$9499c900$d4b707d5@c5c9i0> <20021202070037.405d5b3d.fharrell@virginia.edu>
Message-ID: <004a01c29b10$0217ee60$f40b06d5@c5c9i0>

many thanks for all your comments !

>>summary(columnvariable ~ rowvar1+rowvar2+...., method='reverse') will do
what you want, if you are interested in separate summaries for each row
variable.  >>This uses the summary.formula function in the Hmisc library
(http://hesweb1.med.virginia.edu/biostat/s/Hmisc.html) for which there are
plot, print, and latex >>methods for formatting the output.  For 2-way
cross-classified summaries see method='cross'.

...this is really a good starting point !
An improvement should be the possibility use in a function more than 1
column variable !?

I check/AttemptToUnderstand next days the functions from Hmisc and Kickstart
more deeply and
perhaps the modification's are not so difficult !?

P.S.
summary (Hmisc) is a generic function !?
Is it pure R code ?

regards, christian


----- Original Message -----
From: "Frank E Harrell Jr" <fharrell at virginia.edu>
To: "Christian Schulz" <ozric at web.de>
Cc: <r-help at stat.math.ethz.ch>
Sent: Monday, December 02, 2002 1:00 PM
Subject: Re: [R] advanced tabulation


> On Mon, 2 Dec 2002 08:51:09 +0100
> Christian Schulz <ozric at web.de> wrote:
>
> > i make me thoughts about a  "advanced tabulation"  package similar to
> > commercial software products like Quantum or Wincross.
> >
> > Before i'm beginning to fight with coding - is in the mailing-List
anybody
> > doing something similar in the past and have a good starting point
> > and/or suggestions for me ?
> >
> > My purpose ist to define for a dataset  headers (i.e. sex,age-groupes..)
> > which should write in the colums of a landscape table and percentage all
> > other
> > variables ( rows) dependence to the header category !?
> >
> > P.S. The first attempts sure more easy than
> > the possibilities in wincross  .......
> >
> > http://www.skim.nl/software/images/WC-banners.gif
> > http://www.skim.nl/software/images/WC-tables.gif
> >
> > many thanks for advance & regards,
> > Christian
> >
>
> summary(columnvariable ~ rowvar1+rowvar2+...., method='reverse') will do
what you want, if you are interested in separate summaries for each row
variable.  This uses the summary.formula function in the Hmisc library
(http://hesweb1.med.virginia.edu/biostat/s/Hmisc.html) for which there are
plot, print, and latex methods for formatting the output.  For 2-way
cross-classified summaries see method='cross'.
> --
> Frank E Harrell Jr              Prof. of Biostatistics & Statistics
> Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
> U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tlumley at u.washington.edu  Tue Dec  3 22:21:03 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue Dec  3 22:21:03 2002
Subject: [R] data level for stepwise
In-Reply-To: <Pine.GSO.4.10.10212031404320.18108-100000@biosun14>
Message-ID: <Pine.A41.4.44.0212031312210.87796-100000@homer09.u.washington.edu>

On Tue, 3 Dec 2002, Constantine Frangakis wrote:

> This may be of interest to R users.
>
> The command step () for stepwise regression, which asks for
> an object like lm(formula, data=mydata), apparently is looking for
> ``mydata'' in the global environment, not the environment at which
> step() is called.

Not quite.  It's looking at the step() in the environment associated with
the model formula (which will typically be the environment where the model
was created, and often the base environment)

>			That is, when step is called
> from inside another function in which the data that step() calls has also
> been updated inside that function, step() does not use the most recently
> updated data, but instead looks outside the function. (This problem does
> not happen for the lm function). Although the problem can be solved by
> using the assign function, to avoid potential bugs it would be useful to
> know which functions like step() do this.

There is some discussion of this under "Nonstandard evaluation rules" on
http://developer.r-project.org, but it doesn't cover step(), which I'll
need to add.

You can work around this by using update() first: eg with
 data(trees)
 model<-lm(Volume~Height+Girth,data=trees)
 f<-function (i)
 {
    trees <- trees[-i, ]
    step(model)
 }
 g<-function (i)
 {
    trees <- trees[-i, ]
    model <- update(model)
    step(model)
 }

the argument to f() makes no difference, as the original `trees' data
frame is used, but the argument to g() is effective, as the local data
frame is used.


	-thomas



From matej at ceplovi.cz  Tue Dec  3 22:36:03 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Tue Dec  3 22:36:03 2002
Subject: Plot optimization [Was: Re: [R] Plotting Speed: R vs Octave]
In-Reply-To: <200212031343.07923.deepayan@stat.wisc.edu>
References: <NCBBKDNFIKJKKCFELNNMIENLDCAA.chunlou@yahoo.com> <200212031343.07923.deepayan@stat.wisc.edu>
Message-ID: <20021203213235.GA6727@komensky.surfbest.net>

Deepayan Sarkar wrote:
> Also, wireframe code is currently far from optimized (it makes
> a separate R level function call to draw each quadrilateral).
> It would be more interesting to know why (and how much) persp
> is slower.

On somehow different note. I have asked couple of days ago about
possibility of optimalization of plotting functions (pairs
function created for me 0.5MB pictures). Answer was more or less
unsatisfactory. I do not want bother you about that again, but
I have took a look at the EPS file itself and this is what
I found these interesting lines

	% these are definitions
	/c { newpath 0 360 arc } def
	/p1  { stroke } def

	% and than there is a many thousand
	% lines like these (something around 80k to be exact)
	
	330.89 387.93 1.63 c p1
	330.89 377.14 1.63 c p1
	330.89 377.14 1.63 c p1
	330.89 387.93 1.63 c p1
	330.89 387.93 1.63 c p1

If I understand well these lines use procedure /c for drawing
a circle in particular positions, many times overplotting
previously already drawn points (statistically speaking, not
points in terms of pixels).

PDF file created with these pictures prettly certainly kicked
down any laser printer I was pushing it through. Do you think,
that it would not be possible somehow to optimize PostScript
coming from R (at least to avoid overplotting by calling exactly
the same procedure at exactly same points)?

The example file is attached.

Matej

-- 
Matej Cepl, matej at ceplovi.cz,
Finger: 89EF 4BC6 288A BF43 1BAB  25C3 E09F EF25 D964 84AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
 
There is no reason to suppose that most human beings are engaged
in maximizing anything unless it be unhappiness, and even this
with incomplete success.
    -- Ronald Coase
       Introduction to ``The Firm, the Market, and the Law''

-------------- next part --------------
A non-text attachment was scrubbed...
Name: pairs-noscj.eps.bz2
Type: application/octet-stream
Size: 24591 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20021203/e4169137/pairs-noscj.eps.obj

From gregory_r_warnes at groton.pfizer.com  Tue Dec  3 22:43:05 2002
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Tue Dec  3 22:43:05 2002
Subject: [R] RE: Initial release of RSOAP - a simple interface to R via SOAP
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C331@groexmb02.pfizer.com>

The second URL in the previous message is incorrect, it should be 
http://software.biostat.washington.edu/statsoft/snake/RSOAP,
i.e. omit the final '/manage'.

> -----Original Message-----
> From: Warnes, Gregory R 
> Sent: Tuesday, December 03, 2002 4:41 PM
> To: R-Announce (E-mail)
> Subject: Initial release of RSOAP - a simple interface to R via SOAP
> 
> 
> 
> Announcing the initial public release of RSOAP at
> http://software.biostat.washington.edu/statsoft/snake/RSOAP.
> 
> Description:	
> 
> RSOAP provides a SOAP interface for the open-source statistical 
> package R. It permits software to take advantage of the advanced 
> statistical analysis techniques provided by R---running either 
> locally or on a remote machine---using the simple and widely 
> accepted SOAP protocol. 
> 
> RSOAP provides a simple API for managing and communicating with 
> multiple concurrent R processes. Using SOAP as the communications 
> protocol avoids direct handling of binary data while preserving 
> the underlying data structures, and makes R easily accessible 
> from a variety of applications and programming languages. 
> 
> Availability:
> 
> More information and the source code for RSOAP is available at 
> http://software.biostat.washington.edu/statsoft/snake/RSOAP/manage.
> 
> -Greg
> 
> 
> 


LEGAL NOTICE
Unless expressly stated otherwise, this message is confidential and may be privileged. It is intended for the addressee(s) only. Access to this E-mail by anyone else is unauthorized. If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful. If you are not an addressee, please inform the sender immediately.



From gregory_r_warnes at groton.pfizer.com  Tue Dec  3 22:51:06 2002
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Tue Dec  3 22:51:06 2002
Subject: [R] Initial release of RSOAP - a simple interface to R via SOAP
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C330@groexmb02.pfizer.com>

Announcing the initial public release of RSOAP at
http://software.biostat.washington.edu/statsoft/snake/RSOAP.

Description:	

RSOAP provides a SOAP interface for the open-source statistical 
package R. It permits software to take advantage of the advanced 
statistical analysis techniques provided by R---running either 
locally or on a remote machine---using the simple and widely 
accepted SOAP protocol. 

RSOAP provides a simple API for managing and communicating with 
multiple concurrent R processes. Using SOAP as the communications 
protocol avoids direct handling of binary data while preserving 
the underlying data structures, and makes R easily accessible 
from a variety of applications and programming languages. 

Availability:

More information and the source code for RSOAP is available at 
http://software.biostat.washington.edu/statsoft/snake/RSOAP/manage.

-Greg




LEGAL NOTICE
Unless expressly stated otherwise, this message is confidential and may be privileged. It is intended for the addressee(s) only. Access to this E-mail by anyone else is unauthorized. If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful. If you are not an addressee, please inform the sender immediately.



From Liu.Chunhua at epamail.epa.gov  Tue Dec  3 23:16:02 2002
From: Liu.Chunhua at epamail.epa.gov (Liu.Chunhua@epamail.epa.gov)
Date: Tue Dec  3 23:16:02 2002
Subject: [R] Any difference in cbind() b/w SPLus and R??
Message-ID: <OF01DE478B.A4C358AA-ON85256C84.007838A1@rtp.epa.gov>

Dear Experts,

I have a data object named  "data.char".

When I use cbind(data.char) in SPlus, I got the following results:

> cbind(data.char)
               data.char
       data matrix, 2700
   excluded list, 3
cluster.var character, 2
     strata list, 3
       xlog CT
       link logit
     gpcorr 1
missing.row numeric, 0
   zero.row numeric, 22
     infile perc.csv
attr(, "names"):
 [1] "data"        "excluded"    "cluster.var" "strata"      "xlog"
"link"        "gpcorr"      "missing.row"
 [9] "zero.row"    "infile"
>

However, when I use it in R, I got the following error message:
> cbind(data.char)
Error in cbind(...) : cannot create a matrix from these types

I'm converting a program writen in SPlus to R, and have this problem.
Are there any differences in using cbind() b/w SPlus and R? How should I
do it in R?

Your help is greatly appreciated.

Charlie Liu
Graduate Intern at US EPA


THis is what's in "data.char"

> data.char
$data:
            Ref.id Exp Group Species Strain Sex      mg/m3   Hours Nsub
Target Censored GpSize Incid SevLo SevHi
  [1,] "ACC-2688"  "1" "3"   "HU"    "r"    "M" "686"      "7"     "12"
"C"    "n"      "12"   "1"   "1"   "1"
  [2,] "CHL-0259"  "1" "2"   "MU"    "OT"   "F" "1356.58"  "4"     "10"
"L"    "n"      "1"    "4"   "0"   "0"
  [3,] "CHL-0259"  "1" "2"   "MU"    "OT"   "F" "1356.58"  "4"     "10"
"L"    "n"      "1"    "6"   "0"   "1"
  [4,] "CHL-0259"  "1" "3"   "MU"    "OT"   "F" "2713.15"  "4"     "10"
"L"    "n"      "1"    "4"   "0"   "1"
  [5,] "CHL-0259"  "1" "3"   "MU"    "OT"   "F" "2713.15"  "4"     "10"
"L"    "n"      "1"    "6"   "1"   "1"
  [6,] "CHL-0259"  "1" "4"   "MU"    "OT"   "F" "5426.3"   "4"     "10"
"L"    "n"      "1"    "3"   "0"   "1"
  [7,] "CHL-0259"  "1" "4"   "MU"    "OT"   "F" "5426.3"   "4"     "10"
"L"    "n"      "1"    "7"   "1"   "1"
  [8,] "CHL-0259"  "1" "5"   "MU"    "OT"   "F" "10852.6"  "4"     "10"
"L"    "n"      "1"    "10"  "1"   "1"
  [9,] "CHL-0259"  "1" "7"   "MU"    "OT"   "F" "1356.58"  "4"     "10"
"L"    "n"      "1"    "10"  "0"   "0"
 [10,] "CHL-0259"  "1" "8"   "MU"    "OT"   "F" "2713.15"  "4"     "10"
"L"    "n"      "1"    "2"   "0"   "0"
 [11,] "CHL-0259"  "1" "8"   "MU"    "OT"   "F" "2713.15"  "4"     "10"
"L"    "n"      "1"    "8"   "1"   "1"
 [12,] "CHL-0259"  "1" "9"   "MU"    "OT"   "F" "5426.3"   "4"     "10"
"L"    "n"      "1"    "10"  "1"   "1"
 [13,] "CHL-0259"  "1" "10"  "MU"    "OT"   "F" "10852.6"  "4"     "10"
"L"    "n"      "1"    "10"  "1"   "1"
 [14,] "PERC-0107" "1" "2"   "RT"    "CA"   "F" "7800.31"  "4"     "10"
"C"    "n"      "10"   "1"   "0"   "0"
 [15,] "PERC-0107" "1" "3"   "RT"    "CA"   "F" "15600.61" "4"     "10"
"C"    "n"      "10"   "1"   "1"   "1"
 [16,] "PERC-0285" "1" "2"   "HU"    "r"    "M" "1315.88"  "0.25"  "6"
"C"    "n"      "6"    "1"   "0"   "0"
 [17,] "PERC-0285" "1" "3"   "HU"    "r"    "M" "1315.88"  "0.5"   "6"
"C"    "n"      "6"    "1"   "0"   "1"
 [18,] "PERC-0285" "1" "4"   "HU"    "r"    "M" "1315.88"  "3"     "6"
"C"    "n"      "6"    "1"   "0"   "1"
 [19,] "PERC-0285" "2" "2"   "HU"    "r"    "M" "1315.88"  "0.25"  "6"
"C"    "n"      "6"    "1"   "0"   "0"
 [20,] "PERC-0285" "2" "3"   "HU"    "r"    "M" "1315.88"  "0.5"   "6"
"C"    "n"      "6"    "1"   "0"   "1"
 [21,] "PERC-0285" "2" "4"   "HU"    "r"    "M" "1315.88"  "1.5"   "6"
"C"    "n"      "6"    "1"   "0"   "1"
 [22,] "PERC-0334" "1" "1"   "RT"    "WI"   "B" "135787"   "1.2"   "30"
"C"    "n"      "1"    "30"  "2"   "2"
 [23,] "PERC-0334" "1" "2"   "RT"    "WI"   "B" "135787"   "0.08"  "30"
"C"    "n"      "30"   "1"   "0"   "1"
 [24,] "PERC-0334" "1" "3"   "RT"    "WI"   "B" "81472"    "3"     "20"
"C"    "n"      "20"   "1"   "2"   "2"
 [25,] "PERC-0334" "1" "4"   "RT"    "WI"   "B" "81472"    "2.5"   "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [26,] "PERC-0334" "1" "5"   "RT"    "WI"   "B" "81472"    "2"     "20"
"C"    "n"      "20"   "1"   "2"   "2"
 [27,] "PERC-0334" "1" "6"   "RT"    "WI"   "B" "81472"    "1"     "20"
"C"    "n"      "20"   "1"   "2"   "2"
 [28,] "PERC-0334" "1" "7"   "RT"    "WI"   "B" "81472"    "0.6"   "20"
"C"    "n"      "20"   "1"   "2"   "2"
 [29,] "PERC-0334" "1" "8"   "RT"    "WI"   "B" "81472"    "0.4"   "20"
"C"    "n"      "20"   "1"   "0"   "1"
 [30,] "PERC-0334" "1" "9"   "RT"    "WI"   "B" "81472"    "0.3"   "20"
"C"    "n"      "20"   "1"   "2"   "2"
 [31,] "PERC-0334" "1" "10"  "RT"    "WI"   "B" "81472"    "0.2"   "20"
"C"    "n"      "20"   "1"   "0"   "1"
 [32,] "PERC-0334" "1" "11"  "RT"    "WI"   "B" "40736"    "8"     "20"
"C"    "n"      "20"   "1"   "2"   "2"
 [33,] "PERC-0334" "1" "12"  "RT"    "WI"   "B" "40736"    "6"     "10"
"C"    "n"      "10"   "1"   "2"   "2"
 [34,] "PERC-0334" "1" "13"  "RT"    "WI"   "B" "40736"    "5"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [35,] "PERC-0334" "1" "14"  "RT"    "WI"   "B" "40736"    "1"     "15"
"C"    "n"      "15"   "1"   "0"   "1"
 [36,] "PERC-0334" "1" "15"  "RT"    "WI"   "B" "40736"    "0.8"   "11"
"C"    "n"      "11"   "1"   "0"   "1"
 [37,] "PERC-0334" "1" "16"  "RT"    "WI"   "B" "40736"    "0.6"   "20"
"C"    "n"      "20"   "1"   "0"   "1"
 [38,] "PERC-0334" "1" "17"  "RT"    "WI"   "B" "20368"    "8"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [39,] "PERC-0334" "1" "18"  "RT"    "WI"   "B" "20368"    "6"     "10"
"C"    "n"      "10"   "1"   "2"   "2"
 [40,] "PERC-0334" "1" "19"  "RT"    "WI"   "B" "20368"    "5"     "15"
"C"    "n"      "15"   "1"   "2"   "2"
 [41,] "PERC-0334" "1" "20"  "RT"    "WI"   "B" "20368"    "4"     "30"
"C"    "n"      "30"   "1"   "0"   "1"
 [42,] "PERC-0334" "1" "21"  "RT"    "WI"   "B" "13579"    "14"    "10"
"C"    "n"      "10"   "1"   "0"   "0"
 [43,] "PERC-0334" "1" "22"  "RT"    "WI"   "B" "13579"    "10"    "20"
"C"    "n"      "20"   "1"   "0"   "0"
 [44,] "PERC-0334" "2" "1"   "RT"    "WI"   "F" "81472"    "0.2"   "4"
"L"    "n"      "4"    "1"   "0"   "0"
 [45,] "PERC-0334" "2" "2"   "RT"    "WI"   "F" "81472"    "0.6"   "4"
"L"    "n"      "4"    "1"   "0"   "1"
 [46,] "PERC-0334" "2" "3"   "RT"    "WI"   "F" "40748"    "0.4"   "4"
"L"    "n"      "4"    "1"   "0"   "0"
 [47,] "PERC-0334" "2" "4"   "RT"    "WI"   "F" "40748"    "0.6"   "4"
"L"    "n"      "4"    "1"   "0"   "1"
 [48,] "PERC-0334" "2" "5"   "RT"    "WI"   "F" "16973"    "3"     "4"
"L"    "n"      "4"    "1"   "0"   "0"
 [49,] "PERC-0334" "2" "6"   "RT"    "WI"   "F" "16973"    "5"     "4"
"L"    "n"      "4"    "1"   "0"   "1"
 [50,] "PERC-0334" "2" "7"   "RT"    "WI"   "F" "10862"    "5"     "4"
"L"    "n"      "4"    "1"   "0"   "0"
 [51,] "PERC-0334" "2" "8"   "RT"    "WI"   "F" "10862"    "7"     "4"
"L"    "n"      "4"    "1"   "0"   "1"
 [52,] "PERC-0334" "3" "1"   "HU"    "r"    "B" "7197"     "0.03"  "4"
"C"    "n"      "4"    "1"   "1"   "1"
 [53,] "PERC-0334" "3" "2"   "HU"    "r"    "B" "4074"     "0.17"  "2"
"C"    "n"      "2"    "1"   "1"   "1"
 [54,] "PERC-0334" "3" "3"   "HU"    "r"    "B" "1901"     "2"     "4"
"C"    "n"      "4"    "1"   "1"   "1"
 [55,] "PERC-0334" "3" "4"   "HU"    "r"    "B" "1467"     "2"     "4"
"C"    "n"      "4"    "1"   "1"   "1"
 [56,] "PERC-0334" "3" "5"   "HU"    "r"    "B" "720"      "1"     "6"
"C"    "n"      "6"    "1"   "0"   "0"
 [57,] "PERC-0339" "1" "2"   "HU"    "r"    "B" "169.73"   "5.5"   "12"
"C"    "n"      "12"   "1"   "0"   "0"
 [58,] "PERC-0339" "1" "3"   "HU"    "r"    "B" "678.9"    "5.5"   "12"
"C"    "n"      "12"   "1"   "0"   "1"
 [59,] "PERC-0344" "1" "2"   "MU"    "CB"   "F" "5431"     "3"     "6"
"L"    "n"      "6"    "1"   "0"   "1"
 [60,] "PERC-0344" "1" "3"   "MU"    "CB"   "F" "5431"     "3"     "6"
"L"    "n"      "6"    "1"   "0"   "1"
 [61,] "PERC-0344" "1" "4"   "MU"    "CB"   "F" "5431"     "3"     "6"
"L"    "n"      "6"    "1"   "0"   "1"
 [62,] "PERC-0344" "1" "5"   "MU"    "CB"   "F" "5431"     "3"     "6"
"L"    "n"      "6"    "1"   "0"   "1"
 [63,] "PERC-0528" "1" "1"   "RT"    "F3"   "M" "16599"    "4"     "5"
"C"    "n"      "5"    "1"   "0"   "1"
 [64,] "PERC-0528" "1" "2"   "RT"    "F3"   "M" "25703"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [65,] "PERC-0528" "1" "3"   "RT"    "F3"   "M" "27781"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [66,] "PERC-0528" "1" "4"   "RT"    "F3"   "M" "30639"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [67,] "PERC-0528" "1" "5"   "RT"    "F3"   "M" "35052"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [68,] "PERC-0528" "2" "2"   "RT"    "F3"   "F" "25703"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [69,] "PERC-0528" "2" "3"   "RT"    "F3"   "F" "27781"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [70,] "PERC-0528" "2" "4"   "RT"    "F3"   "F" "30639"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [71,] "PERC-0528" "2" "5"   "RT"    "F3"   "F" "35052"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [72,] "PERC-0528" "4" "1"   "MU"    "B6"   "M" "15805"    "4"     "5"
"C"    "n"      "5"    "1"   "0"   "1"
 [73,] "PERC-0528" "4" "2"   "MU"    "B6"   "M" "16599"    "4"     "5"
"C"    "n"      "5"    "1"   "0"   "1"
 [74,] "PERC-0528" "4" "3"   "MU"    "B6"   "M" "17740"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [75,] "PERC-0528" "4" "4"   "MU"    "B6"   "M" "20170"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [76,] "PERC-0528" "4" "5"   "MU"    "B6"   "M" "25703"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [77,] "PERC-0528" "5" "1"   "MU"    "B6"   "F" "15805"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [78,] "PERC-0528" "5" "2"   "MU"    "B6"   "F" "16599"    "4"     "5"
"C"    "n"      "5"    "1"   "0"   "1"
 [79,] "PERC-0528" "5" "3"   "MU"    "B6"   "F" "17740"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [80,] "PERC-0528" "5" "4"   "MU"    "B6"   "F" "20170"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [81,] "PERC-0528" "5" "5"   "MU"    "B6"   "F" "25703"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [82,] "PERC-0530" "1" "1"   "MU"    "r"    "F" "16633"    "4"     "8"
"C"    "y"      "1"    "8"   "0"   "1"
 [83,] "PERC-0530" "1" "2"   "MU"    "r"    "F" "20367"    "4"     "8"
"C"    "y"      "1"    "6"   "0"   "1"
 [84,] "PERC-0530" "1" "2"   "MU"    "r"    "F" "20367"    "4"     "8"
"C"    "y"      "1"    "2"   "2"   "2"
 [85,] "PERC-0530" "1" "3"   "MU"    "r"    "F" "26817"    "4"     "8"
"C"    "y"      "1"    "5"   "0"   "1"
 [86,] "PERC-0530" "1" "3"   "MU"    "r"    "F" "26817"    "4"     "8"
"C"    "y"      "1"    "3"   "2"   "2"
 [87,] "PERC-0530" "1" "4"   "MU"    "r"    "F" "35303"    "4"     "8"
"C"    "y"      "1"    "4"   "0"   "1"
 [88,] "PERC-0530" "1" "4"   "MU"    "r"    "F" "35303"    "4"     "8"
"C"    "y"      "1"    "5"   "2"   "2"
 [89,] "PERC-0530" "1" "5"   "MU"    "r"    "F" "40055"    "4"     "8"
"C"    "y"      "1"    "2"   "0"   "1"
 [90,] "PERC-0530" "1" "5"   "MU"    "r"    "F" "40055"    "4"     "8"
"C"    "y"      "1"    "6"   "2"   "2"
 [91,] "PERC-0530" "1" "6"   "MU"    "r"    "F" "45826"    "4"     "8"
"C"    "y"      "1"    "2"   "0"   "1"
 [92,] "PERC-0530" "1" "6"   "MU"    "r"    "F" "45826"    "4"     "8"
"C"    "y"      "1"    "6"   "2"   "2"
 [93,] "PERC-0530" "1" "7"   "MU"    "r"    "F" "49220"    "4"     "8"
"C"    "y"      "1"    "2"   "0"   "1"
 [94,] "PERC-0530" "1" "7"   "MU"    "r"    "F" "49220"    "4"     "8"
"C"    "y"      "1"    "6"   "2"   "2"
 [95,] "PERC-0530" "1" "8"   "MU"    "r"    "F" "60422"    "4"     "8"
"C"    "y"      "1"    "2"   "0"   "1"
 [96,] "PERC-0530" "1" "8"   "MU"    "r"    "F" "60422"    "4"     "8"
"C"    "y"      "1"    "6"   "2"   "2"
 [97,] "PERC-0530" "2" "1"   "MU"    "r"    "B" "46165"    "0.04"  "15"
"C"    "n"      "15"   "1"   "0"   "1"
 [98,] "PERC-0530" "2" "2"   "MU"    "r"    "B" "46165"    "0.04"  "15"
"C"    "n"      "15"   "1"   "1"   "1"
 [99,] "PERC-0530" "2" "3"   "MU"    "r"    "B" "46165"    "0.09"  "15"
"C"    "n"      "15"   "1"   "1"   "1"
[100,] "PERC-0530" "2" "4"   "MU"    "r"    "B" "46165"    "0.1"   "15"
"C"    "n"      "15"   "1"   "1"   "1"
[101,] "PERC-0530" "2" "5"   "MU"    "r"    "B" "82826"    "0.02"  "15"
"C"    "n"      "15"   "1"   "0"   "1"
[102,] "PERC-0530" "2" "6"   "MU"    "r"    "B" "82826"    "0.03"  "15"
"C"    "n"      "15"   "1"   "1"   "1"
[103,] "PERC-0530" "2" "7"   "MU"    "r"    "B" "82826"    "0.05"  "15"
"C"    "n"      "15"   "1"   "1"   "1"
[104,] "PERC-0530" "2" "8"   "MU"    "r"    "B" "82826"    "0.06"  "15"
"C"    "n"      "15"   "1"   "1"   "1"
[105,] "PERC-0536" "1" "2"   "RT"    "CD"   "M" "13579"    "4"     "15"
"L"    "n"      "15"   "1"   "0"   "0"
[106,] "PERC-0536" "1" "3"   "RT"    "CD"   "M" "13579"    "4"     "15"
"L"    "n"      "15"   "1"   "1"   "1"
[107,] "PERC-0536" "1" "4"   "RT"    "CD"   "M" "13579"    "4"     "15"
"L"    "n"      "15"   "1"   "1"   "1"
[108,] "PERC-0536" "1" "6"   "RT"    "CD"   "M" "6789"     "4"     "15"
"L"    "n"      "15"   "1"   "0"   "0"
[109,] "PERC-0536" "1" "7"   "RT"    "CD"   "M" "6789"     "4"     "15"
"L"    "n"      "15"   "1"   "1"   "1"
[110,] "PERC-0536" "1" "8"   "RT"    "CD"   "M" "6789"     "4"     "15"
"L"    "n"      "15"   "1"   "1"   "1"
[111,] "PERC-0536" "1" "10"  "RT"    "CD"   "M" "3395"     "4"     "15"
"L"    "n"      "15"   "1"   "0"   "0"
[112,] "PERC-0536" "1" "11"  "RT"    "CD"   "M" "3395"     "4"     "15"
"L"    "n"      "15"   "1"   "0"   "0"
[113,] "PERC-0536" "1" "12"  "RT"    "CD"   "M" "3395"     "4"     "15"
"L"    "n"      "15"   "1"   "0"   "0"
[114,] "PERC-0537" "1" "2"   "MU"    "SW"   "F" "25119"    "0.22"  "1"
"C"    "n"      "1"    "1"   "1"   "1"
[115,] "PERC-0537" "1" "3"   "MU"    "SW"   "F" "25119"    "0.3"   "1"
"C"    "n"      "1"    "1"   "1"   "1"
[116,] "PERC-0537" "1" "4"   "MU"    "SW"   "F" "25119"    "0.32"  "1"
"C"    "n"      "1"    "1"   "1"   "1"
[117,] "PERC-0537" "1" "5"   "MU"    "SW"   "F" "25119"    "0.38"  "1"
"C"    "n"      "1"    "1"   "1"   "1"
[118,] "PERC-0537" "1" "6"   "MU"    "SW"   "F" "25119"    "0.45"  "1"
"C"    "n"      "1"    "1"   "1"   "1"
[119,] "PERC-0537" "1" "7"   "MU"    "SW"   "F" "25119"    "0.53"  "1"
"C"    "n"      "1"    "1"   "1"   "1"
[120,] "PERC-0537" "1" "8"   "MU"    "SW"   "F" "25119"    "0.55"  "1"
"C"    "n"      "1"    "1"   "1"   "1"
[121,] "PERC-0537" "1" "9"   "MU"    "SW"   "F" "25119"    "0.68"  "1"
"C"    "n"      "1"    "1"   "1"   "1"
[122,] "PERC-0537" "2" "2"   "MU"    "SW"   "F" "25119"    "6.33"  "17"
"L"    "n"      "1"    "15"  "0"   "0"
[123,] "PERC-0537" "2" "2"   "MU"    "SW"   "F" "25119"    "6.33"  "17"
"L"    "n"      "1"    "2"   "1"   "1"
[124,] "PERC-0537" "2" "3"   "MU"    "SW"   "F" "25119"    "7"     "14"
"L"    "n"      "1"    "13"  "0"   "0"
[125,] "PERC-0537" "2" "3"   "MU"    "SW"   "F" "25119"    "7"     "14"
"L"    "n"      "1"    "1"   "1"   "1"
[126,] "PERC-0537" "2" "4"   "MU"    "SW"   "F" "25119"    "8"     "15"
"L"    "n"      "1"    "7"   "0"   "0"
[127,] "PERC-0537" "2" "4"   "MU"    "SW"   "F" "25119"    "8"     "15"
"L"    "n"      "1"    "8"   "1"   "1"
[128,] "PERC-0537" "2" "5"   "MU"    "SW"   "F" "25119"    "8.67"  "14"
"L"    "n"      "1"    "10"  "0"   "0"
[129,] "PERC-0537" "2" "5"   "MU"    "SW"   "F" "25119"    "8.67"  "14"
"L"    "n"      "1"    "4"   "1"   "1"
[130,] "PERC-0537" "2" "6"   "MU"    "SW"   "F" "25119"    "9.33"  "11"
"L"    "n"      "1"    "1"   "0"   "0"
[131,] "PERC-0537" "2" "6"   "MU"    "SW"   "F" "25119"    "9.33"  "11"
"L"    "n"      "1"    "10"  "1"   "1"
[132,] "PERC-0537" "2" "7"   "MU"    "SW"   "F" "25119"    "11.33" "18"
"L"    "n"      "1"    "4"   "0"   "0"
[133,] "PERC-0537" "2" "7"   "MU"    "SW"   "F" "25119"    "11.33" "18"
"L"    "n"      "1"    "14"  "1"   "1"
[134,] "PERC-0537" "3" "2"   "MU"    "SW"   "F" "25119"    "6"     "1"
"C"    "n"      "1"    "1"   "2"   "2"
[135,] "PERC-0537" "3" "3"   "MU"    "SW"   "F" "25119"    "7.17"  "1"
"C"    "n"      "1"    "1"   "2"   "2"
[136,] "PERC-0537" "3" "4"   "MU"    "SW"   "F" "25119"    "7.75"  "1"
"C"    "n"      "1"    "1"   "2"   "2"
[137,] "PERC-0537" "3" "5"   "MU"    "SW"   "F" "25119"    "8.33"  "1"
"C"    "n"      "1"    "1"   "2"   "2"
[138,] "PERC-0537" "3" "6"   "MU"    "SW"   "F" "25119"    "9"     "1"
"C"    "n"      "1"    "1"   "2"   "2"
[139,] "PERC-0537" "3" "7"   "MU"    "SW"   "F" "25119"    "9.33"  "1"
"C"    "n"      "1"    "1"   "2"   "2"
[140,] "PERC-0537" "3" "8"   "MU"    "SW"   "F" "25119"    "10"    "1"
"C"    "n"      "1"    "1"   "2"   "2"
[141,] "PERC-0537" "3" "9"   "MU"    "SW"   "F" "25119"    "10.33" "1"
"C"    "n"      "1"    "1"   "2"   "2"
[142,] "PERC-0537" "3" "10"  "MU"    "SW"   "F" "25119"    "10.83" "1"
"C"    "n"      "1"    "1"   "2"   "2"
[143,] "PERC-0537" "3" "11"  "MU"    "SW"   "F" "25119"    "11.33" "1"
"C"    "n"      "1"    "1"   "2"   "2"
[144,] "PERC-0537" "3" "12"  "MU"    "SW"   "F" "25119"    "12"    "1"
"C"    "n"      "1"    "1"   "2"   "2"
[145,] "PERC-0537" "3" "13"  "MU"    "SW"   "F" "25119"    "12.5"  "1"
"C"    "n"      "1"    "1"   "2"   "2"
[146,] "PERC-0537" "3" "14"  "MU"    "SW"   "F" "25119"    "13.33" "1"
"C"    "n"      "1"    "1"   "2"   "2"
[147,] "PERC-0537" "3" "15"  "MU"    "SW"   "F" "25119"    "13.75" "1"
"C"    "n"      "1"    "1"   "2"   "2"
[148,] "PERC-0547" "1" "2"   "HU"    "r"    "M" "135.78"   "1"     "3"
"C"    "n"      "3"    "1"   "0"   "0"
[149,] "PERC-0547" "1" "3"   "HU"    "r"    "M" "678.9"    "1"     "3"
"C"    "n"      "3"    "1"   "0"   "0"
[150,] "PERC-0547" "1" "4"   "HU"    "r"    "M" "1018.35"  "1"     "3"
"C"    "n"      "3"    "1"   "0"   "0"
[151,] "PERC-0547" "1" "5"   "HU"    "r"    "M" "135.78"   "3"     "3"
"C"    "n"      "3"    "1"   "0"   "0"
[152,] "PERC-0547" "1" "6"   "HU"    "r"    "M" "678.9"    "3"     "3"
"C"    "n"      "3"    "1"   "0"   "0"
[153,] "PERC-0547" "1" "7"   "HU"    "r"    "M" "1018.35"  "3"     "3"
"C"    "n"      "3"    "1"   "0"   "0"
[154,] "PERC-0547" "1" "8"   "HU"    "r"    "M" "135.78"   "7.5"   "4"
"C"    "n"      "4"    "1"   "0"   "0"
[155,] "PERC-0547" "1" "9"   "HU"    "r"    "M" "678.9"    "7.5"   "4"
"C"    "n"      "4"    "1"   "0"   "1"
[156,] "PERC-0547" "1" "10"  "HU"    "r"    "M" "1018.35"  "7.5"   "4"
"C"    "n"      "4"    "1"   "0"   "1"
[157,] "RFC-1633"  "1" "2"   "RT"    "SD"   "F" "1580"     "4"     "6"
"L"    "n"      "6"    "1"   "0"   "0"
[158,] "RFC-1633"  "1" "3"   "RT"    "SD"   "F" "3150"     "4"     "6"
"L"    "n"      "6"    "1"   "0"   "0"
[159,] "RFC-1633"  "1" "4"   "RT"    "SD"   "F" "6300"     "4"     "6"
"L"    "n"      "6"    "1"   "0"   "0"
[160,] "RFC-1633"  "1" "5"   "RT"    "SD"   "F" "12600"    "4"     "6"
"L"    "n"      "6"    "1"   "0"   "0"
[161,] "RFC-1633"  "1" "6"   "RT"    "SD"   "F" "25200"    "4"     "6"
"L"    "n"      "6"    "1"   "0"   "0"
[162,] "RFC-2109"  "1" "5"   "MU"    "SW"   "M" "4046"     "4"     "10"
"C"    "n"      "10"   "1"   "0"   "1"
[163,] "RFC-2109"  "1" "6"   "MU"    "SW"   "M" "4406"     "4"     "10"
"C"    "n"      "10"   "1"   "0"   "1"
[164,] "RFC-2109"  "1" "7"   "MU"    "SW"   "M" "4644"     "4"     "10"
"C"    "n"      "10"   "1"   "0"   "1"
[165,] "RFC-2109"  "1" "8"   "MU"    "SW"   "M" "5567"     "4"     "10"
"C"    "n"      "10"   "1"   "0"   "1"
[166,] "RFC-2431"  "1" "1"   "MU"    "r"    "B" "24630"    "0.02"  "10"
"C"    "n"      "10"   "1"   "0"   "1"
[167,] "RFC-2431"  "1" "2"   "MU"    "r"    "B" "24630"    "0.03"  "10"
"C"    "n"      "10"   "1"   "1"   "1"
[168,] "RFC-2431"  "1" "3"   "MU"    "r"    "B" "24630"    "0.05"  "10"
"C"    "n"      "10"   "1"   "1"   "1"
[169,] "RFC-2431"  "1" "4"   "MU"    "r"    "B" "24630"    "0.12"  "10"
"C"    "n"      "10"   "1"   "1"   "1"
[170,] "TOL-0178"  "2" "2"   "MU"    "NM"   "M" "616.67"   "0.25"  "27"
"C"    "n"      "27"   "1"   "1"   "1"
[171,] "TOL-0178"  "2" "3"   "MU"    "NM"   "M" "616.67"   "1"     "27"
"C"    "n"      "27"   "1"   "1"   "1"
[172,] "TOL-0178"  "2" "4"   "MU"    "NM"   "M" "2192.59"  "0.25"  "27"
"C"    "n"      "27"   "1"   "1"   "1"
[173,] "TOL-0178"  "2" "5"   "MU"    "NM"   "M" "2192.59"  "1"     "27"
"C"    "n"      "27"   "1"   "1"   "1"
[174,] "TOL-0178"  "2" "6"   "MU"    "NM"   "M" "24666.67" "0.25"  "14"
"C"    "n"      "14"   "1"   "1"   "1"
[175,] "TOL-0178"  "2" "7"   "MU"    "NM"   "M" "24666.67" "1"     "14"
"C"    "n"      "14"   "1"   "1"   "1"
[176,] "TOL-0178"  "2" "8"   "MU"    "NM"   "M" "2740.74"  "1"     "27"
"C"    "n"      "27"   "1"   "0"   "1"
[177,] "TOL-0178"  "2" "9"   "MU"    "NM"   "M" "4111.11"  "1"     "27"
"C"    "n"      "27"   "1"   "0"   "1"
[178,] "TOL-0178"  "2" "10"  "MU"    "NM"   "M" "5481.48"  "1"     "14"
"C"    "n"      "14"   "1"   "0"   "1"
[179,] "TOL-0178"  "2" "11"  "MU"    "NM"   "M" "8222.23"  "1"     "14"
"C"    "n"      "14"   "1"   "0"   "1"
[180,] "TOL-0178"  "2" "12"  "MU"    "NM"   "M" "12333.34" "1"     "14"
"C"    "n"      "14"   "1"   "0"   "1"

$excluded:
$excluded$names:
[1] "Species" "Target"

$excluded$"":
[1] "DG"

$excluded$"":
[1] "R"


$cluster.var:
[1] "Ref.id" "Exp"

$strata:
$strata$intercept:
[1] "Species" "Target"

$strata$conc:
[1] "Target"

$strata$time:
NULL


$xlog:
[1] "CT"

$link:
[1] "logit"

$gpcorr:
[1] 1

$missing.row:
numeric(0)

$zero.row:
 [1]   2   3   4  12  18  21  25  64  67 114 118 122 126 135 148 163 173
179 180 181 182 191

$infile:
[1] "perc.csv"




>



From ben at zoo.ufl.edu  Tue Dec  3 23:44:02 2002
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Tue Dec  3 23:44:02 2002
Subject: Plot optimization [Was: Re: [R] Plotting Speed: R vs Octave]
In-Reply-To: <20021203213235.GA6727@komensky.surfbest.net>
Message-ID: <Pine.LNX.4.44.0212031744040.1111-100000@bolker.zoo.ufl.edu>

  I won't say I know exactly what's going on here, but ... can you simply 
do something like

xycomb <- paste(x,y)
dups <- duplicated(xycomb)
x <- x[!dups]
y <- y[!dups]
plot(x,y)

If you mess with rounding x and y before you paste them, this could also 
give you a way of thinning your plot [although the results would be 
slightly random depending on which points came first]

  It seems to make more sense to put a tiny bit of effort into thinning 
the points at your end rather than building code into R's postscript 
driver to deal with this case.


On Tue, 3 Dec 2002, Matej Cepl wrote:

> Deepayan Sarkar wrote:
> > Also, wireframe code is currently far from optimized (it makes
> > a separate R level function call to draw each quadrilateral).
> > It would be more interesting to know why (and how much) persp
> > is slower.
> 
> On somehow different note. I have asked couple of days ago about
> possibility of optimalization of plotting functions (pairs
> function created for me 0.5MB pictures). Answer was more or less
> unsatisfactory. I do not want bother you about that again, but
> I have took a look at the EPS file itself and this is what
> I found these interesting lines
> 
> 	% these are definitions
> 	/c { newpath 0 360 arc } def
> 	/p1  { stroke } def
> 
> 	% and than there is a many thousand
> 	% lines like these (something around 80k to be exact)
> 	
> 	330.89 387.93 1.63 c p1
> 	330.89 377.14 1.63 c p1
> 	330.89 377.14 1.63 c p1
> 	330.89 387.93 1.63 c p1
> 	330.89 387.93 1.63 c p1
> 
> If I understand well these lines use procedure /c for drawing
> a circle in particular positions, many times overplotting
> previously already drawn points (statistically speaking, not
> points in terms of pixels).
> 
> PDF file created with these pictures prettly certainly kicked
> down any laser printer I was pushing it through. Do you think,
> that it would not be possible somehow to optimize PostScript
> coming from R (at least to avoid overplotting by calling exactly
> the same procedure at exactly same points)?
> 
> The example file is attached.
> 
> Matej
> 
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From andy_liaw at merck.com  Wed Dec  4 01:37:03 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed Dec  4 01:37:03 2002
Subject: [R] Any difference in cbind() b/w SPLus and R??
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC952@usrymx10.merck.com>

I'm no expert, but use of cbind on arbitrary lists like your "data.char" is
undocumented in Splus, so if the program relies on that undocumented
"feature", you can only blame the programmer.

It seems like something like the following in R may give you approximately
the same info:

  str(data.char, max.level=1, vec.len=0, give.attr=FALSE)

HTH,
Andy

-----Original Message-----
From: Liu.Chunhua at epamail.epa.gov [mailto:Liu.Chunhua at epamail.epa.gov]
Sent: Tuesday, December 03, 2002 5:03 PM
To: R-help at stat.math.ethz.ch
Cc: Gift.Jeff at epamail.epa.gov
Subject: [R] Any difference in cbind() b/w SPLus and R??


Dear Experts,

I have a data object named  "data.char".

When I use cbind(data.char) in SPlus, I got the following results:

> cbind(data.char)
               data.char
       data matrix, 2700
   excluded list, 3
cluster.var character, 2
     strata list, 3
       xlog CT
       link logit
     gpcorr 1
missing.row numeric, 0
   zero.row numeric, 22
     infile perc.csv
attr(, "names"):
 [1] "data"        "excluded"    "cluster.var" "strata"      "xlog"
"link"        "gpcorr"      "missing.row"
 [9] "zero.row"    "infile"
>

However, when I use it in R, I got the following error message:
> cbind(data.char)
Error in cbind(...) : cannot create a matrix from these types

I'm converting a program writen in SPlus to R, and have this problem.
Are there any differences in using cbind() b/w SPlus and R? How should I
do it in R?

Your help is greatly appreciated.

Charlie Liu
Graduate Intern at US EPA


THis is what's in "data.char"

> data.char
$data:
            Ref.id Exp Group Species Strain Sex      mg/m3   Hours Nsub
Target Censored GpSize Incid SevLo SevHi
  [1,] "ACC-2688"  "1" "3"   "HU"    "r"    "M" "686"      "7"     "12"
"C"    "n"      "12"   "1"   "1"   "1"
  [2,] "CHL-0259"  "1" "2"   "MU"    "OT"   "F" "1356.58"  "4"     "10"
"L"    "n"      "1"    "4"   "0"   "0"
  [3,] "CHL-0259"  "1" "2"   "MU"    "OT"   "F" "1356.58"  "4"     "10"
"L"    "n"      "1"    "6"   "0"   "1"
  [4,] "CHL-0259"  "1" "3"   "MU"    "OT"   "F" "2713.15"  "4"     "10"
"L"    "n"      "1"    "4"   "0"   "1"
  [5,] "CHL-0259"  "1" "3"   "MU"    "OT"   "F" "2713.15"  "4"     "10"
"L"    "n"      "1"    "6"   "1"   "1"
  [6,] "CHL-0259"  "1" "4"   "MU"    "OT"   "F" "5426.3"   "4"     "10"
"L"    "n"      "1"    "3"   "0"   "1"
  [7,] "CHL-0259"  "1" "4"   "MU"    "OT"   "F" "5426.3"   "4"     "10"
"L"    "n"      "1"    "7"   "1"   "1"
  [8,] "CHL-0259"  "1" "5"   "MU"    "OT"   "F" "10852.6"  "4"     "10"
"L"    "n"      "1"    "10"  "1"   "1"
  [9,] "CHL-0259"  "1" "7"   "MU"    "OT"   "F" "1356.58"  "4"     "10"
"L"    "n"      "1"    "10"  "0"   "0"
 [10,] "CHL-0259"  "1" "8"   "MU"    "OT"   "F" "2713.15"  "4"     "10"
"L"    "n"      "1"    "2"   "0"   "0"
 [11,] "CHL-0259"  "1" "8"   "MU"    "OT"   "F" "2713.15"  "4"     "10"
"L"    "n"      "1"    "8"   "1"   "1"
 [12,] "CHL-0259"  "1" "9"   "MU"    "OT"   "F" "5426.3"   "4"     "10"
"L"    "n"      "1"    "10"  "1"   "1"
 [13,] "CHL-0259"  "1" "10"  "MU"    "OT"   "F" "10852.6"  "4"     "10"
"L"    "n"      "1"    "10"  "1"   "1"
 [14,] "PERC-0107" "1" "2"   "RT"    "CA"   "F" "7800.31"  "4"     "10"
"C"    "n"      "10"   "1"   "0"   "0"
 [15,] "PERC-0107" "1" "3"   "RT"    "CA"   "F" "15600.61" "4"     "10"
"C"    "n"      "10"   "1"   "1"   "1"
 [16,] "PERC-0285" "1" "2"   "HU"    "r"    "M" "1315.88"  "0.25"  "6"
"C"    "n"      "6"    "1"   "0"   "0"
 [17,] "PERC-0285" "1" "3"   "HU"    "r"    "M" "1315.88"  "0.5"   "6"
"C"    "n"      "6"    "1"   "0"   "1"
 [18,] "PERC-0285" "1" "4"   "HU"    "r"    "M" "1315.88"  "3"     "6"
"C"    "n"      "6"    "1"   "0"   "1"
 [19,] "PERC-0285" "2" "2"   "HU"    "r"    "M" "1315.88"  "0.25"  "6"
"C"    "n"      "6"    "1"   "0"   "0"
 [20,] "PERC-0285" "2" "3"   "HU"    "r"    "M" "1315.88"  "0.5"   "6"
"C"    "n"      "6"    "1"   "0"   "1"
 [21,] "PERC-0285" "2" "4"   "HU"    "r"    "M" "1315.88"  "1.5"   "6"
"C"    "n"      "6"    "1"   "0"   "1"
 [22,] "PERC-0334" "1" "1"   "RT"    "WI"   "B" "135787"   "1.2"   "30"
"C"    "n"      "1"    "30"  "2"   "2"
 [23,] "PERC-0334" "1" "2"   "RT"    "WI"   "B" "135787"   "0.08"  "30"
"C"    "n"      "30"   "1"   "0"   "1"
 [24,] "PERC-0334" "1" "3"   "RT"    "WI"   "B" "81472"    "3"     "20"
"C"    "n"      "20"   "1"   "2"   "2"
 [25,] "PERC-0334" "1" "4"   "RT"    "WI"   "B" "81472"    "2.5"   "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [26,] "PERC-0334" "1" "5"   "RT"    "WI"   "B" "81472"    "2"     "20"
"C"    "n"      "20"   "1"   "2"   "2"
 [27,] "PERC-0334" "1" "6"   "RT"    "WI"   "B" "81472"    "1"     "20"
"C"    "n"      "20"   "1"   "2"   "2"
 [28,] "PERC-0334" "1" "7"   "RT"    "WI"   "B" "81472"    "0.6"   "20"
"C"    "n"      "20"   "1"   "2"   "2"
 [29,] "PERC-0334" "1" "8"   "RT"    "WI"   "B" "81472"    "0.4"   "20"
"C"    "n"      "20"   "1"   "0"   "1"
 [30,] "PERC-0334" "1" "9"   "RT"    "WI"   "B" "81472"    "0.3"   "20"
"C"    "n"      "20"   "1"   "2"   "2"
 [31,] "PERC-0334" "1" "10"  "RT"    "WI"   "B" "81472"    "0.2"   "20"
"C"    "n"      "20"   "1"   "0"   "1"
 [32,] "PERC-0334" "1" "11"  "RT"    "WI"   "B" "40736"    "8"     "20"
"C"    "n"      "20"   "1"   "2"   "2"
 [33,] "PERC-0334" "1" "12"  "RT"    "WI"   "B" "40736"    "6"     "10"
"C"    "n"      "10"   "1"   "2"   "2"
 [34,] "PERC-0334" "1" "13"  "RT"    "WI"   "B" "40736"    "5"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [35,] "PERC-0334" "1" "14"  "RT"    "WI"   "B" "40736"    "1"     "15"
"C"    "n"      "15"   "1"   "0"   "1"
 [36,] "PERC-0334" "1" "15"  "RT"    "WI"   "B" "40736"    "0.8"   "11"
"C"    "n"      "11"   "1"   "0"   "1"
 [37,] "PERC-0334" "1" "16"  "RT"    "WI"   "B" "40736"    "0.6"   "20"
"C"    "n"      "20"   "1"   "0"   "1"
 [38,] "PERC-0334" "1" "17"  "RT"    "WI"   "B" "20368"    "8"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [39,] "PERC-0334" "1" "18"  "RT"    "WI"   "B" "20368"    "6"     "10"
"C"    "n"      "10"   "1"   "2"   "2"
 [40,] "PERC-0334" "1" "19"  "RT"    "WI"   "B" "20368"    "5"     "15"
"C"    "n"      "15"   "1"   "2"   "2"
 [41,] "PERC-0334" "1" "20"  "RT"    "WI"   "B" "20368"    "4"     "30"
"C"    "n"      "30"   "1"   "0"   "1"
 [42,] "PERC-0334" "1" "21"  "RT"    "WI"   "B" "13579"    "14"    "10"
"C"    "n"      "10"   "1"   "0"   "0"
 [43,] "PERC-0334" "1" "22"  "RT"    "WI"   "B" "13579"    "10"    "20"
"C"    "n"      "20"   "1"   "0"   "0"
 [44,] "PERC-0334" "2" "1"   "RT"    "WI"   "F" "81472"    "0.2"   "4"
"L"    "n"      "4"    "1"   "0"   "0"
 [45,] "PERC-0334" "2" "2"   "RT"    "WI"   "F" "81472"    "0.6"   "4"
"L"    "n"      "4"    "1"   "0"   "1"
 [46,] "PERC-0334" "2" "3"   "RT"    "WI"   "F" "40748"    "0.4"   "4"
"L"    "n"      "4"    "1"   "0"   "0"
 [47,] "PERC-0334" "2" "4"   "RT"    "WI"   "F" "40748"    "0.6"   "4"
"L"    "n"      "4"    "1"   "0"   "1"
 [48,] "PERC-0334" "2" "5"   "RT"    "WI"   "F" "16973"    "3"     "4"
"L"    "n"      "4"    "1"   "0"   "0"
 [49,] "PERC-0334" "2" "6"   "RT"    "WI"   "F" "16973"    "5"     "4"
"L"    "n"      "4"    "1"   "0"   "1"
 [50,] "PERC-0334" "2" "7"   "RT"    "WI"   "F" "10862"    "5"     "4"
"L"    "n"      "4"    "1"   "0"   "0"
 [51,] "PERC-0334" "2" "8"   "RT"    "WI"   "F" "10862"    "7"     "4"
"L"    "n"      "4"    "1"   "0"   "1"
 [52,] "PERC-0334" "3" "1"   "HU"    "r"    "B" "7197"     "0.03"  "4"
"C"    "n"      "4"    "1"   "1"   "1"
 [53,] "PERC-0334" "3" "2"   "HU"    "r"    "B" "4074"     "0.17"  "2"
"C"    "n"      "2"    "1"   "1"   "1"
 [54,] "PERC-0334" "3" "3"   "HU"    "r"    "B" "1901"     "2"     "4"
"C"    "n"      "4"    "1"   "1"   "1"
 [55,] "PERC-0334" "3" "4"   "HU"    "r"    "B" "1467"     "2"     "4"
"C"    "n"      "4"    "1"   "1"   "1"
 [56,] "PERC-0334" "3" "5"   "HU"    "r"    "B" "720"      "1"     "6"
"C"    "n"      "6"    "1"   "0"   "0"
 [57,] "PERC-0339" "1" "2"   "HU"    "r"    "B" "169.73"   "5.5"   "12"
"C"    "n"      "12"   "1"   "0"   "0"
 [58,] "PERC-0339" "1" "3"   "HU"    "r"    "B" "678.9"    "5.5"   "12"
"C"    "n"      "12"   "1"   "0"   "1"
 [59,] "PERC-0344" "1" "2"   "MU"    "CB"   "F" "5431"     "3"     "6"
"L"    "n"      "6"    "1"   "0"   "1"
 [60,] "PERC-0344" "1" "3"   "MU"    "CB"   "F" "5431"     "3"     "6"
"L"    "n"      "6"    "1"   "0"   "1"
 [61,] "PERC-0344" "1" "4"   "MU"    "CB"   "F" "5431"     "3"     "6"
"L"    "n"      "6"    "1"   "0"   "1"
 [62,] "PERC-0344" "1" "5"   "MU"    "CB"   "F" "5431"     "3"     "6"
"L"    "n"      "6"    "1"   "0"   "1"
 [63,] "PERC-0528" "1" "1"   "RT"    "F3"   "M" "16599"    "4"     "5"
"C"    "n"      "5"    "1"   "0"   "1"
 [64,] "PERC-0528" "1" "2"   "RT"    "F3"   "M" "25703"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [65,] "PERC-0528" "1" "3"   "RT"    "F3"   "M" "27781"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [66,] "PERC-0528" "1" "4"   "RT"    "F3"   "M" "30639"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [67,] "PERC-0528" "1" "5"   "RT"    "F3"   "M" "35052"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [68,] "PERC-0528" "2" "2"   "RT"    "F3"   "F" "25703"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [69,] "PERC-0528" "2" "3"   "RT"    "F3"   "F" "27781"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [70,] "PERC-0528" "2" "4"   "RT"    "F3"   "F" "30639"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [71,] "PERC-0528" "2" "5"   "RT"    "F3"   "F" "35052"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [72,] "PERC-0528" "4" "1"   "MU"    "B6"   "M" "15805"    "4"     "5"
"C"    "n"      "5"    "1"   "0"   "1"
 [73,] "PERC-0528" "4" "2"   "MU"    "B6"   "M" "16599"    "4"     "5"
"C"    "n"      "5"    "1"   "0"   "1"
 [74,] "PERC-0528" "4" "3"   "MU"    "B6"   "M" "17740"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [75,] "PERC-0528" "4" "4"   "MU"    "B6"   "M" "20170"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [76,] "PERC-0528" "4" "5"   "MU"    "B6"   "M" "25703"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [77,] "PERC-0528" "5" "1"   "MU"    "B6"   "F" "15805"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [78,] "PERC-0528" "5" "2"   "MU"    "B6"   "F" "16599"    "4"     "5"
"C"    "n"      "5"    "1"   "0"   "1"
 [79,] "PERC-0528" "5" "3"   "MU"    "B6"   "F" "17740"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [80,] "PERC-0528" "5" "4"   "MU"    "B6"   "F" "20170"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [81,] "PERC-0528" "5" "5"   "MU"    "B6"   "F" "25703"    "4"     "5"
"C"    "n"      "5"    "1"   "2"   "2"
 [82,] "PERC-0530" "1" "1"   "MU"    "r"    "F" "16633"    "4"     "8"
"C"    "y"      "1"    "8"   "0"   "1"
 [83,] "PERC-0530" "1" "2"   "MU"    "r"    "F" "20367"    "4"     "8"
"C"    "y"      "1"    "6"   "0"   "1"
 [84,] "PERC-0530" "1" "2"   "MU"    "r"    "F" "20367"    "4"     "8"
"C"    "y"      "1"    "2"   "2"   "2"
 [85,] "PERC-0530" "1" "3"   "MU"    "r"    "F" "26817"    "4"     "8"
"C"    "y"      "1"    "5"   "0"   "1"
 [86,] "PERC-0530" "1" "3"   "MU"    "r"    "F" "26817"    "4"     "8"
"C"    "y"      "1"    "3"   "2"   "2"
 [87,] "PERC-0530" "1" "4"   "MU"    "r"    "F" "35303"    "4"     "8"
"C"    "y"      "1"    "4"   "0"   "1"
 [88,] "PERC-0530" "1" "4"   "MU"    "r"    "F" "35303"    "4"     "8"
"C"    "y"      "1"    "5"   "2"   "2"
 [89,] "PERC-0530" "1" "5"   "MU"    "r"    "F" "40055"    "4"     "8"
"C"    "y"      "1"    "2"   "0"   "1"
 [90,] "PERC-0530" "1" "5"   "MU"    "r"    "F" "40055"    "4"     "8"
"C"    "y"      "1"    "6"   "2"   "2"
 [91,] "PERC-0530" "1" "6"   "MU"    "r"    "F" "45826"    "4"     "8"
"C"    "y"      "1"    "2"   "0"   "1"
 [92,] "PERC-0530" "1" "6"   "MU"    "r"    "F" "45826"    "4"     "8"
"C"    "y"      "1"    "6"   "2"   "2"
 [93,] "PERC-0530" "1" "7"   "MU"    "r"    "F" "49220"    "4"     "8"
"C"    "y"      "1"    "2"   "0"   "1"
 [94,] "PERC-0530" "1" "7"   "MU"    "r"    "F" "49220"    "4"     "8"
"C"    "y"      "1"    "6"   "2"   "2"
 [95,] "PERC-0530" "1" "8"   "MU"    "r"    "F" "60422"    "4"     "8"
"C"    "y"      "1"    "2"   "0"   "1"
 [96,] "PERC-0530" "1" "8"   "MU"    "r"    "F" "60422"    "4"     "8"
"C"    "y"      "1"    "6"   "2"   "2"
 [97,] "PERC-0530" "2" "1"   "MU"    "r"    "B" "46165"    "0.04"  "15"
"C"    "n"      "15"   "1"   "0"   "1"
 [98,] "PERC-0530" "2" "2"   "MU"    "r"    "B" "46165"    "0.04"  "15"
"C"    "n"      "15"   "1"   "1"   "1"
 [99,] "PERC-0530" "2" "3"   "MU"    "r"    "B" "46165"    "0.09"  "15"
"C"    "n"      "15"   "1"   "1"   "1"
[100,] "PERC-0530" "2" "4"   "MU"    "r"    "B" "46165"    "0.1"   "15"
"C"    "n"      "15"   "1"   "1"   "1"
[101,] "PERC-0530" "2" "5"   "MU"    "r"    "B" "82826"    "0.02"  "15"
"C"    "n"      "15"   "1"   "0"   "1"
[102,] "PERC-0530" "2" "6"   "MU"    "r"    "B" "82826"    "0.03"  "15"
"C"    "n"      "15"   "1"   "1"   "1"
[103,] "PERC-0530" "2" "7"   "MU"    "r"    "B" "82826"    "0.05"  "15"
"C"    "n"      "15"   "1"   "1"   "1"
[104,] "PERC-0530" "2" "8"   "MU"    "r"    "B" "82826"    "0.06"  "15"
"C"    "n"      "15"   "1"   "1"   "1"
[105,] "PERC-0536" "1" "2"   "RT"    "CD"   "M" "13579"    "4"     "15"
"L"    "n"      "15"   "1"   "0"   "0"
[106,] "PERC-0536" "1" "3"   "RT"    "CD"   "M" "13579"    "4"     "15"
"L"    "n"      "15"   "1"   "1"   "1"
[107,] "PERC-0536" "1" "4"   "RT"    "CD"   "M" "13579"    "4"     "15"
"L"    "n"      "15"   "1"   "1"   "1"
[108,] "PERC-0536" "1" "6"   "RT"    "CD"   "M" "6789"     "4"     "15"
"L"    "n"      "15"   "1"   "0"   "0"
[109,] "PERC-0536" "1" "7"   "RT"    "CD"   "M" "6789"     "4"     "15"
"L"    "n"      "15"   "1"   "1"   "1"
[110,] "PERC-0536" "1" "8"   "RT"    "CD"   "M" "6789"     "4"     "15"
"L"    "n"      "15"   "1"   "1"   "1"
[111,] "PERC-0536" "1" "10"  "RT"    "CD"   "M" "3395"     "4"     "15"
"L"    "n"      "15"   "1"   "0"   "0"
[112,] "PERC-0536" "1" "11"  "RT"    "CD"   "M" "3395"     "4"     "15"
"L"    "n"      "15"   "1"   "0"   "0"
[113,] "PERC-0536" "1" "12"  "RT"    "CD"   "M" "3395"     "4"     "15"
"L"    "n"      "15"   "1"   "0"   "0"
[114,] "PERC-0537" "1" "2"   "MU"    "SW"   "F" "25119"    "0.22"  "1"
"C"    "n"      "1"    "1"   "1"   "1"
[115,] "PERC-0537" "1" "3"   "MU"    "SW"   "F" "25119"    "0.3"   "1"
"C"    "n"      "1"    "1"   "1"   "1"
[116,] "PERC-0537" "1" "4"   "MU"    "SW"   "F" "25119"    "0.32"  "1"
"C"    "n"      "1"    "1"   "1"   "1"
[117,] "PERC-0537" "1" "5"   "MU"    "SW"   "F" "25119"    "0.38"  "1"
"C"    "n"      "1"    "1"   "1"   "1"
[118,] "PERC-0537" "1" "6"   "MU"    "SW"   "F" "25119"    "0.45"  "1"
"C"    "n"      "1"    "1"   "1"   "1"
[119,] "PERC-0537" "1" "7"   "MU"    "SW"   "F" "25119"    "0.53"  "1"
"C"    "n"      "1"    "1"   "1"   "1"
[120,] "PERC-0537" "1" "8"   "MU"    "SW"   "F" "25119"    "0.55"  "1"
"C"    "n"      "1"    "1"   "1"   "1"
[121,] "PERC-0537" "1" "9"   "MU"    "SW"   "F" "25119"    "0.68"  "1"
"C"    "n"      "1"    "1"   "1"   "1"
[122,] "PERC-0537" "2" "2"   "MU"    "SW"   "F" "25119"    "6.33"  "17"
"L"    "n"      "1"    "15"  "0"   "0"
[123,] "PERC-0537" "2" "2"   "MU"    "SW"   "F" "25119"    "6.33"  "17"
"L"    "n"      "1"    "2"   "1"   "1"
[124,] "PERC-0537" "2" "3"   "MU"    "SW"   "F" "25119"    "7"     "14"
"L"    "n"      "1"    "13"  "0"   "0"
[125,] "PERC-0537" "2" "3"   "MU"    "SW"   "F" "25119"    "7"     "14"
"L"    "n"      "1"    "1"   "1"   "1"
[126,] "PERC-0537" "2" "4"   "MU"    "SW"   "F" "25119"    "8"     "15"
"L"    "n"      "1"    "7"   "0"   "0"
[127,] "PERC-0537" "2" "4"   "MU"    "SW"   "F" "25119"    "8"     "15"
"L"    "n"      "1"    "8"   "1"   "1"
[128,] "PERC-0537" "2" "5"   "MU"    "SW"   "F" "25119"    "8.67"  "14"
"L"    "n"      "1"    "10"  "0"   "0"
[129,] "PERC-0537" "2" "5"   "MU"    "SW"   "F" "25119"    "8.67"  "14"
"L"    "n"      "1"    "4"   "1"   "1"
[130,] "PERC-0537" "2" "6"   "MU"    "SW"   "F" "25119"    "9.33"  "11"
"L"    "n"      "1"    "1"   "0"   "0"
[131,] "PERC-0537" "2" "6"   "MU"    "SW"   "F" "25119"    "9.33"  "11"
"L"    "n"      "1"    "10"  "1"   "1"
[132,] "PERC-0537" "2" "7"   "MU"    "SW"   "F" "25119"    "11.33" "18"
"L"    "n"      "1"    "4"   "0"   "0"
[133,] "PERC-0537" "2" "7"   "MU"    "SW"   "F" "25119"    "11.33" "18"
"L"    "n"      "1"    "14"  "1"   "1"
[134,] "PERC-0537" "3" "2"   "MU"    "SW"   "F" "25119"    "6"     "1"
"C"    "n"      "1"    "1"   "2"   "2"
[135,] "PERC-0537" "3" "3"   "MU"    "SW"   "F" "25119"    "7.17"  "1"
"C"    "n"      "1"    "1"   "2"   "2"
[136,] "PERC-0537" "3" "4"   "MU"    "SW"   "F" "25119"    "7.75"  "1"
"C"    "n"      "1"    "1"   "2"   "2"
[137,] "PERC-0537" "3" "5"   "MU"    "SW"   "F" "25119"    "8.33"  "1"
"C"    "n"      "1"    "1"   "2"   "2"
[138,] "PERC-0537" "3" "6"   "MU"    "SW"   "F" "25119"    "9"     "1"
"C"    "n"      "1"    "1"   "2"   "2"
[139,] "PERC-0537" "3" "7"   "MU"    "SW"   "F" "25119"    "9.33"  "1"
"C"    "n"      "1"    "1"   "2"   "2"
[140,] "PERC-0537" "3" "8"   "MU"    "SW"   "F" "25119"    "10"    "1"
"C"    "n"      "1"    "1"   "2"   "2"
[141,] "PERC-0537" "3" "9"   "MU"    "SW"   "F" "25119"    "10.33" "1"
"C"    "n"      "1"    "1"   "2"   "2"
[142,] "PERC-0537" "3" "10"  "MU"    "SW"   "F" "25119"    "10.83" "1"
"C"    "n"      "1"    "1"   "2"   "2"
[143,] "PERC-0537" "3" "11"  "MU"    "SW"   "F" "25119"    "11.33" "1"
"C"    "n"      "1"    "1"   "2"   "2"
[144,] "PERC-0537" "3" "12"  "MU"    "SW"   "F" "25119"    "12"    "1"
"C"    "n"      "1"    "1"   "2"   "2"
[145,] "PERC-0537" "3" "13"  "MU"    "SW"   "F" "25119"    "12.5"  "1"
"C"    "n"      "1"    "1"   "2"   "2"
[146,] "PERC-0537" "3" "14"  "MU"    "SW"   "F" "25119"    "13.33" "1"
"C"    "n"      "1"    "1"   "2"   "2"
[147,] "PERC-0537" "3" "15"  "MU"    "SW"   "F" "25119"    "13.75" "1"
"C"    "n"      "1"    "1"   "2"   "2"
[148,] "PERC-0547" "1" "2"   "HU"    "r"    "M" "135.78"   "1"     "3"
"C"    "n"      "3"    "1"   "0"   "0"
[149,] "PERC-0547" "1" "3"   "HU"    "r"    "M" "678.9"    "1"     "3"
"C"    "n"      "3"    "1"   "0"   "0"
[150,] "PERC-0547" "1" "4"   "HU"    "r"    "M" "1018.35"  "1"     "3"
"C"    "n"      "3"    "1"   "0"   "0"
[151,] "PERC-0547" "1" "5"   "HU"    "r"    "M" "135.78"   "3"     "3"
"C"    "n"      "3"    "1"   "0"   "0"
[152,] "PERC-0547" "1" "6"   "HU"    "r"    "M" "678.9"    "3"     "3"
"C"    "n"      "3"    "1"   "0"   "0"
[153,] "PERC-0547" "1" "7"   "HU"    "r"    "M" "1018.35"  "3"     "3"
"C"    "n"      "3"    "1"   "0"   "0"
[154,] "PERC-0547" "1" "8"   "HU"    "r"    "M" "135.78"   "7.5"   "4"
"C"    "n"      "4"    "1"   "0"   "0"
[155,] "PERC-0547" "1" "9"   "HU"    "r"    "M" "678.9"    "7.5"   "4"
"C"    "n"      "4"    "1"   "0"   "1"
[156,] "PERC-0547" "1" "10"  "HU"    "r"    "M" "1018.35"  "7.5"   "4"
"C"    "n"      "4"    "1"   "0"   "1"
[157,] "RFC-1633"  "1" "2"   "RT"    "SD"   "F" "1580"     "4"     "6"
"L"    "n"      "6"    "1"   "0"   "0"
[158,] "RFC-1633"  "1" "3"   "RT"    "SD"   "F" "3150"     "4"     "6"
"L"    "n"      "6"    "1"   "0"   "0"
[159,] "RFC-1633"  "1" "4"   "RT"    "SD"   "F" "6300"     "4"     "6"
"L"    "n"      "6"    "1"   "0"   "0"
[160,] "RFC-1633"  "1" "5"   "RT"    "SD"   "F" "12600"    "4"     "6"
"L"    "n"      "6"    "1"   "0"   "0"
[161,] "RFC-1633"  "1" "6"   "RT"    "SD"   "F" "25200"    "4"     "6"
"L"    "n"      "6"    "1"   "0"   "0"
[162,] "RFC-2109"  "1" "5"   "MU"    "SW"   "M" "4046"     "4"     "10"
"C"    "n"      "10"   "1"   "0"   "1"
[163,] "RFC-2109"  "1" "6"   "MU"    "SW"   "M" "4406"     "4"     "10"
"C"    "n"      "10"   "1"   "0"   "1"
[164,] "RFC-2109"  "1" "7"   "MU"    "SW"   "M" "4644"     "4"     "10"
"C"    "n"      "10"   "1"   "0"   "1"
[165,] "RFC-2109"  "1" "8"   "MU"    "SW"   "M" "5567"     "4"     "10"
"C"    "n"      "10"   "1"   "0"   "1"
[166,] "RFC-2431"  "1" "1"   "MU"    "r"    "B" "24630"    "0.02"  "10"
"C"    "n"      "10"   "1"   "0"   "1"
[167,] "RFC-2431"  "1" "2"   "MU"    "r"    "B" "24630"    "0.03"  "10"
"C"    "n"      "10"   "1"   "1"   "1"
[168,] "RFC-2431"  "1" "3"   "MU"    "r"    "B" "24630"    "0.05"  "10"
"C"    "n"      "10"   "1"   "1"   "1"
[169,] "RFC-2431"  "1" "4"   "MU"    "r"    "B" "24630"    "0.12"  "10"
"C"    "n"      "10"   "1"   "1"   "1"
[170,] "TOL-0178"  "2" "2"   "MU"    "NM"   "M" "616.67"   "0.25"  "27"
"C"    "n"      "27"   "1"   "1"   "1"
[171,] "TOL-0178"  "2" "3"   "MU"    "NM"   "M" "616.67"   "1"     "27"
"C"    "n"      "27"   "1"   "1"   "1"
[172,] "TOL-0178"  "2" "4"   "MU"    "NM"   "M" "2192.59"  "0.25"  "27"
"C"    "n"      "27"   "1"   "1"   "1"
[173,] "TOL-0178"  "2" "5"   "MU"    "NM"   "M" "2192.59"  "1"     "27"
"C"    "n"      "27"   "1"   "1"   "1"
[174,] "TOL-0178"  "2" "6"   "MU"    "NM"   "M" "24666.67" "0.25"  "14"
"C"    "n"      "14"   "1"   "1"   "1"
[175,] "TOL-0178"  "2" "7"   "MU"    "NM"   "M" "24666.67" "1"     "14"
"C"    "n"      "14"   "1"   "1"   "1"
[176,] "TOL-0178"  "2" "8"   "MU"    "NM"   "M" "2740.74"  "1"     "27"
"C"    "n"      "27"   "1"   "0"   "1"
[177,] "TOL-0178"  "2" "9"   "MU"    "NM"   "M" "4111.11"  "1"     "27"
"C"    "n"      "27"   "1"   "0"   "1"
[178,] "TOL-0178"  "2" "10"  "MU"    "NM"   "M" "5481.48"  "1"     "14"
"C"    "n"      "14"   "1"   "0"   "1"
[179,] "TOL-0178"  "2" "11"  "MU"    "NM"   "M" "8222.23"  "1"     "14"
"C"    "n"      "14"   "1"   "0"   "1"
[180,] "TOL-0178"  "2" "12"  "MU"    "NM"   "M" "12333.34" "1"     "14"
"C"    "n"      "14"   "1"   "0"   "1"

$excluded:
$excluded$names:
[1] "Species" "Target"

$excluded$"":
[1] "DG"

$excluded$"":
[1] "R"


$cluster.var:
[1] "Ref.id" "Exp"

$strata:
$strata$intercept:
[1] "Species" "Target"

$strata$conc:
[1] "Target"

$strata$time:
NULL


$xlog:
[1] "CT"

$link:
[1] "logit"

$gpcorr:
[1] 1

$missing.row:
numeric(0)

$zero.row:
 [1]   2   3   4  12  18  21  25  64  67 114 118 122 126 135 148 163 173
179 180 181 182 191

$infile:
[1] "perc.csv"




>

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help

------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message. If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.



From matej at ceplovi.cz  Wed Dec  4 02:13:02 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Wed Dec  4 02:13:02 2002
Subject: Plot optimization [Was: Re: [R] Plotting Speed: R vs Octave]
In-Reply-To: <Pine.LNX.4.44.0212031744040.1111-100000@bolker.zoo.ufl.edu>
Message-ID: <Pine.OSF.3.96.1021203201031.13160C-100000@lynx01.dac.neu.edu>

On Tue, 3 Dec 2002, Ben Bolker wrote:
>   It seems to make more sense to put a tiny bit of effort into
> thinning the points at your end rather than building code into
> R's postscript driver to deal with this case. 

I will have to study your code, but it seems to me, that such
problem can occur quite often, so that optimization-out of this
... well, I believe, bug ... could help a lot.

Matej



From Alexander.Herr at csiro.au  Wed Dec  4 02:15:05 2002
From: Alexander.Herr at csiro.au (Alexander.Herr@csiro.au)
Date: Wed Dec  4 02:15:05 2002
Subject: [R] use of offset - clarification
Message-ID: <2FE6D3D02CCDD211B80600902745F56C018D11DF@exchange-tv.tvl.qld.csiro.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021204/f64f0c8c/attachment.pl

From sutton at soc.ucsb.edu  Wed Dec  4 02:24:14 2002
From: sutton at soc.ucsb.edu (John Sutton)
Date: Wed Dec  4 02:24:14 2002
Subject: [R] R-Winedt
Message-ID: <5.1.0.14.0.20021203171554.00a05470@mail.lsit.ucsb.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021204/5ebb43f3/attachment.pl

From accot at almaden.ibm.com  Wed Dec  4 02:28:05 2002
From: accot at almaden.ibm.com (Johnny Accot)
Date: Wed Dec  4 02:28:05 2002
Subject: [R] R and DirectFB
Message-ID: <3DED59FC.9020805@almaden.ibm.com>

Hi,

I joined the mailing list yesterday and I am very pleased to hear about this SIG-GUI initiative.  Personally I have often thought about the UI aspects of R, but more in a "toolkit approach".  More precisely I wanted (but lacked time) to see if it is easy/possible to interface R with DirectFB (http://directfb.org) under Linux.  My dream would be to have R drive the whole framebuffer, using the Gtk port to DirecFB (http://directfb.org/gtk.xml) or a simple graphical toolkit written in R on top of DirectFB.  The new toolkit would have antialiasing and transparency capabilities, and would be much faster/simpler than its X counterpart.

Would anybody else be interested in such a thing?  Would you have an idea of the difficulty to interface R with DirectFB? (in particular in terms of event loop)

I would appreciate any comment or advice.

Thanks,

Johnny



From fharrell at virginia.edu  Wed Dec  4 04:34:03 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Wed Dec  4 04:34:03 2002
Subject: [R] Converting R help files to S-Plus 6 sgml,html
Message-ID: <20021203223346.33c85306.fharrell@virginia.edu>

I have help files in several formats.  Up until now I have converted nroff files to S-Plus 6 sgml and html files using 

 Splus doc_to_S ... (creates .sgml file)
 Splus HINSTALL ... (creates .sgm and .html files)

I maintain master help files in R .Rd files, and for some of my functions converting from .Rd to .sgm using R CMD Rdconv --type=Ssgm ... produces better .sgm files than beginning with the nroff files, as doc_to_s or HINSTALL can mess up help files with USAGE components showing more than one function invocation.  I think I can put the output of R CMD Rdconv directly into e.g. /usr/local/splus/library/foo/.Data/__Shelp/*.sgm.  But then I don't know how to create the html entry in /usr/local/splus/library/foo/.Data/__Hhelp/*.html.  Any help or corrections to my approach would be most appreciated.

Frank
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From petr.pikal at precheza.cz  Wed Dec  4 07:44:04 2002
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed Dec  4 07:44:04 2002
Subject: [R] terribly naive question
In-Reply-To: <3DED1951.6B589C05@noaa.gov>
Message-ID: <3DEDB1FA.12380.198791@localhost>


On 3 Dec 2002 at 15:51, Sonia Bauer wrote:

> Dear R-Representative:
> I am very new to R and I have to admit that I am not the cleverest of
> users.  So, please bear with me.  I have installed R on my Mac OS 8.6.
> I am interested in eventually using the packages -- many useful ones
> have been downloaded with the basic R software.  I have looked through
> some of the manuals, however, I have not yet found how to access the
> commands in these packages.  I am assuming there are ways to include
> the functions available in these packages in some kind of path.  I
> have used UNIX and I use my Mac mainly as a word processor, but would
> like to learn R on the Mac and perhaps later for research, possibly on
> a new Mac.  So, my question is, what kind of set up is required for me
> to use these packages? Sorry for such an inane question, but I've
> decided that you will be able to help me much more quickly than I am
> able to find what I need at this point. Thank you VERY MUCH.
> Sincerely, Sonia Bauer

On Windows you can access packages through 
menu/packages/load package

or

if you know the "name of the package"
by

library(name of the package)

By the way I *strongly recommend* to read "Introduction to R" 
or some other documentation (I presume already downloaded and 
stored in /doc path. You can find many of good sources from 
CRAN or through internet search eg.StatsRus, J.H.Maindonald's - 
Using R for data analysis...,.



Cheers


Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz



From ripley at stats.ox.ac.uk  Wed Dec  4 08:18:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Dec  4 08:18:03 2002
Subject: [R] use of offset - clarification
In-Reply-To: <2FE6D3D02CCDD211B80600902745F56C018D11DF@exchange-tv.tvl.qld.csiro.au>
Message-ID: <Pine.LNX.4.31.0212040712320.5666-100000@gannet.stats>

On Wed, 4 Dec 2002 Alexander.Herr at csiro.au wrote:

> seems I have forgotten some basics re offset in glm:
>
> data:
> counts (y) from locations off different size (area),
> explanatory variable: x
>
> Model:
> y ~ x+offset(area)
> Predictions (pred) using Poisson errors
>
> plot(x,y) and points(x,pred) gives neat "line" of estimated values.
>
> However, for ease of understanding graphs are better using plot(x,y/area).
>
> Question:
> How to display predictions from the model in the graph (using y/area)?
> Plot(x,y/area) with points(x,pred/area) does not give neat line; predicted
> values are varying throughout the graph.
>
> My understanding was that offset(area) using glm on poisson constraints
> model by area, so pred/area should do the job.
>
> What am I doing wrong, can anyone please clarify?

It's a log-linear model, so the offset should be log(area).  The model is

log(E(y)) = beta_0 + beta_1 x + area

and you want

log(E(y)) = beta_0 + beta_1 x + log(area)

so

E(y) = area x exp(beta_0 + beta_1 x)


See
library(MASS)
?Insurance

for an example.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From TyagiAnupam at aol.com  Wed Dec  4 08:27:04 2002
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Wed Dec  4 08:27:04 2002
Subject: [R] terribly naive question
Message-ID: <6c.269d6011.2b1f077a@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021204/3bccd926/attachment.pl

From ripley at stats.ox.ac.uk  Wed Dec  4 08:35:15 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Dec  4 08:35:15 2002
Subject: Plot optimization [Was: Re: [R] Plotting Speed: R vs Octave]
In-Reply-To: <Pine.OSF.3.96.1021203201031.13160C-100000@lynx01.dac.neu.edu>
Message-ID: <Pine.LNX.4.31.0212040724490.5666-100000@gannet.stats>

On Tue, 3 Dec 2002, Matej Cepl wrote:

> On Tue, 3 Dec 2002, Ben Bolker wrote:
> >   It seems to make more sense to put a tiny bit of effort into
> > thinning the points at your end rather than building code into
> > R's postscript driver to deal with this case.
>
> I will have to study your code, but it seems to me, that such
> problem can occur quite often, so that optimization-out of this
> ... well, I believe, bug ... could help a lot.

Plotting the points you asked for is not a bug: please read the FAQ
about BUGS.  It is not often that users are careless enough to plot
duplicated points many times.  The issue would apply to all drivers, not
just postscript().

It's also not easy to do in the driver: suppose the points were of
different colours?  The postscript rules are of opaque paint, so the last
one wins.  It would be necessary to cache all the points, delete the
earliest ones and then plot them.  Why don't you write an R program to
post-process the .ps output if this bothers you?

Recently one of my students plotted a scatterplot with 1.4m points on. I
couldn't print the PDF from Linux (a 135Mb file) although he could from
Windows (on the same printer which has 96Mb of memory in).  We didn't
report this as a bug in R (and there were no exact duplicates), rather
came up with a statistical way of thinning the points (by forming a
density estimate and thinning the points back to a maximum density).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed Dec  4 08:49:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Dec  4 08:49:03 2002
Subject: [R] Re: [S] Converting R help files to S-Plus 6 sgml,html
In-Reply-To: <20021203223346.33c85306.fharrell@virginia.edu>
Message-ID: <Pine.LNX.4.31.0212040742320.5666-100000@gannet.stats>

On Tue, 3 Dec 2002, Frank E Harrell Jr wrote:

> I have help files in several formats.  Up until now I have converted nroff files to S-Plus 6 sgml and html files using
>
>  Splus doc_to_S ... (creates .sgml file)
>  Splus HINSTALL ... (creates .sgm and .html files)
>
> I maintain master help files in R .Rd files, and for some of my
functions converting from .Rd to .sgm using R CMD Rdconv --type=Ssgm ...
produces better .sgm files than beginning with the nroff files,
as doc_to_s or HINSTALL can mess up help files with USAGE components
showing more than one function invocation.  I think I can put the output
of R CMD Rdconv directly into e.g.
/usr/local/splus/library/foo/.Data/__Shelp/*.sgm.  But then I don't
know how to create the html entry in
/usr/local/splus/library/foo/.Data/__Hhelp/*.html.
Any help or corrections to my approach would be most appreciated.

Which version of S-PLUS?  For 6.x you should be producing .sgml files.
If you do that,  Splus CHAPTER; Splus MAKE will install them for you
and do all the post-processing.  If not,

Splus make HELPSGML=*.sgml install.help

will do the trick.

Note

(i) the files must be .sgml
(ii) they must be in the top-level directory of the chapter.

I have given up trying to maintain common masters for R/S: I now keep
.Rd and .sgml separately.  Although the .Rd->.sgml conversion works
better than .d->.sgml, the possible markup in .Rd and .sgml is not
the same.

Brian

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed Dec  4 09:10:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Dec  4 09:10:03 2002
Subject: [R] terribly naive question
In-Reply-To: <6c.269d6011.2b1f077a@aol.com>
Message-ID: <Pine.LNX.4.31.0212040806230.5666-100000@gannet.stats>

On Wed, 4 Dec 2002 TyagiAnupam at aol.com wrote:

> The Hmisc and Design libraries also have some useful functions, especially
> for data management.  The Intro to S-plus by Alzola and Harrell is quite
> direct and user-friendly. You can find this at:
>
> http://hesweb1.med.virginia.edu/biostat/s/splus.html

Those packages are not available for classic MacOS, though, as I read that
site.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Wed Dec  4 09:44:02 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Dec  4 09:44:02 2002
Subject: [R] R-Winedt
References: <5.1.0.14.0.20021203171554.00a05470@mail.lsit.ucsb.edu>
Message-ID: <3DEDC049.A4FB451C@statistik.uni-dortmund.de>

John Sutton wrote:
> 
> Hello:
> 
> I installed R-WinEdit according to the instructions, including those for
> setting
>   the editor and pager options. Doesn't seem to work--when I try to edit a
> file, I get the following:
> 
> > > options(editor="\"c:/program files/winedt/winedt\" -c=\"R-WinEdt-edit\"
> > -e=r.ini -V")
> > > getOption("editor")
> >[1] "\"c:/program files/winedt/winedt\" -c=\"R-WinEdt-edit\" -e=r.ini -V"
> > > edit ("Multi1.R")
> >Error in edit(name, file, editor) : unable to run editor "c:/program
> >files/winedt/winedt" -c="R-WinEdt-edit" -e=r.ini -V
> 
> Got any advice?

1. First of all, I'd suggest to start the Editor not from R, but from a
shortcut (e.g. in your startmenu or on the desktop) to edit files.

2. edit("Multi1.R") won't work, see ?edit for details.

3. It seems to be required to specify the extension in some windows
versions, e.g.:
"\"c:/program files/winedt/winedt.exe\" -c=\"R-WinEdt-edit\" -e=r.ini
-V"

4. Are you sure WinEdt is installed in the specified directory?

5. In case of any further questions, please 
 a) post a private message - I don't think R-WinEdt is of interest for
the majority on this list.
 b) Tell us (me) some details 
  (i)   Version numbers of: R, Windows, WinEdt, R-WinEdt
  (ii)  Where does WinEdt live?


Uwe Ligges



From maechler at stat.math.ethz.ch  Wed Dec  4 11:21:02 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed Dec  4 11:21:02 2002
Subject: [R] R-help moved to mailman
In-Reply-To: <3DECDFA4.3DD4287B@umsanet.edu.bo>
References: <15851.10524.314512.404704@gargle.gargle.HOWL>
	<3DECDFA4.3DD4287B@umsanet.edu.bo>
Message-ID: <15853.55001.40500.66876@gargle.gargle.HOWL>

>>>>> "kjetil" == kjetil halvorsen <kjetilh at umsanet.edu.bo>
>>>>>     on Tue, 03 Dec 2002 12:45:24 -0400 writes:

    kjetil> Hola!  The R home page have a mailing list page,
    kjetil> which dowesnt seem to be up-to-date whit respect to
    kjetil> this new system. Maybe it should refer to the web
    kjetil> page given below?

It (http://www.R-project.org/mail.html)  *does* for about two
days now.  You must have gotten an old cache or something like
that. 

Martin Maechler



From rggefrm at ucl.ac.uk  Wed Dec  4 11:54:03 2002
From: rggefrm at ucl.ac.uk (Frank Mattes)
Date: Wed Dec  4 11:54:03 2002
Subject: [R] compiling R under hp-ux 10.20
Message-ID: <5.2.0.9.1.20021204104736.00a58180@pop-server.ucl.ac.uk>

Dear R user/ developer,

I'm wondering if anyone has already compiled R 1.6.1 for hp-ux. I tried in 
the past (with version 1.3) and haven't had mutch success.
I'm very interested to hear any comments.

Many thanks

Frank
Frank Mattes, MD
Dpartment of Virology
Royal Free and University Medical School
London



From Virgilio.Gomez at uv.es  Wed Dec  4 13:38:03 2002
From: Virgilio.Gomez at uv.es (Virgilio.Gomez@uv.es)
Date: Wed Dec  4 13:38:03 2002
Subject: [R] RArcInfo 0.4-2 and tutorial (draft) available
Message-ID: <9334881574virgil@uv.es>

Hi,

 A new release of RArcInfo is avaialable from CRAN and
http://matheron.uv.es/~virgil/Rpackages/RArcInfo/

The changes made are:

*V 0.4-2
	- 'index' argument added to plotarc to select the arcs to plot.
	- 'index' argument added to plotpal to select the polygons to plot.
	- New function 'get.nb', which, given a set of polygons, returns
	the neighbouring polygons of each one.
	- Fixed a bug in 'get_tol_data'. The file to be open was of
	type CNT instead of TOL. Now tolerances are read without problems.
	- Output messages have been changed in several functions to
	be more useful for the user.
	- Fixed a bug in 'plotarc' when calculating plot dimensions.
	- Example added to RArcInfo documentation file.

Besides, I am proud to announce that a draf of the RArcInfo tutorial
is now available from http://matheron.uv.es/~virgil/Rpackages/RArcInfo/

I am looking forward to your comments.

REgards,

VIrgilio



From maechler at stat.math.ethz.ch  Wed Dec  4 14:08:06 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed Dec  4 14:08:06 2002
Subject: [R] Re: Mailman password for R-help (and R-*) mailing lists?
In-Reply-To: <s5rruu0pmtrr0dlqju0deglpdm36r6clr2@4ax.com>
References: <s5rruu0pmtrr0dlqju0deglpdm36r6clr2@4ax.com>
Message-ID: <15853.65026.935207.75889@gargle.gargle.HOWL>

I'm forwarding this to R-help since it might be of wider
interest.  I'm glad for your mail, Duncan!

>>>>> "Duncan" == Duncan Murdoch <dmurdoch at pair.com>
>>>>>     on Wed, 04 Dec 2002 06:55:09 -0500 writes:

    Duncan> Hi Martin.  I don't think my mailman password was
    Duncan> mailed to me.

Indeed, it wasn't. I was wrong there.  
It *is* done monthly for *all* mailing lists that haven't
disabled it -- but I missed that date by a few hours.

    Duncan>   Is there a way to ask it to (re)send?

yes.  At the very bottom of the web interface page,
   https://www.stat.math.ethz.ch/mailman/listinfo/r-help
it says

  >>  To change your subscription (set options like digest and
  >>  delivery modes, get a reminder of your password, or
  >>  unsubscribe from R-help), enter your subscription email
  >>  address:

do so and you will ...


    Duncan> This will likely be an issue again in 3 weeks when
    Duncan> people want to suspend their subscriptions for the
    Duncan> holiday, and have forgotten their passwords.

(why should they suspend? if everyone is in holidays, there's
 not much traffic ... ;-) :-)

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From Virgilio.Gomez at uv.es  Wed Dec  4 14:17:03 2002
From: Virgilio.Gomez at uv.es (Virgilio =?ISO-8859-1?Q?G=F3mez?= Rubio)
Date: Wed Dec  4 14:17:03 2002
Subject: [R] RArcInfo 0.4-2 and draft tutorial out
Message-ID: <1039007690.672.10.camel@chomsky>

Hi,

A new release of RArcInfo is out, together with a draft of the tutorial.
You can get both from
http://matheron.estadi.uv.es/~virgil/Rpackages/RArcInfo
Windows binaries are also available and package source can also be
downloaded from CRAN.

I 'd like to encourage users of the package to read the tutorial and
report ideas. Besides, I would like to keep a web page on works where
RArcInfo is being used.

Changes made are:

*V 0.4-2
        - 'index' argument added to plotarc to select the arcs to plot.
        - 'index' argument added to plotpal to select the polygons to
plot.
        - New function 'get.nb', which, given a set of polygons, returns
        the neighbouring polygons of each one.
        - Fixed a bug in 'get_tol_data'. The file to be open was of
        type CNT instead of TOL. Now tolerances are read without
problems.
        - Output messages have been changed in several functions to
        be more useful for the user.
        - Fixed a bug in 'plotarc' when calculating plot dimensions.
        - Example added to RArcInfo documentation file.



Comments are welcome.

Regards and enjoy,

-- 
             Virgilio G?mez Rubio

Dpto. Estad?stica e I. O. - Facultat de Matem?tiques
Avda. Vicent A. Estell?s, 1 - 46100 Burjassot
Valencia - SPAIN

http://matheron.uv.es/~virgil

TLF: 00 34 96 354 43 62 - FAX: 00 34 96 354 47 35



From david.meyer at ci.tuwien.ac.at  Wed Dec  4 14:34:02 2002
From: david.meyer at ci.tuwien.ac.at (David Meyer)
Date: Wed Dec  4 14:34:02 2002
Subject: [R] compiling R under hp-ux 10.20
References: <5.2.0.9.1.20021204104736.00a58180@pop-server.ucl.ac.uk>
Message-ID: <3DEE03D7.2094604A@ci.tuwien.ac.at>

Frank Mattes wrote:
> 
> Dear R user/ developer,
> 
> I'm wondering if anyone has already compiled R 1.6.1 for hp-ux. I tried in
> the past (with version 1.3)

this is rather outdated...

> and haven't had mutch success.

I had. What exactly goes wrong (using a current version)?

-d



From AlessandroSemeria at cramont.it  Wed Dec  4 15:13:05 2002
From: AlessandroSemeria at cramont.it (AlessandroSemeria@cramont.it)
Date: Wed Dec  4 15:13:05 2002
Subject: [R] gene ontology association
Message-ID: <OF75F2172B.AFD06BBD-ONC1256C85.004A3415@tomware.it>

My file come from features extraction sw Agilent and I forgot to say in
previous message that I have the sistematic name too (i.e. gene name
recognized from GenBank), what you means with "mapping"?

Thanks!

Best!
A. S.
----------------------------
Sincerely yours.
|------------------------------------+------------------------------------|
|Alessandro Semeria                  |Tel. +39 544 536811                 |
|------------------------------------+------------------------------------|
|Models and Simulation Laboratory    |Fax. +39 544 538663                 |
|------------------------------------+------------------------------------|
|The Environment Research Center -   |                                    |
|Montecatini (Edison Group),    Via  |                                    |
|Ciro Menotti 48,                    |E-mail: asemeria at cramont.it         |
|48023 Marina di Ravenna (RA), Italy |                                    |
|------------------------------------+------------------------------------|



From uehara_hideaki at mail.tsumura.co.jp  Wed Dec  4 16:42:05 2002
From: uehara_hideaki at mail.tsumura.co.jp (=?iso-2022-jp?B?GyRCPmU4Nj0oPjwbKEI=?=)
Date: Wed Dec  4 16:42:05 2002
Subject: [R] compiling R under hp-ux 10.20
References: <20021204110012.14931.1125.Mailman@hypatia.math.ethz.ch>
Message-ID: <3DEE234A.8EC8A6C5@mail.tsumura.co.jp>

Hi,

I tried it too. It seems to be working.
> version
  _
  platform hppa1.1-hp-hpux10.20
  arch     hppa1.1
  os       hpux10.20
  system   hppa1.1, hpux10.20
  status
  major    1
  minor    6.1
  year     2002
  month    11
  day      01
  language R

However, the result was not very successful.
By now I have kept two problems left unsolved:

1. Testing after "make"failed.

2. Unable to load the library cluster:
 > library(cluster)
Loading required package: mva
Error in dyn.load(x, as.logical(local), as.logical(now)) :
unable to load shared library "/usr/local/lib/R/library/cluster/libs/cluster.sl":
can't open /usr/local/lib/R/library/cluster/libs/cluster.sl
Error in library(cluster) : .First.lib failed
>
I did not realize any trouble during the compilation of the library.

Best regards,

Hideaki Uehara
Biostatistics Group
Medical Development Dept I.
Development Division
Tsumura & Co.



From cyoo at uiuc.edu  Wed Dec  4 18:11:05 2002
From: cyoo at uiuc.edu (Chris Yoo)
Date: Wed Dec  4 18:11:05 2002
Subject: [R] Date: Wed, 27 Nov 2002 09:23:31 -0600
In-Reply-To: <LMEKLMMLPDKOJNOOEELEAEMFDNAA.carlos.ortega@minorplanet.com>
Message-ID: <NGEOJFABIMCKFOGIDNBPEECOCCAA.cyoo@uiuc.edu>

As for the R memory problem I posted, I discussed it with a consultant but
we could not find solution.

Can anyone possibly answer this question?

As I told you briefly, I have a large data set (1017 Mb and about3,600 kb in
csv format). The data contains 14,013 rows (observation) and 44 columns.
I am using Dell Notebook I8000 (got it last year). It has 251,600 KB RAM and
C-drive where R folder is attached has 13.5GB free space.


I am able to read the data but whenever I try the following, I got error
message.

> test <- lm(d.tdc2~d.mktval)
>Error: cannot allocate vector of size 1017272 Kb
>In addition: Warning message:
>Reached total allocation of 1000Mb: see help(memory.size)
>>

I even tried to increase memory assigned by doing

> memory.limit(2000)
NULL
> test <- lm(d.tdc2~d.mktval)
Error: cannot allocate vector of size 1017272 Kb
> memory.limit(3000)
NULL
> test <- lm(d.tdc2~d.mktval)
Error: cannot allocate vector of size 1017272 Kb
>

I also tried
TARGET C:\R\rw1061\bin\Rgui.exe --max-mem-size=2G

Thanks a lot,

Chris

-----Original Message-----



From Z.Cui at bham.ac.uk  Wed Dec  4 18:31:03 2002
From: Z.Cui at bham.ac.uk (Z Cui)
Date: Wed Dec  4 18:31:03 2002
Subject: [R] Help: add arrows on a filled.contour figure
Message-ID: <1039023050.a9460c00Z.Cui@bham.ac.uk>

Dear All

I would like to use filled.contour to plot something with arrows on it. I did it in this way:

filled.contour(1:nx,1:nz,u,col=gray(rev((0:20/20))))
for (j in zseq ) for (i in xseq) arrows(i, j, i+u[i,j],j+w[i,j],length=angleng,angle=angarrow,code=2, lwd=1,col="black")

The peoblem is that the arrows use the whole device area, including the key on the right hand side of the filled contour. Does anyone know how to work out this problem?

Many thanks for your kind reply.
Dr Zhiqiang Cui
School of Geography and Environmental Sciences
The University of Birmingham
Edgbaston, Birmingham
B15 2TT



From ripley at stats.ox.ac.uk  Wed Dec  4 18:57:02 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Dec  4 18:57:02 2002
Subject: [R] Date: Wed, 27 Nov 2002 09:23:31 -0600
In-Reply-To: <NGEOJFABIMCKFOGIDNBPEECOCCAA.cyoo@uiuc.edu>
Message-ID: <Pine.LNX.4.31.0212041750390.26261-100000@gannet.stats>

You could try reading the rw-FAQ:  --max-mem-size=2G won't work, but
something like 1700M might.  But on a 256Mb machine this is not much
point.

I successfully did a regression of that size in 42Mb.  Something is wrong.
Maybe the `columns' are factors with vast numbers of levels, for example.
You really haven't told us anything like enough to go on.

On Wed, 4 Dec 2002, Chris Yoo wrote:

> As for the R memory problem I posted, I discussed it with a consultant but
> we could not find solution.
>
> Can anyone possibly answer this question?
>
> As I told you briefly, I have a large data set (1017 Mb and about3,600 kb in
> csv format). The data contains 14,013 rows (observation) and 44 columns.
> I am using Dell Notebook I8000 (got it last year). It has 251,600 KB RAM and
> C-drive where R folder is attached has 13.5GB free space.
>
>
> I am able to read the data but whenever I try the following, I got error
> message.
>
> > test <- lm(d.tdc2~d.mktval)
> >Error: cannot allocate vector of size 1017272 Kb
> >In addition: Warning message:
> >Reached total allocation of 1000Mb: see help(memory.size)
> >>
>
> I even tried to increase memory assigned by doing
>
> > memory.limit(2000)
> NULL
> > test <- lm(d.tdc2~d.mktval)
> Error: cannot allocate vector of size 1017272 Kb
> > memory.limit(3000)
> NULL
> > test <- lm(d.tdc2~d.mktval)
> Error: cannot allocate vector of size 1017272 Kb
> >
>
> I also tried
> TARGET C:\R\rw1061\bin\Rgui.exe --max-mem-size=2G
>
> Thanks a lot,
>
> Chris
>
> -----Original Message-----
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From matej at ceplovi.cz  Wed Dec  4 19:28:04 2002
From: matej at ceplovi.cz (Matej Cepl)
Date: Wed Dec  4 19:28:04 2002
Subject: Plot optimization [Was: Re: [R] Plotting Speed: R vs Octave]
In-Reply-To: <Pine.LNX.4.31.0212040724490.5666-100000@gannet.stats>
References: <Pine.OSF.3.96.1021203201031.13160C-100000@lynx01.dac.neu.edu> <Pine.LNX.4.31.0212040724490.5666-100000@gannet.stats>
Message-ID: <20021204181514.GC20458@komensky.surfbest.net>

ripley at stats.ox.ac.uk wrote:
> > I will have to study your code, but it seems to me, that such
> > problem can occur quite often, so that optimization-out of
> > this ... well, I believe, bug ... could help a lot.
> 
> Plotting the points you asked for is not a bug: please read the
> FAQ about BUGS.

I know what bugs are (undocumented features :-), and that is the
reason why I have not filed it as bugreport, but to this list in
so hesitating way as I did.

> It is not often that users are careless enough to plot
> duplicated points many times.

Well, what I tried to say is that I do not think, that this
problem affects only careless users. I believe that pairs is best
exactly on very unprocessed raw data in multiple variables.
However, it may be fair to say, that pairs should be used only
for intial observations (with X11 driver, where I have no
problems with the size and complexity) and it should not be
published in the paper.

> The issue would apply to all drivers, not just postscript().

Actually, not exactly, because in bitmap-based drivers (X11, png,
jpeg) there is optimization done in hard way by the nature of the
bitmap pictures -- previous point just vanishes.

Have a nice day,

	Matej

-- 
Matej Cepl, matej at ceplovi.cz,
Finger: 89EF 4BC6 288A BF43 1BAB  25C3 E09F EF25 D964 84AC
138 Highland Ave. #10, Somerville, Ma 02143, (617) 623-1488
 
We are told that [St. Anthony] once fell into dejection, finding
uninterrupted contemplation above his strength; but was taught to
apply himself at intervals to manual labour by a vision of an
angel who appeared platting mats of palm-tree leaves, then rising
to pray, and after some time sitting down again to work; and who
at length said to him, "Do thus, and thou shalt be saved."
    -- Life of St. Anthony



From f0z6305 at labs.tamu.edu  Wed Dec  4 20:23:02 2002
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Wed Dec  4 20:23:02 2002
Subject: [R] Mixture of Multivariate Gaussian Sample Data
Message-ID: <00a901c29bca$74f50930$8bd75ba5@IE.TAMU.EDU>

Hey, I am confused about how to generate the sample data from a mixture of
Multivariate Gaussian ditribution.
For example, there are 2 component Gaussian with prior
probability of 0.4 and 0.6,
the means and variances are
u1=[1 1]', Cov1=[1 0;0 1]
and
u2=[-1 -1]', Cov2=[1 0;0 1]
repectively.

So how can I generate a sample of 500 data from the above mixture
distribution?

Thanks.

Fred



From D.Freiberg at t-online.de  Wed Dec  4 20:46:06 2002
From: D.Freiberg at t-online.de (Roland Goecke)
Date: Wed Dec  4 20:46:06 2002
Subject: [R] Interpreting canonical correlation (cancor) results
Message-ID: <3DEE5B50.6080001@t-online.de>

Hi,

from what I understand about the canonical correlation function 
'cancor', it looks for correlations in two sets of variables, each 
represented in matrix form. Right? Sounds exactly like what I need.

I have tried the following but I am not sure how to interpret the results.

AudioPCs <- c(ArTHarF0PCA$x[,2], ArTHarF1PCA$x[,2], ArTHarF2PCA$x[,2], 
ArTHarF3PCA$x[,2], ArTHarRMSPCA$x[,2])
VideoPCs <- c(ArTHarHeightPCA$x[,2], ArTHarWidthPCA$x[,2], 
ArTHarProUpperPCA$x[,2], ArTHarProLowerPCA$x[,2], ArTHarRelTeethPCA$x[,2])

AudioMatrix <- matrix(AudioPCs, nrow=20, ncol=5)
VideoMatrix <- matrix(VideoPCs, nrow=20, ncol=5)

ArTHarCCA <- cancor(AudioMatrix, VideoMatrix)
ArTHarCCA
$cor
[1] 0.852092 0.833079 0.467436 0.279688 0.026228

$xcoef
            [,1]       [,2]      [,3]       [,4]      [,5]
[1,] -0.0118794  0.0305097 -0.058891 -0.0601489  0.029186
[2,] -0.0350698  0.0163593  0.086743  0.0642735  0.100922
[3,]  0.1228351  0.0035069 -0.061669 -0.0019221  0.047723
[4,] -0.0461149  0.0186040  0.057543 -0.0649049 -0.132400
[5,] -0.0021663 -0.0624439  0.071591 -0.0457682  0.029516

$ycoef
           [,1]      [,2]      [,3]       [,4]      [,5]
[1,] -0.018006 -0.074138 -0.038670  0.0072364  0.082370
[2,] -0.293414 -0.176453 -0.015322 -0.0111357 -0.072555
[3,]  0.179000  0.048471 -0.103974  0.3313531 -0.049797
[4,] -0.126606 -0.088371  0.214449 -0.2998246  0.063524
[5,]  0.133073  0.011817 -0.073828 -0.0278944 -0.081489

$xcenter
[1]  1.9984e-16  2.2177e-15 -7.5495e-16 -2.6312e-15  1.5543e-16

$ycenter
[1] -5.5511e-17  1.4683e-15 -3.1086e-16 -1.9984e-16 -3.5527e-16


So in this example, I took the second principal components each from a 
bunch of variables, stuck them together in matrices and then performed 
CCA on it.

The results tell me that the correlation for two variables was quite 
high 0.85 and 0.83 but how do I know which variables these actually are? 
I mean the correlation values are always given in order from highest to 
lowest, so that is not much help.

How can I find something like that? Or is all I can get out of this that 
there is a linear combination of the parameters of set 1 that is well 
correlated to the parameters of set 2?

Cheers
Roland



From ben at zoo.ufl.edu  Wed Dec  4 20:49:03 2002
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Wed Dec  4 20:49:03 2002
Subject: [R] Mixture of Multivariate Gaussian Sample Data
In-Reply-To: <00a901c29bca$74f50930$8bd75ba5@IE.TAMU.EDU>
Message-ID: <Pine.LNX.4.44.0212041443230.2677-100000@bolker.zoo.ufl.edu>

  Your problem is actually very simple since your variables are all
uncorrelated (diagonal covariance matrices), so you don't really need to
treat it as a multivariate problem, *but* -- assuming you will need to do 
this for correlated variables sometime ...
 
  You need the mvrnorm() command from the MASS library.
  This solution is slightly complicated in an attempt to come up with an 
efficient answer ...

library(MASS)
S1 <- matrix(c(1,0,0,1),nrow=2,byrow=TRUE)
mu1 <- c(1,1)
S2 <- matrix(c(1,0,0,1),nrow=2,byrow=TRUE)
mu2 <- c(-1,-1)

n <- 500
p1 <- 0.4
n1 <- rbinom(1,size=n,prob=p1)  ## how many from first distribution?
n2 <- n-n1
val1 <- mvrnorm(n1,mu=mu1,Sigma=S1)
val2 <- mvrnorm(n2,mu=mu2,Sigma=S2)
allval <- rbind(val1,val2)      ## combine
allval <- allval[sample(n,n),]  ## scramble order



On Wed, 4 Dec 2002, Feng Zhang wrote:

> Hey, I am confused about how to generate the sample data from a mixture of
> Multivariate Gaussian ditribution.
> For example, there are 2 component Gaussian with prior
> probability of 0.4 and 0.6,
> the means and variances are
> u1=[1 1]', Cov1=[1 0;0 1]
> and
> u2=[-1 -1]', Cov2=[1 0;0 1]
> repectively.
> 
> So how can I generate a sample of 500 data from the above mixture
> distribution?
> 
> Thanks.
> 
> Fred
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From jacksragingvileduct at hotmail.com  Wed Dec  4 21:24:03 2002
From: jacksragingvileduct at hotmail.com (Bleh Blah)
Date: Wed Dec  4 21:24:03 2002
Subject: [R] Getting Break Points From Hist Function?
Message-ID: <F171CjOYX6XsXGqbh8o000092eb@hotmail.com>

Is there any way to extract the break points from a hist function as a 
vector so I can later use them for a cut function?

The ultimate goal is to make a frequency table of the data with the same 
break points that were used in the histogram.

Thank you in advance.

-Brian

_________________________________________________________________
MSN 8 helps eliminate e-mail viruses. Get 2 months FREE*.



From fpgibson at umich.edu  Wed Dec  4 22:57:02 2002
From: fpgibson at umich.edu (Bud Gibson)
Date: Wed Dec  4 22:57:02 2002
Subject: [R] bug in lattice xyplot key
Message-ID: <3DEE7A0E.3070704@umich.edu>

Hi:

I am running lattice 0.6-6 with grid 0.7-2 on RH 7.3 using the binary 
version of R 1.6.1 from CRAN.  If I use a key with lines in it, anytime 
I try to set the line type, it causes R to segfault.  Here is the 
simplest lines key code that will do it:

        key=list(corner = c(0,0), x = .16, y = .65,
          text = list(levels(data[[groupName]]), cex = 1.2),
          points = list(pch=c(mylty[1:length(levels(data[[groupName]])) 
- 1])),
          lines = list(type="b")
           )

Lines will work, setting the type does not.  Here is the R exception:

Process R floating point exception at Wed Dec  4 15:48:46 2002

Any help appreciated.

Thanks,
Bud



From jbwu at pangea.stanford.edu  Wed Dec  4 23:00:07 2002
From: jbwu at pangea.stanford.edu (jbwu)
Date: Wed Dec  4 23:00:07 2002
Subject: [R] for help!
Message-ID: <5.1.1.5.2.20021204135346.042fee30@pangea.stanford.edu>

hi, Guys:
Now I am trying to use "R" to do some canonical analysis on large data sets,
one of them is 42MB, and can be read by "R", the other data file is about 90MB,
and this time R cannot read such a big size data. My question is that how can
I deal with such a big dataset with "R", or are there any other statistical 
softwares
which can read a huge data file as I memtioned?

Thank you
Jianbing



From york at noaa.gov  Wed Dec  4 23:03:02 2002
From: york at noaa.gov (Anne York)
Date: Wed Dec  4 23:03:02 2002
Subject: [R] using edit.data.frame
Message-ID: <Pine.GSO.4.05.10212041346070.28997-100000@ofis450a.akctr.noaa.gov>

dum is a simple data frame transferred to Splus using the dump() 
command in Splus and the source() in R. All fields are numeric. There
are no missing data. The data frame looks like it is should:

> apply(dum,2,mode)
     yrcl     sland       s02      s234 
"numeric" "numeric" "numeric" "numeric" 
> apply(dum,2,is.vector)
 yrcl sland   s02  s234 
 TRUE  TRUE  TRUE  TRUE 
> is.data.frame(dum)
[1] TRUE

But, when I try to use the edit.data.frame command, 

> edit.data.frame(dum)
Error in edit.data.frame(dum) : Can only handle vector and factor elements
> 

Any ideas why this won't work?

Anne

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Anne E. York
National Marine Mammal Laboratory
Seattle WA 98115-0070  USA
e-mail: anne.york at noaa.gov
Voice: +1 206-526-4039
Fax: +1 206-526-6615
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From york at noaa.gov  Wed Dec  4 23:26:03 2002
From: york at noaa.gov (Anne York)
Date: Wed Dec  4 23:26:03 2002
Subject: [R] using edit.data.frame
In-Reply-To: <x2smxdjump.fsf@biostat.ku.dk>
Message-ID: <Pine.GSO.4.05.10212041420400.389-100000@ofis450a.akctr.noaa.gov>

THanks very much.  str() gives me the info that two of the columns are
actually time-series. So, applying as.numeric to the offending columns 
allows the editor to work.

Anne

> summary(dum)
      yrcl           sland             s02              s234       
 Min.   :50.00   Min.   :0.7820   Min.   :0.1780   Min.   :0.6350  
 1st Qu.:57.25   1st Qu.:0.8390   1st Qu.:0.3260   1st Qu.:0.8033  
 Median :64.50   Median :0.9000   Median :0.3835   Median :0.8480  
 Mean   :64.50   Mean   :0.8853   Mean   :0.3767   Mean   :0.8390  
 3rd Qu.:71.75   3rd Qu.:0.9255   3rd Qu.:0.4208   3rd Qu.:0.8758  
 Max.   :79.00   Max.   :0.9740   Max.   :0.4930   Max.   :0.9220  
> 
> str(dum)
`data.frame':   30 obs. of  4 variables:
 $ yrcl : num  50 51 52 53 54 55 56 57 58 59 ...
 $ sland: Time-Series  from 1950 to 1979: 0.882 0.842 0.907 0.824 0.786 ...
 $ s02  : Time-Series  from 1950 to 1979: 0.413 0.421 0.457 0.383 0.297
0.326 0.178 0.366 0.493 0.433 ...
 $ s234 : num  0.850 0.873 0.922 0.804 0.742 ...
> 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Anne E. York
National Marine Mammal Laboratory
Seattle WA 98115-0070  USA
e-mail: anne.york at noaa.gov
Voice: +1 206-526-4039
Fax: +1 206-526-6615
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

On 4 Dec 2002, Peter Dalgaard BSA wrote:

|Anne York <york at noaa.gov> writes:
|
|> dum is a simple data frame transferred to Splus using the dump() 
|> command in Splus and the source() in R. All fields are numeric. There
|> are no missing data. The data frame looks like it is should:
|> 
|> > apply(dum,2,mode)
|>      yrcl     sland       s02      s234 
|> "numeric" "numeric" "numeric" "numeric" 
|> > apply(dum,2,is.vector)
|>  yrcl sland   s02  s234 
|>  TRUE  TRUE  TRUE  TRUE 
|> > is.data.frame(dum)
|> [1] TRUE
|> 
|> But, when I try to use the edit.data.frame command, 
|> 
|> > edit.data.frame(dum)
|> Error in edit.data.frame(dum) : Can only handle vector and factor elements
|> > 
|> 
|> Any ideas why this won't work?
|
|Not really, but what do you get from
|
|str(dum)
|summary(dum)
|lapply(dum, mode) # suspect that apply(dum, 2, mode) isn't quite the same
|lapply(dum, class)
|
|?
|-- 
|   O__  ---- Peter Dalgaard             Blegdamsvej 3  
|  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
| (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
|~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
|



From rpeng at stat.ucla.edu  Wed Dec  4 23:29:02 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Wed Dec  4 23:29:02 2002
Subject: [R] Help: add arrows on a filled.contour figure
In-Reply-To: <1039023050.a9460c00Z.Cui@bham.ac.uk>
Message-ID: <Pine.GSO.4.10.10212041424310.22416-100000@fisher.stat.ucla.edu>

You need to use the 'plot.axes' argument.  See the help page.

Try this:

filled.contour(1:nx,1:nz,u,col=gray(rev((0:20/20))), plot.axes = { for (j
in zseq ) for (i in xseq)
arrows(i,j,i+u[i,j],j+w[i,j],length=angleng,angle=angarrow,code=2,
lwd=1,col="black") })


-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Wed, 4 Dec 2002, Z Cui wrote:

> Dear All
> 
> I would like to use filled.contour to plot something with arrows on it. I did it in this way:
> 
> filled.contour(1:nx,1:nz,u,col=gray(rev((0:20/20))))
> for (j in zseq ) for (i in xseq) arrows(i, j, i+u[i,j],j+w[i,j],length=angleng,angle=angarrow,code=2, lwd=1,col="black")
> 
> The peoblem is that the arrows use the whole device area, including the key on the right hand side of the filled contour. Does anyone know how to work out this problem?
> 
> Many thanks for your kind reply.
> Dr Zhiqiang Cui
> School of Geography and Environmental Sciences
> The University of Birmingham
> Edgbaston, Birmingham
> B15 2TT
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From luke at stat.uiowa.edu  Thu Dec  5 01:12:03 2002
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Thu Dec  5 01:12:03 2002
Subject: [R] compiling R under hp-ux 10.20
In-Reply-To: <3DEE234A.8EC8A6C5@mail.tsumura.co.jp>
Message-ID: <Pine.LNX.4.44.0212041804550.19566-100000@itasca.stat.uiowa.edu>

On Thu, 5 Dec 2002, [iso-2022-jp] $B>e86=(><(B wrote:

> 2. Unable to load the library cluster:
>  > library(cluster)
> Loading required package: mva
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
> unable to load shared library "/usr/local/lib/R/library/cluster/libs/cluster.sl":
> can't open /usr/local/lib/R/library/cluster/libs/cluster.sl
> Error in library(cluster) : .First.lib failed
> >

This one appears to be due to a bug in cluster: the C code calls a
fortran function `meet' as `meet_'.  HP-UX fortran compilers do not
append underscores; the C code should probably be changed to use
F77_CALL or whatever the appropriate macro is to avoid this.

luke

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



From stvjc at channing.harvard.edu  Thu Dec  5 01:17:03 2002
From: stvjc at channing.harvard.edu (Vincent Carey 525-2265)
Date: Thu Dec  5 01:17:03 2002
Subject: [R] R configure fails on solaris: configure:12951: error: cannot compute
 sizeof (int), 77
Message-ID: <Pine.GSO.4.40.0212041914010.25605-100000@falmouth.bwh.harvard.edu>

i do not have access to the solaris machine on which
this error is occuring, the info is coming
to me via email.

any advice on how to get R 1.6.1 built in the face of

configure:12951: error: cannot compute sizeof (int), 77

would be appreciated.

here are some snippets from the config.log


  $ ./configure

## --------- ##
## Platform. ##
## --------- ##

hostname = opus
uname -m = sun4u
uname -r = 5.8
uname -s = SunOS
uname -v = Generic_108528-12

/usr/bin/uname -p = sparc
/bin/uname -X     = System = SunOS
Node = opus
Release = 5.8
KernelID = Generic_108528-12
Machine = sun4u
BusType = <unknown>
Serial = <unknown>
Users = <unknown>
OEM# = 0
Origin# = 1
NumCPU = 1
/bin/arch              = sun4
/usr/bin/arch -k       = sun4u
/usr/convex/getsysinfo = unknown
hostinfo               = unknown
/bin/machine           = unknown
/usr/bin/oslevel       = unknown
/bin/universe          = unknown

PATH: /bin
PATH: /usr/bin
PATH: /usr/dt/bin
PATH: /usr/openwin/bin
PATH: /usr/ccs/bin
PATH: /opt/sfw/bin
PATH: /usr/local/bin
PATH: /usr/bin/nsr
PATH: /usr/local/teTeX/bin/sparc-sun-solaris2.8
PATH: /usr/local/teTeX/bin
PATH: /usr/ucb
PATH: /usr/bin/nsr
PATH: .
PATH: /usr/sbin
PATH: /usr/bin

...

configure:3581: gcc -v </dev/null >&5
Reading specs from /opt/sfw/lib/gcc-lib/sparc-sun-solaris2.8/2.95.2/specs
gcc version 2.95.2 19991024 (release)
configure:3584: $? = 0
configure:3586: gcc -V </dev/null >&5
gcc: argument to `-V' is missing
configure:3589: $? = 1
configure:3615: checking for C compiler default output
configure:3618: gcc  -I/usr/local/include -L/usr/local/lib conftest.c  >&5
configure:3621: $? = 0
configure:3654: result: a.out
configure:3659: checking whether the C compiler works
configure:3665: ./a.out
configure:3668: $? = 0
configure:3683: result: yes
configure:3690: checking whether we are cross compiling
configure:3692: result: no
configure:3695: checking for suffix of executables

...

configure:9645: checking for g77
configure:9661: found /opt/sfw/bin/g77
configure:9671: result: g77
configure:9819: checking for Fortran 77 compiler version
configure:9822: g77 --version </dev/null >&5
GNU Fortran 0.5.25 19991024 (release)
Copyright (C) 1997 Free Software Foundation, Inc.
For more version information on components of the GNU Fortran
compilation system, especially useful when reporting bugs,
type the command `g77 --verbose'.

GNU Fortran comes with NO WARRANTY, to the extent permitted by law.
You may redistribute copies of GNU Fortran
under the terms of the GNU General Public License.
For more information about these matters, see the file named COPYING
or type the command `info -f g77 Copying'.
configure:9825: $? = 0
configure:9827: g77 -v </dev/null >&5
g77 version 2.95.2 19991024 (release) (from FSF-g77 version 0.5.25 19991024 (release))
Driving: g77 -v -c -xf77-version /dev/null -xnone
Reading specs from /opt/sfw/lib/gcc-lib/sparc-sun-solaris2.8/2.95.2/specs
gcc version 2.95.2 19991024 (release)
 /opt/sfw/lib/gcc-lib/sparc-sun-solaris2.8/2.95.2/cpp -lang-c -v -D__GNUC__=2 -D__GNUC_MINOR__=95
-D__sparc__ -D__sun__ -D__unix__ -D__svr4__ -D__SVR4 -D__sparc -D__sun -D__unix -Asystem(unix)
-Asystem(svr4) -D_LANGUAGE_FORTRAN -traditional -D__GCC_NEW_VARARGS__ -Acpu(sparc) -Amachine(sparc)
/dev/null /dev/null
GNU CPP version 2.95.2 19991024 (release) (sparc)

...

int
main ()
{

  FILE *f = fopen ("conftest.val", "w");
  if (! f)
    exit (1);
  if (((long) (sizeof (int))) < 0)
    {
      long i = longval ();
      if (i != ((long) (sizeof (int))))
        exit (1);
      fprintf (f, "%ld\n", i);
    }
  else
    {
      unsigned long i = ulongval ();
      if (i != ((long) (sizeof (int))))
        exit (1);
      fprintf (f, "%lu\n", i);
    }
  exit (ferror (f) || fclose (f) != 0);

  ;
  return 0;
}
configure:12951: error: cannot compute sizeof (int), 77



---
Vince Carey, PhD
Ass't Prof Med (Biostatistics)
Harvard Medical School
Channing Laboratory - ph 6175252265 fa 6177311541
181 Longwood Ave Boston MA 02115 USA
stvjc at channing.harvard.edu



From RBF21 at student.canterbury.ac.nz  Thu Dec  5 01:51:03 2002
From: RBF21 at student.canterbury.ac.nz (rbf21)
Date: Thu Dec  5 01:51:03 2002
Subject: [R] tapply
Message-ID: <3DE872E3@webmail>

I'm having trouble with tapply, it seems to give me NA for the mean of a set 
like {2, 3, 4, NA}, can I get it to ignore the NA's and give me a mean like 
say, three? Am I just doing something stupid?

Any help would be apprecitated, Also are there PDF versions of any of the R 
stats books around that I might be able to get my hands on?

Bryn



From rsadler at agric.uwa.edu.au  Thu Dec  5 03:13:03 2002
From: rsadler at agric.uwa.edu.au (rohan sadler)
Date: Thu Dec  5 03:13:03 2002
Subject: [R] tapply
References: <3DE872E3@webmail>
Message-ID: <3DEEB70F.7070200@agric.uwa.edu.au>

Hi Bryn,

You just need to use the na.rm=T option (look under help for the mean 
function)
e.g.
 > x<-c(1,4,6,NA,10,18)    # data
 > mean(x)
[1] NA
 > mean(x,na.rm=T)
[1] 7.8

 > y<-c(1,1,1,2,2,2)        # factor variable
 > tapply(x,y,mean)
       1        2
3.666667       NA
 > tapply(x,y,mean,na.rm=T)
        1         2
 3.666667 14.000000

Rohan


rbf21 wrote:

>I'm having trouble with tapply, it seems to give me NA for the mean of a set 
>like {2, 3, 4, NA}, can I get it to ignore the NA's and give me a mean like 
>say, three? Am I just doing something stupid?
>
>Any help would be apprecitated, Also are there PDF versions of any of the R 
>stats books around that I might be able to get my hands on?
>
>Bryn
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Ecosystems Research Group (ERGO)
School of Plant Biology (Botany), Faculty of Natural & Agricultural Sciences,
The University of Western Australia, 35 Stirling Highway, Crawley  WA  6009, Australia

Ph:  +61 8 9380 7914
Fax: +61 8 9380 7925
email: rsadler at agric.uwa.edu.au
ERGO's web site:<http://www.botany.uwa.edu.au/ergo>



From clyde at stat.duke.edu  Thu Dec  5 03:53:03 2002
From: clyde at stat.duke.edu (Merlise Clyde)
Date: Thu Dec  5 03:53:03 2002
Subject: [R] is.loaded("gamma") is FALSE in Windows
Message-ID: <Pine.OSF.4.44.0212042150420.265-100000@okeeffe.isds.duke.edu>

Hi!  I am working on dynamically loading some C code into R and have my
programs working on a DEC alpha.  I have tried porting it to windows and
found that the gamma function is not loaded in the symbol table there, but
is under unix.  While I can add in the gamma function, I would prefer to
use the same one as in R and have the same code under unix and wondows.
Is there a way to access the internal gamma function from c in windows?

I am using R 1.6.0

best,
Merlise
__________________________________________________
|                                                |
| Merlise Clyde,  Associate Professor            |
| Institute of Statistics and Decision Sciences  |
| 219A  Old Chemistry, BOX 90251                 |
| Duke University                                |
| Durham, NC  27708-0251                         |
|                                                |
| Office Phone: (919) 681-8440                   |
| Fax:          (919) 684-8594                   |
| email:        clyde at stat.duke.edu              |
| web:          http://www.stat.duke.edu/~clyde  |
|________________________________________________|



From p.connolly at hortresearch.co.nz  Thu Dec  5 05:14:03 2002
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Thu Dec  5 05:14:03 2002
Subject: [R] Two different yaxes with lattice plots
Message-ID: <20021205041333.GL24300@hortresearch.co.nz>

In "normal" plots, I can do an axis at side = 2 and a different one at
side = 4.  I've not been able to figure out how to do the same thing
with lattice plots.  The scales list can have only one sublist named
y.  I had thought of using a separate viewport alongside with the text
for the axis label, but I can't see how I could get the ticks to work.

Ideas appreciated.

Thanks.


-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From r.darnell at shrs.uq.edu.au  Thu Dec  5 05:47:03 2002
From: r.darnell at shrs.uq.edu.au (Ross Darnell)
Date: Thu Dec  5 05:47:03 2002
Subject: [R] Problems with segments and multiple graphs
Message-ID: <fztdrs2r.fsf@shrs.uq.edu.au>

I would like to create a page of two graphs (2 rows by 1 col) and then
draw vertical lines (segments?) on both graphs from the minimum
values to the corresponding maximum value.

So I have tried

#
> y <- rnorm(3000)
> par(mfrow=c(2,1))
> plot(y,type="l")
> plot(cumsum(y),type="l")
> segments(1000,min(cumsum(y)),1000,max(cumsum(y)))
> par(mfg=c(1,1))
> segments(1000,min(y),1000,max(y))
> y <- rnorm(3000)


The segment looks fine on the bottom graph but I get a small vertical
line on the top graph. The max(y) value looks OK but the min(y) looks
like the second largest value.

> ymin <- min(y)
> ymax <- max(y)
> segments(1000,ymin,1000,ymax)

doesn't make any difference.

Can I draw a (one) line that crosses both graphs?

Thanks 

Ross Darnell
-- 
Ross Darnell
Email: <r.darnell at shrs.uq.edu.au>



From deepayan at stat.wisc.edu  Thu Dec  5 06:00:05 2002
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu Dec  5 06:00:05 2002
Subject: [R] Two different yaxes with lattice plots
In-Reply-To: <20021205041333.GL24300@hortresearch.co.nz>
References: <20021205041333.GL24300@hortresearch.co.nz>
Message-ID: <200212042300.20743.deepayan@stat.wisc.edu>

On Wednesday 04 December 2002 10:13 pm, Patrick Connolly wrote:

> In "normal" plots, I can do an axis at side = 2 and a different one at
> side = 4.  I've not been able to figure out how to do the same thing
> with lattice plots.  The scales list can have only one sublist named
> y.  I had thought of using a separate viewport alongside with the text
> for the axis label, but I can't see how I could get the ticks to work.

You probably won't be able to do this in lattice (and I can't think of a 
sensible way to modify lattice to allow this that would work for multipanel 
plots). Why do you need lattice for this ? If this is a single-panel plot, 
you could use grid directly. Set the viewport to whatever you want, draw in 
it (you could use a lattice panel function to do that if you want), and add 
the axes with grid.xaxis and grid.yaxis. 

Deepayan



From mike_rphd at yahoo.com  Thu Dec  5 06:41:03 2002
From: mike_rphd at yahoo.com (Mike Sumner)
Date: Thu Dec  5 06:41:03 2002
Subject: [R] colour and weighting with sm.density/regression
In-Reply-To: <20021205041333.GL24300@hortresearch.co.nz>
Message-ID: <20021205054048.31703.qmail@web10708.mail.yahoo.com>

Hello, I am using the sm and chron libraries to
produce density plots, they are lat/lon locations of
marine mammals.

I am using Windows 2000, 1.6.0

The default image plot for sm.density is yellow on a
red background - how can I change these colours? 
Neither sm.options nor par seem to cover this.

It seems that I can use sm.regression to weight the
density plots by attribute values at each point, but
this can only be displayed in "persp".  
Can I display sm.regression surfaces as "image"?  Or,
weight an sm.density surface by attribute value?

All I can think of is to increase the number of points
in an area in proportion to the value I would like
displayed.  (The value I am interested in is the time
between each point).

Cheers, Mike.



From h95mr at mun.ca  Thu Dec  5 07:00:04 2002
From: h95mr at mun.ca (Martin Renner)
Date: Thu Dec  5 07:00:04 2002
Subject: [R] colourcoding scatterplot
In-Reply-To: 
 <18D602BD42B7E24EB810D6454A58DB9001CAE040@ibfftce505.is.de.dresdnerkb.com>
References: 
 <18D602BD42B7E24EB810D6454A58DB9001CAE040@ibfftce505.is.de.dresdnerkb.com>
Message-ID: <a05200f01ba149a303d45@[134.153.109.176]>

Hi All,

I would like to make a x-y scatterplot with a third variable coded 
into a colour-gradient of the scatterplot symbols (which should be 
displayed in a legend like you would do for image-plots). Has anybody 
ever tried this/figured out an easy way to do this?

Cheers,
	Martin



From ripley at stats.ox.ac.uk  Thu Dec  5 07:34:02 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Dec  5 07:34:02 2002
Subject: [R] is.loaded("gamma") is FALSE in Windows
In-Reply-To: <Pine.OSF.4.44.0212042150420.265-100000@okeeffe.isds.duke.edu>
Message-ID: <Pine.LNX.4.31.0212050627190.27301-100000@gannet.stats>

On Wed, 4 Dec 2002, Merlise Clyde wrote:

> Hi!  I am working on dynamically loading some C code into R and have my
> programs working on a DEC alpha.  I have tried porting it to windows and
> found that the gamma function is not loaded in the symbol table there, but
> is under unix.  While I can add in the gamma function, I would prefer to
> use the same one as in R and have the same code under unix and wondows.
> Is there a way to access the internal gamma function from c in windows?

What function do you think you are getting here?   R's internal gamma
function is not symbol `gamma', and it is not documented to be either.
If you look in `Writing R Extensions' you will find that there is a public
interface to a gamma function ....

If in desperation, read the documentation!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Dec  5 07:40:04 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Dec  5 07:40:04 2002
Subject: [R] R configure fails on solaris: configure:12951: error: cannot
 compute sizeof (int), 77
In-Reply-To: <Pine.GSO.4.40.0212041914010.25605-100000@falmouth.bwh.harvard.edu>
Message-ID: <Pine.LNX.4.31.0212050634520.27301-100000@gannet.stats>

That compiler is older than the operating system.  Use a current
version of gcc (2.95.4 or 3.2, not 3.2.1) *built on Solaris 2.8*,
or the current SunPro compiler.

On Wed, 4 Dec 2002, Vincent Carey 525-2265 wrote:

>
> i do not have access to the solaris machine on which
> this error is occuring, the info is coming
> to me via email.
>
> any advice on how to get R 1.6.1 built in the face of
>
> configure:12951: error: cannot compute sizeof (int), 77
>
> would be appreciated.
>
> here are some snippets from the config.log
>
>
>   $ ./configure
>
> ## --------- ##
> ## Platform. ##
> ## --------- ##
>
> hostname = opus
> uname -m = sun4u
> uname -r = 5.8
> uname -s = SunOS
> uname -v = Generic_108528-12
>
> /usr/bin/uname -p = sparc
> /bin/uname -X     = System = SunOS
> Node = opus
> Release = 5.8
> KernelID = Generic_108528-12
> Machine = sun4u
> BusType = <unknown>
> Serial = <unknown>
> Users = <unknown>
> OEM# = 0
> Origin# = 1
> NumCPU = 1
> /bin/arch              = sun4
> /usr/bin/arch -k       = sun4u
> /usr/convex/getsysinfo = unknown
> hostinfo               = unknown
> /bin/machine           = unknown
> /usr/bin/oslevel       = unknown
> /bin/universe          = unknown
>
> PATH: /bin
> PATH: /usr/bin
> PATH: /usr/dt/bin
> PATH: /usr/openwin/bin
> PATH: /usr/ccs/bin
> PATH: /opt/sfw/bin
> PATH: /usr/local/bin
> PATH: /usr/bin/nsr
> PATH: /usr/local/teTeX/bin/sparc-sun-solaris2.8
> PATH: /usr/local/teTeX/bin
> PATH: /usr/ucb
> PATH: /usr/bin/nsr
> PATH: .
> PATH: /usr/sbin
> PATH: /usr/bin
>
> ...
>
> configure:3581: gcc -v </dev/null >&5
> Reading specs from /opt/sfw/lib/gcc-lib/sparc-sun-solaris2.8/2.95.2/specs
> gcc version 2.95.2 19991024 (release)
> configure:3584: $? = 0
> configure:3586: gcc -V </dev/null >&5
> gcc: argument to `-V' is missing
> configure:3589: $? = 1
> configure:3615: checking for C compiler default output
> configure:3618: gcc  -I/usr/local/include -L/usr/local/lib conftest.c  >&5
> configure:3621: $? = 0
> configure:3654: result: a.out
> configure:3659: checking whether the C compiler works
> configure:3665: ./a.out
> configure:3668: $? = 0
> configure:3683: result: yes
> configure:3690: checking whether we are cross compiling
> configure:3692: result: no
> configure:3695: checking for suffix of executables
>
> ...
>
> configure:9645: checking for g77
> configure:9661: found /opt/sfw/bin/g77
> configure:9671: result: g77
> configure:9819: checking for Fortran 77 compiler version
> configure:9822: g77 --version </dev/null >&5
> GNU Fortran 0.5.25 19991024 (release)
> Copyright (C) 1997 Free Software Foundation, Inc.
> For more version information on components of the GNU Fortran
> compilation system, especially useful when reporting bugs,
> type the command `g77 --verbose'.
>
> GNU Fortran comes with NO WARRANTY, to the extent permitted by law.
> You may redistribute copies of GNU Fortran
> under the terms of the GNU General Public License.
> For more information about these matters, see the file named COPYING
> or type the command `info -f g77 Copying'.
> configure:9825: $? = 0
> configure:9827: g77 -v </dev/null >&5
> g77 version 2.95.2 19991024 (release) (from FSF-g77 version 0.5.25 19991024 (release))
> Driving: g77 -v -c -xf77-version /dev/null -xnone
> Reading specs from /opt/sfw/lib/gcc-lib/sparc-sun-solaris2.8/2.95.2/specs
> gcc version 2.95.2 19991024 (release)
>  /opt/sfw/lib/gcc-lib/sparc-sun-solaris2.8/2.95.2/cpp -lang-c -v -D__GNUC__=2 -D__GNUC_MINOR__=95
> -D__sparc__ -D__sun__ -D__unix__ -D__svr4__ -D__SVR4 -D__sparc -D__sun -D__unix -Asystem(unix)
> -Asystem(svr4) -D_LANGUAGE_FORTRAN -traditional -D__GCC_NEW_VARARGS__ -Acpu(sparc) -Amachine(sparc)
> /dev/null /dev/null
> GNU CPP version 2.95.2 19991024 (release) (sparc)
>
> ...
>
> int
> main ()
> {
>
>   FILE *f = fopen ("conftest.val", "w");
>   if (! f)
>     exit (1);
>   if (((long) (sizeof (int))) < 0)
>     {
>       long i = longval ();
>       if (i != ((long) (sizeof (int))))
>         exit (1);
>       fprintf (f, "%ld\n", i);
>     }
>   else
>     {
>       unsigned long i = ulongval ();
>       if (i != ((long) (sizeof (int))))
>         exit (1);
>       fprintf (f, "%lu\n", i);
>     }
>   exit (ferror (f) || fclose (f) != 0);
>
>   ;
>   return 0;
> }
> configure:12951: error: cannot compute sizeof (int), 77
>
>
>
> ---
> Vince Carey, PhD
> Ass't Prof Med (Biostatistics)
> Harvard Medical School
> Channing Laboratory - ph 6175252265 fa 6177311541
> 181 Longwood Ave Boston MA 02115 USA
> stvjc at channing.harvard.edu
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jryjry at hotmail.com  Thu Dec  5 08:48:05 2002
From: jryjry at hotmail.com (jonas)
Date: Thu Dec  5 08:48:05 2002
Subject: [R] rollols
Message-ID: <OE51wIidWZe2BS7QTDV00001837@hotmail.com>

Hi,



Are there functions similar to the S-plus functions rollols and
predict.rollols in R? I've searched the packages but can't seem to find
anything similar.



Any tips would be greatly appreciated,

Jonas



From otoomet at econ.dk  Thu Dec  5 08:51:43 2002
From: otoomet at econ.dk (Ott Toomet)
Date: Thu Dec  5 08:51:43 2002
Subject: [R] Getting Break Points From Hist Function?
In-Reply-To: <F171CjOYX6XsXGqbh8o000092eb@hotmail.com>
	(jacksragingvileduct@hotmail.com)
References: <F171CjOYX6XsXGqbh8o000092eb@hotmail.com>
Message-ID: <200212050750.gB57oVi09771@punik.econ.au.dk>

Hi,

I guess you are looking for something like

a <- hist(...., plot=FALSE) # don't draw the histogram
a$breaks # breakpoints
a$counts # frequency table

This is documented as the return value for hist() on the help page.

Perahps it helps.

Ott

 | From: "Bleh Blah" <jacksragingvileduct at hotmail.com>
 | Date: Wed, 04 Dec 2002 15:22:19 -0500
 | 
 | Is there any way to extract the break points from a hist function as a 
 | vector so I can later use them for a cut function?
 | 
 | The ultimate goal is to make a frequency table of the data with the same 
 | break points that were used in the histogram.



From ripley at stats.ox.ac.uk  Thu Dec  5 09:09:02 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Dec  5 09:09:02 2002
Subject: [R] rollols
In-Reply-To: <OE51wIidWZe2BS7QTDV00001837@hotmail.com>
Message-ID: <Pine.LNX.4.31.0212050807140.27571-100000@gannet.stats>

On Wed, 4 Dec 2002, jonas wrote:

> Are there functions similar to the S-plus functions rollols and
> predict.rollols in R? I've searched the packages but can't seem to find
> anything similar.

As there appear to be no such functions in the current S-PLUS 6.1, I'm
afraid you will have to tell us where you got them from and what they do.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jryjry at hotmail.com  Thu Dec  5 09:32:04 2002
From: jryjry at hotmail.com (jonas)
Date: Thu Dec  5 09:32:04 2002
Subject: [R] rollols
References: <Pine.LNX.4.31.0212050807140.27571-100000@gannet.stats>
Message-ID: <OE55pRcTCi90gP8yJrN00002a79@hotmail.com>

Sorry about that. They are part of the S+Finmetrics add-on package.
rollOLS performs multiple OLS analyses over a series of moving time windows.
predict.rollOLS: perform out-of-sample prediction from a fitted "rollOLS"
object.

information from:
http://www.insightful.com/support/finmetrics10/finmetricsfaq.asp
and
http://stat.tamu.edu/doc/Splus6/FunctionGuide.pdf

Thanks,
Jonas



> On Wed, 4 Dec 2002, jonas wrote:
>
> > Are there functions similar to the S-plus functions rollols and
> > predict.rollols in R? I've searched the packages but can't seem to find
> > anything similar.
>
> As there appear to be no such functions in the current S-PLUS 6.1, I'm
> afraid you will have to tell us where you got them from and what they do.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From maechler at stat.math.ethz.ch  Thu Dec  5 09:43:06 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu Dec  5 09:43:06 2002
Subject: [R] compiling R under hp-ux 10.20
In-Reply-To: <Pine.LNX.4.44.0212041804550.19566-100000@itasca.stat.uiowa.edu>
References: <3DEE234A.8EC8A6C5@mail.tsumura.co.jp>
	<Pine.LNX.4.44.0212041804550.19566-100000@itasca.stat.uiowa.edu>
Message-ID: <15855.4447.313527.346586@gargle.gargle.HOWL>

>>>>> "Luke" == Luke Tierney <luke at stat.uiowa.edu>
>>>>>     on Wed, 4 Dec 2002 18:09:27 -0600 (CST) writes:

    Luke> On Thu, 5 Dec 2002, [iso-2022-jp] $B>e86=(><(B
    Luke> wrote:
    >> 2. Unable to load the library cluster: > library(cluster)
    >> Loading required package: mva Error in dyn.load(x,
    >> as.logical(local), as.logical(now)) : unable to load
    >> shared library
    >> "/usr/local/lib/R/library/cluster/libs/cluster.sl": can't
    >> open /usr/local/lib/R/library/cluster/libs/cluster.sl
    >> Error in library(cluster) : .First.lib failed
    >> >

    Luke> This one appears to be due to a bug in cluster: the C
    Luke> code calls a fortran function `meet' as `meet_'.
    Luke> HP-UX fortran compilers do not append underscores; the
    Luke> C code should probably be changed to use F77_CALL or
    Luke> whatever the appropriate macro is to avoid this.

definitely;  mea culpa.  
I'll release a fixed cluster source (version 1.6-3) to CRAN  ASAP.

Martin

    Luke> -- Luke Tierney University of Iowa Phone: 319-335-3386
    Luke> Department of Statistics and Fax: 319-335-3017
    Luke> Actuarial Science 241 Schaeffer Hall email:
    Luke> luke at stat.uiowa.edu Iowa City, IA 52242 WWW:
    Luke> http://www.stat.uiowa.edu

-- 
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From mrufino at cmima.csic.es  Thu Dec  5 09:51:06 2002
From: mrufino at cmima.csic.es (Marta Rufino)
Date: Thu Dec  5 09:51:06 2002
Subject: [R] crimson
Message-ID: <3.0.1.32.20021205100252.00839380@cucafera.icm.csic.es>

>Date: Tue, 05 Nov 2002 16:52:58 +0100
>To: r-help at lists.R-project.org
>From: Marta Rufino <mrufino at cmima.csic.es>
>Subject: last.warning and function problem
>
>Hello,
>
>I am a newbie in R and I am trying to create a function, that includes
several functions inside.
>To avoid that everything stops if there is an error, I have this statement 
>
>bla = function(....){
>...
>if(exists("last.warning")){rm(last.warning)}
>...
>}
>
>inside the function, which if I use it normally, it works fine, but once I
use it with the funciotn it gives me an error like:
>
>$"remove: variable "last.warning" was not found"
>NULL
>
>which breaks my function.
>I just want to make it do: if exists the file last warning, remove it, if
not, just proceed...
>Does anyone knows why this happens? How can I avoid it?
>Thanks in advance.
>Marta 
    

><((((?>`?.??.???`?.?.???`?...?><((((?>`?.??.???`?.?.???`?...?><((((?>
`?.??.???`?.?.???`?...?><((((?>`?.??.???`?.?.???`?...?><((((?>`?.??.??

Marta Rufino

Centre Mediterrani d'Investigacions Marines i Ambientals
(CMIMA). CSIC
Passeig Maritim 37-49
08003  BARCELONA

Tfno:34 93 230 95 40
Tfax:34 93 230 95 55

><((((?>`?.??.???`?.?.???`?...?><((((?>`?.??.???`?.?.???`?...?><((((?>
`?.??.???`?.?.???`?...?><((((?>`?.??.???`?.?.???`?...?><((((?>`?.??.??



From otoomet at econ.dk  Thu Dec  5 09:54:06 2002
From: otoomet at econ.dk (Ott Toomet)
Date: Thu Dec  5 09:54:06 2002
Subject: [R] for help!
In-Reply-To: <5.1.1.5.2.20021204135346.042fee30@pangea.stanford.edu> (message
	from jbwu on Wed, 04 Dec 2002 13:59:32 -0800)
References: <5.1.1.5.2.20021204135346.042fee30@pangea.stanford.edu>
Message-ID: <200212050854.gB58saL09867@punik.econ.au.dk>

Hi,

In general, there are no clear upper limit on how big datasets R can
handle.  If you have a 32-bit computer, that is probably 2GB, but it
can be lowered.  

In which form do you have your data and how did you try to read it?
If it is an ASCII table, scan() should be much more memory efficient
than read.table().  You may also consider pre-processing your dataset
with e.g. perl in order to get rid of much what you do not need.  The
best (but not trivial) way is perhaps to read the data into a SQL
database and user R to query only necessary variables from there.

Perhaps you should start with a small subset of your data, try to read
it into R and do some exploratory analysis.  

Otherwise, SAS is known for its ability to handle large datasets.

Perhaps it helps.

Ott

 | From: jbwu <jbwu at pangea.stanford.edu>
 | Date: Wed, 04 Dec 2002 13:59:32 -0800
 | 
 | hi, Guys:
 | Now I am trying to use "R" to do some canonical analysis on large data sets,
 | one of them is 42MB, and can be read by "R", the other data file is about 90MB,
 | and this time R cannot read such a big size data. My question is that how can
 | I deal with such a big dataset with "R", or are there any other statistical 
 | softwares
 | which can read a huge data file as I memtioned?



From mrufino at cmima.csic.es  Thu Dec  5 10:01:03 2002
From: mrufino at cmima.csic.es (Marta Rufino)
Date: Thu Dec  5 10:01:03 2002
Subject: [R] crimson editor
Message-ID: <3.0.1.32.20021205101353.0083a100@cucafera.icm.csic.es>

Hello,

Sorry about the last email, I just found the shortcutkey for sending, by
mistake :-(
OK. I am a windows user and I wanted to instal emacs. However, went to
speak with the information staf on the institut and they told me that that
is a bit problematic sometimes, and that there is a free soft that could do
a very similar job which is crimson...
This is like a note pad, but highlights the syntax and can open R and tell
it to execute stuff... I am really happy with it, and I wanted to share it
with you.
(some day I will still try emacs)
OK, Crimson can be downloaded free in 
www.crimsoneditor.com
 
It is really small (fits a flopy disk). After install you just fill in the
menu 
tools < configure usertools :
menu text: R-batch
# this is just the directory where you have your R in batch
Command: C:\Archivos de programa\R\rw1060\bin\Rterm.exe
Argument: --vanilla < $(FileName) 
Initial dir: $(FileDir)

And that is it... really simple. To do this you have to be able to use your
R in batch mode. I have started creating a syntax colour code for this
program (it is realy simple to do it...just asci file)... 
and I was wondering, does anyone know where can I get a complete list of
the R functions? What about separated by packages?
Is there a similar file (of syntax highlighting) from emacs that I can
copy/see? BEcause I think it would be nice to have the same colour scheme...
If anyone wants my syntax highlight send me an email.
If we manage to put this working propertly, I will try to do a proper
manual...

Thank you for your attention and your help in advance,

Marta
    

><((((?>`?.??.???`?.?.???`?...?><((((?>`?.??.???`?.?.???`?...?><((((?>
`?.??.???`?.?.???`?...?><((((?>`?.??.???`?.?.???`?...?><((((?>`?.??.??

Marta Rufino

Centre Mediterrani d'Investigacions Marines i Ambientals
(CMIMA). CSIC
Passeig Maritim 37-49
08003  BARCELONA

Tfno:34 93 230 95 40
Tfax:34 93 230 95 55

><((((?>`?.??.???`?.?.???`?...?><((((?>`?.??.???`?.?.???`?...?><((((?>
`?.??.???`?.?.???`?...?><((((?>`?.??.???`?.?.???`?...?><((((?>`?.??.??



From dray at biomserv.univ-lyon1.fr  Thu Dec  5 10:32:03 2002
From: dray at biomserv.univ-lyon1.fr (Stephane Dray)
Date: Thu Dec  5 10:32:03 2002
Subject: [R] Interpreting canonical correlation (cancor) results
In-Reply-To: <3DEE5B50.6080001@t-online.de>
References: <3DEE5B50.6080001@t-online.de>
Message-ID: <a05010402ba14c906c307@[134.214.32.69]>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021205/a0d512ad/attachment.pl

From Swillemsen at ioo.nl  Thu Dec  5 12:23:02 2002
From: Swillemsen at ioo.nl (Willemsen, Sten)
Date: Thu Dec  5 12:23:02 2002
Subject: [R] crimson editor
Message-ID: <000A1E5494E0D211BC8200805FBBE869028C9854@eimprox1.eim.nl>

Crimson editor is great but it is not as dynamic as emacs is.

Sten Willemsen



From Z.Cui at bham.ac.uk  Thu Dec  5 12:28:03 2002
From: Z.Cui at bham.ac.uk (Z Cui)
Date: Thu Dec  5 12:28:03 2002
Subject: [R] Help: draw 3 filled.contour on one page
Message-ID: <1039087622.abe57c00Z.Cui@bham.ac.uk>

Dear All,

I tried to draw 3 filled.contour plots on one page, but failed. It returns 
"Error in plot.new() : Figure margins too large". 

Can anyone help me to do this.

BTW, does anyone has the experience to draw a isosurface with R?
Dr Zhiqiang Cui
School of Geography and Environmental Sciences
The University of Birmingham
Edgbaston, Birmingham
B15 2TT



From otoomet at econ.dk  Thu Dec  5 12:41:02 2002
From: otoomet at econ.dk (Ott Toomet)
Date: Thu Dec  5 12:41:02 2002
Subject: [R] Problems with segments and multiple graphs
References: <fztdrs2r.fsf@shrs.uq.edu.au>
Message-ID: <200212051141.gB5BfMP09911@punik.econ.au.dk>

Hi,

there are perhaps problems with par(mfg) and coordinate system (at
least on my R 1.5.1 on RH 7.2).  But you may do

  y <- rnorm(3000)
  par(mfrow=c(2,1))
  plot(y,type="l")
  segments(1000,min(y),1000,max(y), col=2)
  plot(cumsum(y),type="l")
  segments(1000,min(cumsum(y)),1000,max(cumsum(y)), col=3)

i.e. plot and draw segment on upper graph, and thereafter do the same
on the lower.  Plot starts a new graph, but segements works on the
previous one.

Perhaps it helps.

Ott

 | From: Ross Darnell <r.darnell at shrs.uq.edu.au>
 | Date: 05 Dec 2002 14:46:20 +1000
 | 
 | I would like to create a page of two graphs (2 rows by 1 col) and then
 | draw vertical lines (segments?) on both graphs from the minimum
 | values to the corresponding maximum value.
 | 
 | So I have tried
 | 
 | #
 | > y <- rnorm(3000)
 | > par(mfrow=c(2,1))
 | > plot(y,type="l")
 | > plot(cumsum(y),type="l")
 | > segments(1000,min(cumsum(y)),1000,max(cumsum(y)))
 | > par(mfg=c(1,1))
 | > segments(1000,min(y),1000,max(y))
 | > y <- rnorm(3000)
 | 
 | 
 | The segment looks fine on the bottom graph but I get a small vertical
 | line on the top graph. The max(y) value looks OK but the min(y) looks
 | like the second largest value.



From otoomet at econ.dk  Thu Dec  5 12:47:03 2002
From: otoomet at econ.dk (Ott Toomet)
Date: Thu Dec  5 12:47:03 2002
Subject: [R] Help: draw 3 filled.contour on one page
References: <1039087622.abe57c00Z.Cui@bham.ac.uk>
Message-ID: <200212051147.gB5BlXV09915@punik.econ.au.dk>

Hi,

take a look what are your par("mar").  Reasonable values are e.g.

par(mar=c(4,3,1,1))

If it does not help, look at help page for par() and look at different
parameters, related with margins.

 | From: Z Cui <Z.Cui at bham.ac.uk>
 | Date: Thu, 05 Dec 2002 11:27:02 +0000
 | 
 | Dear All,
 | 
 | I tried to draw 3 filled.contour plots on one page, but failed. It returns 
 | "Error in plot.new() : Figure margins too large". 
 | 
 | Can anyone help me to do this.
 | 
 | BTW, does anyone has the experience to draw a isosurface with R?

Unfortunately, I have not.

Ott



From jan.wiener at tuebingen.mpg.de  Thu Dec  5 13:12:03 2002
From: jan.wiener at tuebingen.mpg.de (Jan Wiener)
Date: Thu Dec  5 13:12:03 2002
Subject: [R] (no subject)
Message-ID: <web-3189505@tuebingen.mpg.de>

hi, 
suppose you have a for-loop like this: 

for(i in1:x) {} ...

now you want to generate a variable in every
cycle (since you do not know the size of x in
beforehand you have to do this dynamically). 

the variable should e.g. look like this:
variableName1<-c() (if x==1) 
variableName2<-c() (ifx==2) 
variableName3<-c() (if x==3) 
.. 
.. 
i tried this(which obviously didn't work):

paste("variableName",x,sep="")<-c(2,3,4) 

so i need
something similiar to this (but working!)!

thanks for help, greetinx jan



From ligges at statistik.uni-dortmund.de  Thu Dec  5 13:52:02 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu Dec  5 13:52:02 2002
Subject: [R] Problems with segments and multiple graphs
References: <fztdrs2r.fsf@shrs.uq.edu.au>
Message-ID: <3DEF4BEA.C7E35814@statistik.uni-dortmund.de>

Ross Darnell wrote:
> 
> I would like to create a page of two graphs (2 rows by 1 col) and then
> draw vertical lines (segments?) on both graphs from the minimum
> values to the corresponding maximum value.
> 
> So I have tried
> 
> #
> > y <- rnorm(3000)
> > par(mfrow=c(2,1))
> > plot(y,type="l")
> > plot(cumsum(y),type="l")
> > segments(1000,min(cumsum(y)),1000,max(cumsum(y)))
> > par(mfg=c(1,1))
> > segments(1000,min(y),1000,max(y))
> > y <- rnorm(3000)
> 
> The segment looks fine on the bottom graph but I get a small vertical
> line on the top graph. The max(y) value looks OK but the min(y) looks
> like the second largest value.
> 
> > ymin <- min(y)
> > ymax <- max(y)
> > segments(1000,ymin,1000,ymax)
> 
> doesn't make any difference.

OK. The par settings won't be resetted completely, but you can do so
manually:

 y <- rnorm(3000)
 par(mfrow=c(2,1))
 plot(y,type="l")
 rpar <- par()  # remember par settings
 plot(cumsum(y),type="l")
 segments(1000,min(cumsum(y)),1000,max(cumsum(y)))
 par(rpar)      # restore the settings to draw the line 
 par(mfg=c(1,1))
 segments(1000,min(y),1000,max(y), col="red")

In your case it is simpler to complete each plot before stepping to the
next one.


> Can I draw a (one) line that crosses both graphs?

Yes. A simple but rather ugly solution:

  par(xpd = NA)
  abline(v = 1000)

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Thu Dec  5 13:59:02 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu Dec  5 13:59:02 2002
Subject: [R] (no subject)
References: <web-3189505@tuebingen.mpg.de>
Message-ID: <3DEF4D57.410B4CD0@statistik.uni-dortmund.de>

Jan Wiener wrote:
> 
> hi,
> suppose you have a for-loop like this:
> 
> for(i in1:x) {} ...
> 
> now you want to generate a variable in every
> cycle (since you do not know the size of x in
> beforehand you have to do this dynamically).
> 
> the variable should e.g. look like this:
> variableName1<-c() (if x==1)
> variableName2<-c() (ifx==2)
> variableName3<-c() (if x==3)
> ..
> ..
> i tried this(which obviously didn't work):
> 
> paste("variableName",x,sep="")<-c(2,3,4)
> 
> so i need
> something similiar to this (but working!)!

- This is FAQ 7.23 (see the FAQ's, please).
- I'd suggest to use a list instead of a couple of different objects.
- See ?assign for more details related to your question:
  assign(paste("variableName", x, sep=""), c(2,3,4))

Uwe Ligges



From phil at lacertacapital.com  Thu Dec  5 14:22:02 2002
From: phil at lacertacapital.com (Phil Saunders)
Date: Thu Dec  5 14:22:02 2002
Subject: [R] (no subject)
Message-ID: <A5B74A99C30DBB46B9A819C3BD4A65F119168C@blsvr-2.bluelizard.org.uk>

Alternatively if you want to avoid using lists, you can create the variables like this:

for (i in 1:10) assign(paste("x",i,sep=""),i^2)

and view them subsequently like this:

for (i in 1:10) print(get(paste("x",i,sep="")))

Phil

-----Original Message-----
From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
Sent: 05 December 2002 12:58
To: Jan Wiener
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] (no subject)


Jan Wiener wrote:
> 
> hi,
> suppose you have a for-loop like this:
> 
> for(i in1:x) {} ...
> 
> now you want to generate a variable in every
> cycle (since you do not know the size of x in
> beforehand you have to do this dynamically).
> 
> the variable should e.g. look like this:
> variableName1<-c() (if x==1)
> variableName2<-c() (ifx==2)
> variableName3<-c() (if x==3)
> ..
> ..
> i tried this(which obviously didn't work):
> 
> paste("variableName",x,sep="")<-c(2,3,4)
> 
> so i need
> something similiar to this (but working!)!

- This is FAQ 7.23 (see the FAQ's, please).
- I'd suggest to use a list instead of a couple of different objects.
- See ?assign for more details related to your question:
  assign(paste("variableName", x, sep=""), c(2,3,4))

Uwe Ligges

______________________________________________
R-help at stat.math.ethz.ch mailing list http://www.stat.math.ethz.ch/mailman/listinfo/r-help

________________________________________________________________________
This email has been scanned for all viruses by the MessageLabs SkyScan
service. For more information on a proactive anti-virus service working
around the clock, around the globe, visit http://www.messagelabs.com



From vito.muggeo at giustizia.it  Thu Dec  5 16:05:02 2002
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Thu Dec  5 16:05:02 2002
Subject: [R] brillinger test
Message-ID: <010f01c29c6f$133f1780$5c13070a@it.giustizia.it>

Dear all,
below there a code to calculate the Brillinger statistic, testing for
non-monotonic trend in (time series) data.

The function (probably it is not optimized) works, but I could not check for
it. That is, I would be sure that it provides correct output. Does anyone
know any well-known data-set where I can check the output? Or is there
anyone being able to check for it?
Many thanks,
best,
vito


brillinger<-function(y,v=length(y)/10,L=length(y)/20,display=FALSE,iid=FALSE
){   #Brillinger test for non-monotonic trend. Brillinger (1989) Biometrika,
76:23-30.
#   require toeplitz() function in the ts package.
#y: the time series. It has to be a vector.
#v: parameter modelling the Moving Average-based trend estimate
#L: parameter modelling the variance estimate
#display: if TRUE the data are plotted with a nonparametric estimate
superimposed
#iid: are the observations iid?
#author: vito muggeo <vito.muggeo at giustizia.it>
    yy<-y
    y.lab<-deparse(substitute(y))
    n<-length(y)
    y<-y[(v+1):(n-v)]
    x<-1:length(y)
    c.t1<-sqrt((x-1)*(1-(x-1)/n))
    c.t2<-sqrt(x*(1-x/n))
    c.t<-c.t1-c.t2
    Y<-t(toeplitz(yy))
    Y[row(Y)<col(Y)]<-NA
    mu<-rowMeans(Y[,1:(2*v+1)],na.rm=FALSE)
    if(display) {plot(y,type="l",lty=3,xlab="Time",ylab=y.lab)
                lines(mu[!is.na(mu)])
                }
    e<-y-mu[!is.na(mu)]
        if(iid){z.iid<-sum(c.t*y)/(sd(e)*sqrt(sum(c.t^2)))
        p<-1-1*pnorm(abs(z.iid))
        out<-list("Brillinger Statistic"=z.iid,"p-value (one-sided)"=p)
        return(out)
        }
    csi<-apply(as.matrix(1:L),1,function(J){sum(e*exp(-2i*pi*J*(x-1)/n))})

a<-apply(as.matrix(1:L),1,function(J){sin(2*pi*J*(2*v+1)/(2*n))/((2*v+1)*sin
(2*pi*J/(2*n)))})
    den<-sum((1-a)^2)
    S0<-sum(Mod(csi)^2/n)/den
    z<-sum(c.t*y)/sqrt(S0*sum(c.t^2))
    p<-1-1*pnorm(abs(z))
    out<-list("Brillinger Statistic"=z,"p-value (one-sided)"=p)
    return(out)
    }

#Example
> n<-200
> y<-ifelse((1:n)>0.5*n,1,0)*2.5+rnorm(n) #non monotonic trend time serie
> library(ts)
> brillinger(y,display=TRUE,iid=TRUE)
$"Brillinger Statistic"
[1] 1.824676

$"p-value (one-sided)"
[1] 0.03402500



From tlumley at u.washington.edu  Thu Dec  5 17:18:03 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu Dec  5 17:18:03 2002
Subject: [R] crimson editor
In-Reply-To: <3.0.1.32.20021205101353.0083a100@cucafera.icm.csic.es>
Message-ID: <Pine.A41.4.44.0212050810170.29910-100000@homer24.u.washington.edu>

On Thu, 5 Dec 2002, Marta Rufino wrote:

> R in batch mode. I have started creating a syntax colour code for this
> program (it is realy simple to do it...just asci file)...
> and I was wondering, does anyone know where can I get a complete list of
> the R functions? What about separated by packages?

No (since it depends on what packages you have).  However,
  allnames<-lapply(grep("package:",search()),function(i) ls(pos=i))
will return the names of all the base functions and functions in loaded
packages, sorted by package.

There is also a file indexing the installed help pages in
doc/html/search/index.txt
All functions should appear somewhere in an "Aliases" line in this file,
but some non-functions will also appear.

> Is there a similar file (of syntax highlighting) from emacs that I can
> copy/see? BEcause I think it would be nice to have the same colour scheme...

Emacs doesn't do it by knowing all the functions but rather by knowing
what functions look like.

	-thomas



From rpeng at stat.ucla.edu  Thu Dec  5 18:42:03 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Thu Dec  5 18:42:03 2002
Subject: [R] Help: draw 3 filled.contour on one page
In-Reply-To: <1039087622.abe57c00Z.Cui@bham.ac.uk>
Message-ID: <Pine.GSO.4.10.10212050938550.16255-100000@fisher.stat.ucla.edu>

The help page for filled.contour() says:

     This function currently uses the `layout' function and so is
     restricted to a full page display.  In future it is likely to be
     replaced by a genuine `levelplot' function which will work in
     multipanel displays.

I guess it's only one plot per page for now.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Thu, 5 Dec 2002, Z Cui wrote:

> Dear All,
> 
> I tried to draw 3 filled.contour plots on one page, but failed. It returns 
> "Error in plot.new() : Figure margins too large". 
> 
> Can anyone help me to do this.
> 
> BTW, does anyone has the experience to draw a isosurface with R?
> Dr Zhiqiang Cui
> School of Geography and Environmental Sciences
> The University of Birmingham
> Edgbaston, Birmingham
> B15 2TT
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From f0z6305 at labs.tamu.edu  Thu Dec  5 18:58:02 2002
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Thu Dec  5 18:58:02 2002
Subject: [R] [R]How to plot a 3D ellipsoid in R?
Message-ID: <015d01c29c87$b8f9eca0$8bd75ba5@IE.TAMU.EDU>

Hey, all

I am going to plot several 3-dimensional ellipsoids
in R.
For example, A is such a ellipsoid with
mean u=[1 1 1]', covariance matrix C=[1 0 .5;0 1 .6;.5 .6 1];
So how can I plot such object in 3D space?

Is there some function to achieve this?

Thanks.

Fred



From ben at zoo.ufl.edu  Thu Dec  5 20:06:03 2002
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Thu Dec  5 20:06:03 2002
Subject: [R] [R]How to plot a 3D ellipsoid in R?
In-Reply-To: <015d01c29c87$b8f9eca0$8bd75ba5@IE.TAMU.EDU>
Message-ID: <Pine.LNX.4.44.0212051331170.5913-100000@bolker.zoo.ufl.edu>

  R is not particularly good for this task.  Search the mailing list
archives for solutions ... Duncan Murdoch has a package called rgl that
works under Windows with OpenGL, but as far as I can tell you'd still have
to write your own function to put together the primitives for an ellipsoid
(http://www.stats.uwo.ca/faculty/murdoch/software/).  Another choice is my
LG3d package, in the bbmisc bundle at http://www.zoo.ufl.edu/bolker/R/src 
or /windows, which constructs an HTML file which can be dynamically 
rotated with a Java applet from elsewhere.

  Mathematica, Maple, Matlab ( ... I don't know what Octave's capabilities 
are in this regard ...) are other possibilities.

  Ben



On Thu, 5 Dec 2002, Feng Zhang wrote:

> Hey, all
> 
> I am going to plot several 3-dimensional ellipsoids
> in R.
> For example, A is such a ellipsoid with
> mean u=[1 1 1]', covariance matrix C=[1 0 .5;0 1 .6;.5 .6 1];
> So how can I plot such object in 3D space?
> 
> Is there some function to achieve this?
> 
> Thanks.
> 
> Fred
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From Mark.Wilkinson at stjude.org  Thu Dec  5 20:10:03 2002
From: Mark.Wilkinson at stjude.org (Wilkinson, Mark)
Date: Thu Dec  5 20:10:03 2002
Subject: [R] Passing options as lists
Message-ID: <A1DAD6685C12D511B20F00034725151380CD28@sjmemexc3.stjude.org>

Hi,

I apologize if this has previously been posted.  I've just subscribed to the
R-help digest.

I'm writing a plotting function that uses layout() to plot several different
plots on the same device.  This function uses plot(), image(), and a custom
function that uses text().  Each cell of the layout needs different par()
parameters, so what I'd like to do is pass them as lists:

my.plot.func <- function(data1, data2, data3,
                         data1.options=list(),
                         data2.options=list(),
                         data3.options=list()) {

  ## call layout to divide the device

  ## plot data1 with par options in data1.options
  ## plot data2 with par options in data2.options
  ## plot data3 with par options in data3.options

}

my.plot.func(data1, data2, data3, data1.options=list(arg1=12, arg2=FALSE,
cex=.8, las=3), data2.options=list(cex=2, lwd=3))

'. . .' wouldn't seem to work.

How can the user set the options with provided values, while retaining the
default arg values?  This is what I'm trying, but doesn't seem to work in
all cases, especially for '. . .':

args.full <- function(func.name, opt.list) {
  form <-formals(func.name)
  ddd <- c()
  
  rtn <- sapply(union(names(form), names(opt.list)), function(arg) {
    if (is.null(opt.list[[arg]])) {  # not user-defined
      form[[arg]]
    } else if (is.null(form[[arg]])) { # user-defined '...'
      ddd <<- c(ddd, opt.list[[arg]])
    } else {
      opt.list[[arg]]
    }
  })
  
  rtn[["..."]] <- ddd
  return(rtn)
}

opt1.data1 <- args.full("internal.plot.func", data1.options)

Then, within the function, setting each value to the corresponding name from
the return value of the above function with eval(), e.g.,
internal.plot.func(data1, arg1=eval(opt.data1$arg1),
arg2=eval(opt.data1$arg2), eval(opt.data1$...)).

One problem is with '. . .'; those par parameters don't get passed.

I'd also like this to work in general, not just for passing plotting
parameters.  Let me know if I haven't been clear.

Thanks,

Mark Wilkinson
Informatics Analyst
St. Jude Children's Research Hospital
Department of Pharmaceutical Sciences



From rvaradha at jhsph.edu  Thu Dec  5 22:22:02 2002
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Thu Dec  5 22:22:02 2002
Subject: [R] Marginal structural models
Message-ID: <001601c29ca4$297c8070$1158120a@BSTE3005>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021205/3c55c6a7/attachment.pl

From deleeuw at stat.ucla.edu  Fri Dec  6 01:46:19 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Fri Dec  6 01:46:19 2002
Subject: [R] Darwin/X11/Cocoa binaries
Message-ID: <BBC776A0-08B3-11D7-A137-000393860F3C@stat.ucla.edu>

Major overhaul of

http;//gifi.stat.ucla.edu/pub

with R and (sometimes vaguely) R related binaries for
Jaguar  (Mac OS X 10.2.x). Unpack everything in root.

This has R-1.6.1 with 250+ packages, as well as the
dynamic libraries needed for R.bin, R_X11, and R_gnome.
The packages include RXLisp, RSPython, and RSPerl.

It has a framework build of Python-2.3, with TkInter, and with
Carbon/Cocoa versions of IDLE, PythonIDE, PythonLauncher,
and AppletBuilder. It also has site-packages for the Python-2.2
that comes standard with Jaguar, and these include Rpy,
(R programming from Python), Numeric, and Pyobjc (Cocoa programming
from Python).

It has a framework build of Tcl/Tk 8.4.1, where Tk is AquaTk (no X11),
which comes with a Cocoa Wish Shell. The frameworks can be
used to build a Darwin R with native (no X11) support for Tcl/Tk.

It has a build of Ruby-1.7.3, with RubyCocoa (Cocoa programming
from Ruby). Ruby has no R support yet, but it would be nice if it
had. Such a nice language.

It also has a Jaguar build of XLISP-STAT-3.52.18 (currently without
support for R, I hope to add RXLisp).

No Perl yet, because I am waiting for some upgrades.
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------



From alain.guerreau at fnac.net  Fri Dec  6 11:23:02 2002
From: alain.guerreau at fnac.net (guerreau)
Date: Fri Dec  6 11:23:02 2002
Subject: [R] smooth curves
Message-ID: <001b01c29d11$4ca87af0$174bcbd5@jetzt0>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021206/5594e23a/attachment.pl

From luke at inpharmatica.co.uk  Fri Dec  6 11:58:02 2002
From: luke at inpharmatica.co.uk (Luke Whitaker)
Date: Fri Dec  6 11:58:02 2002
Subject: [R] Collapsing levels of a factor
In-Reply-To: <20021204110012.14931.1125.Mailman@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.21.0212061036030.7297-100000@dollis-hill.inpharmatica.co.uk>

Hello,

I have a really trivial question, but I just cannot figure out
a safe and efficient solution:

I have a factor with four levels, and I want to create a new factor
that collapses the four levels down to two levels.

E.g Suppose my factor is x, with levels "A", "B", "C", "D", and I want
to create a new factor y with levels "P", "Q", such that when x is
"A" or "B" then y is "P" and when x is "C"  or "D" then y is "Q".

My solution is:

    y <- NULL
    for (i in 1:length(x))
    {
        # assuming no missing values or extraneous values in x[]
        if ( x[i] == "A" || x[i] == "B") y[i] <- "P"
        else y[i] <- "Q"
    }
    y <- factor(y)
    
This is inelegant and also very slow (I have many records).
I'm sure there is an efficient one-liner, but I just cannot see it.
I want to use the factor in a regression model (initially lm), if that
makes any difference.

Thanks,

Luke Whitaker
Inpharmatica



From ripley at stats.ox.ac.uk  Fri Dec  6 12:38:02 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Dec  6 12:38:02 2002
Subject: [R] Collapsing levels of a factor
In-Reply-To: <Pine.LNX.4.21.0212061036030.7297-100000@dollis-hill.inpharmatica.co.uk>
Message-ID: <Pine.LNX.4.31.0212061134450.6719-100000@gannet.stats>


From maechler at stat.math.ethz.ch  Fri Dec  6 12:53:02 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri Dec  6 12:53:02 2002
Subject: [R] smooth curves
In-Reply-To: <001b01c29d11$4ca87af0$174bcbd5@jetzt0>
References: <001b01c29d11$4ca87af0$174bcbd5@jetzt0>
Message-ID: <15856.36707.453311.734651@gargle.gargle.HOWL>

>>>>> "guerreau" == guerreau  <alain.guerreau at fnac.net>
>>>>>     on Fri, 6 Dec 2002 11:21:48 +0100 writes:

    guerreau> I would like to draw smooth curves instead of
    guerreau> polygons.  I could not find any spline function to
    guerreau> do that : given an x and a y vectors, they all
    guerreau> take the x in increasing order.  Is there a
    guerreau> function to draw a smooth curve through a set of
    guerreau> points in any order ?

I've always wanted to try the following.
Your e-mail prompted me to.

I attach an R source file that shows one solution,
using interpolating spline(s), 
one through (t, x(t))
the other   (t, y(t))

Repeatedly sourcing this file also shows you the limitation of
splines for this situation.
The functions are for your convenience to do more experiments.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: spline-non-function-curve.R
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021206/b5cdb74c/spline-non-function-curve.pl

From nolwenn.lemeur at nantes.inserm.fr  Fri Dec  6 13:57:03 2002
From: nolwenn.lemeur at nantes.inserm.fr (Nolwenn Le Meur)
Date: Fri Dec  6 13:57:03 2002
Subject: [R] Bitmap & Batch mode
Message-ID: <LMEBLNBEKKODLAONNGJMIELCCAAA.nolwenn.lemeur@nantes.inserm.fr>

Hi,
I had tried to print plot via postsript in Batch mode (under UNIX) but owing
to the help list I found out that was not the right thing to do. However
with bitmap() it still doesn't work. I running R in batch mode from a perl
script.I don't get any error and get my results but I can't find my plot
(mydata.png).
Is there a particular tmp directory where it might go ?
Do I have to reconfigure a specific R file with path for bitmap ?

Nolwenn

********************************************
Nolwenn Le Meur
INSERM U533
Facult? de m?decine
1, rue Gaston Veil
44035 Nantes Cedex 1
France

Tel: (+33)-2-40-41-29-86 (office)
     (+33)-2-40-41-28-44 (secretary)
Fax: (+33)-2-40-41-29-50
mail: nolwenn.lemeur at nantes.inserm.fr
********************************************



From mmiller3 at iupui.edu  Fri Dec  6 15:33:03 2002
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: Fri Dec  6 15:33:03 2002
Subject: [R] smooth curves
In-Reply-To: <001b01c29d11$4ca87af0$174bcbd5@jetzt0>
References: <001b01c29d11$4ca87af0$174bcbd5@jetzt0>
Message-ID: <87d6ofp7ek.fsf@lumen.indyrad.iupui.edu>

>>>>> "guerreau" == guerreau  <alain.guerreau at fnac.net> writes:

    > I would like to draw smooth curves instead of polygons.  I
    > could not find any spline function to do that : given an x
    > and a y vectors, they all take the x in increasing order.
    > Is there a function to draw a smooth curve through a set of
    > points in any order ?

The locfit package local regression, likelihood and density
estimation) can be used to that:

library(locfit)
data(ethanol)
fit <- locfit(NOx~E,data=ethanol)
plot(NOx~E,data=ethanol)
lines(fit)


Mike

-- 
Michael A. Miller                               mmiller3 at iupui.edu
  Imaging Sciences, Department of Radiology, IU School of Medicine



From wernberg at byggmek.lth.se  Fri Dec  6 15:37:01 2002
From: wernberg at byggmek.lth.se (Per-Anders Wernberg)
Date: Fri Dec  6 15:37:01 2002
Subject: [R] R 1.6.1 segmentation fault
Message-ID: <3DF0B1C7.F4661599@byggmek.lth.se>

Hi,
We have been running R ver 1.4.1 on a redhat linux (7.1)cluster without
problem for quit some time.
Now, some user wanted me to install version 1.6.1, and it compiled fine,
but it crashes with "segmentation fault" when you run it. I used gcc296
(default) for compiling, Should I change compiler or is there some other
thing I could do to  avoid this problem.

Regards
Per-Anders



From gregor.gawron at rmf.ch  Fri Dec  6 15:40:03 2002
From: gregor.gawron at rmf.ch (Gregor Gawron)
Date: Fri Dec  6 15:40:03 2002
Subject: [R] ts startdate
Message-ID: <3635AAE6EA743844B05655F805CB31250334847A@titlis.rmf.ch>

Dear R-users,

I am facing a trivial problem when trying to parameterise the start date
of a time series object. I am working with monthly data (104) performing
n-steps-ahead (6) forecasts and using a fixed window size (36). At the
end of calculations I have a list  that contains 69 forecasts.
I have no problems in fixing the window size by parametrization, e.g.

k<- control variable in a for loop
my.length<-36
past<-window(X,start=c(1980,k - my.length + 1),end=c(1980,k))

The integer defining the month number can be arbitrary set to: 6,16,46
etc and it always works. This, however, does not work when I try to
parameterise the start date of the result list

my.forecasts<-unlist(my.result.list) 
my.forecast.results<-ts(my.forecasts,start=c(1980,my.length+6),frequency
=12)

The message I recive is:

Error in ts(my.frecasts, start = c(1980, my.length + 6), frequency = 12)
: 
        invalid start

It seems that it works only for month integer up to 12. Does someone
know how to overcome this problem?
Many thanks in advance.

I am using R 1.5.1 on Windows 2000




---
Gregor Gawron



From jrogers at cantatapharm.com  Fri Dec  6 15:45:06 2002
From: jrogers at cantatapharm.com (Jim Rogers)
Date: Fri Dec  6 15:45:06 2002
Subject: [R] Mutiple page trellis plots with relation = "free" or "sliced"
Message-ID: <99A12772DCDEEB458B996332957B0D530116FF@mercury.cantatapharm.com>

Hello,

Has anyone out there encountered a problem like this:

xyplot(Plasma ~ Serum | Analyte,
       data = sp.df,
       aspect = 1,
       layout = c(1, 1, 200),
       scales = list(relation = "free")
       )

Gives the error: 

Error in pretty(x[is.finite(x)], ...) : x must be numeric

On the other hand, this works (but I don't want the default of having
everything on the same page):

xyplot(Plasma ~ Serum | Analyte,
       data = sp.df,
       aspect = 1,
       # layout = c(1, 1, 200),
       scales = list(relation = "free")
       )

and this works (but I don't want the default of using the same axes
limits for all plots):

xyplot(Plasma ~ Serum | Analyte,
       data = sp.df,
       aspect = 1,
       layout = c(1, 1, 200)
       # scales = list(relation = "free")
       )

For my present situation, I can work around this by creating multiple
plots in a loop, but I am wondering if I am missing something about the
way multi-page plots work. 

Thanks for any help. 

platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    6.1            
year     2002           
month    11             
day      01             
language R   

Jim Rogers

James A. Rogers, Ph.D. <rogers at cantatapharm.com>
Statistical Scientist
Cantata Pharmaceuticals
3-G Gill St
Woburn, MA  01801
617.225.9009
Fax 617.225.9010



From edd at debian.org  Fri Dec  6 16:08:03 2002
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri Dec  6 16:08:03 2002
Subject: [R] ts startdate
Message-ID: <E18KK4K-00061I-00@sonny.eddelbuettel.com>

> I am facing a trivial problem when trying to parameterise the start date
> of a time series object. I am working with monthly data (104) performing
> n-steps-ahead (6) forecasts and using a fixed window size (36). At the
> end of calculations I have a list  that contains 69 forecasts.
> I have no problems in fixing the window size by parametrization, e.g.
> 
> k<- control variable in a for loop
> my.length<-36
> past<-window(X,start=c(1980,k - my.length + 1),end=c(1980,k))
> 
> The integer defining the month number can be arbitrary set to: 6,16,46
> etc and it always works. This, however, does not work when I try to
> parameterise the start date of the result list
> 
> my.forecasts<-unlist(my.result.list) 
> my.forecast.results<-ts(my.forecasts,start=c(1980,my.length+6),frequency
> =12)
> 
> The message I recive is:
> 
> Error in ts(my.frecasts, start = c(1980, my.length + 6), frequency = 12)
> : 
>         invalid start
> 
> It seems that it works only for month integer up to 12. Does someone
> know how to overcome this problem?

I typically use offsets relative to tsp() output which is already in the
fractional format of year + 1/12*(months-1) whereas using the c(year,month)
notation has wrap-around issues.

The following (contrived) example works:

> Zbase<-ts(rnorm(110),start=c(1993,1),frequency=12)
> tsp(Zbase)
[1] 1993.000 2002.083   12.000
> for (i in 1:24) Zfcast<-ts(rnorm(110),start=tsp(Zbase)[2]+i/12,frequency=12)
> 

With that construct you can go any number of month past, or prior, a given
date.

Hope this helps,  Dirk

-- 
According to the latest figures, 43% of all signatures are totally worthless.



From ripley at stats.ox.ac.uk  Fri Dec  6 16:40:04 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Fri Dec  6 16:40:04 2002
Subject: [R] smooth curves
In-Reply-To: <87d6ofp7ek.fsf@lumen.indyrad.iupui.edu>
Message-ID: <Pine.WNT.4.44.0212061536020.3124-100000@petrel>

On 6 Dec 2002, Michael A. Miller wrote:

> >>>>> "guerreau" == guerreau  <alain.guerreau at fnac.net> writes:
>
>     > I would like to draw smooth curves instead of polygons.  I
>     > could not find any spline function to do that : given an x
>     > and a y vectors, they all take the x in increasing order.
>     > Is there a function to draw a smooth curve through a set of
>     > points in any order ?
>
> The locfit package local regression, likelihood and density
> estimation) can be used to that:
>
> library(locfit)
> data(ethanol)
> fit <- locfit(NOx~E,data=ethanol)
> plot(NOx~E,data=ethanol)
> lines(fit)

1) That package is in CRAN/Devel because it does not work (fully) with
current R.

2) Your example is of a *smoothed* fit, not of a smooth interpolating
curve.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gregor.gawron at rmf.ch  Fri Dec  6 17:09:18 2002
From: gregor.gawron at rmf.ch (Gregor Gawron)
Date: Fri Dec  6 17:09:18 2002
Subject: [R] ts startdate
Message-ID: <3635AAE6EA743844B05655F805CB31250334847B@titlis.rmf.ch>

Hi Dirk and Paul,

Thank you very, very much. Both methods seem to work excellent. You have
saved my weekend.
Paul, it sounds great that you are updating the dse package. I have
downloaded your documents a few weeks ago and had a look at them. There
were some issues I did not fully understand. As soon as I will have
completed the univariate project I will start with multivariate models,
which is scheduled to the beginning of next year. Then, I will give me
more time to understand it better and will surely return with some
questions.
Thanks again
Gregor
     



--------------------------
Gregor 

If my.length+6 was 15 you would do something like this.

 ts(1:20, start = c(1980 + 15 %/% 12 , 15 %% 12), frequency=12)

BTW, you might want to look at the functions featherForecasts and
horizonForecasts in package dse2 in the dse bundle on CRAN. (These may
be called feather.forecasts and horizon.forecasts in the version
currently on CRAN, I've changed some names recently. I hope to have a
new version out in a few weeks.) These do things very close to what you
appear to be trying, but the looping is done in the underlying fortran
code, so it is a lot faster.

Paul Gilbert

-----------------------


I typically use offsets relative to tsp() output which is already in the
fractional format of year + 1/12*(months-1) whereas using the
c(year,month) notation has wrap-around issues.

The following (contrived) example works:

> Zbase<-ts(rnorm(110),start=c(1993,1),frequency=12)
> tsp(Zbase)
[1] 1993.000 2002.083   12.000
> for (i in 1:24) 
> Zfcast<-ts(rnorm(110),start=tsp(Zbase)[2]+i/12,frequency=12)
> 

With that construct you can go any number of month past, or prior, a
given date.

Hope this helps,  Dirk

-----Original Message-----
From: Gregor Gawron 
Sent: Freitag, 6. Dezember 2002 15:39
To: r-help at stat.math.ethz.ch
Subject: [R] ts startdate


Dear R-users,

I am facing a trivial problem when trying to parameterise the start date
of a time series object. I am working with monthly data (104) performing
n-steps-ahead (6) forecasts and using a fixed window size (36). At the
end of calculations I have a list  that contains 69 forecasts. I have no
problems in fixing the window size by parametrization, e.g.

k<- control variable in a for loop
my.length<-36
past<-window(X,start=c(1980,k - my.length + 1),end=c(1980,k))

The integer defining the month number can be arbitrary set to: 6,16,46
etc and it always works. This, however, does not work when I try to
parameterise the start date of the result list

my.forecasts<-unlist(my.result.list) 
my.forecast.results<-ts(my.forecasts,start=c(1980,my.length+6),frequency
=12)

The message I recive is:

Error in ts(my.frecasts, start = c(1980, my.length + 6), frequency = 12)
: 
        invalid start

It seems that it works only for month integer up to 12. Does someone
know how to overcome this problem? Many thanks in advance.

I am using R 1.5.1 on Windows 2000




---
Gregor Gawron

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kjetilh at jupiter.umsanet.edu.bo  Fri Dec  6 17:21:03 2002
From: kjetilh at jupiter.umsanet.edu.bo (kjetilh@jupiter.umsanet.edu.bo)
Date: Fri Dec  6 17:21:03 2002
Subject: [R] Non-R question.
Message-ID: <1588.200.87.127.1.1039192718.squirrel@www.umsanet.edu.bo>

Hola!

I have a problem which is not strictly R, although R will be used for the
analysis.

We have data from a large investigation of drug abuse, initially
analyzed by logistic regression. But the pupils are selected by first
sampling schools, and as it happens the prevalence of use varies sharply
from school to school, so there is over-dispersion.

Now we are interested in comparing the prevalences estimated from this
study with prevalences from 3 earlier studies (93, 96, 99), which were
analysed assuming no overdispersion, withouyt investigating that issue.
For various reasons we can not get hold of the original databases from
those studies, only the published summary statistics. But we know the
structure of sampling were the same as in the 2002 study, so probaby the
overdispersion were the same (at least assuming that is the best I can
do).

So assuming equal overdispersion I can get four confidence interval s
of "binomial" p's, but people will want an hypothesis test of the overall
null: p_1=p_2=p_3=p_4. Is there some way I can construct an hypothesis test
for that null, from the four confidence intervals?

Hoping this is enough information of the background, as the mail is
already to long!

Thanks,

Kjetil Halvorsen



From Timur.Elzhov at jinr.ru  Fri Dec  6 17:32:03 2002
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Fri Dec  6 17:32:03 2002
Subject: [R] Fitting 2D vs. 2D data with nls()
Message-ID: <20021206163324.GA8135@pcf004.jinr.ru>

Dear R-experts!

I have y(x) data, dim(y) == dim(x) == c(2000, 2)
I'd like to fit them with nls:

fit.result <- nls ( y ~ f(x, p1, p2, p3),
                    start = list(p1 = ... , p2 = .. , p3 = ..)
                  )

Actually I want to fit y[,1] ~ x[,1] and y[,2] ~ x[,2]
*simulaneously*, with the same parameters set {p1, p2, p3}.

I tried to feed R tha above formula, R errors with:
>>  Error in qr.qty(QR, resid) : qr and y must have the same number of rows

I'm sorry, but I don't understand anything about 'qr'.. :-(


So, is it posiible to decide my problem with nls()?
with other fitting function?


Thanks a lot,
Timur.



From friendly at yorku.ca  Fri Dec  6 17:38:03 2002
From: friendly at yorku.ca (Michael Friendly)
Date: Fri Dec  6 17:38:03 2002
Subject: [R] Controlling graphics parameters in lattice
References: <20021206110011.28562.65639.Mailman@hypatia.math.ethz.ch>
Message-ID: <3DF0D24A.B4F2F0E2@yorku.ca>

I'm just starting to work with lattice graphics, and am
having difficulty understanding how to control various graphic
parameters (font sizes, etc.).  [I'm actually using xyplot
via plot.effect() in the car package, and would like to be
able to set some global defaults.]

I read ?xyplot and ?trellis.par.set-- which contains no complete
list of parameters, just a reference to print(trellis.par.get())

> print(trellis.par.get())
$fontsize
$fontsize$default
[1] 10

I tried
> trellis.par.set("fontsize", 12)
>  data(quakes)
>      Depth <- equal.count(quakes$depth, number=8, overlap=.1)
>      xyplot(lat ~ long | Depth, data = quakes)

And this crashes the Rgui (Windows, R 1.6.1).  Is this a buglet
or did I do something wrong?

I then tried

>      xyplot(lat ~ long | Depth, data = quakes, scales=list(cex=1.5))

which makes the tick labels larger, but not the axis labels.

As well, I'm confused about why the following has no effect
on the background (from a fresh start):

> library(lattice)
> trellis.par.set("background", "white")
>  data(quakes)
>      Depth <- equal.count(quakes$depth, number=8, overlap=.1)
>      xyplot(lat ~ long | Depth, data = quakes)

Only after I've run xyplot once, I can repeat

> trellis.par.set("background", "white")
>      xyplot(lat ~ long | Depth, data = quakes)

and the background will change.

thanks,
-Michael
  
-- 
Michael Friendly              friendly at yorku.ca
York University               http://www.math.yorku.ca/SCS/friendly.html
Psychology Department
4700 Keele Street             Tel:  (416) 736-5115 x66249
Toronto, Ontario, M3J 1P3     Fax:  (416) 736-5814



From david.pearson at mail.nerc-essc.ac.uk  Fri Dec  6 18:06:11 2002
From: david.pearson at mail.nerc-essc.ac.uk (David Pearson)
Date: Fri Dec  6 18:06:11 2002
Subject: [R] How to scan concatenated(ish) vectors from a file?
References: <Pine.LNX.4.44.0212051331170.5913-100000@bolker.zoo.ufl.edu>
Message-ID: <3DF0D4FD.C01E51D@mail.nerc-essc.ac.uk>

Hi,

I have a text file containing lists of numbers with the
following structure:

a1,1   a1,2   a1,3   a1,4   a1,5 ...  a1,10
hm1,1  hm1,2  hm1,3  hm1,4  hm1,5 ... hm1,10
vm1,1  vm1,2  vm1,3  vm1,4  vm1,5 ... vm1,10
hx1,1  hx1,2  hx1,3  hx1,4  hx1,5 ... hx1,10
vx1,1  vx1,2  vx1,3  vx1,4  vx1,5 ... vx1,10
a2,1   a2,2   a2,3   a2,4   a2,5 ...  a2,10
hm2,1  hm2,2  hm2,3  hm2,4  hm2,5 ... hm2,10
vm2,1  vm2,2  vm2,3  vm2,4  vm2,5 ... vm2,10
hx2,1  hx2,2  hx2,3  hx2,4  hx2,5 ... hx2,10
vx2,1  vx2,2  vx2,3  vx2,4  vx2,5 ... vx2,10
a3,1   a3,2   a3,3   a3,4   a3,5 ...  a3,10
hm3,1  hm3,2  hm3,3  hm3,4  hm3,5 ... hm3,10
vm3,1  vm3,2  vm3,3  vm3,4  vm3,5 ... vm3,10
hx3,1  hx3,2  hx3,3  hx3,4  hx3,5 ... hx3,10
vx3,1  vx3,2  vx3,3  vx3,4  vx3,5 ... vx3,10

 ....... etc. .........

[I have pasted in a sample at the bottom of this mail]


That is, a 10-vector called a, then another called hm,
then one called vm, then one called hx, then one
called vx. 

Then there is another set of these five vectors, with
different values to the first, then a third set, and so
on.

I need to read these data into R, so that the
a-vectors form a matrix, the hm-vectors form a
matrix, and so on for vm, hx and vx.

It's as if the file contains five matrices that are
shuffled together in an ordered way, or interleaved,
and I want to unshuffle them.

I would be grateful for any advice on how to do this.


Regards
David Pearson,
University of Reading.



P.S. Example of first two repetitions:

     5.7746240000000   10.1944840000000    15.162860000000    19.972452000000
     24.969696000000    29.912084000000    34.990160000000    39.404248000000
     44.112800000000    51.705376000000
     221.05366300000    220.19684700000    218.72863700000    220.01943900000
     219.39893400000    218.72014800000    216.14767600000    215.09151600000
     214.89631500000    212.08561000000
     225.58556100000    223.46567500000    223.10528700000    223.30770900000
     221.60718200000    220.22865200000    217.55770500000    217.62152000000
     214.41164200000    209.87299100000
    -37.552579604438   -37.503499426212   -37.415562374465   -37.297161479559
    -37.139615098163   -36.950400331994   -36.724961035885   -36.509462976145
    -36.271029656279   -35.924838154422
    -37.618462088024   -37.708809366317   -37.869534364650   -38.083765603156
    -38.365379855039   -38.699298090554   -39.092923514193   -39.467900666263
    -39.887743069578   -40.551769666575
     5.1221840000000   10.1482920000000    15.315864000000    20.059060000000
     24.911956000000    29.834140000000    34.926648000000    40.027820000000
     44.981760000000    50.039628000000
     217.77643200000    218.39942900000    217.25389100000    218.11937400000
     218.47274000000    217.84758300000    216.54347200000    216.35888900000
     213.71289700000    212.37202300000
     220.74927700000    222.57766100000    222.07754500000    220.31385300000
     218.94588500000    219.35492500000    217.76563000000    215.84143400000
     214.52370500000    207.70436600000
    -48.400213454151   -48.371561781272   -48.320829545540   -48.253127540243
    -48.159889727331   -48.036491839658   -47.872856930063   -47.666010941283
    -47.418517030988   -47.116296503712
    -48.423571606915   -48.463583233282   -48.531684767151   -48.617406380304
    -48.726522122527   -48.856438207434   -49.005897285660   -49.161753650923
    -49.304896404495   -49.420843878184



From gregor.gawron at rmf.ch  Fri Dec  6 18:09:54 2002
From: gregor.gawron at rmf.ch (Gregor Gawron)
Date: Fri Dec  6 18:09:54 2002
Subject: [R] ts startdate
Message-ID: <3635AAE6EA743844B05655F805CB31250334847C@titlis.rmf.ch>

Thanks Patrik,

 Great. It works too.

Gregor


-----Original Message-----
From: Patrick Burns [mailto:pburns at pburns.seanet.com] 
Sent: Freitag, 6. Dezember 2002 17:32
To: Gregor Gawron
Subject: Re: [R] ts startdate


I just realised that I had the English wrong in my message to you -- it 
should be:

what you want minus one

NOT

one minus what you want


Pat


Gregor Gawron wrote:

>Dear R-users,
>
>I am facing a trivial problem when trying to parameterise the start 
>date of a time series object. I am working with monthly data (104) 
>performing n-steps-ahead (6) forecasts and using a fixed window size 
>(36). At the end of calculations I have a list  that contains 69 
>forecasts. I have no problems in fixing the window size by 
>parametrization, e.g.
>
>k<- control variable in a for loop
>my.length<-36
>past<-window(X,start=c(1980,k - my.length + 1),end=c(1980,k))
>
>The integer defining the month number can be arbitrary set to: 6,16,46 
>etc and it always works. This, however, does not work when I try to 
>parameterise the start date of the result list
>
>my.forecasts<-unlist(my.result.list)
>my.forecast.results<-ts(my.forecasts,start=c(1980,my.length+6),frequenc
y
>=12)
>
>The message I recive is:
>
>Error in ts(my.frecasts, start = c(1980, my.length + 6), frequency = 
>12)
>: 
>        invalid start
>
>It seems that it works only for month integer up to 12. Does someone 
>know how to overcome this problem? Many thanks in advance.
>
>I am using R 1.5.1 on Windows 2000
>
>
>
>
>---
>Gregor Gawron
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list 
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From pan at mathstat.dal.ca  Fri Dec  6 18:13:02 2002
From: pan at mathstat.dal.ca (Pantelis Andreou)
Date: Fri Dec  6 18:13:02 2002
Subject: [R] fast code
Message-ID: <Pine.GSO.3.96.1021206130810.29907A-100000@chase>

Hello,
I have two vectors x1 and x2 both in increasing order.
I want to select the x1[j]th entry which is the max min of the x2[i]th
entry. I can do this using if and for statements but is there a quick way
to do it without running a loop?
Thank you in advance,
Pantelis



From Timur.Elzhov at jinr.ru  Fri Dec  6 18:40:03 2002
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Fri Dec  6 18:40:03 2002
Subject: [R] fast code
In-Reply-To: <Pine.GSO.3.96.1021206130810.29907A-100000@chase>
References: <Pine.GSO.3.96.1021206130810.29907A-100000@chase>
Message-ID: <20021206174126.GB8348@pcf004.jinr.ru>

On Fri, Dec 06, 2002 at 01:12:27PM -0400, Pantelis Andreou wrote:

> I have two vectors x1 and x2 both in increasing order.
> I want to select the x1[j]th entry which is the max min of the x2[i]th
> entry. I can do this using if and for statements but is there a quick way
> to do it without running a loop?
Use `which' function:

x1[which(x2 == max(x2))]


WBR,
Timur.



From ripley at stats.ox.ac.uk  Fri Dec  6 18:51:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Dec  6 18:51:03 2002
Subject: [R] Controlling graphics parameters in lattice
In-Reply-To: <3DF0D24A.B4F2F0E2@yorku.ca>
Message-ID: <Pine.LNX.4.31.0212061743210.1687-100000@gannet.stats>

On Fri, 6 Dec 2002, Michael Friendly wrote:

> I'm just starting to work with lattice graphics, and am
> having difficulty understanding how to control various graphic
> parameters (font sizes, etc.).  [I'm actually using xyplot
> via plot.effect() in the car package, and would like to be
> able to set some global defaults.]
>
> I read ?xyplot and ?trellis.par.set-- which contains no complete
> list of parameters, just a reference to print(trellis.par.get())
>
> > print(trellis.par.get())
> $fontsize
> $fontsize$default
> [1] 10
>
> I tried
> > trellis.par.set("fontsize", 12)
> >  data(quakes)
> >      Depth <- equal.count(quakes$depth, number=8, overlap=.1)
> >      xyplot(lat ~ long | Depth, data = quakes)
>
> And this crashes the Rgui (Windows, R 1.6.1).  Is this a buglet
> or did I do something wrong?

Both.  Try
trellis.par.set("fontsize", list(default=12))

but it is a bug in the grid package.

> As well, I'm confused about why the following has no effect
> on the background (from a fresh start):
>
> > library(lattice)

You need to open the device whose background you are trying to change:

trellis.device()

> > trellis.par.set("background", "white")
> >  data(quakes)
> >      Depth <- equal.count(quakes$depth, number=8, overlap=.1)
> >      xyplot(lat ~ long | Depth, data = quakes)
>
> Only after I've run xyplot once, I can repeat
>
> > trellis.par.set("background", "white")
> >      xyplot(lat ~ long | Depth, data = quakes)
>
> and the background will change.

That should be detected (no trellis device open) and give an error or open
a device.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Fri Dec  6 18:58:02 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri Dec  6 18:58:02 2002
Subject: [R] fast code {for max/min finding}
In-Reply-To: <20021206174126.GB8348@pcf004.jinr.ru>
References: <Pine.GSO.3.96.1021206130810.29907A-100000@chase>
	<20021206174126.GB8348@pcf004.jinr.ru>
Message-ID: <15856.58620.382328.631818@gargle.gargle.HOWL>

>>>>> "Timur" == Timur Elzhov <Timur.Elzhov at jinr.ru>
>>>>>     on Fri, 6 Dec 2002 20:41:26 +0300 writes:

    Timur> On Fri, Dec 06, 2002 at 01:12:27PM -0400, Pantelis
    Timur> Andreou wrote:
    >> I have two vectors x1 and x2 both in increasing order.  I
    >> want to select the x1[j]th entry which is the max min of
    >> the x2[i]th entry. I can do this using if and for
    >> statements but is there a quick way to do it without
    >> running a loop?
    Timur> Use `which' function:

    Timur> x1[which(x2 == max(x2))]
which is equivalent to the {shorter/faster}
	   x1[x2 == max(x2)]

If this is what he meant, an even faster solution might be

   x1[which.max(x2)]

Note that this however might be different! 
If the maximum is not unique, Timur's proposal returns a vector
of length > 1, where which.max(.) always returns the location of
the *first* maximum in x2.


Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From pan at mathstat.dal.ca  Fri Dec  6 19:10:03 2002
From: pan at mathstat.dal.ca (Pantelis Andreou)
Date: Fri Dec  6 19:10:03 2002
Subject: [R] fast code
Message-ID: <Pine.GSO.3.96.1021206140050.724A-100000@chase>

Hello again,
I think I made a mistake discribing the problem.
I have two column vectors x1 and x2 both in increasing order. 
I need a column vector x3 such that
the jth entry of x3 is the maximum ith entry x1 which is smaller
than the jth entry of x2.
Regards,
Pantelis



From Timur.Elzhov at jinr.ru  Fri Dec  6 19:17:03 2002
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Fri Dec  6 19:17:03 2002
Subject: [R] fast code {for max/min finding}
In-Reply-To: <15856.58620.382328.631818@gargle.gargle.HOWL>
References: <Pine.GSO.3.96.1021206130810.29907A-100000@chase> <20021206174126.GB8348@pcf004.jinr.ru> <15856.58620.382328.631818@gargle.gargle.HOWL>
Message-ID: <20021206181833.GA8519@pcf004.jinr.ru>

On Fri, Dec 06, 2002 at 06:57:16PM +0100, Martin Maechler wrote:

>     Timur> On Fri, Dec 06, 2002 at 01:12:27PM -0400, Pantelis
>     Timur> Andreou wrote:
>     >> I have two vectors x1 and x2 both in increasing order.  I
>     >> want to select the x1[j]th entry which is the max min of
>     >> the x2[i]th entry. I can do this using if and for
>     >> statements but is there a quick way to do it without
>     >> running a loop?
>     Timur> Use `which' function:
> 
>     Timur> x1[which(x2 == max(x2))]
> which is equivalent to the {shorter/faster}
> 	   x1[x2 == max(x2)]
Great! but, if length(x1) >> length(x2) you'll get in surprise.
Try, for instance (suppose, length(x2) == 2):

R>  c(1,2,3,4,5,6,7,8)[c(TRUE,FALSE)]
[1] 1 3 5 7

> If this is what he meant, an even faster solution might be
> 
>    x1[which.max(x2)]
> 
> Note that this however might be different! 
> If the maximum is not unique, Timur's proposal returns a vector
> of length > 1, where which.max(.) always returns the location of
> the *first* maximum in x2.
Ok, that's useful example, thanks :)


Timur.



From jkawczak at uncc.edu  Fri Dec  6 19:19:03 2002
From: jkawczak at uncc.edu (Janusz Kawczak)
Date: Fri Dec  6 19:19:03 2002
Subject: [R] fast code
In-Reply-To: <Pine.GSO.3.96.1021206140050.724A-100000@chase>
Message-ID: <Pine.SOL.4.44.0212061317160.7052-100000@ws80.uncc.edu>

Example would help!

On Fri, 6 Dec 2002, Pantelis Andreou wrote:

> Date: Fri, 6 Dec 2002 14:09:22 -0400 (AST)
> From: Pantelis Andreou <pan at mathstat.dal.ca>
> To: r-help at stat.math.ethz.ch
> Subject: [R] fast code
>
> Hello again,
> I think I made a mistake discribing the problem.
> I have two column vectors x1 and x2 both in increasing order.
> I need a column vector x3 such that
> the jth entry of x3 is the maximum ith entry x1 which is smaller
> than the jth entry of x2.
> Regards,
> Pantelis
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From pan at mathstat.dal.ca  Fri Dec  6 19:22:03 2002
From: pan at mathstat.dal.ca (Pantelis Andreou)
Date: Fri Dec  6 19:22:03 2002
Subject: [R] fast code
In-Reply-To: <Pine.SOL.4.44.0212061317160.7052-100000@ws80.uncc.edu>
Message-ID: <Pine.GSO.3.96.1021206142026.724D-100000@chase>

Hello again,
here is an example
x1      x2      x3
3       3.1     3
4       4.2     4
6.5     5	4
20      24	20
35      38	35


On Fri, 6 Dec 2002, Janusz Kawczak wrote:

> Example would help!
> 
> On Fri, 6 Dec 2002, Pantelis Andreou wrote:
> 
> > Date: Fri, 6 Dec 2002 14:09:22 -0400 (AST)
> > From: Pantelis Andreou <pan at mathstat.dal.ca>
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] fast code
> >
> > Hello again,
> > I think I made a mistake discribing the problem.
> > I have two column vectors x1 and x2 both in increasing order.
> > I need a column vector x3 such that
> > the jth entry of x3 is the maximum ith entry x1 which is smaller
> > than the jth entry of x2.
> > Regards,
> > Pantelis
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
>



From bates at stat.wisc.edu  Fri Dec  6 19:23:50 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri Dec  6 19:23:50 2002
Subject: [R] Fitting 2D vs. 2D data with nls()
In-Reply-To: <20021206163324.GA8135@pcf004.jinr.ru>
References: <20021206163324.GA8135@pcf004.jinr.ru>
Message-ID: <6r1y4v6mbf.fsf@bates5.stat.wisc.edu>

Timur Elzhov <Timur.Elzhov at jinr.ru> writes:

> Dear R-experts!
> 
> I have y(x) data, dim(y) == dim(x) == c(2000, 2)
> I'd like to fit them with nls:
> 
> fit.result <- nls ( y ~ f(x, p1, p2, p3),
>                     start = list(p1 = ... , p2 = .. , p3 = ..)
>                   )
> 
> Actually I want to fit y[,1] ~ x[,1] and y[,2] ~ x[,2]
> *simulaneously*, with the same parameters set {p1, p2, p3}.
> 
> I tried to feed R tha above formula, R errors with:
> >>  Error in qr.qty(QR, resid) : qr and y must have the same number of rows

> I'm sorry, but I don't understand anything about 'qr'.. :-(

The error message is an internal error caused by the mismatch of
dimensions.  The nls function assumes that the left hand side of the
formula evaluates to a vector, not a matrix.  It happens that the
mismatch is detected within a manipulation of a QR decomposition.

> So, is it posiible to decide my problem with nls()?
> with other fitting function?

You probably want to use the Box-Draper multiresponse parameter
estimation criterion as described in chapter 4 of Bates and Watts,
"Nonlinear Regression Analysis and Its Applications", Wiley, 1988.
There is a generalization of the Gauss-Newton algorithm for
uniresponse nonlinear least squares given there. As far as I know that
algorithm has not been implemented in R.

You may want to try to minimize the determinant of the crossproduct of
the residual matrix directly with nlm or optim.  If the matrix of
observed responses is y and the matrix of predicted responses is
f(p1,p2,p3) then the Box-Draper criterion is
  prod(svd(y-f(p1,p2,p3), nu=0, nv=0)$d)^2

You wish to minimize that with respect to p1, p2, and p3.



From deepayan at stat.wisc.edu  Fri Dec  6 19:54:03 2002
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri Dec  6 19:54:03 2002
Subject: [R] Mutiple page trellis plots with relation = "free" or "sliced"
In-Reply-To: <99A12772DCDEEB458B996332957B0D530116FF@mercury.cantatapharm.com>
References: <99A12772DCDEEB458B996332957B0D530116FF@mercury.cantatapharm.com>
Message-ID: <200212061254.32792.deepayan@stat.wisc.edu>

On Friday 06 December 2002 08:44 am, Jim Rogers wrote:
> Hello,
>
> Has anyone out there encountered a problem like this:
>
> xyplot(Plasma ~ Serum | Analyte,
>        data = sp.df,
>        aspect = 1,
>        layout = c(1, 1, 200),
>        scales = list(relation = "free")
>        )
>
> Gives the error:
>
> Error in pretty(x[is.finite(x)], ...) : x must be numeric
>
> On the other hand, this works (but I don't want the default of having
> everything on the same page):
>
> xyplot(Plasma ~ Serum | Analyte,
>        data = sp.df,
>        aspect = 1,
>        # layout = c(1, 1, 200),
>        scales = list(relation = "free")
>        )
>
> and this works (but I don't want the default of using the same axes
> limits for all plots):
>
> xyplot(Plasma ~ Serum | Analyte,
>        data = sp.df,
>        aspect = 1,
>        layout = c(1, 1, 200)
>        # scales = list(relation = "free")
>        )
>
> For my present situation, I can work around this by creating multiple
> plots in a loop, but I am wondering if I am missing something about the
> way multi-page plots work.

No, this is supposed to work. I'm not sure where the problem might be, but it 
could have something to do with panels without any data in them. Does that 
happen in your case ?

> Thanks for any help.
>
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    6.1
> year     2002
> month    11
> day      01
> language R
>
> Jim Rogers
>
> James A. Rogers, Ph.D. <rogers at cantatapharm.com>
> Statistical Scientist
> Cantata Pharmaceuticals
> 3-G Gill St
> Woburn, MA  01801
> 617.225.9009
> Fax 617.225.9010
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From gregory_r_warnes at groton.pfizer.com  Fri Dec  6 20:00:03 2002
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Fri Dec  6 20:00:03 2002
Subject: [R] fast code
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C356@groexmb02.pfizer.com>

Perhaps this will do the trick:

> tmp <- data.frame(x1=c(3,4,6.5,20,35), x2=c(3.1,4.2,5,24,38) )
> attach(tmp)
> 
> tmp$x3 <- sapply( x2, function(val) max(x1[x1<val]) )
> 
> tmp
    x1   x2 x3
1  3.0  3.1  3
2  4.0  4.2  4
3  6.5  5.0  4
4 20.0 24.0 20
5 35.0 38.0 35

-G

> -----Original Message-----
> From: Pantelis Andreou [mailto:pan at mathstat.dal.ca]
> Sent: Friday, December 06, 2002 1:21 PM
> To: Janusz Kawczak
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] fast code
> 
> 
> Hello again,
> here is an example
> x1      x2      x3
> 3       3.1     3
> 4       4.2     4
> 6.5     5	4
> 20      24	20
> 35      38	35
> 
> 
> On Fri, 6 Dec 2002, Janusz Kawczak wrote:
> 
> > Example would help!
> > 
> > On Fri, 6 Dec 2002, Pantelis Andreou wrote:
> > 
> > > Date: Fri, 6 Dec 2002 14:09:22 -0400 (AST)
> > > From: Pantelis Andreou <pan at mathstat.dal.ca>
> > > To: r-help at stat.math.ethz.ch
> > > Subject: [R] fast code
> > >
> > > Hello again,
> > > I think I made a mistake discribing the problem.
> > > I have two column vectors x1 and x2 both in increasing order.
> > > I need a column vector x3 such that
> > > the jth entry of x3 is the maximum ith entry x1 which is smaller
> > > than the jth entry of x2.
> > > Regards,
> > > Pantelis
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > >
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this message is ... [[dropped]]



From rangrej at exchange.cheo.on.ca  Fri Dec  6 20:17:03 2002
From: rangrej at exchange.cheo.on.ca (Rangrej, Jagadish)
Date: Fri Dec  6 20:17:03 2002
Subject: [R] Unequal sized three plots in a window
Message-ID: <A032D3A4B7F0D411B9360008C71E3DA50686AA43@cheont3.cheo.on.ca>

Dear all:

I want to divide the graphing window in to three plots such that two plots
are on the top and one at the bottom. The upper two plots are of equal sizes
that cover 50% of the Window, third plot spans the lower half portion of the
Window completely.

How do I do that, I tried layout and other options but they seem to have the
matrix options which does not solve my problem.

Any help or pointer will be greatly appreciated.

Thank you,
-Jag



From jrogers at cantatapharm.com  Fri Dec  6 20:22:03 2002
From: jrogers at cantatapharm.com (Jim Rogers)
Date: Fri Dec  6 20:22:03 2002
Subject: [R] Mutiple page trellis plots with relation = "free" or "sliced"
Message-ID: <99A12772DCDEEB458B996332957B0D53011700@mercury.cantatapharm.com>

Yes. The number of pages in my layout argument (200) was greater than
the number of unique values in my conditioning variable (168). Changing
to layout = c(1, 1, 168) solves the problem. 

Very sorry, I should have thought of that. 

Thanks so much for your response, and many, many thanks for implementing
lattice. It is incredibly powerful and a joy to use. 

Jim 

-----Original Message-----
From: Deepayan Sarkar [mailto:deepayan at stat.wisc.edu] 
Sent: Friday, December 06, 2002 1:55 PM
To: Jim Rogers; r-help at stat.math.ethz.ch
Subject: Re: [R] Mutiple page trellis plots with relation = "free" or
"sliced"


On Friday 06 December 2002 08:44 am, Jim Rogers wrote:
> Hello,
>
> Has anyone out there encountered a problem like this:
>
> xyplot(Plasma ~ Serum | Analyte,
>        data = sp.df,
>        aspect = 1,
>        layout = c(1, 1, 200),
>        scales = list(relation = "free")
>        )
>
> Gives the error:
>
> Error in pretty(x[is.finite(x)], ...) : x must be numeric
>

No, this is supposed to work. I'm not sure where the problem might be,
but it 
could have something to do with panels without any data in them. Does
that 
happen in your case ?



From deepayan at stat.wisc.edu  Fri Dec  6 20:28:03 2002
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri Dec  6 20:28:03 2002
Subject: [R] Controlling graphics parameters in lattice
In-Reply-To: <3DF0D24A.B4F2F0E2@yorku.ca>
References: <20021206110011.28562.65639.Mailman@hypatia.math.ethz.ch> <3DF0D24A.B4F2F0E2@yorku.ca>
Message-ID: <200212061327.57476.deepayan@stat.wisc.edu>

On Friday 06 December 2002 10:37 am, Michael Friendly wrote:
> I'm just starting to work with lattice graphics, and am
> having difficulty understanding how to control various graphic
> parameters (font sizes, etc.).  [I'm actually using xyplot
> via plot.effect() in the car package, and would like to be
> able to set some global defaults.]
>
> I read ?xyplot and ?trellis.par.set-- which contains no complete
> list of parameters, just a reference to print(trellis.par.get())
>
> > print(trellis.par.get())
>
> $fontsize
> $fontsize$default
> [1] 10

I get a much longer list.

> I tried
>
> > trellis.par.set("fontsize", 12)
> >  data(quakes)
> >      Depth <- equal.count(quakes$depth, number=8, overlap=.1)
> >      xyplot(lat ~ long | Depth, data = quakes)
> And this crashes the Rgui (Windows, R 1.6.1).  Is this a buglet
> or did I do something wrong?

You are doing this wrong. ?trellis.par.set gives an example of usage:


     `trellis.par.get' is usually used inside trellis functions to get
     graphical parameters before plotting. Modifications by users via
     `trellis.par.set' is typically done as follows:


     `add.line <- trellis.par.get("add.line")'

     `add.line$col <- "red"'

     `add.line <- trellis.par.set("add.line", add.line)'

(the assignment in the last line is redundant, sorry about that)

Your example, adapted to look like this, would have been:


fsize <- trellis.par.get("fontsize")
fsize$default <- 12
trellis.par.set("fontsize", fsize)

The point you are missing is the value argument to trellis.par.set should be a 
list, even when it has only one component. (I will change trellis.par.set to 
complain when value is not a list.)

A slightly easier way to do this is use

lset(list(fontsize = list(default = 12)))

(This becomes useful when the parameter you are changing has many components,  
but you are changing only one or two.)


> I then tried
>
> >      xyplot(lat ~ long | Depth, data = quakes, scales=list(cex=1.5))
>
> which makes the tick labels larger, but not the axis labels.

That goes into xlab / ylab.

> As well, I'm confused about why the following has no effect
>
> on the background (from a fresh start):
> > library(lattice)
> > trellis.par.set("background", "white")

Same reason. Should be 

trellis.par.set("background", list(col = "white"))

or

lset(list(background = list(col = "white"))

> >  data(quakes)
> >      Depth <- equal.count(quakes$depth, number=8, overlap=.1)
> >      xyplot(lat ~ long | Depth, data = quakes)
>
> Only after I've run xyplot once, I can repeat
>
> > trellis.par.set("background", "white")
> >      xyplot(lat ~ long | Depth, data = quakes)

Probably has to do with the fact that 

trellis.par.get("background")$col is now NULL.

Deepayan



From rpeng at stat.ucla.edu  Fri Dec  6 20:30:12 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Fri Dec  6 20:30:12 2002
Subject: [R] Unequal sized three plots in a window
In-Reply-To: <A032D3A4B7F0D411B9360008C71E3DA50686AA43@cheont3.cheo.on.ca>
Message-ID: <Pine.GSO.4.10.10212061124460.11499-100000@fisher.stat.ucla.edu>

layout() may be able to do what you want (I'm not sure), but also see the
help page for split.screen(), which I'm sure does what you want.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Fri, 6 Dec 2002, Rangrej, Jagadish wrote:

> 
> Dear all:
> 
> I want to divide the graphing window in to three plots such that two plots
> are on the top and one at the bottom. The upper two plots are of equal sizes
> that cover 50% of the Window, third plot spans the lower half portion of the
> Window completely.
> 
> How do I do that, I tried layout and other options but they seem to have the
> matrix options which does not solve my problem.
> 
> Any help or pointer will be greatly appreciated.
> 
> Thank you,
> -Jag
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From Timur.Elzhov at jinr.ru  Fri Dec  6 20:32:03 2002
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Fri Dec  6 20:32:03 2002
Subject: [R] Fitting 2D vs. 2D data with nls()
In-Reply-To: <D7A3CFD7825BD6119B880002A58F06C202F2C357@groexmb02.pfizer.com>
References: <D7A3CFD7825BD6119B880002A58F06C202F2C357@groexmb02.pfizer.com>
Message-ID: <20021206193251.GA8862@pcf004.jinr.ru>

On Fri, Dec 06, 2002 at 01:57:28PM -0500, Warnes, Gregory R wrote:

> > Actually I want to fit y[,1] ~ x[,1] and y[,2] ~ x[,2]
> > *simulaneously*, with the same parameters set {p1, p2, p3}.
> Do you want to get separate estimates of p1, p2, and p3:
> 
> 	one set for y[,1] ~ x[,1] and a separate set for y[,2] ~ x[,2], 
> 
> or do you want to get 3 common parameter values?
> 
> For the latter, just do
> 
> fit.result <- nls ( as.vector(y) ~ f(as.vector(x), p1, p2, p3),
>                     start = list(p1 = ... , p2 = .. , p3 = ..)
> 
Yes! that is answer to question I posted! :-)
But.. I was actually wrong a bit, the situation is more
complicated:
I want *some* of the parameters to have common values,
and to be estimated seperately -- for the rest..

Thank you for your answer anyway, I couldn't guess
that simple solution even for common parameters.


WBR,
Timur



From matthew_wiener at merck.com  Fri Dec  6 20:34:02 2002
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Fri Dec  6 20:34:02 2002
Subject: [R] Unequal sized three plots in a window
Message-ID: <AEBD81486231A343B1813FE62D3352251E4947@usrymx15.merck.com>

layout() does solve your problem.  

Try something like layout(rbind(c(1,2), c(3,3))).
This puts plot 1 in the upper left, plot 2 in the upper right, and plot 3
across the bottom.  The key is that sections that have the same number are
combined for the graph.

You can use the height and width arguments if you want to make the sections
different heights or widths.

Hope this helps,

Matt Wiener

-----Original Message-----
From: Rangrej, Jagadish [mailto:rangrej at exchange.cheo.on.ca]
Sent: Friday, December 06, 2002 2:16 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Unequal sized three plots in a window



Dear all:

I want to divide the graphing window in to three plots such that two plots
are on the top and one at the bottom. The upper two plots are of equal sizes
that cover 50% of the Window, third plot spans the lower half portion of the
Window completely.

How do I do that, I tried layout and other options but they seem to have the
matrix options which does not solve my problem.

Any help or pointer will be greatly appreciated.

Thank you,
-Jag

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named in this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.



From hfeldman at conceptual.com  Fri Dec  6 21:48:05 2002
From: hfeldman at conceptual.com (hfeldman@conceptual.com)
Date: Fri Dec  6 21:48:05 2002
Subject: [R] (no subject)
Message-ID: <20021206204728.90506.qmail@psi.pair.com>

unsubscribe r-announce hfeldman at conceptual.com



From reid_huntsinger at merck.com  Fri Dec  6 22:27:03 2002
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Fri Dec  6 22:27:03 2002
Subject: [R] fast code
Message-ID: <2C23DE2983BE034CB1CB90DB6B813FD6028AC268@uswpmx11.merck.com>

You could use "cut" as follows:

i <- cut(x2,c(x1,Inf),labels=FALSE)

to get the intervals of x1 into which the
entries of x2 fall, then

x3 <- x1[i]

to get the left endpoints. This will give NA for elements of
x2 smaller than any element of x1, which I think you want. 
You may want to play with the options to "cut" to get the
right behavior for exact equality between elements of x1 and x2.

Note x2 need not be sorted. I don't see a way to take advantage
of sorted x2 without explicit looping.

Reid Huntsinger



-----Original Message-----
From: Pantelis Andreou [mailto:pan at mathstat.dal.ca]
Sent: Friday, December 06, 2002 1:21 PM
To: Janusz Kawczak
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] fast code


Hello again,
here is an example
x1      x2      x3
3       3.1     3
4       4.2     4
6.5     5	4
20      24	20
35      38	35


On Fri, 6 Dec 2002, Janusz Kawczak wrote:

> Example would help!
> 
> On Fri, 6 Dec 2002, Pantelis Andreou wrote:
> 
> > Date: Fri, 6 Dec 2002 14:09:22 -0400 (AST)
> > From: Pantelis Andreou <pan at mathstat.dal.ca>
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] fast code
> >
> > Hello again,
> > I think I made a mistake discribing the problem.
> > I have two column vectors x1 and x2 both in increasing order.
> > I need a column vector x3 such that
> > the jth entry of x3 is the maximum ith entry x1 which is smaller
> > than the jth entry of x2.
> > Regards,
> > Pantelis
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named in this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.



From p.dalgaard at biostat.ku.dk  Fri Dec  6 23:21:03 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Dec  6 23:21:03 2002
Subject: [R] How to scan concatenated(ish) vectors from a file?
In-Reply-To: <3DF0D4FD.C01E51D@mail.nerc-essc.ac.uk>
References: <Pine.LNX.4.44.0212051331170.5913-100000@bolker.zoo.ufl.edu>
	<3DF0D4FD.C01E51D@mail.nerc-essc.ac.uk>
Message-ID: <x2hedqssau.fsf@biostat.ku.dk>

David Pearson <david.pearson at mail.nerc-essc.ac.uk> writes:

> Hi,
> 
> I have a text file containing lists of numbers with the
> following structure:
> 
> a1,1   a1,2   a1,3   a1,4   a1,5 ...  a1,10
> hm1,1  hm1,2  hm1,3  hm1,4  hm1,5 ... hm1,10
> vm1,1  vm1,2  vm1,3  vm1,4  vm1,5 ... vm1,10
> hx1,1  hx1,2  hx1,3  hx1,4  hx1,5 ... hx1,10
> vx1,1  vx1,2  vx1,3  vx1,4  vx1,5 ... vx1,10
> a2,1   a2,2   a2,3   a2,4   a2,5 ...  a2,10

>  ....... etc. .........
> 
> [I have pasted in a sample at the bottom of this mail]

> I need to read these data into R, so that the
> a-vectors form a matrix, the hm-vectors form a
> matrix, and so on for vm, hx and vx.

Try:

arr <- array(scan(),c(10,5,2))
a <- arr[,1,]
hm <- arr[,2,]

and so forth. Or:

vlist <- lapply(1:5, function(i)a[,i,])
names(vlist) <- c("a","hm","vm","hx","vx")
vlist$a 
vlist$hm

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ozric at web.de  Sat Dec  7 00:32:02 2002
From: ozric at web.de (Christian Schulz)
Date: Sat Dec  7 00:32:02 2002
Subject: [R] for-loop ?
Message-ID: <005701c29d7f$0fdacc40$4e3f07d5@c5c9i0>

...why the loop produce NA's ?

>>healthy(25.47252)
[1] 0.764
>>healthy(26)
[1] 0.5

many thanks,christian

healthy <- function (x) {
+        if(x < 18)
+        {res <- 0 }
+        if(x >= 18 & x <= 20)
+        { res <- ((20-x)/2) }
+        if(x > 20 & x < 25)
+        { res <- 1 }
+        if(x >= 25 & x <= 27)
+         { res <- ((27-x)/2)}
+        if(x > 27) { res <- 0}
+              return(res)
+        }
>>
>>test[i] <- for (i in 1:30) {
+       healthy(i)
+       }
>>
>>test
 [1]  0 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
NA
[26] NA NA NA NA  0



From deepayan at stat.wisc.edu  Sat Dec  7 01:13:03 2002
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sat Dec  7 01:13:03 2002
Subject: [R] for-loop ?
In-Reply-To: <005701c29d7f$0fdacc40$4e3f07d5@c5c9i0>
References: <005701c29d7f$0fdacc40$4e3f07d5@c5c9i0>
Message-ID: <200212061812.48453.deepayan@stat.wisc.edu>

On Friday 06 December 2002 05:27 pm, Christian Schulz wrote:
> ...why the loop produce NA's ?
>
> >>test[i] <- for (i in 1:30) {
>
> +       healthy(i)
> +       }
>
> >>test
>
>  [1]  0 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
> NA NA
> [26] NA NA NA NA  0


You probably want to do


test <- numeric(30)

for (i in 1:30) {
    test[i] <- healthy(i)
}

-Deepayan



From hammour at msn.com  Sat Dec  7 06:19:03 2002
From: hammour at msn.com (Ahmad Abu Hammour)
Date: Sat Dec  7 06:19:03 2002
Subject: [R] some strange result
Message-ID: <DAV54cYGNuVZWGqjovo0000725d@hotmail.com>

Hi,
I use R 1.6.1 on my machine. While I working I got some strange result. Here
is a piece of a longer code:

minb=0.7; stpb=0.1
minw=0.7; maxw=1.0; stpw=0.1
nj=((1-minb)/stpb)+1
ni=((maxw-minw)/stpw)+1
solm=array(0,c(ni,5,nj))

Everything is OK but if you set minb, minw or both = 0.8 or 0.9

you will get the following error message:

"Error in array(0, c(ni, 5, nj)) : dim<- length of dims do not match the
length of object"

One more thing. Try to do the following to get another strange result.
as.integer((1-0.8)/0.1) which gives you 1 instead of 2.
as.integer((1-0.9)/0.1) which gives you 0 instead of 1.
as.integer((1-0.7)/0.1) which gives you 3 which is correct.

This could be a bug or just meant to be like that. I appreciate your help.

Ahmad Abu Hammour



From ripley at stats.ox.ac.uk  Sat Dec  7 08:50:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat Dec  7 08:50:03 2002
Subject: [R] some strange result
In-Reply-To: <DAV54cYGNuVZWGqjovo0000725d@hotmail.com>
Message-ID: <Pine.LNX.4.31.0212070744220.5124-100000@gannet.stats>

On Sat, 7 Dec 2002, Ahmad Abu Hammour wrote:

> Hi,
> I use R 1.6.1 on my machine. While I working I got some strange result. Here
> is a piece of a longer code:
>
> minb=0.7; stpb=0.1
> minw=0.7; maxw=1.0; stpw=0.1
> nj=((1-minb)/stpb)+1
> ni=((maxw-minw)/stpw)+1
> solm=array(0,c(ni,5,nj))
>
> Everything is OK but if you set minb, minw or both = 0.8 or 0.9
>
> you will get the following error message:
>
> "Error in array(0, c(ni, 5, nj)) : dim<- length of dims do not match the
> length of object"

Works on my machine, but not the dim arguments are supposed to be
integers and your calculations are subject to rounding error.

> One more thing. Try to do the following to get another strange result.
> as.integer((1-0.8)/0.1) which gives you 1 instead of 2.
> as.integer((1-0.9)/0.1) which gives you 0 instead of 1.
> as.integer((1-0.7)/0.1) which gives you 3 which is correct.
>
> This could be a bug or just meant to be like that. I appreciate your help.

?round may help you. as.integer is to do with storage mode, not rounding.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ozric at web.de  Sat Dec  7 10:29:03 2002
From: ozric at web.de (Christian Schulz)
Date: Sat Dec  7 10:29:03 2002
Subject: [R] fortran -> R
Message-ID: <000701c29dd2$810a3ce0$823d07d5@c5c9i0>

Hi,

i'm working with a interesting book from
Michael Smithson: "Fuzzy Set Analysis for Behavioral and Social
Sciences",1987.
with small listenings in Fortran.

It's a pitty that i'm more or less understand nothing from Fortran -
have anybody an sugestion or perhaps interesting (...incl. Fortran skills ?)
how
i can get it in R or Java.

Now anybody a Fortran2Java  translator, it seems that something like this
exist ?
The programs are written in Fortran77 for Dec-10 !

many thanks from suggestions,christian



From gb at stat.umu.se  Sat Dec  7 12:29:02 2002
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Sat Dec  7 12:29:02 2002
Subject: [R] fortran -> R
In-Reply-To: <000701c29dd2$810a3ce0$823d07d5@c5c9i0>
Message-ID: <Pine.LNX.4.44.0212071224250.4693-100000@tal.stat.umu.se>

On Sat, 7 Dec 2002, Christian Schulz wrote:

> Hi,
>
> i'm working with a interesting book from
> Michael Smithson: "Fuzzy Set Analysis for Behavioral and Social
> Sciences",1987.
> with small listenings in Fortran.
>
> It's a pitty that i'm more or less understand nothing from Fortran -
> have anybody an sugestion or perhaps interesting (...incl. Fortran skills ?)
> how
> i can get it in R or Java.

in R: Read "Writing R extensions" especially "...foreign language
interfaces", and look at ?.Fortran
>
> Now anybody a Fortran2Java  translator, it seems that something like this
> exist ?

Don't know anything about that.

> The programs are written in Fortran77 for Dec-10 !

Should be ok, if the code doesn't contain Dec extensions to the F77
standard. But you'll probably notice that at compile time :-)

G?ran



From david.meyer at ci.tuwien.ac.at  Sat Dec  7 14:41:02 2002
From: david.meyer at ci.tuwien.ac.at (David Meyer)
Date: Sat Dec  7 14:41:02 2002
Subject: [R] R 1.6.1 segmentation fault
References: <3DF0B1C7.F4661599@byggmek.lth.se>
Message-ID: <3DF1F9F4.956982C3@ci.tuwien.ac.at>

Per-Anders Wernberg wrote:
> 
> Hi,
> We have been running R ver 1.4.1 on a redhat linux (7.1)cluster without
> problem for quit some time.
> Now, some user wanted me to install version 1.6.1, and it compiled fine,
> but it crashes with "segmentation fault" when you run it. I used gcc296
> (default) for compiling, Should I change compiler

yes, definitely.

-d

> or is there some other
> thing I could do to  avoid this problem.
> 
> Regards
> Per-Anders
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
	Mag. David Meyer		Wiedner Hauptstrasse 8-10
Vienna University of Technology		A-1040 Vienna/AUSTRIA
         Department of			Tel.: (+431) 58801/10772
Statistics and Probability Theory	mail: david.meyer at ci.tuwien.ac.at



From george at lecompte.org  Sat Dec  7 19:09:02 2002
From: george at lecompte.org (George LeCompte)
Date: Sat Dec  7 19:09:02 2002
Subject: [R] simplex(boot) problem
Message-ID: <3DF23A02.4050609@lecompte.org>

The attached test6.r sets up input for simplex from boot package.  It's 
input file is short2A.txt.

Running under R 1.6.1 I get the following error message.

Error in simplex1 (out1$a[1:(n + m1 + m2)], out1$A[, 1:(n + m1 + m2)], :
          subscript out of bounds

Other calls to simplex seem to work properly

What am I doing wrong?
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: test6.R
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021207/03186d4c/test6.pl
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: short2A.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021207/03186d4c/short2A.txt

From ntakebay at bio.indiana.edu  Sat Dec  7 22:01:02 2002
From: ntakebay at bio.indiana.edu (Naoki Takebayashi)
Date: Sat Dec  7 22:01:02 2002
Subject: [R] bugs in system() handling long character strings??
Message-ID: <Pine.GSO.4.44.0212071550060.11487-100000@sunflower.bio.indiana.edu>

Hi,

system(cmd, intern=T) seems to have a problem when cmd returns a long
character string.

For example, if a file (/tmp/long.txt) contains a long string such as:

123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890

There are 120 characters in this one line.

> junk <- system("cat /tmp/long", TRUE)
> junk
[1] "1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678"
[2] "0"
> nchar(junk[1])
[1] 118

So one long line get separated into two parts, and additionally 119-th
character is missing.

Is this a bug in R or am I missing something?

I tried this on R-1.6.1 on linux/alpha and linux/i386.

Thanks,
Naoki

Naoki Takebayashi     <ntakebay at bio.indiana.edu>
--- Dept. of Biology, Box 90338, Duke University, Durham, NC 27708-0338



From ripley at stats.ox.ac.uk  Sat Dec  7 23:51:02 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat Dec  7 23:51:02 2002
Subject: [R] bugs in system() handling long character strings??
In-Reply-To: <Pine.GSO.4.44.0212071550060.11487-100000@sunflower.bio.indiana.edu>
Message-ID: <Pine.LNX.4.31.0212072246030.9481-100000@gannet.stats>

There is an undocumented limit of 119 characters/line when using
system(intern=TRUE) on Unix.  You can easily raise it: it is in
do_system in file src/unix/sys-unix.c.

I think this limit should be raised considerably, but it may well not be
worth eliminating it.

On Sat, 7 Dec 2002, Naoki Takebayashi wrote:

> Hi,
>
> system(cmd, intern=T) seems to have a problem when cmd returns a long
> character string.
>
> For example, if a file (/tmp/long.txt) contains a long string such as:
>
> 123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890
>
> There are 120 characters in this one line.
>
> > junk <- system("cat /tmp/long", TRUE)
> > junk
> [1] "1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678"
> [2] "0"
> > nchar(junk[1])
> [1] 118
>
> So one long line get separated into two parts, and additionally 119-th
> character is missing.
>
> Is this a bug in R or am I missing something?
>
> I tried this on R-1.6.1 on linux/alpha and linux/i386.
>
> Thanks,
> Naoki
>
> Naoki Takebayashi     <ntakebay at bio.indiana.edu>
> --- Dept. of Biology, Box 90338, Duke University, Durham, NC 27708-0338
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Richard.Rowe at jcu.edu.au  Sun Dec  8 04:52:03 2002
From: Richard.Rowe at jcu.edu.au (Richard Rowe)
Date: Sun Dec  8 04:52:03 2002
Subject: [R] color of plot axes involving POSIX types
Message-ID: <5.0.0.25.1.20021208130839.02d5ca60@pop.jcu.edu.au>

I am attempting to plot frequency of occurrence against (calendar) time. As 
the output is to be produced as a Powerpoint picture on a dark background I 
wish to make the plot output yellow

 > par(col="yellow", col.axis="yellow", col.lab="yellow", col.main="yellow")
 > plot(t2, t1, ylim=c(0,40), main="Episynlestes run 2", ylab="frequency", 
type="h", axes=FALSE, lwd=2)

where t2 is a vector of  POSIX type and t1 is the associated frequency.
This works *except* that the x axis is printed ... and in black

 > axis.POSIXct(1, t2, col="yellow")

makes the x axis yellow by overwriting, so I can get what I want 
(fortunately I didn't post this earlier when I was tied in a knot), but it 
doesn't seem elegant.

Any hints?

Thanks,

Richard


Richard Rowe
Senior Lecturer
Department of Zoology and Tropical Ecology, James Cook University
Townsville, Queensland 4811, Australia
fax (61)7 47 25 1570
phone (61)7 47 81 4851
e-mail: Richard.Rowe at jcu.edu.au
http://www.jcu.edu.au/school/tbiol/zoology/homepage.html



From fpgibson at umich.edu  Sun Dec  8 15:04:02 2002
From: fpgibson at umich.edu (Bud Gibson)
Date: Sun Dec  8 15:04:02 2002
Subject: [R] Warning:  as.numeric reorders factor data
Message-ID: <3DF35F5A.1060307@umich.edu>

Recently, I was using aggregate() to develop averages by trial for an 
experiment I was running.  Trials were indicated as ordinal numbers for 
each subject.  aggregate() turned trial into factors during the 
aggregation process.  I then wanted to create a scatter plot of subject 
performance by trial, so I applied as.numeric to the (now) factor 
variable trial.  as.numeric reordered the trial indicator creating some 
(at first) incomprehensible results.

Investigation revealed that aggregate must first be interpreting trial 
as a character and then turning it into a factor.  The behavior I 
observed is reproducible from the following transcript using R1.6.1 on 
RH linux 7.3.

 > test <- as.factor(as.character(c(1,2,3,4,5,6,7,8,9,10,11)))
 > test
  [1] 1  2  3  4  5  6  7  8  9  10 11
Levels: 1 10 11 2 3 4 5 6 7 8 9
 > as.numeric(test)
  [1]  1  4  5  6  7  8  9 10 11  2  3

It strikes me that as.numeric should *never* reorder the vector it is 
working on.  There is this workaround for the problem:

 > as.numeric(as.character(test))
  [1]  1  2  3  4  5  6  7  8  9 10 11

However, I should not have to know about the internals of aggregate to 
be able to use its results.

Bud Gibson



From p.dalgaard at biostat.ku.dk  Sun Dec  8 15:31:02 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Sun Dec  8 15:31:02 2002
Subject: [R] Warning:  as.numeric reorders factor data
In-Reply-To: <3DF35F5A.1060307@umich.edu>
References: <3DF35F5A.1060307@umich.edu>
Message-ID: <x24r9oshu5.fsf@biostat.ku.dk>

Bud Gibson <fpgibson at umich.edu> writes:

>  > test <- as.factor(as.character(c(1,2,3,4,5,6,7,8,9,10,11)))
>  > test
>   [1] 1  2  3  4  5  6  7  8  9  10 11
> Levels: 1 10 11 2 3 4 5 6 7 8 9
>  > as.numeric(test)
>   [1]  1  4  5  6  7  8  9 10 11  2  3
> 
> It strikes me that as.numeric should *never* reorder the vector it is
> working on.  There is this workaround for the problem:

as.numeric is not reordering anything. "2" is the 4th level of the
test factor, which in turn is due to alphabetic ordering of the
factor levels in as.factor() [or factor() for that matter]. If you
want to avoid that, set factor levels explicitly:

test <- factor(as.character(c(1:11)),levels=c(1:11))
test
as.numeric(test)

I suppose that similar treatment of your "trial" variable prior to 
calling aggregate() could solve your problem.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From fpgibson at umich.edu  Sun Dec  8 16:01:02 2002
From: fpgibson at umich.edu (Bud Gibson)
Date: Sun Dec  8 16:01:02 2002
Subject: [R] Warning:  as.numeric reorders factor data
In-Reply-To: <x24r9oshu5.fsf@biostat.ku.dk>
References: <3DF35F5A.1060307@umich.edu> <x24r9oshu5.fsf@biostat.ku.dk>
Message-ID: <3DF36CBB.7040007@umich.edu>

Thanks for the clarification.  It's nice to know that there is some 
systematicity to the behavior.

Is this documented anywhere?  I did look at the help for as.numeric, and 
it makes no mention that it is coercing factors based on their level. 
 This may be obvious to those deeply immersed in R and its machinations, 
but to those who think the number they see on the screen should just 
become a number when it is coerced to one, it is disconcerting.

Further, if I just factor the same vector, and then coerce it back to 
numeric, the order I would have expected is preserved.  I did not report 
that test because it seemed irrelevant.  Why isn't aggregate just doing 
that?

My cut is that there should be some warning in the documentation, 
perhaps in aggregate, about the specific assumptions used in making 
implicit transformations and what one can expect.

Peter Dalgaard BSA wrote:

>Bud Gibson <fpgibson at umich.edu> writes:
>
>  
>
>> > test <- as.factor(as.character(c(1,2,3,4,5,6,7,8,9,10,11)))
>> > test
>>  [1] 1  2  3  4  5  6  7  8  9  10 11
>>Levels: 1 10 11 2 3 4 5 6 7 8 9
>> > as.numeric(test)
>>  [1]  1  4  5  6  7  8  9 10 11  2  3
>>
>>It strikes me that as.numeric should *never* reorder the vector it is
>>working on.  There is this workaround for the problem:
>>    
>>
>
>as.numeric is not reordering anything. "2" is the 4th level of the
>test factor, which in turn is due to alphabetic ordering of the
>factor levels in as.factor() [or factor() for that matter]. If you
>want to avoid that, set factor levels explicitly:
>
>test <- factor(as.character(c(1:11)),levels=c(1:11))
>test
>as.numeric(test)
>
>I suppose that similar treatment of your "trial" variable prior to 
>calling aggregate() could solve your problem.
>
>  
>



From fharrell at virginia.edu  Sun Dec  8 16:07:03 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Sun Dec  8 16:07:03 2002
Subject: [R] Warning:  as.numeric reorders factor data
In-Reply-To: <3DF35F5A.1060307@umich.edu>
References: <3DF35F5A.1060307@umich.edu>
Message-ID: <20021208100700.3fa5be55.fharrell@virginia.edu>

On Sun, 08 Dec 2002 10:03:54 -0500
Bud Gibson <fpgibson at umich.edu> wrote:

> Recently, I was using aggregate() to develop averages by trial for an 
> experiment I was running.  Trials were indicated as ordinal numbers for 
> each subject.  aggregate() turned trial into factors during the 
> aggregation process.  I then wanted to create a scatter plot of subject 
> performance by trial, so I applied as.numeric to the (now) factor 
> variable trial.  as.numeric reordered the trial indicator creating some 
> (at first) incomprehensible results.
> 
> Investigation revealed that aggregate must first be interpreting trial 
> as a character and then turning it into a factor.  The behavior I 
> observed is reproducible from the following transcript using R1.6.1 on 
> RH linux 7.3.
> 
>  > test <- as.factor(as.character(c(1,2,3,4,5,6,7,8,9,10,11)))
>  > test
>   [1] 1  2  3  4  5  6  7  8  9  10 11
> Levels: 1 10 11 2 3 4 5 6 7 8 9
>  > as.numeric(test)
>   [1]  1  4  5  6  7  8  9 10 11  2  3
> 
> It strikes me that as.numeric should *never* reorder the vector it is 
> working on.  There is this workaround for the problem:
> 
>  > as.numeric(as.character(test))
>   [1]  1  2  3  4  5  6  7  8  9 10 11
> 
> However, I should not have to know about the internals of aggregate to 
> be able to use its results.
> 
> Bud Gibson

One of the reasons for being of the summarize function in the Hmisc library (http://hesweb1.med.virginia.edu/biostat/s/Hmisc.html) is that it preserves the nature of the stratification variables.  summarize produces data frames that are like the original data except with the response variables replaced by scalar or vector statistical summaries.
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From ripley at stats.ox.ac.uk  Sun Dec  8 17:34:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun Dec  8 17:34:03 2002
Subject: [R] Warning:  as.numeric reorders factor data
In-Reply-To: <3DF36CBB.7040007@umich.edu>
Message-ID: <Pine.LNX.4.31.0212081629150.23517-100000@gannet.stats>

On Sun, 8 Dec 2002, Bud Gibson wrote:

> Thanks for the clarification.  It's nice to know that there is some
> systematicity to the behavior.
>
> Is this documented anywhere?  I did look at the help for as.numeric, and

Yes, in the FAQ no less, Q7.12 in the version I have:

   ``In any case, do not call `as.numeric()' or their likes directly.''


Ouch....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From fjopp at zedat.fu-berlin.de  Sun Dec  8 18:30:03 2002
From: fjopp at zedat.fu-berlin.de (Fred Jopp)
Date: Sun Dec  8 18:30:03 2002
Subject: [R] strange QQ-Plot
Message-ID: <20021208173120.GC952@zedat.fu-berlin.de>

Hi,

i am working on a data set with EDA. That includes QQ-Plots of
residuals vs expected normal distribution. 
What puzzles me is that the range of ordinate and abscissae is
so different: while the theoretical quantiles range from [-2, 2] 
the sample quantiles on the ordinate do extent from [-20, 50]. 
Quite obviously some kind of transformation is done. 

Although i intensively RTFM i could not find, what is done here. 
What exactly characterizes the range of the ordinate in QQ-Plots ?

cheers,
Fred
-- 
Fred Jopp		       |  fjopp at zedat.fu-berlin.de
Lab.f. Soil Zoology & Ecology  |  www.biologie.fu-berlin.de/bodenzoo/
Grunewaldstr. 34               |  Tel. +49.30.8385.5946
D-12165 Berlin		       |  FAX  +49.30.8385.3886



From fpgibson at umich.edu  Sun Dec  8 18:42:03 2002
From: fpgibson at umich.edu (Bud Gibson)
Date: Sun Dec  8 18:42:03 2002
Subject: [R] Warning:  as.numeric reorders factor data
In-Reply-To: <Pine.LNX.4.31.0212081629150.23517-100000@gannet.stats>
References: <Pine.LNX.4.31.0212081629150.23517-100000@gannet.stats>
Message-ID: <3DF38456.2030701@umich.edu>

Well, it seems my hard won workaround was documented after all. 
 Wouldn't it be nice if this were in the as.numeric help page?  Look, I 
haven't slacked off.  I have the Ripley and Venables book (in fact, all 
4 editions over the years) and the Dalgaard book.

I did look at on-line resources.  However, exactly how was I to find 
this in the FAQ?  The category is "Miscellanea" which is hardly 
informative.  It's not cross-indexed.  There is no search engine.

Is it that much effort to get it in the standard distributed help files? 
 From the FAQ entry, this sounds pretty common.

ripley at stats.ox.ac.uk wrote:

>On Sun, 8 Dec 2002, Bud Gibson wrote:
>
>  
>
>>Thanks for the clarification.  It's nice to know that there is some
>>systematicity to the behavior.
>>
>>Is this documented anywhere?  I did look at the help for as.numeric, and
>>    
>>
>
>Yes, in the FAQ no less, Q7.12 in the version I have:
>
>   ``In any case, do not call `as.numeric()' or their likes directly.''
>
>
>Ouch....
>
>  
>



From loesljrg at accucom.net  Sun Dec  8 19:22:03 2002
From: loesljrg at accucom.net (JRG)
Date: Sun Dec  8 19:22:03 2002
Subject: [R] strange QQ-Plot
In-Reply-To: <20021208173120.GC952@zedat.fu-berlin.de>
Message-ID: <B0013962794@netserv1.accucom.net>

On 8 Dec 02, at 18:31, Fred Jopp wrote:

> Hi,
> 
> i am working on a data set with EDA. That includes QQ-Plots of
> residuals vs expected normal distribution. 
> What puzzles me is that the range of ordinate and abscissae is
> so different: while the theoretical quantiles range from [-2, 2] 
> the sample quantiles on the ordinate do extent from [-20, 50]. 
> Quite obviously some kind of transformation is done. 

?? What transformation?  The ordinate is simplest the variable you supplied, 
and its units are what they are.  And the range of the normal quantiles (the 
abscissa) is driven by the number of observations you supplied.

> 
> Although i intensively RTFM i could not find, what is done here. 
> What exactly characterizes the range of the ordinate in QQ-Plots ?
> 

Rather than TFM, perhaps an elementary introduction to QQ-plots?

---JRG

> cheers,
> Fred
> -- 
> Fred Jopp		       |  fjopp at zedat.fu-berlin.de
> Lab.f. Soil Zoology & Ecology  |  www.biologie.fu-berlin.de/bodenzoo/
> Grunewaldstr. 34               |  Tel. +49.30.8385.5946
> D-12165 Berlin		       |  FAX  +49.30.8385.3886
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



John R. Gleason

Syracuse University
430 Huntington Hall                      Voice:   315-443-3107
Syracuse, NY 13244-2340  USA             FAX:     315-443-4085

PGP public key at keyservers



From jfox at mcmaster.ca  Sun Dec  8 19:25:04 2002
From: jfox at mcmaster.ca (John Fox)
Date: Sun Dec  8 19:25:04 2002
Subject: [R] strange QQ-Plot
In-Reply-To: <20021208173120.GC952@zedat.fu-berlin.de>
Message-ID: <5.1.0.14.2.20021208132010.01dd2820@mcmail.cis.mcmaster.ca>

Dear Fred,

At 06:31 PM 12/8/2002 +0100, you wrote:

>i am working on a data set with EDA. That includes QQ-Plots of
>residuals vs expected normal distribution.
>What puzzles me is that the range of ordinate and abscissae is
>so different: while the theoretical quantiles range from [-2, 2]
>the sample quantiles on the ordinate do extent from [-20, 50].
>Quite obviously some kind of transformation is done.
>
>Although i intensively RTFM i could not find, what is done here.
>What exactly characterizes the range of the ordinate in QQ-Plots ?

I assume that you're plotting against the quantiles of the standard normal 
distribution. Unless your residuals are standardized, there's no reason to 
suppose that the scales would be similar. Moreover, one generally looks 
simply for a linear pattern in the QQ plot, suggesting that the data might 
come from the reference distribution, though possibly with a different 
centre and scale. Various departures from linearity in the plot suggest 
skewness, heavy tails, outliers, etc., relative to the reference distribution.

I hope that this helps,
  John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From drhosini at hotmail.com  Sun Dec  8 19:32:03 2002
From: drhosini at hotmail.com (Moustafa ElHousinie)
Date: Sun Dec  8 19:32:03 2002
Subject: [R] (no subject)
Message-ID: <F113mR7Lan5RfJW177D000145c8@hotmail.com>


Dear listers
I am a very newbie with graphs in R. I have a pulmonary function prediction 
equation in the form of PVC = 1.1 - 0.45*age in years + 0.011*height in cm.  
How can I draw the corresponding nomogram?.  I read the help for the 
design.nomogram function but it is too difficult for me. Excuse my 
ignorance. Any direct help will be appreciated.
Thanks in advance.



_________________________________________________________________
Help STOP SPAM with the new MSN 8 and get 2 months FREE*



From ripley at stats.ox.ac.uk  Sun Dec  8 19:35:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun Dec  8 19:35:03 2002
Subject: [R] strange QQ-Plot
In-Reply-To: <20021208173120.GC952@zedat.fu-berlin.de>
Message-ID: <Pine.LNX.4.31.0212081830280.24937-100000@gannet.stats>

On Sun, 8 Dec 2002, Fred Jopp wrote:

> i am working on a data set with EDA. That includes QQ-Plots of
> residuals vs expected normal distribution.
> What puzzles me is that the range of ordinate and abscissae is
> so different: while the theoretical quantiles range from [-2, 2]
> the sample quantiles on the ordinate do extent from [-20, 50].
> Quite obviously some kind of transformation is done.
>
> Although i intensively RTFM i could not find, what is done here.
> What exactly characterizes the range of the ordinate in QQ-Plots ?

A qqnorm plot (is that what you meant?) is of a sample against a
*standard* normal.  One expects a straight line of slope sigma and
intercept mu.

The answer to your final question is `whatever the users specifies'.
QQ plots are much more general than you seem to think.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From fharrell at virginia.edu  Sun Dec  8 20:06:02 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Sun Dec  8 20:06:02 2002
Subject: [R] (no subject)
In-Reply-To: <F113mR7Lan5RfJW177D000145c8@hotmail.com>
References: <F113mR7Lan5RfJW177D000145c8@hotmail.com>
Message-ID: <20021208140555.0d48f855.fharrell@virginia.edu>

On Sun, 08 Dec 2002 18:31:01 +0000
Moustafa ElHousinie <drhosini at hotmail.com> wrote:

> 
> 
> Dear listers
> I am a very newbie with graphs in R. I have a pulmonary function prediction 
> equation in the form of PVC = 1.1 - 0.45*age in years + 0.011*height in cm.  
> How can I draw the corresponding nomogram?.  I read the help for the 
> design.nomogram function but it is too difficult for me. Excuse my 
> ignorance. Any direct help will be appreciated.
> Thanks in advance.
> 

library(Design)
dd <- datadist(age,height)
options(datadist='dd')
f <- ols(PVC ~ age + height)       # why assume linear and additive?
nomogram(f)                        # many options available
nomogram(f, age=seq(10,70,by=10))  # control age axis, not use default

If you fit a nonlinear and/or nonadditive model nomogram still works (especially well for nonlinear additive models).
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From rjporter at mindspring.com  Sun Dec  8 22:11:02 2002
From: rjporter at mindspring.com (Bob Porter)
Date: Sun Dec  8 22:11:02 2002
Subject: [R] Reminder to register
Message-ID: <00d601c29efe$0fe71740$6501a8c0@HydePark>

This email sent to: r-help at lists.r-project.org

Dear INSC Participant:

This email is being sent to all email addresses of persons participating in INSC 2003 in Vienna in February, 2003.  If you have received this in error, my apologies, perhaps someone used your email address to write us.

Participants should be reminded that they should register at 
http://insc2003.societyforchaostheory.org/confregv06.htm

PLEASE REGISTER AS SOON AS POSSIBLE.

Registration fees increase after Jan 1, 2003.

There are now over 140 participants and hotels and excursions are filling up quickly.

Check at webpage above for more information.

I am looking forward to seeing everyone in Vienna!


Bob Porter


Robert J. Porter, Ph.D.
Conference Chair, 
INSC 2003, Vienna
Professor Emeritus, University of New Orleans
Clinical and Consulting Psychologist
118 West Plymouth ST.
Tampa, FL, 33603
USA
(813) 225-5678 FAX



From chris at fisher.forestry.uga.edu  Sun Dec  8 23:28:03 2002
From: chris at fisher.forestry.uga.edu (Christopher Fonnesbeck)
Date: Sun Dec  8 23:28:03 2002
Subject: [R] scan problems -- what can "what" be?
Message-ID: <39886.66.188.73.8.1039386024.squirrel@fisher.forestry.uga.edu>

Hello,

I am trying to import a list of "structure" objects into R (data for BUGS,
actually), but am having little success. In the help file for scan there
dies not seem to be a list of valid values for the "what" keyword. Can
anyone provide me with one? I have pasted in a sample input file that I am
trying to import below this message. I have tried
what=list(structure,structure,structure) and variations thereof.

Also, is there an easy way of searching the mailing list archives, so that
I dont have to bother the list with silly questions like this one?

Thanks,
cjf

list(
move_n = structure(.Data=c(0.984,0.016, 0.000,
            0.081, 0.904, 0.015,
            0.000, 0.026, 0.974,
            0.974, 0.026, 0.000,
            0.052, 0.930, 0.018,
            0.000, 0.014, 0.986), .Dim=c(3,3,2)),

move_s = structure(.Data=c(0.506, 0.214, 0.280,
		0.048, 0.689, 0.263,
		0.002, 0.914, 0.084,
		0.451, 0.262, 0.287,
		0.062, 0.686, 0.252,
		0.002, 0.890, 0.108), .Dim=c(3,3,2)),

fidel = structure(.Data=c(0.890, 0.055, 0.055,
			0.065, 0.870, 0.065,
			0.060, 0.060, 0.880,
			0.88, 0.06, 0.06,
			0.07, 0.86, 0.07,
			0.075, 0.075, 0.85),.Dim=c(3,3,2))
)

-- 
Christopher J. Fonnesbeck       GA Coop. Fish & Wildlife Research Unit
chris at fisher.forestry.uga.edu   University of Georgia



From Bill.Venables at CMIS.CSIRO.AU  Mon Dec  9 00:04:03 2002
From: Bill.Venables at CMIS.CSIRO.AU (Bill.Venables@CMIS.CSIRO.AU)
Date: Mon Dec  9 00:04:03 2002
Subject: [R] Population modeller position available
Message-ID: <E09E527B56BE2D438A3D6A246DDD27A91656E9@Roper-CV.qld.cmis.csiro.au>

There is a population modeller position available at this laboratory for
someone with strong modelling and computational skills.  Full details are
available at the following web site.

 <http://recruitment.csiro.au/job_details.asp?ref=MRC/02/01> 


Bill Venables, 
CMIS, CSIRO Marine Laboratories, 
PO Box 120, Cleveland, Qld. 4163
AUSTRALIA
Phone:  +61 7 3826 7251  
Fax:    +61 7 3826 7304
Mobile: +61 419 634 642
<mailto: Bill.Venables at csiro.au>
http://www.cmis.csiro.au/bill.venables/



From hbwoo at mail.utexas.edu  Mon Dec  9 00:06:04 2002
From: hbwoo at mail.utexas.edu (hbwoo@mail.utexas.edu)
Date: Mon Dec  9 00:06:04 2002
Subject: [R] (no subject)
Message-ID: <20021208230526.41421.qmail@psi.pair.com>

unsubscribe r-announce hbwoo at mail.utexas.edu



From hbwoo at mail.utexas.edu  Mon Dec  9 00:06:41 2002
From: hbwoo at mail.utexas.edu (hbwoo@mail.utexas.edu)
Date: Mon Dec  9 00:06:41 2002
Subject: [R] (no subject)
Message-ID: <20021208230549.41478.qmail@psi.pair.com>

unsubscribe r-help hbwoo at mail.utexas.edu



From tlumley at u.washington.edu  Mon Dec  9 00:25:03 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon Dec  9 00:25:03 2002
Subject: [R] Warning:  as.numeric reorders factor data
In-Reply-To: <3DF36CBB.7040007@umich.edu>
Message-ID: <Pine.A41.4.44.0212081515530.132236-100000@homer11.u.washington.edu>

On Sun, 8 Dec 2002, Bud Gibson wrote:

> Thanks for the clarification.  It's nice to know that there is some
> systematicity to the behavior.
>
> Is this documented anywhere?  I did look at the help for as.numeric, and
> it makes no mention that it is coercing factors based on their level.

Well, the help page for as.numeric says

     `as.numeric' for factors yields the codes underlying the factor
     levels, not the numeric representation of the labels.

>  This may be obvious to those deeply immersed in R and its machinations,
> but to those who think the number they see on the screen should just
> become a number when it is coerced to one, it is disconcerting.

Yes it is. It might have been better if at the dawn of time codes() had
been defined to do what as.numeric does and as.numeric to do what you
expect.   However, it's not completely obvious: what should as.numeric do
with a factor of postal codes whose levels are "3163" "90210" and "OX1 3DP"?


> Further, if I just factor the same vector, and then coerce it back to
> numeric, the order I would have expected is preserved.  I did not report
> that test because it seemed irrelevant.  Why isn't aggregate just doing
> that?

Because when you have more than one `by' variable in aggegrate it needs to
make a factor of the combined levels, which it does by pasting them
together as characters.

> My cut is that there should be some warning in the documentation,
> perhaps in aggregate, about the specific assumptions used in making
> implicit transformations and what one can expect.

It might be worth help(aggregate) mentioning that the variables are turned
into factors.

	-thomas



From fpgibson at umich.edu  Mon Dec  9 00:54:03 2002
From: fpgibson at umich.edu (Bud Gibson)
Date: Mon Dec  9 00:54:03 2002
Subject: [R] Warning:  as.numeric reorders factor data
In-Reply-To: <Pine.A41.4.44.0212081515530.132236-100000@homer11.u.washington.edu>
References: <Pine.A41.4.44.0212081515530.132236-100000@homer11.u.washington.edu>
Message-ID: <3DF3DB63.80404@umich.edu>

The behavior makes more sense now but is in need of clarification in the 
help files.  

Specifically, aggregate should mention that it is converting arguments 
to characters.  Factoring a numeric vector leads to what you might 
expect, factors ordered numerically.  So, even though I knew the by 
variables were being factored, it seemed they should be okay.  For instance,

 > factor(c(1:15))
 [1] 1  2  3  4  5  6  7  8  9  10 11 12 13 14 15
Levels: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15

 Ultimately, it occurred to me after much staring at the output that 
factoring must be doing a character conversion first, and that is how I 
figured out my workaround.  As it turns out, the workaround is  in the 
FAQ (albeit filed under Miscellanea).

So, ultimately the problem may not be in as.numeric.  Since one needs to 
know something about the internal processing of aggregate to use it, it 
might be that this should be in the help files.
Thomas Lumley wrote:

>On Sun, 8 Dec 2002, Bud Gibson wrote:
>
>  
>
>>Thanks for the clarification.  It's nice to know that there is some
>>systematicity to the behavior.
>>
>>Is this documented anywhere?  I did look at the help for as.numeric, and
>>it makes no mention that it is coercing factors based on their level.
>>    
>>
>
>Well, the help page for as.numeric says
>
>     `as.numeric' for factors yields the codes underlying the factor
>     levels, not the numeric representation of the labels.
>
>  
>
>> This may be obvious to those deeply immersed in R and its machinations,
>>but to those who think the number they see on the screen should just
>>become a number when it is coerced to one, it is disconcerting.
>>    
>>
>
>Yes it is. It might have been better if at the dawn of time codes() had
>been defined to do what as.numeric does and as.numeric to do what you
>expect.   However, it's not completely obvious: what should as.numeric do
>with a factor of postal codes whose levels are "3163" "90210" and "OX1 3DP"?
>
>
>  
>
>>Further, if I just factor the same vector, and then coerce it back to
>>numeric, the order I would have expected is preserved.  I did not report
>>that test because it seemed irrelevant.  Why isn't aggregate just doing
>>that?
>>    
>>
>
>Because when you have more than one `by' variable in aggegrate it needs to
>make a factor of the combined levels, which it does by pasting them
>together as characters.
>
>  
>
>>My cut is that there should be some warning in the documentation,
>>perhaps in aggregate, about the specific assumptions used in making
>>implicit transformations and what one can expect.
>>    
>>
>
>It might be worth help(aggregate) mentioning that the variables are turned
>into factors.
>
>	-thomas
>  
>



From liuhz at mail.cptt.com.tw  Mon Dec  9 01:05:03 2002
From: liuhz at mail.cptt.com.tw (=?big5?B?vEKu/Lpz?=)
Date: Mon Dec  9 01:05:03 2002
Subject: [R] Re: R-help digest, Vol 1 #10 - 6 msgs
References: <20021208110008.11310.46432.Mailman@hypatia.math.ethz.ch>
Message-ID: <003301c29f16$bcdfb6b0$88fc150a@tft.cptt.com.tw>

_
----- Original Message -----
From: <r-help-request at stat.math.ethz.ch>
To: <r-help at stat.math.ethz.ch>
Sent: Sunday, December 08, 2002 7:00 PM
Subject: R-help digest, Vol 1 #10 - 6 msgs


> Send R-help mailing list submissions to
> r-help at stat.math.ethz.ch
>
> To subscribe or unsubscribe via the World Wide Web, visit
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> or, via email, send a message with subject or body 'help' to
> r-help-request at stat.math.ethz.ch
>
> You can reach the person managing the list at
> r-help-admin at stat.math.ethz.ch
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-help digest..."
>
>
> Today's Topics:
>
>    1. Re: fortran -> R (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
>    2. Re: R 1.6.1 segmentation fault (David Meyer)
>    3. simplex(boot) problem (George LeCompte)
>    4. bugs in system() handling long character strings?? (Naoki
Takebayashi)
>    5. Re: bugs in system() handling long character strings??
(ripley at stats.ox.ac.uk)
>    6. color of plot axes involving POSIX types (Richard Rowe)
>
> --__--__--
>
> Message: 1
> Date: Sat, 7 Dec 2002 12:28:50 +0100 (CET)
> From: =?iso-8859-1?Q?G=F6ran_Brostr=F6m?= <gb at stat.umu.se>
> To: Christian Schulz <ozric at web.de>
> cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] fortran -> R
>
> On Sat, 7 Dec 2002, Christian Schulz wrote:
>
> > Hi,
> >
> > i'm working with a interesting book from
> > Michael Smithson: "Fuzzy Set Analysis for Behavioral and Social
> > Sciences",1987.
> > with small listenings in Fortran.
> >
> > It's a pitty that i'm more or less understand nothing from Fortran -
> > have anybody an sugestion or perhaps interesting (...incl. Fortran
skills ?)
> > how
> > i can get it in R or Java.
>
> in R: Read "Writing R extensions" especially "...foreign language
> interfaces", and look at ?.Fortran
> >
> > Now anybody a Fortran2Java  translator, it seems that something like
this
> > exist ?
>
> Don't know anything about that.
>
> > The programs are written in Fortran77 for Dec-10 !
>
> Should be ok, if the code doesn't contain Dec extensions to the F77
> standard. But you'll probably notice that at compile time :-)
>
> Gran
>
>
> --__--__--
>
> Message: 2
> Date: Sat, 07 Dec 2002 14:39:00 +0100
> From: David Meyer <david.meyer at ci.tuwien.ac.at>
> Organization: Vienna University of Technology
> To: Per-Anders Wernberg <wernberg at byggmek.lth.se>
> CC: r-help at stat.math.ethz.ch
> Subject: Re: [R] R 1.6.1 segmentation fault
>
> Per-Anders Wernberg wrote:
> >
> > Hi,
> > We have been running R ver 1.4.1 on a redhat linux (7.1)cluster without
> > problem for quit some time.
> > Now, some user wanted me to install version 1.6.1, and it compiled fine,
> > but it crashes with "segmentation fault" when you run it. I used gcc296
> > (default) for compiling, Should I change compiler
>
> yes, definitely.
>
> -d
>
> > or is there some other
> > thing I could do to  avoid this problem.
> >
> > Regards
> > Per-Anders
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> --
> Mag. David Meyer Wiedner Hauptstrasse 8-10
> Vienna University of Technology A-1040 Vienna/AUSTRIA
>          Department of Tel.: (+431) 58801/10772
> Statistics and Probability Theory mail: david.meyer at ci.tuwien.ac.at
>
>
> --__--__--
>
> Message: 3
> Date: Sat, 07 Dec 2002 10:12:18 -0800
> From: George LeCompte <george at lecompte.org>
> To: R-help at stat.math.ethz.ch
> Subject: [R] simplex(boot) problem
>
> This is a multi-part message in MIME format.
> --------------060007010402070602040701
> Content-Type: text/plain; charset=us-ascii; format=flowed
> Content-Transfer-Encoding: 7bit
>
> The attached test6.r sets up input for simplex from boot package.  It's
> input file is short2A.txt.
>
> Running under R 1.6.1 I get the following error message.
>
> Error in simplex1 (out1$a[1:(n + m1 + m2)], out1$A[, 1:(n + m1 + m2)], :
>           subscript out of bounds
>
> Other calls to simplex seem to work properly
>
> What am I doing wrong?
>
> --------------060007010402070602040701
> Content-Type: text/plain;
>  name="test6.R"
> Content-Transfer-Encoding: 7bit
> Content-Disposition: inline;
>  filename="test6.R"
>
> library(boot)
> filen<-"short2A.txt"
> print(filen)
> read.table(filen,header = TRUE,row.names=1,sep=",")->tab
> print("tab")
> print(tab)
> v<-scan(file=filen,what=list(v="V"),flush=TRUE,sep=",")
> names<-v$v[2:length(v$v)]
> print("names")
> print(names)
> print("f")
> f<-tab[,1]
> print(f)
>
> A1<-t(tab[,2:5])
> e<-rep(0,length(f))
> e[2]<-1
> A1<-rbind(A1,e)
> print("A1")
> print(A1)
> b1<-c(rep(100,4),1)
> print(b1)
> A2<-t(tab[,6:11])
> e<-rep(0,length(f))
> e[5]<-1
> A2<-rbind(A2,e)
> b2<-c(rep(100,6),4)
> print(A2)
> print(b2)
> print("A3")
> e4<-rep(0,length(f))
> e4[4]<-1
> e1<-rep(0,length(f))
> e1[1]<-1
> e3<-rep(0,length(f))
> e3[3]<-1
> A3<-rbind(e4,e1,e3)
> b3<-c(0,0,0)
> print(A3)
> print(b3)
> ss<-simplex(f,A1,b1,A2,b2,A3,b3)
>
> --------------060007010402070602040701
> Content-Type: text/plain;
>  name="short2A.txt"
> Content-Transfer-Encoding: 7bit
> Content-Disposition: inline;
>  filename="short2A.txt"
>
> "X1","X2","X3","X4","X5","X6","X7","X8","X9","X10","X11","X12"
> "y1",210,15,9,0,6,9,10,0,15,0,2
> "Y2",450,33,19,0,12,19,21,0,30,2,6
> "y3",540,40,23,0,15,23,25,0,35,2,8
> "y4",610,45,25,0,16,26,28,0,40,2,8
> "y5",100,10,15,25,5,1,8,30,25,15,6
> "y6",150,3,3,0,11,9,6,0,0,20,10
> "y7",340,12,8,6,26,19,0,0,0,20,25
> "y8",300,5,3,0,16,20,11,0,0,10,8
> "y9",380,8,11,5,10,25,9,2,40,30,10
> "y10",40,5,0,0,2,1,2,0,0,0,0
> "y11",230,12,9,0,11,13,4,0,0,0,10
> "y12",180,0,0,0,0,14,0,6,210,4,2
>
> --------------060007010402070602040701--
>
>
> --__--__--
>
> Message: 4
> Date: Sat, 7 Dec 2002 16:01:04 -0500 (EST)
> From: Naoki Takebayashi <ntakebay at bio.indiana.edu>
> To: r-help at stat.math.ethz.ch
> Subject: [R] bugs in system() handling long character strings??
>
> Hi,
>
> system(cmd, intern=T) seems to have a problem when cmd returns a long
> character string.
>
> For example, if a file (/tmp/long.txt) contains a long string such as:
>
>
1234567890123456789012345678901234567890123456789012345678901234567890123456
78901234567890123456789012345678901234567890
>
> There are 120 characters in this one line.
>
> > junk <- system("cat /tmp/long", TRUE)
> > junk
> [1]
"123456789012345678901234567890123456789012345678901234567890123456789012345
6789012345678901234567890123456789012345678"
> [2] "0"
> > nchar(junk[1])
> [1] 118
>
> So one long line get separated into two parts, and additionally 119-th
> character is missing.
>
> Is this a bug in R or am I missing something?
>
> I tried this on R-1.6.1 on linux/alpha and linux/i386.
>
> Thanks,
> Naoki
>
> Naoki Takebayashi     <ntakebay at bio.indiana.edu>
> --- Dept. of Biology, Box 90338, Duke University, Durham, NC 27708-0338
>
>
> --__--__--
>
> Message: 5
> Date: Sat, 7 Dec 2002 22:50:06 +0000 (GMT)
> From: <ripley at stats.ox.ac.uk>
> To: Naoki Takebayashi <ntakebay at bio.indiana.edu>
> cc: <r-help at stat.math.ethz.ch>
> Subject: Re: [R] bugs in system() handling long character strings??
>
> There is an undocumented limit of 119 characters/line when using
> system(intern=TRUE) on Unix.  You can easily raise it: it is in
> do_system in file src/unix/sys-unix.c.
>
> I think this limit should be raised considerably, but it may well not be
> worth eliminating it.
>
> On Sat, 7 Dec 2002, Naoki Takebayashi wrote:
>
> > Hi,
> >
> > system(cmd, intern=T) seems to have a problem when cmd returns a long
> > character string.
> >
> > For example, if a file (/tmp/long.txt) contains a long string such as:
> >
> >
1234567890123456789012345678901234567890123456789012345678901234567890123456
78901234567890123456789012345678901234567890
> >
> > There are 120 characters in this one line.
> >
> > > junk <- system("cat /tmp/long", TRUE)
> > > junk
> > [1]
"123456789012345678901234567890123456789012345678901234567890123456789012345
6789012345678901234567890123456789012345678"
> > [2] "0"
> > > nchar(junk[1])
> > [1] 118
> >
> > So one long line get separated into two parts, and additionally 119-th
> > character is missing.
> >
> > Is this a bug in R or am I missing something?
> >
> > I tried this on R-1.6.1 on linux/alpha and linux/i386.
> >
> > Thanks,
> > Naoki
> >
> > Naoki Takebayashi     <ntakebay at bio.indiana.edu>
> > --- Dept. of Biology, Box 90338, Duke University, Durham, NC 27708-0338
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>
> --__--__--
>
> Message: 6
> Date: Sun, 08 Dec 2002 13:41:11 +1000
> To: r-help at stat.math.ethz.ch
> From: Richard Rowe <Richard.Rowe at jcu.edu.au>
> Subject: [R] color of plot axes involving POSIX types
>
> I am attempting to plot frequency of occurrence against (calendar) time.
As
> the output is to be produced as a Powerpoint picture on a dark background
I
> wish to make the plot output yellow
>
>  > par(col="yellow", col.axis="yellow", col.lab="yellow",
col.main="yellow")
>  > plot(t2, t1, ylim=c(0,40), main="Episynlestes run 2", ylab="frequency",
> type="h", axes=FALSE, lwd=2)
>
> where t2 is a vector of  POSIX type and t1 is the associated frequency.
> This works *except* that the x axis is printed ... and in black
>
>  > axis.POSIXct(1, t2, col="yellow")
>
> makes the x axis yellow by overwriting, so I can get what I want
> (fortunately I didn't post this earlier when I was tied in a knot), but it
> doesn't seem elegant.
>
> Any hints?
>
> Thanks,
>
> Richard
>
>
> Richard Rowe
> Senior Lecturer
> Department of Zoology and Tropical Ecology, James Cook University
> Townsville, Queensland 4811, Australia
> fax (61)7 47 25 1570
> phone (61)7 47 81 4851
> e-mail: Richard.Rowe at jcu.edu.au
> http://www.jcu.edu.au/school/tbiol/zoology/homepage.html
>
>
>
> --__--__--
>
> _______________________________________________
> R-help mailing list  DIGESTED
> R-help at stat.math.ethz.ch
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
> End of R-help Digest



From rsadler at agric.uwa.edu.au  Mon Dec  9 01:46:03 2002
From: rsadler at agric.uwa.edu.au (rohan sadler)
Date: Mon Dec  9 01:46:03 2002
Subject: [R] R 1.6.1 segmentation fault
References: <3DF0B1C7.F4661599@byggmek.lth.se>
Message-ID: <3DF3E8D1.7030607@agric.uwa.edu.au>

Hi,

I had a segmentation fault similar to the way you described, but  
between R 1.5.1 and R 1.6.1 on RH 7.3.
All I had to do was to change the value of the environmental variables 
R_HOME and R_LIBS since R 1.6.1 was compiled in a different directory 
from R 1.5.1. I had defined these variables earlier in order to couple R 
with the data exploration package GGOBI, which may or may not be your 
case. My segmentation fault arose (from memory) primarily when trying to 
load a library since there were two library systems available, one from 
1.5.1 and one from 1.6.1.

Somebody else is likely to be more clear on this matter.

Rohan


Per-Anders Wernberg wrote:

>Hi,
>We have been running R ver 1.4.1 on a redhat linux (7.1)cluster without
>problem for quit some time.
>Now, some user wanted me to install version 1.6.1, and it compiled fine,
>but it crashes with "segmentation fault" when you run it. I used gcc296
>(default) for compiling, Should I change compiler or is there some other
>thing I could do to  avoid this problem.
>
>Regards
>Per-Anders
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Ecosystems Research Group (ERGO)
School of Plant Biology (Botany), Faculty of Natural & Agricultural Sciences,
The University of Western Australia, 35 Stirling Highway, Crawley  WA  6009, Australia

Ph:  +61 8 9380 7914
Fax: +61 8 9380 7925
email: rsadler at agric.uwa.edu.au
ERGO's web site:<http://www.botany.uwa.edu.au/ergo>



From ripley at stats.ox.ac.uk  Mon Dec  9 08:58:06 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Dec  9 08:58:06 2002
Subject: [R] scan problems -- what can "what" be?
In-Reply-To: <39886.66.188.73.8.1039386024.squirrel@fisher.forestry.uga.edu>
Message-ID: <Pine.LNX.4.31.0212090753460.30339-100000@gannet.stats>

On Sun, 8 Dec 2002, Christopher Fonnesbeck wrote:

> Hello,
>
> I am trying to import a list of "structure" objects into R (data for BUGS,
> actually), but am having little success. In the help file for scan there
> dies not seem to be a list of valid values for the "what" keyword. Can
> anyone provide me with one? I have pasted in a sample input file that I am

There is no such list.  As the help page says, it is the *type*  of `what'
that counts.  So it can be an integer, logical, numeric, complex or
character vector, or a list containing such vectors.


> trying to import below this message. I have tried
> what=list(structure,structure,structure) and variations thereof.

Those are arrays.  Scan them as vectors and then add dimensions.

> Also, is there an easy way of searching the mailing list archives, so that
> I dont have to bother the list with silly questions like this one?
>
> Thanks,
> cjf
>
> list(
> move_n = structure(.Data=c(0.984,0.016, 0.000,
>             0.081, 0.904, 0.015,
>             0.000, 0.026, 0.974,
>             0.974, 0.026, 0.000,
>             0.052, 0.930, 0.018,
>             0.000, 0.014, 0.986), .Dim=c(3,3,2)),
>
> move_s = structure(.Data=c(0.506, 0.214, 0.280,
> 		0.048, 0.689, 0.263,
> 		0.002, 0.914, 0.084,
> 		0.451, 0.262, 0.287,
> 		0.062, 0.686, 0.252,
> 		0.002, 0.890, 0.108), .Dim=c(3,3,2)),
>
> fidel = structure(.Data=c(0.890, 0.055, 0.055,
> 			0.065, 0.870, 0.065,
> 			0.060, 0.060, 0.880,
> 			0.88, 0.06, 0.06,
> 			0.07, 0.86, 0.07,
> 			0.075, 0.075, 0.85),.Dim=c(3,3,2))
> )
>
> --
> Christopher J. Fonnesbeck       GA Coop. Fish & Wildlife Research Unit
> chris at fisher.forestry.uga.edu   University of Georgia
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bhx2 at mevik.net  Mon Dec  9 10:08:03 2002
From: bhx2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge?= Mevik)
Date: Mon Dec  9 10:08:03 2002
Subject: [R] Generating cyclic designs?
Message-ID: <7o1y4rpneq.fsf@foo.nemo-project.org>

Are there any functions for generating cyclic designs in R?

-- 
Bj?rn-Helge Mevik



From Soren.Hojsgaard at agrsci.dk  Mon Dec  9 10:56:06 2002
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Mon Dec  9 10:56:06 2002
Subject: [R] R as a COM client - is it possible?
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC0CC539@DJFPOST01.djf.agrsci.dk>

Dear all,

In S+, there are functions like

	create.ole.object
	call.ole.method
	release.ole.object

for communicating with other programs which work as a COM server (on
Windows).

Is it possible to do something similar in R (I've studied the 'connections'
facilities, but they do not seem to work).

==========================================
S?ren H?jsgaard,  PhD, Senior Scientist
Biometry Research Unit
Danish Institute of Agricultural Sciences
Research Centre Foulum, DK-8830 Tjele, Denmark
Phone: +45 8999 1703
E-mail : sorenh at agrsci.dk
Homepage : http://www.jbs.agrsci.dk/~sorenh/



From eia018 at comp.lancs.ac.uk  Mon Dec  9 11:19:03 2002
From: eia018 at comp.lancs.ac.uk (Dr Andrew Wilson)
Date: Mon Dec  9 11:19:03 2002
Subject: [R] Fitting a distribution involving a cusum
Message-ID: <Pine.GSO.4.21.0212091003440.23951-100000@austin>

Sorry if this is a naive question, but I only started using R last
week.

I would like to fit a distribution to data which includes a cumulative
sum:

P(r) = \sum^{V}_{i=r} D e^{-n/i} i^{-d}

This equation is used to fit rank-frequency data: P(r) is the frequency of
an entity with rank r; V is the number of unique entity types; and D, n
and d are constants to be estimated.

I've found out how to fit nonlinear distributions generally (using nls)
but I don't know how to include the cumulative sum in the formula.  Could
anyone help me?

Many thanks,
Andrew Wilson



From Arne.Muller at aventis.com  Mon Dec  9 11:39:03 2002
From: Arne.Muller at aventis.com (Arne.Muller@aventis.com)
Date: Mon Dec  9 11:39:03 2002
Subject: [R] Principal component analysis
Message-ID: <C80ECAFA2ACC1B45BE45D133ED660ADE41099E@crbsmxsusr04.pharma.aventis.com>

Dear R users,

I'm trying to cluster 30 gene chips using principal component analysis in
package mva.prcomp. Each chip is a point with 1,000 dimensions. PCA is
probably just one of several methods to cluster the 30 chips. However, I
don't know how to run prcomp, and I don't know how to interpret it's output.

If there are 30 data points in 1,000 dimensions each, do I have to provide
the data in a 1,000x30 matrix or data frame (i.e. 1000 columns)?

> data[1:5,1:5]
  x.HU.04h.Ctr.118.01.4.ctrl x.HU.04h.010.118.04.4.0.1
1                         21                        45
2                         24                        35
3                        109                       173
4                         86                        99
5                        130                       204
  x.HU.04h.050.118.05.4.0.5 x.HU.04h.100.118.06.4.1
x.HU.24h.Ctr.118.07.24.ctrl
1                        24                      28
22
2                        25                      25
20
3                       107                     125
95
4                        72                      79
61
5                       126                     166
128

> m <- t(data)
> m[1:5,1:5]
                             1  2   3  4   5
x.HU.04h.Ctr.118.01.4.ctrl  21 24 109 86 130
x.HU.04h.010.118.04.4.0.1   45 35 173 99 204
x.HU.04h.050.118.05.4.0.5   24 25 107 72 126
x.HU.04h.100.118.06.4.1     28 25 125 79 166
x.HU.24h.Ctr.118.07.24.ctrl 22 20  95 61 128

> pca <- prcomp(m, retx = TRUE)

there are 30 "PC"s displayed (I've truncated the output). Shouldn't tere be
1000 PCs, with the 1st PC beeing the most discriminativePC? In a principal
comp. Alanysis, aren't there as many PCs as dimensions? On the other hand I
thought that PCA somehow collapses dimensionality ... . What is are PCs for
my 30 data points. Afterwards I'd also like to display the results in a
diagram, e.g. in 2 or 3 dimensions, to visualise clusters. I'm not sure I'm
doing the right thing.

	I'm happy for any comments and explanations,

	kind regards,

	Arne


> pca["x"]
$x
                             
                                     PC1          PC2         PC3
PC4        PC5         PC6
  x.HU.04h.Ctr.118.01.4.ctrl  -1272.1203  -249.465634 -2185.20558
1083.15814  421.67755   100.26612
  x.HU.04h.010.118.04.4.0.1   -1493.8623  1483.260490 -1090.31102
-286.70562 1274.34804    37.88463
  x.HU.04h.050.118.05.4.0.5   -2688.5157  2055.336930   -83.70279
154.24116 1202.58763  -604.08124
  x.HU.04h.100.118.06.4.1     -2477.3271  2029.248507   -14.37922
-314.08755 1422.88800  -509.37791
  x.HU.24h.Ctr.118.07.24.ctrl -3198.7071 -2264.516725   209.04504
763.56664 -762.61481  -542.35302
  x.HU.24h.010.118.10.24.0.1  -3370.0556 -2190.205040   298.17498
702.80862 -783.48849  -509.22595
  x.HU.24h.050.118.11.24.0.5  -2662.8329 -1436.400955  1478.81635
129.83910  406.10451   337.88507
  x.HU.24h.100.118.12.24.1    -4193.3836 -1210.594052  1844.22923
914.84373  -11.33207    11.58916
  x.HU.04h.Ctr.206.13.4.ctrl   2305.5848  -180.584730 -2017.05340
1274.07436  132.14756   930.35799
  x.HU.04h.010.206.14.4.0.1    1703.4976  2032.883878   -78.67578
1697.50799 -301.93647   234.25139
  x.HU.04h.025.206.15.4.0.25   1294.1932  2876.862370   534.11002
1229.73355  -68.31220   226.47566
  x.HU.04h.050.206.16.4.0.5    3666.8441  3520.249397  1187.37289
-45.83772 -271.06706   145.75181
  x.HU.04h.100.206.17.4.1      3657.9687  3432.347857  1318.94834
-484.73817 -405.36077   349.88323
  x.HU.24h.Ctr.206.18.24.ctrl  5796.1801 -2985.085353 -1052.08033
-306.45667  265.22940  -732.59152
  x.HU.24h.010.206.19.24.0.1   4429.6809 -2685.801572 -1027.66157
822.76848  171.15959 -1118.12987
  x.HU.24h.025.206.20.24.0.25  5672.4279 -1559.896071  1177.74742
-734.37026  336.46183  -132.25625
  x.HU.24h.050.206.21.24.0.5   4855.8534  -809.112994  1825.99459
-594.09109  190.00907  -234.33254
  x.HU.24h.100.206.22.24.1     4015.2594  -166.349964  1015.96643
622.86202 -267.17075   400.45741
  x.HU.04h.Ctr.821.23.4.ctrl   -485.9779    91.410337 -2446.35100
-263.83351 -453.89005   491.14145
  x.HU.04h.Ctr.821.24.4.ctrl    390.5580    -8.264721 -2707.56580
-1265.35762 -156.67885   555.41157
  x.HU.04h.010.821.25.4.0.1   -1138.4096  1733.090222  -885.89460
-460.04065 -276.68619  -200.20132
  x.HU.04h.025.821.26.4.0.25  -1622.0565  2333.333749  -297.50664
-838.12742 -783.19740  -206.76327
  x.HU.04h.050.821.27.4.0.5   -1920.9992  2462.596326  -213.80507
-463.02219 -683.90138  -731.04753
  x.HU.04h.100.821.28.4.1     -2288.0687  2251.971783   223.28215
-472.78173 -668.16917  -623.88411
  x.HU.24h.Ctr.821.29.24.ctrl  -599.7405 -2105.800732  -792.89966
-902.43731 -158.37800   314.34868
  x.HU.24h.Ctr.821.30.24.ctrl  -743.5533 -2154.937309  -350.37118
-744.69040 -479.01087   172.03340
  x.HU.24h.010.821.31.24.0.1  -2240.3848 -1963.626249   306.05426
-178.59331 -166.16473   266.24216
  x.HU.24h.025.821.32.24.0.25 -1840.1627 -1667.075636  1271.79029
-333.21614 -178.28014   477.06373
  x.HU.24h.050.821.33.24.0.5  -1575.7248 -1431.615872  1059.90748
-531.84286  537.76332   502.46140
  x.HU.24h.100.821.34.24.1    -1976.1656 -1233.258236  1492.02417
-175.17357  515.26288   590.73966

[...]



From baron at cattell.psych.upenn.edu  Mon Dec  9 11:50:04 2002
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Mon Dec  9 11:50:04 2002
Subject: [R] Principal component analysis
In-Reply-To: <C80ECAFA2ACC1B45BE45D133ED660ADE41099E@crbsmxsusr04.pharma.aventis.com>; from Arne.Muller@aventis.com on Mon, Dec 09, 2002 at 11:38:43AM +0100
References: <C80ECAFA2ACC1B45BE45D133ED660ADE41099E@crbsmxsusr04.pharma.aventis.com>
Message-ID: <20021209054941.A22551@cattell.psych.upenn.edu>

On 12/09/02 11:38, Arne.Muller at aventis.com wrote:
>Dear R users,
>
>I'm trying to cluster 30 gene chips using principal component analysis in
>package mva.prcomp. Each chip is a point with 1,000 dimensions. PCA is
>probably just one of several methods to cluster the 30 chips. However, I
>don't know how to run prcomp, and I don't know how to interpret it's output.

PCA is almost certainly not what you want.  Kmeans might work (or
other functions designed for clustering).

The reason your output is limited to 30 components is (roughly)
that, once you have this many, all the other 970 are predictable
from these, because you have only 30 observations.

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
R page:               http://finzi.psych.upenn.edu/



From otoomet at econ.dk  Mon Dec  9 11:51:03 2002
From: otoomet at econ.dk (Ott Toomet)
Date: Mon Dec  9 11:51:03 2002
Subject: [R] Sth better than cycle?
Message-ID: <200212091051.gB9ApPB08181@punik.econ.au.dk>

Hi,

I want to calculate expected likelihood over a 2D discrete
distribution, something like

\sum_k \sum_l p_{kl} L(v_k, v_l)

It is trivial to write a cycle like

for(k in 1:K)
   for(l in 1:L)
      sum <- sum + p[k,l]*L(v[k], v[l])

But is there a more clever way for R?

Best wishes,

Ott



From ripley at stats.ox.ac.uk  Mon Dec  9 11:58:02 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Dec  9 11:58:02 2002
Subject: [R] R as a COM client - is it possible?
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC0CC539@DJFPOST01.djf.agrsci.dk>
Message-ID: <Pine.LNX.4.31.0212091055450.12259-100000@gannet.stats>

On Mon, 9 Dec 2002, [iso-8859-1] Sren Hjsgaard wrote:

> Dear all,
>
> In S+, there are functions like
>
> 	create.ole.object
> 	call.ole.method
> 	release.ole.object
>
> for communicating with other programs which work as a COM server (on
> Windows).
>
> Is it possible to do something similar in R (I've studied the 'connections'
> facilities, but they do not seem to work).

They work!   But not to COM servers (a Windows-only concept).

There is a DCOM server for R on CRAN by Thomas Baier: I am not aware of a
COM/OLE client interface for R.  Perhaps some Windows user would like ot
contribute one.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Dec  9 12:15:06 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Dec  9 12:15:06 2002
Subject: [R] Principal component analysis
In-Reply-To: <C80ECAFA2ACC1B45BE45D133ED660ADE41099E@crbsmxsusr04.pharma.aventis.com>
Message-ID: <Pine.LNX.4.31.0212091107250.12346-100000@gannet.stats>

On Mon, 9 Dec 2002 Arne.Muller at aventis.com wrote:

> Dear R users,
>
> I'm trying to cluster 30 gene chips using principal component analysis in
> package mva.prcomp. Each chip is a point with 1,000 dimensions. PCA is
> probably just one of several methods to cluster the 30 chips. However, I
> don't know how to run prcomp, and I don't know how to interpret it's output.
>
> If there are 30 data points in 1,000 dimensions each, do I have to provide
> the data in a 1,000x30 matrix or data frame (i.e. 1000 columns)?

None of those. A 30x1000 matrix.

> > data[1:5,1:5]
>   x.HU.04h.Ctr.118.01.4.ctrl x.HU.04h.010.118.04.4.0.1
> 1                         21                        45
> 2                         24                        35
> 3                        109                       173
> 4                         86                        99
> 5                        130                       204
>   x.HU.04h.050.118.05.4.0.5 x.HU.04h.100.118.06.4.1
> x.HU.24h.Ctr.118.07.24.ctrl
> 1                        24                      28
> 22
> 2                        25                      25
> 20
> 3                       107                     125
> 95
> 4                        72                      79
> 61
> 5                       126                     166
> 128
>
> > m <- t(data)
> > m[1:5,1:5]
>                              1  2   3  4   5
> x.HU.04h.Ctr.118.01.4.ctrl  21 24 109 86 130
> x.HU.04h.010.118.04.4.0.1   45 35 173 99 204
> x.HU.04h.050.118.05.4.0.5   24 25 107 72 126
> x.HU.04h.100.118.06.4.1     28 25 125 79 166
> x.HU.24h.Ctr.118.07.24.ctrl 22 20  95 61 128
>
> > pca <- prcomp(m, retx = TRUE)
>
> there are 30 "PC"s displayed (I've truncated the output). Shouldn't tere be
> 1000 PCs, with the 1st PC beeing the most discriminativePC? In a principal

No.  970 of them span the null space: you have massive over-fitting.

> comp. Alanysis, aren't there as many PCs as dimensions? On the other hand I
> thought that PCA somehow collapses dimensionality ... . What is are PCs for
> my 30 data points. Afterwards I'd also like to display the results in a
> diagram, e.g. in 2 or 3 dimensions, to visualise clusters. I'm not sure I'm
> doing the right thing.

Well, statistically neither am I.  But mathematically at least, the PCs
for your 30 data points are the `x' component of the result, and you can
plot them via

plot(pca$x[1:2])

in two dimensions, or use scatterplot3d (a package) or (preferably as it
is dynamic) the ggobi or xgobi interfaces in 3D.

This sort of thing *is* covered in many of the texts about S (or S-PLUS or
R).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Dec  9 12:20:04 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Dec  9 12:20:04 2002
Subject: [R] color of plot axes involving POSIX types
In-Reply-To: <5.0.0.25.1.20021208130839.02d5ca60@pop.jcu.edu.au>
Message-ID: <Pine.LNX.4.31.0212081145580.23275-100000@gannet.stats>

plot.POSIXct doesn't have an `axes=FALSE' argument, but you can use
xaxt="n".  However, with your settings and my example I get a yellow
axis, so I can't reproduce this.


On Sun, 8 Dec 2002, Richard Rowe wrote:

> I am attempting to plot frequency of occurrence against (calendar) time. As
> the output is to be produced as a Powerpoint picture on a dark background I
> wish to make the plot output yellow
>
>  > par(col="yellow", col.axis="yellow", col.lab="yellow", col.main="yellow")
>  > plot(t2, t1, ylim=c(0,40), main="Episynlestes run 2", ylab="frequency",
> type="h", axes=FALSE, lwd=2)
>
> where t2 is a vector of  POSIX type and t1 is the associated frequency.
> This works *except* that the x axis is printed ... and in black
>
>  > axis.POSIXct(1, t2, col="yellow")
>
> makes the x axis yellow by overwriting, so I can get what I want
> (fortunately I didn't post this earlier when I was tied in a knot), but it
> doesn't seem elegant.
>
> Any hints?
>
> Thanks,
>
> Richard
>
>
> Richard Rowe
> Senior Lecturer
> Department of Zoology and Tropical Ecology, James Cook University
> Townsville, Queensland 4811, Australia
> fax (61)7 47 25 1570
> phone (61)7 47 81 4851
> e-mail: Richard.Rowe at jcu.edu.au
> http://www.jcu.edu.au/school/tbiol/zoology/homepage.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andyj at splash.princeton.edu  Mon Dec  9 14:06:03 2002
From: andyj at splash.princeton.edu (Andy Jacobson)
Date: Mon Dec  9 14:06:03 2002
Subject: [R] triangular PDF
Message-ID: <f2kel8rgx67.fsf@tazman.Princeton.EDU>

Howdy,

        I couldn't find any way to generate deviates from a triangular
        PDF in R, so here's a function to do so.

        -Andy

rtri <- function(n=1,min=0,max=1,ml=0.5) {

  # Return independent random deviates from a
  # triangular distribution.
  
  # n is number of deviates requested
  # min, max are lower and upper limits of r.v. range
  # ml is the most-likely value

  # if ml = (min+max)/2, pdf is symmetric
  # if ml=min, pdf is left triangular
  # if ml=max, pdf is right triangular

  # Method reference is Section 7.3.9 of Law and Keaton (1982):
  
  # @Book{law82a,
  #  author =	 {Averill M. Law and W. David Keaton},
  #  title = 	 {Simulation modeling and analysis},
  #  publisher = 	 {Mc{G}raw-Hill},
  #  year = 	 1982
  #}

  # Written by Andy Jacobson (andyj at splash.princeton.edu), 6 Dec 2002
  # Credit is also due to Jeffrey S. Smith, (jsmith at eng.auburn.edu),
  # whose C++ implementation I looked at first.

  if((ml<min)||(ml>max)) {
    stop("ml outside of range [min max]")
  }
  
  u <- runif(n)

  mode <- (ml-min)/(max-min)  # "mode" defined in range [0 1] (rescaling will be done last)

  s1 <- which(u<=mode)
  s2 <- which(u>mode)

  u[s1] <- sqrt(mode*u[s1])
  u[s2] <- 1-sqrt((1-mode)*(1-u[s2]))

  min+(max-min)*u
  
}


-- 
Andy Jacobson

arj at gfdl.gov

Program in Atmospheric and Oceanic Sciences
Sayre Hall, Forrestal Campus
Princeton University
PO Box CN710 Princeton, NJ 08544-0710 USA

Tel: 609/258-5260  Fax: 609/258-2850



From Vincent.Spiesser at univ-tlse1.fr  Mon Dec  9 14:18:04 2002
From: Vincent.Spiesser at univ-tlse1.fr (Vincent Spiesser)
Date: Mon Dec  9 14:18:04 2002
Subject: [R] (no subject)
Message-ID: <4.2.0.58.20021209142058.00a48e10@mail.univ-tlse1.fr>

confirm 781466



From duncan at research.bell-labs.com  Mon Dec  9 14:22:05 2002
From: duncan at research.bell-labs.com (Duncan Temple Lang)
Date: Mon Dec  9 14:22:05 2002
Subject: [R] R as a COM client - is it possible?
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC0CC539@DJFPOST01.djf.agrsci.dk>; from Soren.Hojsgaard@agrsci.dk on Mon, Dec 09, 2002 at 10:54:57AM +0100
References: <C83C5E3DEEE97E498B74729A33F6EAEC0CC539@DJFPOST01.djf.agrsci.dk>
Message-ID: <20021209082022.C8636@jessie.research.bell-labs.com>

S?ren H?jsgaard wrote:
> Dear all,
> 
> In S+, there are functions like
> 
> 	create.ole.object
> 	call.ole.method
> 	release.ole.object
> 
> for communicating with other programs which work as a COM server (on
> Windows).
> 
> Is it possible to do something similar in R (I've studied the 'connections'
> facilities, but they do not seem to work).


There are currently two packages being developed that will provide
basic COM client facilities for R. Thomas Baier is developing one
which is pretty close to complete, as far as I understand, but he has
not released it yet.

And I and others here in Bell Labs are developing a package also
(along the lines of the Python win32com.client module, if that helps).
We will probably make an alpha version of our dynamic COM package
available in the next few weeks. The compiled bindings approach will
have to wait until sometime in January.  If you want to try the
current code, let me know and I can make it available.

 D.


> 
> ==========================================
> S?ren H?jsgaard,  PhD, Senior Scientist
> Biometry Research Unit
> Danish Institute of Agricultural Sciences
> Research Centre Foulum, DK-8830 Tjele, Denmark
> Phone: +45 8999 1703
> E-mail : sorenh at agrsci.dk
> Homepage : http://www.jbs.agrsci.dk/~sorenh/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan



From jfox at mcmaster.ca  Mon Dec  9 14:41:03 2002
From: jfox at mcmaster.ca (John Fox)
Date: Mon Dec  9 14:41:03 2002
Subject: [R] Sth better than cycle?
In-Reply-To: <200212091051.gB9ApPB08181@punik.econ.au.dk>
Message-ID: <5.1.0.14.2.20021209083342.01dd2c00@mcmail.cis.mcmaster.ca>

Dear Ott,

At 11:51 AM 12/9/2002 +0100, you wrote:

>I want to calculate expected likelihood over a 2D discrete
>distribution, something like
>
>\sum_k \sum_l p_{kl} L(v_k, v_l)
>
>It is trivial to write a cycle like
>
>for(k in 1:K)
>    for(l in 1:L)
>       sum <- sum + p[k,l]*L(v[k], v[l])
>
>But is there a more clever way for R?

If the dimensions K and L are the same (isn't that implied by the common 
vector v?) then how about something like sum(p * outer(v, v, L)). If there 
are two vectors, say v1 and v2, then sum(p * outer(v1, v2, L)).

I hope that this helps,
  John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From Vincent.Spiesser at univ-tlse1.fr  Mon Dec  9 15:04:03 2002
From: Vincent.Spiesser at univ-tlse1.fr (Vincent Spiesser)
Date: Mon Dec  9 15:04:03 2002
Subject: [R] heteroscedasticity analysis
Message-ID: <4.2.0.58.20021209143513.00a41d10@mail.univ-tlse1.fr>

Hello,
First, sorry for my poor english, I will try to be understood.
It's the first time I try this "r-help mailing list" and I hope it will be 
a success.

I am working on heteroscedasticity analysis. I would like to get the 
"Box-Ljung" and the "Lagrange multipliers" test.
I found the first one in the library "ts", but I can't find the second one. 
Does anybody know how this test can be called.

Vincent Spiesser



From christopher.knight at plant-sciences.oxford.ac.uk  Mon Dec  9 15:11:03 2002
From: christopher.knight at plant-sciences.oxford.ac.uk (Chris Knight)
Date: Mon Dec  9 15:11:03 2002
Subject: [R] 3D density estimation
Message-ID: <a05200f03ba1a4afa7160@[163.1.36.122]>

I am trying to carry out density estimation for three dimensions 
(with anywhere between a few hundred and ~8000 data points). Which 
leads me to ask:

a) is there any equivalent to kde2d (in MASS) or bkde2D (in 
KernSmooth) out there for three dimensions?

b) if not, my skills only seem to extend as far as writing a function 
which measures density as the number of data points falling within a 
sphere at each point on a 3D grid. The results for  spheres of the 
minimum size to cover all the space (i.e. slightly intersecting) on a 
30x30x30 mesh don't seem too bad.
  i) How inadequate is such an analysis likely to be for subsequent 
comparison of different density distributions?
ii) Is there anything equally simple I could implement which might be 
preferable?

Any help much appreciated,

Chris
-- 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Dr. Christopher G. Knight               Tel:+44 (0)1865 275 111
Department of Plant Sciences              +44 (0)1865 275 790
South Parks Road
Oxford          OX1 3RB
UK                                                                 ` 
? . , ,><(((?>
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From andy_liaw at merck.com  Mon Dec  9 15:48:03 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon Dec  9 15:48:03 2002
Subject: [R] 3D density estimation
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC984@usrymx10.merck.com>

I believe the sm package has functions for estimating (and even plotting?)
3D kernel density estimates.

Another possibility is the locfit package (currently in the "devel" section
on CRAN, because it hasn't been updated for the latest version of R, but may
still largely work).

(Both of these packages are companion software for books, so you may want to
check out those books.)

HTH,
Andy

-----Original Message-----
From: Chris Knight
[mailto:christopher.knight at plant-sciences.oxford.ac.uk]
Sent: Monday, December 09, 2002 9:04 AM
To: r-help at stat.math.ethz.ch
Subject: [R] 3D density estimation


I am trying to carry out density estimation for three dimensions 
(with anywhere between a few hundred and ~8000 data points). Which 
leads me to ask:

a) is there any equivalent to kde2d (in MASS) or bkde2D (in 
KernSmooth) out there for three dimensions?

b) if not, my skills only seem to extend as far as writing a function 
which measures density as the number of data points falling within a 
sphere at each point on a 3D grid. The results for  spheres of the 
minimum size to cover all the space (i.e. slightly intersecting) on a 
30x30x30 mesh don't seem too bad.
  i) How inadequate is such an analysis likely to be for subsequent 
comparison of different density distributions?
ii) Is there anything equally simple I could implement which might be 
preferable?

Any help much appreciated,

Chris
-- 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Dr. Christopher G. Knight               Tel:+44 (0)1865 275 111
Department of Plant Sciences              +44 (0)1865 275 790
South Parks Road
Oxford          OX1 3RB
UK                                                                 ` 
? . , ,><(((?>
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named in this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.



From maechler at stat.math.ethz.ch  Mon Dec  9 16:25:03 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon Dec  9 16:25:03 2002
Subject: [R] Sth better than cycle?
In-Reply-To: <200212091051.gB9ApPB08181@punik.econ.au.dk>
References: <200212091051.gB9ApPB08181@punik.econ.au.dk>
Message-ID: <15860.46520.499069.181827@gargle.gargle.HOWL>

>>>>> "Ott" == Ott Toomet <otoomet at econ.dk>
>>>>>     on Mon, 9 Dec 2002 11:51:25 +0100 writes:

    Ott> Hi,
    Ott> I want to calculate expected likelihood over a 2D discrete
    Ott> distribution, something like

    Ott> \sum_k \sum_l p_{kl} L(v_k, v_l)

    Ott> It is trivial to write a cycle like

    Ott> for(k in 1:K)
    Ott>  for(l in 1:L)
    Ott>    sum <- sum + p[k,l]*L(v[k], v[l])

    Ott> But is there a more clever way for R?

"more clever" meaning "faster", right?

Well, this really depends if L(.,.) is vectorized,
i.e. when x1 and x2 are vectors of length n,  
     r <- L(x1,x2) is of lenghth n with the proper values?

If this is the case, {something like} the following should work:

   n <- length(v)
   v1 <- rep(v, n)
   v2 <- rep(v, each = n)  
   
   sum(p * L(v1,v2)) ## or L(v2,v1) if it matters

Note that above,  
cbind(v1,v2)    is really a (fast no-names) version of 
expand.grid(v,v)

Hoping this helps,
Martin

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From ozric at web.de  Mon Dec  9 16:30:03 2002
From: ozric at web.de (Christian Schulz)
Date: Mon Dec  9 16:30:03 2002
Subject: [R] ifelse ?
Message-ID: <001601c29f96$e7268f90$f93e07d5@c5c9i0>

Hi,

i want transform data and using apply(data,2,fuz)
, but i don't know why the values   < low  &  > high  don't get 0 or 1, they
get
the value from Formula ,too  "((x-low)/(high-low))"  what's not the
intention ?

....is switch more approriate !?

thanks for advance ,Christian

fuz <- function (x) {
#x <- na.omit(x)
low <- quantile(x,0.15)[[1]]
high <- quantile(x,0.85)[[1]]
if (x < low ) zg <- 0
if (x >= low &  x <= high)
zg <- ((x-low)/(high-low))
if (x > high)
zg <- 1
return(zg) }


fuz <- function (x) {
#x <- na.omit(x)
low <- quantile(x,0.15)[[1]]
high <- quantile(x,0.85)[[1]]
ifelse(x < low,0,(x-low)/(high-low))
ifelse (x > high,1,(x-low)/(high-low))}



From Bernhard.Pfaff at drkw.com  Mon Dec  9 16:42:03 2002
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Mon Dec  9 16:42:03 2002
Subject: [R] heteroscedasticity analysis
Message-ID: 
    <18D602BD42B7E24EB810D6454A58DB9001CAE0C1@ibfftce505.is.de.dresdnerkb.com>

Have a look at the 'lmtest'-contributed package.

maybe the following function is of use, too. Pls. check, if I got the
calculation of the test statistic right.

arch<-function(x, lag=4)
	{
		xfit<-lm(x)
		res<-xfit$residuals
		ressq<-res^2
#
		tslag<-function(x,d=1)
			{
			 n<-length(x)
    			 c(rep(NA,d),x)[1:n]
			} 
#
		ressq.data<-array(NA,c(length(ressq), lag))
		labels<-paste("ressq.l",1:lag, sep="")
		colnames(ressq.data)<-labels
		for ( i in 1:lag)
			{
			 ressq.data[,i]<-tslag(ressq,d=i)
			}
		residssq<-as.data.frame(ressq.data)
		attach(residssq)
		aux<-as.formula(paste("ressq~",paste(labels,collapse="+")))
		auxfit<-lm(aux)
		auxsum<-summary(auxfit)
		stat<-length(auxsum$residuals)* auxsum$r.squared
		pval<-1-pchisq(stat,df=lag)
		detach(residssq)
		ARCH.Stat<-c(stat,pval)
		ARCH.Stat
	}

As input you have tp provide your model formula, the test itself is based
upon the lm-residuals.

HTH,
Bernhard

-----Original Message-----
From: Vincent Spiesser [mailto:Vincent.Spiesser at univ-tlse1.fr]
Sent: 09 December 2002 15:07
To: r-help at stat.math.ethz.ch
Subject: [R] heteroscedasticity analysis


Hello,
First, sorry for my poor english, I will try to be understood.
It's the first time I try this "r-help mailing list" and I hope it will be 
a success.

I am working on heteroscedasticity analysis. I would like to get the 
"Box-Ljung" and the "Lagrange multipliers" test.
I found the first one in the library "ts", but I can't find the second one. 
Does anybody know how this test can be called.

Vincent Spiesser

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help


----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.
----------------------------------------------------------------------



From michaell.taylor at reis.com  Mon Dec  9 16:53:09 2002
From: michaell.taylor at reis.com (Michaell Taylor)
Date: Mon Dec  9 16:53:09 2002
Subject: [R] writing S-Plus datasets
Message-ID: <200212091044.33076.michaell.taylor@reis.com>


I find myself needing to write R data frames to S-Plus (sdd) forma to ship to 
clients.  Currently I save the R data into text files and import into S-Plus 
to form sdd file.  I would very much like to skip the S-Plus stage if 
possible (for a variety of silly reasons shipping the text files is not an 
answer.)  ---  Pretty good endorsement of R eh?, I own S-plus and want to 
avoid using it in favor of R.

I would consider scriptable non-S-plus data conversion utilities.

I know that the foreign package allows one to read S-Plus files in R, but 
seemingly there is not a 'write.S' function.  

Any one tackled this issue already?


=========================================
Michaell Taylor, PhD



From andy_liaw at merck.com  Mon Dec  9 16:58:03 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon Dec  9 16:58:03 2002
Subject: [R] ifelse ?
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC988@usrymx10.merck.com>

The following seems to do what you want:

fuz <- function(x) {
  x.range <- quantile(x, c(.15, .85))
  x[x < x.range[1]] <- x.range[1]
  x[x > x.range[2]] <- x.range[2]
  x <- (x - x.range[1]) / (x.range[2] - x)
  x
}

HTH,
Andy

-----Original Message-----
From: Christian Schulz [mailto:ozric at web.de]
Sent: Monday, December 09, 2002 10:23 AM
To: r-help at stat.math.ethz.ch
Subject: [R] ifelse ?


Hi,

i want transform data and using apply(data,2,fuz)
, but i don't know why the values   < low  &  > high  don't get 0 or 1, they
get
the value from Formula ,too  "((x-low)/(high-low))"  what's not the
intention ?

....is switch more approriate !?

thanks for advance ,Christian

fuz <- function (x) {
#x <- na.omit(x)
low <- quantile(x,0.15)[[1]]
high <- quantile(x,0.85)[[1]]
if (x < low ) zg <- 0
if (x >= low &  x <= high)
zg <- ((x-low)/(high-low))
if (x > high)
zg <- 1
return(zg) }


fuz <- function (x) {
#x <- na.omit(x)
low <- quantile(x,0.15)[[1]]
high <- quantile(x,0.85)[[1]]
ifelse(x < low,0,(x-low)/(high-low))
ifelse (x > high,1,(x-low)/(high-low))}

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named in this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.



From mohamed at engr.uconn.edu  Mon Dec  9 17:20:03 2002
From: mohamed at engr.uconn.edu (Mohamed A. Kerasha)
Date: Mon Dec  9 17:20:03 2002
Subject: [R] Cyclic arrivals
Message-ID: <3DF4C28D.7090604@engr.uconn.edu>

Dear R help,

Is there a way to generate a cyclic arrivals in R, where the number of 
jobs submitted strongly correlates with the time of the day and the day 
of the week.

Thanks in advance,

-Mohamed.



From Mark.Wilkinson at stjude.org  Mon Dec  9 17:34:06 2002
From: Mark.Wilkinson at stjude.org (Wilkinson, Mark)
Date: Mon Dec  9 17:34:06 2002
Subject: [R] RE: Passing options as lists
Message-ID: <A1DAD6685C12D511B20F00034725151380CD3C@sjmemexc3.stjude.org>

Thanks a bunch to those who replied to my convoluted question.

Wiener, Matthew [matthew_wiener at merck.com] says to use do.call("plot",
args.list).
This is what I chose to do.

In addtion to do.call(), Mark.Bravington at csiro.au suggested incrementally
building the call:

my.plot.func <- function(data1, data2, data3,
	data1.options=list(),
	data2.options=list(),
	data3.options=list()) {

## call layout to divide the device
## plot data1 with par options in data1.options
call1_ quote( plot( data1)) # the basic call, as an expression
call1_ as.call( c( as.list( call1), data1.options)) # tack on the extra
args
eval( call1)  # evaluate it

<< rest of code>>

}



Mark Wilkinson
Informatics Analyst
St. Jude Children's Research Hospital
Department of Pharmaceutical Sciences


		 -----Original Message-----
		From: 	Wilkinson, Mark  
		Sent:	Thursday, December 05, 2002 1:08 PM
		To:	'r-help at stat.math.ethz.ch'
		Subject:	Passing options as lists


		Hi,

		I apologize if this has previously been posted.  I've just
subscribed to the R-help digest.

		I'm writing a plotting function that uses layout() to plot
several different plots on the same device.  This function uses plot(),
image(), and a custom function that uses text().  Each cell of the layout
needs different par() parameters, so what I'd like to do is pass them as
lists:

		my.plot.func <- function(data1, data2, data3,
		                         data1.options=list(),
		                         data2.options=list(),
		                         data3.options=list()) {

		  ## call layout to divide the device

		  ## plot data1 with par options in data1.options
		  ## plot data2 with par options in data2.options
		  ## plot data3 with par options in data3.options

		}

		my.plot.func(data1, data2, data3,
data1.options=list(arg1=12, arg2=FALSE, cex=.8, las=3),
data2.options=list(cex=2, lwd=3))

		'. . .' wouldn't seem to work.

		How can the user set the options with provided values, while
retaining the default arg values?  This is what I'm trying, but doesn't seem
to work in all cases, especially for '. . .':

		args.full <- function(func.name, opt.list) {
		  form <-formals(func.name)
		  ddd <- c()
		  
		  rtn <- sapply(union(names(form), names(opt.list)),
function(arg) {
		    if (is.null(opt.list[[arg]])) {  # not user-defined
		      form[[arg]]
		    } else if (is.null(form[[arg]])) { # user-defined '...'
		      ddd <<- c(ddd, opt.list[[arg]])
		    } else {
		      opt.list[[arg]]
		    }
		  })
		  
		  rtn[["..."]] <- ddd
		  return(rtn)
		}

		opt1.data1 <- args.full("internal.plot.func", data1.options)

		Then, within the function, setting each value to the
corresponding name from the return value of the above function with eval(),
e.g., internal.plot.func(data1, arg1=eval(opt.data1$arg1),
arg2=eval(opt.data1$arg2), eval(opt.data1$...)).

		One problem is with '. . .'; those par parameters don't get
passed.

		I'd also like this to work in general, not just for passing
plotting parameters.  Let me know if I haven't been clear.

		Thanks,
		
		Mark Wilkinson
		Informatics Analyst
		St. Jude Children's Research Hospital
		Department of Pharmaceutical Sciences



From ozric at web.de  Mon Dec  9 18:29:03 2002
From: ozric at web.de (Christian Schulz)
Date: Mon Dec  9 18:29:03 2002
Subject: [R] ifelse ?
References: <51F9C42DA15CD311BD220008C707D81906FFC988@usrymx10.merck.com>
Message-ID: <001201c29fa7$dc4f3b10$b09f06d5@c5c9i0>

many thanks !
Subscripting  is really the power of R and for next problems i hopefully
don't forget it :-(

christian


----- Original Message -----
From: "Liaw, Andy" <andy_liaw at merck.com>
To: "'Christian Schulz'" <ozric at web.de>; <r-help at stat.math.ethz.ch>
Sent: Monday, December 09, 2002 4:57 PM
Subject: RE: [R] ifelse ?


> The following seems to do what you want:
>
> fuz <- function(x) {
>   x.range <- quantile(x, c(.15, .85))
>   x[x < x.range[1]] <- x.range[1]
>   x[x > x.range[2]] <- x.range[2]
>   x <- (x - x.range[1]) / (x.range[2] - x)
>   x
> }
>
> HTH,
> Andy
>
> -----Original Message-----
> From: Christian Schulz [mailto:ozric at web.de]
> Sent: Monday, December 09, 2002 10:23 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] ifelse ?
>
>
> Hi,
>
> i want transform data and using apply(data,2,fuz)
> , but i don't know why the values   < low  &  > high  don't get 0 or 1,
they
> get
> the value from Formula ,too  "((x-low)/(high-low))"  what's not the
> intention ?
>
> ....is switch more approriate !?
>
> thanks for advance ,Christian
>
> fuz <- function (x) {
> #x <- na.omit(x)
> low <- quantile(x,0.15)[[1]]
> high <- quantile(x,0.85)[[1]]
> if (x < low ) zg <- 0
> if (x >= low &  x <= high)
> zg <- ((x-low)/(high-low))
> if (x > high)
> zg <- 1
> return(zg) }
>
>
> fuz <- function (x) {
> #x <- na.omit(x)
> low <- quantile(x,0.15)[[1]]
> high <- quantile(x,0.85)[[1]]
> ifelse(x < low,0,(x-low)/(high-low))
> ifelse (x > high,1,(x-low)/(high-low))}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
> --------------------------------------------------------------------------
----
> Notice:  This e-mail message, together with any attachments, contains
information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that
may be confidential, proprietary copyrighted and/or legally privileged, and
is intended solely for the use of the individual or entity named in this
message.  If you are not the intended recipient, and have received this
message in error, please immediately return this by e-mail and then delete
it.
>
>
============================================================================
==
>



From alain.guerreau at fnac.net  Mon Dec  9 19:20:03 2002
From: alain.guerreau at fnac.net (guerreau)
Date: Mon Dec  9 19:20:03 2002
Subject: [R] smooth curves (following)
Message-ID: <002901c29faf$87a3d730$b941cbd5@jetzt0>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021209/e744fb9b/attachment.pl

From rexbryan1 at attbi.com  Mon Dec  9 19:48:02 2002
From: rexbryan1 at attbi.com (RexBryan)
Date: Mon Dec  9 19:48:02 2002
Subject: [R] Problem with differences between S+ and R in parsing output tables with $
Message-ID: <000001c29fb3$db9e4420$3182fd0c@dell1700>

R-wizards

I have successfully run with S+ a statistical power calculation for
non-normal distributions as presented in M. Crawley?s new book.? When I
tried the newest version of R on the same code, the $ parse statement
doesn't seem to retrieve the appropriate number from a table. Note that
some of the cosmetic differences in the two tables have to be dealt with
by the parser. Any ideas what's happening?
REX

# Begin R -------------------------------------------------------------
#
> summary(aov(model))
 
             	Df 	Sum Sq 	Mean Sq 	F value 	Pr(>F)
fa            	1   	11.1    	11.1  	0.9327 	0.3345
Residuals   	698 	8279.3    	11.9

# R: ... trying to parse the table gives a NULL for the probability of
F... 

> (summary(aov(model))$"Pr(>F)")[1]
NULL

# End R ---------------------------------------------------------------

# Begin S+ ------------------------------------------------------------

> summary(aov(model))

           		Df 	Sum of Sq  	Mean Sq   	F Value
Pr(F) 
fa   			1    	11.063 	11.06286 	0.9326708
0.3345044
Residuals 		698  	8279.314 	11.86148          

# S+ ... using $ to parse the table gives the right answer for the
probability of F...

(summary(aov(model))$"Pr(F)")[1]
[1] 0.3345044

# End S+ --------------------------------------------------------------



From bates at stat.wisc.edu  Mon Dec  9 20:25:03 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon Dec  9 20:25:03 2002
Subject: [R] Problem with differences between S+ and R in parsing output tables with $
In-Reply-To: <000001c29fb3$db9e4420$3182fd0c@dell1700>
References: <000001c29fb3$db9e4420$3182fd0c@dell1700>
Message-ID: <6rel8rgfm9.fsf@bates5.stat.wisc.edu>

"RexBryan" <rexbryan1 at attbi.com> writes:

> R-wizards
> 
> I have successfully run with S+ a statistical power calculation for
> non-normal distributions as presented in M. Crawley's new book.? When I
> tried the newest version of R on the same code, the $ parse statement
> doesn't seem to retrieve the appropriate number from a table. Note that
> some of the cosmetic differences in the two tables have to be dealt with
> by the parser. Any ideas what's happening?
> REX
> 
> # Begin R -------------------------------------------------------------
> #
> > summary(aov(model))
>  
>              	Df 	Sum Sq 	Mean Sq 	F value 	Pr(>F)
> fa            	1   	11.1    	11.1  	0.9327 	0.3345
> Residuals   	698 	8279.3    	11.9
> 
> # R: ... trying to parse the table gives a NULL for the probability of
> F... 
> 
> > (summary(aov(model))$"Pr(>F)")[1]
> NULL
> 
> # End R ---------------------------------------------------------------

Hmm - that's a peculiar way of trying to extract the information but
if you really want to do it like that you should first use str() to
determine the structure of the returned value.  It turns out that the
value is a list and the first component of the list is a data frame
with one column labelled "Pr(>F)".


> str(summary(aov(model)))
List of 1
 $ :Classes anova  and `data.frame':	3 obs. of  5 variables:
  ..$ Df     : num [1:3] 3 5 15
  ..$ Sum Sq : num [1:3] 13445  1428   781
  ..$ Mean Sq: num [1:3] 4482  286   52
  ..$ F value: num [1:3] 86.11  5.49    NA
  ..$ Pr(>F) : num [1:3] 1.11e-09 4.55e-03       NA
 - attr(*, "class")= chr [1:2] "summary.aov" "listof"

This means you would need to put [[1]] before the $

> summary(aov(model))[[1]]$"Pr(>F)"
[1] 1.110419e-09 4.550074e-03           NA



From ben at zoo.ufl.edu  Mon Dec  9 20:38:02 2002
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Mon Dec  9 20:38:02 2002
Subject: [R] Problem with differences between S+ and R in parsing output
 tables with $
In-Reply-To: <000001c29fb3$db9e4420$3182fd0c@dell1700>
Message-ID: <Pine.LNX.4.44.0212091436330.27152-100000@bolker.zoo.ufl.edu>

  In R, it looks like the "summary.aov" type actually contains the data 
frame you're trying to extract as the first (and only) element of a list, 
so 

summary(aov(model))[[1]]

is more or less equivalent to the summary(aov(model)) object in S-PLUS, 
and

summary(aov(model))[[1]]$"Pr(>F)"[1]

gets the specific number you're looking for.

str()  and class() are the tools for disentangling this kind of problem.  
It is a shame that it's so hard to extract the value in this case, but the
authors have to be able to structure things internally however they find
convenient, and unless they provide accessor methods for everything anyone 
could conceivably want, people are going to have to dig at some point ...


On Mon, 9 Dec 2002, RexBryan wrote:

> R-wizards
> 
> I have successfully run with S+ a statistical power calculation for
> non-normal distributions as presented in M. Crawley?s new book.? When I
> tried the newest version of R on the same code, the $ parse statement
> doesn't seem to retrieve the appropriate number from a table. Note that
> some of the cosmetic differences in the two tables have to be dealt with
> by the parser. Any ideas what's happening?
> REX
> 
> # Begin R -------------------------------------------------------------
> #
> > summary(aov(model))
>  
>              	Df 	Sum Sq 	Mean Sq 	F value 	Pr(>F)
> fa            	1   	11.1    	11.1  	0.9327 	0.3345
> Residuals   	698 	8279.3    	11.9
> 
> # R: ... trying to parse the table gives a NULL for the probability of
> F... 
> 
> > (summary(aov(model))$"Pr(>F)")[1]
> NULL
> 
> # End R ---------------------------------------------------------------
> 
> # Begin S+ ------------------------------------------------------------
> 
> > summary(aov(model))
> 
>            		Df 	Sum of Sq  	Mean Sq   	F Value
> Pr(F) 
> fa   			1    	11.063 	11.06286 	0.9326708
> 0.3345044
> Residuals 		698  	8279.314 	11.86148          
> 
> # S+ ... using $ to parse the table gives the right answer for the
> probability of F...
> 
> (summary(aov(model))$"Pr(F)")[1]
> [1] 0.3345044
> 
> # End S+ --------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From ben at zoo.ufl.edu  Mon Dec  9 20:43:03 2002
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Mon Dec  9 20:43:03 2002
Subject: [R] Problem with differences between S+ and R in parsing output
 tables with $
In-Reply-To: <6rel8rgfm9.fsf@bates5.stat.wisc.edu>
Message-ID: <Pine.LNX.4.44.0212091443160.27192-100000@bolker.zoo.ufl.edu>

On 9 Dec 2002, Douglas Bates wrote:

> Hmm - that's a peculiar way of trying to extract the information but
> if you really want to do it like that you should first use str() to
> determine the structure of the returned value.  It turns out that the
> value is a list and the first component of the list is a data frame
> with one column labelled "Pr(>F)".
> 

  How would you normally go about extracting such information?  Other than 
doing it via summary(model(aov))[[1]]$"Pr(>F)"[1] [which is admittedly 
pretty horrible], or extracting the raw information from the aov object 
and computing the F-prob oneself, I can't see how to do it ...

  Ben



From bates at stat.wisc.edu  Mon Dec  9 20:56:03 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon Dec  9 20:56:03 2002
Subject: [R] Problem with differences between S+ and R in parsing output tables with $
In-Reply-To: <Pine.LNX.4.44.0212091443160.27192-100000@bolker.zoo.ufl.edu>
References: <Pine.LNX.4.44.0212091443160.27192-100000@bolker.zoo.ufl.edu>
Message-ID: <6r3cp7ge77.fsf@bates5.stat.wisc.edu>

Ben Bolker <ben at zoo.ufl.edu> writes:

> On 9 Dec 2002, Douglas Bates wrote:
> 
> > Hmm - that's a peculiar way of trying to extract the information but
> > if you really want to do it like that you should first use str() to
> > determine the structure of the returned value.  It turns out that the
> > value is a list and the first component of the list is a data frame
> > with one column labelled "Pr(>F)".
> > 
> 
>   How would you normally go about extracting such information?  Other than 
> doing it via summary(model(aov))[[1]]$"Pr(>F)"[1] [which is admittedly 
> pretty horrible], or extracting the raw information from the aov object 
> and computing the F-prob oneself, I can't see how to do it ...

I think this means I should learn not to make editorial comments and
just stick to the answer.  On reflection I think you are correct in
what you said in your earlier posting.  This is not a particularly
elegant way of getting the p-value but it seems to be the only way of
doing so.  There is no accessor method for it.  Having an accessor
would be a more elegant design.



From rbf21 at student.canterbury.ac.nz  Mon Dec  9 21:08:03 2002
From: rbf21 at student.canterbury.ac.nz (Robert B Fenwick)
Date: Mon Dec  9 21:08:03 2002
Subject: [R] teach me to write functions
Message-ID: <3DF4F80F.7C69C00E@student.canterbury.ac.nz>

Hi 

I am a programming pleb, however I would like to learn how to write my
own functions and methods.

Can anyone suggest a good place to start teaching myself, readings or
other?



From colin at DMI.USherb.CA  Mon Dec  9 21:32:02 2002
From: colin at DMI.USherb.CA (Bernard Colin)
Date: Mon Dec  9 21:32:02 2002
Subject: [R] Re : Information
Message-ID: <001101c29fc1$cc85cae0$7f28d284@dmi.usherb.ca>

To whom it may concern,

For a sample (xi,yi) i=1,2,...,n of a bivariate normal vector (X,Y), I have
to evaluate ( for some simulation) the cumulative distribution function of
(X,Y) at each point (xi,yi) and I have not find in R a package that evaluate
this function. Is there a such package in R? If no, how can I do to make my
simulation succesful?

Thank you very much for your assistance.

Sincerely yours

Colin Bernard


Colin Bernard
Professeur titulaire
D?partement de Math?matiques et d'Informatique
Facult? des Sciences
Universit? de Sherbrooke
SHERBROOKE J1K-2R1 (Qu?bec)
Canada
Tel : (819)821-8000 poste 2012
Fax :(819)821-8200
e-mail : bernard.colin at dmi.usherb.ca



From jfox at mcmaster.ca  Mon Dec  9 21:50:03 2002
From: jfox at mcmaster.ca (John Fox)
Date: Mon Dec  9 21:50:03 2002
Subject: [R] heteroscedasticity analysis
In-Reply-To: <18D602BD42B7E24EB810D6454A58DB9001CAE0C1@ibfftce505.is.de.
 dresdnerkb.com>
Message-ID: <5.1.0.14.2.20021209154718.01e35080@mcmail.cis.mcmaster.ca>

Dear Vincent,

See the ncv.test function in the car package.

I hope that this helps,
  John


>-----Original Message-----
>From: Vincent Spiesser [mailto:Vincent.Spiesser at univ-tlse1.fr]
>Sent: 09 December 2002 15:07
>To: r-help at stat.math.ethz.ch
>Subject: [R] heteroscedasticity analysis
>
>
>First, sorry for my poor english, I will try to be understood.
>It's the first time I try this "r-help mailing list" and I hope it will be
>a success.
>
>I am working on heteroscedasticity analysis. I would like to get the
>"Box-Ljung" and the "Lagrange multipliers" test.
>I found the first one in the library "ts", but I can't find the second one.
>Does anybody know how this test can be called.

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From s.mcclatchie at niwa.co.nz  Mon Dec  9 22:05:03 2002
From: s.mcclatchie at niwa.co.nz (Sam McClatchie)
Date: Mon Dec  9 22:05:03 2002
Subject: [R] r-help:
Message-ID: <3DF50534.6010509@niwa.cri.nz>

System info:
Linux slackware
R Version 1.6.0  (2002-10-01)
ESS 5.1.21
Emacs 21.2.1
-------------------

Colleagues

Can anyone tell me what R does with local variables when they are passed
in a system call to a shell script?

e.g. I have a string as an R variable called tripcode. I want to pass
this variable in a system call to a local bash script calling gmt
(Generic Mapping Tool) functions:

  system("source map_acoustic_transects_and_trawls.gmt", tripcode)

I think this is what is meant in Section 4.6 of Venables and Ripley(?).

When I ECHO the parameter passed into the bash script nothing is returned:

echo "TripCode" $tripcode
TripCode

Is there a way to do this efficiently without writing the string
variable to a file and re-reading it into the shell script?

Thanks for advice,

Sam
-- 
Sam McClatchie, Research scientist (fisheries acoustics))))))))))
NIWA (National Institute of Water & Atmospheric Research Ltd)
PO Box 14 901, Kilbirnie, Wellington, New Zealand
s.mcclatchie at niwa.cri.nz
Research home page <http://www.smcc.150m.com/>
                       /\
            >><xX(&>
                    /// \\\
                   //// \\\\
                  ///  <%)Xx><<
                 /////  \\\\\\
           ><(((@>
     ><(((%>     ..>><xX(?>O<?)Xx><<



From Ko-Kang at xtra.co.nz  Mon Dec  9 22:17:03 2002
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Mon Dec  9 22:17:03 2002
Subject: [R] teach me to write functions
References: <3DF4F80F.7C69C00E@student.canterbury.ac.nz>
Message-ID: <006001c29fc8$150c04e0$9d7536d2@kwan022>

Hi,

John Chambers's "Programming with Data", aka The Green Book is a good start.

Or/and Venables and Ripley's "S Programming".

Cheers,

Kevin

------------------------------------------------
Ko-Kang Kevin Wang
Master of Science MSc Student
Department of Statistics
University of Auckland
New Zealand
www.stat.auckland.ac.nz/~kwan022

----- Original Message -----
From: "Robert B Fenwick"
<rbf21 at student.canterbury.ac.nz>
To: "R, help" <r-help at stat.math.ethz.ch>
Sent: Tuesday, December 10, 2002 9:07 AM
Subject: [R] teach me to write functions


> Hi
>
> I am a programming pleb, however I would like to learn how to write my
> own functions and methods.
>
> Can anyone suggest a good place to start teaching myself, readings or
> other?
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



********************************************
Viralock... Zero Escape for Email Viruses... http://www.viralock.com



From pocernic at rap.ucar.edu  Mon Dec  9 23:19:05 2002
From: pocernic at rap.ucar.edu (Matt Pocernich)
Date: Mon Dec  9 23:19:05 2002
Subject: [R] netcdf
Message-ID: <Pine.LNX.4.44.0212091503590.7491-100000@markov.rap.ucar.edu>

Hello,

I have been having difficulties opening netcdf files using the netcdf
library.  I am able to successfully open the file and I can determine the
names and size.  However, when I try to read it I receive an error.
Reading the documentation, I am wondering if this might be due to a
difference between netcdf version 2 and more recent netcdf format? I've
tried using different values for the count option without luck.  I have
had success reading this file into matlab.


> library(netCDF)
> aaa<- open.netCDF("/scratch/pocernic/int_fcst.20021201.0010.nc")
> class(aaa)
[1] "netCDF"
> summary(aaa)
netCDF file /scratch/pocernic/int_fcst.20021201.0010.nc is open
$types
 [1] "integer" "numeric" "numeric" "integer" "integer" "integer" "single"
 [8] "single"  "single"  "single"  "single"  "single"  "single"  "single"
[15] "single"  "single"  "single"  "single"  "single"  "single"  "single"
[22] "single"  "single"  "single"  "single"
 ... etc

## when I try to read it, I get the following error.

> bbb<- read.netCDF(aaa)
Error: dim: Invalid dimension vector

Thanks

Matt

Matt Pocernich
NCAR - Research Applications Group
303-497-8312



From r.hankin at auckland.ac.nz  Mon Dec  9 23:44:02 2002
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Mon Dec  9 23:44:02 2002
Subject: [R] generalized cbind()
Message-ID: <200212092235.gB9MZeU22979@r.hankin.sges.auckland.ac.nz>

Hello Rexperts

If I have an array "a" with a <- array(1:8,c(2,2,2)) then there are
three ways of putting "a" together with another version of "a", one
for each dimension.

The first way is easy:

 array(c(a,a),c(2,2,4))
, , 1

     [,1] [,2]
[1,]    1    3
[2,]    2    4

, , 2

     [,1] [,2]
[1,]    5    7
[2,]    6    8

, , 3

     [,1] [,2]
[1,]    1    3
[2,]    2    4

, , 4

     [,1] [,2]
[1,]    5    7
[2,]    6    8

[that is, just a and then another a in positions [,,1:2].  Is there an
easy way to create the equivalent thing but joined along another
dimension?  The other two would be:


     [,1] [,2] [,3] [,4]
[1,]    1    3    1    3
[2,]    2    4    2    4

, , 2

     [,1] [,2] [,3] [,4]
[1,]    5    7    5    7
[2,]    6    8    6    8


and



, , 1

     [,1] [,2]
[1,]    1    3
[2,]    2    4
[3,]    1    3
[4,]    2    4

, , 2

     [,1] [,2]
[1,]    5    7
[2,]    6    8
[3,]    5    7
[4,]    6    8 


Does anyone know of a function that would do this? It would ideally be
called like


R> join(a,a,dimension=3)



-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042

as of: Tue Dec 10 11:32:00 NZDT 2002
This (linux) system up continuously for:  467 days, 17 hours, 14 minutes



From rexbryan1 at attbi.com  Tue Dec 10 00:35:03 2002
From: rexbryan1 at attbi.com (RexBryan)
Date: Tue Dec 10 00:35:03 2002
Subject: [R] FW: Answers to "Problem with differences between S+ and R in parsing output tables with $"
Message-ID: <000001c29fdc$0d8337c0$3182fd0c@dell1700>

To R-wizards:

Thank you for your quick an insightful responses.  I now have R running
a translated version of S+ code for power calculations for non-normal
data.  This is from the Michael Crawley's new book Statistical
Computing--An Introduction to Data Analysis using S-Plus. Peter Dalgaard
corrected me on the issue of the $ operator not being a parser.  It sure
looked like an advanced Regex type command to me!  Andy Liaw was there
quickly with the answer, while Ben Bolker and Douglas Bates showed the
importance of the str() function to sort out problems like these.
Thanks to all.  I will ask more questions in the future as I plunge more
and more into R.

The code set forward by M. Crawley seems to eloquently establish a
fundamental calculating engine for determining the power of a test for
non-normal data.  If one has seen how many contorted lines are required
for the same thing in programs like C++, FORTRAN, SAS or Statistica you
would appreciate my use of term "eloquence".  How-to discussions of the
calculation of Power [1 - F(-)] tends to be glossed over even in them
most advanced of statistical books.  Not so for Statistical
Computing...for that I recommend it.

The code with S+ and R variants that work is shown below.  It would be
nice if someone could come up with a version that can be used by both S+
and R without transform. The use of the statement "summary(aov(model))"
seems more universal than the statement "summary.aov(model)".  Anyone
know why?


>d<-numeric(1000)
>n<-350
>for(i in 1:1000){
> y1<-rnbinom(n,1,.3)  
> y2<-rnbinom(n,1,.25)
> y<-c(y1,y2)
> fa<-factor(c(rep(1,n),rep(2,n)))
> model<-glm(y~fa,poisson)
># S+ variants
>#d[i]<-as.vector(summary(aov(model))$"Pr(F)")[1]}    #A. Does work in
S+  
>#d[i]<-as.vector(summary.aov(model)$"Pr(F)")[1]}     #B. Does work in
S+  
>#
------------------------------------------------------------------------
># R variants
>d[i]<-as.vector(summary(aov(model))[[1]]$"Pr(>F)"[1])#C. Does work in R

>#
------------------------------------------------------------------------
>}

Essentially an F test comparing two means is been performed 1000 times,
with 1000 tables produced and only the alpha level extracted and kept.
These 1000 alphas are kept in vector d[].  The question then is asked:
How many times out of 1000 does a random sampling of two distributions
known to have different means produce a statistically significant
difference? That proportion is considered an estimate of the Power or
the test.  In this case the simulation could produce a number like 0.840
given when the alpha level of 0.05 and n1=n2=350 are set.
Ex:

> sum(d<0.05)/1000  
>[1] 0.8400

Why I call this a "Power calculating engine" is that:
1. Vectors y1 and y2 can have different n1 and n2.
2. y1 and y2 can come from ANY distribution, even complex ones
3. y1 and y2 can even come from distributions that are not easily
defined, i.e. from bootstrapping.
4. The code can be tailored to estimate Power even when multi-stage
tests are proposed.


I hope that my intuition is correct.

REX 


 

-----Original Message-----
From: RexBryan [mailto:rexbryan1 at attbi.com] 
Sent: Monday, December 09, 2002 11:51 AM
To: 'r-help at lists.R-project.org'
Subject: Problem with differences between S+ and R in parsing output
tables with $ 

R-wizards

I have successfully run with S+ a statistical power calculation for
non-normal distributions as presented in M. Crawley?s new book.? When I
tried the newest version of R on the same code, the $ parse statement
doesn't seem to retrieve the appropriate number from a table. Note that
some of the cosmetic differences in the two tables have to be dealt with
by the parser. Any ideas what's happening?
REX

# Begin R -------------------------------------------------------------
#
> summary(aov(model))
 
             	Df 	Sum Sq 	Mean Sq 	F value 	Pr(>F)
fa            	1   	11.1    	11.1  	0.9327 	0.3345
Residuals   	698 	8279.3    	11.9

# R: ... trying to parse the table gives a NULL for the probability of
F... 

> (summary(aov(model))$"Pr(>F)")[1]
NULL

# End R ---------------------------------------------------------------

# Begin S+ ------------------------------------------------------------

> summary(aov(model))

           		Df 	Sum of Sq  	Mean Sq   	F Value
Pr(F) 
fa   			1    	11.063 	11.06286 	0.9326708
0.3345044
Residuals 		698  	8279.314 	11.86148          

# S+ ... using $ to parse the table gives the right answer for the
probability of F...

(summary(aov(model))$"Pr(F)")[1]
[1] 0.3345044

# End S+ --------------------------------------------------------------



From r-spady at nwu.edu  Tue Dec 10 01:34:02 2002
From: r-spady at nwu.edu (Richard Spady)
Date: Tue Dec 10 01:34:02 2002
Subject: [R] RGnumeric real time refresh?
Message-ID: <3DF53664.8234A72A@nwu.edu>

I have data that comes in every 7 seconds or so and I'd like to display it in a spreadsheet, and
possibly take user input from the spreadsheet.

I have installed RGnumeric and written an appropriate R function that reads, manipulates and
displays the data by writing via RGnumeric to a spreadsheet. However, the results of this are
not displayed until the R function returns, so refreshing by just putting the body of this function
in a loop will not work (apparently.) Nor can I see how to get Gnumeric to call the function
repeatedly, i.e. without retyping 'runR()' or similar; even the refresh button F9 only works once
(therafter a message to the effect that "R Code is not found" appears.)

Any pointers?

Thnaks,
Richard Spady
P.S. This ua Gnumeric 1.0.9 on RedHat 8.0, R 1.6.1.



From peters5 at mail.com  Tue Dec 10 07:43:06 2002
From: peters5 at mail.com (ONI  THEO)
Date: Tue Dec 10 07:43:06 2002
Subject: [R] URGENT
Message-ID: <200212100642.gBA6gsYE007358@hypatia.math.ethz.ch>

Attention:

I presume this email will not be a surprise to you.

Am an engineer with the ministry of mineral resources
and energy in south Africa and also a member of the 
contract awarding committee of this ministry under the south
Africa government.

Many year ago, the south Africa government asked this committee
to awards contracts to foregn firms, in which myself and two 
of my partner are leader of the committee, with our good
position in this committee, we over involved this contract to 
the tune of of us$21,500,000:00, to be benefited by me and two 
other of my partner that are in charge of this contract awarding 
committee in this ministry.

Now, that the contracts value has been paid off to the actual
contractor that executed this job, All we want is a trusted 
foreign partner like you that we shall front to claim this over
involved sum.

Upon our agreement to carry on this business transaction with you,
the said fund will be share as follow, 75% will be for myself and two 
others of my partner, 20% will be for you for using your bank account,
5% will be set aside for any expenses that might be incurred by us and 
you in the process of the document and other formalities that will 
justify you as the rightful owner of this said fund.

You should bear in mind that you will be required to put head together
with us, and give this business transaction moral and financially 
support it required to be successful.

If you are interested and financially capable in handly this business
transaction, Kindly reply us through this email address  (theoruffy at netscape.net)
for more details and to let you know what is required of this business 
transaction to be successful.

Also we request your private and office phone number to open communication
with you.

Your faithfully,

Oni  Theo



From arv at ono.com  Tue Dec 10 08:26:04 2002
From: arv at ono.com (antonio rodriguez)
Date: Tue Dec 10 08:26:04 2002
Subject: [R] netcdf
References: <Pine.LNX.4.44.0212091503590.7491-100000@markov.rap.ucar.edu>
Message-ID: <01d501c2a01d$a7ae29e0$0300a8c0@ono>

Hi Matt,

I use the following procedure after opening a netcdf file:

library(netCDF)
wind<-read.netCDF("C:/To?o/datos/fnomc_nc/wind.nc")
str(wind)
a<-wind$"UV_MAG_MEAN"
a[a == attributes(a)$"missing_value"] <- NA
dimnames(a) <-
list(wind$"TIME_SERIES",wind$"LAT125_128",wind$"LON351_354")

Hope this helps

Cheers,

Antonio Rodriguez



From gisar at nus.edu.sg  Tue Dec 10 08:51:02 2002
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Tue Dec 10 08:51:02 2002
Subject: [R] Variance of a single number
Message-ID: <024D6AEFCB92CB47BA1085751D184BB80105F1CD@MBXSRV03.stf.nus.edu.sg>

Just out of curiosity, can some please explain the following return NA.

x <- 6
var(x)

y <- c( NA, NA, 10000 )
var(y, na.rm=T)


Unless I am seriously misguided, I believe that the variance of a single
number (i.e. a constant) should be zero. Thanks.

Regards, Adai.



From bojan.leskosek at guest.arnes.si  Tue Dec 10 09:53:03 2002
From: bojan.leskosek at guest.arnes.si (Bojan Leskosek)
Date: Tue Dec 10 09:53:03 2002
Subject: [R] C caron character in R
Message-ID: <000001c2a029$704b46c0$3364a8c0@sp.unilj.si>

Hi!
In R 1.6.1. for Windows using RGui interface I try to use characters of
Slovenian alphabet. Slovenia is a small Slavic country south of Austria
with 3 characters which are not found in English alphabet, namely C, S
and Z- all with caron. As S and Z are presented OK in both Console and
Graphics window, this is not the case with C caron, which is shown as E
acute- for an example please see:
http://www.sp.uni-lj.si/bojan/statuni/datoteke/temp/q.gif
(In RTerm problem is even worse - all characters are wrong. I don't want
to bother you with RTerm, because I rarely use it). 
Any idea?
Thanks in advance,

Bojan Leskosek
University of Ljubljana
Slovenia



From otoomet at econ.dk  Tue Dec 10 10:22:03 2002
From: otoomet at econ.dk (Ott Toomet)
Date: Tue Dec 10 10:22:03 2002
Subject: [R] r-help:
Message-ID: <200212100922.gBA9MkS08789@punik.econ.au.dk>

Hi,

 | From: Sam McClatchie <s.mcclatchie at niwa.co.nz>
 | Date: Tue, 10 Dec 2002 10:03:48 +1300
 | 
 | Can anyone tell me what R does with local variables when they are passed
 | in a system call to a shell script?
 | 
 | e.g. I have a string as an R variable called tripcode. I want to pass
 | this variable in a system call to a local bash script calling gmt
 | (Generic Mapping Tool) functions:
 | 
 |   system("source map_acoustic_transects_and_trawls.gmt", tripcode)

You are missing paste() here.  Look ?paste.
E.g.

a <- "-l"
> system("ls", a)
10-doc		     funktsioonid.R~	    lave-spell	       Overview.dvi
andmed		     gauss-analyse.tar.gz   lave-spell.tar.gz  Overview.log
artikkel2	     gauss-analyse.tar.gz~  Leifi_kirjad.txt   Overview.tex
...

> system(paste("ls", a))
total 488
drwxrwxr-x    2 otoomet  otoomet      4096 dets   5 14:19 10-doc
drwxrwxr-x    3 otoomet  otoomet      4096 nov   19 15:46 andmed
drwxrwxr-x    3 otoomet  otoomet      4096 dets   5 12:44 artikkel2
drwxrwxr-x    2 otoomet  otoomet      4096 dets   5 07:03 bilder
...

 | I think this is what is meant in Section 4.6 of Venables and Ripley(?).
 | 
 | When I ECHO the parameter passed into the bash script nothing is returned:
 | 
 | echo "TripCode" $tripcode
 | TripCode
 | 
 | Is there a way to do this efficiently without writing the string
 | variable to a file and re-reading it into the shell script?

Ott



From J.C.Rougier at durham.ac.uk  Tue Dec 10 11:12:03 2002
From: J.C.Rougier at durham.ac.uk (Jonathan Rougier)
Date: Tue Dec 10 11:12:03 2002
Subject: [R] generalized cbind()
References: <200212092235.gB9MZeU22979@r.hankin.sges.auckland.ac.nz>
Message-ID: <3DF5BDCC.7040809@durham.ac.uk>

Hi Robin,

I wrote myself a function "abind" to do this a while ago.  I have not 
used it recently but I am attaching the code and man page for you to 
have a look at.

Cheers, Jonathan.

Robin Hankin wrote:
> Hello Rexperts
> 
> If I have an array "a" with a <- array(1:8,c(2,2,2)) then there are
> three ways of putting "a" together with another version of "a", one
> for each dimension.

 > [snip]

-- 
Jonathan Rougier                       Science Laboratories
Department of Mathematical Sciences    South Road
University of Durham                   Durham DH1 3LE
tel: +44 (0)191 374 2361, fax: +44 (0)191 374 7388
http://www.maths.dur.ac.uk/stats/people/jcr/jcr.html
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: abind.R
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021210/b1c3d576/abind.pl
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: abind.Rd
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021210/b1c3d576/abind-0001.pl

From petr.pikal at precheza.cz  Tue Dec 10 11:25:08 2002
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue Dec 10 11:25:08 2002
Subject: [R] Variance of a single number
In-Reply-To: <024D6AEFCB92CB47BA1085751D184BB80105F1CD@MBXSRV03.stf.nus.edu.sg>
Message-ID: <3DF5CED3.5925.A7088C@localhost>

Most probably:


     The denominator n - 1 is used which gives an unbiased 
estimator of
     the (co)variance for i.i.d. observations. These functions return
     `NA' when there is only one observation (whereas S-plus has 
been
     returning `NaN'), and from R 1.2.3 fail if `x' has length zero.

from help page for var

try
?var


On 10 Dec 2002 at 15:50, Adaikalavan Ramasamy wrote:

> Just out of curiosity, can some please explain the following return
> NA.
> 
> x <- 6
> var(x)
> 
> y <- c( NA, NA, 10000 )
> var(y, na.rm=T)
> 
> 
> Unless I am seriously misguided, I believe that the variance of a
> single number (i.e. a constant) should be zero. Thanks.
> 
> Regards, Adai.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz



From ripley at stats.ox.ac.uk  Tue Dec 10 11:52:02 2002
From: ripley at stats.ox.ac.uk (Brian D Ripley)
Date: Tue Dec 10 11:52:02 2002
Subject: [R] Variance of a single number
In-Reply-To: <024D6AEFCB92CB47BA1085751D184BB80105F1CD@MBXSRV03.stf.nus.edu.sg>
Message-ID: <Pine.GSO.4.31.0212101050410.23694-100000@markov.stats>


On Tue, 10 Dec 2002, Adaikalavan Ramasamy wrote:

> Just out of curiosity, can some please explain the following return NA.
>
> x <- 6
> var(x)
>
> y <- c( NA, NA, 10000 )
> var(y, na.rm=T)
>
>
> Unless I am seriously misguided, I believe that the variance of a single
> number (i.e. a constant) should be zero. Thanks.

You are.  It's an estimate of the population variance, about which there
is no information at all in one number.  Or just look at the formula,
which gives 0/0.



From ripley at stats.ox.ac.uk  Tue Dec 10 11:57:04 2002
From: ripley at stats.ox.ac.uk (Brian D Ripley)
Date: Tue Dec 10 11:57:04 2002
Subject: [R] C caron character in R
In-Reply-To: <000001c2a029$704b46c0$3364a8c0@sp.unilj.si>
Message-ID: <Pine.GSO.4.31.0212101054550.23694-100000@markov.stats>


On Tue, 10 Dec 2002, Bojan Leskosek wrote:

> Hi!
> In R 1.6.1. for Windows using RGui interface I try to use characters of
> Slovenian alphabet. Slovenia is a small Slavic country south of Austria
> with 3 characters which are not found in English alphabet, namely C, S
> and Z- all with caron. As S and Z are presented OK in both Console and
> Graphics window, this is not the case with C caron, which is shown as E
> acute- for an example please see:
> http://www.sp.uni-lj.si/bojan/statuni/datoteke/temp/q.gif
> (In RTerm problem is even worse - all characters are wrong. I don't want
> to bother you with RTerm, because I rarely use it).
> Any idea?

Yes, the problem is in your version of Windows.  What OS is this?
R just asks Windows which characters are which, and Windows sometimes
lies.



From duncan at research.bell-labs.com  Tue Dec 10 12:37:08 2002
From: duncan at research.bell-labs.com (Duncan Temple Lang)
Date: Tue Dec 10 12:37:08 2002
Subject: [R] RGnumeric real time refresh?
In-Reply-To: <3DF53664.8234A72A@nwu.edu>; from r-spady@nwu.edu on Mon, Dec 09, 2002 at 06:33:40PM -0600
References: <3DF53664.8234A72A@nwu.edu>
Message-ID: <20021210063608.D3090@jessie.research.bell-labs.com>

That's a very nice example of a general concept that I have hoped we
might get to. There are a variety of ways to approach this issue.
While slightly abstract/apparently indirect, using the Gnumeric/Gtk
event loop is probably the easiest way to think about things and you
can interact with it using the RGtk package.

At its simplest, if you really knew that there was more data arriving
each and every 7 seconds, you could register a timer action with the
Gnumeric event loop using the gtkAddTimeout() function in theRGtk
package.  Here's a function a that one can call from Gnumeric which
arranges for the function f (defined inside this function) to be
called every interval milli-seconds.  That function f generates a
single normal observation and puts it in a cell ( A1 by default)
and forces the entire workbook to be updated.

setTimer <-
function(interval, r = 1, c = 1, .sheet) {
 library(RGtk)

 f <-
   function() {
     .sheet[r, c] <- rnorm(1, mean = 10)
     recalcBook(getGnumericWorkbook(.sheet))
     return(FALSE)
   }
 
 gtkAddTimeout(interval, f)
}

gnumeric.registerFunction(
      setTimer, "setTimer", "fff", "garbage", "Set a timer to fire each interval")
      
So you can then call this from within a Gnumeric cell as

  =setTimer(7000, 1, 1)

and it will just continue to update.

(The return(FALSE) at the end of f() is slightly unintuitive. It says
don't renew the timer action. Why? Because recalculating the sheet
will reset the timer when the =setTimer(..) cell is re-evaluated).


That's how you can do things with timers.  If the data is coming from
one of a collection of connection types (e.g. FIFOs, sockets, etc.) we
might register an S function that is invoked each time more data
becomes available.  In other words, we would put an event handler on
the connection. At present, this is not possible to do in regular R.
I have written code that implements it but never committed it for a
variety of reasons. Perhaps I will do so soon.

 Thanks for the application. This is one of the more interesting cases
which motivated the RGtk package.

 D.


Richard Spady wrote:
> I have data that comes in every 7 seconds or so and I'd like to display it in a spreadsheet, and
> possibly take user input from the spreadsheet.
> 
> I have installed RGnumeric and written an appropriate R function that reads, manipulates and
> displays the data by writing via RGnumeric to a spreadsheet. However, the results of this are
> not displayed until the R function returns, so refreshing by just putting the body of this function
> in a loop will not work (apparently.) Nor can I see how to get Gnumeric to call the function
> repeatedly, i.e. without retyping 'runR()' or similar; even the refresh button F9 only works once
> (therafter a message to the effect that "R Code is not found" appears.)
> 
> Any pointers?
> 
> Thnaks,
> Richard Spady
> P.S. This ua Gnumeric 1.0.9 on RedHat 8.0, R 1.6.1.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan



From ltorgo at liacc.up.pt  Tue Dec 10 12:50:07 2002
From: ltorgo at liacc.up.pt (Luis Torgo)
Date: Tue Dec 10 12:50:07 2002
Subject: [R] lattice barchart with "negative" bars
Message-ID: <200212101211.13595.ltorgo@liacc.up.pt>

Dear all,

I'm trying to use the lattice barchart function to obtain a bar plot of a 
variable for different values of two factors. The thing I'm trying to do is 
something like this:

> barchart(MyVar ~ season | place, data=mydataset)

My problem is that the column MyVar has some negative values and I would like 
them to be represented as bars stacking down from zero instead of what the 
function does that is finding the minimum value and then stacking all bars 
from this minimum value up. I've looked into the the help pages and I saw no 
way to go around this behaviour. Is there an easy way to get these "negative" 
bars?

Thanks,
Luis
 
-- 
Luis Torgo
    FEP/LIACC, University of Porto   Phone : (+351) 22 607 88 30
    Machine Learning Group           Fax   : (+351) 22 600 36 54
    R. Campo Alegre, 823             email : ltorgo at liacc.up.pt
    4150 PORTO   -  PORTUGAL         WWW   : http://www.liacc.up.pt/~ltorgo



From Ted.Harding at nessie.mcc.ac.uk  Tue Dec 10 12:57:03 2002
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue Dec 10 12:57:03 2002
Subject: [R] clogit and general conditional logistic regression
Message-ID: <XFMail.021210113516.Ted.Harding@nessie.mcc.ac.uk>

Can someone clarify what I cannot make out from the
documentation?

The function 'clogit' in the 'survival' package is
described as performing a "conditional logistic regression".
Its return value is stated to be "an object of class clogit
which is a wrapper for a coxph object."

This suggests that its usefulness is confined to the sort of
data which arise in survival/proportional hazard applications.

My question is: is 'clogit' capable of a general conditional
logistic analysis?

E.g. given a set of data on binomial experiments with Y=1
r_i times out of n_i, associated with levels A_i and B_i
of factors A and B at N_A and N_B levels, would

  clogit(Y ~ A+B, method=c(Exact"))

generate something sensible containing the results of a standard
exact conditional logistic regression of Y on A and B?

With thanks,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 10-Dec-02                                       Time: 11:35:16
------------------------------ XFMail ------------------------------



From silvia.sitton at prometeia.it  Tue Dec 10 13:04:02 2002
From: silvia.sitton at prometeia.it (Silvia Sitton)
Date: Tue Dec 10 13:04:02 2002
Subject: [R] question about R - barplot function
Message-ID: <5.1.1.6.0.20021210124049.00a08ba0@lisa>

I would ask you a question around the function "barplot"
I have a problem in the graphical output when I run, for example, this 
program (and the others like this):

postscript("copnido.ps",horizontal=F,family="Helvetica",pointsize=15.5,width=10.5,height=9)
par(mar=c(5,6,4,4))
dati <- read.table("infanzia.tab")
tasso <- cbind(dati$tasso)
barplot(tasso,beside = TRUE, space = c(0.6),col = c("blue"), axes = FALSE, 
ylim = c(25,40),horiz=FALSE)
axis(1,c(1.1,2.7,4.3,5.9,7.5),c("99-00","00-01", "01-02", "02-03", 
"03-04"),tck = 0,las = 1)
axis(2,las =2)
box()
dev.off()

The problem is only using the newer versions of the program (R 1.6) and is 
the following:
the bars which make up the plot start below the x axes (and not at the 0 
level).
For resolving this problem you must change "ylim", using 0 as first limit. 
But this changes also the graphic.

Thanks
Silvia Sitton



From bojan.leskosek at guest.arnes.si  Tue Dec 10 13:24:03 2002
From: bojan.leskosek at guest.arnes.si (Bojan Leskosek)
Date: Tue Dec 10 13:24:03 2002
Subject: [R] C caron character in R
Message-ID: <000001c2a046$f61b89f0$3364a8c0@sp.unilj.si>

>> In R 1.6.1. for Windows using RGui interface I try to use characters 
>> of Slovenian alphabet. Slovenia is a small Slavic country south of 
>> Austria with 3 characters which are not found in English alphabet, 
>> namely C, S and Z- all with caron. As S and Z are presented OK in
both 
>> Console and Graphics window, this is not the case with C caron, which

>> is shown as E
>> acute- for an example please see:
>> http://www.sp.uni-lj.si/bojan/statuni/datoteke/temp/q.gif
>> (In RTerm problem is even worse - all characters are wrong. I don't
want
>> to bother you with RTerm, because I rarely use it).
>> Any idea?

>Yes, the problem is in your version of Windows.  What OS is this? R
just >asks Windows which characters are which, and Windows sometimes
lies.
I try on 3 different versions: Win'98 Slovenian, Win 2000 English and
Win XP Slovenian. Result is allways the same
(http://www.sp.uni-lj.si/bojan/statuni/datoteke/temp/q.gif).
Therefore, it seems to me that result is *not* connected with the OS
version(?).
Will someone please try this on his computer? C caron Unicode is 010C
(uppercase) and 010D (lowercase C caron).
Regards,
B. Lesko?ek



From eia018 at comp.lancs.ac.uk  Tue Dec 10 13:26:02 2002
From: eia018 at comp.lancs.ac.uk (Dr Andrew Wilson)
Date: Tue Dec 10 13:26:02 2002
Subject: [R] Lognormal distribution
Message-ID: <Pine.GSO.4.21.0212101220180.24386-100000@austin>

I am trying to fit a lognormal distribution to a set of data and test its
goodness of fit with regard to predicted values.

I managed to get so far:

> y <- c(2,6,2,3,6,7,6,10,11,6,12,9,15,11,15,8,9,12,6,5)
> library(MASS)
> fitdistr(y,"lognormal",start=list(meanlog=0.1,sdlog=0.1))
    meanlog       sdlog   
  1.94810515   0.57091032 
 (0.12765945) (0.09034437)

But I would now also like to generate the predicted values, so that I can
make a comparison using e.g. the Cramer test in the cramer package.

I'd also like to plot the curves for both sets of values.

Could anyone help me with these two points?

Many thanks,
Andrew Wilson



From MROBERTS at ers.usda.gov  Tue Dec 10 13:42:02 2002
From: MROBERTS at ers.usda.gov (Michael Roberts)
Date: Tue Dec 10 13:42:02 2002
Subject: [R] autoregressive poisson process
Message-ID: <sdf59aa9.092@mailbox.ers.usda.gov>

Dear R users,
 
I am trying to find a package that can estimate
an autoregressive model for discrete data.  I am 
imagining a Poisson or Gamma process in which the 
mean (say mu) follows a process such as
 
mu_t = a + b*x + c*mu_{t-1}
 
Suppose I have data on the time-series Poisson 
outcomes and x and would like to obtain ML estimates 
for b and c.
 
Does anyone know of a package that can do this or 
something similar in R?  My first (naive) instinct was
to use glm and the lagged outcome as a regressor,
but that isn't quite right.
 
Thanks very much,
 
Michael Roberts
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20021210/46e1193c/attachment.html

From petr.pikal at precheza.cz  Tue Dec 10 13:47:03 2002
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue Dec 10 13:47:03 2002
Subject: [R] Lognormal distribution
In-Reply-To: <Pine.GSO.4.21.0212101220180.24386-100000@austin>
Message-ID: <3DF5F039.10550.1297FD3@localhost>

Hallo

On 10 Dec 2002 at 12:24, Dr Andrew Wilson wrote:

> I am trying to fit a lognormal distribution to a set of data and test
> its goodness of fit with regard to predicted values.
> 
> I managed to get so far:
> 
> > y <- c(2,6,2,3,6,7,6,10,11,6,12,9,15,11,15,8,9,12,6,5)
> > library(MASS)
> > fitdistr(y,"lognormal",start=list(meanlog=0.1,sdlog=0.1))
>     meanlog       sdlog   
>   1.94810515   0.57091032 
>  (0.12765945) (0.09034437)

I think that you can use distribution generator 
in this case

mydistr<-rlnorm(n, meanlog = 1.94810515, sdlog = 0.57091032)

where n is number of points you would like to generate.

see
?rlnorm



> 
> But I would now also like to generate the predicted values, so that I
> can make a comparison using e.g. the Cramer test in the cramer
> package.
> 
> I'd also like to plot the curves for both sets of values.

something like histogram(mydist) or lines(density(mydist))

or if you want the fitted distribution curve

plot(0:100,dlnorm(0:100, meanlog = 1.94810515, sdlog = 
0.57091032),type="l")

> 
> Could anyone help me with these two points?
> 
> Many thanks,
> Andrew Wilson
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

Hope it helps
Cheers
Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz



From ligges at statistik.uni-dortmund.de  Tue Dec 10 14:35:06 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue Dec 10 14:35:06 2002
Subject: [R] question about R - barplot function
References: <5.1.1.6.0.20021210124049.00a08ba0@lisa>
Message-ID: <3DF5ED8F.C3CB982E@statistik.uni-dortmund.de>

Silvia Sitton wrote:
> 
> I would ask you a question around the function "barplot"
> I have a problem in the graphical output when I run, for example, this
> program (and the others like this):
> 
> postscript("copnido.ps",horizontal=F,family="Helvetica",pointsize=15.5,width=10.5,height=9)
> par(mar=c(5,6,4,4))
> dati <- read.table("infanzia.tab")
> tasso <- cbind(dati$tasso)
> barplot(tasso,beside = TRUE, space = c(0.6),col = c("blue"), axes = FALSE,
> ylim = c(25,40),horiz=FALSE)
> axis(1,c(1.1,2.7,4.3,5.9,7.5),c("99-00","00-01", "01-02", "02-03",
> "03-04"),tck = 0,las = 1)
> axis(2,las =2)
> box()
> dev.off()
> 
> The problem is only using the newer versions of the program (R 1.6) and is
> the following:
> the bars which make up the plot start below the x axes (and not at the 0
> level).
> For resolving this problem you must change "ylim", using 0 as first limit.
> But this changes also the graphic.

Unfortunately, your example is not reproducible (we don't have the
data), can you provide a simple (as simple as possible, without the need
for a separate data frame) reproducible example, please?
What does "newer" versions mean? R-1.6.1 is recent. And the phaenomenon
which I guessed you are talking about  (I have to guess, because I
cannot reproduce the example) is already present in the "old" version
R-1.5.1.

Uwe Ligges



From vito.muggeo at giustizia.it  Tue Dec 10 15:04:02 2002
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Tue Dec 10 15:04:02 2002
Subject: [R] clogit and general conditional logistic regression
References: <XFMail.021210113516.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <00b501c2a054$6fae8300$5c13070a@it.giustizia.it>

Hi Ted,
The conditional exact (log)-Lik for a conditional logistic model (i.e. data
with matched pairs), and the exact (log)-Lik for a PH Cox model are *the
same* (1 matched pair== risk set), therefore clogit() is a wrapper for
coxph() (You can estimate conditional logistic model by means of coxph())

> My question is: is 'clogit' capable of a general conditional
> logistic analysis?

Yes, however I don't know if "general" means something else that I ignore,

best,
vito



----- Original Message -----
From: "Ted Harding" <Ted.Harding at nessie.mcc.ac.uk>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, December 10, 2002 12:35 PM
Subject: [R] clogit and general conditional logistic regression


> Can someone clarify what I cannot make out from the
> documentation?
>
> The function 'clogit' in the 'survival' package is
> described as performing a "conditional logistic regression".
> Its return value is stated to be "an object of class clogit
> which is a wrapper for a coxph object."
>
> This suggests that its usefulness is confined to the sort of
> data which arise in survival/proportional hazard applications.
>
> My question is: is 'clogit' capable of a general conditional
> logistic analysis?
>
> E.g. given a set of data on binomial experiments with Y=1
> r_i times out of n_i, associated with levels A_i and B_i
> of factors A and B at N_A and N_B levels, would
>
>   clogit(Y ~ A+B, method=c(Exact"))
>
> generate something sensible containing the results of a standard
> exact conditional logistic regression of Y on A and B?
>
> With thanks,
> Ted.
>
>
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 167 1972
> Date: 10-Dec-02                                       Time: 11:35:16
> ------------------------------ XFMail ------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From deepayan at stat.wisc.edu  Tue Dec 10 15:30:08 2002
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue Dec 10 15:30:08 2002
Subject: [R] lattice barchart with "negative" bars
In-Reply-To: <200212101211.13595.ltorgo@liacc.up.pt>
References: <200212101211.13595.ltorgo@liacc.up.pt>
Message-ID: <200212100830.27841.deepayan@stat.wisc.edu>

On Tuesday 10 December 2002 06:11 am, Luis Torgo wrote:
> Dear all,
>
> I'm trying to use the lattice barchart function to obtain a bar plot of a
> variable for different values of two factors. The thing I'm trying to do is
>
> something like this:
> > barchart(MyVar ~ season | place, data=mydataset)
>
> My problem is that the column MyVar has some negative values and I would
> like them to be represented as bars stacking down from zero instead of what
> the function does that is finding the minimum value and then stacking all
> bars from this minimum value up. I've looked into the the help pages and I
> saw no way to go around this behaviour. Is there an easy way to get these
> "negative" bars?

No, I don't think so (short of using a modified panel.barchart, which should 
be relatively easy -- panel.barchart essentially has just 3 lines of code). 
But this seems very reasonable thing to want, so I'll add an option for this.

You could also use xyplot with type = "h", but that will give you lines 
instead of bars.

Deepayan



From marlon at lscp.pqi.ep.usp.br  Tue Dec 10 16:30:03 2002
From: marlon at lscp.pqi.ep.usp.br (Marlon Martins dos Reis)
Date: Tue Dec 10 16:30:03 2002
Subject: [R] Counting time in R?
Message-ID: <3DF60B34.89F7A836@lscp.pqi.ep.usp.br>

Dear All,

I?d like to known how to count time in R?
For example, I'd like to do a loop to read a file every 20 seconds,
Thanks in advance,
Regards,
Marlon !!!



From tlumley at u.washington.edu  Tue Dec 10 16:35:03 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue Dec 10 16:35:03 2002
Subject: [R] clogit and general conditional logistic regression
In-Reply-To: <XFMail.021210113516.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.A41.4.44.0212100725240.69002-100000@homer39.u.washington.edu>

On Tue, 10 Dec 2002 Ted.Harding at nessie.mcc.ac.uk wrote:

> Can someone clarify what I cannot make out from the
> documentation?
>
> The function 'clogit' in the 'survival' package is
> described as performing a "conditional logistic regression".
> Its return value is stated to be "an object of class clogit
> which is a wrapper for a coxph object."
>
> This suggests that its usefulness is confined to the sort of
> data which arise in survival/proportional hazard applications.
>
> My question is: is 'clogit' capable of a general conditional
> logistic analysis?

Yes.


> E.g. given a set of data on binomial experiments with Y=1
> r_i times out of n_i, associated with levels A_i and B_i
> of factors A and B at N_A and N_B levels, would
>
>   clogit(Y ~ A+B, method=c(Exact"))
>
> generate something sensible containing the results of a standard
> exact conditional logistic regression of Y on A and B?

Well, you need a stratum variable -- conditional logistic regression is
for matched sets. If you don't have strata it's just a very slow way of
doing logistic regression.  Also, when it says `exact' it means it's using
the exact conditional likelihood, not that it is doing permutation tests
the way LogXact does.

Look at the example on the help page. It has data from a matched
case-control study with two predictors and a stratifying variable. The
example has the variables (with values 0,1,2) in a linear term, but you
could use factor() around them if you wanted to.

The conditional likelihood for logistic regression is (proportional to)
the partial likelihood for a stratified Cox model in which the event times
are all the same. That's why it works and why it's in the survival
package.


	-thomas



From Ted.Harding at nessie.mcc.ac.uk  Tue Dec 10 17:17:03 2002
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue Dec 10 17:17:03 2002
Subject: [R] clogit and general conditional logistic regression
In-Reply-To: <XFMail.021210113516.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <XFMail.021210160615.Ted.Harding@nessie.mcc.ac.uk>

Thanks to Vito Muggeio & Tony Rossini for pointing out that
the form of the partial likelihood in the Cox PH model and
the conditional logistic regression model are the same.

However, that is a theoretical truth! What I was really
asking (and apologies if it was not clear) was whether
(and, if so, how) it would be possible to present the sort
of data I was referring to to the R function 'coxph' or
'clogit'; the documentation seems to assume data involving
a time component in a survival context, and I find I am
confused about how to escape from that context into the
more general regression (logistic linear model) context, when
using these functions in R.

Specifically, suppose I have data (say in the form of vectors)

  A = Level of categorical factor A
  X = Value of quantitative covariate X
  Cases = Number of Cases, r_i, out of n_i
  Unaffected = Number of Unaffected, (n_i - r_i), out of n_i

(no "time" involved here) and I want to fit, by conditional
logistic regression, a model such as

  Cases ~ A + X

How, then, may such data be presented to say 'coxph'?

Might the trick simply be to give every row an extra quasi-start-time
equal to 0, and a quasi-end-time equal to 1?

With thanks,
Ted.

On 10-Dec-02 Ted Harding wrote:
> Can someone clarify what I cannot make out from the
> documentation?
> 
> The function 'clogit' in the 'survival' package is
> described as performing a "conditional logistic regression".
> Its return value is stated to be "an object of class clogit
> which is a wrapper for a coxph object."
> 
> This suggests that its usefulness is confined to the sort of
> data which arise in survival/proportional hazard applications.
> 
> My question is: is 'clogit' capable of a general conditional
> logistic analysis?
> 
> E.g. given a set of data on binomial experiments with Y=1
> r_i times out of n_i, associated with levels A_i and B_i
> of factors A and B at N_A and N_B levels, would
> 
>   clogit(Y ~ A+B, method=c(Exact"))
> 
> generate something sensible containing the results of a standard
> exact conditional logistic regression of Y on A and B?
> 
> With thanks,
> Ted.
> 
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 167 1972
> Date: 10-Dec-02                                       Time: 11:35:16
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 10-Dec-02                                       Time: 16:06:15
------------------------------ XFMail ------------------------------



From ripley at stats.ox.ac.uk  Tue Dec 10 17:27:07 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Dec 10 17:27:07 2002
Subject: [R] Counting time in R?
In-Reply-To: <3DF60B34.89F7A836@lscp.pqi.ep.usp.br>
Message-ID: <Pine.LNX.4.31.0212101624130.13043-100000@gannet.stats>

help.search("time")
?Sys.time
?Sys.sleep
?proc.time

On Tue, 10 Dec 2002, Marlon Martins dos Reis wrote:

> Dear All,
>
> Id like to known how to count time in R?
> For example, I'd like to do a loop to read a file every 20 seconds,
> Thanks in advance,
> Regards,
> Marlon !!!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Tue Dec 10 17:29:10 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue Dec 10 17:29:10 2002
Subject: [R] C caron character in R
In-Reply-To: <000001c2a046$f61b89f0$3364a8c0@sp.unilj.si>
References: <000001c2a046$f61b89f0$3364a8c0@sp.unilj.si>
Message-ID: <x2isy1n8jp.fsf@biostat.ku.dk>

"Bojan Leskosek" <bojan.leskosek at guest.arnes.si> writes:

> >> In R 1.6.1. for Windows using RGui interface I try to use characters 
> >> of Slovenian alphabet. Slovenia is a small Slavic country south of 
> >> Austria with 3 characters which are not found in English alphabet, 
> >> namely C, S and Z- all with caron. As S and Z are presented OK in
> both 
> >> Console and Graphics window, this is not the case with C caron, which
> 
> >> is shown as E
> >> acute- for an example please see:
> >> http://www.sp.uni-lj.si/bojan/statuni/datoteke/temp/q.gif
> >> (In RTerm problem is even worse - all characters are wrong. I don't
> want
> >> to bother you with RTerm, because I rarely use it).
> >> Any idea?
> 
> >Yes, the problem is in your version of Windows.  What OS is this? R
> just >asks Windows which characters are which, and Windows sometimes
> lies.
> I try on 3 different versions: Win'98 Slovenian, Win 2000 English and
> Win XP Slovenian. Result is allways the same
> (http://www.sp.uni-lj.si/bojan/statuni/datoteke/temp/q.gif).
> Therefore, it seems to me that result is *not* connected with the OS
> version(?).
> Will someone please try this on his computer? C caron Unicode is 010C
> (uppercase) and 010D (lowercase C caron).
> Regards,
> B. Lesko?ek

I can't help you with concrete advice but your symptoms would seem
consistent with your computer(s) trying to use WinLatin1 which has the
s and z caron letters, but not c caron. 

See for instance
http://czyborra.com/charsets/iso8859.html
which I found via a page by one of your compatriots at
http://nl.ijs.si/gnusl/cee/iso8859-2.html

[BTW, the letter you're seeing instead of c/C caron is e/E *grave* not
acute -- both sit at c8/e8 in latin-1 resp. -2, whereas e/E acute is
c9/e9 in both variants] 
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tlumley at u.washington.edu  Tue Dec 10 17:33:06 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue Dec 10 17:33:06 2002
Subject: [R] clogit and general conditional logistic regression
In-Reply-To: <XFMail.021210160615.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.A41.4.44.0212100830330.42930-100000@homer31.u.washington.edu>

On Tue, 10 Dec 2002 Ted.Harding at nessie.mcc.ac.uk wrote:
>
> However, that is a theoretical truth! What I was really
> asking (and apologies if it was not clear) was whether
> (and, if so, how) it would be possible to present the sort
> of data I was referring to to the R function 'coxph' or
> 'clogit'; the documentation seems to assume data involving
> a time component in a survival context, and I find I am
> confused about how to escape from that context into the
> more general regression (logistic linear model) context, when
> using these functions in R.
>
> Specifically, suppose I have data (say in the form of vectors)
>
>   A = Level of categorical factor A
>   X = Value of quantitative covariate X
>   Cases = Number of Cases, r_i, out of n_i
>   Unaffected = Number of Unaffected, (n_i - r_i), out of n_i
>
> (no "time" involved here) and I want to fit, by conditional
> logistic regression, a model such as
>
>   Cases ~ A + X
>
> How, then, may such data be presented to say 'coxph'?
>
> Might the trick simply be to give every row an extra quasi-start-time
> equal to 0, and a quasi-end-time equal to 1?
>

If you look at the example for clogit it shows how to use it, and if you
look at the code you can see how it works.  It does just construct an end
time of 1 for every observation.

	-thomas



From pan at mathstat.dal.ca  Tue Dec 10 18:31:06 2002
From: pan at mathstat.dal.ca (Pantelis Andreou)
Date: Tue Dec 10 18:31:06 2002
Subject: [R] fast code
In-Reply-To: <2C23DE2983BE034CB1CB90DB6B813FD6028AC268@uswpmx11.merck.com>
Message-ID: <Pine.GSO.3.96.1021210132828.5770A-100000@chase>

Hello Reid,
thank you for the suggestion.
Regards,
Pantelis

> x1<-c(3,4,6.5,20,35)
> x2<-c(3.1,4.2,5,24,38)
> i <- cut(x2,c(x1,Inf),labels=FALSE)
> i
[1] 1 2 2 4 5
> x3 <- x1[i]
> x3
[1]  3  4  4 20 35
> 


On Fri, 6 Dec 2002, Huntsinger, Reid wrote:

> You could use "cut" as follows:
> 
> i <- cut(x2,c(x1,Inf),labels=FALSE)
> 
> to get the intervals of x1 into which the
> entries of x2 fall, then
> 
> x3 <- x1[i]
> 
> to get the left endpoints. This will give NA for elements of
> x2 smaller than any element of x1, which I think you want. 
> You may want to play with the options to "cut" to get the
> right behavior for exact equality between elements of x1 and x2.
> 
> Note x2 need not be sorted. I don't see a way to take advantage
> of sorted x2 without explicit looping.
> 
> Reid Huntsinger
> 
> 
> 
> -----Original Message-----
> From: Pantelis Andreou [mailto:pan at mathstat.dal.ca]
> Sent: Friday, December 06, 2002 1:21 PM
> To: Janusz Kawczak
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] fast code
> 
> 
> Hello again,
> here is an example
> x1      x2      x3
> 3       3.1     3
> 4       4.2     4
> 6.5     5	4
> 20      24	20
> 35      38	35
> 
> 
> On Fri, 6 Dec 2002, Janusz Kawczak wrote:
> 
> > Example would help!
> > 
> > On Fri, 6 Dec 2002, Pantelis Andreou wrote:
> > 
> > > Date: Fri, 6 Dec 2002 14:09:22 -0400 (AST)
> > > From: Pantelis Andreou <pan at mathstat.dal.ca>
> > > To: r-help at stat.math.ethz.ch
> > > Subject: [R] fast code
> > >
> > > Hello again,
> > > I think I made a mistake discribing the problem.
> > > I have two column vectors x1 and x2 both in increasing order.
> > > I need a column vector x3 such that
> > > the jth entry of x3 is the maximum ith entry x1 which is smaller
> > > than the jth entry of x2.
> > > Regards,
> > > Pantelis
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > >
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
> ------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named in this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.
> 
> ==============================================================================
> 
>



From ltorgo at liacc.up.pt  Tue Dec 10 18:54:02 2002
From: ltorgo at liacc.up.pt (Luis Torgo)
Date: Tue Dec 10 18:54:02 2002
Subject: [R] lattice barchart with "negative" bars
In-Reply-To: <200212100830.27841.deepayan@stat.wisc.edu>
References: <200212101211.13595.ltorgo@liacc.up.pt> <200212100830.27841.deepayan@stat.wisc.edu>
Message-ID: <200212101815.22509.ltorgo@liacc.up.pt>

On Tuesday 10 December 2002 14:30, Deepayan Sarkar wrote:

> No, I don't think so (short of using a modified panel.barchart, which
> should be relatively easy -- panel.barchart essentially has just 3 lines of
> code). But this seems very reasonable thing to want, so I'll add an option
> for this.
>
> You could also use xyplot with type = "h", but that will give you lines
> instead of bars.
>

Thank you for your help. You are right it is easy to adapt panel.barchart to 
perform what I wanted. As such, while you do not add an option for that, I've 
took the liberty to create my version of panel.barchart to solve the problem 
temporarily. I herein include it together with a simple example use, in case 
somebody has the same problem as me.

The function works almost fine. The only problem I was not able to get around 
is the zero value reference line I want to draw in the case of horizontal 
bars. I've used the grid.lines function. It works fine for vertical bars, but 
it doesn't work for horizontal bars...

Luis Torgo


# Adapted from the code of panel.barchart by Deepayan Sarkar
my.panel.barchart <- function (x, y, box.ratio = 1, horizontal = TRUE, col = 
bar.fill$col, 
    ...) 
{
    x <- as.numeric(x)
    y <- as.numeric(y)
    bar.fill <- trellis.par.get("bar.fill")
    if (horizontal) {
        height <- box.ratio/(1 + box.ratio)
        grid.lines(x=0,y=unit(c(0,1),"npc"),default.units="native")
        for (i in seq(along = x))
          if (x[i] >= 0)
            grid.rect(gp = gpar(fill = col), y = y[i], x = 0,
                      height = height, width = y[i] - 0, 
                      just = c("left", "centre"), default.units = "native")
          else
            grid.rect(gp = gpar(fill = col), y = y[i], x = x[i],
                      height = height, width = 0 - x[i], 
                      just = c("left", "centre"), default.units = "native")
    }
    else {
        width <- box.ratio/(1 + box.ratio)
        grid.lines(x=unit(c(0,1),"npc"),y=0,default.units="native")
        for (i in seq(along = y))
          if (y[i] >= 0)
            grid.rect(gp = gpar(fill = col), x = x[i], y = 0,
                      height = y[i] - 0, width = width, 
                      just = c("centre", "bottom"), default.units = "native")
          else
            grid.rect(gp = gpar(fill = col), x = x[i], y = y[i],
                      height = 0 - y[i], width = width, 
                      just = c("centre", "bottom"), default.units = "native")
    }
}

# Example using the function

my.data <- 
data.frame(var=c(34,-10,25,-40),season=c('s','w','s','w'),site=c('A','A','B','B'))

barchart(var ~ season | site, data=my.data, panel="my.panel.barchart")


-- 
Luis Torgo
    FEP/LIACC, University of Porto   Phone : (+351) 22 607 88 30
    Machine Learning Group           Fax   : (+351) 22 600 36 54
    R. Campo Alegre, 823             email : ltorgo at liacc.up.pt
    4150 PORTO   -  PORTUGAL         WWW   : http://www.liacc.up.pt/~ltorgo



From deepayan at stat.wisc.edu  Tue Dec 10 19:44:05 2002
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue Dec 10 19:44:05 2002
Subject: [R] lattice barchart with "negative" bars
In-Reply-To: <200212101815.22509.ltorgo@liacc.up.pt>
References: <200212101211.13595.ltorgo@liacc.up.pt> <200212100830.27841.deepayan@stat.wisc.edu> <200212101815.22509.ltorgo@liacc.up.pt>
Message-ID: <200212101242.55296.deepayan@stat.wisc.edu>

On Tuesday 10 December 2002 12:15 pm, Luis Torgo wrote:
> On Tuesday 10 December 2002 14:30, Deepayan Sarkar wrote:
> > No, I don't think so (short of using a modified panel.barchart, which
> > should be relatively easy -- panel.barchart essentially has just 3 lines
> > of code). But this seems very reasonable thing to want, so I'll add an
> > option for this.
> >
> > You could also use xyplot with type = "h", but that will give you lines
> > instead of bars.
>
> Thank you for your help. You are right it is easy to adapt panel.barchart
> to perform what I wanted. As such, while you do not add an option for that,
> I've took the liberty to create my version of panel.barchart to solve the
> problem temporarily. I herein include it together with a simple example
> use, in case somebody has the same problem as me.
>
> The function works almost fine. The only problem I was not able to get
> around is the zero value reference line I want to draw in the case of
> horizontal bars. I've used the grid.lines function. It works fine for
> vertical bars, but it doesn't work for horizontal bars...
>
> Luis Torgo
>
>
> # Adapted from the code of panel.barchart by Deepayan Sarkar
> my.panel.barchart <- function (x, y, box.ratio = 1, horizontal = TRUE, col
> = bar.fill$col,
>     ...)
> {
>     x <- as.numeric(x)
>     y <- as.numeric(y)
>     bar.fill <- trellis.par.get("bar.fill")
>     if (horizontal) {
>         height <- box.ratio/(1 + box.ratio)
>         grid.lines(x=0,y=unit(c(0,1),"npc"),default.units="native")

This seems to need x = c(0,0). It's slightly odd that this works in the other 
case. In any case, 

          panel.abline(v = 0) ## correspondingly, h = 0 below

might be a more elegant solution.

>         for (i in seq(along = x))
>           if (x[i] >= 0)
>             grid.rect(gp = gpar(fill = col), y = y[i], x = 0,
>                       height = height, width = y[i] - 0,
                                         ^^^^^^^^^^^^^^^^
Typo here, should be                     width = x[i] - 0,

>                       just = c("left", "centre"), default.units = "native")
>           else
>             grid.rect(gp = gpar(fill = col), y = y[i], x = x[i],
>                       height = height, width = 0 - x[i],
>                       just = c("left", "centre"), default.units = "native")
>     }
>     else {
>         width <- box.ratio/(1 + box.ratio)
>         grid.lines(x=unit(c(0,1),"npc"),y=0,default.units="native")
>         for (i in seq(along = y))
>           if (y[i] >= 0)
>             grid.rect(gp = gpar(fill = col), x = x[i], y = 0,
>                       height = y[i] - 0, width = width,
>                       just = c("centre", "bottom"), default.units =
> "native") else
>             grid.rect(gp = gpar(fill = col), x = x[i], y = y[i],
>                       height = 0 - y[i], width = width,
>                       just = c("centre", "bottom"), default.units =
> "native") }
> }
>
> # Example using the function
>
> my.data <-
> data.frame(var=c(34,-10,25,-40),season=c('s','w','s','w'),site=c('A','A','B
>','B'))
>
> barchart(var ~ season | site, data=my.data, panel="my.panel.barchart")



From jfox at mcmaster.ca  Tue Dec 10 19:49:02 2002
From: jfox at mcmaster.ca (John Fox)
Date: Tue Dec 10 19:49:02 2002
Subject: [R] RPgSQL,  Rdbi.PGSQL, and Rdbi for Windows?
Message-ID: <5.1.0.14.2.20021210134228.01e257d0@mcmail.cis.mcmaster.ca>

Dear list members,

I wonder whether anyone has succeeded in building either the RPgSQL or the 
Rdbi.PGSQL and Rdbi packages for Windows. If so, would you be willing to 
share either the binary package(s) or instructions about how to set up the 
configure scripts? My preliminary efforts to get things going under Windows 
2000  haven't met with much success.

Thanks,
  John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------



From ozric at web.de  Tue Dec 10 21:03:02 2002
From: ozric at web.de (Christian Schulz)
Date: Tue Dec 10 21:03:02 2002
Subject: [R] "mystic" apply ?
Message-ID: <003f01c2a086$835df570$8f3f07d5@c5c9i0>

hi,

have anybody a suggestion why this function
works only for a vector correct.
When i'm using apply(data,2,fuzzy) i have the columns
stacked (i.e. dim(x) =1000,4  should after the function 1000,8 
instead is 2000,4) - for single vector it's ok.


fuzzy  <- function (x) 
{
    fuz.x <- cbind(x, x)
    min <- quantile(x, 0.20)
    max <- quantile(x, 0.80)
    fuz.x[x >= max, 1] <- 1
    fuz.x[x >= max, 2] <- 0
    fuz.x[x <= min, 1] <- 0
    fuz.x[x <= min, 2] <- 1
    fuz.x[x > min & x < max, 1] <- (x[x > min & x < max] - min)/(max - min)
    fuz.x[x > min & x < max, 2] <- (max - x[x > min & x < max])/(max - min)
    fuz.x
}



From tlumley at u.washington.edu  Tue Dec 10 21:32:02 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue Dec 10 21:32:02 2002
Subject: [R] "mystic" apply ?
In-Reply-To: <003f01c2a086$835df570$8f3f07d5@c5c9i0>
Message-ID: <Pine.A41.4.44.0212101226520.42930-100000@homer31.u.washington.edu>

On Tue, 10 Dec 2002, Christian Schulz wrote:

> hi,
>
> have anybody a suggestion why this function
> works only for a vector correct.
> When i'm using apply(data,2,fuzzy) i have the columns
> stacked (i.e. dim(x) =1000,4  should after the function 1000,8
> instead is 2000,4) - for single vector it's ok.
>

No, apply doesn't do that -- it doesn't look at matrix arguments at all.

If dim(x) is c(1000,4) then fuzzy is called 4 times, each time with an
argument of length 1000.  It returns a value of length 2000 and so you get
a 2000x4 result.

I can't see why you would expect to get a 1000x8 result -- I might have
expected a 1000x4x2 array, though.

You can get the result you want with

matrix(apply(x,2,fuzzy), nrow=nrow(x))


	-thomas


> fuzzy  <- function (x)
> {
>     fuz.x <- cbind(x, x)
>     min <- quantile(x, 0.20)
>     max <- quantile(x, 0.80)
>     fuz.x[x >= max, 1] <- 1
>     fuz.x[x >= max, 2] <- 0
>     fuz.x[x <= min, 1] <- 0
>     fuz.x[x <= min, 2] <- 1
>     fuz.x[x > min & x < max, 1] <- (x[x > min & x < max] - min)/(max - min)
>     fuz.x[x > min & x < max, 2] <- (max - x[x > min & x < max])/(max - min)
>     fuz.x
> }
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle
^^^^^^^^^^^^^^^^^^^^^^^^
- NOTE NEW EMAIL ADDRESS



From ozric at web.de  Tue Dec 10 22:30:03 2002
From: ozric at web.de (Christian Schulz)
Date: Tue Dec 10 22:30:03 2002
Subject: [R] "mystic" apply ?
References: <Pine.A41.4.44.0212101226520.42930-100000@homer31.u.washington.edu>
Message-ID: <009101c2a092$c08f95a0$8f3f07d5@c5c9i0>

many thanks for the enlightenment !

> I can't see why you would expect to get a 1000x8 result -- I might have
> expected a 1000x4x2 array, though.
I'm working with fuzzy-logic membership
functions for data.frames with real values.
i.e.   age
         23
could get  age.young     age.old
                    0.75            0.25
How many coulmns you can get is a point of definition.
Possible are  modifiers as "small, middle, big"  or many others , but the
sum is always 1.

christian



From LCheung at crch.hawaii.edu  Tue Dec 10 23:15:06 2002
From: LCheung at crch.hawaii.edu (Leo Wang-Kit Cheung)
Date: Tue Dec 10 23:15:06 2002
Subject: [R] Installing a new R Package for MacOS
Message-ID: <sdf5da9e.035@mail-server.crch.hawaii.edu>

Hi,

I am new to using R. I am using the MacOS rm161 version on my
PowerMac G4, and having problem installing a new package msm.
Within R, I typed 

> options(CRAN = "http://cran.stat.ucla.edu/")

Then, I use the following functions, but keep getting errors.

> install.packages("msm") 
Error: couldn't find function "install.packages"

and 

> download.packages("msm")
Error: couldn't find function "download.packages"

Please help. Thanks!

Leo



From deleeuw at stat.ucla.edu  Tue Dec 10 23:32:38 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Tue Dec 10 23:32:38 2002
Subject: [R] Installing a new R Package for MacOS
In-Reply-To: <sdf5da9e.035@mail-server.crch.hawaii.edu>
Message-ID: <1BCF9814-0C8F-11D7-9FE4-003065A21C86@stat.ucla.edu>

The Carbon version of R cannot download and install packages. You have
to install them manually, and if this involves building shared libs  
that is
a royal pain. The Darwin version uses the standard *nix tools and has no
such problems.

-- Jan

On Tuesday, Dec 10, 2002, at 14:14 US/Pacific, Leo Wang-Kit Cheung  
wrote:

> Hi,
>
> I am new to using R. I am using the MacOS rm161 version on my
> PowerMac G4, and having problem installing a new package msm.
> Within R, I typed
>
>> options(CRAN = "http://cran.stat.ucla.edu/")
>
> Then, I use the following functions, but keep getting errors.
>
>> install.packages("msm")
> Error: couldn't find function "install.packages"
>
> and
>
>> download.packages("msm")
> Error: couldn't find function "download.packages"
>
> Please help. Thanks!
>
> Leo
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics
US mail: 8142 Math Sciences Bldg, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
                  www: http://www.stat.ucla.edu/~deleeuw
======================================================================== 
====
          Remember, wherever you go, there you are. --- Buckaroo Banzai
======================================================================== 
====



From Peter.Devoil at dpi.qld.gov.au  Tue Dec 10 23:54:19 2002
From: Peter.Devoil at dpi.qld.gov.au (Peter.Devoil@dpi.qld.gov.au)
Date: Tue Dec 10 23:54:19 2002
Subject: [R] netcdf
In-Reply-To: Your message of "Tue, 10 Dec 2002 12:00:09 +0100."             <20021210110009.11842.43141.Mailman@hypatia.math.ethz.ch> 
Message-ID: <200212102241.gBAMffD12110@localhost.localdomain>

hi matt,

the netcdf stuff has worked on anything I can dump with ncdump.  try:

> aaa<- open.netCDF("/scratch/pocernic/int_fcst.20021201.0010.nc")
> names(aaa)
..."VAR"
> var<- read.netcdf(aaa,"VAR")
or as slabs
>  var <- as.vector(read.netCDF(aaa, name="VAR", byrow=F, start=512,
count=512,attr=F))

Yours,
pdev.

********************************DISCLAIMER****************************
The information contained in the above e-mail message or messages 
(which includes any attachments) is confidential and may be legally 
privileged.  It is intended only for the use of the person or entity 
to which it is addressed.  If you are not the addressee any form of 
disclosure, copying, modification, distribution or any action taken 
or omitted in reliance on the information is unauthorised.  Opinions 
contained in the message(s) do not necessarily reflect the opinions 
of the Queensland Government and its authorities.  If you received 
this communication in error, please notify the sender immediately and 
delete it from your computer system network.



From jeremybutler at paradise.net.nz  Wed Dec 11 00:05:04 2002
From: jeremybutler at paradise.net.nz (Jeremy Z Butler)
Date: Wed Dec 11 00:05:04 2002
Subject: [R] Independant column sorting using sort.list
Message-ID: <1039561463.3df672f7d4387@www.paradise.net.nz>

Hi,
I'm trying to _independantly_ sort the columns of a data frame. 

Using:
> varespec[sort.list(varespec[,1]),]
the columns are sorted *by the first row*.
 
How would I modify this so that all columns are sorted independantly (the result
being *all* columns are rearranged from smallest to biggest not just the first)?

Cheers, Jeremy



From p.connolly at hortresearch.co.nz  Wed Dec 11 00:50:03 2002
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Wed Dec 11 00:50:03 2002
Subject: [R] Adding a title to a postscript file
Message-ID: <20021210234848.GB5018@hortresearch.co.nz>

I create lots of postscript files which I view with ghostview.  The
beginning of the files all begin something like

%!PS-Adobe-3.0
%%DocumentNeededResources: font Helvetica
%%+ font Helvetica-Bold
%%+ font Helvetica-Oblique
%%+ font Helvetica-BoldOblique
%%+ font Symbol
%%DocumentMedia: a4 595 841 0 () ()
%%Title: R Graphics Output
%%Creator: R Software


The consequence is that in ghostview, they are all titled 
'R Graphics Output'.

Is it possible to add a title at the time the file is created (say,
defaulting to the name of the file) so that it's visible from within
ghostview?

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From bates at stat.wisc.edu  Wed Dec 11 00:55:03 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed Dec 11 00:55:03 2002
Subject: [R] Independant column sorting using sort.list
In-Reply-To: <1039561463.3df672f7d4387@www.paradise.net.nz>
References: <1039561463.3df672f7d4387@www.paradise.net.nz>
Message-ID: <6r8yyxh1m0.fsf@bates5.stat.wisc.edu>

Jeremy Z Butler <jeremybutler at paradise.net.nz> writes:

> Hi,
> I'm trying to _independantly_ sort the columns of a data frame. 
> 
> Using:
> > varespec[sort.list(varespec[,1]),]
> the columns are sorted *by the first row*.
>  
> How would I modify this so that all columns are sorted independantly (the result
> being *all* columns are rearranged from smallest to biggest not just the first)?

Apply the sort rather than using sort.list.

varespec <- data.frame(lapply(varespec, sort))



From deleeuw at stat.ucla.edu  Wed Dec 11 01:04:03 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Wed Dec 11 01:04:03 2002
Subject: [R] Installing a new R Package for MacOS
In-Reply-To: <sdf5da9e.035@mail-server.crch.hawaii.edu>
Message-ID: <1BCF9814-0C8F-11D7-9FE4-003065A21C86@stat.ucla.edu>

The Carbon version of R cannot download and install packages. You have
to install them manually, and if this involves building shared libs  
that is
a royal pain. The Darwin version uses the standard *nix tools and has no
such problems.

-- Jan

On Tuesday, Dec 10, 2002, at 14:14 US/Pacific, Leo Wang-Kit Cheung  
wrote:

> Hi,
>
> I am new to using R. I am using the MacOS rm161 version on my
> PowerMac G4, and having problem installing a new package msm.
> Within R, I typed
>
>> options(CRAN = "http://cran.stat.ucla.edu/")
>
> Then, I use the following functions, but keep getting errors.
>
>> install.packages("msm")
> Error: couldn't find function "install.packages"
>
> and
>
>> download.packages("msm")
> Error: couldn't find function "download.packages"
>
> Please help. Thanks!
>
> Leo
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics
US mail: 8142 Math Sciences Bldg, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
                  www: http://www.stat.ucla.edu/~deleeuw
======================================================================== 
====
          Remember, wherever you go, there you are. --- Buckaroo Banzai
======================================================================== 
====



From arc at arcriswell.com  Wed Dec 11 05:02:03 2002
From: arc at arcriswell.com (Andrew Criswell)
Date: Wed Dec 11 05:02:03 2002
Subject: [R] ordering x's and y's
Message-ID: <004501c2a12f$195d3970$c8d994cb@andrewvhowclyz>

Hello ALL:

How do I get R to list all possible orderings of 2 x's and 3 y's?  It should
look like this (which rows appear first is unimportant):

x x y y y
x y x y y
x y y x y
x y y y x
y x x y y
y x y x y
y x y y x
y y x x y
y y x y x
y y y x x

Thanks,
ANDREW



From r.hankin at auckland.ac.nz  Wed Dec 11 05:19:06 2002
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Wed Dec 11 05:19:06 2002
Subject: [R] ordering x's and y's
In-Reply-To: <004501c2a12f$195d3970$c8d994cb@andrewvhowclyz>
	(arc@arcriswell.com)
References: <004501c2a12f$195d3970$c8d994cb@andrewvhowclyz>
Message-ID: <200212110411.gBB4B3X18184@r.hankin.sges.auckland.ac.nz>

Hi Andrew.

This was asked a few days ago (but I posted my offering offline)..
Try:

library(gregmisc)
do.thing2 <- function(x,y) {
   a <- c(x,y)
   tt <- combinations(length(a),length(x))
   answer <- matrix(NA,nrow(tt),length(a))
   for(i in 1:nrow(tt)) {
     answer[i, tt[i,]] <- x
     answer[i,-tt[i,]] <- y
   }
return(answer)
}

[anyone got a vectorized version?]


best

rksh



-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042

as of: Wed Dec 11 17:08:00 NZDT 2002
This (linux) system up continuously for:  468 days, 22 hours, 50 minutes



From mkazuki at ffpri.affrc.go.jp  Wed Dec 11 07:44:03 2002
From: mkazuki at ffpri.affrc.go.jp (Kazuki Miyamoto)
Date: Wed Dec 11 07:44:03 2002
Subject: [R] residuals: lm and glm
Message-ID: <0H6Y0070Q00367@mailer1.affrc.go.jp>

Dear list members,

I would like to know the difference in outputs and calculation processes
between residuals.glm(object, type="response") and residuals.lm(object).

For above-ground biomass estimation of trees, I estimated parameters of
 an allometric equation (ln y = b0 + b1*ln x) using glm as follows:

fm <- glm(Ws~log(Wb), family=quasi(link="log", variance="mu")),

where Ws and Wb are vectors containing the data of stem dry weight and 
branch dry weight(untransformed data, unit: kg), respectively.
 Here, I assumed that the variance of response variable depends on
 the mean value. 

Since ln-transformation introduces a systematic bias into the calculations,
 the estimated values from the allometric equation are need to be corrected 
using a correction factor, which is calculated from the variance of
 the regression.

I obtained residual variances in different ways:

1. sum(residuals.glm(fm, type="response")^2)/(length(Ws)-2)

2. sum(residuals.lm(fm)^2)/(length(Ws)-2)

The former gave 97.78767 and the latter 0.3520604.

These outputs are quite different. I want to obtain the variance based on 
ln-transformed data not on original data. In this sense, the latter seems to be 
appropreate for me.

I would appreciate if anyone could give some advice on this issue.

Sincerely,

*****************************************
Kazuki Miyamoto (Ph. D.)

Kansai Research Center, Forestry and Forest
Products Research Institute,
Nagaikyutaro 68, Momoyama, Kyoto 612-0855,
Japan

Tel: +81.75.611.1385
Fax: +81.75.611.1207
E-mail: mkazuki at ffpri.affrc.go.jp
*****************************************



From Bill.Venables at CMIS.CSIRO.AU  Wed Dec 11 07:51:03 2002
From: Bill.Venables at CMIS.CSIRO.AU (Bill.Venables@CMIS.CSIRO.AU)
Date: Wed Dec 11 07:51:03 2002
Subject: [R] ordering x's and y's
Message-ID: <E09E527B56BE2D438A3D6A246DDD27A9165718@roper-cv.qld.cmis.CSIRO.AU>

Robin Hankin asks below for a vectorized version of his solution below:

>  -----Original Message-----
> From: 	Robin Hankin [mailto:r.hankin at auckland.ac.nz] 
> Sent:	Wednesday, December 11, 2002 2:11 PM
> To:	arc at arcriswell.com
> Cc:	r-help at stat.math.ethz.ch
> Subject:	Re: [R] ordering x's and y's
> 
> Hi Andrew.
> 
> This was asked a few days ago (but I posted my offering offline)..
> Try:
> 
> library(gregmisc)
> do.thing2 <- function(x,y) {
>    a <- c(x,y)
>    tt <- combinations(length(a),length(x))
>    answer <- matrix(NA,nrow(tt),length(a))
>    for(i in 1:nrow(tt)) {
>      answer[i, tt[i,]] <- x
>      answer[i,-tt[i,]] <- y
>    }
> return(answer)
> }
> 
> [anyone got a vectorized version?]
	[WNV]  The original question had a single value for both x and y
with variable repititions.  I prefer to stick to this, but it could be
generalized slightly.

	library(gregmisc)
	xy.sets <- function(nx, ny, x = "x", y = "y") {
		tt <- combinations(nx + ny, nx)
		answer <- matrix(y, nrow(tt), nx + ny)
		answer[cbind(as.vector(row(tt)), as.vector(tt))] <- x
		answer
	}

	Checking:
	> xy.sets(2,3)
	      [,1] [,2] [,3] [,4] [,5]
	 [1,] "x"  "x"  "y"  "y"  "y" 
	 [2,] "x"  "y"  "x"  "y"  "y" 
	 [3,] "x"  "y"  "y"  "x"  "y" 
	 [4,] "x"  "y"  "y"  "y"  "x" 
	 [5,] "y"  "x"  "x"  "y"  "y" 
	 [6,] "y"  "x"  "y"  "x"  "y" 
	 [7,] "y"  "x"  "y"  "y"  "x" 
	 [8,] "y"  "y"  "x"  "x"  "y" 
	 [9,] "y"  "y"  "x"  "y"  "x" 
	[10,] "y"  "y"  "y"  "x"  "x" 

	The trick is the old matrix-as-index thing that surprises so many
people.

	Bill Venables.



> best
> 
> rksh
> 
> 
> 
> -- 
> 
> Robin Hankin, Lecturer,
> School of Geography and Environmental Science
> Tamaki Campus
> Private Bag 92019 Auckland
> New Zealand
> 
> r.hankin at auckland.ac.nz
> tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042
> 
> as of: Wed Dec 11 17:08:00 NZDT 2002
> This (linux) system up continuously for:  468 days, 22 hours, 50 minutes
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From vito.muggeo at giustizia.it  Wed Dec 11 08:45:03 2002
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Wed Dec 11 08:45:03 2002
Subject: [R] autoregressive poisson process
References: <sdf59aa9.092@mailbox.ers.usda.gov>
Message-ID: <002e01c2a0e8$9a226f40$5c13070a@it.giustizia.it>

>I am trying to find a package that can estimate
>an autoregressive model for discrete data.  I am
>imagining a Poisson or Gamma process in which the
>mean (say mu) follows a process such as

>mu_t = a + b*x + c*mu_{t-1}

>Suppose I have data on the time-series Poisson
>outcomes and x and would like to obtain ML estimates
>for b and c.

>Does anyone know of a package that can do this or
>something similar in R?  My first (naive) instinct was
>to use glm and the lagged outcome as a regressor,
>but that isn't quite right.

Right, it should not be the best choice, unless you don't have negative
aucorrelation between the data.

Otherwise you could fit the lagged residuals, namely something like

log E[Y_t]=\eta_t+ r*(log y_{t-1}-\eta_{t-1})

where \eta_t is the linear predictor and r is the autoregression parameter.

You could build a while() loop to fit the model above, it should not be very
difficult; otherwise see the gar() function in gnlr package by J.Lindsey,
although I didn't test it.

Hope this helps,
best,
vito

Hope this help

----- Original Message -----
From: Michael Roberts
To: R-help at stat.math.ethz.ch
Sent: Tuesday, December 10, 2002 1:41 PM
Subject: [R] autoregressive poisson process


Dear R users,


Thanks very much,

Michael Roberts



From ripley at stats.ox.ac.uk  Wed Dec 11 08:51:02 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Dec 11 08:51:02 2002
Subject: [R] Adding a title to a postscript file
In-Reply-To: <20021210234848.GB5018@hortresearch.co.nz>
Message-ID: <Pine.LNX.4.31.0212110747130.23961-100000@gannet.stats>

On Wed, 11 Dec 2002, Patrick Connolly wrote:

> I create lots of postscript files which I view with ghostview.  The
> beginning of the files all begin something like
>
> %!PS-Adobe-3.0
> %%DocumentNeededResources: font Helvetica
> %%+ font Helvetica-Bold
> %%+ font Helvetica-Oblique
> %%+ font Helvetica-BoldOblique
> %%+ font Symbol
> %%DocumentMedia: a4 595 841 0 () ()
> %%Title: R Graphics Output
> %%Creator: R Software
>
>
> The consequence is that in ghostview, they are all titled
> 'R Graphics Output'.
>
> Is it possible to add a title at the time the file is created (say,
> defaulting to the name of the file) so that it's visible from within
> ghostview?

Only by patching R.  I'll add this to R-devel.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From r.darnell at shrs.uq.edu.au  Wed Dec 11 09:09:03 2002
From: r.darnell at shrs.uq.edu.au (Ross Darnell)
Date: Wed Dec 11 09:09:03 2002
Subject: [R] stepAIC and the keep argument
Message-ID: <fzt50yhh.fsf@shrs.uq.edu.au>

I would like to "keep" the call formulae from the stepAIC sequence.

Does anyone know of an example showing how to use the keep argument?

Help would be much appreciated.

Ross Darnell

Email: <r.darnell at shrs.uq.edu.au>



From valdentro at hotmail.com  Wed Dec 11 10:26:03 2002
From: valdentro at hotmail.com (juan pablo perez)
Date: Wed Dec 11 10:26:03 2002
Subject: [R] =?iso-8859-1?B?bWFudWFsIFIgZW4gZXNwYfFvbA==?=
Message-ID: <F101FqV2mEIkLeoOWGM00000411@hotmail.com>

Hello!
I wrote an introductory manual for R beginners in spanish. It is in pdf 
format and has a txt file with data.
If you are interested you can download it from
http://www.iestiemposmodernos.com/depart/LibroR.zip
Espero que os sea de utilidad!




_________________________________________________________________
Charla con tus amigos en l?nea mediante MSN Messenger: 
http://messenger.microsoft.com/es



From jarioksa at sun3.oulu.fi  Wed Dec 11 11:13:03 2002
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Wed Dec 11 11:13:03 2002
Subject: [R] C caron character in R 
In-Reply-To: Message from Peter Dalgaard BSA <p.dalgaard@biostat.ku.dk> 
   of "10 Dec 2002 17:27:38 +0100." <x2isy1n8jp.fsf@biostat.ku.dk> 
Message-ID: <200212111012.gBBACKI19021@pc112145.oulu.fi>

p.dalgaard at biostat.ku.dk said:
> I can't help you with concrete advice but your symptoms would seem
> consistent with your computer(s) trying to use WinLatin1 which has the
> s and z caron letters, but not c caron. 

> See for instance http://czyborra.com/charsets/iso8859.html which I
> found via a page by one of your compatriots at http://nl.ijs.si/gnusl/
> cee/iso8859-2.html

> [BTW, the letter you're seeing instead of c/C caron is e/E *grave* not
> acute -- both sit at c8/e8 in latin-1 resp. -2, whereas e/E acute is
> c9/e9 in both variants] 

Indeed, it seems that iso-8859-2 for c-caron (isn't that ha?ek in czech?) is 
displayed as e-grave (?) in Latin-1 (iso-8859-1 and iso-8859-15):

       347   231   E7     ?     LATIN SMALL LETTER C WITH CEDILLA
       350   232   E8     ?     LATIN SMALL LETTER C WITH CARON
       351   233   E9     ?     LATIN SMALL LETTER E WITH ACUTE

(where the iso-8859-15 display shows e-grave for the middle row, what ever it 
looks in various mail programs around the world).

It seems that Windows uses codepage 1250 which is not identical to iso-8859-2, 
although R may think so. It may that the difference bites here. The following 
(Slovenian: Uni of Ljubljana) page list mainly Linux-specific solutions, but 
has some hints for Microsoft Windows as well. These might be (or might not be) 
compatible with R:

http://nl.ijs.si/gnusl/cee/iso8859-2.html

cheers, jari oksanen 
(who knows ? and ?, but lacks c-caron which would be needed in S?mi language,
but is fortunately available in LaTeX with Babel).
-- 
Jari Oksanen -- Biologian laitos, Oulun yliopisto, 90014 Oulu
Puh. (08) 553 1526, k?si 040 5136529, fax (08) 553 1061
sposti jari.oksanen at oulu.fi, kotisivu http://cc.oulu.fi/~jarioksa/



From eia018 at comp.lancs.ac.uk  Wed Dec 11 11:56:03 2002
From: eia018 at comp.lancs.ac.uk (Dr Andrew Wilson)
Date: Wed Dec 11 11:56:03 2002
Subject: [R] Modified Bessel Function - 2nd kind
Message-ID: <Pine.GSO.4.21.0212110947080.24731-100000@austin>

In order to fit a probability distribution proposed by Sichel [Journal of
the Royal Statistical Society. Series A (General), Vol. 137, 
No. 1. (1974), pp. 25-34], I need a modified Bessel function of the 2nd
kind.  I notice that the base package of "R" only has modified Bessel
functions of the 1st and 3rd kind.  Does a modified Bessel function of the
2nd kind exist anywhere?

Many thanks,
Andrew Wilson



From david.pearson at mail.nerc-essc.ac.uk  Wed Dec 11 13:02:03 2002
From: david.pearson at mail.nerc-essc.ac.uk (David Pearson)
Date: Wed Dec 11 13:02:03 2002
Subject: [R] Modified Bessel Function - 2nd kind
References: <Pine.GSO.4.21.0212110947080.24731-100000@austin>
Message-ID: <3DF726CE.22337853@mail.nerc-essc.ac.uk>


Dr Andrew Wilson wrote:
> 
> In order to fit a probability distribution proposed by Sichel [Journal of
> the Royal Statistical Society. Series A (General), Vol. 137,
> No. 1. (1974), pp. 25-34], I need a modified Bessel function of the 2nd
> kind.  I notice that the base package of "R" only has modified Bessel
> functions of the 1st and 3rd kind.  Does a modified Bessel function of the
> 2nd kind exist anywhere?

G'day,

According to Mathworld, you can make it from modified Bessel
functions of the 1st kind:

http://mathworld.wolfram.com/ModifiedBesselFunctionoftheSecondKind.html



Regards,
David.



-- 
David Pearson                                david.pearson at mail.nerc-essc.ac.uk
Environmental Systems Science Centre         Tel: (0118) 9318741
Harry Pitt Building                          Fax: (0118) 9316413
University of Reading                        WWW: http://www.nerc-essc.ac.uk/~dwcp/Home.html
RG6 6AL, United Kingdom



From eia018 at comp.lancs.ac.uk  Wed Dec 11 13:59:06 2002
From: eia018 at comp.lancs.ac.uk (Dr Andrew Wilson)
Date: Wed Dec 11 13:59:06 2002
Subject: [R] Modified Bessel Function - 2nd kind
In-Reply-To: <3DF726CE.22337853@mail.nerc-essc.ac.uk>
Message-ID: <Pine.GSO.4.21.0212111247090.24791-100000@austin>

Many thanks for this pointer.

Using the formula from the page you referenced, I now have the formula
with the modified Bessel function of the second kind:

> x <- c(1,2,3,4,5,6,7,8)
> y <- c(1,4,5,7,5,4,1,1)
> library(nls)
> library(gregmisc)
> y2 <- nls(y ~
sqrt((2*a)/pi)*exp(a*sqrt(1-q))*((((a*q)/2)^x)/factorial(x))* ((pi/2) *
(besselI(a,-(x-0.5)) - besselI(a,(x-0.5)))/sin((x-0.5) * pi)),
start=list(a=0.1,q=0.1),trace=TRUE)

However, for some reason, I get the following error message:

133.9999 :  0.100 0.001 
Error in numericDeriv(form[[3]], names(ind), env) : 
        Missing value or an Infinity produced when evaluating the model
In addition: Warning messages: 
1: NaNs produced in: sqrt((2 * a)/pi) 
2: NaNs produced in: sqrt(1 - q) 
3: NaNs produced in: besselI(x, nu, 1 + as.logical(expon.scaled)) 
4: NaNs produced in: besselI(x, nu, 1 + as.logical(expon.scaled)) 

Could anyone tell me what I'm doing wrong (and how to fix it)?

The following constraints should apply to the parameters, but I'm not
aware of a "constrain" option in nls that allows me to set these minima
and maxima:

0 < q < 1
a > 0

Many thanks,
Andrew Wilson



From kris.nackaerts at agr.kuleuven.ac.be  Wed Dec 11 15:53:02 2002
From: kris.nackaerts at agr.kuleuven.ac.be (Kris Nackaerts)
Date: Wed Dec 11 15:53:02 2002
Subject: [R] Can't find nls()
Message-ID: <3DF75139.2000907@agr.kuleuven.ac.be>

Hi,

I looked for the nls() function and couldn't find it. In the refman.pdf 
it's mentioned as part of the nls package which I cannot find and I also 
read something about the MASS package, also impossible to find for me.

Kris

-- 
------------------------------------------------------------------------

  http://perswww.kuleuven.ac.be/~u0027178/VCard/mycard.php?name=krisn

------------------------------------------------------------------------
  Minds are like parachutes, they only work when open



From friendly at yorku.ca  Wed Dec 11 16:16:05 2002
From: friendly at yorku.ca (Michael Friendly)
Date: Wed Dec 11 16:16:05 2002
Subject: [R] Excluding levels in table and xtabs
References: <20021211110014.7309.21238.Mailman@hypatia.math.ethz.ch>
Message-ID: <3DF756A7.269929C1@yorku.ca>

I'm trying to form contingincy tables among a set of character variables
which were read from a .csv file and 
have missing represented as "".  I want to exclude the missing levels
from the table.

> levels(CPIC)
[1] ""  "N" "Y"
> levels(Manix)
[1] ""  "N" "Y"
> xtabs(~CPIC + Manix, exclude=c("",NA))
    Manix
CPIC        N    Y
     272    4   15
   N 154 2812 1472
   Y 158  466 4870

> table(CPIC, Manix, exclude=c("",NA))

    Manix
CPIC        N    Y
     272    4   15
   N 154 2812 1472
   Y 158  466 4870

The only way I can exclude them is by

t <- table(CPIC, Manix)
t <- t[-1,-1]

that's not to hard in this case, but my application is to a much
larger table where this gets unweildly.

-- 
Michael Friendly              friendly at yorku.ca
York University               http://www.math.yorku.ca/SCS/friendly.html
Psychology Department
4700 Keele Street             Tel:  (416) 736-5115 x66249
Toronto, Ontario, M3J 1P3     Fax:  (416) 736-5814



From Timur.Elzhov at jinr.ru  Wed Dec 11 16:36:05 2002
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Wed Dec 11 16:36:05 2002
Subject: [R] nlm() vs. nls()
Message-ID: <20021211153747.GA16860@pcf004.jinr.ru>

Dear R-experts!

I've been using nls() for a while for fitting my data, approx 10,000
points long.  Now, I have to use low-level minimizing functions to get
more control on fitting process, so I tried nlm().  And, the fitting
process became *much* more slower!

The question is: why? why nls() works faster?

Thank you very much!
Timur.



From Bernhard.Pfaff at drkw.com  Wed Dec 11 16:38:03 2002
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Wed Dec 11 16:38:03 2002
Subject: [R] Modified Bessel Function - 2nd kind
Message-ID: 
    <18D602BD42B7E24EB810D6454A58DB9001CAE0D9@ibfftce505.is.de.dresdnerkb.com>

Maybe this hint is of help to you:

rather to enter the parameters (a,q) directly into your equation, you could
use some transformations to circumvent the inequalities, such as:

0 < q < 1
q = exp(x)/(1+exp(x))

and insert the rhs for q into your argument. Likewise instead, of 

a > 0
use:
a = y^2

HTH,
Bernhard


-----Original Message-----
From: Dr Andrew Wilson [mailto:eia018 at comp.lancs.ac.uk]
Sent: 11 December 2002 13:58
To: r-help at stat.math.ethz.ch
Subject: Re: [R] Modified Bessel Function - 2nd kind


Many thanks for this pointer.

Using the formula from the page you referenced, I now have the formula
with the modified Bessel function of the second kind:

> x <- c(1,2,3,4,5,6,7,8)
> y <- c(1,4,5,7,5,4,1,1)
> library(nls)
> library(gregmisc)
> y2 <- nls(y ~
sqrt((2*a)/pi)*exp(a*sqrt(1-q))*((((a*q)/2)^x)/factorial(x))* ((pi/2) *
(besselI(a,-(x-0.5)) - besselI(a,(x-0.5)))/sin((x-0.5) * pi)),
start=list(a=0.1,q=0.1),trace=TRUE)

However, for some reason, I get the following error message:

133.9999 :  0.100 0.001 
Error in numericDeriv(form[[3]], names(ind), env) : 
        Missing value or an Infinity produced when evaluating the model
In addition: Warning messages: 
1: NaNs produced in: sqrt((2 * a)/pi) 
2: NaNs produced in: sqrt(1 - q) 
3: NaNs produced in: besselI(x, nu, 1 + as.logical(expon.scaled)) 
4: NaNs produced in: besselI(x, nu, 1 + as.logical(expon.scaled)) 

Could anyone tell me what I'm doing wrong (and how to fix it)?

The following constraints should apply to the parameters, but I'm not
aware of a "constrain" option in nls that allows me to set these minima
and maxima:

0 < q < 1
a > 0

Many thanks,
Andrew Wilson

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help


----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.
----------------------------------------------------------------------



From rdiaz at cnio.es  Wed Dec 11 16:45:03 2002
From: rdiaz at cnio.es (Ramon Diaz)
Date: Wed Dec 11 16:45:03 2002
Subject: [R] Can't find nls()
In-Reply-To: <3DF75139.2000907@agr.kuleuven.ac.be>
References: <3DF75139.2000907@agr.kuleuven.ac.be>
Message-ID: <200212111638.23309.rdiaz@cnio.es>

Dear Kris,

Try typing "library(nls)" and "library(MASS)" at the R prompt. nls and MASS 
should be part of your R installation (assuming you are using a relatively 
recent R version).

You can find more answers to these questions in the FAQ (5.1 shows the 
packages which are part of the standard distribution and 5.3 explains, among 
others, how to load packages). You might also want to read R-intro ("An 
introduction to R") and/or some of the other into docs available from the web 
page.

Hope this helps.

Ram?n


On Wednesday 11 December 2002 15:52, Kris Nackaerts wrote:
> Hi,
>
> I looked for the nls() function and couldn't find it. In the refman.pdf
> it's mentioned as part of the nls package which I cannot find and I also
> read something about the MASS package, also impossible to find for me.
>
> Kris

-- 
Ram?n D?az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
http://bioinfo.cnio.es/~rdiaz



From ripley at stats.ox.ac.uk  Wed Dec 11 17:00:09 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Dec 11 17:00:09 2002
Subject: [R] Can't find nls()
In-Reply-To: <3DF75139.2000907@agr.kuleuven.ac.be>
Message-ID: <Pine.LNX.4.31.0212111557320.29095-100000@gannet.stats>

Do

library(nls)
library(MASS)

not work?  If so your R installation is incomplete or corrupt.  Please
take this up with your local sysadmin.

On Wed, 11 Dec 2002, Kris Nackaerts wrote:

> Hi,
>
> I looked for the nls() function and couldn't find it. In the refman.pdf
> it's mentioned as part of the nls package which I cannot find and I also
> read something about the MASS package, also impossible to find for me.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From vprovi at essex.ac.uk  Wed Dec 11 17:07:05 2002
From: vprovi at essex.ac.uk (Vikentia Provizionatou)
Date: Wed Dec 11 17:07:05 2002
Subject: [R] Data Frame
Message-ID: <000201c2a12f$386b34c0$a517f59b@essex.ac.uk>

Hi,

I am trying to read.table, while my file is in .csv form.

However, I can not make it into a data frame.

Any hints?

Thanks a lot

Vikentia Provizionatou



From Serena.Richards at corporate-recruiter.co.uk  Wed Dec 11 17:09:06 2002
From: Serena.Richards at corporate-recruiter.co.uk (Serena Richards (HH))
Date: Wed Dec 11 17:09:06 2002
Subject: [R] New Job
Message-ID: <A70C44141DDE8B49B16CE08AE35CF2D805F916@crserver.corporate-recruiter.local>

Dear List,

Break into consultancy - X-train and broaden your horizons

If variety is the spice of life - this job is pretty hot!!
If you are a graduate with a numerical / statistical degree and 2+ years
statistical analysis this could be the change you are looking for. If
your aptitude for number crunching trading risk analysis, drug trial
analysis customer analytics or data mining is matched by your outgoing
client facing personality then my client will want to meet you. In
return you will have a varied role. One day you could be programming in
S-Plus or similar (they'll train you from SAS, C / C++, Java, 'R', etc),
another day you could be delivering a training course to existing
clients or adding statistical / technical weight alongside sales people
pitching for big business. This is an established company so the
benefits are good. Yet the strategic changes that have taken place make
this a ground floor opportunity for you to shine in a new role. Call to
day for more information and an immediate interview.

Location: Hertfordshire

Salary: up to 30K + Car + Bens

Kind regards

Serena Richards
Corporate Recruiter 
020 78619987



From bates at stat.wisc.edu  Wed Dec 11 17:15:04 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed Dec 11 17:15:04 2002
Subject: [R] Modified Bessel Function - 2nd kind
In-Reply-To: <Pine.GSO.4.21.0212111247090.24791-100000@austin>
References: <Pine.GSO.4.21.0212111247090.24791-100000@austin>
Message-ID: <6ru1hkmt1r.fsf@bates5.stat.wisc.edu>

Dr Andrew Wilson <eia018 at comp.lancs.ac.uk> writes:

> Many thanks for this pointer.
> 
> Using the formula from the page you referenced, I now have the formula
> with the modified Bessel function of the second kind:
> 
> > x <- c(1,2,3,4,5,6,7,8)
> > y <- c(1,4,5,7,5,4,1,1)
> > library(nls)
> > library(gregmisc)
> > y2 <- nls(y ~
> sqrt((2*a)/pi)*exp(a*sqrt(1-q))*((((a*q)/2)^x)/factorial(x))* ((pi/2) *
> (besselI(a,-(x-0.5)) - besselI(a,(x-0.5)))/sin((x-0.5) * pi)),
> start=list(a=0.1,q=0.1),trace=TRUE)
> 
> However, for some reason, I get the following error message:
> 
> 133.9999 :  0.100 0.001 
> Error in numericDeriv(form[[3]], names(ind), env) : 
>         Missing value or an Infinity produced when evaluating the model
> In addition: Warning messages: 

It appears that the value of q is being driven toward negative
values.  The numerical derivative routine is trying to evaluate the
predictions at a negative value of a and q.  This suggests that your
model may not fit the data or that you need better starting values for
the parameters.

> 1: NaNs produced in: sqrt((2 * a)/pi) 
> 2: NaNs produced in: sqrt(1 - q) 
> 3: NaNs produced in: besselI(x, nu, 1 + as.logical(expon.scaled)) 
> 4: NaNs produced in: besselI(x, nu, 1 + as.logical(expon.scaled)) 
> 
> Could anyone tell me what I'm doing wrong (and how to fix it)?
> 
> The following constraints should apply to the parameters, but I'm not
> aware of a "constrain" option in nls that allows me to set these minima
> and maxima:
> 
> 0 < q < 1
> a > 0

One way of enforcing constraints on the parameters in a nonlinear
regression is to use transformed parameters.  In this case you can use
a logistic transformation for q and the logarithm of a.  I suggest
that you write a function for the model rather than an expression

modl <- function(x, loga, logisq) {
 xm5 <- x - 0.5
 a <- exp(loga)
 q <- 1/(1 + exp(-logisq))
 sqrt((2*a)/pi)*exp(a*sqrt(1-q))*((((a*q)/2)^x)/factorial(x))* ((pi/2) *
 (besselI(a,-xm5) - besselI(a,xm5))/sin(xm5 * pi)) 
}

and try to fit

 y2 <- nls(y ~ modl(x, loga, logisq), start=list(loga=log(0.1),
           logisq=log(0.1/0.9), trace = TRUE)



From jzhang at jimmy.harvard.edu  Wed Dec 11 17:17:03 2002
From: jzhang at jimmy.harvard.edu (John Zhang)
Date: Wed Dec 11 17:17:03 2002
Subject: [R] Data Frame
Message-ID: <200212111616.LAA24702@blaise.dfci.harvard.edu>

>From: "Vikentia Provizionatou" <vprovi at essex.ac.uk>
>To: <r-help at stat.math.ethz.ch>
>MIME-Version: 1.0
>Content-Transfer-Encoding: 7bit
>X-Priority: 3 (Normal)
>X-MSMail-Priority: Normal
>Importance: Normal
>X-MimeOLE: Produced By Microsoft MimeOLE V6.00.2800.1106
>X-MailScanner: Found to be clean
>X-Virus-Scanned: by amavisd-milter (http://amavis.org/)
>X-Virus-Scanned: by amavisd-milter (http://amavis.org/)
>X-Spam-Status: No, hits=0.8 required=5.0 tests=SPAM_PHRASE_00_01 version=2.43
>X-Spam-Level: 
>Subject: [R] Data Frame
>X-BeenThere: r-help at stat.math.ethz.ch
>X-Mailman-Version: 2.0.13
>List-Help: <mailto:r-help-request at stat.math.ethz.ch?subject=help>
>List-Post: <mailto:r-help at stat.math.ethz.ch>
>List-Subscribe: <http://www.stat.math.ethz.ch/mailman/listinfo/r-help>, 
<mailto:r-help-request at stat.math.ethz.ch?subject=subscribe>
>List-Id: Main R Mailing List: Primary help <r-help.stat.math.ethz.ch>
>List-Unsubscribe: <http://www.stat.math.ethz.ch/mailman/listinfo/r-help>, 
<mailto:r-help-request at stat.math.ethz.ch?subject=unsubscribe>
>List-Archive: <http://www.stat.math.ethz.ch/pipermail/r-help/>
>X-Original-Date: Wed, 11 Dec 2002 16:06:08 -0000
>Date: Wed, 11 Dec 2002 16:06:08 -0000
>
>Hi,
>
>I am trying to read.table, while my file is in .csv form.

Did you try read.csv?

>
>However, I can not make it into a data frame.
>
>Any hints?
>
>Thanks a lot
>
>Vikentia Provizionatou
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jfox at mcmaster.ca  Wed Dec 11 17:23:03 2002
From: jfox at mcmaster.ca (John Fox)
Date: Wed Dec 11 17:23:03 2002
Subject: [R] Excluding levels in table and xtabs
In-Reply-To: <3DF756A7.269929C1@yorku.ca>
References: <20021211110014.7309.21238.Mailman@hypatia.math.ethz.ch>
Message-ID: <5.0.2.1.0.20021211110357.00ae4940@mcmail.cis.mcmaster.ca>

Dear Mike,

You could read the file specifying the na.strings argument to read.csv. 
Does that do what you need?

Regards,
  John

At 10:15 AM 12/11/2002 -0500, Michael Friendly wrote:
>I'm trying to form contingincy tables among a set of character variables
>which were read from a .csv file and
>have missing represented as "".  I want to exclude the missing levels
>from the table.
>
> > levels(CPIC)
>[1] ""  "N" "Y"
> > levels(Manix)
>[1] ""  "N" "Y"
> > xtabs(~CPIC + Manix, exclude=c("",NA))
>     Manix
>CPIC        N    Y
>      272    4   15
>    N 154 2812 1472
>    Y 158  466 4870
>
> > table(CPIC, Manix, exclude=c("",NA))
>
>     Manix
>CPIC        N    Y
>      272    4   15
>    N 154 2812 1472
>    Y 158  466 4870
>
>The only way I can exclude them is by
>
>t <- table(CPIC, Manix)
>t <- t[-1,-1]
>
>that's not to hard in this case, but my application is to a much
>larger table where this gets unweildly.
>
>--
>Michael Friendly              friendly at yorku.ca
>York University               http://www.math.yorku.ca/SCS/friendly.html
>Psychology Department
>4700 Keele Street             Tel:  (416) 736-5115 x66249
>Toronto, Ontario, M3J 1P3     Fax:  (416) 736-5814
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help

____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox



From rvaradha at jhsph.edu  Wed Dec 11 18:07:03 2002
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Wed Dec 11 18:07:03 2002
Subject: [R] Modified Bessel Function - 2nd kind
Message-ID: <b3a0ccb332a0.b332a0b3a0cc@jhsph.edu>

Hi Andrew:

There is the "besselK()" function in the base distribution.  This is 
exactly the Modified Bessel's function of the Second Kind. You don't 
need to write this in terms of I.0 and I.1.

Ravi.

----- Original Message -----
From: Dr Andrew Wilson <eia018 at comp.lancs.ac.uk>
Date: Wednesday, December 11, 2002 5:55 am
Subject: [R] Modified Bessel Function - 2nd kind

> In order to fit a probability distribution proposed by Sichel 
> [Journal of
> the Royal Statistical Society. Series A (General), Vol. 137, 
> No. 1. (1974), pp. 25-34], I need a modified Bessel function of 
> the 2nd
> kind.  I notice that the base package of "R" only has modified Bessel
> functions of the 1st and 3rd kind.  Does a modified Bessel 
> function of the
> 2nd kind exist anywhere?
> 
> Many thanks,
> Andrew Wilson
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From tlumley at u.washington.edu  Wed Dec 11 18:08:56 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed Dec 11 18:08:56 2002
Subject: [R] residuals: lm and glm
In-Reply-To: <0H6Y0070Q00367@mailer1.affrc.go.jp>
Message-ID: <Pine.A41.4.44.0212110902080.234794-100000@homer01.u.washington.edu>

On Wed, 11 Dec 2002, Kazuki Miyamoto wrote:

> Dear list members,
>
> I would like to know the difference in outputs and calculation processes
> between residuals.glm(object, type="response") and residuals.lm(object).

There's one very important similarity between these calls: you probably
shouldn't use either of them. Calling methods directly is generally a bad
idea.

residuals.lm() returns the $residuals component of the object. In an lm()
this is the residuals, but in a glm()  it is the working residuals. That's
why you shouldn't call residuals.lm() on a glm.

residuals.glm(, type="response") returns the observed value minus the
fitted value.


	-thomas



From AlessandroSemeria at cramont.it  Wed Dec 11 19:26:02 2002
From: AlessandroSemeria at cramont.it (AlessandroSemeria@cramont.it)
Date: Wed Dec 11 19:26:02 2002
Subject: [R] filter on data frame
Message-ID: <OF8885381E.C4537BAE-ONC1256C8C.0063425B@tomware.it>

Hello R-list.
Someone know how to delete  rows on a char/num matrix
following some criteria without a loop (something like: my.matrix[my.matrix
[,4]<1e-5],
but this one put within rows, that follow citeria, "NA")?
 Thanks!

A.S.



From mmiller3 at iupui.edu  Wed Dec 11 19:37:02 2002
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: Wed Dec 11 19:37:02 2002
Subject: [R] filter on data frame
In-Reply-To: <OF8885381E.C4537BAE-ONC1256C8C.0063425B@tomware.it>
References: <OF8885381E.C4537BAE-ONC1256C8C.0063425B@tomware.it>
Message-ID: <874r9kflno.fsf@lumen.indyrad.iupui.edu>

>>>>> "AlessandroSemeria" == AlessandroSemeria  <AlessandroSemeria at cramont.it> writes:

    > Hello R-list.  Someone know how to delete rows on a
    > char/num matrix following some criteria without a loop
    > (something like: my.matrix[my.matrix [,4]<1e-5], but this
    > one put within rows, that follow citeria, "NA")?  Thanks!

How about subset and is.na?

Mike

> df
  V1   V2
1  1    a
2  2    b
3  3    f
4  4    g
5  5 <NA>
6  6 <NA>
7  7    a
> subset(df,!is.na(V2))
  V1 V2
1  1  a
2  2  b
3  3  f
4  4  g
7  7  a



From tlumley at u.washington.edu  Wed Dec 11 19:54:05 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed Dec 11 19:54:05 2002
Subject: [R] Excluding levels in table and xtabs
In-Reply-To: <3DF756A7.269929C1@yorku.ca>
Message-ID: <Pine.A41.4.44.0212111049430.234794-100000@homer01.u.washington.edu>

On Wed, 11 Dec 2002, Michael Friendly wrote:

> I'm trying to form contingincy tables among a set of character variables
> which were read from a .csv file and
> have missing represented as "".  I want to exclude the missing levels
> from the table.

I think this is a bug. The exclude= argument doesn't work for factors,
because the argument is passed to factor(), and its exclude argument has
a different format when the main argument is a factor.

	-thomas


>
> > levels(CPIC)
> [1] ""  "N" "Y"
> > levels(Manix)
> [1] ""  "N" "Y"
> > xtabs(~CPIC + Manix, exclude=c("",NA))
>     Manix
> CPIC        N    Y
>      272    4   15
>    N 154 2812 1472
>    Y 158  466 4870
>
> > table(CPIC, Manix, exclude=c("",NA))
>
>     Manix
> CPIC        N    Y
>      272    4   15
>    N 154 2812 1472
>    Y 158  466 4870
>
> The only way I can exclude them is by
>
> t <- table(CPIC, Manix)
> t <- t[-1,-1]
>
> that's not to hard in this case, but my application is to a much
> larger table where this gets unweildly.
>
> --
> Michael Friendly              friendly at yorku.ca
> York University               http://www.math.yorku.ca/SCS/friendly.html
> Psychology Department
> 4700 Keele Street             Tel:  (416) 736-5115 x66249
> Toronto, Ontario, M3J 1P3     Fax:  (416) 736-5814
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle
^^^^^^^^^^^^^^^^^^^^^^^^
- NOTE NEW EMAIL ADDRESS



From jzhang at jimmy.harvard.edu  Wed Dec 11 20:09:02 2002
From: jzhang at jimmy.harvard.edu (John Zhang)
Date: Wed Dec 11 20:09:02 2002
Subject: [R] filter on data frame
Message-ID: <200212111908.OAA06482@blaise.dfci.harvard.edu>

Is this what you want?

> tt <- matrix(1:20, ncol = 4)
> tt
     [,1] [,2] [,3] [,4]
[1,]    1    6   11   16
[2,]    2    7   12   17
[3,]    3    8   13   18
[4,]    4    9   14   19
[5,]    5   10   15   20
> tt[tt[,1] < 3, ]
     [,1] [,2] [,3] [,4]
[1,]    1    6   11   16
[2,]    2    7   12   17


>To: r-help at stat.math.ethz.ch
>From: AlessandroSemeria at cramont.it
>X-MIMETrack: Serialize by Router on ecom/twd(Release 5.0.6a |January 17, 2001) 
at 12/11/2002 07:26:51 PM
>MIME-Version: 1.0
>X-Virus-Scanned: by amavisd-milter (http://amavis.org/)
>X-Virus-Scanned: by amavisd-milter (http://amavis.org/)
>X-Spam-Status: No, hits=2.1 required=5.0 
tests=MAY_BE_FORGED,NO_REAL_NAME,SPAM_PHRASE_00_01 version=2.43
>X-Spam-Level: **
>Subject: [R] filter on data frame
>X-BeenThere: r-help at stat.math.ethz.ch
>X-Mailman-Version: 2.0.13
>List-Help: <mailto:r-help-request at stat.math.ethz.ch?subject=help>
>List-Post: <mailto:r-help at stat.math.ethz.ch>
>List-Subscribe: <http://www.stat.math.ethz.ch/mailman/listinfo/r-help>, 
<mailto:r-help-request at stat.math.ethz.ch?subject=subscribe>
>List-Id: Main R Mailing List: Primary help <r-help.stat.math.ethz.ch>
>List-Unsubscribe: <http://www.stat.math.ethz.ch/mailman/listinfo/r-help>, 
<mailto:r-help-request at stat.math.ethz.ch?subject=unsubscribe>
>List-Archive: <http://www.stat.math.ethz.ch/pipermail/r-help/>
>X-Original-Date: Wed, 11 Dec 2002 19:28:28 +0100
>Date: Wed, 11 Dec 2002 19:28:28 +0100
>
>Hello R-list.
>Someone know how to delete  rows on a char/num matrix
>following some criteria without a loop (something like: my.matrix[my.matrix
>[,4]<1e-5],
>but this one put within rows, that follow citeria, "NA")?
> Thanks!
>
>A.S.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Hicham.Zmarrou at student.uva.nl  Wed Dec 11 21:53:03 2002
From: Hicham.Zmarrou at student.uva.nl (H. Zmarrou)
Date: Wed Dec 11 21:53:03 2002
Subject: [R] Histogram
Message-ID: <6a0a136a1aba.6a1aba6a0a13@student.uva.nl>

Dear R-ers:
I'm sorry to disturb you, I want just ask if there is a package to use 
in ploting histograms in two dimensionl case.

 
Thank you very much 
 Hicham 
University ofAmsterdam



From r.hankin at auckland.ac.nz  Wed Dec 11 22:03:05 2002
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Wed Dec 11 22:03:05 2002
Subject: [R] ordering x's and y's
In-Reply-To: 
	<E09E527B56BE2D438A3D6A246DDD27A9165718@roper-cv.qld.cmis.CSIRO.AU>
	(Bill.Venables@CMIS.CSIRO.AU)
References: <E09E527B56BE2D438A3D6A246DDD27A9165718@roper-cv.qld.cmis.CSIRO.AU>
Message-ID: <200212112054.gBBKsAh05292@r.hankin.sges.auckland.ac.nz>

WNV writes

> 	[WNV]  The original question had a single value for both x and y
> with variable repititions.  I prefer to stick to this, but it could be
> generalized slightly.
> 
> 	library(gregmisc)
> 	xy.sets <- function(nx, ny, x = "x", y = "y") {
> 		tt <- combinations(nx + ny, nx)
> 		answer <- matrix(y, nrow(tt), nx + ny)
> 		answer[cbind(as.vector(row(tt)), as.vector(tt))] <- x
> 		answer
> 	}
> 

[rksh] Bill's solution is indeed vectorized and elegant; I spent some
time pondering the "trick" (as a reformed Matlab user, Bill's comment
about "matrix-as-index" techniques being surprising truly strikes
home, as the following code which I wrote years ago attests:

*****warning: Matlab code follows*********

function out=do_r(matrix,p)
%function out=do_r(matrix,p)
%
%example
%
%      a=reshape(1:12,3,4)
%      p=[1 1;1 4; 2 2]
%      do_r(a,p)    %consider 2nd row of p (=1,4); a(1,4)=10 as reqd.
%   
%      see assign
[n m]=size(matrix);
a=reshape(matrix,n*m,1);
places=(p(:,2)-1)*n+p(:,1);
out=a(places);

function out=assign(matrix,p,values);
%does what a(p)=values should do:
%a=reshape(1:12,3,4) 
%p=[1 2;1 3 ;3 4]
%assign(a,p,0)
%assign(a,p,-[99 99 99])
%
%
%see do_r
[n m]=size(matrix);
a=reshape(matrix,1,n*m);
places=p(:,1)+n*(p(:,2)-1);
a(places)=values;
out=reshape(a,n,m);
*****matlab code ends******

).  

I spent a bit of time trying to generalize Bill's xy.sets() but the
best I could come up with was


xy <- function(x, y) {
  nx <- length(x)
  ny <- length(y)
  tt <- combinations(nx + ny, nx)
  placeholder <- matrix(rep(FALSE,nx+ny), nrow(tt), nx + ny,byrow=F)
  answer <- placeholder
  placeholder[cbind(as.vector(row(tt)),   as.vector(tt))] <- TRUE
  answer <- t(answer)
  placeholder <- t(placeholder)
  answer[placeholder== TRUE] <- x
  answer[placeholder==FALSE] <- y 
  t(answer)
 }

then xy(1:3,10:11) works.  xy() has to deal with the transpose of
answer and placeholder in order to put the elements of x and y in
their correct places.  Is there a better way?

Oh yes, I had omitted to point out that do.thing2() could solve the
original problem with something like

R> do.thing2(rep("x",2),rep("y",3))

best 

rksh


> > 
> > This was asked a few days ago (but I posted my offering offline)..
> > Try:
> > 
> > library(gregmisc)
> > do.thing2 <- function(x,y) {
> >    a <- c(x,y)
> >    tt <- combinations(length(a),length(x))
> >    answer <- matrix(NA,nrow(tt),length(a))
> >    for(i in 1:nrow(tt)) {
> >      answer[i, tt[i,]] <- x
> >      answer[i,-tt[i,]] <- y
> >    }
> > return(answer)
> > }
> > 
> > [anyone got a vectorized version?]

[check deleted]


> 
> 	The trick is the old matrix-as-index thing that surprises so many
> people.
> 
> 	Bill Venables.
> 
> 


Robin K. S. Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042

as of: Thu Dec 12 09:00:00 NZDT 2002
This (linux) system up continuously for:  469 days, 14 hours, 42 minutes


-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042

as of: Thu Dec 12 09:49:00 NZDT 2002
This (linux) system up continuously for:  469 days, 15 hours, 31 minutes



From gregory_r_warnes at groton.pfizer.com  Wed Dec 11 23:28:03 2002
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Wed Dec 11 23:28:03 2002
Subject: [R] Histogram
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C382@groexmb02.pfizer.com>

In the gregmisc package there is a function 'hist2d' which generates a 2-d
histogram using a user-specified number of bins in each dimension.

-Greg

> -----Original Message-----
> From: H. Zmarrou [mailto:Hicham.Zmarrou at student.uva.nl]
> Sent: Wednesday, December 11, 2002 3:53 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Histogram
> 
> 
> Dear R-ers:
> I'm sorry to disturb you, I want just ask if there is a 
> package to use 
> in ploting histograms in two dimensionl case.
> 
>  
> Thank you very much 
>  Hicham 
> University ofAmsterdam
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this message is ... [[dropped]]



From kjetilh at umsanet.edu.bo  Thu Dec 12 01:33:03 2002
From: kjetilh at umsanet.edu.bo (kjetil halvorsen)
Date: Thu Dec 12 01:33:03 2002
Subject: [R] Excluding levels in table and xtabs
References: <Pine.A41.4.44.0212111049430.234794-100000@homer01.u.washington.edu>
Message-ID: <3DF7D5E9.61CB268D@umsanet.edu.bo>

Hola!

Thomas Lumley wrote:
> 
> On Wed, 11 Dec 2002, Michael Friendly wrote:
> 
> > I'm trying to form contingincy tables among a set of character variables
> > which were read from a .csv file and
> > have missing represented as "".  I want to exclude the missing levels
> > from the table.
> 
> I think this is a bug. The exclude= argument doesn't work for factors,
> because the argument is passed to factor(), and its exclude argument has
> a different format when the main argument is a factor. 

I dot think that is correct. table doesnt call factor on factors, so the
exclude argument doesnt get used at all. I had the oposite problem as
the original poster.
To include NA's as a level in a table. Why should't table simply call
factor also on factor arguments, so the exclude argument to table get
used in this case to. I modifyed table to Table doing this, and it
works, the only problem being that NA is not labelled in the table.

Kjetil Halvorsen


 
> 
>         -thomas
> 
> >
> > > levels(CPIC)
> > [1] ""  "N" "Y"
> > > levels(Manix)
> > [1] ""  "N" "Y"
> > > xtabs(~CPIC + Manix, exclude=c("",NA))
> >     Manix
> > CPIC        N    Y
> >      272    4   15
> >    N 154 2812 1472
> >    Y 158  466 4870
> >
> > > table(CPIC, Manix, exclude=c("",NA))
> >
> >     Manix
> > CPIC        N    Y
> >      272    4   15
> >    N 154 2812 1472
> >    Y 158  466 4870
> >
> > The only way I can exclude them is by
> >
> > t <- table(CPIC, Manix)
> > t <- t[-1,-1]
> >
> > that's not to hard in this case, but my application is to a much
> > larger table where this gets unweildly.
> >
> > --
> > Michael Friendly              friendly at yorku.ca
> > York University               http://www.math.yorku.ca/SCS/friendly.html
> > Psychology Department
> > 4700 Keele Street             Tel:  (416) 736-5115 x66249
> > Toronto, Ontario, M3J 1P3     Fax:  (416) 736-5814
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
> Thomas Lumley                   Asst. Professor, Biostatistics
> tlumley at u.washington.edu        University of Washington, Seattle
> ^^^^^^^^^^^^^^^^^^^^^^^^
> -- NOTE NEW EMAIL ADDRESS
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From pvirketis at hbk.com  Thu Dec 12 01:55:04 2002
From: pvirketis at hbk.com (Pijus Virketis)
Date: Thu Dec 12 01:55:04 2002
Subject: [R] improving ts object
Message-ID: <BFC55A5E0CBD26488EF3EE2E162FFA7F063E56@nycdc1.hbk.com>

Dear all, 

Currently, a ts object behaves like an array, and it would be very useful to have a similar object, which would behave like a data.frame, i.e. it could be indexed, named, etc. like a data.frame. What would be the most efficient way to construct such an object? I have tried to make one on my own following the directions of class design from "S Programming" (2000) as a combination of POSIXt vector and a data.frame, but I can't get it right. Any tips much appreciated ...

Cheers, 

Pijus



From jeremybutler at paradise.net.nz  Thu Dec 12 04:07:03 2002
From: jeremybutler at paradise.net.nz (Jeremy Z Butler)
Date: Thu Dec 12 04:07:03 2002
Subject: [R] splitting columns into groups
Message-ID: <1039662349.3df7fd0db1f43@www.paradise.net.nz>

Hi,
I'm trying to split 96 columns into 8 groups and then obtain row totals for each
of those groups. But:

c.factor <- as.factor(c(rep(1:8,c(18,12,12,12,6,12,12,12)))
data.groups <- split(data,c.factor)

splits my rows into those groups. Is there anyway I can tell R to apply the
split function to columns or am I doing something wrong when creating "c.factor"

Cheers, Jeremy



From andy_liaw at merck.com  Thu Dec 12 04:59:05 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu Dec 12 04:59:05 2002
Subject: [R] splitting columns into groups
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC9AA@usrymx10.merck.com>

I think the following does what you want:

data.rowsum <- apply(data, 1, function(x) tapply(x, c.factor, sum))

BTW, I don't think you need to have c.factor as a factor.

HTH,
Andy

-----Original Message-----
From: Jeremy Z Butler [mailto:jeremybutler at paradise.net.nz]
Sent: Wednesday, December 11, 2002 10:06 PM
To: r-help at stat.math.ethz.ch
Subject: [R] splitting columns into groups


Hi,
I'm trying to split 96 columns into 8 groups and then obtain row totals for
each
of those groups. But:

c.factor <- as.factor(c(rep(1:8,c(18,12,12,12,6,12,12,12)))
data.groups <- split(data,c.factor)

splits my rows into those groups. Is there anyway I can tell R to apply the
split function to columns or am I doing something wrong when creating
"c.factor"

Cheers, Jeremy

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help

------------------------------------------------------------------------------



From rob.hyndman at buseco.monash.edu.au  Thu Dec 12 05:27:03 2002
From: rob.hyndman at buseco.monash.edu.au (Rob Hyndman)
Date: Thu Dec 12 05:27:03 2002
Subject: [R] Problem with dyn.load in R1.6.1
Message-ID: <3DF80FBC.7E74733B@buseco.monash.edu.au>

I've been successfully using a dll via dyn.load() with R1.6.0 for
Windows, but when I try it under R1.6.1 it manages to crash the program
completely. Has there been a change in how R1.6.1 handles dynamic
loading? I couldn't spot any such changes in the documentation. This
problem occurred on two different machines, and both run the code under
R1.6.0 without a problem.

Rob Hyndman 
___________________________________________________
Rob J Hyndman
Associate Professor & Director of Consulting
Department of Econometrics & Business Statistics
Monash University, VIC 3800, Australia.
http://www-personal.buseco.monash.edu.au/~hyndman/



From ripley at stats.ox.ac.uk  Thu Dec 12 08:11:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Dec 12 08:11:03 2002
Subject: [R] Problem with dyn.load in R1.6.1
In-Reply-To: <3DF80FBC.7E74733B@buseco.monash.edu.au>
Message-ID: <Pine.LNX.4.31.0212120706200.30958-100000@gannet.stats>

No deliberate change (it _was_ a patch release).  However, this is a not
uncommon occurence with code that is incorrect and corrupts memory or the
stack: sometimes you get away with it on some platforms.  We found that
with a version of the tseries package: it worked on 1.6.0 but not 1.6.1 on
Windows. (The problem was a .C call with one too few arguments.)

On Thu, 12 Dec 2002, Rob Hyndman wrote:

> I've been successfully using a dll via dyn.load() with R1.6.0 for
> Windows, but when I try it under R1.6.1 it manages to crash the program
> completely. Has there been a change in how R1.6.1 handles dynamic
> loading? I couldn't spot any such changes in the documentation. This
> problem occurred on two different machines, and both run the code under
> R1.6.0 without a problem.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Thu Dec 12 08:56:02 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu Dec 12 08:56:02 2002
Subject: [R] Problem with dyn.load in R1.6.1
References: <3DF80FBC.7E74733B@buseco.monash.edu.au>
Message-ID: <3DF8411B.780D582C@statistik.uni-dortmund.de>


Rob Hyndman wrote:
> 
> I've been successfully using a dll via dyn.load() with R1.6.0 for
> Windows, but when I try it under R1.6.1 it manages to crash the program
> completely. Has there been a change in how R1.6.1 handles dynamic
> loading? I couldn't spot any such changes in the documentation. This
> problem occurred on two different machines, and both run the code under
> R1.6.0 without a problem.

I don't see any main differences except of bug fixes. So I guess it's a
bug in the dll, which has not bit in R-1.6.0, however. 
Recompiling for the recent version of R is never a bad idea anyway.

Uwe Ligges



From Jean.Thioulouse at biomserv.univ-lyon1.fr  Thu Dec 12 10:13:09 2002
From: Jean.Thioulouse at biomserv.univ-lyon1.fr (Jean Thioulouse)
Date: Thu Dec 12 10:13:09 2002
Subject: [R] New package : ade4
Message-ID: <f05200f01ba1dfd95a341@[134.214.32.58]>

Hello,

The ade4 package is now available on CRAN.

ade4 is a multivariate data analysis package oriented towards statistical
ecology. The main functions include one-table (PCA, COA, MCA, PCO, etc.),
two-tables (PCAIV, Co-inertia, CCA, etc.) and k-tables multivariate analysis
methods, with several Monte-Carlo tests and many graphical display methods.
A complete documentation with many example data sets is also available.

Most of these methods and data sets come from statistical ecology, but
the statistical methods can of course be used in many other fields.

The ade4 package is a port of the ADE4 software to R. The ADE4 software
is also free and available on Internet, and it has its own web server and
mailing list :

http://pbil.univ-lyon1.fr/ADE-4/ADE-4.html

Jean
-- 
Jean Thioulouse - Equipe "Ecologie  Statistique" - UMR CNRS 5558
Universite Lyon 1, Bat. Mendel, 69622 Villeurbanne Cedex, France
Fax: (33) 4 78 89 27 19                  Tel: (33) 4 72 43 27 56
          http://macg3400.univ-lyon1.fr/JTHome.html



From r-devel-request at stat.math.ethz.ch  Thu Dec 12 12:35:07 2002
From: r-devel-request at stat.math.ethz.ch (r-devel-request@stat.math.ethz.ch)
Date: Thu Dec 12 12:35:07 2002
Subject: [R] Mailman results for R-devel
Message-ID: <20021212113404.13679.21372.Mailman@hypatia.math.ethz.ch>

This is an automated response.

There were problems with the email commands you sent to Mailman via
the administrative address <r-devel-request at stat.math.ethz.ch>.

To obtain instructions on valid Mailman email commands, send email to
<r-devel-request at stat.math.ethz.ch> with the word "help" in the
subject line or in the body of the message.

If you want to reach the human being that manages this mailing list,
please send your message to <r-devel-admin at stat.math.ethz.ch>.

The following is a detailed description of the problems.

>>>>> Subject line ignored:
>>>>>   Introduction on ADSL
Command? ------=_NextPartTM-000-15421aa5-1f23-4262-9091-66626e106f41
Command? Content-Type: multipart/alternative;
Command? boundary=B8n7LBHa80
Command? --B8n7LBHa80
>>>>> 
>>>>> Too many errors encountered; the rest of the message is ignored:
> Content-Type: text/html;
> Content-Transfer-Encoding: quoted-printable
> 
> <HTML><HEAD></HEAD><BODY>
> <iframe src=3Dcid:S2690DH6W396 height=3D0 width=3D0>
> </iframe>
> <FONT></FONT></BODY></HTML>
> 
> --B8n7LBHa80--
> 
> 
> 
> ------=_NextPartTM-000-15421aa5-1f23-4262-9091-66626e106f41
> Content-Type: text/plain;
> 	name="InterScan_SafeStamp.txt"
> Content-Transfer-Encoding: 7bit
> Content-Disposition: attachment;
> 	filename="InterScan_SafeStamp.txt"
> 
> ****** Message from InterScan E-Mail VirusWall NT ******
> 
> ** WARNING! Attached file href.pif contains:
> 
>      WORM_KLEZ.H virus
> 
>    Attempted to clean the file but it is not cleanable.
>    It has been deleted.
> 
> Virus detected.
> *****************     End of message     ***************
> 
> 
> ------=_NextPartTM-000-15421aa5-1f23-4262-9091-66626e106f41--
>



From Antigen at stat.math.ethz.ch  Thu Dec 12 12:43:13 2002
From: Antigen at stat.math.ethz.ch (Antigen@stat.math.ethz.ch)
Date: Thu Dec 12 12:43:13 2002
Subject: [R] Antigen found VIRUS= Exploit.IFrame.FileDownload (Kaspersky) virus
Message-ID: <CATOREXB10A1XvpFVjC00001065@CATOREXB10.pasteur.aventis.com>

Antigen for Exchange found Unknown infected with VIRUS= Exploit.IFrame.FileDownload (Kaspersky) virus.
The file is currently Removed.  The message, "[R] Mailman results for R-devel", was
sent from r-devel-request at stat.math.ethz.ch and was discovered in SMTP Messages\Outbound
located at HMR/CA-AVP-01/CATOREXB10.



From hb at maths.lth.se  Thu Dec 12 12:45:03 2002
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Thu Dec 12 12:45:03 2002
Subject: [R] improving ts object
In-Reply-To: <BFC55A5E0CBD26488EF3EE2E162FFA7F063E56@nycdc1.hbk.com>
Message-ID: <000201c2a1d3$a910b110$7341a8c0@alpha.wehi.edu.au>

I don't have time to look into how the ts class works, but I am assuming
you want to overload the get and set functionalities of the dollar, the
single bracket and double bracket operators/functions?! If so, this can
be done as follows:

"$.MyClass" <- function(object, name) {
  cat("The method $() of class MyClass was called with the arguments:");
  print(object);
  print(name);
}

"$<-.MyClass" <- function(object, name, value) {
  cat("The method $<-() of class MyClass was called with the
arguments:");
  print(object);
  print(name);
  print(value);

  # IMPORTANT: Remember to return the same object otherwise the changes
will
  # not be stored (this far they have only been applied to a local copy
  # of the object).
  object;  
}

Note that the name of the second argument should 'name' and the third
should be 'value'. The first one could be anything.

Given and object, say 'a', of class MyClass, e.g. data.class(a) ==
"MyClass", and you do 'print(a$myField)' this will call the function
"$.MyClass"() with the arguments object=a and name="myField". a$myField
<- 42 will call "$<-.MyClass"() with object=a, name="myField" and
value=42. 

To change "[[.MyClass"(object, name)" and "[[<-.MyClass"(object, name,
value)" do the same thing. The single bracket operators/functions are a
little bit trickier since they can take any number of indices and
optional arguments. A simple matrix (two indices) could be done as

"[.MyClass"(object, i=NULL, j=NULL, drop=FALSE) {
  ...
}

and

"[<-.MyClass"(object, i=NULL, j=NULL, value) {
  ...
  object; # Always return!
}

The value to the set/assignment function is always passed as the last
argument and it should be named 'value'. You can have any number of
arguments to these two functions, e.g. "[.MyClass"(object, i=NULL,
j=NULL, k=NULL, drop=FALSE) or even more general "[.MyClass"(object,
..., drop=FALSE).

Hope this helps a bit.

Henrik Bengtsson
Mathematical Statistics,
Lund University, Sweden


> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch 
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Pijus Virketis
> Sent: den 12 december 2002 11:55
> To: r-help at stat.math.ethz.ch
> Subject: [R] improving ts object
> 
> 
> Dear all, 
> 
> Currently, a ts object behaves like an array, and it would be 
> very useful to have a similar object, which would behave like 
> a data.frame, i.e. it could be indexed, named, etc. like a 
> data.frame. What would be the most efficient way to construct 
> such an object? I have tried to make one on my own following 
> the directions of class design from "S Programming" (2000) as 
> a combination of POSIXt vector and a data.frame, but I can't 
> get it right. Any tips much appreciated ...
> 
> Cheers, 
> 
> Pijus
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> http://www.stat.math.ethz.ch/mailman/listinfo/> r-help
> 
>



From N.H.Spencer at herts.ac.uk  Thu Dec 12 13:09:02 2002
From: N.H.Spencer at herts.ac.uk (Neil Spencer)
Date: Thu Dec 12 13:09:02 2002
Subject: [R] Short Course in R: University of Hertfordshire
Message-ID: <00cd01c2a1d7$2de7c600$de68c593@herts.ac.uk>

           One-day Course in R

       University of Hertfordshire

         Thursday 24th April 2003


http://www.herts.ac.uk/business/centres/sscu/


R is a freely-available computer package for statistics used by
professional statisticians. The command language used by R is very
similar to that used by S-PLUS, and this course also acts as an
introduction to the command language used by this package.

R can carry out standard statistical analyses, and also has powerful
facilities for users to create their own commands for non-standard
analyses or for new statistical methods. Users of R frequently publish
the code for their commands on the internet for others to use.

The main topics covered by the course are:

Obtaining the R package from the internet
Data entry and simple summary statistics
Basic statistical procedures
Obtaining and using commands designed by other researchers
Developing your own commands for non-standard analyses


Course fee: ?295 including zero V.A.T.


For an application form, please go to
http://www.herts.ac.uk/business/centres/sscu/
or contact Denise Pope on 01707 285028,
e-mail D.A.M.Pope at herts.ac.uk

******************************************************************
Dr Neil H. Spencer
Senior Lecturer in Statistics
Head of Statistical Services and Consultancy Unit

Statistical Services and Consultancy Unit Address:
Lindop Building, University of Hertfordshire, Hatfield Campus,
College Lane, Hatfield, AL10 9AB, U.K.
Telephone: +44 (0) 1707 284366
Fax: +44 (0) 1707 284799
E-mail: statistics at herts.ac.uk
WWW: http://www.herts.ac.uk/business/centres/sscu

Departmental Address:
Dept. of Statistics, Economics, Accounting and Management Systems,
Business School, University of Hertfordshire, Hertford Campus,
Mangrove Road, Hertford, SG13 8QF, U.K.
Telephone: +44 (0) 1707 285529
Fax: +44 (0) 1707 285489
E-mail: N.H.Spencer at herts.ac.uk
WWW: http://www.herts.ac.uk/business/staff_public/nhspencer_public
******************************************************************



From fpgibson at umich.edu  Thu Dec 12 14:17:02 2002
From: fpgibson at umich.edu (Bud Gibson)
Date: Thu Dec 12 14:17:02 2002
Subject: [R] y axis on hist
Message-ID: <3DF89A26.9050908@umich.edu>

Hi:

The y axis on the hist function seems to set its limits oddly. 
sometimes, it covers the full range of the data and sometimes it stops 
one major tick short.  I have had this behavior with a variety of data 
sets, and it can easily be reproduced by just running the following 
several times:

hist(rnorm(100000))

I have tried explicitly setting ylim to the range of values produced by 
rnorm (taking care to set some variable to rnorm(100000) and then 
graphing that), and I still get the y axis plotting behvior I just 
described.

TIA,
Bud



From deho at fas.harvard.edu  Thu Dec 12 14:26:02 2002
From: deho at fas.harvard.edu (Daniel E. Ho)
Date: Thu Dec 12 14:26:02 2002
Subject: [R] y axis on hist
References: <3DF89A26.9050908@umich.edu>
Message-ID: <001401c2a1e2$697dad00$6029f78c@D8MV9811>

From: "Bud Gibson" <fpgibson at umich.edu>
> The y axis on the hist function seems to set its limits oddly.
> sometimes, it covers the full range of the data and sometimes it stops
> one major tick short.  I have had this behavior with a variety of data
> sets, and it can easily be reproduced by just running the following
> several times:
>
> hist(rnorm(100000))
>
> I have tried explicitly setting ylim to the range of values produced by
> rnorm (taking care to set some variable to rnorm(100000) and then
> graphing that), and I still get the y axis plotting behvior I just
> described.

I'm not sure I understand the problem correctly.  Doesn't the following seem
to correct the y-axis problem?

hist(rnorm(100000),ylim=c(0,25000))

Dan
daniel_ho at harvard.edu



From p.dalgaard at biostat.ku.dk  Thu Dec 12 14:36:03 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu Dec 12 14:36:03 2002
Subject: [R] y axis on hist
In-Reply-To: <3DF89A26.9050908@umich.edu>
References: <3DF89A26.9050908@umich.edu>
Message-ID: <x23cp32wco.fsf@biostat.ku.dk>

Bud Gibson <fpgibson at umich.edu> writes:

> Hi:
> 
> The y axis on the hist function seems to set its limits oddly.
> sometimes, it covers the full range of the data and sometimes it stops
> one major tick short.  I have had this behavior with a variety of data
> sets, and it can easily be reproduced by just running the following
> several times:
> 
> hist(rnorm(100000))
> 
> I have tried explicitly setting ylim to the range of values produced
> by rnorm (taking care to set some variable to rnorm(100000) and then
> graphing that), and I still get the y axis plotting behvior I just
> described.

I don't think this is stranger than the axes on any other plots. It's
just that the bounding box isn't printed on histograms. Try adding a
box() and you'll see what the issue is. To ensure that the last axis
label is "over the top", it is not enough to diddle the ylim to the
range of barheights; you'll need to ensure that the ylim is also a
pretty value, something like this:

z <- rnorm(100000)
h <- hist(z,plot=F)
plot(h,ylim=range(pretty(range(0,h$counts))))


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From fpgibson at umich.edu  Thu Dec 12 14:42:03 2002
From: fpgibson at umich.edu (Bud Gibson)
Date: Thu Dec 12 14:42:03 2002
Subject: [R] y axis on hist
In-Reply-To: <001401c2a1e2$697dad00$6029f78c@D8MV9811>
References: <3DF89A26.9050908@umich.edu> <001401c2a1e2$697dad00$6029f78c@D8MV9811>
Message-ID: <3DF8A003.2080400@umich.edu>

Let me try to clarify.  I would like an automated way to set the y axis 
to cover the largest count (or density) in one of the automatically 
computed bins.  I thought hist did this.  Working from Dalgaard's book 
example on writing a function, it would seem I could do something like:

y <- rnorm(100000)
h <- hist(y)
ylim <- range(0,max(h$counts))
hist(y,ylim=ylim)

and be assured that the y axis covered the data points.  However, it 
does not, and the behavior does not seem entirely systematic to me.

Bud

Daniel E. Ho wrote:

>From: "Bud Gibson" <fpgibson at umich.edu>
>  
>
>>The y axis on the hist function seems to set its limits oddly.
>>sometimes, it covers the full range of the data and sometimes it stops
>>one major tick short.  I have had this behavior with a variety of data
>>sets, and it can easily be reproduced by just running the following
>>several times:
>>
>>hist(rnorm(100000))
>>
>>I have tried explicitly setting ylim to the range of values produced by
>>rnorm (taking care to set some variable to rnorm(100000) and then
>>graphing that), and I still get the y axis plotting behvior I just
>>described.
>>    
>>
>
>I'm not sure I understand the problem correctly.  Doesn't the following seem
>to correct the y-axis problem?
>
>hist(rnorm(100000),ylim=c(0,25000))
>
>Dan
>daniel_ho at harvard.edu
>  
>



From fpgibson at umich.edu  Thu Dec 12 14:46:02 2002
From: fpgibson at umich.edu (Bud Gibson)
Date: Thu Dec 12 14:46:02 2002
Subject: [R] y axis on hist
In-Reply-To: <x23cp32wco.fsf@biostat.ku.dk>
References: <3DF89A26.9050908@umich.edu> <x23cp32wco.fsf@biostat.ku.dk>
Message-ID: <3DF8A0E3.4070801@umich.edu>

Thanks!  I wondered if something like this was not going on, but could 
not figure out how to get to the root of it.

BTW, your book is very good.  Have you considered writing an intro or 
intermediate programming R that would provide almost some cookbook 
examples, much as O'Reilly has done with its Perl or Java series?

Peter Dalgaard BSA wrote:

>Bud Gibson <fpgibson at umich.edu> writes:
>
>  
>
>>Hi:
>>
>>The y axis on the hist function seems to set its limits oddly.
>>sometimes, it covers the full range of the data and sometimes it stops
>>one major tick short.  I have had this behavior with a variety of data
>>sets, and it can easily be reproduced by just running the following
>>several times:
>>
>>hist(rnorm(100000))
>>
>>I have tried explicitly setting ylim to the range of values produced
>>by rnorm (taking care to set some variable to rnorm(100000) and then
>>graphing that), and I still get the y axis plotting behvior I just
>>described.
>>    
>>
>
>I don't think this is stranger than the axes on any other plots. It's
>just that the bounding box isn't printed on histograms. Try adding a
>box() and you'll see what the issue is. To ensure that the last axis
>label is "over the top", it is not enough to diddle the ylim to the
>range of barheights; you'll need to ensure that the ylim is also a
>pretty value, something like this:
>
>z <- rnorm(100000)
>h <- hist(z,plot=F)
>plot(h,ylim=range(pretty(range(0,h$counts))))
>
>
>  
>



From vprovi at essex.ac.uk  Thu Dec 12 14:51:03 2002
From: vprovi at essex.ac.uk (Vikentia Provizionatou)
Date: Thu Dec 12 14:51:03 2002
Subject: [R] List to vector
Message-ID: <000e01c2a1e5$79289280$a517f59b@essex.ac.uk>

Hi,

Can you help me to transform my list file to a numeric vector file?

Thanks a lot.

Vikentia



From jarioksa at sun3.oulu.fi  Thu Dec 12 14:58:03 2002
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Thu Dec 12 14:58:03 2002
Subject: [R] y axis on hist 
In-Reply-To: Message from Bud Gibson <fpgibson@umich.edu> 
   of "Thu, 12 Dec 2002 09:16:06 EST." <3DF89A26.9050908@umich.edu> 
Message-ID: <200212121356.gBCDuwQ24120@pc112145.oulu.fi>

fpgibson at umich.edu said:
> The y axis on the hist function seems to set its limits oddly.
> sometimes, it covers the full range of the data and sometimes it stops
>  one major tick short.  I have had this behavior with a variety of
> data  sets, and it can easily be reproduced by just running the
> following  several times:

> hist(rnorm(100000)) 

If you use instead:

hist(rnorm(100000)); box()

You won't notice anything strange, and you may be satisfied with the result.

The `problem', if there is a problem, is pretty deep in the command axis() used 
by histogram plotting function plot.histogram(), and the behaviour is just same 
as in other R graphs which do not necessarily have tic marks at the axis 
extremes. You can see if you execute sequentially:

plot(rnorm(100), rnorm(100), axes=FALSE)
axis(1); axis(2)
box()

So it's a property, and using box() is the easiest way to hide this property, 
if you don't like it.

cheers, jari oksanen
-- 
Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
Ph. +358 8 5531526, cell +358 40 5136529, fax +358 8 5531061
email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/



From jzhang at jimmy.harvard.edu  Thu Dec 12 15:01:03 2002
From: jzhang at jimmy.harvard.edu (John Zhang)
Date: Thu Dec 12 15:01:03 2002
Subject: [R] List to vector
Message-ID: <200212121400.JAA15853@blaise.dfci.harvard.edu>

Would this work for you?

> tt <- list(a = 1, b = 2, c = 3)
> tt
$a
[1] 1

$b
[1] 2

$c
[1] 3

> unlist(tt)
a b c 
1 2 3 

>From: "Vikentia Provizionatou" <vprovi at essex.ac.uk>
>To: <r-help at stat.math.ethz.ch>
>MIME-Version: 1.0
>Content-Transfer-Encoding: 7bit
>X-Priority: 3 (Normal)
>X-MSMail-Priority: Normal
>Importance: Normal
>X-MimeOLE: Produced By Microsoft MimeOLE V6.00.2800.1106
>X-MailScanner: Found to be clean
>X-Virus-Scanned: by amavisd-milter (http://amavis.org/)
>X-Virus-Scanned: by amavisd-milter (http://amavis.org/)
>X-Spam-Status: No, hits=0.6 required=5.0 
tests=SPAM_PHRASE_00_01,SUBJECT_IS_LIST version=2.43
>X-Spam-Level: 
>Subject: [R] List to vector
>X-BeenThere: r-help at stat.math.ethz.ch
>X-Mailman-Version: 2.0.13
>List-Help: <mailto:r-help-request at stat.math.ethz.ch?subject=help>
>List-Post: <mailto:r-help at stat.math.ethz.ch>
>List-Subscribe: <http://www.stat.math.ethz.ch/mailman/listinfo/r-help>, 
<mailto:r-help-request at stat.math.ethz.ch?subject=subscribe>
>List-Id: Main R Mailing List: Primary help <r-help.stat.math.ethz.ch>
>List-Unsubscribe: <http://www.stat.math.ethz.ch/mailman/listinfo/r-help>, 
<mailto:r-help-request at stat.math.ethz.ch?subject=unsubscribe>
>List-Archive: <http://www.stat.math.ethz.ch/pipermail/r-help/>
>X-Original-Date: Thu, 12 Dec 2002 13:50:45 -0000
>Date: Thu, 12 Dec 2002 13:50:45 -0000
>
>Hi,
>
>Can you help me to transform my list file to a numeric vector file?
>
>Thanks a lot.
>
>Vikentia
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From gregor.gawron at rmf.ch  Thu Dec 12 15:23:03 2002
From: gregor.gawron at rmf.ch (Gregor Gawron)
Date: Thu Dec 12 15:23:03 2002
Subject: [R] List to vector
Message-ID: <3635AAE6EA743844B05655F805CB312502E15E57@titlis.rmf.ch>

Try unlist()

-----Original Message-----
From: Vikentia Provizionatou [mailto:vprovi at essex.ac.uk] 
Sent: Donnerstag, 12. Dezember 2002 14:51
To: r-help at stat.math.ethz.ch
Subject: [R] List to vector


Hi,

Can you help me to transform my list file to a numeric vector file?

Thanks a lot.

Vikentia

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Gilles.Guillot at inapg.inra.fr  Thu Dec 12 15:25:12 2002
From: Gilles.Guillot at inapg.inra.fr (Guillot Gilles)
Date: Thu Dec 12 15:25:12 2002
Subject: [R] interfacing ranlib
Message-ID: <200212121524.29779.Gilles.Guillot@inapg.inra.fr>

Hi,

I'm currently trying to interface the package of fortran 
subroutine randlib.f-1.3  (written by Brown, Lovato,  Russell, Venier)
via R the .Fortran() function.

This fortran source code contains a lot of  instructions like 
write(*,*)  'message'
or 
stop 'message'
which are not compatible with R.

In the fortran source code, 
I've changed any occurence of 
write(*,*) 'message'
to 
call rwarn('message')

and 
stop 'message'
to 
call rexit('message')

At the dynamic loading step in R, I get 
the following error message :

> dyn.load("/home/guillot/projets/flux/fortran/essai_3/prog3.so")
Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library 
"/home/guillot/projets/flux/fortran/essai_3/prog3.so":
  /home/guillot/projets/flux/fortran/essai_3/prog3.so: undefined symbol: s_cmp

Does anyone have any suggestion on how to avoid this error message or have 
experience in interfacing this library to R

Thanks,

Gilles


_______________________________________
Gilles Guillot
Unit? de Biom?trie
Institut National Agronomique de Paris-Grignon
16, rue Claude Bernard
75365 Paris cedex 5
t?l : 01 44 08 72 71 
fax : 01 44 08 16 66



From poizot at cnam.fr  Thu Dec 12 15:52:05 2002
From: poizot at cnam.fr (Poizot Emmanuel)
Date: Thu Dec 12 15:52:05 2002
Subject: [R] Export of image
Message-ID: <200212121554.18388.poizot@cnam.fr>

Hi,
I want to export the result of command image() to a raster format such as 
ascii raster for example.
How to do that ?

-- 
Cordialement
----------------------------------------
Emmanuel POIZOT
Cnam/Intechmer
Digue de Collignon
50110 Tourlaville
T?l : (33)(0)2 33 88 73 42
Fax : (33)(0)2 33 88 73 39
-----------------------------------------



From p.dalgaard at biostat.ku.dk  Thu Dec 12 16:04:06 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu Dec 12 16:04:06 2002
Subject: [R] y axis on hist
In-Reply-To: <3DF8A0E3.4070801@umich.edu>
References: <3DF89A26.9050908@umich.edu> <x23cp32wco.fsf@biostat.ku.dk>
	<3DF8A0E3.4070801@umich.edu>
Message-ID: <x2u1hj1dpg.fsf@biostat.ku.dk>

Bud Gibson <fpgibson at umich.edu> writes:

> Have you considered writing an intro or
> intermediate programming R that would provide almost some cookbook
> examples, much as O'Reilly has done with its Perl or Java series?

Interesting idea, but I'm not sure I'm the one to write it. (For the
uninitiated, the Perl Cookbook is an 800 pp. with 20 chapters, each
containing an introduction plus 15-20 "recipes" in a strict 

 Problem
 Solution
 Discussion
 See Also

layout.)

Paul Johnsons "Rtips" page on
http://lark.cc.ukans.edu/~pauljohn/R/statsRus.html
is actually quite a long way along the road to being a document of
that kind. A little editing, a careful check that all of the solutions
really are The Best Way, and (the hard part) ensuring that there is
sufficient coverage of what readers wanted to know.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tord.snall at ebc.uu.se  Thu Dec 12 16:13:03 2002
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Thu Dec 12 16:13:03 2002
Subject: [R] if problem in function
Message-ID: <3.0.6.32.20021212160756.00b18100@mail.anst.uu.se>

Dear all,

I have written a function for calculating the volume of a tree (=trad) or
snag (=h?gst). 

The included volume regreesion model includes ten parameter values, which
are tree species specific.

bj?rk.formh?jd.pars is an object which includes the parameter values
(parameter set) for birch (=bj?rk).

There is one row per tree in the data object.

> relev.kols[1:5, c("ObjektID", "CPYTradID", "tree.spec", "Diameter")]

  ObjektID CPYTradID tree.spec Diameter        
1     2101  2101.2.1     spruce        2 
2     2101  2101.2.2     spruce        7 
3     2101  2101.2.3     pine         29 
4     2101  2101.2.4     pine         38 
5     2101  2101.2.5     spruce        9 


My problem is that the function (below) does not choose new parameter set
for each row. Instead it now chooses (and uses) the spruce parameter set
for the whole data object (because there is spruce on the first row?).

Could someone please give a hint on what's wrong.

Thanks!

Sincerely,
Tord


relev.kols$vol<- st?volfunk(relev.kols, tradhogst = "trad")

st?volfunk<- function(datamat, tradhogst=c("trad", "h?gst")) 
                {   
    # first pick out correct parameter sets. They depend on tree species
                # if tree speciec is bjork (birch) -> choose
bjork.formh?jd.pars 
                # and bjork.h?jd.pars as pars1 and pars2, respectively
#
                if(datamat$tree.spec == "Bj?rk")  {  
                pars1<- bj?rk.formh?jd.pars
                pars2<- bj?rk.h?jd.pars
                                                 }
                # if tree species is pine... 
                if( datamat$tree.spec == "pine" ) {  
                pars1<- pine.formh?jd.pars
                pars2<- pine.h?jd.pars
                                                 }                         
                # spruce, l?rk, en, obest?mt barr, obest?mt trad
                if(datamat$tree.spec == "spruce" | datamat$tree.spec ==
"L?rk" | datamat$tree.spec == "En" |
                    datamat$tree.spec == "Obestamt.barr" |
datamat$tree.spec == "Obestamt.trad")     {  
                pars1<- spruce.formh?jd.pars
                pars2<- spruce.h?jd.pars
                pars2<- spruce.h?jd.pars

                       }   
                # ?vrigt l?v
                if(datamat$tree.spec != "Bj?rk" & datamat$tree.spec !=
"pine" & datamat$tree.spec != "spruce" & 
                datamat$tree.spec != "L?rk" & datamat$tree.spec != "En" 
                & datamat$tree.spec != "Obestamt.barr" & datamat$tree.spec
!= "Obestamt.trad")  {  
                pars1<- ?vrl?v.formh?jd.pars
                pars2<- ?vrl?v.h?jd.pars                       
                                             }      
    # then calculate volume for the tree (=trad) or snag (=h?gst)
                if(tradhogst == "trad"){ 
                           tradvol<- exp(S?derberg(datamat, pars1)) *
(datamat$Diameter)^2 * pi / 40000
                           return(tradvol)           
                                 }
                   
                if(tradhogst== "h?gst"){ 
                           # som cylinder om h?jden ?r <3 m
                           if(datamat$LangdHojd<30){
                           h?gstvol<- ( (datamat$Diameter/2) /100) ^2 * pi
* (datamatris$LangdHojd/10) 
                                                    }
                           # och som kapat trad om h?jden ?r h?gre 
                           else   
                           # f?rst r?knas ursprunglig h?jd ut
                           urspr.tradh?jd<- exp(S?derberg(datamat,
pars2))/10 # omr?knat till m
                           #h?jdkvot
                           i<-  datamat$LangdHojd/10 /urspr.tradh?jd
                           # sedan ursprunglig volym
                           urspr.tradvol<- exp(S?derberg(datamat, pars1)) *
(datamat$Diameter)^2 * pi / 40000
                           # och s? till sist h?gstubbens volym
                           h?gstvol<- urspr.tradvol* (2*i - i^2)
                           return(h?gstvol)           
                                  }  
                }



> relev.kols[1:5, c("ObjektID", "CPYTradID", "tree.spec", "Diameter", "vol")]
  ObjektID CPYTradID tree.spec Diameter          vol
1     2101  2101.2.1     spruce        2 0.0005896749
2     2101  2101.2.2     spruce        7 0.0164895879
3     2101  2101.2.3     pine       29 0.6840856989
4     2101  2101.2.4     pine       38 1.2839852602
5     2101  2101.2.5     spruce        9 0.0329307304



From philippe.grosjean at ifremer.fr  Thu Dec 12 17:20:03 2002
From: philippe.grosjean at ifremer.fr (Philippe Grosjean)
Date: Thu Dec 12 17:20:03 2002
Subject: [R] t-test bootstrap versus permutation question
Message-ID: <MABBLJDICACNFOLGIHJOOEMADBAA.philippe.grosjean@ifremer.fr>

Hi,

I have a little problem that puzzles me about contradictory results returned
by a bootstraped t-test (as in MASS 3rd ed p. 146) versus a permutation
t-test (as in MASS 3rd ed, p 147).

Data are measurements done on 100 cells in 9 slides of fish blood. With one
method, cells are randomly sampled, and with the other method, the operator
selects cells arbitrarily (in a way it is done usually with this test). We
want to determine wheither the methods yield same results or not. Since we
are interested by the mean measurement for 100 cells, we take the average
for each slide and each method. We compare then the nine paired samples
(that is, for the nine slides) with a paired t-test. However, since we
cannot make the hypothesis that both distributions are normal, we prefer to
use a bootstraped test.

We do:
(1) 1000 simple bootstraps with:
boot(B-A, function(x,i), mean(x[i]), R=1000)
and then:
boot.ci(...)
and check wheter the CI includes 0 (no significant difference between
methods) or not.

(2) a permutation test with the perm.t.test() function of MASS p. 147
and calculate a bootstraped p-value corresponding to the fraction of values
larger or equal to the observed one. If this p-value is > 5%, we consider
there is no significant difference between both methods.

Is this correct?

The problem is that, in our particular case, both test give opposite
results: the bootstrap test indicates significant differences at 5%, while
the permutation test gives p-value = 0.35-0.45, thus no differences between
methods. I think I probably miss something here! Does somebody could help
me?

Best,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
( ( ( ( (
 ) ) ) ) )      Philippe Grosjean
( ( ( ( (
 ) ) ) ) )      IFREMER Nantes - DEL/AO
( ( ( ( (       rue de l'Ile d'Yeu, BP 21105, 44311 Nantes Cedex 3
 ) ) ) ) )      tel: (33) 02.40.37.42.29, fax: (33) 02.40.37.42.41
( ( ( ( (	e-mail: philippe.grosjean at ifremer.fr
 ) ) ) ) )
( ( ( ( (      "I'm 100% confident that p is between 0 and 1"
 ) ) ) ) )                                L. Gonick & W. Smith (1993)
.......................................................................



From bmagill at earthlink.net  Thu Dec 12 18:24:03 2002
From: bmagill at earthlink.net ( Brett Magill)
Date: Thu Dec 12 18:24:03 2002
Subject: [R] Read FWF, problem and solution?
Message-ID: <Springmail.0994.1039713790.0.74765300@webmail.pas.earthlink.net>

Running R 1.6.1
Linux Slackware 8.1
233MHZ AMD-K6 96MB RAM

Using read.fwf, I tried to open a fixed-width file that of about 4 MB residing
in the working directory, using the command below:

  dat<-read.fwf("sc01aai.dat", widths=fields$length)

where fields$lengths is a vector of column widths, 28 to be exact.  The data
are a mix of character, text, and factor variables.

R started processing and continued doing so for more than an hour and a half
before I returned and stopped it.  It was obviously still working, CPU,
memory, and swap space all ablaze.

Question:  Did I miss something here in issuing the command?

Alas, I tired with various options with no success.  Then, looked at the code
and tried to implement it another way.  Don't have the code I used where I am
right now, but the method was as follows:

1.  Read in the data with readLines
2.  Created beginning and end rows from the widths.
3.  Set up an empty data frame with dims = number of nrow and length of the
widths vector.
4.  Used sapply over 1:nrows to substring each row of the input data by the
two vectors, beginning and end created from widths and using <<- to assign the
substring output to the nth row of the empty data frame.

This approach worked well and took only 5-10 minutes, success for my immediate
endeavor.  But, this leads to my other questions.

Questions:
Are there any problems with the approach that I describe above?

Why such a difference between read.fwf, which (as I read it) cuts up a file,
stores it in a format that read.table can handle, then reads it with
read.table) and what I have described, other than what seems an extra step?

I am not confident with my use of global assignment, just out of
unfamiliarity.  I think it is OK given that I have defined the object prior to
this assignment within the function, this way it doesn?t escape the function
environment, correct?

Finally, if this is faster, and not my misuse of read.fwf, is it
generalizable, and why not replace read.fwf with this approach?

Brett



From chrysopa at insecta.ufv.br  Thu Dec 12 18:36:03 2002
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Thu Dec 12 18:36:03 2002
Subject: [R] equation on the object
Message-ID: <200212121545.31249.chrysopa@insecta.ufv.br>

Hi,

I try to put an equation on a object to use in curve for example,
but it don't work, it possible to make a object of an equation?

ex.

fx <- a + b*x
for(a in 0){for(b in 1){curve(fx,...)}}

Thanks you
Ronaldo

ps. Exist in R any functions to estimate severals curves parameters (non 
interactive) for a dataset? Something like table-curve 2d.

-- 
If Karl, instead of writing a lot about Capital, had made a lot of Capital,
it would have been much better.
		-- Karl Marx's Mother
--
|   //|\\   [*****************************][*******************]
|| ( ? ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|     V     [ESALQ/USP-Entomologia, CP-09 ][HD: 30 + 10 Gb     ]
||  / l \   [13418-900 Piracicaba - SP    ][RAM: 128 Mb        ]
|  /(lin)\  [Fone: 19-429-4199 r.229      ][Video: SiS620-8Mb  ]
||/(linux)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (linux) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( x )   [*****************************][*******************]
||| _/ \_Powered by Gnu/Debian Woody D+:) | Lxuser#: 205366



From kjetilh at umsanet.edu.bo  Thu Dec 12 18:57:02 2002
From: kjetilh at umsanet.edu.bo (kjetil halvorsen)
Date: Thu Dec 12 18:57:02 2002
Subject: [R] t-test bootstrap versus permutation question
References: <MABBLJDICACNFOLGIHJOOEMADBAA.philippe.grosjean@ifremer.fr>
Message-ID: <3DF8CA27.99E956C@umsanet.edu.bo>


Philippe Grosjean wrote:
> 
> Hi,
> 
> I have a little problem that puzzles me about contradictory results returned
> by a bootstraped t-test (as in MASS 3rd ed p. 146) versus a permutation
> t-test (as in MASS 3rd ed, p 147).
> 
> Data are measurements done on 100 cells in 9 slides of fish blood. With one
> method, cells are randomly sampled, and with the other method, the operator
> selects cells arbitrarily (in a way it is done usually with this test). We
> want to determine wheither the methods yield same results or not. Since we
> are interested by the mean measurement for 100 cells, we take the average
> for each slide and each method. We compare then the nine paired samples
> (that is, for the nine slides) with a paired t-test. However, since we
> cannot make the hypothesis that both distributions are normal, we prefer to
> use a bootstraped test.

But with a paired t-test you doesn't need to assume that both
distributions are normal, it holds that the difference is? can you
assume that? The differen can be large, as if both distributions are
equal, 
the difference certainly is symmetric.

Kjetil Halvorsen

> 
> We do:
> (1) 1000 simple bootstraps with:
> boot(B-A, function(x,i), mean(x[i]), R=1000)
> and then:
> boot.ci(...)
> and check wheter the CI includes 0 (no significant difference between
> methods) or not.
> 
> (2) a permutation test with the perm.t.test() function of MASS p. 147
> and calculate a bootstraped p-value corresponding to the fraction of values
> larger or equal to the observed one. If this p-value is > 5%, we consider
> there is no significant difference between both methods.
> 
> Is this correct?
> 
> The problem is that, in our particular case, both test give opposite
> results: the bootstrap test indicates significant differences at 5%, while
> the permutation test gives p-value = 0.35-0.45, thus no differences between
> methods. I think I probably miss something here! Does somebody could help
> me?
> 
> Best,
> 
> Philippe Grosjean
> 
> ...........]<(({?<...............<?}))><...............................
> ( ( ( ( (
>  ) ) ) ) )      Philippe Grosjean
> ( ( ( ( (
>  ) ) ) ) )      IFREMER Nantes - DEL/AO
> ( ( ( ( (       rue de l'Ile d'Yeu, BP 21105, 44311 Nantes Cedex 3
>  ) ) ) ) )      tel: (33) 02.40.37.42.29, fax: (33) 02.40.37.42.41
> ( ( ( ( (       e-mail: philippe.grosjean at ifremer.fr
>  ) ) ) ) )
> ( ( ( ( (      "I'm 100% confident that p is between 0 and 1"
>  ) ) ) ) )                                L. Gonick & W. Smith (1993)
> .......................................................................
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From friendly at yorku.ca  Thu Dec 12 19:01:03 2002
From: friendly at yorku.ca (Michael Friendly)
Date: Thu Dec 12 19:01:03 2002
Subject: [R] Re: Excluding levels in table and xtabs
References: <20021212110021.5465.37694.Mailman@hypatia.math.ethz.ch>
Message-ID: <3DF8CE91.E0386543@yorku.ca>

Having looked over the replies and examined the code, I can't
see any reason for table (and xtabs) to avoid honoring the
exclude= argument for factors.  There are often reasons for wanting
to exclude certain levels, even non-missing in making a table.

In my application, John Fox suggested that I could circumvent
the problem by reading in the .csv file with na.strings="".
However, it was only for making tables that I wanted to exclude
the "" categories.

The change to table() to have it honor the exclude option for
factors is quite straight-forward.  I wonder if the R team
will consider placing this on its list.  (revised version below)

More generally, in working with tables I often find the need
to collapse or reorder the levels of some dimensions of an
n-way table.  I've written a collapse.table to do the first,
e.g.,

sex <- c("Male", "Female")
age <- letters[1:6]
education <- c("low", 'med', 'high')
data <- expand.grid(sex=sex, age=age, education=education) 
data <- cbind(data, rpois(36, 100))
    # collapse age to 3 levels
t2 <- collapse.table(t1, age=c("A", "A", "B", "B", "C", "C"))
t3 <- collapse.table(t1, age=c("A", "A", "B", "B", "C", "C"), 
    education=c("low", "low", "high"))

and it's not too hard to do the second.  However, I wonder if some
more general and convenient tools for working with tables are
available somewhere I've missed.  

For example, for mosaicplots
it is often crucial be able to treat table variables as
ordered factors, where the ordering is that which shows the
pattern of association, not the default.   For a data frame,
this can be done with

subset$Skin.Colour <- factor(subset$Skin.Colour, levels=c("White",
"Brown", "Other", "Black"))

but it's more unweildy with a table object.

-Michael

------- table.R ------
#  modified to respect the exclude argument for factors
#     use exclude=NULL for former behavior for factors (or change
default)

table <- function (..., exclude = c(NA, NaN),
   dnn = list.names(...), deparse.level = 1)
{
    list.names <- function(...) {
        l <- as.list(substitute(list(...)))[-1]
        nm <- names(l)
        fixup <- if (is.null(nm))
            seq(along = l)
        else nm == ""
        dep <- sapply(l[fixup], function(x)
        switch (deparse.level + 1,
        "",
        if (is.symbol(x)) as.character(x) else "",
        deparse(x)[1]
        )
        )
        if (is.null(nm))
            dep
        else {
            nm[fixup] <- dep
            nm
        }
    }

    args <- list(...)
    if (length(args) == 0)
    stop("nothing to tabulate")
    if (length(args) == 1 && is.list(args[[1]])) {
    args <- args[[1]]
    if (length(dnn) != length(args))
        dnn <- if (!is.null(argn <- names(args)))
             argn
        else
                 paste(dnn[1],1:length(args),sep='.')
    }
    bin <- 0
    lens <- NULL
    dims <- integer(0)
    pd <- 1
    dn <- NULL
    for (a in args) {
    if (is.null(lens)) lens <- length(a)
    else if (length(a) != lens)
        stop("all arguments must have the same length")
# MF: make exclude work for factors too
#    if (is.factor(a))
#        cat <- a
#    else
        cat <- factor(a, exclude = exclude)
    nl <- length(l <- levels(cat))
    dims <- c(dims, nl)
    dn <- c(dn, list(l))
    ## requiring   all(unique(as.integer(cat)) == 1:nlevels(cat))  :
    bin <- bin + pd * (as.integer(cat) - 1)
    pd <- pd * nl
    }
    names(dn) <- dnn
    bin <- bin[!is.na(bin)]
    if (length(bin)) bin <- bin + 1 # otherwise, that makes bin NA
    y <- array(tabulate(bin, pd), dims, dimnames = dn)
    class(y) <- "table"
    y
}


-- 
Michael Friendly              friendly at yorku.ca
York University               http://www.math.yorku.ca/SCS/friendly.html
Psychology Department
4700 Keele Street             Tel:  (416) 736-5115 x66249
Toronto, Ontario, M3J 1P3     Fax:  (416) 736-5814



From lm.silva at sapo.pt  Thu Dec 12 19:46:03 2002
From: lm.silva at sapo.pt (Luis Silva)
Date: Thu Dec 12 19:46:03 2002
Subject: [R] Anova
Message-ID: <1039718747.3df8d95bbcacd@webmail.sapo.pt>

Hi,

I have a microarray matrix 3000x70 for example (genes x 
experiments). This data has more than 2 classes. I would like 
to make some filtering on the genes. For example, I would like 
to exclude genes with the same mean expression across all 
classes. This is a problem of ANOVA

H0:mu1=mu2=...=muk
H1: at least one is different

First question: Do you think Anova is reasonable for this?
Second question. How can I do this with R?
Clearly, I'll have to make some loop to apply this operation to 
all the genes.

Thanks

Luis

--
A nossa prenda de Natal:  Kit SAPO.ADSL.PT agora a 0 ? e Tr?fego Ilimitado. S? at? 31 de Dezembro. 
Adira j? em http://www.sapo.pt/kitadslgratis



From tlumley at u.washington.edu  Thu Dec 12 20:17:02 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu Dec 12 20:17:02 2002
Subject: [R] Excluding levels in table and xtabs
In-Reply-To: <3DF7D5E9.61CB268D@umsanet.edu.bo>
Message-ID: <Pine.A41.4.44.0212121114330.45386-100000@homer10.u.washington.edu>

On Wed, 11 Dec 2002, kjetil halvorsen wrote:

> Hola!
>
> Thomas Lumley wrote:
> >
> > On Wed, 11 Dec 2002, Michael Friendly wrote:
> >
> > > I'm trying to form contingincy tables among a set of character variables
> > > which were read from a .csv file and
> > > have missing represented as "".  I want to exclude the missing levels
> > > from the table.
> >
> > I think this is a bug. The exclude= argument doesn't work for factors,
> > because the argument is passed to factor(), and its exclude argument has
> > a different format when the main argument is a factor.
>
> I dot think that is correct. table doesnt call factor on factors, so the
> exclude argument doesnt get used at all. I had the oposite problem as
> the original poster.

Yes, you're right.

> To include NA's as a level in a table. Why should't table simply call
> factor also on factor arguments, so the exclude argument to table get
> used in this case to. I modifyed table to Table doing this, and it
> works, the only problem being that NA is not labelled in the table.

I think there's another problem: this will exclude empty levels, which we
deliberately don't do (that's probably why we don't call factor()).

The real solution may be slightly more complicated.

	-thomas



From tlumley at u.washington.edu  Thu Dec 12 20:21:04 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu Dec 12 20:21:04 2002
Subject: [R] y axis on hist
In-Reply-To: <x2u1hj1dpg.fsf@biostat.ku.dk>
Message-ID: <Pine.A41.4.44.0212121119270.45386-100000@homer10.u.washington.edu>

On 12 Dec 2002, Peter Dalgaard BSA wrote:

> Bud Gibson <fpgibson at umich.edu> writes:
>
> > Have you considered writing an intro or
> > intermediate programming R that would provide almost some cookbook
> > examples, much as O'Reilly has done with its Perl or Java series?
>
> Interesting idea, but I'm not sure I'm the one to write it. (For the
> uninitiated, the Perl Cookbook is an 800 pp. with 20 chapters, each
> containing an introduction plus 15-20 "recipes" in a strict
>
>  Problem
>  Solution
>  Discussion
>  See Also
>
> layout.)
>

This sort of thing is exactly what Sweave and the Vignette mechanism are
good for.

	-thomas



From rdiaz at cnio.es  Thu Dec 12 20:23:08 2002
From: rdiaz at cnio.es (Ramon Diaz)
Date: Thu Dec 12 20:23:08 2002
Subject: [R] Anova
In-Reply-To: <1039718747.3df8d95bbcacd@webmail.sapo.pt>
References: <1039718747.3df8d95bbcacd@webmail.sapo.pt>
Message-ID: <200212122015.36795.rdiaz@cnio.es>

Dear Luis,

You might want to take a look at the multtest and genefilter packages (which 
are part of Bioconductor ---www.bioconductor.org---; links to it also from 
R's web page).

Note, however, that no explicit loop would be necessary anyway, since you can 
use, say, 

apply(my.data, 1, my.anova.function)

asuming your data are in a data frame "my.data", where genes are in rows, and 
your "my.anova.function" returns whichever component from an aov or 
summary(aov) you are interested in.

Hope this helps.

Ram?n


On Thursday 12 December 2002 19:45, Luis Silva wrote:
> Hi,
>
> I have a microarray matrix 3000x70 for example (genes x
> experiments). This data has more than 2 classes. I would like
> to make some filtering on the genes. For example, I would like
> to exclude genes with the same mean expression across all
> classes. This is a problem of ANOVA
>
> H0:mu1=mu2=...=muk
> H1: at least one is different
>
> First question: Do you think Anova is reasonable for this?
> Second question. How can I do this with R?
> Clearly, I'll have to make some loop to apply this operation to
> all the genes.
>
> Thanks
>
> Luis

-- 
Ram?n D?az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
http://bioinfo.cnio.es/~rdiaz



From Ted.Harding at nessie.mcc.ac.uk  Thu Dec 12 20:29:02 2002
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu Dec 12 20:29:02 2002
Subject: [R] data.entry segfault
Message-ID: <XFMail.021212171419.Ted.Harding@nessie.mcc.ac.uk>

Hi Folks,

With R Version 1.3.0  (2001-06-2) on SuSE-7.2 Linux,
starting from scratch, first:

> X<-rep(0,1200);X<-matrix(X,ncol=4)
> data.entry(X)

Up comes the "spreadsheet" window, filled with 0s in
a 300x4 array, and the "cursor" in the (1,1) cell.

Then I type a "1" to enter it into the cell.

Then: Segmentation fault

Is this a known problem with R-1.3.0 with/without SuSE?

With thanks,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 12-Dec-02                                       Time: 17:14:19
------------------------------ XFMail ------------------------------



From tlumley at u.washington.edu  Thu Dec 12 20:32:03 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu Dec 12 20:32:03 2002
Subject: [R] equation on the object
In-Reply-To: <200212121545.31249.chrysopa@insecta.ufv.br>
Message-ID: <Pine.A41.4.44.0212121124520.45386-100000@homer10.u.washington.edu>

On Thu, 12 Dec 2002, Ronaldo Reis Jr. wrote:

> Hi,
>
> I try to put an equation on a object to use in curve for example,
> but it don't work, it possible to make a object of an equation?
>
> ex.
>
> fx <- a + b*x
> for(a in 0){for(b in 1){curve(fx,...)}}
>

It's tricky because curve allows both expressions and functions as
arguments.

Your example couldn't work because
   fx <- a + b*x
sets fx to a number (or vector), the number a+b*x.  You would want
   fx <- expression(a+b*x)
or
   fx <- quote(a+b*x)
to store the expression "a+b*x"

Now, could reasonably be expected to work, but doesn't.  It doesn't
because curve assumes that its argument is a literal expression involving
x or a function. So you need to do either

 for(a in 0){for(b in 1){curve(a+b*x)}}
or
 fx<- function(x) a+b*x
 for(a in 0){for(b in 1){curve(fx)}}


	-thomas



From swisdom at operamail.com  Thu Dec 12 21:33:03 2002
From: swisdom at operamail.com (stephen wisdom)
Date: Thu Dec 12 21:33:03 2002
Subject: [R] Suppressing name-wrangling in a data.frame
Message-ID: <20021212203245.21321.qmail@operamail.com>

 
Is there a simple way to avoid name-wrangling in a dataframe?

Math operations on a dataframe cause R to correct the names(), for instance from "1" "2" "3" to "X1" "X2" "X3"

A workaround is to as.matrix() the dataframe, perform the math, then re-data.frame() it, but this seems like the long way home 

Thanks 
Steve Wisdom

> df <- data.frame(matrix(1:15,5),check.names=F)

> df
  1  2  3
1 1  6 11
2 2  7 12
3 3  8 13
4 4  9 14
5 5 10 15

> df+0
  X1 X2 X3
1  1  6 11
2  2  7 12
3  3  8 13
4  4  9 14
5  5 10 15

> data.frame(as.matrix(df)+0,check.names=F)
  1  2  3
1 1  6 11
2 2  7 12
3 3  8 13
4 4  9 14
5 5 10 15
 
> names(df)
[1] "1" "2" "3"

> names(df+0)
[1] "X1" "X2" "X3"
 

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    6.1            
year     2002           
month    11             
day      01             
language R              




    

-- 
_______________________________________________
Get your free email from http://mymail.operamail.com

Powered by Outblaze



From jasont at indigoindustrial.co.nz  Thu Dec 12 21:37:03 2002
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu Dec 12 21:37:03 2002
Subject: [R] Read FWF, problem and solution?
In-Reply-To: <Springmail.0994.1039713790.0.74765300@webmail.pas.earthlink.net>; from bmagill@earthlink.net on Thu, Dec 12, 2002 at 09:23:10AM -0800
References: <Springmail.0994.1039713790.0.74765300@webmail.pas.earthlink.net>
Message-ID: <20021212203455.A2148@camille.indigoindustrial.co.nz>

On Thu, Dec 12, 2002 at 09:23:10AM -0800,  Brett Magill wrote:
...
> Using read.fwf, I tried to open a fixed-width file that of about 4 MB residing
> in the working directory, using the command below:
> 
>   dat<-read.fwf("sc01aai.dat", widths=fields$length)
> 
> where fields$lengths is a vector of column widths, 28 to be exact.  The data
> are a mix of character, text, and factor variables.
> 
> R started processing and continued doing so for more than an hour and a half
> before I returned and stopped it.  It was obviously still working, CPU,
> memory, and swap space all ablaze.
...

4MB and 28 cols would be a non-trivial number of rows.  Not enourmous,
but non-trivial.  For jobs like this, scan() is my preferred method
(for enormous jobs, I load the data into a proper database server - 
e.g. PostgreSQL, MySQL, Oracle, MS SQL server, etc - and load into
R from there).

So - scan() is your friend.

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz



From tlumley at u.washington.edu  Thu Dec 12 22:39:03 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu Dec 12 22:39:03 2002
Subject: [R] Re: Excluding levels in table and xtabs
In-Reply-To: <3DF8CE91.E0386543@yorku.ca>
Message-ID: <Pine.A41.4.44.0212121333170.45386-100000@homer10.u.washington.edu>

On Thu, 12 Dec 2002, Michael Friendly wrote:

> Having looked over the replies and examined the code, I can't
> see any reason for table (and xtabs) to avoid honoring the
> exclude= argument for factors.  There are often reasons for wanting
> to exclude certain levels, even non-missing in making a table.
>
> In my application, John Fox suggested that I could circumvent
> the problem by reading in the .csv file with na.strings="".
> However, it was only for making tables that I wanted to exclude
> the "" categories.
>
> The change to table() to have it honor the exclude option for
> factors is quite straight-forward.  I wonder if the R team
> will consider placing this on its list.  (revised version below)
>

It doesn't work for me (R1.6.1)

R> a<-factor( rep(c("A","B","C"),10))
R> a
 [1] A B C A B C A B C A B C A B C A B C A B C A B C A B C A B C
Levels: A B C
> mftable(a)
a
 A  B  C
10 10 10
> mftable(a,exclude=c("A",NA))
a
 A  B  C
10 10 10
Warning message:
NAs introduced by coercion


and in addition it loses empty levels

> levels(a)<-LETTERS[1:5]
> table(a)
a
 A  B  C  D  E
10 10 10  0  0
> mftable(a)
a
 A  B  C
10 10 10


I agree that the fix needs to be done, though.



	-thomas



From p.murrell at auckland.ac.nz  Thu Dec 12 22:49:02 2002
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Thu Dec 12 22:49:02 2002
Subject: [R] y axis on hist
References: <3DF89A26.9050908@umich.edu> <x23cp32wco.fsf@biostat.ku.dk>
Message-ID: <3DF905CD.5CB98B00@stat.auckland.ac.nz>

Hi

Note also that box() can take a bty argument (see help(par)) so you
don't have to draw all four sides. For example ...

	hist(rnorm(100000))
	box(bty="l")

Paul


Peter Dalgaard BSA wrote:
> 
> Bud Gibson <fpgibson at umich.edu> writes:
> 
> > Hi:
> >
> > The y axis on the hist function seems to set its limits oddly.
> > sometimes, it covers the full range of the data and sometimes it stops
> > one major tick short.  I have had this behavior with a variety of data
> > sets, and it can easily be reproduced by just running the following
> > several times:
> >
> > hist(rnorm(100000))
> >
> > I have tried explicitly setting ylim to the range of values produced
> > by rnorm (taking care to set some variable to rnorm(100000) and then
> > graphing that), and I still get the y axis plotting behvior I just
> > described.
> 
> I don't think this is stranger than the axes on any other plots. It's
> just that the bounding box isn't printed on histograms. Try adding a
> box() and you'll see what the issue is. To ensure that the last axis
> label is "over the top", it is not enough to diddle the ylim to the
> range of barheights; you'll need to ensure that the ylim is also a
> pretty value, something like this:
> 
> z <- rnorm(100000)
> h <- hist(z,plot=F)
> plot(h,ylim=range(pretty(range(0,h$counts))))
> 
> --
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz



From omorodioneki at netscape.net  Thu Dec 12 23:18:02 2002
From: omorodioneki at netscape.net (MRS EKI OMORODION)
Date: Thu Dec 12 23:18:02 2002
Subject: [R] THANKS & GOD BLESS
Message-ID: <E18Mbdo-0005Jb-00@bernie.ethz.ch>

MRS. EKI OMORODION
# 8 Queens Drive Ikoyi
Lagos.
Email:omorodioneki at netscape.net 
 
INTRODUCTION: l am Mrs. Eki Omorodion l know this 
proposal will come to you as a surprise because we
have not met before 
either physically or through correspondence. I have no
doubt in your 
ability to handle this proposal
involving huge sum of money.  

THE SUBJECT: MY HUSBAND CHIEF JOSEPH OMORODION (Now
Late)
was the Royal 
Head of my Community, JESSE (an oil rich town)in
Nigeria. My late husband'S 
community produces 3.5%  of the total crude oil
production in Nigeria 
and 0.5%  of the Dollar value of each barrel is paid
to my husband as 
royalty by the Federal Government. 

My husband was also the Chairman of  OMPADEC,Jesse
branch.
In 
his position as the Royal head and Chairman of the
OMPADEC, Jesse branch,
he 
made some money which he left for me and our children
as
the only thing to 
inherit. The money is Twelve Million US 
Dollars($12M). 

Though this said fund accumulated  between the
period 
1976-1998. Due to 
poor banking system in Nigeria and political
instability as a result of 
past Military rules (1985-1999), he deposited this
Money in a  Strong 
Room/safe with an open beneficiary in Apex Bank of
Nigeria pending 
when he would finish arrangement to transfer it abroad
as a CONTRACT 
PAYMENT. He  was planning this when he died late last
year of Heart 
Attack. 
 
THE PROPOSAL: Just before my husband died he called my
attention to the 
money and charged me to look for a foreigner who would
assist me in the 
transfer / investment of the funds abroad. So l would
be very grateful 
if you could accept to help me archieve this great
objective. 

I promise to give you 20% of the total funds
transferred to your vital 
bank account as compensation for your assistance. Five
percent 
(5%)would be set aside to take care of all expenses we
may incure during the 
transaction. To indicate your interest, contact me
urgently and 
confidentially for more information and the roles you
will play in this 
business. All the legal information concerning  this
Money will be sent to you 
as soon as we agree together. 

Send your reply through this mail box, or see the note
below 

Yours faithfully, 
MRS. Eki Omorodion.

N.B
I will like you to provide me immediately with your
full names, 
telephone and fax numbers to enable my eldest son
samson Omorodion to contact you.
He shall handle this transaction from A-Z on behalf of
the family.
Alternatively you can call him on his telephone
numbers 
234-1-7761459, 873-762-533-730, fax 873-762-533-731
Ask him for the
code and he shall respond GOODLUCK before discussion.
Just to be sure that you are speaking to him.  

From r.hankin at auckland.ac.nz  Thu Dec 12 23:30:03 2002
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Thu Dec 12 23:30:03 2002
Subject: [R] width and length arguments to postscript()
Message-ID: <200212122221.gBCMLCc20204@r.hankin.sges.auckland.ac.nz>

Hi everyone

This must be a FAQ but I can't find it anywhere...

I want a postscript image of a contour() plot, with axes of equal
length. Try

R> postscript(file="~/f.ps")
R> contour(matrix(rnorm(100),10,10))
R> dev.off()

This isn't what I want: the plotting region is, as documented, quarter
of an inch shy of the paper edge and the axes appear to be different
lengths.  contour() doesn't take a "asp" argument.

postscript() does have a width and a length argument but I can't make
them work as I want:

R> postscript(file="~/f.ps",width=5,height=5)
R> contour(matrix(rnorm(100),10,10))
R> dev.off()

gives axes of about 96mm by 80mm (on A4 paper).

What do I have to do to get square contour plots on a postscript file?

-- 

Robin K. S. Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042

as of: Fri Dec 13 11:07:00 NZDT 2002
This (linux) system up continuously for:  470 days, 16 hours, 49 minutes



From tsvetan.stoyanov at mirant.com  Thu Dec 12 23:47:03 2002
From: tsvetan.stoyanov at mirant.com (Stoyanov, Tsvetan)
Date: Thu Dec 12 23:47:03 2002
Subject: [R] sum a list of vectors
Message-ID: <BA5106B991DBAE49AEB14CB58EDFA7AA01188DE4@atlexm04>

In Mathematica there is a neat feature, where you can change the head of a list from "list" to say "+" and obtain a sum of the list elements. 
I can't find a way to sum a list of vectors of same length or list of matrices of the same dimension and was curious if something like that exists in R.  do.call("+",list) doesn't work because "+" accepts only two arguments, I can obviously use loops but this is quite slow and inelegant.

Thanks,
Tsvetan



From p.murrell at auckland.ac.nz  Thu Dec 12 23:53:03 2002
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Thu Dec 12 23:53:03 2002
Subject: [R] width and length arguments to postscript()
References: <200212122221.gBCMLCc20204@r.hankin.sges.auckland.ac.nz>
Message-ID: <3DF914F0.CB048DB1@stat.auckland.ac.nz>

Hi

Does par(pty="s") do the trick?

(setting the width and height of the device typically won't make the
plot square because the margins around the plot are typically not equal)

Paul



Robin Hankin wrote:
> 
> Hi everyone
> 
> This must be a FAQ but I can't find it anywhere...
> 
> I want a postscript image of a contour() plot, with axes of equal
> length. Try
> 
> R> postscript(file="~/f.ps")
> R> contour(matrix(rnorm(100),10,10))
> R> dev.off()
> 
> This isn't what I want: the plotting region is, as documented, quarter
> of an inch shy of the paper edge and the axes appear to be different
> lengths.  contour() doesn't take a "asp" argument.
> 
> postscript() does have a width and a length argument but I can't make
> them work as I want:
> 
> R> postscript(file="~/f.ps",width=5,height=5)
> R> contour(matrix(rnorm(100),10,10))
> R> dev.off()
> 
> gives axes of about 96mm by 80mm (on A4 paper).
> 
> What do I have to do to get square contour plots on a postscript file?
> 
> --
> 
> Robin K. S. Hankin, Lecturer,
> School of Geography and Environmental Science
> Tamaki Campus
> Private Bag 92019 Auckland
> New Zealand
> 
> r.hankin at auckland.ac.nz
> tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042
> 
> as of: Fri Dec 13 11:07:00 NZDT 2002
> This (linux) system up continuously for:  470 days, 16 hours, 49 minutes
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz



From sundar.dorai-raj at pdf.com  Fri Dec 13 00:02:03 2002
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Fri Dec 13 00:02:03 2002
Subject: [R] sum a list of vectors
References: <BA5106B991DBAE49AEB14CB58EDFA7AA01188DE4@atlexm04>
Message-ID: <3DF9151B.40D39A89@pdf.com>

Hi Tsvetan,

"Stoyanov, Tsvetan" wrote:
> 
> In Mathematica there is a neat feature, where you can change the head of a list from "list" to say "+" and obtain a sum of the list elements.
> I can't find a way to sum a list of vectors of same length or list of matrices of the same dimension and was curious if something like that exists in R.  do.call("+",list) doesn't work because "+" accepts only two arguments, I can obviously use loops but this is quite slow and inelegant.
> 

If you are sure all the elements have equal dimension, you can try the
following:

> x=list(a=1:10,b=11:20,c=21:30)
> x
$a
 [1]  1  2  3  4  5  6  7  8  9 10

$b
 [1] 11 12 13 14 15 16 17 18 19 20

$c
 [1] 21 22 23 24 25 26 27 28 29 30

> rowSums(as.data.frame(x))
 1  2  3  4  5  6  7  8  9 10 
33 36 39 42 45 48 51 54 57 60 
> y=list(a=matrix(1:10,2,5),
+        b=matrix(11:20,2,5),
+        c=matrix(21:30,2,5))
> y
$a
     [,1] [,2] [,3] [,4] [,5]
[1,]    1    3    5    7    9
[2,]    2    4    6    8   10

$b
     [,1] [,2] [,3] [,4] [,5]
[1,]   11   13   15   17   19
[2,]   12   14   16   18   20

$c
     [,1] [,2] [,3] [,4] [,5]
[1,]   21   23   25   27   29
[2,]   22   24   26   28   30

> matrix(rowSums(as.data.frame(x)),nrow(y[[1]]),ncol(y[[2]]))
     [,1] [,2] [,3] [,4] [,5]
[1,]   33   39   45   51   57
[2,]   36   42   48   54   60
> 

Perhaps there's a better way?

Sundar

-- 
Sundar Dorai-Raj
PDF Solutions, Inc.
Dallas TX



From p.dalgaard at biostat.ku.dk  Fri Dec 13 00:12:03 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Dec 13 00:12:03 2002
Subject: [R] sum a list of vectors
In-Reply-To: <BA5106B991DBAE49AEB14CB58EDFA7AA01188DE4@atlexm04>
References: <BA5106B991DBAE49AEB14CB58EDFA7AA01188DE4@atlexm04>
Message-ID: <x2d6o64yti.fsf@biostat.ku.dk>

"Stoyanov, Tsvetan" <tsvetan.stoyanov at mirant.com> writes:

> In Mathematica there is a neat feature, where you can change the
> head of a list from "list" to say "+" and obtain a sum of the list
> elements. I can't find a way to sum a list of vectors of same length
> or list of matrices of the same dimension and was curious if
> something like that exists in R. do.call("+",list) doesn't work
> because "+" accepts only two arguments, I can obviously use loops
> but this is quite slow and inelegant.

 psum <- function(...)apply(cbind(...),1,sum)
 psum(1:3,4:6,1:9)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Bill.Venables at CMIS.CSIRO.AU  Fri Dec 13 00:40:04 2002
From: Bill.Venables at CMIS.CSIRO.AU (Bill.Venables@CMIS.CSIRO.AU)
Date: Fri Dec 13 00:40:04 2002
Subject: [R] sum a list of vectors
Message-ID: <E09E527B56BE2D438A3D6A246DDD27A9165726@roper-cv.qld.cmis.CSIRO.AU>

Tsvetan Sotyanov asks:

>  -----Original Message-----
> From: 	Stoyanov, Tsvetan [mailto:tsvetan.stoyanov at mirant.com] 
> Sent:	Friday, December 13, 2002 8:46 AM
> To:	'r-help at stat.math.ethz.ch'
> Subject:	[R] sum a list of vectors
> 
> In Mathematica there is a neat feature, where you can change the head of a
> list from "list" to say "+" and obtain a sum of the list elements. 
> I can't find a way to sum a list of vectors of same length or list of
> matrices of the same dimension and was curious if something like that
> exists in R.  do.call("+",list) doesn't work because "+" accepts only two
> arguments, I can obviously use loops but this is quite slow and inelegant.
	[WNV]  Actually, a loop is not all that bad (contrary to the popular
prejudice), and the inelegance can be overcome simply by having the right
function available.  How about "psum" for "parallel sum", like pmax and
pmin?

	psum <- function(...) {
	        x <- list(...)
	        s <- x[[1]]
	        for(j in seq(along=x)) s <- s+x[[j]]
	        s
	}

	l <- list(a=1:3, b=2:4, c=3:5)
	> do.call("psum", l)
	[1]  7 11 15

	As a homework exercise you could fix psum so that it works with a
null list of arguments.  Use the "most elegant" way you can think of...

	The solution presented elsewhere using rowSums is probably the best,
though, if you can be sure that you are only dealing with vectors and they
all have the same length.  The advantage of going about it the way outlined
above is that the recycling rule kicks in if you need it, or if you are
dealing with more general arrays the answer has the right shape.

	Bill Venables.

> Thanks,
> Tsvetan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jeremybutler at paradise.net.nz  Fri Dec 13 01:06:03 2002
From: jeremybutler at paradise.net.nz (Jeremy Z Butler)
Date: Fri Dec 13 01:06:03 2002
Subject: [R] A beginner's problems with plotting
Message-ID: <1039737922.3df9244223760@www.paradise.net.nz>

Hi,
How would I go about plotting all 8 columns of a data.frame on a simple line
graph. i.e. eight lines and sets of points, differentiated by line pattern or
colour)?

An what further arguments would I need to invoke a log scale on the y-axis of
that same plot (normal x-axis)?

Cheers, Jeremy



From dunn at usq.edu.au  Fri Dec 13 01:39:03 2002
From: dunn at usq.edu.au (Peter Dunn)
Date: Fri Dec 13 01:39:03 2002
Subject: [R] Loading libraries:  Nas introduced
Message-ID: <4CE94EAEAD60B744B9263A2C82A9C79219EB1D@alpha.usq.edu.au>

Hi all,

I am trying to package a library in R 1.6.1 (Windoze XP).

I have read the document "Writing R extensions" and think I
have done things correctly (though apparently not).  I have
searched the mail archives for help to no avail.

When I try to attach the library using, eg

	> library( libname, lib.loc=path.to.library)

I get this message:

	Warning message: 
	NAs introduced by coercion 

and the library does not work.

Points to note:

* I have no FORTRAN, only R code (getting FORTRAN working is
  the next project...!  Stay tuned!)

* If I simply source the R code, the functions all work with no
  problems.  So at present I am just sourcing the R code that is
  living in the R directory of my library and using it with no 
  problems.  This seems to suggest that the R code is not at fault
  since I am using the same R code that the library would use.

I can't figure out where or why NAs need to be introduced
(by coercion or otherwise!).  What is the reason, where is
it happening and why, and what is the solution?

Any help much appreciated.

Thanks as always.

P.

Dr Peter Dunn          (USQ CRICOS No. 00244B)
  Web:    http://www.sci.usq.edu.au/staff/dunn
  Email:  dunn @ usq.edu.au
<Insert favourite worthless disclaimer here>



From p.dalgaard at biostat.ku.dk  Fri Dec 13 02:01:03 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Dec 13 02:01:03 2002
Subject: [R] Loading libraries:  Nas introduced
In-Reply-To: <4CE94EAEAD60B744B9263A2C82A9C79219EB1D@alpha.usq.edu.au>
References: <4CE94EAEAD60B744B9263A2C82A9C79219EB1D@alpha.usq.edu.au>
Message-ID: <x28yyu4tru.fsf@biostat.ku.dk>

"Peter Dunn" <dunn at usq.edu.au> writes:

> Hi all,
> 
> I am trying to package a library in R 1.6.1 (Windoze XP).
> 
> I have read the document "Writing R extensions" and think I
> have done things correctly (though apparently not).  I have
> searched the mail archives for help to no avail.
> 
> When I try to attach the library using, eg
> 
> 	> library( libname, lib.loc=path.to.library)
> 
> I get this message:
> 
> 	Warning message: 
> 	NAs introduced by coercion 
> 
> and the library does not work.
> 
> Points to note:
> 
> * I have no FORTRAN, only R code (getting FORTRAN working is
>   the next project...!  Stay tuned!)
> 
> * If I simply source the R code, the functions all work with no
>   problems.  So at present I am just sourcing the R code that is
>   living in the R directory of my library and using it with no 
>   problems.  This seems to suggest that the R code is not at fault
>   since I am using the same R code that the library would use.
> 
> I can't figure out where or why NAs need to be introduced
> (by coercion or otherwise!).  What is the reason, where is
> it happening and why, and what is the solution?

Hmm... that Warning message could come from lots of things --
as.numeric(c(1,2,"a")) is prototypical. 

First, did you install the package properly? Rcmd INSTALL, etc.

I see three places where things could go wrong:

1.  in the library() function itself
2.  while sourcing /path/to/yourlibrary/yourpackage/R/yourpackage
3.  during .First.lib processing

if /path/to/yourlibrary/yourpackage/R/yourpackage has nothing but
function definitions, something is structurally wrong. I think I'd try
sticking in a few test printouts between the functions in that file
and try to home in on the trouble spot that way.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Alexander.Herr at csiro.au  Fri Dec 13 05:26:03 2002
From: Alexander.Herr at csiro.au (Alexander.Herr@csiro.au)
Date: Fri Dec 13 05:26:03 2002
Subject: [R] lattice barchart sorting and coloring
Message-ID: <2FE6D3D02CCDD211B80600902745F56C018D11F0@exchange-tv.tvl.qld.csiro.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021213/7d044186/attachment.pl

From deepayan at stat.wisc.edu  Fri Dec 13 06:15:05 2002
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri Dec 13 06:15:05 2002
Subject: [R] lattice barchart sorting and coloring
In-Reply-To: <2FE6D3D02CCDD211B80600902745F56C018D11F0@exchange-tv.tvl.qld.csiro.au>
References: <2FE6D3D02CCDD211B80600902745F56C018D11F0@exchange-tv.tvl.qld.csiro.au>
Message-ID: <200212122315.03485.deepayan@stat.wisc.edu>

On Thursday 12 December 2002 10:25 pm, Alexander.Herr at csiro.au wrote:
> Hi List,
>
> I am trying to produce a lattice barchart with text as labels. My data is
> ordered, but the chart sorts x labels alphabetically.

What do you mean by your data is 'ordered' ? I am guessing your x variable is 
just character strings. character variables are converted into factors before 
being plotted, and the order in which they are plotted is determined by the 
order in which they appear in the levels of that factor. By default, factor 
levels are assigned in alphabetical order, which is what you are seeing in 
barchart. For example,

> y <- c("jan", "feb", "mar")[sample(1:3, 10, rep = T)]
> y
 [1] "jan" "mar" "mar" "feb" "mar" "feb" "mar" "feb" "jan" "mar"


> factor(y) # default : alphabetical order
 [1] jan mar mar feb mar feb mar feb jan mar
Levels: feb jan mar


> factor(y, levels = unique(y))  # explicitly specified levels
 [1] jan mar mar feb mar feb mar feb jan mar
Levels: jan mar feb


> Is there any way of forcing my ordering onto the chart?

Create the factor beforehand with the ordering you want.

> Secondly, I wish to color groups of the bars based on a coded variable. Any
> way of passing these codes onto colors on the chart (panel.superpose does
> changes columns to dots).

Not doable yet, unless you write your own panel function. I have plans to 
implement this, but probably not before next year/month.

Deepayan



From ripley at stats.ox.ac.uk  Fri Dec 13 07:58:04 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Dec 13 07:58:04 2002
Subject: [R] width and length arguments to postscript()
In-Reply-To: <200212122221.gBCMLCc20204@r.hankin.sges.auckland.ac.nz>
Message-ID: <Pine.LNX.4.31.0212130656130.2314-100000@gannet.stats>

There are lots of examples in MASS of doing this for spatial data.  Use
eqscplot (from MASS) with type="n", then contour(add=T)

On Fri, 13 Dec 2002, Robin Hankin wrote:

> Hi everyone
>
> This must be a FAQ but I can't find it anywhere...
>
> I want a postscript image of a contour() plot, with axes of equal
> length. Try
>
> R> postscript(file="~/f.ps")
> R> contour(matrix(rnorm(100),10,10))
> R> dev.off()
>
> This isn't what I want: the plotting region is, as documented, quarter
> of an inch shy of the paper edge and the axes appear to be different
> lengths.  contour() doesn't take a "asp" argument.
>
> postscript() does have a width and a length argument but I can't make
> them work as I want:
>
> R> postscript(file="~/f.ps",width=5,height=5)
> R> contour(matrix(rnorm(100),10,10))
> R> dev.off()
>
> gives axes of about 96mm by 80mm (on A4 paper).
>
> What do I have to do to get square contour plots on a postscript file?
>
> --
>
> Robin K. S. Hankin, Lecturer,
> School of Geography and Environmental Science
> Tamaki Campus
> Private Bag 92019 Auckland
> New Zealand
>
> r.hankin at auckland.ac.nz
> tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042
>
> as of: Fri Dec 13 11:07:00 NZDT 2002
> This (linux) system up continuously for:  470 days, 16 hours, 49 minutes
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From AlessandroSemeria at cramont.it  Fri Dec 13 09:12:03 2002
From: AlessandroSemeria at cramont.it (AlessandroSemeria@cramont.it)
Date: Fri Dec 13 09:12:03 2002
Subject: [R] filter matrix
Message-ID: <OF5E38059F.74282B96-ONC1256C8E.002D3F89@tomware.it>

Hello dear R-list!
I have an alphanumeric matrix (mymat) like this one:

   (Embedded image moved to file: pic06334.pcx)
with 13000 rows (5 columns), I want to extract from it a submatrix following a citeria:
col(5)<0.01.
I tried with :

> sub.mymat <-  mymat[as.numeric(mymat[,5])<0.01,]    # "as.numeric " because elements are quoted!

but this give a bad result (I filtered mymat with two different spreadsheet obtaining a result
very diffrent from that obtained with previous R-line).
Some suggestion?

Thanks in advance!
A.S.

----------------------------

|------------------------------------+------------------------------------|
|Alessandro Semeria                  |Tel. +39 544 536811                 |
|------------------------------------+------------------------------------|
|Models and Simulation Laboratory    |Fax. +39 544 538663                 |
|------------------------------------+------------------------------------|
|The Environment Research Center -   |                                    |
|Montecatini (Edison Group),    Via  |                                    |
|Ciro Menotti 48,                    |E-mail: asemeria at cramont.it         |
|48023 Marina di Ravenna (RA), Italy |                                    |
|------------------------------------+------------------------------------|


-------------- next part --------------
A non-text attachment was scrubbed...
Name: pic06334.pcx
Type: application/octet-stream
Size: 128 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20021213/d35d9c48/pic06334.obj

From Torsten.Hothorn at rzmail.uni-erlangen.de  Fri Dec 13 09:49:03 2002
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Fri Dec 13 09:49:03 2002
Subject: [R] t-test bootstrap versus permutation question
In-Reply-To: <MABBLJDICACNFOLGIHJOOEMADBAA.philippe.grosjean@ifremer.fr>
Message-ID: <Pine.LNX.4.21.0212130937100.3293-100000@artemis>

> Hi,
> 
> I have a little problem that puzzles me about contradictory results returned
> by a bootstraped t-test (as in MASS 3rd ed p. 146) versus a permutation
> t-test (as in MASS 3rd ed, p 147).
> 
> Data are measurements done on 100 cells in 9 slides of fish blood. With one
> method, cells are randomly sampled, and with the other method, the operator
> selects cells arbitrarily (in a way it is done usually with this test). We
> want to determine wheither the methods yield same results or not. Since we
> are interested by the mean measurement for 100 cells, we take the average
> for each slide and each method. We compare then the nine paired samples
> (that is, for the nine slides) with a paired t-test. However, since we
> cannot make the hypothesis that both distributions are normal, we prefer to
> use a bootstraped test.
> 

that is: you have 9 differences and you hypothesis is "the underlying
distribution is symmetric about zero", i.e. the two methods do not
differ in this sense, right?


> We do:
> (1) 1000 simple bootstraps with:
> boot(B-A, function(x,i), mean(x[i]), R=1000)
> and then:
> boot.ci(...)
> and check wheter the CI includes 0 (no significant difference between
> methods) or not.

so you are computing a bootstrap estimate of the standard error of the
mean for later use in a confidence interval for the mean? But you can
calculate this directly (Section 5.2 in Efron/Tibshirani: Intro to the
Boostrap) and the confidence set per t.test, if I'm not completely
misguided.

> 
> (2) a permutation test with the perm.t.test() function of MASS p. 147
> and calculate a bootstraped p-value corresponding to the fraction of values
                  ^^^^^^^^^^^

I just can't find my MASS3 at the moment, but I suspect perm.t.test
computes the statistic for all possible permutations, so no bootstrap
here.

> larger or equal to the observed one. If this p-value is > 5%, we consider
> there is no significant difference between both methods.
> 
> Is this correct?
> 
> The problem is that, in our particular case, both test give opposite
> results: the bootstrap test indicates significant differences at 5%, while
> the permutation test gives p-value = 0.35-0.45, thus no differences between
> methods. I think I probably miss something here! Does somebody could help
> me?

maybe you should post the 9 measurements ;-) 
For the shoes data, one could do the following, which looks consitent to
me:

R> 
R> library(MASS)
R> library(exactRankTests)
R> data(shoes)
R> attach(shoes)
R> t.test(A,B, paired=TRUE, conf.int=TRUE)

	Paired t-test

data:  A and B 
t = -3.3489, df = 9, p-value = 0.008539
alternative hypothesis: true difference in means is not equal to 0 
95 percent confidence interval:
 -0.6869539 -0.1330461 
sample estimates:
mean of the differences 
                  -0.41 

R> wilcox.exact(A,B, paired=TRUE, conf.int=TRUE)

	Exact Wilcoxon signed rank test

data:  A and B 
V = 3, p-value = 0.007812
alternative hypothesis: true mu is not equal to 0 
95 percent confidence interval:
 -0.7 -0.1 
sample estimates:
(pseudo)median 
          -0.4 

R> wilcox.test(A,B, paired=TRUE, exact=FALSE)

	Wilcoxon signed rank test with continuity correction

data:  A and B 
V = 3, p-value = 0.01431
alternative hypothesis: true mu is not equal to 0 

R> perm.test(A*10,B*10, paired=TRUE) # map into integers

	1-sample Permutation Test

data:  A * 10 and B * 10 
T = 3, p-value = 0.01367
alternative hypothesis: true mu is not equal to 0 


best, 

Torsten

> 
> Best,
> 
> Philippe Grosjean
> 
> ...........]<(({?<...............<?}))><...............................
> ( ( ( ( (
>  ) ) ) ) )      Philippe Grosjean
> ( ( ( ( (
>  ) ) ) ) )      IFREMER Nantes - DEL/AO
> ( ( ( ( (       rue de l'Ile d'Yeu, BP 21105, 44311 Nantes Cedex 3
>  ) ) ) ) )      tel: (33) 02.40.37.42.29, fax: (33) 02.40.37.42.41
> ( ( ( ( (	e-mail: philippe.grosjean at ifremer.fr
>  ) ) ) ) )
> ( ( ( ( (      "I'm 100% confident that p is between 0 and 1"
>  ) ) ) ) )                                L. Gonick & W. Smith (1993)
> .......................................................................
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From nac at nac.spb.ru  Fri Dec 13 10:08:06 2002
From: nac at nac.spb.ru (=?koi8-r?B?7sXawdfJ08nN2cog4c7BzMnUyd7F08vJyiDjxc7U0g==?=)
Date: Fri Dec 13 10:08:06 2002
Subject: [R] R: help needed. Slow output to metafile
Message-ID: <000d01c2a286$99d47430$6900a8c0@nac.net>

Hi!
I am using R 1.6.0 with ESS on Win2000. My code outputs a lot of graphics to
the win.metafile graphics device
(a .wmf file on disk). When i start my code through 'ESS Evaluation' code
works slowly, but output works fast.
And when i run my code through R Term directly (without ESS), output to
win.metafile device takes a _lot_ of
time (approximately, 1.5-2 minutes per plot).
Please, help, how to solve this problem or what i am doing wrong? Maybe some
'buffers' or something else
what i need to configure?

Thanks!

sorry for my english not very well.



From Morten.Sickel at nrpa.no  Fri Dec 13 11:40:04 2002
From: Morten.Sickel at nrpa.no (Morten Sickel)
Date: Fri Dec 13 11:40:04 2002
Subject: [R] A beginner's problems with plotting
Message-ID: <54DE9A561AD20C4D9FF88B116965420E4E5CB1@postix.nrpa.no>


-----Original Message-----
Jeremy Z Butler wrote:
>Hi,
>How would I go about plotting all 8 columns of a data.frame on a simple
line
>graph. i.e. eight lines and sets of points, differentiated by line pattern
or
>colour)?
>
>An what further arguments would I need to invoke a log scale on the y-axis
of
>that same plot (normal x-axis)?

For example (a snippet from something I have been working on the last couple
of days)

plot(Nucs$Year,Nucs[[2]],type='b',xlim=c(first,last),pch=2,col=2,
ylim=c(min,max),xlab='',ylab='Releases, GBq/year',log=logax)
for (i in c(3:length(Nucs))){
	lines(Nucs$Year,Nucs[[i]],col=i)
	points(Nucs$Year,Nucs[[i]],col=i,pch=i)
}

Nucs is my data frame, Year is the X variable. I am setting up the plot and
plotting the first series with the plot command, Earlier in my script I have
calculated the min,max,first and last values, set them manually if you know
them. If the variable logax is set to 'y' (or maybe also 'Y') then the y
axis is plottet logaritmic.

By the way, you might end up with one of the palette colors being white,
what you probably do not want... if that happens, run a 
palette(c('red','blue','green','yellow','orange','black','brown','violet','p
urple'))
before doing the plot.

(I am by no means an R-expert, somebody might have a better solution, but
this works fine for me.)

Morten

-- 
Morten Sickel
Norwegian Radiation Protection Authority
http://www.nrpa.no



From maechler at stat.math.ethz.ch  Fri Dec 13 12:08:03 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri Dec 13 12:08:03 2002
Subject: [R] A beginner's problems with plotting
In-Reply-To: <1039737922.3df9244223760@www.paradise.net.nz>
References: <1039737922.3df9244223760@www.paradise.net.nz>
Message-ID: <15865.49005.965047.346528@gargle.gargle.HOWL>

>>>>> "Jeremy" == Jeremy Z Butler <jeremybutler at paradise.net.nz>
>>>>>     on Fri, 13 Dec 2002 13:05:22 +1300 (NZDT) writes:


    Jeremy> How would I go about plotting all 8 columns of a
    Jeremy> data.frame on a simple line graph. i.e. eight lines
    Jeremy> and sets of points, differentiated by line pattern
    Jeremy> or colour)?

help(matplot) and its examples;
also as you might want a legend anyway 
help(legend) and its examples

{and there is a "lattice" way to do this...}

    Jeremy> An what further arguments would I need to invoke a
    Jeremy> log scale on the y-axis of that same plot (normal
    Jeremy> x-axis)?

matplot(........., log = "y")

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/



From ahenningsen at email.uni-kiel.de  Fri Dec 13 12:42:03 2002
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Fri Dec 13 12:42:03 2002
Subject: [R] data.entry segfault
In-Reply-To: <20021213110010.10915.30921.Mailman@hypatia.math.ethz.ch>
References: <20021213110010.10915.30921.Mailman@hypatia.math.ethz.ch>
Message-ID: <200212131239.06346.ahenningsen@email.uni-kiel.de>

Hi,
there is a similar problem with R Version 1.6.1 on SuSE-Linux 8.0:
R crashes and I get "Speicherzugriffsfehler" (=~ Memory Access Error) from the 
console. I think R tries to write something to somewhere where it has no 
write access. I hope that this could help others to find a solution.
Arne. 

On Thu, 12 Dec 2002 17:14:19,  Ted.Harding at nessie.mcc.ac.uk wrote:
> Hi Folks,
>
> With R Version 1.3.0  (2001-06-2) on SuSE-7.2 Linux,
>
> starting from scratch, first:
> > X<-rep(0,1200);X<-matrix(X,ncol=4)
> > data.entry(X)
>
> Up comes the "spreadsheet" window, filled with 0s in
> a 300x4 array, and the "cursor" in the (1,1) cell.
>
> Then I type a "1" to enter it into the cell.
>
> Then: Segmentation fault
>
> Is this a known problem with R-1.3.0 with/without SuSE?
>
> With thanks,
> Ted.
>
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 167 1972
> Date: 12-Dec-02                                       Time: 17:14:19
> ------------------------------ XFMail ------------------------------

-- 
Arne Henningsen
Department of Agricultural Economics
Christian-Albrechts-University Kiel
24098 Kiel, Germany
Tel: +49-431-880-4445
Fax: +49-431-880-1397 
ahenningsen at email.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From alobo at ija.csic.es  Fri Dec 13 15:12:03 2002
From: alobo at ija.csic.es (Agustin Lobo)
Date: Fri Dec 13 15:12:03 2002
Subject: [R] Advice on long for loop
Message-ID: <Pine.OSF.3.96.1021213152038.30089E-100000@paleo.ija.csic.es>

I'd appreciate advice on the following:

I've written an R function
that uses 3 vectors (temperature,
precipitation and potential evapotranspiration)
for a given site, calculates a water budget
(which implies few (<4) iterations), and, from
thresults of this water budget, calculates a number of
bioclimatic indices.

Now I want to calculate these indices
for a large number of sites (arranged
as cells in a raster map),  using
monthly raster maps (m rows x n cols)  of temperature,
precipitation and potential evapotranspiration.

I do not see any other way than using
two nested for loops and calling the
aforementioned function for each cell in the
map. But this would be a problem in R
as m and n can be ~ 500.

My question is: would it be any better if
I write a simple python function with the loops
and call the R function for each cell (using
the R-Python interface)? Or, as the calculation
in each cell is independent, should I rather write a
shell script with the loop and submit jobs
with R CMD BATCH?

Thanks

Agus

Dr. Agustin Lobo
Instituto de Ciencias de la Tierra (CSIC)
Lluis Sole Sabaris s/n
08028 Barcelona SPAIN
tel 34 93409 5410
fax 34 93411 0012
alobo at ija.csic.es



From p.dalgaard at biostat.ku.dk  Fri Dec 13 15:34:02 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Dec 13 15:34:02 2002
Subject: [R] data.entry segfault
In-Reply-To: <200212131239.06346.ahenningsen@email.uni-kiel.de>
References: <20021213110010.10915.30921.Mailman@hypatia.math.ethz.ch>
	<200212131239.06346.ahenningsen@email.uni-kiel.de>
Message-ID: <x2fzt2c7k6.fsf@biostat.ku.dk>

Arne Henningsen <ahenningsen at email.uni-kiel.de> writes:

> Hi,
> there is a similar problem with R Version 1.6.1 on SuSE-Linux 8.0:
> R crashes and I get "Speicherzugriffsfehler" (=~ Memory Access Error) from the 
> console. I think R tries to write something to somewhere where it has no 
> write access. I hope that this could help others to find a solution.
> Arne. 
> 
> On Thu, 12 Dec 2002 17:14:19,  Ted.Harding at nessie.mcc.ac.uk wrote:
> > Hi Folks,
> >
> > With R Version 1.3.0  (2001-06-2) on SuSE-7.2 Linux,
> >
> > starting from scratch, first:
> > > X<-rep(0,1200);X<-matrix(X,ncol=4)
> > > data.entry(X)
> >
> > Up comes the "spreadsheet" window, filled with 0s in
> > a 300x4 array, and the "cursor" in the (1,1) cell.
> >
> > Then I type a "1" to enter it into the cell.
> >
> > Then: Segmentation fault
> >
> > Is this a known problem with R-1.3.0 with/without SuSE?
> >
> > With thanks,
> > Ted.

I get this (with 1.6.0 installed from the CRAN RPM) SuSE too, but *not* on
RedHat. More detailed symptoms are 

Breakpoint 2, doSpreadKey (key=0, event=0xbfffe0e4) at dataentry.c:1172
1172    in dataentry.c
(gdb) s
GetKey (event=0xbfffe0e4) at dataentry.c:1248
1248    in dataentry.c
(gdb)
1249    in dataentry.c
(gdb)
1250    in dataentry.c
(gdb)
doSpreadKey (key=68, event=0x12) at dataentry.c:1173
1173    in dataentry.c
(gdb)
GetCharP (event=0x12) at dataentry.c:1257
1257    in dataentry.c
(gdb)

Program received signal SIGSEGV, Segmentation fault.
0x40290087 in XLookupString () from /usr/X11R6/lib/libX11.so.6
(gdb) bt
#0  0x40290087 in XLookupString () from /usr/X11R6/lib/libX11.so.6
#1  0x4021475b in GetCharP (event=0x12) at dataentry.c:1257
#2  0x402143b3 in doSpreadKey (key=68, event=0x12) at dataentry.c:1173
(gdb)

so it would seem like something in the GetKey call is destroying the
stack. 

It is reproducible with a hand-compiled version and things boil down
to

1243    static KeySym GetKey(DEEvent * event)
1244    {
1245        char text[1];
1246        KeySym iokey;
1247
1248        XLookupString(event, text, 10, &iokey, 0);
1249        return iokey;
1250    }

And the XLookupString call is the culprit. "10" is the buffer length,
but "text" is declared to have length 1, and in practice has at least 2
bytes since "text" is \0-terminated...

Switching to "char text[10];" looks like a likely fix.

        -p


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ltorgo at liacc.up.pt  Fri Dec 13 15:38:03 2002
From: ltorgo at liacc.up.pt (Luis Torgo)
Date: Fri Dec 13 15:38:03 2002
Subject: [R] Problem with lattice bwplot
Message-ID: <200212131457.07423.ltorgo@liacc.up.pt>

I've come across the following error when using free scales with bwplot (I use 
a small example data set just to illustrate the problem):

> d <- data.frame(
x=c(34.4, 12.4, NA, 65.3, NA, 12.0, 45.0, 645.0, 644.0,323.0),
fac1=c('a','a','b','a','b','a','a','c','c','c'),
fac2=c('v2','v2','v1','v2','v2','v2','v1','v2','v1','v2')
)

# ok, although "x" has only NA values for fac1=='b'
> bwplot(fac2 ~ x | fac1,data=d)

# not ok, if I try to use different scales in the X axis
> bwplot(fac2 ~ x | fac1,data=d,scales=list(x="free"))
Error in pretty(x[is.finite(x)], ...) : x must be numeric

# I can go around the error with
> bwplot(fac2 ~ x | fac1,data=d[!is.na(d$x),],scales=list(x="free"))

The problem is that one of the panels has no data because 'x' has only NA 
values for that particular factor combination. This causes no problem with 
uniform scales, but generates that error when trying to guess the best scale 
for each panel. I think that it should be easy to add some test to the code 
obtaining the scales for each panel, to avoid the always unpleasant 
criptographic error messages ;-)

Thanks,
Luis Torgo

-- 
Luis Torgo
    FEP/LIACC, University of Porto   Phone : (+351) 22 607 88 30
    Machine Learning Group           Fax   : (+351) 22 600 36 54
    R. Campo Alegre, 823             email : ltorgo at liacc.up.pt
    4150 PORTO   -  PORTUGAL         WWW   : http://www.liacc.up.pt/~ltorgo



From jzhang at jimmy.harvard.edu  Fri Dec 13 15:42:07 2002
From: jzhang at jimmy.harvard.edu (John Zhang)
Date: Fri Dec 13 15:42:07 2002
Subject: [R] Advice on long for loop
Message-ID: <200212131439.JAA11263@blaise.dfci.harvard.edu>

I think something like the following will let you do the thing you want in R:

> vec1 <- 1:10
> vec2 <- 2:11
> vec3 <- 3:12
> fun <- function(x){
+ vec1[x] * vec2[x] * vec3[x] #whatever
+ }
> tt <- lapply(1:10, fun)
>


>From: Agustin Lobo <alobo at ija.csic.es>
>To: r-help <r-help at stat.math.ethz.ch>
>MIME-Version: 1.0
>X-Virus-Scanned: by amavisd-milter (http://amavis.org/)
>X-Virus-Scanned: by amavisd-milter (http://amavis.org/)
>X-Spam-Status: No, hits=-0.1 required=5.0 
tests=SPAM_PHRASE_00_01,TO_LOCALPART_EQ_REAL,USER_AGENT_PINE version=2.43
>X-Spam-Level: 
>Subject: [R] Advice on long for loop
>X-BeenThere: r-help at stat.math.ethz.ch
>X-Mailman-Version: 2.0.13
>List-Help: <mailto:r-help-request at stat.math.ethz.ch?subject=help>
>List-Post: <mailto:r-help at stat.math.ethz.ch>
>List-Subscribe: <http://www.stat.math.ethz.ch/mailman/listinfo/r-help>, 
<mailto:r-help-request at stat.math.ethz.ch?subject=subscribe>
>List-Id: Main R Mailing List: Primary help <r-help.stat.math.ethz.ch>
>List-Unsubscribe: <http://www.stat.math.ethz.ch/mailman/listinfo/r-help>, 
<mailto:r-help-request at stat.math.ethz.ch?subject=unsubscribe>
>List-Archive: <http://www.stat.math.ethz.ch/pipermail/r-help/>
>X-Original-Date: Fri, 13 Dec 2002 15:22:22 +0100 (MET)
>Date: Fri, 13 Dec 2002 15:22:22 +0100 (MET)
>
>
>I'd appreciate advice on the following:
>
>I've written an R function
>that uses 3 vectors (temperature,
>precipitation and potential evapotranspiration)
>for a given site, calculates a water budget
>(which implies few (<4) iterations), and, from
>thresults of this water budget, calculates a number of
>bioclimatic indices.
>
>Now I want to calculate these indices
>for a large number of sites (arranged
>as cells in a raster map),  using
>monthly raster maps (m rows x n cols)  of temperature,
>precipitation and potential evapotranspiration.
>
>I do not see any other way than using
>two nested for loops and calling the
>aforementioned function for each cell in the
>map. But this would be a problem in R
>as m and n can be ~ 500.
>
>My question is: would it be any better if
>I write a simple python function with the loops
>and call the R function for each cell (using
>the R-Python interface)? Or, as the calculation
>in each cell is independent, should I rather write a
>shell script with the loop and submit jobs
>with R CMD BATCH?
>
>Thanks
>
>Agus
>
>Dr. Agustin Lobo
>Instituto de Ciencias de la Tierra (CSIC)
>Lluis Sole Sabaris s/n
>08028 Barcelona SPAIN
>tel 34 93409 5410
>fax 34 93411 0012
>alobo at ija.csic.es
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From p.dalgaard at biostat.ku.dk  Fri Dec 13 15:53:02 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri Dec 13 15:53:02 2002
Subject: [R] data.entry segfault
In-Reply-To: <x2fzt2c7k6.fsf@biostat.ku.dk>
References: <20021213110010.10915.30921.Mailman@hypatia.math.ethz.ch>
	<200212131239.06346.ahenningsen@email.uni-kiel.de>
	<x2fzt2c7k6.fsf@biostat.ku.dk>
Message-ID: <x2bs3qc6nu.fsf@biostat.ku.dk>

Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:


> 1243    static KeySym GetKey(DEEvent * event)
> 1244    {
> 1245        char text[1];
> 1246        KeySym iokey;
> 1247
> 1248        XLookupString(event, text, 10, &iokey, 0);
> 1249        return iokey;
> 1250    }
> 
> And the XLookupString call is the culprit. "10" is the buffer length,
> but "text" is declared to have length 1, and in practice has at least 2
> bytes since "text" is \0-terminated...
> 
> Switching to "char text[10];" looks like a likely fix.

Actually, replacing 10 with 1 also works.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tsvetan.stoyanov at mirant.com  Fri Dec 13 17:13:03 2002
From: tsvetan.stoyanov at mirant.com (Stoyanov, Tsvetan)
Date: Fri Dec 13 17:13:03 2002
Subject: [R] sum a list of vectors
Message-ID: <BA5106B991DBAE49AEB14CB58EDFA7AA01188DE6@atlexm04>

Thanks for the response.  Still, my point is that there isn't a straightforward way to do an operation which should be bread and butter for a language, that prides itself in its connection to Lisp.

Tsvetan Stoyanov

---------------
From: Bill.Venables at CMIS.CSIRO.AU
To: tsvetan.stoyanov at mirant.com, r-help at stat.math.ethz.ch
Subject: RE: [R] sum a list of vectors
Date: Fri, 13 Dec 2002 09:38:45 +1000

Tsvetan Sotyanov asks:

>  -----Original Message-----
> From: 	Stoyanov, Tsvetan [mailto:tsvetan.stoyanov at mirant.com] 
> Sent:	Friday, December 13, 2002 8:46 AM
> To:	'r-help at stat.math.ethz.ch'
> Subject:	[R] sum a list of vectors
> 
> In Mathematica there is a neat feature, where you can change the head of a
> list from "list" to say "+" and obtain a sum of the list elements. 
> I can't find a way to sum a list of vectors of same length or list of
> matrices of the same dimension and was curious if something like that
> exists in R.  do.call("+",list) doesn't work because "+" accepts only two
> arguments, I can obviously use loops but this is quite slow and inelegant.
	[WNV]  Actually, a loop is not all that bad (contrary to the popular
prejudice), and the inelegance can be overcome simply by having the right
function available.  How about "psum" for "parallel sum", like pmax and
pmin?

	psum <- function(...) {
	        x <- list(...)
	        s <- x[[1]]
	        for(j in seq(along=x)) s <- s+x[[j]]
	        s
	}

	l <- list(a=1:3, b=2:4, c=3:5)
	> do.call("psum", l)
	[1]  7 11 15

	As a homework exercise you could fix psum so that it works with a
null list of arguments.  Use the "most elegant" way you can think of...

	The solution presented elsewhere using rowSums is probably the best,
though, if you can be sure that you are only dealing with vectors and they
all have the same length.  The advantage of going about it the way outlined
above is that the recycling rule kicks in if you need it, or if you are
dealing with more general arrays the answer has the right shape.

	Bill Venables.



From michal at igc.gulbenkian.pt  Fri Dec 13 17:47:03 2002
From: michal at igc.gulbenkian.pt (Michal Or-Guil)
Date: Fri Dec 13 17:47:03 2002
Subject: [R] (no subject)
Message-ID: <Pine.GSO.4.21.0212131631440.1695-100000@pen2.igc.gulbenkian.pt>

Dear R-Help list members,


I started programming in R not very long ago, and I would like to make my
own changes in functions like isoMDS (library MASS), as for example
changing the definition of the stress function. 
Looking at the code of isoMDS, it seems that the function uses precompiled
C code routines. Is there a way to get those routines and include own
changes there, or would I have to write an own, new isoMDS-function?


Thanks a lot for your help!

Michal Or-Guil

ITB, Humboldt-University, Berlin



From ripley at stats.ox.ac.uk  Fri Dec 13 17:58:02 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Dec 13 17:58:02 2002
Subject: [R] (no subject)
In-Reply-To: <Pine.GSO.4.21.0212131631440.1695-100000@pen2.igc.gulbenkian.pt>
Message-ID: <Pine.LNX.4.31.0212131655530.7232-100000@gannet.stats>

On Fri, 13 Dec 2002, Michal Or-Guil wrote:

> I started programming in R not very long ago, and I would like to make my
> own changes in functions like isoMDS (library MASS), as for example
> changing the definition of the stress function.
> Looking at the code of isoMDS, it seems that the function uses precompiled
> C code routines. Is there a way to get those routines and include own
> changes there, or would I have to write an own, new isoMDS-function?

The C code is part of the sources on CRAN.  If you have precompiled code
you are probably using Windows or MacOS and omitting to tell us.
If you are using Windows, do read the rw-FAQ about installing packages.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ltorgo at liacc.up.pt  Fri Dec 13 18:07:02 2002
From: ltorgo at liacc.up.pt (Luis Torgo)
Date: Fri Dec 13 18:07:02 2002
Subject: [R] Problem with RMySQL 0.5-0 under RH7.3
Message-ID: <200212131729.17027.ltorgo@liacc.up.pt>

I have upgraded R on my Linux box from 1.5.1 to 1.6.1 using the binary 
distributions for redhat 7.x.
My machine is runing:
Linux  2.4.18-3
Red Hat Linux release 7.3 (Valhalla)

After upgrading R, I executed upgrade.packages()
During the upgrading of the different packages there was an error on RMySQL. 
Here is a dump of the upgrading messages:
===============================================================
* Installing *source* package 'RMySQL' ...
creating cache ./config.cache
checking how to run the C preprocessor... cc -E
checking for mysql_init in -lmysqlclient... no
checking for mysql.h... no
checking for mysql_init in -lmysqlclient... no
checking for mysql_init in -lmysqlclient... yes
checking for /usr/local/include/mysql/mysql.h... no
checking for /usr/include/mysql/mysql.h... yes
updating cache ./config.cache
creating ./config.status
creating src/Makevars
** libs
gcc -I/usr/lib/R/include -I/usr/include/mysql -I/usr/local/include 
-D__NO_MATH_INLINES -mieee-fp  -fPIC  -O2 -m486 -fno-strength-reduce -g -c 
RS-DBI.c -o RS-DBI.o
gcc -I/usr/lib/R/include -I/usr/include/mysql -I/usr/local/include 
-D__NO_MATH_INLINES -mieee-fp  -fPIC  -O2 -m486 -fno-strength-reduce -g -c 
RS-MySQL.c -o RS-MySQL.o
gcc -shared -L/usr/local/lib -o RMySQL.so RS-DBI.o RS-MySQL.o -L/usr/lib/mysql 
-lmysqlclient -lz
** R
** inst
** save image
[1] TRUE
[1] "dbObjectId"
Creating a new generic function for "format" in package
RMySQL
[1] "format"
[1] "show"
Creating a new generic function for "print" in package
RMySQL
[1] "print"
Error in getProperties(ClassDef) : "slots" is not a valid slot for this object 
(or was mistakenly deleted)
Execution halted
/usr/lib/R/bin/INSTALL: line 346: 24149 Broken pipe             cat 
"${lib}/${pkg}/R/${pkg}"
ERROR: execution of package source for 'RMySQL' failed
=====================================================

After this process if I try to use the package I get the following result:

> library(RMySQL)
Error in getProperties(ClassDef) : "slots" is not a valid slot for this object 
(or was mistakenly deleted)

Looking at the result of installed.packages() it seems that R is still using 
my previous RMySQL version (0.4-6). Moreover, I cannot use it to connect to 
my MySQL server anymore:

> channel<- dbConnect(MySQL(),dbname=db,user="xxx",password="yyy")
Error in dbConnect(MySQL(), dbname = db, user = "xxx", password = "yyy") :
        couldn't find function "MySQL"

I check the mailing list for solutions but I did not find anything, although 
I've noticed a similar problem report but for R1.6.0 (although there was no 
answer to this other message that I could try to transpose to my problem).

Any help on solving this problem is welcome.

Thank you,
Luis Torgo

-- 
Luis Torgo
    FEP/LIACC, University of Porto   Phone : (+351) 22 607 88 30
    Machine Learning Group           Fax   : (+351) 22 600 36 54
    R. Campo Alegre, 823             email : ltorgo at liacc.up.pt
    4150 PORTO   -  PORTUGAL         WWW   : http://www.liacc.up.pt/~ltorgo



From rvaradha at jhsph.edu  Fri Dec 13 18:20:03 2002
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Fri Dec 13 18:20:03 2002
Subject: [R] How to get objects from a "formula" specification?
Message-ID: <4fc1d4ee8b.4ee8b4fc1d@jhsph.edu>

Hi:

I'd like to get the objects corresponding to the elements in a formula, 
from a data frame.  For example, suppose I would like to make a 
function call, such as follows:

myfunc(formula="y ~ x1 + x2 + log(x3)" , data=mydata)

This function will get the vector objects y, x1, x2, and log(x3) from 
the data frame "mydata" to form the design matrix and then perform a 
maximum likelihood estimation of the regression parameters.  

My questions is,  how do I get the the vector objects y, x1, x2, and 
log(x3),specified the formula, from the data frame "mydata"?

thanks for any help,
Ravi.



From Ted.Harding at nessie.mcc.ac.uk  Fri Dec 13 18:40:03 2002
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri Dec 13 18:40:03 2002
Subject: [R] data.entry segfault
In-Reply-To: <x2fzt2c7k6.fsf@biostat.ku.dk>
Message-ID: <XFMail.021213172934.Ted.Harding@nessie.mcc.ac.uk>

On 13-Dec-02 Peter Dalgaard BSA wrote:
> I get this (with 1.6.0 installed from the CRAN RPM) SuSE too,
> but *not* on RedHat. More detailed symptoms are [SNIP]...
> 
> It is reproducible with a hand-compiled version and things boil
> down to
> 
> 1243    static KeySym GetKey(DEEvent * event)
> 1244    {
> 1245        char text[1];
> 1246        KeySym iokey;
> 1247
> 1248        XLookupString(event, text, 10, &iokey, 0);
> 1249        return iokey;
> 1250    }
> 
> And the XLookupString call is the culprit. "10" is the buffer length,
> but "text" is declared to have length 1, and in practice has at least 2
> bytes since "text" is \0-terminated...
> 
> Switching to "char text[10];" looks like a likely fix.

Interesting. But why does it give a problem in SuSE (both RPM and
hand-compiled) but not on RedHat? (I too have R also on Red Hat 7.2,
was R-1.2, is now R-1.6.1, and have not had this problem with either
version of R; R-1.4 on SuSE 7.2 however segfaults). Presumably the
same code is compiled on both distributions ... ?

Best wishes,
Ted.




--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 13-Dec-02                                       Time: 17:29:34
------------------------------ XFMail ------------------------------



From ripley at stats.ox.ac.uk  Fri Dec 13 18:45:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Dec 13 18:45:03 2002
Subject: [R] How to get objects from a "formula" specification?
In-Reply-To: <4fc1d4ee8b.4ee8b4fc1d@jhsph.edu>
Message-ID: <Pine.LNX.4.31.0212131742220.8041-100000@gannet.stats>

?model.frame
?model.matrix

`S Programming' by Venables & Ripley (2000).

On Fri, 13 Dec 2002, Ravi Varadhan wrote:

> Hi:
>
> I'd like to get the objects corresponding to the elements in a formula,
> from a data frame.  For example, suppose I would like to make a
> function call, such as follows:
>
> myfunc(formula="y ~ x1 + x2 + log(x3)" , data=mydata)
>
> This function will get the vector objects y, x1, x2, and log(x3) from
> the data frame "mydata" to form the design matrix and then perform a
> maximum likelihood estimation of the regression parameters.
>
> My questions is,  how do I get the the vector objects y, x1, x2, and
> log(x3),specified the formula, from the data frame "mydata"?

BTW, that's not precisely how formulae in R work.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From scottyv at bell-labs.com  Fri Dec 13 19:45:03 2002
From: scottyv at bell-labs.com (scottyv@bell-labs.com)
Date: Fri Dec 13 19:45:03 2002
Subject: [R] histogram bug?: type='count', unequal breaks
Message-ID: <200212131843.gBDIhl7q004388@jessie.research.bell-labs.com>

I ask for a histogram of counts with slightly uneven breaks but
histogram() ignores the 'type' argument and provides density scaling
instead.

   x = sample(1:3, 100, replace=TRUE)
   histogram( ~ x, breaks=c(0,1.5,2.5,3.5), type='count')

My real application has time data with month boundaries for the breaks
and I DO want counts on the y-axis.

A work-around is not difficult but shouldn't histogram honor the
type argument when given?

 Scott Vander Wiel
 Statistics and Data Mining Research
 Bell Laboratories, Lucent Technologies



From rvaradha at jhsph.edu  Fri Dec 13 19:50:26 2002
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Fri Dec 13 19:50:26 2002
Subject: [R] How to get objects from a "formula" specification?
Message-ID: <6c7076c76c.6c76c6c707@jhsph.edu>

I'd like to thank Prof. Ripley and Andy Liaw for their solution to my 
question. They suggested using "model.frame" or "model.matrix"

Best,
Ravi.
----- Original Message -----
From: ripley at stats.ox.ac.uk
Date: Friday, December 13, 2002 12:44 pm
Subject: Re: [R] How to get objects from a "formula" specification?

> ?model.frame
> ?model.matrix
> 
> `S Programming' by Venables & Ripley (2000).
> 
> On Fri, 13 Dec 2002, Ravi Varadhan wrote:
> 
> > Hi:
> >
> > I'd like to get the objects corresponding to the elements in a 
> formula,> from a data frame.  For example, suppose I would like to 
> make a
> > function call, such as follows:
> >
> > myfunc(formula="y ~ x1 + x2 + log(x3)" , data=mydata)
> >
> > This function will get the vector objects y, x1, x2, and log(x3) 
> from> the data frame "mydata" to form the design matrix and then 
> perform a
> > maximum likelihood estimation of the regression parameters.
> >
> > My questions is,  how do I get the the vector objects y, x1, x2, and
> > log(x3),specified the formula, from the data frame "mydata"?
> 
> BTW, that's not precisely how formulae in R work.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From deepayan at stat.wisc.edu  Fri Dec 13 19:54:03 2002
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri Dec 13 19:54:03 2002
Subject: [R] Problem with lattice bwplot (same as PR#2349)
In-Reply-To: <200212131457.07423.ltorgo@liacc.up.pt>
References: <200212131457.07423.ltorgo@liacc.up.pt>
Message-ID: <200212131248.15584.deepayan@stat.wisc.edu>

This is the same bug as that reported by Wolfram Fischer a few days back. I'm 
working on it, and hopefully it would be fixed by the next release of lattice 
(sometime next week).

Deepayan

On Friday 13 December 2002 08:57 am, Luis Torgo wrote:
> I've come across the following error when using free scales with bwplot (I
> use
>
> a small example data set just to illustrate the problem):
> > d <- data.frame(
>
> x=c(34.4, 12.4, NA, 65.3, NA, 12.0, 45.0, 645.0, 644.0,323.0),
> fac1=c('a','a','b','a','b','a','a','c','c','c'),
> fac2=c('v2','v2','v1','v2','v2','v2','v1','v2','v1','v2')
> )
>
> # ok, although "x" has only NA values for fac1=='b'
>
> > bwplot(fac2 ~ x | fac1,data=d)
>
> # not ok, if I try to use different scales in the X axis
>
> > bwplot(fac2 ~ x | fac1,data=d,scales=list(x="free"))
>
> Error in pretty(x[is.finite(x)], ...) : x must be numeric
>
> # I can go around the error with
>
> > bwplot(fac2 ~ x | fac1,data=d[!is.na(d$x),],scales=list(x="free"))
>
> The problem is that one of the panels has no data because 'x' has only NA
> values for that particular factor combination. This causes no problem with
> uniform scales, but generates that error when trying to guess the best
> scale for each panel. I think that it should be easy to add some test to
> the code obtaining the scales for each panel, to avoid the always
> unpleasant criptographic error messages ;-)
>
> Thanks,
> Luis Torgo



From tlumley at u.washington.edu  Fri Dec 13 19:58:09 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri Dec 13 19:58:09 2002
Subject: [R] sum a list of vectors
In-Reply-To: <BA5106B991DBAE49AEB14CB58EDFA7AA01188DE6@atlexm04>
Message-ID: <Pine.A41.4.44.0212130855460.54134-100000@homer22.u.washington.edu>

On Fri, 13 Dec 2002, Stoyanov, Tsvetan wrote:

> Thanks for the response.  Still, my point is that there isn't a
> straightforward way to do an operation which should be bread and butter
> for a language, that prides itself in its connection to Lisp.
>

It's easy to write a LISP-style implementation

reduce<-function(args, FUN=get("+")){
	if (length(args)==2)
		FUN(args[[1]], args[[2]])
	else
	        FUN(args[[1]], reduce(args[-1], FUN=FUN))

}

but it is fairly inefficient in R (worse than the loop) and won't work for
large lists because of the fairly small R stack.

Unwinding the recursion into a loop is the efficient solution, though I
suppose an internal version of reduce() that hid this from the user might
be considered more elegant.

	-thomas



From deepayan at stat.wisc.edu  Fri Dec 13 20:04:02 2002
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri Dec 13 20:04:02 2002
Subject: [R] histogram bug?: type='count', unequal breaks
In-Reply-To: <200212131843.gBDIhl7q004388@jessie.research.bell-labs.com>
References: <200212131843.gBDIhl7q004388@jessie.research.bell-labs.com>
Message-ID: <200212131304.08977.deepayan@stat.wisc.edu>

On Friday 13 December 2002 12:43 pm, scottyv at bell-labs.com wrote:
> I ask for a histogram of counts with slightly uneven breaks but
> histogram() ignores the 'type' argument and provides density scaling
> instead.
>
>    x = sample(1:3, 100, replace=TRUE)
>    histogram( ~ x, breaks=c(0,1.5,2.5,3.5), type='count')
>
> My real application has time data with month boundaries for the breaks
> and I DO want counts on the y-axis.
>
> A work-around is not difficult but shouldn't histogram honor the
> type argument when given?

Yes, it should, and it doesn't because of a bug in the released version of 
lattice. This should be fixed in the next release (hopefully sometime next 
week).

Deepayan



From Zhongming.Yang at cchmc.org  Fri Dec 13 21:21:02 2002
From: Zhongming.Yang at cchmc.org (Zhongming Yang)
Date: Fri Dec 13 21:21:02 2002
Subject: [R] how to get Residual Standard Error
Message-ID: <sdf9faa5.024@mailx.chmcc.org>

Hi,

I use lm or loess to make smoothing. After smoothing I need "Residual
Standard Error" in my script. Could you please tell me how can I get
this information?

Thanks,



From gregory_r_warnes at groton.pfizer.com  Fri Dec 13 21:34:03 2002
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Fri Dec 13 21:34:03 2002
Subject: [R] Surprising results from summary(lm()) on data with NO variation
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C393@groexmb02.pfizer.com>

I have some data (from Affymetrix experiments) where I fit an aov() model to
a large number of outcome variables.  A reasonable fraction of the outcome
variables have 0 variability because values below a cutoff have been
replaced with the cutoff value (often 20) .  

In this case, the overall p-value from summary(lm(..))  is misleadingly
small:

For example (equivalent results in R 1.6.1 on both Solaris and for Windows
2000):


	> x <- rep(20, 4+5+5)  # no variation
	> Treatment <- factor(rep( c("Control","Low","High"), c(4,5,5) ))  #
3 treatment levels
	> summary( lm( x ~ Treatment)  )
	
	Call:
	lm(formula = x ~ Treatment)
	
	Residuals:
	       Min         1Q     Median         3Q        Max 
	-1.994e-14  7.889e-31  7.889e-31  7.889e-31  6.647e-15 
	
	Coefficients:
	               Estimate Std. Error   t value Pr(>|t|)    
	(Intercept)   2.000e+01  3.471e-15 5.762e+15   <2e-16 ***
	TreatmentHigh 6.647e-15  4.657e-15 1.427e+00    0.181    
	TreatmentLow  6.647e-15  4.657e-15 1.427e+00    0.181    
	---
	Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
	
	Residual standard error: 6.942e-15 on 11 degrees of freedom
	Multiple R-Squared: 0.5333,     Adjusted R-squared: 0.4485 
	F-statistic: 6.286 on 2 and 11 DF,  p-value: 0.01512
                                          ^^^^^^^^^^^^^^^^

Note F statistic and the overall p-value.     

For some values (eg 0 and 7),  fitting this model will generate NA's for the
estimates.  For most values, we get similar results.  I presume that this is
due to numerical problems in the fitting algorithm.  Still the result is
quite surprising.

It appears that summary.aov doesn't have the same problem:

	> x <- rep(20, 4+5+5)  # no variation
	> Treatment <- factor(rep( c("Control","Low","High"), c(4,5,5) ))  #
3 treatment levels
	> summary( aov( x ~ Treatment)  )
	            Df     Sum Sq    Mean Sq F value Pr(>F)
	Treatment    2 1.2622e-28 6.3110e-29  1.3095 0.3089
	Residuals   11 5.3011e-28 4.8190e-29               

Perhaps the mechanism for computing the F statistic that summary.aov uses is
less susceptible to the 'no variability' problem than the computation in
summary.lm.

I'm posting this here  to raise a warning flag.  For my particular
application, I'll just check for the no variability case and handle it
separately.  I'll leave it to the R core folks to decide if this is a big
enough problem to do something about in the code.

-Greg


LEGAL NOTICE\ Unless expressly stated otherwise, this message is ... [[dropped]]



From ripley at stats.ox.ac.uk  Fri Dec 13 21:50:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Dec 13 21:50:03 2002
Subject: [R] Surprising results from summary(lm()) on data with NO
 variation
In-Reply-To: <D7A3CFD7825BD6119B880002A58F06C202F2C393@groexmb02.pfizer.com>
Message-ID: <Pine.LNX.4.31.0212132047010.8570-100000@gannet.stats>

It's just rounding errors.  We can't tell if you are genuinely interested
in studying rounding error or not.  In other words, whether something is
really constant or has a very small range of variation is not something
you can get from the numbers alone.

lda tries hard to warn here, but doing that well is expensive.

On Fri, 13 Dec 2002, Warnes, Gregory R wrote:

>
> I have some data (from Affymetrix experiments) where I fit an aov() model to
> a large number of outcome variables.  A reasonable fraction of the outcome
> variables have 0 variability because values below a cutoff have been
> replaced with the cutoff value (often 20) .
>
> In this case, the overall p-value from summary(lm(..))  is misleadingly
> small:
>
> For example (equivalent results in R 1.6.1 on both Solaris and for Windows
> 2000):
>
>
> 	> x <- rep(20, 4+5+5)  # no variation
> 	> Treatment <- factor(rep( c("Control","Low","High"), c(4,5,5) ))  #
> 3 treatment levels
> 	> summary( lm( x ~ Treatment)  )
>
> 	Call:
> 	lm(formula = x ~ Treatment)
>
> 	Residuals:
> 	       Min         1Q     Median         3Q        Max
> 	-1.994e-14  7.889e-31  7.889e-31  7.889e-31  6.647e-15
>
> 	Coefficients:
> 	               Estimate Std. Error   t value Pr(>|t|)
> 	(Intercept)   2.000e+01  3.471e-15 5.762e+15   <2e-16 ***
> 	TreatmentHigh 6.647e-15  4.657e-15 1.427e+00    0.181
> 	TreatmentLow  6.647e-15  4.657e-15 1.427e+00    0.181
> 	---
> 	Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
>
> 	Residual standard error: 6.942e-15 on 11 degrees of freedom
> 	Multiple R-Squared: 0.5333,     Adjusted R-squared: 0.4485
> 	F-statistic: 6.286 on 2 and 11 DF,  p-value: 0.01512
>                                           ^^^^^^^^^^^^^^^^
>
> Note F statistic and the overall p-value.
>
> For some values (eg 0 and 7),  fitting this model will generate NA's for the
> estimates.  For most values, we get similar results.  I presume that this is
> due to numerical problems in the fitting algorithm.  Still the result is
> quite surprising.
>
> It appears that summary.aov doesn't have the same problem:
>
> 	> x <- rep(20, 4+5+5)  # no variation
> 	> Treatment <- factor(rep( c("Control","Low","High"), c(4,5,5) ))  #
> 3 treatment levels
> 	> summary( aov( x ~ Treatment)  )
> 	            Df     Sum Sq    Mean Sq F value Pr(>F)
> 	Treatment    2 1.2622e-28 6.3110e-29  1.3095 0.3089
> 	Residuals   11 5.3011e-28 4.8190e-29
>
> Perhaps the mechanism for computing the F statistic that summary.aov uses is
> less susceptible to the 'no variability' problem than the computation in
> summary.lm.
>
> I'm posting this here  to raise a warning flag.  For my particular
> application, I'll just check for the no variability case and handle it
> separately.  I'll leave it to the R core folks to decide if this is a big
> enough problem to do something about in the code.
>
> -Greg
>
>
> LEGAL NOTICE\ Unless expressly stated otherwise, this message is ... [[dropped]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bates at stat.wisc.edu  Fri Dec 13 22:16:12 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri Dec 13 22:16:12 2002
Subject: [R] how to get Residual Standard Error
In-Reply-To: <sdf9faa5.024@mailx.chmcc.org>
References: <sdf9faa5.024@mailx.chmcc.org>
Message-ID: <6rpts5vcwi.fsf@bates5.stat.wisc.edu>

"Zhongming Yang" <Zhongming.Yang at cchmc.org> writes:

> Hi,
> 
> I use lm or loess to make smoothing. After smoothing I need "Residual
> Standard Error" in my script. Could you please tell me how can I get
> this information?

A preferred way would be to use
 sqrt(deviance(fm)/df.residual(fm))
if fm is your fitted model. 

pFor example

> data(Formaldehyde)
> fm <- lm(optden ~ carb, data = Formaldehyde)
> summary(fm)

Call:
lm(formula = optden ~ carb, data = Formaldehyde)

Residuals:
        1         2         3         4         5         6 
-0.006714  0.001029  0.002771  0.007143  0.007514 -0.011743 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) 0.005086   0.007834   0.649    0.552    
carb        0.876286   0.013535  64.744 3.41e-07 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

Residual standard error: 0.008649 on 4 degrees of freedom
Multiple R-Squared: 0.999,	Adjusted R-squared: 0.9988 
F-statistic:  4192 on 1 and 4 DF,  p-value: 3.409e-07 

> sqrt(deviance(fm)/df.residual(fm))
[1] 0.0086487



From miranda at di.fct.unl.pt  Fri Dec 13 22:29:02 2002
From: miranda at di.fct.unl.pt (Don Eduardo Miranda)
Date: Fri Dec 13 22:29:02 2002
Subject: [R] clustering dissimilarities
Message-ID: <002001c2a2ee$8aa99180$f801000a@pong>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021213/12e59e85/attachment.pl

From reid_huntsinger at merck.com  Fri Dec 13 23:05:03 2002
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Fri Dec 13 23:05:03 2002
Subject: [R] clustering dissimilarities
Message-ID: <2C23DE2983BE034CB1CB90DB6B813FD6028AC27C@uswpmx11.merck.com>

The model-based methods I'm familiar with (mixture models) require
the "ambient space" from which the sample was drawn, not just the
metric restricted to the sample points. You could try an embedding
approach like multidimensional scaling (e.g. cmdscale in package mva)
with fairly high dimension and then use a model-based approach on the
result. The choice of embedding will likely have some influence on
the final result.

Reid Huntsinger

-----Original Message-----
From: Don Eduardo Miranda [mailto:miranda at di.fct.unl.pt]
Sent: Friday, December 13, 2002 4:28 PM
To: r-help at stat.math.ethz.ch
Subject: [R] clustering dissimilarities


Hello.  I know my dissimilarity matrix but not my original data.  Is there
any way i could use the clustering function Mclust or EMclust with this
dissimilarity matrix?   or at least some equivalent of these functions?  As
this is model based clustering i dont know if it is actually possible to do
it without the original data


thanks in advance for your help

	[[alternate HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help

------------------------------------------------------------------------------



From neelypitts at provedor.com  Sat Dec 14 10:24:16 2002
From: neelypitts at provedor.com (darylene  )
Date: Sat Dec 14 10:24:16 2002
Subject: [R] r-announce,RE: Awesome Chistmas_Gift for All Ages!
Message-ID: <TGA-MAIL-FAXFG3R1ne0001b2a3@tga-mail-fax.glatfelteragency.com>

Dear r-announce at stat.math.ethz.ch

=========================================================
     The World's Smallest Radio-Controlled Car...
       ..Is this years hottest Christmas gift!
=========================================================
The Hot New Mini-Racer.  

The smallest radio-controlled car in the world
Are "Sold Out"in stores...but we have them!

Better hurry while supplies (less than 1000 cars left!) last.

Christmas Special: Buy 3 get 3 FREE!

FREE Shipping (United States Residents Only)! 

Guaranteed delivery before Christmas or your money back if ordered
by December 20, 2002.

http://specialproducts4u.com/dvda/
*************************************************************
This is a VERY LIMITED TIME offer. We will sell out. 
     These are simply way too HOT for you to pass up!
*************************************************************

To opt out:

http://specialproducts4u.com/dvda/



From tura at centroin.com.br  Sat Dec 14 15:36:03 2002
From: tura at centroin.com.br (Bernardo Rangel Tura)
Date: Sat Dec 14 15:36:03 2002
Subject: [R] Power analysis for 1-sample Binomial
Message-ID: <5.1.0.14.2.20021214122035.00a16ec0@centroin.com.br>

Hi R Masters!


I will make a populational survey in my hospital.  
Using the program I calculated the sample size for disease proportion in population.
---------------
pop<-2400
p<-.2
d<-.05
alpha<-.05
z<-qnorm(1-alpha/2)
n<-z^2*(p*(1-p))/d^2
sample<-n/(1+(n/pop))
sample
---------------
Well, do I know the sample size for this study, but is it possible to do an power analysis for this study using the R?

Thanks in advance

Bernardo Rangel Tura, MD, MSc
National Institute of Cardiology Laranjeiras
Rio de Janeiro Brazil



From Zhongming.Yang at cchmc.org  Sat Dec 14 16:34:02 2002
From: Zhongming.Yang at cchmc.org (Zhongming Yang)
Date: Sat Dec 14 16:34:02 2002
Subject: [R] how to get Residual Standard Error
Message-ID: <sdfb08ef.024@mailx.chmcc.org>

Thanks for your answer.

But I really want to know whether I can get "Residual Standard Error",
directly. If I use summary(), there is an item "Residual Standard
Error". So I think we might can access this information directly.

Thanks again,









> summary(mod)
Call:
loess(formula = y ~ x)

Number of Observations: 10 
Equivalent Number of Parameters: 4.95 
Residual Standard Error: 8.734e-16 
Trace of smoother matrix: 5.47 

Control settings:
  normalize:  TRUE 
  span      :  0.75 
  degree   :  2 
  family   :  gaussian
  surface  :  interpolate         cell = 0.2







>>> Douglas Bates <bates at stat.wisc.edu> 12/13/02 04:15PM >>>
"Zhongming Yang" <Zhongming.Yang at cchmc.org> writes:

> Hi,
> 
> I use lm or loess to make smoothing. After smoothing I need
"Residual
> Standard Error" in my script. Could you please tell me how can I get
> this information?

A preferred way would be to use
 sqrt(deviance(fm)/df.residual(fm))
if fm is your fitted model. 

pFor example

> data(Formaldehyde)
> fm <- lm(optden ~ carb, data = Formaldehyde)
> summary(fm)

Call:
lm(formula = optden ~ carb, data = Formaldehyde)

Residuals:
        1         2         3         4         5         6 
-0.006714  0.001029  0.002771  0.007143  0.007514 -0.011743 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) 0.005086   0.007834   0.649    0.552    
carb        0.876286   0.013535  64.744 3.41e-07 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

Residual standard error: 0.008649 on 4 degrees of freedom
Multiple R-Squared: 0.999,	Adjusted R-squared: 0.9988 
F-statistic:  4192 on 1 and 4 DF,  p-value: 3.409e-07 

> sqrt(deviance(fm)/df.residual(fm))
[1] 0.0086487

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From roger at ysidro.econ.uiuc.edu  Sat Dec 14 18:02:02 2002
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Sat Dec 14 18:02:02 2002
Subject: [R] tripack on solaris
Message-ID: <Pine.SOL.4.30.0212141047510.17703-100000@ysidro.econ.uiuc.edu>

I'm trying to revive a project that uses the tripack package on a R1.6.1 solaris system.
Contrary to my prior experience the function voronoi.mosaic now crashes with a bus error.
(This is true in my examples but it also happens running R CMD check tripack in executing
the documentation examples on a fresh version of the package. On our linux system tripack
checks flawlessly.)  Before digging into the gory details, I wondered if anyone else
might have experience with this, or if there are any general suggestions about what
to look for.   Compilation on both solaris and linux is with g77.


url:	http://www.econ.uiuc.edu		Roger Koenker
email	roger at ysidro.econ.uiuc.edu		Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820



From ligges at statistik.uni-dortmund.de  Sat Dec 14 19:55:03 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat Dec 14 19:55:03 2002
Subject: [R] how to get Residual Standard Error
References: <sdfb08ef.024@mailx.chmcc.org>
Message-ID: <3DFB7E94.3054F26@statistik.uni-dortmund.de>

Zhongming Yang wrote:
> 
> Thanks for your answer.
> 
> But I really want to know whether I can get "Residual Standard Error",
> directly. If I use summary(), there is an item "Residual Standard
> Error". So I think we might can access this information directly.
> 
> Thanks again,

Well, you can get it with summary(x)$sigma, if class(x) == "lm"
(Attention: it might be completely different for other classes!).
summary() calculates much more than this value, thus it is much faster
to calculate it *directly*, i.e. in the way Douglas Bates already
pointed out.

Uwe Ligges


> > summary(mod)
> Call:
> loess(formula = y ~ x)
> 
> Number of Observations: 10
> Equivalent Number of Parameters: 4.95
> Residual Standard Error: 8.734e-16
> Trace of smoother matrix: 5.47
> 
> Control settings:
>   normalize:  TRUE
>   span      :  0.75
>   degree   :  2
>   family   :  gaussian
>   surface  :  interpolate         cell = 0.2
> 
> >>> Douglas Bates <bates at stat.wisc.edu> 12/13/02 04:15PM >>>
> "Zhongming Yang" <Zhongming.Yang at cchmc.org> writes:
> 
> > Hi,
> >
> > I use lm or loess to make smoothing. After smoothing I need
> "Residual
> > Standard Error" in my script. Could you please tell me how can I get
> > this information?
> 
> A preferred way would be to use
>  sqrt(deviance(fm)/df.residual(fm))
> if fm is your fitted model.
> 
> pFor example
> 
> > data(Formaldehyde)
> > fm <- lm(optden ~ carb, data = Formaldehyde)
> > summary(fm)
> 
> Call:
> lm(formula = optden ~ carb, data = Formaldehyde)
> 
> Residuals:
>         1         2         3         4         5         6
> -0.006714  0.001029  0.002771  0.007143  0.007514 -0.011743
> 
> Coefficients:
>             Estimate Std. Error t value Pr(>|t|)
> (Intercept) 0.005086   0.007834   0.649    0.552
> carb        0.876286   0.013535  64.744 3.41e-07 ***
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
> 
> Residual standard error: 0.008649 on 4 degrees of freedom
> Multiple R-Squared: 0.999,      Adjusted R-squared: 0.9988
> F-statistic:  4192 on 1 and 4 DF,  p-value: 3.409e-07
> 
> > sqrt(deviance(fm)/df.residual(fm))
> [1] 0.0086487
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From kwan022 at stat.auckland.ac.nz  Sat Dec 14 21:45:04 2002
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Sat Dec 14 21:45:04 2002
Subject: [R] scan() with "what"
Message-ID: <Pine.SOL.4.21.0212150944100.14204-100000@stat1.stat.auckland.ac.nz>

Hi,

I have a medium-sized (19MB) CSV file that I'd like to read into R.  The
read.csv() function seems to be a bit inefficient to deal with it, and I
remember that using scan() with "what" options is better.

However I'm unable to understand how to use it.  The first few lines of
the data look like:

USAGE,MILEAGE,SEX,EXCESS,NCD,PRIMAGE,MINAGE,DRIVERS,DISTRICT,CARGROUP,CAR_AGE,WSCLMS,ADCLMS,FTCLMS,PDCLMS,PICLMS,ADINCUR,PDINCUR,WSINCUR,FTINCUR,PIINCUR,RECORD,DAYS,MINAGEN,PRIMAGEN
  SC,7000,M,100,4,59,25,3,4,7,6,0,0,0,,,0,,0,0,,1,85,25,59
  SC,7000,M,100,4,59,59,2,4,13,5,0,0,0,,,0,,0,0,,2,278,59,59
  SC,7000,M,100,4,60,60,2,4,13,5,0,0,0,,,0,,0,0,,3,364,60,60
  SB,10000,M,75,4,53,44,2,3,14,4,1,0,0,0,0,0,0,146.18,0,0,4,364,44,53
  SB,10000,M,75,4,54,45,2,3,14,4,0,0,0,,,0,,0,0,,5,363,45,54

i.e. columns are separated by commas and may contain missing values, and
has headers.

I'd really appreciated it if someone can tell me how to use the
scan() command to read this data in.

Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

Ko-Kang Kevin Wang
Master of Science (MSc) Student
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022



From ripley at stats.ox.ac.uk  Sat Dec 14 21:59:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat Dec 14 21:59:03 2002
Subject: [R] scan() with "what"
In-Reply-To: <Pine.SOL.4.21.0212150944100.14204-100000@stat1.stat.auckland.ac.nz>
Message-ID: <Pine.LNX.4.31.0212142057070.1687-100000@gannet.stats>

On Sun, 15 Dec 2002, Ko-Kang Kevin Wang wrote:

> Hi,
>
> I have a medium-sized (19MB) CSV file that I'd like to read into R.  The
> read.csv() function seems to be a bit inefficient to deal with it, and I
> remember that using scan() with "what" options is better.

Unlikely if you specify colClasses, which sets up calls to scan() for you.

> However I'm unable to understand how to use it.  The first few lines of
> the data look like:
>
> USAGE,MILEAGE,SEX,EXCESS,NCD,PRIMAGE,MINAGE,DRIVERS,DISTRICT,CARGROUP,CAR_AGE,WSCLMS,ADCLMS,FTCLMS,PDCLMS,PICLMS,ADINCUR,PDINCUR,WSINCUR,FTINCUR,PIINCUR,RECORD,DAYS,MINAGEN,PRIMAGEN
>   SC,7000,M,100,4,59,25,3,4,7,6,0,0,0,,,0,,0,0,,1,85,25,59
>   SC,7000,M,100,4,59,59,2,4,13,5,0,0,0,,,0,,0,0,,2,278,59,59
>   SC,7000,M,100,4,60,60,2,4,13,5,0,0,0,,,0,,0,0,,3,364,60,60
>   SB,10000,M,75,4,53,44,2,3,14,4,1,0,0,0,0,0,0,146.18,0,0,4,364,44,53
>   SB,10000,M,75,4,54,45,2,3,14,4,0,0,0,,,0,,0,0,,5,363,45,54
>
> i.e. columns are separated by commas and may contain missing values, and
> has headers.
>
> I'd really appreciated it if someone can tell me how to use the
> scan() command to read this data in.

Try colClasses first.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From abunn at montana.edu  Sat Dec 14 23:42:02 2002
From: abunn at montana.edu (Andy Bunn)
Date: Sat Dec 14 23:42:02 2002
Subject: [R] adding contour lines to a filled.contour
Message-ID: <000201c2a3c1$d9d70c00$0100a8c0@simATE>

Hi all, 

Does anybody know how to add contour lines to a filled contour plot?

I want to draw a single contour around values that are above a certain
level (e.g., significant). The problem I'm having is that since the
filled.contour command actually draws two plots (data and the key),
adding contour lines paints them over both plots.

Any suggestions?

Thanks, Andy


#~~~~~~~~~~~~~~~~~~~
#example

junk.mat <- matrix(rnorm(1600), 16, 100)

filled.contour(junk.mat, 
               color = terrain.colors)

#set values < 2 to zero
contour.mat <- ifelse(junk.mat < 2, 0, junk.mat)

#add contours
contour(contour.mat,
        levels = 1,
        drawlabels = F,
        axes = F, 
        frame.plot = F,
        add = T)



From mabramso at gmu.edu  Sun Dec 15 01:53:02 2002
From: mabramso at gmu.edu (Myriam Abramson)
Date: Sun Dec 15 01:53:02 2002
Subject: [R] axis
Message-ID: <m3adj814vv.fsf@home.sweet.home>

I have to draw a phase space graph. Is it possible to draw the axis at
the center at (0,0)? 

TIA

-- 
                                   myriam



From mabramso at gmu.edu  Sun Dec 15 06:13:03 2002
From: mabramso at gmu.edu (Myriam Abramson)
Date: Sun Dec 15 06:13:03 2002
Subject: [R] shading
In-Reply-To: <m3adj814vv.fsf@home.sweet.home>
References: <m3adj814vv.fsf@home.sweet.home>
Message-ID: <m365tv27fj.fsf@home.sweet.home>

I need to shade one area of a graph. Any ideas on how to do that?

                                   myriam



From jeff_hamann at hamanndonald.com  Sun Dec 15 08:50:03 2002
From: jeff_hamann at hamanndonald.com (Jeff D. Hamann)
Date: Sun Dec 15 08:50:03 2002
Subject: [R] maximum likelihood example?
Message-ID: <000501c2a40e$7f3e6c50$0400a8c0@toastman>

I'm trying to get a grasp of maximum-likelihood estimation and would like to
find a package that performs mle (hopefully a simple example). It seems as
if there are plenty of packages that make use of different types of
likelihood estimators, but none are of a simple, "newbie" type. Does anyone
have a suggestion for which package would be the best for a mle example?

Thanks,
Jeff.



From ripley at stats.ox.ac.uk  Sun Dec 15 09:02:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun Dec 15 09:02:03 2002
Subject: [R] maximum likelihood example?
In-Reply-To: <000501c2a40e$7f3e6c50$0400a8c0@toastman>
Message-ID: <Pine.LNX.4.31.0212150800440.16822-100000@gannet.stats>

fitdistr in MASS.  It's about as basic as you can get: iid samples from
standard distributions.

On Sat, 14 Dec 2002, Jeff D. Hamann wrote:

> I'm trying to get a grasp of maximum-likelihood estimation and would like to
> find a package that performs mle (hopefully a simple example). It seems as
> if there are plenty of packages that make use of different types of
> likelihood estimators, but none are of a simple, "newbie" type. Does anyone
> have a suggestion for which package would be the best for a mle example?
>
> Thanks,
> Jeff.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Sun Dec 15 11:20:03 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun Dec 15 11:20:03 2002
Subject: [R] adding contour lines to a filled.contour
References: <000201c2a3c1$d9d70c00$0100a8c0@simATE>
Message-ID: <3DFC57A8.6AD0F441@statistik.uni-dortmund.de>


Andy Bunn wrote:
> 
> Hi all,
> 
> Does anybody know how to add contour lines to a filled contour plot?
> 
> I want to draw a single contour around values that are above a certain
> level (e.g., significant). The problem I'm having is that since the
> filled.contour command actually draws two plots (data and the key),
> adding contour lines paints them over both plots.
> 
> Any suggestions?

Yes. Look into the code of filled.contour(), how things are set up for
those two parts of the plot. The following solution will become clear:

 # your code:
 junk.mat <- matrix(rnorm(1600), 16, 100)
 filled.contour(junk.mat, color = terrain.colors)
 contour.mat <- ifelse(junk.mat < 2, 0, junk.mat)

 # insert 3 lines of code, stolen from filled.contour():
 mar.orig <- par("mar")
 w <- (3 + mar.orig[2]) * par("csi") * 2.54
 layout(matrix(c(2, 1), nc = 2), widths = c(1, lcm(w)))

 # your code:
 contour(contour.mat, levels = 1, drawlabels = FALSE, 
     axes = FALSE, frame.plot = FFALSE, add = TRUE)
 

Uwe Ligges





> Thanks, Andy
> 
> #~~~~~~~~~~~~~~~~~~~
> #example
> 
> junk.mat <- matrix(rnorm(1600), 16, 100)
> 
> filled.contour(junk.mat,
>                color = terrain.colors)
> 
> #set values < 2 to zero
> contour.mat <- ifelse(junk.mat < 2, 0, junk.mat)
> 
> #add contours
> contour(contour.mat,
>         levels = 1,
>         drawlabels = F,
>         axes = F,
>         frame.plot = F,
>         add = T)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ligges at statistik.uni-dortmund.de  Sun Dec 15 11:30:04 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun Dec 15 11:30:04 2002
Subject: [R] axis
References: <m3adj814vv.fsf@home.sweet.home>
Message-ID: <3DFC59AC.F8D8686@statistik.uni-dortmund.de>


Myriam Abramson wrote:
> 
> I have to draw a phase space graph. Is it possible to draw the axis at
> the center at (0,0)?

Yes, using axis() with argument "pos", see ?axis. 

Example:

 y <- rnorm(21)
 plot(-10:10, y, axes=FALSE)
 axis(1, pos=0)
 axis(2, pos=0)

 # OK. Looks ugly (the zero). Next try:
 plot(-10:10, y, axes=FALSE) 
 axis(1, pos = 0, at = c(-10, -5, 5, 10))
 yprt <- pretty(y)
 yprt <- yprt[yprt != 0]
 axis(2, pos = 0, at = yprt)


Uwe Ligges



From ligges at statistik.uni-dortmund.de  Sun Dec 15 11:37:08 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun Dec 15 11:37:08 2002
Subject: [R] shading
References: <m3adj814vv.fsf@home.sweet.home> <m365tv27fj.fsf@home.sweet.home>
Message-ID: <3DFC5A57.2AFC68F3@statistik.uni-dortmund.de>


Myriam Abramson wrote:
> 
> I need to shade one area of a graph. Any ideas on how to do that?

First set up your plot( ...., type = "n").
Then draw the shading using polygon(...., col = "grey"), after that the
lines() and points() to appear in front of it.

Uwe Ligges



From oliver at colorado.edu  Sun Dec 15 13:13:03 2002
From: oliver at colorado.edu (Bill Oliver)
Date: Sun Dec 15 13:13:03 2002
Subject: [R] maximum likelihood example?
In-Reply-To: <000501c2a40e$7f3e6c50$0400a8c0@toastman>
References: <000501c2a40e$7f3e6c50$0400a8c0@toastman>
Message-ID: <3DFC71B0.3030407@colorado.edu>

Jeff D. Hamann wrote:
> I'm trying to get a grasp of maximum-likelihood estimation and would like to
> find a package that performs mle (hopefully a simple example). It seems as
> if there are plenty of packages that make use of different types of
> likelihood estimators, but none are of a simple, "newbie" type. Does anyone
> have a suggestion for which package would be the best for a mle example?
> 

I would suggest that you check out the very good book by Yudi Pawitan 
entitled "In all likelihood". He provides the R code for *all* of the 
examples and figures in the book at the following web page.

http://statistics.ucc.ie/staff/yudi/

-Bill



From Olof.Leimar at zoologi.su.se  Sun Dec 15 13:25:03 2002
From: Olof.Leimar at zoologi.su.se (Olof Leimar)
Date: Sun Dec 15 13:25:03 2002
Subject: [R] Interpretation of hypothesis tests for mixed models
Message-ID: <1039955040.1113.13.camel@plantago>

My question concerns the logic behind hypothesis tests for fixed-effect
terms in models fitted with lme. Suppose the levels of Subj indicate a
grouping structure (k subjects) and Trt is a two-level factor (two
treatments) for which there are several (n) responses y from each
treatment and subject combination. If one suspects a subject by
treatment interaction, either of the following models seem natural
  
> fm1 <- lme(y ~ Trt, random = list(Subj = pdDiag(~ Trt)))
> fm2 <- lme(y ~ trt, random = ~ 1 | Subj/Trt)

These models seem to correspond to the same situation. Both have two
variance components (subject and treatment within subject). However,
they result in different denominator degrees of freedom (denDF) of the
F-statistic for a (fixed-effect) test for treatment. For the case of few
subjects and many observations per subject-treatment combination, denDF
will be much larger for fm1 (denDF = k*2*n-k-1) than for fm2 (denDF =
k-1).

What is the essential difference in the nature of random effects for
situations modelled by fm1 and fm2? On the other hand, if there is no
essential difference between fm1 and fm2, why are the tests different? 

I realize that fm2 corresponds to the classical analysis
> fm3 <- aov(y ~ Trt + Error(Subj/Trt))
but what is the logic behind fm1?

I have looked in Venables & Ripley (2002) and Pinheiro & Bates (2000),
but neither of these excellent books seems to explain how or whether
models like fm1 and fm2 differ.

Olof Leimar, Professor
Department of Zoology
Stockholm University
SE-106 91 Stockholm
Sweden

Olof.Leimar at zoologi.su.se



From cmonrocq at damacosy.fr  Sun Dec 15 19:02:08 2002
From: cmonrocq at damacosy.fr (Ch Monrocq)
Date: Sun Dec 15 19:02:08 2002
Subject: [R] (no subject)
Message-ID: <3DFCC399.2080004@damacosy.fr>

|subscribe|



From bates at stat.wisc.edu  Sun Dec 15 20:33:02 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun Dec 15 20:33:02 2002
Subject: [R] Interpretation of hypothesis tests for mixed models
In-Reply-To: <1039955040.1113.13.camel@plantago>
References: <1039955040.1113.13.camel@plantago>
Message-ID: <6r1y4jw017.fsf@bates5.stat.wisc.edu>

Olof Leimar <Olof.Leimar at zoologi.su.se> writes:

> My question concerns the logic behind hypothesis tests for fixed-effect
> terms in models fitted with lme. Suppose the levels of Subj indicate a
> grouping structure (k subjects) and Trt is a two-level factor (two
> treatments) for which there are several (n) responses y from each
> treatment and subject combination. If one suspects a subject by
> treatment interaction, either of the following models seem natural
>   
> > fm1 <- lme(y ~ Trt, random = list(Subj = pdDiag(~ Trt)))
> > fm2 <- lme(y ~ trt, random = ~ 1 | Subj/Trt)

I don't think those models are equivalent.  To get equivalent models I
think you need random = list(Subj = pdCompSymm(~ Trt - 1)) in the first
model.

For example

> library(nlme)
Loading required package: nls 
Loading required package: lattice 
> data(Machines)
> fm1 <- lme(score ~ Machine, data = Machines, random = ~ 1 | Worker/Machine)
> logLik(fm1)
`log Lik.' -107.8438 (df=6)
> fm2 <- lme(score ~ Machine, data = Machines, random=list(Worker=pdCompSymm(~Machine - 1)))
> logLik(fm2)
`log Lik.' -107.8438 (df=6)
> summary(fm1)
Linear mixed-effects model fit by REML
 Data: Machines 
       AIC      BIC    logLik
  227.6876 239.2785 -107.8438

Random effects:
 Formula: ~1 | Worker
        (Intercept)
StdDev:    4.781049

 Formula: ~1 | Machine %in% Worker
        (Intercept)  Residual
StdDev:    3.729536 0.9615768

Fixed effects: score ~ Machine 
               Value Std.Error DF   t-value p-value
(Intercept) 52.35556  2.485829 36 21.061606  <.0001
MachineB     7.96667  2.176974 10  3.659514  0.0044
MachineC    13.91667  2.176974 10  6.392665  0.0001
 Correlation: 
         (Intr) MachnB
MachineB -0.438       
MachineC -0.438  0.500

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max 
-2.26958756 -0.54846582 -0.01070588  0.43936575  2.54005852 

Number of Observations: 54
Number of Groups: 
             Worker Machine %in% Worker 
                  6                  18 
> summary(fm2)
Linear mixed-effects model fit by REML
 Data: Machines 
       AIC      BIC    logLik
  227.6876 239.2785 -107.8438

Random effects:
 Formula: ~Machine - 1 | Worker
 Structure: Compound Symmetry
         StdDev    Corr       
MachineA 6.0626364            
MachineB 6.0626364 0.621      
MachineC 6.0626364 0.621 0.621
Residual 0.9615618            

Fixed effects: score ~ Machine 
               Value Std.Error DF   t-value p-value
(Intercept) 52.35556  2.485416 46 21.065106  <.0001
MachineB     7.96667  2.177416 46  3.658770   7e-04
MachineC    13.91667  2.177416 46  6.391367  <.0001
 Correlation: 
         (Intr) MachnB
MachineB -0.438       
MachineC -0.438  0.500

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max 
-2.26962147 -0.54844560 -0.01068651  0.43936587  2.54004419 

Number of Observations: 54
Number of Groups: 6 

This still doesn't get around the problem of the different definitions
of the degrees of freedom in the denominator of the F tests.  That
occurs because the definition of the degrees of freedom is not
invariant with respect to the different formulation of the models.

I prefer to formulate such a model as nested random effects rather
than trying to decide how the model matrices should be defined in a
model with a compound symmetry structure for the variance-covariance
term.  I think the definition of the degrees of freedom is cleaner
in that case too.



From matthew_wiener at merck.com  Sun Dec 15 20:48:03 2002
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Sun Dec 15 20:48:03 2002
Subject: [R] SHLIB issue
Message-ID: <AEBD81486231A343B1813FE62D3352251E497C@usrymx15.merck.com>

Hi.  I'm trying to compile (CMD SHLIB) a simple c program under R-1.6.1.

version:
platform powerpc-ibm-aix5.1.0.0
arch     powerpc
os       aix5.1.0.0
system   powerpc, aix5.1.0.0
status
major    1
minor    6.1
year     2002
month    11
day      01
language R

> /usr/local/R-1.6.1/bin/R CMD SHLIB matrix.add.c
cc_r -I/usr/local/R-1.6.1/lib/R/include  -I/usr/local/include     -O
-qmaxmem=-1 -
qarch=auto -qtune=auto -c matrix.add.c -o matrix.add.o
mmap failed: Not enough space
make: *** [matrix.add.o] Error 1
>

As far as I can tell, I have plenty of space on the system, both disk space
and physical memory when I try this.
I looked around in the documentation and mailing list,  but didn't find
anything. Anyone have any ideas?

Thanks for any help,

Matthew Wiener
RY84-202
Applied Computer Science & Mathematics Dept.
Merck Research Labs
126 E. Lincoln Ave.
Rahway, NJ 07065
732-594-5303 



------------------------------------------------------------------------------



From stormplot at hotmail.com  Sun Dec 15 21:23:02 2002
From: stormplot at hotmail.com (Jason Fisher)
Date: Sun Dec 15 21:23:02 2002
Subject: [R] irregual space plot
Message-ID: <F1246oJDEIXq2gEIn3q00031614@hotmail.com>

Hello everyone...

I was hoping an R wizard could help me out with this one.  My current R 
programming endeavors require that I generate plots of groundwater state 
variables (e.g. pressure fields, contaminate plumes, etc.) in a 2-D slice of 
a 3-D system.  While the functions contour() and filled.contour() are close 
to what Im looking for, they unfortunately lack in their inability to deal 
with irregular boundaries (non-rectangular systems).  The irregular systems 
Im working with are made up of finite elements (each 2-D element 
constructed from 3 or 4 nodes) where linear basis functions describe every 
point (x,y) in the element.  I believe I could deal with my plotting dilemma 
if I had a function very similar to .Internal(filledcontour()).  A 
function, which would allow me to specify contours or colors between 
contours within an element.  If someone could give me a hand on this project 
or point me towards helpful resources, it would be greatly appreciated.

Regards,

Jason

PS:  If any additional information is needed, please ask.





***************************************
Jason C. Fisher
UCLA Graduate Student
Civil & Environmental Engineering Dept.
5731 Boelter Hall
Box 951593
Los Angeles, CA 90095-1593
Phone Number: (310) 825-2292
Email: stormplot at hotmail.com
***************************************




_________________________________________________________________
Add photos to your e-mail with MSN 8. Get 2 months FREE*.



From stormplot at hotmail.com  Sun Dec 15 21:31:11 2002
From: stormplot at hotmail.com (Jason Fisher)
Date: Sun Dec 15 21:31:11 2002
Subject: [R] irregual space plot
Message-ID: <F76zAKsqKTDHRcXQBfh00004d86@hotmail.com>




Hello everyone...

I was hoping an R wizard could help me out with this one.  My current R 
programming endeavors require that I generate plots of groundwater state 
variables (e.g. pressure fields, contaminate plumes, etc.) in a 2-D slice of 
a 3-D system.  While the functions contour() and filled.contour() are close 
to what Im looking for, they unfortunately lack in their inability to deal 
with irregular boundaries (non-rectangular systems).  The irregular systems 
Im working with are made up of finite elements (each 2-D element 
constructed from 3 or 4 nodes) where linear basis functions describe every 
point (x,y) in the element.  I believe I could deal with my plotting dilemma 
if I had a function very similar to .Internal(filledcontour()).  A 
function, which would allow me to specify contours or colors between 
contours within an element.  If someone could give me a hand on this project 
or point me towards helpful resources, it would be greatly appreciated.

Regards,

Jason

PS:  If any additional information is needed, please ask.





***************************************
Jason C. Fisher
UCLA Graduate Student
Civil & Environmental Engineering Dept.
5731 Boelter Hall
Box 951593
Los Angeles, CA 90095-1593
Phone Number: (310) 825-2292
Email: stormplot at hotmail.com
***************************************



From ben at zoo.ufl.edu  Sun Dec 15 22:52:03 2002
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Sun Dec 15 22:52:03 2002
Subject: [R] maximum likelihood example?
In-Reply-To: <000501c2a40e$7f3e6c50$0400a8c0@toastman>
Message-ID: <Pine.LNX.4.44.0212151654020.10725-100000@bolker.zoo.ufl.edu>

   I have an "mleprof" package that implements some basic methods for ML 
estimation, profiling, etc..  It's in the bbmisc package on my web page at 
http://www.zoo.ufl.edu/bolker/R (windows or src).

   Ben Bolker

On Sat, 14 Dec 2002, Jeff D. Hamann wrote:

> I'm trying to get a grasp of maximum-likelihood estimation and would like to
> find a package that performs mle (hopefully a simple example). It seems as
> if there are plenty of packages that make use of different types of
> likelihood estimators, but none are of a simple, "newbie" type. Does anyone
> have a suggestion for which package would be the best for a mle example?
> 
> Thanks,
> Jeff.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From rpeng at stat.ucla.edu  Mon Dec 16 00:10:03 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Mon Dec 16 00:10:03 2002
Subject: [R] adding contour lines to a filled.contour
In-Reply-To: <3DFC57A8.6AD0F441@statistik.uni-dortmund.de>
Message-ID: <Pine.GSO.4.10.10212151459040.9324-100000@fisher.stat.ucla.edu>

There is an easier solution.  Try,

junk.mat <- matrix(rnorm(1600), 16, 100)
contour.mat <- ifelse(junk.mat < 2, 0, junk.mat)
filled.contour(junk.mat, color = terrain.colors, 
               plot.axes = contour(contour.mat, levels = 1, 
                                   drawlabels = FALSE, axes = FALSE, 
                                   frame.plot = FFALSE, add = TRUE))

The 'plot.axes' argument to filled.contour() gives you access to the
coordinate system in the actual plotting area.  However, you will notice
that the axes are missing.  You need to add them explicitly, as in:

filled.contour(junk.mat, color = terrain.colors, 
               plot.axes = { contour(contour.mat, levels = 1, 
                                     drawlabels = FALSE, axes = FALSE, 
                                     frame.plot = FFALSE, add = TRUE);
			     axis(1); axis(2) } )

This also useful for adding titles, text annotations, points, etc. 

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Sun, 15 Dec 2002, Uwe Ligges wrote:

> 
> 
> Andy Bunn wrote:
> > 
> > Hi all,
> > 
> > Does anybody know how to add contour lines to a filled contour plot?
> > 
> > I want to draw a single contour around values that are above a certain
> > level (e.g., significant). The problem I'm having is that since the
> > filled.contour command actually draws two plots (data and the key),
> > adding contour lines paints them over both plots.
> > 
> > Any suggestions?
> 
> Yes. Look into the code of filled.contour(), how things are set up for
> those two parts of the plot. The following solution will become clear:
> 
>  # your code:
>  junk.mat <- matrix(rnorm(1600), 16, 100)
>  filled.contour(junk.mat, color = terrain.colors)
>  contour.mat <- ifelse(junk.mat < 2, 0, junk.mat)
> 
>  # insert 3 lines of code, stolen from filled.contour():
>  mar.orig <- par("mar")
>  w <- (3 + mar.orig[2]) * par("csi") * 2.54
>  layout(matrix(c(2, 1), nc = 2), widths = c(1, lcm(w)))
> 
>  # your code:
>  contour(contour.mat, levels = 1, drawlabels = FALSE, 
>      axes = FALSE, frame.plot = FFALSE, add = TRUE)
>  
> 
> Uwe Ligges
> 
> 
> 
> 
> 
> > Thanks, Andy
> > 
> > #~~~~~~~~~~~~~~~~~~~
> > #example
> > 
> > junk.mat <- matrix(rnorm(1600), 16, 100)
> > 
> > filled.contour(junk.mat,
> >                color = terrain.colors)
> > 
> > #set values < 2 to zero
> > contour.mat <- ifelse(junk.mat < 2, 0, junk.mat)
> > 
> > #add contours
> > contour(contour.mat,
> >         levels = 1,
> >         drawlabels = F,
> >         axes = F,
> >         frame.plot = F,
> >         add = T)
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From dunn at usq.edu.au  Mon Dec 16 02:00:03 2002
From: dunn at usq.edu.au (Peter Dunn)
Date: Mon Dec 16 02:00:03 2002
Subject: [R] Creating libraries:  Cannot make help
Message-ID: <4CE94EAEAD60B744B9263A2C82A9C79219EB1E@alpha.usq.edu.au>

Hi all

I am trying to package a library in R 1.6.1 (Windoze XP).

I have read the document "Writing R extensions" and think I
have done things correctly (though apparently not).  I have
searched the mail archives for help to no avail.

I also posted a few days ago and thanks to Peter Dalgaard I have
managed to focus my search for errors.

I am trying to create a library in R.  I run the INSTALL
script and installing the R files in the library itself go 
fine; the message is


  adding build stamp to DESCRIPTION
  installing R files


Indeed, after loading the library, I can use these files.
But creating the help is causing troubles:


  installing man source files
make[1]: Leaving directory
`/cygdrive/d/pkd/research/tweedie/libraries/R/<lib-name>'
make: *** [pkg-<lib-name>] Error 255
make: Leaving directory `/cygdrive/d/Programs/R/rw1061/src/gnuwin32'

*** Installation of <lib-name> failed ***


And so while the library files work, there is no help available.

Without knowing Perl or anything, I seem to have found the line in
the INSTALL script that causes things to die (line break added):


    if(system("make -C $R_HOME/src/gnuwin32 PKGDIR=$pkgdir 
       RLIB=$library SAVE=$save $helpflags $makecmd-$pkgname")){


If I run this command in a Cygwin window, expanding the variable names,
I get this (abbreviated, editted) message:


---------- Making package <lib-name> ------------
mkdir -p d:/Programs/R/rw1061/library/<lib-name>
cp -r   ./INDEX  ./TITLE ./contents ./index.bak
d:/Programs/R/rw1061/library/<lib-name>/
  adding build stamp to DESCRIPTION
make[1]: Leaving directory `/cygdrive/<path>/libraries/R/<lib-name>'
make[1]: Entering directory
`/cygdrive/d/Programs/R/rw1061/src/gnuwin32/help'
Makefile:42: *** missing separator.  Stop.
make[1]: Leaving directory
`/cygdrive/d/Programs/R/rw1061/src/gnuwin32/help'
make: *** [pkg-<lib-name>] Error 2
make: Leaving directory `/cygdrive/d/Programs/R/rw1061/src/gnuwin32'


It indicates a missing separator.  But my knowledge of Perl and
Makefiles
is basically zip (apart from what I learnt to get this far).

My running the appropriate commands my self, I can generate, eg, html
files so there is nothing wrong with my  sgml  source files.  But
running
the INSTALL script fails to create anything help-ful.

Can anyone help me sort out what I am doing wrong or why I am getting
these
messages?

P.

Dr Peter Dunn          (USQ CRICOS No. 00244B)
  Web:    http://www.sci.usq.edu.au/staff/dunn
  Email:  dunn @ usq.edu.au
<Insert favourite worthless disclaimer here>



From jeremybutler at paradise.net.nz  Mon Dec 16 05:12:03 2002
From: jeremybutler at paradise.net.nz (Jeremy Z Butler)
Date: Mon Dec 16 05:12:03 2002
Subject: [R] unknown decorana error returned (vegan package)
Message-ID: <1040011904.3dfd5280d21f8@www.paradise.net.nz>

Hi
After trying a simple decorana analysis (from the vegan package) on a simple
data frame which contains no NA's the following error was returned:

> tt_decorana(covN)
Error in decorana(covN) : NA/NaN/Inf in foreign function call (arg 1)

Have any vegan users come across this error and know what can be done about it?
Cheers,
J



From ken_lee at tynesys.com  Mon Dec 16 06:51:03 2002
From: ken_lee at tynesys.com (Ken Lee)
Date: Mon Dec 16 06:51:03 2002
Subject: [R] scan() with "what"
In-Reply-To: <Pine.SOL.4.21.0212150944100.14204-100000@stat1.stat.auckland.ac.nz>
Message-ID: <FFEKIEFDONDECJDODGDJGEHPCDAA.ken_lee@tynesys.com>

Dear,
   coltypes<-rep("character(0)",25)
   x<-scan(file,what=noquote(as.list(coltypes)),sep=",",quiet=TRUE,skip=1)
   names(x)<-scan(file,what="",nlines=1, sep=",") 
   x<-as.data.frame(x)

  I hope it can help you.

Ken

     

-----Original Message-----
From: r-help-admin at stat.math.ethz.ch [mailto:r-help-admin at stat.math.ethz.ch]On Behalf Of Ko-Kang Kevin Wang
Sent: Sunday, December 15, 2002 4:45 AM
To: R Help
Subject: [R] scan() with "what"


Hi,

I have a medium-sized (19MB) CSV file that I'd like to read into R.  The
read.csv() function seems to be a bit inefficient to deal with it, and I
remember that using scan() with "what" options is better.

However I'm unable to understand how to use it.  The first few lines of
the data look like:

USAGE,MILEAGE,SEX,EXCESS,NCD,PRIMAGE,MINAGE,DRIVERS,DISTRICT,CARGROUP,CAR_AGE,WSCLMS,ADCLMS,FTCLMS,PDCLMS,PICLMS,ADINCUR,PDINCUR,WSINCUR,FTINCUR,PIINCUR,RECORD,DAYS,MINAGEN,PRIMAGEN
  SC,7000,M,100,4,59,25,3,4,7,6,0,0,0,,,0,,0,0,,1,85,25,59
  SC,7000,M,100,4,59,59,2,4,13,5,0,0,0,,,0,,0,0,,2,278,59,59
  SC,7000,M,100,4,60,60,2,4,13,5,0,0,0,,,0,,0,0,,3,364,60,60
  SB,10000,M,75,4,53,44,2,3,14,4,1,0,0,0,0,0,0,146.18,0,0,4,364,44,53
  SB,10000,M,75,4,54,45,2,3,14,4,0,0,0,,,0,,0,0,,5,363,45,54

i.e. columns are separated by commas and may contain missing values, and
has headers.

I'd really appreciated it if someone can tell me how to use the
scan() command to read this data in.

Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

Ko-Kang Kevin Wang
Master of Science (MSc) Student
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ligges at statistik.uni-dortmund.de  Mon Dec 16 08:33:04 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Dec 16 08:33:04 2002
Subject: [R] irregual space plot
References: <F76zAKsqKTDHRcXQBfh00004d86@hotmail.com>
Message-ID: <3DFD81B2.9D9C4CC8@statistik.uni-dortmund.de>


Jason Fisher wrote:
> 
> Hello everyone...
> 
> I was hoping an R wizard could help me out with this one.  My current R
> programming endeavors require that I generate plots of groundwater state
> variables (e.g. pressure fields, contaminate plumes, etc.) in a 2-D slice of
> a 3-D system.  While the functions contour() and filled.contour() are close
> to what I?m looking for, they unfortunately lack in their inability to deal
> with irregular boundaries (non-rectangular systems).  The irregular systems
> I?m working with are made up of finite elements (each 2-D element
> constructed from 3 or 4 nodes) where linear basis functions describe every
> point (x,y) in the element.  I believe I could deal with my plotting dilemma
> if I had a function very similar to ?.Internal(filledcontour())?.  A
> function, which would allow me to specify contours or colors between
> contours within an element.  If someone could give me a hand on this project
> or point me towards helpful resources, it would be greatly appreciated.
> 
> Regards,
> 
> Jason
> 
> PS:  If any additional information is needed, please ask.

What about setting non-existing points of your system to NA (will result
in "white space") in that matrix you use for filled.contour()?

Uwe



From michel.arnaud at cirad.fr  Mon Dec 16 08:41:05 2002
From: michel.arnaud at cirad.fr (Michel ARNAUD)
Date: Mon Dec 16 08:41:05 2002
Subject: [R] axes with same scale
References: <FFEKIEFDONDECJDODGDJGEHPCDAA.ken_lee@tynesys.com>
Message-ID: <3DFD81F4.13EF852A@cirad.fr>

Hello
Does anybody know how to draw a plot with same units on each axes ?
For exemple,  if on X the range of value is [1, 2] and on Y the range is [1, 10] I would like the length of Y is  5*the length of  X.
Any suggestions ?

--
Michel ARNAUD
CIRAD TA60/15
73, av. Jean Fran?ois Breton
34938 MONTPELLIER CEDEX 5
tel : 04 67 59 38 34
Fax : 04 67 59 38 38

-------------- next part --------------
A non-text attachment was scrubbed...
Name: michel.arnaud.vcf
Type: text/x-vcard
Size: 204 bytes
Desc: Carte pour Michel ARNAUD
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20021216/53c9e65b/michel.arnaud.vcf

From ligges at statistik.uni-dortmund.de  Mon Dec 16 08:46:03 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Dec 16 08:46:03 2002
Subject: [R] Creating libraries:  Cannot make help
References: <4CE94EAEAD60B744B9263A2C82A9C79219EB1E@alpha.usq.edu.au>
Message-ID: <3DFD8414.824F8256@statistik.uni-dortmund.de>

Peter Dunn wrote:
> 
> Hi all
> 
> I am trying to package a library in R 1.6.1 (Windoze XP).
> 
> I have read the document "Writing R extensions" and think I
> have done things correctly (though apparently not).  I have
> searched the mail archives for help to no avail.
> 
> I also posted a few days ago and thanks to Peter Dalgaard I have
> managed to focus my search for errors.
> 
> I am trying to create a library in R.  I run the INSTALL
> script and installing the R files in the library itself go
> fine; the message is
> 
>   adding build stamp to DESCRIPTION
>   installing R files
> 
> Indeed, after loading the library, I can use these files.
> But creating the help is causing troubles:
> 
>   installing man source files
> make[1]: Leaving directory
> `/cygdrive/d/pkd/research/tweedie/libraries/R/<lib-name>'
> make: *** [pkg-<lib-name>] Error 255
> make: Leaving directory `/cygdrive/d/Programs/R/rw1061/src/gnuwin32'
> 
> *** Installation of <lib-name> failed ***
> 
> And so while the library files work, there is no help available.
> 
> Without knowing Perl or anything, I seem to have found the line in
> the INSTALL script that causes things to die (line break added):
> 
>     if(system("make -C $R_HOME/src/gnuwin32 PKGDIR=$pkgdir
>        RLIB=$library SAVE=$save $helpflags $makecmd-$pkgname")){
> 
> If I run this command in a Cygwin window, 


In a *cygwin* window? In think compiling in a cygwin shell is not
documented to work. 
Please try to compile from a windows command shell.




> expanding the variable names,
> I get this (abbreviated, editted) message:
> 
> ---------- Making package <lib-name> ------------
> mkdir -p d:/Programs/R/rw1061/library/<lib-name>
> cp -r   ./INDEX  ./TITLE ./contents ./index.bak
> d:/Programs/R/rw1061/library/<lib-name>/
>   adding build stamp to DESCRIPTION
> make[1]: Leaving directory `/cygdrive/<path>/libraries/R/<lib-name>'
> make[1]: Entering directory
> `/cygdrive/d/Programs/R/rw1061/src/gnuwin32/help'
> Makefile:42: *** missing separator.  Stop.

Is your MkRules file edited appropriately (see
.../src/gnuwin32/readme.packages for a note on preserving tabs in
MkRules)?



> make[1]: Leaving directory
> `/cygdrive/d/Programs/R/rw1061/src/gnuwin32/help'
> make: *** [pkg-<lib-name>] Error 2
> make: Leaving directory `/cygdrive/d/Programs/R/rw1061/src/gnuwin32'
> 
> It indicates a missing separator.  But my knowledge of Perl and
> Makefiles
> is basically zip (apart from what I learnt to get this far).
> 
> My running the appropriate commands my self, I can generate, eg, html
> files so there is nothing wrong with my  sgml  source files.  But
> running
> the INSTALL script fails to create anything help-ful.
>
> Can anyone help me sort out what I am doing wrong or why I am getting
> these
> messages?

Additionally to the things mentioned above: Please follow
readme.packages exactly (i.e. install *all* the tools mentioned in
there).

Uwe Ligges


> P.
> 
> Dr Peter Dunn          (USQ CRICOS No. 00244B)
>   Web:    http://www.sci.usq.edu.au/staff/dunn
>   Email:  dunn @ usq.edu.au
> <Insert favourite worthless disclaimer here>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ligges at statistik.uni-dortmund.de  Mon Dec 16 08:53:02 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Dec 16 08:53:02 2002
Subject: [R] axes with same scale
References: <FFEKIEFDONDECJDODGDJGEHPCDAA.ken_lee@tynesys.com> <3DFD81F4.13EF852A@cirad.fr>
Message-ID: <3DFD8650.D768B11D@statistik.uni-dortmund.de>


Michel ARNAUD wrote:
> 
> Hello
> Does anybody know how to draw a plot with same units on each axes ?
> For exemple,  if on X the range of value is [1, 2] and on Y the range is [1, 10] I would like the length of Y is  5*the length of  X.
> Any suggestions ?

Does plot(...., asp = 1) help?
For details see ?plot.default and ?plot.window.

Uwe Ligges


 
> --
> Michel ARNAUD
> CIRAD TA60/15
> 73, av. Jean Fran?ois Breton
> 34938 MONTPELLIER CEDEX 5
> tel : 04 67 59 38 34
> Fax : 04 67 59 38 38



From ripley at stats.ox.ac.uk  Mon Dec 16 08:58:07 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Dec 16 08:58:07 2002
Subject: [R] axes with same scale
In-Reply-To: <3DFD81F4.13EF852A@cirad.fr>
Message-ID: <Pine.LNX.4.31.0212160755200.27118-100000@gannet.stats>

On Mon, 16 Dec 2002, Michel ARNAUD wrote:

> Does anybody know how to draw a plot with same units on each axes ?
> For exemple,  if on X the range of value is [1, 2] and on Y the range is [1, 10] I would like the length of Y is  5*the length of  X.
> Any suggestions ?

1) use eqscplot in package MASS

2) use argument `asp' (documented in ?plot.window)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jarioksa at sun3.oulu.fi  Mon Dec 16 09:05:03 2002
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Mon Dec 16 09:05:03 2002
Subject: [R] unknown decorana error returned (vegan package) 
In-Reply-To: Message from Jeremy Z Butler <jeremybutler@paradise.net.nz> 
   of "Mon, 16 Dec 2002 17:11:44 +1300." <1040011904.3dfd5280d21f8@www.paradise.net.nz> 
Message-ID: <200212160804.gBG84UB09116@pc112145.oulu.fi>

Dear Jeremy,

`vegan' is a little known add-on package for a special group of users.
Contacting its author directly might be more useful than broadcasting the whole
R mailing list.

Then to the problem: This is an error that occurs (at least) when you have 
all-zero rows or columns in your data set: 

> decorana(rbind(varespec, rep(0, ncol(varespec))))
Error in decorana(rbind(varespec, rep(0, ncol(varespec)))) : 
	NA/NaN/Inf in foreign function call (arg 1)

So check your data for column and row sums, and remove the empty columns and 
rows (arguably decorana should check this and fail more informatively than now).

Decorana implements a peculiar variant of Correspondence Analysis. CA can
handle only non-negative matrix values and all marginal totals must be above
zero. The name you use for your matrix (covN) sounds like you might have a
covariance matrix which cannot be handled by correspondence analysis at all.
With the information you posted, I cannot give any better guesses.

cheers, jari oksanen
-- 
Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
Ph. +358 8 5531526, cell +358 40 5136529, fax +358 8 5531061
email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/



From Olof.Leimar at zoologi.su.se  Mon Dec 16 09:34:03 2002
From: Olof.Leimar at zoologi.su.se (Olof Leimar)
Date: Mon Dec 16 09:34:03 2002
Subject: [R] Interpretation of hypothesis tests for mixed models
In-Reply-To: <6r1y4jw017.fsf@bates5.stat.wisc.edu>
References: <1039955040.1113.13.camel@plantago>
	 <6r1y4jw017.fsf@bates5.stat.wisc.edu>
Message-ID: <1040027639.1116.113.camel@plantago>

Thanks for setting me straight about the model

> fm1 <- lme(y ~ Trt, random = list(Subj = pdCompSymm(~ Trt - 1)))

being the one that is equivalent to

> fm2 <- lme(y ~ Trt, random = ~ 1 | Subj/Trt)

It seems that denDF of a fixed effect test for treatment should also be
the same for fm1 and fm2. Is it possible to modify the method of
computing denDF in nlme to achive this? 

Meanwhile, my understanding is that fm2 is to be preferred over fm1. I
did simulations for fm1/fm2 with no true (fixed) difference between
treatments, which seemed to show that a test with the fm1 formulation
can sometimes produce considerably more statistical significances than
would be warranted. 

I then have another question. How should I go about formulating a model
corresponding to the nesting in fm2 if instead of a treatment factor I
have a covariate? Since in my example Trt was a two-level factor, one
could for instance let the levels be zero and one and regard the
treatment as a covariate. If I express the treatment as a covariate x
and fit

> fm4 <- lme(y ~ x, random = ~ 1 | Subj/x)

I get the same denDF as for fm2, but for a general covariate (with more
than two values) denDF depends on the number of distinct values taken by
the covariate (but it should not, should it?). It seems that random = ~
1 | Subj/x treats x as a a factor. Is there another model formulation
that takes care of this problem? 

More generally, if I have complex terms, like a treatment by covariate
interaction, for which I suspect random subject components, how can I
formulate a mixed model so that denDF properly takes into account the
nested random effects?

-- 
Olof Leimar, Professor
Department of Zoology
Stockholm University
SE-106 91 Stockholm
Sweden

Olof.Leimar at zoologi.su.se



From laurent at cbs.dtu.dk  Mon Dec 16 09:40:04 2002
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Mon Dec 16 09:40:04 2002
Subject: [R] Compiling R under IBM-AIX using IBM native C-compiler
Message-ID: <20021216083419.GE131658357@genome.cbs.dtu.dk>

Would anybody have any experience with that ?
(that's the first time I use AIX)
The configure step is incredibly slow... any hint ?


L.



From y.m.al-tawarah at maths.keele.ac.uk  Mon Dec 16 10:22:06 2002
From: y.m.al-tawarah at maths.keele.ac.uk (Yasin Al-Tawarah)
Date: Mon Dec 16 10:22:06 2002
Subject: [R] help
Message-ID: <3DFA1237.510BACD0@maths.keele.ac.uk>

Hi
I download the R, but I dont know how to get the script (syntax) file
and run it.
I would be very pleased for any help.
Regards.
Yasin


--

Yasin Al-tawarah

Tel: (01782) 583652
E-mail: mad26 at keele.ac.uk



From zeileis at ci.tuwien.ac.at  Mon Dec 16 11:04:08 2002
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Mon Dec 16 11:04:08 2002
Subject: [R] new package "vcd" 0.1-3
Message-ID: <3DFDA500.384A8908@ci.tuwien.ac.at>

Dear R users,

there is a new package on CRAN called `vcd' for visualizing categorical
data. It basically implements a set of visualization techniques together
with a large collection of data sets and examples from the book
"Visualizing Categorical Data" by Michael Friendly. By now the features
of the package essentially cover chapters 2-4 from the book:
  o fitting and graphing discrete distributions:
    goodness-of-fit tests for poisson, binomial and negative binomial
    distribution; rootograms; Ord plots; poissonness plots.
  o 2-way contingency tables:
    improved fourfold displays (compared to base); trilinear plots;
    sieve diagrams, agreement charts.
  o mosaic displays for n-way tables:
    improved mosaicplots (compared to base); mosaic matrices.
We work on extensions enhancing several functions so this is very much
work-in-progress, but we wanted to provide a first version which already
offers a lot of functionality. Furthermore we intend to implement
further visualization tools for categorical data, in particular for
loglinear models.
The DESCRIPTION of the package is given below.
Best wishes,
Achim Zeileis


Package: vcd
Version: 0.1-3
Date: 2002-11-22
Title: Visualizing Categorical Data
Author: David Meyer, Achim Zeileis, Alexandros Karatzoglou, Kurt Hornik
Maintainer: Kurt Hornik <Kurt.Hornik at R-project.org>
Description: Functions and data sets based on the book "Visualizing
             Categorical Data" by Michael Friendly.
License: GPL
Depends: R(>= 1.4.0), MASS, ctest



From eia018 at comp.lancs.ac.uk  Mon Dec 16 12:39:02 2002
From: eia018 at comp.lancs.ac.uk (Dr Andrew Wilson)
Date: Mon Dec 16 12:39:02 2002
Subject: [R] Partial Sums
Message-ID: <Pine.GSO.4.21.0212161129490.27372-100000@austin>

Is it possible to calculate partial sums in R?

I have the equation:

Px  =  (k / x) * SUM_{from j >= x to infinity} Pj             x=1,2,3,...

where k is a parameter, Pj is the Poisson probability, and x is a rank.
(This is for rank-frequency data.)  In other words, the frequency of an
entity at rank x depends on the sum of frequencies of all entities at
ranks j > x.

Many thanks,
Andrew Wilson



From p.dalgaard at biostat.ku.dk  Mon Dec 16 13:13:07 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon Dec 16 13:13:07 2002
Subject: [R] Partial Sums
In-Reply-To: <Pine.GSO.4.21.0212161129490.27372-100000@austin>
References: <Pine.GSO.4.21.0212161129490.27372-100000@austin>
Message-ID: <x2vg1uyxej.fsf@biostat.ku.dk>

Dr Andrew Wilson <eia018 at comp.lancs.ac.uk> writes:

> Is it possible to calculate partial sums in R?
> 
> I have the equation:
> 
> Px  =  (k / x) * SUM_{from j >= x to infinity} Pj             x=1,2,3,...
> 
> where k is a parameter, Pj is the Poisson probability, and x is a rank.
> (This is for rank-frequency data.)  In other words, the frequency of an
> entity at rank x depends on the sum of frequencies of all entities at
> ranks j > x.

With some restriction on k and the Poisson intensity lambda, I presume?

How about

  k/x * (1-ppois(x-1,lambda))

or am I overlooking something??

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Morten.Sickel at nrpa.no  Mon Dec 16 13:40:04 2002
From: Morten.Sickel at nrpa.no (Morten Sickel)
Date: Mon Dec 16 13:40:04 2002
Subject: [R] Command line parameters to a script
Message-ID: <54DE9A561AD20C4D9FF88B116965420E4E5CCA@postix.nrpa.no>

I am using R quite a lot for reading data from a db and plotting them. I
often have to make different language versions of my plots, i.e. in
Norwegian and English. In stead of making and maintaining two different
versions of the script files, I am looking for a variable within the script,
e.g.:

  if (lang=='N') {
	"Utslipp (TBq/?r)"->yrtext } else {
	"Releases (TBq/year)"->yrtext }

Then I can set lang to N to get the Norwegian version or to something else
to get the english labels. To avoid a crash when I have not set lang, I also
need

  if (length(objects(pattern='lang'))==0) 'E'-> lang

early in the script. 

I would like to know if there are any other possibilities for sending
'command line parameters' to a script? Although the present way of doing it
works, it feels like a kludge. If not, are there any other way to check for
the existence of an object with a give name?

Morten

-- 
Morten Sickel
Norwegian Radiation Protection Authority
http://www.nrpa.no



From maechler at stat.math.ethz.ch  Mon Dec 16 14:19:07 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon Dec 16 14:19:07 2002
Subject: [R] axes with same scale
In-Reply-To: <3DFD81F4.13EF852A@cirad.fr>
References: <3DFD81F4.13EF852A@cirad.fr>
Message-ID: <15869.53577.265422.892150@gargle.gargle.HOWL>

>>>>> "Michel" == Michel ARNAUD <michel.arnaud at cirad.fr>
>>>>>     on Mon, 16 Dec 2002 08:34:12 +0100 writes:

[by replying to another R-help message.
 ***Please don't do this!***
 It destroys sensible threading! Please search "Michel Arnoud" in the archive,
 https://www.stat.math.ethz.ch/pipermail/r-help/2002-December/thread.html
 to see the the wrong thread your message is in!]

    Michel> Hello Does anybody know how to draw a plot with same
    Michel> units on each axes ?  For exemple, if on X the range
    Michel> of value is [1, 2] and on Y the range is [1, 10] I
    Michel> would like the length of Y is 5*the length of X.
    Michel> Any suggestions ?

Use  plot(.....,  asp = 1) ## asp = [aspect ratio] = 1
This is explained a bit in  help(plot.default)

An older alternative that also works in S-PLUS is
 library(MASS)
 eqscplot(.....)

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From e.pebesma at geog.uu.nl  Mon Dec 16 14:50:03 2002
From: e.pebesma at geog.uu.nl (Edzer J. Pebesma)
Date: Mon Dec 16 14:50:03 2002
Subject: [R] %% in \example{}
Message-ID: <3DFDD9F2.34FB541B@geog.uu.nl>

I would like to use the %% operator in the \example{} section of a R
documentation
file, but it leads to errors when this is processed.

How should I do this?
--
Edzer



From pgilbert at bank-banque-canada.ca  Mon Dec 16 16:06:03 2002
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Mon Dec 16 16:06:03 2002
Subject: [R] compiling R with gcc 3.2 on Solaris
Message-ID: <3DFDEB66.690B2542@bank-banque-canada.ca>

I am trying to compile R 1.6.1 with gcc 3.2 on Solaris (Sun OS 5.8) and
configure gives me:

checking whether g77 and gcc agree on int and double... configure: WARNING: g77
and gcc disagree on int and double
configure: error: Maybe change CFLAGS or FFLAGS?

Complete output from configure is below. I am not setting CFLAGS or FFLAGS, but
can someone suggest what I should set them to (or is this some other problem)?

Also, the reason I am trying gcc 3.2 is to use -m64. Do I need to specify this
explicitly or will configure choose that automatically?

Thanks,
Paul Gilbert
_______

[21] /home/com1/gilp/toolchain/R/zot2 : cd R-1.6.1
[22] /home/com1/gilp/toolchain/R/zot2/R-1.6.1 : gcc --version          
gcc (GCC) 3.2
Copyright (C) 2002 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

[23] /home/com1/gilp/toolchain/R/zot2/R-1.6.1 : g77 --version
GNU Fortran (GCC 3.2) 3.2 20020814 (release)
Copyright (C) 2002 Free Software Foundation, Inc.

GNU Fortran comes with NO WARRANTY, to the extent permitted by law.
You may redistribute copies of GNU Fortran
under the terms of the GNU General Public License.
For more information about these matters, see the file named COPYING
or type the command `info -f g77 Copying'.
[24] /home/com1/gilp/toolchain/R/zot2/R-1.6.1 : ./configure
checking for a BSD-compatible install... tools/install-sh -c
checking whether build environment is sane... yes
checking whether make sets ${MAKE}... yes
checking for working aclocal-1.4... missing
checking for working autoconf... found
checking for working automake-1.4... missing
checking for working autoheader... found
checking for working makeinfo... found
checking build system type... sparc-sun-solaris2.8
checking host system type... sparc-sun-solaris2.8
loading site script ./config.site
loading build specific script ./config.site
checking for pwd... /usr/bin/pwd
checking whether builddir is srcdir... yes
checking for gawk... no
checking for mawk... no
checking for nawk... nawk
checking whether ln -s works... yes
checking for ranlib... ranlib
checking for bison... no
checking for byacc... no
checking for ar... ar
checking for javac... /usr/bin/javac
checking for less... /usr/bin/less
checking for perl... /home/mfa/gilp/bin/perl
checking whether perl version is at least 5.005... yes
checking for dvips... /apps/asd/unix/gnu/bin/dvips
checking for tex... /apps/asd/unix/gnu/bin/tex
checking for latex... /apps/asd/unix/gnu/bin/latex
checking for makeindex... /home/mfa/gilp/SunOS-5.8/bin/makeindex
checking for pdftex... /home/mfa/gilp/SunOS-5.8/bin/pdftex
checking for pdflatex... /apps/asd/unix/gnu/bin/pdflatex
checking for makeinfo... /apps/asd/unix/gnu/bin/makeinfo
checking for unzip... /usr/bin/unzip
checking for zip... /usr/bin/zip
checking for gcc... gcc
checking for C compiler default output... a.out
checking whether the C compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables... 
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for ld used by GCC... /usr/ccs/bin/ld
checking if the linker (/usr/ccs/bin/ld) is GNU ld... no
checking for /usr/ccs/bin/ld option to reload object files... -r
checking for BSD-compatible nm... /home/mfa/gilp/SunOS-5.8/bin/nm -B
checking how to recognise dependant libraries... pass_all
checking command to parse /home/mfa/gilp/SunOS-5.8/bin/nm -B output... ok
checking how to run the C preprocessor... gcc -E
checking for ANSI C header files... yes
checking for sys/types.h... yes
checking for sys/stat.h... no
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... no
checking for unistd.h... yes
checking dlfcn.h usability... yes
checking dlfcn.h presence... yes
checking for dlfcn.h... yes
checking for ranlib... (cached) ranlib
checking for strip... strip
checking for objdir... .libs
checking for gcc option to produce PIC... -fPIC
checking if gcc PIC flag -fPIC works... yes
checking if gcc static flag -static works... yes
checking if gcc supports -c -o file.o... yes
checking if gcc supports -c -o file.lo... yes
checking if gcc supports -fno-rtti -fno-exceptions... yes
checking whether the linker (/usr/ccs/bin/ld) supports shared libraries... yes
checking how to hardcode library paths into programs... immediate
checking whether stripping libraries is possible... yes
checking dynamic linker characteristics... solaris2.8 ld.so
checking if libtool supports shared libraries... yes
checking whether to build shared libraries... yes
checking whether to build static libraries... no
creating libtool
checking whether makeinfo version is at least 4... no
configure: WARNING: you cannot build info versions of the R manuals
checking for netscape... /apps/mfa/bin/netscape
checking for gcc... (cached) gcc
checking whether we are using the GNU C compiler... (cached) yes
checking whether gcc accepts -g... (cached) yes
checking for gcc option to accept ANSI C... none needed
checking whether gcc needs -traditional... no
checking how to run the C preprocessor... gcc -E
checking for g77... g77
checking whether we are using the GNU Fortran 77 compiler... yes
checking whether g77 accepts -g... yes
checking for g++... g++
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
checking how to run the C++ preprocessor... g++ -E
checking for main in -lm... yes
checking for sin in -lm... yes
checking for main in -lncurses... no
checking for main in -ltermcap... yes
checking for dlopen in -ldl... yes
checking for rl_callback_read_char in -lreadline... no
checking for ANSI C header files... (cached) yes
checking whether time.h and sys/time.h may both be included... yes
checking for dirent.h that defines DIR... yes
checking for library containing opendir... none required
checking for sys/wait.h that is POSIX.1 compatible... yes
checking arpa/inet.h usability... yes
checking arpa/inet.h presence... yes
checking for arpa/inet.h... yes
checking dl.h usability... no
checking dl.h presence... no
checking for dl.h... no
checking for dlfcn.h... (cached) yes
checking elf.h usability... yes
checking elf.h presence... yes
checking for elf.h... yes
checking fcntl.h usability... yes
checking fcntl.h presence... yes
checking for fcntl.h... yes
checking floatingpoint.h usability... yes
checking floatingpoint.h presence... yes
checking for floatingpoint.h... yes
checking fpu_control.h usability... no
checking fpu_control.h presence... no
checking for fpu_control.h... no
checking grp.h usability... yes
checking grp.h presence... yes
checking for grp.h... yes
checking ieee754.h usability... no
checking ieee754.h presence... no
checking for ieee754.h... no
checking ieeefp.h usability... yes
checking ieeefp.h presence... yes
checking for ieeefp.h... yes
checking locale.h usability... yes
checking locale.h presence... yes
checking for locale.h... yes
checking netdb.h usability... yes
checking netdb.h presence... yes
checking for netdb.h... yes
checking netinet/in.h usability... yes
checking netinet/in.h presence... yes
checking for netinet/in.h... yes
checking pwd.h usability... yes
checking pwd.h presence... yes
checking for pwd.h... yes
checking readline/history.h usability... no
checking readline/history.h presence... no
checking for readline/history.h... no
checking readline/readline.h usability... no
checking readline/readline.h presence... no
checking for readline/readline.h... no
checking for strings.h... (cached) yes
checking sys/param.h usability... yes
checking sys/param.h presence... yes
checking for sys/param.h... yes
checking sys/select.h usability... yes
checking sys/select.h presence... yes
checking for sys/select.h... yes
checking sys/socket.h usability... yes
checking sys/socket.h presence... yes
checking for sys/socket.h... yes
checking for sys/stat.h... (cached) no
checking sys/time.h usability... yes
checking sys/time.h presence... yes
checking for sys/time.h... yes
checking sys/times.h usability... yes
checking sys/times.h presence... yes
checking for sys/times.h... yes
checking sys/utsname.h usability... yes
checking sys/utsname.h presence... yes
checking for sys/utsname.h... yes
checking for unistd.h... (cached) yes
checking errno.h usability... yes
checking errno.h presence... yes
checking for errno.h... yes
checking stdarg.h usability... yes
checking stdarg.h presence... yes
checking for stdarg.h... yes
checking for string.h... (cached) yes
checking whether setjmp.h is POSIX.1 compatible... yes
checking for GNU C library with version >= 2... no
checking return type of signal handlers... void
checking for pid_t... yes
checking for size_t... yes
checking for blkcnt_t... yes
checking for type of socket length... socklen_t *
checking whether byte ordering is bigendian... yes
checking for an ANSI C-conforming const... yes
checking for int... yes
checking size of int... 4
checking for long... yes
checking size of long... 4
checking for long long... yes
checking size of long long... 8
checking for long double... yes
checking size of long double... 16
checking whether gcc accepts -M for generating dependencies... yes
checking whether gcc supports -c -o FILE.lo... yes
checking how to get verbose linking output from g77... -v
checking for Fortran 77 libraries...  -L/usr/ccs/lib -L/usr/lib -L/usr/local/lib
-L/apps/asd/unix/gnu/gcc/3.2/SunOS5.8/lib/gcc-lib
-L/apps/asd/unix/gnu/gcc/3.2/install/lib/gcc-lib/sparc-sun-solaris2.6/3.2
-L/usr/ccs/bin
-L/apps/asd/unix/gnu/gcc/3.2/install/lib/gcc-lib/sparc-sun-solaris2.6/3.2/../../..
-ldl -ltermcap -lfrtbegin -lg2c -lm -lgcc_s
checking for dummy main to link with Fortran 77 libraries... none
checking for Fortran 77 name-mangling scheme... lower case, underscore, extra
underscore
checking whether g77 and gcc agree on int and double... configure: WARNING: g77
and gcc disagree on int and double
configure: error: Maybe change CFLAGS or FFLAGS?
[25] /home/com1/gilp/toolchain/R/zot2/R-1.6.1 :



From ripley at stats.ox.ac.uk  Mon Dec 16 16:17:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Dec 16 16:17:03 2002
Subject: [R] compiling R with gcc 3.2 on Solaris
In-Reply-To: <3DFDEB66.690B2542@bank-banque-canada.ca>
Message-ID: <Pine.LNX.4.31.0212161514080.14708-100000@gannet.stats>

On Mon, 16 Dec 2002, Paul Gilbert wrote:

> I am trying to compile R 1.6.1 with gcc 3.2 on Solaris (Sun OS 5.8) and
> configure gives me:
>
> checking whether g77 and gcc agree on int and double... configure: WARNING: g77
> and gcc disagree on int and double
> configure: error: Maybe change CFLAGS or FFLAGS?
>
> Complete output from configure is below. I am not setting CFLAGS or FFLAGS, but
> can someone suggest what I should set them to (or is this some other problem)?

You need to make sure Fortran is working, and for g77 that needs
/usr/local/lib in LD_LIBRARY_PATH.

> Also, the reason I am trying gcc 3.2 is to use -m64. Do I need to specify this
> explicitly or will configure choose that automatically?

See R-admin.texi for how to do this ... (and for the above, at least in
the current versions).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Dec 16 16:21:13 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Dec 16 16:21:13 2002
Subject: [R] %% in \example{}
In-Reply-To: <3DFDD9F2.34FB541B@geog.uu.nl>
Message-ID: <Pine.LNX.4.31.0212161516310.14708-100000@gannet.stats>

On Mon, 16 Dec 2002, Edzer J. Pebesma wrote:

> I would like to use the %% operator in the \example{} section of a R
> documentation
> file, but it leads to errors when this is processed.
>
> How should I do this?

Read the manual, `Writing R Extensions' in this case:

The ``comment'' and ``control'' characters @samp{%} and @samp{\}
@emph{always} need to be escaped.  Inside the verbatim-like commands
(@code{\code} and @code{\examples}), no other characters are special

so it's \%\% you need to write.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tlumley at u.washington.edu  Mon Dec 16 16:33:05 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon Dec 16 16:33:05 2002
Subject: [R] Compiling R under IBM-AIX using IBM native C-compiler
In-Reply-To: <20021216083419.GE131658357@genome.cbs.dtu.dk>
Message-ID: <Pine.A41.4.44.0212160727270.158328-100000@homer05.u.washington.edu>

On Mon, 16 Dec 2002, Laurent Gautier wrote:

> Would anybody have any experience with that ?
> (that's the first time I use AIX)
> The configure step is incredibly slow... any hint ?
>

It seems to depend on exactly what AIX you have.  With 4.3 on RS/6000
hardware I can compile with either gcc or the native tools (though not
with a mixture of the two). The configure and build is very slow, and is
even worse with gcc.   I don't actually *use* R on AIX, but it does pass
make check.  There are also some R users on AIX at CMU, I believe.

OTOH, someone has reported problems with a more modern AIX on PowerPC
hardware.

	-thomas



From bates at stat.wisc.edu  Mon Dec 16 16:47:03 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon Dec 16 16:47:03 2002
Subject: [R] Interpretation of hypothesis tests for mixed models
In-Reply-To: <1040027639.1116.113.camel@plantago>
References: <1039955040.1113.13.camel@plantago>
	<6r1y4jw017.fsf@bates5.stat.wisc.edu>
	<1040027639.1116.113.camel@plantago>
Message-ID: <6r1y4iklvs.fsf@bates5.stat.wisc.edu>

Olof Leimar <Olof.Leimar at zoologi.su.se> writes:

> Thanks for setting me straight about the model
> 
> > fm1 <- lme(y ~ Trt, random = list(Subj = pdCompSymm(~ Trt - 1)))
> 
> being the one that is equivalent to
> 
> > fm2 <- lme(y ~ Trt, random = ~ 1 | Subj/Trt)
> 
> It seems that denDF of a fixed effect test for treatment should also be
> the same for fm1 and fm2. Is it possible to modify the method of
> computing denDF in nlme to achive this? 

That would require a complete redesign and rewrite of the
corresponding part of the nlme package.  As described on p. 91 of
Pinheiro and Bates (2000) the denominator degrees of freedom are
calculated according to the number observations and the number of
groups at each level of random effects.  For fm2 there are three
choices while for fm1 there are only two.

It happens that the models are equivalent but discovering that
equivalence within the model-fitting function would be extremely
difficult.  The different formulations will result in different
denominator degrees of freedom in the current formulation.
Contributions of code that uses alternative formulations are welcome.
For example SAS PROC MIXED has both containment and Satterthwaite
options.

> Meanwhile, my understanding is that fm2 is to be preferred over fm1. I
> did simulations for fm1/fm2 with no true (fixed) difference between
> treatments, which seemed to show that a test with the fm1 formulation
> can sometimes produce considerably more statistical significances than
> would be warranted. 

I don't understand this.  In my previous reply I showed an example
using the Machines data.  I reproduce it here with the numbering you
use (fm1 is the model with pdCompSymm and one level of random effects,
fm2 uses nested random effects)

> library(nlme)
Loading required package: nls 
Loading required package: lattice 
> data(Machines)
> fm1 <- lme(score ~ Machine, data = Machines, 
+            random = list(Worker = pdCompSymm(~ Machine - 1)))
> fm2 <- lme(score ~ Machine, data = Machines, random = ~ 1 | Worker/Machine)
> summary(fm1)$tTable
                Value Std.Error DF   t-value      p-value
(Intercept) 52.355556  2.485416 46 21.065106 2.903585e-25
MachineB     7.966667  2.177416 46  3.658770 6.505878e-04
MachineC    13.916667  2.177416 46  6.391367 7.483288e-08
> summary(fm2)$tTable
                Value Std.Error DF   t-value      p-value
(Intercept) 52.355556  2.485829 36 21.061606 7.844348e-22
MachineB     7.966667  2.176974 10  3.659514 4.392617e-03
MachineC    13.916667  2.176974 10  6.392665 7.906445e-05

In these results the estimates and standard errors are the same but
the denominator degrees of freedom in fm2 are smaller than those in
fm1.  That would always be the case so the F- and t-tests from fm2
would be more conservative than those from fm1.

> I then have another question. How should I go about formulating a model
> corresponding to the nesting in fm2 if instead of a treatment factor I
> have a covariate? Since in my example Trt was a two-level factor, one
> could for instance let the levels be zero and one and regard the
> treatment as a covariate. If I express the treatment as a covariate x
> and fit
> 
> > fm4 <- lme(y ~ x, random = ~ 1 | Subj/x)
> 
> I get the same denDF as for fm2, but for a general covariate (with more
> than two values) denDF depends on the number of distinct values taken by
> the covariate (but it should not, should it?). 

I'm sorry but I have no idea what you are trying to do.  If x is a
covariate the only models that would make sense to me are

 lme(y ~ x, random = ~ 1 | Subj)

and 
 
 lme(y ~ x, random = ~ x | Subj)



From Ko-Kang at xtra.co.nz  Mon Dec 16 19:23:03 2002
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Mon Dec 16 19:23:03 2002
Subject: [R] help
References: <3DFA1237.510BACD0@maths.keele.ac.uk>
Message-ID: <005201c2a52f$f40e50a0$f22037d2@kwan022>

Hi,

I'm not sure if I get your meaning, but if I'm right you have a script
file -- a file with a couple of R commands, that you want to run in BATCH
mode?

Depending on your OS, on Windows, you can open a command line window, cd
into the directory containing your script file.  Make sure $R_HOME\bin is in
your PATH.  It is usually C:\Program Files\R\rw1061\bin.  Then type:
   Rcmd BATCH file.R
which will produce a file.Rout containing the results.

On Linux/Unix, simply do
  R CMD BATCH file.R

I'm not sure about Mac though.

Cheers,

Kevin

------------------------------------------------
Ko-Kang Kevin Wang
Master of Science (MSc) Student
Department of Statistics
University of Auckland
New Zealand
www.stat.auckland.ac.nz/~kwan022

----- Original Message -----
From: "Yasin Al-Tawarah"
<y.m.al-tawarah at maths.keele.ac.uk>
To: "R-help" <R-help at stat.math.ethz.ch>
Sent: Saturday, December 14, 2002 6:00 AM
Subject: [R] help


> Hi
> I download the R, but I dont know how to get the script (syntax) file
> and run it.
> I would be very pleased for any help.
> Regards.
> Yasin
>
>
> --
>
> Yasin Al-tawarah
>
> Tel: (01782) 583652
> E-mail: mad26 at keele.ac.uk
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



********************************************



From jake.luciani at riskmetrics.com  Mon Dec 16 19:34:06 2002
From: jake.luciani at riskmetrics.com (T Jake Luciani)
Date: Mon Dec 16 19:34:06 2002
Subject: [R] New SVG Graphics Device for R
Message-ID: <200212161320.33134.jake.luciani@riskmetrics.com>

Hello,

	I just released a Graphics Device for R >= 1.4 which outputs w3 compliant 
SVG.  I Have also created a Java 1.1 applet which can render and manipulate 
the SVG generated from the graphics device.  

Please visit http://www.darkridge.com/~jake/RSvg/ for more info

Thanks,

T Jake Luciani



From york at noaa.gov  Mon Dec 16 20:07:02 2002
From: york at noaa.gov (Anne York)
Date: Mon Dec 16 20:07:02 2002
Subject: [R] applying a different function to rows of a dataframe
Message-ID: <Pine.GSO.4.05.10212161039230.8654-100000@ofis450a.akctr.noaa.gov>

Here is a simple example of what I would like to do:

Given a data frame foo with variables x and fn. Suppose fn is a vector of
characters which correspond to  names of previously defined  functions
which have only one argument. I would like a vector returned where fn is
applied to x

foo <-  data.frame(x=c(2,5,7), fn = letters[c(6,7,6)])
foo$fn <- as.character(foo$fn)

 "f" <- function(x){17*x}
 "g" <- function(x){3*x}


foo
  x fn
1 2  f
2 5  g
3 7  f

wanted:  a function which returns c(f(2),g(5),f(7)) = c(34, 15, 119)

A simple application of do.call doesn't do what I need (it applies the
function f to each x): 

> do.call(foo$fn,args=list(x = foo$x))
[1]  34  85 119

Whereas the following works but seems like overkill.

> diag(sapply(foo$fn,do.call,args=list(x=foo$x)))
[1]  34  15 119

Another idea that didn't work:

 do.call("evalq",args =list(paste(foo$fn,"(foo$x)",sep="")))
[1] "f(foo$x)" "g(foo$x)" "f(foo$x)"

Thanks in advance
Anne

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Anne E. York
National Marine Mammal Laboratory
Seattle WA 98115-0070  USA
e-mail: anne.york at noaa.gov
Voice: +1 206-526-4039
Fax: +1 206-526-6615
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From ripley at stats.ox.ac.uk  Mon Dec 16 20:19:02 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Dec 16 20:19:02 2002
Subject: [R] applying a different function to rows of a dataframe
In-Reply-To: <Pine.GSO.4.05.10212161039230.8654-100000@ofis450a.akctr.noaa.gov>
Message-ID: <Pine.LNX.4.31.0212161913410.16193-100000@gannet.stats>

Looks to me like you want

sapply(1:nrow(foo), function(i) get(foo$fn[i])(foo$x[i]))

or the equivalent for loop.

On Mon, 16 Dec 2002, Anne York wrote:

> Here is a simple example of what I would like to do:
>
> Given a data frame foo with variables x and fn. Suppose fn is a vector of
> characters which correspond to  names of previously defined  functions
> which have only one argument. I would like a vector returned where fn is
> applied to x
>
> foo <-  data.frame(x=c(2,5,7), fn = letters[c(6,7,6)])
> foo$fn <- as.character(foo$fn)
>
>  "f" <- function(x){17*x}
>  "g" <- function(x){3*x}
>
>
> foo
>   x fn
> 1 2  f
> 2 5  g
> 3 7  f
>
> wanted:  a function which returns c(f(2),g(5),f(7)) = c(34, 15, 119)
>
> A simple application of do.call doesn't do what I need (it applies the
> function f to each x):
>
> > do.call(foo$fn,args=list(x = foo$x))
> [1]  34  85 119
>
> Whereas the following works but seems like overkill.
>
> > diag(sapply(foo$fn,do.call,args=list(x=foo$x)))
> [1]  34  15 119
>
> Another idea that didn't work:
>
>  do.call("evalq",args =list(paste(foo$fn,"(foo$x)",sep="")))
> [1] "f(foo$x)" "g(foo$x)" "f(foo$x)"
>
> Thanks in advance
> Anne
>
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> Anne E. York
> National Marine Mammal Laboratory
> Seattle WA 98115-0070  USA
> e-mail: anne.york at noaa.gov
> Voice: +1 206-526-4039
> Fax: +1 206-526-6615
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From SMarkandsusan at aol.com  Mon Dec 16 21:08:02 2002
From: SMarkandsusan at aol.com (SMarkandsusan@aol.com)
Date: Mon Dec 16 21:08:02 2002
Subject: [R] Manipulating the output from read.spss
Message-ID: <1a1.d7e7b6a.2b2f8c05@aol.com>

This seems like a problem that others may have run into before. I got a 
merged dataset from SPSS. It has ~750 columns X 3400 rows. Most of the cell 
entries are NA. There are about 375 rows that contain observations on all 
variables and I want to extract this subset from the original list (of 
lists). I'm pretty sure I can do it programmatically in R but it will take me 
a few hours to write and debug. Before I start down that road I thought I'd 
ask if anyone had already tackled this particular type problem already.
Thanks a lot,
Mark Schultz



From ozric at web.de  Mon Dec 16 21:13:03 2002
From: ozric at web.de (Christian Schulz)
Date: Mon Dec 16 21:13:03 2002
Subject: [R] New SVG Graphics Device for R
References: <200212161320.33134.jake.luciani@riskmetrics.com>
Message-ID: <000b01c2a53e$661ff140$e70206d5@c5c9i0>

... really a nice tool !
, after enter dev.off() the Rgui.exe crash !?
(Win2000 / R.1.6.1)

...neverthless the  *.svg is written correctly.

thanks for advance & regards,christian




----- Original Message -----
From: "T Jake Luciani" <jake.luciani at riskmetrics.com>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, December 16, 2002 7:20 PM
Subject: [R] New SVG Graphics Device for R


> Hello,
>
> I just released a Graphics Device for R >= 1.4 which outputs w3 compliant
> SVG.  I Have also created a Java 1.1 applet which can render and
manipulate
> the SVG generated from the graphics device.
>
> Please visit http://www.darkridge.com/~jake/RSvg/ for more info
>
> Thanks,
>
> T Jake Luciani
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jake.luciani at riskmetrics.com  Mon Dec 16 21:19:06 2002
From: jake.luciani at riskmetrics.com (T Jake Luciani)
Date: Mon Dec 16 21:19:06 2002
Subject: [R] New SVG Graphics Device for R
In-Reply-To: <000b01c2a53e$661ff140$e70206d5@c5c9i0>
References: <200212161320.33134.jake.luciani@riskmetrics.com> <000b01c2a53e$661ff140$e70206d5@c5c9i0>
Message-ID: <200212161512.32388.jake.luciani@riskmetrics.com>

Yeah I got the same.

I'm confused because it works fine in Linux.

I'm registering the device properly as fas as I can tell.

Can a core developer take a look and tell me what I'm doing wrong.  
The code is at the bottom of devSVG.c

Thanks,

Jake

On Monday 16 December 2002 03:04 pm, Christian Schulz wrote:
> ... really a nice tool !
> , after enter dev.off() the Rgui.exe crash !?
> (Win2000 / R.1.6.1)
>
> ...neverthless the  *.svg is written correctly.
>
> thanks for advance & regards,christian
>
>
>
>
> ----- Original Message -----
> From: "T Jake Luciani" <jake.luciani at riskmetrics.com>
> To: <r-help at stat.math.ethz.ch>
> Sent: Monday, December 16, 2002 7:20 PM
> Subject: [R] New SVG Graphics Device for R
>
> > Hello,
> >
> > I just released a Graphics Device for R >= 1.4 which outputs w3 compliant
> > SVG.  I Have also created a Java 1.1 applet which can render and
>
> manipulate
>
> > the SVG generated from the graphics device.
> >
> > Please visit http://www.darkridge.com/~jake/RSvg/ for more info
> >
> > Thanks,
> >
> > T Jake Luciani
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Olof.Leimar at zoologi.su.se  Mon Dec 16 21:23:03 2002
From: Olof.Leimar at zoologi.su.se (Olof Leimar)
Date: Mon Dec 16 21:23:03 2002
Subject: [R] Interpretation of hypothesis tests for mixed models
In-Reply-To: <6r1y4iklvs.fsf@bates5.stat.wisc.edu>
References: <1039955040.1113.13.camel@plantago>
	 <6r1y4jw017.fsf@bates5.stat.wisc.edu> <1040027639.1116.113.camel@plantago>
	 <6r1y4iklvs.fsf@bates5.stat.wisc.edu>
Message-ID: <1040070055.1121.54.camel@plantago>

Sorry if my questions and statements were not clear enough. It is of
course true that the F- and t-tests from fm2 would always be more
conservative than those from fm1, your example for the Machines data
make this point. My (tentative) suggestion was that tests from fm2 are
closer to realising the nominal level of a test. This was based on
running the following code:


library(nlme)
k <- 2            # num subj
n <- 10           # subj/treatm sample size
m1 <- 1.0         # value of fixed effect of treatm 1
m2 <- m1          # same for treatm 2
s.sbj <- 0.5      # SD subj random effect
s.sbj.tr <- 1.0   # SD subj by treatm interaction
s.res <- 0.1      # Residual SD
Subj <- factor( rep(1:k, each=2*n) )
Trt <- factor( rep( rep(c("Tr1","Tr2"), k), each=n) )
m <- rep( rep(c(m1, m2), k), each=n) # fixed effects

n.sims <- 1000
p.f1 <- rep(0, n.sims)
p.f2 <- rep(0, n.sims)
for (i in 1:n.sims) {
  # first get subject/treatment random deviations
  b <- rep( rep(rnorm(k, 0, s.sbj), each=2) + 
           rnorm(2*k, 0, s.sbj.tr), each=n )
  # then get response
  y <- m + b + rnorm(2*k*n, 0, s.res)
  dat <- data.frame(Subj, Trt, y)
  fm1 <- lme(y ~ Trt, data = dat,
             random = list(Subj = pdCompSymm(~ Trt - 1)))
  p.f1[i] <- anova(fm1)$"p-value"[2]
  fm2 <- lme(y ~ Trt, data = dat,
             random = ~ 1 | Subj/Trt)
  p.f2[i] <- anova(fm2)$"p-value"[2]
}

print( sum(p.f1<0.05)/n.sims ) # should be about 0.05
print( sum(p.f2<0.05)/n.sims ) # should be about 0.05
print( sum(p.f1<0.01)/n.sims ) # should be about 0.01
print( sum(p.f2<0.01)/n.sims ) # should be about 0.01

rm(k,n,m1,m2,s.sbj,s.sbj.tr,s.res,Subj,Trt,m)
rm(i,b,y,dat,fm1,fm2)
#rm(n.sims,p.f1,p.f2)

Sorry if the code seems pedestrian. I am not an experienced S
programmer, but I hope I generated data in agreement with the
assumptions of the mixed models I am fitting. As an example of results,
I got
[1] 0.3
[1] 0.053
[1] 0.229
[1] 0.002
suggesting that fm2 comes much closer to the nominal significance
levels. My simulated data are of course a bit extreme (only two
subjects, etc) just to illustrate how much the two tests can differ. 

Coming back to my previous questions, I worry that models like 
 
 lme(y ~ x, random = ~ x | Subj) 

have a similar problem as fm1 in being too liberal (because denDF in a
test for an effect of x will be large in the same way as for fm1). Am I
wrong in worrying about this?  


-- 
Olof Leimar, Professor
Department of Zoology
Stockholm University
SE-106 91 Stockholm
Sweden

Olof.Leimar at zoologi.su.se



From tlumley at u.washington.edu  Mon Dec 16 21:27:03 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon Dec 16 21:27:03 2002
Subject: [R] Manipulating the output from read.spss
In-Reply-To: <1a1.d7e7b6a.2b2f8c05@aol.com>
Message-ID: <Pine.A41.4.44.0212161223140.21186-100000@homer18.u.washington.edu>

On Mon, 16 Dec 2002 SMarkandsusan at aol.com wrote:

> This seems like a problem that others may have run into before. I got a
> merged dataset from SPSS. It has ~750 columns X 3400 rows. Most of the cell
> entries are NA. There are about 375 rows that contain observations on all
> variables and I want to extract this subset from the original list (of
> lists). I'm pretty sure I can do it programmatically in R but it will take me
> a few hours to write and debug. Before I start down that road I thought I'd
> ask if anyone had already tackled this particular type problem already.


The na.omit() function removes rows from a dataframe that have any missing
values.

	-thomas



From Jameshutton25 at aol.com  Mon Dec 16 21:58:03 2002
From: Jameshutton25 at aol.com (Jameshutton25@aol.com)
Date: Mon Dec 16 21:58:03 2002
Subject: [R] R commands
Message-ID: <f7.25c721d8.2b2f9676@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021216/4c11d9ae/attachment.pl

From ben at zoo.ufl.edu  Mon Dec 16 22:20:04 2002
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Mon Dec 16 22:20:04 2002
Subject: [R] R commands
In-Reply-To: <f7.25c721d8.2b2f9676@aol.com>
Message-ID: <Pine.LNX.4.44.0212161622520.12296-100000@bolker.zoo.ufl.edu>

  The first two are pretty basic:

  #1: x <- rnorm(20)
  #2: x[x<0] <- 0
  
  #3 is poorly defined.  Do you want the estimate of the mean and s.d. of 
the initial (non-truncated) distribution?  I think this might be doable, 
but someone (preferably you) would have to try to work out the details ... 
this is a statistical question, not an R coding question.

  which[x<=0]

  Ben Bolker

On Mon, 16 Dec 2002 Jameshutton25 at aol.com wrote:

> I would like to know how to do the following commands on R:
> 1) Choose 20 random numbers modelled on the normal distribution.
> 2)Any of these numbers that are negative to change them to ZERO.
> 3)Perform a command that will enable me to find the maximum likelihood (the 
> true mean of the distribution). If any of the numbers are zero i need to know 
> which ones they were if possible.
> 
> Thank you very much for your. I look forward to hearing from you.
> 
> Yours Sincerely,
> 
> James Hutton
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From ozric at web.de  Mon Dec 16 22:25:03 2002
From: ozric at web.de (Christian Schulz)
Date: Mon Dec 16 22:25:03 2002
Subject: [R] Manipulating the output from read.spss
References: <1a1.d7e7b6a.2b2f8c05@aol.com>
Message-ID: <002101c2a548$ec5e8140$e70206d5@c5c9i0>

..if i understand you correct that you
wan't only the 375 rows with no NA in
~ 750 columns use:

all.data  <- read.spss("c:/yourData.sav",use.value.label=F,to.data.frame=T)
all.validData <- na.omit(all.data)

christian

----- Original Message -----
From: <SMarkandsusan at aol.com>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, December 16, 2002 9:05 PM
Subject: [R] Manipulating the output from read.spss


> This seems like a problem that others may have run into before. I got a
> merged dataset from SPSS. It has ~750 columns X 3400 rows. Most of the
cell
> entries are NA. There are about 375 rows that contain observations on all
> variables and I want to extract this subset from the original list (of
> lists). I'm pretty sure I can do it programmatically in R but it will take
me
> a few hours to write and debug. Before I start down that road I thought
I'd
> ask if anyone had already tackled this particular type problem already.
> Thanks a lot,
> Mark Schultz
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From rolf at math.unb.ca  Mon Dec 16 22:35:03 2002
From: rolf at math.unb.ca (Rolf Turner)
Date: Mon Dec 16 22:35:03 2002
Subject: [R] R commands
Message-ID: <200212162134.RAA13365@gelfand.math.unb.ca>

The recent posting by Jameshutton25 at aol.com looks suspiciously
like a homework question to me.  I would advise/request my
colleagues out there to be circumspect about answering such
questions.

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From ripley at stats.ox.ac.uk  Mon Dec 16 22:45:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Dec 16 22:45:03 2002
Subject: [R] New SVG Graphics Device for R
In-Reply-To: <200212161512.32388.jake.luciani@riskmetrics.com>
Message-ID: <Pine.LNX.4.31.0212162131010.16426-100000@gannet.stats>

On Mon, 16 Dec 2002, T Jake Luciani wrote:

> Yeah I got the same.
>
> I'm confused because it works fine in Linux.
>
> I'm registering the device properly as fas as I can tell.
>
> Can a core developer take a look and tell me what I'm doing wrong.

Using undocumented non-public entry points in the R internals.  The
traceback is (whyever do people not report this basic information: see the
rw-FAQ for how?)

Call stack:
0048241B  R.dll:0048241B  free
004CA292  R.dll:004CA292  GEdestroyDevDesc
004F10F6  R.dll:004F10F6  Rf_selectDevice
0051B1FE  R.dll:0051B1FE  do_devoff
005049B4  R.dll:005049B4  do_internal
...

so the R graphics internals are calling R's internal free on memory
allocated by your device, which allocated the memory from msvcrt.dll and
not from the internal malloc.

Solution: build in the source tree of R and add -lRm to Makevars
(and you might as well have configure.win and Makevars.win whilst you are
at it).  That gives you access to R's internal malloc.


> The code is at the bottom of devSVG.c
>
> Thanks,
>
> Jake
>
> On Monday 16 December 2002 03:04 pm, Christian Schulz wrote:
> > ... really a nice tool !
> > , after enter dev.off() the Rgui.exe crash !?
> > (Win2000 / R.1.6.1)
> >
> > ...neverthless the  *.svg is written correctly.
> >
> > thanks for advance & regards,christian
> >
> >
> >
> >
> > ----- Original Message -----
> > From: "T Jake Luciani" <jake.luciani at riskmetrics.com>
> > To: <r-help at stat.math.ethz.ch>
> > Sent: Monday, December 16, 2002 7:20 PM
> > Subject: [R] New SVG Graphics Device for R
> >
> > > Hello,
> > >
> > > I just released a Graphics Device for R >= 1.4 which outputs w3 compliant
> > > SVG.  I Have also created a Java 1.1 applet which can render and
> >
> > manipulate
> >
> > > the SVG generated from the graphics device.
> > >
> > > Please visit http://www.darkridge.com/~jake/RSvg/ for more info
> > >
> > > Thanks,
> > >
> > > T Jake Luciani
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jake.luciani at riskmetrics.com  Tue Dec 17 00:22:02 2002
From: jake.luciani at riskmetrics.com (T Jake Luciani)
Date: Tue Dec 17 00:22:02 2002
Subject: [R] New SVG Graphics Device for R
In-Reply-To: <000b01c2a53e$661ff140$e70206d5@c5c9i0>
References: <200212161320.33134.jake.luciani@riskmetrics.com> <000b01c2a53e$661ff140$e70206d5@c5c9i0>
Message-ID: <200212161816.20101.jake.luciani@riskmetrics.com>

This is fixed.  It no longer crashes on Win32. Sorry about that.

Grab new version from http://www.darkridge.com/~jake/RSvg

It should be on CRAN soon.

-Jake

On Monday 16 December 2002 03:04 pm, Christian Schulz wrote:
> ... really a nice tool !
> , after enter dev.off() the Rgui.exe crash !?
> (Win2000 / R.1.6.1)
>
> ...neverthless the  *.svg is written correctly.
>
> thanks for advance & regards,christian
>
>
>
>
> ----- Original Message -----
> From: "T Jake Luciani" <jake.luciani at riskmetrics.com>
> To: <r-help at stat.math.ethz.ch>
> Sent: Monday, December 16, 2002 7:20 PM
> Subject: [R] New SVG Graphics Device for R
>
> > Hello,
> >
> > I just released a Graphics Device for R >= 1.4 which outputs w3 compliant
> > SVG.  I Have also created a Java 1.1 applet which can render and
>
> manipulate
>
> > the SVG generated from the graphics device.
> >
> > Please visit http://www.darkridge.com/~jake/RSvg/ for more info
> >
> > Thanks,
> >
> > T Jake Luciani
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Ted.Harding at nessie.mcc.ac.uk  Tue Dec 17 00:33:03 2002
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue Dec 17 00:33:03 2002
Subject: [R] lme invocation
Message-ID: <XFMail.021216232843.Ted.Harding@nessie.mcc.ac.uk>

Hi Folks,
I'm trying to understand the model specification formalities
for 'lme', and the documentation is leaving me a bit confused.

Specifically, using the example dataset 'Orthodont' in the
'nlme' package, first I use the invocation given in the example
shown by "?lme":

  > fm1 <- lme(distance ~ age, data = Orthodont) # random is ~ age

Despite the Comment ("# random is ~ age"),

  > summary(fm1)

says that

  [...]
  Random effects:
   Formula: ~age | Subject
   Structure: General positive-definite
  [...]
  Fixed effects: distance ~ age 

In view of the statement "Formula: ~age | Subject" above,
I next try:

  > fm1<-lme(distance~age,data=Orthodont,random=~age|Subject)
  > summary(fm1)
  [...]
  Random effects:
   Formula: ~age | Subject
   Structure: General positive-definite, Log-Cholesky parametrization
  [...]
  Fixed effects: distance ~ age 

So the summaries of the two invocations give identical statements
of the Random and Fixed Effects models, but the second adds
"Log-Cholesky parametrization" to the "Structure", and the numerical
results are very slightly different (though hardly enough to visible
in this case).

Finally, if I take the Comment ("# random is ~ age") from the first
invocation and base an invocation on that:

  > fm1<-lme(distance~age,data=Orthodont,random=~age)
  > summary(fm1)

I get results identical with the second invocation.

I'm not following how/why the first two different invocations give
rise to the different results, and am puzzled by their relationship
with the third (given the Comment).

Can someone explain?

With thanks,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 16-Dec-02                                       Time: 23:28:43
------------------------------ XFMail ------------------------------



From bates at stat.wisc.edu  Tue Dec 17 01:11:03 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue Dec 17 01:11:03 2002
Subject: [R] lme invocation
In-Reply-To: <XFMail.021216232843.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.021216232843.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <6rel8hh5dv.fsf@bates5.stat.wisc.edu>

For convenience lme offers several different ways of specifying the
formula and nesting structure of the random effects.  The default
random effects have the same model matrix as the fixed effects and the
default grouping variable.  If the model matrix has more than one
column the default structure for the variance-covariance of the random
effects is a general positive-definite symmetric (pdSymm) structure.
The default parameterization for pdSymm is pdLogChol

Orthodont is a groupedData object that carries information on the
grouping structure.  The default grouping variable is Subject.  Hence
the following specifications should be equivalent after 
  fixed = distance ~ age, data = Orthodont

 random = list(Subject = pdLogChol(~ age))
 random = list(Subject = pdSymm(~ age))
 random = ~ age | Subject
 random = ~ age
 no random specification

I'm not sure why you got different answers between your first and
second specifications.  It may be that there is a route through the
code that picks up a parameterization for pdSymm other than
pdLogChol.  The default in S-PLUS was pdMatrixLog but we changed that
in the R implementation because it is difficult (perhaps impossible)
to get an analytic gradient of the matrix exponential.

(Ted Harding) <Ted.Harding at nessie.mcc.ac.uk> writes:

> I'm trying to understand the model specification formalities
> for 'lme', and the documentation is leaving me a bit confused.
> 
> Specifically, using the example dataset 'Orthodont' in the
> 'nlme' package, first I use the invocation given in the example
> shown by "?lme":
> 
>   > fm1 <- lme(distance ~ age, data = Orthodont) # random is ~ age
> 
> Despite the Comment ("# random is ~ age"),
> 
>   > summary(fm1)
> 
> says that
> 
>   [...]
>   Random effects:
>    Formula: ~age | Subject
>    Structure: General positive-definite
>   [...]
>   Fixed effects: distance ~ age 
> 
> In view of the statement "Formula: ~age | Subject" above,
> I next try:
> 
>   > fm1<-lme(distance~age,data=Orthodont,random=~age|Subject)
>   > summary(fm1)
>   [...]
>   Random effects:
>    Formula: ~age | Subject
>    Structure: General positive-definite, Log-Cholesky parametrization
>   [...]
>   Fixed effects: distance ~ age 
> 
> So the summaries of the two invocations give identical statements
> of the Random and Fixed Effects models, but the second adds
> "Log-Cholesky parametrization" to the "Structure", and the numerical
> results are very slightly different (though hardly enough to visible
> in this case).
> 
> Finally, if I take the Comment ("# random is ~ age") from the first
> invocation and base an invocation on that:
> 
>   > fm1<-lme(distance~age,data=Orthodont,random=~age)
>   > summary(fm1)
> 
> I get results identical with the second invocation.
> 
> I'm not following how/why the first two different invocations give
> rise to the different results, and am puzzled by their relationship
> with the third (given the Comment).
> 
> Can someone explain?
> 
> With thanks,
> Ted.
> 
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 167 1972
> Date: 16-Dec-02                                       Time: 23:28:43
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Lydia.Shenstone at buseco.monash.edu.au  Tue Dec 17 01:17:06 2002
From: Lydia.Shenstone at buseco.monash.edu.au (Lydia.Shenstone@buseco.monash.edu.au)
Date: Tue Dec 17 01:17:06 2002
Subject: [R] How plot \ell  in the title of a graph
Message-ID: <3DFE6CB4.CD1E07EE@buseco.monash.edu.au>

Hi there,

I am trying to put the LATEX symbol \ell
in the title of a graph, do you know how
to do it?

Thanks.

Lydia



From kjetilh at umsanet.edu.bo  Tue Dec 17 01:20:00 2002
From: kjetilh at umsanet.edu.bo (kjetil halvorsen)
Date: Tue Dec 17 01:20:00 2002
Subject: [R] Manipulating the output from read.spss
References: <1a1.d7e7b6a.2b2f8c05@aol.com>
Message-ID: <3DFE67EB.A973198E@umsanet.edu.bo>

use read.spss with to.data.frame=TRUE, then
na.omit on the result. This assumes that the missing values are signes
as such in spss, so read.spss imports them correctly.

Kjetil Halvorsen


SMarkandsusan at aol.com wrote:
> 
> This seems like a problem that others may have run into before. I got a
> merged dataset from SPSS. It has ~750 columns X 3400 rows. Most of the cell
> entries are NA. There are about 375 rows that contain observations on all
> variables and I want to extract this subset from the original list (of
> lists). I'm pretty sure I can do it programmatically in R but it will take me
> a few hours to write and debug. Before I start down that road I thought I'd
> ask if anyone had already tackled this particular type problem already.
> Thanks a lot,
> Mark Schultz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Ted.Harding at nessie.mcc.ac.uk  Tue Dec 17 02:37:03 2002
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue Dec 17 02:37:03 2002
Subject: [R] lme invocation
In-Reply-To: <6rel8hh5dv.fsf@bates5.stat.wisc.edu>
Message-ID: <XFMail.021217012949.Ted.Harding@nessie.mcc.ac.uk>

Doug,
Thanks for these clarifications, especially for pointing out
the chain of defaults (I now see I was a bit out of my depth
when posting my previous mail, so thanks also for the kick-start
in swimming ... ).

See below also.

On 17-Dec-02 Douglas Bates wrote:
> For convenience lme offers several different ways of specifying the
> formula and nesting structure of the random effects.  The default
> random effects have the same model matrix as the fixed effects and the
> default grouping variable.  If the model matrix has more than one
> column the default structure for the variance-covariance of the random
> effects is a general positive-definite symmetric (pdSymm) structure.
> The default parameterization for pdSymm is pdLogChol
> 
> Orthodont is a groupedData object that carries information on the
> grouping structure.  The default grouping variable is Subject.  Hence
> the following specifications should be equivalent after 
>   fixed = distance ~ age, data = Orthodont
> 
>  random = list(Subject = pdLogChol(~ age))
>  random = list(Subject = pdSymm(~ age))
>  random = ~ age | Subject
>  random = ~ age
>  no random specification
> 
> I'm not sure why you got different answers between your first and
> second specifications.  It may be that there is a route through the
> code that picks up a parameterization for pdSymm other than
> pdLogChol.  The default in S-PLUS was pdMatrixLog but we changed that
> in the R implementation because it is difficult (perhaps impossible)
> to get an analytic gradient of the matrix exponential.

Just to show the difference, I have done fm1<-lme(...) with the
first and second specifications I referred to below. For comparison,
results output from the second are interleaved with the first,
and marked by "**" at the start of the line:


  > fm1 <- lme(distance ~ age, data = Orthodont)
**> fm1 <- lme(distance ~ age, data = Orthodont, random=age | Subject)
  > summary(fm1)
**> summary(fm1)
  Linear mixed-effects model fit by REML
**Linear mixed-effects model fit by REML
   Data: Orthodont 
** Data: Orthodont 
         AIC      BIC    logLik
**       AIC      BIC    logLik
    454.6367 470.6173 -221.3183
**  454.6367 470.6173 -221.3183
  
  Random effects:
**Random effects:
   Formula: ~age | Subject
** Formula: ~age | Subject
   Structure: General positive-definite
** Structure: General positive-definite, Log-Cholesky parametrization
              StdDev    Corr  
**            StdDev    Corr  
  (Intercept) 2.3269555 (Intr)
**(Intercept) 2.3271018 (Intr)
  age         0.2264214 -0.609
**age         0.2264283 -0.609
  Residual    1.3100414       
**Residual    1.3100432       
  
  Fixed effects: distance ~ age 
**Fixed effects: distance ~ age 
                  Value Std.Error DF   t-value p-value
**                Value Std.Error DF  t-value p-value
  (Intercept) 16.761111 0.7752380 80 21.620602  <.0001
**(Intercept) 16.761111 0.7752549 80 21.62013  <.0001
  age          0.660185 0.0712526 80  9.265423  <.0001
**age          0.660185 0.0712534 80  9.26531  <.0001
   Correlation: 
** Correlation: 
      (Intr)
**    (Intr)
  age -0.848
**age -0.848
  
  Standardized Within-Group Residuals:
**Standardized Within-Group Residuals:
           Min           Q1          Med           Q3          Max 
**         Min           Q1          Med           Q3          Max 
  -3.223158567 -0.493759795  0.007318547  0.472157317  3.916029639 
**-3.223061787 -0.493755276  0.007315541  0.472145258  3.916026878 
  
  Number of Observations: 108
**Number of Observations: 108

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 17-Dec-02                                       Time: 01:29:49
------------------------------ XFMail ------------------------------



From Ngayee.Law at celeradiagnostics.com  Tue Dec 17 03:26:02 2002
From: Ngayee.Law at celeradiagnostics.com (Ngayee J Law)
Date: Tue Dec 17 03:26:02 2002
Subject: [R] Breslow Day Test
Message-ID: <OF4D586215.5E306ABA-ON88256C92.000D075F@pe-c.com>

Hello everyone,

Does anyone know if I can do Breslow Day Test for the homogeneity of odds
ratio in R?
Thanks!

- Jacqueline



From andy_liaw at merck.com  Tue Dec 17 04:34:02 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue Dec 17 04:34:02 2002
Subject: [R] cleaning up after example()
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC9D9@usrymx10.merck.com>

Dear R-help,

I find the example() function is extremely useful in many ways.  However,
there's a minor inconvenience: for long examples, it leaves lots of objects
in the workspace.  While it's sometimes useful to have the objects around
for further exploration, other times they just add to the clutter.  Does
anyone have a good way of cleaning up afterward?  If not, would R core
consider adding such a feature?

Cheers,
Andy


------------------------------------------------------------------------------



From ripley at stats.ox.ac.uk  Tue Dec 17 08:20:04 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Dec 17 08:20:04 2002
Subject: [R] cleaning up after example()
In-Reply-To: <51F9C42DA15CD311BD220008C707D81906FFC9D9@usrymx10.merck.com>
Message-ID: <Pine.LNX.4.31.0212170714590.17019-100000@gannet.stats>

On Mon, 16 Dec 2002, Liaw, Andy wrote:

> I find the example() function is extremely useful in many ways.  However,
> there's a minor inconvenience: for long examples, it leaves lots of objects
> in the workspace.  While it's sometimes useful to have the objects around
> for further exploration, other times they just add to the clutter.  Does
> anyone have a good way of cleaning up afterward?  If not, would R core
> consider adding such a feature?

It's half there.  Example calls source, and source has a local argument
that by default uses the workspace for objects.  We just need to call
source(local=TRUE) in example(), and then the objects will get created in
the frame of the example call.

This BTW is to avoid creating the objects, not cleaning up.  It is not
possible (AFAIK) to find out what objects have been created, nor to know
if they clobber existing objects of the same name.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From vito.muggeo at giustizia.it  Tue Dec 17 08:42:02 2002
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Tue Dec 17 08:42:02 2002
Subject: [R] Breslow Day Test
References: <OF4D586215.5E306ABA-ON88256C92.000D075F@pe-c.com>
Message-ID: <003901c2a59f$3e72f6e0$5c13070a@it.giustizia.it>

I don't remember this test exactly; however testing homogenity of the odds
ratio in K 2x2 tables is equivalent to testing interaction x:z in the
logistic model:

y~x+z+x:z

where y is the (binary) response variable, x is the (binary) "exposure"
variable and z is the K-levels confounding factor,

best,
vito


----- Original Message -----
From: "Ngayee J Law" <Ngayee.Law at celeradiagnostics.com>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, December 17, 2002 3:25 AM
Subject: [R] Breslow Day Test


> Hello everyone,
>
> Does anyone know if I can do Breslow Day Test for the homogeneity of odds
> ratio in R?
> Thanks!
>
> - Jacqueline
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From gisar at nus.edu.sg  Tue Dec 17 11:43:03 2002
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Tue Dec 17 11:43:03 2002
Subject: [R] Coloured label, terminal branch and bars in dendograms
Message-ID: <024D6AEFCB92CB47BA1085751D184BB80105F1D7@MBXSRV03.stf.nus.edu.sg>

Dear R-help,

I have performed a hierarchical clustering on some data that I have and
would like to know some nice ways of visualizing it. I have 2 related
questions:


i) How to color the labels AND the terminal branch of a dendogram? This
is my inelegant way of just getting the colored labels.

data(iris)          # Formatting data into required format
ir <- iris[ ,-5]
ir.class  <- c( rep("s", 50), rep("c", 50), rep("v", 50))

ir.hclust <- hclust( dist(ir), "average" )  # Hierarchical clustering

plclust(ir.hclust, label =rep("", 150))     # could also set hang=-1
option
mtext(ir.class[ir.hclust$order], side=1, col=
ir.fac.class[ir.hclust$order], 	at=1:150, line=-2)

This does not color the terminal branch and does not work very well if I
wish to cluster 400 - 500 objects as the text gets very cramped (even
after cex and las option).


ii) I also wish to investigate if the data is clustered according to
several suspected factors/prognosis. Therefore I want to plot these as
'color filled bars' underneath the dendogram (akin to those published
microarray clustering papers). 

My way of doing this is to use mtext with "-" as follows:

plclust(ir.hclust)
mtext( "-", side=1, col=ir.var1[ir.hclust$order], at=1:150, line=-1)
mtext( "-", side=1, col=ir.var2[ir.hclust$order], at=1:150, line=-1.5)


Any help or reference is greatly appreciated.

Thanks, Adai.



From michel.arnaud at cirad.fr  Tue Dec 17 15:37:06 2002
From: michel.arnaud at cirad.fr (Michel ARNAUD)
Date: Tue Dec 17 15:37:06 2002
Subject: [R] hist and density on the same plot
References: <Pine.LNX.4.31.0212170714590.17019-100000@gannet.stats>
Message-ID: <3DFF36C7.E01AB4AA@cirad.fr>

Hi
I would like to plot hist and density associated on the same graph.
I don't find the code.
Any suggestions ?

--
Michel ARNAUD
CIRAD TA60/15
73, av. Jean Fran?ois Breton
34938 MONTPELLIER CEDEX 5
tel : 04 67 59 38 34
Fax : 04 67 59 38 38

-------------- next part --------------
A non-text attachment was scrubbed...
Name: michel.arnaud.vcf
Type: text/x-vcard
Size: 204 bytes
Desc: Carte pour Michel ARNAUD
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20021217/133d56c2/michel.arnaud.vcf

From petr.pikal at precheza.cz  Tue Dec 17 15:57:03 2002
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue Dec 17 15:57:03 2002
Subject: [R] hist and density on the same plot
In-Reply-To: <3DFF36C7.E01AB4AA@cirad.fr>
Message-ID: <3DFF48F6.1761.1BFF3D5@localhost>

An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20021217/4665d73f/attachment.html

From carlos.ortega at minorplanet.com  Tue Dec 17 16:02:14 2002
From: carlos.ortega at minorplanet.com (Carlos Ortega)
Date: Tue Dec 17 16:02:14 2002
Subject: [R] hist and density on the same plot
In-Reply-To: <3DFF36C7.E01AB4AA@cirad.fr>
Message-ID: <LMEKLMMLPDKOJNOOEELEKEGADOAA.carlos.ortega@minorplanet.com>

Hello,

Yes, you have some examples in the "histogram" command in the lattice
library.

Regards,
Carlos.

-----Mensaje original-----
De: r-help-admin at stat.math.ethz.ch
[mailto:r-help-admin at stat.math.ethz.ch]En nombre de Michel ARNAUD
Enviado el: martes, 17 de diciembre de 2002 15:38
Para: 'r-help at stat.math.ethz.ch'
Asunto: [R] hist and density on the same plot


Hi
I would like to plot hist and density associated on the same graph.
I don't find the code.
Any suggestions ?

--
Michel ARNAUD
CIRAD TA60/15
73, av. Jean Fran?ois Breton
34938 MONTPELLIER CEDEX 5
tel : 04 67 59 38 34
Fax : 04 67 59 38 38



_____
The information in this email is confidential and it may not be\ ... [[dropped]]



From mihastaut at hotmail.com  Tue Dec 17 16:12:03 2002
From: mihastaut at hotmail.com (Miha STAUT)
Date: Tue Dec 17 16:12:03 2002
Subject: [R] A newbie question
Message-ID: <F191EwLqJrfP6nmGq3M00003160@hotmail.com>

Hi all,

I just subscribed to the mail and I have got a question.

From R.eschen at cabi-bioscience.ch  Tue Dec 17 17:03:06 2002
From: R.eschen at cabi-bioscience.ch (Rene Eschen)
Date: Tue Dec 17 17:03:06 2002
Subject: [R] Cross-correlograms or cross-variograms in R?
Message-ID: <D173FA00F56FD21184C300104BB732571C279F@DELEMONT_SRVR>

Hello group,

For my PhD I'm working on a spatial sampling grid. I do have two data sets
which I'd like to compare using cross-correlograms or cross-variograms. 

Is this an option in one of the R-packages? I've been searching the R-help
archive and the available package-documentations, but I can't find how to do
this. 

Thanks in advance,

Ren?.

_______________________________________

Ren? Eschen
CABI Bioscience Switzerland Centre
1 Rue des Grillons
CH-2800 Del?mont
Switzerland
+41 32 421 48 87 (Direct)
+41 32 421 48 70 (Secretary)
+41 32 421 48 71 (Fax)
r.eschen at cabi-bioscience.ch



From Ted.Harding at nessie.mcc.ac.uk  Tue Dec 17 17:19:02 2002
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue Dec 17 17:19:02 2002
Subject: [R] Quick tip please!
Message-ID: <XFMail.021217154727.Ted.Harding@nessie.mcc.ac.uk>

I have two CSV files (exported from Excel), say file1 and file2.

The have the same number of rows, and each has several columns,
with names on the first line; and some of the columns in file1
are repeated in file2.

Using the "foreign" package, I can read these in separately
to dataframes say d1 and d2 with

  > d1<-read.csv("file1")
  > d2<-read.csv("file2")

Now I would like to combine these into a single dataframe D,
notionally

  D <- "d1 on the left, d2 on the right"

which contains all the columns except that duplicates only occur
once (and, preferably, in the order of occurrence on d1 -- i.e.
remove them from d2 if already dound in d1).

Any tips for how to do this slickly?

With thanks,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 17-Dec-02                                       Time: 15:47:27
------------------------------ XFMail ------------------------------



From york at noaa.gov  Tue Dec 17 17:22:04 2002
From: york at noaa.gov (Anne York)
Date: Tue Dec 17 17:22:04 2002
Subject: [R] cleaning up after example()
Message-ID: <Pine.GSO.4.05.10212170813020.27019-100000@ofis450a.akctr.noaa.gov>

The example() and demo() functions are very useful and they do
clutter up workspaces. 

For that reason, I run them (usually, I remember to do is)  in
a demo  workspace.  That way, I don't care about the objects or saving them
etc. This makes cleaning up unnecessary. 

Anne

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Anne E. York
National Marine Mammal Laboratory
Seattle WA 98115-0070  USA
e-mail: york at ofis450a.akctr.noaa.gov
Voice: +1 206-526-4039
Fax: +1 206-526-6615
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


++++++++++++++++++++++++++++++++++++++++++
Date: Mon, 16 Dec 2002 22:33:27 -0500
From: "Liaw, Andy" <andy_liaw at merck.com>
To: "'r-help at stat.math.ethz.ch'" <r-help at stat.math.ethz.ch>
Subject: [R] cleaning up after example()

Dear R-help,

I find the example() function is extremely useful in many ways.  However,
there's a minor inconvenience: for long examples, it leaves lots of objects
in the workspace.  While it's sometimes useful to have the objects around
for further exploration, other times they just add to the clutter.  Does
anyone have a good way of cleaning up afterward?  If not, would R core
consider adding such a feature?

Cheers,
Andy





~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Anne E. York
National Marine Mammal Laboratory
Seattle WA 98115-0070  USA
e-mail: anne.york at noaa.gov
Voice: +1 206-526-4039
Fax: +1 206-526-6615
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From ben at zoo.ufl.edu  Tue Dec 17 17:27:04 2002
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Tue Dec 17 17:27:04 2002
Subject: [R] Quick tip please!
In-Reply-To: <XFMail.021217154727.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.LNX.4.44.0212171130500.14020-100000@bolker.zoo.ufl.edu>

  Maybe

data.frame(d1,d2[!names(d2) %in% names(d1)])    ?

On Tue, 17 Dec 2002 Ted.Harding at nessie.mcc.ac.uk wrote:

> I have two CSV files (exported from Excel), say file1 and file2.
> 
> The have the same number of rows, and each has several columns,
> with names on the first line; and some of the columns in file1
> are repeated in file2.
> 
> Using the "foreign" package, I can read these in separately
> to dataframes say d1 and d2 with
> 
>   > d1<-read.csv("file1")
>   > d2<-read.csv("file2")
> 
> Now I would like to combine these into a single dataframe D,
> notionally
> 
>   D <- "d1 on the left, d2 on the right"
> 
> which contains all the columns except that duplicates only occur
> once (and, preferably, in the order of occurrence on d1 -- i.e.
> remove them from d2 if already dound in d1).
> 
> Any tips for how to do this slickly?
> 
> With thanks,
> Ted.
> 
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 167 1972
> Date: 17-Dec-02                                       Time: 15:47:27
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From umalvarez at fata.unam.mx  Tue Dec 17 17:46:03 2002
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Tue Dec 17 17:46:03 2002
Subject: [R] Quick tip please!
In-Reply-To: <XFMail.021217154727.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.LNX.4.44.0212171145460.23606-100000@fata.unam.mx>

Ted:

Take a look at ?merge

Good look

 

On Tue, 17 Dec 2002 Ted.Harding at nessie.mcc.ac.uk wrote:

> I have two CSV files (exported from Excel), say file1 and file2.
> 
> The have the same number of rows, and each has several columns,
> with names on the first line; and some of the columns in file1
> are repeated in file2.
> 
> Using the "foreign" package, I can read these in separately
> to dataframes say d1 and d2 with
> 
>   > d1<-read.csv("file1")
>   > d2<-read.csv("file2")
> 
> Now I would like to combine these into a single dataframe D,
> notionally
> 
>   D <- "d1 on the left, d2 on the right"
> 
> which contains all the columns except that duplicates only occur
> once (and, preferably, in the order of occurrence on d1 -- i.e.
> remove them from d2 if already dound in d1).
> 
> Any tips for how to do this slickly?
> 
> With thanks,
> Ted.
> 
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 167 1972
> Date: 17-Dec-02                                       Time: 15:47:27
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUES 
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez at fata.unam.mx



From Mark.Wilkinson at stjude.org  Tue Dec 17 17:50:04 2002
From: Mark.Wilkinson at stjude.org (Wilkinson, Mark)
Date: Tue Dec 17 17:50:04 2002
Subject: [R] Quick tip please!
Message-ID: <A1DAD6685C12D511B20F00034725151380CD6B@sjmemexc3.stjude.org>

For slickness, I like

DD <- merge(d1, d2)

assuming duplicate columns have identical labels.


Mark Wilkinson
Informatics Analyst
St. Jude Children's Research Hospital
Department of Pharmaceutical Sciences


 -----Original Message-----
From: 	Ted.Harding at nessie.mcc.ac.uk [mailto:Ted.Harding at nessie.mcc.ac.uk] 
Sent:	Tuesday, December 17, 2002 9:47 AM
To:	r-help at stat.math.ethz.ch
Subject:	[R] Quick tip please!

I have two CSV files (exported from Excel), say file1 and file2.

The have the same number of rows, and each has several columns,
with names on the first line; and some of the columns in file1
are repeated in file2.

Using the "foreign" package, I can read these in separately
to dataframes say d1 and d2 with

  > d1<-read.csv("file1")
  > d2<-read.csv("file2")

Now I would like to combine these into a single dataframe D,
notionally

  D <- "d1 on the left, d2 on the right"

which contains all the columns except that duplicates only occur
once (and, preferably, in the order of occurrence on d1 -- i.e.
remove them from d2 if already dound in d1).

Any tips for how to do this slickly?

With thanks,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 17-Dec-02                                       Time: 15:47:27
------------------------------ XFMail ------------------------------

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From sundar.dorai-raj at pdf.com  Tue Dec 17 17:53:06 2002
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue Dec 17 17:53:06 2002
Subject: [R] cleaning up after example()
References: <51F9C42DA15CD311BD220008C707D81906FFC9D9@usrymx10.merck.com>
Message-ID: <3DFF55F0.267407F0@pdf.com>

> Dear R-help,
> 
> I find the example() function is extremely useful in many ways.  However,
> there's a minor inconvenience: for long examples, it leaves lots of objects
> in the workspace.  While it's sometimes useful to have the objects around
> for further exploration, other times they just add to the clutter.  Does
> anyone have a good way of cleaning up afterward?  If not, would R core
> consider adding such a feature?
> 

Andy,
  One quick fix would be to take a snapshot of your current workspace,
then delete anything new afterwards. Of course, this doesn't account for
overwritten variables.

> snapshot = ls()
> example("smooth",pack="eda",lib.loc=.Library)
...
> remove(list = ls()[!ls()%in%snapshot]) # also removes `snapshot'

Regards,
Sundar

-- 
Sundar Dorai-Raj
PDF Solutions, Inc.
Dallas TX



From carlos.ortega at minorplanet.com  Tue Dec 17 17:57:03 2002
From: carlos.ortega at minorplanet.com (Carlos Ortega)
Date: Tue Dec 17 17:57:03 2002
Subject: [R] Quick tip please!
In-Reply-To: <Pine.LNX.4.44.0212171130500.14020-100000@bolker.zoo.ufl.edu>
Message-ID: <LMEKLMMLPDKOJNOOEELEAEGEDOAA.carlos.ortega@minorplanet.com>

Hi,

Please read "merge".

Regards,
Carlos.


-----Mensaje original-----
De: r-help-admin at stat.math.ethz.ch
[mailto:r-help-admin at stat.math.ethz.ch]En nombre de Ben Bolker
Enviado el: martes, 17 de diciembre de 2002 17:32
Para: Ted.Harding at nessie.mcc.ac.uk
CC: r-help at stat.math.ethz.ch
Asunto: Re: [R] Quick tip please!



  Maybe

data.frame(d1,d2[!names(d2) %in% names(d1)])    ?

On Tue, 17 Dec 2002 Ted.Harding at nessie.mcc.ac.uk wrote:

> I have two CSV files (exported from Excel), say file1 and file2.
> 
> The have the same number of rows, and each has several columns,
> with names on the first line; and some of the columns in file1
> are repeated in file2.
> 
> Using the "foreign" package, I can read these in separately
> to dataframes say d1 and d2 with
> 
>   > d1<-read.csv("file1")
>   > d2<-read.csv("file2")
> 
> Now I would like to combine these into a single dataframe D,
> notionally
> 
>   D <- "d1 on the left, d2 on the right"
> 
> which contains all the columns except that duplicates only occur
> once (and, preferably, in the order of occurrence on d1 -- i.e.
> remove them from d2 if already dound in d1).
> 
> Any tips for how to do this slickly?
> 
> With thanks,
> Ted.
> 
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 167 1972
> Date: 17-Dec-02                                       Time: 15:47:27
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help

_____
The information in this email is confidential and it may not be\ ... [[dropped]]



From carlos.ortega at minorplanet.com  Tue Dec 17 18:00:09 2002
From: carlos.ortega at minorplanet.com (Carlos Ortega)
Date: Tue Dec 17 18:00:09 2002
Subject: [R] Cross-correlograms or cross-variograms in R?
In-Reply-To: <D173FA00F56FD21184C300104BB732571C279F@DELEMONT_SRVR>
Message-ID: <LMEKLMMLPDKOJNOOEELEIEGEDOAA.carlos.ortega@minorplanet.com>

Hello,

The library "spatial" included as a default library in the base package
could help you.

Regards,
Carlos.


-----Mensaje original-----
De: r-help-admin at stat.math.ethz.ch
[mailto:r-help-admin at stat.math.ethz.ch]En nombre de Rene Eschen
Enviado el: martes, 17 de diciembre de 2002 17:56
Para: 'r-help at stat.math.ethz.ch'
Asunto: [R] Cross-correlograms or cross-variograms in R?


Hello group,

For my PhD I'm working on a spatial sampling grid. I do have two data sets
which I'd like to compare using cross-correlograms or cross-variograms.

Is this an option in one of the R-packages? I've been searching the R-help
archive and the available package-documentations, but I can't find how to do
this.

Thanks in advance,

Ren?.

_______________________________________

Ren? Eschen
CABI Bioscience Switzerland Centre
1 Rue des Grillons
CH-2800 Del?mont
Switzerland
+41 32 421 48 87 (Direct)
+41 32 421 48 70 (Secretary)
+41 32 421 48 71 (Fax)
r.eschen at cabi-bioscience.ch

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help


_____
The information in this email is confidential and it may not be\ ... [[dropped]]



From den.duurs at lycos.com  Tue Dec 17 20:32:21 2002
From: den.duurs at lycos.com (Remko Duursma)
Date: Tue Dec 17 20:32:21 2002
Subject: [R] getData.lme error
Message-ID: <AIDNPENODAEDHAAA@mailcity.com>

hi list,

i am making some diagnostic plots using plot.lme(),
my lme model was fit with the option na.action='na.exclude'.

On the following (or similar) commands:

plot(flu.trees.42.w25.10.2,  resid(., type="p") ~ fitted(.)|species, abline=0)

R returns an error message: 
Error in getData.lme(object) : couldn't find function "naAct"

It turns out that the function getData.lme does:

naAct <- eval(mCall$na.action)
    if (!is.null(naAct)) {
        data <- naAct(data)
    }

however, the funcion na.exclude is not properly assigned to naAct
in this way.

Has anyone encountered this before?
What to do?

(i can, ofcourse, refit my model with excluding the NAs myself - but thats not so elegant!)

Thanks,

Remko Duursma


#####################################
Remko A. Duursma, Ph.D. student
Forest Biometrics Lab / Idaho Stable Isotopes Laboratory
Department of Forest Resources
University of Idaho - College of Natural Resources
Email: remkoduursma at yahoo.com
Tel: (208)-885-5165


_____________________________________________________________
Get 25MB, POP3, Spam Filtering with LYCOS MAIL PLUS for $19.95/year.
http://login.mail.lycos.com/brandPage.shtml?pageId=plus&ref=lmtplus



From andy_liaw at merck.com  Tue Dec 17 21:10:20 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue Dec 17 21:10:20 2002
Subject: [R] new version of randomForest
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC9E1@usrymx10.merck.com>

A new version of the randomForest package is now available on CRAN.  The
DESCRIPTION is:

Package: randomForest
Title: Breiman's random forest for classification and regression
Version: 3.4-1
Depends: R (>= 1.5.0)
Author: Fortran original by Leo Breiman and Adele Cutler, R port by Andy
Liaw and Matthew Wiener.
Description: Classification and regression based on a forest of trees using
random inputs.
Maintainer: Andy Liaw <andy_liaw at merck.com>
License: GPL version 2 or later


This version (3.4-1) contains bug fixes as well as some additional features:

o  Error rates or MSE are returned as a vector, so one can 
   examine how they change as number of trees increases.

o  Added a plot() method for randomForest objects, which
   plots the error rates or MSEs.

o  Added var.imp.plot() to plot the variable importance.

o  Added partial.plot() for visualizing marginal effect of
   a predictor variable in regression.

o  Added functions grow() and combine(), which can be used
   to aggregate several randomForest objects into one.  This
   can be useful, e.g., when the forests are ran on different
   machines in parallel, as can be done quite easily with 
   Prof. Tierney's "snow" package.

As always, comments/bug reports/patches welcomed.

Regards,
Andy


Andy I. Liaw, PhD
Biometrics Research          Phone: (732) 594-0820
Merck & Co., Inc.              Fax: (732) 594-1565
P.O. Box 2000, RY84-16            Rahway, NJ 07065
mailto:andy_liaw at merck.com



------------------------------------------------------------------------------



From rreeve at liposcience.com  Tue Dec 17 23:32:03 2002
From: rreeve at liposcience.com (Russell Reeve)
Date: Tue Dec 17 23:32:03 2002
Subject: [R] Summary of multi-way tables: Bug?
Message-ID: <30701A6FBB6D7542B664EED3152F982B04041C@LIPOMAIL.lipomed.lipoprofile.com>

The function summary.table seems to have a bug with the degrees of freedom calculation. summary.table calculates a Pearson chi-squared statistic to test for independence of the factors. Degrees of freedom are calculated as the product of the levels - 1; i.e., for a 2x3x3x2 table, we get df=(2-1)*(3-1)*(3-1)*(2-1) = 4, when one should get df=36-(2-1)-(3-1)-(3-1)-(2-1)-1 = 29. The test statistic is calculated correctly, however. I'm using version 1.5.0; has this been fixed for 1.6? 

As an alternative, loglin works correctly.

Russell Reeve, Ph.D.
Dir of Experimental Design, Analysis, and Quality
rreeve at liposcience.com



From rvaradha at jhsph.edu  Wed Dec 18 00:27:03 2002
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Wed Dec 18 00:27:03 2002
Subject: [R] Multidimensional quadrature using "integrate"
Message-ID: <31b2bb322752.32275231b2bb@jhsph.edu>

Hi:

I was wondering if someone could give me some examples of how to use 
the "integrate" function to perform multi-dimensional quadrature? I 
have a posterior density (up to a constant), for which I'd like to 
evaluate the normalizing constant. 

thanks for any help,
Ravi.



From Alexander.Herr at csiro.au  Wed Dec 18 03:15:04 2002
From: Alexander.Herr at csiro.au (Alexander.Herr@csiro.au)
Date: Wed Dec 18 03:15:04 2002
Subject: [R] summary stats including NA's into new dataframe
Message-ID: <2FE6D3D02CCDD211B80600902745F56C018D11F2@exchange-tv.tvl.qld.csiro.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021218/68f2eceb/attachment.pl

From epakpahan at hki-indonesia.org  Wed Dec 18 03:26:06 2002
From: epakpahan at hki-indonesia.org (epakpahan@hki-indonesia.org)
Date: Wed Dec 18 03:26:06 2002
Subject: [R] meta analysis
Message-ID: <5007.202.158.106.202.1040203539.squirrel@webmail.hki-indonesia.org>

Dear R-lister,
is there any function for Meta Analysis in R? (like homogeneity an, risk 
differences, relative riskm amd odds ratios?

Many thanks,

Edwin



From epakpahan at hki-indonesia.org  Wed Dec 18 04:36:02 2002
From: epakpahan at hki-indonesia.org (epakpahan@hki-indonesia.org)
Date: Wed Dec 18 04:36:02 2002
Subject: [R] meta analysis
Message-ID: <7058.202.158.106.202.1040207786.squirrel@webmail.hki-indonesia.org>

Dear Andy,
I have chekced my R, but the output is as follows...

>library(rmeta)
Error in library(rmeta) : There is no package called `rmeta'

would you please tell me what the problem is??
Thanks,

Edwin



From Ko-Kang at xtra.co.nz  Wed Dec 18 04:51:02 2002
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Wed Dec 18 04:51:02 2002
Subject: [R] meta analysis
References: <7058.202.158.106.202.1040207786.squirrel@webmail.hki-indonesia.org>
Message-ID: <007d01c2a648$6be2b170$c02758db@kwan022>

rmeta package is contributed.  Hence you need to get it from a CRAN site and
install it yourself.

Cheers,

Kevin

------------------------------------------------
Ko-Kang Kevin Wang
Master of Science (MSc) Student
Department of Statistics
University of Auckland
New Zealand
www.stat.auckland.ac.nz/~kwan022

----- Original Message -----
From: "epakpahan"
<epakpahan at hki-indonesia.org>
To: "R-help" <R-help at stat.math.ethz.ch>
Cc: "andy_liaw" <andy_liaw at merck.com>
Sent: Wednesday, December 18, 2002 11:36 PM
Subject: RE: [R] meta analysis


> Dear Andy,
> I have chekced my R, but the output is as follows...
>
> >library(rmeta)
> Error in library(rmeta) : There is no package called `rmeta'
>
> would you please tell me what the problem is??
> Thanks,
>
> Edwin
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



********************************************



From jyan at stat.wisc.edu  Wed Dec 18 07:21:03 2002
From: jyan at stat.wisc.edu (Jun Yan)
Date: Wed Dec 18 07:21:03 2002
Subject: [R] calling La_svd from c code
In-Reply-To: <5007.202.158.106.202.1040203539.squirrel@webmail.hki-indonesia.org>
Message-ID: <Pine.LNX.4.21.0212180004460.5712-100000@istat01.stat.wisc.edu>

I was trying to call the c function La_svd (which was used by R function
La.svd) from my c code (see below), but I keep getting the following error
message in the simple testing:

> dyn.load("/u/j/y/jyan/ludwig/work/newgeese/feepack/src/feepack.so")
> x <- matrix(1:4, 2)
> .Call("try_svd", x)
Error: LAPACK routine DGESVD gave error code -1

I would appreciate if someone can point out what I am missing.

Thanks,   --Jun

===================c code========================
#include <R.h>
#include <Rdefines.h>

  SEXP La_svd(SEXP jobu, SEXP jobv, SEXP x, SEXP s, SEXP u, SEXP v, SEXP
method);

  SEXP try_svd(SEXP x) {
    int *xdims;
    xdims = INTEGER(coerceVector(getAttrib(x, R_DimSymbol), INTSXP));
    int p = xdims[1];

    SEXP jobu, jobv, s, u, v, method, res;

    jobu = PROTECT(allocVector(STRSXP, 1));
    SET_STRING_ELT(jobu, 0, mkChar("A"));

    jobv = PROTECT(allocVector(STRSXP, 1));
    SET_STRING_ELT(jobv, 0, mkChar("A"));

    s = PROTECT(allocVector(REALSXP, p));
    u = PROTECT(allocMatrix(REALSXP, p, p));
    v = PROTECT(allocMatrix(REALSXP, p, p));

    method = PROTECT(allocVector(STRSXP, 1));
    SET_STRING_ELT(jobu, 0, mkChar("dgesvd"));

    res = PROTECT(La_svd(jobu, jobv, x, s, u, v, method)); 
    UNPROTECT(7);
    return res;
  }



From ligges at statistik.uni-dortmund.de  Wed Dec 18 08:25:04 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Dec 18 08:25:04 2002
Subject: [R] meta analysis
In-Reply-To: <7058.202.158.106.202.1040207786.squirrel@webmail.hki-indonesia.org>
References: <7058.202.158.106.202.1040207786.squirrel@webmail.hki-indonesia.org>
Message-ID: <3E00228F.30707@statistik.uni-dortmund.de>

epakpahan at hki-indonesia.org wrote:
> Dear Andy,
> I have chekced my R, but the output is as follows...
> 
> 
>>library(rmeta)
> 
> Error in library(rmeta) : There is no package called `rmeta'
> 
> would you please tell me what the problem is??
> Thanks,
> 
> Edwin

You have to install the package at first (available via CRAN, and please 
read ?install.packages).

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Wed Dec 18 08:33:03 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Dec 18 08:33:03 2002
Subject: [R] summary stats including NA's into new dataframe
In-Reply-To: <2FE6D3D02CCDD211B80600902745F56C018D11F2@exchange-tv.tvl.qld.csiro.au>
References: <2FE6D3D02CCDD211B80600902745F56C018D11F2@exchange-tv.tvl.qld.csiro.au>
Message-ID: <3E002404.2090301@statistik.uni-dortmund.de>

Alexander.Herr at csiro.au wrote:
> List,
> 
> I am trying to extract summary statistics from a data frame with several
> variables (and NAs) into a dataframe with the columns: Variablename (ie the
> colnames of original data), mean, stdev, max, min, Valid N, Missing Values.
> 
> Extracting the statistics is straightforward using stack and aggregate.
> However, I haven't succeeded in obtaining the number of Missing Values. I
> can extract these from describe (Hmisc library), but surely there is a
> simpler way similar to obtaining the mean using aggregate?

The similar way is:

aggregate(......., function(x) sum(is.na(x)))

Uwe Ligges

> Suggestions are much appreciated



From htourneur at free.fr  Wed Dec 18 08:55:03 2002
From: htourneur at free.fr (Henri Tourneur)
Date: Wed Dec 18 08:55:03 2002
Subject: [R] Running R on a Local Area Network
Message-ID: <1040198623.3e002bdf94eb6@imp.free.fr>

A couple of months ago I downloaded R 1.6.0's binary for Windows, which I have 
since been using without any particular problem, that is  on one machine running 
Windows 98.

Last week I set up a local network and have since tried to use R remotely, i.e. 
R is installed on the previous machine and nowhere else.  On the client's side, 
the GUI opens correctly and allows me to do simple computations such as 
x<-1:20
y<-1:20
plot(x,y)

So far, so good. Problem  is with packages which I don't seem to be able to 
access on the server (locally, I repeat, this works fine)

i.e. when I try library()
I get 

no packages found
Warning message: 
libraries `//ServerComputer/c/Program Files/R/rw1060/library', 
`//SERVERCOMPUTER/C/PROGRA~1/R/RW1060/library' contain no packages in: library() 

Does that ring any bell to one of you  ?  Am I trying to do something R was 
never designed to do in the first place ?


Henri



From Jesus.Frias at dit.ie  Wed Dec 18 14:47:03 2002
From: Jesus.Frias at dit.ie (Jesus Frias)
Date: Wed Dec 18 14:47:03 2002
Subject: [R] Binary of Dopt library
In-Reply-To: <1040198623.3e002bdf94eb6@imp.free.fr>
Message-ID: <LGECJJCANFBOOHCMGPJEOEJBCEAA.Jesus.Frias@dit.ie>

Dear R-helpers,

	Would anybody have a compiled binary version (for Windows) of the Dopt
library that is in the development site?.

best regards,

IOsu

--------------------------------------------------------------
Jes?s Mar?a Fr?as Celayeta
Dublin Institute of Technology
School of Food Sci. and Env. Health.
Cathal Bruha St., Dublin 1. Ireland
Phone: +353 1 4024459 Fax: +353 1 4024495
http://www.dit.ie/DIT/tourismfood/science/staff/frias.html
--------------------------------------------------------------


-- 
This message has been scanned for viruses by
the DIT Computer Centre MailScanner Service, 
and is believed to be clean.



From kgk at pharm.auth.gr  Wed Dec 18 15:03:00 2002
From: kgk at pharm.auth.gr (Kyriakos Kachrimanis)
Date: Wed Dec 18 15:03:00 2002
Subject: [R] acceptable p-level for scientific studies
Message-ID: <00b501c2a693$28974200$5e05cf9b@pharm.auth.gr>

Dear list members,

I have a statistical question, that doesn't belong to this list, and I
apologise for that in advance but I would appreciate your help very much.
Is there some convention for selecting the a level for significance testing
in scientific (e.g. chemical processes) studies? Most people use the 0.05
level but I could not find a reference to justify this. Why not 0.01 or 0.1?
Montgomery in his book "Design and Analysis of Experiments" disagrees with
setting a priori acceptable levels at all. Is it necessary to set a limit
for significance testing since R can provide exact probability levels for
the significance of each effect?

Thanks in advance.

Kyriakos Kachrimanis.



From petr.pikal at precheza.cz  Wed Dec 18 15:11:20 2002
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed Dec 18 15:11:20 2002
Subject: [R] from wav to R
Message-ID: <3E0070CE.23749.E31F22@localhost>

Dear all

I would like to perform frequency analysis of a sound (noise) 
recorded as a wav file (I would like to compare different sounds if 
they vary in frequency and how much). I know there exists some 
packages (Cool Edit) for doing frequency analysis of sounds but I 
wonder if anybody tried to do it in R.

I found a package sound. It enables to play with wav files, to 
append them and to make some filtrations. But if I wanted to 
invoke a spectrum() function it did not work with sound object.

Please can somebody give me a hint where to look or how to 
convert wav file to some kind of object analysable by R functions.

Thank you very much.

Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz



From AlessandroSemeria at cramont.it  Wed Dec 18 15:16:40 2002
From: AlessandroSemeria at cramont.it (AlessandroSemeria@cramont.it)
Date: Wed Dec 18 15:16:40 2002
Subject: [R] gene ontology association
Message-ID: <OF2EE8FE01.E45A77A3-ONC1256C83.004F43CD@tomware.it>

Hello! I don't know if there is some R-package able
to associate  ontology  to a long list of GeneBank Name (a txt-tab file or
an XML file), i.e.
I would as output a formatted file with 4 columns (1:GeneBank Name
2,3,4:ontology).
I know that I have to perform a mapping of genes, I got  a  look on
AnnBuilder pkg,
but I 've not idea from where to start.
Some suggestion? Thanks in advance!

A. S.



From fharrell at virginia.edu  Wed Dec 18 15:20:14 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Wed Dec 18 15:20:14 2002
Subject: [R] acceptable p-level for scientific studies
In-Reply-To: <00b501c2a693$28974200$5e05cf9b@pharm.auth.gr>
References: <00b501c2a693$28974200$5e05cf9b@pharm.auth.gr>
Message-ID: <20021218091251.36c5eaae.fharrell@virginia.edu>

On Wed, 18 Dec 2002 14:44:05 +0200
Kyriakos Kachrimanis <kgk at pharm.auth.gr> wrote:

> Dear list members,
> 
> I have a statistical question, that doesn't belong to this list, and I
> apologise for that in advance but I would appreciate your help very much.
> Is there some convention for selecting the a level for significance testing
> in scientific (e.g. chemical processes) studies? Most people use the 0.05
> level but I could not find a reference to justify this. Why not 0.01 or 0.1?
> Montgomery in his book "Design and Analysis of Experiments" disagrees with
> setting a priori acceptable levels at all. Is it necessary to set a limit
> for significance testing since R can provide exact probability levels for
> the significance of each effect?
> 
> Thanks in advance.
> 
> Kyriakos Kachrimanis.
> 

Want to open up the floodgates?  Some personal opinions:

- Alpha=0.05 is arbitrary, silly, and boring
- Reporting P and letting the reader decide is a bit better
- Bayesian posterior probabilities are still better although
  more thinking is required
- Confidence limits can be good compromise solutions (some journals are
  almost disallowing P-values in favor of CLs)
- P-values are dangerous, especially large, small, and in-between ones.
  See http://hesweb1.med.virginia.edu/biostat/teaching/bayes.short.course.pdf for a full sermon.
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From Jesus.Frias at dit.ie  Wed Dec 18 15:23:40 2002
From: Jesus.Frias at dit.ie (Jesus Frias)
Date: Wed Dec 18 15:23:40 2002
Subject: [R] Windows binary of Dopt library
Message-ID: <LGECJJCANFBOOHCMGPJEMEJHCEAA.Jesus.Frias@dit.ie>

Dear R-helpers,

	Would anybody have a compiled binary version (for Windows) of the Dopt
library that is in the development site?.

best regards,

IOsu


--------------------------------------------------------------
Jes?s Mar?a Fr?as Celayeta
Dublin Institute of Technology
School of Food Sci. and Env. Health.
Cathal Bruha St., Dublin 1. Ireland
Phone: +353 1 4024459 Fax: +353 1 4024495
http://www.dit.ie/DIT/tourismfood/science/staff/frias.html
--------------------------------------------------------------


-- 
This message has been scanned for viruses by
the DIT Computer Centre MailScanner Service, 
and is believed to be clean.



From Meriema.Belaidouni at int-evry.fr  Wed Dec 18 15:26:46 2002
From: Meriema.Belaidouni at int-evry.fr (Meriema BELAIDOUNI)
Date: Wed Dec 18 15:26:46 2002
Subject: [R] weibull test
Message-ID: <3E004B8D.74894471@int-evry.fr>

Hello
What is the appropriate method to test if a given distribution is a
weibull
thank you
meriema

email
meriema.belaidouni at int-evry.fr



From htourneur at free.fr  Wed Dec 18 15:29:43 2002
From: htourneur at free.fr (Henri Tourneur)
Date: Wed Dec 18 15:29:43 2002
Subject: [R] Running R on a Local Area Network
Message-ID: <1040206991.3e004c8fea6f6@imp.free.fr>

Spot on Brian !  For those using Windows 98 who might be interested: Right click 
on Network Neighborhood, then Map Network Drive.

Works great !

Thanks a lot,

Henri



From ligges at statistik.uni-dortmund.de  Wed Dec 18 15:34:01 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Dec 18 15:34:01 2002
Subject: [R] Running R on a Local Area Network
In-Reply-To: <1040198623.3e002bdf94eb6@imp.free.fr>
References: <1040198623.3e002bdf94eb6@imp.free.fr>
Message-ID: <3E0036C5.1020309@statistik.uni-dortmund.de>

Henri Tourneur wrote:
> A couple of months ago I downloaded R 1.6.0's binary for Windows, which I have 
> since been using without any particular problem, that is  on one machine running 
> Windows 98.
> 
> Last week I set up a local network and have since tried to use R remotely, i.e. 
> R is installed on the previous machine and nowhere else.  On the client's side, 
> the GUI opens correctly and allows me to do simple computations such as 
> x<-1:20
> y<-1:20
> plot(x,y)
> 
> So far, so good. Problem  is with packages which I don't seem to be able to 
> access on the server (locally, I repeat, this works fine)
> 
> i.e. when I try library()
> I get 
> 
> no packages found
> Warning message: 
> libraries `//ServerComputer/c/Program Files/R/rw1060/library', 
> `//SERVERCOMPUTER/C/PROGRA~1/R/RW1060/library' contain no packages in: library() 
>
> Does that ring any bell to one of you  ?  Am I trying to do something R was 
> never designed to do in the first place ?

We are running R completely from a server (all machines, both server and 
clients, are NT-based, i.e. WinNT, WinXP), and it works without any 
problems.

But you should consider the following points:

- Use a sensible network share (i.e. regularly it's not a good idea to 
share the whole drive).
- Don't use any blanks in the paths. (e.g., we have installed R at the 
following UNC path: "\\server\software\R")
- Assign a drive letter to the UNC path at the client side, e.g. with a 
startup script that includes the line:
  net use s: \\server\software
So you can create a shortcut that starts R at the following location: 
s:\R\bin\RGui.exe

Uwe Ligges



From baron at cattell.psych.upenn.edu  Wed Dec 18 15:38:09 2002
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Wed Dec 18 15:38:09 2002
Subject: [R] acceptable p-level for scientific studies
In-Reply-To: <20021218091251.36c5eaae.fharrell@virginia.edu>; from fharrell@virginia.edu on Wed, Dec 18, 2002 at 09:12:51AM -0500
References: <00b501c2a693$28974200$5e05cf9b@pharm.auth.gr> <20021218091251.36c5eaae.fharrell@virginia.edu>
Message-ID: <20021218092658.A14882@cattell.psych.upenn.edu>

For some further discussion, see
Nickerson, Raymond S. Null hypothesis significance testing: A
review of an old and continuing controversy. [Journal Article]
Psychological Methods. Vol 5(2) Jun 2000, 241-301.



From tona at stat.math.ethz.ch  Wed Dec 18 15:42:12 2002
From: tona at stat.math.ethz.ch (Bruno Tona)
Date: Wed Dec 18 15:42:12 2002
Subject: [R] problem with 'gnls'
Message-ID: <15872.34851.563541.568907@gargle.gargle.HOWL>

I'm working with data measured in a tunnel to estimate the
emission factor of heavy & light vehicles.
I tried to use 'gnls' and I get the following Error:
>> Error in "coef<-.corARMA"(*tmp*, value = c(174.267493382104, 173.412740072763 : 
>> Coefficient matrix not invertible


Here is my R-code:

 data <- d.plabutsch.neu
 
 # calculating the starting coeficients:
 r.CO2.rlm <- rlm(EF.CO2 ~ pLKW.total + Sat + Sun + Fz.total,
                 data = data, method = "MM", na.action =
                 na.exclude)
 START <- coef(r.CO2.rlm); names(START) <- letters[1:5]

 # 'gnls':
 r.CO2.gnls <- gnls(log(EF.CO2) ~ log(a + b * pLKW.total) + c * Sat +
                    d * Sun + e * Fz.total,start = START, data = data,
                    correlation=corARMA(p=p[2],q=0), na.action = na.exclude)



The data d.plabutsch.neu has the following stucture: (Not all columns are NA!)
> str(d.plabutsch.neu)
`data.frame':	806 obs. of  90 variables:
 $ Tag          : num  NA NA NA NA NA NA NA NA NA NA ...
 $ b.Std        : num  NA NA NA NA NA NA NA NA NA NA ...
 $ b.Min        : num  NA NA NA NA NA NA NA NA NA NA ...
 $ e.Std        : num  NA NA NA NA NA NA NA NA NA NA ...
 $ e.Min        : num  NA NA NA NA NA NA NA NA NA NA ...
 $ CO.fresh     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ CO.tunn      : num  NA NA NA NA NA NA NA NA NA NA ...
 $ CO.diff      : num  NA NA NA NA NA NA NA NA NA NA ...
 $ NO.fresh     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ NO.tunn      : num  NA NA NA NA NA NA NA NA NA NA ...
 $ NO.diff      : num  NA NA NA NA NA NA NA NA NA NA ...
 $ NOx.fresh    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ NOx.tunn     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ NOx.diff     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ NOx.fresh    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ NOx.tunn     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ NOx.diff     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ THC.fresh    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ THC.tunn     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ THC.diff     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ PM10.fresh   : num  NA NA NA NA NA NA NA NA NA NA ...
 $ PM10.tunn    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ PM10.diff    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ O3.fresh     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ CO2.fresh    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ CH4.tunn     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ NCH4.tunn    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ SO2.tunn     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Druck.tunn   : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Feucht.tunn  : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Temp.tunn    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Luft.fresh   : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Luft.waste   : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Menge.CO     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Menge.NOx    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Menge.THC    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ EF.CO        : num  NA NA NA NA NA NA NA NA NA NA ...
 $ EF.NOx       : num  NA NA NA NA NA NA NA NA NA NA ...
 $ EF.THC       : num  NA NA NA NA NA NA NA NA NA NA ...
 $ EF.CO2       : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Emission.CO  : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Emission.NOx : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Emission.THC : num  NA NA NA NA NA NA NA NA NA NA ...
 $ PKW.Nord     : int  NA NA NA NA NA NA NA NA NA NA ...
 $ PKW.Sued     : int  NA NA NA NA NA NA NA NA NA NA ...
 $ PKW.total    : int  NA NA NA NA NA NA NA NA NA NA ...
 $ LKW.Nord     : int  NA NA NA NA NA NA NA NA NA NA ...
 $ LKW.Sued     : int  NA NA NA NA NA NA NA NA NA NA ...
 $ LKW.total    : int  NA NA NA NA NA NA NA NA NA NA ...
 $ Fz.Nord      : int  NA NA NA NA NA NA NA NA NA NA ...
 $ Fz.Sued      : int  NA NA NA NA NA NA NA NA NA NA ...
 $ Fz.total     : int  NA NA NA NA NA NA NA NA NA NA ...
 $ pPKW.Nord    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ pPKW.Sued    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ pLKW.Nord    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ pLKW.Sued    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ pPKW.total   : num  NA NA NA NA NA NA NA NA NA NA ...
 $ pLKW.total   : num  NA NA NA NA NA NA NA NA NA NA ...
 $ pPKW.N       : num  NA NA NA NA NA NA NA NA NA NA ...
 $ pPKW.S       : num  NA NA NA NA NA NA NA NA NA NA ...
 $ pLKW.N       : num  NA NA NA NA NA NA NA NA NA NA ...
 $ pLKW.S       : num  NA NA NA NA NA NA NA NA NA NA ...
 $ weekend      : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Sat          : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Sun          : num  NA NA NA NA NA NA NA NA NA NA ...
 $ verbot       : num  NA NA NA NA NA NA NA NA NA NA ...
 $ EF.CO.t1     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ EF.NOx.t1    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ EF.THC.t1    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ EF.CO2.t1    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ EF.CO.t2     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ EF.NOx.t2    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ EF.THC.t2    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ EF.CO2.t2    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ EF.CO.t3     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ EF.NOx.t3    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ EF.THC.t3    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ EF.CO2.t3    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ pLKW.total.t1: num  NA NA NA NA NA NA NA NA NA NA ...
 $ Sat.t1       : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Sun.t1       : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Fz.total.t1  : int  NA NA NA NA NA NA NA NA NA NA ...
 $ pLKW.total.t2: num  NA NA NA NA NA NA NA NA NA NA ...
 $ Sat.t2       : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Sun.t2       : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Fz.total.t2  : int  NA NA NA NA NA NA NA NA NA NA ...
 $ pLKW.total.t3: num  NA NA NA NA NA NA NA NA NA NA ...
 $ Sat.t3       : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Sun.t3       : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Fz.total.t3  : int  NA NA NA NA NA NA NA NA NA NA ...


I also tried with an AR(3) and an AR(1). The AR(3) gives the same
error like above and the AR(1) gives the error:
>> Error in optim(fn = function(gnlsPars) -logLik(gnlsSt, gnlsPars), par = c(coef(gnlsSt)),  : 
>> 	initial value in vmmin is not finite
>> In addition: There were 14 warnings (use warnings() to see them)

Thanks for any help

regards
Bruno Tona



From ripley at stats.ox.ac.uk  Wed Dec 18 15:45:30 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed Dec 18 15:45:30 2002
Subject: [R] Running R on a Local Area Network
In-Reply-To: <1040198623.3e002bdf94eb6@imp.free.fr>
Message-ID: <Pine.LNX.4.31.0212180823450.9787-100000@gannet.stats>

You should try mapping your remote files to a local drive. It's absolutely
normal to do so.  I have no idea why this is not working, as all the I/O
is done via normal Windows API calls.  Once mapped it certainly works:
our lab has R on the N: drive, which is served from a remote Linux Samba
server.

By the way, I am sure you are not trying to run R remotely: R is running
on the local machine but using files served from a remote machine without
being mounted.  This is equivalent to expecting server:/usr/local/bin/R
syntax to work on a Unix box (which it will not).

On Wed, 18 Dec 2002, Henri Tourneur wrote:

> A couple of months ago I downloaded R 1.6.0's binary for Windows, which I have
> since been using without any particular problem, that is  on one machine running
> Windows 98.
>
> Last week I set up a local network and have since tried to use R remotely, i.e.
> R is installed on the previous machine and nowhere else.  On the client's side,
> the GUI opens correctly and allows me to do simple computations such as
> x<-1:20
> y<-1:20
> plot(x,y)
>
> So far, so good. Problem  is with packages which I don't seem to be able to
> access on the server (locally, I repeat, this works fine)
>
> i.e. when I try library()
> I get
>
> no packages found
> Warning message:
> libraries `//ServerComputer/c/Program Files/R/rw1060/library',
> `//SERVERCOMPUTER/C/PROGRA~1/R/RW1060/library' contain no packages in: library()
>
> Does that ring any bell to one of you  ?  Am I trying to do something R was
> never designed to do in the first place ?
>
>
> Henri
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From christian.ritter at shell.com  Wed Dec 18 15:52:06 2002
From: christian.ritter at shell.com (Ritter, Christian C MCIL-CTGAS)
Date: Wed Dec 18 15:52:06 2002
Subject: [R] Chasing after the Windows/Xemacs/R1.6.1 graphics device bug
Message-ID: <156CDC8CCFD1894295D2907F16337A481FA874@bru-s-006.europe.shell.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021218/32283548/attachment.pl

From isung at epidemiology.com  Wed Dec 18 16:01:03 2002
From: isung at epidemiology.com (Iyue Sung)
Date: Wed Dec 18 16:01:03 2002
Subject: [R] workspace vs. image
Message-ID: <433782665F24734CB1EDEF38E0F9F3EF329360@ntserver>

Hello [R]ians,

  I'm hoping someone can clarify the difference between a Workspace Image 
and Working Directory.  I created a directory on my PC, say,
"C:\Program Files\R\Project1" and then saved my objects in
"C:\Program Files\R\Project1\.Rdata".

Then, in a subsequent session, I reloaded these objects using

> load("C:/Program Files/R/Project1/.RData")

At first, I thought I was suppose to use

> setwd("C:\\Program Files\\R\\Project1")  

and that R would automatically use "C:/Program Files/R/Project1/.RData".
But this appears not to be the case.  
I got this impression from Section 1.11 of "An Introduction to R" which states 
"...objects are written to a file called '.RData' in the current directory".

What "things" then, should go in the Workspace Image but not the Working Directory
and vice versa (Plots?), and what am I not understanding?

Gratefully Yours,

Iyue

-----------------------------------------
Iyue Sung, PhD
Ingenix , Epidemiology Division 
-----------------------------------------



From bwheeler at echip.com  Wed Dec 18 16:12:02 2002
From: bwheeler at echip.com (Bob Wheeler)
Date: Wed Dec 18 16:12:02 2002
Subject: [R] Windows binary of Dopt library
References: <LGECJJCANFBOOHCMGPJEMEJHCEAA.Jesus.Frias@dit.ie>
Message-ID: <3E008FE2.2F29EE4E@echip.com>

I'll send you a copy if you like. The program seems buggy.
The Cholesky decomposition in particular. It may be nothing
more than a transcription error in the Fortran, but you
should check any results it produces. Let me know if you
want it.


Jesus Frias wrote:
> 
> Dear R-helpers,
> 
>         Would anybody have a compiled binary version (for Windows) of the Dopt
> library that is in the development site?.
> 
> best regards,
> 
> IOsu
> 
> --------------------------------------------------------------
> Jes?s Mar?a Fr?as Celayeta
> Dublin Institute of Technology
> School of Food Sci. and Env. Health.
> Cathal Bruha St., Dublin 1. Ireland
> Phone: +353 1 4024459 Fax: +353 1 4024495
> http://www.dit.ie/DIT/tourismfood/science/staff/frias.html
> --------------------------------------------------------------
> 
> --
> This message has been scanned for viruses by
> the DIT Computer Centre MailScanner Service,
> and is believed to be clean.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Bob Wheeler --- (Reply to: bwheeler at echip.com)
        ECHIP, Inc. --- (302) 239-6620, voice FAX
           724 Yorklyn Rd., Hockessin, DE 19707
              Randomness comes in bunches



From christian.ritter at shell.com  Wed Dec 18 16:41:06 2002
From: christian.ritter at shell.com (Ritter, Christian C MCIL-CTGAS)
Date: Wed Dec 18 16:41:06 2002
Subject: [R] A little problem handling logicals in RMySQL under R1.6.1
Message-ID: <156CDC8CCFD1894295D2907F16337A481FA875@bru-s-006.europe.shell.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021218/0039ad52/attachment.pl

From paradis at isem.univ-montp2.fr  Wed Dec 18 16:54:40 2002
From: paradis at isem.univ-montp2.fr (Emmanuel Paradis)
Date: Wed Dec 18 16:54:40 2002
Subject: [R] weibull test
In-Reply-To: <3E004B8D.74894471@int-evry.fr>
Message-ID: <4.2.0.58.20021218161330.00b31688@162.38.183.200>

At 11:18 18/12/2002 +0100, vous avez ?crit:
>Hello
>What is the appropriate method to test if a given distribution is a
>weibull
>thank you
>meriema
>
>email
>meriema.belaidouni at int-evry.fr

You can use a Kolmogorov-Smirnov test. See ?ks.test where there is an 
example with a gamma distribution. You will probably need to estimate the 
parameters  of the Weibull which you can do with fitdistr() in package MASS.

However, I don't know if the distribution of the KS test will be the same 
if some parameters are estimated from the data or not (apparently, 
ks.test() doesn't do any correction). Someone on the list can help here.

Emmanuel Paradis



From ligges at statistik.uni-dortmund.de  Wed Dec 18 17:02:06 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed Dec 18 17:02:06 2002
Subject: [R] from wav to R
In-Reply-To: <3E0070CE.23749.E31F22@localhost>
References: <3E0070CE.23749.E31F22@localhost>
Message-ID: <3E0095BF.4040501@statistik.uni-dortmund.de>

Petr Pikal wrote:
> Dear all
> 
> I would like to perform frequency analysis of a sound (noise) 
> recorded as a wav file (I would like to compare different sounds if 
> they vary in frequency and how much). I know there exists some 
> packages (Cool Edit) for doing frequency analysis of sounds but I 
> wonder if anybody tried to do it in R.
> 
> I found a package sound. It enables to play with wav files, to 
> append them and to make some filtrations. But if I wanted to 
> invoke a spectrum() function it did not work with sound object.
> 
> Please can somebody give me a hint where to look or how to 
> convert wav file to some kind of object analysable by R functions.

If you did
  mywave <- loadSample(.....)
the data you are trying to analyze is in the matrix
  mywave$sound


Uwe Ligges



From paradis at isem.univ-montp2.fr  Wed Dec 18 17:06:28 2002
From: paradis at isem.univ-montp2.fr (Emmanuel Paradis)
Date: Wed Dec 18 17:06:28 2002
Subject: [R] workspace vs. image
In-Reply-To: <433782665F24734CB1EDEF38E0F9F3EF329360@ntserver>
Message-ID: <4.2.0.58.20021218164704.00b5c388@162.38.183.200>

At 09:58 18/12/2002 -0500, vous avez ?crit:

>Hello [R]ians,
>
>   I'm hoping someone can clarify the difference between a Workspace Image
>and Working Directory.  I created a directory on my PC, say,
>"C:\Program Files\R\Project1" and then saved my objects in
>"C:\Program Files\R\Project1\.Rdata".
>
>Then, in a subsequent session, I reloaded these objects using
>
> > load("C:/Program Files/R/Project1/.RData")
>
>At first, I thought I was suppose to use
>
> > setwd("C:\\Program Files\\R\\Project1")

This changes the working directory only for the current session.


>and that R would automatically use "C:/Program Files/R/Project1/.RData".
>But this appears not to be the case.
>I got this impression from Section 1.11 of "An Introduction to R" which 
>states
>"...objects are written to a file called '.RData' in the current directory".
>
>What "things" then, should go in the Workspace Image but not the Working 
>Directory
>and vice versa (Plots?), and what am I not understanding?

Under Windows, the most practical solution is to create a short-cut of 
Rgui.exe, right-click on it, and then modify the directory in the field 
"Start in:" under the tab "Short-cut". When started from this short-cut, R 
will use this directory as its working directory, and load any .RData if 
there is one there. You can then create as many short-cuts as you want, 
each with its own working directory.

Hope this helps.

Emmanuel Paradis

>Gratefully Yours,
>
>Iyue
>
>-----------------------------------------
>Iyue Sung, PhD
>Ingenix , Epidemiology Division
>-----------------------------------------
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tlumley at u.washington.edu  Wed Dec 18 17:09:34 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed Dec 18 17:09:34 2002
Subject: [R] workspace vs. image
In-Reply-To: <433782665F24734CB1EDEF38E0F9F3EF329360@ntserver>
Message-ID: <Pine.A41.4.44.0212180800020.135446-100000@homer38.u.washington.edu>

On Wed, 18 Dec 2002, Iyue Sung wrote:

>
> Hello [R]ians,
>
>   I'm hoping someone can clarify the difference between a Workspace Image
> and Working Directory.  I created a directory on my PC, say,

The workspace image is a file (containing an R workspace), the working
directory is a directory

> "C:\Program Files\R\Project1" and then saved my objects in
> "C:\Program Files\R\Project1\.Rdata".

Good.

> Then, in a subsequent session, I reloaded these objects using
>
> > load("C:/Program Files/R/Project1/.RData")

Yes.

> At first, I thought I was suppose to use
>
> > setwd("C:\\Program Files\\R\\Project1")
>
> and that R would automatically use "C:/Program Files/R/Project1/.RData".
> But this appears not to be the case.

No, because it's too late by then.

At startup R automatically looks for .RData in the directory that it is
started in, the initial working directory.  Changing the working directory
afterwards won't make a new .RData be loaded

To change which workspace is loaded at startup you need to change the
directory R starts in.  The easiest way to do this under Windows is
probably to make a number of different R shortcuts and set the 'Start in'
directory in the Properties tab of each one.

> I got this impression from Section 1.11 of "An Introduction to R" which states
> "...objects are written to a file called '.RData' in the current directory".

Yes. The current directory when the writing or reading is happening.

> What "things" then, should go in the Workspace Image but not the Working Directory
> and vice versa (Plots?), and what am I not understanding?

R reads and writes everything in the current working directory unless told
otherwise.  I think you aren't understanding `current'


	-thomas



From murali_vemula at hms.harvard.edu  Wed Dec 18 17:13:07 2002
From: murali_vemula at hms.harvard.edu (Muralikrishna Vemula)
Date: Wed Dec 18 17:13:07 2002
Subject: [R] rat array annotation
Message-ID: <3E01002E@webmail.med.harvard.edu>

Hi All,

I am working with rat genome array (RGU34A). I have identified a set of 350 
genes. I am looking for a way to get pubmed abstracts (as much as 10 per 
gene). Is there a package or function in R that can do this? Thanks for all 
help.

Murali



From rgentlem at jimmy.harvard.edu  Wed Dec 18 17:19:05 2002
From: rgentlem at jimmy.harvard.edu (Robert Gentleman)
Date: Wed Dec 18 17:19:05 2002
Subject: [R] rat array annotation
In-Reply-To: <3E01002E@webmail.med.harvard.edu>; from murali_vemula@hms.harvard.edu on Wed, Dec 18, 2002 at 11:12:52AM -0500
References: <3E01002E@webmail.med.harvard.edu>
Message-ID: <20021218111839.U3064@jimmy.harvard.edu>

Much of what you want to do is available from the Bioconductor
website. www.bioconductor.org and in an R News article from earlier
this year (these are easily obtained from www.r-project.org).

Please direct more specific questions to the Bioconductor mailing list
as these are not really about R, but rather about a specialized set of
routines for comp. biology using R.

 Robert

On Wed, Dec 18, 2002 at 11:12:52AM -0500, Muralikrishna Vemula wrote:
> Hi All,
> 
> I am working with rat genome array (RGU34A). I have identified a set of 350 
> genes. I am looking for a way to get pubmed abstracts (as much as 10 per 
> gene). Is there a package or function in R that can do this? Thanks for all 
> help.
> 
> Murali
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
+---------------------------------------------------------------------------+
| Robert Gentleman                 phone : (617) 632-5250                   |
| Associate Professor              fax:   (617)  632-2444                   |
| Department of Biostatistics      office: M1B20
| Harvard School of Public Health  email: rgentlem at jimmy.dfci.harvard.edu   |
+---------------------------------------------------------------------------+



From kjetilh at umsanet.edu.bo  Wed Dec 18 17:24:06 2002
From: kjetilh at umsanet.edu.bo (kjetil halvorsen)
Date: Wed Dec 18 17:24:06 2002
Subject: [R] Windows binary of Dopt library
References: <LGECJJCANFBOOHCMGPJEMEJHCEAA.Jesus.Frias@dit.ie> <3E008FE2.2F29EE4E@echip.com>
Message-ID: <3E009F41.B9B279CB@umsanet.edu.bo>

Yes, the program is buggy, and the problem is with the fortran code (it
is not a transcription error). I tried sometimes to debug the fortran
code, but have given  up on that. Still the program is usefull, BUT it
will
bomb R for some input!. So save your workspace before using. 
If yoy want block sizes 2, it always bomb, but I have seen it bomb with
block size 3 also.

Kjetil Halvorsen



Bob Wheeler wrote:
> 
> I'll send you a copy if you like. The program seems buggy.
> The Cholesky decomposition in particular. It may be nothing
> more than a transcription error in the Fortran, but you
> should check any results it produces. Let me know if you
> want it.
> 
> Jesus Frias wrote:
> >
> > Dear R-helpers,
> >
> >         Would anybody have a compiled binary version (for Windows) of the Dopt
> > library that is in the development site?.
> >
> > best regards,
> >
> > IOsu
> >
> > --------------------------------------------------------------
> > Jes?s Mar?a Fr?as Celayeta
> > Dublin Institute of Technology
> > School of Food Sci. and Env. Health.
> > Cathal Bruha St., Dublin 1. Ireland
> > Phone: +353 1 4024459 Fax: +353 1 4024495
> > http://www.dit.ie/DIT/tourismfood/science/staff/frias.html
> > --------------------------------------------------------------
> >
> > --
> > This message has been scanned for viruses by
> > the DIT Computer Centre MailScanner Service,
> > and is believed to be clean.
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> --
> Bob Wheeler --- (Reply to: bwheeler at echip.com)
>         ECHIP, Inc. --- (302) 239-6620, voice FAX
>            724 Yorklyn Rd., Hockessin, DE 19707
>               Randomness comes in bunches
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kjetilh at umsanet.edu.bo  Wed Dec 18 17:30:03 2002
From: kjetilh at umsanet.edu.bo (kjetil halvorsen)
Date: Wed Dec 18 17:30:03 2002
Subject: [R] weibull test
References: <4.2.0.58.20021218161330.00b31688@162.38.183.200>
Message-ID: <3E00A0A7.1FF56C7@umsanet.edu.bo>

I don't know the answer, but there must be something better than the KS
test?, but maybe not in R. If you can think about an alternative you can
construct a likelihood ratio test.

Kjetil Halvorsen

Emmanuel Paradis wrote:
> 
> At 11:18 18/12/2002 +0100, vous avez ?crit:
> >Hello
> >What is the appropriate method to test if a given distribution is a
> >weibull
> >thank you
> >meriema
> >
> >email
> >meriema.belaidouni at int-evry.fr
> 
> You can use a Kolmogorov-Smirnov test. See ?ks.test where there is an
> example with a gamma distribution. You will probably need to estimate the
> parameters  of the Weibull which you can do with fitdistr() in package MASS.
> 
> However, I don't know if the distribution of the KS test will be the same
> if some parameters are estimated from the data or not (apparently,
> ks.test() doesn't do any correction). Someone on the list can help here.
> 
> Emmanuel Paradis
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kjetilh at umsanet.edu.bo  Wed Dec 18 17:34:03 2002
From: kjetilh at umsanet.edu.bo (kjetil halvorsen)
Date: Wed Dec 18 17:34:03 2002
Subject: [R] Binary of Dopt library
References: <LGECJJCANFBOOHCMGPJEOEJBCEAA.Jesus.Frias@dit.ie>
Message-ID: <3E009CD7.BC858FC3@umsanet.edu.bo>

I''ll send you one tomorrow.

Kjetil Halvorsen



Jesus Frias wrote:
> 
> Dear R-helpers,
> 
>         Would anybody have a compiled binary version (for Windows) of the Dopt
> library that is in the development site?.
> 
> best regards,
> 
> IOsu
> 
> --------------------------------------------------------------
> Jes?s Mar?a Fr?as Celayeta
> Dublin Institute of Technology
> School of Food Sci. and Env. Health.
> Cathal Bruha St., Dublin 1. Ireland
> Phone: +353 1 4024459 Fax: +353 1 4024495
> http://www.dit.ie/DIT/tourismfood/science/staff/frias.html
> --------------------------------------------------------------
> 
> --
> This message has been scanned for viruses by
> the DIT Computer Centre MailScanner Service,
> and is believed to be clean.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From isung at epidemiology.com  Wed Dec 18 17:39:02 2002
From: isung at epidemiology.com (Iyue Sung)
Date: Wed Dec 18 17:39:02 2002
Subject: [R] workspace vs. image
Message-ID: <433782665F24734CB1EDEF38E0F9F3EF31AA9C@ntserver>

Thanks for the reply Thomas, I think I (am starting to) understand.

But it appears that if I load, "C:\Program Files\R\Project1\.RData",
after starting in the directory "C:\Program Files\R\rw1060", 
R will save the objects I create in the current session in both
"C:~\Project1" and "C:~\rw1060".  

So, if all I really care about is making sure objects for 
projects are stored in different .RData files, why would it
matter which directory I start in? 

Thanks,
Iyue


> -----Original Message-----
> From: Thomas Lumley [mailto:tlumley at u.washington.edu]
> Sent: Wednesday, December 18, 2002 11:05 AM
> To: Iyue Sung
> Cc: R-help at stat.math.ethz.ch
> Subject: Re: [R] workspace vs. image
> 
> 
> On Wed, 18 Dec 2002, Iyue Sung wrote:
> 
> >
> > Hello [R]ians,
> >
> >   I'm hoping someone can clarify the difference between a 
> Workspace Image
> > and Working Directory.  I created a directory on my PC, say,
> 
> The workspace image is a file (containing an R workspace), the working
> directory is a directory
> 
> > "C:\Program Files\R\Project1" and then saved my objects in
> > "C:\Program Files\R\Project1\.Rdata".
> 
> Good.
> 
> > Then, in a subsequent session, I reloaded these objects using
> >
> > > load("C:/Program Files/R/Project1/.RData")
> 
> Yes.
> 
> > At first, I thought I was suppose to use
> >
> > > setwd("C:\\Program Files\\R\\Project1")
> >
> > and that R would automatically use "C:/Program 
> Files/R/Project1/.RData".
> > But this appears not to be the case.
> 
> No, because it's too late by then.
> 
> At startup R automatically looks for .RData in the directory 
> that it is
> started in, the initial working directory.  Changing the 
> working directory
> afterwards won't make a new .RData be loaded
> 
> To change which workspace is loaded at startup you need to change the
> directory R starts in.  The easiest way to do this under Windows is
> probably to make a number of different R shortcuts and set 
> the 'Start in'
> directory in the Properties tab of each one.
> 
> > I got this impression from Section 1.11 of "An Introduction 
> to R" which states
> > "...objects are written to a file called '.RData' in the 
> current directory".
> 
> Yes. The current directory when the writing or reading is happening.
> 
> > What "things" then, should go in the Workspace Image but 
> not the Working Directory
> > and vice versa (Plots?), and what am I not understanding?
> 
> R reads and writes everything in the current working 
> directory unless told
> otherwise.  I think you aren't understanding `current'
> 
> 
> 	-thomas
> 
> 
>



From Alexander.Hener at daimlerchrysler.com  Wed Dec 18 19:37:02 2002
From: Alexander.Hener at daimlerchrysler.com (Alexander.Hener@daimlerchrysler.com)
Date: Wed Dec 18 19:37:02 2002
Subject: [R] Alexander Hener/FT/DCAG/DCX is out of office.
Message-ID: <0057440046335027000002L472*@MHS>

Ich werde ab  18.12.2002 nicht im B?ro sein. Ich kehre zur?ck am  13.01.2003.



From p.dalgaard at biostat.ku.dk  Wed Dec 18 19:43:03 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed Dec 18 19:43:03 2002
Subject: [R] acceptable p-level for scientific studies
In-Reply-To: <20021218091251.36c5eaae.fharrell@virginia.edu>
References: <00b501c2a693$28974200$5e05cf9b@pharm.auth.gr>
	<20021218091251.36c5eaae.fharrell@virginia.edu>
Message-ID: <x2lm2ntbij.fsf@biostat.ku.dk>

Frank E Harrell Jr <fharrell at virginia.edu> writes:

> - Confidence limits can be good compromise solutions (some journals are
>   almost disallowing P-values in favor of CLs)

I gather that some journals *are* doing that, to the extent of
actually disallowing multi-df testing (I'll say that it is a case of
proselytes being holier than the prophets). And of course a 95% CI is
strongly linked to testing at a fixed significance level, so the
information contained in the P-value is lost that way.

> - P-values are dangerous, especially large, small, and in-between ones.

<grin> Good one...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From apollo_w at yahoo.com  Wed Dec 18 21:48:03 2002
From: apollo_w at yahoo.com (apollo wong)
Date: Wed Dec 18 21:48:03 2002
Subject: [R] Memory leak in R v1.6.0?
Message-ID: <20021218201620.98589.qmail@web40904.mail.yahoo.com>

I have a function that needs to be repeated many times
with for loop. I have take measure to rm all the big
arrays that was used in the function. The only array
that cannot be rm was the return arrays. The loop
needed to be repeat for over 2000 times and I am using
v1.6.0 in Windows 2000
 When I look at the task manager, I see that the
memory used by R keep going up and reach more than 1G
byte after 700 iteration or so. I have try including
gc after every loop. No help at all. I'll appreciate
any suggestion. 
 What is the command to free up unused memory in R
other than relying on automatic garbage collection? Is
there a free command in R?
 Thanks
Apollo Wong



From jgentry at jimmy.harvard.edu  Wed Dec 18 21:56:14 2002
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Wed Dec 18 21:56:14 2002
Subject: [R] Memory leak in R v1.6.0?
In-Reply-To: <20021218201620.98589.qmail@web40904.mail.yahoo.com>
Message-ID: <Pine.SOL.4.20.0212181550430.29690-100000@santiam.dfci.harvard.edu>

>  When I look at the task manager, I see that the
> memory used by R keep going up and reach more than 1G
> byte after 700 iteration or so. I have try including
> gc after every loop. No help at all. I'll appreciate
> any suggestion. 

Have you tried R1.6.1?  I believe it fixes this problem.

-J



From Zhongming.Yang at cchmc.org  Wed Dec 18 21:59:05 2002
From: Zhongming.Yang at cchmc.org (Zhongming Yang)
Date: Wed Dec 18 21:59:05 2002
Subject: [R] Can I build an array of regrssion model?
Message-ID: <se0099cf.046@mailx.chmcc.org>

Hi,

I am trying to use piecewise linear regression to approximate a
nonlinear function. Actually, I don't know how many linear functions I
need, therefore, I want build an array of regression models to automate
the approximation job. Could you please give me any clue?

Attached is ongoing code:

rawData = scan("c:/zyang/mass/data/A01/1.PRN",
what=list(numeric(),numeric()));
len = length(rawData[[1]]);
cuts = len*c(0.01, 0.03, 0.08, 0.18, 0.38, 0.69, 1);
cuts = as.integer(cuts); 

mod1 = lm(rawData[[2]][1:cuts[1]]~rawData[[1]][1:cuts[1]]);
mod2 =
lm(rawData[[2]][cuts[1]:cuts[2]]~rawData[[1]][cuts[1]:cuts[2]]);
mod3 =
lm(rawData[[2]][cuts[2]:cuts[3]]~rawData[[1]][cuts[2]:cuts[3]]);
mod4 =
lm(rawData[[2]][cuts[3]:cuts[4]]~rawData[[1]][cuts[3]:cuts[4]]);
mod5 =
lm(rawData[[2]][cuts[4]:cuts[5]]~rawData[[1]][cuts[4]:cuts[5]]);
mod6 =
lm(rawData[[2]][cuts[5]:cuts[6]]~rawData[[1]][cuts[5]:cuts[6]]);
mod7 =
lm(rawData[[2]][cuts[6]:cuts[7]]~rawData[[1]][cuts[6]:cuts[7]]);

plot(rawData[[1]],rawData[[2]],type='l', col="green", xlab="Da/z",
ylab="m/z");
abline(mod1, lty="1", col="red");
abline(mod2, lty="1", col="red");
abline(mod3, lty="1", col="red");
abline(mod4, lty="1", col="red");
abline(mod5, lty="1", col="red");
abline(mod6, lty="1", col="red");
abline(mod7, lty="1", col="red");







Thanks in advance,



From rolf at math.unb.ca  Wed Dec 18 22:02:00 2002
From: rolf at math.unb.ca (Rolf Turner)
Date: Wed Dec 18 22:02:00 2002
Subject: [R] Kernel smoothing.
Message-ID: <200212182053.QAA03667@gelfand.math.unb.ca>

I wish to produce a weighted (Gaussian?) kernel density estimate, in
2 dimensions, where the weights are permitted to be ***negative***.
(I can ASSURE you that there are perfectly legitimate reasons why I
want to do this.  :-)) Clearly it is not really a density that I am
trying to estimate.

I had a go at using sm.density() from the sm package, but this
requires that the weights be positive.  Is there any software lurking
in the undergrowth that I could use for my purpose?  Or bits and
pieces that could give me a start on building the machine that I
need?

Ta.

			cheers,

				Rolf Turner
				rolf at math.unb.ca



From rpeng at stat.ucla.edu  Wed Dec 18 22:05:05 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Wed Dec 18 22:05:05 2002
Subject: [R] Memory leak in R v1.6.0?
In-Reply-To: <20021218201620.98589.qmail@web40904.mail.yahoo.com>
Message-ID: <Pine.GSO.4.10.10212181257400.17704-100000@fisher.stat.ucla.edu>

There was a memory leak discovered in R 1.6.0 but it's difficult to tell
if this is in fact causing your problem.  At any rate, you should upgrade
to version 1.6.1 (the latest release).

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Wed, 18 Dec 2002, apollo wong wrote:

> I have a function that needs to be repeated many times
> with for loop. I have take measure to rm all the big
> arrays that was used in the function. The only array
> that cannot be rm was the return arrays. The loop
> needed to be repeat for over 2000 times and I am using
> v1.6.0 in Windows 2000
>  When I look at the task manager, I see that the
> memory used by R keep going up and reach more than 1G
> byte after 700 iteration or so. I have try including
> gc after every loop. No help at all. I'll appreciate
> any suggestion. 
>  What is the command to free up unused memory in R
> other than relying on automatic garbage collection? Is
> there a free command in R?
>  Thanks
> Apollo Wong
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From molinaro at cc.ucsf.edu  Wed Dec 18 22:30:03 2002
From: molinaro at cc.ucsf.edu (Annette Molinaro)
Date: Wed Dec 18 22:30:03 2002
Subject: [R] Memory Leak in R v1.6.1
Message-ID: <004901c2a6dc$af9ec8b0$0301a8c0@ccmolinarolt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021218/4d57d9f3/attachment.pl

From dj at research.bell-labs.com  Wed Dec 18 22:50:03 2002
From: dj at research.bell-labs.com (David James)
Date: Wed Dec 18 22:50:03 2002
Subject: [R] A little problem handling logicals in RMySQL under R1.6.1
In-Reply-To: <156CDC8CCFD1894295D2907F16337A481FA875@bru-s-006.europe.shell.com>; from christian.ritter@shell.com on Wed, Dec 18, 2002 at 04:39:41PM +0100
References: <156CDC8CCFD1894295D2907F16337A481FA875@bru-s-006.europe.shell.com>
Message-ID: <20021218164923.A13489@jessie.research.bell-labs.com>

Hi Christian,

Thanks a lot for the bug report and the fix.  I ended up modifying your fix
only very slightly:
    
    for(i in seq(along = value)){
        if(is(value[[i]], "logical"))
           value[[i]] <- as(value[[i]], "integer")
    }
    
[the idiom class(x) <- "foo", when using library(methods) is "strongly
deprecated" -- see help("class", package = "methods").]

Regards,

--
David

Ritter, Christian C MCIL-CTGAS wrote:
> There is a little problem in handling logicals in RMySQL:
> 
> # here is the MySQL connection
> > con
> <MySQLConnection:(1816,0)> 
> 
> # here is the data frame
> > print(a<-data.frame(x=c(TRUE,FALSE),y=c(FALSE,TRUE)))
>       x     y
> 1  TRUE FALSE
> 2 FALSE  TRUE
> 
> # as promised, the two data frame columns are identified as logicals and 
> # the field types are set to tinyint
> > field.types <- sapply(a, dbDataType, dbObj = con)
> > field.types
>         x         y 
> "tinyint" "tinyint" 
> 
> #  However, in WriteTable, nothing is done to convert the logicals to 0s and 1s.
> #  And logically, the infile is written in TRUE and FALSE and finally, in MySQL
> #  all becomes zero. Here is what we get in MySQL:
> # 	row_names  x  y  
> # 	1 0 0 
> # 	2 0 0 
> #
> # So, logically this is what we get back in R:
> > dbWriteTable(con,"test",a)
> [1] TRUE
> > aa<-dbReadTable(con,"test")
> > aa
>   x y
> 1 0 0
> 2 0 0
> > 
> # and this is clearly not what we want... 
> # 
> # as a crude patch I added for (i in 1:length(value)) if (class(value[[i]])=="logical") class(value[[i]])<-"integer"
> # before i <- match("row.names", ... in mysqlWriteTable 
> # but others have much more talent in writing clean code than I ...
> # 
> > mysqlWriteTablecrudepatch(con,"test",a,overwrite=TRUE)
> [1] TRUE
> # and
> > aa<-dbReadTable(con,"test")
> > aa
>   x y
> 1 1 0
> 2 0 1
> # and this IS what we want.
> 
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    1              
> minor    6.1            
> year     2002           
> month    11             
> day      01             
> language R              
> 
> 
> 
> Christian Ritter
> Functional Specialist Statistics
> Shell Coordination Centre S.A.
> Monnet Centre International Laboratory, Avenue Jean Monnet 1, B-1348 Louvain-La-Neuve, Belgium
> 
> Tel: +32 10 477  349 Fax: +32 10 477 219
> Email: christian.ritter at shell.com
> Internet: http://www.shell.com/chemicals
> 
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
David A. James
Statistics Research, Room 2C-253            Phone:  (908) 582-3082       
Bell Labs, Lucent Technologies              Fax:    (908) 582-3340
Murray Hill, NJ 09794-0636



From jasont at indigoindustrial.co.nz  Wed Dec 18 23:09:03 2002
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed Dec 18 23:09:03 2002
Subject: [R] Can I build an array of regrssion model?
In-Reply-To: <se0099cf.046@mailx.chmcc.org>; from Zhongming.Yang@cchmc.org on Wed, Dec 18, 2002 at 03:51:47PM -0500
References: <se0099cf.046@mailx.chmcc.org>
Message-ID: <20021219110816.A12597@camille.indigoindustrial.co.nz>

On Wed, Dec 18, 2002 at 03:51:47PM -0500, Zhongming Yang wrote:
> I am trying to use piecewise linear regression to approximate a
> nonlinear function. 

Why not smooth regression, or non-linear regression?

> Actually, I don't know how many linear functions I
> need, therefore, I want build an array of regression models to automate
> the approximation job. Could you please give me any clue?

Clue 1) See above.  You might be using the wrong tool.  A smooth
regression might be better here.  help(loess), library(gss), and
library(sm) are your friends.

Clue 2) If you really want piecewise linear, a list makes more
sense than a vector.  R does handle vectors quite nicely, but I
find its real strength is the way it handles complex lists with
ease.

> Attached is ongoing code:
> 
> rawData = scan("c:/zyang/mass/data/A01/1.PRN",
> what=list(numeric(),numeric()));
> len = length(rawData[[1]]);
> cuts = len*c(0.01, 0.03, 0.08, 0.18, 0.38, 0.69, 1);
> cuts = as.integer(cuts); 

#change cuts to a matrix of values, col 1 is the lower
#bound, col 2 is the upper bound for your segments.

cuts <- cbind(c(1,cuts[1:(length(cuts)-1)], cuts)

#make an empty list
mod.list <- list()
#fill that list with models
for(ii in 1:dim(cuts)[1]) { 
	start <- cuts[ii,1]
	end <- cuts[ii,2]
	mod.list[[ii]] <- lm(rawData[[2]][start,end] ~ rawData[[1]][start,end])
}

#to extract coefficients
lapply(mod.list,coef)

#to extract coefficients, and confidence intervals
lapply(mod.list,function(x,...){ coef(summary(x))} )

#to reproduce your ablines
lapply(mod.list,abline,col="red")

etc

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz



From jasont at indigoindustrial.co.nz  Wed Dec 18 23:23:03 2002
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed Dec 18 23:23:03 2002
Subject: [R] Kernel smoothing.
In-Reply-To: <200212182053.QAA03667@gelfand.math.unb.ca>; from rolf@math.unb.ca on Wed, Dec 18, 2002 at 04:53:37PM -0400
References: <200212182053.QAA03667@gelfand.math.unb.ca>
Message-ID: <20021219112202.B12597@camille.indigoindustrial.co.nz>

On Wed, Dec 18, 2002 at 04:53:37PM -0400, Rolf Turner wrote:
> I wish to produce a weighted (Gaussian?) kernel density estimate, in
> 2 dimensions, where the weights are permitted to be ***negative***.
> (I can ASSURE you that there are perfectly legitimate reasons why I
> want to do this.  :-)) 

hmm... "trust me, I know what I'm doing".  The very phrase that results
in many, many children being born each year....   ;)

> Clearly it is not really a density that I am
> trying to estimate.

possible quick workarounds...

1) remove entries that have negative weights before you calculate
the density?
2) re-scale your weights so they're all positive.  Depending on
the weighting (and exctly what you're doing), 

my.weights2 <- exp(my.weights) 

or

my.weights2 <- my.weights + min(my.weights)

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz



From andy_liaw at merck.com  Thu Dec 19 00:01:03 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu Dec 19 00:01:03 2002
Subject: [R] Can I build an array of regrssion model?
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC9ED@usrymx10.merck.com>

And if you *really* want piecewise linear function (and most likely you want
the pieces to be continuous, no?), there are better ways than yours.  For
"manual" fitting, use something like:

  library(splines)
  lm(y ~ bs(x, knots=..., deg=1))

For more automatic fitting, I believe bruto() or even mars() in the package
`mda' will do.

Andy

> -----Original Message-----
> From: Jason Turner [mailto:jasont at indigoindustrial.co.nz]
> Sent: Wednesday, December 18, 2002 5:08 PM
> To: Zhongming Yang
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Can I build an array of regrssion model?
> 
> 
> On Wed, Dec 18, 2002 at 03:51:47PM -0500, Zhongming Yang wrote:
> > I am trying to use piecewise linear regression to approximate a
> > nonlinear function. 
> 
> Why not smooth regression, or non-linear regression?
> 
> > Actually, I don't know how many linear functions I
> > need, therefore, I want build an array of regression models 
> to automate
> > the approximation job. Could you please give me any clue?
> 
> Clue 1) See above.  You might be using the wrong tool.  A smooth
> regression might be better here.  help(loess), library(gss), and
> library(sm) are your friends.
> 
> Clue 2) If you really want piecewise linear, a list makes more
> sense than a vector.  R does handle vectors quite nicely, but I
> find its real strength is the way it handles complex lists with
> ease.
> 
> > Attached is ongoing code:
> > 
> > rawData = scan("c:/zyang/mass/data/A01/1.PRN",
> > what=list(numeric(),numeric()));
> > len = length(rawData[[1]]);
> > cuts = len*c(0.01, 0.03, 0.08, 0.18, 0.38, 0.69, 1);
> > cuts = as.integer(cuts); 
> 
> #change cuts to a matrix of values, col 1 is the lower
> #bound, col 2 is the upper bound for your segments.
> 
> cuts <- cbind(c(1,cuts[1:(length(cuts)-1)], cuts)
> 
> #make an empty list
> mod.list <- list()
> #fill that list with models
> for(ii in 1:dim(cuts)[1]) { 
> 	start <- cuts[ii,1]
> 	end <- cuts[ii,2]
> 	mod.list[[ii]] <- lm(rawData[[2]][start,end] ~ 
> rawData[[1]][start,end])
> }
> 
> #to extract coefficients
> lapply(mod.list,coef)
> 
> #to extract coefficients, and confidence intervals
> lapply(mod.list,function(x,...){ coef(summary(x))} )
> 
> #to reproduce your ablines
> lapply(mod.list,abline,col="red")
> 
> etc
> 
> Cheers
> 
> Jason
> -- 
> Indigo Industrial Controls Ltd.
> 64-21-343-545
> jasont at indigoindustrial.co.nz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------



From Jameshutton25 at aol.com  Thu Dec 19 00:14:02 2002
From: Jameshutton25 at aol.com (Jameshutton25@aol.com)
Date: Thu Dec 19 00:14:02 2002
Subject: [R] Help on R commands
Message-ID: <1bc.184a5fd0.2b325ad4@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021219/72defb35/attachment.pl

From Jameshutton25 at aol.com  Thu Dec 19 00:18:02 2002
From: Jameshutton25 at aol.com (Jameshutton25@aol.com)
Date: Thu Dec 19 00:18:02 2002
Subject: [R] Help on R commands
Message-ID: <122.1c2903c1.2b325a67@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021219/e40f1244/attachment.pl

From p.dalgaard at biostat.ku.dk  Thu Dec 19 00:30:03 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu Dec 19 00:30:03 2002
Subject: [R] Memory leak in R v1.6.0?
In-Reply-To: <Pine.GSO.4.10.10212181257400.17704-100000@fisher.stat.ucla.edu>
References: <Pine.GSO.4.10.10212181257400.17704-100000@fisher.stat.ucla.edu>
Message-ID: <x2u1haewjf.fsf@biostat.ku.dk>

Roger Peng <rpeng at stat.ucla.edu> writes:

> There was a memory leak discovered in R 1.6.0 but it's difficult to tell
> if this is in fact causing your problem.  At any rate, you should upgrade
> to version 1.6.1 (the latest release).

Yep. In fact it is highly likely that this is the cause. That problem
was in deparsing, and almost everything does deparsing somewhere, so
simulations with a high repeat count would easily be affected.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From elvis at xlsolutions-corp.com  Thu Dec 19 01:32:03 2002
From: elvis at xlsolutions-corp.com (Elvis Miller, PhD)
Date: Thu Dec 19 01:32:03 2002
Subject: [R] Course***R/Splus programming I: Essentials and Data Analysis***January 2003
Message-ID: <APEHLKCMHHAKBGLAPKPCIEPFCAAA.elvis@xlsolutions-corp.com>

XLSolutions Corporation (www.xlsolutions-corp.com) is pleased to
announce a two-day S-plus/R course. The monthly schedule for our
2003 courses will be available soon! Do you know we've added
new courses at different levels and revised some of our course
to fit your needs?

"S-plus/R programming I: Essentials and Data Analysis" in:

	  San Francisco  ****  January 23-24, 2003
        Washington DC  ****  January 23-24, 2003
        Chicago        ****  January 30-31, 2003
        London, UK     ****  January 30-31, 2003

This two-day hands-on course teaches participants the basics of S and R
syntax.
We will concentrate on learning the data structures and commands necessary
for data analysis. This course is designed for those who want to learn
to write programs to accomplish typical data-processing tasks, including
creating graphics. The course will give participants a strong foundation
for becoming a versatile programmer.


Cost for two-day course (payment due after the class).

          Commercial $765
          Academic   $650     Early bird special and group discount: email
us!

(Includes course materials, 90 days Technical Support for R,
snacks and continental breakfast!)

We also offer private affordable 1-day or 2-day courses customized to your
needs.

Registration:

Email Sue Turner: sue at xlsolutions-corp.com
Phone: 206-686-1578 x221
Visit us: www.xlsolutions-corp.com/training.htm


Benefits:

This two-day course focuses on how to

   ? Create and Enhance Different kinds of Plots  (Scatter plots,
Histograms,
Boxplots,.etc)
   ? Import/export data into the software environment
   ? Create and manipulate data (vectors, data frames, lists)
   ? Use the graphical features of the software to explore data
   ? Perform basics statistics and fit linear regression
   ? Write functions to automate data analysis tasks


Course Topics:


   ? An Overview of the Software System: Installation and Demonstration
   ? Data Objects and Syntax
   ? Data Manipulation and Management
   ? Overview of High-level and Low-level Graphics Functions for Data
Exploration
   ? Creating and Enhancing Plots
   ? A Comparison of R and S-PLUS
   ? Writing Functions and Automating Analyses
   ? Constructing Models and Testing Hypotheses
   ? Fitting Linear regression modeling
   ? Tips and Troubleshooting



Course Format:

This course consists of a series of short lectures in a PC lab with
demonstrations and interactive sessions for the participants. Each student
is provided with bound copies of the notes and a CD-ROM containing all
examples,
exercises and software used on the course.


Share Your Thoughts:

Are there any additional topics you would like for this course to address?
Would you like for this course to be offered in another city?

Please let us know by contributing to our recommendation list:
training at xlsolutions-corp.com.



From john.maindonald at anu.edu.au  Thu Dec 19 01:38:05 2002
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu Dec 19 01:38:05 2002
Subject: [R] acceptable p-level for scientific studies
In-Reply-To: <20021218092658.A14882@cattell.psych.upenn.edu>
Message-ID: <3CD1688D-12EA-11D7-883C-000393073F7A@anu.edu.au>

Another interesting paper is:

Gigerenzer, G. 1998. We need statistical thinking, not statistical
rituals. Behavioural and Brain Sciences 21: 199-200.

It is interesting that Gigerenzer's recent, highly readable and
disturbing book :"Calculated Risks" (US: Simon & Schuster) or
"Reckoning with Risk" (UK, Allen Lane) has no reference to
p-values in the index.

Gigerenzer describes an investigation where just one AIDS
counsellor out of 20 showed any recognition that the estimate
of the probability of infection, given a positive AIDS test, would
depend on the risk group from which the person came.
The very small P[positive test | no infection] is an incomplete
part of the story.

Regrettably I suspect that the result would be much the same for
AIDS or genetics counsellors anywhere.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Bioinformation Science, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.



From Alexander.Herr at csiro.au  Thu Dec 19 02:19:03 2002
From: Alexander.Herr at csiro.au (Alexander.Herr@csiro.au)
Date: Thu Dec 19 02:19:03 2002
Subject: [R] summary stats including NA's into new dataframe
Message-ID: <2FE6D3D02CCDD211B80600902745F56C018D11F3@exchange-tv.tvl.qld.csiro.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021219/7aa80471/attachment.pl

From maj at stats.waikato.ac.nz  Thu Dec 19 03:21:02 2002
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Thu Dec 19 03:21:02 2002
Subject: [R] Simulation/OR in R
Message-ID: <3E012CDE.7050108@stats.waikato.ac.nz>

Well it looks like I'll be teaching half of a second year "Optimization 
and Simulation" course next year. Not really my thing, but it should 
make an interesting change. I'm looking for ideas for using R in such a 
course.

I will be teaching more the stochastic part of the course and my 
colleague will continue to teach linear and integer programming and 
transportation/network problems. If I sound vague about what exactly I 
will cover, it's because I have not decided or even given it much 
thought yet. Just the same I would be greatful for any suggestions 
regarding nice applications of R in simulation and stochastic OR.

Murray
-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home     Mobile 021 395 862



From karruo at utu.fi  Thu Dec 19 07:46:04 2002
From: karruo at utu.fi (Kari Ruohonen)
Date: Thu Dec 19 07:46:04 2002
Subject: [R] prediction intervals in lme
Message-ID: <87lm2mh5hn.fsf@trane.utu.fi>

I have an lme model that I want to use for prediction. With lm objects
it is possible to use "interval" and "level" options of predict.lm to
obtain prediction intervals. This seems not to be applicable for
predict.lme. Is there a way to get prediction intervals also for lme
predictions?

Regards, Kari
--



From ligges at statistik.uni-dortmund.de  Thu Dec 19 08:52:04 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu Dec 19 08:52:04 2002
Subject: [R] summary stats including NA's into new dataframe
In-Reply-To: <2FE6D3D02CCDD211B80600902745F56C018D11F3@exchange-tv.tvl.qld.csiro.au>
References: <2FE6D3D02CCDD211B80600902745F56C018D11F3@exchange-tv.tvl.qld.csiro.au>
Message-ID: <3E017A87.5040407@statistik.uni-dortmund.de>

Alexander.Herr at csiro.au wrote:
> Thanks Uwe,
> Can't seem to get your formula to work...
> I should have made this clearer. I am after a listing of the number of NAs
> and Valid Ns (or total N)for export to csv,eg:
> Variable, mean, Missing Values, Valid N
> test,	6.00000,2,18
> bummer,5.44444,1,19
> 
> from:
> 
> x<-c(1,4,2,6,8,3,5,6,7,8,7,2,4,7,5,1,8,9,8,9)
> labl<-gl(2,2,length=20,labels=c("test","bummer"))
> x[3]<-NA
> x[5]<-NA
> x[6]<-NA
> 
> 
> aggregate(x,by=list(labl),mean, sum(is.na(x)))
> #  Group.1  x
> #1    test NA
> #2  bummer NA
> 
> aggregate(x,by=list(labl),mean, na.rm=T)
> #  Group.1           x
> #1    test 6.000000
> #2  bummer 5.444444
> 
> aggregate(x,by=list(labl),sum(is.na(x)))
> # Error in FUN(X[[1]], ...) : Argument "INDEX" is missing, with no default

You didn't read carefully enough:

aggregate(......., function(x) sum(is.na(x)))
                    ^^^^^^^^^^^^

Or instead of this anonymous function, you can do as well:

countna <- function(x) sum(is.na(x))
aggregate(......., countna)


> Cheers Herry
> 
> 
> --------------------------------------------
> Alexander Herr - Herry
> Northern Futures
> Davies Laboratory
> PMB, Aitkenvale, QLD 4814
> Phone (07) 4753 8510
> Fax   (07) 4753 8650
> Home: http://batcall.csu.edu.au/~aherr
> CSIRO Sustainable Ecosystems:
> http://www.cse.csiro.au/
> --------------------------------------------
> 
> 
> 
> -----Original Message-----
> From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
> Sent: Wednesday, 18 December 2002 5:30 PM
> To: Alexander.Herr at csiro.au
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] summary stats including NA's into new dataframe
> 
> 
> Alexander.Herr at csiro.au wrote:
> 
>>List,
>>
>>I am trying to extract summary statistics from a data frame with several
>>variables (and NAs) into a dataframe with the columns: Variablename (ie
> 
> the
> 
>>colnames of original data), mean, stdev, max, min, Valid N, Missing
> 
> Values.
> 
>>Extracting the statistics is straightforward using stack and aggregate.
>>However, I haven't succeeded in obtaining the number of Missing Values. I
>>can extract these from describe (Hmisc library), but surely there is a
>>simpler way similar to obtaining the mean using aggregate?
> 
> 
> The similar way is:
> 
> aggregate(......., function(x) sum(is.na(x)))
> 
> Uwe Ligges
> 
> 
>>Suggestions are much appreciated
> 
> 
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From dtrenkler at nts6.oec.uni-osnabrueck.de  Thu Dec 19 09:05:04 2002
From: dtrenkler at nts6.oec.uni-osnabrueck.de (Trenkler, Dietrich)
Date: Thu Dec 19 09:05:04 2002
Subject: [R] weibull test
Message-ID: <FB75CFC167F3D311B11D00A0CC20FB0E373B43@nts7.oec.Uni-Osnabrueck.DE>


> -----Original Message-----
> From:	Meriema BELAIDOUNI 
> Sent:	Wednesday, December 18, 2002 11:19 AM
> To:	R-help at stat.math.ethz.ch
> Subject:	[R] weibull test
> 
> Hello
> What is the appropriate method to test if a given distribution is a
> weibull
> thank you
> meriema
	 

	[Dietrich Trenkler]  The following articles may be of interest for
you:

	@ARTICLE{Chandra81,
	  author = {M. Chandra and N.D. Singpurwalla and M.A. Stephens},
	  year = 1981,
	  title = {Kolmogorov Statistics for Tests of Fit for the
Extreme-Value and
	          Weibull Distributions},
	  journal = {Journal of the American Statistical Association},
	  volume = 76,
	  pages = {729--731},
	  keywords = {Extreme-Value Distribution; Goodness of Fit;
Kolmogorov-Smirnov
	             Tests; Kuiper Statistic; Weibull Distribution}
	}                                                                


	@ARTICLE{Lockhart94,
	  author = {Richard A. Lockhart and Michael A. Stephens},
	  year = 1994,
	  title = {Estimation and Tests of Fit for the Three-Parameter
Weibull
	          Distribution},
	  journal = {Journal of the Royal Statistical Society B},
	  volume = 56,
	  pages = {491--500},
	  keywords = {Empirical Distribution Function; Empirical
Distribution Function
	             Tests; Goodness of Fit; Reliability; Survival Analysis}
	}

	Hope this helps.

	D. Trenkler

--
Dietrich Trenkler   Universit?t Osnabr?ck                                  
FB Wirtschaftswissenschaften           
Rolandstr.8              D-49069 Osnabr?ck

dtrenkler at nts6.oec.uni-osnabrueck.de



From christian.ritter at shell.com  Thu Dec 19 11:17:05 2002
From: christian.ritter at shell.com (Ritter, Christian C MCIL-CTGAS)
Date: Thu Dec 19 11:17:05 2002
Subject: [R] Ongoing unhappiness with NA and factor behavior of distributed lm/predict.lm
Message-ID: <156CDC8CCFD1894295D2907F16337A481FA876@bru-s-006.europe.shell.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021219/891798ed/attachment.pl

From Bernhard.Pfaff at drkw.com  Thu Dec 19 14:58:02 2002
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Thu Dec 19 14:58:02 2002
Subject: [R] optimize() - Solution is invariant with respect to parameters - l
 exical function
Message-ID: 
    <18D602BD42B7E24EB810D6454A58DB9001CAE116@ibfftce505.is.de.dresdnerkb.com>

Dear R-List member,

suppose the following single valued functional form is given: y = f(x | a,
b, c). Now I want to use optimize to solve for the value of x that satisfy
the function.
As an example, pls. take a look at the following:

input <- function(y,a,b,c){
f <- function(x){
  (a + b*x + c*x^2 - y)^2
}
optimize(f,c(1,100))
}
#
# example with x=2
#
input(y=7,a=1,b=1,c=1)
temp1 <- input(y=7,a=1,b=1,c=1)$minimum
temp1
1 + temp1 + temp1^2
#
# example with x=3
#
input(y=14,a=2,b=1,c=1)
temp2 <- input(y=14,a=2,b=1,c=1)$minimum
temp2
2 + temp2 + temp2^2

So far, so good(?). Now, the function that I am interesting in has the
following form:


bsiv.opt <- function(op, s, x, r, tt){
  iv <- function(sig){
   (s*pnorm((log(s/x)+(r+0.5*sig^2)*tt)/sig*sqrt(tt)) -
x*exp(-r*tt)*pnorm((log(s/x)+(r+0.5*sig^2)*(tt))/sig*sqrt(tt)-sig*sqrt(tt))
- op)^2
  }
  optimize(iv,c(1,100))
}
#
# example 1
#
bsiv.opt(4.75, 93.625, 90, 0.0512, 22)
#
# example 2
#
bsiv.opt(4.75, 93.625, 80, 0.0512, 22)

My question is as follows: although, I have altered one parameter value, the
solved minimum value does not change; how come? What have I made wrong?
Any hints and pointers are most welcome.

Rgds,
Bernhard 




----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.
----------------------------------------------------------------------



From bojaniss at poczta.onet.pl  Thu Dec 19 15:36:02 2002
From: bojaniss at poczta.onet.pl (Michal Bojanowski)
Date: Thu Dec 19 15:36:02 2002
Subject: [R] acceptable p-level for scientific studies
In-Reply-To: <20021218091251.36c5eaae.fharrell@virginia.edu>
References: <00b501c2a693$28974200$5e05cf9b@pharm.auth.gr>
 <20021218091251.36c5eaae.fharrell@virginia.edu>
Message-ID: <751339100.20021219153121@poczta.onet.pl>

Wednesday, December 18, 2002, 3:12:51 PM, you wrote:

FEHJ> Want to open up the floodgates?  Some personal opinions:

FEHJ> - Alpha=0.05 is arbitrary, silly, and boring
FEHJ> - Reporting P and letting the reader decide is a bit better
FEHJ> - Bayesian posterior probabilities are still better although
FEHJ>   more thinking is required
FEHJ> - Confidence limits can be good compromise solutions (some journals are
FEHJ>   almost disallowing P-values in favor of CLs)
FEHJ> - P-values are dangerous, especially large, small, and in-between ones.
FEHJ>   See http://hesweb1.med.virginia.edu/biostat/teaching/bayes.short.course.pdf for a full sermon.

Hello,

I'm very interested in differences between bayesian and frequentist
decision making. The only source of knowledge about Bayesian approach
I have is:

James O. Berger "Statistical Decision Theory and Bayesian Analysis"
Springer-Verlag 1985

Could you point me to some books/articles that will explain
differences between those approaches. The explanation in the book
above is not satisfying (for me).

I'm especially very interested in the `philosophical' grounds, that
constitute Bayesian approach.

Thank you in advance.


Michal


~,~`~,~`~,~`~,~`~,~`~,~
Micha? Bojanowski
bojaniss at poczta.onet.pl



***************r-e-k-l-a-m-a**************

Masz do?? p?acenia prowizji bankowi ?
mBank - za??? konto
http://epieniadze.onet.pl/mbank



From bmagill at earthlink.net  Thu Dec 19 15:40:04 2002
From: bmagill at earthlink.net ( Brett Magill)
Date: Thu Dec 19 15:40:04 2002
Subject: [R] summary stats including NA's into new dataframe
Message-ID: <Springmail.0994.1040308564.0.34160300@webmail.pas.earthlink.net>

I think my dstats function does what you want, if I understand you coorrectly.
 You could apply it over rows or columns:

  http://home.earthlink.net/~bmagill/MyMisc.html

It is there along with several other functions.



On Thu, 19 Dec 2002 11:18:25 +1000 Alexander.Herr at csiro.au wrote:

> Thanks Uwe,
> Can't seem to get your formula to work...
> I should have made this clearer. I am after a
> listing of the number of NAs
> and Valid Ns (or total N)for export to csv,eg:
> Variable, mean, Missing Values, Valid N
> test,	6.00000,2,18
> bummer,5.44444,1,19
> 
> from:
> 
> x List,
> > 
> > I am trying to extract summary statistics
> from a data frame with several
> > variables (and NAs) into a dataframe with the
> columns: Variablename (ie
> the
> > colnames of original data), mean, stdev, max,
> min, Valid N, Missing
> Values.
> > 
> > Extracting the statistics is straightforward
> using stack and aggregate.
> > However, I haven't succeeded in obtaining the
> number of Missing Values. I
> > can extract these from describe (Hmisc
> library), but surely there is a
> > simpler way similar to obtaining the mean
> using aggregate?
> 
> The similar way is:
> 
> aggregate(......., function(x) sum(is.na(x)))
> 
> Uwe Ligges
> 
> > Suggestions are much appreciated
> 
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From nolwenn.lemeur at nantes.inserm.fr  Thu Dec 19 15:43:04 2002
From: nolwenn.lemeur at nantes.inserm.fr (Nolwenn Le Meur)
Date: Thu Dec 19 15:43:04 2002
Subject: [R] lattice and display
Message-ID: <LMEBLNBEKKODLAONNGJMCELPCAAA.nolwenn.lemeur@nantes.inserm.fr>

Hi,

I have just started using lattice and it looks great. But I already have 3
questions about xyplot display.
----------------------------------------------------------------------------
---------------------------------
1.I would like to create two differeny xyplot with different color to
identify my different groups but I have trouble applying colors.
Here are the scripts

 xyplot(resultdata$Y~resultdata$X , data=resultdata,groups=resultdata$Block,
 panel="panel.xyplot",
 panel.groups="panel.xyplot",
 xlab="X",ylab="Y",pch="*",
 col.groups=trellis.par.get("superpose.symbol")$col[1:6],cex=2,
 key=list(space="right",
 points=list(pch="*",
	     col=trellis.par.get("superpose.symbol")$col[1:6]),
 text=list(paste("Block",1:6)))
 )

xyplot(resultdata$Y~resultdata$X |resultdata$Block, data=resultdata,
 xlab="X",ylab="Y",
col.groups=trellis.par.get("superpose.symbol")$col[1:6],cex=2,
 key=list(space="right",
 points=list(pch=trellis.par.get("superpose.symbol")$pch[1:6],
	     col=trellis.par.get("superpose.symbol")$col[1:6]),
 text=list(paste("Block",1:6)))
 )
----------------------------------------------------------------------------
-------------------------------

2.For the latest formula I would also like to change the resultdata$Block
label by the corresponding "Block x".
----------------------------------------------------------------------------
-------------------------------

3.I finally would like to save my plot as "jpg" files under Linux but I
loose the color.


Thanks,

Nolwenn


********************************************
Nolwenn Le Meur
INSERM U533
Facult? de m?decine
1, rue Gaston Veil
44035 Nantes Cedex 1
France

Tel: (+33)-2-40-41-29-86 (office)
     (+33)-2-40-41-28-44 (secretary)
Fax: (+33)-2-40-41-29-50
mail: nolwenn.lemeur at nantes.inserm.fr
********************************************



From Alexander.Hener at daimlerchrysler.com  Thu Dec 19 15:50:06 2002
From: Alexander.Hener at daimlerchrysler.com (Alexander.Hener@daimlerchrysler.com)
Date: Thu Dec 19 15:50:06 2002
Subject: [R] Alexander Hener/FT/DCAG/DCX is out of office.
Message-ID: <0057440046477257000002L472*@MHS>

Ich werde ab  18.12.2002 nicht im B?ro sein. Ich kehre zur?ck am  13.01.2003.



From andy_liaw at merck.com  Thu Dec 19 15:53:00 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu Dec 19 15:53:00 2002
Subject: [R] Memory Leak in R v1.6.1
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC9EF@usrymx10.merck.com>

For the benefit of those who might have similar problem...

-----Original Message-----
From: Annette Molinaro [mailto:molinaro at cc.ucsf.edu]
Sent: Wednesday, December 18, 2002 11:51 PM
To: Liaw, Andy
Subject: Re: [R] Memory Leak in R v1.6.1


Thanks Andy!
It worked!

----- Original Message -----
From: "Liaw, Andy" <andy_liaw at merck.com>
To: "'Annette Molinaro'" <molinaro at cc.ucsf.edu>
Sent: Wednesday, December 18, 2002 2:52 PM
Subject: RE: [R] Memory Leak in R v1.6.1


> Try following the rm() by a few gc()'s and see if that helps.
>
> Andy
>
> > -----Original Message-----
> > From: Annette Molinaro [mailto:molinaro at cc.ucsf.edu]
> > Sent: Wednesday, December 18, 2002 4:30 PM
> > To: R-help at stat.math.ethz.ch
> > Subject: [R] Memory Leak in R v1.6.1
> >
> >
> > Greetings,
> >
> > I am running R v 1.6.1 on a linux operating system with 2GB
> > physical memory and dual processors. When using BATCH to run
> > a simulation with a super large dataset I can only get
> > through 1 1/2 repetitions before R uses all the memory and
> > the simulation crashes. It starts with 10% of the memory - up
> > to 50% by the end of the first repetition and then starts the
> > second with approx 65% of the memory. I am using rm at the
> > end of each section and thus only keeping a small matrix of
> > results. Any suggestions?
> >
> > Thanks,
> > Annette
> >
> > [[alternate HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
> --------------------------------------------------------------------------
----
> Notice: This e-mail message, together with any attachments, contains
information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that
may be confidential, proprietary copyrighted and/or legally privileged, and
is intended solely for the use of the individual or entity named on this
message. If you are not the intended recipient, and have received this
message in error, please immediately return this by e-mail and then delete
it.
>
>
============================================================================
==
>


------------------------------------------------------------------------------



From saurav at sas.upenn.edu  Thu Dec 19 16:23:02 2002
From: saurav at sas.upenn.edu (Saurav Pathak)
Date: Thu Dec 19 16:23:02 2002
Subject: [R] newbie question on dist
Message-ID: <20021219152241.GC20292@mail1.sas.upenn.edu>

hi,

i have just begun using R, so please bear with me.

i am trying to use cmdscale and display the result.  i read the data
using read.table(), calculate the proximity matrix using dist() and
the display the result using the cmdscale().  this is very fine.

in addition, i want the display to distinguish between two classes
of records in my data.  i have my data records marked as "1" or "0".
so i want to display 1's and 0's.  how may i do that?

i use the following code:

----
> fj <- read.table("fj")
>  names(fj)
[1] "V1" "V2" "V3" "V4" "V5" # "V5" contains the class mark (1 or 0)
> #
> # since i dont want the class attribute in the distance matrix
> # i create another data.frame dropping it.  but how do i pass it
> # so that I may use it while plotting?
> fjN <- data.frame(V1=fj$V1, V2=fj$V2, V3=fj$V3, V4=fj$V4)
> library(mva)
> fjNDist <- dist(fjN, method="euclidean")
> fjCMDS <- cmdscale(fjNDist)
> plot(x, y, type="n", main="cmdscale(fjNDist)")
> text(x, y, ".", cex=0.8)
----

any help will be much appreciated.

thanks,
saurav



From Zhongming.Yang at cchmc.org  Thu Dec 19 16:48:02 2002
From: Zhongming.Yang at cchmc.org (Zhongming Yang)
Date: Thu Dec 19 16:48:02 2002
Subject: [R] Can I build an array of regrssion model?
Message-ID: <se01a3cf.090@mailx.chmcc.org>

Thank you for your time.

Actually, the purpose of this program is not smoothing but rather to
pick some peaks from the noisy exponential decay data.  Piecewise linear
regression is ued to find the baseline. I don't know whether there is
other technique to solve this problem.

Could you please check the following code? The concern is how to draw
the raw data and piecewise linear functions on one diagram.

rawData = scan("c:/zyang/mass/data/A01/1.PRN",
what=list(numeric(),numeric()));
#write.table(rawData, 'rawdata.txt', quote=FALSE, row.names=FALSE,
col.names=FALSE);
len = length(rawData[[1]]);
cuts = len*c(0.01, 0.03, 0.08, 0.18, 0.38, 0.69, 1);
cuts = as.integer(cuts); 

#make an empty list
mod.list <- list();
for(i in 1:length(cuts)) 
{ 
      if (i==1)
      {
	start = 1;
      }
      else
      {
   	start = cuts[i-1];
      }
      end = cuts[i];
      mod.list[[i]] = lm(rawData[[2]][start:end] ~
rawData[[1]][start:end])
}

plot(rawData[[1]],rawData[[2]],type='l', col="green", xlab="Da/z",
ylab="m/z");
for(i in 1:length(cuts)) 
{ 
      if (i==1)
      {
	start = 1;
      }
      else
      {
   	start = cuts[i-1];
      }
      end = cuts[i];
      fitted.value[start:end] = predict(mod.list[[i]],
newdata=rawData[[1]][start:end], type='response' );
}
abline(rawData[[1]],fitted.value, col="red");

Thanks,



  






>>> Jason Turner <jasont at indigoindustrial.co.nz> 12/18/02 05:08PM >>>
On Wed, Dec 18, 2002 at 03:51:47PM -0500, Zhongming Yang wrote:
> I am trying to use piecewise linear regression to approximate a
> nonlinear function. 

Why not smooth regression, or non-linear regression?

> Actually, I don't know how many linear functions I
> need, therefore, I want build an array of regression models to
automate
> the approximation job. Could you please give me any clue?

Clue 1) See above.  You might be using the wrong tool.  A smooth
regression might be better here.  help(loess), library(gss), and
library(sm) are your friends.

Clue 2) If you really want piecewise linear, a list makes more
sense than a vector.  R does handle vectors quite nicely, but I
find its real strength is the way it handles complex lists with
ease.

> Attached is ongoing code:
> 
> rawData = scan("c:/zyang/mass/data/A01/1.PRN",
> what=list(numeric(),numeric()));
> len = length(rawData[[1]]);
> cuts = len*c(0.01, 0.03, 0.08, 0.18, 0.38, 0.69, 1);
> cuts = as.integer(cuts); 

#change cuts to a matrix of values, col 1 is the lower
#bound, col 2 is the upper bound for your segments.

cuts <- cbind(c(1,cuts[1:(length(cuts)-1)], cuts)

#make an empty list
mod.list <- list()
#fill that list with models
for(ii in 1:dim(cuts)[1]) { 
	start <- cuts[ii,1]
	end <- cuts[ii,2]
	mod.list[[ii]] <- lm(rawData[[2]][start,end] ~
rawData[[1]][start,end])
}

#to extract coefficients
lapply(mod.list,coef)

#to extract coefficients, and confidence intervals
lapply(mod.list,function(x,...){ coef(summary(x))} )

#to reproduce your ablines
lapply(mod.list,abline,col="red")

etc

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz



From ripley at stats.ox.ac.uk  Thu Dec 19 16:54:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Dec 19 16:54:03 2002
Subject: [R] newbie question on dist
In-Reply-To: <20021219152241.GC20292@mail1.sas.upenn.edu>
Message-ID: <Pine.LNX.4.31.0212191547360.1433-100000@gannet.stats>

On Thu, 19 Dec 2002, Saurav Pathak wrote:

> i have just begun using R, so please bear with me.
>
> i am trying to use cmdscale and display the result.  i read the data
> using read.table(), calculate the proximity matrix using dist() and
> the display the result using the cmdscale().  this is very fine.
>
> in addition, i want the display to distinguish between two classes
> of records in my data.  i have my data records marked as "1" or "0".
> so i want to display 1's and 0's.  how may i do that?

There are examples of this in library/MASS/scripts/ch11.R, and see below


>
> i use the following code:
>
> ----
> > fj <- read.table("fj")
> >  names(fj)
> [1] "V1" "V2" "V3" "V4" "V5" # "V5" contains the class mark (1 or 0)
> > #
> > # since i dont want the class attribute in the distance matrix
> > # i create another data.frame dropping it.  but how do i pass it
> > # so that I may use it while plotting?
> > fjN <- data.frame(V1=fj$V1, V2=fj$V2, V3=fj$V3, V4=fj$V4)
> > library(mva)
> > fjNDist <- dist(fjN, method="euclidean")

Just fj[,-5] will do here

> > fjCMDS <- cmdscale(fjNDist)
> > plot(x, y, type="n", main="cmdscale(fjNDist)")
> > text(x, y, ".", cex=0.8)

Don't use text to plot a dot, use points().

text(x, y, labels=fj$V5)


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Bernhard.Pfaff at drkw.com  Thu Dec 19 16:57:25 2002
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Thu Dec 19 16:57:25 2002
Subject: [R] optimize() - Solution is invariant with respect to parame
    ters - l exical function
Message-ID: 
    <18D602BD42B7E24EB810D6454A58DB9001CAE119@ibfftce505.is.de.dresdnerkb.com>

Solved the problem myself, thks, for any efforts taken!

-----Original Message-----
From: Pfaff, Bernhard [mailto:Bernhard.Pfaff at drkw.com]
Sent: 19 December 2002 14:58
To: r-help at stat.math.ethz.ch
Subject: [R] optimize() - Solution is invariant with respect to
parameters - l exical function


Dear R-List member,

suppose the following single valued functional form is given: y = f(x | a,
b, c). Now I want to use optimize to solve for the value of x that satisfy
the function.
As an example, pls. take a look at the following:

input <- function(y,a,b,c){
f <- function(x){
  (a + b*x + c*x^2 - y)^2
}
optimize(f,c(1,100))
}
#
# example with x=2
#
input(y=7,a=1,b=1,c=1)
temp1 <- input(y=7,a=1,b=1,c=1)$minimum
temp1
1 + temp1 + temp1^2
#
# example with x=3
#
input(y=14,a=2,b=1,c=1)
temp2 <- input(y=14,a=2,b=1,c=1)$minimum
temp2
2 + temp2 + temp2^2

So far, so good(?). Now, the function that I am interesting in has the
following form:


bsiv.opt <- function(op, s, x, r, tt){
  iv <- function(sig){
   (s*pnorm((log(s/x)+(r+0.5*sig^2)*tt)/sig*sqrt(tt)) -
x*exp(-r*tt)*pnorm((log(s/x)+(r+0.5*sig^2)*(tt))/sig*sqrt(tt)-sig*sqrt(tt))
- op)^2
  }
  optimize(iv,c(1,100))
}
#
# example 1
#
bsiv.opt(4.75, 93.625, 90, 0.0512, 22)
#
# example 2
#
bsiv.opt(4.75, 93.625, 80, 0.0512, 22)

My question is as follows: although, I have altered one parameter value, the
solved minimum value does not change; how come? What have I made wrong?
Any hints and pointers are most welcome.

Rgds,
Bernhard 




----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.
----------------------------------------------------------------------

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help


----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.
----------------------------------------------------------------------



From tlumley at u.washington.edu  Thu Dec 19 17:05:03 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu Dec 19 17:05:03 2002
Subject: [R] Can I build an array of regrssion model?
In-Reply-To: <20021219110816.A12597@camille.indigoindustrial.co.nz>
Message-ID: <Pine.A41.4.44.0212190801200.183840-100000@homer06.u.washington.edu>

On Thu, 19 Dec 2002, Jason Turner wrote:

> On Wed, Dec 18, 2002 at 03:51:47PM -0500, Zhongming Yang wrote:
> > I am trying to use piecewise linear regression to approximate a
> > nonlinear function.
>
> Why not smooth regression, or non-linear regression?
>
> > Actually, I don't know how many linear functions I
> > need, therefore, I want build an array of regression models to automate
> > the approximation job. Could you please give me any clue?
>
> Clue 1) See above.  You might be using the wrong tool.  A smooth
> regression might be better here.  help(loess), library(gss), and
> library(sm) are your friends.
>
> Clue 2) If you really want piecewise linear, a list makes more
> sense than a vector.  R does handle vectors quite nicely, but I
> find its real strength is the way it handles complex lists with
> ease.


I don't see any problem with wanting to fit linear splines.  It's quite
easy, as well
eg
models <-  lapply( 1:8, function(n) lm(y~bs(x, n, degree=1)))

fits piecewise linear functions with 1 to 8 pieces.

	-thomas



From carders at north.sr.unh.edu  Thu Dec 19 17:22:26 2002
From: carders at north.sr.unh.edu (Hilmar M. Carders)
Date: Thu Dec 19 17:22:26 2002
Subject: [R] R function similar to UNIX "uniq -c"?
In-Reply-To: <Pine.LNX.4.44.0210161116220.19977-100000@north.sr.unh.edu>
Message-ID: <Pine.LNX.4.44.0212191025100.21516-100000@north.sr.unh.edu>

Is there an R function that gives the equivalent of the UNIX command 
"uniq -c" which could be applied to a vector with duplicate values?



From Zhongming.Yang at cchmc.org  Thu Dec 19 17:26:34 2002
From: Zhongming.Yang at cchmc.org (Zhongming Yang)
Date: Thu Dec 19 17:26:34 2002
Subject: [R] Can I build an array of regrssion model?
Message-ID: <se01aba8.050@mailx.chmcc.org>

Thanks,

But why I can't draw regression line with the following code:

rawData = scan("c:/zyang/mass/data/A01/1.PRN",
what=list(numeric(),numeric()));
len = length(rawData[[1]]);
mod = lm(rawData[[2]]~bs(rawData[[1]],10,degree=1));
plot(rawData[[1]],rawData[[2]],type='l', col="green", xlab="Da/z",
ylab="m/z");
abline(mod,col="red");







>>> Thomas Lumley <tlumley at u.washington.edu> 12/19/02 11:04AM >>>
On Thu, 19 Dec 2002, Jason Turner wrote:

> On Wed, Dec 18, 2002 at 03:51:47PM -0500, Zhongming Yang wrote:
> > I am trying to use piecewise linear regression to approximate a
> > nonlinear function.
>
> Why not smooth regression, or non-linear regression?
>
> > Actually, I don't know how many linear functions I
> > need, therefore, I want build an array of regression models to
automate
> > the approximation job. Could you please give me any clue?
>
> Clue 1) See above.  You might be using the wrong tool.  A smooth
> regression might be better here.  help(loess), library(gss), and
> library(sm) are your friends.
>
> Clue 2) If you really want piecewise linear, a list makes more
> sense than a vector.  R does handle vectors quite nicely, but I
> find its real strength is the way it handles complex lists with
> ease.


I don't see any problem with wanting to fit linear splines.  It's
quite
easy, as well
eg
models <-  lapply( 1:8, function(n) lm(y~bs(x, n, degree=1)))

fits piecewise linear functions with 1 to 8 pieces.

	-thomas

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jgentry at jimmy.harvard.edu  Thu Dec 19 17:33:12 2002
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Thu Dec 19 17:33:12 2002
Subject: [R] R function similar to UNIX "uniq -c"?
In-Reply-To: <Pine.LNX.4.44.0212191025100.21516-100000@north.sr.unh.edu>
Message-ID: <Pine.SOL.4.20.0212191128570.3318-100000@santiam.dfci.harvard.edu>


On Thu, 19 Dec 2002, Hilmar M. Carders wrote:
> Is there an R function that gives the equivalent of the UNIX command 
> "uniq -c" which could be applied to a vector with duplicate values?

There must be a better way to do this, but this would get you the
information you're looking for:

> z <- c("a","b","c","d","a","a","c")
> unique(z)
[1] "a" "b" "c" "d"
> lapply(unique(z),function(x){length(z[z==x])})
[[1]]
[1] 3

[[2]]
[1] 1

[[3]]
[1] 2

[[4]]
[1] 1

-J



From ripley at stats.ox.ac.uk  Thu Dec 19 17:41:02 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Dec 19 17:41:02 2002
Subject: [R] R function similar to UNIX "uniq -c"?
In-Reply-To: <Pine.SOL.4.20.0212191128570.3318-100000@santiam.dfci.harvard.edu>
Message-ID: <Pine.LNX.4.31.0212191638490.4582-100000@gannet.stats>

How about

> table(factor(z))

a b c d
3 1 2 1

?


On Thu, 19 Dec 2002, Jeff Gentry wrote:

> On Thu, 19 Dec 2002, Hilmar M. Carders wrote:
> > Is there an R function that gives the equivalent of the UNIX command
> > "uniq -c" which could be applied to a vector with duplicate values?
>
> There must be a better way to do this, but this would get you the
> information you're looking for:
>
> > z <- c("a","b","c","d","a","a","c")
> > unique(z)
> [1] "a" "b" "c" "d"
> > lapply(unique(z),function(x){length(z[z==x])})
> [[1]]
> [1] 3
>
> [[2]]
> [1] 1
>
> [[3]]
> [1] 2
>
> [[4]]
> [1] 1

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Thu Dec 19 18:07:03 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu Dec 19 18:07:03 2002
Subject: [R] R function similar to UNIX "uniq -c"?
In-Reply-To: <Pine.LNX.4.44.0212191025100.21516-100000@north.sr.unh.edu>
References: <Pine.LNX.4.44.0212191025100.21516-100000@north.sr.unh.edu>
Message-ID: <3E01F707.9060602@statistik.uni-dortmund.de>

Hilmar M. Carders wrote:
> Is there an R function that gives the equivalent of the UNIX command 
> "uniq -c" which could be applied to a vector with duplicate values?

See ?table.

Uwe Ligges



From tlumley at u.washington.edu  Thu Dec 19 18:14:55 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu Dec 19 18:14:55 2002
Subject: [R] Can I build an array of regrssion model?
In-Reply-To: <se01aba8.051@mailx.chmcc.org>
Message-ID: <Pine.A41.4.44.0212190905410.59992-100000@homer10.u.washington.edu>

On Thu, 19 Dec 2002, Zhongming Yang wrote:

> Thanks,
>
> But why I can't draw regression line with the following code:
>
> rawData = scan("c:/zyang/mass/data/A01/1.PRN",
> what=list(numeric(),numeric()));
> len = length(rawData[[1]]);
> mod = lm(rawData[[2]]~bs(rawData[[1]],10,degree=1));
> plot(rawData[[1]],rawData[[2]],type='l', col="green", xlab="Da/z",
> ylab="m/z");
> abline(mod,col="red");
>

Because that's not what abline does.  It draws a straight line, not a
piecewise linear regression curve.

You might find termplot() useful.

	-thomas



From andy_liaw at merck.com  Thu Dec 19 18:22:03 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu Dec 19 18:22:03 2002
Subject: [R] Can I build an array of regrssion model?
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC9F0@usrymx10.merck.com>

Try lines(predict(mod), col="red").  (This is assuming your original x data
are sorted.)

abline(mod) draws a single straight line, using intercept and slope from a
simple linear regression model ('mod').  If mod has more than one slope (as
is the case with bs()), it won't make sense.

Andy

> -----Original Message-----
> From: Zhongming Yang [mailto:Zhongming.Yang at cchmc.org]
> Sent: Thursday, December 19, 2002 11:21 AM
> To: jasont at indigoindustrial.co.nz; tlumley at u.washington.edu
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Can I build an array of regrssion model?
> 
> 
> Thanks,
> 
> But why I can't draw regression line with the following code:
> 
> rawData = scan("c:/zyang/mass/data/A01/1.PRN",
> what=list(numeric(),numeric()));
> len = length(rawData[[1]]);
> mod = lm(rawData[[2]]~bs(rawData[[1]],10,degree=1));
> plot(rawData[[1]],rawData[[2]],type='l', col="green", xlab="Da/z",
> ylab="m/z");
> abline(mod,col="red");
> 
> 
> 
> 
> 
> 
> 
> >>> Thomas Lumley <tlumley at u.washington.edu> 12/19/02 11:04AM >>>
> On Thu, 19 Dec 2002, Jason Turner wrote:
> 
> > On Wed, Dec 18, 2002 at 03:51:47PM -0500, Zhongming Yang wrote:
> > > I am trying to use piecewise linear regression to approximate a
> > > nonlinear function.
> >
> > Why not smooth regression, or non-linear regression?
> >
> > > Actually, I don't know how many linear functions I
> > > need, therefore, I want build an array of regression models to
> automate
> > > the approximation job. Could you please give me any clue?
> >
> > Clue 1) See above.  You might be using the wrong tool.  A smooth
> > regression might be better here.  help(loess), library(gss), and
> > library(sm) are your friends.
> >
> > Clue 2) If you really want piecewise linear, a list makes more
> > sense than a vector.  R does handle vectors quite nicely, but I
> > find its real strength is the way it handles complex lists with
> > ease.
> 
> 
> I don't see any problem with wanting to fit linear splines.  It's
> quite
> easy, as well
> eg
> models <-  lapply( 1:8, function(n) lm(y~bs(x, n, degree=1)))
> 
> fits piecewise linear functions with 1 to 8 pieces.
> 
> 	-thomas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------



From carders at north.sr.unh.edu  Thu Dec 19 18:27:13 2002
From: carders at north.sr.unh.edu (Hilmar M. Carders)
Date: Thu Dec 19 18:27:13 2002
Subject: [R] R function similar to UNIX "uniq -c"?
In-Reply-To: <3E01F707.9060602@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.44.0212191223580.14331-100000@north.sr.unh.edu>

Thanks to all who responded so quickly, table() is exactly what I was 
looking for.



On Thu, 19 Dec 2002, Uwe Ligges wrote:

> Hilmar M. Carders wrote:
> > Is there an R function that gives the equivalent of the UNIX command 
> > "uniq -c" which could be applied to a vector with duplicate values?
> 
> See ?table.
> 
> Uwe Ligges
>



From deepayan at stat.wisc.edu  Thu Dec 19 18:42:03 2002
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu Dec 19 18:42:03 2002
Subject: [R] lattice and display
In-Reply-To: <LMEBLNBEKKODLAONNGJMCELPCAAA.nolwenn.lemeur@nantes.inserm.fr>
References: <LMEBLNBEKKODLAONNGJMCELPCAAA.nolwenn.lemeur@nantes.inserm.fr>
Message-ID: <200212191142.16548.deepayan@stat.wisc.edu>

On Thursday 19 December 2002 08:33 am, Nolwenn Le Meur wrote:
> Hi,
>
> I have just started using lattice and it looks great. But I already have 3
> questions about xyplot display.
> ---------------------------------------------------------------------------
>- ---------------------------------
> 1.I would like to create two differeny xyplot with different color to
> identify my different groups but I have trouble applying colors.
> Here are the scripts
>
>  xyplot(resultdata$Y~resultdata$X ,
> data=resultdata,groups=resultdata$Block, panel="panel.xyplot",
>  panel.groups="panel.xyplot",
>  xlab="X",ylab="Y",pch="*",
>  col.groups=trellis.par.get("superpose.symbol")$col[1:6],cex=2,
>  key=list(space="right",
>  points=list(pch="*",
> 	     col=trellis.par.get("superpose.symbol")$col[1:6]),
>  text=list(paste("Block",1:6)))
>  )

This is supposed to be called like


xyplot(Y~X, data = resultdata, 
       groups = Block, 
       xlab="X", ylab="Y",
       pch="*",
       key=list(space="right",
                points=list(pch="*",
 	        col=trellis.par.get("superpose.symbol")$col[1:6]),
                text=list(paste("Block",1:6))))

There's no argument called col.groups, and the panel function you meant to use 
was panel.superpose, not panel.xyplot (which you don't have to specify 
explicitly since it's the default).

> xyplot(resultdata$Y~resultdata$X |resultdata$Block, data=resultdata,
>  xlab="X",ylab="Y",
> col.groups=trellis.par.get("superpose.symbol")$col[1:6],cex=2,
>  key=list(space="right",
>  points=list(pch=trellis.par.get("superpose.symbol")$pch[1:6],
> 	     col=trellis.par.get("superpose.symbol")$col[1:6]),
>  text=list(paste("Block",1:6)))
>  )

What exactly are you trying to do here? You don't have a grouping factor, so 
why is just 

xyplot(Y ~ X | Block, data = resultdata, 
       xlab="X", ylab="Y", cex = 2)

not OK ?


> ---------------------------------------------------------------------------
>- -------------------------------
>
> 2.For the latest formula I would also like to change the resultdata$Block
> label by the corresponding "Block x".

I'm not sure what you mean. If you are talking about the Labels in the strip 
above each panel, that would come from the levels of the Block variable. So, 
the Block variable has to be a factor, and it should have levels "Block 1" 
... "Block 6". See ?factor for how to do that.


> ---------------------------------------------------------------------------
>- -------------------------------
>
> 3.I finally would like to save my plot as "jpg" files under Linux but I
> loose the color.

How did you try to do this ?

Deepayan



From Benjamin.STABLER at odot.state.or.us  Thu Dec 19 19:25:03 2002
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Thu Dec 19 19:25:03 2002
Subject: [R] list to data.frame
Message-ID: <76A000A82289D411952F001083F9DD06039AC96E@exsalem4-bu.odot.state.or.us>

R Help-

I have a list of 102 vectors all of the same type and length called
time.by.orig.  I can't data.frame(time.by.orig) but I can
data.frame(time.by.orig[1:length(time.by.orig)]).  Why is this?  Thanks for
your help. 

str(time.by.orig)
List of 102
 $ 1  : num [1:102]  1.34 17.39 14.36 14.22  7.56 ...
 $ 2  : num [1:102] 17.5  0.7 17.7 12.4 10.4 ...
 $ 3  : num [1:102] 14.063 17.568  0.754  8.065 15.100 ...
 $ 4  : num [1:102] 13.940 12.423  7.546  0.766 14.977 ...
 $ 100: num [1:102]  7.722 10.400 15.049 14.915  0.467 ...
 $ 101: num [1:102]  5.68 13.99 13.90 13.77  4.01 ...
 $ 102: num [1:102]  6.67 11.86 14.88 14.75  1.68 ...
 ......
 - attr(*, "dim")= int 102
 - attr(*, "dimnames")=List of 1
  ..$ : chr [1:102] "1" "2" "3" "4" ...


> data.frame(time.by.orig)
Error in as.data.frame.default(x[[i]], optional = TRUE) : 
        can't coerce array into a data.frame

> data.frame(time.by.orig[1:length(time.by.orig)])
 -Works fine


Benjamin Stabler
Transportation Planning Analysis Unit
Oregon Department of Transportation
Salem, OR 97301 USA

-----Original Message-----
From: Deepayan Sarkar [mailto:deepayan at stat.wisc.edu]
Sent: Thursday, December 19, 2002 9:42 AM
To: Nolwenn Le Meur; r-help at stat.math.ethz.ch
Subject: Re: [R] lattice and display


On Thursday 19 December 2002 08:33 am, Nolwenn Le Meur wrote:
> Hi,
>
> I have just started using lattice and it looks great. But I already have 3
> questions about xyplot display.
>
---------------------------------------------------------------------------
>- ---------------------------------
> 1.I would like to create two differeny xyplot with different color to
> identify my different groups but I have trouble applying colors.
> Here are the scripts
>
>  xyplot(resultdata$Y~resultdata$X ,
> data=resultdata,groups=resultdata$Block, panel="panel.xyplot",
>  panel.groups="panel.xyplot",
>  xlab="X",ylab="Y",pch="*",
>  col.groups=trellis.par.get("superpose.symbol")$col[1:6],cex=2,
>  key=list(space="right",
>  points=list(pch="*",
> 	     col=trellis.par.get("superpose.symbol")$col[1:6]),
>  text=list(paste("Block",1:6)))
>  )

This is supposed to be called like


xyplot(Y~X, data = resultdata, 
       groups = Block, 
       xlab="X", ylab="Y",
       pch="*",
       key=list(space="right",
                points=list(pch="*",
 	        col=trellis.par.get("superpose.symbol")$col[1:6]),
                text=list(paste("Block",1:6))))

There's no argument called col.groups, and the panel function you meant to
use 
was panel.superpose, not panel.xyplot (which you don't have to specify 
explicitly since it's the default).

> xyplot(resultdata$Y~resultdata$X |resultdata$Block, data=resultdata,
>  xlab="X",ylab="Y",
> col.groups=trellis.par.get("superpose.symbol")$col[1:6],cex=2,
>  key=list(space="right",
>  points=list(pch=trellis.par.get("superpose.symbol")$pch[1:6],
> 	     col=trellis.par.get("superpose.symbol")$col[1:6]),
>  text=list(paste("Block",1:6)))
>  )

What exactly are you trying to do here? You don't have a grouping factor, so

why is just 

xyplot(Y ~ X | Block, data = resultdata, 
       xlab="X", ylab="Y", cex = 2)

not OK ?


>
---------------------------------------------------------------------------
>- -------------------------------
>
> 2.For the latest formula I would also like to change the resultdata$Block
> label by the corresponding "Block x".

I'm not sure what you mean. If you are talking about the Labels in the strip

above each panel, that would come from the levels of the Block variable. So,

the Block variable has to be a factor, and it should have levels "Block 1" 
... "Block 6". See ?factor for how to do that.


>
---------------------------------------------------------------------------
>- -------------------------------
>
> 3.I finally would like to save my plot as "jpg" files under Linux but I
> loose the color.

How did you try to do this ?

Deepayan

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Benjamin.STABLER at odot.state.or.us  Thu Dec 19 19:36:03 2002
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Thu Dec 19 19:36:03 2002
Subject: [R] list to data.frame
Message-ID: <76A000A82289D411952F001083F9DD06039AC96F@exsalem4-bu.odot.state.or.us>

as.data.frame() does not work but as.data.frame.list() does.  Any thoughts?

as.data.frame(time.by.orig)
Error in as.data.frame.default(time.by.orig) : 
        can't coerce array into a data.frame

as.data.frame.list(time.by.orig)
-Works fine

-----Original Message-----
From: Richards, Tom [mailto:richards at upci.pitt.edu]
Sent: Thursday, December 19, 2002 10:24 AM
To: STABLER Benjamin
Subject: RE: [R] list to data.frame


It's because there is no list method for data.frame(), but there is a method
called as.data.frame.list, and thus as.data.frame(time.by.orig) should work
(I haven't tried).

Tom Richards

> -----Original Message-----
> From: Benjamin.STABLER at odot.state.or.us
> [mailto:Benjamin.STABLER at odot.state.or.us]
> Sent: Thursday, December 19, 2002 1:24 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] list to data.frame
> 
> 
> R Help-
> 
> I have a list of 102 vectors all of the same type and length called
> time.by.orig.  I can't data.frame(time.by.orig) but I can
> data.frame(time.by.orig[1:length(time.by.orig)]).  Why is 
> this?  Thanks for
> your help. 
> 
> str(time.by.orig)
> List of 102
>  $ 1  : num [1:102]  1.34 17.39 14.36 14.22  7.56 ...
>  $ 2  : num [1:102] 17.5  0.7 17.7 12.4 10.4 ...
>  $ 3  : num [1:102] 14.063 17.568  0.754  8.065 15.100 ...
>  $ 4  : num [1:102] 13.940 12.423  7.546  0.766 14.977 ...
>  $ 100: num [1:102]  7.722 10.400 15.049 14.915  0.467 ...
>  $ 101: num [1:102]  5.68 13.99 13.90 13.77  4.01 ...
>  $ 102: num [1:102]  6.67 11.86 14.88 14.75  1.68 ...
>  ......
>  - attr(*, "dim")= int 102
>  - attr(*, "dimnames")=List of 1
>   ..$ : chr [1:102] "1" "2" "3" "4" ...
> 
> 
> > data.frame(time.by.orig)
> Error in as.data.frame.default(x[[i]], optional = TRUE) : 
>         can't coerce array into a data.frame
> 
> > data.frame(time.by.orig[1:length(time.by.orig)])
>  -Works fine
> 
> 
> Benjamin Stabler
> Transportation Planning Analysis Unit
> Oregon Department of Transportation
> Salem, OR 97301 USA
> 
> -----Original Message-----
> From: Deepayan Sarkar [mailto:deepayan at stat.wisc.edu]
> Sent: Thursday, December 19, 2002 9:42 AM
> To: Nolwenn Le Meur; r-help at stat.math.ethz.ch
> Subject: Re: [R] lattice and display
> 
> 
> On Thursday 19 December 2002 08:33 am, Nolwenn Le Meur wrote:
> > Hi,
> >
> > I have just started using lattice and it looks great. But I 
> already have 3
> > questions about xyplot display.
> >
> --------------------------------------------------------------
> -------------
> >- ---------------------------------
> > 1.I would like to create two differeny xyplot with 
> different color to
> > identify my different groups but I have trouble applying colors.
> > Here are the scripts
> >
> >  xyplot(resultdata$Y~resultdata$X ,
> > data=resultdata,groups=resultdata$Block, panel="panel.xyplot",
> >  panel.groups="panel.xyplot",
> >  xlab="X",ylab="Y",pch="*",
> >  col.groups=trellis.par.get("superpose.symbol")$col[1:6],cex=2,
> >  key=list(space="right",
> >  points=list(pch="*",
> > 	     col=trellis.par.get("superpose.symbol")$col[1:6]),
> >  text=list(paste("Block",1:6)))
> >  )
> 
> This is supposed to be called like
> 
> 
> xyplot(Y~X, data = resultdata, 
>        groups = Block, 
>        xlab="X", ylab="Y",
>        pch="*",
>        key=list(space="right",
>                 points=list(pch="*",
>  	        col=trellis.par.get("superpose.symbol")$col[1:6]),
>                 text=list(paste("Block",1:6))))
> 
> There's no argument called col.groups, and the panel function 
> you meant to
> use 
> was panel.superpose, not panel.xyplot (which you don't have 
> to specify 
> explicitly since it's the default).
> 
> > xyplot(resultdata$Y~resultdata$X |resultdata$Block, data=resultdata,
> >  xlab="X",ylab="Y",
> > col.groups=trellis.par.get("superpose.symbol")$col[1:6],cex=2,
> >  key=list(space="right",
> >  points=list(pch=trellis.par.get("superpose.symbol")$pch[1:6],
> > 	     col=trellis.par.get("superpose.symbol")$col[1:6]),
> >  text=list(paste("Block",1:6)))
> >  )
> 
> What exactly are you trying to do here? You don't have a 
> grouping factor, so
> 
> why is just 
> 
> xyplot(Y ~ X | Block, data = resultdata, 
>        xlab="X", ylab="Y", cex = 2)
> 
> not OK ?
> 
> 
> >
> --------------------------------------------------------------
> -------------
> >- -------------------------------
> >
> > 2.For the latest formula I would also like to change the 
> resultdata$Block
> > label by the corresponding "Block x".
> 
> I'm not sure what you mean. If you are talking about the 
> Labels in the strip
> 
> above each panel, that would come from the levels of the 
> Block variable. So,
> 
> the Block variable has to be a factor, and it should have 
> levels "Block 1" 
> ... "Block 6". See ?factor for how to do that.
> 
> 
> >
> --------------------------------------------------------------
> -------------
> >- -------------------------------
> >
> > 3.I finally would like to save my plot as "jpg" files under 
> Linux but I
> > loose the color.
> 
> How did you try to do this ?
> 
> Deepayan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ripley at stats.ox.ac.uk  Thu Dec 19 19:50:07 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu Dec 19 19:50:07 2002
Subject: [R] list to data.frame
In-Reply-To: <76A000A82289D411952F001083F9DD06039AC96E@exsalem4-bu.odot.state.or.us>
Message-ID: <Pine.LNX.4.31.0212191846530.4973-100000@gannet.stats>

On Thu, 19 Dec 2002 Benjamin.STABLER at odot.state.or.us wrote:

> I have a list of 102 vectors all of the same type and length called
> time.by.orig.  I can't data.frame(time.by.orig) but I can
> data.frame(time.by.orig[1:length(time.by.orig)]).  Why is this?  Thanks for
> your help.

You don't have a list: you have a one-dimensional array of mode list.
Subsetting drops the dimension and gives you a list.

Please pay attention to the messages: note the attributes of your object
and that the error message said it was a list.

> str(time.by.orig)
> List of 102
>  $ 1  : num [1:102]  1.34 17.39 14.36 14.22  7.56 ...
>  $ 2  : num [1:102] 17.5  0.7 17.7 12.4 10.4 ...
>  $ 3  : num [1:102] 14.063 17.568  0.754  8.065 15.100 ...
>  $ 4  : num [1:102] 13.940 12.423  7.546  0.766 14.977 ...
>  $ 100: num [1:102]  7.722 10.400 15.049 14.915  0.467 ...
>  $ 101: num [1:102]  5.68 13.99 13.90 13.77  4.01 ...
>  $ 102: num [1:102]  6.67 11.86 14.88 14.75  1.68 ...
>  ......
>  - attr(*, "dim")= int 102
>  - attr(*, "dimnames")=List of 1
>   ..$ : chr [1:102] "1" "2" "3" "4" ...
>
>
> > data.frame(time.by.orig)
> Error in as.data.frame.default(x[[i]], optional = TRUE) :
>         can't coerce array into a data.frame
>
> > data.frame(time.by.orig[1:length(time.by.orig)])
>  -Works fine

Irrelevant earlier message deleted: please don't waste bandwidth like
that.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From apjaworski at mmm.com  Thu Dec 19 20:36:02 2002
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Thu Dec 19 20:36:02 2002
Subject: [R] New versions of lattice and grid
Message-ID: <OF7B13DBC2.840A4DEA-ON86256C94.006999CE@mmm.com>

I just ran package update on my Win2000 R-1.6.1 and it installed new
versions of lattice and grid (0.6-7 and 0.7-3 respectively).  Then I ran
demo(lattice) and noticed that the last plot, which is supposed to
illustrate math expression usage, fails in the sense that all expression
are shown literally.  For example the title of the plot reads " pi*sum(x,
i=0, n)", the x-axis label is "sigma[i]", the subtitle reads
frac(demonstrating, expressions), etc.  This happed using windows device as
well as postscrip device (on Win2000 and Linux platforms).

I am almost sure that this worked before.  Could anybody confirm this?

Andy

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122



From vograno at arbitrade.com  Thu Dec 19 20:57:07 2002
From: vograno at arbitrade.com (Vadim Ogranovich)
Date: Thu Dec 19 20:57:07 2002
Subject: [R] disabling NA token as na.string in read.table
Message-ID: <AFD78192EC49D311BFAE00902798AB8F23DC64@jupiter.arbitrade.com>

Dear R-Users,

I have a csv file that has NA tokens and these tokens are perfectly good
values that need not to be converted to NA by read.table(). I tried to
prevent the conversion by specifying the na.strings arg., but this seems to
only add to the list of NA strings, not substitute.

> system("cat foo")
system("cat foo")
1 foo
2 NA
> read.table("foo", na.strings="foo")
read.table("foo", na.strings="foo")
  V1 V2
1  1 NA
2  2 NA


This is R1.6.0 on Linux.

What did I do wrong?

Thanks, Vadim

-------------------------------------------------- 
DISCLAIMER \ This e-mail, and any attachments thereto, is intend ... [[dropped]]



From kwan022 at stat.auckland.ac.nz  Thu Dec 19 22:09:03 2002
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Thu Dec 19 22:09:03 2002
Subject: [R] More on scan()
Message-ID: <Pine.SOL.4.21.0212201006450.8645-100000@stat1.stat.auckland.ac.nz>

Hi,

If I have a CSV file which has several comments at the top, and the data
start immediately after the line:
  @DATA

Is it possible to use the scan() command to get the CSV data into R, by
only reading the lines after @DATA?  If so, how can I do it?

Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

Ko-Kang Kevin Wang
Master of Science (MSc) Student
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022



From deepayan at stat.wisc.edu  Thu Dec 19 23:09:02 2002
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu Dec 19 23:09:02 2002
Subject: [R] New versions of lattice and grid
In-Reply-To: <OF7B13DBC2.840A4DEA-ON86256C94.006999CE@mmm.com>
References: <OF7B13DBC2.840A4DEA-ON86256C94.006999CE@mmm.com>
Message-ID: <200212191609.27025.deepayan@stat.wisc.edu>

On Thursday 19 December 2002 01:35 pm, apjaworski at mmm.com wrote:
> I just ran package update on my Win2000 R-1.6.1 and it installed new
> versions of lattice and grid (0.6-7 and 0.7-3 respectively).  Then I ran
> demo(lattice) and noticed that the last plot, which is supposed to
> illustrate math expression usage, fails in the sense that all expression
> are shown literally.  For example the title of the plot reads " pi*sum(x,
> i=0, n)", the x-axis label is "sigma[i]", the subtitle reads
> frac(demonstrating, expressions), etc.  This happed using windows device as
> well as postscrip device (on Win2000 and Linux platforms).
>
> I am almost sure that this worked before.  Could anybody confirm this?

The problem is definitely real. Fortunately I had a fairly recent (but not the 
most recent) version of grid that didn't have this problem, and comparing the 
two, the problem seems to be a small change in grid.text. The older version 
seems to work:

grid.text <- function(label, x=unit(0.5, "npc"), y=unit(0.5, "npc"),
                  just="centre", rot=0, check.overlap=FALSE,
                  default.units="npc", gp=gpar(), draw=TRUE, vp=NULL) {
  if (!is.unit(x))
    x <- unit(x, default.units)
  if (!is.unit(y))
    y <- unit(y, default.units)
  txt <- list(label=label, x=x, y=y, gp=gp,
              ## WAS label = as.character(label)
              just=just, rot=rot, check.overlap=check.overlap,
              vp=vp)
  cl <- "text"
  grid.grob(txt, cl, draw)
}

I have no idea whether this might break anything else. If Paul is able to look 
at this before he disappears for the holidays, great. Otherwise, we will 
probably have to wait to get this fixed.

Deepayan



From p.dalgaard at biostat.ku.dk  Thu Dec 19 23:17:03 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu Dec 19 23:17:03 2002
Subject: [R] disabling NA token as na.string in read.table
In-Reply-To: <AFD78192EC49D311BFAE00902798AB8F23DC64@jupiter.arbitrade.com>
References: <AFD78192EC49D311BFAE00902798AB8F23DC64@jupiter.arbitrade.com>
Message-ID: <x2hed9d5ht.fsf@biostat.ku.dk>

Vadim Ogranovich <vograno at arbitrade.com> writes:

> Dear R-Users,
> 
> I have a csv file that has NA tokens and these tokens are perfectly good
> values that need not to be converted to NA by read.table(). I tried to
> prevent the conversion by specifying the na.strings arg., but this seems to
> only add to the list of NA strings, not substitute.
> 
> > system("cat foo")
> system("cat foo")
> 1 foo
> 2 NA
> > read.table("foo", na.strings="foo")
> read.table("foo", na.strings="foo")
>   V1 V2
> 1  1 NA
> 2  2 NA
> 
> 
> This is R1.6.0 on Linux.
> 
> What did I do wrong?

Hmm, this looks like a bit of a bug. read.table() ends up calling
type.convert() with its default "NA" na.string. Now, if "NA" was in
the na.string for read.table(), scan() would already have turned it
into <NA> at that point, so I suspect you might have preferred
na.strings=character(0), but that has the side effect of turning the
real NA into a factor level:

> x <- c(NA,"NA","foo")
> type.convert(x)
[1] <NA> <NA> foo
Levels: foo
> type.convert(x,na.strings=character(0))
[1] <NA> NA   foo
Levels: NA foo NA
> dput(type.convert(x,na.strings=character(0)))
structure(c(3, 1, 2), .Label = c("NA", "foo", NA), class = "factor")

I.e. it looks like the internals of type.convert needs some fixing up.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From apjaworski at mmm.com  Thu Dec 19 23:25:03 2002
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Thu Dec 19 23:25:03 2002
Subject: [R] More on scan()
Message-ID: <OF0D85D847.5A03E963-ON86256C94.007934C6@mmm.com>

Here is one way of doing this.
(1) read the whole file in as a vector of strings one line at a time
      x <- readLines("<path to your data file>")
(2) find the position of the "@DATA" string in your vector
      s <- which(x == "@DATA")
(3) scan the file again skipping s lines
      scan("<path to your data file>", skip=s, sep=",", ...)

You may want to consider using read.table instead of scan - it has the skip
parameter too.  Finally you could actually reuse x from (1) above by
something like
      x <- x[-(1:s])
      loop through elements of x and use the strsplit command to extract
numbers from each line
I suspect that this would be more cumbersome and slower than re-reading the
file skiiping s lines from the top.

Cheers,

Andy

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


|---------+------------------------------>
|         |           Ko-Kang Kevin Wang |
|         |           <kwan022 at stat.auckl|
|         |           and.ac.nz>         |
|         |           Sent by:           |
|         |           r-help-admin at stat.m|
|         |           ath.ethz.ch        |
|         |                              |
|         |                              |
|         |           12/20/2002 04:08   |
|         |                              |
|---------+------------------------------>
  >-----------------------------------------------------------------------------------------------------------------------------|
  |                                                                                                                             |
  |      To:       R Help <r-help at stat.math.ethz.ch>                                                                            |
  |      cc:                                                                                                                    |
  |      Subject:  [R] More on scan()                                                                                           |
  >-----------------------------------------------------------------------------------------------------------------------------|



Hi,

If I have a CSV file which has several comments at the top, and the data
start immediately after the line:
  @DATA

Is it possible to use the scan() command to get the CSV data into R, by
only reading the lines after @DATA?  If so, how can I do it?

Cheers,

Kevin

------------------------------------------------------------------------------

/* Time is the greatest teacher, unfortunately it kills its students */

Ko-Kang Kevin Wang
Master of Science (MSc) Student
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From p.dalgaard at biostat.ku.dk  Thu Dec 19 23:32:03 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu Dec 19 23:32:03 2002
Subject: [R] New versions of lattice and grid
In-Reply-To: <200212191609.27025.deepayan@stat.wisc.edu>
References: <OF7B13DBC2.840A4DEA-ON86256C94.006999CE@mmm.com>
	<200212191609.27025.deepayan@stat.wisc.edu>
Message-ID: <x28yyld4lt.fsf@biostat.ku.dk>

Deepayan Sarkar <deepayan at stat.wisc.edu> writes:

> two, the problem seems to be a small change in grid.text. The older version 
> seems to work:
> 
> grid.text <- function(label, x=unit(0.5, "npc"), y=unit(0.5, "npc"),
>                   just="centre", rot=0, check.overlap=FALSE,
>                   default.units="npc", gp=gpar(), draw=TRUE, vp=NULL) {
>   if (!is.unit(x))
>     x <- unit(x, default.units)
>   if (!is.unit(y))
>     y <- unit(y, default.units)
>   txt <- list(label=label, x=x, y=y, gp=gp,
>               ## WAS label = as.character(label)
>               just=just, rot=rot, check.overlap=check.overlap,
>               vp=vp)
>   cl <- "text"
>   grid.grob(txt, cl, draw)
> }

...for values of "WAS" meaning "Is currently", I presume.
 
> I have no idea whether this might break anything else. If Paul is able to look 
> at this before he disappears for the holidays, great. Otherwise, we will 
> probably have to wait to get this fixed.

It's pretty patently wrong and I think Paul will be gone until after
the 1.6.2 release, so it would be unfortunate to wait. Perhaps we
could program defensively using something like

   if (!is.language(label)) label <- as.character(label)
   txt <- list(label=label, x=x, y=y, gp=gp, ...etc...

??


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From paradis at isem.univ-montp2.fr  Fri Dec 20 00:10:03 2002
From: paradis at isem.univ-montp2.fr (Emmanuel Paradis)
Date: Fri Dec 20 00:10:03 2002
Subject: [R] More on scan()
In-Reply-To: <Pine.SOL.4.21.0212201006450.8645-100000@stat1.stat.aucklan
 d.ac.nz>
Message-ID: <4.2.0.58.20021219235534.00b35068@162.38.183.200>

At 10:08 20/12/2002 +1300, vous avez ?crit:
>Hi,
>
>If I have a CSV file which has several comments at the top, and the data
>start immediately after the line:
>   @DATA
>
>Is it possible to use the scan() command to get the CSV data into R, by
>only reading the lines after @DATA?  If so, how can I do it?
>
>Cheers,
>
>Kevin


Here is a possible solution (if your data file is `yourfile.txt'):


tmp <- scan("yourfile.txt", what = "", sep = "\n")
skp <- grep("@DATA", tmp)
your.data <- scan("yourfile.txt", what = [...], skip = skp)


You may improve this by scanning line by line with:

scan("foo.txt", what = "", sep = "\n", n = 1, skip = s)

with s = 0, 1, 2, ... till you meet "@DATA".


Hope this helps.

EP

Emmanuel Paradis
Laboratoire de Pal?ontologie
Institut des Sciences de l'?volution
Universit? Montpellier II
F-34095 Montpellier c?dex 05
France
    phone: +33  4 67 14 39 64
      fax: +33  4 67 14 36 10
   mailto:paradis at isem.univ-montp2.fr
http://www.isem.univ-montp2.fr/ISEMFre/Equipes/PPP/PPerso/ParadisE.php



From p.murrell at auckland.ac.nz  Fri Dec 20 00:34:02 2002
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Fri Dec 20 00:34:02 2002
Subject: [R] New versions of lattice and grid
References: <OF7B13DBC2.840A4DEA-ON86256C94.006999CE@mmm.com>
		<200212191609.27025.deepayan@stat.wisc.edu> <x28yyld4lt.fsf@biostat.ku.dk>
Message-ID: <3E0258DF.95E968F2@stat.auckland.ac.nz>

Hi


Peter Dalgaard BSA wrote:
> 
> Deepayan Sarkar <deepayan at stat.wisc.edu> writes:
> 
> > two, the problem seems to be a small change in grid.text. The older version
> > seems to work:
> >
> > grid.text <- function(label, x=unit(0.5, "npc"), y=unit(0.5, "npc"),
> >                   just="centre", rot=0, check.overlap=FALSE,
> >                   default.units="npc", gp=gpar(), draw=TRUE, vp=NULL) {
> >   if (!is.unit(x))
> >     x <- unit(x, default.units)
> >   if (!is.unit(y))
> >     y <- unit(y, default.units)
> >   txt <- list(label=label, x=x, y=y, gp=gp,
> >               ## WAS label = as.character(label)
> >               just=just, rot=rot, check.overlap=check.overlap,
> >               vp=vp)
> >   cl <- "text"
> >   grid.grob(txt, cl, draw)
> > }
> 
> ...for values of "WAS" meaning "Is currently", I presume.
> 
> > I have no idea whether this might break anything else. If Paul is able to look
> > at this before he disappears for the holidays, great. Otherwise, we will
> > probably have to wait to get this fixed.
> 
> It's pretty patently wrong and I think Paul will be gone until after
> the 1.6.2 release, so it would be unfortunate to wait. Perhaps we
> could program defensively using something like
> 
>    if (!is.language(label)) label <- as.character(label)
>    txt <- list(label=label, x=x, y=y, gp=gp, ...etc...
> 
> ??


Not gone yet (and not for a couple of hours it would seem).  This was a
brain-dead bug fix of mine.  I'm working on a better one.  Once I have
that and have checked that I will put up a grid_0.7-4 

Paul



From bitwrit at ozemail.com.au  Fri Dec 20 00:42:03 2002
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Fri Dec 20 00:42:03 2002
Subject: [R] acceptable p-level for scientific studies
In-Reply-To: <20021218091251.36c5eaae.fharrell@virginia.edu>
References: <00b501c2a693$28974200$5e05cf9b@pharm.auth.gr> <20021218091251.36c5eaae.fharrell@virginia.edu>
Message-ID: <20021219233408.VICI8759.mta04.mail.mel.aone.net.au@there>

Kyriakos Kachrimanis (et al.) wrote:

> I have a statistical question, that doesn't belong to this list, and I
> apologise for that in advance but I would appreciate your help very much.
> Is there some convention for selecting the a level for significance 
> testing in scientific (e.g. chemical processes) studies? Most people use
> the 0.05 level but I could not find a reference to justify this. Why not 
> 0.01 or 0.1? Montgomery in his book "Design and Analysis of Experiments" 
> disagrees with setting a priori acceptable levels at all. Is it 
> necessary to set a limit for significance testing since R can provide 
> exact probability levels for the significance of each effect?
>
In general, setting arbitrary criteria for statistical significance seems 
to be based upon a compromise between apparent progress (maximal 
discovery) and theoretical durability (minimal disconfirmation). If we are 
to build knowledge from ignorance or misapprehension, it is best to choose 
methods and criteria that lead to an optimal compromise. Statistical 
evaluation of data has done a much better job than rhetorical contention 
as a method. 
Criteria range from the apparently slack alpha=0.1 in fields where is it 
difficult to discover any regularity to approximately 0.000000001 for 
establishing an effect at "six sigma" where variables are apparently well 
described and measurement is correspondingly precise.
In fact, what seems to happen is that researchers and reviewers find 
criteria that allow them to advance, at least apparently, at a certain 
rate. Thus my opinion is that a certain level of apparent progress is 
psychologically necessary in research, and those in the messier areas are 
willing to look a bit more foolish.

Jim



From tlumley at u.washington.edu  Fri Dec 20 00:47:21 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri Dec 20 00:47:21 2002
Subject: [R] More on scan()
In-Reply-To: <OF0D85D847.5A03E963-ON86256C94.007934C6@mmm.com>
Message-ID: <Pine.A41.4.44.0212191530080.59992-100000@homer10.u.washington.edu>

On Thu, 19 Dec 2002 apjaworski at mmm.com wrote:

>
> Here is one way of doing this.
> (1) read the whole file in as a vector of strings one line at a time
>       x <- readLines("<path to your data file>")
> (2) find the position of the "@DATA" string in your vector
>       s <- which(x == "@DATA")
> (3) scan the file again skipping s lines
>       scan("<path to your data file>", skip=s, sep=",", ...)
>
> You may want to consider using read.table instead of scan - it has the skip
> parameter too.  Finally you could actually reuse x from (1) above by
> something like
>       x <- x[-(1:s])
>       loop through elements of x and use the strsplit command to extract
> numbers from each line
> I suspect that this would be more cumbersome and slower than re-reading the
> file skiiping s lines from the top.

A simpler  solution that doesn't involve rereading is to use a connection

   conn<-file("myfile.txt")
   open(conn)
   repeat({
	a.line <- readLines(conn,n=1)
	if (substr(a.line,1,6)=="@DATA") break
   })

   read.csv(conn)

   close(conn)


	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From deepayan at stat.wisc.edu  Fri Dec 20 00:52:27 2002
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri Dec 20 00:52:27 2002
Subject: [R] New versions of lattice and grid
In-Reply-To: <x28yyld4lt.fsf@biostat.ku.dk>
References: <OF7B13DBC2.840A4DEA-ON86256C94.006999CE@mmm.com> <200212191609.27025.deepayan@stat.wisc.edu> <x28yyld4lt.fsf@biostat.ku.dk>
Message-ID: <200212191737.23056.deepayan@stat.wisc.edu>

On Thursday 19 December 2002 04:30 pm, Peter Dalgaard BSA wrote:
> Deepayan Sarkar <deepayan at stat.wisc.edu> writes:
> > two, the problem seems to be a small change in grid.text. The older
> > version seems to work:
> >
> > grid.text <- function(label, x=unit(0.5, "npc"), y=unit(0.5, "npc"),
> >                   just="centre", rot=0, check.overlap=FALSE,
> >                   default.units="npc", gp=gpar(), draw=TRUE, vp=NULL) {
> >   if (!is.unit(x))
> >     x <- unit(x, default.units)
> >   if (!is.unit(y))
> >     y <- unit(y, default.units)
> >   txt <- list(label=label, x=x, y=y, gp=gp,
> >               ## WAS label = as.character(label)
> >               just=just, rot=rot, check.overlap=check.overlap,
> >               vp=vp)
> >   cl <- "text"
> >   grid.grob(txt, cl, draw)
> > }
>
> ...for values of "WAS" meaning "Is currently", I presume.

Right.

> > I have no idea whether this might break anything else. If Paul is able to
> > look at this before he disappears for the holidays, great. Otherwise, we
> > will probably have to wait to get this fixed.
>
> It's pretty patently wrong and I think Paul will be gone until after
> the 1.6.2 release, so it would be unfortunate to wait. Perhaps we
> could program defensively using something like
>
>    if (!is.language(label)) label <- as.character(label)
>    txt <- list(label=label, x=x, y=y, gp=gp, ...etc...
>
> ??

That seems like a good idea. For what it's worth, both grid and lattice pass R 
CMD check, and the other changes don't look like they are related.

Deepayan



From yuelin at shaggy.infosys.chop.edu  Fri Dec 20 00:59:10 2002
From: yuelin at shaggy.infosys.chop.edu (Yuelin Li)
Date: Fri Dec 20 00:59:10 2002
Subject: [R] testing correlated proportions
Message-ID: <200212192340.gBJNeSFE002394@hypatia.math.ethz.ch>

A question about comparing symptom reduction over time and across 
treatment groups.  Each respondent is asked twice if they 
experience symptoms (coded 1), at baseline and then at 6 months 
later.  They are randomly assigned to either the control or the 
intervention group.  The 2x2x2 table below shows the frequency 
counts.

As can be seen in the margins of the table, 21% of the control 
group show symptoms at baseline, then it reduced to 7% six months 
later; and 48% of the intervention group show symptoms at 
baseline, then only 4% at 6 month.  

The question is, given the information below, how do I test if 
the intervention group has a better improvement?

Intuitively, I imagine that a difference of 44% should be better 
than a 14% difference in a sample of about 30 respondents.  But 
it is no so according to Levin & Serlin's method (J. of Stats 
Education, 8 (2), 2000).

Levin and Serlin say that correlated proportions between two 
groups can be tested by a simple 2x2 table using the frequency of 
changes:

			Control		Intervention
		------------------------------------
0 --> 1 (worse)		2		0
1 --> 0 (better)	6		12
----------------------------------------------------

A fisher.test(matrix(c(2,6,0,12), ncol=2)) shows a p-value of 
0.15.  

I'd appreciate suggestions to alternative methods, perhaps a test 
of conditional independence in loglin()?  But I am not sure how 
to do that.

Yuelin Li.

---------  Table  -------------

Control Group

(baseline by 6 months)
Frequency|
Percent  |
Row Pct  |       0|       1|  Total
---------+--------+--------+
       0 |     20 |      2 |     22
         |  71.43 |   7.14 |  78.57
         |  90.91 |   9.09 |
---------+--------+--------+
       1 |      6 |      0 |      6
         |  21.43 |   0.00 |  21.43
         | 100.00 |   0.00 |
---------+--------+--------+
Total          26        2       28
            92.86     7.14   100.00

Intervention Group

(baseline by 6 months)
Frequency|
Percent  |
Row Pct  |       0|       1|  Total
---------+--------+--------+
       0 |     14 |      0 |     14
         |  51.85 |   0.00 |  51.85
         | 100.00 |   0.00 |
---------+--------+--------+
       1 |     12 |      1 |     13
         |  44.44 |   3.70 |  48.15
         |  92.31 |   7.69 |
---------+--------+--------+
Total          26        1       27
            96.30     3.70   100.00



From p.murrell at auckland.ac.nz  Fri Dec 20 01:21:02 2002
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Fri Dec 20 01:21:02 2002
Subject: [R] New versions of lattice and grid
References: <OF7B13DBC2.840A4DEA-ON86256C94.006999CE@mmm.com>
			<200212191609.27025.deepayan@stat.wisc.edu> <x28yyld4lt.fsf@biostat.ku.dk> <3E0258DF.95E968F2@stat.auckland.ac.nz>
Message-ID: <3E026405.D308B07D@stat.auckland.ac.nz>

Hi

grid_0.7-4 has been submitted to CRAN.
Apologies for the stuff up.
I may try to go on holiday now ... :)

Paul

technical note:  I used is.expression() rather than is.language()
because that is all that grid's C code checks for.  Yes, this should be
expanded to allow is.language() at some point.

even more technical note:  is.language() does not correspond to the
C-level function isLanguage ...


Paul Murrell wrote:
> 
> Hi
> 
> Peter Dalgaard BSA wrote:
> >
> > Deepayan Sarkar <deepayan at stat.wisc.edu> writes:
> >
> > > two, the problem seems to be a small change in grid.text. The older version
> > > seems to work:
> > >
> > > grid.text <- function(label, x=unit(0.5, "npc"), y=unit(0.5, "npc"),
> > >                   just="centre", rot=0, check.overlap=FALSE,
> > >                   default.units="npc", gp=gpar(), draw=TRUE, vp=NULL) {
> > >   if (!is.unit(x))
> > >     x <- unit(x, default.units)
> > >   if (!is.unit(y))
> > >     y <- unit(y, default.units)
> > >   txt <- list(label=label, x=x, y=y, gp=gp,
> > >               ## WAS label = as.character(label)
> > >               just=just, rot=rot, check.overlap=check.overlap,
> > >               vp=vp)
> > >   cl <- "text"
> > >   grid.grob(txt, cl, draw)
> > > }
> >
> > ...for values of "WAS" meaning "Is currently", I presume.
> >
> > > I have no idea whether this might break anything else. If Paul is able to look
> > > at this before he disappears for the holidays, great. Otherwise, we will
> > > probably have to wait to get this fixed.
> >
> > It's pretty patently wrong and I think Paul will be gone until after
> > the 1.6.2 release, so it would be unfortunate to wait. Perhaps we
> > could program defensively using something like
> >
> >    if (!is.language(label)) label <- as.character(label)
> >    txt <- list(label=label, x=x, y=y, gp=gp, ...etc...
> >
> > ??
> 
> Not gone yet (and not for a couple of hours it would seem).  This was a
> brain-dead bug fix of mine.  I'm working on a better one.  Once I have
> that and have checked that I will put up a grid_0.7-4
> 
> Paul

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz



From Ted.Harding at nessie.mcc.ac.uk  Fri Dec 20 03:39:03 2002
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri Dec 20 03:39:03 2002
Subject: [R] Printing correlation matrices (lm/glm)
Message-ID: <XFMail.021220023149.Ted.Harding@nessie.mcc.ac.uk>

Hi Folks,

I'm analysing some data which, in its simplest aspect,
has 3 factors A, B, C each at 2 levels.

If I do

  lm1 <- lm(y ~ A*B)

say, and then

  summary(lm1, corr=T)

I get the correlation matrix of the estimated coeffcients
with numerical values for the correlations (3 coeffs in this
case). Likewise with 'glm' instead of 'lm'.

However, if I do

  lm2 <- lm(y ~ A*B*C)

and then

  summary(lm2, corr=T)

I get only symbols (such as ".", "+", "*") for the values,
denoting ranges, and not numbers (7 coefficients in this case).

Presumably this happens when the number of columns is considered
to be getting a bit large for numbers -- though 7 is not huge ...

Anyway, is there any way I can get the full correlation matrix
out with numbers instead of symbols, even with several coefficients?

With thanks,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 20-Dec-02                                       Time: 02:31:49
------------------------------ XFMail ------------------------------



From andy_liaw at merck.com  Fri Dec 20 07:12:03 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri Dec 20 07:12:03 2002
Subject: [R] Printing correlation matrices (lm/glm)
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC9F8@usrymx10.merck.com>

Try print(summary(lm2, corr=TRUE), symbolic.corr=FALSE).  It *is* in the
help page.

HTH,
Andy

> From: Ted.Harding at nessie.mcc.ac.uk 
> Subject: [R] Printing correlation matrices (lm/glm)
> 
> Hi Folks,
> 
> I'm analysing some data which, in its simplest aspect,
> has 3 factors A, B, C each at 2 levels.
> 
> If I do
> 
>   lm1 <- lm(y ~ A*B)
> 
> say, and then
> 
>   summary(lm1, corr=T)
> 
> I get the correlation matrix of the estimated coeffcients
> with numerical values for the correlations (3 coeffs in this
> case). Likewise with 'glm' instead of 'lm'.
> 
> However, if I do
> 
>   lm2 <- lm(y ~ A*B*C)
> 
> and then
> 
>   summary(lm2, corr=T)
> 
> I get only symbols (such as ".", "+", "*") for the values,
> denoting ranges, and not numbers (7 coefficients in this case).
> 
> Presumably this happens when the number of columns is considered
> to be getting a bit large for numbers -- though 7 is not huge ...
> 
> Anyway, is there any way I can get the full correlation matrix
> out with numbers instead of symbols, even with several coefficients?
> 
> With thanks,
> Ted.

------------------------------------------------------------------------------



From arc at arcriswell.com  Fri Dec 20 07:26:03 2002
From: arc at arcriswell.com (Andrew Criswell)
Date: Fri Dec 20 07:26:03 2002
Subject: [R] Getting graphs into LaTeX
Message-ID: <3F44C651.3060006@arcriswell.com>

Hello ALL:

I ran with success the following commands in R getting a file saved
------------------------------------------------------------------------------------
postscript()

postscript('~/data/st202/2003/lecture00/lecture00-graph-01.eps',
           horizontal = FALSE, height = 6, pointsize = 10)

hist(trial.outcome.5, breaks = 5,
     main = '1000 Replications of 5 Trials of a Coin Toss',
     xlab = 'Frequency of a Tail')
------------------------------------------------------------------------------------
But when I try to include it within a LaTeX document, I get the 
following complaint.

LaTeX document (trix.tex):
------------------------------------------------------------------------------------
\documentclass[11pt]{article}
\usepackage[pdftex]{graphicx,color}
\begin{document}
\includegraphics{lecture00-graph-01.eps}
\end{document}
------------------------------------------------------------------------------------
Which I try to compile with the command:  pdflatex trix.tex

But then, I get this error:
------------------------------------------------------------------------------------
! LaTeX Error: Unknown graphics extension: .eps.

See the LaTeX manual or LaTeX Companion for explanation.
Type  H <return>  for immediate help.
 ...

l.5 \includegraphics{lecture00-graph-01.eps}

?
------------------------------------------------------------------------------------
Any suggestions?

Thanks,
ANDREW



From Ko-Kang at xtra.co.nz  Fri Dec 20 07:42:03 2002
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Fri Dec 20 07:42:03 2002
Subject: [R] Getting graphs into LaTeX
References: <3F44C651.3060006@arcriswell.com>
Message-ID: <00a301c2a7f2$c663d1f0$df2558db@kwan022>

Hi,

----- Original Message -----
From: "Andrew Criswell" <arc at arcriswell.com>
To: "r-help" <r-help at stat.math.ethz.ch>
Sent: Friday, August 22, 2003 2:17 AM
Subject: [R] Getting graphs into LaTeX


> Hello ALL:
>
> I ran with success the following commands in R getting a file saved
> --------------------------------------------------------------------------
----------
> postscript()
>
> postscript('~/data/st202/2003/lecture00/lecture00-graph-01.eps',
>            horizontal = FALSE, height = 6, pointsize = 10)
>
> hist(trial.outcome.5, breaks = 5,
>      main = '1000 Replications of 5 Trials of a Coin Toss',
>      xlab = 'Frequency of a Tail')
> --------------------------------------------------------------------------
----------


Have you closed the postscript device?  Normally you need a dev.off() after
you finished the plot.  Try putting dev.off() after your hist().

The other thing is can you actually view "lecture00-graph-01.eps" in the
directory, with a postscript Viewer?

The last point, I think pdflatex (or pdftex) does not accept PS/EPS
formatted picture.  Can you latex trix.tex?  If so, try to save your
histogram as a PDF or PNG file, then pdflatex it again.

Cheers,

Kevin

------------------------------------------------
Ko-Kang Kevin Wang
Master of Science (MSc) Student
Department of Statistics
University of Auckland
New Zealand
www.stat.auckland.ac.nz/~kwan022



********************************************



From sarthur67 at yahoo.com  Fri Dec 20 07:53:03 2002
From: sarthur67 at yahoo.com (Stephen Arthur)
Date: Fri Dec 20 07:53:03 2002
Subject: [R] read.ssd {foreign} (Reading a permanent SAS dataset into an R data frame)
Message-ID: <20021220030708.88827.qmail@web11101.mail.yahoo.com>

I just downloaded and installed R 1.6.1 on my Windows
machine where I also run SAS.

I want to use the 'read.ssd' function so that I can
convert a permanent SAS data set into an R data frame.

I downloaded and installed the package 'foreign' on my
machine, which includes the 'read.ssd' function.

I read the instructions, and followed the example
closely in the R documentation.

C:\Program
Files\R\rw1061\library\foreign\html\read.ssd.html

When I run the first R command, in the example, on my
SAS library:

> list.files("C:\\My Documents\\SAS_Data_Sets")

I get the correct output.

When I run the second R command, in the example, 

> read.ssd("C:\\My Documents\\SAS_Data_Sets","use")

I get the following message,

'Error: couldn't find function "read.ssd"'

Why is R saying it can not find the function
'read.ssd' when I downloaded it and I see it in my
file system?

Thanks for your help,

Stephen



From rossini at blindglobe.net  Fri Dec 20 07:59:03 2002
From: rossini at blindglobe.net (A.J. Rossini)
Date: Fri Dec 20 07:59:03 2002
Subject: [R] Getting graphs into LaTeX
In-Reply-To: <3F44C651.3060006@arcriswell.com> (Andrew Criswell's message of
 "Thu, 21 Aug 2003 20:17:05 +0700")
References: <3F44C651.3060006@arcriswell.com>
Message-ID: <87bs3hfaen.fsf@jeeves.blindglobe.net>

pdflatex needs pdf,jpg, or other formats -- it can't handle eps.

best,
-tony

>>>>> "andrew" == Andrew Criswell <arc at arcriswell.com> writes:

    andrew> Hello ALL:
    andrew> I ran with success the following commands in R getting a file saved
    andrew> ------------------------------------------------------------------------------------
    andrew> postscript()

    andrew> postscript('~/data/st202/2003/lecture00/lecture00-graph-01.eps',
    andrew>            horizontal = FALSE, height = 6, pointsize = 10)

    andrew> hist(trial.outcome.5, breaks = 5,
    andrew>      main = '1000 Replications of 5 Trials of a Coin Toss',
    andrew>      xlab = 'Frequency of a Tail')
    andrew> ------------------------------------------------------------------------------------
    andrew> But when I try to include it within a LaTeX document, I get the
    andrew> following complaint.

    andrew> LaTeX document (trix.tex):
    andrew> ------------------------------------------------------------------------------------
    andrew> \documentclass[11pt]{article}
    andrew> \usepackage[pdftex]{graphicx,color}
    andrew> \begin{document}
    andrew> \includegraphics{lecture00-graph-01.eps}
    andrew> \end{document}
    andrew> ------------------------------------------------------------------------------------
    andrew> Which I try to compile with the command:  pdflatex trix.tex

    andrew> But then, I get this error:
    andrew> ------------------------------------------------------------------------------------
    andrew> ! LaTeX Error: Unknown graphics extension: .eps.

    andrew> See the LaTeX manual or LaTeX Companion for explanation.
    andrew> Type  H <return>  for immediate help.
    andrew>  ...

    andrew> l.5 \includegraphics{lecture00-graph-01.eps}

    andrew> ?
    andrew> ------------------------------------------------------------------------------------
    andrew> Any suggestions?

    andrew> Thanks,
    andrew> ANDREW

    andrew> ______________________________________________
    andrew> R-help at stat.math.ethz.ch mailing list
    andrew> http://www.stat.math.ethz.ch/mailman/listinfo/r-help


-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)



From Alexander.Herr at csiro.au  Fri Dec 20 08:34:28 2002
From: Alexander.Herr at csiro.au (Alexander.Herr@csiro.au)
Date: Fri Dec 20 08:34:28 2002
Subject: [R] stack on factors
Message-ID: <2FE6D3D02CCDD211B80600902745F56C018D11F6@exchange-tv.tvl.qld.csiro.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021220/e5154c04/attachment.pl

From ripley at stats.ox.ac.uk  Fri Dec 20 08:44:04 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Dec 20 08:44:04 2002
Subject: [R] More on scan()
In-Reply-To: <OF0D85D847.5A03E963-ON86256C94.007934C6@mmm.com>
Message-ID: <Pine.LNX.4.31.0212200741210.5916-100000@gannet.stats>

On Thu, 19 Dec 2002 apjaworski at mmm.com wrote:

> Here is one way of doing this.
> (1) read the whole file in as a vector of strings one line at a time
>       x <- readLines("<path to your data file>")
> (2) find the position of the "@DATA" string in your vector
>       s <- which(x == "@DATA")
> (3) scan the file again skipping s lines
>       scan("<path to your data file>", skip=s, sep=",", ...)

Or use a file connection and read one line at a time until you find @DATA,
then call skip on the connection.  That's the sort of thing connections
were intended for.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Dec 20 08:53:06 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Dec 20 08:53:06 2002
Subject: [R] Getting graphs into LaTeX
In-Reply-To: <87bs3hfaen.fsf@jeeves.blindglobe.net>
Message-ID: <Pine.LNX.4.31.0212200748330.5934-100000@gannet.stats>

On Thu, 19 Dec 2002, A.J. Rossini wrote:

> pdflatex needs pdf,jpg, or other formats -- it can't handle eps.

pdf or png these days I believe.  (There was tiff and jpg support once,
but tiff has definitely gone.)

R does have a pdf() device (and I wonder who wanted to include graphs in
pdftex documents?).  Otherwise eps can be converted to pdf by the script
epstopdf (which calls distiller or gs) which has an executable version on
Windows, epstopdf.exe.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Dec 20 08:58:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Dec 20 08:58:03 2002
Subject: [R] read.ssd {foreign} (Reading a permanent SAS dataset into an
 R data frame)
In-Reply-To: <20021220030708.88827.qmail@web11101.mail.yahoo.com>
Message-ID: <Pine.LNX.4.31.0212200754030.5934-100000@gannet.stats>

On Thu, 19 Dec 2002, Stephen Arthur wrote:

> I just downloaded and installed R 1.6.1 on my Windows
> machine where I also run SAS.
>
> I want to use the 'read.ssd' function so that I can
> convert a permanent SAS data set into an R data frame.
>
> I downloaded and installed the package 'foreign' on my
> machine, which includes the 'read.ssd' function.
>
> I read the instructions, and followed the example
> closely in the R documentation.
>
> C:\Program
> Files\R\rw1061\library\foreign\html\read.ssd.html
>
> When I run the first R command, in the example, on my
> SAS library:
>
> > list.files("C:\\My Documents\\SAS_Data_Sets")
>
> I get the correct output.
>
> When I run the second R command, in the example,
>
> > read.ssd("C:\\My Documents\\SAS_Data_Sets","use")
>
> I get the following message,
>
> 'Error: couldn't find function "read.ssd"'
>
> Why is R saying it can not find the function
> 'read.ssd' when I downloaded it and I see it in my
> file system?

1) Foreign shipped with R 1.6.1 for Windows, so you did not need to
download it.

2) To use a package you need to use e.g.

library(foreign)

When you have time, please do read `An Introduction to R'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jmiyamot at u.washington.edu  Fri Dec 20 09:17:03 2002
From: jmiyamot at u.washington.edu (John Miyamoto)
Date: Fri Dec 20 09:17:03 2002
Subject: [R] vectorizing test for equality
Message-ID: <Pine.A41.4.44.0212192353240.12680-100000@mead5.u.washington.edu>

Dear R Help,
   I am trying to create a boolean vector that is TRUE whenever a
particular value occurs in a numeric vector, and FALSE otherwise.  For
example, suppose that

> y <- c(5, 2, 4, 3, 1)
> y
[1] 5 2 4 3 1

and suppose that I want to find where 3 occurs in y.  Then, the following
yields the solution:

> y == 3
[1] FALSE FALSE FALSE  TRUE FALSE

My problem arises when the numeric vector has missing values.  For
example, suppose that x is the vector

> x <- c( 2, NA, 1, 5, 3)
> x
[1]  2 NA  1  5  3

Now x == 5 yields

> x == 5
[1] FALSE    NA FALSE  TRUE FALSE

whereas what I want is

FALSE  FALSE  FALSE  TRUE  FALSE

I can solve this problem with a for loop:

> flag <- NULL
> for (i in 1:length(x)) flag <- c(flag, identical(x[i], 5))
> flag
[1] FALSE FALSE FALSE  TRUE FALSE

Is there a way to avoid the for loop?  I'm also curious why the following
does not work, because it seems to me it should:

> test <- function(x) identical(x[1], x[2])
> apply(cbind(x, 5), 1, test)
[1] FALSE FALSE FALSE FALSE FALSE

I was expecting to see FALSE FALSE FALSE TRUE FALSE.

John Miyamoto

--------------------------------------------------------------------
John Miyamoto, Dept. of Psychology, Box 351525
University of Washington, Seattle, WA 98195-1525
Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
Homepage http://faculty.washington.edu/jmiyamot/
--------------------------------------------------------------------



From ripley at stats.ox.ac.uk  Fri Dec 20 09:30:04 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Dec 20 09:30:04 2002
Subject: [R] vectorizing test for equality
In-Reply-To: <Pine.A41.4.44.0212192353240.12680-100000@mead5.u.washington.edu>
Message-ID: <Pine.LNX.4.31.0212200827250.6123-100000@gannet.stats>

> x <- c( 2, NA, 1, 5, 3)
> x %in% 5
[1] FALSE FALSE FALSE  TRUE FALSE

Knowledge like this is covered in chapter 2 of MASS4 (Venables & Ripley,
2002).

Note that your subject is misleading:  == does test for equality, but that
is not what you actually wanted.

On Fri, 20 Dec 2002, John Miyamoto wrote:

> Dear R Help,
>    I am trying to create a boolean vector that is TRUE whenever a
> particular value occurs in a numeric vector, and FALSE otherwise.  For
> example, suppose that
>
> > y <- c(5, 2, 4, 3, 1)
> > y
> [1] 5 2 4 3 1
>
> and suppose that I want to find where 3 occurs in y.  Then, the following
> yields the solution:
>
> > y == 3
> [1] FALSE FALSE FALSE  TRUE FALSE
>
> My problem arises when the numeric vector has missing values.  For
> example, suppose that x is the vector
>
> > x <- c( 2, NA, 1, 5, 3)
> > x
> [1]  2 NA  1  5  3
>
> Now x == 5 yields
>
> > x == 5
> [1] FALSE    NA FALSE  TRUE FALSE
>
> whereas what I want is
>
> FALSE  FALSE  FALSE  TRUE  FALSE
>
> I can solve this problem with a for loop:
>
> > flag <- NULL
> > for (i in 1:length(x)) flag <- c(flag, identical(x[i], 5))
> > flag
> [1] FALSE FALSE FALSE  TRUE FALSE
>
> Is there a way to avoid the for loop?  I'm also curious why the following
> does not work, because it seems to me it should:
>
> > test <- function(x) identical(x[1], x[2])
> > apply(cbind(x, 5), 1, test)
> [1] FALSE FALSE FALSE FALSE FALSE
>
> I was expecting to see FALSE FALSE FALSE TRUE FALSE.
>
> John Miyamoto
>
> --------------------------------------------------------------------
> John Miyamoto, Dept. of Psychology, Box 351525
> University of Washington, Seattle, WA 98195-1525
> Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
> Homepage http://faculty.washington.edu/jmiyamot/
> --------------------------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From lecoutre at stat.ucl.ac.be  Fri Dec 20 09:35:03 2002
From: lecoutre at stat.ucl.ac.be (Eric Lecoutre)
Date: Fri Dec 20 09:35:03 2002
Subject: [R] vectorizing test for equality
In-Reply-To: <Pine.A41.4.44.0212192353240.12680-100000@mead5.u.washingto
 n.edu>
Message-ID: <5.1.1.5.2.20021220093059.00ccc488@stat4ux.stat.ucl.ac.be>

Take a look at 'any', which allows to remove missing values before test:

any(y==3, na.rm=TRUE)

If your vector does not contain integers, dont forget to change 'y==3' test 
by something more appropriate. (begin to round with a fixed number of dec. 
for exemple).

Eric

At 00:15 20/12/2002 -0800, you wrote:
>Dear R Help,
>    I am trying to create a boolean vector that is TRUE whenever a
>particular value occurs in a numeric vector, and FALSE otherwise.  For
>example, suppose that
>
> > y <- c(5, 2, 4, 3, 1)
> > y
>[1] 5 2 4 3 1
>
>and suppose that I want to find where 3 occurs in y.  Then, the following
>yields the solution:
>
> > y == 3
>[1] FALSE FALSE FALSE  TRUE FALSE
>
>My problem arises when the numeric vector has missing values.  For
>example, suppose that x is the vector
>
> > x <- c( 2, NA, 1, 5, 3)
> > x
>[1]  2 NA  1  5  3
>
>Now x == 5 yields
>
> > x == 5
>[1] FALSE    NA FALSE  TRUE FALSE
>
>whereas what I want is
>
>FALSE  FALSE  FALSE  TRUE  FALSE
>
>I can solve this problem with a for loop:
>
> > flag <- NULL
> > for (i in 1:length(x)) flag <- c(flag, identical(x[i], 5))
> > flag
>[1] FALSE FALSE FALSE  TRUE FALSE
>
>Is there a way to avoid the for loop?  I'm also curious why the following
>does not work, because it seems to me it should:
>
> > test <- function(x) identical(x[1], x[2])
> > apply(cbind(x, 5), 1, test)
>[1] FALSE FALSE FALSE FALSE FALSE
>
>I was expecting to see FALSE FALSE FALSE TRUE FALSE.
>
>John Miyamoto
>
>--------------------------------------------------------------------
>John Miyamoto, Dept. of Psychology, Box 351525
>University of Washington, Seattle, WA 98195-1525
>Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
>Homepage http://faculty.washington.edu/jmiyamot/
>--------------------------------------------------------------------
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>http://www.stat.math.ethz.ch/mailman/listinfo/r-help


__________________________________________________

Eric Lecoutre           Informaticien/Statisticien
Institut de Statistique                        UCL

                               (+32) (0)10 47 30 50
                            lecoutre at stat.ucl.ac.be
     http://www.stat.ucl.ac.be/ISpersonnel/lecoutre
__________________________________________________
Le vrai danger, ce n'est pas quand les ordinateurs
penseront comme des hommes, c'est quand les hommes
penseront comme des ordinateurs.     Sydney Harris



From lunneborg at attbi.com  Fri Dec 20 10:30:04 2002
From: lunneborg at attbi.com (Cliff Lunneborg)
Date: Fri Dec 20 10:30:04 2002
Subject: RE [R] workspace vs. image
Message-ID: <002001c2a80a$4c9d1ee0$38297cd9@stat.washington.edu>

As an alternative to the use of multiple shortcus to gain entry to different
R environments on WIndows platforms I would like to suggest the use of two R
functions written by my colleague John Miyamoto. I have taken the liberty of
attaching their definitions to this message. Their efficient use is based on
adopting the following regimen or something like it: (1) at startup attach
an .Rdata workspace containing the two functions, say to position 2. This I
do in my etc/Rprofile file. (2) then attach one or more .Rdata workspaces to
additional positions in the search path. These contain data and/or
user-defined functions relevant to the current problem. Position 1 of the
search, .GlobalEnv is then used only for sctratchwork.

move(obj,pos=3) moves obj from .GlobalEnv to the environent of position 3,
saves that environment to the associated .Rdata file, and removes obj from
.GlobalEnv.

rm.sv(obj,pos=3) removes obj from the environment at position 3 and then
saves the remaining objects to the associated .Rdata file.

The use of the two keeps the .Rdata files updated.

##Here is the first function

move<-
function(x, pos=NA, dir="c:/directory name/file name", replace=F)  {
    if (is.na(pos)) dirL _ paste("file:", dir, sep="") else dirL _
search()[pos]
    if (mode(x) != "character")  name _ deparse(substitute(x)) else name _ x
# Assign the correct number to tmpos = pos, if it is not already assigned.
    if (is.na(pos)) {
        tmp _ search() == dirL
        if (sum(tmp) < 1) stop(message=paste(dir, "not in search path."))
        if (sum(tmp) > 1)  {
            cat("There is more than one directory named",
                dir, "in the search path.\n",
                "Set the destination with the pos argument.\n")
            stop(message = "Execution of move terminated.")
            } #end of if (sum(tmp) > 1)
        tmpos _ (1:length(search()))[tmp]
        }   else tmpos _ pos        #End of if (is.na(pos))
# Assign the correct directory name to dirN if it is not already assigned.
    tms _ search()[tmpos]
    dirN _ substring(tms, 6, nchar(tms))
#--------------------------------------------------
# The next if carries out the move, if this is possible.
    e.test _ NULL;  for (i in 1:length(name))
        e.test _ c(e.test, !exists(name[i], env=pos.to.env(tmpos)) )
    if ( all(e.test) | replace)   {
        for (i in 1:length(name)) assign(name[i], get(name[i],
envir=.GlobalEnv),
            pos=tmpos)
        save(list=objects(pos=tmpos, all=T), file=dirN )
        rm(list=name, envir=.GlobalEnv)
        }   else    {   #end if, start else
#--------------------------------------------------
# The next code gives warning messages if the move could not be carried out.
# Case I: The target directory was specified by dir.
        if (is.na(pos)) {
        cat("\n No movement of object was carried out!\n Object(s) ",
        name[!e.test], " exists in ", dir,".\n\n",
        'Add "replace=T" to the move command in order to replace',
        name[!e.test],"\nin", dir,".\n\n") } else
        {
# Case II: The target directory was specified by pos.
        cat("\n No movement of object was carried out!\n Object(s) ",
        name[!e.test], " exists in pos =", pos,".\n\n",
        'Add "replace=T" to the move command in order to replace',
        name[!e.test],"\nin pos =", pos,".\n\n") }
    } #end of case where object exists in destination directory
} #end of function
definition --------------------------------------------------

# and here is the second function:

rm.sv<-
function(x, pos=NA, dir="e:/r/jmm/jmfuns.rda")  {
    if (is.na(pos)) dirL _ paste("file:", dir, sep="") else dirL _
search()[pos]
    if (mode(x) != "character")  name _ deparse(substitute(x)) else name _ x
# Assign the correct number to tmpos = pos, if it is not already assigned.
    if (is.na(pos)) {
        tmp _ search() == dirL
        if (sum(tmp) < 1) stop(message=paste(dir, "not in search path."))
        if (sum(tmp) > 1)  {
            cat("There is more than one directory named",
                dir, "in the search path.\n",
                "Set the destination with the pos argument.\n")
            stop(message = "Execution of move terminated.")
            } #end of if (sum(tmp) > 1)
        tmpos _ (1:length(search()))[tmp]
        }   else tmpos _ pos        #End of if (is.na(pos))
# Assign the correct directory name to dirN if it is not already assigned.
    tms _ search()[tmpos]
    dirN _ substring(tms, 6, nchar(tms))
#--------------------------------------------------
# The next if carries out the deletion, if this is possible.
    e.test _ NULL;  for (i in 1:length(name))
        e.test _ c(e.test, exists(name[i], env=pos.to.env(tmpos)) )
    if ( all(e.test) )
        {
        rm(list=name, pos=tmpos)
        save(list=objects(pos=tmpos, all=T), file=dirN)
        cat(paste("Deletion completed.  Current objects in",
            dirN, "are:\n") )
        print(objects(pos=tmpos, all=T))
        }   else    {   #end if, start else
#--------------------------------------------------
# The next code gives warning messages if the object does not exist in the
target directory.
# Case I: The target directory was specified by dir.
        if (is.na(pos)) {
        cat("\n No deletion of object was carried out!\n Object ",
        name[!e.test], " does not exist in ", dir,".\n\n") } else
        {
# Case II: The target directory was specified by pos.
        cat("\n No deletion of object was carried out!\n Object ",
        name[!e.test], " does not exist in pos =", pos,".\n\n") }
    } #end of case where object does not exist in target directory
} #end of function
definition --------------------------------------------------



**********************************************************
Cliff and/or Pat Lunneborg
Temporarily in Salobrena
Costa Granada, ESPANA
Nov 2002 thru Jan 2003

cliff at ms.washington.edu
or
lunneborg at attbi.com



From Ted.Harding at nessie.mcc.ac.uk  Fri Dec 20 11:19:02 2002
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri Dec 20 11:19:02 2002
Subject: [R] Printing correlation matrices (lm/glm)
In-Reply-To: <51F9C42DA15CD311BD220008C707D81906FFC9F8@usrymx10.merck.com>
Message-ID: <XFMail.021220095234.Ted.Harding@nessie.mcc.ac.uk>

Hi Andy!
Thanks for the reply. It gives the clue: in fact it should be

  print(summary(lm2, corr=TRUE), symbolic.cor=FALSE)

(not "symbolic.corr"). However, this raises a further mystery!

I had spent ages with "?" and "help.search" (e.g. "summary.lm",
"summaru.glm", "summary", "print", "symbolic", "corr" ... ) trying
to find something relevant, with no success. Following your mail, I
grepped right down /usr/lib/R, first for "symbolic.corr" (with no
success) and then for "symbolic", and finally found "symbolic.cor"
in a help file for "lm.summary" in package "base" (Also "glm.summary").

Now: "?lm.summary" fails to find anything, likewise "?glm.summary",
nor does "help.search("lm.summary")".

So I'm wondering what is going wrong here: Using R-1.6.1 of Nov 2002,
version for Red Hat 7.2 installed from the RPM package.

Thanks,
Ted.

On 20-Dec-02 Liaw, Andy wrote:
> Try print(summary(lm2, corr=TRUE), symbolic.corr=FALSE).  It *is* in
> the
> help page.
> 
> HTH,
> Andy
> 
>> From: Ted.Harding at nessie.mcc.ac.uk 
>> Subject: [R] Printing correlation matrices (lm/glm)
>> 
>> Hi Folks,
>> 
>> I'm analysing some data which, in its simplest aspect,
>> has 3 factors A, B, C each at 2 levels.
>> 
>> If I do
>> 
>>   lm1 <- lm(y ~ A*B)
>> 
>> say, and then
>> 
>>   summary(lm1, corr=T)
>> 
>> I get the correlation matrix of the estimated coeffcients
>> with numerical values for the correlations (3 coeffs in this
>> case). Likewise with 'glm' instead of 'lm'.
>> 
>> However, if I do
>> 
>>   lm2 <- lm(y ~ A*B*C)
>> 
>> and then
>> 
>>   summary(lm2, corr=T)
>> 
>> I get only symbols (such as ".", "+", "*") for the values,
>> denoting ranges, and not numbers (7 coefficients in this case).
>> 
>> Presumably this happens when the number of columns is considered
>> to be getting a bit large for numbers -- though 7 is not huge ...
>> 
>> Anyway, is there any way I can get the full correlation matrix
>> out with numbers instead of symbols, even with several coefficients?
>> 
>> With thanks,
>> Ted.
> 
> ------------------------------------------------------------------------
> ------
> Notice: This e-mail message, together with any attachments, contains
> information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA)
> that may be confidential, proprietary copyrighted and/or legally
> privileged, and is intended solely for the use of the individual or
> entity named on this message.  If you are not the intended recipient,
> and have received this message in error, please immediately return this
> by e-mail and then delete it.
> 
> ========================================================================
> ======

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 20-Dec-02                                       Time: 09:52:34
------------------------------ XFMail ------------------------------



From Friedrich.Leisch at univie.ac.at  Fri Dec 20 11:48:07 2002
From: Friedrich.Leisch at univie.ac.at (Friedrich.Leisch@univie.ac.at)
Date: Fri Dec 20 11:48:07 2002
Subject: [R] R News Volume 2/3
Message-ID: <15874.62769.631269.707935@ci.tuwien.ac.at>

Just in time to provide you with reading material for the holidays we
have published the 2002/3 issue of R News on

        http://cran.R-project.org/doc/Rnews

where you can download the newsletter as PDF or Postscript file. It
will propagate to the CRAN mirrors within a day or two.

This issue starts a new regular column, the "R Help Desk" edited by
Uwe Ligges. umn, with an article on "Automation of Mathematical
Annotation in Plots". Angelo Canty continues the series on primers for
recommended packages with "Resampling Methods in R: The boot
Package". project on "gRaphical Modeling in R". And of course, there
is much more ...

Contents of this issue:

Resampling Methods in R: The boot Package
Diagnostic Checking in Regression Relationships
Delayed Data Packages
geepack: Yet Another Package for Generalized Estimating Equations
On Multiple Comparisons in R
Classification and Regression by randomForest
Some Strategies for Dealing with Genomic Data
Changes to the R-Tcl/Tk package
Sweave, Part I: Mixing R and LATEX
R Help Desk
Changes in R
Changes on CRAN
New Publications
gRaphical Models in R
Recent and Upcoming Events


For the editorial board,
Fritz Leisch

PS: All the best for 2003!

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                      Tel: (+43 1) 4277 38613
Universit?t Wien  		            Fax: (+43 1) 4277 38639
Universit?tsstra?e 5                  Friedrich.Leisch at univie.ac.at
A-1010 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch
-------------------------------------------------------------------



From Ted.Harding at nessie.mcc.ac.uk  Fri Dec 20 12:13:03 2002
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri Dec 20 12:13:03 2002
Subject: [R] Printing correlation matrices (lm/glm)
In-Reply-To: <XFMail.021220095234.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <XFMail.021220110508.Ted.Harding@nessie.mcc.ac.uk>

On 20-Dec-02 Ted Harding wrote:
> I had spent ages with "?" and "help.search" (e.g. "summary.lm",
> "summaru.glm", "summary", "print", "symbolic", "corr" ... ) trying
> to find something relevant, with no success. Following your mail, I
> grepped right down /usr/lib/R, first for "symbolic.corr" (with no
> success) and then for "symbolic", and finally found "symbolic.cor"
> in a help file for "lm.summary" in package "base" (Also "glm.summary").
> 
> On 20-Dec-02 Liaw, Andy wrote:
>> Try print(summary(lm2, corr=TRUE), symbolic.corr=FALSE).  It *is* in
>> the help page.

I've found something now!

In fact "methods(print)" lists, inter alia, "print.lm", and "?print.lm"
shows it in the "Usage" section as an item in a parameter list:

     print(summary.lm.obj, digits = max(3, getOption("digits") - 3),
           symbolic.cor = p > 4,
           signif.stars= getOption("show.signif.stars"), ...)

However, the parameter "symbolic.cor" is not mentioned anywhere else
in the rest of the help page, which is why I missed it!

(This is not the first time I've wished it were easier to track down
the detail you're looking for in R help, though this seems to have
been a particularly tough nut).

Best wishes to all,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 20-Dec-02                                       Time: 11:05:08
------------------------------ XFMail ------------------------------



From el at ac.lisse.na  Fri Dec 20 12:46:09 2002
From: el at ac.lisse.na (Dr Eberhard W. Lisse)
Date: Fri Dec 20 12:46:09 2002
Subject: [R] Re: R News Volume 2/3
In-Reply-To: Your message of "Fri, 20 Dec 2002 11:47:13 BST."
             <15874.62769.631269.707935@ci.tuwien.ac.at> 
Message-ID: <20021220114332.EC7B669C9C@ac.lisse.na>

In message <15874.62769.631269.707935 at ci.tuwien.ac.at>, Friedrich.Leisch at univie
.ac.at writes:
> 
> Just in time to provide you with reading material for the holidays we
> have published the 2002/3 issue of R News on
> 
>         http://cran.R-project.org/doc/Rnews

Friedrich,

would it perhaps be possible to post the complete URL on he mirrors? 
SO we can just click the sucker?

el



From jmiyamot at u.washington.edu  Fri Dec 20 12:54:11 2002
From: jmiyamot at u.washington.edu (John Miyamoto)
Date: Fri Dec 20 12:54:11 2002
Subject: [R] Summary: vectorizing test for equality
Message-ID: <Pine.A41.4.44.0212200343410.12680-100000@mead5.u.washington.edu>

Thanks for many prompt and useful comments.  The question was:  if x is
the vector

> x <- c( 2, NA, 1, 5, 3)
> x
[1]  2 NA  1  5  3

Then x == 5 yields

> x == 5
[1] FALSE    NA FALSE  TRUE FALSE

whereas what I want is

FALSE  FALSE  FALSE  TRUE  FALSE
#--------------
Matthew Dowle sent a simple solution:

> x
[1]  2 NA  1  5  3
> x==5 & !is.na(x)
[1] FALSE FALSE FALSE  TRUE FALSE

Thanks also to Brian Ripley who suggested that I look at chapter 2 of
MASS4, and Eric Lecoutre who pointed out that the 'which' function could
be useful for this problem.

John Miyamoto


--------------------------------------------------------------------
John Miyamoto, Dept. of Psychology, Box 351525
University of Washington, Seattle, WA 98195-1525
Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
Homepage http://faculty.washington.edu/jmiyamot/
--------------------------------------------------------------------



From ben at zoo.ufl.edu  Fri Dec 20 13:13:02 2002
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Fri Dec 20 13:13:02 2002
Subject: [R] Help on R commands
In-Reply-To: <122.1c2903c1.2b325a67@aol.com>
Message-ID: <Pine.LNX.4.44.0212200703410.19714-100000@bolker.zoo.ufl.edu>

  You're not too far off.
  You need to do something like

objfun <- function(p) {
  mu <- p[1]
  sigma <- p[2]
  -sum(dnorm(x,mean=mu,sd=sigma,log=TRUE))
}

optim(par=c(0,1),fn=objfun)  # check ?optim for correct argument names

Some points:
  - the main thing is that you have to define mu and sigma within your 
objective function
  - you're better off with the log-likelihood than the likelihood; by 
convention people usually try to minimize the negative log-likelihood 
rather than maximizing the likelihood
  - "nlmin" is an S-PLUS function.  The analogues in R are nlm and optim.
  - your setting negative values to zero complicates your problem 
considerably.  Can you use a gamma model instead?
  - the ML estimate of normal data (given that you haven't messed with 
negative values) is mu=mean(x), sd=sd(x)*sqrt(length(x)/(length(x)-1)) = 
sqrt(mean((x-mean(x))^2)) 

  A lot of these questions are pretty basic; you really need to try to get
some help off-list.  You may not get too much more help here unless you
explain what your situation is (are you doing this for a class,
independent project, etc.) and give some indication that you've exhausted
local resources ...

 cheers,
  Ben Bolker

On Wed, 18 Dec 2002 Jameshutton25 at aol.com wrote:

> Dear mailing list,
> 
> I desperately need help on making a small program that is trying to find the 
> likelihood of a distribution. Anyone that has any ideas please feel free to 
> suggest them.
> 
> Ok this is what I have done so far:
> 
> I wanted 20 random numbers that were normally distributed, and I did this by 
> typing x<-rnorm(20).
>  I then wanted to change any negative values in the data set to zero and I 
> did this by x[x<0]<-0.
> These numbers have come from the normal density 
> 1/sigma(2pi)1/2exp-{(x-mew)2/2sigma2}, what I want to do now and having 
> trouble with is that for each of these results (which can be substituted back 
> into the x in the eqation above) is to multiply all 20 results (in the above 
> equation form) together to form the likelihood. However the critical problem 
> that I am experiencing is that for each case I do not know the mew and sigma 
> eventhough that i know tthe x value. The reason why i dont know the vales of 
> sigma and mew is because after I have formed the program i want to use nlmin( 
>   ,   ) to basically maximse the the likelihood so i find the values for mew 
> and sigma, this is what i am aiming finally to do.
> My pathetic effort so far is:  
>                                                  
> prod(dnorm(x,mean=mu,sd=sigma)
> 
> However I know that this doesn't incorporate the fact that mew and sigma are 
> not known as when i input this it says that mu is not recognised but I dont 
> know how to make mu and sigma different to each other.
> 
> If anyone has any ideas please feel free to suggest them as I will basically 
> try anything.
> 
> Yours Faithfully,
> 
> James Hutton
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From R.eschen at cabi-bioscience.ch  Fri Dec 20 13:18:02 2002
From: R.eschen at cabi-bioscience.ch (Rene Eschen)
Date: Fri Dec 20 13:18:02 2002
Subject: [R] Cross-correlograms or cross-variograms in R?
Message-ID: <D173FA00F56FD21184C300104BB732571C27A5@DELEMONT_SRVR>


> The library "spatial" included as a default library in the base package
could help you.
I did find the option to calculate correlograms and variograms, but not
_cross_variograms and _cross_correlograms. Are those in this package and if
so, what is the command?
Regards,

Ren? Eschen.



> For my PhD I'm working on a spatial sampling grid. I do have two data sets
which I'd like to compare using cross-correlograms or cross-variograms.
> 
> Is this an option in one of the R-packages? I've been searching the R-help
archive and the available package-documentations, but I can't find how to do
this.
_______________________________________

Ren? Eschen
CABI Bioscience Switzerland Centre
1 Rue des Grillons
CH-2800 Del?mont
Switzerland
+41 32 421 48 87 (Direct)
+41 32 421 48 70 (Secretary)
+41 32 421 48 71 (Fax)
r.eschen at cabi-bioscience.ch



From jniesch at gwdg.de  Fri Dec 20 13:54:02 2002
From: jniesch at gwdg.de (Jens Nieschulze)
Date: Fri Dec 20 13:54:02 2002
Subject: [R] Cross-correlograms or cross-variograms in R?
In-Reply-To: <D173FA00F56FD21184C300104BB732571C27A5@DELEMONT_SRVR>
Message-ID: <Pine.SO4.4.10.10212201351560.16174-100000@ufobi7.uni-forst.gwdg.de>

On Fri, 20 Dec 2002, Rene Eschen wrote:

%
%
%> The library "spatial" included as a default library in the base package
%could help you.
%I did find the option to calculate correlograms and variograms, but not
%_cross_variograms and _cross_correlograms. Are those in this package and if
%so, what is the command?
don't know about spatial but
est.variogram{sgeostat}
specifiy variable a1 AND a2
may help you

	JN
%Regards,
%
%Ren Eschen.
%
%
%
%> For my PhD I'm working on a spatial sampling grid. I do have two data sets
%which I'd like to compare using cross-correlograms or cross-variograms.
%> 
%> Is this an option in one of the R-packages? I've been searching the R-help
%archive and the available package-documentations, but I can't find how to do
%this.
%_______________________________________
%
%Ren Eschen
%CABI Bioscience Switzerland Centre
%1 Rue des Grillons
%CH-2800 Delmont
%Switzerland
%+41 32 421 48 87 (Direct)
%+41 32 421 48 70 (Secretary)
%+41 32 421 48 71 (Fax)
%r.eschen at cabi-bioscience.ch
%
%______________________________________________
%R-help at stat.math.ethz.ch mailing list
%http://www.stat.math.ethz.ch/mailman/listinfo/r-help
%

***********************************************************************
Jens Nieschulze

Institute for Forest Biometrics &	Phone: ++49-551-39-12107
Applied Computer Science		Fax  : ++49-551-39-3465
Buesgenweg 4
37077 Goettingen		E-mail: jniesch at uni-forst.gwdg.de
GERMANY				http://www.uni-forst.gwdg.de/~jniesch



From apollo_w at yahoo.com  Fri Dec 20 14:35:03 2002
From: apollo_w at yahoo.com (apollo wong)
Date: Fri Dec 20 14:35:03 2002
Subject: [R] n-dim quasi random number generator
Message-ID: <20021220133426.14209.qmail@web40902.mail.yahoo.com>

Hi,
 Does anyone know that if there is R-code available
for a n-dim quasi random number generator, n>500.
 Thanks.
Apollo Wong



From apollo_w at yahoo.com  Fri Dec 20 14:40:04 2002
From: apollo_w at yahoo.com (apollo wong)
Date: Fri Dec 20 14:40:04 2002
Subject: [R] Memory Leak in 1.6.0
Message-ID: <20021220133327.66474.qmail@web40908.mail.yahoo.com>

Thanks Folks, the 1.6.1 did fix this problem



From malewski.peter at mh-hannover.de  Fri Dec 20 16:03:02 2002
From: malewski.peter at mh-hannover.de (Peter Malewski)
Date: Fri Dec 20 16:03:02 2002
Subject: [R] Getting graphs into LaTeX
In-Reply-To: <3F44C651.3060006@arcriswell.com>; from arc@arcriswell.com on Thu, Aug 21, 2003 at 08:17:05PM +0700
References: <3F44C651.3060006@arcriswell.com>
Message-ID: <20021220160141.A5426@rzsrv2.rz.tu-bs.de>

On Thu, Aug 21, 2003 at 08:17:05PM +0700, Andrew Criswell wrote:
> Which I try to compile with the command:  pdflatex trix.tex
> 
> But then, I get this error:
> ------------------------------------------------------------------------------------
> ! LaTeX Error: Unknown graphics extension: .eps.


"pdflatex" wants pdf-pics, not eps. If you want to use both, latex &
pdflaex, save one version with pdf(), one version with postscript
and use \includegraphics{~/xx} without ending. pdflatex & latex
will choose the appropiate file. 
pm


-- 
P.Malewski, Limmerstr.47, 30451 Hannover, 0511-2135008
At work: http://www.MH-Hannover.de 0511 532 3194 / Fax: 0511 532 3190, 
P.Malewski at tu-bs.de, peter.malewski at gmx.de, malewski.peter at mh-hannover.de.



From tlumley at u.washington.edu  Fri Dec 20 16:27:02 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri Dec 20 16:27:02 2002
Subject: [R] Printing correlation matrices (lm/glm)
In-Reply-To: <XFMail.021220095234.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.A41.4.44.0212200724550.65692-100000@homer31.u.washington.edu>

On Fri, 20 Dec 2002 Ted.Harding at nessie.mcc.ac.uk wrote:

> Hi Andy!
> Thanks for the reply. It gives the clue: in fact it should be
>
>   print(summary(lm2, corr=TRUE), symbolic.cor=FALSE)
>
> (not "symbolic.corr"). However, this raises a further mystery!
>
> I had spent ages with "?" and "help.search" (e.g. "summary.lm",
> "summaru.glm", "summary", "print", "symbolic", "corr" ... ) trying
> to find something relevant, with no success. Following your mail, I
> grepped right down /usr/lib/R, first for "symbolic.corr" (with no
> success) and then for "symbolic", and finally found "symbolic.cor"
> in a help file for "lm.summary" in package "base" (Also "glm.summary").

I find it in
    help(summary.lm)
and
    help(summary.glm)


	-thomas



From bates at stat.wisc.edu  Fri Dec 20 16:44:03 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri Dec 20 16:44:03 2002
Subject: [R] stack on factors
In-Reply-To: <2FE6D3D02CCDD211B80600902745F56C018D11F6@exchange-tv.tvl.qld.csiro.au>
References: <2FE6D3D02CCDD211B80600902745F56C018D11F6@exchange-tv.tvl.qld.csiro.au>
Message-ID: <6rhed8elvs.fsf@bates5.stat.wisc.edu>

Alexander.Herr at csiro.au writes:

> It seems that stack() does not include factors. Any easy way of "stacking"
> factors in a dataframe without recoding to numbers?

You may want to try reshape(..., direction = 'long') instead of stack.



From bates at stat.wisc.edu  Fri Dec 20 16:54:03 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri Dec 20 16:54:03 2002
Subject: [R] Re: R News Volume 2/3
In-Reply-To: <20021220114332.EC7B669C9C@ac.lisse.na>
References: <20021220114332.EC7B669C9C@ac.lisse.na>
Message-ID: <6rd6nwelgf.fsf@bates5.stat.wisc.edu>

For those who prefer to click their way to RNews, the PDF file is
         http://cran.R-project.org/doc/Rnews/Rnews_2002-3.pdf
and the gzip'd PostScript file is 
        http://cran.R-project.org/doc/Rnews/Rnews_2002-3.ps.gz

In North America please use
       http://cran.us.R-project.org/doc/Rnews/Rnews_2002-3.pdf
or
      http://cran.us.R-project.org/doc/Rnews/Rnews_2002-3.ps.gz



From sarthur67 at yahoo.com  Fri Dec 20 17:26:03 2002
From: sarthur67 at yahoo.com (Stephen Arthur)
Date: Fri Dec 20 17:26:03 2002
Subject: Part II Re: [R] read.ssd {foreign} (Reading a permanent SAS dataset into an R data frame)
In-Reply-To: <Pine.LNX.4.31.0212200754030.5934-100000@gannet.stats>
Message-ID: <20021220155523.92410.qmail@web11102.mail.yahoo.com>

Hello,

I adopted the suggestion to use the R command

> foreign

before the 

>
read.ssd("J:\\QM\\Reports\\Sarthur\\SAS_Application\\SAS_Data_Sets","use")

statement (notice, I am at work now, so the directory
structure changes).  Do I need any of the other
read.ssd parameters to get this statement to work,
because...

... I get the following error message in R: 

"
SAS failed.  SAS program at
C:\TEMP\Rtmp12421\file21582.sas 
a log and other error products should be in the
vicinity
NULL
Warning messages: 
1: sas not found 
2: SAS return code was -1 in:
read.ssd("J:\\QM\\Reports\\Sarthur\\SAS_Application\\SAS_Data_Sets",
 
> 
"

Why am I getting the message "sas not found", when I
have SAS installed on my machine?

I checked the PROC COPY SAS program generated in the
indicated temporary file:

"
libname src2rd
'J:\QM\Reports\Sarthur\SAS_Application\SAS_Data_Sets';
libname rd xport 'C:\TEMP\Rtmp12421\file14817';
proc copy in=src2rd out=rd;
select use ;
"

SAS log

"
NOTE: SAS initialization used:
      real time           4.64 seconds
      cpu time            0.73 seconds
"

Can anyone help me get to the next step of this
process?  I believe I am close to getting R to read
SAS permanent data sets directly, which I would really
like to be able to do.

Thanks,

Stephen



--- ripley at stats.ox.ac.uk wrote:
> On Thu, 19 Dec 2002, Stephen Arthur wrote:
> 
> > I just downloaded and installed R 1.6.1 on my
> Windows
> > machine where I also run SAS.
> >
> > I want to use the 'read.ssd' function so that I
> can
> > convert a permanent SAS data set into an R data
> frame.
> >

> > C:\Program
> > Files\R\rw1061\library\foreign\html\read.ssd.html
> >
> > When I run the first R command, in the example, on
> my
> > SAS library:
> >
> > > list.files("C:\\My Documents\\SAS_Data_Sets")
> >
> > I get the correct output.
> >
> > When I run the second R command, in the example,
> >
> > > read.ssd("C:\\My
> Documents\\SAS_Data_Sets","use")
> >

> 2) To use a package you need to use e.g.
> 
> library(foreign)



From Timur.Elzhov at jinr.ru  Fri Dec 20 17:35:08 2002
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Fri Dec 20 17:35:08 2002
Subject: [R] GetRNGstate() crashes with 'Segmentation fault'
Message-ID: <20021220163433.GA31192@pcf004.jinr.ru>

Dear R-masters,


I tried to compile this simpel C-code:

//-----------------

#include<R.h>

int main()
{
    GetRNGstate();
    return 0;
}
 
//-----------------

Compiling:

~> gcc -o a  a.c -I/usr/lib/R/include/ -L/usr/lib/R/bin/ -lR
~> ldd a
        libR.so => /usr/lib/libR.so (0x40018000)
        libc.so.6 => /lib/libc.so.6 (0x401a8000)
        libblas.so.2 => /usr/lib/libblas.so.2 (0x402bb000)
        libreadline.so.4 => /lib/libreadline.so.4 (0x4031e000)
        libdl.so.2 => /lib/libdl.so.2 (0x40347000)
        libncurses.so.5 => /lib/libncurses.so.5 (0x4034a000)
        libm.so.6 => /lib/libm.so.6 (0x40389000)
        libz.so.1 => /usr/lib/libz.so.1 (0x403ab000)
        /lib/ld-linux.so.2 => /lib/ld-linux.so.2 (0x40000000)

~> ./a
Segmentation fault


Where am I wrong?
I'm using R 1.6.1, glibc-2.3.1 on Debian woody system.

Thanks a lot!

--
WBR,
Timur.



From Bernhard.Pfaff at drkw.com  Fri Dec 20 17:39:19 2002
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Fri Dec 20 17:39:19 2002
Subject: Part II Re: [R] read.ssd {foreign} (Reading a permanent SAS d
    ataset into an R data frame)
Message-ID: 
    <18D602BD42B7E24EB810D6454A58DB9001CAE121@ibfftce505.is.de.dresdnerkb.com>

try:

library(foreign)
read.ssd("J:\\QM\\Reports\\Sarthur\\SAS_Application\\SAS_Data_Sets","use")

instead, hth, Merry Christmas, Bernhard

-----Original Message-----
From: Stephen Arthur [mailto:sarthur67 at yahoo.com]
Sent: 20 December 2002 16:55
To: ripley at stats.ox.ac.uk; rossini at blindglobe.net
Cc: r-help at stat.math.ethz.ch; stvjc at channing.harvard.edu
Subject: Part II Re: [R] read.ssd {foreign} (Reading a permanent SAS
dataset into an R data frame)


Hello,

I adopted the suggestion to use the R command

> foreign

before the 

>
read.ssd("J:\\QM\\Reports\\Sarthur\\SAS_Application\\SAS_Data_Sets","use")

statement (notice, I am at work now, so the directory
structure changes).  Do I need any of the other
read.ssd parameters to get this statement to work,
because...

... I get the following error message in R: 

"
SAS failed.  SAS program at
C:\TEMP\Rtmp12421\file21582.sas 
a log and other error products should be in the
vicinity
NULL
Warning messages: 
1: sas not found 
2: SAS return code was -1 in:
read.ssd("J:\\QM\\Reports\\Sarthur\\SAS_Application\\SAS_Data_Sets",
 
> 
"

Why am I getting the message "sas not found", when I
have SAS installed on my machine?

I checked the PROC COPY SAS program generated in the
indicated temporary file:

"
libname src2rd
'J:\QM\Reports\Sarthur\SAS_Application\SAS_Data_Sets';
libname rd xport 'C:\TEMP\Rtmp12421\file14817';
proc copy in=src2rd out=rd;
select use ;
"

SAS log

"
NOTE: SAS initialization used:
      real time           4.64 seconds
      cpu time            0.73 seconds
"

Can anyone help me get to the next step of this
process?  I believe I am close to getting R to read
SAS permanent data sets directly, which I would really
like to be able to do.

Thanks,

Stephen



--- ripley at stats.ox.ac.uk wrote:
> On Thu, 19 Dec 2002, Stephen Arthur wrote:
> 
> > I just downloaded and installed R 1.6.1 on my
> Windows
> > machine where I also run SAS.
> >
> > I want to use the 'read.ssd' function so that I
> can
> > convert a permanent SAS data set into an R data
> frame.
> >

> > C:\Program
> > Files\R\rw1061\library\foreign\html\read.ssd.html
> >
> > When I run the first R command, in the example, on
> my
> > SAS library:
> >
> > > list.files("C:\\My Documents\\SAS_Data_Sets")
> >
> > I get the correct output.
> >
> > When I run the second R command, in the example,
> >
> > > read.ssd("C:\\My
> Documents\\SAS_Data_Sets","use")
> >

> 2) To use a package you need to use e.g.
> 
> library(foreign)

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help


----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.
----------------------------------------------------------------------



From sarthur67 at yahoo.com  Fri Dec 20 17:55:03 2002
From: sarthur67 at yahoo.com (Stephen Arthur)
Date: Fri Dec 20 17:55:03 2002
Subject: Part II Re: [R] read.ssd {foreign} (Reading a permanent SAS d    ataset into an R data frame)
In-Reply-To: <18D602BD42B7E24EB810D6454A58DB9001CAE121@ibfftce505.is.de.dresdnerkb.com>
Message-ID: <20021220165447.25416.qmail@web11101.mail.yahoo.com>

Thanks

> library(foreign)

I did do that originally, I just mis-tpyed it, and it
did not work.

I talked with people at SAS, and they said the PROC
COPY SAS code was good, but that I just need to play
around with the R parameters for read.ssd

Will get back to you on this issue.

If you have any additional suggestions, please send
them.


--- "Pfaff, Bernhard" <Bernhard.Pfaff at drkw.com> wrote:
> try:
> 
> library(foreign)
>
read.ssd("J:\\QM\\Reports\\Sarthur\\SAS_Application\\SAS_Data_Sets","use")
>



From ripley at stats.ox.ac.uk  Fri Dec 20 18:00:04 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Dec 20 18:00:04 2002
Subject: [R] GetRNGstate() crashes with 'Segmentation fault'
In-Reply-To: <20021220163433.GA31192@pcf004.jinr.ru>
Message-ID: <Pine.LNX.4.31.0212201648210.6208-100000@gannet.stats>

Whyever do you think that should work?

If you want to link against libR.so and call into R, you do need to
initialize R, and you have not done so.

I also don't see that the program has any use.  The complicated ways to
manipulate the random number generator are really only of any use from R
code (via C code, perhaps).

On Fri, 20 Dec 2002, Timur Elzhov wrote:

> Dear R-masters,
>
>
> I tried to compile this simpel C-code:
>
> //-----------------
>
> #include<R.h>
>
> int main()
> {
>     GetRNGstate();
>     return 0;
> }
>
> //-----------------
>
> Compiling:
>
> ~> gcc -o a  a.c -I/usr/lib/R/include/ -L/usr/lib/R/bin/ -lR
> ~> ldd a
>         libR.so => /usr/lib/libR.so (0x40018000)
>         libc.so.6 => /lib/libc.so.6 (0x401a8000)
>         libblas.so.2 => /usr/lib/libblas.so.2 (0x402bb000)
>         libreadline.so.4 => /lib/libreadline.so.4 (0x4031e000)
>         libdl.so.2 => /lib/libdl.so.2 (0x40347000)
>         libncurses.so.5 => /lib/libncurses.so.5 (0x4034a000)
>         libm.so.6 => /lib/libm.so.6 (0x40389000)
>         libz.so.1 => /usr/lib/libz.so.1 (0x403ab000)
>         /lib/ld-linux.so.2 => /lib/ld-linux.so.2 (0x40000000)
>
> ~> ./a
> Segmentation fault
>
>
> Where am I wrong?
> I'm using R 1.6.1, glibc-2.3.1 on Debian woody system.
>
> Thanks a lot!
>
> --
> WBR,
> Timur.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Timur.Elzhov at jinr.ru  Fri Dec 20 18:11:02 2002
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Fri Dec 20 18:11:02 2002
Subject: [R] GetRNGstate() crashes with 'Segmentation fault'
In-Reply-To: <Pine.LNX.4.31.0212201648210.6208-100000@gannet.stats>
References: <20021220163433.GA31192@pcf004.jinr.ru> <Pine.LNX.4.31.0212201648210.6208-100000@gannet.stats>
Message-ID: <20021220171357.GA31437@pcf004.jinr.ru>

On Fri, Dec 20, 2002 at 04:56:31PM +0000, ripley at stats.ox.ac.uk wrote:

> > ~> ./a
> > Segmentation fault
> Whyever do you think that should work?
> 
> If you want to link against libR.so and call into R, you do need to
> initialize R, and you have not done so.
> 
> I also don't see that the program has any use.  The complicated ways to
> manipulate the random number generator are really only of any use from R
> code (via C code, perhaps).
Yes, this code was intended to be used from R!  I decided just to
test it this way ;) .  So, it seems to be impossible to write
separate program, link it against R library, test it (and then create
shared library to used from within R)?

Thanks.


WBR,
Timur.



From ripley at stats.ox.ac.uk  Fri Dec 20 18:53:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Dec 20 18:53:03 2002
Subject: [R] GetRNGstate() crashes with 'Segmentation fault'
In-Reply-To: <20021220171357.GA31437@pcf004.jinr.ru>
Message-ID: <Pine.LNX.4.31.0212201752180.6247-100000@gannet.stats>

On Fri, 20 Dec 2002, Timur Elzhov wrote:

> On Fri, Dec 20, 2002 at 04:56:31PM +0000, ripley at stats.ox.ac.uk wrote:
>
> > > ~> ./a
> > > Segmentation fault
> > Whyever do you think that should work?
> >
> > If you want to link against libR.so and call into R, you do need to
> > initialize R, and you have not done so.
> >
> > I also don't see that the program has any use.  The complicated ways to
> > manipulate the random number generator are really only of any use from R
> > code (via C code, perhaps).
> Yes, this code was intended to be used from R!  I decided just to
> test it this way ;) .  So, it seems to be impossible to write
> separate program, link it against R library, test it (and then create
> shared library to used from within R)?

It's not impossible, but it is not straightforward.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tlumley at u.washington.edu  Fri Dec 20 19:10:03 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri Dec 20 19:10:03 2002
Subject: Part II Re: [R] read.ssd {foreign} (Reading a permanent SAS d 
   ataset into an R data frame)
In-Reply-To: <20021220165447.25416.qmail@web11101.mail.yahoo.com>
Message-ID: <Pine.A41.4.44.0212200939500.47234-100000@homer19.u.washington.edu>

On Fri, 20 Dec 2002, Stephen Arthur wrote:

> Thanks
>
> > library(foreign)
>
> I did do that originally, I just mis-tpyed it, and it
> did not work.
>
> I talked with people at SAS, and they said the PROC
> COPY SAS code was good, but that I just need to play
> around with the R parameters for read.ssd
>

If the SAS code is good then just using it in SAS seems like a useful
workaround.

	-thomas



From sarthur67 at yahoo.com  Fri Dec 20 20:07:03 2002
From: sarthur67 at yahoo.com (Stephen Arthur)
Date: Fri Dec 20 20:07:03 2002
Subject: Part II Re: [R] read.ssd {foreign} (Reading a permanent SAS d    ataset into an R data frame)
In-Reply-To: <Pine.A41.4.44.0212200939500.47234-100000@homer19.u.washington.edu>
Message-ID: <20021220190616.80134.qmail@web11106.mail.yahoo.com>

Thomas,

Your point is well taken.  I spoke with the people at
SAS again, and they said that a reason why I was
having a problem with the SAS xpt file, is that my
variable names are sometimes longer than 8 characters
long.

PROC COPY puts a limit of 8 characters length to
variable names.  Does R have a limit to the length of
variable names?

Instead, I used PROC CPORT, which can handle variable
names longer than 8 characters long, successfully.

proc cport library=src2rd file=tranfile;
 select use;
run;

But now, when I try to use the R function
'read.xport', I get the following error message:

read.xport("J:\\QM\\Reports\\Sarthur\\SAS_Application\\SAS_Data_Sets\\use")

Error in lookup.xport(file) : unable to open file

Thanks,

Stephen


--- Thomas Lumley <tlumley at u.washington.edu> wrote:
> On Fri, 20 Dec 2002, Stephen Arthur wrote:
> 
> > Thanks
> >
> > > library(foreign)
> >
> > I did do that originally, I just mis-tpyed it, and
> it
> > did not work.
> >
> > I talked with people at SAS, and they said the
> PROC
> > COPY SAS code was good, but that I just need to
> play
> > around with the R parameters for read.ssd
> >
> 
> If the SAS code is good then just using it in SAS
> seems like a useful
> workaround.
> 
> 	-thomas
>



From tlumley at u.washington.edu  Fri Dec 20 20:22:20 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri Dec 20 20:22:20 2002
Subject: Part II Re: [R] read.ssd {foreign} (Reading a permanent SAS d 
   ataset into an R data frame)
In-Reply-To: <20021220190616.80134.qmail@web11106.mail.yahoo.com>
Message-ID: <Pine.A41.4.44.0212201115540.47234-100000@homer19.u.washington.edu>

On Fri, 20 Dec 2002, Stephen Arthur wrote:

> Thomas,
>
> Your point is well taken.  I spoke with the people at
> SAS again, and they said that a reason why I was
> having a problem with the SAS xpt file, is that my
> variable names are sometimes longer than 8 characters
> long.
>
> PROC COPY puts a limit of 8 characters length to
> variable names.  Does R have a limit to the length of
> variable names?

No. (well, it probably does but it's so long I don't know what it is)

> Instead, I used PROC CPORT, which can handle variable
> names longer than 8 characters long, successfully.
>
> proc cport library=src2rd file=tranfile;
>  select use;
> run;
>
> But now, when I try to use the R function
> 'read.xport', I get the following error message:
>
> read.xport("J:\\QM\\Reports\\Sarthur\\SAS_Application\\SAS_Data_Sets\\use")
>
> Error in lookup.xport(file) : unable to open file
>

That means R can't find the file.  Are you sure it's there?

	-thomas



From Mark.Wilkinson at stjude.org  Fri Dec 20 21:00:07 2002
From: Mark.Wilkinson at stjude.org (Wilkinson, Mark)
Date: Fri Dec 20 21:00:07 2002
Subject: [R] lower triangle
Message-ID: <A1DAD6685C12D511B20F00034725151380CD96@sjmemexc3.stjude.org>

Hi,

I want to compute the lower triangle of a square matrix (optionally, sans
diagonal).  With for() loops I can do something like this:

## 5 by 5 matrix rtn
for (j in 1:5) {
	for (k in 1:j) {
		if (j != k) {  ## optional
		rtn[j, k] <- my.func(j, k)
		}
}
}


I'd like to do this with apply().  Is there some way I can do this kind of
'short-circuit'?

Thanks,


Mark Wilkinson
Informatics Analyst
St. Jude Children's Research Hospital
Department of Pharmaceutical Sciences



From Ngayee.Law at celeradiagnostics.com  Fri Dec 20 21:09:16 2002
From: Ngayee.Law at celeradiagnostics.com (Ngayee J Law)
Date: Fri Dec 20 21:09:16 2002
Subject: [R] JAVA and R
Message-ID: <OFC50B0EFB.70E0EE2B-ON88256C95.006DD978@pe-c.com>

Hello everyone,

Is it possible to call R in JAVA? Thanks!

Jacqueline



From hedderik at cmu.edu  Fri Dec 20 21:14:48 2002
From: hedderik at cmu.edu (Hedderik van Rijn)
Date: Fri Dec 20 21:14:48 2002
Subject: [R] Sweave & xtable
Message-ID: <DBB31EDB-1455-11D7-9977-000393678426@cmu.edu>

I'm trying to get Sweave running for automatic report generation, and 
it seems to run fine when just using verbatim output. However, I've ran 
into a problem with xtable. I would like to print the following matrix 
using xtable:

 > dim(counts)
[1] 19 15

All columns are filled with real/integer numbers > 0 and < 1000. Just 
typing xtable(counts) gives correct LaTeX output, but running Sweave on:

<<results=tex>>=
library(xtable)
xtable(counts)
@

Generates truncated TeX output:

% latex table generated in R 1.6.1 by xtable 1.0-10 package
% Fri Dec 20 14:50:08 2002
\begin{table}
[...]
5 & 105.00 & 400.00 & 0.00 & 0.00 & 0.00 & 0.00 & 1000.00 & 542.00 & 
181.00 & 858.00 & 4
62.00 & 103.00 & 744.00 & 449.00 & 93.00 \\
6 & 201.00 & 400.00 & 0.00 &

xtable(counts[1:4,]) does work. Do I have to flush the output of 
xtables in some way? Or is my table just too large?

  - Hedderik.



From sarthur67 at yahoo.com  Fri Dec 20 21:28:02 2002
From: sarthur67 at yahoo.com (Stephen Arthur)
Date: Fri Dec 20 21:28:02 2002
Subject: Part II Re: [R] read.ssd {foreign} (Reading a permanent SAS d    ataset into an R data frame)
In-Reply-To: <Pine.A41.4.44.0212201115540.47234-100000@homer19.u.washington.edu>
Message-ID: <20021220202749.40104.qmail@web11108.mail.yahoo.com>

Thomas,

The SAS data set I PROC CPORTed is [9] the result is
[10].  I PROC CIMPORTed  [10] back to its orginal
state [9], and it worked. 

So the SAS people think that the error is not with the
SAS XPORT file, but with R trying to load a text SAS
XPORT file, when it should be loading the SAS XPORT
file in binary format?  Is this a problem?

Here is a list of my commands to R:

>
list.files("J:\\QM\\Reports\\Sarthur\\SAS_Application\\SAS_Data_Sets")

[1]...
[9] "comm_acq_inj.sas7bdat"
[10] "cport.xpt"       
...[66]

> library(foreign)

>
read.xport("J:\\QM\\Reports\\Sarthur\\SAS_Application\\SAS_Data_Sets\\cport.xpt")
Error in lookup.xport(file) : File not in SAS transfer
format

--- Thomas Lumley <tlumley at u.washington.edu> wrote:
> 
> That means R can't find the file.  Are you sure it's
> there?
> 
> 	-thomas
> 

I am sure that the "cport.xpt" file is in the correct
directory.

Thanks for your assistance in this matter,

Stephen



From bates at stat.wisc.edu  Fri Dec 20 21:34:02 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri Dec 20 21:34:02 2002
Subject: [R] lower triangle
In-Reply-To: <A1DAD6685C12D511B20F00034725151380CD96@sjmemexc3.stjude.org>
References: <A1DAD6685C12D511B20F00034725151380CD96@sjmemexc3.stjude.org>
Message-ID: <6rznr0bfcm.fsf@bates5.stat.wisc.edu>

"Wilkinson, Mark" <Mark.Wilkinson at stjude.org> writes:

> I want to compute the lower triangle of a square matrix (optionally, sans
> diagonal).  With for() loops I can do something like this:
> 
> ## 5 by 5 matrix rtn
> for (j in 1:5) {
> 	for (k in 1:j) {
> 		if (j != k) {  ## optional
> 		rtn[j, k] <- my.func(j, k)
> 		}
> }
> }
> 
> 
> I'd like to do this with apply().  Is there some way I can do this kind of
> 'short-circuit'?

It depends.  If you can easily calculate a vector of values of
my.func(j,k) in the order in which the elements of the lower triangle
are stored you can do the assignment as

rtn[lower.tri(rtn)] <- vals

or

rtn[lower.tri(rtn, diag = TRUE)] <- vals


If you need to go through something like a double loop to calculate
the new values then this form of the replacement won't provide much of
an advantage.

See ?lower.tri and the lower.tri function itself.



From pdebruic at mgmt.purdue.edu  Fri Dec 20 22:21:05 2002
From: pdebruic at mgmt.purdue.edu (Debruicker, Paul A)
Date: Fri Dec 20 22:21:05 2002
Subject: [R] Newbie - referencing and vectorization questions
Message-ID: <D88E4A8CEFAE3D44B1959692C2C85A48318F48@parkplace.mgmt.purdue.edu>

Dear List,
 
    I am working on learning R and have come up with a few questions that I haven't been able to answer with books from the local library. I am attempting to find the mean and variance of subsets of a ~140k item vector(lets say variable X). Using groups of 5 variables from a pool of 7, I limit the values of X by only selecting those who remain in the set after sorting on interpercentile ranges of the 5 other variables. There are 21 groups of 5 sorting variables, and if I were to use interquartile ranges, 5^4 possible combinations for each group.  So, I am trying to learn to write fast code, while learning R.
 
My questions are these:
 
     Is there a way to select a vector from a dataframe(containing values of sorting variables) using a character string located in another dataframe (containing possible groups of variables) that has been referenced with a numeric index?
 
     If there is, is there a way to do it using a vectorized process, rather than an iterative with several for loops or something?
 
 
Thanks for your consideration,
 
Paul



From andy_liaw at merck.com  Fri Dec 20 22:44:06 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri Dec 20 22:44:06 2002
Subject: [R] new optimized BLAS
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC9FD@usrymx10.merck.com>

Dear R-help,

Here's a posting to the most recent NA-digest:

From: Robert van de Geijn <rvdg at cs.utexas.edu>
Date: Fri, 13 Dec 2002 11:15:23 -0600
Subject: Fast BLAS Libraries for Current Architectures

Recent research by Kazushige Goto, Visiting Scientist at UT-Austin,
has resulted in high-performance BLAS libraries for the Intel (R)
Pentium (R) III and 4 processors, the HP/Compaq/DEC alpha processor,
and the IBM Power 3 and 4 architectures.  Performance improvements
appear to be substantial.  For example, by linking this library
instead of other commonly used BLAS libraries, the performance of the
600 processor (Pentium 4 processor based) cluster at the University at
Buffalo-SUNY was increased from roughly 1.5 TeraFLOPS to 2.0 TeraFLOPS
(HPL LINPACK benchmark used for the TOP500 list.  See
http://www.ccr.buffalo.edu/newsReleases/newsRelease.htm).

To help us evaluate this library, kindly visit
   http://www.cs.utexas.edu/users/flame/goto/

For information on the techniques underlying the implementation, see

Kazushige Goto and Robert van de Geijn. On Reducing TLB Misses in
Matrix Multiplication. FLAME Working Note #9, The University of Texas
at Austin, Department of Computer Sciences. Technical Report
TR-2002-55. Nov. 2002.

available from

http://www.cs.utexas.edu/users/flame/pubs.html

Regards
Robert van de Geijn

==========================================

Anyone interested in trying to link R against it and see how much of a
difference it makes?  (I would, except I won't have high speed net access
until I get back to office next year, and d/l large files are too
painful...)

Cheers,
Andy



------------------------------------------------------------------------------



From rossini at blindglobe.net  Fri Dec 20 23:19:05 2002
From: rossini at blindglobe.net (A.J. Rossini)
Date: Fri Dec 20 23:19:05 2002
Subject: [R] JAVA and R
In-Reply-To: <OFC50B0EFB.70E0EE2B-ON88256C95.006DD978@pe-c.com> ("Ngayee J
 Law"'s message of "Fri, 20 Dec 2002 12:00:30 -0800")
References: <OFC50B0EFB.70E0EE2B-ON88256C95.006DD978@pe-c.com>
Message-ID: <87el8cqqvw.fsf@jeeves.blindglobe.net>

>>>>> "ngayee" == Ngayee J Law <Ngayee> writes:

    ngayee> Is it possible to call R in JAVA? Thanks!

Yes.

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)



From rossini at blindglobe.net  Fri Dec 20 23:26:03 2002
From: rossini at blindglobe.net (A.J. Rossini)
Date: Fri Dec 20 23:26:03 2002
Subject: [R] Sweave & xtable
In-Reply-To: <DBB31EDB-1455-11D7-9977-000393678426@cmu.edu> (Hedderik van
 Rijn's message of "Fri, 20 Dec 2002 15:01:42 -0500")
References: <DBB31EDB-1455-11D7-9977-000393678426@cmu.edu>
Message-ID: <87adj0qqsk.fsf@jeeves.blindglobe.net>

>>>>> "hedderik" == Hedderik van Rijn <hedderik at cmu.edu> writes:

    hedderik> I'm trying to get Sweave running for automatic report generation, and
    hedderik> it seems to run fine when just using verbatim output. However, I've
    hedderik> ran into a problem with xtable. I would like to print the following
    hedderik> matrix using xtable:

I've had problems with large matrices, but never got around to
figuring out why (the cheap hack solution was to split matrices and
present in different tables).  

(matrices representing components of a model, not raw data, so it made
some sense, but wasn't optimal).

i.e. I think it might be a bug.

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)



From saikat at stat.wisc.edu  Sat Dec 21 01:21:02 2002
From: saikat at stat.wisc.edu (Saikat Debroy)
Date: Sat Dec 21 01:21:02 2002
Subject: Part II Re: [R] read.ssd {foreign} (Reading a permanent SAS d 
   ataset into an R data frame)
Message-ID: <Pine.LNX.4.21.0212201818300.4576-100000@istat02.stat.wisc.edu>

>>>>> "Stephen" == Stephen Arthur <sarthur67 at yahoo.com> writes:

  Stephen> The SAS data set I PROC CPORTed is [9] the result is [10].
  Stephen> I PROC CIMPORTed [10] back to its orginal state [9], and it
  Stephen> worked.

  Stephen> So the SAS people think that the error is not with the SAS
  Stephen> XPORT file, but with R trying to load a text SAS XPORT
  Stephen> file, when it should be loading the SAS XPORT file in
  Stephen> binary format?  Is this a problem?

I have no idea what you mean by binary/text SAS XPORT formats. R
implements the XPORT format as described in
    http://ftp.sas.com/techsup/download/technote/ts140.html
and that definitely is not a text format.


From tlumley at u.washington.edu  Sat Dec 21 02:05:03 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat Dec 21 02:05:03 2002
Subject: Part II Re: [R] read.ssd {foreign} (Reading a permanent SAS d 
   ataset into an R data frame)
In-Reply-To: <Pine.LNX.4.21.0212201818300.4576-100000@istat02.stat.wisc.edu>
Message-ID: <Pine.A41.4.44.0212201702180.47234-100000@homer19.u.washington.edu>

On Fri, 20 Dec 2002, Saikat Debroy wrote:

> I have no idea what you mean by binary/text SAS XPORT formats. R
> implements the XPORT format as described in
>     http://ftp.sas.com/techsup/download/technote/ts140.html
> and that definitely is not a text format.
>


Quoth http://www.nber.org/data/sasport.html :
---------------
There are two main kinds of SAS portable format datasets. These are CPORT
and XPORT. Both are popularly referred to as Transport datasets, but they
are quite different, and completely incompatible.

The CPORT datasets have the advantage that they can contain a wide variety
of SAS objects, not just datasets. However, they have no backwards
portability at all. Indeed, I am informed by SAS tech support that even
lateral portability is not to be taken for granted. The earliest version
of SAS for Unix to be able to read CPORT files generated under MVS 6.07 is
6.07.3 - not the more widespread release 6.07.2.

The true portable format is the XPORT format. Supposedly this has full
forwards and backwards compatibility (but see below). Only datasets can be
transferred with XPORT, not catalogs, formats, etc. This is the format you
would use to send data to another site.
----------------------


So CPORT is different, we don't know what the format is, and it may not be
documented anywhere.

	-thomas



From arc at arcriswell.com  Sat Dec 21 05:40:04 2002
From: arc at arcriswell.com (Andrew Criswell)
Date: Sat Dec 21 05:40:04 2002
Subject: [R] Getting graphs into LaTeX
Message-ID: <3F45FF8B.9060703@arcriswell.com>

Thanks to all who responded to my inquiry.  Bingo, it works!

I revised the code as follows and it works fine:

For the R code:
_______________________________________________
pdf()

pdf('lecture00-graph-01.pdf',
           horizontal = FALSE, height = 6, pointsize = 10)

hist(trial.outcome.5, breaks = 5,
     main = '1000 Replications of 5 Trials of a Coin Toss',
     xlab = 'Frequency of a Tail')

dev.off()
_______________________________________________

For the LaTeX document:
_______________________________________________

\documentclass[11pt]{article}
\usepackage[pdftex]{graphicx,color}
\begin{document}
\includegraphics{lecture00-graph-01}
\end{document}



From ozric at web.de  Sat Dec 21 17:35:04 2002
From: ozric at web.de (Christian Schulz)
Date: Sat Dec 21 17:35:04 2002
Subject: [R] apply vs. sapply
Message-ID: <009901c2a90e$553ca7f0$863f07d5@c5c9i0>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021221/9d7d8953/attachment.pl

From fredrik.karlsson at ling.umu.se  Sat Dec 21 18:09:03 2002
From: fredrik.karlsson at ling.umu.se (Fredrik Karlsson)
Date: Sat Dec 21 18:09:03 2002
Subject: [R] Regexpr capturing in R?
Message-ID: <20021221171056.GA1875@ling.umu.se>

A non-text attachment was scrubbed...
Name: msg.pgp
Type: application/pgp
Size: 720 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20021221/88eaa4b9/msg.bin

From ligges at statistik.uni-dortmund.de  Sat Dec 21 18:28:02 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat Dec 21 18:28:02 2002
Subject: [R] apply vs. sapply
References: <009901c2a90e$553ca7f0$863f07d5@c5c9i0>
Message-ID: <3E04A4FC.48245EA7@statistik.uni-dortmund.de>

Christian Schulz wrote:
> 
> Hi,
> 
> sapply((1:NCOL(hermes)),function(x) hist(hermes[,x],main=names(hermes)[x]))
> 
> .......this works , but i would like use it with apply to generate many plots in one step!

sapply() already *has* generated many plots, if NCOL(hermes) > 1.
It's rather complicated to help if one does not know what kind of object
"hermes" is [I guess a data.frame, because names() seems to give
reasonable results for you]


> ####################################################################
> 
> >>apply((1:ncol(hermes)),2,function(x) hist(hermes[,x],main=names(hermes)[x]))
> Error in apply(1:ncol(hermes), 2, function(x) hist(hermes[, x], main = names(hermes)[x])) :
>         dim(X) must have a positive length

apply() expects an array or a matrix, but not a vector.
The function within apply works on rows / columns of the matrix given as
the first argument, so something like
 apply(hermes, 2, hist) 
should do the trick.

Anyway, for labeling purposes I'd highly recommend to use a loop rather
than apply().

Uwe Ligges

 
> >>apply(hermes[,1:6],2,function(x) hist(hermes[,x],main=names(hermes)[x]))
> Error in hist.default(hermes[, x], main = names(hermes)[x]) :
>         `x' must be numeric
> 
> >>apply(hermes,2,function(x) hist(hermes[,x],main=names(hermes)[x]))
> Error in hist.default(hermes[,x ], main = names(hermes)[x]) :
>         `x' must be numeric
> 
> thanks for advance & regards
> 
>         [[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ozric at web.de  Sat Dec 21 19:48:06 2002
From: ozric at web.de (Christian Schulz)
Date: Sat Dec 21 19:48:06 2002
Subject: [R] apply vs. sapply
References: <009901c2a90e$553ca7f0$863f07d5@c5c9i0> <3E04A4FC.48245EA7@statistik.uni-dortmund.de>
Message-ID: <001e01c2a920$ee09ea30$71b407d5@c5c9i0>

....hmm sorry "sometimes after several experiments" my graphic.device
(W2000/1.6.1)didn't popUp & only
a new start helps, but now it works :-)

# hermes is data.frame
apply(hermes,2,hist) #without names
sapply((1:ncol(hermes)),function(x) hist(hermes[,x],main=names(hermes)[x]))
#with col.names

thanks & regards,christian



From shuangge at cs.wisc.edu  Sun Dec 22 00:01:03 2002
From: shuangge at cs.wisc.edu (Shuangge Ma)
Date: Sun Dec 22 00:01:03 2002
Subject: [R] a maximazation question
Message-ID: <Pine.GSO.4.21.0212211657220.1633-100000@route66.cs.wisc.edu>

Dear Sir/Madam:
this is shuangge Ma, graduate student in UW-Madison statistics department. 
I have a computational question.
I have a function f(x,y). I want to find the y(x) that maximize f(x,y)
under the constraint y(x) is a non-decreasing step function.
Is there any R package or algorithm I can use for this purpose?
thanks a lot for your time and help, 

Sincerely,
Shuangge Ma



From jeremybutler at paradise.net.nz  Sun Dec 22 01:25:03 2002
From: jeremybutler at paradise.net.nz (Jeremy Z Butler)
Date: Sun Dec 22 01:25:03 2002
Subject: [R] log axis error
Message-ID: <1040516630.3e05061629c6b@www.paradise.net.nz>

Hi,
When trying to benerate a barplot with a log y axis from a data matrix I get an
error which I just cant figure out:

> barplot(col.groups,beside=T,log="y")
Error in plot.window(xlim, ylim, log = "", ...) :
        formal argument "log" matched by multiple actual arguments

Can anyone tell me what this error means and possible solutions
Cheers, Jeremy



From mschwartz at medanalytics.com  Sun Dec 22 01:40:08 2002
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Sun Dec 22 01:40:08 2002
Subject: [R] log axis error
In-Reply-To: <1040516630.3e05061629c6b@www.paradise.net.nz>
Message-ID: <000201c2a953$05b84fa0$0201a8c0@MARC>

> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch 
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of Jeremy Z Butler
> Sent: Saturday, December 21, 2002 6:24 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] log axis error
> 
> 
> Hi,
> When trying to benerate a barplot with a log y axis from a 
> data matrix I get an error which I just cant figure out:
> 
> > barplot(col.groups,beside=T,log="y")
> Error in plot.window(xlim, ylim, log = "", ...) :
>         formal argument "log" matched by multiple actual arguments
> 
> Can anyone tell me what this error means and possible 
> solutions Cheers, Jeremy

Jeremy,

Log scale axes are not presently supported in barplot().

Look for the barplot2() function in the gregmisc package on CRAN.
That supports log scale axes and other features.

If you have any questions on its use, let me know.

Best regards,

Marc Schwartz



From hedderik at van-rijn.org  Sun Dec 22 03:42:02 2002
From: hedderik at van-rijn.org (Hedderik van Rijn)
Date: Sun Dec 22 03:42:02 2002
Subject: [R] Sweave & xtable [problem solved/workaround -> bug in xtable or textConnection?]
In-Reply-To: <DBB31EDB-1455-11D7-9977-000393678426@cmu.edu>
Message-ID: <DDDD0CCC-1556-11D7-9977-000393678426@van-rijn.org>

> I'm trying to get Sweave running for automatic report generation, and 
> it seems to run fine when just using verbatim output. However, I've 
> ran into a problem with xtable.

A quick solution (as long as the table is not too wide) is to include 
the following code after library(xtable), replacing the original 
print.string

print.string <- function(x,...) {
   
lapply(strsplit(x$text,"\n")[[1]],cat,"\n",file=x$file,append=x$append)
   return(invisible())
}

The problem seems to be that textConnection() (used in the Sweave code) 
is not able to process the long strings that sometimes get sink'ed to 
it. When sending a string directly to it, a warning is triggered:

## Error/truncation with warning:
con <- textConnection("output","w");
sink(file=con);
paste(rep("123456789!",1000),collapse="");
## Warning message:
## line truncated in output text connection
sink()
rm(last.warning)

However, when a long string is send to textConnection via xtable, no 
warning is shown:

## Error/truncation without warning:
library("xtable")
con <- textConnection("output","w")
sink(file=con)
xtable(matrix(rnorm(1000),100))
sink()
## print(output) would show the truncated LaTeX table, warnings() 
doesn't show any warning

I'm not sure whether textConnection or xtable should be blamed, but 
changing the single cat() with the lapply/strsplit/cat combination in 
print.string solved the/my problem.

If the truncation of long strings is official/known behavior of 
textConnection, the following text in textConnection's help page might 
need some revision, i.e., some more explicit statement that long 
strings might get truncated. (And, maybe also a definition of what a 
"completed line of output" is, i.e., ending in a "\n".)

      An output text connection is opened and creates an R character
      vector of the given name in the user's workspace.  This object
      will at all times hold the completed lines of output to the
      connection, and `isIncomplete' will indicate if there is an
      incomplete final line.  Closing the connection will output the
      final line, complete or not.

   - Hedderik.

P.S. I've seen a lot of bus errors and segmentation faults while trying 
to find the cause of the problem. If anyone is interested, I can try to 
see if I can reproduce those. I'm using:

R : Copyright 2002, The R Development Core Team
Version 1.6.1  (2002-11-01)

% latex table generated in R 1.6.1 by xtable 1.0-11 package



From ypeng at math.mun.ca  Sun Dec 22 03:55:03 2002
From: ypeng at math.mun.ca (Paul Y. Peng)
Date: Sun Dec 22 03:55:03 2002
Subject: [R] lgamma(-0.8)=?
Message-ID: <3E052973.551FAA4C@math.mun.ca>

Dear R users:

I wonder anyone is aware of such a thing from lgamma()

> lgamma(-0.8)
[1] 1.747207

I thought it should be NA as in S-PLUS. Both R-1.3.1 and R-1.5.1
report this result. I don't have the latest R-1.6.1 so I don't
know whether this is corrected or not.

Happy holidays,
Paul.



From deleeuw at stat.ucla.edu  Sun Dec 22 04:03:03 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Sun Dec 22 04:03:03 2002
Subject: [R] lgamma(-0.8)=?
In-Reply-To: <3E052973.551FAA4C@math.mun.ca>
Message-ID: <C7278C8E-1559-11D7-9C37-000393860F3C@stat.ucla.edu>

lgamma returns the ln of the abs of gamma (see ?lgamma)

 > log(abs(gamma(-0.8)))
[1] 1.747207

On Saturday, December 21, 2002, at 06:54 PM, Paul Y. Peng wrote:

>> lgamma(-0.8)
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------



From jmiyamot at u.washington.edu  Sun Dec 22 09:02:03 2002
From: jmiyamot at u.washington.edu (John Miyamoto)
Date: Sun Dec 22 09:02:03 2002
Subject: [R] pasting "\" into character strings
Message-ID: <Pine.A41.4.44.0212212340540.49202-100000@mead4.u.washington.edu>

Dear R-Help,
   I'm using R version 1.6.0 on a Windows computer.  I am trying to create
a function that, among other things, constructs strings that refer to
Windows files, e.g., I might want to construct a string like
'c:\work\part1.txt'.  I have found that the following does not work.

> paste("c:", "\", "work", "\", "part1.txt", sep="")
Error: syntax error

I'm guessing that R interprets "\" as some kind of special control
character, and that there is some way to show that one wants a literal
interpretation of "\" and not a control interpretation, but I haven't been
able to find an explanation of this issue.  I understand that I must use
'c:\\work\\part1.txt' or 'c:/work/part1.txt' to refer to the file that
Windows knows as 'c:\work\part.txt', but what I'm trying to do is to
write an R function that writes references to Windows files into a text
file, where a different Windows programs will later read these references
in the standard Windows syntax.
   Can someone tell me how to create the character string
'c:\work\part1.txt' from the parts, "c:", "work", an "part1.txt"?

John Miyamoto

--------------------------------------------------------------------
John Miyamoto, Dept. of Psychology, Box 351525
University of Washington, Seattle, WA 98195-1525
Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
Homepage http://faculty.washington.edu/jmiyamot/
--------------------------------------------------------------------



From ripley at stats.ox.ac.uk  Sun Dec 22 09:20:02 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun Dec 22 09:20:02 2002
Subject: [R] Sweave & xtable [problem solved/workaround -> bug in xtable
 or textConnection?]
In-Reply-To: <DDDD0CCC-1556-11D7-9977-000393678426@van-rijn.org>
Message-ID: <Pine.LNX.4.31.0212220810040.26654-100000@gannet.stats>

Connections do correctly give you a warning if the internal line limit is
exceeded.  This is docuemnted in the source code, which is there for you
to read. It is naive to assume that systems have arbitrary line-length
limits: many do not including the Unix terminal/shells I use. (And that is
not in their man pages either.)

Looks to me as if text connections are being used where anonymous file
connections would be much more appropriate.

On Sat, 21 Dec 2002, Hedderik van Rijn wrote:

[...]

> If the truncation of long strings is official/known behavior of
> textConnection, the following text in textConnection's help page might
> need some revision, i.e., some more explicit statement that long
> strings might get truncated. (And, maybe also a definition of what a
> "completed line of output" is, i.e., ending in a "\n".)

Whatever else could it mean?  I doubt if the end user would know what \n
means if (s)he is so naive as not to know what an incomplete line is!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sun Dec 22 09:27:05 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun Dec 22 09:27:05 2002
Subject: [R] pasting "\" into character strings
In-Reply-To: <Pine.A41.4.44.0212212340540.49202-100000@mead4.u.washington.edu>
Message-ID: <Pine.LNX.4.31.0212220820010.26654-100000@gannet.stats>

Why guess?  It's in the R Language definition and in all good books on
S/R.

`String constants are delimited by a pair of single (') or double (")
quotes and can contain all other printable characters. Quotes and other
special characters within strings are specified using escape sequences:'

paste("c:",  "work", "part1.txt", sep="\\")



On Sun, 22 Dec 2002, John Miyamoto wrote:

> Dear R-Help,
>    I'm using R version 1.6.0 on a Windows computer.  I am trying to create
> a function that, among other things, constructs strings that refer to
> Windows files, e.g., I might want to construct a string like
> 'c:\work\part1.txt'.  I have found that the following does not work.
>
> > paste("c:", "\", "work", "\", "part1.txt", sep="")
> Error: syntax error
>
> I'm guessing that R interprets "\" as some kind of special control
> character, and that there is some way to show that one wants a literal
> interpretation of "\" and not a control interpretation, but I haven't been
> able to find an explanation of this issue.  I understand that I must use
> 'c:\\work\\part1.txt' or 'c:/work/part1.txt' to refer to the file that
> Windows knows as 'c:\work\part.txt', but what I'm trying to do is to
> write an R function that writes references to Windows files into a text
> file, where a different Windows programs will later read these references
> in the standard Windows syntax.

c:/work/part1.txt *is* standard Windows syntax, too!

>    Can someone tell me how to create the character string
> 'c:\work\part1.txt' from the parts, "c:", "work", an "part1.txt"?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jgentry at jimmy.harvard.edu  Sun Dec 22 09:33:03 2002
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Sun Dec 22 09:33:03 2002
Subject: [R] pasting "\" into character strings
In-Reply-To: <Pine.A41.4.44.0212212340540.49202-100000@mead4.u.washington.edu>
Message-ID: <Pine.SOL.4.20.0212220330580.11477-100000@santiam.dfci.harvard.edu>

> write an R function that writes references to Windows files into a text
> file, where a different Windows programs will later read these references
> in the standard Windows syntax.
>    Can someone tell me how to create the character string
> 'c:\work\part1.txt' from the parts, "c:", "work", an "part1.txt"?

I don't have access to a Windows machine right now to test this, but might
file.path() help here?

-J



From hb at maths.lth.se  Sun Dec 22 09:38:04 2002
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Sun Dec 22 09:38:04 2002
Subject: [R] pasting "\" into character strings
In-Reply-To: <Pine.A41.4.44.0212212340540.49202-100000@mead4.u.washington.edu>
Message-ID: <000001c2a995$5e72ac70$7341a8c0@alpha.wehi.edu.au>

R is interpreting \" as the ASCII character for ", not "\". This means
that your second argument to paste() is the string "\", " and there
there follows a 'work', which is why you get a syntax error.

Yes, you should use \\ for backslash, e.g.

> pathname <- paste("c:", "\\", "work", "\\", "part1.txt", sep="")
> print(pathname)
[1] "c:\\work\\part1.txt"
> cat(pathname, "\n")
c:\work\part1.txt

Note that the "\\" is not two characters but one, i.e. nchar("\\") == 1.

Henrik Bengtsson


> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch 
> [mailto:r-help-admin at stat.math.ethz.ch] On Behalf Of John Miyamoto
> Sent: den 22 december 2002 19:01
> To: R discussion group
> Subject: [R] pasting "\" into character strings
> 
> 
> Dear R-Help,
>    I'm using R version 1.6.0 on a Windows computer.  I am 
> trying to create a function that, among other things, 
> constructs strings that refer to Windows files, e.g., I might 
> want to construct a string like 'c:\work\part1.txt'.  I have 
> found that the following does not work.
> 
> > paste("c:", "\", "work", "\", "part1.txt", sep="")
> Error: syntax error
> 
> I'm guessing that R interprets "\" as some kind of special 
> control character, and that there is some way to show that 
> one wants a literal interpretation of "\" and not a control 
> interpretation, but I haven't been able to find an 
> explanation of this issue.  I understand that I must use 
> 'c:\\work\\part1.txt' or 'c:/work/part1.txt' to refer to the 
> file that Windows knows as 'c:\work\part.txt', but what I'm 
> trying to do is to write an R function that writes references 
> to Windows files into a text file, where a different Windows 
> programs will later read these references in the standard 
> Windows syntax.
>    Can someone tell me how to create the character string 
> 'c:\work\part1.txt' from the parts, "c:", "work", an "part1.txt"?
> 
> John Miyamoto
> 
> --------------------------------------------------------------------
> John Miyamoto, Dept. of Psychology, Box 351525
> University of Washington, Seattle, WA 98195-1525
> Phone 206-543-0805, Fax 206-685-3157, Email 
> jmiyamot at u.washington.edu Homepage 
> http://faculty.washington.edu/jmiyamot/
> 
> --------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> http://www.stat.math.ethz.ch/mailman/listinfo/> r-help
> 
>



From ripley at stats.ox.ac.uk  Sun Dec 22 09:46:02 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun Dec 22 09:46:02 2002
Subject: [R] pasting "\" into character strings
In-Reply-To: <Pine.SOL.4.20.0212220330580.11477-100000@santiam.dfci.harvard.edu>
Message-ID: <Pine.LNX.4.31.0212220844350.26748-100000@gannet.stats>

On Sun, 22 Dec 2002, Jeff Gentry wrote:

> > write an R function that writes references to Windows files into a text
> > file, where a different Windows programs will later read these references
> > in the standard Windows syntax.
> >    Can someone tell me how to create the character string
> > 'c:\work\part1.txt' from the parts, "c:", "work", an "part1.txt"?
>
> I don't have access to a Windows machine right now to test this, but might
> file.path() help here?

It would, but it generates the other Windows standard, using /.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jmiyamot at u.washington.edu  Sun Dec 22 12:08:03 2002
From: jmiyamot at u.washington.edu (John Miyamoto)
Date: Sun Dec 22 12:08:03 2002
Subject: [R] pasting "\" into character strings
In-Reply-To: <Pine.LNX.4.31.0212220820010.26654-100000@gannet.stats>
Message-ID: <Pine.A41.4.44.0212220301220.49202-100000@mead4.u.washington.edu>

On Sun, 22 Dec 2002 ripley at stats.ox.ac.uk wrote:

> Why guess?  It's in the R Language definition and in all good books on
> S/R.
>
> `String constants are delimited by a pair of single (') or double (")
> quotes and can contain all other printable characters. Quotes and other
> special characters within strings are specified using escape sequences:'
>
> paste("c:",  "work", "part1.txt", sep="\\")

Reply: The problem with this command is that it produces

paste("c:",  "work", "part1.txt", sep="\\")
[1] "c:\\work\\part1.txt"

whereas I want "c:\work\part1.txt".  Some people have suggested to try
'file.path', but it either doesn't work, or I don't know how to make it
work.

> file.path("c:","work","part1.txt", fsep = "\")
Error: syntax error
> file.path("c:","work","part1.txt", fsep = "\\")
[1] "c:\\work\\part1.txt"

John Miyamoto



From ripley at stats.ox.ac.uk  Sun Dec 22 12:43:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun Dec 22 12:43:03 2002
Subject: [R] pasting "\" into character strings
In-Reply-To: <Pine.A41.4.44.0212220301220.49202-100000@mead4.u.washington.edu>
Message-ID: <Pine.LNX.4.31.0212221136380.31488-100000@gannet.stats>

Oh dear, oh dear, oh dear!

My answer is correct, and it does gives you

c:\work\part1.txt

However, print() (which you have called by auto-printing) escapes the
escape characters.  cat() does not, so you get

> x <- paste("c:",  "work", "part1.txt", sep="\\")
> x
[1] "c:\\work\\part1.txt"
> cat(x, "\n")
c:\work\part1.txt


On Sun, 22 Dec 2002, John Miyamoto wrote:

> On Sun, 22 Dec 2002 ripley at stats.ox.ac.uk wrote:
>
> > Why guess?  It's in the R Language definition and in all good books on
> > S/R.
> >
> > `String constants are delimited by a pair of single (') or double (")
> > quotes and can contain all other printable characters. Quotes and other
> > special characters within strings are specified using escape sequences:'
> >
> > paste("c:",  "work", "part1.txt", sep="\\")
>
> Reply: The problem with this command is that it produces
>
> paste("c:",  "work", "part1.txt", sep="\\")
> [1] "c:\\work\\part1.txt"
>
> whereas I want "c:\work\part1.txt".  Some people have suggested to try
> 'file.path', but it either doesn't work, or I don't know how to make it
> work.
>
> > file.path("c:","work","part1.txt", fsep = "\")
> Error: syntax error
> > file.path("c:","work","part1.txt", fsep = "\\")
> [1] "c:\\work\\part1.txt"
>
> John Miyamoto
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jmiyamot at u.washington.edu  Sun Dec 22 14:59:02 2002
From: jmiyamot at u.washington.edu (John Miyamoto)
Date: Sun Dec 22 14:59:02 2002
Subject: [R] pasting "\" into character strings
In-Reply-To: <Pine.LNX.4.31.0212221136380.31488-100000@gannet.stats>
Message-ID: <Pine.A41.4.44.0212220555410.49202-100000@mead4.u.washington.edu>

Thank you, Professor Ripley,
    Your comment does indeed lead to the solution to my problem as stated.
As you point out, this code

> x <- paste("c:",  "work", "part1.txt", sep="\\")
> x
[1] "c:\\work\\part1.txt"
> cat(x, "\n")
c:\work\part1.txt

produces the output I want.  I need only indicate the file and append
option to achieve my purpose.

> x <- paste("c:",  "work", "part1.txt", sep="\\")
> cat(x, file = "out.txt", append = TRUE, "\n")

I discovered from this interchange that I did not quite state my problem
correctly, but the discussion solved the real problem as well as the
stated problem.  What started me on these questions was the desire to
write a function that would convert a R-intelligible file reference, e.g.,
'c:/work/part1.txt' to a Windows file reference, e.g.,
'c:\work\part1.txt'.  Having gotten this big hint, I now see how to solve
the problem as shown in the following:

> outfile <- "e:/temp/tmout1"
> outfile
[1] "e:/temp/tmout1"

> out.1 <- strsplit(outfile, "/")[[1]]
> out.1
[1] "e:"     "temp"   "tmout1"

> out.2 <- paste(out.1, sep="", collapse="\\")
> out.2
[1] "e:\\temp\\tmout1"

> cat(out.3, "\n")
e:\temp\tmout1

Since out.1 is a character vector, I needed to use 'collapse' rather than
'sep' to create "e:\\temp\\tmout1", but with this minor alteration,
everything works fine.

John Miyamoto

--------------------------------------------------------------------
John Miyamoto, Dept. of Psychology, Box 351525
University of Washington, Seattle, WA 98195-1525
Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
Homepage http://faculty.washington.edu/jmiyamot/
--------------------------------------------------------------------



From hedderik at cmu.edu  Sun Dec 22 21:14:03 2002
From: hedderik at cmu.edu (Hedderik van Rijn)
Date: Sun Dec 22 21:14:03 2002
Subject: [R] Sweave & xtable [problem solved/workaround -> bug in xtable or textConnection?]
In-Reply-To: <Pine.LNX.4.31.0212220810040.26654-100000@gannet.stats>
Message-ID: <DB0EDECD-15E9-11D7-9977-000393678426@cmu.edu>

> Connections do correctly give you a warning if the internal line limit 
> is
> exceeded.  This is docuemnted in the source code, which is there for 
> you
> to read.

I know, discovered that it did give warning if the string is sink'ed 
directly, instead of going through xtable (and which was illustrated 
with the examples in the previous email). After some more explorations, 
it seems to be caused by cat'ing instead of print'ing a long string to 
a textConnection using sink.

This code triggers a warning: (Same behavior of course if the 
paste(...) is explicitly embedded in a print(...) statement)

con <- textConnection("output","w");
sink(file=con);
paste(rep("123456789!",1000),collapse="")
## Warning message:
## line truncated in output text connection
sink()
close(con)

Whereas this code snippet "silently" truncates the string, without 
warning:

con <- textConnection("output","w");
sink(file=con);
cat(paste(rep("123456789!",1000),collapse=""))
sink()
close(con)

I'm not sure which function (if any) to blame, but I definitely think 
that either cat or textConnection should have made sure that a warning 
"came through". As you mentioned, it is naive to assume an arbitrary 
line-length, but if the above code is not incorrect, my opinion is that 
it should warn users of incorrect output, or state it in the help pages.

> Looks to me as if text connections are being used where anonymous file
> connections would be much more appropriate.

Indeed, changing Sweave's RweaveLatexRuncode (line 1596 of tools, R 
1.6.1) to use file/readLines instead of textConnection:

         ## HvR replaced: tmpcon <- textConnection("output", "w")
         tmpcon <- file()
         sink(file=tmpcon)
         err <- NULL
         if(options$eval) err <- RweaveEvalWithOpt(ce, options)
         ## HvR added (make sure the final line is complete (with final 
EOL marker):
         cat("\n")
         sink()
         ## HvR added:
         output <- readLines(tmpcon)
         close(tmpcon)

solves the truncation problem for the Sweave/xtable/cat combination.

> [...]
>
>> If the truncation of long strings is official/known behavior of
>> textConnection, the following text in textConnection's help page might
>> need some revision, i.e., some more explicit statement that long
>> strings might get truncated. (And, maybe also a definition of what a
>> "completed line of output" is, i.e., ending in a "\n".)
>
> Whatever else could it mean?  I doubt if the end user would know what 
> \n
> means if (s)he is so naive as not to know what an incomplete line is!

While trying to figure out how to use anonymous file connections, I 
come acros the following reference in the readLines help page:

      If the final line is incomplete (no final EOL marker) the
      behaviour depends on whether the connection is blocking or not.

I guess the addition of "(no final EOL marker)" would at least for me 
be a useful extension to the textConnection help page.
After having spend a couple of hours with textConnections and other 
redirections, and knowing more about how they work, I certainly see 
your point. However, it might have saved me some initial confusion if 
this would have been there in the first place.

At the same time, it might be valuable to add an explicit reference to 
file() (besides the "See also: connections"), stating something along 
the line of the combination file/readLines being preferred over 
textConnection if the purpose is to process large chunks of output. (If 
I gathered correctly from your remarks that anonymous file connections 
are more appropriate in these situations.)

Thanks for the valuable comments, again, I learned a lot.

   - Hedderik.



From p.dalgaard at biostat.ku.dk  Mon Dec 23 01:12:02 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon Dec 23 01:12:02 2002
Subject: [R] Sweave & xtable [problem solved/workaround -> bug in xtable or textConnection?]
In-Reply-To: <DB0EDECD-15E9-11D7-9977-000393678426@cmu.edu>
References: <DB0EDECD-15E9-11D7-9977-000393678426@cmu.edu>
Message-ID: <x2el89bnlp.fsf@biostat.ku.dk>

Hedderik van Rijn <hedderik at cmu.edu> writes:

> Whereas this code snippet "silently" truncates the string, without
> warning:
> 
> con <- textConnection("output","w");
> sink(file=con);
> cat(paste(rep("123456789!",1000),collapse=""))
> sink()
> close(con)
> 
> I'm not sure which function (if any) to blame, but I definitely think
> that either cat or textConnection should have made sure that a warning
> "came through". As you mentioned, it is naive to assume an arbitrary
> line-length, but if the above code is not incorrect, my opinion is
> that it should warn users of incorrect output, or state it in the help
> pages.

The warning should be inside "output", shouldn't it? It actually isn't
there, so perhaps it is getting appended to the already overlong
string??

As I was trying to dig deeper, I ran into the following interesting
segfault on RH8.0:

> con <- textConnection("output","w");
> sink(file=con);
> cat(paste(rep("123456789!",1000),collapse=""))
> sink()
> close(con)
>
> output
[1]
"123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!123456789!!
123456789"
> cat(paste(rep("123456789!",1000),collapse=""))
Program received signal SIGSEGV, Segmentation fault.
0x4207a4cb in strlen () from /lib/i686/libc.so.6

(The cat(...) call being obtained with up-arrow command recall) 

Apparently this is not quite reproducible and might depend on stuff in
the workspace, but it looks suspicious. Will have a better look.
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Mon Dec 23 01:38:03 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon Dec 23 01:38:03 2002
Subject: [R] Sweave & xtable [problem solved/workaround -> bug in xtable or textConnection?]
In-Reply-To: <x2el89bnlp.fsf@biostat.ku.dk>
References: <DB0EDECD-15E9-11D7-9977-000393678426@cmu.edu>
	<x2el89bnlp.fsf@biostat.ku.dk>
Message-ID: <x2adixbmcv.fsf@biostat.ku.dk>

Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:

> > cat(paste(rep("123456789!",1000),collapse=""))
> Program received signal SIGSEGV, Segmentation fault.
> 0x4207a4cb in strlen () from /lib/i686/libc.so.6
> 
> (The cat(...) call being obtained with up-arrow command recall) 

To be precise, it happens *next* time I press "up"
 
> Apparently this is not quite reproducible and might depend on stuff in
> the workspace, but it looks suspicious. Will have a better look.

It does seem to depend on my workspace and/or my history file, neither
of which are particularly interesting. The segfault happens deep into
readline calls, so it's not really appealing to try and track it down...

Apparently, it still happens with r-devel from Dec. 9 (which is the
most recent I have on that particular machine...).
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From alobo at ija.csic.es  Mon Dec 23 11:55:03 2002
From: alobo at ija.csic.es (Agustin Lobo)
Date: Mon Dec 23 11:55:03 2002
Subject: [R] calling R from python (fwd)
Message-ID: <Pine.OSF.3.96.1021223115812.20781C-100000@paleo.ija.csic.es>

A question for a (experienced) user of the RPython package on
linux.

I'm trying to call R from python on a linux (Suse 7.3) box.

After installing  R CMD INSTALL -c RSPython_0.5-2.tar.gz

I start python and do:

>>> import sys
>>> sys.path.append('/usr/local/lib/R/library/RSPython')
>>> sys.path.append('/usr/local/lib/R/library/RSPython/Python')
>>> sys.path.append('/usr/local/lib/R/library/RSPython/libs')
>>> sys.path.append('/usr/local/lib/R/library/RSPython/man')
>>> sys.path.append('/usr/local/lib/R/library/R/RSPython')
>>> sys.path.append('/usr/local/lib/R/library/RSPython/R/RSPython')
>>> sys.path.append('/usr/local/lib/R/library/RSPython/R')
>>> sys.path.append('/usr/local/lib/R/library/RSPython/include')
>>> sys.path.append('/usr/local/lib/R/include/R_ext')
>>> import RS
Traceback (most recent call last):
  File "<stdin>", line 1, in ?
  File "/usr/local/lib/R/library/RSPython/Python/RS.py", line 1, in ?
    import RSInternal
ImportError: /usr/local/lib/R/library/RSPython/libs/RSInternal.so:
undefined symbol: R_GlobalEnv
>>> import RS
>>> RS.call("rnorm", 10);
Traceback (most recent call last):
  File "<stdin>", line 1, in ?
AttributeError: 'RS' module has no attribute 'call'

Any idea of what am I doing wrong? Where should R_GlobalEnv
be defined?

Thanks

Agus

Dr. Agustin Lobo
Instituto de Ciencias de la Tierra (CSIC)
Lluis Sole Sabaris s/n
08028 Barcelona SPAIN
tel 34 93409 5410
fax 34 93411 0012
alobo at ija.csic.es



From baty at biomserv.univ-lyon1.fr  Mon Dec 23 13:48:02 2002
From: baty at biomserv.univ-lyon1.fr (Florent BATY)
Date: Mon Dec 23 13:48:02 2002
Subject: [R] Extracting a dataset from an nls object
Message-ID: <3E070AB8.60404@biomserv.univ-lyon1.fr>

Hi,

Does anyone know if it is possible to extract the whole data set from an 
nls object?
I tried

'nls.object'$data

but it only provides the name of the data frame with no direct access to 
content of this data frame.
Do you have an idea??

Thanks in advance.

Florent BATY

-- 
_______________________________________

Florent BATY
CNRS UMR 5558
Dynamique des Populations Bact?riennes
Facult? de M?decine Lyon-Sud
69921 OULLINS, BP 12
FRANCE
tel : +33 (0)4 78 86 31 67
fax : +33 (0)4 78 86 31 49



From duncan at research.bell-labs.com  Mon Dec 23 15:04:02 2002
From: duncan at research.bell-labs.com (Duncan Temple Lang)
Date: Mon Dec 23 15:04:02 2002
Subject: [R] calling R from python (fwd)
In-Reply-To: <Pine.OSF.3.96.1021223115812.20781C-100000@paleo.ija.csic.es>; from alobo@ija.csic.es on Mon, Dec 23, 2002 at 12:06:07PM +0100
References: <Pine.OSF.3.96.1021223115812.20781C-100000@paleo.ija.csic.es>
Message-ID: <20021223090315.B27877@jessie.research.bell-labs.com>

My immediate guess is that you do not have R compiled as a shared
library, i.e. libR.so.  Without this, you cannot use R within Python,
but only Python within R.  libR.so is where R_GlobalEnv will come
from.

So check for libR.so in the directory `R RHOME`/bin.
If it is not there, you will have to build R from source
by configuring it with
  ./configure --enable-R-shlib

Then, re-install the RSPython package and things should work.
There is a shell script  in the scripts/ directory of the
installed RSPython package that sets the relevant variables.
Just source that into your shell (i.e. source for csh/tcsh,
or . sciptName for Bash) and that should set the PYTHONLIB
and LD_LIBRARY_PATH correctly.

 D.


Agustin Lobo wrote:
> A question for a (experienced) user of the RPython package on
> linux.
> 
> I'm trying to call R from python on a linux (Suse 7.3) box.
> 
> After installing  R CMD INSTALL -c RSPython_0.5-2.tar.gz
> 
> I start python and do:
> 
> >>> import sys
> >>> sys.path.append('/usr/local/lib/R/library/RSPython')
> >>> sys.path.append('/usr/local/lib/R/library/RSPython/Python')
> >>> sys.path.append('/usr/local/lib/R/library/RSPython/libs')
> >>> sys.path.append('/usr/local/lib/R/library/RSPython/man')
> >>> sys.path.append('/usr/local/lib/R/library/R/RSPython')
> >>> sys.path.append('/usr/local/lib/R/library/RSPython/R/RSPython')
> >>> sys.path.append('/usr/local/lib/R/library/RSPython/R')
> >>> sys.path.append('/usr/local/lib/R/library/RSPython/include')
> >>> sys.path.append('/usr/local/lib/R/include/R_ext')
> >>> import RS
> Traceback (most recent call last):
>   File "<stdin>", line 1, in ?
>   File "/usr/local/lib/R/library/RSPython/Python/RS.py", line 1, in ?
>     import RSInternal
> ImportError: /usr/local/lib/R/library/RSPython/libs/RSInternal.so:
> undefined symbol: R_GlobalEnv
> >>> import RS
> >>> RS.call("rnorm", 10);
> Traceback (most recent call last):
>   File "<stdin>", line 1, in ?
> AttributeError: 'RS' module has no attribute 'call'
> 
> Any idea of what am I doing wrong? Where should R_GlobalEnv
> be defined?
> 
> Thanks
> 
> Agus
> 
> Dr. Agustin Lobo
> Instituto de Ciencias de la Tierra (CSIC)
> Lluis Sole Sabaris s/n
> 08028 Barcelona SPAIN
> tel 34 93409 5410
> fax 34 93411 0012
> alobo at ija.csic.es
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan



From tlumley at u.washington.edu  Mon Dec 23 17:16:03 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon Dec 23 17:16:03 2002
Subject: [R] a maximazation question
In-Reply-To: <Pine.GSO.4.21.0212211657220.1633-100000@route66.cs.wisc.edu>
Message-ID: <Pine.A41.4.44.0212230802320.44502-100000@homer26.u.washington.edu>

On Sat, 21 Dec 2002, Shuangge Ma wrote:

> Dear Sir/Madam:
> this is shuangge Ma, graduate student in UW-Madison statistics department.
> I have a computational question.
> I have a function f(x,y). I want to find the y(x) that maximize f(x,y)
> under the constraint y(x) is a non-decreasing step function.
> Is there any R package or algorithm I can use for this purpose?
> thanks a lot for your time and help,
>

Often for a problem like this a finite set of possible locations for the
steps are known (for a not-necessarily-unique solution) -- eg the observed
values of x.  In that case the answer can be parametrised by the step
heights at each of these x values, with the constraint that these are
non-negative.  The L-BFGS-B method of optim() will probably work.

If you don't know where the steps are, it's likely to be much harder.

One important special case that's worth mentioning is the isotonic
regression problem.  If you have data (x_i,y_i) and are trying to fit an
increasing function by least squares or maximum likelihood the (or at
least a) solution is usually the isotonic regression, given by the
Pool-Adjacent-Violators Algorithm.


	-thomas



From Jim_Garrett at bd.com  Mon Dec 23 17:21:29 2002
From: Jim_Garrett at bd.com (Jim_Garrett@bd.com)
Date: Mon Dec 23 17:21:29 2002
Subject: [R] Re: pasting "\" into character strings
Message-ID: <OF5C4B7527.3C6C979B-ON85256C98.00593556@bd.com>

Is it really necessary to use "\"?

On my Windows 2000 system here at work, it appears that the "dos" shell
interprets "/" as "\", even though "\" is the "official" Windows folder
delimiter.  For instance, I can type "C:/Program
Files/R/rw1061/bin/Rgui.exe" (quotes included) and R opens.  Using "/"
would simplify matters, but are there pitfalls?  Do all Windows systems
exhibit this behavior?

Just curious.

Jim Garrett
Becton Dickinson Diagnostic Systems
Baltimore, Maryland, USA


*********************************************************************************
This message is intended only for the designated recipient(s).  It may
contain confidential or proprietary information and may be subject to
the attorney-client privilege or other confidentiality protections.
If you are not a designated recipient, you may not review, use, copy
or distribute this message.  If you receive this in error, please
notify the sender by reply e-mail and delete this message.  Thank you. 

**********************************************************************************



From tlumley at u.washington.edu  Mon Dec 23 17:25:04 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon Dec 23 17:25:04 2002
Subject: [R] pasting "\" into character strings
In-Reply-To: <Pine.A41.4.44.0212220555410.49202-100000@mead4.u.washington.edu>
Message-ID: <Pine.A41.4.44.0212230817290.44502-100000@homer26.u.washington.edu>

On Sun, 22 Dec 2002, John Miyamoto wrote:

>
> I discovered from this interchange that I did not quite state my problem
> correctly, but the discussion solved the real problem as well as the
> stated problem.  What started me on these questions was the desire to
> write a function that would convert a R-intelligible file reference, e.g.,
> 'c:/work/part1.txt' to a Windows file reference, e.g.,
> 'c:\work\part1.txt'.  Having gotten this big hint, I now see how to solve
> the problem as shown in the following:
>

a) You very rarely need to do this conversion. R (and a lot of other
Windows software) is perfectly happy with c:/work/part1.txt

b) An easier way to convert is to use chartr()
> chartr("/","\\","c:/work/part1.txt")
[1] "c:\\work\\part1.txt"


	-thomas



From deleeuw at stat.ucla.edu  Mon Dec 23 17:36:03 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Mon Dec 23 17:36:03 2002
Subject: [R] a maximazation question
In-Reply-To: <Pine.A41.4.44.0212230802320.44502-100000@homer26.u.washington.edu>
Message-ID: <782446DE-1694-11D7-9E2D-000393860F3C@stat.ucla.edu>

Here is a version of pooled-adjacent-violators in R, which
does weighted mean, weighted median, and weighted p-fractile.

===============================================================

pava<-function(x,w=rep(1,length(x)),block=weighted.mean){
nblock<-n<-length(x); blocklist<-array(1:n,c(n,2)); blockvalues<-x;  
active<-1
repeat{
	if (!is.up.satisfied(blockvalues,active)) {
		blockmerge<-merge.block.up(blocklist,blockvalues,x,w,active,block)
		blockvalues<-blockmerge$v; blocklist<-blockmerge$l
		nblock<-nblock-1
		while (!is.down.satisfied(blockvalues,active)) {
			blockmerge<-merge.block.up(blocklist,blockvalues,x,w,active-1,block)
			blockvalues<-blockmerge$v; blocklist<-blockmerge$l;
			nblock<-nblock-1; active<-active-1;
			}
		}
	else if (active == nblock) break() else active<-active+1
	}	
put.back(n,blocklist,blockvalues)
}

merge.block.up<-function(blocklist,blockvalues,x,w,i,block){
n<-length(blockvalues); nn<-1:n; ii<-which(i+1!=nn)
blocklist[i,]<-c(blocklist[i,1],blocklist[i+1,2])
indi<-blocklist[i,1]:blocklist[i+1,2]
blockvalues[i]<-block(x[indi],w[indi])
blocklist<-blocklist[ii,]
if (length(ii) == 1) dim(blocklist)<-c(1,2)
blockvalues<-blockvalues[ii]
list(v=blockvalues,l=blocklist)
}

put.back<-function(n,blocklist,blockvalues){
x<-rep(0,n);nb<-length(blockvalues)
for (i in 1:nb) {
		x[blocklist[i,1]:blocklist[i,2]]<-blockvalues[i]}
return(x)
}

is.up.satisfied<-function(x,i) (i == length(x))||(x[i]<=x[i+1])

is.down.satisfied<-function(x,i) (i == 1)||(x[i-1]<=x[i])

weighted.median<-function(x,w=rep(1,length(x))){
ox<-order(x);x<-x[ox];w<-w[ox];k<-1
low<-cumsum(c(0,w)); up<-sum(w)-low; df<-low-up
repeat{
	if (df[k] < 0) k<-k+1
		else if (df[k] == 0) return((w[k]*x[k]+w[k-1]*x[k-1])/(w[k]+w[k-1]))
			else return(x[k-1])
	}
}

weighted.pth.fractile<-function(x,w=rep(1,length(x)),a=1,b=1){
ox<-order(x);x<-x[ox];w<-w[ox];k<-1
low<-cumsum(c(0,w)); up<-sum(w)-low; df<-a*low-b*up
repeat{
	if (df[k] < 0) k<-k+1
		else if (df[k] == 0) return((w[k]*x[k]+w[k-1]*x[k-1])/(w[k]+w[k-1]))
			else return(x[k-1])
	}
}

On Monday, December 23, 2002, at 08:15 AM, Thomas Lumley wrote:

> On Sat, 21 Dec 2002, Shuangge Ma wrote:
>
>> Dear Sir/Madam:
>> this is shuangge Ma, graduate student in UW-Madison statistics  
>> department.
>> I have a computational question.
>> I have a function f(x,y). I want to find the y(x) that maximize f(x,y)
>> under the constraint y(x) is a non-decreasing step function.
>> Is there any R package or algorithm I can use for this purpose?
>> thanks a lot for your time and help,
>>
>
> Often for a problem like this a finite set of possible locations for  
> the
> steps are known (for a not-necessarily-unique solution) -- eg the  
> observed
> values of x.  In that case the answer can be parametrised by the step
> heights at each of these x values, with the constraint that these are
> non-negative.  The L-BFGS-B method of optim() will probably work.
>
> If you don't know where the steps are, it's likely to be much harder.
>
> One important special case that's worth mentioning is the isotonic
> regression problem.  If you have data (x_i,y_i) and are trying to fit  
> an
> increasing function by least squares or maximum likelihood the (or at
> least a) solution is usually the isotonic regression, given by the
> Pool-Adjacent-Violators Algorithm.
>
>
> 	-thomas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://gifi.stat.ucla.edu
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------



From Mike.Prager at noaa.gov  Mon Dec 23 18:09:03 2002
From: Mike.Prager at noaa.gov (Mike Prager)
Date: Mon Dec 23 18:09:03 2002
Subject: [R] Barplot() questions
Message-ID: <5.1.0.14.2.20021223111243.02b73938@hermes.nos.noaa.gov>

Using R 1.6.1 on Windows 2000.  As always, a big THANK YOU to the R team.

(1) Can the legend position be specified in barplot()?    Right now, we are 
doing this with a separate call to legend().

(2) For a stacked bar, we wish to show both positive and negative values, 
rather than taking an algebraic sum.  Right now, negative values in a stack 
are plotted starting from the top of any summed positive values.  Not sure 
if this is a feature or a bug (as the negative values can overlay the 
positive and vice versa).


-- 
Michael Prager, Ph.D.                <Mike.Prager at noaa.gov>
NOAA Center for Coastal Fisheries and Habitat Research
Beaufort, North Carolina  28516
http://shrimp.ccfhrb.noaa.gov/~mprager/



From bob.ohara at helsinki.fi  Mon Dec 23 18:16:03 2002
From: bob.ohara at helsinki.fi (Anon.)
Date: Mon Dec 23 18:16:03 2002
Subject: [R] Strange axis labels?
Message-ID: <3E074399.D19AE322@helsinki.fi>

Moi!

I'm trying to add a rather long label to a y-axis, and it's so long that
it won't fit into one line.  However, things get strange when I try and
split it over 2 lines.  The problem seems to be the plus/minus symbol,
which means I have to use expression().  I'm using R1.6.1 on Windoze
2000.

As an example:

thing1 <- expression(paste("log odds of survival probability ( " %+-%
"95% C.I.)", sep="     ")
thing2 <- expression(paste("log odds of survival probability \n( " %+-%
"95% C.I.)"))

plot(c(1,2), c(1,2), ylab=thing1)
par(mar =c(2.1, 6.1, 2.1, 2.1)); plot(c(1,2), c(1,2), ylab=thing2)

The first plot has the label on one line, with only a single space
between the bracket and the +/-.  Tbis is what I want, but I wonder why
paste has a sep=, if it doesn't do anything (I assume I've missed
something here).

The second plot has the label on 2 lines (you need the par() to get it
all in!), but the open bracket, "(", lines up with the start of the
first lines, and there is then a large gap, and the string continues
with the plus/minus below and to the right of the final part of the
first line.  Not what I expected at all.  Can anyone explain what's
going on, and how to remove this large space?

Thanks!

Bob

-- 
Bob O'Hara

Rolf Nevanlinna Institute
P.O. Box 4 (Yliopistonkatu 5)
FIN-00014 University of Helsinki
Finland

tel: +358 9 191 23743      mobile: +358 50 599 0540
fax: +358 9 191 22779    email: bob.ohara at helsinki.fi

It is being said of a certain poet, that though he tortures the English
language, he has still never yet succeeded in forcing it to reveal his
meaning
- Beachcomber



From ligges at statistik.uni-dortmund.de  Mon Dec 23 19:30:03 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon Dec 23 19:30:03 2002
Subject: [R] Strange axis labels?
References: <3E074399.D19AE322@helsinki.fi>
Message-ID: <3E07567B.94D72069@statistik.uni-dortmund.de>

"Anon." wrote:
> 
> Moi!
> 
> I'm trying to add a rather long label to a y-axis, and it's so long that
> it won't fit into one line.  However, things get strange when I try and
> split it over 2 lines.  The problem seems to be the plus/minus symbol,
> which means I have to use expression().  I'm using R1.6.1 on Windoze
> 2000.

I think it's not the symbol, it's the not very appropriate use of the
help page ?plotmath.
[BTW: I guess your OS is called Windows 2000.]


> As an example:
> 
> thing1 <- expression(paste("log odds of survival probability ( " %+-%
> "95% C.I.)", sep="     ")
> thing2 <- expression(paste("log odds of survival probability \n( " %+-%
> "95% C.I.)"))
> 
> plot(c(1,2), c(1,2), ylab=thing1)
> par(mar =c(2.1, 6.1, 2.1, 2.1)); plot(c(1,2), c(1,2), ylab=thing2)
> 
> The first plot has the label on one line, with only a single space
> between the bracket and the +/-.  Tbis is what I want, but I wonder why
> paste has a sep=, if it doesn't do anything (I assume I've missed
> something here).

You gave paste() exactly one argument (additionally to "sep"). So
between which arguments do you expect the spaces? So in your example,
paste() is superfluously. BTW, ?plotmath doesn't say anything about
"sep":
  "paste(x, y, z)       ---  juxtapose x, y, and z"

To put extra spaces in, you might want to use "~~", ?plotmath says:
  "x ~~ y               ---  put extra space between x and y",
or phantom(...), ?plotmath:
  "x + phantom(0) + y   ---  leave gap for "0", but don't draw it"

Example:

 thing1 <- expression("log odds of survival probability (" * 
   phantom(0) %+-%  "95% C.I.)")
 plot(c(1,2), c(1,2), ylab=thing1)

> The second plot has the label on 2 lines (you need the par() to get it
> all in!), but the open bracket, "(", lines up with the start of the
> first lines, and there is then a large gap, and the string continues
> with the plus/minus below and to the right of the final part of the
> first line.  Not what I expected at all.  Can anyone explain what's
> going on, and how to remove this large space?

The internal algorithms are calculating the spaces needed to plot the
whole expression into one rectangle . And one of the spaces (that one to
the left) persists after your forced the linebreak; more precisely, all
spaces are still there (including those below the first part of your
formula, and above the second part, respectively). "\n" within
expressions is not documented to work for mathematical annotation.

So don't specify it as "ylab" in your call to plot(), but as two calls
to mtext(), one call for each line. See ?mtext for details.

Example:
 plot(c(1,2), c(1,2), ylab="")
 mtext("log odds of survival probability", 2, line = 3)
 mtext(expression("(" %+-% "95% C.I.)"), 2, line = 2)

Uwe Ligges



From sarthur67 at yahoo.com  Mon Dec 23 19:44:02 2002
From: sarthur67 at yahoo.com (Stephen Arthur)
Date: Mon Dec 23 19:44:02 2002
Subject: Part II Re: [R] read.ssd {foreign} (Reading a permanent SAS d    ataset into an R data frame)
In-Reply-To: <Pine.LNX.4.21.0212201818300.4576-100000@istat02.stat.wisc.edu>
Message-ID: <20021223184225.45106.qmail@web11104.mail.yahoo.com>

I'd like to thank the R Core Team for making the
parameters clearer for me on how to solve this
problem.

I think for now I will try to do most data management
tasks in SAS (from Oracle) and then use PROC EXPORT in
SAS to create a csv file that R can read and then I
can do my graphics, for publications and presentations
in R, because I frequently have variable names that
are greater than length 8.

I think this is the best solution for me given my
skills and the level of support I could expect to
receive for problems that are probably not high
priority.  I have written R functions in the past.  I
will have to re-learn how to do that.  This will all
take time.

Using Partha's solution:

* 1) Partha's code in SAS for using PROC EXPORT is:
LIBNAME libref 'C:\Windows\Path';
* 'yourfile' could be permanent or temporary SAS data;
PROC EXPORT DATA=libref.yourfile
 OUTFILE="C:\Windows\Path\yourfile.csv" REPLACE; 
RUN;

* 2) Partha's code in R for importing a csv file is;
yourfile <-
read.csv("C:\\Windows\\Path\\yourfile.csv")
names(yourfile)
yourfile

I thought the task of reading SAS data into R and
separately reading Oracle data into R was going to be
much easier than I now know it is.  I set up an Oracle
to SAS connection and an MS Access to SAS connection
on my system, just reading through notes on the web.

But because I realize R is much more a product of UNIX
than windows regarding database connectivity, I will
have to re-think my strategy.

Stephen



From Mike.Prager at noaa.gov  Mon Dec 23 20:32:03 2002
From: Mike.Prager at noaa.gov (Mike Prager)
Date: Mon Dec 23 20:32:03 2002
Subject: [R] Plot scales
Message-ID: <5.1.0.14.2.20021223143044.02b926d8@hermes.nos.noaa.gov>

I remember reading somewhere that locations on plots (in my case, arguments 
x and y for legend()) can be specified in several scales besides the usual 
data scale.  I would like to set x and y as proportions of total plot size 
or something similar.  Can anyone steer me to documentation on how to do it?

-- 

Michael Prager, Ph.D.                <Mike.Prager at noaa.gov>
NOAA Center for Coastal Fisheries and Habitat Research
Beaufort, North Carolina  28516
http://shrimp.ccfhrb.noaa.gov/~mprager/



From chrysopa at insecta.ufv.br  Mon Dec 23 21:00:10 2002
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Mon Dec 23 21:00:10 2002
Subject: [R] doubt on survreg.
Message-ID: <200212231811.38840.chrysopa@insecta.ufv.br>

Hi all,
I make a censored model using survreg from survival package. But the deviance 
values are too high, it is possible that must be a error in my model?

> summary(completo)
      conc          peso             dv              w               temp      
 Min.   :0.7   Min.   : 5.00   Min.   : 1.00   Min.   :0.0000   Min.   :22.70  
 1st Qu.:2.3   1st Qu.: 9.00   1st Qu.: 4.00   1st Qu.:0.0000   1st Qu.:24.20  
 Median :3.9   Median :11.00   Median :11.00   Median :0.0000   Median :25.00  
 Mean   :3.9   Mean   :11.21   Mean   :12.90   Mean   :0.2727   Mean   :25.22  
 3rd Qu.:5.5   3rd Qu.:13.00   3rd Qu.:22.25   3rd Qu.:1.0000   3rd Qu.:26.30  
 Max.   :7.1   Max.   :23.00   Max.   :29.00   Max.   :1.0000   Max.   :30.00  
      sp    
 Erato :66  
 Ethila:66  
            
> m0 <- survreg(Surv(dv,w)~1)
> m0
Call:
survreg(formula = Surv(dv, w) ~ 1)

Coefficients:
(Intercept) 
   3.268812 

Scale= 0.08118577 

Loglik(model)= -86.5   Loglik(intercept only)= -86.5
n= 132 
> m1 <- update(m0,.~. +sp+sp:conc+conc+peso+temp)
> m1
Call:
survreg(formula = Surv(dv, w) ~ sp + conc + peso + temp + sp:conc)

Coefficients:
  (Intercept)      spEthila          conc          peso          temp 
   6.16976497    0.47406628   -0.17860548    0.08421499   -0.16791187 
spEthila:conc 
  -0.07836046 

Scale= 0.0809617 

Loglik(model)= -1.088904e+40   Loglik(intercept only)= -86.5
	Chisq= -2.177807e+40 on 5 degrees of freedom, p= 1 
n= 132 
> 

Thanks for all and happy new year.
Ronaldo
-- 
In marriage, as in war, it is permitted to take every advantage of the enemy.
--
|   //|\\   [*****************************][*******************]
|| ( ? ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|     V     [ESALQ/USP-Entomologia, CP-09 ][HD: 30 + 10 Gb     ]
||  / l \   [13418-900 Piracicaba - SP    ][RAM: 128 Mb        ]
|  /(lin)\  [Fone: 19-429-4199 r.229      ][Video: SiS620-8Mb  ]
||/(linux)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (linux) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( x )   [*****************************][*******************]
||| _/ \_Powered by Gnu/Debian Woody D+:) | Lxuser#: 205366



From Zhongming.Yang at cchmc.org  Mon Dec 23 21:04:03 2002
From: Zhongming.Yang at cchmc.org (Zhongming Yang)
Date: Mon Dec 23 21:04:03 2002
Subject: [R] how to call R from Perl
Message-ID: <se0725a2.093@mailx.chmcc.org>

Hi,

Could you please tell me how to call R from Perl and call Perl
functions from R?

Thanks,



From edd at debian.org  Mon Dec 23 21:09:06 2002
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon Dec 23 21:09:06 2002
Subject: [R] how to call R from Perl
Message-ID: <E18QYrd-0006RZ-00@sonny.eddelbuettel.com>

> Could you please tell me how to call R from Perl and call Perl
> functions from R?

Please see http://www.omegahat.org/RSPerl

Dirk

-- 
According to the latest figures, 43% of all signatures are totally worthless.



From tchur at optushome.com.au  Mon Dec 23 21:24:03 2002
From: tchur at optushome.com.au (Tim Churches)
Date: Mon Dec 23 21:24:03 2002
Subject: [R] calling R from python (fwd)
References: <Pine.OSF.3.96.1021223115812.20781C-100000@paleo.ija.csic.es>
Message-ID: <3E075DE7.73137087@optushome.com.au>

Agustin Lobo wrote:
> 
> A question for a (experienced) user of the RPython package on
> linux.
> 
> I'm trying to call R from python on a linux (Suse 7.3) box.

Since you are calling R from Python, you could try Walter Moreira's
excellent RPy module. I found it much easier to install than RSPython
(provided you follow Waletr's instructions), and it has been very
reliable. It is also very efficient at converting Numeric Python arrays
to R, and has a very easy to use object model - much nicer than
RSPython's. See http://rpy.sourceforge.net

Of course, RSPython can also call Python from R, which RPy can't do.

Tim C



From hedderik at cmu.edu  Mon Dec 23 23:11:02 2002
From: hedderik at cmu.edu (Hedderik van Rijn)
Date: Mon Dec 23 23:11:02 2002
Subject: [R] Sweave & xtable [problem solved/workaround -> bug in xtable or textConnection?]
In-Reply-To: <x2adixbmcv.fsf@biostat.ku.dk>
Message-ID: <45073BD2-16C3-11D7-9977-000393678426@cmu.edu>

>>> cat(paste(rep("123456789!",1000),collapse=""))
>> Program received signal SIGSEGV, Segmentation fault.
>> 0x4207a4cb in strlen () from /lib/i686/libc.so.6
>>
>> (The cat(...) call being obtained with up-arrow command recall)
>
> To be precise, it happens *next* time I press "up"

This is the same behavior I encountered. The first time _always_ goes 
fine, the next time (also by pressing "up", "enter") sometimes(?) 
results in a segv and sometimes in a bus error. (Using R 1.6.1, Mac OS 
X, latest OS X update, 10.2.3? and just released fink installed.)

As I was not sure if I could replicate it always, I only referred to it 
in a "P.S." in the second email I sent on this topic.

  - Hedderik.



From ripley at stats.ox.ac.uk  Mon Dec 23 23:38:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon Dec 23 23:38:03 2002
Subject: [R] Sweave & xtable [problem solved/workaround -> bug in xtable
 or textConnection?]
In-Reply-To: <45073BD2-16C3-11D7-9977-000393678426@cmu.edu>
Message-ID: <Pine.LNX.4.31.0212232235550.23791-100000@gannet.stats>

This should be fixed in R-patched and R-devel (and has been since
Saturday).  Certainly it has gone away for me.

On Mon, 23 Dec 2002, Hedderik van Rijn wrote:

> >>> cat(paste(rep("123456789!",1000),collapse=""))
> >> Program received signal SIGSEGV, Segmentation fault.
> >> 0x4207a4cb in strlen () from /lib/i686/libc.so.6
> >>
> >> (The cat(...) call being obtained with up-arrow command recall)
> >
> > To be precise, it happens *next* time I press "up"
>
> This is the same behavior I encountered. The first time _always_ goes
> fine, the next time (also by pressing "up", "enter") sometimes(?)
> results in a segv and sometimes in a bus error. (Using R 1.6.1, Mac OS
> X, latest OS X update, 10.2.3? and just released fink installed.)
>
> As I was not sure if I could replicate it always, I only referred to it
> in a "P.S." in the second email I sent on this topic.
>
>   - Hedderik.
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wscherr at itc-world.com  Tue Dec 24 05:14:02 2002
From: wscherr at itc-world.com (Wolfgang Scherr)
Date: Tue Dec 24 05:14:02 2002
Subject: [R] Linking R script and a COM application
Message-ID: <GDEBIOHLIGJIMKMGJELHMELECKAA.wscherr@itc-world.com>

I am new to R. I run it under MS Windows.

My goal is to interface an existing R program (500 lines) with a commercial software. That one
can be used as an OLE-Server. Ideally I would be able to reference and control the R-program
and components of the other software out of one VBA program. To make it easier, the R script
has no text or graphics output. I have downloaded http://cran.r-project.org/contrib/extra/dcom/
but I do not understand:

?? what command do I use in VBA to run an existing COM script ??

Can someone send me a sample of VB code?

Wolfgang Scherr
Innovative Transportation Concepts, Inc.
302-654-4384 phone
wscherr at itc-world.com



From SamirMishra at cbuae.gov.ae  Tue Dec 24 05:41:03 2002
From: SamirMishra at cbuae.gov.ae (Samir Mishra)
Date: Tue Dec 24 05:41:03 2002
Subject: [R] calling R from python (fwd)
Message-ID: <211AD0070D42D1118C7B00A024FF19AE24C03D@AUHEXCH>

I'm working in WinXP. Is it the case that RSPython does not work on Win32
platforms? I believe I read this somewhere... I'd appreciate confirmation.
Either way, I wasn't able to get RSPython to work for me, this was some time
ago, and at that time I was very new to Python.

Thanks.


-----Original Message-----
From: Tim Churches [mailto:tchur at optushome.com.au]
Sent: Monday, December 23, 2002 23:03
To: Agustin Lobo
Cc: r-help
Subject: Re: [R] calling R from python (fwd)


Agustin Lobo wrote:
> 
> A question for a (experienced) user of the RPython package on
> linux.
> 
> I'm trying to call R from python on a linux (Suse 7.3) box.

Since you are calling R from Python, you could try Walter Moreira's
excellent RPy module. I found it much easier to install than RSPython
(provided you follow Waletr's instructions), and it has been very
reliable. It is also very efficient at converting Numeric Python arrays
to R, and has a very easy to use object model - much nicer than
RSPython's. See http://rpy.sourceforge.net

Of course, RSPython can also call Python from R, which RPy can't do.

Tim C

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From SamirMishra at cbuae.gov.ae  Tue Dec 24 06:26:03 2002
From: SamirMishra at cbuae.gov.ae (Samir Mishra)
Date: Tue Dec 24 06:26:03 2002
Subject: [R] calling R from python (fwd)
Message-ID: <211AD0070D42D1118C7B00A024FF19AE24C03E@AUHEXCH>

After reading the documentation, I believe the problem may be specific to
me. Either way, I'll have to investigate further, and I'll provide more
details next time, if I'm unable to get things to work. In the meantime,
suggestions & tips are always welcome.

Thanks again.
Samir.


-----Original Message-----

I'm working in WinXP. Is it the case that RSPython does not work on Win32
platforms? I believe I read this somewhere... I'd appreciate confirmation.
Either way, I wasn't able to get RSPython to work for me, this was some time
ago, and at that time I was very new to Python.

Thanks.



From ligges at statistik.uni-dortmund.de  Tue Dec 24 12:05:03 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue Dec 24 12:05:03 2002
Subject: [R] Linking R script and a COM application
References: <GDEBIOHLIGJIMKMGJELHMELECKAA.wscherr@itc-world.com>
Message-ID: <3E083FA0.86695C4D@statistik.uni-dortmund.de>


Wolfgang Scherr wrote:
> 
> I am new to R. I run it under MS Windows.
> 
> My goal is to interface an existing R program (500 lines) with a commercial software. That one
> can be used as an OLE-Server. Ideally I would be able to reference and control the R-program
> and components of the other software out of one VBA program. To make it easier, the R script
> has no text or graphics output. I have downloaded http://cran.r-project.org/contrib/extra/dcom/
> but I do not understand:
> 
> ?? what command do I use in VBA to run an existing COM script ??
> 
> Can someone send me a sample of VB code?

Take a look into the R-Excel Interface (by Erich Neuwirth,
http://cran.r-project.org/contrib/extra/excel) which has several
examples, becauses it uses DCOM heavily.

Uwe Ligges



From adrianoazevedofilho at yahoo.com.br  Tue Dec 24 16:27:02 2002
From: adrianoazevedofilho at yahoo.com.br (=?iso-8859-1?q?Adriano=20Azevedo=20Filho?=)
Date: Tue Dec 24 16:27:02 2002
Subject: [R] R-News: congrats and suggestion
Message-ID: <20021224152557.82655.qmail@web10704.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021224/c3c9941d/attachment.pl

From Mike.Prager at noaa.gov  Tue Dec 24 16:36:03 2002
From: Mike.Prager at noaa.gov (Mike Prager)
Date: Tue Dec 24 16:36:03 2002
Subject: [R] Clearing graphics history (Windows)
Message-ID: <5.1.0.14.2.20021224103024.00acf628@hermes.nos.noaa.gov>

Using R 1.6.1 on Windows 2000.

The graphics history stored for the windows() device can be cleared using 
the menu system of rgui for Windows.  Is there a corresponding R function 
that can be called from a script to clear the history?


-- 
Michael Prager, Ph.D.                <Mike.Prager at noaa.gov>
NOAA Center for Coastal Fisheries and Habitat Research
Beaufort, North Carolina  28516
http://shrimp.ccfhrb.noaa.gov/~mprager/



From Zhongming.Yang at cchmc.org  Tue Dec 24 17:45:02 2002
From: Zhongming.Yang at cchmc.org (Zhongming Yang)
Date: Tue Dec 24 17:45:02 2002
Subject: [R] question on plot
Message-ID: <se084894.009@mailx.chmcc.org>

The following commands only draw two lines (blue and red ones) rather
than three lines.
plot(inData[[1]], inData[[2]], type='l', col="blue", );
lines(inData[[1]], mod.data$prepeak, col="green");
lines(inData[[1]], baseline, col="red");

But when I can draw three lines in different diagrams by using 
par(fraw=c(3,1));
plot(inData[[1]], inData[[2]], type='l', col="blue", );
plot(inData[[1]], mod.data$prepeak, type='l', col="green");
plot(inData[[1]], baseline, type='l', col="red");

What's wrong with the first three commands?

Thanks,



From ripley at stats.ox.ac.uk  Tue Dec 24 17:52:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Dec 24 17:52:03 2002
Subject: [R] Clearing graphics history (Windows)
In-Reply-To: <5.1.0.14.2.20021224103024.00acf628@hermes.nos.noaa.gov>
Message-ID: <Pine.LNX.4.31.0212241642270.24627-100000@gannet.stats>

.SavedPlots <- NULL

On Tue, 24 Dec 2002, Mike Prager wrote:

> Using R 1.6.1 on Windows 2000.
>
> The graphics history stored for the windows() device can be cleared using
> the menu system of rgui for Windows.  Is there a corresponding R function
> that can be called from a script to clear the history?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From edd at debian.org  Tue Dec 24 18:05:03 2002
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue Dec 24 18:05:03 2002
Subject: [R] question on plot
In-Reply-To: <se084894.009@mailx.chmcc.org>
References: <se084894.009@mailx.chmcc.org>
Message-ID: <20021224170407.GA11782@sonny.eddelbuettel.com>

On Tue, Dec 24, 2002 at 11:44:02AM -0500, Zhongming Yang wrote:
> The following commands only draw two lines (blue and red ones) rather
> than three lines.
> plot(inData[[1]], inData[[2]], type='l', col="blue", );
> lines(inData[[1]], mod.data$prepeak, col="green");
> lines(inData[[1]], baseline, col="red");
> 
> But when I can draw three lines in different diagrams by using 
> par(fraw=c(3,1));
> plot(inData[[1]], inData[[2]], type='l', col="blue", );
> plot(inData[[1]], mod.data$prepeak, type='l', col="green");
> plot(inData[[1]], baseline, type='l', col="red");
> 
> What's wrong with the first three commands?


From Mike.Prager at noaa.gov  Tue Dec 24 18:39:02 2002
From: Mike.Prager at noaa.gov (Mike Prager)
Date: Tue Dec 24 18:39:02 2002
Subject: [R] Clearing graphics history (Windows)
In-Reply-To: <Pine.LNX.4.31.0212241642270.24627-100000@gannet.stats>
References: <5.1.0.14.2.20021224103024.00acf628@hermes.nos.noaa.gov>
Message-ID: <5.1.0.14.2.20021224123519.02cb1a98@hermes.nos.noaa.gov>

Either I am being especially absent-minded today, or setting    .SavedPlots 
<- NULL   does not work as expected.  Am I missing something, or should I 
send this to R-bugs?


 > .SavedPlots
NULL

yet after bringing up the windows() device, it still has plots 
stored.  Also, after generating additional plots (that are recorded), 
.SavedPlots is still NULL.

...MHP


At 12/24/2002 at 11:46 AM, Brian D. Ripley wrote:
>.SavedPlots <- NULL
>
>On Tue, 24 Dec 2002, Mike Prager wrote:
>
> > Using R 1.6.1 on Windows 2000. [...] Is there a [...] function
> > that can be called from a script to clear the [graphics] history?

-- 
Michael Prager, Ph.D.                <Mike.Prager at noaa.gov>
NOAA Center for Coastal Fisheries and Habitat Research
Beaufort, North Carolina  28516
http://shrimp.ccfhrb.noaa.gov/~mprager/



From ripley at stats.ox.ac.uk  Tue Dec 24 18:53:02 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Dec 24 18:53:02 2002
Subject: [R] Clearing graphics history (Windows)
In-Reply-To: <5.1.0.14.2.20021224123519.02cb1a98@hermes.nos.noaa.gov>
Message-ID: <Pine.LNX.4.31.0212241743590.24787-100000@gannet.stats>

On Tue, 24 Dec 2002, Mike Prager wrote:

> Either I am being especially absent-minded today, or setting    .SavedPlots
> <- NULL   does not work as expected.  Am I missing something, or should I
> send this to R-bugs?

Well, first you have to establish that there *is* a bug in R rather than
in your expectations.  All the clear menu does is

    gsetVar(install(".SavedPlots"), R_NilValue, R_NilValue);

which sets .SavedPlots to NULL in base.  So you may need

> assign(".SavedPlots", NULL, "package:base")

You are missing reading src/gnuwin32/devga.c: I was being far too kind in
reading it for you.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sarthur67 at yahoo.com  Wed Dec 25 05:16:02 2002
From: sarthur67 at yahoo.com (Stephen Arthur)
Date: Wed Dec 25 05:16:02 2002
Subject: Part II Re: [R] read.ssd {foreign} (Reading a permanent SAS d    ataset into an R data frame)
In-Reply-To: <20021224153712.I92795-100000@fellspt.charm.net>
Message-ID: <20021225041525.85252.qmail@web11103.mail.yahoo.com>

Scot,

Thanks for the info.  I will try your code out to
verify the result, but before I do that, will your
code (SAS and R) work with variable names that are
longer than 8 characters long without truncating the
variable name in R?

Also, I wonder about using your method or the PROC
EXPORT method with larger data sets.  The data sets I
will be working with for the most part will not be
that large, but for larger data sets, I do not like to
create the intermediate csv file that PROC EXPORT
creates because I do not like having unused files
stored on my computer.

Thanks,

Stephen

--- Scot W McNary <smcnary at fellspt.charm.net> wrote:
> 
> 
> Stephen,
> 
> I use SAS a lot and have to admit I use the proc
> export version to csv
> format you posted on a regular basis, however, I was
> able to get the
> transport version to work by using the xport engine
> in a libname statement
> as follows (SAS 8.2 on Windows98SE, rw1061):
> 
> 
> # using SAS
> libname check xport 'e:\testing.xpt' ;
> 
> data a;
> 
> do i = 1 to 10 ;
> 	x = 1 + i ;
> 	y = 50/x ;
> 	output;
> 	end;
> 
> run;
> 
> data check.a ;
> set a ;
> 
> run;
> 
> proc print data = check.a ;
> run;
> 
>     The SAS System     15:31 Tuesday, December 24,
> 2002   1
> 
> Obs     I     X       Y
> 
>   1     1     2    25.0000
>   2     2     3    16.6667
>   3     3     4    12.5000
>   4     4     5    10.0000
>   5     5     6     8.3333
>   6     6     7     7.1429
>   7     7     8     6.2500
>   8     8     9     5.5556
>   9     9    10     5.0000
>  10    10    11     4.5455
> 
> # now reading into R
> 
> > library(foreign)
> > test<-read.xport("e:/testing.xpt")
> > test
>     I  X         Y
> 1   1  2 25.000000
> 2   2  3 16.666667
> 3   3  4 12.500000
> 4   4  5 10.000000
> 5   5  6  8.333333
> 6   6  7  7.142857
> 7   7  8  6.250000
> 8   8  9  5.555556
> 9   9 10  5.000000
> 10 10 11  4.545455
> 
> The tricky part for me is having to suspend the
> metaphor of a "libname as
> folder" and think of the libname check as pointing
> to a file:
> "testing.xpt".  It works that way in trying to read
> spss files with the
> spss engine too.  I would assume it's also true for
> using bmdp and osiris
> engines, but I haven't had occasion to use them.
> 
> 
> Hope this helps,
> 
> Scot
> 
> 
> 
> --
>   Scot W. McNary  email:smcnary at charm.net
> 
>



From laurent at cbs.dtu.dk  Wed Dec 25 06:26:03 2002
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Wed Dec 25 06:26:03 2002
Subject: [R] Compiling on IBM AIX. The package 'cluster' causes trouble...
Message-ID: <20021225052533.GB174863731@genome.cbs.dtu.dk>

Hi (and Merry Christmas),

I am trying to compile R on an AIX IBM machine using 
the native C and FORTRAN compilers... and everything
goes smoothly (congratulations for the configure and
make files, this is very nice)... until the pacakge
'cluster' (see dump below)....

Any hint ?


Laurent


1501-510  Compilation successful for file pam.f.
        cc -I/data1/laurent/R-1.6.1/include  -I/usr/local/include     -g -O2 -c  
spannel.c -o spannel.o
        f77     -O2 -c twins.f -o twins.o
** twins   === End of Compilation 1 ===
** averl   === End of Compilation 2 ===
** banag   === End of Compilation 3 ===
** splyt   === End of Compilation 4 ===
** supcl   === End of Compilation 5 ===
** bandy   === End of Compilation 6 ===
1501-510  Compilation successful for file twins.f.
        cc -Wl,-bM:SRE -Wl,-H512 -Wl,-T512 -Wl,-bnoentry -Wl,-bexpall -Wl,-bI:/d 
ata1/laurent/R-1.6.1/etc/R.exp -L/usr/local/lib -o cluster.so clara.o daisy.o fa 
nny.o meet.o mona.o pam.o spannel.o twins.o  -L/usr/local/lib -lreadline -ldl -l 
termcap -lm -lxlf90 -lxlopt -lxlf -lxlomp_ser -lm 
ld: 0711-317 ERROR: Undefined symbol: .meet_
ld: 0711-345 Use the -bloadmap or -bnoquiet option to obtain more information.
make: 1254-004 The error code from the last command is 8.


Stop.
ERROR: compilation failed for package 'cluster'
make: 1254-004 The error code from the last command is 5.



From kana_boy at lycos.com  Wed Dec 25 13:17:02 2002
From: kana_boy at lycos.com (Kanagaraj Krishna)
Date: Wed Dec 25 13:17:02 2002
Subject: [R] Re: Red Hat Linux 8.0 support
Message-ID: <NPKBBBMLNKIDOBAA@mailcity.com>

Hi,
   I'm planning to use SWARM to do the simulation for my project regarding trust in multi agent environment. I'll be using R for data analysis and graph generation. Would i be facing problems doing this in Red Hat 8.0 environment and is there any stability issues? 
Thanks

Regards,
Kana



From Zhongming.Yang at cchmc.org  Wed Dec 25 16:04:03 2002
From: Zhongming.Yang at cchmc.org (Zhongming Yang)
Date: Wed Dec 25 16:04:03 2002
Subject: [R] Is there string class in R?
Message-ID: <se098260.003@mailx.chmcc.org>

Hi,

I want to use R handle hundreds data file. So I want use some string
class to handle the names of data file. 

My idea procedure like:

for i in 1:20
{
   filename = "***" + i +".PRN"
   scan(filename)
   ....
}

Do anyone know how to do this?

Thanks,



From tlumley at u.washington.edu  Wed Dec 25 16:58:02 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed Dec 25 16:58:02 2002
Subject: [R] Compiling on IBM AIX. The package 'cluster' causes trouble...
In-Reply-To: <20021225052533.GB174863731@genome.cbs.dtu.dk>
Message-ID: <Pine.A41.4.44.0212250753590.72470-100000@homer21.u.washington.edu>

On Wed, 25 Dec 2002, Laurent Gautier wrote:

> Hi (and Merry Christmas),
>
> I am trying to compile R on an AIX IBM machine using
> the native C and FORTRAN compilers... and everything
> goes smoothly (congratulations for the configure and
> make files, this is very nice)... until the pacakge
> 'cluster' (see dump below)....
>

In cluster.h and clara.c the Fortran function meet() is coded as meet_()
and the AIX compilers don't append an underscore.  You could remove the
underscore or even better use F77_CALL(meet)

	-thomas



From rpeng at stat.ucla.edu  Wed Dec 25 18:35:03 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Wed Dec 25 18:35:03 2002
Subject: [R] Is there string class in R?
In-Reply-To: <se098260.003@mailx.chmcc.org>
Message-ID: <Pine.GSO.4.10.10212250930270.27563-100000@quetelet.stat.ucla.edu>

See the paste() function.

for(i in 1:N) {
  filename  <-  paste("***", i, ".PRN", sep = "")
  scan(filename)
  ...
}

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Wed, 25 Dec 2002, Zhongming Yang wrote:

> Hi,
> 
> I want to use R handle hundreds data file. So I want use some string
> class to handle the names of data file. 
> 
> My idea procedure like:
> 
> for i in 1:20
> {
>    filename = "***" + i +".PRN"
>    scan(filename)
>    ....
> }
> 
> Do anyone know how to do this?
> 
> Thanks,
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From sarthur67 at yahoo.com  Wed Dec 25 19:39:02 2002
From: sarthur67 at yahoo.com (Stephen Arthur)
Date: Wed Dec 25 19:39:02 2002
Subject: Part II Re: [R] read.ssd {foreign} (Reading a permanent SAS d    ataset into an R data frame)
In-Reply-To: <20021225002957.A99357-100000@fellspt.charm.net>
Message-ID: <20021225183800.472.qmail@web11105.mail.yahoo.com>

Scot,

Thanks for the additional information.  On further
reflection... whether one uses SAS PROC EXPORT or uses
a SAS LIBNAME yourfile XPORT 'yourpathname';
statement, an intermediate file is created in either
case.  As far as experience tells me now, PROC EXPORT
is a far superior choice, because variable names do
not get truncated and you only have to deal with
reading in a simple text file, not a propritary funky
SAS Transport File, which seems to complicate matters
not help them.

My future use of R is still in the works, but my boss
is impressed with the R graphics, so I am going to
continue to press on developing intelligent ways to
read data from different systems in addition to
solving statistical problems.  BTW, I am a novice in
all these approaches and appreciate all the useful
feedback I can get for making these decisions on how
to best use R.

Thanks Scot,

Stephen

--- Scot W McNary <smcnary at fellspt.charm.net> wrote:
> 
> Stephen,
> 
> Good questions. I didn't know the answers so did a
> little experiment.
> The long variable names are apparently a problem for
> the spss engine (see
> highlighted log note--other comments below):
> 
> 
> 41   * using SAS ;
> 42   libname check xport 'e:\testing.xpt' ;
> NOTE: Libref CHECK was successfully assigned as
> follows:
>       Engine:        XPORT
>       Physical Name: e:\testing.xpt
> 43
> 44   data a;
> 45
> 46   do i = 1 to 10 ;
> 47          xnamedlongerthan8char = 1 + i ;
> 48          yalsonamedlongerthan8char =
> 50/xnamedlongerthan8char ;
> 49          output;
> 50          end;
> 51
> 52   run;
> 
> NOTE: The data set WORK.A has 10 observations and 3
> variables.
> NOTE: DATA statement used:
>       real time           0.00 seconds
> 
> 
> 53
> 54   data check.a ;
> 55   set a ;
> 56
> 57   run;
> 
> ERROR: The variable name xnamedlongerthan8char is
> illegal for the version
>           
> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> 6 file CHECK.A.DATA.
> 
> 
> NOTE: The SAS System stopped processing this step
> because of errors.
> WARNING: The data set CHECK.A was only partially
> opened and will not be
> saved.
> NOTE: DATA statement used:
>       real time           0.10 seconds
> 
> Taking a browse of the manual didn't give much
> enlightenment as to why the
> transport engine doesn't like long variable names,
> except that since the
> xport engine can also be used to 'regress' datasets
> from version 8 to
> version 6, which doesn't support long variable
> names.  SAS may have
> decided that version 6 is the lowest common
> denominator for transport
> format files and so all formats devolve to that.
> 
> I wonder if your question about preserving long
> variable names in
> transport format would be worth a post to the SAS-L
> list (or
> comp.soft-sys.sas)?  There's probably a PROC SQL
> solution out there
> somewhere...
> 
> I don't know about the size of the dataset issue
> either, although I rarely
> work with files that either SAS or R would complain
> about.  The long
> variable name issue is problem when it comes to the
> xport engine, which is
> why in retrospect I've stuck with the PROC EXPORT
> solution, since I've
> come to really rely on long variable names in my
> day-to-day work with SAS.
> 
> The PROC EXPORT solution has worked pretty well for
> me so far and doesn't
> seem to take too much extra programming on either
> the SAS or R end, at
> least when I've used it. That actually might be a
> pretty decent
> workaround, except for the extra dataset problem you
> mention.
> 
> Thought I had something that would work for you, but
> turned out not to be
> all that helpful.  Sorry.
> 
> One other thought is that in Frank Harrell's Design
> library there is a
> function called 'sas.get' that will start a sas job
> from within R, write
> out the file from within a dataset, and read it into
> R.  This might get
> around the long variable name truncation since it
> never calls the XPORT
> engine or uses PROC CPORT.  I've not ever used it
> however, so can't
> testify on it's use.  In addition, the call to SAS
> might need some
> configuring.  Frank Harrell often posts to the
> R-help list and has been
> extremely helpful in answering questions, if you
> wanted to try that route
> out and ran into trouble.
> 
> Scot
>



From marc.wildi at bluewin.ch  Thu Dec 26 09:22:03 2002
From: marc.wildi at bluewin.ch (marc wildi)
Date: Thu Dec 26 09:22:03 2002
Subject: [R] Kalman-filtering
Message-ID: <000001c2acb7$be6cf700$e66e03d5@zhwin.ch>


I have a problem involving state space models with a multivariate
observation equation. In other words: the kalman filtering routines as
implemented in the package ts cannot be used since it treats the
univariate case only. My question : does a multivariate kalman filtering
procedure for R exist somewhere in the world?
Where could I perhaps expect to find something like that?

Many thanks

M. Wildi



From Mike at michaelltaylor.com  Thu Dec 26 13:58:02 2002
From: Mike at michaelltaylor.com (Michaell Taylor)
Date: Thu Dec 26 13:58:02 2002
Subject: [R] Is there string class in R?
In-Reply-To: <se098260.003@mailx.chmcc.org>
References: <se098260.003@mailx.chmcc.org>
Message-ID: <200212260757.12734.Mike@michaelltaylor.com>

There are lots of ways you could approach this:

files _ list.files('.')
files _ files[grep('.PRN$',files)]
for (File in files){
	scan(file=File)
	....
}

would provide lots of flexibility - grep could be used to specify 'irregular' 
types of file names.

If you have very structured file names, then your example would be great.

for i in 1:20
{
   filename = paste("***",i,+".PRN",sep='')
   scan(file=filename)
   ....
}


Michaell Taylor

On Wednesday 25 December 2002 10:02 am, Zhongming Yang spoke unto the masses 
thusly:
> Hi,
>
> I want to use R handle hundreds data file. So I want use some string
> class to handle the names of data file.
>
> My idea procedure like:
>
> for i in 1:20
> {
>    filename = "***" + i +".PRN"
>    scan(filename)
>    ....
> }
>
> Do anyone know how to do this?
>
> Thanks,
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
=========================================
Michaell



From tuffek at jippii.fi  Thu Dec 26 23:20:04 2002
From: tuffek at jippii.fi (tuffek@jippii.fi)
Date: Thu Dec 26 23:20:04 2002
Subject: [R] Quotation marks in Strings?
Message-ID: <26938893.1040941153814.JavaMail.tuffek@jippii.fi>

Hello!

How do I construct following string:

s <- " *** "Hello!" *** "

Tuomas

__
Ota itsellesi luotettava kotimainen email http://www.jippii.fi/
Tutustu samalla netin parhaaseen pelipaikkaan JIPPIIGAMESIIN.



From yusuke at koko15.hus.osaka-u.ac.jp  Thu Dec 26 23:56:03 2002
From: yusuke at koko15.hus.osaka-u.ac.jp (MIYAMOTO Yusuke)
Date: Thu Dec 26 23:56:03 2002
Subject: [R] Quotation marks in Strings?
In-Reply-To: <26938893.1040941153814.JavaMail.tuffek@jippii.fi>
References: <26938893.1040941153814.JavaMail.tuffek@jippii.fi>
Message-ID: <20021227075515.566d8b4a.yusuke@koko15.hus.osaka-u.ac.jp>

Hi, 

On Fri, 27 Dec 2002 00:19:13 +0200 (EET)
tuffek at jippii.fi wrote:
> 
> Hello!
> 
> How do I construct following string:
> 
> s <- " *** "Hello!" *** "
> 
> Tuomas

Try the following:

 s <- " *** \"Hello!\" *** "
 cat(s, "\n")

--
 MIYAMOTO, Y.



From bates at stat.wisc.edu  Fri Dec 27 00:03:03 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri Dec 27 00:03:03 2002
Subject: [R] Quotation marks in Strings?
In-Reply-To: <26938893.1040941153814.JavaMail.tuffek@jippii.fi>
References: <26938893.1040941153814.JavaMail.tuffek@jippii.fi>
Message-ID: <6r4r90crjl.fsf@bates4.stat.wisc.edu>

tuffek at jippii.fi writes:

> How do I construct following string:
> s <- " *** "Hello!" *** "

Either

> s <- ' *** "Hello!" *** '
> s
[1] " *** \"Hello!\" *** "
> cat(s)
 *** "Hello!" *** > 

or

> s <- " *** \"Hello!\" *** "
> cat(s)
 *** "Hello!" *** > 

Note that when you print a string all " characters are expressed as \"
but if you use the cat function you get the actual string as it is
stored.



From Mark.Bravington at csiro.au  Fri Dec 27 04:33:03 2002
From: Mark.Bravington at csiro.au (Mark.Bravington@csiro.au)
Date: Fri Dec 27 04:33:03 2002
Subject: [R] Multi-line string constants: proposal
Message-ID: <A8877251964B294BAB5BA1FC58B43FED025B4475@molly.tas.csiro.au>

R's parser complains about syntax like this:

a <- 'one string
that covers several lines'

The parser wants the first line to end with a backslash.

Would it be possible to change the parsing rules to not require the
backslash inside character strings? IE if the line ends before the string
does, and the last character on the line isn't a [single] backslash, then
just auto-add the backslash?

Reasons why this might be useful: [apart from compatibility with Splus 2000,
which doesn't mind the no-backslash syntax-- I don't know about later
versions of S]. When maintaining source code for objects which include large
chunks of text, it is very awkward to have to remember to end each line with
a backslash. I can't just append backslashes to every line, because some of
the source code isn't "inside" a string.

BTW, until and unless the backslash requirement disappears: I couldn't find
any mention of the backslash requirement in the documentation (at least in
what comes with the Windows binary)-- good places might be in the discussion
of character vectors in R-Intro (section 2.6), and in the discussion of the
parser in R-Lang (10.3 I think). Not sure where it might go in the help
system.

cheers
Mark

*******************************

Mark Bravington
CSIRO (CMIS)
PO Box 1538
Castray Esplanade
Hobart
TAS 7001

phone (61) 3 6232 5118
fax (61) 3 6232 5012
Mark.Bravington at csiro.au



From Mark.Bravington at csiro.au  Fri Dec 27 04:43:02 2002
From: Mark.Bravington at csiro.au (Mark.Bravington@csiro.au)
Date: Fri Dec 27 04:43:02 2002
Subject: [R] Wish list: add an "until" or "EOF.marker" parameter to scan & rea
 dLines
Message-ID: <A8877251964B294BAB5BA1FC58B43FED025B4476@molly.tas.csiro.au>

A bit late for Santa, but on my wish-list nevertheless:

is there any chance that "scan" and "readLines" could be extended to take a
parameter "until" or "EOF.marker", which would be a character string that
(if encountered while reading) would cause the reading to stop, just as if
an end-of-file had been found? [But leaving a connection open, so that
subsequent calls could read the rest of the file.] Compatibility could be
ensured by making "until" default to as.character( NA), which can never be
encountered. If the "until" string isn't encountered when reading, then
reading continues until a real end-of-file (or the "n" parameter is
satisfied).

This would be useful in all sorts of contexts; one example is in processing
a single data file that's made up of multiple segments each of different
formats. 

cheers
Mark

*******************************

Mark Bravington
CSIRO (CMIS)
PO Box 1538
Castray Esplanade
Hobart
TAS 7001

phone (61) 3 6232 5118
fax (61) 3 6232 5012
Mark.Bravington at csiro.au



From ozric at web.de  Fri Dec 27 11:25:03 2002
From: ozric at web.de (Christian Schulz)
Date: Fri Dec 27 11:25:03 2002
Subject: [R] RSvgDevice & sapply(plotmeans)
Message-ID: <001901c2ad91$8eb9a730$c5b607d5@c5c9i0>

Hi,
anybody know why this not works for several
plots ?
When i set onefile=T the plots are stacked one about another
, onefile=F only the first plot is shown in AllbusMeansPlots.svg.
[h2 is a data.frame]
......hist and sapply works for several plots  nice with RSvgDevice !
Maybe setting the title after apply is a problem, but until yet i didn't
found a better solution ?

library(RSvgDevice)
library(gregmisc)
devSVG(file = "AllbusMeanPlots.svg", width = 10, height = 8,
       bg = "lightblue", fg = "white", onefile=T, xmlHeader=TRUE)
#par(bg="lightblue",ann=T)
plt <- function(x) {
   plotmeans(h2[,x] ~
h2$V174,ylab=names(h2)[x],xlab="InglehartIndex",mean.labels=T,
   connect=list(1:2,3:4,4:5),ccol="red",pch=7,barwidth=1,barcol="black")
   title("Mittelwert-Plots Allbus 1998")
   }
sapply((2:ncol(h2)),plt)
dev.off()


Thanks for advance
christian



From ozric at web.de  Fri Dec 27 14:52:03 2002
From: ozric at web.de (Christian Schulz)
Date: Fri Dec 27 14:52:03 2002
Subject: [R] RSvgDevice & sapply(plotmeans)
References: <001901c2ad91$8eb9a730$c5b607d5@c5c9i0>
Message-ID: <001001c2adae$7853ae60$7b3c07d5@c5c9i0>

...hist didn't  works,too. 
Wrong remind, but with pdf() the sapply functions work !
christian

----- Original Message ----- 
From: "Christian Schulz" <ozric at web.de>
To: <r-help at stat.math.ethz.ch>
Cc: <jake.luciani at riskmetrics.com>
Sent: Friday, December 27, 2002 11:20 AM
Subject: [R] RSvgDevice & sapply(plotmeans)


> Hi,
> anybody know why this not works for several
> plots ?
> When i set onefile=T the plots are stacked one about another
> , onefile=F only the first plot is shown in AllbusMeansPlots.svg.
> [h2 is a data.frame]
> ......hist and sapply works for several plots  nice with RSvgDevice !
> Maybe setting the title after apply is a problem, but until yet i didn't
> found a better solution ?
> 
> library(RSvgDevice)
> library(gregmisc)
> devSVG(file = "AllbusMeanPlots.svg", width = 10, height = 8,
>        bg = "lightblue", fg = "white", onefile=T, xmlHeader=TRUE)
> #par(bg="lightblue",ann=T)
> plt <- function(x) {
>    plotmeans(h2[,x] ~
> h2$V174,ylab=names(h2)[x],xlab="InglehartIndex",mean.labels=T,
>    connect=list(1:2,3:4,4:5),ccol="red",pch=7,barwidth=1,barcol="black")
>    title("Mittelwert-Plots Allbus 1998")
>    }
> sapply((2:ncol(h2)),plt)
> dev.off()
> 
> 
> Thanks for advance
> christian
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Fri Dec 27 15:09:02 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Dec 27 15:09:02 2002
Subject: [R] Wish list: add an "until" or "EOF.marker" parameter to scan
 & rea dLines
In-Reply-To: <A8877251964B294BAB5BA1FC58B43FED025B4476@molly.tas.csiro.au>
Message-ID: <Pine.LNX.4.31.0212271402580.7298-100000@gannet.stats>

Why is this necessary?  There are plenty of ways to do this already via
connections, e.g copy line-by-line to an anonymous file connection and
then scan from that.

Yes, it is useful, and that's why people already supplied you with a more
general tool, namely connections.  Please do look at the internals of scan
before suggesting complicating it further: it is already close to
unmaintainable.

I don't think R-help is the place for wishlist items: there is R-devel and
the R-bugs list has a wishlist section too (but please note that this gets
little action due to the perceived usefulness of the wishes).

On Fri, 27 Dec 2002 Mark.Bravington at csiro.au wrote:

> A bit late for Santa, but on my wish-list nevertheless:
>
> is there any chance that "scan" and "readLines" could be extended to take a
> parameter "until" or "EOF.marker", which would be a character string that
> (if encountered while reading) would cause the reading to stop, just as if
> an end-of-file had been found? [But leaving a connection open, so that
> subsequent calls could read the rest of the file.] Compatibility could be
> ensured by making "until" default to as.character( NA), which can never be
> encountered. If the "until" string isn't encountered when reading, then
> reading continues until a real end-of-file (or the "n" parameter is
> satisfied).
>
> This would be useful in all sorts of contexts; one example is in processing
> a single data file that's made up of multiple segments each of different
> formats.
>
> cheers
> Mark
>
> *******************************
>
> Mark Bravington
> CSIRO (CMIS)
> PO Box 1538
> Castray Esplanade
> Hobart
> TAS 7001
>
> phone (61) 3 6232 5118
> fax (61) 3 6232 5012
> Mark.Bravington at csiro.au
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wscherr at itc-world.com  Fri Dec 27 16:39:02 2002
From: wscherr at itc-world.com (Wolfgang Scherr)
Date: Fri Dec 27 16:39:02 2002
Subject: [R] Linking R script and a COM application
In-Reply-To: <1040718488.3e081a98c3411@my.uq.edu.au>
Message-ID: <GDEBIOHLIGJIMKMGJELHIELJCKAA.wscherr@itc-world.com>

Andrew,

thank you for your response. However, the Oregon Department of Transportation has taken the
decision to go with R for some particular applications. Seems, that they like the open code
idea. And I am only an employee of a small consultant, so I can hardly change their path.

Wolfgang


> -----Original Message-----
> From: ANDREW WARD [mailto:s195404 at student.uq.edu.au]
> Sent: Tuesday, December 24, 2002 3:28 AM
> To: wscherr at itc-world.com
> Subject: Re: [R] Linking R script and a COM application
>
>
> Wolfgang,
>
> While some of this may be possible in R, S-PLUS is much better at doing this
> sort of thing. I suspect that Windows connectivity is a low priority for the
> (volunteer) developers of R. The commercial publishers of S-PLUS, on the other
> hand, have the resources to do this. R code can usually be transferred fairly
> easily to S-PLUS, and the features you want are available and documented
> there. Is using S-PLUS an option?
>
> Regards,
>
> Andrew C. Ward
>
> CAPE Centre
> Department of Chemical Engineering
> The University of Queensland
> Brisbane Qld 4072 Australia
> andreww at cheque.uq.edu.au
>
>
> Quoting Wolfgang Scherr <wscherr at itc-world.com>:
>
> > I am new to R. I run it under MS Windows.
> >
> > My goal is to interface an existing R program (500 lines) with a commercial
> > software. That one
> > can be used as an OLE-Server. Ideally I would be able to reference and
> > control the R-program
> > and components of the other software out of one VBA program. To make it
> > easier, the R script
> > has no text or graphics output. I have downloaded
> > http://cran.r-project.org/contrib/extra/dcom/
> > but I do not understand:
> >
> > ?? what command do I use in VBA to run an existing COM script ??
> >
> > Can someone send me a sample of VB code?
> >
> > Wolfgang Scherr
> > Innovative Transportation Concepts, Inc.
> > 302-654-4384 phone
> > wscherr at itc-world.com
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>



From Timur.Elzhov at jinr.ru  Fri Dec 27 16:54:03 2002
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Fri Dec 27 16:54:03 2002
Subject: [R] handling objects plotted on x11 device
Message-ID: <20021227155752.GA2504@pcf004.jinr.ru>

Dear R masters!

Is it possible to handle objects have already been plotted on
x11 device?  For example, I wrote the text on the wrong place.
Can I remove it, or I have to re-draw all the canvas, again?

Thank you!

--
WBR,
Timur.



From ligges at statistik.uni-dortmund.de  Fri Dec 27 17:08:02 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri Dec 27 17:08:02 2002
Subject: [R] handling objects plotted on x11 device
In-Reply-To: <20021227155752.GA2504@pcf004.jinr.ru>
References: <20021227155752.GA2504@pcf004.jinr.ru>
Message-ID: <3E0C7AB0.40202@statistik.uni-dortmund.de>

Timur Elzhov wrote:
> Dear R masters!
> 
> Is it possible to handle objects have already been plotted on
> x11 device?  For example, I wrote the text on the wrong place.
> Can I remove it, or I have to re-draw all the canvas, again?

The latter.

Uwe Ligges



From Timur.Elzhov at jinr.ru  Fri Dec 27 17:57:03 2002
From: Timur.Elzhov at jinr.ru (Timur Elzhov)
Date: Fri Dec 27 17:57:03 2002
Subject: [R] Getting graphs into LaTeX
In-Reply-To: <3F45FF8B.9060703@arcriswell.com>
References: <3F45FF8B.9060703@arcriswell.com>
Message-ID: <20021227170031.GA2608@pcf004.jinr.ru>

On Fri, Aug 22, 2003 at 06:33:31PM +0700, Andrew Criswell wrote:

> Thanks to all who responded to my inquiry.  Bingo, it works!
> 
> I revised the code as follows and it works fine:
> 
> For the R code:
> _______________________________________________
> pdf()
BTW, you can create eps-files only, as usual, and then convert
them to the pdf-files on demand, by the `epstopdf' program
(available on CTAN, calls ghostscript for transform).
You do not need touch R code in the case.


--
WBR,
Timur.



From ripley at stats.ox.ac.uk  Fri Dec 27 20:11:02 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri Dec 27 20:11:02 2002
Subject: [R] handling objects plotted on x11 device
In-Reply-To: <3E0C7AB0.40202@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.31.0212271904410.7425-100000@gannet.stats>

On Fri, 27 Dec 2002, Uwe Ligges wrote:

> Timur Elzhov wrote:
> >
> > Is it possible to handle objects have already been plotted on
> > x11 device?  For example, I wrote the text on the wrong place.
> > Can I remove it, or I have to re-draw all the canvas, again?
>
> The latter.

You can re-plot the text in background colour (col=0) *provided that is
not transparent*  (when you can use the canvas colour) and provided it did
not overlap other graphics.

In practice, Uwe's suggestion is much the easiest one.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Richard.Rowe at jcu.edu.au  Sat Dec 28 02:10:03 2002
From: Richard.Rowe at jcu.edu.au (Richard Rowe)
Date: Sat Dec 28 02:10:03 2002
Subject: [R] handling objects plotted on x11 device
In-Reply-To: <Pine.LNX.4.31.0212271904410.7425-100000@gannet.stats>
References: <3E0C7AB0.40202@statistik.uni-dortmund.de>
Message-ID: <5.0.0.25.1.20021228110202.03969870@pop.jcu.edu.au>

At 19:06 27/12/02 +0000, Brian Ripley wrote:
>On Fri, 27 Dec 2002, Uwe Ligges wrote:
>
> > Timur Elzhov wrote:
> > >
> > > Is it possible to handle objects have already been plotted on
> > > x11 device?  For example, I wrote the text on the wrong place.
> > > Can I remove it, or I have to re-draw all the canvas, again?
> >
> > The latter.
>
>You can re-plot the text in background colour (col=0) *provided that is
>not transparent*  (when you can use the canvas colour) and provided it did
>not overlap other graphics.
>
>In practice, Uwe's suggestion is much the easiest one.

And almost totally painless if you use (short) scripts rather than the 
keyboard to generate the R activity,

Richard Rowe



Richard Rowe
Senior Lecturer
Department of Zoology and Tropical Ecology, James Cook University
Townsville, Queensland 4811, Australia
fax (61)7 47 25 1570
phone (61)7 47 81 4851
e-mail: Richard.Rowe at jcu.edu.au
http://www.jcu.edu.au/school/tbiol/zoology/homepage.html



From miranda at di.fct.unl.pt  Sat Dec 28 07:48:03 2002
From: miranda at di.fct.unl.pt (Don Eduardo Miranda)
Date: Sat Dec 28 07:48:03 2002
Subject: [R] graph clustering
Message-ID: <007901c2ae3d$02287880$f801000a@pong>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20021228/86df21a5/attachment.pl

From rjporter at mindspring.com  Sun Dec 29 20:53:02 2002
From: rjporter at mindspring.com (Bob Porter)
Date: Sun Dec 29 20:53:02 2002
Subject: [R] lowess + turnpoints = doubling integers?
Message-ID: <01ce01c2af73$c941aea0$6501a8c0@HydePark>

Happy New Year, r-helpers!

I am using lowess to smooth a scatter plot,
xx<-lowess(xinput,f=.04)  #defaults for other args
 followed by
turnpoints(xx$y) #defaults for other args

I plot the smoothed result as well as turnpoints (using yy$tppos) on top of raw
data plot.
Result is exactly as expected, graphically.

For another purpose, I calcuate the difference between turnpoints (representing
time intervals between turnspoints in my applicaiton), e.g.

aduration[j]<-yy$tppos[i+1]-yytppos[i]

This also appears to work as expected, HOWEVER, a typical list of such
differences looks like:
22,33,22,11,33,44,33,33,11,33,44,66,33,22,.........
there are, in some instances, three digit measure such as 110 or 106, etc. but
the double-digit measures, although of the proper magnitude, seem to always be
double integers 11 to 99.

The double-integer results are found with f=.04 and total length of vector of
1200.  With vector of length 1100 (same input data), the results are NOT
double-integer but are ALWAYS (?) of the form x0, e.g.
70,50,50,70,100,40............  The magnitude of these latter results (22 vs 70,
for example) is evidently due to the change in the smoothing span from .04*1200
to .04*1100, but I am mystified why the results have double-integers in the
first case, and terminal zeros in the second.

My project involves applying these functions in a batch run for dozens of data
sets so I want to understand more about what is going on that yeilds these
strange double-integers or zero-terminating values.

Thanks,

Bob Porter, Tampa



From S.G.Pickering at bath.ac.uk  Sun Dec 29 22:18:03 2002
From: S.G.Pickering at bath.ac.uk (S G Pickering)
Date: Sun Dec 29 22:18:03 2002
Subject: [R] R on the Zaurus
Message-ID: <Pine.GSO.4.44.0212292111180.22673-100000@amos.bath.ac.uk>

Dear All,

I have a working (in so far as NAs are handled correctly)
version of R running on the Zaurus.
The problem was not ieee 754 compliance but rather the fact that the
configure script did not realise that the Z had a bigendian processor.

I'll post a link, etc. tomorrow on the Zaurus forum for those who may be
interested (http://www.zaurus.com/dev/board/) in downloading a copy.

Regards,


Simon



From wolski at molgen.mpg.de  Sun Dec 29 23:20:03 2002
From: wolski at molgen.mpg.de (Eryk Wolski)
Date: Sun Dec 29 23:20:03 2002
Subject: [R] methods package intro.. tutorial?
Message-ID: <Pine.OSF.4.31.0212292315220.2452-100000@molgix.molgen.mpg.de>

Have seen some time ago an intro to the methods package somewhere on the
net. But cant find it anymore?
Where to find current sources for learning how to use it?

Happy new year
/EW.



From p.dalgaard at biostat.ku.dk  Sun Dec 29 23:42:02 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Sun Dec 29 23:42:02 2002
Subject: [R] R on the Zaurus
In-Reply-To: <Pine.GSO.4.44.0212292111180.22673-100000@amos.bath.ac.uk>
References: <Pine.GSO.4.44.0212292111180.22673-100000@amos.bath.ac.uk>
Message-ID: <x2r8c0fnxr.fsf@biostat.ku.dk>

S G Pickering <S.G.Pickering at bath.ac.uk> writes:

> Dear All,
> 
> I have a working (in so far as NAs are handled correctly)
> version of R running on the Zaurus.
> The problem was not ieee 754 compliance but rather the fact that the
> configure script did not realise that the Z had a bigendian processor.
> 
> I'll post a link, etc. tomorrow on the Zaurus forum for those who may be
> interested (http://www.zaurus.com/dev/board/) in downloading a copy.

Wheee, thanks! I'm sure other people with ARM processors will be happy
if we can get this wrinkle ironed out.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From bates at stat.wisc.edu  Mon Dec 30 00:04:03 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon Dec 30 00:04:03 2002
Subject: [R] methods package intro.. tutorial?
In-Reply-To: <Pine.OSF.4.31.0212292315220.2452-100000@molgix.molgen.mpg.de>
References: <Pine.OSF.4.31.0212292315220.2452-100000@molgix.molgen.mpg.de>
Message-ID: <6radiotoli.fsf@bates4.stat.wisc.edu>

Eryk Wolski <wolski at molgen.mpg.de> writes:

> Have seen some time ago an intro to the methods package somewhere on the
> net. But cant find it anymore?

You are probably thinking of http://www.omegahat.org/RSMethods/ and
the file http://www.omegahat.org/RSMethods/Intro.pdf



From rpeng at stat.ucla.edu  Mon Dec 30 02:31:02 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Mon Dec 30 02:31:02 2002
Subject: [R] Writing packages with `methods' package
Message-ID: <Pine.GSO.4.10.10212291718020.2197-100000@quetelet.stat.ucla.edu>

I'm trying to write a package which uses classes/methods as defined in the
`methods' package.  I have a single .R file which defines the class and
various methods for that class.  At the top of the file I have

require(methods)

and then 

setClass("myclass", ...)
setGeneric("intersect")
setMethod("intersect", "myclass", function(x,y) ...)

I noticed that when I build the package and subsequently load it via
library(), the methods show up in the global workspace, which is not quite
what I wanted.

In general, is there any documentation on building packages with the
`methods' package (i.e. is it any different from building packages without
`methods'?) or perhaps an R-help thread I should look for?

In short, how should I setup my package so that my methods do not show up
in the global workspace?  

Thanks,

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng



From rossini at blindglobe.net  Mon Dec 30 02:39:03 2002
From: rossini at blindglobe.net (A.J. Rossini)
Date: Mon Dec 30 02:39:03 2002
Subject: [R] Writing packages with `methods' package
In-Reply-To: <Pine.GSO.4.10.10212291718020.2197-100000@quetelet.stat.ucla.edu> (Roger
 Peng's message of "Sun, 29 Dec 2002 17:27:28 -0800 (PST)")
References: <Pine.GSO.4.10.10212291718020.2197-100000@quetelet.stat.ucla.edu>
Message-ID: <87fzsg8f2p.fsf@jeeves.blindglobe.net>

Take a look at the Bioconductor packages for some examples,
i.e. Biobase and affy, but others as well.

best,
-tony

>>>>> "roger" == Roger Peng <rpeng at stat.ucla.edu> writes:

    roger> I'm trying to write a package which uses classes/methods as
    roger> defined in the `methods' package.  I have a single .R file
    roger> which defines the class and various methods for that class.
    roger> At the top of the file I have

    roger> require(methods)

    roger> and then

    roger> setClass("myclass", ...)  setGeneric("intersect")
    roger> setMethod("intersect", "myclass", function(x,y) ...)

    roger> I noticed that when I build the package and subsequently
    roger> load it via library(), the methods show up in the global
    roger> workspace, which is not quite what I wanted.

    roger> In general, is there any documentation on building packages
    roger> with the `methods' package (i.e. is it any different from
    roger> building packages without `methods'?) or perhaps an R-help
    roger> thread I should look for?

    roger> In short, how should I setup my package so that my methods
    roger> do not show up in the global workspace?

    roger> Thanks,

    roger> -roger _______________________________ UCLA Department of
    roger> Statistics rpeng at stat.ucla.edu
    roger> http://www.stat.ucla.edu/~rpeng

    roger> ______________________________________________
    roger> R-help at stat.math.ethz.ch mailing list
    roger> http://www.stat.math.ethz.ch/mailman/listinfo/r-help


-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my tuesday/wednesday/friday locations are completely unpredictable.)



From enpsgp at bath.ac.uk  Mon Dec 30 15:32:05 2002
From: enpsgp at bath.ac.uk (Simon Pickering)
Date: Mon Dec 30 15:32:05 2002
Subject: [R] R on the Zaurus link
Message-ID: <OFEJKEHLCPGGDMAIINLLIEDICCAA.enpsgp@bath.ac.uk>

Hello All,

The link to the binary & installation instructions (tar.gz binary not an ipk
I'm afraid) is as follows: http://students.bath.ac.uk/enpsgp/Zaurus/#R

It eventually dawned on me that the WORDS_BIGENDIAN define (or lack thereof)
was causing the problems (after testing ieee NaN compliance that is).

When cross-compiling it's probably fair enough that the configure script
can't work out what the endianness should be, however the same thing
happened (WORDS_BIGENDIAN not defined) when compiling on an ARM machine (one
of the iPAQ skiff cluster machines. See
http://www.handhelds.org/z/wiki/SkiffCluster)

The following is the section of the config.log pertaining to determining
endianness, for those who may want to try to fix/alter the configure script
(from the ARM iPAQ machine):

=============================================================
configure:12298: checking whether byte ordering is bigendian
configure:12328: gcc -c -g -O2 -I/usr/local/include conftest.c >&5
configure:12331: $? = 0
configure:12334: test -s conftest.o
configure:12337: $? = 0
configure:12364: gcc -c -g -O2 -I/usr/local/include conftest.c >&5
configure: In function `main':
configure:12354: `not' undeclared (first use in this function)
configure:12354: (Each undeclared identifier is reported only once
configure:12354: for each function it appears in.)
configure:12354: parse error before `big'
configure:12367: $? = 1
configure: failed program was:
#line 12340 "configure"
#include "confdefs.h"
#include <sys/types.h>
#include <sys/param.h>

#ifdef F77_DUMMY_MAIN
#  ifdef __cplusplus
     extern "C"
#  endif
   int F77_DUMMY_MAIN() { return 1; }
#endif
int
main ()
{
#if BYTE_ORDER != BIG_ENDIAN
 not big endian
#endif

  ;
  return 0;
}
configure:12481: result: no
=============================================================

Might be something to do with the /sys/ tacked on the front of the types.h
and param.h includes?

In any case if you just want it to compile then use something like the
following:

$ ./configure --host=arm-linux --build=i686-mandrake-linux
ac_cv_c_bigendian=yes

I've not tested the X parts of R yet, nor have I done anything else other
than making sure that NAs are handled correctly.

Happy new year to you all,


Simon

--------------------------------------------
Simon Pickering MEng
Dept. of Mechanical Engineering
University of Bath
Bath, BA2 7AY, UK

Tel: +44 (0)1225 383314
Fax: +44 (0)1225 386928
--------------------------------------------



From p.dalgaard at biostat.ku.dk  Mon Dec 30 16:31:06 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon Dec 30 16:31:06 2002
Subject: [R] R on the Zaurus link
In-Reply-To: <OFEJKEHLCPGGDMAIINLLIEDICCAA.enpsgp@bath.ac.uk>
References: <OFEJKEHLCPGGDMAIINLLIEDICCAA.enpsgp@bath.ac.uk>
Message-ID: <x2isxbfrrc.fsf@biostat.ku.dk>

Simon Pickering <enpsgp at bath.ac.uk> writes:

> #include "confdefs.h"
> #include <sys/types.h>
> #include <sys/param.h>
> 
> #ifdef F77_DUMMY_MAIN
> #  ifdef __cplusplus
>      extern "C"
> #  endif
>    int F77_DUMMY_MAIN() { return 1; }
> #endif
> int
> main ()
> {
> #if BYTE_ORDER != BIG_ENDIAN
>  not big endian
> #endif
> 
>   ;
>   return 0;
> }
> configure:12481: result: no
> =============================================================
> 
> Might be something to do with the /sys/ tacked on the front of the types.h
> and param.h includes?

I don't think so, but the test looks dubious: at least on i386-Linux, it is 
__BYTE_ORDER and __BIG_ENDIAN, unless you include endian.h.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jake.luciani at riskmetrics.com  Mon Dec 30 19:46:05 2002
From: jake.luciani at riskmetrics.com (T Jake Luciani)
Date: Mon Dec 30 19:46:05 2002
Subject: [R] Re: RSvgDevice & sapply(plotmeans)
In-Reply-To: <001901c2ad91$8eb9a730$c5b607d5@c5c9i0>
References: <001901c2ad91$8eb9a730$c5b607d5@c5c9i0>
Message-ID: <1041256001.13462.1.camel@limbic>

I'll try fixing the problem shortly.

Thanks for the feedback.

Jake

On Fri, 2002-12-27 at 05:20, Christian Schulz wrote:
> Hi,
> anybody know why this not works for several
> plots ?
> When i set onefile=T the plots are stacked one about another
> , onefile=F only the first plot is shown in AllbusMeansPlots.svg.
> [h2 is a data.frame]
> ......hist and sapply works for several plots  nice with RSvgDevice !
> Maybe setting the title after apply is a problem, but until yet i didn't
> found a better solution ?
> 
> library(RSvgDevice)
> library(gregmisc)
> devSVG(file = "AllbusMeanPlots.svg", width = 10, height = 8,
>        bg = "lightblue", fg = "white", onefile=T, xmlHeader=TRUE)
> #par(bg="lightblue",ann=T)
> plt <- function(x) {
>    plotmeans(h2[,x] ~
> h2$V174,ylab=names(h2)[x],xlab="InglehartIndex",mean.labels=T,
>    connect=list(1:2,3:4,4:5),ccol="red",pch=7,barwidth=1,barcol="black")
>    title("Mittelwert-Plots Allbus 1998")
>    }
> sapply((2:ncol(h2)),plt)
> dev.off()
> 
> 
> Thanks for advance
> christian



From Ngayee.Law at celeradiagnostics.com  Mon Dec 30 23:07:02 2002
From: Ngayee.Law at celeradiagnostics.com (Ngayee J Law)
Date: Mon Dec 30 23:07:02 2002
Subject: [R] Check whether a file exits ...
Message-ID: <OF655D6F20.A65B7088-ON88256C9F.00794BF9@pe-c.com>

Hello all,

I need to write a R program that checks whether a file exists in the
directory. Any easy ways
to do that? Thanks!

- Jacqueline



From jgentry at jimmy.harvard.edu  Mon Dec 30 23:17:06 2002
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Mon Dec 30 23:17:06 2002
Subject: [R] Check whether a file exits ...
In-Reply-To: <OF655D6F20.A65B7088-ON88256C9F.00794BF9@pe-c.com>
Message-ID: <Pine.SOL.4.20.0212301709260.6952-100000@santiam.dfci.harvard.edu>

> I need to write a R program that checks whether a file exists in the
> directory. Any easy ways
> to do that? Thanks!

file.exists()



From p.dalgaard at biostat.ku.dk  Mon Dec 30 23:23:03 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon Dec 30 23:23:03 2002
Subject: [R] Check whether a file exits ...
In-Reply-To: <OF655D6F20.A65B7088-ON88256C9F.00794BF9@pe-c.com>
References: <OF655D6F20.A65B7088-ON88256C9F.00794BF9@pe-c.com>
Message-ID: <x2adinf8pd.fsf@biostat.ku.dk>

"Ngayee J Law" <Ngayee.Law at celeradiagnostics.com> writes:

> Hello all,
> 
> I need to write a R program that checks whether a file exists in the
> directory. Any easy ways
> to do that? Thanks!

Look up file.exists() (and possibly file.path() too)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From till.baumgaertel at epost.de  Tue Dec 31 02:55:03 2002
From: till.baumgaertel at epost.de (Till Baumgaertel)
Date: Tue Dec 31 02:55:03 2002
Subject: [R] Selecting variables from a data.frame
Message-ID: <3E10B8A700000141@PPD27101.epost.de>

Hi all,

currently I'm working with physical data stored in a data.frame. I have
N observations, typically 100-300 per data set.
Each row in a set holds M (typically 2100) variables which represent a curve.

For linear discriminant analysis I chose first to do a wavelet transform
(because M >> N) and then feed the transformed data (of level L) in lda.

This works fine (e.g. error < 0.01) if I take all variables or a subset
of consecutive variables. But now I want to take only the even numbered
variables (1st, 3rd, 5th,...) and then do the wavelet transform.

My question: which is the most elegant way to select the desired variables?


Or in general: I'd like to select 2^m variables starting with the n-th variable
of the original set with a distinct distance d. If m==3, n==5 and d==3 this
should get me the following variables:
5, 8, 11, 14, 17, 20, 23, 26
And for n==1 d==2 we would get the first problem.

I would appreciate your help very much!

Thanks,
Till


________________________________________
Abos online bestellen. Oder Leser werben und Pr?mie aussuchen. http://www.epost.de/aboservice



From laurent at cbs.dtu.dk  Tue Dec 31 03:39:02 2002
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Tue Dec 31 03:39:02 2002
Subject: [R] Selecting variables from a data.frame
In-Reply-To: <3E10B8A700000141@PPD27101.epost.de>
References: <3E10B8A700000141@PPD27101.epost.de>
Message-ID: <20021231023841.GC211294544@genome.cbs.dtu.dk>

On Tue, Dec 31, 2002 at 02:33:37AM +0100, Till Baumgaertel wrote:
> 
> My question: which is the most elegant way to select the desired variables?
> 
> 
> Or in general: I'd like to select 2^m variables starting with the n-th variable
> of the original set with a distinct distance d. If m==3, n==5 and d==3 this
> should get me the following variables:
> 5, 8, 11, 14, 17, 20, 23, 26

seq(n, n + d * (2^m - 1), by=d) 

seems to generate the index vector you want



Hopin' it helps,


Laurent



From phgrosjean at sciviews.org  Tue Dec 31 10:57:02 2002
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Tue Dec 31 10:57:02 2002
Subject: [R] lowess + turnpoints = doubling integers?
In-Reply-To: <01ce01c2af73$c941aea0$6501a8c0@HydePark>
Message-ID: <MABBLJDICACNFOLGIHJOCEDBDCAA.phgrosjean@sciviews.org>

Bob,
Happy New Year. Could you, please, cook an example so as we could spot the
problem?
Best,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oc?anologique
 ) ) ) ) )      BP 28
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.16, fax: +33.4.93.76.38.34
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................



-----Original Message-----
From: r-help-admin at stat.math.ethz.ch
[mailto:r-help-admin at stat.math.ethz.ch]On Behalf Of Bob Porter
Sent: dimanche 29 d?cembre 2002 8:52
To: r-help at stat.math.ethz.ch
Subject: [R] lowess + turnpoints = doubling integers?


Happy New Year, r-helpers!

I am using lowess to smooth a scatter plot,
xx<-lowess(xinput,f=.04)  #defaults for other args
 followed by
turnpoints(xx$y) #defaults for other args

I plot the smoothed result as well as turnpoints (using yy$tppos) on top of
raw
data plot.
Result is exactly as expected, graphically.

For another purpose, I calcuate the difference between turnpoints
(representing
time intervals between turnspoints in my applicaiton), e.g.

aduration[j]<-yy$tppos[i+1]-yytppos[i]

This also appears to work as expected, HOWEVER, a typical list of such
differences looks like:
22,33,22,11,33,44,33,33,11,33,44,66,33,22,.........
there are, in some instances, three digit measure such as 110 or 106, etc.
but
the double-digit measures, although of the proper magnitude, seem to always
be
double integers 11 to 99.

The double-integer results are found with f=.04 and total length of vector
of
1200.  With vector of length 1100 (same input data), the results are NOT
double-integer but are ALWAYS (?) of the form x0, e.g.
70,50,50,70,100,40............  The magnitude of these latter results (22 vs
70,
for example) is evidently due to the change in the smoothing span from
.04*1200
to .04*1100, but I am mystified why the results have double-integers in the
first case, and terminal zeros in the second.

My project involves applying these functions in a batch run for dozens of
data
sets so I want to understand more about what is going on that yeilds these
strange double-integers or zero-terminating values.

Thanks,

Bob Porter, Tampa

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From rjporter at mindspring.com  Tue Dec 31 13:22:02 2002
From: rjporter at mindspring.com (Bob Porter)
Date: Tue Dec 31 13:22:02 2002
Subject: [R] lowess + turnpoints = doubling integers?
Message-ID: <00ce01c2b0c7$2be51890$6501a8c0@HydePark>

Hello Philippe:

Thank you for your interest.  I have explored this and it appears to happen with
sequences in which small differences between successive occurrences, somewhere
in
turnpoints, but I have not tracked it down exactly.  The following is a cobbled
together demo based on the original code.  m b, Bob

***********************************************
foo<-rnorm(n=1200,mean=23.02, sd=34.14) #based on stat of actual data
xx<-lowess(foo,f=.04) #note that changing f or length of foo (equivalent,
actually) changes the result
yy<- turnpoints(xx$y)

onsets<-seq(1:yy$nturns)
peaks<-seq(1:yy$nturns)
offsets<-seq(1:yy$nturns)
ievent<-1


istart<-1
if(yy$firstispeak) istart<-2 #always start with a pit
i<-istart
adj<-1 #dummy adjustment, means something in original code

while(i<=yy$nturns-istart-adj)
    {
            # points are processed in sets of three pit-peak-pit events,
starting with a pit

        onsets[ievent]<-yy$tppos[i+1]-yy$tppos[i]#i is the onset point for this
event, this calculates its duration
        peaks[ievent]<-yy$tppos[i+1] #i+1 is the location of the peak point
        offsets[ievent]<-yy$tppos[i+2]-yy$tppos[i+1] #calculate the offset
duration but subtracting peak point from offset point
        i<-i+2 #set i to the offset point WHICH IS ALSO THE ONSET POINT FOR THE
NEXT EVENT
        ievent<-ievent+1
        #cat(i,"  ",ievent,"// ")
    }

events<-onsets+offsets

cat("\n",events,"events n=", nevents,"\n")
cat(onsets,"onsets\n")
cat(offsets,"offsets\n","\n")
*****************************************

----- Original Message -----
From: "Philippe Grosjean" <phgrosjean at sciviews.org>
To: "Bob Porter" <rjporter at mindspring.com>
Cc: <r-help at stat.math.ethz.ch>
Sent: Tuesday, December 31, 2002 4:55 AM
Subject: RE: [R] lowess + turnpoints = doubling integers?


> Bob,
> Happy New Year. Could you, please, cook an example so as we could spot the
> problem?
> Best,
>
> Philippe Grosjean
>
> ...........]<(({?<...............<?}))><...............................
>  ) ) ) ) )
> ( ( ( ( (       Dr. Philippe Grosjean
>  ) ) ) ) )
> ( ( ( ( (       LOV, UMR 7093
>  ) ) ) ) )      Station Zoologique
> ( ( ( ( (       Observatoire Oc?anologique
>  ) ) ) ) )      BP 28
> ( ( ( ( (       06234 Villefranche sur mer cedex
>  ) ) ) ) )      France
> ( ( ( ( (
>  ) ) ) ) )      tel: +33.4.93.76.38.16, fax: +33.4.93.76.38.34
> ( ( ( ( (
>  ) ) ) ) )      e-mail: phgrosjean at sciviews.org
> ( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
>  ) ) ) ) )
> .......................................................................
>
>
>
> -----Original Message-----
> From: r-help-admin at stat.math.ethz.ch
> [mailto:r-help-admin at stat.math.ethz.ch]On Behalf Of Bob Porter
> Sent: dimanche 29 d?cembre 2002 8:52
> To: r-help at stat.math.ethz.ch
> Subject: [R] lowess + turnpoints = doubling integers?
>
>
> Happy New Year, r-helpers!
>
> I am using lowess to smooth a scatter plot,
> xx<-lowess(xinput,f=.04)  #defaults for other args
>  followed by
> turnpoints(xx$y) #defaults for other args
>
> I plot the smoothed result as well as turnpoints (using yy$tppos) on top of
> raw
> data plot.
> Result is exactly as expected, graphically.
>
> For another purpose, I calcuate the difference between turnpoints
> (representing
> time intervals between turnspoints in my applicaiton), e.g.
>
> aduration[j]<-yy$tppos[i+1]-yytppos[i]
>
> This also appears to work as expected, HOWEVER, a typical list of such
> differences looks like:
> 22,33,22,11,33,44,33,33,11,33,44,66,33,22,.........
> there are, in some instances, three digit measure such as 110 or 106, etc.
> but
> the double-digit measures, although of the proper magnitude, seem to always
> be
> double integers 11 to 99.
>
> The double-integer results are found with f=.04 and total length of vector
> of
> 1200.  With vector of length 1100 (same input data), the results are NOT
> double-integer but are ALWAYS (?) of the form x0, e.g.
> 70,50,50,70,100,40............  The magnitude of these latter results (22 vs
> 70,
> for example) is evidently due to the change in the smoothing span from
> .04*1200
> to .04*1100, but I am mystified why the results have double-integers in the
> first case, and terminal zeros in the second.
>
> My project involves applying these functions in a batch run for dozens of
> data
> sets so I want to understand more about what is going on that yeilds these
> strange double-integers or zero-terminating values.
>
> Thanks,
>
> Bob Porter, Tampa
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
>
>



From Hui_Wang at affymetrix.com  Tue Dec 31 19:27:03 2002
From: Hui_Wang at affymetrix.com (Wang, Hui)
Date: Tue Dec 31 19:27:03 2002
Subject: [R] Plot scales
Message-ID: <48F1F432BF75D6118FAC0002B325BE3610CB46@ntex04.affymetrix.com>

Is par(cex=scale factor) what you need? 

> -----Original Message-----
> From: Mike Prager [mailto:Mike.Prager at noaa.gov]
> Sent: Monday, December 23, 2002 11:35 AM
> To: R Help list
> Subject: [R] Plot scales
> 
> I remember reading somewhere that locations on plots (in my case,
> arguments
> x and y for legend()) can be specified in several scales besides the usual
> data scale.  I would like to set x and y as proportions of total plot size
> or something similar.  Can anyone steer me to documentation on how to do
> it?
> 
> --
> 
> Michael Prager, Ph.D.                <Mike.Prager at noaa.gov>
> NOAA Center for Coastal Fisheries and Habitat Research
> Beaufort, North Carolina  28516
> http://shrimp.ccfhrb.noaa.gov/~mprager/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jeff_hamann at hamanndonald.com  Tue Dec 31 21:07:03 2002
From: jeff_hamann at hamanndonald.com (Jeff D. Hamann)
Date: Tue Dec 31 21:07:03 2002
Subject: [R] newbie and bivariate distributions
Message-ID: <001e01c2b108$013a2e00$7c74c180@forestry.oregonstate.edu>

I have a data set I would like to fit truncated bivariate distributions to.
Are there any packages suited to this task?

Jeff.



From rpates at virginia.edu  Tue Dec 31 21:33:03 2002
From: rpates at virginia.edu (Robert Pates)
Date: Tue Dec 31 21:33:03 2002
Subject: [R] RODBCType&NullDataExportProblems
Message-ID: <3E11FECE.659B986A@virginia.edu>

Hello
I am trying to move data between R and other systems (e.g. SAS and MS
SQL Server) using RODBC.  I think I have the most recent version of
RODBC (0.9) and here is some other system info:
> odbcGetInfo(channel)
[1] "Microsoft SQL Server version 08.00.0679. Driver ODBC version 03.52"

> version
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    6.1
year     2002
month    11
day      01
language R
>

I appear to be having 2 sets of problems when I execute an sqlSave to
export an R dataframe to either SAS or to MS SQL:
1) RODBC seems to deal with chars and int types OK -- but seems to want
to create "double" types in the receiving systems which don't support
"double"s (instead -- for example -- MS SQL supports "float").  How can
I specify more precisely the data types to be created in the receiving
system?  If this is documented on the R site, or in the RODBC docs, I
have missed it.
2) So if I create a file with chars and ints in MS SQL it seems to work
OK -- until I have missing data in the data frame (e.g. int NAs).  I
have not yet hit upon the way to write nulls to the receiving system.  I
have played with "nastring=" and each time I get:
"[RODBC]Failed exec in Update22005 0 [Microsoft][ODBC SQL Server
Driver]Invalid character value for cast specification "

In my defence, I have spent many hours trying to sort these issues out.
What am I missing? Any help would be much appreciated.

Thanks

Rob Pates
UVA, Charlottesville, VA, USA



From ripley at stats.ox.ac.uk  Tue Dec 31 22:06:02 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue Dec 31 22:06:02 2002
Subject: [R] RODBCType&NullDataExportProblems
In-Reply-To: <3E11FECE.659B986A@virginia.edu>
Message-ID: <Pine.LNX.4.31.0212312103010.24747-100000@gannet.stats>

On Tue, 31 Dec 2002, Robert Pates wrote:

> Hello
> I am trying to move data between R and other systems (e.g. SAS and MS
> SQL Server) using RODBC.  I think I have the most recent version of
> RODBC (0.9) and here is some other system info:
> > odbcGetInfo(channel)
> [1] "Microsoft SQL Server version 08.00.0679. Driver ODBC version 03.52"
>
> > version
>          _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    6.1
> year     2002
> month    11
> day      01
> language R
> >
>
> I appear to be having 2 sets of problems when I execute an sqlSave to
> export an R dataframe to either SAS or to MS SQL:
> 1) RODBC seems to deal with chars and int types OK -- but seems to want
> to create "double" types in the receiving systems which don't support
> "double"s (instead -- for example -- MS SQL supports "float").  How can
> I specify more precisely the data types to be created in the receiving
> system?  If this is documented on the R site, or in the RODBC docs, I
> have missed it.

Have you looked at SQLTypeInfo?  My bet is that the RODBC driver is
reporting that `double' is supported, as it jolly well should be.

> 2) So if I create a file with chars and ints in MS SQL it seems to work
> OK -- until I have missing data in the data frame (e.g. int NAs).  I
> have not yet hit upon the way to write nulls to the receiving system.  I
> have played with "nastring=" and each time I get:
> "[RODBC]Failed exec in Update22005 0 [Microsoft][ODBC SQL Server
> Driver]Invalid character value for cast specification "

Looks like a bug in the driver.

> In my defence, I have spent many hours trying to sort these issues out.
> What am I missing? Any help would be much appreciated.

My guess is that you are looking in the wrong place: see if this works
with a well-written ODBC driver.  1) certainly does.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Ngayee.Law at celeradiagnostics.com  Tue Dec 31 23:19:03 2002
From: Ngayee.Law at celeradiagnostics.com (Ngayee J Law)
Date: Tue Dec 31 23:19:03 2002
Subject: [R] Probit Analysis
Message-ID: <OFB50FF731.293FBCBC-ON88256CA0.007A260E@pe-c.com>

Hello all,

I have a very simple set of data and I would like to analyze them with
probit analysis.
The data are:

X    Event          Trial
100  8         8
75   8         8
50   6         8
25   4         8
10   2         8
0    0         8

I want to estimate the value of X that will give a 95% hit rate
(Event/Trial) and the corresponding
95% CI. Anyone can offer some help? Thanks!!

- Jacqueline



From apjaworski at mmm.com  Tue Dec 31 23:49:02 2002
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Tue Dec 31 23:49:02 2002
Subject: [R] Probit Analysis
Message-ID: <OFCAC06063.431564A8-ON86256CA0.007CEEEF@mmm.com>

Jacqueline,

This should be a simple application of GLM.  Check the help pages for glm,
family and dose.p in library MASS.  Look at the example at the bottom of
the dose.p help page - it does almost exactly what you need.

Hope this helps,

Andy

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


|---------+---------------------------------->
|         |           "Ngayee J Law"         |
|         |           <Ngayee.Law at celeradiagn|
|         |           ostics.com>            |
|         |           Sent by:               |
|         |           r-help-admin at stat.math.|
|         |           ethz.ch                |
|         |                                  |
|         |                                  |
|         |           12/31/2002 16:17       |
|         |                                  |
|---------+---------------------------------->
  >-----------------------------------------------------------------------------------------------------------------------------|
  |                                                                                                                             |
  |      To:       r-help at stat.math.ethz.ch                                                                                     |
  |      cc:                                                                                                                    |
  |      Subject:  [R] Probit Analysis                                                                                          |
  >-----------------------------------------------------------------------------------------------------------------------------|



Hello all,

I have a very simple set of data and I would like to analyze them with
probit analysis.
The data are:

X    Event          Trial
100  8         8
75   8         8
50   6         8
25   4         8
10   2         8
0    0         8

I want to estimate the value of X that will give a 95% hit rate
(Event/Trial) and the corresponding
95% CI. Anyone can offer some help? Thanks!!

- Jacqueline

______________________________________________
R-help at stat.math.ethz.ch mailing list
http://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jmc at research.bell-labs.com  Tue Dec 31 23:57:03 2002
From: jmc at research.bell-labs.com (John Chambers)
Date: Tue Dec 31 23:57:03 2002
Subject: [R] Writing packages with `methods' package
References: <Pine.GSO.4.10.10212291718020.2197-100000@quetelet.stat.ucla.edu>
Message-ID: <3E121F78.FF2BEEAF@research.bell-labs.com>

The problem here is that the standard R way of attaching a package is to
source in the R code; when the code contains setMethod() calls and the
like, the result is to store the resulting definitions in the global
environment.

When you're writing packages using methods, you essentially always want
to use an alternative installation for the package, which creates a
binary image when R INSTALL runs.   This image is loaded when the
package is attached by calling library(), and the objects for methods,
etc. are in the package database,as you would like.

There's a paragraph in the online documentation for INSTALL that
describes what to do.  (if you want a quick fix, just touch an empty
file install.R in the package's top level directory.)

When you run INSTALL, you should see a line:

** save image

in the printout.  And no files generated in the global environment from
calling library()

Regards,
 John Chambers

Roger Peng wrote:
> 
> I'm trying to write a package which uses classes/methods as defined in the
> `methods' package.  I have a single .R file which defines the class and
> various methods for that class.  At the top of the file I have
> 
> require(methods)
> 
> and then
> 
> setClass("myclass", ...)
> setGeneric("intersect")
> setMethod("intersect", "myclass", function(x,y) ...)
> 
> I noticed that when I build the package and subsequently load it via
> library(), the methods show up in the global workspace, which is not quite
> what I wanted.
> 
> In general, is there any documentation on building packages with the
> `methods' package (i.e. is it any different from building packages without
> `methods'?) or perhaps an R-help thread I should look for?
> 
> In short, how should I setup my package so that my methods do not show up
> in the global workspace?
> 
> Thanks,
> 
> -roger
> _______________________________
> UCLA Department of Statistics
> rpeng at stat.ucla.edu
> http://www.stat.ucla.edu/~rpeng
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> http://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
John M. Chambers                  jmc at bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc


