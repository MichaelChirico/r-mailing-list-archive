From bitwrit at ozemail.com.au  Wed Mar  2 23:56:19 2005
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Thu, 3 Mar 2005 09:56:19 +1100
Subject: [R] Getting tick positions
Message-ID: <20050226195338.VXYR24950.smta03.mail.ozemail.net@there>

Thanks for the answers - I should have been more specific as I had already 
tried axTicks and pretty.

The function in question is gantt.chart() in the latest plotrix package 
(Thanks to Scott Waichler for the original code). I settled on axis.POSIXct 
as it seemed the most appropriate for this function, but couldn't find a way 
to get the positions of the ticks so that I could then draw grid lines along 
the months|days|hours. While the trick of copying the original function 
works, I wondered why the axis* functions don't return the tick positions as 
barplot returns the bar positions. Is there any reason not to return "z", or 
is it just historical?

Jim



From pensterfuzzer at yahoo.de  Tue Mar  1 00:27:01 2005
From: pensterfuzzer at yahoo.de (Werner Wernersen)
Date: Tue, 1 Mar 2005 00:27:01 +0100 (CET)
Subject: [R] Journal Quality R Graphs?
Message-ID: <20050228232701.41735.qmail@web25804.mail.ukl.yahoo.com>

Hi!

I have browsed the help archives but did not find
anything on the subject: How 
to make publication quality graphs with R best?
Is there some document about that topic out there? The
problem is that the 
graphs look nice on the screen but when printed in
black and white every color 
apart from black doesn't look very nice. Is there some
guideline how to set 
color palettes and or fill patterns for charts?

Thank you very much for considering my question in
advance.

Best,
   Werner



From brett at hbrc.govt.nz  Tue Mar  1 00:33:40 2005
From: brett at hbrc.govt.nz (Brett Stansfield)
Date: Tue, 1 Mar 2005 12:33:40 +1300 
Subject: [R] (no subject)
Message-ID: <3542A1BF5AE1984D9FF577DA2CF8BA9868B0C2@MSX2>

Dear R
Can you tell me how to change the working directory of R

It's just that I have some text files that I wish to save separately from
the R filing structure eg. into C:/my documents and need to change the
working directory of R so that it reads these files . This means if I ever
upgrade the current version of R nothing will be effected.

brett

Brett Stansfield 
Environmental Scientist - Water Quality 
Hawke's Bay Regional Council 
102 Vautier Street 
Private Bag 6006 
Napier 
Phone (06) 835-9200 extn 9334 
Fax (06) 835-3601



From gunter.berton at gene.com  Tue Mar  1 00:48:22 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Mon, 28 Feb 2005 15:48:22 -0800
Subject: [R] (no subject)
In-Reply-To: <3542A1BF5AE1984D9FF577DA2CF8BA9868B0C2@MSX2>
Message-ID: <200502282348.j1SNmMCG014967@hertz.gene.com>

help.search("working directory")

The R folks have worked very hard to provide good documentation. Please make
use of the Help system and other resources before posting, as the Posting
Guide asks (below).

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Brett 
> Stansfield
> Sent: Monday, February 28, 2005 3:34 PM
> To: R help (E-mail)
> Subject: [R] (no subject)
> 
> Dear R
> Can you tell me how to change the working directory of R
> 
> It's just that I have some text files that I wish to save 
> separately from
> the R filing structure eg. into C:/my documents and need to change the
> working directory of R so that it reads these files . This 
> means if I ever
> upgrade the current version of R nothing will be effected.
> 
> brett
> 
> Brett Stansfield 
> Environmental Scientist - Water Quality 
> Hawke's Bay Regional Council 
> 102 Vautier Street 
> Private Bag 6006 
> Napier 
> Phone (06) 835-9200 extn 9334 
> Fax (06) 835-3601
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From gunter.berton at gene.com  Tue Mar  1 00:52:32 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Mon, 28 Feb 2005 15:52:32 -0800
Subject: [R] Journal Quality R Graphs?
In-Reply-To: <20050228232701.41735.qmail@web25804.mail.ukl.yahoo.com>
Message-ID: <200502282352.j1SNqWaE022661@compton.gene.com>

Please read the posting guide. As a minimum, you'll need to specify your OS
and R version plus probably other particulars about what form the output
must be in, etc. I am surprised that you were unable to find anything in the
archives, as this is a frequent discussion topic.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Werner 
> Wernersen
> Sent: Monday, February 28, 2005 3:27 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Journal Quality R Graphs?
> 
> Hi!
> 
> I have browsed the help archives but did not find
> anything on the subject: How 
> to make publication quality graphs with R best?
> Is there some document about that topic out there? The
> problem is that the 
> graphs look nice on the screen but when printed in
> black and white every color 
> apart from black doesn't look very nice. Is there some
> guideline how to set 
> color palettes and or fill patterns for charts?
> 
> Thank you very much for considering my question in
> advance.
> 
> Best,
>    Werner
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From spencer.graves at pdf.com  Tue Mar  1 00:55:43 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 28 Feb 2005 15:55:43 -0800
Subject: [R] change working directory [was:  (no subject)]
In-Reply-To: <3542A1BF5AE1984D9FF577DA2CF8BA9868B0C2@MSX2>
References: <3542A1BF5AE1984D9FF577DA2CF8BA9868B0C2@MSX2>
Message-ID: <4223AF7F.7050305@pdf.com>

      'help.search("working directory")' identifies "getwd", the help 
file for which describes "setwd". 

      Similarly, "www.r-project.org" -> search -> "R site search" for 
"working directory" produced 564 hits.  I checked the first 4, and they 
all mentioned either getwd or setwd. 

      hope this helps. 
      spencer graves

Brett Stansfield wrote:

>Dear R
>Can you tell me how to change the working directory of R
>
>It's just that I have some text files that I wish to save separately from
>the R filing structure eg. into C:/my documents and need to change the
>working directory of R so that it reads these files . This means if I ever
>upgrade the current version of R nothing will be effected.
>
>brett
>
>Brett Stansfield 
>Environmental Scientist - Water Quality 
>Hawke's Bay Regional Council 
>102 Vautier Street 
>Private Bag 6006 
>Napier 
>Phone (06) 835-9200 extn 9334 
>Fax (06) 835-3601
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From saurav at sas.upenn.edu  Tue Mar  1 01:03:12 2005
From: saurav at sas.upenn.edu (SP)
Date: Mon, 28 Feb 2005 19:03:12 -0500
Subject: [R] 3d scatterplots of more than 1 data set
In-Reply-To: <20050228133505.XWVS1919.tomts22-srv.bellnexxia.net@JohnDesktop8300>
References: <20050228043244.GA18629@mail1.sas.upenn.edu>
	<20050228133505.XWVS1919.tomts22-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <20050301000312.GA19491@mail1.sas.upenn.edu>

Hi John,

Thanks.  I could get done most of what I wanted.    

Rcmdr is a fantastic package, btw.  Thanks for that too. 

Saurav


John Fox [Mon, Feb 28, 2005 at 08:35:04AM -0500]:

+  Dear Saurav,
+  
+  The scatter3d() function in the Rcmdr package will plot by groups, using
+  different colours for the groups. The function can be used directly or
+  called via the Rcmdr menus. scatter3d() appears to do what you want, but in
+  any event is a straightforward function, and you should be able to alter it,
+  or simply add to the plot using, e.g., rgl.spheres() from the rgl package.
+  
+  I hope this helps,
+   John
+  
+  --------------------------------
+  John Fox
+  Department of Sociology
+  McMaster University
+  Hamilton, Ontario
+  Canada L8S 4M4
+  905-525-9140x23604
+  http://socserv.mcmaster.ca/jfox 
+  -------------------------------- 
+  
+  > -----Original Message-----
+  > From: r-help-bounces at stat.math.ethz.ch 
+  > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Saurav Pathak
+  > Sent: Sunday, February 27, 2005 11:33 PM
+  > To: r-help at stat.math.ethz.ch
+  > Subject: [R] 3d scatterplots of more than 1 data set
+  > 
+  > hi,
+  > 
+  > i am need to plot two or more sets of data in a 3d 
+  > scatterplot, each set with different color.
+  > 
+  > i tried Rcmdr, and the 3d scatterplot facility, based on rgl. 
+  >  that is what i need.  but i cannot seem to code different 
+  > sets of data differently.  any help will be very helpful.
+  > 
+  > i tried scatterplot3d, but it is difficult to get the right 
+  > angle in it.  i need to be able to rotate the axes, and 
+  > export an eps file from the right angle.
+  > 
+  > thanks in advance.
+  > --
+  > saurav
+  > 
+  > ______________________________________________
+  > R-help at stat.math.ethz.ch mailing list
+  > https://stat.ethz.ch/mailman/listinfo/r-help
+  > PLEASE do read the posting guide! 
+  > http://www.R-project.org/posting-guide.html

-- 
saurav



From ggrothendieck at myway.com  Tue Mar  1 02:21:33 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 1 Mar 2005 01:21:33 +0000 (UTC)
Subject: [R] formatting output
References: <7f8fd6d7f8cfa8.7f8cfa87f8fd6d@123mail.cl>
	<1109625004.19511.31.camel@horizons.localdomain>
Message-ID: <loom.20050301T021131-237@post.gmane.org>

Marc Schwartz <MSchwartz <at> MedAnalytics.com> writes:

: 
: On Mon, 2005-02-28 at 14:05 -0400, Peyuco Porras Porras . wrote:
: >    Dear R-users
: > 
: >    A  basic  question  that I wasn't able to solve: Is it possible to get
: >    the  results  of the function 'quantile' expressed as data.frame? What
: >    I'm  doing  is  to  apply the following code to get the quantiles in a
: >    particular dataset:
: > 
: >    tmp<-tapply(data$DEN,list(Age=data$AGE,Sex=data$SEX),quantile)
: > 
: >    and  then I save this output to HTML using the library R2HTML. However
: >    in  order  to  format  the  tables  in  HTML I have to use the command
: >    HTML.data.frame(...)  which  allows  me  to  define,  for example, the
: >    number of digits in the html table.

Note that HTML has numerous methods, not just HTML.data.frame.  Issue
the command:

  methods(HTML)

to see them.

: > 
: >    But  the object 'tmp' is not a dataframe and I can't coarce it to this
: >    format.  Is  it  possible  to  get  the  results of this function as a
: >    dataframe? I  know  that  I'm probably missing some important concepts
: >    here but Im not very good in programming.
: > 
: >    Any hint will be appreciated
: 
: Here is one approach, using an expansion of one of the examples in
: ?tapply:
: 
: # Get quantiles of 'breaks' for each combination of 'wool' and 'tension'
: > my.tmp <- tapply(warpbreaks$breaks, 
:                    list(warpbreaks$wool, warpbreaks$tension), quantile)
: 
: # Note that my.tmp is a 2 x 6 matrix of list elements
: # with each list element being the results of quantile
: # on each combination of 'wool' and 'tension'
: 
: > my.tmp
:   L         M         H
: A Numeric,5 Numeric,5 Numeric,5
: B Numeric,5 Numeric,5 Numeric,5
: 
: For example:
: 
: > my.tmp[1, 1]
: [[1]]
:   0%  25%  50%  75% 100%
:   25   26   51   54   70
: 
: Now get this into a manageable structure by taking each list element in
: my.tmp and converting it into a row in a new matrix, use:
: 
: > my.mat <- do.call("rbind", my.tmp)
: 
: > my.mat
:      0% 25% 50% 75% 100%
: [1,] 25  26  51  54   70
: [2,] 14  20  29  31   44
: [3,] 12  18  21  30   36
: [4,] 16  21  28  39   42
: [5,] 10  18  24  28   43
: [6,] 13  15  17  21   28
[...snipped off code to add row names...]

Here is a slight variation of Marc's solution that avoids explicit
setting of the row names:

R>   my.tmp <- split(warpbreaks$breaks, 
+     list(warpbreaks$wool, warpbreaks$tension))
R>   my.tmp <- lapply(my.tmp, quantile)
R>   do.call("rbind", my.tmp)
    0% 25% 50% 75% 100%
A.L 25  26  51  54   70
B.L 14  20  29  31   44
A.M 12  18  21  30   36
B.M 16  21  28  39   42
A.H 10  18  24  28   43
B.H 13  15  17  21   28



From MSchwartz at MedAnalytics.com  Tue Mar  1 03:11:46 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Mon, 28 Feb 2005 20:11:46 -0600
Subject: [R] formatting output
In-Reply-To: <loom.20050301T021131-237@post.gmane.org>
References: <7f8fd6d7f8cfa8.7f8cfa87f8fd6d@123mail.cl>
	<1109625004.19511.31.camel@horizons.localdomain>
	<loom.20050301T021131-237@post.gmane.org>
Message-ID: <1109643106.12567.2.camel@horizons.localdomain>

On Tue, 2005-03-01 at 01:21 +0000, Gabor Grothendieck wrote:

<snip>

> Here is a slight variation of Marc's solution that avoids explicit
> setting of the row names:
> 
> R>   my.tmp <- split(warpbreaks$breaks, 
> +     list(warpbreaks$wool, warpbreaks$tension))
> R>   my.tmp <- lapply(my.tmp, quantile)
> R>   do.call("rbind", my.tmp)
>     0% 25% 50% 75% 100%
> A.L 25  26  51  54   70
> B.L 14  20  29  31   44
> A.M 12  18  21  30   36
> B.M 16  21  28  39   42
> A.H 10  18  24  28   43
> B.H 13  15  17  21   28

Gabor,

I had my head wrapped around trying to figure out a solution in a post
hoc fashion. Didn't even think of splitting the data first.

Better solution.

Thanks,

Marc



From james.smith at cdu.edu.au  Tue Mar  1 03:14:02 2005
From: james.smith at cdu.edu.au (James Smith)
Date: Tue, 1 Mar 2005 11:44:02 +0930
Subject: [R] packages masking other objects
Message-ID: <E62D4EFB4204BF4F947E1BBDA775517B359B1F@mail.site.cdu.edu.au>

hello all, 

I am trying to use the function getCovariateFormula(nlme) in conjunction with the library lme4. When I load both packages I get the following message and the getCovariateFormula function no longer works:

library(nlme)
library(lme4)

Attaching package 'lme4':


        The following object(s) are masked from package:nlme :

         contr.SAS getCovariateFormula getResponseFormula groupedData lmeControl 

I have tried removing the package after using it, with:
detach(package:lme4)
library(nlme)

but I still get an error message when I try to use getCovariateFormula. The line I use it in, and the error message is below:

rownames(table)<-c((getCovariateFormula(model1)),(getCovariateFormula(model2)),(getCovariateFormula(model3)),(getCovariateFormula(model4)),(getCovariateFormula(model5)),(getCovariateFormula(model6)),(getCovariateFormula(modelnull)))

Error in switch(mode(x), "NULL" = structure(NULL, class = "formula"),  : 
        invalid formula

This line works fine when I run models with different structures that are not in the lme4 package.
Does anyone have any suggestions about this ?
Am I not removing the package completely ?

Any suggestions would be greatly appreciated
Thanks
James Smith



From james.smith at cdu.edu.au  Tue Mar  1 03:20:59 2005
From: james.smith at cdu.edu.au (James Smith)
Date: Tue, 1 Mar 2005 11:50:59 +0930
Subject: [R] packages masking other objects
Message-ID: <E62D4EFB4204BF4F947E1BBDA775517B359B20@mail.site.cdu.edu.au>


> hello all, 
> 
> I am trying to use the function getCovariateFormula(nlme) in conjunction with the library lme4. When I load both packages I get the following message and the getCovariateFormula function no longer works:
> 
> library(nlme)
> library(lme4)
> 
> Attaching package 'lme4':
> 
> 
>         The following object(s) are masked from package:nlme :
> 
>          contr.SAS getCovariateFormula getResponseFormula groupedData lmeControl 
> 
> I have tried removing the package after using it, with:
> detach(package:lme4)
> library(nlme)
> 
> but I still get an error message when I try to use getCovariateFormula. The line I use it in, and the error message is below:
> 
> rownames(table)<-c((getCovariateFormula(model1)),(getCovariateFormula(model2)),(getCovariateFormula(model3)),(getCovariateFormula(model4)),(getCovariateFormula(model5)),(getCovariateFormula(model6)),(getCovariateFormula(modelnull)))
> 
> Error in switch(mode(x), "NULL" = structure(NULL, class = "formula"),  : 
>         invalid formula
> 
> This line works fine when I run models with different structures that are not in the lme4 package.
> Does anyone have any suggestions about this ?
> Am I not removing the package completely ?
> 
> Any suggestions would be greatly appreciated
> Thanks
> James Smith
>



From ggrothendieck at myway.com  Tue Mar  1 03:21:28 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 1 Mar 2005 02:21:28 +0000 (UTC)
Subject: [R] packages masking other objects
References: <E62D4EFB4204BF4F947E1BBDA775517B359B1F@mail.site.cdu.edu.au>
Message-ID: <loom.20050301T032058-50@post.gmane.org>

James Smith <james.smith <at> cdu.edu.au> writes:

: 
: hello all, 
: 
: I am trying to use the function getCovariateFormula(nlme) in conjunction 
with the library lme4. When I
: load both packages I get the following message and the getCovariateFormula 
function no longer works:
: 
: library(nlme)
: library(lme4)
: 
: Attaching package 'lme4':
: 
:         The following object(s) are masked from package:nlme :
: 
:          contr.SAS getCovariateFormula getResponseFormula groupedData 
lmeControl 
: 
: I have tried removing the package after using it, with:
: detach(package:lme4)
: library(nlme)
: 
: but I still get an error message when I try to use getCovariateFormula. The 
line I use it in, and the error
: message is below:
: 
: rownames(table)<-c((getCovariateFormula(model1)),(getCovariateFormula
(model2)),(getCovariateFormula(model3)),(getCovariateFormula(model4)),
(getCovariateFormula(model5)),(getCovariateFormula(model6)),
(getCovariateFormula(modelnull)))
: 
: Error in switch(mode(x), "NULL" = structure(NULL, class = "formula"),  : 
:         invalid formula
: 
: This line works fine when I run models with different structures that are 
not in the lme4 package.
: Does anyone have any suggestions about this ?
: Am I not removing the package completely ?
: 

Check out:

?"::"



From paul.boutros at utoronto.ca  Tue Mar  1 05:19:02 2005
From: paul.boutros at utoronto.ca (paul.boutros@utoronto.ca)
Date: Mon, 28 Feb 2005 23:19:02 -0500
Subject: [R] Problems Building Ron AIX 5.2.0.0 (Solved)
Message-ID: <1109650742.4223ed36b9939@webmail.utoronto.ca>

Happily I got this to work, largely by trial-and-error.  In hopes that this will 
help somebody else, my config.site ended up being:
OBJECT_MODE=64
R_PAPERSIZE=letter
CC=/usr/local/bin/gcc
MAIN_LDFLAGS=-Wl,-brtl
SHLIB_LDFLAGS=-Wl,-G

Which is virtually identical to that recommended in R-admin: one of my problems 
was using "-W1,brtl" rather than "-W1,-brtl".  This was R 2.0.1
on AIX 5.2.0.0 with GCC 3.3.2

The previous messages I'd posted on this issue are included below.

Paul

============================================================
My apologies -- I had believed that by linking the source message I
had made the detailed context available.  I will be more careful in
the future to correctly give full context.

Paul

> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Saturday, February 26, 2005 5:23 AM
> To: paul.boutros at utoronto.ca
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Problems Building R on AIX 5.2.0.0 (Update)
>
>
> Quotes from messages about Solaris 9 are not necessarily applicable to
> AIX, and in omitting the context you have misrepresented me.
>
> Please do bear in mind the `moral rights' on quoting given at
>
> http://www.jiscmail.ac.uk/help/policy/copyright.htm
>
> (Perhaps such a reference is needed in the posting guide?)
>
>
> On Fri, 25 Feb 2005 paul.boutros at utoronto.ca wrote:
>
> > Hi,
> >
> > My previous message is appended: I'm still struggling with
> building on AIX.  I
> > updated my config.site to follow the suggestions from R-admin:
> > MAIN_LDFLAGS=-Wl,brtl
> > SHLIB_LDFLAGS=-Wl,-G
> >
> > This led to an error during configure:
> > checking whether mixed C/Fortran code can be run... configure:
> WARNING: cannot
> > run mixed C/Fortan code
> > configure: error: Maybe check LDFLAGS for paths to Fortran libraries?
> >
> > This confused me a bit, because before adding the MAIN_LDFLAGS
> and SHLIB_LDFLAGS
> > to config.site this step of configure did not show an error.
> When I googled this
> > I found a previous message from last year:
> > http://tolstoy.newcastle.edu.au/R/help/04/04/1622.html
> >
> > At the end of this message Professor Ripley says:
> > "You need wherever libg2c.so is installed in your LD_LIBRARY_PATH."
> >
> > So... I went looking for this file and could not find it!  In
> /usr/local/lib I
> > have:
> > $ ls -al libg2c*
> > -rw-r--r--   1 freeware staff       7751224 Jan 09 2004  libg2c.a
> > -rwxr-xr-x   1 freeware staff           714 Jan 09 2004  libg2c.la
> >
> > But no libg2c.so appears to be on my system.  Does this
> indicate a bad install
> > of gcc, or could anybody offer any suggestions on where to go from here?
> >
> > Paul
> >
> > ---------------------------------------------------
> > From: Paul Boutros <Paul.Boutros_at_utoronto.ca>
> > Date: Thu 24 Feb 2005 - 02:43:52 EST
> >
> > Hello,
> >
> > I am trying to build R 2.0.1 on an AIX 5.2.0.0 machine using gcc 3.3.2:
> > $ oslevel
> >
> > 5.2.0.0
> > $ gcc -v
> >
> > Reading specs from
> /usr/local/lib/gcc-lib/powerpc-ibm-aix5.2.0.0/3.3.2/specs
> > Configured with: ../gcc-3.3.2/configure : (reconfigured)
> ../gcc-3.3.2/configure
> > --disable-nls : (reconfigured) ../gcc-3.3.2/configure
> --disable-nls Thread
> > model: aix
> > gcc version 3.3.2
> >
> > Configure goes okay, but I get an error that I don't quite know
> how to interpret
> > during make. I've included the summary output from the end of
> configure as well
> > as the error that I get during make below. Any
> suggestions/recommendations are
> > very much appreciate: I'm stuck on ideas for what could be going wrong.
> >
> > Paul
> >
> > $ ./configure --prefix=/db2blaste/R
> >
> >
> > <snip>
> >
> > R is now configured for powerpc-ibm-aix5.2.0.0
> >
> >  Source directory: .
> >  Installation directory: /db2blast/R
> >
> >  C compiler:                gcc -mno-fp-in-toc -g -O2
> >  C++ compiler:              g++  -g -O2
> >  Fortran compiler:          g77  -g -O2
> >
> >  Interfaces supported:      X11
> >
> >  External libraries:
> >  Additional capabilities: PNG, JPEG
> >  Options enabled: R profiling
> >
> >  Recommended packages: yes
> >
> > configure: WARNING: you cannot build DVI versions of the R manuals
> > configure: WARNING: you cannot build info or html versions of
> the R manuals
> > configure: WARNING: you cannot build PDF versions of the R manuals
> > configure: WARNING: I could not determine a browser
> > configure: WARNING: I could not determine a PDF viewer
> >
> >
> > $ make
> >
> >
> > <snip>
> >
> >        gcc -Wl,-bM:SRE -Wl,-H512 -Wl,-T512 -Wl,-bnoentry
> -Wl,-bexpall -Wl,- bI:
> > .
> >
> > ./../../etc/R.exp -L/usr/local/lib -o
> > lapack.so -Wl,-bI:../../../etc/Rlapack.exp
> > Lapack.lo rgeev.lo
> >
> > rsyev.lo -L../../../lib -lRlapack -L/usr/local/lib -L/usr/
> local/lib/gcc-lib/
> > powerpc-ibm-aix5.2.0.0/3.3.2 -L/usr/local/lib/gcc-lib/powe rpc-
> > ibm-aix5.2.0.0/3.3.2/../../.. -lfrtbegin -lg2c -lm -lgcc_s
> /usr/local/lib/gcclib
> > /powerpc-ibm-aix5.2.0.0/3.3.2/libgcc.a -lg -ldl -ltermcap -lm
> -lc ld: 0706-006
> > Cannot find or open library file: -l Rlapack
> >
> >        ld:open(): A file or directory in the path name does not exist.
> > collect2: ld returned 255 exit status
> > make: 1254-004 The error code from the last command is 1.
> >
> > Stop.
> > make: 1254-004 The error code from the last command is 2.
> >
> > Stop.
> > make: 1254-004 The error code from the last command is 1.
> >
> > Stop.
> > make: 1254-004 The error code from the last command is 1.
> >
> > Stop.
> > make: 1254-004 The error code from the last command is 1.
> >
> > Stop.
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>

--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ramasamy at cancer.org.uk  Tue Mar  1 05:33:54 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 01 Mar 2005 04:33:54 +0000
Subject: [R] (no subject)
In-Reply-To: <3542A1BF5AE1984D9FF577DA2CF8BA9868B0C2@MSX2>
References: <3542A1BF5AE1984D9FF577DA2CF8BA9868B0C2@MSX2>
Message-ID: <1109651635.7746.11.camel@localhost.localdomain>

Reading the posting guide http://www.R-project.org/posting-guide.html
will tell you to specify an informative subject line in your postings.

You can change working directory by using setwd(), see help("setwd").
For example setwd("c:\My Documents") might work. I am not sure if you
need to truncate the path names to 8 characters anymore.


But if you want to read files in other directory, you can do so without
changing your current working directory. As long as you can supply the
absolute or full path, you should be fine.

For example read.delim(file="c:\My Documents\project1\datafile.txt")
would read that file into R regardless of current directory. 

If you use absolute paths and if you saved the commands onto a script
file, then you can re-execute these command under whatever version of R.
I would recommend this approach since you will have a rather static
working directory.


Regards, Adai



On Tue, 2005-03-01 at 12:33 +1300, Brett Stansfield wrote: 
> Dear R
> Can you tell me how to change the working directory of R
> 
> It's just that I have some text files that I wish to save separately from
> the R filing structure eg. into C:/my documents and need to change the
> working directory of R so that it reads these files . This means if I ever
> upgrade the current version of R nothing will be effected.
> 
> brett
> 
> Brett Stansfield 
> Environmental Scientist - Water Quality 
> Hawke's Bay Regional Council 
> 102 Vautier Street 
> Private Bag 6006 
> Napier 
> Phone (06) 835-9200 extn 9334 
> Fax (06) 835-3601
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From mn216 at columbia.edu  Tue Mar  1 05:18:10 2005
From: mn216 at columbia.edu (Murad Nayal)
Date: Mon, 28 Feb 2005 23:18:10 -0500
Subject: [R] variable importance in random forest
Message-ID: <4223ED02.FB8D34BF@columbia.edu>



Hello,

In Breiman papers on random forests 4 variable importance measures are
described. as far as I can tell only two are available in the random
forest R package. reduction in accuracy when the variable is permuted,
and the mean decrease in the gini index due to the variable (no
permutation). is this gini measure computed on the training set or the
OOB cases?. in any event, Breiman actually seems to prefer a different
measure based on average lowering of margin across all cases when the
variable is permuted. is there any way to get this 'margin-based'
variable importance measure from the result returned by the randomForest
function? or do I have to use the original Breiman code to get access to
this measure?

I am using randomForest package release 4.3

many thanks
Murad Nayal



From ramasamy at cancer.org.uk  Tue Mar  1 05:54:54 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 01 Mar 2005 04:54:54 +0000
Subject: [R] Journal Quality R Graphs?
In-Reply-To: <20050228232701.41735.qmail@web25804.mail.ukl.yahoo.com>
References: <20050228232701.41735.qmail@web25804.mail.ukl.yahoo.com>
Message-ID: <1109652894.7865.2.camel@localhost.localdomain>

Searching for "graph publication" on
http://maths.newcastle.edu.au/~rking/R/ gave me the following hit :
http://tolstoy.newcastle.edu.au/R/help/04/03/0202.html which suggests
postscript().

Have you tried printing other documents in black and white on the same
printer or tried different printers for the same R graph. This will
hopefully eliminate printer as a possible culprit. Dying printer toners
sometimes makes the graph look worse than it actually is.


Regards, Adai





On Tue, 2005-03-01 at 00:27 +0100, Werner Wernersen wrote: 
> Hi!
> 
> I have browsed the help archives but did not find
> anything on the subject: How 
> to make publication quality graphs with R best?
> Is there some document about that topic out there? The
> problem is that the 
> graphs look nice on the screen but when printed in
> black and white every color 
> apart from black doesn't look very nice. Is there some
> guideline how to set 
> color palettes and or fill patterns for charts?
> 
> Thank you very much for considering my question in
> advance.
> 
> Best,
>    Werner
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ramasamy at cancer.org.uk  Tue Mar  1 05:58:06 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 01 Mar 2005 04:58:06 +0000
Subject: [R] (no subject)
In-Reply-To: <1109651635.7746.11.camel@localhost.localdomain>
References: <3542A1BF5AE1984D9FF577DA2CF8BA9868B0C2@MSX2>
	<1109651635.7746.11.camel@localhost.localdomain>
Message-ID: <1109653086.7865.6.camel@localhost.localdomain>

Sorry, all backslashes have to be doubled in R as mentioned in FAQ 2.14
http://cran.r-project.org/bin/windows/base/rw-FAQ.html#R-can_0027t-find-
my-file

Regards, Adai



On Tue, 2005-03-01 at 04:33 +0000, Adaikalavan Ramasamy wrote:
> Reading the posting guide http://www.R-project.org/posting-guide.html
> will tell you to specify an informative subject line in your postings.
> 
> You can change working directory by using setwd(), see help("setwd").
> For example setwd("c:\My Documents") might work. I am not sure if you
> need to truncate the path names to 8 characters anymore.
> 
> 
> But if you want to read files in other directory, you can do so without
> changing your current working directory. As long as you can supply the
> absolute or full path, you should be fine.
> 
> For example read.delim(file="c:\My Documents\project1\datafile.txt")
> would read that file into R regardless of current directory. 
> 
> If you use absolute paths and if you saved the commands onto a script
> file, then you can re-execute these command under whatever version of R.
> I would recommend this approach since you will have a rather static
> working directory.
> 
> 
> Regards, Adai
> 
> 
> 
> On Tue, 2005-03-01 at 12:33 +1300, Brett Stansfield wrote: 
> > Dear R
> > Can you tell me how to change the working directory of R
> > 
> > It's just that I have some text files that I wish to save separately from
> > the R filing structure eg. into C:/my documents and need to change the
> > working directory of R so that it reads these files . This means if I ever
> > upgrade the current version of R nothing will be effected.
> > 
> > brett
> > 
> > Brett Stansfield 
> > Environmental Scientist - Water Quality 
> > Hawke's Bay Regional Council 
> > 102 Vautier Street 
> > Private Bag 6006 
> > Napier 
> > Phone (06) 835-9200 extn 9334 
> > Fax (06) 835-3601
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >



From scott.meers at gov.ab.ca  Tue Mar  1 07:16:39 2005
From: scott.meers at gov.ab.ca (scott.meers@gov.ab.ca)
Date: Mon, 28 Feb 2005 23:16:39 -0700
Subject: [R] Creating matrices for Mantel test
Message-ID: <OFADB557C6.9A466D7A-ON87256FB7.00227BFB-87256FB7.00227BFF@agric.gov.ab.ca>


   This  seems  like  a  real simple question - but I am not finding the   answer in the help files and manuals.  I am not a real sophisticated    user  of  R  so maybe that is why I cant seem to get this.  Anyway - I
   ne   collecte   make  this  h   APE library.

   Thank you in advance for your help.
   &nbs   Scott Meers
   

From renaud.lancelot at cirad.fr  Tue Mar  1 07:45:10 2005
From: renaud.lancelot at cirad.fr (Renaud Lancelot)
Date: Tue, 01 Mar 2005 09:45:10 +0300
Subject: [R] problems with Rd format
In-Reply-To: <Pine.LNX.4.61.0502282138550.5609@gannet.stats>
References: <42237D3C.9050004@cirad.fr>
	<Pine.LNX.4.61.0502282138550.5609@gannet.stats>
Message-ID: <42240F76.2090906@cirad.fr>

Prof Brian Ripley a ?crit :
> On Mon, 28 Feb 2005, Renaud Lancelot wrote:
> 
>> Dear R-helpers,
>>
>> I have an Rd file with a section:
>>
>> \details{
>>  The model is:\cr
>>  \eqn{y | \lambda ~ Binomial(n, \lambda)},\cr
>>  [snip]
>>  }
>>
>> I would like the equation line to be indented, with a \tab character 
>> for example. How can I do that ?
> 
> 
> Well, use markup that allows \tab: if you want a table, use \tabular.
> But if you find yourself doing this, you are not in the spirit of layout 
> languages, and Rd is a layout language.
> 
>> Moreover, the panel of greek letters available in HTML files generated 
>> from Rd files looks very limited (e.g., \eqn{\phi} produces phi, not 
>> the corresponding greek letter). Is there a way to overcome this in 
>> HTML files ?
> 
> 
> What HTML 4.0 _guarantees_ a browser can show is very limited, and does 
> not include phi (at least according to my HTML 4.0 book).  So, not in 
> strict HTML.

Thanks for your reply. I got a nice result (in text and HTML) with:

\details{
   The model is:\cr
   \tabular{lll}{
     \tab ? \tab \eqn{y | \lambda ~ Binomial(n, \lambda)}, with
                 \eqn{\lambda ~ Beta(S1, S2)},\cr
     [snip]
     }
   [snip]
   }

What would be a solution "in the spirit of layout languages" ?

Best,

Renaud

-- 
Dr Renaud Lancelot, v?t?rinaire
C/0 Ambassade de France - SCAC
BP 834 Antananarivo 101 - Madagascar

e-mail: renaud.lancelot at cirad.fr
tel.:   +261 32 40 165 53 (cell)
         +261 20 22 665 36 ext. 225 (work)
         +261 20 22 494 37 (home)



From gregor.gorjanc at bfro.uni-lj.si  Tue Mar  1 07:53:47 2005
From: gregor.gorjanc at bfro.uni-lj.si (Gregor GORJANC)
Date: Tue, 01 Mar 2005 07:53:47 +0100
Subject: [R] Sweave and \input or \include LaTeX commands
Message-ID: <4224117B.8030407@bfro.uni-lj.si>

Hi!

What is wrong if there would be the same command? Recall my example from 
previous posts and at the end of this mail. If I have a file a.Rnw and this
one inputs file a1.Rnw. My idea was that Sweave would check \input{a1} or 
\include{a1} statements. If file a1 would have extension .Rnw it would
parse it otherwise (i.e. having .tex) it would skip it. Sweave would just 
parse .Rnw files, while latex would put all of them in one file during 
typesetting.

Example:
- we have files
   a.Rnw, which has \input{a1} or \include{a1}
   a1.Rnw
- run Sweave(a.Rnw) and you get
   a.tex
   a1.tex
- run LaTeX (i.e. texi2dvi --pdf a.tex) and you get
   a.pdf

Having new command i.e. \SweaveInput{} would also do the job perfectly,
however I don't se any new benefits of it. One should write more or less 
the same R code as for \input or \include.

-----------------------------------------------------------------------
[...]

   > Gabor
   > Since this might not be desirable in all instances,
   > if Sweave were to have an include facility then it should
   > not be implemented in such a way that the latex include facility
   > can no longer be used.  The point was just that it should be possible
   > to do the include at the Sweave or at the latex level.

Friedrich
I agree that it should not be the same command. I have put an
\SweaveInput{} on my 2do list, should be doable for R 2.1.0.

-- 
Lep pozdrav / With regards,
     Gregor GORJANC

-----------------------------------------------------------------------
University of Ljubljana
Biotechnical Faculty        URI: http://www.bfro.uni-lj.si/MR/ggorjan
Zootechnical Department     mail: gregor.gorjanc <at> bfro.uni-lj.si
Groblje 3                   tel: +386 (0)1 72 17 861
SI-1230 Domzale             fax: +386 (0)1 72 17 888
Slovenia, Europe
-----------------------------------------------------------------------

: Imagine this situation:
:
: % --- a.Rnw start ---
: \documentclass{book}
: \usepackage{Sweave}
: \begin{document}
: % some toy example
: <<print=TRUE>>=
: x <- 1:10
:  <at>
: % now we input additional file
: \input{a1}
: % and lets look again at x
: <<print=TRUE>>=
: x
:  <at>
: \end{document}
: % --- a.Rnw end ---
:
: % --- a1.Rnw start ---
: %\usepackage{Sweave}
: % add 1 to x
: <<print=TRUE>>=
: x <- x + 1
:  <at>
: % --- a1.Rnw end ---



From ligges at statistik.uni-dortmund.de  Tue Mar  1 08:26:57 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 01 Mar 2005 08:26:57 +0100
Subject: [R] packages masking other objects
In-Reply-To: <E62D4EFB4204BF4F947E1BBDA775517B359B1F@mail.site.cdu.edu.au>
References: <E62D4EFB4204BF4F947E1BBDA775517B359B1F@mail.site.cdu.edu.au>
Message-ID: <42241941.4050304@statistik.uni-dortmund.de>

James Smith wrote:
> hello all, 
> 
> I am trying to use the function getCovariateFormula(nlme) in conjunction with the library lme4. When I load both packages I get the following message and the getCovariateFormula function no longer works:
> 
> library(nlme)
> library(lme4)
> 
> Attaching package 'lme4':
> 
> 
>         The following object(s) are masked from package:nlme :
> 
>          contr.SAS getCovariateFormula getResponseFormula groupedData lmeControl 

So you don't have the most recent version of lme4 which tells you instead:

 > library(nlme)
 > library(lme4)
Loading required package: Matrix
Loading required package: latticeExtra
Error in fun(...) : Package lme4 conflicts with package nlme.
  To attach lme4 you must restart R without package nlme.
Error: .onLoad failed in loadNamespace for 'lme4'
Error in library(lme4) : package/namespace load failed for 'lme4'

So the answer is: Don't do that.

Uwe Ligges


> I have tried removing the package after using it, with:
> detach(package:lme4)
> library(nlme)
> 
> but I still get an error message when I try to use getCovariateFormula. The line I use it in, and the error message is below:
> 
> rownames(table)<-c((getCovariateFormula(model1)),(getCovariateFormula(model2)),(getCovariateFormula(model3)),(getCovariateFormula(model4)),(getCovariateFormula(model5)),(getCovariateFormula(model6)),(getCovariateFormula(modelnull)))
> 
> Error in switch(mode(x), "NULL" = structure(NULL, class = "formula"),  : 
>         invalid formula
> 
> This line works fine when I run models with different structures that are not in the lme4 package.
> Does anyone have any suggestions about this ?
> Am I not removing the package completely ?
> 
> Any suggestions would be greatly appreciated
> Thanks
> James Smith
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From samferguson at ihug.com.au  Tue Mar  1 08:02:07 2005
From: samferguson at ihug.com.au (Sam Ferguson)
Date: Tue, 01 Mar 2005 19:02:07 +1200
Subject: [R] Anova with Scheffe Tests
Message-ID: <opsmx8lttzc0cqda@localhost>

Hi R-people,

I am wanting to run Factorial ANOVA followed by Scheffe tests on some spatial subjective data. I'm comparing X-Y independent coordinates against x-y dependent coordinates. There are only four independent spatial coordinates that form a square.

I am wondering whether I am doing the right thing, because there doesn't seem to be a simple way of doing this. I have attempted to read `Practical regression and ANOVA using R' and am still confused.

In good ol' Statview (now dearly departed) to complete a Scheffe test you selected the independent variables and dependent variable and it produced a  table with the pairwise comparisons of the levels of the factor. I'm looking for a system that is as basic, but can be done using R and has documentation so I'm not guessing what I'm doing. I'd rather not have to do plots in R and then run over to dead software to do Scheffe's if possible.

I checked on google and there seems to be code for a couple of functions out there, but I need something that has a manual.

Is there a Scheffe function out there that is reasonably well documented, or should I consider some other method of dealing with this data. We have been using Scheffe for this type of analysis as I was under the impression it was very conservative. Tukey's HSD seems to be conservative as well. Should I try this? Is there a different approacch that is better and where can I read about it.

Thanks for any help you can provide.

Sam



From Friedrich.Leisch at tuwien.ac.at  Tue Mar  1 09:09:39 2005
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Tue, 1 Mar 2005 09:09:39 +0100
Subject: [R] Sweave and \input or \include LaTeX commands
In-Reply-To: <4224117B.8030407@bfro.uni-lj.si>
References: <4224117B.8030407@bfro.uni-lj.si>
Message-ID: <16932.9027.36958.616314@galadriel.ci.tuwien.ac.at>

>>>>> On Tue, 01 Mar 2005 07:53:47 +0100,
>>>>> Gregor GORJANC (GG) wrote:

  > Hi!
  > What is wrong if there would be the same command?

2  reasons:

1) I try to keep the Sweave and LaTeX namespaces disjunct, i.e., I
   currently do not overload regular LaTeX commands with a different
   meaning, and I want to keep it that way.

2) If it is "the same" command, then I you can already take bets on
   the date of the first "bug report" claiming that Sweave's \input{}
   command behaves differently that LaTeX's, e.g., by not searching
   .Rnw files along the TEXINPUTS path, etc.

I currently also plan only a \SweaveInput{}, but no \SweaveInclude{}
(the former is much easier to implement, because I don't have to
switch output files in the middle of operation).


  > Recall my example from 
  > previous posts and at the end of this mail. If I have a file a.Rnw and this
  > one inputs file a1.Rnw. My idea was that Sweave would check \input{a1} or 
  > \include{a1} statements. If file a1 would have extension .Rnw it would
  > parse it otherwise (i.e. having .tex) it would skip it. Sweave would just 
  > parse .Rnw files, while latex would put all of them in one file during 
  > typesetting.

  > Example:
  > - we have files
  >    a.Rnw, which has \input{a1} or \include{a1}
  >    a1.Rnw

Note that theese are *not* the same under LaTeX

  > - run Sweave(a.Rnw) and you get
  >    a.tex
  >    a1.tex

Nope, for \input{a1} you would get only a.tex. From the LaTeX
documentation:

**********************************************************
   `\input{file}'

   The `\input' command causes the indicated `file' to be read and
processed, exactly as if its contents had been inserted in the current
file at that point.  The file name may be a complete file name with
extension or just a first name, in which case the file `file.tex' is
used.
**********************************************************


That is easy to implement, because I read the .Rnw file, replace
(recursively) all \SweaveInput{} statements with their contents until
no more \SweaveInput{} statements are found (here the unique name
comes in handy ;-) and then process as usual.

If you want a fancier system with include statements I am happily
waiting for your code implementing it.

Best,
Fritz

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch



From jlvw at na.rau.ac.za  Tue Mar  1 09:25:37 2005
From: jlvw at na.rau.ac.za (Jacob van Wyk)
Date: Tue, 01 Mar 2005 10:25:37 +0200
Subject: [R] Beginner - simple simulation
Message-ID: <s224433a.017@rauzen.rau.ac.za>

Hallo to everybody. I am new to the list and would appreciate some help
in a basic "first demo" of how to use R for simulating a simple game; I
would like my students to use R and this may stimulate their interest.

The problem is simply:

Two players (A and B) play the following game. Each player rolls a die
(fair, 6-sided) and they write down the result: say A rolls nA and B
rolls nB. If nA is even, A pays B $nB: if nA is odd, B pays A $nA (we
think of A paying B a negative amount). The amount that A pays B is a
random variable X. Find the expectation of X.

Theoretically it is 1/4 - B is ahead on average with 25c.

Would anybody be prepared to help a little. I want to avoid loops and
vectorize the computations, simulate the value of X for various sample
sizes and preparea basic plot to show that the average value of X
"converges" to 1/4.

I would start with, say,
sample(1:6,2,replace=T)
for one simulated roll of the two dice. I want to repeat this n times,
where n is, say, 10:2000 in steps of 10. Put the results in a matrix and
work columnwise - choosing when the first roll is even, selecting the
corresponding value of the second roll, and computing the payoff as
described, etc. But I need help to put this together.

In Matlab I would, for example, do the following to display the average
payouts of A and B:

c=1;
samplesizes=[10:10:2000];
for s=samplesizes
rolls=ceil(6*rand(s,2));
a_pays_b_index=find(mod(rolls(:,1),2)==0);
a_pays_b_value=rolls(a_pays_b_index,2);
b_pays_a_index=find(mod(rolls(:,1),2)==1);
b_pays_a_value=rolls(b_pays_a_index,1);
a_pays_average(c)=mean(a_pays_b_value);
b_pays_average(c)=mean(b_pays_a_value);
c=c+1;
end

Then do the plotting, etc. (One could also take differences, and so
on.)

I would really appreciate if anybody would be kind enough to help. I
thought it might be a nice example to introduce students (in general,
perhaps - because it is a kind of interesting game) to simulation in R.

Thank you !
Jacob
(PS Any credit would be respected, i.e. my students will know who
helped me with this introduction.)




Jacob L van Wyk
Department of Mathematics and Statistics
University of Johannesburg APK
P O Box 524
Auckland Park 2006
South Africa
Tel: +27-11-489-3080
Fax: +27-11-489-2832



From dimitris.rizopoulos at med.kuleuven.ac.be  Tue Mar  1 10:01:35 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Tue, 1 Mar 2005 10:01:35 +0100
Subject: [R] Beginner - simple simulation
References: <s224433a.017@rauzen.rau.ac.za>
Message-ID: <008901c51e3d$4563bd90$0540210a@www.domain>

a simple approach could be:

n <- seq(10, 5000, 10)
means <- numeric(length(n))
for(i in seq(along=n)){
    mat <- sample(1:6, 2*n[i], TRUE); dim(mat) <- c(n[i], 2)
    means[i] <- mean(ifelse(!mat[,1]%%2, mat[,1], -mat[,2]))
}
means
plot(n, means, xlab="sample size", ylab="mean")


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm




----- Original Message ----- 
From: "Jacob van Wyk" <jlvw at na.rau.ac.za>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, March 01, 2005 9:25 AM
Subject: [R] Beginner - simple simulation


> Hallo to everybody. I am new to the list and would appreciate some 
> help
> in a basic "first demo" of how to use R for simulating a simple 
> game; I
> would like my students to use R and this may stimulate their 
> interest.
>
> The problem is simply:
>
> Two players (A and B) play the following game. Each player rolls a 
> die
> (fair, 6-sided) and they write down the result: say A rolls nA and B
> rolls nB. If nA is even, A pays B $nB: if nA is odd, B pays A $nA 
> (we
> think of A paying B a negative amount). The amount that A pays B is 
> a
> random variable X. Find the expectation of X.
>
> Theoretically it is 1/4 - B is ahead on average with 25c.
>
> Would anybody be prepared to help a little. I want to avoid loops 
> and
> vectorize the computations, simulate the value of X for various 
> sample
> sizes and preparea basic plot to show that the average value of X
> "converges" to 1/4.
>
> I would start with, say,
> sample(1:6,2,replace=T)
> for one simulated roll of the two dice. I want to repeat this n 
> times,
> where n is, say, 10:2000 in steps of 10. Put the results in a matrix 
> and
> work columnwise - choosing when the first roll is even, selecting 
> the
> corresponding value of the second roll, and computing the payoff as
> described, etc. But I need help to put this together.
>
> In Matlab I would, for example, do the following to display the 
> average
> payouts of A and B:
>
> c=1;
> samplesizes=[10:10:2000];
> for s=samplesizes
> rolls=ceil(6*rand(s,2));
> a_pays_b_index=find(mod(rolls(:,1),2)==0);
> a_pays_b_value=rolls(a_pays_b_index,2);
> b_pays_a_index=find(mod(rolls(:,1),2)==1);
> b_pays_a_value=rolls(b_pays_a_index,1);
> a_pays_average(c)=mean(a_pays_b_value);
> b_pays_average(c)=mean(b_pays_a_value);
> c=c+1;
> end
>
> Then do the plotting, etc. (One could also take differences, and so
> on.)
>
> I would really appreciate if anybody would be kind enough to help. I
> thought it might be a nice example to introduce students (in 
> general,
> perhaps - because it is a kind of interesting game) to simulation in 
> R.
>
> Thank you !
> Jacob
> (PS Any credit would be respected, i.e. my students will know who
> helped me with this introduction.)
>
>
>
>
> Jacob L van Wyk
> Department of Mathematics and Statistics
> University of Johannesburg APK
> P O Box 524
> Auckland Park 2006
> South Africa
> Tel: +27-11-489-3080
> Fax: +27-11-489-2832
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From bhx2 at mevik.net  Tue Mar  1 10:07:35 2005
From: bhx2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Tue, 01 Mar 2005 10:07:35 +0100
Subject: [R] Journal Quality R Graphs?
In-Reply-To: <20050228232701.41735.qmail@web25804.mail.ukl.yahoo.com> (Werner
	Wernersen's message of "Tue, 1 Mar 2005 00:27:01 +0100 (CET)")
References: <20050228232701.41735.qmail@web25804.mail.ukl.yahoo.com>
Message-ID: <m0zmxn4tuw.fsf@bar.nemo-project.org>

Werner Wernersen writes:

> the graphs look nice on the screen but when printed in black and
> white every color apart from black doesn't look very nice.

My advice is: If you want a black-and-white or grayscale printout, don't
plot in colors.

-- 
Bj?rn-Helge Mevik



From consentino at infinito.it  Tue Mar  1 11:14:51 2005
From: consentino at infinito.it (consentino@infinito.it)
Date: Tue, 01 Mar 2005 11:14:51 +0100
Subject: [R] Variogram with time series
In-Reply-To: <web-51064440@infinito.it>
References: <web-51064440@infinito.it>
Message-ID: <web-51269173@infinito.it>

Hello,
  
I'm using a dataset with unequally spaced time series
and I'd want to know if there is in R some functions in
order to calculate the autocorrelation function, because
acf() in stats package cannot calculate it, because I
have many missing data.
  
And if so, is it necessary to organize dataset in ts
structure or is it possible to consider it like a simple
vector?
  
Thanks in advance
  
Fabrizio Consentino
_______________________________________



From ggrothendieck at myway.com  Tue Mar  1 13:08:25 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 1 Mar 2005 12:08:25 +0000 (UTC)
Subject: [R] Sweave and \input or \include LaTeX commands
References: <4224117B.8030407@bfro.uni-lj.si>
	<16932.9027.36958.616314@galadriel.ci.tuwien.ac.at>
Message-ID: <loom.20050301T124437-98@post.gmane.org>

 <Friedrich.Leisch <at> tuwien.ac.at> writes:

> I currently also plan only a \SweaveInput{}, 

I agree that its clearer to keep the two systems distinct rather
than having subtle changes in functionality depending on the
extension of the file in \input.

While we are discussing I just wanted to bring two related points up
regarding how Sweave and R CMD interact.

1. As mentioned in a previous post in this thread, if I don't
want R CMD CHECK to process a certain portion of my vignette 
(since its involves lengthy processing or software that might not
be available on other systems) I place that portion into a file 
called sub, say, with no extension so that R CMD CHECK does not know 
its a Sweave file (and therefore automatically process it).  I then 
process it manually with Sweave:  Sweave("sub") and in my main file, 
main.Rnw, have an input statement

\input{sub.tex}

The only thing that's a bit confusing is that sub has no extension
but otherwise this has the intended effect of letting me circumvent
the R CMD CHECK for sub.   This is all ok, it works fine, but I 
was just wondering if there are any clearer ways of achieving this
effect.  I guess I could use an extension such as .Rnw-hide or
use the .Rbuildignore file to mask it (although using .Rbuildignore
in that way has the disadvantage that it would be entirely excluded 
from the build) but was just wondering if there is some standard way 
of dealing with this situation.  

2. A second problem that is related is that I think there should
be an easy way to include a .pdf vignette that was not generated
by Sweave or even latex.  Currently, as I under it, one must use 
Sweave since the package building process uses the \VignetteIndexEntry 
and associated commands to know how to process the build.  If this
is already possible then can someone indicate how its done.  Some
time ago I raised this point but no one responded at that time.


The above two points relate to the interaction between the check/build
and Sweave and may not even be about Sweave itself but the same problems
are involved so I thought its relevant to bring all considerations in
at this point.



From jonathan.charrier at bordeaux.inra.fr  Tue Mar  1 13:36:00 2005
From: jonathan.charrier at bordeaux.inra.fr (Jonathan Charrier)
Date: Tue, 01 Mar 2005 13:36:00 +0100
Subject: [R] part of name  to Date
Message-ID: <422461B0.8050107@bordeaux.inra.fr>

hi everybody,

i try to extract  a part of name to a date :

like : "VGT1_VGT2_CONTR_B020030401.H0V0.MIR"    to    "20030401"

but the beginning of the files changes

i have a list of files:

 [,1]                                
[1,] "VGT1_CONTR_B020020301.H0V0.MIR"                                 
[2,] "VGT1_VGT2_CONTR_B020020611.H0V0.MIR"
[3,] "VGT1_VGT2_CONTR_B020030401.H0V0.MIR"
[4,] "VGT1_VGT2_CONTR_B020030711.H0V0.MIR"
[5,] "VGT1_VGT2_CONTR_B020031211.H0V0.MIR"

i try the function "get()" and  "assign()" but without succeed

i know it's easy in C but in R i don't know the way


if you have an idee


thanks ,

Jonathan Charrier



From coforfe at gmail.com  Tue Mar  1 13:51:32 2005
From: coforfe at gmail.com (CARLOS ORTEGA)
Date: Tue, 1 Mar 2005 13:51:32 +0100
Subject: [R] part of name to Date
In-Reply-To: <422461B0.8050107@bordeaux.inra.fr>
References: <422461B0.8050107@bordeaux.inra.fr>
Message-ID: <7b18cd4d05030104515f8e8f63@mail.gmail.com>

Please check string manipulation functions:
- substr
- strsplit

Regards,
Carlos Ortega


On Tue, 01 Mar 2005 13:36:00 +0100, Jonathan Charrier
<jonathan.charrier at bordeaux.inra.fr> wrote:
> hi everybody,
> 
> i try to extract  a part of name to a date :
> 
> like : "VGT1_VGT2_CONTR_B020030401.H0V0.MIR"    to    "20030401"
> 
> but the beginning of the files changes
> 
> i have a list of files:
> 
>  [,1]
> [1,] "VGT1_CONTR_B020020301.H0V0.MIR"
> [2,] "VGT1_VGT2_CONTR_B020020611.H0V0.MIR"
> [3,] "VGT1_VGT2_CONTR_B020030401.H0V0.MIR"
> [4,] "VGT1_VGT2_CONTR_B020030711.H0V0.MIR"
> [5,] "VGT1_VGT2_CONTR_B020031211.H0V0.MIR"
> 
> i try the function "get()" and  "assign()" but without succeed
> 
> i know it's easy in C but in R i don't know the way
> 
> if you have an idee
> 
> thanks ,
> 
> Jonathan Charrier
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
___________________
Carlos Ortega
C/Donoso Cort?s 47 - 6C
Madrid 28015
Espa?a



From f.gherardini at pigrecodata.net  Tue Mar  1 15:10:35 2005
From: f.gherardini at pigrecodata.net (Federico Gherardini)
Date: Tue, 1 Mar 2005 15:10:35 +0100
Subject: [R] Negative intercept in glm poisson model
Message-ID: <200503011510.35079.f.gherardini@pigrecodata.net>

Dear list,
I'm trying to fit a glm model using family=poisson(link = "identity"). The 
problem is that the glm function fits a model with a negative intercept, 
which sounds like a nonsense to me, being the response a Poisson variable. 
>From a previous discussion on this list I've understood that the glm function 
uses IRLS for the fitting without any constraint so it is possible for it to 
end up in a region of values which are not admissible given the model, and in 
fact sometimes it fails asking for valid starting values. In this case I 
expected it to fail asking to supply starting values, and instead it fits the 
model just nice with this negative intercept. What am I missing?

Thanks,
Cheers
Federico



From Friedrich.Leisch at tuwien.ac.at  Tue Mar  1 14:07:09 2005
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Tue, 1 Mar 2005 14:07:09 +0100
Subject: [R] Sweave and \input or \include LaTeX commands
In-Reply-To: <loom.20050301T124437-98@post.gmane.org>
References: <4224117B.8030407@bfro.uni-lj.si>
	<16932.9027.36958.616314@galadriel.ci.tuwien.ac.at>
	<loom.20050301T124437-98@post.gmane.org>
Message-ID: <16932.26877.287127.549158@galadriel.ci.tuwien.ac.at>


>>>>> On Tue, 1 Mar 2005 12:08:25 +0000 (UTC),
>>>>> Gabor Grothendieck (GG) wrote:

  >  <Friedrich.Leisch <at> tuwien.ac.at> writes:
  >> I currently also plan only a \SweaveInput{}, 

  > I agree that its clearer to keep the two systems distinct rather
  > than having subtle changes in functionality depending on the
  > extension of the file in \input.

  > While we are discussing I just wanted to bring two related points up
  > regarding how Sweave and R CMD interact.

  > 1. As mentioned in a previous post in this thread, if I don't
  > want R CMD CHECK to process a certain portion of my vignette 
  > (since its involves lengthy processing or software that might not
  > be available on other systems) I place that portion into a file 
  > called sub, say, with no extension so that R CMD CHECK does not know 
  > its a Sweave file (and therefore automatically process it).  I then 
  > process it manually with Sweave:  Sweave("sub") and in my main file, 
  > main.Rnw, have an input statement

  > \input{sub.tex}

  > The only thing that's a bit confusing is that sub has no extension
  > but otherwise this has the intended effect of letting me circumvent
  > the R CMD CHECK for sub.   This is all ok, it works fine, but I 
  > was just wondering if there are any clearer ways of achieving this
  > effect.  I guess I could use an extension such as .Rnw-hide or
  > use the .Rbuildignore file to mask it (although using .Rbuildignore
  > in that way has the disadvantage that it would be entirely excluded 
  > from the build) but was just wondering if there is some standard way 
  > of dealing with this situation.

Both R and TeX are programming languages, and both feature if/else
statements, so you can easily do

if(FAST){
  load("pre-computed-results.RData")
}
else{
  res = compute.results()
  save(res, file="pre-computed-results.RData")
}

But note that vignettes are meant as introductionary material
containing user-runnable examples, so putting lengthy computations in
there might not serve that purpose too well (depends on the packages
and application, of course).


  > 2. A second problem that is related is that I think there should
  > be an easy way to include a .pdf vignette that was not generated
  > by Sweave or even latex.  Currently, as I under it, one must use 
  > Sweave since the package building process uses the \VignetteIndexEntry 
  > and associated commands to know how to process the build.  If this
  > is already possible then can someone indicate how its done.  Some
  > time ago I raised this point but no one responded at that time.


Packages already can have documentation in arbitrary formats (although
we strongly recommend PDF) in the inst/doc directory and many packages
on CRAN do have non-Sweave docs.  The directory is linked into the
help.start() version of the help system ("HTML help" in the Windows
Help menu). If inst/doc contains a file index.html that is used as a
TOC for the package docs. I decided to call those other documentation
objects "user guides" mostly because I had no better idea.

I think we should not call them vignettes for several reasons.  Users
should be able to expect that they can easily get and execute the code
contained in a "vignette". r-devel contains a poor man's non-gui
version of Bioconductor's vExplorer() where the edit() method for
vignette objects opens the code in an editor. It would be absolutely
fine with me to use alternative methods for vignettes than Sweave (I
am unlikely to implement any ;-), but code extraction for testing and
learning is a key concept.

So a PDF file at the moment does not qualify as a vignette, and that
is not because of missing \VignetteIndexEntry{} statements, but
because you cannot extract the code from the file. The vignette
concept of documents where you can do computations on the code
contained in the document is by no means limited to Sweave, but
currently we do not have any other implementation which can be
installed on all key platforms without too much difficulty.


BTW, I think this discussion is getting way too technical for the
r-help list -> if this thread goes on it should do so on r-devel.

Best,

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch



From consentino at infinito.it  Tue Mar  1 14:08:04 2005
From: consentino at infinito.it (consentino@infinito.it)
Date: Tue, 01 Mar 2005 14:08:04 +0100
Subject: [R] Variogram with time series
In-Reply-To: <web-51269173@infinito.it>
References: <web-51064440@infinito.it>
 <web-51269173@infinito.it>
Message-ID: <web-51314529@infinito.it>

Hello,
   
I'm using a dataset with unequally spaced time series
and I'd want to know if there is in R some functions in
order to calculate the autocorrelation function, because
acf() in stats package cannot calculate it, because I
have many missing data.
   
And if so, is it necessary to organize dataset in ts
structure or is it possible to consider it like a simple
vector?
   
Thanks in advance

Fabrizio Consentino



From kjetil at acelerate.com  Tue Mar  1 14:15:49 2005
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Tue, 01 Mar 2005 09:15:49 -0400
Subject: [R] draw random samples from empirical distribution
In-Reply-To: <20050228175431.13215.qmail@web50110.mail.yahoo.com>
References: <20050228175431.13215.qmail@web50110.mail.yahoo.com>
Message-ID: <42246B05.9000308@acelerate.com>

bogdan romocea wrote:

>Dear useRs,
>
>I have an empirical distribution (not normal etc) and I want to draw
>random samples from it. One solution I can think of is to compute let's
>say 100 quantiles, then use runif() to draw a random number Q between 1
>and 100, and finally run runif() again to pull a random value from the
>quantile Q. Is there perhaps a better/more elegant way of doing this?
>
>Thank you,
>b.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>
sample(mysample, n, replace=TRUE)

Kjetil

-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra





-- 
No virus found in this outgoing message.
Checked by AVG Anti-Virus.



From bates at stat.wisc.edu  Tue Mar  1 14:31:46 2005
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 01 Mar 2005 07:31:46 -0600
Subject: [R] Negative intercept in glm poisson model
In-Reply-To: <200503011510.35079.f.gherardini@pigrecodata.net>
References: <200503011510.35079.f.gherardini@pigrecodata.net>
Message-ID: <42246EC2.9050602@stat.wisc.edu>

Federico Gherardini wrote:

> I'm trying to fit a glm model using family=poisson(link = "identity"). The 
> problem is that the glm function fits a model with a negative intercept, 
> which sounds like a nonsense to me, being the response a Poisson variable. 

Not really.  The negative intercept is on the scale of the linear 
predictor.  The expected response, which is the exponential of the 
linear predictor, is always positive.



From p.dalgaard at biostat.ku.dk  Tue Mar  1 14:48:39 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 01 Mar 2005 14:48:39 +0100
Subject: [R] Negative intercept in glm poisson model
In-Reply-To: <42246EC2.9050602@stat.wisc.edu>
References: <200503011510.35079.f.gherardini@pigrecodata.net>
	<42246EC2.9050602@stat.wisc.edu>
Message-ID: <x2sm3fv5mw.fsf@biostat.ku.dk>

Douglas Bates <bates at stat.wisc.edu> writes:

> Federico Gherardini wrote:
> 
> > I'm trying to fit a glm model using family=poisson(link =
> > "identity"). The problem is that the glm function fits a model with
> > a negative intercept, which sounds like a nonsense to me, being the
> > response a Poisson variable.
> 
> Not really.  The negative intercept is on the scale of the linear
> predictor.  The expected response, which is the exponential of the
> linear predictor, is always positive.

Not when the link is "identity"...! However, in that case, sufficient
extrapolation will always lead to negative values, unless the slope is
exactly zero. Whether a negative value is a problem for the intercept
depends on whether it corresponds to a relevant extrapolation of data.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From f.gherardini at pigrecodata.net  Tue Mar  1 16:01:12 2005
From: f.gherardini at pigrecodata.net (Federico Gherardini)
Date: Tue, 1 Mar 2005 16:01:12 +0100
Subject: [R] Negative intercept in glm poisson model
In-Reply-To: <42246EC2.9050602@stat.wisc.edu>
References: <200503011510.35079.f.gherardini@pigrecodata.net>
	<42246EC2.9050602@stat.wisc.edu>
Message-ID: <200503011601.12745.f.gherardini@pigrecodata.net>

On Tuesday 01 March 2005 14:31, Douglas Bates wrote:
> Not really.  The negative intercept is on the scale of the linear
> predictor.  The expected response, which is the exponential of the
> linear predictor, is always positive.
Thank you very much for the quick response. Actually I used link = linear, so 
I suppose that the response is on the same scale of the linear predictor, 
isn't it?

Cheers,
Federico



From caroline.truntzer at chu-lyon.fr  Tue Mar  1 15:04:17 2005
From: caroline.truntzer at chu-lyon.fr (Caroline TRUNTZER)
Date: Tue, 01 Mar 2005 15:04:17 +0100
Subject: [R] Help : delete at random
Message-ID: <42247661.8CD13429@chu-lyon.fr>

Hello
I would like to delete some values at random in a data frame. Does
anyone know how I could do?
With best regards
Caroline



From bates at stat.wisc.edu  Tue Mar  1 15:07:11 2005
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 01 Mar 2005 08:07:11 -0600
Subject: [R] Negative intercept in glm poisson model
In-Reply-To: <x2sm3fv5mw.fsf@biostat.ku.dk>
References: <200503011510.35079.f.gherardini@pigrecodata.net>	<42246EC2.9050602@stat.wisc.edu>
	<x2sm3fv5mw.fsf@biostat.ku.dk>
Message-ID: <4224770F.20606@stat.wisc.edu>

Peter Dalgaard wrote:
> Douglas Bates <bates at stat.wisc.edu> writes:
>>Federico Gherardini wrote:
>>>I'm trying to fit a glm model using family=poisson(link =
>>>"identity"). The problem is that the glm function fits a model with
>>>a negative intercept, which sounds like a nonsense to me, being the
>>>response a Poisson variable.
>>
>>Not really.  The negative intercept is on the scale of the linear
>>predictor.  The expected response, which is the exponential of the
>>linear predictor, is always positive.
> 
> 
> Not when the link is "identity"...! However, in that case, sufficient
> extrapolation will always lead to negative values, unless the slope is
> exactly zero. Whether a negative value is a problem for the intercept
> depends on whether it corresponds to a relevant extrapolation of data.
> 

Yes, of course.  Must learn not to post to a public list before the 
second cup of coffee.



From sdavis2 at mail.nih.gov  Tue Mar  1 15:17:56 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 1 Mar 2005 09:17:56 -0500
Subject: [R] Help : delete at random
In-Reply-To: <42247661.8CD13429@chu-lyon.fr>
References: <42247661.8CD13429@chu-lyon.fr>
Message-ID: <d4baae6beaefcd32ac7b16ffbd64eed7@mail.nih.gov>

Caroline,

You probably want to look at ?sample.

Use sample to choose the rows for deletion then use:

df.new = df[-sampled,]

Sean

On Mar 1, 2005, at 9:04 AM, Caroline TRUNTZER wrote:

> Hello
> I would like to delete some values at random in a data frame. Does
> anyone know how I could do?
> With best regards
> Caroline
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From murdoch at stats.uwo.ca  Tue Mar  1 15:21:31 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 01 Mar 2005 14:21:31 +0000
Subject: [R] Negative intercept in glm poisson model
In-Reply-To: <200503011510.35079.f.gherardini@pigrecodata.net>
References: <200503011510.35079.f.gherardini@pigrecodata.net>
Message-ID: <hhq821hm7k6o1ssjo6o9jqid39f7reithq@4ax.com>

On Tue, 1 Mar 2005 15:10:35 +0100, Federico Gherardini
<f.gherardini at pigrecodata.net> wrote :

>Dear list,
>I'm trying to fit a glm model using family=poisson(link = "identity"). The 
>problem is that the glm function fits a model with a negative intercept, 
>which sounds like a nonsense to me, being the response a Poisson variable. 

>>From a previous discussion on this list I've understood that the glm function 
>uses IRLS for the fitting without any constraint so it is possible for it to 
>end up in a region of values which are not admissible given the model, and in 
>fact sometimes it fails asking for valid starting values. In this case I 
>expected it to fail asking to supply starting values, and instead it fits the 
>model just nice with this negative intercept. What am I missing?

The problem isn't in the software, it's due to using an identity link
with a model that does not allow a negative mean.  Suppose glm()
constrained the intercept to be positive, and you ended up fitting a
positive slope:  then you would still get negative predictions for
sufficiently large negative values of the predictor variables.

Duncan Murdoch



From MSchwartz at MedAnalytics.com  Tue Mar  1 15:28:25 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Tue, 01 Mar 2005 08:28:25 -0600
Subject: [R] Help : delete at random
In-Reply-To: <42247661.8CD13429@chu-lyon.fr>
References: <42247661.8CD13429@chu-lyon.fr>
Message-ID: <1109687306.11573.22.camel@horizons.localdomain>

On Tue, 2005-03-01 at 15:04 +0100, Caroline TRUNTZER wrote:
> Hello
> I would like to delete some values at random in a data frame. Does
> anyone know how I could do?
> With best regards
> Caroline


The basic process is to randomly select row indices from the possible
number of rows. If your data frame is 'df' and you want to randomly
delete 10 rows:

df.new <- df[-sample(1:nrow(df), 10), ]

The sample() function in this case randomly selects 10 values in the
range 1:nrow(df). Using the '-' then removes these rows in the
subsetting process, returning the new, smaller, data frame in df.new.

See ?sample and ?Extract for more information.

HTH,

Marc Schwartz



From ligges at statistik.uni-dortmund.de  Tue Mar  1 15:30:01 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 01 Mar 2005 15:30:01 +0100
Subject: [R] Help : delete at random
In-Reply-To: <42247661.8CD13429@chu-lyon.fr>
References: <42247661.8CD13429@chu-lyon.fr>
Message-ID: <42247C69.3090208@statistik.uni-dortmund.de>

Caroline TRUNTZER wrote:
> Hello
> I would like to delete some values at random in a data frame. Does
> anyone know how I could do?

What about sample()-ing (if I understand "at random" correctly) a 
certain number of values from 1:nrow(data) and using the result as 
negative index the data.frame?

Uwe Ligges


> With best regards
> Caroline
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From t.muhlhofer at lse.ac.uk  Tue Mar  1 15:29:05 2005
From: t.muhlhofer at lse.ac.uk (Tobias Muhlhofer)
Date: Tue, 01 Mar 2005 14:29:05 +0000
Subject: [R] GARCH
Message-ID: <42247C31.9030007@lse.ac.uk>

Hi, everyone!

Is there a function to do single-variable GARCH in R? If yes, what 
library is it in?

Thanks!
	Toby
-- 
**************************************************************************
When Thomas Edison invented the light bulb he tried over 2000
experiments before he got it to work. A young reporter asked
him how it felt to have failed so many times. He said
"I never failed once. I invented the light bulb.
It just happened to be a 2000-step process."



From murdoch at stats.uwo.ca  Tue Mar  1 15:28:36 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 01 Mar 2005 14:28:36 +0000
Subject: [R] Help : delete at random
In-Reply-To: <42247661.8CD13429@chu-lyon.fr>
References: <42247661.8CD13429@chu-lyon.fr>
Message-ID: <osu821pmcv6oh6eg3l1seqkgkj56grb7gf@4ax.com>

On Tue, 01 Mar 2005 15:04:17 +0100, Caroline TRUNTZER
<caroline.truntzer at chu-lyon.fr> wrote :

>Hello
>I would like to delete some values at random in a data frame. Does
>anyone know how I could do?

Assuming your data.frame is named df:

To delete index i, use df[-i, ] (i.e. the row selection is the
negative of the index you don't want).

This works for vectors i, so df[-sample(1:N, n), ]  would delete
a random selection of n rows from N.

Duncan Murdoch



From hook_l at bookofhook.com  Tue Mar  1 15:42:46 2005
From: hook_l at bookofhook.com (Brian Hook)
Date: Tue, 1 Mar 2005 09:42:46 -0500
Subject: [R] altering legend with plot(density(..))
Message-ID: <20053194246.503602@GATEWAY>

I'm having a hard time modifying the legend that is emitted by default 
when calling plot(density(...)) and then legend().  I've looked at the 
docs and I'm not sure what I'm doing wrong, if anything.  Any advice 
appreciated.

Thanks,

Brian



From Luisr at frs.fo  Tue Mar  1 15:50:35 2005
From: Luisr at frs.fo (Luis Ridao Cruz)
Date: Tue, 01 Mar 2005 14:50:35 +0000
Subject: [R] lattice -- panel order display
Message-ID: <s2248147.000@ffdata.setur.fo>

R-help,

I'm using 'xyplot' in lattice package which plots length frecuencies by
year (10).
The order I get is not logical and the 'index.cond' argument to
'xyplot' is a bit cumbersome when it comes to plot a great deal of (in
my case years).

I have tried sorting the conditioning variable but still get the same
result.

Is there any easy way to do it without making use of 'index.cond' ?

The function call is as follows:

xyplot ( number ~ cm | as.factor(test$year) , data=test)


Thanks in advance


> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    0.1            
year     2004           
month    11             
day      15             
language R



From Matthias.Templ at statistik.gv.at  Tue Mar  1 15:52:41 2005
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Tue, 1 Mar 2005 15:52:41 +0100
Subject: [R] Help : delete at random
Message-ID: <83536658864BC243BE3C06D7E936ABD5027BA912@xchg1.statistik.local>

Hello,

d <- data.frame(a=c(2,3,4), b=c(2,4,1), c=c(3,5,6))

## one NA

s.r <- sample(dim(d)[1], 1)
s.c <- sample(dim(d)[2], 1)

d.na <- d
d.na[s.r, s.c] <- NA
d.na

# Here a matrix is more comfortable by using sample.

For multiple NA, you should write a loop, but to choose e.g. exact 4 values, it might be, that one value is more than one times chosen.
For this purpose you can search at your NA by using which(is.na(d), arr.ind=TRUE) and count only if those index is not a NA at a while loop. This is not an elegant way, but probably it helps you a little bit.

Best,
Matthias



> -----Urspr?ngliche Nachricht-----
> Von: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] Im Auftrag von 
> Caroline TRUNTZER
> Gesendet: Dienstag, 01. M?rz 2005 15:04
> An: R-help at stat.math.ethz.ch
> Betreff: [R] Help : delete at random
> 
> 
> Hello
> I would like to delete some values at random in a data frame. 
> Does anyone know how I could do? With best regards Caroline
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read 
> the posting guide! http://www.R-project.org/posting-guide.html
>



From ramasamy at cancer.org.uk  Tue Mar  1 16:07:07 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 01 Mar 2005 15:07:07 +0000
Subject: [R] part of name  to Date
In-Reply-To: <422461B0.8050107@bordeaux.inra.fr>
References: <422461B0.8050107@bordeaux.inra.fr>
Message-ID: <1109689627.6153.85.camel@ndmpc126.orc.ox.ac.uk>

Here is one way

x <- c( "VGT1_CONTR_B020020301.H0V0.MIR", 
	"VGT1_VGT2_CONTR_B020020611.H0V0.MIR", 
	"VGT1_VGT2_CONTR_B020030401.H0V0.MIR", 
	"VGT1_VGT2_CONTR_B020030711.H0V0.MIR", 
	"VGT1_VGT2_CONTR_B020031211.H0V0.MIR" )

( tmp1 <- sapply( strsplit(x, split="_"), tail, n=1 ) )
[1] "B020020301.H0V0.MIR" "B020020611.H0V0.MIR" "B020030401.H0V0.MIR"
[4] "B020030711.H0V0.MIR" "B020031211.H0V0.MIR"

( tmp2 <- sapply( strsplit( tmp1, split="\\." ), head, n=1 ) )
[1] "B020020301" "B020020611" "B020030401" "B020030711" "B020031211"

gsub( "B", "", tmp2 )
[1] "020020301" "020020611" "020030401" "020030711" "020031211"
 

Here is another approach using regular expressions. Please be careful
with my one-liner as I am no expert in this. Maybe someone on the list
can point if there are any errors 
	gsub(".*\_B?(.*)\\.H.*", "\\1", x)


If you want reliability, go with the first suggestion.

Regards, Adai



On Tue, 2005-03-01 at 13:36 +0100, Jonathan Charrier wrote:
> hi everybody,
> 
> i try to extract  a part of name to a date :
> 
> like : "VGT1_VGT2_CONTR_B020030401.H0V0.MIR"    to    "20030401"
> 
> but the beginning of the files changes
> 
> i have a list of files:
> 
>  [,1]                                
> [1,] "VGT1_CONTR_B020020301.H0V0.MIR"                                 
> [2,] "VGT1_VGT2_CONTR_B020020611.H0V0.MIR"
> [3,] "VGT1_VGT2_CONTR_B020030401.H0V0.MIR"
> [4,] "VGT1_VGT2_CONTR_B020030711.H0V0.MIR"
> [5,] "VGT1_VGT2_CONTR_B020031211.H0V0.MIR"
> 
> i try the function "get()" and  "assign()" but without succeed
> 
> i know it's easy in C but in R i don't know the way
> 
> 
> if you have an idee
> 
> 
> thanks ,
> 
> Jonathan Charrier
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From helprhelp at gmail.com  Tue Mar  1 16:16:23 2005
From: helprhelp at gmail.com (WeiWei Shi)
Date: Tue, 1 Mar 2005 09:16:23 -0600
Subject: [R] repost my question of cda in case
In-Reply-To: <cdf81783050225103850689476@mail.gmail.com>
References: <cdf81783050225103850689476@mail.gmail.com>
Message-ID: <cdf8178305030107165a3e5a7b@mail.gmail.com>

Dear R-helpers:

I sent this question 3 days ago but I didn't get any reply. In case
this question was somewhat not seen by people who happpened to know
the answer, I repost it here. Sorry for bother but I am kind of
needing some help. BTW, if the question itself was not well expressed,
please let me know.

The question is as followed:


I am wondering if I can get some general help or source about
canonical discriminant analysis in R.

My idea is trying to linearly "combine" 300 variables supervisely
(according to the class lables to the observations". I think it is
kinda PCA to do some decreasing dimentionality work, but w/
considering the class and I used SAS to do CDA proc before.

But I read the introduction from sas on this proc and found the
following statement:

"The process of extracting canonical variables can be repeated until
the number of canonical variables equals the number of original
variables or the number of classes minus one, whichever is smaller.
"
does it mean I can only have two new variables if  I only have 2 classes?

I am not a stat guy and sorry for the question if it should not be
addressed here.

Ed



From marta at statistica.it  Tue Mar  1 16:23:17 2005
From: marta at statistica.it (marta@statistica.it)
Date: Tue, 1 Mar 2005 16:23:17 +0100 (CET)
Subject: [R] write a library under 2.0.1 version
Message-ID: <4248.155.198.41.106.1109690597.squirrel@ensim-2.playnet.it>

Hi there,
I had written a library under R 1.9.0 and now I would like to import that
library under R 2.0.1
Apparently it does not work; I can install the package, but when I try to
read it the error is the following:

Error in library(compvar) : 'compvar' is not a valid package -- installed
< 2.0.0

I have checked other libraries in R 2.0.1 and I noticed that there is a
new folders (Meta) that were not present under R 1.9.1 as well as a file
(MD5). Moreover, under R folders there are files with .rdx and .rdb
extensions that were not present before.

I was wondering how I can built these files for the library to be
importable under 2.0.1 version.

Any suggestion?

Cheers,
Marta



From ligges at statistik.uni-dortmund.de  Tue Mar  1 16:38:42 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 01 Mar 2005 16:38:42 +0100
Subject: [R] altering legend with plot(density(..))
In-Reply-To: <20053194246.503602@GATEWAY>
References: <20053194246.503602@GATEWAY>
Message-ID: <42248C82.60807@statistik.uni-dortmund.de>

Brian Hook wrote:

> I'm having a hard time modifying the legend that is emitted by default 
> when calling plot(density(...)) and then legend().  I've looked at the 
> docs and I'm not sure what I'm doing wrong, if anything.  Any advice 
> appreciated.

So, can you tell us what is wrong with
   set.seed(123)
   plot(density(rnorm(100)))
and where the legend is? Maybe you don't like the defaults for "xlab" or 
"main"?

Uwe Ligges

> Thanks,
> 
> Brian
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Tue Mar  1 16:40:15 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 01 Mar 2005 16:40:15 +0100
Subject: [R] lattice -- panel order display
In-Reply-To: <s2248147.000@ffdata.setur.fo>
References: <s2248147.000@ffdata.setur.fo>
Message-ID: <42248CDF.9080905@statistik.uni-dortmund.de>

Luis Ridao Cruz wrote:

> R-help,
> 
> I'm using 'xyplot' in lattice package which plots length frecuencies by
> year (10).
> The order I get is not logical and the 'index.cond' argument to
> 'xyplot' is a bit cumbersome when it comes to plot a great deal of (in
> my case years).
> 
> I have tried sorting the conditioning variable but still get the same
> result.
> 
> Is there any easy way to do it without making use of 'index.cond' ?
> 
> The function call is as follows:
> 
> xyplot ( number ~ cm | as.factor(test$year) , data=test)

Not reproducible for us, we don't have "test", so please make your 
example small and reproducible.

Uwe Ligges

> 
> Thanks in advance
> 
> 
> 
>>version
> 
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    2              
> minor    0.1            
> year     2004           
> month    11             
> day      15             
> language R
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From shigesong at gmail.com  Tue Mar  1 16:42:58 2005
From: shigesong at gmail.com (Shige Song)
Date: Tue, 1 Mar 2005 23:42:58 +0800
Subject: [R] Using mutiply imputed data in NLME
In-Reply-To: <88EAF3512A55DF46B06B1954AEF73F7407E57AE5@dc1ex2.air.org>
References: <88EAF3512A55DF46B06B1954AEF73F7407E57AE5@dc1ex2.air.org>
Message-ID: <5abc11d805030107424bc19e5e@mail.gmail.com>

For example

Will NLME work with mitools written by Thomas Lumley?

Shige

On Mon, 28 Feb 2005 13:02:54 -0500, Doran, Harold <HDoran at air.org> wrote:
> Well, I may be missing something but why don't you call each dataframe
> from within a loop and save the results in a new data frame each time?
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Shige Song
> Sent: Monday, February 28, 2005 12:18 PM
> To: R-help at stat.math.ethz.ch
> Subject: [R] Using mutiply imputed data in NLME
> 
> Dear All,
> 
> I am doing a growth modeling using NLME. I have three levels in my
> data: observation, individual, household. About half of my total sample
> have missing values in my household-level covariates. Under this
> situation, the best way to go is probably to multiply impute the data
> (for, say, 5 times), estimate the same model separately on each model
> using LME function, and merge the results. My question is: given the
> multiply imputed data sets have already been generated, is there a
> simple way to automate the process of estimating the mixed model and
> merging the results? HLM has similar features...
> 
> Thanks!
> 
> Best,
> Shige
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
>



From Luisr at frs.fo  Tue Mar  1 16:53:01 2005
From: Luisr at frs.fo (Luis Ridao Cruz)
Date: Tue, 01 Mar 2005 15:53:01 +0000
Subject: [R] lattice -- panel order display
Message-ID: <s2248fe4.029@ffdata.setur.fo>


Here is a 'subset' of the ' test ' data .

xyplot ( number ~ cm | as.factor(test$year) , data=test)

> test
    year cm number
34  1995 72     34
35  1995 73     37
36  1995 74     31
37  1995 75     13
38  1995 76     18
39  1995 77      4
40  1995 78     10
41  1995 79      6
42  1995 80      4
43  1995 81      2
44  1995 83      2
45  1995 84      5
46  1995 87      1
47  1996 32      2
48  1996 34      6
49  1996 36      1
50  1996 37     31
51  1996 38     11
52  1996 39     58
53  1996 40    134
54  1996 41    164
55  1996 42    391
94  1997 40      2
95  1997 41      1
96  1997 42      5
97  1997 43     37
142 1998 38      6
143 1998 39      8
144 1998 40     10
145 1998 41     22
146 1998 42     43
191 1999 35      2
192 1999 36     10
193 1999 37      4
194 1999 38     12
195 1999 39     34
196 1999 40     60
239 2000 38      1
240 2000 39      5
241 2000 40      2
242 2000 41      7
243 2000 42     21
284 2001 38      1
285 2001 39      5
286 2001 40      6
287 2001 41     14
288 2001 42     56
289 2001 43     68
332 2002 32      1
333 2002 36     12
334 2002 37      3
335 2002 38      4
336 2002 39     13
386 2003 34      3
387 2003 37      3
388 2003 38      2
389 2003 39      4
390 2003 40     26
391 2003 41     25
392 2003 42     41
393 2003 43     59
438 2004 35      4
439 2004 36      3
440 2004 37      4
441 2004 38     18
442 2004 39     24
443 2004 40     50

>>> Uwe Ligges <ligges at statistik.uni-dortmund.de> 01/03/2005 15:40:15
>>>
Luis Ridao Cruz wrote:

> R-help,
> 
> I'm using 'xyplot' in lattice package which plots length frecuencies
by
> year (10).
> The order I get is not logical and the 'index.cond' argument to
> 'xyplot' is a bit cumbersome when it comes to plot a great deal of
(in
> my case years).
> 
> I have tried sorting the conditioning variable but still get the
same
> result.
> 
> Is there any easy way to do it without making use of 'index.cond' ?
> 
> The function call is as follows:
> 
> xyplot ( number ~ cm | as.factor(test$year) , data=test)

Not reproducible for us, we don't have "test", so please make your 
example small and reproducible.

Uwe Ligges

> 
> Thanks in advance
> 
> 
> 
>>version
> 
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    2              
> minor    0.1            
> year     2004           
> month    11             
> day      15             
> language R
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ramasamy at cancer.org.uk  Tue Mar  1 16:54:21 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 01 Mar 2005 15:54:21 +0000
Subject: [R] Help : delete at random
In-Reply-To: <42247C69.3090208@statistik.uni-dortmund.de>
References: <42247661.8CD13429@chu-lyon.fr>
	<42247C69.3090208@statistik.uni-dortmund.de>
Message-ID: <1109692461.6153.98.camel@ndmpc126.orc.ox.ac.uk>

Might be slightly more interesting. If we want to generate values which
are completely missing at random, then we can just simply sample all
available index of a 2-d array.

 
# simulate data #
 set.seed(1) # for reproducibility
 m <- matrix( rnorm(12), nr=4, nc=3 )
 m
           [,1]       [,2]       [,3]
[1,] -0.6264538  0.3295078  0.5757814
[2,]  0.1836433 -0.8204684 -0.3053884
[3,] -0.8356286  0.4874291  1.5117812
[4,]  1.5952808  0.7383247  0.3898432
   

 indices  <- expand.grid( row=1:nrow(m), col=1:ncol(m) )
                               # generate all possible indices
 N        <- ncol(m)*nrow(m)   # number of total elements


Now suppose you want to generate 25% missing values, then

 k <- round( 0.25 * N )
 w <- as.matrix( indices[ sample( 1:N, k ), ] )
 w            # shows the row and column numbers that will be imputed
   row col
4    4   1
5    1   2
1    1   1

  
 m[ w ] <- NA    # impute NAs
 m
           [,1]       [,2]       [,3]
[1,]         NA		NA  0.5757814
[2,]  0.1836433 -0.8204684 -0.3053884
[3,] -0.8356286  0.4874291  1.5117812
[4,]  	     NA  0.7383247  0.3898432


Regards, Adai



On Tue, 2005-03-01 at 15:30 +0100, Uwe Ligges wrote:
> Caroline TRUNTZER wrote:
> > Hello
> > I would like to delete some values at random in a data frame. Does
> > anyone know how I could do?
> 
> What about sample()-ing (if I understand "at random" correctly) a 
> certain number of values from 1:nrow(data) and using the result as 
> negative index the data.frame?
> 
> Uwe Ligges
> 
> 
> > With best regards
> > Caroline
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From sundar.dorai-raj at pdf.com  Tue Mar  1 17:04:34 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 01 Mar 2005 10:04:34 -0600
Subject: [R] lattice -- panel order display
In-Reply-To: <s2248147.000@ffdata.setur.fo>
References: <s2248147.000@ffdata.setur.fo>
Message-ID: <42249292.1050500@pdf.com>



Luis Ridao Cruz allegedly said on 3/1/2005 8:50 AM:
> R-help,
> 
> I'm using 'xyplot' in lattice package which plots length frecuencies by
> year (10).
> The order I get is not logical and the 'index.cond' argument to
> 'xyplot' is a bit cumbersome when it comes to plot a great deal of (in
> my case years).
> 
> I have tried sorting the conditioning variable but still get the same
> result.
> 
> Is there any easy way to do it without making use of 'index.cond' ?
> 
> The function call is as follows:
> 
> xyplot ( number ~ cm | as.factor(test$year) , data=test)
> 
> 
> Thanks in advance
> 
> 
> 
>>version
> 
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    2              
> minor    0.1            
> year     2004           
> month    11             
> day      15             
> language R
> 


Luis,

You should set test$year as ?ordered:

# set `levels' to the order you want the panels to appear
test$year <- ordered(test$year, levels = .......)
xyplot ( number ~ cm | year , data = test)

--sundar



From deepayan at stat.wisc.edu  Tue Mar  1 17:08:28 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 1 Mar 2005 10:08:28 -0600
Subject: [R] lattice -- panel order display
In-Reply-To: <s2248147.000@ffdata.setur.fo>
References: <s2248147.000@ffdata.setur.fo>
Message-ID: <200503011008.28154.deepayan@stat.wisc.edu>

On Tuesday 01 March 2005 08:50, Luis Ridao Cruz wrote:
> R-help,
>
> I'm using 'xyplot' in lattice package which plots length frecuencies
> by year (10).
> The order I get is not logical and the 'index.cond' argument to
> 'xyplot' is a bit cumbersome when it comes to plot a great deal of
> (in my case years).
>
> I have tried sorting the conditioning variable but still get the same
> result.
>
> Is there any easy way to do it without making use of 'index.cond' ?
>
> The function call is as follows:
>
> xyplot ( number ~ cm | as.factor(test$year) , data=test)

The order of panels would be the same as you would get by 

> levels(as.factor(test$year))

So what you really need to figure out is how to explicitly specify the 
order of levels when creating a factor. In other words, this is not a 
lattice issue.

How best to do this depends on details you haven't given, specifically, 
what you think the 'logical' order is. Reading ?factor 
and ?reorder.factor might help.

-Deepayan



From KWollenberg at tufts-nemc.org  Tue Mar  1 17:08:28 2005
From: KWollenberg at tufts-nemc.org (Wollenberg, Kurt R)
Date: Tue, 1 Mar 2005 11:08:28 -0500 
Subject: [R] Two problems building a package
Message-ID: <A16C769D4A7E564597075EA02A91C003047E87E1@neexchange01.nemc.org>

Hello all:

I have written a few R scripts and am trying to turn them into a package for
submission to CRAN. All of these scripts are R code only, no C or C++ or
anything else. I'm working with R 2.0.1 running on a Windows XP machine. So
far running ">rcmd install --build --docs=normal mypkge" seems to work
(i.e., the library "mypkge" is installed in R\rw2001\library and the library
loads and the scripts do what I have written them to do). 

While this is all well and good I have two (hopefully small) problems.
First, running ">rcmd check mypkge" on R\rw2001\bin\mypkg (not
R\rw2001\library\mtpkge) returns the error "\bin\mypkge is not a source
package." Have I got something very wrong or am I misunderstanding which
directory contains the "source" package? Second, I've included some
equations in the Details section of one of my .Rd files and would like to
check that I've coded them correctly in the documentation before submission.
So far, my html and latex docs don't contain a details section, even though
they contain all other recent changes. My detail section looks like this:

\details{blah blah blah 
    \deqn{blah = Blah}{%
      blah = Blah}
where 	\eqn{blah}{%blah} = frequency of \emph{b} in Blah.

  Blah blah blah.
}

Any help would be greatly appreciated.

Cheers,
Kurt Wollenberg, PhD
Tufts Center for Vision Research 
New England Medical Center
750 Washington St, Box 450 
Boston, MA, USA
kwollenberg at tufts-nemc.org 
617-636-8945 (Fax)
617-636-9028 (Lab)

The most exciting phrase to hear in science, the one that heralds new
discoveries, is not "Eureka!" (I found it!) but  "That's funny ..." 
--Isaac Asimov


********************** 
Confidentiality Notice\ **********************\      The inf...{{dropped}}



From ligges at statistik.uni-dortmund.de  Tue Mar  1 17:08:32 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 01 Mar 2005 17:08:32 +0100
Subject: [R] lattice -- panel order display
In-Reply-To: <s2248fe4.030@ffdata.setur.fo>
References: <s2248fe4.030@ffdata.setur.fo>
Message-ID: <42249380.6060406@statistik.uni-dortmund.de>

Luis Ridao Cruz wrote:

> Here is a 'subset' of the ' test ' data .
> 
> xyplot ( number ~ cm | as.factor(test$year) , data=test)
> 
> 
>>test
> 
>     year cm number
> 34  1995 72     34
> 35  1995 73     37
>

[SNIP, was NTW a) not easily reproducible and b) too much waste of bandwith]


I still don't see any problem?

The order seems to be fine, and setting "index.cond" works as expected ...

Uwe Ligges




> 
> 
>>>>Uwe Ligges <ligges at statistik.uni-dortmund.de> 01/03/2005 15:40:15
>>>>
> 
> Luis Ridao Cruz wrote:
> 
> 
>>R-help,
>>
>>I'm using 'xyplot' in lattice package which plots length frecuencies
> 
> by
> 
>>year (10).
>>The order I get is not logical and the 'index.cond' argument to
>>'xyplot' is a bit cumbersome when it comes to plot a great deal of
> 
> (in
> 
>>my case years).
>>
>>I have tried sorting the conditioning variable but still get the
> 
> same
> 
>>result.
>>
>>Is there any easy way to do it without making use of 'index.cond' ?
>>
>>The function call is as follows:
>>
>>xyplot ( number ~ cm | as.factor(test$year) , data=test)
> 
> 
> Not reproducible for us, we don't have "test", so please make your 
> example small and reproducible.
> 
> Uwe Ligges
> 
> 
>>Thanks in advance
>>
>>
>>
>>
>>>version
>>
>>         _              
>>platform i386-pc-mingw32
>>arch     i386           
>>os       mingw32        
>>system   i386, mingw32  
>>status                  
>>major    2              
>>minor    0.1            
>>year     2004           
>>month    11             
>>day      15             
>>language R
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help 
>>PLEASE do read the posting guide!
> 
> http://www.R-project.org/posting-guide.html



From hook_l at bookofhook.com  Tue Mar  1 17:09:29 2005
From: hook_l at bookofhook.com (Brian Hook)
Date: Tue, 1 Mar 2005 11:09:29 -0500
Subject: [R] altering legend with plot(density(..))
In-Reply-To: <42248C82.60807@statistik.uni-dortmund.de>
Message-ID: <20053111929.606882@GATEWAY>

 On Tue, 01 Mar 2005 16:38:42 +0100, Uwe Ligges wrote:

> So, can you tell us what is wrong with
> set.seed(123)
> plot(density(rnorm(100)))
> and where the legend is? Maybe you don't like the defaults for
> "xlab" or "main"?

Ah, yes, I was confusing xlab with the legend.  Sorry for that.  In 
addition, "legend" wasn't showing up where I expected (beneath xlab) 
-- is there a way to put a legend outside of the graph itself?

Thank you,

Brian



From ligges at statistik.uni-dortmund.de  Tue Mar  1 17:14:06 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 01 Mar 2005 17:14:06 +0100
Subject: [R] write a library under 2.0.1 version
In-Reply-To: <4248.155.198.41.106.1109690597.squirrel@ensim-2.playnet.it>
References: <4248.155.198.41.106.1109690597.squirrel@ensim-2.playnet.it>
Message-ID: <422494CE.2090102@statistik.uni-dortmund.de>

marta at statistica.it wrote:

> Hi there,
> I had written a library

You are talking about a *package*, I guess.


> under R 1.9.0 and now I would like to import that
> library under R 2.0.1

You have to (re-)install it from the sources.

> Apparently it does not work; I can install the package, but when I try to
> read it the error is the following:
> 
> Error in library(compvar) : 'compvar' is not a valid package -- installed
> < 2.0.0
 >
> I have checked other libraries in R 2.0.1 and I noticed that there is a
> new folders (Meta) that were not present under R 1.9.1 as well as a file
> (MD5). Moreover, under R folders there are files with .rdx and .rdb
> extensions that were not present before.

Right, lazy loading database.

> I was wondering how I can built these files for the library to be
> importable under 2.0.1 version.

I guess you are under Windows?
Please read the R FAQ, the R for Windows FAQ, the manual "Writing R 
Extensions" and also ?INSTALL. All of them mention how to install from 
the package's sources.

Uwe Ligges


> 
> Any suggestion?
> 
> Cheers,
> Marta
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Tue Mar  1 17:17:17 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 01 Mar 2005 17:17:17 +0100
Subject: [R] altering legend with plot(density(..))
In-Reply-To: <20053111929.606882@GATEWAY>
References: <20053111929.606882@GATEWAY>
Message-ID: <4224958D.5040601@statistik.uni-dortmund.de>

Brian Hook wrote:

>  On Tue, 01 Mar 2005 16:38:42 +0100, Uwe Ligges wrote:
> 
> 
>>So, can you tell us what is wrong with
>>set.seed(123)
>>plot(density(rnorm(100)))
>>and where the legend is? Maybe you don't like the defaults for
>>"xlab" or "main"?
> 
> 
> Ah, yes, I was confusing xlab with the legend.  Sorry for that.  In
> addition, "legend" wasn't showing up where I expected (beneath xlab)
> -- is there a way to put a legend outside of the graph itself?

So you are using legend() specifying coordinates outside the plot region?

Yes, it work if you set par(xpd=TRUE) before, see ?par.

Uwe Ligges




> Thank you,
> 
> Brian
>



From maechler at stat.math.ethz.ch  Tue Mar  1 17:18:34 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 1 Mar 2005 17:18:34 +0100
Subject: [R] altering legend with plot(density(..))
In-Reply-To: <20053194246.503602@GATEWAY>
References: <20053194246.503602@GATEWAY>
Message-ID: <16932.38362.959678.797803@stat.math.ethz.ch>

>>>>> "Brian" == Brian Hook <hook_l at bookofhook.com>
>>>>>     on Tue, 1 Mar 2005 09:42:46 -0500 writes:

    Brian> I'm having a hard time modifying the legend that is
    Brian> emitted by default when calling plot(density(...))
    Brian> and then legend().  I've looked at the docs and I'm
    Brian> not sure what I'm doing wrong, if anything.  Any
    Brian> advice appreciated.

    Brian> ______________________________________________
    Brian> R-help at stat.math.ethz.ch mailing list
    Brian> https://stat.ethz.ch/mailman/listinfo/r-help
    Brian> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

could  PLEASE do what the line above asks you to do,
and then re-post your question accordingly?

Thank you,
Martin Maechler, ETH Zurich



From pburns at pburns.seanet.com  Tue Mar  1 17:18:49 2005
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Tue, 01 Mar 2005 16:18:49 +0000
Subject: [R] GARCH
In-Reply-To: <42247C31.9030007@lse.ac.uk>
References: <42247C31.9030007@lse.ac.uk>
Message-ID: <422495E9.9080506@pburns.seanet.com>

Yes.  Probably the best approach is if you go to the Rmetrics website
http://www.rmetrics.org/

Patrick Burns

Burns Statistics
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Tobias Muhlhofer wrote:

> Hi, everyone!
>
> Is there a function to do single-variable GARCH in R? If yes, what 
> library is it in?
>
> Thanks!
>     Toby



From br44114 at yahoo.com  Tue Mar  1 17:20:12 2005
From: br44114 at yahoo.com (bogdan romocea)
Date: Tue, 1 Mar 2005 08:20:12 -0800 (PST)
Subject: [R] Temporal Analysis of variable x;
	How to select the outlier threshold in R?
Message-ID: <20050301162012.62604.qmail@web50101.mail.yahoo.com>

I'm not sure I understand. 
You have financial data and want to throw away some outliers?? 
Why would you ever do this?

First of all, I'd suggest you pay close attention to what the data is
trying to say. Maybe your distribution is not normal after all (see
tests for normality etc). Maybe you shouldn't force your normality
assumption upon the data. 



-----Original Message-----
From: Melanie Vida [mailto:mvida at mitre.org]
Sent: Friday, February 25, 2005 1:30 PM
To: r-help
Subject: [R] Temporal Analysis of variable x; How to select the outlier
threshold in R?


For a financial data set with large variance, I'm trying to find the 
outlier threshold of one variable "x" over a two year period. I 
qqplot(x2001, x2002) and found a normal distribution. The latter part
of 
the normal distribution did not look linear though. Is there a suitable

method in R to find the outlier threshold of this variable from 2001
and 
2002  in R?

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From maechler at stat.math.ethz.ch  Tue Mar  1 17:28:04 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 1 Mar 2005 17:28:04 +0100
Subject: [R] write a **package** under 2.0.1 version
In-Reply-To: <4248.155.198.41.106.1109690597.squirrel@ensim-2.playnet.it>
References: <4248.155.198.41.106.1109690597.squirrel@ensim-2.playnet.it>
Message-ID: <16932.38932.907926.741701@stat.math.ethz.ch>

>>>>> "marta" == marta  <marta at statistica.it>
>>>>>     on Tue, 1 Mar 2005 16:23:17 +0100 (CET) writes:

    marta> Hi there,
    marta> I had written a library under R 1.9.0 and now I would like to import that
    marta> library under R 2.0.1

"package", "package", "package" -- a "library" is something
really different!

    marta> Apparently it does not work; I can install the
    marta> package, but when I try to read it the error is the
    marta> following:

    marta> Error in library(compvar) : 'compvar' is not a valid package -- installed
    marta> < 2.0.0


so you haven't really "installed" in the sense of "Rcmd INSTALL <pkgname>"
[ You didn't tell us, but you probably are using Micro$oft Windows?
  On other platforms its "R CMD INSTALL <pkgname>"   ]

and you (or whoever provided the ``pre-compiled'' package to you)
must run "Rcmd INSTALL" on that package where 'Rcmd' is any R
version 2.x.y (2.0.1, typically).

However, this won't work easily for you if you are on Windows,
since you need to first install quite a few tools before you can
build and install packages ```from source''
--> read the 'rw-faq' i.e. "R for windows Frequently Asked
Questions (and answers)" that is accessible from the [Help] menu
on Windows.

    marta> I have checked other libraries in R 2.0.1 and I
other >> packages <<

    marta> noticed that there is a new folders (Meta) that were
    marta> not present under R 1.9.1 as well as a file
    marta> (MD5). Moreover, under R folders there are files with
    marta> .rdx and .rdb extensions that were not present
    marta> before.

these are rather in connection with Lazyloading and other
features that more packages are using, but you shouldn't have to
know about.

    marta> I was wondering how I can built these files for the library to be
    marta> importable under 2.0.1 version.

    marta> Any suggestion?

"Rcmd INSTALL" (but see above)

Regards,
Martin Maechler, ETH Zurich



From murdoch at stats.uwo.ca  Tue Mar  1 17:35:34 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 01 Mar 2005 16:35:34 +0000
Subject: [R] write a library under 2.0.1 version
In-Reply-To: <4248.155.198.41.106.1109690597.squirrel@ensim-2.playnet.it>
References: <4248.155.198.41.106.1109690597.squirrel@ensim-2.playnet.it>
Message-ID: <ga6921pq0du2a8b6ikgcmt0p746n5jq74q@4ax.com>

On Tue, 1 Mar 2005 16:23:17 +0100 (CET), marta at statistica.it wrote :

>Hi there,
>I had written a library under R 1.9.0 and now I would like to import that
>library under R 2.0.1
>Apparently it does not work; I can install the package, but when I try to
>read it the error is the following:
>
>Error in library(compvar) : 'compvar' is not a valid package -- installed
>< 2.0.0
>
>I have checked other libraries in R 2.0.1 and I noticed that there is a
>new folders (Meta) that were not present under R 1.9.1 as well as a file
>(MD5). Moreover, under R folders there are files with .rdx and .rdb
>extensions that were not present before.
>
>I was wondering how I can built these files for the library to be
>importable under 2.0.1 version.
>
>Any suggestion?

You need to use R CMD INSTALL path-to-src-package

to build those files and install the package properly.  Simply copying
it into place doesn't work.  See the Writing R Extensions manual for
more details.

Duncan Murdoch



From sundar.dorai-raj at pdf.com  Tue Mar  1 17:36:21 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 01 Mar 2005 10:36:21 -0600
Subject: [R] lattice -- panel order display
In-Reply-To: <s2248fe4.029@ffdata.setur.fo>
References: <s2248fe4.029@ffdata.setur.fo>
Message-ID: <42249A05.1090006@pdf.com>



Luis Ridao Cruz allegedly said on 3/1/2005 9:53 AM:
> Here is a 'subset' of the ' test ' data .
> 
> xyplot ( number ~ cm | as.factor(test$year) , data=test)
> 
> 

<snip data>


Luis,

So what order are you expecting? Perhaps using `as.table = TRUE' is what 
you want??

xyplot(number ~ cm | as.factor(year), test, as.table = TRUE)


--sundar

> 
> 
>>>>Uwe Ligges <ligges at statistik.uni-dortmund.de> 01/03/2005 15:40:15
>>>>
> 
> Luis Ridao Cruz wrote:
> 
> 
>>R-help,
>>
>>I'm using 'xyplot' in lattice package which plots length frecuencies
> 
> by
> 
>>year (10).
>>The order I get is not logical and the 'index.cond' argument to
>>'xyplot' is a bit cumbersome when it comes to plot a great deal of
> 
> (in
> 
>>my case years).
>>
>>I have tried sorting the conditioning variable but still get the
> 
> same
> 
>>result.
>>
>>Is there any easy way to do it without making use of 'index.cond' ?
>>
>>The function call is as follows:
>>
>>xyplot ( number ~ cm | as.factor(test$year) , data=test)
> 
> 
> Not reproducible for us, we don't have "test", so please make your 
> example small and reproducible.
> 
> Uwe Ligges
> 
> 
>>Thanks in advance
>>
>>
>>
>>
>>>version
>>
>>         _              
>>platform i386-pc-mingw32
>>arch     i386           
>>os       mingw32        
>>system   i386, mingw32  
>>status                  
>>major    2              
>>minor    0.1            
>>year     2004           
>>month    11             
>>day      15             
>>language R
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help 
>>PLEASE do read the posting guide!
> 
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Luisr at frs.fo  Tue Mar  1 17:41:35 2005
From: Luisr at frs.fo (Luis Ridao Cruz)
Date: Tue, 01 Mar 2005 16:41:35 +0000
Subject: [R] lattice -- panel order display
Message-ID: <s2249b47.052@ffdata.setur.fo>

I do the following:

test$year <- factor (test$year , ordered = TRUE)
xyplot ( number~cm | year, data = test , type = "l" )

and still get the same.


Luis

>>> Sundar Dorai-Raj <sundar.dorai-raj at pdf.com> 01/03/2005 16:04:34
>>>


Luis Ridao Cruz allegedly said on 3/1/2005 8:50 AM:
> R-help,
> 
> I'm using 'xyplot' in lattice package which plots length frecuencies
by
> year (10).
> The order I get is not logical and the 'index.cond' argument to
> 'xyplot' is a bit cumbersome when it comes to plot a great deal of
(in
> my case years).
> 
> I have tried sorting the conditioning variable but still get the
same
> result.
> 
> Is there any easy way to do it without making use of 'index.cond' ?
> 
> The function call is as follows:
> 
> xyplot ( number ~ cm | as.factor(test$year) , data=test)
> 
> 
> Thanks in advance
> 
> 
> 
>>version
> 
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    2              
> minor    0.1            
> year     2004           
> month    11             
> day      15             
> language R
> 


Luis,

You should set test$year as ?ordered:

# set `levels' to the order you want the panels to appear
test$year <- ordered(test$year, levels = .......)
xyplot ( number ~ cm | year , data = test)

--sundar



From bill.shipley at usherbrooke.ca  Tue Mar  1 17:47:00 2005
From: bill.shipley at usherbrooke.ca (Bill Shipley)
Date: Tue, 1 Mar 2005 11:47:00 -0500
Subject: [R] constraining initial slope in smoother.spline
Message-ID: <002301c51e7e$4a18a990$ae1ad284@BIO041>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050301/8bc0a13b/attachment.pl

From achilleas.psomas at wsl.ch  Tue Mar  1 17:53:29 2005
From: achilleas.psomas at wsl.ch (achilleas.psomas@wsl.ch)
Date: Tue,  1 Mar 2005 17:53:29 +0100
Subject: [R] Data in an object = Existing Objects??
In-Reply-To: <1107965723.420a371b2bf55@webmail.wsl.ch>
References: <1107965723.420a371b2bf55@webmail.wsl.ch>
Message-ID: <1109696009.42249e091fbef@webmail.wsl.ch>

Dear R-help...

I am rather new so I would appreciate your help..
My question if the following..

I have generated (with R) a data frame DF looking like this..

> print(DF)
       X1      X2
2   C_05_04 C_05_11
3   C_05_04 C_05_17
4   C_05_04 C_06_08
5   C_05_04 C_06_29
6   C_05_04 C_07_16


Where "C_05_04"....and all the rest data are objects-names already calculated
and existing in my R workspace...
What i tried to do (and i doesnt work) is the following
e.g

x1 <- DF[1,1]
  C_05_04

(Where C_05_04 exists as an object in the workspace )
and then try to apply any kind of function using this x1
Is there a way to specify that x1 should be concidered as an object and not just
as data ?


I hope i have explained clearly enough my question..

I would appreciate any help.

Achilleas.



From R.P.Clement at westminster.ac.uk  Tue Mar  1 22:52:55 2005
From: R.P.Clement at westminster.ac.uk (Ross Clement)
Date: 01 Mar 2005 16:52:55 -0500
Subject: [R] Fun and games with lowess()
Message-ID: <1109713975.3311.48.camel@staff-pc01.harrowscs.westminster.ac.uk>

This is not a "help" request, just an experience with R that I found
amusing.

I have a machine learning module that I teach which was originally all
symbolic, but has a slowly growing numeric/statistical component.

Today I taught a two part lecture on instance based methods for
learning, with the first half being simple KNN, then kernel methods for
regression. The second half was using case-based reasoning to learn
machine translation from human training.

Anyhow, here's the relevant bit. In the tutorial I got one of the
students to fire up R so that we could use a normal pdf as the kernel
function for a worked example. I ended up that part of the tutorial
showing them the board data (just three points) plotted on a graph, and
then plotting the predicted (according to board calculations) y value
for the "unseen" x value as per the board. 

Then since the tutorial had ended, I thought I'd get a little bit fancy.
I created some sample data where the x values were uniform random
between 0 and 8, and the y value was x^2 plus some gaussian noise. I
then plotted the raw data, and a lowess() curve, explaining to the
students that the lowess() curve was a more sophisticated method than
we'd covered in class (I had mentioned locally weighted regression
during the lecture). Finally I plotted the true y=x^2 line so that we
could compare the lowess() curve to the true curve. The students were
all very impressed at the close fit.

So, I then decided to show what happens when the noise gets really
large. So, I recreated my x^2 + noise sample with large amounts of
noise. Plot the lowess() curve and ... it's still pretty well bang on.
So, increase the noise even further, plot the lowess() curve and the
true curve and ... still very accurate. OK, quick explanation that the
random Gaussian noise is more or less evenly distributed either side of
the true line. So, I create some Gaussian noise with mean of 0, squared
it, subtracted the first constant I thought of, and added it to the x^2
values to create the fake "observed" y values. Plot the data, and you
can see the lower part of the curve clearly, but really random looking
noise above it. Plot the lowess() curve, plot the true curve and ...
pretty well bang on.

At this point I'd run out of time, and hence couldn't think of even
tougher tests. The students were all fairly impressed on this. I saw
several of them copying R (whole windows directory) off the hard drive
to take home. Others asked if I could write them some notes on lowess()
etc.

Once again I learn not to do things on the fly in lectures :-)

Cheers,

Ross-c



From reid_huntsinger at merck.com  Tue Mar  1 18:33:53 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Tue, 1 Mar 2005 12:33:53 -0500
Subject: [R] memory problem with mac os X
Message-ID: <D9A95B4B7B20354992E165EEADA31999056A9306@uswpmx00.merck.com>

Yes, this came up last week as well. "dist" uses .C() to call code to
compute the upper triangle, which is passed an "empty" R vector of size
N(N-1)/2 to fill in. It returns a list containing the arguments passed in
and assigns the result to another vector. I can only guess that because
arguments are not copied in the .C call with DUP=FALSE, R is conservative
and assumes that a copy needs to be made in the assignment, so for a while
two copies exist. I haven't found this in the code, yet, so maybe there's
something quite different going on.

In any case, you can compute the distance matrix yourself more
space-efficiently, but if you really need large distance matrices you'll
need more RAM or perhaps 64 bit hardware. The following R code is less
memory-hungry than dist, but returns the whole matrix. It uses about 1.2 GB
on a 10,000 observation dataset, while dist runs into the 3 GB address space
limit on my machine. By default it computes squared Euclidean distance, but
the "func" argument can be passed another R function to get d[i,j] =
func(x[,i],x[,j]). (Note it works on columns rather than rows. )

function(x, func=function(y) colSums(y*y)) {
# computes d[i,j] = func(column i - column j) 
n <- dim(x)[2]
d <- vector(length=n*n)
dim(d) <- c(n,n)
for (j in 1:n) {
  d[,j] <- func(x - x[,j])
}
d
}

Reid Huntsinger

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Edouard Henrion
Sent: Monday, February 28, 2005 12:47 PM
To: r-help at stat.math.ethz.ch
Subject: [R] memory problem with mac os X


Dear list,

I am using R.2.0.1 on a G5 biprocessor 2.5GHz with 2Go RAM (Mac OS X 
10.3.8).

I'm trying to calculate an object of type "dist". I am getting the 
following memory error :

*** malloc: vm_allocate(size=1295929344) failed (error code=3)
*** malloc[25960]: error: Can't allocate region
Error: cannot allocate vector of size 1265554 Kb

When I do a top on the terminal, I can see that this size has already 
been allocated... It seems that R tries to allocate the memory twice.
Does anybody have an advice about this ?

Thanks,

Edouard Henrion

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From cobraram at comcast.net  Tue Mar  1 18:34:32 2005
From: cobraram at comcast.net (Aram Matevosov)
Date: Tue, 1 Mar 2005 09:34:32 -0800
Subject: [R] Atkinson's score
Message-ID: <200503011734.j21HYTuJ012288@hypatia.math.ethz.ch>

Hello Dear R Users,

I would like to compute the Atkinson's score for a linear model 
$Y = \beta_0 + \beta_1 X_1$. I could not find a decent literature to do
that. Is there a package in R that computes Atkinson's score? Thank you very
much.

New user, Aram. 

 
 
" Many people would sooner die than think; in fact, they do so."
- Bertrand Russell



From ripley at stats.ox.ac.uk  Tue Mar  1 18:40:20 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 1 Mar 2005 17:40:20 +0000 (GMT)
Subject: [R] write a library under 2.0.1 version
In-Reply-To: <4248.155.198.41.106.1109690597.squirrel@ensim-2.playnet.it>
References: <4248.155.198.41.106.1109690597.squirrel@ensim-2.playnet.it>
Message-ID: <Pine.LNX.4.61.0503011738370.17424@gannet.stats>

On Tue, 1 Mar 2005 marta at statistica.it wrote:

> Hi there,
> I had written a library under R 1.9.0 and now I would like to import that
> library under R 2.0.1
> Apparently it does not work; I can install the package, but when I try to
> read it the error is the following:
>
> Error in library(compvar) : 'compvar' is not a valid package -- installed
> < 2.0.0
>
> I have checked other libraries in R 2.0.1 and I noticed that there is a
> new folders (Meta) that were not present under R 1.9.1 as well as a file
> (MD5). Moreover, under R folders there are files with .rdx and .rdb
> extensions that were not present before.
>
> I was wondering how I can built these files for the library to be
> importable under 2.0.1 version.

You install the package with R CMD INSTALL, just as was documented for 
1.9.1.  See the `Writing R Extensions' and `R Installation and 
Administration' manuals.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From spencer.graves at pdf.com  Tue Mar  1 18:41:19 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 01 Mar 2005 09:41:19 -0800
Subject: [R] GARCH
In-Reply-To: <42247C31.9030007@lse.ac.uk>
References: <42247C31.9030007@lse.ac.uk>
Message-ID: <4224A93F.8000709@pdf.com>

      I just got 163 hits from "www.r-project.org" -> search -> "R site 
search" -> garch.  The first hit mentioned package "tseries".  The 
second also mentioned "fSeries", "fOptions". 

      hope this helps. 
      spencer graves

Tobias Muhlhofer wrote:

> Hi, everyone!
>
> Is there a function to do single-variable GARCH in R? If yes, what 
> library is it in?
>
> Thanks!
>     Toby



From spencer.graves at pdf.com  Tue Mar  1 18:50:49 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 01 Mar 2005 09:50:49 -0800
Subject: [R] repost my question of cda in case
In-Reply-To: <cdf8178305030107165a3e5a7b@mail.gmail.com>
References: <cdf81783050225103850689476@mail.gmail.com>
	<cdf8178305030107165a3e5a7b@mail.gmail.com>
Message-ID: <4224AB79.8070107@pdf.com>

      For linear discriminate analysis with only 2 classes, you get one 
new variable, that being a straight line between the means of the two 
groups. 

      With 3 classes, the 3 points determine a plane defined by 2 lines 
or "new functions" = linear combinations of the original variables.  
However, if the distinctions are not statistically significant, you will 
get less than 2. 

      hope this helps. 
      spencer graves

WeiWei Shi wrote:

>Dear R-helpers:
>
>I sent this question 3 days ago but I didn't get any reply. In case
>this question was somewhat not seen by people who happpened to know
>the answer, I repost it here. Sorry for bother but I am kind of
>needing some help. BTW, if the question itself was not well expressed,
>please let me know.
>
>The question is as followed:
>
>
>I am wondering if I can get some general help or source about
>canonical discriminant analysis in R.
>
>My idea is trying to linearly "combine" 300 variables supervisely
>(according to the class lables to the observations". I think it is
>kinda PCA to do some decreasing dimentionality work, but w/
>considering the class and I used SAS to do CDA proc before.
>
>But I read the introduction from sas on this proc and found the
>following statement:
>
>"The process of extracting canonical variables can be repeated until
>the number of canonical variables equals the number of original
>variables or the number of classes minus one, whichever is smaller.
>"
>does it mean I can only have two new variables if  I only have 2 classes?
>
>I am not a stat guy and sorry for the question if it should not be
>addressed here.
>
>Ed
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From tlumley at u.washington.edu  Tue Mar  1 18:58:42 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 1 Mar 2005 09:58:42 -0800 (PST)
Subject: [R] Using mutiply imputed data in NLME
In-Reply-To: <5abc11d805030107424bc19e5e@mail.gmail.com>
References: <88EAF3512A55DF46B06B1954AEF73F7407E57AE5@dc1ex2.air.org>
	<5abc11d805030107424bc19e5e@mail.gmail.com>
Message-ID: <Pine.A41.4.61b.0503010955130.47876@homer10.u.washington.edu>

On Tue, 1 Mar 2005, Shige Song wrote:

> For example
>
> Will NLME work with mitools written by Thomas Lumley?

Yes, but since the coefficients are not just returned by the coef() 
function you will need to use the full MIextract/MIcombine approach rather 
than the shortcut of just using MIcombine() on the list of models.

 	-thomas

>
> Shige
>
> On Mon, 28 Feb 2005 13:02:54 -0500, Doran, Harold <HDoran at air.org> wrote:
>> Well, I may be missing something but why don't you call each dataframe
>> from within a loop and save the results in a new data frame each time?
>>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Shige Song
>> Sent: Monday, February 28, 2005 12:18 PM
>> To: R-help at stat.math.ethz.ch
>> Subject: [R] Using mutiply imputed data in NLME
>>
>> Dear All,
>>
>> I am doing a growth modeling using NLME. I have three levels in my
>> data: observation, individual, household. About half of my total sample
>> have missing values in my household-level covariates. Under this
>> situation, the best way to go is probably to multiply impute the data
>> (for, say, 5 times), estimate the same model separately on each model
>> using LME function, and merge the results. My question is: given the
>> multiply imputed data sets have already been generated, is there a
>> simple way to automate the process of estimating the mixed model and
>> merging the results? HLM has similar features...
>>
>> Thanks!
>>
>> Best,
>> Shige
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From blindglobe at gmail.com  Tue Mar  1 19:12:59 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Tue, 1 Mar 2005 19:12:59 +0100
Subject: [R] write a **package** under 2.0.1 version
In-Reply-To: <16932.38932.907926.741701@stat.math.ethz.ch>
References: <4248.155.198.41.106.1109690597.squirrel@ensim-2.playnet.it>
	<16932.38932.907926.741701@stat.math.ethz.ch>
Message-ID: <1abe3fa9050301101225e38cfa@mail.gmail.com>

Yet again, yet again, Martin.  I told you...


On Tue, 1 Mar 2005 17:28:04 +0100, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
> >>>>> "marta" == marta  <marta at statistica.it>
> >>>>>     on Tue, 1 Mar 2005 16:23:17 +0100 (CET) writes:
> 
>     marta> Hi there,
>     marta> I had written a library under R 1.9.0 and now I would like to import that
>     marta> library under R 2.0.1
> 
> "package", "package", "package" -- a "library" is something
> really different!
> 
>     marta> Apparently it does not work; I can install the
>     marta> package, but when I try to read it the error is the
>     marta> following:
> 
>     marta> Error in library(compvar) : 'compvar' is not a valid package -- installed
>     marta> < 2.0.0
> 
> so you haven't really "installed" in the sense of "Rcmd INSTALL <pkgname>"
> [ You didn't tell us, but you probably are using Micro$oft Windows?
>   On other platforms its "R CMD INSTALL <pkgname>"   ]
> 
> and you (or whoever provided the ``pre-compiled'' package to you)
> must run "Rcmd INSTALL" on that package where 'Rcmd' is any R
> version 2.x.y (2.0.1, typically).
> 
> However, this won't work easily for you if you are on Windows,
> since you need to first install quite a few tools before you can
> build and install packages ```from source''
> --> read the 'rw-faq' i.e. "R for windows Frequently Asked
> Questions (and answers)" that is accessible from the [Help] menu
> on Windows.
> 
>     marta> I have checked other libraries in R 2.0.1 and I
> other >> packages <<
> 
>     marta> noticed that there is a new folders (Meta) that were
>     marta> not present under R 1.9.1 as well as a file
>     marta> (MD5). Moreover, under R folders there are files with
>     marta> .rdx and .rdb extensions that were not present
>     marta> before.
> 
> these are rather in connection with Lazyloading and other
> features that more packages are using, but you shouldn't have to
> know about.
> 
>     marta> I was wondering how I can built these files for the library to be
>     marta> importable under 2.0.1 version.
> 
>     marta> Any suggestion?
> 
> "Rcmd INSTALL" (but see above)
> 
> Regards,
> Martin Maechler, ETH Zurich
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
best,
-tony

"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).

A.J. Rossini
blindglobe at gmail.com



From mvida at mitre.org  Tue Mar  1 19:25:51 2005
From: mvida at mitre.org (Melanie Vida)
Date: Tue, 01 Mar 2005 13:25:51 -0500
Subject: [R] Temporal Analysis of variable x; How to select the outlier
	threshold in R?
Message-ID: <4224B3AF.4090601@mitre.org>


--- bogdan romocea <br44114 at yahoo.com> wrote:

 > I'm not sure I understand.
 > You have financial data and want to throw away some
 > outliers??
 > Why would you ever do this?

I would select an outlier threshold, to extract a subset of the data "x" 
that had significant difference in financial contributions in a range of 
two years. "x" represents a variable for the amount of dollar value 
change in allocations to an account over a 2 year period.

 >
 > First of all, I'd suggest you pay close attention to
 > what the data is
 > trying to say. Maybe your distribution is not normal
 > after all (see
 > tests for normality etc). Maybe you shouldn't force
 > your normality
 > assumption upon the data.
 >

A plot off qq.plot(x) or qqnorm(x) indicated that the data was not 
normally distributed. I also used shapiro.test() which gave a p-value << 
0.05.

In order to select the outlier threshold, I ended up using the following :
outlier_threshold <- qauntile(x, 3/4) + 1.5* IQR(x)


-Melanie

 >
 >
 > -----Original Message-----
 > From: Melanie Vida [mailto:mvida at mitre.org]
 > Sent: Friday, February 25, 2005 1:30 PM
 > To: r-help
 > Subject: [R] Temporal Analysis of variable x; How to
 > select the outlier
 > threshold in R?
 >
 >
 > For a financial data set with large variance, I'm
 > trying to find the
 > outlier threshold of one variable "x" over a two
 > year period. I
 > qqplot(x2001, x2002) and found a normal
 > distribution. The latter part
 > of
 > the normal distribution did not look linear though.
 > Is there a suitable
 >
 > method in R to find the outlier threshold of this
 > variable from 2001
 > and
 > 2002  in R?
 >
 > ______________________________________________
 > R-help at stat.math.ethz.ch mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide!
 > http://www.R-project.org/posting-guide.html
 >
 > ______________________________________________
 > R-help at stat.math.ethz.ch mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide!
 > http://www.R-project.org/posting-guide.html
 >



From M.Anyadike-Danes at erini.ac.uk  Tue Mar  1 19:38:01 2005
From: M.Anyadike-Danes at erini.ac.uk (Michael Anyadike-Danes)
Date: Tue, 1 Mar 2005 18:38:01 -0000
Subject: [R] almost lower triangular matrices
Message-ID: <C9328F0EEDC3BC439FDABD12060E910904CB09@erini1.ERINI.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050301/2d09c118/attachment.pl

From Benjamin.Osborne at uvm.edu  Tue Mar  1 19:43:23 2005
From: Benjamin.Osborne at uvm.edu (Benjamin M. Osborne)
Date: Tue,  1 Mar 2005 13:43:23 -0500
Subject: [R] na.strings in readLines or is.na?
Message-ID: <1109702603.4224b7cb1ed37@webmail.uvm.edu>

When reading a data set into R using readLines, na.strings="-99.99" is ignored. 
Is there an equivalent command for readLines?  Alternatively, either
immediately after reading into R or once the data set has been converted to a
data frame, what is the appropriate command (or appropriate use of is.na) to
convert my -99.99s to NAs?
Thanks,
Ben Osborne

-- 
Botany Department
University of Vermont
109 Carrigan Drive
Burlington, VT 05405

benjamin.osborne at uvm.edu
phone: 802-656-0297
fax: 802-656-0440



From deepayan at stat.wisc.edu  Tue Mar  1 19:49:14 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 1 Mar 2005 12:49:14 -0600
Subject: [R] lattice -- panel order display
In-Reply-To: <s2249b47.052@ffdata.setur.fo>
References: <s2249b47.052@ffdata.setur.fo>
Message-ID: <200503011249.14303.deepayan@stat.wisc.edu>

On Tuesday 01 March 2005 10:41, Luis Ridao Cruz wrote:
> I do the following:
>
> test$year <- factor (test$year , ordered = TRUE)
> xyplot ( number~cm | year, data = test , type = "l" )
>
> and still get the same.

What you haven't told us yet is what's wrong with what you get.

-Deepayan



From lisas at salford-systems.com  Tue Mar  1 20:01:19 2005
From: lisas at salford-systems.com (Lisa Solomon)
Date: Tue, 01 Mar 2005 11:01:19 -0800
Subject: [R] Schedule Published for Data Mining Conference: New York City,
 March 28-30, Two full-days of Case Study Presentations
Message-ID: <4224BBFF.8060803@salford-systems.com>

Apologies for cross posting
-----------------------------------------------------------------------------
                    Salford Systems Data Mining 2005
                      New York, March 28-30, 2005
Focusing on the Contributions of Data Mining to Solving Real World 
Challenges

               Two Full Days of Case Study Presentations

                           CONFERENCE SCHEDULE
              http://www.salforddatamining.com/program.htm
------------------------------------------------------------------------------

TRACKS:
Data Mining Issues and Implementation
Real World Success Stories: Business
Real World Success Stories: Biomedical
Real World Success Stories: Environmental
Novel Methodologies

POST-CONFERENCE HANDS-ON TRAINING
March 31 - April 1, 2005

Network with Data Mining Experts and Pick up Pointers from Companies, 
Research Centers and Laboratories Including:
The International Monetary Fund, American Express, Barnes and Noble, 
Visa, Pfizer, International Steel, Wells Fargo Bank, Ciphergen, Stanford 
Linear Accelerator, Johns Hopkins University Medical School, AT&T Labs - 
Research and the Columbia University School of Public Health.

If you have an interest in attending this conference or the 
post-conference training, please contact Lisa Solomon:
Phone: 619-543-8880 x14, Email:  lisas at salforddatamining.com
Conference Website: http://www.salforddatamining.com



From reid_huntsinger at merck.com  Tue Mar  1 20:32:18 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Tue, 1 Mar 2005 14:32:18 -0500
Subject: [R] Data in an object = Existing Objects??
Message-ID: <D9A95B4B7B20354992E165EEADA31999056A9309@uswpmx00.merck.com>

If you have the name of an object, you can use "get" to get the object
itself. 

You didn't ask, and I don't know what your intended use is, but this looks
like a difficult and inefficient way to keep track of things in R. You may
want to look over some of the R introductions (on www.r-project.org) to see
other ways to represent your data. For example, perhaps a two-way array C
such that e.g. your C_05_04 is the 5,4 entry. R is good at handling arrays
and more importantly, you won't have to deal with constructing strings and
breaking them apart again, using "get" and "assign" to get and assign to
objects with these names, etc. 

Reid Huntsinger

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
achilleas.psomas at wsl.ch
Sent: Tuesday, March 01, 2005 11:53 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Data in an object = Existing Objects??


Dear R-help...

I am rather new so I would appreciate your help..
My question if the following..

I have generated (with R) a data frame DF looking like this..

> print(DF)
       X1      X2
2   C_05_04 C_05_11
3   C_05_04 C_05_17
4   C_05_04 C_06_08
5   C_05_04 C_06_29
6   C_05_04 C_07_16


Where "C_05_04"....and all the rest data are objects-names already
calculated
and existing in my R workspace...
What i tried to do (and i doesnt work) is the following
e.g

x1 <- DF[1,1]
  C_05_04

(Where C_05_04 exists as an object in the workspace )
and then try to apply any kind of function using this x1
Is there a way to specify that x1 should be concidered as an object and not
just
as data ?


I hope i have explained clearly enough my question..

I would appreciate any help.

Achilleas.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From kwelling at paladindata.com  Tue Mar  1 20:42:14 2005
From: kwelling at paladindata.com (Kyle Welling)
Date: Tue, 1 Mar 2005 11:42:14 -0800
Subject: [R] R with C#
Message-ID: <658807DA77E67541971AA8897942F214D85075@postoffice.paladin_nw.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050301/6d75af4e/attachment.pl

From lroot at umiami.ir.miami.edu  Tue Mar  1 20:53:30 2005
From: lroot at umiami.ir.miami.edu (Lindsey Root)
Date: Tue, 01 Mar 2005 14:53:30 -0500
Subject: [R] start values for random effects in nlme
Message-ID: <001801c51e98$5aa08a20$b204ec0a@psy.miami.edu>

I am attempting to run an exponential decay model in nlme with 3 fixed
and random effects (an initial value, an asymptote, and a decay rate). I
am having trouble getting convergence now that I have added the
asymptote to the model, so I was attempting to specify start values for
the random effects.  I have 161 groups (SUBJECT) and have constructed a
161 x 3 matrix (E) for the random effects start values.  However, I
receive the following error message:

> fm3 <- nlme(model = RASCH16A ~  B + A*(exp(-K*DAYS)),
+ fixed = B + A + K ~ 1,
+ data = rasch,
+ random = B + A + K ~ 1 | SUBJECT, groups = ~SUBJECT, 
+ start = list(fixed = c(20, 68, 0.03), random= E))
Error in nlme.formula(model = RASCH16A ~ B + A * (exp(-K * DAYS)), fixed
= B +  : 
 	groups levels mismatch in random and starting values for random
at level SUBJECT

Does anyone have any ideas as to what might be triggering this error
message?

Thanks if you can help~
Lindsey Root



From sdavis2 at mail.nih.gov  Tue Mar  1 20:54:54 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 1 Mar 2005 14:54:54 -0500
Subject: [R] tkRplot under macos x
In-Reply-To: <Pine.LNX.4.61.0502281124160.10902@nokomis.stat.uiowa.edu>
References: <00c601c51d9f$fdf318e0$1f6df345@WATSON>
	<Pine.LNX.4.61.0502281124160.10902@nokomis.stat.uiowa.edu>
Message-ID: <ea640e53b8b4afa68b4fe90c5e86a897@mail.nih.gov>

Luke,

Thanks for the pointer to the postings.  I still don't have it working. 
  Here is what I have done:

 >% R CMD INSTALL -l ~/Library/R/library/ tkrplot
* Installing *source* package 'tkrplot' ...
configure: creating ./config.status
config.status: creating src/Makevars
** libs
gcc -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/include 
-I/usr/local/include -I/usr/local/include -I/usr/X11R6/include 
-I/usr/local/include   -fno-common  -g -O2 -c tcltkimg.c -o tcltkimg.o
gcc -bundle -flat_namespace -undefined suppress -L/usr/local/lib -o 
tkrplot.so tcltkimg.o -L/usr/local/lib -ltcl8.4 -L/usr/local/lib 
-ltk8.4 -L/usr/X11R6/lib -lX11 -framework CoreFoundation -lcc_dynamic 
-framework R

 >% cd tkrplot/src
 >% gcc --dynamic -flat_namespace -undefined suppress -L/usr/local/lib 
-o libtkrplot.dylib tcltkimg.o -L/usr/local/lib -ltcl8.4 
-L/usr/local/lib -ltk8.4 -L/usr/X11R6/lib -lX11 -framework 
CoreFoundation -lcc_dynamic -framework R

 >% cp libtkrplot.dylib ~/Library/R/library/tkrplot/libs/

Then in tkrplot under the R directory in the installation, I changed 
the file extension line to:

         file.ext <- '.dylib'

Then I started R from an xterm (which is where I typically use it) and 
got:

 > library(tcltk)  #no problems here....
 > library(tkrplot)
Loading required package: tcltk
Error in structure(.External("dotTcl", ..., PACKAGE = "tcltk"), class = 
"tclObj") :
         [tcl] dyld: 
/Library/Frameworks/R.framework/Resources/bin/exec/R can't open 
library: Rplot  (No such file or directory, errno = 2)
.
Error in library(tkrplot) : .First.lib failed for 'tkrplot'

I'm missing something here, obviously.  Any other hints....

Thanks,
Sean


On Feb 28, 2005, at 12:24 PM, Luke Tierney wrote:

> It only works under X11; if that is what you want this posting should
> tell you what needs to be done:
>
>         
> https://stat.ethz.ch/pipermail/r-sig-mac/2004-December/001465.html
>
> Best,
>
> luke
>
> On Mon, 28 Feb 2005, Sean Davis wrote:
>
>> I have not successfully gotten tkRplot to install on macos 10.3.8, R 
>> 2.0.0.  Other tcltk packages work just fine.  Any suggestions?  I can 
>> post all the output from the compile,etc., but thought I would check 
>> the "short" version first.
>>
>> Thanks,
>> Sean
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
>
> -- 
> Luke Tierney
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>    Actuarial Science
> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



From ggrothendieck at myway.com  Tue Mar  1 21:07:46 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 1 Mar 2005 20:07:46 +0000 (UTC)
Subject: [R] Data in an object = Existing Objects??
References: <1107965723.420a371b2bf55@webmail.wsl.ch>
	<1109696009.42249e091fbef@webmail.wsl.ch>
Message-ID: <loom.20050301T210040-818@post.gmane.org>

 <achilleas.psomas <at> wsl.ch> writes:

: 
: Dear R-help...
: 
: I am rather new so I would appreciate your help..
: My question if the following..
: 
: I have generated (with R) a data frame DF looking like this..
: 
: > print(DF)
:        X1      X2
: 2   C_05_04 C_05_11
: 3   C_05_04 C_05_17
: 4   C_05_04 C_06_08
: 5   C_05_04 C_06_29
: 6   C_05_04 C_07_16
: 
: Where "C_05_04"....and all the rest data are objects-names already calculated
: and existing in my R workspace...
: What i tried to do (and i doesnt work) is the following
: e.g
: 
: x1 <- DF[1,1]
:   C_05_04
: 
: (Where C_05_04 exists as an object in the workspace )
: and then try to apply any kind of function using this x1
: Is there a way to specify that x1 should be concidered as an object and not 
just
: as data ?
: 
: I hope i have explained clearly enough my question..

I think your setup is clear enough but perhaps you could
give some more background on your application since there 
might be a better data structure in the first place.



From rolf at math.unb.ca  Tue Mar  1 21:24:50 2005
From: rolf at math.unb.ca (Rolf Turner)
Date: Tue, 1 Mar 2005 16:24:50 -0400 (AST)
Subject: [R] almost lower triangular matrices
Message-ID: <200503012024.j21KOoOm010721@erdos.math.unb.ca>


 > x <- 1:6 # In real life x <- scan(<filename>).
 > m <- matrix(0,4,4)
 > m[row(m)<col(m)] <- x
 > m <- t(m)
 > m
     [,1] [,2] [,3] [,4]
[1,]    0    0    0    0
[2,]    1    0    0    0
[3,]    2    3    0    0
[4,]    4    5    6    0


The fiddle with the transposing is needed because R puts
data into matrices column-by-column, not row-by-row.

				cheers,

					Rolf Turner
					rolf at math.unb.ca
Michael Anyadike-Danes wrote:

> I have output from a program which produces a distance matrix I want
> to read into a clustering program in R.
> 
> The output is a .txt file and is 'almost' lower triangular in the
> sense that it is just the triangle below the diagonal.
> 
> So for example a 4-by-4 distance matrix appears as,
> 
> 1
> 
> 2 3
> 
> 4 5 6
> 
> i.e. it looks like a lower triangular of a 3-by3.
> 
> I thought I might be able to use "diag" to add zeros but apparently not.
> 
> It's a problem because my matrix is actually 1989-by-1989 not 4-by-4
> 
> I would not be at all surprised if the solution is obvious but I cannot
> quite see how to read this into R.



From bates at stat.wisc.edu  Tue Mar  1 21:24:45 2005
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 01 Mar 2005 14:24:45 -0600
Subject: [R] almost lower triangular matrices
In-Reply-To: <C9328F0EEDC3BC439FDABD12060E910904CB09@erini1.ERINI.local>
References: <C9328F0EEDC3BC439FDABD12060E910904CB09@erini1.ERINI.local>
Message-ID: <4224CF8D.7030609@stat.wisc.edu>

Michael Anyadike-Danes wrote:
> I have output from a program which produces a distance matrix I want to
> read into a clustering program in R.
> 
>  
> 
> The output is a .txt file and is 'almost' lower triangular in the sense
> that it is just the triangle below the diagonal.
> 
>  
> 
> So for example a 4-by-4 distance matrix appears as,
> 
>  
> 
> 1
> 
> 2 3
> 
> 4 5 6
> 
>  
> 
> i.e. it looks like a lower triangular of a 3-by3.
> 
>  
> 
> I thought I might be able to use "diag" to add zeros but apparently not.
> 
>  
> 
> It's a problem because my matrix is actually 1989-by-1989 not 4-by-4
> 
>  
> 
> I would not be at all surprised if the solution is obvious but I cannot
> quite see how to read this into R.

You can use scan to get the entries from the file in row order.  Then 
create the matrix to hold the result and overwrite the elements in the 
upper triangle with scanned vector.  (R stores matrices in column-major 
order so the row-major order from your file corresponds to the upper 
triangle, not the lower triangle).  I'll leave it to you to work out the 
  symmetrization operation.

 > file.show("/tmp/tri.dat")
1
2 3
4 5 6
7 8 9 10

 > mm <- array(0, c(4,4))
 > mm[upper.tri(mm, diag = TRUE)] <- scan("/tmp/tri.dat")
Read 10 items
 > mm
      [,1] [,2] [,3] [,4]
[1,]    1    2    4    7
[2,]    0    3    5    8
[3,]    0    0    6    9
[4,]    0    0    0   10
 > (res <- mm + t(mm))
      [,1] [,2] [,3] [,4]
[1,]    2    2    4    7
[2,]    2    6    5    8
[3,]    4    5   12    9
[4,]    7    8    9   20
 > diag(res) <- diag(res)/2
 > res
      [,1] [,2] [,3] [,4]
[1,]    1    2    4    7
[2,]    2    3    5    8
[3,]    4    5    6    9
[4,]    7    8    9   10



From pauljohn at ku.edu  Tue Mar  1 21:30:02 2005
From: pauljohn at ku.edu (Paul Johnson)
Date: Tue, 01 Mar 2005 14:30:02 -0600
Subject: [R] Users in Ukraine & cyrillic support
Message-ID: <4224D0CA.2060001@ku.edu>

Hello, everybody:

My friends in Ukraine are starting a research lab at a national
university and they asked what programs to use.  I said "R" of course,
and they then asked me 'what support does it have for Cyrillic'?

i've done some snooping in the R website and all the references i find
to foreign languages concern c and fortran, not Ukrainian or Russian.
Since i'm an English-only user, I have no idea what is involved here, or
what difficulties might be caused with non-English character sets and
file systems.

Not to mention the problem that the documentation/manuals are in English.

If you have any advice that I can collect up for my friends, I would
appreciate it.

-- 
Paul E. Johnson                       email: pauljohn at ku.edu
Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
1541 Lilac Lane, Rm 504
University of Kansas                  Office: (785) 864-9086
Lawrence, Kansas 66044-3177           FAX: (785) 864-5700



From laura at env.leeds.ac.uk  Tue Mar  1 21:30:20 2005
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Tue, 1 Mar 2005 20:30:20 +0000 (GMT)
Subject: [R] Reconstructing Datasets
Message-ID: <Pine.LNX.4.44.0503012029010.4905-100000@gw.env.leeds.ac.uk>

Hi,

Is it possible to recreate "smoothed" data sets in R, by performing a PCA
and then reconstructing a data set from say the first 2/3 EOFs?

I've had a look in the help pages and don't seem to find anything
relevant.

Thanks in advance,
Laura

Laura Quinn
Institute of Atmospheric Science
School of Earth and Environment
University of Leeds
Leeds
LS2 9JT

tel: +44 113 343 1596
fax: +44 113 343 6716
mail: laura at env.leeds.ac.uk



From glarowe at indiana.edu  Tue Mar  1 22:19:46 2005
From: glarowe at indiana.edu (Gavin La Rowe)
Date: Tue, 1 Mar 2005 16:19:46 -0500
Subject: [R] AIX 5.1
Message-ID: <18e1523055802751b58a8fd4b4a8046e@indiana.edu>

Hello,

I was wondering if someone who has successfully built R (either 
2.0.2005 or 1.91) on Platform 3/4 and compiled for AIX 5.1 could send 
on their compilation flags, tricks/tips ...

Thanks,

Gavin



From ripley at stats.ox.ac.uk  Tue Mar  1 22:18:37 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 1 Mar 2005 21:18:37 +0000 (GMT)
Subject: [R] Users in Ukraine & cyrillic support
In-Reply-To: <4224D0CA.2060001@ku.edu>
References: <4224D0CA.2060001@ku.edu>
Message-ID: <Pine.LNX.4.61.0503012117360.19556@gannet.stats>

As from the next release it has support of almost all human languages.
Previews of that are available now.


On Tue, 1 Mar 2005, Paul Johnson wrote:

> Hello, everybody:
>
> My friends in Ukraine are starting a research lab at a national
> university and they asked what programs to use.  I said "R" of course,
> and they then asked me 'what support does it have for Cyrillic'?
>
> i've done some snooping in the R website and all the references i find
> to foreign languages concern c and fortran, not Ukrainian or Russian.
> Since i'm an English-only user, I have no idea what is involved here, or
> what difficulties might be caused with non-English character sets and
> file systems.
>
> Not to mention the problem that the documentation/manuals are in English.
>
> If you have any advice that I can collect up for my friends, I would
> appreciate it.
>
> -- 
> Paul E. Johnson                       email: pauljohn at ku.edu
> Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
> 1541 Lilac Lane, Rm 504
> University of Kansas                  Office: (785) 864-9086
> Lawrence, Kansas 66044-3177           FAX: (785) 864-5700
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tlumley at u.washington.edu  Tue Mar  1 22:26:56 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 1 Mar 2005 13:26:56 -0800 (PST)
Subject: [R] Users in Ukraine & cyrillic support
In-Reply-To: <4224D0CA.2060001@ku.edu>
References: <4224D0CA.2060001@ku.edu>
Message-ID: <Pine.A41.4.61b.0503011313180.47876@homer10.u.washington.edu>

On Tue, 1 Mar 2005, Paul Johnson wrote:

> Hello, everybody:
>
> My friends in Ukraine are starting a research lab at a national
> university and they asked what programs to use.  I said "R" of course,
> and they then asked me 'what support does it have for Cyrillic'?


The development version (to become 2.1.0) supports a wide variety of 
character encodings and has facilities for translation of error/warning 
messages (though someone still has to do the translation).

See
   http://developer.r-project.org/descriptions.Encodings_and_R.html
and
   http://developer.r-project.org/Translations.html
for some descriptions


>
> Not to mention the problem that the documentation/manuals are in English.
>

This, of course, is a much bigger job and a more rapidly moving target.


 	-thomas



From Wittner.Ben at mgh.harvard.edu  Tue Mar  1 22:48:47 2005
From: Wittner.Ben at mgh.harvard.edu (Wittner, Ben)
Date: Tue, 1 Mar 2005 16:48:47 -0500
Subject: [R] looking for 3D plotting with real-time rotation
Message-ID: <B1D5C2D0D1D6AE4C9DF88E81330D71C60D9D24@PHSXMB23.partners.org>

I would like to plot points in 3D and then be able to rotate the plot in real
time in order to understand the distribution of the points using the visual
parallax that results from the rotation.

The R-package scatterplot3d will plot in 3D, but I've not found a way to rotate
the results in real time. (It also does not seem to get the projection from 3D
to a viewing plane right.)

The R-package rgl seems to support real-time 3D rendering using OpenGL, but it
appears to be lower-level than I'm looking for (i.e., it provide graphics
primitives, but not a plotting function that would take care of axis labels,
etc.)

Any help would be appreciated.

Thanks.

-Ben



From ripley at stats.ox.ac.uk  Tue Mar  1 22:52:25 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 1 Mar 2005 21:52:25 +0000 (GMT)
Subject: [R] AIX 5.1
In-Reply-To: <18e1523055802751b58a8fd4b4a8046e@indiana.edu>
References: <18e1523055802751b58a8fd4b4a8046e@indiana.edu>
Message-ID: <Pine.LNX.4.61.0503012149490.22500@gannet.stats>

On Tue, 1 Mar 2005, Gavin La Rowe wrote:

> I was wondering if someone who has successfully built R (either 2.0.2005 or 
> 1.91) on Platform 3/4 and compiled for AIX 5.1 could send on their 
> compilation flags, tricks/tips ...

People have built on AIX 5.1, and their flags and tips are in the R-admin 
manual that the INSTALL file points you to.  There was a report in the 
last 24 hours of success on AIX 5.2 using those tips, so check the 
archives.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jfox at mcmaster.ca  Tue Mar  1 23:05:09 2005
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 01 Mar 2005 17:05:09 -0500
Subject: [R] looking for 3D plotting with real-time rotation
In-Reply-To: <B1D5C2D0D1D6AE4C9DF88E81330D71C60D9D24@PHSXMB23.partners.org>
Message-ID: <web-84314841@cgpsrv2.cis.mcmaster.ca>

Dear Ben,

The scatter3d() function in the Rcmdr package uses rgl to plot
rotatable point clouds and regression surfaces. The function is usable
with or without the Rcmdr GUI. You'll find an illustrative plot at
<http://socserv.socsci.mcmaster.ca/jfox/Courses/S-course/index.html>.

I hope this helps,
 John

On Tue, 1 Mar 2005 16:48:47 -0500
 "Wittner, Ben" <Wittner.Ben at mgh.harvard.edu> wrote:
> I would like to plot points in 3D and then be able to rotate the plot
> in real
> time in order to understand the distribution of the points using the
> visual
> parallax that results from the rotation.
> 
> The R-package scatterplot3d will plot in 3D, but I've not found a way
> to rotate
> the results in real time. (It also does not seem to get the
> projection from 3D
> to a viewing plane right.)
> 
> The R-package rgl seems to support real-time 3D rendering using
> OpenGL, but it
> appears to be lower-level than I'm looking for (i.e., it provide
> graphics
> primitives, but not a plotting function that would take care of axis
> labels,
> etc.)
> 
> Any help would be appreciated.
> 
> Thanks.
> 
> -Ben
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/



From jfox at mcmaster.ca  Tue Mar  1 23:14:15 2005
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 01 Mar 2005 17:14:15 -0500
Subject: [R] na.strings in readLines or is.na?
In-Reply-To: <1109702603.4224b7cb1ed37@webmail.uvm.edu>
Message-ID: <web-84316007@cgpsrv2.cis.mcmaster.ca>

Dear Ben,

Since readLines() returns the lines in the file as character strings,
it wouldn't be appropriate for it to substitute for missing values on
input. One approach would be to replace "-99.99" with "NA" in the
strings, but a simpler method would be to deal with the data frame (say
DF): 
  DF[DF == -99.99] <- NA
(assuming that you've converted the strings to numeric values).

I hope this helps,
 John


On Tue,  1 Mar 2005 13:43:23 -0500
 "Benjamin M. Osborne" <Benjamin.Osborne at uvm.edu> wrote:
> When reading a data set into R using readLines, na.strings="-99.99"
> is ignored. 
> Is there an equivalent command for readLines?  Alternatively, either
> immediately after reading into R or once the data set has been
> converted to a
> data frame, what is the appropriate command (or appropriate use of
> is.na) to
> convert my -99.99s to NAs?
> Thanks,
> Ben Osborne
> 
> -- 
> Botany Department
> University of Vermont
> 109 Carrigan Drive
> Burlington, VT 05405
> 
> benjamin.osborne at uvm.edu
> phone: 802-656-0297
> fax: 802-656-0440
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/



From spencer.graves at pdf.com  Tue Mar  1 23:20:50 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 01 Mar 2005 14:20:50 -0800
Subject: [R] almost lower triangular matrices
In-Reply-To: <4224CF8D.7030609@stat.wisc.edu>
References: <C9328F0EEDC3BC439FDABD12060E910904CB09@erini1.ERINI.local>
	<4224CF8D.7030609@stat.wisc.edu>
Message-ID: <4224EAC2.20204@pdf.com>

      Output from which program?  If the output is of class "dist", then 
"as.matrix" should give you what you want: 

 > set.seed(1)
 > X <- array(rnorm(12), dim=c(4,3))
 > (dX <- dist(X))
          1         2         3
2 1.6598683                   
3 0.9720025 2.4600033         
4 2.2666735 2.2149274 2.6890545
 > length(dX)
[1] 6
 > as.matrix(dX)
          1        2         3        4
1 0.0000000 1.659868 0.9720025 2.266674
2 1.6598683 0.000000 2.4600033 2.214927
3 0.9720025 2.460003 0.0000000 2.689054
4 2.2666735 2.214927 2.6890545 0.000000
 >
      hope this helps. 
      spencer graves

Douglas Bates wrote:

> Michael Anyadike-Danes wrote:
>
>> I have output from a program which produces a distance matrix I want to
>> read into a clustering program in R.
>>
>>  
>>
>> The output is a .txt file and is 'almost' lower triangular in the sense
>> that it is just the triangle below the diagonal.
>>
>>  
>>
>> So for example a 4-by-4 distance matrix appears as,
>>
>>  
>>
>> 1
>>
>> 2 3
>>
>> 4 5 6
>>
>>  
>>
>> i.e. it looks like a lower triangular of a 3-by3.
>>
>>  
>>
>> I thought I might be able to use "diag" to add zeros but apparently not.
>>
>>  
>>
>> It's a problem because my matrix is actually 1989-by-1989 not 4-by-4
>>
>>  
>>
>> I would not be at all surprised if the solution is obvious but I cannot
>> quite see how to read this into R.
>
>
> You can use scan to get the entries from the file in row order.  Then 
> create the matrix to hold the result and overwrite the elements in the 
> upper triangle with scanned vector.  (R stores matrices in 
> column-major order so the row-major order from your file corresponds 
> to the upper triangle, not the lower triangle).  I'll leave it to you 
> to work out the  symmetrization operation.
>
> > file.show("/tmp/tri.dat")
> 1
> 2 3
> 4 5 6
> 7 8 9 10
>
> > mm <- array(0, c(4,4))
> > mm[upper.tri(mm, diag = TRUE)] <- scan("/tmp/tri.dat")
> Read 10 items
> > mm
>      [,1] [,2] [,3] [,4]
> [1,]    1    2    4    7
> [2,]    0    3    5    8
> [3,]    0    0    6    9
> [4,]    0    0    0   10
> > (res <- mm + t(mm))
>      [,1] [,2] [,3] [,4]
> [1,]    2    2    4    7
> [2,]    2    6    5    8
> [3,]    4    5   12    9
> [4,]    7    8    9   20
> > diag(res) <- diag(res)/2
> > res
>      [,1] [,2] [,3] [,4]
> [1,]    1    2    4    7
> [2,]    2    3    5    8
> [3,]    4    5    6    9
> [4,]    7    8    9   10
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Tue Mar  1 23:19:09 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 01 Mar 2005 23:19:09 +0100
Subject: [R] Users in Ukraine & cyrillic support
In-Reply-To: <4224D0CA.2060001@ku.edu>
References: <4224D0CA.2060001@ku.edu>
Message-ID: <x2sm3f9fhe.fsf@biostat.ku.dk>

Paul Johnson <pauljohn at ku.edu> writes:

> Hello, everybody:
> 
> My friends in Ukraine are starting a research lab at a national
> university and they asked what programs to use.  I said "R" of course,
> and they then asked me 'what support does it have for Cyrillic'?
> 
> i've done some snooping in the R website and all the references i find
> to foreign languages concern c and fortran, not Ukrainian or Russian.
> Since i'm an English-only user, I have no idea what is involved here, or
> what difficulties might be caused with non-English character sets and
> file systems.
> 
> Not to mention the problem that the documentation/manuals are in English.
> 
> If you have any advice that I can collect up for my friends, I would
> appreciate it.


Well, you're probably not going to find someone to translate the
manual into Ukrainian outside Ukraine...

The good news is that, due to our indefatigueable mr. Ripley, R-2.1.0
will have support for UTF-8, including Cyrillic. It will also have
some support for message catalogs and the potential to change the GUI
language. Check out the NEWS file in R-devel
(https://svn.r-project.org/R/trunk/NEWS).


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From chris at subtlety.com  Tue Mar  1 23:45:36 2005
From: chris at subtlety.com (Chris Bergstresser)
Date: Tue, 01 Mar 2005 16:45:36 -0600
Subject: [R] How to convert a factor to a numeric?
In-Reply-To: <loom.20050216T074328-689@post.gmane.org>
References: <8975119BCD0AC5419D61A9CF1A923E950121BA4A@iahce2knas1.iah.bbsrc.reserved>
	<loom.20050216T074328-689@post.gmane.org>
Message-ID: <4224F090.3000301@subtlety.com>

Hi all --

    I've got two columns, both of which correspond to three factor 
levels (e.g., column1 is "a", "b", or "c"; column2 is "x", "y", or "z"). 
  I'd like to generate a third column, consisting on whether the two 
factors are correctly aligned for a given case (in this example, "a" 
corresponds to "x", "b" to "y", and "c" to "z").  For example:

    a   x   TRUE
    a   y   FALSE
    b   y   TRUE
    c   z   TRUE
    b   x   FALSE

    Several questions:

    The easiest way seemed to me to be comparing the numeric values 
across columns, but the encodings are (a=1, b=2, c=3) and (x=1, y=3, 
z=2).  Is there a way to change the underlying value representing each 
factor, so I could just run an equality on them?
    Is there a simple way to check for correspondence without recoding 
the factors?
    In the help for factor(), it says "In particular, 'as.numeric' 
applied to a factor is meaningless, and may happen by implicit coercion. 
  To "revert" a factor 'f' to its original numeric values, 
'as.numeric(levels(f))[f]' is recommended and slightly more efficient 
than 'as.numeric(as.character(f))'."  However, I get the following 
results.  What's going on?

 > f = gl(3, 1, 6, labels=c("a", "b", "c"))
 > f
[1] a b c a b c
Levels: a b c
 > as.numeric(levels(f))[f]
[1] NA NA NA NA NA NA
Warning message:
NAs introduced by coercion
 > as.numeric(as.character(f))
[1] NA NA NA NA NA NA
Warning message:
NAs introduced by coercion
 > as.numeric(f)
[1] 1 2 3 1 2 3



From roebuck at odin.mdacc.tmc.edu  Tue Mar  1 23:47:43 2005
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Tue, 1 Mar 2005 16:47:43 -0600 (CST)
Subject: [R] write a library under 2.0.1 version
In-Reply-To: <Pine.LNX.4.61.0503011738370.17424@gannet.stats>
References: <4248.155.198.41.106.1109690597.squirrel@ensim-2.playnet.it>
	<Pine.LNX.4.61.0503011738370.17424@gannet.stats>
Message-ID: <Pine.OSF.4.58.0503011631420.412611@odin.mdacc.tmc.edu>

On Tue, 1 Mar 2005, Prof Brian Ripley wrote:

> On Tue, 1 Mar 2005 marta at statistica.it wrote:
>
> > I had written a library under R 1.9.0 and now I would like to import that
> > library under R 2.0.1
> > Apparently it does not work; I can install the package, but when I try to
> > read it the error is the following:
> >
> > Error in library(compvar) : 'compvar' is not a valid package -- installed
> > < 2.0.0
> >
> > [SNIP]
>
> You install the package with R CMD INSTALL, just as was documented for
> 1.9.1.  See the `Writing R Extensions' and `R Installation and
> Administration' manuals.

Out of curiousity, just how often has the package installation
compatibility between versions been an issue? Would it perhaps
be beneficial to version personal directories by major version?
I.e. instead of having just "~/R/library", would it be better
to have "~/R/1.x/library" and "~/R/2.x/library" and have the
.Rprofile select appropriately depending on version of R being
executed? If so, maybe this question would cease to be an issue.

I'd be interested to know how Prof. Ripley's R_LIBS variable
is defined, if he wouldn't mind sharing. Also curious if most
people keep BioConductor packages installed separately in a
third location.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From gunter.berton at gene.com  Wed Mar  2 00:49:18 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Tue, 1 Mar 2005 15:49:18 -0800
Subject: [R] How to convert a factor to a numeric?
In-Reply-To: <4224F090.3000301@subtlety.com>
Message-ID: <200503012349.j21NnI88018884@meitner.gene.com>

# If fact1 and fact2 are your factors, let prm be the permutation such that
# levels(fact2) corresponds to ("aligns to") levels(fact1)[prm] . In your
example, the permutation is
# apparently the identity, (1:3).

#Then

levels(fact2)[prm[fact1]]==fact2

## does what you want. I wouldn't be surprised if there are cleverer
solutions, though.


-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Chris 
> Bergstresser
> Sent: Tuesday, March 01, 2005 2:46 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] How to convert a factor to a numeric?
> 
> Hi all --
> 
>     I've got two columns, both of which correspond to three factor 
> levels (e.g., column1 is "a", "b", or "c"; column2 is "x", 
> "y", or "z"). 
>   I'd like to generate a third column, consisting on whether the two 
> factors are correctly aligned for a given case (in this example, "a" 
> corresponds to "x", "b" to "y", and "c" to "z").  For example:
> 
>     a   x   TRUE
>     a   y   FALSE
>     b   y   TRUE
>     c   z   TRUE
>     b   x   FALSE
> 
>     Several questions:
> 
>     The easiest way seemed to me to be comparing the numeric values 
> across columns, but the encodings are (a=1, b=2, c=3) and (x=1, y=3, 
> z=2).  Is there a way to change the underlying value 
> representing each 
> factor, so I could just run an equality on them?
>     Is there a simple way to check for correspondence without 
> recoding 
> the factors?
>     In the help for factor(), it says "In particular, 'as.numeric' 
> applied to a factor is meaningless, and may happen by 
> implicit coercion. 
>   To "revert" a factor 'f' to its original numeric values, 
> 'as.numeric(levels(f))[f]' is recommended and slightly more efficient 
> than 'as.numeric(as.character(f))'."  However, I get the following 
> results.  What's going on?
> 
>  > f = gl(3, 1, 6, labels=c("a", "b", "c"))
>  > f
> [1] a b c a b c
> Levels: a b c
>  > as.numeric(levels(f))[f]
> [1] NA NA NA NA NA NA
> Warning message:
> NAs introduced by coercion
>  > as.numeric(as.character(f))
> [1] NA NA NA NA NA NA
> Warning message:
> NAs introduced by coercion
>  > as.numeric(f)
> [1] 1 2 3 1 2 3
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ggrothendieck at myway.com  Wed Mar  2 01:17:02 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 2 Mar 2005 00:17:02 +0000 (UTC)
Subject: [R] How to convert a factor to a numeric?
References: <8975119BCD0AC5419D61A9CF1A923E950121BA4A@iahce2knas1.iah.bbsrc.reserved>
	<loom.20050216T074328-689@post.gmane.org>
	<4224F090.3000301@subtlety.com>
Message-ID: <loom.20050302T011341-72@post.gmane.org>

Chris Bergstresser <chris <at> subtlety.com> writes:

: 
: Date:   Tue, 01 Mar 2005 16:45:36 -0600 
: From:   Chris Bergstresser <chris at subtlety.com>
: To:   <r-help at stat.math.ethz.ch> 
: Subject:   [R] How to convert a factor to a numeric? 
: 
:  
: Hi all --
: 
: I've got two columns, both of which correspond to three factor 
: levels (e.g., column1 is "a", "b", or "c"; column2 is "x", "y", or "z"). 
: I'd like to generate a third column, consisting on whether the two 
: factors are correctly aligned for a given case (in this example, "a" 
: corresponds to "x", "b" to "y", and "c" to "z"). For example:
: 
: a x TRUE
: a y FALSE
: b y TRUE
: c z TRUE
: b x FALSE
: 
: Several questions:
: 
: The easiest way seemed to me to be comparing the numeric values 
: across columns, but the encodings are (a=1, b=2, c=3) and (x=1, y=3, 
: z=2). Is there a way to change the underlying value representing each 
: factor, so I could just run an equality on them?

If f1 and f2 are the two factors:

   as.numeric(f1) == as.numeric(factor(as.character(f2)))

: Is there a simple way to check for correspondence without recoding 
: the factors?

I am not sure I would recommend this but it could be done like this:

   as.numeric(f1) == ifelse(f2=="x", 1, 5-as.numeric(f2))

: In the help for factor(), it says "In particular, 'as.numeric' 
: applied to a factor is meaningless, and may happen by implicit coercion. 
: To "revert" a factor 'f' to its original numeric values, 
: 'as.numeric(levels(f))[f]' is recommended and slightly more efficient 
: than 'as.numeric(as.character(f))'." However, I get the following 
: results. What's going on?

I suspect they were thinking of the case where the levels themselves are 
of class numeric as in factor(c(10,10,11,11,12,12)) since it does not
seem to be correct otherwise.



From Simon.Blomberg at anu.edu.au  Wed Mar  2 01:24:59 2005
From: Simon.Blomberg at anu.edu.au (Simon Blomberg)
Date: Wed, 2 Mar 2005 11:24:59 +1100
Subject: [R] Anova with Scheffe Tests
In-Reply-To: <opsmx8lttzc0cqda@localhost>
References: <opsmx8lttzc0cqda@localhost>
Message-ID: <a06110400be4ab6b10d07@[150.203.51.113]>

Hi,

I don't think there are any packages on CRAN that implement Scheffe's 
test. If you don't mind using another multiple comparisons procedure, 
you could look at ?TukeyHSD and/or the multcomp package. 
Alternatively, you could write your own function to do Scheffe's 
test. At least one other person has done that. See the following post 
in the R-help archive 
http://finzi.psych.upenn.edu/R/Rhelp02a/archive/19393.html. I can't 
vouch for whether that person's function works properly, but it 
shouldn't be hard to hand-check it, and improve it. You could search 
R-help yourself and maybe come up with other solutions.

Cheers,

Simon.

>Hi R-people,
>
>I am wanting to run Factorial ANOVA followed by Scheffe tests on 
>some spatial subjective data. I'm comparing X-Y independent 
>coordinates against x-y dependent coordinates. There are only four 
>independent spatial coordinates that form a square.
>
>I am wondering whether I am doing the right thing, because there 
>doesn't seem to be a simple way of doing this. I have attempted to 
>read `Practical regression and ANOVA using R' and am still confused.
>
>In good ol' Statview (now dearly departed) to complete a Scheffe 
>test you selected the independent variables and dependent variable 
>and it produced a  table with the pairwise comparisons of the levels 
>of the factor. I'm looking for a system that is as basic, but can be 
>done using R and has documentation so I'm not guessing what I'm 
>doing. I'd rather not have to do plots in R and then run over to 
>dead software to do Scheffe's if possible.
>
>I checked on google and there seems to be code for a couple of 
>functions out there, but I need something that has a manual.
>
>Is there a Scheffe function out there that is reasonably well 
>documented, or should I consider some other method of dealing with 
>this data. We have been using Scheffe for this type of analysis as I 
>was under the impression it was very conservative. Tukey's HSD seems 
>to be conservative as well. Should I try this? Is there a different 
>approacch that is better and where can I read about it.
>
>Thanks for any help you can provide.
>
>Sam
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Simon Blomberg, B.Sc.(Hons.), Ph.D, M.App.Stat.
Visiting Fellow
School of Botany & Zoology
The Australian National University
Canberra ACT 0200
Australia

T: +61 2 6125 8057  email: Simon.Blomberg at anu.edu.au
F: +61 2 6125 5573

CRICOS Provider # 00120C



From David.Duffy at qimr.edu.au  Wed Mar  2 01:44:49 2005
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 2 Mar 2005 10:44:49 +1000 (EST)
Subject: [R] Re: R-help Digest, Vol 25, Issue 1
In-Reply-To: <200503011108.j21B3ckO017025@hypatia.math.ethz.ch>
References: <200503011108.j21B3ckO017025@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.61.0503021039030.1928@moonboom.qimr.edu.au>

sczhang at mail.ustc.edu.cn wrote:
> Subject: [R] Ask for your help
> I got following error information when I run the haplo.glm program.Could
> you tell me which wrong was happened in my program?Many thanks. Shanchun
> 
> fit.gaus <- haplo.glm(y ~ SEX+geno, family = gaussian,
> + data=my.data, locus.label=label, control =
> + haplo.glm.control(haplo.freq.min = 0.02))
> 
> Error in haplo.model.frame(m, locus.label = locus.label, allele.lev =
> allele.lev, :
> Missing allele.lev = list of vectors for labels of alleles
> Check par list for haplo.glm
> 
allele.lev needs to be correctly specified, usually as:
allele.lev=attributes(geno)$unique.alleles
As documented, this is R specific.

| David Duffy (MBBS PhD)   email: David.Duffy at qimr.edu.au              ,-_|\
| ph: INT+61+7+3362-0217 fax: -0101                                   /     *
| Genetic Epidemiology Lab, Queensland Institute of Medical Research  \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A       v



From Simon.Blomberg at anu.edu.au  Wed Mar  2 02:04:49 2005
From: Simon.Blomberg at anu.edu.au (Simon Blomberg)
Date: Wed, 2 Mar 2005 12:04:49 +1100
Subject: [R] Anova with Scheffe Tests
In-Reply-To: <200503020040.j220efmL012077@ohm.gene.com>
References: <200503020040.j220efmL012077@ohm.gene.com>
Message-ID: <a06110402be4ac14f8ba4@[150.203.51.113]>

I stand corrected, although confidence.ellipse is a plotting 
function, and may not be quite what the questioner had in mind.

Cheers,

Simon.

>See confidence.ellipse() in the car() package. (Found from an R site search
>on "Scheffe")
>
>-- Bert Gunter
>Genentech Non-Clinical Statistics
>South San Francisco, CA
>
>"The business of the statistician is to catalyze the scientific learning
>process."  - George E. P. Box
>
>
>
>>  -----Original Message-----
>>  From: r-help-bounces at stat.math.ethz.ch
>>  [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Simon Blomberg
>>  Sent: Tuesday, March 01, 2005 4:25 PM
>>  To: samferguson at ihug.com.au; R-help at stat.math.ethz.ch
>>  Subject: Re: [R] Anova with Scheffe Tests
>>
>>  Hi,
>>
>>  I don't think there are any packages on CRAN that implement Scheffe's
>>  test. If you don't mind using another multiple comparisons procedure,
>>  you could look at ?TukeyHSD and/or the multcomp package.
>>  Alternatively, you could write your own function to do Scheffe's
>>  test. At least one other person has done that. See the following post
>>  in the R-help archive
>>  http://finzi.psych.upenn.edu/R/Rhelp02a/archive/19393.html. I can't
>>  vouch for whether that person's function works properly, but it
>>  shouldn't be hard to hand-check it, and improve it. You could search
>>  R-help yourself and maybe come up with other solutions.
>>
>>  Cheers,
>>
>>  Simon.
>>
>>  >Hi R-people,
>>  >
>>  >I am wanting to run Factorial ANOVA followed by Scheffe tests on
>>  >some spatial subjective data. I'm comparing X-Y independent
>>  >coordinates against x-y dependent coordinates. There are only four
>>  >independent spatial coordinates that form a square.
>>  >
>>  >I am wondering whether I am doing the right thing, because there
>>  >doesn't seem to be a simple way of doing this. I have attempted to
>>  >read `Practical regression and ANOVA using R' and am still confused.
>>  >
>>  >In good ol' Statview (now dearly departed) to complete a Scheffe
>>  >test you selected the independent variables and dependent variable
>>  >and it produced a  table with the pairwise comparisons of the levels
>>  >of the factor. I'm looking for a system that is as basic, but can be
>>  >done using R and has documentation so I'm not guessing what I'm
>>  >doing. I'd rather not have to do plots in R and then run over to
>>  >dead software to do Scheffe's if possible.
>>  >
>>  >I checked on google and there seems to be code for a couple of
>>  >functions out there, but I need something that has a manual.
>>  >
>>  >Is there a Scheffe function out there that is reasonably well
>>  >documented, or should I consider some other method of dealing with
>>  >this data. We have been using Scheffe for this type of analysis as I
>>  >was under the impression it was very conservative. Tukey's HSD seems
>>  >to be conservative as well. Should I try this? Is there a different
>>  >approacch that is better and where can I read about it.
>>  >
>>  >Thanks for any help you can provide.
>>  >
>>  >Sam
>>  >
>>  >______________________________________________
>>  >R-help at stat.math.ethz.ch mailing list
>>  >https://stat.ethz.ch/mailman/listinfo/r-help
>>  >PLEASE do read the posting guide!
>>  http://www.R-project.org/posting-guide.html
>>
>>
>>  --
>>  Simon Blomberg, B.Sc.(Hons.), Ph.D, M.App.Stat.
>>  Visiting Fellow
>>  School of Botany & Zoology
>>  The Australian National University
>>  Canberra ACT 0200
>>  Australia
>>
>>  T: +61 2 6125 8057  email: Simon.Blomberg at anu.edu.au
>>  F: +61 2 6125 5573
>>
>>  CRICOS Provider # 00120C
>>
>>  ______________________________________________
>>  R-help at stat.math.ethz.ch mailing list
>>  https://stat.ethz.ch/mailman/listinfo/r-help
>>  PLEASE do read the posting guide!
>>  http://www.R-project.org/posting-guide.html
>>


-- 
Simon Blomberg, B.Sc.(Hons.), Ph.D, M.App.Stat.
Visiting Fellow
School of Botany & Zoology
The Australian National University
Canberra ACT 0200
Australia

T: +61 2 6125 8057  email: Simon.Blomberg at anu.edu.au
F: +61 2 6125 5573

CRICOS Provider # 00120C



From fengchen at hkusua.hku.hk  Wed Mar  2 03:03:21 2005
From: fengchen at hkusua.hku.hk (Feng Chen)
Date: Wed, 2 Mar 2005 10:03:21 +0800
Subject: [R] A problem about outer()
References: <002c01c51da6$abd33750$77d40893@S119>
	<1109607919.7070.49.camel@ndmpc126.orc.ox.ac.uk>
Message-ID: <003d01c51ecc$0579b0b0$77d40893@S119>

Thanks for the informative comments and the detailed explanation.

----- Original Message ----- 
From: "Adaikalavan Ramasamy" <ramasamy at cancer.org.uk>
To: "Feng Chen" <fengchen at hkusua.hku.hk>
Cc: "R-help" <r-help at stat.math.ethz.ch>
Sent: Tuesday, March 01, 2005 12:25 AM
Subject: Re: [R] A problem about outer()


> You might want to read (or re-read) the posting guide about giving a
> simple example. See comments below.

Henceafter, I won't post any question before:
1. searching the documentation,
2. googling the web,
3. reading the code of the relevant functions,
and
4. a careful rereading of the posting guide.

>
>
> On Mon, 2005-02-28 at 23:03 +0800, Feng Chen wrote:
>> Dear all,
>>
>> I have something about function outer() that I can't understand. Just 
>> see the following example. The two NaNs are due to 0/0, but I can't 
>> figure out the cause of the last two errors. I wonder if some one can 
>> explain this for me.
>> ___________________________________________________________________
>> > sx=rbinom(10,1,0.5);ot=rbinom(10,1,0.5);ag <- rbinom(10,100,0.3);ho 
>> > <- rbinom(10,100,0.5)
>
>
> Cute but unfortunately not very legible. Why are you mixing "=" and
> "<-" ? Is there a problem with space bars and return key on your

I am not sure about the reason for that mixture. Perhaps because "=" and 
"_" are so close on the keyboard. Anyway, they were definitely not made 
so by intention.

> keyboard ? Please learn to wrap the emails at about 72 characters per
> line (see http://expita.com/nomime.html).

Thanks, I have followed the instructions listed on that page.
>
>
>> > dp <- 
>> > function(s,a,h)sum((sx==s)&(ag==a)&(ho==h)&(ot==1))/sum((sx==s)&(ag==a)&(ho==h))
>
>> > (function(x,y)dp(1,x,y))(2,3)
>> [1] NaN
>> > (function(x,y)dp(0,x,y))(27,52)
>> [1] NaN
>
> Again this is confusing. Why not define another function (you will 
> need

Here just for testing pupose. I thought I just need that once (in the 
outer() function).

> to anyway - see below).
>
> Alternatively, you can set 1 as the default value for s in dp().
>
>> > dpm <- outer(ag,ho,function(x,y)dp(1,x,y))
>> Error in outer(ag, ho, function(x, y) dp(1, x, y)) :
>>  dim<- : dims [product 100] do not match the length of object [1]
>
>>From help("outer") :
>
> 'FUN' must be a function (or the name of it) which expects at
> least two arguments and which operates elementwise on arrays.
>
>
> And following the suggestion of Prof. Daalgard in the thread
> http://tolstoy.newcastle.edu.au/R/help/00a/1445.html
>
> dp.vect <- function(s, x, y){
>  sapply( 1:length(x), function(i) dp( s=s, a=x[i], h=y[i]) )
> }
> outer(ag, ho, FUN=dp.vect, s=1 )
> # works but I leave the verification to you

It does work.

>
>
>
> Your problem could be generalised as the following example
>
> one <- rnorm(3); two <- rnorm(4)                 # data
> outer( one, two, function(x, y) x + y )          # works fine
> outer( one, two, function(x, y) sum(c(x, y)) )   # does not work

I had tried this before posting.

>
> sum.vect <- function(x, y){
>  sapply( 1:length(x), function(i) sum( c( x[i], y[i] ) ) )
> }
> outer( one, two, sum.vect )
>

You have thoroughly explained away my confusion. Thanks for your great 
patience.

Thank all for being so tolerant and friendly to newcomers.

>
>
>> > dpf <- outer(ag,ho,function(x,y)dp(0,x,y))
>> Error in outer(ag, ho, function(x, y) dp(0, x, y)) :
>>  dim<- : dims [product 100] do not match the length of object [1]
>> >
>> -------------------------------------------------------------------------------------------------------------------
>>
>> Thanks very much,
>> Feng
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>



From WeiQiang.Li at seagate.com  Wed Mar  2 04:43:36 2005
From: WeiQiang.Li at seagate.com (WeiQiang.Li@seagate.com)
Date: Wed, 2 Mar 2005 11:43:36 +0800
Subject: [R] How to force specific variables in all the models using regsubsets
Message-ID: <OFC821546C.6CAECB20-ON48256FB8.00133A1F-48256FB8.00148D52@seagate.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050302/eebf4c5d/attachment.pl

From renaud.lancelot at cirad.fr  Wed Mar  2 05:45:05 2005
From: renaud.lancelot at cirad.fr (Renaud Lancelot)
Date: Wed, 02 Mar 2005 07:45:05 +0300
Subject: [R] Reconstructing Datasets
In-Reply-To: <Pine.LNX.4.44.0503012029010.4905-100000@gw.env.leeds.ac.uk>
References: <Pine.LNX.4.44.0503012029010.4905-100000@gw.env.leeds.ac.uk>
Message-ID: <422544D1.9090502@cirad.fr>

Laura Quinn a ?crit :
> Hi,
> 
> Is it possible to recreate "smoothed" data sets in R, by performing a PCA
> and then reconstructing a data set from say the first 2/3 EOFs?
> 
> I've had a look in the help pages and don't seem to find anything
> relevant.

See function reconst in package ade4.

Best,

Renaud


-- 
Dr Renaud Lancelot, v?t?rinaire
C/0 Ambassade de France - SCAC
BP 834 Antananarivo 101 - Madagascar

e-mail: renaud.lancelot at cirad.fr
tel.:   +261 32 40 165 53 (cell)
         +261 20 22 665 36 ext. 225 (work)
         +261 20 22 494 37 (home)



From jarioksa at sun3.oulu.fi  Wed Mar  2 07:30:24 2005
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Wed, 02 Mar 2005 08:30:24 +0200
Subject: [R] Reconstructing Datasets
In-Reply-To: <Pine.LNX.4.44.0503012029010.4905-100000@gw.env.leeds.ac.uk>
References: <Pine.LNX.4.44.0503012029010.4905-100000@gw.env.leeds.ac.uk>
Message-ID: <1109745024.13281.9.camel@biol102145.oulu.fi>


On Tue, 2005-03-01 at 20:30 +0000, Laura Quinn wrote:
> Hi,
> 
> Is it possible to recreate "smoothed" data sets in R, by performing a PCA
> and then reconstructing a data set from say the first 2/3 EOFs?
> 
> I've had a look in the help pages and don't seem to find anything
> relevant.
> 
It's not in the R help, but in the books about PCA in help references. 

This can be done, not quite directly. Most of the hassle comes from the
centring, and I guess in your case, from scaling of the results. I guess
it is best to first scale the results like PCA would do, then make the
low-rank approximation, and then de-scale:

x <- scale(x, scale = TRUE)
pc <- prcomp(x)

Full rank will be:

xfull <- pc$x %*% pc$rotation

The eigenvalues already are incorporated in pc$x, and you don't have to
care about them.

Then rank=3 approximation will be:

x3 <- pc$x[,1:3] %*% pc$rotation[,1:3]

Then you have to "de-scale":

x3 <- sweep(x3, 2, attr(x, "scaled:scale", "*")
x3 <- sweep(x3, 2, attr(x, "scaled:center", "+")

And here you are. I wouldn't call this a smoothing, though.

Library 'vegan' can do this automatically for PCA run with function
'rda', but there the scaling of raw results is non-conventional (though
"biplot").

cheers, jari oksanen
-- 
Jari Oksanen <jarioksa at sun3.oulu.fi>



From jarioksa at sun3.oulu.fi  Wed Mar  2 07:39:10 2005
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Wed, 02 Mar 2005 08:39:10 +0200
Subject: [R] Reconstructing Datasets
In-Reply-To: <1109745024.13281.9.camel@biol102145.oulu.fi>
References: <Pine.LNX.4.44.0503012029010.4905-100000@gw.env.leeds.ac.uk>
	<1109745024.13281.9.camel@biol102145.oulu.fi>
Message-ID: <1109745550.13281.16.camel@biol102145.oulu.fi>

On Wed, 2005-03-02 at 08:30 +0200, Jari Oksanen wrote:
> On Tue, 2005-03-01 at 20:30 +0000, Laura Quinn wrote:
> > Hi,
> > 
> > Is it possible to recreate "smoothed" data sets in R, by performing a PCA
> > and then reconstructing a data set from say the first 2/3 EOFs?
> > 
> > I've had a look in the help pages and don't seem to find anything
> > relevant.
> > 
> It's not in the R help, but in the books about PCA in help references. 
> 
> This can be done, not quite directly. Most of the hassle comes from the
> centring, and I guess in your case, from scaling of the results. I guess
> it is best to first scale the results like PCA would do, then make the
> low-rank approximation, and then de-scale:
> 
> x <- scale(x, scale = TRUE)
> pc <- prcomp(x)
> 
> Full rank will be:
> 
> xfull <- pc$x %*% pc$rotation

Naturally, I forgot the transposition:

xfull <- pc$x %*% t(pc$rotation)

and the check:

range(x - xfull) 

which should be something in magnitude 1e-12 or better (6e-15 in the
test I run).

> 
> The eigenvalues already are incorporated in pc$x, and you don't have to
> care about them.
> 
> Then rank=3 approximation will be:
> 
> x3 <- pc$x[,1:3] %*% pc$rotation[,1:3]
> 
and the same here:

x3 <- pc$x[,1:3] %*% t(pc$rotation[,1:3])

The moral: cut-and-paste.

> Then you have to "de-scale":
> 
> x3 <- sweep(x3, 2, attr(x, "scaled:scale", "*")
> x3 <- sweep(x3, 2, attr(x, "scaled:center", "+")
> 
And here you need to close the parentheses: 

x3 <- sweep(x3, 2, attr(x, "scaled:scale", "*"))
x3 <- sweep(x3, 2, attr(x, "scaled:center", "+"))

The moral #1: cut-and-paste.
and #2: drink coffee in the morning.

> And here you are. I wouldn't call this a smoothing, though.
> 
> Library 'vegan' can do this automatically for PCA run with function
> 'rda', but there the scaling of raw results is non-conventional (though
> "biplot").
> 

cheers, jari oksanen
-- 
Jari Oksanen <jarioksa at sun3.oulu.fi>



From sfalcon at fhcrc.org  Wed Mar  2 08:21:44 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 1 Mar 2005 23:21:44 -0800
Subject: [R] return from nested function?
In-Reply-To: <20050225203420.F1681AEA30@mail.rsma.frb.gov>
References: <20050225203420.F1681AEA30@mail.rsma.frb.gov>
Message-ID: <6eb05719add6861cc72c25a41f432622@fhcrc.org>

On Feb 25, 2005, at 12:34 PM, jhallman at frb.gov wrote:

> Is is possible from within a function to cause its caller to return()?

This snippet may be of interest:


 > f = function(x) {
+ print("f")
+ g(return())
+ print("end of f")
+ }

 > g=function(x) {print("g")
+ x
+ print("end of g")
+ }

 > f(1)
[1] "f"
[1] "g"
NULL



From ligges at statistik.uni-dortmund.de  Wed Mar  2 08:31:04 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 02 Mar 2005 08:31:04 +0100
Subject: [R] write a library under 2.0.1 version
In-Reply-To: <Pine.OSF.4.58.0503011631420.412611@odin.mdacc.tmc.edu>
References: <4248.155.198.41.106.1109690597.squirrel@ensim-2.playnet.it>	<Pine.LNX.4.61.0503011738370.17424@gannet.stats>
	<Pine.OSF.4.58.0503011631420.412611@odin.mdacc.tmc.edu>
Message-ID: <42256BB8.9030908@statistik.uni-dortmund.de>

Paul Roebuck wrote:
> On Tue, 1 Mar 2005, Prof Brian Ripley wrote:
> 
> 
>>On Tue, 1 Mar 2005 marta at statistica.it wrote:
>>
>>
>>>I had written a library under R 1.9.0 and now I would like to import that
>>>library under R 2.0.1
>>>Apparently it does not work; I can install the package, but when I try to
>>>read it the error is the following:
>>>
>>>Error in library(compvar) : 'compvar' is not a valid package -- installed
>>>< 2.0.0
>>>
>>>[SNIP]
>>
>>You install the package with R CMD INSTALL, just as was documented for
>>1.9.1.  See the `Writing R Extensions' and `R Installation and
>>Administration' manuals.
> 
> 
> Out of curiousity, just how often has the package installation
> compatibility between versions been an issue? Would it perhaps

Happens from time to time, in particular if compiled code is included.


> be beneficial to version personal directories by major version?
> I.e. instead of having just "~/R/library", would it be better
> to have "~/R/1.x/library" and "~/R/2.x/library" and have the

Why???

> .Rprofile select appropriately depending on version of R being
> executed? If so, maybe this question would cease to be an issue.

Why do you want to execute any R version < 2.0.1?

> I'd be interested to know how Prof. Ripley's R_LIBS variable
> is defined, if he wouldn't mind sharing. Also curious if most
> people keep BioConductor packages installed separately in a
> third location.

Now I'm completely lost. if you really want to keep separate libraries 
for R-2.x.y and R-1.x.y, you can simply call R with R_LIBS set, or for 
your convenience write a two line shell script that sets R_LIBS 
appropriately and calls the relevant version of R after that.

Uwe Ligges


> ----------------------------------------------------------
> SIGSIG -- signature too long (core dumped)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From robin.smit at tno.nl  Wed Mar  2 08:56:01 2005
From: robin.smit at tno.nl (Smit, Robin)
Date: Wed, 2 Mar 2005 08:56:01 +0100
Subject: [R] Leaps & regsubsets
Message-ID: <2395774549BBDA40AC83BC9E6223FBFF22F8B4@MS-DT01VS01.tsn.tno.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050302/e6392304/attachment.pl

From pensterfuzzer at yahoo.de  Wed Mar  2 09:24:03 2005
From: pensterfuzzer at yahoo.de (Werner Wernersen)
Date: Wed, 2 Mar 2005 09:24:03 +0100 (CET)
Subject: [R] Journal Quality R Graphs?
Message-ID: <20050302082403.42207.qmail@web25810.mail.ukl.yahoo.com>

Thanks for your answer, Adai!

Being a newbie, I finally tried a lot of things and
wasted a stack of paper in 
order to get a black & white printer printable chart
of good quality.

My experiences are the following:
* do never (!) use the alpha correction color settings
for transparency if the 
graph is to be printed (alpha correction also works
with few formats, e.g. PDF 1.4)
* the library(gstat), bpy.colors() color palette
prints nicely in grey
* there is a small difference in output from saving
the graphs to PS or PDF with 
PS looking slightly better
* set the line width with par(lwd=)
* set the line style with par(lty="solid")
* in the print dialog before printing: check if the
automatic scaling option is set

After doing all of this, my chart looks rather
acceptable now.
The R version used was R 2.0.1 on win2k and printing
was done on a HP LJ 4M Plus.

Thanks again for your answers!

Best,
   Werner



Adaikalavan Ramasamy wrote:
> Searching for "graph publication" on
> http://maths.newcastle.edu.au/~rking/R/ gave me the
following hit :
>
http://tolstoy.newcastle.edu.au/R/help/04/03/0202.html
which suggests
> postscript().
> 
> Have you tried printing other documents in black and
white on the same
> printer or tried different printers for the same R
graph. This will
> hopefully eliminate printer as a possible culprit.
Dying printer toners
> sometimes makes the graph look worse than it
actually is.
> 
> 
> Regards, Adai
> 
> 
> 
> 
> 
> On Tue, 2005-03-01 at 00:27 +0100, Werner Wernersen
wrote: 
> 
>>Hi!
>>
>>I have browsed the help archives but did not find
>>anything on the subject: How 
>>to make publication quality graphs with R best?
>>Is there some document about that topic out there?
The
>>problem is that the 
>>graphs look nice on the screen but when printed in
>>black and white every color 
>>apart from black doesn't look very nice. Is there
some
>>guideline how to set 
>>color palettes and or fill patterns for charts?
>>
>>Thank you very much for considering my question in
>>advance.
>>
>>Best,
>>   Werner
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>>
> 
> 
> 
>



From pensterfuzzer at yahoo.de  Wed Mar  2 09:24:21 2005
From: pensterfuzzer at yahoo.de (Werner Wernersen)
Date: Wed, 2 Mar 2005 09:24:21 +0100 (CET)
Subject: [R] Journal Quality R Graphs?
Message-ID: <20050302082421.73405.qmail@web25805.mail.ukl.yahoo.com>

Thanks for your answer, Adai!

Being a newbie, I finally tried a lot of things and
wasted a stack of paper in 
order to get a black & white printer printable chart
of good quality.

My experiences are the following:
* do never (!) use the alpha correction color settings
for transparency if the 
graph is to be printed (alpha correction also works
with few formats, e.g. PDF 1.4)
* the library(gstat), bpy.colors() color palette
prints nicely in grey
* there is a small difference in output from saving
the graphs to PS or PDF with 
PS looking slightly better
* set the line width with par(lwd=)
* set the line style with par(lty=)
* in the print dialog before printing: check if the
automatic scaling option is set

After doing all of this, my chart looks rather
acceptable now.
The R version used was R 2.0.1 on win2k and printing
was done on a HP LJ 4M Plus.

Thanks again for your answers!

Best,
   Werner



Adaikalavan Ramasamy wrote:
> Searching for "graph publication" on
> http://maths.newcastle.edu.au/~rking/R/ gave me the
following hit :
>
http://tolstoy.newcastle.edu.au/R/help/04/03/0202.html
which suggests
> postscript().
> 
> Have you tried printing other documents in black and
white on the same
> printer or tried different printers for the same R
graph. This will
> hopefully eliminate printer as a possible culprit.
Dying printer toners
> sometimes makes the graph look worse than it
actually is.
> 
> 
> Regards, Adai
> 
> 
> 
> 
> 
> On Tue, 2005-03-01 at 00:27 +0100, Werner Wernersen
wrote: 
> 
>>Hi!
>>
>>I have browsed the help archives but did not find
>>anything on the subject: How 
>>to make publication quality graphs with R best?
>>Is there some document about that topic out there?
The
>>problem is that the 
>>graphs look nice on the screen but when printed in
>>black and white every color 
>>apart from black doesn't look very nice. Is there
some
>>guideline how to set 
>>color palettes and or fill patterns for charts?
>>
>>Thank you very much for considering my question in
>>advance.
>>
>>Best,
>>   Werner
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>>
> 
> 
> 
>



From sanobast-r01 at yahoo.de  Wed Mar  2 10:44:04 2005
From: sanobast-r01 at yahoo.de (Thomas)
Date: Wed, 02 Mar 2005 10:44:04 +0100
Subject: [R] barchart error (invalid line type) maybe caused by mangled data
 frame, & fix() resolving the problem
Message-ID: <d041lm$lj0$1@sea.gmane.org>

Hi,

I use R 2.0.1 at WinXP. I ran into the following problem when using 
barchart() and would like to ask if there is a solution for it other 
than using fix().

My data is:

>> class(b)
> [1] "data.frame"
>> unclass(b)
> $uint
>  [1]  84  42  71  82  80 123  13   1  15  77  61  56  62  27 100  87 110 191  71
> [20]   3  48 144 101 115 161  52 164 105 154 266  93   1  53 167 161 130 195
> 
> $uext
>  [1]  17  12  13  17  14  32  34   5  50 132  93  66  86  66  65  63  54  97  34
> [20]  41  81 123  88  85 213 159 171 158 140 153  75  65 126 252 225 127 192
> 
> $uges
>  [1] 101  54  84  99  94 155  47   6  65 209 154 122 148  93 165 150 164 288 105
> [20]  44 129 267 189 200 374 211 335 263 294 419 168  66 179 419 386 257 387
> 
> $month
>  [1] "01" "02" "03" "04" "05" "06" "07" "08" "09" "10" "11" "12" "01" "02" "03"
> [16] "04" "05" "06" "07" "08" "09" "10" "11" "12" "01" "02" "03" "04" "05" "06"
> [31] "07" "08" "09" "10" "11" "12" "01"
> 
> $year
>  [1] "02" "02" "02" "02" "02" "02" "02" "02" "02" "02" "02" "02" "03" "03" "03"
> [16] "03" "03" "03" "03" "03" "03" "03" "03" "03" "04" "04" "04" "04" "04" "04"
> [31] "04" "04" "04" "04" "04" "04" "05"
> 
> attr(,"row.names")
>  [1] "1"   "11"  "12"  "13"  "14"  "15"  "16"  "17"  "18"  "19"  "110" "111"
> [13] "112" "113" "114" "115" "116" "117" "118" "119" "120" "121" "122" "123"
> [25] "124" "125" "126" "127" "128" "129" "130" "131" "132" "133" "134" "135"
> [37] "136"

or simply:

 > b
     uint uext uges month year
1     84   17  101    01   02
11    42   12   54    02   02
12    71   13   84    03   02
13    82   17   99    04   02
14    80   14   94    05   02
15   123   32  155    06   02
16    13   34   47    07   02
17     1    5    6    08   02
18    15   50   65    09   02
19    77  132  209    10   02
110   61   93  154    11   02
111   56   66  122    12   02
112   62   86  148    01   03
113   27   66   93    02   03
114  100   65  165    03   03
115   87   63  150    04   03
116  110   54  164    05   03
117  191   97  288    06   03
118   71   34  105    07   03
119    3   41   44    08   03
120   48   81  129    09   03
121  144  123  267    10   03
122  101   88  189    11   03
123  115   85  200    12   03
124  161  213  374    01   04
125   52  159  211    02   04
126  164  171  335    03   04
127  105  158  263    04   04
128  154  140  294    05   04
129  266  153  419    06   04
130   93   75  168    07   04
131    1   65   66    08   04
132   53  126  179    09   04
133  167  252  419    10   04
134  161  225  386    11   04
135  130  127  257    12   04
136  195  192  387    01   05

What I would like to do is this: display a bar chart uint per month with 
the values per year stacked. So I type:

> barchart(uint ~ month, data=b, stack=TRUE, horizontal=F, groups=year,
>         xlab="Month", ylab="Count"
> )

The trellis window pops up and I after drawing one bar I get this error 
message:

> Error in grid.Call.graphics("L_rect", x$x, x$y, x$width, x$height, valid.just(x$just)) : 
>         invalid line type

I tried several things to resolve the problem. Rather by accident I typed:

> fix(b)

After trying the barchart() function again, it was properly displayed.

I guess that the data.frame is somehow messed up during the aggregation 
procedure, which didn't cause any problems so far, and that fix() 
somehow puts things right again. Now, is there a non-interactive 
solution for this problem? Does anybody know what caused this problem in 
the first place?

The data is read from a bundle of csv files using this function:

> cls.read.data <- function (name, months=months.default, only.all=F, ...) {
>     datavars <- paste(name, months, sep="")
>     
>     for (m in months) {
>         v <- paste(name, m, sep="")
>         filename <- paste(data.dir, paste(v, ".txt", sep=""), sep="/")
>         print(filename)
>         data <- tryCatch(read.table(filename, ...), error=function(filename, ...) {data.frame()})
>         if (nrow(data) > 0) {
>             data[['month']] <- m
>         }
>         assign(v, data)
>     }
>    
>     fn <- function(m) {eval(parse(text=m))}
>     rv <- lapply(datavars, fn)
>     rv$all <- do.call("rbind", rv)
>     if (only.all) {
>         rv$all
>     } else {
>         rv
>     }
> }
> 
> ben.cols <- c("uint", "uext", "uges")
> months.all <- c(
>     "0201", "0202", "0203", "0204", "0205", "0206", "0207", "0208", "0209", "0210", 
>     "0211", "0212", "0301", "0302", "0303", "0304", "0305", "0306", "0307", "0308", 
>     "0309", "0310", "0311", "0312", "0401", "0402", "0403", "0404", "0405", "0406", "0407",
>     "0408", "0409", "0410", "0411", "0412", "0501",
> )
> bb <- cls.read.data("benutzer", header=F, sep=";", quote="", col.names=ben.cols, month=months.all)
 > b <- bb$all
> b$month <- substring(bb$all$month, 3)
> b$year <- substring(bb$all$month, 1, 2)

I'm (still) new to R, so I guess there are more appropriate ways to 
collect the data.

Regards,
Thomas.



From simon at stats.gla.ac.uk  Wed Mar  2 11:14:52 2005
From: simon at stats.gla.ac.uk (Simon Wood)
Date: Wed, 2 Mar 2005 10:14:52 +0000 (GMT)
Subject: [R] constraining initial slope in smoother.spline
In-Reply-To: <002301c51e7e$4a18a990$ae1ad284@BIO041>
References: <002301c51e7e$4a18a990$ae1ad284@BIO041>
Message-ID: <Pine.LNX.4.58.0503021012340.11227@moon.stats.gla.ac.uk>

> Hello.  I want to fit a smoother spline (or an equivalent local
> regression method) to a series of data in which the initial value of the
> 1st derivative (slope) is constrained to a specific value.  Is it
> possible to do this?  If so, how?

- you should be able to modify the example in the help file for 
mgcv::pcls, to do this. The example uses inequality constraints to impose 
monotonicity on a smooth, but the routine will also accept equality 
constraints.

Simon



From matthieu.cornec at gmail.com  Wed Mar  2 11:34:06 2005
From: matthieu.cornec at gmail.com (Matthieu Cornec)
Date: Wed, 2 Mar 2005 11:34:06 +0100
Subject: [R] Using time series and lm
In-Reply-To: <8a83e50005021808354a6f6687@mail.gmail.com>
References: <8a83e50005021808354a6f6687@mail.gmail.com>
Message-ID: <8a83e500050302023425bf072a@mail.gmail.com>

Hello,

I apologize for this question that may has been asked a lot of times
but I could not go through it.

I create a multivariate time series containing NA values. (This
dataset of time series can come directly from an imported file).
I want to compute a linear regression and obtain a time serie for both
residuals and fitted values. I have tried the trick ts.intersect,
without success.

Could you help me out of this?
####
Example:

y<-ts(1:10+rnorm(10))
x<-ts(1:10)
datats<-cbind(y,lagx=lag(x))

Notice the datats could come directly from an imported file, that is
why I did not use ts.intersect(y,lagx=lag(x))

fit<-lm(y~lagx,data=datats,na.action=na.omit)

but how do I get a time serie of residuals instead of a vector residuals(fit)?
######



From agmartinca at gruposantander.com  Wed Mar  2 12:02:23 2005
From: agmartinca at gruposantander.com (MARTIN CALMARZA AGUSTIN)
Date: Wed, 2 Mar 2005 12:02:23 +0100
Subject: [R] Problems with the "tseries" package
Message-ID: <17BE0E8C19D93E448FED29112825876A915C6E@VEXCHA0005.san.corp>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050302/d32aaf39/attachment.pl

From jtk at cmp.uea.ac.uk  Wed Mar  2 13:13:17 2005
From: jtk at cmp.uea.ac.uk (Jan T. Kim)
Date: Wed, 2 Mar 2005 12:13:17 +0000
Subject: [R] return from nested function?
In-Reply-To: <6eb05719add6861cc72c25a41f432622@fhcrc.org>
References: <20050225203420.F1681AEA30@mail.rsma.frb.gov>
	<6eb05719add6861cc72c25a41f432622@fhcrc.org>
Message-ID: <20050302121317.GA1498@jtkpc.cmp.uea.ac.uk>

On Tue, Mar 01, 2005 at 11:21:44PM -0800, Seth Falcon wrote:
> On Feb 25, 2005, at 12:34 PM, jhallman at frb.gov wrote:
> 
> >Is is possible from within a function to cause its caller to return()?
> 
> This snippet may be of interest:
> 
> 
> > f = function(x) {
> + print("f")
> + g(return())
> + print("end of f")
> + }
> 
> > g=function(x) {print("g")
> + x
> + print("end of g")
> + }
> 
> > f(1)
> [1] "f"
> [1] "g"
> NULL

I may be dumb today, but doesn't that beg the question of how does g
cause f not to return?

Best regards, Jan
-- 
 +- Jan T. Kim -------------------------------------------------------+
 |    *NEW*    email: jtk at cmp.uea.ac.uk                               |
 |    *NEW*    WWW:   http://www.cmp.uea.ac.uk/people/jtk             |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*



From Wittner.Ben at mgh.harvard.edu  Wed Mar  2 12:33:18 2005
From: Wittner.Ben at mgh.harvard.edu (Wittner, Ben)
Date: Wed, 2 Mar 2005 06:33:18 -0500
Subject: [R] subset selection for logistic regression
Message-ID: <B1D5C2D0D1D6AE4C9DF88E81330D71C60DA2BE@PHSXMB23.partners.org>

R-packages leaps and subselect implement various methods of selecting best or
good subsets of predictor variables for linear regression models, but they do
not seem to be applicable to logistic regression models.
 
Does anyone know of software for finding good subsets of predictor variables for
linear regression models?
 
Thanks.
 
-Ben
 
p.s., The leaps package references "Subset Selection in Regression" by Alan
Miller. On page 2 of the
2nd edition of that text it states the following:
 
  "All of the models which will be considered in this monograph will be linear;
that is they
   will be linear in the regression coefficients.Though most of the ideas and
problems carry
   over to the fitting of nonlinear models and generalized linear models
(particularly the fitting
   of logistic relationships), the complexity is greatly increased."



From f.harrell at vanderbilt.edu  Wed Mar  2 14:12:47 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Wed, 02 Mar 2005 07:12:47 -0600
Subject: [R] subset selection for logistic regression
In-Reply-To: <B1D5C2D0D1D6AE4C9DF88E81330D71C60DA2BE@PHSXMB23.partners.org>
References: <B1D5C2D0D1D6AE4C9DF88E81330D71C60DA2BE@PHSXMB23.partners.org>
Message-ID: <4225BBCF.4090706@vanderbilt.edu>

Wittner, Ben wrote:
> R-packages leaps and subselect implement various methods of selecting best or
> good subsets of predictor variables for linear regression models, but they do
> not seem to be applicable to logistic regression models.
>  
> Does anyone know of software for finding good subsets of predictor variables for
> linear regression models?
>  
> Thanks.
>  
> -Ben

Why are these procedures still being used?  The performance is known to 
be bad in almost every sense (see r-help archives).

Frank Harrell

>  
> p.s., The leaps package references "Subset Selection in Regression" by Alan
> Miller. On page 2 of the
> 2nd edition of that text it states the following:
>  
>   "All of the models which will be considered in this monograph will be linear;
> that is they
>    will be linear in the regression coefficients.Though most of the ideas and
> problems carry
>    over to the fitting of nonlinear models and generalized linear models
> (particularly the fitting
>    of logistic relationships), the complexity is greatly increased."


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From James.A.Rogers at pfizer.com  Wed Mar  2 14:35:14 2005
From: James.A.Rogers at pfizer.com (Rogers, James A [PGRD Groton])
Date: Wed, 2 Mar 2005 08:35:14 -0500 
Subject: [R] Anova with Scheffe Tests
Message-ID: <2A8DE2E40F52E049B8FBB4634D32AFE64B61BF@groamrexm01.amer.pfizer.com>

>
>In good ol' Statview (now dearly departed) to complete a Scheffe 
>test you selected the independent variables and dependent variable 
>and it produced a  table with the pairwise comparisons of the levels 
>of the factor. I'm looking for a system that is as basic, but can be 
>done using R and has documentation so I'm not guessing what I'm 
>doing. I'd rather not have to do plots in R and then run over to 
>dead software to do Scheffe's if possible.
>
>I checked on google and there seems to be code for a couple of 
>functions out there, but I need something that has a manual.
>
>Is there a Scheffe function out there that is reasonably well 
>documented, or should I consider some other method of dealing with 
>this data. We have been using Scheffe for this type of analysis as I 
>was under the impression it was very conservative. Tukey's HSD seems 
>to be conservative as well. Should I try this? Is there a different 
>approacch that is better and where can I read about it.
>
>Thanks for any help you can provide.
>
>Sam
>

It sounds like you are only interested in simple pairwise comparisons, in
which case you are better off using Tukey's HSD. This will still protect the
family-wise error rate, but will allow you to infer more differences than
you would using Scheff?'s method. Scheff?'s method is exact if you are truly
interested in all contrasts (a situation I have never come across), but it
is overly conservative when inferences are only made for pairwise
differences. 

A geometric explanation of the difference between the two methods can be
found in Jason Hsu's book "Multiple Comparisons: Theory and Methods". 

As you can also read in that book, there is no good reason to precede
Tukey's HSD with an ANOVA F-test. Tukey's HSD controls the family-wise error
rate anyway, so an initial F-test is superfluous.

--Jim 

James A. Rogers 
Manager, Nonclinical Statistics
PGR&D Groton Labs
Eastern Point Road (MS 8260-1331)
Groton, CT 06340
office: (860) 686-0786
fax: (860) 715-5445
 


LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From consentino at infinito.it  Wed Mar  2 14:40:05 2005
From: consentino at infinito.it (consentino@infinito.it)
Date: Wed, 02 Mar 2005 14:40:05 +0100
Subject: [R] Problems with the "tseries" package
In-Reply-To: <17BE0E8C19D93E448FED29112825876A915C6E@VEXCHA0005.san.corp>
References: <17BE0E8C19D93E448FED29112825876A915C6E@VEXCHA0005.san.corp>
Message-ID: <web-51606948@infinito.it>

Hi, there is a package called quadprog in the CRAN page, 
under Windonws version in the page
Index of /bin/windows/contrib/2.0

Fabrizio Consentino

On Wed, 2 Mar 2005 12:02:23 +0100
  "MARTIN CALMARZA AGUSTIN" 
<agmartinca at gruposantander.com> wrote:
> Dear Sirs,
> I am trying to perform a garch analysis to some data 
>time series.Therefore, I've downloaded the package 
>"tseries", as the garch analysis is not available in the 
>main R  program.When I try to load the "tseries package" 
>from the R-Console screen, the following message appears:
> 
> local({pkg <- select.list(sort(.packages(all.available = 
>TRUE)))
> + if(nchar(pkg)) library(pkg, character.only=TRUE)})
> Loading required package: quadprog 
> Error: package 'quadprog' could not be loaded
> In addition: Warning message: 
> There is no package called 'quadprog' in: library(pkg, 
>character.only = TRUE, logical = TRUE, lib.loc = lib.loc) 
> 
> It seems that the program detects a failure in a package 
>called "quadprog", which I can't find (while I am trying 
>to select the "tseries" package). As a consequence I 
>cannot use the "garch" command.Could you lend me a 
>helping hand on this issue?.
> 
> Thanks very much.Best regards,
> Agust?n Mart?n
> 
> 
> ******************AVISO LEGAL**********************
> 
> Este mensaje es privado y confidencial y solamente para 
>la persona a la que va dirigido. Si usted ha recibido 
>este mensaje por error, no debe revelar, copiar, 
>distribuir o usarlo en ning?n sentido. Le rogamos lo 
>comunique al remitente y borre dicho mensaje y cualquier 
>documento adjunto que pudiera contener. No hay renuncia a 
>la confidencialidad ni a ning?n privilegio por causa de 
>transmisi?n err?nea o mal funcionamiento.  Cualquier 
>opini?n expresada en este mensaje pertenece ?nicamente al 
>autor remitente, y no representa necesariamente la 
>opini?n de Santander Central Hispano, a no ser que 
>expresamente se diga y el remitente est? autorizado para 
>hacerlo. Los correos electr?nicos no son seguros, no 
>garantizan la confidencialidad ni la correcta recepci?n 
>de los mismos, dado que pueden ser interceptados, 
>manipulados, destruidos, llegar con demora, incompletos, 
>o con virus. Santander Central Hispano no se hace 
>responsable de las alteraciones que pudieran hacerse al 
>mensaje una vez enviado.Este mensaje s?lo tiene una 
>finalidad de informaci?n, y no debe interpretarse como 
>una oferta de venta o de compra de valores ni de 
>instrumentos financieros relacionados. En el caso de que 
>el destinatario de este mensaje no consintiera la 
>utilizaci?n del correo electr?nico via Internet, rogamos 
>lo ponga en nuestro conocimiento.
> 
> **********************DISCLAIMER*****************
> This message is private and confidential and it is 
>intended exclusively for the addressee. If you receive 
>this message by mistake, you should not disseminate, 
>distribute or copy this e-mail. Please inform the sender 
>and delete the message and attachments from your system. 
>No confidentiality nor any privilege regarding the 
>information is waived or lost by any mistransmission or 
>malfunction.Any views or opinions contained in this 
>message are solely those of the author, and do not 
>necessarily represent those of Santander Central Hispano, 
>unless otherwise specifically stated and the sender is 
>authorised to do so.E-mail transmission cannot be 
>guaranteed to be secure, confidential, or error-free, as 
>information could be intercepted, corrupted, lost, 
>destroyed, arrive late, incomplete, or contain viruses. 
>Santander Central Hispano does not accept responsibility 
>for any changes in the contents of this message after it 
>has been sent.This message is provided for informational 
>purposes and should not be construed as a solicitation or 
>offer to buy or sell any securities or related financial 
>instruments. If the addressee of this message does not 
>consent to the use of internet e-mail, please communicate 
>it to us.
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From ramasamy at cancer.org.uk  Wed Mar  2 14:42:33 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 02 Mar 2005 13:42:33 +0000
Subject: [R] Differences between package and library terminology
Message-ID: <1109770953.6175.34.camel@ndmpc126.orc.ox.ac.uk>

Just out of curiosity, what is the difference between the terms for
package and library ?  Why are we loading a package with the library()
command ?

If this is a case of RTFM, I would be happy to do so if pointed in the
right direction. I have searched the FAQ and mail archives and only came
up with http://tolstoy.newcastle.edu.au/R/help/05/02/12162.html but this
still does not explain what is the requirement/features of a package vs.
library.

Does this question not qualify to be included in the FAQs.

Thank you

Regards, Adai



From colliera at ukzn.ac.za  Wed Mar  2 14:44:29 2005
From: colliera at ukzn.ac.za (Andrew Collier)
Date: Wed, 2 Mar 2005 15:44:29 +0200
Subject: [R] orientation of eps files
Message-ID: <20050302134429.GA22030@adelie>

hello,

i have a problem with the orientation of eps files produced with the postscript() command. i have generated some eps files with R using:

postscript(file = filename, horizontal = FALSE, paper = "special", onefile = F
ALSE, height = height, width = width, pointsize = pointsize)

now, when i include these eps files into a standard paper document (ie. a4 paper, portrait orientation) everything is fine.

however, i am now wanting to incorporate the same images into a presentation. i am making a pdf file, which for presentation purposes is in landscape orientation. i am using latex with the prosper package. images are included with \includegraphics{} and a pdf file is generated with dvipdf. however, in this case, when i include the eps figures the whole page suddenly gets rotated around into portrait. eps files from other packages seem to work fine.

there is an example of the problem at ftp://chinstrap.nu.ac.za/orientation.pdf.

if you have any ideas as to what might be causing this problem, i would be extremely happy to hear them.

best regards,
andrew.

-- 
Andrew B. Collier

Antarctic Research Fellow                                   tel: +27 31 2601157
Space Physics Research Institute                            fax: +27 31 2616550
University of KwaZulu-Natal, Durban, 4041, South Africa



From drcarbon at gmail.com  Wed Mar  2 15:16:08 2005
From: drcarbon at gmail.com (Dr Carbon)
Date: Wed, 2 Mar 2005 09:16:08 -0500
Subject: [R] Differences between package and library terminology
Message-ID: <e89bb7ac05030206161612e58f@mail.gmail.com>

If you believe the fortunes package (or is it library) then your
answer is contained therein:

#59
Zhu Wang: I am trying to create a library which uses some Fortran
source files [...]

Douglas Bates: Someone named Martin Maechler will shortly be sending
you email regarding the distinction between 'library' and 'package'
:-)

Zhu Wang and Douglas Bates;NA;R-help;May 2004





> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Adaikalavan
> Ramasamy
> Sent: Wednesday, March 02, 2005 8:43 AM
> To: R-help
> Subject: [R] Differences between package and library terminology
> 
> 
> Just out of curiosity, what is the difference between the terms for
> package and library ?  Why are we loading a package with the library()
> command ?
> 
> If this is a case of RTFM, I would be happy to do so if pointed in the
> right direction. I have searched the FAQ and mail archives and only came
> up with http://tolstoy.newcastle.edu.au/R/help/05/02/12162.html but this
> still does not explain what is the requirement/features of a package vs.
> library.
> 
> Does this question not qualify to be included in the FAQs.
> 
> Thank you
> 
> Regards, Adai
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From dr.mike at ntlworld.com  Wed Mar  2 15:17:16 2005
From: dr.mike at ntlworld.com (dr mike)
Date: Wed, 2 Mar 2005 14:17:16 -0000
Subject: [R] subset selection for logistic regression
In-Reply-To: <B1D5C2D0D1D6AE4C9DF88E81330D71C60DA2BE@PHSXMB23.partners.org>
Message-ID: <20050302141742.JUWH3971.aamta07-winn.mailhost.ntl.com@c400>

 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Wittner, Ben
> Sent: 02 March 2005 11:33
> To: r-help at lists.R-project.org
> Subject: [R] subset selection for logistic regression
> 
> R-packages leaps and subselect implement various methods of 
> selecting best or good subsets of predictor variables for 
> linear regression models, but they do not seem to be 
> applicable to logistic regression models.
>  
> Does anyone know of software for finding good subsets of 
> predictor variables for linear regression models?
>  
> Thanks.
>  
> -Ben
>  
> p.s., The leaps package references "Subset Selection in 
> Regression" by Alan Miller. On page 2 of the 2nd edition of 
> that text it states the following:
>  
>   "All of the models which will be considered in this 
> monograph will be linear; that is they
>    will be linear in the regression coefficients.Though most 
> of the ideas and problems carry
>    over to the fitting of nonlinear models and generalized 
> linear models (particularly the fitting
>    of logistic relationships), the complexity is greatly increased."
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 

The LASSO method and the Least Angle Regression method are two such that
have both been implemented (efficiently IMHO - only one least squares for
all levels of shrinkage IIRC) in the lars package for R of Hastie and Efron.
There is a paper by Madigan and Ridgeway that discusses the use of the Least
Angle Regresson approach in the context of logistic regression - available
for download from Madigan's space at Ruttgers: 
www.stat.rutgers.edu/~madigan/PAPERS/lars3.pdf 

HTH

Mike



From MSchwartz at MedAnalytics.com  Wed Mar  2 15:20:44 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed, 02 Mar 2005 08:20:44 -0600
Subject: [R] Differences between package and library terminology
In-Reply-To: <1109770953.6175.34.camel@ndmpc126.orc.ox.ac.uk>
References: <1109770953.6175.34.camel@ndmpc126.orc.ox.ac.uk>
Message-ID: <1109773245.11573.44.camel@horizons.localdomain>

On Wed, 2005-03-02 at 13:42 +0000, Adaikalavan Ramasamy wrote:
> Just out of curiosity, what is the difference between the terms for
> package and library ?  Why are we loading a package with the library()
> command ?
> 
> If this is a case of RTFM, I would be happy to do so if pointed in the
> right direction. I have searched the FAQ and mail archives and only came
> up with http://tolstoy.newcastle.edu.au/R/help/05/02/12162.html but this
> still does not explain what is the requirement/features of a package vs.
> library.
> 
> Does this question not qualify to be included in the FAQs.
> 
> Thank you
> 
> Regards, Adai


There was actually just an exchange on this last month, which was
precipitated by a thread on r-help and then moved to r-devel. The r-
devel part, which is more relevant here, begins at:

https://stat.ethz.ch/pipermail/r-devel/2005-February/032095.html

HTH,

Marc Schwartz



From ramasamy at cancer.org.uk  Wed Mar  2 15:21:13 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 02 Mar 2005 14:21:13 +0000
Subject: [R] questions related to ploting in R
In-Reply-To: <16A0583FB1644E4DB8C0A0265028B6FD28B928@nihexchange13.nih.gov>
References: <16A0583FB1644E4DB8C0A0265028B6FD28B928@nihexchange13.nih.gov>
Message-ID: <1109773274.6175.67.camel@ndmpc126.orc.ox.ac.uk>

You have to decided whether you want one single plot or 23 plots (one
for each chromosome). Since I suspect that, say, copy_num at the end of
Chromosome 1 and the copy_num at the start of Chromosome 2 are not
related (like time series data) and would suggest 23 plots instead.


# simulate data #
df <- data.frame( Chromosome=rep(1:23, each=10), 
                  location=round(runif(230, max=1000000)), 
                  copy_num=runif(230, max=10) )

head(df)
  Chromosome location  copy_num
1          1   289588 7.3537879
2          1   267081 8.3605345
3          1   926470 0.1270541
4          1   214679 7.1798719
5          1   388366 4.2847290
6          1   332667 7.7888741
...

library(lattice)
xyplot( copy_num ~ location | Chromosome, data=df )


If you want it as one big plot, then you will need to somehow adjust the
location variable. I would suggest you think about putting the
chromosomes end to end. If you add the cumulative length of each
chromosome to the location to all the variables within a chromosome,
then you will get unique mapping for location. 

For example, if Chromosome 1 was 1,000,000 bases long and Chromosome 2
was 800,000 bases long, then a gene in location 500 of Chromosome 3
would actually be in position 1,800,500 (= 1,000,000 + 800,000 + 500) in
the overall map. Then you can simple plot the copy_num vs the new
location variable.

You might want to also check BioConductor packages if they have anything
more specific to your needs.

Regards, Adai



On Fri, 2004-08-06 at 16:03 -0400, Li, Aiguo (NIH/NCI) wrote:
> Dear all.
>  
> I need to draw a scatter plot of 23 chromosome copy numbers (y axes) against
> chromosome and physical location within each chromosome in one plot.  The
> data matrix looks as below:
>  
> chr  location copy_num
>  1   118345 1.320118
>  1   3776202 1.133879
>  1   4798845 0.989997
>  1   5350951 1.100967
> . more data here
> .
> .
>  2    118345 2.459119
>  2    157739 1.915919
>  2   1530065 1.924372
>  2   1530235 3.138177
> .
> .
> .
> more data here
> 23   118345     2.454111
> 23   5142838 1.719263
> 23   5163858 1.228840
>  
> The x axes of the plot should have chromosome label from 1 to 23 and
> physical location within each chromosome label.  The physical location
> values start from each chromosome (not necessaryly same value).  That means
> that x axes will have label (tick) for chromosome 1, within chromosome 1
> there are physical location from whatever value to the largest physical
> location value for chromosome 1, then chromosome 2 label, within chromosome
> 2 label physical location increase from whatever value to the largest
> physical location value for chromosome 2...... till chromosome 23.  
>  
> Is it possible to draw this type of plot in R? and How to draw it?
>  
> Thanks in advance
>  
> Aiguo Li, Ph.D.
> Bioinformatician & Molecular biologist
> NCI/NIH
>  
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From dimitris.rizopoulos at med.kuleuven.ac.be  Wed Mar  2 15:23:46 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Wed, 2 Mar 2005 15:23:46 +0100
Subject: [R] Differences between package and library terminology
References: <1109770953.6175.34.camel@ndmpc126.orc.ox.ac.uk>
Message-ID: <003101c51f33$7205e7f0$0540210a@www.domain>

look at this message

http://tolstoy.newcastle.edu.au/R/devel/05/02/2148.html

and the thread it comes from for more info.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Adaikalavan Ramasamy" <ramasamy at cancer.org.uk>
To: "R-help" <r-help at stat.math.ethz.ch>
Sent: Wednesday, March 02, 2005 2:42 PM
Subject: [R] Differences between package and library terminology


> Just out of curiosity, what is the difference between the terms for
> package and library ?  Why are we loading a package with the 
> library()
> command ?
>
> If this is a case of RTFM, I would be happy to do so if pointed in 
> the
> right direction. I have searched the FAQ and mail archives and only 
> came
> up with http://tolstoy.newcastle.edu.au/R/help/05/02/12162.html but 
> this
> still does not explain what is the requirement/features of a package 
> vs.
> library.
>
> Does this question not qualify to be included in the FAQs.
>
> Thank you
>
> Regards, Adai
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From murdoch at stats.uwo.ca  Wed Mar  2 15:27:28 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 02 Mar 2005 14:27:28 +0000
Subject: [R] return from nested function?
In-Reply-To: <20050302121317.GA1498@jtkpc.cmp.uea.ac.uk>
References: <20050225203420.F1681AEA30@mail.rsma.frb.gov>
	<6eb05719add6861cc72c25a41f432622@fhcrc.org>
	<20050302121317.GA1498@jtkpc.cmp.uea.ac.uk>
Message-ID: <srib219i8k8sok18i1bvavr1erklmtskdl@4ax.com>

On Wed, 2 Mar 2005 12:13:17 +0000, "Jan T. Kim" <jtk at cmp.uea.ac.uk>
wrote :

>On Tue, Mar 01, 2005 at 11:21:44PM -0800, Seth Falcon wrote:
>> On Feb 25, 2005, at 12:34 PM, jhallman at frb.gov wrote:
>> 
>> >Is is possible from within a function to cause its caller to return()?
>> 
>> This snippet may be of interest:
>> 
>> 
>> > f = function(x) {
>> + print("f")
>> + g(return())
>> + print("end of f")
>> + }
>> 
>> > g=function(x) {print("g")
>> + x
>> + print("end of g")
>> + }
>> 
>> > f(1)
>> [1] "f"
>> [1] "g"
>> NULL
>
>I may be dumb today, but doesn't that beg the question of how does g
>cause f not to return?

I'm not suggesting that I would ever use code like this, but if x is
never evaluated then the double return would not happen:

> f
function(x) {
print("f")
g(x, return())
print("end of f")
}
> g
function(x, blastoff) {
   print("g")
   if (x) blastoff
   print("end of g")
}
> f(TRUE)
[1] "f"
[1] "g"
NULL
> f(FALSE)
[1] "f"
[1] "g"
[1] "end of g"
[1] "end of f"

However, this is not a style of programming that I would expect to
last for more than 5 minutes after I published a program using it.
Follow Thomas's advice, and use tryCatch instead.

Duncan Murdoch



From MSchwartz at MedAnalytics.com  Wed Mar  2 15:30:53 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed, 02 Mar 2005 08:30:53 -0600
Subject: [R] orientation of eps files
In-Reply-To: <20050302134429.GA22030@adelie>
References: <20050302134429.GA22030@adelie>
Message-ID: <1109773853.11573.54.camel@horizons.localdomain>

On Wed, 2005-03-02 at 15:44 +0200, Andrew Collier wrote:
> hello,
> 
> i have a problem with the orientation of eps files produced with the
> postscript() command. i have generated some eps files with R using:
> 
> postscript(file = filename, horizontal = FALSE, paper = "special",
> onefile = F
> ALSE, height = height, width = width, pointsize = pointsize)
> 
> now, when i include these eps files into a standard paper document
> (ie. a4 paper, portrait orientation) everything is fine.
> 
> however, i am now wanting to incorporate the same images into a
> presentation. i am making a pdf file, which for presentation purposes
> is in landscape orientation. i am using latex with the prosper
> package. images are included with \includegraphics{} and a pdf file is
> generated with dvipdf. however, in this case, when i include the eps
> figures the whole page suddenly gets rotated around into portrait. eps
> files from other packages seem to work fine.
> 
> there is an example of the problem at
> ftp://chinstrap.nu.ac.za/orientation.pdf.
> 
> if you have any ideas as to what might be causing this problem, i
> would be extremely happy to hear them.


My recollection is that it is impacted upon by your setting of the
height and width arguments.

I have used the seminar package for creating slides with embedded EPS
files from R. Using the standard U.S. "letter" size paper, I have:

   postscript(..., width = 9.5, height = 7.5, ...)

This leaves 1 inch margins on the right and left sides of the page and
half inch margins on the top and bottom.

I don't recall the specifics, but if I went much larger than the above
settings, the landscape page would get rotated to portrait.

In the LaTeX code, I then have:

\begin{slide}
  \begin{center}
    \includegraphics[width=0.9\textwidth]{FileName.eps}
  \end{center}
\end{slide}

The above seems to work in the seminar package and I believe that
prosper is built upon the former. Note the 'width' setting.

You will likely need to make comparable adjustments using the 'a4' page
size in order to maintain a landscape orientation.

HTH,

Marc Schwartz



From ligges at statistik.uni-dortmund.de  Wed Mar  2 15:47:46 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 02 Mar 2005 15:47:46 +0100
Subject: [R] Differences between package and library terminology
In-Reply-To: <1109770953.6175.34.camel@ndmpc126.orc.ox.ac.uk>
References: <1109770953.6175.34.camel@ndmpc126.orc.ox.ac.uk>
Message-ID: <4225D212.6020000@statistik.uni-dortmund.de>

Adaikalavan Ramasamy wrote:

> Just out of curiosity, what is the difference between the terms for
> package and library ?  Why are we loading a package with the library()
> command ?
> 
> If this is a case of RTFM, I would be happy to do so if pointed in the
> right direction. I have searched the FAQ and mail archives and only came
> up with http://tolstoy.newcastle.edu.au/R/help/05/02/12162.html but this
> still does not explain what is the requirement/features of a package vs.
> library.
> 
> Does this question not qualify to be included in the FAQs.
> 
> Thank you
> 
> Regards, Adai
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

It is answered in the FAQs (FAQ 5.2)!
Also, e.g., in the manual "R Installation and Administration" and in R 
News 3(3), pp. 37-39: "R Help Desk: Package Management".

You use library() to load a package from a *library* containing *packages*.

Uwe Ligges



From rpeng at jhsph.edu  Wed Mar  2 16:07:06 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 02 Mar 2005 10:07:06 -0500
Subject: [R] orientation of eps files
In-Reply-To: <20050302134429.GA22030@adelie>
References: <20050302134429.GA22030@adelie>
Message-ID: <4225D69A.3010709@jhsph.edu>

This is ghostscript feature, I believe.  See here:

https://www.stat.math.ethz.ch/pipermail/r-devel/2003-October/027759.html

I usually do

setenv GS_OPTIONS "-dAutoRotatePages=/None"

in tcsh.

-roger

Andrew Collier wrote:
> hello,
> 
> i have a problem with the orientation of eps files produced with the postscript() command. i have generated some eps files with R using:
> 
> postscript(file = filename, horizontal = FALSE, paper = "special", onefile = F
> ALSE, height = height, width = width, pointsize = pointsize)
> 
> now, when i include these eps files into a standard paper document (ie. a4 paper, portrait orientation) everything is fine.
> 
> however, i am now wanting to incorporate the same images into a presentation. i am making a pdf file, which for presentation purposes is in landscape orientation. i am using latex with the prosper package. images are included with \includegraphics{} and a pdf file is generated with dvipdf. however, in this case, when i include the eps figures the whole page suddenly gets rotated around into portrait. eps files from other packages seem to work fine.
> 
> there is an example of the problem at ftp://chinstrap.nu.ac.za/orientation.pdf.
> 
> if you have any ideas as to what might be causing this problem, i would be extremely happy to hear them.
> 
> best regards,
> andrew.
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/



From ramasamy at cancer.org.uk  Wed Mar  2 16:10:44 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 02 Mar 2005 15:10:44 +0000
Subject: [R] Differences between package and library terminology
In-Reply-To: <1109773245.11573.44.camel@horizons.localdomain>
References: <1109770953.6175.34.camel@ndmpc126.orc.ox.ac.uk>
	<1109773245.11573.44.camel@horizons.localdomain>
Message-ID: <1109776245.6175.73.camel@ndmpc126.orc.ox.ac.uk>

Thank you to Marc Schwartz, Dimitris Rizopoulos and Uwe Ligges.

The discussions in R-devel thread was helpful. I think it is the usage
library(package) that confuses new users to confuse the term packages
with libraries.

Thank you.

Regards, Adai



On Wed, 2005-03-02 at 08:20 -0600, Marc Schwartz wrote:
> On Wed, 2005-03-02 at 13:42 +0000, Adaikalavan Ramasamy wrote:
> > Just out of curiosity, what is the difference between the terms for
> > package and library ?  Why are we loading a package with the library()
> > command ?
> > 
> > If this is a case of RTFM, I would be happy to do so if pointed in the
> > right direction. I have searched the FAQ and mail archives and only came
> > up with http://tolstoy.newcastle.edu.au/R/help/05/02/12162.html but this
> > still does not explain what is the requirement/features of a package vs.
> > library.
> > 
> > Does this question not qualify to be included in the FAQs.
> > 
> > Thank you
> > 
> > Regards, Adai
> 
> 
> There was actually just an exchange on this last month, which was
> precipitated by a thread on r-help and then moved to r-devel. The r-
> devel part, which is more relevant here, begins at:
> 
> https://stat.ethz.ch/pipermail/r-devel/2005-February/032095.html
> 
> HTH,
> 
> Marc Schwartz
> 
> 
>



From sfalcon at fhcrc.org  Wed Mar  2 16:14:09 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 2 Mar 2005 07:14:09 -0800
Subject: [R] return from nested function?
In-Reply-To: <20050302121317.GA1498@jtkpc.cmp.uea.ac.uk>
References: <20050225203420.F1681AEA30@mail.rsma.frb.gov>
	<6eb05719add6861cc72c25a41f432622@fhcrc.org>
	<20050302121317.GA1498@jtkpc.cmp.uea.ac.uk>
Message-ID: <03ca366bf25682077df14532745c3ce3@fhcrc.org>


On Mar 2, 2005, at 4:13 AM, Jan T. Kim wrote:
>
> I may be dumb today, but doesn't that beg the question of how does g
> cause f not to return?

No, I think my post doesn't really help you.  In the context of a 
recursive function, the code I posted provides a way to jump out of the 
recursion which is a cousin of what you are looking for.

I wonder if try or tryCatch might be what you want?

cheers,

+ seth



From sanobast-r01 at yahoo.de  Wed Mar  2 16:17:04 2005
From: sanobast-r01 at yahoo.de (Thomas)
Date: Wed, 02 Mar 2005 16:17:04 +0100
Subject: [R] barchart error (invalid line type) maybe caused by mangled
	data   frame, & fix() resolving the problem
In-Reply-To: <d041lm$lj0$1@sea.gmane.org>
References: <d041lm$lj0$1@sea.gmane.org>
Message-ID: <d04l5v$ksj$1@sea.gmane.org>

>> b$month <- substring(bb$all$month, 3)
>> b$year <- substring(bb$all$month, 1, 2)

Ah well, I have to make it a factor. Thank you.

Regards,
Thomas.



From f.harrell at vanderbilt.edu  Wed Mar  2 16:28:07 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Wed, 02 Mar 2005 09:28:07 -0600
Subject: [R] subset selection for logistic regression
In-Reply-To: <20050302141742.JUWH3971.aamta07-winn.mailhost.ntl.com@c400>
References: <20050302141742.JUWH3971.aamta07-winn.mailhost.ntl.com@c400>
Message-ID: <4225DB87.8000405@vanderbilt.edu>

dr mike wrote:
>  
> 
> 
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch 
>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Wittner, Ben
>>Sent: 02 March 2005 11:33
>>To: r-help at lists.R-project.org
>>Subject: [R] subset selection for logistic regression
>>
>>R-packages leaps and subselect implement various methods of 
>>selecting best or good subsets of predictor variables for 
>>linear regression models, but they do not seem to be 
>>applicable to logistic regression models.
>> 
>>Does anyone know of software for finding good subsets of 
>>predictor variables for linear regression models?
>> 
>>Thanks.
>> 
>>-Ben
>> 
>>p.s., The leaps package references "Subset Selection in 
>>Regression" by Alan Miller. On page 2 of the 2nd edition of 
>>that text it states the following:
>> 
>>  "All of the models which will be considered in this 
>>monograph will be linear; that is they
>>   will be linear in the regression coefficients.Though most 
>>of the ideas and problems carry
>>   over to the fitting of nonlinear models and generalized 
>>linear models (particularly the fitting
>>   of logistic relationships), the complexity is greatly increased."
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
> 
> 
> The LASSO method and the Least Angle Regression method are two such that
> have both been implemented (efficiently IMHO - only one least squares for
> all levels of shrinkage IIRC) in the lars package for R of Hastie and Efron.
> There is a paper by Madigan and Ridgeway that discusses the use of the Least
> Angle Regresson approach in the context of logistic regression - available
> for download from Madigan's space at Ruttgers: 
> www.stat.rutgers.edu/~madigan/PAPERS/lars3.pdf 
> 
> HTH
> 
> Mike
Yes things like lasso can help a lot.
-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From MBock at arcadis-us.com  Wed Mar  2 16:29:52 2005
From: MBock at arcadis-us.com (Bock, Michael)
Date: Wed, 2 Mar 2005 08:29:52 -0700
Subject: [R] Text in lattice Graphics outside plot area
Message-ID: <0016F5677B1F1D4281EEBC034993595102658E7A@CORPEXBE1.arcadis-us.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050302/449f4da0/attachment.pl

From gunter.berton at gene.com  Wed Mar  2 16:53:06 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 2 Mar 2005 07:53:06 -0800
Subject: [R] subset selection for logistic regression
In-Reply-To: <4225BBCF.4090706@vanderbilt.edu>
Message-ID: <200503021553.j22Fr6l7012411@meitner.gene.com>

To clarify Frank's remark ...

A prominent theme in statistical research over at least the last 25 years
(with roots that go back 50 or more, probably) has been the superiority of
"shrinkage" methods over variable selection. I also find it distressing that
these ideas have apparently not penetrated much (at all?) into the wider
scientific community (but I suppose I shouldn't be surprised -- most
scientists still do one factor at a time experiments 80 years after Fisher).
Specific incarnations can be found in anything Bayesian, mixed effects
models for repeated measures, ridge regression, and the R packages lars and
lasso, among others.

I would speculate that aside from the usual statistics/science cultural
issues, part of the reason for this is that the estimators don't generally
come with neat, classical inference procedures: like it or not, many
scientists have been conditioned by their Stat 101 courses to expect P
values, so in some sense, we are hoisted by our own petard.

Just my $.02 -- contrary(and more knowledgeable) opinions welcome.

-- Bert Gunter
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Frank 
> E Harrell Jr
> Sent: Wednesday, March 02, 2005 5:13 AM
> To: Wittner, Ben
> Cc: r-help at lists.R-project.org
> Subject: Re: [R] subset selection for logistic regression
> 
> Wittner, Ben wrote:
> > R-packages leaps and subselect implement various methods of 
> selecting best or
> > good subsets of predictor variables for linear regression 
> models, but they do
> > not seem to be applicable to logistic regression models.
> >  
> > Does anyone know of software for finding good subsets of 
> predictor variables for
> > linear regression models?
> >  
> > Thanks.
> >  
> > -Ben
> 
> Why are these procedures still being used?  The performance 
> is known to 
> be bad in almost every sense (see r-help archives).
> 
> Frank Harrell
> 
> >  
> > p.s., The leaps package references "Subset Selection in 
> Regression" by Alan
> > Miller. On page 2 of the
> > 2nd edition of that text it states the following:
> >  
> >   "All of the models which will be considered in this 
> monograph will be linear;
> > that is they
> >    will be linear in the regression coefficients.Though 
> most of the ideas and
> > problems carry
> >    over to the fitting of nonlinear models and generalized 
> linear models
> > (particularly the fitting
> >    of logistic relationships), the complexity is greatly increased."
> 
> 
> -- 
> Frank E Harrell Jr   Professor and Chair           School of Medicine
>                       Department of Biostatistics   
> Vanderbilt University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From LyleK at utk.edu  Wed Mar  2 19:58:23 2005
From: LyleK at utk.edu (Lyle W. Konigsberg)
Date: Wed, 02 Mar 2005 10:58:23 -0800
Subject: [R] Warning: number of items to replace is not a multiple of
	replacement length
Message-ID: <6.2.0.14.0.20050302105212.01ce1530@pop.utk.edu>

I feel like a complete dolt, as I know this question has been asked by 
others on a fairly regular basis, but I'm going in circles trying to get 
the following to work:

id.prob<-function (tt)
{
library(mvtnorm)
#============================
Makeham<-function(tt)
{
a2=0.030386513
a3=0.006688287
b3=0.039047537
t<-tt-20
h.t<-a2+a3*exp(b3*t)
S.t<-exp(-a2*t+a3/b3*(1-exp(b3*t)))
return(S.t*h.t)
}
#===========================
trans<-function (age)
{
indic=c(2,2)
lage=log(age)
xpars=c(2.1862908,7.5528077,8.5806697,2.3319461,8.8959507,9.1380187,0.3720293)
beta<-c(0,0)
alpha1<-c(0,0)
alpha2<-c(0,0)
beta[1]<-xpars[1]
alpha1[1]<-xpars[2]
alpha2[1]<-xpars[3]
beta[2]<-xpars[4]
alpha1[2]<-xpars[5]
alpha2[2]<-xpars[6]
corr<-matrix(rep(0,4),nc=2)
corr[1,1]=1
corr[2,2]=1
corr[1,2]=xpars[7]
corr[2,1]=corr[1,2]

LLK<-0
L<-c(0,0)
R<-c(0,0)

for(j in 1:2){
   if(indic[j]==1){
     L[j]<--Inf
     R[j]<-alpha1[j]-beta[j]*lage}
   if(indic[j]==2){
     L[j]<-alpha1[j]-beta[j]*lage
     R[j]<-alpha2[j]-beta[j]*lage}
   if(indic[j]==3){
     L[j]<-alpha2[j]-beta[j]*lage
     R[j]<-Inf}
}

   LLK<-pmvnorm(lower=L,upper=R,corr=corr)[1]

return(LLK)
}

#===========================

tot<-Makeham(tt)*trans(tt)
return(tot)
}


And then:

 > id.prob(20)
[1] 0.0001417763
 > id.prob(21)
[1] 0.00018078
 > id.prob(20:21)
[1] 0.0001417763 0.0001375794
Warning messages:
1: number of items to replace is not a multiple of replacement length
2: number of items to replace is not a multiple of replacement length
3: number of items to replace is not a multiple of replacement length
4: number of items to replace is not a multiple of replacement length

Ultimately I need to be able to integrate this function, which isn't going 
to happen (correctly) if I've messed-up writing the function.  Thanks for 
any advice on this.

Regards,
Lyle W. Konigsberg
Professor of Anthropology
University of Tennessee
Knoxville, TN
LyleK at utk.edu



From ligges at statistik.uni-dortmund.de  Wed Mar  2 17:22:25 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 02 Mar 2005 17:22:25 +0100
Subject: [R] Problems with the "tseries" package
In-Reply-To: <17BE0E8C19D93E448FED29112825876A915C6E@VEXCHA0005.san.corp>
References: <17BE0E8C19D93E448FED29112825876A915C6E@VEXCHA0005.san.corp>
Message-ID: <4225E841.4010601@statistik.uni-dortmund.de>

MARTIN CALMARZA AGUSTIN wrote:

> Dear Sirs,
> I am trying to perform a garch analysis to some data time series.Therefore, I've downloaded the package "tseries", as the garch analysis is not available in the main R  program.When I try to load the "tseries package" from the R-Console screen, the following message appears:
> 
> local({pkg <- select.list(sort(.packages(all.available = TRUE)))
> + if(nchar(pkg)) library(pkg, character.only=TRUE)})
> Loading required package: quadprog 
> Error: package 'quadprog' could not be loaded
> In addition: Warning message: 
> There is no package called 'quadprog' in: library(pkg, character.only = TRUE, logical = TRUE, lib.loc = lib.loc) 

Do you have quadprog installed?

Uwe Ligges



> It seems that the program detects a failure in a package called "quadprog", which I can't find (while I am trying to select the "tseries" package). As a consequence I cannot use the "garch" command.Could you lend me a helping hand on this issue?.
> 
> Thanks very much.Best regards,
> Agust?n Mart?n
> 
> 
> ******************AVISO LEGAL**********************
> 
> Este mensaje es privado y confidencial y solamente para la persona a ..........
> 
> **********************DISCLAIMER*****************
> This message is private and confidential and it is intended ...........
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Wed Mar  2 17:30:44 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 02 Mar 2005 17:30:44 +0100
Subject: [R] Two problems building a package
In-Reply-To: <A16C769D4A7E564597075EA02A91C003047E87E1@neexchange01.nemc.org>
References: <A16C769D4A7E564597075EA02A91C003047E87E1@neexchange01.nemc.org>
Message-ID: <4225EA34.4040701@statistik.uni-dortmund.de>

Wollenberg, Kurt R wrote:

> Hello all:
> 
> I have written a few R scripts and am trying to turn them into a package for
> submission to CRAN. All of these scripts are R code only, no C or C++ or
> anything else. I'm working with R 2.0.1 running on a Windows XP machine. So
> far running ">rcmd install --build --docs=normal mypkge" seems to work
> (i.e., the library "mypkge" is installed in R\rw2001\library and the library
> loads and the scripts do what I have written them to do). 

You are talking about your *package* and your *functions*, I think.


> While this is all well and good I have two (hopefully small) problems.
> First, running ">rcmd check mypkge" on R\rw2001\bin\mypkg (

Does not need to be in ...../bin


> not
> R\rw2001\library\mtpkge) returns the error "\bin\mypkge is not a source
> package." 

So your source package is broken somehow. Please check the DESCRIPTION file.


> Have I got something very wrong or am I misunderstanding which
> directory contains the "source" package? Second, I've included some
> equations in the Details section of one of my .Rd files and would like to
> check that I've coded them correctly in the documentation before submission.
> So far, my html and latex docs don't contain a details section, even though
> they contain all other recent changes. My detail section looks like this:
> 
> \details{blah blah blah 
>     \deqn{blah = Blah}{%
>       blah = Blah}
> where 	\eqn{blah}{%blah} = frequency of \emph{b} in Blah.


The "%" above seem to be dangerous (without having tested) ...

Uwe Ligges

>   Blah blah blah.
> }
> 
> Any help would be greatly appreciated.
> 
> Cheers,
> Kurt Wollenberg, PhD
> Tufts Center for Vision Research 
> New England Medical Center
> 750 Washington St, Box 450 
> Boston, MA, USA
> kwollenberg at tufts-nemc.org 
> 617-636-8945 (Fax)
> 617-636-9028 (Lab)
> 
> The most exciting phrase to hear in science, the one that heralds new
> discoveries, is not "Eureka!" (I found it!) but  "That's funny ..." 
> --Isaac Asimov
> 
> 
> ********************** 
> Confidentiality Notice\ **********************\      The inf...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From spencer.graves at pdf.com  Wed Mar  2 17:32:02 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 02 Mar 2005 08:32:02 -0800
Subject: [R] Leaps & regsubsets
In-Reply-To: <2395774549BBDA40AC83BC9E6223FBFF22F8B4@MS-DT01VS01.tsn.tno.nl>
References: <2395774549BBDA40AC83BC9E6223FBFF22F8B4@MS-DT01VS01.tsn.tno.nl>
Message-ID: <4225EA82.2050803@pdf.com>

      I can't help you answer your specific question, but after you 
figure it out, would you please rerun the analysis, say, 1,000 times 
after randomly permuting your response variable each time (or bootstrap 
sampling therefrom).  I would be interested in your comparison of your 
actual results with the Monte Carlo / bootstrap. 

      spencer graves

Smit, Robin wrote:

>Hello
> 
>I am trying to use all subsets regression on a test dataset consisting
>of 11 trails and 46 potential predictor variables. 
>I would like to use Mallow's Cp as a selection criterion. 
>The leaps function would provide the required output but does not work
>with this many variables (see below).
>The alternative function regsubsets should be used, but I am not able to
>define the function in such a way that is gives satisfactory results.
> 
>
>library(leaps)
>
>data <- read.table('C:/test_plot_sum2.txt', header = TRUE)
>
>attach(data)
>
>nox <- data[,1]
>
>cnt <- data[,2]
>
>vars <- data[,3:48]
>
> 
>
>leaps.setup(x = vars, y = nox, wt = cnt, nvmax = 1)
>
>leaps(x = vars, y = nox, wt = cnt, method = "Cp", nbest = 2, names =
>names(vars))
>
> 
>
>Error in leaps(x = vars, y = nox, wt = cnt, method = "Cp", nbest = 2,  :
>
>
>        leaps does not allow more than 31 variables; use regsubsets()
>
> 
>
>regsubsets(x = vars, y = nox, weights = cnt, method = "seqrep", nbest =
>1, names = names(vars), nvmax = 3)
>
> 
>
>1 subsets of each size up to 4
>
>Selection Algorithm: 'sequential replacement'
>
>Warning message: 
>
>37  linear dependencies found in: leaps.setup(x, y, wt = weights, nbest
>= nbest, nvmax = nvmax,  
>
> 
>Is there someone who could shine a few rays of light on this?
>Many thanks for your assistance.
> 
>Kind regards,
>Robin Smit
>
>This e-mail and its contents are subject to the DISCLAIMER at http://www.tno.nl/disclaimer/email.html
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From deepayan at stat.wisc.edu  Wed Mar  2 17:56:15 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 2 Mar 2005 10:56:15 -0600
Subject: [R] Text in lattice Graphics outside plot area
In-Reply-To: <0016F5677B1F1D4281EEBC034993595102658E7A@CORPEXBE1.arcadis-us.com>
References: <0016F5677B1F1D4281EEBC034993595102658E7A@CORPEXBE1.arcadis-us.com>
Message-ID: <200503021056.15432.deepayan@stat.wisc.edu>

On Wednesday 02 March 2005 09:29, Bock, Michael wrote:
> I am trying to get the same text printed on each page of a multi-page
> series of bar charts. The text need to appear in the upper left-hand
> corner of the page, outside of the plot area. A watermark might be
> the closest analogy to what I am after
>
> This is what I have so far:
>
> PData <- na.omit(subset(TData,Matrix == "Product"))
> barchart(AdjResND0 ~ reorder(Compound, Sort) | Label , PData,
>    box.ratio = 0.8, ylab= ("Concentration (mg/kg)"),
>    layout = c(0,1), scales = list(x="free",y="free",rot=90,cex = 0.4,
>    axs = "i"  ), panel=function(x,y,...) {
>         panel.barchart(x,y,...)
>         grid.text(label = "Privileged and Confidential \nDRAFT",
>         x = unit(0.01, "npc"), y = unit(0.95, "npc"))})
>
>
> This plot a bar chart for each sample, with label representing the
> sample ID. I love getting 30 plots with a small among of code! The
> problem with this is that the text appears inside the plot area, I
> need it outside in the corner of the page.
>
> I think I am close, perhaps if I have the text be in the primary
> panel which would be taking up the whole page with the bar chart
> inside in a sub panel? An example would be great as I have tried a
> number of things and I either get errors or "curious" looking plots.
> The option of last resort would be to explicitly plot each sample and
> add the text to each plot, but this does not take advantage of the
> multi-plot capabilities of lattice graphics.

If I'm not mistaken, you want (conceptually) a label for every page, not 
every panel (in your case you have one panel per page, so the 
distinction is not as obvious). The correct way to do this would be 
through the 'page' argument, not the panel function. e.g., 


barchart(variety ~ yield | site, data = barley, 
         groups = year, layout = c(3,1), 
         page = function(n) {
             grid.text(label = "Privileged and Confidential \nDRAFT",
                       x = unit(0.01, "npc"), y = unit(0.95, "npc"),
                       just = c("left", "center"))
         })

HTH,

Deepayan



From ripley at stats.ox.ac.uk  Wed Mar  2 18:02:04 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 2 Mar 2005 17:02:04 +0000 (GMT)
Subject: [R] orientation of eps files
In-Reply-To: <4225D69A.3010709@jhsph.edu>
References: <20050302134429.GA22030@adelie> <4225D69A.3010709@jhsph.edu>
Message-ID: <Pine.LNX.4.61.0503021657390.29121@gannet.stats>

Yes, and it happens because by default R's plots have rotated text on the 
y axis, and it is this that tends to trigger auto-rotation.

The answer is in

https://www.stat.math.ethz.ch/pipermail/r-devel/2003-October/027766.html

various other items in the thread being off the point.

On Wed, 2 Mar 2005, Roger D. Peng wrote:

> This is ghostscript feature, I believe.  See here:
>
> https://www.stat.math.ethz.ch/pipermail/r-devel/2003-October/027759.html
>
> I usually do
>
> setenv GS_OPTIONS "-dAutoRotatePages=/None"
>
> in tcsh.
>
> -roger
>
> Andrew Collier wrote:
>> hello,
>> 
>> i have a problem with the orientation of eps files produced with the 
>> postscript() command. i have generated some eps files with R using:
>> 
>> postscript(file = filename, horizontal = FALSE, paper = "special", onefile 
>> = F
>> ALSE, height = height, width = width, pointsize = pointsize)
>> 
>> now, when i include these eps files into a standard paper document (ie. a4 
>> paper, portrait orientation) everything is fine.
>> 
>> however, i am now wanting to incorporate the same images into a 
>> presentation. i am making a pdf file, which for presentation purposes is in 
>> landscape orientation. i am using latex with the prosper package. images 
>> are included with \includegraphics{} and a pdf file is generated with 
>> dvipdf. however, in this case, when i include the eps figures the whole 
>> page suddenly gets rotated around into portrait. eps files from other 
>> packages seem to work fine.
>> 
>> there is an example of the problem at 
>> ftp://chinstrap.nu.ac.za/orientation.pdf.
>> 
>> if you have any ideas as to what might be causing this problem, i would be 
>> extremely happy to hear them.
>> 
>> best regards,
>> andrew.
>> 
>
> -- 
> Roger D. Peng
> http://www.biostat.jhsph.edu/~rpeng/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Wed Mar  2 18:03:46 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 02 Mar 2005 18:03:46 +0100
Subject: [R] Warning: number of items to replace is not a multiple of
	replacement length
In-Reply-To: <6.2.0.14.0.20050302105212.01ce1530@pop.utk.edu>
References: <6.2.0.14.0.20050302105212.01ce1530@pop.utk.edu>
Message-ID: <4225F1F2.50706@statistik.uni-dortmund.de>

Lyle W. Konigsberg wrote:

> I feel like a complete dolt, as I know this question has been asked by 
> others on a fairly regular basis, but I'm going in circles trying to get 
> the following to work:
> 
> id.prob<-function (tt)
> {
> library(mvtnorm)
> #============================
> Makeham<-function(tt)
> {
> a2=0.030386513
> a3=0.006688287
> b3=0.039047537
> t<-tt-20
> h.t<-a2+a3*exp(b3*t)
> S.t<-exp(-a2*t+a3/b3*(1-exp(b3*t)))
> return(S.t*h.t)
> }
> #===========================
> trans<-function (age)
> {
> indic=c(2,2)
> lage=log(age)
> xpars=c(2.1862908,7.5528077,8.5806697,2.3319461,8.8959507,9.1380187,0.3720293) 
> 
> beta<-c(0,0)
> alpha1<-c(0,0)
> alpha2<-c(0,0)
> beta[1]<-xpars[1]
> alpha1[1]<-xpars[2]
> alpha2[1]<-xpars[3]
> beta[2]<-xpars[4]
> alpha1[2]<-xpars[5]
> alpha2[2]<-xpars[6]
> corr<-matrix(rep(0,4),nc=2)
> corr[1,1]=1
> corr[2,2]=1
> corr[1,2]=xpars[7]
> corr[2,1]=corr[1,2]
> 
> LLK<-0
> L<-c(0,0)
> R<-c(0,0)
> 
> for(j in 1:2){
>   if(indic[j]==1){
>     L[j]<--Inf
>     R[j]<-alpha1[j]-beta[j]*lage}
>   if(indic[j]==2){
>     L[j]<-alpha1[j]-beta[j]*lage
>     R[j]<-alpha2[j]-beta[j]*lage}
>   if(indic[j]==3){
>     L[j]<-alpha2[j]-beta[j]*lage
>     R[j]<-Inf}
> }
> 
>   LLK<-pmvnorm(lower=L,upper=R,corr=corr)[1]
> 
> return(LLK)
> }
> 
> #===========================
> 
> tot<-Makeham(tt)*trans(tt)
> return(tot)
> }
> 
> 
> And then:
> 
>  > id.prob(20)
> [1] 0.0001417763
>  > id.prob(21)
> [1] 0.00018078
>  > id.prob(20:21)
> [1] 0.0001417763 0.0001375794
> Warning messages:
> 1: number of items to replace is not a multiple of replacement length
> 2: number of items to replace is not a multiple of replacement length
> 3: number of items to replace is not a multiple of replacement length
> 4: number of items to replace is not a multiple of replacement length


Please read some introductory literature regarding the S / R language!
Your code is not vectorizable at all.


In
   tot <- Makeham(tt)*trans(tt)

Makeham has length 2 and works (I guess), but in  trans(tt) you have

   lage=log(age)

which has length 2, but you get also length 2 in

   R[j]<-alpha1[j]-beta[j]*lage}

but assign it to a scalar value.



> Ultimately I need to be able to integrate this function, which isn't 
> going to happen (correctly) if I've messed-up writing the function.  
> Thanks for any advice on this.
> 
> Regards,
> Lyle W. Konigsberg
> Professor of Anthropology
> University of Tennessee
> Knoxville, TN
> LyleK at utk.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From fm3a004 at math.uni-hamburg.de  Wed Mar  2 18:10:46 2005
From: fm3a004 at math.uni-hamburg.de (Christian Hennig)
Date: Wed, 2 Mar 2005 18:10:46 +0100 (MET)
Subject: [R] subset selection for logistic regression
In-Reply-To: <200503021553.j22Fr6l7012411@meitner.gene.com>
Message-ID: <Pine.GSO.3.95q.1050302175848.19444E-100000@sun11.math.uni-hamburg.de>

Perhaps I should not write it because I will discredit myself with this
but...

Suppose I have a setup with 100 variables and some 1000 cases and I want to
boil down the number of variables to a maximum of 10 for practical reasons
even if I lose 10% prediction quality by this (for example because it is
expensive to measure all variables on new cases).  

Is it really so wrong to use a stepwise method?
Let's say I divide the sample into three parts and do variable selction on
the first part, estimation on the second and test on the third part (this
solves almost all problems Frank is talking about on p. 56/57 in his
excellent book). Is there always a tractable alternative? 

Of course it is wrong to interpret the selected variables as "the true
influences" and all others as "unrelated", but if I don't do that?

If it should really be a taboo to do stepwise variable selection, why are p.
58/59 of "Regression Modeling Strategies" devoted to "how to do it of you
must"?

Please forget my name;-)

Christian

On Wed, 2 Mar 2005, Berton Gunter wrote:

> To clarify Frank's remark ...
> 
> A prominent theme in statistical research over at least the last 25 years
> (with roots that go back 50 or more, probably) has been the superiority of
> "shrinkage" methods over variable selection. I also find it distressing that
> these ideas have apparently not penetrated much (at all?) into the wider
> scientific community (but I suppose I shouldn't be surprised -- most
> scientists still do one factor at a time experiments 80 years after Fisher).
> Specific incarnations can be found in anything Bayesian, mixed effects
> models for repeated measures, ridge regression, and the R packages lars and
> lasso, among others.
> 
> I would speculate that aside from the usual statistics/science cultural
> issues, part of the reason for this is that the estimators don't generally
> come with neat, classical inference procedures: like it or not, many
> scientists have been conditioned by their Stat 101 courses to expect P
> values, so in some sense, we are hoisted by our own petard.
> 
> Just my $.02 -- contrary(and more knowledgeable) opinions welcome.
> 
> -- Bert Gunter
>  
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Frank 
> > E Harrell Jr
> > Sent: Wednesday, March 02, 2005 5:13 AM
> > To: Wittner, Ben
> > Cc: r-help at lists.R-project.org
> > Subject: Re: [R] subset selection for logistic regression
> > 
> > Wittner, Ben wrote:
> > > R-packages leaps and subselect implement various methods of 
> > selecting best or
> > > good subsets of predictor variables for linear regression 
> > models, but they do
> > > not seem to be applicable to logistic regression models.
> > >  
> > > Does anyone know of software for finding good subsets of 
> > predictor variables for
> > > linear regression models?
> > >  
> > > Thanks.
> > >  
> > > -Ben
> > 
> > Why are these procedures still being used?  The performance 
> > is known to 
> > be bad in almost every sense (see r-help archives).
> > 
> > Frank Harrell
> > 
> > >  
> > > p.s., The leaps package references "Subset Selection in 
> > Regression" by Alan
> > > Miller. On page 2 of the
> > > 2nd edition of that text it states the following:
> > >  
> > >   "All of the models which will be considered in this 
> > monograph will be linear;
> > > that is they
> > >    will be linear in the regression coefficients.Though 
> > most of the ideas and
> > > problems carry
> > >    over to the fitting of nonlinear models and generalized 
> > linear models
> > > (particularly the fitting
> > >    of logistic relationships), the complexity is greatly increased."
> > 
> > 
> > -- 
> > Frank E Harrell Jr   Professor and Chair           School of Medicine
> >                       Department of Biostatistics   
> > Vanderbilt University
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

***********************************************************************
Christian Hennig
Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
>From 1 April 2005: Department of Statistical Science, UCL, London
#######################################################################
ich empfehle www.boag-online.de



From marc.m.belisle at usherbrooke.ca  Wed Mar  2 18:16:12 2005
From: marc.m.belisle at usherbrooke.ca (Marc Belisle)
Date: Wed, 2 Mar 2005 12:16:12 -0500
Subject: [R] Applying a function to all combinations of factors
Message-ID: <APEJLJBDGGLPABONJPDMGENECMAA.marc.m.belisle@usherbrooke.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050302/0817420b/attachment.pl

From sue at xlsolutions-corp.com  Wed Mar  2 18:18:36 2005
From: sue at xlsolutions-corp.com (sue@xlsolutions-corp.com)
Date: Wed,  2 Mar 2005 10:18:36 -0700
Subject: [R] R/S course in New York city***April, 2005
Message-ID: <20050302171836.21415.qmail@webmail14.mesa1.secureserver.net>

XLSolutions Corporation (www.xlsolutions-corp.com) is proud to
announce  2-day "R/S-plus Fundamentals and Programming
Techniques" in New York: www.xlsolutions-corp.com/training.htm


****New York, NY ------------------------------------ April 14th -15th,
2005

Reserve your seat now at the early bird rates! Payment due AFTER
the class.

Course Description:

This two-day beginner to intermediate R/S-plus course focuses on a
broad spectrum of topics, from reading raw data to a comparison of R
and S. We will learn the essentials of data manipulation, graphical
visualization and R/S-plus programming. We will explore statistical
data analysis tools,including graphics with data sets. How to enhance
your plots. We will perform basic statistics and fit linear regression
models. Participants are encouraged to bring data for interactive
sessions


With the following outline:

- An Overview of R and S
- Data Manipulation and Graphics
- Using Lattice Graphics
- A Comparison of R and S-Plus
- How can R Complement SAS?
- Writing Functions
- Avoiding Loops
- Vectorization
- Statistical Modeling
- Project Management
- Techniques for Effective use of R and S
- Enhancing Plots
- Using High-level Plotting Functions
- Building and Distributing Packages (libraries)


Email us for group discounts.
Email Sue Turner: sue at xlsolutions-corp.com
Phone: 206-686-1578
Visit us: www.xlsolutions-corp.com/training.htm
Please let us know if you and your colleagues are interested in this
classto take advantage of group discount. Register now to secure your
seat!

 Interested in R/Splus Advanced course? email us.


Cheers,
Elvis Miller, PhD
Manager Training.
XLSolutions Corporation
206 686 1578
www.xlsolutions-corp.com
elvis at xlsolutions-corp.com



From vdetours at ulb.ac.be  Wed Mar  2 18:44:31 2005
From: vdetours at ulb.ac.be (Vincent Detours)
Date: Wed, 2 Mar 2005 18:44:31 +0100 (CET)
Subject: [R] data.frame, data types, and apply
Message-ID: <Pine.GSO.4.58.0503021801330.12047@maxi>

Dear all,

Here is an issue I often stumble on.

1- colunm types in data.frames.

-------------------------------
> d <- data.frame(x=as.character(c("a", "b", "c")), y=as.numeric(c(1, 2, 3)))
> d
  x y
1 a 1
2 b 2
3 c 3
> is.numeric(d[1,2])
[1] TRUE
> is.numeric(d[1,1])
[1] FALSE
> apply(d, c(1,2), is.numeric)
      x     y
1 FALSE FALSE
2 FALSE FALSE
3 FALSE FALSE
>
-------------------------------

All item in column "y" should be TRUE right? What should I do to apply
a function only to numerics in d? (beside using nested 'for' loops)

Thanks for your help, and for all the great software.


Vincent Detours



From ahenningsen at email.uni-kiel.de  Wed Mar  2 19:02:49 2005
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Wed, 2 Mar 2005 19:02:49 +0100
Subject: [R] orientation of eps files
In-Reply-To: <20050302134429.GA22030@adelie>
References: <20050302134429.GA22030@adelie>
Message-ID: <200503021902.49910.ahenningsen@email.uni-kiel.de>

I also had problems with the rotation of eps files in LaTeX presentations. 
Now, I produce eps files in R with postscript( ), 'distill' it with "ps2eps", 
make a pdf with "epstopdf", include it in my LaTeX file with \pgfimage{ },
use LaTeX class "beamer" (http://latex-beamer.sourceforge.net) and compile my 
presentation with pdflatex. This works great!

HTH,
Arne


On Wednesday 02 March 2005 14:44, Andrew Collier wrote:
> hello,
>
> i have a problem with the orientation of eps files produced with the
> postscript() command. i have generated some eps files with R using:
>
> postscript(file = filename, horizontal = FALSE, paper = "special", onefile
> = F ALSE, height = height, width = width, pointsize = pointsize)
>
> now, when i include these eps files into a standard paper document (ie. a4
> paper, portrait orientation) everything is fine.
>
> however, i am now wanting to incorporate the same images into a
> presentation. i am making a pdf file, which for presentation purposes is in
> landscape orientation. i am using latex with the prosper package. images
> are included with \includegraphics{} and a pdf file is generated with
> dvipdf. however, in this case, when i include the eps figures the whole
> page suddenly gets rotated around into portrait. eps files from other
> packages seem to work fine.
>
> there is an example of the problem at
> ftp://chinstrap.nu.ac.za/orientation.pdf.
>
> if you have any ideas as to what might be causing this problem, i would be
> extremely happy to hear them.
>
> best regards,
> andrew.

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From MSchwartz at MedAnalytics.com  Wed Mar  2 19:04:12 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed, 02 Mar 2005 12:04:12 -0600
Subject: [R] orientation of eps files
In-Reply-To: <Pine.LNX.4.61.0503021657390.29121@gannet.stats>
References: <20050302134429.GA22030@adelie> <4225D69A.3010709@jhsph.edu>
	<Pine.LNX.4.61.0503021657390.29121@gannet.stats>
Message-ID: <1109786652.32707.15.camel@horizons.localdomain>

On Wed, 2005-03-02 at 17:02 +0000, Prof Brian Ripley wrote:
> Yes, and it happens because by default R's plots have rotated text on the 
> y axis, and it is this that tends to trigger auto-rotation.
> 
> The answer is in
> 
> https://www.stat.math.ethz.ch/pipermail/r-devel/2003-October/027766.html
> 
> various other items in the thread being off the point.
> 
> On Wed, 2 Mar 2005, Roger D. Peng wrote:
> 
> > This is ghostscript feature, I believe.  See here:
> >
> > https://www.stat.math.ethz.ch/pipermail/r-devel/2003-October/027759.html
> >
> > I usually do
> >
> > setenv GS_OPTIONS "-dAutoRotatePages=/None"
> >
> > in tcsh.
> >
> > -roger


Thanks to both of you for that clarification on this. It is curious that
I was able to restrict this behavior seemingly by adjusting the size of
the plot and the margins on the slide page when this behavior occurred.
Presumably those changes masked this underlying issue.

As an FYI, for those using the bash shell (typical for many Linuxen),
the commands would be:

GS_OPTIONS="-dAutoRotatePages=/None"
export GS_OPTIONS

or they can be combined in a single command:

export GS_OPTIONS="-dAutoRotatePages=/None"

which can be placed in a shell script or in ~/.bash_profile, which makes
the change "global" for the login session.

Thanks,

Marc



From charshaw at presby.edu  Wed Mar  2 19:10:43 2005
From: charshaw at presby.edu (Clint Harshaw)
Date: Wed, 02 Mar 2005 13:10:43 -0500
Subject: [R] .ps and .pdf page size differences in FC vs. Debian
Message-ID: <422601A3.9050503@presby.edu>

R version: 2.0.0
OS: Fedora Core 1

When I'm using Fedora Core 1, Rplots.ps (and subsequent Rplots.pdf 
created after using ps2pdf Rplots.ps) which are created from the command 
line execution of R are too large to fit on a US Letter sized page when 
printed. The same code will produce a US letter sized page when I'm on 
my Debian Sid box. Both boxes are connected to the same shared printer, 
and both are configured in CUPS to use US Letter paper size. When I 
posted a question to the FC folks, the consensus was there was a 
configuration that needed to be done in R to set the proper page for 
graphics exported.

I've google'd for a solution and came up with a check for a locale 
variable in /etc/sysconfig/i18n to be set to the same as for the lang 
variable. I tried that, and the results were still incorrectly sized.

Three sample graphs of the problem can be seen at this url:

http://penguinsolutions.org/math108/Rexamples/Rplots.pdf

Notice how the graph extends beyond the paper on the right side of each 
page.

The command I am running from the terminal is:

R <baseballsalary.R >output --vanilla -q

I then read about postscript() in the documentation, so I found this 
sequence to be successful:

 > postscript("testthis.ps", paper='letter')
[...run all my same R code here...]
 > dev.off()
 > q()

and then run ps2pdf testthis.ps to create the plots as I intended on US 
letter:

http://penguinsolutions.org/math108/Rexamples/testthis.pdf

Notice that the graphs do not extend beyond the edge of US letter paper 
on these plots.

How do I set (in Fedora Core 1) the paper size for R to US letter, so I 
can run my commands R <baseballsalary.R >output --vanilla -q from the 
terminal?

Thanks very much,
Clint
-- 
Clint Harshaw, PhD   		Email: charshaw at presby.edu
Department of Mathematics	Ph: 864.833.8995
Presbyterian College		Fax: 864.938.3769	
Clinton, SC USA  29325		Harrington-Peachtree Rm 412



From ligges at statistik.uni-dortmund.de  Wed Mar  2 19:13:44 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 02 Mar 2005 19:13:44 +0100
Subject: [R] data.frame, data types, and apply
In-Reply-To: <Pine.GSO.4.58.0503021801330.12047@maxi>
References: <Pine.GSO.4.58.0503021801330.12047@maxi>
Message-ID: <42260258.4060309@statistik.uni-dortmund.de>

Vincent Detours wrote:

> Dear all,
> 
> Here is an issue I often stumble on.
> 
> 1- colunm types in data.frames.
> 
> -------------------------------
> 
>>d <- data.frame(x=as.character(c("a", "b", "c")), y=as.numeric(c(1, 2, 3)))
>>d
> 
>   x y
> 1 a 1
> 2 b 2
> 3 c 3
> 
>>is.numeric(d[1,2])
> 
> [1] TRUE
> 
>>is.numeric(d[1,1])
> 
> [1] FALSE
> 
>>apply(d, c(1,2), is.numeric)
> 
>       x     y
> 1 FALSE FALSE
> 2 FALSE FALSE
> 3 FALSE FALSE
> 
> -------------------------------
> 
> All item in column "y" should be TRUE right? What should I do to apply
> a function only to numerics in d? (beside using nested 'for' loops)

It is correct!
d is a data.frame, but apply() works on matrices. So d is coerced to a 
matrix which means that there need to be only one mode - and that is 
character!

Check the columns as in

   sapply(d, is.numeric)


Uwe Ligges



> Thanks for your help, and for all the great software.
> 
> 
> Vincent Detours
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From rs at natchie.mine.nu  Wed Mar  2 17:38:37 2005
From: rs at natchie.mine.nu (Rusty Shackleford)
Date: Wed, 2 Mar 2005 16:38:37 +0000 (UTC)
Subject: [R] OT: Looking for freely available medical data
Message-ID: <slrnd2br9g.bv2.rs@mwilson.umlcoop.net>

I'm a computer science graduate student studying machine learning and
rule-based induction.  I'd like to explore if it is possible to predict
future disease rates based on medical data.

However, medical claims data like this is usually only collected by
insurance companies who aren't going to share with me.

There are lots of statisticians on this list -- maybe somebody knows
about some freely available datasets, like 20-year-old Medicare claims
that have all personal information removed.

TIA



From charshaw at presby.edu  Wed Mar  2 19:39:29 2005
From: charshaw at presby.edu (Clint Harshaw)
Date: Wed, 02 Mar 2005 13:39:29 -0500
Subject: [R] .ps and .pdf page size differences in FC vs. Debian
In-Reply-To: <422601A3.9050503@presby.edu>
References: <422601A3.9050503@presby.edu>
Message-ID: <42260861.5010803@presby.edu>

Clint Harshaw wrote:

 > R version: 2.0.0
 > OS: Fedora Core 1

[...]

 > How do I set (in Fedora Core 1) the paper size for R to US letter, so 
I can run my commands R <baseballsalary.R >output --vanilla -q from the 
terminal?


About 15 minutes after I sent this question in to the list, I found some 
help at this url:

http://www.ku.edu/~pauljohn/R/Rtips.html#5.4

So I tried including options(pagesize="letter") and the result properly 
fit on US Letter paper.

But I would still like to learn how to set a configuration parameter for 
R, so that R code I write will behave the same regardless of my running 
it on my Debian box or my FC1 box.

Thanks,
Clint

-- 
Clint Harshaw, PhD   		Email: charshaw at presby.edu
Department of Mathematics	Ph: 864.833.8995
Presbyterian College		Fax: 864.938.3769	
Clinton, SC USA  29325		Harrington-Peachtree Rm 412



From ripley at stats.ox.ac.uk  Wed Mar  2 19:55:18 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 2 Mar 2005 18:55:18 +0000 (GMT)
Subject: [R] .ps and .pdf page size differences in FC vs. Debian
In-Reply-To: <422601A3.9050503@presby.edu>
References: <422601A3.9050503@presby.edu>
Message-ID: <Pine.LNX.4.61.0503021844280.29795@gannet.stats>

This *is* in the R-admin manual that the INSTALL file asks you to read, 
and also in configure --help.  There is even an loud hint for `North 
American readers'.  If you have not read that, you need to.

At this stage, go to R_HOME/etc/Renviron and change the default for
R_PAPERSIZE to one of the values stated in the manual.

On Wed, 2 Mar 2005, Clint Harshaw wrote:

> R version: 2.0.0
> OS: Fedora Core 1
>
> When I'm using Fedora Core 1, Rplots.ps (and subsequent Rplots.pdf created 
> after using ps2pdf Rplots.ps) which are created from the command line 
> execution of R are too large to fit on a US Letter sized page when printed. 
> The same code will produce a US letter sized page when I'm on my Debian Sid 
> box. Both boxes are connected to the same shared printer, and both are 
> configured in CUPS to use US Letter paper size. When I posted a question to 
> the FC folks, the consensus was there was a configuration that needed to be 
> done in R to set the proper page for graphics exported.
>
> I've google'd for a solution and came up with a check for a locale variable 
> in /etc/sysconfig/i18n to be set to the same as for the lang variable. I 
> tried that, and the results were still incorrectly sized.
>
> Three sample graphs of the problem can be seen at this url:
>
> http://penguinsolutions.org/math108/Rexamples/Rplots.pdf
>
> Notice how the graph extends beyond the paper on the right side of each page.
>
> The command I am running from the terminal is:
>
> R <baseballsalary.R >output --vanilla -q
>
> I then read about postscript() in the documentation, so I found this sequence 
> to be successful:
>
>> postscript("testthis.ps", paper='letter')
> [...run all my same R code here...]
>> dev.off()
>> q()
>
> and then run ps2pdf testthis.ps to create the plots as I intended on US 
> letter:
>
> http://penguinsolutions.org/math108/Rexamples/testthis.pdf
>
> Notice that the graphs do not extend beyond the edge of US letter paper on 
> these plots.
>
> How do I set (in Fedora Core 1) the paper size for R to US letter, so I can 
> run my commands R <baseballsalary.R >output --vanilla -q from the terminal?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Scott.Waichler at pnl.gov  Wed Mar  2 20:01:01 2005
From: Scott.Waichler at pnl.gov (Waichler, Scott R)
Date: Wed, 02 Mar 2005 11:01:01 -0800
Subject: [R] Rounding parameter values in genoud(), Rgenoud package
Message-ID: <7E4C06F49D6FEB49BE4B60E5FC92ED7A018344CC@pnlmse35.pnl.gov>


I would like to limit the significant figures of the calibrated
parameters determined by genoud() in the Rgenoud package.  Below is some
example output, where column 1 is model run number, columns 2-7 are the
parameter values, and columns 8-12 are model fit statistics.  I would
like genoud to internally limit parameters to 4 decimal places as shown
in this output.  It is clear that the function is generating many
parameter sets that are identical after rounding.  Can I impose rounding
on the function and thereby lessen processing time?  The only function
argument that seems related is the solution.tolerance, but this is not
for the parameter values.

Run  par1    par2     par3     par4    par5     par6     Bias    MAE
R2       E2       E1'
507 0.0239 0.0219 0.0267 0.0274 0.0283 0.0245 -0.0112 0.0804 0.9994
0.9994 0.9792
508 0.0239 0.0219 0.0267 0.0274 0.0283 0.0245 -0.0112 0.0804 0.9994
0.9994 0.9792
509 0.0239 0.0219 0.0267 0.0274 0.0283 0.0245 -0.0112 0.0804 0.9994
0.9994 0.9792
510 0.0239 0.0219 0.0267 0.0274 0.0283 0.0245 -0.0112 0.0804 0.9994
0.9994 0.9792
511 0.0239 0.0219 0.0267 0.0274 0.0283 0.0245 -0.0112 0.0804 0.9994
0.9994 0.9792
512 0.0239 0.0219 0.0267 0.0274 0.0283 0.0245 -0.0112 0.0804 0.9994
0.9994 0.9792
513 0.0239 0.0219 0.0267 0.0274 0.0283 0.0245 -0.0112 0.0804 0.9994
0.9994 0.9792
514 0.0239 0.0219 0.0267 0.0274 0.0283 0.0245 -0.0112 0.0804 0.9994
0.9994 0.9792
515 0.0239 0.0219 0.0267 0.0274 0.0283 0.0245 -0.0112 0.0804 0.9994
0.9994 0.9792
516 0.0239 0.0219 0.0267 0.0274 0.0283 0.0245 -0.0112 0.0804 0.9994
0.9994 0.9792

Thanks,
Scott Waichler
Senior Research Scientist
Pacific Northwest National Laboratory
Richland, WA   USA
scott.waichler at pnl.gov



From jeaneid at chass.utoronto.ca  Wed Mar  2 20:55:23 2005
From: jeaneid at chass.utoronto.ca (jeaneid@chass.utoronto.ca)
Date: Wed, 2 Mar 2005 14:55:23 -0500 (EST)
Subject: [R] Applying a function to all combinations of factors
In-Reply-To: <APEJLJBDGGLPABONJPDMGENECMAA.marc.m.belisle@usherbrooke.ca>
References: <APEJLJBDGGLPABONJPDMGENECMAA.marc.m.belisle@usherbrooke.ca>
Message-ID: <2475.128.100.178.79.1109793323.squirrel@128.100.178.79>

you could use something  like

by(data, list(data1$day, data1$hour), function(x) cor(x[,"var1"], x[,
"var2"]))

This will return a list and then you can unlist and turn to matrix

HTH
> Is there a way to apply a function, say cor(), to each combination of some
> number of variables, and this, without using loops?
>
> For example, I have day, hour, var1 and var2. How could I compute
> cor(var1,var2) for each day*hour combination and obtain a matrix with day,
> hour and the cor value for each combination?
>
> Thanks for your time,
>
> Marc
>
> ==================Marc B?lisle
> Professeur adjoint
> Chaire de recherche du Canada en ?cologie spatiale et en ?cologie du
> paysage
> D?partement de biologie
> Universit? de Sherbrooke
> 2500 Boul. de l'Universit?
> Sherbrooke, Qu?bec
> J1K 2R1 Canada
>
> T?l: +1-819-821-8000 poste 1313
> Fax: +1-819-821-8049
> Courri?l: Marc.M.Belisle at USherbrooke.ca
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From tyliu_ad at hotmail.com  Wed Mar  2 21:15:21 2005
From: tyliu_ad at hotmail.com (Liu Ting-Yuan)
Date: Wed, 02 Mar 2005 12:15:21 -0800
Subject: [R] wilcox.test statistics
Message-ID: <BAY104-F393D0908989D155C925F1CE85A0@phx.gbl>


Hi,

Could anyone provide the formula of the statistics which the wilcox.test 
used for the two-sample rank-sum test?  I got some statistics of 0 values, 
but it is impossible to have 0 "rank-sum".  Does the function use the 
Mann-Whitney U test statistics?  Thanks.

Ting-Yuan Liu



From gunter.berton at gene.com  Wed Mar  2 21:23:32 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 2 Mar 2005 12:23:32 -0800
Subject: [R] wilcox.test statistics
In-Reply-To: <BAY104-F393D0908989D155C925F1CE85A0@phx.gbl>
Message-ID: <200503022023.j22KNW5s014384@faraday.gene.com>

R is open source, so you can read the code yourself!

stats:::wilcox.test.default

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Liu Ting-Yuan
> Sent: Wednesday, March 02, 2005 12:15 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] wilcox.test statistics
> 
> 
> Hi,
> 
> Could anyone provide the formula of the statistics which the 
> wilcox.test 
> used for the two-sample rank-sum test?  I got some statistics 
> of 0 values, 
> but it is impossible to have 0 "rank-sum".  Does the function use the 
> Mann-Whitney U test statistics?  Thanks.
> 
> Ting-Yuan Liu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From hook_l at bookofhook.com  Wed Mar  2 21:56:19 2005
From: hook_l at bookofhook.com (Brian Hook)
Date: Wed, 2 Mar 2005 15:56:19 -0500
Subject: [R] overlapping/interleaved histogram help
Message-ID: <200532155619.181366@GATEWAY>

NOTE: I have read the FAQ, Verzani's book, Rtips, and googled.

For various reasons I don't want to use a density plot when comparing 
two distributions, I would prefer to have interleaved histograms over 
the same ranges.

In addition to this, I would also like to normalize the two histograms 
so that both of their max Y values are the same (so I can compare 
relative distributions within one distribution to the relative 
distributions within another, i.e. peaks).  The data is clustered in a 
narrow range with quite a few outliers, and for this reason the 
regular histogram function with default parameters tends to give a 
poor graph (very wide swaths to encompass the outliers), whereas I'd 
prefer a fixed visual size to cover the outliers.

My current instinct is that I will have to do the following:

1.  Take existing data and bin it
2.  Iterate over data and perform optional normalization
3.  Interleave the two data sets
4.  Render with bar plots

If those sounds like the appropriate steps then I'll research it and 
go with that, but I'm hoping there's a much simpler solution.

Thanks,

Brian



From Setzer.Woodrow at epamail.epa.gov  Wed Mar  2 22:02:23 2005
From: Setzer.Woodrow at epamail.epa.gov (Setzer.Woodrow@epamail.epa.gov)
Date: Wed, 02 Mar 2005 16:02:23 -0500
Subject: [R] Using varPower in gnls, an answer of sorts.
Message-ID: <OF23D647D7.96DE0BDF-ON85256FB8.006EC6B7-85256FB8.00739549@epamail.epa.gov>

Back on January 16, a message on R-help from Ravi Varadhan described a
problem with gnls using weights=varPower().  The problem was that the
fit failed with error

Error in eval(expr, envir, enclos) : Object "." not found

I can reliably get this error in version 2.0.1-patched 2004-12-09 on
Windows XP and 2.0.1-Patched 2005-01-26 on Linux.

The key feature of that example is that the data are being passed in the
environment.  Consider a modification of the example in the man page for
gnls:

First, something that should work:

> gnls(weight ~ Asym/(1 + exp((xmid - Time)/scal)),data=Soybean,
+ start=c(Asym=16,xmid=50,scal=7),weights=varPower())
Generalized nonlinear least squares fit
  Model: weight ~ Asym/(1 + exp((xmid - Time)/scal))
  Data: Soybean
  Log-likelihood: -486.8973

Coefficients:
    Asym     xmid     scal
17.35681 51.87230  7.62052

Variance function:
 Structure: Power of variance covariate
 Formula: ~fitted(.)
 Parameter estimates:
    power
0.8815438
Degrees of freedom: 412 total; 409 residual
Residual standard error: 0.3662752

## Now, use with() to pass Soybean in the environment of gnls:

> with(Soybean,gnls(weight ~ Asym/(1 + exp((xmid - Time)/scal)),
+ start=c(Asym=16,xmid=50,scal=7),weights=varPower()))

Error in eval(expr, envir, enclos) : Object "." not found

## drop the weights argument from gnls, and the error message goes away.

The problem is in a call to model.frame.  When varPower() (and
presumably other weight functions using '.' to represent a fitted model)
is used, gnls() constructs a formula argument for model.matrix that
looks like:
~.+weight+Time
This works when the data are passed in a data frame, but not when they
are in the environment.  Look at the example in the man page for
model.frame

> data.class(model.frame(~.+dist+speed, data=cars))
[1] "data.frame"
> data.class(with(cars,model.frame(~.+dist+speed)))
Error in eval(expr, envir, enclos) : Object "." not found
> data.class(with(cars,model.frame(~dist+speed)))
[1] "data.frame"
> env <- new.env(TRUE,NULL)
> assign("dist",cars$dist,envir=env)
> assign("speed",cars$speed,envir=env)
> data.class(model.frame(~dist+speed,data=env))
[1] "data.frame"
> data.class(model.frame(~.+dist+speed,data=env))
Error in eval(expr, envir, enclos) : Object "." not found

I'm sending this to r-help rather to the authors of nlme because I am
not sure where the bug is: is model.frame misbehaving, or should gnls
not include '.' in its call to model.frame?

R. Woodrow Setzer, Jr.                        Phone: (919) 541-0128
Experimental Toxicology Division             Fax:  (919) 541-4284
Pharmacokinetics Branch
NHEERL B143-01; US EPA; RTP, NC 27711



From nkn at turing.une.edu.au  Wed Mar  2 23:14:28 2005
From: nkn at turing.une.edu.au (Nam-Ky Nguyen)
Date: Thu, 3 Mar 2005 09:14:28 +1100 (EST)
Subject: [R] Suppressing observation numbers
Message-ID: <50543.203.206.241.246.1109801668.squirrel@203.206.241.246>

Dear R gurus,

Below is a part of the R output. Please consider the two lines:
> data
> model.matrix(m1)

Is there a way of suppressing the observation numbers 1, 2, ...27 in the
output (I don't want these number to appear in the output)?

Regards,
NKN

> # Orthogonal blocking
> data=read.table("cut.txt",header=T)
> attach(data)
> data
   b x1 x2 x3
1  1 -1 -1  0
2  1 -1  0  1
3  1 -1  1 -1
4  1  0 -1  0
5  1  0  0  1
6  1  0  1 -1
7  1  1 -1 -1
8  1  1  0  0
9  1  1  1  1
10 2 -1 -1 -1
11 2 -1  0  0
12 2 -1  1  1
13 2  0 -1  1
14 2  0  0 -1
15 2  0  1  0
16 2  1 -1  0
17 2  1  0  1
18 2  1  1 -1
19 3 -1 -1  1
20 3 -1  0 -1
21 3 -1  1  0
22 3  0 -1 -1
23 3  0  0  0
24 3  0  1  1
25 3  1 -1  1
26 3  1  0 -1
27 3  1  1  0
> b=factor(b)
> y=rnorm(27)
> x4=x1*x2
> x5=x1*x3
> x6=x2*x3
> x7=x1*x1
> x8=x2*x2
> x9=x3*x3
> options(contrasts=c("contr.sum","contr.poly"))
> m1=lm(y~b+x1+x2+x3+x4+x5+x6+x7+x8+x9)
> model.matrix(m1)
   (Intercept) b1 b2 x1 x2 x3 x4 x5 x6 x7 x8 x9
1            1  1  0 -1 -1  0  1  0  0  1  1  0
2            1  1  0 -1  0  1  0 -1  0  1  0  1
3            1  1  0 -1  1 -1 -1  1 -1  1  1  1
4            1  1  0  0 -1  0  0  0  0  0  1  0
5            1  1  0  0  0  1  0  0  0  0  0  1
6            1  1  0  0  1 -1  0  0 -1  0  1  1
7            1  1  0  1 -1 -1 -1 -1  1  1  1  1
8            1  1  0  1  0  0  0  0  0  1  0  0
9            1  1  0  1  1  1  1  1  1  1  1  1
10           1  0  1 -1 -1 -1  1  1  1  1  1  1
11           1  0  1 -1  0  0  0  0  0  1  0  0
12           1  0  1 -1  1  1 -1 -1  1  1  1  1
13           1  0  1  0 -1  1  0  0 -1  0  1  1
14           1  0  1  0  0 -1  0  0  0  0  0  1
15           1  0  1  0  1  0  0  0  0  0  1  0
16           1  0  1  1 -1  0 -1  0  0  1  1  0
17           1  0  1  1  0  1  0  1  0  1  0  1
18           1  0  1  1  1 -1  1 -1 -1  1  1  1
19           1 -1 -1 -1 -1  1  1 -1 -1  1  1  1
20           1 -1 -1 -1  0 -1  0  1  0  1  0  1
21           1 -1 -1 -1  1  0 -1  0  0  1  1  0
22           1 -1 -1  0 -1 -1  0  0  1  0  1  1
23           1 -1 -1  0  0  0  0  0  0  0  0  0
24           1 -1 -1  0  1  1  0  0  1  0  1  1
25           1 -1 -1  1 -1  1 -1  1 -1  1  1  1
26           1 -1 -1  1  0 -1  0 -1  0  1  0  1
27           1 -1 -1  1  1  0  1  0  0  1  1  0
attr(,"assign")
 [1]  0  1  1  2  3  4  5  6  7  8  9 10
attr(,"contrasts")
attr(,"contrasts")$b
[1] "contr.sum"



--
Nam-Ky Nguyen, Senior Lecturer
School of Mathematics, Statistics and Computer Science
University of New England, Armidale NSW 2351 Australia
nkn at turing.une.edu.au              Tel: +612 6773 2763
http://turing.une.edu.au/~nkn      Fax: +612 6773 3312

Please convert Word files to PDF files before sending them to me.
See http://www.gnu.org/philosophy/no-word-attachments.html



From whit at twinfieldscapital.com  Wed Mar  2 23:22:43 2005
From: whit at twinfieldscapital.com (Whit Armstrong)
Date: Wed, 2 Mar 2005 17:22:43 -0500
Subject: [R] apply a function to a rolling subset of a vector
Message-ID: <726FC6DD09DE1046AF81B499D70C3BCE15790C@twinfields02.CORP.TWINFIELDSCAPITAL.COM>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050302/331d8b6f/attachment.pl

From hodgess at gator.uhd.edu  Wed Mar  2 23:24:49 2005
From: hodgess at gator.uhd.edu (Erin Hodgess)
Date: Wed, 2 Mar 2005 16:24:49 -0600
Subject: [R] Graphing question/possibly lattice/xyplot
Message-ID: <200503022224.j22MOnc29206@gator.dt.uh.edu>

Dear R People:
I have a data frame with the variables calories, sodium and "type", 
where type is either zero or one.

I would like to produce a scatterplot with sodium on the horizontal,
calories on the vertical and have the dots be clear when type is one and
black when type is zero.

It can be done via lines and points, but I was wondering if there is a
better way with lattice graphics.

Thanks in advance,
Sincerely,
Erin Hodgess
mailto: hodgess at gator.uhd.edu



From ripley at stats.ox.ac.uk  Wed Mar  2 23:28:41 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 2 Mar 2005 22:28:41 +0000 (GMT)
Subject: [R] Using varPower in gnls, an answer of sorts.
In-Reply-To: <OF23D647D7.96DE0BDF-ON85256FB8.006EC6B7-85256FB8.00739549@epamail.epa.gov>
References: <OF23D647D7.96DE0BDF-ON85256FB8.006EC6B7-85256FB8.00739549@epamail.epa.gov>
Message-ID: <Pine.LNX.4.61.0503022222390.5495@gannet.stats>

On Wed, 2 Mar 2005 Setzer.Woodrow at epamail.epa.gov wrote:

> Back on January 16, a message on R-help from Ravi Varadhan described a
> problem with gnls using weights=varPower().  The problem was that the
> fit failed with error

[...]

> I'm sending this to r-help rather to the authors of nlme because I am
> not sure where the bug is: is model.frame misbehaving, or should gnls
> not include '.' in its call to model.frame?

'.' is only defined in a formula for model.frame() when there is a 'data' 
argument (otherwise what do you think it might mean?).  So this is not a 
problem in model.frame(), hence on your analysis in gnls() or the usage of 
it.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rolf at math.unb.ca  Wed Mar  2 23:30:21 2005
From: rolf at math.unb.ca (Rolf Turner)
Date: Wed, 2 Mar 2005 18:30:21 -0400 (AST)
Subject: [R] Suppressing observation numbers
Message-ID: <200503022230.j22MULF2002138@erdos.math.unb.ca>


Nam-Ky Nguyen wrote:

> Below is a part of the R output. Please consider the two lines:
> > data
> > model.matrix(m1)
> 
> Is there a way of suppressing the observation numbers 1, 2, ...27 in the
> output (I don't want these number to appear in the output)?

The (``relatively low level''?) function prmatrix() allows you to do
what you want:

	> prmatrix(model.matrix(m1),rowlab=rep("",27))

I have in the past suggested to the R Core Team that an argument be
added to print.matrix() and print.data.frame() to permit the
suppression of the printing of row names.  Something like
``print.row.names=TRUE''.  This would be easy to accomplish, since
print.matrix() and print.data.frame() simply call upon prmatrix().
However my suggestion has so far fallen upon deaf ears.

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From ripley at stats.ox.ac.uk  Wed Mar  2 23:34:46 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 2 Mar 2005 22:34:46 +0000 (GMT)
Subject: [R] Suppressing observation numbers
In-Reply-To: <50543.203.206.241.246.1109801668.squirrel@203.206.241.246>
References: <50543.203.206.241.246.1109801668.squirrel@203.206.241.246>
Message-ID: <Pine.LNX.4.61.0503022229020.5495@gannet.stats>

On Thu, 3 Mar 2005, Nam-Ky Nguyen wrote:

> Dear R gurus,
>
> Below is a part of the R output. Please consider the two lines:
>> data
>> model.matrix(m1)
>
> Is there a way of suppressing the observation numbers 1, 2, ...27 in the
> output (I don't want these number to appear in the output)?

Actually, these are the row names of a data frame, and the answer is yes.
(Note: I _have_ answered your question!)

If you meant to ask how to do it, here is a hint

library(MASS); write.matrix(hills)

>
> Regards,
> NKN
>
>> # Orthogonal blocking
>> data=read.table("cut.txt",header=T)
>> attach(data)
>> data
>   b x1 x2 x3
> 1  1 -1 -1  0
> 2  1 -1  0  1
> 3  1 -1  1 -1
> 4  1  0 -1  0
> 5  1  0  0  1
> 6  1  0  1 -1
> 7  1  1 -1 -1
> 8  1  1  0  0
> 9  1  1  1  1
> 10 2 -1 -1 -1
> 11 2 -1  0  0
> 12 2 -1  1  1
> 13 2  0 -1  1
> 14 2  0  0 -1
> 15 2  0  1  0
> 16 2  1 -1  0
> 17 2  1  0  1
> 18 2  1  1 -1
> 19 3 -1 -1  1
> 20 3 -1  0 -1
> 21 3 -1  1  0
> 22 3  0 -1 -1
> 23 3  0  0  0
> 24 3  0  1  1
> 25 3  1 -1  1
> 26 3  1  0 -1
> 27 3  1  1  0
>> b=factor(b)
>> y=rnorm(27)
>> x4=x1*x2
>> x5=x1*x3
>> x6=x2*x3
>> x7=x1*x1
>> x8=x2*x2
>> x9=x3*x3
>> options(contrasts=c("contr.sum","contr.poly"))
>> m1=lm(y~b+x1+x2+x3+x4+x5+x6+x7+x8+x9)
>> model.matrix(m1)
>   (Intercept) b1 b2 x1 x2 x3 x4 x5 x6 x7 x8 x9
> 1            1  1  0 -1 -1  0  1  0  0  1  1  0
> 2            1  1  0 -1  0  1  0 -1  0  1  0  1
> 3            1  1  0 -1  1 -1 -1  1 -1  1  1  1
> 4            1  1  0  0 -1  0  0  0  0  0  1  0
> 5            1  1  0  0  0  1  0  0  0  0  0  1
> 6            1  1  0  0  1 -1  0  0 -1  0  1  1
> 7            1  1  0  1 -1 -1 -1 -1  1  1  1  1
> 8            1  1  0  1  0  0  0  0  0  1  0  0
> 9            1  1  0  1  1  1  1  1  1  1  1  1
> 10           1  0  1 -1 -1 -1  1  1  1  1  1  1
> 11           1  0  1 -1  0  0  0  0  0  1  0  0
> 12           1  0  1 -1  1  1 -1 -1  1  1  1  1
> 13           1  0  1  0 -1  1  0  0 -1  0  1  1
> 14           1  0  1  0  0 -1  0  0  0  0  0  1
> 15           1  0  1  0  1  0  0  0  0  0  1  0
> 16           1  0  1  1 -1  0 -1  0  0  1  1  0
> 17           1  0  1  1  0  1  0  1  0  1  0  1
> 18           1  0  1  1  1 -1  1 -1 -1  1  1  1
> 19           1 -1 -1 -1 -1  1  1 -1 -1  1  1  1
> 20           1 -1 -1 -1  0 -1  0  1  0  1  0  1
> 21           1 -1 -1 -1  1  0 -1  0  0  1  1  0
> 22           1 -1 -1  0 -1 -1  0  0  1  0  1  1
> 23           1 -1 -1  0  0  0  0  0  0  0  0  0
> 24           1 -1 -1  0  1  1  0  0  1  0  1  1
> 25           1 -1 -1  1 -1  1 -1  1 -1  1  1  1
> 26           1 -1 -1  1  0 -1  0 -1  0  1  0  1
> 27           1 -1 -1  1  1  0  1  0  0  1  1  0
> attr(,"assign")
> [1]  0  1  1  2  3  4  5  6  7  8  9 10
> attr(,"contrasts")
> attr(,"contrasts")$b
> [1] "contr.sum"
>
>
>
> --
> Nam-Ky Nguyen, Senior Lecturer
> School of Mathematics, Statistics and Computer Science
> University of New England, Armidale NSW 2351 Australia
> nkn at turing.une.edu.au              Tel: +612 6773 2763
> http://turing.une.edu.au/~nkn      Fax: +612 6773 3312
>
> Please convert Word files to PDF files before sending them to me.
> See http://www.gnu.org/philosophy/no-word-attachments.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From knoblauch at lyon.inserm.fr  Wed Mar  2 22:42:01 2005
From: knoblauch at lyon.inserm.fr (Ken Knoblauch)
Date: Wed,  2 Mar 2005 22:42:01 +0100
Subject: [R] apply a function to a rolling subset of a vector
Message-ID: <1109799721.422633296f90c@webmail.lyon.inserm.fr>

Try this:

> ?convolve
> x<-rnorm(1000)
> y<-rep(1,20)
> z<-convolve(x,y,type="filter")
> plot(x,type="l")
> str(z)
 num [1:981] 6.31 7.28 8.16 7.39 4.65 ...
> lines(c(rep(0,10),z,rep(0,10)),col="yellow",lwd=3)
> lines(c(rep(0,10),z,rep(0,10))/length(y),col="red",lwd=3) #running mean

You wrote:
Does anyone know an easy way to calculate the rolling 20 period average
or sum of a vector?

For instance:
x <- rnorm(1000)

y <- apply.subset(x,20,fun="sum")

The first element of y would contain the sum of elements 1 to 20, the
second element of y 
would contain the sum of elements 2:21, and so on.

I thought I had seen this on the list a year or so ago, but I couldn't
find anything in the archives.


Thanks in advance,
Whit

        [[alternative HTML version deleted]]

____________________
Ken Knoblauch
Inserm U 371
Cerveau et Vision
18 avenue du Doyen Lepine
69675 Bron cedex
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: 06 84 10 64 10



From murdoch at stats.uwo.ca  Wed Mar  2 23:39:31 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 02 Mar 2005 22:39:31 +0000
Subject: [R] apply a function to a rolling subset of a vector
In-Reply-To: <726FC6DD09DE1046AF81B499D70C3BCE15790C@twinfields02.CORP.TWINFIELDSCAPITAL.COM>
References: <726FC6DD09DE1046AF81B499D70C3BCE15790C@twinfields02.CORP.TWINFIELDSCAPITAL.COM>
Message-ID: <ivfc21hf8s75k92ku1vcl3hkar4mbkui4e@4ax.com>

On Wed, 2 Mar 2005 17:22:43 -0500, "Whit Armstrong"
<whit at twinfieldscapital.com> wrote :

>Does anyone know an easy way to calculate the rolling 20 period average
>or sum of a vector?
>
>For instance:
>x <- rnorm(1000)
>
>y <- apply.subset(x,20,fun="sum")
>
>The first element of y would contain the sum of elements 1 to 20, the
>second element of y 
>would contain the sum of elements 2:21, and so on.
>
>I thought I had seen this on the list a year or so ago, but I couldn't
>find anything in the archives.

I don't know of a general purpose function, but filter() (in the stats
package) can do the example you give, or any other linear filter.

e.g.

x <- rnorm(1000)
y <- filter(x, rep(1,20))

puts 20 element sums into y.  The vector ends up the same length as x,
with NAs at the beginning and end (by default).

Duncan Murdoch



From MSchwartz at MedAnalytics.com  Wed Mar  2 23:45:59 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed, 02 Mar 2005 16:45:59 -0600
Subject: [R] apply a function to a rolling subset of a vector
In-Reply-To: <726FC6DD09DE1046AF81B499D70C3BCE15790C@twinfields02.CORP.TWINFIELDSCAPITAL.COM>
References: <726FC6DD09DE1046AF81B499D70C3BCE15790C@twinfields02.CORP.TWINFIELDSCAPITAL.COM>
Message-ID: <1109803560.14981.7.camel@horizons.localdomain>

On Wed, 2005-03-02 at 17:22 -0500, Whit Armstrong wrote:
> Does anyone know an easy way to calculate the rolling 20 period average
> or sum of a vector?
> 
> For instance:
> x <- rnorm(1000)
> 
> y <- apply.subset(x,20,fun="sum")
> 
> The first element of y would contain the sum of elements 1 to 20, the
> second element of y 
> would contain the sum of elements 2:21, and so on.
> 
> I thought I had seen this on the list a year or so ago, but I couldn't
> find anything in the archives.

You can use the running() function in the gtools package, which is in
the gregmisc bundle:

x <- rnorm(1000)

> running(x, fun = sum, width = 20)
         1:20          2:21          3:22          4:23          5:24
 -2.009684610  -2.205737077  -1.410810606  -2.226661837  -1.684604289
         6:25          7:26          8:27          9:28         10:29
 -4.492008605  -3.816273719  -5.348364598  -6.444591766  -5.263013812
        11:30         12:31         13:32         14:33         15:34
 -4.609829115  -5.935537291  -6.909232329  -4.881021777  -5.803659103
...

See ?running for more information, after installing gregmisc from CRAN. 

HTH,

Marc Schwartz



From ggrothendieck at myway.com  Wed Mar  2 23:47:32 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 2 Mar 2005 22:47:32 +0000 (UTC)
Subject: [R] apply a function to a rolling subset of a vector
References: <726FC6DD09DE1046AF81B499D70C3BCE15790C@twinfields02.CORP.TWINFIELDSCAPITAL.COM>
Message-ID: <loom.20050302T234615-210@post.gmane.org>

Whit Armstrong <whit <at> twinfieldscapital.com> writes:

: 
: Does anyone know an easy way to calculate the rolling 20 period average
: or sum of a vector?
: 
: For instance:
: x <- rnorm(1000)
: 
: y <- apply.subset(x,20,fun="sum")
: 
: The first element of y would contain the sum of elements 1 to 20, the
: second element of y 
: would contain the sum of elements 2:21, and so on.
: 
: I thought I had seen this on the list a year or so ago, but I couldn't
: find anything in the archives.
: 

Look at ?filter .  Also ?embed and gtools::running .  filter is the
fastest.



From whit at twinfieldscapital.com  Thu Mar  3 00:03:54 2005
From: whit at twinfieldscapital.com (Whit Armstrong)
Date: Wed, 2 Mar 2005 18:03:54 -0500
Subject: [R] apply a function to a rolling subset of a vector
Message-ID: <726FC6DD09DE1046AF81B499D70C3BCE15790F@twinfields02.CORP.TWINFIELDSCAPITAL.COM>

Thanks, everyone, for all the suggestions.

The rollFun turs out to be just what I needed.

Cheers,
Whit
 

-----Original Message-----
From: Kjetil Brinchmann Halvorsen [mailto:kjetil at acelerate.com] 
Sent: Wednesday, March 02, 2005 5:45 PM
To: Whit Armstrong
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] apply a function to a rolling subset of a vector

Whit Armstrong wrote:

>Does anyone know an easy way to calculate the rolling 20 period average

>or sum of a vector?
>
>For instance:
>x <- rnorm(1000)
>
>y <- apply.subset(x,20,fun="sum")
>  
>
help.search("rolling")

gives me (among others)

RollingAnalysis(fSeries)
                        Rolling Analysis

so trying

library(fSeries)
x <- rnorm(1000)
y <- rollFun(x, 20, mean)

Kjetil

>The first element of y would contain the sum of elements 1 to 20, the 
>second element of y would contain the sum of elements 2:21, and so on.
>
>I thought I had seen this on the list a year or so ago, but I couldn't 
>find anything in the archives.
>
>
>Thanks in advance,
>Whit
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html
>
>
>
>  
>


-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra




--
No virus found in this outgoing message.
Checked by AVG Anti-Virus.



From f.harrell at vanderbilt.edu  Thu Mar  3 00:23:49 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Wed, 02 Mar 2005 17:23:49 -0600
Subject: [R] subset selection for logistic regression
In-Reply-To: <Pine.GSO.3.95q.1050302175848.19444E-100000@sun11.math.uni-hamburg.de>
References: <Pine.GSO.3.95q.1050302175848.19444E-100000@sun11.math.uni-hamburg.de>
Message-ID: <42264B05.80708@vanderbilt.edu>

Christian Hennig wrote:
> Perhaps I should not write it because I will discredit myself with this
> but...
> 
> Suppose I have a setup with 100 variables and some 1000 cases and I want to
> boil down the number of variables to a maximum of 10 for practical reasons
> even if I lose 10% prediction quality by this (for example because it is
> expensive to measure all variables on new cases).  
> 
> Is it really so wrong to use a stepwise method?

Yes.  Read about model uncertainty and bias in models developed using 
stepwise methods.  One exception: if there is a large number of 
variables with truly zero regression coefficients, and the rest are not 
very weak, stepwise can sort things out fairly well.  But you never know 
this in advance.

> Let's say I divide the sample into three parts and do variable selction on
> the first part, estimation on the second and test on the third part (this
> solves almost all problems Frank is talking about on p. 56/57 in his
> excellent book). Is there always a tractable alternative? 

That's a good way to find out how bad the method is, not to fix the 
problems inherent in it.

> 
> Of course it is wrong to interpret the selected variables as "the true
> influences" and all others as "unrelated", but if I don't do that?
> 
> If it should really be a taboo to do stepwise variable selection, why are p.
> 58/59 of "Regression Modeling Strategies" devoted to "how to do it of you
> must"?

Stress on "if".  And note that if you ask what is the optimum alpha for 
variables to be kept in the model when doing backwards stepdown, it's 
alpha=1.0.  A good compromise is alpha=0.5.  See

@Article{ste01pro,
   author = 		 {Steyerberg, Ewout W. and Eijkemans, Marinus
   J. C. and Harrell, Frank E. and Habbema, J. Dik F.},
   title = 		 {Prognostic modeling with logistic regression
   analysis: {In} search of a sensible strategy in small data sets},
   journal = 	 Medical Decision Making,
   year = 		 2001,
   volume =		 21,
   pages =		 {45-56},
   annote =		 {shrinkage; variable selection; dichotomization of
   continuous varibles; sign of regression coefficient; calibration; 
validation}
}

And on Bert's excellent question about why shrinkage is not used more 
often, here is our attempt at a remedy:

@Article{moo04pen,
   author = 		 {Moons, K. G. M. and Donders, A. Rogier T. and
Steyerberg, E. W. and Harrell, F. E.},
   title = 		 {Penalized maximum likelihood estimation to directly
adjust diagnostic and prognostic prediction models for overoptimism: a
clinical example},
   journal = 	 J Clinical Epidemiology,
   year = 		 2004,
   volume =		 57,
   pages =		 {1262-1270},
   annote =		 {prediction 
research;overoptimism;overfitting;penalization;bootstrapping;shrinkage}
}

Frank


> 
> Please forget my name;-)
> 
> Christian
> 
> On Wed, 2 Mar 2005, Berton Gunter wrote:
> 
> 
>>To clarify Frank's remark ...
>>
>>A prominent theme in statistical research over at least the last 25 years
>>(with roots that go back 50 or more, probably) has been the superiority of
>>"shrinkage" methods over variable selection. I also find it distressing that
>>these ideas have apparently not penetrated much (at all?) into the wider
>>scientific community (but I suppose I shouldn't be surprised -- most
>>scientists still do one factor at a time experiments 80 years after Fisher).
>>Specific incarnations can be found in anything Bayesian, mixed effects
>>models for repeated measures, ridge regression, and the R packages lars and
>>lasso, among others.
>>
>>I would speculate that aside from the usual statistics/science cultural
>>issues, part of the reason for this is that the estimators don't generally
>>come with neat, classical inference procedures: like it or not, many
>>scientists have been conditioned by their Stat 101 courses to expect P
>>values, so in some sense, we are hoisted by our own petard.
>>
>>Just my $.02 -- contrary(and more knowledgeable) opinions welcome.
>>
>>-- Bert Gunter
>> 
>>
>>
>>>-----Original Message-----
>>>From: r-help-bounces at stat.math.ethz.ch 
>>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Frank 
>>>E Harrell Jr
>>>Sent: Wednesday, March 02, 2005 5:13 AM
>>>To: Wittner, Ben
>>>Cc: r-help at lists.R-project.org
>>>Subject: Re: [R] subset selection for logistic regression
>>>
>>>Wittner, Ben wrote:
>>>
>>>>R-packages leaps and subselect implement various methods of 
>>>
>>>selecting best or
>>>
>>>>good subsets of predictor variables for linear regression 
>>>
>>>models, but they do
>>>
>>>>not seem to be applicable to logistic regression models.
>>>> 
>>>>Does anyone know of software for finding good subsets of 
>>>
>>>predictor variables for
>>>
>>>>linear regression models?
>>>> 
>>>>Thanks.
>>>> 
>>>>-Ben
>>>
>>>Why are these procedures still being used?  The performance 
>>>is known to 
>>>be bad in almost every sense (see r-help archives).
>>>
>>>Frank Harrell
>>>
>>>
>>>> 
>>>>p.s., The leaps package references "Subset Selection in 
>>>
>>>Regression" by Alan
>>>
>>>>Miller. On page 2 of the
>>>>2nd edition of that text it states the following:
>>>> 
>>>>  "All of the models which will be considered in this 
>>>
>>>monograph will be linear;
>>>
>>>>that is they
>>>>   will be linear in the regression coefficients.Though 
>>>
>>>most of the ideas and
>>>
>>>>problems carry
>>>>   over to the fitting of nonlinear models and generalized 
>>>
>>>linear models
>>>
>>>>(particularly the fitting
>>>>   of logistic relationships), the complexity is greatly increased."
>>>
>>>
>>>-- 
>>>Frank E Harrell Jr   Professor and Chair           School of Medicine
>>>                      Department of Biostatistics   
>>>Vanderbilt University
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! 
>>>http://www.R-project.org/posting-guide.html
>>>
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
> 
> ***********************************************************************
> Christian Hennig
> Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
> hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
>>From 1 April 2005: Department of Statistical Science, UCL, London
> #######################################################################
> ich empfehle www.boag-online.de
> 
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From deepayan at stat.wisc.edu  Thu Mar  3 00:29:10 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 2 Mar 2005 17:29:10 -0600
Subject: [R] Graphing question/possibly lattice/xyplot
In-Reply-To: <200503022224.j22MOnc29206@gator.dt.uh.edu>
References: <200503022224.j22MOnc29206@gator.dt.uh.edu>
Message-ID: <200503021729.10189.deepayan@stat.wisc.edu>

On Wednesday 02 March 2005 16:24, Erin Hodgess wrote:
> Dear R People:
> I have a data frame with the variables calories, sodium and "type",
> where type is either zero or one.
>
> I would like to produce a scatterplot with sodium on the horizontal,
> calories on the vertical and have the dots be clear when type is one
> and black when type is zero.
>
> It can be done via lines and points, but I was wondering if there is
> a better way with lattice graphics.

How about something like

xyplot(calories ~ sodium, 
       groups = type, 
       col = 'black',
       pch = c(16, 1))

? 

-Deepayan



From rcran.10.escoffier at antichef.net  Thu Mar  3 00:57:36 2005
From: rcran.10.escoffier at antichef.net (rcran.10.escoffier@antichef.net)
Date: Wed, 2 Mar 2005 15:57:36 -0800 (PST)
Subject: [R] power law distribution; making new distributions
Message-ID: <20050302235736.17428.qmail@web60007.mail.yahoo.com>

hi

i have data which i think is coming from a power law
distribution P(X > a) = c/a^k and i would like to find
the exponent and constant. i would like it to use my
experimental data to find c and k.  

also, if i would like to create a new distribution, is
it easy to add to R, if so, how is that done?

thanks
-gong
	
__________________________________ 



From vograno at evafunds.com  Thu Mar  3 01:25:06 2005
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Wed, 2 Mar 2005 16:25:06 -0800
Subject: [R] total variation penalty
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A58FEEC0@phost015.EVAFUNDS.intermedia.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050302/d8a63064/attachment.pl

From spencer.graves at pdf.com  Thu Mar  3 01:58:48 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 02 Mar 2005 16:58:48 -0800
Subject: [R] power law distribution; making new distributions
In-Reply-To: <20050302235736.17428.qmail@web60007.mail.yahoo.com>
References: <20050302235736.17428.qmail@web60007.mail.yahoo.com>
Message-ID: <42266148.60509@pdf.com>

      You've cited one form of the Pareto distribution 
(http://mathworld.wolfram.com/ParetoDistribution.html).  A slightly 
different form is available in Jim Lindsey's package "rmutil".  This is 
not available CRAN, but can be assessed by "www.r-project.org" -> search 
-> "R site search" -> "Jim Lindsey's packages". 

      Regarding adding a new distribution to R, you can follow this 
example from Lindsey or the skewed t distribution in package "skewt".  
See the documentation on "Writing R Extensions".  I don't know the 
protocol for contributing something to CRAN. 

      hope this helps. 
      spencer graves

rcran.10.escoffier at antichef.net wrote:

>hi
>
>i have data which i think is coming from a power law
>distribution P(X > a) = c/a^k and i would like to find
>the exponent and constant. i would like it to use my
>experimental data to find c and k.  
>
>also, if i would like to create a new distribution, is
>it easy to add to R, if so, how is that done?
>
>thanks
>-gong
>
>
>__________________________________ 
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From roger at ysidro.econ.uiuc.edu  Thu Mar  3 03:30:26 2005
From: roger at ysidro.econ.uiuc.edu (roger koenker)
Date: Wed, 2 Mar 2005 20:30:26 -0600
Subject: [R] total variation penalty
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A58FEEC0@phost015.EVAFUNDS.intermedia.net>
References: <C698D707214E6F4AB39AB7096C3DE5A58FEEC0@phost015.EVAFUNDS.intermedia.net>
Message-ID: <741a361ba579ea658a92d0378dee8adc@ysidro.econ.uiuc.edu>


On Mar 2, 2005, at 6:25 PM, Vadim Ogranovich wrote:
>
> I was recently plowing through the docs of the quantreg package by 
> Roger
> Koenker and came across the total variation penalty approach to
> 1-dimensional spline fitting. I googled around a bit and have found 
> some
> papers originated in the image processing community, but (apart from
> Roger's papers) no paper that would discuss its statistical aspects.

You might look at

@article{davi:kova:2001,
     Author = {Davies, P. L. and Kovac, A.},
     Title = {Local Extremes, Runs, Strings and Multiresolution},
     Year = 2001,
     Journal = {The Annals of Statistics},
     Volume = 29,
     Number = 1,
     Pages = {1--65},
     Keywords = {[62G07 (MSC2000)]; [65D10 (MSC2000)]; [62G20 (MSC2000)];
                [nonparametric regression]; [local extremes]; [runs];
                [strings]; [multiresolution analysis]; [asymptotics];
                [outliers]; [low power peaks]; nonparametric function
                estimation}
}
They are using total variation of the function rather than total 
variation of its derivative
as in the KNP paper mentioned below, but there are close connections 
between the
methods.

There are several recent  papers on what Tibshirani calls the lasso vs 
other penalties for
regression problems... for example:

@article{knig:fu:2000,
     Author = {Knight, Keith and Fu, Wenjiang},
     Title = {Asymptotics for Lasso-type Estimators},
     Year = 2000,
     Journal = {The Annals of Statistics},
     Volume = 28,
     Number = 5,
     Pages = {1356--1378},
     Keywords = {[62J05 (MSC1991)]; [62J07 (MSC1991)]; [62E20 (MSC1991)];
                [60F05 (MSC1991)]; [Penalized regression]; [Lasso];
                [shrinkage estimation]; [epi-convergence in 
distribution];
                neural network models}
}
@article{fan:li:2001,
     Author = {Fan, Jianqing and Li, Runze},
     Title = {Variable Selection Via Nonconcave Penalized Likelihood and 
Its
             Oracle Properties},
     Year = 2001,
     Journal = {Journal of the American Statistical Association},
     Volume = 96,
     Number = 456,
     Pages = {1348--1360},
     Keywords = {[HARD THRESHOLDING]; [LASSO]; [NONNEGATIVE GARROTE];
                [PENALIZED LIKELIHOOD]; [ORACLE ESTIMATOR]; [SCAD]; [SOFT


>
> I have a couple of questions in this regard:
> * Is it more natural to consider the total variation penalty in the
> context of quantile regression than in the context of OLS?

Not especially, see the lasso literature which is predominantly based
on Gaussian likelihood.  The taut string idea is also based on Gaussian
fidelity, at least in its original form.  There are some computational
conveniences involved in using l1 penalties with l1 fidelities, but with
the development of modern interior point algorithms, l1 vs l2 fidelity 
isn't really
much of a distinction.  The real question is:  do you believe in that 
old
time religion, do you have that Gaussian faith?  I don't.

> * Could someone please point to a good overview paper on the subject?
> Ideally something that compares merits of different penalty functions.

See above....
>
> Threre seems to be an ongoing effort to generalize this approach to 2d,
> but at this time I am more interested in 1-d smoothing.
>
For the sake of completeness, the additive model component of quantreg 
is
based primarily on the following two papers:


@article{koen:ng:port:1994,
     Author = {Koenker, Roger and Ng, Pin and Portnoy, Stephen},
     Title = {Quantile Smoothing Splines},
     Year = 1994,
     Journal = {Biometrika},
     Volume = 81,
     Pages = {673--680}
}

@article{KM.04,
         Author = {Koenker, R. and I. Mizera},
         Title = {Penalized Triograms:  Total Variation Regularization 
for Bivariate Smoothing},
         Journal = JRSS-B,
         Volume = 66,
         Pages = {145--163},
         Year = 2004
}

> url:    www.econ.uiuc.edu/~roger                Roger Koenker
> email   rkoenker at uiuc.edu                       Department of Economics
> vox:    217-333-4558                            University of Illinois
> fax:    217-244-6678                            Champaign, IL 61820



From jsekhon at fas.harvard.edu  Thu Mar  3 07:27:22 2005
From: jsekhon at fas.harvard.edu (Jasjeet Sekhon)
Date: Thu, 3 Mar 2005 01:27:22 -0500 (EST)
Subject: [R] Rounding parameter values in genoud(), Rgenoud package
Message-ID: <Pine.LNX.4.58.0503030125430.28846@ls04.fas.harvard.edu>


Hi Scott,

> I would like genoud to internally limit parameters to 4 decimal
> places as shown in this output.

Thanks for the question.  I don't know what your application is but
you may want to use the integer datatype (data.type.int=TRUE) and then
rescale the parameters in your function to provide the decimal
resolution you would like.  For example, set the genoud bounds so a
given parameter can range from -1,000,000 to 1,000,000 but in your fit
function divide the parameter by 10,000 so it actually ranges from
-100 to 100 and allows for four decimal places.  Judging from the
numbers you have printed, you could probably get away with the genoud
range being just -100,000 to 100,000 etc.

For example, set the "default.domains=100,000" or use the Domains
option to set individual parameter specific bounds; set
"data.type.int=TRUE"; and in your fit function:

FitFunction <- function(PARMS)
  {
    PARMS <- PARMS/10000
    [....your code....]
  }

Cheers, Jas.

======================================
Jasjeet S. Sekhon
Associate Professor
Harvard University
Institute for Quantitative
  Social Science
jasjeet_sekhon at harvard.edu
http://jsekhon.fas.harvard.edu/
Office: 617.496.2426 Fax: 617.507.5524
======================================





> From: "Waichler, Scott R" <Scott.Waichler at pnl.gov>
> Date: March 2, 2005 1:01:01 PM CST
> To: r-help at stat.math.ethz.ch
> Subject: [R] Rounding parameter values in genoud(), Rgenoud package
>
>
> I would like to limit the significant figures of the calibrated
> parameters determined by genoud() in the Rgenoud package.  Below is
> some
> example output, where column 1 is model run number, columns 2-7 are the
> parameter values, and columns 8-12 are model fit statistics.  I would
> like genoud to internally limit parameters to 4 decimal places as shown
> in this output.  It is clear that the function is generating many
> parameter sets that are identical after rounding.  Can I impose
> rounding
> on the function and thereby lessen processing time?  The only function
> argument that seems related is the solution.tolerance, but this is not
> for the parameter values.
>
> Run  par1    par2     par3     par4    par5     par6     Bias    MAE
> R2       E2       E1'
> 507 0.0239 0.0219 0.0267 0.0274 0.0283 0.0245 -0.0112 0.0804 0.9994
> 0.9994 0.9792
> 508 0.0239 0.0219 0.0267 0.0274 0.0283 0.0245 -0.0112 0.0804 0.9994
> 0.9994 0.9792
> 509 0.0239 0.0219 0.0267 0.0274 0.0283 0.0245 -0.0112 0.0804 0.9994
> 0.9994 0.9792
> 510 0.0239 0.0219 0.0267 0.0274 0.0283 0.0245 -0.0112 0.0804 0.9994
> 0.9994 0.9792
> 511 0.0239 0.0219 0.0267 0.0274 0.0283 0.0245 -0.0112 0.0804 0.9994
> 0.9994 0.9792
> 512 0.0239 0.0219 0.0267 0.0274 0.0283 0.0245 -0.0112 0.0804 0.9994
> 0.9994 0.9792
> 513 0.0239 0.0219 0.0267 0.0274 0.0283 0.0245 -0.0112 0.0804 0.9994
> 0.9994 0.9792
> 514 0.0239 0.0219 0.0267 0.0274 0.0283 0.0245 -0.0112 0.0804 0.9994
> 0.9994 0.9792
> 515 0.0239 0.0219 0.0267 0.0274 0.0283 0.0245 -0.0112 0.0804 0.9994
> 0.9994 0.9792
> 516 0.0239 0.0219 0.0267 0.0274 0.0283 0.0245 -0.0112 0.0804 0.9994
> 0.9994 0.9792
>
> Thanks,
> Scott Waichler
> Senior Research Scientist
> Pacific Northwest National Laboratory
> Richland, WA   USA
> scott.waichler at pnl.gov
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From nkn at turing.une.edu.au  Thu Mar  3 07:32:24 2005
From: nkn at turing.une.edu.au (Nam-Ky Nguyen)
Date: Thu, 3 Mar 2005 17:32:24 +1100 (EST)
Subject: [R] Suppressing observation numbers
In-Reply-To: <Pine.LNX.4.61.0503022229020.5495@gannet.stats>
References: <50543.203.206.241.246.1109801668.squirrel@203.206.241.246>
	<Pine.LNX.4.61.0503022229020.5495@gannet.stats>
Message-ID: <33442.129.180.11.187.1109831544.squirrel@129.180.11.187>

Thank you VERY much for Brian's HINT and Rolf's ANSWER. NKN.

> On Thu, 3 Mar 2005, Nam-Ky Nguyen wrote:
>
>> Dear R gurus,
>>
>> Below is a part of the R output. Please consider the two lines:
>>> data
>>> model.matrix(m1)
>>
>> Is there a way of suppressing the observation numbers 1, 2, ...27 in the
>> output (I don't want these number to appear in the output)?
>
> Actually, these are the row names of a data frame, and the answer is yes.
> (Note: I _have_ answered your question!)
>
> If you meant to ask how to do it, here is a hint
>
> library(MASS); write.matrix(hills)
>
>>
>> Regards,
>> NKN
>>
>>> # Orthogonal blocking
>>> data=read.table("cut.txt",header=T)
>>> attach(data)
>>> data
>>   b x1 x2 x3
>> 1  1 -1 -1  0
>> 2  1 -1  0  1
>> 3  1 -1  1 -1
>> 4  1  0 -1  0
>> 5  1  0  0  1
>> 6  1  0  1 -1
>> 7  1  1 -1 -1
>> 8  1  1  0  0
>> 9  1  1  1  1
>> 10 2 -1 -1 -1
>> 11 2 -1  0  0
>> 12 2 -1  1  1
>> 13 2  0 -1  1
>> 14 2  0  0 -1
>> 15 2  0  1  0
>> 16 2  1 -1  0
>> 17 2  1  0  1
>> 18 2  1  1 -1
>> 19 3 -1 -1  1
>> 20 3 -1  0 -1
>> 21 3 -1  1  0
>> 22 3  0 -1 -1
>> 23 3  0  0  0
>> 24 3  0  1  1
>> 25 3  1 -1  1
>> 26 3  1  0 -1
>> 27 3  1  1  0
>>> b=factor(b)
>>> y=rnorm(27)
>>> x4=x1*x2
>>> x5=x1*x3
>>> x6=x2*x3
>>> x7=x1*x1
>>> x8=x2*x2
>>> x9=x3*x3
>>> options(contrasts=c("contr.sum","contr.poly"))
>>> m1=lm(y~b+x1+x2+x3+x4+x5+x6+x7+x8+x9)
>>> model.matrix(m1)
>>   (Intercept) b1 b2 x1 x2 x3 x4 x5 x6 x7 x8 x9
>> 1            1  1  0 -1 -1  0  1  0  0  1  1  0
>> 2            1  1  0 -1  0  1  0 -1  0  1  0  1
>> 3            1  1  0 -1  1 -1 -1  1 -1  1  1  1
>> 4            1  1  0  0 -1  0  0  0  0  0  1  0
>> 5            1  1  0  0  0  1  0  0  0  0  0  1
>> 6            1  1  0  0  1 -1  0  0 -1  0  1  1
>> 7            1  1  0  1 -1 -1 -1 -1  1  1  1  1
>> 8            1  1  0  1  0  0  0  0  0  1  0  0
>> 9            1  1  0  1  1  1  1  1  1  1  1  1
>> 10           1  0  1 -1 -1 -1  1  1  1  1  1  1
>> 11           1  0  1 -1  0  0  0  0  0  1  0  0
>> 12           1  0  1 -1  1  1 -1 -1  1  1  1  1
>> 13           1  0  1  0 -1  1  0  0 -1  0  1  1
>> 14           1  0  1  0  0 -1  0  0  0  0  0  1
>> 15           1  0  1  0  1  0  0  0  0  0  1  0
>> 16           1  0  1  1 -1  0 -1  0  0  1  1  0
>> 17           1  0  1  1  0  1  0  1  0  1  0  1
>> 18           1  0  1  1  1 -1  1 -1 -1  1  1  1
>> 19           1 -1 -1 -1 -1  1  1 -1 -1  1  1  1
>> 20           1 -1 -1 -1  0 -1  0  1  0  1  0  1
>> 21           1 -1 -1 -1  1  0 -1  0  0  1  1  0
>> 22           1 -1 -1  0 -1 -1  0  0  1  0  1  1
>> 23           1 -1 -1  0  0  0  0  0  0  0  0  0
>> 24           1 -1 -1  0  1  1  0  0  1  0  1  1
>> 25           1 -1 -1  1 -1  1 -1  1 -1  1  1  1
>> 26           1 -1 -1  1  0 -1  0 -1  0  1  0  1
>> 27           1 -1 -1  1  1  0  1  0  0  1  1  0
>> attr(,"assign")
>> [1]  0  1  1  2  3  4  5  6  7  8  9 10
>> attr(,"contrasts")
>> attr(,"contrasts")$b
>> [1] "contr.sum"
>>
>>
>>
>> --
>> Nam-Ky Nguyen, Senior Lecturer
>> School of Mathematics, Statistics and Computer Science
>> University of New England, Armidale NSW 2351 Australia
>> nkn at turing.une.edu.au              Tel: +612 6773 2763
>> http://turing.une.edu.au/~nkn      Fax: +612 6773 3312
>>
>> Please convert Word files to PDF files before sending them to me.
>> See http://www.gnu.org/philosophy/no-word-attachments.html
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


-- 
Nam-Ky Nguyen, Senior Lecturer
School of Mathematics, Statistics and Computer Science
University of New England, Armidale NSW 2351 Australia
nkn at turing.une.edu.au              Tel: +612 6773 2763
http://turing.une.edu.au/~nkn      Fax: +612 6773 3312

Please convert Word files to PDF files before sending them to me.
See http://www.gnu.org/philosophy/no-word-attachments.html



From h.y.wong at leeds.ac.uk  Thu Mar  3 10:54:26 2005
From: h.y.wong at leeds.ac.uk (Yan Wong)
Date: Thu, 3 Mar 2005 09:54:26 +0000
Subject: [R] Simple suggestion for improvement
Message-ID: <cd0ba916953aac943d128f67c48e7d20@leeds.ac.uk>

Hello,

Being relatively new to R, I often find myself searching for functions 
using help.search("term"). Why not have the command ??term invoke it in 
the same way as ?topic invokes index.search("topic")? Using a double 
question mark to invoke a wider search for a term seems relatively 
intuitive to me, and presumably would be trivial to implement.

Cheers

Yan Wong
Leeds University



From srjafar at yahoo.com  Thu Mar  3 10:56:59 2005
From: srjafar at yahoo.com (Seyed Reza Jafarzadeh)
Date: Thu, 3 Mar 2005 01:56:59 -0800 (PST)
Subject: [R] Negative binomial regression for count data
Message-ID: <20050303095659.72486.qmail@web31006.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050303/4dd153ae/attachment.pl

From jspc at novonordisk.com  Thu Mar  3 11:00:10 2005
From: jspc at novonordisk.com (JSPC (Jeppe Skytte Spicker))
Date: Thu, 3 Mar 2005 11:00:10 +0100
Subject: [R] Putting different colors on labels in plot (hclust)
Message-ID: <CE4C1B6620E59840BB07F6F12256AEDF026B6185@exdkba021.novo.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050303/6d1558c5/attachment.pl

From murdoch at stats.uwo.ca  Thu Mar  3 11:08:57 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 03 Mar 2005 10:08:57 +0000
Subject: [R] Simple suggestion for improvement
In-Reply-To: <cd0ba916953aac943d128f67c48e7d20@leeds.ac.uk>
References: <cd0ba916953aac943d128f67c48e7d20@leeds.ac.uk>
Message-ID: <q1od21tge7fg9g1ab1dd36pj6vo06sfmtu@4ax.com>

On Thu, 3 Mar 2005 09:54:26 +0000, Yan Wong <h.y.wong at leeds.ac.uk>
wrote :

>Hello,
>
>Being relatively new to R, I often find myself searching for functions 
>using help.search("term"). Why not have the command ??term invoke it in 
>the same way as ?topic invokes index.search("topic")? Using a double 
>question mark to invoke a wider search for a term seems relatively 
>intuitive to me, and presumably would be trivial to implement.

That's not a bad suggestion, but it might not be trivial to implement.
Right now the "?" is an operator that is parsed like other operators
such as "+":  it becomes a function call . To have "??" mean something
special would mean changes to the parser, or a special case to the
.helpForCall function that the "?" function calls.

Duncan Murdoch



From h.y.wong at leeds.ac.uk  Thu Mar  3 11:21:26 2005
From: h.y.wong at leeds.ac.uk (Yan Wong)
Date: Thu, 3 Mar 2005 10:21:26 +0000
Subject: [R] Simple suggestion for improvement
In-Reply-To: <q1od21tge7fg9g1ab1dd36pj6vo06sfmtu@4ax.com>
References: <cd0ba916953aac943d128f67c48e7d20@leeds.ac.uk>
	<q1od21tge7fg9g1ab1dd36pj6vo06sfmtu@4ax.com>
Message-ID: <fbb1f20f7e191ad81689ea258f9162b7@leeds.ac.uk>


On 3 Mar 2005, at 10:08, Duncan Murdoch wrote:

> That's not a bad suggestion, but it might not be trivial to implement.
> Right now the "?" is an operator that is parsed like other operators
> such as "+":  it becomes a function call . To have "??" mean something
> special would mean changes to the parser, or a special case to the
> .helpForCall function that the "?" function calls.

OK, I can see that. Adding another operator might be seen as too great 
a change to consider "trivial". But the second way (changing the 
function) seems a little "hacky" to me. Anyway, it is just a suggestion 
that would save me (and others) some typing time.

Thanks for replying to my original post,

Yan



From Friedrich.Leisch at tuwien.ac.at  Thu Mar  3 11:28:37 2005
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Thu, 3 Mar 2005 11:28:37 +0100
Subject: [R] Putting different colors on labels in plot (hclust)
In-Reply-To: <CE4C1B6620E59840BB07F6F12256AEDF026B6185@exdkba021.novo.dk>
References: <CE4C1B6620E59840BB07F6F12256AEDF026B6185@exdkba021.novo.dk>
Message-ID: <16934.59093.152410.966074@galadriel.ci.tuwien.ac.at>

>>>>> On Thu, 3 Mar 2005 11:00:10 +0100,
>>>>> JSPC (Jeppe Skytte Spicker) (J(SS) wrote:

  > Hi All R-helpers
  > This is my first (but probartly not last ;-) mail to R-help, so hello to everybody.

  > My problem: Is there a way to give colors to the labels (sample labels) in plots for a hclust object for better visualization?

  > I have looked through plot, points, hclust and more but cannot find anything on label color. Anybody know if this is doable?

Have a look at example(dendrogram).

Hth,

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch



From r.hankin at soc.soton.ac.uk  Thu Mar  3 10:31:16 2005
From: r.hankin at soc.soton.ac.uk (Robin Hankin)
Date: Thu, 3 Mar 2005 09:31:16 +0000
Subject: [R] [R-pkgs] new package: ResistorArray
Message-ID: <207fa1db08ad58cc37bcf4eceb887741@soc.soton.ac.uk>

Announcing the release of a new R package ResistorArray.


This package solves the (nontrivial) general problem of resistance on 
arbitrary (finite)
resistor arrays.

Outside electrical engineering, the problem has a wide range of 
applications to
situations such as groundwater modelling; there is a direct 
correspondence
between electrical networks and random walks.

The package has a reasonably complete set of literature references, and 
solves a number
of classical problems such as the resistance between opposite points of 
a skeleton resistor
cube, and the Wheatstone bridge.

The package comes with a variety of standard resistor arrays, including 
all five platonic
solids, the Fibonacci ladder, and "N" arbitrary resistors in series.

The package gives nice numerical illustrations of a few theoretical 
results from the
recent (2004) literature.

One of the Google aptitude tests was to determine the electrical 
resistance between two points
on an infinite grid of resistors. I couldn't solve this problem 
analytically (although I found the
other day that a solution does exist);  ResistorArray gets the answer 
correct to within about 1%.



--
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From francoisromain at free.fr  Thu Mar  3 12:00:24 2005
From: francoisromain at free.fr (Romain Francois)
Date: Thu, 03 Mar 2005 12:00:24 +0100
Subject: [R] Putting different colors on labels in plot (hclust)
In-Reply-To: <CE4C1B6620E59840BB07F6F12256AEDF026B6185@exdkba021.novo.dk>
References: <CE4C1B6620E59840BB07F6F12256AEDF026B6185@exdkba021.novo.dk>
Message-ID: <4226EE48.2070605@free.fr>

Le 03.03.2005 11:00, JSPC (Jeppe Skytte Spicker) a ?crit :

>Hi All R-helpers
>
>This is my first (but probartly not last ;-) mail to R-help, so hello to everybody.
>
>My problem: Is there a way to give colors to the labels (sample labels) in plots for a hclust object for better visualization?
>
>I have looked through plot, points, hclust and more but cannot find anything on label color. Anybody know if this is doable?
>
>Best regards Jeppe
>
>___________________________________
>
>Jeppe Skytte Spicker
>Ph.d. student
>Virology and Molecular Toxicology
>
>Novo Nordisk A/S
>Novo Nordisk Park
>DK-2760 M?l?v
>Denmark
>44438733 (direct)
>jspc at novonordisk.dk
>
>  
>
Hello,

if you mean smoething like : http://addictedtor.free.fr/images600x300/image4.png
i have a couple of functions to do that available at : http://addictedtor.free.fr/Download/A2R.zip
this is not an R package, you must unzip the file an source all the *.R files
I guarantee nothing, it's been a while since i used them.

I used it in that document :
http://addictedtor.free.fr/biblio/projetClassif1_-_classification.automatique.pdf
Source code is on the end


Romain


-- 
Romain FRANCOIS : francoisromain at free.fr
page web : http://addictedtor.free.fr/  (en construction)
06 18 39 14 69 / 01 46 80 65 60
_______________________________________________________
Etudiant en 3eme ann?e
Institut de Statistique de l'Universit? de Paris (ISUP)
Fili?re Industrie et Services
http://www.isup.cicrp.jussieu.fr/



From buser at stat.math.ethz.ch  Thu Mar  3 12:08:24 2005
From: buser at stat.math.ethz.ch (Christoph Buser)
Date: Thu, 3 Mar 2005 12:08:24 +0100
Subject: [R] wilcox.test statistics
In-Reply-To: <BAY104-F393D0908989D155C925F1CE85A0@phx.gbl>
References: <BAY104-F393D0908989D155C925F1CE85A0@phx.gbl>
Message-ID: <16934.61480.388829.140153@stat.math.ethz.ch>

Hi,

a value of 0 for the test statistic is possible. The test
statistic is not just the sum of ranks, but this sum - n*(n+1)/2,
where n is the number of observations of the group the rank sum
is build.
This statistic is equivalent to the ranks sums, since it
differs only about a constant, which depends on the number of
observations.
Look at the following situation

> x <- 1:10
> y <- 11:20
> wilcox.test(x,y)
Wilcoxon rank sum test

data:  x and y 
W = 0, p-value = 1.083e-05
alternative hypothesis: true mu is not equal to 0 

When every observation of group1 is smaller than those of group2
the rank sum of the smaller group is
sum(1:n1) = sum(1:10) = 10*(10+1)/2 = n1*(n1+1)/2 
If you compare this to the test statistics, you'll observe that
in this case the test statistic is 0.

Regards,

Christoph Buser

--------------------------------------------------------------
Christoph Buser <buser at stat.math.ethz.ch>
Seminar fuer Statistik, LEO C11
ETH (Federal Inst. Technology)	8092 Zurich	 SWITZERLAND
phone: x-41-1-632-5414		fax: 632-1228
http://stat.ethz.ch/~buser/
--------------------------------------------------------------


Liu Ting-Yuan writes:
 > 
 > Hi,
 > 
 > Could anyone provide the formula of the statistics which the wilcox.test 
 > used for the two-sample rank-sum test?  I got some statistics of 0 values, 
 > but it is impossible to have 0 "rank-sum".  Does the function use the 
 > Mann-Whitney U test statistics?  Thanks.
 > 
 > Ting-Yuan Liu
 > 
 > ______________________________________________
 > R-help at stat.math.ethz.ch mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From pensterfuzzer at yahoo.de  Thu Mar  3 12:49:25 2005
From: pensterfuzzer at yahoo.de (Werner Wernersen)
Date: Thu, 3 Mar 2005 12:49:25 +0100 (CET)
Subject: [R] R Site Search Firefox Plugin
Message-ID: <20050303114925.57821.qmail@web25807.mail.ukl.yahoo.com>

Hi!

I have made a simple plugin for the Firefox search bar
which searches via R Site 
Search. I submitted it weeks ago to Mozilla.org but
they don't seem to respond. 
Thus, if anybody is interested, please let me know.
Maybe we could also find 
some space on a ftp server for it.

Best,
   Werner

P.S.: This might be the newbiest of all newbie
questions you've heard: Is there 
some overview over all official packages which gives
insight into the functions 
(names and functionality) available? Right now it is
more or less by accident 
that I find a function or package by searching R Site Search.



From Raquel.Granell at bristol.ac.uk  Thu Mar  3 13:09:14 2005
From: Raquel.Granell at bristol.ac.uk (R Granell, Medicine)
Date: Thu, 03 Mar 2005 12:09:14 -0000
Subject: [R] minimizing multivariate functions
Message-ID: <7697203.1109851754@rhu5.med.bris.ac.uk>


Is there any implicit function in R to minimize a
function with many variables?

Many thanks
Raquel

----------------------
R Granell, Rheumatology Unit & School of Mathematics
University of Bristol
Raquel.Granell at bristol.ac.uk
Tel:07968079410



From dimitris.rizopoulos at med.kuleuven.ac.be  Thu Mar  3 13:23:57 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Thu, 3 Mar 2005 13:23:57 +0100
Subject: [R] minimizing multivariate functions
References: <7697203.1109851754@rhu5.med.bris.ac.uk>
Message-ID: <005601c51feb$df290430$0540210a@www.domain>

maybe you could find `?optim' useful.


Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "R Granell, Medicine" <Raquel.Granell at bristol.ac.uk>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, March 03, 2005 1:09 PM
Subject: [R] minimizing multivariate functions


>
> Is there any implicit function in R to minimize a
> function with many variables?
>
> Many thanks
> Raquel
>
> ----------------------
> R Granell, Rheumatology Unit & School of Mathematics
> University of Bristol
> Raquel.Granell at bristol.ac.uk
> Tel:07968079410
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From bettina.kulle at medisin.uio.no  Thu Mar  3 14:20:45 2005
From: bettina.kulle at medisin.uio.no (Bettina Kulle)
Date: Thu, 03 Mar 2005 14:20:45 +0100
Subject: [R] calculating of linkage-disequilibrium measures?
Message-ID: <42270F2D.2030504@medisin.uio.no>

Hi ,
is it possible to calculate ld-measures D, D', r and
perhaps corresponding p-values with r IF THE
PHASE IS KNOWN?
The genetics - package provides the LD function
only for ambigious phase.

Thank you very much

Bettina Kulle



From vmuggeo at dssm.unipa.it  Thu Mar  3 14:50:40 2005
From: vmuggeo at dssm.unipa.it (vito muggeo)
Date: Thu, 03 Mar 2005 14:50:40 +0100
Subject: [R] Negative binomial regression for count data
In-Reply-To: <20050303095659.72486.qmail@web31006.mail.mud.yahoo.com>
References: <20050303095659.72486.qmail@web31006.mail.mud.yahoo.com>
Message-ID: <42271630.1010503@dssm.unipa.it>

Hi,
I do not know the article. Notice that an excess of zeroes can lead to 
(spurious) overdispersion in data, therefore you should decide whether 
assuming a zip ( zero excess coming from a "mixture") or a negBin (zero 
execess due to overdispersion) model. Of course some likelihood based 
criteria (eg AIC) could be of help for you

However it is possible (at least in principle) to account for both extra 
zeros  and overdispersion as well. S. Jackman has written code to fit 
zip or zinb regression models http://pscl.stanford.edu/zeroinfl.r You 
should modify the code if you want to assume different "linear 
predictors" in the logit (zero vs non/zero) and count part

Hope this helps,
vito



Seyed Reza Jafarzadeh wrote:
> Dear list,
>  
> I would like to fit a negative binomial regression model as described in "Byers AL, Allore H, Gill TM, Peduzzi PN., Application of negative binomial modeling for discrete outcomes: a case study in aging research. J Clin Epidemiol. 2003 Jun;56(6):559-64"  to my data in which the response is count data. There are also 10 predictors that are count data, and I have also 3 categorical and 2 continious predictors. There is overdispersion in the distribution of the response variable (mean=2.8, variance=28) as well as in predictors, and there are a lot of zero's (zero-inflated).
> The authors of that paper used PROC GENMOD in SAS 8.1. I wonder which of the following packages and tests to use in R to acheive such model for my analysis. Is there any tutorial available?
>  
> 
> anova.negbin 
>    Likelihood Ratio Tests for Negative Binomial GLMs 
> glm.convert 
>    Change a Negative Binomial fit to a GLM fit 
> glm.nb 
>    Fit a Negative Binomial Generalized Linear Model 
> negative.binomial 
>    Family function for Negative Binomial GLMs 
> rnegbin 
>    Simulate Negative Binomial Variates 
> theta.md 
>    Estimate theta of the Negative Binomial 
> gam.neg.bin 
>    GAMs with the negative binomial distribution 
> dnb2 
>    Density for negative binomial, used in mmlcr 
> theta.mmmod 
>    Estimate theta of the Negative Binomial by Moments 
> NegBinomial 
>    The Negative Binomial Distribution 
> ezinb 
>    The expected value of the censored zero-inflated negative binomial model
> 
>  
> 
> Thanks,
> 
> Reza
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
====================================
Vito M.R. Muggeo
Dip.to Sc Statist e Matem `Vianelli'
Universit? di Palermo
viale delle Scienze, edificio 13
90121 Palermo - ITALY
tel: 091 6626240
fax: 091 485726/485612



From R.P.Clement at westminster.ac.uk  Thu Mar  3 20:04:15 2005
From: R.P.Clement at westminster.ac.uk (Ross Clement)
Date: 03 Mar 2005 14:04:15 -0500
Subject: [R] 3d plot of regression squared error
Message-ID: <1109876655.3311.92.camel@staff-pc01.harrowscs.westminster.ac.uk>

Hi. I'm trying to create a 3d plot for a teaching example of finding a
least-squares estimate of the parameters to fit a line to some data. I
was hoping to get a nice plot with a clear, single minima where the
derivative of the surface is zero. No matter how much I tinker, I can't
seem to get a simple straightforward plot. Am I doing something wrong?

Thanks in anticipation,

Ross-c

x <- c( 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 )
y <- c( 3, 4.2, 8.7, 11.7, 13.2, 19.1, 21, 25, 26.1, 29.8 )

sqe <- function( a, b ) {
   total <- 0
   for ( i in 1:length(x) ) {
       diff <- y[i] - a * x[i] + b
       total <- total + diff * diff
   }
   return( total )
}

df <- data.frame( x=x, y=y )

lm( y ~ x, df )

a.axis <- seq( -5, 10, length=20 )
b.axis <- seq( -20, 20, length=30 )

z <- outer( a.axis, b.axis, sqe )

persp( a.axis, b.axis, z, col="light grey", xlab="a", ylab="b",
zlab="sum.squared.error", theta=45 )



From pensterfuzzer at yahoo.de  Thu Mar  3 15:26:41 2005
From: pensterfuzzer at yahoo.de (Werner Wernersen)
Date: Thu, 3 Mar 2005 15:26:41 +0100 (CET)
Subject: [R] Re: R Site Search Firefox Plugin
Message-ID: <20050303142642.55909.qmail@web25802.mail.ukl.yahoo.com>

Hi again!

someone has kindly provided webspace for the R Site
Search plugin.
You'll find it here:
http://www.xyzump.de/rsitesearch.zip

Just extract the files to the
\Mozilla Firefox\searchplugins\
directory and restart Firefox.

Best,
   Werner



From gwgilc at wm.edu  Thu Mar  3 15:46:17 2005
From: gwgilc at wm.edu (George W. Gilchrist)
Date: Thu, 03 Mar 2005 09:46:17 -0500
Subject: [R] Baffled by drop1
Message-ID: <BE4C8D69.4C2E%gwgilc@wm.edu>

I've been experimenting with drop1 for my biostatistics class, to obtain the
so-called Type III sums of squares. I am fully aware of the deficiencies of
this method, however I feel that the students should be familiar with it.
What I find baffling is that when applied to a fully balanced design, you
obtain different sums of squares. I've used this for several years in Splus
and R and never encountered this before. Am I off my rocker? I have read the
help files and remain clueless. Thanks for any advice.

> replications(Wt~Sex*Par.trt, data=tmp1)
$Sex
[1] 22

$Par.trt
[1] 22

$"Sex:Par.trt"
   Par.trt
Sex  N  S
  F 11 11
  M 11 11

> summary(tmp2<-aov(Wt~Sex*Par.trt, data=tmp1))
            Df Sum Sq Mean Sq F value    Pr(>F)
Sex          1 215600  215600 31.5367 1.638e-06 ***
Par.trt      1   7127    7127  1.0425    0.3134
Sex:Par.trt  1  19236   19236  2.8138    0.1013
Residuals   40 273459    6836
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
> drop1(tmp2, ~., test="F")
Single term deletions

Model:
Wt ~ Sex * Par.trt
            Df Sum of Sq    RSS    AIC F value    Pr(F)
<none>                   273459    392
Sex          1     53018 326477    398  7.7552 0.008144 **
Par.trt      1      1473 274932    391  0.2154 0.645067
Sex:Par.trt  1     19236 292695    393  2.8138 0.101256
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
> 
==================================================================
George W. Gilchrist                        Email #1: gwgilc at wm.edu
Department of Biology, Box 8795          Email #2: kitesci at cox.net
College of William & Mary                    Phone: (757) 221-7751
Williamsburg, VA 23187-8795                    Fax: (757) 221-6483
http://gwgilc.people.wm.edu/



From gwgilc at wm.edu  Thu Mar  3 16:07:53 2005
From: gwgilc at wm.edu (George W. Gilchrist)
Date: Thu, 03 Mar 2005 10:07:53 -0500
Subject: [R] Baffled by drop1: Please ignore previous request!
Message-ID: <BE4C9279.4C37%gwgilc@wm.edu>

My apologies to the list for sending this without adequate research. I have
found my answer; please ignore! Thanks.

I've been experimenting with drop1 for my biostatistics class, to obtain the
so-called Type III sums of squares. I am fully aware of the deficiencies of
this method, however I feel that the students should be familiar with it.
What I find baffling is that when applied to a fully balanced design, you
obtain different sums of squares. I've used this for several years in Splus
and R and never encountered this before. Am I off my rocker? I have read the
help files and remain clueless. Thanks for any advice.

> replications(Wt~Sex*Par.trt, data=tmp1)
$Sex
[1] 22

$Par.trt
[1] 22

$"Sex:Par.trt"
   Par.trt
Sex  N  S
  F 11 11
  M 11 11

> summary(tmp2<-aov(Wt~Sex*Par.trt, data=tmp1))
            Df Sum Sq Mean Sq F value    Pr(>F)
Sex          1 215600  215600 31.5367 1.638e-06 ***
Par.trt      1   7127    7127  1.0425    0.3134
Sex:Par.trt  1  19236   19236  2.8138    0.1013
Residuals   40 273459    6836
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
> drop1(tmp2, ~., test="F")
Single term deletions

Model:
Wt ~ Sex * Par.trt
            Df Sum of Sq    RSS    AIC F value    Pr(F)
<none>                   273459    392
Sex          1     53018 326477    398  7.7552 0.008144 **
Par.trt      1      1473 274932    391  0.2154 0.645067
Sex:Par.trt  1     19236 292695    393  2.8138 0.101256
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
> 
==================================================================
George W. Gilchrist                        Email #1: gwgilc at wm.edu
Department of Biology, Box 8795          Email #2: kitesci at cox.net
College of William & Mary                    Phone: (757) 221-7751
Williamsburg, VA 23187-8795                    Fax: (757) 221-6483
http://gwgilc.people.wm.edu/



From drcarbon at gmail.com  Thu Mar  3 16:28:10 2005
From: drcarbon at gmail.com (Dr Carbon)
Date: Thu, 3 Mar 2005 10:28:10 -0500
Subject: [R] creating a formula on-the-fly inside a function
Message-ID: <e89bb7ac0503030728272c8e6c@mail.gmail.com>

I have a function that, among other things, runs a linear model and
returns r2. But, the number of predictor variables passed to the
function changes from 1 to 3. How can I change the formula inside the
function depending on the number of variables passed in?

An example:

get.model.fit <- function(response.dat, pred1.dat, pred2.dat = NULL,
pred3.dat = NULL)
{
    res <- lm(response.dat ~ pred1.dat + pred2.dat + pred3.dat)
    summary(res)$r.squared
    # other stuff happens here...
}

y <- rnorm(10)
x1 <- y + runif(10)
x2 <- y + runif(10)
x3 <- y + runif(10)
get.model.fit(y, x1, x2, x3)
get.model.fit(y, x1, x2)
get.model.fit(y, x1)

Many thanks....
DrC




> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    0.1            
year     2004           
month    11             
day      15             
language R



From SBist at LordAbbett.com  Thu Mar  3 16:43:48 2005
From: SBist at LordAbbett.com (Bist, Sandip)
Date: Thu, 3 Mar 2005 10:43:48 -0500 
Subject: [R] creating a formula on-the-fly inside a function
Message-ID: <BCB019F368866A479696C25C8F0B3AEB03976B0B@la-mail3.lordabbett.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050303/043b20ff/attachment.pl

From MSchwartz at MedAnalytics.com  Thu Mar  3 16:52:26 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu, 03 Mar 2005 09:52:26 -0600
Subject: [R] creating a formula on-the-fly inside a function
In-Reply-To: <e89bb7ac0503030728272c8e6c@mail.gmail.com>
References: <e89bb7ac0503030728272c8e6c@mail.gmail.com>
Message-ID: <1109865147.29733.16.camel@horizons.localdomain>

On Thu, 2005-03-03 at 10:28 -0500, Dr Carbon wrote:
> I have a function that, among other things, runs a linear model and
> returns r2. But, the number of predictor variables passed to the
> function changes from 1 to 3. How can I change the formula inside the
> function depending on the number of variables passed in?
> 
> An example:
> 
> get.model.fit <- function(response.dat, pred1.dat, pred2.dat = NULL,
> pred3.dat = NULL)
> {
>     res <- lm(response.dat ~ pred1.dat + pred2.dat + pred3.dat)
>     summary(res)$r.squared
>     # other stuff happens here...
> }
> 
> y <- rnorm(10)
> x1 <- y + runif(10)
> x2 <- y + runif(10)
> x3 <- y + runif(10)
> get.model.fit(y, x1, x2, x3)
> get.model.fit(y, x1, x2)
> get.model.fit(y, x1)


Consider using as.formula() to take a character vector that you pass as
an argument instead of specifying each IV separately:

get.model.fit <- function(my.form)
{
    res <- lm(as.formula(my.form))
    summary(res)$r.squared
    # other stuff happens here...
}


Then call it with:

get.model.fit("y ~ x1 + x2 + x3")

Internally, the vector will be converted to:

> as.formula("y ~ x1 + x2 + x3")
y ~ x1 + x2 + x3

Doing it this way provides for greater flexibility if you want to use a
more complicated formula construct.

See ?as.formula for more information and further examples, including the
use of paste() if you want to separate the DV from the IVs for an
additional approach for a long set of similarly named IV's (ie x1:x25).

HTH,

Marc Schwartz



From ggrothendieck at myway.com  Thu Mar  3 16:57:21 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 3 Mar 2005 15:57:21 +0000 (UTC)
Subject: [R] creating a formula on-the-fly inside a function
References: <e89bb7ac0503030728272c8e6c@mail.gmail.com>
Message-ID: <loom.20050303T165448-537@post.gmane.org>

Dr Carbon <drcarbon <at> gmail.com> writes:

: 
: I have a function that, among other things, runs a linear model and
: returns r2. But, the number of predictor variables passed to the
: function changes from 1 to 3. How can I change the formula inside the
: function depending on the number of variables passed in?
: 
: An example:
: 
: get.model.fit <- function(response.dat, pred1.dat, pred2.dat = NULL,
: pred3.dat = NULL)
: {
:     res <- lm(response.dat ~ pred1.dat + pred2.dat + pred3.dat)
:     summary(res)$r.squared
:     # other stuff happens here...
: }


The following allows any number of predictors:

 f <- function(y, ...) summary(lm(y ~., data.frame(y = y, ...)))$r.squared

Another possibility is to just pass the formula itself:

 f <- function(fo) summary(lm(fo))$r.squared



From W.E.Wolski at ncl.ac.uk  Thu Mar  3 17:27:40 2005
From: W.E.Wolski at ncl.ac.uk (Witold Eryk Wolski)
Date: Thu, 03 Mar 2005 17:27:40 +0100
Subject: [R] Hot to _set_ an xmlAttr XML xmlAttr set
Message-ID: <42273AFC.9040700@ncl.ac.uk>

Dear R-Gurus!

I have read an xml document with
xmlTreeParse

and can access that attribute value by
xmlGetAttr
or
xmlAttrs

What I want to do is to set a new value and to write the modified DOM 
tree into an XML file.

But until now I have not found an setter method equivalent to the getter 
method?



Eryk



-- 
Witold Eryk Wolski
__("<  School of Mathematics and Statistics     _
\__/   University of Newcastle                 'v'
 ||    Newcastle upon Tyne, NE1 7RU, ENGLAND  /   \
 ^^    mail: witek96 at users.sourceforge.net     m m
       Phone : 044 (0)191 222 5376
       FAX   : 044 (0)191 222 8020



From christoph.lehmann at gmx.ch  Thu Mar  3 17:29:35 2005
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Thu, 03 Mar 2005 17:29:35 +0100
Subject: [R] plot question
Message-ID: <42273B6F.5060801@gmx.ch>

I have the following simple situation:

tt <- data.frame(c(0.5, 1, 0.5))
names(tt) <- "a"
plot(tt$a, type = 'o')

gives the following plot ('I' and '.' represent the axis):

I
I
I     X
I
I
I X       X
I...........
   1   2   3

what do I have to change to get the following:


I
I
I          X
I
I
I      X       X
I.....................
        1   2   3

i.e. the plot-region should be widened at the left and right side

thanks for a hint

christoph



From deepayan at stat.wisc.edu  Thu Mar  3 17:18:07 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 3 Mar 2005 10:18:07 -0600
Subject: [R] 3d plot of regression squared error
In-Reply-To: <1109876655.3311.92.camel@staff-pc01.harrowscs.westminster.ac.uk>
References: <1109876655.3311.92.camel@staff-pc01.harrowscs.westminster.ac.uk>
Message-ID: <200503031018.07512.deepayan@stat.wisc.edu>

On Thursday 03 March 2005 13:04, Ross Clement wrote:
> Hi. I'm trying to create a 3d plot for a teaching example of finding
> a least-squares estimate of the parameters to fit a line to some
> data. I was hoping to get a nice plot with a clear, single minima
> where the derivative of the surface is zero. No matter how much I
> tinker, I can't seem to get a simple straightforward plot. Am I doing
> something wrong?
>
> Thanks in anticipation,
>
> Ross-c
>
> x <- c( 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 )
> y <- c( 3, 4.2, 8.7, 11.7, 13.2, 19.1, 21, 25, 26.1, 29.8 )

Well, you need to go far enough away to see the curve. Centering the 
x-variable is important (at least with your parametrization of straight 
lines). E.g., the following combination gives a surface that looks nice 
enough:

x <- 1:10 - 5.5
a.axis <- seq( 0, 10, length=20 ) 
b.axis <- seq( -30, 0, length=20 )

-Deepayan

> sqe <- function( a, b ) {
>    total <- 0
>    for ( i in 1:length(x) ) {
>        diff <- y[i] - a * x[i] + b
>        total <- total + diff * diff
>    }
>    return( total )
> }
>
> df <- data.frame( x=x, y=y )
>
> lm( y ~ x, df )
>
> a.axis <- seq( -5, 10, length=20 )
> b.axis <- seq( -20, 20, length=30 )
>
> z <- outer( a.axis, b.axis, sqe )
>
> persp( a.axis, b.axis, z, col="light grey", xlab="a", ylab="b",
> zlab="sum.squared.error", theta=45 )



From gunter.berton at gene.com  Thu Mar  3 17:41:07 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Thu, 3 Mar 2005 08:41:07 -0800
Subject: [R] creating a formula on-the-fly inside a function
In-Reply-To: <1109865147.29733.16.camel@horizons.localdomain>
Message-ID: <200503031641.j23Gf8eT009301@compton.gene.com>

If these are nested models, see ?drop.terms. 


-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Marc Schwartz
> Sent: Thursday, March 03, 2005 7:52 AM
> To: Dr Carbon
> Cc: r-help at r-project.org
> Subject: Re: [R] creating a formula on-the-fly inside a function
> 
> On Thu, 2005-03-03 at 10:28 -0500, Dr Carbon wrote:
> > I have a function that, among other things, runs a linear model and
> > returns r2. But, the number of predictor variables passed to the
> > function changes from 1 to 3. How can I change the formula 
> inside the
> > function depending on the number of variables passed in?
> > 
> > An example:
> > 
> > get.model.fit <- function(response.dat, pred1.dat, pred2.dat = NULL,
> > pred3.dat = NULL)
> > {
> >     res <- lm(response.dat ~ pred1.dat + pred2.dat + pred3.dat)
> >     summary(res)$r.squared
> >     # other stuff happens here...
> > }
> > 
> > y <- rnorm(10)
> > x1 <- y + runif(10)
> > x2 <- y + runif(10)
> > x3 <- y + runif(10)
> > get.model.fit(y, x1, x2, x3)
> > get.model.fit(y, x1, x2)
> > get.model.fit(y, x1)
> 
> 
> Consider using as.formula() to take a character vector that 
> you pass as
> an argument instead of specifying each IV separately:
> 
> get.model.fit <- function(my.form)
> {
>     res <- lm(as.formula(my.form))
>     summary(res)$r.squared
>     # other stuff happens here...
> }
> 
> 
> Then call it with:
> 
> get.model.fit("y ~ x1 + x2 + x3")
> 
> Internally, the vector will be converted to:
> 
> > as.formula("y ~ x1 + x2 + x3")
> y ~ x1 + x2 + x3
> 
> Doing it this way provides for greater flexibility if you 
> want to use a
> more complicated formula construct.
> 
> See ?as.formula for more information and further examples, 
> including the
> use of paste() if you want to separate the DV from the IVs for an
> additional approach for a long set of similarly named IV's 
> (ie x1:x25).
> 
> HTH,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From MSchwartz at MedAnalytics.com  Thu Mar  3 17:44:49 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu, 03 Mar 2005 10:44:49 -0600
Subject: [R] plot question
In-Reply-To: <42273B6F.5060801@gmx.ch>
References: <42273B6F.5060801@gmx.ch>
Message-ID: <1109868290.29733.33.camel@horizons.localdomain>

On Thu, 2005-03-03 at 17:29 +0100, Christoph Lehmann wrote:
> I have the following simple situation:
> 
> tt <- data.frame(c(0.5, 1, 0.5))
> names(tt) <- "a"
> plot(tt$a, type = 'o')
> 
> gives the following plot ('I' and '.' represent the axis):
> 
> I
> I
> I     X
> I
> I
> I X       X
> I...........
>    1   2   3
> 
> what do I have to change to get the following:
> 
> 
> I
> I
> I          X
> I
> I
> I      X       X
> I.....................
>         1   2   3
> 
> i.e. the plot-region should be widened at the left and right side
> 
> thanks for a hint


Use 'xlim' to specify the range of the x axis:

plot(c(0.5, 1, 0.5), type = 'o', xlim = c(0, 4))

See ?par for more information.

HTH,

Marc Schwartz



From james.holtman at convergys.com  Thu Mar  3 17:46:15 2005
From: james.holtman at convergys.com (james.holtman@convergys.com)
Date: Thu, 3 Mar 2005 11:46:15 -0500
Subject: [R] plot question
In-Reply-To: <42273B6F.5060801@gmx.ch>
Message-ID: <OF1C9C2B6F.BE669053-ON85256FB9.005C1849-85256FB9.005C2002@nd.convergys.com>





tt <- data.frame(c(0.5, 1, 0.5))
names(tt) <- "a"
plot(tt$a, type = 'o',xlim=c(0,4))

__________________________________________________________
James Holtman        "What is the problem you are trying to solve?"
Executive Technical Consultant  --  Office of Technology, Convergys
james.holtman at convergys.com
+1 (513) 723-2929


                                                                                                                                           
                      Christoph Lehmann                                                                                                    
                      <christoph.lehmann at gm        To:       r-help at stat.math.ethz.ch                                                      
                      x.ch>                        cc:                                                                                     
                      Sent by:                     Subject:  [R] plot question                                                             
                      r-help-bounces at stat.m                                                                                                
                      ath.ethz.ch                                                                                                          
                                                                                                                                           
                                                                                                                                           
                      03/03/2005 11:29                                                                                                     
                                                                                                                                           




I have the following simple situation:

tt <- data.frame(c(0.5, 1, 0.5))
names(tt) <- "a"
plot(tt$a, type = 'o')

gives the following plot ('I' and '.' represent the axis):

I
I
I     X
I
I
I X       X
I...........
   1   2   3

what do I have to change to get the following:


I
I
I          X
I
I
I      X       X
I.....................
        1   2   3

i.e. the plot-region should be widened at the left and right side

thanks for a hint

christoph

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From MSchwartz at MedAnalytics.com  Thu Mar  3 17:47:51 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu, 03 Mar 2005 10:47:51 -0600
Subject: [R] plot question
In-Reply-To: <1109868290.29733.33.camel@horizons.localdomain>
References: <42273B6F.5060801@gmx.ch>
	<1109868290.29733.33.camel@horizons.localdomain>
Message-ID: <1109868472.29733.35.camel@horizons.localdomain>

On Thu, 2005-03-03 at 10:44 -0600, Marc Schwartz wrote:

> See ?par for more information.

Correction, that should have been ?plot.default for more information,
though ?par has other relevant information on plot parameters as well.

Marc



From rsanges at tigem.it  Thu Mar  3 17:50:55 2005
From: rsanges at tigem.it (Remo Sanges)
Date: Thu, 3 Mar 2005 17:50:55 +0100
Subject: [R] plot question
In-Reply-To: <42273B6F.5060801@gmx.ch>
References: <42273B6F.5060801@gmx.ch>
Message-ID: <46197fda6ee3eb5615a68970b2dbf412@tigem.it>

On Mar 3, 2005, at 5:29 PM, Christoph Lehmann wrote:

> I have the following simple situation:
>
> tt <- data.frame(c(0.5, 1, 0.5))
> names(tt) <- "a"
> plot(tt$a, type = 'o')
>
> gives the following plot ('I' and '.' represent the axis):
>
> I
> I
> I     X
> I
> I
> I X       X
> I...........
>   1   2   3
>
> what do I have to change to get the following:
>
>
> I
> I
> I          X
> I
> I
> I      X       X
> I.....................
>        1   2   3
>
> i.e. the plot-region should be widened at the left and right side

What about:

plot(tt$a, type = 'o',xlim=c(0,4))

HTH

Remo



From ramasamy at cancer.org.uk  Thu Mar  3 18:17:34 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 03 Mar 2005 17:17:34 +0000
Subject: [R] Simple suggestion for improvement
In-Reply-To: <fbb1f20f7e191ad81689ea258f9162b7@leeds.ac.uk>
References: <cd0ba916953aac943d128f67c48e7d20@leeds.ac.uk>
	<q1od21tge7fg9g1ab1dd36pj6vo06sfmtu@4ax.com>
	<fbb1f20f7e191ad81689ea258f9162b7@leeds.ac.uk>
Message-ID: <1109870255.5978.24.camel@ramasamy.stats>

How will you deal with multiple word searches such as

	help.search("eps dev")

One way to implement would be ??"eps dev" but this looks awkward to me.

Regards, Adai


On Thu, 2005-03-03 at 10:21 +0000, Yan Wong wrote:
> On 3 Mar 2005, at 10:08, Duncan Murdoch wrote:
> 
> > That's not a bad suggestion, but it might not be trivial to implement.
> > Right now the "?" is an operator that is parsed like other operators
> > such as "+":  it becomes a function call . To have "??" mean something
> > special would mean changes to the parser, or a special case to the
> > .helpForCall function that the "?" function calls.
> 
> OK, I can see that. Adding another operator might be seen as too great 
> a change to consider "trivial". But the second way (changing the 
> function) seems a little "hacky" to me. Anyway, it is just a suggestion 
> that would save me (and others) some typing time.
> 
> Thanks for replying to my original post,
> 
> Yan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From mi2kelgrum at yahoo.com  Thu Mar  3 18:42:09 2005
From: mi2kelgrum at yahoo.com (Mikkel Grum)
Date: Thu, 3 Mar 2005 09:42:09 -0800 (PST)
Subject: [R] image() z-values beyond zlim
Message-ID: <20050303174209.85410.qmail@web60206.mail.yahoo.com>

Dear useRs,

When plotting with image(), I would like the z-values
that extend beyond the upper zlim to be indicated with
one colour, or preferably with som sort of hatching,
as I'm printing in black and white.  By default these
values just show up as blank areas in the image.  I've
tried all sorts of things, but nothing seems to work
for me.

Any solutions would be greatly appreciated.

cheers,
Mikkel



From Stephan.Freyberger at rwth-aachen.de  Thu Mar  3 18:45:02 2005
From: Stephan.Freyberger at rwth-aachen.de (Stephan Freyberger)
Date: Thu, 03 Mar 2005 17:45:02 +0000 (GMT)
Subject: [R] Plotting of 3D Point Sets
Message-ID: <18547d17f8e8.17f8e818547d@post.rwth-aachen.de>

Hi,

Trials have generated a vast number of points, which I would like 
to have plotted in 3D. They are in no particular order. I would be 
satisfied with just being able to see the points in a graph, much 
nicer, though, would be something as shown on the R Aqua 
screenshot page. Thanx in advance

Stephan



From soumyadeep_nandi at yahoo.com  Thu Mar  3 19:03:00 2005
From: soumyadeep_nandi at yahoo.com (Soumyadeep nandi)
Date: Thu, 3 Mar 2005 10:03:00 -0800 (PST)
Subject: [R] Need suggestions for plotting 3D plot
Message-ID: <20050303180301.47406.qmail@web52202.mail.yahoo.com>

Hi Everybody,
I am a newbie in R. I have a data in the form of a
matrix which I want to make some 3D plots using R.
There is some functions for instance hist() for 2D
plots, but I cant find any function for 3D plots. Is
there any function available in R for 3D plots? If so,
is there any documention available on internet so that
I can go through. 
With regards,
Soumyadeep



From Roger.Bivand at nhh.no  Thu Mar  3 19:10:47 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 3 Mar 2005 19:10:47 +0100 (CET)
Subject: [R] image() z-values beyond zlim
In-Reply-To: <20050303174209.85410.qmail@web60206.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0503031859180.25896-100000@reclus.nhh.no>

On Thu, 3 Mar 2005, Mikkel Grum wrote:

> Dear useRs,
> 
> When plotting with image(), I would like the z-values
> that extend beyond the upper zlim to be indicated with
> one colour, or preferably with som sort of hatching,
> as I'm printing in black and white.  By default these
> values just show up as blank areas in the image.  I've
> tried all sorts of things, but nothing seems to work
> for me.

Use the breaks= and col= arguments to do this, extending zlim= to be the 
range of z (or just drop it). Values of z outside zlim are made NA, and 
thus not included in the span of colours.

> 
> Any solutions would be greatly appreciated.
> 
> cheers,
> Mikkel
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From W.E.Wolski at ncl.ac.uk  Thu Mar  3 19:14:14 2005
From: W.E.Wolski at ncl.ac.uk (Witold Eryk Wolski)
Date: Thu, 03 Mar 2005 19:14:14 +0100
Subject: [R] Need suggestions for plotting 3D plot
In-Reply-To: <20050303180301.47406.qmail@web52202.mail.yahoo.com>
References: <20050303180301.47406.qmail@web52202.mail.yahoo.com>
Message-ID: <422753F6.1080603@ncl.ac.uk>

Hi,

http://www.stat.ucl.ac.be/ISpersonnel/lecoutre/stats/fichiers/_gallery.pdf

The document above starts showing 3 different types of  3D graphics

persp

scatterplot3d

wireframe




A few days ago there was a discussion here on the list about providing a 
"graph library".
During this discussion several resources of example code where mentioned 
( inter-alia that above).
So if you need more ideas follow search this e-mails.

cheers

Eryk



Soumyadeep nandi wrote:

>Hi Everybody,
>I am a newbie in R. I have a data in the form of a
>matrix which I want to make some 3D plots using R.
>There is some functions for instance hist() for 2D
>plots, but I cant find any function for 3D plots. Is
>there any function available in R for 3D plots? If so,
>is there any documention available on internet so that
>I can go through. 
>With regards,
>Soumyadeep
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>


-- 
Witold Eryk Wolski
__("<  School of Mathematics and Statistics     _
\__/   University of Newcastle                 'v'
 ||    Newcastle upon Tyne, NE1 7RU, ENGLAND  /   \
 ^^    mail: witek96 at users.sourceforge.net     m m
       Phone : 044 (0)191 222 5376
       FAX   : 044 (0)191 222 8020



From ramasamy at cancer.org.uk  Thu Mar  3 19:21:18 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 03 Mar 2005 18:21:18 +0000
Subject: [R] Plotting of 3D Point Sets
In-Reply-To: <18547d17f8e8.17f8e818547d@post.rwth-aachen.de>
References: <18547d17f8e8.17f8e818547d@post.rwth-aachen.de>
Message-ID: <1109874079.6604.21.camel@ramasamy.stats>

Try scatterplot3d() in the scatterplot3d package.

Alternatively try searching http://maths.newcastle.edu.au/~rking/R/

Regards, Adai



On Thu, 2005-03-03 at 17:45 +0000, Stephan Freyberger wrote:
> Hi,
> 
> Trials have generated a vast number of points, which I would like 
> to have plotted in 3D. They are in no particular order. I would be 
> satisfied with just being able to see the points in a graph, much 
> nicer, though, would be something as shown on the R Aqua 
> screenshot page. Thanx in advance
> 
> Stephan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From vivekrao4 at yahoo.com  Thu Mar  3 21:09:24 2005
From: vivekrao4 at yahoo.com (Vivek Rao)
Date: Thu, 3 Mar 2005 12:09:24 -0800 (PST)
Subject: [R] stdev, skew, kurtosis, ACF from summary function?
In-Reply-To: <1109876655.3311.92.camel@staff-pc01.harrowscs.westminster.ac.uk>
Message-ID: <20050303200924.14350.qmail@web53401.mail.yahoo.com>

The summary() function shows the min, median, mean,
max, and 25th and 75th percentiles, but not the
standard deviation, skew, and kurtosis (at least by
default). Is there are an option of summary() that
does this, or has someone written code for this?

Since the columns of my table are time series, I would
also like to display the autocrrelations of each
series up to a certain lag, as part of the summary.
Thanks.

Vivek Rao
Philadelphia, USA



From fnkci at uaf.edu  Thu Mar  3 22:22:53 2005
From: fnkci at uaf.edu (Ken Irving)
Date: Thu, 3 Mar 2005 12:22:53 -0900
Subject: [R] reading row vectors from file
Message-ID: <20050303212252.GA21411@localhost>

Hi,

New to R, using version 2.0.1 (2004-11-15) on debian Linux (sid), kernel
2.6.8-2-686.

I have data in files with separate vectors on each row of the file,
e.g.,

    $ cat /tmp/stats
    freq,0,1,2,3,4,5,6,7,8,9,16,17,18,19,20,...
    noise,49,47,48,48,50,47,48,47,46,50,48,54,49,47,49,...
    signal,99,0,100,0,0,100,0,100,100,0,100,101,100,0,0,...
    pctrcv,5,0,5,0,0,5,0,5,11,0,5,5,5,0,0,...

I can transpose the data file (e.g., using an awk script), and then read
it using read.csv("tstats"),

    $ transpose /tmp/stats > /tmp/tstats
    $ cat /tmp/tstats
    freq,noise,signal,pctrcv
    0,49,99,5
    1,47,0,0
    2,48,100,5
    ...

but would prefer to import the line-oriented files directly. I've
drawn a blank after perusing help, documentation, google searches, etc.. 

Something like read.csv( "transpose stat |" ) might be nice, e.g., the
trailing pipe symbol invokes the argument as a shell pipeline, then
reads from stdin, but I'm just making this up...  Actually, this does
work:

    t <- read.csv( pipe("transpose stat1") )

but it does rely on an external transpose command. Is there a way to
read line-oriented vector files directly?

Thanks for any help or leads,
  
Ken

-- 
Ken Irving, Research Analyst, fnkci at uaf.edu
Water and Environmental Research Center
Institute of Northern Engineering
University of Alaska, Fairbanks



From pensterfuzzer at yahoo.de  Thu Mar  3 22:35:42 2005
From: pensterfuzzer at yahoo.de (Werner Wernersen)
Date: Thu, 3 Mar 2005 22:35:42 +0100 (CET)
Subject: [R] German Map Data?
Message-ID: <20050303213542.15505.qmail@web25801.mail.ukl.yahoo.com>

Hello!

Is there a more accurate map of germany than the one
included in the world map 
of the map package available?
I am using R 2.0.1 under win2k.

Thanks,
   Werner



From ggrothendieck at myway.com  Thu Mar  3 22:30:39 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 3 Mar 2005 21:30:39 +0000 (UTC)
Subject: [R] reading row vectors from file
References: <20050303212252.GA21411@localhost>
Message-ID: <loom.20050303T222926-344@post.gmane.org>

Ken Irving <fnkci <at> uaf.edu> writes:

: 
: Hi,
: 
: New to R, using version 2.0.1 (2004-11-15) on debian Linux (sid), kernel
: 2.6.8-2-686.
: 
: I have data in files with separate vectors on each row of the file,
: e.g.,
: 
:     $ cat /tmp/stats
:     freq,0,1,2,3,4,5,6,7,8,9,16,17,18,19,20,...
:     noise,49,47,48,48,50,47,48,47,46,50,48,54,49,47,49,...
:     signal,99,0,100,0,0,100,0,100,100,0,100,101,100,0,0,...
:     pctrcv,5,0,5,0,0,5,0,5,11,0,5,5,5,0,0,...
: 
: I can transpose the data file (e.g., using an awk script), and then read
: it using read.csv("tstats"),
: 
:     $ transpose /tmp/stats > /tmp/tstats
:     $ cat /tmp/tstats
:     freq,noise,signal,pctrcv
:     0,49,99,5
:     1,47,0,0
:     2,48,100,5
:     ...
: 
: but would prefer to import the line-oriented files directly. I've
: drawn a blank after perusing help, documentation, google searches, etc.. 
: 
: Something like read.csv( "transpose stat |" ) might be nice, e.g., the
: trailing pipe symbol invokes the argument as a shell pipeline, then
: reads from stdin, but I'm just making this up...  Actually, this does
: work:
: 
:     t <- read.csv( pipe("transpose stat1") )
: 
: but it does rely on an external transpose command. Is there a way to
: read line-oriented vector files directly?
: 

for(v in strsplit(readLines(myfile), ",")) assign(v[[1]], as.numeric(v[-1]))



From ggrothendieck at myway.com  Thu Mar  3 22:44:05 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 3 Mar 2005 21:44:05 +0000 (UTC)
Subject: [R] stdev, skew, kurtosis, ACF from summary function?
References: <1109876655.3311.92.camel@staff-pc01.harrowscs.westminster.ac.uk>
	<20050303200924.14350.qmail@web53401.mail.yahoo.com>
Message-ID: <loom.20050303T224032-316@post.gmane.org>

Vivek Rao <vivekrao4 <at> yahoo.com> writes:

: 
: The summary() function shows the min, median, mean,
: max, and 25th and 75th percentiles, but not the
: standard deviation, skew, and kurtosis (at least by
: default). Is there are an option of summary() that
: does this, or has someone written code for this?
: 
: Since the columns of my table are time series, I would
: also like to display the autocrrelations of each
: series up to a certain lag, as part of the summary.
: Thanks.
: 

library(e1071) # to get the skewness and kurtosis functions
apply(x, 2, function(x) 
  c(sd = sd(x), skew = skewness(x), kurtosis = kurtosis(x), acf = acf(x)$acf))



From e.leoni at gmail.com  Thu Mar  3 23:15:39 2005
From: e.leoni at gmail.com (Eduardo Leoni)
Date: Thu, 3 Mar 2005 17:15:39 -0500
Subject: [R] regression on a matrix
Message-ID: <e474b37905030314151e2c7b6d@mail.gmail.com>

Hi - 

I am doing a monte carlo experiment that requires to do a linear
regression of a matrix of vectors of dependent variables on  a fixed
set of covariates (one regression per vector). I am wondering if
anyone has any idea of how to speed up the computations in R. The code
follows:

#regression function
#Linear regression code
qreg <- function(y,x) {
  X=cbind(1,x)
  m<-lm.fit(y=y,x=X)
  p<-m$rank

  r <- m$residuals
  n <- length(r)
  rss <- sum(r^2)
  resvar <- rss/(n - p)		
  
  Qr <- m$qr
  p1 <- 1:p
  R <- chol2inv(Qr$qr[p1, p1, drop = FALSE])
  se <- sqrt(diag(R) * resvar)
  b <- m$coefficients
  return(c(b[2],se[2]))
}


#simulate
a <- c(1,.63,.63,1)
a <- matrix(a,2,2)
c <- chol(a)
C <- 0.7
theta <- 0.8
sims <- 1000
n<-20

u <- rnorm(n,0,sqrt(1-C))
w <- rgamma(n,C/theta,1/theta)
e <- rnorm(n,0,sqrt(w))
  
x1 <- rnorm(n)
x <- x1*c[2,2]+c[1,2]*w
v <- e+u
y <- 1+x+v
w <- rgamma(n,C/theta,1/theta)

#create matrix of dep variable
newdep <- matrix(rnorm(length(y)*sims,y,sqrt(w)),c(length(y),sims))


monte <- apply(newdep,2,qreg,x=x)



From ramasamy at cancer.org.uk  Thu Mar  3 23:17:19 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 03 Mar 2005 22:17:19 +0000
Subject: [R] reading row vectors from file
In-Reply-To: <20050303212252.GA21411@localhost>
References: <20050303212252.GA21411@localhost>
Message-ID: <1109888239.5867.6.camel@dhcp-63.ccc.ox.ac.uk>

Why not simply read it as an csv file, then transpose it. If you also
store it as a data frame, you can use attach() or detach() the object to
the search path whenever you want to access the variables directly.


df <- read.csv( "tmp.txt", header=FALSE, row.names=1 )
df <- data.frame( t( df ) )
df
    freq noise signal pctrcv
V2     0    49     99      5
V3     1    47      0      0
V4     2    48    100      5
V5     3    48      0      0
V6     4    50      0      0
V7     5    47    100      5
V8     6    48      0      0
V9     7    47    100      5
V10    8    46    100     11
V11    9    50      0      0
V12   16    48    100      5
V13   17    54    101      5
V14   18    49    100      5
V15   19    47      0      0
V16   20    49      0      0


attach( df )
pctrcv
 [1]  5  0  5  0  0  5  0  5 11  0  5  5  5  0  0

signal / noise
 [1] 2.020408 0.000000 2.083333 0.000000 0.000000 2.127660 0.000000
2.127660
 [9] 2.173913 0.000000 2.083333 1.870370 2.040816 0.000000 0.000000



On Thu, 2005-03-03 at 12:22 -0900, Ken Irving wrote:
> Hi,
> 
> New to R, using version 2.0.1 (2004-11-15) on debian Linux (sid), kernel
> 2.6.8-2-686.
> 
> I have data in files with separate vectors on each row of the file,
> e.g.,
> 
>     $ cat /tmp/stats
>     freq,0,1,2,3,4,5,6,7,8,9,16,17,18,19,20,...
>     noise,49,47,48,48,50,47,48,47,46,50,48,54,49,47,49,...
>     signal,99,0,100,0,0,100,0,100,100,0,100,101,100,0,0,...
>     pctrcv,5,0,5,0,0,5,0,5,11,0,5,5,5,0,0,...
> 
> I can transpose the data file (e.g., using an awk script), and then read
> it using read.csv("tstats"),
> 
>     $ transpose /tmp/stats > /tmp/tstats
>     $ cat /tmp/tstats
>     freq,noise,signal,pctrcv
>     0,49,99,5
>     1,47,0,0
>     2,48,100,5
>     ...
> 
> but would prefer to import the line-oriented files directly. I've
> drawn a blank after perusing help, documentation, google searches, etc.. 
> 
> Something like read.csv( "transpose stat |" ) might be nice, e.g., the
> trailing pipe symbol invokes the argument as a shell pipeline, then
> reads from stdin, but I'm just making this up...  Actually, this does
> work:
> 
>     t <- read.csv( pipe("transpose stat1") )
> 
> but it does rely on an external transpose command. Is there a way to
> read line-oriented vector files directly?
> 
> Thanks for any help or leads,
>   
> Ken
>



From ggrothendieck at myway.com  Thu Mar  3 23:16:56 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 3 Mar 2005 22:16:56 +0000 (UTC)
Subject: [R] reading row vectors from file
References: <20050303212252.GA21411@localhost>
	<loom.20050303T222926-344@post.gmane.org>
Message-ID: <loom.20050303T231400-416@post.gmane.org>

Gabor Grothendieck <ggrothendieck <at> myway.com> writes:

: 
: Ken Irving <fnkci <at> uaf.edu> writes:
: 
: : 
: : Hi,
: : 
: : New to R, using version 2.0.1 (2004-11-15) on debian Linux (sid), kernel
: : 2.6.8-2-686.
: : 
: : I have data in files with separate vectors on each row of the file,
: : e.g.,
: : 
: :     $ cat /tmp/stats
: :     freq,0,1,2,3,4,5,6,7,8,9,16,17,18,19,20,...
: :     noise,49,47,48,48,50,47,48,47,46,50,48,54,49,47,49,...
: :     signal,99,0,100,0,0,100,0,100,100,0,100,101,100,0,0,...
: :     pctrcv,5,0,5,0,0,5,0,5,11,0,5,5,5,0,0,...
: : 
: : I can transpose the data file (e.g., using an awk script), and then read
: : it using read.csv("tstats"),
: : 
: :     $ transpose /tmp/stats > /tmp/tstats
: :     $ cat /tmp/tstats
: :     freq,noise,signal,pctrcv
: :     0,49,99,5
: :     1,47,0,0
: :     2,48,100,5
: :     ...
: : 
: : but would prefer to import the line-oriented files directly. I've
: : drawn a blank after perusing help, documentation, google searches, etc.. 
: : 
: : Something like read.csv( "transpose stat |" ) might be nice, e.g., the
: : trailing pipe symbol invokes the argument as a shell pipeline, then
: : reads from stdin, but I'm just making this up...  Actually, this does
: : work:
: : 
: :     t <- read.csv( pipe("transpose stat1") )
: : 
: : but it does rely on an external transpose command. Is there a way to
: : read line-oriented vector files directly?
: : 
: 
: for(v in strsplit(readLines(myfile), ",")) assign(v[[1]], as.numeric(v[-1]))
: 

One more comment.  If the vectors are of the same length and you want 
to create a data frame out of them you could do this:

e <- new.env()
# next line is same as previous solution except for e in 3rd arg of assign
for(v in strsplit(readLines(myfile), ",")) assign(v[[1]], as.numeric(v[-1]),e)
as.data.frame(as.list(e))



From sdavis2 at mail.nih.gov  Thu Mar  3 23:22:29 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Thu, 3 Mar 2005 17:22:29 -0500
Subject: [R] Rank-based p-value on large dataset
Message-ID: <f93a14b5418efd99355a201557d9f8da@mail.nih.gov>

I have a fairly simple problem--I have about 80,000 values (call them 
y) that I am using as an empirical distribution and I want to find the 
p-value (never mind the multiple testing issues here, for the time 
being) of 130,000 points (call them x) from the empirical distribution. 
  I typically do that (for one-sided test) something like

loop over i in x
p.val[i] = sum(y>x[i])/length(y)

and repeat for all i.  However, length(x) is large here as is 
length(y), so this process takes quite a long time.  Any suggestions?

Thanks,
Sean



From reid_huntsinger at merck.com  Thu Mar  3 23:24:22 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Thu, 3 Mar 2005 17:24:22 -0500
Subject: [R] regression on a matrix
Message-ID: <D9A95B4B7B20354992E165EEADA31999056A9312@uswpmx00.merck.com>

You might use lsfit instead and just do the whole Y matrix at once. That
saves all the recalculation of things involving only X. 

Reid Huntsinger

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Eduardo Leoni
Sent: Thursday, March 03, 2005 5:16 PM
To: r-help at stat.math.ethz.ch
Subject: [R] regression on a matrix


Hi - 

I am doing a monte carlo experiment that requires to do a linear
regression of a matrix of vectors of dependent variables on  a fixed
set of covariates (one regression per vector). I am wondering if
anyone has any idea of how to speed up the computations in R. The code
follows:

#regression function
#Linear regression code
qreg <- function(y,x) {
  X=cbind(1,x)
  m<-lm.fit(y=y,x=X)
  p<-m$rank

  r <- m$residuals
  n <- length(r)
  rss <- sum(r^2)
  resvar <- rss/(n - p)		
  
  Qr <- m$qr
  p1 <- 1:p
  R <- chol2inv(Qr$qr[p1, p1, drop = FALSE])
  se <- sqrt(diag(R) * resvar)
  b <- m$coefficients
  return(c(b[2],se[2]))
}


#simulate
a <- c(1,.63,.63,1)
a <- matrix(a,2,2)
c <- chol(a)
C <- 0.7
theta <- 0.8
sims <- 1000
n<-20

u <- rnorm(n,0,sqrt(1-C))
w <- rgamma(n,C/theta,1/theta)
e <- rnorm(n,0,sqrt(w))
  
x1 <- rnorm(n)
x <- x1*c[2,2]+c[1,2]*w
v <- e+u
y <- 1+x+v
w <- rgamma(n,C/theta,1/theta)

#create matrix of dep variable
newdep <- matrix(rnorm(length(y)*sims,y,sqrt(w)),c(length(y),sims))


monte <- apply(newdep,2,qreg,x=x)

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From reid_huntsinger at merck.com  Thu Mar  3 23:38:50 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Thu, 3 Mar 2005 17:38:50 -0500
Subject: [R] Rank-based p-value on large dataset
Message-ID: <D9A95B4B7B20354992E165EEADA31999056A9313@uswpmx00.merck.com>

When you say the 130,000 points are from the empirical distribution, how did
you get them? Is each one really one of the values of y? If you sorted y
first, would you know which one (ie which index) each x is? (Sorting 80,000
elements took essentially no time at all on my sub-gigahertz Pentium III.)
But maybe that's not an option... more details would help.

Reid Huntsinger

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Sean Davis
Sent: Thursday, March 03, 2005 5:22 PM
To: r-help
Subject: [R] Rank-based p-value on large dataset


I have a fairly simple problem--I have about 80,000 values (call them 
y) that I am using as an empirical distribution and I want to find the 
p-value (never mind the multiple testing issues here, for the time 
being) of 130,000 points (call them x) from the empirical distribution. 
  I typically do that (for one-sided test) something like

loop over i in x
p.val[i] = sum(y>x[i])/length(y)

and repeat for all i.  However, length(x) is large here as is 
length(y), so this process takes quite a long time.  Any suggestions?

Thanks,
Sean

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From greg.snow at ihc.com  Thu Mar  3 23:46:39 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Thu, 03 Mar 2005 15:46:39 -0700
Subject: [R] German Map Data?
Message-ID: <s227316f.009@lp-msg1.co.ihc.com>

There is a shapefile at:
http://www.vdstech.com/map_data.htm

The maptools package can read and plot shapefiles. 

Greg Snow, Ph.D.
Statistical Data Center
greg.snow at ihc.com
(801) 408-8111

>>> Werner Wernersen <pensterfuzzer at yahoo.de> 03/03/05 02:35PM >>>
Hello!

Is there a more accurate map of germany than the one
included in the world map 
of the map package available?
I am using R 2.0.1 under win2k.

Thanks,
   Werner

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From sdavis2 at mail.nih.gov  Thu Mar  3 23:49:55 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Thu, 3 Mar 2005 17:49:55 -0500
Subject: [R] Rank-based p-value on large dataset
In-Reply-To: <D9A95B4B7B20354992E165EEADA31999056A9313@uswpmx00.merck.com>
References: <D9A95B4B7B20354992E165EEADA31999056A9313@uswpmx00.merck.com>
Message-ID: <1d3f0681140252ffe63d011c54e7d520@mail.nih.gov>

The x's and y's are different sets--210,000 values altogether.  That is  
really the issue--they can't just be sorted, at least that I can  
see....

Sean

On Mar 3, 2005, at 5:38 PM, Huntsinger, Reid wrote:

> When you say the 130,000 points are from the empirical distribution,  
> how did
> you get them? Is each one really one of the values of y? If you sorted  
> y
> first, would you know which one (ie which index) each x is? (Sorting  
> 80,000
> elements took essentially no time at all on my sub-gigahertz Pentium  
> III.)
> But maybe that's not an option... more details would help.
>
> Reid Huntsinger
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Sean Davis
> Sent: Thursday, March 03, 2005 5:22 PM
> To: r-help
> Subject: [R] Rank-based p-value on large dataset
>
>
> I have a fairly simple problem--I have about 80,000 values (call them
> y) that I am using as an empirical distribution and I want to find the
> p-value (never mind the multiple testing issues here, for the time
> being) of 130,000 points (call them x) from the empirical distribution.
>   I typically do that (for one-sided test) something like
>
> loop over i in x
> p.val[i] = sum(y>x[i])/length(y)
>
> and repeat for all i.  However, length(x) is large here as is
> length(y), so this process takes quite a long time.  Any suggestions?
>
> Thanks,
> Sean
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>
>
>
>
>
> ----------------------------------------------------------------------- 
> -------
> Notice:  This e-mail message, together with any attachment...{{dropped}}



From deepayan at stat.wisc.edu  Thu Mar  3 23:32:38 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 3 Mar 2005 16:32:38 -0600
Subject: [R] Rank-based p-value on large dataset
In-Reply-To: <f93a14b5418efd99355a201557d9f8da@mail.nih.gov>
References: <f93a14b5418efd99355a201557d9f8da@mail.nih.gov>
Message-ID: <200503031632.38804.deepayan@stat.wisc.edu>

On Thursday 03 March 2005 16:22, Sean Davis wrote:
> I have a fairly simple problem--I have about 80,000 values (call them
> y) that I am using as an empirical distribution and I want to find
> the p-value (never mind the multiple testing issues here, for the
> time being) of 130,000 points (call them x) from the empirical
> distribution. I typically do that (for one-sided test) something like
>
> loop over i in x
> p.val[i] = sum(y>x[i])/length(y)
>
> and repeat for all i.  However, length(x) is large here as is
> length(y), so this process takes quite a long time.  Any suggestions?

The obvious thing to do would be 

p.val = 1 - ecdf(x)(y)

wouldn't it? On a 1.1 GHz Athlon, I get 

> x <- rnorm(130000)
> y <- rnorm(80000)
> system.time(p.val <- 1 - ecdf(y)(x))
[1] 1.03 0.03 1.06 0.00 0.00

-Deepayan



From m_osm at gmx.net  Thu Mar  3 23:57:22 2005
From: m_osm at gmx.net (Mahdi Osman)
Date: Thu, 3 Mar 2005 23:57:22 +0100 (MET)
Subject: [R] ESS
Message-ID: <17801.1109890642@www37.gmx.net>

Hi all,

I am running R 2.0.1 under Windows XP in German. I configured my path as
follows:

C:\Programme\R\rw2001\bin;C:\Programme\xemacs-packages\lib-src\;C:\Programme\XEmacs-21.4.13\i586-pc-win32

I can not start R proccess or ESS from within XEmacs. What is going wrong?

I can not start S. M-x S gives "no matching"

How can I configure XEmacs for STATA 8?

Thanks for your help.


M


-- 
-----------------------------------
Mahdi Osman (PhD)
E-mail: m_osm at gmx.net
-----------------------------------

DSL Komplett von GMX +++ Supergnstig und stressfrei einsteigen!
AKTION "Kein Einrichtungspreis" nutzen: http://www.gmx.net/de/go/dsl



From tom_hoary at web.de  Fri Mar  4 00:06:54 2005
From: tom_hoary at web.de (Thomas =?iso-8859-1?q?Sch=F6nhoff?=)
Date: Fri, 4 Mar 2005 00:06:54 +0100
Subject: [R] Need suggestions for plotting 3D plot
In-Reply-To: <20050303180301.47406.qmail@web52202.mail.yahoo.com>
References: <20050303180301.47406.qmail@web52202.mail.yahoo.com>
Message-ID: <200503040006.54995.tom_hoary@web.de>

Am Donnerstag, 3. M?rz 2005 19:03 schrieb Soumyadeep nandi:
> Hi Everybody,
> I am a newbie in R. I have a data in the form of a
> matrix which I want to make some 3D plots using R.
> There is some functions for instance hist() for 2D
> plots, but I cant find any function for 3D plots. Is
> there any function available in R for 3D plots? If so,
> is there any documention available on internet so that
> I can go through.
Yes,what about 'help.search("3d") (gives me some hits concerning your 
topic). There is at least one package which might meet your demands 
directly: "scatterplot3d".

regards

Thomas



From deepayan at stat.wisc.edu  Thu Mar  3 23:40:55 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 3 Mar 2005 16:40:55 -0600
Subject: [R] Rank-based p-value on large dataset
In-Reply-To: <200503031632.38804.deepayan@stat.wisc.edu>
References: <f93a14b5418efd99355a201557d9f8da@mail.nih.gov>
	<200503031632.38804.deepayan@stat.wisc.edu>
Message-ID: <200503031640.55824.deepayan@stat.wisc.edu>

On Thursday 03 March 2005 16:32, Deepayan Sarkar wrote:
> On Thursday 03 March 2005 16:22, Sean Davis wrote:
> > I have a fairly simple problem--I have about 80,000 values (call
> > them y) that I am using as an empirical distribution and I want to
> > find the p-value (never mind the multiple testing issues here, for
> > the time being) of 130,000 points (call them x) from the empirical
> > distribution. I typically do that (for one-sided test) something
> > like
> >
> > loop over i in x
> > p.val[i] = sum(y>x[i])/length(y)
> >
> > and repeat for all i.  However, length(x) is large here as is
> > length(y), so this process takes quite a long time.  Any
> > suggestions?
>
> The obvious thing to do would be
>
> p.val = 1 - ecdf(x)(y)

or rather: p.val = 1 - ecdf(y)(x)

> wouldn't it? On a 1.1 GHz Athlon, I get
>
> > x <- rnorm(130000)
> > y <- rnorm(80000)
> > system.time(p.val <- 1 - ecdf(y)(x))
>
> [1] 1.03 0.03 1.06 0.00 0.00



From wcai11 at hotmail.com  Fri Mar  4 00:17:26 2005
From: wcai11 at hotmail.com (Weijie Cai)
Date: Thu, 03 Mar 2005 18:17:26 -0500
Subject: [R] how to capture a series of plots
Message-ID: <BAY103-F332E8DAC280267588F09FD35B0@phx.gbl>

Hi, there

I am trying to capture a series of plots into jpeg or png files so that I 
can create gif animation later. However, my plot background generation is 
very slow, and I create the background plot only at the very beginning, and 
at each step I only refresh the foreground points and symbols like this:
plot(x,y)
while (condition holds){
symbols(...add=1);
}

My question is, can I create a series of plots test1.jpg, 
test2.jpg...continuously? To my knowledge, R has to close current device (by 
dev.off()) to write to current file, so once first jpeg file is written, the 
current device with background will be off, therefore, I cannot add symbols 
in next device and create following file series.

Any suggestions?

Thanks

WC



From ramasamy at cancer.org.uk  Fri Mar  4 01:04:16 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Fri, 04 Mar 2005 00:04:16 +0000
Subject: [R] Rank-based p-value on large dataset
In-Reply-To: <f93a14b5418efd99355a201557d9f8da@mail.nih.gov>
References: <f93a14b5418efd99355a201557d9f8da@mail.nih.gov>
Message-ID: <1109894656.6066.17.camel@dhcp-63.ccc.ox.ac.uk>

One solution is to cut() 'x' according to the breaks defined by 'y'.
Using cut with labels=FALSE is really fast. See a simulation below.

However the accuracy depends on the number of ties you have in your
"empirical" distribution. I have tried to simulate with the round()
function below.

# simulate data
y <- round(rnorm(80000),  5) # empirical distribution with some ties
x <- round(rnorm(130000), 5) # observed values with some ties

# current way
system.time({
  p1 <- numeric( length(x) )
  for(i in 1:length(x)){ p1[i] <- sum( x[i] < y )/length(y) }
})
[1] 484.67  25.08 512.04   0.00   0.00

# suggested solution
system.time({
  break.points <- c(-Inf, unique(sort(y)), Inf)
  p2 <- cut( x, breaks=break.points, labels=FALSE )
  p2 <- 1 - p2/length(break.points)
})
[1] 0.27 0.01 0.28 0.00 0.00
 

head( cbind( p1, p2 ) )
           p1         p2
[1,] 0.658375 0.65813482
[2,] 0.144000 0.14533705
[3,] 0.815500 0.81436898
[4,] 0.412500 0.41269640
[5,] 0.553625 0.55334516
[6,] 0.044500 0.04510897
...

cor(p1, p2)
[1] 0.9999987


The difference arises mainly because I had to use a unique breakpoints
in cut(). You may want to investigate further if you are interested.
Please let me know if you find anything good or bad about this
suggestion as I am using it as part of my codes too. Thank you.

Regards, Adai


On Thu, 2005-03-03 at 17:22 -0500, Sean Davis wrote:
> I have a fairly simple problem--I have about 80,000 values (call them 
> y) that I am using as an empirical distribution and I want to find the 
> p-value (never mind the multiple testing issues here, for the time 
> being) of 130,000 points (call them x) from the empirical distribution. 
>   I typically do that (for one-sided test) something like
> 
> loop over i in x
> p.val[i] = sum(y>x[i])/length(y)
> 
> and repeat for all i.  However, length(x) is large here as is 
> length(y), so this process takes quite a long time.  Any suggestions?
> 
> Thanks,
> Sean
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Duncan.Mackay at flinders.edu.au  Fri Mar  4 01:15:08 2005
From: Duncan.Mackay at flinders.edu.au (Duncan Mackay)
Date: Fri, 4 Mar 2005 10:45:08 +1030
Subject: [R] Rconsole wishlist
Message-ID: <000001c5204f$39763300$cce66081@duncanlt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050304/2ab1f4a9/attachment.pl

From sdavis2 at mail.nih.gov  Fri Mar  4 01:15:41 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Thu, 03 Mar 2005 19:15:41 -0500
Subject: [R] Rank-based p-value on large dataset
In-Reply-To: <1109894656.6066.17.camel@dhcp-63.ccc.ox.ac.uk>
Message-ID: <BE4D12DD.3BBF%sdavis2@mail.nih.gov>

On 3/3/05 19:04, "Adaikalavan Ramasamy" <ramasamy at cancer.org.uk> wrote:

> One solution is to cut() 'x' according to the breaks defined by 'y'.
> Using cut with labels=FALSE is really fast. See a simulation below.
> 
> However the accuracy depends on the number of ties you have in your
> "empirical" distribution. I have tried to simulate with the round()
> function below.
> 
> # simulate data
> y <- round(rnorm(80000),  5) # empirical distribution with some ties
> x <- round(rnorm(130000), 5) # observed values with some ties
> 
> # current way
> system.time({
> p1 <- numeric( length(x) )
> for(i in 1:length(x)){ p1[i] <- sum( x[i] < y )/length(y) }
> })
> [1] 484.67  25.08 512.04   0.00   0.00
> 
> # suggested solution
> system.time({
> break.points <- c(-Inf, unique(sort(y)), Inf)
> p2 <- cut( x, breaks=break.points, labels=FALSE )
> p2 <- 1 - p2/length(break.points)
> })
> [1] 0.27 0.01 0.28 0.00 0.00
> 
> 
> head( cbind( p1, p2 ) )
>          p1         p2
> [1,] 0.658375 0.65813482
> [2,] 0.144000 0.14533705
> [3,] 0.815500 0.81436898
> [4,] 0.412500 0.41269640
> [5,] 0.553625 0.55334516
> [6,] 0.044500 0.04510897
> ...
> 
> cor(p1, p2)
> [1] 0.9999987
> 
> 
> The difference arises mainly because I had to use a unique breakpoints
> in cut(). You may want to investigate further if you are interested.
> Please let me know if you find anything good or bad about this
> suggestion as I am using it as part of my codes too. Thank you.
> 
> Regards, Adai
>

Adai,

All I have to say is, "WOW!".  I'll give it a try tomorrow and let you know.

Thanks,
Sean



From ramasamy at cancer.org.uk  Fri Mar  4 01:19:23 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Fri, 04 Mar 2005 00:19:23 +0000
Subject: [R] ESS
In-Reply-To: <17801.1109890642@www37.gmx.net>
References: <17801.1109890642@www37.gmx.net>
Message-ID: <1109895563.6066.31.camel@dhcp-63.ccc.ox.ac.uk>

There is an ESS mailing list that might be more appropriate.

I use emacs rather than Xemacs, but I think you need to point the path
to ess in init.el file which is located on the home directory. E.g. :

   (setq ess-icon-directory "C:/Programme/xemacs-packages/etc/ess")
   (require 'ess-site)

Follow the excellent instructions at John Fox's website
http://socserv.mcmaster.ca/jfox/Books/Companion/ESS/

Then to start R, try 'M-x R'.

Regards, Adai



On Thu, 2005-03-03 at 23:57 +0100, Mahdi Osman wrote:
> Hi all,
> 
> I am running R 2.0.1 under Windows XP in German. I configured my path as
> follows:
> 
> C:\Programme\R\rw2001\bin;C:\Programme\xemacs-packages\lib-src\;C:\Programme\XEmacs-21.4.13\i586-pc-win32
> 
> I can not start R proccess or ESS from within XEmacs. What is going wrong?
> 
> I can not start S. M-x S gives "no matching"
> 
> How can I configure XEmacs for STATA 8?
> 
> Thanks for your help.
> 
> 
> M
> 
>



From andy_liaw at merck.com  Fri Mar  4 01:43:40 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 3 Mar 2005 19:43:40 -0500
Subject: [R] Rconsole wishlist
Message-ID: <3A822319EB35174CA3714066D590DCD50994E7D7@usrymx25.merck.com>

I'm guessing you're talking about Rgui on Windows, but please don't leave us
guessing.

If you run R under Ess/(X)Emacs, you have the entire session that can be
saved in a (transcript) file.

Does your OS not put date stamps on file?

> file.info(".Rhistory")
          size isdir mode               mtime               ctime
.Rhistory 1025 FALSE  666 2005-03-03 19:27:31 2004-08-13 10:45:09
                        atime
.Rhistory 2005-03-03 19:27:31

Andy


> From: Duncan Mackay
> 
> Hi all,
> Wouldn't it be nice (??!!) if R automatically issued a 
> warning message when
> the R console buffer was about to fill so that you could save all your
> output into a text file? (I know about sink(), but I think it 
> would be good
> to have an easier mechanism to save a complete record of messages and
> function output). And on a similar vein, wouldn't it also be nice if R
> automatically entered a date stamp into the history file??
> 
> Duncan
> 
> 
> *****************************************
> Dr. Duncan Mackay
> School of Biological Sciences
> Flinders University
> GPO Box 2100
> Adelaide
> S.A.    5001
> AUSTRALIA
> 
> Ph (08) 8201 2627    FAX (08) 8201 3015
> 
http://www.scieng.flinders.edu.au/biology/people/mackay_d/index.html
  


	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From dmb at mrc-dunn.cam.ac.uk  Fri Mar  4 02:48:34 2005
From: dmb at mrc-dunn.cam.ac.uk (Dan Bolser)
Date: Fri, 4 Mar 2005 01:48:34 +0000 (GMT)
Subject: [R] Question about density()
Message-ID: <Pine.LNX.4.21.0503040141110.11985-100000@mail.mrc-dunn.cam.ac.uk>


If I integrate over the result of the density() funcion, is the result 1?

For example 

x <- rnorm(1000)
plot(density(x))

Does the area under the curve I see sum to 1?


What I really want to know is if I can directly compare two particular
curves, generated like this


x <- rnorm(1000)
plot(density(x))

a.seq <- seq(min(x),max(x),0.01)
lines(a.seq,dnorm(x=a.seq,mean=mean(x),sd=sd(x)))


I guess they are directly comparable if the area under density sums to
one.

Is this correct?



From ggrothendieck at myway.com  Fri Mar  4 03:11:46 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 4 Mar 2005 02:11:46 +0000 (UTC)
Subject: [R] Question about density()
References: <Pine.LNX.4.21.0503040141110.11985-100000@mail.mrc-dunn.cam.ac.uk>
Message-ID: <loom.20050304T030957-586@post.gmane.org>

Dan Bolser <dmb <at> mrc-dunn.cam.ac.uk> writes:

: 
: If I integrate over the result of the density() funcion, is the result 1?
: 
: For example 
: 
: x <- rnorm(1000)
: plot(density(x))
: 
: Does the area under the curve I see sum to 1?
: 
: What I really want to know is if I can directly compare two particular
: curves, generated like this
: 
: x <- rnorm(1000)
: plot(density(x))
: 
: a.seq <- seq(min(x),max(x),0.01)
: lines(a.seq,dnorm(x=a.seq,mean=mean(x),sd=sd(x)))
: 
: I guess they are directly comparable if the area under density sums to
: one.
: 
: Is this correct?

We can integrate it to find out:

R> set.seed(1)
R> z <- density(rnorm(10000))
R> f <- approxfun(z$x, z$y, yleft = 0, yright = 0)
R> integrate(f, -Inf, Inf)
1.000978 with absolute error < 6.6e-05



From r_hlp at yahoo.com  Fri Mar  4 03:44:10 2005
From: r_hlp at yahoo.com (r help)
Date: Thu, 3 Mar 2005 18:44:10 -0800 (PST)
Subject: [R] fitting pareto to data?
Message-ID: <20050304024410.37823.qmail@web42103.mail.yahoo.com>

hi

i have an experimental dataset which i think is coming
from a pareto/powerlaw distribution. 

i am trying to use the 2 parameter pareto distribution
from Jim Lindsey's rmutil package (i am open to using
any package however.)

i would like R to compute estimates for the 2 pareto
parameters based on my dataset; what commands would
achieve this?  

thanks
-gong



From Duncan.Mackay at flinders.edu.au  Fri Mar  4 05:00:20 2005
From: Duncan.Mackay at flinders.edu.au (Duncan Mackay)
Date: Fri, 4 Mar 2005 14:30:20 +1030
Subject: [R] Rconsole wishlist
In-Reply-To: <3A822319EB35174CA3714066D590DCD50994E7D7@usrymx25.merck.com>
Message-ID: <000601c5206e$af018150$cce66081@duncanlt>

Sorry, yes, Rgui under WinXP (SP2). But while Windows date stamps the
history file

> file.info(".Rhistory")
          size isdir mode               mtime               ctime
.Rhistory 5377 FALSE  666 2005-03-04 10:37:52 2005-03-04 10:37:52
                        atime
.Rhistory 2005-03-04 13:54:11

the problem is that there can be multiple sessions stored in .Rhistory and
the session dates aren't stored there. Moreover, it seems to me that the
history buffer can also overflow without warning after long sessions or many
repeated sessions and so that you can inadvertently lose parts of your
command log. (Is this right, anyone?) Perhaps it would be preferable for R
to save each session's command history in a separate history file, along the
lines of 

.Last <- function() {
savefilename <- paste("Rhistory",date())
savefilename <- gsub(" ","_",savefilename)
savefilename <- gsub(":",".",savefilename)
savefilename <- paste(savefilename,".txt",sep="")
if(interactive())  try(savehistory(savefilename))
cat("Current history saved in file: ",savefilename,"\n")
}

but this doesn't address any overflow issues.

Duncan


-----Original Message-----
From: Liaw, Andy [mailto:andy_liaw at merck.com] 
Sent: Friday, 4 March 2005 11:14 AM
To: 'Duncan Mackay'; R-news
Subject: RE: [R] Rconsole wishlist


I'm guessing you're talking about Rgui on Windows, but please don't leave us
guessing.

If you run R under Ess/(X)Emacs, you have the entire session that can be
saved in a (transcript) file.

Does your OS not put date stamps on file?

> file.info(".Rhistory")
          size isdir mode               mtime               ctime
.Rhistory 1025 FALSE  666 2005-03-03 19:27:31 2004-08-13 10:45:09
                        atime
.Rhistory 2005-03-03 19:27:31

Andy


> From: Duncan Mackay
> 
> Hi all,
> Wouldn't it be nice (??!!) if R automatically issued a
> warning message when
> the R console buffer was about to fill so that you could save all your
> output into a text file? (I know about sink(), but I think it 
> would be good
> to have an easier mechanism to save a complete record of messages and
> function output). And on a similar vein, wouldn't it also be nice if R
> automatically entered a date stamp into the history file??
> 
> Duncan
> 
> 
> *****************************************
> Dr. Duncan Mackay
> School of Biological Sciences
> Flinders University
> GPO Box 2100
> Adelaide
> S.A.    5001
> AUSTRALIA
> 
> Ph (08) 8201 2627    FAX (08) 8201 3015
> 
http://www.scieng.flinders.edu.au/biology/people/mackay_d/index.html
  


	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html





----------------------------------------------------------------------------
--
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From brett at hbrc.govt.nz  Fri Mar  4 05:08:05 2005
From: brett at hbrc.govt.nz (Brett Stansfield)
Date: Fri, 4 Mar 2005 17:08:05 +1300 
Subject: [R] (no subject)
Message-ID: <3542A1BF5AE1984D9FF577DA2CF8BA9868B0FE@MSX2>

Dear R help
Is there a way for R to ignore NA entries in a data set.
I find I can do box plots for certain columns that have no NA  entries but
cannot do histograms or boxplots for the other columns that have NA entries

Brett Stansfield



From kjetil at acelerate.com  Fri Mar  4 06:02:33 2005
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Fri, 04 Mar 2005 01:02:33 -0400
Subject: [R] Rconsole wishlist
In-Reply-To: <000601c5206e$af018150$cce66081@duncanlt>
References: <000601c5206e$af018150$cce66081@duncanlt>
Message-ID: <4227EBE9.5040401@acelerate.com>

Duncan Mackay wrote:

>Sorry, yes, Rgui under WinXP (SP2). But while Windows date stamps the
>history file
>
>  
>
>>file.info(".Rhistory")
>>    
>>
>          size isdir mode               mtime               ctime
>.Rhistory 5377 FALSE  666 2005-03-04 10:37:52 2005-03-04 10:37:52
>                        atime
>.Rhistory 2005-03-04 13:54:11
>
>the problem is that there can be multiple sessions stored in .Rhistory and
>the session dates aren't stored there. Moreover, it seems to me that the
>history buffer can also overflow without warning after long sessions or many
>repeated sessions and so that you can inadvertently lose parts of your
>command log.
>
Yes. But you can define an environment variable R_HISTSIZE (or some 
similar name, do a
R site search to find. Not defined on my machine now. That should really 
be in the help file for
savehistory()) to avoid the problem.


> (Is this right, anyone?) Perhaps it would be preferable for R
>to save each session's command history in a separate history file, along the
>lines of 
>  
>
NO. it is better to have just one file as now.

Kjetil


>.Last <- function() {
>savefilename <- paste("Rhistory",date())
>savefilename <- gsub(" ","_",savefilename)
>savefilename <- gsub(":",".",savefilename)
>savefilename <- paste(savefilename,".txt",sep="")
>if(interactive())  try(savehistory(savefilename))
>cat("Current history saved in file: ",savefilename,"\n")
>}
>
>but this doesn't address any overflow issues.
>
>Duncan
>
>
>-----Original Message-----
>From: Liaw, Andy [mailto:andy_liaw at merck.com] 
>Sent: Friday, 4 March 2005 11:14 AM
>To: 'Duncan Mackay'; R-news
>Subject: RE: [R] Rconsole wishlist
>
>
>I'm guessing you're talking about Rgui on Windows, but please don't leave us
>guessing.
>
>If you run R under Ess/(X)Emacs, you have the entire session that can be
>saved in a (transcript) file.
>
>Does your OS not put date stamps on file?
>
>  
>
>>file.info(".Rhistory")
>>    
>>
>          size isdir mode               mtime               ctime
>.Rhistory 1025 FALSE  666 2005-03-03 19:27:31 2004-08-13 10:45:09
>                        atime
>.Rhistory 2005-03-03 19:27:31
>
>Andy
>
>
>  
>
>>From: Duncan Mackay
>>
>>Hi all,
>>Wouldn't it be nice (??!!) if R automatically issued a
>>warning message when
>>the R console buffer was about to fill so that you could save all your
>>output into a text file? (I know about sink(), but I think it 
>>would be good
>>to have an easier mechanism to save a complete record of messages and
>>function output). And on a similar vein, wouldn't it also be nice if R
>>automatically entered a date stamp into the history file??
>>
>>Duncan
>>
>>
>>*****************************************
>>Dr. Duncan Mackay
>>School of Biological Sciences
>>Flinders University
>>GPO Box 2100
>>Adelaide
>>S.A.    5001
>>AUSTRALIA
>>
>>Ph (08) 8201 2627    FAX (08) 8201 3015
>>
>>    
>>
>http://www.scieng.flinders.edu.au/biology/people/mackay_d/index.html
>  
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide!
>http://www.R-project.org/posting-guide.html
>
>
>
>
>
>----------------------------------------------------------------------------
>--
>Notice:  This e-mail message, together with any attachments,...{{dropped}}
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>


-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra





-- 
No virus found in this outgoing message.
Checked by AVG Anti-Virus.



From ggrothendieck at myway.com  Fri Mar  4 06:13:32 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 4 Mar 2005 05:13:32 +0000 (UTC)
Subject: [R] fitting pareto to data?
References: <20050304024410.37823.qmail@web42103.mail.yahoo.com>
Message-ID: <loom.20050304T060955-648@post.gmane.org>

r help <r_hlp <at> yahoo.com> writes:

: 
: hi
: 
: i have an experimental dataset which i think is coming
: from a pareto/powerlaw distribution. 
: 
: i am trying to use the 2 parameter pareto distribution
: from Jim Lindsey's rmutil package (i am open to using
: any package however.)
: 
: i would like R to compute estimates for the 2 pareto
: parameters based on my dataset; what commands would
: achieve this?  
: 
: thanks
: -gong
: 

Assuming you want to find the maximum likelihood estimate 
use optim or nlm.



From ripley at stats.ox.ac.uk  Fri Mar  4 07:35:04 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 4 Mar 2005 06:35:04 +0000 (GMT)
Subject: [R] Rconsole wishlist
In-Reply-To: <4227EBE9.5040401@acelerate.com>
References: <000601c5206e$af018150$cce66081@duncanlt>
	<4227EBE9.5040401@acelerate.com>
Message-ID: <Pine.LNX.4.61.0503040614590.23377@gannet.stats>

The problem is that the commands history is GUI-specific (there are four 
mechanisms, readline on Unix, one for the GUI MacOS X (I believe), one for 
RGui and one for rterm. And we will have to cope with both GNU and BSD 
readline shortly).  We try to keep them consistent, and that means a 
lowest-common denominator approach.

History is *not* intended to be a `command log' but a way to retrieve
recentish commands, and the console buffer is just that, a buffer.  They 
are implemented for fast access backwards and so not really appropriate 
for large logs.  If you want a session log, look at 'split' option to 
sink().

With the advent of multibyte characters (supported in R as from 2.1.0) we 
need to redesign some of this (rterm's command line will not support such 
locales for 2.1.0).  It should be possible to make the default R_HISTSIZE 
unlimited.

The console buffer is less clear: how do you want to be warned?  This 
could happen in the middle of a single print() command: it could even 
happen that a single line of output exceeds the buffer size.

Finally: R-devel is for R development issues, so if people want to pursue 
this, please move there.  (I am trying to be non-technical in this reply, 
and probably not succeeding.)


On Fri, 4 Mar 2005, Kjetil Brinchmann Halvorsen wrote:

> Duncan Mackay wrote:
>
>> Sorry, yes, Rgui under WinXP (SP2). But while Windows date stamps the
>> history file
>> 
>> 
>>> file.info(".Rhistory")
>>> 
>>          size isdir mode               mtime               ctime
>> .Rhistory 5377 FALSE  666 2005-03-04 10:37:52 2005-03-04 10:37:52
>>                        atime
>> .Rhistory 2005-03-04 13:54:11
>> 
>> the problem is that there can be multiple sessions stored in .Rhistory and
>> the session dates aren't stored there. Moreover, it seems to me that the
>> history buffer can also overflow without warning after long sessions or 
>> many
>> repeated sessions and so that you can inadvertently lose parts of your
>> command log.
>> 
> Yes. But you can define an environment variable R_HISTSIZE (or some similar 
> name, do a
> R site search to find. Not defined on my machine now. That should really be 
> in the help file for
> savehistory()) to avoid the problem.
>
>
>> (Is this right, anyone?) Perhaps it would be preferable for R
>> to save each session's command history in a separate history file, along 
>> the
>> lines of 
> NO. it is better to have just one file as now.
>
> Kjetil
>
>
>> .Last <- function() {
>> savefilename <- paste("Rhistory",date())
>> savefilename <- gsub(" ","_",savefilename)
>> savefilename <- gsub(":",".",savefilename)
>> savefilename <- paste(savefilename,".txt",sep="")
>> if(interactive())  try(savehistory(savefilename))
>> cat("Current history saved in file: ",savefilename,"\n")
>> }
>> 
>> but this doesn't address any overflow issues.
>> 
>> Duncan
>> 
>> 
>> -----Original Message-----
>> From: Liaw, Andy [mailto:andy_liaw at merck.com] Sent: Friday, 4 March 2005 
>> 11:14 AM
>> To: 'Duncan Mackay'; R-news
>> Subject: RE: [R] Rconsole wishlist
>> 
>> 
>> I'm guessing you're talking about Rgui on Windows, but please don't leave 
>> us
>> guessing.
>> 
>> If you run R under Ess/(X)Emacs, you have the entire session that can be
>> saved in a (transcript) file.
>> 
>> Does your OS not put date stamps on file?
>> 
>> 
>>> file.info(".Rhistory")
>>> 
>>          size isdir mode               mtime               ctime
>> .Rhistory 1025 FALSE  666 2005-03-03 19:27:31 2004-08-13 10:45:09
>>                        atime
>> .Rhistory 2005-03-03 19:27:31
>> 
>> Andy
>> 
>> 
>> 
>>> From: Duncan Mackay
>>> 
>>> Hi all,
>>> Wouldn't it be nice (??!!) if R automatically issued a
>>> warning message when
>>> the R console buffer was about to fill so that you could save all your
>>> output into a text file? (I know about sink(), but I think it would be 
>>> good
>>> to have an easier mechanism to save a complete record of messages and
>>> function output). And on a similar vein, wouldn't it also be nice if R
>>> automatically entered a date stamp into the history file??
>>> 
>>> Duncan
>>> 
>>> 
>>> *****************************************
>>> Dr. Duncan Mackay
>>> School of Biological Sciences
>>> Flinders University
>>> GPO Box 2100
>>> Adelaide
>>> S.A.    5001
>>> AUSTRALIA
>>> 
>>> Ph (08) 8201 2627    FAX (08) 8201 3015
>>> 
>>> 
>> http://www.scieng.flinders.edu.au/biology/people/mackay_d/index.html
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>> 
>> 
>> 
>> 
>> 
>> ----------------------------------------------------------------------------
>> --
>> Notice:  This e-mail message, together with any attachments,...{{dropped}}
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>> 
>> 
>> 
>> 
>
>
> -- 
>
> Kjetil Halvorsen.
>
> Peace is the most effective weapon of mass construction.
>              --  Mahdi Elmandjra
>
>
>
>
>
> -- 
> No virus found in this outgoing message.
> Checked by AVG Anti-Virus.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tom_hoary at web.de  Fri Mar  4 08:08:57 2005
From: tom_hoary at web.de (Thomas =?iso-8859-1?q?Sch=F6nhoff?=)
Date: Fri, 4 Mar 2005 08:08:57 +0100
Subject: [R] (no subject)
In-Reply-To: <3542A1BF5AE1984D9FF577DA2CF8BA9868B0FE@MSX2>
References: <3542A1BF5AE1984D9FF577DA2CF8BA9868B0FE@MSX2>
Message-ID: <200503040808.57830.tom_hoary@web.de>

Am Freitag, 4. M?rz 2005 05:08 schrieb Brett Stansfield:
> Dear R help
> Is there a way for R to ignore NA entries in a data set.
Yes, what about na.omit, try help.search("missing values"), there are 
some very good examples for handling missing values

Please, have a look at the posting guide and use a meningful subject. 
This will increase the likelihood for helpful responses a lot

regards
Thomas



From ligges at statistik.uni-dortmund.de  Fri Mar  4 08:34:46 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 04 Mar 2005 08:34:46 +0100
Subject: [R] how to capture a series of plots
In-Reply-To: <BAY103-F332E8DAC280267588F09FD35B0@phx.gbl>
References: <BAY103-F332E8DAC280267588F09FD35B0@phx.gbl>
Message-ID: <42280F96.7030604@statistik.uni-dortmund.de>

See ?dev.copy

Uwe Ligges

Weijie Cai wrote:

> Hi, there
> 
> I am trying to capture a series of plots into jpeg or png files so that 
> I can create gif animation later. However, my plot background generation 
> is very slow, and I create the background plot only at the very 
> beginning, and at each step I only refresh the foreground points and 
> symbols like this:
> plot(x,y)
> while (condition holds){
> symbols(...add=1);
> }
> 
> My question is, can I create a series of plots test1.jpg, 
> test2.jpg...continuously? To my knowledge, R has to close current device 
> (by dev.off()) to write to current file, so once first jpeg file is 
> written, the current device with background will be off, therefore, I 
> cannot add symbols in next device and create following file series.
> 
> Any suggestions?
> 
> Thanks
> 
> WC
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From tjrc at sanger.ac.uk  Fri Mar  4 08:46:13 2005
From: tjrc at sanger.ac.uk (Tim Cutts)
Date: Fri, 4 Mar 2005 07:46:13 +0000
Subject: [R] Is aggregate() what I need here?
Message-ID: <3af8a2682444d0f33619cc935dca0b4f@sanger.ac.uk>

I'm pretty new to R, and I've been given a script by a user who wants 
some help with it.  I know enough about the way R works to know that 
this is a very inefficient way to do what the user wants (the 
LSB_JOBINDEX stuff is added by me so that this can work on many 
hundreds of input data files as LSF jobs - it's the nested loops I'm 
really interested in):

gtpfile<-paste("genotype_chunk.", sep="", Sys.getenv("LSB_JOBINDEX"))
snps<-read.table(gtpfile,header=TRUE)
exp<-read.table("data.TXT",header=TRUE)
# the above two files have columns for individuals and snps (or genes) 
for rows
# so the next two lines simply transpose these data matrices
tsnps<-t(snps)
texp<-t(exp)
sink(paste("output.", sep="", Sys.getenv("LSB_JOBINDEX")))
#loops below are hardwired for 5 gene-expression levels (some genes 
have two
#probes, and those are treated as separate genes for now) and 100 SNPs.
for (iexp in 1:5){
    for (isnp in 1:100){
    genotype<-factor(tsnps[,isnp])
#     make sure there is more than one genotypic class before doing 
ANOVA
    if (length(unique(genotype))>1)  {
       expression<-texp[,iexp]
       stuff<-anova(lm(expression ~ genotype))
       qq=c(iexp,isnp)
       print (qq)
       print(stuff)
#     plot(factor(tsnps[,isnp]),texp[,iexp], xlab="Genotype", 
ylab="Expression
  level")
    }
}
}
sink()

Eventually, on the full data set, the size of the two data sets being 
related to each other will be much larger - several hundred thousand 
rows in snps, and several hundred rows in exp.

Clearly, the genotype<-factor line is being calculated repeatedly, and 
in the wrong place; it should be done en masse up front once the data 
has been read, and I'm sure both loops could actually be expressed some 
other way.

It seems to me that I ought to be able to calculate all the factors in 
a statement before the iexp loop, presumably by using apply() or 
aggregate(), but apply() seems to coerce the result so the results 
aren't factors any more, and I'm clearly missing something with regard 
to the way aggregate() works; I really don't understand what I'd need 
to set the 'by' parameter to.

I apologise if this is a hopelessly naive question, but I've got both 
the "Introduction to R" and Peter's introductory statistics with R book 
here, and I'm having some difficulty finding the information I'm after. 
"Introduction to R" doesn't mention the word "aggregate" once... :-)

Thanks in advance,

Tim

-- 
Dr Tim Cutts
Informatics Systems Group, Wellcome Trust Sanger Institute
GPG: 1024D/E3134233 FE3D 6C73 BBD6 726A A3F5  860B 3CDD 3F56 E313 4233



From maechler at stat.math.ethz.ch  Fri Mar  4 09:00:18 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 4 Mar 2005 09:00:18 +0100
Subject: [R] regression on a matrix
In-Reply-To: <D9A95B4B7B20354992E165EEADA31999056A9312@uswpmx00.merck.com>
References: <D9A95B4B7B20354992E165EEADA31999056A9312@uswpmx00.merck.com>
Message-ID: <16936.5522.945982.948611@stat.math.ethz.ch>

>>>>> "ReidH" == Huntsinger, Reid <reid_huntsinger at merck.com>
>>>>>     on Thu, 3 Mar 2005 17:24:22 -0500 writes:

    ReidH> You might use lsfit instead and just do the whole Y
    ReidH> matrix at once. That saves all the recalculation of
    ReidH> things involving only X.

yes,  but in these cases, we have been recommending
lm.fit() instead -- just so you use the identical internal
numeric code as lm() and still have the `benefit' of not having
to re-build the design matrix X .

Martin Maechler, ETH Zurich


    ReidH> Reid Huntsinger

    ReidH> -----Original Message----- From:
    ReidH> r-help-bounces at stat.math.ethz.ch
    ReidH> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf
    ReidH> Of Eduardo Leoni Sent: Thursday, March 03, 2005 5:16
    ReidH> PM To: r-help at stat.math.ethz.ch Subject: [R]
    ReidH> regression on a matrix


    ReidH> Hi -

    ReidH> I am doing a monte carlo experiment that requires to
    ReidH> do a linear regression of a matrix of vectors of
    ReidH> dependent variables on a fixed set of covariates (one
    ReidH> regression per vector). I am wondering if anyone has
    ReidH> any idea of how to speed up the computations in
    ReidH> R. The code follows:

    ReidH> #regression function #Linear regression code qreg <-
    ReidH> function(y,x) { X=cbind(1,x) m<-lm.fit(y=y,x=X)
    ReidH> p<-m$rank

    ReidH>   r <- m$residuals n <- length(r) rss <- sum(r^2)
    ReidH> resvar <- rss/(n - p)
  
    ReidH>   Qr <- m$qr p1 <- 1:p R <- chol2inv(Qr$qr[p1, p1,
    ReidH> drop = FALSE]) se <- sqrt(diag(R) * resvar) b <-
    ReidH> m$coefficients return(c(b[2],se[2])) }


    ReidH> #simulate a <- c(1,.63,.63,1) a <- matrix(a,2,2) c <-
    ReidH> chol(a) C <- 0.7 theta <- 0.8 sims <- 1000 n<-20

    ReidH> u <- rnorm(n,0,sqrt(1-C)) w <-
    ReidH> rgamma(n,C/theta,1/theta) e <- rnorm(n,0,sqrt(w))
  
    ReidH> x1 <- rnorm(n) x <- x1*c[2,2]+c[1,2]*w v <- e+u y <-
    ReidH> 1+x+v w <- rgamma(n,C/theta,1/theta)

    ReidH> #create matrix of dep variable newdep <-
    ReidH> matrix(rnorm(length(y)*sims,y,sqrt(w)),c(length(y),sims))


    ReidH> monte <- apply(newdep,2,qreg,x=x)

    ReidH> ______________________________________________
    ReidH> R-help at stat.math.ethz.ch mailing list
    ReidH> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE
    ReidH> do read the posting guide!
    ReidH> http://www.R-project.org/posting-guide.html

    ReidH> ______________________________________________
    ReidH> R-help at stat.math.ethz.ch mailing list
    ReidH> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE
    ReidH> do read the posting guide!
    ReidH> http://www.R-project.org/posting-guide.html



From dvrecko at sfu.ca  Fri Mar  4 09:39:27 2005
From: dvrecko at sfu.ca (dvrecko@sfu.ca)
Date: Fri, 04 Mar 2005 00:39:27 -0800
Subject: [R] Basic stratification calculations
Message-ID: <200503040839.j248dRCk015660@rm-rstar.sfu.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050304/3f92b339/attachment.pl

From vmuggeo at dssm.unipa.it  Fri Mar  4 09:48:59 2005
From: vmuggeo at dssm.unipa.it (vito muggeo)
Date: Fri, 04 Mar 2005 09:48:59 +0100
Subject: [R] Basic stratification calculations
In-Reply-To: <200503040839.j248dRCk015660@rm-rstar.sfu.ca>
References: <200503040839.j248dRCk015660@rm-rstar.sfu.ca>
Message-ID: <422820FB.1050301@dssm.unipa.it>

Hi,
if I understand correctly, tapply() is your friend here,

vito

dvrecko at sfu.ca wrote:
> 
> Hi. I'm a student at SFU in Canada. The basic thing I want to do is
> calculate means of different strata. I have 2 vectors. One has the values I
> want to take the means from, the other is the four strata I am interested
> in. So I essentially want to break up the information vector into the four
> strata and calculate four means, one for each stratum. How can I do this in
> a reasonable way?
> 
> 
> Thanks very much.
> Dean Vrecko
> 
> PS: Incidentally I forget how to see the code of functions. Does anyone
> remember the command to do this?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
====================================
Vito M.R. Muggeo
Dip.to Sc Statist e Matem `Vianelli'
Universit? di Palermo
viale delle Scienze, edificio 13
90121 Palermo - ITALY
tel: 091 6626240
fax: 091 485726/485612



From h.y.wong at leeds.ac.uk  Fri Mar  4 10:28:28 2005
From: h.y.wong at leeds.ac.uk (Yan Wong)
Date: Fri, 4 Mar 2005 09:28:28 +0000
Subject: [R] Simple suggestion for improvement
In-Reply-To: <1109870255.5978.24.camel@ramasamy.stats>
References: <cd0ba916953aac943d128f67c48e7d20@leeds.ac.uk>
	<q1od21tge7fg9g1ab1dd36pj6vo06sfmtu@4ax.com>
	<fbb1f20f7e191ad81689ea258f9162b7@leeds.ac.uk>
	<1109870255.5978.24.camel@ramasamy.stats>
Message-ID: <35d74282d2270153922f711de2ae97fc@leeds.ac.uk>


On 3 Mar 2005, at 17:17, Adaikalavan Ramasamy wrote:

> How will you deal with multiple word searches such as
>
> 	help.search("eps dev")
>
> One way to implement would be ??"eps dev" but this looks awkward to me.

That's what you have to do with the normal help function sometimes 
anyway, e.g.

?"+"
?"base-defunct"

etc.



From angel_lul at hotmail.com  Fri Mar  4 11:11:42 2005
From: angel_lul at hotmail.com (Angel Lopez)
Date: Fri, 04 Mar 2005 11:11:42 +0100
Subject: [R] Reconstructing Datasets
In-Reply-To: <Pine.LNX.4.44.0503012029010.4905-100000@gw.env.leeds.ac.uk>
References: <Pine.LNX.4.44.0503012029010.4905-100000@gw.env.leeds.ac.uk>
Message-ID: <4228345E.70102@hotmail.com>

Hi Laura,
You might want to have a look at function decevf in package pastecs.
It uses  eigenvector filtering to reconstruct a signal using only the 
most representative eigenvectors.
It is applied for time series but you could easily modify the code to 
use it for spatial data also.
Bests,
Angel

Laura Quinn wrote:
> Hi,
> 
> Is it possible to recreate "smoothed" data sets in R, by performing a PCA
> and then reconstructing a data set from say the first 2/3 EOFs?
> 
> I've had a look in the help pages and don't seem to find anything
> relevant.
> 
> Thanks in advance,
> Laura
> 
> Laura Quinn
> Institute of Atmospheric Science
> School of Earth and Environment
> University of Leeds
> Leeds
> LS2 9JT
> 
> tel: +44 113 343 1596
> fax: +44 113 343 6716
> mail: laura at env.leeds.ac.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> .
>



From Rau at demogr.mpg.de  Fri Mar  4 11:45:18 2005
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Fri, 4 Mar 2005 11:45:18 +0100
Subject: [R] ESS
Message-ID: <8B08A3A1EA7AAC41BE24C750338754E651FFCC@HERMES.demogr.mpg.de>

Hi, 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Mahdi Osman
> Sent: Thursday, March 03, 2005 11:57 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] ESS
> 
> 
> I can not start R proccess or ESS from within XEmacs. What is 
> going wrong?


Do you have a HOME directory?

AFAIK, XEmacs is going there to check for the file .emacs or for
.xemacs/init.el.
If you don't have one, I think XEmacs is checking C:\ as the default
location.
In my init.el-file I have the following lines:

(load "u:\\XEmacs\\xemacs-packages\\lisp\\ess\\ess-site")
(add-path "u:\\XEmacs\\xemacs-packages\\lisp\\ess\\")
(require 'ess-site)

Most likely you have to modify them according to your own settings. ;-)

You also have to modify the file ess-site.el
In my version of ESS you find the important lines you have to change at
about line 325. (If I remember correctly, the location in previous
versions of ESS was about line 250).

My line for R looks like:

(setq-default inferior-R-program-name "U:\\R\\rw2001\\bin\\Rterm.exe")
; msdos systems



> 
> I can not start S. M-x S gives "no matching"


Try M-x R
> 
> How can I configure XEmacs for STATA 8?

Probably the wrong mailing list?
However, if you have ESS corretly configured, you can open any *.do file
and XEmacs switches to ESS[STA] mode and supports syntax highlighting
and probably a lot more (I haven't used Stata for a while now - thanks
to R).

Hope this helps.

Best,
Roland

P.S. This is my version of ESS:
;;; ess-site.el --- user customization of ess-mode

;; Copyright (C) 1993 David M. Smith
;; Copyright (C) 1997--2004 A.J. Rossini, R.M. Heiberger, Martin
;; Maechler, Kurt Hornik, Rodney Sparapani, and Stephen Eglen.

;; Author: David Smith <D.M.Smith at lancaster.ac.uk>
;; Maintainer: A.J. Rossini <rossini at u.washington.edu>, 
;;             Martin Maechler <maechler at stat.math.ethz.ch>
;; Created: 12 Nov 1993
;; Modified: $Date: 2004/07/28 15:07:04 $
;; Version: $Revision: 1.3 $
;; RCS: $Id: ess-site.el,v 1.3 2004/07/28 15:07:04 rsparapa Exp $


+++++
This mail has been sent through the MPI for Demographic Rese...{{dropped}}



From chencheva at gmail.com  Fri Mar  4 11:49:29 2005
From: chencheva at gmail.com (Hu Chen)
Date: Fri, 4 Mar 2005 18:49:29 +0800
Subject: [R] how to draw graphs within clickable hyperlink
Message-ID: <6f3fc9ee050304024941af281c@mail.gmail.com>

Hi all
I want to draw a graph containing points and edges. Package graphics
could do this. However I want to make each those points and edges
clickable with a hyperlink on them.
Anybody know how to do this?
Thanks very much.



From Allan at STATS.uct.ac.za  Fri Mar  4 12:07:21 2005
From: Allan at STATS.uct.ac.za (Clark Allan)
Date: Fri, 04 Mar 2005 13:07:21 +0200
Subject: [R] R: simulation
Message-ID: <42284169.6608D6F9@STATS.uct.ac.za>

hi all

a simple question

i want to run simulations in r. i however want the experiments to be
repeated at a later time with exactly the same numbers by other users.
can i set the random number seed for rnorm in some way?

e.g. is there some arguement that goes with rnorm?

please supply an example

regards
Allan

From karlknoblich at yahoo.de  Fri Mar  4 12:14:49 2005
From: karlknoblich at yahoo.de (Karl Knoblick)
Date: Fri, 4 Mar 2005 12:14:49 +0100 (CET)
Subject: [R] bayesmix - What is or where can I find JAGS executable?
Message-ID: <20050304111449.20481.qmail@web26501.mail.ukl.yahoo.com>

Hallo!

I want to use the package bayesmix. Trying the
examples I had no success. The reason is, I think: 
> haveJAGS()
[1] FALSE

Have read of JAGS executable (I could not find
JAGS.exe in my R directory). What is JAGS? Where can I
find or download it?

Karl



From mdillies at pasteur.fr  Fri Mar  4 12:16:17 2005
From: mdillies at pasteur.fr (=?iso-8859-1?Q?Marie-Agn=E8s?= DILLIES)
Date: Fri, 04 Mar 2005 12:16:17 +0100
Subject: [R] reproducibility of the loess function
Message-ID: <5.0.2.1.2.20050304120748.00bfa3f0@mailhost.pasteur.fr>

Hi,

We noticed a difference between R versions 1.9.1 and 2.0.1 concerning the 
loess function. The resulting fitted data is quite different. Furthermore, 
with the 2.0.1 release, if I apply the loess function several times on the 
same input data set, I get different results.

Has anybody already noticed such a problem ?

Thanks

Marie-Agn?s



From matthieu.cornec at gmail.com  Fri Mar  4 12:32:22 2005
From: matthieu.cornec at gmail.com (Matthieu Cornec)
Date: Fri, 4 Mar 2005 03:32:22 -0800
Subject: [R] Concatenate vector into string
In-Reply-To: <8a83e50005021808354a6f6687@mail.gmail.com>
References: <8a83e50005021808354a6f6687@mail.gmail.com>
Message-ID: <8a83e5000503040332ac436b8@mail.gmail.com>

Hello,

I would like to convert c("a","b","c") into "abc".
Anyone could help?
Thanks,

Matthieu Cornec



From andy_liaw at merck.com  Fri Mar  4 12:33:49 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 4 Mar 2005 06:33:49 -0500
Subject: [R] regression on a matrix
Message-ID: <3A822319EB35174CA3714066D590DCD50994E7DA@usrymx25.merck.com>

> From: Martin Maechler
> 
> >>>>> "ReidH" == Huntsinger, Reid <reid_huntsinger at merck.com>
> >>>>>     on Thu, 3 Mar 2005 17:24:22 -0500 writes:
> 
>     ReidH> You might use lsfit instead and just do the whole Y
>     ReidH> matrix at once. That saves all the recalculation of
>     ReidH> things involving only X.
> 
> yes,  but in these cases, we have been recommending
> lm.fit() instead -- just so you use the identical internal
> numeric code as lm() and still have the `benefit' of not having
> to re-build the design matrix X .

Yes, but ?lm.fit says y has to be a vector, while ?lsfit says y can be a
matrix.  If lm.fit can handle y as a matrix, its help page should be
updated.

Andy

 
> Martin Maechler, ETH Zurich
> 
> 
>     ReidH> Reid Huntsinger
> 
>     ReidH> -----Original Message----- From:
>     ReidH> r-help-bounces at stat.math.ethz.ch
>     ReidH> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf
>     ReidH> Of Eduardo Leoni Sent: Thursday, March 03, 2005 5:16
>     ReidH> PM To: r-help at stat.math.ethz.ch Subject: [R]
>     ReidH> regression on a matrix
> 
> 
>     ReidH> Hi -
> 
>     ReidH> I am doing a monte carlo experiment that requires to
>     ReidH> do a linear regression of a matrix of vectors of
>     ReidH> dependent variables on a fixed set of covariates (one
>     ReidH> regression per vector). I am wondering if anyone has
>     ReidH> any idea of how to speed up the computations in
>     ReidH> R. The code follows:
> 
>     ReidH> #regression function #Linear regression code qreg <-
>     ReidH> function(y,x) { X=cbind(1,x) m<-lm.fit(y=y,x=X)
>     ReidH> p<-m$rank
> 
>     ReidH>   r <- m$residuals n <- length(r) rss <- sum(r^2)
>     ReidH> resvar <- rss/(n - p)
>   
>     ReidH>   Qr <- m$qr p1 <- 1:p R <- chol2inv(Qr$qr[p1, p1,
>     ReidH> drop = FALSE]) se <- sqrt(diag(R) * resvar) b <-
>     ReidH> m$coefficients return(c(b[2],se[2])) }
> 
> 
>     ReidH> #simulate a <- c(1,.63,.63,1) a <- matrix(a,2,2) c <-
>     ReidH> chol(a) C <- 0.7 theta <- 0.8 sims <- 1000 n<-20
> 
>     ReidH> u <- rnorm(n,0,sqrt(1-C)) w <-
>     ReidH> rgamma(n,C/theta,1/theta) e <- rnorm(n,0,sqrt(w))
>   
>     ReidH> x1 <- rnorm(n) x <- x1*c[2,2]+c[1,2]*w v <- e+u y <-
>     ReidH> 1+x+v w <- rgamma(n,C/theta,1/theta)
> 
>     ReidH> #create matrix of dep variable newdep <-
>     ReidH> matrix(rnorm(length(y)*sims,y,sqrt(w)),c(length(y),sims))
> 
> 
>     ReidH> monte <- apply(newdep,2,qreg,x=x)
> 
>     ReidH> ______________________________________________
>     ReidH> R-help at stat.math.ethz.ch mailing list
>     ReidH> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE
>     ReidH> do read the posting guide!
>     ReidH> http://www.R-project.org/posting-guide.html
> 
>     ReidH> ______________________________________________
>     ReidH> R-help at stat.math.ethz.ch mailing list
>     ReidH> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE
>     ReidH> do read the posting guide!
>     ReidH> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From ramseyer_amandine at yahoo.fr  Fri Mar  4 12:54:12 2005
From: ramseyer_amandine at yahoo.fr (Ramseyer Amandine)
Date: Fri, 4 Mar 2005 12:54:12 +0100 (CET)
Subject: [R] R 2.0.1 installation 
Message-ID: <20050304115412.95272.qmail@web25406.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050304/c1c85574/attachment.pl

From charshaw at presby.edu  Fri Mar  4 12:55:29 2005
From: charshaw at presby.edu (Clint Harshaw)
Date: Fri, 04 Mar 2005 06:55:29 -0500
Subject: [R] Basic stratification calculations
In-Reply-To: <422820FB.1050301@dssm.unipa.it>
References: <200503040839.j248dRCk015660@rm-rstar.sfu.ca>
	<422820FB.1050301@dssm.unipa.it>
Message-ID: <42284CB1.4010506@presby.edu>

vito muggeo wrote:
> Hi,
> if I understand correctly, tapply() is your friend here,
> 
> vito
> 
> dvrecko at sfu.ca wrote:
> 
>>
>> Hi. I'm a student at SFU in Canada. The basic thing I want to do is
>> calculate means of different strata. I have 2 vectors. One has the 
>> values I
>> want to take the means from, the other is the four strata I am interested
>> in. So I essentially want to break up the information vector into the 
>> four
>> strata and calculate four means, one for each stratum. How can I do 
>> this in
>> a reasonable way?
>>
>>
>> Thanks very much.
>> Dean Vrecko
>>
>> PS: Incidentally I forget how to see the code of functions. Does anyone
>> remember the command to do this?
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
> 

Would split(y,f) be of some help here? And then you could find the mean 
for each level of f:

y.split <- split(y,f)
mean(y.split$"0")
mean(y.split$"1")
mean(y.split$"2")
mean(y.split$"3")

Clint


-- 
Clint Harshaw, PhD		EMail: charshaw at presby.edu	
Department of Mathematics	Phone: 864.833.8995
Presbyterian College		Fax: 864.938.3769
Clinton SC  29325		Office: Harrington-Peachtree Rm 412



From ramasamy at cancer.org.uk  Fri Mar  4 13:02:00 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Fri, 04 Mar 2005 12:02:00 +0000
Subject: [R] ESS
In-Reply-To: <5abc11d805030319464564f871@mail.gmail.com>
References: <17801.1109890642@www37.gmx.net>
	<1109895563.6066.31.camel@dhcp-63.ccc.ox.ac.uk>
	<5abc11d805030319464564f871@mail.gmail.com>
Message-ID: <1109937720.6187.8.camel@localhost.localdomain>

I did not suggest the use of emacs over Xemacs (or vice versa) but was
merely suggesting that I have little experience with Xemacs and thus may
advice may be inaccurate to some level.

I do not know why Stata does not work for you. I never used Stata and
this is neither a Stata nor ESS mailing list. This is the R-help.

Have you checked :
https://stat.ethz.ch/mailman/listinfo/ess-help
http://stat.ethz.ch/ESS/Manual/ess.html
http://www.xemacs.org/Documentation/




On Fri, 2005-03-04 at 11:46 +0800, Shige Song wrote:
> It's not possible to invoke stata8 within Emacs buffer because the CLI
> interface of Stata for windows does not exist.
> 
> Shige
> 
> 
> On Fri, 04 Mar 2005 00:19:23 +0000, Adaikalavan Ramasamy
> <ramasamy at cancer.org.uk> wrote:
> > There is an ESS mailing list that might be more appropriate.
> > 
> > I use emacs rather than Xemacs, but I think you need to point the path
> > to ess in init.el file which is located on the home directory. E.g. :
> > 
> >    (setq ess-icon-directory "C:/Programme/xemacs-packages/etc/ess")
> >    (require 'ess-site)
> > 
> > Follow the excellent instructions at John Fox's website
> > http://socserv.mcmaster.ca/jfox/Books/Companion/ESS/
> > 
> > Then to start R, try 'M-x R'.
> > 
> > Regards, Adai
> > 
> > 
> > On Thu, 2005-03-03 at 23:57 +0100, Mahdi Osman wrote:
> > > Hi all,
> > >
> > > I am running R 2.0.1 under Windows XP in German. I configured my path as
> > > follows:
> > >
> > > C:\Programme\R\rw2001\bin;C:\Programme\xemacs-packages\lib-src\;C:\Programme\XEmacs-21.4.13\i586-pc-win32
> > >
> > > I can not start R proccess or ESS from within XEmacs. What is going wrong?
> > >
> > > I can not start S. M-x S gives "no matching"
> > >
> > > How can I configure XEmacs for STATA 8?
> > >
> > > Thanks for your help.
> > >
> > >
> > > M
> > >
> > >
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>



From dimitris.rizopoulos at med.kuleuven.ac.be  Fri Mar  4 13:11:18 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Fri, 4 Mar 2005 13:11:18 +0100
Subject: [R] R: simulation
References: <42284169.6608D6F9@STATS.uct.ac.za>
Message-ID: <006c01c520b3$45493e70$0540210a@www.domain>

look at ?set.seed, e.g.,

rnorm. <- function(seed, ...){
    set.seed(seed)
    rnorm(...)
}
#########
rnorm.(100, 1, 2)

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Clark Allan" <Allan at stats.uct.ac.za>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, March 04, 2005 12:07 PM
Subject: [R] R: simulation


> hi all
>
> a simple question
>
> i want to run simulations in r. i however want the experiments to be
> repeated at a later time with exactly the same numbers by other 
> users.
> can i set the random number seed for rnorm in some way?
>
> e.g. is there some arguement that goes with rnorm?
>
> please supply an example
>
> regards
> Allan


--------------------------------------------------------------------------------


> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From meier at stat.math.ethz.ch  Fri Mar  4 13:20:09 2005
From: meier at stat.math.ethz.ch (Lukas Meier)
Date: Fri, 4 Mar 2005 13:20:09 +0100
Subject: [R] R: simulation
In-Reply-To: <42284169.6608D6F9@STATS.uct.ac.za>
References: <42284169.6608D6F9@STATS.uct.ac.za>
Message-ID: <16936.21113.570637.506601@stat.math.ethz.ch>

Clark Allan writes:
 > i want to run simulations in r. i however want the experiments to be
 > repeated at a later time with exactly the same numbers by other users.
 > can i set the random number seed for rnorm in some way?
 > 
 > e.g. is there some arguement that goes with rnorm?

set.seed(79) ## replace 79 with another value if you don't like it
rnorm(10)

Hope this helps,

Lukas

-- 
Lukas Meier				http://stat.ethz.ch/people/meier/
Seminar fuer Statistik			phone:	+41 44 632 35 04
ETH-Zentrum, LEO D6			fax:	+41 44 632 12 28
CH-8092 Zurich, Switzerland



From Allan at STATS.uct.ac.za  Fri Mar  4 13:21:27 2005
From: Allan at STATS.uct.ac.za (Clark Allan)
Date: Fri, 04 Mar 2005 14:21:27 +0200
Subject: [R] R: simulation
References: <42284169.6608D6F9@STATS.uct.ac.za>
	<006c01c520b3$45493e70$0540210a@www.domain>
Message-ID: <422852C7.D536E17C@STATS.uct.ac.za>

Hi 

thanx for the reply.

i used your code and pasted it into R and ran it a few times. the output
is below. what i want is to get the same output every time the program
is run. is this possible? 

another question?

x<-rnorm(100)
y<-rnorm(100)

is x and y independent?


> rnorm(1)
[1] 0.4251004
> rnorm(1)
[1] -0.2386471
> rnorm(1)
[1] 1.058483
> rnorm(1)
[1] 0.8864227
> rnorm(1)
[1] -0.619243
> rnorm(1)
[1] 2.206102
> rnorm(1)
[1] -0.2550270
> rnorm(1)
[1] -1.424495
> rnorm(1)
[1] -0.1443996
> rnorm(1)
[1] 0.2075383
> rnorm(1)
[1] 2.307978
> rnorm(1)
[1] 0.1058024


Dimitris Rizopoulos wrote:
> 
> look at ?set.seed, e.g.,
> 
> rnorm. <- function(seed, ...){
>     set.seed(seed)
>     rnorm(...)
> }
> #########
> rnorm.(100, 1, 2)
> 
> I hope it helps.
> 
> Best,
> Dimitris
> 
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
> 
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/16/336899
> Fax: +32/16/337015
> Web: http://www.med.kuleuven.ac.be/biostat/
>      http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
> 
> ----- Original Message -----
> From: "Clark Allan" <Allan at stats.uct.ac.za>
> To: <r-help at stat.math.ethz.ch>
> Sent: Friday, March 04, 2005 12:07 PM
> Subject: [R] R: simulation
> 
> > hi all
> >
> > a simple question
> >
> > i want to run simulations in r. i however want the experiments to be
> > repeated at a later time with exactly the same numbers by other
> > users.
> > can i set the random number seed for rnorm in some way?
> >
> > e.g. is there some arguement that goes with rnorm?
> >
> > please supply an example
> >
> > regards
> > Allan
> 
> --------------------------------------------------------------------------------
> 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html

From petr.pikal at precheza.cz  Fri Mar  4 13:26:53 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 04 Mar 2005 13:26:53 +0100
Subject: [R] R: simulation
In-Reply-To: <42284169.6608D6F9@STATS.uct.ac.za>
Message-ID: <4228621D.18325.13FA103@localhost>



On 4 Mar 2005 at 13:07, Clark Allan wrote:

> hi all
> 
> a simple question
> 
> i want to run simulations in r. i however want the experiments to be
> repeated at a later time with exactly the same numbers by other users.
> can i set the random number seed for rnorm in some way?

See ?set.seed
It is called once before rnorm generator

> set.seed(1)
> rnorm(10)
 [1] -0.6264538  0.1836433 -0.8356286  1.5952808  0.3295078 -
0.8204684  0.4874291  0.7383247  0.5757814 -0.3053884

> set.seed(10)
> rnorm(10)
 [1]  0.01874617 -0.18425254 -1.37133055 -0.59916772  0.29454513  
0.38979430 -1.20807618 -0.36367602 -1.62667268 -0.25647839

> set.seed(1)
> rnorm(10)
 [1] -0.6264538  0.1836433 -0.8356286  1.5952808  0.3295078 -
0.8204684  0.4874291  0.7383247  0.5757814 -0.3053884
>

Cheers.
Petr


> 
> e.g. is there some arguement that goes with rnorm?
> 
> please supply an example
> 
> regards
> Allan

Petr Pikal
petr.pikal at precheza.cz



From detlef.steuer at hsu-hh.de  Fri Mar  4 13:31:25 2005
From: detlef.steuer at hsu-hh.de (Detlef Steuer)
Date: Fri, 4 Mar 2005 13:31:25 +0100
Subject: [R] R: simulation
In-Reply-To: <42284169.6608D6F9@STATS.uct.ac.za>
References: <42284169.6608D6F9@STATS.uct.ac.za>
Message-ID: <20050304133125.6f85bfc5@gaia.unibw-hamburg.de>

On Fri, 04 Mar 2005 13:07:21 +0200
Clark Allan <Allan at STATS.uct.ac.za> wrote:

> hi all
> 
> a simple question
> 
> i want to run simulations in r. i however want the experiments to be
> repeated at a later time with exactly the same numbers by other users.
> can i set the random number seed for rnorm in some way?

See ?.Random.seed 

Btw: it's on the help page for rnorm ...

Detlef

> 
> e.g. is there some arguement that goes with rnorm?
> 
> please supply an example
> 
> regards
> Allan



From dimitris.rizopoulos at med.kuleuven.ac.be  Fri Mar  4 13:32:37 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Fri, 4 Mar 2005 13:32:37 +0100
Subject: [R] R: simulation
References: <42284169.6608D6F9@STATS.uct.ac.za>
	<006c01c520b3$45493e70$0540210a@www.domain>
	<422852C7.D536E17C@STATS.uct.ac.za>
Message-ID: <008001c520b6$400540f0$0540210a@www.domain>

are you sure you tried the function I gave you? There is a "." that 
you might have missed. When I try it I get this:

> rnorm. <- function(seed, ...){
+      set.seed(seed)
+     rnorm(...)
+ }
> #########
> rnorm.(1, 1)
[1] -0.6264538
> rnorm.(1, 1)
[1] -0.6264538
> rnorm.(1, 1)
[1] -0.6264538
> rnorm.(1, 1)
[1] -0.6264538
> rnorm.(1, 1)
[1] -0.6264538
> rnorm.(1, 1)
[1] -0.6264538

Observe that the first argument is the seed, `...' is used to pass 
arguments to `rnorm()'!

x <- rnorm(100)
y <- rnorm(100)

are independent, however,

x <- rnorm.(1, 100)
y <- rnorm.(1, 100)

will be exactly the same.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Clark Allan" <Allan at STATS.uct.ac.za>
To: "Dimitris Rizopoulos" <dimitris.rizopoulos at med.kuleuven.ac.be>; 
<r-help at stat.math.ethz.ch>
Sent: Friday, March 04, 2005 1:21 PM
Subject: Re: [R] R: simulation


> Hi
>
> thanx for the reply.
>
> i used your code and pasted it into R and ran it a few times. the 
> output
> is below. what i want is to get the same output every time the 
> program
> is run. is this possible?
>
> another question?
>
> x<-rnorm(100)
> y<-rnorm(100)
>
> is x and y independent?
>
>
>> rnorm(1)
> [1] 0.4251004
>> rnorm(1)
> [1] -0.2386471
>> rnorm(1)
> [1] 1.058483
>> rnorm(1)
> [1] 0.8864227
>> rnorm(1)
> [1] -0.619243
>> rnorm(1)
> [1] 2.206102
>> rnorm(1)
> [1] -0.2550270
>> rnorm(1)
> [1] -1.424495
>> rnorm(1)
> [1] -0.1443996
>> rnorm(1)
> [1] 0.2075383
>> rnorm(1)
> [1] 2.307978
>> rnorm(1)
> [1] 0.1058024
>
>
> Dimitris Rizopoulos wrote:
>>
>> look at ?set.seed, e.g.,
>>
>> rnorm. <- function(seed, ...){
>>     set.seed(seed)
>>     rnorm(...)
>> }
>> #########
>> rnorm.(100, 1, 2)
>>
>> I hope it helps.
>>
>> Best,
>> Dimitris
>>
>> ----
>> Dimitris Rizopoulos
>> Ph.D. Student
>> Biostatistical Centre
>> School of Public Health
>> Catholic University of Leuven
>>
>> Address: Kapucijnenvoer 35, Leuven, Belgium
>> Tel: +32/16/336899
>> Fax: +32/16/337015
>> Web: http://www.med.kuleuven.ac.be/biostat/
>>      http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
>>
>> ----- Original Message -----
>> From: "Clark Allan" <Allan at stats.uct.ac.za>
>> To: <r-help at stat.math.ethz.ch>
>> Sent: Friday, March 04, 2005 12:07 PM
>> Subject: [R] R: simulation
>>
>> > hi all
>> >
>> > a simple question
>> >
>> > i want to run simulations in r. i however want the experiments to 
>> > be
>> > repeated at a later time with exactly the same numbers by other
>> > users.
>> > can i set the random number seed for rnorm in some way?
>> >
>> > e.g. is there some arguement that goes with rnorm?
>> >
>> > please supply an example
>> >
>> > regards
>> > Allan
>>
>> --------------------------------------------------------------------------------
>>
>> > ______________________________________________
>> > R-help at stat.math.ethz.ch mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide!
>> > http://www.R-project.org/posting-guide.html



From gruen at ci.tuwien.ac.at  Fri Mar  4 13:33:03 2005
From: gruen at ci.tuwien.ac.at (Bettina Gruen)
Date: Fri, 04 Mar 2005 13:33:03 +0100
Subject: [R] bayesmix - What is or where can I find JAGS executable?
In-Reply-To: <20050304111449.20481.qmail@web26501.mail.ukl.yahoo.com>
References: <20050304111449.20481.qmail@web26501.mail.ukl.yahoo.com>
Message-ID: <4228557F.7030205@ci.tuwien.ac.at>

Hi Karl!

In the DESCRIPTION file there is the package homepage 
(www.ci.tuwien.ac.at/~gruen/BayesMix) indicated. You can download the 
windows binaries together with JAGS.exe from this page or follow the 
link to Martyn Plummer's JAGS homepage where you can get the sources for 
compiling jags for other platforms.

BTW: It is always a good idea to send questions also to the package 
maintainer.

Best,
Bettina

Karl Knoblick wrote:
> Hallo!
> 
> I want to use the package bayesmix. Trying the
> examples I had no success. The reason is, I think: 
> 
>>haveJAGS()
> 
> [1] FALSE
> 
> Have read of JAGS executable (I could not find
> JAGS.exe in my R directory). What is JAGS? Where can I
> find or download it?
> 
> Karl
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
-------------------------------------------------------------------
Bettina Gr?n
Institut f?r Statistik
Technische Universit?t Wien
Wiedner Hauptstra?e 8-10/1071
A-1040 Wien, ?sterreich
Tel: (+43 1) 58801 10716
Fax: (+43 1) 58801 10798



From ccleland at optonline.net  Fri Mar  4 13:38:20 2005
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 04 Mar 2005 07:38:20 -0500
Subject: [R] Concatenate vector into string
In-Reply-To: <8a83e5000503040332ac436b8@mail.gmail.com>
References: <8a83e50005021808354a6f6687@mail.gmail.com>
	<8a83e5000503040332ac436b8@mail.gmail.com>
Message-ID: <422856BC.4060008@optonline.net>

Matthieu Cornec wrote:
> Hello,
> 
> I would like to convert c("a","b","c") into "abc".
> Anyone could help?

?paste

paste(c("a","b","c"), collapse="")

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From ligges at statistik.uni-dortmund.de  Fri Mar  4 13:38:09 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 04 Mar 2005 13:38:09 +0100
Subject: [R] R: simulation
In-Reply-To: <42284169.6608D6F9@STATS.uct.ac.za>
References: <42284169.6608D6F9@STATS.uct.ac.za>
Message-ID: <422856B1.5000905@statistik.uni-dortmund.de>

Clark Allan wrote:

> hi all
> 
> a simple question
> 
> i want to run simulations in r. i however want the experiments to be
> repeated at a later time with exactly the same numbers by other users.
> can i set the random number seed for rnorm in some way?
> 
> e.g. is there some arguement that goes with rnorm?
> 
> please supply an example
> 
> regards
> Allan
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Please read the docs and in particular: ?set.seed

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Fri Mar  4 13:39:24 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 04 Mar 2005 13:39:24 +0100
Subject: [R] bayesmix - What is or where can I find JAGS executable?
In-Reply-To: <20050304111449.20481.qmail@web26501.mail.ukl.yahoo.com>
References: <20050304111449.20481.qmail@web26501.mail.ukl.yahoo.com>
Message-ID: <422856FC.6020002@statistik.uni-dortmund.de>

Karl Knoblick wrote:

> Hallo!
> 
> I want to use the package bayesmix. Trying the
> examples I had no success. The reason is, I think: 
> 
>>haveJAGS()
> 
> [1] FALSE
> 
> Have read of JAGS executable (I could not find
> JAGS.exe in my R directory). What is JAGS? Where can I
> find or download it?

What about googling for "JAGS.exe"?

Uwe Ligges



> Karl
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Saghir.Bashir at UCB-Group.com  Fri Mar  4 13:42:48 2005
From: Saghir.Bashir at UCB-Group.com (Bashir Saghir (Aztek Global))
Date: Fri, 4 Mar 2005 13:42:48 +0100 
Subject: [R] Concatenate vector into string
Message-ID: <3EBA5559F490D61189430002A5F0AE8905632B22@ntexcrd.braine.ucb>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050304/1940e689/attachment.pl

From ligges at statistik.uni-dortmund.de  Fri Mar  4 13:43:20 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 04 Mar 2005 13:43:20 +0100
Subject: [R] Concatenate vector into string
In-Reply-To: <8a83e5000503040332ac436b8@mail.gmail.com>
References: <8a83e50005021808354a6f6687@mail.gmail.com>
	<8a83e5000503040332ac436b8@mail.gmail.com>
Message-ID: <422857E8.1040309@statistik.uni-dortmund.de>

Matthieu Cornec wrote:

> Hello,
> 
> I would like to convert c("a","b","c") into "abc".
> Anyone could help?

See ?paste

Uwe Ligges


> Thanks,
> 
> Matthieu Cornec
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From sdavis2 at mail.nih.gov  Fri Mar  4 13:46:18 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 04 Mar 2005 07:46:18 -0500
Subject: [R] Rank-based p-value on large dataset
In-Reply-To: <200503031640.55824.deepayan@stat.wisc.edu>
Message-ID: <BE4DC2CA.3C29%sdavis2@mail.nih.gov>

On 3/3/05 17:40, "Deepayan Sarkar" <deepayan at stat.wisc.edu> wrote:

> On Thursday 03 March 2005 16:32, Deepayan Sarkar wrote:
>> On Thursday 03 March 2005 16:22, Sean Davis wrote:
>>> I have a fairly simple problem--I have about 80,000 values (call
>>> them y) that I am using as an empirical distribution and I want to
>>> find the p-value (never mind the multiple testing issues here, for
>>> the time being) of 130,000 points (call them x) from the empirical
>>> distribution. I typically do that (for one-sided test) something
>>> like
>>> 
>>> loop over i in x
>>> p.val[i] = sum(y>x[i])/length(y)
>>> 
>>> and repeat for all i.  However, length(x) is large here as is
>>> length(y), so this process takes quite a long time.  Any
>>> suggestions?
>> 
>> The obvious thing to do would be
>> 
>> p.val = 1 - ecdf(x)(y)
> 
> or rather: p.val = 1 - ecdf(y)(x)
> 

Deepayan,

Thanks (and to Martin, also).  This works wonderfully.  I didn't expect such
a function to exist, but knowing of it will simplify matters significantly
for me.  

Sean



From ramasamy at cancer.org.uk  Fri Mar  4 13:52:04 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Fri, 04 Mar 2005 12:52:04 +0000
Subject: [R] R: simulation
In-Reply-To: <42284169.6608D6F9@STATS.uct.ac.za>
References: <42284169.6608D6F9@STATS.uct.ac.za>
Message-ID: <1109940724.6187.23.camel@localhost.localdomain>

See help("set.seed").

set.seed(1)

rnorm(5)
[1] -0.6264538  0.1836433 -0.8356286  1.5952808  0.3295078

rnorm(5)
[1] -0.8204684  0.4874291  0.7383247  0.5757814 -0.3053884


set.seed(1)
rnorm(5)
[1] -0.6264538  0.1836433 -0.8356286  1.5952808  0.3295078



On Fri, 2005-03-04 at 13:07 +0200, Clark Allan wrote:
> hi all
> 
> a simple question
> 
> i want to run simulations in r. i however want the experiments to be
> repeated at a later time with exactly the same numbers by other users.
> can i set the random number seed for rnorm in some way?
> 
> e.g. is there some arguement that goes with rnorm?
> 
> please supply an example
> 
> regards
> Allan
> ______________________________________________ R-help at stat.math.ethz.ch mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ramasamy at cancer.org.uk  Fri Mar  4 13:53:31 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Fri, 04 Mar 2005 12:53:31 +0000
Subject: [R] Concatenate vector into string
In-Reply-To: <8a83e5000503040332ac436b8@mail.gmail.com>
References: <8a83e50005021808354a6f6687@mail.gmail.com>
	<8a83e5000503040332ac436b8@mail.gmail.com>
Message-ID: <1109940811.6187.25.camel@localhost.localdomain>

Use the collapse argument in paste.

paste( c("a", "b", "c"), collapse="" )
[1] "abc"



On Fri, 2005-03-04 at 03:32 -0800, Matthieu Cornec wrote:
> Hello,
> 
> I would like to convert c("a","b","c") into "abc".
> Anyone could help?
> Thanks,
> 
> Matthieu Cornec
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From fm3a004 at math.uni-hamburg.de  Fri Mar  4 13:53:22 2005
From: fm3a004 at math.uni-hamburg.de (Christian Hennig)
Date: Fri, 4 Mar 2005 13:53:22 +0100 (MET)
Subject: [R] R: simulation
In-Reply-To: <42284169.6608D6F9@STATS.uct.ac.za>
Message-ID: <Pine.GSO.3.95q.1050304135310.22044B-100000@sun11.math.uni-hamburg.de>

?set.seed

On Fri, 4 Mar 2005, Clark Allan wrote:

> hi all
> 
> a simple question
> 
> i want to run simulations in r. i however want the experiments to be
> repeated at a later time with exactly the same numbers by other users.
> can i set the random number seed for rnorm in some way?
> 
> e.g. is there some arguement that goes with rnorm?
> 
> please supply an example
> 
> regards
> Allan

***********************************************************************
Christian Hennig
Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
>From 1 April 2005: Department of Statistical Science, UCL, London
#######################################################################
ich empfehle www.boag-online.de



From pierre.bady at univ-lyon1.fr  Fri Mar  4 14:01:04 2005
From: pierre.bady at univ-lyon1.fr (Pierre BADY)
Date: Fri, 04 Mar 2005 14:01:04 +0100
Subject: [R] Concatenate vector into string
In-Reply-To: <8a83e5000503040332ac436b8@mail.gmail.com>
References: <8a83e50005021808354a6f6687@mail.gmail.com>
	<8a83e50005021808354a6f6687@mail.gmail.com>
Message-ID: <5.1.0.14.2.20050304135854.00ba90c8@pop.univ-lyon1.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050304/993d4c07/attachment.pl

From matthieu.cornec at gmail.com  Fri Mar  4 14:10:50 2005
From: matthieu.cornec at gmail.com (Matthieu Cornec)
Date: Fri, 4 Mar 2005 05:10:50 -0800
Subject: [R] lm and time series
Message-ID: <8a83e5000503040510433fc792@mail.gmail.com>

Hello,


I create a multivariate time series containing NA values (that could
come directly from an imported file,)
I want to compute a linear regression and obtain a time serie for both
residuals and fitted values. I have tried the trick ts.intersect,
without success.

Could you help me out of this?
####
Example:

y<-ts(1:10+rnorm(10))
x<-ts(1:10)
datats<-cbind(y,lagx=lag(x))

Notice the datats could come directly from an imported file, that is
why I did not use ts.intersect(y,lagx=lag(x))

fit<-lm(y~lagx,data=datats,na.action=na.omit)

but how do I get a time serie of residuals instead of a vector residuals(fit)?
######

Matthieu Cornec



From damian.betebenner at bc.edu  Fri Mar  4 14:20:16 2005
From: damian.betebenner at bc.edu (Damian Betebenner)
Date: Fri, 04 Mar 2005 08:20:16 -0500
Subject: [R] how to draw graphs within clickable hyperlink
Message-ID: <web-3631271@be1.bc.edu>

Hu,

I've found two methods of doing this---1 in R and the other in S-Plus.

1. The S-Plus solution is called graphlets which are a java-based graphics
device that allows one to build various types of interactivity into their graphs.

2. The R solution uses the gridSVG package by Paul Murrell. The package is
experimental, but I've found it to work nicely. The package can be downloaded
from

http://www.stat.auckland.ac.nz/~paul/

I'd be interested in knowing others' solutions. 



Damian Betebenner
Educational Research, Measurement & Evaluation
Lynch School of Education
Boston College
Chestnut Hill, MA 02467

(617) 552 4491



From andy_liaw at merck.com  Fri Mar  4 14:25:35 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 4 Mar 2005 08:25:35 -0500
Subject: [R] R: simulation
Message-ID: <3A822319EB35174CA3714066D590DCD50994E7DB@usrymx25.merck.com>

See ?set.seed.  

Andy

> From: Clark Allan
> 
> hi all
> 
> a simple question
> 
> i want to run simulations in r. i however want the experiments to be
> repeated at a later time with exactly the same numbers by other users.
> can i set the random number seed for rnorm in some way?
> 
> e.g. is there some arguement that goes with rnorm?
> 
> please supply an example
> 
> regards
> Allan
>



From sdavis2 at mail.nih.gov  Fri Mar  4 14:27:59 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 4 Mar 2005 08:27:59 -0500
Subject: [R] Basic stratification calculations
In-Reply-To: <42284CB1.4010506@presby.edu>
References: <200503040839.j248dRCk015660@rm-rstar.sfu.ca>
	<422820FB.1050301@dssm.unipa.it> <42284CB1.4010506@presby.edu>
Message-ID: <a8eb2b91d49860544c7baddc468151b7@mail.nih.gov>


On Mar 4, 2005, at 6:55 AM, Clint Harshaw wrote:

> vito muggeo wrote:
>> Hi,
>> if I understand correctly, tapply() is your friend here,
>> vito
>> dvrecko at sfu.ca wrote:
>>>
>>> Hi. I'm a student at SFU in Canada. The basic thing I want to do is
>>> calculate means of different strata. I have 2 vectors. One has the 
>>> values I
>>> want to take the means from, the other is the four strata I am 
>>> interested
>>> in. So I essentially want to break up the information vector into 
>>> the four
>>> strata and calculate four means, one for each stratum. How can I do 
>>> this in
>>> a reasonable way?
>>>
>>>
>>> Thanks very much.
>>> Dean Vrecko
>>>
>>> PS: Incidentally I forget how to see the code of functions. Does 
>>> anyone
>>> remember the command to do this?
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! 
>>> http://www.R-project.org/posting-guide.html
>>>
>
> Would split(y,f) be of some help here? And then you could find the 
> mean for each level of f:
>
> y.split <- split(y,f)
> mean(y.split$"0")
> mean(y.split$"1")
> mean(y.split$"2")
> mean(y.split$"3")

You can automate this using aggregate:

 > a <- rep(c('A','B','C','D'),25)
 > b <- rnorm(100)
 > aggregate(b,by=list(a),mean)
   Group.1          x
1       A  0.1409995
2       B -0.1524387
3       C  0.3329184
4       D  0.1354157

Sean



From andy_liaw at merck.com  Fri Mar  4 14:27:33 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 4 Mar 2005 08:27:33 -0500
Subject: [R] how to draw graphs within clickable hyperlink
Message-ID: <3A822319EB35174CA3714066D590DCD50994E7DC@usrymx25.merck.com>

You need to output the graph in a format that allow such interactivity.  I
believe svg (available through the svgDevice package on CRAN) can do that.

Andy

> From: Hu Chen
> 
> Hi all
> I want to draw a graph containing points and edges. Package graphics
> could do this. However I want to make each those points and edges
> clickable with a hyperlink on them.
> Anybody know how to do this?
> Thanks very much.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From andy_liaw at merck.com  Fri Mar  4 14:31:53 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 4 Mar 2005 08:31:53 -0500
Subject: [R] Concatenate vector into string
Message-ID: <3A822319EB35174CA3714066D590DCD50994E7DD@usrymx25.merck.com>

See ?paste, e.g.,

> char <- c("a", "b", "c")
> paste(char, collapse="")
[1] "abc"

Andy

> From: Matthieu Cornec
> 
> Hello,
> 
> I would like to convert c("a","b","c") into "abc".
> Anyone could help?
> Thanks,
> 
> Matthieu Cornec
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From spencer.graves at pdf.com  Fri Mar  4 14:51:47 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 04 Mar 2005 05:51:47 -0800
Subject: [R] R: simulation
In-Reply-To: <42284169.6608D6F9@STATS.uct.ac.za>
References: <42284169.6608D6F9@STATS.uct.ac.za>
Message-ID: <422867F3.6080302@pdf.com>

      The help page for "rnorm" says "See Also:  ... '.Random.seed' 
...", and the help page for ".Random.seed" says, " 'set.seed' is the 
recommended way to specify seeds."

      hope this helps. 
      spencer graves

Clark Allan wrote:

>hi all
>
>a simple question
>
>i want to run simulations in r. i however want the experiments to be
>repeated at a later time with exactly the same numbers by other users.
>can i set the random number seed for rnorm in some way?
>
>e.g. is there some arguement that goes with rnorm?
>
>please supply an example
>
>regards
>Allan
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From W.E.Wolski at ncl.ac.uk  Fri Mar  4 14:52:08 2005
From: W.E.Wolski at ncl.ac.uk (Witold Eryk Wolski)
Date: Fri, 04 Mar 2005 14:52:08 +0100
Subject: [R] Concatenate vector into string
In-Reply-To: <8a83e5000503040332ac436b8@mail.gmail.com>
References: <8a83e50005021808354a6f6687@mail.gmail.com>
	<8a83e5000503040332ac436b8@mail.gmail.com>
Message-ID: <42286808.5060300@ncl.ac.uk>

Matthieu Cornec wrote:

>Hello,
>
>I would like to convert c("a","b","c") into "abc".
>Anyone could help?
>Thanks,
>
>Matthieu Cornec
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>

paste( c("a","b","c"),collapse="")


Eryk

-- 
Witold Eryk Wolski
__("<  School of Mathematics and Statistics     _
\__/   University of Newcastle                 'v'
 ||    Newcastle upon Tyne, NE1 7RU, ENGLAND  /   \
 ^^    mail: witek96 at users.sourceforge.net     m m
       Phone : 044 (0)191 222 5376
       FAX   : 044 (0)191 222 8020



From p.dalgaard at biostat.ku.dk  Fri Mar  4 14:51:04 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 04 Mar 2005 14:51:04 +0100
Subject: [R] R: simulation
In-Reply-To: <42284169.6608D6F9@STATS.uct.ac.za>
References: <42284169.6608D6F9@STATS.uct.ac.za>
Message-ID: <x27jkneczb.fsf@biostat.ku.dk>

Clark Allan <Allan at STATS.uct.ac.za> writes:

> hi all
> 
> a simple question
> 
> i want to run simulations in r. i however want the experiments to be
> repeated at a later time with exactly the same numbers by other users.
> can i set the random number seed for rnorm in some way?
> 
> e.g. is there some arguement that goes with rnorm?
> 
> please supply an example

Do read the help page for rnorm, in particular the "See Also" section.

> regards
> Allan______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From spencer.graves at pdf.com  Fri Mar  4 14:59:51 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 04 Mar 2005 05:59:51 -0800
Subject: [R] bayesmix - What is or where can I find JAGS executable?
In-Reply-To: <20050304111449.20481.qmail@web26501.mail.ukl.yahoo.com>
References: <20050304111449.20481.qmail@web26501.mail.ukl.yahoo.com>
Message-ID: <422869D7.40109@pdf.com>

      I did "www.r-project.org" -> search -> "R site search" -> 
bayesmix.  The first hit told me it was a package, which I confirmed by 
trying "www.r-project.org" -> "download:  CRAN" -> (select a local 
mirror) -> "Software:  Packages".  There, I found "bayesmix" listed. 

      Then I used 'install.packages("bayesmix")'.  A few minutes later 
(with a voice grade line), it told me, "package 'bayesmix' successfully 
unpacked and MD5 sums checked". 

      hope this helps. 
      spencer graves

Karl Knoblick wrote:

>Hallo!
>
>I want to use the package bayesmix. Trying the
>examples I had no success. The reason is, I think: 
>  
>
>>haveJAGS()
>>    
>>
>[1] FALSE
>
>Have read of JAGS executable (I could not find
>JAGS.exe in my R directory). What is JAGS? Where can I
>find or download it?
>
>Karl
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From spencer.graves at pdf.com  Fri Mar  4 15:02:02 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 04 Mar 2005 06:02:02 -0800
Subject: [R] Concatenate vector into string
In-Reply-To: <8a83e5000503040332ac436b8@mail.gmail.com>
References: <8a83e50005021808354a6f6687@mail.gmail.com>
	<8a83e5000503040332ac436b8@mail.gmail.com>
Message-ID: <42286A5A.9070200@pdf.com>

      How about: 

      > paste( c("a","b","c"), collapse="")
[1] "abc"
 >
      hope this helps. 
      spencer graves

Matthieu Cornec wrote:

>Hello,
>
>I would like to convert c("a","b","c") into "abc".
>Anyone could help?
>Thanks,
>
>Matthieu Cornec
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From r.hankin at soc.soton.ac.uk  Fri Mar  4 15:06:02 2005
From: r.hankin at soc.soton.ac.uk (Robin Hankin)
Date: Fri, 4 Mar 2005 14:06:02 +0000
Subject: [R] Farey sequences
Message-ID: <136a085d5db383acf4ba5f3fc0c770cc@soc.soton.ac.uk>

Hi

has anyone coded up Farey sequences?

[
The Farey sequence of order "n"  is the set of  rational numbers i/j
with (i,j)=1 such that 0 <= i,j <= n; the sequence is ordered from 
lowest to highest.
Thus

Farey_4 = {0/1 , 1/4 , 1/3 , 1/2 , 2/3 , 3/4 , 1/1}
]

My motivation is unimodular transformations: I need to systematically
generate 2-by-2 integer matrices with determinant 1, and Farey sequences
seem to be the best way to do this.




--
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From tjrc at sanger.ac.uk  Fri Mar  4 15:10:09 2005
From: tjrc at sanger.ac.uk (Tim Cutts)
Date: Fri, 4 Mar 2005 14:10:09 +0000
Subject: [R] Concatenate vector into string
In-Reply-To: <8a83e5000503040332ac436b8@mail.gmail.com>
References: <8a83e50005021808354a6f6687@mail.gmail.com>
	<8a83e5000503040332ac436b8@mail.gmail.com>
Message-ID: <f3db9d2e45fb08b2a08a6976ac20d283@sanger.ac.uk>


On 4 Mar 2005, at 11:32 am, Matthieu Cornec wrote:

> Hello,
>
> I would like to convert c("a","b","c") into "abc".
> Anyone could help?

paste(c("a", "b", "c"), sep="")

Tim

-- 
Dr Tim Cutts
Informatics Systems Group, Wellcome Trust Sanger Institute
GPG: 1024D/E3134233 FE3D 6C73 BBD6 726A A3F5  860B 3CDD 3F56 E313 4233



From ramasamy at cancer.org.uk  Fri Mar  4 15:19:30 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Fri, 04 Mar 2005 14:19:30 +0000
Subject: [R] R 2.0.1 installation
In-Reply-To: <20050304115412.95272.qmail@web25406.mail.ukl.yahoo.com>
References: <20050304115412.95272.qmail@web25406.mail.ukl.yahoo.com>
Message-ID: <1109945971.7879.1.camel@localhost.localdomain>

Are you using Windows operating system ? If so, then you will need to
download the executable not the source codes from
http://www.cran.r-project.org/bin/windows/base/rw2001.exe

Regards, Adai



On Fri, 2005-03-04 at 12:54 +0100, Ramseyer Amandine wrote:
> 
> Hello,
>  
> I'm a student in biology, writting from Strasbourg, France.
> I need to use the logiciel R to analyse biological results. I have ADE4 since 2001, but technology's now largely evoluted !
>  
> That's why I'm just trying to get the new version of :
> - ADE4_1.3-3.zip ; 
> - R 2.0.1.ter ; 
> - DCluster_0.1-3.zip.
> However, I don't know HOW TO INSTALL R on my computer ? I don't understand help's files because they refer to a great number of files ! So could you just indicate me : WHICH FILE(s) HAVE I TO OPEN TO INSTALL R ? 
>  
> Moreover I'd like to know if DCluster, CRAN and ADE4 are necessary or if R alone makes the same analyses (cluster analysis, linear hierarchy,...) ? (maybe this logiciels belong to R?)
>  
> Thanks a lot !
>  
> Best regards,  
>  
> Amandine RAMSEYER
> Laboratoire d'Ethologie
> CNRS UPR 9010
> 7 rue de l'Universit
> 67000 Strasbourg
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 		
> ---------------------------------
> 
> mails !
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From s_fakheran at yahoo.com  Fri Mar  4 15:51:21 2005
From: s_fakheran at yahoo.com (sima fakheran)
Date: Fri, 4 Mar 2005 06:51:21 -0800 (PST)
Subject: [R] Clustering of Binary data in R
Message-ID: <20050304145121.89264.qmail@web31110.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050304/5d50345a/attachment.pl

From ILAIKEREN at msn.com  Fri Mar  4 15:54:46 2005
From: ILAIKEREN at msn.com (ILAI KEREN)
Date: Fri, 4 Mar 2005 07:54:46 -0700
Subject: [R] Multilevel modeling of animal behavior
Message-ID: <BAY5-DAV32220174032AD1FB76685FBF5C0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050304/ec0d37a7/attachment.pl

From ggrothendieck at myway.com  Fri Mar  4 16:53:45 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri,  4 Mar 2005 10:53:45 -0500 (EST)
Subject: [R] lm and time series
Message-ID: <20050304155345.C4C0A12D5C@mprdmxin.myway.com>


 
From:   Matthieu Cornec <matthieu.cornec at gmail.com>
 
> I create a multivariate time series containing NA values (that could
> come directly from an imported file,)
> I want to compute a linear regression and obtain a time serie for both
> residuals and fitted values. I have tried the trick ts.intersect,
> without success.
> 
> Could you help me out of this?
> ####
> Example:
> 
> y<-ts(1:10+rnorm(10))
> x<-ts(1:10)
> datats<-cbind(y,lagx=lag(x))
> 
> Notice the datats could come directly from an imported file, that is
> why I did not use ts.intersect(y,lagx=lag(x))
> 
> fit<-lm(y~lagx,data=datats,na.action=na.omit)
> 
> but how do I get a time serie of residuals instead of a vector residuals(fit)?
> ######
> 
> Matthieu Cornec
> 

ts is used for regular time series.  Removing NAs, other
than at the beginning or end, means its probably best to
model it as an irregular time series and so to use an
irregular time series package.  Below it is done in zoo.  
Also review the comments in my post to your previous question 
along these lines and, in particular, be sure you read the zoo vignette referenced there which has 15 pages of examples
of time series manipulations.


library(zoo)

# set up test data with NAs
set.seed(1)
x <- zoo(1:10)
y <- x + rnorm(10)
y[5] <- x[2] <- NA

# create multivariate zoo series without NAs
# Note: if you want to fill in NAs rather than omit them see ?na.locf
z <- na.omit(merge(y, lagx = lag(x, -1)))

# run lm
# (This also works:   z.lm <- lm(I(y ~ lagx), z)
# but the syntax is experimental.)
z.lm <- lm(y ~ lagx, as.data.frame(z))

# get fitted and resid using fact that their time base is that of z
z.fit <- z.resid <- z[,1]
z.fit[] <- fitted(z.lm)
z.resid[] <- resid(z.lm)

# We can just use the zoo series already created.  Its not really
# necessary to convert it to ts but if for some reason we want a 
# ts series the following creates one.
# (This uses facts that we know y starts at 1 and is regularly spaced
# and other series have a subset of the time base of y.)
ts(coredata(merge(y, x, z.fit, z.resid)))



From scott.chasalow at bms.com  Fri Mar  4 17:03:46 2005
From: scott.chasalow at bms.com (Scott D Chasalow)
Date: Fri, 04 Mar 2005 11:03:46 -0500
Subject: [R] calculating of linkage-disequilibrium measures?
In-Reply-To: <42270F2D.2030504@medisin.uio.no>
References: <42270F2D.2030504@medisin.uio.no>
Message-ID: <422886E2.6000306@bms.com>

Taking a lead from Brian, the answer is "yes".  :-)

But just in case you were seeking a somewhat more detailed answer:
If phase is known, it is not only possible to compute all these LD 
measures in R, it is much simpler.

For example, if you have alleles A and a at locus 1, and B and b at 
locus 2, and you let p(i) = relative frequency of gamete genotype i, 
then D = p(AB) - p(A)p(B).  If you have these relative frequencies 
stored e.g. in a matrix, you don't really need a special function to 
compute D.  D' is marginally more complicated, and worth a function. 
(Unfortunately, I am not at present at liberty to send you mine.  But 
I'm working on that.)  The R^2 statistic typically used in this context 
is, for 2-allele loci, simply X2/N, where X2 is the Pearson X2 statistic 
to test for association in the 2x2 table, and N is the number of 
gametes.  You might find function chisq.test of interest.  Although, if 
you want to do this for 100,000s of locus pairs, there are MUCH faster ways.

Cheers,
Scott

Bettina Kulle wrote:

> Hi ,
> is it possible to calculate ld-measures D, D', r and
> perhaps corresponding p-values with r IF THE
> PHASE IS KNOWN?
> The genetics - package provides the LD function
> only for ambigious phase.
> 
> Thank you very much
> 
> Bettina Kulle
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From B.Rowlingson at lancaster.ac.uk  Fri Mar  4 17:01:25 2005
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 04 Mar 2005 16:01:25 +0000
Subject: [R] how to draw graphs within clickable hyperlink
In-Reply-To: <web-3631271@be1.bc.edu>
References: <web-3631271@be1.bc.edu>
Message-ID: <42288655.6010404@lancaster.ac.uk>

Damian Betebenner wrote:
> Hu,
> 
> I've found two methods of doing this---1 in R and the other in S-Plus.

Here's something I did a few years ago that lets you create PNG files 
and an HTML imagemap

http://www.maths.lancs.ac.uk/Software/Imagemap/

  It might be tricky to add clickable areas to plots drawn by other 
functions and packages, since you dont know exactly where the points 
are, but with access to the source code that should be fixable.

  For example, suppose you wanted to make the box of a boxplot 
clickable, you need to know the coordinates of the box on the graphics 
device. If the return value and parameters to boxplot dont give this 
information, you'll have to work it out.

  Baz



From fm3a004 at math.uni-hamburg.de  Fri Mar  4 17:57:56 2005
From: fm3a004 at math.uni-hamburg.de (Christian Hennig)
Date: Fri, 4 Mar 2005 17:57:56 +0100 (MET)
Subject: [R] Clustering of Binary data in R
In-Reply-To: <20050304145121.89264.qmail@web31110.mail.mud.yahoo.com>
Message-ID: <Pine.GSO.3.95q.1050304175449.22044E-100000@sun11.math.uni-hamburg.de>

Hi,

as a starting point, see
?dist (method="binary")
library(prabclus)
?jaccard
?kulczynski
For distance based clustering methods see
library(cluster)
?agnes
?pam 

Best,
Christian

On Fri, 4 Mar 2005, sima fakheran wrote:

> 
>  
> 
> Good afternoon!
> 
>  
> 
> I would like to ask you about similarity measures and clustering in R for Binary data.
> 
> Would you please kindly help me and let me know about that commands in R? 
> 
>  
> 
> Thanks in advance for your kind attentions.
> 
>  
> 
> I look forward to hearing from you as soon as possible.
> 
>  
> 
> Best regards,
> 
> Sima
> 
> 
> 
>  
>  
> ---------------------------------------------------------------------------------------------------------
>  
> Sima Fakheran Esfahani
> PhD Student
> Institute of Environmental Sciences
> University of Zurich
> Winterthurerstrasse 190
> 8057 Zurich
> Switzerland
> Tel: +41 1 635 61 18
> Fax:+41 1 635 57 11
> email:fakheran at uwinst.unizh.ch
> 
> 
> 
> 
> 		
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

***********************************************************************
Christian Hennig
Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
>From 1 April 2005: Department of Statistical Science, UCL, London
#######################################################################
ich empfehle www.boag-online.de



From helprhelp at gmail.com  Fri Mar  4 19:07:06 2005
From: helprhelp at gmail.com (WeiWei Shi)
Date: Fri, 4 Mar 2005 12:07:06 -0600
Subject: [R] gbm
Message-ID: <cdf8178305030410074cae0bee@mail.gmail.com>

Hi, there:
Is there anyone who read the codes for gbm package before? Before i
sent this email, I also sent an email to ask for help from the author,
Greg. But still I am wondering if someone here can share some
understanding like the roadmap or document on the "implementation"
too.

Thanks,

Ed.



From lroot at umiami.ir.miami.edu  Fri Mar  4 19:49:54 2005
From: lroot at umiami.ir.miami.edu (Lindsey Root)
Date: Fri, 04 Mar 2005 13:49:54 -0500
Subject: [R] test of significance for nlme coefficients
Message-ID: <000101c520ea$f771beb0$b204ec0a@psy.miami.edu>

Hello,

I am using the nlme package to fit an exponential decay model to a
longitudinal data set:

> ##Model a variable called RASCH16A as an exponential function ## of an
initial value "A" and a decay rate "K"
> fm2 <- nlme(model = RASCH16A ~  A* (exp(-K*DAYS)), 
+ ###A has nonzero fixed and random effects, K has nonzero fixed and
random effects
+ fixed = A + K ~ 1,
+ data = rasch,
+ random = A + K ~ 1 | SUBJECT,
+ ##Give a start value for the fixed effects, expressed using the
concatenate function
+ start = c(60, 0.007))

However, 20 of the 161 estimates decay rates are NOT decay rates, but
are very small positive growth rates (all less than a standard deviation
(.03) from zero).  I would like to run a significance test to see how
many of these positive growth rates are significantly different from
zero. However, the nlme package only offers confidence intervals for the
model parameters, not the person-specific coefficients. I would welcome
any and all suggestions. 

Thanks if you can help,
Lindsey Root



From mi2kelgrum at yahoo.com  Fri Mar  4 20:06:08 2005
From: mi2kelgrum at yahoo.com (Mikkel Grum)
Date: Fri, 4 Mar 2005 11:06:08 -0800 (PST)
Subject: [R] image size
Message-ID: <20050304190608.26667.qmail@web60210.mail.yahoo.com>

Dear useRs,

I'm working in R 2.0.1 for Windows and producing PDF
files with Sweave. I seem to be hitting an image size
ceiling of around 6.8 x 6.8 inches.  I would like to
produce taller images to make better use of my A4 page
and have tried:

<<TestMap, fig = TRUE, width = 6.5, height = 8 >>=
par.old(fin = c(6.5, 8))
image(x, etc.)

I get the message:
Error in plot.new(): Figure region too large

Is there anything I can do?

Mikkel



From marcosjbd_g5a at mail.com  Fri Mar  4 20:35:42 2005
From: marcosjbd_g5a at mail.com (marcosjbd_g5a@mail.com)
Date: Fri, 04 Mar 2005 16:35:42 -0300
Subject: [R] Listas de E-mails para Mala Direta , Marketing Direto
Message-ID: <20050304193601.EFC838451@scorpion2.uol.com.br>

cadastros de e-mails divididos por profiss?o cadastros de e-mails divididos por 
segmento Cadastros para mala direta livre de spam:

http://www.gueb.de/divulgamail

Listas de E-mails para Mala Direta , Marketing Direto cadastros de e-mails divididos 
por profiss?o cadastros de e-mails divididos por segmento programas gr?tis para 
e-mail marketing cadastros de e-mails divididos por segmento cadastros de e-mails 
divididos por profiss?o
cadastros de e-mails divididos por segmento Listas de E-mails para Mala Direta 
, Marketing Direto:

http://www.gueb.de/divulgamail


cadastros de e-mails divididos por profiss?o cadastros de e-mails divididos por 
segmento Cadastros para mala direta livre de spam programas gr?tis para e-mail 
marketing Cadastros para mala direta livre de spam
e-mails para mala direta por classe social Listas de E-mails para Mala Direta 
, Marketing Direto cadastros de e-mails divididos por profiss?o Cadastros para 
mala direta livre de spam Listas de E-mails para Mala Direta , Marketing Direto 
e-mails para mala direta por classe social
Cadastros para mala direta livre de spam cadastros de e-mails divididos por profiss?o:

http://www.gueb.de/divulgamail



From kef at plantpath.wisc.edu  Fri Mar  4 21:21:10 2005
From: kef at plantpath.wisc.edu (Ken)
Date: Fri, 4 Mar 2005 14:21:10 -0600
Subject: [R] Need suggestions for finding dose response using nls
Message-ID: <F271448E-8CEA-11D9-9608-0050E459F370@plantpath.wisc.edu>

I am relatively new to R and am looking for advice, ideas or both...

I have a data set that consists of pathogen population sizes on 
individual plant units in an experimental field plot.  However, in 
order to estimate the pathogen population sizes I had to destroy the 
plant unit and could not determine if that plant unit became diseased 
or to what extent it would have become diseased. I collected disease 
data from each plot and have estimates of the disease in an 
experimental plot several days after the pathogen population sizes were 
estimated.  From this data I would like to determine a dose-response 
relationship in the field between the pathogen and host.

i. e.

P(disease) = sum P(disease | pathogen population size) x P(pathogen 
population size)  ... I think


I determined that the pathogen population sizes among plant units are 
well described by the lognormal distribution.  I am also assuming that 
P(disease | pathogen population size) is could be described by the 
normal distribution described by two parameters lam and tau...my dose 
response.

I would like to use nonlinear least squares to estimate lam and tau.  I 
included the R code and some data below.  I'm not sure if this code is 
correct, but it give reasonable estimates of lam and tau for the first 
data set.  However, I included another data set where the estimates of 
lam and tau do not make sense.  I have never done nonlinear regression. 
  Is the code correct?  Is this a sound approach to estimating a dose 
response in the field?  Does anyone have other ideas about how to 
approach this data?  I am currently  doing this analysis ad hoc, but if 
the results are promise I might like to do some planned experiments.

R 2.0.1
mac os 10.2

Thanks in advance for any responses
Ken

Example data...

mn is the mean of the log transformed pathogen population size
ss is the standard deviation of the log transformed pathogen population 
size
dap27 is the disease 7 days after the pathogen population sizes were 
estimated
dap31 is the disease 11 days after the pathogen population sizes were 
estimated

mn	ss	dap27	dap31
6.762	0.492	0.582	0.567
4.382	1.63	0.393	0.394
2.472	2.449	0.181	0.19
6.66	0.495	0.698	0.541
4.282	1.401	0.345	0.435
1.08	2.423	0.16	0.196
6.636	0.362	0.704	0.526
3.638	1.445	0.12	0.509
1.854	2.07	0.148	0.075


fm1 <- nls(dap27 ~ pnorm((mn - lam) / ((ss^2) + (tau^2))) , data = dg, 
start=c(lam = 6, tau = 2), trace = TRUE)

summary(fm1)

plot(dap27 ~ mn, dg)

kfc<-as.numeric(kf<-lm(dg$ss ~ dg$mn)$coefficients)
mm<-mean(dg$mn, na.rm = T)
vv<-var(dg$mn, na.rm = T)

for(i in 1:5){
n<-100
mn<-rnorm(n, mm, sqrt(vv))
xx<- mn * kfc[2] + kfc[1]; lter<-rnorm(n, 0, 1)
ss<-xx + lter
newdat<-data.frame(mn,ss)
lines(lowess(newdat$mn , predict(fm1, newdat), f = 2/3), col = i)
}

The nonlinear regression did not fit for this data set (or at least 
dap27).

mn	ss	dap27	dap31
0.31	0.94	0.01	0.31
0.09	3.33	0.01	.
3.3	2.43	0.07	0.22
5.9	1.78	0.46	0.91
6.03	1.26	0.33	0.96
4.7	1.96	0.09	0.67
2.67	2.04	0.06	0.51
4.7	1.78	0.31	0.93
3.07	2.74	0.02	0.39
5.13	2.6	0.27	0.68
3.38	2.24	0.05	0.44
5.9	1.7	0.49	.
5.06	2.18	0.08	0.54
2.99	2.64	0.09	0.38
5.41	2.73	0.08	0.46
1.65	2.96	0.04	0.39



From aloisio at cedeplar.ufmg.br  Fri Mar  4 21:43:27 2005
From: aloisio at cedeplar.ufmg.br (Aloisio Joaquim Freitas Ribeiro)
Date: Fri, 4 Mar 2005 17:43:27 -0300
Subject: [R] MGCV-confidence interval
Message-ID: <20050304204111.M75868@cedeplar.ufmg.br>


   I  am  using  MGCv  to smoothing mortality rates. I need to   simultaneous confidence intervals for the mortality function. Is   possible using MGCV?

   Thanks

   Aloisio

   -- 
   Open WebMail Project ([1]http://openwebmail.org) 
   --
   Esta mensagem foi verificada pelo sistema de
   antiv?rus e acredita-se estar livre de perigo.
   --

References

   1. 3D"http://openwebmail.org/"


From zkzach at gmail.com  Fri Mar  4 22:52:49 2005
From: zkzach at gmail.com (Zachariah Zachariah)
Date: Fri, 4 Mar 2005 13:52:49 -0800
Subject: [R] R-2.01 and RSPerl-0.6.2
Message-ID: <4162f22e050304135264f145f8@mail.gmail.com>

Hi,

I am somewhat new to R and RSPerl, but I think this particular problem
has to do with RSPerl and so I am not sure if this is the right forum
to ask for help. Nevertheless I am quite sure that many of you would
have used RSPerl with R.

My hardware platform is a Sun/Solaris V440 server running Solaris 9
operating system I use the gcc-3.4.0 compiler to compile R without any
problems. My intention is to call R from Perl. So I use the
--enable-R-shlib option as the document says. My perl version is at
5.8.6. I also compiled in RSPerl for dual functionality of calling
perl from R and R from Perl. Everything seems to get installed
smoothly as a well oiled machine till I run the tests in the examples
directory.

#R CMD INSTALL -c  RSPerl_0.6-2.tar.gz
#R CMD INSTALL -c --configure-args='with-in-perl' RSPerl_0.6-2.tar.gz
#cd <install directory>/lib/R/library/RSPerl/examples
# perl test.pl
1..1
ok 1
Error in dyn.load(x, as.logical(local), as.logical(now)) : 
        unable to load shared library
"/tools/R/current/lib/R/library/stats/libs/stats.so":
  ld.so.1: perl: fatal: relocation error: file
/tools/R/current/lib/R/library/stats/libs/stats.so: symbol MAIN__:
referenced symbol not found
Loaded RSPerl library
objects $.PerlReference [.PerlArrayReference [.PerlHashReference
[<-.PerlArrayReference [<-.PerlHashReference addConverter
foreignReference getNumPerlConverters getPerlConverterDescriptions
getPerlHandler getPerlScript names.PerlHashReference parseEval
perlInitArgs referenceHandlerGenerator removeConverter setPerlHandler
Testing search path
installing function name search
   1db114
Search path: .GlobalEnv package:RSPerl package:methods
package:graphics package:grDevices package:utils package:datasets
Autoloads package:base
Error in dyn.load(x, as.logical(local), as.logical(now)) : 
        unable to load shared library
"/tools/R/current/lib/R/library/stats/libs/stats.so":
  ld.so.1: perl: fatal: relocation error: file
/tools/R/current/lib/R/library/stats/libs/stats.so: symbol MAIN__:
referenced symbol not found
In addition: Warning message: 
package stats in options("defaultPackages") was not found 
Error in library(package = "stats") : package/namespace load failed for 'stats'
Segmentation fault

I searched the documents for any clue and I believe that I have
followed everything specified in the documentation. I had done a
successful install of R-1.9.1 and RSPerl-0.5.7 on a similar hardware
platform that I thought had given me some confidence but not so with
this one. The documentation did not seem to suggest anything new for
the latest versions of R and RSPerl Thanks in advance for any
help/pointers/tips/etc. Here are my environment variables if that
would help.

# env
PWD=/tools/R/current/lib/R/library/RSPerl/examples
GS_FONTPATH=/usr/lib/X11/fonts/Type1Adobe
TZ=US/Pacific
ORACLE_SID=prosrv
TMPDIR=/usr/tmp
MODULEPATH=/share/init/mod
GS_LIB=/netopt/gs/6.52/lib/
PAGER=less
LOADEDMODULES=sysenv:X11/R6:gnu:sundry:news:perl/current:net:Xmisc:ncbi:gcg/10.3:metamail/current:netscape/current:motif/1.2.3p26:mail:transcript:cap/man:emacs/current:gs/current:acrobat:standard:nsr/current:oracle:R:oraclient/current
CLASSPATH=/netopt/netscape/4.78/java/classes/java40.jar
MANPATH=/tools/perl/current/man:/usr/local/man:/usr/man:/usr/java/man:/netopt/man:/netopt/gnu/man:/tools/X11/R6/man:/tools/gnu/man:/local/links/man:/tools/sundry/man:/tools/news/man:/tools/net/man:/tools/Xmisc/man:/tools/metamail/2.6/man:/netopt/netscape/4.78/man:/tools/motif/1.2.3p26/man:/tools/mail/man:/netopt/emacs/21.3/man:/netopt/gs/6.52/man:/tools/R/current/man
SYS=sparc-sol
XLOCALEDIR=/tools/X11/R6/lib/X11/locale
MODULESHOME=/tools/Modules/2.2
NNTPSERVER=nntp
USER=root
MACHTYPE=sparc
CVS_SERVER=/tools/gnu/bin/cvs
SSH2_SFTP_LOG_FACILITY=-1
XFILESEARCHPATH=/share/init/%T/%N%S:/tools/X11/R6/lib/X11/%T/%N%C%S:/tools/X11/R6/lib/X11/%T/%N%S:/tools/Xmisc/lib/%T/%N%S:/tools/motif/1.2.3p26/lib/X11/%T/%N%C%S:/tools/motif/1.2.3p26/lib/X11/%T/%N%S
LPDEST=NULL
ORACLE_HOME=/share/ora-homes/9.2.0
INFOPATH=/tools/gnu/info:/netopt/emacs/local-info:/netopt/emacs/21.3/info
DISPLAY=sitar:11.0
NPX_PLUGIN_PATH=/usr/j2se/jre/plugin/sparc/ns4
LOGNAME=root
SHLVL=2
_LMFILES_=/share/init/mod/sysenv:/share/init/mod/X11/R6:/share/init/mod/gnu:/share/init/mod/sundry:/share/init/mod/news:/share/init/mod/perl/current:/share/init/mod/net:/share/init/mod/Xmisc:
/share/init/mod/ncbi:/share/init/mod/gcg/10.3:/share/init/mod/metamail/current:/share/init/mod/netscape/current:/share/init/mod/motif/1.2.3p26:/share/init/mod/mail:/share/init/mod/transcript:
/share/init/mod/cap/man:/share/init/mod/emacs/current:/share/init/mod/gs/current:/share/init/mod/acrobat:/share/init/mod/standard:/share/init/mod/nsr/current:/share/init/mod/oracle:/share/init/mod/R:
/share/init/mod/oraclient/current
ORAENV_ASK=NO
SHELL=/bin/bash
UIDPATH=/tools/Xmisc/lib/uid/%U:/tools/motif/1.2.3p26/lib/X11/uid/%U
PRINTER=NULL
HOSTTYPE=sun4
MYWM=twm
OSTYPE=solaris
TERM=xterm
RAD_LOG_FACILITY=LOG_LOCAL0
_=/netopt/bin/sudo
SUDO_COMMAND=/usr/bin/tcsh
LD_LIBRARY_PATH=/share/guitar/ora-homes/9.2.0/lib32:/usr/local/lib:/tools/X11/R6/lib:/tools/gnu/lib:/tools/Xmisc/lib:/usr/lib:/lib:/usr/local/lib:/netopt/lib:/netopt/gnu/lib:/tools/R/current/lib/R/lib:
/tools/R/current/lib/R/bin:/tools/R/current/lib/R/library/RSPerl/libs:/tools/R/current/lib/R/library/tools/libs:/tools/R/current/lib/R/library/stats/libs:/tools/R/current/lib/R/library/methods/libs:
/tools/R/current/lib/R/library/grid/libs:/tools/R/current/lib/R/library/splines/libs:/tools/R/current/lib/R/library/tcltk/libs:/tools/R/current/lib/R/library/MASS/libs:/tools/R/current/lib/R/library/class/libs:
/tools/R/current/lib/R/library/nnet/libs:/tools/R/current/lib/R/library/spatial/libs:/tools/R/current/lib/R/library/cluster/libs:/tools/R/current/lib/R/library/foreign/libs:/tools/R/current/lib/R/library/KernSmooth/libs:
/tools/R/current/lib/R/library/lattice/libs:/tools/R/current/lib/R/library/nlme/libs:/tools/R/current/lib/R/library/mgcv/libs:/tools/R/current/lib/R/library/rpart/libs:/tools/R/current/lib/R/library/survival/libs:/tools/R/current/lib/R/library/RSPerl/libs
MAKE=gmake
PATH=/share/guitar/ora-homes/9.2.0/bin:/tools/perl/current/bin:/usr/bin:/usr/ucb/bin:/usr/ccs/bin:/usr/local/bin:/tools/gnu/bin:/tools/R/current/bin
PERLLIB=/tools/R/current/lib/R/library/RSPerl/share/blib/arch:/tools/R/current/lib/R/library/RSPerl/share/blib/lib:/tools/R/current/lib/R/library/RSPerl/scripts
R_HOME=/tools/R/current/lib/R
LD_LIBRARY_PATH_64=/share/guitar/ora-homes/9.2.0/lib

--Zachariah 
Systems Administrator
Stanford University



From tstalley at ucdavis.edu  Fri Mar  4 22:58:00 2005
From: tstalley at ucdavis.edu (Theresa Sinicrope Talley)
Date: Fri, 04 Mar 2005 13:58:00 -0800
Subject: [R] R: Moran's I
Message-ID: <BE4E19E8.9517%tstalley@ucdavis.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050304/761803e2/attachment.pl

From duncan at wald.ucdavis.edu  Fri Mar  4 23:06:53 2005
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Fri, 4 Mar 2005 14:06:53 -0800
Subject: [R] R-2.01 and RSPerl-0.6.2
In-Reply-To: <4162f22e050304135264f145f8@mail.gmail.com>
References: <4162f22e050304135264f145f8@mail.gmail.com>
Message-ID: <20050304220653.GG7972@wald.ucdavis.edu>


The omega-help mailing list  is more appropriate.
(See http://www.omegahat.org/mailman/listinfo)

One of the things that comes to mind is 
whether you built R via the --enable-R-shlib
entirely from scratch or did you
reconfigure and rebuild from an existing compiled
source.  If it is the latter, and library/stats/lib/stats.so 
was not linked against libR.so, then bad things happen.

Run the command

 ldd /tools/R/current/lib/R/library/stats/libs/stats.so

and see if libR.so is included in the output.
If not, rebuild R with

 make distclean
 ./configure --enable-R-shlib
 make

and try things then.

If this is not the problem, you can send mail directly to me
and I can try to help.

 D.

Zachariah Zachariah wrote:
> Hi,
> 
> I am somewhat new to R and RSPerl, but I think this particular problem
> has to do with RSPerl and so I am not sure if this is the right forum
> to ask for help. Nevertheless I am quite sure that many of you would
> have used RSPerl with R.
> 
> My hardware platform is a Sun/Solaris V440 server running Solaris 9
> operating system I use the gcc-3.4.0 compiler to compile R without any
> problems. My intention is to call R from Perl. So I use the
> --enable-R-shlib option as the document says. My perl version is at
> 5.8.6. I also compiled in RSPerl for dual functionality of calling
> perl from R and R from Perl. Everything seems to get installed
> smoothly as a well oiled machine till I run the tests in the examples
> directory.
> 
> #R CMD INSTALL -c  RSPerl_0.6-2.tar.gz
> #R CMD INSTALL -c --configure-args='with-in-perl' RSPerl_0.6-2.tar.gz
> #cd <install directory>/lib/R/library/RSPerl/examples
> # perl test.pl
> 1..1
> ok 1
> Error in dyn.load(x, as.logical(local), as.logical(now)) : 
>         unable to load shared library
> "/tools/R/current/lib/R/library/stats/libs/stats.so":
>   ld.so.1: perl: fatal: relocation error: file
> /tools/R/current/lib/R/library/stats/libs/stats.so: symbol MAIN__:
> referenced symbol not found
> Loaded RSPerl library
> objects $.PerlReference [.PerlArrayReference [.PerlHashReference
> [<-.PerlArrayReference [<-.PerlHashReference addConverter
> foreignReference getNumPerlConverters getPerlConverterDescriptions
> getPerlHandler getPerlScript names.PerlHashReference parseEval
> perlInitArgs referenceHandlerGenerator removeConverter setPerlHandler
> Testing search path
> installing function name search
>    1db114
> Search path: .GlobalEnv package:RSPerl package:methods
> package:graphics package:grDevices package:utils package:datasets
> Autoloads package:base
> Error in dyn.load(x, as.logical(local), as.logical(now)) : 
>         unable to load shared library
> "/tools/R/current/lib/R/library/stats/libs/stats.so":
>   ld.so.1: perl: fatal: relocation error: file
> /tools/R/current/lib/R/library/stats/libs/stats.so: symbol MAIN__:
> referenced symbol not found
> In addition: Warning message: 
> package stats in options("defaultPackages") was not found 
> Error in library(package = "stats") : package/namespace load failed for 'stats'
> Segmentation fault
> 
> I searched the documents for any clue and I believe that I have
> followed everything specified in the documentation. I had done a
> successful install of R-1.9.1 and RSPerl-0.5.7 on a similar hardware
> platform that I thought had given me some confidence but not so with
> this one. The documentation did not seem to suggest anything new for
> the latest versions of R and RSPerl Thanks in advance for any
> help/pointers/tips/etc. Here are my environment variables if that
> would help.
> 
> # env
> PWD=/tools/R/current/lib/R/library/RSPerl/examples
> GS_FONTPATH=/usr/lib/X11/fonts/Type1Adobe
> TZ=US/Pacific
> ORACLE_SID=prosrv
> TMPDIR=/usr/tmp
> MODULEPATH=/share/init/mod
> GS_LIB=/netopt/gs/6.52/lib/
> PAGER=less
> LOADEDMODULES=sysenv:X11/R6:gnu:sundry:news:perl/current:net:Xmisc:ncbi:gcg/10.3:metamail/current:netscape/current:motif/1.2.3p26:mail:transcript:cap/man:emacs/current:gs/current:acrobat:standard:nsr/current:oracle:R:oraclient/current
> CLASSPATH=/netopt/netscape/4.78/java/classes/java40.jar
> MANPATH=/tools/perl/current/man:/usr/local/man:/usr/man:/usr/java/man:/netopt/man:/netopt/gnu/man:/tools/X11/R6/man:/tools/gnu/man:/local/links/man:/tools/sundry/man:/tools/news/man:/tools/net/man:/tools/Xmisc/man:/tools/metamail/2.6/man:/netopt/netscape/4.78/man:/tools/motif/1.2.3p26/man:/tools/mail/man:/netopt/emacs/21.3/man:/netopt/gs/6.52/man:/tools/R/current/man
> SYS=sparc-sol
> XLOCALEDIR=/tools/X11/R6/lib/X11/locale
> MODULESHOME=/tools/Modules/2.2
> NNTPSERVER=nntp
> USER=root
> MACHTYPE=sparc
> CVS_SERVER=/tools/gnu/bin/cvs
> SSH2_SFTP_LOG_FACILITY=-1
> XFILESEARCHPATH=/share/init/%T/%N%S:/tools/X11/R6/lib/X11/%T/%N%C%S:/tools/X11/R6/lib/X11/%T/%N%S:/tools/Xmisc/lib/%T/%N%S:/tools/motif/1.2.3p26/lib/X11/%T/%N%C%S:/tools/motif/1.2.3p26/lib/X11/%T/%N%S
> LPDEST=NULL
> ORACLE_HOME=/share/ora-homes/9.2.0
> INFOPATH=/tools/gnu/info:/netopt/emacs/local-info:/netopt/emacs/21.3/info
> DISPLAY=sitar:11.0
> NPX_PLUGIN_PATH=/usr/j2se/jre/plugin/sparc/ns4
> LOGNAME=root
> SHLVL=2
> _LMFILES_=/share/init/mod/sysenv:/share/init/mod/X11/R6:/share/init/mod/gnu:/share/init/mod/sundry:/share/init/mod/news:/share/init/mod/perl/current:/share/init/mod/net:/share/init/mod/Xmisc:
> /share/init/mod/ncbi:/share/init/mod/gcg/10.3:/share/init/mod/metamail/current:/share/init/mod/netscape/current:/share/init/mod/motif/1.2.3p26:/share/init/mod/mail:/share/init/mod/transcript:
> /share/init/mod/cap/man:/share/init/mod/emacs/current:/share/init/mod/gs/current:/share/init/mod/acrobat:/share/init/mod/standard:/share/init/mod/nsr/current:/share/init/mod/oracle:/share/init/mod/R:
> /share/init/mod/oraclient/current
> ORAENV_ASK=NO
> SHELL=/bin/bash
> UIDPATH=/tools/Xmisc/lib/uid/%U:/tools/motif/1.2.3p26/lib/X11/uid/%U
> PRINTER=NULL
> HOSTTYPE=sun4
> MYWM=twm
> OSTYPE=solaris
> TERM=xterm
> RAD_LOG_FACILITY=LOG_LOCAL0
> _=/netopt/bin/sudo
> SUDO_COMMAND=/usr/bin/tcsh
> LD_LIBRARY_PATH=/share/guitar/ora-homes/9.2.0/lib32:/usr/local/lib:/tools/X11/R6/lib:/tools/gnu/lib:/tools/Xmisc/lib:/usr/lib:/lib:/usr/local/lib:/netopt/lib:/netopt/gnu/lib:/tools/R/current/lib/R/lib:
> /tools/R/current/lib/R/bin:/tools/R/current/lib/R/library/RSPerl/libs:/tools/R/current/lib/R/library/tools/libs:/tools/R/current/lib/R/library/stats/libs:/tools/R/current/lib/R/library/methods/libs:
> /tools/R/current/lib/R/library/grid/libs:/tools/R/current/lib/R/library/splines/libs:/tools/R/current/lib/R/library/tcltk/libs:/tools/R/current/lib/R/library/MASS/libs:/tools/R/current/lib/R/library/class/libs:
> /tools/R/current/lib/R/library/nnet/libs:/tools/R/current/lib/R/library/spatial/libs:/tools/R/current/lib/R/library/cluster/libs:/tools/R/current/lib/R/library/foreign/libs:/tools/R/current/lib/R/library/KernSmooth/libs:
> /tools/R/current/lib/R/library/lattice/libs:/tools/R/current/lib/R/library/nlme/libs:/tools/R/current/lib/R/library/mgcv/libs:/tools/R/current/lib/R/library/rpart/libs:/tools/R/current/lib/R/library/survival/libs:/tools/R/current/lib/R/library/RSPerl/libs
> MAKE=gmake
> PATH=/share/guitar/ora-homes/9.2.0/bin:/tools/perl/current/bin:/usr/bin:/usr/ucb/bin:/usr/ccs/bin:/usr/local/bin:/tools/gnu/bin:/tools/R/current/bin
> PERLLIB=/tools/R/current/lib/R/library/RSPerl/share/blib/arch:/tools/R/current/lib/R/library/RSPerl/share/blib/lib:/tools/R/current/lib/R/library/RSPerl/scripts
> R_HOME=/tools/R/current/lib/R
> LD_LIBRARY_PATH_64=/share/guitar/ora-homes/9.2.0/lib
> 
> --Zachariah 
> Systems Administrator
> Stanford University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Duncan Temple Lang                duncan at wald.ucdavis.edu
Department of Statistics          work:  (530) 752-4782
371 Kerr Hall                     fax:   (530) 752-7099
One Shields Ave.
University of California at Davis
Davis, CA 95616, USA



From pauljohn at ku.edu  Fri Mar  4 23:39:49 2005
From: pauljohn at ku.edu (Paul Johnson)
Date: Fri, 04 Mar 2005 16:39:49 -0600
Subject: [R] here's why it make s sense
Message-ID: <4228E3B5.2000905@ku.edu>

if you go

x[i]

you are giving x an "index vector", which we had mistakenly thought was 
an integer. Rather, it is a vector of indices for observations.  Here's data

x <- c(1 , 4, 3, 2, 5)

x[1] would be 1
x[2] would bd 4

but if you put an "index vector" in the brackets, you have


x [ c(1,2,1,2] ]

it means take the first, the second, the first, the second, so

x [ c(1,2,1,2] ]

is

1, 4, 1, 4

So in the procedure diff.ttest, when we have x[i] and y[i], we mean 
"take the vectors x and y after grabbing the index values selected for 
each resample"

That page I sent you a minute ago is from R by Example, which I think is 
quite great.

http://www.mayin.org/ajayshah/KB/R/index.html

pj

-- 
Paul E. Johnson                       email: pauljohn at ku.edu
Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
1541 Lilac Lane, Rm 504
University of Kansas                  Office: (785) 864-9086
Lawrence, Kansas 66044-3177           FAX: (785) 864-5700



From yeaman at zoology.ubc.ca  Sat Mar  5 01:08:59 2005
From: yeaman at zoology.ubc.ca (Sam Yeaman)
Date: Fri, 04 Mar 2005 16:08:59 -0800
Subject: [R] vector memory allocation?
Message-ID: <4228F89B.4020908@zoology.ubc.ca>

Hi all,

I have a vector size allocation problem with R 2.0.1 (script and output 
shown):

 > var1 <- sum (input1 * input2, na = TRUE)

 > gc()
           used  (Mb) gc trigger   (Mb)
Ncells   199327   5.4     785113   21.0 
Vcells 71039552 542.0  206003790 1571.7

 > var2 <- sum (input1 * input2 / input2, na = TRUE)

Error: cannot allocate vector of size 524288 Kb

input1 and input2 are matrices input from text files of about 100 MB.

This error happens irrespective of whether I calculate var1 or var2 
first...it will always calculate the first and always have an error on 
the second. Am I misusing the garbage-collector? I am confused by the 
fact that the difference between 'trigger' and 'used' seems so much 
higher than the size of vector that it says it can't allocate.


thanks, Sam Yeaman



From Scott.Waichler at pnl.gov  Sat Mar  5 01:58:41 2005
From: Scott.Waichler at pnl.gov (Waichler, Scott R)
Date: Fri, 04 Mar 2005 16:58:41 -0800
Subject: [R] Emacs keystroke to toggle T/F for setting logical values
Message-ID: <7E4C06F49D6FEB49BE4B60E5FC92ED7A01834B59@pnlmse35.pnl.gov>


I'd like to have an Emacs keystroke that would let me toggle between T
and F when editing logical settings in R code.  I looked in the ESS
documentation and in my O'Reilly emacs books but found nothing.  Any
ideas?

Scott Waichler
Pacific Northwest National Laboratory
scott.waichler at pnl.gov



From jijunl at amgen.com  Sat Mar  5 02:07:17 2005
From: jijunl at amgen.com (Liu, Jane)
Date: Fri, 4 Mar 2005 17:07:17 -0800 
Subject: [R] Gap plots
Message-ID: <569E4D734A4F05448D603396CB1C651101CE08E9@USSF-MB1.amgen.com>

Hi,

Does anyone know how to do gap plots for k-mean clustering in R?

Thanks a lot!

Jane



From kjetil at acelerate.com  Sat Mar  5 02:49:20 2005
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Fri, 04 Mar 2005 21:49:20 -0400
Subject: leap years (Was: [R] lm and time series)
In-Reply-To: <20050304155345.C4C0A12D5C@mprdmxin.myway.com>
References: <20050304155345.C4C0A12D5C@mprdmxin.myway.com>
Message-ID: <42291020.8060604@acelerate.com>

A followup:

How do people treat dsaily time series, when there is a yearly cycle?

For the moment I just left out the 29 of February's, but that dsoes'nt look
really good. Is the only way to include them to use irregular time series?

Kjetil

Gabor Grothendieck wrote:

> 
>From:   Matthieu Cornec <matthieu.cornec at gmail.com>
> 
>  
>
>>I create a multivariate time series containing NA values (that could
>>come directly from an imported file,)
>>I want to compute a linear regression and obtain a time serie for both
>>residuals and fitted values. I have tried the trick ts.intersect,
>>without success.
>>
>>Could you help me out of this?
>>####
>>Example:
>>
>>y<-ts(1:10+rnorm(10))
>>x<-ts(1:10)
>>datats<-cbind(y,lagx=lag(x))
>>
>>Notice the datats could come directly from an imported file, that is
>>why I did not use ts.intersect(y,lagx=lag(x))
>>
>>fit<-lm(y~lagx,data=datats,na.action=na.omit)
>>
>>but how do I get a time serie of residuals instead of a vector residuals(fit)?
>>######
>>
>>Matthieu Cornec
>>
>>    
>>
>
>ts is used for regular time series.  Removing NAs, other
>than at the beginning or end, means its probably best to
>model it as an irregular time series and so to use an
>irregular time series package.  Below it is done in zoo.  
>Also review the comments in my post to your previous question 
>along these lines and, in particular, be sure you read the zoo vignette referenced there which has 15 pages of examples
>of time series manipulations.
>
>
>library(zoo)
>
># set up test data with NAs
>set.seed(1)
>x <- zoo(1:10)
>y <- x + rnorm(10)
>y[5] <- x[2] <- NA
>
># create multivariate zoo series without NAs
># Note: if you want to fill in NAs rather than omit them see ?na.locf
>z <- na.omit(merge(y, lagx = lag(x, -1)))
>
># run lm
># (This also works:   z.lm <- lm(I(y ~ lagx), z)
># but the syntax is experimental.)
>z.lm <- lm(y ~ lagx, as.data.frame(z))
>
># get fitted and resid using fact that their time base is that of z
>z.fit <- z.resid <- z[,1]
>z.fit[] <- fitted(z.lm)
>z.resid[] <- resid(z.lm)
>
># We can just use the zoo series already created.  Its not really
># necessary to convert it to ts but if for some reason we want a 
># ts series the following creates one.
># (This uses facts that we know y starts at 1 and is regularly spaced
># and other series have a subset of the time base of y.)
>ts(coredata(merge(y, x, z.fit, z.resid)))
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>


-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra





-- 
No virus found in this outgoing message.
Checked by AVG Anti-Virus.



From ggrothendieck at myway.com  Sat Mar  5 06:23:33 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 5 Mar 2005 05:23:33 +0000 (UTC)
Subject: leap years (Was: [R] lm and time series)
References: <20050304155345.C4C0A12D5C@mprdmxin.myway.com>
	<42291020.8060604@acelerate.com>
Message-ID: <loom.20050305T062204-733@post.gmane.org>


The other approach is the pastecs::daystoyears approach where each
year consists of 365.25 days.

Kjetil Brinchmann Halvorsen <kjetil <at> acelerate.com> writes:

: 
: A followup:
: 
: How do people treat dsaily time series, when there is a yearly cycle?
: 
: For the moment I just left out the 29 of February's, but that dsoes'nt look
: really good. Is the only way to include them to use irregular time series?
: 
: Kjetil
: 
: Gabor Grothendieck wrote:
: 
: > 
: >From:   Matthieu Cornec <matthieu.cornec <at> gmail.com>
: > 
: >  
: >
: >>I create a multivariate time series containing NA values (that could
: >>come directly from an imported file,)
: >>I want to compute a linear regression and obtain a time serie for both
: >>residuals and fitted values. I have tried the trick ts.intersect,
: >>without success.
: >>
: >>Could you help me out of this?
: >>####
: >>Example:
: >>
: >>y<-ts(1:10+rnorm(10))
: >>x<-ts(1:10)
: >>datats<-cbind(y,lagx=lag(x))
: >>
: >>Notice the datats could come directly from an imported file, that is
: >>why I did not use ts.intersect(y,lagx=lag(x))
: >>
: >>fit<-lm(y~lagx,data=datats,na.action=na.omit)
: >>
: >>but how do I get a time serie of residuals instead of a vector residuals
(fit)?
: >>######
: >>
: >>Matthieu Cornec
: >>
: >>    
: >>
: >
: >ts is used for regular time series.  Removing NAs, other
: >than at the beginning or end, means its probably best to
: >model it as an irregular time series and so to use an
: >irregular time series package.  Below it is done in zoo.  
: >Also review the comments in my post to your previous question 
: >along these lines and, in particular, be sure you read the zoo vignette 
referenced there which has 15 pages
: of examples
: >of time series manipulations.
: >
: >
: >library(zoo)
: >
: ># set up test data with NAs
: >set.seed(1)
: >x <- zoo(1:10)
: >y <- x + rnorm(10)
: >y[5] <- x[2] <- NA
: >
: ># create multivariate zoo series without NAs
: ># Note: if you want to fill in NAs rather than omit them see ?na.locf
: >z <- na.omit(merge(y, lagx = lag(x, -1)))
: >
: ># run lm
: ># (This also works:   z.lm <- lm(I(y ~ lagx), z)
: ># but the syntax is experimental.)
: >z.lm <- lm(y ~ lagx, as.data.frame(z))
: >
: ># get fitted and resid using fact that their time base is that of z
: >z.fit <- z.resid <- z[,1]
: >z.fit[] <- fitted(z.lm)
: >z.resid[] <- resid(z.lm)
: >
: ># We can just use the zoo series already created.  Its not really
: ># necessary to convert it to ts but if for some reason we want a 
: ># ts series the following creates one.
: ># (This uses facts that we know y starts at 1 and is regularly spaced
: ># and other series have a subset of the time base of y.)
: >ts(coredata(merge(y, x, z.fit, z.resid)))
: >
: >______________________________________________
: >R-help <at> stat.math.ethz.ch mailing list
: >https://stat.ethz.ch/mailman/listinfo/r-help
: >PLEASE do read the posting guide! http://www.R-project.org/posting-
guide.html
: >
: >
: >
: >  
: >
:



From s.chamaille at wanadoo.fr  Sat Mar  5 08:56:24 2005
From: s.chamaille at wanadoo.fr (=?ISO-8859-1?Q?Simon_Chamaill=E9?=)
Date: Sat, 05 Mar 2005 08:56:24 +0100
Subject: [R] S-code for piecewise regression
Message-ID: <42296628.10300@wanadoo.fr>

Dear R-helpers,
a S-code for piecewise regressions was provided by Toms & Lesperance 
(2003) Ecology, 84, 2034-2041 (paper can be found on the web).The code 
is quite complete with different types of transitions around breakpoints 
and model selection fonctions.
It doesn't work directly under R due to some "translation" problems I 
guess. However I  reckon that  it would be a  valuable  add-on to R, so 
if anyone that knows both S and R syntax (I don't) doesn't know what to 
do during the week-end, it could provide some entertainment...
attached is the code.
regards,
simon
" R is love" (L.D.)
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: pwreg_fns.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050305/fbe1dae4/pwreg_fns.txt

From ripley at stats.ox.ac.uk  Sat Mar  5 08:45:51 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 5 Mar 2005 07:45:51 +0000 (GMT)
Subject: [R] vector memory allocation?
In-Reply-To: <4228F89B.4020908@zoology.ubc.ca>
References: <4228F89B.4020908@zoology.ubc.ca>
Message-ID: <Pine.LNX.4.61.0503050720530.19450@gannet.stats>

On Fri, 4 Mar 2005, Sam Yeaman wrote:

> I have a vector size allocation problem with R 2.0.1 (script and output 
> shown):

And your computer's OS and RAM size are?

>> var1 <- sum (input1 * input2, na = TRUE)

What do you think na=TRUE does?  There is an na.rm argument, but

sum(1, na=TRUE)

may surprise you.  (You cannot use partial matching on arguments after 
..., and you would do well never to use it when programming or reporting a 
problem)

>> gc()
>          used  (Mb) gc trigger   (Mb)
> Ncells   199327   5.4     785113   21.0 Vcells 71039552 542.0  206003790 
> 1571.7
>
>> var2 <- sum (input1 * input2 / input2, na = TRUE)
>
> Error: cannot allocate vector of size 524288 Kb
>
> input1 and input2 are matrices input from text files of about 100 MB.

Numeric matrices, presumably?  And what object.size()?

> This error happens irrespective of whether I calculate var1 or var2 
> first...it will always calculate the first and always have an error on the 
> second.

It is likely that you have fragmented the address space.  If this is a 
32-bit OS, you are using objects large compared to the user address space 
(probably 2 or 3 Gb).  Finding gaps of 512Mb (that's a suspiciously 
`round' number, 524288Kb = 512Mb) in a 2Gb block is not easy

> Am I misusing the garbage-collector? I am confused by the fact that 
> the difference between 'trigger' and 'used' seems so much higher than the 
> size of vector that it says it can't allocate.

Like a factor of 2.01 `higher'?  Methinks you do protest too much.

It has to allocate at least 2 vectors en route to var2.  Something like

tmp1 <- input1 * input2
tmp2 <- tmp1/input2
var2 <- sum(tmp2, as.numeric(TRUE)

However, the 'trigger' is exactly that, and can exceed the 
address space of the machine: it is the point at which garbage collection 
gets called, not the size of the available vector heap.

We know at least one way to improve R's ability to work close to the 
address space limits (and it is likely to appear in 2.1.0), but really
doing anything useful with 512Mb objects needs a 64-bit machine.
(R has supported 64-bit OSes for serveral years.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Sat Mar  5 09:25:49 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 05 Mar 2005 09:25:49 +0100
Subject: [R] S-code for piecewise regression
In-Reply-To: <42296628.10300@wanadoo.fr>
References: <42296628.10300@wanadoo.fr>
Message-ID: <x2y8d2xzw2.fsf@biostat.ku.dk>

Simon Chamaill? <s.chamaille at wanadoo.fr> writes:

> Dear R-helpers,
> a S-code for piecewise regressions was provided by Toms & Lesperance
> (2003) Ecology, 84, 2034-2041 (paper can be found on the web).The code
> is quite complete with different types of transitions around
> breakpoints and model selection fonctions.
> It doesn't work directly under R due to some "translation" problems I
> guess. However I  reckon that  it would be a  valuable  add-on to R,
> so if anyone that knows both S and R syntax (I don't) doesn't know
> what to do during the week-end, it could provide some entertainment...
> attached is the code.

Umm, I don't think posting 1200 lines on nonworking code to r-help is
the right way to go about this, especially since the code is not
yours. I'm pretty sure you didn't read (or if you did, you certainly
didn't understand)

http://www.esapubs.org/archive/copyright.htm

which is the copyright stated on

http://www.esapubs.org/archive/ecol/E084/047/suppl-1.htm

> regards,
> simon
> " R is love" (L.D.)

The right way is of course to volunteer as maintainer for an R
package (maybe after finding someone to help you iron out the
wrinkles), contact the authors and the journal to get permission to
publish under the GPL and submit to CRAN.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tom_hoary at web.de  Sat Mar  5 09:54:20 2005
From: tom_hoary at web.de (Thomas =?iso-8859-15?q?Sch=F6nhoff?=)
Date: Sat, 5 Mar 2005 09:54:20 +0100
Subject: [R] Clustering of Binary data in R
In-Reply-To: <20050304145121.89264.qmail@web31110.mail.mud.yahoo.com>
References: <20050304145121.89264.qmail@web31110.mail.mud.yahoo.com>
Message-ID: <200503050954.20332.tom_hoary@web.de>

Hello,

Am Freitag, 4. M?rz 2005 15:51 schrieb sima fakheran:
> Good afternoon!
>
>
>
> I would like to ask you about similarity measures and clustering in
> R for Binary data.
>
> Would you please kindly help me and let me know about that commands
> in R?

help.seach("cluster") will give you an overview of available 
appropriate functions in your local R installation. In these help 
pages you'll find some very good examples on how to do clustering.

If you want some more detailed response have a look at the posting 
guide (www.r-project.org/posting-guide.html) and provide some more 
informations on your data and what you've done so far (example code)! 
Another source of wealth is the Mail archive of this R-help, which 
provides a helpful search dialog to browse....

regards

Thomas



From Roger.Bivand at nhh.no  Sat Mar  5 11:32:41 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 5 Mar 2005 11:32:41 +0100 (CET)
Subject: [R] R: Moran's I
In-Reply-To: <BE4E19E8.9517%tstalley@ucdavis.edu>
Message-ID: <Pine.LNX.4.44.0503051124390.30319-100000@reclus.nhh.no>

On Fri, 4 Mar 2005, Theresa Sinicrope Talley wrote:

> Hi-
> I would like to assign distance classes (lags) to the moran's I test in R.
> 
>  I don?t have equally spaced points since I was mapping shrubs across a
> landscape (vs. an experiment or survey in a grid).   I somehow need to
> select points based on the distances in the distance matrix (i.e., I need to
> select all pairs of points that occur 0-25 m from each other, 25-50 m,
> etc...).  
> 
> Does anyone have code or a detailed procedure for subsampling or dividing a
> dataset into distance classes for moran?s I (or mantel test)?
> I know there is sp.correlogram  but I need significance values for each I
> value and I need to use distance lags, not lags of number of polygons.
> 

If you need to follow this up further, please consider moving your reply 
to the r-sig-geo list (access from http://www.r-project.org/Rgeo).

In the spdep package, you can define distance based lists of neighbours 
by:

nb0_25 <- dnearneigh(points, d1=0, d2=25)
nb25_50 <- dnearneigh(points, d1=25, d2=50)

then calculate Moran's I (moran.test()) or a chosen Mantel test
(sp.mantel.mc()) using these lists. You are right that sp.correlogram()
is not appropriate in this setting.

> 
> Any suggestions would be appreciated.
> Best wishes, theresa
> 
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From ramasamy at cancer.org.uk  Sat Mar  5 14:54:55 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Sat, 05 Mar 2005 13:54:55 +0000
Subject: [R] Emacs keystroke to toggle T/F for setting logical values
In-Reply-To: <7E4C06F49D6FEB49BE4B60E5FC92ED7A01834B59@pnlmse35.pnl.gov>
References: <7E4C06F49D6FEB49BE4B60E5FC92ED7A01834B59@pnlmse35.pnl.gov>
Message-ID: <1110030895.5869.5.camel@dhcp-63.ccc.ox.ac.uk>

Not answering your question here directly but here is an alternative. 
Interactive search and replace TRUE for FALSE with M-% after
highlighting the region that you are interested in. And then repeat for
changing FALSE to TRUE. 

You can bind some function keys in your configuration file to simplify
this a bit.

Regards, Adai



On Fri, 2005-03-04 at 16:58 -0800, Waichler, Scott R wrote:
> I'd like to have an Emacs keystroke that would let me toggle between T
> and F when editing logical settings in R code.  I looked in the ESS
> documentation and in my O'Reilly emacs books but found nothing.  Any
> ideas?
> 
> Scott Waichler
> Pacific Northwest National Laboratory
> scott.waichler at pnl.gov
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From drcarbon at gmail.com  Sat Mar  5 15:08:41 2005
From: drcarbon at gmail.com (Dr Carbon)
Date: Sat, 5 Mar 2005 09:08:41 -0500
Subject: [R] partial r2 using PLS
In-Reply-To: <e89bb7ac0503040751290eafd3@mail.gmail.com>
References: <e89bb7ac0503040751290eafd3@mail.gmail.com>
Message-ID: <e89bb7ac0503050608c3c8860@mail.gmail.com>

I'm trying to get the coefficient of partial determination for each of
three independent variables. I've tried mvr in package pls.pcr. I'm a
little confused by the output. I'm curious how I can order the LV's
according to their names rather than their relative contribution to
the regression.

For instance, using the crabs data from MASS I made a regression of FL~RW+noise

set.seed(124)
library(pls.pcr)
library(MASS)
attach(crabs)
crabs.simpls <- mvr(data.frame(x1 = RW,x2 = runif(200)), FL,
validation="CV", method="SIMPLS")
summary(crabs.simpls)
crabs.simpls <- mvr(data.frame(x1 = runif(200), x2 = RW), FL,
validation="CV", method="SIMPLS")
summary(crabs.simpls)
# compare to summary(lm(FL~RW+runif(200)))
detach(crabs)

The two summaries are almost identical, as are the inputs. But the order of
the LVs are different. How can I know that it is x1 is the useful
predictor in the first example and that x2 is the useful predictor in
the second example. I hope to run a three variable regression in a MC
framework and output the partial rsq for x1, x2, and x3 in every run.

Can I do this? I fear I've made some fundamental misunderstanding about mvr()

Thanks, DC

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    0.1            
year     2004           
month    11             
day      15             
language R



From spencer.graves at pdf.com  Sat Mar  5 17:14:15 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 05 Mar 2005 08:14:15 -0800
Subject: [R] How to use "lag"?  
Message-ID: <4229DAD7.6030405@pdf.com>

      Is it possible to fit a lagged regression, "y[t]=b0+b1*x[t-1]+e", 
using the function "lag"?  If so, how?  If not, of what use is the 
function "lag"?  I get the same answer from y~x as y~lag(x), whether 
using lm or arima.  I found it using y~c(NA, x[-length(x)])).  Consider 
the following: 

 > set.seed(1)
 > x <- rep(c(rep(0, 4), 9), len=9)
 > y <- (rep(c(rep(0, 5), 9), len=9)+rnorm(9)) # y[t] = x[t-1]+e
 >
 > lm(y~x)
(Intercept)            x 
     1.2872      -0.1064 
 > lm(y~lag(x))
(Intercept)       lag(x) 
     1.2872      -0.1064 
 > arima(y, xreg=x)
      intercept        x
         1.2872  -0.1064
s.e.     0.9009   0.3003
sigma^2 estimated as 6.492:  log likelihood = -21.19,  aic = 48.38
 > arima(y, xreg=lag(x))
      intercept   lag(x)
         1.2872  -0.1064
s.e.     0.9009   0.3003
 > arima(y, xreg=c(NA, x[-9]))
      intercept  c(NA, x[-9])
         0.4392        0.8600
s.e.     0.2372        0.0745
sigma^2 estimated as 0.3937:  log likelihood = -7.62,  aic = 21.25
 > arima(ts(y), xreg=lag(ts(x)))
arima(x = ts(y), xreg = lag(ts(x)))
      intercept  lag(ts(x))
         1.2872     -0.1064
s.e.     0.9009      0.3003
sigma^2 estimated as 6.492:  log likelihood = -21.19,  aic = 48.38
 
      Thanks for your help. 
      Spencer Graves



From berkowi4 at msu.edu  Sat Mar  5 17:42:02 2005
From: berkowi4 at msu.edu (Shelby Berkowitz)
Date: Sat, 5 Mar 2005 11:42:02 -0500
Subject: [R] Problem with plotting size/location on variation of
	star/segment plot
Message-ID: <005501c521a2$42a8e270$144dfea9@shelbyhome>

Dear R gurus,

I'm running into a problem with some modified segment plots I've coded
using stars().  What I am trying to do is superimpose two series of data
along with radial axes markers in a 2x2 graphics frame.  This is working
fine now, except for the hitch: my plots overfill the frame and are not
centered within it (on my runs they always end up looking like they've
been budged up and to the left).  They're also a little warped-looking
(more oval than perfectly round).

- I don't think this is a problem with my par() settings, as I've
checked them out and they don't look suspicious.  Also, I've tested
generating other plots (e.g., dummy histograms) on the same device and
they fit perfectly.  It's also not a problem with fitting stars() plots
into a par(mfrow=c(2,2) frame, as I get the same offset/overflow when I
run just one plot on a mfrow=c(1,1) frame.
- I don't think it's a problem with the windows graphics device, as I
tried plotting to other devices (e.g., postscript) and get the same
results.
- Thus, I'm pretty sure this comes down to something funky with the way
I'm using stars().  My runs of examples from stars() fit just as they
should inside their graphics frames, but as far as I can see, the
individual calls to stars() below don't look materially different from
the ones in the examples.

At this point, I'm completely stumped.  Can someone please point me
towards what I might be doing wrong here?  Any and all advice will be
most humbly appreciated!
BTW, I'm running R 2.00 on Windows XP, all packages updated.

Example version of my code is pasted below (the loop is for example
purposes only):

##begin sample code
par(mfrow=c(2,2))
for (i in 1:4) {
	## generate sample data for plot:
	a<- sample(c(20:70)*.01,18)
	testA <-
as.data.frame(rbind(a,a+((1-a)*sample(c(1:10)*.1,18,replace=T))))
	## open new plot space
	plot.new()
	## plot data series:
	stars(testA[2,], locations=0:1,full = TRUE, scale = F,
draw.segments=TRUE, add=TRUE,col.segments=heatshades[7])
	stars(testA[1,], locations=0:1,full = TRUE, scale = F,
draw.segments=TRUE, add=TRUE,col.segments=heatshades[3])
	majgrid <- matrix(rep((c(1:10)*.1),ncol(testA)),nrow=10,byrow=F)
	## generate and plot radar grid:
	mingrid <-
matrix(rep((c(1:10)*.1-.05),ncol(testA)),nrow=10,byrow=F)
	stars(majgrid, locations=0:1, scale=F, draw.segments = TRUE,
add=T, lty=1, col.segments=0)
	stars(mingrid, locations=0:1, scale=F, draw.segments = TRUE,
add=T, lty=2, col.segments=0)}
par(mfrow=c(1,1))
##end sample code

Thank you,

Shelby

===============================
Shelby L. Berkowitz
Ecological-Community Psychology
and Institute for Health Care Studies
Michigan State University
berkowi4 at msu.edu



From edd at debian.org  Sat Mar  5 18:14:50 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 5 Mar 2005 11:14:50 -0600
Subject: [R] How to use "lag"?  
In-Reply-To: <4229DAD7.6030405@pdf.com>
References: <4229DAD7.6030405@pdf.com>
Message-ID: <16937.59658.196821.296047@basebud.nulle.part>


Spencer,

You may want to peruse the list archive for posts that match 'ts' and are
written by Brian Ripley -- these issues have come up before. 

The ts class is designed for arima and friends (like Kalman filtering), and
very useful in that context, but possibly not so much anywhere else.  lag()
only shifts the _reference dates_ attached to the object. So in a data.frame
context (as for lm()) .... nothing happens.

Personally, I use its as my main container for daily or weekly data. There is
also zoo, which I have meant to examine more closely for a while now.  You
want want to use one of those for shifting, matching, intersecting, ... and
then use one of the exporter functions (core() for its) to pass to lm(), say.

Hope this helps,  Dirk

-- 
Better to have an approximate answer to the right question than a precise 
answer to the wrong question.  --  John Tukey as quoted by John Chambers



From ggrothendieck at myway.com  Sat Mar  5 18:21:17 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 5 Mar 2005 17:21:17 +0000 (UTC)
Subject: [R] How to use "lag"?
References: <4229DAD7.6030405@pdf.com>
Message-ID: <loom.20050305T181813-162@post.gmane.org>

Spencer Graves <spencer.graves <at> pdf.com> writes:

: 
: Is it possible to fit a lagged regression, "y[t]=b0+b1*x[t-1]+e", 
: using the function "lag"?  If so, how?  If not, of what use is the 
: function "lag"?  I get the same answer from y~x as y~lag(x), whether 
: using lm or arima.  I found it using y~c(NA, x[-length(x)])).  Consider 
: the following: 
: 
:  > set.seed(1)
:  > x <- rep(c(rep(0, 4), 9), len=9)
:  > y <- (rep(c(rep(0, 5), 9), len=9)+rnorm(9)) # y[t] = x[t-1]+e
:  >
:  > lm(y~x)
: (Intercept)            x 
:      1.2872      -0.1064 
:  > lm(y~lag(x))
: (Intercept)       lag(x) 
:      1.2872      -0.1064 
:  > arima(y, xreg=x)
:       intercept        x
:          1.2872  -0.1064
: s.e.     0.9009   0.3003
: sigma^2 estimated as 6.492:  log likelihood = -21.19,  aic = 48.38
:  > arima(y, xreg=lag(x))
:       intercept   lag(x)
:          1.2872  -0.1064
: s.e.     0.9009   0.3003
:  > arima(y, xreg=c(NA, x[-9]))
:       intercept  c(NA, x[-9])
:          0.4392        0.8600
: s.e.     0.2372        0.0745
: sigma^2 estimated as 0.3937:  log likelihood = -7.62,  aic = 21.25
:  > arima(ts(y), xreg=lag(ts(x)))
: arima(x = ts(y), xreg = lag(ts(x)))
:       intercept  lag(ts(x))
:          1.2872     -0.1064
: s.e.     0.9009      0.3003
: sigma^2 estimated as 6.492:  log likelihood = -21.19,  aic = 48.38
: 

Here is some sample code:

R> # following 3 lines are from your post
R> set.seed(1)
R> x <- rep(c(rep(0, 4), 9), len=9)
R> y <- (rep(c(rep(0, 5), 9), len=9)+rnorm(9)) # y[t] = x[t-1]+e
R> 
R> # here are some examples using ts class - first one uses no lag
R> lm(y ~ x, cbind(y = ts(y), x = ts(x)))

Call:
lm(formula = y ~ x, data = cbind(y = ts(y), x = ts(x)))

Coefficients:
(Intercept)            x  
     1.2872      -0.1064  

R> # now lets redo it with a lag. 
R> lm(y ~ lagx, cbind(y = ts(y), lagx = lag(ts(x), -1)) )

Call:
lm(formula = y ~ lagx, data = cbind(y = ts(y), lagx = lag(ts(x),     -1)))

Coefficients:
(Intercept)         lagx  
     0.4392       0.8600  

R> # here is arima without a lag
R> b <- cbind(ts(y), ts(x))
R> arima(b[,1], order = c(1,1,1), xreg = b[,2])

Call:
arima(x = b[, 1], order = c(1, 1, 1), xreg = b[, 2])

Coefficients:
         ar1      ma1   b[, 2]
      0.3906  -1.0000  -0.3803
s.e.  0.4890   0.4119   0.3753

sigma^2 estimated as 7.565:  log likelihood = -20.2,  aic = 48.4

R> # and now we redo arima with a lag
R> bb <- cbind(ts(y), lag(ts(x),-1))
R> arima(bb[,1], order = c(1,1,1), xreg = bb[,2])

Call:
arima(x = bb[, 1], order = c(1, 1, 1), xreg = bb[, 2])

Coefficients:
          ar1      ma1  bb[, 2]
      -0.2991  -0.8252   0.8537
s.e.   0.4516   1.0009   0.0838

sigma^2 estimated as 0.444:  log likelihood = -7.9,  aic = 23.8

R> # you can alternately use the I notation with lm and ts objects
R> # if you load zoo first
R> library(zoo)
R> yt <- ts(y); xt <- ts(x)
R> lm(I(yt ~ xt))

Call:
lm(formula = I(yt ~ xt))

Coefficients:
(Intercept)           xt  
     1.2872      -0.1064  

R> lm(I(yt ~ lag(xt, -1)))

Call:
lm(formula = I(yt ~ lag(xt, -1)))

Coefficients:
(Intercept)  lag(xt, -1)  
     0.4392       0.8600



From remigijus.lapinskas at maf.vu.lt  Sat Mar  5 18:34:23 2005
From: remigijus.lapinskas at maf.vu.lt (Remigijus Lapinskas)
Date: Sat, 5 Mar 2005 19:34:23 +0200
Subject: [R] How to use "lag"?
In-Reply-To: <4229DAD7.6030405@pdf.com>
References: <4229DAD7.6030405@pdf.com>
Message-ID: <1454339453.20050305193423@maf.vu.lt>


I use the following two function for a lagged regression:

lm.lag=function(y,lag=1) summary(lm(embed(y,lag+1)[,1]~embed(y,lag+1)[,2:(lag+1)]))
lm.lag.x=function(y,x,lag=1) summary(lm(embed(y,lag+1)[,1]~embed(x,lag+1)[,2:(lag+1)]))

for, respectively,

y_t=a+b_1*y_t-1+...+b_lag*y_t-lag
y_t=a+b_1*x_t-1+...+b_lag*x_t-lag

I am not quite sure whether this an answer to your question, but here
are two examples:

set.seed(7)
ar1=arima.sim(n=300,list(ar=0.8))
lm.lag(ar1)
lm.lag.x(ar1,ar1)

set.seed(8)
ar3=arima.sim(n = 200, list(ar = c(0.4, -0.5, 0.7)))
lm.lag(ar3,3) 
lm.lag.x(ar3,ar3,3)

Best wishes,
Rem




Saturday, March 5, 2005, 6:14:15 PM, you wrote:

SG>       Is it possible to fit a lagged regression, "y[t]=b0+b1*x[t-1]+e",
SG> using the function "lag"?  If so, how?  If not, of what use is the
SG> function "lag"?  I get the same answer from y~x as y~lag(x), whether
SG> using lm or arima.  I found it using y~c(NA, x[-length(x)])). Consider
SG> the following: 

 >> set.seed(1)
 >> x <- rep(c(rep(0, 4), 9), len=9)
 >> y <- (rep(c(rep(0, 5), 9), len=9)+rnorm(9)) # y[t] = x[t-1]+e
 >>
 >> lm(y~x)
SG> (Intercept)            x 
SG>      1.2872      -0.1064 
 >> lm(y~lag(x))
SG> (Intercept)       lag(x) 
SG>      1.2872      -0.1064 
 >> arima(y, xreg=x)
SG>       intercept        x
SG>          1.2872  -0.1064
SG> s.e.     0.9009   0.3003
SG> sigma^2 estimated as 6.492:  log likelihood = -21.19,  aic = 48.38
 >> arima(y, xreg=lag(x))
SG>       intercept   lag(x)
SG>          1.2872  -0.1064
SG> s.e.     0.9009   0.3003
 >> arima(y, xreg=c(NA, x[-9]))
SG>       intercept  c(NA, x[-9])
SG>          0.4392        0.8600
SG> s.e.     0.2372        0.0745
SG> sigma^2 estimated as 0.3937:  log likelihood = -7.62,  aic = 21.25
 >> arima(ts(y), xreg=lag(ts(x)))
SG> arima(x = ts(y), xreg = lag(ts(x)))
SG>       intercept  lag(ts(x))
SG>          1.2872     -0.1064
SG> s.e.     0.9009      0.3003
SG> sigma^2 estimated as 6.492:  log likelihood = -21.19,  aic = 48.38
 
SG>       Thanks for your help. 
SG>       Spencer Graves

SG> ______________________________________________
SG> R-help at stat.math.ethz.ch mailing list
SG> https://stat.ethz.ch/mailman/listinfo/r-help
SG> PLEASE do read the posting guide!
SG> http://www.R-project.org/posting-guide.html



From ggrothendieck at myway.com  Sat Mar  5 18:24:53 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 5 Mar 2005 17:24:53 +0000 (UTC)
Subject: [R] How to use "lag"?
References: <4229DAD7.6030405@pdf.com>
	<16937.59658.196821.296047@basebud.nulle.part>
Message-ID: <loom.20050305T182208-160@post.gmane.org>

Dirk Eddelbuettel <edd <at> debian.org> writes:

> 
> Spencer,
> 
> You may want to peruse the list archive for posts that match 'ts' and are
> written by Brian Ripley -- these issues have come up before. 
> 
> The ts class is designed for arima and friends (like Kalman filtering), and
> very useful in that context, but possibly not so much anywhere else.  lag()
> only shifts the _reference dates_ attached to the object. So in a data.frame
> context (as for lm()) .... nothing happens.
> 
> Personally, I use its as my main container for daily or weekly data. There is
> also zoo, which I have meant to examine more closely for a while now.  

Here is the example redone using zoo:

R> # here it is redone using zoo objects
R> 
R> # following 3 lines are from the original post
R> set.seed(1)
R> x <- rep(c(rep(0, 4), 9), len=9)
R> y <- (rep(c(rep(0, 5), 9), len=9)+rnorm(9)) # y[t] = x[t-1]+e
R> 
R> library(zoo)
R> 
R> yz <- zoo(y); xz <- zoo(x)
R> lm(I(yz ~ xz))

Call:
lm(formula = I(yz ~ xz))

Coefficients:
(Intercept)           xz  
     1.2872      -0.1064  

R> lm(I(yz ~ lag(xz, -1)))

Call:
lm(formula = I(yz ~ lag(xz, -1)))

Coefficients:
(Intercept)  lag(xz, -1)  
     0.4392       0.8600  

R> 
R> z <- merge(yz, xz)
R> arima(coredata(z[,1]), order = c(1,1,1), xreg = coredata(z[,2]))

Call:
arima(x = coredata(z[, 1]), order = c(1, 1, 1), xreg = coredata(z[, 2]))

Coefficients:
         ar1      ma1  coredata(z[, 2])
      0.3906  -1.0000           -0.3803
s.e.  0.4890   0.4119            0.3753

sigma^2 estimated as 7.565:  log likelihood = -20.2,  aic = 48.4
 
R> zz <- merge(yz, lag(xz, -1))
R> arima(coredata(zz[,1]), order = c(1,1,1), xreg = coredata(zz[,2]))

Call:
arima(x = coredata(zz[, 1]), order = c(1, 1, 1), xreg = coredata(zz[, 2]))

Coefficients:
          ar1      ma1  coredata(zz[, 2])
      -0.2991  -0.8252             0.8537
s.e.   0.4516   1.0009             0.0838

sigma^2 estimated as 0.444:  log likelihood = -7.9,  aic = 23.8



From gsxej2 at cam.ac.uk  Sat Mar  5 19:07:18 2005
From: gsxej2 at cam.ac.uk (Gregory Jefferis)
Date: Sat, 05 Mar 2005 18:07:18 +0000
Subject: [R] Reverse plot axes with xlim=rev(range(x)) fails with asp=1
Message-ID: <BE4FA5D6.4C04%gsxej2@cam.ac.uk>

Dear R users,

I would like to reverse the axes on some xy plots (for example to set the
origin at the top left rather than the bottom left).  I had planned to use
something of the following form:

plot(y=y<-c(20,4,5,6),x=x<-c(10,20,30,40),ylim=rev(range(y)))

ie reversing ylim to reverse the y axis.  This works fine however I also
want to use the parameter asp=1 to ensure that equal distances in the x or y
direction are plotted as such on the screen.  However the simple example I
showed above now fails:

> plot(y=y<-c(20,4,5,6),x=x<-c(10,20,30,40),ylim=rev(range(y)),asp=1)

The actual ylim used is considerably less than it should be, so no points
appear on the plot.

Can anyone suggest a simple remedy?

Many thanks,

Greg Jefferis.

PS I would guess that the origin of this behaviour is that plot.window
expects xlim (and ylim) to be in the order xmin,xmax (or ymin,ymax) when it
sets about redefining xlim and ylim if asp!=NA.  If that suggestion is
correct, I'm not quite sure why the restriction is necessary.

-- 
Gregory Jefferis, PhD                               and:
Research Fellow
Department of Zoology                               St John's College
Downing Street                                      Cambridge
Cambridge, CB2 3EJ                                  CB2 1TP



From ligges at statistik.uni-dortmund.de  Sat Mar  5 19:19:25 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 05 Mar 2005 19:19:25 +0100
Subject: [R] image size
In-Reply-To: <20050304190608.26667.qmail@web60210.mail.yahoo.com>
References: <20050304190608.26667.qmail@web60210.mail.yahoo.com>
Message-ID: <4229F82D.6090003@statistik.uni-dortmund.de>

Mikkel Grum wrote:

> Dear useRs,
> 
> I'm working in R 2.0.1 for Windows and producing PDF
> files with Sweave. I seem to be hitting an image size
> ceiling of around 6.8 x 6.8 inches.  I would like to
> produce taller images to make better use of my A4 page
> and have tried:
> 
> <<TestMap, fig = TRUE, width = 6.5, height = 8 >>=
> par.old(fin = c(6.5, 8))

What is par.old()?

If you mean par(): you cannot always make the figure region as large as 
the whole device region. Either enlarge the device region or set fin to 
a smaller value.

Uwe Ligges



> image(x, etc.)
> 
> I get the message:
> Error in plot.new(): Figure region too large
> 
> Is there anything I can do?



> Mikkel
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From patrick.giraudoux at univ-fcomte.fr  Sat Mar  5 19:02:24 2005
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux H)
Date: Sat, 05 Mar 2005 19:02:24 +0100
Subject: [R] maptools, filename writing shapefiles
Message-ID: <5.0.2.1.2.20050305185452.02be60a0@utinam.univ-fcomte.fr>

Hi,

I meet a strange trouble writing shapefiles with write.pointShape() from 
maptools.

 > write.pointShape(mylines[,5:9], file="Sxtplinshp", mycoordspt)
Error in write.pointShape(mylines[, 5:9], file = "Sxtplinshp", mycoordspt) :
         shapefile names must conform to the 8.3 format

It seems that the function request a special shapefile name spelling 
(conformed to 8.3 ESRI format?).

 > write.pointShape(mylines[,5:9], file="Sxtplin", mycoordspt)

When just shortened, everything goes smoothly with the file correctly written.

I am not sure about ESRI standard requesting short names (modifying the 
filename by hand keep it readable by any GIS).

Can anybody (especially Roger...) tell us where comes the trouble from?

Patrick Giraudoux



From ligges at statistik.uni-dortmund.de  Sat Mar  5 19:49:21 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 05 Mar 2005 19:49:21 +0100
Subject: [R] Problem with plotting size/location on variation
	of	star/segment plot
In-Reply-To: <005501c521a2$42a8e270$144dfea9@shelbyhome>
References: <005501c521a2$42a8e270$144dfea9@shelbyhome>
Message-ID: <4229FF31.2070601@statistik.uni-dortmund.de>

Shelby Berkowitz wrote:

> Dear R gurus,
> 
> I'm running into a problem with some modified segment plots I've coded
> using stars().  What I am trying to do is superimpose two series of data
> along with radial axes markers in a 2x2 graphics frame.  This is working
> fine now, except for the hitch: my plots overfill the frame and are not
> centered within it (on my runs they always end up looking like they've
> been budged up and to the left).  They're also a little warped-looking
> (more oval than perfectly round).
> 
> - I don't think this is a problem with my par() settings, as I've
> checked them out and they don't look suspicious.  Also, I've tested
> generating other plots (e.g., dummy histograms) on the same device and
> they fit perfectly.  It's also not a problem with fitting stars() plots
> into a par(mfrow=c(2,2) frame, as I get the same offset/overflow when I
> run just one plot on a mfrow=c(1,1) frame.
> - I don't think it's a problem with the windows graphics device, as I
> tried plotting to other devices (e.g., postscript) and get the same
> results.
> - Thus, I'm pretty sure this comes down to something funky with the way
> I'm using stars().  My runs of examples from stars() fit just as they
> should inside their graphics frames, but as far as I can see, the
> individual calls to stars() below don't look materially different from
> the ones in the examples.
> 
> At this point, I'm completely stumped.  Can someone please point me
> towards what I might be doing wrong here?  Any and all advice will be
> most humbly appreciated!
> BTW, I'm running R 2.00 on Windows XP, all packages updated.
> 
> Example version of my code is pasted below (the loop is for example
> purposes only):
> 
> ##begin sample code
> par(mfrow=c(2,2))
> for (i in 1:4) {
> 	## generate sample data for plot:
> 	a<- sample(c(20:70)*.01,18)
> 	testA <-
> as.data.frame(rbind(a,a+((1-a)*sample(c(1:10)*.1,18,replace=T))))
> 	## open new plot space
> 	plot.new()
> 	## plot data series:
> 	stars(testA[2,], locations=0:1,full = TRUE, scale = F,
> draw.segments=TRUE, add=TRUE,col.segments=heatshades[7])

Well, since you have neither called plot.window() nor stars() with 
"add=FALSE"), the dimensions have not been set up correctly.

In the first call above, simply say add = FALSE.

Uwe Ligges



> 	stars(testA[1,], locations=0:1,full = TRUE, scale = F,
> draw.segments=TRUE, add=TRUE,col.segments=heatshades[3])
> 	majgrid <- matrix(rep((c(1:10)*.1),ncol(testA)),nrow=10,byrow=F)
> 	## generate and plot radar grid:
> 	mingrid <-
> matrix(rep((c(1:10)*.1-.05),ncol(testA)),nrow=10,byrow=F)
> 	stars(majgrid, locations=0:1, scale=F, draw.segments = TRUE,
> add=T, lty=1, col.segments=0)
> 	stars(mingrid, locations=0:1, scale=F, draw.segments = TRUE,
> add=T, lty=2, col.segments=0)}
> par(mfrow=c(1,1))
> ##end sample code
> 
> Thank you,
> 
> Shelby
> 
> ===============================
> Shelby L. Berkowitz
> Ecological-Community Psychology
> and Institute for Health Care Studies
> Michigan State University
> berkowi4 at msu.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Roger.Bivand at nhh.no  Sat Mar  5 19:52:37 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 5 Mar 2005 19:52:37 +0100 (CET)
Subject: [R] Re: maptools, filename writing shapefiles
In-Reply-To: <5.0.2.1.2.20050305185452.02be60a0@utinam.univ-fcomte.fr>
Message-ID: <Pine.LNX.4.44.0503051940320.30319-100000@reclus.nhh.no>

On Sat, 5 Mar 2005, Patrick Giraudoux H wrote:

> Hi,
> 
> I meet a strange trouble writing shapefiles with write.pointShape() from 
> maptools.
> 
>  > write.pointShape(mylines[,5:9], file="Sxtplinshp", mycoordspt)
> Error in write.pointShape(mylines[, 5:9], file = "Sxtplinshp", mycoordspt) :
>          shapefile names must conform to the 8.3 format
> 
> It seems that the function request a special shapefile name spelling 
> (conformed to 8.3 ESRI format?).
> 
>  > write.pointShape(mylines[,5:9], file="Sxtplin", mycoordspt)
> 
> When just shortened, everything goes smoothly with the file correctly written.
> 
> I am not sure about ESRI standard requesting short names (modifying the 
> filename by hand keep it readable by any GIS).

Well, the ESRI technical description - access also at:

http://dl.maptools.org/dl/shapelib/shapefile.pdf

says (p. 6): "All file names adhere to the 8.3 naming convention. The main
file, the index file, and the dBASE file have the same prefix. The prefix
must start with an alphanumeric character (aZ, 09), followed by zero or up
to seven characters (aZ, 09, _, -). The suffix for the main file is .shp.
The suffix for the index file is .shx. The suffix for the dBASE table is
.dbf."

so maptools tries to follow the standard. It doesn't actually try hard
enough, because the same paragraph continues: "All letters in a file name
are in lower case on operating systems with case sensitive file names". So
I guess tolower() will have to be used too! The white paper is dated 1998,
by the way. A possible change in maptools would be to add a
strictFilename=FALSE argument, so that users can "adhere" to ESRI's
standards (as were) if they are still running ArcView on Windows 3.*; this
will probably be in the next (> 0.4-13) version, since there do not seem
to be any limitations in the shapelib code.

Roger

> 
> Can anybody (especially Roger...) tell us where comes the trouble from?
> 
> Patrick Giraudoux
> 
> 
> 
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From ggrothendieck at myway.com  Sat Mar  5 19:58:50 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 5 Mar 2005 18:58:50 +0000 (UTC)
Subject: [R] How to use "lag"?
References: <4229DAD7.6030405@pdf.com> <1454339453.20050305193423@maf.vu.lt>
Message-ID: <loom.20050305T195648-876@post.gmane.org>

Remigijus Lapinskas <remigijus.lapinskas <at> maf.vu.lt> writes:

: 
: I use the following two function for a lagged regression:
: 
: lm.lag=function(y,lag=1) summary(lm(embed(y,lag+1)[,1]~embed(y,lag+1)[,2:
(lag+1)]))
: lm.lag.x=function(y,x,lag=1) summary(lm(embed(y,lag+1)[,1]~embed(x,lag+1)[,2:
(lag+1)]))
: 
: for, respectively,
: 
: y_t=a+b_1*y_t-1+...+b_lag*y_t-lag
: y_t=a+b_1*x_t-1+...+b_lag*x_t-lag


One could combine these into one function like this:

lm.lag <- function(y, x = y, lag = 1) 
   summary( lm( embed(y, lag+1)[,1] ~ embed(x, lag+1)[,-1] ) )



From Roger.Bivand at nhh.no  Sat Mar  5 20:19:04 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 5 Mar 2005 20:19:04 +0100 (CET)
Subject: [R] Reverse plot axes with xlim=rev(range(x)) fails with asp=1
In-Reply-To: <BE4FA5D6.4C04%gsxej2@cam.ac.uk>
Message-ID: <Pine.LNX.4.44.0503052003510.30319-100000@reclus.nhh.no>

On Sat, 5 Mar 2005, Gregory Jefferis wrote:

> Dear R users,
> 
> I would like to reverse the axes on some xy plots (for example to set the
> origin at the top left rather than the bottom left).  I had planned to use
> something of the following form:
> 
> plot(y=y<-c(20,4,5,6),x=x<-c(10,20,30,40),ylim=rev(range(y)))
> 
> ie reversing ylim to reverse the y axis.  This works fine however I also
> want to use the parameter asp=1 to ensure that equal distances in the x or y
> direction are plotted as such on the screen.  However the simple example I
> showed above now fails:
> 
> > plot(y=y<-c(20,4,5,6),x=x<-c(10,20,30,40),ylim=rev(range(y)),asp=1)
> 
> The actual ylim used is considerably less than it should be, so no points
> appear on the plot.
> 
> Can anyone suggest a simple remedy?

> plot(y=-y,x=x, ylim=range(-y), asp=1, axes=FALSE)
> box()
> axis(1)
> axis(2, at=seq(-20,-5,5), label=seq(20,5,-5))

is a simple kludge, the explanation is touched on in a comment in
src/main/plot.c, after line 564:

 *	The use of asp can have weird effects when axis is an
 *	interpreted function.  It has to be internal so that the
 *	full computation is captured in the display list.

and may be related to the sign of ydelta being dropped in line 652 (for 
the y axis) and Gscale() being possibly called in line 666 with incorrect 
assumptions about whether to add or subtract the correction factor - 
untried!

> 
> Many thanks,
> 
> Greg Jefferis.
> 
> PS I would guess that the origin of this behaviour is that plot.window
> expects xlim (and ylim) to be in the order xmin,xmax (or ymin,ymax) when it
> sets about redefining xlim and ylim if asp!=NA.  If that suggestion is
> correct, I'm not quite sure why the restriction is necessary.
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From michael_shen at hotmail.com  Sun Mar  6 03:11:46 2005
From: michael_shen at hotmail.com (peng shen)
Date: Sun, 06 Mar 2005 02:11:46 +0000
Subject: [R] Search and convert string function
Message-ID: <BAY1-F64B98EE61B150F55F67E9E75E0@phx.gbl>

Hi all,
I want to do this kind of function In R enviroment :
For example :
R <- 4
testString <- "I love $R"
then search this testString, when find "$R",replace "$R" to R ,and because 
the value of R is 4
So the final string I want to get is "I love 4"
How can I implement? Thanks advance

Michael



From ggrothendieck at myway.com  Sun Mar  6 04:04:38 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 6 Mar 2005 03:04:38 +0000 (UTC)
Subject: [R] Search and convert string function
References: <BAY1-F64B98EE61B150F55F67E9E75E0@phx.gbl>
Message-ID: <loom.20050306T035144-802@post.gmane.org>

peng shen <michael_shen <at> hotmail.com> writes:

: 
: Hi all,
: I want to do this kind of function In R enviroment :
: For example :
: R <- 4
: testString <- "I love $R"
: then search this testString, when find "$R",replace "$R" to R ,and because 
: the value of R is 4
: So the final string I want to get is "I love 4"
: How can I implement? Thanks advance
: 

Here is one way to do string interpolation:

R> interp <- function(x, e = parent.frame(), pre = "\\$", post = "" ) {
+    for(el in ls(e)) {
+       tag <- paste(pre, el, post, sep = "")
+       if (length(grep(tag, x))) x <- gsub(tag, eval(parse(text = el), e), x)
+    }
+    x
+ }
 
R> # a test
R> R <- 4
R> x <- "I love $R"
R> interp(x)
[1] "I love 4"
 
R> # another test
R> y <- "I love ${R}"
R> interp(y, pre = "\\${", post = "}")
[1] "I love 4"



From ripley at stats.ox.ac.uk  Sun Mar  6 05:46:10 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 6 Mar 2005 04:46:10 +0000 (GMT)
Subject: [R] Search and convert string function
In-Reply-To: <BAY1-F64B98EE61B150F55F67E9E75E0@phx.gbl>
References: <BAY1-F64B98EE61B150F55F67E9E75E0@phx.gbl>
Message-ID: <Pine.LNX.4.61.0503060444070.15962@gannet.stats>

On Sun, 6 Mar 2005, peng shen wrote:

> Hi all,
> I want to do this kind of function In R enviroment :
> For example :
> R <- 4
> testString <- "I love $R"
> then search this testString, when find "$R",replace "$R" to R ,and because 
> the value of R is 4
> So the final string I want to get is "I love 4"
> How can I implement? Thanks advance

sub("$R", R, testString, fixed = TRUE)


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From michael_shen at hotmail.com  Sun Mar  6 08:40:19 2005
From: michael_shen at hotmail.com (peng shen)
Date: Sun, 06 Mar 2005 07:40:19 +0000
Subject: [R] I modified my question in "search and convert string function "
Message-ID: <BAY1-F27B273D958F8BA68DB2E91E75E0@phx.gbl>

Hi ,all R-helper!
I modified my  question  in "search and convert string function".
I want to do this kind of operation In R enviroment :
For example :
R <- 4
testString <- "I love %R%"
then search this testString, when find beginning and end symbol"%",get a new 
substring "%R%".
then get rid of symbole"%",replace string"R" by R(numeric )
So the final string is "I love 4"

How can I implement? if there is not this kind of function ,how can I write 
function in C and implement in R.
Thanks advance

Michael



From patrick.giraudoux at univ-fcomte.fr  Sun Mar  6 08:44:17 2005
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux H)
Date: Sun, 06 Mar 2005 08:44:17 +0100
Subject: [R] Re: maptools, filename writing shapefiles
In-Reply-To: <Pine.LNX.4.44.0503051940320.30319-100000@reclus.nhh.no>
References: <5.0.2.1.2.20050305185452.02be60a0@utinam.univ-fcomte.fr>
Message-ID: <5.0.2.1.2.20050306083910.02493f58@utinam.univ-fcomte.fr>


>says (p. 6): "All file names adhere to the 8.3 naming convention. The main
>file, the index file, and the dBASE file have the same prefix. The prefix
>must start with an alphanumeric character (aZ, 09), followed by zero or up
>to seven characters (aZ, 09, _, -). The suffix for the main file is .shp.
>The suffix for the index file is .shx. The suffix for the dBASE table is
>.dbf."

So, the number of characters was the trouble origin (... up to 7 
characters). Easy to manage when known. This also means that ESRI 
ArcGISdoes not itself comply to the standard since one can use much more 
than 7 characters naming shapefiles from there....

Thanks a lot for maptools (those fonctions to write shapefiles are really 
useful) and the clarification.

All the best,

Patrick



From ggrothendieck at myway.com  Sun Mar  6 15:00:53 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 6 Mar 2005 14:00:53 +0000 (UTC)
Subject: [R] I modified my question in "search and convert string function
	"
References: <BAY1-F27B273D958F8BA68DB2E91E75E0@phx.gbl>
Message-ID: <loom.20050306T145747-334@post.gmane.org>

peng shen <michael_shen <at> hotmail.com> writes:

: 
: Hi ,all R-helper!
: I modified my  question  in "search and convert string function".
: I want to do this kind of operation In R enviroment :
: For example :
: R <- 4
: testString <- "I love %R%"
: then search this testString, when find beginning and end symbol"%",get a new 
: substring "%R%".
: then get rid of symbole"%",replace string"R" by R(numeric )
: So the final string is "I love 4"
: 
: How can I implement? if there is not this kind of function ,how can I write 
: function in C and implement in R.
: Thanks advance
: 

The function in my response to your original post can already do that:

R> interp("I love %R%", pre = "%", post = "%")
[1] "I love 4"



From renaud.lancelot at cirad.fr  Sun Mar  6 18:23:59 2005
From: renaud.lancelot at cirad.fr (Renaud Lancelot)
Date: Sun, 06 Mar 2005 20:23:59 +0300
Subject: [R] error when when making package tcltk from source (R.0.1)
Message-ID: <422B3CAF.4000908@cirad.fr>

Dear R-Helpers,

I am working with Windows XP.
I am trying to build R 2.0.1 from source (R-2.0.1.tar.gz downloaded from 
CRAN).
I read the R Installation and Administration manual and the 
README.packages file as well (probably tot carefully enough !).

I installed the recommended tools and software including TCL/TK software 
(from archive ActiveTcl8.4.9.0.121397-win32-ix86.exe). I modified the 
PATH system variable and created new user variables:

TCLTK_CPPFLAGS=C:\tcl\include
TCLTK_LIBS=C:\tcl\lib

I meet the following error when building R:

CD C:\R-2.0.1\src\gnuwin32
make all bitmapdll recommended vignettes

[snip]

---------- Making package tcltk ------------
   adding build stamp to DESCRIPTION
   installing NAMESPACE file and metadata
   running src/Makefile.win ...
gcc  -IC:/R-2.0.1/include -Wall -O2 -I "C:/R-2.0.1/Tcl"/include -DWin32 
  -c init.c -o init.o
tcltk.h:3:17 tcl.h: No such file or directory
tcltk.h:4:16 tk.h: No such file or directory
make[5]: *** [init.o] Error 1
make[4]: *** [srcDynlib] Error 2
make[3]: *** [all] Error 2
make[2]: *** [pkg-tcltk] Error 2
make[1]: *** [rpackage] Error 1
make: *** [all] Error 2

I checked in the Tcl installation and tcl.h and tk.h are actually in the 
tcl\include directory.

What did I do wrong, and how to fix it ?

Thanks and best regards,

Renaud

-- 
Dr Renaud Lancelot, v?t?rinaire
C/0 Ambassade de France - SCAC
BP 834 Antananarivo 101 - Madagascar

e-mail: renaud.lancelot at cirad.fr
tel.:   +261 32 40 165 53 (cell)
         +261 20 22 665 36 ext. 225 (work)
         +261 20 22 494 37 (home)



From murdoch at stats.uwo.ca  Sun Mar  6 18:48:12 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 06 Mar 2005 17:48:12 +0000
Subject: [R] error when when making package tcltk from source (R.0.1)
In-Reply-To: <422B3CAF.4000908@cirad.fr>
References: <422B3CAF.4000908@cirad.fr>
Message-ID: <l4gm21ha516ea4047d8fpjh34dchb3alo8@4ax.com>

On Sun, 06 Mar 2005 20:23:59 +0300, Renaud Lancelot
<renaud.lancelot at cirad.fr> wrote :

>Dear R-Helpers,
>
>I am working with Windows XP.
>I am trying to build R 2.0.1 from source (R-2.0.1.tar.gz downloaded from 
>CRAN).
>I read the R Installation and Administration manual and the 
>README.packages file as well (probably tot carefully enough !).
>
>I installed the recommended tools and software including TCL/TK software 
>(from archive ActiveTcl8.4.9.0.121397-win32-ix86.exe). I modified the 
>PATH system variable and created new user variables:
>
>TCLTK_CPPFLAGS=C:\tcl\include
>TCLTK_LIBS=C:\tcl\lib

I think these are the problem.  In Windows you should only need to
edit the MkRules file to change these lines:

# Where does Tcl/Tk live? Spaces allowed.
TCL_HOME = $(RHOME)/Tcl
TCL_VERSION = 84

The section I think you were reading where you found TCLTK_CPPFLAGS
was specific to using the configure utility in Unix.

Duncan Murdoch



From soumyadeep_nandi at yahoo.com  Sun Mar  6 18:56:08 2005
From: soumyadeep_nandi at yahoo.com (Soumyadeep nandi)
Date: Sun, 6 Mar 2005 09:56:08 -0800 (PST)
Subject: [R] Need suggestions for plotting 3D plot
In-Reply-To: 6667
Message-ID: <20050306175609.329.qmail@web52207.mail.yahoo.com>

Thanks Witold and Thomas,

I could make 3D plots of my data. thanks for your kind
suggestions.

With best of my regards,
Soumyadeep

--- Witold Eryk Wolski <W.E.Wolski at ncl.ac.uk> wrote:
> Hi,
> 
>
http://www.stat.ucl.ac.be/ISpersonnel/lecoutre/stats/fichiers/_gallery.pdf
> 
> The document above starts showing 3 different types
> of  3D graphics
> 
> persp
> 
> scatterplot3d
> 
> wireframe
> 
> 
> 
> 
> A few days ago there was a discussion here on the
> list about providing a 
> "graph library".
> During this discussion several resources of example
> code where mentioned 
> ( inter-alia that above).
> So if you need more ideas follow search this
> e-mails.
> 
> cheers
> 
> Eryk
> 
> 
> 
> Soumyadeep nandi wrote:
> 
> >Hi Everybody,
> >I am a newbie in R. I have a data in the form of a
> >matrix which I want to make some 3D plots using R.
> >There is some functions for instance hist() for 2D
> >plots, but I cant find any function for 3D plots.
> Is
> >there any function available in R for 3D plots? If
> so,
> >is there any documention available on internet so
> that
> >I can go through. 
> >With regards,
> >Soumyadeep
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
> >
> >  
> >
> 
> 
> -- 
> Witold Eryk Wolski
> __("<  School of Mathematics and Statistics     _
> \__/   University of Newcastle                 'v'
>  ||    Newcastle upon Tyne, NE1 7RU, ENGLAND  /   \
>  ^^    mail: witek96 at users.sourceforge.net     m m
>        Phone : 044 (0)191 222 5376
>        FAX   : 044 (0)191 222 8020
> 
>



From my_perl_stuff at yahoo.co.uk  Sun Mar  6 19:29:11 2005
From: my_perl_stuff at yahoo.co.uk (Scott Patterson)
Date: Sun, 6 Mar 2005 18:29:11 +0000 (GMT)
Subject: [R] Communication with R and mod perl
Message-ID: <20050306182911.68239.qmail@web26603.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050306/86cea84d/attachment.pl

From ripley at stats.ox.ac.uk  Sun Mar  6 20:10:46 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 6 Mar 2005 19:10:46 +0000 (GMT)
Subject: [R] error when when making package tcltk from source (R.0.1)
In-Reply-To: <422B3CAF.4000908@cirad.fr>
References: <422B3CAF.4000908@cirad.fr>
Message-ID: <Pine.LNX.4.61.0503061908300.24579@gannet.stats>

On Sun, 6 Mar 2005, Renaud Lancelot wrote:

> Dear R-Helpers,
>
> I am working with Windows XP.
> I am trying to build R 2.0.1 from source (R-2.0.1.tar.gz downloaded from 
> CRAN).
> I read the R Installation and Administration manual and the README.packages 
> file as well (probably tot carefully enough !).
>
> I installed the recommended tools and software including TCL/TK software 
> (from archive ActiveTcl8.4.9.0.121397-win32-ix86.exe).

That is not the recommendation in src/gnuwin32/INSTALL (the file you seem 
to have missed).

>  I modified the PATH 
> system variable and created new user variables:
>
> TCLTK_CPPFLAGS=C:\tcl\include
> TCLTK_LIBS=C:\tcl\lib
>
> I meet the following error when building R:
>
> CD C:\R-2.0.1\src\gnuwin32
> make all bitmapdll recommended vignettes
>
> [snip]
>
> ---------- Making package tcltk ------------
>  adding build stamp to DESCRIPTION
>  installing NAMESPACE file and metadata
>  running src/Makefile.win ...
> gcc  -IC:/R-2.0.1/include -Wall -O2 -I "C:/R-2.0.1/Tcl"/include -DWin32  -c
                                          ^^^^^^^^^^^^^^^^
NB.  You need to set the path in MkRules.

> init.c -o init.o
> tcltk.h:3:17 tcl.h: No such file or directory
> tcltk.h:4:16 tk.h: No such file or directory
> make[5]: *** [init.o] Error 1
> make[4]: *** [srcDynlib] Error 2
> make[3]: *** [all] Error 2
> make[2]: *** [pkg-tcltk] Error 2
> make[1]: *** [rpackage] Error 1
> make: *** [all] Error 2
>
> I checked in the Tcl installation and tcl.h and tk.h are actually in the 
> tcl\include directory.
>
> What did I do wrong, and how to fix it ?
>
> Thanks and best regards,
>
> Renaud
>
> -- 
> Dr Renaud Lancelot, v?t?rinaire
> C/0 Ambassade de France - SCAC
> BP 834 Antananarivo 101 - Madagascar
>
> e-mail: renaud.lancelot at cirad.fr
> tel.:   +261 32 40 165 53 (cell)
>        +261 20 22 665 36 ext. 225 (work)
>        +261 20 22 494 37 (home)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From renaud.lancelot at cirad.fr  Sun Mar  6 20:31:39 2005
From: renaud.lancelot at cirad.fr (Renaud Lancelot)
Date: Sun, 06 Mar 2005 22:31:39 +0300
Subject: [R] error when when making package tcltk from source (R.0.1)
In-Reply-To: <l4gm21ha516ea4047d8fpjh34dchb3alo8@4ax.com>
References: <422B3CAF.4000908@cirad.fr>
	<l4gm21ha516ea4047d8fpjh34dchb3alo8@4ax.com>
Message-ID: <422B5A9B.4000004@cirad.fr>

Duncan Murdoch a ?crit :
> On Sun, 06 Mar 2005 20:23:59 +0300, Renaud Lancelot
> <renaud.lancelot at cirad.fr> wrote :
> 
> 
>>Dear R-Helpers,
>>
>>I am working with Windows XP.
>>I am trying to build R 2.0.1 from source (R-2.0.1.tar.gz downloaded from 
>>CRAN).
>>I read the R Installation and Administration manual and the 
>>README.packages file as well (probably tot carefully enough !).
>>
>>I installed the recommended tools and software including TCL/TK software 
>>(from archive ActiveTcl8.4.9.0.121397-win32-ix86.exe). I modified the 
>>PATH system variable and created new user variables:
>>
>>TCLTK_CPPFLAGS=C:\tcl\include
>>TCLTK_LIBS=C:\tcl\lib
> 
> 
> I think these are the problem.  In Windows you should only need to
> edit the MkRules file to change these lines:
> 
> # Where does Tcl/Tk live? Spaces allowed.
> TCL_HOME = $(RHOME)/Tcl
> TCL_VERSION = 84
> 
> The section I think you were reading where you found TCLTK_CPPFLAGS
> was specific to using the configure utility in Unix.

Yes, you are right in both issues. Thank you very much for your help. I 
am now able to build R.

Best,

Renaud

-- 
Dr Renaud Lancelot, v?t?rinaire
C/0 Ambassade de France - SCAC
BP 834 Antananarivo 101 - Madagascar

e-mail: renaud.lancelot at cirad.fr
tel.:   +261 32 40 165 53 (cell)
         +261 20 22 665 36 ext. 225 (work)
         +261 20 22 494 37 (home)



From renaud.lancelot at cirad.fr  Sun Mar  6 20:44:21 2005
From: renaud.lancelot at cirad.fr (Renaud Lancelot)
Date: Sun, 06 Mar 2005 22:44:21 +0300
Subject: [R] error when when making package tcltk from source (R.0.1)
In-Reply-To: <Pine.LNX.4.61.0503061908300.24579@gannet.stats>
References: <422B3CAF.4000908@cirad.fr>
	<Pine.LNX.4.61.0503061908300.24579@gannet.stats>
Message-ID: <422B5D95.1080507@cirad.fr>

Prof Brian Ripley a ?crit :

> On Sun, 6 Mar 2005, Renaud Lancelot wrote:
> 
>> Dear R-Helpers,
>>
>> I am working with Windows XP.
>> I am trying to build R 2.0.1 from source (R-2.0.1.tar.gz downloaded 
>> from CRAN).
>> I read the R Installation and Administration manual and the 
>> README.packages file as well (probably tot carefully enough !).
>>
>> I installed the recommended tools and software including TCL/TK 
>> software (from archive ActiveTcl8.4.9.0.121397-win32-ix86.exe).
> 
> 
> That is not the recommendation in src/gnuwin32/INSTALL (the file you 
> seem to have missed).

Thank you for pointing my mistake.

>>  I modified the PATH system variable and created new user variables:
>>
>> TCLTK_CPPFLAGS=C:\tcl\include
>> TCLTK_LIBS=C:\tcl\lib
>>
>> I meet the following error when building R:
>>
>> CD C:\R-2.0.1\src\gnuwin32
>> make all bitmapdll recommended vignettes
>>
>> [snip]
>>
>> ---------- Making package tcltk ------------
>>  adding build stamp to DESCRIPTION
>>  installing NAMESPACE file and metadata
>>  running src/Makefile.win ...
>> gcc  -IC:/R-2.0.1/include -Wall -O2 -I "C:/R-2.0.1/Tcl"/include 
>> -DWin32  -c
> 
>                                          ^^^^^^^^^^^^^^^^
> NB.  You need to set the path in MkRules.

Thank you. It works now.

Best regards,

Renaud

-- 
Dr Renaud Lancelot, v?t?rinaire
C/0 Ambassade de France - SCAC
BP 834 Antananarivo 101 - Madagascar

e-mail: renaud.lancelot at cirad.fr
tel.:   +261 32 40 165 53 (cell)
         +261 20 22 665 36 ext. 225 (work)
         +261 20 22 494 37 (home)



From 2ryang at rogers.com  Mon Mar  7 10:54:09 2005
From: 2ryang at rogers.com (Ryan Glover)
Date: Mon, 7 Mar 2005 01:54:09 -0800
Subject: [R] information on maximum likelihood
Message-ID: <JFEOJFDBIGBIFOGNDAKMKEELCBAA.2ryang@rogers.com>

Hello,

I have a time series that contains 40 years of daily average temperature.  I
am attempting to create a time series model for the temperature based on a
number of papers that do the same.  I have an expression that describes the
temperature behavior over time but it contains 7 unknown parameters.  The
authors of the aforementioned papers state that they calculate the
parameters using MLE but they do not discuss the topic further.  A few days
ago I was unaware of what MLE was.  Now I know what it is, as well as
someone can know in 72 hours, but I do not know how to perform the work to
determine my own parameter values.  I have read a number of help pages for R
that relate to MLE but I admit to still being in the dark.  Many examples
discuss Poisson distributions and normal distributions but I don't think
these apply to me since I already have my own expression for the time series
data.  Could someone please instruct me how to process my data set and my
function in R with MLE so that it outputs values for my unknown parameters?

Many thanks,

Ryan Glover



From gsxej2 at cam.ac.uk  Mon Mar  7 09:44:08 2005
From: gsxej2 at cam.ac.uk (Gregory Jefferis)
Date: Mon, 07 Mar 2005 08:44:08 +0000
Subject: [R] Reverse plot axes with xlim=rev(range(x)) fails with asp=1
In-Reply-To: <Pine.LNX.4.44.0503052003510.30319-100000@reclus.nhh.no>
Message-ID: <BE51C4D8.4C3E%gsxej2@cam.ac.uk>

Dear Roger,

Thank you for your suggestion and explanation, that was v. helpful.  I also
found the axTicks() command to help generate the normal sequences for tick
marks and labels used in your 'kludge' eg:

>plot(y=-y,x=x, ylim=range(-y), asp=1, axes=FALSE)
>box()
>axis(1) 
axis(2, at=axTicks(2), label=axTicks(2)*-1)

Many thanks,

Greg.


On 5/3/05 7:19 pm, "Roger Bivand" <Roger.Bivand at nhh.no> wrote:

> On Sat, 5 Mar 2005, Gregory Jefferis wrote:
> 
>> Dear R users,
>> 
>> I would like to reverse the axes on some xy plots (for example to set the
>> origin at the top left rather than the bottom left).  I had planned to use
>> something of the following form:
>> 
>> plot(y=y<-c(20,4,5,6),x=x<-c(10,20,30,40),ylim=rev(range(y)))
>> 
>> ie reversing ylim to reverse the y axis.  This works fine however I also
>> want to use the parameter asp=1 to ensure that equal distances in the x or y
>> direction are plotted as such on the screen.  However the simple example I
>> showed above now fails:
>> 
>>> plot(y=y<-c(20,4,5,6),x=x<-c(10,20,30,40),ylim=rev(range(y)),asp=1)
>> 
>> The actual ylim used is considerably less than it should be, so no points
>> appear on the plot.
>> 
>> Can anyone suggest a simple remedy?
> 
>> plot(y=-y,x=x, ylim=range(-y), asp=1, axes=FALSE)
>> box()
>> axis(1)
>> axis(2, at=seq(-20,-5,5), label=seq(20,5,-5))
> 
> is a simple kludge, the explanation is touched on in a comment in
> src/main/plot.c, after line 564:
> 
>  * The use of asp can have weird effects when axis is an
>  * interpreted function.  It has to be internal so that the
>  * full computation is captured in the display list.
> 
> and may be related to the sign of ydelta being dropped in line 652 (for
> the y axis) and Gscale() being possibly called in line 666 with incorrect
> assumptions about whether to add or subtract the correction factor -
> untried!
> 
>> 
>> Many thanks,
>> 
>> Greg Jefferis.
>> 
>> PS I would guess that the origin of this behaviour is that plot.window
>> expects xlim (and ylim) to be in the order xmin,xmax (or ymin,ymax) when it
>> sets about redefining xlim and ylim if asp!=NA.  If that suggestion is
>> correct, I'm not quite sure why the restriction is necessary.
>> 
>> 

-- 
Gregory Jefferis, PhD                               and:
Research Fellow
Department of Zoology                               St John's College
Downing Street                                      Cambridge
Cambridge, CB2 3EJ                                  CB2 1TP

Tel: +44 (0)1223 336683                             +44 (0)1223 339899
Fax: +44 (0)1223 336676                             +44 (0)1223 337720

gsxej2 at cam.ac.uk



From xpsun at ict.ac.cn  Mon Mar  7 10:14:02 2005
From: xpsun at ict.ac.cn (XP Sun)
Date: Mon, 7 Mar 2005 17:14:02 +0800
Subject: [R] cl$cluster of kmeans 
Message-ID: <200503070914.j279E70P001885@hypatia.math.ethz.ch>

hi, all,

	i had a problem when i used kmeans as follow:

	> pp <- scan("m0028.data", quiet= TRUE)
	> x <- matrix(pp, nc=3, byrow=TRUE)
	> cl<-kmeans(x, 4, 20)
	> plot(x, col=cl$cluster)
	> save(cl$cluster, file="m0028.ks", ascii=TRUE)
		Error in save(cl$cluster, file = "m0028.ks", ascii = TRUE) : 
  	      Object "cl$cluster" not found

	when i wanted to save the vector of cluster only, a reflection was  thrown out as that. 

	could i save cl$cluster only? how?
	thank you in advance.

best,
xp sun



From ligges at statistik.uni-dortmund.de  Mon Mar  7 10:24:11 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 07 Mar 2005 10:24:11 +0100
Subject: [R] cl$cluster of kmeans
In-Reply-To: <200503070914.j279E70P001885@hypatia.math.ethz.ch>
References: <200503070914.j279E70P001885@hypatia.math.ethz.ch>
Message-ID: <422C1DBB.5050806@statistik.uni-dortmund.de>

XP Sun wrote:

> hi, all,
> 
> 	i had a problem when i used kmeans as follow:
> 
> 	> pp <- scan("m0028.data", quiet= TRUE)
> 	> x <- matrix(pp, nc=3, byrow=TRUE)
> 	> cl<-kmeans(x, 4, 20)
> 	> plot(x, col=cl$cluster)
> 	> save(cl$cluster, file="m0028.ks", ascii=TRUE)
> 		Error in save(cl$cluster, file = "m0028.ks", ascii = TRUE) : 
>   	      Object "cl$cluster" not found
> 
> 	when i wanted to save the vector of cluster only, a reflection was  thrown out as that. 
> 
> 	could i save cl$cluster only? how?
> 	thank you in advance.


clc <- cl$cluster
save(clc, .....)

Uwe Ligges



> best,
> xp sun
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Mon Mar  7 10:30:26 2005
From: ripley at stats.ox.ac.uk (Brian D Ripley)
Date: Mon, 7 Mar 2005 09:30:26 +0000 (GMT)
Subject: [R] save (was cl$cluster of kmeans)
In-Reply-To: <200503070914.j279E70P001885@hypatia.math.ethz.ch>
Message-ID: <Pine.GSO.4.31.0503070927540.23322-100000@markov.stats>

On Mon, 7 Mar 2005, XP Sun wrote:

> hi, all,
>
> 	i had a problem when i used kmeans as follow:

No, when you used save()!

> 	> pp <- scan("m0028.data", quiet= TRUE)
> 	> x <- matrix(pp, nc=3, byrow=TRUE)
> 	> cl<-kmeans(x, 4, 20)
> 	> plot(x, col=cl$cluster)
> 	> save(cl$cluster, file="m0028.ks", ascii=TRUE)
> 		Error in save(cl$cluster, file = "m0028.ks", ascii = TRUE) :
>   	      Object "cl$cluster" not found
>
> 	when i wanted to save the vector of cluster only, a reflection
>       was thrown out as that.
>
> 	could i save cl$cluster only? how?
> 	thank you in advance.

You can only save() named objects, not a single element, as its help page
says.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From SAULEAUEA at ch-mulhouse.fr  Sat Mar  5 11:09:34 2005
From: SAULEAUEA at ch-mulhouse.fr (=?iso-8859-1?Q?SAULEAU_Erik-Andr=E9?=)
Date: Sat, 5 Mar 2005 11:09:34 +0100
Subject: [R] Object containing different classes
Message-ID: <A91EF0B9121F834EA6484582DFE1CF4436F701@messagerie.chm.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050305/2bc47417/attachment.pl

From ligges at statistik.uni-dortmund.de  Mon Mar  7 11:36:12 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 07 Mar 2005 11:36:12 +0100
Subject: [R] Object containing different classes
In-Reply-To: <A91EF0B9121F834EA6484582DFE1CF4436F701@messagerie.chm.com>
References: <A91EF0B9121F834EA6484582DFE1CF4436F701@messagerie.chm.com>
Message-ID: <422C2E9C.4050804@statistik.uni-dortmund.de>

SAULEAU Erik-Andr? wrote:

> Hi,
> 
> i want to create an object which contains different classes: for example i
> have some time series and test if ARIMA models are best than HoltWinters
> models: for each of my time serie i want to collect in an unique object
> which model was the best: for some it will be an HoltWinters class and for
> some other an Arima class.
> 
> is there any solution?? thanks in advance, with my best, erik sauleau

?list

Uwe Ligges


> ===========================
> SAULEAU Erik-andr?
> Haut Rhin Cancer Registry
> F-Mulhouse
> www.arer68.org
> ===========================
> 
> 
> **********************************************************************************
> Afin d'eviter toute propagation de virus informatique, et en complement 
> des dispositifs en place, ce message (et ses pieces jointes s'il y en a) 
> a ete automatiquement analyse par un antivirus de messagerie. 
> **********************************************************************************
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From xpsun at ict.ac.cn  Mon Mar  7 13:27:32 2005
From: xpsun at ict.ac.cn (XP Sun)
Date: Mon, 7 Mar 2005 20:27:32 +0800
Subject: [R] show time?
Message-ID: <200503071227.j27CRYQ0005392@hypatia.math.ethz.ch>

hi, all,

	how to show time? what is the command?

	thank you in advance!

best, 
xp sun



From ccleland at optonline.net  Mon Mar  7 13:33:52 2005
From: ccleland at optonline.net (Chuck Cleland)
Date: Mon, 07 Mar 2005 07:33:52 -0500
Subject: [R] show time?
In-Reply-To: <200503071227.j27CRYQ0005392@hypatia.math.ethz.ch>
References: <200503071227.j27CRYQ0005392@hypatia.math.ethz.ch>
Message-ID: <422C4A30.1010803@optonline.net>

?Sys.time()

> Sys.time()
[1] "2005-03-07 07:32:57 Eastern Standard Time"

XP Sun wrote:
> hi, all,
> 
> 	how to show time? what is the command?
> 
> 	thank you in advance!

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From jonathan.charrier at bordeaux.inra.fr  Mon Mar  7 15:10:05 2005
From: jonathan.charrier at bordeaux.inra.fr (Jonathan Charrier)
Date: Mon, 07 Mar 2005 15:10:05 +0100
Subject: [R] simple problem
Message-ID: <422C60BD.7020705@bordeaux.inra.fr>

Hello,

I have a little problem, very simple, but i can't solve it.

I have a list of files
I have a function

I want that the function take files one to one
(the results is a matrix (1 file (the values) for 1 column))

I used some functions (like apply, lapply and more)

but in each case,
i have a warning message : "only first element of `description' argument 
used "
it takes only the first file...

if someone have an idea

Thanks  a lot


Jonathan Charrier



From ggrothendieck at myway.com  Mon Mar  7 15:10:38 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 7 Mar 2005 14:10:38 +0000 (UTC)
Subject: [R] information on maximum likelihood
References: <JFEOJFDBIGBIFOGNDAKMKEELCBAA.2ryang@rogers.com>
Message-ID: <loom.20050307T150556-562@post.gmane.org>

Ryan Glover <2ryang <at> rogers.com> writes:

: 
: Hello,
: 
: I have a time series that contains 40 years of daily average temperature.  I
: am attempting to create a time series model for the temperature based on a
: number of papers that do the same.  I have an expression that describes the
: temperature behavior over time but it contains 7 unknown parameters.  The
: authors of the aforementioned papers state that they calculate the
: parameters using MLE but they do not discuss the topic further.  A few days
: ago I was unaware of what MLE was.  Now I know what it is, as well as
: someone can know in 72 hours, but I do not know how to perform the work to
: determine my own parameter values.  I have read a number of help pages for R
: that relate to MLE but I admit to still being in the dark.  Many examples
: discuss Poisson distributions and normal distributions but I don't think
: these apply to me since I already have my own expression for the time series
: data.  Could someone please instruct me how to process my data set and my
: function in R with MLE so that it outputs values for my unknown parameters?


I assume from your post that you have the probability density, f(x,p),
of your data as a function of your 40 year data vector x and your vector
of 7 unknown parameters p.  Define 

	negloglik <- function(p) -log(f(x,p))

and run:

	nlm(negloglik, p0)

where p0 is a vector of starting values for p.   See ?nlm .
?optim is an alternate possibility.  If you have difficulties
in getting convergence try different starting values, try
using -f(x,p) instead of -log(f(x,p)), check out ?optim or try
reparameterizing. Also you might check if your model fits into 
some category that R already knows about using the search 
facilities explained in the posting guide at the bottom.

Also, you might want to do repeated optimizations using many different
starting values in case the likelihood has multiple local maxima.



From ligges at statistik.uni-dortmund.de  Mon Mar  7 15:20:06 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 07 Mar 2005 15:20:06 +0100
Subject: [R] simple problem
In-Reply-To: <422C60BD.7020705@bordeaux.inra.fr>
References: <422C60BD.7020705@bordeaux.inra.fr>
Message-ID: <422C6316.6050403@statistik.uni-dortmund.de>

Jonathan Charrier wrote:

> Hello,
> 
> I have a little problem, very simple, but i can't solve it.
> 
> I have a list of files
> I have a function
> 
> I want that the function take files one to one
> (the results is a matrix (1 file (the values) for 1 column))
> 
> I used some functions (like apply, lapply and more)

sapply on a *vector* of filenames should work, as frequently discussed 
on this list.

Uwe Ligges



> but in each case,
> i have a warning message : "only first element of `description' argument 
> used "
> it takes only the first file...
> 
> if someone have an idea
> 
> Thanks  a lot
> 
> 
> Jonathan Charrier
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From roger.bos at gmail.com  Mon Mar  7 16:16:50 2005
From: roger.bos at gmail.com (roger bos)
Date: Mon, 7 Mar 2005 10:16:50 -0500
Subject: [R] simple if...else causes syntax error
Message-ID: <1db7268005030707166b93ff6c@mail.gmail.com>

I am trying to do the simplest thing in the world.  The following works:

aaa <- ifelse(aaa==5, 6, 7)            
            
But if I want to change the if...else syntax instead, it gives errors
and assigns 7 to aaa.  Here is the problem code:

aaa <- 5
if ( aaa==5 ) { 
   aaa <- 6
}
else {
   aaa <- 7
}
            
Here is the output:

> aaa <- 5
>             if ( aaa==5 ) { 
+             aaa <- 6
+   }
>             else {
Error: syntax error
> aaa <- 7
> }
Error: syntax error
>             

Hope someone can solve this easy question for me.

BTW, how come "?if" does not pull up the help file for the 'if' statement?

Thanks,

Roger



From dimitris.rizopoulos at med.kuleuven.ac.be  Mon Mar  7 16:29:27 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Mon, 7 Mar 2005 16:29:27 +0100
Subject: [R] simple if...else causes syntax error
References: <1db7268005030707166b93ff6c@mail.gmail.com>
Message-ID: <005601c5232a$72bc2a60$0540210a@www.domain>

from the help page of ?"if" (not "?if") you get:

Note that it is a common mistake to forget to put braces `({..})' 
around your statements, e.g., after `if(..)' or `for(...)'. In 
particular, you should not have a newline between `}' and `else' to 
avoid a syntax error ...

So you should use:

aaa <- 5
if ( aaa==5 ) {
   aaa <- 6
} else {
   aaa <- 7
}


Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "roger bos" <roger.bos at gmail.com>
To: <R-help at stat.math.ethz.ch>
Sent: Monday, March 07, 2005 4:16 PM
Subject: [R] simple if...else causes syntax error


>I am trying to do the simplest thing in the world.  The following 
>works:
>
> aaa <- ifelse(aaa==5, 6, 7)
>
> But if I want to change the if...else syntax instead, it gives 
> errors
> and assigns 7 to aaa.  Here is the problem code:
>
> aaa <- 5
> if ( aaa==5 ) {
>   aaa <- 6
> }
> else {
>   aaa <- 7
> }
>
> Here is the output:
>
>> aaa <- 5
>>             if ( aaa==5 ) {
> +             aaa <- 6
> +   }
>>             else {
> Error: syntax error
>> aaa <- 7
>> }
> Error: syntax error
>>
>
> Hope someone can solve this easy question for me.
>
> BTW, how come "?if" does not pull up the help file for the 'if' 
> statement?
>
> Thanks,
>
> Roger
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From cperoni at racine.ra.it  Mon Mar  7 16:28:54 2005
From: cperoni at racine.ra.it (cperoni@racine.ra.it)
Date: Mon,  7 Mar 2005 16:28:54 +0100
Subject: [R] plot gam object 
Message-ID: <1110209334.422c7336f1c60@www.racine.ra.it>

Dear R help,

I am fitting a gam model with package GAM ( I use lo() to fit 2 non-parametric 
additive components).

When I plot the GAM object, along with the graphics window displaying plots of 
each components, I read the following warnings at the prompt: 
3: the condition has length 1 and only the first element will be used in: if 
(scale2 < scale) rep(mean(ylim), 2) + ((ylim - mean(ylim)) *  
4: number of items to replace is not a multiple of replacement length .

I am changing the scale parameter but I still get the same warnings. 

I have no idea of the meaning of the warnings, I would be grateful if you could 
help.

Is it possible to find a C code of th ebackfitting algorithm?

Many thanks,

Chiara

-----------------------

Chiara Peroni
University of York & Bologna



From ligges at statistik.uni-dortmund.de  Mon Mar  7 16:29:14 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 07 Mar 2005 16:29:14 +0100
Subject: [R] simple if...else causes syntax error
In-Reply-To: <1db7268005030707166b93ff6c@mail.gmail.com>
References: <1db7268005030707166b93ff6c@mail.gmail.com>
Message-ID: <422C734A.9030701@statistik.uni-dortmund.de>

roger bos wrote:

> I am trying to do the simplest thing in the world.  The following works:
> 
> aaa <- ifelse(aaa==5, 6, 7)            
>             
> But if I want to change the if...else syntax instead, it gives errors
> and assigns 7 to aaa.  Here is the problem code:
> 
> aaa <- 5
> if ( aaa==5 ) { 
>    aaa <- 6
> }
> else {
>    aaa <- 7
> }
>             
> Here is the output:
> 
> 
>>aaa <- 5
>>            if ( aaa==5 ) { 
> 
> +             aaa <- 6
> +   }
> 
>>            else {
> 
> Error: syntax error
> 
>>aaa <- 7
>>}
> 
> Error: syntax error
> 
>>            
> 
> 
> Hope someone can solve this easy question for me.
> 
> BTW, how come "?if" does not pull up the help file for the 'if' statement?

Parser, try ?"if"


And in ?"if" read the Details section, which tells you:

"[...] In particular, you should not have a newline between } and else 
to avoid a syntax error [...]".


The point is that
    if(A)
        B
is already syntactically complete (else can be omitted), so what the 
parser does not know what follows and has to evaluate ...


Uwe Ligges





> Thanks,
> 
> Roger
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From secchi at sssup.it  Mon Mar  7 17:39:44 2005
From: secchi at sssup.it (Angelo Secchi)
Date: Mon, 7 Mar 2005 16:39:44 +0000
Subject: [R] ismev package
Message-ID: <20050307163944.03fb2e2d.secchi@sssup.it>


Hi,
I'm exploring the ismev package and in particular the pp.fit function.
Documentation says that this function performs Maximum-likelihood
fitting for the point process model, including generalized linear
modelling of each parameter.
Actually I'm afraid not to understand what it means with "Point process
model". Any suggestion on possible references for further infos?
thanks
Angelo



From andy_liaw at merck.com  Mon Mar  7 16:44:44 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 7 Mar 2005 10:44:44 -0500
Subject: [R] plot gam object
Message-ID: <3A822319EB35174CA3714066D590DCD50994E7F2@usrymx25.merck.com>

The `scale' argument to plot.gam() needs to be a single number, not a
vector.  Is that what you've done?  You have not given enough detail, and we
are left to guess.  Please try to follow the posting guide.

All packages on CRAN are available in _source_ form.  (That's the way
packages are submitted to CRAN.)  Just download the .tar.gz version and
unpack that, then look in the src/ subdirectory for C/Fortran/C++ code.

Andy

> From: cperoni at racine.ra.it
> 
> Dear R help,
> 
> I am fitting a gam model with package GAM ( I use lo() to fit 
> 2 non-parametric 
> additive components).
> 
> When I plot the GAM object, along with the graphics window 
> displaying plots of 
> each components, I read the following warnings at the prompt: 
> 3: the condition has length 1 and only the first element will 
> be used in: if 
> (scale2 < scale) rep(mean(ylim), 2) + ((ylim - mean(ylim)) *  
> 4: number of items to replace is not a multiple of 
> replacement length .
> 
> I am changing the scale parameter but I still get the same warnings. 
> 
> I have no idea of the meaning of the warnings, I would be 
> grateful if you could 
> help.
> 
> Is it possible to find a C code of th ebackfitting algorithm?
> 
> Many thanks,
> 
> Chiara
> 
> -----------------------
> 
> Chiara Peroni
> University of York & Bologna
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From jtk at cmp.uea.ac.uk  Mon Mar  7 17:46:49 2005
From: jtk at cmp.uea.ac.uk (Jan T. Kim)
Date: Mon, 7 Mar 2005 16:46:49 +0000
Subject: [R] simple if...else causes syntax error
In-Reply-To: <1db7268005030707166b93ff6c@mail.gmail.com>
References: <1db7268005030707166b93ff6c@mail.gmail.com>
Message-ID: <20050307164649.GD32158@jtkpc.cmp.uea.ac.uk>

On Mon, Mar 07, 2005 at 10:16:50AM -0500, roger bos wrote:
> I am trying to do the simplest thing in the world.  The following works:
> 
> aaa <- ifelse(aaa==5, 6, 7)            
>             
> But if I want to change the if...else syntax instead, it gives errors
> and assigns 7 to aaa.  Here is the problem code:
> 
> aaa <- 5
> if ( aaa==5 ) { 
>    aaa <- 6
> }
> else {
>    aaa <- 7
> }

This is due to R's (somewhat peculiar) semantics of newline, which R
interprets as a terminator if an expression can terminate at the position
of the newline, or else as a plain whitespace, see section on "Separators"
in the R Language Definition. In the construction

    if ( aaa==5 ) {
       aaa <- 6
    }

R decides that the final newline can be a terminator, namely of an if-
expression without an else branch. So, the if-expression is consumed
by the parser and "forgotten" for the purpose of associating the else
branch with it. The else branch thus appears to be astray and is reported
as a syntax error.

All this does not happen if the entire construct is enclosed in braces.
Alternatively, the "else" can be placed on one line with the brace closing
the if branch.

Out of personal interest: Does anyone here know why the R parser was
designed this way? Personally, I have been coding in R for years in the
belief that newline is whitespace, and never even noticed any problems
because all my ifs with elses were within functions and thus enclosed
in curly braces.

Best regards, Jan
-- 
 +- Jan T. Kim -------------------------------------------------------+
 |    *NEW*    email: jtk at cmp.uea.ac.uk                               |
 |    *NEW*    WWW:   http://www.cmp.uea.ac.uk/people/jtk             |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*



From daniel.k.kang at gmail.com  Mon Mar  7 16:53:05 2005
From: daniel.k.kang at gmail.com (Daniel Kang)
Date: Mon, 7 Mar 2005 10:53:05 -0500
Subject: [R] Need your help on R & BioC exploration
Message-ID: <13bd111205030707532b98d8cd@mail.gmail.com>

I have just finished a graduate introductory R & BioC class, and found
them very interesting.   At this moment, I am not doing any R & BioC
related-work, which might end up with "use it or lose it".   My plan
is to get into bioinformatics fields shortly after the completion of
master's degree in bioinformatics that I am studying.  Considering
being very new to R & BioC, I think there might be some projects,
group study, work, workshop, etc that I can participate and learn R &
BioC.

Please let me know if you know of anything helpful for my exploration.  

Thank you,

Daniel



From lamkelj at yahoo.com  Mon Mar  7 17:07:32 2005
From: lamkelj at yahoo.com (Kel Lam)
Date: Mon, 7 Mar 2005 08:07:32 -0800 (PST)
Subject: [R] gbm (Kelvin Lam)
Message-ID: <20050307160732.2680.qmail@web52710.mail.yahoo.com>

I have got some help from Greg during the course of my
boosting procedure.  I maybe able to help out.  What
exactly are you looking for?

Message: 46
Date: Fri, 4 Mar 2005 12:07:06 -0600
From: WeiWei Shi <helprhelp at gmail.com>
Subject: [R] gbm
To: R-help at stat.math.ethz.ch
Message-ID:
<cdf8178305030410074cae0bee at mail.gmail.com>
Content-Type: text/plain; charset=US-ASCII

Hi, there:
Is there anyone who read the codes for gbm package
before? Before i
sent this email, I also sent an email to ask for help
from the author,
Greg. But still I am wondering if someone here can
share some
understanding like the roadmap or document on the
"implementation"
too.

Thanks,

Ed.



From ggrothendieck at myway.com  Mon Mar  7 17:17:43 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 7 Mar 2005 16:17:43 +0000 (UTC)
Subject: [R] simple if...else causes syntax error
References: <1db7268005030707166b93ff6c@mail.gmail.com>
	<20050307164649.GD32158@jtkpc.cmp.uea.ac.uk>
Message-ID: <loom.20050307T171450-177@post.gmane.org>

Jan T. Kim <jtk <at> cmp.uea.ac.uk> writes:

: 
: On Mon, Mar 07, 2005 at 10:16:50AM -0500, roger bos wrote:
: > I am trying to do the simplest thing in the world.  The following works:
: > 
: > aaa <- ifelse(aaa==5, 6, 7)            
: >             
: > But if I want to change the if...else syntax instead, it gives errors
: > and assigns 7 to aaa.  Here is the problem code:
: > 
: > aaa <- 5
: > if ( aaa==5 ) { 
: >    aaa <- 6
: > }
: > else {
: >    aaa <- 7
: > }
: 
: This is due to R's (somewhat peculiar) semantics of newline, which R
: interprets as a terminator if an expression can terminate at the position
: of the newline, or else as a plain whitespace, see section on "Separators"
: in the R Language Definition. In the construction
: 
:     if ( aaa==5 ) {
:        aaa <- 6
:     }
: 
: R decides that the final newline can be a terminator, namely of an if-
: expression without an else branch. So, the if-expression is consumed
: by the parser and "forgotten" for the purpose of associating the else
: branch with it. The else branch thus appears to be astray and is reported
: as a syntax error.
: 
: All this does not happen if the entire construct is enclosed in braces.
: Alternatively, the "else" can be placed on one line with the brace closing
: the if branch.
: 
: Out of personal interest: Does anyone here know why the R parser was
: designed this way? Personally, I have been coding in R for years in the
: belief that newline is whitespace, and never even noticed any problems
: because all my ifs with elses were within functions and thus enclosed
: in curly braces.
: 

If it did not work that way it would require console lookahead.  That is 
it would not know that the if statement was finished and would have
to wait for the following statement to be completely typed in before
it could process the if.  The way it works now the if statement can
be processed immediately.



From c_joseph_lu at yahoo.com.tw  Mon Mar  7 17:31:07 2005
From: c_joseph_lu at yahoo.com.tw (Lu Joseph)
Date: Tue, 8 Mar 2005 00:31:07 +0800 (CST)
Subject: [R] How can we ring a bell in Windows?
Message-ID: <20050307163107.63099.qmail@web17110.mail.tpe.yahoo.com>

Hello useRs,

Is there a way to write code in R
to ring a bell in Windows?

Best regards,

C. Joseph Lu
Department of Statistics
National Cheng-Kung University
Tainan, Taiwan
ROC

_______________________________________________________________________




From tlumley at u.washington.edu  Mon Mar  7 17:36:50 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 7 Mar 2005 08:36:50 -0800 (PST)
Subject: [R] simple if...else causes syntax error
In-Reply-To: <1db7268005030707166b93ff6c@mail.gmail.com>
References: <1db7268005030707166b93ff6c@mail.gmail.com>
Message-ID: <Pine.A41.4.61b.0503070825440.250270@homer12.u.washington.edu>

On Mon, 7 Mar 2005, roger bos wrote:

> I am trying to do the simplest thing in the world.  The following works:
>
> aaa <- ifelse(aaa==5, 6, 7)
>
> But if I want to change the if...else syntax instead, it gives errors
> and assigns 7 to aaa.  Here is the problem code:

Other people have told you how to fix this.  I will point out in addition 
that if...else is not different syntax for ifelse() but a very different 
construct.

ifelse() is a function that operates on vectors and returns a vector that 
is always the same length as the first argument. It does not change the 
flow of execution: all three of the arguments are evaluated.

if(){} else {} chooses which branch of code to evaluate based on a single 
logical value.  The value returned by this expression could be of 
completely different length and type depending on which code was 
evaluated.


It might also be worth noting that the behaviour of newlines in 
terminating if() {} expressions is unavoidable in an interpreter using 
this syntax. When the user types

if(condition){
    some.code()
}

the interpreter cannot possibly tell whether an `else' clause is coming. 
Avoiding the problem would require a fairly significant change to the 
language, not just to the parser, eg adding an endif (the shell script 
solution), or requiring parentheses around the whole expression (the LISP 
solution, and in a sense the Python solution, though there the parentheses 
are invisible)



 	-thomas



From jerk_alert at hotmail.com  Mon Mar  7 17:37:02 2005
From: jerk_alert at hotmail.com (Ken Termiso)
Date: Mon, 07 Mar 2005 16:37:02 +0000
Subject: [R] Faster way of binding multiple rows of data than rbind?
Message-ID: <BAY101-F17BAD384690B07F80C4364E85F0@phx.gbl>

Hi all,

I have a vector that contains the row numbers of data taken from several 
filtering operations performed on a large data frame (20,000rows x 500cols).

In order to output this subset of data, I've been looping through the vector 
containing the row numbers (keepRows).

output <- data.frame(row.names = rownames(bigMatrix))

for(i in keepRows)
{
	output <- rbind(output, bigMatrix[i, ])
}


As you may guess, doing all of these rbinds takes a LOT of time, so I'm 
wondering if there's a workaround where I can maybe use an intermediate 
matrix-like object to store the loop output, and then coerce it back to a 
data frame after the loop is complete??

Thanks in advance,
Ken



From roger.bos at gmail.com  Mon Mar  7 17:49:10 2005
From: roger.bos at gmail.com (roger bos)
Date: Mon, 7 Mar 2005 11:49:10 -0500
Subject: [R] simple if...else causes syntax error
In-Reply-To: <Pine.A41.4.61b.0503070825440.250270@homer12.u.washington.edu>
References: <1db7268005030707166b93ff6c@mail.gmail.com>
	<Pine.A41.4.61b.0503070825440.250270@homer12.u.washington.edu>
Message-ID: <1db72680050307084928193ef9@mail.gmail.com>

Thanks to everyone who took the time to point out the simple error. 
You would not think I have been programming in R/S for over a year. 
Could it be that the code works when enclosed in a function?  I tested
my code and it worked previously, but I was running it line by line
and discovered my syntax error.

Thanks again.

Roger



On Mon, 7 Mar 2005 08:36:50 -0800 (PST), Thomas Lumley
<tlumley at u.washington.edu> wrote:
> On Mon, 7 Mar 2005, roger bos wrote:
> 
> > I am trying to do the simplest thing in the world.  The following works:
> >
> > aaa <- ifelse(aaa==5, 6, 7)
> >
> > But if I want to change the if...else syntax instead, it gives errors
> > and assigns 7 to aaa.  Here is the problem code:
> 
> Other people have told you how to fix this.  I will point out in addition
> that if...else is not different syntax for ifelse() but a very different
> construct.
> 
> ifelse() is a function that operates on vectors and returns a vector that
> is always the same length as the first argument. It does not change the
> flow of execution: all three of the arguments are evaluated.
> 
> if(){} else {} chooses which branch of code to evaluate based on a single
> logical value.  The value returned by this expression could be of
> completely different length and type depending on which code was
> evaluated.
> 
> It might also be worth noting that the behaviour of newlines in
> terminating if() {} expressions is unavoidable in an interpreter using
> this syntax. When the user types
> 
> if(condition){
>    some.code()
> }
> 
> the interpreter cannot possibly tell whether an `else' clause is coming.
> Avoiding the problem would require a fairly significant change to the
> language, not just to the parser, eg adding an endif (the shell script
> solution), or requiring parentheses around the whole expression (the LISP
> solution, and in a sense the Python solution, though there the parentheses
> are invisible)
> 
> 
>        -thomas
>



From Gregor.gawron at rmf.ch  Mon Mar  7 17:52:44 2005
From: Gregor.gawron at rmf.ch (Gregor.gawron@rmf.ch)
Date: Mon, 7 Mar 2005 17:52:44 +0100
Subject: [R] ismev package
Message-ID: <A3A7D687D463B240844F0718418B68BA4F68E4@michexmb01.maninvestments.ad.man.com>

Check the reference book and the homepage of the author:" An Introduction to Statistical Modeling of Extreme Values" by Stuart Coles
Springer Series in Statistics. ISBN 1-85233-459-2. Published: September, 2001. You will find explanation and examples Point process. Alternatively, you may also look at  http://www.math.ethz.ch/~mcneil and his publication list.
Gregor  


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Angelo Secchi
Sent: Montag, 7. M?rz 2005 17:40
To: R-help at stat.math.ethz.ch
Subject: [R] ismev package



Hi,
I'm exploring the ismev package and in particular the pp.fit function. Documentation says that this function performs Maximum-likelihood fitting for the point process model, including generalized linear modelling of each parameter. Actually I'm afraid not to understand what it means with "Point process model". Any suggestion on possible references for further infos? thanks Angelo

______________________________________________
R-help at stat.math.ethz.ch mailing list https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


Any information in this communication is confidential and ma...{{dropped}}



From ggrothendieck at myway.com  Mon Mar  7 17:44:03 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 7 Mar 2005 16:44:03 +0000 (UTC)
Subject: [R] How can we ring a bell in Windows?
References: <20050307163107.63099.qmail@web17110.mail.tpe.yahoo.com>
Message-ID: <loom.20050307T174141-729@post.gmane.org>

Lu Joseph <c_joseph_lu <at> yahoo.com.tw> writes:

: 
: Hello useRs,
: 
: Is there a way to write code in R
: to ring a bell in Windows?
: 

Here are two ways:

cat("\7")

system("sndrec32 /play /close c:/windows/media/ding.wav")

The second way uses Windows Sound Recorder to play the ding.wav file
on my XP system and which may or may exist in the same location on 
other versions of Windows.



From mvida at mitre.org  Mon Mar  7 18:02:12 2005
From: mvida at mitre.org (Melanie Vida)
Date: Mon, 07 Mar 2005 12:02:12 -0500
Subject: [R] Writing to a file
Message-ID: <422C8914.4040802@mitre.org>

Here is a simple question. Is there a quicker way to write to a file 
several rows of data at a time rather than one line at a time? How can 
the code below be optimized to write several rows at a time to a file 
rather than one line at a time. See my slow method of write.table below:

---------------------------
x<-1000
for( i in 1:385420)
    (
    if(Info[i,4] > x)
       write.table (cbind(Info[i,1], Info[i,4], file="/tmp/CT.dat", 
append=TRUE, row.names=FALSE, col.names=FALSE)

Thanks,

-Melanie



From murdoch at stats.uwo.ca  Mon Mar  7 18:11:09 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 07 Mar 2005 17:11:09 +0000
Subject: [R] How can we ring a bell in Windows?
In-Reply-To: <20050307163107.63099.qmail@web17110.mail.tpe.yahoo.com>
References: <20050307163107.63099.qmail@web17110.mail.tpe.yahoo.com>
Message-ID: <4e2p21947nh3ofuorh8uvrrl08or1h4cj2@4ax.com>

On Tue, 8 Mar 2005 00:31:07 +0800 (CST), Lu Joseph
<c_joseph_lu at yahoo.com.tw> wrote :

>Hello useRs,
>
>Is there a way to write code in R
>to ring a bell in Windows?

If you load the tcltk package, then

tkbell() 

will get you a bell on more platforms than just Windows.  If you don't
want to use tcltk, then you could call the Windows API function
MessageBeep from some C code, but I don't think we have a "bell" or
"beep" function in the standard R packages.

Duncan Murdoch



From bates at stat.wisc.edu  Mon Mar  7 18:28:26 2005
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 07 Mar 2005 11:28:26 -0600
Subject: [R] Faster way of binding multiple rows of data than rbind?
In-Reply-To: <BAY101-F17BAD384690B07F80C4364E85F0@phx.gbl>
References: <BAY101-F17BAD384690B07F80C4364E85F0@phx.gbl>
Message-ID: <422C8F3A.1070501@stat.wisc.edu>

Ken Termiso wrote:
> Hi all,
> 
> I have a vector that contains the row numbers of data taken from several 
> filtering operations performed on a large data frame (20,000rows x 
> 500cols).
> 
> In order to output this subset of data, I've been looping through the 
> vector containing the row numbers (keepRows).
> 
> output <- data.frame(row.names = rownames(bigMatrix))
> 
> for(i in keepRows)
> {
>     output <- rbind(output, bigMatrix[i, ])
> }
> 
> 
> As you may guess, doing all of these rbinds takes a LOT of time, so I'm 
> wondering if there's a workaround where I can maybe use an intermediate 
> matrix-like object to store the loop output, and then coerce it back to 
> a data frame after the loop is complete??

The indexing operations in R are very flexible.  You can do this in a 
single operation as

output <- bigMatrix[keepRows, ]



From vincent.goulet at act.ulaval.ca  Mon Mar  7 18:39:21 2005
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Mon, 7 Mar 2005 12:39:21 -0500
Subject: [R] Emacs keystroke to toggle T/F for setting logical values
In-Reply-To: <1110030895.5869.5.camel@dhcp-63.ccc.ox.ac.uk>
References: <7E4C06F49D6FEB49BE4B60E5FC92ED7A01834B59@pnlmse35.pnl.gov>
	<1110030895.5869.5.camel@dhcp-63.ccc.ox.ac.uk>
Message-ID: <200503071239.21496.vincent.goulet@act.ulaval.ca>

Le 5 Mars 2005 08:54, Adaikalavan Ramasamy a ?crit :
> Not answering your question here directly but here is an alternative.
> Interactive search and replace TRUE for FALSE with M-% after
> highlighting the region that you are interested in. And then repeat for
> changing FALSE to TRUE.

... and end up with TRUEs only! If you want to go along that route, you'll 
have to convert the original TRUE values to some intermediate string first.

Regards,   Vincent

> You can bind some function keys in your configuration file to simplify
> this a bit.
>
> Regards, Adai
>
> On Fri, 2005-03-04 at 16:58 -0800, Waichler, Scott R wrote:
> > I'd like to have an Emacs keystroke that would let me toggle between T
> > and F when editing logical settings in R code.  I looked in the ESS
> > documentation and in my O'Reilly emacs books but found nothing.  Any
> > ideas?
> >
> > Scott Waichler
> > Pacific Northwest National Laboratory
> > scott.waichler at pnl.gov
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
  Vincent Goulet, Professeur agr?g?
  ?cole d'actuariat
  Universit? Laval, Qu?bec 
  Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca



From p.dalgaard at biostat.ku.dk  Mon Mar  7 18:42:52 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 07 Mar 2005 18:42:52 +0100
Subject: [R] simple if...else causes syntax error
In-Reply-To: <loom.20050307T171450-177@post.gmane.org>
References: <1db7268005030707166b93ff6c@mail.gmail.com>
	<20050307164649.GD32158@jtkpc.cmp.uea.ac.uk>
	<loom.20050307T171450-177@post.gmane.org>
Message-ID: <x2y8cz4ajn.fsf@biostat.ku.dk>

Gabor Grothendieck <ggrothendieck at myway.com> writes:

> Jan T. Kim <jtk <at> cmp.uea.ac.uk> writes:

> : Out of personal interest: Does anyone here know why the R parser was
> : designed this way? Personally, I have been coding in R for years in the
> : belief that newline is whitespace, and never even noticed any problems
> : because all my ifs with elses were within functions and thus enclosed
> : in curly braces.
> : 
> 
> If it did not work that way it would require console lookahead.  That is 
> it would not know that the if statement was finished and would have
> to wait for the following statement to be completely typed in before
> it could process the if.  The way it works now the if statement can
> be processed immediately.

Or put differently, the language designers were not quite aware of the
reason that other command-line languages tend to use explicit
construct terminators like "endif" or "fi".... (I think that is almost
a quote from one of the prominent language experts inside R core, but
I can't pinpoint the details.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From spencer.graves at pdf.com  Mon Mar  7 18:49:57 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 07 Mar 2005 09:49:57 -0800
Subject: [R] Density estimation when an end may not go to zero?  
Message-ID: <422C9445.2020700@pdf.com>

      All the density estimators I've found in R seem to force the ends 
to go to zero.  What can we do if we don't believe that, e.g., with 
something that might be a uniform distribution or a truncated normal 
with only observations above mu+sigma observed?  

      The closest I could come to this was to artificially extend the 
numbers beyond the range, thereby forcing the density estimator to 
continue outside the range of the numbers, then plot only the part that 
I wanted.  The following example supposes simulates observations from a 
truncated normal with mean 0, standard deviation 1, and only 
observations above 1.5 are observed and we faked numbers between 1 and 
1.5: 

set.seed(1)
tst <- rnorm(1000)
tst1 <- tst[tst>1]
knl <- density(tst1)
sel <- knl$x>1.5
plot(knl$x[sel], knl$y[sel], type="l")

      Are there any convenient methods for handling this kind of thing 
currently available in R? 

      Thanks,
      Spencer Graves



From michael.gray at somerville.oxford.ac.uk  Mon Mar  7 18:51:01 2005
From: michael.gray at somerville.oxford.ac.uk (Michael Gray)
Date: Mon, 7 Mar 2005 17:51:01 +0000 (GMT)
Subject: [R] generalised linear models
Message-ID: <20050307175101.1CC4122662@webmail219.herald.ox.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050307/957bd047/attachment.pl

From andy_liaw at merck.com  Mon Mar  7 19:15:10 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 7 Mar 2005 13:15:10 -0500
Subject: [R] Writing to a file
Message-ID: <3A822319EB35174CA3714066D590DCD50994E7F4@usrymx25.merck.com>

Would the following do?

x <- 1000
write.table(Info[Info[,4] > x, c(1, 4)], file="/tmp/CT.dat")

Andy

> From: Melanie Vida
> 
> Here is a simple question. Is there a quicker way to write to a file 
> several rows of data at a time rather than one line at a 
> time? How can 
> the code below be optimized to write several rows at a time to a file 
> rather than one line at a time. See my slow method of 
> write.table below:
> 
> ---------------------------
> x<-1000
> for( i in 1:385420)
>     (
>     if(Info[i,4] > x)
>        write.table (cbind(Info[i,1], Info[i,4], file="/tmp/CT.dat", 
> append=TRUE, row.names=FALSE, col.names=FALSE)
> 
> Thanks,
> 
> -Melanie
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From ripley at stats.ox.ac.uk  Mon Mar  7 19:18:37 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 7 Mar 2005 18:18:37 +0000 (GMT)
Subject: [R] How can we ring a bell in Windows?
In-Reply-To: <4e2p21947nh3ofuorh8uvrrl08or1h4cj2@4ax.com>
References: <20050307163107.63099.qmail@web17110.mail.tpe.yahoo.com>
	<4e2p21947nh3ofuorh8uvrrl08or1h4cj2@4ax.com>
Message-ID: <Pine.LNX.4.61.0503071816280.7898@gannet.stats>

On Mon, 7 Mar 2005, Duncan Murdoch wrote:

> On Tue, 8 Mar 2005 00:31:07 +0800 (CST), Lu Joseph
> <c_joseph_lu at yahoo.com.tw> wrote :
>
>> Hello useRs,
>>
>> Is there a way to write code in R
>> to ring a bell in Windows?
>
> If you load the tcltk package, then
>
> tkbell()
>
> will get you a bell on more platforms than just Windows.  If you don't
> want to use tcltk, then you could call the Windows API function
> MessageBeep from some C code, but I don't think we have a "bell" or
> "beep" function in the standard R packages.

But there is the ANSI "\a": cat("\n") works as expected, on all platforms.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Mar  7 19:22:39 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 7 Mar 2005 18:22:39 +0000 (GMT)
Subject: [R] Writing to a file
In-Reply-To: <3A822319EB35174CA3714066D590DCD50994E7F4@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50994E7F4@usrymx25.merck.com>
Message-ID: <Pine.LNX.4.61.0503071820180.7898@gannet.stats>

On Mon, 7 Mar 2005, Liaw, Andy wrote:

> Would the following do?
>
> x <- 1000
> write.table(Info[Info[,4] > x, c(1, 4)], file="/tmp/CT.dat")
>
> Andy
>
>> From: Melanie Vida
>>
>> Here is a simple question. Is there a quicker way to write to a file
>> several rows of data at a time rather than one line at a
>> time? How can
>> the code below be optimized to write several rows at a time to a file
>> rather than one line at a time. See my slow method of
>> write.table below:

There is almost no penalty in writing a line at a time *if* you open a 
connection and write to that.  It might save you if Andy's solution runs 
you out of memory.  I would investigate doing this is large blocks of rows 
in that case.


>>
>> ---------------------------
>> x<-1000
>> for( i in 1:385420)
>>     (
>>     if(Info[i,4] > x)
>>        write.table (cbind(Info[i,1], Info[i,4], file="/tmp/CT.dat",
>> append=TRUE, row.names=FALSE, col.names=FALSE)
>>
>> Thanks,
>>
>> -Melanie
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Mar  7 19:28:30 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 7 Mar 2005 18:28:30 +0000 (GMT)
Subject: [R] Density estimation when an end may not go to zero?  
In-Reply-To: <422C9445.2020700@pdf.com>
References: <422C9445.2020700@pdf.com>
Message-ID: <Pine.LNX.4.61.0503071823290.7898@gannet.stats>

On Mon, 7 Mar 2005, Spencer Graves wrote:

>     All the density estimators I've found in R seem to force the ends to go 
> to zero.

Which ones are those?

> What can we do if we don't believe that, e.g., with something that 
> might be a uniform distribution or a truncated normal with only observations 
> above mu+sigma observed? 
>     The closest I could come to this was to artificially extend the numbers 
> beyond the range, thereby forcing the density estimator to continue outside 
> the range of the numbers, then plot only the part that I wanted.  The 
> following example supposes simulates observations from a truncated normal 
> with mean 0, standard deviation 1, and only observations above 1.5 are 
> observed and we faked numbers between 1 and 1.5: 
> set.seed(1)
> tst <- rnorm(1000)
> tst1 <- tst[tst>1]
> knl <- density(tst1)
> sel <- knl$x>1.5
> plot(knl$x[sel], knl$y[sel], type="l")

>     Are there any convenient methods for handling this kind of thing 
> currently available in R?

This is covered in MASS, for example.  logspline() would be a good choice 
here: it allows a finite support.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Mar  7 19:30:57 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 7 Mar 2005 18:30:57 +0000 (GMT)
Subject: [R] generalised linear models
In-Reply-To: <20050307175101.1CC4122662@webmail219.herald.ox.ac.uk>
References: <20050307175101.1CC4122662@webmail219.herald.ox.ac.uk>
Message-ID: <Pine.LNX.4.61.0503071828510.7898@gannet.stats>

On Mon, 7 Mar 2005, Michael Gray wrote:

> To whom this may concern,
>
> I would be very grateful if someone could give me some advice on where I 
> am going wrong with a logistic regression I am trying to run. I am 
> trying to run a logistic regression on an aggregated data set and have 
> input the command:
>
> logistic.mod<-glm(x~Frequency+Location+Sex+Age.Group,family=binomial(link="logit"),data=earsag1.dat)
>
> where x is the count of my response and frequency, location, sex and 
> age.group are other variables. However, R gives an error because my 
> values of x are not between 0 and 1. Therefore to compensate for this I 
> denoted y= x/n where n is the number of people in each group and ran the 
> regression
>
> logistic.mod<-glm(y~Frequency+Location+Sex+Age.Group,family=binomial(link="logit"),data=earsag1.dat)
>
> At this point R told me that my y values were not integer values and 
> hence there was an error. I do not know how, therefore, to set up the 
> logistic regression properly, so I would be very grateful if someone 
> could give me some pointers. If I haven't explained anything well 
> enough, let me know. Thanks very much for your help,

You have forgotten to set the weights=n.  The alternative is to have
response cbind(x, n-x).

See MASS4, p.190.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From greg.snow at ihc.com  Mon Mar  7 19:50:08 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Mon, 07 Mar 2005 11:50:08 -0700
Subject: [R] Farey sequences
Message-ID: <s22c4007.093@lp-msg1.co.ihc.com>

This sequence of commands replicates your example, could you expand this
to do what you want?

> tmp <- c( outer( 0:4, 1:4, "/") )
> tmp <- tmp[tmp <= 1]
> tmp <- unique(tmp)
> tmp <- sort(tmp)
> library(MASS)
> fractions(tmp)
[1]   0 1/4 1/3 1/2 2/3 3/4   1


Greg Snow, Ph.D.
Statistical Data Center
greg.snow at ihc.com
(801) 408-8111

>>> Robin Hankin <r.hankin at soc.soton.ac.uk> 03/04/05 07:06AM >>>
Hi

has anyone coded up Farey sequences?

[
The Farey sequence of order "n"  is the set of  rational numbers i/j
with (i,j)=1 such that 0 <= i,j <= n; the sequence is ordered from 
lowest to highest.
Thus

Farey_4 = {0/1 , 1/4 , 1/3 , 1/2 , 2/3 , 3/4 , 1/1}
]

My motivation is unimodular transformations: I need to systematically
generate 2-by-2 integer matrices with determinant 1, and Farey
sequences
seem to be the best way to do this.




--
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From mvida at mitre.org  Mon Mar  7 20:31:32 2005
From: mvida at mitre.org (Melanie Vida)
Date: Mon, 07 Mar 2005 14:31:32 -0500
Subject: [R] Writing to a file
In-Reply-To: <3A822319EB35174CA3714066D590DCD50994E7F4@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50994E7F4@usrymx25.merck.com>
Message-ID: <422CAC14.1050209@mitre.org>

Yes, Andy, the command you gave takes only a minute to output the whole 
data set to a file rather than mine, which takes hours to complete the 
file ouput operation. Thanks!

Liaw, Andy wrote:

>Would the following do?
>
>x <- 1000
>write.table(Info[Info[,4] > x, c(1, 4)], file="/tmp/CT.dat")
>
>Andy
>
>  
>
>>From: Melanie Vida
>>
>>Here is a simple question. Is there a quicker way to write to a file 
>>several rows of data at a time rather than one line at a 
>>time? How can 
>>the code below be optimized to write several rows at a time to a file 
>>rather than one line at a time. See my slow method of 
>>write.table below:
>>
>>---------------------------
>>x<-1000
>>for( i in 1:385420)
>>    (
>>    if(Info[i,4] > x)
>>       write.table (cbind(Info[i,1], Info[i,4], file="/tmp/CT.dat", 
>>append=TRUE, row.names=FALSE, col.names=FALSE)
>>
>>Thanks,
>>
>>-Melanie
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
>>
>>
>>    
>>
>
>
>
>------------------------------------------------------------------------------
>Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, New Jersey, USA 08889), and/or its affiliates (which may be known outside the United States as Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be confidential, proprietary copyrighted and/or legally privileged. It is intended solely for the use of the individual or entity named on this message.  If you are not the intended recipient, and have received this message in error, please notify us immediately by reply e-mail and then delete it from your system.
>------------------------------------------------------------------------------
>  
>



From murdoch at stats.uwo.ca  Mon Mar  7 20:32:17 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 07 Mar 2005 19:32:17 +0000
Subject: [R] How can we ring a bell in Windows?
In-Reply-To: <Pine.LNX.4.61.0503071816280.7898@gannet.stats>
References: <20050307163107.63099.qmail@web17110.mail.tpe.yahoo.com>
	<4e2p21947nh3ofuorh8uvrrl08or1h4cj2@4ax.com>
	<Pine.LNX.4.61.0503071816280.7898@gannet.stats>
Message-ID: <jtap21pbp7f2hrtfpqtfbfbrdbkt4c9hms@4ax.com>

On Mon, 7 Mar 2005 18:18:37 +0000 (GMT), Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote :

>On Mon, 7 Mar 2005, Duncan Murdoch wrote:
>
>> On Tue, 8 Mar 2005 00:31:07 +0800 (CST), Lu Joseph
>> <c_joseph_lu at yahoo.com.tw> wrote :
>>
>>> Hello useRs,
>>>
>>> Is there a way to write code in R
>>> to ring a bell in Windows?
>>
>> If you load the tcltk package, then
>>
>> tkbell()
>>
>> will get you a bell on more platforms than just Windows.  If you don't
>> want to use tcltk, then you could call the Windows API function
>> MessageBeep from some C code, but I don't think we have a "bell" or
>> "beep" function in the standard R packages.
>
>But there is the ANSI "\a": cat("\n") works as expected, on all platforms.

Perhaps we should have a beep() or bell() function, to remind those of
us who never knew all the C escapes and wouldn't have guessed that the
ancient ASCII control codes still function.

I'll put it on my list...

Duncan Murdoch



From David.Brahm at geodecapital.com  Mon Mar  7 21:25:47 2005
From: David.Brahm at geodecapital.com (Brahm, David)
Date: Mon, 7 Mar 2005 15:25:47 -0500
Subject: [R] Search and convert string function
Message-ID: <4DD6F8B8782D584FABF50BF3A32B03D801A2BB6D@MSGBOSCLF2WIN.DMN1.FMR.COM>

peng shen [mailto:michael_shen at hotmail.com] wrote:
> R <- 4
> testString <- "I love $R"
> So the final string I want to get is "I love 4".  How can I implement?

I've written an interpolater function "g.p" with these additional
features:
 - Loops through all occurences of the escape character ($) rather than
all
   external variables.
 - Variable names are terminated by any non-alphanumeric char or a
"silent" $$.
 - Variables may come from the parent environment or from named
arguments.
 - Pastes together its unnamed arguments with sep="", useful for long
strings.

Example:
R> R <- 4
R> testString <- "I love $R"
R> g.p(testString)
   [1] "I love 4"

Fancier example:
R> var1 <- 7
R> var2 <- 5
R> g.p("Add $var1 to $var2 to calc",
       "ulate $var3",
       var3=var1+var2)
   [1] "Add 7 to 5 to calculate 12"

Function definition:
g.p <- function(..., esc="\\$", sep="", collapse=" ", parent=1) {
  a <- lapply(list(...), as.character)
  n <- names(a);  if (is.null(n)) n <- rep("", length(a))
  s <- do.call("paste", c(a[n==""], sep=sep, collapse=collapse))
  for (i in which(n != "")) s <- gsub(paste(esc,n[i],sep=""), a[[i]], s)
  while ((r <- regexpr(paste(esc,"\\w*",sep=""), s)) > 0) {
    v <- substring(s, r+1, r+attr(r,"match.length")-1)
    s <- if (v=="") paste(substring(s,1,r-1), substring(s,r+2), sep="")
else
         gsub(paste(esc,v,sep=""),
              as.character(eval.parent(parse(text=v), parent)), s)
  }
  s
}

-- David Brahm (brahm at alum.mit.edu)



From nepossiver at yahoo.com  Mon Mar  7 21:42:47 2005
From: nepossiver at yahoo.com (Horacio Montenegro)
Date: Mon, 7 Mar 2005 12:42:47 -0800 (PST)
Subject: [R] Questions about glmms.
Message-ID: <20050307204247.66329.qmail@web50603.mail.yahoo.com>


	Hi,
	
	I have a couple of questions related to glmm (glmmPQL
in MASS and GLMM in lme4). 

	1) is there some way do obtain the fitted values by
group, similar to:

> predict(dbd.glmmPQL, dbd.cytdens, 
+       type="response", level=0)

	where dbd.glmmPQL is the fitted model and dbd.cytdens
is a data frame with a subset of the factors?
	
	2) when I double-click on a saved workspace (.RData
file) containing lme4 objects there is an error
message and R crashes. Instead, if I load lme4 and
then open the file, it loads smoothly. Is this a bug
or just a feature? I'm working with R 2.0.1, lme4
0.9-2, Matrix 0.95-3, on windows 98. Unfortunately, I
cant provide the error message, as I dont have R
installed on this computer, but I can provide it
later, if asked.
	
	3) Has the result of anova(dbd.glmmPQL) or
anova(dbd.GLMM) any meaning? If yes, what is it? I
mean, if I do an anova(glmmPQL.object) or
anova(GLMM.object), I do obtain an anova table that,
for me (a biologist), is easily interpretable. I know
that this question has been asked before, but, so far,
I did not find a comprehensive answer. I've read
Venables & Ripley MASS (2000), but glmmPQL is not
mentioned there, and I do not have access to the later
edition. Besides, in lme4 manual, under GLMM-class
there is an anova method, but there are no further
details explaining the method or its usage.

	cheers, 
	Horacio

--
Horacio Montenegro
PhD student in Genetics
Departamento de Gentica e Evoluo
UNICAMP
Campinas - SP - Brasil



From SimaFakheran at invitation.sms.ac  Mon Mar  7 23:05:21 2005
From: SimaFakheran at invitation.sms.ac (SimaFakheran@invitation.sms.ac)
Date: Mon,  7 Mar 2005 17:05:21 -0500 (EST)
Subject: [R] Sima Fakheran's invitation
Message-ID: <20050307220521.5D4F535945@smtp49.sms.ac>



From adrian at maths.uwa.edu.au  Tue Mar  8 01:56:52 2005
From: adrian at maths.uwa.edu.au (Adrian Baddeley)
Date: Tue, 8 Mar 2005 08:56:52 +0800
Subject: [R] lazy blighter
Message-ID: <16940.63572.849287.87709@maths.uwa.edu.au>

A question about package development.

Our package tarfile (spatstat_1.5-10.tar.gz) has already passed R CMD check.
We install the package in a local directory, either by hand or by
running the package checker. Starting R 2.0.1 and loading this package
using library(spatstat, lib.loc="./spatstat.Rcheck") or whatever,
we get the following error as soon as there is a data() command:

 > 	Error in lazyLoadDBfetch(key, datafile, compressed, envhook) : 
 >                 file open failed
 
The file permissions are all 644. This happens on at least two
systems including pc-linux-gnu.

Is this a bug in lazy loading ? oder?

thanks
Adrian Baddeley & Rolf Turner



From DominikGrathwohl at gmx.de  Tue Mar  8 02:17:46 2005
From: DominikGrathwohl at gmx.de (Dominik Grathwohl)
Date: Tue, 8 Mar 2005 02:17:46 +0100 (MET)
Subject: [R] One mixed effects model for two variables
Message-ID: <402.1110244666@www67.gmx.net>

Hello R-help group,

I need some suggestions in stating a mixed effects model. I would like to
fit one mixed effect model to two or more variables and than investigating
treatment effects by applying the multcomp library. I will explain my
problem along an example of weight and length measurements on infants.
Weight and length  are measured at two occasions in time and for two
treatment groups, one group got some experimental formula and the other some
control formula. It is also reasonable to assume that weight and length are
correlated. Aim is to estimate the treatment effect on weight and on length
taking multiplicity into account. 
Below I generated some data of the proposed properties and I applied also
two mixed effects models, one model for weight and one for length. Up to now
I&#8217;m not able to state a model for both variables together, any
suggestions?

library(nlme)

n <- 200                # n = number of subjects
id <- rep(1:n, each=2)  # id = subject identification number
t <- rep(0:1, times=n)  # two occations in time
trt <- rep(sample(rep(0:1, times=n/2)), each=2) # two treatment groups
b1 <- rnorm(n, mean=0, sd=0.5)              # b1 = random effect of weight

y1 <- 3.5 + rep(b1, each=2) + 0.7 * t + 0.01 * trt + 0.1 * t * trt +
rnorm(2*n,mean=0, sd=0.09)
# y1 = weight measurements, 3.5 kg at baseline, 
# 0.7 kg more at the second time occation 
# 0.01 = the treatment effect at baseline, 
# the treatment effect is 0.1 kg for the 
# experimental group at at the second time occation. 
# The whithin subject standard deviation is 0.09.

b2 <- 0.9 * 3/sd(b1) * b1 + rnorm(length(b1), mean=0, sd=sqrt(1-0.9**2)*3)
# b2 = random effect for length with standard deviation = 3 
# and correlated with the random effect of weight (b1) by r=0.9

y2 <- 49 + rep(b2, each=2) + 2 * t - 0.05 * trt + 0.5 * t * trt +
rnorm(2*n,mean=0, sd=1)
# y2 = length measurements, 49 cm at baseline, 
# 2 cm more at the second time occation 
# 0.05 = the treatment effect at baseline, 
# the treatment effect is 0.5 cm for the 
# experimental group at at the second time occation. 
# The whithin subject standard deviation is 1.


# data frame of the data:
df <- data.frame(var=as.factor(rep(0:1, each=2*n)),
 id=c(id, id), t=as.factor(c(t, t)), trt=as.factor(c(trt, trt)), y=c(y1,
y2))

# grouped data object:
gd <- groupedData(y ~ t | id, data=df)

# mixed effects model on weight:
fm1weight <- lme(y ~ t * trt, random = ~ 1 | id, data = gd, subset=var==0)
summary(fm1weight)

# mixed effect model on length:
fm1length <- lme(y ~ t * trt, random = ~ 1 | id, data = gd, subset=var==1)
summary(fm1length)

-- 
DSL Komplett von GMX +++ Supergnstig und stressfrei einsteigen!
AKTION "Kein Einrichtungspreis" nutzen: http://www.gmx.net/de/go/dsl



From berkowi4 at msu.edu  Tue Mar  8 02:23:39 2005
From: berkowi4 at msu.edu (Shelby Berkowitz)
Date: Mon, 7 Mar 2005 20:23:39 -0500
Subject: [R] Problem with plotting size/location on variation of
	star/segment plot
In-Reply-To: <4229FF31.2070601@statistik.uni-dortmund.de>
Message-ID: <000001c5237d$75cd7350$144dfea9@shelbyhome>

Beautiful!!!  Thanks so much, Uwe!

[Notes for anyone else stumbling across similar issues in the future:
After making the change Uwe suggested, I realized a couple of things:
first, the plot.new() commands were redundant with add=F in place.
Second, I was still scratching my head for a few minutes wondering why
some of my plots now fit perfectly while others were still a bit too big
for the frame (though not as bad as before).  Then I put 2 and 2
together based on a hint in Uwe's message: the first plot command in the
series was driving the dimension calculations.  So...plots that had one
or more data points at the full radius of my post-plotted axes ended up
fine, others ended up too big once the final gridlines were added.  The
solution of course was to make the first stars() command a plot of the
major-gridline axis with invisible lines.  Revised code follows.]

par(mfrow=c(2,2), mar=c(1,0,1,0),oma=c(2,2,2,2))
## code segment for each separate radar chart within frame
majgrid <- matrix(rep((c(1:10)*.1),ncol(DF)),nrow=10,byrow=F)
mingrid <- matrix(rep((c(1:10)*.1-.05),ncol(DF)),nrow=10,byrow=F)
stars(majgrid, locations = 0:1, scale=F, draw.segments = TRUE,
add=FALSE, lty=0, col.segments=0,main="Plot Title")
stars(DF[seriesindex1,], locations=0:1,full = TRUE, scale = F,
draw.segments=TRUE, add=TRUE,col.segments=heatshades[7])
stars(DF[seriesindex2,], locations=0:1,full = TRUE, scale = F,
draw.segments=TRUE, add=TRUE,col.segments=heatshades[3])
stars(majgrid, locations = 0:1, scale=F, draw.segments = TRUE, add=T,
lty=1, col.segments=0,lwd=1.5)
stars(mingrid, locations = 0:1, scale=F, draw.segments = TRUE, add=T,
lty=2, col.segments=0,lwd=1)
###rinse and repeat as needed

Warmly,

Shelby

>-----Original Message-----
>From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
>Sent: Saturday, March 05, 2005 1:49 PM
>To: Shelby Berkowitz
>Cc: r-help at r-project.org
>Subject: Re: [R] Problem with plotting size/location on 
>variation of star/segment plot
>
>
>Shelby Berkowitz wrote:
>
>> Dear R gurus,
>> 
>> I'm running into a problem with some modified segment plots 
>I've coded 
>> using stars().  What I am trying to do is superimpose two series of 
>> data along with radial axes markers in a 2x2 graphics frame. 
> This is 
>> working fine now, except for the hitch: my plots overfill the frame 
>> and are not centered within it (on my runs they always end 
>up looking 
>> like they've been budged up and to the left).  They're also a little 
>> warped-looking (more oval than perfectly round).
>> 
>> - I don't think this is a problem with my par() settings, as I've 
>> checked them out and they don't look suspicious.  Also, I've tested 
>> generating other plots (e.g., dummy histograms) on the same 
>device and 
>> they fit perfectly.  It's also not a problem with fitting stars() 
>> plots into a par(mfrow=c(2,2) frame, as I get the same 
>offset/overflow 
>> when I run just one plot on a mfrow=c(1,1) frame.
>> - I don't think it's a problem with the windows graphics 
>device, as I 
>> tried plotting to other devices (e.g., postscript) and get the same 
>> results.
>> - Thus, I'm pretty sure this comes down to something funky with the 
>> way I'm using stars().  My runs of examples from stars() fit just as 
>> they should inside their graphics frames, but as far as I 
>can see, the 
>> individual calls to stars() below don't look materially 
>different from 
>> the ones in the examples.
>> 
>> At this point, I'm completely stumped.  Can someone please point me 
>> towards what I might be doing wrong here?  Any and all 
>advice will be 
>> most humbly appreciated! BTW, I'm running R 2.00 on Windows XP, all 
>> packages updated.
>> 
>> Example version of my code is pasted below (the loop is for example 
>> purposes only):
>> 
>> ##begin sample code
>> par(mfrow=c(2,2))
>> for (i in 1:4) {
>> 	## generate sample data for plot:
>> 	a<- sample(c(20:70)*.01,18)
>> 	testA <-
>> as.data.frame(rbind(a,a+((1-a)*sample(c(1:10)*.1,18,replace=T))))
>> 	## open new plot space
>> 	plot.new()
>> 	## plot data series:
>> 	stars(testA[2,], locations=0:1,full = TRUE, scale = F, 
>> draw.segments=TRUE, add=TRUE,col.segments=heatshades[7])
>
>Well, since you have neither called plot.window() nor stars() with 
>"add=FALSE"), the dimensions have not been set up correctly.
>
>In the first call above, simply say add = FALSE.
>
>Uwe Ligges
>
>
>
>> 	stars(testA[1,], locations=0:1,full = TRUE, scale = F, 
>> draw.segments=TRUE, add=TRUE,col.segments=heatshades[3])
>> 	majgrid <- matrix(rep((c(1:10)*.1),ncol(testA)),nrow=10,byrow=F)
>> 	## generate and plot radar grid:
>> 	mingrid <-
>> matrix(rep((c(1:10)*.1-.05),ncol(testA)),nrow=10,byrow=F)
>> 	stars(majgrid, locations=0:1, scale=F, draw.segments = 
>TRUE, add=T, 
>> lty=1, col.segments=0)
>> 	stars(mingrid, locations=0:1, scale=F, draw.segments = 
>TRUE, add=T, 
>> lty=2, col.segments=0)}
>> par(mfrow=c(1,1))
>> ##end sample code
>> 
>> Thank you,
>> 
>> Shelby
>> 
>> ===============================
>> Shelby L. Berkowitz
>> Ecological-Community Psychology
>> and Institute for Health Care Studies
>> Michigan State University
>> berkowi4 at msu.edu



From maustin at amgen.com  Tue Mar  8 03:11:11 2005
From: maustin at amgen.com (Austin, Matt)
Date: Mon, 7 Mar 2005 18:11:11 -0800 
Subject: [R] One mixed effects model for two variables
Message-ID: <E7D5AB4811D20B489622AABA9C53859104E0E00D@teal-exch.amgen.com>

Here are two possibilities, but neither tests simultaneously--others may
have those suggestions.  

1.  If one of the variables in clinically more important than the other,
consider a stepdown procedure where the more important is tested first, then
if the first is successful the second is tested.  Procedures such as this
are well documented in the literature.

2.  Find a function of the two that has a clinical interpretation and model
that response. Body mass index is an example of such a function (kg/m^2),
but probably is not an endpoint that would be of interest in a growth study
in pediatrics.

Matt Austin
Statistician

Amgen 
One Amgen Center Drive
M/S 24-2-C
Thousand Oaks CA 93021
(805) 447 - 7431

"Today has the fatigue of a Friday and the desperation of a Monday"  -- S.
Pearce 2005


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Dominik 
> Grathwohl
> Sent: Monday, March 07, 2005 17:18 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] One mixed effects model for two variables
> 
> 
> Hello R-help group,
> 
> I need some suggestions in stating a mixed effects model. I 
> would like to
> fit one mixed effect model to two or more variables and than 
> investigating
> treatment effects by applying the multcomp library. I will explain my
> problem along an example of weight and length measurements on infants.
> Weight and length  are measured at two occasions in time and for two
> treatment groups, one group got some experimental formula and 
> the other some
> control formula. It is also reasonable to assume that weight 
> and length are
> correlated. Aim is to estimate the treatment effect on weight 
> and on length
> taking multiplicity into account. 
> Below I generated some data of the proposed properties and I 
> applied also
> two mixed effects models, one model for weight and one for 
> length. Up to now
> I&#8217;m not able to state a model for both variables together, any
> suggestions?
> 
> library(nlme)
> 
> n <- 200                # n = number of subjects
> id <- rep(1:n, each=2)  # id = subject identification number
> t <- rep(0:1, times=n)  # two occations in time
> trt <- rep(sample(rep(0:1, times=n/2)), each=2) # two treatment groups
> b1 <- rnorm(n, mean=0, sd=0.5)              # b1 = random 
> effect of weight
> 
> y1 <- 3.5 + rep(b1, each=2) + 0.7 * t + 0.01 * trt + 0.1 * t * trt +
> rnorm(2*n,mean=0, sd=0.09)
> # y1 = weight measurements, 3.5 kg at baseline, 
> # 0.7 kg more at the second time occation 
> # 0.01 = the treatment effect at baseline, 
> # the treatment effect is 0.1 kg for the 
> # experimental group at at the second time occation. 
> # The whithin subject standard deviation is 0.09.
> 
> b2 <- 0.9 * 3/sd(b1) * b1 + rnorm(length(b1), mean=0, 
> sd=sqrt(1-0.9**2)*3)
> # b2 = random effect for length with standard deviation = 3 
> # and correlated with the random effect of weight (b1) by r=0.9
> 
> y2 <- 49 + rep(b2, each=2) + 2 * t - 0.05 * trt + 0.5 * t * trt +
> rnorm(2*n,mean=0, sd=1)
> # y2 = length measurements, 49 cm at baseline, 
> # 2 cm more at the second time occation 
> # 0.05 = the treatment effect at baseline, 
> # the treatment effect is 0.5 cm for the 
> # experimental group at at the second time occation. 
> # The whithin subject standard deviation is 1.
> 
> 
> # data frame of the data:
> df <- data.frame(var=as.factor(rep(0:1, each=2*n)),
>  id=c(id, id), t=as.factor(c(t, t)), trt=as.factor(c(trt, 
> trt)), y=c(y1,
> y2))
> 
> # grouped data object:
> gd <- groupedData(y ~ t | id, data=df)
> 
> # mixed effects model on weight:
> fm1weight <- lme(y ~ t * trt, random = ~ 1 | id, data = gd, 
> subset=var==0)
> summary(fm1weight)
> 
> # mixed effect model on length:
> fm1length <- lme(y ~ t * trt, random = ~ 1 | id, data = gd, 
> subset=var==1)
> summary(fm1length)
> 
> -- 
> DSL Komplett von GMX +++ Superg?nstig und stressfrei einsteigen!
> AKTION "Kein Einrichtungspreis" nutzen: http://www.gmx.net/de/go/dsl
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html



From drcarbon at gmail.com  Tue Mar  8 04:12:10 2005
From: drcarbon at gmail.com (Dr Carbon)
Date: Mon, 7 Mar 2005 22:12:10 -0500
Subject: [R] coefficient of partial determination...partial r square [redux]
In-Reply-To: <e89bb7ac0503050608c3c8860@mail.gmail.com>
References: <e89bb7ac0503040751290eafd3@mail.gmail.com>
	<e89bb7ac0503050608c3c8860@mail.gmail.com>
Message-ID: <e89bb7ac05030719126a780ce@mail.gmail.com>

After the deafening silence from my last post (which likely caused
shudders of disgust in statistics departments on the six continents)
I'll reformulate:

Is there a function that will return the coefficients of partial
determination for the independent variables in a lm (or glm). For y =
x1 + x2....xn can I use R to extract the partial rsq for x1 to n?

I am, and remain, with Admiration, etc. etc., at your Bidding,
DC



From ggrothendieck at myway.com  Tue Mar  8 04:21:33 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 8 Mar 2005 03:21:33 +0000 (UTC)
Subject: [R] lazy blighter
References: <16940.63572.849287.87709@maths.uwa.edu.au>
Message-ID: <loom.20050308T041656-91@post.gmane.org>

Adrian Baddeley <adrian <at> maths.uwa.edu.au> writes:

: 
: A question about package development.
: 
: Our package tarfile (spatstat_1.5-10.tar.gz) has already passed R CMD check.
: We install the package in a local directory, either by hand or by
: running the package checker. Starting R 2.0.1 and loading this package
: using library(spatstat, lib.loc="./spatstat.Rcheck") or whatever,
: we get the following error as soon as there is a data() command:
: 
:  > 	Error in lazyLoadDBfetch(key, datafile, compressed, envhook) : 
:  >                 file open failed
: 
: The file permissions are all 644. This happens on at least two
: systems including pc-linux-gnu.
: 
: Is this a bug in lazy loading ? oder?
: 

You could try adding

LazyLoad: no

to your DESCRIPTION file although even if that works it may
just get rid of the message and there may still be a real 
error in your package lurking.  In the past I have found that
often a lazyload error is not related to lazyloading at all and
signifies some completely different error.  Once I was able to
get past it by using forward rather than backward slashes on a
pathname in MS-Windows, for example.  Another time I had to 
successively remove half my package until I pinpointed the 
real error.  If you search the archives you can find comments
similar to this by myself although I think I got the main
points here.



From andy_liaw at merck.com  Tue Mar  8 04:42:50 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 7 Mar 2005 22:42:50 -0500
Subject: [R] coefficient of partial determination...partial r square
	[ redux]
Message-ID: <3A822319EB35174CA3714066D590DCD50994E7F9@usrymx25.merck.com>

If I'm not mistaken, partial R-squared is the R^2 of the quantities plotted
in a partial residual plot, so you can base the computation on that.  Prof.
Fox's `car' package on CRAN has a function for creating those plots, but you
need to figure out the way to extract the quantities being plotted.

[In any case, the basic tools for doing such computations are all in R, and
it shouldn't be hard at all to cook up such a thing, starting from the
formula.  Writing a function that works on any conceivable models that can
be fitted with lm() would be a bit more challenging, but I doubt you need
that.]

HTH,
Andy

> From: Dr Carbon
> 
> After the deafening silence from my last post (which likely caused
> shudders of disgust in statistics departments on the six continents)
> I'll reformulate:
> 
> Is there a function that will return the coefficients of partial
> determination for the independent variables in a lm (or glm). For y =
> x1 + x2....xn can I use R to extract the partial rsq for x1 to n?
> 
> I am, and remain, with Admiration, etc. etc., at your Bidding,
> DC
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From kim83 at uiuc.edu  Tue Mar  8 08:50:04 2005
From: kim83 at uiuc.edu (kim83@uiuc.edu)
Date: Tue, 8 Mar 2005 01:50:04 -0600
Subject: [R] 3D plot not working as desired!
Message-ID: <74a8ad69.d9b6cd05.81ec500@expms1.cites.uiuc.edu>

Hello R-users!

I am trying to plot 3 vectors (x,y,z) of observations
generated by mvrnorm in library(MASS).

I tried plot3d in library(djmrgl) and scatterplot3d.
But these program gives x,y,z axis which do not 
intersect at the origin (0,0,0). 

I searched through all the graphics related packages
for R like xgobi, ggobi, grid and more. Quite
confusing which one to choose.

Would anyone recommend any way to plot the 3-dimensional
randomly generated numbers? It would be very nice if it
can create 95% confidence region ellisoid around the
observations, just like the 95% confidence ellipse around
the bivariate normal random numbers.

Thanks in advance!

Sangwhan Kim
Department of Economics
University of Illinois at Urbana-Champaign



From maechler at stat.math.ethz.ch  Tue Mar  8 09:06:31 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 8 Mar 2005 09:06:31 +0100
Subject: [R] How can we ring a bell in Windows?
In-Reply-To: <jtap21pbp7f2hrtfpqtfbfbrdbkt4c9hms@4ax.com>
References: <20050307163107.63099.qmail@web17110.mail.tpe.yahoo.com>
	<4e2p21947nh3ofuorh8uvrrl08or1h4cj2@4ax.com>
	<Pine.LNX.4.61.0503071816280.7898@gannet.stats>
	<jtap21pbp7f2hrtfpqtfbfbrdbkt4c9hms@4ax.com>
Message-ID: <16941.23815.382837.532001@stat.math.ethz.ch>

>>>>> "Duncan" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>     on Mon, 07 Mar 2005 19:32:17 +0000 writes:

    Duncan> On Mon, 7 Mar 2005 18:18:37 +0000 (GMT), Prof Brian
    Duncan> Ripley <ripley at stats.ox.ac.uk> wrote :

    >> On Mon, 7 Mar 2005, Duncan Murdoch wrote:
    >> 
    >>> On Tue, 8 Mar 2005 00:31:07 +0800 (CST), Lu Joseph
    >>> <c_joseph_lu at yahoo.com.tw> wrote :
    >>> 
    >>>> Hello useRs,
    >>>> 
    >>>> Is there a way to write code in R to ring a bell in
    >>>> Windows?
    >>>  If you load the tcltk package, then
    >>> 
    >>> tkbell()
    >>> 
    >>> will get you a bell on more platforms than just Windows.
    >>> If you don't want to use tcltk, then you could call the
    >>> Windows API function MessageBeep from some C code, but I
    >>> don't think we have a "bell" or "beep" function in the
    >>> standard R packages.
    >>  But there is the ANSI "\a": cat("\n") works as expected,
    >> on all platforms.

{and of course,   cat("\a")   was meant above}

    Duncan> Perhaps we should have a beep() or bell() function,
    Duncan> to remind those of us who never knew all the C
    Duncan> escapes and wouldn't have guessed that the ancient
    Duncan> ASCII control codes still function.

    Duncan> I'll put it on my list...
    Duncan> Duncan Murdoch

good.  Yes that would be a very sensible encapsulation of
functionality.

Note that ASCII control codes don't work on all
kinds of terminals, e.g., they don't work in ESS  --- but ESS
could be made to react smartly to a beep() function call.

Martin





    Duncan> ______________________________________________
    Duncan> R-help at stat.math.ethz.ch mailing list
    Duncan> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE
    Duncan> do read the posting guide!
    Duncan> http://www.R-project.org/posting-guide.html



From murdoch at stats.uwo.ca  Tue Mar  8 09:36:07 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 08 Mar 2005 08:36:07 +0000
Subject: [R] 3D plot not working as desired!
In-Reply-To: <74a8ad69.d9b6cd05.81ec500@expms1.cites.uiuc.edu>
References: <74a8ad69.d9b6cd05.81ec500@expms1.cites.uiuc.edu>
Message-ID: <1ioq21hfl3fhsd9lm83fmvgkpc41jvlvvj@4ax.com>

On Tue, 8 Mar 2005 01:50:04 -0600, <kim83 at uiuc.edu> wrote :

>Hello R-users!
>
>I am trying to plot 3 vectors (x,y,z) of observations
>generated by mvrnorm in library(MASS).
>
>I tried plot3d in library(djmrgl) and scatterplot3d.
>But these program gives x,y,z axis which do not 
>intersect at the origin (0,0,0). 

The default in R is to create axes outside the range of your data, and
that's what djmrgl and scatterplot3d do.  In djmrgl you can control
the placement of the axes if you really want them in the middle of
your data, but why would you want that?? 

See the example in ?axis3d for details.
>
>I searched through all the graphics related packages
>for R like xgobi, ggobi, grid and more. Quite
>confusing which one to choose.
>
>Would anyone recommend any way to plot the 3-dimensional
>randomly generated numbers? It would be very nice if it
>can create 95% confidence region ellisoid around the
>observations, just like the 95% confidence ellipse around
>the bivariate normal random numbers.

I don't know a package that does that, but there probably is one.

Duncan Murdoch



From r.hankin at soc.soton.ac.uk  Tue Mar  8 10:03:43 2005
From: r.hankin at soc.soton.ac.uk (Robin Hankin)
Date: Tue, 8 Mar 2005 09:03:43 +0000
Subject: [R] a==0 vs as.integer(a)==0 vs all.equal(a,0)
Message-ID: <0e18b9f7126370cea830727f44e733b7@soc.soton.ac.uk>

hi


?integer says:

      Note that on almost all implementations of R the range of
      representable integers is restricted to about +/-2*10^9: 'double's
      can hold much larger integers exactly.


I am getting very confused as to when to use integers and when not to.  
In my line
I need exact comparisons of large integer-valued arrays, so I often use 
as.integer(),
but the above seems to tell me that doubles might  be better.

Consider the following R idiom of Euclid's algorithm for the highest 
common factor
of two positive integers:

   gcd <- function(a, b){
     if (b == 0){ return(a)}
     return(Recall(b, a%%b))
   }

If I call this with gcd(10,12), for example, then  a%%b is not an 
integer, so the first
line of the function, testing b for being zero, isn't legitimate.

OK, so I have some options:

(1) stick in "a <- as.integer(a),  b <- as.integer(b)" into the 
function:  then a%%b *will* be an
                integer and the "==" test is appropriate
(2) use some test like abs(b) < TOL for some suitable TOL (0.5?)
(3) use identical(all.equal(b,0),TRUE) like it says in identical.Rd
(4) use identical(all.equal(b,as.integer(0)),TRUE)

How does the List deal with this kind of problem?

Also, gcd() as written returns a non-integer.  Would the List recommend 
rewriting the last
line as

return(as.integer(Recall(b,a%%b)))

or not?


--
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From p.dalgaard at biostat.ku.dk  Tue Mar  8 10:45:26 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 08 Mar 2005 10:45:26 +0100
Subject: [R] a==0 vs as.integer(a)==0 vs all.equal(a,0)
In-Reply-To: <0e18b9f7126370cea830727f44e733b7@soc.soton.ac.uk>
References: <0e18b9f7126370cea830727f44e733b7@soc.soton.ac.uk>
Message-ID: <x2sm36eaix.fsf@biostat.ku.dk>

Robin Hankin <r.hankin at soc.soton.ac.uk> writes:

> hi
> 
> 
> ?integer says:
> 
>       Note that on almost all implementations of R the range of
>       representable integers is restricted to about +/-2*10^9: 'double's
>       can hold much larger integers exactly.
> 
> 
> I am getting very confused as to when to use integers and when not to.
> In my line
> I need exact comparisons of large integer-valued arrays, so I often
> use as.integer(),
> but the above seems to tell me that doubles might  be better.
> 
> Consider the following R idiom of Euclid's algorithm for the highest
> common factor
> of two positive integers:
> 
>    gcd <- function(a, b){
>      if (b == 0){ return(a)}
>      return(Recall(b, a%%b))
>    }
> 
> If I call this with gcd(10,12), for example, then  a%%b is not an
> integer, so the first
> line of the function, testing b for being zero, isn't legitimate.
> 
> OK, so I have some options:
> 
> (1) stick in "a <- as.integer(a),  b <- as.integer(b)" into the
> function:  then a%%b *will* be an
>                 integer and the "==" test is appropriate
> (2) use some test like abs(b) < TOL for some suitable TOL (0.5?)
> (3) use identical(all.equal(b,0),TRUE) like it says in identical.Rd
> (4) use identical(all.equal(b,as.integer(0)),TRUE)
> 
> How does the List deal with this kind of problem?
> 
> Also, gcd() as written returns a non-integer.  Would the List
> recommend rewriting the last
> line as
> 
> return(as.integer(Recall(b,a%%b)))
> 
> or not?

Not if you want things to work in the large-integer domain...

You're in somewhat murky waters here because it all has to do with
whether you can rely on the floating point aritmetic being exact for
integers up to 2^53. *If* that works, then there's really no reason to
distrust "==" in this context and the gcd() works as originally
written. You might consider wrapping it in a function that checks
whether a and b are both (1) in range and (2) that they are integers
in the sense that round(x)==x. (Failing 2, you likely get an infinite
recursion). 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From murdoch at stats.uwo.ca  Tue Mar  8 10:56:30 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 08 Mar 2005 09:56:30 +0000
Subject: [R] a==0 vs as.integer(a)==0 vs all.equal(a,0)
In-Reply-To: <0e18b9f7126370cea830727f44e733b7@soc.soton.ac.uk>
References: <0e18b9f7126370cea830727f44e733b7@soc.soton.ac.uk>
Message-ID: <glrq21tldm53qh2n7lqd6f73prgb768asp@4ax.com>

On Tue, 8 Mar 2005 09:03:43 +0000, Robin Hankin
<r.hankin at soc.soton.ac.uk> wrote :

>hi
>
>
>?integer says:
>
>      Note that on almost all implementations of R the range of
>      representable integers is restricted to about +/-2*10^9: 'double's
>      can hold much larger integers exactly.
>
>
>I am getting very confused as to when to use integers and when not to.  
>In my line
>I need exact comparisons of large integer-valued arrays, so I often use 
>as.integer(),
>but the above seems to tell me that doubles might  be better.
>
>Consider the following R idiom of Euclid's algorithm for the highest 
>common factor
>of two positive integers:
>
>   gcd <- function(a, b){
>     if (b == 0){ return(a)}
>     return(Recall(b, a%%b))
>   }
>
>If I call this with gcd(10,12), for example, then  a%%b is not an 
>integer, so the first
>line of the function, testing b for being zero, isn't legitimate.

When you say it isn't legitimate, you mean that it violates the advice
never to use exact comparison on floating point values?

I think that's just advice, it's not a hard and fast rule.  If you
happen to know that the values being compared have been calculated and
stored exactly, then "==" is valid.  In your function, when a and b
are integers that are within some range (I'm not sure what it is, but
it approaches +/- 2^53), the %% operator should return exact results.
(Does it do so on all platforms?  I'm not sure, but I'd call it a bug
if it didn't unless a and/or b were very close to the upper limit of
exactly representable integers.)

Do you know of examples where a and b are integers stored in floating
point, and a %% b returns a value that is different from as.integer(a)
%% as.integer(b)?


>
>OK, so I have some options:
>
>(1) stick in "a <- as.integer(a),  b <- as.integer(b)" into the 
>function:  then a%%b *will* be an
>                integer and the "==" test is appropriate
>(2) use some test like abs(b) < TOL for some suitable TOL (0.5?)
>(3) use identical(all.equal(b,0),TRUE) like it says in identical.Rd
>(4) use identical(all.equal(b,as.integer(0)),TRUE)

I'd suggest

(5) Use your gcd function almost as above, but modified to work on
vectors:

   gcd <- function(a, b){
     result <- a
     nonzero <- b != 0
     if (any(nonzero))
       result[nonzero] <- Recall(b[nonzero], a[nonzero] %% b[nonzero])
     return(result)
   }

>How does the List deal with this kind of problem?
>
>Also, gcd() as written returns a non-integer.  Would the List recommend 
>rewriting the last
>line as
>
>return(as.integer(Recall(b,a%%b)))
>
>or not?

I'd say not.  Your original function returns integer when both a and b
are stored as integers, and double when at least one of them is not.
That seems like reasonable behaviour to me.

Duncan Murdoch



From ripley at stats.ox.ac.uk  Tue Mar  8 11:42:29 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 8 Mar 2005 10:42:29 +0000 (GMT)
Subject: [R] a==0 vs as.integer(a)==0 vs all.equal(a,0)
In-Reply-To: <glrq21tldm53qh2n7lqd6f73prgb768asp@4ax.com>
References: <0e18b9f7126370cea830727f44e733b7@soc.soton.ac.uk>
	<glrq21tldm53qh2n7lqd6f73prgb768asp@4ax.com>
Message-ID: <Pine.LNX.4.61.0503081032480.9388@gannet.stats>

On Tue, 8 Mar 2005, Duncan Murdoch wrote:

> On Tue, 8 Mar 2005 09:03:43 +0000, Robin Hankin
> <r.hankin at soc.soton.ac.uk> wrote :
>
>> hi
>>
>>
>> ?integer says:
>>
>>      Note that on almost all implementations of R the range of
>>      representable integers is restricted to about +/-2*10^9: 'double's
>>      can hold much larger integers exactly.
>>
>>
>> I am getting very confused as to when to use integers and when not to.
>> In my line
>> I need exact comparisons of large integer-valued arrays, so I often use
>> as.integer(),
>> but the above seems to tell me that doubles might  be better.
>>
>> Consider the following R idiom of Euclid's algorithm for the highest
>> common factor
>> of two positive integers:
>>
>>   gcd <- function(a, b){
>>     if (b == 0){ return(a)}
>>     return(Recall(b, a%%b))
>>   }
>>
>> If I call this with gcd(10,12), for example, then  a%%b is not an
>> integer, so the first
>> line of the function, testing b for being zero, isn't legitimate.
>
> When you say it isn't legitimate, you mean that it violates the advice
> never to use exact comparison on floating point values?
>
> I think that's just advice, it's not a hard and fast rule.  If you
> happen to know that the values being compared have been calculated and
> stored exactly, then "==" is valid.  In your function, when a and b
> are integers that are within some range (I'm not sure what it is, but
> it approaches +/- 2^53), the %% operator should return exact results.
> (Does it do so on all platforms?  I'm not sure, but I'd call it a bug
> if it didn't unless a and/or b were very close to the upper limit of
> exactly representable integers.)

It is supposed to do so up to (but not including)
.Machine$double.base ^ .Machine$double.digits,
normally 2^53, irrespective of sign.  (These are computed at run-time, 
so one can be pretty confident about them, at least if your FPU is 
bug-free.)

> Do you know of examples where a and b are integers stored in floating
> point, and a %% b returns a value that is different from as.integer(a)
> %% as.integer(b)?

Yes (see the NEWS for R-devel), but only for large integers where the 
second is NA.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Markus.Gesmann at lloyds.com  Tue Mar  8 12:29:49 2005
From: Markus.Gesmann at lloyds.com (Gesmann, Markus)
Date: Tue, 08 Mar 2005 11:29:49 +0000
Subject: [R] To convert an adjacency list model into a nested set model
Message-ID: <321C3EEBDB00C24185705B8BF733DADD0503F6FF@LNVCNTEXCH01.corp.lloydsnet>

Dear R-help

I am wondering if somebody wrote some code to convert an adjacency list
model into a nested set model.
In principal I want to do the same as John Celko mentioned it here with
SQL:
http://groups.google.co.uk/groups?hl=en&lr=lang_en&selm=8j0n05%24n31%241
%40nnrp1.deja.com

Assume you have a tree structure like this
    	        Albert 
             /       \
           /           \
         Bert        Chuck 
                   /    |   \
                 /      |     \
               /        |       \
             /          |         \
        Donna        Eddie       Fred

in an adjacency list model:

> emp=c("Albert", "Bert", "Chuck", "Donna", "Eddie", "Fred")
> boss=c(NA, "Albert", "Albert", "Chuck", "Chuck", "Chuck")
> print(Personnel<-data.frame(emp, boss))
     emp   boss
1 Albert   <NA>
2   Bert Albert
3  Chuck Albert
4  Donna  Chuck
5  Eddie  Chuck
6   Fred  Chuck

Then it is quite hard to find the all the supervisors of one employee.
John's suggestion is to convert the adjacency list model into a nested
set model.
The organizational chart would look like this as a directed graph:

            Albert (1,12)
            /        \
          /            \
    Bert (2,3)    Chuck (4,11)
                   /    |   \
                 /      |     \
               /        |       \
             /          |         \
        Donna (5,6)  Eddie (7,8)  Fred (9,10)

The data is than stored in the following form:

> lft=c(1,2,4,5,7,9)
> rgt=c(12,3,11,6,8,10)
> print(Per<-data.frame(emp, lft, rgt))
  emp lft rgt
1 Albert   1  12
2   Bert   2   3
3  Chuck   4  11
4  Donna   5   6
5  Eddie   7   8
6   Fred   9  10

To find now the supervisor of an employee all you have to do is to look
where the employees lft figure is between lft and rgt. The supervisors
of Eddie are therefore
> subset(Per, lft < 7 & rgt > 7)
     emp lft rgt
1 Albert   1  12
3  Chuck   4  11

In the site mentioned above John provides also some code to transform a
adjacency list model into a nested set model. 
Does somebody know if there is already a package for this in R? 

Kind Regards

Markus Gesmann



************LNSCNTMCS01***************************************************
The information in this E-Mail and in any attachments is CONFIDENTIAL and may be privileged.  If you are NOT the intended recipient, please destroy this message and notify the sender immediately.  You should NOT retain, copy or use this E-mail for any purpose, nor disclose all or any part of its contents to any other person or persons.

Any views expressed in this message are those of the individual sender, EXCEPT where the sender specifically states them to be the views of Lloyd's.

Lloyd's may monitor the content of E-mails sent and received via its
network for viruses or unauthorised use and for other lawful
business purposes."

Lloyd's is authorised under the Financial Services and Markets Act 2000



From ripley at stats.ox.ac.uk  Tue Mar  8 12:51:09 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 8 Mar 2005 11:51:09 +0000 (GMT)
Subject: [R] How can we ring a bell in Windows?
In-Reply-To: <16941.23815.382837.532001@stat.math.ethz.ch>
References: <20050307163107.63099.qmail@web17110.mail.tpe.yahoo.com>
	<4e2p21947nh3ofuorh8uvrrl08or1h4cj2@4ax.com>
	<Pine.LNX.4.61.0503071816280.7898@gannet.stats>
	<jtap21pbp7f2hrtfpqtfbfbrdbkt4c9hms@4ax.com>
	<16941.23815.382837.532001@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.61.0503081141310.10099@gannet.stats>

On Tue, 8 Mar 2005, Martin Maechler wrote:

>>>>>> "Duncan" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>>     on Mon, 07 Mar 2005 19:32:17 +0000 writes:
>
>    Duncan> On Mon, 7 Mar 2005 18:18:37 +0000 (GMT), Prof Brian
>    Duncan> Ripley <ripley at stats.ox.ac.uk> wrote :
>
>    >> On Mon, 7 Mar 2005, Duncan Murdoch wrote:
>    >>
>    >>> On Tue, 8 Mar 2005 00:31:07 +0800 (CST), Lu Joseph
>    >>> <c_joseph_lu at yahoo.com.tw> wrote :
>    >>>
>    >>>> Hello useRs,
>    >>>>
>    >>>> Is there a way to write code in R to ring a bell in
>    >>>> Windows?
>    >>>  If you load the tcltk package, then
>    >>>
>    >>> tkbell()
>    >>>
>    >>> will get you a bell on more platforms than just Windows.
>    >>> If you don't want to use tcltk, then you could call the
>    >>> Windows API function MessageBeep from some C code, but I
>    >>> don't think we have a "bell" or "beep" function in the
>    >>> standard R packages.
>    >>  But there is the ANSI "\a": cat("\n") works as expected,
>    >> on all platforms.
>
> {and of course,   cat("\a")   was meant above}
>
>    Duncan> Perhaps we should have a beep() or bell() function,
>    Duncan> to remind those of us who never knew all the C
>    Duncan> escapes and wouldn't have guessed that the ancient
>    Duncan> ASCII control codes still function.

Well, they are in the current C99 standard, section 5.2.2.

>    Duncan> I'll put it on my list...
>    Duncan> Duncan Murdoch
>
> good.  Yes that would be a very sensible encapsulation of
> functionality.
>
> Note that ASCII control codes don't work on all
> kinds of terminals, e.g., they don't work in ESS  --- but ESS
> could be made to react smartly to a beep() function call.

Why does ESS implement only some of the ANSI/C control codes? That looks 
like an ESS deficiency.  I have never come across any other terminal that 
did not.  These are in the ISO C standard, although the "a" is for 
"alarm", and that need not be a sound (it says "audible or visible").
So alarm() would be better than beep().

Would it not be better to correct the problem in ESS: there are lots of 
other ways that \a might be sent to stdout?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From f.harrell at vanderbilt.edu  Tue Mar  8 14:21:19 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Tue, 08 Mar 2005 07:21:19 -0600
Subject: [R] Quantian
Message-ID: <422DA6CF.6000705@vanderbilt.edu>

Congratulations Dirk on the article in linuxtoday.com today about Quantian.

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From sebastien_ballesteros at yahoo.fr  Tue Mar  8 14:23:32 2005
From: sebastien_ballesteros at yahoo.fr (=?iso-8859-1?q?S=E9bastien=20Ballesteros?=)
Date: Tue, 8 Mar 2005 14:23:32 +0100 (CET)
Subject: [R] Non-linear minimization
Message-ID: <20050308132332.92495.qmail@web26604.mail.ukl.yahoo.com>

hello, I have got some trouble with R functions nlm(),
nls() or optim() : I would like to fit 3 parameters
which must stay in a precise interval. For exemple
with nlm() :

fn<-function(p) sum((dN-estdata(p[1],p[2],p[3]))^2)
out<-nlm(fn, p=c(4, 17, 5),
hessian=TRUE,print.level=2)

with estdata() a function which returns value to fit
with dN (observed data vactor)

My problem is that only optim() allows me to set
parameters interval with "L-BFGS-B" method but this
one doesn't work in my case.

I have heard about nls2 package (www.inra.fr/bia) but
it doesn't work on Windows.

Do you know any solutions

Thank's a lot for reading my post

Best regards

Sebastien
INA P-G ecology dpt



From ligges at statistik.uni-dortmund.de  Tue Mar  8 14:53:43 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 08 Mar 2005 14:53:43 +0100
Subject: [R] Non-linear minimization
In-Reply-To: <20050308132332.92495.qmail@web26604.mail.ukl.yahoo.com>
References: <20050308132332.92495.qmail@web26604.mail.ukl.yahoo.com>
Message-ID: <422DAE67.8000601@statistik.uni-dortmund.de>

S?bastien Ballesteros wrote:
> hello, I have got some trouble with R functions nlm(),
> nls() or optim() : I would like to fit 3 parameters
> which must stay in a precise interval. For exemple
> with nlm() :
> 
> fn<-function(p) sum((dN-estdata(p[1],p[2],p[3]))^2)
> out<-nlm(fn, p=c(4, 17, 5),
> hessian=TRUE,print.level=2)
> 
> with estdata() a function which returns value to fit
> with dN (observed data vactor)
> 
> My problem is that only optim() allows me to set
> parameters interval with "L-BFGS-B" method but this
> one doesn't work in my case.
> 
> I have heard about nls2 package (www.inra.fr/bia) but
> it doesn't work on Windows.


"it doesn't work on Windows" is a very gentle description in this 
particular case...


> Do you know any solutions

A typical trick is to redefine the function so that for points outside 
the boundaries increasing penalties are added (if you know enough about 
your function).

Uwe Ligges


> Thank's a lot for reading my post
> 
> Best regards
> 
> Sebastien
> INA P-G ecology dpt
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From matthew_wiener at merck.com  Tue Mar  8 14:57:21 2005
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Tue, 8 Mar 2005 08:57:21 -0500
Subject: [R] Non-linear minimization
Message-ID: <45AAE6FD142DCB43A38C00A11FF5DF3E049940AE@uswsmx03.merck.com>

I have had my best luck by re-parametrizing so that I no longer needed
restrictions.  For example, if parameters must be positive, then I optimize
over parameters in log space, taking the exponential within my function.
This requires small changes to the function I'm optimizing (and the
gradient, if supplied), but, for me at least, has worked better than trying
to enforce box constraints as in L-BFGS-B.

Hope this helps,

Matt Wiener

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of S?bastien Ballesteros
Sent: Tuesday, March 08, 2005 8:24 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Non-linear minimization


hello, I have got some trouble with R functions nlm(),
nls() or optim() : I would like to fit 3 parameters
which must stay in a precise interval. For exemple
with nlm() :

fn<-function(p) sum((dN-estdata(p[1],p[2],p[3]))^2)
out<-nlm(fn, p=c(4, 17, 5),
hessian=TRUE,print.level=2)

with estdata() a function which returns value to fit
with dN (observed data vactor)

My problem is that only optim() allows me to set
parameters interval with "L-BFGS-B" method but this
one doesn't work in my case.

I have heard about nls2 package (www.inra.fr/bia) but
it doesn't work on Windows.

Do you know any solutions

Thank's a lot for reading my post

Best regards

Sebastien
INA P-G ecology dpt

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From dimitris.rizopoulos at med.kuleuven.ac.be  Tue Mar  8 15:05:34 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Tue, 8 Mar 2005 15:05:34 +0100
Subject: [R] Non-linear minimization
References: <20050308132332.92495.qmail@web26604.mail.ukl.yahoo.com>
Message-ID: <002201c523e7$e5af36d0$0540210a@www.domain>

maybe you could re-parameterize the problem, e.g.,

p \in (a, b)
p^* = (p - a) / (b - a) \in (0, 1)
x = qlogis(p^*) \in \Re

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm



----- Original Message ----- 
From: "S?bastien Ballesteros" <sebastien_ballesteros at yahoo.fr>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, March 08, 2005 2:23 PM
Subject: [R] Non-linear minimization


> hello, I have got some trouble with R functions nlm(),
> nls() or optim() : I would like to fit 3 parameters
> which must stay in a precise interval. For exemple
> with nlm() :
>
> fn<-function(p) sum((dN-estdata(p[1],p[2],p[3]))^2)
> out<-nlm(fn, p=c(4, 17, 5),
> hessian=TRUE,print.level=2)
>
> with estdata() a function which returns value to fit
> with dN (observed data vactor)
>
> My problem is that only optim() allows me to set
> parameters interval with "L-BFGS-B" method but this
> one doesn't work in my case.
>
> I have heard about nls2 package (www.inra.fr/bia) but
> it doesn't work on Windows.
>
> Do you know any solutions
>
> Thank's a lot for reading my post
>
> Best regards
>
> Sebastien
> INA P-G ecology dpt
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ramzi_feg at yahoo.fr  Tue Mar  8 16:44:10 2005
From: ramzi_feg at yahoo.fr (Ramzi Feghali)
Date: Tue, 8 Mar 2005 16:44:10 +0100 (CET)
Subject: [R] Dataframe modification
Message-ID: <20050308154410.27418.qmail@web50001.mail.yahoo.com>

Hello,
I have a problem and wish if anybody have a quick
solution or function or if this question was asked
before and you could give me the date to look in the
archives for the response.
My problem is that I have a dataframe D[663,40] with
only  one column with repeated values lines and a
factor with 4 levels.
I want to reorganize my dataframe, create a dataframe
D1[x,40*4] and put the repeated values in one line so
that all the factors will be in columns. For the
values with a missing level factor I want to keep
empty the concerning place.
For example if i a have this dataframe:

A	B	C								
32	a	14								
32	b	22								
55	a	44								
55	b	77								
55	c	55								
55	d	44								
83	c	77								
83	d	55								
83	e	44						
I want to transform it to have this one: 

32	a	14	b	22						
55	a	44	b	77	c	55				
83					c	77	d	55	e	44


Thanks & best regards



From m_osm at gmx.net  Tue Mar  8 17:31:18 2005
From: m_osm at gmx.net (Mahdi Osman)
Date: Tue, 8 Mar 2005 17:31:18 +0100 (MET)
Subject: [R] ESS
Message-ID: <18302.1110299478@www43.gmx.net>

Hi all,

I have got a dataframe in coma delimted text format. My ESS and R processes
are working well and active. I can read R help files and documentations from
inside ESS.

Can I perform anayltical operations such as (glm, plot ect) on elements of
my dataframe (variables) from within ESS? I could do these tasks directly in
Rconsole and would like to them in ESS directly.

How can I sumbit commandlines relevant to my datafrom to R?

Thanks for your help


Cheers

Mahdi

-- 
-----------------------------------
Mahdi Osman (PhD)
E-mail: m_osm at gmx.net
-----------------------------------

DSL Komplett von GMX +++ Supergnstig und stressfrei einsteigen!
AKTION "Kein Einrichtungspreis" nutzen: http://www.gmx.net/de/go/dsl



From ggrothendieck at myway.com  Tue Mar  8 17:19:51 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 8 Mar 2005 16:19:51 +0000 (UTC)
Subject: [R] Dataframe modification
References: <20050308154410.27418.qmail@web50001.mail.yahoo.com>
Message-ID: <loom.20050308T171834-742@post.gmane.org>

Ramzi Feghali <ramzi_feg <at> yahoo.fr> writes:

: 
: Hello,
: I have a problem and wish if anybody have a quick
: solution or function or if this question was asked
: before and you could give me the date to look in the
: archives for the response.
: My problem is that I have a dataframe D[663,40] with
: only  one column with repeated values lines and a
: factor with 4 levels.
: I want to reorganize my dataframe, create a dataframe
: D1[x,40*4] and put the repeated values in one line so
: that all the factors will be in columns. For the
: values with a missing level factor I want to keep
: empty the concerning place.
: For example if i a have this dataframe:
: 
: A	B	C							
	
: 32	a	14							
	
: 32	b	22							
	
: 55	a	44							
	
: 55	b	77							
	
: 55	c	55							
	
: 55	d	44							
	
: 83	c	77							
	
: 83	d	55							
	
: 83	e	44						
: I want to transform it to have this one: 
: 
: 32	a	14	b	22					
	
: 55	a	44	b	77	c	55			
	
: 83					c	77	d	55	e
	44
: 



Is this good enough?

R> # first solution
R> reshape(D, idvar="A", timevar="B", direction = "wide")
   A C.a C.b C.c C.d C.e
1 32  14  22  NA  NA  NA
3 55  44  77  55  44  NA
7 83  NA  NA  77  55  44

R> # second solution
R> xtabs(C ~ A + B, D)
    B
A     a  b  c  d  e
  32 14 22  0  0  0
  55 44 77 55 44  0
  83  0  0 77 55 44



From jeaneid at chass.utoronto.ca  Tue Mar  8 17:48:40 2005
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Tue, 8 Mar 2005 11:48:40 -0500
Subject: [R] ESS
In-Reply-To: <18302.1110299478@www43.gmx.net>
Message-ID: <Pine.SGI.4.40.0503081146410.16691987-100000@origin.chass.utoronto.ca>

try and read the ess manual a bit and look at the folowing reference card

http://stat.ethz.ch/ESS/refcard.pdf

On Tue, 8 Mar 2005, Mahdi Osman wrote:

> Hi all,
>
> I have got a dataframe in coma delimted text format. My ESS and R processes
> are working well and active. I can read R help files and documentations from
> inside ESS.
>
> Can I perform anayltical operations such as (glm, plot ect) on elements of
> my dataframe (variables) from within ESS? I could do these tasks directly in
> Rconsole and would like to them in ESS directly.
>
> How can I sumbit commandlines relevant to my datafrom to R?
>
> Thanks for your help
>
>
> Cheers
>
> Mahdi
>
> --
> -----------------------------------
> Mahdi Osman (PhD)
> E-mail: m_osm at gmx.net
> -----------------------------------
>
> DSL Komplett von GMX +++ Supergnstig und stressfrei einsteigen!
> AKTION "Kein Einrichtungspreis" nutzen: http://www.gmx.net/de/go/dsl
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From jrgold at insightful.com  Tue Mar  8 17:43:40 2005
From: jrgold at insightful.com (Jill Goldschneider)
Date: Tue, 8 Mar 2005 08:43:40 -0800
Subject: [R] Job: Life Sciences Statistical Computing,
	Insightful Corp. Seattle
Message-ID: <74653ECF95C67448BA99696A2D7F411B2EA28C@se2kexch01.insightful.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050308/7c7404c8/attachment.pl

From biocperi at yahoo.com  Tue Mar  8 17:57:05 2005
From: biocperi at yahoo.com (S Peri)
Date: Tue, 8 Mar 2005 08:57:05 -0800 (PST)
Subject: [R] Pattern recognition
In-Reply-To: 6667
Message-ID: <20050308165705.62181.qmail@web50008.mail.yahoo.com>

Dear group, 
 
A data matrix when plotted as a line plot, I see
several 
patterns. For example, how my students performed for
different courses they took this academic year. I need
to find out a pattern divided into three categories...
say excellent, mediocral and worst.  How can I be able
to fix a threshold and seperate the patterns into
these 3 categories. The question being asked is:
I want to pick those students who are exceptionally
good in a course and exceptionally bad in a course
(here 2 bins) and third category being, for a given
course i did not see any students who performed either
good or bad (pretty much a straight line or all
students behave the same way).

my question is Can I do this in R. If so, would you
please suggest some good tutorials, considering the
fact that i am not a statistician.

The arbitarary matrix is:
a,b,c,d - On X-axis
Stu. 1 - 5 : on Y-axis,


	Stu1   stu2    stu3   stu4     stu5
a	1	2	7	3	2
b	2	2	3	2	3
c	2	1	2	3	2
d	1	2	6	2	1


Thanks
P.



From biocperi at yahoo.com  Tue Mar  8 18:14:39 2005
From: biocperi at yahoo.com (S Peri)
Date: Tue, 8 Mar 2005 09:14:39 -0800 (PST)
Subject: [R] Pattern recognition
In-Reply-To: 6667
Message-ID: <20050308171439.82606.qmail@web50003.mail.yahoo.com>

A small correction:

 a,b,c,d - On X-axis
 course points : on Y-axis for all students. 


2. I do not know if this can be called pattern
recognition. What i mean is the line patterns in the
line graph. 

P



--- S Peri <biocperi at yahoo.com> wrote:
> Dear group, 
>  
> A data matrix when plotted as a line plot, I see
> several 
> patterns. For example, how my students performed for
> different courses they took this academic year. I
> need
> to find out a pattern divided into three
> categories...
> say excellent, mediocral and worst.  How can I be
> able
> to fix a threshold and seperate the patterns into
> these 3 categories. The question being asked is:
> I want to pick those students who are exceptionally
> good in a course and exceptionally bad in a course
> (here 2 bins) and third category being, for a given
> course i did not see any students who performed
> either
> good or bad (pretty much a straight line or all
> students behave the same way).
> 
> my question is Can I do this in R. If so, would you
> please suggest some good tutorials, considering the
> fact that i am not a statistician.
> 
> The arbitarary matrix is:
> a,b,c,d - On X-axis
> Stu. 1 - 5 : on Y-axis,
> 
> 
> 	Stu1   stu2    stu3   stu4     stu5
> a	1	2	7	3	2
> b	2	2	3	2	3
> c	2	1	2	3	2
> d	1	2	6	2	1
> 
> 
> Thanks
> P.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From ggrothendieck at myway.com  Tue Mar  8 18:19:12 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 8 Mar 2005 17:19:12 +0000 (UTC)
Subject: [R] To convert an adjacency list model into a nested set model
References: <321C3EEBDB00C24185705B8BF733DADD0503F6FF@LNVCNTEXCH01.corp.lloydsnet>
Message-ID: <loom.20050308T181636-487@post.gmane.org>

Gesmann, Markus <Markus.Gesmann <at> lloyds.com> writes:

: 
: Dear R-help
: 
: I am wondering if somebody wrote some code to convert an adjacency list
: model into a nested set model.
: In principal I want to do the same as John Celko mentioned it here with
: SQL:
: http://groups.google.co.uk/groups?hl=en&lr=lang_en&selm=8j0n05%24n31%241
: %40nnrp1.deja.com
: 
: Assume you have a tree structure like this
:     	        Albert 
:              /       \
:            /           \
:          Bert        Chuck 
:                    /    |   \
:                  /      |     \
:                /        |       \
:              /          |         \
:         Donna        Eddie       Fred
: 
: in an adjacency list model:
: 
: > emp=c("Albert", "Bert", "Chuck", "Donna", "Eddie", "Fred")
: > boss=c(NA, "Albert", "Albert", "Chuck", "Chuck", "Chuck")
: > print(Personnel<-data.frame(emp, boss))
:      emp   boss
: 1 Albert   <NA>
: 2   Bert Albert
: 3  Chuck Albert
: 4  Donna  Chuck
: 5  Eddie  Chuck
: 6   Fred  Chuck
: 
: Then it is quite hard to find the all the supervisors of one employee.
: John's suggestion is to convert the adjacency list model into a nested
: set model.
: The organizational chart would look like this as a directed graph:
: 
:             Albert (1,12)
:             /        \
:           /            \
:     Bert (2,3)    Chuck (4,11)
:                    /    |   \
:                  /      |     \
:                /        |       \
:              /          |         \
:         Donna (5,6)  Eddie (7,8)  Fred (9,10)
: 
: The data is than stored in the following form:
: 
: > lft=c(1,2,4,5,7,9)
: > rgt=c(12,3,11,6,8,10)
: > print(Per<-data.frame(emp, lft, rgt))
:   emp lft rgt
: 1 Albert   1  12
: 2   Bert   2   3
: 3  Chuck   4  11
: 4  Donna   5   6
: 5  Eddie   7   8
: 6   Fred   9  10
: 
: To find now the supervisor of an employee all you have to do is to look
: where the employees lft figure is between lft and rgt. The supervisors
: of Eddie are therefore
: > subset(Per, lft < 7 & rgt > 7)
:      emp lft rgt
: 1 Albert   1  12
: 3  Chuck   4  11
: 
: In the site mentioned above John provides also some code to transform a
: adjacency list model into a nested set model. 
: Does somebody know if there is already a package for this in R? 
: 
: Kind Regards
: 
: Markus Gesmann
: 

This is not a direct answer to getting a nesting from an adjacency
but the following is easy to do and gives all the same info.


Note that if A is the adjacency matrix of children (rows) and ]
parents (columns) then A^n is the matrix defining ancestors n 
generations away and exp(A) is a weighted version of that with
A^i weighted by i! (These expressions are mathematics, not R.)  
Thus:

empf <- factor(emp, level = union(emp, boss))  # emp as factor
bossf <- factor(boss, level = union(emp, boss)) # ditto for boss

adj <- table(empf, bossf)  # i,j is 1 if j is boss of i

library(rmutil)  # http://popgen.unimaas.nl/~jlindsey/rcode.html
mexp(adj, type = "series") - diag(length(empf))

giving a matrix whose i,j-th entry is 1/n! if j is n-generations above i.
>From that you can get the info you need.



From ibergus at gmail.com  Tue Mar  8 18:43:16 2005
From: ibergus at gmail.com (Isaac Waisberg)
Date: Tue, 8 Mar 2005 17:43:16 +0000
Subject: [R] Multidimensional Scaling (MDS) in R
Message-ID: <8eb2df300503080943329d72cb@mail.gmail.com>

Hi;

I am working with the similarity matrix below and I would like to plot
a two-dimensional MDS solution such as each point in the plot has a
label.

This is what I did:

data <- read.table('c:/multivariate/mds/colour.txt',header=FALSE)
similarity <- as.dist(data)
distance <- 1-similarity
result.nmds <- nmds(distance)
plot(result.nmds)

(nmds and plot.nmds as defined at
labdsv.nr.usu.edu/splus_R/lab8/lab8.html; nmds simply calls isoMDS)

Colour.txt, containing the similaity matrix, reads as follows:

 1.0 .86 .42 .42 .18 .06 .07 .04 .02 .07 .09 .12 .13 .16
 .86 1.0 .50 .44 .22 .09 .07 .07 .02 .04 .07 .11 .13 .14
 .42 .50 1.0 .81 .47 .17 .10 .08 .02 .01 .02 .01 .05 .03
 .42 .44 .81 1.0 .54 .25 .10 .09 .02 .01 .01 .01 .02 .04
 .18 .22 .47 .54 1.0 .61 .31 .26 .07 .02 .02 .01 .02 .01
 .06 .09 .17 .25 .61 1.0 .62 .45 .14 .08 .02 .02 .02 .01
 .07 .07 .10 .10 .31 .62 1.0 .73 .22 .14 .05 .02 .02 .01
 .04 .07 .08 .09 .26 .45 .73 1.0 .33 .19 .04 .03 .02 .02
 .02 .02 .02 .02 .07 .14 .22 .33 1.0 .58 .37 .27 .20 .23
 .07 .04 .01 .01 .02 .08 .14 .19 .58 1.0 .74 .50 .41 .28
 .09 .07 .02 .01 .02 .02 .05 .04 .37 .74 1.0 .76 .62 .55
 .12 .11 .01 .01 .01 .02 .02 .03 .27 .50 .76 1.0 .85 .68
 .13 .13 .05 .02 .02 .02 .02 .02 .20 .41 .62 .85 1.0 .76
 .16 .14 .03 .04 .01 .01 .01 .02 .23 .28 .55 .68 .76 1.0
 
The first row corresponds to colour 1 (C1), the second to colour 2
(C2), and so on.

First, I'm not sure if this is correct or not. Second, obviously the
points in the plot are not labeled. I suppose I must add a labels
column and then print the labels together with the results. But, how
should I do it?

Many thanks,

Isaac



From ibergus at gmail.com  Tue Mar  8 18:43:16 2005
From: ibergus at gmail.com (Isaac Waisberg)
Date: Tue, 8 Mar 2005 17:43:16 +0000
Subject: [R] Multidimensional Scaling (MDS) in R
Message-ID: <8eb2df300503080943329d72cb@mail.gmail.com>

Hi;

I am working with the similarity matrix below and I would like to plot
a two-dimensional MDS solution such as each point in the plot has a
label.

This is what I did:

data <- read.table('c:/multivariate/mds/colour.txt',header=FALSE)
similarity <- as.dist(data)
distance <- 1-similarity
result.nmds <- nmds(distance)
plot(result.nmds)

(nmds and plot.nmds as defined at
labdsv.nr.usu.edu/splus_R/lab8/lab8.html; nmds simply calls isoMDS)

Colour.txt, containing the similaity matrix, reads as follows:

 1.0 .86 .42 .42 .18 .06 .07 .04 .02 .07 .09 .12 .13 .16
 .86 1.0 .50 .44 .22 .09 .07 .07 .02 .04 .07 .11 .13 .14
 .42 .50 1.0 .81 .47 .17 .10 .08 .02 .01 .02 .01 .05 .03
 .42 .44 .81 1.0 .54 .25 .10 .09 .02 .01 .01 .01 .02 .04
 .18 .22 .47 .54 1.0 .61 .31 .26 .07 .02 .02 .01 .02 .01
 .06 .09 .17 .25 .61 1.0 .62 .45 .14 .08 .02 .02 .02 .01
 .07 .07 .10 .10 .31 .62 1.0 .73 .22 .14 .05 .02 .02 .01
 .04 .07 .08 .09 .26 .45 .73 1.0 .33 .19 .04 .03 .02 .02
 .02 .02 .02 .02 .07 .14 .22 .33 1.0 .58 .37 .27 .20 .23
 .07 .04 .01 .01 .02 .08 .14 .19 .58 1.0 .74 .50 .41 .28
 .09 .07 .02 .01 .02 .02 .05 .04 .37 .74 1.0 .76 .62 .55
 .12 .11 .01 .01 .01 .02 .02 .03 .27 .50 .76 1.0 .85 .68
 .13 .13 .05 .02 .02 .02 .02 .02 .20 .41 .62 .85 1.0 .76
 .16 .14 .03 .04 .01 .01 .01 .02 .23 .28 .55 .68 .76 1.0
 
The first row corresponds to colour 1 (C1), the second to colour 2
(C2), and so on.

First, I'm not sure if this is correct or not. Second, obviously the
points in the plot are not labeled. I suppose I must add a labels
column and then print the labels together with the results. But, how
should I do it?

Many thanks,

Isaac



From wgshi2001 at yahoo.ca  Tue Mar  8 18:51:37 2005
From: wgshi2001 at yahoo.ca (Weiguang Shi)
Date: Tue, 8 Mar 2005 12:51:37 -0500 (EST)
Subject: [R] The null hypothesis in kpss test (kpss.test())
Message-ID: <20050308175137.56146.qmail@web30001.mail.mud.yahoo.com>

is that 'x' is level or trend stationary. I did this
 
  > s<-rnorm(1000)
  > kpss.test(s)
 
        KPSS Test for Level Stationarity
 
  data:  s
  KPSS Level = 0.0429, Truncation lag parameter = 7,
p-value = 0.1
 
  Warning message:
  p-value greater than printed p-value in:
kpss.test(s)

My question is whether p=0.1 is a good number to
reject 
N0? On the other hand, I have a series r and did the 
following:
  > plot.ts(r)
  > kpss.test(r)
 
        KPSS Test for Level Stationarity
 
  data:  r
  KPSS Level = 3.1955, Truncation lag parameter = 7,
p-value = 0.01
 
  Warning message:
  p-value smaller than printed p-value in:
kpss.test(r)

So this says we can have more confidence in saying r
is _not_ stationary? Should I worry about the
warnings?

Thanks very much.
Weiguang



From Achim.Zeileis at wu-wien.ac.at  Tue Mar  8 19:12:54 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Tue, 8 Mar 2005 19:12:54 +0100
Subject: [R] The null hypothesis in kpss test (kpss.test())
In-Reply-To: <20050308175137.56146.qmail@web30001.mail.mud.yahoo.com>
References: <20050308175137.56146.qmail@web30001.mail.mud.yahoo.com>
Message-ID: <20050308191254.3f39625e.Achim.Zeileis@wu-wien.ac.at>

As help(kpss.test) tells you: kpss.test() approximates the p values by
interpolation from a simulated table of critical values. As p values
larger than 0.1 are typically regarded to be non-significant and p
values smaller than 0.01 are typically regarded to be highly
significant, the corresponding critical values are only stored for the
range 0.1 to 0.01.

Hence...

On Tue, 8 Mar 2005 12:51:37 -0500 (EST) Weiguang Shi wrote:

> is that 'x' is level or trend stationary. I did this
>  
>   > s<-rnorm(1000)
>   > kpss.test(s)
>  
>         KPSS Test for Level Stationarity
>  
>   data:  s
>   KPSS Level = 0.0429, Truncation lag parameter = 7,
> p-value = 0.1
>  
>   Warning message:
>   p-value greater than printed p-value in:
> kpss.test(s)
> 
> My question is whether p=0.1 is a good number to
> reject N0? 

...stationarity cannot be rejected here (which is not surprising) and...

> On the other hand, I have a series r and did the 
> following:
>   > plot.ts(r)
>   > kpss.test(r)
>  
>         KPSS Test for Level Stationarity
>  
>   data:  r
>   KPSS Level = 3.1955, Truncation lag parameter = 7,
> p-value = 0.01
>  
>   Warning message:
>   p-value smaller than printed p-value in:
> kpss.test(r)

...stationarity is clearly rejected here.

> So this says we can have more confidence in saying r
> is _not_ stationary?

Yes (I guess. I'm not sure about `more confidence'...`more' than what?)
Z

> Should I worry about the warnings?
> 
> Thanks very much.
> Weiguang
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From wgshi2001 at yahoo.ca  Tue Mar  8 19:33:02 2005
From: wgshi2001 at yahoo.ca (Weiguang Shi)
Date: Tue, 8 Mar 2005 13:33:02 -0500 (EST)
Subject: [R] The null hypothesis in kpss test (kpss.test())
In-Reply-To: <20050308191254.3f39625e.Achim.Zeileis@wu-wien.ac.at>
Message-ID: <20050308183302.58769.qmail@web30009.mail.mud.yahoo.com>

Understood!
And thanks!

Weiguang

 --- Achim Zeileis <Achim.Zeileis at wu-wien.ac.at>
wrote: 
> As help(kpss.test) tells you: kpss.test()
> approximates the p values by
> interpolation from a simulated table of critical
> values. As p values
> larger than 0.1 are typically regarded to be
> non-significant and p
> values smaller than 0.01 are typically regarded to
> be highly
> significant, the corresponding critical values are
> only stored for the
> range 0.1 to 0.01.
> 
> Hence...



From f.calboli at imperial.ac.uk  Tue Mar  8 21:51:44 2005
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Tue, 08 Mar 2005 20:51:44 +0000
Subject: [R] removing message: [Previously saved workspace restored]
Message-ID: <1110315104.3357.1225.camel@localhost.localdomain>

Dear All, 

I saved by mistake the environment I was working in after typing q(),
and now I get the annoying message:

[Previously saved workspace restored]

I have already deleted all the objects in the environment, saving it as
an empty environment, so it's just a matter of nitpicking I suppose. The
message does not appear if I start R from any other place in the
directory tree.

I am reading ?Startup and related docs, but I am utterly failing to
understand how to remove [Previously saved workspace restored] when I
call R from the offending dir...

I am using R on Debian Sarge x86

Cheers,

Federico Calboli
-- 
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St Mary's Campus
Norfolk Place, London W2 1PG

Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From abunn at whrc.org  Tue Mar  8 21:54:47 2005
From: abunn at whrc.org (abunn)
Date: Tue, 8 Mar 2005 15:54:47 -0500
Subject: [R] coefficient of partial determination...partial r square [
	redux]
In-Reply-To: <3A822319EB35174CA3714066D590DCD50994E7F9@usrymx25.merck.com>
Message-ID: <NEBBIPHDAMMOKDKPOFFIOEKJDBAA.abunn@whrc.org>

Dr. C:

I implemented this example of partial r square from Neter et al.'s big blue
book. It's easily extendable to a three variable model (or more). I might
write it to work with class lm or glm if there is interest.

HTH, Andy


Applied Linear Statistical Models by John Neter, Michael H Kutner, William
Wasserman, Christopher J. Nachtsheim

Section 7.4 in my copy page 274:


# body fat example from Neter et al.
bf.dat <- read.csv("body.fat.data.csv", header = T)
#R > bf.dat
#     x1   x2   x3    y
#1  19.5 43.1 29.1 11.9
#2  24.7 49.8 28.2 22.8
#3  30.7 51.9 37.0 18.7
#4  29.8 54.3 31.1 20.1
#5  19.1 42.2 30.9 12.9
#6  25.6 53.9 23.7 21.7
#7  31.4 58.5 27.6 27.1
#8  27.9 52.1 30.6 25.4
#9  22.1 49.9 23.2 21.3
#10 25.5 53.5 24.8 19.3
#11 31.1 56.6 30.0 25.4
#12 30.4 56.7 28.3 27.2
#13 18.7 46.5 23.0 11.7
#14 19.7 44.2 28.6 17.8
#15 14.6 42.7 21.3 12.8
#16 29.5 54.4 30.1 23.9
#17 27.7 55.3 25.7 22.6
#18 30.2 58.6 24.6 25.4
#19 22.7 48.2 27.1 14.8
#20 25.2 51.0 27.5 21.1
#R >
# Not run:
#names(bf.dat) <- c('Triceps Skinfold Thickness', x2 = 'Thigh
Circumference', x3 = 'Midarm Circumference', y = 'Body Fat')
summary(bf.dat)
lm.x1 <- lm(y ~ x1, data = bf.dat)
lm.x2 <- lm(y ~ x2, data = bf.dat)
lm.x1.x2 <- lm(y ~ x1 + x2, data = bf.dat)

# SSR(x2|x1) = SSR(x1,x2) - SSR(x1)
ssr.x1.x2 <- sum(anova(lm.x1.x2)$"Sum Sq"[1:2])
ssr.x1    <- anova(lm.x1)$"Sum Sq"[1]
ssr.x2    <- anova(lm.x2)$"Sum Sq"[1]
ssr.x1.x2 - ssr.x1
# also
sse.x1    <- anova(lm.x1)$"Sum Sq"[2] # eq sum(lm.x1$resid^2)
sse.x2    <- anova(lm.x2)$"Sum Sq"[2] # eq sum(lm.x2$resid^2)

# The partial r2 of x1 while controlling for x2 is 0.031
# pr2_1.2 = SSR(x1|x2) / SSE(x2)
(ssr.x1.x2 - ssr.x2) / sse.x2
# The partial r2 of x2 while controlling for x1 is 0.232
# pr2_2.1 = SSR(x2|x1) / SSE(x1)
(ssr.x1.x2 - ssr.x1) / sse.x1



From rpeng at jhsph.edu  Tue Mar  8 22:00:29 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 08 Mar 2005 16:00:29 -0500
Subject: [R] removing message: [Previously saved workspace restored]
In-Reply-To: <1110315104.3357.1225.camel@localhost.localdomain>
References: <1110315104.3357.1225.camel@localhost.localdomain>
Message-ID: <422E126D.3070105@jhsph.edu>

R saves the workspace in a file called '.RData'.  Simply remove this 
file from your working directory.  Or if you startup R and get the 
message, try

unlink(".RData")

-roger

Federico Calboli wrote:
> Dear All, 
> 
> I saved by mistake the environment I was working in after typing q(),
> and now I get the annoying message:
> 
> [Previously saved workspace restored]
> 
> I have already deleted all the objects in the environment, saving it as
> an empty environment, so it's just a matter of nitpicking I suppose. The
> message does not appear if I start R from any other place in the
> directory tree.
> 
> I am reading ?Startup and related docs, but I am utterly failing to
> understand how to remove [Previously saved workspace restored] when I
> call R from the offending dir...
> 
> I am using R on Debian Sarge x86
> 
> Cheers,
> 
> Federico Calboli

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/



From f.calboli at imperial.ac.uk  Tue Mar  8 22:01:10 2005
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Tue, 08 Mar 2005 21:01:10 +0000
Subject: [R] removing message: [Previously saved workspace restored]
In-Reply-To: <45AAE6FD142DCB43A38C00A11FF5DF3E049940BD@uswsmx03.merck.com>
References: <45AAE6FD142DCB43A38C00A11FF5DF3E049940BD@uswsmx03.merck.com>
Message-ID: <1110315670.3357.1227.camel@localhost.localdomain>

On Tue, 2005-03-08 at 15:57 -0500, Wiener, Matthew wrote:
> Remove the (now empty, because you deleted all objects) file ".RData" from
> the directory.
> 
> Hope this helps,


Thanks, it did fix the problem.

Cheers,

Federico Calboli
-- 
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St Mary's Campus
Norfolk Place, London W2 1PG

Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From andy_liaw at merck.com  Tue Mar  8 22:01:55 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 8 Mar 2005 16:01:55 -0500
Subject: [R] removing message: [Previously saved workspace restored]
Message-ID: <3A822319EB35174CA3714066D590DCD50994E805@usrymx25.merck.com>

Either remove .RData in the directory, or start R with --no-restore option.

Andy

> From: Federico Calboli
> 
> Dear All, 
> 
> I saved by mistake the environment I was working in after typing q(),
> and now I get the annoying message:
> 
> [Previously saved workspace restored]
> 
> I have already deleted all the objects in the environment, 
> saving it as
> an empty environment, so it's just a matter of nitpicking I 
> suppose. The
> message does not appear if I start R from any other place in the
> directory tree.
> 
> I am reading ?Startup and related docs, but I am utterly failing to
> understand how to remove [Previously saved workspace restored] when I
> call R from the offending dir...
> 
> I am using R on Debian Sarge x86
> 
> Cheers,
> 
> Federico Calboli
> -- 
> Federico C. F. Calboli
> Department of Epidemiology and Public Health
> Imperial College, St Mary's Campus
> Norfolk Place, London W2 1PG
> 
> Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193
> 
> f.calboli [.a.t] imperial.ac.uk
> f.calboli [.a.t] gmail.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From jtk at cmp.uea.ac.uk  Tue Mar  8 22:59:22 2005
From: jtk at cmp.uea.ac.uk (Jan T. Kim)
Date: Tue, 8 Mar 2005 21:59:22 +0000
Subject: [R] removing message: [Previously saved workspace restored]
In-Reply-To: <1110315104.3357.1225.camel@localhost.localdomain>
References: <1110315104.3357.1225.camel@localhost.localdomain>
Message-ID: <20050308215922.GH11399@jtkpc.cmp.uea.ac.uk>

On Tue, Mar 08, 2005 at 08:51:44PM +0000, Federico Calboli wrote:

> I saved by mistake the environment I was working in after typing q(),
> and now I get the annoying message:
> 
> [Previously saved workspace restored]
> 
> I have already deleted all the objects in the environment, saving it as
> an empty environment, so it's just a matter of nitpicking I suppose. The
> message does not appear if I start R from any other place in the
> directory tree.
> 
> I am reading ?Startup and related docs, but I am utterly failing to
> understand how to remove [Previously saved workspace restored] when I
> call R from the offending dir...
> 
> I am using R on Debian Sarge x86

There is a file called .Rdata, containing the saved workspace, in the
"offending directory". Following Unix convention, the file is not normally
displayed by ls and other programs because its name begins with a dot.
See "Data permanency and removing objects" in the R-intro.

If you don't want the saved stuff anymore, simply delete that file.

Best regards, Jan
-- 
 +- Jan T. Kim -------------------------------------------------------+
 |    *NEW*    email: jtk at cmp.uea.ac.uk                               |
 |    *NEW*    WWW:   http://www.cmp.uea.ac.uk/people/jtk             |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*



From Achim.Zeileis at wu-wien.ac.at  Tue Mar  8 22:03:06 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Tue, 8 Mar 2005 22:03:06 +0100
Subject: [R] removing message: [Previously saved workspace restored]
In-Reply-To: <1110315104.3357.1225.camel@localhost.localdomain>
References: <1110315104.3357.1225.camel@localhost.localdomain>
Message-ID: <20050308220306.31ca5ff5.Achim.Zeileis@wu-wien.ac.at>

On Tue, 08 Mar 2005 20:51:44 +0000 Federico Calboli wrote:

> Dear All, 
> 
> I saved by mistake the environment I was working in after typing q(),
> and now I get the annoying message:
> 
> [Previously saved workspace restored]
> 
> I have already deleted all the objects in the environment, saving it
> as an empty environment, so it's just a matter of nitpicking I
> suppose. The message does not appear if I start R from any other place
> in the directory tree.

The saved workspace is stored in the .RData in that particular
directory. It is loaded when you start R in that directory. If you
remove the file, it cannot be loaded anymore.
Z

> I am reading ?Startup and related docs, but I am utterly failing to
> understand how to remove [Previously saved workspace restored] when I
> call R from the offending dir...
> 
> I am using R on Debian Sarge x86
> 
> Cheers,
> 
> Federico Calboli
> -- 
> Federico C. F. Calboli
> Department of Epidemiology and Public Health
> Imperial College, St Mary's Campus
> Norfolk Place, London W2 1PG
> 
> Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193
> 
> f.calboli [.a.t] imperial.ac.uk
> f.calboli [.a.t] gmail.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From facS93 at mors.hampshire.edu  Tue Mar  8 23:00:53 2005
From: facS93 at mors.hampshire.edu (shang stud)
Date: Tue, 8 Mar 2005 17:00:53 -0500 (EST)
Subject: [R] generically setting attributes of a function
Message-ID: <Pine.LNX.4.58.0503081652140.11842@mors.hampshire.edu>


Hello all:

I wonder if there is a generic way to assign the name of a function as an
attribute of the function. For example,

w = function(x) x^2;
attr(w, "name") =  "w";

This assigns the name attribute of function w to be "w".

Would it be possible to put the second line of the code inside the
function definition? I would like to avoid typing specifically the
name, "w", when assigning the attribute.

Many thanks in advance.

Fang



From tplate at acm.org  Tue Mar  8 23:18:16 2005
From: tplate at acm.org (Tony Plate)
Date: Tue, 08 Mar 2005 15:18:16 -0700
Subject: [R] glm and percentage data with many zero values
In-Reply-To: <42666EF1.7040901@ips.unibe.ch>
References: <200501201136.j0KBH1wd031095@hypatia.math.ethz.ch>
	<42666EF1.7040901@ips.unibe.ch>
Message-ID: <6.2.1.2.2.20050308151134.1a838578@mailhost.blackmesacapital.com>

A very quick and easy thing to do with count data is to add 1 (or 0.5) to 
all your counts (I'm sure you can work backwards from abundance data to 
counts and then forward again).  This gets rid of zero problems.  In some 
cases this approximates a Bayesian approach with a low-information prior 
(though I'm not at all sure whether this is the case with a glm with 
Poisson errors).

-- Tony Plate

At Wednesday 08:02 AM 4/20/2005, Christian Kamenik wrote:
>Dear all,
>
>I am interested in correctly testing effects of continuous environmental 
>variables and ordered factors on bacterial abundance. Bacterial abundance 
>is derived from counts and expressed as percentage. My problem is that the 
>abundance data contain many zero values:
>Bacteria <- 
>c(2.23,0,0.03,0.71,2.34,0,0.2,0.2,0.02,2.07,0.85,0.12,0,0.59,0.02,2.3,0.29,0.39,1.32,0.07,0.52,1.2,0,0.85,1.09,0,0.5,1.4,0.08,0.11,0.05,0.17,0.31,0,0.12,0,0.99,1.11,1.78,0,0,0,2.33,0.07,0.66,1.03,0.15,0.15,0.59,0,0.03,0.16,2.86,0.2,1.66,0.12,0.09,0.01,0,0.82,0.31,0.2,0.48,0.15)
>
>First I tried transforming the data (e.g., logit) but because of the zeros 
>I was not satisfied. Next I converted the percentages into integer values 
>by round(Bacteria*10) or ceiling(Bacteria*10) and calculated a glm with a 
>Poisson error structure; however, I am not very happy with this approach 
>because it changes the original percentage data substantially (e.g., 0.03 
>becomes either 0 or 1). The same is true for converting the percentages 
>into factors and calculating a multinomial or proportional-odds model 
>(anyway, I do not know if this would be a meaningful approach).
>I was searching the web and the best answer I could get was 
>http://www.biostat.wustl.edu/archives/html/s-news/1998-12/msg00010.html in 
>which several persons suggested quasi-likelihood. Would it be reasonable 
>to use a glm with quasipoisson? If yes, how I can I find the appropriate 
>variance function? Any other suggestions?
>
>Many thanks in advance, Christian
>
>
>================================
>
>
>Christian Kamenik
>Institute of Plant Sciences
>University of Bern
>Altenbergrain 21
>3013 Bern
>Switzerland
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From vograno at evafunds.com  Wed Mar  9 00:36:14 2005
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Tue, 8 Mar 2005 15:36:14 -0800
Subject: [R] how modify object in parent.env
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A58FF117@phost015.EVAFUNDS.intermedia.net>

Hi,
 
Is it possible to modify an object in the parent.env (as opposed to
re-bind)? Here is what I tried:
 
> x = 1:3
# try to modify the first element of x from within a new environment
> local(get("x", parent.env(environment()))[1] <- NA)
Error in eval(expr, envir, enclos) : Target of assignment expands to
non-language object

# On the other hand retrieval works just fine
> local(get("x", parent.env(environment()))[1])
[1] 1

Thanks,
Vadim



From ggrothendieck at myway.com  Wed Mar  9 00:45:39 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 8 Mar 2005 23:45:39 +0000 (UTC)
Subject: [R] generically setting attributes of a function
References: <Pine.LNX.4.58.0503081652140.11842@mors.hampshire.edu>
Message-ID: <loom.20050309T004439-702@post.gmane.org>

shang stud <facS93 <at> mors.hampshire.edu> writes:

: 
: Hello all:
: 
: I wonder if there is a generic way to assign the name of a function as an
: attribute of the function. For example,
: 
: w = function(x) x^2;
: attr(w, "name") =  "w";
: 
: This assigns the name attribute of function w to be "w".
: 
: Would it be possible to put the second line of the code inside the
: function definition? I would like to avoid typing specifically the
: name, "w", when assigning the attribute.
: 

structure(function(x) x^2, name = "w")



From Robert.McGehee at geodecapital.com  Wed Mar  9 00:48:16 2005
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Tue, 8 Mar 2005 18:48:16 -0500
Subject: [R] how modify object in parent.env
Message-ID: <67DCA285A2D7754280D3B8E88EB548020C946549@MSGBOSCLB2WIN.DMN1.FMR.COM>

This isn't an environment problem. Assigning something to a get call
doesn't make any sense. Use assign.

> a <- 5
> get("a") <- 10
Error: couldn't find function "get<-"

And from the ?assign help page, you can pick what environment you want
to make the assignment. Just pick the parent environment.


-----Original Message-----
From: Vadim Ogranovich [mailto:vograno at evafunds.com] 
Sent: Tuesday, March 08, 2005 6:36 PM
To: r-help at stat.math.ethz.ch
Subject: [R] how modify object in parent.env


Hi,
 
Is it possible to modify an object in the parent.env (as opposed to
re-bind)? Here is what I tried:
 
> x = 1:3
# try to modify the first element of x from within a new environment
> local(get("x", parent.env(environment()))[1] <- NA)
Error in eval(expr, envir, enclos) : Target of assignment expands to
non-language object

# On the other hand retrieval works just fine
> local(get("x", parent.env(environment()))[1])
[1] 1

Thanks,
Vadim

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Wed Mar  9 00:49:10 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 8 Mar 2005 18:49:10 -0500
Subject: [R] generically setting attributes of a function
Message-ID: <3A822319EB35174CA3714066D590DCD50994E809@usrymx25.merck.com>

If you can explain what you intend to do with that attribute, perhaps
someone might be able to help better.  Short of that, would the following
work for you?

> w <- structure(function(x) x^2, name="w")
> w
function(x) x^2
attr(,"name")
[1] "w"


Andy

> From: shang stud
> 
> Hello all:
> 
> I wonder if there is a generic way to assign the name of a 
> function as an
> attribute of the function. For example,
> 
> w = function(x) x^2;
> attr(w, "name") =  "w";
> 
> This assigns the name attribute of function w to be "w".
> 
> Would it be possible to put the second line of the code inside the
> function definition? I would like to avoid typing specifically the
> name, "w", when assigning the attribute.
> 
> Many thanks in advance.
> 
> Fang
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From vograno at evafunds.com  Wed Mar  9 01:03:20 2005
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Tue, 8 Mar 2005 16:03:20 -0800
Subject: [R] how modify object in parent.env
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A58FF11C@phost015.EVAFUNDS.intermedia.net>

Assign() re-binds the value, not modifies it (the latter is what I
needed) 

> -----Original Message-----
> From: McGehee, Robert [mailto:Robert.McGehee at geodecapital.com] 
> Sent: Tuesday, March 08, 2005 3:48 PM
> To: Vadim Ogranovich; r-help at stat.math.ethz.ch
> Subject: RE: [R] how modify object in parent.env
> 
> This isn't an environment problem. Assigning something to a 
> get call doesn't make any sense. Use assign.
> 
> > a <- 5
> > get("a") <- 10
> Error: couldn't find function "get<-"
> 
> And from the ?assign help page, you can pick what environment 
> you want to make the assignment. Just pick the parent environment.
> 
> 
> -----Original Message-----
> From: Vadim Ogranovich [mailto:vograno at evafunds.com]
> Sent: Tuesday, March 08, 2005 6:36 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] how modify object in parent.env
> 
> 
> Hi,
>  
> Is it possible to modify an object in the parent.env (as opposed to
> re-bind)? Here is what I tried:
>  
> > x = 1:3
> # try to modify the first element of x from within a new environment
> > local(get("x", parent.env(environment()))[1] <- NA)
> Error in eval(expr, envir, enclos) : Target of assignment expands to
> non-language object
> 
> # On the other hand retrieval works just fine
> > local(get("x", parent.env(environment()))[1])
> [1] 1
> 
> Thanks,
> Vadim
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From MSchwartz at MedAnalytics.com  Wed Mar  9 01:03:45 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Tue, 08 Mar 2005 18:03:45 -0600
Subject: [R] how modify object in parent.env
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A58FF117@phost015.EVAFUNDS.intermedia.net>
References: <C698D707214E6F4AB39AB7096C3DE5A58FF117@phost015.EVAFUNDS.intermedia.net>
Message-ID: <1110326626.6079.5.camel@horizons.localdomain>

On Tue, 2005-03-08 at 15:36 -0800, Vadim Ogranovich wrote:
> Hi,
>  
> Is it possible to modify an object in the parent.env (as opposed to
> re-bind)? Here is what I tried:
>  
> > x = 1:3
> # try to modify the first element of x from within a new environment
> > local(get("x", parent.env(environment()))[1] <- NA)
> Error in eval(expr, envir, enclos) : Target of assignment expands to
> non-language object
> 
> # On the other hand retrieval works just fine
> > local(get("x", parent.env(environment()))[1])
> [1] 1


You could try this:

> x <- 1:3

mod.x <- function(x)
{
  eval.parent(substitute(x[1] <- NA))
}

> x
[1] 1 2 3

> mod.x(x)

> x
[1] NA  2  3


See ?eval.parent for more information and variations on this.

HTH,

Marc Schwartz



From ggrothendieck at myway.com  Wed Mar  9 01:06:15 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 9 Mar 2005 00:06:15 +0000 (UTC)
Subject: [R] how modify object in parent.env
References: <C698D707214E6F4AB39AB7096C3DE5A58FF11C@phost015.EVAFUNDS.intermedia.net>
Message-ID: <loom.20050309T010434-778@post.gmane.org>


You can use "<<-" like this:

x <- 1:3
local(x[1] <<- x[1]+1)

Vadim Ogranovich <vograno <at> evafunds.com> writes:

: 
: Assign() re-binds the value, not modifies it (the latter is what I
: needed) 
: 
: > -----Original Message-----
: > From: McGehee, Robert [mailto:Robert.McGehee <at> geodecapital.com] 
: > Sent: Tuesday, March 08, 2005 3:48 PM
: > To: Vadim Ogranovich; r-help <at> stat.math.ethz.ch
: > Subject: RE: [R] how modify object in parent.env
: > 
: > This isn't an environment problem. Assigning something to a 
: > get call doesn't make any sense. Use assign.
: > 
: > > a <- 5
: > > get("a") <- 10
: > Error: couldn't find function "get<-"
: > 
: > And from the ?assign help page, you can pick what environment 
: > you want to make the assignment. Just pick the parent environment.
: > 
: > 
: > -----Original Message-----
: > From: Vadim Ogranovich [mailto:vograno <at> evafunds.com]
: > Sent: Tuesday, March 08, 2005 6:36 PM
: > To: r-help <at> stat.math.ethz.ch
: > Subject: [R] how modify object in parent.env
: > 
: > 
: > Hi,
: >  
: > Is it possible to modify an object in the parent.env (as opposed to
: > re-bind)? Here is what I tried:
: >  
: > > x = 1:3
: > # try to modify the first element of x from within a new environment
: > > local(get("x", parent.env(environment()))[1] <- NA)
: > Error in eval(expr, envir, enclos) : Target of assignment expands to
: > non-language object
: > 
: > # On the other hand retrieval works just fine
: > > local(get("x", parent.env(environment()))[1])
: > [1] 1
: > 
: > Thanks,
: > Vadim
: > 
: > ______________________________________________
: > R-help <at> stat.math.ethz.ch mailing list
: > https://stat.ethz.ch/mailman/listinfo/r-help
: > PLEASE do read the posting guide!
: > http://www.R-project.org/posting-guide.html
: >
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://stat.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From christopher.m.turner at jpmorgan.com  Wed Mar  9 01:15:07 2005
From: christopher.m.turner at jpmorgan.com (christopher.m.turner@jpmorgan.com)
Date: Tue, 8 Mar 2005 19:15:07 -0500
Subject: [R] Non-linear minimization
Message-ID: <OF26380E65.2560DA0C-ON85256FBF.0001035D-85256FBF.0001626A@jpmchase.com>


After some experimentation, I have had very good luck with the rgenoud
package. It handles box constraints well and for small problems its slow
speed has not been much of a problem. It has worked for me on Windows,
Macintosh, and Linux.

Chris
JPMorgan Asset Management



|---------+-------------------------------->
|         |           S?bastien Ballesteros|
|         |           <sebastien_ballestero|
|         |           s at yahoo.fr>          |
|         |           Sent by:             |
|         |           r-help-bounces at stat.m|
|         |           ath.ethz.ch          |
|         |                                |
|         |                                |
|         |           03/08/2005 08:23 AM  |
|         |                                |
|---------+-------------------------------->
  >-----------------------------------------------------------------------------------------------------------------------------|
  |                                                                                                                             |
  |       To:       r-help at stat.math.ethz.ch                                                                                    |
  |       cc:                                                                                                                   |
  |       Subject:  [R] Non-linear minimization                                                                                 |
  >-----------------------------------------------------------------------------------------------------------------------------|




hello, I have got some trouble with R functions nlm(),
nls() or optim() : I would like to fit 3 parameters
which must stay in a precise interval. For exemple
with nlm() :

fn<-function(p) sum((dN-estdata(p[1],p[2],p[3]))^2)
out<-nlm(fn, p=c(4, 17, 5),
hessian=TRUE,print.level=2)

with estdata() a function which returns value to fit
with dN (observed data vactor)

My problem is that only optim() allows me to set
parameters interval with "L-BFGS-B" method but this
one doesn't work in my case.

I have heard about nls2 package (www.inra.fr/bia) but
it doesn't work on Windows.

Do you know any solutions

Thank's a lot for reading my post

Best regards

Sebastien
INA P-G ecology dpt

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html




This communication is for informational purposes only. It is not intended
as an offer or solicitation for the purchase or sale of any financial
instrument or as an official confirmation of any transaction. All market prices,
data and other information are not warranted as to completeness or accuracy and
are subject to change without notice. Any comments or statements made herein 
do not necessarily reflect those of JPMorgan Chase & Co., its subsidiaries 
and affiliates



From zhliur at yahoo.com  Wed Mar  9 06:20:12 2005
From: zhliur at yahoo.com (yyan liu)
Date: Tue, 8 Mar 2005 21:20:12 -0800 (PST)
Subject: [R] from long/lat to UTM
Message-ID: <20050309052012.24953.qmail@web53110.mail.yahoo.com>

Hi:
  Is there any function in R which can convert the
long/lat to UTM(Universal Transverse Mercator)?
  There are quite a few converters on Internet.
However, the interface is designed as input->output
which I can not convert lots of locations at the same
time.
  Another question is whether there is a function in R
which can tell the time zone from the location's
lat/long?
  Thank you!

liu



From gabriel.rossetti at movemail.com  Wed Mar  9 09:09:50 2005
From: gabriel.rossetti at movemail.com (Gabriel Rossetti)
Date: Wed, 09 Mar 2005 16:09:50 +0800
Subject: [R] R-2.0.1 Gentoo g77 problem
Message-ID: <20050309080950.E77871027BE@ws3.hk5.outblaze.com>

Hello,

I use Gentoo and I can't get R 2.0.1 to compile. I used the portage system, Gentoo's source package sytem, and after it uncompresses the source to R, it says that I don't have a fortran compiler. It told me to use f77 flag and re-emerge gcc, which I did with the f77 and fortran flags, but it still won't compile. Does anyone have any ideas? I suspect that gcc has changed it's interworkings, because if I do a gcc -v it says that I can compile fortran(f77) programs, but I don't have g77. If anyone has any ideas or workarounds, it would be great. I really need it for a P&S class. Thanks!

Gabriel

My gcc version is : 
gcc version 3.3.5  (Gentoo Linux 3.3.5-r1, ssp-3.3.2-3, pie-8.7.7.1)
--



From pdasilva at xtra.co.nz  Thu Mar 10 10:12:59 2005
From: pdasilva at xtra.co.nz (Adriano von Sydow)
Date: Wed, 09 Mar 2005 21:12:59 -1200
Subject: [R] RMySQL installed but not availalable
Message-ID: <42300F9B.5040902@xtra.co.nz>

Hi
I run Linux SuSE 9.1, with MSQL 4.0.18
I installed R 2.0.1 and it is working fine
I installed RM 0.5-5 package and verified all installed.packages (see 
below) but when I tried to use any RMySQL specific comand is gives me 
the same error messages

 > dbConnect
Error: Object "dbConnect" not found

It looks like the  packages is not installed

Any ideas or help would be welcome
Thanks,
Popolito

*** INSTALL *****
ginossauro:/home/avonsydow/Download/Stats # R CMD INSTALL 
RMySQL_0.5-5.tar.gz
* Installing *source* package 'RMySQL' ...
creating cache ./config.cache
checking how to run the C preprocessor... cc -E
checking for compress in -lz... yes
checking for getopt_long in -lc... yes
checking for mysql_init in -lmysqlclient... yes
checking for mysql.h... no
checking for /usr/local/include/mysql/mysql.h... no
checking for /usr/include/mysql/mysql.h... yes
updating cache ./config.cache
creating ./config.status
creating src/Makevars
** libs
gcc -I/usr/lib/R/include -I/usr/include/mysql -I/usr/local/include 
-I/opt/gnome/
include   -fPIC   -c RS-DBI.c -o RS-DBI.o
gcc -I/usr/lib/R/include -I/usr/include/mysql -I/usr/local/include 
-I/opt/gnome/
include   -fPIC   -c RS-MySQL.c -o RS-MySQL.o
gcc -shared -L/usr/local/lib -L/opt/gnome/lib -o RMySQL.so RS-DBI.o 
RS-MySQL.o -
lmysqlclient -lz  -L/usr/lib/R/lib -lR
** R
** inst
** save image
Loading required package: DBI
[1] "dbObjectId"
[1] "format"
[1] "show"
[1] "print"
[1] "MySQLObject"
[1] "MySQLDriver"
[1] "dbUnloadDriver"
[1] "dbGetInfo"
[1] "dbListConnections"
[1] "summary"
[1] "MySQLConnection"
[1] "dbConnect"
[1] "dbConnect"
[1] "dbConnect"
[1] "dbDisconnect"
[1] "dbSendQuery"
[1] "dbGetQuery"
[1] "dbGetException"
[1] "dbGetInfo"
[1] "dbListResults"
[1] "summary"
[1] "dbListTables"
[1] "dbReadTable"
[1] "dbWriteTable"
[1] "dbExistsTable"
[1] "dbRemoveTable"
[1] "dbListFields"
[1] "dbCommit"
[1] "dbRollback"
[1] "dbCallProc"
[1] "MySQLResult"
[1] "dbClearResult"
[1] "fetch"
[1] "fetch"
[1] "dbGetInfo"
[1] "dbGetStatement"
[1] "dbListFields"
[1] "dbColumnInfo"
[1] "dbGetRowsAffected"
[1] "dbGetRowCount"
[1] "dbHasCompleted"
[1] "dbGetException"
[1] "summary"
[1] "dbDataType"
[1] "make.db.names"
[1] "SQLKeywords"
[1] "isSQLKeyword"
[1] "dbApply"
[1] "dbApply"

** help
 >>> Building/Updating help pages for package 'RMySQL'
     Formats: text html latex example
  MySQL                             text    html    latex   example
  MySQLConnection-class             text    html    latex   example
  MySQLDriver-class                 text    html    latex   example
  MySQLObject-class                 text    html    latex   example
  MySQLResult-class                 text    html    latex   example
  S4R                               text    html    latex
  dbApply-methods                   text    html    latex   example
  dbApply                           text    html    latex   example
  dbCallProc-methods                text    html    latex
  dbCommit-methods                  text    html    latex   example
  dbConnect-methods                 text    html    latex   example
  dbDataType-methods                text    html    latex   example
  dbDriver-methods                  text    html    latex   example
  dbGetInfo-methods                 text    html    latex   example
  dbListTables-methods              text    html    latex   example
  dbObjectId-class                  text    html    latex   example
  dbReadTable-methods               text    html    latex   example
  dbSendQuery-methods               text    html    latex   example
  dbSetDataMappings-methods         text    html    latex   example
  fetch-methods                     text    html    latex   example
  isIdCurrent                       text    html    latex   example
  make.db.names-methods             text    html    latex   example
  mysqlDBApply                      text    html    latex   example
  mysqlSupport                      text    html    latex
  safe.write                        text    html    latex   example
  summary-methods                   text    html    latex
* DONE (RMySQL)



*****INSTALLED.PACKAGES *******

 > installed.packages()
           Package      LibPath              Version   Priority      Bundle
base       "base"       "/usr/lib/R/library" "2.0.1"   "base"        NA
boot       "boot"       "/usr/lib/R/library" "1.2-20"  "recommended" NA
class      "class"      "/usr/lib/R/library" "7.2-10"  "recommended" "VR"
cluster    "cluster"    "/usr/lib/R/library" "1.9.6"   "recommended" NA
datasets   "datasets"   "/usr/lib/R/library" "2.0.1"   "base"        NA
DBI        "DBI"        "/usr/lib/R/library" "0.1-8"   NA            NA
foreign    "foreign"    "/usr/lib/R/library" "0.8-0"   "recommended" NA
graphics   "graphics"   "/usr/lib/R/library" "2.0.1"   "base"        NA
grDevices  "grDevices"  "/usr/lib/R/library" "2.0.1"   "base"        NA
grid       "grid"       "/usr/lib/R/library" "2.0.1"   "base"        NA
KernSmooth "KernSmooth" "/usr/lib/R/library" "2.22-14" "recommended" NA
lattice    "lattice"    "/usr/lib/R/library" "0.10-14" "recommended" NA
MASS       "MASS"       "/usr/lib/R/library" "7.2-10"  "recommended" "VR"
methods    "methods"    "/usr/lib/R/library" "2.0.1"   "base"        NA
mgcv       "mgcv"       "/usr/lib/R/library" "1.1-8"   "recommended" NA
nlme       "nlme"       "/usr/lib/R/library" "3.1-53"  "recommended" NA
nnet       "nnet"       "/usr/lib/R/library" "7.2-10"  "recommended" "VR"
RMySQL     "RMySQL"     "/usr/lib/R/library" "0.5-5"   NA            NA
rpart      "rpart"      "/usr/lib/R/library" "3.1-20"  "recommended" NA
spatial    "spatial"    "/usr/lib/R/library" "7.2-10"  "recommended" "VR"
splines    "splines"    "/usr/lib/R/library" "2.0.1"   "base"        NA
stats      "stats"      "/usr/lib/R/library" "2.0.1"   "base"        NA
stats4     "stats4"     "/usr/lib/R/library" "2.0.1"   "base"        NA
survival   "survival"   "/usr/lib/R/library" "2.15"    "recommended" NA
tcltk      "tcltk"      "/usr/lib/R/library" "2.0.1"   "base"        NA
tools      "tools"      "/usr/lib/R/library" "2.0.1"   "base"        NA
utils      "utils"      "/usr/lib/R/library" "2.0.1"   "base"        NA
           Depends
base       NA
boot       "R (>= 2.0.0), graphics, stats"
class      "R (>= 2.0.0), graphics, stats"
cluster    "R (>= 1.9), stats, graphics, utils"
datasets   NA
DBI        "R (>= 1.7.1), methods"
foreign    "R (>= 2.0.0)"
graphics   "grDevices"
grDevices  NA
grid       "grDevices"
KernSmooth "R (>= 1.9.0)"
lattice    "R (>= 2.0.0)"
MASS       "R (>= 2.0.0), graphics, stats"
methods    NA
mgcv       "R (>= 1.9.0)"
nlme       "graphics, stats, R(>= 2.0.0)"
nnet       "R (>= 2.0.0), graphics, stats"
RMySQL     "R (>= 1.8.0), methods, DBI (>= 0.1-4)"
rpart      "R (>= 2.0.0)"
spatial    "R (>= 2.0.0), graphics, stats"
splines    NA
stats      NA
stats4     "graphics, stats, methods"
survival   "stats, utils, graphics, splines, R (>= 2.0.0)"
tcltk      NA
tools      NA
utils      NA
           Suggests
base       NA
boot       "survival"
class      "lattice, nlme, survival"
cluster    NA
datasets   NA
DBI        NA
foreign    NA
graphics   NA
grDevices  NA
grid       "lattice"
KernSmooth "MASS"
lattice    "grid"
MASS       "lattice, nlme, survival"
methods    NA
mgcv       "nlme (>= 3.1-52), MASS (>= 7.2-2)"
nlme       NA
nnet       "lattice, nlme, survival"
RMySQL     NA
rpart      "survival"
spatial    "lattice, nlme, survival"
splines    NA
stats      NA
stats4     NA
survival   NA
tcltk      NA
tools      NA
utils      NA
 >



From ales.ziberna at guest.arnes.si  Wed Mar  9 09:24:06 2005
From: ales.ziberna at guest.arnes.si (=?windows-1250?Q?Ale=9A_=8Eiberna?=)
Date: Wed, 9 Mar 2005 09:24:06 +0100
Subject: [R] Using RCC (R to C Compiler)
Message-ID: <002c01c52481$7fedf710$0709f9c2@ales>

Hello!

I would like to know if anyone has any experience in using RCC (R to C
Compiler) [http://hipersoft.cs.rice.edu/rcc/index.html].

I thing I have successfully compiled both RCC and R 1.9.0 following the 
instructions on the RCC web site. However, I have no idea how to actually 
use it.



I found no instructions either on the web page or the authors master's 
thesis. I have also tried to contact the author, however, I got no reply.



Therefore I would be very grateful for any information on how to actually 
use RCC.

Thank you in advance!


Ales Ziberna



From Tom.Mulholland at dpi.wa.gov.au  Wed Mar  9 09:45:32 2005
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Wed, 9 Mar 2005 16:45:32 +0800
Subject: [R] from long/lat to UTM
Message-ID: <33F91FB3FDF42E4180428AC66A5CF30B02D3C9BB@afhex01.dpi.wa.gov.au>

I think I recall seeing a limited capability in the PBSmapping package.

Tom

> -----Original Message-----
> From: yyan liu [mailto:zhliur at yahoo.com]
> Sent: Wednesday, 9 March 2005 1:20 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] from long/lat to UTM
> 
> 
> Hi:
>   Is there any function in R which can convert the
> long/lat to UTM(Universal Transverse Mercator)?
>   There are quite a few converters on Internet.
> However, the interface is designed as input->output
> which I can not convert lots of locations at the same
> time.
>   Another question is whether there is a function in R
> which can tell the time zone from the location's
> lat/long?
>   Thank you!
> 
> liu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From Tom.Mulholland at dpi.wa.gov.au  Wed Mar  9 09:48:28 2005
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Wed, 9 Mar 2005 16:48:28 +0800
Subject: [R] RMySQL installed but not availalable
Message-ID: <33F91FB3FDF42E4180428AC66A5CF30B02D3C9BC@afhex01.dpi.wa.gov.au>

I don't use MySQL but I have seen messages like this before. They often have replies which indicate that you need to follow the instructions more closely. I suggest you search the list for these previous posts as I'm sure there is help there, somewhere!

Tom

> -----Original Message-----
> From: Adriano von Sydow [mailto:pdasilva at xtra.co.nz]
> Sent: Thursday, 10 March 2005 5:13 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] RMySQL installed but not availalable
> 
> 
> Hi
> I run Linux SuSE 9.1, with MSQL 4.0.18
> I installed R 2.0.1 and it is working fine
> I installed RM 0.5-5 package and verified all installed.packages (see 
> below) but when I tried to use any RMySQL specific comand is gives me 
> the same error messages
> 
>  > dbConnect
> Error: Object "dbConnect" not found
> 
> It looks like the  packages is not installed
> 
> Any ideas or help would be welcome
> Thanks,
> Popolito
> 
> *** INSTALL *****
> ginossauro:/home/avonsydow/Download/Stats # R CMD INSTALL 
> RMySQL_0.5-5.tar.gz
> * Installing *source* package 'RMySQL' ...
> creating cache ./config.cache
> checking how to run the C preprocessor... cc -E
> checking for compress in -lz... yes
> checking for getopt_long in -lc... yes
> checking for mysql_init in -lmysqlclient... yes
> checking for mysql.h... no
> checking for /usr/local/include/mysql/mysql.h... no
> checking for /usr/include/mysql/mysql.h... yes
> updating cache ./config.cache
> creating ./config.status
> creating src/Makevars
> ** libs
> gcc -I/usr/lib/R/include -I/usr/include/mysql -I/usr/local/include 
> -I/opt/gnome/
> include   -fPIC   -c RS-DBI.c -o RS-DBI.o
> gcc -I/usr/lib/R/include -I/usr/include/mysql -I/usr/local/include 
> -I/opt/gnome/
> include   -fPIC   -c RS-MySQL.c -o RS-MySQL.o
> gcc -shared -L/usr/local/lib -L/opt/gnome/lib -o RMySQL.so RS-DBI.o 
> RS-MySQL.o -
> lmysqlclient -lz  -L/usr/lib/R/lib -lR
> ** R
> ** inst
> ** save image
> Loading required package: DBI
> [1] "dbObjectId"
> [1] "format"
> [1] "show"
> [1] "print"
> [1] "MySQLObject"
> [1] "MySQLDriver"
> [1] "dbUnloadDriver"
> [1] "dbGetInfo"
> [1] "dbListConnections"
> [1] "summary"
> [1] "MySQLConnection"
> [1] "dbConnect"
> [1] "dbConnect"
> [1] "dbConnect"
> [1] "dbDisconnect"
> [1] "dbSendQuery"
> [1] "dbGetQuery"
> [1] "dbGetException"
> [1] "dbGetInfo"
> [1] "dbListResults"
> [1] "summary"
> [1] "dbListTables"
> [1] "dbReadTable"
> [1] "dbWriteTable"
> [1] "dbExistsTable"
> [1] "dbRemoveTable"
> [1] "dbListFields"
> [1] "dbCommit"
> [1] "dbRollback"
> [1] "dbCallProc"
> [1] "MySQLResult"
> [1] "dbClearResult"
> [1] "fetch"
> [1] "fetch"
> [1] "dbGetInfo"
> [1] "dbGetStatement"
> [1] "dbListFields"
> [1] "dbColumnInfo"
> [1] "dbGetRowsAffected"
> [1] "dbGetRowCount"
> [1] "dbHasCompleted"
> [1] "dbGetException"
> [1] "summary"
> [1] "dbDataType"
> [1] "make.db.names"
> [1] "SQLKeywords"
> [1] "isSQLKeyword"
> [1] "dbApply"
> [1] "dbApply"
> 
> ** help
>  >>> Building/Updating help pages for package 'RMySQL'
>      Formats: text html latex example
>   MySQL                             text    html    latex   example
>   MySQLConnection-class             text    html    latex   example
>   MySQLDriver-class                 text    html    latex   example
>   MySQLObject-class                 text    html    latex   example
>   MySQLResult-class                 text    html    latex   example
>   S4R                               text    html    latex
>   dbApply-methods                   text    html    latex   example
>   dbApply                           text    html    latex   example
>   dbCallProc-methods                text    html    latex
>   dbCommit-methods                  text    html    latex   example
>   dbConnect-methods                 text    html    latex   example
>   dbDataType-methods                text    html    latex   example
>   dbDriver-methods                  text    html    latex   example
>   dbGetInfo-methods                 text    html    latex   example
>   dbListTables-methods              text    html    latex   example
>   dbObjectId-class                  text    html    latex   example
>   dbReadTable-methods               text    html    latex   example
>   dbSendQuery-methods               text    html    latex   example
>   dbSetDataMappings-methods         text    html    latex   example
>   fetch-methods                     text    html    latex   example
>   isIdCurrent                       text    html    latex   example
>   make.db.names-methods             text    html    latex   example
>   mysqlDBApply                      text    html    latex   example
>   mysqlSupport                      text    html    latex
>   safe.write                        text    html    latex   example
>   summary-methods                   text    html    latex
> * DONE (RMySQL)
> 
> 
> 
> *****INSTALLED.PACKAGES *******
> 
>  > installed.packages()
>            Package      LibPath              Version   
> Priority      Bundle
> base       "base"       "/usr/lib/R/library" "2.0.1"   "base" 
>        NA
> boot       "boot"       "/usr/lib/R/library" "1.2-20"  
> "recommended" NA
> class      "class"      "/usr/lib/R/library" "7.2-10"  
> "recommended" "VR"
> cluster    "cluster"    "/usr/lib/R/library" "1.9.6"   
> "recommended" NA
> datasets   "datasets"   "/usr/lib/R/library" "2.0.1"   "base" 
>        NA
> DBI        "DBI"        "/usr/lib/R/library" "0.1-8"   NA     
>        NA
> foreign    "foreign"    "/usr/lib/R/library" "0.8-0"   
> "recommended" NA
> graphics   "graphics"   "/usr/lib/R/library" "2.0.1"   "base" 
>        NA
> grDevices  "grDevices"  "/usr/lib/R/library" "2.0.1"   "base" 
>        NA
> grid       "grid"       "/usr/lib/R/library" "2.0.1"   "base" 
>        NA
> KernSmooth "KernSmooth" "/usr/lib/R/library" "2.22-14" 
> "recommended" NA
> lattice    "lattice"    "/usr/lib/R/library" "0.10-14" 
> "recommended" NA
> MASS       "MASS"       "/usr/lib/R/library" "7.2-10"  
> "recommended" "VR"
> methods    "methods"    "/usr/lib/R/library" "2.0.1"   "base" 
>        NA
> mgcv       "mgcv"       "/usr/lib/R/library" "1.1-8"   
> "recommended" NA
> nlme       "nlme"       "/usr/lib/R/library" "3.1-53"  
> "recommended" NA
> nnet       "nnet"       "/usr/lib/R/library" "7.2-10"  
> "recommended" "VR"
> RMySQL     "RMySQL"     "/usr/lib/R/library" "0.5-5"   NA     
>        NA
> rpart      "rpart"      "/usr/lib/R/library" "3.1-20"  
> "recommended" NA
> spatial    "spatial"    "/usr/lib/R/library" "7.2-10"  
> "recommended" "VR"
> splines    "splines"    "/usr/lib/R/library" "2.0.1"   "base" 
>        NA
> stats      "stats"      "/usr/lib/R/library" "2.0.1"   "base" 
>        NA
> stats4     "stats4"     "/usr/lib/R/library" "2.0.1"   "base" 
>        NA
> survival   "survival"   "/usr/lib/R/library" "2.15"    
> "recommended" NA
> tcltk      "tcltk"      "/usr/lib/R/library" "2.0.1"   "base" 
>        NA
> tools      "tools"      "/usr/lib/R/library" "2.0.1"   "base" 
>        NA
> utils      "utils"      "/usr/lib/R/library" "2.0.1"   "base" 
>        NA
>            Depends
> base       NA
> boot       "R (>= 2.0.0), graphics, stats"
> class      "R (>= 2.0.0), graphics, stats"
> cluster    "R (>= 1.9), stats, graphics, utils"
> datasets   NA
> DBI        "R (>= 1.7.1), methods"
> foreign    "R (>= 2.0.0)"
> graphics   "grDevices"
> grDevices  NA
> grid       "grDevices"
> KernSmooth "R (>= 1.9.0)"
> lattice    "R (>= 2.0.0)"
> MASS       "R (>= 2.0.0), graphics, stats"
> methods    NA
> mgcv       "R (>= 1.9.0)"
> nlme       "graphics, stats, R(>= 2.0.0)"
> nnet       "R (>= 2.0.0), graphics, stats"
> RMySQL     "R (>= 1.8.0), methods, DBI (>= 0.1-4)"
> rpart      "R (>= 2.0.0)"
> spatial    "R (>= 2.0.0), graphics, stats"
> splines    NA
> stats      NA
> stats4     "graphics, stats, methods"
> survival   "stats, utils, graphics, splines, R (>= 2.0.0)"
> tcltk      NA
> tools      NA
> utils      NA
>            Suggests
> base       NA
> boot       "survival"
> class      "lattice, nlme, survival"
> cluster    NA
> datasets   NA
> DBI        NA
> foreign    NA
> graphics   NA
> grDevices  NA
> grid       "lattice"
> KernSmooth "MASS"
> lattice    "grid"
> MASS       "lattice, nlme, survival"
> methods    NA
> mgcv       "nlme (>= 3.1-52), MASS (>= 7.2-2)"
> nlme       NA
> nnet       "lattice, nlme, survival"
> RMySQL     NA
> rpart      "survival"
> spatial    "lattice, nlme, survival"
> splines    NA
> stats      NA
> stats4     NA
> survival   NA
> tcltk      NA
> tools      NA
> utils      NA
>  >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From maechler at stat.math.ethz.ch  Wed Mar  9 10:14:34 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 9 Mar 2005 10:14:34 +0100
Subject: [R] To convert an adjacency list model into a nested set model
In-Reply-To: <loom.20050308T181636-487@post.gmane.org>
References: <321C3EEBDB00C24185705B8BF733DADD0503F6FF@LNVCNTEXCH01.corp.lloydsnet>
	<loom.20050308T181636-487@post.gmane.org>
Message-ID: <16942.48762.445488.715769@stat.math.ethz.ch>

>>>>> "Gabor" == Gabor Grothendieck <ggrothendieck at myway.com>
>>>>>     on Tue, 8 Mar 2005 17:19:12 +0000 (UTC) writes:

    <..............>

    Gabor> This is not a direct answer to getting a nesting from
    Gabor> an adjacency but the following is easy to do and
    Gabor> gives all the same info.


    Gabor> Note that if A is the adjacency matrix of children
    Gabor> (rows) and ] parents (columns) then A^n is the matrix
    Gabor> defining ancestors n generations away and exp(A) is a
    Gabor> weighted version of that with A^i weighted by i!
    Gabor> (These expressions are mathematics, not R.)  Thus:

    Gabor> empf <- factor(emp, level = union(emp, boss))  # emp as factor
    Gabor> bossf <- factor(boss, level = union(emp, boss)) # ditto for boss

    Gabor> adj <- table(empf, bossf)  # i,j is 1 if j is boss of i

    Gabor> library(rmutil)  # http://popgen.unimaas.nl/~jlindsey/rcode.html
    Gabor> mexp(adj, type = "series") - diag(length(empf))

just a note on the matrix exponential:

The Matrix package (from CRAN) now also has the matrix
exponential,  expm(.) , 
using the ''least dubious '' algorithm of

  Moler, C. and Van Loan C. (2003)
  "Ninteen dubious ways to compute the exponential of a
   matrix, twenty-five years later".
  SIAM review 45, 3--49

namely the one also in use by Matlab and Octave

So the above would be something like

library(Matrix)
expm( as(adj, "dgeMatrix") ) - as(diag(length(empf)), "dgeMatrix")


    Gabor> giving a matrix whose i,j-th entry is 1/n! if j is
    Gabor> n-generations above i.

    Gabor> From that you can get the info you need.



From j.hall at beatson.gla.ac.uk  Wed Mar  9 11:36:49 2005
From: j.hall at beatson.gla.ac.uk (Jacqueline Hall)
Date: Wed, 9 Mar 2005 10:36:49 -0000
Subject: [R] plot(bclust) what is the 2nd plot?
Message-ID: <000201c52493$e79f0cc0$afe8d182@o1jh>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050309/83f722d3/attachment.pl

From Friedrich.Leisch at tuwien.ac.at  Wed Mar  9 12:14:48 2005
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Wed, 9 Mar 2005 12:14:48 +0100
Subject: [R] plot(bclust) what is the 2nd plot?
In-Reply-To: <000201c52493$e79f0cc0$afe8d182@o1jh>
References: <000201c52493$e79f0cc0$afe8d182@o1jh>
Message-ID: <16942.55976.691306.282856@galadriel.ci.tuwien.ac.at>

>>>>> On Wed, 9 Mar 2005 10:36:49 -0000,
>>>>> Jacqueline Hall (JH) wrote:

  > Hi everyone,
  > Currently i'm trying to understand the bagged clustering algorithm, bclust
  > {e1071}. 
 
  > When I run the given example in the help file (as below)
  >   data(iris)
  >      bc1 <- bclust(iris[,1:4], 3, base.centers=5)
  >      plot(bc1)

  > and plot the bclust object, 2 graphs are produced. 
  > The first is a dendrogram, but what is the second plot? The axes are not
  > labelled and what do the two lines represent?

 
The monotonic decreasing line gives the relative height of the split
of tyhe tree into 2, 3, etc. branches, the second line is the first
differences of the first. A peak in the differencescan be used as a
crude estimation for the number of clusters.

  > I tried looking in the URL
  > given in the references but that didn't help.

Look at Section IV.A of the working paper.

HTH,

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch



From chris.jackson at imperial.ac.uk  Wed Mar  9 11:48:48 2005
From: chris.jackson at imperial.ac.uk (Chris Jackson)
Date: Wed, 09 Mar 2005 10:48:48 +0000
Subject: [R] [R-pkgs] msm version 0.5 released
Message-ID: <422ED490.8040307@imperial.ac.uk>

A major update of the "msm" package for continuous-time Markov and
hidden Markov multi-state models is now available from CRAN.

Hidden Markov models with general, continuous response distributions are
now supported.  These models are used for Markov processes which can
only be observed through the value of some noisy marker.

Censored states are now supported at any observation time.  The
observation scheme is also allowed to be different for each observation,
for example, process snapshot / fully-observed histories /
partially-observed histories such as death times.

Users upgrading from previous versions of msm should note that
some of the syntax for specifying models has changed.  In particular,
initial values are now specified in the "qmatrix" and "covinits"
arguments instead of the inits argument, so that "qmatrix" is no longer
a matrix of 0/1 indicators.

As always, refer to the user guide "msm-manual.pdf" in the "doc"
subdirectory for a full description of the methodology, and worked
examples in the use of the package.  See the appendix for a full
list of the syntax changes, and the NEWS file in the top-level
installation directory for a full list of the changes in this release.

-- 
Christopher Jackson <chris.jackson at imperial.ac.uk>, Research Associate,
Department of Epidemiology and Public Health, Imperial College
School of Medicine, Norfolk Place, London W2 1PG, tel. 020 759 43371

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From midnightsun at blueyonder.co.uk  Wed Mar  9 12:21:13 2005
From: midnightsun at blueyonder.co.uk (midnightsun@blueyonder.co.uk)
Date: Wed, 9 Mar 2005 11:21:13 -0000 (GMT)
Subject: [R] Plotting several series on one set of axes
Message-ID: <18347.195.188.213.34.1110367273.squirrel@195.188.213.34>

Dear All,

I am rather rusty with my R, but I recall being able to do something like
plot(x1,...);plot(x2,add=TRUE,...)
to plot two series on the same axes.

Any suggestions how this may be done will be appreciated.



From zh107 at york.ac.uk  Wed Mar  9 12:27:21 2005
From: zh107 at york.ac.uk (Zhesi He)
Date: Wed, 9 Mar 2005 11:27:21 +0000
Subject: [R] RSPYTHON install failed on Mac
In-Reply-To: <16942.55976.691306.282856@galadriel.ci.tuwien.ac.at>
References: <000201c52493$e79f0cc0$afe8d182@o1jh>
	<16942.55976.691306.282856@galadriel.ci.tuwien.ac.at>
Message-ID: <5fe990df0de5700918a262fd81e3ff6e@york.ac.uk>

Dear all,

I was trying to install RSPYTHON on my Mac OS X 10.3 into R, and got 
the following errors, is it because of my C compiler or the python I 
installed?


R CMD INSTALL -c Desktop/RSPython_0.5-4.tar.gz
* Installing *source* package 'RSPython' ...
checking for python... /usr/bin/python
Python version 2.3
Using threads
checking for gcc... gcc
checking for C compiler default output... configure: error: C compiler 
cannot create executables
See `config.log' for more details.
ERROR: configuration failed for package 'RSPython'
** Removing 
'/Applications/StartR.app/RAqua.app/Contents/library/RSPython'

Thanks in advance.


___________________________________________________

Zhesi He
Computational Biology Laboratory, University of York
York YO10 5YW, U.K.
Phone:  +44-(0)1904-328279
Email:  zh107 at york.ac.uk



From W.E.Wolski at ncl.ac.uk  Wed Mar  9 12:42:56 2005
From: W.E.Wolski at ncl.ac.uk (Witold Eryk Wolski)
Date: Wed, 09 Mar 2005 12:42:56 +0100
Subject: [R] Plotting several series on one set of axes
In-Reply-To: <18347.195.188.213.34.1110367273.squirrel@195.188.213.34>
References: <18347.195.188.213.34.1110367273.squirrel@195.188.213.34>
Message-ID: <422EE140.2090106@ncl.ac.uk>

midnightsun at blueyonder.co.uk wrote:

>Dear All,
>
>I am rather rusty with my R, but I recall being able to do something like
>plot(x1,...);plot(x2,add=TRUE,...)
>to plot two series on the same axes.
>
>Any suggestions how this may be done will be appreciated.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>

?lines
?points
par(new=TRUE)


cheers
Eryk

-- 
Witold Eryk Wolski
__("<  School of Mathematics and Statistics     _
\__/   University of Newcastle                 'v'
 ||    Newcastle upon Tyne, NE1 7RU, ENGLAND  /   \
 ^^    mail: witek96 at users.sourceforge.net     m m
       Phone : 044 (0)191 222 5376
       FAX   : 044 (0)191 222 8020



From ahenningsen at email.uni-kiel.de  Wed Mar  9 13:30:13 2005
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Wed, 9 Mar 2005 13:30:13 +0100
Subject: [R] RMySQL installed but not availalable
In-Reply-To: <42300F9B.5040902@xtra.co.nz>
References: <42300F9B.5040902@xtra.co.nz>
Message-ID: <200503091330.14164.ahenningsen@email.uni-kiel.de>

Did you _load_ the package?
R> library( RMySQL )

On Thursday 10 March 2005 10:12, Adriano von Sydow wrote:
> Hi
> I run Linux SuSE 9.1, with MSQL 4.0.18
> I installed R 2.0.1 and it is working fine
> I installed RM 0.5-5 package and verified all installed.packages (see
> below) but when I tried to use any RMySQL specific comand is gives me
> the same error messages
>
>  > dbConnect
>
> Error: Object "dbConnect" not found
>
> It looks like the  packages is not installed
>
> Any ideas or help would be welcome
> Thanks,
> Popolito
>
> *** INSTALL *****
> ginossauro:/home/avonsydow/Download/Stats # R CMD INSTALL
> RMySQL_0.5-5.tar.gz
> * Installing *source* package 'RMySQL' ...
> creating cache ./config.cache
> checking how to run the C preprocessor... cc -E
> checking for compress in -lz... yes
> checking for getopt_long in -lc... yes
> checking for mysql_init in -lmysqlclient... yes
> checking for mysql.h... no
> checking for /usr/local/include/mysql/mysql.h... no
> checking for /usr/include/mysql/mysql.h... yes
> updating cache ./config.cache
> creating ./config.status
> creating src/Makevars
> ** libs
> gcc -I/usr/lib/R/include -I/usr/include/mysql -I/usr/local/include
> -I/opt/gnome/
> include   -fPIC   -c RS-DBI.c -o RS-DBI.o
> gcc -I/usr/lib/R/include -I/usr/include/mysql -I/usr/local/include
> -I/opt/gnome/
> include   -fPIC   -c RS-MySQL.c -o RS-MySQL.o
> gcc -shared -L/usr/local/lib -L/opt/gnome/lib -o RMySQL.so RS-DBI.o
> RS-MySQL.o -
> lmysqlclient -lz  -L/usr/lib/R/lib -lR
> ** R
> ** inst
> ** save image
> Loading required package: DBI
> [1] "dbObjectId"
> [1] "format"
> [1] "show"
> [1] "print"
> [1] "MySQLObject"
> [1] "MySQLDriver"
> [1] "dbUnloadDriver"
> [1] "dbGetInfo"
> [1] "dbListConnections"
> [1] "summary"
> [1] "MySQLConnection"
> [1] "dbConnect"
> [1] "dbConnect"
> [1] "dbConnect"
> [1] "dbDisconnect"
> [1] "dbSendQuery"
> [1] "dbGetQuery"
> [1] "dbGetException"
> [1] "dbGetInfo"
> [1] "dbListResults"
> [1] "summary"
> [1] "dbListTables"
> [1] "dbReadTable"
> [1] "dbWriteTable"
> [1] "dbExistsTable"
> [1] "dbRemoveTable"
> [1] "dbListFields"
> [1] "dbCommit"
> [1] "dbRollback"
> [1] "dbCallProc"
> [1] "MySQLResult"
> [1] "dbClearResult"
> [1] "fetch"
> [1] "fetch"
> [1] "dbGetInfo"
> [1] "dbGetStatement"
> [1] "dbListFields"
> [1] "dbColumnInfo"
> [1] "dbGetRowsAffected"
> [1] "dbGetRowCount"
> [1] "dbHasCompleted"
> [1] "dbGetException"
> [1] "summary"
> [1] "dbDataType"
> [1] "make.db.names"
> [1] "SQLKeywords"
> [1] "isSQLKeyword"
> [1] "dbApply"
> [1] "dbApply"
>
> ** help
>
>  >>> Building/Updating help pages for package 'RMySQL'
>
>      Formats: text html latex example
>   MySQL                             text    html    latex   example
>   MySQLConnection-class             text    html    latex   example
>   MySQLDriver-class                 text    html    latex   example
>   MySQLObject-class                 text    html    latex   example
>   MySQLResult-class                 text    html    latex   example
>   S4R                               text    html    latex
>   dbApply-methods                   text    html    latex   example
>   dbApply                           text    html    latex   example
>   dbCallProc-methods                text    html    latex
>   dbCommit-methods                  text    html    latex   example
>   dbConnect-methods                 text    html    latex   example
>   dbDataType-methods                text    html    latex   example
>   dbDriver-methods                  text    html    latex   example
>   dbGetInfo-methods                 text    html    latex   example
>   dbListTables-methods              text    html    latex   example
>   dbObjectId-class                  text    html    latex   example
>   dbReadTable-methods               text    html    latex   example
>   dbSendQuery-methods               text    html    latex   example
>   dbSetDataMappings-methods         text    html    latex   example
>   fetch-methods                     text    html    latex   example
>   isIdCurrent                       text    html    latex   example
>   make.db.names-methods             text    html    latex   example
>   mysqlDBApply                      text    html    latex   example
>   mysqlSupport                      text    html    latex
>   safe.write                        text    html    latex   example
>   summary-methods                   text    html    latex
> * DONE (RMySQL)
>
>
>
> *****INSTALLED.PACKAGES *******
>
>  > installed.packages()
>
>            Package      LibPath              Version   Priority      Bundle
> base       "base"       "/usr/lib/R/library" "2.0.1"   "base"        NA
> boot       "boot"       "/usr/lib/R/library" "1.2-20"  "recommended" NA
> class      "class"      "/usr/lib/R/library" "7.2-10"  "recommended" "VR"
> cluster    "cluster"    "/usr/lib/R/library" "1.9.6"   "recommended" NA
> datasets   "datasets"   "/usr/lib/R/library" "2.0.1"   "base"        NA
> DBI        "DBI"        "/usr/lib/R/library" "0.1-8"   NA            NA
> foreign    "foreign"    "/usr/lib/R/library" "0.8-0"   "recommended" NA
> graphics   "graphics"   "/usr/lib/R/library" "2.0.1"   "base"        NA
> grDevices  "grDevices"  "/usr/lib/R/library" "2.0.1"   "base"        NA
> grid       "grid"       "/usr/lib/R/library" "2.0.1"   "base"        NA
> KernSmooth "KernSmooth" "/usr/lib/R/library" "2.22-14" "recommended" NA
> lattice    "lattice"    "/usr/lib/R/library" "0.10-14" "recommended" NA
> MASS       "MASS"       "/usr/lib/R/library" "7.2-10"  "recommended" "VR"
> methods    "methods"    "/usr/lib/R/library" "2.0.1"   "base"        NA
> mgcv       "mgcv"       "/usr/lib/R/library" "1.1-8"   "recommended" NA
> nlme       "nlme"       "/usr/lib/R/library" "3.1-53"  "recommended" NA
> nnet       "nnet"       "/usr/lib/R/library" "7.2-10"  "recommended" "VR"
> RMySQL     "RMySQL"     "/usr/lib/R/library" "0.5-5"   NA            NA
> rpart      "rpart"      "/usr/lib/R/library" "3.1-20"  "recommended" NA
> spatial    "spatial"    "/usr/lib/R/library" "7.2-10"  "recommended" "VR"
> splines    "splines"    "/usr/lib/R/library" "2.0.1"   "base"        NA
> stats      "stats"      "/usr/lib/R/library" "2.0.1"   "base"        NA
> stats4     "stats4"     "/usr/lib/R/library" "2.0.1"   "base"        NA
> survival   "survival"   "/usr/lib/R/library" "2.15"    "recommended" NA
> tcltk      "tcltk"      "/usr/lib/R/library" "2.0.1"   "base"        NA
> tools      "tools"      "/usr/lib/R/library" "2.0.1"   "base"        NA
> utils      "utils"      "/usr/lib/R/library" "2.0.1"   "base"        NA
>            Depends
> base       NA
> boot       "R (>= 2.0.0), graphics, stats"
> class      "R (>= 2.0.0), graphics, stats"
> cluster    "R (>= 1.9), stats, graphics, utils"
> datasets   NA
> DBI        "R (>= 1.7.1), methods"
> foreign    "R (>= 2.0.0)"
> graphics   "grDevices"
> grDevices  NA
> grid       "grDevices"
> KernSmooth "R (>= 1.9.0)"
> lattice    "R (>= 2.0.0)"
> MASS       "R (>= 2.0.0), graphics, stats"
> methods    NA
> mgcv       "R (>= 1.9.0)"
> nlme       "graphics, stats, R(>= 2.0.0)"
> nnet       "R (>= 2.0.0), graphics, stats"
> RMySQL     "R (>= 1.8.0), methods, DBI (>= 0.1-4)"
> rpart      "R (>= 2.0.0)"
> spatial    "R (>= 2.0.0), graphics, stats"
> splines    NA
> stats      NA
> stats4     "graphics, stats, methods"
> survival   "stats, utils, graphics, splines, R (>= 2.0.0)"
> tcltk      NA
> tools      NA
> utils      NA
>            Suggests
> base       NA
> boot       "survival"
> class      "lattice, nlme, survival"
> cluster    NA
> datasets   NA
> DBI        NA
> foreign    NA
> graphics   NA
> grDevices  NA
> grid       "lattice"
> KernSmooth "MASS"
> lattice    "grid"
> MASS       "lattice, nlme, survival"
> methods    NA
> mgcv       "nlme (>= 3.1-52), MASS (>= 7.2-2)"
> nlme       NA
> nnet       "lattice, nlme, survival"
> RMySQL     NA
> rpart      "survival"
> spatial    "lattice, nlme, survival"
> splines    NA
> stats      NA
> stats4     NA
> survival   NA
> tcltk      NA
> tools      NA
> utils      NA
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From max.marinucci at ya.com  Wed Mar  9 13:31:16 2005
From: max.marinucci at ya.com (max.marinucci)
Date: Wed, 9 Mar 2005 13:31:16 +0100
Subject: [R] Trouble with mixreg
Message-ID: <001901c524a3$e6fce610$780a1d50@maxmad9rubu4nk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050309/4fed44ee/attachment.pl

From sekemp at glam.ac.uk  Wed Mar  9 14:02:22 2005
From: sekemp at glam.ac.uk (Kemp S E (Comp))
Date: Wed, 9 Mar 2005 13:02:22 -0000
Subject: [R] nnet abstol
Message-ID: <0BA7EE4D4646E0409D458D347C508B783C624B@MAILSERV1.uni.glam.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050309/6a31d5ee/attachment.pl

From ripley at stats.ox.ac.uk  Wed Mar  9 14:02:38 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 9 Mar 2005 13:02:38 +0000 (GMT)
Subject: [R] RSPYTHON install failed on Mac
In-Reply-To: <5fe990df0de5700918a262fd81e3ff6e@york.ac.uk>
References: <000201c52493$e79f0cc0$afe8d182@o1jh>
	<16942.55976.691306.282856@galadriel.ci.tuwien.ac.at>
	<5fe990df0de5700918a262fd81e3ff6e@york.ac.uk>
Message-ID: <Pine.LNX.4.61.0503091259240.14376@gannet.stats>

Without seeing config.log, we have no more idea than you do.

This is an Omegahat package, and either its list or the R-sig-mac list 
would be far more appropriate than this one.  But I suspect the answer is 
clear from config.log -- unpack the package before installing to see it.

On Wed, 9 Mar 2005, Zhesi He wrote:

> Dear all,
>
> I was trying to install RSPYTHON on my Mac OS X 10.3 into R, and got the 
> following errors, is it because of my C compiler or the python I installed?
>
>
> R CMD INSTALL -c Desktop/RSPython_0.5-4.tar.gz
> * Installing *source* package 'RSPython' ...
> checking for python... /usr/bin/python
> Python version 2.3
> Using threads
> checking for gcc... gcc
> checking for C compiler default output... configure: error: C compiler cannot 
> create executables
> See `config.log' for more details.
> ERROR: configuration failed for package 'RSPython'
> ** Removing '/Applications/StartR.app/RAqua.app/Contents/library/RSPython'

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From =?iso-8859-1?Q?Micha=EBl?=  Wed Mar  9 14:14:46 2005
From: =?iso-8859-1?Q?Micha=EBl?= (=?iso-8859-1?Q?Micha=EBl?=)
Date: Wed, 09 Mar 2005 14:14:46 +0100
Subject: [R] multiple comparisons for lme using multcomp
Message-ID: <5.0.2.1.2.20050309141008.00bfd748@utinam.univ-fcomte.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050309/fb10d079/attachment.pl

From roy.werkman at asml.com  Wed Mar  9 14:30:16 2005
From: roy.werkman at asml.com (Roy Werkman)
Date: Wed, 9 Mar 2005 14:30:16 +0100
Subject: [R] Question about biasing in sd()???
Message-ID: <448071208107374B96ED90585EEBA9124CBC63@NLVDHX84.sn-eu.asml.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050309/cf38d03d/attachment.pl

From MSchwartz at MedAnalytics.com  Wed Mar  9 14:30:12 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed, 09 Mar 2005 07:30:12 -0600
Subject: [R] Plotting several series on one set of axes
In-Reply-To: <18347.195.188.213.34.1110367273.squirrel@195.188.213.34>
References: <18347.195.188.213.34.1110367273.squirrel@195.188.213.34>
Message-ID: <1110375013.8857.3.camel@horizons.localdomain>

On Wed, 2005-03-09 at 11:21 +0000, midnightsun at blueyonder.co.uk wrote:
> Dear All,
> 
> I am rather rusty with my R, but I recall being able to do something like
> plot(x1,...);plot(x2,add=TRUE,...)
> to plot two series on the same axes.
> 
> Any suggestions how this may be done will be appreciated.

If you have several series with common axes, you can use matplot() and
do it with a single function call.

See ?matplot for more information.

HTH,

Marc Schwartz



From ronny.klein at wiwi.uni-halle.de  Wed Mar  9 14:46:42 2005
From: ronny.klein at wiwi.uni-halle.de (Ronny Klein)
Date: Wed, 9 Mar 2005 14:46:42 +0100
Subject: [R] Decimal point as a comma in postcript and pdf graphics
Message-ID: <200503091446.42497.ronny.klein@wiwi.uni-halle.de>

Hi,

after a lengthy but unsuccessfull search I couldn't come up with a solution to 
the following problem:

I would like to have a "comma" instead of a "point" as the decimal point in my 
graphics, i.e. postscript and pdf files, for I write my thesis in German. My 
system is:

OS: Debian Unstable
R-Version:  2.0.1
System locale: de_DE at euro

Could someone, please, help me out or at least point me to the right 
documentation. I'm just lost at the moment.

Ronny


PS: The problem of displaying the German umlauts, I have already solved: I 
have to use the WinAnsi.enc as the default encoding file. Which is odd in my 
opinion.



From andy_liaw at merck.com  Wed Mar  9 14:55:01 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 9 Mar 2005 08:55:01 -0500
Subject: [R] Question about biasing in sd()???
Message-ID: <3A822319EB35174CA3714066D590DCD50994E811@usrymx25.merck.com>

Where in the help file of sd() do you see the claim that it produces
unbiased estimate?  Try the following:

sample.sizes <- 3:30
reps <- 5000
set.seed(1)
mean.vars <- sapply(sample.sizes, 
                    function(n) mean(sd(matrix(rnorm(n*reps), nc=reps))^2))
plot(sample.sizes,mean.vars)

I.e., the sample variance, or sd()^2, is unbiased for the true variance.  If
U is an unbiased estimator of a parameter theta, f(U) is _not_ necessarily
unbiased for f(theta).  It would be if f() is linear.

Andy


> From: Roy Werkman
> 
> Hi,
>  
> Can anyone help me with the following. I have been using R for Monte
> Carlo simulations and got some results I couldn't explain. Therefor I
> performed following short test:
>  
> --------------
> mean.sds <- NULL
> sample.sizes <- 3:30
>  
>  for(N in sample.sizes){
>  dum <- NULL
>  for(I in 1:5000){
>   x <- rnorm(N,0,1)
>   dum <- c(dum,sd(x))
>  }
>  mean.sds<- c(mean.sds,mean(dum))
> }
> plot(sample.sizes,mean.sds)
> --------------
>  
> My question is why don't I get 1 as a result from my sd() for small
> sample sizes? According to the help, sd() is unbiased, which anyway
> would not explain the small offset... Is it something in rnorm()?
>  
> Thanx,
> Roy
> 
> 
> -- 
> The information contained in this communication and any\ >...{{dropped}}



From ronny.klein at wiwi.uni-halle.de  Wed Mar  9 14:57:27 2005
From: ronny.klein at wiwi.uni-halle.de (Ronny Klein)
Date: Wed, 9 Mar 2005 14:57:27 +0100
Subject: [R] function in order to plot the same graph to postscript and pdf
Message-ID: <200503091457.28079.ronny.klein@wiwi.uni-halle.de>

Hi,

I've written a function in order to plot the same graph in a postcript and in 
a pdf file. Unfortunately, the second graph is always empty, i.e.:

plot.both <- function{myplot, filename}{
  pdf(file=paste(filename, ".pdf", sep=""))
   myplot
  dev.off()
  postscript(file=paste(filename, ".eps", sep=""))
   myplot
  dev.off()
}

yields in a correct pdf but an empty eps file. However something like this:

plot.both <- function{myplot1, myplot2, filename}{
  pdf(file=paste(filename, ".pdf", sep=""))
   myplot1
  dev.off()
  postscript(file=paste(filename, ".eps", sep=""))
   myplot2
  dev.off()
}

yields the expected results even if myplot1 and myplot2 are identical.

Does somebody know, how I can implement the desired (first) function?

Ronny

PS: My system is: Linux Debian Unstable and R-Version:  2.0.1.



From Achim.Zeileis at wu-wien.ac.at  Wed Mar  9 15:11:17 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Wed, 9 Mar 2005 15:11:17 +0100
Subject: [R] function in order to plot the same graph to postscript and pdf
In-Reply-To: <200503091457.28079.ronny.klein@wiwi.uni-halle.de>
References: <200503091457.28079.ronny.klein@wiwi.uni-halle.de>
Message-ID: <20050309151117.37f9f998.Achim.Zeileis@wu-wien.ac.at>

On Wed, 9 Mar 2005 14:57:27 +0100 Ronny Klein wrote:

> Hi,
> 
> I've written a function in order to plot the same graph in a postcript
> and in a pdf file. Unfortunately, the second graph is always empty,
> i.e.:
> 
> plot.both <- function{myplot, filename}{
>   pdf(file=paste(filename, ".pdf", sep=""))
>    myplot
>   dev.off()
>   postscript(file=paste(filename, ".eps", sep=""))
>    myplot
>   dev.off()
> }
> 
> yields in a correct pdf but an empty eps file. However something like
> this:
> 
> plot.both <- function{myplot1, myplot2, filename}{
>   pdf(file=paste(filename, ".pdf", sep=""))
>    myplot1
>   dev.off()
>   postscript(file=paste(filename, ".eps", sep=""))
>    myplot2
>   dev.off()
> }
> 
> yields the expected results even if myplot1 and myplot2 are identical.

What are the myplot objects? Expressions or graphical objects that are
printed?

In any case, a good recommendation for this kind of stuff is to look at
Sweave() in the utils package. I guess you're writing your thesis in
LaTeX...and Sweave is a great possibility to mix LaTeX code and R code
which for example generates both pdf and eps graphics.
Z

> Does somebody know, how I can implement the desired (first) function?
> 
> Ronny
> 
> PS: My system is: Linux Debian Unstable and R-Version:  2.0.1.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From p.dalgaard at biostat.ku.dk  Wed Mar  9 15:04:51 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 09 Mar 2005 15:04:51 +0100
Subject: [R] Question about biasing in sd()???
In-Reply-To: <448071208107374B96ED90585EEBA9124CBC63@NLVDHX84.sn-eu.asml.com>
References: <448071208107374B96ED90585EEBA9124CBC63@NLVDHX84.sn-eu.asml.com>
Message-ID: <x2psy8ewzg.fsf@biostat.ku.dk>

"Roy Werkman" <roy.werkman at asml.com> writes:

> Hi,
>  
> Can anyone help me with the following. I have been using R for Monte
> Carlo simulations and got some results I couldn't explain. Therefor I
> performed following short test:
>  
> --------------
> mean.sds <- NULL
> sample.sizes <- 3:30
>  
>  for(N in sample.sizes){
>  dum <- NULL
>  for(I in 1:5000){
>   x <- rnorm(N,0,1)
>   dum <- c(dum,sd(x))
>  }
>  mean.sds<- c(mean.sds,mean(dum))
> }
> plot(sample.sizes,mean.sds)
> --------------
>  
> My question is why don't I get 1 as a result from my sd() for small
> sample sizes? According to the help, sd() is unbiased, which anyway
> would not explain the small offset... Is it something in rnorm()?

According to *what* help? In ?sd, it isn't there and it wouldn't be
true if it was there. Please don't spread rumors like that.

The _variance_, var(x) is unbiased, and sd(x) is the square root of
that. It is not possible for a concave function of an unbiased
estimator to be unbiased (unless you're talking median unbiasedness
which is clearly not the case). This is first-year math-stat theory. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jinss at hkusua.hku.hk  Wed Mar  9 15:18:34 2005
From: jinss at hkusua.hku.hk (Jin Shusong)
Date: Wed, 9 Mar 2005 22:18:34 +0800
Subject: [R] R-2.0.1 Gentoo g77 problem
In-Reply-To: <20050309080950.E77871027BE@ws3.hk5.outblaze.com>
References: <20050309080950.E77871027BE@ws3.hk5.outblaze.com>
Message-ID: <20050309141834.GA4060@localhost>

On Wed, Mar 09, 2005 at 04:09:50PM +0800, Gabriel Rossetti wrote:
> Hello,
> 
> I use Gentoo and I can't get R 2.0.1 to compile. I used the portage system, Gentoo's source package sytem, and after it uncompresses the source to R, it says that I don't have a fortran compiler. It told me to use f77 flag and re-emerge gcc, which I did with the f77 and fortran flags, but it still won't compile. Does anyone have any ideas? I suspect that gcc has changed it's interworkings, because if I do a gcc -v it says that I can compile fortran(f77) programs, but I don't have g77. If anyone has any ideas or workarounds, it would be great. I really need it for a P&S class. Thanks!
> 
> Gabriel
> 
> My gcc version is : 
> gcc version 3.3.5  (Gentoo Linux 3.3.5-r1, ssp-3.3.2-3, pie-8.7.7.1)
> --
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Dear Gabriel,
Gentoo does not install g77 with gcc as a default
component.  You should emerge your gcc again.
Just follow the steps below
1. modify your configure file /etc/make.conf.  There is a
line beginning with USE, add f77 in that line.
2. emerge gcc.  This may take a long time.
3. emerge R.  Remember that you should not set the FFLAGS
with aggressive flags.

Good luck. 
-- 


                       Yours  Sincerely

                               Shusong Jin


===============================================================
Add: Meng Wah Complex, RM518     Email: jinss at hkusua.hku.hk
     Dept. of Statistics         Tel:   (+852)28597942
      and Actuarial Science      fax:   (+852)28589041
     The Univ. of Hong Kong
     Pokfulam Road, Hong Kong



From ronny.klein at wiwi.uni-halle.de  Wed Mar  9 15:24:48 2005
From: ronny.klein at wiwi.uni-halle.de (Ronny Klein)
Date: Wed, 9 Mar 2005 15:24:48 +0100
Subject: [R] function in order to plot the same graph to postscript and pdf
In-Reply-To: <20050309151117.37f9f998.Achim.Zeileis@wu-wien.ac.at>
References: <200503091457.28079.ronny.klein@wiwi.uni-halle.de>
	<20050309151117.37f9f998.Achim.Zeileis@wu-wien.ac.at>
Message-ID: <200503091524.48433.ronny.klein@wiwi.uni-halle.de>

> What are the myplot objects? Expressions or graphical objects that are
> printed?

The myplot is something like this:

plot(x)
text(foo)

etc.

> In any case, a good recommendation for this kind of stuff is to look at
> Sweave() in the utils package. I guess you're writing your thesis in
> LaTeX...and Sweave is a great possibility to mix LaTeX code and R code
> which for example generates both pdf and eps graphics.

Thanks, I will have a look on it.

Ronny



From p.dalgaard at biostat.ku.dk  Wed Mar  9 15:18:31 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 09 Mar 2005 15:18:31 +0100
Subject: [R] Decimal point as a comma in postcript and pdf graphics
In-Reply-To: <200503091446.42497.ronny.klein@wiwi.uni-halle.de>
References: <200503091446.42497.ronny.klein@wiwi.uni-halle.de>
Message-ID: <x2ll8wewco.fsf@biostat.ku.dk>

Ronny Klein <ronny.klein at wiwi.uni-halle.de> writes:

> Hi,
> 
> after a lengthy but unsuccessfull search I couldn't come up with a solution to 
> the following problem:
> 
> I would like to have a "comma" instead of a "point" as the decimal point in my 
> graphics, i.e. postscript and pdf files, for I write my thesis in German. My 
> system is:
> 
> OS: Debian Unstable
> R-Version:  2.0.1
> System locale: de_DE at euro
> 
> Could someone, please, help me out or at least point me to the right 
> documentation. I'm just lost at the moment.


We don't have a way of formatting numbers according to LC_NUMERIC, as
far as I know. This leaves it to you to set up axes etc. to your
liking, e.g.

 x <- rnorm(100,,.2)
 p <- pretty(x)
 hist(x,xaxt="n")
 axis(1, at=p, labels=sub("\\.", ",", p))

(and possibly throw in xlim=range(p) on the hist() call. Or use
axTicks(), which is probably a better idea.)

> Ronny
> 
> 
> PS: The problem of displaying the German umlauts, I have already solved: I 
> have to use the WinAnsi.enc as the default encoding file. Which is odd in my 
> opinion.

This should improve in 2.1.0 (or at least be broken in new and
interesting ways) due to support for UTF-8 encodings.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ggrothendieck at myway.com  Wed Mar  9 15:23:54 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 9 Mar 2005 14:23:54 +0000 (UTC)
Subject: [R] Plotting several series on one set of axes
References: <18347.195.188.213.34.1110367273.squirrel@195.188.213.34>
Message-ID: <loom.20050309T151550-767@post.gmane.org>

 <midnightsun <at> blueyonder.co.uk> writes:

: I am rather rusty with my R, but I recall being able to do something like
: plot(x1,...);plot(x2,add=TRUE,...)
: to plot two series on the same axes.
: 

You can use ts.plot to plot multiple ts time series on one set of
axes in one command (even if they have different time bases though
they must have the same frequency). See ?ts.plot

zoo can represent series as irregular so that even ones with 
different frequencies can be simultaneously plotted on the same
axes in one command. See library(zoo)l; help(plot.zoo)



From Achim.Zeileis at wu-wien.ac.at  Wed Mar  9 15:41:25 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Wed, 9 Mar 2005 15:41:25 +0100
Subject: [R] function in order to plot the same graph to postscript and pdf
In-Reply-To: <200503091524.48433.ronny.klein@wiwi.uni-halle.de>
References: <200503091457.28079.ronny.klein@wiwi.uni-halle.de>
	<20050309151117.37f9f998.Achim.Zeileis@wu-wien.ac.at>
	<200503091524.48433.ronny.klein@wiwi.uni-halle.de>
Message-ID: <20050309154125.69ae14b2.Achim.Zeileis@wu-wien.ac.at>

On Wed, 9 Mar 2005 15:24:48 +0100 Ronny Klein wrote:

> > What are the myplot objects? Expressions or graphical objects that
> > are printed?
> 
> The myplot is something like this:
> 
> plot(x)
> text(foo)

Aha, I was surprised that this worked for one of the two plots.
You could pass myplot as an expression, e.g. myplot =
expression(plot(x)), and then eval() that in the body of plot.both(). 

But personally, I wouldn't do that :-) and use Sweave instead.
Z

> etc.
> 
> > In any case, a good recommendation for this kind of stuff is to look
> > at Sweave() in the utils package. I guess you're writing your thesis
> > in LaTeX...and Sweave is a great possibility to mix LaTeX code and R
> > code which for example generates both pdf and eps graphics.
> 
> Thanks, I will have a look on it.
> 
> Ronny
>



From atcdias at biologia.ufrj.br  Wed Mar  9 15:52:36 2005
From: atcdias at biologia.ufrj.br (=?ISO-8859-1?Q?Andr=E9_Tavares?==?ISO-8859-1?Q?Corr=EAa_Dias?=)
Date: Wed, 09 Mar 2005 11:52:36 -0300 (BRT)
Subject: [R] Structural equation models with R
Message-ID: <1110379956.422f0db40fe4a@webmail.biologia.ufrj.br>

Hello useRs,
I`m running structural equation models with R, but for one of my models the 
below error message apears. I`m trying to change startvalues but without 
success. The manual for sem package did not help me. Does anyone knows how to 
change startvalues for iteration in sem package? Or it can be another problem 
with the model?

Error in startvalues(S, ram, debug = debug, tol = start.tol) : 
subscript out of bounds

The model (with three latent variables: 'reg','folha','solo'))

model.com=matrix(c(
'ridos>dendos',	'a1',	NA,
'ridos>reg',	'a2',	NA,
'ridos>folha',	'a3',	NA,
'ridos>solo',	'a4',	NA,
'ridos>raiz',	'a5',	NA,
'dendos>litter',	'a6',	NA,
'dendos>reg',	'a7',	NA,
'litter>reg',	'a8',	NA,
'folha>reg',	'a9',	NA,
'solo>reg',		'a10',	NA,
'raiz>reg',		'a11',	NA,
'raiz>solo',	'a12',	NA,
'folha>solo',	'a13',	NA,
'reg>denjov',	'l1',	NA,
'reg>riqjov',	'l2',	NA,
'folha>nfolha',	'l3',	NA,
'folha>pfolha',	'l4',	NA,
'solo>nsolo',	'l5',	NA,
'solo>psolo',	'l6',	NA,
'riqjov<>riqjov',	'e1',	NA,
'denjov<>denjov',	'e2',	NA,
'litter<>litter',	'e3',	NA,
'riqdos<>riqdos',	'e4',	NA,
'dendos<>dendos',	'e5',	NA,
'raiz<>raiz',	'e6',	NA,
'nsolo<>nsolo',	'e7',	NA,
'psolo<>psolo',	'e8',	NA,
'nfolha<>nfolha',	'e9', NA,
'pfolha<>pfolha',	'e10',	NA,
'reg<>reg',		NA,	1,
'solo<>solo',	NA,	1,
'folha<>folha',	NA,	1),
ncol=3, byrow=TRUE)

obs.vars.com=c('riqjov','denjov','litter','riqdos','dendos','raiz',
'nsolo','psolo','nfolha','pfolha')

sem.com=sem(model.com,S.com,30,obs.vars.com)

-------------------------------
Andr? Tavares Corr?a Dias
Laborat?rio de Ecologia Vegetal
Departamento de Ecologia - IB
Universidade Federal do Rio de Janeiro
Ilha do Fund?o, CCS
Rio de Janeiro, RJ. Brasil
CEP 21941-590    CP 68020
Tel. (21)2562-6377



From ripley at stats.ox.ac.uk  Wed Mar  9 15:57:51 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 9 Mar 2005 14:57:51 +0000 (GMT)
Subject: [R] nnet abstol
In-Reply-To: <0BA7EE4D4646E0409D458D347C508B783C624B@MAILSERV1.uni.glam.ac.uk>
References: <0BA7EE4D4646E0409D458D347C508B783C624B@MAILSERV1.uni.glam.ac.uk>
Message-ID: <Pine.LNX.4.61.0503091452530.15750@gannet.stats>

>From the help page:

   abstol: Stop if the fit criterion falls below 'abstol', indicating an
           essentially perfect fit.

Now, what the `fit criterion' is depends on the other options that you 
have not told us, but I don't see MSE mentioned anywhere on that help 
page, and I do see `least-squares'.

On Wed, 9 Mar 2005, Kemp S E (Comp) wrote:

> Hi,
>
> I am using nnet to learn transfer functions. For each transfer function 
> I can estimate the best possible Mean Squared Error (MSE). So, rather 
> than trying to grind the MSE to 0, I would like to use abstol to stop 
> training once the best MSE is reached.
>
> Can anyone confirm that the abstol parameter in the nnet function is the 
> MSE, or is it the Sum-of-Squares (SSE)?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed Mar  9 16:12:01 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 9 Mar 2005 15:12:01 +0000 (GMT)
Subject: [R] Decimal point as a comma in postcript and pdf graphics
In-Reply-To: <200503091446.42497.ronny.klein@wiwi.uni-halle.de>
References: <200503091446.42497.ronny.klein@wiwi.uni-halle.de>
Message-ID: <Pine.LNX.4.61.0503091500080.15750@gannet.stats>

On Wed, 9 Mar 2005, Ronny Klein wrote:

> Hi,
>
> after a lengthy but unsuccessfull search I couldn't come up with a 
> solution to the following problem:
>
> I would like to have a "comma" instead of a "point" as the decimal point in my
> graphics, i.e. postscript and pdf files, for I write my thesis in German. My
> system is:
>
> OS: Debian Unstable
> R-Version:  2.0.1
> System locale: de_DE at euro
>
> Could someone, please, help me out or at least point me to the right
> documentation. I'm just lost at the moment.

You need to label your axes with comma: R does not support , as a decimal 
point.  Use explicit calls to axis(), or edit the postscript after 
production.

No one has ever requested this before.  Since the grammar would not allow 
, to be used as a decimal point for console input, it is awkward to allow 
it for output (but a few functions such as write.table do).


> PS: The problem of displaying the German umlauts, I have already solved: I
> have to use the WinAnsi.enc as the default encoding file. Which is odd in my
> opinion.

It's not true!  There is a problem with some PDF viewers, worked around a 
long time ago in R-patched:

     o	Some PDF readers do not define PDFDocEncoding, so pdf()'s
 	ISOLatin1 encoding is now derived from WinAnsi rather than
 	PDFDocEncoding.

It seems Adobe changed the standard since the version that the pdf() 
device was written to support, and some viewers are not backwards 
compatible.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jfox at mcmaster.ca  Wed Mar  9 16:13:27 2005
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 9 Mar 2005 10:13:27 -0500
Subject: [R] Structural equation models with R
In-Reply-To: <1110379956.422f0db40fe4a@webmail.biologia.ufrj.br>
Message-ID: <20050309151325.UJJA1836.tomts16-srv.bellnexxia.net@JohnDesktop8300>

Dear Andre,

Is one of the observed variables named "ridos" or "riqdos"?

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Andr? 
> TavaresCorr?a Dias
> Sent: Wednesday, March 09, 2005 9:53 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Structural equation models with R
> 
> Hello useRs,
> I`m running structural equation models with R, but for one of 
> my models the below error message apears. I`m trying to 
> change startvalues but without success. The manual for sem 
> package did not help me. Does anyone knows how to change 
> startvalues for iteration in sem package? Or it can be 
> another problem with the model?
> 
> Error in startvalues(S, ram, debug = debug, tol = start.tol) : 
> subscript out of bounds
> 
> The model (with three latent variables: 'reg','folha','solo'))
> 
> model.com=matrix(c(
> 'ridos>dendos',	'a1',	NA,
> 'ridos>reg',	'a2',	NA,
> 'ridos>folha',	'a3',	NA,
> 'ridos>solo',	'a4',	NA,
> 'ridos>raiz',	'a5',	NA,
> 'dendos>litter',	'a6',	NA,
> 'dendos>reg',	'a7',	NA,
> 'litter>reg',	'a8',	NA,
> 'folha>reg',	'a9',	NA,
> 'solo>reg',		'a10',	NA,
> 'raiz>reg',		'a11',	NA,
> 'raiz>solo',	'a12',	NA,
> 'folha>solo',	'a13',	NA,
> 'reg>denjov',	'l1',	NA,
> 'reg>riqjov',	'l2',	NA,
> 'folha>nfolha',	'l3',	NA,
> 'folha>pfolha',	'l4',	NA,
> 'solo>nsolo',	'l5',	NA,
> 'solo>psolo',	'l6',	NA,
> 'riqjov<>riqjov',	'e1',	NA,
> 'denjov<>denjov',	'e2',	NA,
> 'litter<>litter',	'e3',	NA,
> 'riqdos<>riqdos',	'e4',	NA,
> 'dendos<>dendos',	'e5',	NA,
> 'raiz<>raiz',	'e6',	NA,
> 'nsolo<>nsolo',	'e7',	NA,
> 'psolo<>psolo',	'e8',	NA,
> 'nfolha<>nfolha',	'e9', NA,
> 'pfolha<>pfolha',	'e10',	NA,
> 'reg<>reg',		NA,	1,
> 'solo<>solo',	NA,	1,
> 'folha<>folha',	NA,	1),
> ncol=3, byrow=TRUE)
> 
> obs.vars.com=c('riqjov','denjov','litter','riqdos','dendos','raiz',
> 'nsolo','psolo','nfolha','pfolha')
> 
> sem.com=sem(model.com,S.com,30,obs.vars.com)
> 
> -------------------------------
> Andr? Tavares Corr?a Dias
> Laborat?rio de Ecologia Vegetal
> Departamento de Ecologia - IB
> Universidade Federal do Rio de Janeiro
> Ilha do Fund?o, CCS
> Rio de Janeiro, RJ. Brasil
> CEP 21941-590    CP 68020
> Tel. (21)2562-6377
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ggrothendieck at myway.com  Wed Mar  9 15:55:09 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 9 Mar 2005 14:55:09 +0000 (UTC)
Subject: [R] function in order to plot the same graph to postscript and pdf
References: <200503091457.28079.ronny.klein@wiwi.uni-halle.de>
Message-ID: <loom.20050309T155329-837@post.gmane.org>

Ronny Klein <ronny.klein <at> wiwi.uni-halle.de> writes:

: 
: Hi,
: 
: I've written a function in order to plot the same graph in a postcript and 
in 
: a pdf file. Unfortunately, the second graph is always empty, i.e.:
: 
: plot.both <- function{myplot, filename}{
:   pdf(file=paste(filename, ".pdf", sep=""))
:    myplot
:   dev.off()
:   postscript(file=paste(filename, ".eps", sep=""))
:    myplot
:   dev.off()
: }
: 
: yields in a correct pdf but an empty eps file. However something like this:
: 
: plot.both <- function{myplot1, myplot2, filename}{
:   pdf(file=paste(filename, ".pdf", sep=""))
:    myplot1
:   dev.off()
:   postscript(file=paste(filename, ".eps", sep=""))
:    myplot2
:   dev.off()
: }
: 
: yields the expected results even if myplot1 and myplot2 are identical.
: 
: Does somebody know, how I can implement the desired (first) function?
: 
: Ronny
: 
: PS: My system is: Linux Debian Unstable and R-Version:  2.0.1.
: 

The following works on Windows R 2.1.0.  Don't know about Linux:

dev.control(displaylist="enable") # enable display list
plot(1:10)
myplot <- recordPlot() # load displaylist into variable
savePlot("myplot", type = "pdf")
savePlot("myplot", type = "ps")



From tghoward at gw.dec.state.ny.us  Wed Mar  9 17:07:42 2005
From: tghoward at gw.dec.state.ny.us (Tim Howard)
Date: Wed, 09 Mar 2005 11:07:42 -0500
Subject: [R] Encodebuf?  yet another memory question
Message-ID: <s22ed90b.038@gwsmtp.DEC.STATE.NY.US>

Hi all,
   I was surprised to see this memory error:

Error in scan(Cn.minex13, nlines = 2, quiet = TRUE) : 
        Could not allocate memory for Encodebuf
> memory.size(max=TRUE)
[1] 256843776
> memory.size(FALSE)
[1] 180144528
> memory.limit()
[1] 2147483648


I don't have any objects named 'Encodebuf' and help and the R site
search turn up no matches for this word.  

As memory.size and memory.limit indicate, I'm way below my limit (but,
I grant that maybe windows won't give R any more memory...).   In my
next run, I'll ask to scan fewer lines, but I thought it worth asking
the group if this 'Encodebuf' error meant anything different than the
standard "can't allocate xxxxx bytes" message. (btw, if you are confused
that scanning only 2 lines would max out my memory... I'm scanning two
long lines from 36 different connections so it does add up).

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    0.1            
year     2004           
month    11             
day      15             
language R  

Thanks.

Tim Howard



From Ollivier.Taramasco at imag.fr  Wed Mar  9 17:12:20 2005
From: Ollivier.Taramasco at imag.fr (Ollivier TARAMASCO)
Date: Wed, 9 Mar 2005 17:12:20 +0100
Subject: [R] R CMD check errors
Message-ID: <20050309161310.9F63A8E159@mailu2.upmf-grenoble.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050309/7c2c50bd/attachment.pl

From greg.snow at ihc.com  Wed Mar  9 17:23:44 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Wed, 09 Mar 2005 09:23:44 -0700
Subject: [R] Decimal point as a comma in postcript and pdf graphics
Message-ID: <s22ec0a8.025@lp-msg1.co.ihc.com>

>>>> Peter Dalgaard <p.dalgaard at biostat.ku.dk> 03/09/05 07:18AM >>>
>Ronny Klein <ronny.klein at wiwi.uni-halle.de> writes:
>
>> Hi,
>> 
>> after a lengthy but unsuccessfull search I couldn't come up with a
solution to 
>> the following problem:
>> 
>> I would like to have a "comma" instead of a "point" as the decimal
point in my 
>> graphics, i.e. postscript and pdf files, for I write my thesis in
German. My 
>> system is:
>> 
>> OS: Debian Unstable
>> R-Version:  2.0.1
>> System locale: de_DE at euro
>> 
>> Could someone, please, help me out or at least point me to the right

>> documentation. I'm just lost at the moment.
>
>
>We don't have a way of formatting numbers according to LC_NUMERIC, as
>far as I know. This leaves it to you to set up axes etc. to your
>liking, e.g.
>
> x <- rnorm(100,,.2)
> p <- pretty(x)
> hist(x,xaxt="n")
> axis(1, at=p, labels=sub("\\.", ",", p))

or for the last line:

axis(1, at=p, labels=format(p, decimal.mark=','))


>
>(and possibly throw in xlim=range(p) on the hist() call. Or use
>axTicks(), which is probably a better idea.)
>
>> Ronny
>> 
>> 
>> PS: The problem of displaying the German umlauts, I have already
solved: I 
>> have to use the WinAnsi.enc as the default encoding file. Which is
odd in my 
>> opinion.
>
>This should improve in 2.1.0 (or at least be broken in new and
>interesting ways) due to support for UTF-8 encodings.



Greg Snow, Ph.D.
Statistical Data Center
greg.snow at ihc.com
(801) 408-8111



From cdeclercq at nordnet.fr  Wed Mar  9 17:46:45 2005
From: cdeclercq at nordnet.fr (Christophe Declercq)
Date: Wed, 9 Mar 2005 17:46:45 +0100
Subject: [R] Decimal point as a comma in postcript and pdf graphics
In-Reply-To: <x2ll8wewco.fsf@biostat.ku.dk>
Message-ID: <MJELLLFFFCNHMHOOLCMBKEPGDAAA.cdeclercq@nordnet.fr>



> De : r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]De la part de
> Peter Dalgaard
> Envoye : mercredi 9 mars 2005 15:19
>
>
> Ronny Klein <ronny.klein at wiwi.uni-halle.de> writes:

[...]
> > I would like to have a "comma" instead of a "point" as
> the decimal point in my
> > graphics, i.e. postscript and pdf files, for I write my
> thesis in German. My
[...]
>
> We don't have a way of formatting numbers according to
> LC_NUMERIC, as
> far as I know. This leaves it to you to set up axes etc. to your
> liking, e.g.
>
>  x <- rnorm(100,,.2)
>  p <- pretty(x)
>  hist(x,xaxt="n")
>  axis(1, at=p, labels=sub("\\.", ",", p))
>
> (and possibly throw in xlim=range(p) on the hist() call. Or use
> axTicks(), which is probably a better idea.)

When I need that, I use something like Peter but with the 'format'
function, for example:

  x <- rnorm(100,,.2)
  p <- pretty(x)
  hist(x,xaxt="n")
  axis(1, at=p, labels=format(pretty(x), decimal.mark=","))

Hope it helps.

Christophe
--
Christophe Declercq, MD
Observatoire regional de la sante Nord-Pas-de-Calais
13, rue Faidherbe
F-59046 LILLE Cedex
Phone 33 3 20 15 49 24
Fax 33 3 20 55 92 30
E-mail c.declercq at orsnpdc.org


>
> > Ronny
> >
> >
> > PS: The problem of displaying the German umlauts, I have
> already solved: I
> > have to use the WinAnsi.enc as the default encoding file.
> Which is odd in my
> > opinion.
>
> This should improve in 2.1.0 (or at least be broken in new and
> interesting ways) due to support for UTF-8 encodings.
>
> --
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph:
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX:
> (+45) 35327907
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>
>



From ripley at stats.ox.ac.uk  Wed Mar  9 17:49:23 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 9 Mar 2005 16:49:23 +0000 (GMT)
Subject: [R] Encodebuf?  yet another memory question
In-Reply-To: <s22ed90b.038@gwsmtp.DEC.STATE.NY.US>
References: <s22ed90b.038@gwsmtp.DEC.STATE.NY.US>
Message-ID: <Pine.LNX.4.61.0503091641070.16872@gannet.stats>

On Wed, 9 Mar 2005, Tim Howard wrote:

> Hi all,
>   I was surprised to see this memory error:
>
> Error in scan(Cn.minex13, nlines = 2, quiet = TRUE) :
>        Could not allocate memory for Encodebuf
>> memory.size(max=TRUE)
> [1] 256843776
>> memory.size(FALSE)
> [1] 180144528
>> memory.limit()
> [1] 2147483648
>
>
> I don't have any objects named 'Encodebuf' and help and the R site
> search turn up no matches for this word.

Try the source code, specifically that for R_AllocStringBuffer.

> As memory.size and memory.limit indicate, I'm way below my limit (but,
> I grant that maybe windows won't give R any more memory...).   In my
> next run, I'll ask to scan fewer lines, but I thought it worth asking
> the group if this 'Encodebuf' error meant anything different than the
> standard "can't allocate xxxxx bytes" message. (btw, if you are confused
> that scanning only 2 lines would max out my memory... I'm scanning two
> long lines from 36 different connections so it does add up).

Yes, in that it is a direct call to malloc so no gc() takes place.
In any case, you have run out of memory and this is perfectly possible if 
they are long lines since scan reads a line at a time into memory.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ronny.klein at wiwi.uni-halle.de  Wed Mar  9 18:21:41 2005
From: ronny.klein at wiwi.uni-halle.de (Ronny Klein)
Date: Wed, 9 Mar 2005 18:21:41 +0100
Subject: [R] function in order to plot the same graph to postscript and pdf
In-Reply-To: <20050309154125.69ae14b2.Achim.Zeileis@wu-wien.ac.at>
References: <200503091457.28079.ronny.klein@wiwi.uni-halle.de>
	<200503091524.48433.ronny.klein@wiwi.uni-halle.de>
	<20050309154125.69ae14b2.Achim.Zeileis@wu-wien.ac.at>
Message-ID: <200503091821.41428.ronny.klein@wiwi.uni-halle.de>

> > The myplot is something like this:
> >
> > plot(x)
> > text(foo)
>
> Aha, I was surprised that this worked for one of the two plots.
> You could pass myplot as an expression, e.g. myplot =
> expression(plot(x)), and then eval() that in the body of plot.both().

I've followed your advice and changed my function to something like this:

plot.both <- function{myplot, filename}{
     MYPLOT <- expression(myplot)
     pdf(file=paste(filename, ".pdf", sep=""))
     eval(myplot)
     dev.off()
     postscript(file=paste(filename, ".eps", sep=""))
     eval(myplot)
    dev.off()
 }

However the result is the same: the first one is actually printed but the 
second plot is empty. 

Ronny



From knoblauch at lyon.inserm.fr  Wed Mar  9 17:27:27 2005
From: knoblauch at lyon.inserm.fr (Ken Knoblauch)
Date: Wed,  9 Mar 2005 17:27:27 +0100
Subject: [R] problem using uniroot with integrate
Message-ID: <1110385647.422f23efd138d@webmail.lyon.inserm.fr>

Hi, 

I'm trying to calculate the value of the variable, dp, below, in the
argument to the integral of dnorm(x-dp) * pnorm(x)^(m-1).  This
corresponds to the estimate of the sensitivity of an observer in an
m-alternative forced choice experiment, given the probability of
a correct response, Pc, a Gaussian assumption for the noise and
no bias.  The function that I wrote below gives me an error:

Error in f(x, ...) : recursive default argument reference

The problem seems to be at the statement using uniroot,
because the furntion est.dp works fine outside of the main function.
I've been using R for awhile but there are still many nuances
about the scoping and the use of environments that I'm weak on
and would like to understand better.  I would appreciate any
suggestions or solutions that anyone might offer for fixing
my error.  Thank you.

dprime.mAFC <- function(Pc, m) {
		est.dp <- function(dp, Pc = Pc, m = m) {
		
		  pr <- function(x, dpt = dp, m0 = m) {
		    	dnorm(x - dpt) * pnorm(x)^(m0 - 1)
			    }
		
		  Pc - integrate(pr, lower = -Inf, upper = Inf, 
		  dpt = dp, m0 = m)$value
		}
		
	dp.res <- uniroot(est.dp, interval = c(0,5), Pc = Pc, m = m)
	dp.res$root	
	}

platform powerpc-apple-darwin6.8
arch     powerpc                
os       darwin6.8              
system   powerpc, darwin6.8     
status                          
major    2                      
minor    0.1                    
year     2004                   
month    11                     
day      15                     
language R 

ken

____________________
Ken Knoblauch
Inserm U 371
Cerveau et Vision
18 avenue du Doyen Lepine
69675 Bron cedex
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: 06 84 10 64 10



From andy_liaw at merck.com  Wed Mar  9 18:39:53 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 9 Mar 2005 12:39:53 -0500
Subject: [R] function in order to plot the same graph to postscript
	an d pdf
Message-ID: <3A822319EB35174CA3714066D590DCD50994E817@usrymx25.merck.com>

This works for me:

plot.both <- function(expr, filename) {
     pdf(file=paste(filename, ".pdf", sep=""))
     eval(expr)
     dev.off()
     postscript(file=paste(filename, ".eps", sep=""))
     eval(expr)
    dev.off()
}

plot.both(expression(plot(1:10)), "testboth")


Andy

PS:  Please make sure you post correct code.  The code you posted has syntax
(and other) errors.

> From: Ronny Klein
> 
> > > The myplot is something like this:
> > >
> > > plot(x)
> > > text(foo)
> >
> > Aha, I was surprised that this worked for one of the two plots.
> > You could pass myplot as an expression, e.g. myplot =
> > expression(plot(x)), and then eval() that in the body of 
> plot.both().
> 
> I've followed your advice and changed my function to 
> something like this:
> 
> plot.both <- function{myplot, filename}{
>      MYPLOT <- expression(myplot)
>      pdf(file=paste(filename, ".pdf", sep=""))
>      eval(myplot)
>      dev.off()
>      postscript(file=paste(filename, ".eps", sep=""))
>      eval(myplot)
>     dev.off()
>  }
> 
> However the result is the same: the first one is actually 
> printed but the 
> second plot is empty. 
> 
> Ronny
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From chris.jackson at imperial.ac.uk  Wed Mar  9 18:41:36 2005
From: chris.jackson at imperial.ac.uk (Chris Jackson)
Date: Wed, 09 Mar 2005 17:41:36 +0000
Subject: [R] R CMD check errors
In-Reply-To: <20050309161310.9F63A8E159@mailu2.upmf-grenoble.fr>
References: <20050309161310.9F63A8E159@mailu2.upmf-grenoble.fr>
Message-ID: <422F3550.2010108@imperial.ac.uk>

In my experience these are usually signs of an error in your NAMESPACE
file, such as a function name in the NAMESPACE which does not match the
function name in the package.

Chris

Ollivier TARAMASCO wrote:

 > I wrote a library which seems to work on my PC, and on different Unix
 > systems.
 >
 > As it is written in the "Writing R Extensions" manual, I execute a R CMD
 > check on my library.
 >
 >
 > I have always the same errors messages:
 >
 > * checking S3 generic/method consistency ... WARNING
 > Error in .try_quietly({ : Error in library(package, lib.loc = lib.loc,
 > character
 > .only = TRUE, verbose = FALSE) :
 >         package/namespace load failed for 'TATA'
 > Execution halted
 >
 > See section 'Generic functions and methods' of the 'Writing R Extensions'
 > manual.
 >
 >
 > * checking replacement functions ... WARNING
 > Error in .try_quietly({ : Error in library(package, lib.loc = lib.loc,
 > character
 > .only = TRUE, verbose = FALSE) :
 >         package/namespace load failed for 'TATA'
 > Execution halted
 >
 > In R, the argument of a replacement function which corresponds to the 
right
 > hand side must be named 'value'.
 >
 >
 > * checking foreign function calls ... WARNING
 > Error in .try_quietly({ : Error in library(package, lib.loc = lib.loc,
 > character
 > .only = TRUE, verbose = FALSE) :
 >         package/namespace load failed for 'TATA'
 > Execution halted
 > See section 'System and foreign language interfaces' of the 'Writing R
 > Extensions' manual.


-- 
Christopher Jackson <chris.jackson at imperial.ac.uk>, Research Associate,
Department of Epidemiology and Public Health, Imperial College
School of Medicine, Norfolk Place, London W2 1PG, tel. 020 759 43371



From xt_wang at cse.concordia.ca  Wed Mar  9 18:44:52 2005
From: xt_wang at cse.concordia.ca (xt_wang@cse.concordia.ca)
Date: Wed,  9 Mar 2005 12:44:52 -0500
Subject: [R] about create a R package
Message-ID: <1110390292.422f361421ad6@mail.encs.concordia.ca>


Hello, everyone,

I would like to create a package which includes C code. My input data comes from
a text file and I will output my solution into a text file too. My question is
that I put the input file in src directory or data directory or somewhere else?

On the other hand, I want to call this C function from R. Is he R code put in
the R directory or I carry out this code in R environment directly?

maggie



From sundar.dorai-raj at pdf.com  Wed Mar  9 18:57:33 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 09 Mar 2005 11:57:33 -0600
Subject: [R] problem using uniroot with integrate
In-Reply-To: <1110385647.422f23efd138d@webmail.lyon.inserm.fr>
References: <1110385647.422f23efd138d@webmail.lyon.inserm.fr>
Message-ID: <422F390D.80909@pdf.com>



Ken Knoblauch wrote on 3/9/2005 10:27 AM:
> Hi, 
> 
> I'm trying to calculate the value of the variable, dp, below, in the
> argument to the integral of dnorm(x-dp) * pnorm(x)^(m-1).  This
> corresponds to the estimate of the sensitivity of an observer in an
> m-alternative forced choice experiment, given the probability of
> a correct response, Pc, a Gaussian assumption for the noise and
> no bias.  The function that I wrote below gives me an error:
> 
> Error in f(x, ...) : recursive default argument reference
> 
> The problem seems to be at the statement using uniroot,
> because the furntion est.dp works fine outside of the main function.
> I've been using R for awhile but there are still many nuances
> about the scoping and the use of environments that I'm weak on
> and would like to understand better.  I would appreciate any
> suggestions or solutions that anyone might offer for fixing
> my error.  Thank you.
> 
> dprime.mAFC <- function(Pc, m) {
> 		est.dp <- function(dp, Pc = Pc, m = m) {
> 		
> 		  pr <- function(x, dpt = dp, m0 = m) {
> 		    	dnorm(x - dpt) * pnorm(x)^(m0 - 1)
> 			    }
> 		
> 		  Pc - integrate(pr, lower = -Inf, upper = Inf, 
> 		  dpt = dp, m0 = m)$value
> 		}
> 		
> 	dp.res <- uniroot(est.dp, interval = c(0,5), Pc = Pc, m = m)
> 	dp.res$root	
> 	}
> 

Ken,

Look at the argument list for ?uniroot and think "partial matching". 
You're "m" is being interpretted for "maxiter". Simply change to

dp.res <- uniroot(est.dp, interval = c(0,5), Pc = Pc, m0 = m)

and in other places for consistency and the error goes away. Of course, 
since you gave no working example, I'm not sure if other errors are 
present that I'm missing.

--sundar



From tplate at acm.org  Wed Mar  9 19:10:48 2005
From: tplate at acm.org (Tony Plate)
Date: Wed, 09 Mar 2005 11:10:48 -0700
Subject: [R] problem using uniroot with integrate
In-Reply-To: <1110385647.422f23efd138d@webmail.lyon.inserm.fr>
References: <1110385647.422f23efd138d@webmail.lyon.inserm.fr>
Message-ID: <6.2.1.2.2.20050309110319.1aab5c10@mailhost.blackmesacapital.com>

At Wednesday 09:27 AM 3/9/2005, Ken Knoblauch wrote:
>Hi,
>
>I'm trying to calculate the value of the variable, dp, below, in the
>argument to the integral of dnorm(x-dp) * pnorm(x)^(m-1).  This
>corresponds to the estimate of the sensitivity of an observer in an
>m-alternative forced choice experiment, given the probability of
>a correct response, Pc, a Gaussian assumption for the noise and
>no bias.  The function that I wrote below gives me an error:
>
>Error in f(x, ...) : recursive default argument reference
>
>The problem seems to be at the statement using uniroot,
>because the furntion est.dp works fine outside of the main function.
>I've been using R for awhile but there are still many nuances
>about the scoping and the use of environments that I'm weak on
>and would like to understand better.  I would appreciate any
>suggestions or solutions that anyone might offer for fixing
>my error.  Thank you.
>
>dprime.mAFC <- function(Pc, m) {
>                 est.dp <- function(dp, Pc = Pc, m = m) {
>
>                   pr <- function(x, dpt = dp, m0 = m) {
>                         dnorm(x - dpt) * pnorm(x)^(m0 - 1)
>                             }
>
>                   Pc - integrate(pr, lower = -Inf, upper = Inf,
>                   dpt = dp, m0 = m)$value
>                 }
>
>         dp.res <- uniroot(est.dp, interval = c(0,5), Pc = Pc, m = m)
>         dp.res$root
>         }

You've got several problems here
* recursive argument defaults: these are unnecessary but result in the 
particular error message you are seeing (e.g., in the def of est.dp, the 
default value for the argument 'm' is the value of the argument 'm' itself 
-- default values for arguments are interpreted in the frame of the 
function itself)
* the argument m=m you supply to uniroot() is being interpreted as 
specifying the 'maxiter' argument to uniroot()

I think you can fix it by changing the 'm' argument of function est.dp to 
be named 'm0', and specifying 'm0' in the call to uniroot.  (but I can't 
tell for sure because you didn't supply a working example -- when I just 
guess at values to pass in I get numerical errors.)
Also, it would be best to remove the incorrect recursive default arguments 
for the functions est.dp and pr.

-- Tony Plate



From Robert.McGehee at geodecapital.com  Wed Mar  9 19:17:06 2005
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Wed, 9 Mar 2005 13:17:06 -0500
Subject: [R] function in order to plot the same graph to postscript and pdf
Message-ID: <67DCA285A2D7754280D3B8E88EB548020C1ED69F@MSGBOSCLB2WIN.DMN1.FMR.COM>

Use substitute() instead of expression(); choose to use either MYPLOT or
myplot because they are different variables; and use parentheses around
your function arguments instead of braces.

-----Original Message-----
From: Ronny Klein [mailto:ronny.klein at wiwi.uni-halle.de] 
Sent: Wednesday, March 09, 2005 12:22 PM
To: Achim Zeileis
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] function in order to plot the same graph to postscript
and pdf


> > The myplot is something like this:
> >
> > plot(x)
> > text(foo)
>
> Aha, I was surprised that this worked for one of the two plots.
> You could pass myplot as an expression, e.g. myplot =
> expression(plot(x)), and then eval() that in the body of plot.both().

I've followed your advice and changed my function to something like
this:

plot.both <- function{myplot, filename}{
     MYPLOT <- expression(myplot)
     pdf(file=paste(filename, ".pdf", sep=""))
     eval(myplot)
     dev.off()
     postscript(file=paste(filename, ".eps", sep=""))
     eval(myplot)
    dev.off()
 }

However the result is the same: the first one is actually printed but
the 
second plot is empty. 

Ronny

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From cberry at tajo.ucsd.edu  Wed Mar  9 19:21:09 2005
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Wed, 9 Mar 2005 10:21:09 -0800
Subject: [R] R-2.0.1 Gentoo g77 problem
In-Reply-To: <20050309080950.E77871027BE@ws3.hk5.outblaze.com>
References: <20050309080950.E77871027BE@ws3.hk5.outblaze.com>
Message-ID: <Pine.LNX.4.62.0503091007180.28376@tajo.ucsd.edu>

On Wed, 9 Mar 2005, Gabriel Rossetti wrote:

> Hello,
>
> I use Gentoo and I can't get R 2.0.1 to compile. I used the portage 
> system, Gentoo's source package sytem, and after it uncompresses the 
> source to R, it says that I don't have a fortran compiler. It told me to 
> use f77 flag and re-emerge gcc, which I did with the f77 and fortran 
> flags, but it still won't compile. Does anyone have any ideas? I suspect 
> that gcc has changed it's interworkings, because if I do a gcc -v it 
> says that I can compile fortran(f77) programs, but I don't have g77. If 
> anyone has any ideas or workarounds, it would be great. I really need it 
> for a P&S class. Thanks!


After experiencing similar problems and noticing that g77 was nowhere to 
be found, I symlinked /usr/bin/g77 --> /usr/bin/gcc.

R then built and passed 'make check'.

Surely there is something wrong with my approach that this hack is needed, 
but figuring out what is wrong is not high on my list...

BTW, I build R outside of portage and install R into /usr/local to avoid 
the lag between Gentoo ebuilds and the current R-release.

Chuck

>
> Gabriel
>
> My gcc version is :
> gcc version 3.3.5  (Gentoo Linux 3.3.5-r1, ssp-3.3.2-3, pie-8.7.7.1)
> --
>
>
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://hacuna.ucsd.edu/members/ccb.html  La Jolla, San Diego 92093-0717



From OBUCHNER at DAL.CA  Wed Mar  9 19:28:38 2005
From: OBUCHNER at DAL.CA (Owen Buchner)
Date: Wed,  9 Mar 2005 14:28:38 -0400
Subject: [R] plotting
Message-ID: <1110392918.422f40568c26e@my2.dal.ca>

I have two questions for you.  Firstly I'm having troubles trying to plot more
then 1 graph.  I'm attempting to make a plot with 9 panels, but i have no clue
what type of code to use.
Secondly i was wondering if there was some code to generate random numbers
between two defined intervals and then have R chose one randomly in a program. 
If you could answer either of these questions for me I would appreciate it.

Owen Buchner



From wgshi2001 at yahoo.ca  Wed Mar  9 19:31:16 2005
From: wgshi2001 at yahoo.ca (Weiguang Shi)
Date: Wed, 9 Mar 2005 13:31:16 -0500 (EST)
Subject: [R] about kpss.test()
Message-ID: <20050309183116.71326.qmail@web30003.mail.mud.yahoo.com>

Hi All,

First of all, could you tell me what the "KPSS Level" 
in the output of the test means?

I have a series, x, of periodic data and tried 
kpss.test() on it to verify its stationarity. The
tests
gave me the p-value above 0.1. Since the null 
hypothesis N0 is that the series _is_ stationary, this

means that I cannot reject N0. But the series does
look
periodic!

So does all this say stationarity and periodicity can 
co-exist?

Thanks,
Weiguang



From Achim.Zeileis at wu-wien.ac.at  Wed Mar  9 19:35:13 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Wed, 9 Mar 2005 19:35:13 +0100
Subject: [R] function in order to plot the same graph to postscript and pdf
In-Reply-To: <200503091821.41428.ronny.klein@wiwi.uni-halle.de>
References: <200503091457.28079.ronny.klein@wiwi.uni-halle.de>
	<200503091524.48433.ronny.klein@wiwi.uni-halle.de>
	<20050309154125.69ae14b2.Achim.Zeileis@wu-wien.ac.at>
	<200503091821.41428.ronny.klein@wiwi.uni-halle.de>
Message-ID: <20050309193513.1c6b3d11.Achim.Zeileis@wu-wien.ac.at>

On Wed, 9 Mar 2005 18:21:41 +0100 Ronny Klein wrote:

> > > The myplot is something like this:
> > >
> > > plot(x)
> > > text(foo)
> >
> > Aha, I was surprised that this worked for one of the two plots.
> > You could pass myplot as an expression, e.g. myplot =
> > expression(plot(x)), and then eval() that in the body of
> > plot.both().
> 
> I've followed your advice

Not quite...

> and changed my function to something like this:
> 
> plot.both <- function{myplot, filename}{
>      MYPLOT <- expression(myplot)
>      pdf(file=paste(filename, ".pdf", sep=""))
>      eval(myplot)
>      dev.off()
>      postscript(file=paste(filename, ".eps", sep=""))
>      eval(myplot)
>     dev.off()
>  }

I guess you would want eval(MYPLOT) there?

But the function above works if you say
  plot.both(myplot = expression(plot(x)), filename = "foo")
and that is what I said above: set myplot = expression(plot(x)).
Z

> However the result is the same: the first one is actually printed but
> the second plot is empty. 
> 
> Ronny
>



From rolf at math.unb.ca  Wed Mar  9 19:43:39 2005
From: rolf at math.unb.ca (Rolf Turner)
Date: Wed, 9 Mar 2005 14:43:39 -0400 (AST)
Subject: [R] Trouble with mixreg
Message-ID: <200503091843.j29Ihd2a001120@erdos.math.unb.ca>


Just read your email about mixreg.  The problem is the assignment

	y <- as.matrix(LRINTER)

The y argument has to be a ***vector***, not a matrix.  Deep in the
bowels of mixreg, yhat is formed as a matrix of fitted values for all
of the models in the mixture.  (The first column of yhat consists of
the fitted values from model 1, the second of the fitted values from
model 2, und so weiter.)

If y is a vector then y - yhat is the matrix whose columns are
y - (the respective columns of yhat).  This is standard R syntax.  If
y is a matrix, R won't touch the subtraction with a sterilized
barge-pole, and rightly so.

Remember that in R there is a big difference between a vector and
1-dimensional array, much as the two may seem to resemble each other.

				cheers,

					Rolf Turner
					rolf at math.unb.ca

P. S.  The usual protocol for asking questions about
***contributed*** packages is to attempt firstly to contact the
author of the package.  (In this case me.)  Only if the author is a
recalcitrant guttersnipe, and fails to respond, should you bug the
r-help list about the problem.

					R. T.

===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===

Massimiliano Marinucci wrote:

> I am trying to estimate a mixture of regression and get the
> following error using the mixreg package:
> 
> Error in y - yhat : non-conformable arrays
> 
> The instruction I used were:
> x <- as.matrix(LRHUN)
> y <- as.matrix(LRINTER)
> 
> TS  <- list(list(beta=c(3.0,1.0),sigsq=1,lambda=0.4),
>             list(beta=c(0.0,1.0),sigsq=1,lambda=0.6))
> 
> prova <- mixreg(x,y, ncomp=2, theta.start=TS)
> 
> The data set has about 1200 observations.
> I checked out that x and y have the same number of obs.
> Also examples work fine.
> 
> Any hints on what is going on? Thanks
> best regards
> M
> 
> **********************************************
> Massimiliano Marinucci
> http://personales.ya.com/max_mar/
> Ph.D Candidate in Economics
> Fundamentos del Analisis Econ?mico II
> (Econom?a Cuantitativa)
> Facultad de CC.EE.
> Universidad Complutense Madrid
> Campus de Somosaguas
> Madrid - Spain
> **********************************************



From Achim.Zeileis at wu-wien.ac.at  Wed Mar  9 19:46:43 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Wed, 9 Mar 2005 19:46:43 +0100
Subject: [R] about kpss.test()
In-Reply-To: <20050309183116.71326.qmail@web30003.mail.mud.yahoo.com>
References: <20050309183116.71326.qmail@web30003.mail.mud.yahoo.com>
Message-ID: <20050309194643.2c92cf6d.Achim.Zeileis@wu-wien.ac.at>

On Wed, 9 Mar 2005 13:31:16 -0500 (EST) Weiguang Shi wrote:

> Hi All,
> 
> First of all, could you tell me what the "KPSS Level" 
> in the output of the test means?

It means that you tested for level stationarity and gives you the test
statistic.

> I have a series, x, of periodic data and tried 
> kpss.test() on it to verify its stationarity. The

Note that stationarity is the null hypothesis and not the alternative of
the KPSS test.

> tests
> gave me the p-value above 0.1. Since the null 
> hypothesis N0 is that the series _is_ stationary, this
> means that I cannot reject N0. But the series does
> look
> periodic!
> 
> So does all this say stationarity and periodicity can 
> co-exist?

Please check the references of kpss.test or any book on economectric
time series analysis for which alternatives the KPSS test was designed.
Hint: it's not designed for detecting cyclical variations.
Z
 
> Thanks,
> Weiguang
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From jrclmilks at joimail.com  Wed Mar  9 20:17:03 2005
From: jrclmilks at joimail.com (Jim and Chana Milks)
Date: Wed, 9 Mar 2005 14:17:03 -0500
Subject: [R] Aid with 3-D scatterplots
Message-ID: <820a93e60855459800d565ab995091f4@joimail.com>

I am attempting to classify pixels from a Landsat image by using their 
associated numbers in bands 2, 3, and 4 (It's from an assignment on 
classification).  To aid me, I want to create a 3-D scatterplot using 
the "cloud" command.  Due to my ignorance of the finer plotting 
functions, I am unable to display the scale on the three axes or to 
display the grid.

My dataframe (RS) contains four columns: Class, band2, band3, band4.  
Class is the classification variable (vegetation, water, soil, etc.)

The basic code I used was:
cloud(band4~band2*band3,RS,xlab="TM Band 2",ylab="TM Band 3",zlab="TM 
Band 4",group=RS$Class).

Unfortunately, I'm unsure which arguments to use and how to write them 
in.  I've tried adding arguments using "scale", but have not been 
successful, mostly because I'm unsure which arguments apply.  The scale 
I want for all three axes is 0-100.

Thank you for any help.

Jim Milks



From MBock at arcadis-us.com  Wed Mar  9 20:19:26 2005
From: MBock at arcadis-us.com (Bock, Michael)
Date: Wed, 9 Mar 2005 12:19:26 -0700
Subject: [R] Lattice device page options-margins
Message-ID: <0016F5677B1F1D4281EEBC034993595102728A15@CORPEXBE1.arcadis-us.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050309/cb85ab2b/attachment.pl

From deepayan at stat.wisc.edu  Wed Mar  9 20:26:18 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 9 Mar 2005 13:26:18 -0600
Subject: [R] Aid with 3-D scatterplots
In-Reply-To: <820a93e60855459800d565ab995091f4@joimail.com>
References: <820a93e60855459800d565ab995091f4@joimail.com>
Message-ID: <200503091326.18175.deepayan@stat.wisc.edu>

On Wednesday 09 March 2005 13:17, Jim and Chana Milks wrote:
> I am attempting to classify pixels from a Landsat image by using their
> associated numbers in bands 2, 3, and 4 (It's from an assignment on
> classification).  To aid me, I want to create a 3-D scatterplot using
> the "cloud" command.  Due to my ignorance of the finer plotting
> functions, I am unable to display the scale on the three axes or to
> display the grid.
>
> My dataframe (RS) contains four columns: Class, band2, band3, band4.
> Class is the classification variable (vegetation, water, soil, etc.)
>
> The basic code I used was:
> cloud(band4~band2*band3,RS,xlab="TM Band 2",ylab="TM Band 3",zlab="TM
> Band 4",group=RS$Class).

Just 'groups = Class' should work.

>
> Unfortunately, I'm unsure which arguments to use and how to write them
> in.  I've tried adding arguments using "scale", but have not been
> successful, mostly because I'm unsure which arguments apply.  The scale
> I want for all three axes is 0-100.

You want 

cloud(..., xlim = c(0, 100), ylim = c(0, 100), zlim = c(0, 100))

and perhaps 
 
cloud(..., xlim = c(0, 100), ylim = c(0, 100), zlim = c(0, 100), 
      scales = list(arrows = FALSE))

-Deepayan



From OBUCHNER at DAL.CA  Wed Mar  9 20:24:45 2005
From: OBUCHNER at DAL.CA (Owen Buchner)
Date: Wed,  9 Mar 2005 15:24:45 -0400
Subject: [R] matrix program
Message-ID: <1110396285.422f4d7d708fa@my1.dal.ca>

I'm attempting to produce a program in which i can multiply a 4x4 matrix by a
vector.  I would like to have this occur 30 times with the product of the
matrix and vector replace the original vector, kind of like population growth.
I'm having difficulties with the programing aspect and continuously get errors
from R.  I would appreciate any help.

Owen Buchner

From sundar.dorai-raj at pdf.com  Wed Mar  9 20:31:08 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 09 Mar 2005 13:31:08 -0600
Subject: [R] Lattice device page options-margins
In-Reply-To: <0016F5677B1F1D4281EEBC034993595102728A15@CORPEXBE1.arcadis-us.com>
References: <0016F5677B1F1D4281EEBC034993595102728A15@CORPEXBE1.arcadis-us.com>
Message-ID: <422F4EFC.2050904@pdf.com>



Bock, Michael wrote on 3/9/2005 1:19 PM:
> I am using lattice to make figures as pdfs:
> trellis.device(device = "pdf",file = "Figure6.pdf",color = FALSE)
> 
> I need to specify some blank space on the left-hand margins (the pages
> will be bound so we need about 0.5 inch)). I have tried a number of
> solutions but none seems to work (e.g. par.set). Can this be done when
> initiating the plotting device? Or is the some other way that does not
> require me to manually move everything over?
> 
> 
> 
> 

Michael,

I believe you can do this using print.trellis and setting the position 
argument. E.g.

trellis.device(device = "pdf",file = "Figure6.pdf",color = FALSE)
xy <- xyplot(...)
print(xy, pos = c(0.10, 0, 1, 1))
dev.off()

--sundar



From wgshi2001 at yahoo.ca  Wed Mar  9 20:32:09 2005
From: wgshi2001 at yahoo.ca (Weiguang Shi)
Date: Wed, 9 Mar 2005 14:32:09 -0500 (EST)
Subject: [R] about kpss.test()
In-Reply-To: <20050309194643.2c92cf6d.Achim.Zeileis@wu-wien.ac.at>
Message-ID: <20050309193210.57536.qmail@web30008.mail.mud.yahoo.com>


 --- Achim Zeileis <Achim.Zeileis at wu-wien.ac.at>
wrote: 
> > First of all, could you tell me what the "KPSS
> Level" 
> > in the output of the test means?
Thanks. But I meant to also ask about the number after

that, e.g., 
    KPSS Level = 0.0027

> 
> Please check the references of kpss.test or any book
> on economectric
> time series analysis for which alternatives the KPSS
> test was designed.
Will soon do.

> Hint: it's not designed for detecting cyclical
> variations.
OK. I guess there must be some pre-requisite on the 
data before kpss-ing it.

Thanks
Weiguang



From ccleland at optonline.net  Wed Mar  9 20:39:35 2005
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 09 Mar 2005 14:39:35 -0500
Subject: [R] Lattice device page options-margins
In-Reply-To: <0016F5677B1F1D4281EEBC034993595102728A15@CORPEXBE1.arcadis-us.com>
References: <0016F5677B1F1D4281EEBC034993595102728A15@CORPEXBE1.arcadis-us.com>
Message-ID: <422F50F7.1070806@optonline.net>

You can add some space to the left by setting the left.padding component 
of the layout.widths trellis setting. For example:

library(lattice)
trellis.device(new=TRUE)
trellis.par.set(layout.widths = list(left.padding = 20))

require(stats)
## Tonga Trench Earthquakes
Depth <- equal.count(quakes$depth, number=8, overlap=.1)
xyplot(lat ~ long | Depth, data = quakes)

hope this helps,

Chuck Cleland

Bock, Michael wrote:
> I am using lattice to make figures as pdfs:
> trellis.device(device = "pdf",file = "Figure6.pdf",color = FALSE)
> 
> I need to specify some blank space on the left-hand margins (the pages
> will be bound so we need about 0.5 inch)). I have tried a number of
> solutions but none seems to work (e.g. par.set). Can this be done when
> initiating the plotting device? Or is the some other way that does not
> require me to manually move everything over?
> 
> 
> 
> 
> Michael J. Bock, PhD.
> ARCADIS
> 24 Preble St. Suite 100
> Portland, ME 04101
> 207.828.0046
> fax 207.828.0062
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From Achim.Zeileis at wu-wien.ac.at  Wed Mar  9 20:43:09 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Wed, 9 Mar 2005 20:43:09 +0100
Subject: [R] matrix program
In-Reply-To: <1110396285.422f4d7d708fa@my1.dal.ca>
References: <1110396285.422f4d7d708fa@my1.dal.ca>
Message-ID: <20050309204309.7facbd13.Achim.Zeileis@wu-wien.ac.at>

On Wed,  9 Mar 2005 15:24:45 -0400 Owen Buchner wrote:

> I'm attempting to produce a program in which i can multiply a 4x4
> matrix by a vector.  I would like to have this occur 30 times with the
> product of the matrix and vector replace the original vector, kind of
> like population growth. I'm having difficulties with the programing
> aspect and continuously get errors from R.  I would appreciate any
> help.

Are you looking for something like this toy example?

Generate a matrix mm and a vector xx:

R> mm <- matrix(rep(1, 4), ncol = 2)
R> xx <- rep(1, 2)
R> mm
     [,1] [,2]
[1,]    1    1
[2,]    1    1
R> xx
[1] 1 1

And then pre-multiply 10 times by mm:

R> for(i in 1:10) xx <- mm %*% xx
R> xx
     [,1]
[1,] 1024
[2,] 1024

which in this case is of course just 2^10.

hth,
Z


> Owen Buchner
>



From vograno at evafunds.com  Wed Mar  9 20:46:32 2005
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Wed, 9 Mar 2005 11:46:32 -0800
Subject: [R] how modify object in parent.env
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A58FF184@phost015.EVAFUNDS.intermedia.net>

Thank you to Gabor and Mark Schwartz for the answers. Both of them
solved the problem I posted, but my actual problem, as I now see, is a
little bit more involved. Let me try again.

I have a vector 'x'. I want to compute its entries in a loop (yes, I
know...). Say

x = seq(3)

for (i in seq(length(x)) {
	x0 = someValue
	x[i] = x0
} 

There are two problems with the above code:
1. x0 pollutes the global envirnoment (not to mention possible
over-write of an existing x0). Therefore I thought I'd wrap it with
local().
2. x0 is not a good name from a readability perspective. I'd rather call
it x to emphasize it's an entry in an outer vector 'x'. (In this small
example it doesn't really matter, but I have much more involved scripts
where consistent naming is important)

Gabor's solution solves 1 but not 2. Maybe there is a simple way around
this restriction?

Thanks,
Vadim



> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Gabor 
> Grothendieck
> Sent: Tuesday, March 08, 2005 4:06 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] how modify object in parent.env
> 
> 
> You can use "<<-" like this:
> 
> x <- 1:3
> local(x[1] <<- x[1]+1)
> 
> Vadim Ogranovich <vograno <at> evafunds.com> writes:
> 
> : 
> : Assign() re-binds the value, not modifies it (the latter is what I
> : needed)
> : 
> : > -----Original Message-----
> : > From: McGehee, Robert [mailto:Robert.McGehee <at> 
> geodecapital.com]
> : > Sent: Tuesday, March 08, 2005 3:48 PM
> : > To: Vadim Ogranovich; r-help <at> stat.math.ethz.ch
> : > Subject: RE: [R] how modify object in parent.env
> : >
> : > This isn't an environment problem. Assigning something to a
> : > get call doesn't make any sense. Use assign.
> : >
> : > > a <- 5
> : > > get("a") <- 10
> : > Error: couldn't find function "get<-"
> : >
> : > And from the ?assign help page, you can pick what environment
> : > you want to make the assignment. Just pick the parent environment.
> : >
> : >
> : > -----Original Message-----
> : > From: Vadim Ogranovich [mailto:vograno <at> evafunds.com]
> : > Sent: Tuesday, March 08, 2005 6:36 PM
> : > To: r-help <at> stat.math.ethz.ch
> : > Subject: [R] how modify object in parent.env
> : >
> : >
> : > Hi,
> : >
> : > Is it possible to modify an object in the parent.env (as 
> opposed to
> : > re-bind)? Here is what I tried:
> : >
> : > > x = 1:3
> : > # try to modify the first element of x from within a new 
> environment
> : > > local(get("x", parent.env(environment()))[1] <- NA)
> : > Error in eval(expr, envir, enclos) : Target of assignment 
> expands to
> : > non-language object
> : >
> : > # On the other hand retrieval works just fine
> : > > local(get("x", parent.env(environment()))[1])
> : > [1] 1
> : >
> : > Thanks,
> : > Vadim
> : >
> : > ______________________________________________
> : > R-help <at> stat.math.ethz.ch mailing list
> : > https://stat.ethz.ch/mailman/listinfo/r-help
> : > PLEASE do read the posting guide!
> : > http://www.R-project.org/posting-guide.html
> : >
> : 
> : ______________________________________________
> : R-help <at> stat.math.ethz.ch mailing list
> : https://stat.ethz.ch/mailman/listinfo/r-help
> : PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> : 
> :
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From choudary.jagar at swosu.edu  Wed Mar  9 20:49:44 2005
From: choudary.jagar at swosu.edu (Jagarlamudi, Choudary)
Date: Wed, 9 Mar 2005 13:49:44 -0600
Subject: [R] How to get standard deviation of rows in a matrix
Message-ID: <E03EBB50FF2C024781A6E4460AD58F0607C1A6@swosu-mbx01.admin.swosu.edu>

Hi all,
 
   I am trying to find sd of my rows in a matrix and i get column sd inspite of extracting rows.
I tried to do the sqrt(var(x)) but that did'nt work as well,
 
Here is my data
 
genes
15 24 63 40
25 42 46 35
23 53 37 45
30 37 50 55
40 51 30 48
 
x<-sd(genes[1:5,])
 
y<-sqrt(var(genes[1:5,]))
 
I get 4 sds for the 4 columns instead of 5 sds for my 5 rows.
Thanks you in advance.
 
Choudary Jagarlamudi
Instructor
Southwestern Oklahoma State University
STF 254
100 campus Drive
Weatherford OK 73096
Tel 580-774-7136

________________________________


From p.murrell at auckland.ac.nz  Wed Mar  9 20:54:50 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Thu, 10 Mar 2005 08:54:50 +1300
Subject: [R] Lattice device page options-margins
References: <0016F5677B1F1D4281EEBC034993595102728A15@CORPEXBE1.arcadis-us.com>
	<422F4EFC.2050904@pdf.com>
Message-ID: <422F548A.7010505@stat.auckland.ac.nz>

Hi


Sundar Dorai-Raj wrote:
> 
> 
> Bock, Michael wrote on 3/9/2005 1:19 PM:
> 
>> I am using lattice to make figures as pdfs:
>> trellis.device(device = "pdf",file = "Figure6.pdf",color = FALSE)
>>
>> I need to specify some blank space on the left-hand margins (the pages
>> will be bound so we need about 0.5 inch)). I have tried a number of
>> solutions but none seems to work (e.g. par.set). Can this be done when
>> initiating the plotting device? Or is the some other way that does not
>> require me to manually move everything over?
>>
>>
>>
>>
> 
> Michael,
> 
> I believe you can do this using print.trellis and setting the position 
> argument. E.g.
> 
> trellis.device(device = "pdf",file = "Figure6.pdf",color = FALSE)
> xy <- xyplot(...)
> print(xy, pos = c(0.10, 0, 1, 1))
> dev.off()


Or if you want exactly 0.5 inches, something like ...

# may need
# library(grid)
trellis.device(device = "pdf",file = "Figure6.pdf",color = FALSE)
xy <- xyplot(1:10 ~ 1:10)
pushViewport(viewport(x=1,
                       width=unit(1, "npc") - unit(0.5, "inches"),
                       just="right"))
# to show region you're plotting in
# grid.rect(gp=gpar(col="grey"))
print(xy, newpage=FALSE)
popViewport()
dev.off()

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From sundar.dorai-raj at pdf.com  Wed Mar  9 21:00:40 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 09 Mar 2005 14:00:40 -0600
Subject: [R] How to get standard deviation of rows in a matrix
In-Reply-To: <E03EBB50FF2C024781A6E4460AD58F0607C1A6@swosu-mbx01.admin.swosu.edu>
References: <E03EBB50FF2C024781A6E4460AD58F0607C1A6@swosu-mbx01.admin.swosu.edu>
Message-ID: <422F55E8.40102@pdf.com>



Jagarlamudi, Choudary wrote on 3/9/2005 1:49 PM:
> Hi all,
>  
>    I am trying to find sd of my rows in a matrix and i get column sd inspite of extracting rows.
> I tried to do the sqrt(var(x)) but that did'nt work as well,
>  
> Here is my data
>  
> genes
> 15 24 63 40
> 25 42 46 35
> 23 53 37 45
> 30 37 50 55
> 40 51 30 48
>  
> x<-sd(genes[1:5,])
>  
> y<-sqrt(var(genes[1:5,]))
>  
> I get 4 sds for the 4 columns instead of 5 sds for my 5 rows.
> Thanks you in advance.
>  

This has come up several times in the past and a quick search of the 
archives would have lead you to:

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/34169.html

HTH,
--sundar



From lorin at cs.umd.edu  Wed Mar  9 21:07:20 2005
From: lorin at cs.umd.edu (Lorin Hochstein)
Date: Wed, 09 Mar 2005 15:07:20 -0500
Subject: [R] Flattening a list of data frames
Message-ID: <422F5778.50509@cs.umd.edu>

Hello all,

Simple version of my problem:

I've got a list of data frames, where each data frame has the same 
number of columns and the same column names. I'd like to flatten the 
list into one large data frame. Is there an easy way to do this?

Quick example code:
a <- data.frame(x=c(1,2,3),y=c(5,7,9)
b <- data.frame(x=c(2,4,7,9),y=c(2,3,5,4))
z <- list(a,b)

# Do "something" to get the equivalent of  rbind(z[[1]],z[[2]])
???

More complex version:

My data is in this format because it's the output of a "by" statment 
that looks like this:

y <- by(d,list(d$StudentID,d$Assignment),gapfun)

(where gapfun is a function I've defined that takes a data frame and 
returns another data frame).

What I would like is to do is transform y into a data frame that has 
columns "StudentID", "Assignment", and the columns in the data frame 
returned by gapfun.

Any ideas?

Lorin

----------
Lorin Hochstein
Graduate Research Assistant
Experimental Software Engineering Group
Computer Science Department
University of Maryland, College Park



From knoblauch at lyon.inserm.fr  Wed Mar  9 20:19:30 2005
From: knoblauch at lyon.inserm.fr (Ken Knoblauch)
Date: Wed,  9 Mar 2005 20:19:30 +0100
Subject: [R] problem using uniroot with integrate
Message-ID: <1110395970.422f4c42cc56a@webmail.lyon.inserm.fr>

Thank you very much.  Yes, that was the problem, partial matching.  
I saw a warning about that in integrate and some discussion from 1999
in the archives and so added the m0 for integrate but somehow
I wasn't bright enough to see that I had the same problem
in uniroot.  

Sorry about no working example, but I'm not sure what I could
have added, if I understand what you mean by working example,
because my function wasn't working.

best,

ken


Quoting Sundar Dorai-Raj <sundar.dorai-raj at pdf.com>:

> 
> 
> Ken Knoblauch wrote on 3/9/2005 10:27 AM:
> > Hi, 
> > 
> > I'm trying to calculate the value of the variable, dp, below, in the
> > argument to the integral of dnorm(x-dp) * pnorm(x)^(m-1).  This
> > corresponds to the estimate of the sensitivity of an observer in an
> > m-alternative forced choice experiment, given the probability of
> > a correct response, Pc, a Gaussian assumption for the noise and
> > no bias.  The function that I wrote below gives me an error:
> > 
> > Error in f(x, ...) : recursive default argument reference
> > 
> > The problem seems to be at the statement using uniroot,
> > because the furntion est.dp works fine outside of the main function.
> > I've been using R for awhile but there are still many nuances
> > about the scoping and the use of environments that I'm weak on
> > and would like to understand better.  I would appreciate any
> > suggestions or solutions that anyone might offer for fixing
> > my error.  Thank you.
> > 
> > dprime.mAFC <- function(Pc, m) {
> > 		est.dp <- function(dp, Pc = Pc, m = m) {
> > 		
> > 		  pr <- function(x, dpt = dp, m0 = m) {
> > 		    	dnorm(x - dpt) * pnorm(x)^(m0 - 1)
> > 			    }
> > 		
> > 		  Pc - integrate(pr, lower = -Inf, upper = Inf, 
> > 		  dpt = dp, m0 = m)$value
> > 		}
> > 		
> > 	dp.res <- uniroot(est.dp, interval = c(0,5), Pc = Pc, m = m)
> > 	dp.res$root	
> > 	}
> > 
> 
> Ken,
> 
> Look at the argument list for ?uniroot and think "partial matching". 
> You're "m" is being interpretted for "maxiter". Simply change to
> 
> dp.res <- uniroot(est.dp, interval = c(0,5), Pc = Pc, m0 = m)
> 
> and in other places for consistency and the error goes away. Of course, 
> since you gave no working example, I'm not sure if other errors are 
> present that I'm missing.
> 
> --sundar
> 



____________________
Ken Knoblauch
Inserm U 371
Cerveau et Vision
18 avenue du Doyen Lepine
69675 Bron cedex
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: 06 84 10 64 10



From tobias.verbeke at telenet.be  Wed Mar  9 21:20:42 2005
From: tobias.verbeke at telenet.be (Tobias Verbeke)
Date: Wed, 9 Mar 2005 21:20:42 +0100
Subject: [R] How to get standard deviation of rows in a matrix
In-Reply-To: <E03EBB50FF2C024781A6E4460AD58F0607C1A6@swosu-mbx01.admin.swosu.edu>
References: <E03EBB50FF2C024781A6E4460AD58F0607C1A6@swosu-mbx01.admin.swosu.edu>
Message-ID: <20050309212042.135d1770.tobias.verbeke@telenet.be>

On Wed, 9 Mar 2005 13:49:44 -0600
"Jagarlamudi, Choudary" <choudary.jagar at swosu.edu> wrote:

> Hi all,
>  
>    I am trying to find sd of my rows in a matrix and i get column sd inspite of extracting rows.
> I tried to do the sqrt(var(x)) but that did'nt work as well,
>  
> Here is my data
>  
> genes
> 15 24 63 40
> 25 42 46 35
> 23 53 37 45
> 30 37 50 55
> 40 51 30 48
>  
> x<-sd(genes[1:5,])
>  
> y<-sqrt(var(genes[1:5,]))
>  
> I get 4 sds for the 4 columns instead of 5 sds for my 5 rows.
> Thanks you in advance.

> mymat <- matrix(rnorm(20), 5)
> mymat
           [,1]       [,2]       [,3]       [,4]
[1,] -0.1418666 -0.6754704 -0.2525154 -1.4832003
[2,] -0.2254920  1.8705093 -0.9678318 -0.1108883
[3,]  2.2501392  0.1687349 -0.1279790  0.7055311
[4,]  0.9893453 -0.5924199  0.2410576  0.9001638
[5,] -0.4179559  0.9334556 -0.6501605  0.6148958
> apply(mymat, 1, sd)
[1] 0.6084171 1.2135998 1.0584750 0.7318231 0.7722641

See ?apply

HTH,
Tobias



From andy_liaw at merck.com  Wed Mar  9 21:30:53 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 9 Mar 2005 15:30:53 -0500
Subject: [R] How to get standard deviation of rows in a matrix
Message-ID: <3A822319EB35174CA3714066D590DCD50994E819@usrymx25.merck.com>

You should read ?var and ?sd more carefully.  For a data frame or a matrix,
var() returns the covariance matrix of the columns, whereas sd() returns the
standard deviations of the columns.  If you want standard deviations of the
rows, you need to transpose the data.

Andy

> From: Jagarlamudi, Choudary
> 
> Hi all,
>  
>    I am trying to find sd of my rows in a matrix and i get 
> column sd inspite of extracting rows.
> I tried to do the sqrt(var(x)) but that did'nt work as well,
>  
> Here is my data
>  
> genes
> 15 24 63 40
> 25 42 46 35
> 23 53 37 45
> 30 37 50 55
> 40 51 30 48
>  
> x<-sd(genes[1:5,])
>  
> y<-sqrt(var(genes[1:5,]))
>  
> I get 4 sds for the 4 columns instead of 5 sds for my 5 rows.
> Thanks you in advance.
>  
> Choudary Jagarlamudi
> Instructor
> Southwestern Oklahoma State University
> STF 254
> 100 campus Drive
> Weatherford OK 73096
> Tel 580-774-7136
> 
> ________________________________
> 
>



From deepayan at stat.wisc.edu  Wed Mar  9 23:09:22 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 9 Mar 2005 16:09:22 -0600
Subject: [R] Lattice device page options-margins
In-Reply-To: <422F548A.7010505@stat.auckland.ac.nz>
References: <0016F5677B1F1D4281EEBC034993595102728A15@CORPEXBE1.arcadis-us.com>
	<422F4EFC.2050904@pdf.com> <422F548A.7010505@stat.auckland.ac.nz>
Message-ID: <200503091609.22922.deepayan@stat.wisc.edu>

On Wednesday 09 March 2005 13:54, Paul Murrell wrote:
> Hi
>
> Sundar Dorai-Raj wrote:
> > Bock, Michael wrote on 3/9/2005 1:19 PM:
> >> I am using lattice to make figures as pdfs:
> >> trellis.device(device = "pdf",file = "Figure6.pdf",color = FALSE)
> >>
> >> I need to specify some blank space on the left-hand margins (the
> >> pages will be bound so we need about 0.5 inch)). I have tried a
> >> number of solutions but none seems to work (e.g. par.set). Can
> >> this be done when initiating the plotting device? Or is the some
> >> other way that does not require me to manually move everything
> >> over?
> >
> > Michael,
> >
> > I believe you can do this using print.trellis and setting the
> > position argument. E.g.
> >
> > trellis.device(device = "pdf",file = "Figure6.pdf",color = FALSE)
> > xy <- xyplot(...)
> > print(xy, pos = c(0.10, 0, 1, 1))
> > dev.off()
>
> Or if you want exactly 0.5 inches, something like ...
>
> # may need
> # library(grid)
> trellis.device(device = "pdf",file = "Figure6.pdf",color = FALSE)
> xy <- xyplot(1:10 ~ 1:10)
> pushViewport(viewport(x=1,
>                        width=unit(1, "npc") - unit(0.5, "inches"),
>                        just="right"))
> # to show region you're plotting in
> # grid.rect(gp=gpar(col="grey"))
> print(xy, newpage=FALSE)
> popViewport()
> dev.off()

Yet another option, especially if you want this for multiple plots 
without having to handle each one separately, is to say (after loading 
lattice):

lattice.options(layout.widths = list(left.padding = 
                list(x = 0.5, units = "inches")))

Unlike par settings though, this would stay in effect across devices.

Deepayan



From idimakos at upatras.gr  Wed Mar  9 23:10:48 2005
From: idimakos at upatras.gr (Dimakos Ioannis)
Date: Thu, 10 Mar 2005 00:10:48 +0200 (EET)
Subject: [R] R-2.0.1 Gentoo g77 problem
In-Reply-To: <Pine.LNX.4.62.0503091007180.28376@tajo.ucsd.edu>
References: <20050309080950.E77871027BE@ws3.hk5.outblaze.com>
	<Pine.LNX.4.62.0503091007180.28376@tajo.ucsd.edu>
Message-ID: <3125.150.140.128.236.1110406248.squirrel@150.140.128.236>

> On Wed, 9 Mar 2005, Gabriel Rossetti wrote:
>
>> Hello,
>>
>> I use Gentoo and I can't get R 2.0.1 to compile. I used the portage
>> system, Gentoo's source package sytem, and after it uncompresses the
>> source to R, it says that I don't have a fortran compiler. It told me to
>> use f77 flag and re-emerge gcc, which I did with the f77 and fortran
>> flags, but it still won't compile. Does anyone have any ideas? I suspect
>> that gcc has changed it's interworkings, because if I do a gcc -v it
>> says that I can compile fortran(f77) programs, but I don't have g77. If
>> anyone has any ideas or workarounds, it would be great. I really need it
>> for a P&S class. Thanks!
>
>
> After experiencing similar problems and noticing that g77 was nowhere to
> be found, I symlinked /usr/bin/g77 --> /usr/bin/gcc.
>
> R then built and passed 'make check'.

As I pointed out in a private message to the original poster, g77 is not
found in the gentoo system.  However, the system does provide f2c which
will translate fortran to C code and then R-2.0.1 passes configure, and
make and make check and make install and everything

HTH,

ICD

-- 
Ioannis C. Dimakos
University of Patras
Department of Elementary Education
Patras, GR-26500 GREECE
http://www.elemedu.upatras.gr/dimakos/
http://yannishome.port5.com/

-- 
Ioannis C. Dimakos
University of Patras
Department of Elementary Education
Patras, GR-26500 GREECE
http://www.elemedu.upatras.gr/dimakos/
http://yannishome.port5.com/



From Sholte at fhcrc.org  Wed Mar  9 21:45:13 2005
From: Sholte at fhcrc.org (Sarah Holte)
Date: Wed, 09 Mar 2005 12:45:13 -0800
Subject: [R] need help getting started writing a new varFunc class for lme()
Message-ID: <422F6059.9020308@fhcrc.org>

Hello - I've been using R for years, but have always been able to find 
what I need already available.  Now I find that I would like to write a 
new varFunc class for the lme() or nlme() packages.  There is some 
guidance for this in Problem 4 Chapter 5 of Bates and Pinheiro Mixed 
Effects Models in S and S-Plus.  However, I find that I am unable to 
even get started and so have just purchased John Chambers Book - 
Programming with Data, A Guide to the S Language.

Any specific tips about how to write a new varFunc class (I want one 
that models the variance of longitudinal correlated data as a logistic 
function of a covariate) or general tips or references to sections in 
Chambers book about the steps mentioned in Problem 4, Chapter 5 of Bates 
and Pinheiro (eg. write a constructor, constructor arguements (value and 
form), write an initialize method, etc) would be much appreciated.   I 
did find a few threads in the archives discussing this problem, but they 
were already way beyond my understanding of how to execute writing this 
new new varFunc class.

Thanks so much - Sarah Holte



From murdoch at stats.uwo.ca  Wed Mar  9 21:46:13 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 09 Mar 2005 20:46:13 +0000
Subject: [R] How to get standard deviation of rows in a matrix
In-Reply-To: <E03EBB50FF2C024781A6E4460AD58F0607C1A6@swosu-mbx01.admin.swosu.edu>
References: <E03EBB50FF2C024781A6E4460AD58F0607C1A6@swosu-mbx01.admin.swosu.edu>
Message-ID: <m0ou21l2607vdaq8n704e8n9ovqukqsk31@4ax.com>

On Wed, 9 Mar 2005 13:49:44 -0600, "Jagarlamudi, Choudary"
<choudary.jagar at swosu.edu> wrote :

>Hi all,
> 
>   I am trying to find sd of my rows in a matrix and i get column sd inspite of extracting rows.
>I tried to do the sqrt(var(x)) but that did'nt work as well,
> 
>Here is my data
> 
>genes
>15 24 63 40
>25 42 46 35
>23 53 37 45
>30 37 50 55
>40 51 30 48
> 
>x<-sd(genes[1:5,])

This doesn't extract the rows, it just returns the same matrix.  As
the man page for sd says, when applied to a matrix it calculates the
standard deviation of each column.

What you want to do is to use the apply function.  Rows are the first
dimension, so you would use

apply(genes, 1, sd)

Duncan Murdoch



From upasna at iitb.ac.in  Wed Mar  9 22:02:08 2005
From: upasna at iitb.ac.in (Upasna Sharma)
Date: Thu, 10 Mar 2005 02:32:08 +0530 (IST)
Subject: [R] Dropping coloumns while redaing dtaa from text file.
Message-ID: <1408.10.11.11.2.1110402128.squirrel@gpo.iitb.ac.in>

Hi

I have a huge text file and .dat file from which I want to read data. I do
not need all the columns in the files. I want to extract only some columns
from the .txt file or the .dat file, because reading the entire file is
becoming very difficult due to memory issues. Is it possible to extract a
few columns from .txt or .dat file while reading the data in R?

Thanks
Upasna


-- 
"The past is a history, the future is a mystery, and this moment is a
gift. That is why this moment is called 'the present'." Anonymous



From cberry at tajo.ucsd.edu  Thu Mar 10 00:08:04 2005
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Wed, 9 Mar 2005 15:08:04 -0800
Subject: [R] R-2.0.1 Gentoo g77 problem
In-Reply-To: <3125.150.140.128.236.1110406248.squirrel@150.140.128.236>
References: <20050309080950.E77871027BE@ws3.hk5.outblaze.com>   
	<Pine.LNX.4.62.0503091007180.28376@tajo.ucsd.edu>
	<3125.150.140.128.236.1110406248.squirrel@150.140.128.236>
Message-ID: <Pine.LNX.4.62.0503091436200.28376@tajo.ucsd.edu>


Dimakos said:

> As I pointed out in a private message to the original poster, g77 is not
> found in the gentoo system.  However, the system does provide f2c which
  [ Dimakos' full text below]


It IS found on my gentoo system:

bash-2.05b$ g77 -fversion
GNU Fortran (GCC) 3.3.5  (Gentoo Linux 3.3.5-r1, ssp-3.3.2-3, pie-8.7.7.1)
Copyright (C) 2002 Free Software Foundation, Inc.
[snip]

This is where portage puts it:

------------------------

bash-2.05b$ locate g77

[stuff deleted]

/usr/share/gcc-data/sparc-unknown-linux-gnu/3.3.5/man/man1/g77.1.gz
/usr/sparc-unknown-linux-gnu/gcc-bin/3.3.5/g77
/usr/sparc-unknown-linux-gnu/gcc-bin/3.3.5/sparc-unknown-linux-gnu-g77

[more stuff deleted]

bash-2.05b$ locate f771
/usr/lib/gcc-lib/sparc-unknown-linux-gnu/3.3.5/f771

------------------------

As someone else noted you have to set the USE flags to 
include 'f77' or 'g77' and emerge gcc.

But setting USE = f77 did not leave a link or copy of g77 in /usr/bin. 
Hence, the symlink referred to in my message below.

Apparently, Gabriel and I are not the only ones to come up against this. 
There are a number of discussions like this one:

 	http://forums.gentoo.org/viewtopic.php?t=266985

where the solution was to copy or symlink /usr/bin/gcc to /usr/bin/g77.

Chuck

On Thu, 10 Mar 2005, Dimakos Ioannis wrote:

>> On Wed, 9 Mar 2005, Gabriel Rossetti wrote:
>>
>>> Hello,
>>>
>>> I use Gentoo and I can't get R 2.0.1 to compile. I used the portage
>>> system, Gentoo's source package sytem, and after it uncompresses the
>>> source to R, it says that I don't have a fortran compiler. It told me to
>>> use f77 flag and re-emerge gcc, which I did with the f77 and fortran
>>> flags, but it still won't compile. Does anyone have any ideas? I suspect
>>> that gcc has changed it's interworkings, because if I do a gcc -v it
>>> says that I can compile fortran(f77) programs, but I don't have g77. If
>>> anyone has any ideas or workarounds, it would be great. I really need it
>>> for a P&S class. Thanks!
>>
>>
>> After experiencing similar problems and noticing that g77 was nowhere to
>> be found, I symlinked /usr/bin/g77 --> /usr/bin/gcc.
>>
>> R then built and passed 'make check'.
>
> As I pointed out in a private message to the original poster, g77 is not
> found in the gentoo system.  However, the system does provide f2c which
> will translate fortran to C code and then R-2.0.1 passes configure, and
> make and make check and make install and everything
>
> HTH,
>
> ICD
>
> -- 
> Ioannis C. Dimakos
> University of Patras
> Department of Elementary Education
> Patras, GR-26500 GREECE
> http://www.elemedu.upatras.gr/dimakos/
> http://yannishome.port5.com/
>
> -- 
> Ioannis C. Dimakos
> University of Patras
> Department of Elementary Education
> Patras, GR-26500 GREECE
> http://www.elemedu.upatras.gr/dimakos/
> http://yannishome.port5.com/
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://hacuna.ucsd.edu/members/ccb.html  La Jolla, San Diego 92093-0717



From zh107 at york.ac.uk  Thu Mar 10 00:25:19 2005
From: zh107 at york.ac.uk (Zhesi He)
Date: Wed, 9 Mar 2005 23:25:19 +0000
Subject: [R] RSPYTHON install failed on Mac
In-Reply-To: <Pine.LNX.4.61.0503091259240.14376@gannet.stats>
References: <000201c52493$e79f0cc0$afe8d182@o1jh>
	<16942.55976.691306.282856@galadriel.ci.tuwien.ac.at>
	<5fe990df0de5700918a262fd81e3ff6e@york.ac.uk>
	<Pine.LNX.4.61.0503091259240.14376@gannet.stats>
Message-ID: <dff4d6e6099198a90095644bb9262457@york.ac.uk>

Dear Prof Brian Ripley,

I downloaded RSPython install tar file from other sites and get the 
same results.
After extract the file and configuer, I still get the same error.
Here I attached the config.log file. And there's not much information I 
can get from basic config info. Please advise on this.

Thanks,
Zhesi.

-------------- next part --------------



On 9 Mar 2005, at 13:02, Prof Brian Ripley wrote:

> Without seeing config.log, we have no more idea than you do.
>
> This is an Omegahat package, and either its list or the R-sig-mac list 
> would be far more appropriate than this one.  But I suspect the answer 
> is clear from config.log -- unpack the package before installing to 
> see it.
>
> On Wed, 9 Mar 2005, Zhesi He wrote:
>
>> Dear all,
>>
>> I was trying to install RSPYTHON on my Mac OS X 10.3 into R, and got 
>> the following errors, is it because of my C compiler or the python I 
>> installed?
>>
>>
>> R CMD INSTALL -c Desktop/RSPython_0.5-4.tar.gz
>> * Installing *source* package 'RSPython' ...
>> checking for python... /usr/bin/python
>> Python version 2.3
>> Using threads
>> checking for gcc... gcc
>> checking for C compiler default output... configure: error: C 
>> compiler cannot create executables
>> See `config.log' for more details.
>> ERROR: configuration failed for package 'RSPython'
>> ** Removing 
>> '/Applications/StartR.app/RAqua.app/Contents/library/RSPython'
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From xt_wang at cse.concordia.ca  Thu Mar 10 00:54:36 2005
From: xt_wang at cse.concordia.ca (xt_wang@cse.concordia.ca)
Date: Wed,  9 Mar 2005 18:54:36 -0500
Subject: [R] How to use a R package with C code
Message-ID: <1110412476.422f8cbc6ad05@mail.encs.concordia.ca>


Hello, everybody,

I created a R package which includes C code. But I load this package, and carry
out the R function in it. It shows C function is not in load table as follows.
Would you tell me what is the problem? Where do I make mistake?

Maggie



[Previously saved workspace restored]

> library(var)

Attaching package 'var':


        The following object(s) are masked _by_ .GlobalEnv :

         b

> wxt0124()
Error in .C("wxt1221") : C function name not in load table



From DarrenLeeWeber at gmail.com  Thu Mar 10 01:03:42 2005
From: DarrenLeeWeber at gmail.com (Darren Weber)
Date: Wed, 09 Mar 2005 16:03:42 -0800
Subject: [R] contrast matrix for aov
Message-ID: <422F8EDE.2030009@gmail.com>


How do we specify a contrast interaction matrix for an ANOVA model?

We have a two-factor, repeated measures design, with

Cue Direction (2) x  Brain Hemisphere(2)

Each of these has 2 levels, 'left' and 'right', so it's a simple 2x2 design 
matrix.  We have 8 subjects in each cell (a balanced design) and we want to 
specify the interaction contrast so that:

CueLeft>CueRght for the Right Hemisphere
CueRght>CueLeft for the Left Hemisphere.

Here is a copy of the relevant commands for R:

########################################
lh_cueL <- rowMeans( LHroi.cueL[,t1:t2] )
lh_cueR <- rowMeans( LHroi.cueR[,t1:t2] )
rh_cueL <- rowMeans( RHroi.cueL[,t1:t2] )
rh_cueR <- rowMeans( RHroi.cueR[,t1:t2] )
roiValues <- c( lh_cueL, lh_cueR, rh_cueL, rh_cueR )

cuelabels <- c("CueLeft", "CueRight")
hemlabels <- c("LH", "RH")

roiDataframe <- data.frame( roi=roiValues, Subject=gl(8,1,32,subjectlabels), 
Hemisphere=gl(2,16,32,hemlabels), Cue=gl(2,8,32,cuelabels) )

roi.aov <- aov(roi ~ (Cue*Hemisphere) + Error(Subject/(Cue*Hemisphere)), 
data=roiDataframe)
print(summary(roi.aov))
########################################


I've tried to create a contrast matrix like this:

cm <- contrasts(roiDataframe$Cue)

which gives the main effect contrasts for the Cue factor.  I really want to 
specify the interaction contrasts, so I tried this:

########################################
# c( lh_cueL, lh_cueR, rh_cueL, rh_cueR )
# CueRight>CueLeft for the Left Hemisphere.
# CueLeft>CueRight for the Right Hemisphere

cm <- c(-1, 1, 1, -1)
dim(cm) <- c(2,2)

roi.aov <- aov( roi ~ (Cue*Hemisphere) + Error(Subject/(Cue*Hemisphere)),
contrasts=cm, data=roiDataframe)
print(summary(roi.aov))
########################################

but the results of these two aov commands are identical.  Is it the case that 
the 2x2 design matrix is always going to give the same F values for the 
interaction regardless of the contrast direction?  OR, is there some way to get 
a summary output for the contrasts that is not available from the print method?



From eric.y.hu at gmail.com  Thu Mar 10 01:17:13 2005
From: eric.y.hu at gmail.com (Eric Hu)
Date: Wed, 9 Mar 2005 16:17:13 -0800
Subject: [R] install R redhat rpm as a normal user
Message-ID: <a6f83c5a05030916176e99a8e4@mail.gmail.com>

Hi, I wonder if anyone has done this before. I have rpm-build
installed in my workstation. Thanks.

Eric



From aamacher at nature.berkeley.edu  Thu Mar 10 01:19:22 2005
From: aamacher at nature.berkeley.edu (Andrew James Amacher)
Date: Wed, 9 Mar 2005 16:19:22 -0800 (PST)
Subject: [R] Help with lme Random Factor
Message-ID: <2809.128.32.179.208.1110413962.squirrel@nature.berkeley.edu>

Hi,

I need help creating a code for a multiple BACI design (Before-After
Control-Impact) ANOVA.  I'm new to R and basically need to run a complex
mixed model ANOVA that treats location as a random factor.

Data are from a fire experiment, run 2001-2004 (2 years pre, 2 years
post).  Response is bird abundance.  4 Treatments had 3 replicates each
(forest stands): 1. Control, 2. Prescribed fire only, 3. Timber harvesting
only, and 4. Fire and harvesting.

Basically, I'm having trouble figuring out the code that makes the
variable "LOC" a random factor.

Also, I'm having trouble figuring out how to script contrasts comparing
the treatments to the control (multiple comparisons w/ a control). 
Treatment group is not a part of the lme script.  Do I need to run them
each individually, i.e. C vs. T1, C vs. T2, C vs T3? or can I code in
treatment contrasts?

Script (used S-plus GUI to build it):

GCKI~.+C+B+LOC%in%C+T%in%B+C:B+C:T%in%B+LOC%in%C:B+LOC%in%C:T%in%B
**unsure what goes here to make LOC random****

Terms:

GCKI: Golden-crowned kinglet abundance.

C:  Control-Impact (2 levels, either control (no treatment), or impact
(received treatment after 2 years)

B: Before-After (2 levels, 2001-2002 = Before, 2003-2004 = After)

T: Time, 4 levels, years 2001, 2002, 2003, 2004

LOC: location, 3 replicates in among the 4 treatments (RANDOM FACTOR)


Sorry to write so much, but any help would be appreciated.  The ANOVA
model comes from a book: Monitoring Ecological Impacts: Downes et al.
2002.

I am used to running GUIs, but it appears I need to script this ANOVA.  I
am unfamiliar with random factor scripts or scripts for multiple contrasts
with controls.

Cheers,

Andrew



From murdoch at stats.uwo.ca  Thu Mar 10 01:28:41 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 10 Mar 2005 00:28:41 +0000
Subject: [R] How to use a R package with C code
In-Reply-To: <1110412476.422f8cbc6ad05@mail.encs.concordia.ca>
References: <1110412476.422f8cbc6ad05@mail.encs.concordia.ca>
Message-ID: <hs4v21t88vshu22gm9etq9reh8rdkkrqii@4ax.com>

On Wed,  9 Mar 2005 18:54:36 -0500, xt_wang at cse.concordia.ca wrote :

>
>Hello, everybody,
>
>I created a R package which includes C code. But I load this package, and carry
>out the R function in it. It shows C function is not in load table as follows.
>Would you tell me what is the problem? Where do I make mistake?

You aren't giving enough information for anyone to know that.  You
need to tell us exactly what you did to create your package, and what
operating system you're on.

Duncan Murdoch
>
>Maggie
>
>
>
>[Previously saved workspace restored]
>
>> library(var)
>
>Attaching package 'var':
>
>
>        The following object(s) are masked _by_ .GlobalEnv :
>
>         b
>
>> wxt0124()
>Error in .C("wxt1221") : C function name not in load table
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From slist at oomvanlieshout.net  Thu Mar 10 08:03:49 2005
From: slist at oomvanlieshout.net (Sander Oom)
Date: Thu, 10 Mar 2005 09:03:49 +0200
Subject: [R] from long/lat to UTM
In-Reply-To: <20050309052012.24953.qmail@web53110.mail.yahoo.com>
References: <20050309052012.24953.qmail@web53110.mail.yahoo.com>
Message-ID: <422FF155.5030506@oomvanlieshout.net>

Hi Yyan,

The proj4R package by Roger Bivand will allow you to project data in 
many ways and directions.

http://spatial.nhh.no/R/Devel/proj4R-pkg.pdf

It uses the proj libraries from:

http://www.remotesensing.org/proj/

Not sure where you would derive the time zone!

Good luck,

Sander.

yyan liu wrote:
> Hi:
>   Is there any function in R which can convert the
> long/lat to UTM(Universal Transverse Mercator)?
>   There are quite a few converters on Internet.
> However, the interface is designed as input->output
> which I can not convert lots of locations at the same
> time.
>   Another question is whether there is a function in R
> which can tell the time zone from the location's
> lat/long?
>   Thank you!
> 
> liu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
--------------------------------------------
Dr. Sander P. Oom
Animal, Plant and Environmental Sciences,
University of the Witwatersrand
Private Bag 3, Wits 2050, South Africa
Tel (work)      +27 (0)11 717 64 04
Tel (home)      +27 (0)18 297 44 51
Fax             +27 (0)18 299 24 64
Email   sander at oomvanlieshout.net
Web     www.oomvanlieshout.net/sander



From lavanya_ldb2000 at yahoo.co.in  Thu Mar 10 08:25:37 2005
From: lavanya_ldb2000 at yahoo.co.in (Lakshmi Dhevi Baskar)
Date: Wed, 9 Mar 2005 23:25:37 -0800 (PST)
Subject: [R] Help :plotting 3d  images
Message-ID: <20050310072537.41883.qmail@web8502.mail.in.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050309/0ff14f8b/attachment.pl

From hjort at isds.duke.edu  Thu Mar 10 06:22:25 2005
From: hjort at isds.duke.edu (Nils-at-Duke Lid Hjort)
Date: Thu, 10 Mar 2005 00:22:25 -0500
Subject: [R] two-dimensional integration?
Message-ID: <422FD991.70304@isds.duke.edu>

I find the one-dimensional "integrate" very helpful,
but often enough I stumble into problems that require
two (or more)-dimensional integrals. I suppose there
are no R functions that can do this for me, "directly"?

The ideal thing would be to be able to define say
f <- function(x)
{
x1 <- x[1]
x2 <- x[2]
sin(x1*x2)*exp(x1-x2)
}
and then write say
integrate(f, xlim=c(0,1), ylim=c(0,1))  .

(a) No such thing exists, as of today, right?
(b) There *are* general numerical routines "out there"
for doing such things, right? (Importance sampling
or adaptive important sampling would often do the
job, but it would be difficult to find something that
"always" works -- at least in higher dimension?
Also, iterated one-dimensional integrations could
be attempted, but I find that messy, also because
things lose the g(many) = many(g) property, and
then R refuses to integrate g.)
(c) Will a thing like the above exist in R before
the Tromsoe Olympics in 2014? For which dimensions? 

Nils Lid Hjort
[Professor of statistics at Oslo, but currently at Duke]



From michael_shen at hotmail.com  Thu Mar 10 07:37:13 2005
From: michael_shen at hotmail.com (Michael shen)
Date: Thu, 10 Mar 2005 06:37:13 +0000
Subject: [R] How could I catch the R data-output stream and presented by
	other software func 
Message-ID: <BAY1-F6BCE686270DB826B648ABE7520@phx.gbl>

Dear All R-helper,

I wonder to know that could I do the computation  staff in R environment and 
get the R data output stream ,then presented by other software functions in 
their GUI.(for example: get the R data output streamand present the data 
using SPSS function in SPSS output GUI). Is there some R -packages in CRAN 
already do this kind of function? and what kind of document should I read?

Thanks in advance

Michael



From jari.oksanen at oulu.fi  Thu Mar 10 07:34:33 2005
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Thu, 10 Mar 2005 08:34:33 +0200
Subject: [R] Multidimensional Scaling (MDS) in R
In-Reply-To: <8eb2df300503080943329d72cb@mail.gmail.com>
References: <8eb2df300503080943329d72cb@mail.gmail.com>
Message-ID: <92539d7a9cc630f357a5b47b3f28e2a7@oulu.fi>

This nmds seems to be the wrapper function in the labdsv package. 
Please check the documentation in that package. If I remember 
correctly, labdsv is geared for cases with large number of points, and 
then you don't want to get labels because they would be too congested 
to be seen anyway. The recommended procedure is to identify interesting 
points using 'plotid' function in labdsv.

Function nmds is a very simple wrapper: it uses isoMDS in the MASS 
package, and adds class and some class methods. You may use isoMDS 
directly instead:

dis <- dsvdis(x) # Assuming you use labdsv
ord <- isoMDS(dis)
plot(ord$points, asp = 1, type="n")
text(ord$points, rownames(ord$points)

The posting guide tells  you to make package specific questions to the 
package author directly. In this case, the package author does not read 
R-News.

cheers, jari oksanen

On 8 Mar 2005, at 19:43, Isaac Waisberg wrote:

> Hi;
>
> I am working with the similarity matrix below and I would like to plot
> a two-dimensional MDS solution such as each point in the plot has a
> label.
>
> This is what I did:
>
> data <- read.table('c:/multivariate/mds/colour.txt',header=FALSE)
> similarity <- as.dist(data)
> distance <- 1-similarity
> result.nmds <- nmds(distance)
> plot(result.nmds)
>
> (nmds and plot.nmds as defined at
> labdsv.nr.usu.edu/splus_R/lab8/lab8.html; nmds simply calls isoMDS)
>
> Colour.txt, containing the similaity matrix, reads as follows:
>
>  1.0 .86 .42 .42 .18 .06 .07 .04 .02 .07 .09 .12 .13 .16
>  .86 1.0 .50 .44 .22 .09 .07 .07 .02 .04 .07 .11 .13 .14
>  .42 .50 1.0 .81 .47 .17 .10 .08 .02 .01 .02 .01 .05 .03
>  .42 .44 .81 1.0 .54 .25 .10 .09 .02 .01 .01 .01 .02 .04
>  .18 .22 .47 .54 1.0 .61 .31 .26 .07 .02 .02 .01 .02 .01
>  .06 .09 .17 .25 .61 1.0 .62 .45 .14 .08 .02 .02 .02 .01
>  .07 .07 .10 .10 .31 .62 1.0 .73 .22 .14 .05 .02 .02 .01
>  .04 .07 .08 .09 .26 .45 .73 1.0 .33 .19 .04 .03 .02 .02
>  .02 .02 .02 .02 .07 .14 .22 .33 1.0 .58 .37 .27 .20 .23
>  .07 .04 .01 .01 .02 .08 .14 .19 .58 1.0 .74 .50 .41 .28
>  .09 .07 .02 .01 .02 .02 .05 .04 .37 .74 1.0 .76 .62 .55
>  .12 .11 .01 .01 .01 .02 .02 .03 .27 .50 .76 1.0 .85 .68
>  .13 .13 .05 .02 .02 .02 .02 .02 .20 .41 .62 .85 1.0 .76
>  .16 .14 .03 .04 .01 .01 .01 .02 .23 .28 .55 .68 .76 1.0
>
> The first row corresponds to colour 1 (C1), the second to colour 2
> (C2), and so on.
>
> First, I'm not sure if this is correct or not. Second, obviously the
> points in the plot are not labeled. I suppose I must add a labels
> column and then print the labels together with the results. But, how
> should I do it?
>
> Many thanks,
>
> Isaac
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
--
Jari Oksanen, Oulu, Finland



From pdasilva at xtra.co.nz  Fri Mar 11 08:00:15 2005
From: pdasilva at xtra.co.nz (Adriano von Sydow)
Date: Thu, 10 Mar 2005 19:00:15 -1200
Subject: [R] RMySQL installed but not availalable
In-Reply-To: <200503091330.14164.ahenningsen@email.uni-kiel.de>
References: <42300F9B.5040902@xtra.co.nz>
	<200503091330.14164.ahenningsen@email.uni-kiel.de>
Message-ID: <423141FF.3030507@xtra.co.nz>

Thanks Arne,
that was spot on.
Cheers,
Popolito


Arne Henningsen wrote:

>Did you _load_ the package?
>R> library( RMySQL )
>
>On Thursday 10 March 2005 10:12, Adriano von Sydow wrote:
>  
>
>>Hi
>>I run Linux SuSE 9.1, with MSQL 4.0.18
>>I installed R 2.0.1 and it is working fine
>>I installed RM 0.5-5 package and verified all installed.packages (see
>>below) but when I tried to use any RMySQL specific comand is gives me
>>the same error messages
>>
>> > dbConnect
>>
>>Error: Object "dbConnect" not found
>>
>>It looks like the  packages is not installed
>>
>>Any ideas or help would be welcome
>>Thanks,
>>Popolito
>>
>>*** INSTALL *****
>>ginossauro:/home/avonsydow/Download/Stats # R CMD INSTALL
>>RMySQL_0.5-5.tar.gz
>>* Installing *source* package 'RMySQL' ...
>>creating cache ./config.cache
>>checking how to run the C preprocessor... cc -E
>>checking for compress in -lz... yes
>>checking for getopt_long in -lc... yes
>>checking for mysql_init in -lmysqlclient... yes
>>checking for mysql.h... no
>>checking for /usr/local/include/mysql/mysql.h... no
>>checking for /usr/include/mysql/mysql.h... yes
>>updating cache ./config.cache
>>creating ./config.status
>>creating src/Makevars
>>** libs
>>gcc -I/usr/lib/R/include -I/usr/include/mysql -I/usr/local/include
>>-I/opt/gnome/
>>include   -fPIC   -c RS-DBI.c -o RS-DBI.o
>>gcc -I/usr/lib/R/include -I/usr/include/mysql -I/usr/local/include
>>-I/opt/gnome/
>>include   -fPIC   -c RS-MySQL.c -o RS-MySQL.o
>>gcc -shared -L/usr/local/lib -L/opt/gnome/lib -o RMySQL.so RS-DBI.o
>>RS-MySQL.o -
>>lmysqlclient -lz  -L/usr/lib/R/lib -lR
>>** R
>>** inst
>>** save image
>>Loading required package: DBI
>>[1] "dbObjectId"
>>[1] "format"
>>[1] "show"
>>[1] "print"
>>[1] "MySQLObject"
>>[1] "MySQLDriver"
>>[1] "dbUnloadDriver"
>>[1] "dbGetInfo"
>>[1] "dbListConnections"
>>[1] "summary"
>>[1] "MySQLConnection"
>>[1] "dbConnect"
>>[1] "dbConnect"
>>[1] "dbConnect"
>>[1] "dbDisconnect"
>>[1] "dbSendQuery"
>>[1] "dbGetQuery"
>>[1] "dbGetException"
>>[1] "dbGetInfo"
>>[1] "dbListResults"
>>[1] "summary"
>>[1] "dbListTables"
>>[1] "dbReadTable"
>>[1] "dbWriteTable"
>>[1] "dbExistsTable"
>>[1] "dbRemoveTable"
>>[1] "dbListFields"
>>[1] "dbCommit"
>>[1] "dbRollback"
>>[1] "dbCallProc"
>>[1] "MySQLResult"
>>[1] "dbClearResult"
>>[1] "fetch"
>>[1] "fetch"
>>[1] "dbGetInfo"
>>[1] "dbGetStatement"
>>[1] "dbListFields"
>>[1] "dbColumnInfo"
>>[1] "dbGetRowsAffected"
>>[1] "dbGetRowCount"
>>[1] "dbHasCompleted"
>>[1] "dbGetException"
>>[1] "summary"
>>[1] "dbDataType"
>>[1] "make.db.names"
>>[1] "SQLKeywords"
>>[1] "isSQLKeyword"
>>[1] "dbApply"
>>[1] "dbApply"
>>
>>** help
>>
>> >>> Building/Updating help pages for package 'RMySQL'
>>
>>     Formats: text html latex example
>>  MySQL                             text    html    latex   example
>>  MySQLConnection-class             text    html    latex   example
>>  MySQLDriver-class                 text    html    latex   example
>>  MySQLObject-class                 text    html    latex   example
>>  MySQLResult-class                 text    html    latex   example
>>  S4R                               text    html    latex
>>  dbApply-methods                   text    html    latex   example
>>  dbApply                           text    html    latex   example
>>  dbCallProc-methods                text    html    latex
>>  dbCommit-methods                  text    html    latex   example
>>  dbConnect-methods                 text    html    latex   example
>>  dbDataType-methods                text    html    latex   example
>>  dbDriver-methods                  text    html    latex   example
>>  dbGetInfo-methods                 text    html    latex   example
>>  dbListTables-methods              text    html    latex   example
>>  dbObjectId-class                  text    html    latex   example
>>  dbReadTable-methods               text    html    latex   example
>>  dbSendQuery-methods               text    html    latex   example
>>  dbSetDataMappings-methods         text    html    latex   example
>>  fetch-methods                     text    html    latex   example
>>  isIdCurrent                       text    html    latex   example
>>  make.db.names-methods             text    html    latex   example
>>  mysqlDBApply                      text    html    latex   example
>>  mysqlSupport                      text    html    latex
>>  safe.write                        text    html    latex   example
>>  summary-methods                   text    html    latex
>>* DONE (RMySQL)
>>
>>
>>
>>*****INSTALLED.PACKAGES *******
>>
>> > installed.packages()
>>
>>           Package      LibPath              Version   Priority      Bundle
>>base       "base"       "/usr/lib/R/library" "2.0.1"   "base"        NA
>>boot       "boot"       "/usr/lib/R/library" "1.2-20"  "recommended" NA
>>class      "class"      "/usr/lib/R/library" "7.2-10"  "recommended" "VR"
>>cluster    "cluster"    "/usr/lib/R/library" "1.9.6"   "recommended" NA
>>datasets   "datasets"   "/usr/lib/R/library" "2.0.1"   "base"        NA
>>DBI        "DBI"        "/usr/lib/R/library" "0.1-8"   NA            NA
>>foreign    "foreign"    "/usr/lib/R/library" "0.8-0"   "recommended" NA
>>graphics   "graphics"   "/usr/lib/R/library" "2.0.1"   "base"        NA
>>grDevices  "grDevices"  "/usr/lib/R/library" "2.0.1"   "base"        NA
>>grid       "grid"       "/usr/lib/R/library" "2.0.1"   "base"        NA
>>KernSmooth "KernSmooth" "/usr/lib/R/library" "2.22-14" "recommended" NA
>>lattice    "lattice"    "/usr/lib/R/library" "0.10-14" "recommended" NA
>>MASS       "MASS"       "/usr/lib/R/library" "7.2-10"  "recommended" "VR"
>>methods    "methods"    "/usr/lib/R/library" "2.0.1"   "base"        NA
>>mgcv       "mgcv"       "/usr/lib/R/library" "1.1-8"   "recommended" NA
>>nlme       "nlme"       "/usr/lib/R/library" "3.1-53"  "recommended" NA
>>nnet       "nnet"       "/usr/lib/R/library" "7.2-10"  "recommended" "VR"
>>RMySQL     "RMySQL"     "/usr/lib/R/library" "0.5-5"   NA            NA
>>rpart      "rpart"      "/usr/lib/R/library" "3.1-20"  "recommended" NA
>>spatial    "spatial"    "/usr/lib/R/library" "7.2-10"  "recommended" "VR"
>>splines    "splines"    "/usr/lib/R/library" "2.0.1"   "base"        NA
>>stats      "stats"      "/usr/lib/R/library" "2.0.1"   "base"        NA
>>stats4     "stats4"     "/usr/lib/R/library" "2.0.1"   "base"        NA
>>survival   "survival"   "/usr/lib/R/library" "2.15"    "recommended" NA
>>tcltk      "tcltk"      "/usr/lib/R/library" "2.0.1"   "base"        NA
>>tools      "tools"      "/usr/lib/R/library" "2.0.1"   "base"        NA
>>utils      "utils"      "/usr/lib/R/library" "2.0.1"   "base"        NA
>>           Depends
>>base       NA
>>boot       "R (>= 2.0.0), graphics, stats"
>>class      "R (>= 2.0.0), graphics, stats"
>>cluster    "R (>= 1.9), stats, graphics, utils"
>>datasets   NA
>>DBI        "R (>= 1.7.1), methods"
>>foreign    "R (>= 2.0.0)"
>>graphics   "grDevices"
>>grDevices  NA
>>grid       "grDevices"
>>KernSmooth "R (>= 1.9.0)"
>>lattice    "R (>= 2.0.0)"
>>MASS       "R (>= 2.0.0), graphics, stats"
>>methods    NA
>>mgcv       "R (>= 1.9.0)"
>>nlme       "graphics, stats, R(>= 2.0.0)"
>>nnet       "R (>= 2.0.0), graphics, stats"
>>RMySQL     "R (>= 1.8.0), methods, DBI (>= 0.1-4)"
>>rpart      "R (>= 2.0.0)"
>>spatial    "R (>= 2.0.0), graphics, stats"
>>splines    NA
>>stats      NA
>>stats4     "graphics, stats, methods"
>>survival   "stats, utils, graphics, splines, R (>= 2.0.0)"
>>tcltk      NA
>>tools      NA
>>utils      NA
>>           Suggests
>>base       NA
>>boot       "survival"
>>class      "lattice, nlme, survival"
>>cluster    NA
>>datasets   NA
>>DBI        NA
>>foreign    NA
>>graphics   NA
>>grDevices  NA
>>grid       "lattice"
>>KernSmooth "MASS"
>>lattice    "grid"
>>MASS       "lattice, nlme, survival"
>>methods    NA
>>mgcv       "nlme (>= 3.1-52), MASS (>= 7.2-2)"
>>nlme       NA
>>nnet       "lattice, nlme, survival"
>>RMySQL     NA
>>rpart      "survival"
>>spatial    "lattice, nlme, survival"
>>splines    NA
>>stats      NA
>>stats4     NA
>>survival   NA
>>tcltk      NA
>>tools      NA
>>utils      NA
>>
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
>>http://www.R-project.org/posting-guide.html
>>    
>>
>
>  
>



From h0394018 at hkusua.hku.hk  Thu Mar 10 05:26:43 2005
From: h0394018 at hkusua.hku.hk (h0394018@hkusua.hku.hk)
Date: Thu, 10 Mar 2005 12:26:43 +0800
Subject: [R] urgent request
Message-ID: <1110428803.422fcc83156a6@imp.webmail.hku.hk>

Hi guys,
I want to do weighted conditional logistic regression, but clogit do not accept
weights. Would you tell me whether there are any ways to do this?
Thanks a lot in advance,
Spring



From andrewr at uidaho.edu  Thu Mar 10 01:39:27 2005
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Wed, 09 Mar 2005 16:39:27 -0800
Subject: [R] Help with lme Random Factor
Message-ID: <6846e96844ad.6844ad6846e9@uidaho.edu>

Hello Andrew,

I strongly suggest that you obtain a copy of the book that documents the use of the package, and read it.  

Mixed Effects Models in S and S-Plus
by Jose C. Pinheiro and Douglas M. Bates  Springer Verlag 2000.

I hope that this helps,

Andrew


----- Original Message -----
From: Andrew James Amacher <aamacher at nature.berkeley.edu>
Date: Wednesday, March 9, 2005 4:19 pm
Subject: [R] Help with lme Random Factor

> Hi,
> 
> I need help creating a code for a multiple BACI design (Before-After
> Control-Impact) ANOVA.  I'm new to R and basically need to run a 
> complexmixed model ANOVA that treats location as a random factor.
> 
> Data are from a fire experiment, run 2001-2004 (2 years pre, 2 years
> post).  Response is bird abundance.  4 Treatments had 3 replicates 
> each(forest stands): 1. Control, 2. Prescribed fire only, 3. 
> Timber harvesting
> only, and 4. Fire and harvesting.
> 
> Basically, I'm having trouble figuring out the code that makes the
> variable "LOC" a random factor.
> 
> Also, I'm having trouble figuring out how to script contrasts 
> comparingthe treatments to the control (multiple comparisons w/ a 
> control). 
> Treatment group is not a part of the lme script.  Do I need to run 
> themeach individually, i.e. C vs. T1, C vs. T2, C vs T3? or can I 
> code in
> treatment contrasts?
> 
> Script (used S-plus GUI to build it):
> 
> GCKI~.+C+B+LOC%in%C+T%in%B+C:B+C:T%in%B+LOC%in%C:B+LOC%in%C:T%in%B
> **unsure what goes here to make LOC random****
> 
> Terms:
> 
> GCKI: Golden-crowned kinglet abundance.
> 
> C:  Control-Impact (2 levels, either control (no treatment), or impact
> (received treatment after 2 years)
> 
> B: Before-After (2 levels, 2001-2002 = Before, 2003-2004 = After)
> 
> T: Time, 4 levels, years 2001, 2002, 2003, 2004
> 
> LOC: location, 3 replicates in among the 4 treatments (RANDOM FACTOR)
> 
> 
> Sorry to write so much, but any help would be appreciated.  The ANOVA
> model comes from a book: Monitoring Ecological Impacts: Downes et al.
> 2002.
> 
> I am used to running GUIs, but it appears I need to script this 
> ANOVA.  I
> am unfamiliar with random factor scripts or scripts for multiple 
> contrastswith controls.
> 
> Cheers,
> 
> Andrew
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-
> guide.html



From p.murrell at auckland.ac.nz  Thu Mar 10 02:50:49 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Thu, 10 Mar 2005 14:50:49 +1300
Subject: [R] Lattice device page options-margins
References: <0016F5677B1F1D4281EEBC034993595102728D3A@CORPEXBE1.arcadis-us.com>
Message-ID: <422FA7F9.2090204@stat.auckland.ac.nz>

Hi


Bock, Michael wrote:
>  
> 
> 
>>-----Original Message-----
>>From: Deepayan Sarkar [mailto:deepayan at stat.wisc.edu] 
>>Sent: Wednesday, March 09, 2005 5:09 PM
>>To: r-help at stat.math.ethz.ch
>>Cc: Paul Murrell; Bock, Michael; Sundar Dorai-Raj
>>Subject: Re: [R] Lattice device page options-margins
>>
>>On Wednesday 09 March 2005 13:54, Paul Murrell wrote:
>>
>>>Hi
>>>
>>>Sundar Dorai-Raj wrote:
>>>
>>>>Bock, Michael wrote on 3/9/2005 1:19 PM:
>>>>
>>>>>I am using lattice to make figures as pdfs:
>>>>>trellis.device(device = "pdf",file = "Figure6.pdf",color = FALSE)
>>>>>
>>>>>I need to specify some blank space on the left-hand margins (the 
>>>>>pages will be bound so we need about 0.5 inch)). I have tried a 
>>>>>number of solutions but none seems to work (e.g. 
>>>>
>>par.set). Can this 
>>
>>>>>be done when initiating the plotting device? Or is the 
>>>>
>>some other 
>>
>>>>>way that does not require me to manually move everything over?
>>>>
>>>>Michael,
>>>>
>>>>I believe you can do this using print.trellis and setting the 
>>>>position argument. E.g.
>>>>
>>>>trellis.device(device = "pdf",file = "Figure6.pdf",color 
>>>
>>= FALSE) xy 
>>
>>>><- xyplot(...) print(xy, pos = c(0.10, 0, 1, 1))
>>>>dev.off()
>>>
>>>Or if you want exactly 0.5 inches, something like ...
>>>
>>># may need
>>># library(grid)
>>>trellis.device(device = "pdf",file = "Figure6.pdf",color = 
>>
>>FALSE) xy 
>>
>>><- xyplot(1:10 ~ 1:10) pushViewport(viewport(x=1,
>>>                       width=unit(1, "npc") - unit(0.5, "inches"),
>>>                       just="right"))
>>># to show region you're plotting in
>>># grid.rect(gp=gpar(col="grey"))
>>>print(xy, newpage=FALSE)
>>>popViewport()
>>>dev.off()
>>
>>Yet another option, especially if you want this for multiple 
>>plots without having to handle each one separately, is to say 
>>(after loading
>>lattice):
>>
>>lattice.options(layout.widths = list(left.padding = 
>>                list(x = 0.5, units = "inches")))
>>
>>Unlike par settings though, this would stay in effect across devices.
>>
>>Deepayan
>>
>>
> 
> Thanks for the suggestions. None of these do exactly what I want. I have
> some multi panel plotts
> Excepted Commands:
> BC.PP<-bwplot(PP.PAH ~ Area, Crab, horizontal = FALSE,
>         ylab = "Priority Pollutant PAHs (mg/kg)",
>         scales = list(x="free",rot=90),  aspect = 1.5,
>         main = list(label = "Blue Crabs",cex=0.8,font=1),
>         fontfamily = "HersheySans")
> RM.PP<-bwplot( PP.PAH ~ Area, Mussel, horizontal = FALSE,
>         ylab = "",
>         scales = list(x="free",rot=90), aspect = 1.5,
>         main = list(label="   Ribbed Mussels",cex =0.8,font=1),
>         fontfamily = "HersheySans")
> print(BC.PP, split = c(1,1,2,1), more = TRUE )
> print(RM.PP, split = c(2,1,2,1),more = TRUE )
> grid.text(label = "Figure 6. Priority Pollutant PAH Tissue
> Concentrations",
>           x = unit(0.01, "npc"), y = unit(0.1, "npc"),
>           just = "left", rot = 0,
>           check.overlap = FALSE, default.units = "npc",
>           name = NULL, gp = gpar(fontsize = 10, font = 2), draw = TRUE)
> grid.text(label = "Privileged and Confidential \nAttorney Work Product",
>           x = unit(0.01, "npc"), y = unit(0.95, "npc"),
>           just = "left", rot = 0,
>           check.overlap = FALSE, default.units = "npc",
>           name = NULL, gp = gpar(fontsize = 6, font = 3), draw = TRUE)
> 
> 
> All of the suggestions shrink the individual boxplots so they both now
> have empty space on the left size. I guess what I really want is to be
> able define the plotting area as a portion of the page, allowing for a
> blank region on the left. Basically defining the margin of the print
> area.
> 
> BSomething like:
> trellis.device(device = "pdf",file = "Figure6.pdf",color = FALSE,left =
> 0.1, right = 0.9)
> Assuming the hypothetical left and right commands set the print area for
> the pdf. Hopefully this better defines my "ideal solution".
> 
> Thanks for the suggestions, if an ideal solution can not be found I at
> least have enough to develop a work around.  It just too bad I hadn't
> though of this issue before writing so many scripts to make my plots
> that will now have to be adjusted manually.


Do you mean like this ...?

# Dummy data
# (it would be easier to give an answer if you gave us the real thing)
Crab <- data.frame(PP.PAH=rnorm(20),
                    Area=factor(sample(20, 1:2, replace=TRUE)))
Mussel <- data.frame(PP.PAH=rnorm(20),
                      Area=factor(sample(20, 1:2, replace=TRUE)))

BC.PP<-bwplot(PP.PAH ~ Area, Crab, horizontal = FALSE,
         ylab = "Priority Pollutant PAHs (mg/kg)",
         scales = list(x="free",rot=90),  aspect = 1.5,
         main = list(label = "Blue Crabs",cex=0.8,font=1),
         fontfamily = "HersheySans")
RM.PP<-bwplot( PP.PAH ~ Area, Mussel, horizontal = FALSE,
         ylab = "",
         scales = list(x="free",rot=90), aspect = 1.5,
         main = list(label="   Ribbed Mussels",cex =0.8,font=1),
         fontfamily = "HersheySans")
trellis.device(device = "pdf",file = "Figure6.pdf",color = FALSE)
# push viewport for ALL drawing
pushViewport(viewport(x=.1, width=.8, just="left"))
# just to show region you're plotting in
grid.rect(gp=gpar(col="grey"))
print(BC.PP, split = c(1,1,2,1), more = TRUE, newpage=FALSE)
print(RM.PP, split = c(2,1,2,1),more = TRUE)
grid.text(label = "Figure 6. Priority Pollutant PAH Tissue Concentrations",
           x = unit(0.01, "npc"), y = unit(0.1, "npc"),
           just = "left", rot = 0,
           check.overlap = FALSE, default.units = "npc",
           name = NULL, gp = gpar(fontsize = 10, font = 2), draw = TRUE)
grid.text(label = "Privileged and Confidential \nAttorney Work Product",
           x = unit(0.01, "npc"), y = unit(0.95, "npc"),
           just = "left", rot = 0,
           check.overlap = FALSE, default.units = "npc",
           name = NULL, gp = gpar(fontsize = 6, font = 3), draw = TRUE)
popViewport()
dev.off()


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From MBock at arcadis-us.com  Thu Mar 10 02:33:24 2005
From: MBock at arcadis-us.com (Bock, Michael)
Date: Wed, 9 Mar 2005 18:33:24 -0700
Subject: [R] Lattice device page options-margins
Message-ID: <0016F5677B1F1D4281EEBC034993595102728D3A@CORPEXBE1.arcadis-us.com>

 

> -----Original Message-----
> From: Deepayan Sarkar [mailto:deepayan at stat.wisc.edu] 
> Sent: Wednesday, March 09, 2005 5:09 PM
> To: r-help at stat.math.ethz.ch
> Cc: Paul Murrell; Bock, Michael; Sundar Dorai-Raj
> Subject: Re: [R] Lattice device page options-margins
> 
> On Wednesday 09 March 2005 13:54, Paul Murrell wrote:
> > Hi
> >
> > Sundar Dorai-Raj wrote:
> > > Bock, Michael wrote on 3/9/2005 1:19 PM:
> > >> I am using lattice to make figures as pdfs:
> > >> trellis.device(device = "pdf",file = "Figure6.pdf",color = FALSE)
> > >>
> > >> I need to specify some blank space on the left-hand margins (the 
> > >> pages will be bound so we need about 0.5 inch)). I have tried a 
> > >> number of solutions but none seems to work (e.g. 
> par.set). Can this 
> > >> be done when initiating the plotting device? Or is the 
> some other 
> > >> way that does not require me to manually move everything over?
> > >
> > > Michael,
> > >
> > > I believe you can do this using print.trellis and setting the 
> > > position argument. E.g.
> > >
> > > trellis.device(device = "pdf",file = "Figure6.pdf",color 
> = FALSE) xy 
> > > <- xyplot(...) print(xy, pos = c(0.10, 0, 1, 1))
> > > dev.off()
> >
> > Or if you want exactly 0.5 inches, something like ...
> >
> > # may need
> > # library(grid)
> > trellis.device(device = "pdf",file = "Figure6.pdf",color = 
> FALSE) xy 
> > <- xyplot(1:10 ~ 1:10) pushViewport(viewport(x=1,
> >                        width=unit(1, "npc") - unit(0.5, "inches"),
> >                        just="right"))
> > # to show region you're plotting in
> > # grid.rect(gp=gpar(col="grey"))
> > print(xy, newpage=FALSE)
> > popViewport()
> > dev.off()
> 
> Yet another option, especially if you want this for multiple 
> plots without having to handle each one separately, is to say 
> (after loading
> lattice):
> 
> lattice.options(layout.widths = list(left.padding = 
>                 list(x = 0.5, units = "inches")))
> 
> Unlike par settings though, this would stay in effect across devices.
> 
> Deepayan
> 
> 
Thanks for the suggestions. None of these do exactly what I want. I have
some multi panel plotts
Excepted Commands:
BC.PP<-bwplot(PP.PAH ~ Area, Crab, horizontal = FALSE,
        ylab = "Priority Pollutant PAHs (mg/kg)",
        scales = list(x="free",rot=90),  aspect = 1.5,
        main = list(label = "Blue Crabs",cex=0.8,font=1),
        fontfamily = "HersheySans")
RM.PP<-bwplot( PP.PAH ~ Area, Mussel, horizontal = FALSE,
        ylab = "",
        scales = list(x="free",rot=90), aspect = 1.5,
        main = list(label="   Ribbed Mussels",cex =0.8,font=1),
        fontfamily = "HersheySans")
print(BC.PP, split = c(1,1,2,1), more = TRUE )
print(RM.PP, split = c(2,1,2,1),more = TRUE )
grid.text(label = "Figure 6. Priority Pollutant PAH Tissue
Concentrations",
          x = unit(0.01, "npc"), y = unit(0.1, "npc"),
          just = "left", rot = 0,
          check.overlap = FALSE, default.units = "npc",
          name = NULL, gp = gpar(fontsize = 10, font = 2), draw = TRUE)
grid.text(label = "Privileged and Confidential \nAttorney Work Product",
          x = unit(0.01, "npc"), y = unit(0.95, "npc"),
          just = "left", rot = 0,
          check.overlap = FALSE, default.units = "npc",
          name = NULL, gp = gpar(fontsize = 6, font = 3), draw = TRUE)


All of the suggestions shrink the individual boxplots so they both now
have empty space on the left size. I guess what I really want is to be
able define the plotting area as a portion of the page, allowing for a
blank region on the left. Basically defining the margin of the print
area.

BSomething like:
trellis.device(device = "pdf",file = "Figure6.pdf",color = FALSE,left =
0.1, right = 0.9)
Assuming the hypothetical left and right commands set the print area for
the pdf. Hopefully this better defines my "ideal solution".

Thanks for the suggestions, if an ideal solution can not be found I at
least have enough to develop a work around.  It just too bad I hadn't
though of this issue before writing so many scripts to make my plots
that will now have to be adjusted manually.

Mike



From MSchwartz at MedAnalytics.com  Thu Mar 10 01:52:14 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed, 09 Mar 2005 18:52:14 -0600
Subject: [R] plotting
In-Reply-To: <1110392918.422f40568c26e@my2.dal.ca>
References: <1110392918.422f40568c26e@my2.dal.ca>
Message-ID: <1110415935.31854.31.camel@horizons.localdomain>

On Wed, 2005-03-09 at 14:28 -0400, Owen Buchner wrote:
> I have two questions for you.  Firstly I'm having troubles trying to plot more
> then 1 graph.  I'm attempting to make a plot with 9 panels, but i have no clue
> what type of code to use.

If you are using R's base graphics and you want 9 plots arranged
vertically, you can use par(mfrow = 9) before your first plot.

The first plot will then be in the top panel (row).

Each successive call to a high level plot function [ie. plot(), boxplot
(), barplot()] will draw the plot in the next panel (row) down.

See ?par for more information and some examples.

Another option, for base graphics, is to use the layout() function and
yet another, is to use the grid/lattice packages for creating "Trellis"
type plots.

> Secondly i was wondering if there was some code to generate random numbers
> between two defined intervals and then have R chose one randomly in a program. 
> If you could answer either of these questions for me I would appreciate it.

If you want to generate random numbers from a pre-specified sequence of
numbers between some min and max values (each number having an equal
probability of being selected) and then return one of them, you can use
the sample function:

  sample(min:max, 1)

See ?sample for more information. Note that the sequence need not be all
integers:

> sample(seq(1, 10, 0.5), 1)
[1] 2.5


If you want the random numbers to be within some min:max set of limits,
such that:

  min <= x <= max

each 'x' having an equal probability of being selected and then return
one of the numbers, use runif():

  runif(1, min, max)

See ?runif for more information.

HTH,

Marc Schwartz



From macq at llnl.gov  Thu Mar 10 01:41:59 2005
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 9 Mar 2005 16:41:59 -0800
Subject: [R] RMySQL installed but not availalable
In-Reply-To: <42300F9B.5040902@xtra.co.nz>
References: <42300F9B.5040902@xtra.co.nz>
Message-ID: <p06210210be55480a8181@[128.115.153.6]>


>require(RMySQL)
>help('MySQL')

then see the examples shown by the help page

At 9:12 PM -1200 3/9/05, Adriano von Sydow wrote:
>Hi
>I run Linux SuSE 9.1, with MSQL 4.0.18
>I installed R 2.0.1 and it is working fine
>I installed RM 0.5-5 package and verified all installed.packages 
>(see below) but when I tried to use any RMySQL specific comand is 
>gives me the same error messages
>
>>  dbConnect
>Error: Object "dbConnect" not found
>
>It looks like the  packages is not installed
>
>Any ideas or help would be welcome
>Thanks,
>Popolito
>
>*** INSTALL *****
>ginossauro:/home/avonsydow/Download/Stats # R CMD INSTALL RMySQL_0.5-5.tar.gz
>* Installing *source* package 'RMySQL' ...
>creating cache ./config.cache
>checking how to run the C preprocessor... cc -E
>checking for compress in -lz... yes
>checking for getopt_long in -lc... yes
>checking for mysql_init in -lmysqlclient... yes
>checking for mysql.h... no
>checking for /usr/local/include/mysql/mysql.h... no
>checking for /usr/include/mysql/mysql.h... yes
>updating cache ./config.cache
>creating ./config.status
>creating src/Makevars
>** libs
>gcc -I/usr/lib/R/include -I/usr/include/mysql -I/usr/local/include 
>-I/opt/gnome/
>include   -fPIC   -c RS-DBI.c -o RS-DBI.o
>gcc -I/usr/lib/R/include -I/usr/include/mysql -I/usr/local/include 
>-I/opt/gnome/
>include   -fPIC   -c RS-MySQL.c -o RS-MySQL.o
>gcc -shared -L/usr/local/lib -L/opt/gnome/lib -o RMySQL.so RS-DBI.o 
>RS-MySQL.o -
>lmysqlclient -lz  -L/usr/lib/R/lib -lR
>** R
>** inst
>** save image
>Loading required package: DBI
>[1] "dbObjectId"
>[1] "format"
>[1] "show"
>[1] "print"
>[1] "MySQLObject"
>[1] "MySQLDriver"
>[1] "dbUnloadDriver"
>[1] "dbGetInfo"
>[1] "dbListConnections"
>[1] "summary"
>[1] "MySQLConnection"
>[1] "dbConnect"
>[1] "dbConnect"
>[1] "dbConnect"
>[1] "dbDisconnect"
>[1] "dbSendQuery"
>[1] "dbGetQuery"
>[1] "dbGetException"
>[1] "dbGetInfo"
>[1] "dbListResults"
>[1] "summary"
>[1] "dbListTables"
>[1] "dbReadTable"
>[1] "dbWriteTable"
>[1] "dbExistsTable"
>[1] "dbRemoveTable"
>[1] "dbListFields"
>[1] "dbCommit"
>[1] "dbRollback"
>[1] "dbCallProc"
>[1] "MySQLResult"
>[1] "dbClearResult"
>[1] "fetch"
>[1] "fetch"
>[1] "dbGetInfo"
>[1] "dbGetStatement"
>[1] "dbListFields"
>[1] "dbColumnInfo"
>[1] "dbGetRowsAffected"
>[1] "dbGetRowCount"
>[1] "dbHasCompleted"
>[1] "dbGetException"
>[1] "summary"
>[1] "dbDataType"
>[1] "make.db.names"
>[1] "SQLKeywords"
>[1] "isSQLKeyword"
>[1] "dbApply"
>[1] "dbApply"
>
>** help
>  >>> Building/Updating help pages for package 'RMySQL'
>     Formats: text html latex example
>  MySQL                             text    html    latex   example
>  MySQLConnection-class             text    html    latex   example
>  MySQLDriver-class                 text    html    latex   example
>  MySQLObject-class                 text    html    latex   example
>  MySQLResult-class                 text    html    latex   example
>  S4R                               text    html    latex
>  dbApply-methods                   text    html    latex   example
>  dbApply                           text    html    latex   example
>  dbCallProc-methods                text    html    latex
>  dbCommit-methods                  text    html    latex   example
>  dbConnect-methods                 text    html    latex   example
>  dbDataType-methods                text    html    latex   example
>  dbDriver-methods                  text    html    latex   example
>  dbGetInfo-methods                 text    html    latex   example
>  dbListTables-methods              text    html    latex   example
>  dbObjectId-class                  text    html    latex   example
>  dbReadTable-methods               text    html    latex   example
>  dbSendQuery-methods               text    html    latex   example
>  dbSetDataMappings-methods         text    html    latex   example
>  fetch-methods                     text    html    latex   example
>  isIdCurrent                       text    html    latex   example
>  make.db.names-methods             text    html    latex   example
>  mysqlDBApply                      text    html    latex   example
>  mysqlSupport                      text    html    latex
>  safe.write                        text    html    latex   example
>  summary-methods                   text    html    latex
>* DONE (RMySQL)
>
>
>
>*****INSTALLED.PACKAGES *******
>
>>  installed.packages()
>           Package      LibPath              Version   Priority      Bundle
>base       "base"       "/usr/lib/R/library" "2.0.1"   "base"        NA
>boot       "boot"       "/usr/lib/R/library" "1.2-20"  "recommended" NA
>class      "class"      "/usr/lib/R/library" "7.2-10"  "recommended" "VR"
>cluster    "cluster"    "/usr/lib/R/library" "1.9.6"   "recommended" NA
>datasets   "datasets"   "/usr/lib/R/library" "2.0.1"   "base"        NA
>DBI        "DBI"        "/usr/lib/R/library" "0.1-8"   NA            NA
>foreign    "foreign"    "/usr/lib/R/library" "0.8-0"   "recommended" NA
>graphics   "graphics"   "/usr/lib/R/library" "2.0.1"   "base"        NA
>grDevices  "grDevices"  "/usr/lib/R/library" "2.0.1"   "base"        NA
>grid       "grid"       "/usr/lib/R/library" "2.0.1"   "base"        NA
>KernSmooth "KernSmooth" "/usr/lib/R/library" "2.22-14" "recommended" NA
>lattice    "lattice"    "/usr/lib/R/library" "0.10-14" "recommended" NA
>MASS       "MASS"       "/usr/lib/R/library" "7.2-10"  "recommended" "VR"
>methods    "methods"    "/usr/lib/R/library" "2.0.1"   "base"        NA
>mgcv       "mgcv"       "/usr/lib/R/library" "1.1-8"   "recommended" NA
>nlme       "nlme"       "/usr/lib/R/library" "3.1-53"  "recommended" NA
>nnet       "nnet"       "/usr/lib/R/library" "7.2-10"  "recommended" "VR"
>RMySQL     "RMySQL"     "/usr/lib/R/library" "0.5-5"   NA            NA
>rpart      "rpart"      "/usr/lib/R/library" "3.1-20"  "recommended" NA
>spatial    "spatial"    "/usr/lib/R/library" "7.2-10"  "recommended" "VR"
>splines    "splines"    "/usr/lib/R/library" "2.0.1"   "base"        NA
>stats      "stats"      "/usr/lib/R/library" "2.0.1"   "base"        NA
>stats4     "stats4"     "/usr/lib/R/library" "2.0.1"   "base"        NA
>survival   "survival"   "/usr/lib/R/library" "2.15"    "recommended" NA
>tcltk      "tcltk"      "/usr/lib/R/library" "2.0.1"   "base"        NA
>tools      "tools"      "/usr/lib/R/library" "2.0.1"   "base"        NA
>utils      "utils"      "/usr/lib/R/library" "2.0.1"   "base"        NA
>           Depends
>base       NA
>boot       "R (>= 2.0.0), graphics, stats"
>class      "R (>= 2.0.0), graphics, stats"
>cluster    "R (>= 1.9), stats, graphics, utils"
>datasets   NA
>DBI        "R (>= 1.7.1), methods"
>foreign    "R (>= 2.0.0)"
>graphics   "grDevices"
>grDevices  NA
>grid       "grDevices"
>KernSmooth "R (>= 1.9.0)"
>lattice    "R (>= 2.0.0)"
>MASS       "R (>= 2.0.0), graphics, stats"
>methods    NA
>mgcv       "R (>= 1.9.0)"
>nlme       "graphics, stats, R(>= 2.0.0)"
>nnet       "R (>= 2.0.0), graphics, stats"
>RMySQL     "R (>= 1.8.0), methods, DBI (>= 0.1-4)"
>rpart      "R (>= 2.0.0)"
>spatial    "R (>= 2.0.0), graphics, stats"
>splines    NA
>stats      NA
>stats4     "graphics, stats, methods"
>survival   "stats, utils, graphics, splines, R (>= 2.0.0)"
>tcltk      NA
>tools      NA
>utils      NA
>           Suggests
>base       NA
>boot       "survival"
>class      "lattice, nlme, survival"
>cluster    NA
>datasets   NA
>DBI        NA
>foreign    NA
>graphics   NA
>grDevices  NA
>grid       "lattice"
>KernSmooth "MASS"
>lattice    "grid"
>MASS       "lattice, nlme, survival"
>methods    NA
>mgcv       "nlme (>= 3.1-52), MASS (>= 7.2-2)"
>nlme       NA
>nnet       "lattice, nlme, survival"
>RMySQL     NA
>rpart      "survival"
>spatial    "lattice, nlme, survival"
>splines    NA
>stats      NA
>stats4     NA
>survival   NA
>tcltk      NA
>tools      NA
>utils      NA
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From ripley at stats.ox.ac.uk  Thu Mar 10 08:56:34 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 10 Mar 2005 07:56:34 +0000 (GMT)
Subject: [R] two-dimensional integration?
In-Reply-To: <422FD991.70304@isds.duke.edu>
References: <422FD991.70304@isds.duke.edu>
Message-ID: <Pine.LNX.4.61.0503100745130.29906@gannet.stats>

Nils,

For 2D, see package 'adapt' on CRAN. e.g.

adapt(2, c(0,0), c(1,1), functn=function(x) sin(prod(x))*exp(x[1]-x[2]))

Package `adapt' will do larger numbers of dimensions, but numerical 
quadrature is often no more effective than Monte-Carlo methods in more 
than a few dimensions.  For very smooth functions, quasi-random numbers 
can help.

A good reference aimed at statisticians is

@Book{Evans.Swartz.00,
   author =       {Michael Evans and Tim Swartz},
   title =        {Approximating Integrals via Monte Carlo and
                   Deterministic Methods},
   publisher =    {Oxford University Press},
   year =         2000,
   address =      {Oxford},
   ISBN =         "0-19-850278-8",
}

BTW, we are not good are predicting to 2014, but fairly good at the 
present.  In this case I could not guess a good search term on
http://search.r-project.org, but it often gets you there.  It has a 
`complete' list of packages, as does CRAN, and searching those pages for 
`integrate' works.

Brian

On Thu, 10 Mar 2005, Nils-at-Duke Lid Hjort wrote:

> I find the one-dimensional "integrate" very helpful,
> but often enough I stumble into problems that require
> two (or more)-dimensional integrals. I suppose there
> are no R functions that can do this for me, "directly"?
>
> The ideal thing would be to be able to define say
> f <- function(x)
> {
> x1 <- x[1]
> x2 <- x[2]
> sin(x1*x2)*exp(x1-x2)
> }
> and then write say
> integrate(f, xlim=c(0,1), ylim=c(0,1))  .
>
> (a) No such thing exists, as of today, right?
> (b) There *are* general numerical routines "out there"
> for doing such things, right? (Importance sampling
> or adaptive important sampling would often do the
> job, but it would be difficult to find something that
> "always" works -- at least in higher dimension?
> Also, iterated one-dimensional integrations could
> be attempted, but I find that messy, also because
> things lose the g(many) = many(g) property, and
> then R refuses to integrate g.)
> (c) Will a thing like the above exist in R before
> the Tromsoe Olympics in 2014? For which dimensions? 
> Nils Lid Hjort
> [Professor of statistics at Oslo, but currently at Duke]


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dimitris.rizopoulos at med.kuleuven.ac.be  Thu Mar 10 09:02:35 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Thu, 10 Mar 2005 09:02:35 +0100
Subject: [R] two-dimensional integration?
References: <422FD991.70304@isds.duke.edu>
Message-ID: <008201c52547$85408130$0540210a@www.domain>

This existed even before the Athens Olympics 2004 :)

look at package "adapt" which integrates a function from 2 to 20 
dimensions, e.g.,

library(adapt)
f <- function(x){
    x1 <- x[1]
    x2 <- x[2]
    sin(x1*x2)*exp(x1-x2)
}

adapt(2, c(0,0), c(1,1), functn=f)

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Nils-at-Duke Lid Hjort" <hjort at isds.duke.edu>
To: <R-help at stat.math.ethz.ch>; <nils at math.uio.no>
Sent: Thursday, March 10, 2005 6:22 AM
Subject: [R] two-dimensional integration?


>I find the one-dimensional "integrate" very helpful,
> but often enough I stumble into problems that require
> two (or more)-dimensional integrals. I suppose there
> are no R functions that can do this for me, "directly"?
>
> The ideal thing would be to be able to define say
> f <- function(x)
> {
> x1 <- x[1]
> x2 <- x[2]
> sin(x1*x2)*exp(x1-x2)
> }
> and then write say
> integrate(f, xlim=c(0,1), ylim=c(0,1))  .
>
> (a) No such thing exists, as of today, right?
> (b) There *are* general numerical routines "out there"
> for doing such things, right? (Importance sampling
> or adaptive important sampling would often do the
> job, but it would be difficult to find something that
> "always" works -- at least in higher dimension?
> Also, iterated one-dimensional integrations could
> be attempted, but I find that messy, also because
> things lose the g(many) = many(g) property, and
> then R refuses to integrate g.)
> (c) Will a thing like the above exist in R before
> the Tromsoe Olympics in 2014? For which dimensions?
> Nils Lid Hjort
> [Professor of statistics at Oslo, but currently at Duke]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From p.dalgaard at biostat.ku.dk  Thu Mar 10 09:06:05 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Mar 2005 09:06:05 +0100
Subject: [R] two-dimensional integration?
In-Reply-To: <422FD991.70304@isds.duke.edu>
References: <422FD991.70304@isds.duke.edu>
Message-ID: <x2wtsgorgy.fsf@biostat.ku.dk>

Nils-at-Duke Lid Hjort <hjort at isds.duke.edu> writes:

> I find the one-dimensional "integrate" very helpful,
> but often enough I stumble into problems that require
> two (or more)-dimensional integrals. I suppose there
...
> (c) Will a thing like the above exist in R before
> the Tromsoe Olympics in 2014? For which dimensions? Nils Lid Hjort
> [Professor of statistics at Oslo, but currently at Duke]

Did you check the CRAN package "adapt"? It's been around at least
since Nagano 1998, I believe.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Allan at STATS.uct.ac.za  Thu Mar 10 09:16:55 2005
From: Allan at STATS.uct.ac.za (Clark Allan)
Date: Thu, 10 Mar 2005 10:16:55 +0200
Subject: [R] R: LIST function and LOOPS
Message-ID: <42300277.D8ED0580@STATS.uct.ac.za>

hi all

another simple question.

i've written a dummy program so that you get the concept. (the code
could be simplfied such that there are no loops. but lets leave the
loops in for now.)

z1<-function(w)
{
for (i in 1:w)
{
set.seed(i+6)
ss<-0
	for (j in 1:5)
	{
		set.seed(j+1+(i-1)*6)
		r<-rnorm(1)
		ss<-ss+r
	}
list(ss=ss)
}
}
check.1<-z1(3)
check.1

the results is:
$ss
[1] -0.01516304


what i want is something that looks like this:

j=1
$ss
[1] -2.213343

j=2
$ss
[1] -2.904235

j=3
$ss
[1] -0.01516304


i know that i could use the print command. (see z2)

z2<-function(w)
{
for (i in 1:w)
{
set.seed(i+6)
ss<-0
	for (j in 1:5)
	{
		set.seed(j+1+(i-1)*6)
		r<-rnorm(1)
		ss<-ss+r
	}
print(ss)
}
}
check.2<-z2(3)
check.2

> check.2<-z2(3)
[1] -2.213343
[1] -2.904235
[1] -0.01516304
> check.2
[1] -0.01516304

the problem with z2 is that only the last value is saved.


what i could do is use matrices like the following: (but i dont want to
do this AND WOULD PREFER TO USE list.)

z3<-function(w)
{
results.<-matrix(nrow=w,ncol=1)
colnames(results.)<-c("ss")
for (i in 1:w)
{
set.seed(i+6)
ss<-0
	for (j in 1:5)
	{
		set.seed(j+1+(i-1)*6)
		r<-rnorm(1)
		ss<-ss+r
	}
results.[i,1]<-ss
}
results.
}
check.3<-z3(3)
check.3

> check.3
              ss
[1,] -2.21334260
[2,] -2.90423463
[3,] -0.01516304

what if i have a new program (something different) and i want the
following:

j=1
$a
1
2
3

$b
1
2
3
4
5

$c
1


###############
j=2
$a
11
21
31

$b
11
21
31
41
51

$c
11

###############
j=3
$a
21
22
32

$b
21
22
32
42
52

$c
21

MATRICES SEEMS TO BE A GOOD WAY OF DOING THIS (but then you would have
to set up three matrices, one for a,b and c). BUT WHAT IF I WANT TO USE
THE LIST FUNCTION? i.e. there is a list in the first loop that i want to
display!

sorry for the long mail.

***
ALLAN

From ripley at stats.ox.ac.uk  Thu Mar 10 09:24:44 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 10 Mar 2005 08:24:44 +0000 (GMT)
Subject: [R] contrast matrix for aov
In-Reply-To: <422F8EDE.2030009@gmail.com>
References: <422F8EDE.2030009@gmail.com>
Message-ID: <Pine.LNX.4.61.0503100722330.29906@gannet.stats>

On Wed, 9 Mar 2005, Darren Weber wrote:

> How do we specify a contrast interaction matrix for an ANOVA model?
>
> We have a two-factor, repeated measures design, with

Where does `repeated measures' come into this?  You appear to have 
repeated a 2x2 experiment in each of 8 blocks (subjects).  Such a design 
is usually analysed with fixed effects.  (Perhaps you averaged over 
repeats in the first few lines of your code?)

> Cue Direction (2) x  Brain Hemisphere(2)
>
> Each of these has 2 levels, 'left' and 'right', so it's a simple 2x2 design 
> matrix.  We have 8 subjects in each cell (a balanced design) and we want to 
> specify the interaction contrast so that:
>
> CueLeft>CueRght for the Right Hemisphere
> CueRght>CueLeft for the Left Hemisphere.
>
> Here is a copy of the relevant commands for R:
>
> ########################################
> lh_cueL <- rowMeans( LHroi.cueL[,t1:t2] )
> lh_cueR <- rowMeans( LHroi.cueR[,t1:t2] )
> rh_cueL <- rowMeans( RHroi.cueL[,t1:t2] )
> rh_cueR <- rowMeans( RHroi.cueR[,t1:t2] )
> roiValues <- c( lh_cueL, lh_cueR, rh_cueL, rh_cueR )
>
> cuelabels <- c("CueLeft", "CueRight")
> hemlabels <- c("LH", "RH")
>
> roiDataframe <- data.frame( roi=roiValues, Subject=gl(8,1,32,subjectlabels), 
> Hemisphere=gl(2,16,32,hemlabels), Cue=gl(2,8,32,cuelabels) )
>
> roi.aov <- aov(roi ~ (Cue*Hemisphere) + Error(Subject/(Cue*Hemisphere)), 
> data=roiDataframe)

I think the error model should be Error(Subject).  In what sense are `Cue' 
and `Cue:Hemisphere' random effects nested inside `Subject'?

Let me fake some `data':

set.seed(1); roiValues <- rnorm(32)
subjectlabels <- paste("V"1:8, sep = "")
options(contrasts = c("contr.helmert", "contr.poly"))
roi.aov <- aov(roi ~ Cue*Hemisphere + Error(Subject), data=roiDataframe)

> roi.aov

Call:
aov(formula = roi ~ Cue * Hemisphere + Error(Subject), data = roiDataframe)

Grand Mean: 0.1165512

Stratum 1: Subject

Terms:
                 Residuals
Sum of Squares   4.200946
Deg. of Freedom         7

Residual standard error: 0.7746839

Stratum 2: Within

Terms:
                       Cue Hemisphere Cue:Hemisphere Residuals
Sum of Squares   0.216453   0.019712       0.057860 21.896872
Deg. of Freedom         1          1              1        21

Residual standard error: 1.021131
Estimated effects are balanced

Note that all the action is in one stratum, and the SSQs are the same 
as

aov(roi ~ Subject + Cue * Hemisphere, data = roiDataframe)

(and also the same as for your fit).

> print(summary(roi.aov))

It auto-prints, so you don't need print().

> ########################################
>
>
> I've tried to create a contrast matrix like this:
>
> cm <- contrasts(roiDataframe$Cue)
>
> which gives the main effect contrasts for the Cue factor.  I really want to 
> specify the interaction contrasts, so I tried this:
>
> ########################################
> # c( lh_cueL, lh_cueR, rh_cueL, rh_cueR )
> # CueRight>CueLeft for the Left Hemisphere.
> # CueLeft>CueRight for the Right Hemisphere
>
> cm <- c(-1, 1, 1, -1)
> dim(cm) <- c(2,2)

(That is up to sign what Helmert contrasts give you.)

> roi.aov <- aov( roi ~ (Cue*Hemisphere) + Error(Subject/(Cue*Hemisphere)),
> contrasts=cm, data=roiDataframe)
> print(summary(roi.aov))
> ########################################
>
> but the results of these two aov commands are identical.  Is it the case that 
> the 2x2 design matrix is always going to give the same F values for the 
> interaction regardless of the contrast direction?

Yes, as however you code the design (via `contrasts') you are fitting the 
same subspaces.  Not sure what you mean by `contrast direction', though.

However, you have not specified `contrasts' correctly:

contrasts: A list of contrasts to be used for some of the factors in
           the formula.

and cm is not a list, and an interaction is not a factor.

> OR, is there some way to get a summary output for the contrasts that is 
> not available from the print method?

For more than two levels, yes: see `split' under ?summary.aov.
Also, see se.contrasts which allows you to find the standard error for any 
contrast.

For the fixed-effects model you can use summary.lm:

> fit <- aov(roi ~ Subject + Cue * Hemisphere, data = roiDataframe)
> summary(fit)
                Df  Sum Sq Mean Sq F value Pr(>F)
Subject         7  4.2009  0.6001  0.5756 0.7677
Cue             1  0.2165  0.2165  0.2076 0.6533
Hemisphere      1  0.0197  0.0197  0.0189 0.8920
Cue:Hemisphere  1  0.0579  0.0579  0.0555 0.8161
Residuals      21 21.8969  1.0427
> summary.lm(fit)

Call:
aov(formula = roi ~ Subject + Cue * Hemisphere, data = roiDataframe)

Residuals:
     Min      1Q  Median      3Q     Max
-1.7893 -0.4197  0.1723  0.5868  1.3033

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)
[...]
Cue1             -0.08224    0.18051  -0.456    0.653
Hemisphere1       0.02482    0.18051   0.137    0.892
Cue1:Hemisphere1 -0.04252    0.18051  -0.236    0.816

where the F values are the squares of the t values.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Thu Mar 10 09:21:18 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Mar 2005 09:21:18 +0100
Subject: [R] Dropping coloumns while redaing dtaa from text file.
In-Reply-To: <1408.10.11.11.2.1110402128.squirrel@gpo.iitb.ac.in>
References: <1408.10.11.11.2.1110402128.squirrel@gpo.iitb.ac.in>
Message-ID: <x2sm33q5c1.fsf@biostat.ku.dk>

"Upasna Sharma" <upasna at iitb.ac.in> writes:

> Hi
> 
> I have a huge text file and .dat file from which I want to read data. I do
> not need all the columns in the files. I want to extract only some columns
> from the .txt file or the .dat file, because reading the entire file is
> becoming very difficult due to memory issues. Is it possible to extract a
> few columns from .txt or .dat file while reading the data in R?

You're not sayin what tools you are using to read in the first place,
but notice that the colClasses argument to read.table can have NULL
elements. 


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Thu Mar 10 09:28:22 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 10 Mar 2005 08:28:22 +0000 (GMT)
Subject: [R] Dropping coloumns while redaing dtaa from text file.
In-Reply-To: <1408.10.11.11.2.1110402128.squirrel@gpo.iitb.ac.in>
References: <1408.10.11.11.2.1110402128.squirrel@gpo.iitb.ac.in>
Message-ID: <Pine.LNX.4.61.0503100825390.29906@gannet.stats>

On Thu, 10 Mar 2005, Upasna Sharma wrote:

> Hi
>
> I have a huge text file and .dat file from which I want to read data. I do
> not need all the columns in the files. I want to extract only some columns
> from the .txt file or the .dat file, because reading the entire file is
> becoming very difficult due to memory issues. Is it possible to extract a
> few columns from .txt or .dat file while reading the data in R?

Yes.

Look at the use of NULL for 'colClasses' (read.table) or 'what' (scan), 
and also 'flush'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ronny.klein at wiwi.uni-halle.de  Thu Mar 10 09:32:55 2005
From: ronny.klein at wiwi.uni-halle.de (Ronny Klein)
Date: Thu, 10 Mar 2005 09:32:55 +0100
Subject: [R] function in order to plot the same graph to postscript and pdf
In-Reply-To: <20050309193513.1c6b3d11.Achim.Zeileis@wu-wien.ac.at>
References: <200503091457.28079.ronny.klein@wiwi.uni-halle.de>
	<200503091821.41428.ronny.klein@wiwi.uni-halle.de>
	<20050309193513.1c6b3d11.Achim.Zeileis@wu-wien.ac.at>
Message-ID: <200503100932.55426.ronny.klein@wiwi.uni-halle.de>

> I guess you would want eval(MYPLOT) there?
>
> But the function above works if you say
>   plot.both(myplot = expression(plot(x)), filename = "foo")
> and that is what I said above: set myplot = expression(plot(x)).
> Z

My syntax in the example was a little bit messed, sorry for that.

However Gabor Grothendieck's reply has brought me to the solution. The 
following function does the job right:

print.both <- function(myplot, filename){
     pdf(file=paste(filename, ".pdf", sep=""))
     postscript(file=paste(filename, ".eps", sep=""))
    dev.control(displaylist="enable")
    myplot
    dev.copy(which=dev.next())
    graphics.off()
}

The dev.control(displaylist="enable") is necessary here because only then R 
does record the plot and dev.copy can be used.

So, thank you all for your help.

Ronny



From dimitris.rizopoulos at med.kuleuven.ac.be  Thu Mar 10 10:14:55 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Thu, 10 Mar 2005 10:14:55 +0100
Subject: [R] Flattening a list of data frames
References: <422F5778.50509@cs.umd.edu>
Message-ID: <012301c52551$9fbd7720$0540210a@www.domain>

try this:

do.call("rbind", z)

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Lorin Hochstein" <lorin at cs.umd.edu>
To: <R-help at stat.math.ethz.ch>
Sent: Wednesday, March 09, 2005 9:07 PM
Subject: [R] Flattening a list of data frames


> Hello all,
>
> Simple version of my problem:
>
> I've got a list of data frames, where each data frame has the same 
> number of columns and the same column names. I'd like to flatten the 
> list into one large data frame. Is there an easy way to do this?
>
> Quick example code:
> a <- data.frame(x=c(1,2,3),y=c(5,7,9)
> b <- data.frame(x=c(2,4,7,9),y=c(2,3,5,4))
> z <- list(a,b)
>
> # Do "something" to get the equivalent of  rbind(z[[1]],z[[2]])
> ???
>
> More complex version:
>
> My data is in this format because it's the output of a "by" statment 
> that looks like this:
>
> y <- by(d,list(d$StudentID,d$Assignment),gapfun)
>
> (where gapfun is a function I've defined that takes a data frame and 
> returns another data frame).
>
> What I would like is to do is transform y into a data frame that has 
> columns "StudentID", "Assignment", and the columns in the data frame 
> returned by gapfun.
>
> Any ideas?
>
> Lorin
>
> ----------
> Lorin Hochstein
> Graduate Research Assistant
> Experimental Software Engineering Group
> Computer Science Department
> University of Maryland, College Park
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From p.dalgaard at biostat.ku.dk  Thu Mar 10 10:33:32 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Mar 2005 10:33:32 +0100
Subject: [R] contrast matrix for aov
In-Reply-To: <Pine.LNX.4.61.0503100722330.29906@gannet.stats>
References: <422F8EDE.2030009@gmail.com>
	<Pine.LNX.4.61.0503100722330.29906@gannet.stats>
Message-ID: <x2fyz3q1zn.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> On Wed, 9 Mar 2005, Darren Weber wrote:
> 
> > How do we specify a contrast interaction matrix for an ANOVA model?
> >
> > We have a two-factor, repeated measures design, with
> 
> Where does `repeated measures' come into this?  You appear to have
> repeated a 2x2 experiment in each of 8 blocks (subjects).  Such a
> design is usually analysed with fixed effects.  (Perhaps you averaged
> over repeats in the first few lines of your code?)

Actually, that's not "usual" in SAS (and not SPSS either, I believe)
in things like

proc glm;
        model y1-y4= ;
        repeated row 2 col 2;

[Not that SAS/SPSS is the Gospel, but they do tend to set the
terminology in these matters.]

There you'd get the analysis split up as analyses of three contrasts
corresponding to the main effects and interaction, c(-1,-1,1,1),
c(-1,1,-1,1), and c(-1,1,1,-1) in the 2x2 case (up to scale and sign).
In the 2x2 case, this corresponds exactly to the 4-stratum model
row*col + Error(block/(row*col)).

(It is interesting to note that it is still not the optimal analysis
for arbitrary covariance patterns because dependence between contrasts
is not utilized - it is basically assumed to be absent.)

With more than two levels, you get the additional complications of
sphericity testing and GG/HF epsilons and all that.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From AAmoros at imim.es  Thu Mar 10 10:40:00 2005
From: AAmoros at imim.es (AMOROS NAVARRO, ALEX)
Date: Thu, 10 Mar 2005 10:40:00 +0100
Subject: [R] Interval censoring in Survival analysis
Message-ID: <66373AD054447F47851FCC5EB49B36116CF155@basquet.imim.es>

Hi,

I would like to know if R programme allows doing different kinds of censoring in his last version. What kind of package should I use and is this censoring applicable to parametric and semi-parametric(Cox) models?

Thanks,
?lex.



From pallier at lscp.ehess.fr  Thu Mar 10 10:43:15 2005
From: pallier at lscp.ehess.fr (Christophe Pallier)
Date: Thu, 10 Mar 2005 10:43:15 +0100
Subject: [R] contrast matrix for aov
In-Reply-To: <Pine.LNX.4.61.0503100722330.29906@gannet.stats>
References: <422F8EDE.2030009@gmail.com>
	<Pine.LNX.4.61.0503100722330.29906@gannet.stats>
Message-ID: <423016B3.9090301@lscp.ehess.fr>


Prof Brian Ripley wrote:

>> On Wed, 9 Mar 2005, Darren Weber wrote:
>>
>> We have a two-factor, repeated measures design, with
>
>
> Where does `repeated measures' come into this?  You appear to have 
> repeated a 2x2 experiment in each of 8 blocks (subjects).  Such a 
> design is usually analysed with fixed effects.  (Perhaps you averaged 
> over repeats in the first few lines of your code?)
>
>>
>> roi.aov <- aov(roi ~ (Cue*Hemisphere) + 
>> Error(Subject/(Cue*Hemisphere)), data=roiDataframe)
>
>
> I think the error model should be Error(Subject).  In what sense are 
> `Cue' and `Cue:Hemisphere' random effects nested inside `Subject'?
>

I do not understand this, and I think I am probably not the only one. 
That is why I would be grateful if you could give a bit more information.

My understanding is that the fixed factors Cue and Hemisphere are 
crossed with the random factor Subject (in other words, Cue and 
Hemisphere are within-subjects factors, and this is probably why Darren 
called it a "repeated measure" design).

In this case, it seems to me from the various textbooks I read on Anova, 
that the appropriate MS to  test the interaction Cue:Hemisphere is 
Subject:Cue:Hemisphere (with 7 degress of freedom, as there are 8 
independent subjects). 

If you input Error(Subject/(Cue*Hemisphere)) in the aov formula, then 
the test for the interaction indeed uses the Subject:Cue:Hemisphere 
source of variation in demoninator. This fits with the ouput of other 
softwares.

If you include only 'Subjet', then the test for the interaction has 21 
degrees of Freedom, and I do not understand what this tests.

I apologize in if my terminology is not accurate.  But I hope you can 
clarify what is wrong with the Error(Subject/(Cue*Hemisphere)) term,
or maybe just point us to the relevant textbooks.

Thanks in advance,

Christophe Pallier






> Let me fake some `data':
>
> set.seed(1); roiValues <- rnorm(32)
> subjectlabels <- paste("V"1:8, sep = "")
> options(contrasts = c("contr.helmert", "contr.poly"))
> roi.aov <- aov(roi ~ Cue*Hemisphere + Error(Subject), data=roiDataframe)
>
>> roi.aov
>
>
> Call:
> aov(formula = roi ~ Cue * Hemisphere + Error(Subject), data = 
> roiDataframe)
>
> Grand Mean: 0.1165512
>
> Stratum 1: Subject
>
> Terms:
>                 Residuals
> Sum of Squares   4.200946
> Deg. of Freedom         7
>
> Residual standard error: 0.7746839
>
> Stratum 2: Within
>
> Terms:
>                       Cue Hemisphere Cue:Hemisphere Residuals
> Sum of Squares   0.216453   0.019712       0.057860 21.896872
> Deg. of Freedom         1          1              1        21
>
> Residual standard error: 1.021131
> Estimated effects are balanced
>
> Note that all the action is in one stratum, and the SSQs are the same as
>
> aov(roi ~ Subject + Cue * Hemisphere, data = roiDataframe)
>
> (and also the same as for your fit).
>
>> print(summary(roi.aov))
>
>
> It auto-prints, so you don't need print().
>
>> ########################################
>>
>>
>> I've tried to create a contrast matrix like this:
>>
>> cm <- contrasts(roiDataframe$Cue)
>>
>> which gives the main effect contrasts for the Cue factor.  I really 
>> want to specify the interaction contrasts, so I tried this:
>>
>> ########################################
>> # c( lh_cueL, lh_cueR, rh_cueL, rh_cueR )
>> # CueRight>CueLeft for the Left Hemisphere.
>> # CueLeft>CueRight for the Right Hemisphere
>>
>> cm <- c(-1, 1, 1, -1)
>> dim(cm) <- c(2,2)
>
>
> (That is up to sign what Helmert contrasts give you.)
>
>> roi.aov <- aov( roi ~ (Cue*Hemisphere) + 
>> Error(Subject/(Cue*Hemisphere)),
>> contrasts=cm, data=roiDataframe)
>> print(summary(roi.aov))
>> ########################################
>>
>> but the results of these two aov commands are identical.  Is it the 
>> case that the 2x2 design matrix is always going to give the same F 
>> values for the interaction regardless of the contrast direction?
>
>
> Yes, as however you code the design (via `contrasts') you are fitting 
> the same subspaces.  Not sure what you mean by `contrast direction', 
> though.
>
> However, you have not specified `contrasts' correctly:
>
> contrasts: A list of contrasts to be used for some of the factors in
>           the formula.
>
> and cm is not a list, and an interaction is not a factor.
>
>> OR, is there some way to get a summary output for the contrasts that 
>> is not available from the print method?
>
>
> For more than two levels, yes: see `split' under ?summary.aov.
> Also, see se.contrasts which allows you to find the standard error for 
> any contrast.
>
> For the fixed-effects model you can use summary.lm:
>
>> fit <- aov(roi ~ Subject + Cue * Hemisphere, data = roiDataframe)
>> summary(fit)
>
>                Df  Sum Sq Mean Sq F value Pr(>F)
> Subject         7  4.2009  0.6001  0.5756 0.7677
> Cue             1  0.2165  0.2165  0.2076 0.6533
> Hemisphere      1  0.0197  0.0197  0.0189 0.8920
> Cue:Hemisphere  1  0.0579  0.0579  0.0555 0.8161
> Residuals      21 21.8969  1.0427
>
>> summary.lm(fit)
>
>
> Call:
> aov(formula = roi ~ Subject + Cue * Hemisphere, data = roiDataframe)
>
> Residuals:
>     Min      1Q  Median      3Q     Max
> -1.7893 -0.4197  0.1723  0.5868  1.3033
>
> Coefficients:
>                  Estimate Std. Error t value Pr(>|t|)
> [...]
> Cue1             -0.08224    0.18051  -0.456    0.653
> Hemisphere1       0.02482    0.18051   0.137    0.892
> Cue1:Hemisphere1 -0.04252    0.18051  -0.236    0.816
>
> where the F values are the squares of the t values.
>
>



From Ted.Harding at nessie.mcc.ac.uk  Thu Mar 10 10:47:25 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 10 Mar 2005 09:47:25 -0000 (GMT)
Subject: [R] from long/lat to UTM
In-Reply-To: <422FF155.5030506@oomvanlieshout.net>
Message-ID: <XFMail.050310094725.Ted.Harding@nessie.mcc.ac.uk>

On 10-Mar-05 Sander Oom wrote:
> Hi Yyan,
> 
> The proj4R package by Roger Bivand will allow you to project data in 
> many ways and directions.
> 
> http://spatial.nhh.no/R/Devel/proj4R-pkg.pdf
> 
> It uses the proj libraries from:
> 
> http://www.remotesensing.org/proj/
> 
> Not sure where you would derive the time zone!
> 
> Good luck,
> 
> Sander.

While there is a longitude-based "nominal" time-zone
structure (0deg E is the centre of Zone 0 which extends
for 7.5deg either side; successive time-zones move round
by 15deg), this does not apply cleanly to the time-shifts
adopted in different places for local time.

A World map of regions with different local-time offsets
is a crazy patchwork, with all sorts of contradictory
looking regions. For instance, the "-0700" region of
the USA extends from approx -0830 to approx -0620,
covering over 2 hours, and parts of "-0800" touch the
-0700 line and are more than 0100 East of parts of "-0700".
Even worse can be found over the Indian/Central Asian
and Malaysian parts of the world, where time-shifts
of 30 miniutes are also frequent (and, according to my
Atlas, one country, Nepal, has "5&2/3" i.e. +0540!).

As Sander says, "Not sure where you would derive the time zone!".

Unless you can refer a (long,lat) position to a look-up
table, you can't predict what the zone will be to less
the 1 hour (except of course for the "nominal" time-zones
by 15deg sectors). I've never encountered a "digital"
version of such a table (my Atlas must be based on one,
though).

Best wishes,
Ted.

> yyan liu wrote:
>> Hi:
>>   Is there any function in R which can convert the
>> long/lat to UTM(Universal Transverse Mercator)?
>>   There are quite a few converters on Internet.
>> However, the interface is designed as input->output
>> which I can not convert lots of locations at the same
>> time.
>>   Another question is whether there is a function in R
>> which can tell the time zone from the location's
>> lat/long?
>>   Thank you!
>> 
>> liu
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>> 
>> 
> 
> -- 
> --------------------------------------------
> Dr. Sander P. Oom
> Animal, Plant and Environmental Sciences,
> University of the Witwatersrand
> Private Bag 3, Wits 2050, South Africa
> Tel (work)      +27 (0)11 717 64 04
> Tel (home)      +27 (0)18 297 44 51
> Fax             +27 (0)18 299 24 64
> Email   sander at oomvanlieshout.net
> Web     www.oomvanlieshout.net/sander
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 10-Mar-05                                       Time: 09:47:25
------------------------------ XFMail ------------------------------



From ripley at stats.ox.ac.uk  Thu Mar 10 11:07:22 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 10 Mar 2005 10:07:22 +0000 (GMT)
Subject: [R] contrast matrix for aov
In-Reply-To: <423016B3.9090301@lscp.ehess.fr>
References: <422F8EDE.2030009@gmail.com>
	<Pine.LNX.4.61.0503100722330.29906@gannet.stats>
	<423016B3.9090301@lscp.ehess.fr>
Message-ID: <Pine.LNX.4.61.0503100957340.11562@gannet.stats>

On Thu, 10 Mar 2005, Christophe Pallier wrote:

>
> Prof Brian Ripley wrote:
>
>>> On Wed, 9 Mar 2005, Darren Weber wrote:
>>> 
>>> We have a two-factor, repeated measures design, with
>> 
>> 
>> Where does `repeated measures' come into this?  You appear to have repeated 
>> a 2x2 experiment in each of 8 blocks (subjects).  Such a design is usually 
>> analysed with fixed effects.  (Perhaps you averaged over repeats in the 
>> first few lines of your code?)
>> 
>>> 
>>> roi.aov <- aov(roi ~ (Cue*Hemisphere) + Error(Subject/(Cue*Hemisphere)), 
>>> data=roiDataframe)
>> 
>> 
>> I think the error model should be Error(Subject).  In what sense are `Cue' 
>> and `Cue:Hemisphere' random effects nested inside `Subject'?
>> 
>
> I do not understand this, and I think I am probably not the only one. That is 
> why I would be grateful if you could give a bit more information.
>
> My understanding is that the fixed factors Cue and Hemisphere are crossed 
> with the random factor Subject (in other words, Cue and Hemisphere are 
> within-subjects factors, and this is probably why Darren called it a 
> "repeated measure" design).

The issue is whether the variance of the error really depends on the 
treatment combination, which is what the Error(Subject/(Cue*Hemisphere)) 
assumes.  With that model

Error: Subject:Cue
           Df Sum Sq Mean Sq F value Pr(>F)
Cue        1 0.2165  0.2165  0.1967 0.6708
Residuals  7 7.7041  1.1006

Error: Subject:Hemisphere
            Df Sum Sq Mean Sq F value Pr(>F)
Hemisphere  1 0.0197  0.0197  0.0154 0.9047
Residuals   7 8.9561  1.2794

Error: Subject:Cue:Hemisphere
                Df Sum Sq Mean Sq F value Pr(>F)
Cue:Hemisphere  1 0.0579  0.0579  0.0773  0.789
Residuals       7 5.2366  0.7481

you are assuming different variances for three contrasts.

> In this case, it seems to me from the various textbooks I read on Anova, that 
> the appropriate MS to  test the interaction Cue:Hemisphere is 
> Subject:Cue:Hemisphere (with 7 degress of freedom, as there are 8 independent 
> subjects). 
> If you input Error(Subject/(Cue*Hemisphere)) in the aov formula, then the 
> test for the interaction indeed uses the Subject:Cue:Hemisphere source of 
> variation in demoninator. This fits with the ouput of other softwares.
>
> If you include only 'Subjet', then the test for the interaction has 21 
> degrees of Freedom, and I do not understand what this tests.

It uses a common variance for all treatment combinations.

> I apologize in if my terminology is not accurate.  But I hope you can clarify 
> what is wrong with the Error(Subject/(Cue*Hemisphere)) term,
> or maybe just point us to the relevant textbooks.

Nothing is `wrong' with it, it just seems discordant with the description
of the experiment.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Mar 10 11:38:20 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 10 Mar 2005 10:38:20 +0000 (GMT)
Subject: [R] contrast matrix for aov
In-Reply-To: <x2fyz3q1zn.fsf@biostat.ku.dk>
References: <422F8EDE.2030009@gmail.com>
	<Pine.LNX.4.61.0503100722330.29906@gannet.stats>
	<x2fyz3q1zn.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.61.0503101028001.15737@gannet.stats>

On Thu, 10 Mar 2005, Peter Dalgaard wrote:

> Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
>
>> On Wed, 9 Mar 2005, Darren Weber wrote:
>>
>>> How do we specify a contrast interaction matrix for an ANOVA model?
>>>
>>> We have a two-factor, repeated measures design, with
>>
>> Where does `repeated measures' come into this?  You appear to have
>> repeated a 2x2 experiment in each of 8 blocks (subjects).  Such a
>> design is usually analysed with fixed effects.  (Perhaps you averaged
>> over repeats in the first few lines of your code?)
>
> Actually, that's not "usual" in SAS (and not SPSS either, I believe)
> in things like
>
> proc glm;
>        model y1-y4= ;
>        repeated row 2 col 2;
>
> [Not that SAS/SPSS is the Gospel, but they do tend to set the
> terminology in these matters.]

That seems to be appropriate only if the four treatments are done in a 
particular order (`repeated') and one expects correlations in the 
responses.  However, here the measurements seem to have been averages of 
replications.

It may be "usual" to (mis?)specify experiments in SAS that way: I don't 
know what end users do, but it is not the only way possible in SAS.

> There you'd get the analysis split up as analyses of three contrasts
> corresponding to the main effects and interaction, c(-1,-1,1,1),
> c(-1,1,-1,1), and c(-1,1,1,-1) in the 2x2 case (up to scale and sign).
> In the 2x2 case, this corresponds exactly to the 4-stratum model
> row*col + Error(block/(row*col)).
>
> (It is interesting to note that it is still not the optimal analysis
> for arbitrary covariance patterns because dependence between contrasts
> is not utilized - it is basically assumed to be absent.)

It also assumes that there is a difference between variances of the 
contrasts, that is there is either correlation between results or a 
difference in variances under different treatments.  Nothing in the 
description led me to expect either of those, but I was asking why it was 
specified that way.  (If the variance does differ with the mean then there 
are probably more appropriate analyses.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Rau at demogr.mpg.de  Thu Mar 10 12:14:44 2005
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Thu, 10 Mar 2005 12:14:44 +0100
Subject: [R] Interval censoring in Survival analysis
Message-ID: <8B08A3A1EA7AAC41BE24C750338754E651FFEE@HERMES.demogr.mpg.de>

Hi,
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of AMOROS 
> NAVARRO, ALEX
> 
> I would like to know if R programme allows doing different 
> kinds of censoring in his last version. What kind of package 
> should I use 

Yes, try the following:
library(survival)
?Surv


Best,
Roland


+++++
This mail has been sent through the MPI for Demographic Rese...{{dropped}}



From atcdias at biologia.ufrj.br  Thu Mar 10 12:13:40 2005
From: atcdias at biologia.ufrj.br (=?ISO-8859-1?Q?Andr=E9_Tavares?==?ISO-8859-1?Q?Corr=EAa_Dias?=)
Date: Thu, 10 Mar 2005 08:13:40 -0300 (BRT)
Subject: [R] Structural equation models with R
In-Reply-To: <20050309151325.UJJA1836.tomts16-srv.bellnexxia.net@JohnDesktop8300>
References: <20050309151325.UJJA1836.tomts16-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <1110453220.42302be45cd1f@webmail.biologia.ufrj.br>

Dear John,
Thanks very much! I don?t know how I didn?t see this before. I checked a 
thousand of times....
There is one more thing that I can not understand. What are the possible 
reasons for problems on calculation of confidence interval for RMSEA? For the 
same model I sent before (after correction of the variable name) the lower CI 
output was NA:

Model Chisquare =  10.824   Df =  13 Pr(>Chisq) = 0.62558
 Goodness-of-fit index =  0.91656
 Adjusted goodness-of-fit index =  0.76895
 RMSEA index =  0   90 % CI: (NA, 0.15652)
 BIC =  -60.425

I have other models with the same behavior, even when the estimative of RMSEA 
is different from zero.

Model Chisquare =  15.165   Df =  14 Pr(>Chisq) = 0.367
 Goodness-of-fit index =  0.89038
 Adjusted goodness-of-fit index =  0.71811
 RMSEA index =  0.053558   90 % CI: (NA, 0.19141)
 BIC =  -61.564

Thanks and all the best.
Andr?

-------------------------------
Andr? Tavares Corr?a Dias
Laborat?rio de Ecologia Vegetal
Departamento de Ecologia - IB
Universidade Federal do Rio de Janeiro
Ilha do Fund?o, CCS
Rio de Janeiro, RJ. Brasil
CEP 21941-590    CP 68020
Tel. (21)2562-6377



From =?iso-8859-1?Q?Micha=EBl?=  Thu Mar 10 12:12:39 2005
From: =?iso-8859-1?Q?Micha=EBl?= (=?iso-8859-1?Q?Micha=EBl?=)
Date: Thu, 10 Mar 2005 12:12:39 +0100
Subject: [R] multiple comparisons for lme using multcomp
Message-ID: <5.0.2.1.2.20050310121149.02af74d0@utinam.univ-fcomte.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050310/989a59b1/attachment.pl

From midnightsun at blueyonder.co.uk  Thu Mar 10 12:34:34 2005
From: midnightsun at blueyonder.co.uk (midnightsun@blueyonder.co.uk)
Date: Thu, 10 Mar 2005 11:34:34 -0000 (GMT)
Subject: [R] Re: plotting several series on the sames axes
Message-ID: <16326.195.188.213.35.1110454474.squirrel@195.188.213.35>

Many thanks to all those who replied to my 'simple' query, all of which
have been posted to the list.



From Achim.Zeileis at wu-wien.ac.at  Thu Mar 10 13:14:01 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Thu, 10 Mar 2005 13:14:01 +0100
Subject: [R] about kpss.test()
In-Reply-To: <20050309193210.57536.qmail@web30008.mail.mud.yahoo.com>
References: <20050309194643.2c92cf6d.Achim.Zeileis@wu-wien.ac.at>
	<20050309193210.57536.qmail@web30008.mail.mud.yahoo.com>
Message-ID: <20050310131401.099b7334.Achim.Zeileis@wu-wien.ac.at>

On Wed, 9 Mar 2005 14:32:09 -0500 (EST) Weiguang Shi wrote:

>  --- Achim Zeileis <Achim.Zeileis at wu-wien.ac.at>
> wrote: 
> > > First of all, could you tell me what the "KPSS
> > Level" 
> > > in the output of the test means?
> Thanks. But I meant to also ask about the number after
> that, e.g., 
>     KPSS Level = 0.0027

If you wouldn't have deleted my reply to that question, you could still
see the answer! It was:

  <quote>
  It means that you tested for level stationarity and gives you the test
  statistic.
  </quote>

Note the second half of the sentence.

> > Please check the references of kpss.test or any book
> > on economectric
> > time series analysis for which alternatives the KPSS
> > test was designed.
> Will soon do.
> 
> > Hint: it's not designed for detecting cyclical
> > variations.
> OK. I guess there must be some pre-requisite on the 
> data before kpss-ing it.

In particular it means: There are infinitely many conceivable ways of
deviation from stationarity and the KPSS test is only good at detecting
certain kinds of deviation (which do not include cyclical variations).
Z



From p.dalgaard at biostat.ku.dk  Thu Mar 10 13:13:14 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Mar 2005 13:13:14 +0100
Subject: [R] multiple comparisons for lme using multcomp
In-Reply-To: <5.0.2.1.2.20050310121149.02af74d0@utinam.univ-fcomte.fr>
References: <5.0.2.1.2.20050310121149.02af74d0@utinam.univ-fcomte.fr>
Message-ID: <x2br9ru2at.fsf@biostat.ku.dk>

Micha?l Coeurdassier <michael.coeurdassier at univ-fcomte.fr> writes:

> summary(csimtest(vect,vcov(lm1),cmatrix=contrMat(table(treatment),type="Tukey"),df=59))
....
> Coefficients:
>                Estimate t value Std.Err. p raw p Bonf p adj
> Al800-Al100     -2.253 -10.467    0.213 0.000  0.000 0.000
> Al600-Al100     -2.185 -10.389    0.207 0.000  0.000 0.000
> Al400-Al100     -2.036  -9.850    0.210 0.000  0.000 0.000
> Al200-Al100     -1.712  -8.051    0.215 0.000  0.000 0.000
> control-Al100   -1.487  -7.243    0.205 0.000  0.000 0.000
> control-Al800    0.767  -5.282    0.143 0.000  0.000 0.000
> control-Al600    0.698  -5.072    0.148 0.000  0.000 0.000
> control-Al400    0.550  -4.160    0.155 0.000  0.001 0.001
> Al800-Al200     -0.542  -3.488    0.141 0.001  0.006 0.006
> Al600-Al200     -0.473  -3.191    0.140 0.002  0.014 0.012
> Al400-Al200     -0.325  -2.267    0.147 0.027  0.135 0.110
> control-Al200    0.225  -1.593    0.132 0.116  0.466 0.341
> Al800-Al400     -0.217  -1.475    0.152 0.145  0.466 0.341
> Al600-Al400     -0.149  -1.064    0.138 0.292  0.583 0.466
> Al800-Al600     -0.068  -0.449    0.145 0.655  0.655 0.655
> 
>  > #a friend told me that it is possible to do multiple comparisons for lme 
> in a simplest way, i.e. :
>  > anova(lm1,L=c("treatmentcontrol"=1,"treatmentAl200"=-1))
> F-test for linear combination(s)
>    treatmentAl200 treatmentcontrol
>                -1                1
>    numDF denDF  F-value p-value
> 1     1    12 2.538813  0.1371
> 
>  > anova(lm1,L=c("treatmentcontrol"=1,"treatmentAl400"=-1))
> F-test for linear combination(s)
>    treatmentAl400 treatmentcontrol
>                -1                1
>    numDF denDF  F-value p-value
> 1     1    12 17.30181  0.0013
> 
>  > anova(lm1,L=c("treatmentcontrol"=1,"treatmentAl600"=-1))
> F-test for linear combination(s)
>    treatmentAl600 treatmentcontrol
>                -1                1
>    numDF denDF  F-value p-value
> 1     1    12 25.72466   3e-04
> 
>  > anova(lm1,L=c("treatmentcontrol"=1,"treatmentAl800"=-1))
> F-test for linear combination(s)
>    treatmentAl800 treatmentcontrol
>                -1                1
>    numDF denDF F-value p-value
> 1     1    12 27.9043   2e-04
> 
>  > # however, p values are different that those obtained above. Is this way 
> OK or not?


Notice that in all cases, the F-value is exactly the square of the
t-value from Csimtest. The main difference is that you have claimed
that the vcov matrix has 59 DF, whereas the lme analysis says 12. I'd
suspect the latter to be (more) correct. Apart from that, notice that
the "L" approach at best gives you the "p raw" value, i.e., it is
uncorrected for multiple testing.


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From lavanya_ldb2000 at yahoo.co.in  Thu Mar 10 13:27:32 2005
From: lavanya_ldb2000 at yahoo.co.in (Lakshmi Dhevi Baskar)
Date: Thu, 10 Mar 2005 04:27:32 -0800 (PST)
Subject: [R] R-help:loading data from text file and viewing it in persp
Message-ID: <20050310122732.20146.qmail@web8502.mail.in.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050310/9fa90000/attachment.pl

From ggrothendieck at myway.com  Thu Mar 10 13:36:58 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 10 Mar 2005 12:36:58 +0000 (UTC)
Subject: [R] how modify object in parent.env
References: <C698D707214E6F4AB39AB7096C3DE5A58FF184@phost015.EVAFUNDS.intermedia.net>
Message-ID: <loom.20050310T133216-392@post.gmane.org>

[I sent this last night but it does not appear to have shown up
so this is second attempt.  Apologies if this gets posted twice.]



The search for the left hand side of the <<- starts in 
the parent while search for the right side is in the
current environment so: 

x <- 1:3
local( for (i in seq(along = x)) { x <- 99; x[i] <<- x } )

Its important not to define the local x prior seq(along = x)
so that that seq(along=x) refers to the x in the parent.  If
you do define it first and therefore need to force reference 
to the parent x use get or eval in the seq:

  seq(along = get("x", parent.frame()))

Actually, it may be less confusing to just use a different,
but related, variable name.  If you don't like x0, perhaps
x. would be ok:

x <- 1:3
local( { x. <- 99; for (i in seq(along = x)) x[i] <<- x. } )



Vadim Ogranovich <vograno <at> evafunds.com> writes:

: 
: Thank you to Gabor and Mark Schwartz for the answers. Both of them
: solved the problem I posted, but my actual problem, as I now see, is a
: little bit more involved. Let me try again.
: 
: I have a vector 'x'. I want to compute its entries in a loop (yes, I
: know...). Say
: 
: x = seq(3)
: 
: for (i in seq(length(x)) {
: 	x0 = someValue
: 	x[i] = x0
: } 
: 
: There are two problems with the above code:
: 1. x0 pollutes the global envirnoment (not to mention possible
: over-write of an existing x0). Therefore I thought I'd wrap it with
: local().
: 2. x0 is not a good name from a readability perspective. I'd rather call
: it x to emphasize it's an entry in an outer vector 'x'. (In this small
: example it doesn't really matter, but I have much more involved scripts
: where consistent naming is important)
: 
: Gabor's solution solves 1 but not 2. Maybe there is a simple way around
: this restriction?
: 
: Thanks,
: Vadim
: 
: > -----Original Message-----
: > From: r-help-bounces <at> stat.math.ethz.ch 
: > [mailto:r-help-bounces <at> stat.math.ethz.ch] On Behalf Of Gabor 
: > Grothendieck
: > Sent: Tuesday, March 08, 2005 4:06 PM
: > To: r-help <at> stat.math.ethz.ch
: > Subject: Re: [R] how modify object in parent.env
: > 
: > 
: > You can use "<<-" like this:
: > 
: > x <- 1:3
: > local(x[1] <<- x[1]+1)
: > 
: > Vadim Ogranovich <vograno <at> evafunds.com> writes:
: > 
: > : 
: > : Assign() re-binds the value, not modifies it (the latter is what I
: > : needed)
: > : 
: > : > -----Original Message-----
: > : > From: McGehee, Robert [mailto:Robert.McGehee <at> 
: > geodecapital.com]
: > : > Sent: Tuesday, March 08, 2005 3:48 PM
: > : > To: Vadim Ogranovich; r-help <at> stat.math.ethz.ch
: > : > Subject: RE: [R] how modify object in parent.env
: > : >
: > : > This isn't an environment problem. Assigning something to a
: > : > get call doesn't make any sense. Use assign.
: > : >
: > : > > a <- 5
: > : > > get("a") <- 10
: > : > Error: couldn't find function "get<-"
: > : >
: > : > And from the ?assign help page, you can pick what environment
: > : > you want to make the assignment. Just pick the parent environment.
: > : >
: > : >
: > : > -----Original Message-----
: > : > From: Vadim Ogranovich [mailto:vograno <at> evafunds.com]
: > : > Sent: Tuesday, March 08, 2005 6:36 PM
: > : > To: r-help <at> stat.math.ethz.ch
: > : > Subject: [R] how modify object in parent.env
: > : >
: > : >
: > : > Hi,
: > : >
: > : > Is it possible to modify an object in the parent.env (as 
: > opposed to
: > : > re-bind)? Here is what I tried:
: > : >
: > : > > x = 1:3
: > : > # try to modify the first element of x from within a new 
: > environment
: > : > > local(get("x", parent.env(environment()))[1] <- NA)
: > : > Error in eval(expr, envir, enclos) : Target of assignment 
: > expands to
: > : > non-language object
: > : >
: > : > # On the other hand retrieval works just fine
: > : > > local(get("x", parent.env(environment()))[1])
: > : > [1] 1
: > : >
: > : > Thanks,
: > : > Vadim
: > : >
: > : > ______________________________________________
: > : > R-help <at> stat.math.ethz.ch mailing list
: > : > https://stat.ethz.ch/mailman/listinfo/r-help
: > : > PLEASE do read the posting guide!
: > : > http://www.R-project.org/posting-guide.html
: > : >
: > : 
: > : ______________________________________________
: > : R-help <at> stat.math.ethz.ch mailing list
: > : https://stat.ethz.ch/mailman/listinfo/r-help
: > : PLEASE do read the posting guide! 
: > http://www.R-project.org/posting-guide.html
: > : 
: > :
: > 
: > ______________________________________________
: > R-help <at> stat.math.ethz.ch mailing list
: > https://stat.ethz.ch/mailman/listinfo/r-help
: > PLEASE do read the posting guide! 
: > http://www.R-project.org/posting-guide.html
: >
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://stat.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From nestor.fernandez at ufz.de  Thu Mar 10 14:00:44 2005
From: nestor.fernandez at ufz.de (Nestor Fernandez)
Date: Thu, 10 Mar 2005 14:00:44 +0100
Subject: [R] Gap statistic
Message-ID: <423044FC.1080604@ufz.de>

Dear All,

I need to calculate the optimal number of clusters for a classification based on a large number of observations (tens of thousands).
Thibshirani et al. proposed the gap statistic for this purpose. I tried the R-code developed by R. J?rnsten but R hangs with such amount of data ().
Is it available any other (optimised) code?
Any help would be appreciated, including suggestions about other alternatives for the selection of an optimal number of cluster from large datasets.

Thanks, 


N?stor Fern?ndez, PhD.

Department of Ecological Modelling
UFZ - Centre for Environmental Research
PF 500136, DE-04301, Leipzig, Germany.
Tel: +49 341-2352034
E-mail: nestor.fernandez at ufz.de



From christian.kamenik at ips.unibe.ch  Thu Mar 10 14:44:48 2005
From: christian.kamenik at ips.unibe.ch (Christian Kamenik)
Date: Thu, 10 Mar 2005 14:44:48 +0100
Subject: [R] Gregmisc
Message-ID: <42304F50.9070109@ips.unibe.ch>

Dear all,

I use R 2.0.1 on Windows XP professional. When I want to load the 
'Gregmisc' library I get the following error message:

Error in library(pkg, character.only = TRUE) :  'gregmisc' is not a 
valid package -- installed < 2.0.0?

Can anybody tell me what's wrong with this package?

Cheers, Christian



From ccleland at optonline.net  Thu Mar 10 14:51:03 2005
From: ccleland at optonline.net (Chuck Cleland)
Date: Thu, 10 Mar 2005 08:51:03 -0500
Subject: [R] Gregmisc
In-Reply-To: <42304F50.9070109@ips.unibe.ch>
References: <42304F50.9070109@ips.unibe.ch>
Message-ID: <423050C7.3080909@optonline.net>

It's a bundle of 4 packages (gtools, gdata, gmodels, and gplots), so you 
need to load one of those packages.  See the following:

http://cran.us.r-project.org/src/contrib/Descriptions/gregmisc.html

Chuck Cleland

Christian Kamenik wrote:
> Dear all,
> 
> I use R 2.0.1 on Windows XP professional. When I want to load the 
> 'Gregmisc' library I get the following error message:
> 
> Error in library(pkg, character.only = TRUE) :  'gregmisc' is not a 
> valid package -- installed < 2.0.0?
> 
> Can anybody tell me what's wrong with this package?
> 
> Cheers, Christian
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From MSchwartz at MedAnalytics.com  Thu Mar 10 14:54:07 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu, 10 Mar 2005 07:54:07 -0600
Subject: [R] Gregmisc
In-Reply-To: <42304F50.9070109@ips.unibe.ch>
References: <42304F50.9070109@ips.unibe.ch>
Message-ID: <1110462848.7934.7.camel@horizons.localdomain>

On Thu, 2005-03-10 at 14:44 +0100, Christian Kamenik wrote:
> Dear all,
> 
> I use R 2.0.1 on Windows XP professional. When I want to load the 
> 'Gregmisc' library I get the following error message:
> 
> Error in library(pkg, character.only = TRUE) :  'gregmisc' is not a 
> valid package -- installed < 2.0.0?
> 
> Can anybody tell me what's wrong with this package?


gregmisc is a _bundle_, not a package. It is now comprised of four
separate packages:

1. gtools

2. gdata

3. gmodels

4. gplots

You will need to load the particular package that you wish to use or
load all four if you wish.

HTH,

Marc Schwartz



From ggrothendieck at myway.com  Thu Mar 10 14:52:53 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 10 Mar 2005 13:52:53 +0000 (UTC)
Subject: [R] from long/lat to UTM
References: <422FF155.5030506@oomvanlieshout.net>
	<XFMail.050310094725.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <loom.20050310T145039-193@post.gmane.org>

 <Ted.Harding <at> nessie.mcc.ac.uk> writes:
: 
: > yyan liu wrote:
: >> Hi:
: >>   Is there any function in R which can convert the
: >> long/lat to UTM(Universal Transverse Mercator)?
: >>   There are quite a few converters on Internet.
: >> However, the interface is designed as input->output
: >> which I can not convert lots of locations at the same
: >> time.
: >>   Another question is whether there is a function in R
: >> which can tell the time zone from the location's
: >> lat/long?
: >>   Thank you!
: >> 
: >> liu
: 
: On 10-Mar-05 Sander Oom wrote:
: > Hi Yyan,
: > 
: > The proj4R package by Roger Bivand will allow you to project data in 
: > many ways and directions.
: > 
: > http://spatial.nhh.no/R/Devel/proj4R-pkg.pdf
: > 
: > It uses the proj libraries from:
: > 
: > http://www.remotesensing.org/proj/
: > 
: > Not sure where you would derive the time zone!
: > 
: > Good luck,
: > 
: > Sander.
: 
: While there is a longitude-based "nominal" time-zone
: structure (0deg E is the centre of Zone 0 which extends
: for 7.5deg either side; successive time-zones move round
: by 15deg), this does not apply cleanly to the time-shifts
: adopted in different places for local time.
: 
: A World map of regions with different local-time offsets
: is a crazy patchwork, with all sorts of contradictory
: looking regions. For instance, the "-0700" region of
: the USA extends from approx -0830 to approx -0620,
: covering over 2 hours, and parts of "-0800" touch the
: -0700 line and are more than 0100 East of parts of "-0700".
: Even worse can be found over the Indian/Central Asian
: and Malaysian parts of the world, where time-shifts
: of 30 miniutes are also frequent (and, according to my
: Atlas, one country, Nepal, has "5&2/3" i.e. +0540!).
: 
: As Sander says, "Not sure where you would derive the time zone!".
: 
: Unless you can refer a (long,lat) position to a look-up
: table, you can't predict what the zone will be to less
: the 1 hour (except of course for the "nominal" time-zones
: by 15deg sectors). I've never encountered a "digital"
: version of such a table (my Atlas must be based on one,
: though).
: 
: Best wishes,
: Ted.

The fBasics package of the rmetrics project uses the Olsen time
zone data base which does take some of these things into account.



From Kevin.Wang at maths.anu.edu.au  Thu Mar 10 14:56:25 2005
From: Kevin.Wang at maths.anu.edu.au (Kevin Wang)
Date: Fri, 11 Mar 2005 00:56:25 +1100
Subject: [R] Gregmisc
In-Reply-To: <42304F50.9070109@ips.unibe.ch>
References: <42304F50.9070109@ips.unibe.ch>
Message-ID: <42305209.7040104@maths.anu.edu.au>

Hi,

Christian Kamenik wrote:
> Dear all,
> 
> I use R 2.0.1 on Windows XP professional. When I want to load the 
> 'Gregmisc' library I get the following error message:

gregmisc is no longer a package (it used to be a package, NOT a 
library), it is now a "bundle of gtools, gdata, gmodels, gplots"

Cheers,

Kev


-- 
Ko-Kang Kevin Wang
PhD Student
Centre for Mathematics and its Applications
Building 27, Room 1004
Mathematical Sciences Institute (MSI)
Australian National University
Canberra, ACT 0200
Australia

Homepage: http://wwwmaths.anu.edu.au/~wangk/
Ph (W): +61-2-6125-2431
Ph (H): +61-2-6125-7407
Ph (M): +61-40-451-8301



From ligges at statistik.uni-dortmund.de  Thu Mar 10 14:57:57 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 10 Mar 2005 14:57:57 +0100 (CET)
Subject: [R] Gregmisc
In-Reply-To: <42304F50.9070109@ips.unibe.ch>
References: <42304F50.9070109@ips.unibe.ch>
Message-ID: <Pine.LNX.4.58.0503101455340.19818@amadeus.statistik.uni-dortmund.de>



On Thu, 10 Mar 2005, Christian Kamenik wrote:

> Dear all,
> 
> I use R 2.0.1 on Windows XP professional. When I want to load the 
> 'Gregmisc' library I get the following error message:
> 
> Error in library(pkg, character.only = TRUE) :  'gregmisc' is not a 
> valid package -- installed < 2.0.0?
> 
> Can anybody tell me what's wrong with this package?


gregmisc is a package bundle these days.
Probably you have installed the new package bundle (including packages 
such as "gtools") but did not remove your old package "gregmuisc".
 
Try, e.g., library(gtools)

Uwe Ligges


> Cheers, Christian
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From jfox at mcmaster.ca  Thu Mar 10 15:22:04 2005
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 10 Mar 2005 09:22:04 -0500
Subject: [R] Structural equation models with R
In-Reply-To: <1110453220.42302be45cd1f@webmail.biologia.ufrj.br>
Message-ID: <20050310142202.XEBT1919.tomts22-srv.bellnexxia.net@JohnDesktop8300>

Dear Andre,

> -----Original Message-----
> From: Andr? TavaresCorr?a Dias [mailto:atcdias at biologia.ufrj.br] 
> Sent: Thursday, March 10, 2005 6:14 AM
> To: John Fox
> Cc: r-help at stat.math.ethz.ch
> Subject: RE: [R] Structural equation models with R
> 
> Dear John,
> Thanks very much! I don?t know how I didn?t see this before. 
> I checked a thousand of times.... 

(Recall that there was a typo in Andre's model specification.)

> There is one more thing that I 
> can not understand. What are the possible reasons for 
> problems on calculation of confidence interval for RMSEA? For 
> the same model I sent before (after correction of the 
> variable name) the lower CI output was NA:
> 
> Model Chisquare =  10.824   Df =  13 Pr(>Chisq) = 0.62558
>  Goodness-of-fit index =  0.91656
>  Adjusted goodness-of-fit index =  0.76895
>  RMSEA index =  0   90 % CI: (NA, 0.15652)
>  BIC =  -60.425
> 
> I have other models with the same behavior, even when the 
> estimative of RMSEA is different from zero.
> 
> Model Chisquare =  15.165   Df =  14 Pr(>Chisq) = 0.367
>  Goodness-of-fit index =  0.89038
>  Adjusted goodness-of-fit index =  0.71811
>  RMSEA index =  0.053558   90 % CI: (NA, 0.19141)
>  BIC =  -61.564
> 

The method used to get the confidence interval (from Browne and Du Toit,
Multivariate Behavioral Research, 1992, 27:269-300) can produce a lower
bound above the RMSEA estimate or an upper bound below the estimate; when
this happens, the bound is set to NA. One of the nice things about R is that
you can look at the code for a function -- in this case, summary.sem() -- to
see exactly what it does. Take a look at how RMSEA.L and RMSEA.U are
computed.

Regards,
 John



From MSchwartz at MedAnalytics.com  Thu Mar 10 16:21:17 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu, 10 Mar 2005 09:21:17 -0600
Subject: [R] install R redhat rpm as a normal user
In-Reply-To: <a6f83c5a05030916176e99a8e4@mail.gmail.com>
References: <a6f83c5a05030916176e99a8e4@mail.gmail.com>
Message-ID: <1110468078.7934.29.camel@horizons.localdomain>

On Wed, 2005-03-09 at 16:17 -0800, Eric Hu wrote:
> Hi, I wonder if anyone has done this before. I have rpm-build
> installed in my workstation. Thanks.
> 
> Eric


I have not seen any other replies to this, but as far as I know Martyn's
RPMS are not relocatable and a test this morning confirms that.

If you need to install R as a non-root user, you are likely better off
installing from source code. Modify the "--prefix" argument
to ./configure as per the R Administration Manual. For example:

  ./configure --prefix="TargetDir"

where TargetDir is a directory that you have write privileges to.

Then use "make" and "make install" which will then build and install R.

R will be installed in TargetDir (ie. "/home/UserName/R") with a set of
subdirs bin, lib and man. To run R, you would then use:

  TargetDir/bin/R

Or you can create a symlink in /home/UserName/bin to the above file and
then just use "R" to start it.

See the R Administration Manual for more information.

HTH,

Marc Schwartz



From ramasamy at cancer.org.uk  Thu Mar 10 16:29:34 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 10 Mar 2005 15:29:34 +0000
Subject: [R] R: LIST function and LOOPS
In-Reply-To: <42300277.D8ED0580@STATS.uct.ac.za>
References: <42300277.D8ED0580@STATS.uct.ac.za>
Message-ID: <1110468574.7407.19.camel@ndmpc126.orc.ox.ac.uk>

You will need to capture the value of ss at the end of each 'i' as such

z4 <-function(w){

  output <- numeric(w)
  
  for (i in 1:w){
    
    set.seed(i+6)  # this is redundant line
    ss<-0
    
    for (j in 1:5){
      set.seed(j+1+(i-1)*6)
      r<-rnorm(1)
      ss<-ss+r
    }

    output[i] <- ss
  }
  return(output)
}

BTW, I do not think it is a good idea to set.seed() so many times.


To answer you more general question, see if the following is useful.
I am trying to simulate 'n' values from a standard normal distribution
but 'n' is random variable itself.

f <-function(w, lambda=3){
 
  tmp <- list(NULL)
  
  for (i in 1:w){
    n <- 1 + rpois(1, lambda=lambda)  # number of simulation required
    tmp[[ i ]]  <- rnorm(n)
  }

  # flatten the list into a ragged matrix
  out.lengths   <- sapply(tmp, length)
  out           <- matrix( nr=w, nc=max( out.lengths ) )
  rownames(out) <- paste("w =", 1:w)
  for(i in 1:w) out[i, 1:out.lengths[i] ] <- tmp[[i]]

  return(out)
}

f(6, lambda=3)

It is not very elegant but I hope that helps you out somehow.

Regards, Adai



On Thu, 2005-03-10 at 10:16 +0200, Clark Allan wrote:
> hi all
> 
> another simple question.
> 
> i've written a dummy program so that you get the concept. (the code
> could be simplfied such that there are no loops. but lets leave the
> loops in for now.)
> 
> z1<-function(w)
> {
> for (i in 1:w)
> {
> set.seed(i+6)
> ss<-0
> 	for (j in 1:5)
> 	{
> 		set.seed(j+1+(i-1)*6)
> 		r<-rnorm(1)
> 		ss<-ss+r
> 	}
> list(ss=ss)
> }
> }
> check.1<-z1(3)
> check.1
> 
> the results is:
> $ss
> [1] -0.01516304
> 
> 
> what i want is something that looks like this:
> 
> j=1
> $ss
> [1] -2.213343
> 
> j=2
> $ss
> [1] -2.904235
> 
> j=3
> $ss
> [1] -0.01516304
> 
> 
> i know that i could use the print command. (see z2)
> 
> z2<-function(w)
> {
> for (i in 1:w)
> {
> set.seed(i+6)
> ss<-0
> 	for (j in 1:5)
> 	{
> 		set.seed(j+1+(i-1)*6)
> 		r<-rnorm(1)
> 		ss<-ss+r
> 	}
> print(ss)
> }
> }
> check.2<-z2(3)
> check.2
> 
> > check.2<-z2(3)
> [1] -2.213343
> [1] -2.904235
> [1] -0.01516304
> > check.2
> [1] -0.01516304
> 
> the problem with z2 is that only the last value is saved.
> 
> 
> what i could do is use matrices like the following: (but i dont want to
> do this AND WOULD PREFER TO USE list.)
> 
> z3<-function(w)
> {
> results.<-matrix(nrow=w,ncol=1)
> colnames(results.)<-c("ss")
> for (i in 1:w)
> {
> set.seed(i+6)
> ss<-0
> 	for (j in 1:5)
> 	{
> 		set.seed(j+1+(i-1)*6)
> 		r<-rnorm(1)
> 		ss<-ss+r
> 	}
> results.[i,1]<-ss
> }
> results.
> }
> check.3<-z3(3)
> check.3
> 
> > check.3
>               ss
> [1,] -2.21334260
> [2,] -2.90423463
> [3,] -0.01516304
> 
> what if i have a new program (something different) and i want the
> following:
> 
> j=1
> $a
> 1
> 2
> 3
> 
> $b
> 1
> 2
> 3
> 4
> 5
> 
> $c
> 1
> 
> 
> ###############
> j=2
> $a
> 11
> 21
> 31
> 
> $b
> 11
> 21
> 31
> 41
> 51
> 
> $c
> 11
> 
> ###############
> j=3
> $a
> 21
> 22
> 32
> 
> $b
> 21
> 22
> 32
> 42
> 52
> 
> $c
> 21
> 
> MATRICES SEEMS TO BE A GOOD WAY OF DOING THIS (but then you would have
> to set up three matrices, one for a,b and c). BUT WHAT IF I WANT TO USE
> THE LIST FUNCTION? i.e. there is a list in the first loop that i want to
> display!
> 
> sorry for the long mail.
> 
> ***
> ALLAN
> ______________________________________________ R-help at stat.math.ethz.ch mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From abunn at whrc.org  Thu Mar 10 16:30:11 2005
From: abunn at whrc.org (abunn)
Date: Thu, 10 Mar 2005 10:30:11 -0500
Subject: [R] Vogelsang test? RATS? Time series analysis.
Message-ID: <NEBBIPHDAMMOKDKPOFFIKEMADBAA.abunn@whrc.org>

Has anybody implemented the Vogelsang test from Vogelsang's 1998
Econometrica paper? Or the tests by Fomby and Vogelsang from their 2002
paper?

I have been looking for trends in many time series (1000's) with unknown
autocorrelation. In brief, I have fit AR models  and classified them as
stochastic or deterministic with augmented Dickey-Fuller tests. A colleague
has suggested that we use a "new and more elegant test" that is robust to
the nature of serial correlation in the residuals and pointed me the RATS
program in general and Fomby and Vogelsang test in particular.

Any leads appreciated, Andy

~~~~~~~~~~~~~~
Fomby TB, Vogelsang TJ, The application of size-robust trend statistics to
global-warming temperature series. JOURNAL OF CLIMATE 15 (1): 117-123 2002
Vogelsang TJ, Trend function hypothesis testing in the presence of serial
correlation. ECONOMETRICA 66 (1): 123-148 1998



From tlumley at u.washington.edu  Thu Mar 10 16:56:04 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 10 Mar 2005 07:56:04 -0800 (PST)
Subject: [R] problem using uniroot with integrate
In-Reply-To: <1110395970.422f4c42cc56a@webmail.lyon.inserm.fr>
References: <1110395970.422f4c42cc56a@webmail.lyon.inserm.fr>
Message-ID: <Pine.A41.4.61b.0503100747340.145576@homer10.u.washington.edu>

On Wed, 9 Mar 2005, Ken Knoblauch wrote:

> Thank you very much.  Yes, that was the problem, partial matching.
> I saw a warning about that in integrate and some discussion from 1999
> in the archives and so added the m0 for integrate but somehow
> I wasn't bright enough to see that I had the same problem
> in uniroot.

It is perhaps worth pointing out that in R you usually don't need to pass 
these extra arguments down

  dprime.mAFC <- function(Pc, m) {
              est.dp <- function(dp) {

                pr <- function(x) {
                      dnorm(x - dp) * pnorm(x)^(m - 1)
                          }

                Pc - integrate(pr, lower = -Inf, upper = Inf)$value
              }

      dp.res <- uniroot(est.dp, interval = c(0,5))
      dp.res$root
      }

Because pr() is defined inside est.dp, which is defined inside 
dprime.mAFC, the arguments are already accessible.

In most cases, passing extra arguments through a higher-order function is 
not needed in R, as lexical scope allows the function to have access to 
the information directly.  You also don't have to keep thinking up 
different names for 'm'.

> Sorry about no working example, but I'm not sure what I could
> have added, if I understand what you mean by working example,
> because my function wasn't working.

A set of arguments at which you wanted to evaluate the function, so that 
a) we could get the same error that you did
b) we could tell when it worked.

 	-thomas


> best,
>
> ken
>
>
> Quoting Sundar Dorai-Raj <sundar.dorai-raj at pdf.com>:
>
>>
>>
>> Ken Knoblauch wrote on 3/9/2005 10:27 AM:
>>> Hi,
>>>
>>> I'm trying to calculate the value of the variable, dp, below, in the
>>> argument to the integral of dnorm(x-dp) * pnorm(x)^(m-1).  This
>>> corresponds to the estimate of the sensitivity of an observer in an
>>> m-alternative forced choice experiment, given the probability of
>>> a correct response, Pc, a Gaussian assumption for the noise and
>>> no bias.  The function that I wrote below gives me an error:
>>>
>>> Error in f(x, ...) : recursive default argument reference
>>>
>>> The problem seems to be at the statement using uniroot,
>>> because the furntion est.dp works fine outside of the main function.
>>> I've been using R for awhile but there are still many nuances
>>> about the scoping and the use of environments that I'm weak on
>>> and would like to understand better.  I would appreciate any
>>> suggestions or solutions that anyone might offer for fixing
>>> my error.  Thank you.
>>>
>>> dprime.mAFC <- function(Pc, m) {
>>> 		est.dp <- function(dp, Pc = Pc, m = m) {
>>>
>>> 		  pr <- function(x, dpt = dp, m0 = m) {
>>> 		    	dnorm(x - dpt) * pnorm(x)^(m0 - 1)
>>> 			    }
>>>
>>> 		  Pc - integrate(pr, lower = -Inf, upper = Inf,
>>> 		  dpt = dp, m0 = m)$value
>>> 		}
>>>
>>> 	dp.res <- uniroot(est.dp, interval = c(0,5), Pc = Pc, m = m)
>>> 	dp.res$root
>>> 	}
>>>
>>
>> Ken,
>>
>> Look at the argument list for ?uniroot and think "partial matching".
>> You're "m" is being interpretted for "maxiter". Simply change to
>>
>> dp.res <- uniroot(est.dp, interval = c(0,5), Pc = Pc, m0 = m)
>>
>> and in other places for consistency and the error goes away. Of course,
>> since you gave no working example, I'm not sure if other errors are
>> present that I'm missing.
>>
>> --sundar
>>
>
>
>
> ____________________
> Ken Knoblauch
> Inserm U 371
> Cerveau et Vision
> 18 avenue du Doyen Lepine
> 69675 Bron cedex
> France
> tel: +33 (0)4 72 91 34 77
> fax: +33 (0)4 72 91 34 61
> portable: 06 84 10 64 10
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From tlumley at u.washington.edu  Thu Mar 10 17:01:57 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 10 Mar 2005 08:01:57 -0800 (PST)
Subject: [R] Interval censoring in Survival analysis
In-Reply-To: <66373AD054447F47851FCC5EB49B36116CF155@basquet.imim.es>
References: <66373AD054447F47851FCC5EB49B36116CF155@basquet.imim.es>
Message-ID: <Pine.A41.4.61b.0503100756110.145576@homer10.u.washington.edu>

On Thu, 10 Mar 2005, AMOROS NAVARRO, ALEX wrote:

> Hi,
>
> I would like to know if R programme allows doing different kinds of 
> censoring in his last version. What kind of package should I use and is 
> this censoring applicable to parametric and semi-parametric(Cox) models?
>

To some extent.

The "survival" package allows left censoring and interval censoring, but 
only for parametric models.  The Icens package estimates survival curves 
for interval censored data (including multivariate times), but does not do 
regression.

I am not aware of any package that allows semiparametric regression 
modelling of interval censored or doubly censored data.

 	-thomas



From sfalcon at fhcrc.org  Thu Mar 10 17:29:21 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 10 Mar 2005 08:29:21 -0800
Subject: [R] Re: [Rd] dealing with package bundles
In-Reply-To: <3A822319EB35174CA3714066D590DCD50994E823@usrymx25.merck.com>
	(Andy Liaw's message of "Thu, 10 Mar 2005 11:04:07 -0500")
References: <3A822319EB35174CA3714066D590DCD50994E823@usrymx25.merck.com>
Message-ID: <m2oedr4g7y.fsf@macaroni.local>

"Liaw, Andy" <andy_liaw at merck.com> writes:

> Given the confusions that some users have regarding package bundles, I'd
> like to suggest some changes to how package bundles are handled.

I wonder if a guideline of naming packages bundles in a manner that
identifies them as bundles would help?

An example of what I'm thinking: gregmisc-bundle_x.y.z.tar.gz

Then users could (once familiar with the convention) know when they
are dealing with a bundle.  

Such a name scheme fits with my understanding of bundles: they provide
a mechanism to download and install multiple packages at once.  After
installation there is no notion of bundle.  One doesn't call library
on a bundle (and I think that is a good thing).


Best,

+ seth



From Ted.Harding at nessie.mcc.ac.uk  Thu Mar 10 17:13:01 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 10 Mar 2005 16:13:01 -0000 (GMT)
Subject: [R] from long/lat to UTM
In-Reply-To: <loom.20050310T145039-193@post.gmane.org>
Message-ID: <XFMail.050310161301.Ted.Harding@nessie.mcc.ac.uk>

On 10-Mar-05 Gabor Grothendieck wrote:
>  <Ted.Harding <at> nessie.mcc.ac.uk> writes:
>: [...]
>: As Sander says, "Not sure where you would derive the time zone!".
>: 
>: Unless you can refer a (long,lat) position to a look-up
>: table, you can't predict what the zone will be to less
>: the 1 hour (except of course for the "nominal" time-zones
>: by 15deg sectors). I've never encountered a "digital"
>: version of such a table (my Atlas must be based on one,
>: though).
>: 
>: Best wishes,
>: Ted.
> 
> The fBasics package of the rmetrics project uses the Olsen time
> zone data base which does take some of these things into account.

Thanks, Gabor! However, this seems to be just the usual sort
of thing -- TimeZone name with corresponding TZ data. You first
have to know the TZ name. (Unless I have overlooked sonething
in the Olsen database).

What I had in mind was a "look-up" facility whereby a (long,lat)
pair could be submitted as a query, returning the TZ region
(name) within which that geographical point lay.

The only completely general mechanism I can think of would
consist of

a) a named list of boundary contours
b) a function which, for each name in the list, returns
   the TZ name

Then, for instance, given a point P = (long,lat), the list
could be searched by verifying, for each contour in the list,
whether the point lay in the region circumscribed by the
coutour (e.g. by computing the winding number for the contour
with respect to the point). This would also work for regions
with holes in them, provided the  boundary of the hole was
presented in the correct order of points (e.g. such that the
region of which it was the boundary lies to the left as you
go through the sequence).

If, for instance, I had the contour data for the TZ map
in my Atlas, I could construct such a thing! But, as I say,
I have not come across such a dataset. I'd be interested
to learn of one, though!

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 10-Mar-05                                       Time: 16:13:01
------------------------------ XFMail ------------------------------



From gregory.r.warnes at pfizer.com  Thu Mar 10 18:08:11 2005
From: gregory.r.warnes at pfizer.com (Warnes, Gregory R)
Date: Thu, 10 Mar 2005 12:08:11 -0500
Subject: [R] How could I catch the R data-output stream and presented 
	by other software func 
Message-ID: <915D2D65A9986440A277AC5C98AA466F978C0E@groamrexm02.amer.pfizer.com>

There are quite a few packages which allow R to be accessed from other
software systems.  Examples include RDCOM (included with Windows R), RSOAP
(http://rsoap.sf.net), Rpy (Python, http://rpy.sf.net), RSPerl
(http://www.omegahat.org/RSPerl/).  Duncan Temple Lang, the developer of
RSPerl, has a whole pile of these tools, see http://www.omegahat.org for a
full list.

-Greg

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Michael shen
> Sent: Thursday, March 10, 2005 1:37 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] How could I catch the R data-output stream and 
> presented by
> other software func 
> 
> 
> Dear All R-helper,
> 
> I wonder to know that could I do the computation  staff in R 
> environment and 
> get the R data output stream ,then presented by other 
> software functions in 
> their GUI.(for example: get the R data output streamand 
> present the data 
> using SPSS function in SPSS output GUI). Is there some R 
> -packages in CRAN 
> already do this kind of function? and what kind of document 
> should I read?
> 
> Thanks in advance
> 
> Michael
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From pbruce at statistics.com  Thu Mar 10 18:23:16 2005
From: pbruce at statistics.com (Peter C. Bruce)
Date: Thu, 10 Mar 2005 12:23:16 -0500
Subject: [R] Online short course:  Advanced Resampling Methods
Message-ID: <6.1.0.6.2.20050310122224.01fd2d70@mail.statistics.com>

Online short course:  Advanced Resampling Methods

Phillip Good will offer his online short course "Advanced Resampling 
Methods" March 18 ? April 8.  In the bootstrap area, it will cover BCA 
(bias corrected and accelerated) confidence intervals, bootstrap-t 
intervals, the parametric bootstrap, and the tilted bootstrap.  The use of 
bootstrapping for estimating power and sample sizes will be covered, as 
will model validation.  Permutation tests will also be discussed, with 
coverage of 2-sided alternatives, matched pairs, strata, and ordered RxC 
tables.  Dr. Good will also discuss decision trees.  (Note:  topic coverage 
may be adjusted slightly to accommodate the needs of 
participants.)  Examples will be provided in R.

Participants will interact with Dr. Good via a private discussion board 
over approximately 4 weeks; the course will require about 10 hours per week 
and there are no set hours when you must be online.

Details and registration:

http://www.statistics.com/content/courses/advancedresamp/index.html

Peter Bruce
pbruce at statistics.com



From greg.snow at ihc.com  Thu Mar 10 18:28:00 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Thu, 10 Mar 2005 10:28:00 -0700
Subject: [R] from long/lat to UTM
Message-ID: <s230213d.017@lp-msg1.co.ihc.com>


>>> Ted Harding <Ted.Harding at nessie.mcc.ac.uk> 03/10/05 09:13AM >>>
>> On 10-Mar-05 Gabor Grothendieck wrote:
>> >  <Ted.Harding <at> nessie.mcc.ac.uk> writes:
>> >: [...]
>> >: As Sander says, "Not sure where you would derive the time
zone!".
>> >: 

[snip]

>> The only completely general mechanism I can think of would
>> consist of
>> 
>> a) a named list of boundary contours

I found a shapefile of time zones at: 
http://openmap.bbn.com/data/shape/timezone/ 

A google search on the keywords timezone & shapefile finds a 
few other possibilities. 

>> b) a function which, for each name in the list, returns
>>    the TZ name

The "maptools" package can read in the above shapefile and 
convert it to a list of polygons and the "sgeostat" has an
"in.polygon" function to see if a point is in a given polygon.

The following code worked for me:

library(maptools)
tz <- read.shape('c:/maps/WrldTZA')
plot(tz)
plot(tz,xlim=c(-150,-50), ylim=c(20,50))

mappoly <- Map2poly(tz)

library(sgeostat)

tmp <- sapply(mappoly, function(x){ x <- na.exclude(x)
	in.polygon( -110, 42, x[,1], x[,2] ) } )

tz$att.data[tmp,]


the -110 and 42 come from me plotting the map and using 
locator to approximate where I am at.  I was actually 
suprized at how quick the sapply was (under a second on
my fairly fast pc (windows 2000)).

It shouldn't be too hard to convert this into a more general
function.




Greg Snow, Ph.D.
Statistical Data Center
greg.snow at ihc.com
(801) 408-8111



From Ted.Harding at nessie.mcc.ac.uk  Thu Mar 10 19:10:23 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 10 Mar 2005 18:10:23 -0000 (GMT)
Subject: [R] from long/lat to UTM
In-Reply-To: <s230213d.017@lp-msg1.co.ihc.com>
Message-ID: <XFMail.050310181023.Ted.Harding@nessie.mcc.ac.uk>

On 10-Mar-05 Greg Snow wrote:
> [...]
> I found a shapefile of time zones at: 
> http://openmap.bbn.com/data/shape/timezone/ 
> 
> A google search on the keywords timezone & shapefile finds a 
> few other possibilities. 
> 
>>> b) a function which, for each name in the list, returns
>>>    the TZ name
> 
> The "maptools" package can read in the above shapefile and 
> convert it to a list of polygons and the "sgeostat" has an
> "in.polygon" function to see if a point is in a given polygon.
> 
> The following code worked for me:
> [....]

Many thanks, Greg. That looks just the job, and I'll look
into it.

All best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 10-Mar-05                                       Time: 18:10:23
------------------------------ XFMail ------------------------------



From DarrenLeeWeber at gmail.com  Thu Mar 10 19:54:18 2005
From: DarrenLeeWeber at gmail.com (Darren Weber)
Date: Thu, 10 Mar 2005 10:54:18 -0800
Subject: [R] contrast matrix for aov
In-Reply-To: <Pine.LNX.4.61.0503100722330.29906@gannet.stats>
References: <422F8EDE.2030009@gmail.com>
	<Pine.LNX.4.61.0503100722330.29906@gannet.stats>
Message-ID: <423097DA.80906@gmail.com>

Prof Brian Ripley wrote:

> On Wed, 9 Mar 2005, Darren Weber wrote:
>
>> How do we specify a contrast interaction matrix for an ANOVA model?
>>
>> We have a two-factor, repeated measures design, with
>
>
> Where does `repeated measures' come into this?  You appear to have 
> repeated a 2x2 experiment in each of 8 blocks (subjects).  Such a 
> design is usually analysed with fixed effects.  (Perhaps you averaged 
> over repeats in the first few lines of your code?)


Each subject experiences multiple instances of a visual stimulus that 
cues them to orient their attention to the left or right visual field.  
For each instance, we acquire brain activity measures from the left and 
right hemisphere (to put it simply).  For each condition in this 2x2 
design, we actually have about 400 instances for each cell for each 
subject.  These are averaged in several ways, so we obtain a single 
scalar value for each subject in the final analysis.  So, at this point, 
it does not appear to be a repeated measures analysis.  Perhaps another 
way to put it - each subject experiences every cell of the design, so we 
have "within-subjects" factors rather than "between-subjects" factors.  
That is, each subject experiences all experimental conditions, we do not 
separate and randomly allocate subjects to only one cell or another of 
the experiment.

I hope this clarifies the first question.  I will try to digest further 
points in this thread, if they are not too confounded by this first 
point of contention already.



From xt_wang at cse.concordia.ca  Thu Mar 10 20:00:47 2005
From: xt_wang at cse.concordia.ca (xt_wang@cse.concordia.ca)
Date: Thu, 10 Mar 2005 14:00:47 -0500
Subject: [R] about R CMD check
Message-ID: <1110481247.4230995ff2bdf@mail.encs.concordia.ca>

hello, everybody,

I create a package by myself named "var" on Linux system. I attach a C code
which uses "R_ext/Lapack.h" in directory "src". But when I carry out " R CMD
check var", it shows

>  wxt0124()
Error in .C("wxt1221", PACKAGE = "var") : C function name not in DLL for package
var
Execution halted

Could you tell me what is the problem?

Maggie


[credsim at confsys myrpackages]$ R CMD check var
* checking for working latex ... OK
* using log directory '/home/credsim/src/myrpackages/var.Rcheck'
* checking for file 'var/DESCRIPTION' ... OK
* checking if this is a source package ... OK

* Installing *source* package 'var' ...
** libs
gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp 
-fPIC  -O2 -g -march=i386 -mcpu=i686 -c wxt1221.c -o wxt1221.o
wxt1221.c: In function `Matrix_A_12':
wxt1221.c:774: warning: passing arg 3 of `dpotrf_' from incompatible pointer
type
wxt1221.c:775: warning: passing arg 4 of `dpotrs_' from incompatible pointer
type
wxt1221.c: In function `Matrix_A_1':
wxt1221.c:1038: warning: passing arg 3 of `dpotrf_' from incompatible pointer
type
wxt1221.c:1039: warning: passing arg 4 of `dpotrs_' from incompatible pointer
type
wxt1221.c: In function `Matrix_A_2':
wxt1221.c:1290: warning: passing arg 3 of `dpotrf_' from incompatible pointer
type
wxt1221.c:1291: warning: passing arg 4 of `dpotrs_' from incompatible pointer
type
gcc -shared -L/usr/local/lib -o var.so wxt1221.o -L/usr/lib/R/bin -lRlapack 
-L/usr/local/lib -L/usr/lib/gcc-lib/i386-redhat-linux/3.2.2
-L/usr/lib/gcc-lib/i386-redhat-linux/3.2.2/../../.. -lfrtbegin -lg2c -lm
-lgcc_s
** R
** help
Warning: \alias{wxt0124} already in wxt0124.Rd -- skipping the one in wxt1221.Rd
 >>> Building/Updating help pages for package 'var'
     Formats: text html latex example
  wxt0124                           text    html    latex   example
  wxt1221                           text    html    latex   example
* DONE (var)

* checking package directory ... OK
* checking for portable file names ... OK
* checking for sufficient/correct file permissions ... OK
* checking DESCRIPTION meta-information ... OK
* checking package dependencies ... OK
* checking index information ... OK
* checking package subdirectories ... OK
* checking R files for syntax errors ... OK
* checking R files for library.dynam ... OK
* checking S3 generic/method consistency ... OK
* checking for replacement functions with final arg not named 'value' ... OK
* checking foreign function calls ... OK
* checking Rd files ... OK
* checking for missing documentation entries ... WARNING
Undocumented code objects:
  b
All user-level objects in a package should have documentation entries.
See chapter 'Writing R documentation files' in manual 'Writing R
Extensions'.
* checking for code/documentation mismatches ... OK
* checking Rd \usage sections ... OK
* checking for CRLF line endings in C sources/headers ... OK
* creating var-Ex.R ... OK
* checking examples ... ERROR
Running examples in var-Ex.R failed.
The error most likely occurred in:

> ### * wxt0124
>
> flush(stderr()); flush(stdout())
>
> ### Name: wxt0124
> ### Title: Estimation of Optimal Variance Components in CCC Model
> ### Aliases: wxt0124
> ### Keywords: array
> >  wxt0124()
Error in .C("wxt1221", PACKAGE = "var") : C function name not in DLL for package
var
Execution halted

> ### ** Examples
>



From DarrenLeeWeber at gmail.com  Thu Mar 10 20:07:44 2005
From: DarrenLeeWeber at gmail.com (Darren Weber)
Date: Thu, 10 Mar 2005 11:07:44 -0800
Subject: [R] contrast matrix for aov
In-Reply-To: <Pine.LNX.4.61.0503100957340.11562@gannet.stats>
References: <422F8EDE.2030009@gmail.com>
	<Pine.LNX.4.61.0503100722330.29906@gannet.stats>
	<423016B3.9090301@lscp.ehess.fr>
	<Pine.LNX.4.61.0503100957340.11562@gannet.stats>
Message-ID: <42309B00.7090708@gmail.com>


As an R newbie (formerly SPSS), I was pleased to find some helpful notes 
on ANOVA here:

http://personality-project.org/r/r.anova.html

In my case, I believe the relevant section is:

Example 4. Two-Way Within-Subjects ANOVA

This is where I noted and copied the error notation.

Sorry for any confusion about terms - I did mean "within-subjects" 
factors, rather than repeated measures (although, as noted earlier, we 
do have both in this experiment).


Prof Brian Ripley wrote:

> On Thu, 10 Mar 2005, Christophe Pallier wrote:
>
>>
>> Prof Brian Ripley wrote:
>>
>>>> On Wed, 9 Mar 2005, Darren Weber wrote:
>>>>
>>>> We have a two-factor, repeated measures design, with
>>>
>>>
>>>
>>> Where does `repeated measures' come into this?  You appear to have 
>>> repeated a 2x2 experiment in each of 8 blocks (subjects).  Such a 
>>> design is usually analysed with fixed effects.  (Perhaps you 
>>> averaged over repeats in the first few lines of your code?)
>>>
>>>>
>>>> roi.aov <- aov(roi ~ (Cue*Hemisphere) + 
>>>> Error(Subject/(Cue*Hemisphere)), data=roiDataframe)
>>>
>>>
>>>
>>> I think the error model should be Error(Subject).  In what sense are 
>>> `Cue' and `Cue:Hemisphere' random effects nested inside `Subject'?
>>>
>>
>> I do not understand this, and I think I am probably not the only one. 
>> That is why I would be grateful if you could give a bit more 
>> information.
>>
>> My understanding is that the fixed factors Cue and Hemisphere are 
>> crossed with the random factor Subject (in other words, Cue and 
>> Hemisphere are within-subjects factors, and this is probably why 
>> Darren called it a "repeated measure" design).
>
>
> The issue is whether the variance of the error really depends on the 
> treatment combination, which is what the 
> Error(Subject/(Cue*Hemisphere)) assumes.  With that model
>
> Error: Subject:Cue
>           Df Sum Sq Mean Sq F value Pr(>F)
> Cue        1 0.2165  0.2165  0.1967 0.6708
> Residuals  7 7.7041  1.1006
>
> Error: Subject:Hemisphere
>            Df Sum Sq Mean Sq F value Pr(>F)
> Hemisphere  1 0.0197  0.0197  0.0154 0.9047
> Residuals   7 8.9561  1.2794
>
> Error: Subject:Cue:Hemisphere
>                Df Sum Sq Mean Sq F value Pr(>F)
> Cue:Hemisphere  1 0.0579  0.0579  0.0773  0.789
> Residuals       7 5.2366  0.7481
>
> you are assuming different variances for three contrasts.
>
>> In this case, it seems to me from the various textbooks I read on 
>> Anova, that the appropriate MS to  test the interaction 
>> Cue:Hemisphere is Subject:Cue:Hemisphere (with 7 degress of freedom, 
>> as there are 8 independent subjects). If you input 
>> Error(Subject/(Cue*Hemisphere)) in the aov formula, then the test for 
>> the interaction indeed uses the Subject:Cue:Hemisphere source of 
>> variation in demoninator. This fits with the ouput of other softwares.
>>
>> If you include only 'Subjet', then the test for the interaction has 
>> 21 degrees of Freedom, and I do not understand what this tests.
>
>
> It uses a common variance for all treatment combinations.
>
>> I apologize in if my terminology is not accurate.  But I hope you can 
>> clarify what is wrong with the Error(Subject/(Cue*Hemisphere)) term,
>> or maybe just point us to the relevant textbooks.
>
>
> Nothing is `wrong' with it, it just seems discordant with the description
> of the experiment.
>



From Sholte at fhcrc.org  Thu Mar 10 20:28:17 2005
From: Sholte at fhcrc.org (Sarah Holte)
Date: Thu, 10 Mar 2005 11:28:17 -0800
Subject: [R] how to view the syntax of a method which is not a generic method
Message-ID: <42309FD1.6080002@fhcrc.org>


Hello - I'm trying to modify an option for the lme() or nlme() macros.  
I want to write my own specification for the variance function and am 
following homework problem 4, Chapter 5, page 268 of Pinheiro and Bates 
book on mixed effect.

I'm up to point where I've created a new class using an existing 
variance function class, varExp as a template.  Next I need to write an 
initialize method.  The book suggests that I use the inialize method for 
one of the exisiting variance functions for lme(), eg varExp.
What I want is the syntax of the initialize.varExp method so that I can 
edit it to create an initialize method for my newly constructed class.

So - I tried to get the text of this method, called initialize.varExp by 
using the showMethods command.

Here's what happened.

 > showMethods("initialize.varExp")

Function "initialize.varExp":
<not a generic function>

So I assume that inialize.varExp is not a generic method.   I also have 
the following information.

 > findFunction("initialize.varExp")
list()

and

 > findFunction("varExp")
[[1]]
<environment: package:nlme>
attr(,"name")
[1] "package:nlme"
attr(,"path")
[1] "C:/PROGRA~1/R/rw1091/library/nlme"

So I'm guessing I somehow need to tell the showMethods command that 
initialize.varExp is part of the nlme package.  And now I'm stuck - any 
suggestions?

Thanks so much - Sarah Holte



From uofiowa at gmail.com  Thu Mar 10 20:29:59 2005
From: uofiowa at gmail.com (Omar Lakkis)
Date: Thu, 10 Mar 2005 14:29:59 -0500
Subject: [R] RODBC autocommit
Message-ID: <3f87cc6d050310112939a2bebe@mail.gmail.com>

How can I turn autocommit off using my RODBC connection to an Informix database?
I want to turn autocommit off, insert a thousand or so rows then commit.



From andy_liaw at merck.com  Thu Mar 10 21:00:45 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 10 Mar 2005 15:00:45 -0500
Subject: [R] about R CMD check
Message-ID: <3A822319EB35174CA3714066D590DCD50994E826@usrymx25.merck.com>

Please show us at least the prototype of the C function(s) being called, and
the .C call in the R code.

Just to make sure:  The first argument to .C() should be the name of the C
function, not the name of the C source file.

Andy

> From: xt_wang at cse.concordia.ca
> 
> hello, everybody,
> 
> I create a package by myself named "var" on Linux system. I 
> attach a C code
> which uses "R_ext/Lapack.h" in directory "src". But when I 
> carry out " R CMD
> check var", it shows
> 
> >  wxt0124()
> Error in .C("wxt1221", PACKAGE = "var") : C function name not 
> in DLL for package
> var
> Execution halted
> 
> Could you tell me what is the problem?
> 
> Maggie
> 
> 
> [credsim at confsys myrpackages]$ R CMD check var
> * checking for working latex ... OK
> * using log directory '/home/credsim/src/myrpackages/var.Rcheck'
> * checking for file 'var/DESCRIPTION' ... OK
> * checking if this is a source package ... OK
> 
> * Installing *source* package 'var' ...
> ** libs
> gcc -I/usr/lib/R/include  -I/usr/local/include 
> -D__NO_MATH_INLINES -mieee-fp 
> -fPIC  -O2 -g -march=i386 -mcpu=i686 -c wxt1221.c -o wxt1221.o
> wxt1221.c: In function `Matrix_A_12':
> wxt1221.c:774: warning: passing arg 3 of `dpotrf_' from 
> incompatible pointer
> type
> wxt1221.c:775: warning: passing arg 4 of `dpotrs_' from 
> incompatible pointer
> type
> wxt1221.c: In function `Matrix_A_1':
> wxt1221.c:1038: warning: passing arg 3 of `dpotrf_' from 
> incompatible pointer
> type
> wxt1221.c:1039: warning: passing arg 4 of `dpotrs_' from 
> incompatible pointer
> type
> wxt1221.c: In function `Matrix_A_2':
> wxt1221.c:1290: warning: passing arg 3 of `dpotrf_' from 
> incompatible pointer
> type
> wxt1221.c:1291: warning: passing arg 4 of `dpotrs_' from 
> incompatible pointer
> type
> gcc -shared -L/usr/local/lib -o var.so wxt1221.o 
> -L/usr/lib/R/bin -lRlapack 
> -L/usr/local/lib -L/usr/lib/gcc-lib/i386-redhat-linux/3.2.2
> -L/usr/lib/gcc-lib/i386-redhat-linux/3.2.2/../../.. 
> -lfrtbegin -lg2c -lm
> -lgcc_s
> ** R
> ** help
> Warning: \alias{wxt0124} already in wxt0124.Rd -- skipping 
> the one in wxt1221.Rd
>  >>> Building/Updating help pages for package 'var'
>      Formats: text html latex example
>   wxt0124                           text    html    latex   example
>   wxt1221                           text    html    latex   example
> * DONE (var)
> 
> * checking package directory ... OK
> * checking for portable file names ... OK
> * checking for sufficient/correct file permissions ... OK
> * checking DESCRIPTION meta-information ... OK
> * checking package dependencies ... OK
> * checking index information ... OK
> * checking package subdirectories ... OK
> * checking R files for syntax errors ... OK
> * checking R files for library.dynam ... OK
> * checking S3 generic/method consistency ... OK
> * checking for replacement functions with final arg not named 
> 'value' ... OK
> * checking foreign function calls ... OK
> * checking Rd files ... OK
> * checking for missing documentation entries ... WARNING
> Undocumented code objects:
>   b
> All user-level objects in a package should have documentation entries.
> See chapter 'Writing R documentation files' in manual 'Writing R
> Extensions'.
> * checking for code/documentation mismatches ... OK
> * checking Rd \usage sections ... OK
> * checking for CRLF line endings in C sources/headers ... OK
> * creating var-Ex.R ... OK
> * checking examples ... ERROR
> Running examples in var-Ex.R failed.
> The error most likely occurred in:
> 
> > ### * wxt0124
> >
> > flush(stderr()); flush(stdout())
> >
> > ### Name: wxt0124
> > ### Title: Estimation of Optimal Variance Components in CCC Model
> > ### Aliases: wxt0124
> > ### Keywords: array
> > >  wxt0124()
> Error in .C("wxt1221", PACKAGE = "var") : C function name not 
> in DLL for package
> var
> Execution halted
> 
> > ### ** Examples
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From n.r.street at soton.ac.uk  Thu Mar 10 21:14:45 2005
From: n.r.street at soton.ac.uk (Nathaniel Street)
Date: Thu, 10 Mar 2005 20:14:45 +0000
Subject: [R] Transparent colors OR two series on one histogram
In-Reply-To: <200503101109.j2AB2U1b002542@hypatia.math.ethz.ch>
References: <200503101109.j2AB2U1b002542@hypatia.math.ethz.ch>
Message-ID: <4230AAB5.5030407@soton.ac.uk>

Hi,

I want to be able to plot a single histogram of a measured trait with 
trait values from two conditions on the same histogram to allow easy 
comparison.

I have previously done this in excel by plotting the two series on a 
single bargraph having calculated frequencies in bins. You then get one 
condition plotted immediately to the right of the other. I hope that 
makes sense?

I don't know if this is possible in R?

If not, I could plot the second one on top of the first i.e.

hist(x)
hist(y,add=TRUE)

but i would need to set one as having a semi-transparent color so that 
where the two sets of are plotted on top of each other, you can see the 
frequency of the first series 'behind' the second.

Can anyone help me do this? It would be another step towards never using 
excel again :)

Thanks



From sfalcon at fhcrc.org  Thu Mar 10 21:18:53 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 10 Mar 2005 12:18:53 -0800
Subject: [R] how to view the syntax of a method which is not a generic
	method
In-Reply-To: <42309FD1.6080002@fhcrc.org> (Sarah Holte's message of "Thu, 10
	Mar 2005 11:28:17 -0800")
References: <42309FD1.6080002@fhcrc.org>
Message-ID: <m2eken2r0y.fsf@macaroni.local>

Hi Sarah,

Sarah Holte <Sholte at fhcrc.org> writes:

> The book suggests that I use the inialize method for one of the
> exisiting variance functions for lme(), eg varExp.  What I want is
> the syntax of the initialize.varExp method so that I can edit it to
> create an initialize method for my newly constructed class.

You might want to download the source package for nlme.  You can get
it here:

http://cran.fhcrc.org/src/contrib/nlme_3.1-56.tar.gz

I think the function you are looking for is defined in varFunc.R and
it looks like it is Initialize.varExp (initial cap) so you might retry
your search techniques with that name.

Hope that helps,

+ seth



From tlumley at u.washington.edu  Thu Mar 10 21:41:07 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 10 Mar 2005 12:41:07 -0800 (PST)
Subject: [R] Transparent colors OR two series on one histogram
In-Reply-To: <4230AAB5.5030407@soton.ac.uk>
References: <200503101109.j2AB2U1b002542@hypatia.math.ethz.ch>
	<4230AAB5.5030407@soton.ac.uk>
Message-ID: <Pine.A41.4.61b.0503101238190.126942@homer05.u.washington.edu>

On Thu, 10 Mar 2005, Nathaniel Street wrote:

> Hi,
>
> I want to be able to plot a single histogram of a measured trait with trait 
> values from two conditions on the same histogram to allow easy comparison.
>
> I have previously done this in excel by plotting the two series on a single 
> bargraph having calculated frequencies in bins. You then get one condition 
> plotted immediately to the right of the other. I hope that makes sense?
>
> I don't know if this is possible in R?

You can do it for bar plots, but not for histograms.  Look at 
barplot(beside=TRUE)

> If not, I could plot the second one on top of the first i.e.
>
> hist(x)
> hist(y,add=TRUE)
>
> but i would need to set one as having a semi-transparent color so that where 
> the two sets of are plotted on top of each other, you can see the frequency 
> of the first series 'behind' the second.

Semitransparent colors are available for the pdf() and quartz() devices. 
They were described by Paul Murrell in R News Vol 4 No 2.

 	-thomas



From jean.vidal at freesurf.fr  Thu Mar 10 21:56:05 2005
From: jean.vidal at freesurf.fr (Jean Vidal)
Date: Thu, 10 Mar 2005 20:56:05 -0000
Subject: [R] Question regarding mosaicplot
Message-ID: <6.0.0.22.1.20031118232152.01cec730@pop.freesurf.fr>

I tried this : 
> mosaicplot(stoc ~ q9r + segca,data=tmp2,color=T) : works fine.

And now, this :
> mosaicplot(stoc ~ q9r + segca, data=tmp2, color=T, main="Big title")
Error in model.frame(formula, rownames, variables, varnames, extras, extranames,  : 
        invalid variable type

I'm probably stupid and missed something simple in the manual (and wouldn't like to be flamed if insinuating that, may be... a bug ? Oh no !).

It can be done with :
> mosaicplot(table(tmp2$stoc,tmp2$q9r,tmp2$segca),color=T,main="Big title") : works fine.

So, no real trouble for me... 

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    8.0            
year     2003           
month    10             
day      08             
language R



From twiens at interbaun.com  Thu Mar 10 22:06:18 2005
From: twiens at interbaun.com (Trevor Wiens)
Date: Thu, 10 Mar 2005 14:06:18 -0700
Subject: [R] Logistic regression goodness of fit tests
Message-ID: <20050310140618.51e3d284.twiens@interbaun.com>

I was unsure of what suitable goodness-of-fit tests existed in R for logistic regression. After searching the R-help archive I found that using the Design models and resid, could be used to calculate this as follows:

d <- datadist(mydataframe)
options(datadist = 'd')
fit <- lrm(response ~ predictor1 + predictor2..., data=mydataframe, x =T, y=T)
resid(fit, 'gof').

I set up a script to first use glm to create models use stepAIC to determine the optimal model. I used this instead of fastbw because I found the AIC values to be completely different and the final models didn't always match. Then my script takes the reduced model formula and recreates it using lrm as above. Now the problem is that for some models I run into an error to which I can find no reference whatsoever on the mailing list or on the web. It is as follows:

test.lrm <- lrm(cclo ~ elev + aspect + cti_var + planar + feat_div + loamy + sands + sandy + wet + slr_mean, data=datamatrix, x = T, y = T)
singular information matrix in lrm.fit (rank= 10 ).  Offending variable(s):
slr_mean 
Error in j:(j + params[i] - 1) : NA/NaN argument


Now if I add the singularity criterion and make the value smaller than the default of 1E-7 to 1E-9 or 1E-12 which is the default in calibrate, it works. Why is that?

Not being a statistician but a biogeographer using regression as a tool, I don't really understand what is happening here. 

Does changing the tol variable, change how I should interpret goodness-of-fit results or other evaluations of the models created?

I've included a summary of the data below (in case it might be helpful) with all variables in the data frame as it was easier than selecting out the ones used in the model.

Thanks in advance.

T
-- 
Trevor Wiens 
twiens at interbaun.com

The significant problems that we face cannot be solved at the same 
level of thinking we were at when we created them. 
(Albert Einstein)

----------------------------
 summary(datamatrix)
     siteid         block         recordyear        cclo       
 564-125:   5   Min.   :1.000   Min.   :2000   Min.   :0.0000  
 564-130:   5   1st Qu.:2.000   1st Qu.:2001   1st Qu.:1.0000  
 564-135:   5   Median :3.000   Median :2002   Median :1.0000  
 564-140:   5   Mean   :3.042   Mean   :2002   Mean   :0.7509  
 564-145:   5   3rd Qu.:4.000   3rd Qu.:2003   3rd Qu.:1.0000  
 564-150:   5   Max.   :5.000   Max.   :2004   Max.   :1.0000  
 (Other):1098                                                  

      elev            slope            aspect          slr_mean   
 Min.   :0.0000   Min.   :0.1499   Min.   :0.0000   Min.   :7681  
 1st Qu.:0.0000   1st Qu.:0.5876   1st Qu.:0.0000   1st Qu.:7852  
 Median :1.0000   Median :0.9195   Median :0.0000   Median :7877  
 Mean   :0.6259   Mean   :1.2523   Mean   :0.2482   Mean   :7871  
 3rd Qu.:1.0000   3rd Qu.:1.6694   3rd Qu.:0.0000   3rd Qu.:7892  
 Max.   :1.0000   Max.   :5.3366   Max.   :1.0000   Max.   :7981  

       cti           cti_var           planar          feat_div    
 Min.   :7.157   Min.   :0.4497   Min.   :0.0000   Min.   :1.000  
 1st Qu.:7.651   1st Qu.:0.6187   1st Qu.:1.0000   1st Qu.:2.000  
 Median :7.720   Median :0.8495   Median :1.0000   Median :3.000  
 Mean   :7.763   Mean   :0.9542   Mean   :0.8254   Mean   :3.379  
 3rd Qu.:7.822   3rd Qu.:1.1918   3rd Qu.:1.0000   3rd Qu.:4.000  
 Max.   :8.769   Max.   :2.5615   Max.   :1.0000   Max.   :6.000  

   chop_san           loamy            sands            sandy       
 Min.   :0.00000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  
 1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  
 Median :0.00000   Median :0.0000   Median :0.0000   Median :0.0000  
 Mean   :0.05762   Mean   :0.3094   Mean   :0.3236   Mean   :0.1099  
 3rd Qu.:0.00000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000  
 Max.   :1.00000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  
                                                                     
      wet          timesinceburn         ndvi             evi        
 Min.   :0.00000   Min.   :  1.00   Min.   :0.1140   Min.   :0.1041  
 1st Qu.:0.00000   1st Qu.:100.00   1st Qu.:0.2973   1st Qu.:0.1667  
 Median :0.00000   Median :100.00   Median :0.3342   Median :0.2027  
 Mean   :0.01950   Mean   : 87.84   Mean   :0.3629   Mean   :0.2184  
 3rd Qu.:0.00000   3rd Qu.:100.00   3rd Qu.:0.4463   3rd Qu.:0.2711  
 Max.   :1.00000   Max.   :100.00   Max.   :0.5932   Max.   :0.4788  
                                                                     
     msavi2              fc              gdd            precip      
 Min.   :0.09156   Min.   :0.1552   Min.   :380.6   Min.   : 50.04  
 1st Qu.:0.14936   1st Qu.:0.3246   1st Qu.:492.8   1st Qu.: 76.17  
 Median :0.18257   Median :0.4082   Median :500.8   Median : 85.50  
 Mean   :0.19653   Mean   :0.4398   Mean   :476.4   Mean   : 94.35  
 3rd Qu.:0.24626   3rd Qu.:0.5630   3rd Qu.:501.6   3rd Qu.: 95.16  
 Max.   :0.33258   Max.   :0.6996   Max.   :519.7   Max.   :163.86  
                                                                    
    precip_1        precip_2         slr_yr    
 Min.   :164.2   Min.   :164.2   Min.   :7417  
 1st Qu.:254.2   1st Qu.:254.2   1st Qu.:7704  
 Median :338.0   Median :357.1   Median :7775  
 Mean   :298.1   Mean   :301.5   Mean   :7828  
 3rd Qu.:357.1   3rd Qu.:360.5   3rd Qu.:8014  
 Max.   :414.2   Max.   :414.2   Max.   :8151



From Achim.Zeileis at wu-wien.ac.at  Thu Mar 10 22:16:38 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Thu, 10 Mar 2005 22:16:38 +0100
Subject: [R] Question regarding mosaicplot
In-Reply-To: <6.0.0.22.1.20031118232152.01cec730@pop.freesurf.fr>
References: <6.0.0.22.1.20031118232152.01cec730@pop.freesurf.fr>
Message-ID: <20050310221638.7fff1b25.Achim.Zeileis@wu-wien.ac.at>

Jean:

On Tue, 18 Nov 2003 23:32:05 Jean Vidal wrote:

> I tried this : 
> > mosaicplot(stoc ~ q9r + segca,data=tmp2,color=T) : works fine.
> 
> And now, this :
> > mosaicplot(stoc ~ q9r + segca, data=tmp2, color=T, main="Big title")
> Error in model.frame(formula, rownames, variables, varnames, extras,
> extranames,  : 
>         invalid variable type
> 
> I'm probably stupid and missed something simple in the manual (and
> wouldn't like to be flamed if insinuating that, may be... a bug ? Oh
> no !).

OK, so you're getting flamed for something else:

  1. Your example is not reproducible because you didn't provide
     the data (or use artificial data or ...)!
     If I use
       tmp2 <- data.frame(stoc = gl(2, 1, 8), q9r = gl(2, 2, 8),
                          segca = gl(2, 4, 8))
     the above works correct. But then again...
  2. ...your R version is ancient, please upgrade before posting
     such requests!
  3. Please read the posting guide.

Best,
Z


> It can be done with :
> > mosaicplot(table(tmp2$stoc,tmp2$q9r,tmp2$segca),color=T,main="Big
> > title") : works fine.
> 
> So, no real trouble for me... 
> 
> > version
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    1              
> minor    8.0            
> year     2003           
> month    10             
> day      08             
> language R
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From Roger.Bivand at nhh.no  Thu Mar 10 22:36:09 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 10 Mar 2005 22:36:09 +0100 (CET)
Subject: [R] Logistic regression goodness of fit tests
In-Reply-To: <20050310140618.51e3d284.twiens@interbaun.com>
Message-ID: <Pine.LNX.4.44.0503102216380.21499-100000@reclus.nhh.no>

On Thu, 10 Mar 2005, Trevor Wiens wrote:

> I was unsure of what suitable goodness-of-fit tests existed in R for
> logistic regression. After searching the R-help archive I found that
> using the Design models and resid, could be used to calculate this as
> follows:
> 
> d <- datadist(mydataframe)
> options(datadist = 'd')
> fit <- lrm(response ~ predictor1 + predictor2..., data=mydataframe, x =T, y=T)
> resid(fit, 'gof').
> 
> I set up a script to first use glm to create models use stepAIC to
> determine the optimal model. I used this instead of fastbw because I
> found the AIC values to be completely different and the final models
> didn't always match. Then my script takes the reduced model formula and
> recreates it using lrm as above. Now the problem is that for some models
> I run into an error to which I can find no reference whatsoever on the
> mailing list or on the web. It is as follows:
> 
> test.lrm <- lrm(cclo ~ elev + aspect + cti_var + planar + feat_div + loamy + sands + sandy + wet + slr_mean, data=datamatrix, x = T, y = T)
> singular information matrix in lrm.fit (rank= 10 ).  Offending variable(s):
> slr_mean 
> Error in j:(j + params[i] - 1) : NA/NaN argument
> 
> 
> Now if I add the singularity criterion and make the value smaller than
> the default of 1E-7 to 1E-9 or 1E-12 which is the default in calibrate,
> it works. Why is that?
> 
> Not being a statistician but a biogeographer using regression as a tool,
> I don't really understand what is happening here.

>From one geographer to another, and being prepared to bow to
better-founded explanations, you seem to have included a variable - the
offending variable slr_mean - that is very highly correlated with another.  
Making the tolerance tighter says that you are prepared to take the risk
of confounding your results. You've already "been fishing" for right hand
side variables anyway, so your results are somewhat prejudiced, aren't
they?

I think you may also like to review which of the right hand side variables
should be treated as factors rather than numeric (looking at the summary
suggests that many are factors), and perhaps the dependent variable too,
although lrm() seems to take care of this if you haven't.

> 
> Does changing the tol variable, change how I should interpret
> goodness-of-fit results or other evaluations of the models created?
> 
> I've included a summary of the data below (in case it might be helpful)
> with all variables in the data frame as it was easier than selecting out
> the ones used in the model.
> 
> Thanks in advance.
> 
> T
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From f.harrell at vanderbilt.edu  Thu Mar 10 23:19:41 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Thu, 10 Mar 2005 16:19:41 -0600
Subject: [R] Logistic regression goodness of fit tests
In-Reply-To: <20050310140618.51e3d284.twiens@interbaun.com>
References: <20050310140618.51e3d284.twiens@interbaun.com>
Message-ID: <4230C7FD.6080301@vanderbilt.edu>

Trevor Wiens wrote:
> I was unsure of what suitable goodness-of-fit tests existed in R for logistic regression. After searching the R-help archive I found that using the Design models and resid, could be used to calculate this as follows:
> 
> d <- datadist(mydataframe)
> options(datadist = 'd')
> fit <- lrm(response ~ predictor1 + predictor2..., data=mydataframe, x =T, y=T)
> resid(fit, 'gof').
> 
> I set up a script to first use glm to create models use stepAIC to determine the optimal model. I used this instead of fastbw because I found the AIC values to be completely different and the final models didn't always match. Then my script takes the reduced model formula and recreates it using lrm as above. Now the problem is that for some models I run into an error to which I can find no reference whatsoever on the mailing list or on the web. It is as follows:
> 
> test.lrm <- lrm(cclo ~ elev + aspect + cti_var + planar + feat_div + loamy + sands + sandy + wet + slr_mean, data=datamatrix, x = T, y = T)
> singular information matrix in lrm.fit (rank= 10 ).  Offending variable(s):
> slr_mean 
> Error in j:(j + params[i] - 1) : NA/NaN argument
> 
> 
> Now if I add the singularity criterion and make the value smaller than the default of 1E-7 to 1E-9 or 1E-12 which is the default in calibrate, it works. Why is that?
> 
> Not being a statistician but a biogeographer using regression as a tool, I don't really understand what is happening here. 
> 
> Does changing the tol variable, change how I should interpret goodness-of-fit results or other evaluations of the models created?
> 
> I've included a summary of the data below (in case it might be helpful) with all variables in the data frame as it was easier than selecting out the ones used in the model.
> 
> Thanks in advance.
> 
> T

The goodness of fit test only works on prespecified models.  It is not 
valid when stepwise variable selection is used (unless perhaps you use 
alpha=0.5).

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From eric.y.hu at gmail.com  Thu Mar 10 23:25:53 2005
From: eric.y.hu at gmail.com (Eric Hu)
Date: Thu, 10 Mar 2005 14:25:53 -0800
Subject: [R] install R redhat rpm as a normal user
In-Reply-To: <1110468078.7934.29.camel@horizons.localdomain>
References: <a6f83c5a05030916176e99a8e4@mail.gmail.com>
	<1110468078.7934.29.camel@horizons.localdomain>
Message-ID: <0a4a2f9fac755b74540fc4473954b948@gmail.com>

Thank you all.

Best,
Eric
On Mar 10, 2005, at 7:21 AM, Marc Schwartz wrote:

> On Wed, 2005-03-09 at 16:17 -0800, Eric Hu wrote:
>> Hi, I wonder if anyone has done this before. I have rpm-build
>> installed in my workstation. Thanks.
>>
>> Eric
>
>
> I have not seen any other replies to this, but as far as I know 
> Martyn's
> RPMS are not relocatable and a test this morning confirms that.
>
> If you need to install R as a non-root user, you are likely better off
> installing from source code. Modify the "--prefix" argument
> to ./configure as per the R Administration Manual. For example:
>
>   ./configure --prefix="TargetDir"
>
> where TargetDir is a directory that you have write privileges to.
>
> Then use "make" and "make install" which will then build and install R.
>
> R will be installed in TargetDir (ie. "/home/UserName/R") with a set of
> subdirs bin, lib and man. To run R, you would then use:
>
>   TargetDir/bin/R
>
> Or you can create a symlink in /home/UserName/bin to the above file and
> then just use "R" to start it.
>
> See the R Administration Manual for more information.
>
> HTH,
>
> Marc Schwartz
>
>



From twiens at interbaun.com  Thu Mar 10 23:29:20 2005
From: twiens at interbaun.com (Trevor Wiens)
Date: Thu, 10 Mar 2005 15:29:20 -0700
Subject: [R] Logistic regression goodness of fit tests
In-Reply-To: <Pine.LNX.4.44.0503102216380.21499-100000@reclus.nhh.no>
References: <20050310140618.51e3d284.twiens@interbaun.com>
	<Pine.LNX.4.44.0503102216380.21499-100000@reclus.nhh.no>
Message-ID: <20050310152920.4575d455.twiens@interbaun.com>

On Thu, 10 Mar 2005 22:36:09 +0100 (CET)
Roger Bivand <Roger.Bivand at nhh.no> wrote:

> From one geographer to another, and being prepared to bow to
> better-founded explanations, you seem to have included a variable - the
> offending variable slr_mean - that is very highly correlated with another.  
> Making the tolerance tighter says that you are prepared to take the risk
> of confounding your results. You've already "been fishing" for right hand
> side variables anyway, so your results are somewhat prejudiced, aren't
> they?
> 
> I think you may also like to review which of the right hand side variables
> should be treated as factors rather than numeric (looking at the summary
> suggests that many are factors), and perhaps the dependent variable too,
> although lrm() seems to take care of this if you haven't.
> 

Thanks for your informative reply.

The nature of the research is habitat selection for 15 species of grassland birds (my masters project).  The response here is presence of Chestnut-collared Longsur (cclo). I very carefull reviewed the variables for collinearity and none of them showed any difficulty except in a few cases which I've used to break some cases into two models where one would have otherwise seemed reasonable. Just out of interest however I did run the global model, and this problem didn't occur, which seems to indicate to me, based on your comments, I'm seeing an interaction effect, not a result of two closely correlated variables. 

I don't think I've been fishing. I selected variables for inclusion in competing models based on ecologically reasonable criteria. I did examine relationships between species occurance and static variables such as dem derived variables, to see if the data supported including all variables that based on ecological criteria should explain the birds distribution. I have included some variables inspite of weak statistical relationships based on a paper by Anderson, Burnham and Thompson in Journal of Wildlife Management which talks about how factors that are ecologically significant, can have interaction effects in a model to provide explanation in your response variable, even though individually they are not statistically significant by themselves. So, I've tried to avoid fishing, but instead simply trying to select the most parsimonious models from the set of selected models for each species.

Based on your advice once I've selected my top candidate models, I'll re-run at lower tolerances and only keep models that can pass at that level. Alternatively I could simply reject models that don't pass at lower tolerances. I do find it curious however that they run fine using glm (family = binomial) without complaint.

Thanks again.

T
-- 
Trevor Wiens 
twiens at interbaun.com

The significant problems that we face cannot be solved at the same 
level of thinking we were at when we created them. 
(Albert Einstein)



From twiens at interbaun.com  Thu Mar 10 23:49:13 2005
From: twiens at interbaun.com (Trevor Wiens)
Date: Thu, 10 Mar 2005 15:49:13 -0700
Subject: [R] Logistic regression goodness of fit tests
In-Reply-To: <4230C7FD.6080301@vanderbilt.edu>
References: <20050310140618.51e3d284.twiens@interbaun.com>
	<4230C7FD.6080301@vanderbilt.edu>
Message-ID: <20050310154913.0d4b03e4.twiens@interbaun.com>

On Thu, 10 Mar 2005 16:19:41 -0600
Frank E Harrell Jr <f.harrell at vanderbilt.edu> wrote:

> The goodness of fit test only works on prespecified models.  It is not 
> valid when stepwise variable selection is used (unless perhaps you use 
> alpha=0.5).
> 

Perhaps I'm blind, but I can't find any reference to an alpha parameter on the help page for stepAIC. It runs fine however when I set the parameter and produces as model with the same right hand variables as without. Can you tell me what it is ?

T
-- 
Trevor Wiens 
twiens at interbaun.com

The significant problems that we face cannot be solved at the same 
level of thinking we were at when we created them. 
(Albert Einstein)



From murdoch at stats.uwo.ca  Thu Mar 10 23:55:39 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 10 Mar 2005 22:55:39 +0000
Subject: [R] Is anyone using the MiniR distribution?
In-Reply-To: <i22701hrulp6s3oggmrcuq5m41u21ip6g6@4ax.com>
References: <btg601p2sr5cdsj8fc49qa4t1ssfsqpt6d@4ax.com>
	<16899.31899.47067.432764@stat.math.ethz.ch>
	<i22701hrulp6s3oggmrcuq5m41u21ip6g6@4ax.com>
Message-ID: <ivj13110b6cgkst1jac6ea65v8if4tk3n8@4ax.com>

On Fri, 04 Feb 2005 14:45:35 +0000, Duncan Murdoch
<murdoch at stats.uwo.ca> wrote :

>On Fri, 4 Feb 2005 14:46:03 +0100, Martin Maechler
><maechler at stat.math.ethz.ch> wrote :
>
>>
>>>>>>> "Duncan" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>>>     on Fri, 04 Feb 2005 09:50:22 +0000 writes:
>
>>    Duncan> The miniR files only include a minimal installation
>>    Duncan> of R, and are rarely tested.  Rather than building
>>    Duncan> something that may not even work, I'd like to stop
>>    Duncan> building them.
>>
>>    Duncan> Would this be a problem for anyone?
>>
>>
>>People for which this is a problem will probably not be
>>subscribed to R-help because they'll be living in places /
>>situations with bad / expensive internet connection.
>>
>>(Sorry to be not really constructive here).
>
>That's a good point; I'll put a copy of my question in the miniR
>directory on CRAN.  It's not a big problem to build it, but I don't
>want to test it if it's not being used.  

Not having heard any complaints on this issue, I have now stopped
building the mini distribution.  I have taken the 2.0.1 files offline
(but still have them available in case this causes hardship for
anyone).

Duncan Murdoch



From kingroi at hotmail.com  Fri Mar 11 00:43:16 2005
From: kingroi at hotmail.com (paul king)
Date: Thu, 10 Mar 2005 23:43:16 +0000
Subject: [R] Any upcoming R Advanced Programming in Bay area?
Message-ID: <BAY16-F263F696616D58237D437EBB0520@phx.gbl>

Hi all,

I am taking a new job in San Francisco and wonder if there's an upcoming
R advanced course in bay area.

Best- Paul



From Innkeyp-r at yahoo.com  Fri Mar 11 00:50:16 2005
From: Innkeyp-r at yahoo.com (T Petersen)
Date: Fri, 11 Mar 2005 00:50:16 +0100
Subject: [R] Setting variable main in plot-function
Message-ID: <4230DD38.7000103@yahoo.com>

Hi,

I am plotting the residuals of z like this

plot(resid(z))

and I want the title of the graph to be

main="Residuals from regression [name of regression]"

where in this case "z" is the name of the regression. Is there a way to 
automaticall put the name of the regression in the title, e.g if the 
regressions name changes to "y", the title changes accordingly?

Regards T Petersen



From martin at metahuman.org  Fri Mar 11 01:52:29 2005
From: martin at metahuman.org (Martin C. Martin)
Date: Thu, 10 Mar 2005 19:52:29 -0500
Subject: [R] Ploting a function of two arguments
Message-ID: <4230EBCD.2060001@metahuman.org>

Hi,

I've written a function:

myfun <- function(x, y) {
   // blah blah
}

and I want to graph it.  My plan is to use persp(), and my question is: 
how do I create the array of values?  One possibility is:

x <- seq(0, 10, by=.1)
y <- seq(0, 10, by=.1)

inputs <- <somehow create an array of x,y pairs>

outputs <- apply(A, c(1,2), myfun)

The "inputs" array would need to be 101x101x2 array, i.e. basically a 2D 
array of pairs.  I might need to write a little wrapper for myfun.

Am I on the right track, or is there an easier way to do this?  It seems 
there should be an easier way to graph a 2 argument function like this.

- Martin



From dreinke at dowlinginc.com  Fri Mar 11 01:52:40 2005
From: dreinke at dowlinginc.com (David Reinke)
Date: Thu, 10 Mar 2005 16:52:40 -0800
Subject: [R] trouble loading R function code
Message-ID: <200503110052.j2B0qh5c025454@hypatia.math.ethz.ch>

I created an R function offline with a text editor and saved it as fhv.R
When I type in 
load(file="fhv.R")
I get the message
Error: bad restore file magic number (file may be corrupted)-- no data
loaded
I've checked the file, and it opens up fine in Notepad and other text
editors. I also tried this from another folder and got the same message.
What's going on?
Thanks in advance.

David Reinke

Senior Transportation Engineer/Economist
Dowling Associates, Inc.
180 Grand Avenue, Suite 250
Oakland, California 94612-3774
510.839.1742 x104 (voice)
510.839.0871 (fax)
www.dowlinginc.com



From martin at metahuman.org  Fri Mar 11 02:04:33 2005
From: martin at metahuman.org (Martin C. Martin)
Date: Thu, 10 Mar 2005 20:04:33 -0500
Subject: [R] trouble loading R function code
In-Reply-To: <200503110052.j2B0qh5c025454@hypatia.math.ethz.ch>
References: <200503110052.j2B0qh5c025454@hypatia.math.ethz.ch>
Message-ID: <4230EEA1.4070707@metahuman.org>

try:

source("fhv.R")

David Reinke wrote:

> I created an R function offline with a text editor and saved it as fhv.R
> When I type in 
> load(file="fhv.R")
> I get the message
> Error: bad restore file magic number (file may be corrupted)-- no data
> loaded
> I've checked the file, and it opens up fine in Notepad and other text
> editors. I also tried this from another folder and got the same message.
> What's going on?
> Thanks in advance.
> 
> David Reinke
> 
> Senior Transportation Engineer/Economist
> Dowling Associates, Inc.
> 180 Grand Avenue, Suite 250
> Oakland, California 94612-3774
> 510.839.1742 x104 (voice)
> 510.839.0871 (fax)
> www.dowlinginc.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From chris at subtlety.com  Fri Mar 11 02:11:08 2005
From: chris at subtlety.com (Chris Bergstresser)
Date: Thu, 10 Mar 2005 19:11:08 -0600
Subject: [R] Errors reading data file?
In-Reply-To: <20050302082421.73405.qmail@web25805.mail.ukl.yahoo.com>
References: <20050302082421.73405.qmail@web25805.mail.ukl.yahoo.com>
Message-ID: <4230F02C.7090402@subtlety.com>

Hi all --

    I tried loading a data file with the following command:

 > data = read.table("filename.txt", header = TRUE, sep = ",")

    This appeared to work fine, except it silently skipped 400 records 
(out of 1200).  It turns out, some of the text fields included quotes, 
and I needed to use 'quote = ""'.
    Why wasn't there an error message?  Is there some way to enable one?

-- Chris



From cgormally at plantbio.uga.edu  Fri Mar 11 02:40:38 2005
From: cgormally at plantbio.uga.edu (Cara Gormally)
Date: Thu, 10 Mar 2005 20:40:38 -0500
Subject: [R] Bonferroni simultaneous confidence intervals for multiple
	regression
Message-ID: <20050310204038.c5930525@dogwood.plantbio.uga.edu>

Hi,

I'm having no luck figuring out how to find Bonferroni simultaneous confidence intervals to obtain a family of estimates in R.  Does anyone know how to do this?
Thank you!



From MSchwartz at MedAnalytics.com  Fri Mar 11 02:55:51 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu, 10 Mar 2005 19:55:51 -0600
Subject: [R] Setting variable main in plot-function
In-Reply-To: <4230DD38.7000103@yahoo.com>
References: <4230DD38.7000103@yahoo.com>
Message-ID: <1110506151.14726.35.camel@horizons.localdomain>

On Fri, 2005-03-11 at 00:50 +0100, T Petersen wrote:
> Hi,
> 
> I am plotting the residuals of z like this
> 
> plot(resid(z))
> 
> and I want the title of the graph to be
> 
> main="Residuals from regression [name of regression]"
> 
> where in this case "z" is the name of the regression. Is there a way to 
> automaticall put the name of the regression in the title, e.g if the 
> regressions name changes to "y", the title changes accordingly?


I am presuming that by the name of the regression, you mean the model
formula.

Using one of the example models from ?lm, where a model is created
called "lm.D9":

plot(resid(lm.D9), 
     main = paste("Residuals from regression", deparse(lm.D9$call)))

In this case, the model function call is:

> deparse(lm.D9$call)
[1] "lm(formula = weight ~ group)"

which gets pasted to your initial text. The initial model function call
is stored in the linear model object as ModelName$call.

So in your case use:

plot(resid(z), 
     main = paste("Residuals from regression", deparse(z$call)))

Just replace 'z' with the name of each new model object and the title
will change or use the same model object name each time you create a new
model, whichever makes sense for your application.

One way to figure these things out, if you know that it has been done by
some other function, is to review the code for that function. In this
case review the code for print.lm or even plot.lm to gain some insight
into how R expressions are used in function text or plot title and axis
label outputs.

HTH,

Marc Schwartz



From br44114 at yahoo.com  Fri Mar 11 03:19:26 2005
From: br44114 at yahoo.com (bogdan romocea)
Date: Thu, 10 Mar 2005 18:19:26 -0800 (PST)
Subject: [R] XML to data frame or list
Message-ID: <20050311021926.61533.qmail@web50106.mail.yahoo.com>

Dear useRs,

I have a simple/RTFM question about XML parsing. Given an XML file,
such as (fragment)
<A>100</A>
<B>23</B>
<C>true</C>
how do I import it in a data frame or list, so that the values (100,
23, true) can be accessed through the names A, B and C?

I installed the XML package and looked over the documentation...
however after 20 minutes and a couple of tests I still don't know what
I should start with. 

Can someone provide an example or point me to the appropriate
function(s)?

Thank you,
b.



From keithw at galen.med.usyd.edu.au  Fri Mar 11 03:47:50 2005
From: keithw at galen.med.usyd.edu.au (Keith Wong)
Date: Fri, 11 Mar 2005 13:47:50 +1100
Subject: [R] How to reply to a posting if I subscribe to the digest version
 of R-help?
Message-ID: <6.0.0.22.2.20050311134517.01ea12d0@mail.med.usyd.edu.au>

Dear listmembers,

Is there a recommended method of responding to a thread if I am getting the 
mailing list in digest form?

Will the mailing list program automatically match threads if I copy the 
subject from the original posting?

Thank you.

Keith



From andy_liaw at merck.com  Fri Mar 11 03:48:51 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 10 Mar 2005 21:48:51 -0500
Subject: [R] Ploting a function of two arguments
Message-ID: <3A822319EB35174CA3714066D590DCD50994E827@usrymx25.merck.com>

There are at least two options:

1. Use outer(); e.g., something like z <- outer(x, y, f).

2. Use expand.grid(x, y), then call f() with the output.

Andy

> From: Martin C. Martin
> 
> Hi,
> 
> I've written a function:
> 
> myfun <- function(x, y) {
>    // blah blah
> }
> 
> and I want to graph it.  My plan is to use persp(), and my 
> question is: 
> how do I create the array of values?  One possibility is:
> 
> x <- seq(0, 10, by=.1)
> y <- seq(0, 10, by=.1)
> 
> inputs <- <somehow create an array of x,y pairs>
> 
> outputs <- apply(A, c(1,2), myfun)
> 
> The "inputs" array would need to be 101x101x2 array, i.e. 
> basically a 2D 
> array of pairs.  I might need to write a little wrapper for myfun.
> 
> Am I on the right track, or is there an easier way to do 
> this?  It seems 
> there should be an easier way to graph a 2 argument function 
> like this.
> 
> - Martin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From sell_mirage_ne at hotmail.com  Fri Mar 11 03:54:37 2005
From: sell_mirage_ne at hotmail.com (mirage sell)
Date: Thu, 10 Mar 2005 20:54:37 -0600
Subject: [R] sample function
Message-ID: <BAY10-F303206AF04A6B0EE46602FC7530@phx.gbl>

Hi everyone, I need help.
I want to have a "uniform" kind distribution. When I used sample function I 
got almost twice many zeros compared to other numbers. What's wrong with my 
command ?

temp <-sample(0:12, 2000, replace=T,prob=(rep(1/13,13)))
hist(temp)

Thanks in advance,

Taka,



From martin at metahuman.org  Fri Mar 11 04:05:11 2005
From: martin at metahuman.org (Martin C. Martin)
Date: Thu, 10 Mar 2005 22:05:11 -0500
Subject: [R] sample function
In-Reply-To: <BAY10-F303206AF04A6B0EE46602FC7530@phx.gbl>
References: <BAY10-F303206AF04A6B0EE46602FC7530@phx.gbl>
Message-ID: <42310AE7.4050505@metahuman.org>

"hist" is lumping things together.

Try:
sum(temp == 0)

compare to the height of the left most bar.

Is this a bug in hist?

- Martin

mirage sell wrote:

> Hi everyone, I need help.
> I want to have a "uniform" kind distribution. When I used sample 
> function I got almost twice many zeros compared to other numbers. What's 
> wrong with my command ?
> 
> temp <-sample(0:12, 2000, replace=T,prob=(rep(1/13,13)))
> hist(temp)
> 
> Thanks in advance,
> 
> Taka,
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Fri Mar 11 04:05:15 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 10 Mar 2005 22:05:15 -0500
Subject: [R] sample function
Message-ID: <3A822319EB35174CA3714066D590DCD50994E828@usrymx25.merck.com>

It's not the simulated data, but how hist() handled it.  If you use
truehist() in the MASS package, you don't see the problem.  Nor would you
see it like this:

> table(temp)/length(temp)
temp
     0      1      2      3      4      5      6      7      8      9     10
11 
0.0745 0.0745 0.0830 0.0755 0.0760 0.0750 0.0700 0.0765 0.0775 0.0805 0.0830
0.0765 
    12 
0.0775 

Andy

> From: mirage sell
> 
> Hi everyone, I need help.
> I want to have a "uniform" kind distribution. When I used 
> sample function I 
> got almost twice many zeros compared to other numbers. What's 
> wrong with my 
> command ?
> 
> temp <-sample(0:12, 2000, replace=T,prob=(rep(1/13,13)))
> hist(temp)
> 
> Thanks in advance,
> 
> Taka,
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From d.scott at auckland.ac.nz  Fri Mar 11 04:13:01 2005
From: d.scott at auckland.ac.nz (David Scott)
Date: Fri, 11 Mar 2005 16:13:01 +1300 (NZDT)
Subject: [R] sample function
In-Reply-To: <BAY10-F303206AF04A6B0EE46602FC7530@phx.gbl>
References: <BAY10-F303206AF04A6B0EE46602FC7530@phx.gbl>
Message-ID: <Pine.LNX.4.61.0503111610190.3043@stat12.stat.auckland.ac.nz>

On Thu, 10 Mar 2005, mirage sell wrote:

> Hi everyone, I need help.
> I want to have a "uniform" kind distribution. When I used sample function I 
> got almost twice many zeros compared to other numbers. What's wrong with my 
> command ?
>

Nothing is wrong with your sampling, it is the display in the histogram.

Try
temp <-sample(0:12, 2000, replace=T,prob=(rep(1/13,13)))
table(temp)

David Scott

_________________________________________________________________
David Scott	Department of Statistics, Tamaki Campus
 		The University of Auckland, PB 92019
 		Auckland	NEW ZEALAND
Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
Email:	d.scott at auckland.ac.nz


Graduate Officer, Department of Statistics



From d.scott at auckland.ac.nz  Fri Mar 11 04:17:49 2005
From: d.scott at auckland.ac.nz (David Scott)
Date: Fri, 11 Mar 2005 16:17:49 +1300 (NZDT)
Subject: [R] sample function
In-Reply-To: <42310AE7.4050505@metahuman.org>
References: <BAY10-F303206AF04A6B0EE46602FC7530@phx.gbl>
	<42310AE7.4050505@metahuman.org>
Message-ID: <Pine.LNX.4.61.0503111616190.3043@stat12.stat.auckland.ac.nz>

On Thu, 10 Mar 2005, Martin C. Martin wrote:

> "hist" is lumping things together.
>
> Try:
> sum(temp == 0)
>
> compare to the height of the left most bar.
>
> Is this a bug in hist?
>
No, hist is the wrong thing to use to display this data.

Try

temp <-sample(0:12, 2000, replace=T,prob=(rep(1/13,13)))
barplot(table(temp))

David Scott
_________________________________________________________________
David Scott	Department of Statistics, Tamaki Campus
 		The University of Auckland, PB 92019
 		Auckland	NEW ZEALAND
Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
Email:	d.scott at auckland.ac.nz


Graduate Officer, Department of Statistics



From MSchwartz at MedAnalytics.com  Fri Mar 11 04:20:15 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu, 10 Mar 2005 21:20:15 -0600
Subject: [R] sample function
In-Reply-To: <BAY10-F303206AF04A6B0EE46602FC7530@phx.gbl>
References: <BAY10-F303206AF04A6B0EE46602FC7530@phx.gbl>
Message-ID: <1110511216.14726.52.camel@horizons.localdomain>

On Thu, 2005-03-10 at 20:54 -0600, mirage sell wrote:
> Hi everyone, I need help.
> I want to have a "uniform" kind distribution. When I used sample function I 
> got almost twice many zeros compared to other numbers. What's wrong with my 
> command ?
> 
> temp <-sample(0:12, 2000, replace=T,prob=(rep(1/13,13)))
> hist(temp)
> 
> Thanks in advance,

Hint: take note that there are only 12 cells in the plot, not 13...

However, note that the frequency of the 13 elements are appropriate:

> table(sample(0:12, 2000, replace=T))

  0   1   2   3   4   5   6   7   8   9  10  11  12
158 156 151 163 156 158 146 154 134 158 146 147 173


Review the details of how the breaks are selected in ?hist.

BTW, you do not need to specify the 'prob' argument if you want equal
probabilities as per my example above.

HTH,

Marc Schwartz



From blindglobe at gmail.com  Fri Mar 11 06:39:39 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Fri, 11 Mar 2005 06:39:39 +0100
Subject: [R] Interval censoring in Survival analysis
In-Reply-To: <Pine.A41.4.61b.0503100756110.145576@homer10.u.washington.edu>
References: <66373AD054447F47851FCC5EB49B36116CF155@basquet.imim.es>
	<Pine.A41.4.61b.0503100756110.145576@homer10.u.washington.edu>
Message-ID: <1abe3fa905031021394512aabf@mail.gmail.com>

On Thu, 10 Mar 2005 08:01:57 -0800 (PST), Thomas Lumley
<tlumley at u.washington.edu> wrote:
> On Thu, 10 Mar 2005, AMOROS NAVARRO, ALEX wrote:
> 
> I am not aware of any package that allows semiparametric regression
> modelling of interval censored or doubly censored data.

I'm aware of 2 such packages, but the one that is more accurate won't
be published due to licensing restrictions on one of the subcomponents
(nonlinear programming with nonlinear constraints optimizer), and the
other is less accurate (a profiling approach) and shouldn't be.

That being said, I'm sure others have tried.

-- 
best,
-tony

"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).

A.J. Rossini
blindglobe at gmail.com



From jean.vidal at freesurf.fr  Fri Mar 11 07:34:04 2005
From: jean.vidal at freesurf.fr (Jean Vidal)
Date: Fri, 11 Mar 2005 07:34:04 +0100
Subject: Apologies --- Re: [R] Question regarding mosaicplot
In-Reply-To: <20050310221638.7fff1b25.Achim.Zeileis@wu-wien.ac.at>
References: <6.0.0.22.1.20031118232152.01cec730@pop.freesurf.fr>
	<20050310221638.7fff1b25.Achim.Zeileis@wu-wien.ac.at>
Message-ID: <6.0.0.22.0.20050311073047.01d1a228@pop.freesurf.fr>

May I present my apologies to all, on this list, and to you Achim ?
It's an old message that was sent by accident yesterday when testing the 
Thunderbird mail program.

So, please, ignore this question. It was answered and solved months ago.





At 22:16 10/03/2005, Achim Zeileis wrote:
>Jean:
>
>On Tue, 18 Nov 2003 23:32:05 Jean Vidal wrote:
>
> > I tried this :
> > > mosaicplot(stoc ~ q9r + segca,data=tmp2,color=T) : works fine.
> >
> > And now, this :
> > > mosaicplot(stoc ~ q9r + segca, data=tmp2, color=T, main="Big title")
> > Error in model.frame(formula, rownames, variables, varnames, extras,
> > extranames,  :
> >         invalid variable type
> >
> > I'm probably stupid and missed something simple in the manual (and
> > wouldn't like to be flamed if insinuating that, may be... a bug ? Oh
> > no !).
>
>OK, so you're getting flamed for something else:
>
>   1. Your example is not reproducible because you didn't provide
>      the data (or use artificial data or ...)!
>      If I use
>        tmp2 <- data.frame(stoc = gl(2, 1, 8), q9r = gl(2, 2, 8),
>                           segca = gl(2, 4, 8))
>      the above works correct. But then again...
>   2. ...your R version is ancient, please upgrade before posting
>      such requests!
>   3. Please read the posting guide.
>
>Best,
>Z
>
>
> > It can be done with :
> > > mosaicplot(table(tmp2$stoc,tmp2$q9r,tmp2$segca),color=T,main="Big
> > > title") : works fine.
> >
> > So, no real trouble for me...
> >
> > > version
> >          _
> > platform i386-pc-mingw32
> > arch     i386
> > os       mingw32
> > system   i386, mingw32
> > status
> > major    1
> > minor    8.0
> > year     2003
> > month    10
> > day      08
> > language R
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >



From tpeng at u.washington.edu  Fri Mar 11 07:39:01 2005
From: tpeng at u.washington.edu (tpeng@u.washington.edu)
Date: Thu, 10 Mar 2005 22:39:01 -0800 (PST)
Subject: [R] help on warning message when using anova
Message-ID: <Pine.LNX.4.43.0503102239010.20124@hymn07.u.washington.edu>

Hi can someone help me with the following warning message I got when I used two
way anova: Warning messages: 1: Models with response "NULL" removed because
response differs from model 1 in: anova.lmlist(object, ...) 2: Models with
response "NULL" removed because response differs from model 1 in:
anova.lmlist(object, ...)
 (I have two rows of separate data sets)

Thanks in advance,

tao



From mike.rstat at gmail.com  Fri Mar 11 07:43:47 2005
From: mike.rstat at gmail.com (Mike R)
Date: Thu, 10 Mar 2005 22:43:47 -0800
Subject: [R] howto: plot location, web search
Message-ID: <27db823f05031022433178ea21@mail.gmail.com>

Hi,

new to the list, R and rpy. my first post.

using rpy, i find this

  r.X11(height=3, width=6)

allows me to preset the size of a subsequent

   r.plot(x, y)

but i've been unable to find documention on related aspects, such as
programatic control of the plot window location on the monitor, or
programatic resizing of a plot once it is generated. Are these
possible?

In general I've found it diffcult to use google to search for answers
because "R" is not a very effective keyword. Are there tricks to
googling for R info?  And If a start a web accessible html page for R,
what keywords can I include that would make it easier for search
engines to index so that other R-folk could find it?

Thanks in advance,
mike



From dieter.menne at menne-biomed.de  Fri Mar 11 08:35:04 2005
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Fri, 11 Mar 2005 08:35:04 +0100
Subject: [R] xlab cex bug in Lattice/grid and multipage-output (Windows
	only?)
Message-ID: <INEGIMHGODBGKFPOJBBMKEGPCDAA.dieter.menne@menne-biomed.de>


The following problem seems to be Windows-specific. Deepayan informed me
that it cannot be reproduced on "platform i386-pc-linux-gnu".

-----
library(lattice)
trellis.device("png", file="sepal%02d.png",color=T,  theme="col.whitebg")
p=xyplot(Sepal.Length + Sepal.Width ~ Petal.Length + Petal.Width | Species,
       data = iris, scales = "free", layout = c(1, 1)
       )

print(p)
dev.off()
----

Compare the x-label on the first and on all following pages: font size is
different.
Same for bmp. Does not occur on multipage-devices such as ps.
By comparing with the png files from Deepayan/Linux, I believe that only the
first xlab has the correct small size, and all others are not correct.

My version: (all libraries updated today)
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    0.1
year     2004
month    11
day      15
language R



From Tom.Mulholland at dpi.wa.gov.au  Fri Mar 11 08:42:31 2005
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Fri, 11 Mar 2005 15:42:31 +0800
Subject: [R] howto: plot location, web search
Message-ID: <33F91FB3FDF42E4180428AC66A5CF30B02D3BA96@afhex01.dpi.wa.gov.au>

If it's specifically R that I am looking for I use the following link http://finzi.psych.upenn.edu/search.html

If I were going to use google I would go to the advanced page and insert finzi.psych.upenn.edu into the "Domain" field so as to restrict the search. As you have found out the letter R is ubiquitous. There are other search engines listed on the CRAN website that you can also use http://cran.r-project.org/search.html

However rpy is much less frequent. In fact google comes up with it straight away. From that I discovered that RPy has a mailing list http://rpy.sourceforge.net/maillist.html. Maybe you should try searching their archives http://rpy.sourceforge.net/maillist.html. 

I hope that helps

Tom

> -----Original Message-----
> From: Mike R [mailto:mike.rstat at gmail.com]
> Sent: Friday, 11 March 2005 2:44 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] howto: plot location, web search
> 
> 
> Hi,
> 
> new to the list, R and rpy. my first post.
> 
> using rpy, i find this
> 
>   r.X11(height=3, width=6)
> 
> allows me to preset the size of a subsequent
> 
>    r.plot(x, y)
> 
> but i've been unable to find documention on related aspects, such as
> programatic control of the plot window location on the monitor, or
> programatic resizing of a plot once it is generated. Are these
> possible?
> 
> In general I've found it diffcult to use google to search for answers
> because "R" is not a very effective keyword. Are there tricks to
> googling for R info?  And If a start a web accessible html page for R,
> what keywords can I include that would make it easier for search
> engines to index so that other R-folk could find it?
> 
> Thanks in advance,
> mike
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From Tom.Mulholland at dpi.wa.gov.au  Fri Mar 11 08:50:07 2005
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Fri, 11 Mar 2005 15:50:07 +0800
Subject: [R] howto: plot location, web search
Message-ID: <33F91FB3FDF42E4180428AC66A5CF30B02D3C9BF@afhex01.dpi.wa.gov.au>

Sorry about the wrong link. The archives are at http://sourceforge.net/mailarchive/forum.php?forum=rpy-list

> -----Original Message-----
> From: Mike R [mailto:mike.rstat at gmail.com]
> Sent: Friday, 11 March 2005 2:44 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] howto: plot location, web search
> 
> 
> Hi,
> 
> new to the list, R and rpy. my first post.
> 
> using rpy, i find this
> 
>   r.X11(height=3, width=6)
> 
> allows me to preset the size of a subsequent
> 
>    r.plot(x, y)
> 
> but i've been unable to find documention on related aspects, such as
> programatic control of the plot window location on the monitor, or
> programatic resizing of a plot once it is generated. Are these
> possible?
> 
> In general I've found it diffcult to use google to search for answers
> because "R" is not a very effective keyword. Are there tricks to
> googling for R info?  And If a start a web accessible html page for R,
> what keywords can I include that would make it easier for search
> engines to index so that other R-folk could find it?
> 
> Thanks in advance,
> mike
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From gasper.cankar at ric.si  Fri Mar 11 10:00:16 2005
From: gasper.cankar at ric.si (Gasper Cankar)
Date: Fri, 11 Mar 2005 10:00:16 +0100
Subject: [R] name of object from character vector
Message-ID: <7BD626BBA7717A49816E995DF152C04A3AB600@intra2003.ric.si>

Hello everyone!

A simple question (I'm not sure about the answer):

How can I give a name to my data.frame from a character vector of names? 
For example, each data.frame is a table of results for a subject and I have a vector of subject names like

b <- c("math", "geography", "history")

How do I create a data.frame named "math" by calling b[1]? 

I'm importing data via RODBC in one big loop for all subjects and
I want them separated so I'll be able to load them one at a time later on. 

Thanks for your help,

Gasper


Gasper Cankar
National Examinations Centre
Slovenia
+386 1 54 84 682
gasper.cankarATric.si



From dimitris.rizopoulos at med.kuleuven.ac.be  Fri Mar 11 10:16:12 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Fri, 11 Mar 2005 10:16:12 +0100
Subject: [R] name of object from character vector
References: <7BD626BBA7717A49816E995DF152C04A3AB600@intra2003.ric.si>
Message-ID: <00ae01c5261a$f87eec80$0540210a@www.domain>

look at "?assign", e.g.,


b <- c("math", "geography", "history")
assign(b[1], data.frame(x=rnorm(5), y=rnorm(5)))
math


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Gasper Cankar" <gasper.cankar at ric.si>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, March 11, 2005 10:00 AM
Subject: [R] name of object from character vector


> Hello everyone!
>
> A simple question (I'm not sure about the answer):
>
> How can I give a name to my data.frame from a character vector of 
> names?
> For example, each data.frame is a table of results for a subject and 
> I have a vector of subject names like
>
> b <- c("math", "geography", "history")
>
> How do I create a data.frame named "math" by calling b[1]?
>
> I'm importing data via RODBC in one big loop for all subjects and
> I want them separated so I'll be able to load them one at a time 
> later on.
>
> Thanks for your help,
>
> Gasper
>
>
> Gasper Cankar
> National Examinations Centre
> Slovenia
> +386 1 54 84 682
> gasper.cankarATric.si
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From Stephan.Freyberger at rwth-aachen.de  Fri Mar 11 10:53:21 2005
From: Stephan.Freyberger at rwth-aachen.de (Stephan Freyberger)
Date: Fri, 11 Mar 2005 09:53:21 +0000 (GMT)
Subject: [R] RODBC Package
Message-ID: <1564b6154122.1541221564b6@post.rwth-aachen.de>

Hello R-Help,

is there any way of using the RODBC Package on a Mac OS X 
System? If yes, what do I need to get it running. Concerning these 
issues, I am pretty unexperienced, so please state any step 
necessary. The actual problem is accessing data in Excel- files. 
(unfortunately no alternative way of entering the data). 
I already installed the Package, but it says the following:

> versuch <- odbcConnectExcel("Thermanali-Versuch.xls")
Error: couldn't find function "odbcConnectExcel"

Thanks in Advance

Stephan Freyberger



From dieter.menne at menne-biomed.de  Fri Mar 11 11:35:08 2005
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Fri, 11 Mar 2005 10:35:08 +0000 (UTC)
Subject: [R] Bonferroni simultaneous confidence intervals for
	=?utf-8?b?bXVsdGlwbGUJcmVncmVzc2lvbg==?=
References: <20050310204038.c5930525@dogwood.plantbio.uga.edu>
Message-ID: <loom.20050311T113316-789@post.gmane.org>

Cara Gormally <cgormally <at> plantbio.uga.edu> writes:

> I'm having no luck figuring out how to find Bonferroni simultaneous 
confidence intervals to obtain a
> family of estimates in R.  

Try package multcomp (no Bonferroni, but more powerful alternatives) or 
multtest on Bioconductor (Bonferroni-family, but only p-value).

Dieter Menne



From wildscop at yahoo.com  Fri Mar 11 12:07:56 2005
From: wildscop at yahoo.com (Mohammad Ehsanul Karim)
Date: Fri, 11 Mar 2005 03:07:56 -0800 (PST)
Subject: [R] Calculating lengths of runs of 0 or 1 sequences in
	meteorological data
Message-ID: <20050311110756.95105.qmail@web52605.mail.yahoo.com>

Dear List Members,

I need some help about programming in S language. My
problem is as follows:

I have meteorological data (about rainfall measurement
each day from 1989-2002), say like 
http://www.angelfire.com/ab5/get5/data.rainfall.txt 
or http://www.angelfire.com/ab5/get5/R.rainfall.txt
in a sequence of 0(denoting dry day)'s and 1(denoting
wet day)'s. I want to construct a frequency
distribution table of various lengths
(1,2,3,4,5,6,7,8,9,or more) of observed wet spells
(number of successive 1's) and dry spells (number of
successive 0's) occurring in data.

How should i proceed? Is there any existing
program/function/package to solve such problem (seems
like the algorithm should be similar to statistical
run test)?

Any suggestion, direction, references, help, replies
will be highly appreciated.

Thank you for your time.

_____________________________

Mohammad Ehsanul Karim
E-mail: wildscop at yahoo.com
Web: http://snipurl.com/ehsan
ISRT, University of Dhaka, BD



From Ted.Harding at nessie.mcc.ac.uk  Fri Mar 11 11:59:55 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 11 Mar 2005 10:59:55 -0000 (GMT)
Subject: [R] sample function
In-Reply-To: <42310AE7.4050505@metahuman.org>
Message-ID: <XFMail.050311105955.Ted.Harding@nessie.mcc.ac.uk>

On 11-Mar-05 Martin C. Martin wrote:
> "hist" is lumping things together.
> 
> Try:
> sum(temp == 0)
> 
> compare to the height of the left most bar.
> 
> Is this a bug in hist?
> 
> - Martin

Well, not a bug strictly speaking since "it works as documented",
but I do think it's not necessarily a happy choice.

The unsuspecting (like Martin) will step into holes even after
reading "?hist", since the truths are rather deeply (and I think
somewhat obliquely) hidden ("?hist" leads you to look up
"?nclass.Sturges" which in turn only mentions "Sturges' formula"
and invites you to read V&R's MASS book and other references
in the hope of further clarification -- all a bit much when
you just want to draw a histogram, which ought to be kid's
stuff! Not to mention the things to do with parameters
"include.lowest" and "right" whose combined effect is not
too obvious).

I'd like to repeat the sort of hint I occasionally give:

In using R, if there's any doubt it is best to spell out exactly
what you want rather than expecting the functions to agree with
what you want. R functions are often more complex and subtle
than you might suspect.

In this particular case,

  hist(temp,breaks= -0.5+(-0:14) )

will produce the sort of thing which is wanted. One could
interpret the results which Martin reported as due to a
sort of "confusion" (but on whose part -- R or Martin?)
over the fact that "hist" is designed to deal with
"continuous" values, while his sample consists of integers.

For that particular case, one could also use "table" or
"barchart", as has been suggested by David Scott, which
would produce a plot of similar appearance; but this is
not in the "histogram family" despite appearances, since
it is not primarily a "quantitative" plot (i.e. respecting
the numerical values and their numerical comparisons), but
more a "catefory count". In particular, natural variants
of the above "hist" command such as

  hist(temp,breaks= -0.5+2*(0:7) )

(which corresponds to binning by different intervals) do
not lie so easily in the "table" or "barchart" domain.

And I don't agree with David's comment that "No, hist
is the wrong thing to use to display this data."

In so far as these data are considered to be numerical
values of which one wants a view of their distribution,
then "hist" is entirely appropriate, as for any other
numerical variable. The only question is how to get
this to happen appropriately.

Would David make the same comment about data sampled
from (0:5000) instead of (0:12)?

Best wishes to all,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 11-Mar-05                                       Time: 10:59:55
------------------------------ XFMail ------------------------------



From detlef.steuer at hsu-hh.de  Fri Mar 11 12:22:30 2005
From: detlef.steuer at hsu-hh.de (Detlef Steuer)
Date: Fri, 11 Mar 2005 12:22:30 +0100
Subject: [R] Calculating lengths of runs of 0 or 1 sequences in
	meteorological data
In-Reply-To: <20050311110756.95105.qmail@web52605.mail.yahoo.com>
References: <20050311110756.95105.qmail@web52605.mail.yahoo.com>
Message-ID: <20050311122230.35b0b7f1@gaia.unibw-hamburg.de>

Mohammad,

?rle

is your friend, I guess.

Detlef

On Fri, 11 Mar 2005 03:07:56 -0800 (PST)
Mohammad Ehsanul Karim <wildscop at yahoo.com> wrote:

> Dear List Members,
> 
> I need some help about programming in S language. My
> problem is as follows:
> 
> I have meteorological data (about rainfall measurement
> each day from 1989-2002), say like 
> http://www.angelfire.com/ab5/get5/data.rainfall.txt 
> or http://www.angelfire.com/ab5/get5/R.rainfall.txt
> in a sequence of 0(denoting dry day)'s and 1(denoting
> wet day)'s. I want to construct a frequency
> distribution table of various lengths
> (1,2,3,4,5,6,7,8,9,or more) of observed wet spells
> (number of successive 1's) and dry spells (number of
> successive 0's) occurring in data.
> 
> How should i proceed? Is there any existing
> program/function/package to solve such problem (seems
> like the algorithm should be similar to statistical
> run test)?
> 
> Any suggestion, direction, references, help, replies
> will be highly appreciated.
> 
> Thank you for your time.
> 
> _____________________________
> 
> Mohammad Ehsanul Karim
> E-mail: wildscop at yahoo.com
> Web: http://snipurl.com/ehsan
> ISRT, University of Dhaka, BD
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Ted.Harding at nessie.mcc.ac.uk  Fri Mar 11 12:37:50 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 11 Mar 2005 11:37:50 -0000 (GMT)
Subject: [R] Calculating lengths of runs of 0 or 1 sequences in meteo
In-Reply-To: <20050311110756.95105.qmail@web52605.mail.yahoo.com>
Message-ID: <XFMail.050311113750.Ted.Harding@nessie.mcc.ac.uk>

On 11-Mar-05 Mohammad Ehsanul Karim wrote:
> Dear List Members,
> 
> I need some help about programming in S language. My
> problem is as follows:
> 
> I have meteorological data (about rainfall measurement
> each day from 1989-2002), say like 
> http://www.angelfire.com/ab5/get5/data.rainfall.txt 
> or http://www.angelfire.com/ab5/get5/R.rainfall.txt
> in a sequence of 0(denoting dry day)'s and 1(denoting
> wet day)'s. I want to construct a frequency
> distribution table of various lengths
> (1,2,3,4,5,6,7,8,9,or more) of observed wet spells
> (number of successive 1's) and dry spells (number of
> successive 0's) occurring in data.
> 
> How should i proceed? Is there any existing
> program/function/package to solve such problem (seems
> like the algorithm should be similar to statistical
> run test)?
> 
> Any suggestion, direction, references, help, replies
> will be highly appreciated.

The function 'rle' will do what you ask: see ?rle

For example, if X is your sequence of 0s and 1s,

  table(rle(X)$lengths)

will produce a frequency table of lengths of runs.
E.g.

  X<-sample(c(0,1),5000,replace=TRUE)
  table(rle(X)$lengths)

   1    2    3    4    5    6    7    8    9   10   11 
1181  644  333  168   83   35   15    5    3    3    3

(But -- see recent postings -- be careful about using

  hist(rle(X)$lengths)

!!!)

Hoping this helps,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 11-Mar-05                                       Time: 11:37:50
------------------------------ XFMail ------------------------------



From Allan at STATS.uct.ac.za  Fri Mar 11 13:15:30 2005
From: Allan at STATS.uct.ac.za (Clark Allan)
Date: Fri, 11 Mar 2005 14:15:30 +0200
Subject: [R] R: LIST function and LOOPS
References: <42300277.D8ED0580@STATS.uct.ac.za>
	<1110468574.7407.19.camel@ndmpc126.orc.ox.ac.uk>
Message-ID: <42318BE2.1415B7E5@STATS.uct.ac.za>

hi 

thanx for the help. i dont want to use matrices. i solve my problem, see
the example below.

the set.seed is used because in my actual application i need to generate
INDEPENDENT variables. will this ensure that the variables are
independent? 


z3<-function(w)
{
for (i in 1:w)
{
ss<-0
       for (j in 1:5)
       {
                set.seed(j+1+(i-1)*6)
                r<-rnorm(1)
        	ss<-ss+r
		a<-list(ss=ss,r=r)
       }
print(paste("############ i=",i,"############"))
print(a)
}
}
z3(3)



> z3(3)
[1] "############ i= 1  ############"
$ss
[1] -2.213343

$r
[1] 0.269606

[1] "############ i= 2  ############"
$ss
[1] -2.904235

$r
[1] -1.480568

[1] "############ i= 3  ############"
$ss
[1] -0.01516304

$r
[1] 0.9264592


thanx again

***
allan

###############################################################################################
###############################################################################################
###############################################################################################
###############################################################################################
###############################################################################################
###############################################################################################


Adaikalavan Ramasamy wrote:
> 
> You will need to capture the value of ss at the end of each 'i' as such
> 
> z4 <-function(w){
> 
>   output <- numeric(w)
> 
>   for (i in 1:w){
> 
>     set.seed(i+6)  # this is redundant line
>     ss<-0
> 
>     for (j in 1:5){
>       set.seed(j+1+(i-1)*6)
>       r<-rnorm(1)
>       ss<-ss+r
>     }
> 
>     output[i] <- ss
>   }
>   return(output)
> }
> 
> BTW, I do not think it is a good idea to set.seed() so many times.
> 
> To answer you more general question, see if the following is useful.
> I am trying to simulate 'n' values from a standard normal distribution
> but 'n' is random variable itself.
> 
> f <-function(w, lambda=3){
> 
>   tmp <- list(NULL)
> 
>   for (i in 1:w){
>     n <- 1 + rpois(1, lambda=lambda)  # number of simulation required
>     tmp[[ i ]]  <- rnorm(n)
>   }
> 
>   # flatten the list into a ragged matrix
>   out.lengths   <- sapply(tmp, length)
>   out           <- matrix( nr=w, nc=max( out.lengths ) )
>   rownames(out) <- paste("w =", 1:w)
>   for(i in 1:w) out[i, 1:out.lengths[i] ] <- tmp[[i]]
> 
>   return(out)
> }
> 
> f(6, lambda=3)
> 
> It is not very elegant but I hope that helps you out somehow.
> 
> Regards, Adai
> 
> On Thu, 2005-03-10 at 10:16 +0200, Clark Allan wrote:
> > hi all
> >
> > another simple question.
> >
> > i've written a dummy program so that you get the concept. (the code
> > could be simplfied such that there are no loops. but lets leave the
> > loops in for now.)
> >
> > z1<-function(w)
> > {
> > for (i in 1:w)
> > {
> > set.seed(i+6)
> > ss<-0
> >       for (j in 1:5)
> >       {
> >               set.seed(j+1+(i-1)*6)
> >               r<-rnorm(1)
> >               ss<-ss+r
> >       }
> > list(ss=ss)
> > }
> > }
> > check.1<-z1(3)
> > check.1
> >
> > the results is:
> > $ss
> > [1] -0.01516304
> >
> >
> > what i want is something that looks like this:
> >
> > j=1
> > $ss
> > [1] -2.213343
> >
> > j=2
> > $ss
> > [1] -2.904235
> >
> > j=3
> > $ss
> > [1] -0.01516304
> >
> >
> > i know that i could use the print command. (see z2)
> >
> > z2<-function(w)
> > {
> > for (i in 1:w)
> > {
> > set.seed(i+6)
> > ss<-0
> >       for (j in 1:5)
> >       {
> >               set.seed(j+1+(i-1)*6)
> >               r<-rnorm(1)
> >               ss<-ss+r
> >       }
> > print(ss)
> > }
> > }
> > check.2<-z2(3)
> > check.2
> >
> > > check.2<-z2(3)
> > [1] -2.213343
> > [1] -2.904235
> > [1] -0.01516304
> > > check.2
> > [1] -0.01516304
> >
> > the problem with z2 is that only the last value is saved.
> >
> >
> > what i could do is use matrices like the following: (but i dont want to
> > do this AND WOULD PREFER TO USE list.)
> >
> > z3<-function(w)
> > {
> > results.<-matrix(nrow=w,ncol=1)
> > colnames(results.)<-c("ss")
> > for (i in 1:w)
> > {
> > set.seed(i+6)
> > ss<-0
> >       for (j in 1:5)
> >       {
> >               set.seed(j+1+(i-1)*6)
> >               r<-rnorm(1)
> >               ss<-ss+r
> >       }
> > results.[i,1]<-ss
> > }
> > results.
> > }
> > check.3<-z3(3)
> > check.3
> >
> > > check.3
> >               ss
> > [1,] -2.21334260
> > [2,] -2.90423463
> > [3,] -0.01516304
> >
> > what if i have a new program (something different) and i want the
> > following:
> >
> > j=1
> > $a
> > 1
> > 2
> > 3
> >
> > $b
> > 1
> > 2
> > 3
> > 4
> > 5
> >
> > $c
> > 1
> >
> >
> > ###############
> > j=2
> > $a
> > 11
> > 21
> > 31
> >
> > $b
> > 11
> > 21
> > 31
> > 41
> > 51
> >
> > $c
> > 11
> >
> > ###############
> > j=3
> > $a
> > 21
> > 22
> > 32
> >
> > $b
> > 21
> > 22
> > 32
> > 42
> > 52
> >
> > $c
> > 21
> >
> > MATRICES SEEMS TO BE A GOOD WAY OF DOING THIS (but then you would have
> > to set up three matrices, one for a,b and c). BUT WHAT IF I WANT TO USE
> > THE LIST FUNCTION? i.e. there is a list in the first loop that i want to
> > display!
> >
> > sorry for the long mail.
> >
> > ***
> > ALLAN
> > ______________________________________________ R-help at stat.math.ethz.ch mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

From jfox at mcmaster.ca  Fri Mar 11 13:29:43 2005
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 11 Mar 2005 07:29:43 -0500
Subject: [R] Bonferroni simultaneous confidence intervals for
	multipleregression
In-Reply-To: <20050310204038.c5930525@dogwood.plantbio.uga.edu>
Message-ID: <20050311122940.OMZT2034.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Cara,

You could use the confint() function, setting the level argument to 1 -
alpha/length(coefficients(model)), where model is the linear model that
you've fit and alpha is the complement of the level of confidence. If you're
interested only in a subset of say p coefficients, then use 1 - alpha/p.

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Cara Gormally
> Sent: Thursday, March 10, 2005 8:41 PM
> To: R-help at stat.math.ethz.ch
> Subject: [R] Bonferroni simultaneous confidence intervals for 
> multipleregression
> 
> Hi,
> 
> I'm having no luck figuring out how to find Bonferroni 
> simultaneous confidence intervals to obtain a family of 
> estimates in R.  Does anyone know how to do this?
> Thank you!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From f.harrell at vanderbilt.edu  Fri Mar 11 13:32:30 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Fri, 11 Mar 2005 07:32:30 -0500
Subject: [R] Logistic regression goodness of fit tests
In-Reply-To: <20050310154913.0d4b03e4.twiens@interbaun.com>
References: <20050310140618.51e3d284.twiens@interbaun.com>	<4230C7FD.6080301@vanderbilt.edu>
	<20050310154913.0d4b03e4.twiens@interbaun.com>
Message-ID: <42318FDE.4060302@vanderbilt.edu>

Trevor Wiens wrote:
> On Thu, 10 Mar 2005 16:19:41 -0600
> Frank E Harrell Jr <f.harrell at vanderbilt.edu> wrote:
> 
> 
>>The goodness of fit test only works on prespecified models.  It is not 
>>valid when stepwise variable selection is used (unless perhaps you use 
>>alpha=0.5).
>>
> 
> 
> Perhaps I'm blind, but I can't find any reference to an alpha parameter on the help page for stepAIC. It runs fine however when I set the parameter and produces as model with the same right hand variables as without. Can you tell me what it is ?
> 
> T

What I mean is the effective significance level for keeping a variable 
in the model.  Using AIC for one degree of freedom variables is 
effectively using an alpha of 0.16 if I recall properly.

But I hope you got the point that resid(fit,'gof') as with most goodness 
of fit tests assumes prespecified models.

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From ripley at stats.ox.ac.uk  Fri Mar 11 13:33:22 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 11 Mar 2005 12:33:22 +0000 (GMT)
Subject: [R] RODBC Package
In-Reply-To: <1564b6154122.1541221564b6@post.rwth-aachen.de>
References: <1564b6154122.1541221564b6@post.rwth-aachen.de>
Message-ID: <Pine.LNX.4.61.0503111229590.13271@gannet.stats>

On Fri, 11 Mar 2005, Stephan Freyberger wrote:

> Hello R-Help,
>
> is there any way of using the RODBC Package on a Mac OS X
> System? If yes, what do I need to get it running. Concerning these
> issues, I am pretty unexperienced, so please state any step
> necessary. The actual problem is accessing data in Excel- files.
> (unfortunately no alternative way of entering the data).
> I already installed the Package, but it says the following:
>
>> versuch <- odbcConnectExcel("Thermanali-Versuch.xls")
> Error: couldn't find function "odbcConnectExcel"

As the documentation says very clearly, odbcConnectExcel is only available 
on Windows.

Do you have an Excel ODBC driver?  If so, set up a DSN to point it at the 
file you want and call odbcConnect() with that DSN.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Allan at STATS.uct.ac.za  Fri Mar 11 13:47:02 2005
From: Allan at STATS.uct.ac.za (Clark Allan)
Date: Fri, 11 Mar 2005 14:47:02 +0200
Subject: [R] R: generating independent vectors
Message-ID: <42319346.59FA7A64@STATS.uct.ac.za>

hi all

i would like to generate independent vectors. i have included the code
below. i display the correlation matrix of the n*p (n=the number of
samples, p= the number of variables) matrix. 
what i find is that as n increases, the correlation matrix tends to an
identity matrix. i.e. independence. for small samples (see examples
below, for n=20, p=5 ; n=50,p=5, n=100,p=5; n=10000,p=5) the variables
does not appear to be independent. note that i have not tested this
statement statistically.

ARE these variables independent? by setting the seed for each variable
run i HOPE that the variables are now independent. IS this true??? if
not does anyone know how to generate these independent variables?

how does R generate its random variables? does it use the box muller
technique? if so how does it generate the random uniform variables?

thanking you in advance!!!
***
allan



IND<-function(rows.=10,col.=3)
{
a<-matrix(nrow=rows.,ncol=col.)
for (j in 1:col.)
{
	set.seed(j)
	r<-rnorm(rows.)
	a[,j]<-r
}
#list(a=a,cor=cor(a))
cor(a)
}
IND(rows.=10,col.=3)



> IND(rows.=20,col.=5)
            [,1]        [,2]        [,3]        [,4]       [,5]
[1,]  1.00000000  0.25677165 -0.14882130 -0.09190797  0.1562481
[2,]  0.25677165  1.00000000  0.02585515  0.13735712 -0.1443301
[3,] -0.14882130  0.02585515  1.00000000 -0.11311416  0.1437001
[4,] -0.09190797  0.13735712 -0.11311416  1.00000000  0.1833647
[5,]  0.15624807 -0.14433011  0.14370006  0.18336467  1.0000000


> IND(rows.=50,col.=5)
              [,1]        [,2]          [,3]        [,4]        [,5]
[1,]  1.0000000000  0.07915025  0.0009239851 -0.14102117 -0.07335342
[2,]  0.0791502463  1.00000000 -0.1764530631  0.10021081  0.19742285
[3,]  0.0009239851 -0.17645306  1.0000000000  0.02968062  0.14543350
[4,] -0.1410211698  0.10021081  0.0296806188  1.00000000  0.07234953
[5,] -0.0733534183  0.19742285  0.1454335014  0.07234953  1.00000000
> 

> IND(rows.=100,col.=5)
            [,1]       [,2]         [,3]         [,4]       [,5]
[1,]  1.00000000 -0.1537208 -0.023741715 -0.135245915 0.01961224
[2,] -0.15372076  1.0000000 -0.141796984  0.157219334 0.15518443
[3,] -0.02374171 -0.1417970  1.000000000  0.005865698 0.19118563
[4,] -0.13524592  0.1572193  0.005865698  1.000000000 0.07345299
[5,]  0.01961224  0.1551844  0.191185627  0.073452993 1.00000000
> 

> IND(rows.=10000,col.=5)
             [,1]         [,2]         [,3]         [,4]         [,5]
[1,]  1.000000000  0.015928444 -0.008288940 -0.005646904  0.006936662
[2,]  0.015928444  1.000000000 -0.005444611  0.005242395 -0.008246009
[3,] -0.008288940 -0.005444611  1.000000000  0.007277489  0.012299247
[4,] -0.005646904  0.005242395  0.007277489  1.000000000  0.001918704
[5,]  0.006936662 -0.008246009  0.012299247  0.001918704  1.000000000

From ccleland at optonline.net  Fri Mar 11 13:58:20 2005
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 11 Mar 2005 07:58:20 -0500
Subject: [R] R: generating independent vectors
In-Reply-To: <42319346.59FA7A64@STATS.uct.ac.za>
References: <42319346.59FA7A64@STATS.uct.ac.za>
Message-ID: <423195EC.6050506@optonline.net>

You might try mvrnorm() in MASS.

library(MASS)
mvrnorm(n=10, mu=rep(0, 3), Sigma=diag(3), empirical=TRUE)

Clark Allan wrote:
> hi all
> 
> i would like to generate independent vectors. i have included the code
> below. i display the correlation matrix of the n*p (n=the number of
> samples, p= the number of variables) matrix. 
> what i find is that as n increases, the correlation matrix tends to an
> identity matrix. i.e. independence. for small samples (see examples
> below, for n=20, p=5 ; n=50,p=5, n=100,p=5; n=10000,p=5) the variables
> does not appear to be independent. note that i have not tested this
> statement statistically.
> 
> ARE these variables independent? by setting the seed for each variable
> run i HOPE that the variables are now independent. IS this true??? if
> not does anyone know how to generate these independent variables?
> 
> how does R generate its random variables? does it use the box muller
> technique? if so how does it generate the random uniform variables?
> 
> thanking you in advance!!!
> ***
> allan
> 
> 
> 
> IND<-function(rows.=10,col.=3)
> {
> a<-matrix(nrow=rows.,ncol=col.)
> for (j in 1:col.)
> {
> 	set.seed(j)
> 	r<-rnorm(rows.)
> 	a[,j]<-r
> }
> #list(a=a,cor=cor(a))
> cor(a)
> }
> IND(rows.=10,col.=3)
> 
> 
> 
> 
>>IND(rows.=20,col.=5)
> 
>             [,1]        [,2]        [,3]        [,4]       [,5]
> [1,]  1.00000000  0.25677165 -0.14882130 -0.09190797  0.1562481
> [2,]  0.25677165  1.00000000  0.02585515  0.13735712 -0.1443301
> [3,] -0.14882130  0.02585515  1.00000000 -0.11311416  0.1437001
> [4,] -0.09190797  0.13735712 -0.11311416  1.00000000  0.1833647
> [5,]  0.15624807 -0.14433011  0.14370006  0.18336467  1.0000000
> 
> 
> 
>>IND(rows.=50,col.=5)
> 
>               [,1]        [,2]          [,3]        [,4]        [,5]
> [1,]  1.0000000000  0.07915025  0.0009239851 -0.14102117 -0.07335342
> [2,]  0.0791502463  1.00000000 -0.1764530631  0.10021081  0.19742285
> [3,]  0.0009239851 -0.17645306  1.0000000000  0.02968062  0.14543350
> [4,] -0.1410211698  0.10021081  0.0296806188  1.00000000  0.07234953
> [5,] -0.0733534183  0.19742285  0.1454335014  0.07234953  1.00000000
> 
> 
>>IND(rows.=100,col.=5)
> 
>             [,1]       [,2]         [,3]         [,4]       [,5]
> [1,]  1.00000000 -0.1537208 -0.023741715 -0.135245915 0.01961224
> [2,] -0.15372076  1.0000000 -0.141796984  0.157219334 0.15518443
> [3,] -0.02374171 -0.1417970  1.000000000  0.005865698 0.19118563
> [4,] -0.13524592  0.1572193  0.005865698  1.000000000 0.07345299
> [5,]  0.01961224  0.1551844  0.191185627  0.073452993 1.00000000
> 
> 
>>IND(rows.=10000,col.=5)
> 
>              [,1]         [,2]         [,3]         [,4]         [,5]
> [1,]  1.000000000  0.015928444 -0.008288940 -0.005646904  0.006936662
> [2,]  0.015928444  1.000000000 -0.005444611  0.005242395 -0.008246009
> [3,] -0.008288940 -0.005444611  1.000000000  0.007277489  0.012299247
> [4,] -0.005646904  0.005242395  0.007277489  1.000000000  0.001918704
> [5,]  0.006936662 -0.008246009  0.012299247  0.001918704  1.000000000
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From Allan at STATS.uct.ac.za  Fri Mar 11 14:03:00 2005
From: Allan at STATS.uct.ac.za (Clark Allan)
Date: Fri, 11 Mar 2005 15:03:00 +0200
Subject: [R] R: generating independent vectors
References: <42319346.59FA7A64@STATS.uct.ac.za>
	<423195EC.6050506@optonline.net>
Message-ID: <42319704.6167F2CA@STATS.uct.ac.za>

thanx. this function works and does exactly what i want

Chuck Cleland wrote:
> 
> You might try mvrnorm() in MASS.
> 
> library(MASS)
> mvrnorm(n=10, mu=rep(0, 3), Sigma=diag(3), empirical=TRUE)
> 
> Clark Allan wrote:
> > hi all
> >
> > i would like to generate independent vectors. i have included the code
> > below. i display the correlation matrix of the n*p (n=the number of
> > samples, p= the number of variables) matrix.
> > what i find is that as n increases, the correlation matrix tends to an
> > identity matrix. i.e. independence. for small samples (see examples
> > below, for n=20, p=5 ; n=50,p=5, n=100,p=5; n=10000,p=5) the variables
> > does not appear to be independent. note that i have not tested this
> > statement statistically.
> >
> > ARE these variables independent? by setting the seed for each variable
> > run i HOPE that the variables are now independent. IS this true??? if
> > not does anyone know how to generate these independent variables?
> >
> > how does R generate its random variables? does it use the box muller
> > technique? if so how does it generate the random uniform variables?
> >
> > thanking you in advance!!!
> > ***
> > allan
> >
> >
> >
> > IND<-function(rows.=10,col.=3)
> > {
> > a<-matrix(nrow=rows.,ncol=col.)
> > for (j in 1:col.)
> > {
> >       set.seed(j)
> >       r<-rnorm(rows.)
> >       a[,j]<-r
> > }
> > #list(a=a,cor=cor(a))
> > cor(a)
> > }
> > IND(rows.=10,col.=3)
> >
> >
> >
> >
> >>IND(rows.=20,col.=5)
> >
> >             [,1]        [,2]        [,3]        [,4]       [,5]
> > [1,]  1.00000000  0.25677165 -0.14882130 -0.09190797  0.1562481
> > [2,]  0.25677165  1.00000000  0.02585515  0.13735712 -0.1443301
> > [3,] -0.14882130  0.02585515  1.00000000 -0.11311416  0.1437001
> > [4,] -0.09190797  0.13735712 -0.11311416  1.00000000  0.1833647
> > [5,]  0.15624807 -0.14433011  0.14370006  0.18336467  1.0000000
> >
> >
> >
> >>IND(rows.=50,col.=5)
> >
> >               [,1]        [,2]          [,3]        [,4]        [,5]
> > [1,]  1.0000000000  0.07915025  0.0009239851 -0.14102117 -0.07335342
> > [2,]  0.0791502463  1.00000000 -0.1764530631  0.10021081  0.19742285
> > [3,]  0.0009239851 -0.17645306  1.0000000000  0.02968062  0.14543350
> > [4,] -0.1410211698  0.10021081  0.0296806188  1.00000000  0.07234953
> > [5,] -0.0733534183  0.19742285  0.1454335014  0.07234953  1.00000000
> >
> >
> >>IND(rows.=100,col.=5)
> >
> >             [,1]       [,2]         [,3]         [,4]       [,5]
> > [1,]  1.00000000 -0.1537208 -0.023741715 -0.135245915 0.01961224
> > [2,] -0.15372076  1.0000000 -0.141796984  0.157219334 0.15518443
> > [3,] -0.02374171 -0.1417970  1.000000000  0.005865698 0.19118563
> > [4,] -0.13524592  0.1572193  0.005865698  1.000000000 0.07345299
> > [5,]  0.01961224  0.1551844  0.191185627  0.073452993 1.00000000
> >
> >
> >>IND(rows.=10000,col.=5)
> >
> >              [,1]         [,2]         [,3]         [,4]         [,5]
> > [1,]  1.000000000  0.015928444 -0.008288940 -0.005646904  0.006936662
> > [2,]  0.015928444  1.000000000 -0.005444611  0.005242395 -0.008246009
> > [3,] -0.008288940 -0.005444611  1.000000000  0.007277489  0.012299247
> > [4,] -0.005646904  0.005242395  0.007277489  1.000000000  0.001918704
> > [5,]  0.006936662 -0.008246009  0.012299247  0.001918704  1.000000000
> >
> >
> > ------------------------------------------------------------------------
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> --
> Chuck Cleland, Ph.D.
> NDRI, Inc.
> 71 West 23rd Street, 8th floor
> New York, NY 10010
> tel: (212) 845-4495 (Tu, Th)
> tel: (732) 452-1424 (M, W, F)
> fax: (917) 438-0894

From upasna at iitb.ac.in  Fri Mar 11 14:40:33 2005
From: upasna at iitb.ac.in (Upasna Sharma)
Date: Fri, 11 Mar 2005 19:10:33 +0530 (IST)
Subject: [R] reading in data  problems
Message-ID: <1930.10.127.130.15.1110548433.squirrel@gpo.iitb.ac.in>

Hi

I have a dataset (.txt file and .dat file) in which the length of one
record is 144. There is no header in the .txt or .dat file itself. When I
read this file using the read.table command, and want to drop some
coloumns by setting the argument colClasses to "NULL" for the columns that
I want to drop, it does not work, because the entire record of the length
144 is being treated as one column only, of the type 'character'. I tried
using read.fwf instead of read.table, but that doesn't seem to work
either. what should I do, if I want to read in only some columns from the
file?

If it helps, the description of the .dat file in the supporting documents
if given as follows:

Work-file:01(Wrk101r/u) (person level work-file) record length : 145

No.    field                     	    length 	byte-Position
1.	Id					2	1 - 2
2.	Rnd sch					3	3 - 5
3.	sub-sample-original           	        1       6
4.	sec					1	7
5.	State-reg				3	8 - 10
6.	Stratum					2	11 - 12
7.	Sub-stratum				1	13
8.	Dist					2	14 - 15
9.	Sub rnd					1	16
10.	Sub-sample-revised			1	17
11.	Fsu					5	18 - 22
12.	Segment					1	23
13.	HHd -sl. No.				2	24 - 25
14. 	Survey code				1	26
15.	Reason -sub				1	27
16.	Nss					3	28 - 30
17.	Nsc					3	31 - 33
18.	Mult -ss				10	34 - 43
19.	HHD -size				3	44 - 46
20.	Mpce					8	47 - 54
21.	Mpce code				2	55 - 56
22.	Cmpce code				2	57 - 58
23.	HHd Type				1	59
24.	Religion				1	60
25.	Social group				1	61
26.	Land possessed CODE			2	62 - 63
27.	Dwelling code				1	64
28.	Type dwelling				1	65
29.	Type structure				1	66
30.	Covered area				6	67 - 72
31.	Cook					2	73 - 74
32.	Light					1	75
33.	Meal taken outside			1	76
34.	Ceremony performed			1	77
35.	Pds purchase				1	78
36.	Get food				1	79
37.	Not get food in the month of Jan	2	80 - 81
38.	Not get food in the month of Feb	2	82 - 83
39.	Not get food in the month of Mar	2	84 - 85
40.	Not get food in the month of Apr	2	86 - 87
41.	Not get food in the month of May	2	88 - 89
42.	Not get food in the month of June	2	90 - 91
43.	Not get food in the month of July	2	92 - 93
44.	Not get food in the month of Aug	2	94 - 95
45.	Not get food in the month of Sep	2	96 - 97
46.	Not get food in the month of Oct	2	98 - 99
47.	Not get food in the month of Nov	2	100 -101
48.	Not get food in the month of Dec	2	102 -103
49.	Tot no. of month not getting food	2	104 -105
50.	Whether asked				1	106
51.	Time canvass				3	107 109
52.	Person sl. No.				3	110 -112
53.	Relation				1	113
54.	Sex					1	114
55.	Age					2	115 -116
56.	Marital status				1	117
57.	Edu code				2	118 -119
58.	Upst code 				2	120 -121
59.	Upnic code				2	122 -123
60.	Sbst code				2	124 -125
61.	Sbnic code				2	126 -127
62.	Cwst code 				2	128 -129
63.	Cwnic code 				2	130 -131
64. 	Days stayed away			2	132 -133
65.	No. meal/day				1	134
66.	Meal school				2	135 -136
67.	Meal employer				2	137 -138
68.	Meal other				2	139 -140
69.	Meal on payment				2	141 -142
70.	Meal at home				2	143 -144
_______________________________________________________________________


-- 
"The past is a history, the future is a mystery, and this moment is a
gift. That is why this moment is called 'the present'." Anonymous



From simon at stats.gla.ac.uk  Fri Mar 11 15:01:06 2005
From: simon at stats.gla.ac.uk (Simon Wood)
Date: Fri, 11 Mar 2005 14:01:06 +0000 (GMT)
Subject: [R] [R-pkgs] mgcv 1.2-0
Message-ID: <Pine.LNX.4.58.0503111253460.28840@moon.stats.gla.ac.uk>

mgcv version 1.2 is on CRAN now. mgcv provides generalized additive models 
and generalized additive mixed models with automatic estimation of the 
smoothness of model components. 

Changes in this version are:

* A new gam fitting method is implemented for the generalized case. It 
provides more reliable convergence than the previous default, but can be 
a little slower.  See ?gam.method, ?gam.fit2 and ?gam.outer for details. 
The old method is still available as an option.

* `gam' has acquired a new list argument `method' to cope with the number 
of fitting  method options now available, and there has been some alteration 
to the `control' argument.

* Any smoothers can now be used to construct nested models, including 
tensor product smooths. See ?fixDependence and ?gam.side for details.

* By default all smooths are now parameterized to be centred, without 
requiring additional constraints (this is automatic and applies also to 
user defined smooths). The old behaviour is still available as an option. 
See ?smoothCon for details. (This should be user transparent.) 

* Smoothing parameter initialization has been modified for better 
performance with tensor product smooths. See ?initial.sp.

* By default, tensor product smooths have been modified to use more 
interpretable penalties. See ?te for details. This leaves smooths based 
on the default basis unchanged, but improves the performance of smooths 
based on other marginal bases.

* Examples of how to obtain variance estimates etc. efficiently, for any 
quantities derived from a fitted gam model are provided in ?predict.gam.

_____________________________________________________________________
> Simon Wood simon at stats.gla.ac.uk        www.stats.gla.ac.uk/~simon/
>>  Department of Statistics, University of Glasgow, Glasgow, G12 8QQ
>>>   Direct telephone: (0)141 330 4530          Fax: (0)141 330 4814

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From ggrothendieck at myway.com  Fri Mar 11 15:43:53 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 11 Mar 2005 14:43:53 +0000 (UTC)
Subject: [R] XML to data frame or list
References: <20050311021926.61533.qmail@web50106.mail.yahoo.com>
Message-ID: <loom.20050311T154207-618@post.gmane.org>

bogdan romocea <br44114 <at> yahoo.com> writes:

: 
: Dear useRs,
: 
: I have a simple/RTFM question about XML parsing. Given an XML file,
: such as (fragment)
: <A>100</A>
: <B>23</B>
: <C>true</C>
: how do I import it in a data frame or list, so that the values (100,
: 23, true) can be accessed through the names A, B and C?
: 
: I installed the XML package and looked over the documentation...
: however after 20 minutes and a couple of tests I still don't know what
: I should start with. 
: 
: Can someone provide an example or point me to the appropriate
: function(s)?
: 

You could check out the ctv package that was recently announced.
It uses XML so its source would provide an example.

If its a one-time operation, Excel reads XML and you could then
use one of the many Excel to R possibilities.



From B.Rowlingson at lancaster.ac.uk  Fri Mar 11 16:06:18 2005
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 11 Mar 2005 15:06:18 +0000
Subject: [R] XML to data frame or list
In-Reply-To: <loom.20050311T154207-618@post.gmane.org>
References: <20050311021926.61533.qmail@web50106.mail.yahoo.com>
	<loom.20050311T154207-618@post.gmane.org>
Message-ID: <4231B3EA.90708@lancaster.ac.uk>

Gabor Grothendieck wrote:

> 
> You could check out the ctv package that was recently announced.
> It uses XML so its source would provide an example.
> 
> If its a one-time operation, Excel reads XML and you could then
> use one of the many Excel to R possibilities.

  For an xml file like this:

<?xml version="1.0"?>
<variables>
<a>100</a>
<b>23</b>
<z>666</z>
</variables>

its a one-liner with the XML package (library(XML)):

xmlReadSimple <-
function(xmlFile){
   as.list(xmlSApply(xmlRoot(xmlTreeParse(xmlFile)),xmlValue))
}

add an lapply(...,as.numeric) for conversion to numbers.

  sweet.

Baz



From christoph.lehmann at gmx.ch  Fri Mar 11 16:21:30 2005
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Fri, 11 Mar 2005 16:21:30 +0100
Subject: [R] aov or t-test applied on all variables of a data.frame
Message-ID: <4231B77A.6040908@gmx.ch>

Hi
I have a data.frame with say 10 continuous variables and one grouping 
factor (say 3 levels)

how can I easily (without loops) apply for each continous variable e.g. 
an aov, with the grouping factor as my factor (or if the grouping factor 
has 2 levels, eg. a t-test)

thanks for a hint

cheers

christoph



From tlumley at u.washington.edu  Fri Mar 11 16:23:56 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 11 Mar 2005 07:23:56 -0800 (PST)
Subject: [R] reading in data  problems
In-Reply-To: <1930.10.127.130.15.1110548433.squirrel@gpo.iitb.ac.in>
References: <1930.10.127.130.15.1110548433.squirrel@gpo.iitb.ac.in>
Message-ID: <Pine.A41.4.61b.0503110722390.127732@homer03.u.washington.edu>

On Fri, 11 Mar 2005, Upasna Sharma wrote:

> Hi
>
> I have a dataset (.txt file and .dat file) in which the length of one
> record is 144. There is no header in the .txt or .dat file itself. When I
> read this file using the read.table command, and want to drop some
> coloumns by setting the argument colClasses to "NULL" for the columns that
> I want to drop, it does not work, because the entire record of the length
> 144 is being treated as one column only, of the type 'character'. I tried
> using read.fwf instead of read.table, but that doesn't seem to work
> either.

You should use read.fwf().  You didn't say what the problem was, so we 
have to guess: did you try to use NULL to skip columns rather than using 
negative field widths as the help page says?

 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From tlumley at u.washington.edu  Fri Mar 11 16:29:28 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 11 Mar 2005 07:29:28 -0800 (PST)
Subject: [R] aov or t-test applied on all variables of a data.frame
In-Reply-To: <4231B77A.6040908@gmx.ch>
References: <4231B77A.6040908@gmx.ch>
Message-ID: <Pine.A41.4.61b.0503110724170.127732@homer03.u.washington.edu>

On Fri, 11 Mar 2005, Christoph Lehmann wrote:

> Hi
> I have a data.frame with say 10 continuous variables and one grouping factor 
> (say 3 levels)
>
> how can I easily (without loops) apply for each continous variable e.g. an 
> aov, with the grouping factor as my factor (or if the grouping factor has 2 
> levels, eg. a t-test)
>

You can call aov() or lm() with a multicolumn response variable.
> summary(aov(cbind(y1,y2,y3)~factor(x),data=df))
  Response y1 :
             Df Sum Sq Mean Sq F value Pr(>F)
factor(x)    2  0.187   0.093  0.0735 0.9293
Residuals   27 34.326   1.271

  Response y2 :
             Df Sum Sq Mean Sq F value Pr(>F)
factor(x)    2  0.133   0.066  0.0497 0.9516
Residuals   27 36.107   1.337

  Response y3 :
             Df Sum Sq Mean Sq F value  Pr(>F)
factor(x)    2  6.051   3.026  2.5605 0.09589 .
Residuals   27 31.903   1.182
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1


 	-thomas



From dimitris.rizopoulos at med.kuleuven.ac.be  Fri Mar 11 16:36:55 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Fri, 11 Mar 2005 16:36:55 +0100
Subject: [R] aov or t-test applied on all variables of a data.frame
References: <4231B77A.6040908@gmx.ch>
Message-ID: <007f01c52650$27fe65f0$0540210a@www.domain>

you mean something like this:

dat <- data.frame(matrix(rnorm(10*100), 100), f=sample(letters[1:3], 
100, TRUE))
models <- lapply(dat[sapply(dat, is.numeric)], function(x, f) 
aov(x~f), f=dat$f)
#################
models
lapply(models, summary)

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Christoph Lehmann" <christoph.lehmann at gmx.ch>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, March 11, 2005 4:21 PM
Subject: [R] aov or t-test applied on all variables of a data.frame


> Hi
> I have a data.frame with say 10 continuous variables and one 
> grouping factor (say 3 levels)
>
> how can I easily (without loops) apply for each continous variable 
> e.g. an aov, with the grouping factor as my factor (or if the 
> grouping factor has 2 levels, eg. a t-test)
>
> thanks for a hint
>
> cheers
>
> christoph
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From twiens at interbaun.com  Fri Mar 11 16:37:13 2005
From: twiens at interbaun.com (Trevor Wiens)
Date: Fri, 11 Mar 2005 08:37:13 -0700
Subject: [R] Logistic regression goodness of fit tests
In-Reply-To: <42318FDE.4060302@vanderbilt.edu>
References: <20050310140618.51e3d284.twiens@interbaun.com>
	<4230C7FD.6080301@vanderbilt.edu>
	<20050310154913.0d4b03e4.twiens@interbaun.com>
	<42318FDE.4060302@vanderbilt.edu>
Message-ID: <20050311083713.663c9b01.twiens@interbaun.com>

On Fri, 11 Mar 2005 07:32:30 -0500
Frank E Harrell Jr <f.harrell at vanderbilt.edu> wrote:

> What I mean is the effective significance level for keeping a variable 
> in the model.  Using AIC for one degree of freedom variables is 
> effectively using an alpha of 0.16 if I recall properly.
> 
> But I hope you got the point that resid(fit,'gof') as with most goodness 
> of fit tests assumes prespecified models.
> 

Yes. I understand. Late last night someone replied similarly off the list but I didn't realize they hadn't posted to the list until this morning, otherwise I would have posted a note that my question had been resolved. Sorry for taking your time.

T
-- 
Trevor Wiens 
twiens at interbaun.com

The significant problems that we face cannot be solved at the same 
level of thinking we were at when we created them. 
(Albert Einstein)



From p.dalgaard at biostat.ku.dk  Fri Mar 11 16:47:27 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 11 Mar 2005 16:47:27 +0100
Subject: [R] aov or t-test applied on all variables of a data.frame
In-Reply-To: <4231B77A.6040908@gmx.ch>
References: <4231B77A.6040908@gmx.ch>
Message-ID: <x2acpa4228.fsf@biostat.ku.dk>

Christoph Lehmann <christoph.lehmann at gmx.ch> writes:

> Hi
> I have a data.frame with say 10 continuous variables and one grouping
> factor (say 3 levels)
> 
> how can I easily (without loops) apply for each continous variable
> e.g. an aov, with the grouping factor as my factor (or if the grouping
> factor has 2 levels, eg. a t-test)
> 
> thanks for a hint

Generally something with lapply or sapply, e.g.

lapply(dd[-1], function(y) t.test(y~dd$V1))

$V2

        Welch Two Sample t-test

data:  y by dd$V1
t = 1.5465, df = 39.396, p-value = 0.13
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -0.02500802  0.18764439
sample estimates:
mean in group 1 mean in group 2
       1.096818        1.015500

...etc, one for each of V2..V8

or, in a more compact form 

sapply(dd[-1], function(y) t.test(y~dd$V1))[1:3,]

          V2        V3        V4         V5         V6        V7
statistic 1.546456  1.008719  0.08158578 -0.2456436 -0.872376 -1.405966
parameter 39.39554  36.30778  39.70288   36.99061   36.99944  35.97947
p.value   0.1299909 0.3197851 0.935386   0.807316   0.3886296 0.1683118
          V8
statistic -0.6724112
parameter 29.65156
p.value   0.5065284

or (this'll get the confidence intervals and estimates printed sensibly).

sapply(dd[-1], function(y)unlist(t.test(y~dd$V1)[1:5]))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From eugenedalt at yahoo.com  Fri Mar 11 17:18:22 2005
From: eugenedalt at yahoo.com (eugene dalt)
Date: Fri, 11 Mar 2005 08:18:22 -0800 (PST)
Subject: [R] Re: [S] Looking for advanced R/S+ programming course in bay area
In-Reply-To: 6667
Message-ID: <20050311161822.13010.qmail@web30007.mail.mud.yahoo.com>

Check out www.xlsolutions-corp.com, they are offering
a course in San Francisco  March 31st - April 1st.  

--- paul king <kingroi at hotmail.com> wrote:
> Hi all,
> 
> I am taking a new job in San Francisco and looking
> for an upcoming
> advanced R/S+ programming course in bay area.
> 
> Best - Paul
> 
>
_________________________________________________________________
> Dont just search. Find. Check out the new MSN
> Search! 
>
http://search.msn.click-url.com/go/onm00200636ave/direct/01/
> 
>
--------------------------------------------------------------------
> This message was distributed by
> s-news at lists.biostat.wustl.edu.  To
> unsubscribe send e-mail to
> s-news-request at lists.biostat.wustl.edu with

>



From stoneman at otsys.com  Fri Mar 11 18:09:15 2005
From: stoneman at otsys.com (Andrew Stoneman)
Date: Fri, 11 Mar 2005 09:09:15 -0800
Subject: [R] Simplex(boot) returning invalid answer
Message-ID: <a05f3b8e3f799ec5a4ca7cc0feb025a6@otsys.com>

In trying to use simplex() from the boot package, I have run into a 
situation that doesn't seem like it should be possible.  It is claiming 
that it has solved the LP, but returns a vector of all zeros, which 
does not satisfy the constraints I passed in.  A small example:

 > ubMatrix <- matrix(c(1,1,-1,0,-1,-1), 3, 2)
 > ubVector <- c(2,1,-1)
 > objective <- c(0,1)

 > ubMatrix
      [,1] [,2]
[1,]    1    0
[2,]    1   -1
[3,]   -1   -1
 > ubVector
[1]  2  1 -1

 > smplx <- simplex( a = objective, A1 = ubMatrix, b1 = ubVector)

 > smplx$solved
[1] 1
 > smplx$soln
x1 x2
  0  0

 > ubMatrix %*% smplx$soln <= ubVector
       [,1]
[1,]  TRUE
[2,]  TRUE
[3,] FALSE

The correct answer to the problem, which also has a value of 0, but 
satisfies the constraints is [1, 0] :

 > ubMatrix %*% c(1,0) <= ubVector
      [,1]
[1,] TRUE
[2,] TRUE
[3,] TRUE

Any ideas what's going on here?  Am I missing something obvious?  Any 
advice on how I might work around this problem would be greatly 
appreciated.

Andrew



From bng354 at yahoo.fr  Fri Mar 11 18:20:57 2005
From: bng354 at yahoo.fr (Riad BENGHIDA)
Date: Fri, 11 Mar 2005 18:20:57 +0100 (CET)
Subject: [R] dates and graphic
Message-ID: <20050311172057.91132.qmail@web26906.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050311/17ed9af0/attachment.pl

From berge319 at umn.edu  Fri Mar 11 18:39:06 2005
From: berge319 at umn.edu (Tracy Bergemann)
Date: Fri, 11 Mar 2005 11:39:06 -0600
Subject: [R] difficulties with the save.image() function
Message-ID: <smtpd.7419.4231d7ba.7a514.1@mtaout-c.tc.umn.edu>


Dear list,

I've had difficulty saving my workspace to an .RData file.
This causes considerable frustration as it means that I have to regenerate
my analysis every time I want to update it.  For microarray data in
particular, this can be quite time consuming.

I'm saving my data to a network folder on my system in Windows XP, something
like an "H:\" drive or a "P:\" drive instead of a "C:\" drive.

Here is the command which saves my workspace to my working directory:
save.image("H:/Consulting/cmlExprA.RData")
And here is the error I get:
Error in save(list = ls(envir = .GlobalEnv, all.names = TRUE), file =
outfile,: error writing to connection

Any assistance?

Many thanks,
Tracy L. Bergemann, PhD
Biostatistics Core
University of Minnesota Cancer Center
B412-4 Mayo building
Office # 626-5408



From christoph.lehmann at gmx.ch  Fri Mar 11 18:45:06 2005
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Fri, 11 Mar 2005 18:45:06 +0100
Subject: [R] aov or t-test applied on all variables of a data.frame
In-Reply-To: <x2acpa4228.fsf@biostat.ku.dk>
References: <4231B77A.6040908@gmx.ch> <x2acpa4228.fsf@biostat.ku.dk>
Message-ID: <4231D922.2050806@gmx.ch>

many thanks for the sapply hint. How can I use sapply for a compact 
result of the aov computation, say I call

sapply(dd[-1], function(y, f) aov(y ~ f), f = dd$V1)

aov gives the result in another form than t.test

thanks a lot



Peter Dalgaard wrote:
> Christoph Lehmann <christoph.lehmann at gmx.ch> writes:
> 
>>Hi
>>I have a data.frame with say 10 continuous variables and one grouping
>>factor (say 3 levels)
>>
>>how can I easily (without loops) apply for each continous variable
>>e.g. an aov, with the grouping factor as my factor (or if the grouping
>>factor has 2 levels, eg. a t-test)
>>
>>thanks for a hint
> 
> Generally something with lapply or sapply, e.g.
> 
> lapply(dd[-1], function(y) t.test(y~dd$V1))
> 
> $V2
> 
>         Welch Two Sample t-test
> 
> data:  y by dd$V1
> t = 1.5465, df = 39.396, p-value = 0.13
> alternative hypothesis: true difference in means is not equal to 0
> 95 percent confidence interval:
>  -0.02500802  0.18764439
> sample estimates:
> mean in group 1 mean in group 2
>        1.096818        1.015500
> 
> ...etc, one for each of V2..V8
> 
> or, in a more compact form 
> 
> sapply(dd[-1], function(y) t.test(y~dd$V1))[1:3,]
> 
>           V2        V3        V4         V5         V6        V7
> statistic 1.546456  1.008719  0.08158578 -0.2456436 -0.872376 -1.405966
> parameter 39.39554  36.30778  39.70288   36.99061   36.99944  35.97947
> p.value   0.1299909 0.3197851 0.935386   0.807316   0.3886296 0.1683118
>           V8
> statistic -0.6724112
> parameter 29.65156
> p.value   0.5065284
> 
> or (this'll get the confidence intervals and estimates printed sensibly).
> 
> sapply(dd[-1], function(y)unlist(t.test(y~dd$V1)[1:5]))
>



From dyang at NRCan.gc.ca  Fri Mar 11 18:47:20 2005
From: dyang at NRCan.gc.ca (Yang, Richard)
Date: Fri, 11 Mar 2005 12:47:20 -0500
Subject: [R] Lattice bwplot error
Message-ID: <F0E0B899CB43D5118D220002A55113CF04FE5758@s2-edm-r1.nrn.nrcan.gc.ca>

Dear all;

	Searching the R site for answers to my problem, but found none.

Here is the run and error:

> bwplot(dev ~ Dbhcl | Period, data = DbhValid2, font = 2,
+   main=list(" "), axis.font =2,
+   ylab = list(label = "Residual (cm)", font = 2),
+   xlab = list(label = "Dbh class (cm)", font = 2), 
+   par.strip.text=list(cex=0.8, font=2),
+   panel=function(x, y) {
+   panel.grid()
+   panel.abline(h = 0)
+   panel.bwplot(x, y, horizontal = TRUE)
+   }
+   )

Error in "[<-"(`*tmp*`, pos.heights[[nm]], value = numeric(0)) : 
        nothing to replace with

> str(DbhValid2$dev)
 num [1:11469] 0.318 0.764 1.230 0.403 0.526 ...
> str(DbhValid2$Dbhcl)
 Factor w/ 26 levels "2","3","4","5",..: 9 9 9 10 10 10 10 11 11 11 ...

Stepped through debugging bwplot(), I couldn't locate where the error
occurred (there are more than 11,000 data points). However, I had no problem
using boxplot() to generate four graphs separately:

> boxplot(dev ~ Dbhcl, data=DbhValid2[DbhValid2$period == 5,])

Any ideas and suggestions?

TIA,

Richard Yang


Northern Forestry Centre   /	Centre de foresterie du Nord
Canadian Forest Service	   /	Service canadien des for?ts
Natural Resources Canada   /	Ressources naturelles Canada
5320-122 Street     	   /	5320, rue 122

Edmonton Alberta Canada
T6H 3S5



From tpeng at u.washington.edu  Fri Mar 11 18:55:55 2005
From: tpeng at u.washington.edu (tpeng@u.washington.edu)
Date: Fri, 11 Mar 2005 09:55:55 -0800 (PST)
Subject: [R] warning message when using anova
Message-ID: <Pine.LNX.4.43.0503110955550.9444@hymn06.u.washington.edu>

Hi can someone help me with the following warning message I got when I used two
way anova: Warning messages: 1: Models with response "NULL" removed because
response differs from model 1 in: anova.lmlist(object, ...) 2: Models with
response "NULL" removed because response differs from model 1 in:
anova.lmlist(object, ...)
  (I have two rows of separate data sets)

Thanks in advance,

tao



From deepayan at stat.wisc.edu  Fri Mar 11 20:00:31 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 11 Mar 2005 13:00:31 -0600
Subject: [R] Lattice bwplot error
In-Reply-To: <F0E0B899CB43D5118D220002A55113CF04FE5758@s2-edm-r1.nrn.nrcan.gc.ca>
References: <F0E0B899CB43D5118D220002A55113CF04FE5758@s2-edm-r1.nrn.nrcan.gc.ca>
Message-ID: <200503111300.31727.deepayan@stat.wisc.edu>

On Friday 11 March 2005 11:47, Yang, Richard wrote:
> Dear all;
>
>  Searching the R site for answers to my problem, but found none.

If this is what I'm guessing it is, you haven't searched carefully enough. 
This was a bug (in lattice) that was reported several times, but has been 
fixed long ago. Run update.packages() and try again.

> Here is the run and error:
> > bwplot(dev ~ Dbhcl | Period, data = DbhValid2, font = 2,
>
> +   main=list(" "), axis.font =2,
> +   ylab = list(label = "Residual (cm)", font = 2),
> +   xlab = list(label = "Dbh class (cm)", font = 2),
> +   par.strip.text=list(cex=0.8, font=2),
> +   panel=function(x, y) {
> +   panel.grid()
> +   panel.abline(h = 0)
> +   panel.bwplot(x, y, horizontal = TRUE)
> +   }
> +   )
>
> Error in "[<-"(`*tmp*`, pos.heights[[nm]], value = numeric(0)) :
>         nothing to replace with

If I remember correctly, this wasn't enough to trigger the problem in a fresh 
R session.

Deepayan



From dyang at NRCan.gc.ca  Fri Mar 11 22:28:56 2005
From: dyang at NRCan.gc.ca (Yang, Richard)
Date: Fri, 11 Mar 2005 16:28:56 -0500
Subject: [R] Lattice bwplot error
Message-ID: <F0E0B899CB43D5118D220002A55113CF04FE575C@s2-edm-r1.nrn.nrcan.gc.ca>

Thank, Deepayan Sarkar and Sundar Dorai-Raj for their quick responses. After
updating lattice, the problem resolved.

Richard

-----Original Message-----

Subject: [R] Lattice bwplot error


Dear all;

	Searching the R site for answers to my problem, but found none.

Here is the run and error:

> bwplot(dev ~ Dbhcl | Period, data = DbhValid2, font = 2,
+   main=list(" "), axis.font =2,
+   ylab = list(label = "Residual (cm)", font = 2),
+   xlab = list(label = "Dbh class (cm)", font = 2), 
+   par.strip.text=list(cex=0.8, font=2),
+   panel=function(x, y) {
+   panel.grid()
+   panel.abline(h = 0)
+   panel.bwplot(x, y, horizontal = TRUE)
+   }
+   )

Error in "[<-"(`*tmp*`, pos.heights[[nm]], value = numeric(0)) : 
        nothing to replace with

> str(DbhValid2$dev)
 num [1:11469] 0.318 0.764 1.230 0.403 0.526 ...
> str(DbhValid2$Dbhcl)
 Factor w/ 26 levels "2","3","4","5",..: 9 9 9 10 10 10 10 11 11 11 ...

Stepped through debugging bwplot(), I couldn't locate where the error
occurred (there are more than 11,000 data points). However, I had no problem
using boxplot() to generate four graphs separately:

> boxplot(dev ~ Dbhcl, data=DbhValid2[DbhValid2$period == 5,])

Any ideas and suggestions?

TIA,

Richard Yang


Northern Forestry Centre   /	Centre de foresterie du Nord
Canadian Forest Service	   /	Service canadien des for?ts
Natural Resources Canada   /	Ressources naturelles Canada
5320-122 Street     	   /	5320, rue 122

Edmonton Alberta Canada
T6H 3S5

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From srjafar at yahoo.com  Sat Mar 12 00:06:59 2005
From: srjafar at yahoo.com (Seyed Reza Jafarzadeh)
Date: Fri, 11 Mar 2005 15:06:59 -0800 (PST)
Subject: [R] Negative binomial regression for count data, 
In-Reply-To: 6667
Message-ID: <20050311230659.58146.qmail@web31004.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050311/e68c3fc5/attachment.pl

From spencer.graves at pdf.com  Sat Mar 12 01:03:00 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 11 Mar 2005 16:03:00 -0800
Subject: [R] Bonferroni simultaneous confidence intervals for multiple
	regression
In-Reply-To: <20050311122940.OMZT2034.tomts20-srv.bellnexxia.net@JohnDesktop8300>
References: <20050311122940.OMZT2034.tomts20-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <423231B4.1080601@pdf.com>

      John Fox described one version of the standard Bonferroni 
correction.  I just got 51 hits from "www.r-project.org" -> Search -> "R 
Site Search -> "Bonferroni";  you may wish to review them.  More 
generally, a Google search for "Bonferroni" produced "about 347,000" 
hits, the fifth of which was the NIST / Sematech Engineering Statistics 
Handbook 
(http://www.itl.nist.gov/div898/handbook/prc/section4/prc473.htm), which 
is quite useful for many things. 

      However, if package multcomp or multtest (in Bioconductor) 
suggested by Dieter Menne will work in your application, they would 
probably be better than Bonferroni.  Bonferroni is like using a sledge 
hammer to open a can.  The sledge hammer would work, but a can opener 
would be preferable.  Bonferroni will work when other things won't, so I 
would use something like multcomp or multtest when I could and 
Bonferroni otherwise. 

      hope this helps.  spencer graves

John Fox wrote:

>Dear Cara,
>
>You could use the confint() function, setting the level argument to 1 -
>alpha/length(coefficients(model)), where model is the linear model that
>you've fit and alpha is the complement of the level of confidence. If you're
>interested only in a subset of say p coefficients, then use 1 - alpha/p.
>
>I hope this helps,
> John
>
>--------------------------------
>John Fox
>Department of Sociology
>McMaster University
>Hamilton, Ontario
>Canada L8S 4M4
>905-525-9140x23604
>http://socserv.mcmaster.ca/jfox 
>-------------------------------- 
>
>  
>
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch 
>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Cara Gormally
>>Sent: Thursday, March 10, 2005 8:41 PM
>>To: R-help at stat.math.ethz.ch
>>Subject: [R] Bonferroni simultaneous confidence intervals for 
>>multipleregression
>>
>>Hi,
>>
>>I'm having no luck figuring out how to find Bonferroni 
>>simultaneous confidence intervals to obtain a family of 
>>estimates in R.  Does anyone know how to do this?
>>Thank you!
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From spencer.graves at pdf.com  Sat Mar 12 01:12:20 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 11 Mar 2005 16:12:20 -0800
Subject: [R] dates and graphic
In-Reply-To: <20050311172057.91132.qmail@web26906.mail.ukl.yahoo.com>
References: <20050311172057.91132.qmail@web26906.mail.ukl.yahoo.com>
Message-ID: <423233E4.30406@pdf.com>

      I'm not certain what you want, but will the following help you: 

plot(1:4, type="n")
text(1:4, letters[1:4])

      If this does NOT solve your problem, please tell us why it is 
deficient.  If you try something else that does not work, please 
describe what you tried and why you didn't like that, either. 

      hope this helps. 
p.s.  The posting guide "http://www.R-project.org/posting-guide.html" 
might help you find answers and / or formulate a question so it would 
more likely generate a useful reply. 

Riad BENGHIDA wrote:

>hi
>I'm student in master, for my work I use R software, I make a grphic, I will, for each point on graphic the corresponding date of consulting. The number of consultations is variable for the patients ( min=6, max= 44) 
>thank's 
>
>		
>---------------------------------
>
>mails !
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From dugas at dms.umontreal.ca  Sat Mar 12 04:49:43 2005
From: dugas at dms.umontreal.ca (Charles Dugas)
Date: Fri, 11 Mar 2005 22:49:43 -0500
Subject: [R] pretty print of summary
Message-ID: <8da163c5c8813b086da6784ffb90e7b4@dms.umontreal.ca>

Dear R-users,

using the interactive mode, the command
 > summary(my.survreg.object)
will output details of the object my.survreg.object in a very neat 
fashion.

I would like to have that sent to a file, in ascii format, as it 
appears within the interactive mode.
Is that possible ?

This seems like a very simple task, but i haven't found the solution:
- print doesn't care about a file option
- save(my.surreg.object,file="tmp",ascii=T) almost does it but puts 
every word on its own line,
so "tmp" contains a very long column of words.
- dump will output the structure of the object so it can be loaded back.
- write is suited for matrices of data, not arbitrary objects.
Something else i should look at ?

Thanks,
Chuck

---
Charles Dugas, Ph.D., A.S.A.
Professeur adjoint,
D?partement de Math?matiques et Statistique
Universit? de Montr?al
www.dms.umontreal.ca
t?l.	: (514) 343-6433
cell.	: (514) 592-9301



From MSchwartz at MedAnalytics.com  Sat Mar 12 04:56:04 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Fri, 11 Mar 2005 21:56:04 -0600
Subject: [R] pretty print of summary
In-Reply-To: <8da163c5c8813b086da6784ffb90e7b4@dms.umontreal.ca>
References: <8da163c5c8813b086da6784ffb90e7b4@dms.umontreal.ca>
Message-ID: <1110599764.18816.26.camel@horizons.localdomain>

On Fri, 2005-03-11 at 22:49 -0500, Charles Dugas wrote:
> Dear R-users,
> 
> using the interactive mode, the command
>  > summary(my.survreg.object)
> will output details of the object my.survreg.object in a very neat 
> fashion.
> 
> I would like to have that sent to a file, in ascii format, as it 
> appears within the interactive mode.
> Is that possible ?
> 
> This seems like a very simple task, but i haven't found the solution:
> - print doesn't care about a file option
> - save(my.surreg.object,file="tmp",ascii=T) almost does it but puts 
> every word on its own line,
> so "tmp" contains a very long column of words.
> - dump will output the structure of the object so it can be loaded back.
> - write is suited for matrices of data, not arbitrary objects.
> Something else i should look at ?


See either ?capture.output or ?sink

HTH,

Marc Schwartz



From tura at centroin.com.br  Sat Mar 12 12:15:42 2005
From: tura at centroin.com.br (Bernardo Rangel Tura)
Date: Sat, 12 Mar 2005 08:15:42 -0300
Subject: [R] Database reorganization
Message-ID: <6.1.2.0.2.20050312080520.048dc260@centroin.com.br>

Hi people,


I need reorganization several databases. I would like to know if that is 
possible in R. My problem is like that:

original data base:

Age     x1980   x1981
1       5       8
3       7       9
5       9       15
7       11      20

future data base

year    age     x
1980    1       5
1980    3       7
1980    5       9
1980    7       11
1981    1       8
1981    3       9
1981    5       15
1981    7       20



Thanks in advance

Bernardo Rangel Tura, MD, MSc
National Institute of Cardiology Laranjeiras
Rio de Janeiro Brazil 


-- 
No virus found in this outgoing message.
Checked by AVG Anti-Virus.



From oleg at sai.msu.su  Sat Mar 12 13:29:15 2005
From: oleg at sai.msu.su (Oleg Bartunov)
Date: Sat, 12 Mar 2005 15:29:15 +0300 (MSK)
Subject: [R] data frame excerption
Message-ID: <Pine.GSO.4.62.0503121524400.5508@ra.sai.msu.su>

Hello,

is't possible to get excerptions of data frame using some contstraints,
something like q1 = q[q$V3<1] ?

 	Regards,
 		Oleg
_____________________________________________________________
Oleg Bartunov, sci.researcher, hostmaster of AstroNet,
Sternberg Astronomical Institute, Moscow University (Russia)
Internet: oleg at sai.msu.su, http://www.sai.msu.su/~megera/
phone: +007(095)939-16-83, +007(095)939-23-83



From ggrothendieck at myway.com  Sat Mar 12 14:03:56 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 12 Mar 2005 13:03:56 +0000 (UTC)
Subject: [R] Database reorganization
References: <6.1.2.0.2.20050312080520.048dc260@centroin.com.br>
Message-ID: <loom.20050312T140151-265@post.gmane.org>

Bernardo Rangel Tura <tura <at> centroin.com.br> writes:

: original data base:
: 
: Age     x1980   x1981
: 1       5       8
: 3       7       9
: 5       9       15
: 7       11      20
: 
: future data base
: 
: year    age     x
: 1980    1       5
: 1980    3       7
: 1980    5       9
: 1980    7       11
: 1981    1       8
: 1981    3       9
: 1981    5       15
: 1981    7       20

Use reshape like this:

yn <- names(D)[2:3]
reshape(D, dir = "long", varying = list(yn), times = yn, v.names = "x")

and then do whatever fix ups you need on the result.



From ales.ziberna at guest.arnes.si  Sat Mar 12 13:55:16 2005
From: ales.ziberna at guest.arnes.si (=?iso-8859-1?Q?Ales_Ziberna?=)
Date: Sat, 12 Mar 2005 13:55:16 +0100
Subject: [R] data frame excerption
References: <Pine.GSO.4.62.0503121524400.5508@ra.sai.msu.su>
Message-ID: <003301c52708$e0996ca0$0109f9c2@ales>

Yes it is!

you should write:

q1 <- q[q$V3<1,]

Since the data.frame has two indices, the first one indicating rows, which 
is what you need!

Regards,
Ales Ziberna


----- Original Message ----- 
From: "Oleg Bartunov" <oleg at sai.msu.su>
To: "R-help" <R-help at stat.math.ethz.ch>
Sent: Saturday, March 12, 2005 1:29 PM
Subject: [R] data frame excerption


> Hello,
>
> is't possible to get excerptions of data frame using some contstraints,
> something like q1 = q[q$V3<1] ?
>
>  Regards,
>  Oleg
> _____________________________________________________________
> Oleg Bartunov, sci.researcher, hostmaster of AstroNet,
> Sternberg Astronomical Institute, Moscow University (Russia)
> Internet: oleg at sai.msu.su, http://www.sai.msu.su/~megera/
> phone: +007(095)939-16-83, +007(095)939-23-83
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
>



From liuwensui at gmail.com  Sat Mar 12 15:08:42 2005
From: liuwensui at gmail.com (Wensui Liu)
Date: Sat, 12 Mar 2005 09:08:42 -0500
Subject: [R] any book and tutorial about how to manipulate data with R/S+
Message-ID: <1115a2b0050312060831892ba3@mail.gmail.com>

In real world, data manipulation might take even longer time and more
effort than statistical analysis and modeling.

Does anyone know a good book and tutorial about data manupulation?
Thank you so much.

-- 
WenSui Liu, MS MA
Senior Decision Support Analyst
Division of Health Policy and Clinical Effectiveness



From ligges at statistik.uni-dortmund.de  Sat Mar 12 15:21:44 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 12 Mar 2005 15:21:44 +0100
Subject: [R] warning message when using anova
In-Reply-To: <Pine.LNX.4.43.0503110955550.9444@hymn06.u.washington.edu>
References: <Pine.LNX.4.43.0503110955550.9444@hymn06.u.washington.edu>
Message-ID: <4232FAF8.8000201@statistik.uni-dortmund.de>

tpeng at u.washington.edu wrote:

> Hi can someone help me with the following warning message I got when I 
> used two
> way anova: Warning messages: 1: Models with response "NULL" removed because
> response differs from model 1 in: anova.lmlist(object, ...) 2: Models with
> response "NULL" removed because response differs from model 1 in:
> anova.lmlist(object, ...)
>  (I have two rows of separate data sets)
> 
> Thanks in advance,
> 
> tao


Instead of re-posting your question, please read the posting guide and 
tell us a) what you are going to do and b) specify  a simple but 
reproducible example with your code that fails...
Your question is too unspecific in order to help.

Uwe Ligges



> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From tom_hoary at web.de  Sat Mar 12 15:34:06 2005
From: tom_hoary at web.de (Thomas =?iso-8859-1?q?Sch=F6nhoff?=)
Date: Sat, 12 Mar 2005 15:34:06 +0100
Subject: [R] any book and tutorial about how to manipulate data with R/S+
In-Reply-To: <1115a2b0050312060831892ba3@mail.gmail.com>
References: <1115a2b0050312060831892ba3@mail.gmail.com>
Message-ID: <200503121534.06453.tom_hoary@web.de>

Hallo,

Am Samstag, 12. M?rz 2005 15:08 schrieb Wensui Liu:
> In real world, data manipulation might take even longer time and
> more effort than statistical analysis and modeling.
>
> Does anyone know a good book and tutorial about data manupulation?
> Thank you so much.

Well, it would be much easier to meet your demands if you could give 
us an idea what you exactly looking for.
Anyway, there are some recommendations in R-Manual regarding 
introduxtory materials on doing statistics in R. If I remember 
correctly there are also some advices on r-cran.org in the generell 
FAQ.
If you're looking for some introductory stuff doing data manipulation 
in R the book of Peter Dalgaard, Introductory Statistics with R 
should be taken into consideration.
Not long time ago there was a similar question to this list, giving 
the whole range of available books on statistics in S/R . Have a look 
at http://maths.newcastle.edu.au/~rking/R/, you'll will be 
overwhelmed.
Last but not least, if you look at r-cran website you'll find in 
contributed section some case-oriented tutorials, i.e. data mining or 
similar stuff!

regards

Thomas



From ligges at statistik.uni-dortmund.de  Sat Mar 12 15:27:33 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 12 Mar 2005 15:27:33 +0100
Subject: [R] R: LIST function and LOOPS
In-Reply-To: <42318BE2.1415B7E5@STATS.uct.ac.za>
References: <42300277.D8ED0580@STATS.uct.ac.za>	<1110468574.7407.19.camel@ndmpc126.orc.ox.ac.uk>
	<42318BE2.1415B7E5@STATS.uct.ac.za>
Message-ID: <4232FC55.6000906@statistik.uni-dortmund.de>

Clark Allan wrote:

> hi 
> 
> thanx for the help. i dont want to use matrices. i solve my problem, see
> the example below.
> 
> the set.seed is used because in my actual application i need to generate
> INDEPENDENT variables. will this ensure that the variables are
> independent? 

Why do you want to set.seed() inside the loop?
Just set it once at the beginning of your simulation in order to get 
reproducible results - you can assume independence anyway.
Or maybe I am missing the point why you are going to set.seed() inside 
the loop.

Uwe Ligges



> 
> z3<-function(w)
> {
> for (i in 1:w)
> {
> ss<-0
>        for (j in 1:5)
>        {
>                 set.seed(j+1+(i-1)*6)
>                 r<-rnorm(1)
>         	ss<-ss+r
> 		a<-list(ss=ss,r=r)
>        }
> print(paste("############ i=",i,"############"))
> print(a)
> }
> }
> z3(3)
> 
> 
> 
> 
>>z3(3)
> 
> [1] "############ i= 1  ############"
> $ss
> [1] -2.213343
> 
> $r
> [1] 0.269606
> 
> [1] "############ i= 2  ############"
> $ss
> [1] -2.904235
> 
> $r
> [1] -1.480568
> 
> [1] "############ i= 3  ############"
> $ss
> [1] -0.01516304
> 
> $r
> [1] 0.9264592
> 
> 
> thanx again
> 
> ***
> allan
> 
> ###############################################################################################
> ###############################################################################################
> ###############################################################################################
> ###############################################################################################
> ###############################################################################################
> ###############################################################################################
> 
> 
> Adaikalavan Ramasamy wrote:
> 
>>You will need to capture the value of ss at the end of each 'i' as such
>>
>>z4 <-function(w){
>>
>>  output <- numeric(w)
>>
>>  for (i in 1:w){
>>
>>    set.seed(i+6)  # this is redundant line
>>    ss<-0
>>
>>    for (j in 1:5){
>>      set.seed(j+1+(i-1)*6)
>>      r<-rnorm(1)
>>      ss<-ss+r
>>    }
>>
>>    output[i] <- ss
>>  }
>>  return(output)
>>}
>>
>>BTW, I do not think it is a good idea to set.seed() so many times.
>>
>>To answer you more general question, see if the following is useful.
>>I am trying to simulate 'n' values from a standard normal distribution
>>but 'n' is random variable itself.
>>
>>f <-function(w, lambda=3){
>>
>>  tmp <- list(NULL)
>>
>>  for (i in 1:w){
>>    n <- 1 + rpois(1, lambda=lambda)  # number of simulation required
>>    tmp[[ i ]]  <- rnorm(n)
>>  }
>>
>>  # flatten the list into a ragged matrix
>>  out.lengths   <- sapply(tmp, length)
>>  out           <- matrix( nr=w, nc=max( out.lengths ) )
>>  rownames(out) <- paste("w =", 1:w)
>>  for(i in 1:w) out[i, 1:out.lengths[i] ] <- tmp[[i]]
>>
>>  return(out)
>>}
>>
>>f(6, lambda=3)
>>
>>It is not very elegant but I hope that helps you out somehow.
>>
>>Regards, Adai
>>
>>On Thu, 2005-03-10 at 10:16 +0200, Clark Allan wrote:
>>
>>>hi all
>>>
>>>another simple question.
>>>
>>>i've written a dummy program so that you get the concept. (the code
>>>could be simplfied such that there are no loops. but lets leave the
>>>loops in for now.)
>>>
>>>z1<-function(w)
>>>{
>>>for (i in 1:w)
>>>{
>>>set.seed(i+6)
>>>ss<-0
>>>      for (j in 1:5)
>>>      {
>>>              set.seed(j+1+(i-1)*6)
>>>              r<-rnorm(1)
>>>              ss<-ss+r
>>>      }
>>>list(ss=ss)
>>>}
>>>}
>>>check.1<-z1(3)
>>>check.1
>>>
>>>the results is:
>>>$ss
>>>[1] -0.01516304
>>>
>>>
>>>what i want is something that looks like this:
>>>
>>>j=1
>>>$ss
>>>[1] -2.213343
>>>
>>>j=2
>>>$ss
>>>[1] -2.904235
>>>
>>>j=3
>>>$ss
>>>[1] -0.01516304
>>>
>>>
>>>i know that i could use the print command. (see z2)
>>>
>>>z2<-function(w)
>>>{
>>>for (i in 1:w)
>>>{
>>>set.seed(i+6)
>>>ss<-0
>>>      for (j in 1:5)
>>>      {
>>>              set.seed(j+1+(i-1)*6)
>>>              r<-rnorm(1)
>>>              ss<-ss+r
>>>      }
>>>print(ss)
>>>}
>>>}
>>>check.2<-z2(3)
>>>check.2
>>>
>>>
>>>>check.2<-z2(3)
>>>
>>>[1] -2.213343
>>>[1] -2.904235
>>>[1] -0.01516304
>>>
>>>>check.2
>>>
>>>[1] -0.01516304
>>>
>>>the problem with z2 is that only the last value is saved.
>>>
>>>
>>>what i could do is use matrices like the following: (but i dont want to
>>>do this AND WOULD PREFER TO USE list.)
>>>
>>>z3<-function(w)
>>>{
>>>results.<-matrix(nrow=w,ncol=1)
>>>colnames(results.)<-c("ss")
>>>for (i in 1:w)
>>>{
>>>set.seed(i+6)
>>>ss<-0
>>>      for (j in 1:5)
>>>      {
>>>              set.seed(j+1+(i-1)*6)
>>>              r<-rnorm(1)
>>>              ss<-ss+r
>>>      }
>>>results.[i,1]<-ss
>>>}
>>>results.
>>>}
>>>check.3<-z3(3)
>>>check.3
>>>
>>>
>>>>check.3
>>>
>>>              ss
>>>[1,] -2.21334260
>>>[2,] -2.90423463
>>>[3,] -0.01516304
>>>
>>>what if i have a new program (something different) and i want the
>>>following:
>>>
>>>j=1
>>>$a
>>>1
>>>2
>>>3
>>>
>>>$b
>>>1
>>>2
>>>3
>>>4
>>>5
>>>
>>>$c
>>>1
>>>
>>>
>>>###############
>>>j=2
>>>$a
>>>11
>>>21
>>>31
>>>
>>>$b
>>>11
>>>21
>>>31
>>>41
>>>51
>>>
>>>$c
>>>11
>>>
>>>###############
>>>j=3
>>>$a
>>>21
>>>22
>>>32
>>>
>>>$b
>>>21
>>>22
>>>32
>>>42
>>>52
>>>
>>>$c
>>>21
>>>
>>>MATRICES SEEMS TO BE A GOOD WAY OF DOING THIS (but then you would have
>>>to set up three matrices, one for a,b and c). BUT WHAT IF I WANT TO USE
>>>THE LIST FUNCTION? i.e. there is a list in the first loop that i want to
>>>display!
>>>
>>>sorry for the long mail.
>>>
>>>***
>>>ALLAN
>>>______________________________________________ R-help at stat.math.ethz.ch mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>
>>>
>>>------------------------------------------------------------------------
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Sat Mar 12 15:29:12 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 12 Mar 2005 15:29:12 +0100
Subject: [R] data frame excerption
In-Reply-To: <Pine.GSO.4.62.0503121524400.5508@ra.sai.msu.su>
References: <Pine.GSO.4.62.0503121524400.5508@ra.sai.msu.su>
Message-ID: <4232FCB8.709@statistik.uni-dortmund.de>

Oleg Bartunov wrote:

> Hello,
> 
> is't possible to get excerptions of data frame using some contstraints,
> something like q1 = q[q$V3<1] ?

Yes, but you have to use the indexing matrix-like (see the manuals):

   q1 <- q[q$V3 < 1, ]

Uwe Ligges


> 
>     Regards,
>         Oleg
> _____________________________________________________________
> Oleg Bartunov, sci.researcher, hostmaster of AstroNet,
> Sternberg Astronomical Institute, Moscow University (Russia)
> Internet: oleg at sai.msu.su, http://www.sai.msu.su/~megera/
> phone: +007(095)939-16-83, +007(095)939-23-83
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From constant.depiereux at aqte.be  Sat Mar 12 15:44:08 2005
From: constant.depiereux at aqte.be (Depiereux Constant)
Date: Sat, 12 Mar 2005 15:44:08 +0100
Subject: [R] New user of R on Mac OS X - Please help
Message-ID: <a34f655784e0ef1b658910190dcd19f2@aqte.be>

Brand new Mac OS X user, I am transfering my R stuffs from my windows 
machine.

When porting some of my functions, I got messages such as  :

2005-03-12 15:37:52.456 R[673] *** NSTimer discarding exception 
'NSRangeException' (reason '*** NSRunStorage, _NSBlockNumberForIndex(): 
index (3607) beyond array bounds (2000)') that raised during firing of 
timer with target 3ba850 and selector 'runRELP:'

Does any body of you have any idea where I should be starting looking 
for a solution for ditto?

Thnaks in advance four your help.


Constant Depi?reux
Managing Director
Applied Quality Technologies Europe sprl
Rue des D?port?s 123, B4800   Verviers
Tel : + 32 87 29 21 75
Fax : +32 87 29 21 71
Mobile : +32 475 555 818
e-Mail : constant.depiereux at aqte.be
Web presence : http://www.aqte.be



From ligges at statistik.uni-dortmund.de  Sat Mar 12 15:44:52 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 12 Mar 2005 15:44:52 +0100
Subject: [R] difficulties with the save.image() function
In-Reply-To: <smtpd.7419.4231d7ba.7a514.1@mtaout-c.tc.umn.edu>
References: <smtpd.7419.4231d7ba.7a514.1@mtaout-c.tc.umn.edu>
Message-ID: <42330064.9010605@statistik.uni-dortmund.de>

Tracy Bergemann wrote:

> Dear list,
> 
> I've had difficulty saving my workspace to an .RData file.
> This causes considerable frustration as it means that I have to regenerate
> my analysis every time I want to update it.  For microarray data in
> particular, this can be quite time consuming.
> 
> I'm saving my data to a network folder on my system in Windows XP, something
> like an "H:\" drive or a "P:\" drive instead of a "C:\" drive.
> 
> Here is the command which saves my workspace to my working directory:
> save.image("H:/Consulting/cmlExprA.RData")
> And here is the error I get:
> Error in save(list = ls(envir = .GlobalEnv, all.names = TRUE), file =
> outfile,: error writing to connection
> 
> Any assistance?


- Do you have write access?
- Is there enough space available?
- Any quota?
- Can you save on a local drive, say a temp directory?
- How big is the file size? ("microarray" make me assume it is huge, so 
is it > 2GB?, does the system support the file size?)

- What is the output of
  file.info("H:/Consulting/cmlExprA.RData")
and
  file.info("H:/Consulting")


Uwe Ligges



> Many thanks,
> Tracy L. Bergemann, PhD
> Biostatistics Core
> University of Minnesota Cancer Center
> B412-4 Mayo building
> Office # 626-5408
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Sat Mar 12 16:23:12 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 12 Mar 2005 16:23:12 +0100
Subject: [R] Errors reading data file?
In-Reply-To: <4230F02C.7090402@subtlety.com>
References: <20050302082421.73405.qmail@web25805.mail.ukl.yahoo.com>
	<4230F02C.7090402@subtlety.com>
Message-ID: <42330960.402@statistik.uni-dortmund.de>

Chris Bergstresser wrote:

> Hi all --
> 
>    I tried loading a data file with the following command:
> 
>  > data = read.table("filename.txt", header = TRUE, sep = ",")
> 
>    This appeared to work fine, except it silently skipped 400 records 
> (out of 1200).  It turns out, some of the text fields included quotes, 
> and I needed to use 'quote = ""'.
>    Why wasn't there an error message?  Is there some way to enable one?
> 
> -- Chris
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html


Can you please specify a very short example (5 lines or so) that you 
think fails without appropriate error message?

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Sat Mar 12 16:34:23 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 12 Mar 2005 16:34:23 +0100
Subject: [R] xlab cex bug in Lattice/grid and multipage-output (Windows
	only?)
In-Reply-To: <INEGIMHGODBGKFPOJBBMKEGPCDAA.dieter.menne@menne-biomed.de>
References: <INEGIMHGODBGKFPOJBBMKEGPCDAA.dieter.menne@menne-biomed.de>
Message-ID: <42330BFF.4040007@statistik.uni-dortmund.de>

Dieter Menne wrote:

> The following problem seems to be Windows-specific. Deepayan informed me
> that it cannot be reproduced on "platform i386-pc-linux-gnu".
> 
> -----
> library(lattice)
> trellis.device("png", file="sepal%02d.png",color=T,  theme="col.whitebg")
> p=xyplot(Sepal.Length + Sepal.Width ~ Petal.Length + Petal.Width | Species,
>        data = iris, scales = "free", layout = c(1, 1)
>        )
> 
> print(p)
> dev.off()


Works with a recent version of R-devel (and corresponding version of 
lattice), so seems to be fixed.

Uwe Ligges




> ----
> 
> Compare the x-label on the first and on all following pages: font size is
> different.
> Same for bmp. Does not occur on multipage-devices such as ps.
> By comparing with the png files from Deepayan/Linux, I believe that only the
> first xlab has the correct small size, and all others are not correct.
> 
> My version: (all libraries updated today)
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    0.1
> year     2004
> month    11
> day      15
> language R
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Sat Mar 12 17:14:05 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 12 Mar 2005 17:14:05 +0100
Subject: [R] R-help:loading data from text file and viewing it in persp
In-Reply-To: <20050310122732.20146.qmail@web8502.mail.in.yahoo.com>
References: <20050310122732.20146.qmail@web8502.mail.in.yahoo.com>
Message-ID: <4233154D.2010608@statistik.uni-dortmund.de>

Lakshmi Dhevi Baskar wrote:

> Hi All
>  
> i would like to get some help on how to use the persp() for 3d surface plotting with the data from txt file.
>  
>  
> it has format like
>  
> x1 y1 z1
> x2 y2 z2
> x3 y3 z3
> ............
>  
> and so on...sometimes the txt file data may be very large also..
> how could i load this txt file and view its 3d view.
>


How to import data: "R Data Import/Export" Manual
How to manipulate data to a matrix usable in persp(): "An Introduction 
to R".
How to use persp: ?persp

Uwe Ligges



> thanks in advance
>  
>  
> 
> 		
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Sat Mar 12 17:15:29 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 12 Mar 2005 17:15:29 +0100
Subject: [R] plotting
In-Reply-To: <1110392918.422f40568c26e@my2.dal.ca>
References: <1110392918.422f40568c26e@my2.dal.ca>
Message-ID: <423315A1.10709@statistik.uni-dortmund.de>

Owen Buchner wrote:

> I have two questions for you.  Firstly I'm having troubles trying to plot more
> then 1 graph.  I'm attempting to make a plot with 9 panels, but i have no clue
> what type of code to use.

See ?par and its argument "mar", or ?layout, or even better the latice 
package.


> Secondly i was wondering if there was some code to generate random numbers
> between two defined intervals and then have R chose one randomly in a program. 
> If you could answer either of these questions for me I would appreciate it.

*Uniformly* distributed random numbers? -> see ?runif

Uwe Ligges


> 
> Owen Buchner
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Sat Mar 12 17:17:32 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 12 Mar 2005 17:17:32 +0100
Subject: [R] R CMD check errors
In-Reply-To: <422F3550.2010108@imperial.ac.uk>
References: <20050309161310.9F63A8E159@mailu2.upmf-grenoble.fr>
	<422F3550.2010108@imperial.ac.uk>
Message-ID: <4233161C.4020205@statistik.uni-dortmund.de>

Chris Jackson wrote:

> In my experience these are usually signs of an error in your NAMESPACE
> file, such as a function name in the NAMESPACE which does not match the
> function name in the package.

If the NAMESPACE is not the problem (is it???) there are several other 
points - one has to look closer.

Does the package work properly after INSTALLing it? Is there a filled 
./data directory?

Uwe Ligges


> Chris
> 
> Ollivier TARAMASCO wrote:
> 
>  > I wrote a library which seems to work on my PC, and on different Unix
>  > systems.
>  >
>  > As it is written in the "Writing R Extensions" manual, I execute a R CMD
>  > check on my library.
>  >
>  >
>  > I have always the same errors messages:
>  >
>  > * checking S3 generic/method consistency ... WARNING
>  > Error in .try_quietly({ : Error in library(package, lib.loc = lib.loc,
>  > character
>  > .only = TRUE, verbose = FALSE) :
>  >         package/namespace load failed for 'TATA'
>  > Execution halted
>  >
>  > See section 'Generic functions and methods' of the 'Writing R 
> Extensions'
>  > manual.
>  >
>  >
>  > * checking replacement functions ... WARNING
>  > Error in .try_quietly({ : Error in library(package, lib.loc = lib.loc,
>  > character
>  > .only = TRUE, verbose = FALSE) :
>  >         package/namespace load failed for 'TATA'
>  > Execution halted
>  >
>  > In R, the argument of a replacement function which corresponds to the 
> right
>  > hand side must be named 'value'.
>  >
>  >
>  > * checking foreign function calls ... WARNING
>  > Error in .try_quietly({ : Error in library(package, lib.loc = lib.loc,
>  > character
>  > .only = TRUE, verbose = FALSE) :
>  >         package/namespace load failed for 'TATA'
>  > Execution halted
>  > See section 'System and foreign language interfaces' of the 'Writing R
>  > Extensions' manual.
> 
>



From carsten.steinhoff at gmx.de  Sat Mar 12 17:48:19 2005
From: carsten.steinhoff at gmx.de (Carsten Steinhoff)
Date: Sat, 12 Mar 2005 17:48:19 +0100
Subject: [R] MLE for two random variables
In-Reply-To: <200503121111.j2CB5LxB008618@hypatia.math.ethz.ch>
Message-ID: <200503121648.j2CGmUFA010533@hypatia.math.ethz.ch>

Hello,

I've the following setting:

(1) Data from a source without truncation		(x)

(2) Data from an other source with left-truncation at threshold u	(xu)

I have to fit a model on these these two sources, thereby I assume that both
are "drawn" from the same distribution (eg lognormal). In a MLE I would sum
the densities and maximize. The R-Function could be:

function(x,xu,u,mu,sigma)
dlnorm(x,mu,sigma)+(dlnorm(xu,mu,sigma)/(plnorm(u,mu,sigma)))

So I tried to use the function FITDISTR for the MLE. But unfortunately it
only accepts ONE random variable.
Then I tried to combine x and xu in a vector, but that doesn't work, too,
because the length of x and xu differs.

Does anybody has a solution for my problem?

Thanks in advance.

Carsten



From spencer.graves at pdf.com  Sat Mar 12 20:13:18 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 12 Mar 2005 11:13:18 -0800
Subject: [R] MLE for two random variables
In-Reply-To: <200503121648.j2CGmUFA010533@hypatia.math.ethz.ch>
References: <200503121648.j2CGmUFA010533@hypatia.math.ethz.ch>
Message-ID: <42333F4E.7020008@pdf.com>

    Just to make sure, do you have any information on events when xu > 
u, i.e. do you know how many such events and you know u for those 
events?  If yes, then that's called "censoring", not truncating.  For 
that, the survival package seems pretty good.  I found the information 
in Venables and Ripley, Modern Applied Statistics with S, helpful. 

      If you don't have data when xu > u, do you know u or must that be 
estimated also?  In either case, I would likely use "optim", though 
"nlm" might work also.  If I knew u and didn't have to estimate it, then 
I might combine the data as follows: 

XU <- data.frame(x=c(x,xu),
     u=c(rep(0, length(x)), rep(u, length(xu))))

      If I needed to estimate u, I'd modify this as follows: 

XU. <- data.frame(x=c(x,xu),
     u=c(rep(0, length(x)), rep(1, length(xu))))

      Then I'd write a function to compute, e.g, dev = 
(-2)*log(likelihood) and use optim or nlm to minimize this.  If I had to 
estimate u, I might actually try to estimate ln.up = log(u-max(xu));  I 
may or may not get better numerical convergence using this than trying 
to estimate u directly. 

      hope this helps. 
      spencer graves     

Carsten Steinhoff wrote:

>Hello,
>
>I've the following setting:
>
>(1) Data from a source without truncation		(x)
>
>(2) Data from an other source with left-truncation at threshold u	(xu)
>
>I have to fit a model on these these two sources, thereby I assume that both
>are "drawn" from the same distribution (eg lognormal). In a MLE I would sum
>the densities and maximize. The R-Function could be:
>
>function(x,xu,u,mu,sigma)
>dlnorm(x,mu,sigma)+(dlnorm(xu,mu,sigma)/(plnorm(u,mu,sigma)))
>
>So I tried to use the function FITDISTR for the MLE. But unfortunately it
>only accepts ONE random variable.
>Then I tried to combine x and xu in a vector, but that doesn't work, too,
>because the length of x and xu differs.
>
>Does anybody has a solution for my problem?
>
>Thanks in advance.
>
>Carsten
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From pensterfuzzer at yahoo.de  Sat Mar 12 21:12:58 2005
From: pensterfuzzer at yahoo.de (Werner Wernersen)
Date: Sat, 12 Mar 2005 21:12:58 +0100 (CET)
Subject: [R] Multiple histograms in one chart
Message-ID: <20050312201258.93063.qmail@web25801.mail.ukl.yahoo.com>

Hi!

I've searched quite a while and this is probably a
very easy question: How do I 
prevent a new hist() histogram from clearing the chart
window before drawing?

I would like to have several histograms simply drawn
on each other in one chart...

Thanks for your help!
   Werner

In use: win2ksp4 & R 2.0.1



From liuwensui at gmail.com  Sat Mar 12 21:42:35 2005
From: liuwensui at gmail.com (Wensui Liu)
Date: Sat, 12 Mar 2005 15:42:35 -0500
Subject: [R] any book and tutorial about how to manipulate data with R/S+
In-Reply-To: <200503121534.06453.tom_hoary@web.de>
References: <1115a2b0050312060831892ba3@mail.gmail.com>
	<200503121534.06453.tom_hoary@web.de>
Message-ID: <1115a2b00503121242302acec6@mail.gmail.com>

I am sorry that I did not state my question clearly. 

What I mean by data manipulation includes sort, merge, aggregate,
transpose, data export and import, format, date & time handle, and so
on, which might be not important to statistician.

I have use SAS and SPSS for a while and really want to use R as an
alternative computing system. Unless R/S+ can provide strong
functionality in data manipulation as SAS does, it is hard to compete
with SAS in business rather than in academic.


On Sat, 12 Mar 2005 15:34:06 +0100, Thomas Sch?nhoff <tom_hoary at web.de> wrote:
> Hallo,
> 
> Am Samstag, 12. M?rz 2005 15:08 schrieb Wensui Liu:
> > In real world, data manipulation might take even longer time and
> > more effort than statistical analysis and modeling.
> >
> > Does anyone know a good book and tutorial about data manupulation?
> > Thank you so much.
> 
> Well, it would be much easier to meet your demands if you could give
> us an idea what you exactly looking for.
> Anyway, there are some recommendations in R-Manual regarding
> introduxtory materials on doing statistics in R. If I remember
> correctly there are also some advices on r-cran.org in the generell
> FAQ.
> If you're looking for some introductory stuff doing data manipulation
> in R the book of Peter Dalgaard, Introductory Statistics with R
> should be taken into consideration.
> Not long time ago there was a similar question to this list, giving
> the whole range of available books on statistics in S/R . Have a look
> at http://maths.newcastle.edu.au/~rking/R/, you'll will be
> overwhelmed.
> Last but not least, if you look at r-cran website you'll find in
> contributed section some case-oriented tutorials, i.e. data mining or
> similar stuff!
> 
> regards
> 
> Thomas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
WenSui Liu, MS MA
Senior Decision Support Analyst
Division of Health Policy and Clinical Effectiveness



From constant.depiereux at aqte.be  Sat Mar 12 23:21:32 2005
From: constant.depiereux at aqte.be (Depiereux Constant)
Date: Sat, 12 Mar 2005 23:21:32 +0100
Subject: [R] RODBC, IODBC and Mac OS X
Message-ID: <7357744174790b1d6636042fdf8afce1@aqte.be>

Dear All,

As some of you in the archive, i am experiencing problems in using 
RODBC with IODBC on Mac OS X Panther.

I am currrently facing two problems.

The first one is apparently linked with IODBC (according to returned R 
error message) although testing the database access from IODBC manager 
seems to work fine.

The second is by far more radical, R purely and simply reports an error 
, blocks and I finally got a Mac OS X message.

I browsed the archive without really finding a solution. Before 
spending lengthy hours on an operating system that I am currently 
discovering, I have therefore a simple question :

DOES ANY BODY HAVE A COOKBOOK EXPLAINING HOW TO ACCESS - THRU ODBC - A 
POSTGRESQL DATABASE USING R ON MAC OS X PANTHER ?

Thanks in advance for your help.





Constant Depi?reux
Managing Director
Applied Quality Technologies Europe sprl
Rue des D?port?s 123, B4800   Verviers
Tel : + 32 87 29 21 75
Fax : +32 87 29 21 71
Mobile : +32 475 555 818
e-Mail : constant.depiereux at aqte.be
Web presence : http://www.aqte.be



From deepayan at stat.wisc.edu  Sat Mar 12 23:46:54 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sat, 12 Mar 2005 16:46:54 -0600
Subject: [R] any book and tutorial about how to manipulate data with R/S+
In-Reply-To: <1115a2b00503121242302acec6@mail.gmail.com>
References: <1115a2b0050312060831892ba3@mail.gmail.com>
	<200503121534.06453.tom_hoary@web.de>
	<1115a2b00503121242302acec6@mail.gmail.com>
Message-ID: <200503121646.54940.deepayan@stat.wisc.edu>

On Saturday 12 March 2005 14:42, Wensui Liu wrote:
> I am sorry that I did not state my question clearly.
>
> What I mean by data manipulation includes sort, merge, aggregate,
> transpose, data export and import, format, date & time handle, and so
> on, which might be not important to statistician.
>
> I have use SAS and SPSS for a while and really want to use R as an
> alternative computing system. Unless R/S+ can provide strong
> functionality in data manipulation as SAS does, it is hard to compete
> with SAS in business rather than in academic.

Take a look at the 'R Data Import/Export' manual at 

http://cran.us.r-project.org/manuals.html

as well as 

http://cran.us.r-project.org/other-docs.html --

`An Introduction to S and the Hmisc and Design Libraries' by Carlos 
Alzola and Frank E. Harrell, especially of interest to SAS users, users 
of the Hmisc or Design packages, or R users interested in data 
manipulation, recoding, etc. 

might cover some of what you are looking for.

>
> On Sat, 12 Mar 2005 15:34:06 +0100, Thomas Sch?nhoff 
<tom_hoary at web.de> wrote:
> > Hallo,
> >
> > Am Samstag, 12. M?rz 2005 15:08 schrieb Wensui Liu:
> > > In real world, data manipulation might take even longer time and
> > > more effort than statistical analysis and modeling.
> > >
> > > Does anyone know a good book and tutorial about data
> > > manupulation? Thank you so much.
> >
> > Well, it would be much easier to meet your demands if you could
> > give us an idea what you exactly looking for.
> > Anyway, there are some recommendations in R-Manual regarding
> > introduxtory materials on doing statistics in R. If I remember
> > correctly there are also some advices on r-cran.org in the generell
> > FAQ.
> > If you're looking for some introductory stuff doing data
> > manipulation in R the book of Peter Dalgaard, Introductory
> > Statistics with R should be taken into consideration.
> > Not long time ago there was a similar question to this list, giving
> > the whole range of available books on statistics in S/R . Have a
> > look at http://maths.newcastle.edu.au/~rking/R/, you'll will be
> > overwhelmed.
> > Last but not least, if you look at r-cran website you'll find in
> > contributed section some case-oriented tutorials, i.e. data mining
> > or similar stuff!
> >
> > regards
> >
> > Thomas



From sdavis2 at mail.nih.gov  Sun Mar 13 00:07:55 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Sat, 12 Mar 2005 18:07:55 -0500
Subject: [R] RODBC, IODBC and Mac OS X
References: <7357744174790b1d6636042fdf8afce1@aqte.be>
Message-ID: <000e01c52758$538b71a0$1f6df345@WATSON>

Have you looked at these two packages that, together, provide Postgres 
access and do not require ODBC?  I have found them quite useful and I use 
them on Panther:

http://www.bioconductor.org/repository/release1.5/package/html/Rdbi.html
http://www.bioconductor.org/repository/release1.5/package/html/RdbiPgSQL.html

Sean

----- Original Message ----- 
From: "Depiereux Constant" <constant.depiereux at aqte.be>
To: <r-help at stat.math.ethz.ch>
Sent: Saturday, March 12, 2005 5:21 PM
Subject: [R] RODBC, IODBC and Mac OS X


> Dear All,
>
> As some of you in the archive, i am experiencing problems in using RODBC 
> with IODBC on Mac OS X Panther.
>
> I am currrently facing two problems.
>
> The first one is apparently linked with IODBC (according to returned R 
> error message) although testing the database access from IODBC manager 
> seems to work fine.
>
> The second is by far more radical, R purely and simply reports an error , 
> blocks and I finally got a Mac OS X message.
>
> I browsed the archive without really finding a solution. Before spending 
> lengthy hours on an operating system that I am currently discovering, I 
> have therefore a simple question :
>
> DOES ANY BODY HAVE A COOKBOOK EXPLAINING HOW TO ACCESS - THRU ODBC - A 
> POSTGRESQL DATABASE USING R ON MAC OS X PANTHER ?
>
> Thanks in advance for your help.
>
>
>
>
>
> Constant Depi?reux
> Managing Director
> Applied Quality Technologies Europe sprl
> Rue des D?port?s 123, B4800   Verviers
> Tel : + 32 87 29 21 75
> Fax : +32 87 29 21 71
> Mobile : +32 475 555 818
> e-Mail : constant.depiereux at aqte.be
> Web presence : http://www.aqte.be
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From esimpson at fas.harvard.edu  Sun Mar 13 00:25:19 2005
From: esimpson at fas.harvard.edu (Erin M Simpson)
Date: Sat, 12 Mar 2005 18:25:19 -0500 (EST)
Subject: [R] generalized negative binomial
Message-ID: <Pine.LNX.4.58.0503121818210.15155@ls02.fas.harvard.edu>


I am looking for code that allows for a more flexible negative binomial
model (similar to Stata's "gnbreg").

In particular, I am looking to be able to model the ancillary
shape parameter in terms of a series of covariates.   So if,

	y[i] ~ poisson(mu[i])

	mu[i] = exp(x[i]beta + u[i])

	exp(u[i]) ~ Gamma(1/alpha, alpha)

I am looking to parameterize alpha as exp(z[i]gamma).

If you are familiar with a package that allows for this, I'd appreciate
the heads up.  Similar information that allows for first differences with
such a model is also appreciated.

Thanks.

Erin

---------------
Erin M Simpson
esimpson at fas.harvard.edu
http://people.fas.harvard.edu/~esimpson



From edd at debian.org  Sun Mar 13 01:07:43 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 12 Mar 2005 18:07:43 -0600
Subject: [R] any book and tutorial about how to manipulate data with R/S+
In-Reply-To: <1115a2b00503121242302acec6@mail.gmail.com>
References: <1115a2b0050312060831892ba3@mail.gmail.com>
	<200503121534.06453.tom_hoary@web.de>
	<1115a2b00503121242302acec6@mail.gmail.com>
Message-ID: <16947.33871.629708.595093@basebud.nulle.part>


On 12 March 2005 at 15:42, Wensui Liu wrote:
| I am sorry that I did not state my question clearly. 
| 
| What I mean by data manipulation includes sort, merge, aggregate,
| transpose, data export and import, format, date & time handle, and so
| on, which might be not important to statistician.

R excels at all of those, and it comes with five manuals one of which is
dedicated to data input/output. How to manipulate data once you have it
loaded is covered in the intro document and many of the other documents
that are available on the web or in a fine library or bookstore near you.

| I have use SAS and SPSS for a while and really want to use R as an
| alternative computing system. Unless R/S+ can provide strong
| functionality in data manipulation as SAS does, it is hard to compete
| with SAS in business rather than in academic.

You will find a variety of documents discussing exactly that. You could
start with Frank Harrell's website.

Hth,  Dirk  

-- 
Better to have an approximate answer to the right question than a precise 
answer to the wrong question.  --  John Tukey as quoted by John Chambers



From mwgrant2001 at yahoo.com  Sun Mar 13 03:53:02 2005
From: mwgrant2001 at yahoo.com (Michael Grant)
Date: Sat, 12 Mar 2005 18:53:02 -0800 (PST)
Subject: [R] any book and tutorial about how to manipulate data with R/S+
In-Reply-To: 6667
Message-ID: <20050313025302.87667.qmail@web52010.mail.yahoo.com>

Wensui,

Here is an answer from a different perspective.
Reading between the lines, you may be involved in
'remedial' data preparation at times. Depending on
exactly what kind of tasks you are talking about you
MAY be well advised to work in a database--that is why
they exist. It just depends on what you have to do. 

I work with environmental data. And I work with some
really junky data at times. I have to spend lots of
effort grooming and combining data originally
collected for reasons other than the one at hand, from
disparate idiosyncratic sources, having information in
both similar and very dissimilar formats, data of
varying completeness, etc. I have to process data
qualifiers, strip numbers out of strings, put them
in--on and on. And of course it is different from
record to record. This is just the nature of the
beast. 

Another element is doing these same tasks over. One
sometimes does not get the data in one shot. I
remediate data, construct datasets, and process it.
Then I get additional and/or corrected data and have
do it again. This kind of thing is probably easier to
track in DBs or spreadsheets. 

I would never try doing these tasks in R (or SPSS/SAS
for that matter.) EXCEL works up to a point but I also
go into MSAcess exploiting its visual query building
and VB capabilities. As much as I dislike MS(I've been
bitten too many times)I have to admit that the ability
to easily construct (visual) queries, browse the
results, etc., has been very useful. This kind
remedial preparation is sometimes easy and sometimes
brutal.

A point here is that as the complexity of your data
preparation increases it may be more efficient to do
it in applications more appropriate to the task. Where
the breakpoint is, is of a function of your own
capabilities/inclinations in R (SPSS, SAS), EXCEL,
Access or whatever. The one thing I know is that the
problems of data prep., in my world al least, has
always been there and will likely remain. I accept it
and move on.

The approach(es) you develop should be influenced by
the frequency of such efforts and the size of the
datasets typically involved. BTW, one truism is that
project managers do not seem capable of understanding
that just because something is in a computer does not
mean it is  ready to go to give them what they want
:O(. Gee this stuff takes work...as you seem well
aware. 

I steel myself for the task by reminding myself that
writing and running the R programming is an enjoyable
reward for my toil. R is fun. SPSS never was. I have
not worked much with SAS because--and this a
consideration--I can't afford a seat at home. 

BTW if some DB appears appropriate, then learn some
SQL --even the if you use Access. There is always
RODBC out there and it may be useful down the road.

If you don't want to do all this then get an intern,
graduate student, postdoc, or new career ;O).

Best regards,
Michael Grant
Graduate School of Applied Brute Force in the Sciences



From michael_shen at hotmail.com  Sun Mar 13 04:10:42 2005
From: michael_shen at hotmail.com (Michael S)
Date: Sun, 13 Mar 2005 03:10:42 +0000
Subject: [R] How to get object value in R Active memory
Message-ID: <BAY1-F14CE8150950C85DD33B6A6E7550@phx.gbl>

Dear all R-helpers,
I understand  all the actions of operation in R objects stored in the active 
memory of the computer.Could I do some opreation in active memory,what does 
the structure of active memory looks like?
for exmple : in R : a<- 2 ; capture.output(a) ; I can get the output and 
change to string,this function is written by R ,could I wrtie it in C and 
how?

Thanks in advance
Michael



From michael_shen at hotmail.com  Sun Mar 13 04:12:24 2005
From: michael_shen at hotmail.com (Michael S)
Date: Sun, 13 Mar 2005 03:12:24 +0000
Subject: [R] How to get object value in R Active memory
Message-ID: <BAY1-F18DF3F19D1166AFD8E19DE7550@phx.gbl>

Dear all R-helpers,
I understand  all the actions of operation in R objects stored in the active 
memory of the computer.Could I do some opreation in active memory,what does 
the structure of active memory looks like?
for example : in R : a<- 2 ; capture.output(a) ; I can get the output and 
change to string,this function is written by R ,could I wrtie it in C and 
how?

Thanks in advance
Michael



From ripley at stats.ox.ac.uk  Sun Mar 13 09:01:47 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 13 Mar 2005 08:01:47 +0000 (GMT)
Subject: [R] generalized negative binomial
In-Reply-To: <Pine.LNX.4.58.0503121818210.15155@ls02.fas.harvard.edu>
References: <Pine.LNX.4.58.0503121818210.15155@ls02.fas.harvard.edu>
Message-ID: <Pine.LNX.4.61.0503130750180.14582@gannet.stats>

On Sat, 12 Mar 2005, Erin M Simpson wrote:

> I am looking for code that allows for a more flexible negative binomial
> model (similar to Stata's "gnbreg").

Your subject line is not clear to me: Stata appears to fit a negative 
binomial model, the point being that it is not a glm as fitted by glm.nb. 
(So when Stata says

      `gnbreg is a generalized negative binomial regression'

it is `regression' not `negative binomial' that is being generalized.)

> In particular, I am looking to be able to model the ancillary
> shape parameter in terms of a series of covariates.   So if,
>
> 	y[i] ~ poisson(mu[i])
>
> 	mu[i] = exp(x[i]beta + u[i])
>
> 	exp(u[i]) ~ Gamma(1/alpha, alpha)
>
> I am looking to parameterize alpha as exp(z[i]gamma).
>
> If you are familiar with a package that allows for this, I'd appreciate
> the heads up.  Similar information that allows for first differences with
> such a model is also appreciated.

Just write down the log-likelihood (I am not sure what the free parameters 
here are: are beta and gamma vectors?), and call optim() to maximize it.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From xpsun at ict.ac.cn  Sun Mar 13 13:23:28 2005
From: xpsun at ict.ac.cn (XP Sun)
Date: Sun, 13 Mar 2005 20:23:28 +0800
Subject: [R] how to draw the data set processed by hclust?
Message-ID: <200503131223.j2DCNX96001247@hypatia.math.ethz.ch>

hi, all

   i hava a dataset formated as follow:

	x1 y1 z1
	x2 y2 z2
	x3 y3 z3
	...	

	how to cluster it with hclust?
	and the draw the data with color of cluster?

	thank you in advance!

best!
xpsun



From krcabrer at epm.net.co  Sun Mar 13 14:01:59 2005
From: krcabrer at epm.net.co (Kenneth Cabrera)
Date: Sun, 13 Mar 2005 08:01:59 -0500
Subject: [R] Big databases
In-Reply-To: <42666EF1.7040901@ips.unibe.ch>
References: <200501201136.j0KBH1wd031095@hypatia.math.ethz.ch>
	<42666EF1.7040901@ips.unibe.ch>
Message-ID: <423439C7.7010101@epm.net.co>

Hi R users:

I am using R 2.01. over a LINUX(Scientific Linux CERN)
 platform and I got the following problem:
It takes too much time (more than 6 hours, because I
stop the process) to read a
270MB database. I am using read.table() function.

Is there any workaround to read faster a big data base?

Thank you for your help.

Kenneth


From br44114 at yahoo.com  Sun Mar 13 14:58:40 2005
From: br44114 at yahoo.com (bogdan romocea)
Date: Sun, 13 Mar 2005 05:58:40 -0800 (PST)
Subject: [R] XML to data frame or list 
In-Reply-To: 6667
Message-ID: <20050313135840.15889.qmail@web50102.mail.yahoo.com>

I managed to parse more complex XML files as well. The trick was to
manually determine the position of the child nodes of interest, after
which they can be parsed in a loop. For example:

require(XML)
doc <- xmlTreeParse("file.xml",getDTD=T,addAttributeNamespaces=T)
r <- xmlRoot(doc)

#find the nodes of interest
r[[i]][[j]]....

#then read them
xmldata <- list(NULL)
for (i in 1:xmlSize(r[[2]][[1]])) {
  xmldata[[i]] <- as.data.frame(xmlSApply(r[[2]][[1]][[i]],xmlValue))
  }


--- Barry Rowlingson <B.Rowlingson at lancaster.ac.uk> wrote:
> Gabor Grothendieck wrote:
> 
> >
> > You could check out the ctv package that was recently announced.
> > It uses XML so its source would provide an example.
> >
> > If its a one-time operation, Excel reads XML and you could then
> > use one of the many Excel to R possibilities.
> 
>   For an xml file like this:
> 
> <?xml version="1.0"?>
> <variables>
> <a>100</a>
> <b>23</b>
> <z>666</z>
> </variables>
> 
> its a one-liner with the XML package (library(XML)):
> 
> xmlReadSimple <-
> function(xmlFile){
>    as.list(xmlSApply(xmlRoot(xmlTreeParse(xmlFile)),xmlValue))
> }
> 
> add an lapply(...,as.numeric) for conversion to numbers.
> 
>   sweet.
> 
> Baz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>   
> 
> __________________________________________________


From ligges at statistik.uni-dortmund.de  Sun Mar 13 15:15:45 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 13 Mar 2005 15:15:45 +0100
Subject: [R] Multiple histograms in one chart
In-Reply-To: <20050312201258.93063.qmail@web25801.mail.ukl.yahoo.com>
References: <20050312201258.93063.qmail@web25801.mail.ukl.yahoo.com>
Message-ID: <42344B11.9020902@statistik.uni-dortmund.de>

Werner Wernersen wrote:
> Hi!
> 
> I've searched quite a while and this is probably a
> very easy question: How do I 
> prevent a new hist() histogram from clearing the chart
> window before drawing?
> 
> I would like to have several histograms simply drawn
> on each other in one chart...

See either ?par
   par(new=TRUE)
or try argument add = TRUE in hist, depending on what you want to do 
exactly.

Uwe Ligges


> Thanks for your help!
>    Werner
> 
> In use: win2ksp4 & R 2.0.1
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From chabotd at globetrotter.net  Sun Mar 13 15:51:28 2005
From: chabotd at globetrotter.net (Denis Chabot)
Date: Sun, 13 Mar 2005 09:51:28 -0500
Subject: Objet: [R] New user of R on Mac OS X - Please help
Message-ID: <2f574bff57f8ec0f3efbec9ba3003431@globetrotter.net>

> De: Depiereux Constant <constant.depiereux at aqte.be>
> Date: 12 mars 2005 09:44:08 GMT-05:00
> ?: r-help at stat.math.ethz.ch
> Objet: [R] New user of R on Mac OS X - Please help
>
>
> Brand new Mac OS X user, I am transfering my R stuffs from my windows 
> machine.
>
> When porting some of my functions, I got messages such as  :
>
> 2005-03-12 15:37:52.456 R[673] *** NSTimer discarding exception 
> 'NSRangeException' (reason '*** NSRunStorage, 
> _NSBlockNumberForIndex(): index (3607) beyond array bounds (2000)') 
> that raised during firing of timer with target 3ba850 and selector 
> 'runRELP:'
>
> Does any body of you have any idea where I should be starting looking 
> for a solution for ditto?
>
> Thnaks in advance four your help.
>
>
> Constant Depi?reux
>

If this is too specific to the Mac platform to receive help here, you 
might also try posting your message on
r-sig-mac at stat.math.ethz.ch

Denis



From andy_liaw at merck.com  Sun Mar 13 16:26:23 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sun, 13 Mar 2005 10:26:23 -0500
Subject: [R] Big databases
Message-ID: <3A822319EB35174CA3714066D590DCD50994E83A@usrymx25.merck.com>

1. Read the R Data Import/Export manual.

2. Check the R-help archive, as this question has been asked and answered
many times.

Andy

> From: Kenneth Cabrera
> 
> Hi R users:
> 
> I am using R 2.01. over a LINUX(Scientific Linux CERN)
>  platform and I got the following problem:
> It takes too much time (more than 6 hours, because I
> stop the process) to read a
> 270MB database. I am using read.table() function.
> 
> Is there any workaround to read faster a big data base?
> 
> Thank you for your help.
> 
> Kenneth
> 
>



From spencer.graves at pdf.com  Sun Mar 13 17:40:08 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 13 Mar 2005 08:40:08 -0800
Subject: [R] generalized negative binomial
In-Reply-To: <Pine.LNX.4.61.0503130750180.14582@gannet.stats>
References: <Pine.LNX.4.58.0503121818210.15155@ls02.fas.harvard.edu>
	<Pine.LNX.4.61.0503130750180.14582@gannet.stats>
Message-ID: <42346CE8.2060806@pdf.com>

      I whole-heartedly endorse Prof. Ripley's suggestion to write down 
the log(likelihood) and use optim;  I've done that many times with 
seemingly good results.  For confidence intervals, the best procedure is 
to use 2*log(likelihood ratio) being approximately chi-square.  If you 
are estimating two parameters, you can easily compute log(likelihood) 
for a grid of points about the maximum likelihood estimates (MLEs) and 
use "contour" to draw lines at the difference confidence levels.  You 
can also use the argument "hessian = TRUE" to get the observed 
information matrix and therefore also the covariance matrix of the 
standard asymptotic normal approximation to the distribution of the 
MLEs;  I've done both. 

      hope this helps.  spencer graves

Prof Brian Ripley wrote:

> On Sat, 12 Mar 2005, Erin M Simpson wrote:
>
>> I am looking for code that allows for a more flexible negative binomial
>> model (similar to Stata's "gnbreg").
>
>
> Your subject line is not clear to me: Stata appears to fit a negative 
> binomial model, the point being that it is not a glm as fitted by 
> glm.nb. (So when Stata says
>
>      `gnbreg is a generalized negative binomial regression'
>
> it is `regression' not `negative binomial' that is being generalized.)
>
>> In particular, I am looking to be able to model the ancillary
>> shape parameter in terms of a series of covariates.   So if,
>>
>>     y[i] ~ poisson(mu[i])
>>
>>     mu[i] = exp(x[i]beta + u[i])
>>
>>     exp(u[i]) ~ Gamma(1/alpha, alpha)
>>
>> I am looking to parameterize alpha as exp(z[i]gamma).
>>
>> If you are familiar with a package that allows for this, I'd appreciate
>> the heads up.  Similar information that allows for first differences 
>> with
>> such a model is also appreciated.
>
>
> Just write down the log-likelihood (I am not sure what the free 
> parameters here are: are beta and gamma vectors?), and call optim() to 
> maximize it.
>



From ckjmaner at carolina.rr.com  Sun Mar 13 18:11:09 2005
From: ckjmaner at carolina.rr.com (Charles and Kimberly Maner)
Date: Sun, 13 Mar 2005 12:11:09 -0500
Subject: [R] RODBC, IODBC and Mac OS X
In-Reply-To: <200503131108.j2DB6jFv020881@hypatia.math.ethz.ch>
Message-ID: <200503131710.j2DHA50X027398@ms-smtp-02-eri0.southeast.rr.com>


Hi.  Another, slightly more updated, link to the same info is:

http://bioconductor.org/, under the Developmental Packages under Software,
contains Rdbi version 1.1.1 and RdbiPgSQL version 1.1.3.  I am running them
under MacOSX and they work beautifully.  I am using it to pull data on
PostgreSQL servers running on the same machine as well as a remote FreeBSD
PostgreSQL server.  I'm getting quite respectable performance to boot.


Good luck,
Charles

----- Original Message ----- 
Message: 23
Date: Sat, 12 Mar 2005 18:07:55 -0500
From: "Sean Davis" <sdavis2 at mail.nih.gov>
Subject: Re: [R] RODBC, IODBC and Mac OS X
To: <r-help at stat.math.ethz.ch>,	"Depiereux Constant"
	<constant.depiereux at aqte.be>
Message-ID: <000e01c52758$538b71a0$1f6df345 at WATSON>
Content-Type: text/plain; format=flowed; charset="iso-8859-1";
	reply-type=response

Have you looked at these two packages that, together, provide Postgres 
access and do not require ODBC?  I have found them quite useful and I use 
them on Panther:

http://www.bioconductor.org/repository/release1.5/package/html/Rdbi.html
http://www.bioconductor.org/repository/release1.5/package/html/RdbiPgSQL.htm
l

Sean

----- Original Message ----- 
From: "Depiereux Constant" <constant.depiereux at aqte.be>
To: <r-help at stat.math.ethz.ch>
Sent: Saturday, March 12, 2005 5:21 PM
Subject: [R] RODBC, IODBC and Mac OS X


> Dear All,
>
> As some of you in the archive, i am experiencing problems in using RODBC 
> with IODBC on Mac OS X Panther.
>
> I am currrently facing two problems.
>
> The first one is apparently linked with IODBC (according to returned R 
> error message) although testing the database access from IODBC manager 
> seems to work fine.
>
> The second is by far more radical, R purely and simply reports an error , 
> blocks and I finally got a Mac OS X message.
>
> I browsed the archive without really finding a solution. Before spending 
> lengthy hours on an operating system that I am currently discovering, I 
> have therefore a simple question :
>
> DOES ANY BODY HAVE A COOKBOOK EXPLAINING HOW TO ACCESS - THRU ODBC - A 
> POSTGRESQL DATABASE USING R ON MAC OS X PANTHER ?
>
> Thanks in advance for your help.
>
>
>
>
>
> Constant Depihreux
> Managing Director
> Applied Quality Technologies Europe sprl
> Rue des Diportis 123, B4800   Verviers
> Tel : + 32 87 29 21 75
> Fax : +32 87 29 21 71
> Mobile : +32 475 555 818
> e-Mail : constant.depiereux at aqte.be
> Web presence : http://www.aqte.be
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From andy_liaw at merck.com  Sun Mar 13 20:11:10 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sun, 13 Mar 2005 14:11:10 -0500
Subject: [R] any book and tutorial about how to manipulate data with R /S+
Message-ID: <3A822319EB35174CA3714066D590DCD50994E83B@usrymx25.merck.com>

> From: Wensui Liu
> 
> I am sorry that I did not state my question clearly. 
> 
> What I mean by data manipulation includes sort, merge, aggregate,
> transpose,

R has functions for doing those: sort(), merge(), aggregate(), and t(),
respectively.

> data export and import, format, date & time handle, and so
> on,

As others have pointed out, R comes with a manual on data import/export.
There are articles in the R News that discuss date/time.  Not sure what you
mean by `format'.
 
>  which might be not important to statistician.

I beg to differ: Not too many statisticians (that I know of anyway) have the
luxury of having data formatted  and served on a silver platter for
analysis.

> I have use SAS and SPSS for a while and really want to use R as an
> alternative computing system. Unless R/S+ can provide strong
> functionality in data manipulation as SAS does, it is hard to compete
> with SAS in business rather than in academic.

Let's see:  I've been working at a pharmaceutical company for over five
years now, and I can count the number of times I've used SAS during that
period on one hand (and can't recall when was the last time).  I do data
manipulation all the time (mostly with R).  Just last week I wrote a
three-line function in R to read and parse a data file that's not in
rectangular table format (so read.table and friends can't be used), while a
colleague of mine tried to figure out how to do the same with Perl.

All the tasks you specified can be done in any number of packages/languages,
some easier than others.  I'd say R is one of the easiest, but that does
require that you gain some familiarity with it.  If you have specific
questions, try search in the R-help archive, or if you can't find answer
there, post the question here.  

Andy
 
> 
> On Sat, 12 Mar 2005 15:34:06 +0100, Thomas Sch?nhoff 
> <tom_hoary at web.de> wrote:
> > Hallo,
> > 
> > Am Samstag, 12. M?rz 2005 15:08 schrieb Wensui Liu:
> > > In real world, data manipulation might take even longer time and
> > > more effort than statistical analysis and modeling.
> > >
> > > Does anyone know a good book and tutorial about data manupulation?
> > > Thank you so much.
> > 
> > Well, it would be much easier to meet your demands if you could give
> > us an idea what you exactly looking for.
> > Anyway, there are some recommendations in R-Manual regarding
> > introduxtory materials on doing statistics in R. If I remember
> > correctly there are also some advices on r-cran.org in the generell
> > FAQ.
> > If you're looking for some introductory stuff doing data 
> manipulation
> > in R the book of Peter Dalgaard, Introductory Statistics with R
> > should be taken into consideration.
> > Not long time ago there was a similar question to this list, giving
> > the whole range of available books on statistics in S/R . 
> Have a look
> > at http://maths.newcastle.edu.au/~rking/R/, you'll will be
> > overwhelmed.
> > Last but not least, if you look at r-cran website you'll find in
> > contributed section some case-oriented tutorials, i.e. data 
> mining or
> > similar stuff!
> > 
> > regards
> > 
> > Thomas
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> > 
> 
> 
> -- 
> WenSui Liu, MS MA
> Senior Decision Support Analyst
> Division of Health Policy and Clinical Effectiveness
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From murdoch at stats.uwo.ca  Sun Mar 13 21:58:50 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 13 Mar 2005 20:58:50 +0000
Subject: [R] Simplex(boot) returning invalid answer
In-Reply-To: <a05f3b8e3f799ec5a4ca7cc0feb025a6@otsys.com>
References: <a05f3b8e3f799ec5a4ca7cc0feb025a6@otsys.com>
Message-ID: <5q9931tbmvq6b2lq1c89vc0ms7l7ha5t12@4ax.com>

On Fri, 11 Mar 2005 09:09:15 -0800, Andrew Stoneman
<stoneman at otsys.com> wrote :

>In trying to use simplex() from the boot package, I have run into a 
>situation that doesn't seem like it should be possible.  It is claiming 
>that it has solved the LP, but returns a vector of all zeros, which 
>does not satisfy the constraints I passed in.  A small example:
>
> > ubMatrix <- matrix(c(1,1,-1,0,-1,-1), 3, 2)
> > ubVector <- c(2,1,-1)
> > objective <- c(0,1)
>
> > ubMatrix
>      [,1] [,2]
>[1,]    1    0
>[2,]    1   -1
>[3,]   -1   -1
> > ubVector
>[1]  2  1 -1
>
> > smplx <- simplex( a = objective, A1 = ubMatrix, b1 = ubVector)

You missed this in the help page:

>      b1: A vector of length 'm1' giving the right hand side of the
>          "<=" constraints. This argument is required if 'A1' is given
>          and ignored otherwise.  All values in 'b1' must be
>          non-negative. 

The reason for this requirement is that the origin should be a
feasible solution; that's where the algorithm starts.

It's been a while since I looked at this stuff so I forget if there's
an easier transformation, but one way to solve the problem you're
interested in (-x-y <= -1) is to multiply through by -1 giving (x + y
>= 1),
i.e.

ubMatrix <- matrix(c(1,1,-1,0), 2, 2)
ubVector <- c(2,1)

lbMatrix <- matrix(c(1,1), 1, 2)
lbVector <- 1

objective <- c(0,1)

simplex(a = objective, A1 = ubMatrix, b1 = ubVector, A2 = lbMatrix, b2
= lbVector)

which gives the answer you were looking for.

I suppose you might suggest to the maintainer to add

stopifnot(all(c(b1, b2, b3) >= 0))

to the beginning of the function rather than giving a bad answer for
bad input.

Duncan Murdoch



From twiens at interbaun.com  Sun Mar 13 23:28:54 2005
From: twiens at interbaun.com (Trevor Wiens)
Date: Sun, 13 Mar 2005 15:28:54 -0700
Subject: [R] cross-validation
Message-ID: <20050313152854.3b8045e4.twiens@interbaun.com>

I've been looking at the base and Design libraries and it is unclear to me the best way to approach doing cross-validation. I'm interested in using temporal (I have five years of data), spatial (I've divided my data set up into 5 blocks that make sense and have a block variable attached to my data) and I was also thinking of doing a random cross-validation to look at general model stability. For the third options I can use cross-validation or bootstrapping.

If someone can type out a code example, that would be very helpful to me. 

Thanks in advance.

T
-- 
Trevor Wiens 
twiens at interbaun.com

The significant problems that we face cannot be solved at the same 
level of thinking we were at when we created them. 
(Albert Einstein)



From liuwensui at gmail.com  Mon Mar 14 00:25:34 2005
From: liuwensui at gmail.com (Wensui Liu)
Date: Sun, 13 Mar 2005 18:25:34 -0500
Subject: [R] iterations of nnet training
Message-ID: <1115a2b00503131525dbc2d1c@mail.gmail.com>

Does anyone know how to suppress the iterations of nnet training with
nnet library?

Thank you so much!

-- 
WenSui Liu, MS MA
Senior Decision Support Analyst
Division of Health Policy and Clinical Effectiveness
Cincinnati Children Hospital Medical Center



From andy_liaw at merck.com  Mon Mar 14 00:33:37 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sun, 13 Mar 2005 18:33:37 -0500
Subject: [R] iterations of nnet training
Message-ID: <3A822319EB35174CA3714066D590DCD50994E83C@usrymx25.merck.com>

> From: Wensui Liu
> 
> Does anyone know how to suppress the iterations of nnet training with
> nnet library?

1. That's _package_, not _library_.

2. See the `trace' option in ?nnet.

Andy
 
> Thank you so much!
> 
> -- 
> WenSui Liu, MS MA
> Senior Decision Support Analyst
> Division of Health Policy and Clinical Effectiveness
> Cincinnati Children Hospital Medical Center
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From mcclatchie.sam at saugov.sa.gov.au  Mon Mar 14 01:13:47 2005
From: mcclatchie.sam at saugov.sa.gov.au (McClatchie, Sam (PIRSA-SARDI))
Date: Mon, 14 Mar 2005 10:43:47 +1030
Subject: [R] initialising trellis device {lattice}/ postscript 
Message-ID: <032A8573186A2B4EBBAEFA5784D0523506E10D08@sagemsg0007.sagemsmrd01.sa.gov.au>

Background:
OS: Linux Mandrake 10.1
release: R 2.0.0
editor: GNU Emacs 21.3.2
front-end: ESS 5.2.3
---------------------------------

Colleagues

I am using:
trellis.device(postscript, file="../figures/name.ps")
.....code to generate the trellis display here ....
graphics.off()

to create a postscript from a working xyplot display.

The problem is that the postscript file appears to be blank

I haven't done anything fancy to modify the defaults. Does anyone have a
suggestion as to what might be wrong?

Thanks

Sam
----
Sam McClatchie,
Biological oceanography 
South Australian Aquatic Sciences Centre
PO Box 120, Henley Beach 5022
Adelaide, South Australia
email <mcclatchie.sam at saugov.sa.gov.au>
Telephone: (61-8) 8207 5448
FAX: (61-8) 8200 2481
Research home page <http://www.members.iinet.net.au/~s.mcclatchie/>
  
                   /\
      ...>><xX(?> 
                //// \\\\
                   <?)Xx><<
              /////  \\\\\\
                        ><(((?> 
  >><(((?>   ...>><xX(?>O<?)Xx><<



From mcclatchie.sam at saugov.sa.gov.au  Mon Mar 14 01:28:08 2005
From: mcclatchie.sam at saugov.sa.gov.au (McClatchie, Sam (PIRSA-SARDI))
Date: Mon, 14 Mar 2005 10:58:08 +1030
Subject: fixed/  [R] initialising trellis device {lattice}/ postscript
Message-ID: <032A8573186A2B4EBBAEFA5784D0523506E10D09@sagemsg0007.sagemsmrd01.sa.gov.au>

Thanks Andy

out<- xyplot(....)
print(out)

did the trick nicely.

Sam

----
Sam McClatchie,
Biological oceanography 
South Australian Aquatic Sciences Centre
PO Box 120, Henley Beach 5022
Adelaide, South Australia
email <mcclatchie.sam at saugov.sa.gov.au>
Telephone: (61-8) 8207 5448
FAX: (61-8) 8200 2481
Research home page <http://www.members.iinet.net.au/~s.mcclatchie/>
  
                   /\
      ...>><xX(?> 
                //// \\\\
                   <?)Xx><<
              /////  \\\\\\
                        ><(((?> 
  >><(((?>   ...>><xX(?>O<?)Xx><<


>-----Original Message-----
>From: Liaw, Andy [mailto:andy_liaw at merck.com]
>Sent: Monday, 14 March 2005 10:52 AM
>To: 'McClatchie, Sam (PIRSA-SARDI)'
>Subject: RE: [R] initialising trellis device {lattice}/ postscript
>
>
>Could it be that you need to wrap the xyplot() call in print()?
>
>Andy
>
>> From: McClatchie, Sam (PIRSA-SARDI)
>> 
>> Background:
>> OS: Linux Mandrake 10.1
>> release: R 2.0.0
>> editor: GNU Emacs 21.3.2
>> front-end: ESS 5.2.3
>> ---------------------------------
>> 
>> Colleagues
>> 
>> I am using:
>> trellis.device(postscript, file="../figures/name.ps")
>> .....code to generate the trellis display here ....
>> graphics.off()
>> 
>> to create a postscript from a working xyplot display.
>> 
>> The problem is that the postscript file appears to be blank
>> 
>> I haven't done anything fancy to modify the defaults. Does 
>> anyone have a
>> suggestion as to what might be wrong?
>> 
>> Thanks
>> 
>> Sam
>> ----
>> Sam McClatchie,
>> Biological oceanography 
>> South Australian Aquatic Sciences Centre
>> PO Box 120, Henley Beach 5022
>> Adelaide, South Australia
>> email <mcclatchie.sam at saugov.sa.gov.au>
>> Telephone: (61-8) 8207 5448
>> FAX: (61-8) 8200 2481
>> Research home page <http://www.members.iinet.net.au/~s.mcclatchie/>
>>   
>>                    /\
>>       ...>><xX(?> 
>>                 //// \\\\
>>                    <?)Xx><<
>>               /////  \\\\\\
>>                         ><(((?> 
>>   >><(((?>   ...>><xX(?>O<?)Xx><<
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>> 
>> 
>> 
>
>
>
>---------------------------------------------------------------
>---------------
>Notice:  This e-mail message, together with any attachments, 
>contains information of Merck & Co., Inc. (One Merck Drive, 
>Whitehouse Station, New Jersey, USA 08889), and/or its 
>affiliates (which may be known outside the United States as 
>Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as 
>Banyu) that may be confidential, proprietary copyrighted 
>and/or legally privileged. It is intended solely for the use 
>of the individual or entity named on this message.  If you are 
>not the intended recipient, and have received this message in 
>error, please notify us immediately by reply e-mail and then 
>delete it from your system.
>---------------------------------------------------------------
>---------------
>



From ggrothendieck at myway.com  Mon Mar 14 01:42:17 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 14 Mar 2005 00:42:17 +0000 (UTC)
Subject: [R] any book and tutorial about how to manipulate data with R/S+
References: <1115a2b0050312060831892ba3@mail.gmail.com>
	<200503121534.06453.tom_hoary@web.de>
	<1115a2b00503121242302acec6@mail.gmail.com>
Message-ID: <loom.20050314T013155-569@post.gmane.org>

Wensui Liu <liuwensui <at> gmail.com> writes:

: transpose, data export and import, format, date & time handle, and so

Regarding just the date and time classes part of your question, an
article in R News 4/1 discusses that.



From ramasamy at cancer.org.uk  Mon Mar 14 02:42:32 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 14 Mar 2005 01:42:32 +0000
Subject: [R] Multiple histograms in one chart
In-Reply-To: <42344B11.9020902@statistik.uni-dortmund.de>
References: <20050312201258.93063.qmail@web25801.mail.ukl.yahoo.com>
	<42344B11.9020902@statistik.uni-dortmund.de>
Message-ID: <1110764552.354.7.camel@dhcp-63.ccc.ox.ac.uk>

If you use par(new=TRUE), you are overlaying one graph on top of the
other. In which case, make sure your xlim and ylim are correctly set.

Another way is to split the plotting window. For example

   par(mfrow=c(2,3))
   for(i in 1:6) hist( rnorm(100), main=paste("Histogram", i))

See help("par") for more info.

Regards, Adai


On Sun, 2005-03-13 at 15:15 +0100, Uwe Ligges wrote:
> Werner Wernersen wrote:
> > Hi!
> > 
> > I've searched quite a while and this is probably a
> > very easy question: How do I 
> > prevent a new hist() histogram from clearing the chart
> > window before drawing?
> > 
> > I would like to have several histograms simply drawn
> > on each other in one chart...
> 
> See either ?par
>    par(new=TRUE)
> or try argument add = TRUE in hist, depending on what you want to do 
> exactly.
> 
> Uwe Ligges
> 
> 
> > Thanks for your help!
> >    Werner
> > 
> > In use: win2ksp4 & R 2.0.1
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From twiens at interbaun.com  Mon Mar 14 04:59:04 2005
From: twiens at interbaun.com (Trevor Wiens)
Date: Sun, 13 Mar 2005 20:59:04 -0700
Subject: [R] cross-validation
In-Reply-To: <20050313152854.3b8045e4.twiens@interbaun.com>
References: <20050313152854.3b8045e4.twiens@interbaun.com>
Message-ID: <20050313205904.41c25f59.twiens@interbaun.com>

On Sun, 13 Mar 2005 15:28:54 -0700
Trevor Wiens <twiens at interbaun.com> wrote:

> I've been looking at the stats and Design libraries and it is unclear to me the best way to approach doing cross-validation. I'm interested in using temporal (I have five years of data), spatial (I've divided my data set up into 5 blocks that make sense and have a block variable attached to my data) and I was also thinking of doing a random cross-validation to look at general model stability. For the third option I think either cross-validation or bootstrapping would be appropriate
> 
> If someone can type out a really simple code example ( or point me to one), that would be very helpful. 
> 
I realized I should have mentioned this is for logistic regression using either glm or the Design lrm models.

Thanks

T
-- 
Trevor Wiens 
twiens at interbaun.com

The significant problems that we face cannot be solved at the same 
level of thinking we were at when we created them. 
(Albert Einstein)



From ligges at statistik.uni-dortmund.de  Mon Mar 14 08:27:30 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 14 Mar 2005 08:27:30 +0100
Subject: [R] initialising trellis device {lattice}/ postscript
In-Reply-To: <032A8573186A2B4EBBAEFA5784D0523506E10D08@sagemsg0007.sagemsmrd01.sa.gov.au>
References: <032A8573186A2B4EBBAEFA5784D0523506E10D08@sagemsg0007.sagemsmrd01.sa.gov.au>
Message-ID: <42353CE2.9040603@statistik.uni-dortmund.de>

McClatchie, Sam (PIRSA-SARDI) wrote:
> Background:
> OS: Linux Mandrake 10.1
> release: R 2.0.0
> editor: GNU Emacs 21.3.2
> front-end: ESS 5.2.3
> ---------------------------------
> 
> Colleagues
> 
> I am using:
> trellis.device(postscript, file="../figures/name.ps")
> .....code to generate the trellis display here ....
> graphics.off()
> 
> to create a postscript from a working xyplot display.
> 
> The problem is that the postscript file appears to be blank
> 
> I haven't done anything fancy to modify the defaults. Does anyone have a
> suggestion as to what might be wrong?


Works for me with a recent version of R and lattice given ".....code to 
generate the trellis display here ...." is correct and gets printed. 
Please specify a reproducible example as the posting guide asks you to do.

Uwe Ligges



> Thanks
> 
> Sam
> ----
> Sam McClatchie,
> Biological oceanography 
> South Australian Aquatic Sciences Centre
> PO Box 120, Henley Beach 5022
> Adelaide, South Australia
> email <mcclatchie.sam at saugov.sa.gov.au>
> Telephone: (61-8) 8207 5448
> FAX: (61-8) 8200 2481
> Research home page <http://www.members.iinet.net.au/~s.mcclatchie/>
>   
>                    /\
>       ...>><xX(?> 
>                 //// \\\\
>                    <?)Xx><<
>               /////  \\\\\\
>                         ><(((?> 
>   >><(((?>   ...>><xX(?>O<?)Xx><<
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From tastard at cict.fr  Mon Mar 14 08:29:28 2005
From: tastard at cict.fr (tastard@cict.fr)
Date: Mon, 14 Mar 2005 02:29:28 -0500
Subject: [R] polymars
Message-ID: <141370-22005311472928364@M2W057.mail2web.com>

Can you help me interpret the output I get with "polymars"?
I'd like to find a regression model to predict 2 dependent variables (then
called Y1 and Y2) with 2 independent variables (then called X1 and X2).

Here is the output:
polymars(responses = data[, 13:14], predictors = data[, 2:3])

Model fitting

   0/1 		size     	RSS 1     	RSS 2       	 GCV
1    1    	1	0.2486744 	0.6520499 	0.01756785
2    1    	2 	0.2316042 	0.3820036 	0.01391882
3    1    	3 	0.2312835 	0.3819480 	0.01637875
4    1    	4 	0.2299605 	0.3766946 	0.01935784
5    1   		5 	0.2243804 	0.3766148 	0.02331277
6    1    	6	0.2243499 	0.3764709 	0.02893749
7    0    	5	0.2243804 	0.3766148 	0.02331277
8    0    	4 	0.2299605 	0.3766946 	0.01935784
9    0    	3	0.2312835 	0.3819480 	0.01637875
10   0    	2 	0.2316042 	0.3820036 	0.01391882
11   0   	1	0.2486744 	0.6520499 	0.01756785


Model produced

  pred1 knot1 pred2 knot2     Coefs 1     Coefs 2       SE 1       SE 2
1     0    NA     0    NA  0.40139070  0.14049628 0.02195431 0.02819553
2     2    NA     0    NA -0.02146696 -0.08538267 0.01047337 0.01345076

RESPONSES : 2 

Rsquared : 0.069 0.414



If I have well understood, polymars tries to build several models for each
dependent variable (with one function if it is homogeneous or more ones if
it is not homogeneous) and selects the best one. I suppose the model is the
best one when the GCV is smallest. So here I thought I should have had a
model with 2 functions for each dependent variable (size 2). 

Why do I get only one result (1 function for each dependent variable)? 
How can I get a model with different functions over different ranges of the
independent variables? Do you think it would be a better model?

Are these the good equations?
Y1 = 0,40139 - 0,02147 X2
Y2 = 0,1405 - 0,08538 X2

Does polymars take the interaction between Y1 and Y2 into account ?

Thanks



--------------------------------------------------------------------
mail2web - Check your email from the web at
http://mail2web.com/ .



From Luisr at frs.fo  Mon Mar 14 11:37:20 2005
From: Luisr at frs.fo (Luis Ridao Cruz)
Date: Mon, 14 Mar 2005 10:37:20 +0000
Subject: [R] 'pch' plot symbol with more than one character
Message-ID: <s2356965.041@ffdata.setur.fo>

R-help,

Argument 'pch' in 'plot' can only represent a single character.
Is it possible to represent, let's say, two instead?

Thanks in advance.

I'm running on Windows Xp

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    0.1            
year     2004           
month    11             
day      15             
language R



From Markus.Gesmann at lloyds.com  Mon Mar 14 11:46:29 2005
From: Markus.Gesmann at lloyds.com (Gesmann, Markus)
Date: Mon, 14 Mar 2005 10:46:29 +0000
Subject: [R] 'pch' plot symbol with more than one character
Message-ID: <321C3EEBDB00C24185705B8BF733DADD0503F71F@LNVCNTEXCH01.corp.lloydsnet>


This might do what you want:

> plot.new()
> plot.window(xlim=c(1,10), ylim=c(1,10))
> text(x=1:10, y=1:10, labels="Hallo")

Look at ?text

Regards

Markus


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Luis Ridao Cruz
Sent: 14 March 2005 10:37
To: r-help at stat.math.ethz.ch
Subject: [R] 'pch' plot symbol with more than one character


R-help,

Argument 'pch' in 'plot' can only represent a single character.
Is it possible to represent, let's say, two instead?

Thanks in advance.

I'm running on Windows Xp

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    0.1            
year     2004           
month    11             
day      15             
language R

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html

************LNSCNTMCS01***************************************************
The information in this E-Mail and in any attachments is CON...{{dropped}}



From Allan at STATS.uct.ac.za  Mon Mar 14 11:59:45 2005
From: Allan at STATS.uct.ac.za (Clark Allan)
Date: Mon, 14 Mar 2005 12:59:45 +0200
Subject: [R] r: eviews and r // eigen analysis
Message-ID: <42356EA1.F0C8C19E@STATS.uct.ac.za>

hi all

i have a question that about the eigen analysis found in R and in
eviews.

i used the same data set in the two packages and found different
answers. which is incorrect?

the data is:
aa ( a correlation matrix)

1	0.9801	0.9801	0.9801	0.9801
0.9801	1	0.9801	0.9801	0.9801
0.9801	0.9801	1	0.9801	0.9801
0.9801	0.9801	0.9801	1	0.9801
0.9801	0.9801	0.9801	0.9801	1

now
> svd(aa)
$d
[1] 4.9204 0.0199 0.0199 0.0199 0.0199

$u
           [,1]          [,2]          [,3]          [,4]       [,5]
[1,] -0.4472136  9.283999e-18  1.939587e-17 -2.101554e-15  0.8944272
[2,] -0.4472136  8.089763e-01  7.115435e-17  3.091235e-01 -0.2236068
[3,] -0.4472136  2.178563e-02  8.226578e-18 -8.657513e-01 -0.2236068
[4,] -0.4472136 -4.153810e-01 -7.071068e-01  2.783139e-01 -0.2236068
[5,] -0.4472136 -4.153810e-01  7.071068e-01  2.783139e-01 -0.2236068

$v
           [,1]        [,2]          [,3]       [,4]       [,5]
[1,] -0.4472136  0.00000000  0.000000e+00  0.0000000  0.8944272
[2,] -0.4472136  0.80897632 -4.976488e-17  0.3091235 -0.2236068
[3,] -0.4472136  0.02178563  1.077421e-17 -0.8657513 -0.2236068
[4,] -0.4472136 -0.41538097 -7.071068e-01  0.2783139 -0.2236068
[5,] -0.4472136 -0.41538097  7.071068e-01  0.2783139 -0.2236068

the results from Eviews is:

eigenvectors = (note that Eviews arranges the eigen vectors in ascending
order of the size of the eigen values)

 0.305963	-0.266024	-0.219066	-0.766569	 0.447214
 0.315257	-0.603871	 0.075772	 0.574640	 0.447214
 0.461958	 0.726861	 0.199385	 0.136062	 0.447214
-0.482609	 0.185567	-0.700705	 0.204124	 0.447214
-0.600569	-0.042534	 0.644614	-0.148258	 0.447214

eigen values =

 0.019900
 0.019900
 0.019900
 0.019900
 4.920400

NOTE THAT THE EIGEN VALUES ARE THE SAME BUT THE EIGEN VECTORS ARE NOT!!!

why is this so?

if one sets aa=
 1.000000	 0.500000	 0.250000
 0.500000	 1.000000	 0.350000
 0.250000	 0.350000	 1.000000


then both packages give the same answers.

From dataanalytics at rediffmail.com  Mon Mar 14 12:05:16 2005
From: dataanalytics at rediffmail.com (Arin Basu)
Date: 14 Mar 2005 11:05:16 -0000
Subject: [R] Problem updating mgcv package
Message-ID: <20050314110516.13316.qmail@webmail47.rediffmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050314/ac9a1675/attachment.pl

From andy_liaw at merck.com  Mon Mar 14 12:35:44 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 14 Mar 2005 06:35:44 -0500
Subject: [R] Problem updating mgcv package
Message-ID: <3A822319EB35174CA3714066D590DCD50994E842@usrymx25.merck.com>

> From: Arin Basu
> 
> Hi All:
> 
> I tried to update the package mgcv from my current version 
> 1.1-8 to mgcv version 1.2. Using the command 
> update.packages("mgcv") to update mgcv failed in my computer 
> and the returning message was:
> 
> "Error in old.packages(lib.loc=lib.loc, 
> contriburl=contriburl, method=method, :no installed.packages 
> for (?invalid) lib.loc=mgcv"
> 
> When I typed installed.packages(), I got the following information
> 
> libpath = "/usr/local/lib/R/site-library" for the installed 
> package "mgcv".
> 
> My next error was when I typed 
> update.packages("mgcv",lib.loc="/usr/local/lib/R/site-library").
> It returned the error message, 
> 
> "error in download.file(url = paste(contriburl, "PACKAGES", 
> sep="/"), :unsupported URL scheme"
> 
> What should I do to correctly update this package?


Reading the help file for update.packages() before posting to the list
certainly would help.  You don't specify the name of the package to update.

Andy
 
> I use Debian Linux (MepisLinux), R version 2.0.1
> 
> Would greatly appreciate your advice.
> 
> TIA,
> Arin Basu
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From francoisromain at free.fr  Mon Mar 14 12:44:55 2005
From: francoisromain at free.fr (francoisromain@free.fr)
Date: Mon, 14 Mar 2005 12:44:55 +0100
Subject: [R] AR-ARCH specification and forecast
Message-ID: <1110800695.42357937d2702@imp5-q.free.fr>

Hello list,

I use the packages tseries and fSeries to perform a time series analysis.
I have a model with an AR specification for the mean and an ARCH(1)
specification for the variance.

I just wonder if there is something to compute a forecast with that
specification and also if there is possible to get the AIC for such
AR-ARCH model.

Thanks to all.

Romain.



From ripley at stats.ox.ac.uk  Mon Mar 14 13:03:18 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 14 Mar 2005 12:03:18 +0000 (GMT)
Subject: [R] Problem updating mgcv package
In-Reply-To: <20050314110516.13316.qmail@webmail47.rediffmail.com>
References: <20050314110516.13316.qmail@webmail47.rediffmail.com>
Message-ID: <Pine.LNX.4.61.0503141200330.23798@gannet.stats>

On Mon, 14 Mar 2005, Arin Basu wrote:

> I tried to update the package mgcv from my current version 1.1-8 to mgcv 
> version 1.2. Using the command update.packages("mgcv") to update mgcv 
> failed in my computer and the returning message was:
>
> "Error in old.packages(lib.loc=lib.loc, contriburl=contriburl, 
> method=method, :no installed.packages for (?invalid) lib.loc=mgcv"
>
> When I typed installed.packages(), I got the following information
>
> libpath = "/usr/local/lib/R/site-library" for the installed package "mgcv".
>
> My next error was when I typed
> update.packages("mgcv",lib.loc="/usr/local/lib/R/site-library").
> It returned the error message,
>
> "error in download.file(url = paste(contriburl, "PACKAGES", sep="/"), :unsupported URL scheme"
>
> What should I do to correctly update this package?

Either update.packages() or install.packages("mgcv")

Please read the help page before posting.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From fm3a004 at math.uni-hamburg.de  Mon Mar 14 13:22:53 2005
From: fm3a004 at math.uni-hamburg.de (Christian Hennig)
Date: Mon, 14 Mar 2005 13:22:53 +0100 (MET)
Subject: [R] Parameters of Weibull regression
Message-ID: <Pine.GSO.3.95q.1050314130926.16149A-100000@sun35.math.uni-hamburg.de>

Dear list, dear Frank,

I try to fit a Weibull survival regression model with package Design:

sclear <- psm(sobj~V1+V2,dist="weibull")

sobj is a one-dimensional survival object (no event indicators), V1 and V2
are factors. 

I get the following result:

Parametric Survival Model: Weibull Distribution

psm(formula = sobj ~ V1 + V2, dist = "weibull")

       Obs     Events Model L.R.       d.f.          P         R2 
       120        120      30.96          3          0       0.23 

              Value Std. Error      z        p
(Intercept)  2.6161     0.0639  40.94 0.00e+00
V1=2         0.3098     0.0748   4.14 3.47e-05
V1=3         0.0911     0.0741   1.23 2.19e-01
V2=2        -0.2212     0.0613  -3.61 3.09e-04
Log(scale)  -1.1060     0.0704 -15.70 1.52e-55

Scale= 0.331 

I wonder how to relate the estimated parameters to the Weibull regression
model. Here is the model specification from Harrel, Regression Modeling
Strategies, p. 422:

S(t|X)=exp[-\alpha*t^\gamma exp(X\beta)]

This is the model without intercept, and it is indicated that \alpha can be
replaced by exp(\beta_0) in the model with intercept.

Now I am puzzled by the fact that \alpha (or \alpha exp(X\beta))
is usually referred to as
"scale parameter" in the context of the Weibull distribution. If this would
be the case, I could get the Weibull scale from the \beta/\beta_0 estimators
and I would need an estimator for \gamma. But only one further estimator is
given which is called "scale". This is definitely not the \gamma estimator,
because if I compute, say, median estimators, I get a result outside the
value range. From survplot I know that the model fit of the survival
function is OK, so in principle it seems that I did the right thing.

But how do I relate the output to the parameters
\alpha,\gamma,\beta in the model?

Thanks,
Christian

***********************************************************************
Christian Hennig
Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
>From 1 April 2005: Department of Statistical Science, UCL, London
#######################################################################
ich empfehle www.boag-online.de



From mwgrant2001 at yahoo.com  Mon Mar 14 13:41:54 2005
From: mwgrant2001 at yahoo.com (Michael Grant)
Date: Mon, 14 Mar 2005 04:41:54 -0800 (PST)
Subject: [R] r: eviews and r // eigen analysis
In-Reply-To: 6667
Message-ID: <20050314124154.5987.qmail@web52004.mail.yahoo.com>

It been thirty years since I was emeshed in QM and
lost in Hilbert space :O). So if I'm sloppy
some-someone correct me. IN A NUTSHELL: Note one
vector is the same in both sets (except for the sign).
Necessarily, the four remaining vectors (degenerate
BTW) in each set span the same subspace, i.e., form an
orthonormal basis for that subspace. One should rotate
into the other. It would be a nice exercise (really)to
convince yourself of that, providing some feel, i.e.,
visualization, of what you are dealing with.

Regards,
Michael Grant 


--- Clark Allan <Allan at STATS.uct.ac.za> wrote:
> hi all
> 
> i have a question that about the eigen analysis
> found in R and in
> eviews.
> 
> i used the same data set in the two packages and
> found different
> answers. which is incorrect?
> 
> the data is:
> aa ( a correlation matrix)
> 
> 1	0.9801	0.9801	0.9801	0.9801
> 0.9801	1	0.9801	0.9801	0.9801
> 0.9801	0.9801	1	0.9801	0.9801
> 0.9801	0.9801	0.9801	1	0.9801
> 0.9801	0.9801	0.9801	0.9801	1
> 
> now
> > svd(aa)
> $d
> [1] 4.9204 0.0199 0.0199 0.0199 0.0199
> 
> $u
>            [,1]          [,2]          [,3]         
> [,4]       [,5]
> [1,] -0.4472136  9.283999e-18  1.939587e-17
> -2.101554e-15  0.8944272
> [2,] -0.4472136  8.089763e-01  7.115435e-17 
> 3.091235e-01 -0.2236068
> [3,] -0.4472136  2.178563e-02  8.226578e-18
> -8.657513e-01 -0.2236068
> [4,] -0.4472136 -4.153810e-01 -7.071068e-01 
> 2.783139e-01 -0.2236068
> [5,] -0.4472136 -4.153810e-01  7.071068e-01 
> 2.783139e-01 -0.2236068
> 
> $v
>            [,1]        [,2]          [,3]       [,4]
>       [,5]
> [1,] -0.4472136  0.00000000  0.000000e+00  0.0000000
>  0.8944272
> [2,] -0.4472136  0.80897632 -4.976488e-17  0.3091235
> -0.2236068
> [3,] -0.4472136  0.02178563  1.077421e-17 -0.8657513
> -0.2236068
> [4,] -0.4472136 -0.41538097 -7.071068e-01  0.2783139
> -0.2236068
> [5,] -0.4472136 -0.41538097  7.071068e-01  0.2783139
> -0.2236068
> 
> the results from Eviews is:
> 
> eigenvectors = (note that Eviews arranges the eigen
> vectors in ascending
> order of the size of the eigen values)
> 
>  0.305963	-0.266024	-0.219066	-0.766569	 0.447214
>  0.315257	-0.603871	 0.075772	 0.574640	 0.447214
>  0.461958	 0.726861	 0.199385	 0.136062	 0.447214
> -0.482609	 0.185567	-0.700705	 0.204124	 0.447214
> -0.600569	-0.042534	 0.644614	-0.148258	 0.447214
> 
> eigen values =
> 
>  0.019900
>  0.019900
>  0.019900
>  0.019900
>  4.920400
> 
> NOTE THAT THE EIGEN VALUES ARE THE SAME BUT THE
> EIGEN VECTORS ARE NOT!!!
> 
> why is this so?
> 
> if one sets aa=
>  1.000000	 0.500000	 0.250000
>  0.500000	 1.000000	 0.350000
>  0.250000	 0.350000	 1.000000
> 
> 
> then both packages give the same answers.>
______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From stuart.leask at nottingham.ac.uk  Mon Mar 14 13:46:36 2005
From: stuart.leask at nottingham.ac.uk (Stuart Leask)
Date: Mon, 14 Mar 2005 12:46:36 -0000
Subject: [R] R: install - Perl dependency problem in Debian/Damn Small Linux
References: <42284169.6608D6F9@STATS.uct.ac.za>
	<16936.21113.570637.506601@stat.math.ethz.ch>
Message-ID: <004601c52893$dbf83eb0$f2e1f380@OPENZAURUS>

(I vaguely recall a suggestion there be a r-debian list, which this would be
appropriate for, but I can't find such a list if it exists. Apologies)

OS: Damn Small Linux 1.0rc1 - a tiny (50MB) debian/knoppix-based distro

I can't apt-get R.

root at ttyp0[dsl]# apt-get  install -testing r-base r-base-core r-recommended
Reading Package Lists... Done
Building Dependency Tree... Done
Some packages could not be installed. This may mean that you have
requested an impossible situation or if you are using the unstable
distribution that some required packages have not yet been created
or been moved out of Incoming.
The following information may help to resolve the situation:

The following packages have unmet dependencies:
  r-base-core: Depends: perl but it is not going to be installed
E: Broken packages

PROBLEM 1: Perl is certainly installed. However, it may have various bits
removed to save space.

However, if I try to correct this with:

apt-get install perl

I get:

The following packages have unmet dependencies:
  perl: depends perl-base (=5.6.1-8.7) but 5.8.0-18 is to be installed
E: broken packages

I've tried different feeds eg. -testing, but get the same problem.

Has anyone come across this, or have any ideas?

Stuart


Dr Stuart Leask DM MRCPsych, Senior Lecturer
University Dept of Psychiatry, Duncan Macmillan House
Porchester Road, Nottingham. NG3 6AA. UK
tel. 0115 924 9924 xtn 40784
http://www.nottingham.ac.uk/psychiatry/staff/s_leask.html


This message has been checked for viruses but the contents of an attachment
may still contain software viruses, which could damage your computer system:
you are advised to perform your own checks. Email communications with the
University of Nottingham may be monitored as permitted by UK legislation.



From wouter at paramo.be  Mon Mar 14 16:16:32 2005
From: wouter at paramo.be (Wouter Buytaert)
Date: Mon, 14 Mar 2005 15:16:32 +0000
Subject: [R] postscript rotation (bug?)
Message-ID: <1110813392.7744.10.camel@localhost>


hello,

when making postscript images with postscript() and converting them to
pdf with epstopdf, some images are rotated 90 degrees clockwise. The
postscript displays fine (ggv).

It seems to be related with length(xlab)/length(ylab), e.g:

>postscript("wrong.ps", width=5, height=5, horizontal=F, onefile=F,
paper = "special")
>plot(1, 1, xlab="short", ylab="abitlonger")
>dev.off()

If then converted to pdf with epstopf, then wrong.pdf is rotated

However,

>postscript("OK.ps", width=5, height=5, horizontal=F, onefile=F, paper =
"special")
>plot(1, 1, xlab="equal", ylab="equal")
>dev.off()

en then converted to OK.pdf displays OK.

Setting horizontal=T does not change anything for the final pdf file.
(The .ps is rotated -90 degrees however).

Is anyone able to reproduce this problem? I am using fedora core 3.

Thanks,

Wouter



From MSchwartz at MedAnalytics.com  Mon Mar 14 14:21:27 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Mon, 14 Mar 2005 07:21:27 -0600
Subject: [R] postscript rotation (bug?)
In-Reply-To: <1110813392.7744.10.camel@localhost>
References: <1110813392.7744.10.camel@localhost>
Message-ID: <1110806487.8558.2.camel@horizons.localdomain>

On Mon, 2005-03-14 at 15:16 +0000, Wouter Buytaert wrote:
> hello,
> 
> when making postscript images with postscript() and converting them to
> pdf with epstopdf, some images are rotated 90 degrees clockwise. The
> postscript displays fine (ggv).
> 
> It seems to be related with length(xlab)/length(ylab), e.g:
> 
> >postscript("wrong.ps", width=5, height=5, horizontal=F, onefile=F,
> paper = "special")
> >plot(1, 1, xlab="short", ylab="abitlonger")
> >dev.off()
> 
> If then converted to pdf with epstopf, then wrong.pdf is rotated
> 
> However,
> 
> >postscript("OK.ps", width=5, height=5, horizontal=F, onefile=F, paper =
> "special")
> >plot(1, 1, xlab="equal", ylab="equal")
> >dev.off()
> 
> en then converted to OK.pdf displays OK.
> 
> Setting horizontal=T does not change anything for the final pdf file.
> (The .ps is rotated -90 degrees however).
> 
> Is anyone able to reproduce this problem? I am using fedora core 3.

There was just a discussion on this. See this thread:

https://stat.ethz.ch/pipermail/r-help/2005-March/065593.html

HTH,

Marc Schwartz



From alice.le-bars at nantes.inserm.fr  Mon Mar 14 15:08:40 2005
From: alice.le-bars at nantes.inserm.fr (Alice Le Bars)
Date: Mon, 14 Mar 2005 15:08:40 +0100
Subject: [R] Question about Tukey HSD (stat package)
Message-ID: <42359AE8.6020308@nantes.inserm.fr>

Dear all,

I would be glad if someone could tell me if Tukey HSD (function of stats 
library) accept the NA values and could correct the unbalanced design 
(different number of sample in each group)

Thanks for help

Alice Le Bars



From ales.ziberna at guest.arnes.si  Mon Mar 14 15:38:14 2005
From: ales.ziberna at guest.arnes.si (Ale? ?iberna)
Date: Mon, 14 Mar 2005 15:38:14 +0100
Subject: [R] how to draw the data set processed by hclust?
References: <200503131223.j2DCNX96001247@hypatia.math.ethz.ch>
Message-ID: <008b01c528a3$8130b380$0509f9c2@ales>

type
 ?hclust
for how to use hclut, for example
 hc <- hclust(dist(USArrests), "ave")
Notice that you have to first compute the distance matrix with function 
"dist" or simmilar.

to get groups see
?cutree
for expamle for three grouops use k=3
groups<-cutree(hc,k=3)
and then plot using
plot(USArrests,col=groups)

I hope this help! In the future, PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html and follow the instructions 
(read help pages)!



----- Original Message ----- 
From: "XP Sun" <xpsun at ict.ac.cn>
To: <r-help at stat.math.ethz.ch>
Sent: Sunday, March 13, 2005 1:23 PM
Subject: [R] how to draw the data set processed by hclust?


> hi, all
>
>   i hava a dataset formated as follow:
>
> x1 y1 z1
> x2 y2 z2
> x3 y3 z3
> ...
>
> how to cluster it with hclust?
> and the draw the data with color of cluster?
>
> thank you in advance!
>
> best!
> xpsun
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
>



From ljw1001 at gmail.com  Mon Mar 14 15:42:42 2005
From: ljw1001 at gmail.com (Larry White)
Date: Mon, 14 Mar 2005 09:42:42 -0500
Subject: [R] using postgresql with R/RODBC
Message-ID: <d15ea14a0503140642359f8eee@mail.gmail.com>

Hi, Please excuse these questions if they're obvious. I'm new to R.

I need to access a Postgres db from R.  I'm currently trying RODBC as
I spend part of my time on Windows and rdbi.pgsql seems not to support
windows at this time.

I unzipped the RODBC win binary download into my library directory and
tried to load it using

library(RODBC)

I get the following error:

Error in dyn.load(x, as.logical(local), as.logical(now)) :   unable to
load shared library
"C:/PROGRA~1/R/rw2001/library/RODBC/libs/RODBC.dll":
  LoadLibrary failure:  The specified procedure could not be found.
In addition: Warning message:  package 'RODBC' was built under R version 2.1.0 
Error: .onLoad failed in loadNamespace for 'RODBC'
Error in library(RODBC) : package/namespace load failed for 'RODBC'

The path correctly points to the dll. Can anyone tell me what I'm doing wrong? 

thanks.



From p.dalgaard at biostat.ku.dk  Mon Mar 14 16:13:16 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 Mar 2005 16:13:16 +0100
Subject: [R] Question about Tukey HSD (stat package)
In-Reply-To: <42359AE8.6020308@nantes.inserm.fr>
References: <42359AE8.6020308@nantes.inserm.fr>
Message-ID: <x2vf7umfar.fsf@biostat.ku.dk>

Alice Le Bars <alice.le-bars at nantes.inserm.fr> writes:

> Dear all,
> 
> I would be glad if someone could tell me if Tukey HSD (function of
> stats library) accept the NA values and could correct the unbalanced
> design (different number of sample in each group)

I don't think the *theory* of the HSD allows this. There is some more
or less well-founded speculation that if the imbalance is not too bad,
then the HSD results are somewhat useful anyway, but please consider
using the multcomp package, which is specifically designed to get
these things right.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From macq at llnl.gov  Mon Mar 14 16:21:52 2005
From: macq at llnl.gov (Don MacQueen)
Date: Mon, 14 Mar 2005 07:21:52 -0800
Subject: [R] New user of R on Mac OS X - Please help
In-Reply-To: <a34f655784e0ef1b658910190dcd19f2@aqte.be>
References: <a34f655784e0ef1b658910190dcd19f2@aqte.be>
Message-ID: <p06210200be5b5ac9ec1c@[128.115.153.6]>

First, try to find out where in your function the 
error occurred. Exactly what R expression 
resulted in that error message?

Then ask again, providing that information.

I have been using R on OS X since it first became 
available on OS X, and have never seen an error 
message even remotely similar to this one. So you 
will have to provide more information about what 
you were trying to do.

-Don

p.s.
See also <https://stat.ethz.ch/mailman/listinfo/r-sig-mac>

At 3:44 PM +0100 3/12/05, Depiereux Constant wrote:
>Brand new Mac OS X user, I am transfering my R stuffs from my windows machine.
>
>When porting some of my functions, I got messages such as  :
>
>2005-03-12 15:37:52.456 R[673] *** NSTimer 
>discarding exception 'NSRangeException' (reason 
>'*** NSRunStorage, _NSBlockNumberForIndex(): 
>index (3607) beyond array bounds (2000)') that 
>raised during firing of timer with target 3ba850 
>and selector 'runRELP:'
>
>Does any body of you have any idea where I 
>should be starting looking for a solution for 
>ditto?
>
>Thnaks in advance four your help.
>
>
>Constant Depi?reux
>Managing Director
>Applied Quality Technologies Europe sprl
>Rue des D?port?s 123, B4800   Verviers
>Tel : + 32 87 29 21 75
>Fax : +32 87 29 21 71
>Mobile : +32 475 555 818
>e-Mail : constant.depiereux at aqte.be
>Web presence : http://www.aqte.be
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From ligges at statistik.uni-dortmund.de  Mon Mar 14 16:22:50 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 14 Mar 2005 16:22:50 +0100
Subject: [R] using postgresql with R/RODBC
In-Reply-To: <d15ea14a0503140642359f8eee@mail.gmail.com>
References: <d15ea14a0503140642359f8eee@mail.gmail.com>
Message-ID: <4235AC4A.9060105@statistik.uni-dortmund.de>

Larry White wrote:

> Hi, Please excuse these questions if they're obvious. I'm new to R.
> 
> I need to access a Postgres db from R.  I'm currently trying RODBC as
> I spend part of my time on Windows and rdbi.pgsql seems not to support
> windows at this time.
> 
> I unzipped the RODBC win binary download into my library directory and
> tried to load it using
> 
> library(RODBC)
> 
> I get the following error:
> 
> Error in dyn.load(x, as.logical(local), as.logical(now)) :   unable to
> load shared library
> "C:/PROGRA~1/R/rw2001/library/RODBC/libs/RODBC.dll":
>   LoadLibrary failure:  The specified procedure could not be found.
> In addition: Warning message:  package 'RODBC' was built under R version 2.1.0 

So why don't you use the binary package from CRAN that has been compiled 
for you under R-2.0.1?

Uwe Ligges



> Error: .onLoad failed in loadNamespace for 'RODBC'
> Error in library(RODBC) : package/namespace load failed for 'RODBC'
> 
> The path correctly points to the dll. Can anyone tell me what I'm doing wrong? 
> 
> thanks.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From macq at llnl.gov  Mon Mar 14 16:32:19 2005
From: macq at llnl.gov (Don MacQueen)
Date: Mon, 14 Mar 2005 07:32:19 -0800
Subject: [R] RODBC Package
In-Reply-To: <1564b6154122.1541221564b6@post.rwth-aachen.de>
References: <1564b6154122.1541221564b6@post.rwth-aachen.de>
Message-ID: <p06210201be5b5dc19e38@[128.115.153.6]>

The read.xls() function in the gdata package in the gregmisc bundle 
will import data from Excel spreadsheets on OS X.

I've used it with R 2.0.1 on Mac OS X 10.2.8, and the current version of Excel.

-Don

At 9:53 AM +0000 3/11/05, Stephan Freyberger wrote:
>Hello R-Help,
>
>is there any way of using the RODBC Package on a Mac OS X
>System? If yes, what do I need to get it running. Concerning these
>issues, I am pretty unexperienced, so please state any step
>necessary. The actual problem is accessing data in Excel- files.
>(unfortunately no alternative way of entering the data).
>I already installed the Package, but it says the following:
>
>>  versuch <- odbcConnectExcel("Thermanali-Versuch.xls")
>Error: couldn't find function "odbcConnectExcel"
>
>Thanks in Advance
>
>Stephan Freyberger
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From loesljrg at verizon.net  Mon Mar 14 19:49:32 2005
From: loesljrg at verizon.net (JRG)
Date: Mon, 14 Mar 2005 10:49:32 -0800
Subject: [R] Question about Tukey HSD (stat package)
In-Reply-To: <x2vf7umfar.fsf@biostat.ku.dk>
References: <42359AE8.6020308@nantes.inserm.fr>
Message-ID: <42356C3C.10595.D797E6@localhost>

On 14 Mar 2005 at 16:13, Peter Dalgaard wrote:

> Alice Le Bars <alice.le-bars at nantes.inserm.fr> writes:
> 
> > Dear all,
> > 
> > I would be glad if someone could tell me if Tukey HSD (function of
> > stats library) accept the NA values and could correct the unbalanced
> > design (different number of sample in each group)
> 
> I don't think the *theory* of the HSD allows this. There is some more
> or less well-founded speculation that if the imbalance is not too bad,
> then the HSD results are somewhat useful anyway, but please consider
> using the multcomp package, which is specifically designed to get
> these things right.
> 

I believe that Hayter (JASA, 1984, 12, 61--75) proves that the so-called Tukey-Kramer method is guarnateed to be conservative for 
any set of cell sizes --- under the usual ANOVA model, of course.

---JRG




> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


John R. Gleason

Syracuse University
430 Huntington Hall                      Voice:   315-443-3107
Syracuse, NY 13244-2340  USA             FAX:     315-443-4085

PGP public key at keyservers



From montorsi at polito.it  Mon Mar 14 16:54:46 2005
From: montorsi at polito.it (Guido Montorsi)
Date: Mon, 14 Mar 2005 16:54:46 +0100
Subject: [R] Bug on MWC1019?
Message-ID: <JLEFKFDNBJPHBOPAIEKLIEABDAAA.montorsi@polito.it>

Dear R-developer (Marsaglia??)

The following  piece of code from package SuppDist , routine "dist.cc" seems
to have a bug

ULONG MWC1019(void){
	ULONG long t;
	int	i = endQ-1;

	t = 147669672LL*Q[i] + Q[endQ];
	Q[endQ] = (t>>32);
	if(i>0)
		return(Q[i--] = t);
	i = endQ-1;
	return(Q[0] = t);
}

in fact , being "i" a local variable that have automatic storage, it is
initialized to endQ-1 (1019)
 each time the routine is called so that it can never
cycle through all values as it should.

I think it should be declared as static:

ULONG MWC1019(void){
	ULONG long t;
	static int	i = endQ-1;

	t = 147669672LL*Q[i] + Q[endQ];
	Q[endQ] = (t>>32);
	if(i>0)
		return(Q[i--] = t);
	i = endQ-1;
	return(Q[0] = t);
}

Best regards,

Guido Montorsi



From p.dalgaard at biostat.ku.dk  Mon Mar 14 17:22:09 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 Mar 2005 17:22:09 +0100
Subject: [R] Question about Tukey HSD (stat package)
In-Reply-To: <42356C3C.10595.D797E6@localhost>
References: <42359AE8.6020308@nantes.inserm.fr>
	<42356C3C.10595.D797E6@localhost>
Message-ID: <x2is3umc3y.fsf@biostat.ku.dk>

"JRG" <loesljrg at verizon.net> writes:

> On 14 Mar 2005 at 16:13, Peter Dalgaard wrote:
> 
> > Alice Le Bars <alice.le-bars at nantes.inserm.fr> writes:
> > 
> > > Dear all,
> > > 
> > > I would be glad if someone could tell me if Tukey HSD (function of
> > > stats library) accept the NA values and could correct the unbalanced
> > > design (different number of sample in each group)
> > 
> > I don't think the *theory* of the HSD allows this. There is some more
> > or less well-founded speculation that if the imbalance is not too bad,
> > then the HSD results are somewhat useful anyway, but please consider
> > using the multcomp package, which is specifically designed to get
> > these things right.
> > 
> 
> I believe that Hayter (JASA, 1984, 12, 61--75) proves that the so-called Tukey-Kramer method is guarnateed to be conservative for 
> any set of cell sizes --- under the usual ANOVA model, of course.

Make that Annals of Statistics, not JASA. 

Hayter proves that simultaneous confidence intervals based on using
the Studentized range distribution with (1/ni+1/nj)/2 instead of 1/n
will have coverage at least (1 - \alpha). He doesn't say *how*
conservative it is, though, and it doesn't change the fact that
multcomp has a better idea.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From loesljrg at verizon.net  Mon Mar 14 20:38:10 2005
From: loesljrg at verizon.net (JRG)
Date: Mon, 14 Mar 2005 11:38:10 -0800
Subject: [R] Question about Tukey HSD (stat package)
In-Reply-To: <x2is3umc3y.fsf@biostat.ku.dk>
References: <42356C3C.10595.D797E6@localhost>
Message-ID: <423577A2.18367.1041D1C@localhost>

On 14 Mar 2005 at 17:22, Peter Dalgaard wrote:

> "JRG" <loesljrg at verizon.net> writes:
> 
> > On 14 Mar 2005 at 16:13, Peter Dalgaard wrote:
> > 
> > > Alice Le Bars <alice.le-bars at nantes.inserm.fr> writes:
> > > 
> > > > Dear all,
> > > > 
> > > > I would be glad if someone could tell me if Tukey HSD (function of
> > > > stats library) accept the NA values and could correct the unbalanced
> > > > design (different number of sample in each group)
> > > 
> > > I don't think the *theory* of the HSD allows this. There is some more
> > > or less well-founded speculation that if the imbalance is not too bad,
> > > then the HSD results are somewhat useful anyway, but please consider
> > > using the multcomp package, which is specifically designed to get
> > > these things right.
> > > 
> > 
> > I believe that Hayter (JASA, 1984, 12, 61--75) proves that the so-called Tukey-Kramer method is guarnateed to be conservative for 
> > any set of cell sizes --- under the usual ANOVA model, of course.
> 
> Make that Annals of Statistics, not JASA. 
> 
> Hayter proves that simultaneous confidence intervals based on using
> the Studentized range distribution with (1/ni+1/nj)/2 instead of 1/n
> will have coverage at least (1 - \alpha). He doesn't say *how*
> conservative it is, though, and it doesn't change the fact that
> multcomp has a better idea.
> 

Whoops, let it be Annals.  However, there is a paper by Dunnett (ca 1981) which I again believe to be JASA which shows that the 
degree of conservativism is pretty slight, over a broad range of cell sizes.  Your point about multcomp stands.

---JRG




> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


John R. Gleason
Associate Professor

Syracuse University
430 Huntington Hall                      Voice:   315-443-3107
Syracuse, NY 13244-2340  USA             FAX:     315-443-4085

PGP public key at keyservers



From christian.kamenik at ips.unibe.ch  Mon Mar 14 18:32:12 2005
From: christian.kamenik at ips.unibe.ch (Christian Kamenik)
Date: Mon, 14 Mar 2005 18:32:12 +0100
Subject: [R] Significance of Principal Coordinates
Message-ID: <4235CA9C.1030603@ips.unibe.ch>

Dear all,

I was looking for methods in R that allow assessing the number of  
significant principal coordinates. Unfortunatly I was not very 
successful. I expanded my search to the web and Current Contents, 
however, the information I found is very limited.
Therefore, I tried to write code for doing a randomization. I would 
highly appriciate if somebody could comment on the following approach. I 
am neither a statistician, nor an R expert... the data matrix I used has 
72 species (columns) and 167 samples (rows).

Many thanks in advance, Christian

> # focus on ~80% of all the eigenvalues
>
> nEigen <- round(ncol(Data*0.8))
>
> # Calculate Weights for Principal Coordinates Analysis
>
> Total <- apply(Data,1,sum)
> Weight <- round(Total/max(Total)*1000)
>
>
> # Calculate Chord Distance
>
> library(vegan)
> Chord <- vegdist(decostand(Data, "norm"), "euclidean")
>
> # Calculate Principal Coordinates, including distance matrix row weights
>
> library(ade4)
> PCoord.Eigen <- dudi.pco(Chord,row.w=Weight,scann=F,full=T)$eig[1:nEigen]
>
> # Randomization of Principal Coordinates Analysis
>
> library(labdsv)
> for (i in 1:99) {
>     Data.random <- rndtaxa(Data,species=T,plots=T)
>     Total.random <- apply(Data.random,1,sum)
>     Weight.random <- round(Total.random/max(Total.random)*1000)
>     Chord.random <- vegdist(decostand(Data.random, "norm"), "euclidean")
>     PCoord.Eigen.random <- 
> dudi.pco(Chord.random,row.w=Weight.random,scann=F,full=T)$eig[1:nEigen]
>     PCoord.Eigen <- cbind.data.frame(PCoord.Eigen, PCoord.Eigen.random)
> }
>
> # Plot scree diagramm with original eigenvalues and 95%-quantiles of 
> eigenvalues from randomized principal coordinate analysis
>
> plot(c(1:nEigen),PCoord.Eigen[,1],type="b")
> lines(c(1:nEigen),apply(PCoord.Eigen[,-1],1,quantile,probs=c(0.95)),col="red")


Christian Kamenik
Institute of Plant Sciences
University of Bern



From abmartin at gmv.es  Mon Mar 14 18:36:30 2005
From: abmartin at gmv.es (=?iso-8859-1?Q?Bel=E9n_Mart=EDn_Peiro?=)
Date: Mon, 14 Mar 2005 18:36:30 +0100
Subject: [R] confidence level of kpss test
Message-ID: <000601c528bc$5c0ce9c0$87bc16ac@gmv.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050314/d89209d6/attachment.pl

From Achim.Zeileis at wu-wien.ac.at  Mon Mar 14 18:48:12 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Mon, 14 Mar 2005 18:48:12 +0100
Subject: [R] confidence level of kpss test
In-Reply-To: <000601c528bc$5c0ce9c0$87bc16ac@gmv.es>
References: <000601c528bc$5c0ce9c0$87bc16ac@gmv.es>
Message-ID: <20050314184812.26cb6fcb.Achim.Zeileis@wu-wien.ac.at>

On Mon, 14 Mar 2005 18:36:30 +0100 Bel?n Mart?n Peiro wrote:

> Dear All,
> 
> I am trying to use kpss.test function so as to perform a stationarity
> test on a data sample. Is it possible to know the associated
> confidence level for this test?

As for most other tests implemented in R, a p value is reported so you
can use a confidence level of your choice. For some of the tests you
mention, the p values are approximated from tables of simulated
asymptotic critical values in the range of 0.1 and 0.01. You won't
obtain smaller or larger p values and can therefore use only confidence
levels within that range.
Z

> I have not seen any arguments related to it.
> I had a look at some other tests included in R (adf.test, pp.test,
> ks.test ...) and I could not find this information for them.
> 
> Thanks in advanced. Kind regards,
> 
> Bel?n
> ______________________
> Este mensaje, y en su caso, cualquier fichero anexo al mismo,
>  puede contener informacion clasificada por su emisor como
>  confidencial en el marco de su Sistema de Gestion de Seguridad de la 
> Informacion siendo para uso exclusivo del destinatario, quedando 
> prohibida su divulgacion copia o distribucion a terceros sin la 
> autorizacion expresa del remitente. Si Vd. ha recibido este mensaje 
>  erroneamente, se ruega lo notifique al remitente y proceda a su
>  borrado. 
> Gracias por su colaboracion.
> ______________________
> This message including any attachments may contain\ > conf...{{dropped}}



From tzhou1 at uiuc.edu  Mon Mar 14 18:57:39 2005
From: tzhou1 at uiuc.edu (tianyue)
Date: Mon, 14 Mar 2005 11:57:39 -0600
Subject: [R] The corresponding Fortran77 codes for R function pt()
Message-ID: <4235D093.7060808@uiuc.edu>

Hi,

I'm trying to find the corresponding Fortran77 subroutines for R 
function pt(). I tried some Fortran77 subroutines to compute the t 
distribution function. But none of them are as good as R function pt(). 
Does anyone can give me some information about it?

Thank you very much!

Tianyue



From ljw1001 at gmail.com  Mon Mar 14 19:02:06 2005
From: ljw1001 at gmail.com (Larry White)
Date: Mon, 14 Mar 2005 13:02:06 -0500
Subject: [R] using postgresql with R/RODBC
In-Reply-To: <4235AC4A.9060105@statistik.uni-dortmund.de>
References: <d15ea14a0503140642359f8eee@mail.gmail.com>
	<4235AC4A.9060105@statistik.uni-dortmund.de>
Message-ID: <d15ea14a050314100277b2ee31@mail.gmail.com>

There's only one CRAN RODBC entry under Packages (version 1.1.3). 
That's the one I used.  The  'Depends' line seems to indicate that it
should work with any version of R > 1.9.

In any case, after I received the reply I went back to CRAN and took a
different path (under windows binaries) and located an earlier version
of RODBC (1.1.2).  When I tried that one I get this error:

Error in library(RODBC) : 'RODBC' is not a valid package -- installed < 2.0.0?

Aside from the Depends entry and the runtime error message there
doesn't seem to be any thing to indicate which version is appropriate
for R 2.0.1.

BTW, I'm on win 2000, if that would make a difference. 

On Mon, 14 Mar 2005 16:22:50 +0100, Uwe Ligges
<ligges at statistik.uni-dortmund.de> wrote:
> Larry White wrote:
> 
> > Hi, Please excuse these questions if they're obvious. I'm new to R.
> >
> > I need to access a Postgres db from R.  I'm currently trying RODBC as
> > I spend part of my time on Windows and rdbi.pgsql seems not to support
> > windows at this time.
> >
> > I unzipped the RODBC win binary download into my library directory and
> > tried to load it using
> >
> > library(RODBC)
> >
> > I get the following error:
> >
> > Error in dyn.load(x, as.logical(local), as.logical(now)) :   unable to
> > load shared library
> > "C:/PROGRA~1/R/rw2001/library/RODBC/libs/RODBC.dll":
> >   LoadLibrary failure:  The specified procedure could not be found.
> > In addition: Warning message:  package 'RODBC' was built under R version 2.1.0
> 
> So why don't you use the binary package from CRAN that has been compiled
> for you under R-2.0.1?
> 
> Uwe Ligges
> 
> 
> > Error: .onLoad failed in loadNamespace for 'RODBC'
> > Error in library(RODBC) : package/namespace load failed for 'RODBC'
> >
> > The path correctly points to the dll. Can anyone tell me what I'm doing wrong?
> >
> > thanks.
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From dirk.enzmann at jura.uni-hamburg.de  Mon Mar 14 19:13:49 2005
From: dirk.enzmann at jura.uni-hamburg.de (Dirk Enzmann)
Date: Mon, 14 Mar 2005 19:13:49 +0100
Subject: [R] par(new=TRUE) vs par(new=FALSE)
Message-ID: <4235D45D.3050703@jura.uni-hamburg.de>

Just out of curiosity (and I hope that my question does not confuse 
those who intuitively understood the par(new=TRUE) statement right in 
the beginning):

I would like to know whether beginners (learning R) had the same 
difficulty as I had: Intuitively I thought that par(new=TRUE) would draw 
a new plot (and not into an already existing plot) and that 
par(new=FALSE) would not draw a new plot but draw into an already 
existing plot - opposed to what the par(new=TRUE) statement actually 
does. (It would be interesting to receive an answer also from those who 
meanwhile reached an expert status  in working with the R syntax). 
Perhaps my confusion is due to the fact that I am a trained right-handed 
that really is a left-handed (those people tend to mistake contrasts).

If there are a lot of people having this difficulty, I would like to 
know why the decision was made to define the mode of action of the 
par(new=TRUE) statement as it is now. Perhaps that helps me to 
understand better the way programmers tend to think.

*************************************************
Dr. Dirk Enzmann
Institute of Criminal Sciences
Dept. of Criminology
Schlueterstr. 28
D-20146 Hamburg
Germany

phone: +49-040-42838.7498 (office)
        +49-040-42838.4591 (Billon)
fax:   +49-040-42838.2344
email: dirk.enzmann at jura.uni-hamburg.de
www: 
http://www2.jura.uni-hamburg.de/instkrim/kriminologie/Mitarbeiter/Enzmann/Enzmann.html



From rolf at math.unb.ca  Mon Mar 14 19:15:44 2005
From: rolf at math.unb.ca (Rolf Turner)
Date: Mon, 14 Mar 2005 14:15:44 -0400 (AST)
Subject: [R] confidence level of kpss test
Message-ID: <200503141815.j2EIFivV017428@erdos.math.unb.ca>

I ***do*** wish people wouldn't say ``confidence level'' when they
mean ``significance level''.  Confidence level refers to estimation
and significance level to hypothesis testing.  The two are closely
related but do not pack the same freight.

Moreover, if one indeed wishes to conflate the two ideas, the
confidence level of an estimation procedure is

		***one minus***

the significance level of the corresponding hypothesis test.

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From ligges at statistik.uni-dortmund.de  Mon Mar 14 19:17:49 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 14 Mar 2005 19:17:49 +0100
Subject: [R] using postgresql with R/RODBC
In-Reply-To: <d15ea14a050314100277b2ee31@mail.gmail.com>
References: <d15ea14a0503140642359f8eee@mail.gmail.com>	
	<4235AC4A.9060105@statistik.uni-dortmund.de>
	<d15ea14a050314100277b2ee31@mail.gmail.com>
Message-ID: <4235D54D.4010607@statistik.uni-dortmund.de>

Larry White wrote:

> There's only one CRAN RODBC entry under Packages (version 1.1.3). 
> That's the one I used.  The  'Depends' line seems to indicate that it
> should work with any version of R > 1.9.

Correct for the sources, but binaries must be compiled under the same 
major version for R that is used.


> In any case, after I received the reply I went back to CRAN and took a
> different path (under windows binaries) and located an earlier version
> of RODBC (1.1.2).  When I tried that one I get this error:
> 
> Error in library(RODBC) : 'RODBC' is not a valid package -- installed < 2.0.0?
> 
> Aside from the Depends entry and the runtime error message there
> doesn't seem to be any thing to indicate which version is appropriate
> for R 2.0.1.
>
> BTW, I'm on win 2000, if that would make a difference. 

That one you get when calling install.packages("RODBC") in R-2.0.x is in
CRAN/bin/windows/contrib/2.0/
for CRAN master this is currently:
http://cran.r-project.org/bin/windows/contrib/2.0/RODBC_1.1-3.zip

Uwe Ligges





> On Mon, 14 Mar 2005 16:22:50 +0100, Uwe Ligges
> <ligges at statistik.uni-dortmund.de> wrote:
> 
>>Larry White wrote:
>>
>>
>>>Hi, Please excuse these questions if they're obvious. I'm new to R.
>>>
>>>I need to access a Postgres db from R.  I'm currently trying RODBC as
>>>I spend part of my time on Windows and rdbi.pgsql seems not to support
>>>windows at this time.
>>>
>>>I unzipped the RODBC win binary download into my library directory and
>>>tried to load it using
>>>
>>>library(RODBC)
>>>
>>>I get the following error:
>>>
>>>Error in dyn.load(x, as.logical(local), as.logical(now)) :   unable to
>>>load shared library
>>>"C:/PROGRA~1/R/rw2001/library/RODBC/libs/RODBC.dll":
>>>  LoadLibrary failure:  The specified procedure could not be found.
>>>In addition: Warning message:  package 'RODBC' was built under R version 2.1.0
>>
>>So why don't you use the binary package from CRAN that has been compiled
>>for you under R-2.0.1?
>>
>>Uwe Ligges
>>
>>
>>
>>>Error: .onLoad failed in loadNamespace for 'RODBC'
>>>Error in library(RODBC) : package/namespace load failed for 'RODBC'
>>>
>>>The path correctly points to the dll. Can anyone tell me what I'm doing wrong?
>>>
>>>thanks.
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>>



From reid_huntsinger at merck.com  Mon Mar 14 19:20:35 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Mon, 14 Mar 2005 13:20:35 -0500
Subject: [R] The corresponding Fortran77 codes for R function pt()
Message-ID: <D9A95B4B7B20354992E165EEADA31999056A932F@uswpmx00.merck.com>

The routine "pt" is in the numerical mathematics library, in src/nmath if
you untar the source distribution of R. It's in C, though, not Fortran. You
can write Fortran wrappers for it.

Reid Huntsinger

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of tianyue
Sent: Monday, March 14, 2005 12:58 PM
To: r-help at stat.math.ethz.ch
Subject: [R] The corresponding Fortran77 codes for R function pt()


Hi,

I'm trying to find the corresponding Fortran77 subroutines for R 
function pt(). I tried some Fortran77 subroutines to compute the t 
distribution function. But none of them are as good as R function pt(). 
Does anyone can give me some information about it?

Thank you very much!

Tianyue

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Mon Mar 14 19:23:42 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 14 Mar 2005 19:23:42 +0100
Subject: [R] par(new=TRUE) vs par(new=FALSE)
In-Reply-To: <4235D45D.3050703@jura.uni-hamburg.de>
References: <4235D45D.3050703@jura.uni-hamburg.de>
Message-ID: <4235D6AE.1020700@statistik.uni-dortmund.de>

Dirk Enzmann wrote:

> Just out of curiosity (and I hope that my question does not confuse 
> those who intuitively understood the par(new=TRUE) statement right in 
> the beginning):
> 
> I would like to know whether beginners (learning R) had the same 
> difficulty as I had: Intuitively I thought that par(new=TRUE) would draw 
> a new plot (and not into an already existing plot) and that 
> par(new=FALSE) would not draw a new plot but draw into an already 
> existing plot - opposed to what the par(new=TRUE) statement actually 
> does. (It would be interesting to receive an answer also from those who 
> meanwhile reached an expert status  in working with the R syntax). 
> Perhaps my confusion is due to the fact that I am a trained right-handed 
> that really is a left-handed (those people tend to mistake contrasts).
> 
> If there are a lot of people having this difficulty, I would like to 
> know why the decision was made to define the mode of action of the 
> par(new=TRUE) statement as it is now. Perhaps that helps me to 
> understand better the way programmers tend to think.


This has been defined ages ago in the blue book (maybe in the brown one, 
I don't have it handy), so no chance to redefine. It confuses several 
users, but ?par has the nice explaination:

'new: logical, defaulting to FALSE. If set to TRUE, the next high-level 
plotting command (actually plot.new) should not clean the frame before 
drawing "as if it was on a new device".'

Uwe Ligges



> *************************************************
> Dr. Dirk Enzmann
> Institute of Criminal Sciences
> Dept. of Criminology
> Schlueterstr. 28
> D-20146 Hamburg
> Germany
> 
> phone: +49-040-42838.7498 (office)
>        +49-040-42838.4591 (Billon)
> fax:   +49-040-42838.2344
> email: dirk.enzmann at jura.uni-hamburg.de
> www: 
> http://www2.jura.uni-hamburg.de/instkrim/kriminologie/Mitarbeiter/Enzmann/Enzmann.html 
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From tlumley at u.washington.edu  Mon Mar 14 19:25:18 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 14 Mar 2005 10:25:18 -0800 (PST)
Subject: [R] The corresponding Fortran77 codes for R function pt()
In-Reply-To: <4235D093.7060808@uiuc.edu>
References: <4235D093.7060808@uiuc.edu>
Message-ID: <Pine.A41.4.61b.0503141021360.145614@homer05.u.washington.edu>

On Mon, 14 Mar 2005, tianyue wrote:

> Hi,
>
> I'm trying to find the corresponding Fortran77 subroutines for R function 
> pt(). I tried some Fortran77 subroutines to compute the t distribution 
> function. But none of them are as good as R function pt(). Does anyone can 
> give me some information about it?
>

There is no Fortran subroutine (although some of the C functions are 
translations of Fortran).  The C code is in any R source distribution, in 
src/nmath/pt.c.  It also calls src/nmath/pbeta.c. The comments in the 
code say where the algorithms came from.


 	-thomas



From p.dalgaard at biostat.ku.dk  Mon Mar 14 19:22:50 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 Mar 2005 19:22:50 +0100
Subject: [R] par(new=TRUE) vs par(new=FALSE)
In-Reply-To: <4235D45D.3050703@jura.uni-hamburg.de>
References: <4235D45D.3050703@jura.uni-hamburg.de>
Message-ID: <x2ekeim6it.fsf@biostat.ku.dk>

Dirk Enzmann <dirk.enzmann at jura.uni-hamburg.de> writes:

> Just out of curiosity (and I hope that my question does not confuse
> those who intuitively understood the par(new=TRUE) statement right in
> the beginning):
> 
> I would like to know whether beginners (learning R) had the same
> difficulty as I had: Intuitively I thought that par(new=TRUE) would
> draw a new plot (and not into an already existing plot) and that
> par(new=FALSE) would not draw a new plot but draw into an already
> existing plot - opposed to what the par(new=TRUE) statement actually
> does. (It would be interesting to receive an answer also from those
> who meanwhile reached an expert status  in working with the R syntax).
> Perhaps my confusion is due to the fact that I am a trained
> right-handed that really is a left-handed (those people tend to
> mistake contrasts).
> 
> If there are a lot of people having this difficulty, I would like to
> know why the decision was made to define the mode of action of the
> par(new=TRUE) statement as it is now. Perhaps that helps me to
> understand better the way programmers tend to think.

Well, internal consistency tends to get higher priority than people's
intuition. 

We already had par("new") which reflects a variable that gets set TRUE
when a new page is created, and set FALSE when a page is "dirtied".

This controls whether things like plot() needs to "eject the paper"
and start a new plot area, or whether it can just draw into the
existing area. To write on top of an existing plot it is occasionally
useful to pretend that the plot is new so you set the variable
accordingly.

Now, we could of course have set up the logic so that par("new") was
TRUE whenever you were *not* at the beginning of a new plot. Or we
could have arranged so that par("new"=FALSE) would set par("new) to be
TRUE, but neither struck us a particularly good idea....

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ligges at statistik.uni-dortmund.de  Mon Mar 14 19:32:06 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 14 Mar 2005 19:32:06 +0100
Subject: [R] The corresponding Fortran77 codes for R function pt()
In-Reply-To: <4235D093.7060808@uiuc.edu>
References: <4235D093.7060808@uiuc.edu>
Message-ID: <4235D8A6.4010607@statistik.uni-dortmund.de>

tianyue wrote:

> Hi,
> 
> I'm trying to find the corresponding Fortran77 subroutines for R 
> function pt(). I tried some Fortran77 subroutines to compute the t 
> distribution function. But none of them are as good as R function pt(). 
> Does anyone can give me some information about it?

Well, you can download the sources and take a look...
Who told you that it is in Fortran?

Uwe Ligges



> Thank you very much!
>
> Tianyue
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Mon Mar 14 19:35:08 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 14 Mar 2005 19:35:08 +0100
Subject: [R] Bug on MWC1019?
In-Reply-To: <JLEFKFDNBJPHBOPAIEKLIEABDAAA.montorsi@polito.it>
References: <JLEFKFDNBJPHBOPAIEKLIEABDAAA.montorsi@polito.it>
Message-ID: <4235D95C.2050606@statistik.uni-dortmund.de>

Guido Montorsi wrote:

> Dear R-developer (Marsaglia??)
> 
> The following  piece of code from package SuppDist , routine "dist.cc" seems
> to have a bug

The package is called *SuppDists*.
Bug reports and contributions for contributed packages should be 
addressed to the package maintainer (CCing, he might not be listening) 
rather than to R-help. Thanks.

Uwe Ligges


> ULONG MWC1019(void){
> 	ULONG long t;
> 	int	i = endQ-1;
> 
> 	t = 147669672LL*Q[i] + Q[endQ];
> 	Q[endQ] = (t>>32);
> 	if(i>0)
> 		return(Q[i--] = t);
> 	i = endQ-1;
> 	return(Q[0] = t);
> }
> 
> in fact , being "i" a local variable that have automatic storage, it is
> initialized to endQ-1 (1019)
>  each time the routine is called so that it can never
> cycle through all values as it should.
> 
> I think it should be declared as static:
> 
> ULONG MWC1019(void){
> 	ULONG long t;
> 	static int	i = endQ-1;
> 
> 	t = 147669672LL*Q[i] + Q[endQ];
> 	Q[endQ] = (t>>32);
> 	if(i>0)
> 		return(Q[i--] = t);
> 	i = endQ-1;
> 	return(Q[0] = t);
> }
> 
> Best regards,
> 
> Guido Montorsi
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From murdoch at stats.uwo.ca  Mon Mar 14 19:42:23 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 14 Mar 2005 18:42:23 +0000
Subject: [R] Bug on MWC1019?
In-Reply-To: <JLEFKFDNBJPHBOPAIEKLIEABDAAA.montorsi@polito.it>
References: <JLEFKFDNBJPHBOPAIEKLIEABDAAA.montorsi@polito.it>
Message-ID: <lbmb3150fv66e6q3tq7ksdbktjgv2fnnjm@4ax.com>

On Mon, 14 Mar 2005 16:54:46 +0100, "Guido Montorsi"
<montorsi at polito.it> wrote :

>Dear R-developer (Marsaglia??)
>
>The following  piece of code from package SuppDist , routine "dist.cc" seems
>to have a bug

You should normally send package bug reports to the maintainer, in
this case Bob Wheeler (who I've cc'd).

By the way, I agree that code does look wrong, but it would also be
helpful to provide R code that gives obviously wrong answers because
of it.

Duncan Murdoch

>
>ULONG MWC1019(void){
>	ULONG long t;
>	int	i = endQ-1;
>
>	t = 147669672LL*Q[i] + Q[endQ];
>	Q[endQ] = (t>>32);
>	if(i>0)
>		return(Q[i--] = t);
>	i = endQ-1;
>	return(Q[0] = t);
>}
>
>in fact , being "i" a local variable that have automatic storage, it is
>initialized to endQ-1 (1019)
> each time the routine is called so that it can never
>cycle through all values as it should.
>
>I think it should be declared as static:
>
>ULONG MWC1019(void){
>	ULONG long t;
>	static int	i = endQ-1;
>
>	t = 147669672LL*Q[i] + Q[endQ];
>	Q[endQ] = (t>>32);
>	if(i>0)
>		return(Q[i--] = t);
>	i = endQ-1;
>	return(Q[0] = t);
>}
>
>Best regards,
>
>Guido Montorsi
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From murdoch at stats.uwo.ca  Mon Mar 14 19:48:37 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 14 Mar 2005 18:48:37 +0000
Subject: [R] The corresponding Fortran77 codes for R function pt()
In-Reply-To: <4235D093.7060808@uiuc.edu>
References: <4235D093.7060808@uiuc.edu>
Message-ID: <t1nb31tv0tjt19af8bjp9k4icoljko95gg@4ax.com>

On Mon, 14 Mar 2005 11:57:39 -0600, tianyue <tzhou1 at uiuc.edu> wrote :

>Hi,
>
>I'm trying to find the corresponding Fortran77 subroutines for R 
>function pt(). I tried some Fortran77 subroutines to compute the t 
>distribution function. But none of them are as good as R function pt(). 
>Does anyone can give me some information about it?

Others have pointed you to the source code for that function.  You may
also want to call it directly:  R exports some functions with C
interfaces (that should be callable from Fortran, too).  See the R API
chapter in the Writing R Extensions manual.

Duncan Murdoch



From karlknoblich at yahoo.de  Mon Mar 14 20:19:17 2005
From: karlknoblich at yahoo.de (Karl Knoblick)
Date: Mon, 14 Mar 2005 20:19:17 +0100 (CET)
Subject: [R] bayesmix - What is or where can I find JAGS executable?
In-Reply-To: 6667
Message-ID: <20050314191917.44506.qmail@web26502.mail.ukl.yahoo.com>

Googling shows an pdf - but this link is broken.

Karl


--- Uwe Ligges <ligges at statistik.uni-dortmund.de>
wrote:
> Karl Knoblick wrote:
> 
> > Hallo!
> > 
> > I want to use the package bayesmix. Trying the
> > examples I had no success. The reason is, I think:
> 
> > 
> >>haveJAGS()
> > 
> > [1] FALSE
> > 
> > Have read of JAGS executable (I could not find
> > JAGS.exe in my R directory). What is JAGS? Where
> can I
> > find or download it?
> 
> What about googling for "JAGS.exe"?
> 
> Uwe Ligges
> 
> 
> 
> > Karl
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
>



From gaof at u.washington.edu  Sun Mar 13 20:26:48 2005
From: gaof at u.washington.edu (Faith G)
Date: Sun, 13 Mar 2005 14:26:48 -0500
Subject: [R] Output a dataframe from R to excel
Message-ID: <000601c52802$a5620fc0$0425ad80@FaithGao>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050313/a62aea71/attachment.pl

From karlknoblich at yahoo.de  Mon Mar 14 20:31:27 2005
From: karlknoblich at yahoo.de (Karl Knoblick)
Date: Mon, 14 Mar 2005 20:31:27 +0100 (CET)
Subject: [R] bayesmix - What is or where can I find JAGS executable?
Message-ID: <20050314193128.48645.qmail@web26502.mail.ukl.yahoo.com>

Sorry about the further question:

I downloaded bayesmix_0.5-3.zip (see below) - but
there is no jags.exe (even no *.exe) included.

Adress:
http://www.ci.tuwien.ac.at/~gruen/BayesMix/
Downloaded:
"Windows binaries including JAGS executable:
bayesmix_0.5-3.zip"

Karl



From jgentry at jimmy.harvard.edu  Mon Mar 14 20:34:34 2005
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Mon, 14 Mar 2005 14:34:34 -0500 (EST)
Subject: [R] Output a dataframe from R to excel
In-Reply-To: <000601c52802$a5620fc0$0425ad80@FaithGao>
Message-ID: <Pine.SOL.4.20.0503141434190.20855-100000@santiam.dfci.harvard.edu>

> I am trying to output an dataframe from R to Excel file. Can anyone
> tell me how to do it? Thanks a lot. 

write.csv() might get you where you want to go.



From Roger.Bivand at nhh.no  Mon Mar 14 20:41:05 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 14 Mar 2005 20:41:05 +0100 (CET)
Subject: [R] Output a dataframe from R to excel
In-Reply-To: <000601c52802$a5620fc0$0425ad80@FaithGao>
Message-ID: <Pine.LNX.4.44.0503142040250.2656-100000@reclus.nhh.no>

On Sun, 13 Mar 2005, Faith G wrote:

> Hi, 
> I am trying to output an dataframe from R to Excel file. Can anyone tell me how to do it? Thanks a lot.
> Eg. 
> R dataframe:
> A    B    C    
> 1    2    1
> 3    4    2
> .    .    .    

?write.table (see also the nice example)

> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From macq at llnl.gov  Mon Mar 14 21:36:48 2005
From: macq at llnl.gov (Don MacQueen)
Date: Mon, 14 Mar 2005 12:36:48 -0800
Subject: [R] difficulties with the save.image() function
In-Reply-To: <42330064.9010605@statistik.uni-dortmund.de>
References: <smtpd.7419.4231d7ba.7a514.1@mtaout-c.tc.umn.edu>
	<42330064.9010605@statistik.uni-dortmund.de>
Message-ID: <p06210205be5ba5947400@[128.115.153.6]>

At 3:44 PM +0100 3/12/05, Uwe Ligges wrote:
>Tracy Bergemann wrote:
>
>>Dear list,
>>
>>I've had difficulty saving my workspace to an .RData file.
>>This causes considerable frustration as it means that I have to regenerate
>>my analysis every time I want to update it.  For microarray data in
>>particular, this can be quite time consuming.
>>
>>I'm saving my data to a network folder on my system in Windows XP, something
>>like an "H:\" drive or a "P:\" drive instead of a "C:\" drive.
>>
>>Here is the command which saves my workspace to my working directory:
>>save.image("H:/Consulting/cmlExprA.RData")
>>And here is the error I get:
>>Error in save(list = ls(envir = .GlobalEnv, all.names = TRUE), file =
>>outfile,: error writing to connection
>>
>>Any assistance?

To which we might add a simple test such as:

    sink('H:/Consulting/test.txt') ; ls() ; sink()

Which if it succeeds will eliminate some possible issues, and if it 
fails will eliminate others.

>
>- Do you have write access?
>- Is there enough space available?
>- Any quota?
>- Can you save on a local drive, say a temp directory?
>- How big is the file size? ("microarray" make me assume it is huge, 
>so is it > 2GB?, does the system support the file size?)
>
>- What is the output of
>  file.info("H:/Consulting/cmlExprA.RData")
>and
>  file.info("H:/Consulting")
>
>
>Uwe Ligges
>
>
>>Many thanks,
>>Tracy L. Bergemann, PhD
>>Biostatistics Core
>>University of Minnesota Cancer Center
>>B412-4 Mayo building
>>Office # 626-5408
>>

-Don

-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From Robert.McGehee at geodecapital.com  Mon Mar 14 21:55:55 2005
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Mon, 14 Mar 2005 15:55:55 -0500
Subject: [R] Legend Line Size
Message-ID: <67DCA285A2D7754280D3B8E88EB548020C946551@MSGBOSCLB2WIN.DMN1.FMR.COM>

Hello all,

When I view or print the below plot on my Linux machine under R 2.0.1 I
see a nice thick solid and dashed line with a legend. However, while the
lines are distinguishable, the legend is not. That is, the short (solid)
line next to "line1" and the short (dashed) line next to "line2" seem to
have the exact same length. What I would like to do is to expand the
legend line a bit farther so that the user can clearly see a solid vs. a
dashed line and not too small lines that look the same.

A glance at the legend source code shows that the line segment length
(seg.len) seems to be hard-coded as 2. If I change this to a larger
number within the code, I get the effect that I want (although the box
around the legend needs to be resized). Am I overlooking a more obvious
way to distinguish the legend lines, or would it make more sense to
patch the legend function to fit my needs?

x <- 1:10
plot(x, x, type = "l", lty = 1, lwd = 4)
lines(x, 2*x, type = "l", lty = 5, lwd = 4)
legend(7, 5, legend = c("line1", "line2"), lty = c(1, 5), lwd = 4)

Thanks,
Robert



From Benjamin.Osborne at uvm.edu  Mon Mar 14 22:00:33 2005
From: Benjamin.Osborne at uvm.edu (Benjamin M. Osborne)
Date: Mon, 14 Mar 2005 16:00:33 -0500
Subject: [R] calling objects in a foreloop
Message-ID: <1110834033.4235fb71188bf@webmail.uvm.edu>

I want to organize outputs from several regressions into a handy table.  When I
try the following, each of my "fit_s" is replaces instead of read.  Is there a
way to read from the regression summaries that does not require writing
separate lines of code for each?
-Ben Osborne

> fit1<-lm(dBA.spp16$sp2.dBA.ha~dBA.spp16$sp1.dBA.ha)
> fit2<-lm(dBA.spp16$sp3.dBA.ha~dBA.spp16$sp1.dBA.ha)
> fit3<-lm(dBA.spp16$sp3.dBA.ha~dBA.spp16$sp2.dBA.ha)
> fit4<-lm(dBA.spp16$sp5.dBA.ha~dBA.spp16$sp4.dBA.ha)
> fit5<-lm(dBA.spp16$sp6.dBA.ha~dBA.spp16$sp4.dBA.ha)
> fit6<-lm(dBA.spp16$sp5.dBA.ha~dBA.spp16$sp6.dBA.ha)
> fit7<-lm(dBA.spp16$sp1.dBA.ha~dBA.spp16$sp4.dBA.ha)
> fit8<-lm(dBA.spp16$sp1.dBA.ha~dBA.spp16$sp5.dBA.ha)
>
> dBA.spp16.fits<-matrix(NA, nrow=8, ncol=5)
> colnames(dBA.spp16.fits)<-c("formula","intercept","slope","R^2","adj.R^2")
>
> for (i in 1:8){
+ dBA.spp16.fits[i,1]<-summary(as.name(paste("fit",i,sep="")))$call
+ dBA.spp16.fits[i,2]<-summary(as.name(paste("fit",i,sep="")))$coef[1,1]
+ dBA.spp16.fits[i,3]<-summary(as.name(paste("fit",i,sep="")))$coef[2,1]
+ dBA.spp16.fits[i,4]<-summary(as.name(paste("fit",i,sep="")))$r.squared
+ dBA.spp16.fits[i,5]<-summary(as.name(paste("fit",i,sep="")))$adj.r.squared
+ }
Error in "[<-"(`*tmp*`, i, 1, value = NULL) :
        number of items to replace is not a multiple of replacement length

# Because:
> i<-1
> summary(as.name(paste("fit",i,sep="")))
Length  Class   Mode
     1   name   name
>
-- 
Botany Department
University of Vermont
109 Carrigan Drive
Burlington, VT 05405

benjamin.osborne at uvm.edu
phone: 802-656-0297
fax: 802-656-0440



From younko at uiuc.edu  Mon Mar 14 22:10:19 2005
From: younko at uiuc.edu (Ko,Younhee)
Date: Mon, 14 Mar 2005 15:10:19 -0600
Subject: [R] Install the RMySQL 
Message-ID: <5662d229.dd1719e0.899a800@expms3.cites.uiuc.edu>

Hi, I have some problem to install RMySQL package.
Could you help me?

I set up the path.


[root at ep2 library]# export PKG_CPPFLAGS="-I/var/lib/mysql"
[root at ep2 library]# export PKG_LIBS="-L/var/lib/mysql -
lmysqlclient"
[root at ep2 library]# R CMD INSTALL /home/younko/RMySQL_0.5-
5.tar.gz 


I got this bunch of error message.



Please help me.


* Installing *source* package 'RMySQL' ...
creating cache ./config.cache
checking how to run the C preprocessor... cc -E
checking for compress in -lz... yes
checking for getopt_long in -lc... yes
checking for mysql_init in -lmysqlclient... no
checking for mysql.h... no
updating cache ./config.cache
creating ./config.status
creating src/Makevars
** libs
gcc -I/usr/local/lib/R/include -I/var/lib/mysql -
I/usr/local/include   -fPIC  -g -O2 -c RS-DBI.c -o RS-DBI.o
gcc -I/usr/local/lib/R/include -I/var/lib/mysql -
I/usr/local/include   -fPIC  -g -O2 -c RS-MySQL.c -o RS-
MySQL.o
In file included from RS-MySQL.c:22:
RS-MySQL.h:40:19: mysql.h: No such file or directory
RS-MySQL.h:41:27: mysql_version.h: No such file or directory
RS-MySQL.h:42:23: mysql_com.h: No such file or directory
In file included from RS-MySQL.c:22:
RS-MySQL.h:109: `FIELD_TYPE_DECIMAL' undeclared here (not in 
a function)
RS-MySQL.h:109: initializer element is not constant
RS-MySQL.h:109: (near initialization for `RS_MySQL_dataTypes
[0].typeId')
RS-MySQL.h:109: initializer element is not constant
RS-MySQL.h:109: (near initialization for `RS_MySQL_dataTypes
[0]')
RS-MySQL.h:110: `FIELD_TYPE_TINY' undeclared here (not in a 
function)
RS-MySQL.h:110: initializer element is not constant
RS-MySQL.h:110: (near initialization for `RS_MySQL_dataTypes
[1].typeId')
RS-MySQL.h:110: initializer element is not constant
RS-MySQL.h:110: (near initialization for `RS_MySQL_dataTypes
[1]')
RS-MySQL.h:111: `FIELD_TYPE_SHORT' undeclared here (not in a 
function)
RS-MySQL.h:111: initializer element is not constant
RS-MySQL.h:111: (near initialization for `RS_MySQL_dataTypes
[2].typeId')
RS-MySQL.h:111: initializer element is not constant
RS-MySQL.h:111: (near initialization for `RS_MySQL_dataTypes
[2]')
RS-MySQL.h:112: `FIELD_TYPE_LONG' undeclared here (not in a 
function)
RS-MySQL.h:112: initializer element is not constant
RS-MySQL.h:112: (near initialization for `RS_MySQL_dataTypes
[3].typeId')
RS-MySQL.h:112: initializer element is not constant
RS-MySQL.h:112: (near initialization for `RS_MySQL_dataTypes
[3]')
RS-MySQL.h:113: `FIELD_TYPE_FLOAT' undeclared here (not in a 
function)
RS-MySQL.h:113: initializer element is not constant
RS-MySQL.h:113: (near initialization for `RS_MySQL_dataTypes
[4].typeId')
RS-MySQL.h:113: initializer element is not constant
RS-MySQL.h:113: (near initialization for `RS_MySQL_dataTypes
[4]')
RS-MySQL.h:114: `FIELD_TYPE_DOUBLE' undeclared here (not in 
a function)
RS-MySQL.h:114: initializer element is not constant
RS-MySQL.h:114: (near initialization for `RS_MySQL_dataTypes
[5].typeId')
RS-MySQL.h:114: initializer element is not constant
RS-MySQL.h:114: (near initialization for `RS_MySQL_dataTypes
[5]')
RS-MySQL.h:115: `FIELD_TYPE_NULL' undeclared here (not in a 
function)
RS-MySQL.h:115: initializer element is not constant
RS-MySQL.h:115: (near initialization for `RS_MySQL_dataTypes
[6].typeId')
RS-MySQL.h:115: initializer element is not constant
RS-MySQL.h:115: (near initialization for `RS_MySQL_dataTypes
[6]')
RS-MySQL.h:116: `FIELD_TYPE_TIMESTAMP' undeclared here (not 
in a function)
RS-MySQL.h:116: initializer element is not constant
RS-MySQL.h:116: (near initialization for `RS_MySQL_dataTypes
[7].typeId')
RS-MySQL.h:116: initializer element is not constant
RS-MySQL.h:116: (near initialization for `RS_MySQL_dataTypes
[7]')
RS-MySQL.h:117: `FIELD_TYPE_LONGLONG' undeclared here (not 
in a function)
RS-MySQL.h:117: initializer element is not constant
RS-MySQL.h:117: (near initialization for `RS_MySQL_dataTypes
[8].typeId')
RS-MySQL.h:117: initializer element is not constant
RS-MySQL.h:117: (near initialization for `RS_MySQL_dataTypes
[8]')
RS-MySQL.h:118: `FIELD_TYPE_INT24' undeclared here (not in a 
function)
RS-MySQL.h:118: initializer element is not constant
RS-MySQL.h:118: (near initialization for `RS_MySQL_dataTypes
[9].typeId')
RS-MySQL.h:118: initializer element is not constant
RS-MySQL.h:118: (near initialization for `RS_MySQL_dataTypes
[9]')
RS-MySQL.h:119: `FIELD_TYPE_DATE' undeclared here (not in a 
function)
RS-MySQL.h:119: initializer element is not constant
RS-MySQL.h:119: (near initialization for `RS_MySQL_dataTypes
[10].typeId')
RS-MySQL.h:119: initializer element is not constant
RS-MySQL.h:119: (near initialization for `RS_MySQL_dataTypes
[10]')
RS-MySQL.h:120: `FIELD_TYPE_TIME' undeclared here (not in a 
function)
RS-MySQL.h:120: initializer element is not constant
RS-MySQL.h:120: (near initialization for `RS_MySQL_dataTypes
[11].typeId')
RS-MySQL.h:120: initializer element is not constant
RS-MySQL.h:120: (near initialization for `RS_MySQL_dataTypes
[11]')
RS-MySQL.h:121: `FIELD_TYPE_DATETIME' undeclared here (not 
in a function)
RS-MySQL.h:121: initializer element is not constant
RS-MySQL.h:121: (near initialization for `RS_MySQL_dataTypes
[12].typeId')
RS-MySQL.h:121: initializer element is not constant
RS-MySQL.h:121: (near initialization for `RS_MySQL_dataTypes
[12]')
RS-MySQL.h:122: `FIELD_TYPE_YEAR' undeclared here (not in a 
function)
RS-MySQL.h:122: initializer element is not constant
RS-MySQL.h:122: (near initialization for `RS_MySQL_dataTypes
[13].typeId')
RS-MySQL.h:122: initializer element is not constant
RS-MySQL.h:122: (near initialization for `RS_MySQL_dataTypes
[13]')
RS-MySQL.h:123: `FIELD_TYPE_NEWDATE' undeclared here (not in 
a function)
RS-MySQL.h:123: initializer element is not constant
RS-MySQL.h:123: (near initialization for `RS_MySQL_dataTypes
[14].typeId')
RS-MySQL.h:123: initializer element is not constant
RS-MySQL.h:123: (near initialization for `RS_MySQL_dataTypes
[14]')
RS-MySQL.h:124: `FIELD_TYPE_ENUM' undeclared here (not in a 
function)
RS-MySQL.h:124: initializer element is not constant
RS-MySQL.h:124: (near initialization for `RS_MySQL_dataTypes
[15].typeId')
RS-MySQL.h:124: initializer element is not constant
RS-MySQL.h:124: (near initialization for `RS_MySQL_dataTypes
[15]')
RS-MySQL.h:125: `FIELD_TYPE_SET' undeclared here (not in a 
function)
RS-MySQL.h:125: initializer element is not constant
RS-MySQL.h:125: (near initialization for `RS_MySQL_dataTypes
[16].typeId')
RS-MySQL.h:125: initializer element is not constant
RS-MySQL.h:125: (near initialization for `RS_MySQL_dataTypes
[16]')
RS-MySQL.h:126: `FIELD_TYPE_TINY_BLOB' undeclared here (not 
in a function)
RS-MySQL.h:126: initializer element is not constant
RS-MySQL.h:126: (near initialization for `RS_MySQL_dataTypes
[17].typeId')
RS-MySQL.h:126: initializer element is not constant
RS-MySQL.h:126: (near initialization for `RS_MySQL_dataTypes
[17]')
RS-MySQL.h:127: `FIELD_TYPE_MEDIUM_BLOB' undeclared here 
(not in a function)
RS-MySQL.h:127: initializer element is not constant
RS-MySQL.h:127: (near initialization for `RS_MySQL_dataTypes
[18].typeId')
RS-MySQL.h:127: initializer element is not constant
RS-MySQL.h:127: (near initialization for `RS_MySQL_dataTypes
[18]')
RS-MySQL.h:128: `FIELD_TYPE_LONG_BLOB' undeclared here (not 
in a function)
RS-MySQL.h:128: initializer element is not constant
RS-MySQL.h:128: (near initialization for `RS_MySQL_dataTypes
[19].typeId')
RS-MySQL.h:128: initializer element is not constant
RS-MySQL.h:128: (near initialization for `RS_MySQL_dataTypes
[19]')
RS-MySQL.h:129: `FIELD_TYPE_BLOB' undeclared here (not in a 
function)
RS-MySQL.h:129: initializer element is not constant
RS-MySQL.h:129: (near initialization for `RS_MySQL_dataTypes
[20].typeId')
RS-MySQL.h:129: initializer element is not constant
RS-MySQL.h:129: (near initialization for `RS_MySQL_dataTypes
[20]')
RS-MySQL.h:130: `FIELD_TYPE_VAR_STRING' undeclared here (not 
in a function)
RS-MySQL.h:130: initializer element is not constant
RS-MySQL.h:130: (near initialization for `RS_MySQL_dataTypes
[21].typeId')
RS-MySQL.h:130: initializer element is not constant
RS-MySQL.h:130: (near initialization for `RS_MySQL_dataTypes
[21]')
RS-MySQL.h:131: `FIELD_TYPE_STRING' undeclared here (not in 
a function)
RS-MySQL.h:131: initializer element is not constant
RS-MySQL.h:131: (near initialization for `RS_MySQL_dataTypes
[22].typeId')
RS-MySQL.h:131: initializer element is not constant
RS-MySQL.h:131: (near initialization for `RS_MySQL_dataTypes
[22]')
RS-MySQL.h:132: initializer element is not constant
RS-MySQL.h:132: (near initialization for `RS_MySQL_dataTypes
[23]')
RS-MySQL.c:25: `MYSQL_SERVER_VERSION' undeclared here (not 
in a function)
RS-MySQL.c: In function `RS_MySQL_init':
RS-MySQL.c:73: warning: initialization makes pointer from 
integer without a cast
RS-MySQL.c: In function `RS_MySQL_newConnection':
RS-MySQL.c:189: `MYSQL' undeclared (first use in this 
function)
RS-MySQL.c:189: (Each undeclared identifier is reported only 
once
RS-MySQL.c:189: for each function it appears in.)
RS-MySQL.c:189: `my_connection' undeclared (first use in 
this function)
RS-MySQL.c:238: `MYSQL_READ_DEFAULT_GROUP' undeclared (first 
use in this function)
RS-MySQL.c: In function `RS_MySQL_closeConnection':
RS-MySQL.c:370: `MYSQL' undeclared (first use in this 
function)
RS-MySQL.c:370: `my_connection' undeclared (first use in 
this function)
RS-MySQL.c:386: parse error before ')' token
RS-MySQL.c: In function `RS_MySQL_exec':
RS-MySQL.c:411: `MYSQL' undeclared (first use in this 
function)
RS-MySQL.c:411: `my_connection' undeclared (first use in 
this function)
RS-MySQL.c:412: `MYSQL_RES' undeclared (first use in this 
function)
RS-MySQL.c:412: `my_result' undeclared (first use in this 
function)
RS-MySQL.c:418: parse error before ')' token
RS-MySQL.c:457: parse error before ')' token
RS-MySQL.c: In function `RS_MySQL_createDataMappings':
RS-MySQL.c:496: `MYSQL_RES' undeclared (first use in this 
function)
RS-MySQL.c:496: `my_result' undeclared (first use in this 
function)
RS-MySQL.c:497: `MYSQL_FIELD' undeclared (first use in this 
function)
RS-MySQL.c:497: `select_dp' undeclared (first use in this 
function)
RS-MySQL.c:505: parse error before ')' token
RS-MySQL.c:511: `MYSQL' undeclared (first use in this 
function)
RS-MySQL.c:511: parse error before ')' token
RS-MySQL.c:546: `FIELD_TYPE_VAR_STRING' undeclared (first 
use in this function)
RS-MySQL.c:547: `FIELD_TYPE_STRING' undeclared (first use in 
this function)
RS-MySQL.c:551: `FIELD_TYPE_TINY' undeclared (first use in 
this function)
RS-MySQL.c:552: `FIELD_TYPE_SHORT' undeclared (first use in 
this function)
RS-MySQL.c:553: `FIELD_TYPE_INT24' undeclared (first use in 
this function)
RS-MySQL.c:554: `FIELD_TYPE_LONG' undeclared (first use in 
this function)
RS-MySQL.c:556: `UNSIGNED_FLAG' undeclared (first use in 
this function)
RS-MySQL.c:561: `FIELD_TYPE_LONGLONG' undeclared (first use 
in this function)
RS-MySQL.c:566: `FIELD_TYPE_DECIMAL' undeclared (first use 
in this function)
RS-MySQL.c:572: `FIELD_TYPE_FLOAT' undeclared (first use in 
this function)
RS-MySQL.c:573: `FIELD_TYPE_DOUBLE' undeclared (first use in 
this function)
RS-MySQL.c:576: `FIELD_TYPE_BLOB' undeclared (first use in 
this function)
RS-MySQL.c:577: `FIELD_TYPE_TINY_BLOB' undeclared (first use 
in this function)
RS-MySQL.c:578: `FIELD_TYPE_MEDIUM_BLOB' undeclared (first 
use in this function)
RS-MySQL.c:579: `FIELD_TYPE_LONG_BLOB' undeclared (first use 
in this function)
RS-MySQL.c:583: `FIELD_TYPE_DATE' undeclared (first use in 
this function)
RS-MySQL.c:584: `FIELD_TYPE_TIME' undeclared (first use in 
this function)
RS-MySQL.c:585: `FIELD_TYPE_DATETIME' undeclared (first use 
in this function)
RS-MySQL.c:586: `FIELD_TYPE_YEAR' undeclared (first use in 
this function)
RS-MySQL.c:587: `FIELD_TYPE_NEWDATE' undeclared (first use 
in this function)
RS-MySQL.c:591: `FIELD_TYPE_ENUM' undeclared (first use in 
this function)
RS-MySQL.c:595: `FIELD_TYPE_SET' undeclared (first use in 
this function)
RS-MySQL.c: In function `RS_MySQL_fetch':
RS-MySQL.c:620: `MYSQL_RES' undeclared (first use in this 
function)
RS-MySQL.c:620: `my_result' undeclared (first use in this 
function)
RS-MySQL.c:621: `MYSQL_ROW' undeclared (first use in this 
function)
RS-MySQL.c:621: parse error before "row"
RS-MySQL.c:658: parse error before ')' token
RS-MySQL.c:676: `row' undeclared (first use in this function)
RS-MySQL.c:681: `MYSQL' undeclared (first use in this 
function)
RS-MySQL.c:681: parse error before ')' token
RS-MySQL.c:685: warning: assignment makes pointer from 
integer without a cast
RS-MySQL.c: In function `RS_MySQL_getException':
RS-MySQL.c:789: `MYSQL' undeclared (first use in this 
function)
RS-MySQL.c:789: `my_connection' undeclared (first use in 
this function)
RS-MySQL.c:809: parse error before ')' token
RS-MySQL.c:811: warning: passing arg 1 of `Rf_mkChar' makes 
pointer from integer without a cast
RS-MySQL.c: In function `RS_MySQL_closeResultSet':
RS-MySQL.c:822: `MYSQL_RES' undeclared (first use in this 
function)
RS-MySQL.c:822: `my_result' undeclared (first use in this 
function)
RS-MySQL.c:827: parse error before ')' token
RS-MySQL.c:830: `MYSQL_ROW' undeclared (first use in this 
function)
RS-MySQL.c:830: parse error before "row"
RS-MySQL.c:831: `row' undeclared (first use in this function)
RS-MySQL.c: In function `RS_MySQL_managerInfo':
RS-MySQL.c:900: warning: passing arg 1 of `Rf_mkChar' makes 
pointer from integer without a cast
RS-MySQL.c: In function `RS_MySQL_connectionInfo':
RS-MySQL.c:910: `MYSQL' undeclared (first use in this 
function)
RS-MySQL.c:910: `my_con' undeclared (first use in this 
function)
RS-MySQL.c:925: parse error before ')' token
RS-MySQL.c:939: warning: passing arg 1 of `Rf_mkChar' makes 
pointer from integer without a cast
RS-MySQL.c:940: warning: passing arg 1 of `Rf_mkChar' makes 
pointer from integer without a cast
RS-MySQL.c: In function `RS_MySQL_dbApply':
RS-MySQL.c:1158: `MYSQL_RES' undeclared (first use in this 
function)
RS-MySQL.c:1158: `my_result' undeclared (first use in this 
function)
RS-MySQL.c:1159: `MYSQL_ROW' undeclared (first use in this 
function)
RS-MySQL.c:1159: parse error before "row"
RS-MySQL.c:1184: `row' undeclared (first use in this 
function)
RS-MySQL.c:1233: parse error before ')' token
RS-MySQL.c:1258: `MYSQL' undeclared (first use in this 
function)
RS-MySQL.c:1258: parse error before ')' token
RS-MySQL.c:1264: warning: assignment makes pointer from 
integer without a cast
make: *** [RS-MySQL.o] Error 1
ERROR: compilation failed for package 'RMySQL'

========================
Younhee Ko(younko at uiuc.edu)

http://comedu.korea.ac.kr/~unygo
contact : 217-417-4868
Graduate Student in Dept. of Computer Science
University of Illinois at Urbana-Champaign



From tlumley at u.washington.edu  Mon Mar 14 22:35:08 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 14 Mar 2005 13:35:08 -0800 (PST)
Subject: [R] calling objects in a foreloop
In-Reply-To: <1110834033.4235fb71188bf@webmail.uvm.edu>
References: <1110834033.4235fb71188bf@webmail.uvm.edu>
Message-ID: <Pine.A41.4.61b.0503141308450.145614@homer05.u.washington.edu>

On Mon, 14 Mar 2005, Benjamin M. Osborne wrote:

> I want to organize outputs from several regressions into a handy table.  When I
> try the following, each of my "fit_s" is replaces instead of read.  Is there a
> way to read from the regression summaries that does not require writing
> separate lines of code for each?


Put the lm objects into a list rather than into separate variables, then 
you can loop or lapply() over the list.

fits<-vector("list",8)
fits[[1]]<-lm(dBA.spp16$sp2.dBA.ha~dBA.spp16$sp1.dBA.ha)
fits[[2]]<-lm(dBA.spp16$sp3.dBA.ha~dBA.spp16$sp1.dBA.ha)
etc

dBA.spp16.fits<-matrix(NA, nrow=8, ncol=5)
for (i in 1:8){
     summ<-summary(fit[[i]])
     dBA.spp16.fits[i,2]<-summ$coef[1,1]
     dBA.spp16.fits[i,3]<-summ$coef[2,1]
     dBA.spp16.fits[i,4]<-summ$r.squared
     dBA.spp16.fits[i,5]<-summ$adj.r.squared
}

Other things to note

1/  You can't put the formula into a numeric matrix
2/ lm(dBA.spp16$sp2.dBA.ha~dBA.spp16$sp1.dBA.ha) can be more elegantly 
written as
    lm(sp2.dBA.ha~sp1.DB.ha, data=dBA.spp16)


When you find yourself doing computations on the names of objects rather 
than on their values it is usually a bad sign.


 	-thomas



From blindglobe at gmail.com  Mon Mar 14 09:48:56 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Mon, 14 Mar 2005 09:48:56 +0100
Subject: [R] CDISC tools for R?
Message-ID: <1abe3fa9050314004852424838@mail.gmail.com>

Has anyone hacked up tools for reading/writing CDISC applications
(ADaM, SEND,  SDTM, ODM) files or using/verifying vocabulary with R? 
(i.e. via the XML, ontoTools, and similar packages)?

(I'd be interested in hearing privately from any consultants/vendors
who have been working on this as well; S-PLUS would be a
related/relevant target).

best,
-tony

"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).

A.J. Rossini
blindglobe at gmail.com



From aragon at berkeley.edu  Tue Mar 15 02:08:23 2005
From: aragon at berkeley.edu (Tomas Aragon)
Date: Mon, 14 Mar 2005 17:08:23 -0800 (PST)
Subject: [R] Output a dataframe from R to excel
In-Reply-To: 6667
Message-ID: <20050315010823.14015.qmail@web80108.mail.yahoo.com>


--- Faith G <gaof at u.washington.edu> wrote:
> Hi, 
> I am trying to output an dataframe from R to Excel file. Can anyone
> tell me how to do it? Thanks a lot.
> Eg. 
> R dataframe:
> A    B    C    
> 1    2    1
> 3    4    2
> .    .    .    
> 

Try:
write.table(mydf, "c:/mydf.csv", sep=",", row.names=FALSE)

Then open 'mydf.csv' in Excel.

Tomas
http://www.epitools.net



From christianmacaro at gmail.com  Mon Mar 14 19:21:05 2005
From: christianmacaro at gmail.com (Christian)
Date: Mon, 14 Mar 2005 19:21:05 +0100
Subject: [R] Mandrake 10.1
Message-ID: <4235D611.80201@uniroma2.it>

Dear all,

I am trying to install the R-2.0.0-1mdk.i586.rpm 
<http://cran.planetmirror.com/bin/linux/mandrake/10.0/R-2.0.0-1mdk.i586.rpm> 
file   on mandrake 10.1. Since the file is, originally, meant for 
Mandrake 10.0, it is not surprising me that the installation does not work.

The error message that I get can be translated in something like: 
"impossible to install since the info is not satisfied".
Could you please help me in installing R on my Mandrake 10.1?

PS If you feel to answer me,  consider that I am almost an absolute 
beginner at linux:)

Thanks a lot

Christian



From MSchwartz at MedAnalytics.com  Tue Mar 15 03:34:58 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Mon, 14 Mar 2005 20:34:58 -0600
Subject: [R] Legend Line Size
In-Reply-To: <67DCA285A2D7754280D3B8E88EB548020C946551@MSGBOSCLB2WIN.DMN1.FMR.COM>
References: <67DCA285A2D7754280D3B8E88EB548020C946551@MSGBOSCLB2WIN.DMN1.FMR.COM>
Message-ID: <1110854098.11107.30.camel@horizons.localdomain>

On Mon, 2005-03-14 at 15:55 -0500, McGehee, Robert wrote:
> Hello all,
> 
> When I view or print the below plot on my Linux machine under R 2.0.1 I
> see a nice thick solid and dashed line with a legend. However, while the
> lines are distinguishable, the legend is not. That is, the short (solid)
> line next to "line1" and the short (dashed) line next to "line2" seem to
> have the exact same length. What I would like to do is to expand the
> legend line a bit farther so that the user can clearly see a solid vs. a
> dashed line and not too small lines that look the same.
> 
> A glance at the legend source code shows that the line segment length
> (seg.len) seems to be hard-coded as 2. If I change this to a larger
> number within the code, I get the effect that I want (although the box
> around the legend needs to be resized). Am I overlooking a more obvious
> way to distinguish the legend lines, or would it make more sense to
> patch the legend function to fit my needs?
> 
> x <- 1:10
> plot(x, x, type = "l", lty = 1, lwd = 4)
> lines(x, 2*x, type = "l", lty = 5, lwd = 4)
> legend(7, 5, legend = c("line1", "line2"), lty = c(1, 5), lwd = 4)

Robert,

I think that this is exhibiting an interaction between the line type and
the line width. 

I have not looked at the low level segments code to see what is going
on, but if you try 'lwd = 2' in the call to legend, the dashed line
shows up fine. If I try a line width of 3, it seems that this is the
point where there is the loss of the dashed line type.

There is a difference in the appearance of the line even with a lwd
setting of 1 versus 2.

I temporarily put up a PDF file at:

http://www.MedAnalytics.com/Rplots.pdf

The lwd setting in each plot is:

1, 2
3, 4

You can see the progression of the loss of the dashed line type in the
lower two plots. It appears as if the length of the first dash increases
as the line width increases, rather than just the line width increasing
independently. So there is a progressive loss of the second dash.
resulting in a single solid line.

Not sure if that helps, but if you can stay with 'lwd = 1' for your
plot, that should solve the problem.

HTH,

Marc Schwartz



From mcclatchie.sam at saugov.sa.gov.au  Tue Mar 15 05:14:45 2005
From: mcclatchie.sam at saugov.sa.gov.au (McClatchie, Sam (PIRSA-SARDI))
Date: Tue, 15 Mar 2005 14:44:45 +1030
Subject: [R] trellis/ panel.superpose/ passing in superscripts/ groups
Message-ID: <032A8573186A2B4EBBAEFA5784D0523506E10D0C@sagemsg0007.sagemsmrd01.sa.gov.au>

Background:
OS: Linux Mandrake 10.1
release: R 2.0.0
editor: GNU Emacs 21.3.2
front-end: ESS 5.2.3
---------------------------------

Colleagues

I'm plotting fish egg densities in temperature-salinity space (i.e. mean
temperature ~ mean salinity | fish egg densities) for two survey years.  The
bivariate plot is overlaid on a temperature ~ salinity plot (not means)
showing the distribution of water masses, so I can see the association of
the eggs with water masses.

It is all working, but I have had to replace a call to panel.superpose with
panel.xyplot to plot the two years with different symbols. The problem may
be related to one raised by Volker Franz
<http://maths.newcastle.edu.au/~rking/R/devel/02b/0993.html> that was
reported to be fixed. On the other hand, I may just be using panel.superpose
incorrectly. You can see that I've messed around with the groups variable to
try and get it working.

My code is as follows.

"sardine.egg.T.S.space.2001.and.2002.exp" <-
  function()
  {
    library(lattice)
                                        # trellis.device(postscript,
                                        #
file="../figures/sardine.egg.T.S.space.2001.and.2002.ps",
                                        #                horizontal=FALSE,
color=TRUE)
    
    year <- as.factor(rep(2001,  dim(mn.ts.e.2001)[1]))    
    year.2001 <- cbind(mn.ts.e.2001,year)
    year <- as.factor(rep(2002,  dim(mn.ts.e.2002)[1]))    
    year.2002 <- cbind(mn.ts.e.2002,year)    
    mn.ts.e.both <- rbind(year.2001, year.2002)
                                        #browser()
###trellis plot
    ##int <- matrix(c(0,5,6,10,11,20,21,40,41,80,81,160), ncol=2,
byrow=TRUE)
    int <- matrix(c(0,2,3,4,5,8,9,16,17,32,33,64), ncol=2, byrow=TRUE)
    egg.counts <- shingle(mn.ts.e.both$eggs2.Pilch.Eggs, intervals = int)
    larvae.counts <- shingle(mn.ts.e.both$eggs2.Pilch.Larv, intervals = int)
    
    out1 <- xyplot(mn.t ~  mn.s |  egg.counts,
                   data = mn.ts.e.both,
                                        #groups = year,
                   xlim = c(35,38), ylim = c(12,24),
                   xlab = "mean salinity", ylab = "mean temperature (deg.
C)",
                   main = "2001 and 2002 egg densities in
Temperature-Salinity space",
                   aspect = "xy",
                   jitter = T,
                   layout = c(1,6),
                   auto.key=TRUE,
                   panel = function(x, y, subscripts = c(2,3)){
                     panel.xyplot(data.2001$Salinity,
data.2001$Temperature.oC, 
                                  pch=".", col="yellow")
                     panel.xyplot(data.2002$Salinity,
data.2002$Temperature.oC, 
                                  pch=".", col="orange")
                     panel.text(37.8, 15, "Upwelling")
                     panel.text(37.8, 17.5, "Warm pool")
                     panel.text(37.8, 19.75, "Shelf break")
                     panel.text(37.8, 21.5, "Spencer Gulf")
                     panel.abline(h = c(16,19,20.5), v = 36.5, col="red",
lty=2)
                                          
                    
                     ##  panel.superpose(x,y,
                     ##                  subscripts=c(2,3),
                     ##                  groups = mn.ts.e.both$year,
                     ##                  cex=0.5)
                     ##auto.key = T
                     panel.xyplot(year.2001$mn.s,  year.2001$mn.t,
                                  col="cyan")
                     panel.xyplot(year.2002$mn.s,  year.2002$mn.t,
                                  col="purple")
                     
                   }
                   )

    print(out1)
                                        #   graphics.off()
    
  }


Any suggestions regarding how to get panel.superpose working would be
gratefully received. Sorry I cannot provide the data so the code is easily
used. Data are a bit large to paste into an email.

Sam
----
Sam McClatchie,
Biological oceanography 
South Australian Aquatic Sciences Centre
PO Box 120, Henley Beach 5022
Adelaide, South Australia
email <mcclatchie.sam at saugov.sa.gov.au>
Telephone: (61-8) 8207 5448
FAX: (61-8) 8200 2481
Research home page <http://www.members.iinet.net.au/~s.mcclatchie/>
  
                   /\
      ...>><xX(?> 
                //// \\\\
                   <?)Xx><<
              /////  \\\\\\
                        ><(((?> 
  >><(((?>   ...>><xX(?>O<?)Xx><<



From twiens at interbaun.com  Tue Mar 15 05:29:05 2005
From: twiens at interbaun.com (Trevor Wiens)
Date: Mon, 14 Mar 2005 21:29:05 -0700
Subject: [R] cv.glm {boot}
Message-ID: <20050314212905.078747e6.twiens@interbaun.com>

I am try to cross validate some logistic regressions. cv.glm allows me to do this randomly but since I have data over a number of years and over a number of distince areas, I would like to cross-validate temporarly and spatially. I've already attached the temporal and spatial attributes to my data, but I'm unsure as to how to achieve this, as it seems I can't use cv.glm for this purpose.

Thanks in advance.

T
-- 
Trevor Wiens 
twiens at interbaun.com

The significant problems that we face cannot be solved at the same 
level of thinking we were at when we created them. 
(Albert Einstein)



From ripley at stats.ox.ac.uk  Tue Mar 15 08:05:49 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 15 Mar 2005 07:05:49 +0000 (GMT)
Subject: [R] cv.glm {boot}
In-Reply-To: <20050314212905.078747e6.twiens@interbaun.com>
References: <20050314212905.078747e6.twiens@interbaun.com>
Message-ID: <Pine.LNX.4.61.0503150702160.12742@gannet.stats>

On Mon, 14 Mar 2005, Trevor Wiens wrote:

> I am try to cross validate some logistic regressions. cv.glm allows me 
> to do this randomly but since I have data over a number of years and 
> over a number of distince areas, I would like to cross-validate 
> temporarly and spatially. I've already attached the temporal and spatial 
> attributes to my data, but I'm unsure as to how to achieve this, as it 
> seems I can't use cv.glm for this purpose.

Cross-validation assumes exchangeability of units.  You can easily write 
your own code (lots of examples in MASS), but first you would need to 
prove the validity of what you are attempting.  For example, dropping 
chunks in the middle of a time series is not valid unless your prediction 
somehow takes the temporal structure into account (and glm does not).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Mar 15 08:16:07 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 15 Mar 2005 07:16:07 +0000 (GMT)
Subject: [R] Install the RMySQL 
In-Reply-To: <5662d229.dd1719e0.899a800@expms3.cites.uiuc.edu>
References: <5662d229.dd1719e0.899a800@expms3.cites.uiuc.edu>
Message-ID: <Pine.LNX.4.61.0503150707300.12742@gannet.stats>

On Mon, 14 Mar 2005, Ko,Younhee wrote:

> Hi, I have some problem to install RMySQL package.
> Could you help me?

Please tell us your OS, R version, etc.

> I set up the path.

You set a couple of variables, but no path.  (These at most supplement the 
include and library paths.)

> [root at ep2 library]# export PKG_CPPFLAGS="-I/var/lib/mysql"
> [root at ep2 library]# export PKG_LIBS="-L/var/lib/mysql -
> lmysqlclient"

Looks like your MySQL files are not where you claim they: I would not 
expect them to be there (headers are not normally in a 'lib' directory), 
but where they are depends on whether this is an installation from the 
sources (not likely if it uses /var/lib), RPM etc.  E.g. FC3 has

checking for mysql_init in -lmysqlclient... yes
              mysqlclient found in -L/usr/lib/mysql
checking for /usr/local/include/mysql/mysql.h... no
checking for /usr/include/mysql/mysql.h... yes

Note to David James as maintainer: should not finding these be an error, 
or at least give a very loud warning from configure?


> [root at ep2 library]# R CMD INSTALL /home/younko/RMySQL_0.5-
> 5.tar.gz
>
>
> I got this bunch of error message.
>
>
>
> Please help me.
>
>
> * Installing *source* package 'RMySQL' ...
> creating cache ./config.cache
> checking how to run the C preprocessor... cc -E
> checking for compress in -lz... yes
> checking for getopt_long in -lc... yes
> checking for mysql_init in -lmysqlclient... no
> checking for mysql.h... no
> updating cache ./config.cache
> creating ./config.status
> creating src/Makevars
> ** libs
> gcc -I/usr/local/lib/R/include -I/var/lib/mysql -
> I/usr/local/include   -fPIC  -g -O2 -c RS-DBI.c -o RS-DBI.o
> gcc -I/usr/local/lib/R/include -I/var/lib/mysql -
> I/usr/local/include   -fPIC  -g -O2 -c RS-MySQL.c -o RS-
> MySQL.o
> In file included from RS-MySQL.c:22:
> RS-MySQL.h:40:19: mysql.h: No such file or directory
> RS-MySQL.h:41:27: mysql_version.h: No such file or directory
> RS-MySQL.h:42:23: mysql_com.h: No such file or directory

That's sufficient info.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Tue Mar 15 08:26:46 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 15 Mar 2005 08:26:46 +0100
Subject: [R] bayesmix - What is or where can I find JAGS executable?
In-Reply-To: <20050314193128.48645.qmail@web26502.mail.ukl.yahoo.com>
References: <20050314193128.48645.qmail@web26502.mail.ukl.yahoo.com>
Message-ID: <42368E36.7040602@statistik.uni-dortmund.de>

Karl Knoblick wrote:

> Sorry about the further question:
> 
> I downloaded bayesmix_0.5-3.zip (see below) - but
> there is no jags.exe (even no *.exe) included.
> 
> Adress:
> http://www.ci.tuwien.ac.at/~gruen/BayesMix/
> Downloaded:
> "Windows binaries including JAGS executable:
> bayesmix_0.5-3.zip"


I asked you in a former mail to ask Martyn for his new page location. 
Also, you could ask Martina Gruen to fix the issue with either bayesmix 
or her page cited above (including the link to JAGS). I don't see any 
reason this message was sent to R-help.

Uwe Ligges


> Karl
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From jjonphl at gmail.com  Tue Mar 15 08:46:20 2005
From: jjonphl at gmail.com (miguel manese)
Date: Tue, 15 Mar 2005 15:46:20 +0800
Subject: [R] Mandrake 10.1
In-Reply-To: <4235D611.80201@uniroma2.it>
References: <4235D611.80201@uniroma2.it>
Message-ID: <d35b9da60503142346134a9229@mail.gmail.com>

IIRC I also installed that rpm months ago. I got a problem about
failed depndency on libf2c something, which was satisfied by this
package (search & download it somewhere, or mail me personally so I
can send it to you) libf2c0-3.4.1-4mdk.i586.rpm

jon


On Mon, 14 Mar 2005 19:21:05 +0100, Christian <christianmacaro at gmail.com> wrote:
> Dear all,
> 
> I am trying to install the R-2.0.0-1mdk.i586.rpm
> <http://cran.planetmirror.com/bin/linux/mandrake/10.0/R-2.0.0-1mdk.i586.rpm >
> file   on mandrake 10.1. Since the file is, originally, meant for
> Mandrake 10.0, it is not surprising me that the installation does not work.
> 
> The error message that I get can be translated in something like:
> "impossible to install since the info is not satisfied".
> Could you please help me in installing R on my Mandrake 10.1?
> 
> PS If you feel to answer me,  consider that I am almost an absolute
> beginner at linux:)
> 
> Thanks a lot
> 
> Christian
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html 
>



From maechler at stat.math.ethz.ch  Tue Mar 15 09:51:31 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 15 Mar 2005 09:51:31 +0100
Subject: [R] Re: Installing R on Mandrake 10.1
In-Reply-To: <4235D611.80201@uniroma2.it>
References: <4235D611.80201@uniroma2.it>
Message-ID: <16950.41491.249522.890367@stat.math.ethz.ch>

>>>>> "Christian" == Christian  <christianmacaro at gmail.com>
>>>>>     on Mon, 14 Mar 2005 19:21:05 +0100 writes:

    Christian> Dear all, I am trying to install the
    Christian> R-2.0.0-1mdk.i586.rpm
    Christian> <http://cran.planetmirror.com/bin/linux/mandrake/10.0/R-2.0.0-1mdk.i586.rpm>
    Christian> file on mandrake 10.1. 
.....

Hi Christian, 
I'm not really answering your question, 
but really you shouldn't install R 2.0.0 once R 2.0.1 has been
released for such a long time and already R 2.1.0 is going into
"alpha" stage next Monday.

Why don't you try to install from source?
I've been advocating this as a test of ``having a decently
complete Linux/Unix system'', i.e.,
in order to build R from the sources (without too many warnings
about missing features) you will have to get quite a few useful
things (gcc, g77, perl, latex, texinfo, ..) that you want `anyway'.
One of the five R manuals is called
"R Administration / Installation" -- this should help you to
become successful.  Once you've installed R 2.0.1 from the
sources, you will be ready to try "R 2.1.0 alpha" -- which will
be a service to the R user community, if you help testing out
R 2.0.1 *before* its release.

BTW, you seem to be from Roma, Italy. You might be delighted to
see that R 2.1.0 will speak Italian in some ways.

Martin Maechler, ETH Zurich



From tjrc at sanger.ac.uk  Tue Mar 15 10:12:25 2005
From: tjrc at sanger.ac.uk (Tim Cutts)
Date: Tue, 15 Mar 2005 09:12:25 +0000
Subject: [R] R: install - Perl dependency problem in Debian/Damn Small
	Linux
In-Reply-To: <004601c52893$dbf83eb0$f2e1f380@OPENZAURUS>
References: <42284169.6608D6F9@STATS.uct.ac.za>
	<16936.21113.570637.506601@stat.math.ethz.ch>
	<004601c52893$dbf83eb0$f2e1f380@OPENZAURUS>
Message-ID: <e55506704b29625e4b06650af9e85e10@sanger.ac.uk>


On 14 Mar 2005, at 12:46 pm, Stuart Leask wrote:

> (I vaguely recall a suggestion there be a r-debian list, which this 
> would be
> appropriate for, but I can't find such a list if it exists. Apologies)
>
> OS: Damn Small Linux 1.0rc1 - a tiny (50MB) debian/knoppix-based distro
>
> I can't apt-get R.
>
> root at ttyp0[dsl]# apt-get  install -testing r-base r-base-core 
> r-recommended
> Reading Package Lists... Done
> Building Dependency Tree... Done
> Some packages could not be installed. This may mean that you have
> requested an impossible situation or if you are using the unstable
> distribution that some required packages have not yet been created
> or been moved out of Incoming.
> The following information may help to resolve the situation:
>
> The following packages have unmet dependencies:
>   r-base-core: Depends: perl but it is not going to be installed
> E: Broken packages
>
> PROBLEM 1: Perl is certainly installed. However, it may have various 
> bits
> removed to save space.
>
> However, if I try to correct this with:
>
> apt-get install perl
>
> I get:
>
> The following packages have unmet dependencies:
>   perl: depends perl-base (=5.6.1-8.7) but 5.8.0-18 is to be installed
> E: broken packages
>
> I've tried different feeds eg. -testing, but get the same problem.
>
> Has anyone come across this, or have any ideas?

It's the perl upgrade that's the problem, obviously.  Is there any 
particular reason why you're using this tiny distribution rather than 
just using plain, normal Debian?

Trying to upgrade this with full Debian packages sounds like asking for 
a world of pain, especially since the package versions in testing, in 
particular, are way ahead of what your existing system is using.  It's 
a bit like trying to install Fedora packages on a Red Hat 7.2 box; i.e. 
pretty unlikely to work.

You might do better to actually compile R from scratch on your system, 
rather than installing the binary packages.

Tim

-- 
Dr Tim Cutts
Informatics Systems Group, Wellcome Trust Sanger Institute
GPG: 1024D/E3134233 FE3D 6C73 BBD6 726A A3F5  860B 3CDD 3F56 E313 4233



From petr.pikal at precheza.cz  Tue Mar 15 11:50:37 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 15 Mar 2005 11:50:37 +0100
Subject: [R] Output a dataframe from R to excel
In-Reply-To: <000601c52802$a5620fc0$0425ad80@FaithGao>
Message-ID: <4236CC0D.20158.C9874F@localhost>

E.g.

write.excel <- function(tab, ...) write.table( tab, "clipboard", 
sep="\t", row.names=F)

write.excel(your.data.frame)

and pressing Ctrl-V in Excel copies your.data.frame to Excel

Cheers
Petr

On 13 Mar 2005 at 14:26, Faith G wrote:

> Hi, 
> I am trying to output an dataframe from R to Excel file. Can anyone
> tell me how to do it? Thanks a lot. Eg. R dataframe: A    B    C    1 
>   2    1 3    4    2 .    .    .    
> 
>  [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From pensterfuzzer at yahoo.de  Tue Mar 15 12:00:41 2005
From: pensterfuzzer at yahoo.de (Werner Wernersen)
Date: Tue, 15 Mar 2005 12:00:41 +0100 (CET)
Subject: [R] Exploratory data analysis on several samples of same population
	and of different populations
Message-ID: <20050315110041.19425.qmail@web25806.mail.ukl.yahoo.com>

Hi!

Excuse my ignorance but are there commands / packages
for exploratory data 
analysis on

1) several samples of the same population
2) several samples from different populations

which examine the differences, dependencies etc. via
statistical summaries, 
graphs and tests, all with one command?

My particular data is ordinal and non-parametrics are
required.

I know, I could write it myself but I don't want to
reinvent the wheel...

Thanks in advance for your considerations!

   Werner



From xiyanlon at gmail.com  Tue Mar 15 13:11:57 2005
From: xiyanlon at gmail.com (Xiyan Lon)
Date: Tue, 15 Mar 2005 13:11:57 +0100
Subject: [R] Packages for multi-class classification with boosting
Message-ID: <9a38bfc705031504111c6285b5@mail.gmail.com>

Are there any packages to handle multi-class classification with boosting.
I know adaboost function include in package "boost" but that is only
for two-class.
Thanks for your help.

Xiyan Lon



From patrab at gmail.com  Tue Mar 15 13:41:34 2005
From: patrab at gmail.com (Patralekha Bhattacharya)
Date: Tue, 15 Mar 2005 07:41:34 -0500
Subject: [R] need help with plot.rpart and text.rpart
Message-ID: <eddf5a810503150441358751f0@mail.gmail.com>

Hi,
   I am new to R and need help with rpart. I am trying to create a
classification tree using rpart. In order to plot the reults I use the
plot function and the text function to label the plot of the tree
dendrogram with text. The documentation of text.rpart says : "For the
"class" method, label="yval" results in the factor levels being used,
"yprob" results in the probability of the winning factor level being
used, and 'specific yval level' results in the probability of that
factor level" .  However, neither the label="yprob" option nor the
label='specific yval level'  option works for me. I have copied a
section of my code in order to include the error message.

> plot(fit)
> text(fit, label="yprob")
Error in text.rpart(fit, label = "yprob") : 
        Label must be a column label of the frame component of the tree

On inspecting fit$frame I noticed that neither "yprob" nor 'specific
yval level'  are included in the frame. I therefore even tried to
create these variable in the frame by using the following

fit$frame <- transform(fit$frame, newVar=fit$frame$yval2[,4])

where fit$frame$yval2[,4] are the probabilities of the winning factor level.

However, using this I just get the values of "yval" as the labels
which I could have got anyway by setting the option label="yval".

I would really appreciate any help on this.
Thanks in advance.

Pat



From liuqincn at yahoo.com  Tue Mar 15 13:59:18 2005
From: liuqincn at yahoo.com (liu qin)
Date: Tue, 15 Mar 2005 04:59:18 -0800 (PST)
Subject: [R] KNN one factor predicting problem 
Message-ID: <20050315125918.73492.qmail@web31501.mail.mud.yahoo.com>

Could anybody help me out please?

> cl<-as.factor(traindata[,13])
> knn(traindata[1:295,2], newdata[1:32,2], cl,k=2,
prob=TRUE) 
Error in knn(traindata[1:295, 2], newdata[1:32, 2],
cl, k = m, prob = TRUE) : 
        Dims of test and train differ

Both traindata and newdata have 13 elements. Only one
of the first 12 elemnets is needed to predict the 13
element.
What's the problem of following commands?

Thank you very much indeed

Qin



From andy_liaw at merck.com  Tue Mar 15 14:05:36 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 15 Mar 2005 08:05:36 -0500
Subject: [R] KNN one factor predicting problem
Message-ID: <3A822319EB35174CA3714066D590DCD50994E851@usrymx25.merck.com>

> From: liu qin
> 
> Could anybody help me out please?
> 
> > cl<-as.factor(traindata[,13])
> > knn(traindata[1:295,2], newdata[1:32,2], cl,k=2,
> prob=TRUE) 
> Error in knn(traindata[1:295, 2], newdata[1:32, 2],
> cl, k = m, prob = TRUE) : 
>         Dims of test and train differ
> 
> Both traindata and newdata have 13 elements. Only one
> of the first 12 elemnets is needed to predict the 13
> element.
> What's the problem of following commands?

`traindata[1:295, 2]' says to use the first 295 rows of the second column of
traindata, and likewise you specified the first 32 rows of the second column
of newdata as the second argument.  What do you mean by 12 elements?

Andy

 
> Thank you very much indeed
> 
> Qin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From bates at stat.wisc.edu  Tue Mar 15 14:40:30 2005
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 15 Mar 2005 07:40:30 -0600
Subject: [R] R: install - Perl dependency problem in Debian/Damn Small
	Linux
In-Reply-To: <e55506704b29625e4b06650af9e85e10@sanger.ac.uk>
References: <42284169.6608D6F9@STATS.uct.ac.za>	<16936.21113.570637.506601@stat.math.ethz.ch>	<004601c52893$dbf83eb0$f2e1f380@OPENZAURUS>
	<e55506704b29625e4b06650af9e85e10@sanger.ac.uk>
Message-ID: <4236E5CE.3080408@stat.wisc.edu>

Tim Cutts wrote:
> 
> On 14 Mar 2005, at 12:46 pm, Stuart Leask wrote:
> 
>> (I vaguely recall a suggestion there be a r-debian list, which this 
>> would be
>> appropriate for, but I can't find such a list if it exists. Apologies)

The Debian-specific list is called r-sig-debian at r-project.org and the 
info page is https://stat.ethz.ch/mailman/listinfo/r-sig-debian



From linekris at stud.ntnu.no  Tue Mar 15 14:42:29 2005
From: linekris at stud.ntnu.no (line)
Date: Tue, 15 Mar 2005 14:42:29 +0100
Subject: [R] predict.glm and continous variables
Message-ID: <4236E645.6070802@stud.ntnu.no>

Hello.

I am using the predict function to transform logit values from a glm to 
probabilities, (predict(model,type="response",se=T))..
 Everything is going very well for the categorical variables where I get 
one value for the slope of each level and one value for standard error 
for each level.
The problem occurs when I whant to do the same for my continous 
variables. Instead of getting one value for the slope and and one value 
of SE for each variable (like what pops up in the summary in a 
univariate glm) I get a slope and SE value for every datapoint in the 
variable.

I hope someone knows the solution to my problem.

Regards,

Line.



From br44114 at yahoo.com  Tue Mar 15 14:49:05 2005
From: br44114 at yahoo.com (bogdan romocea)
Date: Tue, 15 Mar 2005 05:49:05 -0800 (PST)
Subject: [R] Mandrake 10.1
Message-ID: <20050315134905.13800.qmail@web50110.mail.yahoo.com>

I managed to install R 2.0.1 on Mandrake 10.1 a couple of weeks ago. It
wasn't that easy, first I had to manually track, download and install
3-4 dependencies.

I would suggest that you consider another GNU/Linux distribution,
Mepis. Mepis combines the best features of several distributions:
	- You can run it from CD, like Knoppix/Quantian.
	- If you like it, you can easily install it on your hard drive (unlike
Knoppix/Quantian). Just double click an icon and a graphical wizard
will guide you through the installation steps. It's as easy to install
as Mandrake, perhaps a bit easier (automatic hardware detection and
configuration etc).
	- Package management is done automatically (no more annoying
notifications from Mdk's urpmi - like sorry, can't do this, go ahead
and figure it out by yourself). You can use Synaptic or apt-get, and
you can install packages from the Debian testing and unstable
repositories (which is great). Unlike Debian though, Mepis is much
easier to install (imho).

As someone who went through several failed installation attempts
(Gentoo, Debian, Quantian), primarily due to hardware issues which I
didn't have the patience to try to fix, I appreciate a lot what Mepis
has to offer. You can have a complete system (R + packages etc) up and
running in 30 minutes starting from scratch (assuming you have
broadband) -- which is about what it would take you to fix the
dependencies for just one binary (such as R-2.0.0-1mdk.i586.rpm) on
Mandrake.

hth,
b.


-----Original Message-----
From: Christian [mailto:christianmacaro at gmail.com]
Sent: Monday, March 14, 2005 1:21 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Mandrake 10.1


Dear all,

I am trying to install the R-2.0.0-1mdk.i586.rpm 
<http://cran.planetmirror.com/bin/linux/mandrake/10.0/R-2.0.0-1mdk.i586.rpm>

file   on mandrake 10.1. Since the file is, originally, meant for 
Mandrake 10.0, it is not surprising me that the installation does not
work.

The error message that I get can be translated in something like: 
"impossible to install since the info is not satisfied".
Could you please help me in installing R on my Mandrake 10.1?

PS If you feel to answer me,  consider that I am almost an absolute 
beginner at linux:)

Thanks a lot

Christian

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From dimitris.rizopoulos at med.kuleuven.ac.be  Tue Mar 15 14:47:23 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Tue, 15 Mar 2005 14:47:23 +0100
Subject: [R] [R-pkgs] New package for latent trait models
Message-ID: <002a01c52965$846b7e00$0540210a@www.domain>

Dear R-users,

I'd like to announce the release of my new package "ltm" (available 
from CRAN), for fitting Latent Trait Models (including the Rasch 
model) under the Item Response Theory approach. The latent trait model 
is the analogous of the factor analysis model for Bernoulli response 
data. "ltm" fits the linear one- and two-factor models but also allows 
for inclusion of nonlinear latent terms (e.g., interaction and 
quadratic). Any kind of feedback (questions, suggestions, bug-reports, 
etc.) is more than welcome.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From depire at inrets.fr  Tue Mar 15 16:13:12 2005
From: depire at inrets.fr (Depire Alexandre)
Date: Tue, 15 Mar 2005 16:13:12 +0100
Subject: [R] gR - installation and computation
Message-ID: <200503151613.12583.depire@inrets.fr>

Hello everyone,
I would like to use R to compute some special hidden markov chain. I see that 
such those models are like dynamic bayesion network.
So, I find some doc about computation of those models in R, but I don't know 
how to install it on R and how to use it.
These doc talks about gR project.

-- 
----------------
Alexandre DEPIRE
INRETS / GARIG



From spjgmwn at iop.kcl.ac.uk  Tue Mar 15 16:19:26 2005
From: spjgmwn at iop.kcl.ac.uk (Matthew W Nash)
Date: Tue, 15 Mar 2005 15:19:26 -0000
Subject: [R] RODBC, sqlSave and sqlAppend
Message-ID: <NDEAJMAPIIPDKHDMLLLOMEKDDAAA.spjgmwn@iop.kcl.ac.uk>

Hi all,

I am currently trying to read, write and append data between R and MS access
using the RODBC library functions. I have no problems reading in the data
but when using sqlSave and sqlAppend it doesn't seem to work. I have made
sure that all the column names are sensible and there are no gaps etc in the
variables. My call looks like this:

sqlSave(channel,treatlist,test=F)

I've played with various options but what consistently happens is that R
writes a new table (column names a written and sensible variable types are
assigned), but it doesn't actually write any data into it. When I run
sqlAppend there are no error messages, but when I look at the MS access
database nothing has been written. (I always have the database closed when
doing this.)

What am I doing wrong?

Matthew Nash,

Post-Doctoral Research Worker,
GENDEP study,
SGDP, Institute of Psychiatry,
PO82, Room CB.15,
16 De Crespigny Park,
London, SE5 8AF,
United Kingdom

Phone: (+44) 207 848 0805

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~
Announcing the 6th MRC SGDP SUMMER SCHOOL 25 -? 29 July 2005 with courses in
a) Twin model fitting, Mx
b) Microarrays (Affymetrix), gene expression, SNPs
c) Linkage, association and allied methods
http://sgdp.iop.kcl.ac.uk/summerschool/



From Rau at demogr.mpg.de  Tue Mar 15 16:41:39 2005
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Tue, 15 Mar 2005 16:41:39 +0100
Subject: [R] Mandrake 10.1
Message-ID: <8B08A3A1EA7AAC41BE24C750338754E6520016@HERMES.demogr.mpg.de>

Hi, 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of bogdan romocea
> Sent: Tuesday, March 15, 2005 2:49 PM
> 
> I would suggest that you consider another GNU/Linux distribution,

I don't think it is necessary. Mandrake 10.1 is fine for running R.[1] I
have Mandrake 10.1 (Community) at home running on my notebook and I was
able to compile R without any problems - just using the software that
was shipped with this distribution.
Maybe you follow the advice of Martin Maechler and try to compile it
yourself? This is (usually) less complicated than it might sound
initially. R was the first thing I compiled myself when I started using
GNU/Linux - and I was surprised how easy it was.

Best,
Roland

[1] I don't want to start a flamewar claiming which distro is better
than the other.


+++++
This mail has been sent through the MPI for Demographic Rese...{{dropped}}



From Simon.Bond at mrc-bsu.cam.ac.uk  Tue Mar 15 16:51:19 2005
From: Simon.Bond at mrc-bsu.cam.ac.uk (Simon.Bond)
Date: Tue, 15 Mar 2005 15:51:19 +0000 (GMT)
Subject: [R] font sizes
Message-ID: <Pine.GSO.4.58.0503151546510.29273@bononcini>

I'm trying to use the pdf() function, and would like to increase the font
size for slide-presentation  purposes. Changing the
argument `pointsize' doesn't seem to do anything.

Anyone come across this or know what to do?

thanks

Simon Bond.

-------------------------------------------------------------------------
    /"\
    \ /    ASCII RIBBON CAMPAIGN - AGAINST HTML MAIL
     X                           - AGAINST MS ATTACHMENTS
    / \

http://www.gnu.org/philosophy/no-word-attachments.html



From twiens at interbaun.com  Tue Mar 15 16:59:36 2005
From: twiens at interbaun.com (Trevor Wiens)
Date: Tue, 15 Mar 2005 08:59:36 -0700
Subject: [R] cv.glm {boot}
In-Reply-To: <Pine.LNX.4.61.0503150702160.12742@gannet.stats>
References: <20050314212905.078747e6.twiens@interbaun.com>
	<Pine.LNX.4.61.0503150702160.12742@gannet.stats>
Message-ID: <20050315085936.4cd7e38e.twiens@interbaun.com>

On Tue, 15 Mar 2005 07:05:49 +0000 (GMT)
Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> 
> Cross-validation assumes exchangeability of units.  You can easily write 
> your own code (lots of examples in MASS), but first you would need to 
> prove the validity of what you are attempting.  For example, dropping 
> chunks in the middle of a time series is not valid unless your prediction 
> somehow takes the temporal structure into account (and glm does not).
> 

Yes, I'm aware of that and I do have a number of predictors which vary with time (from year to year such as precipitation or properly timed vegetation indices from each year....) so that isn't my problem. Also my spatial blocking is also valid (distinct partitions of the study area). I'm also aware of the problems of spatial autocorrelation and have taken some measures to deal with that. I am however rather new at R and not a statistician, so I am heavily reliant on books such as Hosmer and Lemeshow or Manley(Resource selection by Animals) on procedure. Unforunately, they are not S-plus or R oriented so I have some difficulty translating those ideas to R.

You mention lots of examples in MASS regarding cross-validation, but I can't find them. Perhaps I'm looking in the wrong spot. I've done help.search('validation'), .... and found nothing that seemed obviously applicable to my problem. I suppose I should pick up a copy of your books which would probably be very helpful. However, if it isn't too much trouble. I would really appreciate a bit more direct help. 

This is what I assumed I would do somethink like this (in this example basp = Baird's Sparrow presence or absence)

train <- birddata[birddata$recordyear != 2000]
test <- birddata[birddata$recordyear == 2000]
train.glm <- glm(basp ~ elev + slope + precip + precip_1 ..., data=birddata, family=binomial)
pred <- predict(train.glm, newdata=test, type='response')
actual <- test$basp
what happens next??

Thanks in advance.

T
-- 
Trevor Wiens 
twiens at interbaun.com

The significant problems that we face cannot be solved at the same 
level of thinking we were at when we created them. 
(Albert Einstein)



From andy_liaw at merck.com  Tue Mar 15 17:08:05 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 15 Mar 2005 11:08:05 -0500
Subject: [R] cv.glm {boot}
Message-ID: <3A822319EB35174CA3714066D590DCD50994E859@usrymx25.merck.com>

> From: Trevor Wiens
> 
> On Tue, 15 Mar 2005 07:05:49 +0000 (GMT)
> Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> 
> > 
> > Cross-validation assumes exchangeability of units.  You can 
> easily write 
> > your own code (lots of examples in MASS), but first you 
> would need to 
> > prove the validity of what you are attempting.  For 
> example, dropping 
> > chunks in the middle of a time series is not valid unless 
> your prediction 
> > somehow takes the temporal structure into account (and glm 
> does not).
> > 
> 
> Yes, I'm aware of that and I do have a number of predictors 
> which vary with time (from year to year such as precipitation 
> or properly timed vegetation indices from each year....) so 
> that isn't my problem. Also my spatial blocking is also valid 
> (distinct partitions of the study area). I'm also aware of 
> the problems of spatial autocorrelation and have taken some 
> measures to deal with that. I am however rather new at R and 
> not a statistician, so I am heavily reliant on books such as 
> Hosmer and Lemeshow or Manley(Resource selection by Animals) 
> on procedure. Unforunately, they are not S-plus or R oriented 
> so I have some difficulty translating those ideas to R.
> 
> You mention lots of examples in MASS regarding 
> cross-validation, but I can't find them. Perhaps I'm looking 
> in the wrong spot. I've done help.search('validation'), .... 
> and found nothing that seemed obviously applicable to my 
> problem. I suppose I should pick up a copy of your books 
> which would probably be very helpful. However, if it isn't 
> too much trouble. I would really appreciate a bit more direct help. 

`MASS' _is_ a book, the supporting software of which contains a `scripts'
subdirectory that has R verion of codes used in the book, including code for
CV.

Andy

 
> This is what I assumed I would do somethink like this (in 
> this example basp = Baird's Sparrow presence or absence)
> 
> train <- birddata[birddata$recordyear != 2000]
> test <- birddata[birddata$recordyear == 2000]
> train.glm <- glm(basp ~ elev + slope + precip + precip_1 ..., 
> data=birddata, family=binomial)
> pred <- predict(train.glm, newdata=test, type='response')
> actual <- test$basp
> what happens next??
> 
> Thanks in advance.
> 
> T
> -- 
> Trevor Wiens 
> twiens at interbaun.com
> 
> The significant problems that we face cannot be solved at the same 
> level of thinking we were at when we created them. 
> (Albert Einstein)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From dimitris.rizopoulos at med.kuleuven.ac.be  Tue Mar 15 17:12:37 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Tue, 15 Mar 2005 17:12:37 +0100
Subject: [R] cv.glm {boot}
References: <20050314212905.078747e6.twiens@interbaun.com><Pine.LNX.4.61.0503150702160.12742@gannet.stats>
	<20050315085936.4cd7e38e.twiens@interbaun.com>
Message-ID: <011201c52979$cdd8db50$0540210a@www.domain>

you could also take a look at function `?errortest' from package 
`ipred' and V&R's S programming, pp.175

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Trevor Wiens" <twiens at interbaun.com>
To: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
Cc: <r-help at stat.math.ethz.ch>
Sent: Tuesday, March 15, 2005 4:59 PM
Subject: Re: [R] cv.glm {boot}


> On Tue, 15 Mar 2005 07:05:49 +0000 (GMT)
> Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>
>>
>> Cross-validation assumes exchangeability of units.  You can easily 
>> write
>> your own code (lots of examples in MASS), but first you would need 
>> to
>> prove the validity of what you are attempting.  For example, 
>> dropping
>> chunks in the middle of a time series is not valid unless your 
>> prediction
>> somehow takes the temporal structure into account (and glm does 
>> not).
>>
>
> Yes, I'm aware of that and I do have a number of predictors which 
> vary with time (from year to year such as precipitation or properly 
> timed vegetation indices from each year....) so that isn't my 
> problem. Also my spatial blocking is also valid (distinct partitions 
> of the study area). I'm also aware of the problems of spatial 
> autocorrelation and have taken some measures to deal with that. I am 
> however rather new at R and not a statistician, so I am heavily 
> reliant on books such as Hosmer and Lemeshow or Manley(Resource 
> selection by Animals) on procedure. Unforunately, they are not 
> S-plus or R oriented so I have some difficulty translating those 
> ideas to R.
>
> You mention lots of examples in MASS regarding cross-validation, but 
> I can't find them. Perhaps I'm looking in the wrong spot. I've done 
> help.search('validation'), .... and found nothing that seemed 
> obviously applicable to my problem. I suppose I should pick up a 
> copy of your books which would probably be very helpful. However, if 
> it isn't too much trouble. I would really appreciate a bit more 
> direct help.
>
> This is what I assumed I would do somethink like this (in this 
> example basp = Baird's Sparrow presence or absence)
>
> train <- birddata[birddata$recordyear != 2000]
> test <- birddata[birddata$recordyear == 2000]
> train.glm <- glm(basp ~ elev + slope + precip + precip_1 ..., 
> data=birddata, family=binomial)
> pred <- predict(train.glm, newdata=test, type='response')
> actual <- test$basp
> what happens next??
>
> Thanks in advance.
>
> T
> -- 
> Trevor Wiens
> twiens at interbaun.com
>
> The significant problems that we face cannot be solved at the same
> level of thinking we were at when we created them.
> (Albert Einstein)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From twiens at interbaun.com  Tue Mar 15 17:20:44 2005
From: twiens at interbaun.com (Trevor Wiens)
Date: Tue, 15 Mar 2005 09:20:44 -0700
Subject: [R] cv.glm {boot}
In-Reply-To: <011201c52979$cdd8db50$0540210a@www.domain>
References: <20050314212905.078747e6.twiens@interbaun.com>
	<Pine.LNX.4.61.0503150702160.12742@gannet.stats>
	<20050315085936.4cd7e38e.twiens@interbaun.com>
	<011201c52979$cdd8db50$0540210a@www.domain>
Message-ID: <20050315092044.48558f3c.twiens@interbaun.com>

On Tue, 15 Mar 2005 17:12:37 +0100
"Dimitris Rizopoulos" <dimitris.rizopoulos at med.kuleuven.ac.be> wrote:

> you could also take a look at function `?errortest' from package 
> `ipred' and V&R's S programming, pp.175
> 
> I hope it helps.
> 

Yes it does. I think I can make this work.

Thank you very much.

T
-- 
Trevor Wiens 
twiens at interbaun.com

The significant problems that we face cannot be solved at the same 
level of thinking we were at when we created them. 
(Albert Einstein)



From jarioksa at sun3.oulu.fi  Tue Mar 15 17:38:59 2005
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Tue, 15 Mar 2005 18:38:59 +0200
Subject: [R] Significance of Principal Coordinates
In-Reply-To: <4235CA9C.1030603@ips.unibe.ch>
References: <4235CA9C.1030603@ips.unibe.ch>
Message-ID: <1110904739.1231.43.camel@biol102145.oulu.fi>

On Mon, 2005-03-14 at 18:32 +0100, Christian Kamenik wrote:
> Dear all,
> 
> I was looking for methods in R that allow assessing the number of  
> significant principal coordinates. Unfortunatly I was not very 
> successful. I expanded my search to the web and Current Contents, 
> however, the information I found is very limited.
> Therefore, I tried to write code for doing a randomization. I would 
> highly appriciate if somebody could comment on the following approach. I 
> am neither a statistician, nor an R expert... the data matrix I used has 
> 72 species (columns) and 167 samples (rows).
> 
Earlier this year (Sat, 29 Jan 2005) J?r?me Lema?tre asked something
similar here under subject "Bootstrapped eigenvector" (but the code I
posted then had one bug I know and perhaps some I don't know!). Some
ecologists (Donald Jackson, Peres-Neto) have indeed tried to develop
methods for PCA, and they could be easily modified for PCoA which is
about the same method, in particular with Euclidean distances like you
used. So the following two solutions are practically identical (within
2e-15 in the case I tried):

x <- decostand(x, "norm") # in vegan
chordis <- dist(x) # Euclidean is the default, so this is chord distance
pcoa <- cmdscale(chordis)
pca <- prcomp(x)

Verify this with:

procrustes(pcoa, pca, choices=1:2) # in vegan

PCoA with row weights is something different, but I really don't know
why would you like to do this. I really don't understand what people
mean with "significant" eigenvalues, unless they are making Factor
Analysis. In PCA, you rotate your data, and you can find low-rank
approximations of your data, but how these are rotatations are
"significant" is beyond my imagination. Further, resampling with
replacement seems to suit poorly to multivariate analysis: it duplicates
some rows and so it makes easier to find similar rows that is the
ultimate task in PC rotation. It seems that Monte Carlo results are
systematically "better" than any original data (only if number of rows
is much lower than  number of columns this is not disturbing). Also,
resampling or shuffling species tends to create communities that are
fundamentally different from any real community we have: instead of
single or a few abundant species, they may have several or none. With
total abundance constraint you can hide the traces of anarchistic
community assembly, but not its fundamental fault. So I do think that
(1) you cannot use resampling in assessing PCA and its kin, (2) you
cannot say what is the meaning of being "significant" in this case, and
(3) the number of "significant" axes would only be a function of sample
size even here.

Now my hope is that some guru over there gets so irritated that (s)he
chastises me for writing such pieces of stupidity, and sends a correct
solution here with accompanying code and references to the literature.
Let's hope so.

The old truth is that most data sets have 2.5 dimensions (Kruskal):
those two that you can show in a printed plot, and that half a dimension
that you must explain away in the text. Wouldn't that be a sufficient
solution?

cheers, jari oksanen
-- 
Jari Oksanen <jarioksa at sun3.oulu.fi>



From plummer at iarc.fr  Tue Mar 15 17:42:10 2005
From: plummer at iarc.fr (Martyn Plummer)
Date: Tue, 15 Mar 2005 17:42:10 +0100
Subject: [R] gR - installation and computation
In-Reply-To: <200503151613.12583.depire@inrets.fr>
References: <200503151613.12583.depire@inrets.fr>
Message-ID: <1110904930.3391.11.camel@seurat>

On Tue, 2005-03-15 at 16:13 +0100, Depire Alexandre wrote:
> Hello everyone,
> I would like to use R to compute some special hidden markov chain. I see that 
> such those models are like dynamic bayesion network.
> So, I find some doc about computation of those models in R, but I don't know 
> how to install it on R and how to use it.
> These doc talks about gR project.

The home page of the gR project is here:

http://www.r-project.org/gR/

The aim of the project is to bring together several existing programs
for graphical modelling under the umbrella of R. You might want to look
at OpenBUGS (see link) for fitting hidden Markov models.

Martyn



From ripley at stats.ox.ac.uk  Tue Mar 15 17:43:48 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 15 Mar 2005 16:43:48 +0000 (GMT)
Subject: [R] cv.glm {boot}
In-Reply-To: <20050315085936.4cd7e38e.twiens@interbaun.com>
References: <20050314212905.078747e6.twiens@interbaun.com>
	<Pine.LNX.4.61.0503150702160.12742@gannet.stats>
	<20050315085936.4cd7e38e.twiens@interbaun.com>
Message-ID: <Pine.LNX.4.61.0503151643090.23339@gannet.stats>

On Tue, 15 Mar 2005, Trevor Wiens wrote:

> You mention lots of examples in MASS regarding cross-validation, but I 
> can't find them. Perhaps I'm looking in the wrong spot. I've done

Try the index: MASS is a book!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From depire at inrets.fr  Tue Mar 15 17:47:11 2005
From: depire at inrets.fr (Depire Alexandre)
Date: Tue, 15 Mar 2005 17:47:11 +0100
Subject: [R] gR - installation and computation
In-Reply-To: <1110904930.3391.11.camel@seurat>
References: <200503151613.12583.depire@inrets.fr>
	<1110904930.3391.11.camel@seurat>
Message-ID: <200503151747.11919.depire@inrets.fr>

Thanks a lot,
I precisely search a program to compute IOHMM network, and I don't know if 
OpenBUGS can do it

Le Mardi 15 Mars 2005 17:42, Martyn Plummer a ?crit :
> On Tue, 2005-03-15 at 16:13 +0100, Depire Alexandre wrote:
> > Hello everyone,
> > I would like to use R to compute some special hidden markov chain. I see
> > that such those models are like dynamic bayesion network.
> > So, I find some doc about computation of those models in R, but I don't
> > know how to install it on R and how to use it.
> > These doc talks about gR project.
>
> The home page of the gR project is here:
>
> http://www.r-project.org/gR/
>
> The aim of the project is to bring together several existing programs
> for graphical modelling under the umbrella of R. You might want to look
> at OpenBUGS (see link) for fitting hidden Markov models.
>
> Martyn

-- 
----------------
Alexandre DEPIRE
INRETS / GARIG



From ligges at statistik.uni-dortmund.de  Tue Mar 15 18:05:31 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 15 Mar 2005 18:05:31 +0100
Subject: [R] font sizes
In-Reply-To: <Pine.GSO.4.58.0503151546510.29273@bononcini>
References: <Pine.GSO.4.58.0503151546510.29273@bononcini>
Message-ID: <423715DB.9000108@statistik.uni-dortmund.de>

Simon.Bond wrote:

> I'm trying to use the pdf() function, and would like to increase the font
> size for slide-presentation  purposes. Changing the
> argument `pointsize' doesn't seem to do anything.
> 
> Anyone come across this or know what to do?


It does, e.g. compare pointsize=8 / pointsize=14

If you want something different, maybe setting argument "cex" (and 
friends) in par() does what you want. See ?par.

Uwe Ligges

> thanks
> 
> Simon Bond.
> 
> -------------------------------------------------------------------------
>     /"\
>     \ /    ASCII RIBBON CAMPAIGN - AGAINST HTML MAIL
>      X                           - AGAINST MS ATTACHMENTS
>     / \
> 
> http://www.gnu.org/philosophy/no-word-attachments.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From eesteves at ualg.pt  Tue Mar 15 18:18:50 2005
From: eesteves at ualg.pt (eesteves@ualg.pt)
Date: Tue, 15 Mar 2005 17:18:50 +0000
Subject: [R] help w/ xyplot and panel.lmline
Message-ID: <20050315171850.htpend6hkw8w0og0@wmail.ualg.pt>

Dear All,
I'm confortable with xyplot(...) and panel.lmline(...) statements (at least I
thought I did :). I've used the following code to plot the decline in
log-abundance of fish larvae (no.larvae) with age (age.cls, 4 to 27 days-old)
for specific dates of sampling (day, 9 dates). I further plotted data with
different colors and regression lines for ages 5-14 d and 17-23 d in a 7-by-1
layout.

 xyplot(log(no.larvae)~age.cls|factor(day),data=mortal,
  layout=c(7,1),aspect=5/3,
  xlab="Age class (d)",ylab="Ln(Abundance)",ylim=c(-2.5,6.5),xlim=c(0,30),
  panel = function(x, y) {
  panel.xyplot(x, y, col=1)
  panel.xyplot(x[5:14],y[5:14],pch=16,col=1)
  panel.lmline(x[5:14],y[5:14])
  panel.xyplot(x[17:23],y[17:23],pch=16,col=2)
  panel.lmline(x[17:23],y[17:23],lty=2)
  })

Is it possible to change the plotted characters and regression lines for two of
the panels (corresponding to dates 101 and 172). For these dates I intend to
use data only for ages 9-14 d instead of 5-14 d as for the remaining.

Thanks in advance,
Eduardo Esteves



From christianmacaro at gmail.com  Tue Mar 15 18:42:53 2005
From: christianmacaro at gmail.com (Christian)
Date: Tue, 15 Mar 2005 18:42:53 +0100
Subject: [R] Re: Installing R on Mandrake 10.1
In-Reply-To: <16950.41491.249522.890367@stat.math.ethz.ch>
References: <4235D611.80201@uniroma2.it>
	<16950.41491.249522.890367@stat.math.ethz.ch>
Message-ID: <42371E9D.9010109@gmail.com>

Dear all.

First of all, thanks to Jon, Martin, Bogdan and Roland since they tried 
to help me.

In order I tried to
1) install the libf2c0-3.4.1-4mdk.i586.rpm.
2) install R 2.0.1 from the source.


1) Didn't work, since the "info" is still not satisfied
2) I wasn't able to configure it. I mean:

a) as root I uzipped the archive in the home/krisse directory
b) ./configure in the home/krisse/R-2.0.1 directory
the resulting message was that neither a fortran compiler nor f2c was found.

Then I looked for a fortran compiler........
What I have understood is that a fortran compiler is already included in 
the gcc3.4.1-4mdk (already installed).
Is that correct?
In the /usr/bin directory there are g++ an similar things but none of 
the g77, f77, xlf, frt, pgf77, fl32, af77, fort77, f90, xlf90, pgf90, 
epcf90, f95, fort, xlf95, lf95, g95, and fc.

Then I tried to install the f2c package. I don't get the error "neither 
a fortran compiler nor f2c was found" but the configuring command wasn't 
able to build the make file.......

Now, I know I am really bad at linux and I don't actually know the 
meaning of most of the things i have written above,
but it would be really nice if somebody could help me.

Thanks again.


Christian



Martin Maechler wrote:

>>>>>>"Christian" == Christian  <christianmacaro at gmail.com>
>>>>>>    on Mon, 14 Mar 2005 19:21:05 +0100 writes:
>>>>>>            
>>>>>>
>
>    Christian> Dear all, I am trying to install the
>    Christian> R-2.0.0-1mdk.i586.rpm
>    Christian> <http://cran.planetmirror.com/bin/linux/mandrake/10.0/R-2.0.0-1mdk.i586.rpm>
>    Christian> file on mandrake 10.1. 
>.....
>
>Hi Christian, 
>I'm not really answering your question, 
>but really you shouldn't install R 2.0.0 once R 2.0.1 has been
>released for such a long time and already R 2.1.0 is going into
>"alpha" stage next Monday.
>
>Why don't you try to install from source?
>I've been advocating this as a test of ``having a decently
>complete Linux/Unix system'', i.e.,
>in order to build R from the sources (without too many warnings
>about missing features) you will have to get quite a few useful
>things (gcc, g77, perl, latex, texinfo, ..) that you want `anyway'.
>One of the five R manuals is called
>"R Administration / Installation" -- this should help you to
>become successful.  Once you've installed R 2.0.1 from the
>sources, you will be ready to try "R 2.1.0 alpha" -- which will
>be a service to the R user community, if you help testing out
>R 2.0.1 *before* its release.
>
>BTW, you seem to be from Roma, Italy. You might be delighted to
>see that R 2.1.0 will speak Italian in some ways.
>
>Martin Maechler, ETH Zurich
>
>
>  
>



From choudary.jagar at swosu.edu  Tue Mar 15 18:59:02 2005
From: choudary.jagar at swosu.edu (Jagarlamudi, Choudary)
Date: Tue, 15 Mar 2005 11:59:02 -0600
Subject: [R] How to extract x rows to get  x pvalues using t.test
Message-ID: <E03EBB50FF2C024781A6E4460AD58F0607C1AC@swosu-mbx01.admin.swosu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050315/ff59076d/attachment.pl

From dkoschuetzki at gmx.de  Tue Mar 15 19:20:39 2005
From: dkoschuetzki at gmx.de (Dirk Koschuetzki)
Date: Tue, 15 Mar 2005 19:20:39 +0100
Subject: [R] How do I call a masked function in a package without a
	namespace?
Message-ID: <op.snoykpmg61mj6a@moon>

Hello,

I work with two packages sna and graph from CRAN resp. Bioconductor. Both  
packages have a function called "degree". Therefore one of the functions  
is masked by the other and which one gets called depends on the order of  
loading. The problem is that both package do not have a namespace,  
therefore calling the masked function with "package::degree" does not  
work. See the following transcript:

$ R --vanilla

[[ Running on Debian Sarge ]]

R : Copyright 2004, The R Foundation for Statistical Computing
Version 2.0.1  (2004-11-15), ISBN 3-900051-07-0
[...]

> library("sna")
> library("graph")
Loading required package: cluster
Loading required package: Ruuid
Creating a new generic function for "print" in "Ruuid"
Loading required package: Biobase
Loading required package: tools
Welcome to Bioconductor
          Vignettes contain introductory material.  To view,
          simply type: openVignette()
          For details on reading vignettes, see
          the openVignette help page.
> conflicts()
[1] "last.warning" "degree"       "body<-"       "print"        "split"
[6] "union"

> sna::degree()
Error in loadNamespace(name) : package 'sna' does not have a name space
> graph::degree()
Error in loadNamespace(name) : package 'graph' does not have a name space
> sna:::degree
Error in loadNamespace(name) : package 'sna' does not have a name space
> graph:::degree
Error in loadNamespace(name) : package 'graph' does not have a name space


Is there a way to call the masked function via a different way?
And I wold like to create my own function degree which will of course  
masked both functions and should therefore be able to call both functions.

Thanks for any hint!

Cheers,
Dirk



From zhongmingyang at yahoo.com  Tue Mar 15 19:58:13 2005
From: zhongmingyang at yahoo.com (Zhongming Yang)
Date: Tue, 15 Mar 2005 10:58:13 -0800 (PST)
Subject: [R] question on xyplot
Message-ID: <20050315185814.41255.qmail@web51307.mail.yahoo.com>

Dear All:
 
In the attached file, I have 3 group patients, and there are 5 in each group (the groups are decided by the prefix of the idno). I want draw a repeat measurement comparison figure. My goal is to list 5 patients from same group on one  horizontal line. But xyplot sounds pick them randomly (or I was confused?). Could you please help me modify the following code to accomplish this?
 
Thanks
 
Zhongming Yang
 

library(nlme)
library(lattice)
md <- read.table('../data/sample.txt', header=T)
md <- groupedData(md ~ month | idno, data=md)
trellis.device(theme=col.whitebg())
xyplot(md ~ month | idno, data=md, main="title", 
   xlab="x", ylab="y", layout=c(5, 3),
   panel=function(x, y){
   panel.xyplot(x, y)
   panel.lmline(x, y, lty=2)
        }
   )
 




		
---------------------------------

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: sample.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050315/abec4779/sample.txt

From adi at roda.ro  Wed Mar 16 05:59:08 2005
From: adi at roda.ro (Adrian Dusa)
Date: Tue, 15 Mar 2005 20:59:08 -0800
Subject: [R] z and p
Message-ID: <200503152059.08450.adi@roda.ro>


Dear useRs,

I use pnorm to calculate the area under the normal curve to the left of z. 
Now, is there a function which provides the z value given a certain area?
I wrote a function which finds it in about 20 iterations, but it seems to me 
not the best solution; I'm just curios if there is an already built function.

Regards,
Adrian

-- 
Adrian Dusa
Romanian Social Data Archive
Bd. Schitu Magureanu nr.1
Tel./Fax: +40 21 3126618 \
              +40 21 3120210 / int.101


-- 
This message was scanned for spam and viruses by BitDefender.
For more information please visit http://linux.bitdefender.com/



From gunter.berton at gene.com  Tue Mar 15 20:09:17 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Tue, 15 Mar 2005 11:09:17 -0800
Subject: [R] z and p
In-Reply-To: <200503152059.08450.adi@roda.ro>
Message-ID: <200503151909.j2FJ9Iip001426@meitner.gene.com>

qnorm

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Adrian Dusa
> Sent: Tuesday, March 15, 2005 8:59 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] z and p
> 
> 
> Dear useRs,
> 
> I use pnorm to calculate the area under the normal curve to 
> the left of z. 
> Now, is there a function which provides the z value given a 
> certain area?
> I wrote a function which finds it in about 20 iterations, but 
> it seems to me 
> not the best solution; I'm just curios if there is an already 
> built function.
> 
> Regards,
> Adrian
> 
> -- 
> Adrian Dusa
> Romanian Social Data Archive
> Bd. Schitu Magureanu nr.1
> Tel./Fax: +40 21 3126618 \
>               +40 21 3120210 / int.101
> 
> 
> -- 
> This message was scanned for spam and viruses by BitDefender.
> For more information please visit http://linux.bitdefender.com/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From andy_liaw at merck.com  Tue Mar 15 20:11:57 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 15 Mar 2005 14:11:57 -0500
Subject: [R] z and p
Message-ID: <3A822319EB35174CA3714066D590DCD50994E85C@usrymx25.merck.com>

Yes, it's called qnorm().

Andy

> From: Adrian Dusa
> 
> Dear useRs,
> 
> I use pnorm to calculate the area under the normal curve to 
> the left of z. 
> Now, is there a function which provides the z value given a 
> certain area?
> I wrote a function which finds it in about 20 iterations, but 
> it seems to me 
> not the best solution; I'm just curios if there is an already 
> built function.
> 
> Regards,
> Adrian
> 
> -- 
> Adrian Dusa
> Romanian Social Data Archive
> Bd. Schitu Magureanu nr.1
> Tel./Fax: +40 21 3126618 \
>               +40 21 3120210 / int.101
> 
> 
> -- 
> This message was scanned for spam and viruses by BitDefender.
> For more information please visit http://linux.bitdefender.com/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From p.dalgaard at biostat.ku.dk  Tue Mar 15 20:18:19 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 15 Mar 2005 20:18:19 +0100
Subject: [R] z and p
In-Reply-To: <200503152059.08450.adi@roda.ro>
References: <200503152059.08450.adi@roda.ro>
Message-ID: <x2ll8on2f8.fsf@biostat.ku.dk>

Adrian Dusa <adi at roda.ro> writes:

> Dear useRs,
> 
> I use pnorm to calculate the area under the normal curve to the left of z. 
> Now, is there a function which provides the z value given a certain area?
> I wrote a function which finds it in about 20 iterations, but it seems to me 
> not the best solution; I'm just curios if there is an already built function.

Yes, qnorm.
 
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jstenberg at ice.mpg.de  Tue Mar 15 20:26:15 2005
From: jstenberg at ice.mpg.de (Johan Stenberg)
Date: Tue, 15 Mar 2005 20:26:15 +0100
Subject: [R] Dispersion factor in GLM
Message-ID: <423736D7.6B256233@ice.mpg.de>

Dear all,

I have two questions concerning GLM (logistic regression) with
family=binomial.

1. A measure of the departure from the binomial assumption is given by
the
dispersion factor (= residual deviance / residual df). The data is
over-dispersed when the dispersion factor is significantly higher than 1
(Crawley, page 518). Is there any way to test if the dispersion factor
is significantly higher than 1? The residual deviance should be
chi2-distributed which should allow to test for the significance of the
departure...
See below to see how my syntax looks like.

2. How do you calculate the proportion of deviance explained by the
model (the equivalent of r2 in a standard regression) in R?

Kind regards

Johan Stenberg


> y<-cbind(para,unpara)
> model<-glm(y~log(larvae),binomial)
> summary(model)

Call:
glm(formula = y ~ log(larvae), family = binomial)

Deviance Residuals:
    Min       1Q   Median       3Q      Max
-2.0633  -1.6218  -0.1871   0.7907   2.7670

Coefficients:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)   1.0025     0.7049   1.422  0.15499
log(larvae)  -1.0640     0.3870  -2.749  0.00597 **

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 35.981  on 12  degrees of freedom
Residual deviance: 27.298  on 11  degrees of freedom
AIC: 40.949

Number of Fisher Scoring iterations: 4

> anova(model,test="F")
Analysis of Deviance Table

Model: binomial, link: logit

Response: y

Terms added sequentially (first to last)


            Df Deviance Resid. Df Resid. Dev      F   Pr(>F)
NULL                           12     35.981
log(larvae)  1    8.683        11     27.298 8.6828 0.003212 **



From roger.bos at gmail.com  Tue Mar 15 20:26:42 2005
From: roger.bos at gmail.com (roger bos)
Date: Tue, 15 Mar 2005 14:26:42 -0500
Subject: [R] missing sh.exe file when running "R CMD INSTALL test"
Message-ID: <1db7268005031511267e2495c5@mail.gmail.com>

I am trying to learn how to make a simple package that contains no C
or Fortran code.  I used package.skeleton(...) to make a package
called "test".  The directory and files look good.  I downloaded and
installed Rtools (www.murdoch-sutherland.com/Rtools/tools.zip).  I
added the path and from the dos prompt I can verify that make.exe and
sh.exe both exist, but when I try to run "R CMD INSTALL test" I get an
error "make: sh.exe: Command not found"  and "make: *** [pkg-test]
Error 127".  I get the same error message if a try the command "make
pkg-test".

I saw in an old FAQ a suggestion to move sh.eve to the C:\bin\ folder,
but my C: root does not have a "bin" folder.  Nonetheless, I created
one and put sh.exe there and it provided no help (I didn't expect it
too).

Can anyone help me?



From roger.bos at gmail.com  Tue Mar 15 20:39:51 2005
From: roger.bos at gmail.com (roger bos)
Date: Tue, 15 Mar 2005 14:39:51 -0500
Subject: [R] RODBC, sqlSave and sqlAppend
In-Reply-To: <NDEAJMAPIIPDKHDMLLLOMEKDDAAA.spjgmwn@iop.kcl.ac.uk>
References: <NDEAJMAPIIPDKHDMLLLOMEKDDAAA.spjgmwn@iop.kcl.ac.uk>
Message-ID: <1db7268005031511393411ca71@mail.gmail.com>

I use RODBC all day every day and while I am pretty happy with it, I
was never able to make a table separately and append to it using
sqlSave.  Nevertheless, maybe my observations will help.

I always let sqlSave make the table for me.  Make sure the table
doesn't exist and it will make it.  I never use sqlAppend, I use
sqlSave(..., append=TRUE).  Also, how do you know you are not getting
an error.  Try 'go <- sqlSave(...)' and then type go and if it returns
'character(0)' then you have no error, otherwise you will see an
extremely brief hint of what went wrong.  Finally, I always have my
database open when I sqlSave and that is never a problem, so you don't
need to close MS access AFAIK.  Its probably easier to use sqlQuery
right after sqlSave to verify that it worked.

Once sqlSave works, then you can use standard SQL statements to alter
the table and alter to columns to make the datatypes whatever you want
and then use 'insert into' statements to move the data when you want. 
So basically, because I save to a temporary table, alter the columns
to change the datatypes, and then copy that to my final table.  Sounds
like a lot of work, but it can be automated once you write the command
in R.

Maybe someone will provide you with a better answer, but this might
get you started.

Thanks,

Roger


On Tue, 15 Mar 2005 15:19:26 -0000, Matthew W Nash
<spjgmwn at iop.kcl.ac.uk> wrote:
> Hi all,
> 
> I am currently trying to read, write and append data between R and MS access
> using the RODBC library functions. I have no problems reading in the data
> but when using sqlSave and sqlAppend it doesn't seem to work. I have made
> sure that all the column names are sensible and there are no gaps etc in the
> variables. My call looks like this:
> 
> sqlSave(channel,treatlist,test=F)
> 
> I've played with various options but what consistently happens is that R
> writes a new table (column names a written and sensible variable types are
> assigned), but it doesn't actually write any data into it. When I run
> sqlAppend there are no error messages, but when I look at the MS access
> database nothing has been written. (I always have the database closed when
> doing this.)
> 
> What am I doing wrong?
> 
> Matthew Nash,
> 
> Post-Doctoral Research Worker,
> GENDEP study,
> SGDP, Institute of Psychiatry,
> PO82, Room CB.15,
> 16 De Crespigny Park,
> London, SE5 8AF,
> United Kingdom
> 
> Phone: (+44) 207 848 0805
> 
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> ~
> Announcing the 6th MRC SGDP SUMMER SCHOOL 25 -? 29 July 2005 with courses in
> a) Twin model fitting, Mx
> b) Microarrays (Affymetrix), gene expression, SNPs
> c) Linkage, association and allied methods
> http://sgdp.iop.kcl.ac.uk/summerschool/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From murdoch at stats.uwo.ca  Tue Mar 15 20:51:48 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 15 Mar 2005 19:51:48 +0000
Subject: [R] missing sh.exe file when running "R CMD INSTALL test"
In-Reply-To: <1db7268005031511267e2495c5@mail.gmail.com>
References: <1db7268005031511267e2495c5@mail.gmail.com>
Message-ID: <i2fe315gm30ao5hv3mal1grqaa28h9l23n@4ax.com>

On Tue, 15 Mar 2005 14:26:42 -0500, roger bos <roger.bos at gmail.com>
wrote :

>I am trying to learn how to make a simple package that contains no C
>or Fortran code.  I used package.skeleton(...) to make a package
>called "test".  The directory and files look good.  I downloaded and
>installed Rtools (www.murdoch-sutherland.com/Rtools/tools.zip).  I
>added the path and from the dos prompt I can verify that make.exe and
>sh.exe both exist, but when I try to run "R CMD INSTALL test" I get an
>error "make: sh.exe: Command not found"  and "make: *** [pkg-test]
>Error 127".  I get the same error message if a try the command "make
>pkg-test".
>
>I saw in an old FAQ a suggestion to move sh.eve to the C:\bin\ folder,
>but my C: root does not have a "bin" folder.  Nonetheless, I created
>one and put sh.exe there and it provided no help (I didn't expect it
>too).
>
>Can anyone help me?

It sounds as though your PATH is incomplete.  If you just type "sh",
does it run?  If not, then you need to set up your path to include the
R tools directory.  It should probably be first in the PATH, as
described in README.packages..

bDuncan



From ggrothendieck at myway.com  Tue Mar 15 21:27:37 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 15 Mar 2005 20:27:37 +0000 (UTC)
Subject: [R] How do I call a masked function in a package without
	=?utf-8?b?YQluYW1lc3BhY2U/?=
References: <op.snoykpmg61mj6a@moon>
Message-ID: <loom.20050315T211629-395@post.gmane.org>

Dirk Koschuetzki <dkoschuetzki <at> gmx.de> writes:

: 
: Hello,
: 
: I work with two packages sna and graph from CRAN resp. Bioconductor. Both  
: packages have a function called "degree". Therefore one of the functions  
: is masked by the other and which one gets called depends on the order of  
: loading. The problem is that both package do not have a namespace,  
: therefore calling the masked function with "package::degree" does not  
: work. See the following transcript:
: 
: $ R --vanilla
: 
: [[ Running on Debian Sarge ]]
: 
: R : Copyright 2004, The R Foundation for Statistical Computing
: Version 2.0.1  (2004-11-15), ISBN 3-900051-07-0
: [...]
: 
: > library("sna")
: > library("graph")
: Loading required package: cluster
: Loading required package: Ruuid
: Creating a new generic function for "print" in "Ruuid"
: Loading required package: Biobase
: Loading required package: tools
: Welcome to Bioconductor
:           Vignettes contain introductory material.  To view,
:           simply type: openVignette()
:           For details on reading vignettes, see
:           the openVignette help page.
: > conflicts()
: [1] "last.warning" "degree"       "body<-"       "print"        "split"
: [6] "union"
: 
: > sna::degree()
: Error in loadNamespace(name) : package 'sna' does not have a name space
: > graph::degree()
: Error in loadNamespace(name) : package 'graph' does not have a name space
: > sna:::degree
: Error in loadNamespace(name) : package 'sna' does not have a name space
: > graph:::degree
: Error in loadNamespace(name) : package 'graph' does not have a name space
: 
: Is there a way to call the masked function via a different way?
: And I wold like to create my own function degree which will of course  
: masked both functions and should therefore be able to call both functions.
: 

The following looks up the position of the graph package on the
search path and gets degree specifically from there,
invokes it with the indicates arguments.

graph.degree <- function(...)
   get("degree", grep("package:graph$", search()))(...)



From andy_liaw at merck.com  Tue Mar 15 21:37:26 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 15 Mar 2005 15:37:26 -0500
Subject: [R] How do I call a masked function in a package without a
	na mespace?
Message-ID: <3A822319EB35174CA3714066D590DCD50994E860@usrymx25.merck.com>

> From: Gabor Grothendieck
> 
> Dirk Koschuetzki <dkoschuetzki <at> gmx.de> writes:
> 
> : 
> : Hello,
> : 
> : I work with two packages sna and graph from CRAN resp. 
> Bioconductor. Both  
> : packages have a function called "degree". Therefore one of 
> the functions  
> : is masked by the other and which one gets called depends on 
> the order of  
> : loading. The problem is that both package do not have a namespace,  
> : therefore calling the masked function with 
> "package::degree" does not  
> : work. See the following transcript:
> : 
> : $ R --vanilla
> : 
> : [[ Running on Debian Sarge ]]
> : 
> : R : Copyright 2004, The R Foundation for Statistical Computing
> : Version 2.0.1  (2004-11-15), ISBN 3-900051-07-0
> : [...]
> : 
> : > library("sna")
> : > library("graph")
> : Loading required package: cluster
> : Loading required package: Ruuid
> : Creating a new generic function for "print" in "Ruuid"
> : Loading required package: Biobase
> : Loading required package: tools
> : Welcome to Bioconductor
> :           Vignettes contain introductory material.  To view,
> :           simply type: openVignette()
> :           For details on reading vignettes, see
> :           the openVignette help page.
> : > conflicts()
> : [1] "last.warning" "degree"       "body<-"       "print"    
>     "split"
> : [6] "union"
> : 
> : > sna::degree()
> : Error in loadNamespace(name) : package 'sna' does not have 
> a name space
> : > graph::degree()
> : Error in loadNamespace(name) : package 'graph' does not 
> have a name space
> : > sna:::degree
> : Error in loadNamespace(name) : package 'sna' does not have 
> a name space
> : > graph:::degree
> : Error in loadNamespace(name) : package 'graph' does not 
> have a name space
> : 
> : Is there a way to call the masked function via a different way?
> : And I wold like to create my own function degree which will 
> of course  
> : masked both functions and should therefore be able to call 
> both functions.
> : 
> 
> The following looks up the position of the graph package on the
> search path and gets degree specifically from there,
> invokes it with the indicates arguments.
> 
> graph.degree <- function(...)
>    get("degree", grep("package:graph$", search()))(...)
> 

Just 

    get("degree", "package:graph")(...)

will do.  I'd suggest adding require(graph) to make sure it's loaded.

 ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From ggrothendieck at myway.com  Tue Mar 15 21:32:12 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 15 Mar 2005 20:32:12 +0000 (UTC)
Subject: [R] missing sh.exe file when running "R CMD INSTALL test"
References: <1db7268005031511267e2495c5@mail.gmail.com>
Message-ID: <loom.20050315T213041-648@post.gmane.org>

roger bos <roger.bos <at> gmail.com> writes:

: 
: I am trying to learn how to make a simple package that contains no C
: or Fortran code.  I used package.skeleton(...) to make a package
: called "test".  The directory and files look good.  I downloaded and
: installed Rtools (www.murdoch-sutherland.com/Rtools/tools.zip).  I
: added the path and from the dos prompt I can verify that make.exe and
: sh.exe both exist, but when I try to run "R CMD INSTALL test" I get an
: error "make: sh.exe: Command not found"  and "make: *** [pkg-test]
: Error 127".  I get the same error message if a try the command "make
: pkg-test".
: 
: I saw in an old FAQ a suggestion to move sh.eve to the C:\bin\ folder,
: but my C: root does not have a "bin" folder.  Nonetheless, I created
: one and put sh.exe there and it provided no help (I didn't expect it
: too).
: 
: Can anyone help me?

I suspect you may have only defined it for a particular console session,
not permanently.  

1. Right click My Computer
2. Choose Properties
3. Choose Advanced
4. Click on Environment Variables

and make sure its in the PATH defined there.  If



From sluque at mun.ca  Tue Mar 15 22:48:17 2005
From: sluque at mun.ca (Sebastian Luque)
Date: Tue, 15 Mar 2005 15:48:17 -0600
Subject: [R] help w/ xyplot and panel.lmline
References: <20050315171850.htpend6hkw8w0og0@wmail.ualg.pt>
Message-ID: <871xag60ny.fsf@mun.ca>

eesteves at ualg.pt wrote:

[...]

> Is it possible to change the plotted characters and regression lines for
> two of the panels (corresponding to dates 101 and 172). For these dates
> I intend to use data only for ages 9-14 d instead of 5-14 d as for the
> remaining.

Have a look at argument 'panel.number' that you can use when defining your
panel function. You can create a conditional statement based on that
argument. Perhaps something like (replace where appropriate):

 xyplot(log(no.larvae)~age.cls|factor(day),data=mortal,
        layout=c(7,1),aspect=5/3,
        xlab="Age class (d)",ylab="Ln(Abundance)",ylim=c(-2.5,6.5),xlim=c(0,30),
        panel = function(x, y, panel.number, ...) {
          if(panel.number == "panel number for day 101" |
             panel.number == "panel number for day 172") {
            "panel functions for these days here"} else {
              "panel functions for other days here"}
        })

works for you? I've used something similar with 'panel.groups' as the main
panel function, but have never done it as above, so beware :-)


-- 
Sebastian Luque



From solberg at berkeley.edu  Tue Mar 15 23:54:35 2005
From: solberg at berkeley.edu (Owen Solberg)
Date: Tue, 15 Mar 2005 14:54:35 -0800 (PST)
Subject: [R] How to plot points as numbers/strings in lattice
Message-ID: <Pine.LNX.4.61.0503151431270.4639@mws11.biol.berkeley.edu>

Hello,

I would be very grateful if anyone could help with what seems like a 
simple lattice task.  I want to use xyplot, where the symbols for the 
plotted points are taken from another column in the data frame.  So if the 
data frame looked like:

a <- as.data.frame(matrix(data=c(1,1,10,2,2,20,3,3,30), nrow=3, ncol=3, byrow=TRUE))
a

   V1 V2 V3
1  1  1 10
2  2  2 20
3  3  3 30

you would get an xy scatter plot using where "10" (not a dot) is at 
coordinate 1,1, "20" is at 2,2, and so on.

I have made two attempts.  The first, below, almost works, but only takes 
the first character from the V3 column:

library(lattice)
xyplot(V1~V2, data=a, pch=as.character(a$V3))

I've also tried this example, which is given in an online user guide for 
trellis.  It uses the built-in "ethanol" data set (which is also in 
lattice), and subscripts... but when I try the same code in lattice, I get 
an "invalid graphics state" error.

library(lattice)
xyplot(NOx ~ E | C, data = ethanol, aspect = 1/2,
        panel = function(x, y, subscripts)
          text(x, y, subscripts, cex = .75)
)


Thank you very much in advance!

Owen Solberg

------------

> version
          _
platform i686-redhat-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    2
minor    0.0
year     2004
month    10
day      04
language R



From younko at uiuc.edu  Wed Mar 16 00:07:25 2005
From: younko at uiuc.edu (Ko,Younhee)
Date: Tue, 15 Mar 2005 17:07:25 -0600
Subject: [R] Install the RMySQL 
Message-ID: <16d2eb32.dda5a731.8761e00@expms3.cites.uiuc.edu>

Thank you very much for your comments.
Finally I installed it~ :-)

But I have one more general question.

Using the RMySQL package and DBI, 
Can I install the R object to the database?

I mean, suppose I got the Objects from matest function or 
fitmaanova function. 
If I want to save the results to the database table, is it 
possible?

Now I looked up the most functions that are related with 
database, but, I couldn't find it.

is it possible?

Thanks in advance. 
---- Original message ----
>Date: Tue, 15 Mar 2005 07:16:07 +0000 (GMT)
>From: Prof Brian Ripley <ripley at stats.ox.ac.uk>  
>Subject: Re: [R] Install the RMySQL   
>To: "Ko,Younhee" <younko at uiuc.edu>
>Cc: R-help at stat.math.ethz.ch
>
>On Mon, 14 Mar 2005, Ko,Younhee wrote:
>
>> Hi, I have some problem to install RMySQL package.
>> Could you help me?
>
>Please tell us your OS, R version, etc.
>
>> I set up the path.
>
>You set a couple of variables, but no path.  (These at most 
supplement the 
>include and library paths.)
>
>> [root at ep2 library]# export PKG_CPPFLAGS="-I/var/lib/mysql"
>> [root at ep2 library]# export PKG_LIBS="-L/var/lib/mysql -
>> lmysqlclient"
>
>Looks like your MySQL files are not where you claim they: I 
would not 
>expect them to be there (headers are not normally in 
a 'lib' directory), 
>but where they are depends on whether this is an 
installation from the 
>sources (not likely if it uses /var/lib), RPM etc.  E.g. 
FC3 has
>
>checking for mysql_init in -lmysqlclient... yes
>              mysqlclient found in -L/usr/lib/mysql
>checking for /usr/local/include/mysql/mysql.h... no
>checking for /usr/include/mysql/mysql.h... yes
>
>Note to David James as maintainer: should not finding these 
be an error, 
>or at least give a very loud warning from configure?
>
>
>> [root at ep2 library]# R CMD INSTALL /home/younko/RMySQL_0.5-
>> 5.tar.gz
>>
>>
>> I got this bunch of error message.
>>
>>
>>
>> Please help me.
>>
>>
>> * Installing *source* package 'RMySQL' ...
>> creating cache ./config.cache
>> checking how to run the C preprocessor... cc -E
>> checking for compress in -lz... yes
>> checking for getopt_long in -lc... yes
>> checking for mysql_init in -lmysqlclient... no
>> checking for mysql.h... no
>> updating cache ./config.cache
>> creating ./config.status
>> creating src/Makevars
>> ** libs
>> gcc -I/usr/local/lib/R/include -I/var/lib/mysql -
>> I/usr/local/include   -fPIC  -g -O2 -c RS-DBI.c -o RS-
DBI.o
>> gcc -I/usr/local/lib/R/include -I/var/lib/mysql -
>> I/usr/local/include   -fPIC  -g -O2 -c RS-MySQL.c -o RS-
>> MySQL.o
>> In file included from RS-MySQL.c:22:
>> RS-MySQL.h:40:19: mysql.h: No such file or directory
>> RS-MySQL.h:41:27: mysql_version.h: No such file or 
directory
>> RS-MySQL.h:42:23: mysql_com.h: No such file or directory
>
>That's sufficient info.
>
>-- 
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  
http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 
(self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
========================
Younhee Ko(younko at uiuc.edu)

http://comedu.korea.ac.kr/~unygo
contact : 217-417-4868
Graduate Student in Dept. of Computer Science
University of Illinois at Urbana-Champaign



From p.connolly at hortresearch.co.nz  Wed Mar 16 00:18:03 2005
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Wed, 16 Mar 2005 12:18:03 +1300
Subject: [R] Control of vertical spacing in Lattice key text?
Message-ID: <20050315231803.GI4244@hortresearch.co.nz>

I find the key and legend functions in Lattice very useful.  Trouble
is, now I can see what else I'd like to be able to do with them.

If I put a title on a key, it appears too close to the key itself, and
if there's a line break in the title (which often happens), the
leading between the lines is too much.

What I can do is print to a postscript file, then find the lines in
the postscript file where my text appears and fiddle with the
postscript code to move the text up or down as I wish.  For single
plots that's OK, but I'd prefer to be able to do it within R
especially when I wish to do dozens of them.

Is there something in the documentation I overlooked?

TIA

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From constant.depiereux at aqte.be  Wed Mar 16 00:16:37 2005
From: constant.depiereux at aqte.be (Depiereux Constant)
Date: Wed, 16 Mar 2005 00:16:37 +0100
Subject: Fwd: [R] RODBC, sqlSave and sqlAppend
Message-ID: <28ae35f23c7c118c85d4eff66e3fcaba@aqte.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050316/8d6f1a7d/attachment.pl

From iacolonn at uiuc.edu  Wed Mar 16 00:21:42 2005
From: iacolonn at uiuc.edu (Ignacio Colonna)
Date: Tue, 15 Mar 2005 17:21:42 -0600
Subject: [R] How to plot points as numbers/strings in lattice
In-Reply-To: <Pine.LNX.4.61.0503151431270.4639@mws11.biol.berkeley.edu>
Message-ID: <200503152321.j2FNLinB006608@expredir2.cites.uiuc.edu>

Owen,
	I think this gives the plot you are looking for. There may be other
better ways to do it, this is just the one I know. Inside 'panel' you would
need to use 'ltext()' instead of 'text()', as in the example you provided.

xyplot(V1~V2, data=a, groups=V3,
panel = function(x, y, groups)
          ltext(x, y, label=groups, cex = .75)
)

Ignacio

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Owen Solberg
Sent: Tuesday, March 15, 2005 4:55 PM
To: r-help at stat.math.ethz.ch
Subject: [R] How to plot points as numbers/strings in lattice

Hello,

I would be very grateful if anyone could help with what seems like a 
simple lattice task.  I want to use xyplot, where the symbols for the 
plotted points are taken from another column in the data frame.  So if the 
data frame looked like:

a <- as.data.frame(matrix(data=c(1,1,10,2,2,20,3,3,30), nrow=3, ncol=3,
byrow=TRUE))
a

   V1 V2 V3
1  1  1 10
2  2  2 20
3  3  3 30

you would get an xy scatter plot using where "10" (not a dot) is at 
coordinate 1,1, "20" is at 2,2, and so on.

I have made two attempts.  The first, below, almost works, but only takes 
the first character from the V3 column:

library(lattice)
xyplot(V1~V2, data=a, pch=as.character(a$V3))

I've also tried this example, which is given in an online user guide for 
trellis.  It uses the built-in "ethanol" data set (which is also in 
lattice), and subscripts... but when I try the same code in lattice, I get 
an "invalid graphics state" error.

library(lattice)
xyplot(NOx ~ E | C, data = ethanol, aspect = 1/2,
        panel = function(x, y, subscripts)
          text(x, y, subscripts, cex = .75)
)


Thank you very much in advance!

Owen Solberg

------------

> version
          _
platform i686-redhat-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    2
minor    0.0
year     2004
month    10
day      04
language R

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From deepayan at stat.wisc.edu  Wed Mar 16 00:38:42 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 15 Mar 2005 17:38:42 -0600
Subject: [R] How to plot points as numbers/strings in lattice
In-Reply-To: <Pine.LNX.4.61.0503151431270.4639@mws11.biol.berkeley.edu>
References: <Pine.LNX.4.61.0503151431270.4639@mws11.biol.berkeley.edu>
Message-ID: <200503151738.42782.deepayan@stat.wisc.edu>

On Tuesday 15 March 2005 16:54, Owen Solberg wrote:
> Hello,
>
> I would be very grateful if anyone could help with what seems like a
> simple lattice task.  I want to use xyplot, where the symbols for the
> plotted points are taken from another column in the data frame.  So
> if the data frame looked like:
>
> a <- as.data.frame(matrix(data=c(1,1,10,2,2,20,3,3,30), nrow=3,
> ncol=3, byrow=TRUE)) a
>
>    V1 V2 V3
> 1  1  1 10
> 2  2  2 20
> 3  3  3 30
>
> you would get an xy scatter plot using where "10" (not a dot) is at
> coordinate 1,1, "20" is at 2,2, and so on.
>
> I have made two attempts.  The first, below, almost works, but only
> takes the first character from the V3 column:
>
> library(lattice)
> xyplot(V1~V2, data=a, pch=as.character(a$V3))
>
> I've also tried this example, which is given in an online user guide
> for trellis.  It uses the built-in "ethanol" data set (which is also
> in lattice), and subscripts... but when I try the same code in
> lattice, I get an "invalid graphics state" error.
>
> library(lattice)
> xyplot(NOx ~ E | C, data = ethanol, aspect = 1/2,
>         panel = function(x, y, subscripts)
>           text(x, y, subscripts, cex = .75)
> )

text() will not do anything useful in a lattice panel function, you want 
to use ltext or panel.text. There's a very similar example in the help 
page for xyplot.

Deepayan



From MSchwartz at MedAnalytics.com  Wed Mar 16 01:02:09 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Tue, 15 Mar 2005 18:02:09 -0600
Subject: [R] Adobe Reader V7.0 for Unix/Linux Available
Message-ID: <1110931330.18575.17.camel@horizons.localdomain>

Just as a heads up to the community, Adobe has released version 7.0 of
the free stand-alone PDF Reader for Unix/Linux platforms.

There was a post on the Fedora list today and there is an article at:

http://www.scribus.org.uk/modules.php?
op=modload&name=News&file=article&sid=93

The links for downloading are:

# Binary installer
ftp://ftp.adobe.com/pub/adobe/reader/unix/7x/7.0/enu/AdbeRdr70_linux_enu.tar.gz

# i386 RPM
ftp://ftp.adobe.com/pub/adobe/reader/unix/7x/7.0/enu/AdobeReader_enu-7.0.0-1.i386.rpm

Presently, it is only available in English and it is still "closed
source", even though free of charge. The downloads are about 40Mb.

There are no links yet on the main Adobe page for this version and the
normal Adobe download process as of this e-mail still shows version 5 as
the most recent available for Unix/Linux platforms. This appears to be a
"quiet" release so far.

Major changes include a GTK2 based UI rather than Motif, support for PDF
v1.6, inclusion of some additional fonts and other features that bring
it more in line with version 7 for other platforms.

I have replaced my former v5 here and it seems to work quite well so
far. For those using RPM based systems, you will need to remove the old
version if installed via RPM, as the new RPM will conflict with the
older version. The RPM will install to /usr/local/Adobe.

HTH,

Marc Schwartz



From ramasamy at cancer.org.uk  Wed Mar 16 01:32:25 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 16 Mar 2005 00:32:25 +0000
Subject: [R] How to extract x rows to get  x pvalues using t.test
In-Reply-To: <E03EBB50FF2C024781A6E4460AD58F0607C1AC@swosu-mbx01.admin.swosu.edu>
References: <E03EBB50FF2C024781A6E4460AD58F0607C1AC@swosu-mbx01.admin.swosu.edu>
Message-ID: <1110933145.6001.24.camel@dhcp-63.ccc.ox.ac.uk>

You will need to _apply_ the t-test row by row. 

   apply( genes, 1, function(x) t.test( x[1:2], x[3:4] )$p.value )

apply() is a C optimised version of for. Running the above code on a
dataset with 56000 rows and 4 columns took about 63 seconds on my 1.6
GHz Pentium machine with 512 Mb RAM. See help("apply") for more details.

Regards, Adai



On Tue, 2005-03-15 at 11:59 -0600, Jagarlamudi, Choudary wrote:
> Hi all,
>  
>   My data
> genes
>      [,1] [,2] [,3] [,4]
> [1,]   25   72   23   55
> [2,]   34   53   41   33
> [3,]   26   43   26   44
> [4,]   36   64   64   22
> [5,]   47   72   67   34
> 
>  stu<-t.test(genes[,1:2],genes[,3:4])
> > stu$p.value
> [1] 0.4198002
> 
> i get 1 pvalue for the entire col1:col2  Vs col3:col4. I am trying to get 5 p values for the 5 rows i have.
> I am trying to avoid a for loop coz my actual data has 56000 rows and its taking more than 4 minutes to
> compute.
>  
> Thanks in advance.
>  
> Choudary Jagarlamudi
> Instructor
> Southwestern Oklahoma State University
> STF 254
> 100 campus Drive
> Weatherford OK 73096
> Tel 580-774-7136
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From andy_liaw at merck.com  Wed Mar 16 01:43:26 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 15 Mar 2005 19:43:26 -0500
Subject: [R] How to extract x rows to get  x pvalues using t.test
Message-ID: <3A822319EB35174CA3714066D590DCD50994E866@usrymx25.merck.com>

> From: Adaikalavan Ramasamy
> 
> You will need to _apply_ the t-test row by row. 
> 
>    apply( genes, 1, function(x) t.test( x[1:2], x[3:4] )$p.value )
> 
> apply() is a C optimised version of for. Running the above code on a
> dataset with 56000 rows and 4 columns took about 63 seconds on my 1.6
> GHz Pentium machine with 512 Mb RAM. See help("apply") for 
> more details.

That's not true.  In R, there's a for loop hidden inside apply() (just look
at the source).  In S-PLUS, C level looping is done in some situations, and
for others lapply() is used.

Andy

 
> Regards, Adai
> 
> 
> 
> On Tue, 2005-03-15 at 11:59 -0600, Jagarlamudi, Choudary wrote:
> > Hi all,
> >  
> >   My data
> > genes
> >      [,1] [,2] [,3] [,4]
> > [1,]   25   72   23   55
> > [2,]   34   53   41   33
> > [3,]   26   43   26   44
> > [4,]   36   64   64   22
> > [5,]   47   72   67   34
> > 
> >  stu<-t.test(genes[,1:2],genes[,3:4])
> > > stu$p.value
> > [1] 0.4198002
> > 
> > i get 1 pvalue for the entire col1:col2  Vs col3:col4. I am 
> trying to get 5 p values for the 5 rows i have.
> > I am trying to avoid a for loop coz my actual data has 
> 56000 rows and its taking more than 4 minutes to
> > compute.
> >  
> > Thanks in advance.
> >  
> > Choudary Jagarlamudi
> > Instructor
> > Southwestern Oklahoma State University
> > STF 254
> > 100 campus Drive
> > Weatherford OK 73096
> > Tel 580-774-7136
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From christof.bigler at colorado.edu  Wed Mar 16 02:53:14 2005
From: christof.bigler at colorado.edu (Christof Bigler)
Date: Tue, 15 Mar 2005 18:53:14 -0700
Subject: [R] Log-linear model with correlation structure
Message-ID: <a7c258ea620b724d6d79463f775e358a@colorado.edu>

Dear list,

I have a time series of frequency data (number of dead trees in each 
year), including zero frequencies. With a continuous predictor variable 
(climate index), I want to assess the effect on the number of dead 
trees.

Is there a log-linear regression model that includes a serial 
correlation structure to model temporal dependence? I think of an 
autoregressive model, such as in the functions lme or gls in 
library(nlme).

Any help is appreciated!

Christof



From bu.qi.cheng at intel.com  Wed Mar 16 03:27:40 2005
From: bu.qi.cheng at intel.com (Cheng, Bu Qi)
Date: Wed, 16 Mar 2005 10:27:40 +0800
Subject: [R] workload of R
Message-ID: <CEBA252FE3382B4F9147D8686C72455B01B42550@pdsmsx402.ccr.corp.intel.com>

Hi,
	We are working on R language compiler to find out the way to
improve the performance of R in multi core processor and the parallelism
in the workload of R. Where can I find the typical workload wrote by R? 

Thanks!

Cheng, Buqi



From Glen.Jones at team.telstra.com  Wed Mar 16 05:43:14 2005
From: Glen.Jones at team.telstra.com (Jones, Glen R)
Date: Wed, 16 Mar 2005 15:43:14 +1100
Subject: [R] Write.table query
Message-ID: <5D01E8305096D3119D7D00508B5EBBF415BBD658@ntmsg0133.corpmail.telstra.com.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050316/3019881c/attachment.pl

From mcclatchie.sam at saugov.sa.gov.au  Wed Mar 16 06:31:59 2005
From: mcclatchie.sam at saugov.sa.gov.au (McClatchie, Sam (PIRSA-SARDI))
Date: Wed, 16 Mar 2005 16:01:59 +1030
Subject: [R] Fixed/ trellis/ panel.superpose/ passing in superscripts/ groups
Message-ID: <032A8573186A2B4EBBAEFA5784D0523506E10D1B@sagemsg0007.sagemsmrd01.sa.gov.au>

Background:
OS: Linux Mandrake 10.1
release: R 2.0.0
editor: GNU Emacs 21.3.2
front-end: ESS 5.2.3
---------------------------------
Colleagues

I have solved the miscoding with subscript and groups in panel.superpose. I
was neglecting to pass in the variables correctly.

"sardine.egg.T.S.space.2001.and.2002.exp" <-
  function()
  {
    library(lattice)
    library(grid)
    ##     trellis.device(postscript,
    ##
file="../figures/sardine.egg.T.S.space.2001.and.2002.ps",
    ##                  horizontal=FALSE, color=TRUE)
    
    year <- as.factor(rep(2001,  dim(mn.ts.e.2001)[1]))    
    year.2001 <- cbind(mn.ts.e.2001,year)
    year <- as.factor(rep(2002,  dim(mn.ts.e.2002)[1]))    
    year.2002 <- cbind(mn.ts.e.2002,year)    
    mn.ts.e.both <- rbind(year.2001, year.2002)
                                        #browser()    
###trellis plot
    ## define conditioning interval
    int <- matrix(c(0,2,3,4,5,8,9,16,17,32,33,64), ncol=2, byrow=TRUE)
    egg.counts <- shingle(mn.ts.e.both$eggs2.Pilch.Eggs, intervals = int)
    ##larvae.counts <- shingle(mn.ts.e.both$eggs2.Pilch.Larv, intervals =
int)
    ## define plot structure
    out1 <- xyplot(mn.t ~  mn.s |  egg.counts,
                   data = mn.ts.e.both,
                   groups = year,
                   xlim = c(35,38), ylim = c(12,24),
                   xlab = "mean salinity", ylab = "mean temperature (deg.
C)",
                   main = "2001 and 2002 egg densities in
Temperature-Salinity space",
                   aspect = "xy",
                   jitter = T,
                   layout = c(1,6),
                   auto.key=TRUE,
                   ##add to individual panels
                   panel = function(x, y, subscripts, groups){
                     ## plot all the T-S data for both years
                     ## using explicit variables, differing from x,y
                     panel.xyplot(data.2001$Salinity,
data.2001$Temperature.oC, 
                                  pch=".", col="yellow");
                     panel.xyplot(data.2002$Salinity,
data.2002$Temperature.oC, 
                                  pch=".", col="orange");
                     ## add some labels for watermasses
                     panel.text(37.8, 15, "Upwelling");
                     panel.text(37.8, 17.5, "Warm pool");
                     panel.text(37.8, 19.75, "Shelf break");
                     panel.text(37.8, 21.5, "Spencer Gulf");
                     panel.abline(h = c(16,19,20.5), v = 36.5, col="red",
lty=2);
                     ## overlay the conditioned egg data on the TS plots
                     panel.superpose(x, y, subscripts, groups);
                     ## add a legend
                     auto.key = T
                   }
                   )

    print(out1)
    ##   graphics.off()
    
  }

----
Sam McClatchie,
Biological oceanography 
South Australian Aquatic Sciences Centre
PO Box 120, Henley Beach 5022
Adelaide, South Australia
email <mcclatchie.sam at saugov.sa.gov.au>
Telephone: (61-8) 8207 5448
FAX: (61-8) 8200 2481
Research home page <http://www.members.iinet.net.au/~s.mcclatchie/>
  
                   /\
      ...>><xX(?> 
                //// \\\\
                   <?)Xx><<
              /////  \\\\\\
                        ><(((?> 
  >><(((?>   ...>><xX(?>O<?)Xx><<



From henric.nilsson at statisticon.se  Wed Mar 16 07:52:31 2005
From: henric.nilsson at statisticon.se (Henric Nilsson)
Date: Wed, 16 Mar 2005 07:52:31 +0100 (CET)
Subject: [R] Write.table query
In-Reply-To: <5D01E8305096D3119D7D00508B5EBBF415BBD658@ntmsg0133.corpmail.telstra.c
	om.au>
References: <5D01E8305096D3119D7D00508B5EBBF415BBD658@ntmsg0133.corpmail.telstra.com.au>
Message-ID: <1416.10.0.10.126.1110955951.squirrel@poisson.statisticon.se>


On On, 2005-03-16, 05:43, Jones, Glen R skrev:

> Hello,
>
> I have the following 'write.table' statement which works fine
>
> write.table(DataOutput,"c:/Prices.csv",append = TRUE,col.names = NA,sep
> = "," )
>
> My query is, how could I modify this so I can include a variable name as
> a prefix before the 'Prices.CSV' filename.
>
> For example:
>
> prefixname = "DevX"
>
> write.table(DataOutput,"c:/" &prefixname& "Prices.csv",append =
> TRUE,col.names = NA,sep = "," )
>
> With the resultant CSV output to be named "DevXPrices.csv".

Use `paste':

> prefixname <- "DevX"
> paste("c:/", prefixname, "Prices.csv", sep = "")
[1] "c:/DevXPrices.csv"

HTH,
Henric



From robert.pollak at scietec.at  Wed Mar 16 10:35:33 2005
From: robert.pollak at scietec.at (Robert Pollak)
Date: Wed, 16 Mar 2005 10:35:33 +0100
Subject: [R] How to concatenate time series?
Message-ID: <4237FDE5.2020408@scietec.at>

Hello,

I have just completed first experiments in using R, especially creating and 
using ARIMA models, e.g.

# create a model as in example(arima)
fit <- arima(USAccDeaths, order = c(1,1,1),seasonal = list(order=c(1,1,1)))

# use the model to generate a prediction
dp<-predict(fit, n.ahead = 24)

plot(dp$pred) # view the prediction



Now I created a combined chart of the original and predicted values. I tried it 
like this:

dvs <- c(as.vector(USAccDeaths),as.vector(dp$pred))
plot(dvs, type="l")

Here, of course, the x axis does not display time values any more. So I manually 
recontructed a time series from the concatenated vector:

ds<-ts(dvs, 1973, 1980.91666666667, deltat = 1/12)

plot(ds) # this is the chart I wanted



Now my question is:
Is there some way to directly concatenate the original and the predicted time 
series? Searching the help files and this mailing list's archive gave me no hints.


Best regards,
Robert Pollak


-- 
______________________________________
Dipl.-Ing. Robert Pollak
SCIETEC Flussmanagement GmbH
Herrenstrasse 4
A-4020 Linz

Phone:      [+43] (0)732 / 71 31 20 26
Fax:        [+43] (0)732 / 71 31 20 4
Cell Phone: [+43] (0)699 / 11 44 30 32

Mailto: robert.pollak at scietec.at
URL:    http://www.scietec.at



From Simon.Bond at mrc-bsu.cam.ac.uk  Wed Mar 16 10:53:10 2005
From: Simon.Bond at mrc-bsu.cam.ac.uk (Simon.Bond)
Date: Wed, 16 Mar 2005 09:53:10 +0000 (GMT)
Subject: [R] font sizes
In-Reply-To: <423715DB.9000108@statistik.uni-dortmund.de>
References: <Pine.GSO.4.58.0503151546510.29273@bononcini>
	<423715DB.9000108@statistik.uni-dortmund.de>
Message-ID: <Pine.GSO.4.58.0503160941490.372@bononcini>

Having experimented with both a sun workstation and a PC, changing
pointsize within the PC does have the desired effect, but it does nothing
within the Sun.

Unforutnately, the PC won't let me load the workspace I want (which
I normally  access through the sun) due to `lazy loading' errors.

Thinking more generally, although I think the ability to fine tune R
graphics is excellent, even superlative, what I would find really useful
is means to load a whole load of graphical settings in one go; one setting
to look at on-screen, one setting for written reports, one setting for
slides. Can anyone suggest a good way of going about this.

thanks Simon

On Tue, 15 Mar 2005, Uwe Ligges wrote:

> Simon.Bond wrote:
>
> > I'm trying to use the pdf() function, and would like to increase the font
> > size for slide-presentation  purposes. Changing the
> > argument `pointsize' doesn't seem to do anything.
> >
> > Anyone come across this or know what to do?
>
>
> It does, e.g. compare pointsize=8 / pointsize=14
>
> If you want something different, maybe setting argument "cex" (and
> friends) in par() does what you want. See ?par.
>
> Uwe Ligges
>
> > thanks
> >
> > Simon Bond.
> >
> > -------------------------------------------------------------------------
> >     /"\
> >     \ /    ASCII RIBBON CAMPAIGN - AGAINST HTML MAIL
> >      X                           - AGAINST MS ATTACHMENTS
> >     / \
> >
> > http://www.gnu.org/philosophy/no-word-attachments.html
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>

-------------------------------------------------------------------------
    /"\
    \ /    ASCII RIBBON CAMPAIGN - AGAINST HTML MAIL
     X                           - AGAINST MS ATTACHMENTS
    / \

http://www.gnu.org/philosophy/no-word-attachments.html



From zoran.l at sezampro.yu  Wed Mar 16 11:58:35 2005
From: zoran.l at sezampro.yu (Zoran Loncarevic)
Date: Wed, 16 Mar 2005 11:58:35 +0100
Subject: [R] Fitting mixed proportional odds model in R?
Message-ID: <opsnp8rx1rsyfj50@localhost>


Is there a way to fit mixed proportional odds models in R?

-- 
Using Opera's revolutionary e-mail client: http://www.opera.com/m2/



From Luisr at frs.fo  Wed Mar 16 12:16:57 2005
From: Luisr at frs.fo (Luis Ridao Cruz)
Date: Wed, 16 Mar 2005 11:16:57 +0000
Subject: [R] Note: "The default device has been opened to honour attempt to
	modify trellis settings"
Message-ID: <s23815b4.068@ffdata.setur.fo>

R-help,

I'm using a function whose end result is a trellis plot.
When I call the function I get sometimes the following message:

"Note: The default device has been opened to honour attempt to modify
trellis settings "

leading up to any plot whatsoever.

I call the package 'lattice' within the function and 'detach' after
plotting.

I have to close the graphics device to get the desired result (and it
works only after a few more function calls)

Here is the function code

"function"<-function(somedata)
{
 ..........

library(lattice)
trellis.par.set(theme = col.whitebg())

xyplot(log.catch ~ age | yrclass , data = tmp2)

detach(package:lattice)

savePlot(file="catch curve",type="jpeg")

}

function(somedata)


Thanks in advance.

I'm running on Windows XP

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    0.1            
year     2004           
month    11             
day      15             
language R



From ggrothendieck at myway.com  Wed Mar 16 12:23:30 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 16 Mar 2005 11:23:30 +0000 (UTC)
Subject: [R] How to concatenate time series?
References: <4237FDE5.2020408@scietec.at>
Message-ID: <loom.20050316T122215-264@post.gmane.org>

Robert Pollak <robert.pollak <at> scietec.at> writes:

: 
: Hello,
: 
: I have just completed first experiments in using R, especially creating and 
: using ARIMA models, e.g.
: 
: # create a model as in example(arima)
: fit <- arima(USAccDeaths, order = c(1,1,1),seasonal = list(order=c(1,1,1)))
: 
: # use the model to generate a prediction
: dp<-predict(fit, n.ahead = 24)
: 
: plot(dp$pred) # view the prediction
: 
: Now I created a combined chart of the original and predicted values. I tried 
it 
: like this:
: 
: dvs <- c(as.vector(USAccDeaths),as.vector(dp$pred))
: plot(dvs, type="l")
: 
: Here, of course, the x axis does not display time values any more. So I 
manually 
: recontructed a time series from the concatenated vector:
: 
: ds<-ts(dvs, 1973, 1980.91666666667, deltat = 1/12)
: 
: plot(ds) # this is the chart I wanted
: 
: Now my question is:
: Is there some way to directly concatenate the original and the predicted 
time 
: series? Searching the help files and this mailing list's archive gave me no 
hints.

ts.plot(USAccDeaths, dp$pred, col = 1:2)



From Jesus.Frias at dit.ie  Wed Mar 16 12:02:35 2005
From: Jesus.Frias at dit.ie (Jesus Frias)
Date: Wed, 16 Mar 2005 11:02:35 +0000
Subject: [R] use of covariates with nlmeODE
Message-ID: <LGECJJCANFBOOHCMGPJEMEMKDLAA.Jesus.Frias@dit.ie>

Dear R-helpers,
	I have some problem with a model I am trying to run with nlmeODE. I have a
covariate that I want to include in the model and I can't find in the
documentation how to include it in the model so that it can calculate it.

>formula(trial)

PME ~ time | Ident


abcnoniso <- list(DiffEq=list(
                    debdt = ~ -ksol*pH*eb ,
                    desdt = ~ ksolref*pH*eb-kdegref*pH*es,
                    dpHdt= ~ -k*(pH-pHinf)
                    ),
                  ObsEq=list(
                    c1 = ~ 0,
                    c2 = ~ es,
                    c3 = ~ 0),
                  Parms=c("ksol","kdeg","k","es0","eb0"),
                  States=c("es","eb","pH"),
                  Init=list("eb0","es0",3))
abcnonisomodc <- nlmeODE(abcnoniso,trial)

The variable pHinf is a covariate that changes from experiment to
experiment. The model does not take very well pHinf.

regards,

Jesus


--------------------------------------------------------------
Jes?s Mar?a Fr?as Celayeta
School of Food Sci. and Env. Health.
Faculty of Tourism and Food
Dublin Institute of Technology
Cathal Brugha St., Dublin 1. Ireland
t +353 1 4024459 f +353 1 4024495
w www.dit.ie/DIT/tourismfood/science/staff/frias.html
--------------------------------------------------------------



-- 
This message has been scanned for content and 
viruses by the DIT Information Services MailScanner 
Service, and is believed to be clean.
http://www.dit.ie



From sundar.dorai-raj at pdf.com  Wed Mar 16 13:33:35 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 16 Mar 2005 06:33:35 -0600
Subject: [R] Note: "The default device has been opened to honour attempt
	to	modify trellis settings"
In-Reply-To: <s23815b4.068@ffdata.setur.fo>
References: <s23815b4.068@ffdata.setur.fo>
Message-ID: <4238279F.1050803@pdf.com>



Luis Ridao Cruz wrote on 3/16/2005 5:16 AM:
> R-help,
> 
> I'm using a function whose end result is a trellis plot.
> When I call the function I get sometimes the following message:
> 
> "Note: The default device has been opened to honour attempt to modify
> trellis settings "
> 
> leading up to any plot whatsoever.
> 
> I call the package 'lattice' within the function and 'detach' after
> plotting.
> 
> I have to close the graphics device to get the desired result (and it
> works only after a few more function calls)
> 
> Here is the function code
> 
> "function"<-function(somedata)
> {
>  ..........
> 
> library(lattice)
> trellis.par.set(theme = col.whitebg())
> 
> xyplot(log.catch ~ age | yrclass , data = tmp2)
> 
> detach(package:lattice)
> 
> savePlot(file="catch curve",type="jpeg")
> 
> }
> 
> function(somedata)
> 
> 
> Thanks in advance.
> 
> I'm running on Windows XP
> 
> 
>>version
> 
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    2              
> minor    0.1            
> year     2004           
> month    11             
> day      15             
> language R
> 


Luis,

If you are trying to save a plot within a function, you are going about 
it the wrong way.

# don't call your function "function"
# "function"<-function(somedata)
my.function <- function(somedata) {
   require(lattice) # minor change here
   # next line is what's causing the message
   # trellis.par.set(theme = col.whitebg())
   trellis.device(jpeg, file = "catch_curve.jpg", theme = col.whitebg())
   # need to explicitly print the plot to the current device
   # see FAQ 7.22
   print(xyplot(log.catch ~ age | yrclass , data = tmp2))
   # turn device off after printing
   dev.off()
   # not sure why you need to detach every time ...
   detach(package:lattice)
   #savePlot(file="catch curve",type="jpeg")
}

my.function(somedata)

--sundar



From ramasamy at cancer.org.uk  Wed Mar 16 13:55:12 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 16 Mar 2005 12:55:12 +0000
Subject: problems with par and startup (was Re: [R] font sizes)
In-Reply-To: <Pine.GSO.4.58.0503160941490.372@bononcini>
References: <Pine.GSO.4.58.0503151546510.29273@bononcini>
	<423715DB.9000108@statistik.uni-dortmund.de>
	<Pine.GSO.4.58.0503160941490.372@bononcini>
Message-ID: <1110977712.6029.66.camel@localhost.localdomain>

Well, one way you can try is to define the different styles you want in
your $HOME/.Rprofile file (see ?Startup). For example

-----------------------------------------------------------------------
  library(graphics)
  op   <- par(no.readonly = TRUE)               # store original par
  par0 <- function(){ par(op) }                 # restore original par
  par1 <- function(){ par(lty=1, pch = "X")   }
  par2 <- function(){ par(col=2, cex.axis=0.1)}
  dev.off()                     # kills the empty window spawned by par
-----------------------------------------------------------------------

A typical call might be 
par1(); plot(1:5);  par0()
par2(); plot(1:10); par0()

It would be more useful to write this as a parser but I do not know how.


BTW, why does calling par(), even with no.readonly=TRUE argument always
insists on opening a graphics window when there is none present. This is
a little bit annoying as the focus changes to the plotting window. Does
anyone know how to turn this feature off ?

Regards, Adai


On Wed, 2005-03-16 at 09:53 +0000, Simon.Bond wrote:
> Having experimented with both a sun workstation and a PC, changing
> pointsize within the PC does have the desired effect, but it does nothing
> within the Sun.
> 
> Unforutnately, the PC won't let me load the workspace I want (which
> I normally  access through the sun) due to `lazy loading' errors.
> 
> Thinking more generally, although I think the ability to fine tune R
> graphics is excellent, even superlative, what I would find really useful
> is means to load a whole load of graphical settings in one go; one setting
> to look at on-screen, one setting for written reports, one setting for
> slides. Can anyone suggest a good way of going about this.
> 
> thanks Simon
> 
> On Tue, 15 Mar 2005, Uwe Ligges wrote:
> 
> > Simon.Bond wrote:
> >
> > > I'm trying to use the pdf() function, and would like to increase the font
> > > size for slide-presentation  purposes. Changing the
> > > argument `pointsize' doesn't seem to do anything.
> > >
> > > Anyone come across this or know what to do?
> >
> >
> > It does, e.g. compare pointsize=8 / pointsize=14
> >
> > If you want something different, maybe setting argument "cex" (and
> > friends) in par() does what you want. See ?par.
> >
> > Uwe Ligges
> >
> > > thanks
> > >
> > > Simon Bond.
> > >
> > > -------------------------------------------------------------------------
> > >     /"\
> > >     \ /    ASCII RIBBON CAMPAIGN - AGAINST HTML MAIL
> > >      X                           - AGAINST MS ATTACHMENTS
> > >     / \
> > >
> > > http://www.gnu.org/philosophy/no-word-attachments.html
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> >
> 
> -------------------------------------------------------------------------
>     /"\
>     \ /    ASCII RIBBON CAMPAIGN - AGAINST HTML MAIL
>      X                           - AGAINST MS ATTACHMENTS
>     / \
> 
> http://www.gnu.org/philosophy/no-word-attachments.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From kkiely at insightful.com  Wed Mar 16 14:01:42 2005
From: kkiely at insightful.com (Kathy Kiely)
Date: Wed, 16 Mar 2005 13:01:42 -0000
Subject: [R] Insightful Financial Time Series Modelling in S-PLUS - April
	course dates
Message-ID: <B796B8C05975394DA24E457D1985BDB45C7CB7@uk2kexch01.insightful.com>

Insightful are now taking bookings for the Financial Time Series Modelling
course to be held at Carlton Terrace in London SW1 on 12th and 13th April
2005. We are also pleased to offer the 1 day Advanced Time Series Modelling
course on April 19th at the same location. 
 
Extract for Financial Time Series Modelling :
 
This two day course will provide participants with a working knowledge of a
range of advanced techniques in Financial Econometrics as well as the
implementation of these methods within S-PLUS. The first day will concentrate
on econometric methods and the second day will develop a number of issues in
empirical finance as well as practical applications.
 
Tutor: Mark Salmon, Professor of Finance, Warwick University
 
Mark Salmon has many years' experience teaching and research in Financial
econometrics; behavioural finance; asset pricing; knightian uncertainty; risk
management and asset management. Formerly Deutsche Morgan Grenfell Professor
of Financial Markets, Cass Business School, London, Mark is also an advisor
to the Bank of England and has many links with City Institutions. 
 
For full course details please go to: 
 
http://www.insightful.com/services/training/timeseries_UK05.asp
 
To Register:
 
http://www.insightful.com/uk/services/register_uk.asp
 
Advanced workshop 
 
For those who have already attended the Financial Time Series Modelling
course, an Advanced workshop will be held on April 19th covering current
thinking and best practice on a number of topics summarised at: 
 
http://www.insightful.com/services/training/advtimeseries_UK05.asp
 
 
 
If you need any further information please do not hesitate to contact me.
 
Regards
 
Kathy Kiely,
 

 
Kathy Kiely
Sales & Marketing Assistant
Insightful Limited
Network House, Basing View Basingstoke, Hampshire, RG21 4HG
Tel : 01256 339822
Fax : 01256 339839
e mail : kkiely at insightful.com



From ligges at statistik.uni-dortmund.de  Wed Mar 16 14:02:05 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 16 Mar 2005 14:02:05 +0100
Subject: problems with par and startup (was Re: [R] font sizes)
In-Reply-To: <1110977712.6029.66.camel@localhost.localdomain>
References: <Pine.GSO.4.58.0503151546510.29273@bononcini>	
	<423715DB.9000108@statistik.uni-dortmund.de>	
	<Pine.GSO.4.58.0503160941490.372@bononcini>
	<1110977712.6029.66.camel@localhost.localdomain>
Message-ID: <42382E4D.8060606@statistik.uni-dortmund.de>

Adaikalavan Ramasamy wrote:

> Well, one way you can try is to define the different styles you want in
> your $HOME/.Rprofile file (see ?Startup). For example
> 
> -----------------------------------------------------------------------
>   library(graphics)
>   op   <- par(no.readonly = TRUE)               # store original par
>   par0 <- function(){ par(op) }                 # restore original par
>   par1 <- function(){ par(lty=1, pch = "X")   }
>   par2 <- function(){ par(col=2, cex.axis=0.1)}
>   dev.off()                     # kills the empty window spawned by par
> -----------------------------------------------------------------------
> 
> A typical call might be 
> par1(); plot(1:5);  par0()
> par2(); plot(1:10); par0()
> 
> It would be more useful to write this as a parser but I do not know how.
> 
> 
> BTW, why does calling par(), even with no.readonly=TRUE argument always
> insists on opening a graphics window when there is none present. This is
> a little bit annoying as the focus changes to the plotting window. Does
> anyone know how to turn this feature off ?


par() applies setting to the current device (or get from the current 
device). If no device has been opened and par() is called, a device is 
opened to get the settings from.

Uwe Ligges



> Regards, Adai
> 
> 
> On Wed, 2005-03-16 at 09:53 +0000, Simon.Bond wrote:
> 
>>Having experimented with both a sun workstation and a PC, changing
>>pointsize within the PC does have the desired effect, but it does nothing
>>within the Sun.
>>
>>Unforutnately, the PC won't let me load the workspace I want (which
>>I normally  access through the sun) due to `lazy loading' errors.
>>
>>Thinking more generally, although I think the ability to fine tune R
>>graphics is excellent, even superlative, what I would find really useful
>>is means to load a whole load of graphical settings in one go; one setting
>>to look at on-screen, one setting for written reports, one setting for
>>slides. Can anyone suggest a good way of going about this.
>>
>>thanks Simon
>>
>>On Tue, 15 Mar 2005, Uwe Ligges wrote:
>>
>>
>>>Simon.Bond wrote:
>>>
>>>
>>>>I'm trying to use the pdf() function, and would like to increase the font
>>>>size for slide-presentation  purposes. Changing the
>>>>argument `pointsize' doesn't seem to do anything.
>>>>
>>>>Anyone come across this or know what to do?
>>>
>>>
>>>It does, e.g. compare pointsize=8 / pointsize=14
>>>
>>>If you want something different, maybe setting argument "cex" (and
>>>friends) in par() does what you want. See ?par.
>>>
>>>Uwe Ligges
>>>
>>>
>>>>thanks
>>>>
>>>>Simon Bond.
>>>>
>>>>-------------------------------------------------------------------------
>>>>    /"\
>>>>    \ /    ASCII RIBBON CAMPAIGN - AGAINST HTML MAIL
>>>>     X                           - AGAINST MS ATTACHMENTS
>>>>    / \
>>>>
>>>>http://www.gnu.org/philosophy/no-word-attachments.html
>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>
>>>
>>-------------------------------------------------------------------------
>>    /"\
>>    \ /    ASCII RIBBON CAMPAIGN - AGAINST HTML MAIL
>>     X                           - AGAINST MS ATTACHMENTS
>>    / \
>>
>>http://www.gnu.org/philosophy/no-word-attachments.html
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>



From vmuggeo at dssm.unipa.it  Wed Mar 16 14:28:49 2005
From: vmuggeo at dssm.unipa.it (vito muggeo)
Date: Wed, 16 Mar 2005 14:28:49 +0100
Subject: [R] Fitting mixed proportional odds model in R?
In-Reply-To: <opsnp8rx1rsyfj50@localhost>
References: <opsnp8rx1rsyfj50@localhost>
Message-ID: <42383491.5000706@dssm.unipa.it>

Zoran Loncarevic wrote:
> 
> Is there a way to fit mixed proportional odds models in R?
As far as I know, no. (anyway have a look to J Lindsey's packages, I 
don't know)

However MIXOR and friends at http://tigger.uic.edu/~hedeker/mix.html
(standalone programs running on Windows systems ) can fit mixed PO, 
although I do know if you can fit only random intercepts or random 
coefficients as well.

Hope this helps,

vito

> 

-- 
====================================
Vito M.R. Muggeo
Dip.to Sc Statist e Matem `Vianelli'
Universit? di Palermo
viale delle Scienze, edificio 13
90121 Palermo - ITALY
tel: 091 6626240
fax: 091 485726/485612



From sdavis2 at mail.nih.gov  Wed Mar 16 14:36:57 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Wed, 16 Mar 2005 08:36:57 -0500
Subject: [R] X11 Protocol error :  BadWindow
Message-ID: <6c83313c2c89df35a5e23fb5ca38c569@mail.nih.gov>

All,

I am using the tcltk package (under macos 10.3.8, running R from ESS, R 
2.0.0).  I am using tcltk libraries from fink:

  i   tcltk                                       8.4.1-12               
           Tool Command Language and the Tk toolkit
  i   tcltk-dev                                   8.4.1-12               
           Tool Command Language and the Tk toolkit
  i   tcltk-shlibs                                8.4.1-12               
           Tool Command Language and the Tk toolkit

#### R CODE
PressedOK <-  function()
{
   plot(runif(100)*10,runif(100)*10)
}

tt <- tktoplevel()
OK.but <- tkbutton(tt,text="OK",command=PressedOK)
tkgrid(OK.but)
tkfocus(tt)


If I evaluate the above code, it works as expected.  However, when 
completed (I close the "OK" window), if I enter any commands that 
result in errors by R (commands that don't exist, for example), I get:

 > dev()
Error: couldn't find function "dev"
In addition: Warning messages:
1: X11 protocol error: BadWindow (invalid Window parameter)
2: X11 protocol error: BadWindow (invalid Window parameter)
3: X11 protocol error: BadWindow (invalid Window parameter)
4: X11 protocol error: BadWindow (invalid Window parameter)
5: X11 protocol error: BadWindow (invalid Window parameter)
6: X11 protocol error: BadWindow (invalid Window parameter)
7: X11 protocol error: BadWindow (invalid Window parameter)
8: X11 protocol error: BadWindow (invalid Window parameter)


However, as soon as I do ls(), for example, the warning messages 
disappear and don't recur unless I re-execute the code.  The archives 
turned up this thread 
(https://stat.ethz.ch/pipermail/r-help/2004-August/055212.html), which 
relates to RCMDr use, but I think is probably general.  The thread 
doesn't look like it comes to a complete resolution.  (I did one 
suggestion, remove the tkfocus call, and get the same result.)  I am 
tempted to ignore the warnings entirely (being lazy when the code 
works), but just wanted to hear if there are any insights from the 
list.

Thanks,
Sean



From br44114 at yahoo.com  Wed Mar 16 14:41:33 2005
From: br44114 at yahoo.com (bogdan romocea)
Date: Wed, 16 Mar 2005 05:41:33 -0800 (PST)
Subject: [R] Mandrake 10.1
In-Reply-To: 6667
Message-ID: <20050316134133.30012.qmail@web50105.mail.yahoo.com>

--- "Rau, Roland" <Rau at demogr.mpg.de> wrote:

> > -----Original Message-----
> > From: r-help
> > On Behalf Of bogdan romocea
> > Sent: Tuesday, March 15, 2005 2:49 PM
> > 
> > I would suggest that you consider another GNU/Linux distribution,

> I don't think it is necessary. Mandrake 10.1 is fine for 
> running R.[1] I have Mandrake 10.1 (Community) at home 
> running on my notebook and I was able to compile R without 
> any problems - just using the software that was shipped with 
> this distribution.


It is certainly not necessary; even Windows is fine for running R.
However, assuming R is not the only package to be installed and then
upgraded, switching from something like Mandrake to something like
Mepis may result in significant time savings, which is what I care
about most. (Your mileage may vary.) I used Mdk for a couple of years
and prefer to not remember how many hours I wasted on something as
trivial as installing and upgrading packages. (Compilation will not
save you always from having to manually upgrade other libraries,
especially as your Mdk installation gets older.)



From spjgmwn at iop.kcl.ac.uk  Wed Mar 16 14:54:35 2005
From: spjgmwn at iop.kcl.ac.uk (Matthew W Nash)
Date: Wed, 16 Mar 2005 13:54:35 -0000
Subject: [R] RODBC, sqlSave and sqlAppend
In-Reply-To: <1db7268005031511393411ca71@mail.gmail.com>
Message-ID: <NDEAJMAPIIPDKHDMLLLOOEKNDAAA.spjgmwn@iop.kcl.ac.uk>

If anyone is interested, I found out that something (Access or ODBC?) didn't
like the column name 'Left', after changing it to something else, both
sqlSave and sqlUpdate are working as expected.

Thanks to those that replied.

Matthew Nash,

Post-Doctoral Research Worker,
GENDEP study,
SGDP, Institute of Psychiatry,
PO82, Room CB.15,
16 De Crespigny Park,
London, SE5 8AF,
United Kingdom

Phone: (+44) 207 848 0805

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~
Announcing the 6th MRC SGDP SUMMER SCHOOL 25 -? 29 July 2005 with courses in
a) Twin model fitting, Mx
b) Microarrays (Affymetrix), gene expression, SNPs
c) Linkage, association and allied methods
http://sgdp.iop.kcl.ac.uk/summerschool/

-----Original Message-----
From: roger bos [mailto:roger.bos at gmail.com]
Sent: 15 March 2005 19:40
To: spjgmwn at iop.kcl.ac.uk
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] RODBC, sqlSave and sqlAppend

I use RODBC all day every day and while I am pretty happy with it, I
was never able to make a table separately and append to it using
sqlSave.  Nevertheless, maybe my observations will help.

I always let sqlSave make the table for me.  Make sure the table
doesn't exist and it will make it.  I never use sqlAppend, I use
sqlSave(..., append=TRUE).  Also, how do you know you are not getting
an error.  Try 'go <- sqlSave(...)' and then type go and if it returns
'character(0)' then you have no error, otherwise you will see an
extremely brief hint of what went wrong.  Finally, I always have my
database open when I sqlSave and that is never a problem, so you don't
need to close MS access AFAIK.  Its probably easier to use sqlQuery
right after sqlSave to verify that it worked.

Once sqlSave works, then you can use standard SQL statements to alter
the table and alter to columns to make the datatypes whatever you want
and then use 'insert into' statements to move the data when you want.
So basically, because I save to a temporary table, alter the columns
to change the datatypes, and then copy that to my final table.  Sounds
like a lot of work, but it can be automated once you write the command
in R.

Maybe someone will provide you with a better answer, but this might
get you started.

Thanks,

Roger


On Tue, 15 Mar 2005 15:19:26 -0000, Matthew W Nash
<spjgmwn at iop.kcl.ac.uk> wrote:
> Hi all,
>
> I am currently trying to read, write and append data between R and MS
access
> using the RODBC library functions. I have no problems reading in the data
> but when using sqlSave and sqlAppend it doesn't seem to work. I have made
> sure that all the column names are sensible and there are no gaps etc in
the
> variables. My call looks like this:
>
> sqlSave(channel,treatlist,test=F)
>
> I've played with various options but what consistently happens is that R
> writes a new table (column names a written and sensible variable types are
> assigned), but it doesn't actually write any data into it. When I run
> sqlAppend there are no error messages, but when I look at the MS access
> database nothing has been written. (I always have the database closed when
> doing this.)
>
> What am I doing wrong?
>
> Matthew Nash,
>
> Post-Doctoral Research Worker,
> GENDEP study,
> SGDP, Institute of Psychiatry,
> PO82, Room CB.15,
> 16 De Crespigny Park,
> London, SE5 8AF,
> United Kingdom
>
> Phone: (+44) 207 848 0805
>
>
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> ~
> Announcing the 6th MRC SGDP SUMMER SCHOOL 25 - 29 July 2005 with courses
in
> a) Twin model fitting, Mx
> b) Microarrays (Affymetrix), gene expression, SNPs
> c) Linkage, association and allied methods
> http://sgdp.iop.kcl.ac.uk/summerschool/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From robert.pollak at scietec.at  Wed Mar 16 15:15:51 2005
From: robert.pollak at scietec.at (Robert Pollak)
Date: Wed, 16 Mar 2005 15:15:51 +0100
Subject: [R] Re: How to concatenate time series?
In-Reply-To: <A91EF0B9121F834EA6484582DFE1CF4436F731@messagerie.chm.com>
References: <A91EF0B9121F834EA6484582DFE1CF4436F731@messagerie.chm.com>
Message-ID: <42383F97.60900@scietec.at>

SAULEAU Erik-Andr? schrieb:
> Why not just ts.plot(USAccDeaths, dp$pred) ?

Because I did not look at help.search("time series") hard enough :)

Thank you for your help!



From Tristan.Lefebure at univ-lyon1.fr  Wed Mar 16 15:22:47 2005
From: Tristan.Lefebure at univ-lyon1.fr (Lefebure Tristan)
Date: Wed, 16 Mar 2005 15:22:47 +0100
Subject: [R] Mandrake 10.1
In-Reply-To: <d35b9da60503142346134a9229@mail.gmail.com>
References: <4235D611.80201@uniroma2.it>
	<d35b9da60503142346134a9229@mail.gmail.com>
Message-ID: <200503161522.47930.lefebure@univ-lyon1.fr>

I'm running R-2.0.0-1mdk.i586.rpm under Mandrake 10.1 without problem.
I know that there is a problem of dependency with other packages. 
Try that from a shell (eg: Konsole):

cd path_to_your_R_rpm
su
urpmi info-4.7-2.mdk
rpm -i R-2.0.0-1mdk.i586.rpm


Just a remark: While encountering problems under Linux, the "solution" is not 
to move to an other distribution... (in this way you will change of 
distribution each month, and become a super linux installer ... but not a 
good linux user)

HTH

Tristan 

On Tuesday 15 March 2005 08:46, miguel manese wrote:
> > I am trying to install the R-2.0.0-1mdk.i586.rpm
> > <http://cran.planetmirror.com/bin/linux/mandrake/10.0/R-2.0.0-1mdk.i586.r
> >pm > file   on mandrake 10.1. Since the file is, originally, meant for
> > Mandrake 10.0, it is not surprising me that the installation does not
> > work.
> >
> > The error message that I get can be translated in something like:
> > "impossible to install since the info is not satisfied".
> > Could you please help me in installing R on my Mandrake 10.1?
> >
> > PS If you feel to answer me,  consider that I am almost an absolute
> > beginner at linux:)

-- 
------------------------------------------------------------
Tristan LEFEBURE
Laboratoire d'?cologie des hydrosyst?mes fluviaux (UMR 5023)
Universit? Lyon I - Campus de la Doua
Bat. Darwin C 69622 Villeurbanne - France

Phone: (33) (0)4 26 23 44 02
Fax: (33) (0)4 72 43 15 23



From roger.bos at gmail.com  Wed Mar 16 15:37:52 2005
From: roger.bos at gmail.com (roger bos)
Date: Wed, 16 Mar 2005 09:37:52 -0500
Subject: [R] RODBC, sqlSave and sqlAppend
In-Reply-To: <NDEAJMAPIIPDKHDMLLLOOEKNDAAA.spjgmwn@iop.kcl.ac.uk>
References: <1db7268005031511393411ca71@mail.gmail.com>
	<NDEAJMAPIIPDKHDMLLLOOEKNDAAA.spjgmwn@iop.kcl.ac.uk>
Message-ID: <1db7268005031606372a2b10f@mail.gmail.com>

ODBC also doesn't like the name 'index' for a column name.  It also
doesn't like any '.' periods in the column name.  You can use a name
like 'from' as a column name, but then when you query it you have to
put [] around it because from is a sql key word.  Most of these issues
are sql issues rather than R issues, but still good to know and share.


On Wed, 16 Mar 2005 13:54:35 -0000, Matthew W Nash
<spjgmwn at iop.kcl.ac.uk> wrote:
> If anyone is interested, I found out that something (Access or ODBC?) didn't
> like the column name 'Left', after changing it to something else, both
> sqlSave and sqlUpdate are working as expected.
> 
> Thanks to those that replied.
> 
> Matthew Nash,
> 
> Post-Doctoral Research Worker,
> GENDEP study,
> SGDP, Institute of Psychiatry,
> PO82, Room CB.15,
> 16 De Crespigny Park,
> London, SE5 8AF,
> United Kingdom
> 
> Phone: (+44) 207 848 0805
> 
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> ~
> Announcing the 6th MRC SGDP SUMMER SCHOOL 25 -? 29 July 2005 with courses in
> a) Twin model fitting, Mx
> b) Microarrays (Affymetrix), gene expression, SNPs
> c) Linkage, association and allied methods
> http://sgdp.iop.kcl.ac.uk/summerschool/
> 
> -----Original Message-----
> From: roger bos [mailto:roger.bos at gmail.com]
> Sent: 15 March 2005 19:40
> To: spjgmwn at iop.kcl.ac.uk
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] RODBC, sqlSave and sqlAppend
> 
> I use RODBC all day every day and while I am pretty happy with it, I
> was never able to make a table separately and append to it using
> sqlSave.  Nevertheless, maybe my observations will help.
> 
> I always let sqlSave make the table for me.  Make sure the table
> doesn't exist and it will make it.  I never use sqlAppend, I use
> sqlSave(..., append=TRUE).  Also, how do you know you are not getting
> an error.  Try 'go <- sqlSave(...)' and then type go and if it returns
> 'character(0)' then you have no error, otherwise you will see an
> extremely brief hint of what went wrong.  Finally, I always have my
> database open when I sqlSave and that is never a problem, so you don't
> need to close MS access AFAIK.  Its probably easier to use sqlQuery
> right after sqlSave to verify that it worked.
> 
> Once sqlSave works, then you can use standard SQL statements to alter
> the table and alter to columns to make the datatypes whatever you want
> and then use 'insert into' statements to move the data when you want.
> So basically, because I save to a temporary table, alter the columns
> to change the datatypes, and then copy that to my final table.  Sounds
> like a lot of work, but it can be automated once you write the command
> in R.
> 
> Maybe someone will provide you with a better answer, but this might
> get you started.
> 
> Thanks,
> 
> Roger
> 
> On Tue, 15 Mar 2005 15:19:26 -0000, Matthew W Nash
> <spjgmwn at iop.kcl.ac.uk> wrote:
> > Hi all,
> >
> > I am currently trying to read, write and append data between R and MS
> access
> > using the RODBC library functions. I have no problems reading in the data
> > but when using sqlSave and sqlAppend it doesn't seem to work. I have made
> > sure that all the column names are sensible and there are no gaps etc in
> the
> > variables. My call looks like this:
> >
> > sqlSave(channel,treatlist,test=F)
> >
> > I've played with various options but what consistently happens is that R
> > writes a new table (column names a written and sensible variable types are
> > assigned), but it doesn't actually write any data into it. When I run
> > sqlAppend there are no error messages, but when I look at the MS access
> > database nothing has been written. (I always have the database closed when
> > doing this.)
> >
> > What am I doing wrong?
> >
> > Matthew Nash,
> >
> > Post-Doctoral Research Worker,
> > GENDEP study,
> > SGDP, Institute of Psychiatry,
> > PO82, Room CB.15,
> > 16 De Crespigny Park,
> > London, SE5 8AF,
> > United Kingdom
> >
> > Phone: (+44) 207 848 0805
> >
> >
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> > ~
> > Announcing the 6th MRC SGDP SUMMER SCHOOL 25 - 29 July 2005 with courses
> in
> > a) Twin model fitting, Mx
> > b) Microarrays (Affymetrix), gene expression, SNPs
> > c) Linkage, association and allied methods
> > http://sgdp.iop.kcl.ac.uk/summerschool/
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From r.hankin at soc.soton.ac.uk  Wed Mar 16 16:05:56 2005
From: r.hankin at soc.soton.ac.uk (Robin Hankin)
Date: Wed, 16 Mar 2005 15:05:56 +0000
Subject: [R] problem solved and new insight
Message-ID: <a9ac7e26f6f867ad49ce8ab07abfcdd0@soc.soton.ac.uk>

Hi

just now I had an apparently insurmountable problem
that's been bugging me for days, but phrasing my question in a form
suitable for the R-help list enabled me to solve my own problem
in two minutes flat.


thanks everyone.


--
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From tlumley at u.washington.edu  Wed Mar 16 16:16:49 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 16 Mar 2005 07:16:49 -0800 (PST)
Subject: [R] How to extract x rows to get  x pvalues using t.test
In-Reply-To: <3A822319EB35174CA3714066D590DCD50994E866@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50994E866@usrymx25.merck.com>
Message-ID: <Pine.A41.4.61b.0503160706140.97642@homer04.u.washington.edu>

On Tue, 15 Mar 2005, Liaw, Andy wrote:

>> From: Adaikalavan Ramasamy
>>
>> You will need to _apply_ the t-test row by row.
>>
>>    apply( genes, 1, function(x) t.test( x[1:2], x[3:4] )$p.value )
>>
>> apply() is a C optimised version of for. Running the above code on a
>> dataset with 56000 rows and 4 columns took about 63 seconds on my 1.6
>> GHz Pentium machine with 512 Mb RAM. See help("apply") for
>> more details.
>
> That's not true.  In R, there's a for loop hidden inside apply() (just look
> at the source).  In S-PLUS, C level looping is done in some situations, and
> for others lapply() is used.
>

It's slightly more complicated than this.  lapply() really is a C-level 
loop and apply() eventually calls it.

Now, whatever happends inside apply(), it still true that t.test() has to 
be called 56,000 times, providing a lower bound on the time apply() can 
take. In this case I would be very surprised if apply() saved any time. 
What would save time is writing a stripped-down t-test function, 
especially as only the p-value is being used.

The real problem with apply is that when the objects involved are large, 
apply() can be substantially slower because of greater memory use.  As a 
concrete example, an apply() on a 10000x757 set of replicate weights in 
the survey package used half as much memory when turned into a for() loop. 
As a result it ran several times faster on my laptop (where it was paging 
heavily) and slightly faster on my desktop (which has rather more memory).


 	-thomas



From lzhtom at hotmail.com  Wed Mar 16 16:35:48 2005
From: lzhtom at hotmail.com (zhihua li)
Date: Wed, 16 Mar 2005 15:35:48 +0000
Subject: [R] Are there any R packages that can deduce causal relationship
	between variables?
Message-ID: <BAY12-F177A5411C101273DB184EBC7480@phx.gbl>

Hi netters.

Assume Y = {Y1,.....Yn} and X = {X1......Xm}, where Yi and Xi are random 
variables that can take on discrete values from V={0,1,2}.
Each Yi in Y has some (0-k) parent variables in X, which means given the 
values of the parent variables (Xi0....Xik) the values of Yi is set. Yi = 
F(Xi0,...Xik), where F is a mapping function from parents to sons.
Considering there are some noise in the data, we can put it in a 
probabilistic way: the parents and sons have the joint probability 
distribution P(Yi) = P(Yi|Xi0...Xik). 

Now I have a training dataset D, which includes a series of instances of Y 
and X.
For each Yi, I want to find its parent variables (Xi0...Xik) in X and the 
mapping function F so that in most cases Yi = F(Xi0,...Xik). 
In terms of probabilistics, I want to find the joint probability 
distribution  P(Yi|Xi0...Xik) , that best matches D.

I realized it's not a simple task. I've read papers describing how to solve 
this problem using Bayesian Networks. But it's way too difficult for me to 
understand.

So are there any R packages that can solve this problem in a neat way?

Thanks a lot!



From zhongmingyang at yahoo.com  Wed Mar 16 17:07:21 2005
From: zhongmingyang at yahoo.com (Zhongming Yang)
Date: Wed, 16 Mar 2005 08:07:21 -0800 (PST)
Subject: [R] how to draw xyplot figure like figure 4.18 of MASS (4th) ? 
Message-ID: <20050316160721.62072.qmail@web51310.mail.yahoo.com>

Dear All:
 
Could you please tell me how I can draw figure formatted like figure 4.18 of MASS (4th) with the attached data set?
 
Thanks
 
Zhongming Yang


		
---------------------------------

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: sample.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050316/abfdb85e/sample.txt

From msvika at mscc.huji.ac.il  Wed Mar 16 17:21:47 2005
From: msvika at mscc.huji.ac.il (Vicky Landsman)
Date: Wed, 16 Mar 2005 18:21:47 +0200
Subject: [R] Summing up matrices in a list 
Message-ID: <002d01c52a44$40d23d70$a200a8c0@HOME2>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050316/6e0cc8eb/attachment.pl

From ligges at statistik.uni-dortmund.de  Wed Mar 16 17:26:54 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 16 Mar 2005 17:26:54 +0100
Subject: [R] how to draw xyplot figure like figure 4.18 of MASS (4th)
 ?
In-Reply-To: <20050316160721.62072.qmail@web51310.mail.yahoo.com>
References: <20050316160721.62072.qmail@web51310.mail.yahoo.com>
Message-ID: <42385E4E.9090209@statistik.uni-dortmund.de>

Zhongming Yang wrote:

> Dear All:
>  
> Could you please tell me how I can draw figure formatted like figure 4.18 of MASS (4th) with the attached data set?

The example is given on page 101.

Uwe Ligges




> Thanks
>  
> Zhongming Yang
> 
> 
> 		
> ---------------------------------
> 
> 
> 
> ------------------------------------------------------------------------
> 
>       md idno     month group
>   -0.090  521  0.000000    NN
>   -1.330  521 12.460274    NN
>   -0.570  521 14.991781    NN
>   -2.130  559  0.000000    NN
>   -0.920  559  3.978082    NN
>   -1.730  559  6.016438    NN
>   -2.390  559  9.665753    NN
>   -1.300  559 12.460274    NN
>   -2.170  559 15.682192    NN
>   -2.620  559 17.950685    NN
>   -1.830  559 21.664406    NN
>   -3.090  559 25.533258    NN
>   -2.760  559 30.811947    NN
>   -1.240  559 33.830137    NN
>   -0.650  559 36.394521    NN
>   -1.200  559 38.893151    NN
>   -1.320  559 42.147945    NN
>   -2.000  559 45.600000    NN
>   -2.150  559 48.328767    NN
>   -1.430  559 52.569863    NN
>   -2.650  559 56.120548    NN
>   -0.870  559 60.032877    NN
>   -1.920  559 63.550685    NN
>   -2.320  559 65.786301    NN
>   -2.640  559 68.547945    NN
>   -2.030  559 71.533258    NN
>   -1.900  559 75.500472    NN
>   -1.420  559 78.254570    NN
>   -1.330  559 81.863014    NN
>   -2.120  559 84.657534    NN
>   -2.400  559 86.926027    NN
>   -2.410  559 90.147945    NN
>   -3.370  559 93.369863    NN
>   -0.720  559 96.624658    NN
>   -2.075  598  0.000000    NN
>   -2.260  598  3.484932    NN
>   -2.150  598  5.917808    NN
>   -1.420  598  9.828879    NN
>   -1.490  598 12.353470    NN
>   -3.040  598 16.025601    NN
>   -1.960  598 18.845273    NN
>   -2.780  598 22.224658    NN
>   -3.310  598 24.591781    NN
>   -4.420  598 27.517808    NN
>   -1.890  598 30.312329    NN
>   -3.000  598 33.304110    NN
>   -2.260  598 36.065753    NN
>   -0.730  598 40.010959    NN
>   -2.710  598 43.232877    NN
>   -2.430  598 45.994521    NN
>   -1.050  598 49.183562    NN
>   -2.190  598 52.438356    NN
>   -0.580  598 54.969863    NN
>   -2.050  598 57.501011    NN
>   -1.480  598 60.681338    NN
>   -0.960  598 63.664945    NN
>   -2.090  598 66.419043    NN
>   -3.180  598 69.435616    NN
>   -1.230  598 72.394521    NN
>   -2.170  598 74.761644    NN
>   -2.400  598 78.378082    NN
>   -3.630  598 81.698630    NN
>   -2.100  598 84.920548    NN
>   -3.940  598 87.156164    NN
>   -3.780  598 90.378082    NN
>   -5.690  598 95.967123    NN
>  -13.525  622  0.000000    NN
>  -12.670  622  3.680934    NN
>  -13.500  622  7.123557    NN
>  -13.700  622  9.910442    NN
>  -11.260  622 12.926836    NN
>  -12.100  622 15.846575    NN
>  -13.400  622 18.410959    NN
>  -12.330  622 21.435616    NN
>  -12.940  622 24.197260    NN
>  -12.540  622 27.156164    NN
>  -12.550  622 29.917808    NN
>  -11.900  622 33.830137    NN
>  -11.640  622 36.394521    NN
>  -12.100  622 38.893151    NN
>  -11.010  622 41.457534    NN
>  -12.050  622 46.684932    NN
>  -12.650  622 50.136986    NN
>  -11.620  622 54.303885    NN
>  -12.150  622 58.303885    NN
>  -12.990  622 60.959623    NN
>  -12.590  622 63.912329    NN
>  -13.570  622 66.936986    NN
>  -12.480  622 69.336986    NN
>  -12.800  622 72.263014    NN
>  -12.640  622 75.452055    NN
>  -13.830  622 81.073973    NN
>  -13.250  622 84.295890    NN
>  -13.700  622 90.213699    NN
>  -13.250  622 96.197260    NN
>   -2.190  801  0.000000    NN
>   -1.250  801  2.663014    NN
>   -1.550  801  5.589041    NN
>   -1.570  801  8.575612    NN
>   -0.880  801 11.755940    NN
>   -0.230  801 15.428071    NN
>   -0.770  801 17.985448    NN
>   -1.050  801 20.975342    NN
>   -2.260  801 24.394521    NN
>   -2.760  801 27.715068    NN
>   -1.550  801 29.950685    NN
>   -2.330  801 34.093151    NN
>   -1.390  801 36.394521    NN
>   -2.090  801 39.353425    NN
>   -3.050  801 41.917808    NN
>   -1.930  801 44.646575    NN
>   -4.040  801 48.328767    NN
>   -3.260  801 51.780822    NN
>   -2.810  801 54.115068    NN
>   -0.660  801 57.395284    NN
>   -1.800  801 62.903481    NN
>   -1.540  801 65.755940    NN
>   -0.880  801 69.567123    NN
>   -2.000  801 73.117808    NN
>   -1.610  801 76.142466    NN
>   -4.360  801 79.463014    NN
>   -3.200  801 80.712329    NN
>   -3.080  801 83.013699    NN
>   -2.350  801 88.306849    NN
>   -3.170  801 89.917808    NN
>   -3.570  801 95.342466    NN
>   -3.300  525  0.000000    TP
>   -2.500  525  2.991781    TP
>   -5.480  525  5.917808    TP
>   -1.140  525  8.712329    TP
>   -2.260  525 11.967123    TP
>   -0.670  525 14.926027    TP
>   -0.630  525 17.950685    TP
>   -0.600  525 21.336986    TP
>   -1.870  525 24.427397    TP
>   -1.790  525 26.860274    TP
>   -3.640  525 30.771345    TP
>   -2.860  525 33.328722    TP
>   -2.140  525 37.197575    TP
>   -1.560  525 39.787739    TP
>   -0.360  525 42.542466    TP
>   -1.900  525 45.304110    TP
>   -1.190  525 48.032877    TP
>   -3.090  525 51.024658    TP
>   -2.620  525 53.786301    TP
>   -1.360  525 58.126027    TP
>   -1.130  525 60.953425    TP
>   -1.390  525 64.142466    TP
>   -0.270  525 66.904110    TP
>   -1.640  525 69.665753    TP
>   -1.390  525 72.887671    TP
>   -2.550  525 75.221918    TP
>   -2.540  525 78.180822    TP
>   -1.640  525 81.623804    TP
>   -2.410  525 84.574624    TP
>   -2.530  525 88.017247    TP
>   -1.980  525 91.463014    TP
>   -3.060  525 93.895890    TP
>   -1.920  525 96.131507    TP
>   -1.650  525 99.320548    TP
>   -2.625  527  0.000000    TP
>   -2.370  527  2.991781    TP
>    0.050  527  6.180822    TP
>   -0.270  527  9.041096    TP
>    1.060  527 11.736986    TP
>   -3.030  527 15.221918    TP
>   -1.000  527 18.180822    TP
>   -1.270  527 21.895890    TP
>   -1.910  527 24.361644    TP
>   -2.350  527 27.649315    TP
>   -3.720  527 30.142825    TP
>   -3.310  527 33.355940    TP
>   -2.280  527 35.847743    TP
>   -1.860  527 39.290366    TP
>   -5.050  527 42.345205    TP
>   -3.160  527 45.106849    TP
>   -2.270  527 47.802740    TP
>   -1.850  527 50.630137    TP
>   -4.010  527 53.621918    TP
>   -4.520  527 56.383562    TP
>   -3.820  527 60.000000    TP
>   -6.440  527 65.293151    TP
>   -4.600  527 68.350685    TP
>   -5.280  527 71.802740    TP
>   -3.920  527 75.320548    TP
>   -5.080  527 78.175612    TP
>   -8.550  527 80.831350    TP
>   -4.900  527 84.601841    TP
>  -11.620  527 87.585448    TP
>   -6.090  527 91.956164    TP
>   -7.120  527 95.408219    TP
>   -6.365  570  0.000000    TP
>   -6.100  570  2.761644    TP
>   -4.950  570  5.983562    TP
>   -5.530  570  9.205479    TP
>   -3.640  570 11.967123    TP
>   -3.330  570 15.879452    TP
>   -4.950  570 18.310442    TP
>   -5.250  570 21.392410    TP
>   -5.540  570 24.376016    TP
>   -4.300  570 27.359623    TP
>   -4.530  570 29.884932    TP
>   -5.970  570 32.646575    TP
>   -4.950  570 37.019178    TP
>   -5.090  570 39.320548    TP
>   -4.000  570 42.312329    TP
>   -6.160  570 45.073973    TP
>   -6.490  570 49.216438    TP
>   -4.890  570 52.668493    TP
>   -6.620  570 56.350685    TP
>   -7.010  570 61.183562    TP
>   -7.290  570 63.978082    TP
>   -6.440  570 66.736672    TP
>   -7.950  570 69.917000    TP
>   -7.570  570 73.130115    TP
>   -8.150  570 76.113721    TP
>   -8.090  570 78.805479    TP
>   -9.670  570 82.553425    TP
>   -9.480  570 86.169863    TP
>   -9.120  570 90.147945    TP
>  -11.330  570 97.019178    TP
>   -3.750  615  0.000000    TP
>   -3.510  615  3.287671    TP
>   -4.160  615  5.848641    TP
>   -5.170  615  9.651920    TP
>   -4.600  615 12.438805    TP
>   -5.940  615 15.619133    TP
>   -6.270  615 18.608219    TP
>   -4.690  615 21.632877    TP
>   -7.820  615 24.361644    TP
>   -5.940  615 27.189041    TP
>   -5.680  615 30.180822    TP
>   -6.750  615 32.712329    TP
>   -5.130  615 36.854795    TP
>   -6.630  615 39.386301    TP
>   -7.450  615 41.917808    TP
>   -7.290  615 45.369863    TP
>   -9.590  615 48.361644    TP
>   -9.700  615 51.353425    TP
>   -9.570  615 54.799461    TP
>   -9.840  615 57.783068    TP
>   -9.800  615 60.766674    TP
>  -11.000  615 63.291264    TP
>  -11.360  615 66.805479    TP
>  -10.860  615 69.731507    TP
>  -10.610  615 72.493151    TP
>  -12.180  615 78.706849    TP
>  -12.570  615 84.690411    TP
>  -13.280  615 90.213699    TP
>  -15.720  615 96.197260    TP
>    0.375  818  0.000000    TP
>    1.640  818  2.491803    TP
>   -5.190  818  5.967213    TP
>   -3.080  818  9.674018    TP
>   -4.020  818 12.402785    TP
>   -6.380  818 15.854839    TP
>   -4.570  818 17.926072    TP
>   -5.380  818 21.608264    TP
>   -7.210  818 25.060319    TP
>   -8.560  818 27.854839    TP
>   -7.300  818 30.156209    TP
>   -7.590  818 33.312374    TP
>   -7.050  818 36.600045    TP
>   -7.350  818 38.046620    TP
>   -9.040  818 41.893196    TP
>   -8.340  818 45.573770    TP
>   -6.890  818 48.131148    TP
>   -7.190  818 54.098361    TP
>   -7.690  818 57.312374    TP
>   -9.340  818 60.468538    TP
>   -9.580  818 62.572648    TP
>  -10.180  818 65.827442    TP
>   -9.000  818 69.443881    TP
>  -10.760  818 71.547990    TP
>  -10.580  818 74.112374    TP
>  -10.500  818 78.221963    TP
>  -10.460  818 83.252100    TP
>   -9.980  818 89.071278    TP
>   -4.540  535  0.000000    SN
>   -6.050  535  3.221918    SN
>   -4.040  535  5.983562    SN
>   -2.940  535  8.843836    SN
>   -4.360  535 12.197260    SN
>   -3.760  535 14.958904    SN
>   -2.780  535 18.641096    SN
>   -6.140  535 21.402740    SN
>   -6.070  535 24.164384    SN
>   -6.530  535 27.450528    SN
>   -7.320  535 31.057085    SN
>   -6.270  535 33.778397    SN
>   -6.480  535 36.991511    SN
>   -7.440  535 39.747945    SN
>   -9.400  535 42.509589    SN
>   -6.640  535 45.534247    SN
>   -6.170  535 48.098630    SN
>   -5.090  535 51.090411    SN
>   -4.660  535 53.786301    SN
>   -5.420  535 58.158904    SN
>   -8.420  535 60.920548    SN
>   -4.830  535 63.682192    SN
>   -5.210  535 66.673973    SN
>   -5.030  535 69.961644    SN
>   -4.720  535 72.460274    SN
>   -5.570  535 75.253806    SN
>   -4.240  535 79.122659    SN
>   -5.620  535 82.302987    SN
>   -5.180  535 85.286593    SN
>   -4.560  535 88.076712    SN
>   -3.730  535 91.265753    SN
>   -4.490  535 95.473973    SN
>   -5.010  535 99.221918    SN
>   -3.645  541  0.000000    SN
>   -2.130  541  3.024658    SN
>   -2.240  541  6.016438    SN
>   -4.490  541  9.073973    SN
>   -3.310  541 12.000000    SN
>   -3.320  541 16.339726    SN
>   -4.130  541 18.246575    SN
>   -3.640  541 21.271233    SN
>   -3.510  541 24.624658    SN
>   -5.260  541 27.612666    SN
>   -3.340  541 30.825780    SN
>   -3.990  541 33.678239    SN
>   -5.390  541 37.022502    SN
>   -9.960  541 39.616438    SN
>   -3.740  541 43.002740    SN
>   -4.550  541 45.600000    SN
>   -3.370  541 48.295890    SN
>   -4.810  541 50.893151    SN
>   -3.130  541 53.654795    SN
>   -3.770  541 57.632877    SN
>   -3.820  541 60.558904    SN
>   -5.160  541 63.090411    SN
>   -3.530  541 66.016438    SN
>   -4.690  567  0.000000    SN
>   -4.030  567  2.991781    SN
>   -2.080  567  6.049315    SN
>   -2.430  567  9.698630    SN
>   -3.500  567 12.723288    SN
>   -2.690  567 15.189041    SN
>   -3.260  567 18.476712    SN
>   -4.890  567 21.460768    SN
>   -3.940  567 24.673883    SN
>   -4.150  567 28.313227    SN
>   -2.570  567 31.068493    SN
>   -3.290  567 33.402740    SN
>   -2.650  567 36.394521    SN
>   -1.220  567 39.353425    SN
>   -2.230  567 45.764384    SN
>   -2.780  567 48.526027    SN
>   -3.230  567 51.780822    SN
>   -3.470  567 54.542466    SN
>   -2.440  567 57.041096    SN
>   -4.170  567 61.249315    SN
>   -3.440  567 63.715068    SN
>   -1.880  567 66.279452    SN
>   -2.150  567 69.231260    SN
>   -2.150  567 72.673883    SN
>   -7.010  567 89.720548    SN
>   -4.640  567 94.520548    SN
>   -5.600  567 96.723288    SN
>   -2.375  572  0.000000    SN
>   -2.920  572  3.452055    SN
>   -1.310  572  6.246575    SN
>   -1.890  572 10.158904    SN
>   -2.450  572 12.558904    SN
>   -2.590  572 15.189041    SN
>   -2.040  572 18.308826    SN
>   -1.570  572 21.685875    SN
>   -1.930  572 24.472760    SN
>   -1.300  572 27.817022    SN
>   -2.820  572 30.641096    SN
>   -1.240  572 33.600000    SN
>   -0.720  572 36.394521    SN
>   -0.440  572 39.156164    SN
>   -0.750  572 41.917808    SN
>   -1.310  572 45.567123    SN
>   -1.060  572 48.756164    SN
>   -0.670  572 51.517808    SN
>   -1.110  572 54.279452    SN
>   -0.870  572 57.501370    SN
>   -2.400  572 60.493151    SN
>   -1.790  572 63.484932    SN
>   -1.150  572 66.308826    SN
>   -0.550  572 68.800629    SN
>   -1.830  572 72.112104    SN
>   -1.830  572 75.030137    SN
>   -1.640  572 78.772603    SN
>   -2.340  572 81.468493    SN
>   -2.490  572 86.136986    SN
>   -1.840  572 90.147945    SN
>   -1.760  572 93.369863    SN
>   -0.970  572 96.657534    SN
>   -0.960  583  0.000000    SN
>   -1.150  583  3.189041    SN
>   -2.060  583  7.364384    SN
>   -1.710  583  9.402740    SN
>   -0.870  583 12.427397    SN
>   -2.100  583 15.185179    SN
>   -1.290  583 18.660588    SN
>   -1.350  583 21.185179    SN
>   -0.410  583 24.824523    SN
>   -2.750  583 27.550685    SN
>   -1.860  583 30.345205    SN
>   -1.750  583 33.336986    SN
>    0.360  583 36.098630    SN
>   -1.200  583 38.893151    SN
>   -0.900  583 42.575342    SN
>   -1.350  583 45.501370    SN
>   -0.660  583 48.526027    SN
>   -0.950  583 51.254795    SN
>   -1.690  583 54.279452    SN
>   -0.410  583 57.073973    SN
>   -1.090  583 60.295890    SN
>   -0.590  583 63.021244    SN
>   -0.800  583 66.004851    SN
>   -0.700  583 69.250752    SN
>   -0.990  583 72.627801    SN
>   -0.240  583 75.879452    SN
>   -0.180  583 78.673973    SN
>   -1.000  583 81.402740    SN
>   -1.360  583 84.164384    SN
>   -1.240  583 86.958904    SN
>   -1.500  583 90.246575    SN
>   -1.410  583 93.468493    SN
>   -4.260  583 96.230137    SN
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From dimitris.rizopoulos at med.kuleuven.ac.be  Wed Mar 16 17:29:00 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Wed, 16 Mar 2005 17:29:00 +0100
Subject: [R] Summing up matrices in a list 
References: <002d01c52a44$40d23d70$a200a8c0@HOME2>
Message-ID: <018801c52a45$427d8700$0540210a@www.domain>

try this:

matSums <- function(lis, na.rm=FALSE){
    if(!is.list(lis) || !all(sapply(lis, is.matrix))) stop("'lis' must 
be a list containing 2-dimensional arrays")
    dims <- sapply(lis, dim)
    n <- dims[1, 1]
    p <- dims[2, 1]
    if(!all(n == dims[1, ]) || !all(p == dims[2, ])) stop("the 
matrices must have the same dimensions")
    mat <- matrix(unlist(lis), n * p, length(lis))
    matrix(rowSums(mat, na.rm=na.rm), n, p)
}
#########
mylist <- list(matrix(1:6, 2), matrix(7:12, 2))
matSums(mylist)


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Vicky Landsman" <msvika at mscc.huji.ac.il>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, March 16, 2005 5:21 PM
Subject: [R] Summing up matrices in a list


> Dear all,
> I think that my question is very simple but I failed to solve it.
> I have a list which elements are matrices like this:
>
>>mylist
> [[1]]
>     [,1] [,2] [,3]
> [1,]    1    3    5
> [2,]    2    4    6
>
> [[2]]
>     [,1] [,2] [,3]
> [1,]    7    9   11
> [2,]    8   10   12
>
> I'd like to create a matrix M<-mylist[[1]]+mylist[[2]]
>     [,1] [,2] [,3]
> [1,]    8   12   16
> [2,]   10   14   18
>
> Is there a way to create M without looping?
> Thanks a lot,
> Vicky Landsman.
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From gerifalte28 at hotmail.com  Wed Mar 16 17:29:48 2005
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Wed, 16 Mar 2005 16:29:48 +0000
Subject: [R] how to draw xyplot figure like figure 4.18 of MASS (4th) ?
In-Reply-To: <20050316160721.62072.qmail@web51310.mail.yahoo.com>
Message-ID: <BAY103-F1B872121C8E1E8DD6EAC7A6480@phx.gbl>

Dear Zhongming,

By asking for the figure in the book you are restricting you question to 
only the people that has the 4th edition.  I would love to help you but 
unfortunatelly I have the 3rd edition of MASS and there is no figure 4.18 
since chapter 4 is "Programming in S".  Please give us an idea of what you 
want to do and we might be able to help you without looking at the book.

Cheers

Francisco

>From: Zhongming Yang <zhongmingyang at yahoo.com>
>To: r-help at stat.math.ethz.ch
>Subject: [R] how to draw xyplot figure like figure 4.18 of MASS (4th) ? 
>Date: Wed, 16 Mar 2005 08:07:21 -0800 (PST)
>
>Dear All:
>
>Could you please tell me how I can draw figure formatted like figure 4.18 
>of MASS (4th) with the attached data set?
>
>Thanks
>
>Zhongming Yang
>
>
>
>---------------------------------
>
>       md idno     month group
>   -0.090  521  0.000000    NN
>   -1.330  521 12.460274    NN
>   -0.570  521 14.991781    NN
>   -2.130  559  0.000000    NN
>   -0.920  559  3.978082    NN
>   -1.730  559  6.016438    NN
>   -2.390  559  9.665753    NN
>   -1.300  559 12.460274    NN
>   -2.170  559 15.682192    NN
>   -2.620  559 17.950685    NN
>   -1.830  559 21.664406    NN
>   -3.090  559 25.533258    NN
>   -2.760  559 30.811947    NN
>   -1.240  559 33.830137    NN
>   -0.650  559 36.394521    NN
>   -1.200  559 38.893151    NN
>   -1.320  559 42.147945    NN
>   -2.000  559 45.600000    NN
>   -2.150  559 48.328767    NN
>   -1.430  559 52.569863    NN
>   -2.650  559 56.120548    NN
>   -0.870  559 60.032877    NN
>   -1.920  559 63.550685    NN
>   -2.320  559 65.786301    NN
>   -2.640  559 68.547945    NN
>   -2.030  559 71.533258    NN
>   -1.900  559 75.500472    NN
>   -1.420  559 78.254570    NN
>   -1.330  559 81.863014    NN
>   -2.120  559 84.657534    NN
>   -2.400  559 86.926027    NN
>   -2.410  559 90.147945    NN
>   -3.370  559 93.369863    NN
>   -0.720  559 96.624658    NN
>   -2.075  598  0.000000    NN
>   -2.260  598  3.484932    NN
>   -2.150  598  5.917808    NN
>   -1.420  598  9.828879    NN
>   -1.490  598 12.353470    NN
>   -3.040  598 16.025601    NN
>   -1.960  598 18.845273    NN
>   -2.780  598 22.224658    NN
>   -3.310  598 24.591781    NN
>   -4.420  598 27.517808    NN
>   -1.890  598 30.312329    NN
>   -3.000  598 33.304110    NN
>   -2.260  598 36.065753    NN
>   -0.730  598 40.010959    NN
>   -2.710  598 43.232877    NN
>   -2.430  598 45.994521    NN
>   -1.050  598 49.183562    NN
>   -2.190  598 52.438356    NN
>   -0.580  598 54.969863    NN
>   -2.050  598 57.501011    NN
>   -1.480  598 60.681338    NN
>   -0.960  598 63.664945    NN
>   -2.090  598 66.419043    NN
>   -3.180  598 69.435616    NN
>   -1.230  598 72.394521    NN
>   -2.170  598 74.761644    NN
>   -2.400  598 78.378082    NN
>   -3.630  598 81.698630    NN
>   -2.100  598 84.920548    NN
>   -3.940  598 87.156164    NN
>   -3.780  598 90.378082    NN
>   -5.690  598 95.967123    NN
>  -13.525  622  0.000000    NN
>  -12.670  622  3.680934    NN
>  -13.500  622  7.123557    NN
>  -13.700  622  9.910442    NN
>  -11.260  622 12.926836    NN
>  -12.100  622 15.846575    NN
>  -13.400  622 18.410959    NN
>  -12.330  622 21.435616    NN
>  -12.940  622 24.197260    NN
>  -12.540  622 27.156164    NN
>  -12.550  622 29.917808    NN
>  -11.900  622 33.830137    NN
>  -11.640  622 36.394521    NN
>  -12.100  622 38.893151    NN
>  -11.010  622 41.457534    NN
>  -12.050  622 46.684932    NN
>  -12.650  622 50.136986    NN
>  -11.620  622 54.303885    NN
>  -12.150  622 58.303885    NN
>  -12.990  622 60.959623    NN
>  -12.590  622 63.912329    NN
>  -13.570  622 66.936986    NN
>  -12.480  622 69.336986    NN
>  -12.800  622 72.263014    NN
>  -12.640  622 75.452055    NN
>  -13.830  622 81.073973    NN
>  -13.250  622 84.295890    NN
>  -13.700  622 90.213699    NN
>  -13.250  622 96.197260    NN
>   -2.190  801  0.000000    NN
>   -1.250  801  2.663014    NN
>   -1.550  801  5.589041    NN
>   -1.570  801  8.575612    NN
>   -0.880  801 11.755940    NN
>   -0.230  801 15.428071    NN
>   -0.770  801 17.985448    NN
>   -1.050  801 20.975342    NN
>   -2.260  801 24.394521    NN
>   -2.760  801 27.715068    NN
>   -1.550  801 29.950685    NN
>   -2.330  801 34.093151    NN
>   -1.390  801 36.394521    NN
>   -2.090  801 39.353425    NN
>   -3.050  801 41.917808    NN
>   -1.930  801 44.646575    NN
>   -4.040  801 48.328767    NN
>   -3.260  801 51.780822    NN
>   -2.810  801 54.115068    NN
>   -0.660  801 57.395284    NN
>   -1.800  801 62.903481    NN
>   -1.540  801 65.755940    NN
>   -0.880  801 69.567123    NN
>   -2.000  801 73.117808    NN
>   -1.610  801 76.142466    NN
>   -4.360  801 79.463014    NN
>   -3.200  801 80.712329    NN
>   -3.080  801 83.013699    NN
>   -2.350  801 88.306849    NN
>   -3.170  801 89.917808    NN
>   -3.570  801 95.342466    NN
>   -3.300  525  0.000000    TP
>   -2.500  525  2.991781    TP
>   -5.480  525  5.917808    TP
>   -1.140  525  8.712329    TP
>   -2.260  525 11.967123    TP
>   -0.670  525 14.926027    TP
>   -0.630  525 17.950685    TP
>   -0.600  525 21.336986    TP
>   -1.870  525 24.427397    TP
>   -1.790  525 26.860274    TP
>   -3.640  525 30.771345    TP
>   -2.860  525 33.328722    TP
>   -2.140  525 37.197575    TP
>   -1.560  525 39.787739    TP
>   -0.360  525 42.542466    TP
>   -1.900  525 45.304110    TP
>   -1.190  525 48.032877    TP
>   -3.090  525 51.024658    TP
>   -2.620  525 53.786301    TP
>   -1.360  525 58.126027    TP
>   -1.130  525 60.953425    TP
>   -1.390  525 64.142466    TP
>   -0.270  525 66.904110    TP
>   -1.640  525 69.665753    TP
>   -1.390  525 72.887671    TP
>   -2.550  525 75.221918    TP
>   -2.540  525 78.180822    TP
>   -1.640  525 81.623804    TP
>   -2.410  525 84.574624    TP
>   -2.530  525 88.017247    TP
>   -1.980  525 91.463014    TP
>   -3.060  525 93.895890    TP
>   -1.920  525 96.131507    TP
>   -1.650  525 99.320548    TP
>   -2.625  527  0.000000    TP
>   -2.370  527  2.991781    TP
>    0.050  527  6.180822    TP
>   -0.270  527  9.041096    TP
>    1.060  527 11.736986    TP
>   -3.030  527 15.221918    TP
>   -1.000  527 18.180822    TP
>   -1.270  527 21.895890    TP
>   -1.910  527 24.361644    TP
>   -2.350  527 27.649315    TP
>   -3.720  527 30.142825    TP
>   -3.310  527 33.355940    TP
>   -2.280  527 35.847743    TP
>   -1.860  527 39.290366    TP
>   -5.050  527 42.345205    TP
>   -3.160  527 45.106849    TP
>   -2.270  527 47.802740    TP
>   -1.850  527 50.630137    TP
>   -4.010  527 53.621918    TP
>   -4.520  527 56.383562    TP
>   -3.820  527 60.000000    TP
>   -6.440  527 65.293151    TP
>   -4.600  527 68.350685    TP
>   -5.280  527 71.802740    TP
>   -3.920  527 75.320548    TP
>   -5.080  527 78.175612    TP
>   -8.550  527 80.831350    TP
>   -4.900  527 84.601841    TP
>  -11.620  527 87.585448    TP
>   -6.090  527 91.956164    TP
>   -7.120  527 95.408219    TP
>   -6.365  570  0.000000    TP
>   -6.100  570  2.761644    TP
>   -4.950  570  5.983562    TP
>   -5.530  570  9.205479    TP
>   -3.640  570 11.967123    TP
>   -3.330  570 15.879452    TP
>   -4.950  570 18.310442    TP
>   -5.250  570 21.392410    TP
>   -5.540  570 24.376016    TP
>   -4.300  570 27.359623    TP
>   -4.530  570 29.884932    TP
>   -5.970  570 32.646575    TP
>   -4.950  570 37.019178    TP
>   -5.090  570 39.320548    TP
>   -4.000  570 42.312329    TP
>   -6.160  570 45.073973    TP
>   -6.490  570 49.216438    TP
>   -4.890  570 52.668493    TP
>   -6.620  570 56.350685    TP
>   -7.010  570 61.183562    TP
>   -7.290  570 63.978082    TP
>   -6.440  570 66.736672    TP
>   -7.950  570 69.917000    TP
>   -7.570  570 73.130115    TP
>   -8.150  570 76.113721    TP
>   -8.090  570 78.805479    TP
>   -9.670  570 82.553425    TP
>   -9.480  570 86.169863    TP
>   -9.120  570 90.147945    TP
>  -11.330  570 97.019178    TP
>   -3.750  615  0.000000    TP
>   -3.510  615  3.287671    TP
>   -4.160  615  5.848641    TP
>   -5.170  615  9.651920    TP
>   -4.600  615 12.438805    TP
>   -5.940  615 15.619133    TP
>   -6.270  615 18.608219    TP
>   -4.690  615 21.632877    TP
>   -7.820  615 24.361644    TP
>   -5.940  615 27.189041    TP
>   -5.680  615 30.180822    TP
>   -6.750  615 32.712329    TP
>   -5.130  615 36.854795    TP
>   -6.630  615 39.386301    TP
>   -7.450  615 41.917808    TP
>   -7.290  615 45.369863    TP
>   -9.590  615 48.361644    TP
>   -9.700  615 51.353425    TP
>   -9.570  615 54.799461    TP
>   -9.840  615 57.783068    TP
>   -9.800  615 60.766674    TP
>  -11.000  615 63.291264    TP
>  -11.360  615 66.805479    TP
>  -10.860  615 69.731507    TP
>  -10.610  615 72.493151    TP
>  -12.180  615 78.706849    TP
>  -12.570  615 84.690411    TP
>  -13.280  615 90.213699    TP
>  -15.720  615 96.197260    TP
>    0.375  818  0.000000    TP
>    1.640  818  2.491803    TP
>   -5.190  818  5.967213    TP
>   -3.080  818  9.674018    TP
>   -4.020  818 12.402785    TP
>   -6.380  818 15.854839    TP
>   -4.570  818 17.926072    TP
>   -5.380  818 21.608264    TP
>   -7.210  818 25.060319    TP
>   -8.560  818 27.854839    TP
>   -7.300  818 30.156209    TP
>   -7.590  818 33.312374    TP
>   -7.050  818 36.600045    TP
>   -7.350  818 38.046620    TP
>   -9.040  818 41.893196    TP
>   -8.340  818 45.573770    TP
>   -6.890  818 48.131148    TP
>   -7.190  818 54.098361    TP
>   -7.690  818 57.312374    TP
>   -9.340  818 60.468538    TP
>   -9.580  818 62.572648    TP
>  -10.180  818 65.827442    TP
>   -9.000  818 69.443881    TP
>  -10.760  818 71.547990    TP
>  -10.580  818 74.112374    TP
>  -10.500  818 78.221963    TP
>  -10.460  818 83.252100    TP
>   -9.980  818 89.071278    TP
>   -4.540  535  0.000000    SN
>   -6.050  535  3.221918    SN
>   -4.040  535  5.983562    SN
>   -2.940  535  8.843836    SN
>   -4.360  535 12.197260    SN
>   -3.760  535 14.958904    SN
>   -2.780  535 18.641096    SN
>   -6.140  535 21.402740    SN
>   -6.070  535 24.164384    SN
>   -6.530  535 27.450528    SN
>   -7.320  535 31.057085    SN
>   -6.270  535 33.778397    SN
>   -6.480  535 36.991511    SN
>   -7.440  535 39.747945    SN
>   -9.400  535 42.509589    SN
>   -6.640  535 45.534247    SN
>   -6.170  535 48.098630    SN
>   -5.090  535 51.090411    SN
>   -4.660  535 53.786301    SN
>   -5.420  535 58.158904    SN
>   -8.420  535 60.920548    SN
>   -4.830  535 63.682192    SN
>   -5.210  535 66.673973    SN
>   -5.030  535 69.961644    SN
>   -4.720  535 72.460274    SN
>   -5.570  535 75.253806    SN
>   -4.240  535 79.122659    SN
>   -5.620  535 82.302987    SN
>   -5.180  535 85.286593    SN
>   -4.560  535 88.076712    SN
>   -3.730  535 91.265753    SN
>   -4.490  535 95.473973    SN
>   -5.010  535 99.221918    SN
>   -3.645  541  0.000000    SN
>   -2.130  541  3.024658    SN
>   -2.240  541  6.016438    SN
>   -4.490  541  9.073973    SN
>   -3.310  541 12.000000    SN
>   -3.320  541 16.339726    SN
>   -4.130  541 18.246575    SN
>   -3.640  541 21.271233    SN
>   -3.510  541 24.624658    SN
>   -5.260  541 27.612666    SN
>   -3.340  541 30.825780    SN
>   -3.990  541 33.678239    SN
>   -5.390  541 37.022502    SN
>   -9.960  541 39.616438    SN
>   -3.740  541 43.002740    SN
>   -4.550  541 45.600000    SN
>   -3.370  541 48.295890    SN
>   -4.810  541 50.893151    SN
>   -3.130  541 53.654795    SN
>   -3.770  541 57.632877    SN
>   -3.820  541 60.558904    SN
>   -5.160  541 63.090411    SN
>   -3.530  541 66.016438    SN
>   -4.690  567  0.000000    SN
>   -4.030  567  2.991781    SN
>   -2.080  567  6.049315    SN
>   -2.430  567  9.698630    SN
>   -3.500  567 12.723288    SN
>   -2.690  567 15.189041    SN
>   -3.260  567 18.476712    SN
>   -4.890  567 21.460768    SN
>   -3.940  567 24.673883    SN
>   -4.150  567 28.313227    SN
>   -2.570  567 31.068493    SN
>   -3.290  567 33.402740    SN
>   -2.650  567 36.394521    SN
>   -1.220  567 39.353425    SN
>   -2.230  567 45.764384    SN
>   -2.780  567 48.526027    SN
>   -3.230  567 51.780822    SN
>   -3.470  567 54.542466    SN
>   -2.440  567 57.041096    SN
>   -4.170  567 61.249315    SN
>   -3.440  567 63.715068    SN
>   -1.880  567 66.279452    SN
>   -2.150  567 69.231260    SN
>   -2.150  567 72.673883    SN
>   -7.010  567 89.720548    SN
>   -4.640  567 94.520548    SN
>   -5.600  567 96.723288    SN
>   -2.375  572  0.000000    SN
>   -2.920  572  3.452055    SN
>   -1.310  572  6.246575    SN
>   -1.890  572 10.158904    SN
>   -2.450  572 12.558904    SN
>   -2.590  572 15.189041    SN
>   -2.040  572 18.308826    SN
>   -1.570  572 21.685875    SN
>   -1.930  572 24.472760    SN
>   -1.300  572 27.817022    SN
>   -2.820  572 30.641096    SN
>   -1.240  572 33.600000    SN
>   -0.720  572 36.394521    SN
>   -0.440  572 39.156164    SN
>   -0.750  572 41.917808    SN
>   -1.310  572 45.567123    SN
>   -1.060  572 48.756164    SN
>   -0.670  572 51.517808    SN
>   -1.110  572 54.279452    SN
>   -0.870  572 57.501370    SN
>   -2.400  572 60.493151    SN
>   -1.790  572 63.484932    SN
>   -1.150  572 66.308826    SN
>   -0.550  572 68.800629    SN
>   -1.830  572 72.112104    SN
>   -1.830  572 75.030137    SN
>   -1.640  572 78.772603    SN
>   -2.340  572 81.468493    SN
>   -2.490  572 86.136986    SN
>   -1.840  572 90.147945    SN
>   -1.760  572 93.369863    SN
>   -0.970  572 96.657534    SN
>   -0.960  583  0.000000    SN
>   -1.150  583  3.189041    SN
>   -2.060  583  7.364384    SN
>   -1.710  583  9.402740    SN
>   -0.870  583 12.427397    SN
>   -2.100  583 15.185179    SN
>   -1.290  583 18.660588    SN
>   -1.350  583 21.185179    SN
>   -0.410  583 24.824523    SN
>   -2.750  583 27.550685    SN
>   -1.860  583 30.345205    SN
>   -1.750  583 33.336986    SN
>    0.360  583 36.098630    SN
>   -1.200  583 38.893151    SN
>   -0.900  583 42.575342    SN
>   -1.350  583 45.501370    SN
>   -0.660  583 48.526027    SN
>   -0.950  583 51.254795    SN
>   -1.690  583 54.279452    SN
>   -0.410  583 57.073973    SN
>   -1.090  583 60.295890    SN
>   -0.590  583 63.021244    SN
>   -0.800  583 66.004851    SN
>   -0.700  583 69.250752    SN
>   -0.990  583 72.627801    SN
>   -0.240  583 75.879452    SN
>   -0.180  583 78.673973    SN
>   -1.000  583 81.402740    SN
>   -1.360  583 84.164384    SN
>   -1.240  583 86.958904    SN
>   -1.500  583 90.246575    SN
>   -1.410  583 93.468493    SN
>   -4.260  583 96.230137    SN
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From jfox at mcmaster.ca  Wed Mar 16 17:30:07 2005
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 16 Mar 2005 11:30:07 -0500
Subject: [R] Summing up matrices in a list 
In-Reply-To: <002d01c52a44$40d23d70$a200a8c0@HOME2>
Message-ID: <20050316163007.MPVG1899.tomts13-srv.bellnexxia.net@JohnDesktop8300>

Dear Vicky,

Actually, this question was asked before (about a year ago, I think).

Looping turns out to be not so bad a solution; check out the following
example (from a short-course that I taught):

------- snip --------

# to loop or not to loop?
    
    # Example: summing a list of matrices
        
matrices <- as.list(1:1000)   # reasonable
system.time(for (i in 1:1000) matrices[[i]] <- matrix(rnorm(100), 10, 10))

matrices <- list()    # problematic
system.time(for (i in 1:1000) matrices <- c(matrices,
                                            list(matrix(rnorm(100), 10,
10))))

S <- matrix(0, 10, 10)  # simple
system.time(for (i in 1:length(matrices)) S <- S + matrices[[i]])
S

                        # "clever"
system.time(S <- apply(array(unlist(matrices), dim = c(10, 10, 1000)), 1:2,
sum))
S

------- snip --------

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Vicky Landsman
> Sent: Wednesday, March 16, 2005 11:22 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Summing up matrices in a list 
> 
> Dear all,
> I think that my question is very simple but I failed to solve it. 
> I have a list which elements are matrices like this:
>  
> >mylist
> [[1]]
>      [,1] [,2] [,3]
> [1,]    1    3    5
> [2,]    2    4    6
> 
> [[2]]
>      [,1] [,2] [,3]
> [1,]    7    9   11
> [2,]    8   10   12
> 
> I'd like to create a matrix M<-mylist[[1]]+mylist[[2]]
>      [,1] [,2] [,3]
> [1,]    8   12   16
> [2,]   10   14   18
> 
> Is there a way to create M without looping? 
> Thanks a lot,
> Vicky Landsman. 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From MSchwartz at MedAnalytics.com  Wed Mar 16 17:30:15 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed, 16 Mar 2005 10:30:15 -0600
Subject: [R] Summing up matrices in a list
In-Reply-To: <002d01c52a44$40d23d70$a200a8c0@HOME2>
References: <002d01c52a44$40d23d70$a200a8c0@HOME2>
Message-ID: <1110990616.1090.3.camel@horizons.localdomain>

On Wed, 2005-03-16 at 18:21 +0200, Vicky Landsman wrote:
> Dear all,
> I think that my question is very simple but I failed to solve it. 
> I have a list which elements are matrices like this:
>  
> >mylist  
> [[1]]
>      [,1] [,2] [,3]
> [1,]    1    3    5
> [2,]    2    4    6
> 
> [[2]]
>      [,1] [,2] [,3]
> [1,]    7    9   11
> [2,]    8   10   12
> 
> I'd like to create a matrix M<-mylist[[1]]+mylist[[2]]
>      [,1] [,2] [,3]
> [1,]    8   12   16
> [2,]   10   14   18
> 
> Is there a way to create M without looping? 
> Thanks a lot, 


> do.call("+", mylist)
     [,1] [,2] [,3]
[1,]    8   12   16
[2,]   10   14   18

See ?do.call for more information.

HTH,

Marc Schwartz



From sundar.dorai-raj at pdf.com  Wed Mar 16 17:31:11 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 16 Mar 2005 10:31:11 -0600
Subject: [R] Summing up matrices in a list
In-Reply-To: <002d01c52a44$40d23d70$a200a8c0@HOME2>
References: <002d01c52a44$40d23d70$a200a8c0@HOME2>
Message-ID: <42385F4F.4010803@pdf.com>



Vicky Landsman wrote on 3/16/2005 10:21 AM:
> Dear all,
> I think that my question is very simple but I failed to solve it. 
> I have a list which elements are matrices like this:
>  
> 
>>mylist  
> 
> [[1]]
>      [,1] [,2] [,3]
> [1,]    1    3    5
> [2,]    2    4    6
> 
> [[2]]
>      [,1] [,2] [,3]
> [1,]    7    9   11
> [2,]    8   10   12
> 
> I'd like to create a matrix M<-mylist[[1]]+mylist[[2]]
>      [,1] [,2] [,3]
> [1,]    8   12   16
> [2,]   10   14   18
> 
> Is there a way to create M without looping? 
> Thanks a lot, 
> Vicky Landsman. 
> 	[[alternative HTML version deleted]]
> 

Hi Vicky,

This question is in the archives several times:

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/10963.html

My answer last time was the following:

m <- list(matrix(rnorm(4),2,2),
           matrix(rnorm(4),2,2),
           matrix(rnorm(4),2,2))
mexpr <- paste("m[[", seq(along = m), "]]", collapse="+")
eval(parse(text = mexpr))

HTH,

--sundar



From ramasamy at cancer.org.uk  Wed Mar 16 17:32:33 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 16 Mar 2005 16:32:33 +0000
Subject: [R] Summing up matrices in a list
In-Reply-To: <002d01c52a44$40d23d70$a200a8c0@HOME2>
References: <002d01c52a44$40d23d70$a200a8c0@HOME2>
Message-ID: <1110990753.8605.6.camel@localhost.localdomain>

mylist <- list( matrix(1:6, nc=3), matrix(7:12, nc=3) )
do.call("+", mylist)
     [,1] [,2] [,3]
[1,]    8   12   16
[2,]   10   14   18

Regards, Adai


On Wed, 2005-03-16 at 18:21 +0200, Vicky Landsman wrote:
> Dear all,
> I think that my question is very simple but I failed to solve it. 
> I have a list which elements are matrices like this:
>  
> >mylist  
> [[1]]
>      [,1] [,2] [,3]
> [1,]    1    3    5
> [2,]    2    4    6
> 
> [[2]]
>      [,1] [,2] [,3]
> [1,]    7    9   11
> [2,]    8   10   12
> 
> I'd like to create a matrix M<-mylist[[1]]+mylist[[2]]
>      [,1] [,2] [,3]
> [1,]    8   12   16
> [2,]   10   14   18
> 
> Is there a way to create M without looping? 
> Thanks a lot, 
> Vicky Landsman. 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From jfox at mcmaster.ca  Wed Mar 16 18:00:27 2005
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 16 Mar 2005 12:00:27 -0500
Subject: [R] Summing up matrices in a list
In-Reply-To: <1110990616.1090.3.camel@horizons.localdomain>
Message-ID: <20050316170027.VSMQ1567.tomts25-srv.bellnexxia.net@JohnDesktop8300>

Dear Mark,

I believe that your solution won't work if there are more than two matrices
to sum.

Regards,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Marc Schwartz
> Sent: Wednesday, March 16, 2005 11:30 AM
> To: Vicky Landsman
> Cc: R-Help
> Subject: Re: [R] Summing up matrices in a list
> 
> On Wed, 2005-03-16 at 18:21 +0200, Vicky Landsman wrote:
> > Dear all,
> > I think that my question is very simple but I failed to solve it. 
> > I have a list which elements are matrices like this:
> >  
> > >mylist
> > [[1]]
> >      [,1] [,2] [,3]
> > [1,]    1    3    5
> > [2,]    2    4    6
> > 
> > [[2]]
> >      [,1] [,2] [,3]
> > [1,]    7    9   11
> > [2,]    8   10   12
> > 
> > I'd like to create a matrix M<-mylist[[1]]+mylist[[2]]
> >      [,1] [,2] [,3]
> > [1,]    8   12   16
> > [2,]   10   14   18
> > 
> > Is there a way to create M without looping? 
> > Thanks a lot,
> 
> 
> > do.call("+", mylist)
>      [,1] [,2] [,3]
> [1,]    8   12   16
> [2,]   10   14   18
> 
> See ?do.call for more information.
> 
> HTH,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From zhongmingyang at yahoo.com  Wed Mar 16 18:01:07 2005
From: zhongmingyang at yahoo.com (Zhongming Yang)
Date: Wed, 16 Mar 2005 09:01:07 -0800 (PST)
Subject: [R] how to draw xyplot figure like figure 4.18 of MASS (4th) ?
In-Reply-To: <BAY103-F1B872121C8E1E8DD6EAC7A6480@phx.gbl>
Message-ID: <20050316170107.88075.qmail@web51309.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050316/3ce4c547/attachment.pl

From tlumley at u.washington.edu  Wed Mar 16 18:02:04 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 16 Mar 2005 09:02:04 -0800 (PST)
Subject: [R] Summing up matrices in a list
In-Reply-To: <1110990753.8605.6.camel@localhost.localdomain>
References: <002d01c52a44$40d23d70$a200a8c0@HOME2>
	<1110990753.8605.6.camel@localhost.localdomain>
Message-ID: <Pine.A41.4.61b.0503160901160.260228@homer10.u.washington.edu>

On Wed, 16 Mar 2005, Adaikalavan Ramasamy wrote:

> mylist <- list( matrix(1:6, nc=3), matrix(7:12, nc=3) )
> do.call("+", mylist)
>     [,1] [,2] [,3]
> [1,]    8   12   16
> [2,]   10   14   18
>

Yes, but this works only when the list is of length 2, when
M<-mylist[[1]]+mylist[[2]] seems preferable.

 	-thomas



From ggrothendieck at myway.com  Wed Mar 16 17:39:47 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 16 Mar 2005 16:39:47 +0000 (UTC)
Subject: [R] Summing up matrices in a list
References: <002d01c52a44$40d23d70$a200a8c0@HOME2>
Message-ID: <loom.20050316T173814-876@post.gmane.org>

Vicky Landsman <msvika <at> mscc.huji.ac.il> writes:

: 
: Dear all,
: I think that my question is very simple but I failed to solve it. 
: I have a list which elements are matrices like this:
: 
: >mylist  
: [[1]]
:      [,1] [,2] [,3]
: [1,]    1    3    5
: [2,]    2    4    6
: 
: [[2]]
:      [,1] [,2] [,3]
: [1,]    7    9   11
: [2,]    8   10   12
: 
: I'd like to create a matrix M<-mylist[[1]]+mylist[[2]]
:      [,1] [,2] [,3]
: [1,]    8   12   16
: [2,]   10   14   18
: 
: Is there a way to create M without looping? 
: Thanks a lot, 
: Vicky Landsman. 

If there are n3 matrices each of dimension n1 x n2 then we can 
create an n1 x n2 x n3 array and apply sum over it:

# get dimensions
n1xn2 <- dim(mylist[[1]])
n3 <- length(mylist)

# create 3d array and sum
arr <- array(unlist(mylist), c(n1xn2, n3))
apply(arr, 1:2, sum)



From MSchwartz at MedAnalytics.com  Wed Mar 16 18:07:48 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed, 16 Mar 2005 11:07:48 -0600
Subject: [R] Summing up matrices in a list
In-Reply-To: <20050316170027.VSMQ1567.tomts25-srv.bellnexxia.net@JohnDesktop8300>
References: <20050316170027.VSMQ1567.tomts25-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <1110992868.3946.3.camel@horizons.localdomain>

John,

That is correct. I took the example perhaps too literally, depending
upon what Vicky requires. If indeed the data structure is comprised of
>2 matrices, the approach using do.call() will not work.

Thanks for pointing that out.  I see that Adai had a similar idea.

Best regards,

Marc


On Wed, 2005-03-16 at 12:00 -0500, John Fox wrote:
> Dear Mark,
> 
> I believe that your solution won't work if there are more than two matrices
> to sum.
> 
> Regards,
>  John
> 
> --------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> 905-525-9140x23604
> http://socserv.mcmaster.ca/jfox 
> -------------------------------- 
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Marc Schwartz
> > Sent: Wednesday, March 16, 2005 11:30 AM
> > To: Vicky Landsman
> > Cc: R-Help
> > Subject: Re: [R] Summing up matrices in a list
> > 
> > On Wed, 2005-03-16 at 18:21 +0200, Vicky Landsman wrote:
> > > Dear all,
> > > I think that my question is very simple but I failed to solve it. 
> > > I have a list which elements are matrices like this:
> > >  
> > > >mylist
> > > [[1]]
> > >      [,1] [,2] [,3]
> > > [1,]    1    3    5
> > > [2,]    2    4    6
> > > 
> > > [[2]]
> > >      [,1] [,2] [,3]
> > > [1,]    7    9   11
> > > [2,]    8   10   12
> > > 
> > > I'd like to create a matrix M<-mylist[[1]]+mylist[[2]]
> > >      [,1] [,2] [,3]
> > > [1,]    8   12   16
> > > [2,]   10   14   18
> > > 
> > > Is there a way to create M without looping? 
> > > Thanks a lot,
> > 
> > 
> > > do.call("+", mylist)
> >      [,1] [,2] [,3]
> > [1,]    8   12   16
> > [2,]   10   14   18
> > 
> > See ?do.call for more information.
> > 
> > HTH,
> > 
> > Marc Schwartz
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html



From dimitris.rizopoulos at med.kuleuven.ac.be  Wed Mar 16 18:09:35 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Wed, 16 Mar 2005 18:09:35 +0100
Subject: [R] Summing up matrices in a list
References: <002d01c52a44$40d23d70$a200a8c0@HOME2>
	<1110990753.8605.6.camel@localhost.localdomain>
Message-ID: <01e501c52a4a$ede68060$0540210a@www.domain>

yes, but I think this works only if the list contains 2 matrices, 
isn't it?


> mylist <- list(matrix(1:6, 2), matrix(7:12, 2), matrix(13:18, 2))
> do.call("+", mylist)
Error in do.call("+", mylist) : operator needs one or two arguments


Best,
Dimitris



----- Original Message ----- 
From: "Adaikalavan Ramasamy" <ramasamy at cancer.org.uk>
To: "Vicky Landsman" <msvika at mscc.huji.ac.il>
Cc: "R-help" <r-help at stat.math.ethz.ch>
Sent: Wednesday, March 16, 2005 5:32 PM
Subject: Re: [R] Summing up matrices in a list


> mylist <- list( matrix(1:6, nc=3), matrix(7:12, nc=3) )
> do.call("+", mylist)
>     [,1] [,2] [,3]
> [1,]    8   12   16
> [2,]   10   14   18
>
> Regards, Adai
>
>
> On Wed, 2005-03-16 at 18:21 +0200, Vicky Landsman wrote:
>> Dear all,
>> I think that my question is very simple but I failed to solve it.
>> I have a list which elements are matrices like this:
>>
>> >mylist
>> [[1]]
>>      [,1] [,2] [,3]
>> [1,]    1    3    5
>> [2,]    2    4    6
>>
>> [[2]]
>>      [,1] [,2] [,3]
>> [1,]    7    9   11
>> [2,]    8   10   12
>>
>> I'd like to create a matrix M<-mylist[[1]]+mylist[[2]]
>>      [,1] [,2] [,3]
>> [1,]    8   12   16
>> [2,]   10   14   18
>>
>> Is there a way to create M without looping?
>> Thanks a lot,
>> Vicky Landsman.
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From andy_liaw at merck.com  Wed Mar 16 18:14:55 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 16 Mar 2005 12:14:55 -0500
Subject: [R] Summing up matrices in a list
Message-ID: <3A822319EB35174CA3714066D590DCD50994E86B@usrymx25.merck.com>

Here's a slight variation:

> lst <- list(matrix(1:4, 2, 2), matrix(5:8, 2, 2), matrix(9:12, 2, 2))
> m <- matrix(0, 2, 2)
> m[] <- rowSums(do.call("cbind", lapply(lst, c)))
> m
     [,1] [,2]
[1,]   15   21
[2,]   18   24

This can probably be simplified even more with the `abind' package...

Andy

> From: Dimitris Rizopoulos
> 
> try this:
> 
> matSums <- function(lis, na.rm=FALSE){
>     if(!is.list(lis) || !all(sapply(lis, is.matrix))) 
> stop("'lis' must 
> be a list containing 2-dimensional arrays")
>     dims <- sapply(lis, dim)
>     n <- dims[1, 1]
>     p <- dims[2, 1]
>     if(!all(n == dims[1, ]) || !all(p == dims[2, ])) stop("the 
> matrices must have the same dimensions")
>     mat <- matrix(unlist(lis), n * p, length(lis))
>     matrix(rowSums(mat, na.rm=na.rm), n, p)
> }
> #########
> mylist <- list(matrix(1:6, 2), matrix(7:12, 2))
> matSums(mylist)
> 
> 
> I hope it helps.
> 
> Best,
> Dimitris
> 
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
> 
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/16/336899
> Fax: +32/16/337015
> Web: http://www.med.kuleuven.ac.be/biostat/
>      http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
> 
> 
> ----- Original Message ----- 
> From: "Vicky Landsman" <msvika at mscc.huji.ac.il>
> To: <r-help at stat.math.ethz.ch>
> Sent: Wednesday, March 16, 2005 5:21 PM
> Subject: [R] Summing up matrices in a list
> 
> 
> > Dear all,
> > I think that my question is very simple but I failed to solve it.
> > I have a list which elements are matrices like this:
> >
> >>mylist
> > [[1]]
> >     [,1] [,2] [,3]
> > [1,]    1    3    5
> > [2,]    2    4    6
> >
> > [[2]]
> >     [,1] [,2] [,3]
> > [1,]    7    9   11
> > [2,]    8   10   12
> >
> > I'd like to create a matrix M<-mylist[[1]]+mylist[[2]]
> >     [,1] [,2] [,3]
> > [1,]    8   12   16
> > [2,]   10   14   18
> >
> > Is there a way to create M without looping?
> > Thanks a lot,
> > Vicky Landsman.
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From spencer.graves at pdf.com  Wed Mar 16 19:02:30 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 16 Mar 2005 10:02:30 -0800
Subject: [R] problem solved and new insight
In-Reply-To: <a9ac7e26f6f867ad49ce8ab07abfcdd0@soc.soton.ac.uk>
References: <a9ac7e26f6f867ad49ce8ab07abfcdd0@soc.soton.ac.uk>
Message-ID: <423874B6.7070705@pdf.com>

Hi, Robin:  Thanks.  That's a great advertisement for 
"http://www.R-project.org/posting-guide.html", which I might quote in 
the future.  spencer graves

Robin Hankin wrote:

> Hi
>
> just now I had an apparently insurmountable problem
> that's been bugging me for days, but phrasing my question in a form
> suitable for the R-help list enabled me to solve my own problem
> in two minutes flat.
>
>
> thanks everyone.
>
>
> -- 
> Robin Hankin
> Uncertainty Analyst
> Southampton Oceanography Centre
> European Way, Southampton SO14 3ZH, UK
>  tel  023-8059-7743
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From lavanya_ldb2000 at yahoo.co.in  Wed Mar 16 19:02:41 2005
From: lavanya_ldb2000 at yahoo.co.in (Lakshmi Dhevi Baskar)
Date: Wed, 16 Mar 2005 10:02:41 -0800 (PST)
Subject: [R] Help in persp (VERY URGENT ASSISTANCE)
Message-ID: <20050316180241.75090.qmail@web8510.mail.in.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050316/6373c976/attachment.pl

From sundar.dorai-raj at pdf.com  Wed Mar 16 19:15:25 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 16 Mar 2005 12:15:25 -0600
Subject: [R] Help in persp (VERY URGENT ASSISTANCE)
In-Reply-To: <20050316180241.75090.qmail@web8510.mail.in.yahoo.com>
References: <20050316180241.75090.qmail@web8510.mail.in.yahoo.com>
Message-ID: <423877BD.2030004@pdf.com>



Lakshmi Dhevi Baskar wrote on 3/16/2005 12:02 PM:
>  
> Dear All,
>  
> I am very new to R projects.May be i am wrong in some steps.I have given the code which i tried for drawing 3d surface using persp.I need to label the axes with scales
>  
>  z <- array(topnew2$V2, dim=c(600,2))
>  x <- 10 * (1:nrow(z))
>  y <- (1:ncol(z))
>  persp(x, y, z, theta = 30, phi = 30, expand = 0.5, col = "lightblue", xlab ="fluidlevel", ylab ="time", zlab = "probability",xlim=range(x),ylim=range(y))
> 
>  
>  
> I have a text file  of format:
>  
>      V1 V2   V3
> 1     1  0   10
> 2     1  0   20
> 3     1  0   30
> 4     1  0   40
> 5     1  0   50
> ..................
>  now i converted to matrix as "z" 
>  
>   z:............
>         [,1] [,2]
>   [1,]    0    0
>   [2,]    0    0
>   [3,]    0    0
>   [4,]    0    0
>   [5,]    0    0
>   [6,]    0    0
>   [7,]    0    0
>   [8,]    0    0
> ...................
>  
>  
>  
> i need to label x axis with scale from 10 to 6000 with length of 10
> and y axis with 1 and 2 
> and z from 0 to 1(probabilty)
>  
>  
> kindly guide me...(may be i have misunderstood some concepts in commands)...
>  
> thanks in advance for the help and patience
> 
> 		

Lakshmi,

Have you tried using persp(..., ticktype = "detailed", nticks = 10)? 
This is found in ?persp.

--sundar



From choudary.jagar at swosu.edu  Wed Mar 16 19:16:13 2005
From: choudary.jagar at swosu.edu (Jagarlamudi, Choudary)
Date: Wed, 16 Mar 2005 12:16:13 -0600
Subject: [R] How to extract x rows to get  x pvalues using t.test
Message-ID: <E03EBB50FF2C024781A6E4460AD58F0607C1AE@swosu-mbx01.admin.swosu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050316/4d09c6ab/attachment.pl

From lavanya_ldb2000 at yahoo.co.in  Wed Mar 16 20:01:14 2005
From: lavanya_ldb2000 at yahoo.co.in (Lakshmi Dhevi Baskar)
Date: Wed, 16 Mar 2005 11:01:14 -0800 (PST)
Subject: [R] Help regarding persp
Message-ID: <20050316190114.6884.qmail@web8508.mail.in.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050316/9b2d4547/attachment.pl

From consentino at infinito.it  Wed Mar 16 20:17:13 2005
From: consentino at infinito.it (consentino@infinito.it)
Date: Wed, 16 Mar 2005 20:17:13 +0100
Subject: [R] Time Series
In-Reply-To: <web-51314529@infinito.it>
References: <web-51064440@infinito.it> <web-51269173@infinito.it>
	<web-51314529@infinito.it>
Message-ID: <web-55405439@infinito.it>

Hello,

I'm using a dataset with unequally spaced time series
and I'd want to know if there is in R some function in
order to calculate the autocorrelation function, because
acf() in stats package cannot calculate it, because I
have many missing data, and data are not equally spaced.

And if so, is it necessary to organize dataset in ts
structure or is it possible to consider it like a simple
vector?

Thanks in advance

Fabrizio Consentino



From Robert at sanctumfi.com  Wed Mar 16 20:20:23 2005
From: Robert at sanctumfi.com (Robert Sams)
Date: Wed, 16 Mar 2005 19:20:23 -0000
Subject: [R] Time Series
Message-ID: <E585EABA11227445B918BFB74C1A4D36214924@sanctum01.sanctumfi.com>

see packages zoo and its on cran.

> -----Original Message-----
> From: consentino at infinito.it [mailto:consentino at infinito.it]
> Sent: Wednesday, March 16, 2005 7:17 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Time Series
> 
> 
> Hello,
> 
> I'm using a dataset with unequally spaced time series
> and I'd want to know if there is in R some function in
> order to calculate the autocorrelation function, because
> acf() in stats package cannot calculate it, because I
> have many missing data, and data are not equally spaced.
> 
> And if so, is it necessary to organize dataset in ts
> structure or is it possible to consider it like a simple
> vector?
> 
> Thanks in advance
> 
> Fabrizio Consentino
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Wed Mar 16 20:28:47 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 16 Mar 2005 19:28:47 +0000 (GMT)
Subject: [R] Time Series
In-Reply-To: <web-55405439@infinito.it>
References: <web-51064440@infinito.it> <web-51269173@infinito.it>
	<web-51314529@infinito.it> <web-55405439@infinito.it>
Message-ID: <Pine.LNX.4.61.0503161922200.6703@gannet.stats>

On Wed, 16 Mar 2005 consentino at infinito.it wrote:

> I'm using a dataset with unequally spaced time series
> and I'd want to know if there is in R some function in
> order to calculate the autocorrelation function, because
> acf() in stats package cannot calculate it, because I
> have many missing data, and data are not equally spaced.

The autocorrelation function is a theoretical quantity: acf() estimates 
it, not calculates it.  (Do read its help page carefully.)

For `unequally spaced time series' you would need to define what you mean
by the autocorrelation function, then find a credible estimator.
(One way forward is to assume you have a sample of a continuous-time 
series, but only one.)

> And if so, is it necessary to organize dataset in ts
> structure or is it possible to consider it like a simple
> vector?

None of the above!

Depends what you want to do with it, but the structures offered by the 
packages tseries, zoo and its seem more suitable.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jeroschh at ohsu.edu  Wed Mar 16 20:29:43 2005
From: jeroschh at ohsu.edu (Michael Jerosch-Herold)
Date: Wed, 16 Mar 2005 11:29:43 -0800
Subject: [R] user-defined correlation structure in NLME
Message-ID: <s23818af.015@ohsu.edu>



Could somebody help with the definition of new correlation structure for use with a linear mixed-effects model (package nlme). Specifically, I want to define a Toeplitz type correlation structure, but due to my inexperience with programming in R, I feel a bit overwhelmed with the task at hand.

I understand that you can start with a function like corAR1 as template, but I have no idea how I would define the methods (coef, corMatrix, and initialize) in this context.

I did a search on Google and in the R-help archives, but have not found much in terms of hints and specific examples for user defined correlation structures.

Thank you in advance!

Michael Jerosch-Herold



From pauljohn at ku.edu  Wed Mar 16 20:52:36 2005
From: pauljohn at ku.edu (Paul Johnson)
Date: Wed, 16 Mar 2005 13:52:36 -0600
Subject: [R] working with pairlists imported from HDF5,
	converting to data frames?
Message-ID: <42388E84.9000108@ku.edu>

I've used the HDF5 library to bring some data into R. THe verbose output 
looks like this:

 > 
hdf5load("hdfGraphWed_Mar_16_13_33_37_2005.hdf",load=T,verbosity=1,tidy=T)
Processing object: cprSeats ...... which is a Group
Processing object: Seats 0 ...... its a dataset......Finished dataset
Processing object: Seats 1 ...... its a dataset......Finished dataset
Processing object: Seats 2 ...... its a dataset......Finished dataset
Processing object: Seats 3 ...... its a dataset......Finished dataset
Processing object: Seats 4 ...... its a dataset......Finished dataset
... Done group cprSeats
Processing object: effective ...... which is a Group
Processing object: AggComp ...... its a dataset......Finished dataset
Processing object: AggNonComp ...... its a dataset......Finished dataset
Processing object: CPR ...... its a dataset......Finished dataset
Processing object: PR ...... its a dataset......Finished dataset
Processing object: SMD ...... its a dataset......Finished dataset
... Done group effective


Each item inside the group "effective" is a vector of numbers.  I want 
to convert effective into a data frame or matrix for use with matplot.

However, R sees effective not as a collection of vectors, but as a 
pairlist.  I'm not a Lisp programmer, so don't understand the 
significance of the list help page's comment about dotted lists.

 > class(effective)
[1] "pairlist"
 > attributes(effective)
$names
[1] "SMD"        "PR"         "CPR"        "AggNonComp" "AggComp"

I can access the elements in effective as list elements, either with 
effective$SMD or effective[[1]], as in:

 > effective[[1]]
   [1] 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 
1.000000
   [9] 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 
1.000000
  [17] 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 
1.000000
  [25] 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 4.761905 
4.668534
  [33] 4.743833 4.743833 4.694836 4.672897 4.612546 4.612546 4.612546 
4.950495
  [41] 4.766444 4.761905 4.329004 4.990020 4.930966 4.906771 4.378284 
4.686036
  [49] 4.935834 4.793864 4.793864 4.541326 4.849661 4.730369 4.960317 
4.159734


But I can't force it into a data frame

 > as.data.frame(effective)
Error in as.data.frame.default(effective) :
         can't coerce pairlist into a data.frame


But I can manually build the dataframe

 > 
data.frame(effective$SMD,effective$PR,effective$CPR,effective$AggNonComp,effective$AggComp)

But that is a bit frustrating for every individual dataset coming in.

Is there a short cut?


-- 
Paul E. Johnson                       email: pauljohn at ku.edu
Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
1541 Lilac Lane, Rm 504
University of Kansas                  Office: (785) 864-9086
Lawrence, Kansas 66044-3177           FAX: (785) 864-5700



From gunter.berton at gene.com  Wed Mar 16 21:01:21 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 16 Mar 2005 12:01:21 -0800
Subject: [R] Summing up matrices in a list
In-Reply-To: <Pine.A41.4.61b.0503160901160.260228@homer10.u.washington.edu>
Message-ID: <200503162001.j2GK1MAl005646@compton.gene.com>

Well, just for fun, and assuming we don't care about efficiency, we can also
use recursion (I don't think this was posted yet):

sumlist<-function(mylist){
## warning -- arguments not checked
if(length(mylist)==2)mylist[[1]] + mylist[[2]]
else mylist[[1]]+ Recall(mylist[-1])
}


Note that this will also fail if the list is too long so that the recursion
is too deep. But it's fun ... and does have the advantage of working for any
'+' method and corresponding class (as the do.call() construction would if
it were bot just a binary operator).

Cheers to all,

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Thomas Lumley
> Sent: Wednesday, March 16, 2005 9:02 AM
> To: Adaikalavan Ramasamy
> Cc: R-help
> Subject: Re: [R] Summing up matrices in a list
> 
> On Wed, 16 Mar 2005, Adaikalavan Ramasamy wrote:
> 
> > mylist <- list( matrix(1:6, nc=3), matrix(7:12, nc=3) )
> > do.call("+", mylist)
> >     [,1] [,2] [,3]
> > [1,]    8   12   16
> > [2,]   10   14   18
> >
> 
> Yes, but this works only when the list is of length 2, when
> M<-mylist[[1]]+mylist[[2]] seems preferable.
> 
>  	-thomas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From dlrustvold at gmail.com  Wed Mar 16 21:06:55 2005
From: dlrustvold at gmail.com (D L Rustvold)
Date: Wed, 16 Mar 2005 12:06:55 -0800
Subject: [R] mixture model of binned data
Message-ID: <05686ddeb67d780327bfcfdcc619ea6b@gmail.com>


Is there a ready means to do mixture models of binned data in R?

I have a two dimensional grid of intensity values that represents many 
individual observations that are known to have bivariate normal 
distributions, although there is frequent overlap between the 
distributions.  There is also a degree of noise in the data that may be 
modeled by a poisson distribution.  I am looking for a way to identify 
the mixture model that best describes a subset of this grid of 
intensities so that I can deconvolute the multiple observations and 
noise distributions for quantification purposes.

I thought Mclust might be of use, but I didn't see any support for 
binned data.  I have searched the archives, read the FAQ, and the 
document "Fitting Distributions with R" without finding a successful 
solution.

Any help would be appreciated.

Cheers,
Leif Rustvold



From gerifalte28 at hotmail.com  Wed Mar 16 21:22:34 2005
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Wed, 16 Mar 2005 20:22:34 +0000
Subject: [R] how to draw xyplot figure like figure 4.18 of MASS (4th) ?
In-Reply-To: <20050316170107.88075.qmail@web51309.mail.yahoo.com>
Message-ID: <BAY103-F2363DE0C735FB3E1E7D121A6480@phx.gbl>

I am not sure of what you really want.  Do you want one scatterplot with 
'month' in the x axis and 'md' in the y axis, with a line joining each point 
on the plot? Or you want a regression line with a diferent color for each 
group? Or do you want them in 3 separate panels?

If you want one plot and 3 different colors and smoothed lines joining each 
group you can try

d<-read.table('clipboard', header = T) #I copied your data from the 
clipboard
library(lattice)
plot(month,md, col = c('red','blue','black'), type='p')
lines(lowess(d[group=='NN',1]), col = 'red') #overlays a smoothed line to 
your points
lines(lowess(d[group=='SN',1]), col = 'blue')
lines(lowess(d[group=='TP',1]),col = 'black')

Or you can create 3 plots in one graph panel

par(mfrow = c(2, 2)) #2 by 2 plot panel.  Also try par(mfrow = c(3, 1)) and 
see if you like it better
plot(d[group=='NN','month'],d[group=='NN','md'], col = 'red', type='p') 
#plots the 'NN' points
lines(lowess(d[group=='NN',1]), col = 'red') #adds a smoothe line to the 
NN's
plot(d[group=='SN','month'],d[group=='SN','md'], col = 'blue', type='p')
lines(lowess(d[group=='SN',1]), col = 'blue')
plot(d[group=='TP','month'],d[group=='TP','md'], col = 'black', type='p')
lines(lowess(d[group=='TP',1]), col = 'black')

I see that the group 'SN' stays pretty much the same over time, 'TP' shows a 
decreasing trend over time and 'NN' shows that you almost have two separate 
groups with different responses!

Is this what you wanted to do?

Cheers

Francisco


>From: Zhongming Yang <zhongmingyang at yahoo.com>
>To: "Francisco J. Zagmutt" <gerifalte28 at hotmail.com>, 
>r-help at stat.math.ethz.ch
>Subject: RE: [R] how to draw xyplot figure like figure 4.18 of MASS (4th) ?
>Date: Wed, 16 Mar 2005 09:01:07 -0800 (PST)
>
>Dear Francisco and All:
>
>Following is the source code to create figure 4.18 from MASS (4th).
>
>library(MASS)
>library(lattice)
>if(F) { # no data supplied
>xyplot(ratio ~ scant | subject, data = A5,
>       xlab = "scan interval (years)",
>       ylab = "ventricle/brain volume normalized to 1 at start",
>       subscripts = T, ID = A5$ID,
>       strip = function(factor, ...)
>          strip.default(..., factor.levels = labs, style = 1),
>       layout = c(8, 5, 1),
>       skip = c(rep(FALSE, 37), rep(TRUE, 1), rep(FALSE, 1)),
>       panel = function(x, y, subscripts, ID) {
>           panel.xyplot(x, y, type = "b", cex = 0.5)
>           which <- unique(ID[subscripts])
>           panel.xyplot(c(0, 1.5), pr3[names(pr3) == which],
>                        type = "l", lty = 3)
>           if(which == 303 || which == 341) points(1.4, 1.3)
>       })
>}
>
>But there is no data set available for that, I can't figure out many stuff. 
>So I provide my data set, hope you can help me.
>
>In my data set, there are 3 group patients, and 5 patients in each group. 
>The mds are the repeat measurements on month. I want draw a xyplot with 3 
>lines, each line for a group.
>
>
>Many thanks
>
>Zhongming Yang
>
>
>
>
>"Francisco J. Zagmutt" <gerifalte28 at hotmail.com> wrote:
>Dear Zhongming,
>
>By asking for the figure in the book you are restricting you question to
>only the people that has the 4th edition. I would love to help you but
>unfortunatelly I have the 3rd edition of MASS and there is no figure 4.18
>since chapter 4 is "Programming in S". Please give us an idea of what you
>want to do and we might be able to help you without looking at the book.
>
>Cheers
>
>Francisco
>
> >From: Zhongming Yang
> >To: r-help at stat.math.ethz.ch
> >Subject: [R] how to draw xyplot figure like figure 4.18 of MASS (4th) ?
> >Date: Wed, 16 Mar 2005 08:07:21 -0800 (PST)
> >
> >Dear All:
> >
> >Could you please tell me how I can draw figure formatted like figure 4.18
> >of MASS (4th) with the attached data set?
> >
> >Thanks
> >
> >Zhongming Yang
> >
> >
> >
> >---------------------------------
> >
> > md idno month group
> > -0.090 521 0.000000 NN
> > -1.330 521 12.460274 NN
> > -0.570 521 14.991781 NN
> > -2.130 559 0.000000 NN
> > -0.920 559 3.978082 NN
> > -1.730 559 6.016438 NN
> > -2.390 559 9.665753 NN
> > -1.300 559 12.460274 NN
> > -2.170 559 15.682192 NN
> > -2.620 559 17.950685 NN
> > -1.830 559 21.664406 NN
> > -3.090 559 25.533258 NN
> > -2.760 559 30.811947 NN
> > -1.240 559 33.830137 NN
> > -0.650 559 36.394521 NN
> > -1.200 559 38.893151 NN
> > -1.320 559 42.147945 NN
> > -2.000 559 45.600000 NN
> > -2.150 559 48.328767 NN
> > -1.430 559 52.569863 NN
> > -2.650 559 56.120548 NN
> > -0.870 559 60.032877 NN
> > -1.920 559 63.550685 NN
> > -2.320 559 65.786301 NN
> > -2.640 559 68.547945 NN
> > -2.030 559 71.533258 NN
> > -1.900 559 75.500472 NN
> > -1.420 559 78.254570 NN
> > -1.330 559 81.863014 NN
> > -2.120 559 84.657534 NN
> > -2.400 559 86.926027 NN
> > -2.410 559 90.147945 NN
> > -3.370 559 93.369863 NN
> > -0.720 559 96.624658 NN
> > -2.075 598 0.000000 NN
> > -2.260 598 3.484932 NN
> > -2.150 598 5.917808 NN
> > -1.420 598 9.828879 NN
> > -1.490 598 12.353470 NN
> > -3.040 598 16.025601 NN
> > -1.960 598 18.845273 NN
> > -2.780 598 22.224658 NN
> > -3.310 598 24.591781 NN
> > -4.420 598 27.517808 NN
> > -1.890 598 30.312329 NN
> > -3.000 598 33.304110 NN
> > -2.260 598 36.065753 NN
> > -0.730 598 40.010959 NN
> > -2.710 598 43.232877 NN
> > -2.430 598 45.994521 NN
> > -1.050 598 49.183562 NN
> > -2.190 598 52.438356 NN
> > -0.580 598 54.969863 NN
> > -2.050 598 57.501011 NN
> > -1.480 598 60.681338 NN
> > -0.960 598 63.664945 NN
> > -2.090 598 66.419043 NN
> > -3.180 598 69.435616 NN
> > -1.230 598 72.394521 NN
> > -2.170 598 74.761644 NN
> > -2.400 598 78.378082 NN
> > -3.630 598 81.698630 NN
> > -2.100 598 84.920548 NN
> > -3.940 598 87.156164 NN
> > -3.780 598 90.378082 NN
> > -5.690 598 95.967123 NN
> > -13.525 622 0.000000 NN
> > -12.670 622 3.680934 NN
> > -13.500 622 7.123557 NN
> > -13.700 622 9.910442 NN
> > -11.260 622 12.926836 NN
> > -12.100 622 15.846575 NN
> > -13.400 622 18.410959 NN
> > -12.330 622 21.435616 NN
> > -12.940 622 24.197260 NN
> > -12.540 622 27.156164 NN
> > -12.550 622 29.917808 NN
> > -11.900 622 33.830137 NN
> > -11.640 622 36.394521 NN
> > -12.100 622 38.893151 NN
> > -11.010 622 41.457534 NN
> > -12.050 622 46.684932 NN
> > -12.650 622 50.136986 NN
> > -11.620 622 54.303885 NN
> > -12.150 622 58.303885 NN
> > -12.990 622 60.959623 NN
> > -12.590 622 63.912329 NN
> > -13.570 622 66.936986 NN
> > -12.480 622 69.336986 NN
> > -12.800 622 72.263014 NN
> > -12.640 622 75.452055 NN
> > -13.830 622 81.073973 NN
> > -13.250 622 84.295890 NN
> > -13.700 622 90.213699 NN
> > -13.250 622 96.197260 NN
> > -2.190 801 0.000000 NN
> > -1.250 801 2.663014 NN
> > -1.550 801 5.589041 NN
> > -1.570 801 8.575612 NN
> > -0.880 801 11.755940 NN
> > -0.230 801 15.428071 NN
> > -0.770 801 17.985448 NN
> > -1.050 801 20.975342 NN
> > -2.260 801 24.394521 NN
> > -2.760 801 27.715068 NN
> > -1.550 801 29.950685 NN
> > -2.330 801 34.093151 NN
> > -1.390 801 36.394521 NN
> > -2.090 801 39.353425 NN
> > -3.050 801 41.917808 NN
> > -1.930 801 44.646575 NN
> > -4.040 801 48.328767 NN
> > -3.260 801 51.780822 NN
> > -2.810 801 54.115068 NN
> > -0.660 801 57.395284 NN
> > -1.800 801 62.903481 NN
> > -1.540 801 65.755940 NN
> > -0.880 801 69.567123 NN
> > -2.000 801 73.117808 NN
> > -1.610 801 76.142466 NN
> > -4.360 801 79.463014 NN
> > -3.200 801 80.712329 NN
> > -3.080 801 83.013699 NN
> > -2.350 801 88.306849 NN
> > -3.170 801 89.917808 NN
> > -3.570 801 95.342466 NN
> > -3.300 525 0.000000 TP
> > -2.500 525 2.991781 TP
> > -5.480 525 5.917808 TP
> > -1.140 525 8.712329 TP
> > -2.260 525 11.967123 TP
> > -0.670 525 14.926027 TP
> > -0.630 525 17.950685 TP
> > -0.600 525 21.336986 TP
> > -1.870 525 24.427397 TP
> > -1.790 525 26.860274 TP
> > -3.640 525 30.771345 TP
> > -2.860 525 33.328722 TP
> > -2.140 525 37.197575 TP
> > -1.560 525 39.787739 TP
> > -0.360 525 42.542466 TP
> > -1.900 525 45.304110 TP
> > -1.190 525 48.032877 TP
> > -3.090 525 51.024658 TP
> > -2.620 525 53.786301 TP
> > -1.360 525 58.126027 TP
> > -1.130 525 60.953425 TP
> > -1.390 525 64.142466 TP
> > -0.270 525 66.904110 TP
> > -1.640 525 69.665753 TP
> > -1.390 525 72.887671 TP
> > -2.550 525 75.221918 TP
> > -2.540 525 78.180822 TP
> > -1.640 525 81.623804 TP
> > -2.410 525 84.574624 TP
> > -2.530 525 88.017247 TP
> > -1.980 525 91.463014 TP
> > -3.060 525 93.895890 TP
> > -1.920 525 96.131507 TP
> > -1.650 525 99.320548 TP
> > -2.625 527 0.000000 TP
> > -2.370 527 2.991781 TP
> > 0.050 527 6.180822 TP
> > -0.270 527 9.041096 TP
> > 1.060 527 11.736986 TP
> > -3.030 527 15.221918 TP
> > -1.000 527 18.180822 TP
> > -1.270 527 21.895890 TP
> > -1.910 527 24.361644 TP
> > -2.350 527 27.649315 TP
> > -3.720 527 30.142825 TP
> > -3.310 527 33.355940 TP
> > -2.280 527 35.847743 TP
> > -1.860 527 39.290366 TP
> > -5.050 527 42.345205 TP
> > -3.160 527 45.106849 TP
> > -2.270 527 47.802740 TP
> > -1.850 527 50.630137 TP
> > -4.010 527 53.621918 TP
> > -4.520 527 56.383562 TP
> > -3.820 527 60.000000 TP
> > -6.440 527 65.293151 TP
> > -4.600 527 68.350685 TP
> > -5.280 527 71.802740 TP
> > -3.920 527 75.320548 TP
> > -5.080 527 78.175612 TP
> > -8.550 527 80.831350 TP
> > -4.900 527 84.601841 TP
> > -11.620 527 87.585448 TP
> > -6.090 527 91.956164 TP
> > -7.120 527 95.408219 TP
> > -6.365 570 0.000000 TP
> > -6.100 570 2.761644 TP
> > -4.950 570 5.983562 TP
> > -5.530 570 9.205479 TP
> > -3.640 570 11.967123 TP
> > -3.330 570 15.879452 TP
> > -4.950 570 18.310442 TP
> > -5.250 570 21.392410 TP
> > -5.540 570 24.376016 TP
> > -4.300 570 27.359623 TP
> > -4.530 570 29.884932 TP
> > -5.970 570 32.646575 TP
> > -4.950 570 37.019178 TP
> > -5.090 570 39.320548 TP
> > -4.000 570 42.312329 TP
> > -6.160 570 45.073973 TP
> > -6.490 570 49.216438 TP
> > -4.890 570 52.668493 TP
> > -6.620 570 56.350685 TP
> > -7.010 570 61.183562 TP
> > -7.290 570 63.978082 TP
> > -6.440 570 66.736672 TP
> > -7.950 570 69.917000 TP
> > -7.570 570 73.130115 TP
> > -8.150 570 76.113721 TP
> > -8.090 570 78.805479 TP
> > -9.670 570 82.553425 TP
> > -9.480 570 86.169863 TP
> > -9.120 570 90.147945 TP
> > -11.330 570 97.019178 TP
> > -3.750 615 0.000000 TP
> > -3.510 615 3.287671 TP
> > -4.160 615 5.848641 TP
> > -5.170 615 9.651920 TP
> > -4.600 615 12.438805 TP
> > -5.940 615 15.619133 TP
> > -6.270 615 18.608219 TP
> > -4.690 615 21.632877 TP
> > -7.820 615 24.361644 TP
> > -5.940 615 27.189041 TP
> > -5.680 615 30.180822 TP
> > -6.750 615 32.712329 TP
> > -5.130 615 36.854795 TP
> > -6.630 615 39.386301 TP
> > -7.450 615 41.917808 TP
> > -7.290 615 45.369863 TP
> > -9.590 615 48.361644 TP
> > -9.700 615 51.353425 TP
> > -9.570 615 54.799461 TP
> > -9.840 615 57.783068 TP
> > -9.800 615 60.766674 TP
> > -11.000 615 63.291264 TP
> > -11.360 615 66.805479 TP
> > -10.860 615 69.731507 TP
> > -10.610 615 72.493151 TP
> > -12.180 615 78.706849 TP
> > -12.570 615 84.690411 TP
> > -13.280 615 90.213699 TP
> > -15.720 615 96.197260 TP
> > 0.375 818 0.000000 TP
> > 1.640 818 2.491803 TP
> > -5.190 818 5.967213 TP
> > -3.080 818 9.674018 TP
> > -4.020 818 12.402785 TP
> > -6.380 818 15.854839 TP
> > -4.570 818 17.926072 TP
> > -5.380 818 21.608264 TP
> > -7.210 818 25.060319 TP
> > -8.560 818 27.854839 TP
> > -7.300 818 30.156209 TP
> > -7.590 818 33.312374 TP
> > -7.050 818 36.600045 TP
> > -7.350 818 38.046620 TP
> > -9.040 818 41.893196 TP
> > -8.340 818 45.573770 TP
> > -6.890 818 48.131148 TP
> > -7.190 818 54.098361 TP
> > -7.690 818 57.312374 TP
> > -9.340 818 60.468538 TP
> > -9.580 818 62.572648 TP
> > -10.180 818 65.827442 TP
> > -9.000 818 69.443881 TP
> > -10.760 818 71.547990 TP
> > -10.580 818 74.112374 TP
> > -10.500 818 78.221963 TP
> > -10.460 818 83.252100 TP
> > -9.980 818 89.071278 TP
> > -4.540 535 0.000000 SN
> > -6.050 535 3.221918 SN
> > -4.040 535 5.983562 SN
> > -2.940 535 8.843836 SN
> > -4.360 535 12.197260 SN
> > -3.760 535 14.958904 SN
> > -2.780 535 18.641096 SN
> > -6.140 535 21.402740 SN
> > -6.070 535 24.164384 SN
> > -6.530 535 27.450528 SN
> > -7.320 535 31.057085 SN
> > -6.270 535 33.778397 SN
> > -6.480 535 36.991511 SN
> > -7.440 535 39.747945 SN
> > -9.400 535 42.509589 SN
> > -6.640 535 45.534247 SN
> > -6.170 535 48.098630 SN
> > -5.090 535 51.090411 SN
> > -4.660 535 53.786301 SN
> > -5.420 535 58.158904 SN
> > -8.420 535 60.920548 SN
> > -4.830 535 63.682192 SN
> > -5.210 535 66.673973 SN
> > -5.030 535 69.961644 SN
> > -4.720 535 72.460274 SN
> > -5.570 535 75.253806 SN
> > -4.240 535 79.122659 SN
> > -5.620 535 82.302987 SN
> > -5.180 535 85.286593 SN
> > -4.560 535 88.076712 SN
> > -3.730 535 91.265753 SN
> > -4.490 535 95.473973 SN
> > -5.010 535 99.221918 SN
> > -3.645 541 0.000000 SN
> > -2.130 541 3.024658 SN
> > -2.240 541 6.016438 SN
> > -4.490 541 9.073973 SN
> > -3.310 541 12.000000 SN
> > -3.320 541 16.339726 SN
> > -4.130 541 18.246575 SN
> > -3.640 541 21.271233 SN
> > -3.510 541 24.624658 SN
> > -5.260 541 27.612666 SN
> > -3.340 541 30.825780 SN
> > -3.990 541 33.678239 SN
> > -5.390 541 37.022502 SN
> > -9.960 541 39.616438 SN
> > -3.740 541 43.002740 SN
> > -4.550 541 45.600000 SN
> > -3.370 541 48.295890 SN
> > -4.810 541 50.893151 SN
> > -3.130 541 53.654795 SN
> > -3.770 541 57.632877 SN
> > -3.820 541 60.558904 SN
> > -5.160 541 63.090411 SN
> > -3.530 541 66.016438 SN
> > -4.690 567 0.000000 SN
> > -4.030 567 2.991781 SN
> > -2.080 567 6.049315 SN
> > -2.430 567 9.698630 SN
> > -3.500 567 12.723288 SN
> > -2.690 567 15.189041 SN
> > -3.260 567 18.476712 SN
> > -4.890 567 21.460768 SN
> > -3.940 567 24.673883 SN
> > -4.150 567 28.313227 SN
> > -2.570 567 31.068493 SN
> > -3.290 567 33.402740 SN
> > -2.650 567 36.394521 SN
> > -1.220 567 39.353425 SN
> > -2.230 567 45.764384 SN
> > -2.780 567 48.526027 SN
> > -3.230 567 51.780822 SN
> > -3.470 567 54.542466 SN
> > -2.440 567 57.041096 SN
> > -4.170 567 61.249315 SN
> > -3.440 567 63.715068 SN
> > -1.880 567 66.279452 SN
> > -2.150 567 69.231260 SN
> > -2.150 567 72.673883 SN
> > -7.010 567 89.720548 SN
> > -4.640 567 94.520548 SN
> > -5.600 567 96.723288 SN
> > -2.375 572 0.000000 SN
> > -2.920 572 3.452055 SN
> > -1.310 572 6.246575 SN
> > -1.890 572 10.158904 SN
> > -2.450 572 12.558904 SN
> > -2.590 572 15.189041 SN
> > -2.040 572 18.308826 SN
> > -1.570 572 21.685875 SN
> > -1.930 572 24.472760 SN
> > -1.300 572 27.817022 SN
> > -2.820 572 30.641096 SN
> > -1.240 572 33.600000 SN
> > -0.720 572 36.394521 SN
> > -0.440 572 39.156164 SN
> > -0.750 572 41.917808 SN
> > -1.310 572 45.567123 SN
> > -1.060 572 48.756164 SN
> > -0.670 572 51.517808 SN
> > -1.110 572 54.279452 SN
> > -0.870 572 57.501370 SN
> > -2.400 572 60.493151 SN
> > -1.790 572 63.484932 SN
> > -1.150 572 66.308826 SN
> > -0.550 572 68.800629 SN
> > -1.830 572 72.112104 SN
> > -1.830 572 75.030137 SN
> > -1.640 572 78.772603 SN
> > -2.340 572 81.468493 SN
> > -2.490 572 86.136986 SN
> > -1.840 572 90.147945 SN
> > -1.760 572 93.369863 SN
> > -0.970 572 96.657534 SN
> > -0.960 583 0.000000 SN
> > -1.150 583 3.189041 SN
> > -2.060 583 7.364384 SN
> > -1.710 583 9.402740 SN
> > -0.870 583 12.427397 SN
> > -2.100 583 15.185179 SN
> > -1.290 583 18.660588 SN
> > -1.350 583 21.185179 SN
> > -0.410 583 24.824523 SN
> > -2.750 583 27.550685 SN
> > -1.860 583 30.345205 SN
> > -1.750 583 33.336986 SN
> > 0.360 583 36.098630 SN
> > -1.200 583 38.893151 SN
> > -0.900 583 42.575342 SN
> > -1.350 583 45.501370 SN
> > -0.660 583 48.526027 SN
> > -0.950 583 51.254795 SN
> > -1.690 583 54.279452 SN
> > -0.410 583 57.073973 SN
> > -1.090 583 60.295890 SN
> > -0.590 583 63.021244 SN
> > -0.800 583 66.004851 SN
> > -0.700 583 69.250752 SN
> > -0.990 583 72.627801 SN
> > -0.240 583 75.879452 SN
> > -0.180 583 78.673973 SN
> > -1.000 583 81.402740 SN
> > -1.360 583 84.164384 SN
> > -1.240 583 86.958904 SN
> > -1.500 583 90.246575 SN
> > -1.410 583 93.468493 SN
> > -4.260 583 96.230137 SN
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide!
> >http://www.R-project.org/posting-guide.html
>
>
>
>
>
>---------------------------------



From ripley at stats.ox.ac.uk  Wed Mar 16 21:27:02 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 16 Mar 2005 20:27:02 +0000 (GMT)
Subject: [R] working with pairlists imported from HDF5, converting to
	data frames?
In-Reply-To: <42388E84.9000108@ku.edu>
References: <42388E84.9000108@ku.edu>
Message-ID: <Pine.LNX.4.61.0503162014530.7319@gannet.stats>

Does do.call("data.frame", effective) work?  I think it ought to.
If not, as.data.frame(as.list(effective)) would appear to.  In fact almost 
anything you do to a pairlist will turn it into a list, e.g. effective[].

This is really a bug in the hdf5 package, one that you should raise with 
the authors. The help says that groups map to lists, not pairlists, and 
pairlist -> list is easy at C level via PairToVectorList.


On Wed, 16 Mar 2005, Paul Johnson wrote:

> I've used the HDF5 library to bring some data into R. THe verbose output 
> looks like this:
>
>> hdf5load("hdfGraphWed_Mar_16_13_33_37_2005.hdf",load=T,verbosity=1,tidy=T)
> Processing object: cprSeats ...... which is a Group
> Processing object: Seats 0 ...... its a dataset......Finished dataset
> Processing object: Seats 1 ...... its a dataset......Finished dataset
> Processing object: Seats 2 ...... its a dataset......Finished dataset
> Processing object: Seats 3 ...... its a dataset......Finished dataset
> Processing object: Seats 4 ...... its a dataset......Finished dataset
> ... Done group cprSeats
> Processing object: effective ...... which is a Group
> Processing object: AggComp ...... its a dataset......Finished dataset
> Processing object: AggNonComp ...... its a dataset......Finished dataset
> Processing object: CPR ...... its a dataset......Finished dataset
> Processing object: PR ...... its a dataset......Finished dataset
> Processing object: SMD ...... its a dataset......Finished dataset
> ... Done group effective
>
>
> Each item inside the group "effective" is a vector of numbers.  I want to 
> convert effective into a data frame or matrix for use with matplot.
>
> However, R sees effective not as a collection of vectors, but as a pairlist. 
> I'm not a Lisp programmer, so don't understand the significance of the list 
> help page's comment about dotted lists.
>
>> class(effective)
> [1] "pairlist"
>> attributes(effective)
> $names
> [1] "SMD"        "PR"         "CPR"        "AggNonComp" "AggComp"
>
> I can access the elements in effective as list elements, either with 
> effective$SMD or effective[[1]], as in:
>
>> effective[[1]]
>  [1] 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000
>  [9] 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000
> [17] 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000
> [25] 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 4.761905 4.668534
> [33] 4.743833 4.743833 4.694836 4.672897 4.612546 4.612546 4.612546 4.950495
> [41] 4.766444 4.761905 4.329004 4.990020 4.930966 4.906771 4.378284 4.686036
> [49] 4.935834 4.793864 4.793864 4.541326 4.849661 4.730369 4.960317 4.159734
>
>
> But I can't force it into a data frame
>
>> as.data.frame(effective)
> Error in as.data.frame.default(effective) :
>        can't coerce pairlist into a data.frame
>
>
> But I can manually build the dataframe
>
>> 
> data.frame(effective$SMD,effective$PR,effective$CPR,effective$AggNonComp,effective$AggComp)
>
> But that is a bit frustrating for every individual dataset coming in.
>
> Is there a short cut?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From luke at stat.uiowa.edu  Wed Mar 16 21:28:17 2005
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Wed, 16 Mar 2005 14:28:17 -0600 (CST)
Subject: [R] workload of R
In-Reply-To: <16951.60004.528896.496049@stat.math.ethz.ch>
References: <16951.60004.528896.496049@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.61.0503161424540.17514@nokomis.stat.uiowa.edu>

On Wed, 16 Mar 2005, "Cheng, Bu Qi" wrote:

> Hi,
> 	We are working on R language compiler to find out the way to
> improve the performance of R in multi core processor and the parallelism
> in the workload of R. Where can I find the typical workload wrote by R?
>
> Thanks!
>
> Cheng, Buqi

There are several efforts underway for compiling R and also for
parallel computing in R.  If you could ask a clearer question we might
be able to help and cooperate.

luke

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



From gerifalte28 at hotmail.com  Wed Mar 16 21:27:51 2005
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Wed, 16 Mar 2005 20:27:51 +0000
Subject: [R] how to draw xyplot figure like figure 4.18 of MASS (4th) ?
In-Reply-To: <20050316170107.88075.qmail@web51309.mail.yahoo.com>
Message-ID: <BAY103-F211720E3BDBEDAE02E9433A6480@phx.gbl>

Ups, one mistake!  Change the second line of the code from library(lattice) 
to attach(d), so you get:

d<-read.table('clipboard', header = T)
attach(d)
plot(month,md, col = c('red','blue','black'), type='p')
lines(lowess(d[group=='NN',1]), col = 'red')
lines(lowess(d[group=='SN',1]), col = 'blue')
lines(lowess(d[group=='TP',1]),col = 'black')

par(mfrow = c(2, 2))
plot(d[group=='NN','month'],d[group=='NN','md'], col = 'red', type='p')
lines(lowess(d[group=='NN',1]), col = 'red')
plot(d[group=='SN','month'],d[group=='SN','md'], col = 'blue', type='p')
lines(lowess(d[group=='SN',1]), col = 'blue')
plot(d[group=='TP','month'],d[group=='TP','md'], col = 'black', type='p')
lines(lowess(d[group=='TP',1]), col = 'black')

Francisco


>From: Zhongming Yang <zhongmingyang at yahoo.com>
>To: "Francisco J. Zagmutt" <gerifalte28 at hotmail.com>, 
>r-help at stat.math.ethz.ch
>Subject: RE: [R] how to draw xyplot figure like figure 4.18 of MASS (4th) ?
>Date: Wed, 16 Mar 2005 09:01:07 -0800 (PST)
>
>Dear Francisco and All:
>
>Following is the source code to create figure 4.18 from MASS (4th).
>
>library(MASS)
>library(lattice)
>if(F) { # no data supplied
>xyplot(ratio ~ scant | subject, data = A5,
>       xlab = "scan interval (years)",
>       ylab = "ventricle/brain volume normalized to 1 at start",
>       subscripts = T, ID = A5$ID,
>       strip = function(factor, ...)
>          strip.default(..., factor.levels = labs, style = 1),
>       layout = c(8, 5, 1),
>       skip = c(rep(FALSE, 37), rep(TRUE, 1), rep(FALSE, 1)),
>       panel = function(x, y, subscripts, ID) {
>           panel.xyplot(x, y, type = "b", cex = 0.5)
>           which <- unique(ID[subscripts])
>           panel.xyplot(c(0, 1.5), pr3[names(pr3) == which],
>                        type = "l", lty = 3)
>           if(which == 303 || which == 341) points(1.4, 1.3)
>       })
>}
>
>But there is no data set available for that, I can't figure out many stuff. 
>So I provide my data set, hope you can help me.
>
>In my data set, there are 3 group patients, and 5 patients in each group. 
>The mds are the repeat measurements on month. I want draw a xyplot with 3 
>lines, each line for a group.
>
>
>Many thanks
>
>Zhongming Yang
>
>
>
>
>"Francisco J. Zagmutt" <gerifalte28 at hotmail.com> wrote:
>Dear Zhongming,
>
>By asking for the figure in the book you are restricting you question to
>only the people that has the 4th edition. I would love to help you but
>unfortunatelly I have the 3rd edition of MASS and there is no figure 4.18
>since chapter 4 is "Programming in S". Please give us an idea of what you
>want to do and we might be able to help you without looking at the book.
>
>Cheers
>
>Francisco
>
> >From: Zhongming Yang
> >To: r-help at stat.math.ethz.ch
> >Subject: [R] how to draw xyplot figure like figure 4.18 of MASS (4th) ?
> >Date: Wed, 16 Mar 2005 08:07:21 -0800 (PST)
> >
> >Dear All:
> >
> >Could you please tell me how I can draw figure formatted like figure 4.18
> >of MASS (4th) with the attached data set?
> >
> >Thanks
> >
> >Zhongming Yang
> >
> >
> >
> >---------------------------------
> >
> > md idno month group
> > -0.090 521 0.000000 NN
> > -1.330 521 12.460274 NN
> > -0.570 521 14.991781 NN
> > -2.130 559 0.000000 NN
> > -0.920 559 3.978082 NN
> > -1.730 559 6.016438 NN
> > -2.390 559 9.665753 NN
> > -1.300 559 12.460274 NN
> > -2.170 559 15.682192 NN
> > -2.620 559 17.950685 NN
> > -1.830 559 21.664406 NN
> > -3.090 559 25.533258 NN
> > -2.760 559 30.811947 NN
> > -1.240 559 33.830137 NN
> > -0.650 559 36.394521 NN
> > -1.200 559 38.893151 NN
> > -1.320 559 42.147945 NN
> > -2.000 559 45.600000 NN
> > -2.150 559 48.328767 NN
> > -1.430 559 52.569863 NN
> > -2.650 559 56.120548 NN
> > -0.870 559 60.032877 NN
> > -1.920 559 63.550685 NN
> > -2.320 559 65.786301 NN
> > -2.640 559 68.547945 NN
> > -2.030 559 71.533258 NN
> > -1.900 559 75.500472 NN
> > -1.420 559 78.254570 NN
> > -1.330 559 81.863014 NN
> > -2.120 559 84.657534 NN
> > -2.400 559 86.926027 NN
> > -2.410 559 90.147945 NN
> > -3.370 559 93.369863 NN
> > -0.720 559 96.624658 NN
> > -2.075 598 0.000000 NN
> > -2.260 598 3.484932 NN
> > -2.150 598 5.917808 NN
> > -1.420 598 9.828879 NN
> > -1.490 598 12.353470 NN
> > -3.040 598 16.025601 NN
> > -1.960 598 18.845273 NN
> > -2.780 598 22.224658 NN
> > -3.310 598 24.591781 NN
> > -4.420 598 27.517808 NN
> > -1.890 598 30.312329 NN
> > -3.000 598 33.304110 NN
> > -2.260 598 36.065753 NN
> > -0.730 598 40.010959 NN
> > -2.710 598 43.232877 NN
> > -2.430 598 45.994521 NN
> > -1.050 598 49.183562 NN
> > -2.190 598 52.438356 NN
> > -0.580 598 54.969863 NN
> > -2.050 598 57.501011 NN
> > -1.480 598 60.681338 NN
> > -0.960 598 63.664945 NN
> > -2.090 598 66.419043 NN
> > -3.180 598 69.435616 NN
> > -1.230 598 72.394521 NN
> > -2.170 598 74.761644 NN
> > -2.400 598 78.378082 NN
> > -3.630 598 81.698630 NN
> > -2.100 598 84.920548 NN
> > -3.940 598 87.156164 NN
> > -3.780 598 90.378082 NN
> > -5.690 598 95.967123 NN
> > -13.525 622 0.000000 NN
> > -12.670 622 3.680934 NN
> > -13.500 622 7.123557 NN
> > -13.700 622 9.910442 NN
> > -11.260 622 12.926836 NN
> > -12.100 622 15.846575 NN
> > -13.400 622 18.410959 NN
> > -12.330 622 21.435616 NN
> > -12.940 622 24.197260 NN
> > -12.540 622 27.156164 NN
> > -12.550 622 29.917808 NN
> > -11.900 622 33.830137 NN
> > -11.640 622 36.394521 NN
> > -12.100 622 38.893151 NN
> > -11.010 622 41.457534 NN
> > -12.050 622 46.684932 NN
> > -12.650 622 50.136986 NN
> > -11.620 622 54.303885 NN
> > -12.150 622 58.303885 NN
> > -12.990 622 60.959623 NN
> > -12.590 622 63.912329 NN
> > -13.570 622 66.936986 NN
> > -12.480 622 69.336986 NN
> > -12.800 622 72.263014 NN
> > -12.640 622 75.452055 NN
> > -13.830 622 81.073973 NN
> > -13.250 622 84.295890 NN
> > -13.700 622 90.213699 NN
> > -13.250 622 96.197260 NN
> > -2.190 801 0.000000 NN
> > -1.250 801 2.663014 NN
> > -1.550 801 5.589041 NN
> > -1.570 801 8.575612 NN
> > -0.880 801 11.755940 NN
> > -0.230 801 15.428071 NN
> > -0.770 801 17.985448 NN
> > -1.050 801 20.975342 NN
> > -2.260 801 24.394521 NN
> > -2.760 801 27.715068 NN
> > -1.550 801 29.950685 NN
> > -2.330 801 34.093151 NN
> > -1.390 801 36.394521 NN
> > -2.090 801 39.353425 NN
> > -3.050 801 41.917808 NN
> > -1.930 801 44.646575 NN
> > -4.040 801 48.328767 NN
> > -3.260 801 51.780822 NN
> > -2.810 801 54.115068 NN
> > -0.660 801 57.395284 NN
> > -1.800 801 62.903481 NN
> > -1.540 801 65.755940 NN
> > -0.880 801 69.567123 NN
> > -2.000 801 73.117808 NN
> > -1.610 801 76.142466 NN
> > -4.360 801 79.463014 NN
> > -3.200 801 80.712329 NN
> > -3.080 801 83.013699 NN
> > -2.350 801 88.306849 NN
> > -3.170 801 89.917808 NN
> > -3.570 801 95.342466 NN
> > -3.300 525 0.000000 TP
> > -2.500 525 2.991781 TP
> > -5.480 525 5.917808 TP
> > -1.140 525 8.712329 TP
> > -2.260 525 11.967123 TP
> > -0.670 525 14.926027 TP
> > -0.630 525 17.950685 TP
> > -0.600 525 21.336986 TP
> > -1.870 525 24.427397 TP
> > -1.790 525 26.860274 TP
> > -3.640 525 30.771345 TP
> > -2.860 525 33.328722 TP
> > -2.140 525 37.197575 TP
> > -1.560 525 39.787739 TP
> > -0.360 525 42.542466 TP
> > -1.900 525 45.304110 TP
> > -1.190 525 48.032877 TP
> > -3.090 525 51.024658 TP
> > -2.620 525 53.786301 TP
> > -1.360 525 58.126027 TP
> > -1.130 525 60.953425 TP
> > -1.390 525 64.142466 TP
> > -0.270 525 66.904110 TP
> > -1.640 525 69.665753 TP
> > -1.390 525 72.887671 TP
> > -2.550 525 75.221918 TP
> > -2.540 525 78.180822 TP
> > -1.640 525 81.623804 TP
> > -2.410 525 84.574624 TP
> > -2.530 525 88.017247 TP
> > -1.980 525 91.463014 TP
> > -3.060 525 93.895890 TP
> > -1.920 525 96.131507 TP
> > -1.650 525 99.320548 TP
> > -2.625 527 0.000000 TP
> > -2.370 527 2.991781 TP
> > 0.050 527 6.180822 TP
> > -0.270 527 9.041096 TP
> > 1.060 527 11.736986 TP
> > -3.030 527 15.221918 TP
> > -1.000 527 18.180822 TP
> > -1.270 527 21.895890 TP
> > -1.910 527 24.361644 TP
> > -2.350 527 27.649315 TP
> > -3.720 527 30.142825 TP
> > -3.310 527 33.355940 TP
> > -2.280 527 35.847743 TP
> > -1.860 527 39.290366 TP
> > -5.050 527 42.345205 TP
> > -3.160 527 45.106849 TP
> > -2.270 527 47.802740 TP
> > -1.850 527 50.630137 TP
> > -4.010 527 53.621918 TP
> > -4.520 527 56.383562 TP
> > -3.820 527 60.000000 TP
> > -6.440 527 65.293151 TP
> > -4.600 527 68.350685 TP
> > -5.280 527 71.802740 TP
> > -3.920 527 75.320548 TP
> > -5.080 527 78.175612 TP
> > -8.550 527 80.831350 TP
> > -4.900 527 84.601841 TP
> > -11.620 527 87.585448 TP
> > -6.090 527 91.956164 TP
> > -7.120 527 95.408219 TP
> > -6.365 570 0.000000 TP
> > -6.100 570 2.761644 TP
> > -4.950 570 5.983562 TP
> > -5.530 570 9.205479 TP
> > -3.640 570 11.967123 TP
> > -3.330 570 15.879452 TP
> > -4.950 570 18.310442 TP
> > -5.250 570 21.392410 TP
> > -5.540 570 24.376016 TP
> > -4.300 570 27.359623 TP
> > -4.530 570 29.884932 TP
> > -5.970 570 32.646575 TP
> > -4.950 570 37.019178 TP
> > -5.090 570 39.320548 TP
> > -4.000 570 42.312329 TP
> > -6.160 570 45.073973 TP
> > -6.490 570 49.216438 TP
> > -4.890 570 52.668493 TP
> > -6.620 570 56.350685 TP
> > -7.010 570 61.183562 TP
> > -7.290 570 63.978082 TP
> > -6.440 570 66.736672 TP
> > -7.950 570 69.917000 TP
> > -7.570 570 73.130115 TP
> > -8.150 570 76.113721 TP
> > -8.090 570 78.805479 TP
> > -9.670 570 82.553425 TP
> > -9.480 570 86.169863 TP
> > -9.120 570 90.147945 TP
> > -11.330 570 97.019178 TP
> > -3.750 615 0.000000 TP
> > -3.510 615 3.287671 TP
> > -4.160 615 5.848641 TP
> > -5.170 615 9.651920 TP
> > -4.600 615 12.438805 TP
> > -5.940 615 15.619133 TP
> > -6.270 615 18.608219 TP
> > -4.690 615 21.632877 TP
> > -7.820 615 24.361644 TP
> > -5.940 615 27.189041 TP
> > -5.680 615 30.180822 TP
> > -6.750 615 32.712329 TP
> > -5.130 615 36.854795 TP
> > -6.630 615 39.386301 TP
> > -7.450 615 41.917808 TP
> > -7.290 615 45.369863 TP
> > -9.590 615 48.361644 TP
> > -9.700 615 51.353425 TP
> > -9.570 615 54.799461 TP
> > -9.840 615 57.783068 TP
> > -9.800 615 60.766674 TP
> > -11.000 615 63.291264 TP
> > -11.360 615 66.805479 TP
> > -10.860 615 69.731507 TP
> > -10.610 615 72.493151 TP
> > -12.180 615 78.706849 TP
> > -12.570 615 84.690411 TP
> > -13.280 615 90.213699 TP
> > -15.720 615 96.197260 TP
> > 0.375 818 0.000000 TP
> > 1.640 818 2.491803 TP
> > -5.190 818 5.967213 TP
> > -3.080 818 9.674018 TP
> > -4.020 818 12.402785 TP
> > -6.380 818 15.854839 TP
> > -4.570 818 17.926072 TP
> > -5.380 818 21.608264 TP
> > -7.210 818 25.060319 TP
> > -8.560 818 27.854839 TP
> > -7.300 818 30.156209 TP
> > -7.590 818 33.312374 TP
> > -7.050 818 36.600045 TP
> > -7.350 818 38.046620 TP
> > -9.040 818 41.893196 TP
> > -8.340 818 45.573770 TP
> > -6.890 818 48.131148 TP
> > -7.190 818 54.098361 TP
> > -7.690 818 57.312374 TP
> > -9.340 818 60.468538 TP
> > -9.580 818 62.572648 TP
> > -10.180 818 65.827442 TP
> > -9.000 818 69.443881 TP
> > -10.760 818 71.547990 TP
> > -10.580 818 74.112374 TP
> > -10.500 818 78.221963 TP
> > -10.460 818 83.252100 TP
> > -9.980 818 89.071278 TP
> > -4.540 535 0.000000 SN
> > -6.050 535 3.221918 SN
> > -4.040 535 5.983562 SN
> > -2.940 535 8.843836 SN
> > -4.360 535 12.197260 SN
> > -3.760 535 14.958904 SN
> > -2.780 535 18.641096 SN
> > -6.140 535 21.402740 SN
> > -6.070 535 24.164384 SN
> > -6.530 535 27.450528 SN
> > -7.320 535 31.057085 SN
> > -6.270 535 33.778397 SN
> > -6.480 535 36.991511 SN
> > -7.440 535 39.747945 SN
> > -9.400 535 42.509589 SN
> > -6.640 535 45.534247 SN
> > -6.170 535 48.098630 SN
> > -5.090 535 51.090411 SN
> > -4.660 535 53.786301 SN
> > -5.420 535 58.158904 SN
> > -8.420 535 60.920548 SN
> > -4.830 535 63.682192 SN
> > -5.210 535 66.673973 SN
> > -5.030 535 69.961644 SN
> > -4.720 535 72.460274 SN
> > -5.570 535 75.253806 SN
> > -4.240 535 79.122659 SN
> > -5.620 535 82.302987 SN
> > -5.180 535 85.286593 SN
> > -4.560 535 88.076712 SN
> > -3.730 535 91.265753 SN
> > -4.490 535 95.473973 SN
> > -5.010 535 99.221918 SN
> > -3.645 541 0.000000 SN
> > -2.130 541 3.024658 SN
> > -2.240 541 6.016438 SN
> > -4.490 541 9.073973 SN
> > -3.310 541 12.000000 SN
> > -3.320 541 16.339726 SN
> > -4.130 541 18.246575 SN
> > -3.640 541 21.271233 SN
> > -3.510 541 24.624658 SN
> > -5.260 541 27.612666 SN
> > -3.340 541 30.825780 SN
> > -3.990 541 33.678239 SN
> > -5.390 541 37.022502 SN
> > -9.960 541 39.616438 SN
> > -3.740 541 43.002740 SN
> > -4.550 541 45.600000 SN
> > -3.370 541 48.295890 SN
> > -4.810 541 50.893151 SN
> > -3.130 541 53.654795 SN
> > -3.770 541 57.632877 SN
> > -3.820 541 60.558904 SN
> > -5.160 541 63.090411 SN
> > -3.530 541 66.016438 SN
> > -4.690 567 0.000000 SN
> > -4.030 567 2.991781 SN
> > -2.080 567 6.049315 SN
> > -2.430 567 9.698630 SN
> > -3.500 567 12.723288 SN
> > -2.690 567 15.189041 SN
> > -3.260 567 18.476712 SN
> > -4.890 567 21.460768 SN
> > -3.940 567 24.673883 SN
> > -4.150 567 28.313227 SN
> > -2.570 567 31.068493 SN
> > -3.290 567 33.402740 SN
> > -2.650 567 36.394521 SN
> > -1.220 567 39.353425 SN
> > -2.230 567 45.764384 SN
> > -2.780 567 48.526027 SN
> > -3.230 567 51.780822 SN
> > -3.470 567 54.542466 SN
> > -2.440 567 57.041096 SN
> > -4.170 567 61.249315 SN
> > -3.440 567 63.715068 SN
> > -1.880 567 66.279452 SN
> > -2.150 567 69.231260 SN
> > -2.150 567 72.673883 SN
> > -7.010 567 89.720548 SN
> > -4.640 567 94.520548 SN
> > -5.600 567 96.723288 SN
> > -2.375 572 0.000000 SN
> > -2.920 572 3.452055 SN
> > -1.310 572 6.246575 SN
> > -1.890 572 10.158904 SN
> > -2.450 572 12.558904 SN
> > -2.590 572 15.189041 SN
> > -2.040 572 18.308826 SN
> > -1.570 572 21.685875 SN
> > -1.930 572 24.472760 SN
> > -1.300 572 27.817022 SN
> > -2.820 572 30.641096 SN
> > -1.240 572 33.600000 SN
> > -0.720 572 36.394521 SN
> > -0.440 572 39.156164 SN
> > -0.750 572 41.917808 SN
> > -1.310 572 45.567123 SN
> > -1.060 572 48.756164 SN
> > -0.670 572 51.517808 SN
> > -1.110 572 54.279452 SN
> > -0.870 572 57.501370 SN
> > -2.400 572 60.493151 SN
> > -1.790 572 63.484932 SN
> > -1.150 572 66.308826 SN
> > -0.550 572 68.800629 SN
> > -1.830 572 72.112104 SN
> > -1.830 572 75.030137 SN
> > -1.640 572 78.772603 SN
> > -2.340 572 81.468493 SN
> > -2.490 572 86.136986 SN
> > -1.840 572 90.147945 SN
> > -1.760 572 93.369863 SN
> > -0.970 572 96.657534 SN
> > -0.960 583 0.000000 SN
> > -1.150 583 3.189041 SN
> > -2.060 583 7.364384 SN
> > -1.710 583 9.402740 SN
> > -0.870 583 12.427397 SN
> > -2.100 583 15.185179 SN
> > -1.290 583 18.660588 SN
> > -1.350 583 21.185179 SN
> > -0.410 583 24.824523 SN
> > -2.750 583 27.550685 SN
> > -1.860 583 30.345205 SN
> > -1.750 583 33.336986 SN
> > 0.360 583 36.098630 SN
> > -1.200 583 38.893151 SN
> > -0.900 583 42.575342 SN
> > -1.350 583 45.501370 SN
> > -0.660 583 48.526027 SN
> > -0.950 583 51.254795 SN
> > -1.690 583 54.279452 SN
> > -0.410 583 57.073973 SN
> > -1.090 583 60.295890 SN
> > -0.590 583 63.021244 SN
> > -0.800 583 66.004851 SN
> > -0.700 583 69.250752 SN
> > -0.990 583 72.627801 SN
> > -0.240 583 75.879452 SN
> > -0.180 583 78.673973 SN
> > -1.000 583 81.402740 SN
> > -1.360 583 84.164384 SN
> > -1.240 583 86.958904 SN
> > -1.500 583 90.246575 SN
> > -1.410 583 93.468493 SN
> > -4.260 583 96.230137 SN
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide!
> >http://www.R-project.org/posting-guide.html
>
>
>
>
>
>---------------------------------



From MDavy at hortresearch.co.nz  Wed Mar 16 21:53:15 2005
From: MDavy at hortresearch.co.nz (Marcus Davy)
Date: Thu, 17 Mar 2005 09:53:15 +1300
Subject: [R] How to extract x rows to get  x pvalues using t.test
Message-ID: <s23953b1.079@hra2.marc.hort.cri.nz>


Hi,
if a striped down version of t.test is required for speed, before implementing a rewrite I would check out the multtest Bioconductor package.

It takes a fraction of a second to do 56000 t-tests on a 2.4 Ghz PIV.

 dim(X)
[1] 56000     4

pcols <- 4
replicates <- rep(0:1, each=2)

unix.time({tscores <- mt.teststat(X, classlabel=replicates, test="t.equalvar") 
        dfs <- pcols - 2
        pvalues <- 2*(1-pt(abs(tscores), df=dfs))})
[1] 0.21 0.05 0.26 0.00 0.00

> length(pvalues)
[1] 56000

Check out ?mt.teststat and its test argument options.


Marcus

>>> "Jagarlamudi, Choudary" <choudary.jagar at swosu.edu> 17/03/2005 7:16:13 a.m. >>>
Thanks to everyone who posted on this topic. I tried apply() as Ramasamy had suggested and it took 40 seconds on my machine. The for loop however took over 4 minutes and i gave up. I am going to strip the t.test function and write it as suggested by Andy. Hope that will be the quickest.
 
Once again thank you for all who have posted on this.
 
Choudary Jagarlamudi
Instructor Computer Science
Southwestern Oklahoma State University
STF 254
100 campus Drive
Weatherford OK 73096
Tel 580-774-7136

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

______________________________________________________

The contents of this e-mail are privileged and/or confidenti...{{dropped}}



From msvika at mscc.huji.ac.il  Wed Mar 16 22:24:53 2005
From: msvika at mscc.huji.ac.il (Vicky Landsman)
Date: Wed, 16 Mar 2005 23:24:53 +0200
Subject: [R] OPG variance estimate 
Message-ID: <00e401c52a6e$98f59e50$a200a8c0@HOME2>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050316/2f60c6cf/attachment.pl

From brett at hbrc.govt.nz  Wed Mar 16 22:54:45 2005
From: brett at hbrc.govt.nz (Brett Stansfield)
Date: Thu, 17 Mar 2005 10:54:45 +1300
Subject: [R] (no subject)
Message-ID: <3542A1BF5AE1984D9FF577DA2CF8BA9868B100@MSX2>

Dear R
I'm trying to do a correlation matrix for some variables I have.
Unfortunately there are some NA entries for some of the variables 
I tried the following

cor(sleep[c("logbw", "logbrw", "SlowSleep", "ParaSleep", "loglife",
"loggest")])

but it told me
Error in cor(sleep[c("logbw", "logbrw", "SlowSleep", "ParaSleep", "loglife",
: 
        missing observations in cov/cor

How can I get R to conduct a correlation matrix for this data set??

brett



From sundar.dorai-raj at pdf.com  Wed Mar 16 22:59:29 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 16 Mar 2005 15:59:29 -0600
Subject: correlation with NA (was Re: [R] (no subject))
In-Reply-To: <3542A1BF5AE1984D9FF577DA2CF8BA9868B100@MSX2>
References: <3542A1BF5AE1984D9FF577DA2CF8BA9868B100@MSX2>
Message-ID: <4238AC41.50307@pdf.com>



Brett Stansfield wrote on 3/16/2005 3:54 PM:
> Dear R
> I'm trying to do a correlation matrix for some variables I have.
> Unfortunately there are some NA entries for some of the variables 
> I tried the following
> 
> cor(sleep[c("logbw", "logbrw", "SlowSleep", "ParaSleep", "loglife",
> "loggest")])
> 
> but it told me
> Error in cor(sleep[c("logbw", "logbrw", "SlowSleep", "ParaSleep", "loglife",
> : 
>         missing observations in cov/cor
> 
> How can I get R to conduct a correlation matrix for this data set??
> 
> brett

See ?cor. I think you want:

cor(sleep, use = "complete.obs") # or "pairwise.complete.obs"

(please read the posting guide, which would tell you to use an 
informative subject line and also point you to the help files)

PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html

--sundar



From haynesm at cfr.nichd.nih.gov  Wed Mar 16 23:00:23 2005
From: haynesm at cfr.nichd.nih.gov (Haynes, Maurice (NIH/NICHD))
Date: Wed, 16 Mar 2005 17:00:23 -0500
Subject: [R] Code to replace nested for loops
Message-ID: <6000BB14AFA9A741BC2315A598837ED5166F4C3C@nihexchange4.nih.gov>

Dear list members,

How can I replace the nested for loops at then end of the script
below with more efficient code?

# Begin script__________________________________________________
# Dichotomous scores for 100 respondents on 3 items with 
# probabilities of a correct response = .6, .4, and .7, 
# respectively
x1 <- rbinom(100,1,.6)
x2 <- rbinom(100,1,.4)
x3 <- rbinom(100,1,.7)

# 'theta.vec' is a vector holding 31 possible levels of theta
# ranging from -3 to +3 in intervals of .2.
theta.vec <- seq(-3,3,.2)
theta  <- sample(rep(theta.vec,5),100)
x.mat <- (cbind(x1,x2,x3,theta))
rm(x1,x2,x3,theta)

nc <- ncol(x.mat)
ni <- nc - 1
nr <- nrow(x.mat)
ntheta <- length(theta.vec)

# 'opt.mat' is a matrix which will hold the observed proportions
# correct at each level of theta for each item.  Rows have
# dimnames corresponding to the 31 levels  of theta and columns
# have dimnames corresponding to the item names.
opt.mat <- matrix(rep(NA,ni*ntheta),nrow=ntheta, ncol=ni, 
    dimnames=list(round(theta.vec,1),c(dimnames(x.mat)[[2]][1:ni])))

# Set of nested for-loops to compute the observed proportions
# correct at each level of theta for each item and store them in
# the appropriate row and column locations of the 'opt.mat'.
system.time(
for(j in 1:ni) 
    {for (k in 1:ntheta) {
        n.theta.cat <- 0
        sum.theta.cat <- 0
        kt <- theta.vec[k]
        for(i in 1:nr) { 
            it <- x.mat[i,nc]
            if(identical(all.equal(kt,it),TRUE)) n.theta.cat <- n.theta.cat
+ 1
            if(identical(all.equal(kt,it),TRUE)) sum.theta.cat <-
sum.theta.cat + x.mat[i,j]
            if(n.theta.cat > 0) opt.mat[k,j] <- sum.theta.cat / n.theta.cat
            }
        }
    }
)
# End script____________________________________________________

On my Dell 863 MHz machine with 512 MB RAM running Windows XP SP2,
the loop to 21 sec to execute.

Thanks,

Maurice Haynes
National Institute of Child Health and Human Development
Child and Family Research Section
6705 Rockledge Drive, Suite 8030
Bethesda, MD  20892
Voice: 301-496-8180
Fax: 301-496-2766
E-Mail: mh192j at nih.gov



From spencer.graves at pdf.com  Wed Mar 16 23:04:51 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 16 Mar 2005 14:04:51 -0800
Subject: NAs in "cor"?  (was:  Re: [R] (no subject))
In-Reply-To: <3542A1BF5AE1984D9FF577DA2CF8BA9868B100@MSX2>
References: <3542A1BF5AE1984D9FF577DA2CF8BA9868B100@MSX2>
Message-ID: <4238AD83.808@pdf.com>

      "?cor" revealed that the "cor" function has an argument "use" with 
a default of "all.obs" and options of "complete.obs"' or 
'"pairwise.complete.obs".  Either of these other two should get you past 
this error message. 

      hope this helps.
      spencer graves
p.s.  As indicated by earlier remarks on this list, the posting guide 
"http://www.R-project.org/posting-guide.html" has helped people answer 
their own questions in the process of preparing a question for this 
list.  You may wish to try it if you haven't already. 

Brett Stansfield wrote:

>Dear R
>I'm trying to do a correlation matrix for some variables I have.
>Unfortunately there are some NA entries for some of the variables 
>I tried the following
>
>cor(sleep[c("logbw", "logbrw", "SlowSleep", "ParaSleep", "loglife",
>"loggest")])
>
>but it told me
>Error in cor(sleep[c("logbw", "logbrw", "SlowSleep", "ParaSleep", "loglife",
>: 
>        missing observations in cov/cor
>
>How can I get R to conduct a correlation matrix for this data set??
>
>brett
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From andy_liaw at merck.com  Thu Mar 17 00:30:49 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 16 Mar 2005 18:30:49 -0500
Subject: [R] Code to replace nested for loops
Message-ID: <3A822319EB35174CA3714066D590DCD50994E870@usrymx25.merck.com>

You may be able to simplify it further, but just by replacing the whole
inner-most loop with

      opt.mat2[k,j] <- mean(x.mat[kt == x.mat[, nc], j]) 

the computation is instantaneous on my 1.6GHz Pentium M laptop (whereas your
code took just over 7 seconds).

HTH,
Andy

> From: Haynes, Maurice (NIH/NICHD)
> 
> Dear list members,
> 
> How can I replace the nested for loops at then end of the script
> below with more efficient code?
> 
> # Begin script__________________________________________________
> # Dichotomous scores for 100 respondents on 3 items with 
> # probabilities of a correct response = .6, .4, and .7, 
> # respectively
> x1 <- rbinom(100,1,.6)
> x2 <- rbinom(100,1,.4)
> x3 <- rbinom(100,1,.7)
> 
> # 'theta.vec' is a vector holding 31 possible levels of theta
> # ranging from -3 to +3 in intervals of .2.
> theta.vec <- seq(-3,3,.2)
> theta  <- sample(rep(theta.vec,5),100)
> x.mat <- (cbind(x1,x2,x3,theta))
> rm(x1,x2,x3,theta)
> 
> nc <- ncol(x.mat)
> ni <- nc - 1
> nr <- nrow(x.mat)
> ntheta <- length(theta.vec)
> 
> # 'opt.mat' is a matrix which will hold the observed proportions
> # correct at each level of theta for each item.  Rows have
> # dimnames corresponding to the 31 levels  of theta and columns
> # have dimnames corresponding to the item names.
> opt.mat <- matrix(rep(NA,ni*ntheta),nrow=ntheta, ncol=ni, 
>     dimnames=list(round(theta.vec,1),c(dimnames(x.mat)[[2]][1:ni])))
> 
> # Set of nested for-loops to compute the observed proportions
> # correct at each level of theta for each item and store them in
> # the appropriate row and column locations of the 'opt.mat'.
> system.time(
> for(j in 1:ni) 
>     {for (k in 1:ntheta) {
>         n.theta.cat <- 0
>         sum.theta.cat <- 0
>         kt <- theta.vec[k]
>         for(i in 1:nr) { 
>             it <- x.mat[i,nc]
>             if(identical(all.equal(kt,it),TRUE)) n.theta.cat 
> <- n.theta.cat
> + 1
>             if(identical(all.equal(kt,it),TRUE)) sum.theta.cat <-
> sum.theta.cat + x.mat[i,j]
>             if(n.theta.cat > 0) opt.mat[k,j] <- sum.theta.cat 
> / n.theta.cat
>             }
>         }
>     }
> )
> # End script____________________________________________________
> 
> On my Dell 863 MHz machine with 512 MB RAM running Windows XP SP2,
> the loop to 21 sec to execute.
> 
> Thanks,
> 
> Maurice Haynes
> National Institute of Child Health and Human Development
> Child and Family Research Section
> 6705 Rockledge Drive, Suite 8030
> Bethesda, MD  20892
> Voice: 301-496-8180
> Fax: 301-496-2766
> E-Mail: mh192j at nih.gov
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From david.netherway at adelaide.edu.au  Thu Mar 17 00:47:56 2005
From: david.netherway at adelaide.edu.au (David J. Netherway)
Date: Thu, 17 Mar 2005 10:17:56 +1030
Subject: [R] principal component analysis
In-Reply-To: <1416.10.0.10.126.1110955951.squirrel@poisson.statisticon.se>
References: <5D01E8305096D3119D7D00508B5EBBF415BBD658@ntmsg0133.corpmail.telstra.com.au>
	<1416.10.0.10.126.1110955951.squirrel@poisson.statisticon.se>
Message-ID: <4238C5AC.7060505@adelaide.edu.au>

Hello,

I have used "prcomp" and the variances for the first 3 PC's are 2.65, 
1.97 and 0.38.

When I plot the principal component values for each data point I can see 
that the points lie in a plane as one might expect from the variances.

But this plane is diagonal through the 3D space of the first 3 PC's.  My 
question is: is it usual to follow a PC analysis with an eigen analysis 
to align this plane with with 2 principal directions, or is there a way  
of incorporating this into "prcomp".

Thanks, David



From das at cshl.edu  Thu Mar 17 00:55:34 2005
From: das at cshl.edu (Das, Rajdeep)
Date: Wed, 16 Mar 2005 18:55:34 -0500
Subject: [R] decision values and probability in SVM
Message-ID: <C8696843AE995F4EA4CDC3E2B83482A953FEB9@mailbox02.cshl.edu>

Hi,
 
I am using SVM from e1071 package.  I can get decision values very easily. But whenever, I try to get the probability measure, it returns NULL. I use the following codes to generate decision.values and probability. Is there anything wrong in it?
 
 
predictor<-svm(train[,c(x1, x2, x3)], train[,x4], probability=TRUE)
 
pred<-predict(predictor, test[,c(x1, x2, x3)], probability=TRUE, decision.values=TRUE)
 
attr(pred, "decision.values")[1,]
 
attr(pred, "probabilities")[1,]
 
 
Thanks for your help.
 
Raj



From Leon.Barmuta at utas.edu.au  Thu Mar 17 01:48:37 2005
From: Leon.Barmuta at utas.edu.au (Leon Barmuta)
Date: Thu, 17 Mar 2005 11:48:37 +1100
Subject: [R] Varying grid.rect in different panels of a Lattice plot
Message-ID: <6.2.0.14.2.20050317100331.023b3b30@postoffice.sandybay.utas.edu.au>

Dear r-help,

Sleep-deprivation from having 2 youngsters under 2 around the house is 
fuzzing my brain, so please be gentle if the answer to this query is obvious!

In the example below, I'm trying to use grid.rect to add grey rectangles to 
the panels of a lattice plot to indicate which months spawning occurred of 
a (very cute) native Tasmanian fish. The fish in the two lakes spawned at 
slightly different times, so grid.rect needs to be conditioned on when 
spawning happened in each lake. However, the panel function I wrote first, 
and reproduce below, inserts grey rectangles for all dates that spawning 
occured pooled across the two lakes. So after dreging r-help, I've messed 
with subscripts and tried fiddling with panel.number, but can't get this to 
work. Any suggestions most welcome!

# Make up a short data set

library(lattice)
library(grid)

Lake <- rep(c("Crescent","Sorell"), each=13)
Spawning <- c("Y", rep("N",7), rep("Y",4), rep("N",8), rep("Y",5), "N")
Catch <- rpois(26, 30) # fake data
Plotdate <- rep(seq(as.Date("2000/10/1"), by="month", length=13),2)

trellis.device(theme=col.whitebg())

# panel function that doesn't quite work

myPanel <- function(x, y, ...) {
  grid.rect(x=unit(Plotdate[Spawning == "Y"], "native"),
       just="left", width=unit(31, "native"), # a bit of a fudge
       gp=gpar(col="transparent", fill="light grey"))
       panel.xyplot(x, y, ...)}

xyplot(Catch ~ Plotdate|Lake, type="b",
       panel=myPanel,
       layout=c(1,2), xlab="",
       scales = list(x=list(rot = 45, at=as.numeric(Plotdate),
                     labels=format(Plotdate, "%b%Y"))))

Regards,

Leon

-------------------------
Dr Leon A. Barmuta, Senior Lecturer in Zoology
School of Zoology & TAFI, University of Tasmania, Private Bag 5, Hobart, 
Tasmania 7001, Australia
Phone (03) 6226 2785;  Fax (03) 6226 2745; International callers replace 
(03) with +61 3
School of Zoology web page: http://www.scieng.utas.edu.au/zoo/
My web page: http://www.scieng.utas.edu.au/zoo/pagedetails.asp?lpersonId=222



From twiens at interbaun.com  Thu Mar 17 01:59:01 2005
From: twiens at interbaun.com (Trevor Wiens)
Date: Wed, 16 Mar 2005 17:59:01 -0700
Subject: [R] Cross validation, one more time (hopefully the last)
Message-ID: <20050316175901.4b915a3a.twiens@interbaun.com>

I apologize for posting on this question again, but unfortunately, I don't have and can't get access to MASS for at least three weeks. I have found some code on the web however which implements the prediction error algorithm in cv.glm.

http://www.bioconductor.org/workshops/NGFN03/modelsel-exercise.pdf

Now I've tried to adapt it to my purposes, but since I'm not deeply familiar with R programming, I don't know why it doesn't work. Now checking the r-help list faq it seems this is an appropriate question. 

I've included my attempted function below. The error I get is:

logcv(basp.data, form, 'basp', 'recordyear')
Error in order(na.last, decreasing, ...) : 
        Argument 1 is not a vector

My questions are, why doesn't this work, and how do I fix it.

I'm using the formula function to create the formula that I'm sending to my function. And the mdata is a data.frame. I'm assumed that if I passed the column names as strings (response variable - rvar, fold variable - fvar) this would work. Apparently however it doesn't.

Lastly, since I don't have access to MASS and there are apparently many examples of doing this kind of thing in MASS, could someone tell me if this function looks approximately correct?

Thanks

T

------------------------------------------------

logcv <- function(mdata, formula, rvar, fvar) {
require(Hmisc)

# sort by fold variable
sorted <- mdata[order(mdata$fvar), ]

# get fold values and count for each group
vardesc <- describe(sorted$fvar)$values
fvarlist <- as.integer(dimnames(vardesc)[[2]])
k <- length(fvarlist)
countlist <- vardesc[1,1]
for (i in 2:k)
{
countlist[i] <- vardesc[1,i]
}
n <- length(sorted$fvar)

# fit to all the mdata
fit.all <- glm(formula, sorted, family=binomial)
pred.all <- ifelse( predict(fit.all, type="response") < 0.5, 0, 1)

#setup
pred.c <- list()
error.i <- vector(length=k)

for (i in 1:k) 
{
fit.i <- glm(formula, subset(sorted, sorted$fvar != fvarlist[i]), family=binomial)
pred.i <- ifelse(predict(fit.i, newdata=subset(sorted, sorted$fvar == fvarlist[i]), type="response") < 0.5, 0, 1)
pred.c[[i]] = pred.i
pred.all.i <- ifelse(predict(fit.i, newdata=sorted, type="response") < 0.5, 0, 1)
error.i[i] <- sum(sorted$rvar != pred.all.i)/n
}
pred.cc <- unlist(pred.c)
delta.cv.k <- sum(sorted$rvar != pred.cc)/n
p.k <- countlist/n
delta.app <- mean(sorted$rvar != pred.all)/n

delta.acv.k <- delta.cv.k + delta.app - sum(p.k*error.i)

print(delta.acv.k)
}


-- 
Trevor Wiens 
twiens at interbaun.com



From deepayan at stat.wisc.edu  Thu Mar 17 02:28:22 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 16 Mar 2005 19:28:22 -0600
Subject: [R] Varying grid.rect in different panels of a Lattice plot
In-Reply-To: <6.2.0.14.2.20050317100331.023b3b30@postoffice.sandybay.utas.edu.au>
References: <6.2.0.14.2.20050317100331.023b3b30@postoffice.sandybay.utas.edu.au>
Message-ID: <200503161928.22433.deepayan@stat.wisc.edu>

On Wednesday 16 March 2005 18:48, Leon Barmuta wrote:
> Dear r-help,
>
> Sleep-deprivation from having 2 youngsters under 2 around the house
> is fuzzing my brain, so please be gentle if the answer to this query
> is obvious!
>
> In the example below, I'm trying to use grid.rect to add grey
> rectangles to the panels of a lattice plot to indicate which months
> spawning occurred of a (very cute) native Tasmanian fish. The fish in
> the two lakes spawned at slightly different times, so grid.rect needs
> to be conditioned on when spawning happened in each lake. However,
> the panel function I wrote first, and reproduce below, inserts grey
> rectangles for all dates that spawning occured pooled across the two
> lakes. So after dreging r-help, I've messed with subscripts and tried
> fiddling with panel.number, but can't get this to work. Any
> suggestions most welcome!

If I understand you right, you could do something like:



myPanel <- function(x, y, groups, subscripts, ...)
{
    grid.rect(x = unit(x[groups[subscripts] == "Y"], "native"),
              just="left", width=unit(31, "native"), # a bit of a fudge
              gp = gpar(col="transparent", fill="light grey"))
    panel.xyplot(x, y, ...)
}


xyplot(Catch ~ Plotdate | Lake, type="b",
       groups = Spawning,
       panel = myPanel,
       layout= c(1,2), xlab="",
       scales = list(x=list(rot = 45, at=as.numeric(Plotdate),
                     labels=format(Plotdate, "%b%Y"))))



There's nothing (much) special about 'groups', you could also do 


myPanel <- function(x, y, flag, subscripts, ...)
{
    grid.rect(x = unit(x[flag[subscripts] == "Y"], "native"),
              just="left", width=unit(31, "native"), # a bit of a fudge
              gp = gpar(col="transparent", fill="light grey"))
    panel.xyplot(x, y, ...)
}


xyplot(Catch ~ Plotdate | Lake, type="b",
       flag = Spawning,
       panel = myPanel,
       layout= c(1,2), xlab="",
       scales = list(x=list(rot = 45, at=as.numeric(Plotdate),
                     labels=format(Plotdate, "%b%Y"))))



except that if you had your variables in a data frame (supplied as the 
'data' argument) and not in your search path, anything supplied as 
'groups' would also be evaluated in the data frame.

Deepayan



> # Make up a short data set
>
> library(lattice)
> library(grid)
>
> Lake <- rep(c("Crescent","Sorell"), each=13)
> Spawning <- c("Y", rep("N",7), rep("Y",4), rep("N",8), rep("Y",5),
> "N") Catch <- rpois(26, 30) # fake data
> Plotdate <- rep(seq(as.Date("2000/10/1"), by="month", length=13),2)
>
> trellis.device(theme=col.whitebg())
>
> # panel function that doesn't quite work
>
> myPanel <- function(x, y, ...) {
>   grid.rect(x=unit(Plotdate[Spawning == "Y"], "native"),
>        just="left", width=unit(31, "native"), # a bit of a fudge
>        gp=gpar(col="transparent", fill="light grey"))
>        panel.xyplot(x, y, ...)}
>
> xyplot(Catch ~ Plotdate|Lake, type="b",
>        panel=myPanel,
>        layout=c(1,2), xlab="",
>        scales = list(x=list(rot = 45, at=as.numeric(Plotdate),
>                      labels=format(Plotdate, "%b%Y"))))
>
> Regards,
>
> Leon
>
> -------------------------
> Dr Leon A. Barmuta, Senior Lecturer in Zoology
> School of Zoology & TAFI, University of Tasmania, Private Bag 5,
> Hobart, Tasmania 7001, Australia
> Phone (03) 6226 2785;  Fax (03) 6226 2745; International callers
> replace (03) with +61 3
> School of Zoology web page: http://www.scieng.utas.edu.au/zoo/
> My web page:
> http://www.scieng.utas.edu.au/zoo/pagedetails.asp?lpersonId=222



From brett at hbrc.govt.nz  Thu Mar 17 03:17:21 2005
From: brett at hbrc.govt.nz (Brett Stansfield)
Date: Thu, 17 Mar 2005 15:17:21 +1300
Subject: [R] (no subject)
Message-ID: <3542A1BF5AE1984D9FF577DA2CF8BA9868B103@MSX2>

Dear R
I recently created some variables in R as in I opened a data set and then
produced log base 10 transformations on some of the variables. When I ask R
to do a simple x, y plot it recognises the raw data but does not recognise
the log transformed variables. It says

> plot(logbrw, ParaSleep, type="n")
Error in plot(logbrw, ParaSleep, type = "n") : 
        Object "logbrw" not found
> text(logbrw, ParaSleep, labels=row.names(sleep), cex=0.8, col="blue")
Error in text(logbrw, ParaSleep, labels = row.names(sleep), cex = 0.8,  : 
        Object "logbrw" not found


So do I have to somehow change the data for R to recognise the newly created
variables?

What should I do?

brett



From Simon.Blomberg at anu.edu.au  Thu Mar 17 04:43:34 2005
From: Simon.Blomberg at anu.edu.au (Simon Blomberg)
Date: Thu, 17 Mar 2005 14:43:34 +1100
Subject: [R] (no subject)
In-Reply-To: <3542A1BF5AE1984D9FF577DA2CF8BA9868B103@MSX2>
References: <3542A1BF5AE1984D9FF577DA2CF8BA9868B103@MSX2>
Message-ID: <a06110402be5eabecfbe6@[150.203.51.113]>

I assume "opened a data set" means that you have attached a data 
frame. If you add new variables to the data frame (e.g. by 
transforming a variable in that data.frame), you will have to 
detach() and re- attach() it in order to get access to the variables 
without using the $ operator. I think this is in the manual somewhere.

Cheers,

Simon.



>Dear R
>I recently created some variables in R as in I opened a data set and then
>produced log base 10 transformations on some of the variables. When I ask R
>to do a simple x, y plot it recognises the raw data but does not recognise
>the log transformed variables. It says
>
>>  plot(logbrw, ParaSleep, type="n")
>Error in plot(logbrw, ParaSleep, type = "n") :
>         Object "logbrw" not found
>>  text(logbrw, ParaSleep, labels=row.names(sleep), cex=0.8, col="blue")
>Error in text(logbrw, ParaSleep, labels = row.names(sleep), cex = 0.8,  :
>         Object "logbrw" not found
>
>
>So do I have to somehow change the data for R to recognise the newly created
>variables?
>
>What should I do?
>
>brett
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Simon Blomberg, B.Sc.(Hons.), Ph.D, M.App.Stat.
Visiting Fellow
School of Botany & Zoology
The Australian National University
Canberra ACT 0200
Australia

T: +61 2 6125 8057  email: Simon.Blomberg at anu.edu.au
F: +61 2 6125 5573

CRICOS Provider # 00120C



From MSchwartz at MedAnalytics.com  Thu Mar 17 05:16:33 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed, 16 Mar 2005 22:16:33 -0600
Subject: [R] New Vars in Data Frame Not Visible (was: no subject)
In-Reply-To: <a06110402be5eabecfbe6@[150.203.51.113]>
References: <3542A1BF5AE1984D9FF577DA2CF8BA9868B103@MSX2>
	<a06110402be5eabecfbe6@[150.203.51.113]>
Message-ID: <1111032993.18956.18.camel@horizons.localdomain>

On Thu, 2005-03-17 at 14:43 +1100, Simon Blomberg wrote:
> I assume "opened a data set" means that you have attached a data 
> frame. If you add new variables to the data frame (e.g. by 
> transforming a variable in that data.frame), you will have to 
> detach() and re- attach() it in order to get access to the variables 
> without using the $ operator. I think this is in the manual somewhere.

<snip>

"An Introduction To R", Section 6.3.2 "attach() and detach()",
starting on page 27 and continuing on page 28.

HTH,

Marc Schwartz



From twiens at interbaun.com  Thu Mar 17 05:31:01 2005
From: twiens at interbaun.com (Trevor Wiens)
Date: Wed, 16 Mar 2005 21:31:01 -0700
Subject: [R] Cross validation, one more time (hopefully the last)
In-Reply-To: <20050316175901.4b915a3a.twiens@interbaun.com>
References: <20050316175901.4b915a3a.twiens@interbaun.com>
Message-ID: <20050316213101.3bea5aa9.twiens@interbaun.com>

On Wed, 16 Mar 2005 17:59:01 -0700
Trevor Wiens <twiens at interbaun.com> wrote:

> I apologize for posting on this question again, but unfortunately, I don't have and can't get access to MASS for at least three weeks. I have found some code on the web however which implements the prediction error algorithm in cv.glm.
> 
> http://www.bioconductor.org/workshops/NGFN03/modelsel-exercise.pdf
> 
> Now I've tried to adapt it to my purposes, but since I'm not deeply familiar with R programming, I don't know why it doesn't work. Now checking the r-help list faq it seems this is an appropriate question. 
> 

OK. I've determined why that didn't work. But I'm still unsure if I've implemented the algorithm correctly. Any suggestions for testing would be appreciated. The corrected function is attached.

Thanks for your assistance.

------------------------
logcv <- function(mdata, formula, rvar, fvar) {
require(Hmisc)

# determine index of variables
rpos <- match(rvar, names(mdata))
fpos <- match(fvar, names(mdata))

# sort by fold variable
sorted <- mdata[order(mdata[[fpos]]), ]

# get fold values and count for each group
vardesc <- describe(sorted[[fpos]])$values
fvarlist <- as.integer(dimnames(vardesc)[[2]])
k <- length(fvarlist)
countlist <- vardesc[1,1]
for (i in 2:k)
{
countlist[i] <- vardesc[1,i]
}
n <- length(sorted[[fpos]])

# fit to all the mdata
fit.all <- glm(formula, sorted, family=binomial)
pred.all <- ifelse( predict(fit.all, type="response") < 0.5, 0, 1)

#setup
pred.c <- list()
error.i <- vector(length=k)

for (i in 1:k) 
{
fit.i <- glm(formula, subset(sorted, sorted[[fpos]] != fvarlist[i]), family=binomial)
pred.i <- ifelse(predict(fit.i, newdata=subset(sorted, sorted[[fpos]] == fvarlist[i]), type="response") < 0.5, 0, 1)
pred.c[[i]] = pred.i
pred.all.i <- ifelse(predict(fit.i, newdata=sorted, type="response") < 0.5, 0, 1)
error.i[i] <- sum(sorted[[rpos]] != pred.all.i)/n
}
pred.cc <- unlist(pred.c)
delta.cv.k <- sum(sorted[[rpos]] != pred.cc)/n
p.k <- countlist/n
delta.app <- mean(sorted[[rpos]] != pred.all)/n

delta.acv.k <- delta.cv.k + delta.app - sum(p.k*error.i)

return(delta.acv.k)
}

----------

T
-- 
Trevor Wiens 
twiens at interbaun.com



From lavanya_ldb2000 at yahoo.co.in  Thu Mar 17 06:15:59 2005
From: lavanya_ldb2000 at yahoo.co.in (Lakshmi Dhevi Baskar)
Date: Wed, 16 Mar 2005 21:15:59 -0800 (PST)
Subject: [R] help for matrix formation.
Message-ID: <20050317051559.4834.qmail@web8501.mail.in.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050316/588e5806/attachment.pl

From Tom.Mulholland at dpi.wa.gov.au  Thu Mar 17 07:12:54 2005
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Thu, 17 Mar 2005 14:12:54 +0800
Subject: [R] help for matrix formation.
Message-ID: <33F91FB3FDF42E4180428AC66A5CF30B02D3BA9B@afhex01.dpi.wa.gov.au>

I'm not sure I am answereing your question, but here goes

# Create a vector with 2400 items
x <- runif(2400)

# Create a 600 by 4 matrix
y <- matrix(x,ncol = 4)

#If you needed the matrix to be done row by row
#y <- matrix(x,ncol = 4,byrow = T)

# Extract values from a particular part of the matrix
z <- y[500,3]  #row 500 column 3
z

# Extract values that meet certain criterion
z <- y[y < 0.01]
z

# Find postion of those that are extracted
which(y < 0.01)

HTH, Tom


> -----Original Message-----
> From: Lakshmi Dhevi Baskar [mailto:lavanya_ldb2000 at yahoo.co.in]
> Sent: Thursday, 17 March 2005 1:16 PM
> To: r-help-request at stat.math.ethz.ch
> Cc: r-help at stat.math.ethz.ch
> Subject: [R] help for matrix formation.
> 
> 
> Dear people, 
> 
>  I've been  trying to find a  way to do the following. 
> 
> I have a data set in text file with 3 columns and 2400 rows. 
> i tried to read the table as
> fisrt<-("ex.txt",header=FALSE)
>  
> I would like to read the third column values (which has 2400 
> value) and split them into matrix of size (600,4):
>  
> as 
> first 600 column values in first column in matrix and next 
> 600 next values(600 to 1200) as values in second column in 
> matrix and so on.
>  
> and could you also suggest me how to retrieve those items in 
> matrix like matrix(520,3) =0 ...
>  
> thanks in advance for the help.
>  
> 
> 		
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From Tom.Mulholland at dpi.wa.gov.au  Thu Mar 17 07:24:47 2005
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Thu, 17 Mar 2005 14:24:47 +0800
Subject: [R] (no subject)
Message-ID: <33F91FB3FDF42E4180428AC66A5CF30B02D3BA9C@afhex01.dpi.wa.gov.au>

type ?cor and read the help file

In particular read it till you find the entry that tells you how to deal with missing observations. You need to do this because as you get more competent you will undoubdtedly come across other issues, so learning the format of the help and realising why you need to check the Arguments section will reduce your frustration in the future.

You also need to read the posting guide to make sure that you don't put people offside by failing to follow a basic set of standards which include giving a decent description of your problem in the subject of your message.

cor(x, y = NULL, use = "all.obs",
          method = c("pearson", "kendall", "spearman"))

use is the appropriate argument. All you need to do is to decide which option to wish to use.

Tom

> -----Original Message-----
> From: Brett Stansfield [mailto:brett at hbrc.govt.nz]
> Sent: Thursday, 17 March 2005 5:55 AM
> To: R help (E-mail)
> Subject: [R] (no subject)
> 
> 
> Dear R
> I'm trying to do a correlation matrix for some variables I have.
> Unfortunately there are some NA entries for some of the variables 
> I tried the following
> 
> cor(sleep[c("logbw", "logbrw", "SlowSleep", "ParaSleep", "loglife",
> "loggest")])
> 
> but it told me
> Error in cor(sleep[c("logbw", "logbrw", "SlowSleep", 
> "ParaSleep", "loglife",
> : 
>         missing observations in cov/cor
> 
> How can I get R to conduct a correlation matrix for this data set??
> 
> brett
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From bu.qi.cheng at intel.com  Thu Mar 17 07:46:28 2005
From: bu.qi.cheng at intel.com (Cheng, Bu Qi)
Date: Thu, 17 Mar 2005 14:46:28 +0800
Subject: [R] Questions on the typical algorithms or solution in most
	scientific computation area
Message-ID: <CEBA252FE3382B4F9147D8686C72455B01B8576F@pdsmsx402.ccr.corp.intel.com>

Hi,
	I am a compiler guy and not familiar with the most scientific
computation. We are doing research work on R language for multi core
processor. Would you like give me any suggestion on the typical
algorithms or solutions in most scientific computation area? 
	Such as: What are the most popular algorithms in statistical and
graphical methods for the analysis of genomic data?

Thanks!

Cheng, Buqi



From mmohebbi at gmail.com  Thu Mar 17 08:42:23 2005
From: mmohebbi at gmail.com (Matt Mohebbi)
Date: Wed, 16 Mar 2005 23:42:23 -0800
Subject: [R] Quantiles of data in a contingency table
Message-ID: <8181824e0503162342e34c5f3@mail.gmail.com>

Hello, 

I have data of the following form:

> data <- data.frame(type=c("c","d","e"), size=c(10,20,30), count=c(20,10,5))
> data
  type size count
1    c   10    20
2    d   20    10
3    e   30     5

I would like to compute the quantiles of size given the counts. For
instance, in this example, the median size would be 10. Is there an
easy way of doing this?

Is there a good way to deal with data in this format in general? Much
of R seems to center around having an entry for each item. This
question (http://www.r-project.org/nocvs/mail/r-help/2000/0102.html)
seems to be related but no one provided an answer.

Thanks, 
Matt



From ales.ziberna at guest.arnes.si  Thu Mar 17 09:25:29 2005
From: ales.ziberna at guest.arnes.si (=?windows-1250?Q?Ale=9A_=8Eiberna?=)
Date: Thu, 17 Mar 2005 09:25:29 +0100
Subject: [R] Moving form Windows XP to Linux (Ubuntu 4 / debian)
Message-ID: <019001c52acb$282b2110$1209f9c2@ales>

Hello!



I am trying to move my work in R from Windows to Linux. However I am missing 
some of the functionality I was used to under Windows. I tried running R 
2.0.1 by typing R in the terminal and via Emacs/ESS. R Gui currently does 
not work on my Linux. Currently one of my problems is:

Under Windows, I could terminate any R function by pressing "ESC", but this 
does not work under Linux. Is there any other way to do that under Linux?



Thanks in advance for any answer!

Ales Ziberna



From markus.jantti at iki.fi  Thu Mar 17 09:29:16 2005
From: markus.jantti at iki.fi (=?ISO-8859-1?Q?Markus_J=E4ntti?=)
Date: Thu, 17 Mar 2005 10:29:16 +0200
Subject: [R] Quantiles of data in a contingency table
In-Reply-To: <8181824e0503162342e34c5f3@mail.gmail.com>
References: <8181824e0503162342e34c5f3@mail.gmail.com>
Message-ID: <42393FDC.6010302@iki.fi>

Matt Mohebbi wrote:
> Hello, 
> 
> I have data of the following form:
> 
> 
>>data <- data.frame(type=c("c","d","e"), size=c(10,20,30), count=c(20,10,5))
>>data
> 
>   type size count
> 1    c   10    20
> 2    d   20    10
> 3    e   30     5
> 
> I would like to compute the quantiles of size given the counts. For
> instance, in this example, the median size would be 10. Is there an
> easy way of doing this?

One at least is to the function wtd.median [and wtd.quantile] in package 
Hmisc by Frank Harrell.

install.packages("Hmisc")
library(Hmisc)
wtd.median(data$size, data$weights)

is likely a route to get you what you want.

regards,

markus
> 
> Is there a good way to deal with data in this format in general? Much
> of R seems to center around having an entry for each item. This
> question (http://www.r-project.org/nocvs/mail/r-help/2000/0102.html)
> seems to be related but no one provided an answer.
> 
> Thanks, 
> Matt
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Markus Jantti
Abo Akademi University
markus.jantti at iki.fi
http://www.iki.fi/~mjantti



From slist at oomvanlieshout.net  Thu Mar 17 10:05:16 2005
From: slist at oomvanlieshout.net (Sander Oom)
Date: Thu, 17 Mar 2005 11:05:16 +0200
Subject: [R] Landscape indeces analysis methods as an R package!?
In-Reply-To: <00ce01c52a52$dddefaf0$b0c65c90@forecol.wisc.edu>
References: <00ce01c52a52$dddefaf0$b0c65c90@forecol.wisc.edu>
Message-ID: <4239484C.6070404@oomvanlieshout.net>

Dear Barry,

Thanks for your stimulating reply. As you see I have send a CC of this 
reply to the R mailing list. The R mailing list will be the best place 
to send your queries. You can subscribe here: 
http://www.r-project.org/mail.html

 I would think there is an interest in the provision of landscape 
indices analysis methods in R. There are several packages for landscape 
indices analysis available (Fragstats, APACK, IAN), but all use their 
own user and data interfaces. Only the r.le tools are available in a 
more general software: GRASS GIS. It would be usefull to have the 
functionality within the powerful data analysis tool R. Of course 
providing an R package will remove most of the user and data interface 
requirements as they will be taken care off by R. Only the core 
landscape indices methods need to be included. You will have to consult 
the R mailing list on how to translate your code into an R package!

The spatial aspects of R are further developed at the moment and spatial 
packages become more and more powerful. Look here for most recent 
development: http://www.r-project.org/Rgeo

R can currently read (relevant R package name in brackets: ASCII grid 
(with custom function or Adehabitat), shape files (maptools and 
shapefiles), GRASS files (grass) and ArcInfo files (RArcInfo), many 
others via external gdal (rgdal). I would say plenty of opportunities!

Hope this gets you under way!

Cheers,

Sander.


DeZonia, Barry wrote:

>Hi Sander,
>
>APACK is no longer being developed but is still available for download.
>There isn't a Linux version.
>
>APACK has been superceded by IAN
>(http://landscape.forest.wisc.edu/projects/ian/). It is written in Ruby and
>runs on Windows platforms. A Linux port could be done with a little effort.
>
>You are only the second person to talk about making an R package. I've
>considered this and may yet do so. I've been studying what to do and how for
>a little while now. If you wanted to provide input as to what R users' needs
>are I would be appreciative. One question I have is how do users currently
>get raster data loaded into R (as a matrix I suppose but what file formats
>are supported)? I've seen the pixmap library but the formats are not broadly
>supported.
>
>-----Original Message-----
>From: Sander Oom [mailto:sander at oomvanlieshout.net] 
>Sent: Wednesday, March 16, 2005 3:49 AM
>To: apack-mail at facstaff.wisc.edu
>Subject: Apack information?
>
>Dear Apack developers,
>
>Could you inform me about the current status of APACK?
>
>Is a version available for Linux?
>
>Would it be possible to translate APACK into an R package?
>
>Looking forward to more information.
>
>Yours,
>
>Sander Oom.
>
>  
>



From unung at enciety.com  Thu Mar 17 10:10:20 2005
From: unung at enciety.com (Unung Istopo Hartanto)
Date: Thu, 17 Mar 2005 16:10:20 +0700
Subject: [R] Quantiles of data in a contingency table
In-Reply-To: <8181824e0503162342e34c5f3@mail.gmail.com>
References: <8181824e0503162342e34c5f3@mail.gmail.com>
Message-ID: <1111050620.3498.103.camel@IT05>

Try.

median(rep(data$size, data$count))

thanks,

regards,

On Thu, 2005-03-17 at 14:42, Matt Mohebbi wrote:
> Hello, 
> 
> I have data of the following form:
> 
> > data <- data.frame(type=c("c","d","e"), size=c(10,20,30), count=c(20,10,5))
> > data
>   type size count
> 1    c   10    20
> 2    d   20    10
> 3    e   30     5
> 
> I would like to compute the quantiles of size given the counts. For
> instance, in this example, the median size would be 10. Is there an
> easy way of doing this?
> 
> Is there a good way to deal with data in this format in general? Much
> of R seems to center around having an entry for each item. This
> question (http://www.r-project.org/nocvs/mail/r-help/2000/0102.html)
> seems to be related but no one provided an answer.
> 
> Thanks, 
> Matt
> 

-- 
Unung Istopo Hartanto <unung at enciety.com>
ENCIETY Business Consult



From laurent.mauron at credit-suisse.com  Thu Mar 17 10:06:55 2005
From: laurent.mauron at credit-suisse.com (Mauron Laurent (KETR 31))
Date: Thu, 17 Mar 2005 10:06:55 +0100
Subject: [R] Compiling "embedding R" examples
Message-ID: <ED765D0AD42FD6408805FA8A766868D103C4E8AA@sxchs009b.itzrh.ska.com>

Hi,

I am working at a major financial institution and we would like to embed R in one of our front office application. 
The application is written in C/C++ so I started by trying to compile the examples in "tests/Embedding" of R 2.0.1.

I have modified "tests/Embedding/Makefile" according  https://stat.ethz.ch/pipermail/r-help/2005-February/064341.html 
and set "LD_LIBRARY_PATH" using 

export LD_LIBRARY_PATH="/home/laurent/R-clean/lib/R/lib"

But I get the following error messages during linking:

---------------------
laurent at pollux $ make clean
laurent at pollux $ make
gcc -I. -I../../src/include -I/home/laurent/R-2.0.1/src/include -I/usr/local/include -DHAVE_CONFIG_H   -g -O2 -c /home/laurent/R-2.0.1/tests/Embedding/Rtest.c -o Rtest.o
gcc -I. -I../../src/include -I/home/laurent/R-2.0.1/src/include -I/usr/local/include -DHAVE_CONFIG_H   -g -O2 -c /home/laurent/R-2.0.1/tests/Embedding/embeddedRCall.c -o embeddedRCall.o
../../bin/R CMD LINK gcc -o Rtest Rtest.o embeddedRCall.o -L/home/laurent/R-clean/lib -lR
mkdir .libs
gcc -o Rtest Rtest.o embeddedRCall.o  -L/home/laurent/R-clean/lib -lR -R/home/laurent/R-clean/lib/R/lib
Undefined                       first referenced
 symbol                             in file
MAIN__                              /home/laurent/R-clean/lib/libR.so
ld: fatal: Symbol referencing errors. No output written to Rtest
collect2: ld returned 1 exit status
*** Error code 1
make: Fatal error: Command failed for target `Rtest'
-----------------------

I have installed R from source using the following commands. I am running on solaris 8xx

-----------------------
laurent at pollux $ cd /home/laurent/R-clean/
laurent at pollux $ /home/laurent/R-2.0.1/configure --enable-R-shlib --prefix=/home/laurent/R-clean
laurent at pollux $ make
laurent at pollux $ make install
-----------------------

Has anyone an idea where is the problem? I would be extremly grateful if someone could help us.

Best regards,

Laurent



From laurent.mauron at credit-suisse.com  Thu Mar 17 10:12:05 2005
From: laurent.mauron at credit-suisse.com (Mauron Laurent (KETR 31))
Date: Thu, 17 Mar 2005 10:12:05 +0100
Subject: [R] [TEST] Do not read
Message-ID: <ED765D0AD42FD6408805FA8A766868D103C4E8AB@sxchs009b.itzrh.ska.com>

test



From menze at urz.uni-heidelberg.de  Thu Mar 17 10:39:23 2005
From: menze at urz.uni-heidelberg.de (bjoern h menze)
Date: Thu, 17 Mar 2005 10:39:23 +0100 (CET)
Subject: [R] kernlab sigest
In-Reply-To: <200503121110.j2CB5Lx6008618@hypatia.math.ethz.ch>
Message-ID: <Pine.A41.4.42.0503171027330.25140-100000@aixterm9.urz.uni-heidelberg.de>

hello,

I have the following problem setting parameter 'frac' in the sigest
function of the kernlab package.

## executing the ?sigest example:
library(kernlab)
data(spam)
srange <- sigest(type~.,data = spam)

## works fine...

## setting 'frac' explicitly
## (in this case even to the default of .25)
options(error=recover)
srange <- sigest(type~.,data = spam, frac = .25)

## fails..

Error in model.frame(formula, rownames, variables, varnames, extras,
extranames,  :
        variable lengths differ

Enter a frame number, or 0 to exit
1:sigest(type ~ ., data = spam, frac = 0.25)
2:sigest(type ~ ., data = spam, frac = 0.25)
3:.local(x, ...)
4:eval(m, parent.frame())
5:eval(expr, envir, enclos)
6:model.frame(data = ..1, frac = 0.25, formula = x)
7:model.frame

any ideas?

thank you,
Bjoern


---

bjoern menze
menze @ uni-hd de
# 0170 5894150 (mobil)
# 06221 548829 (institut)
# 06221 470787 (heidelberg)
bergstrasse 42  69120 heidelberg



From eric.pellegrini at chemie.uni-erlangen.de  Thu Mar 17 11:19:49 2005
From: eric.pellegrini at chemie.uni-erlangen.de (Eric Pellegrini)
Date: Thu, 17 Mar 2005 11:19:49 +0100
Subject: [R] Question about hist
Message-ID: <200503171119.49286.eric.pellegrini@chemie.uni-erlangen.de>

Hi all, 

here is my problem:

I have a list (called rms) that contains for each of its element a different 
number of values. 

Based on that list, I generate an histogram for each of its elements using:

histList <- lapply(rms,hist,breaks=seq(0,4,0.1),plot=FALSE) 

that gives me a list of histograms (called histList)

Now, I would like to get the cumulative sum for the field $counts of each of 
the element of histList using cumsum function.

Is that possible given the way I used or is there a simpler one ?

Thank you very much

	Eric

-- 
Eric Pellegrini, PhD
Computer-Chemie-Centrum
University of Erlangen-N?rnberg
N?gelbachstra?e, 25
D-91052 Erlangen
Germany



From dimitris.rizopoulos at med.kuleuven.ac.be  Thu Mar 17 11:29:15 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Thu, 17 Mar 2005 11:29:15 +0100
Subject: [R] Question about hist
References: <200503171119.49286.eric.pellegrini@chemie.uni-erlangen.de>
Message-ID: <012401c52adc$2b426370$0540210a@www.domain>

you mean something like this:

lapply(histList, function(x) cumsum(x$counts))

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Eric Pellegrini" <eric.pellegrini at chemie.uni-erlangen.de>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, March 17, 2005 11:19 AM
Subject: [R] Question about hist


> Hi all,
>
> here is my problem:
>
> I have a list (called rms) that contains for each of its element a 
> different
> number of values.
>
> Based on that list, I generate an histogram for each of its elements 
> using:
>
> histList <- lapply(rms,hist,breaks=seq(0,4,0.1),plot=FALSE)
>
> that gives me a list of histograms (called histList)
>
> Now, I would like to get the cumulative sum for the field $counts of 
> each of
> the element of histList using cumsum function.
>
> Is that possible given the way I used or is there a simpler one ?
>
> Thank you very much
>
> Eric
>
> -- 
> Eric Pellegrini, PhD
> Computer-Chemie-Centrum
> University of Erlangen-N?rnberg
> N?gelbachstra?e, 25
> D-91052 Erlangen
> Germany
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From eesteves at ualg.pt  Thu Mar 17 11:30:04 2005
From: eesteves at ualg.pt (eesteves@ualg.pt)
Date: Thu, 17 Mar 2005 10:30:04 +0000
Subject: [R] xyplot w/ panel.lmline "solution"
Message-ID: <20050317103004.y5vbngqr6s0swogg@wmail.ualg.pt>

Dear Sebastian Luque (and All R Users)

With the following code I managed to plot different characters and regression
lines for panels 2 ("Day of year 101") and >4 ("Days of year" 151, 157 and
172):

xyplot(log(no.larvae)~age.cls|factor(day),data=mortal,
	layout=c(7,1),aspect=5/3,
	xlab="Age class (d)",ylab="Ln(Abundance)",
         ylim=c(-2.5,6.5),xlim=c(0,30),
	panel = function(x, y,panel.number) {
	if(panel.number==2){
	panel.xyplot(x, y,col=1)
	panel.xyplot(x[6:11],y[6:11],pch=16,col=1)
	panel.lmline(x[6:11],y[6:11])}
	else{
	panel.xyplot(x, y,col=1)
	panel.xyplot(x[2:11],y[2:11],pch=16,col=1)
	panel.lmline(x[2:11],y[2:11])}
	if(panel.number>4){
	panel.xyplot(x, y,col=1)
	panel.xyplot(x[14:20],y[14:20],pch=16,col=2)
	panel.lmline(x[14:20],y[14:20],lty=2)}
	})

The resulting plot is herein (attached MortalityRates.pdf file).

Thanks to you all, Eduardo Esteves
-------------- next part --------------
A non-text attachment was scrubbed...
Name: MortalityRates.pdf
Type: application/pdf
Size: 32485 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20050317/731f9c46/MortalityRates.pdf

From jonathan.charrier at bordeaux.inra.fr  Thu Mar 17 11:46:04 2005
From: jonathan.charrier at bordeaux.inra.fr (Jonathan Charrier)
Date: Thu, 17 Mar 2005 11:46:04 +0100
Subject: [R] error in solve_technical question
Message-ID: <42395FEC.1030303@bordeaux.inra.fr>

Hi everybody,

it's a technical question .

i have a matrix with 30 columns and 40000 rows, 

i start my program and  i found this error:

"error in solve.default(sBB + Z[,,i] %*% Gamma %*% t(Z[,,i])):
system is computationally singular: reciprocal condition number = 
7.6377e-018 "

 is it R limit?


thanks a lot.

Jonathan Charrier



From ripley at stats.ox.ac.uk  Thu Mar 17 11:46:44 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 17 Mar 2005 10:46:44 +0000 (GMT)
Subject: [R] Moving form Windows XP to Linux (Ubuntu 4 / debian)
In-Reply-To: <019001c52acb$282b2110$1209f9c2@ales>
References: <019001c52acb$282b2110$1209f9c2@ales>
Message-ID: <Pine.LNX.4.61.0503171045310.16409@gannet.stats>

On Thu, 17 Mar 2005, [windows-1250] Alea }iberna wrote:

> I am trying to move my work in R from Windows to Linux. However I am missing 
> some of the functionality I was used to under Windows. I tried running R 
> 2.0.1 by typing R in the terminal and via Emacs/ESS. R Gui currently does not 
> work on my Linux. Currently one of my problems is:
>
> Under Windows, I could terminate any R function by pressing "ESC", but this 
> does not work under Linux. Is there any other way to do that under Linux?

Ctrl-C, as works under Rterm.exe.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Mar 17 11:50:07 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 17 Mar 2005 10:50:07 +0000 (GMT)
Subject: [R] Compiling "embedding R" examples
In-Reply-To: <ED765D0AD42FD6408805FA8A766868D103C4E8AA@sxchs009b.itzrh.ska.com>
References: <ED765D0AD42FD6408805FA8A766868D103C4E8AA@sxchs009b.itzrh.ska.com>
Message-ID: <Pine.LNX.4.61.0503171047510.16409@gannet.stats>

Please read the posting guide and

1) Use the appropriate list, R-devel, and

2) Tell us enough about your environment, for example which OS this is.

On Thu, 17 Mar 2005, Mauron Laurent (KETR 31) wrote:

> Hi,
>
> I am working at a major financial institution and we would like to embed R in one of our front office application.
> The application is written in C/C++ so I started by trying to compile the examples in "tests/Embedding" of R 2.0.1.
>
> I have modified "tests/Embedding/Makefile" according  https://stat.ethz.ch/pipermail/r-help/2005-February/064341.html
> and set "LD_LIBRARY_PATH" using
>
> export LD_LIBRARY_PATH="/home/laurent/R-clean/lib/R/lib"
>
> But I get the following error messages during linking:
>
> ---------------------
> laurent at pollux $ make clean
> laurent at pollux $ make
> gcc -I. -I../../src/include -I/home/laurent/R-2.0.1/src/include -I/usr/local/include -DHAVE_CONFIG_H   -g -O2 -c /home/laurent/R-2.0.1/tests/Embedding/Rtest.c -o Rtest.o
> gcc -I. -I../../src/include -I/home/laurent/R-2.0.1/src/include -I/usr/local/include -DHAVE_CONFIG_H   -g -O2 -c /home/laurent/R-2.0.1/tests/Embedding/embeddedRCall.c -o embeddedRCall.o
> ../../bin/R CMD LINK gcc -o Rtest Rtest.o embeddedRCall.o -L/home/laurent/R-clean/lib -lR
> mkdir .libs
> gcc -o Rtest Rtest.o embeddedRCall.o  -L/home/laurent/R-clean/lib -lR -R/home/laurent/R-clean/lib/R/lib
> Undefined                       first referenced
> symbol                             in file
> MAIN__                              /home/laurent/R-clean/lib/libR.so
> ld: fatal: Symbol referencing errors. No output written to Rtest
> collect2: ld returned 1 exit status
> *** Error code 1
> make: Fatal error: Command failed for target `Rtest'
> -----------------------
>
> I have installed R from source using the following commands. I am running on solaris 8xx
>
> -----------------------
> laurent at pollux $ cd /home/laurent/R-clean/
> laurent at pollux $ /home/laurent/R-2.0.1/configure --enable-R-shlib --prefix=/home/laurent/R-clean
> laurent at pollux $ make
> laurent at pollux $ make install
> -----------------------
>
> Has anyone an idea where is the problem? I would be extremly grateful if someone could help us.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Achim.Zeileis at wu-wien.ac.at  Thu Mar 17 12:17:23 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Thu, 17 Mar 2005 12:17:23 +0100
Subject: [R] kernlab sigest
In-Reply-To: <Pine.A41.4.42.0503171027330.25140-100000@aixterm9.urz.uni-heidelberg.de>
References: <200503121110.j2CB5Lx6008618@hypatia.math.ethz.ch>
	<Pine.A41.4.42.0503171027330.25140-100000@aixterm9.urz.uni-heidelberg.de>
Message-ID: <20050317121723.32206089.Achim.Zeileis@wu-wien.ac.at>

Bjoern,

thanks for your mail. But when reporting problems with a contributed
package, please contact the maintainer first or at least Cc him when
writing to R-help.

The problem below is in the formula method of sigest because the frac
argument gets passed on to model.frame which causes the error. I'll
commit a fix, but you can do it also easily locally if you add the 
second line of
  m$scaled <- NULL
  m$frac <- NULL
in the formula method of sigest.

Best,
Z

On Thu, 17 Mar 2005 10:39:23 +0100 (CET) bjoern h menze wrote:

> hello,
> 
> I have the following problem setting parameter 'frac' in the sigest
> function of the kernlab package.
> 
> ## executing the ?sigest example:
> library(kernlab)
> data(spam)
> srange <- sigest(type~.,data = spam)
> 
> ## works fine...
> 
> ## setting 'frac' explicitly
> ## (in this case even to the default of .25)
> options(error=recover)
> srange <- sigest(type~.,data = spam, frac = .25)
> 
> ## fails..
> 
> Error in model.frame(formula, rownames, variables, varnames, extras,
> extranames,  :
>         variable lengths differ
> 
> Enter a frame number, or 0 to exit
> 1:sigest(type ~ ., data = spam, frac = 0.25)
> 2:sigest(type ~ ., data = spam, frac = 0.25)
> 3:.local(x, ...)
> 4:eval(m, parent.frame())
> 5:eval(expr, envir, enclos)
> 6:model.frame(data = ..1, frac = 0.25, formula = x)
> 7:model.frame
> 
> any ideas?
> 
> thank you,
> Bjoern
> 
> 
> ---
> 
> bjoern menze
> menze @ uni-hd de
> # 0170 5894150 (mobil)
> # 06221 548829 (institut)
> # 06221 470787 (heidelberg)
> bergstrasse 42  69120 heidelberg
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From nioniodesbois at yahoo.fr  Thu Mar 17 12:43:49 2005
From: nioniodesbois at yahoo.fr (Guillaume STORCHI)
Date: Thu, 17 Mar 2005 12:43:49 +0100 (CET)
Subject: [R] Moving form Windows XP to Linux (Ubuntu 4 / debian)
Message-ID: <20050317114349.83032.qmail@web86908.mail.ukl.yahoo.com>

There's no real R user interface under linux, but it's not that better to have
one...ESS/Emacs is pretty good!
(you'll just get nervous when you'll want to save plots, look rplots up in
goolge)    

*Try Rcmdr package, hope sci-views-R we'll be available soon for non-M$windoz
OS
    *or have a look in CRAN->other->RGUIs something called RKward if you run
KDE
    *only if you installed R from a source R-...-tar.gz and did a ./configure
--enable-shlib, ./configure --with-gnome when installed type R
--with-gui='gnome'. if you run Gnome.
    *or a poor one by typing R --with-gui='tk'

For ctrl-C I've had the same problem, but it do works sometimes if you select
the ESS-buffer...  otherwise I don't know

Let me know if you get the clue

Good luck,
Guillaume


From mbibo at qldnet.com.au  Thu Mar 17 12:46:00 2005
From: mbibo at qldnet.com.au (Michael Bibo)
Date: Thu, 17 Mar 2005 11:46:00 +0000 (UTC)
Subject: [R] Re: Installing R on Mandrake 10.1
References: <4235D611.80201@uniroma2.it>
	<16950.41491.249522.890367@stat.math.ethz.ch>
	<42371E9D.9010109@gmail.com>
Message-ID: <loom.20050317T120118-459@post.gmane.org>

Christian <christianmacaro <at> gmail.com> writes:

> 
> Dear all.
> 
> First of all, thanks to Jon, Martin, Bogdan and Roland since they tried 
> to help me.
> 
> In order I tried to
> 1) install the libf2c0-3.4.1-4mdk.i586.rpm.
> 2) install R 2.0.1 from the source.
> 
> 1) Didn't work, since the "info" is still not satisfied
> 2) I wasn't able to configure it. I mean:
> 
> a) as root I uzipped the archive in the home/krisse directory
> b) ./configure in the home/krisse/R-2.0.1 directory
> the resulting message was that neither a fortran compiler nor f2c was found.
> 
> Then I looked for a fortran compiler........
> What I have understood is that a fortran compiler is already included in 
> the gcc3.4.1-4mdk (already installed).
> Is that correct?
> In the /usr/bin directory there are g++ an similar things but none of 
> the g77, f77, xlf, frt, pgf77, fl32, af77, fort77, f90, xlf90, pgf90, 
> epcf90, f95, fort, xlf95, lf95, g95, and fc.

<snip>

Christian,

I have been using R with Mandrake since about mdk 9.2.  Like you, I really don't
consider myself any sort of Linux expert - I rely more on the gui-based tools. 
 At first I used the R rpm's from CRAN (thanks to those who provided them).  In
more recent times I have installed from source in order to remain up to date
with both Mandrake and R, and to benefit from a slight performance improvement.
 I am currently running R 2.0.1 patched under Mandrake 10.1 Official.

All of the dependencies were available on my Mandrake 10.1 Official DVD, and
installed using urpmi, via the 'software management' gui in the Mandrake Control
Centre.  This gui enables you to browse all the software packages available on
the installation CDs/DVD - by category or through searching for keywords in the
package descriptions.  You can also browse available packages on other online
repositories if you choose to set those up - see http://easyurpmi.zarb.org/. 
Urpmi, through the gui, does a reasonable job of finding dependencies of
dependencies, although I admit it is certainly not perfect.

The suggestion has already been made to install Latex related packages.  One way
to do this is to choose Lyx for installation, and all the dependencies should be
taken care of.  At least it works for me.

When I browse my installed software for 'fortran' in package descriptions, I get
the following list of installed packages:

gcc-3.4.1-4mdk
gcc-g77-3.4.1-4mdk
gdb-6.2-2mdk
libf2c0-3.4.1-4mdk
liblapack3-3.0-11mdk

These should all be available from your installation media (assuming a DVD or a
complete set of CDs (4, I think)).

When installing R from source, however, I did have a couple of issues, which
were solved through searching the archives.  But to possibly save you the time:

make sure both 'libreadline' and 'libreadline-devel' are installed (again,
simply search for 'libreadline in the package descriptions) - this is so that
your keyboard arrow keys work to access previous commands.  

make sure both 'xorg-x11-100dpi-' and 'xorg-x11-75dpi-fonts' are installed
(search:"fonts") - this enables all fonts to display properly, eg when using
Rcmdr (which, by the way is a great learning tool).

My belated thanks to those who originally posted these hints.

Hope this helps,

Michael Bibo
Queensland Health
michael_bibo at health.qld.gov.au



From ligges at statistik.uni-dortmund.de  Thu Mar 17 12:49:36 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 17 Mar 2005 12:49:36 +0100
Subject: [R] error in solve_technical question
In-Reply-To: <42395FEC.1030303@bordeaux.inra.fr>
References: <42395FEC.1030303@bordeaux.inra.fr>
Message-ID: <42396ED0.3020104@statistik.uni-dortmund.de>

Jonathan Charrier wrote:
> Hi everybody,
> 
> it's a technical question .
> 
> i have a matrix with 30 columns and 40000 rows,
> i start my program and  i found this error:
> 
> "error in solve.default(sBB + Z[,,i] %*% Gamma %*% t(Z[,,i])):
> system is computationally singular: reciprocal condition number = 
> 7.6377e-018 "
> 
> is it R limit?

Well, if the system is computationally (=almost) singular, so it is very 
dangeraous to do any computations: your solution can be ways off. You 
are protected against interpreting unsensible results.

Uwe Ligges


> 
> thanks a lot.
> 
> Jonathan Charrier
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From johannes at huesing.name  Thu Mar 17 13:20:32 2005
From: johannes at huesing.name (Johannes =?iso-8859-1?Q?H=FCsing?=)
Date: Thu, 17 Mar 2005 13:20:32 +0100 (CET)
Subject: [R] R equivalent to funcall?
Message-ID: <30743.129.206.90.2.1111062032.squirrel@129.206.90.2>

Dear all,
I have a list of time series and want to plot them.
Is there a way that the dot-dot-dot argument of a
function accepts a list as single arguments, such
as funcall in several Lisp dialects?

Greetings


Johannes



From rachelpearce at msn.com  Thu Mar 17 13:41:30 2005
From: rachelpearce at msn.com (Rachel Pearce)
Date: Thu, 17 Mar 2005 12:41:30 -0000
Subject: [R] Legend positioning in scaled survival plot
Message-ID: <BAY4-DAV978220248A3323B59EC4CD4490@phx.gbl>

I am sorry that this is another novice question. I am having trouble
using "legend" with the survival curve plot from the survival package,
and I wonder if it is because I have rescaled my plot. 

Here is the relevant segment of code:

> plot(survfit(Surv(OS,Status)~shortishcr1),main='Overall Survival by
factor',
+ xlab='Years',ylab='% surviving',lty=c(1,2),xscale=365.25,yscale=100)
> legend(5,80,c('Factor=1','Factor=2'),lty=c(1,2)) 

Here the variable OS is in days, but I want to plot it in years, so I
scale it; likewise y is scaled to a percentage.
I am trying to position the legend in the rescaled x and y values.
Legend returns no error, but no legend appears on the plot.

If I exclude the scaling altogether:

> plot(survfit(Surv(OS,Status)~shortishcr1),main='Overall Survival by
factor',
+ xlab='Years',ylab='% surviving',lty=c(1,2),)
> legend(1825,.8,c('Factor=1','Factor=2'),lty=c(1,2))

then the legend appears exactly as expected.

Using the unscaled version of the legend call with the scaled plot,
however, again no legend appears but no error is returned.

I suspect I am making some elementary mistake, but I just can't see it.
It is so elementary that I can't find a similar question in the
archives. Can someone help?

Here is my version information:
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    0.1            
year     2004           
month    11             
day      15             
language R 


Rachel



From ramasamy at cancer.org.uk  Thu Mar 17 14:18:49 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 17 Mar 2005 13:18:49 +0000
Subject: [R] Summing up matrices in a list
In-Reply-To: <1110992868.3946.3.camel@horizons.localdomain>
References: <20050316170027.VSMQ1567.tomts25-srv.bellnexxia.net@JohnDesktop8300>
	<1110992868.3946.3.camel@horizons.localdomain>
Message-ID: <1111065530.5853.14.camel@dhcp-63.ccc.ox.ac.uk>

Yes, I was thinking of the trivial problem of 2 matrices. Nice to know I
am not the only one who made the same error.

Thanks to Thomas Lumley, John Fox, Dimitris Rizopoulos for pointing this
out and many others for providing the correct solution.

Regards, Adai


On Wed, 2005-03-16 at 11:07 -0600, Marc Schwartz wrote:
> John,
> 
> That is correct. I took the example perhaps too literally, depending
> upon what Vicky requires. If indeed the data structure is comprised of
> >2 matrices, the approach using do.call() will not work.
> 
> Thanks for pointing that out.  I see that Adai had a similar idea.
> 
> Best regards,
> 
> Marc
> 
> 
> On Wed, 2005-03-16 at 12:00 -0500, John Fox wrote:
> > Dear Mark,
> > 
> > I believe that your solution won't work if there are more than two matrices
> > to sum.
> > 
> > Regards,
> >  John
> > 
> > --------------------------------
> > John Fox
> > Department of Sociology
> > McMaster University
> > Hamilton, Ontario
> > Canada L8S 4M4
> > 905-525-9140x23604
> > http://socserv.mcmaster.ca/jfox 
> > -------------------------------- 
> > 
> > > -----Original Message-----
> > > From: r-help-bounces at stat.math.ethz.ch 
> > > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Marc Schwartz
> > > Sent: Wednesday, March 16, 2005 11:30 AM
> > > To: Vicky Landsman
> > > Cc: R-Help
> > > Subject: Re: [R] Summing up matrices in a list
> > > 
> > > On Wed, 2005-03-16 at 18:21 +0200, Vicky Landsman wrote:
> > > > Dear all,
> > > > I think that my question is very simple but I failed to solve it. 
> > > > I have a list which elements are matrices like this:
> > > >  
> > > > >mylist
> > > > [[1]]
> > > >      [,1] [,2] [,3]
> > > > [1,]    1    3    5
> > > > [2,]    2    4    6
> > > > 
> > > > [[2]]
> > > >      [,1] [,2] [,3]
> > > > [1,]    7    9   11
> > > > [2,]    8   10   12
> > > > 
> > > > I'd like to create a matrix M<-mylist[[1]]+mylist[[2]]
> > > >      [,1] [,2] [,3]
> > > > [1,]    8   12   16
> > > > [2,]   10   14   18
> > > > 
> > > > Is there a way to create M without looping? 
> > > > Thanks a lot,
> > > 
> > > 
> > > > do.call("+", mylist)
> > >      [,1] [,2] [,3]
> > > [1,]    8   12   16
> > > [2,]   10   14   18
> > > 
> > > See ?do.call for more information.
> > > 
> > > HTH,
> > > 
> > > Marc Schwartz
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> > > http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From murdoch at stats.uwo.ca  Thu Mar 17 14:46:33 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 17 Mar 2005 08:46:33 -0500
Subject: [R] R equivalent to funcall?
In-Reply-To: <30743.129.206.90.2.1111062032.squirrel@129.206.90.2>
References: <30743.129.206.90.2.1111062032.squirrel@129.206.90.2>
Message-ID: <a22j31lp2g8spme5tsdr2mrm2a9h5tvi4e@4ax.com>

On Thu, 17 Mar 2005 13:20:32 +0100 (CET), Johannes H?sing
<johannes at huesing.name> wrote :

>Dear all,
>I have a list of time series and want to plot them.
>Is there a way that the dot-dot-dot argument of a
>function accepts a list as single arguments, such
>as funcall in several Lisp dialects?

do.call() comes close to what you want.  For example,

opts <- list(cex=2, lty=3, type='b')

do.call("plot", c(list(1:10, rnorm(10)), opts))

This messes up some of the tricks plot() uses to set default axis
labels, but otherwise it may be close to what you're after.

Duncan Murdoch



From ligges at statistik.uni-dortmund.de  Thu Mar 17 14:55:44 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 17 Mar 2005 14:55:44 +0100
Subject: [R] Legend positioning in scaled survival plot
In-Reply-To: <BAY4-DAV978220248A3323B59EC4CD4490@phx.gbl>
References: <BAY4-DAV978220248A3323B59EC4CD4490@phx.gbl>
Message-ID: <42398C60.7080703@statistik.uni-dortmund.de>

Rachel Pearce wrote:

> I am sorry that this is another novice question. I am having trouble
> using "legend" with the survival curve plot from the survival package,
> and I wonder if it is because I have rescaled my plot. 
> 
> Here is the relevant segment of code:
> 
> 
>>plot(survfit(Surv(OS,Status)~shortishcr1),main='Overall Survival by
> 
> factor',
> + xlab='Years',ylab='% surviving',lty=c(1,2),xscale=365.25,yscale=100)
> 
>>legend(5,80,c('Factor=1','Factor=2'),lty=c(1,2)) 
> 
> 
> Here the variable OS is in days, but I want to plot it in years, so I
> scale it; likewise y is scaled to a percentage.
> I am trying to position the legend in the rescaled x and y values.
> Legend returns no error, but no legend appears on the plot.


Ask for the real coordinatre system using
   par("usr")
and place the legend somewhere appropriate within these user coordinates.

Uwe Ligges


> If I exclude the scaling altogether:
> 
> 
>>plot(survfit(Surv(OS,Status)~shortishcr1),main='Overall Survival by
> 
> factor',
> + xlab='Years',ylab='% surviving',lty=c(1,2),)
> 
>>legend(1825,.8,c('Factor=1','Factor=2'),lty=c(1,2))
> 
> 
> then the legend appears exactly as expected.
> 
> Using the unscaled version of the legend call with the scaled plot,
> however, again no legend appears but no error is returned.
> 
> I suspect I am making some elementary mistake, but I just can't see it.
> It is so elementary that I can't find a similar question in the
> archives. Can someone help?
> 
> Here is my version information:
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    2              
> minor    0.1            
> year     2004           
> month    11             
> day      15             
> language R 
> 
> 
> Rachel
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From emma.pilgrim at bbsrc.ac.uk  Thu Mar 17 15:03:17 2005
From: emma.pilgrim at bbsrc.ac.uk (emma pilgrim (IGER-NW))
Date: Thu, 17 Mar 2005 14:03:17 -0000
Subject: [R] Repeated Measures, groupedData and lme
Message-ID: <13DEE40AE4BF764586DBF27022F0D6A7A962D6@nwe2knas1.igernet.bbsrc.reserved>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050317/54186bde/attachment.pl

From ramasamy at cancer.org.uk  Thu Mar 17 15:10:00 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 17 Mar 2005 14:10:00 +0000
Subject: [R] how to draw xyplot figure like figure 4.18 of MASS (4th) ?
In-Reply-To: <20050316170107.88075.qmail@web51309.mail.yahoo.com>
References: <20050316170107.88075.qmail@web51309.mail.yahoo.com>
Message-ID: <1111068600.5853.19.camel@dhcp-63.ccc.ox.ac.uk>

I think you have restated your question a couple of days ago here
http://tolstoy.newcastle.edu.au/R/help/05/03/14095.html
I will reply to that thread as it is simpler and easier.

The only new thing this thread adds is "where is the data a5 used to
create Figure 4.18 in MASS (4th Ed)" ?

Regards, Adai



On Wed, 2005-03-16 at 09:01 -0800, Zhongming Yang wrote:
> Dear Francisco and All:
>  
> Following is the source code to create figure 4.18 from MASS (4th).
>  
> library(MASS)
> library(lattice)
> if(F) { # no data supplied
> xyplot(ratio ~ scant | subject, data = A5,
>       xlab = "scan interval (years)",
>       ylab = "ventricle/brain volume normalized to 1 at start",
>       subscripts = T, ID = A5$ID,
>       strip = function(factor, ...)
>          strip.default(..., factor.levels = labs, style = 1),
>       layout = c(8, 5, 1),
>       skip = c(rep(FALSE, 37), rep(TRUE, 1), rep(FALSE, 1)),
>       panel = function(x, y, subscripts, ID) {
>           panel.xyplot(x, y, type = "b", cex = 0.5)
>           which <- unique(ID[subscripts])
>           panel.xyplot(c(0, 1.5), pr3[names(pr3) == which],
>                        type = "l", lty = 3)
>           if(which == 303 || which == 341) points(1.4, 1.3)
>       })
> }
> 
> But there is no data set available for that, I can't figure out many stuff. So I provide my data set, hope you can help me.
>  
> In my data set, there are 3 group patients, and 5 patients in each group. The mds are the repeat measurements on month. I want draw a xyplot with 3 lines, each line for a group. 
>  
> 
> Many thanks
>  
> Zhongming Yang
>  
> 
> 
> 
> "Francisco J. Zagmutt" <gerifalte28 at hotmail.com> wrote:
> Dear Zhongming,
> 
> By asking for the figure in the book you are restricting you question to 
> only the people that has the 4th edition. I would love to help you but 
> unfortunatelly I have the 3rd edition of MASS and there is no figure 4.18 
> since chapter 4 is "Programming in S". Please give us an idea of what you 
> want to do and we might be able to help you without looking at the book.
> 
> Cheers
> 
> Francisco
> 
> >From: Zhongming Yang 
> >To: r-help at stat.math.ethz.ch
> >Subject: [R] how to draw xyplot figure like figure 4.18 of MASS (4th) ? 
> >Date: Wed, 16 Mar 2005 08:07:21 -0800 (PST)
> >
> >Dear All:
> >
> >Could you please tell me how I can draw figure formatted like figure 4.18 
> >of MASS (4th) with the attached data set?
> >
> >Thanks
> >
> >Zhongming Yang
> >
> >
> >
> >---------------------------------
> >
> > md idno month group
> > -0.090 521 0.000000 NN
> > -1.330 521 12.460274 NN
> > -0.570 521 14.991781 NN
> > -2.130 559 0.000000 NN
> > -0.920 559 3.978082 NN
> > -1.730 559 6.016438 NN
> > -2.390 559 9.665753 NN
> > -1.300 559 12.460274 NN
> > -2.170 559 15.682192 NN
> > -2.620 559 17.950685 NN
> > -1.830 559 21.664406 NN
> > -3.090 559 25.533258 NN
> > -2.760 559 30.811947 NN
> > -1.240 559 33.830137 NN
> > -0.650 559 36.394521 NN
> > -1.200 559 38.893151 NN
> > -1.320 559 42.147945 NN
> > -2.000 559 45.600000 NN
> > -2.150 559 48.328767 NN
> > -1.430 559 52.569863 NN
> > -2.650 559 56.120548 NN
> > -0.870 559 60.032877 NN
> > -1.920 559 63.550685 NN
> > -2.320 559 65.786301 NN
> > -2.640 559 68.547945 NN
> > -2.030 559 71.533258 NN
> > -1.900 559 75.500472 NN
> > -1.420 559 78.254570 NN
> > -1.330 559 81.863014 NN
> > -2.120 559 84.657534 NN
> > -2.400 559 86.926027 NN
> > -2.410 559 90.147945 NN
> > -3.370 559 93.369863 NN
> > -0.720 559 96.624658 NN
> > -2.075 598 0.000000 NN
> > -2.260 598 3.484932 NN
> > -2.150 598 5.917808 NN
> > -1.420 598 9.828879 NN
> > -1.490 598 12.353470 NN
> > -3.040 598 16.025601 NN
> > -1.960 598 18.845273 NN
> > -2.780 598 22.224658 NN
> > -3.310 598 24.591781 NN
> > -4.420 598 27.517808 NN
> > -1.890 598 30.312329 NN
> > -3.000 598 33.304110 NN
> > -2.260 598 36.065753 NN
> > -0.730 598 40.010959 NN
> > -2.710 598 43.232877 NN
> > -2.430 598 45.994521 NN
> > -1.050 598 49.183562 NN
> > -2.190 598 52.438356 NN
> > -0.580 598 54.969863 NN
> > -2.050 598 57.501011 NN
> > -1.480 598 60.681338 NN
> > -0.960 598 63.664945 NN
> > -2.090 598 66.419043 NN
> > -3.180 598 69.435616 NN
> > -1.230 598 72.394521 NN
> > -2.170 598 74.761644 NN
> > -2.400 598 78.378082 NN
> > -3.630 598 81.698630 NN
> > -2.100 598 84.920548 NN
> > -3.940 598 87.156164 NN
> > -3.780 598 90.378082 NN
> > -5.690 598 95.967123 NN
> > -13.525 622 0.000000 NN
> > -12.670 622 3.680934 NN
> > -13.500 622 7.123557 NN
> > -13.700 622 9.910442 NN
> > -11.260 622 12.926836 NN
> > -12.100 622 15.846575 NN
> > -13.400 622 18.410959 NN
> > -12.330 622 21.435616 NN
> > -12.940 622 24.197260 NN
> > -12.540 622 27.156164 NN
> > -12.550 622 29.917808 NN
> > -11.900 622 33.830137 NN
> > -11.640 622 36.394521 NN
> > -12.100 622 38.893151 NN
> > -11.010 622 41.457534 NN
> > -12.050 622 46.684932 NN
> > -12.650 622 50.136986 NN
> > -11.620 622 54.303885 NN
> > -12.150 622 58.303885 NN
> > -12.990 622 60.959623 NN
> > -12.590 622 63.912329 NN
> > -13.570 622 66.936986 NN
> > -12.480 622 69.336986 NN
> > -12.800 622 72.263014 NN
> > -12.640 622 75.452055 NN
> > -13.830 622 81.073973 NN
> > -13.250 622 84.295890 NN
> > -13.700 622 90.213699 NN
> > -13.250 622 96.197260 NN
> > -2.190 801 0.000000 NN
> > -1.250 801 2.663014 NN
> > -1.550 801 5.589041 NN
> > -1.570 801 8.575612 NN
> > -0.880 801 11.755940 NN
> > -0.230 801 15.428071 NN
> > -0.770 801 17.985448 NN
> > -1.050 801 20.975342 NN
> > -2.260 801 24.394521 NN
> > -2.760 801 27.715068 NN
> > -1.550 801 29.950685 NN
> > -2.330 801 34.093151 NN
> > -1.390 801 36.394521 NN
> > -2.090 801 39.353425 NN
> > -3.050 801 41.917808 NN
> > -1.930 801 44.646575 NN
> > -4.040 801 48.328767 NN
> > -3.260 801 51.780822 NN
> > -2.810 801 54.115068 NN
> > -0.660 801 57.395284 NN
> > -1.800 801 62.903481 NN
> > -1.540 801 65.755940 NN
> > -0.880 801 69.567123 NN
> > -2.000 801 73.117808 NN
> > -1.610 801 76.142466 NN
> > -4.360 801 79.463014 NN
> > -3.200 801 80.712329 NN
> > -3.080 801 83.013699 NN
> > -2.350 801 88.306849 NN
> > -3.170 801 89.917808 NN
> > -3.570 801 95.342466 NN
> > -3.300 525 0.000000 TP
> > -2.500 525 2.991781 TP
> > -5.480 525 5.917808 TP
> > -1.140 525 8.712329 TP
> > -2.260 525 11.967123 TP
> > -0.670 525 14.926027 TP
> > -0.630 525 17.950685 TP
> > -0.600 525 21.336986 TP
> > -1.870 525 24.427397 TP
> > -1.790 525 26.860274 TP
> > -3.640 525 30.771345 TP
> > -2.860 525 33.328722 TP
> > -2.140 525 37.197575 TP
> > -1.560 525 39.787739 TP
> > -0.360 525 42.542466 TP
> > -1.900 525 45.304110 TP
> > -1.190 525 48.032877 TP
> > -3.090 525 51.024658 TP
> > -2.620 525 53.786301 TP
> > -1.360 525 58.126027 TP
> > -1.130 525 60.953425 TP
> > -1.390 525 64.142466 TP
> > -0.270 525 66.904110 TP
> > -1.640 525 69.665753 TP
> > -1.390 525 72.887671 TP
> > -2.550 525 75.221918 TP
> > -2.540 525 78.180822 TP
> > -1.640 525 81.623804 TP
> > -2.410 525 84.574624 TP
> > -2.530 525 88.017247 TP
> > -1.980 525 91.463014 TP
> > -3.060 525 93.895890 TP
> > -1.920 525 96.131507 TP
> > -1.650 525 99.320548 TP
> > -2.625 527 0.000000 TP
> > -2.370 527 2.991781 TP
> > 0.050 527 6.180822 TP
> > -0.270 527 9.041096 TP
> > 1.060 527 11.736986 TP
> > -3.030 527 15.221918 TP
> > -1.000 527 18.180822 TP
> > -1.270 527 21.895890 TP
> > -1.910 527 24.361644 TP
> > -2.350 527 27.649315 TP
> > -3.720 527 30.142825 TP
> > -3.310 527 33.355940 TP
> > -2.280 527 35.847743 TP
> > -1.860 527 39.290366 TP
> > -5.050 527 42.345205 TP
> > -3.160 527 45.106849 TP
> > -2.270 527 47.802740 TP
> > -1.850 527 50.630137 TP
> > -4.010 527 53.621918 TP
> > -4.520 527 56.383562 TP
> > -3.820 527 60.000000 TP
> > -6.440 527 65.293151 TP
> > -4.600 527 68.350685 TP
> > -5.280 527 71.802740 TP
> > -3.920 527 75.320548 TP
> > -5.080 527 78.175612 TP
> > -8.550 527 80.831350 TP
> > -4.900 527 84.601841 TP
> > -11.620 527 87.585448 TP
> > -6.090 527 91.956164 TP
> > -7.120 527 95.408219 TP
> > -6.365 570 0.000000 TP
> > -6.100 570 2.761644 TP
> > -4.950 570 5.983562 TP
> > -5.530 570 9.205479 TP
> > -3.640 570 11.967123 TP
> > -3.330 570 15.879452 TP
> > -4.950 570 18.310442 TP
> > -5.250 570 21.392410 TP
> > -5.540 570 24.376016 TP
> > -4.300 570 27.359623 TP
> > -4.530 570 29.884932 TP
> > -5.970 570 32.646575 TP
> > -4.950 570 37.019178 TP
> > -5.090 570 39.320548 TP
> > -4.000 570 42.312329 TP
> > -6.160 570 45.073973 TP
> > -6.490 570 49.216438 TP
> > -4.890 570 52.668493 TP
> > -6.620 570 56.350685 TP
> > -7.010 570 61.183562 TP
> > -7.290 570 63.978082 TP
> > -6.440 570 66.736672 TP
> > -7.950 570 69.917000 TP
> > -7.570 570 73.130115 TP
> > -8.150 570 76.113721 TP
> > -8.090 570 78.805479 TP
> > -9.670 570 82.553425 TP
> > -9.480 570 86.169863 TP
> > -9.120 570 90.147945 TP
> > -11.330 570 97.019178 TP
> > -3.750 615 0.000000 TP
> > -3.510 615 3.287671 TP
> > -4.160 615 5.848641 TP
> > -5.170 615 9.651920 TP
> > -4.600 615 12.438805 TP
> > -5.940 615 15.619133 TP
> > -6.270 615 18.608219 TP
> > -4.690 615 21.632877 TP
> > -7.820 615 24.361644 TP
> > -5.940 615 27.189041 TP
> > -5.680 615 30.180822 TP
> > -6.750 615 32.712329 TP
> > -5.130 615 36.854795 TP
> > -6.630 615 39.386301 TP
> > -7.450 615 41.917808 TP
> > -7.290 615 45.369863 TP
> > -9.590 615 48.361644 TP
> > -9.700 615 51.353425 TP
> > -9.570 615 54.799461 TP
> > -9.840 615 57.783068 TP
> > -9.800 615 60.766674 TP
> > -11.000 615 63.291264 TP
> > -11.360 615 66.805479 TP
> > -10.860 615 69.731507 TP
> > -10.610 615 72.493151 TP
> > -12.180 615 78.706849 TP
> > -12.570 615 84.690411 TP
> > -13.280 615 90.213699 TP
> > -15.720 615 96.197260 TP
> > 0.375 818 0.000000 TP
> > 1.640 818 2.491803 TP
> > -5.190 818 5.967213 TP
> > -3.080 818 9.674018 TP
> > -4.020 818 12.402785 TP
> > -6.380 818 15.854839 TP
> > -4.570 818 17.926072 TP
> > -5.380 818 21.608264 TP
> > -7.210 818 25.060319 TP
> > -8.560 818 27.854839 TP
> > -7.300 818 30.156209 TP
> > -7.590 818 33.312374 TP
> > -7.050 818 36.600045 TP
> > -7.350 818 38.046620 TP
> > -9.040 818 41.893196 TP
> > -8.340 818 45.573770 TP
> > -6.890 818 48.131148 TP
> > -7.190 818 54.098361 TP
> > -7.690 818 57.312374 TP
> > -9.340 818 60.468538 TP
> > -9.580 818 62.572648 TP
> > -10.180 818 65.827442 TP
> > -9.000 818 69.443881 TP
> > -10.760 818 71.547990 TP
> > -10.580 818 74.112374 TP
> > -10.500 818 78.221963 TP
> > -10.460 818 83.252100 TP
> > -9.980 818 89.071278 TP
> > -4.540 535 0.000000 SN
> > -6.050 535 3.221918 SN
> > -4.040 535 5.983562 SN
> > -2.940 535 8.843836 SN
> > -4.360 535 12.197260 SN
> > -3.760 535 14.958904 SN
> > -2.780 535 18.641096 SN
> > -6.140 535 21.402740 SN
> > -6.070 535 24.164384 SN
> > -6.530 535 27.450528 SN
> > -7.320 535 31.057085 SN
> > -6.270 535 33.778397 SN
> > -6.480 535 36.991511 SN
> > -7.440 535 39.747945 SN
> > -9.400 535 42.509589 SN
> > -6.640 535 45.534247 SN
> > -6.170 535 48.098630 SN
> > -5.090 535 51.090411 SN
> > -4.660 535 53.786301 SN
> > -5.420 535 58.158904 SN
> > -8.420 535 60.920548 SN
> > -4.830 535 63.682192 SN
> > -5.210 535 66.673973 SN
> > -5.030 535 69.961644 SN
> > -4.720 535 72.460274 SN
> > -5.570 535 75.253806 SN
> > -4.240 535 79.122659 SN
> > -5.620 535 82.302987 SN
> > -5.180 535 85.286593 SN
> > -4.560 535 88.076712 SN
> > -3.730 535 91.265753 SN
> > -4.490 535 95.473973 SN
> > -5.010 535 99.221918 SN
> > -3.645 541 0.000000 SN
> > -2.130 541 3.024658 SN
> > -2.240 541 6.016438 SN
> > -4.490 541 9.073973 SN
> > -3.310 541 12.000000 SN
> > -3.320 541 16.339726 SN
> > -4.130 541 18.246575 SN
> > -3.640 541 21.271233 SN
> > -3.510 541 24.624658 SN
> > -5.260 541 27.612666 SN
> > -3.340 541 30.825780 SN
> > -3.990 541 33.678239 SN
> > -5.390 541 37.022502 SN
> > -9.960 541 39.616438 SN
> > -3.740 541 43.002740 SN
> > -4.550 541 45.600000 SN
> > -3.370 541 48.295890 SN
> > -4.810 541 50.893151 SN
> > -3.130 541 53.654795 SN
> > -3.770 541 57.632877 SN
> > -3.820 541 60.558904 SN
> > -5.160 541 63.090411 SN
> > -3.530 541 66.016438 SN
> > -4.690 567 0.000000 SN
> > -4.030 567 2.991781 SN
> > -2.080 567 6.049315 SN
> > -2.430 567 9.698630 SN
> > -3.500 567 12.723288 SN
> > -2.690 567 15.189041 SN
> > -3.260 567 18.476712 SN
> > -4.890 567 21.460768 SN
> > -3.940 567 24.673883 SN
> > -4.150 567 28.313227 SN
> > -2.570 567 31.068493 SN
> > -3.290 567 33.402740 SN
> > -2.650 567 36.394521 SN
> > -1.220 567 39.353425 SN
> > -2.230 567 45.764384 SN
> > -2.780 567 48.526027 SN
> > -3.230 567 51.780822 SN
> > -3.470 567 54.542466 SN
> > -2.440 567 57.041096 SN
> > -4.170 567 61.249315 SN
> > -3.440 567 63.715068 SN
> > -1.880 567 66.279452 SN
> > -2.150 567 69.231260 SN
> > -2.150 567 72.673883 SN
> > -7.010 567 89.720548 SN
> > -4.640 567 94.520548 SN
> > -5.600 567 96.723288 SN
> > -2.375 572 0.000000 SN
> > -2.920 572 3.452055 SN
> > -1.310 572 6.246575 SN
> > -1.890 572 10.158904 SN
> > -2.450 572 12.558904 SN
> > -2.590 572 15.189041 SN
> > -2.040 572 18.308826 SN
> > -1.570 572 21.685875 SN
> > -1.930 572 24.472760 SN
> > -1.300 572 27.817022 SN
> > -2.820 572 30.641096 SN
> > -1.240 572 33.600000 SN
> > -0.720 572 36.394521 SN
> > -0.440 572 39.156164 SN
> > -0.750 572 41.917808 SN
> > -1.310 572 45.567123 SN
> > -1.060 572 48.756164 SN
> > -0.670 572 51.517808 SN
> > -1.110 572 54.279452 SN
> > -0.870 572 57.501370 SN
> > -2.400 572 60.493151 SN
> > -1.790 572 63.484932 SN
> > -1.150 572 66.308826 SN
> > -0.550 572 68.800629 SN
> > -1.830 572 72.112104 SN
> > -1.830 572 75.030137 SN
> > -1.640 572 78.772603 SN
> > -2.340 572 81.468493 SN
> > -2.490 572 86.136986 SN
> > -1.840 572 90.147945 SN
> > -1.760 572 93.369863 SN
> > -0.970 572 96.657534 SN
> > -0.960 583 0.000000 SN
> > -1.150 583 3.189041 SN
> > -2.060 583 7.364384 SN
> > -1.710 583 9.402740 SN
> > -0.870 583 12.427397 SN
> > -2.100 583 15.185179 SN
> > -1.290 583 18.660588 SN
> > -1.350 583 21.185179 SN
> > -0.410 583 24.824523 SN
> > -2.750 583 27.550685 SN
> > -1.860 583 30.345205 SN
> > -1.750 583 33.336986 SN
> > 0.360 583 36.098630 SN
> > -1.200 583 38.893151 SN
> > -0.900 583 42.575342 SN
> > -1.350 583 45.501370 SN
> > -0.660 583 48.526027 SN
> > -0.950 583 51.254795 SN
> > -1.690 583 54.279452 SN
> > -0.410 583 57.073973 SN
> > -1.090 583 60.295890 SN
> > -0.590 583 63.021244 SN
> > -0.800 583 66.004851 SN
> > -0.700 583 69.250752 SN
> > -0.990 583 72.627801 SN
> > -0.240 583 75.879452 SN
> > -0.180 583 78.673973 SN
> > -1.000 583 81.402740 SN
> > -1.360 583 84.164384 SN
> > -1.240 583 86.958904 SN
> > -1.500 583 90.246575 SN
> > -1.410 583 93.468493 SN
> > -4.260 583 96.230137 SN
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! 
> >http://www.R-project.org/posting-guide.html
> 
> 
> 
> 
> 		
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From johannes at huesing.name  Thu Mar 17 15:11:50 2005
From: johannes at huesing.name (Johannes =?iso-8859-1?Q?H=FCsing?=)
Date: Thu, 17 Mar 2005 15:11:50 +0100 (CET)
Subject: [R] R equivalent to funcall?
In-Reply-To: <a22j31lp2g8spme5tsdr2mrm2a9h5tvi4e@4ax.com>
References: <30743.129.206.90.2.1111062032.squirrel@129.206.90.2>
	<a22j31lp2g8spme5tsdr2mrm2a9h5tvi4e@4ax.com>
Message-ID: <21401.129.206.90.2.1111068710.squirrel@129.206.90.2>


> On Thu, 17 Mar 2005 13:20:32 +0100 (CET), Johannes H?sing
> <johannes at huesing.name> wrote :
[...]
>>Is there a way that the dot-dot-dot argument of a
>>function accepts a list as single arguments, such
>>as funcall in several Lisp dialects?
>
> do.call() comes close to what you want.
[...]

Indeed it does. Thank you very much. I have overlooked
that function.

Greetings


Johannes



From stefaan.lhermitte at biw.kuleuven.be  Thu Mar 17 15:13:25 2005
From: stefaan.lhermitte at biw.kuleuven.be (Stefaan Lhermitte)
Date: Thu, 17 Mar 2005 15:13:25 +0100
Subject: [R] Optimization of constrained linear least-squares problem
Message-ID: <42399085.8070907@biw.kuleuven.be>

Dear R-ians,

I want to perform an linear unmixing of image pixels in fractions of 
pure endmembers. Therefore I need to perform a constrained linear 
least-squares problem that looks like :

min || Cx - d || ? where sum(x) = 1.

I have a 3x3 matrix C, containing the values for endmembers and I have a 
3x1 column vector d (for every pixel in the image). In theory my x 
values should all be in the (0,1) interval but I don't want to force 
them so I can check the validity of my solution. I just want to 
calculate the x values. Can anyone help me with this problem? I've been 
checking the optim, optimize, constrOptim and nlm help files, burt  I 
don't understand it very well. Wich function should I use for my 
problem? I did a first test using optim:

# Make my C matrix
EM<- c(4.5000,6.0000,10.5000,5.0000,27.0000,20.7500,16.7500,23.6666,38.7500)
C <- array(EM, c(3,3))

# Take an arbitrary d
d<-c(10, 20, 20)

# Define the function
 fr <- function(x) {
C[1,]*x=d
C[2,]*x=d
C[3,]*x=d
sum(x)=1}

# Perform the optimization
optim(c(0.25,0.25,0.25),fr)

But it did not work. I got the eror couldn't find function. Can anyone 
tell me what functyion I should use for my problem and how should I 
program it?

Thanx in advance,
Stef



From ramasamy at cancer.org.uk  Thu Mar 17 15:26:34 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 17 Mar 2005 14:26:34 +0000
Subject: [R] question on xyplot
In-Reply-To: <20050315185814.41255.qmail@web51307.mail.yahoo.com>
References: <20050315185814.41255.qmail@web51307.mail.yahoo.com>
Message-ID: <1111069594.5853.34.camel@dhcp-63.ccc.ox.ac.uk>

As promised here is my reply. I am assuming that your problem is
changing the order of the xyplots by idno.


The plotting order in lattice is determined by the levels of md$idno. By
default it was reading the levels from top to bottom of the dataset as
unique(md$idno) would do. 

 library(nlme); library(lattice)
 md <- read.table('sample.txt', header=T)
 md <- groupedData(md ~ month | idno, data=md)

 levels( md$id ) # old levels that were causing the problem 
[1] "TP_603" "TP_549" "TP_642" "NN_533" "NN_619" "NN_833" "SN_683"
 "NN_577" "SN_594" "SN_616" "TP_842" "NN_675" "SN_673" "SN_828" "TP_855"

You see now that the original plotting order was determined by the
above. We can create and set the following new.levels as follows


 ( new.levels <- sort( levels(md$idno) ) )        # create new levels
[1] "NN_533" "NN_577" "NN_619" "NN_675" "NN_833" "SN_594" "SN_616"
"SN_673" "SN_683" "SN_828" "TP_549" "TP_603" "TP_642" "TP_842" "TP_855"

md$idno <- factor( md$idno, levels=new.levels )  # set the new levels


Now you proceed as you have done before.

trellis.device(theme=col.whitebg())
xyplot(md ~ month | idno, data=md, main="title", 
   xlab="x", ylab="y", layout=c(5, 3),
   panel=function(x, y){
   panel.xyplot(x, y)
   panel.lmline(x, y, lty=2)
        }
   )

BTW, I tried to play around with the 'index.cond' and 'perm.cond'
arguments in xyplot with no success. 

Hope this helps.

Regards, Adai



On Tue, 2005-03-15 at 10:58 -0800, Zhongming Yang wrote:
> Dear All:
>  
> In the attached file, I have 3 group patients, and there are 5 in each group (the groups are decided by the prefix of the idno). I want draw a repeat measurement comparison figure. My goal is to list 5 patients from same group on one  horizontal line. But xyplot sounds pick them randomly (or I was confused?). Could you please help me modify the following code to accomplish this?
>  
> Thanks
>  
> Zhongming Yang
>  
> 
> library(nlme)
> library(lattice)
> md <- read.table('../data/sample.txt', header=T)
> md <- groupedData(md ~ month | idno, data=md)
> trellis.device(theme=col.whitebg())
> xyplot(md ~ month | idno, data=md, main="title", 
>    xlab="x", ylab="y", layout=c(5, 3),
>    panel=function(x, y){
>    panel.xyplot(x, y)
>    panel.lmline(x, y, lty=2)
>         }
>    )
>  
> 
> 
> 
> 
> 		
> ---------------------------------
> 
> plain text document attachment (sample.txt), "sample.txt"
>       md   idno     month 
>   -7.705 NN_533  0.000000 
>   -5.880 NN_533  3.254795 
>   -5.850 NN_533  6.049315 
>   -5.700 NN_533  8.876712 
>   -6.470 NN_533 11.967123 
>   -8.240 NN_533 14.958904 
>   -7.180 NN_533 18.673973 
>   -5.200 NN_533 21.501370 
>   -8.180 NN_533 25.380822 
>  -10.130 NN_533 28.303077 
>   -6.750 NN_533 31.057175 
>   -7.190 NN_533 33.647339 
>   -6.410 NN_533 36.630945 
>   -7.640 NN_533 39.616438 
>   -9.820 NN_533 42.772603 
>   -6.260 NN_533 45.534247 
>   -5.580 NN_533 48.131507 
>   -6.350 NN_533 51.747945 
>   -7.380 NN_533 57.534247 
>   -5.780 NN_533 60.723288 
>   -7.130 NN_533 64.931507 
>   -9.440 NN_533 70.389041 
>   -3.885 NN_577  0.000000 
>   -5.990 NN_577  3.221918 
>   -4.610 NN_577  5.983562 
>   -5.680 NN_577  9.205479 
>   -6.410 NN_577 11.736986 
>   -6.050 NN_577 16.338828 
>   -4.990 NN_577 19.092926 
>   -5.760 NN_577 21.617516 
>   -6.050 NN_577 24.601123 
>   -4.900 NN_577 27.584729 
>   -6.690 NN_577 30.575342 
>   -5.460 NN_577 33.567123 
>   -4.840 NN_577 36.558904 
>   -6.280 NN_577 39.550685 
>   -5.090 NN_577 42.542466 
>   -5.700 NN_577 46.684932 
>   -5.280 NN_577 52.208219 
>   -6.330 NN_577 54.739726 
>   -5.650 NN_577 57.271233 
>   -6.130 NN_577 61.347945 
>   -6.130 NN_577 65.027352 
>   -4.930 NN_577 69.945385 
>   -6.650 NN_577 73.355221 
>   -6.680 NN_577 76.339726 
>   -6.130 NN_577 79.561644 
>   -7.090 NN_577 82.093151 
>   -6.680 NN_577 86.268493 
>   -7.210 NN_577 92.876712 
>   -7.290 NN_577 96.723288 
>   -6.530 NN_619  0.000000 
>  -10.090 NN_619  3.452055 
>   -7.220 NN_619  6.274062 
>   -8.220 NN_619  9.815046 
>   -8.820 NN_619 12.634718 
>   -6.210 NN_619 15.552751 
>   -6.750 NN_619 18.772603 
>   -7.020 NN_619 21.304110 
>   -6.700 NN_619 23.901370 
>   -6.170 NN_619 26.663014 
>   -5.890 NN_619 29.884932 
>   -6.110 NN_619 32.876712 
>   -5.530 NN_619 36.493151 
>   -6.510 NN_619 39.254795 
>   -6.630 NN_619 42.082192 
>   -6.760 NN_619 44.843836 
>   -7.620 NN_619 48.000000 
>   -6.490 NN_619 50.991781 
>   -5.340 NN_619 54.437997 
>   -5.530 NN_619 57.880620 
>   -6.710 NN_619 60.470784 
>   -8.130 NN_619 62.995374 
>   -4.830 NN_619 66.838356 
>   -5.610 NN_619 69.600000 
>   -5.720 NN_619 72.131507 
>   -6.440 NN_619 75.419178 
>   -5.870 NN_619 78.378082 
>   -5.130 NN_619 81.830137 
>   -8.990 NN_619 84.821918 
>   -6.260 NN_619 90.345205 
>   -5.320 NN_619 96.789041 
>   -2.085 NN_675  0.000000 
>   -2.610 NN_675  2.761644 
>   -2.710 NN_675  6.904110 
>   -1.560 NN_675  9.205479 
>   -1.590 NN_675 12.197260 
>   -0.950 NN_675 14.958904 
>   -0.660 NN_675 19.791781 
>   -0.630 NN_675 23.967123 
>   -0.380 NN_675 26.695890 
>   -0.930 NN_675 31.528767 
>   -2.570 NN_675 34.323288 
>   -3.030 NN_675 36.621603 
>   -0.750 NN_675 39.801931 
>    0.320 NN_675 43.244554 
>    0.640 NN_675 45.769144 
>    0.420 NN_675 48.986301 
>    0.180 NN_675 51.978082 
>    0.500 NN_675 54.969863 
>    0.700 NN_675 57.961644 
>    0.050 NN_675 60.460274 
>   -0.100 NN_675 63.024658 
>   -0.050 NN_675 69.665753 
>   -0.250 NN_675 72.887671 
>   -1.050 NN_675 80.646575 
>   -2.090 NN_675 86.260948 
>   -5.195 NN_833  0.000000 
>   -4.640 NN_833  3.180328 
>  -10.275 TP_549  0.000000 
>  -15.520 TP_549  3.484932 
>  -15.080 TP_549  6.443836 
>  -19.900 TP_549  9.468493 
>  -19.290 TP_549 14.301370 
>  -20.450 TP_549 19.134247 
>  -19.090 TP_549 22.356164 
>  -20.410 TP_549 24.885426 
>  -19.980 TP_549 28.098540 
>  -20.250 TP_549 33.606737 
>  -18.830 TP_549 36.361644 
>  -19.600 TP_549 39.945205 
>  -19.840 TP_549 43.200000 
>  -20.870 TP_549 46.257534 
>  -20.150 TP_549 49.249315 
>  -21.130 TP_549 52.241096 
>  -20.800 TP_549 54.871233 
>  -23.300 TP_549 57.534247 
>  -21.130 TP_549 60.526027 
>  -22.350 TP_549 64.898630 
>  -21.970 TP_549 69.501370 
>  -21.900 TP_549 72.721491 
>  -22.130 TP_549 76.360835 
>  -22.100 TP_549 79.803458 
>  -24.000 TP_549 83.934606 
>  -22.450 TP_549 88.306849 
>  -25.190 TP_549 97.019178 
>  -23.420 TP_549 99.583562 
>  -13.560 TP_603  0.000000 
>  -15.670 TP_603  3.452055 
>  -13.410 TP_603  6.904110 
>  -15.560 TP_603  9.857804 
>  -12.090 TP_603 13.103705 
>  -14.020 TP_603 15.628296 
>  -15.080 TP_603 18.382394 
>  -16.540 TP_603 21.139726 
>  -13.590 TP_603 24.328767 
>  -16.130 TP_603 28.043836 
>  -14.720 TP_603 31.167123 
>  -12.300 TP_603 33.567123 
>  -15.490 TP_603 36.361644 
>  -16.650 TP_603 40.241096 
>  -17.670 TP_603 43.002740 
>  -15.020 TP_603 46.454795 
>  -14.490 TP_603 49.446575 
>  -18.500 TP_603 54.542466 
>  -13.910 TP_603 56.939771 
>  -18.620 TP_603 61.169279 
>  -18.600 TP_603 64.087312 
>  -20.420 TP_603 67.300427 
>  -18.450 TP_603 70.389041 
>  -19.830 TP_603 72.920548 
>  -19.190 TP_603 78.871233 
>  -18.630 TP_603 84.821918 
>  -10.215 TP_642  0.000000 
>  -12.900 TP_642  2.983607 
>  -12.930 TP_642  5.967213 
>   -7.810 TP_642  9.409836 
>   -7.560 TP_642 11.706265 
>  -12.060 TP_642 15.585717 
>   -9.200 TP_642 19.300786 
>   -9.200 TP_642 22.193937 
>  -11.330 TP_642 24.824074 
>  -14.500 TP_642 28.045991 
>  -11.280 TP_642 30.807635 
>  -13.210 TP_642 34.029553 
>  -11.280 TP_642 37.021334 
>  -15.120 TP_642 39.782978 
>  -13.620 TP_642 43.235033 
>  -13.300 TP_642 45.799416 
>  -15.580 TP_642 48.327869 
>  -11.590 TP_642 50.590164 
>  -14.910 TP_642 54.950820 
>  -12.660 TP_642 57.704918 
>  -16.610 TP_642 60.922704 
>  -16.310 TP_642 63.684348 
>  -16.110 TP_642 66.610375 
>  -20.070 TP_642 69.898046 
>  -13.850 TP_642 72.889827 
>  -18.260 TP_642 75.914485 
>  -16.520 TP_642 79.070649 
>  -15.050 TP_642 85.054211 
>  -14.830 TP_642 92.122704 
>   -3.485 TP_842  0.000000 
>   -3.770 TP_842  3.214821 
>   -2.610 TP_842  5.779205 
>   -3.060 TP_842  9.231260 
>   -2.730 TP_842 11.960027 
>   -2.650 TP_842 15.280575 
>   -1.500 TP_842 17.713452 
>   -3.120 TP_842 20.770986 
>   -3.490 TP_842 24.157287 
>   -3.210 TP_842 27.379205 
>   -3.810 TP_842 30.370986 
>   -3.100 TP_842 32.277835 
>   -4.040 TP_842 35.894274 
>   -3.150 TP_842 40.262295 
>   -3.060 TP_842 42.163934 
>   -5.270 TP_842 44.196721 
>   -4.450 TP_842 48.098361 
>   -2.460 TP_842 51.642219 
>   -2.970 TP_842 53.812082 
>   -3.800 TP_842 55.981945 
>   -3.080 TP_842 59.828520 
>   -2.500 TP_842 63.247698 
>   -3.270 TP_842 67.390164 
>   -2.540 TP_842 70.447698 
>   -4.330 TP_842 72.058657 
>   -4.390 TP_842 75.444958 
>   -3.740 TP_842 79.127150 
>   -4.410 TP_842 81.987424 
>   -5.970 TP_842 85.176465 
>    2.395 TP_855  0.000000 
>    1.990 TP_855  2.728767 
>    1.790 TP_855  5.950685 
>    1.380 TP_855  9.402740 
>    1.230 TP_855 11.901370 
>    1.130 TP_855 15.123288 
>    1.880 TP_855 18.180822 
>    1.350 TP_855 20.679452 
>    0.960 TP_855 23.868493 
>    1.620 TP_855 26.695890 
>    0.780 TP_855 29.720548 
>    1.340 TP_855 32.679452 
>    1.230 TP_855 35.141882 
>    2.970 TP_855 39.076308 
>    0.570 TP_855 41.830406 
>    1.050 TP_855 45.502538 
>    1.110 TP_855 48.263014 
>    0.090 TP_855 50.169863 
>    2.160 TP_855 54.246575 
>    0.030 TP_855 56.745205 
>    1.460 TP_855 60.230137 
>    1.540 TP_855 62.531507 
>    2.180 TP_855 65.983562 
>    1.680 TP_855 68.153425 
>    2.950 TP_855 71.736986 
>    2.230 TP_855 78.871233 
>    0.720 TP_855 84.682865 
>   -3.300 SN_594  0.000000 
>   -3.550 SN_594  3.221918 
>   -5.580 SN_594  5.753425 
>   -4.020 SN_594  9.501370 
>   -2.550 SN_594 12.192230 
>   -3.370 SN_594 15.470918 
>   -5.730 SN_594 18.388951 
>   -1.640 SN_594 21.438132 
>   -5.270 SN_594 24.427397 
>   -1.990 SN_616  0.000000 
>   -2.430 SN_616  4.043836 
>   -2.280 SN_616  6.340175 
>   -3.400 SN_616  9.881159 
>   -2.420 SN_616 13.094274 
>   -3.810 SN_616 15.618864 
>   -2.730 SN_616 18.378082 
>   -1.650 SN_616 21.830137 
>   -4.190 SN_616 25.282192 
>   -2.700 SN_616 28.043836 
>   -2.610 SN_616 31.035616 
>   -2.530 SN_616 33.336986 
>   -2.410 SN_616 37.249315 
>   -3.700 SN_616 40.010959 
>   -3.140 SN_616 42.772603 
>   -3.100 SN_616 45.304110 
>   -2.420 SN_616 49.841096 
>   -1.600 SN_616 53.389355 
>   -2.740 SN_616 56.799192 
>   -2.950 SN_616 60.930339 
>   -4.670 SN_616 64.143454 
>   -2.420 SN_616 66.673973 
>   -2.500 SN_616 69.698630 
>   -4.810 SN_616 73.347945 
>   -4.680 SN_616 75.879452 
>   -3.780 SN_616 79.101370 
>   -2.870 SN_616 82.060274 
>   -2.930 SN_616 86.663014 
>   -7.230 SN_616 89.884932 
>   -3.780 SN_616 97.643836 
>   -0.265 SN_673  0.000000 
>   -0.890 SN_673  3.876937 
>    1.480 SN_673  5.915293 
>    0.800 SN_673  9.202964 
>    1.260 SN_673 11.931731 
>    1.330 SN_673 14.726252 
>    2.010 SN_673 17.027622 
>    1.300 SN_673 21.400225 
>    1.720 SN_673 23.931731 
>    1.760 SN_673 26.660499 
>    1.780 SN_673 29.685156 
>    1.210 SN_673 32.907074 
>    1.150 SN_673 35.898855 
>    1.200 SN_673 39.540984 
>    0.780 SN_673 41.868852 
>    1.240 SN_673 45.475410 
>    2.010 SN_673 48.983786 
>    1.600 SN_673 52.402964 
>    1.880 SN_673 53.750909 
>    1.470 SN_673 57.564608 
>    1.560 SN_673 59.865978 
>    1.400 SN_673 63.482416 
>    1.630 SN_673 65.718033 
>    2.550 SN_673 70.846800 
>    0.950 SN_673 78.671457 
>   -0.360 SN_673 84.194745 
>   -7.610 SN_683  0.000000 
>   -5.940 SN_683  3.419178 
>   -6.270 SN_683  6.641096 
>   -6.230 SN_683 10.093151 
>   -4.210 SN_683 12.854795 
>   -5.360 SN_683 15.649315 
>   -4.300 SN_683 18.871233 
>   -6.240 SN_683 22.290411 
>   -5.010 SN_683 25.084932 
>   -6.400 SN_683 28.306849 
>   -6.670 SN_683 31.068493 
>   -5.870 SN_683 34.060274 
>   -6.510 SN_683 36.586481 
>   -2.975 SN_828  0.000000 
>   -2.990 SN_828  2.983607 
>   -3.990 SN_828  6.885246 
>   -2.620 SN_828  9.184011 
>   -1.380 SN_828 11.945655 
>   -2.230 SN_828 14.510038 
>   -2.080 SN_828 17.699079 
>   -2.410 SN_828 21.611408 
>   -3.290 SN_828 24.175792 
>   -1.980 SN_828 27.134696 
>   -1.970 SN_828 29.929216 
>   -2.450 SN_828 32.263463 
>   -2.390 SN_828 36.603189 
>   -0.950 SN_828 39.134696 
>   -2.490 SN_828 41.896340 
>    2.550 SN_828 44.950820 
>   -3.120 SN_828 48.163934 
>   -0.300 SN_828 52.295082 
>   -2.730 SN_828 54.262295 
>   -3.230 SN_828 57.808668 
>   -1.780 SN_828 60.110038 
>   -2.370 SN_828 63.430586 
>   -3.140 SN_828 65.863463 
>   -2.730 SN_828 69.315518 
>   -1.830 SN_828 71.715518 
>   -2.460 SN_828 75.167572 
>   -2.770 SN_828 77.830586 
>   -2.690 SN_828 84.142915 
>   -2.890 SN_828 90.126477 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Edouard.Henrion at broca.inserm.fr  Thu Mar 17 15:31:59 2005
From: Edouard.Henrion at broca.inserm.fr (Edouard Henrion)
Date: Thu, 17 Mar 2005 15:31:59 +0100
Subject: [R] problem with plot
Message-ID: <9128e5829dd625de8f6c767b9ae9d235@broca.inserm.fr>

Dear list,

I am using R.2.0.1 on a G5 biprocessor 2.5GHz with 2Go RAM (Mac OS X 
10.3.8).

I have some problems to use the plot function... it makes my R 
application crash  !

Have someone any idea about this problem ???

Thanks,

Edouard



From MSchwartz at MedAnalytics.com  Thu Mar 17 15:39:00 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu, 17 Mar 2005 08:39:00 -0600
Subject: [R] Adobe Reader V7.0 for Unix/Linux Available
In-Reply-To: <1111023327.18956.10.camel@horizons.localdomain>
References: <1110931330.18575.17.camel@horizons.localdomain>
	<Pine.LNX.4.62.0503160838360.28419@sasquatch>
	<1110991445.1090.5.camel@horizons.localdomain>
	<Pine.LNX.4.62.0503161326470.13587@sasquatch>
	<1111023327.18956.10.camel@horizons.localdomain>
Message-ID: <1111070340.18956.31.camel@horizons.localdomain>

All,

A couple of updates here:

1. According to a post on the Fedora lists this morning and an article
at:

http://www.heise.de/newsticker/meldung/57616

the version 7.0 Adobe Reader that I referenced in my original post is
still a _Pre-Release_ version, NOT the final version.

If accurate, it would seem that there was some special arrangement made
for a particular Adobe customer and the link for the RPM and binary
installer managed to become public. This would help to explain why there
was no information on the Adobe site about this (notwithstanding the
various other online articles characterizing this as a release version).


2. In checking the Adobe site this morning, the Pre-Release Linux
version 7.0 is indeed now listed in the pull-down menu on the Reader
download page. Both the RPM and the binary installer are listed as
options.

So it would seem that perhaps Adobe has reacted to the inevitability of
the publicity of this version and now made it generally available.


So far, I have been using this version without problems. However, since
it is a Pre-Release version, there may be as yet other unidentified
issues.

My apologies for any inconvenience this may have caused anyone.

Marc Schwartz



From dimitris.rizopoulos at med.kuleuven.ac.be  Thu Mar 17 15:50:03 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Thu, 17 Mar 2005 15:50:03 +0100
Subject: [R] Optimization of constrained linear least-squares problem
References: <42399085.8070907@biw.kuleuven.be>
Message-ID: <009201c52b00$9a400b50$0540210a@www.domain>

you could re-parameterize, e.g.,

EM <- 
c(4.5000,6.0000,10.5000,5.0000,27.0000,20.7500,16.7500,23.6666,38.7500)
W <- array(EM, c(3,3))
d <- c(10, 20, 20)
##############33
fn <- function(x){
    x <- exp(x) / sum(exp(x))
    r <- W%*%x - d
    crossprod(r, r)[1,1]
}
opt <- optim(rnorm(3), fn)
res <- exp(opt$par) / sum(exp(opt$par))
res


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Stefaan Lhermitte" <stefaan.lhermitte at biw.kuleuven.be>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, March 17, 2005 3:13 PM
Subject: [R] Optimization of constrained linear least-squares problem


> Dear R-ians,
>
> I want to perform an linear unmixing of image pixels in fractions of 
> pure endmembers. Therefore I need to perform a constrained linear 
> least-squares problem that looks like :
>
> min || Cx - d || ? where sum(x) = 1.
>
> I have a 3x3 matrix C, containing the values for endmembers and I 
> have a 3x1 column vector d (for every pixel in the image). In theory 
> my x values should all be in the (0,1) interval but I don't want to 
> force them so I can check the validity of my solution. I just want 
> to calculate the x values. Can anyone help me with this problem? 
> I've been checking the optim, optimize, constrOptim and nlm help 
> files, burt  I don't understand it very well. Wich function should I 
> use for my problem? I did a first test using optim:
>
> # Make my C matrix
> EM<- 
> c(4.5000,6.0000,10.5000,5.0000,27.0000,20.7500,16.7500,23.6666,38.7500)
> C <- array(EM, c(3,3))
>
> # Take an arbitrary d
> d<-c(10, 20, 20)
>
> # Define the function
> fr <- function(x) {
> C[1,]*x=d
> C[2,]*x=d
> C[3,]*x=d
> sum(x)=1}
>
> # Perform the optimization
> optim(c(0.25,0.25,0.25),fr)
>
> But it did not work. I got the eror couldn't find function. Can 
> anyone tell me what functyion I should use for my problem and how 
> should I program it?
>
> Thanx in advance,
> Stef
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From zhongmingyang at yahoo.com  Thu Mar 17 16:29:21 2005
From: zhongmingyang at yahoo.com (Zhongming Yang)
Date: Thu, 17 Mar 2005 07:29:21 -0800 (PST)
Subject: [R] how to close trellis.device?
Message-ID: <20050317152921.66484.qmail@web51303.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050317/6431badc/attachment.pl

From ligges at statistik.uni-dortmund.de  Thu Mar 17 16:45:30 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 17 Mar 2005 16:45:30 +0100
Subject: [R] how to close trellis.device?
In-Reply-To: <20050317152921.66484.qmail@web51303.mail.yahoo.com>
References: <20050317152921.66484.qmail@web51303.mail.yahoo.com>
Message-ID: <4239A61A.200@statistik.uni-dortmund.de>

Zhongming Yang wrote:

> Dear All:
>  
> I need draw some figure through trellis.device and save them as pdf files. How can I close trellis.device (something like dev.off() in nonlattice figure)? 

dev.off() is correct, because trellis.device also starts "regular" 
devices (with appropriate sttings).

Uwe Ligges


>  
> Many thanks
>  
> Zhongming Yang
> 
> 		
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ramasamy at cancer.org.uk  Thu Mar 17 16:51:31 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 17 Mar 2005 15:51:31 +0000
Subject: [R] problem with plot
In-Reply-To: <9128e5829dd625de8f6c767b9ae9d235@broca.inserm.fr>
References: <9128e5829dd625de8f6c767b9ae9d235@broca.inserm.fr>
Message-ID: <1111074691.9889.35.camel@dhcp-63.ccc.ox.ac.uk>

We need more info to help you. What do you mean by "crash", does it
generate an error or something ?

I presume you have just installed R. How did you install it ? If you did
from source, did you do a "make check" ? I had this problem once and it
was traced to a broken gcc version
http://tolstoy.newcastle.edu.au/R/help/04/03/0896.html

There is also a R for Mac OS X webpage 
http://cran.r-project.org/bin/macosx/
and a special interest group with a mailing list.

Regards, Adai


On Thu, 2005-03-17 at 15:31 +0100, Edouard Henrion wrote:
> Dear list,
> 
> I am using R.2.0.1 on a G5 biprocessor 2.5GHz with 2Go RAM (Mac OS X 
> 10.3.8).
> 
> I have some problems to use the plot function... it makes my R 
> application crash  !
> 
> Have someone any idea about this problem ???
> 
> Thanks,
> 
> Edouard
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From muster at gmail.com  Thu Mar 17 18:24:07 2005
From: muster at gmail.com (Terry Mu)
Date: Thu, 17 Mar 2005 12:24:07 -0500
Subject: [R] beginner question: how to sort out distinct values from a vector
Message-ID: <b68812e70503170924704729db@mail.gmail.com>

 there is a vector, like:
1, 1, 1, 2, 2, 3, 3, 4, 5, 5, 

I'd like a function that gives me only 1, 2, 3, 4, 5

thank you



From ccleland at optonline.net  Thu Mar 17 18:26:38 2005
From: ccleland at optonline.net (Chuck Cleland)
Date: Thu, 17 Mar 2005 12:26:38 -0500
Subject: [R] beginner question: how to sort out distinct values from a
	vector
In-Reply-To: <b68812e70503170924704729db@mail.gmail.com>
References: <b68812e70503170924704729db@mail.gmail.com>
Message-ID: <4239BDCE.4090300@optonline.net>

?unique

Terry Mu wrote:
>  there is a vector, like:
> 1, 1, 1, 2, 2, 3, 3, 4, 5, 5, 
> 
> I'd like a function that gives me only 1, 2, 3, 4, 5
> 
> thank you
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From MSchwartz at MedAnalytics.com  Thu Mar 17 18:30:10 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu, 17 Mar 2005 11:30:10 -0600
Subject: [R] beginner question: how to sort out distinct values from a
	vector
In-Reply-To: <b68812e70503170924704729db@mail.gmail.com>
References: <b68812e70503170924704729db@mail.gmail.com>
Message-ID: <1111080610.10293.10.camel@horizons.localdomain>

On Thu, 2005-03-17 at 12:24 -0500, Terry Mu wrote:
>  there is a vector, like:
> 1, 1, 1, 2, 2, 3, 3, 4, 5, 5, 
> 
> I'd like a function that gives me only 1, 2, 3, 4, 5

See ?unique

HTH,

Marc SChwartz



From muster at gmail.com  Thu Mar 17 18:30:48 2005
From: muster at gmail.com (Terry Mu)
Date: Thu, 17 Mar 2005 12:30:48 -0500
Subject: [R] beginner question: how to sort out distinct values from a
	vector
In-Reply-To: <1111080610.10293.10.camel@horizons.localdomain>
References: <b68812e70503170924704729db@mail.gmail.com>
	<1111080610.10293.10.camel@horizons.localdomain>
Message-ID: <b68812e7050317093016050711@mail.gmail.com>

thank you so much! all of you!


On Thu, 17 Mar 2005 11:30:10 -0600, Marc Schwartz
<MSchwartz at medanalytics.com> wrote:
> On Thu, 2005-03-17 at 12:24 -0500, Terry Mu wrote:
> >  there is a vector, like:
> > 1, 1, 1, 2, 2, 3, 3, 4, 5, 5,
> >
> > I'd like a function that gives me only 1, 2, 3, 4, 5
> 
> See ?unique
> 
> HTH,
> 
> Marc SChwartz
> 
>



From HDoran at air.org  Thu Mar 17 18:35:00 2005
From: HDoran at air.org (Doran, Harold)
Date: Thu, 17 Mar 2005 12:35:00 -0500
Subject: [R] beginner question: how to sort out distinct values from a
	vector
Message-ID: <88EAF3512A55DF46B06B1954AEF73F7408316A71@dc1ex2.air.org>

You can use unique()

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Terry Mu
Sent: Thursday, March 17, 2005 12:24 PM
To: R-Help
Subject: [R] beginner question: how to sort out distinct values from a
vector

 there is a vector, like:
1, 1, 1, 2, 2, 3, 3, 4, 5, 5, 

I'd like a function that gives me only 1, 2, 3, 4, 5

thank you

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Thu Mar 17 18:36:42 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 17 Mar 2005 18:36:42 +0100
Subject: [R] beginner question: how to sort out distinct values from a
	vector
In-Reply-To: <b68812e70503170924704729db@mail.gmail.com>
References: <b68812e70503170924704729db@mail.gmail.com>
Message-ID: <4239C02A.6030003@statistik.uni-dortmund.de>

Terry Mu wrote:
>  there is a vector, like:
> 1, 1, 1, 2, 2, 3, 3, 4, 5, 5, 
> 
> I'd like a function that gives me only 1, 2, 3, 4, 5


See ?unique

Uwe Ligges


> thank you
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ales.ziberna at guest.arnes.si  Thu Mar 17 18:39:05 2005
From: ales.ziberna at guest.arnes.si (=?iso-8859-2?Q?Ale=B9_=AEiberna?=)
Date: Thu, 17 Mar 2005 18:39:05 +0100
Subject: [R] Function match.call or saving all initial parameters
Message-ID: <023401c52b1b$b3f1d950$1209f9c2@ales>

Hello!

I am interested, is it possible to get a call from the function (like with
match.call), but in such a way that the call would include all elements to a
function, not only those that were set in a call. What I want is to have
also specified arguments that are not listed in the original call and
for which the default values are used. I would like to know all arguments 
used so I could replicate the call. An example follows at the end.

I have searched the help files and the mailing list archives, but have not
found a solution.

Thank you in advance for any advice!

Ales Ziberna



For example,
if I have a function:

my.fun<-function(x,n=1,...){
    call<-match.call()
    res<-list(rep(x = x, times = n),...)
return(list(res=res,call=call))
}
#If I call this function
a<-2
b<-3
res<-my.fun(a,b=b)
#the call element of the result is
res$call #here I only exact the call and get
#my.fun(x = a, b = b)

However, I would like to get
my.fun(x = 2, n = 1, b = 3)

I tried usning substituting
call<-match.call()
with
inital.param<-lapply(as.list(sys.frame(sys.nframe())),eval) #to get initial 
parametrs, whih is esentially what I want
However, this does not give me the arguments in ..., in the example argument 
b.



From ursula.garczarek at roche.com  Thu Mar 17 19:20:50 2005
From: ursula.garczarek at roche.com (Garczarek, Ursula)
Date: Thu, 17 Mar 2005 19:20:50 +0100
Subject: [R] Links between R and Matlab
Message-ID: <A2014C972BC979448DDA4A310707303E042969@rpzmsem1.emea.roche.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050317/9dfa4344/attachment.pl

From rn001 at cebas.csic.es  Thu Mar 17 19:27:08 2005
From: rn001 at cebas.csic.es (javier garcia)
Date: Thu, 17 Mar 2005 19:27:08 +0100
Subject: [R] png device & videos 
Message-ID: <200503171927.08243.rn001@cebas.csic.es>

Hi all;

please, has anyone found a way to convert a series of png files created in an 
R script into a video (as avi), from within the same R script?

I know this has little relation with typical R problems. Just because I've 
spent all day without finding a solution, and perhaps anyone has done it 
before here.

Thanks and best regards,

Javier

-- 
A. Javier Garcia
Water and Soil conservation department
CEBAS-CSIC
Campus Universitario Espinardo
PO BOX 164
30100 Murcia (SPAIN)
Phone: +34 968 39 62 57
Fax: +34 968 39 62 13
email: rn001 at cebas.csic.es



From jerk_alert at hotmail.com  Thu Mar 17 19:30:15 2005
From: jerk_alert at hotmail.com (Ken Termiso)
Date: Thu, 17 Mar 2005 18:30:15 +0000
Subject: [R] Binding one column of characters into a dataframe factors other
	numeric columns
Message-ID: <BAY101-F11D27797358EF8D3D3167BE8490@phx.gbl>

Hi all,

I searched through the archives, but couldn't find a fix...

Basically, I've got a bunch of numeric vectors and one character vector that 
I want to bind into a data frame. When I include the character vector as a 
column in the data frame, all the numeric columns get factored in the data 
frame, which makes it tough to call those columns for calculations later on. 
I've tried using AsIs to prevent this, but without luck...in the examples 
below, the object named "c" is the one that is the character column. The 
others are numeric.

df_without_char <- data.frame(cbind(rl, gl, cp), row.names = rownames(r)) 
#without char vector

df_without_char <- data.frame(cbind(rl, gl, c, cp), row.names = 
rownames(r))#with char vector

df <- data.frame(cbind(rl, gl, I(c), cp), row.names = rownames(r)) #try to 
keep char vector AsIs

df <- data.frame(cbind(rl, gl, c=I(c), cp), row.names = rownames(r)) #try to 
keep char vector AsIs

df <- data.frame(cbind(rl, gl, c, I(cp)), row.names = rownames(r)) #try to 
keep num vector AsIs

df <- data.frame(cbind(rl, gl,  c, cp=I(cp)), row.names = rownames(r)) #try 
to keep num vector AsIs


Thanks in advance,
Ken



From MSchwartz at MedAnalytics.com  Thu Mar 17 20:00:03 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu, 17 Mar 2005 13:00:03 -0600
Subject: [R] Binding one column of characters into a dataframe factors
	other numeric columns
In-Reply-To: <BAY101-F11D27797358EF8D3D3167BE8490@phx.gbl>
References: <BAY101-F11D27797358EF8D3D3167BE8490@phx.gbl>
Message-ID: <1111086003.10293.52.camel@horizons.localdomain>

On Thu, 2005-03-17 at 18:30 +0000, Ken Termiso wrote:
> Hi all,
> 
> I searched through the archives, but couldn't find a fix...
> 
> Basically, I've got a bunch of numeric vectors and one character vector that 
> I want to bind into a data frame. When I include the character vector as a 
> column in the data frame, all the numeric columns get factored in the data 
> frame, which makes it tough to call those columns for calculations later on. 
> I've tried using AsIs to prevent this, but without luck...in the examples 
> below, the object named "c" is the one that is the character column. The 
> others are numeric.
> 
> df_without_char <- data.frame(cbind(rl, gl, cp), row.names = rownames(r)) 
> #without char vector
> 
> df_without_char <- data.frame(cbind(rl, gl, c, cp), row.names = 
> rownames(r))#with char vector
> 
> df <- data.frame(cbind(rl, gl, I(c), cp), row.names = rownames(r)) #try to 
> keep char vector AsIs
> 
> df <- data.frame(cbind(rl, gl, c=I(c), cp), row.names = rownames(r)) #try to 
> keep char vector AsIs
> 
> df <- data.frame(cbind(rl, gl, c, I(cp)), row.names = rownames(r)) #try to 
> keep num vector AsIs
> 
> df <- data.frame(cbind(rl, gl,  c, cp=I(cp)), row.names = rownames(r)) #try 
> to keep num vector AsIs


Don't use cbind() on all vectors, which will initially create a matrix
using a single data type.

Just list each vector separately. Try this:

rl <- 1:5
gl <- 6:10
cp <- 11:15
c <- letters[1:5]

df <- data.frame(rl, gl, cp, c)

> df
  rl gl cp c
1  1  6 11 a
2  2  7 12 b
3  3  8 13 c
4  4  9 14 d
5  5 10 15 e

> str(df)
`data.frame':	5 obs. of  4 variables:
 $ rl: int  1 2 3 4 5
 $ gl: int  6 7 8 9 10
 $ cp: int  11 12 13 14 15
 $ c : Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5


If you do not want 'c' to become a factor, you can use I() like this:

df <- data.frame(rl, gl, cp, I(c))

> str(df)
`data.frame':	5 obs. of  4 variables:
 $ rl: int  1 2 3 4 5
 $ gl: int  6 7 8 9 10
 $ cp: int  11 12 13 14 15
 $ c :Class 'AsIs'  chr [1:5] "a" "b" "c" "d" ...


You can of course still use the "row.names" argument as you are to set
the rownames in the data frame.


HTH,

Marc Schwartz



From MSchwartz at MedAnalytics.com  Thu Mar 17 20:21:13 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu, 17 Mar 2005 13:21:13 -0600
Subject: [R] png device & videos
In-Reply-To: <200503171927.08243.rn001@cebas.csic.es>
References: <200503171927.08243.rn001@cebas.csic.es>
Message-ID: <1111087273.10293.66.camel@horizons.localdomain>

On Thu, 2005-03-17 at 19:27 +0100, javier garcia wrote:
> Hi all;
> 
> please, has anyone found a way to convert a series of png files created in an 
> R script into a video (as avi), from within the same R script?
> 
> I know this has little relation with typical R problems. Just because I've 
> spent all day without finding a solution, and perhaps anyone has done it 
> before here.
> 
> Thanks and best regards,
> 
> Javier


I have not done it personally, but there are several Linux based apps
that can take PNG/JPGs and convert them to MPG/AVI. This is not within
R, but external to it.

Your e-mail header suggests that you are using KDE, so you might want to
look at:

http://kjpeg2avi.sourceforge.net/


I believe that the mencoder application can also do this. It is
available via the MPlayer site. More information is available here:

http://www.mplayerhq.hu/DOCS/HTML/en/menc-feat-enc-images.html


You might want to do a Google search to find additional options.

HTH,

Marc Schwartz



From sghosh at lexgen.com  Thu Mar 17 20:25:19 2005
From: sghosh at lexgen.com (Ghosh, Sandeep)
Date: Thu, 17 Mar 2005 13:25:19 -0600
Subject: [R] Line plot using xyplot function in lattice package
Message-ID: <2B47B68F97330841AC8C670749084A7D06C433@wdexchmb01.lexicon.lexgen.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050317/ec44c4ab/attachment.pl

From kkthird at yahoo.com  Thu Mar 17 20:41:58 2005
From: kkthird at yahoo.com (KKThird@Yahoo.Com)
Date: Thu, 17 Mar 2005 11:41:58 -0800 (PST)
Subject: [R] Ideal Computer and Software (A bit off topic)
Message-ID: <20050317194158.74238.qmail@web52503.mail.yahoo.com>

Hello everyone.

This question might be a bit off topic, but I thought
that (a) there couldn't be a better group to address
my questions and (b) that others might find it useful
too; It also might start an interesting discussion
thread.  

I use R often for simulation purposes (which generally
involve a lot of for() loops) and for most of my
general work. I will be purchasing a new computing
system soon, and I'm wondering the best way to go. I'm
a Windows user now, and from what I know and have read
about Linux, it is what I should be using (or possibly
a Unix machine). I'm not wedded to a Windows system
and I'm willing to put in the time to learn Linux if
it would truly be beneficial. Is it the case that
Linux offers so much more than Windows that it is
definitely worth the switch?

For the hardware issue, is it generally better to run
R on a server and then connect to the server or on a
stand alone computer (Obviously the performance would
be related to the specific hardware, but if the
hardware was essentially equal, would there be any
advantage to either?). 

What seems to be better for using R on, an Intel, AMD,
Unix, or Mac (which I suppose is now a Unix)
processor? In terms of speed, again given the
analogous hardware, is there an advantage to one of
these? 

Does it make sense to get a 64 bit AMD processor, or
is that just an overkill? Would R even make use of the
64 bit processing power?

I'm very interested on any thoughts people have on
this. I'm a big user of computers, but I'm not overly
knowledgeable about their inner workings. 

Thanks and have a nice day,
Ken



From zhongmingyang at yahoo.com  Thu Mar 17 20:59:47 2005
From: zhongmingyang at yahoo.com (Zhongming Yang)
Date: Thu, 17 Mar 2005 11:59:47 -0800 (PST)
Subject: [R] how to close trellis.device?
In-Reply-To: 6667
Message-ID: <20050317195948.45113.qmail@web51307.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050317/8169839e/attachment.pl

From zhongmingyang at yahoo.com  Thu Mar 17 21:08:43 2005
From: zhongmingyang at yahoo.com (Zhongming Yang)
Date: Thu, 17 Mar 2005 12:08:43 -0800 (PST)
Subject: [R] how to close trellis.device?
In-Reply-To: 6667
Message-ID: <20050317200843.15337.qmail@web51301.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050317/7b5b10ed/attachment.pl

From sundar.dorai-raj at pdf.com  Thu Mar 17 21:27:02 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 17 Mar 2005 14:27:02 -0600
Subject: [R] Line plot using xyplot function in lattice package
In-Reply-To: <2B47B68F97330841AC8C670749084A7D06C433@wdexchmb01.lexicon.lexgen.com>
References: <2B47B68F97330841AC8C670749084A7D06C433@wdexchmb01.lexicon.lexgen.com>
Message-ID: <4239E816.5040205@pdf.com>



Ghosh, Sandeep wrote on 3/17/2005 1:25 PM:
> Hi All,
> 
> For the following data when I use xyplot in package lattice the intervals are in the order of 2, 24, 8, but instead I want them to be in the order 2, 8, 24.
> 
>   Treatment Interval  value
>   A          2  		0.448
>   A	       24		1.85
>   A          8  		1.166
>   B          2  		1.074
>   B	       24		1.5
>   B          8  		1.065
>   C  	       2  		0.854
>   C          8  		0.589
> 
> The R script is xyplot(value ~ Interval, data=studyData, type='b', groups = Treatment,
> 
> Is there a way in xyplot to specify the order?. 
> 
> -Sandeep


Hi Sandeep,

You can make Interval an ordered variable:

studyData$Interval <- ordered(studyData$Interval, c("2", "24", "8"))
xyplot(value ~ Interval, data=studyData, type='b', groups = Treatment)

--sundar



From sundar.dorai-raj at pdf.com  Thu Mar 17 21:35:08 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 17 Mar 2005 14:35:08 -0600
Subject: [R] Line plot using xyplot function in lattice package
In-Reply-To: <4239E816.5040205@pdf.com>
References: <2B47B68F97330841AC8C670749084A7D06C433@wdexchmb01.lexicon.lexgen.com>
	<4239E816.5040205@pdf.com>
Message-ID: <4239E9FC.4060603@pdf.com>



Sundar Dorai-Raj wrote on 3/17/2005 2:27 PM:
> 
> 
> Ghosh, Sandeep wrote on 3/17/2005 1:25 PM:
> 
>> Hi All,
>>
>> For the following data when I use xyplot in package lattice the 
>> intervals are in the order of 2, 24, 8, but instead I want them to be 
>> in the order 2, 8, 24.
>>
>>   Treatment Interval  value
>>   A          2          0.448
>>   A           24        1.85
>>   A          8          1.166
>>   B          2          1.074
>>   B           24        1.5
>>   B          8          1.065
>>   C             2          0.854
>>   C          8          0.589
>>
>> The R script is xyplot(value ~ Interval, data=studyData, type='b', 
>> groups = Treatment,
>>
>> Is there a way in xyplot to specify the order?.
>> -Sandeep
> 
> 
> 
> Hi Sandeep,
> 
> You can make Interval an ordered variable:
> 
> studyData$Interval <- ordered(studyData$Interval, c("2", "24", "8"))
> xyplot(value ~ Interval, data=studyData, type='b', groups = Treatment)
> 
> --sundar
> 

Sorry I misread your original message. You just need to re-order the 
data, as in:

studyData <- studyData[do.call("order", studyData), ]
xyplot(value ~ Interval, data=studyData, type='b', groups = Treatment)

HTH,

--sundar



From constant.depiereux at aqte.be  Thu Mar 17 21:56:44 2005
From: constant.depiereux at aqte.be (Depiereux Constant)
Date: Thu, 17 Mar 2005 21:56:44 +0100
Subject: [R] RODBC and portability issue
Message-ID: <7eda8a28a181ac3b2b18a9f237949fdb@aqte.be>


Hello,

New user of R I did experience some trouble using R and ODBC on Windows 
XP, MS Access and PostgreSQL.

While querying a database is relatively simple, the use of sqlSave is a 
bit more tricky.

After a large series of trial, I finally succeeded to get it work 
provided :

1. I leave the application create the table by itself. Once created, 
reusing it is simple and reliable, although you should not try to adapt 
the layout of the table to fix you exact needs. In this case, nothing 
works anymore in about 80% of the cases.

2. I manage to create the database using a record whici contains the 
largest possible data item for a given variable, otherwise there is a 
risk to be limited to a fields that appears to be to narrow to receive 
largest occurrence of the data/field.

Then the real problem really start : to perform the analysis on time, I 
have to run it in parallel on several machines, ideally without 
creating several time the similar table under a different name.

So the question is simple : which 'invisible' information is created 
either by R, ODBC or the database that should be replicated to avoid 
this silly scenario of multiple occurrence of the table.

Help me please.


PS :I think that I read carefully the documentation before asking this 
question, so please avoid refering back to it, unless with a precise 
item to be re-read.





`

Constant Depi?reux
Managing Director
Applied Quality Technologies Europe sprl
Rue des D?port?s 123, B4800   Verviers
Tel : + 32 87 29 21 75
Fax : +32 87 29 21 71
Mobile : +32 475 555 818
e-Mail : constant.depiereux at aqte.be
Web presence : http://www.aqte.be
Skype : cdepiereux



From paul.h.artes at gmail.com  Thu Mar 17 22:02:58 2005
From: paul.h.artes at gmail.com (Paul H Artes)
Date: Thu, 17 Mar 2005 17:02:58 -0400
Subject: [R] exact p-value for Spearman, with ties
Message-ID: <3a0cc956050317130269082014@mail.gmail.com>

Dear R,

I'm looking for exact p-values for Spearman's rank correlation in the
presence of ties. This is available in StatXact and SPSS, but I
haven't yet found it in R. Has anyone implemented this?

-- 
Paul H Artes
Assist Prof, Ophth Vis Sci
Dalhousie University, QEII Eye Care Centre
Halifax, NS, CANADA



From fredrik.bg.lundgren at bredband.net  Thu Mar 17 22:07:35 2005
From: fredrik.bg.lundgren at bredband.net (Fredrik Lundgren)
Date: Thu, 17 Mar 2005 22:07:35 +0100
Subject: [R] "RMySQL for R 2.0.1"
Message-ID: <000f01c52b35$57f237c0$109d72d5@Larissa>

Dear List,

RMySQL is old and wouldn't install on R 2.0.1.
How should the source be rewritten to be accepted by R 2.0.1.

With thanks

Fredrik Lundgren



From pbruce at statistics.com  Thu Mar 17 22:35:22 2005
From: pbruce at statistics.com (Peter C. Bruce)
Date: Thu, 17 Mar 2005 16:35:22 -0500
Subject: [R] short course - modeling in R
Message-ID: <6.1.0.6.2.20050317162545.04d160f0@mail.statistics.com>

Dr. Phillip Good will offer his short course "Modeling in R" April 8 - 
April 29, 2005, online at statistics.com.  This 3-week course will show you 
how to use R to create models for use in classification and prediction. You 
will be introduced to advanced graphing methods as needed. Modeling 
techniques include OLS, LAD, and EIV regression, quantile regression, and 
decision trees.

Dr. Phillip Good is the author of Introduction to Statistics via Resampling 
Methods and R (Wiley, 2005), and numerous other books.   Participants will 
interact with Prof. Good via a private discussion board; the course will 
require about 10 hours per week and there are no set hours when you must be 
online.

Registration and details:
http://www.statistics.com/content/courses/r.html

Peter Bruce
pbruce at statistics.com



From dj at research.bell-labs.com  Thu Mar 17 22:52:20 2005
From: dj at research.bell-labs.com (David James)
Date: Thu, 17 Mar 2005 16:52:20 -0500
Subject: [R] "RMySQL for R 2.0.1"
In-Reply-To: <000f01c52b35$57f237c0$109d72d5@Larissa>;
	from fredrik.bg.lundgren@bredband.net on Thu, Mar 17, 2005 at
	10:07:35PM +0100
References: <000f01c52b35$57f237c0$109d72d5@Larissa>
Message-ID: <20050317165220.A3920@jessie.research.bell-labs.com>

Fredrik Lundgren wrote:
> Dear List,
> 
> RMySQL is old and wouldn't install on R 2.0.1.
> How should the source be rewritten to be accepted by R 2.0.1.
> 
> With thanks
> 
> Fredrik Lundgren
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Hi,

Hmm, I have had no problems installing it and using it under R 2.0.1 
on various systems, e.g., 

  > packageDescription("RMySQL")
  Package: RMySQL
  Version: 0.5-5
  Date: 2004-06-21
  Title: R interface to the MySQL database
  Author: David A. James <dj at bell-labs.com> Saikat DebRoy
          <saikat at stat.wisc.edu>
  Maintainer: David A. James <dj at bell-labs.com>
  Description: Database interface and MySQL driver for R. This version
          complies with the database interface definition as implemented
          in the package DBI 0.1-4.
  Depends: R (>= 1.8.0), methods, DBI (>= 0.1-4)
  License: GPL
  URL: stat.bell-labs.com/RS-DBI www.mysql.com www.omegahat.org
  Packaged: Mon Jun 21 13:40:37 2004; dj
  Built: R 2.0.1; i686-pc-linux-gnu; 2005-03-17 16:43:13; unix
 
There are plans to make some improvements for the upcoming R release,
so I'd welcome your input.

--
David



From p.dalgaard at biostat.ku.dk  Thu Mar 17 23:03:14 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 17 Mar 2005 23:03:14 +0100
Subject: [R] exact p-value for Spearman, with ties
In-Reply-To: <3a0cc956050317130269082014@mail.gmail.com>
References: <3a0cc956050317130269082014@mail.gmail.com>
Message-ID: <x2br9iq6al.fsf@biostat.ku.dk>

Paul H Artes <paul.h.artes at gmail.com> writes:

> Dear R,
> 
> I'm looking for exact p-values for Spearman's rank correlation in the
> presence of ties. This is available in StatXact and SPSS, but I
> haven't yet found it in R. Has anyone implemented this?

The algorithm used by those two (it's the same one -- SPSS licences
it) does not seem to be openly available. 

It should be fairly easy to simulate the distribution of rho.

Another matter is that we really ought to at least get the normal
approximation right in the presence of ties.


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From rjsteckel at impactsci.com  Fri Mar 18 00:00:59 2005
From: rjsteckel at impactsci.com (Ryan Steckel)
Date: Thu, 17 Mar 2005 16:00:59 -0700
Subject: [R] TD Matrix
Message-ID: <AF535237618D884BAE36DF8B0437B979085651@benhur.denver.impactsci.com>

I'm trying to create a term document matrix where the columns are the
documents, the rows are the terms in the documents, and the cells are a
weight of term frequency in the document. My problem is the documents
are all different lengths. So when I add a new document, if the document
length is greater than the max document length in the matrix, I have to
resize the matrix and do a cbind operation. 
 
Does anyone know of an easier way?



From olilili at yahoo.com  Fri Mar 18 00:22:02 2005
From: olilili at yahoo.com (Oli)
Date: Thu, 17 Mar 2005 15:22:02 -0800 (PST)
Subject: [R] glm - poisson
Message-ID: <20050317232203.3402.qmail@web81405.mail.yahoo.com>

Hello,

I have a question on glm - poisson. I would like to
fit a model on proportion of counts with some factors,
and I decided to use glm - poisson because count data
is essentially related to poisson. However, since I
need to deal with proportion, and glm - poisson does
not allow non-integer responses, I am thinking of
adding an offset term = log(total). Is it the right
approach to it? or should I use quasi-poisson family,
or should I even use weights?

Thanks for your help!



From murdoch at stats.uwo.ca  Fri Mar 18 00:24:43 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 17 Mar 2005 18:24:43 -0500
Subject: [R] R equivalent to funcall?
In-Reply-To: <21401.129.206.90.2.1111068710.squirrel@129.206.90.2>
References: <30743.129.206.90.2.1111062032.squirrel@129.206.90.2>
	<a22j31lp2g8spme5tsdr2mrm2a9h5tvi4e@4ax.com>
	<21401.129.206.90.2.1111068710.squirrel@129.206.90.2>
Message-ID: <1d4k319cq6hmd82nee0bmpe2ql4hpr5mgh@4ax.com>

On Thu, 17 Mar 2005 15:11:50 +0100 (CET), Johannes H?sing
<johannes at huesing.name> wrote :

>
>> On Thu, 17 Mar 2005 13:20:32 +0100 (CET), Johannes H?sing
>> <johannes at huesing.name> wrote :
>[...]
>>>Is there a way that the dot-dot-dot argument of a
>>>function accepts a list as single arguments, such
>>>as funcall in several Lisp dialects?
>>
>> do.call() comes close to what you want.
>[...]
>
>Indeed it does. Thank you very much. I have overlooked
>that function.

Here's a variation on my suggestion from Luke Tierney that preserves
the special handling of the x and y arguments to plot():

> opts <- list(cex=2, lty=3, type='b')
> do.call(function(...) plot(1:10,rnorm(10),...), opts)

Duncan Murdoch



From reid_huntsinger at merck.com  Fri Mar 18 02:11:59 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Thu, 17 Mar 2005 20:11:59 -0500
Subject: [R] TD Matrix
Message-ID: <D9A95B4B7B20354992E165EEADA31999056A9351@uswpmx00.merck.com>

Do you mean when you encounter a new term? I would think document *length*
wouldn't matter; presumably you have a list of terms already. If so you
could treat each document as a vector of term codes, then use "tabulate" to
get the column for that document. 

If you're using all terms that appear in any document, and you don't want to
compile a list of terms first, then you might want to think of creating a
sparse representation as in the sparseM package and using the sparse linear
algebra routines there. Just an idea, though.

Reid Huntsinger

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ryan Steckel
Sent: Thursday, March 17, 2005 6:01 PM
To: r-help at stat.math.ethz.ch
Subject: [R] TD Matrix


I'm trying to create a term document matrix where the columns are the
documents, the rows are the terms in the documents, and the cells are a
weight of term frequency in the document. My problem is the documents
are all different lengths. So when I add a new document, if the document
length is greater than the max document length in the matrix, I have to
resize the matrix and do a cbind operation. 
 
Does anyone know of an easier way?

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From brett at hbrc.govt.nz  Fri Mar 18 03:09:17 2005
From: brett at hbrc.govt.nz (Brett Stansfield)
Date: Fri, 18 Mar 2005 15:09:17 +1300
Subject: [R] (no subject)
Message-ID: <3542A1BF5AE1984D9FF577DA2CF8BA9868B10E@MSX2>

I recently tried to make R highlight certain features in a scatterplot
matrix

pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", "loglife", "loggest",
"logbw")],
*	col=1+as.integer(ParaSleep > 5.5))

	this worked fine but when I wanted to add another condition i.e
where another variable SlowSleep = 7.7, this is what I got
	> pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", "loglife",
"loggest", "logbw")],
*	col=1+as.integer(ParaSleep > 5.5 & SlowSleep=7.7))
	Error: syntax error
	> pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", "loglife",
"loggest", "logbw")],
*	col=1+as.integer(ParaSleep > 5.5 & SlowSleep= 7.7))
	Error: syntax error
	> pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", "loglife",
"loggest", "logbw")],
*	col=1+as.integer(ParaSleep > 5.5 & SlowSleep = 7.7))
	Error: syntax error
	I then tried two separate col statements as below
	> pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", "loglife",
"loggest", "logbw")],
*	col=1+as.integer(ParaSleep > 5.5)
*	col1=2+as.integer(SlowSleep = 7.7))
	Error: syntax error
	> pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", "loglife",
"loggest", "logbw")],
*	col=1+as.integer(ParaSleep > 5.5)
*	col=2+as.integer(SlowSleep = 7.7))
Error: syntax error
But still no joy, can you recommend anything
brett.



From tiago17 at socrates.Berkeley.EDU  Fri Mar 18 03:11:59 2005
From: tiago17 at socrates.Berkeley.EDU (Tiago R Magalhaes)
Date: Thu, 17 Mar 2005 18:11:59 -0800
Subject: [R] extract rows in dataframe with duplicated column values
Message-ID: <p06100500be5fe80733ba@[192.168.1.102]>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050317/86bd15ad/attachment.pl

From sasprog474 at yahoo.com  Fri Mar 18 03:15:37 2005
From: sasprog474 at yahoo.com (Greg Tarpinian)
Date: Thu, 17 Mar 2005 18:15:37 -0800 (PST)
Subject: [R] Constrained Nelder-Mead
Message-ID: <20050318021538.52691.qmail@web41413.mail.yahoo.com>

All,

In looking at `optim', it doesn't appear that it is
possible to impose nonlinear constraints on Nelder-
Mead.  I am sufficiently motivated to try to code 
something in C from scratch and try to call it from
R....

Does anyone have some good references to barrier
and/or penalization methods for Nelder-Mead?  I would
ideally like some papers with pseudocode for method(s)
that are in some sense optimal for continuous 
functions.

Thanks,
   
     Greg



From jfox at mcmaster.ca  Fri Mar 18 03:27:18 2005
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 17 Mar 2005 21:27:18 -0500
Subject: [R] use of = in place of ==  (was no subject)
In-Reply-To: <3542A1BF5AE1984D9FF577DA2CF8BA9868B10E@MSX2>
Message-ID: <20050318022717.FMZQ1899.tomts13-srv.bellnexxia.net@JohnDesktop8300>

Dear Bret,

You appear to have used = (for assignment or argument specification) when
you meant == (equals).

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Brett 
> Stansfield
> Sent: Thursday, March 17, 2005 9:09 PM
> To: R help (E-mail)
> Subject: [R] (no subject)
> 
> I recently tried to make R highlight certain features in a 
> scatterplot matrix
> 
> pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", "loglife", 
> "loggest", "logbw")],
> *	col=1+as.integer(ParaSleep > 5.5))
> 
> 	this worked fine but when I wanted to add another 
> condition i.e where another variable SlowSleep = 7.7, this is 
> what I got
> 	> pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", 
> "loglife", "loggest", "logbw")],
> *	col=1+as.integer(ParaSleep > 5.5 & SlowSleep=7.7))
> 	Error: syntax error
> 	> pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", 
> "loglife", "loggest", "logbw")],
> *	col=1+as.integer(ParaSleep > 5.5 & SlowSleep= 7.7))
> 	Error: syntax error
> 	> pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", 
> "loglife", "loggest", "logbw")],
> *	col=1+as.integer(ParaSleep > 5.5 & SlowSleep = 7.7))
> 	Error: syntax error
> 	I then tried two separate col statements as below
> 	> pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", 
> "loglife", "loggest", "logbw")],
> *	col=1+as.integer(ParaSleep > 5.5)
> *	col1=2+as.integer(SlowSleep = 7.7))
> 	Error: syntax error
> 	> pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", 
> "loglife", "loggest", "logbw")],
> *	col=1+as.integer(ParaSleep > 5.5)
> *	col=2+as.integer(SlowSleep = 7.7))
> Error: syntax error
> But still no joy, can you recommend anything brett.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From sundar.dorai-raj at pdf.com  Fri Mar 18 03:27:36 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 17 Mar 2005 20:27:36 -0600
Subject: [R] (no subject)
In-Reply-To: <3542A1BF5AE1984D9FF577DA2CF8BA9868B10E@MSX2>
References: <3542A1BF5AE1984D9FF577DA2CF8BA9868B10E@MSX2>
Message-ID: <423A3C98.9080800@pdf.com>

Please use a meanful subject line!

You want SlowSleep == 7.7, not SlowSleep = 7.7.

Have you read the posting guide as others (including myself) have 
suggested? Have you also read "An Introduction To R," which comes with 
all R distributions?

--sundar

Brett Stansfield wrote on 3/17/2005 8:09 PM:
> I recently tried to make R highlight certain features in a scatterplot
> matrix
> 
> pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", "loglife", "loggest",
> "logbw")],
> *	col=1+as.integer(ParaSleep > 5.5))
> 
> 	this worked fine but when I wanted to add another condition i.e
> where another variable SlowSleep = 7.7, this is what I got
> 	> pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", "loglife",
> "loggest", "logbw")],
> *	col=1+as.integer(ParaSleep > 5.5 & SlowSleep=7.7))
> 	Error: syntax error
> 	> pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", "loglife",
> "loggest", "logbw")],
> *	col=1+as.integer(ParaSleep > 5.5 & SlowSleep= 7.7))
> 	Error: syntax error
> 	> pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", "loglife",
> "loggest", "logbw")],
> *	col=1+as.integer(ParaSleep > 5.5 & SlowSleep = 7.7))
> 	Error: syntax error
> 	I then tried two separate col statements as below
> 	> pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", "loglife",
> "loggest", "logbw")],
> *	col=1+as.integer(ParaSleep > 5.5)
> *	col1=2+as.integer(SlowSleep = 7.7))
> 	Error: syntax error
> 	> pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", "loglife",
> "loggest", "logbw")],
> *	col=1+as.integer(ParaSleep > 5.5)
> *	col=2+as.integer(SlowSleep = 7.7))
> Error: syntax error
> But still no joy, can you recommend anything
> brett.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From sundar.dorai-raj at pdf.com  Fri Mar 18 03:27:47 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 17 Mar 2005 20:27:47 -0600
Subject: [R] (no subject)
In-Reply-To: <3542A1BF5AE1984D9FF577DA2CF8BA9868B10E@MSX2>
References: <3542A1BF5AE1984D9FF577DA2CF8BA9868B10E@MSX2>
Message-ID: <423A3CA3.9030108@pdf.com>

Please use a meaningful subject line!

You want SlowSleep == 7.7, not SlowSleep = 7.7.

Have you read the posting guide as others (including myself) have 
suggested? Have you also read "An Introduction To R," which comes with 
all R distributions?

--sundar

Brett Stansfield wrote on 3/17/2005 8:09 PM:
> I recently tried to make R highlight certain features in a scatterplot
> matrix
> 
> pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", "loglife", "loggest",
> "logbw")],
> *	col=1+as.integer(ParaSleep > 5.5))
> 
> 	this worked fine but when I wanted to add another condition i.e
> where another variable SlowSleep = 7.7, this is what I got
> 	> pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", "loglife",
> "loggest", "logbw")],
> *	col=1+as.integer(ParaSleep > 5.5 & SlowSleep=7.7))
> 	Error: syntax error
> 	> pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", "loglife",
> "loggest", "logbw")],
> *	col=1+as.integer(ParaSleep > 5.5 & SlowSleep= 7.7))
> 	Error: syntax error
> 	> pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", "loglife",
> "loggest", "logbw")],
> *	col=1+as.integer(ParaSleep > 5.5 & SlowSleep = 7.7))
> 	Error: syntax error
> 	I then tried two separate col statements as below
> 	> pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", "loglife",
> "loggest", "logbw")],
> *	col=1+as.integer(ParaSleep > 5.5)
> *	col1=2+as.integer(SlowSleep = 7.7))
> 	Error: syntax error
> 	> pairs(sleep[c("SlowSleep", "ParaSleep", "logbrw", "loglife",
> "loggest", "logbw")],
> *	col=1+as.integer(ParaSleep > 5.5)
> *	col=2+as.integer(SlowSleep = 7.7))
> Error: syntax error
> But still no joy, can you recommend anything
> brett.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Fri Mar 18 04:14:32 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 17 Mar 2005 22:14:32 -0500
Subject: [R] extract rows in dataframe with duplicated column values
Message-ID: <3A822319EB35174CA3714066D590DCD50994E888@usrymx25.merck.com>

Does this work for you?

> x[table(x[,1]) > 1,]
  a  b
2 2 10
3 2 10
5 3 10
6 3 10

Andy

> From: Tiago R Magalhaes
> 
> Hi
> 
> I want to extract all the rows in a data frame that have duplicates 
> for a given column.
> I would expect this question to come up pretty often but I have 
> researched the archives and surprisingly couldn't find anything.
> The best I can come up with is:
> 
> x <- data.frame(a=c(1,2,2,3,3,3), b=10)
> xdup1 <- duplicated(x[,1])
> xdup2 <- duplicated(x[,1][nrow(x):1])[nrow(x):1]
> xAllDups <- x[(xdup1+xdup2)!=0,]
> 
> This seems to work, but it's so convoluted that I'm sure there's a 
> better method.
> Thanks for any help and enlightenment
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From andy_liaw at merck.com  Fri Mar 18 04:25:01 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 17 Mar 2005 22:25:01 -0500
Subject: [R] extract rows in dataframe with duplicated column values
Message-ID: <3A822319EB35174CA3714066D590DCD50994E889@usrymx25.merck.com>

OK, strike one...

Here's my second try:

> cnt <- table(x[,1])
> v <- as.numeric(names(cnt[cnt > 1]))
> v
[1] 2 3
> x[x[,1] %in% v, ]
  a  b
2 2 10
3 2 10
4 3 10
5 3 10
6 3 10

Andy

> From: Liaw, Andy
> 
> Does this work for you?
> 
> > x[table(x[,1]) > 1,]
>   a  b
> 2 2 10
> 3 2 10
> 5 3 10
> 6 3 10
> 
> Andy
> 
> > From: Tiago R Magalhaes
> > 
> > Hi
> > 
> > I want to extract all the rows in a data frame that have duplicates 
> > for a given column.
> > I would expect this question to come up pretty often but I have 
> > researched the archives and surprisingly couldn't find anything.
> > The best I can come up with is:
> > 
> > x <- data.frame(a=c(1,2,2,3,3,3), b=10)
> > xdup1 <- duplicated(x[,1])
> > xdup2 <- duplicated(x[,1][nrow(x):1])[nrow(x):1]
> > xAllDups <- x[(xdup1+xdup2)!=0,]
> > 
> > This seems to work, but it's so convoluted that I'm sure there's a 
> > better method.
> > Thanks for any help and enlightenment
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
> --------------------------------------------------------------
> ----------------
> Notice:  This e-mail message, together with any attachments, 
> contains information of Merck & Co., Inc. (One Merck Drive, 
> Whitehouse Station, New Jersey, USA 08889), and/or its 
> affiliates (which may be known outside the United States as 
> Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as 
> Banyu) that may be confidential, proprietary copyrighted 
> and/or legally privileged. It is intended solely for the use 
> of the individual or entity named on this message.  If you 
> are not the intended recipient, and have received this 
> message in error, please notify us immediately by reply 
> e-mail and then delete it from your system.
> --------------------------------------------------------------
> ----------------
> 
>



From goedman at mac.com  Fri Mar 18 04:35:19 2005
From: goedman at mac.com (Rob J Goedman)
Date: Thu, 17 Mar 2005 19:35:19 -0800
Subject: [R] extract rows in dataframe with duplicated column values
In-Reply-To: <p06100500be5fe80733ba@[192.168.1.102]>
References: <p06100500be5fe80733ba@[192.168.1.102]>
Message-ID: <a1b31e882b3df2b7cb4c702d4376d626@mac.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050317/eec7d6b5/attachment.pl

From MSchwartz at MedAnalytics.com  Fri Mar 18 04:46:18 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu, 17 Mar 2005 21:46:18 -0600
Subject: [R] extract rows in dataframe with duplicated column values
In-Reply-To: <3A822319EB35174CA3714066D590DCD50994E889@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50994E889@usrymx25.merck.com>
Message-ID: <1111117578.10293.105.camel@horizons.localdomain>

Here's one more possibility:

> subset(x, a %in% a[duplicated(a)])
  a  b
2 2 10
3 2 10
4 3 10
5 3 10
6 3 10

HTH,

Marc Schwartz


On Thu, 2005-03-17 at 22:25 -0500, Liaw, Andy wrote:
> OK, strike one...
> 
> Here's my second try:
> 
> > cnt <- table(x[,1])
> > v <- as.numeric(names(cnt[cnt > 1]))
> > v
> [1] 2 3
> > x[x[,1] %in% v, ]
>   a  b
> 2 2 10
> 3 2 10
> 4 3 10
> 5 3 10
> 6 3 10
> 
> Andy
> 
> > From: Liaw, Andy
> > 
> > Does this work for you?
> > 
> > > x[table(x[,1]) > 1,]
> >   a  b
> > 2 2 10
> > 3 2 10
> > 5 3 10
> > 6 3 10
> > 
> > Andy
> > 
> > > From: Tiago R Magalhaes
> > > 
> > > Hi
> > > 
> > > I want to extract all the rows in a data frame that have duplicates 
> > > for a given column.
> > > I would expect this question to come up pretty often but I have 
> > > researched the archives and surprisingly couldn't find anything.
> > > The best I can come up with is:
> > > 
> > > x <- data.frame(a=c(1,2,2,3,3,3), b=10)
> > > xdup1 <- duplicated(x[,1])
> > > xdup2 <- duplicated(x[,1][nrow(x):1])[nrow(x):1]
> > > xAllDups <- x[(xdup1+xdup2)!=0,]
> > > 
> > > This seems to work, but it's so convoluted that I'm sure there's a 
> > > better method.
> > > Thanks for any help and enlightenment
> > > 	[[alternative HTML version deleted]]
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> > > http://www.R-project.org/posting-guide.html
> > > 
> > > 
> > >
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> > 
> > --------------------------------------------------------------
> > ----------------
> > Notice:  This e-mail message, together with any attachments, 
> > contains information of Merck & Co., Inc. (One Merck Drive, 
> > Whitehouse Station, New Jersey, USA 08889), and/or its 
> > affiliates (which may be known outside the United States as 
> > Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as 
> > Banyu) that may be confidential, proprietary copyrighted 
> > and/or legally privileged. It is intended solely for the use 
> > of the individual or entity named on this message.  If you 
> > are not the intended recipient, and have received this 
> > message in error, please notify us immediately by reply 
> > e-mail and then delete it from your system.
> > --------------------------------------------------------------
> > ----------------
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From twiens at interbaun.com  Fri Mar 18 05:59:44 2005
From: twiens at interbaun.com (Trevor Wiens)
Date: Thu, 17 Mar 2005 21:59:44 -0700
Subject: [R] logistic model cross validation resolved
Message-ID: <20050317215944.30864f02.twiens@interbaun.com>

This post is NOT a question, but an answer. For readers please disregard all earlier posts by myself about this question.

I'm posting for two reasons. First to say thanks, especially to Dimitris, for suggesting the use of errorest in the ipred library. Second, so that the solution to this problem is in the archives in case it gets asked again. 
 
If one wants to run a k-fold cross-validation using specified folds, and get misclassification error and root mean squared error this is what you do. 

Below is a script that will do this returning the results of two errorest results combined into a data frame. Now this script assumes that the variable you are going to fold with is an integer. If you want to have the predicted values or models returned from each fold, the calls to errorest, can be modified. Please see the help page for control.errorest on details.

T
-- 
Trevor Wiens 
twiens at interbaun.com

==========================================================
myglm <- function(formula, family, data){
ret <- glm(formula, family=binomial, data=data)
return(ret)
}

myfacpred <- function(object, newdata) {
ret <- as.factor(ifelse(predict.glm(object, newdata, type='response') < 0.5, 0, 1))
return(ret)
}

# logerrorest takes four arguments
# mdata is a data frame holding the data to be modeled
# form is the output of the is.formula function
# rvar is the response variable as a string, for example 'birdx'
# fvar is the fold variable, for example 'recordyear'

logerrorest <- function(mdata, form, rvar, fvar) {
require(Hmisc)
require(ipred)

# determine index of variables
rpos <- match(rvar, names(mdata))
fpos <- match(fvar, names(mdata))
# get fold values and count for each group
vardesc <- describe(mdata[[fpos]])$values
fvarlist <- as.integer(dimnames(vardesc)[[2]])
k <- length(fvarlist)
countlist <- vardesc[1,1]

for (i in 2:k)
{
countlist[i] <- vardesc[1,i]
}
n <- length(mdata[[fpos]])

# get index list for each fold
cc <- list()
for (i in 1:k)
{
cc[[i]] <- as.integer(rownames(mdata[mdata[[fpos]] == fvarlist[i], ]))
}

# determine root mean squared error
ee <- errorest(form, mdata, estimator='cv', model=myglm, est.para=control.errorest(list.tindx = cc))

# determine misclassification error
# first convert to factor
width = length(mdata)
response <- as.factor(as.integer(mdata[[rpos]]))
newmatrix <- data.frame(cbind(mdata[1:(rpos-1)], response, mdata[(rpos+1):width]))
newform <- as.formula(paste('response ~ ', as.character(form)[[3]]))
me <- errorest(newform, newmatrix, estimator='cv', model=myglm, predict=myfacpred, est.para=control.errorest(list.tindx = cc))

ret <- data.frame(cbind(ee, me))

return(ret)
}



From vegard.andersen at ism.uit.no  Fri Mar 18 11:15:34 2005
From: vegard.andersen at ism.uit.no (Vegard Andersen)
Date: Fri, 18 Mar 2005 11:15:34 +0100
Subject: [R] Date conversion problem using "as.Date"
Message-ID: <opsntv38wtk0a1dr@petter-smart>

Hello!

My problem is that the Julian date "behind" my dates seems to be wrong. I  
will examplify my problem.

t1 <- "1998-11-20"
t2 <- as.Date(t1)
# Here t2 is correctly "1998-11-20", but
date.mdy(t2)
$month
[1] 11
$day
[1] 19
$year
[1] 1988

And indeed, if I write: fix(t2) then I get : structure(10550, class =  
"Date"). So the Julian date is 10550, which is "1988-11-19", not the  
correct "1998-11-20"

If I instead of "as.Date" use "as.date", then things work ok. But I have  
not found out how to instruct "as.date" to handle dates from the 21st  
century.


I hope that someone can help me, thanks in advance!

-- 
Best regards,
Vegard Andersen
Institute of Community Medicine
University of Tromso
Tromso, Norway

vegard.andersen at ism.uit.no



From MHM.de.Moor at psy.vu.nl  Fri Mar 18 11:40:47 2005
From: MHM.de.Moor at psy.vu.nl (Moor MHM.de)
Date: Fri, 18 Mar 2005 11:40:47 +0100
Subject: [R] multiple graphs
Message-ID: <D6E56B6A60CC824EB41FC02060D0D953094D3F@jake.psy.vu.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050318/b6423832/attachment.pl

From oarabile at stams.strath.ac.uk  Fri Mar 18 11:49:39 2005
From: oarabile at stams.strath.ac.uk (Oarabile Ruth Molaodi)
Date: Fri, 18 Mar 2005 10:49:39 +0000
Subject: [R] creating functions in R
Message-ID: <423AB243.3010409@stams.strath.ac.uk>

I am trying to learn how to create my own function in R. I want to 
create a function that can plot the polygons/regions/map given the 
coordinates of each region. The function should be able to colour the 
poplygons according to the data supplied ,for examples the means or 
rates of disease at a region/polygon.

your advise will be highly appreciated.

Thanks in advance for your help.

Oarabile



From ligges at statistik.uni-dortmund.de  Fri Mar 18 11:50:00 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 18 Mar 2005 11:50:00 +0100
Subject: [R] multiple graphs
In-Reply-To: <D6E56B6A60CC824EB41FC02060D0D953094D3F@jake.psy.vu.nl>
References: <D6E56B6A60CC824EB41FC02060D0D953094D3F@jake.psy.vu.nl>
Message-ID: <423AB258.8050006@statistik.uni-dortmund.de>

Moor MHM.de wrote:

> Dear all,
> 
>  
> 
> I would like to plot multiple graphs in the same window. For this I
> used:
> 
>  
> 
> par(mfcol=c(5,2) )
> 
>  
> 
> and then I use plot(x,y) to fill the cells of the window with the
> graphs.
> 
>  
> 
> This results in multiple graphs with a lot of space around each graph.
> 
> But I would like the 5 graphs in each column to be 'connected' (i.e., no
> space around them) and to specify values and label on the x-axis only
> for the lowest graph in each column.


See ?par, e.g. set par(mar = rep(0,4)) for the inner plots.

Uwe Ligges

>  
> 
> Does anyone know how I can do this? I considered xyplot(y~x|z) from the
> lattice package, but I have different variables on the y-axis in each
> graph, so this does not seem to work?
> 
>  
> 
> Thanks in advance for any suggestions,
> 
> Marleen de Moor
> 
>  
> 
> Dept. of Biological Psychology
> 
> Free University Amsterdam
> 
> mhm.de.moor at psy.vu.nl 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From vmuggeo at dssm.unipa.it  Fri Mar 18 11:51:57 2005
From: vmuggeo at dssm.unipa.it (vito muggeo)
Date: Fri, 18 Mar 2005 11:51:57 +0100
Subject: [R] multiple graphs
In-Reply-To: <D6E56B6A60CC824EB41FC02060D0D953094D3F@jake.psy.vu.nl>
References: <D6E56B6A60CC824EB41FC02060D0D953094D3F@jake.psy.vu.nl>
Message-ID: <423AB2CD.3040401@dssm.unipa.it>

You can use

par(mai=_yourValues_)

For instance:

 > par(mfcol=c(5,2) )
 > par(mai=c(0,0,0,0))
 > replicate(10,plot(1:10))

Modify the mai parameter and arguments in the plot() function to get 
better results,
hope this helps,

vito



Moor MHM.de wrote:
> Dear all,
> 
>  
> 
> I would like to plot multiple graphs in the same window. For this I
> used:
> 
>  
> 
> par(mfcol=c(5,2) )
> 
>  
> 
> and then I use plot(x,y) to fill the cells of the window with the
> graphs.
> 
>  
> 
> This results in multiple graphs with a lot of space around each graph.
> 
> But I would like the 5 graphs in each column to be 'connected' (i.e., no
> space around them) and to specify values and label on the x-axis only
> for the lowest graph in each column.
> 
>  
> 
> Does anyone know how I can do this? I considered xyplot(y~x|z) from the
> lattice package, but I have different variables on the y-axis in each
> graph, so this does not seem to work?
> 
>  
> 
> Thanks in advance for any suggestions,
> 
> Marleen de Moor
> 
>  
> 
> Dept. of Biological Psychology
> 
> Free University Amsterdam
> 
> mhm.de.moor at psy.vu.nl 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
====================================
Vito M.R. Muggeo
Dip.to Sc Statist e Matem `Vianelli'
Universit? di Palermo
viale delle Scienze, edificio 13
90121 Palermo - ITALY
tel: 091 6626240
fax: 091 485726/485612



From stefaan.lhermitte at biw.kuleuven.be  Fri Mar 18 11:56:41 2005
From: stefaan.lhermitte at biw.kuleuven.be (Stefaan Lhermitte)
Date: Fri, 18 Mar 2005 11:56:41 +0100
Subject: [R] Optimization of constrained linear least-squares problem
In-Reply-To: <009201c52b00$9a400b50$0540210a@www.domain>
References: <42399085.8070907@biw.kuleuven.be>
	<009201c52b00$9a400b50$0540210a@www.domain>
Message-ID: <423AB3E9.3000705@biw.kuleuven.be>

Thanx Dimitris, Patrick and Berwin!

For other people interested in this problem, here are two valid 
solutions that work.

1) Re-parameterize  e.g.,

    EM <- c(100,0,0,0,100,0,0,0,100)
    W <- array(EM, c(3,3))
    d <- c(10, 20, 70)

    fn <- function(x){
          x <- exp(x) / sum(exp(x))
          r <- W%*%x - d
        crossprod(r, r)[1,1]
    }
    opt <- optim(rnorm(3), fn)
    res <- exp(opt$par) / sum(exp(opt$par))
    res

    "The first line of the `fn()' function is just a re-pameterization
    of your problem, i.e., if `y' is a vector of real numbers, then it
    is straightforward to see that `x = exp(y) / sum(exp(y))' will be
    real numbers in (0, 1) for which `sum(y)=1'. So instead of finding
    xs that minimize your function under the constraint (which is more
    difficult) you just find the ys using the above transformation." (I
    owe you a drink Dimitris !!!)

2)  Or minimize it as a quadratic function under a linear constraint:

    EM <- c(100,0,0,0,100,0,0,0,100)
    W <- array(EM, c(3,3))
    d <- c(10, 20, 70)
    library(quadprog)
    Dmat <- crossprod(W,W)
    dvec <- crossprod(d,W)
    A <-matrix(c(1,1,1),ncol=1)
    bvec <- 1
    solve.QP(Dmat, dvec, A, bvec, meq=1)

    This is based on the objective function (i.e. the thing you want to
    minimise) : min x'C'Cx - 2 d'Cx + d'd where sum(x) = 1
    (Thanx Berwin!!)

Kind regards,
Stef



From ligges at statistik.uni-dortmund.de  Fri Mar 18 11:56:36 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 18 Mar 2005 11:56:36 +0100
Subject: [R] creating functions in R
In-Reply-To: <423AB243.3010409@stams.strath.ac.uk>
References: <423AB243.3010409@stams.strath.ac.uk>
Message-ID: <423AB3E4.6090203@statistik.uni-dortmund.de>

Oarabile Ruth Molaodi wrote:

> I am trying to learn how to create my own function in R. I want to 
> create a function that can plot the polygons/regions/map given the 
> coordinates of each region. The function should be able to colour the 
> poplygons according to the data supplied ,for examples the means or 
> rates of disease at a region/polygon.


You might want to take a look at package "maps".

Uwe Ligges


> your advise will be highly appreciated.
> 
> Thanks in advance for your help.
> 
> Oarabile
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ayalahec at msu.edu  Fri Mar 18 12:16:56 2005
From: ayalahec at msu.edu (Hector L. Ayala-del-Rio)
Date: Fri, 18 Mar 2005 07:16:56 -0400
Subject: [R] Installation problem MacOS X
Message-ID: <3D320207-979F-11D9-ABB3-000393DB5846@msu.edu>

R gurus
    I have tried to install the R 2.0.1 binary for OS X and although the 
installation was successful I can get the application going.  When I 
double click the icon R tries to load (R window shows briefly) and it 
quits immediately.  This behavior was described in this list before and 
nobody found the answer to the problem. If you try to load the x11 
version by typing "R" at the command line it loads up with no problem.  
This means that the app is partially working and there are no 
permissions issue.  The most interesting thing is if I log to a 
different account (Dummy) and I double click the application it loads 
with no problem.  This makes me think that there has to be some type of 
user specific file or directory that is causing the gui to quit.  Any 
suggestions on what file(s) could be affecting R?

Thanks

Hector

******************************************
H?ctor L. Ayala-del-R?o, Ph.D.
Assistant Professor
Department of Biology
University of Puerto Rico at Humacao
CUH postal station
100 road 908
Humacao, PR 00791
Ph: 787-850-0000 x 9001
Fax: 787-850-9439



From pingping.zheng at lancaster.ac.uk  Fri Mar 18 12:40:15 2005
From: pingping.zheng at lancaster.ac.uk (Pingping Zheng)
Date: Fri, 18 Mar 2005 11:40:15 +0000
Subject: [R] passing arguments to FUN in lapply
Message-ID: <423ABE1F.9080203@lancs.ac.uk>

Suppose I have a nx2 matrix of data, X, the following code generate
density estimation for each column and plot them

denlist <- apply(X, 2, density)
par(mfrow=c(1,2))
lapply(denlist, plot)

Does anyone know how to change the main title of each density plot
to "var 1", "var 2" by passing optional argument "main"? I've tried

lapply(denlist, plot, main=c("var 1", "var 2"))
which generates two same titles "var 1/var 2" and "var 1/var 2"

lapply(denlist, plot, main=list("var 1", "var 2"))
which generates two same titles "var 1"

Both are not I want.

-- 
Pingping Zheng
Department of Mathematics and Statistics
Fylde College
Lancaster University
Lancaster LA1 4YF
UK



From Roger.Bivand at nhh.no  Fri Mar 18 12:41:13 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 18 Mar 2005 12:41:13 +0100 (CET)
Subject: [R] creating functions in R
In-Reply-To: <423AB3E4.6090203@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.44.0503181234430.5170-100000@reclus.nhh.no>

On Fri, 18 Mar 2005, Uwe Ligges wrote:

> Oarabile Ruth Molaodi wrote:
> 
> > I am trying to learn how to create my own function in R. I want to 
> > create a function that can plot the polygons/regions/map given the 
> > coordinates of each region. The function should be able to colour the 
> > poplygons according to the data supplied ,for examples the means or 
> > rates of disease at a region/polygon.
> 
> 
> You might want to take a look at package "maps".

Or others mentioned on http://www.R-project.org/Rgeo, for example, see how 
the DCluster package plots disease rates, or look at plot.polylist() in 
the maptools package. The maps package does depend on the user building a 
geographical database first, rather than taking an arbitrary ring of 
coordinates as a polygon. Colouring is a class interval problem, which has 
to be done separately anyway - see the examples on the help pages for the 
relevant functions (hint - findInterval() is good at setting the colour 
vector for the polygons).

Roger Bivand

> 
> Uwe Ligges
> 
> 
> > your advise will be highly appreciated.
> > 
> > Thanks in advance for your help.
> > 
> > Oarabile
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From ligges at statistik.uni-dortmund.de  Fri Mar 18 12:46:23 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 18 Mar 2005 12:46:23 +0100
Subject: [R] passing arguments to FUN in lapply
In-Reply-To: <423ABE1F.9080203@lancs.ac.uk>
References: <423ABE1F.9080203@lancs.ac.uk>
Message-ID: <423ABF8F.8080402@statistik.uni-dortmund.de>

Pingping Zheng wrote:

> Suppose I have a nx2 matrix of data, X, the following code generate
> density estimation for each column and plot them
> 
> denlist <- apply(X, 2, density)
> par(mfrow=c(1,2))
> lapply(denlist, plot)
> 
> Does anyone know how to change the main title of each density plot
> to "var 1", "var 2" by passing optional argument "main"? I've tried
> 
> lapply(denlist, plot, main=c("var 1", "var 2"))
> which generates two same titles "var 1/var 2" and "var 1/var 2"
> 
> lapply(denlist, plot, main=list("var 1", "var 2"))
> which generates two same titles "var 1"
> 
> Both are not I want.
> 

If the title is contained in denlist, you can specify a anonymous 
function, if not, use mapply or simply a for() loop.

Uwe Ligges



From j.van_den_hoff at fz-rossendorf.de  Fri Mar 18 12:52:39 2005
From: j.van_den_hoff at fz-rossendorf.de (joerg van den hoff)
Date: Fri, 18 Mar 2005 12:52:39 +0100
Subject: [R] Installation problem MacOS X
In-Reply-To: <3D320207-979F-11D9-ABB3-000393DB5846@msu.edu>
References: <3D320207-979F-11D9-ABB3-000393DB5846@msu.edu>
Message-ID: <423AC107.5000300@fz-rossendorf.de>

Hector L. Ayala-del-Rio wrote:
> R gurus
>    I have tried to install the R 2.0.1 binary for OS X and although the 
> installation was successful I can get the application going.  When I 
> double click the icon R tries to load (R window shows briefly) and it 
> quits immediately.  This behavior was described in this list before and 
> nobody found the answer to the problem. If you try to load the x11 
> version by typing "R" at the command line it loads up with no problem.  
> This means that the app is partially working and there are no 
> permissions issue.  The most interesting thing is if I log to a 
> different account (Dummy) and I double click the application it loads 
> with no problem.  This makes me think that there has to be some type of 
> user specific file or directory that is causing the gui to quit.  Any 
> suggestions on what file(s) could be affecting R?
> 
> Thanks
> 
> Hector
> 
> ******************************************
> H?ctor L. Ayala-del-R?o, Ph.D.
> Assistant Professor
> Department of Biology
> University of Puerto Rico at Humacao
> CUH postal station
> 100 road 908
> Humacao, PR 00791
> Ph: 787-850-0000 x 9001
> Fax: 787-850-9439
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 

you have moved the R app already to it's final destination (instead of 
starting it from the mounted disk image)?

I would try the "Console" utility (in /Applications/Utilities) to have a 
look at console.log and system.log (or inspect the logs directly: 
/private/var/log/system.log and /Library/Logs/Console/vdh/console.log) 
immediately _after_ an  attempt to start the R app. probably it's a 
permission problem all the same.


regards
joerg


ps: there is a R mailing list exclusively for OS X users:

https://stat.ethz.ch/mailman/listinfo/r-sig-mac



From dimitris.rizopoulos at med.kuleuven.ac.be  Fri Mar 18 12:56:09 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Fri, 18 Mar 2005 12:56:09 +0100
Subject: [R] passing arguments to FUN in lapply
References: <423ABE1F.9080203@lancs.ac.uk>
Message-ID: <00f101c52bb1$79a772f0$0540210a@www.domain>

an indirect solution is the following:

lapply(seq(along=denlist), function(i) plot(denlist[[i]], 
main=paste("var", i)))

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm

----- Original Message ----- 
From: "Pingping Zheng" <pingping.zheng at lancaster.ac.uk>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, March 18, 2005 12:40 PM
Subject: [R] passing arguments to FUN in lapply


> Suppose I have a nx2 matrix of data, X, the following code generate
> density estimation for each column and plot them
>
> denlist <- apply(X, 2, density)
> par(mfrow=c(1,2))
> lapply(denlist, plot)
>
> Does anyone know how to change the main title of each density plot
> to "var 1", "var 2" by passing optional argument "main"? I've tried
>
> lapply(denlist, plot, main=c("var 1", "var 2"))
> which generates two same titles "var 1/var 2" and "var 1/var 2"
>
> lapply(denlist, plot, main=list("var 1", "var 2"))
> which generates two same titles "var 1"
>
> Both are not I want.
>
> -- 
> Pingping Zheng
> Department of Mathematics and Statistics
> Fylde College
> Lancaster University
> Lancaster LA1 4YF
> UK
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From a.trapletti at bluewin.ch  Fri Mar 18 13:34:23 2005
From: a.trapletti at bluewin.ch (Adrian Trapletti)
Date: Fri, 18 Mar 2005 13:34:23 +0100
Subject: [R] Constrained Nelder-Mead
Message-ID: <423ACACF.7080804@bluewin.ch>

>
>
>All,
>
>In looking at `optim', it doesn't appear that it is
>possible to impose nonlinear constraints on Nelder-
>Mead.  I am sufficiently motivated to try to code 
>something in C from scratch and try to call it from
>R....
>
>Does anyone have some good references to barrier
>and/or penalization methods for Nelder-Mead?  I would
>ideally like some papers with pseudocode for method(s)
>that are in some sense optimal for continuous 
>functions.
>
>Thanks,
>   
>     Greg
>
http://plato.la.asu.edu/topics/problems/nlores.html

and look for COBYLA (Fortran 77, 90 and C code is available)

best
Adrian



From benjamin.esterni at wanadoo.fr  Fri Mar 18 13:57:13 2005
From: benjamin.esterni at wanadoo.fr (Benjamin Esterni)
Date: Fri, 18 Mar 2005 13:57:13 +0100 (CET)
Subject: [R] RE: problem with Dates
Message-ID: <33427225.1111150633293.JavaMail.www@wwinf0601>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050318/3a66d4e0/attachment.pl

From achilleas.psomas at wsl.ch  Fri Mar 18 14:04:07 2005
From: achilleas.psomas at wsl.ch (achilleas.psomas@wsl.ch)
Date: Fri, 18 Mar 2005 14:04:07 +0100
Subject: [R] Convex hull line coordinates..
In-Reply-To: <1107965723.420a371b2bf55@webmail.wsl.ch>
References: <1107965723.420a371b2bf55@webmail.wsl.ch>
Message-ID: <1111151047.423ad1c781698@webmail.wsl.ch>

Hello R-Helpers..

I am still new in R and I have the following question..
I am applying the function chull on a 2D dataset and have the convex hull nicely
calculated and plotted.
Do you know if there is a way to extract the coordinates of the line created
from the connection of the chull data points..
I have alredy tried with "approx" to lineary interpolate but its not working
correctly since the interpolated values sometimes fall inside the convex .
Using the "yleft" or "yright" doesnt seem to help..

Any suggestions?
Thank you in advance

Achilleas.



From ggrothendieck at myway.com  Fri Mar 18 14:06:07 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 18 Mar 2005 13:06:07 +0000 (UTC)
Subject: [R] passing arguments to FUN in lapply
References: <423ABE1F.9080203@lancs.ac.uk>
Message-ID: <loom.20050318T140352-723@post.gmane.org>

Pingping Zheng <pingping.zheng <at> lancaster.ac.uk> writes:

: 
: Suppose I have a nx2 matrix of data, X, the following code generate
: density estimation for each column and plot them
: 
: denlist <- apply(X, 2, density)
: par(mfrow=c(1,2))
: lapply(denlist, plot)
: 
: Does anyone know how to change the main title of each density plot
: to "var 1", "var 2" by passing optional argument "main"? I've tried
: 
: lapply(denlist, plot, main=c("var 1", "var 2"))
: which generates two same titles "var 1/var 2" and "var 1/var 2"
: 
: lapply(denlist, plot, main=list("var 1", "var 2"))
: which generates two same titles "var 1"
: 
: Both are not I want.
: 

Try mapply instead of lapply:

mapply(plot, denlist, main = paste("var", 1:2))



From ms99_2000 at yahoo.de  Fri Mar 18 14:25:02 2005
From: ms99_2000 at yahoo.de (michael schmitt)
Date: Fri, 18 Mar 2005 14:25:02 +0100 (CET)
Subject: [R] Changing label size in plot.dendrogram
Message-ID: <20050318132503.47363.qmail@web26007.mail.ukl.yahoo.com>

Dear R friends,

I have constructed an object of class 'dendrogram'
using an own function, and I'm using the R function
plot.dendrogram for visualizing it.
It works fine, but I could not find out how to change
the font size of edge and leaf labels.
?plot.dendrogram has shown me that the coloring of the
edge labels can be changed using plot(my.dendrogram,
edgePar=list(t.col='green')), but something like
't.cex' doesn't seem to exist.  

Any hints greatly appreciated.
Best regards,
Michael



From ramasamy at cancer.org.uk  Fri Mar 18 14:29:03 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Fri, 18 Mar 2005 13:29:03 +0000
Subject: [R] passing arguments to FUN in lapply
In-Reply-To: <423ABE1F.9080203@lancs.ac.uk>
References: <423ABE1F.9080203@lancs.ac.uk>
Message-ID: <1111152543.6179.17.camel@ndmpc126.orc.ox.ac.uk>

See Andy Liaw's and my suggestion to this post
http://files.protsuggest.org/biocond/html/7818.html


On Fri, 2005-03-18 at 11:40 +0000, Pingping Zheng wrote:
> Suppose I have a nx2 matrix of data, X, the following code generate
> density estimation for each column and plot them
> 
> denlist <- apply(X, 2, density)
> par(mfrow=c(1,2))
> lapply(denlist, plot)
> 
> Does anyone know how to change the main title of each density plot
> to "var 1", "var 2" by passing optional argument "main"? I've tried
> 
> lapply(denlist, plot, main=c("var 1", "var 2"))
> which generates two same titles "var 1/var 2" and "var 1/var 2"
> 
> lapply(denlist, plot, main=list("var 1", "var 2"))
> which generates two same titles "var 1"
> 
> Both are not I want.
>



From secchi at sssup.it  Fri Mar 18 15:48:56 2005
From: secchi at sssup.it (Angelo Secchi)
Date: Fri, 18 Mar 2005 14:48:56 +0000
Subject: [R] Non linear modeling
Message-ID: <20050318144856.3ec773e6.secchi@sssup.it>


Hi,
is there a way  in R to fit a non linear model like

y=x+exp(a*x)*eps

where a is the parameter and eps is the error term? 
Thanks
Angelo



From ggrothendieck at myway.com  Fri Mar 18 14:51:43 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 18 Mar 2005 13:51:43 +0000 (UTC)
Subject: [R] Date conversion problem using "as.Date"
References: <opsntv38wtk0a1dr@petter-smart>
Message-ID: <loom.20050318T141817-360@post.gmane.org>

Vegard Andersen <vegard.andersen <at> ism.uit.no> writes:

: 
: Hello!
: 
: My problem is that the Julian date "behind" my dates seems to be wrong. I  
: will examplify my problem.
: 
: t1 <- "1998-11-20"
: t2 <- as.Date(t1)
: # Here t2 is correctly "1998-11-20", but
: date.mdy(t2)
: $month
: [1] 11
: $day
: [1] 19
: $year
: [1] 1988
: 
: And indeed, if I write: fix(t2) then I get : structure(10550, class =  
: "Date"). So the Julian date is 10550, which is "1988-11-19", not the  
: correct "1998-11-20"
: 
: If I instead of "as.Date" use "as.date", then things work ok. But I have  
: not found out how to instruct "as.date" to handle dates from the 21st  
: century.
: 
: I hope that someone can help me, thanks in advance!
: 


As already mentioned the "date" class in survival uses 1960 as
its origin:

   R> as.date(0)
   [1] 1Jan60

whereas the "Date" class uses 1970:

   R> structure(0, class = "Date")
   [1] "1970-01-01"

Regarding your other question you can use a 4 digit year:

   R> as.date("2Jan2001")
   [1] 2Jan2001

or:

   R> as.date.Date <- function(x) as.date(format(x), order = "ymd")
   R> as.date.Date(t2)
   [1] 20Nov98



From andy_liaw at merck.com  Fri Mar 18 14:56:38 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 18 Mar 2005 08:56:38 -0500
Subject: [R] Non linear modeling
Message-ID: <3A822319EB35174CA3714066D590DCD50994E88F@usrymx25.merck.com>

AFAIK most model fitting techniques will only deal with additive errors, not
multiplicative ones.  You might want to try fitting:

log(y-x) = a*x + e

which is linear.

Andy

> From: Angelo Secchi
> 
> Hi,
> is there a way  in R to fit a non linear model like
> 
> y=x+exp(a*x)*eps
> 
> where a is the parameter and eps is the error term? 
> Thanks
> Angelo
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From nioniodesbois at yahoo.fr  Fri Mar 18 15:18:44 2005
From: nioniodesbois at yahoo.fr (Guillaume STORCHI)
Date: Fri, 18 Mar 2005 15:18:44 +0100 (CET)
Subject: [R] Re: non-linear model
Message-ID: <20050318141844.77014.qmail@web86908.mail.ukl.yahoo.com>

if a and eps are parameters to be fitted

X<-nls(y~x+exp(a*x)*eps, data=,start=list(a=,eps=))



From macq at llnl.gov  Fri Mar 18 16:12:30 2005
From: macq at llnl.gov (Don MacQueen)
Date: Fri, 18 Mar 2005 07:12:30 -0800
Subject: [R] Ideal Computer and Software (A bit off topic)
In-Reply-To: <20050317194158.74238.qmail@web52503.mail.yahoo.com>
References: <20050317194158.74238.qmail@web52503.mail.yahoo.com>
Message-ID: <p06210225be609caf631e@[128.115.153.6]>

I'd like to mention that if using the desktop applications such as MS 
Word, Excel, Powerpoint, email software, Acrobat Reader, etc. is 
important to you, then the Mac may be a better choice than a Linux 
box. Mac OS X lets you use all of those, and also work at the unix 
level, side by side and simultaneously, on the same machine.

On a Mac you can run R either with a GUI analagous to that of R for 
Windows, or you can run it as a command line app, as on Linux.

I can't help with performance comparison questions, or the 64 bit 
issue, I'm sorry to say.

-Don

At 11:41 AM -0800 3/17/05, KKThird at Yahoo.Com wrote:
>Hello everyone.
>
>This question might be a bit off topic, but I thought
>that (a) there couldn't be a better group to address
>my questions and (b) that others might find it useful
>too; It also might start an interesting discussion
>thread. 
>
>I use R often for simulation purposes (which generally
>involve a lot of for() loops) and for most of my
>general work. I will be purchasing a new computing
>system soon, and I'm wondering the best way to go. I'm
>a Windows user now, and from what I know and have read
>about Linux, it is what I should be using (or possibly
>a Unix machine). I'm not wedded to a Windows system
>and I'm willing to put in the time to learn Linux if
>it would truly be beneficial. Is it the case that
>Linux offers so much more than Windows that it is
>definitely worth the switch?
>
>For the hardware issue, is it generally better to run
>R on a server and then connect to the server or on a
>stand alone computer (Obviously the performance would
>be related to the specific hardware, but if the
>hardware was essentially equal, would there be any
>advantage to either?).

A server might have other users using competing with you for cpu cycles.
A server might have a more reliable backup policy (or might not!).
A server might or might not have security patches and OS upgrades 
done more promptly.
If you need to transfer content from R (text output or graphics 
files) into reports or presentations,
it might be easier with a local machine, depending on whether the 
server shares file systems.


>
>What seems to be better for using R on, an Intel, AMD,
>Unix, or Mac (which I suppose is now a Unix)
>processor? In terms of speed, again given the
>analogous hardware, is there an advantage to one of
>these?
>
>Does it make sense to get a 64 bit AMD processor, or
>is that just an overkill? Would R even make use of the
>64 bit processing power?
>
>I'm very interested on any thoughts people have on
>this. I'm a big user of computers, but I'm not overly
>knowledgeable about their inner workings.
>
>Thanks and have a nice day,
>Ken
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From r_xprt_wannabe at yahoo.com  Fri Mar 18 16:18:06 2005
From: r_xprt_wannabe at yahoo.com (R_xprt_wannabe)
Date: Fri, 18 Mar 2005 07:18:06 -0800 (PST)
Subject: [R] How to create a 'fit' plot
Message-ID: <20050318151806.58932.qmail@web61304.mail.yahoo.com>

Dear List,

As someone who is in the process of trying to migrate
from Excel, I'd appreciate any help on this question:

I have a data set and want to fit, say, three
distributions to it.  I would like to create a plot
that shows my data points against all three fitted
curves (estimated d.f.).  Basically, I lookint to
creat a plot that looks like the one presented in the
attached paper (Figure 5, page 12):

http://www.math.ethz.ch/~mcneil/ftp/astin.pdf


Could you please show me, or point me to example code
showing, how that can be done?  

Thanks,



From tlumley at u.washington.edu  Fri Mar 18 16:33:38 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 18 Mar 2005 07:33:38 -0800 (PST)
Subject: [R] RE: problem with Dates
In-Reply-To: <33427225.1111150633293.JavaMail.www@wwinf0601>
References: <33427225.1111150633293.JavaMail.www@wwinf0601>
Message-ID: <Pine.A41.4.61b.0503180731080.256986@homer05.u.washington.edu>

On Fri, 18 Mar 2005, Benjamin Esterni wrote:

> It seems that you have load the "survival" package
> date.mdy is a function from this one.
> In this function the "origin" of the time is the first day of 1970
> in the base package the origin is the first day of 1960
> it's very curious...

Well, it would be very curious if they defined the same class, but the 
base package defines "Date" and the survival package defines "date". 
There's no reason why they should use the same origin, but it will cause 
problems if you mix them up.

 	-thomas

> Benjamin Esterni
> France
>
> From: "Vegard Andersen" <vegard.andersen at ism.uit.no>
> Subject: [R] Date conversion problem using "as.Date"
> To: "r-help at lists.r-project.org" <r-help at stat.math.ethz.ch>
> Message-ID: <opsntv38wtk0a1dr at petter-smart>
> Content-Type: text/plain; format=flowed; delsp=yes;
> charset=iso-8859-15
>
> Hello!
>
> My problem is that the Julian date "behind" my dates seems to be wrong. I
> will examplify my problem.
>
> t1 <- "1998-11-20"
> t2 <- as.Date(t1)
> # Here t2 is correctly "1998-11-20", but
> date.mdy(t2)
> $month
> [1] 11
> $day
> [1] 19
> $year
> [1] 1988
>
> And indeed, if I write: fix(t2) then I get : structure(10550, class =
> "Date"). So the Julian date is 10550, which is "1988-11-19", not the
> correct "1998-11-20"
>
> If I instead of "as.Date" use "as.date", then things work ok. But I have
> not found out how to instruct "as.date" to handle dates from the 21st
> century.
>
>
> I hope that someone can help me, thanks in advance!
>
> -- 
> Best regards,
> Vegard Andersen
> Institute of Community Medicine
> University of Tromso
> Tromso, Norway
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From goedman at mac.com  Fri Mar 18 16:48:30 2005
From: goedman at mac.com (Rob J Goedman)
Date: Fri, 18 Mar 2005 07:48:30 -0800
Subject: [R] Installation problem MacOS X
In-Reply-To: <3D320207-979F-11D9-ABB3-000393DB5846@msu.edu>
References: <3D320207-979F-11D9-ABB3-000393DB5846@msu.edu>
Message-ID: <228170594667149db75be460b65cf178@mac.com>

Hector,

By application, you mean R or the R + GUI (R.app)?

Please check if you have an existing .RData file in the directory where 
you start R.
If it's R.app and X11 was used when .RData was saved, X11 needs to run 
when the restore takes
place.

Mac OS issues might be better raised on R-SIG-Mac 
(r-sig-mac at stat.math.ethz.ch).

Regards,
Rob


On Mar 18, 2005, at 3:16 AM, Hector L. Ayala-del-Rio wrote:

> R gurus
>    I have tried to install the R 2.0.1 binary for OS X and although 
> the installation was successful I can get the application going.  When 
> I double click the icon R tries to load (R window shows briefly) and 
> it quits immediately.  This behavior was described in this list before 
> and nobody found the answer to the problem. If you try to load the x11 
> version by typing "R" at the command line it loads up with no problem. 
>  This means that the app is partially working and there are no 
> permissions issue.  The most interesting thing is if I log to a 
> different account (Dummy) and I double click the application it loads 
> with no problem.  This makes me think that there has to be some type 
> of user specific file or directory that is causing the gui to quit.  
> Any suggestions on what file(s) could be affecting R?
>
> Thanks
>
> Hector
>
> ******************************************
> H?ctor L. Ayala-del-R?o, Ph.D.
> Assistant Professor
> Department of Biology
> University of Puerto Rico at Humacao
> CUH postal station
> 100 road 908
> Humacao, PR 00791
> Ph: 787-850-0000 x 9001
> Fax: 787-850-9439
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From slacey at umich.edu  Fri Mar 18 17:10:59 2005
From: slacey at umich.edu (Steven Lacey)
Date: Fri, 18 Mar 2005 11:10:59 -0500
Subject: [R] slow computation of mixed ANOVA using aov 
Message-ID: <000601c52bd5$1957cca0$6700a8c0@lsa.adsroot.itcs.umich.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050318/54f04af5/attachment.pl

From 0034058 at fudan.edu.cn  Fri Mar 18 16:44:44 2005
From: 0034058 at fudan.edu.cn (ronggui)
Date: Fri, 18 Mar 2005 23:44:44 +0800
Subject: [R] Non linear modeling
In-Reply-To: <3A822319EB35174CA3714066D590DCD50994E88F@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50994E88F@usrymx25.merck.com>
Message-ID: <20050318234444.69034b86.0034058@fudan.edu.cn>

then is the nls function can deal the problem as Guillaume STORCHI mentioned in the last post? [X<-nls(y~x+exp(a*x)*eps, data=,start=list(a=,eps=))]
or just can solve the problem as:log(y-x) = a*x + e?



On Fri, 18 Mar 2005 08:56:38 -0500
"Liaw, Andy" <andy_liaw at merck.com> wrote:

> AFAIK most model fitting techniques will only deal with additive errors, not
> multiplicative ones.  You might want to try fitting:
> 
> log(y-x) = a*x + e
> 
> which is linear.
> 
> Andy
> 
> > From: Angelo Secchi
> > 
> > Hi,
> > is there a way  in R to fit a non linear model like
> > 
> > y=x+exp(a*x)*eps
> > 
> > where a is the parameter and eps is the error term? 
> > Thanks
> > Angelo
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Fri Mar 18 17:21:12 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 18 Mar 2005 11:21:12 -0500
Subject: [R] Non linear modeling
Message-ID: <3A822319EB35174CA3714066D590DCD50994E894@usrymx25.merck.com>

That's treating eps as a parameter in the model.  If I read your question
right, that's not what you want.  

Andy

> From: ronggui [mailto:0034058 at fudan.edu.cn] 
> 
> then is the nls function can deal the problem as Guillaume 
> STORCHI mentioned in the last post? [X<-nls(y~x+exp(a*x)*eps, 
> data=,start=list(a=,eps=))]
> or just can solve the problem as:log(y-x) = a*x + e?
> 
> 
> 
> On Fri, 18 Mar 2005 08:56:38 -0500
> "Liaw, Andy" <andy_liaw at merck.com> wrote:
> 
> > AFAIK most model fitting techniques will only deal with 
> additive errors, not
> > multiplicative ones.  You might want to try fitting:
> > 
> > log(y-x) = a*x + e
> > 
> > which is linear.
> > 
> > Andy
> > 
> > > From: Angelo Secchi
> > > 
> > > Hi,
> > > is there a way  in R to fit a non linear model like
> > > 
> > > y=x+exp(a*x)*eps
> > > 
> > > where a is the parameter and eps is the error term? 
> > > Thanks
> > > Angelo
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> > > http://www.R-project.org/posting-guide.html
> > > 
> > > 
> > >
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From Ted.Harding at nessie.mcc.ac.uk  Fri Mar 18 17:17:12 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 18 Mar 2005 16:17:12 -0000 (GMT)
Subject: [R] How to create a 'fit' plot
In-Reply-To: <20050318151806.58932.qmail@web61304.mail.yahoo.com>
Message-ID: <XFMail.050318161712.Ted.Harding@nessie.mcc.ac.uk>

On 18-Mar-05 R_xprt_wannabe wrote:
> Dear List,
> 
> As someone who is in the process of trying to migrate
> from Excel, I'd appreciate any help on this question:
> 
> I have a data set and want to fit, say, three
> distributions to it.  I would like to create a plot
> that shows my data points against all three fitted
> curves (estimated d.f.).  Basically, I lookint to
> creat a plot that looks like the one presented in the
> attached paper (Figure 5, page 12):
> 
> http://www.math.ethz.ch/~mcneil/ftp/astin.pdf
> 
> 
> Could you please show me, or point me to example code
> showing, how that can be done?  

You can do something on the lines of:

  plot(x,empDF,pch=".") ## for the empirical plot of x

  lines(x0,GPD,lty="solid") ## for the GPD curve

  lines(x0,Pareto,lty="dashed") ## for the Pareto curve

  lines(x0,LogNormal,lty="dotdash") ## for the LogNormal curve

where x0 is a vector of (fairly finely spaced) x-values,
and LogNormal, Pareto and GPD are the corresponding y-values
(at each x0) for the corresponding curves.

Or the latter could be functions which computed the y-values,
given the x-values, in which case you might use

  lines(x0,GPD(x0),lty="solid") ## for the GPD curve

etc.

Since you're apparently beginning with R, you've encountered
one of the more deeply buried (yet commonly required) aspects
of R, namely how the details of a plot are set up.

You can consult the help on 'plot' and 'lines' with

  ?plot
  ?lines

but it takes a bit of poking around to find that you need to
look up

  ?par

to find the details of things like 'lty' as used above.

You may also need to make sure that you get the axes spanning
over good ranges by making your first command

  plot(x,estDF,pch=".",xlim=c(a,b),ylim=c(c,d))

where a and b are the lower and upper limits for x, and c and d
are those for y, since otherwise 'plot' will choose these limits
in its own way depending on the ranges of values in x and in empDF,
which may not be suitable for proper display of the other graphs.
You can omit either or both of 'xlim' and 'ylim'.

Whatever you do about the limits, however, they will be fixed
once and for all once the first plot has been drawn.

Hoping this helps,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 18-Mar-05                                       Time: 16:17:12
------------------------------ XFMail ------------------------------



From 0034058 at fudan.edu.cn  Fri Mar 18 17:23:57 2005
From: 0034058 at fudan.edu.cn (ronggui)
Date: Sat, 19 Mar 2005 00:23:57 +0800
Subject: [R] glm - poisson
In-Reply-To: <20050317232203.3402.qmail@web81405.mail.yahoo.com>
References: <20050317232203.3402.qmail@web81405.mail.yahoo.com>
Message-ID: <20050319002357.22a30ec3.0034058@fudan.edu.cn>

i think that is ok.
"when a response count n(i) has index equal to t(i),the sample rate is n(i)/t(i),its expected value is u(i)/t(i)......a loglinear model for theexpeted rate has form log(u(i)/t(i))=a+bx"(agresti,2002)
this model can use glm-poisson with a offset term to estimate

On Thu, 17 Mar 2005 15:22:02 -0800 (PST)
Oli <olilili at yahoo.com> wrote:

> Hello,
> 
> I have a question on glm - poisson. I would like to
> fit a model on proportion of counts with some factors,
> and I decided to use glm - poisson because count data
> is essentially related to poisson. However, since I
> need to deal with proportion, and glm - poisson does
> not allow non-integer responses, I am thinking of
> adding an offset term = log(total). Is it the right
> approach to it? or should I use quasi-poisson family,
> or should I even use weights?
> 
> Thanks for your help!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From pekka_vimpari at yahoo.com  Fri Mar 18 17:32:11 2005
From: pekka_vimpari at yahoo.com (Pekka Vimpari)
Date: Fri, 18 Mar 2005 08:32:11 -0800 (PST)
Subject: [R] Bivariate normal distribution and correlation
Message-ID: <20050318163211.46898.qmail@web53205.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050318/642eafc6/attachment.pl

From antho_l at yahoo.com  Fri Mar 18 17:36:02 2005
From: antho_l at yahoo.com (Anthony Landrevie)
Date: Fri, 18 Mar 2005 08:36:02 -0800 (PST)
Subject: [R] Pb with ks.test pvalue
Message-ID: <20050318163602.84641.qmail@web41129.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050318/65e9f27c/attachment.pl

From jvega at banxico.org.mx  Fri Mar 18 17:57:58 2005
From: jvega at banxico.org.mx (=?iso-8859-1?Q?De_la_Vega_G=F3ngora_Jorge?=)
Date: Fri, 18 Mar 2005 10:57:58 -0600
Subject: [R] Basic questions about RMySQL
Message-ID: <F74A1EABDCCFFB4893FD93C96408F58A06791881@BMCORREO.banxico.org.mx>

Hello,

Please forget me if I am asking something that is well documented. I have read documentation but there are points that are not clear for me. I am not expert in R nor Databases, but if someone direct me to a tutorial, I will appreciate it..

 1. In my understanding, I can install and use RMySQL withouth having to install MySQL in my PC, to have access to and to create new tables . Is this right? 

 2. I have created a c:\my.cnf file to access a database I have, but withouth installing the server, where I can define the user, password and host to establish a connection?

Thanks in advance


-------------------------------------------------------------------
Jorge de la Vega Gongora             | Telefono: (525) 5268 8379
Investigador                         | Fax:      (525) 5268 8481
Banco de Mexico                      | email:  jvega at banxico.org.mx
Planeaci?n y Programaci?n de Emisi?n | web:    http://www.stat.umn.edu/~jvega
Calzada Legaria 691 M?dulo IV        |
Col. Irrigaci?n 11500                |



From jeroschh at ohsu.edu  Fri Mar 18 18:27:55 2005
From: jeroschh at ohsu.edu (Michael Jerosch-Herold)
Date: Fri, 18 Mar 2005 09:27:55 -0800
Subject: [R] lme user-defined correlation structures??
Message-ID: <s23a9f2d.097@ohsu.edu>

Could somebody help with the definition of new correlation structure for use with a linear mixed-effects model (package nlme). Specifically, I want to define a Toeplitz type correlation structure, but due to my inexperience with programming in R, I feel a bit overwhelmed with the task at hand.

I understand that you can start with a function like corAR1 as template, but I have no idea how I would define the methods (coef, corMatrix, and initialize) in this context.

An example of code for a user-defined correlation structure would be very helpful.

I did a search on Google and in the R-help archives, but have not found much in terms of hints and specific examples for user defined correlation structures.

Thank you in advance!

Michael Jerosch-Herold



From darrenleeweber at gmail.com  Fri Mar 18 18:45:55 2005
From: darrenleeweber at gmail.com (Darren Weber)
Date: Fri, 18 Mar 2005 09:45:55 -0800
Subject: [R] RSPython
Message-ID: <d2095b8c0503180945603172e0@mail.gmail.com>

Hi,

where is the latest version of the RSPython library?  Is it compatible
with the current stable release of R?

Thanks, Darren



From subianto at cs.uu.nl  Fri Mar 18 18:51:37 2005
From: subianto at cs.uu.nl (Muhammad Subianto)
Date: Fri, 18 Mar 2005 18:51:37 +0100
Subject: [R] How to show which variables include in plot of classification
	tree
Message-ID: <423B1529.1040008@cs.uu.nl>

Dear all
For my research, I am learning classification now.
I was trying some example about classification tree pakages, such as 
tree and rpart, for instance,
in Pima.te dataset have 8 variables (include class=type):

library(rpart)
library(datasets)
pima.rpart <- rpart(type ~ npreg+glu+bp+skin+bmi+ped+age,data=Pima.te, 
method='class')
plot(pima.rpart, uniform=TRUE)
text(pima.rpart)
summary(pima.rpart)

In the result I found only 5 variables: npreg, glu,  bmi, ped, and age 
were showing in the plot.
Now, I have 50 variables in my dataset. The result my classification 
tree very difficult to know which
variables showing in the plot. Are there any trick which variables are 
showing in plot.

Thanks for your help.
Muhammad Subianto



From tiago17 at socrates.Berkeley.EDU  Fri Mar 18 19:21:44 2005
From: tiago17 at socrates.Berkeley.EDU (Tiago R Magalhaes)
Date: Fri, 18 Mar 2005 10:21:44 -0800
Subject: [R] extract rows in dataframe with duplicated column values
In-Reply-To: <1111117578.10293.105.camel@horizons.localdomain>
References: <3A822319EB35174CA3714066D590DCD50994E889@usrymx25.merck.com>
	<1111117578.10293.105.camel@horizons.localdomain>
Message-ID: <p0610050ebe60c8940742@[192.168.1.102]>

Thank you very much to Andy Liaw, Rob J Goedman and Marc Schwartz for 
taking their time to solve my problem. I've learned in many other 
occasions from useful tips coming from all 3 of them and it just 
happened once again. You got to love this mailing list...

subset(x, a %in% a[duplicated(a)])

works in all cases and it's the simplest, but as always all the 
solutions made me understand a little better the R concepts and 
functions.

I would suggest to include this in the help pages for duplicated.
Also useful might be:

subset(x, !a %in% a[duplicated(a)])

giving all rows that don't have any duplicated

again thanks for all help in this mailing list


>Here's one more possibility:
>
>  > subset(x, a %in% a[duplicated(a)])
>   a  b
>2 2 10
>3 2 10
>4 3 10
>5 3 10
>6 3 10
>
>HTH,
>
>Marc Schwartz
>
>
>On Thu, 2005-03-17 at 22:25 -0500, Liaw, Andy wrote:
>>  OK, strike one...
>>
>>  Here's my second try:
>>
>>  > cnt <- table(x[,1])
>>  > v <- as.numeric(names(cnt[cnt > 1]))
>>  > v
>>  [1] 2 3
>>  > x[x[,1] %in% v, ]
>>    a  b
>>  2 2 10
>>  3 2 10
>>  4 3 10
>>  5 3 10
>>  6 3 10
>>
>>  Andy
>>
>>  > From: Liaw, Andy
>>  >
>>  > Does this work for you?
>>  >
>>  > > x[table(x[,1]) > 1,]
>>  >   a  b
>>  > 2 2 10
>>  > 3 2 10
>>  > 5 3 10
>>  > 6 3 10
>>  >
>>  > Andy
>>  >
>>  > > From: Tiago R Magalhaes
>>  > >
>>  > > Hi
>>  > >
>>  > > I want to extract all the rows in a data frame that have duplicates
>>  > > for a given column.
>>  > > I would expect this question to come up pretty often but I have
>>  > > researched the archives and surprisingly couldn't find anything.
>>  > > The best I can come up with is:
>>  > >
>>  > > x <- data.frame(a=c(1,2,2,3,3,3), b=10)
>>  > > xdup1 <- duplicated(x[,1])
>>  > > xdup2 <- duplicated(x[,1][nrow(x):1])[nrow(x):1]
>>  > > xAllDups <- x[(xdup1+xdup2)!=0,]
>>  > >
>>  > > This seems to work, but it's so convoluted that I'm sure there's a
>>  > > better method.
>>  > > Thanks for any help and enlightenment
>  > > >	[[alternative HTML version deleted]]



From br44114 at yahoo.com  Fri Mar 18 19:39:36 2005
From: br44114 at yahoo.com (bogdan romocea)
Date: Fri, 18 Mar 2005 10:39:36 -0800 (PST)
Subject: [R] Basic questions about RMySQL
Message-ID: <20050318183936.32072.qmail@web50106.mail.yahoo.com>

1. No way. You must have MySQL installed on your computer.

2. You must install the server. For details, see
http://dev.mysql.com/doc/mysql/en/index.html . 
For portability, I would suggest that you run MySQL in the shell
(ignore the GUIs) and save the syntax for adding users, creating tables
etc. This will likely take more time when you first do it, but if you
have to move to another computer later on, you can setup the new MySQL
installation very quickly and easily.

hth,
b.


-----Original Message-----
From: De la Vega Gngora Jorge [mailto:jvega at banxico.org.mx]
Sent: Friday, March 18, 2005 11:58 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Basic questions about RMySQL


Hello,

Please forget me if I am asking something that is well documented. I
have read documentation but there are points that are not clear for me.
I am not expert in R nor Databases, but if someone direct me to a
tutorial, I will appreciate it..

 1. In my understanding, I can install and use RMySQL withouth having
to install MySQL in my PC, to have access to and to create new tables .
Is this right? 

 2. I have created a c:\my.cnf file to access a database I have, but
withouth installing the server, where I can define the user, password
and host to establish a connection?

Thanks in advance


-------------------------------------------------------------------
Jorge de la Vega Gongora             | Telefono: (525) 5268 8379
Investigador                         | Fax:      (525) 5268 8481
Banco de Mexico                      | email:  jvega at banxico.org.mx
Planeacin y Programacin de Emisin | web:   
http://www.stat.umn.edu/~jvega
Calzada Legaria 691 Mdulo IV        |
Col. Irrigacin 11500                |

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Fri Mar 18 19:40:13 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 18 Mar 2005 19:40:13 +0100
Subject: [R] RSPython
In-Reply-To: <d2095b8c0503180945603172e0@mail.gmail.com>
References: <d2095b8c0503180945603172e0@mail.gmail.com>
Message-ID: <423B208D.5000408@statistik.uni-dortmund.de>

Darren Weber wrote:

> Hi,
> 
> where is the latest version of the RSPython library?  Is it compatible
> with the current stable release of R?

What about clicking the first item returned when Google'ing for "RSPython"?

Uwe Ligges



> 
> Thanks, Darren
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From br44114 at yahoo.com  Fri Mar 18 19:42:55 2005
From: br44114 at yahoo.com (bogdan romocea)
Date: Fri, 18 Mar 2005 10:42:55 -0800 (PST)
Subject: [R] Basic questions about RMySQL
In-Reply-To: 6667
Message-ID: <20050318184256.77020.qmail@web50109.mail.yahoo.com>

> 1. No way. You must have MySQL installed on your computer.

In fact this is not true. You can use a MySQL server installed
somewhere else on the network.



--- bogdan romocea <br44114 at yahoo.com> wrote:
> 1. No way. You must have MySQL installed on your computer.
> 
> 2. You must install the server. For details, see
> http://dev.mysql.com/doc/mysql/en/index.html . 
> For portability, I would suggest that you run MySQL in the shell
> (ignore the GUIs) and save the syntax for adding users, creating
> tables
> etc. This will likely take more time when you first do it, but if you
> have to move to another computer later on, you can setup the new
> MySQL
> installation very quickly and easily.
> 
> hth,
> b.
> 
> 
> -----Original Message-----
> From: De la Vega Gngora Jorge [mailto:jvega at banxico.org.mx]
> Sent: Friday, March 18, 2005 11:58 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Basic questions about RMySQL
> 
> 
> Hello,
> 
> Please forget me if I am asking something that is well documented. I
> have read documentation but there are points that are not clear for
> me.
> I am not expert in R nor Databases, but if someone direct me to a
> tutorial, I will appreciate it..
> 
>  1. In my understanding, I can install and use RMySQL withouth having
> to install MySQL in my PC, to have access to and to create new tables
> .
> Is this right? 
> 
>  2. I have created a c:\my.cnf file to access a database I have, but
> withouth installing the server, where I can define the user, password
> and host to establish a connection?
> 
> Thanks in advance
> 
> 
> -------------------------------------------------------------------
> Jorge de la Vega Gongora             | Telefono: (525) 5268 8379
> Investigador                         | Fax:      (525) 5268 8481
> Banco de Mexico                      | email:  jvega at banxico.org.mx
> Planeacin y Programacin de Emisin | web:   
> http://www.stat.umn.edu/~jvega
> Calzada Legaria 691 Mdulo IV        |
> Col. Irrigacin 11500                |
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> 
> __________________________________ 
> 


From ligges at statistik.uni-dortmund.de  Fri Mar 18 19:45:41 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 18 Mar 2005 19:45:41 +0100
Subject: [R] How to show which variables include in plot of classification
	tree
In-Reply-To: <423B1529.1040008@cs.uu.nl>
References: <423B1529.1040008@cs.uu.nl>
Message-ID: <423B21D5.4090205@statistik.uni-dortmund.de>

Muhammad Subianto wrote:

> Dear all
> For my research, I am learning classification now.
> I was trying some example about classification tree pakages, such as 
> tree and rpart, for instance,
> in Pima.te dataset have 8 variables (include class=type):
> 
> library(rpart)
> library(datasets)
> pima.rpart <- rpart(type ~ npreg+glu+bp+skin+bmi+ped+age,data=Pima.te, 
> method='class')
> plot(pima.rpart, uniform=TRUE)
> text(pima.rpart)
> summary(pima.rpart)
> 
> In the result I found only 5 variables: npreg, glu,  bmi, ped, and age 
> were showing in the plot.
> Now, I have 50 variables in my dataset. The result my classification 
> tree very difficult to know which
> variables showing in the plot. Are there any trick which variables are 
> showing in plot.


1. Please read a good book on classification. Also, you might want to 
take a look into Breiman et al. (1984) cited in ?rpart.

2. rpart does variable selection when growing the tree, so you should 
not expect to find all 50 variables in the plot. See, e.g.,  ?rpart.control

3. You have specified the formula "type ~ npreg + glu + bp + skin + bmi 
+ ped + age", so in particular you cannot expect to get more variables 
than "npreg + glu + bp + skin + bmi + ped + age"

Uwe Ligges






> Thanks for your help.
> Muhammad Subianto
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Fri Mar 18 19:47:59 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 18 Mar 2005 19:47:59 +0100
Subject: [R] Basic questions about RMySQL
In-Reply-To: <20050318183936.32072.qmail@web50106.mail.yahoo.com>
References: <20050318183936.32072.qmail@web50106.mail.yahoo.com>
Message-ID: <423B225F.6030503@statistik.uni-dortmund.de>

bogdan romocea wrote:

> 1. No way. You must have MySQL installed on your computer.
> 
> 2. You must install the server. For details, see
> http://dev.mysql.com/doc/mysql/en/index.html . 
> For portability, I would suggest that you run MySQL in the shell
> (ignore the GUIs) and save the syntax for adding users, creating tables
> etc. This will likely take more time when you first do it, but if you
> have to move to another computer later on, you can setup the new MySQL
> installation very quickly and easily.

Can you tell us any reason why the server should run on the same machine 
R is running on?

Uwe Ligges


> hth,
> b.
> 
> 
> -----Original Message-----
> From: De la Vega G?ngora Jorge [mailto:jvega at banxico.org.mx]
> Sent: Friday, March 18, 2005 11:58 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Basic questions about RMySQL
> 
> 
> Hello,
> 
> Please forget me if I am asking something that is well documented. I
> have read documentation but there are points that are not clear for me.
> I am not expert in R nor Databases, but if someone direct me to a
> tutorial, I will appreciate it..
> 
>  1. In my understanding, I can install and use RMySQL withouth having
> to install MySQL in my PC, to have access to and to create new tables .
> Is this right? 
> 
>  2. I have created a c:\my.cnf file to access a database I have, but
> withouth installing the server, where I can define the user, password
> and host to establish a connection?
> 
> Thanks in advance
> 
> 
> -------------------------------------------------------------------
> Jorge de la Vega Gongora             | Telefono: (525) 5268 8379
> Investigador                         | Fax:      (525) 5268 8481
> Banco de Mexico                      | email:  jvega at banxico.org.mx
> Planeaci?n y Programaci?n de Emisi?n | web:   
> http://www.stat.umn.edu/~jvega
> Calzada Legaria 691 M?dulo IV        |
> Col. Irrigaci?n 11500                |
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From secchi at sssup.it  Fri Mar 18 21:07:21 2005
From: secchi at sssup.it (Angelo Secchi)
Date: Fri, 18 Mar 2005 20:07:21 +0000
Subject: [R] Non linear modeling
In-Reply-To: <3A822319EB35174CA3714066D590DCD50994E894@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50994E894@usrymx25.merck.com>
Message-ID: <20050318200721.57ac0cb1.secchi@sssup.it>


You are right. eps in my model is not a parameter but the error term.
Also the linearization doesn't solve the problem, since sometimes you
cannot take logs. Any other ideas?
Thanks


On Fri, 18 Mar 2005 11:21:12 -0500
"Liaw, Andy" <andy_liaw at merck.com> wrote:

> That's treating eps as a parameter in the model.  If I read your question
> right, that's not what you want.  
> 
> Andy
> 
> > From: ronggui [mailto:0034058 at fudan.edu.cn] 
> > 
> > then is the nls function can deal the problem as Guillaume 
> > STORCHI mentioned in the last post? [X<-nls(y~x+exp(a*x)*eps, 
> > data=,start=list(a=,eps=))]
> > or just can solve the problem as:log(y-x) = a*x + e?
> > 
> > 
> > 
> > On Fri, 18 Mar 2005 08:56:38 -0500
> > "Liaw, Andy" <andy_liaw at merck.com> wrote:
> > 
> > > AFAIK most model fitting techniques will only deal with 
> > additive errors, not
> > > multiplicative ones.  You might want to try fitting:
> > > 
> > > log(y-x) = a*x + e
> > > 
> > > which is linear.
> > > 
> > > Andy
> > > 
> > > > From: Angelo Secchi
> > > > 
> > > > Hi,
> > > > is there a way  in R to fit a non linear model like
> > > > 
> > > > y=x+exp(a*x)*eps
> > > > 
> > > > where a is the parameter and eps is the error term? 
> > > > Thanks
> > > > Angelo
> > > > 
> > > > ______________________________________________
> > > > R-help at stat.math.ethz.ch mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide! 
> > > > http://www.R-project.org/posting-guide.html
> > > > 
> > > > 
> > > >
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> > 
> > 
> 
> 
> 
> ------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any attachment...{{dropped}}



From br44114 at yahoo.com  Fri Mar 18 20:10:37 2005
From: br44114 at yahoo.com (bogdan romocea)
Date: Fri, 18 Mar 2005 11:10:37 -0800 (PST)
Subject: [R] Basic questions about RMySQL
In-Reply-To: 6667
Message-ID: <20050318191037.43483.qmail@web50106.mail.yahoo.com>

I certainly can't; I initially misunderstood the question.

If connecting to MySQL is the problem, then you need to know the user
ID, the domain and the password. Ask your DB administrator for help.

Here's an example that works for me (local MySQL installation):
require(DBI)
require(RMySQL)
MySQL(max.con = 16, fetch.default.rec = 5000, force.reload = F)
drv <- dbDriver("MySQL")
con <- dbConnect(drv,username="userid",password="pswd",dbname="db")
dbListTables(con)



--- Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:
> bogdan romocea wrote:
> 
> > 1. No way. You must have MySQL installed on your computer.
> > 
> > 2. You must install the server. For details, see
> > http://dev.mysql.com/doc/mysql/en/index.html . 
> > For portability, I would suggest that you run MySQL in the shell
> > (ignore the GUIs) and save the syntax for adding users, creating
> tables
> > etc. This will likely take more time when you first do it, but if
> you
> > have to move to another computer later on, you can setup the new
> MySQL
> > installation very quickly and easily.
> 
> Can you tell us any reason why the server should run on the same
> machine 
> R is running on?
> 
> Uwe Ligges
> 
> 
> > hth,
> > b.
> > 
> > 
> > -----Original Message-----
> > From: De la Vega Gngora Jorge [mailto:jvega at banxico.org.mx]
> > Sent: Friday, March 18, 2005 11:58 AM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] Basic questions about RMySQL
> > 
> > 
> > Hello,
> > 
> > Please forget me if I am asking something that is well documented.
> I
> > have read documentation but there are points that are not clear for
> me.
> > I am not expert in R nor Databases, but if someone direct me to a
> > tutorial, I will appreciate it..
> > 
> >  1. In my understanding, I can install and use RMySQL withouth
> having
> > to install MySQL in my PC, to have access to and to create new
> tables .
> > Is this right? 
> > 
> >  2. I have created a c:\my.cnf file to access a database I have,
> but
> > withouth installing the server, where I can define the user,
> password
> > and host to establish a connection?
> > 
> > Thanks in advance
> > 
> > 
> > -------------------------------------------------------------------
> > Jorge de la Vega Gongora             | Telefono: (525) 5268 8379
> > Investigador                         | Fax:      (525) 5268 8481
> > Banco de Mexico                      | email:  jvega at banxico.org.mx
> > Planeacin y Programacin de Emisin | web:   
> > http://www.stat.umn.edu/~jvega
> > Calzada Legaria 691 Mdulo IV        |
> > Col. Irrigacin 11500                |
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
>



From jvega at banxico.org.mx  Fri Mar 18 20:15:01 2005
From: jvega at banxico.org.mx (=?iso-8859-1?Q?De_la_Vega_G=F3ngora_Jorge?=)
Date: Fri, 18 Mar 2005 13:15:01 -0600
Subject: [R] Basic questions about RMySQL
Message-ID: <F74A1EABDCCFFB4893FD93C96408F58A067A982D@BMCORREO.banxico.org.mx>

Thanks for your help. having MySQL server locally (or in some other place) should solve the configuration problem. 


By the way, I should have written forgive, no forget. Forgive me.

Jorge de la Vega
 

-----Mensaje original-----
De: bogdan romocea [mailto:br44114 at yahoo.com] 
Enviado el: Viernes, 18 de Marzo de 2005 01:11 PM
Para: Uwe Ligges; De la Vega G?ngora Jorge
CC: r-help at stat.math.ethz.ch
Asunto: Re: [R] Basic questions about RMySQL


I certainly can't; I initially misunderstood the question.

If connecting to MySQL is the problem, then you need to know the user ID, the domain and the password. Ask your DB administrator for help.

Here's an example that works for me (local MySQL installation):
require(DBI)
require(RMySQL)
MySQL(max.con = 16, fetch.default.rec = 5000, force.reload = F) drv <- dbDriver("MySQL") con <- dbConnect(drv,username="userid",password="pswd",dbname="db")
dbListTables(con)



--- Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:
> bogdan romocea wrote:
> 
> > 1. No way. You must have MySQL installed on your computer.
> > 
> > 2. You must install the server. For details, see 
> > http://dev.mysql.com/doc/mysql/en/index.html . For portability, I 
> > would suggest that you run MySQL in the shell (ignore the GUIs) and 
> > save the syntax for adding users, creating
> tables
> > etc. This will likely take more time when you first do it, but if
> you
> > have to move to another computer later on, you can setup the new
> MySQL
> > installation very quickly and easily.
> 
> Can you tell us any reason why the server should run on the same 
> machine R is running on?
> 
> Uwe Ligges
> 
> 
> > hth,
> > b.
> > 
> > 
> > -----Original Message-----
> > From: De la Vega G?ngora Jorge [mailto:jvega at banxico.org.mx]
> > Sent: Friday, March 18, 2005 11:58 AM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] Basic questions about RMySQL
> > 
> > 
> > Hello,
> > 
> > Please forget me if I am asking something that is well documented.
> I
> > have read documentation but there are points that are not clear for
> me.
> > I am not expert in R nor Databases, but if someone direct me to a 
> > tutorial, I will appreciate it..
> > 
> >  1. In my understanding, I can install and use RMySQL withouth
> having
> > to install MySQL in my PC, to have access to and to create new
> tables .
> > Is this right?
> > 
> >  2. I have created a c:\my.cnf file to access a database I have,
> but
> > withouth installing the server, where I can define the user,
> password
> > and host to establish a connection?
> > 
> > Thanks in advance
> > 
> > 
> > -------------------------------------------------------------------
> > Jorge de la Vega Gongora             | Telefono: (525) 5268 8379
> > Investigador                         | Fax:      (525) 5268 8481
> > Banco de Mexico                      | email:  jvega at banxico.org.mx
> > Planeaci?n y Programaci?n de Emisi?n | web:   
> > http://www.stat.umn.edu/~jvega
> > Calzada Legaria 691 M?dulo IV        |
> > Col. Irrigaci?n 11500                |
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> 


		
__________________________________ 



From spencer.graves at pdf.com  Fri Mar 18 20:35:38 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 18 Mar 2005 11:35:38 -0800
Subject: [R] Non linear modeling
In-Reply-To: <20050318200721.57ac0cb1.secchi@sssup.it>
References: <3A822319EB35174CA3714066D590DCD50994E894@usrymx25.merck.com>
	<20050318200721.57ac0cb1.secchi@sssup.it>
Message-ID: <423B2D8A.4050306@pdf.com>

      What do you want to minimize?  Can you write a function to compute 
eps given x, y, and a?  Given that, you can then write another function 
to compute the objective function you want to minimize.  If "a" is a 
scalar, compute the objective function for a range of values of "a" and 
plot.  If you want numerical precision, read the help file for "optim", 
work the examples until you understand enough to see how to feed your 
objective function with a starting value to "optim". 

      If you still can't figure it out, please make an attempt, then 
read the posting guide "http://www.R-project.org/posting-guide.html", 
and prepare a follow-up question as needed.  (In a discussion on and off 
this list earlier this week, several people confirmed that they had 
solved many problems following this posting guide.  It may not be as 
good as Polya's famous "How to Solve It", but it's pretty good.)

      hope this helps. 
      spencer graves

Angelo Secchi wrote:

>You are right. eps in my model is not a parameter but the error term.
>Also the linearization doesn't solve the problem, since sometimes you
>cannot take logs. Any other ideas?
>Thanks
>
>
>On Fri, 18 Mar 2005 11:21:12 -0500
>"Liaw, Andy" <andy_liaw at merck.com> wrote:
>
>  
>
>>That's treating eps as a parameter in the model.  If I read your question
>>right, that's not what you want.  
>>
>>Andy
>>
>>    
>>
>>>From: ronggui [mailto:0034058 at fudan.edu.cn] 
>>>
>>>then is the nls function can deal the problem as Guillaume 
>>>STORCHI mentioned in the last post? [X<-nls(y~x+exp(a*x)*eps, 
>>>data=,start=list(a=,eps=))]
>>>or just can solve the problem as:log(y-x) = a*x + e?
>>>
>>>
>>>
>>>On Fri, 18 Mar 2005 08:56:38 -0500
>>>"Liaw, Andy" <andy_liaw at merck.com> wrote:
>>>
>>>      
>>>
>>>>AFAIK most model fitting techniques will only deal with 
>>>>        
>>>>
>>>additive errors, not
>>>      
>>>
>>>>multiplicative ones.  You might want to try fitting:
>>>>
>>>>log(y-x) = a*x + e
>>>>
>>>>which is linear.
>>>>
>>>>Andy
>>>>
>>>>        
>>>>
>>>>>From: Angelo Secchi
>>>>>
>>>>>Hi,
>>>>>is there a way  in R to fit a non linear model like
>>>>>
>>>>>y=x+exp(a*x)*eps
>>>>>
>>>>>where a is the parameter and eps is the error term? 
>>>>>Thanks
>>>>>Angelo
>>>>>
>>>>>______________________________________________
>>>>>R-help at stat.math.ethz.ch mailing list
>>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>PLEASE do read the posting guide! 
>>>>>http://www.R-project.org/posting-guide.html
>>>>>
>>>>>
>>>>>
>>>>>          
>>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide! 
>>>>        
>>>>
>>>http://www.R-project.org/posting-guide.html
>>>
>>>
>>>
>>>      
>>>
>>
>>------------------------------------------------------------------------------
>>Notice:  This e-mail message, together with any attachment...{{dropped}}
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From spencer.graves at pdf.com  Fri Mar 18 20:36:13 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 18 Mar 2005 11:36:13 -0800
Subject: [R] Bivariate normal distribution and correlation
In-Reply-To: <20050318163211.46898.qmail@web53205.mail.yahoo.com>
References: <20050318163211.46898.qmail@web53205.mail.yahoo.com>
Message-ID: <423B2DAD.7080707@pdf.com>

      How about the following: 

      Suppose you have the bivariate cumulative distribution function 
(cdf) for (X, Y). 

      1.  From this first compute the marginal cdf for X.  The median 
will give you EX, and you can get sigmaX = IQR/(2*qnorm(0.75)), where 
IQR = interquartile range = diff(quantile(..., c(0.25, 0.75))).  Repeat 
to get EY and sigmaY. 

      2.  Next compute the median of the conditional distribution for Y 
given X = (EX+sigmaX).  This is E(Y|X=EX+sigmaX) = EY+rho*sigmaY.  [The 
regression equation is E(Y|x) = EY + rho*(x-EX)*sigmaY/sigmaX, and 
(x-EX) = sigmaX by choice.]  From this, you can now solve for rho.  You 
may also wish to repeat this for EX-sigmaX as a check. 

      If you have trouble translating this into R code, please make an 
attempt, then read the posting guide 
"http://www.R-project.org/posting-guide.html", and prepare a follow-up 
question as needed.  (In a discussion on and off this list earlier this 
week, several people confirmed that they had solved many problems 
following this posting guide.  It may not be as good as Polya's famous 
"How to Solve It", but it's pretty good.) 

      hope this helps. 
      spencer
 
Pekka Vimpari wrote:

>Suppose I know the value of cumulative bivariate standard normal distribution. How can I solve correlation between variables?
>
> 
>
>Pekka
>
>
>		
>---------------------------------
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From ramasamy at cancer.org.uk  Fri Mar 18 20:44:33 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Fri, 18 Mar 2005 19:44:33 +0000
Subject: [R] How to create a 'fit' plot
In-Reply-To: <20050318151806.58932.qmail@web61304.mail.yahoo.com>
References: <20050318151806.58932.qmail@web61304.mail.yahoo.com>
Message-ID: <1111175073.7251.107.camel@ndmpc126.orc.ox.ac.uk>

If you know the exact formulae for the distribution, replace it with 'f'
function below. You may want to use the log="x" in the plot.

 f <- function(x) 1 - exp( -x/20 ); 
 plot( f, xlim=c(0,100), ylim=c(0.5, 1) )


Otherwise generate sufficient realisations from it and fit a line as
below

 x <- seq(-5,5,by=0.01)
 y <- dt(x, 5)
 plot( x, y, type="l", col=8 )


Now you can overlay the observations as points

 obs.x <- rnorm(50)
 obs.y <- runif(50)
 points( obs.x, obs.y, pch=18)

You might want to see help("plot"), help("par") or demo(graphics) as
well as http://www.r-project.org/other-docs.html

Regards, Adai



On Fri, 2005-03-18 at 07:18 -0800, R_xprt_wannabe wrote:
> Dear List,
> 
> As someone who is in the process of trying to migrate
> from Excel, I'd appreciate any help on this question:
> 
> I have a data set and want to fit, say, three
> distributions to it.  I would like to create a plot
> that shows my data points against all three fitted
> curves (estimated d.f.).  Basically, I lookint to
> creat a plot that looks like the one presented in the
> attached paper (Figure 5, page 12):
> 
> http://www.math.ethz.ch/~mcneil/ftp/astin.pdf
> 
> 
> Could you please show me, or point me to example code
> showing, how that can be done?  
> 
> Thanks,
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Michaell.Taylor at boxwoodmeans.com  Fri Mar 18 20:46:25 2005
From: Michaell.Taylor at boxwoodmeans.com (Michaell Taylor)
Date: Fri, 18 Mar 2005 13:46:25 -0600
Subject: [R] Hmisc & latex
Message-ID: <1111175185.24023.211.camel@localhost>



Hmisc includes a latex function which typesets objects in latex.  A
great time saver.

I am using it to create a large number of tables in a loop in conjuction
with prettyNum to place '000s separators in the numbers (i.e. 1,000,000
not 1000000).  This converts the numbers to strings.  The Hmisc/latex
default is to left justify characters - which doesn't work in this case.

Hmisc/latex seems to have lots of options, but not one that I was
expecting.  I am having trouble specifying column justification.  I can
specify justification for column labels, column label groups, row
labels, even table justification --- but not the justification of the
data within the table. 

I am convinced that I am missing something. Am I? or this just a "yet to
be coded" feature.  Thanks in advance.


Michaell



From mmohebbi at gmail.com  Fri Mar 18 21:09:52 2005
From: mmohebbi at gmail.com (Matt Mohebbi)
Date: Fri, 18 Mar 2005 12:09:52 -0800
Subject: [R] Quantiles of data in a contingency table
In-Reply-To: <42393FDC.6010302@iki.fi>
References: <8181824e0503162342e34c5f3@mail.gmail.com>
	<42393FDC.6010302@iki.fi>
Message-ID: <8181824e0503181209306b06a8@mail.gmail.com>

On Thu, 17 Mar 2005 10:29:16 +0200, Markus J?ntti <markus.jantti at iki.fi> wrote:
> Matt Mohebbi wrote:
> > Hello,
> >
> > I have data of the following form:
> >
> >
> >>data <- data.frame(type=c("c","d","e"), size=c(10,20,30), count=c(20,10,5))
> >>data
> >
> >   type size count
> > 1    c   10    20
> > 2    d   20    10
> > 3    e   30     5
> >
> > I would like to compute the quantiles of size given the counts. For
> > instance, in this example, the median size would be 10. Is there an
> > easy way of doing this?
> 
> One at least is to the function wtd.median [and wtd.quantile] in package
> Hmisc by Frank Harrell.
> 
> install.packages("Hmisc")
> library(Hmisc)
> wtd.median(data$size, data$weights)
> 
> is likely a route to get you what you want.
Thanks. This worked great. 

I now would like to do a boxplot on a subset of this data. One way of
doing this would be to create a repeated entry form of the above data
frame. This would look like:
   type size 
 1    c   10  
 2    c   10  
 3    c   10  
 4    c   10   
 5    c   10    
 6    c   10    
 7    c   10    
 8    c   10    
 9    c   10    
 10    c   10    
 11    c   10  
 12    c   10  
 13    c   10  
 14    c   10   
 15    c   10    
 16    c   10    
 17    c   10    
 18    c   10    
 19    c   10    
 20    c   10    
(and similarly for types d and e)

I cannot seem to find this in R or Hmisc. Any ideas? 

Thanks,
Matt



> regards,
> 
> markus
> >
> > Is there a good way to deal with data in this format in general? Much
> > of R seems to center around having an entry for each item. This
> > question (http://www.r-project.org/nocvs/mail/r-help/2000/0102.html)
> > seems to be related but no one provided an answer.
> >
> > Thanks,
> > Matt
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> 
> --
> Markus Jantti
> Abo Akademi University
> markus.jantti at iki.fi
> http://www.iki.fi/~mjantti
>



From kjetil at acelerate.com  Fri Mar 18 22:00:47 2005
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Fri, 18 Mar 2005 17:00:47 -0400
Subject: [R] Basic questions about RMySQL
In-Reply-To: <F74A1EABDCCFFB4893FD93C96408F58A06791881@BMCORREO.banxico.org.mx>
References: <F74A1EABDCCFFB4893FD93C96408F58A06791881@BMCORREO.banxico.org.mx>
Message-ID: <423B417F.5030708@acelerate.com>

De la Vega G?ngora Jorge wrote:

>Hello,
>
>Please forget me if I am asking something that is well documented. I have read documentation but there are points that are not clear for me. I am not expert in R nor Databases, but if someone direct me to a tutorial, I will appreciate it..
>
> 1. In my understanding, I can install and use RMySQL withouth having to install MySQL in my PC, to have access to and to create new tables . Is this right? 
>  
>
I doubt very mucg if RMySQP will be of any use without having
MySQL installed!

Kjetil


> 2. I have created a c:\my.cnf file to access a database I have, but withouth installing the server, where I can define the user, password and host to establish a connection?
>
>Thanks in advance
>
>
>-------------------------------------------------------------------
>Jorge de la Vega Gongora             | Telefono: (525) 5268 8379
>Investigador                         | Fax:      (525) 5268 8481
>Banco de Mexico                      | email:  jvega at banxico.org.mx
>Planeaci?n y Programaci?n de Emisi?n | web:    http://www.stat.umn.edu/~jvega
>Calzada Legaria 691 M?dulo IV        |
>Col. Irrigaci?n 11500                |
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>


-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra




-- 
No virus found in this outgoing message.
Checked by AVG Anti-Virus.



From muster at gmail.com  Fri Mar 18 22:37:22 2005
From: muster at gmail.com (Terry Mu)
Date: Fri, 18 Mar 2005 16:37:22 -0500
Subject: [R] Is there such a function that can sort a table according to one
	column?
Message-ID: <b68812e7050318133758b5897f@mail.gmail.com>

when I sort one column, other columns will change with it.

otherwise, I can get index from sort() and write a function.

Better idea? Thanks,



From darrenleeweber at gmail.com  Fri Mar 18 22:41:14 2005
From: darrenleeweber at gmail.com (Darren Weber)
Date: Fri, 18 Mar 2005 13:41:14 -0800
Subject: [R] Is a .R script file name available inside the script?
Message-ID: <d2095b8c05031813417660d0e2@mail.gmail.com>

Hi,

if we have a file called Rscript.R that contains the following, for example:

x <- 1:100
outfile = "Rscript.Rout"
sink(outfile)
print(x)

and then we run

>> source("Rscript.R")

we get an output file called Rscript.Rout - great!

Is there an internal variable, something like .Platform, that holds
the script name when it is being executed?  I would like to use that
variable to define the output file name.

Best, Darren



From gunter.berton at gene.com  Fri Mar 18 22:41:22 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Fri, 18 Mar 2005 13:41:22 -0800
Subject: [R] plotmath question
Message-ID: <200503182141.j2ILfNL9021142@hertz.gene.com>

R listers:

I have been foiled by plotmath!

(in R 2.01,Windows 2000)

The task: Plot a normal density and label the ticks as mu - 3 sigma, mu - 2
sigma, ...., mu + 3 sigma, where the mu's and sigmas appear as Greek
symbols, of course.

The following code does this:

x<-seq(-3,to=3,by=.01)
y<-dnorm(x)
plot(x,y,type='h',col='lightblue',axes=FALSE)
lines(x,y,col='darkblue')
axis(2)
for(i in seq(-3,to=3))
	axis(1,at=i, lab=switch(sign(i)+2,
			eval(substitute(expression(mu-j*sigma),list(j=-i))),
			expression(mu),
			eval(substitute(expression(mu+j*sigma),list(j=i)))))
box()

However, I think the code in the for loop is ugly and probably means that
I'm doing it wrong. In particular:

1) Is there a neat way to use one axis() call and a vector (of expressions?)
for the lab=argument?

2) The plotmath Help state that expressions can be used for axis labels, so
I would have expected the above to work without the eval()call  -- but it
does not. Would someone kindly explain to me why not -- i.e., what I have
misunderstood. That is, to be clear, why does the following not work:

for(i in seq(-3,to=3))
	axis(1,at=i, lab=switch(sign(i)+2,
			substitute(expression(mu-j*sigma),list(j=i)),
			expression(mu),
			substitute(expression(mu+j*sigma),list(j=i))))

Any further ideas,insights, or pointers to reference materials would also be
appreciated. Many thanks.


-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box



From andy_liaw at merck.com  Fri Mar 18 22:47:43 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 18 Mar 2005 16:47:43 -0500
Subject: [R] Is there such a function that can sort a table
	according to one column?
Message-ID: <3A822319EB35174CA3714066D590DCD50994E898@usrymx25.merck.com>

See ?order, which is pointed to in the `See Also' section of ?sort.

Andy

> From: Terry Mu
> 
> when I sort one column, other columns will change with it.
> 
> otherwise, I can get index from sort() and write a function.
> 
> Better idea? Thanks,
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From Katharina.Hoff at gmx.net  Fri Mar 18 22:49:32 2005
From: Katharina.Hoff at gmx.net (Katharina Hoff)
Date: Fri, 18 Mar 2005 22:49:32 +0100 (MET)
Subject: [R] Sweave/margin
Message-ID: <9963.1111182572@www73.gmx.net>

Hi!

I am currently using Sweave for writing my bachelor thesis - and I have a
problem:

I am using a LaTeX style (report) with quite big margin spaces. The Sweave
generated LaTeX code "floats" into the margin - and it looks ugly. The text
is blocked and fine... then there comes some flattering code running over
the margin... and blocked text again.

Considering the LaTeX output, I guess that Sweave puts the source code
somehow in LaTeX-boxes and I suppose there is a place where I could change
the width of the source code boxes (At a certain point, there is a break,
closely before the text would drift out of the page. Then the code continues
in new lines below.)

Does anyone know where I could change or insert the box width? 

Or probably I am totally wrong and someone knows another solution...

Hoping for help - and excuse if anyone asked this stupid question before, I
did not find it in the archive,


Katharina Hoff

-- 
DSL Komplett von GMX +++ Supergnstig und stressfrei einsteigen!
AKTION "Kein Einrichtungspreis" nutzen: http://www.gmx.net/de/go/dsl



From HDoran at air.org  Fri Mar 18 22:54:30 2005
From: HDoran at air.org (Doran, Harold)
Date: Fri, 18 Mar 2005 16:54:30 -0500
Subject: [R] Sweave/margin
Message-ID: <88EAF3512A55DF46B06B1954AEF73F7408316F6D@dc1ex2.air.org>

Try a code chunk like this:

<<echo=FALSE>>=
options(width = 70)
@  

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Katharina Hoff
Sent: Friday, March 18, 2005 4:50 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Sweave/margin

Hi!

I am currently using Sweave for writing my bachelor thesis - and I have a
problem:

I am using a LaTeX style (report) with quite big margin spaces. The Sweave generated LaTeX code "floats" into the margin - and it looks ugly. The text is blocked and fine... then there comes some flattering code running over the margin... and blocked text again.

Considering the LaTeX output, I guess that Sweave puts the source code somehow in LaTeX-boxes and I suppose there is a place where I could change the width of the source code boxes (At a certain point, there is a break, closely before the text would drift out of the page. Then the code continues in new lines below.)

Does anyone know where I could change or insert the box width? 

Or probably I am totally wrong and someone knows another solution...

Hoping for help - and excuse if anyone asked this stupid question before, I did not find it in the archive,


Katharina Hoff

--
DSL Komplett von GMX +++ Superg?nstig und stressfrei einsteigen!
AKTION "Kein Einrichtungspreis" nutzen: http://www.gmx.net/de/go/dsl

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From apjaworski at mmm.com  Fri Mar 18 22:58:03 2005
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Fri, 18 Mar 2005 15:58:03 -0600
Subject: [R] plotmath question
In-Reply-To: <200503182141.j2ILfNL9021142@hertz.gene.com>
Message-ID: <OFC5CE6E51.3E4BF09D-ON86256FC8.00787AFD-86256FC8.0078AC1D@mmm.com>






Bert,

This works fine and and seems a little simpler:

x<-seq(-3,to=3,by=.01)
y<-dnorm(x)
plot(x,y,type='h',col='lightblue',axes=FALSE)
lines(x,y,col='darkblue')
axis(2)

ll <- expression(mu-3*sigma, mu-2*sigma, mu-sigma, mu, mu+sigma,
mu+2*sigma, mu+3*sigma)
axis(1, at=-3:3, lab=ll)

box()

Cheers,

Andy


__________________________________
Andy Jaworski
518-1-01
Process Laboratory
3M Corporate Research Laboratory
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


                                                                           
             Berton Gunter                                                 
             <gunter.berton at ge                                             
             ne.com>                                                    To 
             Sent by:                  "'R-help'"                          
             r-help-bounces at st         <r-help at stat.math.ethz.ch>          
             at.math.ethz.ch                                            cc 
                                                                           
                                                                   Subject 
             03/18/2005 03:41          [R] plotmath question               
             PM                                                            
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           




R listers:

I have been foiled by plotmath!

(in R 2.01,Windows 2000)

The task: Plot a normal density and label the ticks as mu - 3 sigma, mu - 2
sigma, ...., mu + 3 sigma, where the mu's and sigmas appear as Greek
symbols, of course.

The following code does this:

x<-seq(-3,to=3,by=.01)
y<-dnorm(x)
plot(x,y,type='h',col='lightblue',axes=FALSE)
lines(x,y,col='darkblue')
axis(2)
for(i in seq(-3,to=3))
             axis(1,at=i, lab=switch(sign(i)+2,

eval(substitute(expression(mu-j*sigma),list(j=-i))),
                                     expression(mu),

eval(substitute(expression(mu+j*sigma),list(j=i)))))
box()

However, I think the code in the for loop is ugly and probably means that
I'm doing it wrong. In particular:

1) Is there a neat way to use one axis() call and a vector (of
expressions?)
for the lab=argument?

2) The plotmath Help state that expressions can be used for axis labels, so
I would have expected the above to work without the eval()call  -- but it
does not. Would someone kindly explain to me why not -- i.e., what I have
misunderstood. That is, to be clear, why does the following not work:

for(i in seq(-3,to=3))
             axis(1,at=i, lab=switch(sign(i)+2,

substitute(expression(mu-j*sigma),list(j=i)),
                                     expression(mu),

substitute(expression(mu+j*sigma),list(j=i))))

Any further ideas,insights, or pointers to reference materials would also
be
appreciated. Many thanks.


-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA

"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From deepayan at stat.wisc.edu  Fri Mar 18 23:01:41 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 18 Mar 2005 16:01:41 -0600
Subject: [R] Sweave/margin
In-Reply-To: <9963.1111182572@www73.gmx.net>
References: <9963.1111182572@www73.gmx.net>
Message-ID: <200503181601.41858.deepayan@stat.wisc.edu>

On Friday 18 March 2005 15:49, Katharina Hoff wrote:
> Hi!
>
> I am currently using Sweave for writing my bachelor thesis - and I have a
> problem:
>
> I am using a LaTeX style (report) with quite big margin spaces. The Sweave
> generated LaTeX code "floats" into the margin - and it looks ugly. The text
> is blocked and fine... then there comes some flattering code running over
> the margin... and blocked text again.
>
> Considering the LaTeX output, I guess that Sweave puts the source code
> somehow in LaTeX-boxes and I suppose there is a place where I could change
> the width of the source code boxes (At a certain point, there is a break,
> closely before the text would drift out of the page. Then the code
> continues in new lines below.)
>
> Does anyone know where I could change or insert the box width?

If I understand your problem correctly, you might want to try putting

options(width = 40)

at the top of your first chunk.

> Or probably I am totally wrong and someone knows another solution...
>
> Hoping for help - and excuse if anyone asked this stupid question before, I
> did not find it in the archive,

It's in the Sweave FAQ: http://www.ci.tuwien.ac.at/~leisch/Sweave/FAQ.html

-Deepayan



From deepayan at stat.wisc.edu  Fri Mar 18 23:20:44 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 18 Mar 2005 16:20:44 -0600
Subject: [R] plotmath question
In-Reply-To: <200503182141.j2ILfNL9021142@hertz.gene.com>
References: <200503182141.j2ILfNL9021142@hertz.gene.com>
Message-ID: <200503181620.44417.deepayan@stat.wisc.edu>

On Friday 18 March 2005 15:41, Berton Gunter wrote:
> R listers:
>
> I have been foiled by plotmath!
>
> (in R 2.01,Windows 2000)
>
> The task: Plot a normal density and label the ticks as mu - 3 sigma, mu - 2
> sigma, ...., mu + 3 sigma, where the mu's and sigmas appear as Greek
> symbols, of course.
>
> The following code does this:
>
> x<-seq(-3,to=3,by=.01)
> y<-dnorm(x)
> plot(x,y,type='h',col='lightblue',axes=FALSE)
> lines(x,y,col='darkblue')
> axis(2)
> for(i in seq(-3,to=3))
>  axis(1,at=i, lab=switch(sign(i)+2,
>    eval(substitute(expression(mu-j*sigma),list(j=-i))),
>    expression(mu),
>    eval(substitute(expression(mu+j*sigma),list(j=i)))))
> box()
>
> However, I think the code in the for loop is ugly and probably means that
> I'm doing it wrong. In particular:
>
> 1) Is there a neat way to use one axis() call and a vector (of
> expressions?) for the lab=argument?

Yes, expression objects can be vectors. e.g.:

## use switch as above for better formatting
lab = do.call(expression, 
              lapply(-3:3, function(i) { 
                   bquote(mu + .(i) * sigma) 
              } ))
axis(1, at = -3:3, lab = lab)


> 2) The plotmath Help state that expressions can be used for axis labels, so
> I would have expected the above to work without the eval()call  -- but it
> does not. Would someone kindly explain to me why not -- i.e., what I have
> misunderstood. That is, to be clear, why does the following not work:
>
> for(i in seq(-3,to=3))
>  axis(1,at=i, lab=switch(sign(i)+2,
>    substitute(expression(mu-j*sigma),list(j=i)),
>    expression(mu),
>    substitute(expression(mu+j*sigma),list(j=i))))


> is.expression(substitute(expression(mu-j*sigma),list(j=1)))
[1] FALSE
> is.expression(eval(substitute(expression(mu-j*sigma),list(j=1))))
[1] TRUE

?substitute says

Value:

     The 'mode' of the result is generally '"call"' ...

which evidently have to be evaluated.

Hth,

Deepayan



From jan.sabee at gmail.com  Fri Mar 18 23:18:22 2005
From: jan.sabee at gmail.com (Jan Sabee)
Date: Fri, 18 Mar 2005 23:18:22 +0100
Subject: [R] Count all dataset
Message-ID: <96507a8e0503181418614ba2d8@mail.gmail.com>

Dear all R member,

I have a dataset which looks like:

 x1     x2 . . . x250
  A     A           C
  A     C           C
  A     A           A
  A     A        <NA>
  B     B           B
<NA> C           B
...
more 2000 rows.

I need count all dataset at the following:

A       = sum of A
B       = sum of B
C       = sum of C
<NA> = sum of <NA>

What function can I use?
I'm just a beginner in R programming.

Best regards,
Jan Sabee



From ritz at bioassay.dk  Sat Mar 19 00:14:02 2005
From: ritz at bioassay.dk (Christian Ritz)
Date: Sat, 19 Mar 2005 00:14:02 +0100
Subject: [R] Non linear modeling
In-Reply-To: <20050318200721.57ac0cb1.secchi@sssup.it>
References: <3A822319EB35174CA3714066D590DCD50994E894@usrymx25.merck.com>
	<20050318200721.57ac0cb1.secchi@sssup.it>
Message-ID: <423B60BA.4010309@bioassay.dk>

Hi Angelo,

have a look at the following example which uses 'gls' in the nlme package.


library(nlme)

x <- runif(100, 0, 1)
y <- x + exp(4*x)*rnorm(100, 0, 2)
gls(y~x, correlation = varExp(form=~x))


For details see ?gls and ?varExp.

Christian



From tlumley at u.washington.edu  Sat Mar 19 00:19:49 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 18 Mar 2005 15:19:49 -0800 (PST)
Subject: [R] plotmath question
In-Reply-To: <200503182141.j2ILfNL9021142@hertz.gene.com>
References: <200503182141.j2ILfNL9021142@hertz.gene.com>
Message-ID: <Pine.A41.4.61b.0503181518030.256700@homer05.u.washington.edu>

On Fri, 18 Mar 2005, Berton Gunter wrote:
>
> 2) The plotmath Help state that expressions can be used for axis labels, so
> I would have expected the above to work without the eval()call  -- but it
> does not. Would someone kindly explain to me why not -- i.e., what I have
> misunderstood. That is, to be clear, why does the following not work:

Because substitute() doesn't evaluate its argument: the result is not an 
expression but a call to the expression() function.

An example where it is clearer what is going on

substitute(log(x),list(x=1))

doesn't return a number, even though log() returns a number. It returns a 
call to log() that still has to be evaluated

 	-thomas

> for(i in seq(-3,to=3))
> 	axis(1,at=i, lab=switch(sign(i)+2,
> 			substitute(expression(mu-j*sigma),list(j=i)),
> 			expression(mu),
> 			substitute(expression(mu+j*sigma),list(j=i))))
>



From keithw at med.usyd.edu.au  Sat Mar 19 00:40:47 2005
From: keithw at med.usyd.edu.au (Keith Wong)
Date: Sat, 19 Mar 2005 10:40:47 +1100
Subject: [R] Re: Repeated Measures, groupedData and lme
In-Reply-To: <200503181129.j2IBFcsG012539@hypatia.math.ethz.ch>
References: <200503181129.j2IBFcsG012539@hypatia.math.ethz.ch>
Message-ID: <1111189247.423b66ff5d673@www.mail.med.usyd.edu.au>

Hello,

I'm an R-newbie, but I've been learning to use lme for repeated measures
experiments as well.

If I understand correctly: 
  Outcome variable: Mg (Kg/ha)
  Subject/grouping variable: block

  Condition/treatment: treatment (19 levels)
  Repeated factor: time (3 levels: 99, 02, 04)


I think if you specify the model formula in the lme call, then the formula
structure specified in the groupedData object is ignored.

One suggestion for the model:

Model1<-lme(mg~treatment + year + treatment:year, random=~1|block,
data=magnesium)

If the question of interest is the treatment:year interaction

Or
Model2 <- lme(mg~treatment, random=~1|block, data=magnesium)


Hope this helps ... and hope the experts chime in at this point to give more
guidance.

Keith


------quoting original post---
Hello

I am trying to fit a REML to some soil mineral data which has been
collected over the time period 1999 - 2004. I want to know if the 19
different treatments imposed, differ in terms of their soil mineral
content. A tree model of the data has shown differences between the
treatments can be attributed to the Magnesium, Potassium and organic
matter content of the soil, with Magnesium being the primary separating
variable.

I am looking at soil mineral data were collected : 99, 02, 04. 

In the experiment, there are 19 different treatments (treatmentcontrol,
treatment6TFYM, treatment 12TFYM etc),  which are replicated in 3
blocks.

For the magnesium soil data, I have created the following groupedData
object: 

magnesium<-groupedData(Mg~year|treatment, inner=~block) 
Where mg=magnesium Kg/ha

As it is a repeated measures I was going to use an lme.  I have looked
at Pinherio and Bates : Mixed-Effects models in S and S-plus and I am
getting slightly confused.  In order to fit the lme, should I specify
the data to use in the model as the grouped structure model?

If so is the following command correct:

Model1<-lme(mg~treatment, random=block|year, data=magnesium)? 

I am slightly worried that it isn't, because in model summary, instead
of listing the 19 different treatments in the fixed effects section, it
writes intercept (as normal), then treatment^1, treatment^2 etc.

However if I don't specify the groupedData object in the model, then in
the fixed effects section, it names the treatments (i.e. intercept,
treatmentcontrol, treatment6TFYM.

Should I be fitting the model using the whole data set rather than the
groupedData object?


Thank you very much for your help


Emma Pilgrim



From andy_liaw at merck.com  Sat Mar 19 01:22:43 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 18 Mar 2005 19:22:43 -0500
Subject: [R] Count all dataset
Message-ID: <3A822319EB35174CA3714066D590DCD50994E899@usrymx25.merck.com>

Here are two (pretty much the same) ways:

> d
  x1 x2   x3
1  D  D    A
2  B  D    A
3  C  A <NA>
4  D  D    A
5  A  D    C
> table(sapply(d, as.character))

A B C D 
5 1 2 6 
> table(as.matrix(d))

A B C D 
5 1 2 6 
> sum(is.na(d))
[1] 1

HTH,
Andy


> From: Jan Sabee
> 
> Dear all R member,
> 
> I have a dataset which looks like:
> 
>  x1     x2 . . . x250
>   A     A           C
>   A     C           C
>   A     A           A
>   A     A        <NA>
>   B     B           B
> <NA> C           B
> ...
> more 2000 rows.
> 
> I need count all dataset at the following:
> 
> A       = sum of A
> B       = sum of B
> C       = sum of C
> <NA> = sum of <NA>
> 
> What function can I use?
> I'm just a beginner in R programming.
> 
> Best regards,
> Jan Sabee
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From ggrothendieck at myway.com  Sat Mar 19 04:00:23 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 19 Mar 2005 03:00:23 +0000 (UTC)
Subject: [R] Is a .R script file name available inside the script?
References: <d2095b8c05031813417660d0e2@mail.gmail.com>
Message-ID: <loom.20050319T035256-480@post.gmane.org>

Darren Weber <darrenleeweber <at> gmail.com> writes:

: 
: Hi,
: 
: if we have a file called Rscript.R that contains the following, for example:
: 
: x <- 1:100
: outfile = "Rscript.Rout"
: sink(outfile)
: print(x)
: 
: and then we run
: 
: >> source("Rscript.R")
: 
: we get an output file called Rscript.Rout - great!
: 
: Is there an internal variable, something like .Platform, that holds
: the script name when it is being executed?  I would like to use that
: variable to define the output file name.
: 


In R 2.0.1 try putting this in a file and sourcing it.

script.description <- function() eval.parent(quote(file), n = 3)
print(basename(script.description()))


If you are using R 2.1.0 (devel) then use this instead:

script.description <- function() 
	showConnections() [as.character(eval.parent(quote(file), n = 3)), 
		"description"]
print((basename(script.description())))



From xpsun at ict.ac.cn  Sat Mar 19 07:52:00 2005
From: xpsun at ict.ac.cn (XP Sun)
Date: Sat, 19 Mar 2005 14:52:00 +0800
Subject: [R] the number of cluster
Message-ID: <200503190652.j2J6qksf012884@hypatia.math.ethz.ch>

hi, all,

	how to decide the number of cluster before you use kmeans and hclust? 
	thank you in advance!

best
-xpsun



From p.dalgaard at biostat.ku.dk  Sat Mar 19 11:19:19 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 19 Mar 2005 11:19:19 +0100
Subject: [R] slow computation of mixed ANOVA using aov
In-Reply-To: <000601c52bd5$1957cca0$6700a8c0@lsa.adsroot.itcs.umich.edu>
References: <000601c52bd5$1957cca0$6700a8c0@lsa.adsroot.itcs.umich.edu>
Message-ID: <x2u0n8rl94.fsf@biostat.ku.dk>

"Steven Lacey" <slacey at umich.edu> writes:

> Dear R-help list,
>  
> I am trying to do a mixed ANOVA on a 8960 x 5 dataframe. I have 3 factors
> for which I want to test all main effects and interactions : f1 (40 levels),
> f2 (7 levels), and f3 (4 levels). I also have a subject factor, subject, and
> a dependent variable, dv. 
>  
> Some more information about the factors:
> f2 is a between-subject factor. That is, for each level of f2 there are 8
> nested levels of the subject factor. For example, levels 1-8 of subject are
> nested in level 1 of f2. Levels 9-16 of subject are nested in level 2 of f2.
> In other words, the subjects that participated in any level of f2 are
> different from the subjects that participated in any other level of f2. 
>  
> In contrast, f1 and f3 are within-subject factors. That is, for any one of
> the 56 subjects, we have a 160 medians corresponding to each condition from
> a complete crossing of factors f1 and f2. While it is true that we do have
> replicate observations for any subject in each of these conditions, we take
> the median of those values and operate as if there is only a single
> observation for each subject in each of the 160 within-subject conditions. 
>  
> Below is code that will generate dataframe d, which is just like the one I
> am working with:
>  
> f1<-gl(40,1,8960,ordered=T)
> f2<-gl(7,1280,8960,ordered=T)
> f3<-gl(4,40,8960,ordered=T)
> subject<-gl(56,160,8960,ordered=T)
> dv<-rnorm(8960,mean=500,sd=50)
> d <- data.frame(f1,f2,f3,f4,dv)
>  
> To run the mixed ANOVA I use the following call (modeled after J. Baron):
> aov(dv~f1*f2*f3+Error(subject/(f1*f2)),data=d)

[You mean subject/(f1*f3), right? "f2" is a coarsening of "subject"]

> WARNING: Exert caution when running the aov command. I have run the exact
> same command on Windows and Unix machines (each with 1GB of RAM; allocated
> up to 3 or 4GB of memory for the analysis ) and it has taken many, many
> hours to finish. That said, this is not a new problem posted on the R-help
> list. There are several posts where analysts have run into similar problems.
> My general impression of these posts, and correct me if I am wrong, is that
> because aov is a wrapper around lm, the extra time is required to build and
> manipulate a design matrix (via qr decomposition) that is 8960 x several
> thousand columns large! Is that so? It seems fitting because if I call aov
> with only a single factor, then it returns in a few seconds. 

Yes, this is basically correct. The main issue is the calculation of
the projection onto the terms in the Error model, which is done using
the generic lm algorithm even though the design is typicaly orthogonal
so that there are much faster ways to get to the result. 

To paraphrase: if you have double determinations and an error term at
the level of each pair, the algorithm fits a model with N/2 parameters
in order to calculate the mean and difference within each pair. For
large designs, this becomes an issue...

This is in some sense a tradeoff of generality for speed, but the
results for non-orthogonal designs are typically very hard to
interpret.

The topic does come up off and on, and we have been considering the
option of adding an algorithm where it is assumed that the Error model
consists of mutually orthogonal and balanced terms (in the sense that
all factor levels appear equally frequently). Just a "simple matter of
programming"... 

For the near term, there are a couple of things that you can do:

- avoid having an error term that is equivalent to the full data set.
  In your case, subject:f1:f3 is such a term, and subject/(f1+f3) is
  actually equivalent (the second order interaction term becomes the
  residual stratum). This at least saves you from inverting an NxN
  matrix. 

- use a version of R compiled with a fast BLAS, on a fast computer
  with a lot of RAM... (A ~2K square matrix inversion will take a
  while, but "hours" sounds a bit excessive). 

- (not too sure of this, but R 2.1.0 will have some new code for
  multivariate lm, with intra-individual designs, and
  tests under the sphericity assumptions; it is possible that
  your models can be reformulated in that framework. You'd have to
  set it up as a model with 160 responses on 56 subjects, though, and
  the code wasn't really designed with that sort of intrasubject
  dimensionality in mind.)
  
> In order to test if the computational slowness was something unique to R, I
> ran the same analysis, including all 3 factors, in SPSS. To my surprise SPSS
> returned almost instantaneously. I do not know much about the algorithm in
> SPSS, but I suspect it may be calculating condition means and sums of
> squares rather than generating a design matrix. Does that sound plausible?
>  
> At this point I am a dedicated R user. However, I do the kind of analysis
> described above quite often. It is important that my statistical package be
> able to handle it more efficiently than what I have been able to get R to do
> at this point. Am I doing anything obviously wrong? Is there a method in R
> that more closely resembles the algorithm used in SPSS? If not, are there
> any other methods R has to do these kind of analyses? Could I split up the
> analysis in some principled way to ease the processing demand on R?
>  
> Thanks in advanvce for any further insight into this issue, 
> Steve Lacey
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From malfonso at telecom.com.co  Sat Mar 19 11:37:02 2005
From: malfonso at telecom.com.co (Mario Morales)
Date: Sat, 19 Mar 2005 05:37:02 -0500
Subject: [R] How I calculate nCr with R ? (Como calculo nCr con R?  )
Message-ID: <423C00CE.7070406@telecom.com.co>

En espa?ol  (In Spanish)

Necesito calcular la en numeros de combinaciones de n cosas
tomando k al tiempo.

Como hago eso en R ???

Yo escrib? mi propia funci?n pero pienso que  de esa forma no es
f?cil para mis estudiantes .

He estado buscando en la ayuda y no he encontrado informaci?n
sobre una funci?n que calcule eso directamente. Podr?an ayudarme


In English (en Ingl?s )

I need calculate the combination of n things taking k at time.


How do I do that in R ?

I wrote my own function but in this form isn't easy for my
students.

Can you help me ?



From p.dalgaard at biostat.ku.dk  Sat Mar 19 11:35:57 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 19 Mar 2005 11:35:57 +0100
Subject: [R] slow computation of mixed ANOVA using aov
In-Reply-To: <x2u0n8rl94.fsf@biostat.ku.dk>
References: <000601c52bd5$1957cca0$6700a8c0@lsa.adsroot.itcs.umich.edu>
	<x2u0n8rl94.fsf@biostat.ku.dk>
Message-ID: <x2psxvsz1u.fsf@biostat.ku.dk>

Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:

> - use a version of R compiled with a fast BLAS, on a fast computer
>   with a lot of RAM... (A ~2K square matrix inversion will take a
>   while, but "hours" sounds a bit excessive). 

To wit:

>  system.time(aov(dv~f1*f2*f3+Error(subject/(f1+f3)),data=d))
[1] 582.46   9.31 619.01   0.00   0.00

i.e. about 10 minutes on an Opteron 240 (dual, but it only seemed to
use one cpu for this task) with 1GB.


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ligges at statistik.uni-dortmund.de  Sat Mar 19 12:34:19 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 19 Mar 2005 12:34:19 +0100
Subject: [R] How I calculate nCr with R ? (Como calculo nCr con R?  )
In-Reply-To: <423C00CE.7070406@telecom.com.co>
References: <423C00CE.7070406@telecom.com.co>
Message-ID: <423C0E3B.9040700@statistik.uni-dortmund.de>

Mario Morales wrote:

> En espa?ol  (In Spanish)
> 
> Necesito calcular la en numeros de combinaciones de n cosas
> tomando k al tiempo.
> 
> Como hago eso en R ???
> 
> Yo escrib? mi propia funci?n pero pienso que  de esa forma no es
> f?cil para mis estudiantes .
> 
> He estado buscando en la ayuda y no he encontrado informaci?n
> sobre una funci?n que calcule eso directamente. Podr?an ayudarme
> 
> 
> In English (en Ingl?s )
> 
> I need calculate the combination of n things taking k at time.

Just the number of combinations: ?choose

For listing all of them (you could have found those packages yourself, 
BTW), e.g:
- combinations() in package "gtools" in bundle "gregmisc"
- combn() in package "combinat"


Uwe Ligges


> 
> How do I do that in R ?
> 
> I wrote my own function but in this form isn't easy for my
> students.
>
> Can you help me ?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From jeaneid at chass.utoronto.ca  Sat Mar 19 12:42:41 2005
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Sat, 19 Mar 2005 06:42:41 -0500
Subject: [R] How I calculate nCr with R ? (Como calculo nCr con R?  )
In-Reply-To: <423C00CE.7070406@telecom.com.co>
Message-ID: <Pine.SGI.4.40.0503190642120.49706-100000@origin.chass.utoronto.ca>

do you mean n choose k which is a built in function  see
?choose




On Sat, 19 Mar 2005, Mario Morales wrote:

> En espaol  (In Spanish)
>
> Necesito calcular la en numeros de combinaciones de n cosas
> tomando k al tiempo.
>
> Como hago eso en R ???
>
> Yo escrib mi propia funcin pero pienso que  de esa forma no es
> fcil para mis estudiantes .
>
> He estado buscando en la ayuda y no he encontrado informacin
> sobre una funcin que calcule eso directamente. Podran ayudarme
>
>
> In English (en Ingls )
>
> I need calculate the combination of n things taking k at time.
>
>
> How do I do that in R ?
>
> I wrote my own function but in this form isn't easy for my
> students.
>
> Can you help me ?
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Sat Mar 19 12:44:42 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 19 Mar 2005 12:44:42 +0100
Subject: [R] the number of cluster
In-Reply-To: <200503190652.j2J6qksf012884@hypatia.math.ethz.ch>
References: <200503190652.j2J6qksf012884@hypatia.math.ethz.ch>
Message-ID: <423C10AA.7080509@statistik.uni-dortmund.de>

XP Sun wrote:

> hi, all,
> 
> 	how to decide the number of cluster before you use kmeans and hclust? 
> 	thank you in advance!

Depends on your criterion. Best idea is always to use the brain and
think about how many clusters are sensible for the particular
task/problem/data.
For hclust, you can also look at the dendrogram's height and distances
of dissimilarities in order to cut.

Uwe Ligges


> best
> -xpsun
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From samuel_mwalili at yahoo.com  Sat Mar 19 13:57:37 2005
From: samuel_mwalili at yahoo.com (Sameul M Mwalili)
Date: Sat, 19 Mar 2005 04:57:37 -0800 (PST)
Subject: [R] How to use a R package with C code
In-Reply-To: 6667
Message-ID: <20050319125737.74706.qmail@web53403.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050319/3e0d0488/attachment.pl

From joseph at utstat.toronto.edu  Sat Mar 19 14:35:47 2005
From: joseph at utstat.toronto.edu (Joseph Beyene)
Date: Sat, 19 Mar 2005 08:35:47 -0500
Subject: [R] How I calculate nCr with R ? (Como calculo nCr con R?  )
In-Reply-To: <423C00CE.7070406@telecom.com.co>
Message-ID: <000001c52c88$8f06d050$6600a8c0@PHSE4071XL>

Try 

choose(k,r)

> choose(10,2)
[1] 45


JB



> -----Original Message-----
> From: Mario Morales [mailto:malfonso at telecom.com.co]
> Sent: March 19, 2005 5:37 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] How I calculate nCr with R ? (Como calculo nCr con R? )
> 
> En espa?ol  (In Spanish)
> 
> Necesito calcular la en numeros de combinaciones de n cosas
> tomando k al tiempo.
> 
> Como hago eso en R ???
> 
> Yo escrib? mi propia funci?n pero pienso que  de esa forma no es
> f?cil para mis estudiantes .
> 
> He estado buscando en la ayuda y no he encontrado informaci?n
> sobre una funci?n que calcule eso directamente. Podr?an ayudarme
> 
> 
> In English (en Ingl?s )
> 
> I need calculate the combination of n things taking k at time.
> 
> 
> How do I do that in R ?
> 
> I wrote my own function but in this form isn't easy for my
> students.
> 
> Can you help me ?
>



From tura at centroin.com.br  Sat Mar 19 15:13:57 2005
From: tura at centroin.com.br (Bernardo Rangel Tura)
Date: Sat, 19 Mar 2005 11:13:57 -0300
Subject: [R] problem with legend
In-Reply-To: <20050317215944.30864f02.twiens@interbaun.com>
References: <20050317215944.30864f02.twiens@interbaun.com>
Message-ID: <6.1.2.0.2.20050319111305.0268eeb0@centroin.com.br>

I have problem with legend command. Please look this script:

 >dcbv.fm
Time Series:
Start = 1980
End = 2002
Frequency = 1
  [1] 2994.023 3388.414 3111.762 2990.967 3077.438 3058.274 3049.934 2974.130
  [9] 2889.659 2801.790 2631.391 2661.700 2312.526 2518.968 2567.044 2443.952
[17] 2117.638 2042.461 2025.816 1939.560 1640.775 1583.609 1659.912

 > dcbv.ms
Time Series:
Start = 1980
End = 2002
Frequency = 1
  [1] 3700.239 4076.438 3856.495 3680.345 3871.887 3789.770 3831.173 3768.876
  [9] 3585.572 3754.374 3372.859 3419.667 3185.194 3319.215 3445.845 3265.214
[17] 2773.961 2661.904 2669.835 2569.190 2187.719 2217.756 2196.378

 >plot(dcbv.ms,ylim=c(min(dcbv.fm),max(dcbv.ms)))

 >lines(dcbv.fm,col=2)

 >legend(1984,2500,c("DCVB-MS","DCBV-FM"),col=c(1,2),cex=.6,fill=T)

At end of script the legend of plot have only one color: black. I think the 
legend will have two colors: black and red.

Where I make mistake?


version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    0.1
year     2004
month    11
day      15
language R

Thanks in advance

Bernardo Rangel Tura, MD, MSc
National Institute of Cardiology Laranjeiras
Rio de Janeiro Brazil 


-- 
No virus found in this outgoing message.
Checked by AVG Anti-Virus.



From med at aghmed.fsnet.co.uk  Sat Mar 19 16:15:25 2005
From: med at aghmed.fsnet.co.uk (Michael Dewey)
Date: Sat, 19 Mar 2005 15:15:25 +0000
Subject: [R] How I calculate nCr with R ? (Como calculo nCr con R? 
  )
In-Reply-To: <423C00CE.7070406@telecom.com.co>
References: <423C00CE.7070406@telecom.com.co>
Message-ID: <6.2.1.2.0.20050319151325.028e5640@pop.freeserve.net>

At 10:37 19/03/05, Mario Morales wrote:
>En espa?ol  (In Spanish)
>
>Necesito calcular la en numeros de combinaciones de n cosas
>tomando k al tiempo.

In English we usually read this as N choose r and with that clue you might 
go ?choose

Incidentally your English is fine although I see the logic in giving us both.

>Como hago eso en R ???
>
>Yo escrib? mi propia funci?n pero pienso que  de esa forma no es
>f?cil para mis estudiantes .
>
>He estado buscando en la ayuda y no he encontrado informaci?n
>sobre una funci?n que calcule eso directamente. Podr?an ayudarme
>
>
>In English (en Ingl?s )
>
>I need calculate the combination of n things taking k at time.
>
>
>How do I do that in R ?
>
>I wrote my own function but in this form isn't easy for my
>students.
>
>Can you help me ?
>
>

Michael Dewey
med at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html



From alexbri at netcabo.pt  Sat Mar 19 18:03:40 2005
From: alexbri at netcabo.pt (alexbri)
Date: Sat, 19 Mar 2005 17:03:40 -0000
Subject: [R] simple problem, but not for me
Message-ID: <EA91707AE6F4C84495513EFF5117E897062217A4@VS2.hdi.tvcabo>

Hello, I'm new in R and I want to do one thing that is very easy in excel, however, I cant do it in R.

Suppose we have the data frame:

 

data<- data.frame(A=c("a1","a2","a3","a4","a5"))

 

I need to obtain another column in the same data frame (lets say B=c(b1,b2,b3,b4,b5) in the following way:

 

b1=a1/(a1+a2+a3+a4+a5)

b2=a2/(a2+a3+a4+a5)

b3=a3/(a3+a4+a5)

b4=a4/(a4+a5)

b5=a5/a5

 

a1..a5 and b1...b5 are always numeric values

 

(this is just an example, what I really want is apply this kind of formula to a much larger data frame)

 

I think this is easy for those who are used to work in R (and I suppose there are many different ways), but I can make it in this moment, because I cannot leave behind, the "excel thinking way".

I hope you understand my problem and please, help me soon. 

 

Alexandre

 

alexbri at netcabo.pt



From deepayan at stat.wisc.edu  Sat Mar 19 18:10:26 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sat, 19 Mar 2005 11:10:26 -0600
Subject: [R] Control of vertical spacing in Lattice key text?
In-Reply-To: <20050315231803.GI4244@hortresearch.co.nz>
References: <20050315231803.GI4244@hortresearch.co.nz>
Message-ID: <200503191110.26684.deepayan@stat.wisc.edu>

On Tuesday 15 March 2005 17:18, Patrick Connolly wrote:
> I find the key and legend functions in Lattice very useful.  Trouble
> is, now I can see what else I'd like to be able to do with them.
>
> If I put a title on a key, it appears too close to the key itself,
> and if there's a line break in the title (which often happens), the
> leading between the lines is too much.
>
> What I can do is print to a postscript file, then find the lines in
> the postscript file where my text appears and fiddle with the
> postscript code to move the text up or down as I wish.  For single
> plots that's OK, but I'd prefer to be able to do it within R
> especially when I wish to do dozens of them.
>
> Is there something in the documentation I overlooked?

Nope. The space used for the title is currently hard-coded (to be 1.2 
times the height of the title string). It should be easy enough to add 
a new option in draw.key, provided I can think up a good name 
(suggestions welcome).

Deepayan



From ligges at statistik.uni-dortmund.de  Sat Mar 19 18:16:23 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 19 Mar 2005 18:16:23 +0100
Subject: [R] simple problem, but not for me
In-Reply-To: <EA91707AE6F4C84495513EFF5117E897062217A4@VS2.hdi.tvcabo>
References: <EA91707AE6F4C84495513EFF5117E897062217A4@VS2.hdi.tvcabo>
Message-ID: <423C5E67.9070307@statistik.uni-dortmund.de>

alexbri wrote:

> Hello, I'm new in R and I want to do one thing that is very easy in excel, however, I cant do it in R.
> 
> Suppose we have the data frame:
> 
>  
> 
> data<- data.frame(A=c("a1","a2","a3","a4","a5"))
> 
>  
> 
> I need to obtain another column in the same data frame (lets say B=c(b1,b2,b3,b4,b5) in the following way:
> 
>  
> 
> b1=a1/(a1+a2+a3+a4+a5)
> 
> b2=a2/(a2+a3+a4+a5)
> 
> b3=a3/(a3+a4+a5)
> 
> b4=a4/(a4+a5)
> 
> b5=a5/a5


   temp <- rev(data$A)
   data$B <- rev(temp / cumsum(temp))

Uwe Ligges




>  
> 
> a1..a5 and b1...b5 are always numeric values
> 
>  
> 
> (this is just an example, what I really want is apply this kind of formula to a much larger data frame)
> 
>  
> 
> I think this is easy for those who are used to work in R (and I suppose there are many different ways), but I can make it in this moment, because I cannot leave behind, the "excel thinking way".
> 
> I hope you understand my problem and please, help me soon. 
> 
>  
> 
> Alexandre
> 
>  
> 
> alexbri at netcabo.pt
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Sat Mar 19 18:22:52 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 19 Mar 2005 18:22:52 +0100
Subject: [R] problem with legend
In-Reply-To: <6.1.2.0.2.20050319111305.0268eeb0@centroin.com.br>
References: <20050317215944.30864f02.twiens@interbaun.com>
	<6.1.2.0.2.20050319111305.0268eeb0@centroin.com.br>
Message-ID: <423C5FEC.2090409@statistik.uni-dortmund.de>

Bernardo Rangel Tura wrote:

> I have problem with legend command. Please look this script:
> 
>  >dcbv.fm
> Time Series:
> Start = 1980
> End = 2002
> Frequency = 1
>  [1] 2994.023 3388.414 3111.762 2990.967 3077.438 3058.274 3049.934 
> 2974.130
>  [9] 2889.659 2801.790 2631.391 2661.700 2312.526 2518.968 2567.044 
> 2443.952
> [17] 2117.638 2042.461 2025.816 1939.560 1640.775 1583.609 1659.912
> 
>  > dcbv.ms
> Time Series:
> Start = 1980
> End = 2002
> Frequency = 1
>  [1] 3700.239 4076.438 3856.495 3680.345 3871.887 3789.770 3831.173 
> 3768.876
>  [9] 3585.572 3754.374 3372.859 3419.667 3185.194 3319.215 3445.845 
> 3265.214
> [17] 2773.961 2661.904 2669.835 2569.190 2187.719 2217.756 2196.378
> 
>  >plot(dcbv.ms,ylim=c(min(dcbv.fm),max(dcbv.ms)))
> 
>  >lines(dcbv.fm,col=2)
> 
>  >legend(1984,2500,c("DCVB-MS","DCBV-FM"),col=c(1,2),cex=.6,fill=T)


So you want filles boxes? Then you should specify the color in the fill 
argument:

  legend(1984, 2500, c("DCVB-MS", "DCBV-FM"), cex=.6, fill=1:2)

or do you want some lines?

  legend(1984, 2500, c("DCVB-MS", "DCBV-FM"), cex=.6, col=1:2, lwd=2)

Uwe Ligges



> 
> At end of script the legend of plot have only one color: black. I think 
> the legend will have two colors: black and red.
> 
> Where I make mistake?
> 
> 
> version
>          _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    0.1
> year     2004
> month    11
> day      15
> language R
> 
> Thanks in advance
> 
> Bernardo Rangel Tura, MD, MSc
> National Institute of Cardiology Laranjeiras
> Rio de Janeiro Brazil
>



From rolf at math.unb.ca  Sat Mar 19 18:38:52 2005
From: rolf at math.unb.ca (Rolf Turner)
Date: Sat, 19 Mar 2005 13:38:52 -0400 (AST)
Subject: [R] simple problem, but not for me
Message-ID: <200503191738.j2JHcq63010380@erdos.math.unb.ca>


alexbri at netcabo.pt wrote:

> Hello, I'm new in R and I want to do one thing that is very easy in
> excel, however, I cant do it in R.

	Well, if you've deadened your brain by using Excel,
	no wonder.

> Suppose we have the data frame:
> 
> data<- data.frame(A=c("a1","a2","a3","a4","a5"))

	Oh, for Pete's sake!  This makes ``data'' (NOT a good name
	for an object!) into a data frame with a single column named
	``A''.  That column will be a factor with 5 entries (an 5
	levels) with these levels being (the character strings)
	"a1","a2","a3","a4", and "a5".
	
	Nothing to do with what you actually want.
 
> I need to obtain another column in the same data frame (lets say
> B=c(b1,b2,b3,b4,b5) in the following way:

	This would make B a ***vector*** equal to the concatenation
	of b1, ..., b5.

	Perhaps you mean:

		B <- cbind(b1,b2,b3,b4,b5)

> b1=a1/(a1+a2+a3+a4+a5)
> 
> b2=a2/(a2+a3+a4+a5)
> 
> b3=a3/(a3+a4+a5)
> 
> b4=a4/(a4+a5)
> 
> b5=a5/a5
> 
> a1..a5 and b1...b5 are always numeric values
> 
> (this is just an example, what I really want is apply this kind of
> formula to a much larger data frame)
> 
	You are very confused.  Your notation and your use of
	the function c() are all wrong.

	If you are going to use R, get the basic syntax straight.

	You probably should be using matrices rather than data frames
	given that the entries are all numeric.

	Be that as it may, if A is a (numeric) matrix then

		B <- A/t(apply(A,1,function(x){rev(cumsum(x))}))

	will give what you appear to want.

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From p.dalgaard at biostat.ku.dk  Sat Mar 19 19:20:49 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 19 Mar 2005 19:20:49 +0100
Subject: [R] slow computation of mixed ANOVA using aov
In-Reply-To: <x2u0n8rl94.fsf@biostat.ku.dk>
References: <000601c52bd5$1957cca0$6700a8c0@lsa.adsroot.itcs.umich.edu>
	<x2u0n8rl94.fsf@biostat.ku.dk>
Message-ID: <x2k6o3sdj2.fsf@biostat.ku.dk>

Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:

> - (not too sure of this, but R 2.1.0 will have some new code for
>   multivariate lm, with intra-individual designs, and
>   tests under the sphericity assumptions; it is possible that
>   your models can be reformulated in that framework. You'd have to
>   set it up as a model with 160 responses on 56 subjects, though, and
>   the code wasn't really designed with that sort of intrasubject
>   dimensionality in mind.)

OK, I've tried this now and it does seem to work, and much faster than
the aov() approach. I had to fix a buglet in the code (eigenvalues
coming up with small imaginary parts due to numerics), so currently
available versions won't quite work, but it should be in the alpha
releases that are supposed to start Monday.

Here's how it works:

### orig setup, edited so as to actually work...
 f1<-gl(40,1,8960,ordered=T)
 f2<-gl(7,1280,8960,ordered=T)
 f3<-gl(4,40,8960,ordered=T)
 subject<-gl(56,160,8960,ordered=T)
 dv<-rnorm(8960,mean=500,sd=50)
 d <- data.frame(f1,f2,f3,subject,dv)

### Regroup to 56x160 matrix response 
 f2a <- f2[seq(1,8801,160)]
 idata <- d[1:160,] # intrasubj. design, actually need only f1,f3 from this
 Y <- matrix(dv,56,byrow=T)

### now fit models with effect of f2a, constant, and empty
 fit <- lm(Y~f2a)
 fit2 <- lm(Y~1)
 fit3 <- lm(Y~0)

## The main trick is to do anova on within-subject effects. First look
## at the interactions, alias residuals from an additive model ~f1+f3.
## The reduction Model 1-> Model 2 corresponds to testing the f1:f2:f3
## interaction in aov (tests whether the f1:f3 interaction depends on
## f2a) and Model 2 -> Model 3 is the test for the f1:f3 interaction
## being zero.

## I'm not quite sure what to make of the correction terms when the
## estimated SSD matrix is singular (it has to be, the dimension is
## 117, but the df is only 49). Probably the G-G epsilon is bogus, but
## the H-F one seems to fare rather well.

> anova(fit,fit2,fit3,test="Spherical",X=~f1+f3,idata=idata)
Analysis of Variance Table

Model 1: Y ~ f2a
Model 2: Y ~ 1
Model 3: Y ~ 0

Contrasts orthogonal to
~f1 + f3

Greenhouse-Geisser epsilon: 0.2903
Huynh-Feldt epsilon:        0.9639

  Res.Df   Df Gen.var.      F num Df den Df  Pr(>F)  G-G Pr  H-F Pr
1     49       0.00000
2     55    6  0.00000 0.9036    702   5733 0.96034 0.82268 0.95748
3     56    1  0.00000 1.0460    117   5733 0.35003 0.39624 0.35206

## Next, we can look at the f1 effects. This is basically the
## difference between two projections, on ~f1+f3 and ~f3
## This gives us the tests for f2:f1 and f1

> anova(fit,fit2,fit3,test="Spherical",M=~f1+f3,X=~f3,idata=idata)
Analysis of Variance Table

Model 1: Y ~ f2a
Model 2: Y ~ 1
Model 3: Y ~ 0

Contrasts orthogonal to
~f3


Contrasts spanned by
~f1 + f3

Greenhouse-Geisser epsilon: 0.5598
Huynh-Feldt epsilon:        1.0284

  Res.Df   Df Gen.var.      F num Df den Df Pr(>F) G-G Pr H-F Pr
1     49        315.74
2     55    6   344.98 0.9883    234   1911   0.54   0.52   0.54
3     56    1   347.15 0.8393     39   1911   0.75   0.68   0.75

## Same thing with f3

> anova(fit,fit2,fit3,test="Spherical",M=~f1+f3,X=~f1,idata=idata)
Analysis of Variance Table

Model 1: Y ~ f2a
Model 2: Y ~ 1
Model 3: Y ~ 0

Contrasts orthogonal to
~f1


Contrasts spanned by
~f1 + f3

Greenhouse-Geisser epsilon: 0.9482
Huynh-Feldt epsilon:        1.0128

  Res.Df  Df Gen.var.      F num Df den Df Pr(>F) G-G Pr H-F Pr
1     49       35.171
2     55   6   34.679 0.9010     18    147  0.578  0.574  0.578
3     56   1   34.658 1.0039      3    147  0.393  0.390  0.393

## Actually, because of the complete design, we can ignore f1 and get
## the same analysis:

> anova(fit,fit2,fit3,test="Spherical",M=~f3,X=~1,idata=idata)
Analysis of Variance Table

Model 1: Y ~ f2a
Model 2: Y ~ 1
Model 3: Y ~ 0

Contrasts orthogonal to
~1


Contrasts spanned by
~f3

Greenhouse-Geisser epsilon: 0.9482
Huynh-Feldt epsilon:        1.0128

  Res.Df  Df Gen.var.      F num Df den Df Pr(>F) G-G Pr H-F Pr
1     49       35.171
2     55   6   34.679 0.9010     18    147  0.578  0.574  0.578
3     56   1   34.658 1.0039      3    147  0.393  0.390  0.393

## Finally we get the main effect of f2a as follows. Notice that the
## Model 2 -> Model 3 reduction is the test for zero overall mean,
## which you might (and aov does) want to omit.  

> anova(fit,fit2,fit3,test="Spherical",M=~1,X=~0,idata=idata)
Analysis of Variance Table

Model 1: Y ~ f2a
Model 2: Y ~ 1
Model 3: Y ~ 0

Contrasts orthogonal to
~0


Contrasts spanned by
~1

Greenhouse-Geisser epsilon: 1
Huynh-Feldt epsilon:        1

  Res.Df Df Gen.var.          F num Df den Df     Pr(>F)     G-G Pr
  H-F Pr
1     49          11
2     55  6       12 1.5010e+00      6     49  1.976e-01  1.976e-01
  1.976e-01
3     56  1   249956 1.2699e+06      1     49 8.346e-110 8.346e-110
  8.346e-110

## Finally aov() results for comparison:

> system.time(aa <- aov(dv~f1*f2*f3+Error(subject/(f1+f3)),data=d))
[1] 526.50   9.27 561.29   0.00   0.00
> summary(aa)

Error: subject
          Df Sum Sq Mean Sq F value Pr(>F)
f2         6  15883    2647   1.501 0.1976
Residuals 49  86411    1763

Error: subject:f1
            Df  Sum Sq Mean Sq F value Pr(>F)
f1          39   81906    2100  0.8393 0.7487
f1:f2      234  578666    2473  0.9883 0.5376
Residuals 1911 4781665    2502

Error: subject:f3
           Df Sum Sq Mean Sq F value Pr(>F)
f3          3   6899    2300  1.0039 0.3930
f2:f3      18  37153    2064  0.9010 0.5782
Residuals 147 336732    2291

Error: Within
            Df   Sum Sq  Mean Sq F value Pr(>F)
f1:f3      117   308658     2638  1.0460 0.3500
f1:f2:f3   702  1599743     2279  0.9036 0.9603
Residuals 5733 14458856     2522
>


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From spencer.graves at pdf.com  Sat Mar 19 19:56:52 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 19 Mar 2005 10:56:52 -0800
Subject: [R] simple problem, but not for me
In-Reply-To: <200503191738.j2JHcq63010380@erdos.math.unb.ca>
References: <200503191738.j2JHcq63010380@erdos.math.unb.ca>
Message-ID: <423C75F4.9090306@pdf.com>

     The suggestions by Uwe and Rolf use some of the subtler features of 
R.  A simpler (to me) if more tedious approach is provided by the 
following: 

Data <- data.frame(a1=1:4, a2=5:8, a3=9:12)

Data$b1 <- Data$a1/(Data$a1+Data$a2+Data$a3)
Data$b2 <- Data$a2/(Data$a2+Data$a3)

 > Data
  a1 a2 a3         b1        b2
1  1  5  9 0.06666667 0.3571429
2  2  6 10 0.11111111 0.3750000
3  3  7 11 0.14285714 0.3888889
4  4  8 12 0.16666667 0.4000000

      The above can be written in fewer characters using "with": 

Data$b1 <- with(Data, a1/(a1+a2+a3))
Data$b2 <- with(Data, a2/(a2+a3))

      If you want something that will work with an arbitrary number of 
columns, consider the following: 

Data <- data.frame(a1=1:4, a2=5:8, a3=9:12)
dat2 <- Data
k <- length(dat2)
for(i in (k-1):1)
  dat2[[i]] <- (dat2[[i]]+dat2[[i+1]])
Dat2 <- cbind(Data, Data/dat2)
names(Dat2)[k+(1:k)] <- paste("b", 1:k, sep="")

 > Data
  a1 a2 a3
1  1  5  9
2  2  6 10
3  3  7 11
4  4  8 12
 > dat2
  a1 a2 a3
1 15 14  9
2 18 16 10
3 21 18 11
4 24 20 12
 > Dat2
  a1 a2 a3         b1        b2 b3
1  1  5  9 0.06666667 0.3571429  1
2  2  6 10 0.11111111 0.3750000  1
3  3  7 11 0.14285714 0.3888889  1
4  4  8 12 0.16666667 0.4000000  1

      If you want to do this more than once, you can wrap the above code 
in a function;  see "Writing your own functions" in "An Introduction to 
R", available, e.g., vial help.start(). 

      hope this helps. 
      spencer graves
p.s.  The posting guide "http://www.R-project.org/posting-guide.html" 
also seems quite valuable.  In an discussion on (and off) this list 
earlier this week, several people reported they had found solutions to 
their own problems in the process of preparing a question to post to 
this list.  And even if you don't find a solution, the result will more 
likely elicit useful replies. 

Rolf Turner wrote:

>alexbri at netcabo.pt wrote:
>
>  
>
>>Hello, I'm new in R and I want to do one thing that is very easy in
>>excel, however, I cant do it in R.
>>    
>>
>
>	Well, if you've deadened your brain by using Excel,
>	no wonder.
>
>  
>
>>Suppose we have the data frame:
>>
>>data<- data.frame(A=c("a1","a2","a3","a4","a5"))
>>    
>>
>
>	Oh, for Pete's sake!  This makes ``data'' (NOT a good name
>	for an object!) into a data frame with a single column named
>	``A''.  That column will be a factor with 5 entries (an 5
>	levels) with these levels being (the character strings)
>	"a1","a2","a3","a4", and "a5".
>	
>	Nothing to do with what you actually want.
> 
>  
>
>>I need to obtain another column in the same data frame (lets say
>>B=c(b1,b2,b3,b4,b5) in the following way:
>>    
>>
>
>	This would make B a ***vector*** equal to the concatenation
>	of b1, ..., b5.
>
>	Perhaps you mean:
>
>		B <- cbind(b1,b2,b3,b4,b5)
>
>  
>
>>b1=a1/(a1+a2+a3+a4+a5)
>>
>>b2=a2/(a2+a3+a4+a5)
>>
>>b3=a3/(a3+a4+a5)
>>
>>b4=a4/(a4+a5)
>>
>>b5=a5/a5
>>
>>a1..a5 and b1...b5 are always numeric values
>>
>>(this is just an example, what I really want is apply this kind of
>>formula to a much larger data frame)
>>
>>    
>>
>	You are very confused.  Your notation and your use of
>	the function c() are all wrong.
>
>	If you are going to use R, get the basic syntax straight.
>
>	You probably should be using matrices rather than data frames
>	given that the entries are all numeric.
>
>	Be that as it may, if A is a (numeric) matrix then
>
>		B <- A/t(apply(A,1,function(x){rev(cumsum(x))}))
>
>	will give what you appear to want.
>
>				cheers,
>
>					Rolf Turner
>					rolf at math.unb.ca
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From iacolonn at uiuc.edu  Sun Mar 20 05:14:59 2005
From: iacolonn at uiuc.edu (Ignacio Colonna)
Date: Sat, 19 Mar 2005 22:14:59 -0600
Subject: [R] Re: Repeated Measures, groupedData and lme
In-Reply-To: <1111189247.423b66ff5d673@www.mail.med.usyd.edu.au>
Message-ID: <200503200415.j2K4F3tv028749@expredir5.cites.uiuc.edu>

Emma,
	I am not an expert, but I have been trying to fit similar models.
Adding to Keith's reply to your question, I can suggest what I concluded was
the most reasonable model for my case. Based on Keith's Model1, you might
also want to allow for a correlation among years within each experimental
unit (I am assuming the experiment was conducted at the exact same location
over the 3 years). 
	Say you want to impose an autoregressive, order 1 structure (you can
change this to any other structure you may consider appropriate) 
	To do this at the block*treatment unit (the smallest experimental
unit size in your experiment), you can add to keith's code:

correlation=corAR1(form=~1|block/treatment)

thus the entire code would be
Model1<-lme(mg~treatment + year + treatment:year, random=~1|block,
correlation=corAR1(form=~1|block/treatment),data=magnesium)

This results in a model with a certain covariance among all exp.units within
the same block, plus another covariance between pairs of years within the
same exp.unit, and this covariance decreases as the difference in time
increases.

You can see graphically the structure of this covariance by doing:
rho<-0.3
ar1<-corAR1(value=rho,form=~1|block/treatment)
ar1<-Initialize(ar1,data=yourdata)
m1<-corMatrix(ar1)
plot(m1$"1/name of first treatment"[,1])

Now, I really hope someone more knowledgeable is checking this out there and
will point out whether this is incorrect, as I have used it for my analysis
assuming was the correct approach. 

Ignacio


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Keith Wong
Sent: Friday, March 18, 2005 5:41 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Re: Repeated Measures, groupedData and lme

Hello,

I'm an R-newbie, but I've been learning to use lme for repeated measures
experiments as well.

If I understand correctly: 
  Outcome variable: Mg (Kg/ha)
  Subject/grouping variable: block

  Condition/treatment: treatment (19 levels)
  Repeated factor: time (3 levels: 99, 02, 04)


I think if you specify the model formula in the lme call, then the formula
structure specified in the groupedData object is ignored.

One suggestion for the model:

Model1<-lme(mg~treatment + year + treatment:year, random=~1|block,
data=magnesium)

If the question of interest is the treatment:year interaction

Or
Model2 <- lme(mg~treatment, random=~1|block, data=magnesium)


Hope this helps ... and hope the experts chime in at this point to give more
guidance.

Keith


------quoting original post---
Hello

I am trying to fit a REML to some soil mineral data which has been
collected over the time period 1999 - 2004. I want to know if the 19
different treatments imposed, differ in terms of their soil mineral
content. A tree model of the data has shown differences between the
treatments can be attributed to the Magnesium, Potassium and organic
matter content of the soil, with Magnesium being the primary separating
variable.

I am looking at soil mineral data were collected : 99, 02, 04. 

In the experiment, there are 19 different treatments (treatmentcontrol,
treatment6TFYM, treatment 12TFYM etc),  which are replicated in 3
blocks.

For the magnesium soil data, I have created the following groupedData
object: 

magnesium<-groupedData(Mg~year|treatment, inner=~block) 
Where mg=magnesium Kg/ha

As it is a repeated measures I was going to use an lme.  I have looked
at Pinherio and Bates : Mixed-Effects models in S and S-plus and I am
getting slightly confused.  In order to fit the lme, should I specify
the data to use in the model as the grouped structure model?

If so is the following command correct:

Model1<-lme(mg~treatment, random=block|year, data=magnesium)? 

I am slightly worried that it isn't, because in model summary, instead
of listing the 19 different treatments in the fixed effects section, it
writes intercept (as normal), then treatment^1, treatment^2 etc.

However if I don't specify the groupedData object in the model, then in
the fixed effects section, it names the treatments (i.e. intercept,
treatmentcontrol, treatment6TFYM.

Should I be fitting the model using the whole data set rather than the
groupedData object?


Thank you very much for your help


Emma Pilgrim

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From faisal99 at inf.its-sby.edu  Mon Mar 21 04:15:29 2005
From: faisal99 at inf.its-sby.edu (faisal99@inf.its-sby.edu)
Date: Mon, 21 Mar 2005 10:15:29 +0700 (WIT)
Subject: [R] newbie question about beta distribution
Message-ID: <63716.202.155.84.181.1111374929.squirrel@202.155.84.178>

hi everyone,
I'm still a newbie in statistics,

I have a question about beta distribution, that is,

On the ref/tutorials I've found on the net, why beta distribution always
have value p(x) more than 1?
As I know, any probability density function always have value not more
than 1?

is there any one who can explain to me, I'm not statistics people, but I
need to code that needing some of this distribution function.

thx before



From rpeng at jhsph.edu  Sun Mar 20 07:50:53 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Sun, 20 Mar 2005 01:50:53 -0500
Subject: [R] newbie question about beta distribution
In-Reply-To: <63716.202.155.84.181.1111374929.squirrel@202.155.84.178>
References: <63716.202.155.84.181.1111374929.squirrel@202.155.84.178>
Message-ID: <423D1D4D.3060507@jhsph.edu>

A probability density must integrate to 1.  The specific values of the density 
can be either more or less than 1.

-roger

faisal99 at inf.its-sby.edu wrote:
> hi everyone,
> I'm still a newbie in statistics,
> 
> I have a question about beta distribution, that is,
> 
> On the ref/tutorials I've found on the net, why beta distribution always
> have value p(x) more than 1?
> As I know, any probability density function always have value not more
> than 1?
> 
> is there any one who can explain to me, I'm not statistics people, but I
> need to code that needing some of this distribution function.
> 
> thx before
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ggrothendieck at myway.com  Sun Mar 20 13:16:54 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 20 Mar 2005 12:16:54 +0000 (UTC)
Subject: [R] newbie question about beta distribution
References: <63716.202.155.84.181.1111374929.squirrel@202.155.84.178>
Message-ID: <loom.20050320T131324-978@post.gmane.org>

 <faisal99 <at> inf.its-sby.edu> writes:

: 
: hi everyone,
: I'm still a newbie in statistics,
: 
: I have a question about beta distribution, that is,
: 
: On the ref/tutorials I've found on the net, why beta distribution always
: have value p(x) more than 1?


Consider the uniform distribution on the interval (0, 1/a) whose 
probability density graph is a horizontal line at a.  If a > 1 then 
the probability density is greater than 1 for every point of its support
showing the the density can indeed exceed 1.

: As I know, any probability density function always have value not more
: than 1?
: 
: is there any one who can explain to me, I'm not statistics people, but I
: need to code that needing some of this distribution function.
:



From wildscop at yahoo.com  Sun Mar 20 16:46:13 2005
From: wildscop at yahoo.com (Mohammad Ehsanul Karim)
Date: Sun, 20 Mar 2005 07:46:13 -0800 (PST)
Subject: [R] "Graphics (for goodness of fit)" Question
Message-ID: <20050320154613.74360.qmail@web52608.mail.yahoo.com>

Dear List,

Suppose, I have some observed and expected
frequencies, such as following. 
I need to draw a graph where plots of observed and
expected frequencies are merged into one.
------------------------------------------------
 m <- c(1,2,3,4,5,6,7,8,9,10,12,13,17)
 k <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 19)
 ExpWW <- c(0.309330628803245, 0.213645190887434,
0.147558189649435, 0.101913922060107,
0.0703888244654489, 0.0486154051328303,
0.0335771712935674, 0.0231907237838939,
0.0160171226134196, 0.0110625360037919,
0.00764055478558038, 0.00527709716935116,
0.000395627498345897)
 ExpDD <- c(0.420249653259362, 0.243639882194748,
0.141250306182253, 0.0818899139863827,
0.0474757060281664, 0.0275240570315860,
0.0159570816077711, 0.00925112359507395,
0.00536334211198462, 0.00310939944911175,
0.00104510169329968, 0.00060589806906972,
6.84484529305126e-05)
 ObjDD <- c(0.468646864686469, 0.198019801980198,
0.151815181518152, 0.0759075907590759,
0.0396039603960396, 0.0198019801980198,
0.0165016501650165, 0.0099009900990099,
0.0033003300330033, 0.0033003300330033,
0.0033003300330033, 0.0066006600660066,
0.0033003300330033)
 ObjWW <- c(0.373770491803279, 0.150819672131148,
0.127868852459016, 0.0721311475409836,
0.0885245901639344, 0.0622950819672131,
0.039344262295082, 0.0327868852459016,
0.0360655737704918, 0.00327868852459016,
0.00655737704918033, 0.00327868852459016,
0.00327868852459016)
------------------------------------------------
  par(mfrow=c(2,2))
  plot(k,ObjWW, type="l") # Plot 1
  plot(k,ExpWW, type="l") # Plot 2
  plot(m,ObjDD, type="l") # Plot 3
  plot(m,ExpDD, type="l") # Plot 4
------------------------------------------------
# I need to see plot 1 and 2 in same axis, and plot 3
and 4 in another 
# (i.e., 3, 4 both in same axis too, but not with 1
and 2's).
# How can i use different types of legends in the same
graph??
------------------------------------------------
 sum(((ObjWW-ExpWW)^2)/ExpWW) # Chi-Squared Goodness
of Fit Test
 sum(((ObjDD-ExpDD)^2)/ExpDD) # Chi-Squared Goodness
of Fit Test
------------------------------------------------
# Also, is there any other convenient way of doing
chi-squared goodness of fit test (any function or
package may be, to do this directly)?
# And how can i find the P-values of the respective
chi-squared tests in R?
------------------------------------------------

Any suggestion, direction, references, help, replies
will be highly appreciated.

Thank you for your time.
________________________________

Mohammad Ehsanul Karim

Web: http://snipurl.com/ehsan
Institute of Statistical Reseach and Training
University of Dhaka, Dhaka - 1000, Bangladesh



From spencer.graves at pdf.com  Sun Mar 20 16:55:42 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 20 Mar 2005 07:55:42 -0800
Subject: [R] Non linear modeling
In-Reply-To: <20050318200721.57ac0cb1.secchi@sssup.it>
References: <3A822319EB35174CA3714066D590DCD50994E894@usrymx25.merck.com>
	<20050318200721.57ac0cb1.secchi@sssup.it>
Message-ID: <423D9CFE.4050402@pdf.com>

	  Another question:  What do you know or assume about the distribution 
of "e"?  If (y-x) is always positive, the survival package, especially 
the survreg function, might help you.  For this, I found especially 
helpful the discussion of this in Venables and Ripley (2002) Modern 
Applied Statistics with S, 4th ed. (Springer).  For a more thorough 
treatment of the theory (but not of R), see Meeker and Escobar (1998) 
Statistical Methods for Reliability Data (Wiley).

	  Alternatively, if you assume a distribution for "e" and assume the 
different e's are independent, write a function, say, "dev" = (-2) time 
the sum of the log density function of the e's, then give this to 
"optim" [e.g., dnorm = density function for a normal distribution; 
dweibull = density for a Weibull, etc.;  help.start() -> "An 
Introduction to R" covers probability functions and writing your own 
functions.]

	  hope this helps.
	  spencer graves

############################
      What do you want to minimize?  Can you write a function to compute
eps given x, y, and a?  Given that, you can then write another function
to compute the objective function you want to minimize.  If "a" is a
scalar, compute the objective function for a range of values of "a" and
plot.  If you want numerical precision, read the help file for "optim",
work the examples until you understand enough to see how to feed your
objective function with a starting value to "optim".

      If you still can't figure it out, please make an attempt, then
read the posting guide "http://www.R-project.org/posting-guide.html",
and prepare a follow-up question as needed.  (In a discussion on and off
this list earlier this week, several people confirmed that they had
solved many problems following this posting guide.  It may not be as
good as Polya's famous "How to Solve It", but it's pretty good.)

      hope this helps.
      spencer graves

Angelo Secchi wrote:

>You are right. eps in my model is not a parameter but the error term.
>Also the linearization doesn't solve the problem, since sometimes you
>cannot take logs. Any other ideas?
>Thanks
>
>
>On Fri, 18 Mar 2005 11:21:12 -0500
>"Liaw, Andy" <andy_liaw at merck.com> wrote:
>
>  
>
>>That's treating eps as a parameter in the model.  If I read your question
>>right, that's not what you want.  
>>
>>Andy
>>
>>    
>>
>>>From: ronggui [mailto:0034058 at fudan.edu.cn] 
>>>
>>>then is the nls function can deal the problem as Guillaume 
>>>STORCHI mentioned in the last post? [X<-nls(y~x+exp(a*x)*eps, 
>>>data=,start=list(a=,eps=))]
>>>or just can solve the problem as:log(y-x) = a*x + e?
>>>
>>>
>>>
>>>On Fri, 18 Mar 2005 08:56:38 -0500
>>>"Liaw, Andy" <andy_liaw at merck.com> wrote:
>>>
>>>      
>>>
>>>>AFAIK most model fitting techniques will only deal with 
>>>>        
>>>>
>>>additive errors, not
>>>      
>>>
>>>>multiplicative ones.  You might want to try fitting:
>>>>
>>>>log(y-x) = a*x + e
>>>>
>>>>which is linear.
>>>>
>>>>Andy
>>>>
>>>>        
>>>>
>>>>>From: Angelo Secchi
>>>>>
>>>>>Hi,
>>>>>is there a way  in R to fit a non linear model like
>>>>>
>>>>>y=x+exp(a*x)*eps
>>>>>
>>>>>where a is the parameter and eps is the error term? 
>>>>>Thanks
>>>>>Angelo
>>>>>
>>>>>______________________________________________
>>>>>R-help at stat.math.ethz.ch mailing list
>>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>PLEASE do read the posting guide! 
>>>>>http://www.R-project.org/posting-guide.html
>>>>>
>>>>>
>>>>>
>>>>>          
>>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide! 
>>>>        
>>>>
>>>http://www.R-project.org/posting-guide.html
>>>
>>>
>>>
>>>      
>>>
>>
>>------------------------------------------------------------------------------
>>Notice:  This e-mail message, together with any attachment...{{dropped}}
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From Ted.Harding at nessie.mcc.ac.uk  Sun Mar 20 17:09:11 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sun, 20 Mar 2005 16:09:11 -0000 (GMT)
Subject: [R] Using locator() to digitise
Message-ID: <XFMail.050320160911.Ted.Harding@nessie.mcc.ac.uk>

Hi Folks,

I'm contemplating using locator() to digitise external
graphics. To set context, I would be using X11 display
on Linux.

To pre-empt the obvious comment: I've found on the R site
the suggestion to use the 'pixmap' package. I've tried
this, and it works; but it involves building a big R
object (the internal pixmap representation), and this
chokes my somewhat puny laptop (e.g. it can take about
1 minute to draw the graphic inside a plot area using
addlogo(), with mucho swappo, and subsequently working
knee-deep in treacle). The following idea would be a lot
slicker.

For examples: I have something like

a) A scatterplot of data printed in a journal (but the
   data values are not available;

b) A contour map (on paper) of a region.

So, I can scan the document, and obtain a file in some
graphics format (jpeg, pbm or png, say).

Now: an idea which I find attractive is to be able to
overlay an R plot with axes onto a display of the graphics
file (produced as an X window by any suitable program such
as 'xv' or 'display') so that (if the overlay were possible)
clicking on the points of the graphic would in fact be
clicking on the R plot and, via locator(), generate the
R-plot coordinates of the mouse clicks which would correspond
to the selected points on the graphic.

Provided the coordinate system of the R plot were properly
related to the graphic, the results would be a digitisation
of the selected points on the graphic.

What seems to be needed for this idea to work is that
the R-plot should be displayed in an X11() device whose
background was completely transparent, so that when
moved over the (independently generated) display of the
graphic the latter would be visible (but locator() would
still be working on the R-plot itself). Window resizing
could look after the correspondence between graphic coordinates
and R-plot coordinates.

The R plot itself could be empty (apart from coordinate axes)
or could contain "helper" elements such as grid lines, circles
(e.g. I want to digitise graphics points within a certain circle),
etc. "Helper" elements could be added to the R-plot by subsequent
'lines' or 'points' commands (e.g. I identify two points on
the graphic, R-plot the line joining them, and then pick off
graphic-points which lie on the R-line).

So this question is really about producing a "bare" R plot
on, as it were, a virtual acrylic transparency. It's certainly
possible to do such a thing in X: e.g. the cute "xteddy" is
in fact a picture of a bear on a completely transparent
rectangular background, though you'd never know by looking!

Any comments?

With thanks, and best wishes to all,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 20-Mar-05                                       Time: 16:09:11
------------------------------ XFMail ------------------------------



From W.E.Wolski at ncl.ac.uk  Sun Mar 20 19:32:58 2005
From: W.E.Wolski at ncl.ac.uk (Witold Eryk Wolski)
Date: Sun, 20 Mar 2005 19:32:58 +0100
Subject: [R] Interaction term in anova - how it should be written in a
 manuscript table?
Message-ID: <423DC1DA.7050109@ncl.ac.uk>

Dear Rgurus,

Interaction terms in the linear models function lm are specified by the 
colon :
eg: x ~ a + b + a:b

a shortcut for the above is:
 x ~ a*b

the output if calling anova on the lm object will be the same in both cases

a ....
b ....
a:b ...
Resdiuals ...

What I am wondering is how the interaction term (a:b) given above should 
be written in a table in an manuscript?

a ) a*b
b ) a$\cdot$ b
c ) a:b
d) ....

Cheers Eryk.



From spencer.graves at pdf.com  Sun Mar 20 20:22:29 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 20 Mar 2005 11:22:29 -0800
Subject: [R] Interaction term in anova - how it should be written in a
	manuscript table?
In-Reply-To: <423DC1DA.7050109@ncl.ac.uk>
References: <423DC1DA.7050109@ncl.ac.uk>
Message-ID: <423DCD75.6010001@pdf.com>

Hi, Eryk: 

      What is the target journal(s) / audience(s) for your work?  Can 
you find recent publications in that field and copy them? 

      hope this helps.  spencer graves

Witold Eryk Wolski wrote:

> Dear Rgurus,
>
> Interaction terms in the linear models function lm are specified by 
> the colon :
> eg: x ~ a + b + a:b
>
> a shortcut for the above is:
> x ~ a*b
>
> the output if calling anova on the lm object will be the same in both 
> cases
>
> a ....
> b ....
> a:b ...
> Resdiuals ...
>
> What I am wondering is how the interaction term (a:b) given above 
> should be written in a table in an manuscript?
>
> a ) a*b
> b ) a$\cdot$ b
> c ) a:b
> d) ....
>
> Cheers Eryk.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Sun Mar 20 21:44:58 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sun, 20 Mar 2005 15:44:58 -0500
Subject: [R] Interaction term in anova - how it should be written in
	a manuscript table?
Message-ID: <3A822319EB35174CA3714066D590DCD50994E8A2@usrymx25.merck.com>

I'd suggest a $\times$ b, as you'd find in most stat textbook.

Andy

> From: Witold Eryk Wolski
> 
> Dear Rgurus,
> 
> Interaction terms in the linear models function lm are 
> specified by the 
> colon :
> eg: x ~ a + b + a:b
> 
> a shortcut for the above is:
>  x ~ a*b
> 
> the output if calling anova on the lm object will be the same 
> in both cases
> 
> a ....
> b ....
> a:b ...
> Resdiuals ...
> 
> What I am wondering is how the interaction term (a:b) given 
> above should 
> be written in a table in an manuscript?
> 
> a ) a*b
> b ) a$\cdot$ b
> c ) a:b
> d) ....
> 
> Cheers Eryk.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From MSchwartz at MedAnalytics.com  Sun Mar 20 22:22:09 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Sun, 20 Mar 2005 15:22:09 -0600
Subject: [R] Interaction term in anova - how it should be written in a
	manuscript table?
In-Reply-To: <3A822319EB35174CA3714066D590DCD50994E8A2@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50994E8A2@usrymx25.merck.com>
Message-ID: <1111353729.5550.13.camel@horizons.localdomain>

For a me too post, I agree with Andy's recommendation, which in turn is
supported by "How to Report Statistics in Medicine" by Lang and Secic,
ACP, 1997. There is an example table (8.2) on page 133.

HTH,

Marc Schwartz

On Sun, 2005-03-20 at 15:44 -0500, Liaw, Andy wrote:
> I'd suggest a $\times$ b, as you'd find in most stat textbook.
> 
> Andy
> 
> > From: Witold Eryk Wolski
> > 
> > Dear Rgurus,
> > 
> > Interaction terms in the linear models function lm are 
> > specified by the 
> > colon :
> > eg: x ~ a + b + a:b
> > 
> > a shortcut for the above is:
> >  x ~ a*b
> > 
> > the output if calling anova on the lm object will be the same 
> > in both cases
> > 
> > a ....
> > b ....
> > a:b ...
> > Resdiuals ...
> > 
> > What I am wondering is how the interaction term (a:b) given 
> > above should 
> > be written in a table in an manuscript?
> > 
> > a ) a*b
> > b ) a$\cdot$ b
> > c ) a:b
> > d) ....
> > 
> > Cheers Eryk.
> >



From tomhopper at comcast.net  Sun Mar 20 23:23:55 2005
From: tomhopper at comcast.net (Thomas Hopper)
Date: Sun, 20 Mar 2005 17:23:55 -0500
Subject: [R] Generating Interaction Factors (combinations of Data Frame
	columns)
Message-ID: <39c075e4a56c15e4c3270d6f007a44d9@comcast.net>

I'm starting to do a fair amount of DOE in my day job and need to 
generate full- and fractional-factorial designs.

One of the things I'd like to do is generate all possible interaction 
effects, given the main effects. I've been searching through the 
documentation, packages and mail list archives, but the closest I can 
find are combin() in package combinat and combine() and combinations() 
in gregsmisc, none of which actually produces the results I want.

Given a data frame with columns labeled A, B, C and D, I would like to 
generate a data frame with columns that are the combination of each of 
the columns in the original data frame. The output columns would be 
A*B, A*C, A*D, A*E, A*B*C, A*B*D,..., A*B*C*D.

Alternatively, I'd want to generate the interactions for a given level 
(2-factor or 3-factor).

If such a function already exists, I'd be more than happy to use it.

If it doesn't, I can write it, but I would appreciate a little help 
with the algorithm for generating the combinations...how do I loop 
through the given factors to generate all possible combinations?

Thanks,

Tom



From uofiowa at gmail.com  Sun Mar 20 23:25:46 2005
From: uofiowa at gmail.com (Omar Lakkis)
Date: Sun, 20 Mar 2005 17:25:46 -0500
Subject: [R] install package on windows
Message-ID: <3f87cc6d050320142547046470@mail.gmail.com>

I created a package using R CMd build and I do have a .tar.gz fine
now. The package was created on a Linux box. A co-worker needs to
install this package on his Windows machine. How can he do that?
When I tried to install it on his box from a cygwin shell using R CMD
INSTALL perl complained that Dcf.pm was not in the path. Do I need to
install anything?
When I tried installing it from the GUI by choosing install local
package it complained about not being able from the zipped file.

Help is appreciated.



From rolf at math.unb.ca  Sun Mar 20 23:34:38 2005
From: rolf at math.unb.ca (Rolf Turner)
Date: Sun, 20 Mar 2005 18:34:38 -0400 (AST)
Subject: [R] Generating Interaction Factors (combinations of Data Frame
	columns)
Message-ID: <200503202234.j2KMYcYO001169@erdos.math.unb.ca>


?model.matrix



From brett at hbrc.govt.nz  Mon Mar 21 05:10:11 2005
From: brett at hbrc.govt.nz (Brett Stansfield)
Date: Mon, 21 Mar 2005 16:10:11 +1200
Subject: [R] NaN
Message-ID: <3542A1BF5AE1984D9FF577DA2CF8BA9868B13A@MSX2>

Dear R
What does NaN mean?
I recently did a correlation on a batch of data for some reason it didn't
like one column
cor(sleep,use="complete.obs")
                 BodyWt     BrainWt  SlowSleep   ParaSleep TotalSleep
BodyWt       1.00000000  0.95584875 -0.3936373 -0.07488845 -0.3428373
BrainWt      0.95584875  1.00000000 -0.3867947 -0.07427740 -0.3370815
SlowSleep   -0.39363729 -0.38679474  1.0000000  0.51824287  0.9676730
ParaSleep   -0.07488845 -0.07427740  0.5182429  1.00000000  0.7171864
TotalSleep  -0.34283732 -0.33708151  0.9676730  0.71718643  1.0000000
Lifespan     0.46982146  0.62938940 -0.3722345 -0.26834006 -0.3824462
Gestation    0.71434413  0.73353206 -0.6061048 -0.40893177 -0.6144743
PredIndex    0.09588524 -0.01538017 -0.3526558 -0.39795310 -0.4047155
ExposeIndex  0.40563880  0.32318968 -0.5802789 -0.50363338 -0.6213578
DangerIndex  0.25932512  0.15093686 -0.5346247 -0.57194862 -0.6043029
logbrw       0.47461094  0.53992522 -0.6302266 -0.36884187 -0.6223073
loglife      0.37351520  0.45819097 -0.3549184 -0.38521174 -0.4028017
loggest      0.41308558  0.45045240 -0.5754478 -0.57234786 -0.6376850
logbw        0.50905390  0.52255094 -0.6603217 -0.26930774 -0.6174775
logpara             NaN         NaN        NaN         NaN        NaN
               Lifespan   Gestation   PredIndex ExposeIndex DangerIndex
BodyWt       0.46982146  0.71434413  0.09588524   0.4056388  0.25932512
BrainWt      0.62938940  0.73353206 -0.01538017   0.3231897  0.15093686
SlowSleep   -0.37223446 -0.60610477 -0.35265576  -0.5802789 -0.53462471
ParaSleep   -0.26834006 -0.40893177 -0.39795310  -0.5036334 -0.57194862
TotalSleep  -0.38244618 -0.61447431 -0.40471545  -0.6213578 -0.60430286
Lifespan     1.00000000  0.64638866 -0.16973575   0.3157456  0.01468596
Gestation    0.64638866  1.00000000  0.09079823   0.5734727  0.30623551
PredIndex   -0.16973575  0.09079823  1.00000000   0.6256876  0.92731729
ExposeIndex  0.31574564  0.57347265  0.62568764   1.0000000  0.78980702
DangerIndex  0.01468596  0.30623551  0.92731729   0.7898070  1.00000000
logbrw       0.73584286  0.78178948  0.07112786   0.6132218  0.28600619
loglife      0.87677362  0.63260838 -0.09023386   0.5042496  0.14082719
loggest      0.56014783  0.88539870  0.09040680   0.5830778  0.30998808
logbw        0.64683285  0.75938272  0.13046983   0.6473671  0.33957121
logpara             NaN         NaN         NaN         NaN         NaN
                 logbrw     loglife    loggest      logbw logpara
BodyWt       0.47461094  0.37351520  0.4130856  0.5090539     NaN
BrainWt      0.53992522  0.45819097  0.4504524  0.5225509     NaN
SlowSleep   -0.63022657 -0.35491836 -0.5754478 -0.6603217     NaN
ParaSleep   -0.36884187 -0.38521174 -0.5723479 -0.2693077     NaN
TotalSleep  -0.62230729 -0.40280169 -0.6376850 -0.6174775     NaN
Lifespan     0.73584286  0.87677362  0.5601478  0.6468328     NaN
Gestation    0.78178948  0.63260838  0.8853987  0.7593827     NaN
PredIndex    0.07112786 -0.09023386  0.0904068  0.1304698     NaN
ExposeIndex  0.61322176  0.50424965  0.5830778  0.6473671     NaN
DangerIndex  0.28600619  0.14082719  0.3099881  0.3395712     NaN
logbrw       1.00000000  0.79233406  0.7771888  0.9514144     NaN
loglife      0.79233406  1.00000000  0.6417551  0.7079108     NaN
loggest      0.77718882  0.64175514  1.0000000  0.7069276     NaN
logbw        0.95141435  0.70791078  0.7069276  1.0000000     NaN
logpara             NaN         NaN        NaN        NaN       1

for some reason log para has this NaN symbol come up



From billk at fastmail.fm  Mon Mar 21 05:15:45 2005
From: billk at fastmail.fm (Bill Kranec)
Date: Sun, 20 Mar 2005 23:15:45 -0500 (Eastern Standard Time)
Subject: [R] Force labelling of x-axis
Message-ID: <Pine.WNT.4.62.0503202309390.3388@Desktop>

Hi,

I'm trying to do a box-whisker plot of two columns of a data frame, a
list of category names in one column vs. some numerical values in the
other.  The plot itself works fine, but only a few points of the x-axis
( the category names ) are labelled.  I think that this is because the
category names are too long.

Is there any way to force R to label each x-axis value, preferably at a
45-degree slant so that each one can be seen?  I feel like this should be
pretty easy to do, but I can't find anything obvious from the R-manual.

Thanks for any help,

Bill



From bitwrit at ozemail.com.au  Mon Mar 21 06:23:00 2005
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Mon, 21 Mar 2005 16:23:00 +1100
Subject: [R] Force labelling of x-axis
In-Reply-To: <Pine.WNT.4.62.0503202309390.3388@Desktop>
References: <Pine.WNT.4.62.0503202309390.3388@Desktop>
Message-ID: <423E5A34.6060804@ozemail.com.au>

Bill Kranec wrote:
> Hi,
> 
> I'm trying to do a box-whisker plot of two columns of a data frame, a
> list of category names in one column vs. some numerical values in the
> other.  The plot itself works fine, but only a few points of the x-axis
> ( the category names ) are labelled.  I think that this is because the
> category names are too long.
> 
> Is there any way to force R to label each x-axis value, preferably at a
> 45-degree slant so that each one can be seen?  I feel like this should be
> pretty easy to do, but I can't find anything obvious from the R-manual.
> 
> Thanks for any help,
> 
> Bill
> 
You might find the "staxlab" function in the "plotrix" package helpful.

Jim



From rog at stanford.edu  Mon Mar 21 06:21:49 2005
From: rog at stanford.edu (Roger Levy)
Date: 20 Mar 2005 21:21:49 -0800
Subject: [R] anomalous result for wilcox.exact in exactRankTests
Message-ID: <25fyypk1zm.fsf@joel.Stanford.EDU>

Hi,

In the exactRankTest package, I've become aware that you can get
anomalous p-values (i.e., above 1) from the wilcox.exact method, as in:

  > wilcox.exact(c(-0.6,0.8,-0.5))

        Exact Wilcoxon signed rank test

  data:  c(-0.6, 0.8, -0.5) 
  V = 3, p-value = 1.25
  alternative hypothesis: true mu is not equal to 0 

This is disturbing.  Has anyone encountered this before, and if so is
there an obvious reason why this should happen?

Thanks,

Roger



From renaud.lancelot at cirad.fr  Mon Mar 21 06:34:07 2005
From: renaud.lancelot at cirad.fr (Renaud Lancelot)
Date: Mon, 21 Mar 2005 08:34:07 +0300
Subject: [R] Force labelling of x-axis
In-Reply-To: <Pine.WNT.4.62.0503202309390.3388@Desktop>
References: <Pine.WNT.4.62.0503202309390.3388@Desktop>
Message-ID: <423E5CCF.20701@cirad.fr>

Bill Kranec a ?crit :

> Hi,
> 
> I'm trying to do a box-whisker plot of two columns of a data frame, a
> list of category names in one column vs. some numerical values in the
> other.  The plot itself works fine, but only a few points of the x-axis
> ( the category names ) are labelled.  I think that this is because the
> category names are too long.
> 
> Is there any way to force R to label each x-axis value, preferably at a
> 45-degree slant so that each one can be seen?  I feel like this should be
> pretty easy to do, but I can't find anything obvious from the R-manual.
> 
> Thanks for any help,
> 
> Bill
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

For example:

test <- data.frame(
           y = rnorm(120),
           x = rep(month.name, each = 100))
library(lattice)
bwplot(y ~ x, data = test, scales = list(x = list(rot = 45)))

Best,

Renaud

-- 
Dr Renaud Lancelot, v?t?rinaire
C/0 Ambassade de France - SCAC
BP 834 Antananarivo 101 - Madagascar

e-mail: renaud.lancelot at cirad.fr
tel.:   +261 32 40 165 53 (cell)
         +261 20 22 665 36 ext. 225 (work)
         +261 20 22 494 37 (home)



From rashmimathur at shaw.ca  Mon Mar 21 07:12:52 2005
From: rashmimathur at shaw.ca (Rashmi Mathur)
Date: Sun, 20 Mar 2005 22:12:52 -0800
Subject: [R] reading in vectors from text files
Message-ID: <001401c52ddd$07116510$583b5418@RashmisComputer>

Hello,

I am trying to read in a file of data using read.table(), in which the
data in one column is vectors.

The format of the file is as follows -


FirstName	LastName	no.Children		children.ages
Sally		James		3			c(3,5,7)
John		Smith		2			c(13,16)
Betsy		Harold	6			c(2,5,8,12,15,17)


How do I specify that the children.ages column contains vector data, and
that each vector is of a different length when reading in this text
file?

Thanks in advance,
Rashmi



From POPEA at stgeorge.com.au  Mon Mar 21 07:23:42 2005
From: POPEA at stgeorge.com.au (Alun Pope)
Date: Mon, 21 Mar 2005 17:23:42 +1100
Subject: [R] Sweave/margin
Message-ID: <s23f032b.086@stgeorge.com.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050321/ebc41e67/attachment.pl

From gooty at mail1.pknu.ac.kr  Mon Mar 21 07:43:48 2005
From: gooty at mail1.pknu.ac.kr (Tae-Young Goo)
Date: Mon, 21 Mar 2005 15:43:48 +0900
Subject: [R] [R-help] install problem
Message-ID: <002701c52de1$565e4f80$fb727dd2@GOOTY>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050321/3a33d32b/attachment.pl

From Tom.Mulholland at dpi.wa.gov.au  Mon Mar 21 07:45:35 2005
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Mon, 21 Mar 2005 14:45:35 +0800
Subject: [R] NaN
Message-ID: <33F91FB3FDF42E4180428AC66A5CF30B02D3C9D0@afhex01.dpi.wa.gov.au>

type ?NaN and the help will tell you.



> -----Original Message-----
> From: Brett Stansfield [mailto:brett at hbrc.govt.nz]
> Sent: Monday, 21 March 2005 12:10 PM
> To: R help (E-mail)
> Subject: [R] NaN
> 
> 
> Dear R
> What does NaN mean?
> I recently did a correlation on a batch of data for some 
> reason it didn't
> like one column
> cor(sleep,use="complete.obs")
>                  BodyWt     BrainWt  SlowSleep   ParaSleep TotalSleep
> BodyWt       1.00000000  0.95584875 -0.3936373 -0.07488845 -0.3428373
> BrainWt      0.95584875  1.00000000 -0.3867947 -0.07427740 -0.3370815
> SlowSleep   -0.39363729 -0.38679474  1.0000000  0.51824287  0.9676730
> ParaSleep   -0.07488845 -0.07427740  0.5182429  1.00000000  0.7171864
> TotalSleep  -0.34283732 -0.33708151  0.9676730  0.71718643  1.0000000
> Lifespan     0.46982146  0.62938940 -0.3722345 -0.26834006 -0.3824462
> Gestation    0.71434413  0.73353206 -0.6061048 -0.40893177 -0.6144743
> PredIndex    0.09588524 -0.01538017 -0.3526558 -0.39795310 -0.4047155
> ExposeIndex  0.40563880  0.32318968 -0.5802789 -0.50363338 -0.6213578
> DangerIndex  0.25932512  0.15093686 -0.5346247 -0.57194862 -0.6043029
> logbrw       0.47461094  0.53992522 -0.6302266 -0.36884187 -0.6223073
> loglife      0.37351520  0.45819097 -0.3549184 -0.38521174 -0.4028017
> loggest      0.41308558  0.45045240 -0.5754478 -0.57234786 -0.6376850
> logbw        0.50905390  0.52255094 -0.6603217 -0.26930774 -0.6174775
> logpara             NaN         NaN        NaN         NaN        NaN
>                Lifespan   Gestation   PredIndex ExposeIndex 
> DangerIndex
> BodyWt       0.46982146  0.71434413  0.09588524   0.4056388  
> 0.25932512
> BrainWt      0.62938940  0.73353206 -0.01538017   0.3231897  
> 0.15093686
> SlowSleep   -0.37223446 -0.60610477 -0.35265576  -0.5802789 
> -0.53462471
> ParaSleep   -0.26834006 -0.40893177 -0.39795310  -0.5036334 
> -0.57194862
> TotalSleep  -0.38244618 -0.61447431 -0.40471545  -0.6213578 
> -0.60430286
> Lifespan     1.00000000  0.64638866 -0.16973575   0.3157456  
> 0.01468596
> Gestation    0.64638866  1.00000000  0.09079823   0.5734727  
> 0.30623551
> PredIndex   -0.16973575  0.09079823  1.00000000   0.6256876  
> 0.92731729
> ExposeIndex  0.31574564  0.57347265  0.62568764   1.0000000  
> 0.78980702
> DangerIndex  0.01468596  0.30623551  0.92731729   0.7898070  
> 1.00000000
> logbrw       0.73584286  0.78178948  0.07112786   0.6132218  
> 0.28600619
> loglife      0.87677362  0.63260838 -0.09023386   0.5042496  
> 0.14082719
> loggest      0.56014783  0.88539870  0.09040680   0.5830778  
> 0.30998808
> logbw        0.64683285  0.75938272  0.13046983   0.6473671  
> 0.33957121
> logpara             NaN         NaN         NaN         NaN   
>       NaN
>                  logbrw     loglife    loggest      logbw logpara
> BodyWt       0.47461094  0.37351520  0.4130856  0.5090539     NaN
> BrainWt      0.53992522  0.45819097  0.4504524  0.5225509     NaN
> SlowSleep   -0.63022657 -0.35491836 -0.5754478 -0.6603217     NaN
> ParaSleep   -0.36884187 -0.38521174 -0.5723479 -0.2693077     NaN
> TotalSleep  -0.62230729 -0.40280169 -0.6376850 -0.6174775     NaN
> Lifespan     0.73584286  0.87677362  0.5601478  0.6468328     NaN
> Gestation    0.78178948  0.63260838  0.8853987  0.7593827     NaN
> PredIndex    0.07112786 -0.09023386  0.0904068  0.1304698     NaN
> ExposeIndex  0.61322176  0.50424965  0.5830778  0.6473671     NaN
> DangerIndex  0.28600619  0.14082719  0.3099881  0.3395712     NaN
> logbrw       1.00000000  0.79233406  0.7771888  0.9514144     NaN
> loglife      0.79233406  1.00000000  0.6417551  0.7079108     NaN
> loggest      0.77718882  0.64175514  1.0000000  0.7069276     NaN
> logbw        0.95141435  0.70791078  0.7069276  1.0000000     NaN
> logpara             NaN         NaN        NaN        NaN       1
> 
> for some reason log para has this NaN symbol come up
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Mon Mar 21 08:22:09 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 21 Mar 2005 08:22:09 +0100
Subject: [R] install package on windows
In-Reply-To: <3f87cc6d050320142547046470@mail.gmail.com>
References: <3f87cc6d050320142547046470@mail.gmail.com>
Message-ID: <423E7621.9020006@statistik.uni-dortmund.de>

Omar Lakkis wrote:

> I created a package using R CMd build and I do have a .tar.gz fine
> now. The package was created on a Linux box. A co-worker needs to
> install this package on his Windows machine. How can he do that?
> When I tried to install it on his box from a cygwin shell using R CMD
> INSTALL perl complained that Dcf.pm was not in the path. Do I need to
> install anything?
> When I tried installing it from the GUI by choosing install local
> package it complained about not being able from the zipped file.
> 
> Help is appreciated.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Please read the R for Windows FAQ "Can I install packages into libraries 
in this version?".

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Mon Mar 21 08:29:33 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 21 Mar 2005 08:29:33 +0100
Subject: [R] reading in vectors from text files
In-Reply-To: <001401c52ddd$07116510$583b5418@RashmisComputer>
References: <001401c52ddd$07116510$583b5418@RashmisComputer>
Message-ID: <423E77DD.4070601@statistik.uni-dortmund.de>

Rashmi Mathur wrote:

> Hello,
> 
> I am trying to read in a file of data using read.table(), in which the
> data in one column is vectors.
> 
> The format of the file is as follows -
> 
> 
> FirstName	LastName	no.Children		children.ages
> Sally		James		3			c(3,5,7)
> John		Smith		2			c(13,16)
> Betsy		Harold	6			c(2,5,8,12,15,17)
> 
> 
> How do I specify that the children.ages column contains vector data, and
> that each vector is of a different length when reading in this text
> file?

You might want to read the column as character, parse it afterwards, and 
convert your data structure into a list which seems more appropriate to 
represent the data.

Uwe Ligges


> Thanks in advance,
> Rashmi
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From mkondrin at hppi.troitsk.ru  Mon Mar 21 05:38:08 2005
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Mon, 21 Mar 2005 07:38:08 +0300
Subject: [R] Using locator() to digitise
In-Reply-To: <XFMail.050320160911.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.050320160911.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <423E4FB0.3060502@hppi.troitsk.ru>

(Ted Harding) wrote:

>Hi Folks,
>
>I'm contemplating using locator() to digitise external
>graphics. To set context, I would be using X11 display
>on Linux.
>  
>
Hi, Ted!
Beside searching for specialized packages, I would suggest you to try my 
package RImgViewer  which uses Gtk2 library to import and display images 
in R-session. It is  not available on CRAN because it depends on two 
other packages (RGtk2 and GdkDrawing) which conflict with Duncan T. Lang 
RGtk package. All of them can be downloaded from my homepage 
(www.hppi.troitsk.ru/Kondrin/r_img_viewer_html.html , 
www.hppi.troitsk.ru/Kondrin ). It is mainly untested (except by me) and 
I hope you would send me bug-reports if you find the package worth it.
For your purposes this package can be used in this way. You can use the 
image viewer to import and display your scanned image (because 
RImgViewer use specialized widget for image displaying it is quite 
fast). Then you can convert displayed graphics into R-array and with 
markers provided by RImgViewer select region of interest. In your case 
it could be selecting axii' directions. From coordinates of this markers 
you can construct rotation matrix and calculate  true coordinates of 
each point from its array indexes. The coordinates of  drawn curves are 
the coordinates of points with values  0 (i.e.black). I usually digitize 
the whole picture and then use R to delete points which I do not need 
and to smooth the rest.
Hope this helps.

>To pre-empt the obvious comment: I've found on the R site
>the suggestion to use the 'pixmap' package. I've tried
>this, and it works; but it involves building a big R
>object (the internal pixmap representation), and this
>chokes my somewhat puny laptop (e.g. it can take about
>1 minute to draw the graphic inside a plot area using
>addlogo(), with mucho swappo, and subsequently working
>knee-deep in treacle). The following idea would be a lot
>slicker.
>
>For examples: I have something like
>
>a) A scatterplot of data printed in a journal (but the
>   data values are not available;
>
>b) A contour map (on paper) of a region.
>
>So, I can scan the document, and obtain a file in some
>graphics format (jpeg, pbm or png, say).
>
>Now: an idea which I find attractive is to be able to
>overlay an R plot with axes onto a display of the graphics
>file (produced as an X window by any suitable program such
>as 'xv' or 'display') so that (if the overlay were possible)
>clicking on the points of the graphic would in fact be
>clicking on the R plot and, via locator(), generate the
>R-plot coordinates of the mouse clicks which would correspond
>to the selected points on the graphic.
>
>Provided the coordinate system of the R plot were properly
>related to the graphic, the results would be a digitisation
>of the selected points on the graphic.
>
>What seems to be needed for this idea to work is that
>the R-plot should be displayed in an X11() device whose
>background was completely transparent, so that when
>moved over the (independently generated) display of the
>graphic the latter would be visible (but locator() would
>still be working on the R-plot itself). Window resizing
>could look after the correspondence between graphic coordinates
>and R-plot coordinates.
>
>The R plot itself could be empty (apart from coordinate axes)
>or could contain "helper" elements such as grid lines, circles
>(e.g. I want to digitise graphics points within a certain circle),
>etc. "Helper" elements could be added to the R-plot by subsequent
>'lines' or 'points' commands (e.g. I identify two points on
>the graphic, R-plot the line joining them, and then pick off
>graphic-points which lie on the R-line).
>
>So this question is really about producing a "bare" R plot
>on, as it were, a virtual acrylic transparency. It's certainly
>possible to do such a thing in X: e.g. the cute "xteddy" is
>in fact a picture of a bear on a completely transparent
>rectangular background, though you'd never know by looking!
>
>Any comments?
>
>With thanks, and best wishes to all,
>Ted.
>
>
>--------------------------------------------------------------------
>E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
>Fax-to-email: +44 (0)870 094 0861
>Date: 20-Mar-05                                       Time: 16:09:11
>------------------------------ XFMail ------------------------------
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From W.E.Wolski at ncl.ac.uk  Mon Mar 21 10:03:21 2005
From: W.E.Wolski at ncl.ac.uk (Witold Eryk Wolski)
Date: Mon, 21 Mar 2005 10:03:21 +0100
Subject: [R] Interaction term in anova - how it should be written in a
	manuscript table?
In-Reply-To: <1111353729.5550.13.camel@horizons.localdomain>
References: <3A822319EB35174CA3714066D590DCD50994E8A2@usrymx25.merck.com>
	<1111353729.5550.13.camel@horizons.localdomain>
Message-ID: <423E8DD9.3090204@ncl.ac.uk>

Thanks a lot

cheers
Eryk

Marc Schwartz wrote:

>For a me too post, I agree with Andy's recommendation, which in turn is
>supported by "How to Report Statistics in Medicine" by Lang and Secic,
>ACP, 1997. There is an example table (8.2) on page 133.
>
>HTH,
>
>Marc Schwartz
>
>On Sun, 2005-03-20 at 15:44 -0500, Liaw, Andy wrote:
>  
>
>>I'd suggest a $\times$ b, as you'd find in most stat textbook.
>>
>>Andy
>>
>>    
>>
>>>From: Witold Eryk Wolski
>>>
>>>Dear Rgurus,
>>>
>>>Interaction terms in the linear models function lm are 
>>>specified by the 
>>>colon :
>>>eg: x ~ a + b + a:b
>>>
>>>a shortcut for the above is:
>>> x ~ a*b
>>>
>>>the output if calling anova on the lm object will be the same 
>>>in both cases
>>>
>>>a ....
>>>b ....
>>>a:b ...
>>>Resdiuals ...
>>>
>>>What I am wondering is how the interaction term (a:b) given 
>>>above should 
>>>be written in a table in an manuscript?
>>>
>>>a ) a*b
>>>b ) a$\cdot$ b
>>>c ) a:b
>>>d) ....
>>>
>>>Cheers Eryk.
>>>
>>>      
>>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>


-- 
Witold Eryk Wolski
__("<  School of Mathematics and Statistics     _
\__/   University of Newcastle                 'v'
 ||    Newcastle upon Tyne, NE1 7RU, ENGLAND  /   \
 ^^    mail: witek96 at users.sourceforge.net     m m
       Phone : 044 (0)191 222 5376
       FAX   : 044 (0)191 222 8020



From sb at ihe.se  Mon Mar 21 10:05:57 2005
From: sb at ihe.se (Sixten Borg)
Date: Mon, 21 Mar 2005 10:05:57 +0100
Subject: Sv: [R] Using locator() to digitise
Message-ID: <s23e9cab.032@gwmail.ihe.se>

Hi,
Splus allows pasting a graphics object into the plotting window, which makes it possible to do what you describe below.
Now I use R which doesn't seem to allow pasting the picture into the graphics window, so I copy the graph onto a transparency 
sheet, and stick it onto my screen using tape. The coordinates need to be converted to make sense (as you describe).

My methodology with the transparency has a "stoneage" appearance, but it works quite well, if I may say so myself.

I have written down some notes that describes what I did, but it's in Swedish so I guess it's not of much help.

Kind regards,
Sixten.


>>> Ted Harding <Ted.Harding at nessie.mcc.ac.uk> 2005-03-20 17:09 >>>
Hi Folks,

I'm contemplating using locator() to digitise external
graphics. To set context, I would be using X11 display
on Linux.

To pre-empt the obvious comment: I've found on the R site
the suggestion to use the 'pixmap' package. I've tried
this, and it works; but it involves building a big R
object (the internal pixmap representation), and this
chokes my somewhat puny laptop (e.g. it can take about
1 minute to draw the graphic inside a plot area using
addlogo(), with mucho swappo, and subsequently working
knee-deep in treacle). The following idea would be a lot
slicker.

For examples: I have something like

a) A scatterplot of data printed in a journal (but the
   data values are not available;

b) A contour map (on paper) of a region.

So, I can scan the document, and obtain a file in some
graphics format (jpeg, pbm or png, say).

Now: an idea which I find attractive is to be able to
overlay an R plot with axes onto a display of the graphics
file (produced as an X window by any suitable program such
as 'xv' or 'display') so that (if the overlay were possible)
clicking on the points of the graphic would in fact be
clicking on the R plot and, via locator(), generate the
R-plot coordinates of the mouse clicks which would correspond
to the selected points on the graphic.

Provided the coordinate system of the R plot were properly
related to the graphic, the results would be a digitisation
of the selected points on the graphic.

What seems to be needed for this idea to work is that
the R-plot should be displayed in an X11() device whose
background was completely transparent, so that when
moved over the (independently generated) display of the
graphic the latter would be visible (but locator() would
still be working on the R-plot itself). Window resizing
could look after the correspondence between graphic coordinates
and R-plot coordinates.

The R plot itself could be empty (apart from coordinate axes)
or could contain "helper" elements such as grid lines, circles
(e.g. I want to digitise graphics points within a certain circle),
etc. "Helper" elements could be added to the R-plot by subsequent
'lines' or 'points' commands (e.g. I identify two points on
the graphic, R-plot the line joining them, and then pick off
graphic-points which lie on the R-line).

So this question is really about producing a "bare" R plot
on, as it were, a virtual acrylic transparency. It's certainly
possible to do such a thing in X: e.g. the cute "xteddy" is
in fact a picture of a bear on a completely transparent
rectangular background, though you'd never know by looking!

Any comments?

With thanks, and best wishes to all,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 20-Mar-05                                       Time: 16:09:11
------------------------------ XFMail ------------------------------

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Mon Mar 21 10:15:04 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 21 Mar 2005 10:15:04 +0100
Subject: [R] anomalous result for wilcox.exact in exactRankTests
In-Reply-To: <25fyypk1zm.fsf@joel.Stanford.EDU>
References: <25fyypk1zm.fsf@joel.Stanford.EDU>
Message-ID: <x2r7i9pdgn.fsf@turmalin.kubism.ku.dk>

Roger Levy <rog at stanford.edu> writes:

> Hi,
> 
> In the exactRankTest package, I've become aware that you can get
> anomalous p-values (i.e., above 1) from the wilcox.exact method, as in:
> 
>   > wilcox.exact(c(-0.6,0.8,-0.5))
> 
>         Exact Wilcoxon signed rank test
> 
>   data:  c(-0.6, 0.8, -0.5) 
>   V = 3, p-value = 1.25
>   alternative hypothesis: true mu is not equal to 0 
> 
> This is disturbing.  Has anyone encountered this before, and if so is
> there an obvious reason why this should happen?

Presumably by counting the observed value towards both tails:

> dsignrank(0:6,3)
[1] 0.125 0.125 0.125 0.250 0.125 0.125 0.125
> sum(dsignrank(0:3,3))+sum(dsignrank(3:6,3))
[1] 1.25

which looks a bit odd, but of course only happens when the correct
p-value is 1.0, so it is fairly harmless.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Michael.Hecht at dillinger.biz  Mon Mar 21 10:59:03 2005
From: Michael.Hecht at dillinger.biz (Hecht Michael, F+E/ST)
Date: Mon, 21 Mar 2005 10:59:03 +0100
Subject: [R] Median in Classes
Message-ID: <98BC0F9CF5A9D511964100005A478F39087AA2AB@nt03.dillinger.de>

Hello,

I've got a problem to find an effective calculation. 
There are x,y data and I want to build classes for 
the x values. For each class then I want to calculate
the median, N%-Quantiles, outliers, etc. for the 
corresponding y values and store all in a vector or matrix.

Is there a direct possibility to do this without 
storing to much temporary data?

Thank's in advance,

Michael Hecht

-------------------------------------------------
| Dipl.-Math. Michael Hecht
| 66748 Dillingen / Germany
| E-Mail : mailto:michael.hecht at dillinger.de



From Ted.Harding at nessie.mcc.ac.uk  Mon Mar 21 10:55:58 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 21 Mar 2005 09:55:58 -0000 (GMT)
Subject: Sv: [R] Using locator() to digitise
In-Reply-To: <s23e9cab.031@gwmail.ihe.se>
Message-ID: <XFMail.050321095558.Ted.Harding@nessie.mcc.ac.uk>

On 21-Mar-05 Sixten Borg wrote:
> Hi,
> Splus allows pasting a graphics object into the plotting
> window, which makes it possible to do what you describe below.
> Now I use R which doesn't seem to allow pasting the picture
> into the graphics window, so I copy the graph onto a transparency 
> sheet, and stick it onto my screen using tape. The coordinates
> need to be converted to make sense (as you describe).
> 
> My methodology with the transparency has a "stoneage" appearance, but
> it works quite well, if I may say so myself.

Hi Sixten,

Such things often work well! You take me back many years to
my earliest digitising, using a flat-bed pen plotter.

I bought a cheap little "pocket microscope" (the top and
bottom lenses folded out from the upright), plucked two
hairs from my head, and fixed these as *literal* cross-hairs
on the lower lens with sellotape. To use this, I would
remove the pen from its holder on the plotter arm and attach
the microscope to the pen holder with a rubber band. The
sheet to be digitised was laid on the plotter bed in the
usual way.

I then wrote a program (BASIC for CP/M) which would move
the pen-holder under control of the arrow-keys on the
computer, and keep an internal record of the point moved to.
Pressing "Return" would store the plotter coordinates of
the current point in an array.

Any other anecdotes, anyone?

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 21-Mar-05                                       Time: 09:55:58
------------------------------ XFMail ------------------------------



From Ted.Harding at nessie.mcc.ac.uk  Mon Mar 21 10:34:29 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 21 Mar 2005 09:34:29 -0000 (GMT)
Subject: [R] Using locator() to digitise
In-Reply-To: <423E4FB0.3060502@hppi.troitsk.ru>
Message-ID: <XFMail.050321093429.Ted.Harding@nessie.mcc.ac.uk>

On 21-Mar-05 M.Kondrin wrote:
> (Ted Harding) wrote:
> 
>>Hi Folks,
>>
>>I'm contemplating using locator() to digitise external
>>graphics. To set context, I would be using X11 display
>>on Linux.
>>  
>>
> Hi, Ted!
> Beside searching for specialized packages, I would suggest
> you to try my package RImgViewer  which uses Gtk2 library
> to import and display images in R-session. It is  not available
> on CRAN because it depends on two other packages (RGtk2 and
> GdkDrawing) which conflict with Duncan T. Lang RGtk package.
> All of them can be downloaded from my homepage 
> (www.hppi.troitsk.ru/Kondrin/r_img_viewer_html.html , 
> www.hppi.troitsk.ru/Kondrin ).
> [...]

Thanks for pointing this out! From your description, it looks
well worth a try, and if I use it I will be happy to give you
feedback.

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 21-Mar-05                                       Time: 09:34:29
------------------------------ XFMail ------------------------------



From achilleas.psomas at wsl.ch  Mon Mar 21 11:09:46 2005
From: achilleas.psomas at wsl.ch (achilleas.psomas@wsl.ch)
Date: Mon, 21 Mar 2005 11:09:46 +0100
Subject: [R] Convex hull line coordinates..
In-Reply-To: <1111151047.423ad1c781698@webmail.wsl.ch>
References: <1107965723.420a371b2bf55@webmail.wsl.ch>
	<1111151047.423ad1c781698@webmail.wsl.ch>
Message-ID: <1111399786.423e9d6a0c3a2@webmail.wsl.ch>


Hello R-Helpers..

I am still new in R and I have the following question..
I am applying the function chull on a 2D dataset and have the convex hull
nicely
calculated and plotted.
Do you know if there is a way to extract the coordinates of the line created
from the connection of the chull data points..
I have alredy tried with "approx" to lineary interpolate but its not working
correctly since the interpolated values sometimes fall inside the convex .
Using the "yleft" or "yright" doesnt seem to help..

Any suggestions?
Thank you in advance

Achilleas Psomas



From W.E.Wolski at ncl.ac.uk  Mon Mar 21 11:10:43 2005
From: W.E.Wolski at ncl.ac.uk (Witold Eryk Wolski)
Date: Mon, 21 Mar 2005 11:10:43 +0100
Subject: [R] Violin plot for discrete variables.
Message-ID: <423E9DA3.30602@ncl.ac.uk>

Dear Rgurus,

To my knowledge the best way to visualize the distribution of a discrete 
variable X is
plot(table(X))

The problem which I have is the following. I have to discrete variables 
X and Y which distribution I would like to compare. To overlay the 
distribution of Y with lines(table(Y)) gives not satisfying results. 
This is the same in case of using density or histogram.

Hence, I am wondering if there is a equivalent of the vioplot function 
(package vioplot) for discrete variables
which starts with a boxplot and than adds a rotated plot(table()) plot 
to each side of the box plot.

Maybee I should ask it first: Does such a plot make any sense? If not 
are there better solutions?

cheers
Eryk.


-- 
Witold Eryk Wolski
__("<  School of Mathematics and Statistics     _
\__/   University of Newcastle                 'v'
 ||    Newcastle upon Tyne, NE1 7RU, ENGLAND  /   \
 ^^    mail: witek96 at users.sourceforge.net     m m
       Phone : 044 (0)191 222 5376
       FAX   : 044 (0)191 222 8020



From dimitris.rizopoulos at med.kuleuven.ac.be  Mon Mar 21 11:13:08 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Mon, 21 Mar 2005 11:13:08 +0100
Subject: [R] Median in Classes
References: <98BC0F9CF5A9D511964100005A478F39087AA2AB@nt03.dillinger.de>
Message-ID: <00d801c52dfe$94711830$0540210a@www.domain>

you could try something like this:

dat <- data.frame(x=rep(1:4, each=25), y=rnorm(100))
tapply(dat$y, dat$x, summary)

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Hecht Michael, F+E/ST" <Michael.Hecht at dillinger.biz>
To: "'r-help at lists.R-project.org'" <r-help at stat.math.ethz.ch>
Sent: Monday, March 21, 2005 10:59 AM
Subject: [R] Median in Classes


> Hello,
>
> I've got a problem to find an effective calculation.
> There are x,y data and I want to build classes for
> the x values. For each class then I want to calculate
> the median, N%-Quantiles, outliers, etc. for the
> corresponding y values and store all in a vector or matrix.
>
> Is there a direct possibility to do this without
> storing to much temporary data?
>
> Thank's in advance,
>
> Michael Hecht
>
> -------------------------------------------------
> | Dipl.-Math. Michael Hecht
> | 66748 Dillingen / Germany
> | E-Mail : mailto:michael.hecht at dillinger.de
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From m.blizinski at wsisiz.edu.pl  Mon Mar 21 11:12:57 2005
From: m.blizinski at wsisiz.edu.pl (Maciej =?iso-8859-2?Q?Blizi=F1ski?=)
Date: Mon, 21 Mar 2005 11:12:57 +0100
Subject: [R] Remove columns from data-frame
Message-ID: <20050321101257.GA20175@wsisiz.edu.pl>

Hello,

I'm new to the list, hello everybody! :-)


I have a question. I looked carefully through the documentation and
googled, and found no answer, so I'm posting it here.

Let's say I have a data frame with lots of columns (about 300), which
are factors.  Many columns-factors have only one level, for example all
are "Yes" or all are "No". 

If I try to do a regression with that, I get an error message, that
contrasts can be used only when number of factors is at least 2.

> glm(mortality ~ ., family = binomial, data = ecdb_PROC88)
Error in "contrasts<-"(`*tmp*`, value = "contr.treatment") :
        contrasts can be applied only to factors with 2 or more levels


Of course, I could not include them in the model formula, but I don't
feel like typing 150 descriptive variables.

I would like to remove the one-level columns autimatically from the data
frame. Is it possible?

Regards,
Maciej



From nioniodesbois at yahoo.fr  Mon Mar 21 11:25:13 2005
From: nioniodesbois at yahoo.fr (Guillaume STORCHI)
Date: Mon, 21 Mar 2005 11:25:13 +0100 (CET)
Subject: [R] menu() and commands assigned to choices ->break out a repeat
	loop so that the next code lines to be read
Message-ID: <20050321102513.37711.qmail@web86902.mail.ukl.yahoo.com>

first:I'd like to have the choice between breaking out a repeat loop or
continue it

then: i'd would like my code after the end of my repeat loop not to be read
unless I type 2 (to continue executing the content of my repeat loop) THAT'S
THE 
PROBLEM 

Is there any way to go straight out of the loop (like a "goto" associated to a
"label") or a pause like command to prevent R from reading the entire script??

I actually have this kind of code

reapeat{
...
...
...
   switch(menu(c("continue to select points","modelling"),next,break))
}
...
...

Thanks a lot

Guillaume STORCHI



From dimitris.rizopoulos at med.kuleuven.ac.be  Mon Mar 21 11:38:27 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Mon, 21 Mar 2005 11:38:27 +0100
Subject: [R] Remove columns from data-frame
References: <20050321101257.GA20175@wsisiz.edu.pl>
Message-ID: <011701c52e02$1d9ce140$0540210a@www.domain>

try this:

dat <- data.frame(y=rnorm(100), f1=sample(c("Yes", "No"), 100, TRUE), 
f2=rep("Yes", 100), f3=rep("No", 100))
#############
dat[!sapply(dat, function(x) all(x==x[1]))]

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm

----- Original Message ----- 
From: "Maciej Blizi?ski" <m.blizinski at wsisiz.edu.pl>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, March 21, 2005 11:12 AM
Subject: [R] Remove columns from data-frame


> Hello,
>
> I'm new to the list, hello everybody! :-)
>
>
> I have a question. I looked carefully through the documentation and
> googled, and found no answer, so I'm posting it here.
>
> Let's say I have a data frame with lots of columns (about 300), 
> which
> are factors.  Many columns-factors have only one level, for example 
> all
> are "Yes" or all are "No".
>
> If I try to do a regression with that, I get an error message, that
> contrasts can be used only when number of factors is at least 2.
>
>> glm(mortality ~ ., family = binomial, data = ecdb_PROC88)
> Error in "contrasts<-"(`*tmp*`, value = "contr.treatment") :
>        contrasts can be applied only to factors with 2 or more 
> levels
>
>
> Of course, I could not include them in the model formula, but I 
> don't
> feel like typing 150 descriptive variables.
>
> I would like to remove the one-level columns autimatically from the 
> data
> frame. Is it possible?
>
> Regards,
> Maciej
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Mon Mar 21 11:50:29 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 21 Mar 2005 11:50:29 +0100
Subject: [R] menu() and commands assigned to choices ->break out a repeat
	loop so that the next code lines to be read
In-Reply-To: <20050321102513.37711.qmail@web86902.mail.ukl.yahoo.com>
References: <20050321102513.37711.qmail@web86902.mail.ukl.yahoo.com>
Message-ID: <423EA6F5.9030009@statistik.uni-dortmund.de>

Guillaume STORCHI wrote:

> first:I'd like to have the choice between breaking out a repeat loop or
> continue it
 >
> then: i'd would like my code after the end of my repeat loop not to be read
> unless I type 2 (to continue executing the content of my repeat loop) THAT'S
> THE 
> PROBLEM 
> 
> Is there any way to go straight out of the loop (like a "goto" associated to a
> "label") or a pause like command to prevent R from reading the entire script??
> 
> I actually have this kind of code
> 
> reapeat{
> ...
> ...
> ...
>    switch(menu(c("continue to select points","modelling"),next,break))

With the parantheses correct you get

   switch(menu(c("continue to select points","modelling")), next, break)

which seems to work ...

Uwe Ligges



> }
> ...
> ...
> 
> Thanks a lot
> 
> Guillaume STORCHI
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From nioniodesbois at yahoo.fr  Mon Mar 21 11:59:32 2005
From: nioniodesbois at yahoo.fr (Guillaume STORCHI)
Date: Mon, 21 Mar 2005 11:59:32 +0100 (CET)
Subject: [R] classes of data (with a variable size)
Message-ID: <20050321105933.46015.qmail@web86902.mail.ukl.yahoo.com>

How is it possible to "split" a data.frame in order to get classes with
variable size.
actually I'd like to get classes of data with classe size (cs) so that
cs becomes bigger with an other increasing value.

Guillaume Storchi



From nioniodesbois at yahoo.fr  Mon Mar 21 12:05:36 2005
From: nioniodesbois at yahoo.fr (Guillaume STORCHI)
Date: Mon, 21 Mar 2005 12:05:36 +0100 (CET)
Subject: [R] menu() and continue a repeat loop without executing the code
	that follows the loop!!?
Message-ID: <20050321110536.90386.qmail@web86901.mail.ukl.yahoo.com>

> first:I'd like to have the choice between breaking out a repeat loop or
> continue it

>

> then: i'd would like my code after the end of my repeat loop not to be read
> unless I type 2 (to continue executing the content of my repeat loop) THAT'S
> THE PROBLEM
> Is there any way to go straight out of the loop (like a "goto" associated to
a
> "label") or a pause like command to prevent R from reading the entire
script??

I actually have this kind of code

reapeat{
...
...
...
switch(menu(c("continue to select points","modelling")),next,break)
}
...
...


With the right brackets, it doesn't work either!
R read the entire code that follows the switch(...) when I choose "continue to
select points" instead of ONLY reading the repeat loop.

Guillaume Storchi



From jan.sabee at gmail.com  Mon Mar 21 12:07:16 2005
From: jan.sabee at gmail.com (Jan Sabee)
Date: Mon, 21 Mar 2005 12:07:16 +0100
Subject: [R] Count missing variables in dataset
Message-ID: <96507a8e05032103072ae6c5b1@mail.gmail.com>

I have a problem about how to count missing variables in dataset.
I have a question for my customer. They are must choice one of answer
for example: A, B, C, D and E.
Now, I have dataset which is the result from my question, for instance:

x1 x2 x3 x4 x5
A  A  A   B  A
C  A  A   A  A
B  B  A   B  A
B  B  B   C  A
A  B  B   B  B
C  B  B   B  A

I know that my customer only choice A, B and C.
Are there any way to count variables that are not include in dataset.
I mean D and E is missing in dataset.

Thanks for your help.
Jan Sabee



From wolfgang.waser at rz.hu-berlin.de  Mon Mar 21 12:09:31 2005
From: wolfgang.waser at rz.hu-berlin.de (Wolfgang Waser)
Date: Mon, 21 Mar 2005 12:09:31 +0100
Subject: [R] X11 Fonts sizes
Message-ID: <200503211209.31407.wolfgang.waser@rz.hu-berlin.de>

In postscript graphs (pointsize = 10, different sizes in graph adjusted via 
cex) I would like to use different font sizes but get the following warning 
message:

Warning messages: 
1: X11 used font size 8 when 9 was requested 
2: X11 used font size 8 when 7 was requested 
3: X11 used font size 8 when 5 was requested 

This is probably not a R but a X11 problem, nevertheless I would be most 
obliged for any help how to actually use font sizes 9, 7, and 5 and others.


Sincerely

Wolfgang Waser



From Luisr at frs.fo  Mon Mar 21 12:25:24 2005
From: Luisr at frs.fo (Luis Ridao Cruz)
Date: Mon, 21 Mar 2005 11:25:24 +0000
Subject: [R] Remove "save workspace image?" window when exit R
Message-ID: <s23eaf2c.033@ffdata.setur.fo>

R-help,

I wish to remove the message at the end of a session "save workspace
image?" .
By googling I found no answer .


Thanks in advance

I run on Windows XP

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    0.1            
year     2004           
month    11             
day      15             
language R



From andy_liaw at merck.com  Mon Mar 21 12:31:21 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 21 Mar 2005 06:31:21 -0500
Subject: [R] Count missing variables in dataset
Message-ID: <3A822319EB35174CA3714066D590DCD50994E8A5@usrymx25.merck.com>

Something like:

sum(sapply(dat, function(x) ! x %in% c("A", "B", "C")))

probably would work.

HTH,
Andy

> From: Jan Sabee
> 
> I have a problem about how to count missing variables in dataset.
> I have a question for my customer. They are must choice one of answer
> for example: A, B, C, D and E.
> Now, I have dataset which is the result from my question, for 
> instance:
> 
> x1 x2 x3 x4 x5
> A  A  A   B  A
> C  A  A   A  A
> B  B  A   B  A
> B  B  B   C  A
> A  B  B   B  B
> C  B  B   B  A
> 
> I know that my customer only choice A, B and C.
> Are there any way to count variables that are not include in dataset.
> I mean D and E is missing in dataset.
> 
> Thanks for your help.
> Jan Sabee
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From Achim.Zeileis at wu-wien.ac.at  Mon Mar 21 12:37:18 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Mon, 21 Mar 2005 12:37:18 +0100
Subject: [R] Count missing variables in dataset
In-Reply-To: <96507a8e05032103072ae6c5b1@mail.gmail.com>
References: <96507a8e05032103072ae6c5b1@mail.gmail.com>
Message-ID: <20050321123718.6d8ecc5c.Achim.Zeileis@wu-wien.ac.at>

On Mon, 21 Mar 2005 12:07:16 +0100 Jan Sabee wrote:

> I have a problem about how to count missing variables in dataset.
> I have a question for my customer. They are must choice one of answer
> for example: A, B, C, D and E.
> Now, I have dataset which is the result from my question, for
> instance:
> 
> x1 x2 x3 x4 x5
> A  A  A   B  A
> C  A  A   A  A
> B  B  A   B  A
> B  B  B   C  A
> A  B  B   B  B
> C  B  B   B  A
> 
> I know that my customer only choice A, B and C.
> Are there any way to count variables that are not include in dataset.
> I mean D and E is missing in dataset.

You just need to set up the variables properly. If you just say:

R> x <- factor(sample(LETTERS[1:3], 5, replace = TRUE))
R> summary(x)
A B C 
1 2 2 

R will assume that the only levels available are A-C. But if you tell R

R> x <- factor(x, levels = LETTERS[1:5])
R> summary(x)
A B C D E 
1 2 2 0 0 

it will do what you want. Just provide the full choice set as levels to
the corresponding variables.
Z

> Thanks for your help.
> Jan Sabee
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From leonn.turner at email.si  Mon Mar 21 12:43:19 2005
From: leonn.turner at email.si (Leonn Turner)
Date: Mon, 21 Mar 2005 12:43:19 +0100
Subject: [R] Training data
Message-ID: <00ed01c52e0b$30598be0$4101080a@LEONN>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050321/8ff7e65f/attachment.pl

From tjrc at sanger.ac.uk  Mon Mar 21 12:56:25 2005
From: tjrc at sanger.ac.uk (Tim Cutts)
Date: Mon, 21 Mar 2005 11:56:25 +0000
Subject: [R] X11 Fonts sizes
In-Reply-To: <200503211209.31407.wolfgang.waser@rz.hu-berlin.de>
References: <200503211209.31407.wolfgang.waser@rz.hu-berlin.de>
Message-ID: <1bf09e9de44ec9fe4bb59ac481e92c43@sanger.ac.uk>


On 21 Mar 2005, at 11:09 am, Wolfgang Waser wrote:

> In postscript graphs (pointsize = 10, different sizes in graph 
> adjusted via
> cex) I would like to use different font sizes but get the following 
> warning
> message:
>
> Warning messages:
> 1: X11 used font size 8 when 9 was requested
> 2: X11 used font size 8 when 7 was requested
> 3: X11 used font size 8 when 5 was requested
>
> This is probably not a R but a X11 problem, nevertheless I would be 
> most
> obliged for any help how to actually use font sizes 9, 7, and 5 and 
> others.

X11 default fonts are usually bitmaps, and not scalable, so if you 
don't have the 9, 7 and 5 point versions of the font installed, it may 
be automatically reverting to the nearest decent point size.  Have you 
tried changing the font to something that is scalable, like a 
PostScript or TrueType font?

You can also change the X server's configuration so that it will 
attempt to scale bitmap fonts, but the results are not pretty, so I 
never enable that.

Tim

-- 
Dr Tim Cutts
Informatics Systems Group, Wellcome Trust Sanger Institute
GPG: 1024D/E3134233 FE3D 6C73 BBD6 726A A3F5  860B 3CDD 3F56 E313 4233



From ligges at statistik.uni-dortmund.de  Mon Mar 21 12:55:59 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 21 Mar 2005 12:55:59 +0100
Subject: [R] Remove "save workspace image?" window when exit R
In-Reply-To: <s23eaf2c.033@ffdata.setur.fo>
References: <s23eaf2c.033@ffdata.setur.fo>
Message-ID: <423EB64F.2080405@statistik.uni-dortmund.de>

Luis Ridao Cruz wrote:

> R-help,
> 
> I wish to remove the message at the end of a session "save workspace
> image?" .
> By googling I found no answer .


Well, I found at once, e.g. look for a thread that started with
    "Quit asking me" ...
and ended up in a nice quiz.

Uwe Ligges



> 
> Thanks in advance
> 
> I run on Windows XP
> 
> 
>>version
> 
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    2              
> minor    0.1            
> year     2004           
> month    11             
> day      15             
> language R
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Mon Mar 21 13:02:06 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 21 Mar 2005 13:02:06 +0100
Subject: [R] X11 Fonts sizes
In-Reply-To: <200503211209.31407.wolfgang.waser@rz.hu-berlin.de>
References: <200503211209.31407.wolfgang.waser@rz.hu-berlin.de>
Message-ID: <x2is3lp5q9.fsf@turmalin.kubism.ku.dk>

Wolfgang Waser <wolfgang.waser at rz.hu-berlin.de> writes:

> In postscript graphs (pointsize = 10, different sizes in graph adjusted via 
> cex) I would like to use different font sizes but get the following warning 
> message:
> 
> Warning messages: 
> 1: X11 used font size 8 when 9 was requested 
> 2: X11 used font size 8 when 7 was requested 
> 3: X11 used font size 8 when 5 was requested 
> 
> This is probably not a R but a X11 problem, nevertheless I would be most 
> obliged for any help how to actually use font sizes 9, 7, and 5 and others.

The main issue is to have them... If you are using nonscalable fonts,
the available sizes are 8,10,11, etc. Some distributions turn off
scalable fonts because they tend to look ugly compared to the ones
that have been tuned to a particular gridsize, but you can generally
turn them on again by configuring the fontserver. E.g. I have

catalogue = /usr/X11R6/lib/X11/fonts/misc:unscaled,
        /usr/X11R6/lib/X11/fonts/75dpi:unscaled,
        /usr/X11R6/lib/X11/fonts/100dpi:unscaled,

in /etc/X11/fs/config
 
and dropping the :unscaled should allow the server to generate the
in-between sizes, at the expense of appearance.

Also, notice that the X11 font sizes are only relevant for postscript
graphics if you are using dev.print() or dev.copy2eps(). If you use
the postscript() driver directly, X11 never comes into play. (There
might be a minimum legible size, though. I forget.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jabezwuk at yahoo.co.uk  Mon Mar 21 13:03:14 2005
From: jabezwuk at yahoo.co.uk (Jabez Wilson)
Date: Mon, 21 Mar 2005 12:03:14 +0000 (GMT)
Subject: [R] Remove "save workspace image?" window when exit R
Message-ID: <20050321120314.59886.qmail@web25407.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050321/9b56f02a/attachment.pl

From jtk at cmp.uea.ac.uk  Mon Mar 21 14:51:52 2005
From: jtk at cmp.uea.ac.uk (Jan T. Kim)
Date: Mon, 21 Mar 2005 13:51:52 +0000
Subject: [R] Sweave/margin
In-Reply-To: <9963.1111182572@www73.gmx.net>
References: <9963.1111182572@www73.gmx.net>
Message-ID: <20050321135152.GC23046@jtkpc.cmp.uea.ac.uk>

On Fri, Mar 18, 2005 at 10:49:32PM +0100, Katharina Hoff wrote:

> I am currently using Sweave for writing my bachelor thesis - and I have a
> problem:
> 
> I am using a LaTeX style (report) with quite big margin spaces. The Sweave
> generated LaTeX code "floats" into the margin - and it looks ugly. The text
> is blocked and fine... then there comes some flattering code running over
> the margin... and blocked text again.
> 
> Considering the LaTeX output, I guess that Sweave puts the source code
> somehow in LaTeX-boxes and I suppose there is a place where I could change
> the width of the source code boxes (At a certain point, there is a break,
> closely before the text would drift out of the page. Then the code continues
> in new lines below.)
> 
> Does anyone know where I could change or insert the box width? 
> 
> Or probably I am totally wrong and someone knows another solution...
> 
> Hoping for help - and excuse if anyone asked this stupid question before, I
> did not find it in the archive,

I assume you talk about R code lines extending into the right margin of
pages. These are due to the formatting of such stuff using Verbatim
environments.

To gain control over code formatting, you can copy the pertinent lines
from Sweave.sty into your document's preamble:

    \usepackage{fancyvrb}

    % \usepackage{Sweave}

    \DefineVerbatimEnvironment{Sinput}{Verbatim}{fontshape=sl}
    \DefineVerbatimEnvironment{Soutput}{Verbatim}{}
    \DefineVerbatimEnvironment{Scode}{Verbatim}{fontshape=sl}

    \newenvironment{Schunk}{}{}

The comment "% \usepackage{Sweave}" is needed, it suppresses the insertion
of that usepackage line by Sweave.

My Sweave manual just mentions that you are to define Sinput and Soutput,
but in fact, both are wrapped by the currently (R 2.0.1) unused Schunk
environment, providing you with a convenient handle for altering the font
size, as e.g. in:

    \newenvironment{Schunk}{\tiny}{}

Alternatively, you can make use of the fontsize parameter provided by the
Verbatim package of LaTeX.

Finally, you can always try to tweak your R code to consist of, and to produce
shorter lines.

Best regards, Jan
-- 
 +- Jan T. Kim -------------------------------------------------------+
 |    *NEW*    email: jtk at cmp.uea.ac.uk                               |
 |    *NEW*    WWW:   http://www.cmp.uea.ac.uk/people/jtk             |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*



From andy_liaw at merck.com  Mon Mar 21 14:14:20 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 21 Mar 2005 08:14:20 -0500
Subject: [R] Violin plot for discrete variables.
Message-ID: <3A822319EB35174CA3714066D590DCD50994E8A6@usrymx25.merck.com>

I'd suggest dotcharts, such as:

x1 <- sample(letters[1:4], 100, replace=TRUE, prob=c(.2, .3, .4, .1))
x2 <- sample(letters[1:4], 100, replace=TRUE, prob=c(.1, .4, .3, .2))
f1 <- table(x1) / length(x1)
f2 <- table(x2) / length(x2)
lev <- factor(c(names(f1), names(f2)))
require(lattice)
dotplot(lev ~ c(f1, f2), groups=rep(1:2, c(length(f1), length(f2))),
        panel=panel.superpose)

HTH,
Andy

> From: Witold Eryk Wolski
> 
> Dear Rgurus,
> 
> To my knowledge the best way to visualize the distribution of 
> a discrete 
> variable X is
> plot(table(X))
> 
> The problem which I have is the following. I have to discrete 
> variables 
> X and Y which distribution I would like to compare. To overlay the 
> distribution of Y with lines(table(Y)) gives not satisfying results. 
> This is the same in case of using density or histogram.
> 
> Hence, I am wondering if there is a equivalent of the vioplot 
> function 
> (package vioplot) for discrete variables
> which starts with a boxplot and than adds a rotated 
> plot(table()) plot 
> to each side of the box plot.
> 
> Maybee I should ask it first: Does such a plot make any sense? If not 
> are there better solutions?
> 
> cheers
> Eryk.
> 
> 
> -- 
> Witold Eryk Wolski
> __("<  School of Mathematics and Statistics     _
> \__/   University of Newcastle                 'v'
>  ||    Newcastle upon Tyne, NE1 7RU, ENGLAND  /   \
>  ^^    mail: witek96 at users.sourceforge.net     m m
>        Phone : 044 (0)191 222 5376
>        FAX   : 044 (0)191 222 8020
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From andy_liaw at merck.com  Mon Mar 21 14:20:52 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 21 Mar 2005 08:20:52 -0500
Subject: [R] Remove "save workspace image?" window when exit R
Message-ID: <3A822319EB35174CA3714066D590DCD50994E8A7@usrymx25.merck.com>

If you are using Rgui, right-click on the icon you use to start R and click
on "Properties", and add --no-save to the command that starts R.

Andy

> From: Luis Ridao Cruz
> 
> R-help,
> 
> I wish to remove the message at the end of a session "save workspace
> image?" .
> By googling I found no answer .
> 
> 
> Thanks in advance
> 
> I run on Windows XP
> 
> > version
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    2              
> minor    0.1            
> year     2004           
> month    11             
> day      15             
> language R
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From leonn.turner at email.si  Mon Mar 21 14:33:32 2005
From: leonn.turner at email.si (Leonn Turner)
Date: Mon, 21 Mar 2005 14:33:32 +0100
Subject: [R] type=raw vs type=class
Message-ID: <013601c52e1a$9a348dd0$4101080a@LEONN>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050321/d9faa026/attachment.pl

From andy_liaw at merck.com  Mon Mar 21 14:44:31 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 21 Mar 2005 08:44:31 -0500
Subject: [R] type=raw vs type=class
Message-ID: <3A822319EB35174CA3714066D590DCD50994E8A8@usrymx25.merck.com>

For what class?  Those don't sound like they apply to _all_ predict methods.

Andy

> From: Leonn Turner
> 
> Hello!
> 
> Could someone explain me the meaning of predict function 
> parameter named type:
> 1. type="raw"
> 2.type="class"
> 
> Thank you.
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From MSchwartz at MedAnalytics.com  Mon Mar 21 14:58:31 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Mon, 21 Mar 2005 07:58:31 -0600
Subject: [R] Force labelling of x-axis
In-Reply-To: <Pine.WNT.4.62.0503202309390.3388@Desktop>
References: <Pine.WNT.4.62.0503202309390.3388@Desktop>
Message-ID: <1111413511.5550.34.camel@horizons.localdomain>

On Sun, 2005-03-20 at 23:15 -0500, Bill Kranec wrote:
> Hi,
> 
> I'm trying to do a box-whisker plot of two columns of a data frame, a
> list of category names in one column vs. some numerical values in the
> other.  The plot itself works fine, but only a few points of the x-axis
> ( the category names ) are labelled.  I think that this is because the
> category names are too long.
> 
> Is there any way to force R to label each x-axis value, preferably at a
> 45-degree slant so that each one can be seen?  I feel like this should be
> pretty easy to do, but I can't find anything obvious from the R-manual.

Bill, there have been a couple of other suggestions, but I'll throw in
my $0.02 here:

Without a specific example it is hard to know which way to recommend to
you, but a couple of possibilities if you are using R's base graphics:

1. Reduce the font size of the labels by using 'cex.axis' as an argument
in your call to boxplot(). The default is 1, but you may be able to
reduce it to something that gets your labels printed and still be
readable.

Here is an example:

group <- sample(c("Long Label 1", "Long Label 2", "Long Label 3"), 
                40, replace = TRUE)
N <- rnorm(40)
df <- data.frame(group, N)

boxplot(N ~ Group, data = df)

# Now reduce the size of the labels
boxplot(N ~ group, data = df, cex.axis = 0.75)



2. You can split the labels on two lines by using a "\n" in the labels:

boxplot(N ~ group, data = df, xaxt = "n")
mtext(1, at = 1:3, 
      text = c("Long\nLabel 1", "Long\nLabel 2", "Long\nLabel 3"),
      line = 2)

If you want to reduce the font size in the above use 'cex = ...' in the
call to mtext().



3. If neither of the above (or a combination of the two) helps, there is
a FAQ (7.27) that provides an example of how to rotate axis labels at:

http://cran.r-project.org/doc/FAQ/R-FAQ.html#How-can-I-create-rotated-
axis-labels_003f

Beware of line wrapping in the above URL.

HTH,

Marc Schwartz



From xiyanlon at gmail.com  Mon Mar 21 16:05:24 2005
From: xiyanlon at gmail.com (Xiyan Lon)
Date: Mon, 21 Mar 2005 16:05:24 +0100
Subject: [R] Convert numeric to class
Message-ID: <9a38bfc705032107051a8c6725@mail.gmail.com>

Dear all,
I have a script about iteration classification, like this below

data(iris)
  N <- 5
  ir.tr.iter <- vector('list',N)
  ir.tr <- vector('list',N)
  for (j in 1:N) {
    ir.tr[[j]] <- rpart(Species ~., data=iris)
    ir.tr.iter[j] <- ir.tr[[j]]$frame
    result  <- list(ir.tr=ir.tr, ir.tr.iter=ir.tr.iter)
  }        

as.data.frame(as.matrix(ir.tr.iter))

Because I need the result as dataframe I convert to as.matrix, but all
it only numeric
> as.data.frame(as.matrix(ir.tr.iter))
             V1
1 4, 1, 5, 1, 1
2 4, 1, 5, 1, 1
3 4, 1, 5, 1, 1
4 4, 1, 5, 1, 1
5 4, 1, 5, 1, 1


> ir.tr.iter
[[1]]
[1] Petal.Length <leaf>       Petal.Width  <leaf>       <leaf>      
Levels: <leaf> Sepal.Length Sepal.Width Petal.Length Petal.Width
.
.
.
[[5]]
[1] Petal.Length <leaf>       Petal.Width  <leaf>       <leaf>      
Levels: <leaf> Sepal.Length Sepal.Width Petal.Length Petal.Width


I don't know where are 1, 4 and 5 (numeric) come from, but I guest 1
(<leaf>), 4 (Petal.Length) and 5 (Petal.Width).
I want to convert the species (class/type) like,
                                                                        V1
Petal.Length <leaf>       Petal.Width  <leaf>       <leaf>
Petal.Length <leaf>       Petal.Width  <leaf>       <leaf>
Petal.Length <leaf>       Petal.Width  <leaf>       <leaf>
Petal.Length <leaf>       Petal.Width  <leaf>       <leaf>
Petal.Length <leaf>       Petal.Width  <leaf>       <leaf>

How can I do?

Thanks in advance.

Xiyan Lon



From jahernan at umn.edu  Mon Mar 21 16:15:17 2005
From: jahernan at umn.edu (Jose A. Hernandez)
Date: Mon, 21 Mar 2005 09:15:17 -0600
Subject: [R] Bug on the stem function or in my brain ?
Message-ID: <423EE505.7070601@umn.edu>

Good day R-ers!

I was running the basic statistics for the exam that my students took 
last week and something does not make sense with the stem() fucntion.

Here are two of my variables:

time, is time to complete the exam in minutes
exam.1, is the grade for the exam

In stem(), to the left of the vertical bar are the leading digits of the 
grades. To the right of the vertical bar are the last digits of the 
grades. Each single digit on the right represents one grade.

 > time
  [1]  32  41  47  50  59  64  66  66  67  67  68  69  73  78  83  90 
93  93  95
[20] 100 100 110
 > stem(time)

   The decimal point is 1 digit(s) to the right of the |

    2 | 2
    4 | 1709
    6 | 466778938
    8 | 30335
   10 | 000

The stem and leaf plot does not reflect the actual data, the bottom line 
for instance says there were 3 people that spent 100 minutes working on 
the test. The next to bottom line says there were one 80, three 83s, one 
85. And so forth.

 > exam.1
  [1]  82 100  86  81  88  78  92  23  91  49  97   9  89  78  93  60 
80  80  83
[20]  94  51 100

 > stem(exam.1)

   The decimal point is 1 digit(s) to the right of the |

    0 | 9
    2 | 3
    4 | 91
    6 | 088
    8 | 0012368912347
   10 | 00

The Stem-and-Leaf plots DO NOT correspond to the data.

Any educational insights on this issue would be appreciated.

Regards,

Jose

 > class(exam.1)
[1] "numeric"
 > class(time)
[1] "numeric"

 > version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    0.1
year     2004
month    11
day      15
language R


-- 
Jose A. Hernandez
Ph.D. Candidate
Precision Agriculture Center

Department of Soil, Water, and Climate
University of Minnesota
1991 Upper Buford Circle
St. Paul, MN 55108

Ph. (612) 625-0445, Fax. (612) 625-2208



From andy_liaw at merck.com  Mon Mar 21 16:15:37 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 21 Mar 2005 10:15:37 -0500
Subject: [R] Convert numeric to class
Message-ID: <3A822319EB35174CA3714066D590DCD50994E8AC@usrymx25.merck.com>



> -----Original Message-----
> From: Xiyan Lon
> 
> Dear all,
> I have a script about iteration classification, like this below
> 
> data(iris)
>   N <- 5
>   ir.tr.iter <- vector('list',N)
>   ir.tr <- vector('list',N)
>   for (j in 1:N) {
>     ir.tr[[j]] <- rpart(Species ~., data=iris)
>     ir.tr.iter[j] <- ir.tr[[j]]$frame
>     result  <- list(ir.tr=ir.tr, ir.tr.iter=ir.tr.iter)
>   }        
> 
> as.data.frame(as.matrix(ir.tr.iter))
> 
> Because I need the result as dataframe I convert to as.matrix,

The `frame' component of an rpart object should already be a data frame.
You just need to make sure to assign them to components of ir.tr.iter, as,
e.g., 

  ir.tr.iter[[j]] <- ir.tr[[j]]$frame

BTW, why would you want to duplicate the data in `result'?  You can easily
get the `frame' component from ir.tr, so why store a separate copy?

Andy


> but all it only numeric
> > as.data.frame(as.matrix(ir.tr.iter))
>              V1
> 1 4, 1, 5, 1, 1
> 2 4, 1, 5, 1, 1
> 3 4, 1, 5, 1, 1
> 4 4, 1, 5, 1, 1
> 5 4, 1, 5, 1, 1
> 
> 
> > ir.tr.iter
> [[1]]
> [1] Petal.Length <leaf>       Petal.Width  <leaf>       <leaf>      
> Levels: <leaf> Sepal.Length Sepal.Width Petal.Length Petal.Width
> .
> .
> .
> [[5]]
> [1] Petal.Length <leaf>       Petal.Width  <leaf>       <leaf>      
> Levels: <leaf> Sepal.Length Sepal.Width Petal.Length Petal.Width
> 
> 
> I don't know where are 1, 4 and 5 (numeric) come from, but I guest 1
> (<leaf>), 4 (Petal.Length) and 5 (Petal.Width).
> I want to convert the species (class/type) like,
>                                                               
>           V1
> Petal.Length <leaf>       Petal.Width  <leaf>       <leaf>
> Petal.Length <leaf>       Petal.Width  <leaf>       <leaf>
> Petal.Length <leaf>       Petal.Width  <leaf>       <leaf>
> Petal.Length <leaf>       Petal.Width  <leaf>       <leaf>
> Petal.Length <leaf>       Petal.Width  <leaf>       <leaf>
> 
> How can I do?
> 
> Thanks in advance.
> 
> Xiyan Lon
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From xiyanlon at gmail.com  Mon Mar 21 16:50:28 2005
From: xiyanlon at gmail.com (Xiyan Lon)
Date: Mon, 21 Mar 2005 16:50:28 +0100
Subject: [R] Convert numeric to class
In-Reply-To: <3A822319EB35174CA3714066D590DCD50994E8AC@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50994E8AC@usrymx25.merck.com>
Message-ID: <9a38bfc705032107506b80d5d5@mail.gmail.com>

On Mon, 21 Mar 2005 10:15:37 -0500, Liaw, Andy <andy_liaw at merck.com> wrote:

> The `frame' component of an rpart object should already be a data frame.
> You just need to make sure to assign them to components of ir.tr.iter, as,
> e.g.,
> 
>   ir.tr.iter[[j]] <- ir.tr[[j]]$frame
> 
> BTW, why would you want to duplicate the data in `result'?  You can easily
> get the `frame' component from ir.tr, so why store a separate copy?
> 
> Andy
> 
> 

Thanks for your quick respons.
Because I want to make iteration for my classification, I want to see
what class/type (in this example, Species) was possible exits in my
iteration.

Best regrads
Xiyan Lon



From br44114 at yahoo.com  Mon Mar 21 16:51:28 2005
From: br44114 at yahoo.com (bogdan romocea)
Date: Mon, 21 Mar 2005 07:51:28 -0800 (PST)
Subject: [R] "Graphics (for goodness of fit)" Question
Message-ID: <20050321155129.34472.qmail@web50102.mail.yahoo.com>

In regards to your plot question, you could use points() or lines():
a <- sample(1:50,10)
b <- sample(20:40,10)
plot(1:10,a,pch=20,col="red")
points(1:10,b,pch=20,col="blue")
#or
#lines(1:10,b,pch=20,col="blue",type="o")



-----Original Message-----
From: Mohammad Ehsanul Karim [mailto:wildscop at yahoo.com]
Sent: Sunday, March 20, 2005 10:46 AM
To: r-help at stat.math.ethz.ch
Subject: [R] "Graphics (for goodness of fit)" Question


Dear List,

Suppose, I have some observed and expected
frequencies, such as following. 
I need to draw a graph where plots of observed and
expected frequencies are merged into one.
------------------------------------------------
 m <- c(1,2,3,4,5,6,7,8,9,10,12,13,17)
 k <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 19)
 ExpWW <- c(0.309330628803245, 0.213645190887434,
0.147558189649435, 0.101913922060107,
0.0703888244654489, 0.0486154051328303,
0.0335771712935674, 0.0231907237838939,
0.0160171226134196, 0.0110625360037919,
0.00764055478558038, 0.00527709716935116,
0.000395627498345897)
 ExpDD <- c(0.420249653259362, 0.243639882194748,
0.141250306182253, 0.0818899139863827,
0.0474757060281664, 0.0275240570315860,
0.0159570816077711, 0.00925112359507395,
0.00536334211198462, 0.00310939944911175,
0.00104510169329968, 0.00060589806906972,
6.84484529305126e-05)
 ObjDD <- c(0.468646864686469, 0.198019801980198,
0.151815181518152, 0.0759075907590759,
0.0396039603960396, 0.0198019801980198,
0.0165016501650165, 0.0099009900990099,
0.0033003300330033, 0.0033003300330033,
0.0033003300330033, 0.0066006600660066,
0.0033003300330033)
 ObjWW <- c(0.373770491803279, 0.150819672131148,
0.127868852459016, 0.0721311475409836,
0.0885245901639344, 0.0622950819672131,
0.039344262295082, 0.0327868852459016,
0.0360655737704918, 0.00327868852459016,
0.00655737704918033, 0.00327868852459016,
0.00327868852459016)
------------------------------------------------
  par(mfrow=c(2,2))
  plot(k,ObjWW, type="l") # Plot 1
  plot(k,ExpWW, type="l") # Plot 2
  plot(m,ObjDD, type="l") # Plot 3
  plot(m,ExpDD, type="l") # Plot 4
------------------------------------------------
# I need to see plot 1 and 2 in same axis, and plot 3
and 4 in another 
# (i.e., 3, 4 both in same axis too, but not with 1
and 2's).
# How can i use different types of legends in the same
graph??
------------------------------------------------
 sum(((ObjWW-ExpWW)^2)/ExpWW) # Chi-Squared Goodness
of Fit Test
 sum(((ObjDD-ExpDD)^2)/ExpDD) # Chi-Squared Goodness
of Fit Test
------------------------------------------------
# Also, is there any other convenient way of doing
chi-squared goodness of fit test (any function or
package may be, to do this directly)?
# And how can i find the P-values of the respective
chi-squared tests in R?
------------------------------------------------

Any suggestion, direction, references, help, replies
will be highly appreciated.

Thank you for your time.
________________________________

Mohammad Ehsanul Karim

Web: http://snipurl.com/ehsan
Institute of Statistical Reseach and Training
University of Dhaka, Dhaka - 1000, Bangladesh

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ggrothendieck at myway.com  Mon Mar 21 16:42:56 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 21 Mar 2005 15:42:56 +0000 (UTC)
Subject: [R] Violin plot for discrete variables.
References: <423E9DA3.30602@ncl.ac.uk>
Message-ID: <loom.20050321T160218-368@post.gmane.org>

Witold Eryk Wolski <W.E.Wolski <at> ncl.ac.uk> writes:

: 
: Dear Rgurus,
: 
: To my knowledge the best way to visualize the distribution of a discrete 
: variable X is
: plot(table(X))
: 
: The problem which I have is the following. I have to discrete variables 
: X and Y which distribution I would like to compare. To overlay the 
: distribution of Y with lines(table(Y)) gives not satisfying results. 
: This is the same in case of using density or histogram.
: 
: Hence, I am wondering if there is a equivalent of the vioplot function 
: (package vioplot) for discrete variables
: which starts with a boxplot and than adds a rotated plot(table()) plot 
: to each side of the box plot.
: 
: Maybee I should ask it first: Does such a plot make any sense? If not 
: are there better solutions?


You could try a barplot or a balloonplot:

tab <- table(stack(list(x1 = x1, x2 = x2))) # x1, x2 from Andy's post
barplot(t(tab), beside = TRUE)

library(gplots)
balloonplot(tab)


Although intended for comparing data to a theoretical distribution,
rootogram can compare two discrete distributions:

library(vcd)
rootogram(tab[,1], tab[,2])

Another possibility is to fit each distribution to a parametric form
using vcd::distplot as shown in the examples on its help page.



From marvena at tin.it  Mon Mar 21 17:12:12 2005
From: marvena at tin.it (marvena@tin.it)
Date: Mon, 21 Mar 2005 17:12:12 +0100
Subject: [R] Maximum amount of memory
Message-ID: <42000988000214F6@ims4b.cp.tin.it>

Hi, 
I have a problem:I need to use the maximum amount of memory in order to
perform a very tough analysis. By purchasing the suitable computer, what's
the maximum amount of memory obtainable in R?
Thanks, 

                          Marco



From jenniferbecq at free.fr  Mon Mar 21 17:13:50 2005
From: jenniferbecq at free.fr (jenniferbecq@free.fr)
Date: Mon, 21 Mar 2005 17:13:50 +0100
Subject: [R] rpart memory problem
Message-ID: <1111421630.423ef2be339ab@imp6-q.free.fr>


Hi everyone,

I have a problem using rpart (R 2.0.1 under Unix)

Indeed, I have a large matrix (9271x7), my response variable is numeric and all
my predictor variables are categorical (from 3 to 8 levels).

Here is an example :

> mydata[1:5,]
                  distance group3 group4 group5 group6 group7 group8
pos_1    0.141836040224967      a      c      e      a      g      g
pos_501  0.153605961621317      a      a      a      a      g      g
pos_1001 0.152246705384699      a      c      e      a      g      g
pos_1501 0.145563737522463      a      c      e      a      g      g
pos_2001 0.143940027378837      a      c      e      e      g      g

When using rpart() as follow, the program runs for ages, and after a few hours,
R is abruptly killed :

library(rpart)
fit <- rpart(distance ~ ., data = mydata)

When I change the categorical variables into numeric values (e.g. a = 1, b = 2,
c = 3, etc...), the program runs normally in a few seconds. But this is not
what I want because it separates my variables according to "group7 > 4.5"
(continuous) and not "group7 = a,b,d,f" or "c,e,g" (discrete).

here is the result :
>fit
n= 9271

node), split, n, deviance, yval
      * denotes terminal node

 1) root 9271 28.43239000 0.1768883
   2) group7>=4.5 5830  4.87272700 0.1534626
     4) group5< 5.5 5783  3.29538700 0.1520110
       8) group5>=4.5 3068  0.68517040 0.1412967 *
       9) group5< 4.5 2715  1.86003600 0.1641184 *
     5) group5>=5.5 47  0.06597044 0.3320614 *
   3) group7< 4.5 3441 14.93984000 0.2165781
     6) group5< 1.5 1461  1.00414700 0.1906630 *
     7) group5>=1.5 1980 12.23050000 0.2357002
      14) group6>=2.5 1659  2.95395700 0.2090232
        28) group3>=2.5 1315  1.65184200 0.1957505 *
        29) group3< 2.5 344  0.18490260 0.2597607 *
      15) group6< 2.5 321  1.99404400 0.3735729 *


When I create a small dataframe such as the example above, e.g. :

distance = rnorm(5,0.15,0.01)
group3 = c("a","a","a","a","a")
group4 = c("c","a","c","c","c")
group5 = c("e","a","e","e","e")
group6 = c("a","a","a","a","e")
smalldata = data.frame(cbind(distance,group3,group4,group5,group6))

The program runs normally in a few seconds.

Why does it work using the large dataset whith only numeric values but not with 
categorical predictor variables ?

I have the impression that it considers my response variable also as a
categorical variable and therefore it can't handle 9271 levels, which is quite
normal. Is there a way to solve this problem ?

I thank you all for your time and help,

Jennifer Becq



From menghui at gmail.com  Mon Mar 21 17:17:16 2005
From: menghui at gmail.com (Menghui Chen)
Date: Mon, 21 Mar 2005 11:17:16 -0500
Subject: [R] How to do knn regression
Message-ID: <7d30e3c050321081731112760@mail.gmail.com>

How can I do a simple k nearest neighbor regression in R? My training
data have 1 predictor and 1 outcome, both are numeric. I also need to
use FPE and SC to find the optimal model. I know there is knn() in
class package, but it's for knn classification. I also find a kknn
package. What function should I use?

Thanks in advance!

Menghui



From andy_liaw at merck.com  Mon Mar 21 17:22:08 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 21 Mar 2005 11:22:08 -0500
Subject: [R] How to do knn regression
Message-ID: <3A822319EB35174CA3714066D590DCD50994E8AF@usrymx25.merck.com>

ksmooth() will work for you, since you only have one predictor.  There are
better choices, though, such as loess().

Andy

> From: Menghui Chen
> 
> How can I do a simple k nearest neighbor regression in R? My training
> data have 1 predictor and 1 outcome, both are numeric. I also need to
> use FPE and SC to find the optimal model. I know there is knn() in
> class package, but it's for knn classification. I also find a kknn
> package. What function should I use?
> 
> Thanks in advance!
> 
> Menghui
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From iacolonn at uiuc.edu  Mon Mar 21 17:41:45 2005
From: iacolonn at uiuc.edu (Ignacio Colonna)
Date: Mon, 21 Mar 2005 10:41:45 -0600
Subject: [R] Bug on the stem function or in my brain ?
In-Reply-To: <423EE505.7070601@umn.edu>
Message-ID: <200503211641.j2LGfov3025108@expredir4.cites.uiuc.edu>

Jos?,
	Notice that the values to the left of the | in your stem plot are
all even. Odd numbers are included in the same line.

Try
> stem(time,scale=2)

  The decimal point is 1 digit(s) to the right of the |

   3 | 2
   4 | 17
   5 | 09
   6 | 4667789
   7 | 38
   8 | 3
   9 | 0335
  10 | 00
  11 | 0


ignacio

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jose A. Hernandez
Sent: Monday, March 21, 2005 9:15 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Bug on the stem function or in my brain ?

Good day R-ers!

I was running the basic statistics for the exam that my students took 
last week and something does not make sense with the stem() fucntion.

Here are two of my variables:

time, is time to complete the exam in minutes
exam.1, is the grade for the exam

In stem(), to the left of the vertical bar are the leading digits of the 
grades. To the right of the vertical bar are the last digits of the 
grades. Each single digit on the right represents one grade.

 > time
  [1]  32  41  47  50  59  64  66  66  67  67  68  69  73  78  83  90 
93  93  95
[20] 100 100 110
 > stem(time)

   The decimal point is 1 digit(s) to the right of the |

    2 | 2
    4 | 1709
    6 | 466778938
    8 | 30335
   10 | 000

The stem and leaf plot does not reflect the actual data, the bottom line 
for instance says there were 3 people that spent 100 minutes working on 
the test. The next to bottom line says there were one 80, three 83s, one 
85. And so forth.

 > exam.1
  [1]  82 100  86  81  88  78  92  23  91  49  97   9  89  78  93  60 
80  80  83
[20]  94  51 100

 > stem(exam.1)

   The decimal point is 1 digit(s) to the right of the |

    0 | 9
    2 | 3
    4 | 91
    6 | 088
    8 | 0012368912347
   10 | 00

The Stem-and-Leaf plots DO NOT correspond to the data.

Any educational insights on this issue would be appreciated.

Regards,

Jose

 > class(exam.1)
[1] "numeric"
 > class(time)
[1] "numeric"

 > version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    0.1
year     2004
month    11
day      15
language R


-- 
Jose A. Hernandez
Ph.D. Candidate
Precision Agriculture Center

Department of Soil, Water, and Climate
University of Minnesota
1991 Upper Buford Circle
St. Paul, MN 55108

Ph. (612) 625-0445, Fax. (612) 625-2208

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From marvena at tin.it  Mon Mar 21 17:42:52 2005
From: marvena at tin.it (marvena@tin.it)
Date: Mon, 21 Mar 2005 17:42:52 +0100
Subject: [R] Maximum amount of memory 
Message-ID: <4200098800021576@ims4b.cp.tin.it>

Hi, 
I have a problem:I need to use the maximum amount of memory in order to
perform a very tough analysis. By purchasing the suitable computer, what's
the maximum amount of memory obtainable in R?
Thanks, 

                          Marco



From tlumley at u.washington.edu  Mon Mar 21 17:44:42 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 21 Mar 2005 08:44:42 -0800 (PST)
Subject: [R] NaN
In-Reply-To: <3542A1BF5AE1984D9FF577DA2CF8BA9868B13A@MSX2>
References: <3542A1BF5AE1984D9FF577DA2CF8BA9868B13A@MSX2>
Message-ID: <Pine.A41.4.61b.0503210842390.11586@homer04.u.washington.edu>

On Mon, 21 Mar 2005, Brett Stansfield wrote:

> Dear R
> What does NaN mean?

Not a Number.  It is the result of improper mathematical expressions such 
as 0/0, Inf/Inf,  logarithms of negative numbers, and so on.  Might you
have some zeros in `para' giving -Inf logpara?

 	-thomas

> I recently did a correlation on a batch of data for some reason it didn't
> like one column
> cor(sleep,use="complete.obs")
>                 BodyWt     BrainWt  SlowSleep   ParaSleep TotalSleep
> BodyWt       1.00000000  0.95584875 -0.3936373 -0.07488845 -0.3428373
> BrainWt      0.95584875  1.00000000 -0.3867947 -0.07427740 -0.3370815
> SlowSleep   -0.39363729 -0.38679474  1.0000000  0.51824287  0.9676730
> ParaSleep   -0.07488845 -0.07427740  0.5182429  1.00000000  0.7171864
> TotalSleep  -0.34283732 -0.33708151  0.9676730  0.71718643  1.0000000
> Lifespan     0.46982146  0.62938940 -0.3722345 -0.26834006 -0.3824462
> Gestation    0.71434413  0.73353206 -0.6061048 -0.40893177 -0.6144743
> PredIndex    0.09588524 -0.01538017 -0.3526558 -0.39795310 -0.4047155
> ExposeIndex  0.40563880  0.32318968 -0.5802789 -0.50363338 -0.6213578
> DangerIndex  0.25932512  0.15093686 -0.5346247 -0.57194862 -0.6043029
> logbrw       0.47461094  0.53992522 -0.6302266 -0.36884187 -0.6223073
> loglife      0.37351520  0.45819097 -0.3549184 -0.38521174 -0.4028017
> loggest      0.41308558  0.45045240 -0.5754478 -0.57234786 -0.6376850
> logbw        0.50905390  0.52255094 -0.6603217 -0.26930774 -0.6174775
> logpara             NaN         NaN        NaN         NaN        NaN
>               Lifespan   Gestation   PredIndex ExposeIndex DangerIndex
> BodyWt       0.46982146  0.71434413  0.09588524   0.4056388  0.25932512
> BrainWt      0.62938940  0.73353206 -0.01538017   0.3231897  0.15093686
> SlowSleep   -0.37223446 -0.60610477 -0.35265576  -0.5802789 -0.53462471
> ParaSleep   -0.26834006 -0.40893177 -0.39795310  -0.5036334 -0.57194862
> TotalSleep  -0.38244618 -0.61447431 -0.40471545  -0.6213578 -0.60430286
> Lifespan     1.00000000  0.64638866 -0.16973575   0.3157456  0.01468596
> Gestation    0.64638866  1.00000000  0.09079823   0.5734727  0.30623551
> PredIndex   -0.16973575  0.09079823  1.00000000   0.6256876  0.92731729
> ExposeIndex  0.31574564  0.57347265  0.62568764   1.0000000  0.78980702
> DangerIndex  0.01468596  0.30623551  0.92731729   0.7898070  1.00000000
> logbrw       0.73584286  0.78178948  0.07112786   0.6132218  0.28600619
> loglife      0.87677362  0.63260838 -0.09023386   0.5042496  0.14082719
> loggest      0.56014783  0.88539870  0.09040680   0.5830778  0.30998808
> logbw        0.64683285  0.75938272  0.13046983   0.6473671  0.33957121
> logpara             NaN         NaN         NaN         NaN         NaN
>                 logbrw     loglife    loggest      logbw logpara
> BodyWt       0.47461094  0.37351520  0.4130856  0.5090539     NaN
> BrainWt      0.53992522  0.45819097  0.4504524  0.5225509     NaN
> SlowSleep   -0.63022657 -0.35491836 -0.5754478 -0.6603217     NaN
> ParaSleep   -0.36884187 -0.38521174 -0.5723479 -0.2693077     NaN
> TotalSleep  -0.62230729 -0.40280169 -0.6376850 -0.6174775     NaN
> Lifespan     0.73584286  0.87677362  0.5601478  0.6468328     NaN
> Gestation    0.78178948  0.63260838  0.8853987  0.7593827     NaN
> PredIndex    0.07112786 -0.09023386  0.0904068  0.1304698     NaN
> ExposeIndex  0.61322176  0.50424965  0.5830778  0.6473671     NaN
> DangerIndex  0.28600619  0.14082719  0.3099881  0.3395712     NaN
> logbrw       1.00000000  0.79233406  0.7771888  0.9514144     NaN
> loglife      0.79233406  1.00000000  0.6417551  0.7079108     NaN
> loggest      0.77718882  0.64175514  1.0000000  0.7069276     NaN
> logbw        0.95141435  0.70791078  0.7069276  1.0000000     NaN
> logpara             NaN         NaN        NaN        NaN       1
>
> for some reason log para has this NaN symbol come up
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From francoisromain at free.fr  Mon Mar 21 18:03:26 2005
From: francoisromain at free.fr (Romain Francois)
Date: Mon, 21 Mar 2005 18:03:26 +0100
Subject: [R] Convex hull line coordinates..
In-Reply-To: <1111399786.423e9d6a0c3a2@webmail.wsl.ch>
References: <1107965723.420a371b2bf55@webmail.wsl.ch>	<1111151047.423ad1c781698@webmail.wsl.ch>
	<1111399786.423e9d6a0c3a2@webmail.wsl.ch>
Message-ID: <423EFE5E.8060905@free.fr>

Hello,

I'm not sure i got your question right, but i think the whole point is 
to find the equation of a line which passes by two points
See ?lm

Romain.


Le 21.03.2005 11:09, achilleas.psomas at wsl.ch a ?crit :

>Hello R-Helpers..
>
>I am still new in R and I have the following question..
>I am applying the function chull on a 2D dataset and have the convex hull
>nicely
>calculated and plotted.
>Do you know if there is a way to extract the coordinates of the line created
>from the connection of the chull data points..
>I have alredy tried with "approx" to lineary interpolate but its not working
>correctly since the interpolated values sometimes fall inside the convex .
>Using the "yleft" or "yright" doesnt seem to help..
>
>Any suggestions?
>Thank you in advance
>
>Achilleas Psomas
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>


-- 
Romain FRANCOIS : francoisromain at free.fr
page web : http://addictedtor.free.fr/  (en construction)
06 18 39 14 69 / 01 46 80 65 60
_______________________________________________________
Etudiant en 3eme ann?e
Institut de Statistique de l'Universit? de Paris (ISUP)
Fili?re Industrie et Services
http://www.isup.cicrp.jussieu.fr/



From maechler at stat.math.ethz.ch  Mon Mar 21 18:08:58 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 21 Mar 2005 18:08:58 +0100
Subject: [R] Violin plot for discrete variables.
In-Reply-To: <3A822319EB35174CA3714066D590DCD50994E8A6@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50994E8A6@usrymx25.merck.com>
Message-ID: <16958.65450.926028.876972@stat.math.ethz.ch>

>>>>> "AndyL" == Liaw, Andy <andy_liaw at merck.com>
>>>>>     on Mon, 21 Mar 2005 08:14:20 -0500 writes:

    AndyL> I'd suggest dotcharts, such as:
    AndyL> x1 <- sample(letters[1:4], 100, replace=TRUE, prob=c(.2, .3, .4, .1))
    AndyL> x2 <- sample(letters[1:4], 100, replace=TRUE, prob=c(.1, .4, .3, .2))
    AndyL> f1 <- table(x1) / length(x1)
    AndyL> f2 <- table(x2) / length(x2)
    AndyL> lev <- factor(c(names(f1), names(f2)))
    AndyL> require(lattice)

    AndyL> dotplot(lev ~ c(f1, f2), groups=rep(1:2, c(length(f1), length(f2))),
    AndyL>         panel=panel.superpose)

yes. Maybe slightly even more useful --- and closer to the 
plot(table(.)), ...) that Witold mentioned would be the
following slight variation:

dotplot(lev ~ c(f1, f2), groups=rep(1:2, c(length(f1), length(f2))),
        panel=panel.superpose, type =c("p","h"))

Note the nice lattice feature (thanks to Deepayan Sarkar!) of
allowing type to be a union of two basic types.

Martin



From clint at ecy.wa.gov  Mon Mar 21 18:24:42 2005
From: clint at ecy.wa.gov (Clint Bowman)
Date: Mon, 21 Mar 2005 09:24:42 -0800 (PST)
Subject: [R] Convex hull line coordinates..
In-Reply-To: <423EFE5E.8060905@free.fr>
Message-ID: <Pine.LNX.4.44.0503210914170.10199-100000@aeolus.ecy.wa.gov>

?chull

states:

Value:

     An integer vector giving the indices of the points lying on the
     convex hull, in clockwise order.

therefore (see Example in ?chull) you have the end points of each line 
segment from which you can compute the equation of each line segment.  
Since the precision of the calculation is finite, there will necessarily 
be some portion of each line that may fall on one side or the other of the 
"true" convex hull.

Or am I off base?

Clint

On Mon, 21 Mar 2005, Romain Francois wrote:

> Hello,
> 
> I'm not sure i got your question right, but i think the whole point is 
> to find the equation of a line which passes by two points
> See ?lm
> 
> Romain.
> 
> 
> Le 21.03.2005 11:09, achilleas.psomas at wsl.ch a ?crit :
> 
> >Hello R-Helpers..
> >
> >I am still new in R and I have the following question..
> >I am applying the function chull on a 2D dataset and have the convex hull
> >nicely
> >calculated and plotted.
> >Do you know if there is a way to extract the coordinates of the line created
> >from the connection of the chull data points..
> >I have alredy tried with "approx" to lineary interpolate but its not working
> >correctly since the interpolated values sometimes fall inside the convex .
> >Using the "yleft" or "yright" doesnt seem to help..
> >
> >Any suggestions?
> >Thank you in advance
> >
> >Achilleas Psomas
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> >
> >  
> >
> 
> 
> 

-- 
Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600



From lisas at salford-systems.com  Mon Mar 21 18:11:30 2005
From: lisas at salford-systems.com (Lisa Solomon)
Date: Mon, 21 Mar 2005 09:11:30 -0800
Subject: [R] NEXT WEEK: New York City Data Mining Conference: Two full-days
 of Case Study Presentations
Message-ID: <423F0042.9040806@salford-systems.com>

Apologies for cross posting
-----------------------------------------------------------------------------
                    Salford Systems Data Mining 2005
                      New York, March 28-30, 2005
Focusing on the Contributions of Data Mining to Solving Real World 
Challenges

               Two Full Days of Case Study Presentations

                           CONFERENCE SCHEDULE
              http://www.salforddatamining.com/program.htm
------------------------------------------------------------------------------

TRACKS:
Data Mining Issues and Implementation
Real World Success Stories: Business
Real World Success Stories: Biomedical
Real World Success Stories: Environmental
Novel Methodologies

POST-CONFERENCE HANDS-ON TRAINING
March 31 - April 1, 2005
Network with Data Mining Experts and Pick up Pointers from Companies, 
Research Centers and Laboratories Including:
The International Monetary Fund, American Express, Barnes and Noble, 
Visa, Pfizer, International Steel, Wells Fargo Bank, Ciphergen, Stanford 
Linear Accelerator, Johns Hopkins University Medical School, AT&T Labs - 
Research and the Columbia University School of Public Health.

If you have an interest in attending this conference or the 
post-conference training, please contact Lisa Solomon:
Phone: 619-543-8880 x14, Email:  lisas at salforddatamining.com
Conference Website: http://www.salforddatamining.com



From xiyanlon at gmail.com  Mon Mar 21 18:41:22 2005
From: xiyanlon at gmail.com (Xiyan Lon)
Date: Mon, 21 Mar 2005 18:41:22 +0100
Subject: [R] Read a dataset with different lengths
Message-ID: <9a38bfc7050321094133c689dc@mail.gmail.com>

Dear useR again,
How can I read a dataset if lines in dataset did not have same
elements (have different lengths), For example:

1    2,  4, 16,  1,  1,  3,  1,  1, 15,  5,  1,  1, 14,  1,  1
2    2, 13,  5,  1,  1,  3,  1,  1, 15,  5,  1,  1, 14,  1,  1
3    4,  5, 11,  1,  1,  6,  1,  1,  5, 14,  1,  1, 15,  1,  1
4    2,  5,  9,  1,  1, 14,  1,  1,  8, 16,  1,  1, 13,  1,  1
5    3,  7, 14,  1,  1, 14,  1,  1,  5, 21,  1,  1,  8,  1,  1
6            6,  3,  1, 12,  1,  1,  5,  8,  1,  1, 15,  1,  1
7            6,  3,  1, 11,  1,  1, 10,  7,  1,  1, 21,  1,  1
8           21, 20,  9,  1,  1,  6,  1,  1, 13, 10,  1,  1,  1
9    5,  7, 21,  1,  1, 13,  1,  1, 14,  2,  1,  1,  6,  1,  1
10   8, 14, 10,  1,  1,  5,  1,  1, 10,  5,  1,  1,  5,  1,  1
11   5, 20, 17,  1,  1, 19,  1,  1, 14,  7,  1,  1,  6,  1,  1
12   7,  4, 11,  1,  1,  2,  1,  1,  5, 13,  1,  1, 14,  1,  1
13   7, 14, 13,  1,  1,  6,  1,  1, 13, 16,  1,  1, 17,  1,  1
14   7, 14,  5,  1,  1,  5,  1,  1,  5, 17,  1,  1, 17,  1,  1
15           3,  9, 12,  1,  1, 18,  1,  1,  6,  1,  4,  1,  1
16   7, 10,  5,  1,  1, 12,  1,  1,  5, 17,  1,  1, 13,  1,  1
17  12,  8, 16,  1,  1,  5,  1,  1,  8, 10,  1,  1, 14,  1,  1
18   5, 11,  7,  1,  1,  5,  1,  1, 18, 13,  1,  1, 17,  1,  1
19   7, 13,  8,  1,  1, 14,  1,  1,  5, 17,  1,  1, 13,  1,  1
20   7, 18, 21,  1,  1, 16,  1,  1,  5, 17,  1,  1, 13,  1,  1

I know that in BioC package rmutil have a function (read.list) to
handle different lengths sets of lines but it did not work.
> library(rmutil)
Error in library(rmutil) : 'rmutil' is not a valid package -- installed < 2.0.0?
> 

Are there any others function to handle this.

Best regards
Xiyan Lon

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    0.1            
year     2004           
month    11             
day      15             
language R              
>



From spencer.graves at pdf.com  Mon Mar 21 18:45:26 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 21 Mar 2005 09:45:26 -0800
Subject: [R] classes of data (with a variable size)
In-Reply-To: <20050321105933.46015.qmail@web86902.mail.ukl.yahoo.com>
References: <20050321105933.46015.qmail@web86902.mail.ukl.yahoo.com>
Message-ID: <423F0836.7050801@pdf.com>

      Have you looked at "sample" and the various ways of subscripting 
in, e.g., "An Introduction to R" [the upper left option after 
help.start() in R 2.0.1]? 

      Beyond that, I'm very sorry, but I can't understand what you are 
asking.  If this does NOT answer your question, please read the posting 
guide (http://www.R-project.org/posting-guide.html).  Only last week, we 
had several comments from people saying they had solved their own 
problem in the process of preparing a very simple example of what they 
were trying to do, as suggested in the posting guide.  Even if that 
process does not answer your question, I believe it will increase the 
chances you will get a useful reply from your nest post to this list. 

      hope this helps. 
      spencer

Guillaume STORCHI wrote:

>How is it possible to "split" a data.frame in order to get classes with
>variable size.
>actually I'd like to get classes of data with classe size (cs) so that
>cs becomes bigger with an other increasing value.
>
>Guillaume Storchi
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From tjrc at sanger.ac.uk  Mon Mar 21 18:54:25 2005
From: tjrc at sanger.ac.uk (Tim Cutts)
Date: Mon, 21 Mar 2005 17:54:25 +0000
Subject: [R] Maximum amount of memory 
In-Reply-To: <4200098800021576@ims4b.cp.tin.it>
References: <4200098800021576@ims4b.cp.tin.it>
Message-ID: <e9be2c9e8f192b10d54c316ffc57a96f@sanger.ac.uk>


On 21 Mar 2005, at 4:42 pm, marvena at tin.it wrote:

> Hi,
> I have a problem:I need to use the maximum amount of memory in order to
> perform a very tough analysis. By purchasing the suitable computer, 
> what's
> the maximum amount of memory obtainable in R?

Assuming that R is happy to use 64-bit memory pointers, the limit will 
be your wallet.  You could buy an SGI Altix and just keep buying more 
and more memory for it.  I don't know the limit - I know that SGI have 
sold one machine in Japan with 13 terabytes of memory.  We have two of 
them here with 192 GB of RAM each, but I haven't tried R on them yet - 
they're used for other things.

Whether such a course of action is sensible is another matter.  Large 
memory machines rapidly become *extremely* expensive; once you have to 
use DIMMs larger than 1GB each, the price becomes prohibitive.  
Consider spending the same amount of money on employing several 
programmers and/or statisticians to break your problem down into 
smaller tasks than are tractable on smaller machines.

Our 192 GB machine cost quite a lot more than 192 desktop PCs with 1GB 
of RAM each.  In fact, the memory becomes so expensive the rest of the 
machine is virtually free, in comparison.  :-)

If you can get away with more modest amounts of memory, then a machine 
like the HP DL-585 might suit you - a quad processor Opteron, which can 
take up to 32GB or so of memory.  Fairly modest price.

Tim

-- 
Dr Tim Cutts
Informatics Systems Group, Wellcome Trust Sanger Institute
GPG: 1024D/E3134233 FE3D 6C73 BBD6 726A A3F5  860B 3CDD 3F56 E313 4233



From andy_liaw at merck.com  Mon Mar 21 18:54:22 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 21 Mar 2005 12:54:22 -0500
Subject: [R] Read a dataset with different lengths
Message-ID: <3A822319EB35174CA3714066D590DCD50994E8B0@usrymx25.merck.com>

If the file is formatted as you've shown, you should be able to read it with
read.fwf().

Andy

> From: Xiyan Lon
> 
> Dear useR again,
> How can I read a dataset if lines in dataset did not have same
> elements (have different lengths), For example:
> 
> 1    2,  4, 16,  1,  1,  3,  1,  1, 15,  5,  1,  1, 14,  1,  1
> 2    2, 13,  5,  1,  1,  3,  1,  1, 15,  5,  1,  1, 14,  1,  1
> 3    4,  5, 11,  1,  1,  6,  1,  1,  5, 14,  1,  1, 15,  1,  1
> 4    2,  5,  9,  1,  1, 14,  1,  1,  8, 16,  1,  1, 13,  1,  1
> 5    3,  7, 14,  1,  1, 14,  1,  1,  5, 21,  1,  1,  8,  1,  1
> 6            6,  3,  1, 12,  1,  1,  5,  8,  1,  1, 15,  1,  1
> 7            6,  3,  1, 11,  1,  1, 10,  7,  1,  1, 21,  1,  1
> 8           21, 20,  9,  1,  1,  6,  1,  1, 13, 10,  1,  1,  1
> 9    5,  7, 21,  1,  1, 13,  1,  1, 14,  2,  1,  1,  6,  1,  1
> 10   8, 14, 10,  1,  1,  5,  1,  1, 10,  5,  1,  1,  5,  1,  1
> 11   5, 20, 17,  1,  1, 19,  1,  1, 14,  7,  1,  1,  6,  1,  1
> 12   7,  4, 11,  1,  1,  2,  1,  1,  5, 13,  1,  1, 14,  1,  1
> 13   7, 14, 13,  1,  1,  6,  1,  1, 13, 16,  1,  1, 17,  1,  1
> 14   7, 14,  5,  1,  1,  5,  1,  1,  5, 17,  1,  1, 17,  1,  1
> 15           3,  9, 12,  1,  1, 18,  1,  1,  6,  1,  4,  1,  1
> 16   7, 10,  5,  1,  1, 12,  1,  1,  5, 17,  1,  1, 13,  1,  1
> 17  12,  8, 16,  1,  1,  5,  1,  1,  8, 10,  1,  1, 14,  1,  1
> 18   5, 11,  7,  1,  1,  5,  1,  1, 18, 13,  1,  1, 17,  1,  1
> 19   7, 13,  8,  1,  1, 14,  1,  1,  5, 17,  1,  1, 13,  1,  1
> 20   7, 18, 21,  1,  1, 16,  1,  1,  5, 17,  1,  1, 13,  1,  1
> 
> I know that in BioC package rmutil have a function (read.list) to
> handle different lengths sets of lines but it did not work.
> > library(rmutil)
> Error in library(rmutil) : 'rmutil' is not a valid package -- 
> installed < 2.0.0?
> > 
> 
> Are there any others function to handle this.
> 
> Best regards
> Xiyan Lon
> 
> > version
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    2              
> minor    0.1            
> year     2004           
> month    11             
> day      15             
> language R              
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From B.Rowlingson at lancaster.ac.uk  Mon Mar 21 18:56:56 2005
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 21 Mar 2005 17:56:56 +0000
Subject: [R] Convex hull line coordinates..
In-Reply-To: <423EFE5E.8060905@free.fr>
References: <1107965723.420a371b2bf55@webmail.wsl.ch>	<1111151047.423ad1c781698@webmail.wsl.ch>	<1111399786.423e9d6a0c3a2@webmail.wsl.ch>
	<423EFE5E.8060905@free.fr>
Message-ID: <423F0AE8.90409@lancaster.ac.uk>

Romain Francois wrote:
> Hello,
> 
> I'm not sure i got your question right, but i think the whole point is 
> to find the equation of a line which passes by two points
> See ?lm

  Or see a basic geometry book, where you will find a formula such as:

  (x-x1)/(y-y1) = (x2-x1)/(y2-y1)

for the equation of a line passing through (x1,y1) and (x2,y2).

Just watch out for y2==y1 and the inevitable division by zero. Might be 
better to ask what you want the line for in order to find a 
representation that better suits your need - a single point and slope, 
perhaps.

Baz



From ligges at statistik.uni-dortmund.de  Mon Mar 21 19:03:04 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 21 Mar 2005 19:03:04 +0100
Subject: [R] Read a dataset with different lengths
In-Reply-To: <9a38bfc7050321094133c689dc@mail.gmail.com>
References: <9a38bfc7050321094133c689dc@mail.gmail.com>
Message-ID: <423F0C58.4030809@statistik.uni-dortmund.de>

Xiyan Lon wrote:
> Dear useR again,
> How can I read a dataset if lines in dataset did not have same
> elements (have different lengths), For example:
> 
> 1    2,  4, 16,  1,  1,  3,  1,  1, 15,  5,  1,  1, 14,  1,  1
> 2    2, 13,  5,  1,  1,  3,  1,  1, 15,  5,  1,  1, 14,  1,  1
> 3    4,  5, 11,  1,  1,  6,  1,  1,  5, 14,  1,  1, 15,  1,  1
> 4    2,  5,  9,  1,  1, 14,  1,  1,  8, 16,  1,  1, 13,  1,  1
> 5    3,  7, 14,  1,  1, 14,  1,  1,  5, 21,  1,  1,  8,  1,  1
> 6            6,  3,  1, 12,  1,  1,  5,  8,  1,  1, 15,  1,  1
> 7            6,  3,  1, 11,  1,  1, 10,  7,  1,  1, 21,  1,  1
> 8           21, 20,  9,  1,  1,  6,  1,  1, 13, 10,  1,  1,  1
> 9    5,  7, 21,  1,  1, 13,  1,  1, 14,  2,  1,  1,  6,  1,  1
> 10   8, 14, 10,  1,  1,  5,  1,  1, 10,  5,  1,  1,  5,  1,  1
> 11   5, 20, 17,  1,  1, 19,  1,  1, 14,  7,  1,  1,  6,  1,  1
> 12   7,  4, 11,  1,  1,  2,  1,  1,  5, 13,  1,  1, 14,  1,  1
> 13   7, 14, 13,  1,  1,  6,  1,  1, 13, 16,  1,  1, 17,  1,  1
> 14   7, 14,  5,  1,  1,  5,  1,  1,  5, 17,  1,  1, 17,  1,  1
> 15           3,  9, 12,  1,  1, 18,  1,  1,  6,  1,  4,  1,  1
> 16   7, 10,  5,  1,  1, 12,  1,  1,  5, 17,  1,  1, 13,  1,  1
> 17  12,  8, 16,  1,  1,  5,  1,  1,  8, 10,  1,  1, 14,  1,  1
> 18   5, 11,  7,  1,  1,  5,  1,  1, 18, 13,  1,  1, 17,  1,  1
> 19   7, 13,  8,  1,  1, 14,  1,  1,  5, 17,  1,  1, 13,  1,  1
> 20   7, 18, 21,  1,  1, 16,  1,  1,  5, 17,  1,  1, 13,  1,  1
>


For data structured as above, read.fwf() should work.


> I know that in BioC package rmutil have a function (read.list) to
> handle different lengths sets of lines but it did not work.
> 
>>library(rmutil)
> 
> Error in library(rmutil) : 'rmutil' is not a valid package -- installed < 2.0.0?

You have to install a version that has been compiled for R-2.0.x

Uwe Ligges



> 
> Are there any others function to handle this.
> 
> Best regards
> Xiyan Lon
> 
> 
>>version
> 
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    2              
> minor    0.1            
> year     2004           
> month    11             
> day      15             
> language R              
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From gunter.berton at gene.com  Mon Mar 21 19:09:36 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Mon, 21 Mar 2005 10:09:36 -0800
Subject: [R] Read a dataset with different lengths
In-Reply-To: <9a38bfc7050321094133c689dc@mail.gmail.com>
Message-ID: <200503211809.j2LI9a8i007262@hertz.gene.com>

Without some sort of formatting or prior knowledge to indicate which fields
are present and which are missing, I don't see how such a file can be
properly read. With such formatting present, there are several ways. e.g.
See ?read.table, ?readLines, ?scan, ?connections,  ...

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Xiyan Lon
> Sent: Monday, March 21, 2005 9:41 AM
> To: R-help at stat.math.ethz.ch
> Subject: [R] Read a dataset with different lengths
> 
> Dear useR again,
> How can I read a dataset if lines in dataset did not have same
> elements (have different lengths), For example:
> 
> 1    2,  4, 16,  1,  1,  3,  1,  1, 15,  5,  1,  1, 14,  1,  1
> 2    2, 13,  5,  1,  1,  3,  1,  1, 15,  5,  1,  1, 14,  1,  1
> 3    4,  5, 11,  1,  1,  6,  1,  1,  5, 14,  1,  1, 15,  1,  1
> 4    2,  5,  9,  1,  1, 14,  1,  1,  8, 16,  1,  1, 13,  1,  1
> 5    3,  7, 14,  1,  1, 14,  1,  1,  5, 21,  1,  1,  8,  1,  1
> 6            6,  3,  1, 12,  1,  1,  5,  8,  1,  1, 15,  1,  1
> 7            6,  3,  1, 11,  1,  1, 10,  7,  1,  1, 21,  1,  1
> 8           21, 20,  9,  1,  1,  6,  1,  1, 13, 10,  1,  1,  1
> 9    5,  7, 21,  1,  1, 13,  1,  1, 14,  2,  1,  1,  6,  1,  1
> 10   8, 14, 10,  1,  1,  5,  1,  1, 10,  5,  1,  1,  5,  1,  1
> 11   5, 20, 17,  1,  1, 19,  1,  1, 14,  7,  1,  1,  6,  1,  1
> 12   7,  4, 11,  1,  1,  2,  1,  1,  5, 13,  1,  1, 14,  1,  1
> 13   7, 14, 13,  1,  1,  6,  1,  1, 13, 16,  1,  1, 17,  1,  1
> 14   7, 14,  5,  1,  1,  5,  1,  1,  5, 17,  1,  1, 17,  1,  1
> 15           3,  9, 12,  1,  1, 18,  1,  1,  6,  1,  4,  1,  1
> 16   7, 10,  5,  1,  1, 12,  1,  1,  5, 17,  1,  1, 13,  1,  1
> 17  12,  8, 16,  1,  1,  5,  1,  1,  8, 10,  1,  1, 14,  1,  1
> 18   5, 11,  7,  1,  1,  5,  1,  1, 18, 13,  1,  1, 17,  1,  1
> 19   7, 13,  8,  1,  1, 14,  1,  1,  5, 17,  1,  1, 13,  1,  1
> 20   7, 18, 21,  1,  1, 16,  1,  1,  5, 17,  1,  1, 13,  1,  1
> 
> I know that in BioC package rmutil have a function (read.list) to
> handle different lengths sets of lines but it did not work.
> > library(rmutil)
> Error in library(rmutil) : 'rmutil' is not a valid package -- 
> installed < 2.0.0?
> > 
> 
> Are there any others function to handle this.
> 
> Best regards
> Xiyan Lon
> 
> > version
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    2              
> minor    0.1            
> year     2004           
> month    11             
> day      15             
> language R              
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From rpeng at jhsph.edu  Mon Mar 21 19:11:10 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon, 21 Mar 2005 13:11:10 -0500
Subject: [R] Maximum amount of memory
In-Reply-To: <4200098800021576@ims4b.cp.tin.it>
References: <4200098800021576@ims4b.cp.tin.it>
Message-ID: <423F0E3E.6090905@jhsph.edu>

The amount of memory you can access depends on many things, most of 
which are not related to R.  With a 64-bit processor and suitable OS 
we've used R on a machines with 16GB of RAM (and accessed most of it). 
  Of course, the memory does get very expensive after a certain point....

-roger

marvena at tin.it wrote:
> Hi, 
> I have a problem:I need to use the maximum amount of memory in order to
> perform a very tough analysis. By purchasing the suitable computer, what's
> the maximum amount of memory obtainable in R?
> Thanks, 
> 
>                           Marco
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/



From kjetil at acelerate.com  Mon Mar 21 18:13:00 2005
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Mon, 21 Mar 2005 13:13:00 -0400
Subject: [R] Generating Interaction Factors (combinations of Data Frame
	columns)
In-Reply-To: <39c075e4a56c15e4c3270d6f007a44d9@comcast.net>
References: <39c075e4a56c15e4c3270d6f007a44d9@comcast.net>
Message-ID: <423F009C.3010408@acelerate.com>

Thomas Hopper wrote:

> I'm starting to do a fair amount of DOE in my day job and need to 
> generate full- and fractional-factorial designs.
>
> One of the things I'd like to do is generate all possible interaction 
> effects, given the main effects. I've been searching through the 
> documentation, packages and mail list archives, but the closest I can 
> find are combin() in package combinat and combine() and combinations() 
> in gregsmisc, none of which actually produces the results I want.
>
> Given a data frame with columns labeled A, B, C and D, I would like to 
> generate a data frame with columns that are the combination of each of 
> the columns in the original data frame. The output columns would be 
> A*B, A*C, A*D, A*E, A*B*C, A*B*D,..., A*B*C*D.
>
> Alternatively, I'd want to generate the interactions for a given level 
> (2-factor or 3-factor).
>
> If such a function already exists, I'd be more than happy to use it.
>
> If it doesn't, I can write it, but I would appreciate a little help 
> with the algorithm for generating the combinations...how do I loop 
> through the given factors to generate all possible combinations?
>
> Thanks,
>
> Tom
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
>
>
library(BHH2) # on CRAN
?ffDesMatrix
?ffFullMatrix

-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra





-- 
No virus found in this outgoing message.
Checked by AVG Anti-Virus.



From p.dalgaard at biostat.ku.dk  Mon Mar 21 19:19:52 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 21 Mar 2005 19:19:52 +0100
Subject: [R] Maximum amount of memory
In-Reply-To: <e9be2c9e8f192b10d54c316ffc57a96f@sanger.ac.uk>
References: <4200098800021576@ims4b.cp.tin.it>
	<e9be2c9e8f192b10d54c316ffc57a96f@sanger.ac.uk>
Message-ID: <x2mzswuaif.fsf@turmalin.kubism.ku.dk>

Tim Cutts <tjrc at sanger.ac.uk> writes:

> On 21 Mar 2005, at 4:42 pm, marvena at tin.it wrote:
> 
> > Hi,
> > I have a problem:I need to use the maximum amount of memory in order to
> > perform a very tough analysis. By purchasing the suitable computer,
> > what's
> > the maximum amount of memory obtainable in R?
> 
> Assuming that R is happy to use 64-bit memory pointers, the limit will
> be your wallet.  You could buy an SGI Altix and just keep buying more
> and more memory for it.  I don't know the limit - I know that SGI have
> sold one machine in Japan with 13 terabytes of memory.  We have two of
> them here with 192 GB of RAM each, but I haven't tried R on them yet -
> they're used for other things.

Actually, before the wallet-limit, you might bump into the limit on
the size of a single object, about 2G-items (i.e 16GB with 8-byte
doubles). We could fairly easily raise that limit, but beneath it is
another restriction, namely that Fortran subroutines tend to work with
integer sizes, so even if we had larger objects, it might be difficult
to do anything with them.
 
> Whether such a course of action is sensible is another matter.  Large
> memory machines rapidly become *extremely* expensive; once you have to
> use DIMMs larger than 1GB each, the price becomes prohibitive.
> Consider spending the same amount of money on employing several
> programmers and/or statisticians to break your problem down into
> smaller tasks than are tractable on smaller machines.
> 
> Our 192 GB machine cost quite a lot more than 192 desktop PCs with 1GB
> of RAM each.  In fact, the memory becomes so expensive the rest of the
> machine is virtually free, in comparison.  :-)
> 
> If you can get away with more modest amounts of memory, then a machine
> like the HP DL-585 might suit you - a quad processor Opteron, which
> can take up to 32GB or so of memory.  Fairly modest price.
> 
> Tim
> 
> -- 
> Dr Tim Cutts
> Informatics Systems Group, Wellcome Trust Sanger Institute
> GPG: 1024D/E3134233 FE3D 6C73 BBD6 726A A3F5  860B 3CDD 3F56 E313 4233
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ggrothendieck at myway.com  Mon Mar 21 19:28:09 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 21 Mar 2005 18:28:09 +0000 (UTC)
Subject: [R] Read a dataset with different lengths
References: <9a38bfc7050321094133c689dc@mail.gmail.com>
Message-ID: <loom.20050321T191713-203@post.gmane.org>

Xiyan Lon <xiyanlon <at> gmail.com> writes:

: 
: Dear useR again,
: How can I read a dataset if lines in dataset did not have same
: elements (have different lengths), For example:
: 
: 1    2,  4, 16,  1,  1,  3,  1,  1, 15,  5,  1,  1, 14,  1,  1
: 2    2, 13,  5,  1,  1,  3,  1,  1, 15,  5,  1,  1, 14,  1,  1
: 3    4,  5, 11,  1,  1,  6,  1,  1,  5, 14,  1,  1, 15,  1,  1
: 4    2,  5,  9,  1,  1, 14,  1,  1,  8, 16,  1,  1, 13,  1,  1
: 5    3,  7, 14,  1,  1, 14,  1,  1,  5, 21,  1,  1,  8,  1,  1
: 6            6,  3,  1, 12,  1,  1,  5,  8,  1,  1, 15,  1,  1
: 7            6,  3,  1, 11,  1,  1, 10,  7,  1,  1, 21,  1,  1
: 8           21, 20,  9,  1,  1,  6,  1,  1, 13, 10,  1,  1,  1
: 9    5,  7, 21,  1,  1, 13,  1,  1, 14,  2,  1,  1,  6,  1,  1
: 10   8, 14, 10,  1,  1,  5,  1,  1, 10,  5,  1,  1,  5,  1,  1
: 11   5, 20, 17,  1,  1, 19,  1,  1, 14,  7,  1,  1,  6,  1,  1
: 12   7,  4, 11,  1,  1,  2,  1,  1,  5, 13,  1,  1, 14,  1,  1
: 13   7, 14, 13,  1,  1,  6,  1,  1, 13, 16,  1,  1, 17,  1,  1
: 14   7, 14,  5,  1,  1,  5,  1,  1,  5, 17,  1,  1, 17,  1,  1
: 15           3,  9, 12,  1,  1, 18,  1,  1,  6,  1,  4,  1,  1
: 16   7, 10,  5,  1,  1, 12,  1,  1,  5, 17,  1,  1, 13,  1,  1
: 17  12,  8, 16,  1,  1,  5,  1,  1,  8, 10,  1,  1, 14,  1,  1
: 18   5, 11,  7,  1,  1,  5,  1,  1, 18, 13,  1,  1, 17,  1,  1
: 19   7, 13,  8,  1,  1, 14,  1,  1,  5, 17,  1,  1, 13,  1,  1
: 20   7, 18, 21,  1,  1, 16,  1,  1,  5, 17,  1,  1, 13,  1,  1
: 
: I know that in BioC package rmutil have a function (read.list) to
: handle different lengths sets of lines but it did not work.
: > library(rmutil)
: Error in library(rmutil) : 'rmutil' is not a valid package -- installed < 
2.0.0?
: > 

rmutil can be found here:
 http://popgen.unimaas.nl/~jlindsey/rcode.html

: 
: Are there any others function to handle this.



nf <- count.fields(myfile, sep = ",")
z <- read.table(myfile, sep = ",", fill = TRUE, colClass = rep(numeric(), nf))

If the first line is longest you can omit the colClass argument
and the nf computation.

The above returns a data frame with one line per row and NAs at the end
to fill it out as necessary.  If you need a list of rows without the
NAs:

lapply(as.data.frame(t(data.matrix(z))), na.omit)



From jpablo.romero at gmail.com  Mon Mar 21 19:33:54 2005
From: jpablo.romero at gmail.com (Juan Pablo Romero)
Date: Mon, 21 Mar 2005 12:33:54 -0600
Subject: [R] RSPython
Message-ID: <e6507ac7050321103357369d0f@mail.gmail.com>

Hello

I'd like to try RSPython, but can't make it work.

I think I followed all the instructions, and made this shell script to
load python:

---------------------------------
#!/bin/sh
export R_HOME=/usr/local/lib/R
export PYTHONPATH=$R_HOME/library/RSPython/Python:$R_HOME/library/RSPython/libs
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$R_HOME/lib
python
---------------------------------

Now, when I try to 'import RS', this message appears:

>>> import RS
Error in .PythonInit() : Error in Python call: values
Error in library("RSPython") : .First.lib failed for 'RSPython'
Traceback (most recent call last):
  File "<stdin>", line 1, in ?
  File "/usr/local/lib/R/library/RSPython/Python/RS.py", line 69, in ?
    library("RSPython")
  File "/usr/local/lib/R/library/RSPython/Python/RS.py", line 58, in library
    return(call("library", name));
  File "/usr/local/lib/R/library/RSPython/Python/RS.py", line 21, in call
    return RSInternal.call(name, args, other, convert, ref)
RuntimeError: error in calling R: Error in library("RSPython") :
.First.lib failed for 'RSPython'
>>>


Perhaps I'm missing some installation step?

Regardas


   Juan Pablo



From tlumley at u.washington.edu  Mon Mar 21 19:43:36 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 21 Mar 2005 10:43:36 -0800 (PST)
Subject: [R] Maximum amount of memory 
In-Reply-To: <e9be2c9e8f192b10d54c316ffc57a96f@sanger.ac.uk>
References: <4200098800021576@ims4b.cp.tin.it>
	<e9be2c9e8f192b10d54c316ffc57a96f@sanger.ac.uk>
Message-ID: <Pine.A41.4.61b.0503211032250.11586@homer04.u.washington.edu>

On Mon, 21 Mar 2005, Tim Cutts wrote:

>
> On 21 Mar 2005, at 4:42 pm, marvena at tin.it wrote:
>
>> Hi,
>> I have a problem:I need to use the maximum amount of memory in order to
>> perform a very tough analysis. By purchasing the suitable computer, what's
>> the maximum amount of memory obtainable in R?
>
> Assuming that R is happy to use 64-bit memory pointers, the limit will be 
> your wallet.


I believe there are still some limits on sizes of individual objects, such 
as C and Fortran code that uses int or INTEGER to hold dimensions.

Many packages will definitely have problems: for example, the survival 
package cannot correctly handle a design matrix with more than 2^31-1 
elements, no matter how much memory it has.  I don't know how much of the 
internal R code would also break when vectors have more than 2^31-1 
entries.

Now, 2^31-1 entries in a numeric matrix is 16Gb in one object, so your 
wallet is still likely to be the practical limit.

 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From ligges at statistik.uni-dortmund.de  Mon Mar 21 20:32:29 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 21 Mar 2005 20:32:29 +0100
Subject: [R] rpart memory problem
In-Reply-To: <1111421630.423ef2be339ab@imp6-q.free.fr>
References: <1111421630.423ef2be339ab@imp6-q.free.fr>
Message-ID: <423F214D.4070004@statistik.uni-dortmund.de>

jenniferbecq at free.fr wrote:

> Hi everyone,
> 
> I have a problem using rpart (R 2.0.1 under Unix)
> 
> Indeed, I have a large matrix (9271x7), my response variable is numeric and all
> my predictor variables are categorical (from 3 to 8 levels).


Your problem is the number of levels. You get a similar number of dummy 
variables and your problem becomes really huge.

Uwe Ligges


> 
> Here is an example :
> 
> 
>>mydata[1:5,]
> 
>                   distance group3 group4 group5 group6 group7 group8
> pos_1    0.141836040224967      a      c      e      a      g      g
> pos_501  0.153605961621317      a      a      a      a      g      g
> pos_1001 0.152246705384699      a      c      e      a      g      g
> pos_1501 0.145563737522463      a      c      e      a      g      g
> pos_2001 0.143940027378837      a      c      e      e      g      g
> 
> When using rpart() as follow, the program runs for ages, and after a few hours,
> R is abruptly killed :
> 
> library(rpart)
> fit <- rpart(distance ~ ., data = mydata)
> 
> When I change the categorical variables into numeric values (e.g. a = 1, b = 2,
> c = 3, etc...), the program runs normally in a few seconds. But this is not
> what I want because it separates my variables according to "group7 > 4.5"
> (continuous) and not "group7 = a,b,d,f" or "c,e,g" (discrete).
> 
> here is the result :
> 
>>fit
> 
> n= 9271
> 
> node), split, n, deviance, yval
>       * denotes terminal node
> 
>  1) root 9271 28.43239000 0.1768883
>    2) group7>=4.5 5830  4.87272700 0.1534626
>      4) group5< 5.5 5783  3.29538700 0.1520110
>        8) group5>=4.5 3068  0.68517040 0.1412967 *
>        9) group5< 4.5 2715  1.86003600 0.1641184 *
>      5) group5>=5.5 47  0.06597044 0.3320614 *
>    3) group7< 4.5 3441 14.93984000 0.2165781
>      6) group5< 1.5 1461  1.00414700 0.1906630 *
>      7) group5>=1.5 1980 12.23050000 0.2357002
>       14) group6>=2.5 1659  2.95395700 0.2090232
>         28) group3>=2.5 1315  1.65184200 0.1957505 *
>         29) group3< 2.5 344  0.18490260 0.2597607 *
>       15) group6< 2.5 321  1.99404400 0.3735729 *
> 
> 
> When I create a small dataframe such as the example above, e.g. :
> 
> distance = rnorm(5,0.15,0.01)
> group3 = c("a","a","a","a","a")
> group4 = c("c","a","c","c","c")
> group5 = c("e","a","e","e","e")
> group6 = c("a","a","a","a","e")
> smalldata = data.frame(cbind(distance,group3,group4,group5,group6))
> 
> The program runs normally in a few seconds.
> 
> Why does it work using the large dataset whith only numeric values but not with 
> categorical predictor variables ?
 >
> I have the impression that it considers my response variable also as a
> categorical variable and therefore it can't handle 9271 levels, which is quite
> normal. Is there a way to solve this problem ?
> 
> I thank you all for your time and help,
> 
> Jennifer Becq
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From yassir_rabhi at yahoo.fr  Mon Mar 21 21:04:20 2005
From: yassir_rabhi at yahoo.fr (yassir rabhi)
Date: Mon, 21 Mar 2005 21:04:20 +0100 (CET)
Subject: [R] Hazard function or cumulative Hazard function in R
Message-ID: <20050321200420.87188.qmail@web60103.mail.yahoo.com>

   Hi, 
 I'm student from canada, and i'work in survival
analysis.I want to know if there is a hazard function
or cumulative hazard function in R or not, i know how
to program it, but it is easy to use it if they exists
in R.
Thanks.
                                          Yassir



From ggrothendieck at myway.com  Mon Mar 21 21:26:02 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 21 Mar 2005 20:26:02 +0000 (UTC)
Subject: [R] Convex hull line coordinates..
References: <1107965723.420a371b2bf55@webmail.wsl.ch>
	<1111151047.423ad1c781698@webmail.wsl.ch>
	<1111399786.423e9d6a0c3a2@webmail.wsl.ch>
Message-ID: <loom.20050321T210759-391@post.gmane.org>

 <achilleas.psomas <at> wsl.ch> writes:

: 
: Hello R-Helpers..
: 
: I am still new in R and I have the following question..
: I am applying the function chull on a 2D dataset and have the convex hull
: nicely
: calculated and plotted.
: Do you know if there is a way to extract the coordinates of the line created
: from the connection of the chull data points..
: I have alredy tried with "approx" to lineary interpolate but its not working
: correctly since the interpolated values sometimes fall inside the convex .
: Using the "yleft" or "yright" doesnt seem to help..
: 
: Any suggestions?

1. First suggestion is not to post by following up on an unrelated thread
since some people won't see it.   e.g. try finding it on gmane.  Its there
but good luck on finding it.

2. Second suggestion is an example which creates a matrix z whose 
columns are the regression coefficients of the successive line 
segments.  Note use of lm's subset= arg to simplify code:

example(chull)  # creates hpts and X and plots convex hull
z <- sapply(2:length(hpts), function(i)
	coef(lm(X[,2] ~ X[,1], subset = hpts[i-1:0])) ) 

# we can use z to display _full_ lines, on top of the line
# _segments_ that were displyed in example(chull):
for(i in 1:ncol(z)) abline(coef = z[,i], col = "red", lty = 2)



From noel777 at gmail.com  Mon Mar 21 21:42:28 2005
From: noel777 at gmail.com (Noel Anel)
Date: Mon, 21 Mar 2005 21:42:28 +0100
Subject: [R] Numeric prediction
Message-ID: <d00895600503211242412ef5a5@mail.gmail.com>

Hello!

Which class(model) is most appropriate for numeric predition?
I used rpart class...

Thnx, Leonn.



From xiyanlon at gmail.com  Mon Mar 21 22:32:59 2005
From: xiyanlon at gmail.com (Xiyan Lon)
Date: Mon, 21 Mar 2005 22:32:59 +0100
Subject: [R] Read a dataset with different lengths
In-Reply-To: <OF9004B261.BE9B67AB-ON85256FCB.00714428-85256FCB.00714A49@nd.convergys.com>
References: <9a38bfc7050321094133c689dc@mail.gmail.com>
	<OF9004B261.BE9B67AB-ON85256FCB.00714428-85256FCB.00714A49@nd.convergys.com>
Message-ID: <9a38bfc7050321133238071db0@mail.gmail.com>

Thank you for your quick respons, helps, advise, links, etc. 
I have solved my problems now.

Best wishes,
Xiyan Lon



From William.Simpson at drdc-rddc.gc.ca  Mon Mar 21 22:44:22 2005
From: William.Simpson at drdc-rddc.gc.ca (Bill Simpson)
Date: Mon, 21 Mar 2005 16:44:22 -0500 (EST)
Subject: [R] flatten a matrix and unflatten it
Message-ID: <Pine.LNX.4.44.0503211642140.26777-100000@localhost.localdomain>

I want to flatten a matrix and unflatten it again. Please tell me how to 
do it.

1. given a matrix:
x1 y1 z1
x2 y2 z2
...
xk yk zk
convert it to a vector:
x1, y1, z1, x2, y2, z2, ..., xk, yk, zk

2. given a vector:
x1, y1, z1, x2, y2, z2, ..., xk, yk, zk
convert it to a matrix
x1 y1 z1
x2 y2 z2
...
xk yk zk

It is known that the number of dimensions is 3.

Thanks for any help!

Bill



From carsten.steinhoff at gmx.de  Mon Mar 21 22:57:04 2005
From: carsten.steinhoff at gmx.de (Carsten Steinhoff)
Date: Mon, 21 Mar 2005 22:57:04 +0100
Subject: [R] working with tables
In-Reply-To: <200503211114.j2LBA9Uu018774@hypatia.math.ethz.ch>
Message-ID: <200503212157.j2LLvBR5002198@hypatia.math.ethz.ch>

Hi,

two questions - I think simple to solve for you ...

(1) I've written a function containing some loops.
Each loop will generate a few outputs. Finally I have to combine them to get
something like a "spreadsheet" that my colleagues can import in EXCEL.

Up to now I'm doing it as follows:

With each loop-step I assign new values for each "column" of my desired
output like

colum_A=c(column_A,new_value)

At the end I combine all columns: my_table=cbind(column_A,column_B ... )

I think there should be another easier way to assign the new lines directly,
isn't it?


(2) I often have to use the "fitdistr" function included in library MASS.

The generated output for e.g. $estimate has the following format:

      mean          sd    
  0.01664940   0.97682797 

Now I want to write ONLY THE VALUE in a new variable. By doing

mean_a = ...$estimate[1]

I always have the string "mean" IN the variable. How can I eliminate this?
Thanks a lot for your answer !

Carsten



From reid_huntsinger at merck.com  Mon Mar 21 23:03:42 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Mon, 21 Mar 2005 17:03:42 -0500
Subject: [R] flatten a matrix and unflatten it
Message-ID: <D9A95B4B7B20354992E165EEADA31999056A935B@uswpmx00.merck.com>

If you can rearrange things to work column-wise rather than row-wise, then

dim(x) <- NULL

makes a matrix into a vector by concatenating columns, and

dim(x) <- c(m,n)

makes the vector x into a matrix with column 1 equal to the first m elements
of x, column 2 equal to the next m elements, etc.

If you need row-major order, you can do

x <- as.vector(t(x)) 

and 

x <- matrix(x,nrow=m,ncol=n,byrow=TRUE)

Reid Huntsinger

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Bill Simpson
Sent: Monday, March 21, 2005 4:44 PM
To: r-help
Subject: [R] flatten a matrix and unflatten it


I want to flatten a matrix and unflatten it again. Please tell me how to 
do it.

1. given a matrix:
x1 y1 z1
x2 y2 z2
...
xk yk zk
convert it to a vector:
x1, y1, z1, x2, y2, z2, ..., xk, yk, zk

2. given a vector:
x1, y1, z1, x2, y2, z2, ..., xk, yk, zk
convert it to a matrix
x1 y1 z1
x2 y2 z2
...
xk yk zk

It is known that the number of dimensions is 3.

Thanks for any help!

Bill

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From brett at hbrc.govt.nz  Mon Mar 21 23:08:54 2005
From: brett at hbrc.govt.nz (Brett Stansfield)
Date: Tue, 22 Mar 2005 10:08:54 +1200
Subject: [R] Highlighting points in a scatter plot matrix
Message-ID: <3542A1BF5AE1984D9FF577DA2CF8BA9868B147@MSX2>

Dear R
I recently did a scatterplot matrix using the following command
pairs(sleep[c("SlowSleep", "ParaSleep", "logbw", "logbrw", "loglife",
"loggest")],col=1+as.integer(ParaSleep > 5.5 | SlowSleep > 15.7))
this highlighted outlying points for some of the x,y plots that I needed to
identify. Unfortunately this highlights all the x,y plots some for which
these points are not necessarily outliers. Is there a way to specify
highlighting selected points at selected x,y plots within a matrix?



From reid_huntsinger at merck.com  Mon Mar 21 23:12:10 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Mon, 21 Mar 2005 17:12:10 -0500
Subject: [R] working with tables
Message-ID: <D9A95B4B7B20354992E165EEADA31999056A935C@uswpmx00.merck.com>

(1) Define a dataframe or matrix to hold the whole table, then assign rows
like

$ result[i,] <- newLine

Perhaps you can even vectorize the calculation to eliminate the loop...

(2) "as.vector" will strip off the names: mean_a <-
as.vector(result$estimate[1]).

Reid Huntsinger

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Carsten Steinhoff
Sent: Monday, March 21, 2005 4:57 PM
To: r-help at stat.math.ethz.ch
Subject: [R] working with tables


Hi,

two questions - I think simple to solve for you ...

(1) I've written a function containing some loops.
Each loop will generate a few outputs. Finally I have to combine them to get
something like a "spreadsheet" that my colleagues can import in EXCEL.

Up to now I'm doing it as follows:

With each loop-step I assign new values for each "column" of my desired
output like

colum_A=c(column_A,new_value)

At the end I combine all columns: my_table=cbind(column_A,column_B ... )

I think there should be another easier way to assign the new lines directly,
isn't it?


(2) I often have to use the "fitdistr" function included in library MASS.

The generated output for e.g. $estimate has the following format:

      mean          sd    
  0.01664940   0.97682797 

Now I want to write ONLY THE VALUE in a new variable. By doing

mean_a = ...$estimate[1]

I always have the string "mean" IN the variable. How can I eliminate this?
Thanks a lot for your answer !

Carsten

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ggrothendieck at myway.com  Tue Mar 22 00:23:24 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 21 Mar 2005 23:23:24 +0000 (UTC)
Subject: [R] flatten a matrix and unflatten it
References: <Pine.LNX.4.44.0503211642140.26777-100000@localhost.localdomain>
Message-ID: <loom.20050322T002008-267@post.gmane.org>

Bill Simpson <William.Simpson <at> drdc-rddc.gc.ca> writes:

: 
: I want to flatten a matrix and unflatten it again. Please tell me how to 
: do it.
: 
: 1. given a matrix:
: x1 y1 z1
: x2 y2 z2
: ...
: xk yk zk
: convert it to a vector:
: x1, y1, z1, x2, y2, z2, ..., xk, yk, zk
: 
: 2. given a vector:
: x1, y1, z1, x2, y2, z2, ..., xk, yk, zk
: convert it to a matrix
: x1 y1 z1
: x2 y2 z2
: ...
: xk yk zk
: 
: It is known that the number of dimensions is 3.
: 

myvector <- c(t(mymatrix))  
mymatrix <- matrix(myvector, byrow = TRUE, nc=3)  

If column-wise is ok rather than row-wise as you show, then
omit t() in the first line and byrow = TRUE in the second.



From kjetil at acelerate.com  Tue Mar 22 00:53:24 2005
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Mon, 21 Mar 2005 19:53:24 -0400
Subject: [R] Hazard function or cumulative Hazard function in R
In-Reply-To: <20050321200420.87188.qmail@web60103.mail.yahoo.com>
References: <20050321200420.87188.qmail@web60103.mail.yahoo.com>
Message-ID: <423F5E74.4090205@acelerate.com>

yassir rabhi wrote:

>   Hi, 
> I'm student from canada, and i'work in survival
>analysis.I want to know if there is a hazard function
>or cumulative hazard function in R or not, i know how
>to program it, but it is easy to use it if they exists
>in R.
>Thanks.
>                                          Yassir
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>
library(survival)


-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra




-- 
No virus found in this outgoing message.
Checked by AVG Anti-Virus.



From spencer.graves at pdf.com  Tue Mar 22 01:04:50 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 21 Mar 2005 16:04:50 -0800
Subject: [R] Hazard function or cumulative Hazard function in R
In-Reply-To: <20050321200420.87188.qmail@web60103.mail.yahoo.com>
References: <20050321200420.87188.qmail@web60103.mail.yahoo.com>
Message-ID: <423F6122.2040201@pdf.com>

    1.  Have you looked at the "survival" package?  Venables and Ripley 
(2002) Modern Applied Statistics with S (Springer) has a chapter on 
survival analysis that I found quite helpful.  The "survival" package 
includes hazard plots, which are discussed in Venables and Ripley. 

      2.  If that is not adequate, have you tried an "R Site Search" 
(from www.r-project.org -> search)? 

      hope this helps.  spencer graves

yassir rabhi wrote:

>   Hi, 
> I'm student from canada, and i'work in survival
>analysis.I want to know if there is a hazard function
>or cumulative hazard function in R or not, i know how
>to program it, but it is easy to use it if they exists
>in R.
>Thanks.
>                                          Yassir
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From Tom.Mulholland at dpi.wa.gov.au  Tue Mar 22 02:30:00 2005
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Tue, 22 Mar 2005 09:30:00 +0800
Subject: [R] Using locator() to digitise
Message-ID: <33F91FB3FDF42E4180428AC66A5CF30B02D3BA9F@afhex01.dpi.wa.gov.au>

I've used rimage to read in graphics files (jpeg.) If I recall correctly, I think I had to install some libraries. What I can't recall is if it was any faster than pixmap, as I was mainly concerned with the file format and the forensic image processing possibilities.

Tom


> -----Original Message-----
> From: Ted.Harding at nessie.mcc.ac.uk 
> [mailto:Ted.Harding at nessie.mcc.ac.uk]
> Sent: Monday, 21 March 2005 12:09 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Using locator() to digitise
> 
> 
> Hi Folks,
> 
> I'm contemplating using locator() to digitise external
> graphics. To set context, I would be using X11 display
> on Linux.
> 
> To pre-empt the obvious comment: I've found on the R site
> the suggestion to use the 'pixmap' package. I've tried
> this, and it works; but it involves building a big R
> object (the internal pixmap representation), and this
> chokes my somewhat puny laptop (e.g. it can take about
> 1 minute to draw the graphic inside a plot area using
> addlogo(), with mucho swappo, and subsequently working
> knee-deep in treacle). The following idea would be a lot
> slicker.
> 
> For examples: I have something like
> 
> a) A scatterplot of data printed in a journal (but the
>    data values are not available;
> 
> b) A contour map (on paper) of a region.
> 
> So, I can scan the document, and obtain a file in some
> graphics format (jpeg, pbm or png, say).
> 
> Now: an idea which I find attractive is to be able to
> overlay an R plot with axes onto a display of the graphics
> file (produced as an X window by any suitable program such
> as 'xv' or 'display') so that (if the overlay were possible)
> clicking on the points of the graphic would in fact be
> clicking on the R plot and, via locator(), generate the
> R-plot coordinates of the mouse clicks which would correspond
> to the selected points on the graphic.
> 
> Provided the coordinate system of the R plot were properly
> related to the graphic, the results would be a digitisation
> of the selected points on the graphic.
> 
> What seems to be needed for this idea to work is that
> the R-plot should be displayed in an X11() device whose
> background was completely transparent, so that when
> moved over the (independently generated) display of the
> graphic the latter would be visible (but locator() would
> still be working on the R-plot itself). Window resizing
> could look after the correspondence between graphic coordinates
> and R-plot coordinates.
> 
> The R plot itself could be empty (apart from coordinate axes)
> or could contain "helper" elements such as grid lines, circles
> (e.g. I want to digitise graphics points within a certain circle),
> etc. "Helper" elements could be added to the R-plot by subsequent
> 'lines' or 'points' commands (e.g. I identify two points on
> the graphic, R-plot the line joining them, and then pick off
> graphic-points which lie on the R-line).
> 
> So this question is really about producing a "bare" R plot
> on, as it were, a virtual acrylic transparency. It's certainly
> possible to do such a thing in X: e.g. the cute "xteddy" is
> in fact a picture of a bear on a completely transparent
> rectangular background, though you'd never know by looking!
> 
> Any comments?
> 
> With thanks, and best wishes to all,
> Ted.
> 
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 20-Mar-05                                       Time: 16:09:11
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From cahn at email.unc.edu  Tue Mar 22 02:43:40 2005
From: cahn at email.unc.edu (Chaehyung Ahn)
Date: Mon, 21 Mar 2005 20:43:40 -0500 (EST)
Subject: [R] error with polr()
Message-ID: <Pine.LNX.4.44+UNC.0503212035510.7184-100000@bc01-n14.isis.unc.edu>

Dear Sir,

I get an error message when I use polr() in MASS package.

My data is "ord.dat".  I made "y" a factor.

   y y1 y2       x       lx
1  0  0  0 3.2e-02 -1.49485
2  0  0  0 3.2e-02 -1.49485
3  0  0  0 1.0e-01 -1.00000
4  0  0  0 1.0e-01 -1.00000
5  0  0  0 3.2e-01 -0.49485
6  0  0  0 3.2e-01 -0.49485
7  1  1  0 1.0e+00  0.00000
8  0  0  0 1.0e+00  0.00000
9  1  1  0 3.2e+00  0.50515
10 1  1  0 3.2e+00  0.50515
11 0  0  0 1.0e+01  1.00000
12 1  1  0 1.0e+01  1.00000
13 1  1  0 3.2e+01  1.50515
14 2  1  1 3.2e+01  1.50515
15 2  1  1 1.0e+02  2.00000
16 1  1  0 1.0e+02  2.00000
17 2  1  1 3.2e+02  2.50515
18 1  1  0 3.2e+02  2.50515
19 2  1  1 1.0e+03  3.00000
20 2  1  1 1.0e+03  3.00000

When I try,
> polr(y~lx,data=ord.dat)

I gives me a output, which is the same as that from SAS.

But when I try,
> summary(polr(y~lx,data=ord.dat))

Re-fitting to get Hessian

Error in optim(start, fmin, gmin, method = "BFGS", hessian = Hess, ...) :
        initial value in vmmin is not finite

And the weird thing is that it's fine if I use "x" instead of
"lx", where lx=log10(x).

thanks

Sincerely,

cahn



From michael_shen at hotmail.com  Tue Mar 22 03:58:43 2005
From: michael_shen at hotmail.com (Michael S)
Date: Tue, 22 Mar 2005 02:58:43 +0000
Subject: [R] problem in textConnection function
Message-ID: <BAY1-F23291AB6AE0BEBF9EF4794E74E0@phx.gbl>

Dear all-helpers:

I create one package ,code like this:
"output" <-
function(x,y)
{
	zz <-textConnection("foo","w")
	sink(zz)
	a <-5
	b <-6
	z <-a*b
	z
	e <-"spss"
	h <-c(1,2,3)
	ls()
	r<-c("s","p","s","s")
	p<-list(1:10)
	p
	sink()
                close(zz)
	x <- foo
                y <- foo
    # .C("output",as.character(x),as.character(y))
}

packege making is ok , but when I use "output" in Rgui,  none of object x 
ory can get the result what I expect(textConnection result),when I copy the 
code and paste on Rgui ,it is ok.what should I do ?

thanks in advance



From Tom.Mulholland at dpi.wa.gov.au  Tue Mar 22 04:18:14 2005
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Tue, 22 Mar 2005 11:18:14 +0800
Subject: [R] problem in textConnection function
Message-ID: <33F91FB3FDF42E4180428AC66A5CF30B02D3C9D2@afhex01.dpi.wa.gov.au>

It seems to me that you are trying to do too much at a time. Firstly I think it would be a good idea to get you code working before you try and make a package.

Some possibilities are that you write somethin meaningful rather than the first thing that pops into your head. What sort of output are you really expecting

When I used your code 


> -----Original Message-----
> From: Michael S [mailto:michael_shen at hotmail.com]
> Sent: Tuesday, 22 March 2005 10:59 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] problem in textConnection function
> 
> 
> Dear all-helpers:
> 
> I create one package ,code like this:
> "output" <-
> function(x,y)
> {
> 	zz <-textConnection("foo","w")
> 	sink(zz)
> 	a <-5
> 	b <-6
> 	z <-a*b
> 	z
> 	e <-"spss"
> 	h <-c(1,2,3)
> 	ls()
> 	r<-c("s","p","s","s")
> 	p<-list(1:10)
> 	p
> 	sink()
>                 close(zz)
> 	x <- foo
>                 y <- foo
>     # .C("output",as.character(x),as.character(y))
> }
> 
> packege making is ok , but when I use "output" in Rgui,  none 
> of object x 
> ory can get the result what I expect(textConnection 
> result),when I copy the 
> code and paste on Rgui ,it is ok.what should I do ?
> 
> thanks in advance
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html



From michael_shen at hotmail.com  Tue Mar 22 04:50:30 2005
From: michael_shen at hotmail.com (Michael S)
Date: Tue, 22 Mar 2005 03:50:30 +0000
Subject: [R] I modify my question in "textconnection output"
Message-ID: <BAY1-F15E295A6D3367075A8B221E74E0@phx.gbl>

dear ALL-R-helper:
I modify my question in "textconnection output":
I wrote one function in Rgui:
output <- function(y){
	x <- textConnection("foo","w")
	sink(x)
	a <-5
	b <-6
	z <-a*b
	z
	e <-"spss"
	h <-c(1,2,3)
	ls()
	r<-c("s","p","s","s")
	p<-list(1:10)
	p
	y <- foo
	sink()
     	close(x)
	return(y)
}

I want to get resulte is :
>y

[1] "[1] 30"
[2] " [1] \"a\"      \"b\"      \"c\"      \"d\"      \"e\"      \"f\"      
\"foo\"    \"g\"      \"g.p\"    \"h\"      \"interp\" \"m\"      
\"mytest\""
[3] "[14] \"output\" \"p\"      \"r\"      \"var1\"   \"var2\"   \"x\"      
\"y\"      \"z\"     "
[4] "[[1]]"
[5] " [1]  1  2  3  4  5  6  7  8  9 10"
[6] ""

when I copy the command line within the function ,and paste to RGui,result 
is ok .but when I use the output function ,">y" show value of y object.I got 
result "character(0)"

seem to me : I didn't get  value of y within function

thanks



From ggrothendieck at myway.com  Tue Mar 22 04:49:46 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 22 Mar 2005 03:49:46 +0000 (UTC)
Subject: [R] problem in textConnection function
References: <BAY1-F23291AB6AE0BEBF9EF4794E74E0@phx.gbl>
Message-ID: <loom.20050322T044846-465@post.gmane.org>

Michael S <michael_shen <at> hotmail.com> writes:

: 
: Dear all-helpers:
: 
: I create one package ,code like this:
: "output" <-
: function(x,y)
: {
: 	zz <-textConnection("foo","w")
: 	sink(zz)
: 	a <-5
: 	b <-6
: 	z <-a*b
: 	z
: 	e <-"spss"
: 	h <-c(1,2,3)
: 	ls()
: 	r<-c("s","p","s","s")
: 	p<-list(1:10)
: 	p
: 	sink()
:                 close(zz)
: 	x <- foo
:                 y <- foo
:     # .C("output",as.character(x),as.character(y))
: }
: 
: packege making is ok , but when I use "output" in Rgui,  none of object x 
: ory can get the result what I expect(textConnection result),when I copy the 
: code and paste on Rgui ,it is ok.what should I do ?
: 

This is a FAQ:

http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-is-the-output-not-printed-
when-I-source_0028_0029-a-file_003f



From ggrothendieck at myway.com  Tue Mar 22 04:57:28 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 22 Mar 2005 03:57:28 +0000 (UTC)
Subject: [R] I modify my question in "textconnection output"
References: <BAY1-F15E295A6D3367075A8B221E74E0@phx.gbl>
Message-ID: <loom.20050322T045328-810@post.gmane.org>

Michael S <michael_shen <at> hotmail.com> writes:

: 
: dear ALL-R-helper:
: I modify my question in "textconnection output":
: I wrote one function in Rgui:
: output <- function(y){
: 	x <- textConnection("foo","w")
: 	sink(x)
: 	a <-5
: 	b <-6
: 	z <-a*b
: 	z
: 	e <-"spss"
: 	h <-c(1,2,3)
: 	ls()
: 	r<-c("s","p","s","s")
: 	p<-list(1:10)
: 	p
: 	y <- foo
: 	sink()
:      	close(x)
: 	return(y)
: }
: 
: I want to get resulte is :
: >y
: 
: [1] "[1] 30"
: [2] " [1] \"a\"      \"b\"      \"c\"      \"d\"      \"e\"      \"f\"      
: \"foo\"    \"g\"      \"g.p\"    \"h\"      \"interp\" \"m\"      
: \"mytest\""
: [3] "[14] \"output\" \"p\"      \"r\"      \"var1\"   \"var2\"   \"x\"      
: \"y\"      \"z\"     "
: [4] "[[1]]"
: [5] " [1]  1  2  3  4  5  6  7  8  9 10"
: [6] ""
: 
: when I copy the command line within the function ,and paste to RGui,result 
: is ok .but when I use the output function ,">y" show value of y object.I got 
: result "character(0)"
: 
: seem to me : I didn't get  value of y within function

You have not defined foo within your function.  If you have
a foo outside your function then that is being assigned to
y.  If you haven't a foo anywhere then you should have received 
an error.

You might want to look at ?capture.output  

y <- capture.output({
  x <- 1
  print(x)
})



From Tom.Mulholland at dpi.wa.gov.au  Tue Mar 22 06:34:34 2005
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Tue, 22 Mar 2005 13:34:34 +0800
Subject: [R] List of tables rather than an extra dimension in the table or
	(l)apply(xtabs)
Message-ID: <33F91FB3FDF42E4180428AC66A5CF30B02D3BAA3@afhex01.dpi.wa.gov.au>

I'm not sure how to best explain what I am after but here goes. I have a data frame with 2 geographical factors. One is the major region the other is the component regions.

I am trying to process all the regions at the same time without using "for". So I need (think, I do)  a list of matrices each structured according to the number of subregions within each region.

So is there a way of using lapply with xtabs or is there a better way to achieve my desired output?

Using the Titanic data as an example

t1 <- as.data.frame(Titanic)
t2 <- split(t1,t1$Class)

# I would then drop any unused levels in the factors for the geography creating distinctly different data.frames (see end of message)

> xtabs(Freq ~ Age + Sex + Class,t1)
, , Class = 1st

       Sex
Age     Male Female
  Child   5    1   
  Adult 175  144   

, , Class = 2nd

       Sex
Age     Male Female
  Child  11   13   
  Adult 168   93   

, , Class = 3rd

       Sex
Age     Male Female
  Child  48   31   
  Adult 462  165   

, , Class = Crew

       Sex
Age     Male Female
  Child   0    0   
  Adult 862   23   

Can I do something with t2 to produce a list which is in effect an Age by Sex crosstab with one item for each value of Class. I would be wanting to drop.unused.levels, so that the last part of the table is just 

       Sex
Age     Male Female
  Adult 862   23   

or in my case each item in the list has the same number of rows as there are subregions for that region.

List of 9
 $ 1:`data.frame':      4009 obs. of  7 variables:
  ..$ sex      : Factor w/ 2 levels "Females","Males": 2 2 2 2 2 2 2 2 2 2 ...
  ..$ age      : Factor w/ 18 levels "0-4","5-9","10-14",..: 1 1 1 1 1 1 1 1 1 1 ...
  ..$ lga      : Factor w/ 23 levels "Carnamah (S)",..: 1 2 3 4 5 6 7 8 9 10 ...   # 23 subregions
  ..$ psn      : num [1:4009] 71 336 26 84 30 133 904 385 99 110 ...
  ..$ year     : num [1:4009] 1991 1991 1991 1991 1991 ...
  ..$ agecomp  : Factor w/ 14 levels "0-4","5-9","10-14",..: 1 1 1 1 1 1 1 1 1 1 ...
  ..$ RegionNum: num [1:4009] 1 1 1 1 1 1 1 1 1 1 ...
 $ 2:`data.frame':      720 obs. of  7 variables:
  ..$ sex      : Factor w/ 2 levels "Females","Males": 2 2 2 2 2 2 2 2 2 2 ...
  ..$ age      : Factor w/ 18 levels "0-4","5-9","10-14",..: 1 1 1 1 2 2 2 2 3 3 ...
  ..$ lga      : Factor w/ 4 levels "Broome (S)","De..",..: 1 2 3 4 1 2 3 4 1 2 ... # 4 subregions etc
  ..$ psn      : num [1:720] 495 445 189 377 415 374 189 330 324 319 ...
  ..$ year     : num [1:720] 1991 1991 1991 1991 1991 ...
  ..$ agecomp  : Factor w/ 14 levels "0-4","5-9","10-14",..: 1 1 1 1 2 2 2 2 3 3 ...
  ..$ RegionNum: num [1:720] 2 2 2 2 2 2 2 2 2 2 ...

So these two items would produce

> round(xtabs(psn ~ lga + agecomp,eas[[1]]),-2)
                    agecomp
lga                  0-4   5-9   10-14 15-19 20-24 25-29 30-34 35-39 40-44 45-49 50-54 55-59 60-64 65plus
  Carnamah (S)         500   400   300   200   300   300   500   400   400   300   300   200   100   300 
  Carnarvon (S)       2800  3000  2600  2100  2400  2700  2800  2600  2400  2200  2000  1600  1300  2800 
  Chapman Valley (S)   300   400   300   200   200   300   300   300   300   400   400   300   200   300 
  Coorow (S)           700   700   600   200   300   600   700   600   500   500   400   400   300   500 
  Cue (S)              200   200   100   100   200   200   300   200   200   200   200   100   100   100 
  Exmouth (S)          900  1000   800   600   700  1100  1100  1100  1100   800   700   500   400   700 
  Geraldton (C)       7700  7700  8100  8200  7200  7400  7500  7200  6900  6100  5400  4600  4300 12400 
  Greenough (S)       4700  5400  5500  4400  3100  3700  4800  5100  5200  4200  3500  2600  1900  3200 
  Irwin (S)           1000  1100  1000   600   600   900  1000  1200  1000   900   800   900   800  1800 
  Meekatharra (S)      800   700   600   600   900  1000   900   700   600   500   400   300   200   400 
  Mingenew (S)         300   300   200   100   200   200   300   300   200   200   200   200   100   200 
  Morawa (S)           400   500   400   400   200   400   500   400   300   300   300   300   200   500 
  Mount Magnet (S)     500   400   300   200   400   500   400   400   300   300   200   200   100   200 
  Mullewa (S)          600   600   800   400   400   500   500   400   300   300   300   300   200   400 
  Murchison (S)        100   100   100   100     0   100   100     0     0     0   100     0     0     0 
  Northampton (S)     1300  1300  1200   700   700   900  1200  1300  1200  1200  1000  1000   900  2000 
  Perenjori (S)        300   300   300   100   200   200   300   300   300   200   200   200   100   300 
  Sandstone (S)          0     0     0     0   100   100   100   100   100   100   100   100     0   100 
  Shark Bay (S)        300   300   200   200   200   300   400   400   400   300   300   300   200   600 
  Three Springs (S)    300   300   300   100   200   300   400   300   300   200   300   200   200   400 
  Upper Gascoyne (S)   100   200   200   100   100   100   100   100   100   100   100   100   100   100 
  Wiluna (S)           200   200   200   300   600   700   600   400   300   300   300   200   100   100 
  Yalgoo (S)           100   100   100     0   200   200   200   100   200   200   100   100   100   100 
> round(xtabs(psn ~ lga + agecomp,eas[[2]]),-2)
                            agecomp
lga                          0-4  5-9  10-14 15-19 20-24 25-29 30-34 35-39 40-44 45-49 50-54 55-59 60-64 65plus
  Broome (S)                 5600 5400 4500  3900  4900  5800  6100  5500  4500  3700  2800  2000  1500  2200  
  Derby-West Kimberley (S)   4000 3900 3400  3100  3800  4000  3800  3100  2500  1900  1500  1200   900  1800  
  Halls Creek (S)            2100 2100 1700  1600  1800  1600  1400  1100  1000   900   700   600   400   800  
  Wyndham-East Kimberley (S) 3500 3300 2800  2300  2900  3500  3500  3000  2600  2100  1800  1300   800  1200  

 $ 3:`data.frame':      2130 obs. of  7 variables:
  ..$ sex      : Factor w/ 2 levels "Females","Males": 2 2 2 2 2 2 2 2 2 2 ...
  ..$ age      : Factor w/ 18 levels "0-4","5-9","10-14",..: 1 1 1 1 1 1 1 1 1 1 ...
  ..$ lga      : Factor w/ 12 levels "Albany (C)","Br..",..: 1 2 3 4 5 6 7 8 9 10 ...
  ..$ psn      : num [1:2130] 1107   21   63  167  115 ...
  ..$ year     : num [1:2130] 1991 1991 1991 1991 1991 ...
  ..$ agecomp  : Factor w/ 14 levels "0-4","5-9","10-14",..: 1 1 1 1 1 1 1 1 1 1 ...
  ..$ RegionNum: num [1:2130] 3 3 3 3 3 3 3 3 3 3 ...
 $ 4:`data.frame':      5188 obs. of  7 variables:
  ..$ sex      : Factor w/ 2 levels "Females","Males": 2 2 2 2 2 2 2 2 2 2 ...
  ..$ age      : Factor w/ 18 levels "0-4","5-9","10-14",..: 1 1 1 1 1 1 1 1 1 1 ...
  ..$ lga      : Factor w/ 29 levels "Beverley (S)",..: 1 2 3 4 5 6 7 8 9 10 ...
  ..$ psn      : num [1:5188] 55 58 84 90 105 134 57 132 56 70 ...
  ..$ year     : num [1:5188] 1991 1991 1991 1991 1991 ...
  ..$ agecomp  : Factor w/ 14 levels "0-4","5-9","10-14",..: 1 1 1 1 1 1 1 1 1 1 ...
  ..$ RegionNum: num [1:5188] 4 4 4 4 4 4 4 4 4 4 ...
 $ 5:`data.frame':      5400 obs. of  7 variables:
  ..$ sex      : Factor w/ 2 levels "Females","Males": 2 2 2 2 2 2 2 2 2 2 ...
  ..$ age      : Factor w/ 18 levels "0-4","5-9","10-14",..: 1 1 1 1 1 1 1 1 1 1 ...
  ..$ lga      : Factor w/ 30 levels "Armadale (C)",..: 1 2 3 4 5 6 7 8 9 10 ...
  ..$ psn      : num [1:5400] 2163  479 1824  865  749 ...
  ..$ year     : num [1:5400] 1991 1991 1991 1991 1991 ...
  ..$ agecomp  : Factor w/ 14 levels "0-4","5-9","10-14",..: 1 1 1 1 1 1 1 1 1 1 ...
  ..$ RegionNum: num [1:5400] 5 5 5 5 5 5 5 5 5 5 ...
 $ 6:`data.frame':      720 obs. of  7 variables:
  ..$ sex      : Factor w/ 2 levels "Females","Males": 2 2 2 2 2 2 2 2 2 2 ...
  ..$ age      : Factor w/ 18 levels "0-4","5-9","10-14",..: 1 1 1 1 2 2 2 2 3 3 ...
  ..$ lga      : Factor w/ 4 levels "Ashburton (S)",..: 1 2 3 4 1 2 3 4 1 2 ...
  ..$ psn      : num [1:720] 532 624 699 930 433 539 689 846 320 379 ...
  ..$ year     : num [1:720] 1991 1991 1991 1991 1991 ...
  ..$ agecomp  : Factor w/ 14 levels "0-4","5-9","10-14",..: 1 1 1 1 2 2 2 2 3 3 ...
  ..$ RegionNum: num [1:720] 6 6 6 6 6 6 6 6 6 6 ...
 $ 7:`data.frame':      1601 obs. of  7 variables:
  ..$ sex      : Factor w/ 2 levels "Females","Males": 2 2 2 2 2 2 2 2 2 2 ...
  ..$ age      : Factor w/ 18 levels "0-4","5-9","10-14",..: 1 1 1 1 1 1 1 1 1 2 ...
  ..$ lga      : Factor w/ 9 levels "Coolgardie ..",..: 1 2 3 4 5 6 7 8 9 1 ...
  ..$ psn      : num [1:1601]  342  105  534 1352   85 ...
  ..$ year     : num [1:1601] 1991 1991 1991 1991 1991 ...
  ..$ agecomp  : Factor w/ 14 levels "0-4","5-9","10-14",..: 1 1 1 1 1 1 1 1 1 2 ...
  ..$ RegionNum: num [1:1601] 7 7 7 7 7 7 7 7 7 7 ...
 $ 8:`data.frame':      2880 obs. of  7 variables:
  ..$ sex      : Factor w/ 2 levels "Females","Males": 2 2 2 2 2 2 2 2 2 2 ...
  ..$ age      : Factor w/ 18 levels "0-4","5-9","10-14",..: 1 1 1 1 1 1 1 1 1 1 ...
  ..$ lga      : Factor w/ 16 levels "Augusta-Mar..",..: 1 2 3 4 5 6 7 8 9 10 ...
  ..$ psn      : num [1:2880]  294   66   85  188 1144 ...
  ..$ year     : num [1:2880] 1991 1991 1991 1991 1991 ...
  ..$ agecomp  : Factor w/ 14 levels "0-4","5-9","10-14",..: 1 1 1 1 1 1 1 1 1 1 ...
  ..$ RegionNum: num [1:2880] 8 8 8 8 8 8 8 8 8 8 ...
 $ 9:`data.frame':      2694 obs. of  7 variables:
  ..$ sex      : Factor w/ 2 levels "Females","Males": 2 2 2 2 2 2 2 2 2 2 ...
  ..$ age      : Factor w/ 18 levels "0-4","5-9","10-14",..: 1 1 1 1 1 1 1 1 1 1 ...
  ..$ lga      : Factor w/ 15 levels "Brookton (S)",..: 1 2 3 4 5 6 7 9 8 10 ...
  ..$ psn      : num [1:2694] 49 67 38 46 67 51 104 214 44 69 ...
  ..$ year     : num [1:2694] 1991 1991 1991 1991 1991 ...
  ..$ agecomp  : Factor w/ 14 levels "0-4","5-9","10-14",..: 1 1 1 1 1 1 1 1 1 1 ...
  ..$ RegionNum: num [1:2694] 9 9 9 9 9 9 9 9 9 9 ...

platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    0.1            
year     2004           
month    11             
day      15             
language R

Tom Mulholland
Senior Demographer
Spatial Information and Research
State and Regional Policy
Department for Planning and Infrastructure
Perth, Western Australia
+61 (08) 9264 7936



From Gerrit.Eichner at math.uni-giessen.de  Tue Mar 22 06:59:08 2005
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Tue, 22 Mar 2005 06:59:08 +0100 (MET)
Subject: [R] lattice xyplot() postscript (?) problem in R 2.0.0
Message-ID: <Pine.GSO.4.61.0503220644420.3780@c1.hrz.uni-giessen.de>

Dear all,

I work with R Version 2.0.0 on
Machine hardware:   sun4u
OS version:         5.9
Processor type:     sparc
Hardware:           SUNW,Sun-Blade-1000

and I have a very simple data frame (called OR) with the following 
variables:
> sapply( OR, class)
         X        ci      FTyp
  "factor" "numeric"  "factor"

(In OR$ci there are some Inf-values. OR's complete contents are appended 
below.)

If I do

> library( lattice)
> xyplot( X ~ ci | FTyp, data= OR)

the requested trellis plot appears and everything is fine. BUT, if I want 
to produce this plot in a postscript file a very strange and reproducible 
error ocurs:

> postscript( "OR.ps")
> xyplot( X ~ ci | FTyp, data= OR)
Error in "[<-"(`*tmp*`, pos.heights[[nm]], value = numeric(0)) :
         nothing to replace with

This procedure -- applied to this very data frame -- did work fine 
previously, i.e., when I used R 1.9.1. (traceback() didn't help me 
tracking the problem further down.)
I have the impression that it fails since I've started using R 2.0.0. 
Could this be a version related problem? Any ideas?

Thanks for any help!

  Best regards  --  Gerrit

PS: Here are the contents of data frame OR:

> OR
    X     ci FTyp
1  a 0.0000    A
2  a 0.0000    A
3  a    Inf    A
4  a 1.1158    B
5  a 0.2578    B
6  a    Inf    B
7  b 0.6568    A
8  b 0.0159    A
9  b    Inf    A
10 b 0.1051    B
11 b 0.0164    B
12 b    Inf    B
13 c    Inf    A
14 c 0.2217    A
15 c    Inf    A
16 c 9.2356    B
17 c 1.7123    B
18 c    Inf    B
19 d 0.4140    A
20 d 0.0099    A
21 d    Inf    A
22 d 1.7827    B
23 d 0.3606    B
24 d    Inf    B

-----------------------------------------------------------------------
AR Dr. Gerrit Eichner                            Mathematical Institute
gerrit.eichner at math.uni-giessen.de     Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104            Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32029      http://www.math.uni-giessen.de/Stochastik



From Tom.Mulholland at dpi.wa.gov.au  Tue Mar 22 07:18:25 2005
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Tue, 22 Mar 2005 14:18:25 +0800
Subject: [R] List of tables rather than an extra dimension in the table or
	(l)apply(xtabs)
Message-ID: <33F91FB3FDF42E4180428AC66A5CF30B02D3C9D6@afhex01.dpi.wa.gov.au>

I wrote a function that created the crosstab  and removed the extraneous lines and then used lapply


aestabs <- function(x){
   temp <- xtabs(psn ~ lga + year,x)
   temp <- temp[rowSums(temp) != 0,]
   return(temp)
   }
   
eas2 <- lapply(split(ipi$eas,ipi$eas$RegionNum),aestabs)

It's not really reuseable. I guess I could pass a formula and work out a better method of subsetting dimensions (where certain factor levels are not used. But maybe someone has an elegant method they could share.

Tom

> -----Original Message-----
> From: Mulholland, Tom 
> Sent: Tuesday, 22 March 2005 1:35 PM
> To: R-Help (E-mail)
> Subject: [R] List of tables rather than an extra dimension in 
> the table
> or (l)apply(xtabs)
> 
> 
> I'm not sure how to best explain what I am after but here 
> goes. I have a data frame with 2 geographical factors. One is 
> the major region the other is the component regions.
> 
> I am trying to process all the regions at the same time 
> without using "for". So I need (think, I do)  a list of 
> matrices each structured according to the number of 
> subregions within each region.
> 
> So is there a way of using lapply with xtabs or is there a 
> better way to achieve my desired output?
> 
> Using the Titanic data as an example
> 
> t1 <- as.data.frame(Titanic)
> t2 <- split(t1,t1$Class)
> 
> # I would then drop any unused levels in the factors for the 
> geography creating distinctly different data.frames (see end 
> of message)
> 
> > xtabs(Freq ~ Age + Sex + Class,t1)
> , , Class = 1st
> 
>        Sex
> Age     Male Female
>   Child   5    1   
>   Adult 175  144   
> 
> , , Class = 2nd
> 
>        Sex
> Age     Male Female
>   Child  11   13   
>   Adult 168   93   
> 
> , , Class = 3rd
> 
>        Sex
> Age     Male Female
>   Child  48   31   
>   Adult 462  165   
> 
> , , Class = Crew
> 
>        Sex
> Age     Male Female
>   Child   0    0   
>   Adult 862   23   
> 
> Can I do something with t2 to produce a list which is in 
> effect an Age by Sex crosstab with one item for each value of 
> Class. I would be wanting to drop.unused.levels, so that the 
> last part of the table is just 
> 
>        Sex
> Age     Male Female
>   Adult 862   23   
> 
> or in my case each item in the list has the same number of 
> rows as there are subregions for that region.
> 
> List of 9
>  $ 1:`data.frame':      4009 obs. of  7 variables:
>   ..$ sex      : Factor w/ 2 levels "Females","Males": 2 2 2 
> 2 2 2 2 2 2 2 ...
>   ..$ age      : Factor w/ 18 levels "0-4","5-9","10-14",..: 
> 1 1 1 1 1 1 1 1 1 1 ...
>   ..$ lga      : Factor w/ 23 levels "Carnamah (S)",..: 1 2 3 
> 4 5 6 7 8 9 10 ...   # 23 subregions
>   ..$ psn      : num [1:4009] 71 336 26 84 30 133 904 385 99 110 ...
>   ..$ year     : num [1:4009] 1991 1991 1991 1991 1991 ...
>   ..$ agecomp  : Factor w/ 14 levels "0-4","5-9","10-14",..: 
> 1 1 1 1 1 1 1 1 1 1 ...
>   ..$ RegionNum: num [1:4009] 1 1 1 1 1 1 1 1 1 1 ...
>  $ 2:`data.frame':      720 obs. of  7 variables:
>   ..$ sex      : Factor w/ 2 levels "Females","Males": 2 2 2 
> 2 2 2 2 2 2 2 ...
>   ..$ age      : Factor w/ 18 levels "0-4","5-9","10-14",..: 
> 1 1 1 1 2 2 2 2 3 3 ...
>   ..$ lga      : Factor w/ 4 levels "Broome (S)","De..",..: 1 
> 2 3 4 1 2 3 4 1 2 ... # 4 subregions etc
>   ..$ psn      : num [1:720] 495 445 189 377 415 374 189 330 
> 324 319 ...
>   ..$ year     : num [1:720] 1991 1991 1991 1991 1991 ...
>   ..$ agecomp  : Factor w/ 14 levels "0-4","5-9","10-14",..: 
> 1 1 1 1 2 2 2 2 3 3 ...
>   ..$ RegionNum: num [1:720] 2 2 2 2 2 2 2 2 2 2 ...
> 
> So these two items would produce
> 
> > round(xtabs(psn ~ lga + agecomp,eas[[1]]),-2)
>                     agecomp
> lga                  0-4   5-9   10-14 15-19 20-24 25-29 
> 30-34 35-39 40-44 45-49 50-54 55-59 60-64 65plus
>   Carnamah (S)         500   400   300   200   300   300   
> 500   400   400   300   300   200   100   300 
>   Carnarvon (S)       2800  3000  2600  2100  2400  2700  
> 2800  2600  2400  2200  2000  1600  1300  2800 
>   Chapman Valley (S)   300   400   300   200   200   300   
> 300   300   300   400   400   300   200   300 
>   Coorow (S)           700   700   600   200   300   600   
> 700   600   500   500   400   400   300   500 
>   Cue (S)              200   200   100   100   200   200   
> 300   200   200   200   200   100   100   100 
>   Exmouth (S)          900  1000   800   600   700  1100  
> 1100  1100  1100   800   700   500   400   700 
>   Geraldton (C)       7700  7700  8100  8200  7200  7400  
> 7500  7200  6900  6100  5400  4600  4300 12400 
>   Greenough (S)       4700  5400  5500  4400  3100  3700  
> 4800  5100  5200  4200  3500  2600  1900  3200 
>   Irwin (S)           1000  1100  1000   600   600   900  
> 1000  1200  1000   900   800   900   800  1800 
>   Meekatharra (S)      800   700   600   600   900  1000   
> 900   700   600   500   400   300   200   400 
>   Mingenew (S)         300   300   200   100   200   200   
> 300   300   200   200   200   200   100   200 
>   Morawa (S)           400   500   400   400   200   400   
> 500   400   300   300   300   300   200   500 
>   Mount Magnet (S)     500   400   300   200   400   500   
> 400   400   300   300   200   200   100   200 
>   Mullewa (S)          600   600   800   400   400   500   
> 500   400   300   300   300   300   200   400 
>   Murchison (S)        100   100   100   100     0   100   
> 100     0     0     0   100     0     0     0 
>   Northampton (S)     1300  1300  1200   700   700   900  
> 1200  1300  1200  1200  1000  1000   900  2000 
>   Perenjori (S)        300   300   300   100   200   200   
> 300   300   300   200   200   200   100   300 
>   Sandstone (S)          0     0     0     0   100   100   
> 100   100   100   100   100   100     0   100 
>   Shark Bay (S)        300   300   200   200   200   300   
> 400   400   400   300   300   300   200   600 
>   Three Springs (S)    300   300   300   100   200   300   
> 400   300   300   200   300   200   200   400 
>   Upper Gascoyne (S)   100   200   200   100   100   100   
> 100   100   100   100   100   100   100   100 
>   Wiluna (S)           200   200   200   300   600   700   
> 600   400   300   300   300   200   100   100 
>   Yalgoo (S)           100   100   100     0   200   200   
> 200   100   200   200   100   100   100   100 
> > round(xtabs(psn ~ lga + agecomp,eas[[2]]),-2)
>                             agecomp
> lga                          0-4  5-9  10-14 15-19 20-24 
> 25-29 30-34 35-39 40-44 45-49 50-54 55-59 60-64 65plus
>   Broome (S)                 5600 5400 4500  3900  4900  5800 
>  6100  5500  4500  3700  2800  2000  1500  2200  
>   Derby-West Kimberley (S)   4000 3900 3400  3100  3800  4000 
>  3800  3100  2500  1900  1500  1200   900  1800  
>   Halls Creek (S)            2100 2100 1700  1600  1800  1600 
>  1400  1100  1000   900   700   600   400   800  
>   Wyndham-East Kimberley (S) 3500 3300 2800  2300  2900  3500 
>  3500  3000  2600  2100  1800  1300   800  1200  
> 
>  $ 3:`data.frame':      2130 obs. of  7 variables:
>   ..$ sex      : Factor w/ 2 levels "Females","Males": 2 2 2 
> 2 2 2 2 2 2 2 ...
>   ..$ age      : Factor w/ 18 levels "0-4","5-9","10-14",..: 
> 1 1 1 1 1 1 1 1 1 1 ...
>   ..$ lga      : Factor w/ 12 levels "Albany (C)","Br..",..: 
> 1 2 3 4 5 6 7 8 9 10 ...
>   ..$ psn      : num [1:2130] 1107   21   63  167  115 ...
>   ..$ year     : num [1:2130] 1991 1991 1991 1991 1991 ...
>   ..$ agecomp  : Factor w/ 14 levels "0-4","5-9","10-14",..: 
> 1 1 1 1 1 1 1 1 1 1 ...
>   ..$ RegionNum: num [1:2130] 3 3 3 3 3 3 3 3 3 3 ...
>  $ 4:`data.frame':      5188 obs. of  7 variables:
>   ..$ sex      : Factor w/ 2 levels "Females","Males": 2 2 2 
> 2 2 2 2 2 2 2 ...
>   ..$ age      : Factor w/ 18 levels "0-4","5-9","10-14",..: 
> 1 1 1 1 1 1 1 1 1 1 ...
>   ..$ lga      : Factor w/ 29 levels "Beverley (S)",..: 1 2 3 
> 4 5 6 7 8 9 10 ...
>   ..$ psn      : num [1:5188] 55 58 84 90 105 134 57 132 56 70 ...
>   ..$ year     : num [1:5188] 1991 1991 1991 1991 1991 ...
>   ..$ agecomp  : Factor w/ 14 levels "0-4","5-9","10-14",..: 
> 1 1 1 1 1 1 1 1 1 1 ...
>   ..$ RegionNum: num [1:5188] 4 4 4 4 4 4 4 4 4 4 ...
>  $ 5:`data.frame':      5400 obs. of  7 variables:
>   ..$ sex      : Factor w/ 2 levels "Females","Males": 2 2 2 
> 2 2 2 2 2 2 2 ...
>   ..$ age      : Factor w/ 18 levels "0-4","5-9","10-14",..: 
> 1 1 1 1 1 1 1 1 1 1 ...
>   ..$ lga      : Factor w/ 30 levels "Armadale (C)",..: 1 2 3 
> 4 5 6 7 8 9 10 ...
>   ..$ psn      : num [1:5400] 2163  479 1824  865  749 ...
>   ..$ year     : num [1:5400] 1991 1991 1991 1991 1991 ...
>   ..$ agecomp  : Factor w/ 14 levels "0-4","5-9","10-14",..: 
> 1 1 1 1 1 1 1 1 1 1 ...
>   ..$ RegionNum: num [1:5400] 5 5 5 5 5 5 5 5 5 5 ...
>  $ 6:`data.frame':      720 obs. of  7 variables:
>   ..$ sex      : Factor w/ 2 levels "Females","Males": 2 2 2 
> 2 2 2 2 2 2 2 ...
>   ..$ age      : Factor w/ 18 levels "0-4","5-9","10-14",..: 
> 1 1 1 1 2 2 2 2 3 3 ...
>   ..$ lga      : Factor w/ 4 levels "Ashburton (S)",..: 1 2 3 
> 4 1 2 3 4 1 2 ...
>   ..$ psn      : num [1:720] 532 624 699 930 433 539 689 846 
> 320 379 ...
>   ..$ year     : num [1:720] 1991 1991 1991 1991 1991 ...
>   ..$ agecomp  : Factor w/ 14 levels "0-4","5-9","10-14",..: 
> 1 1 1 1 2 2 2 2 3 3 ...
>   ..$ RegionNum: num [1:720] 6 6 6 6 6 6 6 6 6 6 ...
>  $ 7:`data.frame':      1601 obs. of  7 variables:
>   ..$ sex      : Factor w/ 2 levels "Females","Males": 2 2 2 
> 2 2 2 2 2 2 2 ...
>   ..$ age      : Factor w/ 18 levels "0-4","5-9","10-14",..: 
> 1 1 1 1 1 1 1 1 1 2 ...
>   ..$ lga      : Factor w/ 9 levels "Coolgardie ..",..: 1 2 3 
> 4 5 6 7 8 9 1 ...
>   ..$ psn      : num [1:1601]  342  105  534 1352   85 ...
>   ..$ year     : num [1:1601] 1991 1991 1991 1991 1991 ...
>   ..$ agecomp  : Factor w/ 14 levels "0-4","5-9","10-14",..: 
> 1 1 1 1 1 1 1 1 1 2 ...
>   ..$ RegionNum: num [1:1601] 7 7 7 7 7 7 7 7 7 7 ...
>  $ 8:`data.frame':      2880 obs. of  7 variables:
>   ..$ sex      : Factor w/ 2 levels "Females","Males": 2 2 2 
> 2 2 2 2 2 2 2 ...
>   ..$ age      : Factor w/ 18 levels "0-4","5-9","10-14",..: 
> 1 1 1 1 1 1 1 1 1 1 ...
>   ..$ lga      : Factor w/ 16 levels "Augusta-Mar..",..: 1 2 
> 3 4 5 6 7 8 9 10 ...
>   ..$ psn      : num [1:2880]  294   66   85  188 1144 ...
>   ..$ year     : num [1:2880] 1991 1991 1991 1991 1991 ...
>   ..$ agecomp  : Factor w/ 14 levels "0-4","5-9","10-14",..: 
> 1 1 1 1 1 1 1 1 1 1 ...
>   ..$ RegionNum: num [1:2880] 8 8 8 8 8 8 8 8 8 8 ...
>  $ 9:`data.frame':      2694 obs. of  7 variables:
>   ..$ sex      : Factor w/ 2 levels "Females","Males": 2 2 2 
> 2 2 2 2 2 2 2 ...
>   ..$ age      : Factor w/ 18 levels "0-4","5-9","10-14",..: 
> 1 1 1 1 1 1 1 1 1 1 ...
>   ..$ lga      : Factor w/ 15 levels "Brookton (S)",..: 1 2 3 
> 4 5 6 7 9 8 10 ...
>   ..$ psn      : num [1:2694] 49 67 38 46 67 51 104 214 44 69 ...
>   ..$ year     : num [1:2694] 1991 1991 1991 1991 1991 ...
>   ..$ agecomp  : Factor w/ 14 levels "0-4","5-9","10-14",..: 
> 1 1 1 1 1 1 1 1 1 1 ...
>   ..$ RegionNum: num [1:2694] 9 9 9 9 9 9 9 9 9 9 ...
> 
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    2              
> minor    0.1            
> year     2004           
> month    11             
> day      15             
> language R
> 
> Tom Mulholland
> Senior Demographer
> Spatial Information and Research
> State and Regional Policy
> Department for Planning and Infrastructure
> Perth, Western Australia
> +61 (08) 9264 7936
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From Bill.Venables at csiro.au  Tue Mar 22 07:24:42 2005
From: Bill.Venables at csiro.au (Bill.Venables@csiro.au)
Date: Tue, 22 Mar 2005 17:24:42 +1100
Subject: [R] error with polr()
Message-ID: <B998A44C8986644EA8029CFE6396A9241B2ED0@exqld2-bne.qld.csiro.au>

This is always tricky.  Here is a work-around.  

Try asking for the Hessian with the original fit:

> fm <- polr(factor(y) ~ lx, data = ord.dat, Hess=T)
> summary(fm)
Call:
polr(formula = factor(y) ~ lx, data = ord.dat, Hess = T)

Coefficients:
      Value Std. Error  t value
lx 2.420614  0.8146359 2.971406

Intercepts:
    Value  Std. Error t value
0|1 0.5865 0.8118     0.7224 
1|2 4.8966 1.7422     2.8106 

Residual Deviance: 20.43286 
AIC: 26.43286 

---

[I have no idea if this is "the same as SAS" but if not, please report
the problem to SAS Inc.]

Bill Venables.


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Chaehyung Ahn
Sent: Tuesday, 22 March 2005 11:44 AM
To: r-help at stat.math.ethz.ch
Subject: [R] error with polr()


Dear Sir,

I get an error message when I use polr() in MASS package.

My data is "ord.dat".  I made "y" a factor.

   y y1 y2       x       lx
1  0  0  0 3.2e-02 -1.49485
2  0  0  0 3.2e-02 -1.49485
3  0  0  0 1.0e-01 -1.00000
4  0  0  0 1.0e-01 -1.00000
5  0  0  0 3.2e-01 -0.49485
6  0  0  0 3.2e-01 -0.49485
7  1  1  0 1.0e+00  0.00000
8  0  0  0 1.0e+00  0.00000
9  1  1  0 3.2e+00  0.50515
10 1  1  0 3.2e+00  0.50515
11 0  0  0 1.0e+01  1.00000
12 1  1  0 1.0e+01  1.00000
13 1  1  0 3.2e+01  1.50515
14 2  1  1 3.2e+01  1.50515
15 2  1  1 1.0e+02  2.00000
16 1  1  0 1.0e+02  2.00000
17 2  1  1 3.2e+02  2.50515
18 1  1  0 3.2e+02  2.50515
19 2  1  1 1.0e+03  3.00000
20 2  1  1 1.0e+03  3.00000

When I try,
> polr(y~lx,data=ord.dat)

I gives me a output, which is the same as that from SAS.

But when I try,
> summary(polr(y~lx,data=ord.dat))

Re-fitting to get Hessian

Error in optim(start, fmin, gmin, method = "BFGS", hessian = Hess, ...)
:
        initial value in vmmin is not finite

And the weird thing is that it's fine if I use "x" instead of
"lx", where lx=log10(x).

thanks

Sincerely,

cahn

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Tue Mar 22 08:19:35 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 22 Mar 2005 08:19:35 +0100
Subject: [R] Highlighting points in a scatter plot matrix
In-Reply-To: <3542A1BF5AE1984D9FF577DA2CF8BA9868B147@MSX2>
References: <3542A1BF5AE1984D9FF577DA2CF8BA9868B147@MSX2>
Message-ID: <423FC707.4050604@statistik.uni-dortmund.de>

Brett Stansfield wrote:
> Dear R
> I recently did a scatterplot matrix using the following command
> pairs(sleep[c("SlowSleep", "ParaSleep", "logbw", "logbrw", "loglife",
> "loggest")],col=1+as.integer(ParaSleep > 5.5 | SlowSleep > 15.7))
> this highlighted outlying points for some of the x,y plots that I needed to
> identify. Unfortunately this highlights all the x,y plots some for which
> these points are not necessarily outliers. Is there a way to specify
> highlighting selected points at selected x,y plots within a matrix?

It's tricky, you would have to specify your own panel functions, 
probably even better using lattice.



> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Tue Mar 22 08:23:49 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 22 Mar 2005 08:23:49 +0100
Subject: [R] Numeric prediction
In-Reply-To: <d00895600503211242412ef5a5@mail.gmail.com>
References: <d00895600503211242412ef5a5@mail.gmail.com>
Message-ID: <423FC805.5050502@statistik.uni-dortmund.de>

Noel Anel wrote:
> Hello!
> 
> Which class(model) is most appropriate for numeric predition?

This is a joke, isn't it?
It highly depends on your problem (what "numeric predition" means), the 
data, your criterion what "most appropriate" means, etc.

Please read some basic textbook(s) on statistics or look for a local 
consultant!

> I used rpart class...

Some others start with regression analysis using linear models.


Uwe Ligges


> Thnx, Leonn.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Tue Mar 22 08:46:16 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 22 Mar 2005 08:46:16 +0100
Subject: [R] lattice xyplot() postscript (?) problem in R 2.0.0
In-Reply-To: <Pine.GSO.4.61.0503220644420.3780@c1.hrz.uni-giessen.de>
References: <Pine.GSO.4.61.0503220644420.3780@c1.hrz.uni-giessen.de>
Message-ID: <423FCD48.8060007@statistik.uni-dortmund.de>

Gerrit Eichner wrote:

> Dear all,
> 
> I work with R Version 2.0.0 on
> Machine hardware:   sun4u
> OS version:         5.9
> Processor type:     sparc
> Hardware:           SUNW,Sun-Blade-1000
> 
> and I have a very simple data frame (called OR) with the following 
> variables:
> 
>> sapply( OR, class)
> 
>         X        ci      FTyp
>  "factor" "numeric"  "factor"
> 
> (In OR$ci there are some Inf-values. OR's complete contents are appended 
> below.)
> 
> If I do
> 
>> library( lattice)
>> xyplot( X ~ ci | FTyp, data= OR)
> 
> 
> the requested trellis plot appears and everything is fine. BUT, if I 
> want to produce this plot in a postscript file a very strange and 
> reproducible error ocurs:
> 
>> postscript( "OR.ps")
>> xyplot( X ~ ci | FTyp, data= OR)
> 
> Error in "[<-"(`*tmp*`, pos.heights[[nm]], value = numeric(0)) :
>         nothing to replace with
> 
> This procedure -- applied to this very data frame -- did work fine 
> previously, i.e., when I used R 1.9.1. (traceback() didn't help me 
> tracking the problem further down.)
> I have the impression that it fails since I've started using R 2.0.0. 
> Could this be a version related problem? Any ideas?


a) You should try R-2.0.1 with a recent version of lattice (or help to 
try out and test R-devel). It works!

b) You want to use trellis.device("postscript", ...) rather than 
psotscript().

Uwe Ligges



> Thanks for any help!
> 
>  Best regards  --  Gerrit
> 
> PS: Here are the contents of data frame OR:
> 
>> OR
> 
>    X     ci FTyp
> 1  a 0.0000    A
> 2  a 0.0000    A
> 3  a    Inf    A
> 4  a 1.1158    B
> 5  a 0.2578    B
> 6  a    Inf    B
> 7  b 0.6568    A
> 8  b 0.0159    A
> 9  b    Inf    A
> 10 b 0.1051    B
> 11 b 0.0164    B
> 12 b    Inf    B
> 13 c    Inf    A
> 14 c 0.2217    A
> 15 c    Inf    A
> 16 c 9.2356    B
> 17 c 1.7123    B
> 18 c    Inf    B
> 19 d 0.4140    A
> 20 d 0.0099    A
> 21 d    Inf    A
> 22 d 1.7827    B
> 23 d 0.3606    B
> 24 d    Inf    B
> 
> -----------------------------------------------------------------------
> AR Dr. Gerrit Eichner                            Mathematical Institute
> gerrit.eichner at math.uni-giessen.de     Justus-Liebig-University Giessen
> Tel: +49-(0)641-99-32104            Arndtstr. 2, 35392 Giessen, Germany
> Fax: +49-(0)641-99-32029      http://www.math.uni-giessen.de/Stochastik
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From Tom.Mulholland at dpi.wa.gov.au  Tue Mar 22 09:20:48 2005
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Tue, 22 Mar 2005 16:20:48 +0800
Subject: [R] Highlighting points in a scatter plot matrix
Message-ID: <33F91FB3FDF42E4180428AC66A5CF30B02D3BAA5@afhex01.dpi.wa.gov.au>

There are two issues here identifying the outliers and highlighting them.

I have only a basic grasp of both of these concepts but will give what I have in case it helps. There appears to have been a move in the last 2 decades to improve the concepts of what actually constitutes an outlier, Brian Ripley made comment on this in 2003 when he said "That's the whole point of robust methods: compensate rather than reject." So I would suggest that you might like to find a copy of an article cited by Brian last year http://finzi.psych.upenn.edu/R/Rhelp02a/archive/35340.html 

As Uwe has pointed out if you are using pairs than you will have to write your own panel function unless someone has already written something. I have avoided using the panel function as it seems a bit cumbersome in comparison to writing your own using normal plots.

I haven't used the lattice package for a while now but it is obvious that major improvements have been made recently and you may find that this is a better vehicle for plotting your data.

However for a single plot there's no real problem.
plot(x,y,pch = 20, col = "navy")
points(x[outlier],y[outlier],pch = 20, col = "red")

where "outlier" are the observations you consider to be such

A crude example of what can be done rather than what should be done is (I have used inappropriate data)

par(mfrow = c(4,4))
# Just select setosa
iris <- iris[1:50,]

for (j in 1:4){
  for (k in 1:4){
  if (j == k){
    plot(5,axes = FALSE,type = "n",xlab = "",ylab = "")
    } else {
    mah <- mahalanobis(iris[,c(j,k)],rowMeans(iris[,c(j,k)]),cov(iris[,c(j,k)]))
    outlier <- which(mah > quantile(mah,.95))

    plot(iris[,j],iris[,k],pch = 20, col = "navy",axes = F,xlab = names(iris)[j],ylab = names(iris)[k])
    points(iris[outlier,j],iris[outlier,k],pch = 20, col = "red")
    }
    }
    }
    



> -----Original Message-----
> From: Brett Stansfield [mailto:brett at hbrc.govt.nz]
> Sent: Tuesday, 22 March 2005 6:09 AM
> To: R help (E-mail)
> Subject: [R] Highlighting points in a scatter plot matrix
> 
> 
> Dear R
> I recently did a scatterplot matrix using the following command
> pairs(sleep[c("SlowSleep", "ParaSleep", "logbw", "logbrw", "loglife",
> "loggest")],col=1+as.integer(ParaSleep > 5.5 | SlowSleep > 15.7))
> this highlighted outlying points for some of the x,y plots 
> that I needed to
> identify. Unfortunately this highlights all the x,y plots 
> some for which
> these points are not necessarily outliers. Is there a way to specify
> highlighting selected points at selected x,y plots within a matrix?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Tue Mar 22 09:26:04 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 22 Mar 2005 08:26:04 +0000 (GMT)
Subject: [R] Maximum amount of memory 
In-Reply-To: <Pine.A41.4.61b.0503211032250.11586@homer04.u.washington.edu>
References: <4200098800021576@ims4b.cp.tin.it>
	<e9be2c9e8f192b10d54c316ffc57a96f@sanger.ac.uk>
	<Pine.A41.4.61b.0503211032250.11586@homer04.u.washington.edu>
Message-ID: <Pine.LNX.4.61.0503220816230.5109@gannet.stats>

On Mon, 21 Mar 2005, Thomas Lumley wrote:

> On Mon, 21 Mar 2005, Tim Cutts wrote:
>
>> 
>> On 21 Mar 2005, at 4:42 pm, marvena at tin.it wrote:
>> 
>>> Hi,
>>> I have a problem:I need to use the maximum amount of memory in order to
>>> perform a very tough analysis. By purchasing the suitable computer, what's
>>> the maximum amount of memory obtainable in R?
>> 
>> Assuming that R is happy to use 64-bit memory pointers, the limit will be 
>> your wallet.

(It has been for several years.)

> I believe there are still some limits on sizes of individual objects, such as 
> C and Fortran code that uses int or INTEGER to hold dimensions.
>
> Many packages will definitely have problems: for example, the survival 
> package cannot correctly handle a design matrix with more than 2^31-1 
> elements, no matter how much memory it has.  I don't know how much of the 
> internal R code would also break when vectors have more than 2^31-1 entries.

For the record: R limits the length of vectors to 2^31 - 1, even on 64-bit 
machines.  We have discussed changing this, but the use of Fortran for 
e.g. matrix algebra (which does not have a longer integer type) means that 
a lot of work would be needed to raise the limit.

> Now, 2^31-1 entries in a numeric matrix is 16Gb in one object, so your wallet 
> is still likely to be the practical limit.

Indeed, that is why we have postponed changing the internal limit until 
nearer the time as machines with say 64Gb of RAM become commonplace. 
(You need to be able to make copies to do anything useful with R objects.)
Moore's Law suggests that will not happen until the early 2010s.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Olivier.Gremillet at web.de  Tue Mar 22 09:49:59 2005
From: Olivier.Gremillet at web.de (=?iso-8859-1?Q? Olivier=20Gr=E9millet ?=)
Date: Tue, 22 Mar 2005 09:49:59 +0100
Subject: [R] Index of dispersion for counts
Message-ID: <435743763@web.de>

Hi !

I am interrested in counting process analysis (as described in the text book of D.R. Cox  the statistical analysis of series of events) and in particular
in calculating index of dispersion of counts IDC(t)=Var(Nt)/E(Nt). is there some useful functions in R for such analysis ?
Many thanks in advance.

Olivier



From qinwei628 at gmail.com  Tue Mar 22 10:00:46 2005
From: qinwei628 at gmail.com (chin wei)
Date: Tue, 22 Mar 2005 17:00:46 +0800
Subject: [R] a simple question
Message-ID: <1ef27dc8050322010033a24a38@mail.gmail.com>

hi, all. 
I am a beginner. Could you tell me how to use read.table() to read
following beams.txt file.
thanks

file content is here:

"beams" <-
structure(list(strength = c(11.14, 12.74, 13.13, 11.51, 12.38, 
12.6, 11.13, 11.7, 11.02, 11.41), SpecificGravity = c(0.499, 
0.558, 0.604, 0.441, 0.55, 0.528, 0.418, 0.48, 0.406, 0.467), 
    moisture = c(11.1, 8.9, 8.8, 8.9, 8.8, 9.9, 10.7, 10.5, 10.5, 
    10.7)), .Names = c("strength", "SpecificGravity", "moisture"
), class = "data.frame", row.names = c("1", "2", "3", "4", "5", 
"6", "7", "8", "9", "10"))



From Gerrit.Eichner at math.uni-giessen.de  Tue Mar 22 10:06:37 2005
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Tue, 22 Mar 2005 10:06:37 +0100 (MET)
Subject: [R] Solved: lattice xyplot() postscript (?) problem in R 2.0.0
In-Reply-To: <423FCD48.8060007@statistik.uni-dortmund.de>
References: <Pine.GSO.4.61.0503220644420.3780@c1.hrz.uni-giessen.de>
	<423FCD48.8060007@statistik.uni-dortmund.de>
Message-ID: <Pine.GSO.4.61.0503221001430.4486@c1.hrz.uni-giessen.de>

Thanks to Uwe Ligges! The problem seems to have been my fault. Using his 
advice b) was the solution for me (under R-2.0.0). (My use of postscript() 
must have been a relict from my migration from S-PLUS to R.)

> a) You should try R-2.0.1 with a recent version of lattice (or help to 
> try out and test R-devel). It works!
>
> b) You want to use trellis.device("postscript", ...) rather than 
> postscript().

  Regards  --  Gerrit

-----------------------------------------------------------------------
AR Dr. Gerrit Eichner                            Mathematical Institute
gerrit.eichner at math.uni-giessen.de     Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104            Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32029      http://www.math.uni-giessen.de/Stochastik



From ramasamy at cancer.org.uk  Tue Mar 22 10:27:24 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 22 Mar 2005 09:27:24 +0000
Subject: [R] a simple question
In-Reply-To: <1ef27dc8050322010033a24a38@mail.gmail.com>
References: <1ef27dc8050322010033a24a38@mail.gmail.com>
Message-ID: <1111483644.6598.12.camel@dhcp-63.ccc.ox.ac.uk>

Try source("beams.txt") which reads and executes the commands in
beams.txt. 

It might make more sense in future to store and work with dataframes,
especially with big datasets.

Regards, Adai



On Tue, 2005-03-22 at 17:00 +0800, chin wei wrote:
> hi, all. 
> I am a beginner. Could you tell me how to use read.table() to read
> following beams.txt file.
> thanks
> 
> file content is here:
> 
> "beams" <-
> structure(list(strength = c(11.14, 12.74, 13.13, 11.51, 12.38, 
> 12.6, 11.13, 11.7, 11.02, 11.41), SpecificGravity = c(0.499, 
> 0.558, 0.604, 0.441, 0.55, 0.528, 0.418, 0.48, 0.406, 0.467), 
>     moisture = c(11.1, 8.9, 8.8, 8.9, 8.8, 9.9, 10.7, 10.5, 10.5, 
>     10.7)), .Names = c("strength", "SpecificGravity", "moisture"
> ), class = "data.frame", row.names = c("1", "2", "3", "4", "5", 
> "6", "7", "8", "9", "10"))
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Tue Mar 22 10:53:25 2005
From: ripley at stats.ox.ac.uk (Brian D Ripley)
Date: Tue, 22 Mar 2005 09:53:25 +0000 (GMT)
Subject: [R] [R-help] install problem
In-Reply-To: <002701c52de1$565e4f80$fb727dd2@GOOTY>
Message-ID: <Pine.GSO.4.31.0503220950470.19130-100000@markov.stats>

On Mon, 21 Mar 2005, Tae-Young Goo wrote:

> Hello.
>
> I've tried to install R to IBM AIX(v.5.1) machine.
> I've used compile options indicated by R-admin.

There are several sets there, so which exactly?

> Then, I met following error messages.
>
> /home/local/R_2.0.1/lib/R/bin/exec/R is unchanged
> /home/local/R_2.0.1/lib/R/modules/R_X11.so is unchanged
> /home/local/R_2.0.1/lib/R/modules/internet.so is unchanged

Those are not error messages.

> cp: lapack.so: file was not found.

So there were some earlier error messages about that.

> This error has broken out at the last stage of "make install"
> Please let me know what is wrong.

Please let us know what you did.  In particular AIX is tricky, and you
need to follow the instructions in the R-admin.html manual very
carefully.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.bleuyard at opgc.univ-bpclermont.fr  Tue Mar 22 11:26:26 2005
From: p.bleuyard at opgc.univ-bpclermont.fr (Pascal BLEUYARD)
Date: Tue, 22 Mar 2005 11:26:26 +0100
Subject: [R] Newbie: Matrix indexing
Message-ID: <008f01c52ec9$9ac65300$610410ac@meteophys.local>

Hi all,

  I need to compute some "occurence matrix": given a zero matrix and a set
of paired indexes, I want to store the number of occurences of each paired
index in a matrix. The paired indexes are stores as an index matrix. I
prefere not to use loops for performances purpose.

  Here follows a dummy example:

> occurence <- matrix(0, 2, 2); data
     [,1] [,2]
[1,]    0    0
[2,]    0    0
>
> index <- matrix(1, 3, 2); index
     [,1] [,2]
[1,]    1    1
[2,]    1    1
[3,]    1    1
>
> occurence[index] <- occurence[index] + 1

  I was expecting the folowing result:

> occurence
     [,1] [,2]
[1,]    3    0
[2,]    0    0

  I get instead:

> occurence
     [,1] [,2]
[1,]    1    0
[2,]    0    0

  I guess that there is some "hidden copy" involved but I wanted to know if
there is an efficient workaround (not using some loop structure). I thought
"factors" could do the job but I didn't manage to use them for that problem.

----------------------------------------------------------------------------
Pascal BLEUYARD
Laboratoire de M?t?orologie Physique (LaMP)
OPGC, Universit? Blaise Pascal
24, avenue des Landais
63177 AUBIERE CEDEX
T?l  : 04 73 40 73 75
Fax : 04 73 40 51 36
M?l : P.Bleuyard at opgc.univ-bpclermont.fr



From lecoutre at stat.ucl.ac.be  Tue Mar 22 11:43:28 2005
From: lecoutre at stat.ucl.ac.be (Eric Lecoutre)
Date: Tue, 22 Mar 2005 11:43:28 +0100
Subject: [R] Newbie: Matrix indexing
In-Reply-To: <008f01c52ec9$9ac65300$610410ac@meteophys.local>
Message-ID: <009d01c52ecb$fbac0280$6e8b6882@didacdom.stat.ucl.ac.be>

Hi Pascal,

One thing you can do is to work on indexes, count unique occurences and
assign them, as following:

> index <- as.data.frame(table(index[,1],index[,2]))
> index <- do.call("cbind",lapply(index, as.numeric)) # ensures numeric
coding (as table turns into factors)
> occurence[index[,1:2]] <- index[,3]
> occurence
     [,1] [,2]
[1,]    3    0
[2,]    0    0

Eric


Eric Lecoutre
UCL /  Institut de Statistique
Voie du Roman Pays, 20
1348 Louvain-la-Neuve
Belgium

tel: (+32)(0)10473050
lecoutre at stat.ucl.ac.be
http://www.stat.ucl.ac.be/ISpersonnel/lecoutre

If the statistics are boring, then you've got the wrong numbers. -Edward
Tufte   


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Pascal BLEUYARD
> Sent: mardi 22 mars 2005 11:26
> To: r-help at stat.math.ethz.ch
> Subject: [R] Newbie: Matrix indexing
> 
> 
> Hi all,
> 
>   I need to compute some "occurence matrix": given a zero 
> matrix and a set of paired indexes, I want to store the 
> number of occurences of each paired index in a matrix. The 
> paired indexes are stores as an index matrix. I prefere not 
> to use loops for performances purpose.
> 
>   Here follows a dummy example:
> 
> > occurence <- matrix(0, 2, 2); data
>      [,1] [,2]
> [1,]    0    0
> [2,]    0    0
> >
> > index <- matrix(1, 3, 2); index
>      [,1] [,2]
> [1,]    1    1
> [2,]    1    1
> [3,]    1    1
> >
> > occurence[index] <- occurence[index] + 1
> 
>   I was expecting the folowing result:
> 
> > occurence
>      [,1] [,2]
> [1,]    3    0
> [2,]    0    0
> 
>   I get instead:
> 
> > occurence
>      [,1] [,2]
> [1,]    1    0
> [2,]    0    0
> 
>   I guess that there is some "hidden copy" involved but I 
> wanted to know if there is an efficient workaround (not using 
> some loop structure). I thought "factors" could do the job 
> but I didn't manage to use them for that problem.
> 
> --------------------------------------------------------------
> --------------
> Pascal BLEUYARD
> Laboratoire de M?t?orologie Physique (LaMP)
> OPGC, Universit? Blaise Pascal
> 24, avenue des Landais
> 63177 AUBIERE CEDEX
> T?l  : 04 73 40 73 75
> Fax : 04 73 40 51 36
> M?l : P.Bleuyard at opgc.univ-bpclermont.fr
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From christoph.lehmann at gmx.ch  Tue Mar 22 11:59:25 2005
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Tue, 22 Mar 2005 11:59:25 +0100
Subject: [R] r under linux: creating high quality bmp's for win users
Message-ID: <423FFA8D.3000907@gmx.ch>

Hi

I produce graphics with R under linux, but my collaborators often use 
windows and cannot import eps pics e.g. in msword

what is the standard way to get e.g. bmp's with the same quality as eps. 
  going the way: creating eps, convert eps2bmp using 'convert' doesn't 
yield good enough bmp's

thanks for a short hint

cheers
christoph



From Markus.Gesmann at lloyds.com  Tue Mar 22 12:05:27 2005
From: Markus.Gesmann at lloyds.com (Gesmann, Markus)
Date: Tue, 22 Mar 2005 11:05:27 +0000
Subject: [R] r under linux: creating high quality bmp's for win users
Message-ID: <321C3EEBDB00C24185705B8BF733DADD0503F738@LNVCNTEXCH01.corp.lloydsnet>

I suggest using png() in the first place, as MS Word can handle them as
well.

Regards

Markus

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Christoph Lehmann
Sent: 22 March 2005 10:59
To: r-help at stat.math.ethz.ch
Subject: [Maybe spam] [R] r under linux: creating high quality bmp's for
win users


Hi

I produce graphics with R under linux, but my collaborators often use 
windows and cannot import eps pics e.g. in msword

what is the standard way to get e.g. bmp's with the same quality as eps.

  going the way: creating eps, convert eps2bmp using 'convert' doesn't 
yield good enough bmp's

thanks for a short hint

cheers
christoph

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html





************LNSCNTMCS01***************************************************
The information in this E-Mail and in any attachments is CON...{{dropped}}



From jtk at cmp.uea.ac.uk  Tue Mar 22 13:18:13 2005
From: jtk at cmp.uea.ac.uk (Jan T. Kim)
Date: Tue, 22 Mar 2005 12:18:13 +0000
Subject: [R] r under linux: creating high quality bmp's for win users
In-Reply-To: <423FFA8D.3000907@gmx.ch>
References: <423FFA8D.3000907@gmx.ch>
Message-ID: <20050322121813.GA26535@jtkpc.cmp.uea.ac.uk>

On Tue, Mar 22, 2005 at 11:59:25AM +0100, Christoph Lehmann wrote:

> I produce graphics with R under linux, but my collaborators often use 
> windows and cannot import eps pics e.g. in msword
> 
> what is the standard way to get e.g. bmp's with the same quality as eps. 
>  going the way: creating eps, convert eps2bmp using 'convert' doesn't 
> yield good enough bmp's
> 
> thanks for a short hint

The too short version: You can't get bmps of the same quality as encapsulated
postscript because bmp is a raster format and postscript is a language that
implements vector graphics.

The somewhat more useful (hopefully) version: You can always use gs to
produce a fixed resolution raster snapshot of your EPS file, e.g.

    gs -r600x600 -sDEVICE=bmp16m -sOutputFile=x.bmp -dNOPAUSE x.eps -c quit

This allows you to control the resolution (-r option) and should allow
you to produce any "quality" that may practically suffice, although this
is a kludge.

Best regards, Jan

P.S.: I believe that the convert program just acts as a wrapper to gs
anyway, with a resolution that is chosen to be useful for screen graphics
rather than for printing.

P.P.S.: I'll never understand why Word & Co. don't support encapsulated
postscript. With all that OLE and whatever, it can't be impossible to
do as LaTeX / xdvi does...?
-- 
 +- Jan T. Kim -------------------------------------------------------+
 |    *NEW*    email: jtk at cmp.uea.ac.uk                               |
 |    *NEW*    WWW:   http://www.cmp.uea.ac.uk/people/jtk             |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*



From ramasamy at cancer.org.uk  Tue Mar 22 12:21:20 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 22 Mar 2005 11:21:20 +0000
Subject: [R] Newbie: Matrix indexing
In-Reply-To: <008f01c52ec9$9ac65300$610410ac@meteophys.local>
References: <008f01c52ec9$9ac65300$610410ac@meteophys.local>
Message-ID: <1111490480.6598.52.camel@dhcp-63.ccc.ox.ac.uk>

It would be a lot easier if try to do the reverse by generating the
table last. However you will need to coerce your numeric data into
factors first. See what happens with the first example when you omit the
factor coercion.

 mat <- matrix(1, nr=3, nc2)   # called 'index' in your example
 my.levels <- c(1, 2)
 table( factor( mat[ ,1], levels=my.levels), 
        factor( mat[ ,2], levels=my.levels) )
   
    1 2
  1 3 0
  2 0 0


Here is a slightly more interesting examples.

 mat <- matrix(c(1,1, 1,1, 1,2, 2,2, 1,2) , nr=5, nc=2, byrow=T)
 my.levels <- c(1, 2, 3)
 table( factor(mat[ ,1], levels=my.levels), 
        factor(mat[ ,2], levels=my.levels) )

    1 2 3
  1 2 2 0
  2 0 1 0
  3 0 0 0

Regards, Adai



On Tue, 2005-03-22 at 11:26 +0100, Pascal BLEUYARD wrote:
> Hi all,
> 
>   I need to compute some "occurence matrix": given a zero matrix and a set
> of paired indexes, I want to store the number of occurences of each paired
> index in a matrix. The paired indexes are stores as an index matrix. I
> prefere not to use loops for performances purpose.
> 
>   Here follows a dummy example:
> 
> > occurence <- matrix(0, 2, 2); data
>      [,1] [,2]
> [1,]    0    0
> [2,]    0    0
> >
> > index <- matrix(1, 3, 2); index
>      [,1] [,2]
> [1,]    1    1
> [2,]    1    1
> [3,]    1    1
> >
> > occurence[index] <- occurence[index] + 1
> 
>   I was expecting the folowing result:
> 
> > occurence
>      [,1] [,2]
> [1,]    3    0
> [2,]    0    0
> 
>   I get instead:
> 
> > occurence
>      [,1] [,2]
> [1,]    1    0
> [2,]    0    0
> 
>   I guess that there is some "hidden copy" involved but I wanted to know if
> there is an efficient workaround (not using some loop structure). I thought
> "factors" could do the job but I didn't manage to use them for that problem.
> 
> ----------------------------------------------------------------------------
> Pascal BLEUYARD
> Laboratoire de M?t?orologie Physique (LaMP)
> OPGC, Universit? Blaise Pascal
> 24, avenue des Landais
> 63177 AUBIERE CEDEX
> T?l  : 04 73 40 73 75
> Fax : 04 73 40 51 36
> M?l : P.Bleuyard at opgc.univ-bpclermont.fr
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Rau at demogr.mpg.de  Tue Mar 22 13:03:34 2005
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Tue, 22 Mar 2005 13:03:34 +0100
Subject: [R] r under linux: creating high quality bmp's for win users
Message-ID: <8B08A3A1EA7AAC41BE24C750338754E6520065@HERMES.demogr.mpg.de>

Dear useRs, 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jan T. Kim
> Sent: Tuesday, March 22, 2005 1:18 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] r under linux: creating high quality bmp's 
> for win users
> 
> On Tue, Mar 22, 2005 at 11:59:25AM +0100, Christoph Lehmann wrote:
> 
> > I produce graphics with R under linux, but my collaborators 
> often use 
> > windows and cannot import eps pics e.g. in msword
> > 
> 
> P.P.S.: I'll never understand why Word & Co. don't support 
> encapsulated
> postscript. With all that OLE and whatever, it can't be impossible to
> do as LaTeX / xdvi does...?

as far as I know, it is possible now. At least, it recently worked for
me. I could include an eps-file which I produced with R into an ordinary
MS word document. So it should be possible for them to include your
eps-graphics.

Best,
Roland

Here at work, we do have:
- Microsoft Windows XP Professional Version 2002, Service Pack 2
and
- Microsoft Office Word SP1


+++++
This mail has been sent through the MPI for Demographic Rese...{{dropped}}



From ripley at stats.ox.ac.uk  Tue Mar 22 12:46:11 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 22 Mar 2005 11:46:11 +0000 (GMT)
Subject: [R] r under linux: creating high quality bmp's for win users
In-Reply-To: <423FFA8D.3000907@gmx.ch>
References: <423FFA8D.3000907@gmx.ch>
Message-ID: <Pine.LNX.4.61.0503221144320.22404@gannet.stats>

On Tue, 22 Mar 2005, Christoph Lehmann wrote:

> Hi
>
> I produce graphics with R under linux, but my collaborators often use windows 
> and cannot import eps pics e.g. in msword

Are they sure?  One can import eps images into Word, but you need to print 
them on a postscript printer.

> what is the standard way to get e.g. bmp's with the same quality as eps. 
> going the way: creating eps, convert eps2bmp using 'convert' doesn't yield 
> good enough bmp's

The bitmap() device might do better, although both are really using gs.

I would use png() and convert to bmp with ImageMagick's convert or 
otherwise.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From buser at stat.math.ethz.ch  Tue Mar 22 13:57:13 2005
From: buser at stat.math.ethz.ch (Christoph Buser)
Date: Tue, 22 Mar 2005 13:57:13 +0100
Subject: [R] setAs between a new S4 class and "POSIXlt"
Message-ID: <16960.5673.329571.968230@stat.math.ethz.ch>

Dear R gurus

I've a question concerning the transformation of a new S4 class
(that I defined) and the existing class "POSIXlt". I did the
following: 

## Definition of the new class:
setClass("dtime",
         representation(data = "POSIXlt"),
         prototype(data = as.POSIXlt("2004/06/01")))

## Transformation between the new class "dtime" and "POSIXlt":
setAs("dtime", "POSIXlt", def = function(from) {
  from at data
})
setAs("POSIXlt", "dtime", def = function(from) {
  new("dtime", data = from)
})

## Create a new "dtime" object:
(x1 <- new("dtime"))
str(x1)
## Transformation to "POSIXlt" class works well:
(y1 <- as(x1, "POSIXlt"))
str(y1)

## Transformation to "dtime" class fails
as(y2, "dtime")
> Fehler in insertMethod(methods, sig, args, def, TRUE) : 
	inserting method into non-methods-list object (class "NULL")

## This works properly
new("dtime", data = y2)

####################################################################

## Now I put another setAs for the Subclass "POSIXt"
setAs("POSIXt", "dtime", def = function(from) {
  new("dtime", data = from)
})

## and the transformation to "dtime" class works:
as(y2, "dtime")


I tried to understand what happend, without success. Could
someone give me a hint or a reference (some help page or others) 
to improve my understanding, please?
Thank you very much.

I work with:

platform i686-pc-linux-gnu           
arch     i686                        
os       linux-gnu                   
system   i686, linux-gnu             
status   Under development (unstable)
major    2                           
minor    1.0                         
year     2005                        
month    03                          
day      22                          
language R                           


Regards,

Christoph Buser

--------------------------------------------------------------
Christoph Buser <buser at stat.math.ethz.ch>
Seminar fuer Statistik, LEO C11
ETH (Federal Inst. Technology)	8092 Zurich	 SWITZERLAND
phone: x-41-1-632-5414		fax: 632-1228
http://stat.ethz.ch/~buser/



From William.Simpson at drdc-rddc.gc.ca  Tue Mar 22 14:22:22 2005
From: William.Simpson at drdc-rddc.gc.ca (Bill Simpson)
Date: Tue, 22 Mar 2005 08:22:22 -0500 (EST)
Subject: [R] flatten a matrix and unflatten it
In-Reply-To: <D9A95B4B7B20354992E165EEADA31999056A935B@uswpmx00.merck.com>
Message-ID: <Pine.LNX.4.44.0503220819450.27550-100000@localhost.localdomain>

Sorry -- I meant to say "dataframe" instead of matrix.

Anyway I see that my troubles are gone when I scan the data in as a vector 
then convert to matrix. (I had troubles doing such manipulations when I 
read in the data using read.table)

x<-scan("/home/wsimpson/papers/face/max.dat")
xx<-matrix(x, ncol=3, nrow=length(x)/3, byrow=T)

Thanks for the help.

Bill



From buser at stat.math.ethz.ch  Tue Mar 22 14:32:14 2005
From: buser at stat.math.ethz.ch (Christoph Buser)
Date: Tue, 22 Mar 2005 14:32:14 +0100
Subject: [R] Pb with ks.test pvalue
In-Reply-To: <20050318163602.84641.qmail@web41129.mail.yahoo.com>
References: <20050318163602.84641.qmail@web41129.mail.yahoo.com>
Message-ID: <16960.7774.172924.736767@stat.math.ethz.ch>

Dear Anthony

I don't know how SAS calculates the p-value, but in R the
p-value is calculated under the assumption that the parameters
of the distribution (you want to compare with your samples) are
known and not estimated from the data.

In your example you estimate them from the data (by mean(w) and
sd(w) and therefore the p-values are not reliable. 
Somehow you fit the theoretical distribution to well to your
data (using mean and sd, estimated from the data).
Hence you are too conservative and the p.values are two large.
Maybe SAS does a correction for the estimation of the parameters
and therefore gets smaller p-values, but this is pure
speculation since I don't know the way how SAS is doing the
calculation.

I did a simulation and created 10000 samples from a normal
distribution and calculated the ks.test. I expected around 500 
significant results (on the level 0.05) by chance and got 1 or
2. 

I recommend to use graphical methods (e.g. normal plots) to
validate the normal distribution of your data instead of testing
it.  
See also ?qqnorm or ?qqplot.

Regards,

Christoph Buser

--------------------------------------------------------------
Christoph Buser <buser at stat.math.ethz.ch>
Seminar fuer Statistik, LEO C11
ETH (Federal Inst. Technology)	8092 Zurich	 SWITZERLAND
phone: x-41-1-632-5414		fax: 632-1228
http://stat.ethz.ch/~buser/
--------------------------------------------------------------



Anthony Landrevie writes:
 > 
 > Hello,
 > 
 > While doing test of normality under R and SAS, in order to prove the efficiency of R to my company, I notice
 > 
 > that Anderson Darling, Cramer Van Mises and Shapiro-Wilk tests results are quite the same under the two environnements,
 > 
 > but the Kolmogorov-smirnov p-value really is different.
 > 
 > Here is what I do:
 > 
 > > ks.test(w,pnorm,mean(w),sd(w))
 > 
 > One-sample Kolmogorov-Smirnov test
 > 
 > data: w 
 > 
 > D = 0.2143, p-value = 0.3803
 > 
 > alternative hypothesis: two.sided 
 > 
 > > w
 > 
 > [1] 3837 3334 2208 1745 2576 3208 3746 3523 3430 3480 3116 3428 2184 2383 3500 3866 3542
 > 
 > [18] 3278
 > 
 >  
 > 
 > SAS results:
 > 
 > Kolmogorov-Smirnov D 0.214278 Pr > D 0.0271
 > 
 > Why is the p-value so high under R? Much higher than with other tests.
 > 
 > Best regards,
 > 
 > Anthony Landrevie (French Student)
 > 
 > 
 > 		
 > ---------------------------------
 > 
 > 
 > 	[[alternative HTML version deleted]]
 > 
 > ______________________________________________
 > R-help at stat.math.ethz.ch mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ggrothendieck at myway.com  Tue Mar 22 14:35:52 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 22 Mar 2005 13:35:52 +0000 (UTC)
Subject: [R] Newbie: Matrix indexing
References: <008f01c52ec9$9ac65300$610410ac@meteophys.local>
Message-ID: <loom.20050322T143317-162@post.gmane.org>

Pascal BLEUYARD <p.bleuyard <at> opgc.univ-bpclermont.fr> writes:

: 
: Hi all,
: 
:   I need to compute some "occurence matrix": given a zero matrix and a set
: of paired indexes, I want to store the number of occurences of each paired
: index in a matrix. The paired indexes are stores as an index matrix. I
: prefere not to use loops for performances purpose.
: 
:   Here follows a dummy example:
: 
: > occurence <- matrix(0, 2, 2); data
:      [,1] [,2]
: [1,]    0    0
: [2,]    0    0
: >
: > index <- matrix(1, 3, 2); index
:      [,1] [,2]
: [1,]    1    1
: [2,]    1    1
: [3,]    1    1
: >
: > occurence[index] <- occurence[index] + 1
: 
:   I was expecting the folowing result:
: 
: > occurence
:      [,1] [,2]
: [1,]    3    0
: [2,]    0    0
: 
:   I get instead:
: 
: > occurence
:      [,1] [,2]
: [1,]    1    0
: [2,]    0    0
: 
:   I guess that there is some "hidden copy" involved but I wanted to know if
: there is an efficient workaround (not using some loop structure). I thought
: "factors" could do the job but I didn't manage to use them for that problem.

Turn your index matrix into a data frame so you can use lapply on it.
Then convert each of the two columns to a two-level factor.  Now you 
can use table on the result:

   table(lapply(as.data.frame(index), factor, lev = 1:2))



From nioniodesbois at yahoo.fr  Tue Mar 22 14:45:29 2005
From: nioniodesbois at yahoo.fr (Guillaume STORCHI)
Date: Tue, 22 Mar 2005 14:45:29 +0100 (CET)
Subject: [R] nls() and "singular grandient"
Message-ID: <20050322134529.59238.qmail@web86902.mail.ukl.yahoo.com>

Hello,

I have a problem with nls() when I want to fit a model with more than two
parameters to be fitted which are written as start=list(a1=,a2=,a3=,...).
Everytime, it displays:'error... singular gradient'
it's a real pain!!! 

Hope sb knows something about this

Thanks

GS



From deepayan at stat.wisc.edu  Tue Mar 22 15:06:36 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 22 Mar 2005 08:06:36 -0600
Subject: [R] Solved: lattice xyplot() postscript (?) problem in R 2.0.0
In-Reply-To: <Pine.GSO.4.61.0503221001430.4486@c1.hrz.uni-giessen.de>
References: <Pine.GSO.4.61.0503220644420.3780@c1.hrz.uni-giessen.de>
	<423FCD48.8060007@statistik.uni-dortmund.de>
	<Pine.GSO.4.61.0503221001430.4486@c1.hrz.uni-giessen.de>
Message-ID: <200503220806.36564.deepayan@stat.wisc.edu>

On Tuesday 22 March 2005 03:06, Gerrit Eichner wrote:
> Thanks to Uwe Ligges! The problem seems to have been my fault. Using
> his advice b) was the solution for me (under R-2.0.0). (My use of
> postscript() must have been a relict from my migration from S-PLUS to
> R.)

Actually, that advice is more pertinent to S-PLUS than R, and doesn't 
really make any difference in lattice (except for certain situations 
where one wants to use non-default settings).

What you saw was a bug in the version of lattice that was shipped with R 
2.0.0. It has been long since fixed, and if you don't want to upgrade 
R, just running update.packages() should get you a correct version.

> > a) You should try R-2.0.1 with a recent version of lattice (or help
> > to try out and test R-devel). It works!
> >
> > b) You want to use trellis.device("postscript", ...) rather than
> > postscript().



From liuwensui at gmail.com  Tue Mar 22 15:11:05 2005
From: liuwensui at gmail.com (Wensui Liu)
Date: Tue, 22 Mar 2005 09:11:05 -0500
Subject: [R] Is it too big for R?
Message-ID: <1115a2b0050322061112592e18@mail.gmail.com>

a data file (close to 60M) with 90,000 rows and 173 columns. Is it too
big for R?

Thanks.



From pallier at lscp.ehess.fr  Tue Mar 22 15:15:25 2005
From: pallier at lscp.ehess.fr (Christophe Pallier)
Date: Tue, 22 Mar 2005 15:15:25 +0100
Subject: [R] r under linux: creating high quality bmp's for win users
In-Reply-To: <423FFA8D.3000907@gmx.ch>
References: <423FFA8D.3000907@gmx.ch>
Message-ID: <4240287D.9040804@lscp.ehess.fr>

Hello Christoph!

In the past, I used an utility called "eps2wmf".
It only works under Windows though (maybe under Linux with wine?).
I believe it is available on the CTAN (Tex archives).

The nice thing is that wmf files are not bitmap and scale well.

Christophe Pallier


Christoph Lehmann wrote:

> Hi
>
> I produce graphics with R under linux, but my collaborators often use 
> windows and cannot import eps pics e.g. in msword
>
> what is the standard way to get e.g. bmp's with the same quality as 
> eps.  going the way: creating eps, convert eps2bmp using 'convert' 
> doesn't yield good enough bmp's
>
> thanks for a short hint
>
> cheers
> christoph
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Tue Mar 22 15:21:31 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 22 Mar 2005 09:21:31 -0500
Subject: [R] Is it too big for R?
Message-ID: <3A822319EB35174CA3714066D590DCD50994E8C1@usrymx25.merck.com>

It might be too big to R on the machine your are using, and it's also highly
dependent on what you want to do with it.  E.g., if you try to cluster the
rows using something that requires the full distance matrix, you're most
likely out of luck.  I've dealt with data with 20,000 rows but more than
5000 columns in R with no problem.

Andy

> From: Wensui Liu
> 
> a data file (close to 60M) with 90,000 rows and 173 columns. Is it too
> big for R?
> 
> Thanks.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From sojourn at ameritech.net  Tue Mar 22 15:33:56 2005
From: sojourn at ameritech.net (Shelby)
Date: Tue, 22 Mar 2005 09:33:56 -0500
Subject: [R] r under linux: creating high quality bmp's for win users
In-Reply-To: <Pine.LNX.4.61.0503221144320.22404@gannet.stats>
Message-ID: <008801c52eec$39d754e0$0201a8c0@shelbyhome>

I have also recently come across a conversion program that works with
ghostscript to convert ps and pdf images into other vector formats,
including .wmf and .emf for M$ software: http://www.pstoedit.net/.  This
might be helpful if your colleagues do not have, as Dr. Ripley
indicated, a postscript printer (if they do have a PS printer then the
regular .eps files produced by ghostscript should work fine, but they
will not be rendered at proper resolution on the screen preview while
they are working on the document).

Note: I have not given this program a thorough workout in comparison to
imagemagick or anything else - just enough to see that it does what it
says it does.

===============================
Shelby L. Berkowitz
Ecological-Community Psychology
and Institute for Health Care Studies
Michigan State University
berkowi4 at msu.edu 

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Prof 
>Brian Ripley
>Sent: Tuesday, March 22, 2005 6:46 AM
>To: Christoph Lehmann
>Cc: r-help at stat.math.ethz.ch
>Subject: Re: [R] r under linux: creating high quality bmp's 
>for win users
>
>
>On Tue, 22 Mar 2005, Christoph Lehmann wrote:
>
>> Hi
>>
>> I produce graphics with R under linux, but my collaborators 
>often use 
>> windows
>> and cannot import eps pics e.g. in msword
>
>Are they sure?  One can import eps images into Word, but you 
>need to print 
>them on a postscript printer.
>
>> what is the standard way to get e.g. bmp's with the same quality as 
>> eps.
>> going the way: creating eps, convert eps2bmp using 'convert' 
>doesn't yield 
>> good enough bmp's
>
>The bitmap() device might do better, although both are really using gs.
>
>I would use png() and convert to bmp with ImageMagick's convert or 
>otherwise.
>
>-- 
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list 
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read 
>the posting guide! http://www.R-project.org/posting-guide.html
>
>-- 
>No virus found in this incoming message.
>Checked by AVG Anti-Virus.
>Version: 7.0.308 / Virus Database: 266.8.0 - Release Date: 3/21/2005
> 
>



From agostino.manzato at osmer.fvg.it  Tue Mar 22 15:34:45 2005
From: agostino.manzato at osmer.fvg.it (Agostino.Manzato@osmer.fvg.it)
Date: Tue, 22 Mar 2005 15:34:45 +0100
Subject: [R] R on SuSe 9.2 AMD 64 bit
Message-ID: <42402D05.1DCB703@osmer.fvg.it>

Hi everybody,
I would like to know if it is possible to find the RPM
of R 2.0.1 for SuSe 9.2 AMD64 (Athlon 64 bit).
Alternatively, where to find clear instructions how to 
compile it on the same OS (I'm not an expert).

Many thanks in advance.

	Tino



From gb at stat.umu.se  Tue Mar 22 15:44:31 2005
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Tue, 22 Mar 2005 15:44:31 +0100
Subject: [R] Hazard function or cumulative Hazard function in R
In-Reply-To: <423F6122.2040201@pdf.com>
References: <20050321200420.87188.qmail@web60103.mail.yahoo.com>
	<423F6122.2040201@pdf.com>
Message-ID: <20050322144431.GA29099@stat.umu.se>

On Mon, Mar 21, 2005 at 04:04:50PM -0800, Spencer Graves wrote:
>    1.  Have you looked at the "survival" package?  Venables and Ripley 
> (2002) Modern Applied Statistics with S (Springer) has a chapter on 
> survival analysis that I found quite helpful.  The "survival" package 
> includes hazard plots, which are discussed in Venables and Ripley. 

It seems more likely that Yassir wants to calculate theoretical hazard and
cumulative hazards functions (as he knows how to "program it") for a given
distribution, and then the answer is 'No there are no such functions'.

But, taking the Weibull distribution as an example, they are easily
calculated using 'pweibull' and 'dweibull':

1. From ?pweibull:

   The cumulative hazard H(t) = - log(1 - F(t)) is 
   '-pweibull(t, a, b, lower = FALSE, log = TRUE)'

2. The hazard function hweibull itself can be given by
   
   hweibull <- function(t, shape, scale = 1) dweibull(t, shape, scale) /
   pweibull(t, shape, scale, lower.tail = FALSE)  

'hweibull', as defined here, is not the numerically optimal solution, but
the formula has the advantage of working for any distribution.

>      2.  If that is not adequate, have you tried an "R Site Search" 
> (from www.r-project.org -> search)? 
> 
>      hope this helps.  spencer graves
> 
> yassir rabhi wrote:
> 
> >  Hi, 
> >I'm student from canada, and i'work in survival
> >analysis.I want to know if there is a hazard function
> >or cumulative hazard function in R or not, i know how
> >to program it, but it is easy to use it if they exists
> >in R.
> >Thanks.
> >                                         Yassir
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! 
> >http://www.R-project.org/posting-guide.html
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html

-- 
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se



From brostaux.y at fsagx.ac.be  Tue Mar 22 15:53:32 2005
From: brostaux.y at fsagx.ac.be (Yves Brostaux)
Date: Tue, 22 Mar 2005 15:53:32 +0100
Subject: [R] Lattice : factor levels in the margins
Message-ID: <4240316C.1050201@fsagx.ac.be>

Hello !

I'm struggling again against lattice graprhics. ;) I'm trying to produce 
a conditionnal xyplot with two conditionning factors (let's say A and 
B). I want the levels of those factors (A1, A2, etc)  to show in the 
margins of the lattice plot, not in the strips between the panels.

A1     A2     A3

plot11 plot12 plot13  B1

plot21 plot22 plot23  B2


I managed to remove the strips with strip=FALSE, but now I can't find 
how to write the levels of the factors in the margin in front of their 
respective lines/columns. It doesn't seems that xlab and ylab arguments 
could help doing this, as I can't insert multiple xlab's (x variable and 
A levels, or y variable and B levels) and can't decide which side to use 
for writing them.

Does anybody have a hint ? Thank you very much !

-- 
Ir. Yves BROSTAUX
Unit? de Statistique et Informatique
Facult? universitaire des Sciences agronomiques de Gembloux (FUSAGx)
8, avenue de la Facult?
B-5030 Gembloux
Belgique
T?l: +32 81 62 24 69
Email: brostaux.y at fsagx.ac.be



From spencer.graves at pdf.com  Tue Mar 22 16:04:07 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 22 Mar 2005 07:04:07 -0800
Subject: [R] nls() and "singular grandient"
In-Reply-To: <20050322134529.59238.qmail@web86902.mail.ukl.yahoo.com>
References: <20050322134529.59238.qmail@web86902.mail.ukl.yahoo.com>
Message-ID: <424033E7.4@pdf.com>

      Many people could help you, but the question is too general.  In 
brief, it means that the algorithm has found a place where the 
(estimated?) matrix of first or second partial derivatives is of reduced 
rank, and it refuses to do more.  For such problems, I often use "optim". 

      If you need more specifics, PLEASE do read the posting guide! 
"http://www.R-project.org/posting-guide.html", prepare a very simple 
example of what you get, and submit that to this list.  Many people find 
answers to their questions in the process of preparing a post following 
this guide, and those that don't, I believe, are more likely to get more 
informative replies. 

      spencer graves

Guillaume STORCHI wrote:

>Hello,
>
>I have a problem with nls() when I want to fit a model with more than two
>parameters to be fitted which are written as start=list(a1=,a2=,a3=,...).
>Everytime, it displays:'error... singular gradient'
>it's a real pain!!! 
>
>Hope sb knows something about this
>
>Thanks
>
>GS
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From spencer.graves at pdf.com  Tue Mar 22 16:05:26 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 22 Mar 2005 07:05:26 -0800
Subject: [R] Numeric prediction
In-Reply-To: <423FC805.5050502@statistik.uni-dortmund.de>
References: <d00895600503211242412ef5a5@mail.gmail.com>
	<423FC805.5050502@statistik.uni-dortmund.de>
Message-ID: <42403436.9060201@pdf.com>

      Or at least read the posting guide! 
http://www.R-project.org/posting-guide.html.  Working through that can 
help you get a more informative reply.  spencer graves

Uwe Ligges wrote:

> Noel Anel wrote:
>
>> Hello!
>>
>> Which class(model) is most appropriate for numeric predition?
>
>
> This is a joke, isn't it?
> It highly depends on your problem (what "numeric predition" means), 
> the data, your criterion what "most appropriate" means, etc.
>
> Please read some basic textbook(s) on statistics or look for a local 
> consultant!
>
>> I used rpart class...
>
>
> Some others start with regression analysis using linear models.
>
>
> Uwe Ligges
>
>
>> Thnx, Leonn.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From nioniodesbois at yahoo.fr  Tue Mar 22 16:07:44 2005
From: nioniodesbois at yahoo.fr (Guillaume STORCHI)
Date: Tue, 22 Mar 2005 16:07:44 +0100 (CET)
Subject: [R] Re: xyplot 
Message-ID: <20050322150744.76179.qmail@web86907.mail.ukl.yahoo.com>

d'habitude je mets juste xyplot(y~x | factor(z)...) ou xyplot(y~factor(x)... )
il faut mettre la variable dont tu veux voir les niveaux comme factor()


GS



From Mike.Prager at noaa.gov  Tue Mar 22 16:09:20 2005
From: Mike.Prager at noaa.gov (Mike Prager)
Date: Tue, 22 Mar 2005 10:09:20 -0500
Subject: [R] r under linux: creating high quality bmp's for win
  users
In-Reply-To: <4240287D.9040804@lscp.ehess.fr>
References: <423FFA8D.3000907@gmx.ch>
 <4240287D.9040804@lscp.ehess.fr>
Message-ID: <6.1.2.0.2.20050322100138.01dc1ec0@hermes.nos.noaa.gov>

Christoph Lehmann wrote:

>I produce graphics with R under linux, but my collaborators often use 
>windows and cannot import eps pics e.g. in msword
>
>what is the standard way to get e.g. bmp's with the same quality as 
>eps.  going the way: creating eps, convert eps2bmp using 'convert' doesn't 
>yield good enough bmp's

It is impossible to get BMPs with same quality as EPS, as the latter is 
mainly a vector format, so it scales perfectly.  It also uses hardware 
(PostScript) scalable fonts.

The simplest way to meet this need might be to ask your collaborators to 
either update or explore their copies of MS Word.  The version I am using 
(MS Word 2002 SP3) not only imports and prints EPS files correctly, it adds 
previews so they can be seen while editing. Although EPS support has varied 
among Word versions, it seems to be getting better in recent years.

Slightly off-topic:  The Windows metafile formats are native Windows vector 
graphics, sometimes recommended as substitutes for EPS.  In my experience, 
they suffer two problems: (1) They are not portable across platforms; and 
(2) the way they choose fonts is machine-specific, which can cause some 
very annoying problems.


-- 
Michael Prager, Ph.D.
Population Dynamics Team, NMFS SE Fisheries Science Center
NOAA Center for Coastal Fisheries and Habitat Research
Beaufort, North Carolina  28516
http://shrimp.ccfhrb.noaa.gov/~mprager/



From nioniodesbois at yahoo.fr  Tue Mar 22 16:11:41 2005
From: nioniodesbois at yahoo.fr (Guillaume STORCHI)
Date: Tue, 22 Mar 2005 16:11:41 +0100 (CET)
Subject: [R] Re:xyplot
Message-ID: <20050322151142.42589.qmail@web86909.mail.ukl.yahoo.com>

Try xyplot(y~factor(x)...)
or  xyplot(y~x | factor(z)...)

it depends on your data

GS



From deepayan at stat.wisc.edu  Tue Mar 22 16:19:00 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 22 Mar 2005 09:19:00 -0600
Subject: [R] Lattice : factor levels in the margins
In-Reply-To: <4240316C.1050201@fsagx.ac.be>
References: <4240316C.1050201@fsagx.ac.be>
Message-ID: <200503220919.00751.deepayan@stat.wisc.edu>

On Tuesday 22 March 2005 08:53, Yves Brostaux wrote:
> Hello !
>
> I'm struggling again against lattice graprhics. ;) I'm trying to
> produce a conditionnal xyplot with two conditionning factors (let's
> say A and B). I want the levels of those factors (A1, A2, etc)  to
> show in the margins of the lattice plot, not in the strips between
> the panels.
>
> A1     A2     A3
>
> plot11 plot12 plot13  B1
>
> plot21 plot22 plot23  B2

You cannot do this with xyplot (or any other lattice function). But 
try ?coplot.

Deepayan

> I managed to remove the strips with strip=FALSE, but now I can't find
> how to write the levels of the factors in the margin in front of
> their respective lines/columns. It doesn't seems that xlab and ylab
> arguments could help doing this, as I can't insert multiple xlab's (x
> variable and A levels, or y variable and B levels) and can't decide
> which side to use for writing them.
>
> Does anybody have a hint ? Thank you very much !



From ggrothendieck at myway.com  Tue Mar 22 16:11:00 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 22 Mar 2005 15:11:00 +0000 (UTC)
Subject: [R] r under linux: creating high quality bmp's for win users
References: <423FFA8D.3000907@gmx.ch> <4240287D.9040804@lscp.ehess.fr>
Message-ID: <loom.20050322T160943-549@post.gmane.org>


Can you provide a link.  I did a google search and found something
on a Japanese site but it turned out that the writer had made a 
mistake and it linked to wmf2eps, not eps2wmf.

Christophe Pallier <pallier <at> lscp.ehess.fr> writes:

: 
: Hello Christoph!
: 
: In the past, I used an utility called "eps2wmf".
: It only works under Windows though (maybe under Linux with wine?).
: I believe it is available on the CTAN (Tex archives).
: 
: The nice thing is that wmf files are not bitmap and scale well.
: 
: Christophe Pallier
: 
: Christoph Lehmann wrote:
: 
: > Hi
: >
: > I produce graphics with R under linux, but my collaborators often use 
: > windows and cannot import eps pics e.g. in msword
: >
: > what is the standard way to get e.g. bmp's with the same quality as 
: > eps.  going the way: creating eps, convert eps2bmp using 'convert' 
: > doesn't yield good enough bmp's
: >
: > thanks for a short hint
: >
: > cheers
: > christoph
: >
: > ______________________________________________
: > R-help <at> stat.math.ethz.ch mailing list
: > https://stat.ethz.ch/mailman/listinfo/r-help
: > PLEASE do read the posting guide! 
: > http://www.R-project.org/posting-guide.html
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://stat.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From macq at llnl.gov  Tue Mar 22 17:03:11 2005
From: macq at llnl.gov (Don MacQueen)
Date: Tue, 22 Mar 2005 08:03:11 -0800
Subject: [R] Is it too big for R?
In-Reply-To: <1115a2b0050322061112592e18@mail.gmail.com>
References: <1115a2b0050322061112592e18@mail.gmail.com>
Message-ID: <p06210209be65f0af1814@[128.115.153.6]>

I regularly work with data frames with around 144000 rows and 23 columns.

In fact, I work with two of them in the same session, one in 
.GlobalEnv and the other in search()[2], attached using attach() on a 
file previously saved with save().

-Don

At 9:11 AM -0500 3/22/05, Wensui Liu wrote:
>a data file (close to 60M) with 90,000 rows and 173 columns. Is it too
>big for R?
>
>Thanks.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From i.visser at uva.nl  Tue Mar 22 17:20:40 2005
From: i.visser at uva.nl (Ingmar Visser)
Date: Tue, 22 Mar 2005 11:20:40 -0500
Subject: [R] Convert timeseries to transition matrix
Message-ID: <BE65B008.2603%i.visser@uva.nl>

Hi All,
Does someone have an idea of how to cleverly convert a categorical
timeseries into a transition matrix?
Ie, I have something like:
x<- c(1,1,2,1,1,2,2,2,1,2),
And I want a matrix with counts and/or probabilities:
> tr <- matrix(c(2,3,2,2),2,2)
> tr
     [,1] [,2]
[1,]    2    2
[2,]    3    2
Meaning that there are two transitions from 1 to 1, two from 1 to 2, three
from 2 to 1 and two from 2 to 2.
Using for loops etc this is of course no problem, but I am curious whether
there is a smarter solution.
Any hints appreciated, Ingmar

-- 
Ingmar Visser
Department of Psychology, University of Amsterdam
Roetersstraat 15, room 1009
1018 WB Amsterdam
The Netherlands
http://users.fmg.uva.nl/ivisser/
tel: +31-20-5256735



From sghosh at lexgen.com  Tue Mar 22 17:26:49 2005
From: sghosh at lexgen.com (Ghosh, Sandeep)
Date: Tue, 22 Mar 2005 10:26:49 -0600
Subject: [R] Question with lattice xyplot
Message-ID: <2B47B68F97330841AC8C670749084A7D06C43B@wdexchmb01.lexicon.lexgen.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050322/089b8543/attachment.pl

From GPetris at uark.edu  Tue Mar 22 17:27:37 2005
From: GPetris at uark.edu (Giovanni Petris)
Date: Tue, 22 Mar 2005 10:27:37 -0600 (CST)
Subject: [R] Convert timeseries to transition matrix
In-Reply-To: <BE65B008.2603%i.visser@uva.nl> (message from Ingmar Visser on
	Tue, 22 Mar 2005 11:20:40 -0500)
References: <BE65B008.2603%i.visser@uva.nl>
Message-ID: <200503221627.j2MGRbYb003418@definetti.uark.edu>


The following, using table, seems to work:

> x <- sample(letters[1:2], 10, replace=T)
> x
 [1] "b" "a" "a" "b" "b" "a" "a" "b" "b" "b"
> table(x[-1],x[-length(x)])
   
    a b
  a 2 2
  b 2 3


Hope this helps,
Giovanni Petris

> Date: Tue, 22 Mar 2005 11:20:40 -0500
> From: Ingmar Visser <i.visser at uva.nl>
> Sender: r-help-bounces at stat.math.ethz.ch
> Cc: 
> Precedence: list
> User-Agent: Microsoft-Entourage/11.1.0.040913
> 
> Hi All,
> Does someone have an idea of how to cleverly convert a categorical
> timeseries into a transition matrix?
> Ie, I have something like:
> x<- c(1,1,2,1,1,2,2,2,1,2),
> And I want a matrix with counts and/or probabilities:
> > tr <- matrix(c(2,3,2,2),2,2)
> > tr
>      [,1] [,2]
> [1,]    2    2
> [2,]    3    2
> Meaning that there are two transitions from 1 to 1, two from 1 to 2, three
> from 2 to 1 and two from 2 to 2.
> Using for loops etc this is of course no problem, but I am curious whether
> there is a smarter solution.
> Any hints appreciated, Ingmar
> 
> -- 
> Ingmar Visser
> Department of Psychology, University of Amsterdam
> Roetersstraat 15, room 1009
> 1018 WB Amsterdam
> The Netherlands
> http://users.fmg.uva.nl/ivisser/
> tel: +31-20-5256735
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From dr.mike at ntlworld.com  Tue Mar 22 17:30:05 2005
From: dr.mike at ntlworld.com (dr mike)
Date: Tue, 22 Mar 2005 16:30:05 -0000
Subject: [R] r under linux: creating high quality bmp's for win users
In-Reply-To: <Pine.LNX.4.61.0503221144320.22404@gannet.stats>
Message-ID: <20050322163029.NRCT1289.aamta02-winn.mailhost.ntl.com@c400>

I second the use of png() to create portable network graphics format
pictures, as MS Word (XP and 2003 at least) can handle these without any
problems. I use this format as a matter of course in preparing material for
embedding in web pages.

Regards,

Mike

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Prof 
> Brian Ripley
> Sent: 22 March 2005 11:46
> To: Christoph Lehmann
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] r under linux: creating high quality bmp's 
> for win users
> 
> On Tue, 22 Mar 2005, Christoph Lehmann wrote:
> 
> > Hi
> >
> > I produce graphics with R under linux, but my collaborators 
> often use 
> > windows and cannot import eps pics e.g. in msword
> 
> Are they sure?  One can import eps images into Word, but you 
> need to print them on a postscript printer.
> 
> > what is the standard way to get e.g. bmp's with the same 
> quality as eps. 
> > going the way: creating eps, convert eps2bmp using 
> 'convert' doesn't 
> > yield good enough bmp's
> 
> The bitmap() device might do better, although both are really 
> using gs.
> 
> I would use png() and convert to bmp with ImageMagick's 
> convert or otherwise.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From drew.balazs at gmail.com  Tue Mar 22 17:31:54 2005
From: drew.balazs at gmail.com (Drew Balazs)
Date: Tue, 22 Mar 2005 10:31:54 -0600
Subject: [R] OS X proxy question
Message-ID: <6a2c704c050322083142a91274@mail.gmail.com>

All,

I'm currently using R 2.0.1 on a Powerbook G4 with OS X 10.3.8. So far
the only way I've found to set my proxy is by doing 
Sys.putenv("http_proxy"="<insert proxy url>:<proxy port>)  everytime I
start up R.

This works fine, but I'd like to find a solution that doesnt require
manual input everytime I start up R. Does any one have a better way of
accomplishing this?


Thanks,

Drew Balazs



From matthew_wiener at merck.com  Tue Mar 22 17:36:28 2005
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Tue, 22 Mar 2005 11:36:28 -0500
Subject: [R] Convert timeseries to transition matrix
Message-ID: <45AAE6FD142DCB43A38C00A11FF5DF3E049941BF@uswsmx03.merck.com>

Ingmar --

Using "embed" and "table" can do it.  "Embed" creates the 

> temp1 <- sample(1:3, 500, replace = TRUE)
> temp2 <- embed(temp1, 2)
> dim(temp2)
[1] 499   2
> table(as.data.frame(temp2[, c(2,1)]))
   V2
V1  1  2  3 
  1 47 59 50
  2 68 57 52
  3 42 61 63

You need to reverse the times because embed creates rows of the form (x[t],
x[t-1]).  For higher dimensions you could use rev(1:ncol(x)).

Hope this helps,

Matt Wiener

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ingmar Visser
Sent: Tuesday, March 22, 2005 11:21 AM
To: R-help at stat.math.ethz.ch
Subject: [R] Convert timeseries to transition matrix


Hi All,
Does someone have an idea of how to cleverly convert a categorical
timeseries into a transition matrix?
Ie, I have something like:
x<- c(1,1,2,1,1,2,2,2,1,2),
And I want a matrix with counts and/or probabilities:
> tr <- matrix(c(2,3,2,2),2,2)
> tr
     [,1] [,2]
[1,]    2    2
[2,]    3    2
Meaning that there are two transitions from 1 to 1, two from 1 to 2, three
from 2 to 1 and two from 2 to 2.
Using for loops etc this is of course no problem, but I am curious whether
there is a smarter solution.
Any hints appreciated, Ingmar

-- 
Ingmar Visser
Department of Psychology, University of Amsterdam
Roetersstraat 15, room 1009
1018 WB Amsterdam
The Netherlands
http://users.fmg.uva.nl/ivisser/
tel: +31-20-5256735

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From brostaux.y at fsagx.ac.be  Tue Mar 22 17:41:36 2005
From: brostaux.y at fsagx.ac.be (Yves Brostaux)
Date: Tue, 22 Mar 2005 17:41:36 +0100
Subject: [R] Lattice : factor levels in the margins
In-Reply-To: <200503220919.00751.deepayan@stat.wisc.edu>
References: <4240316C.1050201@fsagx.ac.be>
	<200503220919.00751.deepayan@stat.wisc.edu>
Message-ID: <42404AC0.9020400@fsagx.ac.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050322/cb62768f/attachment.pl

From ggrothendieck at myway.com  Tue Mar 22 17:35:33 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 22 Mar 2005 16:35:33 +0000 (UTC)
Subject: [R] Convert timeseries to transition matrix
References: <BE65B008.2603%i.visser@uva.nl>
Message-ID: <loom.20050322T173230-29@post.gmane.org>

Ingmar Visser <i.visser <at> uva.nl> writes:

: 
: Hi All,
: Does someone have an idea of how to cleverly convert a categorical
: timeseries into a transition matrix?
: Ie, I have something like:
: x<- c(1,1,2,1,1,2,2,2,1,2),
: And I want a matrix with counts and/or probabilities:
: > tr <- matrix(c(2,3,2,2),2,2)
: > tr
:      [,1] [,2]
: [1,]    2    2
: [2,]    3    2
: Meaning that there are two transitions from 1 to 1, two from 1 to 2, three
: from 2 to 1 and two from 2 to 2.
: Using for loops etc this is of course no problem, but I am curious whether
: there is a smarter solution.
: Any hints appreciated, Ingmar
: 


Try this:

table(from = x[-length(x)], to = x[-1])

It gives the transpose of tr in your example since there are actually
three transitions from 1 to 2, not three transitions from 2 to 1.



From christos at nuverabio.com  Tue Mar 22 17:40:28 2005
From: christos at nuverabio.com (Christos Hatzis)
Date: Tue, 22 Mar 2005 11:40:28 -0500
Subject: [R] Convert timeseries to transition matrix
In-Reply-To: <BE65B008.2603%i.visser@uva.nl>
Message-ID: <200503221642.j2MGgc102905@drac.host4u.net>

Here is a way to do this:

x <- c(1,1,2,1,1,2,2,2,1,2)
y <- cbind(x,c(x[-1],NA)) # time-shifted by one
aggregate(y, by=list(y[,1],y[,2]), length) 

-Christos Hatzis

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ingmar Visser
Sent: Tuesday, March 22, 2005 11:21 AM
To: R-help at stat.math.ethz.ch
Subject: [R] Convert timeseries to transition matrix

Hi All,
Does someone have an idea of how to cleverly convert a categorical
timeseries into a transition matrix?
Ie, I have something like:
x<- c(1,1,2,1,1,2,2,2,1,2),
And I want a matrix with counts and/or probabilities:
> tr <- matrix(c(2,3,2,2),2,2)
> tr
     [,1] [,2]
[1,]    2    2
[2,]    3    2
Meaning that there are two transitions from 1 to 1, two from 1 to 2, three
from 2 to 1 and two from 2 to 2.
Using for loops etc this is of course no problem, but I am curious whether
there is a smarter solution.
Any hints appreciated, Ingmar

--
Ingmar Visser
Department of Psychology, University of Amsterdam Roetersstraat 15, room
1009
1018 WB Amsterdam
The Netherlands
http://users.fmg.uva.nl/ivisser/
tel: +31-20-5256735

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From i.visser at uva.nl  Tue Mar 22 17:51:36 2005
From: i.visser at uva.nl (Ingmar Visser)
Date: Tue, 22 Mar 2005 11:51:36 -0500
Subject: [R] Convert timeseries to transition matrix
In-Reply-To: <200503221642.j2MGgc102905@drac.host4u.net>
Message-ID: <BE65B748.260F%i.visser@uva.nl>

Thanks to everyone for your quick and helpful answers!
ingmar


On 3/22/05 11:40 AM, "Christos Hatzis" <christos at nuverabio.com> wrote:

> Here is a way to do this:
> 
> x <- c(1,1,2,1,1,2,2,2,1,2)
> y <- cbind(x,c(x[-1],NA)) # time-shifted by one
> aggregate(y, by=list(y[,1],y[,2]), length)
> 
> -Christos Hatzis
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ingmar Visser
> Sent: Tuesday, March 22, 2005 11:21 AM
> To: R-help at stat.math.ethz.ch
> Subject: [R] Convert timeseries to transition matrix
> 
> Hi All,
> Does someone have an idea of how to cleverly convert a categorical
> timeseries into a transition matrix?
> Ie, I have something like:
> x<- c(1,1,2,1,1,2,2,2,1,2),
> And I want a matrix with counts and/or probabilities:
>> tr <- matrix(c(2,3,2,2),2,2)
>> tr
>      [,1] [,2]
> [1,]    2    2
> [2,]    3    2
> Meaning that there are two transitions from 1 to 1, two from 1 to 2, three
> from 2 to 1 and two from 2 to 2.
> Using for loops etc this is of course no problem, but I am curious whether
> there is a smarter solution.
> Any hints appreciated, Ingmar
> 
> --
> Ingmar Visser
> Department of Psychology, University of Amsterdam Roetersstraat 15, room
> 1009
> 1018 WB Amsterdam
> The Netherlands
> http://users.fmg.uva.nl/ivisser/
> tel: +31-20-5256735
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> 

-- 
Ingmar Visser
Department of Psychology, University of Amsterdam
Roetersstraat 15, 1018 WB Amsterdam
The Netherlands
http://users.fmg.uva.nl/ivisser/
tel: +31-20-5256735



From deepayan at stat.wisc.edu  Tue Mar 22 18:01:02 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 22 Mar 2005 11:01:02 -0600
Subject: [R] Question with lattice xyplot
In-Reply-To: <2B47B68F97330841AC8C670749084A7D06C43B@wdexchmb01.lexicon.lexgen.com>
References: <2B47B68F97330841AC8C670749084A7D06C43B@wdexchmb01.lexicon.lexgen.com>
Message-ID: <200503221101.02539.deepayan@stat.wisc.edu>

On Tuesday 22 March 2005 10:26, Ghosh, Sandeep wrote:
> Hi All,
>
> I have a quick question and any help is greatly appreciated. For the
> following data when I try to produce the image using xyplot function
> in lattice package, the key has 4 rows instead of 2. Can anyone tell
> me what I'm doing wrong and what is the way to fix the problem. Here
> the code that I'm running

Your key is not formatted correctly. In particular, the first component 
of key$points is (1) not named and (2) itself a list of length 4. Since 
it's not named, it's not contributing anything to the key itself, but 
the length of 4 confuses draw.key into thinking that the points 
component should have 4 rows.

Deepayan

> print(xyplot(foldChange ~ timeInterval, data=studyData, type='b',
> groups = treatment, pch=1:treatmentCount,
> key = list(points = list(Rows(trellis.par.get("superpose.line"), 
> c(1:treatmentCount)), col=Rows(trellis.par.get("superpose.line"), 
> c(1:treatmentCount))$col, pch = 1:treatmentCount, type='b'), cex =
> trellis.par.get("superpose.symbol")$cex[1:treatmentCount], text =
> list(lab = as.character(unique(studyData$treatment))), columns = 1,
>     border=TRUE,
>     space="top"),
> ylab="Relative Change(1=12.50%tile)",
> xlab="Time Interval (hour)"));
>
> Thanks,
> Sandeep.



From Jan.Verbesselt at biw.kuleuven.be  Tue Mar 22 18:20:24 2005
From: Jan.Verbesselt at biw.kuleuven.be (Jan Verbesselt)
Date: Tue, 22 Mar 2005 18:20:24 +0100
Subject: [R] Confidence interval for Tau-a or c-index to compare logistic
	lrm (binary) models with each other.
Message-ID: <001d01c52f03$6f3bbb00$1145210a@agr.ad10.intern.kuleuven.ac.be>

Dear R list,

How can confidence interval be derived for e.g. the Tau-a coefficient or the
c index (area under ROC curve) such that I can compare the fitted lrm
(logistic) models with each other. Is this possible?

The aim is to conclude that one model is significantly better than other
model (a, b or c). 

y~a (continu)+ d(catergoric)
y~b (continu)+ d(catergoric)
y~c (continu)+ d(catergoric)

I will look at residual deviance, the AIC, c-index en Tau-a to compare
different logistic models (lrm Design package).  All extra advice is mostly
welcome!

Regards,
Jan

_______________________________________________________________________
ir. Jan Verbesselt 
Research Associate 
Lab of Geomatics Engineering K.U. Leuven
Vital Decosterstraat 102. B-3000 Leuven Belgium 
Tel: +32-16-329750   Fax: +32-16-329760
http://gloveg.kuleuven.ac.be/



From jeroschh at ohsu.edu  Tue Mar 22 18:20:08 2005
From: jeroschh at ohsu.edu (Michael Jerosch-Herold)
Date: Tue, 22 Mar 2005 09:20:08 -0800
Subject: [R] LME correlation structures: user defined
Message-ID: <s23fe350.047@ohsu.edu>


Let me modify my question about user-defined covariance structures for LME models: Can somebody tell me how I can see the code for the definition of the correlation structures that come with the NLME package. Specifically I like to see the code for the functions coef, corMatrix, and intialize for any of the pre-defined correlation structures, and use this as a template to define a new correlation structure. So how do I see e.g. the code for the method initialize for the correlation structure corExp or corARMA?

thank you in advance!

Michael Jerosch-Herold

PS: Oh, and if somebody could still send me example code for a user defined correlation structure I would much appreciate it, as my previous requests for help have not yielded any response.



From GPetris at uark.edu  Tue Mar 22 18:23:36 2005
From: GPetris at uark.edu (Giovanni Petris)
Date: Tue, 22 Mar 2005 11:23:36 -0600 (CST)
Subject: [R] Package vignette and build
Message-ID: <200503221723.j2MHNahB003520@definetti.uark.edu>


Hello,

I am writing a package called 'DLM' containing a vignette. 
The vignette contains a chunck with the function call 'library(DLM)'. 
This worked fine with 'R CMD check DLM', but when it comes to building
the package with 'R CMD build DLM' I get the following error message:

* creating vignettes ... ERROR

Error:  chunk 1 
Error in library(DLM) : There is no package called 'DLM'
Error in buildVignettes(dir = ".") : Error:  chunk 1 
Error in library(DLM) : There is no package called 'DLM'
Execution halted

It looks to me as if I should have the package already installed
before building it...  I have read the article by F. Leisch on package
vignettes in R News 3/2 and looked at the source for 'strucchange',
but I can't figure out what I am doing wrong.

Any suggestions you can provide are more than welcome!

Thank you in advance,
Giovanni

> version
         _                   
platform sparc-sun-solaris2.8
arch     sparc               
os       solaris2.8          
system   sparc, solaris2.8   
status                       
major    2                   
minor    0.1                 
year     2004                
month    11                  
day      15                  
language R                   

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]



From j.van_den_hoff at fz-rossendorf.de  Tue Mar 22 19:09:43 2005
From: j.van_den_hoff at fz-rossendorf.de (joerg van den hoff)
Date: Tue, 22 Mar 2005 19:09:43 +0100
Subject: [R] OS X proxy question
In-Reply-To: <6a2c704c050322083142a91274@mail.gmail.com>
References: <6a2c704c050322083142a91274@mail.gmail.com>
Message-ID: <42405F67.8070503@fz-rossendorf.de>

Drew Balazs wrote:
> All,
> 
> I'm currently using R 2.0.1 on a Powerbook G4 with OS X 10.3.8. So far
> the only way I've found to set my proxy is by doing 
> Sys.putenv("http_proxy"="<insert proxy url>:<proxy port>)  everytime I
> start up R.
> 
> This works fine, but I'd like to find a solution that doesnt require
> manual input everytime I start up R. Does any one have a better way of
> accomplishing this?
> 
> 
> Thanks,
> 
> Drew Balazs
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

if I understand your  problem, you need a way to get some environment 
variables right which usually are set in .profile or .cshrc.

to this  end you need a directory `.MacOSX' in your home dir and there a 
file `environment.plist'. this can best be edited with the uitility 
`Property Editor' which is in `/Developer/Applications/Utilities'.

see also http://developer.apple.com/qa/qa2001/qa1067.html

hope this helps


joerg



From ripley at stats.ox.ac.uk  Tue Mar 22 19:27:07 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 22 Mar 2005 18:27:07 +0000 (GMT)
Subject: [R] r under linux: creating high quality bmp's for win users
In-Reply-To: <008801c52eec$39d754e0$0201a8c0@shelbyhome>
References: <008801c52eec$39d754e0$0201a8c0@shelbyhome>
Message-ID: <Pine.LNX.4.61.0503221824470.30346@gannet.stats>

On Tue, 22 Mar 2005, Shelby wrote:

> I have also recently come across a conversion program that works with
> ghostscript to convert ps and pdf images into other vector formats,
> including .wmf and .emf for M$ software: http://www.pstoedit.net/.  This

AFAIK, it converts to those formats only under Windows.  If you are going 
to allow running quite complex applications under Windows, consider 
running R under Windows!

> might be helpful if your colleagues do not have, as Dr. Ripley
> indicated, a postscript printer (if they do have a PS printer then the
> regular .eps files produced by ghostscript should work fine, but they
> will not be rendered at proper resolution on the screen preview while
> they are working on the document).
>
> Note: I have not given this program a thorough workout in comparison to
> imagemagick or anything else - just enough to see that it does what it
> says it does.
>
> ===============================
> Shelby L. Berkowitz
> Ecological-Community Psychology
> and Institute for Health Care Studies
> Michigan State University
> berkowi4 at msu.edu
>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Prof
>> Brian Ripley
>> Sent: Tuesday, March 22, 2005 6:46 AM
>> To: Christoph Lehmann
>> Cc: r-help at stat.math.ethz.ch
>> Subject: Re: [R] r under linux: creating high quality bmp's
>> for win users
>>
>>
>> On Tue, 22 Mar 2005, Christoph Lehmann wrote:
>>
>>> Hi
>>>
>>> I produce graphics with R under linux, but my collaborators
>> often use
>>> windows
>>> and cannot import eps pics e.g. in msword
>>
>> Are they sure?  One can import eps images into Word, but you
>> need to print
>> them on a postscript printer.
>>
>>> what is the standard way to get e.g. bmp's with the same quality as
>>> eps.
>>> going the way: creating eps, convert eps2bmp using 'convert'
>> doesn't yield
>>> good enough bmp's
>>
>> The bitmap() device might do better, although both are really using gs.
>>
>> I would use png() and convert to bmp with ImageMagick's convert or
>> otherwise.
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read
>> the posting guide! http://www.R-project.org/posting-guide.html
>>
>> --
>> No virus found in this incoming message.
>> Checked by AVG Anti-Virus.
>> Version: 7.0.308 / Virus Database: 266.8.0 - Release Date: 3/21/2005
>>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From f.harrell at vanderbilt.edu  Tue Mar 22 19:46:22 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Tue, 22 Mar 2005 12:46:22 -0600
Subject: [R] Confidence interval for Tau-a or c-index to compare logistic
	lrm (binary) models with each other.
In-Reply-To: <001d01c52f03$6f3bbb00$1145210a@agr.ad10.intern.kuleuven.ac.be>
References: <001d01c52f03$6f3bbb00$1145210a@agr.ad10.intern.kuleuven.ac.be>
Message-ID: <424067FE.5000307@vanderbilt.edu>

Jan Verbesselt wrote:
> Dear R list,
> 
> How can confidence interval be derived for e.g. the Tau-a coefficient or the
> c index (area under ROC curve) such that I can compare the fitted lrm
> (logistic) models with each other. Is this possible?
> 
> The aim is to conclude that one model is significantly better than other
> model (a, b or c). 
> 
> y~a (continu)+ d(catergoric)
> y~b (continu)+ d(catergoric)
> y~c (continu)+ d(catergoric)
> 
> I will look at residual deviance, the AIC, c-index en Tau-a to compare
> different logistic models (lrm Design package).  All extra advice is mostly
> welcome!
> 
> Regards,
> Jan

You can only do this if you have an independent test dataset that was 
never used in model development or coefficient estimation.  Given that, 
look at the rcorrp.cens function in Hmisc.

Frank Harrell

> 
> _______________________________________________________________________
> ir. Jan Verbesselt 
> Research Associate 
> Lab of Geomatics Engineering K.U. Leuven
> Vital Decosterstraat 102. B-3000 Leuven Belgium 
> Tel: +32-16-329750   Fax: +32-16-329760
> http://gloveg.kuleuven.ac.be/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From h_joel_allen_phd at yahoo.com  Tue Mar 22 21:52:01 2005
From: h_joel_allen_phd at yahoo.com (j a)
Date: Tue, 22 Mar 2005 12:52:01 -0800 (PST)
Subject: [R] DCOM - RODBC/RMySQL problem
Message-ID: <20050322205201.82158.qmail@web52908.mail.yahoo.com>

All,
I have a windows application in which data are written
to MySQL and R analysis initiated by a VB frontend. 
After upgrading to DCOM 1.35, the analysis has become
excruciatingly slow when processing a simple RODBC
query.  I am using DCOM 1.35 - I didn't have this
difficulty prior to upgrading.  I upgraded all other
associated software with no change in performance:
R 2.1
MySQL 4.1.10
MyODBC 3.51.11

I then installed DBI and RMySQL.  I have been working
with RMySQL using emacs.  When establishing a
connection, Rterm crashes with the error "instruction
at "0x78001d0b" referenced memory at "0x00000000" the
memory could not be read."

Is anyone familiar with these problems?  Any help is
appreciated.

R.Version()
$platform
[1] "i386-pc-mingw32"
$arch
[1] "i386"
$os
[1] "mingw32"
$system
[1] "i386, mingw32"
$status
[1] ""
$major
[1] "2"
$minor
[1] "0.1"
$year
[1] "2004"
$month
[1] "11"
$day
[1] "15"
$language
[1] "R"

Joel Allen
U.S. EPA



From drf5n at maplepark.com  Tue Mar 22 22:02:20 2005
From: drf5n at maplepark.com (David Forrest)
Date: Tue, 22 Mar 2005 15:02:20 -0600 (CST)
Subject: [R] sub('^','var',1:3) produces unexpected results
Message-ID: <Pine.LNX.4.58.0503221452570.21381@maplepark.com>

Hi,

According to help(sub), the ^ should match the zero-length string at the
beginning of a string:

sub('^','var',1:3) # "1" "2" "3"
sub('$','var',1:3) # "1var" "2var" "3var"

# This generates what I expected from the first case:
sub('^.','var',11:13)  # "var1" "var2" "var3"

Dave
-- 
 Dr. David Forrest
 drf at vims.edu                                    (804)684-7900w
 drf5n at maplepark.com                             (804)642-0662h
                                   http://maplepark.com/~drf5n/



From syu5 at utmem.edu  Tue Mar 22 23:19:42 2005
From: syu5 at utmem.edu (Senhua Yu)
Date: Tue, 22 Mar 2005 16:19:42 -0600
Subject: [R] root authorization
Message-ID: <dfc7f5dfd18f.dfd18fdfc7f5@utnet2.utmem.edu>

Hi,

I am using R 2.0.1 Mac OS X 10.3.5. I was able to authorize R to run system command as root using login and password. But, I forgot to turn this function on before installing Bioconductor, so I terminated the process of the installation. Then, I tried to authorize R to run system command as root, I failed to do that because I saw the locker was not open. I am sure my login and password are correct. How can I recover this function?

Thanks a lot,
Senhua



From jmartinez5 at verizon.net  Wed Mar 23 00:11:20 2005
From: jmartinez5 at verizon.net (Jason W. Martinez)
Date: Tue, 22 Mar 2005 15:11:20 -0800
Subject: [R] mixtures as outcome variables
Message-ID: <1111533080.4000.98.camel@wizard>

Dear R-users,

I have an outcome variable and I'm unsure about how to treat it. Any
advice?

I have spending data for each county in the state of California (N=58).
Each county has been allocated money to spend on any one of the
following four categories: A, B, C, and D.

Each county may spend the money in any way they see fit. This also means
that the county need not spend all the money that was allocated to them.
The data structure looks something like the one below:

COUNTY    A        B       C       D        Total
----------------------------------------------------
alameda  2534221  1555592 2835475  3063249  9988537
alpine   3174     8500    0        45558    55232
amador    0       0        0        0       0
....


The goal is to explain variation in spending patterns, which are
presumably the result of characteristics for each county.

I may treat the problem like a simple linear regression problem for each
category, but by definition, money spent in one category will take away
the amount of money that can be spent in any other category---and each
county is not allocated the same amount of money to spend.

I have constructed proportions of amount spent on each category and have
conducted quasibinomial regression, on each dependent outcome but that
does not seem very convincing to me. 

Would anyone have any advice about how to treat an outcome variable of
this sort?

Thanks for any hints!

Jason





-- 
Jason W. Martinez, Gradaute Student
University of California, Riverside
Department of Sociology
E-mail: jmartinez5 at verizon.net



From mvida at mitre.org  Wed Mar 23 00:14:09 2005
From: mvida at mitre.org (Melanie Vida)
Date: Tue, 22 Mar 2005 18:14:09 -0500
Subject: [R] Error: Can not handle categorical predictors with more than 32
	categories.
Message-ID: <4240A6C1.9080106@mitre.org>

Hi All,

My question is in regards to an error generated when using randomForest 
in R. Is there a special way to format the data in order to avoid this 
error, or am I completely confused on what the error implies?

"Error in randomForest.default(m, y, ...) :
        Can not handle categorical predictors with more than 32 categories."

This is generated from the command line:
 > credit.rf <- randomForest(V16 ~ ., data=credit, mtry=2, importance = 
TRUE, do.trace=100)

The data set is the credit-screening data from the UCI respository, 
ftp://ftp.ics.uci.edu/pub/machine-learning-databases/credit-screening/crx.data. 
This data consists of  690 samples and 16 attributes.
The attribute information includes:

A1:	b, a.
    A2:	continuous.
    A3:	continuous.
    A4:	u, y, l, t.
    A5:	g, p, gg.
    A6:	c, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.
    A7:	v, h, bb, j, n, z, dd, ff, o.
    A8:	continuous.
    A9:	t, f.
    A10:	t, f.
    A11:	continuous.
    A12:	t, f.
    A13:	g, p, s.
    A14:	continuous.
    A15:	continuous.
    A16: +,-         (class attribute)

Has anyone tried randomForests in R on the credit-screening data set 
from the UCI repository?

Thanks in advance for any useful hints and tips,

Melanie



From dm60062003 at yahoo.com  Wed Mar 23 00:26:09 2005
From: dm60062003 at yahoo.com (Derek Margetts)
Date: Tue, 22 Mar 2005 15:26:09 -0800 (PST)
Subject: [R] Installation Error
Message-ID: <20050322232609.70238.qmail@web53208.mail.yahoo.com>

When trying to install an older version of R on a
windows XP system and recieved the following error.

R for windows GUI front end

App Rgui.exe
App version 1.6.1.21101.0
Mod MSUCET.dll
mod version 7.02600.1106
offset 0003213b

I do not know what this means.  Please help.



From Simon.Blomberg at anu.edu.au  Wed Mar 23 00:56:46 2005
From: Simon.Blomberg at anu.edu.au (Simon Blomberg)
Date: Wed, 23 Mar 2005 10:56:46 +1100
Subject: [R] LME correlation structures: user defined
In-Reply-To: <s23fe350.047@ohsu.edu>
References: <s23fe350.047@ohsu.edu>
Message-ID: <a06110401be665f5792dd@[150.203.51.113]>

>Let me modify my question about user-defined covariance structures 
>for LME models: Can somebody tell me how I can see the code for the 
>definition of the correlation structures that come with the NLME 
>package. Specifically I like to see the code for the functions coef, 
>corMatrix, and intialize for any of the pre-defined correlation 
>structures, and use this as a template to define a new correlation 
>structure. So how do I see e.g. the code for the method initialize 
>for the correlation structure corExp or corARMA?

I'm interested in this too. Go to CRAN and download the source code 
for the nlme package. ungzip and untar it. Got to the R subdirectory. 
Inside that is a file called corStruct.R with all the method 
definitions for the built-in corStruct classes. Reading those should 
help.

Cheers,

Simon.


>
>thank you in advance!
>
>Michael Jerosch-Herold
>
>PS: Oh, and if somebody could still send me example code for a user 
>defined correlation structure I would much appreciate it, as my 
>previous requests for help have not yielded any response.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Simon Blomberg, B.Sc.(Hons.), Ph.D, M.App.Stat.
Visiting Fellow
School of Botany & Zoology
The Australian National University
Canberra ACT 0200
Australia

T: +61 2 6125 8057  email: Simon.Blomberg at anu.edu.au
F: +61 2 6125 5573

CRICOS Provider # 00120C



From zhliur at yahoo.com  Wed Mar 23 01:23:45 2005
From: zhliur at yahoo.com (yyan liu)
Date: Tue, 22 Mar 2005 16:23:45 -0800 (PST)
Subject: [R] Confirmatory Factor Analysis in Non-Normal case
Message-ID: <20050323002345.58838.qmail@web53103.mail.yahoo.com>

Hi:
  I am doing a confirmatory factor analysis now. In
the analysis, I have null hypothesis test which
specify some special structure for the loading matrix.
And the alternative is there is no such special
structure. Then the log likelihood ratio test can be
used. The problem I have is my data comes from a
questionnaire and all the variables are discrete from
1 to 7, which makes the normality assumption a
problem. I wonder if there is any other test can do
this job or at least I can make some sensible
transformation to make the variables "normal"?
  Thank you very much!

liu



From andy_liaw at merck.com  Wed Mar 23 01:25:51 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 22 Mar 2005 19:25:51 -0500
Subject: [R] Error: Can not handle categorical predictors with more
	th an 32 categories.
Message-ID: <3A822319EB35174CA3714066D590DCD50994E8CD@usrymx25.merck.com>

It always helps to check whether you got the data into R correctly.  Hint:
What does str(credit) tell you?

Andy

> From: Melanie Vida
> 
> Hi All,
> 
> My question is in regards to an error generated when using 
> randomForest 
> in R. Is there a special way to format the data in order to 
> avoid this 
> error, or am I completely confused on what the error implies?
> 
> "Error in randomForest.default(m, y, ...) :
>         Can not handle categorical predictors with more than 
> 32 categories."
> 
> This is generated from the command line:
>  > credit.rf <- randomForest(V16 ~ ., data=credit, mtry=2, 
> importance = 
> TRUE, do.trace=100)
> 
> The data set is the credit-screening data from the UCI respository, 
> ftp://ftp.ics.uci.edu/pub/machine-learning-databases/credit-sc
reening/crx.data. 
This data consists of  690 samples and 16 attributes.
The attribute information includes:

A1:	b, a.
    A2:	continuous.
    A3:	continuous.
    A4:	u, y, l, t.
    A5:	g, p, gg.
    A6:	c, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.
    A7:	v, h, bb, j, n, z, dd, ff, o.
    A8:	continuous.
    A9:	t, f.
    A10:	t, f.
    A11:	continuous.
    A12:	t, f.
    A13:	g, p, s.
    A14:	continuous.
    A15:	continuous.
    A16: +,-         (class attribute)

Has anyone tried randomForests in R on the credit-screening data set 
from the UCI repository?

Thanks in advance for any useful hints and tips,

Melanie

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From jfox at mcmaster.ca  Wed Mar 23 02:27:25 2005
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 22 Mar 2005 20:27:25 -0500
Subject: [R] Confirmatory Factor Analysis in Non-Normal case
In-Reply-To: <20050323002345.58838.qmail@web53103.mail.yahoo.com>
Message-ID: <20050323012723.WZIJ1836.tomts16-srv.bellnexxia.net@JohnDesktop8300>

Dear Liu,

I'm not aware of any way of doing what you want in R at present. You can
base the analysis on polychoric correlations, which can be computed using
the polycor package, and you can get consistent estimates of the factor
loadings and factor correlations from the sem packages, but the likelihood
won't be right. 

I hope that this is of some help,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of yyan liu
> Sent: Tuesday, March 22, 2005 7:24 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Confirmatory Factor Analysis in Non-Normal case
> 
> Hi:
>   I am doing a confirmatory factor analysis now. In the 
> analysis, I have null hypothesis test which specify some 
> special structure for the loading matrix.
> And the alternative is there is no such special structure. 
> Then the log likelihood ratio test can be used. The problem I 
> have is my data comes from a questionnaire and all the 
> variables are discrete from
> 1 to 7, which makes the normality assumption a problem. I 
> wonder if there is any other test can do this job or at least 
> I can make some sensible transformation to make the variables 
> "normal"?
>   Thank you very much!
> 
> liu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From yzhang4 at turing.une.edu.au  Wed Mar 23 06:12:52 2005
From: yzhang4 at turing.une.edu.au (Yuandan Zhang)
Date: Wed, 23 Mar 2005 16:12:52 +1100
Subject: [R] Tool for update
Message-ID: <1111554772.6580.1.camel@zhangqiang>

Hi,

Is there any tool to check if there is update version of a package
available? I look for things alike YUM for linux?

YD



From sluque at mun.ca  Wed Mar 23 07:10:37 2005
From: sluque at mun.ca (Sebastian Luque)
Date: Wed, 23 Mar 2005 00:10:37 -0600
Subject: [R] alternative to 'groups' for lattice bwplot()
Message-ID: <87psxqdh9e.fsf@mun.ca>

Hi,

Is there some alternative to the 'groups' argument in lattice's bwplot
function for boxplots? Say in the example below:

bwplot(yield ~ site | year, data = barley)

you want to have two side by side boxplots per site, corresponding to each
year in the barley data frame. Ideally, the space between boxplots of the
same site should be smaller than that between boxplots of different sites.

This seemed like a job for the 'groups' argument, but panel.bwplot doesn't
take it. I saw that boxplot() might do this for the particular example
above, but not for a more complex one with additional conditioning
variables (as in my actual problem).

I thought I'd find something about this in the archives, but I'm either
not using the right keywords or the question hasn't come up yet.

Some help on how to deal with this please?

-- 
Sebastian P. Luque



From Tom.Mulholland at dpi.wa.gov.au  Wed Mar 23 07:02:46 2005
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Wed, 23 Mar 2005 14:02:46 +0800
Subject: [R] Tool for update
Message-ID: <33F91FB3FDF42E4180428AC66A5CF30B02D3BAA6@afhex01.dpi.wa.gov.au>

Are you talking about something other than 'update.packages'?

as the help notes 

Description:

     These functions can be used to automatically compare the version
     numbers of installed packages with the newest available version on
     CRAN and update outdated packages on the fly.

> -----Original Message-----
> From: Yuandan Zhang [mailto:yzhang4 at turing.une.edu.au]
> Sent: Wednesday, 23 March 2005 1:13 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Tool for update
> 
> 
> Hi,
> 
> Is there any tool to check if there is update version of a package
> available? I look for things alike YUM for linux?
> 
> YD
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From Satadru.Sarkar at infineon.com  Wed Mar 23 07:32:24 2005
From: Satadru.Sarkar at infineon.com (Satadru.Sarkar@infineon.com)
Date: Wed, 23 Mar 2005 12:02:24 +0530
Subject: [R] Problem encounter during graphics device driver
Message-ID: <D99246B510C34944823191CB90759C860593F9@blrse201.ap.infineon.com>


Hello

I am facing the following problem using the R-version 1.9.1

The PDF or PS none of these device drivers are opening while I am using
R-1.9.1, the following error message is coming

Error in PS(file, old$paper, old$family, old$encoding, old$bg, old$fg,
: 
	unable to start device PostScript
In addition: Warning message: 
problem loading encoding file 
Execution halted

But while I am using the R-1.9.0, no error message is coming.

Though I have installed all the required packages.

Please suggest any workaround.

With regards

Satadru

Disclaimer*
"This e-mail and any attachments are confidential and may contain trade
secrets or privileged or undisclosed information. They may also be
subject to copyright protection. Please do not copy, distribute or
forward this email to anyone unless authorised. If you are not a named
addressee, you must not use, disclose, retain or reproduce all or any
part of the information contained in this e-mail or any attachments. If
you have received this email by mistake please notify the sender
immediately by return email and destroy/delete all copies of the email."



From Tom.Mulholland at dpi.wa.gov.au  Wed Mar 23 07:39:58 2005
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Wed, 23 Mar 2005 14:39:58 +0800
Subject: [R] alternative to 'groups' for lattice bwplot()
Message-ID: <33F91FB3FDF42E4180428AC66A5CF30B02D3BAA7@afhex01.dpi.wa.gov.au>

I'm afraid you have lost me. What is it that you want that reordering the formula does not achieve.

bwplot(yield ~ year | site, data = barley) has sites next to each other. If the lattice structure is your issue (it appears you wish to remove the structure and replace it with a wider space) then I guess you might find writing your own code easier than forcing lattice to be something other than itself.

> -----Original Message-----
> From: Sebastian Luque [mailto:sluque at mun.ca]
> Sent: Wednesday, 23 March 2005 2:11 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] alternative to 'groups' for lattice bwplot()
> 
> 
> Hi,
> 
> Is there some alternative to the 'groups' argument in lattice's bwplot
> function for boxplots? Say in the example below:
> 
> bwplot(yield ~ site | year, data = barley)
> 
> you want to have two side by side boxplots per site, 
> corresponding to each
> year in the barley data frame. Ideally, the space between 
> boxplots of the
> same site should be smaller than that between boxplots of 
> different sites.
> 
> This seemed like a job for the 'groups' argument, but 
> panel.bwplot doesn't
> take it. I saw that boxplot() might do this for the particular example
> above, but not for a more complex one with additional conditioning
> variables (as in my actual problem).
> 
> I thought I'd find something about this in the archives, but 
> I'm either
> not using the right keywords or the question hasn't come up yet.
> 
> Some help on how to deal with this please?
> 
> -- 
> Sebastian P. Luque
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From Tom.Mulholland at dpi.wa.gov.au  Wed Mar 23 07:48:17 2005
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Wed, 23 Mar 2005 14:48:17 +0800
Subject: [R] Problem encounter during graphics device driver
Message-ID: <33F91FB3FDF42E4180428AC66A5CF30B02D3BAA8@afhex01.dpi.wa.gov.au>

Do you have a really good reason to be using 1.9.1. If not then just keep using 1.9.0. Did you check what changes were made in the 1.9 upgrade. Often you will find useful information about this type of issue in the change log.

You have not told us anything about the machine you are using and this is important information when it comes to devices.

I think you may be better off upgrading, I think 2.1 is due out shortly.

Tom

> -----Original Message-----
> From: Satadru.Sarkar at infineon.com [mailto:Satadru.Sarkar at infineon.com]
> Sent: Wednesday, 23 March 2005 2:32 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Problem encounter during graphics device driver
> 
> 
> 
> Hello
> 
> I am facing the following problem using the R-version 1.9.1
> 
> The PDF or PS none of these device drivers are opening while 
> I am using
> R-1.9.1, the following error message is coming
> 
> Error in PS(file, old$paper, old$family, old$encoding, old$bg, old$fg,
> : 
> 	unable to start device PostScript
> In addition: Warning message: 
> problem loading encoding file 
> Execution halted
> 
> But while I am using the R-1.9.0, no error message is coming.
> 
> Though I have installed all the required packages.
> 
> Please suggest any workaround.
> 
> With regards
> 
> Satadru
> 
> Disclaimer*
> "This e-mail and any attachments are confidential and may 
> contain trade
> secrets or privileged or undisclosed information. They may also be
> subject to copyright protection. Please do not copy, distribute or
> forward this email to anyone unless authorised. If you are not a named
> addressee, you must not use, disclose, retain or reproduce all or any
> part of the information contained in this e-mail or any 
> attachments. If
> you have received this email by mistake please notify the sender
> immediately by return email and destroy/delete all copies of 
> the email."
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Wed Mar 23 08:26:20 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 23 Mar 2005 08:26:20 +0100
Subject: [R] root authorization
In-Reply-To: <dfc7f5dfd18f.dfd18fdfc7f5@utnet2.utmem.edu>
References: <dfc7f5dfd18f.dfd18fdfc7f5@utnet2.utmem.edu>
Message-ID: <42411A1C.8050904@statistik.uni-dortmund.de>

Senhua Yu wrote:

> Hi,
> 
> I am using R 2.0.1 Mac OS X 10.3.5. I was able to authorize R to run system command as root using login and password. But, I forgot to turn this function on before installing Bioconductor, so I terminated the process of the installation. Then, I tried to authorize R to run system command as root, I failed to do that because I saw the locker was not open. I am sure my login and password are correct. How can I recover this function?


I guess there is a 00lock directory in your library now (because of 
terminating incorrctly before). Simply remove that directory manually.

Uwe Ligges



> Thanks a lot,
> Senhua
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Wed Mar 23 08:32:25 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 23 Mar 2005 08:32:25 +0100
Subject: [R] Error: Can not handle categorical predictors with more than
	32	categories.
In-Reply-To: <4240A6C1.9080106@mitre.org>
References: <4240A6C1.9080106@mitre.org>
Message-ID: <42411B89.6000603@statistik.uni-dortmund.de>

Melanie Vida wrote:

> Hi All,
> 
> My question is in regards to an error generated when using randomForest 
> in R. Is there a special way to format the data in order to avoid this 
> error, or am I completely confused on what the error implies?
> 
> "Error in randomForest.default(m, y, ...) :
>        Can not handle categorical predictors with more than 32 categories."
> 
> This is generated from the command line:
>  > credit.rf <- randomForest(V16 ~ ., data=credit, mtry=2, importance = 
> TRUE, do.trace=100)
> 
> The data set is the credit-screening data from the UCI respository, 
> ftp://ftp.ics.uci.edu/pub/machine-learning-databases/credit-screening/crx.data. 
> This data consists of  690 samples and 16 attributes.
> The attribute information includes:
> 
> A1:    b, a.
>    A2:    continuous.
>    A3:    continuous.
>    A4:    u, y, l, t.
>    A5:    g, p, gg.
>    A6:    c, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.
>    A7:    v, h, bb, j, n, z, dd, ff, o.
>    A8:    continuous.
>    A9:    t, f.
>    A10:    t, f.
>    A11:    continuous.
>    A12:    t, f.
>    A13:    g, p, s.
>    A14:    continuous.
>    A15:    continuous.
>    A16: +,-         (class attribute)
>
> Has anyone tried randomForests in R on the credit-screening data set 
> from the UCI repository?


For sure you forgot to set  na.strings = "?"  in read.table()....
Look at str(credit) to see that some numerics had been converted to 
factors for that reason.

Uwe Ligges



> Thanks in advance for any useful hints and tips,
> 
> Melanie
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Wed Mar 23 08:36:06 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 23 Mar 2005 08:36:06 +0100
Subject: [R] Installation Error
In-Reply-To: <20050322232609.70238.qmail@web53208.mail.yahoo.com>
References: <20050322232609.70238.qmail@web53208.mail.yahoo.com>
Message-ID: <42411C66.5040703@statistik.uni-dortmund.de>

Derek Margetts wrote:

> When trying to install an older version of R on a
> windows XP system and recieved the following error.
> 
> R for windows GUI front end
> 
> App Rgui.exe
> App version 1.6.1.21101.0
> Mod MSUCET.dll
> mod version 7.02600.1106
> offset 0003213b
> 
> I do not know what this means.  Please help.


R has crashed.

Since we cannot fix outdated versions of R, do not know what you did to 
produce this error (did it appear during installation???) and we cannot 
fix Windows (with unknown ServicePack level) either:

PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html

Uwe Ligges



> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From pallier at lscp.ehess.fr  Wed Mar 23 08:40:31 2005
From: pallier at lscp.ehess.fr (Christophe Pallier)
Date: Wed, 23 Mar 2005 08:40:31 +0100
Subject: [R] r under linux: creating high quality bmp's for win users
In-Reply-To: <loom.20050322T160943-549@post.gmane.org>
References: <423FFA8D.3000907@gmx.ch> <4240287D.9040804@lscp.ehess.fr>
	<loom.20050322T160943-549@post.gmane.org>
Message-ID: <42411D6F.6000903@lscp.ehess.fr>

Oops, sorry: I spread a false information in my previous post.

I used, years ago, wmf2eps to convert metafiles -> eps, and not the 
other way round.

Apologies to people who have searched for eps2wmf !

The only utility that I have sometimes used to convert from eps to a 
vector format (xfig) is pstoedit.

Christophe Pallier

Gabor Grothendieck a ?crit :

>Can you provide a link.  I did a google search and found something
>on a Japanese site but it turned out that the writer had made a 
>mistake and it linked to wmf2eps, not eps2wmf.
>
>Christophe Pallier <pallier <at> lscp.ehess.fr> writes:
>
>: 
>: Hello Christoph!
>: 
>: In the past, I used an utility called "eps2wmf".
>: It only works under Windows though (maybe under Linux with wine?).
>: I believe it is available on the CTAN (Tex archives).
>: 
>: The nice thing is that wmf files are not bitmap and scale well.
>: 
>: Christophe Pallier
>: 
>: Christoph Lehmann wrote:
>: 
>: > Hi
>: >
>: > I produce graphics with R under linux, but my collaborators often use 
>: > windows and cannot import eps pics e.g. in msword
>: >
>: > what is the standard way to get e.g. bmp's with the same quality as 
>: > eps.  going the way: creating eps, convert eps2bmp using 'convert' 
>: > doesn't yield good enough bmp's
>: >
>: > thanks for a short hint
>: >
>: > cheers
>: > christoph
>: >
>: > ______________________________________________
>: > R-help <at> stat.math.ethz.ch mailing list
>: > https://stat.ethz.ch/mailman/listinfo/r-help
>: > PLEASE do read the posting guide! 
>: > http://www.R-project.org/posting-guide.html
>: 
>: ______________________________________________
>: R-help <at> stat.math.ethz.ch mailing list
>: https://stat.ethz.ch/mailman/listinfo/r-help
>: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>: 
>:
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From maechler at stat.math.ethz.ch  Wed Mar 23 08:55:38 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 23 Mar 2005 08:55:38 +0100
Subject: [R] sub('^', .....) bugs
In-Reply-To: <Pine.LNX.4.58.0503221452570.21381@maplepark.com>
References: <Pine.LNX.4.58.0503221452570.21381@maplepark.com>
Message-ID: <16961.8442.934183.882100@stat.math.ethz.ch>

>>>>> "David" == David Forrest <drf5n at maplepark.com>
>>>>>     on Tue, 22 Mar 2005 15:02:20 -0600 (CST) writes:

    David> According to help(sub), the ^ should match the
    David> zero-length string at the beginning of a string:

yes, indeed.

    David> sub('^','var',1:3) # "1" "2" "3"
    David> sub('$','var',1:3) # "1var" "2var" "3var"

    David> # This generates what I expected from the first case:
    David> sub('^.','var',11:13)  # "var1" "var2" "var3"

there are even more fishy things here:

1) In your cases, the integer 'x' argument is auto-coerced to
   character, however that fails as soon as  'perl = TRUE' is used.

 > sub('^','v_', 1:3, perl=TRUE)
 Error in sub.perl(pattern, replacement, x, ignore.case) : 
	 invalid argument

 {one can argue that this is not a bug, since the help file asks
  for 'x' to be a character vector; OTOH, we have
  as.character(.) magic in many other places, i.e. quite
  naturally here;  
  at least  perl=TRUE and perl=FALSE should behave consistently.}


2) The 'perl=TRUE' case behaves even more problematically here:

  > sub('^','v_', LETTERS[1:3], perl=TRUE)
  [1] "A\0e" "B\0J" "C\0S"
  > sub('^','v_', LETTERS[1:3], perl=TRUE)
  [1] "A\0J" "B\0P" "C\0J"
  > sub('^','v_', LETTERS[1:3], perl=TRUE)
  [1] "A\0\0" "B\0\0" "C\0m" 
  >

 i.e., the result is random nonsense.

Note that this happens both for R-patched (2.0.1)  and R-devel (2.1.0 alpha).

==> "forwarded" as bug report to R-bugs



From harloff at softuse.com  Wed Mar 23 09:05:19 2005
From: harloff at softuse.com (Joachim Harloff)
Date: Wed, 23 Mar 2005 09:05:19 +0100
Subject: [R] Adding a "We think R rocks" page
Message-ID: <r02010500-1038-4CA82E709B7211D9A3F9000393CAE166@[192.168.0.2]>

Hi,

there is a reference given for R. It should be used to prove its value to donators. OK, I quoted R but probably nobody will ever recognize that.
A web page where dummies and no name users like me were pointed to and could leave a short statement of use and usefulness might help in demonstrating the impact and the spread of R. (Besides download numbers). At least this was more visible than merely quoting R.

Regards, Joachim


____________________________
Soft Use
Dr. Joachim Harloff
Tel.  089 74 49 37 95
Mobil 0177 58 24 124
Fax 089 74 49 37 94
http://www.softuse.com



From antho_l at yahoo.com  Wed Mar 23 10:03:21 2005
From: antho_l at yahoo.com (Anthony Landrevie)
Date: Wed, 23 Mar 2005 01:03:21 -0800 (PST)
Subject: [R] R accuracy
Message-ID: <20050323090321.85399.qmail@web41114.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050323/abf22c7c/attachment.pl

From ligges at statistik.uni-dortmund.de  Wed Mar 23 10:11:56 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 23 Mar 2005 10:11:56 +0100
Subject: [R] R accuracy
In-Reply-To: <20050323090321.85399.qmail@web41114.mail.yahoo.com>
References: <20050323090321.85399.qmail@web41114.mail.yahoo.com>
Message-ID: <424132DC.5080609@statistik.uni-dortmund.de>

Anthony Landrevie wrote:

> Hello,
>  
> I am trying to test the precision of R on datasets from The Statistical Reference Datasets Project http://www.itl.nist.gov/div898/strd/index.html and I don't manage to understand how R is storing its results.
>  
> For example, I calculate a mean on the michelso dataset (100 values) and find:
>  
> 
>>m=mean(michel)
>>m
> 
>       V1 
> 299.8524 
> 
>>print(m,digits=15)
> 
>       V1 
> 299.8524 
> 
> 
>>print(m,digits=22)
> 
>                 V1 
> 299.85239999999993 
> 
>  
> The certified value of the mean is 299.85240, so I try
>  
>  
> 
>>print(m-299.8524)
> 
>            V1 
> -5.684342e-14 
>  
> 
>>print(m-299.8524,digits=15)
> 
>                    V1 
> -5.68434188608080e-14 
> 
> Does it have a sens to print with more than 15 signifiant digits?

Depends, e.g. you mightg want to see that the result is only 
-5.684342e-14 off, hence not identical() to, but all.equal() with what 
you expected.


> Why is the difference not equal to zero?

Floating point calculations on a digital computer are involved...

Uwe Ligges



> I am using R 2.0.1 under Windows XP.
>  
> Regards,
>  
> Anthony Landrevie 
> 
> 		
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From roy.werkman at asml.com  Wed Mar 23 10:21:34 2005
From: roy.werkman at asml.com (Roy Werkman)
Date: Wed, 23 Mar 2005 10:21:34 +0100
Subject: [R] Question on statistics
Message-ID: <448071208107374B96ED90585EEBA91256C2D2@NLVDHX84.sn-eu.asml.com>

 
Hi,

Can anyone help me with the following (although not directly correlated
to R functionality)? I have been looking on the internet but can not
find the answer.

My question: what is the variation on the mean of a limited distribution
(total N points normally distributed), when I have a small sample of
that distribution (n < N)?

Your help would be very welcome.

Thanx,
Roy


-- 
The information contained in this communication and any atta...{{dropped}}



From tom_hoary at web.de  Wed Mar 23 10:41:48 2005
From: tom_hoary at web.de (Thomas =?iso-8859-15?q?Sch=F6nhoff?=)
Date: Wed, 23 Mar 2005 10:41:48 +0100
Subject: [R] Tool for update
In-Reply-To: <1111554772.6580.1.camel@zhangqiang>
References: <1111554772.6580.1.camel@zhangqiang>
Message-ID: <200503231041.49240.tom_hoary@web.de>

Hello,

Am Mittwoch, 23. M?rz 2005 06:12 schrieb Yuandan Zhang:
> Hi,
>
> Is there any tool to check if there is update version of a package
> available? I look for things alike YUM for linux?

Start "R --no-save" on a  root console and launch "update.packages()" 
from within R-Enviroment.
Surely, this is not like YUM but does a supherb job.


Thomas



From ripley at stats.ox.ac.uk  Wed Mar 23 11:10:52 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 23 Mar 2005 10:10:52 +0000 (GMT)
Subject: [R] Problem encounter during graphics device driver
In-Reply-To: <D99246B510C34944823191CB90759C860593F9@blrse201.ap.infineon.com>
References: <D99246B510C34944823191CB90759C860593F9@blrse201.ap.infineon.com>
Message-ID: <Pine.LNX.4.61.0503231003130.31486@gannet.stats>

On Wed, 23 Mar 2005 Satadru.Sarkar at infineon.com wrote:

>
> Hello
>
> I am facing the following problem using the R-version 1.9.1
>
> The PDF or PS none of these device drivers are opening while I am using
> R-1.9.1, the following error message is coming
>
> Error in PS(file, old$paper, old$family, old$encoding, old$bg, old$fg,
> :
> 	unable to start device PostScript
> In addition: Warning message:
> problem loading encoding file
> Execution halted
>
> But while I am using the R-1.9.0, no error message is coming.
>
> Though I have installed all the required packages.
>
> Please suggest any workaround.

Use an encoding for which you do have a readable file!  The message is 
quite explicit:

> In addition: Warning message: problem loading encoding file

so it is to do with the encoding you requested.  Check what it is, that 
the file exists and that it is readable to you.  I suspect a permissions 
problem in your R installation or an incorrect setting of ps.options().

Your R is well out of date, and that message no longer exists in the R 
sources.  Please read the R posting guide, use a current R, and tell us 
your OS etc.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jan.sabee at gmail.com  Wed Mar 23 11:17:29 2005
From: jan.sabee at gmail.com (Jan Sabee)
Date: Wed, 23 Mar 2005 11:17:29 +0100
Subject: [R] more classes to one class in one dataset
Message-ID: <96507a8e05032302173578e826@mail.gmail.com>

I have a big database which more classes in class variable. I want to
make each class to one dataset, for example:
x1 x2 x3 x4  class
a  b  a  c  c    M1
c  b  b  c  c    M4
c  c  a  c  c    M2
c  a  c  a  a    M2
c  c  a  a  a    M1
c  a  b  c  a    M3
c  c  a  b  c    M3
c  a  c  a  b    M2
c  c  a  b  a    M1

How can I make, like:

x1 x2 x3 x4  class
a  b  a  c  c    M1
c  c  a  a  a    M1
c  c  a  b  a    M1

x1 x2 x3 x4  class
c  c  a  c  c    M2
c  a  c  a  a    M2
c  a  c  a  b    M2

x1 x2 x3 x4  class
c  a  b  c  a    M3
c  c  a  b  c    M3

x1 x2 x3 x4  class
c  b  b  c  c    M4

Thanks for your help.
Jan Sabee



From dimitris.rizopoulos at med.kuleuven.ac.be  Wed Mar 23 11:30:22 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Wed, 23 Mar 2005 11:30:22 +0100
Subject: [R] more classes to one class in one dataset
References: <96507a8e05032302173578e826@mail.gmail.com>
Message-ID: <017801c52f93$51cffb90$0540210a@www.domain>

try this:

split(dat, dat$class)

where 'dat' is your data.frame


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Jan Sabee" <jan.sabee at gmail.com>
To: <R-help at stat.math.ethz.ch>
Sent: Wednesday, March 23, 2005 11:17 AM
Subject: [R] more classes to one class in one dataset


>I have a big database which more classes in class variable. I want to
> make each class to one dataset, for example:
> x1 x2 x3 x4  class
> a  b  a  c  c    M1
> c  b  b  c  c    M4
> c  c  a  c  c    M2
> c  a  c  a  a    M2
> c  c  a  a  a    M1
> c  a  b  c  a    M3
> c  c  a  b  c    M3
> c  a  c  a  b    M2
> c  c  a  b  a    M1
>
> How can I make, like:
>
> x1 x2 x3 x4  class
> a  b  a  c  c    M1
> c  c  a  a  a    M1
> c  c  a  b  a    M1
>
> x1 x2 x3 x4  class
> c  c  a  c  c    M2
> c  a  c  a  a    M2
> c  a  c  a  b    M2
>
> x1 x2 x3 x4  class
> c  a  b  c  a    M3
> c  c  a  b  c    M3
>
> x1 x2 x3 x4  class
> c  b  b  c  c    M4
>
> Thanks for your help.
> Jan Sabee
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From jan.sabee at gmail.com  Wed Mar 23 11:51:49 2005
From: jan.sabee at gmail.com (Jan Sabee)
Date: Wed, 23 Mar 2005 11:51:49 +0100
Subject: [R] more classes to one class in one dataset
In-Reply-To: <017801c52f93$51cffb90$0540210a@www.domain>
References: <96507a8e05032302173578e826@mail.gmail.com>
	<017801c52f93$51cffb90$0540210a@www.domain>
Message-ID: <96507a8e0503230251720fba3c@mail.gmail.com>

Thanks. It's work.

Jan Sabee


On Wed, 23 Mar 2005 11:30:22 +0100, Dimitris Rizopoulos
<dimitris.rizopoulos at med.kuleuven.ac.be> wrote:
> try this:
> 
> split(dat, dat$class)
> 
> where 'dat' is your data.frame
> 
> I hope it helps.
> 
> Best,
> Dimitris
> 
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
> 
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/16/336899
> Fax: +32/16/337015
> Web: http://www.med.kuleuven.ac.be/biostat/
>      http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
> 
> 
> ----- Original Message -----
> From: "Jan Sabee" <jan.sabee at gmail.com>
> To: <R-help at stat.math.ethz.ch>
> Sent: Wednesday, March 23, 2005 11:17 AM
> Subject: [R] more classes to one class in one dataset
> 
> >I have a big database which more classes in class variable. I want to
> > make each class to one dataset, for example:
> > x1 x2 x3 x4  class
> > a  b  a  c  c    M1
> > c  b  b  c  c    M4
> > c  c  a  c  c    M2
> > c  a  c  a  a    M2
> > c  c  a  a  a    M1
> > c  a  b  c  a    M3
> > c  c  a  b  c    M3
> > c  a  c  a  b    M2
> > c  c  a  b  a    M1
> >
> > How can I make, like:
> >
> > x1 x2 x3 x4  class
> > a  b  a  c  c    M1
> > c  c  a  a  a    M1
> > c  c  a  b  a    M1
> >
> > x1 x2 x3 x4  class
> > c  c  a  c  c    M2
> > c  a  c  a  a    M2
> > c  a  c  a  b    M2
> >
> > x1 x2 x3 x4  class
> > c  a  b  c  a    M3
> > c  c  a  b  c    M3
> >
> > x1 x2 x3 x4  class
> > c  b  b  c  c    M4
> >
> > Thanks for your help.
> > Jan Sabee
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> 
>



From chris.desimpelaere at ugent.be  Wed Mar 23 11:58:45 2005
From: chris.desimpelaere at ugent.be (chris desimpelaere)
Date: Wed, 23 Mar 2005 11:58:45 +0100
Subject: [R] smallest/biggest number
Message-ID: <42414BE5.3090503@ugent.be>

Hi,

I'm running monte carlo and i wonder what is the biggest/smallest number 
that
can reliably be represented in R?

Thanks,
Chris



From ripley at stats.ox.ac.uk  Wed Mar 23 12:19:42 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 23 Mar 2005 11:19:42 +0000 (GMT)
Subject: [R] smallest/biggest number
In-Reply-To: <42414BE5.3090503@ugent.be>
References: <42414BE5.3090503@ugent.be>
Message-ID: <Pine.LNX.4.61.0503231115470.3105@gannet.stats>

On Wed, 23 Mar 2005, chris desimpelaere wrote:

> I'm running monte carlo and i wonder what is the biggest/smallest number that
> can reliably be represented in R?

Well, -Inf and Inf, of course.  But if you meant a finite number, see
?.Machine : the values are OS-specific.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From agostino.manzato at osmer.fvg.it  Wed Mar 23 12:24:55 2005
From: agostino.manzato at osmer.fvg.it (Agostino.Manzato@osmer.fvg.it)
Date: Wed, 23 Mar 2005 12:24:55 +0100
Subject: [R] R on SuSe 9.2 AMD 64 bit: Solved
Message-ID: <42415207.9AD4DB60@osmer.fvg.it>

Hi everybody,
I just downloaded the file R-2.0.1.tar.gz and followed
the instruction written in doc/R-admin.html.

In particular we installed for SuSe 9.2 AMD64 the following
packages: gcc, gcc++, gcc-g77, Perl, te-latex, te-pdf, libpng, 
libbz, PCRE, Tcl/Tk, BLAS, LAPACK.

After we just made:
./configure
make
make check
make install (from root)
make install-info
make install-pdf 

Now everything seems to work properly: no problem at all!
Many thanks to all of you who helped.
Ciao!



From carsten.steinhoff at gmx.de  Wed Mar 23 12:44:23 2005
From: carsten.steinhoff at gmx.de (Carsten Steinhoff)
Date: Wed, 23 Mar 2005 12:44:23 +0100
Subject: [R] Browser to replace the internal browser?
In-Reply-To: <200503221117.j2MB8Fku024247@hypatia.math.ethz.ch>
Message-ID: <200503231144.j2NBiP14016217@hypatia.math.ethz.ch>

Hello,

I see that the more I work with R and the more the code gets larger I would
like to have some graphic support in my quellcode.
Is there a browser that could be easily implemened in R?
And how do I call it from R? It would be nice if the browser replaces the
"fix()" function.

Carsten



From sdavis2 at mail.nih.gov  Wed Mar 23 13:00:00 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Wed, 23 Mar 2005 07:00:00 -0500
Subject: [R] Browser to replace the internal browser?
In-Reply-To: <200503231144.j2NBiP14016217@hypatia.math.ethz.ch>
References: <200503231144.j2NBiP14016217@hypatia.math.ethz.ch>
Message-ID: <0d26504f0ed17e54c24fc72b240e2b59@mail.nih.gov>



On Mar 23, 2005, at 6:44 AM, Carsten Steinhoff wrote:

> Hello,
>
> I see that the more I work with R and the more the code gets larger I 
> would
> like to have some graphic support in my quellcode.
> Is there a browser that could be easily implemened in R?
> And how do I call it from R? It would be nice if the browser replaces 
> the
> "fix()" function.

You may want to think about using ESS within emacs.  There are other 
options that offer similar features, but ESS is what I personally like 
and use.

Sean



From murdoch at stats.uwo.ca  Wed Mar 23 13:10:03 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 23 Mar 2005 07:10:03 -0500
Subject: [R] Browser to replace the internal browser?
In-Reply-To: <200503231144.j2NBiP14016217@hypatia.math.ethz.ch>
References: <200503221117.j2MB8Fku024247@hypatia.math.ethz.ch>
	<200503231144.j2NBiP14016217@hypatia.math.ethz.ch>
Message-ID: <p3n241hchq07nuckvabsv05c6vbi7dic9l@4ax.com>

On Wed, 23 Mar 2005 12:44:23 +0100, "Carsten Steinhoff"
<carsten.steinhoff at gmx.de> wrote :

>Hello,
>
>I see that the more I work with R and the more the code gets larger I would
>like to have some graphic support in my quellcode.
>Is there a browser that could be easily implemened in R?
>And how do I call it from R? It would be nice if the browser replaces the
>"fix()" function.

See the help for edit() to change the default editor.

Duncan Murdoch



From T.A.Wassenaar at rug.nl  Wed Mar 23 13:31:03 2005
From: T.A.Wassenaar at rug.nl (T.A.Wassenaar)
Date: Wed, 23 Mar 2005 13:31:03 +0100
Subject: [R] manova and contrasts, again
Message-ID: <web-2031283@mail3.rug.nl>


Hi R-people,

To determine contrasts after MANOVA I've found a piece of 
R-code provided by Yves Rosseel 
(http://tolstoy.newcastle.edu.au/R/help/04/06/0134.html), 
which has been very helpful. Now I Would like to determine 
contrasts for a model which has a main effect and an 
interaction effect, and in which both effects were found 
to be statistically significant. I'm a bit puzzled with 
the contrast matrix to feed the routine, especially for 
the interactions. Could anybody help me out here? If more 
information is necessary on the underlying model, pleas 
let me know.

Best regards,

Tsjerk



From roy.werkman at asml.com  Wed Mar 23 13:38:33 2005
From: roy.werkman at asml.com (Roy Werkman)
Date: Wed, 23 Mar 2005 13:38:33 +0100
Subject: [R] Question on statistics
Message-ID: <448071208107374B96ED90585EEBA91256C37C@NLVDHX84.sn-eu.asml.com>


Ehh, by limited distribution, I meant to say a population of N points.

...

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Roy Werkman
Sent: Wednesday, March 23, 2005 10:22 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Question on statistics

 
Hi,

Can anyone help me with the following (although not directly correlated
to R functionality)? I have been looking on the internet but can not
find the answer.

My question: what is the variation on the mean of a limited distribution
(total N points normally distributed), when I have a small sample of
that distribution (n < N)?

Your help would be very welcome.

Thanx,
Roy


--
The information contained in this communication and any\ att...{{dropped}}



From luis.tercero at ebi-wasser.uni-karlsruhe.de  Wed Mar 23 13:54:43 2005
From: luis.tercero at ebi-wasser.uni-karlsruhe.de (Luis Tercero)
Date: Wed, 23 Mar 2005 13:54:43 +0100
Subject: [R] extracting numerical data from text field
Message-ID: <42416713.4070504@ebi-wasser.uni-karlsruhe.de>

I have imported a data frame that looks like this:

           Measurement.Date.and.Time Z.Average..nm.   PDI
572 Dienstag, 22. M?rz 2005 11:05:59          366,4 0,468
573 Dienstag, 22. M?rz 2005 11:09:30          353,4 0,532
574 Dienstag, 22. M?rz 2005 11:12:59            343 0,428
575 Dienstag, 22. M?rz 2005 11:16:28          354,1 0,433
576 Dienstag, 22. M?rz 2005 11:19:59          341,9 0,349
577 Dienstag, 22. M?rz 2005 11:23:29          334,9 0,429
...

Would there be a way to extract the time in numerical form from the
Measurement.Date.and.Time field?  What I would like to do is a time
series where, for example,
Dienstag, 22. M?rz 2005 11:05:59 is time=0 min
Dienstag, 22. M?rz 2005 11:09:30 is time=3.5 min, etc.

Thank you in advance for your help.

Luis



From andy_liaw at merck.com  Wed Mar 23 14:08:24 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 23 Mar 2005 08:08:24 -0500
Subject: [R] Tool for update
Message-ID: <3A822319EB35174CA3714066D590DCD50994E8D2@usrymx25.merck.com>

If you're talking about R itself, I believe the answer is "no".  However,
the release schedule for R is rather predictable (two major releases per
year, one in Spring and another in Fall, with patch releases in between as
needed), so the need is not that great, IMHO.  

Andy

> From: Yuandan Zhang
> 
> Hi,
> 
> Is there any tool to check if there is update version of a package
> available? I look for things alike YUM for linux?
> 
> YD
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From andy_liaw at merck.com  Wed Mar 23 14:17:05 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 23 Mar 2005 08:17:05 -0500
Subject: [R] Question on statistics
Message-ID: <3A822319EB35174CA3714066D590DCD50994E8D3@usrymx25.merck.com>

If the sample is drawn with replacement from the finite population, then the
usual formula applies (assuming iid samples); i.e., var(sample mean) =
var(population) / n.

There's some problem in your description:  A finite population, I believe,
is necessarily discrete (since there are only N possible values), so it can
not be Gaussian (i.e., normal).

Andy

> From: Roy Werkman
> 
> Ehh, by limited distribution, I meant to say a population of N points.
> 
> ...
>  
> Hi,
> 
> Can anyone help me with the following (although not directly 
> correlated
> to R functionality)? I have been looking on the internet but can not
> find the answer.
> 
> My question: what is the variation on the mean of a limited 
> distribution
> (total N points normally distributed), when I have a small sample of
> that distribution (n < N)?
> 
> Your help would be very welcome.
> 
> Thanx,
> Roy
> 
> 
> --
> The information contained in this communication and any\\ ...{{dropped}}



From blindglobe at gmail.com  Wed Mar 23 14:22:43 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Wed, 23 Mar 2005 14:22:43 +0100
Subject: [R] Package vignette and build
In-Reply-To: <200503221723.j2MHNahB003520@definetti.uark.edu>
References: <200503221723.j2MHNahB003520@definetti.uark.edu>
Message-ID: <1abe3fa90503230522693590b1@mail.gmail.com>

Yes, you need the package installed first.  

Something like:

R CMD build --no-vignettes DLM
R CMD install DLM.....
R CMD build DLM
R CMD install DLM.....

At least you had to do this with 1.9.1, can't recall looking again since then.


On Tue, 22 Mar 2005 11:23:36 -0600 (CST), Giovanni Petris
<GPetris at uark.edu> wrote:
> 
> Hello,
> 
> I am writing a package called 'DLM' containing a vignette.
> The vignette contains a chunck with the function call 'library(DLM)'.
> This worked fine with 'R CMD check DLM', but when it comes to building
> the package with 'R CMD build DLM' I get the following error message:
> 
> * creating vignettes ... ERROR
> 
> Error:  chunk 1
> Error in library(DLM) : There is no package called 'DLM'
> Error in buildVignettes(dir = ".") : Error:  chunk 1
> Error in library(DLM) : There is no package called 'DLM'
> Execution halted
> 
> It looks to me as if I should have the package already installed
> before building it...  I have read the article by F. Leisch on package
> vignettes in R News 3/2 and looked at the source for 'strucchange',
> but I can't figure out what I am doing wrong.
> 
> Any suggestions you can provide are more than welcome!
> 
> Thank you in advance,
> Giovanni
> 
> > version
>          _
> platform sparc-sun-solaris2.8
> arch     sparc
> os       solaris2.8
> system   sparc, solaris2.8
> status
> major    2
> minor    0.1
> year     2004
> month    11
> day      15
> language R
> 
> --
> 
>  __________________________________________________
> [                                                  ]
> [ Giovanni Petris                 GPetris at uark.edu ]
> [ Department of Mathematical Sciences              ]
> [ University of Arkansas - Fayetteville, AR 72701  ]
> [ Ph: (479) 575-6324, 575-8630 (fax)               ]
> [ http://definetti.uark.edu/~gpetris/              ]
> [__________________________________________________]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
best,
-tony

"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).

A.J. Rossini
blindglobe at gmail.com



From roy.werkman at asml.com  Wed Mar 23 14:32:05 2005
From: roy.werkman at asml.com (Roy Werkman)
Date: Wed, 23 Mar 2005 14:32:05 +0100
Subject: [R] Question on statistics
Message-ID: <448071208107374B96ED90585EEBA91256C3AB@NLVDHX84.sn-eu.asml.com>


Yes, it is discrete, but the underlying distribution is Gaussian.

Just got the following from a college:

Var(mean of finite population) = ((N - n)/(N - 1)) * var(population) / n

This should be it...

Greetings,
Roy

-----Original Message-----
From: Liaw, Andy [mailto:andy_liaw at merck.com] 
Sent: Wednesday, March 23, 2005 2:17 PM
To: Roy Werkman; r-help at stat.math.ethz.ch
Subject: RE: [R] Question on statistics

If the sample is drawn with replacement from the finite population, then
the usual formula applies (assuming iid samples); i.e., var(sample mean)
=
var(population) / n.

There's some problem in your description:  A finite population, I
believe, is necessarily discrete (since there are only N possible
values), so it can not be Gaussian (i.e., normal).

Andy

> From: Roy Werkman
> 
> Ehh, by limited distribution, I meant to say a population of N points.
> 
> ...
>  
> Hi,
> 
> Can anyone help me with the following (although not directly 
> correlated to R functionality)? I have been looking on the internet 
> but can not find the answer.
> 
> My question: what is the variation on the mean of a limited 
> distribution (total N points normally distributed), when I have a 
> small sample of that distribution (n < N)?
> 
> Your help would be very welcome.
> 
> Thanx,
> Roy
> 
> 
> --
> The information contained in this communication and any\ 
> att...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
> 



------------------------------------------------------------------------
------
Notice:  This e-mail message, together with any attachments, contains
information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station,
New Jersey, USA 08889), and/or its affiliates (which may be known
outside the United States as Merck Frosst, Merck Sharp & Dohme or MSD
and in Japan, as Banyu) that may be confidential, proprietary
copyrighted and/or legally privileged. It is intended solely for the use
of the individual or entity named on this message.  If you are not the
intended recipient, and have received this message in error, please
notify us immediately by reply e-mail and then delete it from your
system.
------------------------------------------------------------------------
------


-- 
The information contained in this communication and any attachments is confidential and may be privileged, and is for the sole use of the intended recipient(s). Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please notify the sender immediately by replying to this message and destroy all copies of this message and any attachments. ASML is neither liable for the proper and complete transmission of the information contained in this communication, nor for any delay in its receipt.



From dvumani at hotmail.com  Wed Mar 23 14:53:10 2005
From: dvumani at hotmail.com (Vumani Dlamini)
Date: Wed, 23 Mar 2005 13:53:10 +0000
Subject: [R] sampling from a mixture distribution
Message-ID: <BAY16-F11080E305735FD71C6756EA34F0@phx.gbl>

Dear R users,
I would like to sample from a mixture distribution p1*f(x1)+p2*f(x2). I 
usually sample variates from both distributions and weight them with their 
respective probabilities, but someone told me that was wrong. What is the 
correct way?
Vumani



From dimitris.rizopoulos at med.kuleuven.ac.be  Wed Mar 23 15:14:44 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Wed, 23 Mar 2005 15:14:44 +0100
Subject: [R] sampling from a mixture distribution
References: <BAY16-F11080E305735FD71C6756EA34F0@phx.gbl>
Message-ID: <005c01c52fb2$a957b9b0$0540210a@www.domain>

you have also to sample the mixture compoment membership; check this 
for a mixtrue of two normals:

rnorm.mixture <- function(n, prob=0.5, mu1=0, sigma1=1, mu2=0, 
sigma2=1){
    u <- runif(n)
    out <- numeric(n)
    for(i in 1:n) out[i] <- if(u[i] < prob) rnorm(1, mu1, sigma1) else 
rnorm(1, mu2, sigma2)
    out
}
########
hist(rnorm.mixture(1000, prob=0.6, mu1=-1, sigma1=0.5, mu2=2, 
sigma2=0.5))


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Vumani Dlamini" <dvumani at hotmail.com>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, March 23, 2005 2:53 PM
Subject: [R] sampling from a mixture distribution


> Dear R users,
> I would like to sample from a mixture distribution 
> p1*f(x1)+p2*f(x2). I usually sample variates from both distributions 
> and weight them with their respective probabilities, but someone 
> told me that was wrong. What is the correct way?
> Vumani
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From pensterfuzzer at yahoo.de  Wed Mar 23 15:14:49 2005
From: pensterfuzzer at yahoo.de (Werner Wernersen)
Date: Wed, 23 Mar 2005 15:14:49 +0100 (CET)
Subject: [R] replace values in a matrix subject to boolean condition
Message-ID: <20050323141449.75181.qmail@web25810.mail.ukl.yahoo.com>

Hi everybody!

I am sorry to bother you with a question so simple but
I think there might be a 
better solution:
I have a matrix of size 360x501 where I want to check
the value of each 5th 
column of each row and replace it (and the 6th, 7th,
8th column) by zero if the 
value is less than 1000. I have written a double loop
to do that but that 
requires a lot of time.

Is there a faster way to achieve this?

Thanks,
   Werner



From dsandif at email.unc.edu  Wed Mar 23 15:19:46 2005
From: dsandif at email.unc.edu (dsandif)
Date: Wed, 23 Mar 2005 09:19:46 -0500
Subject: [R] Will "R" work on this 64 bit machine?...
Message-ID: <42417B02.7050907@email.unc.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050323/14435757/attachment.pl

From GPetris at uark.edu  Wed Mar 23 15:17:35 2005
From: GPetris at uark.edu (Giovanni Petris)
Date: Wed, 23 Mar 2005 08:17:35 -0600 (CST)
Subject: [R] sampling from a mixture distribution
In-Reply-To: <BAY16-F11080E305735FD71C6756EA34F0@phx.gbl> (message from Vumani
	Dlamini on Wed, 23 Mar 2005 13:53:10 +0000)
References: <BAY16-F11080E305735FD71C6756EA34F0@phx.gbl>
Message-ID: <200503231417.j2NEHZgR005164@definetti.uark.edu>


For each variate, generate it from f1() with probability p1, and from
f2() with probability p2. In other words, flip a p1-biased coin to
decide which distribution, f1 or f2, to generate from. 

HTH,
Giovanni

> Date: Wed, 23 Mar 2005 13:53:10 +0000
> From: Vumani Dlamini <dvumani at hotmail.com>
> Sender: r-help-bounces at stat.math.ethz.ch
> Precedence: list
> 
> Dear R users,
> I would like to sample from a mixture distribution p1*f(x1)+p2*f(x2). I 
> usually sample variates from both distributions and weight them with their 
> respective probabilities, but someone told me that was wrong. What is the 
> correct way?
> Vumani
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]



From andy_liaw at merck.com  Wed Mar 23 15:24:00 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 23 Mar 2005 09:24:00 -0500
Subject: [R] sampling from a mixture distribution
Message-ID: <3A822319EB35174CA3714066D590DCD50994E8D8@usrymx25.merck.com>

Here's one possible way:

rmix2 <- function(n, p1, rF1, rF2, argF1=NULL, argF2=NULL) {
    ## n is the number of deviates to simulate
    ## p1 is the probability of a point coming from the 1st component
    ## rF1, rF2 are functions for generating random deviates
    ##     from the two components
    ## argF1, argF2 are lists of arguments to rF1 and rF2
    n1 <- rbinom(1, n, p1)
    n2 <- n - n1
    x1 <- do.call("rF1", c(list(n1), argF1))
    x2 <- do.call("rF2", c(list(n2), argF2))
    c(x1, x2)
}

To test:

   x <- rmix2(1000, 0.3, rnorm, rnorm, list(mean=5))
   hist(x)

HTH,
Andy

> From: Vumani Dlamini
> 
> Dear R users,
> I would like to sample from a mixture distribution 
> p1*f(x1)+p2*f(x2). I 
> usually sample variates from both distributions and weight 
> them with their 
> respective probabilities, but someone told me that was wrong. 
> What is the 
> correct way?
> Vumani
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From Hans.Skaug at mi.uib.no  Wed Mar 23 16:00:31 2005
From: Hans.Skaug at mi.uib.no (Hans.Skaug@mi.uib.no)
Date: Wed, 23 Mar 2005 16:00:31 +0100
Subject: [R] Negative binomial GLMMs in R
Message-ID: <1111590031.4241848f1f6ad@webmail.uib.no>

Dear R-users,

A recent post (Feb 16) to R-help inquired about fitting 
a glmm with  a negative binomial distribution. 
Professor Ripley responded that this was a difficult problem with the
simpler Poisson model already being a difficult case:

https://stat.ethz.ch/pipermail/r-help/2005-February/064708.html

Since we are developing software for fitting general nonlinear random 
effects models we thought this might be an interesting challenge. 
We contacted Professor Ripley who kindly directed us to the epilepsy data 
in Venables & Ripley section 10.4 (4th ed.). While V&B did not actually 
fit a negative binomial to these data they did refer to evidence 
of overdispersion in the response.  Fortunately Booth et al. (2003) did 
attempt to fit this model with a negative binomial which gave us something 
to which we could compare our results. Booth et al. fitted two forms of 
the model a simpler one and a more complicated model. They reported some 
difficulty fitting the more complicated  model. We found that we could 
reliably fit (MLE) both the complicated and simpler model in 20 seconds 
or less (although the more complicated turns out to be overparameterized)

Using the random effects module of AD Model Builder we have developed 
a shared library (Windows dll) that can be called from R via the driver 
function glmm.admb(). The function can be downloaded from

http://otter-rsch.com/admbre/examples/nbmm/nbmm.html

The two models of Booth et al are fit by the commands:

glmm.admb(y~Base*trt+Age+Visit,random=~1,group="subject",data=epil2)
glmm.admb(y~Base*trt+Age+Visit,random=~Visit,group="subject",data=epil2)

I will be happy to receive feedback on the function glmm.admb().


Best regards,

Hans Skaug



Reference: 
Booth J.G.; Casella G.; Friedl H.; Hobert J.P, Negative binomial loglinear 
mixed models.
Statistical Modelling, October 2003, vol. 3, no. 3, pp. 179-191



From rolf at math.unb.ca  Wed Mar 23 16:03:01 2005
From: rolf at math.unb.ca (Rolf Turner)
Date: Wed, 23 Mar 2005 11:03:01 -0400 (AST)
Subject: [R] sampling from a mixture distribution
Message-ID: <200503231503.j2NF31G6025849@erdos.math.unb.ca>


> I would like to sample from a mixture distribution p1*f(x1)+p2*f(x2).

	***Surely*** you mean ``p1*f1(x)+p2*f2(x)'' !!!

> I usually sample variates from both distributions and weight them
> with their respective probabilities, but someone told me that was
> wrong. What is the correct way?

	If you want a sample of size n, first generate n1 by

		n1 <- rbinom(1,n,p1)

	Then generate a vector x1 equal to n1 observations from the
	f1(x) distribution and a vector x2 equal to n2 = n-n1
	observations from the f2(x) distribution.  Finally combine
	the two vectors of observations into a single vector:

		x <- c(x1,x2)

	You can then shuffle the order of x

		x <- sample(x,n)

	if you want to be obsessive about it.

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From mvida at mitre.org  Wed Mar 23 16:05:10 2005
From: mvida at mitre.org (Melanie Vida)
Date: Wed, 23 Mar 2005 10:05:10 -0500
Subject: [R] Question on class 1, 2 output for  RandomForest
In-Reply-To: <4240A6C1.9080106@mitre.org>
References: <4240A6C1.9080106@mitre.org>
Message-ID: <424185A6.1010207@mitre.org>

Hi All,

I read the R-newsletter Volum 2/3, December 2002 on page 18. I tried the 
example there, too. Then, I used a different data set with random Forest 
from the UCI respository. The results for the "credit" data generated 2 
additional columns, column "1" and a column "2" that the example given 
in the newsletter did not generate from the  fgl data set.

For the "credit" data, what does the output with the heading "1", " 2" 
imply for ntree=100...500 (below)? Does the "1" imply the actual data, 
"class 1" and a group of synthetic data "2" -> "class 2"? Did my random 
forest automatically default to unsupervised learning  and automatically 
create the class 2, synthetic data, then classify the combined data with 
the random Forest? If so, which method did R used to generate the 
synthetic data? The newsletter states that there are 2 ways to generate 
synthetic data.

Further, the  parameters to tune these randomForest would ideally 
optimize the OOB error rate and whatever column 1 and 2 error rates 
mean? I tried mtry=2, 3 and 10, but that didn't change the errors much. 
Are these results reasonable, or should I tried to tune different 
parameters for this special case?

ntree      OOB      1      2
  100:  20.72% 14.10% 28.99%
  200:  18.99% 13.58% 25.73%
  300:  19.71% 15.14% 25.41%
  400:  20.00% 14.10% 27.36%
  500:  19.13% 13.58% 26.06%

Call:
 randomForest(x = V16 ~ ., data = credit, mtry = 3, importance = 
TRUE,      do.trace = 100)
               Type of random forest: classification
                     Number of trees: 500
No. of variables tried at each split: 3

        OOB estimate of  error rate: 19.86%
Confusion matrix:
    -   + class.error
- 326  57   0.1488251
+  80 227   0.2605863


Thanks in advance,

-Melanie
-------
# Read in the credit table
credit = 
read.table(url('ftp://ftp.ics.uci.edu/pub/machine-learning-databases/credit-screening/crx.data'),sep=",")
str(credit)
credit$V2 = as.numeric(credit$V2)
credit$V14 = as.numeric(credit$V14)
str(credit)

credit.rf <- randomForest(V16 ~ ., data=credit, mtry=3, importance = 
TRUE, do.trace=100)
print(credit.rf)


-Melanie



From rpeng at jhsph.edu  Wed Mar 23 16:13:38 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 23 Mar 2005 10:13:38 -0500
Subject: [R] Will "R" work on this 64 bit machine?...
In-Reply-To: <42417B02.7050907@email.unc.edu>
References: <42417B02.7050907@email.unc.edu>
Message-ID: <424187A2.9090403@jhsph.edu>

I believe R will run out of the box on your setup.  I personally 
haven't tried the RPMs but you can always build R from the sources 
(fairly straightforward on a Linux box).

-roger

dsandif wrote:
> Hello,
> 
> Will "R" work on this 64 bit machine?, Here are the specs.
> of our linux box:
> 
> *Red Hat Enterprise Linux WS (v.3 Standard for AMD64 and Intel EM64T)
> *OS: redhat-release
> Release: 3WS
> CPU Arch: ia32e-redhat-linux
> 
> 
> 
> (4) GenuineIntel Intel(R) Xeon(TM) CPU 3.40GHz 3399 MHZ
> 
>  Arch: 	EM64T 	Cache: 	1024 KB
>  Vendor: 	GenuineIntel 	Memory: 	2000 MB
>  Stepping: 	1
>  Family: 	15 	Swap: 	4000 MB
> 
> 
> I see that you have it for Unix machines and that you have it for the 
> following linux platforms:
> 
> Red Hat 	i386 	8/9/Fedora1/Fedora2/Fedora3 	Martyn Plummer
> 
> 	x86_64 	Fedora1 	James Henstridge
> 
> 	x86_64 	Fedora3 	Brian Ripley
> 
> 	i386 	Enterprise Linux 	Matthew P. Cox
> 
> 
> Could I use the Fedore 3 x86_64 version?
> 
> Thanks for you attention and help.
> 
> D-
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/



From ripley at stats.ox.ac.uk  Wed Mar 23 16:26:38 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 23 Mar 2005 15:26:38 +0000 (GMT)
Subject: [R] Will "R" work on this 64 bit machine?...
In-Reply-To: <42417B02.7050907@email.unc.edu>
References: <42417B02.7050907@email.unc.edu>
Message-ID: <Pine.LNX.4.61.0503231520410.14618@gannet.stats>

On Wed, 23 Mar 2005, dsandif wrote:

> Hello,
>
> Will "R" work on this 64 bit machine?,

Yes.

> Here are the specs.
> of our linux box:
>
> *Red Hat Enterprise Linux WS (v.3 Standard for AMD64 and Intel EM64T)
> *OS: redhat-release
> Release: 3WS
> CPU Arch: ia32e-redhat-linux

That's not at all clear: what is `ia32e'?  Depending on what it means R 
will work in 32- or 64-bit mode.  My hesitation is that when we tried 
RHEL3 without much happiness on an AMD64 box: it had lots of 32-bit 
components.

> (4) GenuineIntel Intel(R) Xeon(TM) CPU 3.40GHz 3399 MHZ
>
> Arch: 	EM64T 	Cache: 	1024 KB
> Vendor: 	GenuineIntel 	Memory: 	2000 MB
> Stepping: 	1
> Family: 	15 	Swap: 	4000 MB
>
>
> I see that you have it for Unix machines and that you have it for the
> following linux platforms:
>
> Red Hat 	i386 	8/9/Fedora1/Fedora2/Fedora3 	Martyn Plummer
>
> 	x86_64 	Fedora1 	James Henstridge
>
> 	x86_64 	Fedora3 	Brian Ripley
>
> 	i386 	Enterprise Linux 	Matthew P. Cox
>
>
> Could I use the Fedore 3 x86_64 version?

Not likely (it has later software than RHEL3).  Building from the sources 
should be straightforward, but watch the compiler versions.  Martin 
Maechler had problems (with I believe RHEL3) and need to update gcc and 
g77. The problem was with gcc 3.2.x, and 3.3.3 and 3.4.3 are both fine.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From nioniodesbois at yahoo.fr  Wed Mar 23 16:28:41 2005
From: nioniodesbois at yahoo.fr (Guillaume STORCHI)
Date: Wed, 23 Mar 2005 16:28:41 +0100 (CET)
Subject: [R] nl regression with 8 parameters, help!
Message-ID: <20050323152841.92996.qmail@web86905.mail.ukl.yahoo.com>

I'm doing a non linear regression with 8 parameters to be fitted:

J.Tl.nls<-nls(Gw~(a1/(1+exp(-a2*Tl+a3))+a4)*(b1/(1+exp(b2*Tl-b3))+b4),data=Enveloppe,
                       start=list(a1=0.88957,a2=0.36298,a3=10.59241,a4=0.26308,
                                 
b1=0.391268,b2=1.041856,b3=0.391268,b4=0.03439))

   First, I fitted my curve on my data by guessing the parameters' values ("by
hand"), and wrote them. 
   Then, I ajusted my model only with two parameters (whereas the others were
fixed with previously found values, I did it the same way for all parameters. 
   Finally, I got 8 fitted values that I enventually embedded in my nls()
function, like above, yet R talled me: 
"Error in nlsModel(formula, mf, start) : singular gradient matrix at initial
parameter estimates"

should I use optim() or optimize()? 
How could I perform it?

Thanks for help

Guillaume Storchi



From andy_liaw at merck.com  Wed Mar 23 16:31:22 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 23 Mar 2005 10:31:22 -0500
Subject: [R] Question on class 1, 2 output for  RandomForest
Message-ID: <3A822319EB35174CA3714066D590DCD50994E8DB@usrymx25.merck.com>

The `1' and `2' columns are the error rates within those classes.  E.g., the
last row of the `1' column should correspond to the class.error for "-", and
the last row of the `2' column to the class.error for "+".      (I would
have thought that that should be fairly obvious, but I guess not.  It mimics
what Breiman and Cutler's Fortran code does.)  I suspect you showed us the
output from two different runs, so they don't match.  It does for me:

> library(randomForest)
randomForest 4.5-4 
Type rfNews() to see new features/changes/bug fixes.
> credit <- read.csv(url("ftp://ftp.ics.
> credit <-
read.csv(url("ftp://ftp.ics.uci.edu/pub/machine-learning-databases/credit-sc
reening/crx.data"), header=FALSE, na.string="?")
> credit.rf <- randomForest(V16~., credit, imp=T, do.trace=100,
na.action=na.omit)
ntree      OOB      1      2
  100:  20.37% 14.01% 28.04%
  200:  21.59% 15.41% 29.05%
  300:  20.52% 13.45% 29.05%
  400:  20.52% 13.17% 29.39%
  500:  20.21% 12.61% 29.39%
> credit.rf

Call:
 randomForest(x = V16 ~ ., data = credit, imp = T, do.trace = 100,
na.action = na.omit) 
               Type of random forest: classification
                     Number of trees: 500
No. of variables tried at each split: 3

        OOB estimate of  error rate: 20.21%
Confusion matrix:
    -   + class.error
- 312  45   0.1260504
+  87 209   0.2939189

The article in R News was written for the first version of the package.  It
has changed quite a bit in many respects since then.  The `class error' may
be important, e.g., if one of the classes only make up a small proportion of
the data.

Andy


> From: Melanie Vida
> 
> Hi All,
> 
> I read the R-newsletter Volum 2/3, December 2002 on page 18. 
> I tried the 
> example there, too. Then, I used a different data set with 
> random Forest 
> from the UCI respository. The results for the "credit" data 
> generated 2 
> additional columns, column "1" and a column "2" that the 
> example given 
> in the newsletter did not generate from the  fgl data set.
> 
> For the "credit" data, what does the output with the heading 
> "1", " 2" 
> imply for ntree=100...500 (below)? Does the "1" imply the 
> actual data, 
> "class 1" and a group of synthetic data "2" -> "class 2"? Did 
> my random 
> forest automatically default to unsupervised learning  and 
> automatically 
> create the class 2, synthetic data, then classify the 
> combined data with 
> the random Forest? If so, which method did R used to generate the 
> synthetic data? The newsletter states that there are 2 ways 
> to generate 
> synthetic data.
> 
> Further, the  parameters to tune these randomForest would ideally 
> optimize the OOB error rate and whatever column 1 and 2 error rates 
> mean? I tried mtry=2, 3 and 10, but that didn't change the 
> errors much. 
> Are these results reasonable, or should I tried to tune different 
> parameters for this special case?
> 
> ntree      OOB      1      2
>   100:  20.72% 14.10% 28.99%
>   200:  18.99% 13.58% 25.73%
>   300:  19.71% 15.14% 25.41%
>   400:  20.00% 14.10% 27.36%
>   500:  19.13% 13.58% 26.06%
> 
> Call:
>  randomForest(x = V16 ~ ., data = credit, mtry = 3, importance = 
> TRUE,      do.trace = 100)
>                Type of random forest: classification
>                      Number of trees: 500
> No. of variables tried at each split: 3
> 
>         OOB estimate of  error rate: 19.86%
> Confusion matrix:
>     -   + class.error
> - 326  57   0.1488251
> +  80 227   0.2605863
> 
> 
> Thanks in advance,
> 
> -Melanie
> -------
> # Read in the credit table
> credit = 
> read.table(url('ftp://ftp.ics.uci.edu/pub/machine-learning-dat
abases/credit-screening/crx.data'),sep=",")
> str(credit)
> credit$V2 = as.numeric(credit$V2)
> credit$V14 = as.numeric(credit$V14)
> str(credit)
> 
> credit.rf <- randomForest(V16 ~ ., data=credit, mtry=3, importance = 
> TRUE, do.trace=100)
> print(credit.rf)
> 
> 
> -Melanie
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From macq at llnl.gov  Wed Mar 23 16:40:19 2005
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 23 Mar 2005 07:40:19 -0800
Subject: [R] R accuracy
In-Reply-To: <20050323090321.85399.qmail@web41114.mail.yahoo.com>
References: <20050323090321.85399.qmail@web41114.mail.yahoo.com>
Message-ID: <p06210200be673d7517a5@[128.115.153.6]>

Try

   signif(m,8)


At 1:03 AM -0800 3/23/05, Anthony Landrevie wrote:
>Hello,
>
>I am trying to test the precision of R on datasets from The 
>Statistical Reference Datasets Project 
>http://www.itl.nist.gov/div898/strd/index.html and I don't manage to 
>understand how R is storing its results.
>
>For example, I calculate a mean on the michelso dataset (100 values) and find:
>
>>  m=mean(michel)
>>  m
>       V1
>299.8524
>>  print(m,digits=15)
>       V1
>299.8524
>
>>  print(m,digits=22)
>                 V1
>299.85239999999993
>
>
>The certified value of the mean is 299.85240, so I try
>
>
>>  print(m-299.8524)
>            V1
>-5.684342e-14
>
>>  print(m-299.8524,digits=15)
>                    V1
>-5.68434188608080e-14
>
>Does it have a sens to print with more than 15 signifiant digits?
>Why is the difference not equal to zero?
>
>I am using R 2.0.1 under Windows XP.
>
>Regards,
>
>Anthony Landrevie
>
>
>---------------------------------
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From sluque at mun.ca  Wed Mar 23 17:16:24 2005
From: sluque at mun.ca (Sebastian Luque)
Date: Wed, 23 Mar 2005 10:16:24 -0600
Subject: [R] alternative to 'groups' for lattice bwplot()
References: <33F91FB3FDF42E4180428AC66A5CF30B02D3BAA7@afhex01.dpi.wa.gov.au>
Message-ID: <878y4ecp7r.fsf@mun.ca>

"Mulholland, Tom" <Tom.Mulholland at dpi.wa.gov.au> wrote:

> I'm afraid you have lost me. What is it that you want that reordering
> the formula does not achieve.
>
> bwplot(yield ~ year | site, data = barley) has sites next to each other.

Yes, they are next to each other, but in different panels, as expected
when using a formula like that. I should have been more explicit saying
that I want the conditioning variable to show within a panel.


> If the lattice structure is your issue (it appears you wish to remove
> the structure and replace it with a wider space) then I guess you might
> find writing your own code easier than forcing lattice to be something
> other than itself.

I disagree. IMHO, I don't think the sole purpose of lattice is to put
plots in different panels. There are several cases, where (I think)
lattice can "mark" groups of data in a single panel more efficiently than
other tools. One may or may not need other conditioning variables to show
in different panels.


-- 
Sebastian P. Luque



From deepayan at stat.wisc.edu  Wed Mar 23 17:38:59 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 23 Mar 2005 10:38:59 -0600
Subject: [R] alternative to 'groups' for lattice bwplot()
In-Reply-To: <87psxqdh9e.fsf@mun.ca>
References: <87psxqdh9e.fsf@mun.ca>
Message-ID: <200503231038.59694.deepayan@stat.wisc.edu>

On Wednesday 23 March 2005 00:10, Sebastian Luque wrote:
> Hi,
>
> Is there some alternative to the 'groups' argument in lattice's
> bwplot function for boxplots? Say in the example below:
>
> bwplot(yield ~ site | year, data = barley)
>
> you want to have two side by side boxplots per site, corresponding to
> each year in the barley data frame. Ideally, the space between
> boxplots of the same site should be smaller than that between
> boxplots of different sites.
>
> This seemed like a job for the 'groups' argument, but panel.bwplot
> doesn't take it. I saw that boxplot() might do this for the
> particular example above, but not for a more complex one with
> additional conditioning variables (as in my actual problem).

I consider bwplot to already provide a grouped display (box plots are 
univariate summaries, and bwplot allows you to display several of them 
together within a panel). What you are looking for may be appropriate 
in certain situations, but is not general enough to warrant a built-in 
implementation. In other words, you'll have to write your own panel 
function.

> I thought I'd find something about this in the archives, but I'm
> either not using the right keywords or the question hasn't come up
> yet.

The only instance I can recall is:

http://tolstoy.newcastle.edu.au/R/help/04/02/0848.html

Deepayan



From ahenningsen at email.uni-kiel.de  Wed Mar 23 17:47:00 2005
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Wed, 23 Mar 2005 17:47:00 +0100
Subject: [R] nl regression with 8 parameters, help!
In-Reply-To: <20050323152841.92996.qmail@web86905.mail.ukl.yahoo.com>
References: <20050323152841.92996.qmail@web86905.mail.ukl.yahoo.com>
Message-ID: <200503231747.00775.ahenningsen@email.uni-kiel.de>

Does this error always occur independently of the starting values that you 
provide? I guess so, because I think that the parameters in your equation are 
not identifiable, since the first term (a1 to a4) is identical to the second 
term (b1 to b4) with a1 = b1, -a2 = b2, a3 = -b3, and a4 = b4 .
Do you really want to have the same explanatory variable ("Tl") in both terms?

Arne


On Wednesday 23 March 2005 16:28, Guillaume STORCHI wrote:
> I'm doing a non linear regression with 8 parameters to be fitted:
>
> J.Tl.nls<-nls(Gw~(a1/(1+exp(-a2*Tl+a3))+a4)*(b1/(1+exp(b2*Tl-b3))+b4),data=
>Enveloppe, start=list(a1=0.88957,a2=0.36298,a3=10.59241,a4=0.26308,
>
> b1=0.391268,b2=1.041856,b3=0.391268,b4=0.03439))
>
>    First, I fitted my curve on my data by guessing the parameters' values
> ("by hand"), and wrote them.
>    Then, I ajusted my model only with two parameters (whereas the others
> were fixed with previously found values, I did it the same way for all
> parameters. Finally, I got 8 fitted values that I enventually embedded in
> my nls() function, like above, yet R talled me:
> "Error in nlsModel(formula, mf, start) : singular gradient matrix at
> initial parameter estimates"
>
> should I use optim() or optimize()?
> How could I perform it?
>
> Thanks for help
>
> Guillaume Storchi
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From 0034058 at fudan.edu.cn  Mon Mar 21 12:29:14 2005
From: 0034058 at fudan.edu.cn (ronggui)
Date: Mon, 21 Mar 2005 19:29:14 +0800
Subject: [R] How to do such MDS in R
Message-ID: <20050321192914.68bc3e7a.0034058@fudan.edu.cn>

i know cmdscale and isoMDS inR can do classical and non-metric MDS.but i want to konw if there is packages can carry on "individual differences scaling" and "multidimensional analysis og preference"?both method are important one,but i can not find any clue on how to do it using R.
anyone can help?
thank you!



From 042045003 at fudan.edu.cn  Wed Mar 23 14:37:59 2005
From: 042045003 at fudan.edu.cn (ronggui)
Date: Wed, 23 Mar 2005 21:37:59 +0800
Subject: [R] how to test for equality of covariance Matrices in lda
Message-ID: <20050323213759.142dce3d.042045003@fudan.edu.cn>

when  using  the two-group discriminant analysis,we need to test for equality of covariance Matrices in lda.as whenm we formed our estimate of the within-group covariance matrix by pooling across groups,we implicitly assumed that the covariance structure was the same across groups.so it seems important the test the equality.but i can not find function in R to do these.



From kjetil at acelerate.com  Wed Mar 23 17:36:41 2005
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Wed, 23 Mar 2005 12:36:41 -0400
Subject: [R] mixtures as outcome variables
In-Reply-To: <1111533080.4000.98.camel@wizard>
References: <1111533080.4000.98.camel@wizard>
Message-ID: <42419B19.5020309@acelerate.com>

Jason W. Martinez wrote:

>Dear R-users,
>
>I have an outcome variable and I'm unsure about how to treat it. Any
>advice?
>
>I have spending data for each county in the state of California (N=58).
>Each county has been allocated money to spend on any one of the
>following four categories: A, B, C, and D.
>
>Each county may spend the money in any way they see fit. This also means
>that the county need not spend all the money that was allocated to them.
>The data structure looks something like the one below:
>
>COUNTY    A        B       C       D        Total
>----------------------------------------------------
>alameda  2534221  1555592 2835475  3063249  9988537
>alpine   3174     8500    0        45558    55232
>amador    0       0        0        0       0
>....
>
>
>The goal is to explain variation in spending patterns, which are
>presumably the result of characteristics for each county.
>
>I may treat the problem like a simple linear regression problem for each
>category, but by definition, money spent in one category will take away
>the amount of money that can be spent in any other category---and each
>county is not allocated the same amount of money to spend.
>
>I have constructed proportions of amount spent on each category and have
>conducted quasibinomial regression, on each dependent outcome but that
>does not seem very convincing to me. 
>
>Would anyone have any advice about how to treat an outcome variable of
>this sort?
>
>Thanks for any hints!
>
>Jason
>
>
>
>
>
>  
>
If you only concentrate on the relative proportions, this are called 
compositional data. I f your data are in
mydata (n x 4), you obtain compositions by
sweep(mydata, 1, apply(mydata, 1, sum), "/")

There are not (AFAIK) specific functions/packages for R for 
compositional data AFAIK, but you
can try googling. Aitchison  has a monography (Chapman & Hall) and a 
paper in JRSS B.

One way to start might be lm's or anova on the symmetric logratio 
transform of the
compositons. The R function lm can take a multivariate response, but 
some extra programming will be needed
for interpretation. With simulated data:

 > slr
function(y) { # y should sum to 1
          v <- log(y)
          return( v - mean(v) ) }
 > testdata <- matrix( rgamma(120, 2,3), 30, 4)
 > str(testdata)
 num [1:30, 1:4] 0.200 0.414 0.311 2.145 0.233 ...
 > comp <- sweep(testdata, 1, apply(testdata,1,sum), "/")
# To get the symmetric logratio transform:
comp <- t(apply(comp, 1, slr))
# Observe:
apply(cov(comp), 1, sum)
[1] -5.551115e-17  2.775558e-17  5.551115e-17 -2.775558e-17
 > lm( comp ~ 1)

Call:
lm(formula = comp ~ 1)

Coefficients:
             [,1]      [,2]      [,3]      [,4]   
(Intercept)   0.17606   0.06165  -0.03783  -0.19988

 > summary(lm( comp ~ 1))
Response Y1 :

Call:
lm(formula = Y1 ~ 1)

Residuals:
     Min       1Q   Median       3Q      Max
-1.29004 -0.46725 -0.07657  0.55834  1.20551

Coefficients:
     Estimate Std. Error t value Pr(>|t|)
[1,]   0.1761     0.1265   1.391    0.175

Residual standard error: 0.6931 on 29 degrees of freedom


Response Y2 :

Call:
lm(formula = Y2 ~ 1)

Residuals:
    Min      1Q  Median      3Q     Max
-1.2982 -0.5711 -0.1355  0.5424  1.6598

Coefficients:
     Estimate Std. Error t value Pr(>|t|)
[1,]  0.06165    0.15049    0.41    0.685

Residual standard error: 0.8242 on 29 degrees of freedom


Response Y3 :

Call:
lm(formula = Y3 ~ 1)

Residuals:
     Min       1Q   Median       3Q      Max
-1.97529 -0.41115  0.03666  0.42785  0.88567

Coefficients:
     Estimate Std. Error t value Pr(>|t|)
[1,] -0.03783    0.11623  -0.325    0.747

Residual standard error: 0.6366 on 29 degrees of freedom


Response Y4 :

Call:
lm(formula = Y4 ~ 1)

Residuals:
    Min      1Q  Median      3Q     Max
-2.8513 -0.3955  0.2815  0.5939  1.2475

Coefficients:
     Estimate Std. Error t value Pr(>|t|)
[1,]  -0.1999     0.1620  -1.234    0.227

Residual standard error: 0.8872 on 29 degrees of freedom


Sorry for not being of more help!

Kjetil


-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra





-- 
No virus found in this outgoing message.
Checked by AVG Anti-Virus.



From shawp at mail.nih.gov  Wed Mar 23 17:58:09 2005
From: shawp at mail.nih.gov (Shaw, Philip (NIH/NIMH))
Date: Wed, 23 Mar 2005 11:58:09 -0500
Subject: [R] nested random effects
Message-ID: <5F9DE1C25708B04EAD634A1AE3D9113007A707AA@nihexchange20.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050323/e5ce1750/attachment.pl

From kjetil at acelerate.com  Wed Mar 23 17:51:25 2005
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Wed, 23 Mar 2005 12:51:25 -0400
Subject: [R] Question on statistics
In-Reply-To: <448071208107374B96ED90585EEBA91256C3AB@NLVDHX84.sn-eu.asml.com>
References: <448071208107374B96ED90585EEBA91256C3AB@NLVDHX84.sn-eu.asml.com>
Message-ID: <42419E8D.8050606@acelerate.com>

Roy Werkman wrote:

>Yes, it is discrete, but the underlying distribution is Gaussian.
>  
>
/ I guess you mean what somebody calls the superpopulation distribution.

Kjetil
/

>Just got the following from a college:
>
>Var(mean of finite population) = ((N - n)/(N - 1)) * var(population) / n
>
>This should be it...
>
>Greetings,
>Roy
>
>-----Original Message-----
>From: Liaw, Andy [mailto:andy_liaw at merck.com] 
>Sent: Wednesday, March 23, 2005 2:17 PM
>To: Roy Werkman; r-help at stat.math.ethz.ch
>Subject: RE: [R] Question on statistics
>
>If the sample is drawn with replacement from the finite population, then
>the usual formula applies (assuming iid samples); i.e., var(sample mean)
>=
>var(population) / n.
>
>There's some problem in your description:  A finite population, I
>believe, is necessarily discrete (since there are only N possible
>values), so it can not be Gaussian (i.e., normal).
>
>Andy
>
>  
>
>>From: Roy Werkman
>>
>>Ehh, by limited distribution, I meant to say a population of N points.
>>
>>...
>> 
>>Hi,
>>
>>Can anyone help me with the following (although not directly 
>>correlated to R functionality)? I have been looking on the internet 
>>but can not find the answer.
>>
>>My question: what is the variation on the mean of a limited 
>>distribution (total N points normally distributed), when I have a 
>>small sample of that distribution (n < N)?
>>
>>Your help would be very welcome.
>>
>>Thanx,
>>Roy
>>
>>
>>--
>>The information contained in this communication and any\ 
>>att...{{dropped}}
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
>>
>>
>>    
>>
>
>
>
>------------------------------------------------------------------------
>------
>Notice:  This e-mail message, together with any attachments, contains
>information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station,
>New Jersey, USA 08889), and/or its affiliates (which may be known
>outside the United States as Merck Frosst, Merck Sharp & Dohme or MSD
>and in Japan, as Banyu) that may be confidential, proprietary
>copyrighted and/or legally privileged. It is intended solely for the use
>of the individual or entity named on this message.  If you are not the
>intended recipient, and have received this message in error, please
>notify us immediately by reply e-mail and then delete it from your
>system.
>------------------------------------------------------------------------
>------
>
>
>  
>



-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra





-- 
No virus found in this outgoing message.
Checked by AVG Anti-Virus.



From p.dalgaard at biostat.ku.dk  Wed Mar 23 18:08:35 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 23 Mar 2005 18:08:35 +0100
Subject: [R] nl regression with 8 parameters, help!
In-Reply-To: <200503231747.00775.ahenningsen@email.uni-kiel.de>
References: <20050323152841.92996.qmail@web86905.mail.ukl.yahoo.com>
	<200503231747.00775.ahenningsen@email.uni-kiel.de>
Message-ID: <x2psxqwar0.fsf@turmalin.kubism.ku.dk>

Arne Henningsen <ahenningsen at email.uni-kiel.de> writes:

> Does this error always occur independently of the starting values that you 
> provide? I guess so, because I think that the parameters in your equation are 
> not identifiable, since the first term (a1 to a4) is identical to the second 
> term (b1 to b4) with a1 = b1, -a2 = b2, a3 = -b3, and a4 = b4 .
> Do you really want to have the same explanatory variable ("Tl") in both terms?

That's not necessarily a problem. There will of course always be two
solutions, but the algorithm may still converge to one of them. This
happens all the time with biexponential curves, e.g.. However, in this
case we have a local unidentifiability too: if you multiply a1 and a4
by a constant and divide b1 and b4 by the same constant, you get the
same fitted values. This is reflected in the singular gradient.

> On Wednesday 23 March 2005 16:28, Guillaume STORCHI wrote:
> > I'm doing a non linear regression with 8 parameters to be fitted:
> >
> > J.Tl.nls<-nls(Gw~(a1/(1+exp(-a2*Tl+a3))+a4)*(b1/(1+exp(b2*Tl-b3))+b4),data=
> >Enveloppe, start=list(a1=0.88957,a2=0.36298,a3=10.59241,a4=0.26308,
> >
> > b1=0.391268,b2=1.041856,b3=0.391268,b4=0.03439))


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jari.oksanen at oulu.fi  Wed Mar 23 18:19:23 2005
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Wed, 23 Mar 2005 19:19:23 +0200
Subject: [R] How to do such MDS in R
In-Reply-To: <20050321192914.68bc3e7a.0034058@fudan.edu.cn>
References: <20050321192914.68bc3e7a.0034058@fudan.edu.cn>
Message-ID: <d86d8d646098b70b90f31c488aaff8b3@oulu.fi>

On 21 Mar 2005, at 13:29, ronggui wrote:

> i know cmdscale and isoMDS inR can do classical and non-metric MDS.but 
> i want to konw if there is packages can carry on "individual 
> differences scaling" and "multidimensional analysis og 
> preference"?both method are important one,but i can not find any clue 
> on how to do it using R.
> anyone can help?
> thank you!

It may be that individual differences scaling is not available in R. 
The classic piece of software for this purpose is SINDSCAL. It is 
beautiful Fortran (although this sounds like contradiction in terms), 
and it would be easy to port the software into R, but I think the 
license does not allow this. The hardest bit would be to change the 
output into R. I suggest you dig up SINDSCAL somewhere -- it could be 
in netlib -- and compile it yourself. Gnu g77 is quite OK.

cheers, jari oksanen
--
Jari Oksanen, Oulu, Finland



From David.Ruau at rwth-aachen.de  Wed Mar 23 18:31:17 2005
From: David.Ruau at rwth-aachen.de (David Ruau)
Date: Wed, 23 Mar 2005 18:31:17 +0100
Subject: [R] Does R work in 64 bit on apple G5?
Message-ID: <bda0ce399e1bbb6c2a8c53cd802ed94a@rwth-aachen.de>

Hi,

I am working with R on 2xG5 1.8Ghz from Apple under 10.3.8
The G5 chip is 64 bits but does R run in 64 bit or 32 under OS X?
How can know?
I think it run in 32 bits... but not sure...

anyway thanks for this fabulous soft... ;-)

David



From f.calboli at imperial.ac.uk  Wed Mar 23 18:33:47 2005
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Wed, 23 Mar 2005 17:33:47 +0000
Subject: [R] nested random effects
In-Reply-To: <5F9DE1C25708B04EAD634A1AE3D9113007A707AA@nihexchange20.nih.gov>
References: <5F9DE1C25708B04EAD634A1AE3D9113007A707AA@nihexchange20.nih.gov>
Message-ID: <1111599227.11063.336.camel@localhost.localdomain>

On Wed, 2005-03-23 at 11:58 -0500, Shaw, Philip (NIH/NIMH) wrote:
> Hi
>  
> I am struggling with nested random effects and hope someone can help.
>  
> 
> 
> I have individuals (ID) who are nested within families (FAM).  I want to
> model an outcome variable, and take account of the intercorrelation of
> individuals within each family. 
>  
> I think this amounts to two random effects, one nested within the other.
>  
> How can I model this in R?
>  
> So far I have tried using the library(nlme), and then
>  
> Y~ID, random=~1|ID*FAM, 
>  

An interaction random effect/fixed effect is noted as 

random ~1|random/fixed

in your case random =~1|ID/FAM (but I don't uderstand why indiviuals
withing families are fixed and and families are random, but there you
go).

Check out Pinheiro and Bates Ch1, especially pg 23 onwards.

Cheers,

F 
-- 
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St Mary's Campus
Norfolk Place, London W2 1PG

Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From tlumley at u.washington.edu  Wed Mar 23 18:44:43 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 23 Mar 2005 09:44:43 -0800 (PST)
Subject: [R] Does R work in 64 bit on apple G5?
In-Reply-To: <bda0ce399e1bbb6c2a8c53cd802ed94a@rwth-aachen.de>
References: <bda0ce399e1bbb6c2a8c53cd802ed94a@rwth-aachen.de>
Message-ID: <Pine.A41.4.61b.0503230943040.164148@homer03.u.washington.edu>

On Wed, 23 Mar 2005, David Ruau wrote:

> Hi,
>
> I am working with R on 2xG5 1.8Ghz from Apple under 10.3.8
> The G5 chip is 64 bits but does R run in 64 bit or 32 under OS X?
> How can know?
> I think it run in 32 bits... but not sure...

Under the current OS X it runs 32bit.  You can tell by looking at
      .Machine$sizeof.pointer
which is 4.

The next version of OS X is advertised as having full 64bit support so 
this limitation will go away then.

 	-thomas



From ripley at stats.ox.ac.uk  Wed Mar 23 18:50:38 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 23 Mar 2005 17:50:38 +0000 (GMT)
Subject: [R] Does R work in 64 bit on apple G5?
In-Reply-To: <bda0ce399e1bbb6c2a8c53cd802ed94a@rwth-aachen.de>
References: <bda0ce399e1bbb6c2a8c53cd802ed94a@rwth-aachen.de>
Message-ID: <Pine.LNX.4.61.0503231744590.31459@gannet.stats>

On Wed, 23 Mar 2005, David Ruau wrote:

> I am working with R on 2xG5 1.8Ghz from Apple under 10.3.8
> The G5 chip is 64 bits but does R run in 64 bit or 32 under OS X?
> How can know?

>From the size of the ncells!
32-bit machine:

> gc()
          used (Mb) gc trigger (Mb)
Ncells 144907  3.9     350000  9.4
Vcells  61911  0.5     786432  6.0

64-bit machine:
> gc()
          used (Mb) gc trigger (Mb)
Ncells 141134  7.6     350000 18.7
Vcells  63088  0.5     786432  6.0

The ncells are 28bytes on a 32-bit machine and usually 56 on a 64-bit 
machine (depending on alignment needs).

> I think it run in 32 bits... but not sure...

The precompiled binary is definitely 32-bit.  If you compiled R yourself I 
suspect you would know if you sed a 64-bit compiler (if you had one).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From greg.snow at ihc.com  Wed Mar 23 18:52:57 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Wed, 23 Mar 2005 10:52:57 -0700
Subject: [R] mixtures as outcome variables
Message-ID: <s2414a97.065@lp-msg1.co.ihc.com>

>>  >>> "Jason W. Martinez" <jmartinez5 at verizon.net> 03/22/05 04:11PM
>>>
>>  Dear R-users,
>>  
>>  I have an outcome variable and I'm unsure about how to treat it.
Any
>>  advice?

Below are a couple of ideas/suggestions of things to think about

>>  
>>  I have spending data for each county in the state of California
(N=58).
>>  Each county has been allocated money to spend on any one of the
>>  following four categories: A, B, C, and D.
>>  
>>  Each county may spend the money in any way they see fit. This also
means
>>  that the county need not spend all the money that was allocated to
them.
>>  The data structure looks something like the one below:

You might want to include a category for the amout of money not spent
(for
a total of 5 possibilities).

>>  COUNTY    A        B       C       D        Total
>>  ----------------------------------------------------
>>  alameda  2534221  1555592 2835475  3063249  9988537
>>  alpine   3174     8500    0        45558    55232
>>  amador    0       0        0        0       0
>>  ....
>>  
>>  
>>  The goal is to explain variation in spending patterns, which are
>>  presumably the result of characteristics for each county.

Do you have data representing these characteristics?  The predictor
values
in a regression type model?

Starting with some good graphics may help determine and show 
interesting patterns.

The maptools package can read in shapefiles and plot the maps.  You can

download a shapefile with the county boundaries from:
http://www.census.gov/geo/www/cob/co2000.html

Then you could use the symbols function to plot a star in the center of
each 
county (use get.Pcent from maptools to find the coordinates of the
centers).

Then just look for groups of counties with similar looking stars, or
stars that
are different from those close by (I would use the percentage spent in
each
category for the lengths of the star spokes).

Another graph that may prove interesting is the trilinear plot (see the
article
in Chance from the summer of 2002).  Combine your categories into 3
groups
(e.g. A&B vs. C&D vs. not spent; or A vs. B vs. all others) then plot
each county's
spending on the trilinear plot (functions to do the plot are:
triangle.plot in ade4,
triplot in klaR, or I have some code that I wrote (not on CRAN yet)).

Look for clusters of counties in these plots.

>>  I may treat the problem like a simple linear regression problem for
each
>>  category, but by definition, money spent in one category will take
away
>>  the amount of money that can be spent in any other category---and
each
>>  county is not allocated the same amount of money to spend.
>>  
>>  I have constructed proportions of amount spent on each category and
have
>>  conducted quasibinomial regression, on each dependent outcome but
that
>>  does not seem very convincing to me. 
>>  
>>  Would anyone have any advice about how to treat an outcome variable
of
>>  this sort?

Here are a couple of thoughts (there may be better options).

Assuming that you have some predictor (x) variables about each county:

use the multinom function in the nnet package, the idea being that each

dollar spent follows a multinomial with certain probabilities as to
which category
it will be spent in and the predictors tell you what the probabilities
are.

Similarly you could use package rpart to do a tree model, use the
category as the
outcome and the percentage spent on the category as the weights (each
county
would be spread accross 4 or 5 lines of the dataset with the predictors
replicated
on each line).  rpart gives the probabilities/proportions for each
category based
on splits of the predictor variables.


>>  Thanks for any hints!
>>  
>>  Jason
>>  
>>  
>>  -- 
>>  Jason W. Martinez, Gradaute Student
>>  University of California, Riverside
>>  Department of Sociology
>>  E-mail: jmartinez5 at verizon.net 
>>  

hope this helps,

Greg Snow, Ph.D.
Statistical Data Center
greg.snow at ihc.com
(801) 408-8111



From gunter.berton at gene.com  Wed Mar 23 19:04:06 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 23 Mar 2005 10:04:06 -0800
Subject: [R] nested random effects
In-Reply-To: <1111599227.11063.336.camel@localhost.localdomain>
Message-ID: <200503231804.j2NI46FD014229@compton.gene.com>

> 
> An interaction random effect/fixed effect is noted as 
> 
> random ~1|random/fixed
> 
> in your case random =~1|ID/FAM (but I don't uderstand why indiviuals
> withing families are fixed and and families are random, but there you
> go).
> 

1. Fixed effects cannot be nested within random effects. 

2. The "random" specification is backwards: nesting, |g1/g2/g3... , is outer
to inner and so FAM/ID


> Check out Pinheiro and Bates Ch1, especially pg 23 onwards.
> 

Indeed. See the Worker/Machine example on p. 24 for outer to inner nesting.

-- Bert Gunter



From HDoran at air.org  Wed Mar 23 19:33:24 2005
From: HDoran at air.org (Doran, Harold)
Date: Wed, 23 Mar 2005 13:33:24 -0500
Subject: [R] nested random effects
Message-ID: <88EAF3512A55DF46B06B1954AEF73F74084B504B@dc1ex2.air.org>

It should be random=~1|FAM/ID indicating individuals are nested within
families. 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Federico Calboli
Sent: Wednesday, March 23, 2005 12:34 PM
To: Shaw, Philip (NIH/NIMH)
Cc: r-help
Subject: Re: [R] nested random effects

On Wed, 2005-03-23 at 11:58 -0500, Shaw, Philip (NIH/NIMH) wrote:
> Hi
>  
> I am struggling with nested random effects and hope someone can help.
>  
> 
> 
> I have individuals (ID) who are nested within families (FAM).  I want 
> to model an outcome variable, and take account of the intercorrelation

> of individuals within each family.
>  
> I think this amounts to two random effects, one nested within the
other.
>  
> How can I model this in R?
>  
> So far I have tried using the library(nlme), and then
>  
> Y~ID, random=~1|ID*FAM,
>  

An interaction random effect/fixed effect is noted as 

random ~1|random/fixed

in your case random =~1|ID/FAM (but I don't uderstand why indiviuals
withing families are fixed and and families are random, but there you
go).

Check out Pinheiro and Bates Ch1, especially pg 23 onwards.

Cheers,

F 
-- 
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St Mary's Campus
Norfolk Place, London W2 1PG

Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From David.Ruau at rwth-aachen.de  Wed Mar 23 19:40:17 2005
From: David.Ruau at rwth-aachen.de (David Ruau)
Date: Wed, 23 Mar 2005 19:40:17 +0100
Subject: [R] Does R work in 64 bit on apple G5?
In-Reply-To: <Pine.A41.4.61b.0503230943040.164148@homer03.u.washington.edu>
References: <bda0ce399e1bbb6c2a8c53cd802ed94a@rwth-aachen.de>
	<Pine.A41.4.61b.0503230943040.164148@homer03.u.washington.edu>
Message-ID: <24ba4bb7b8ddb584baca0eb305aff3cd@rwth-aachen.de>

Thanks,
I was sure the pre-compile version was 32 bit but not if you compile it 
your self...
It give the same infos when you run gc() or .Machine$sizeof.pointer 
either on OS X client with a pre-compiled version or on OS X Server 
with a home compile version.
 > .Machine$sizeof.pointer
[1] 4
 > gc()
          used (Mb) gc trigger (Mb)
Ncells 140949  3.8     350000  9.4
Vcells  52967  0.5     786432  6.0

Did anybody use R with Xgrid?
I am trying but it's not so easy to send the R job to the controller...

David

On Mar 23, 2005, at 18:44, Thomas Lumley wrote:

> On Wed, 23 Mar 2005, David Ruau wrote:
>
>> Hi,
>>
>> I am working with R on 2xG5 1.8Ghz from Apple under 10.3.8
>> The G5 chip is 64 bits but does R run in 64 bit or 32 under OS X?
>> How can know?
>> I think it run in 32 bits... but not sure...
>
> Under the current OS X it runs 32bit.  You can tell by looking at
>      .Machine$sizeof.pointer
> which is 4.
>
> The next version of OS X is advertised as having full 64bit support so 
> this limitation will go away then.
>
> 	-thomas
>
>



From f.calboli at imperial.ac.uk  Wed Mar 23 20:00:47 2005
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Wed, 23 Mar 2005 19:00:47 +0000
Subject: [R] nested random effects
In-Reply-To: <200503231804.j2NI46FD014229@compton.gene.com>
References: <200503231804.j2NI46FD014229@compton.gene.com>
Message-ID: <1111604447.11063.341.camel@localhost.localdomain>

On Wed, 2005-03-23 at 10:04 -0800, Berton Gunter wrote:
> > 
> > An interaction random effect/fixed effect is noted as 
> > 
> > random ~1|random/fixed
> > 
> > in your case random =~1|ID/FAM (but I don't uderstand why indiviuals
> > withing families are fixed and and families are random, but there you
> > go).
> > 
> 
> 1. Fixed effects cannot be nested within random effects. 
> 
> 2. The "random" specification is backwards: nesting, |g1/g2/g3... , is outer
> to inner and so FAM/ID

The original question had 

Y~ID

so I assumed ID was/is fixed. I have my reservations on that, but who am
I to decide? it' not my data and anyway I have not seen it.

F
-- 
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St Mary's Campus
Norfolk Place, London W2 1PG

Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From gunter.berton at gene.com  Wed Mar 23 20:04:58 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 23 Mar 2005 11:04:58 -0800
Subject: [R] nested random effects
In-Reply-To: <1111599227.11063.336.camel@localhost.localdomain>
Message-ID: <200503231905.j2NJ4wRj017451@volta.gene.com>


I should have added that if you have only one Y observation per ID (within
family), then the ID variance component is residual error and the model
becomes (without any covariates)

Y~1, rand=~1|FAM

-- Bert


> On Wed, 2005-03-23 at 11:58 -0500, Shaw, Philip (NIH/NIMH) wrote:
> > Hi
> >  
> > I am struggling with nested random effects and hope someone 
> can help.
> >  
> > 
> > 
> > I have individuals (ID) who are nested within families 
> (FAM).  I want to
> > model an outcome variable, and take account of the 
> intercorrelation of
> > individuals within each family. 
> >  
> > I think this amounts to two random effects, one nested 
> within the other.
> >  
> > How can I model this in R?
> >  
> > So far I have tried using the library(nlme), and then
> >  
> > Y~ID, random=~1|ID*FAM, 
> >  
> 
> An interaction random effect/fixed effect is noted as 
> 
> random ~1|random/fixed
> 
> in your case random =~1|ID/FAM (but I don't uderstand why indiviuals
> withing families are fixed and and families are random, but there you
> go).
> 
> Check out Pinheiro and Bates Ch1, especially pg 23 onwards.
> 
> Cheers,
> 
> F 
> -- 
> Federico C. F. Calboli
> Department of Epidemiology and Public Health
> Imperial College, St Mary's Campus
> Norfolk Place, London W2 1PG
> 
> Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193
> 
> f.calboli [.a.t] imperial.ac.uk
> f.calboli [.a.t] gmail.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From nioniodesbois at yahoo.fr  Wed Mar 23 20:25:17 2005
From: nioniodesbois at yahoo.fr (Guillaume STORCHI)
Date: Wed, 23 Mar 2005 20:25:17 +0100 (CET)
Subject: [R] go to msn!!!!
Message-ID: <20050323192517.41585.qmail@web86908.mail.ukl.yahoo.com>

Some people think that this server is like msn messenger!

I see that lots of people talk about some uninteresting things like G5 stuff or
whatever, but nobody is able to think about real useRs' problems!


Guillaume Storchi



From JAROSLAW.W.TUSZYNSKI at saic.com  Wed Mar 23 21:09:29 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Wed, 23 Mar 2005 15:09:29 -0500
Subject: [R] Looking for function for Double to raw to double conversions
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD57F3FFE@us-arlington-0668.mail.saic.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050323/9d11cd00/attachment.pl

From sghosh at lexgen.com  Wed Mar 23 21:58:05 2005
From: sghosh at lexgen.com (Ghosh, Sandeep)
Date: Wed, 23 Mar 2005 14:58:05 -0600
Subject: [R] R on red hat 2.1 problem while trying to generate image
Message-ID: <2B47B68F97330841AC8C670749084A7D06C441@wdexchmb01.lexicon.lexgen.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050323/27b046be/attachment.pl

From mvida at mitre.org  Wed Mar 23 21:58:35 2005
From: mvida at mitre.org (Melanie Vida)
Date: Wed, 23 Mar 2005 15:58:35 -0500
Subject: [R] Gini's Importance Value  Variable = Inf 
Message-ID: <4241D87B.1010101@mitre.org>

Hi All,

In the script below, the importance measure for column 4 (ie 
MeanDecreaseGini) indicated "Inf" for V7.
Running the getTree command showed that "V7" had been selected at least 
twice in one of the trees for Random Forest. So the "Inf" command was 
not generated as a result of dividing the sum of the decreases by 0.

Any suggestions on what may be causing the Inf in "V7" would be helpful?
Thanks in advance,

-Melanie

---------i

 library(randomForest)

credit<-read.csv(url("ftp://ftp.ics.uci.edu/pub/machine-learning-databases/credit-screening/crx.data"), 
header=FALSE, na.string="?")

credit.rf <- randomForest(V16~., credit, imp=T, 
do.trace=100,na.action=na.omit)

imp <- round(importance(credit.rf), 2)

imp
 -     + MeanDecreaseAccuracy MeanDecreaseGini
V1   0.00  0.00                 0.00             0.00
V2   0.75  0.25                 0.55            19.92
V3   0.41  0.57                 0.46            22.13
V4   0.39  0.33                 0.33             4.93
V5   0.26  0.24                 0.21             0.60
V6   0.39  0.50                 0.40           -46.21
V7   0.91  0.59                 0.71              Inf
V8   1.35  1.35                 1.06            37.15
V9   0.00  0.00                 0.00             0.00
V10  0.00  0.00                 0.00             0.00
V11  1.65  1.59                 1.23            49.16
V12  0.00  0.00                 0.00             0.00
V13 -0.11 -0.10                -0.10             0.21
V14  0.82  0.57                 0.66            20.71
V15  1.36  1.02                 1.01            33.47

getTree(credit.rf, 1)

 left daughter right daughter split var split point status prediction
  [1,]             2              3        15    492.0000      1          0
  [2,]             4              5        11      2.5000      1          0
  [3,]             6              7         2     38.5000      1          0
  [4,]             8              9        14     83.0000      1          0
  [5,]            10             11         7    207.0000      1          0
  [6,]            12             13        11      0.5000      1          0
  [7,]             0              0         0      0.0000     -1          2
  [8,]            14             15         7    117.0000      1          0
  [9,]            16             17         8      3.0625      1          0
 [10,]            18             19         3      0.2700      1          0
 [11,]             0              0         0      0.0000     -1          2
 [12,]            20             21        15   4753.0000      1          0
 [13,]            22             23         2     37.0850      1          0
 [14,]            24             25        14      8.5000      1          0



From sue at xlsolutions-corp.com  Wed Mar 23 22:03:04 2005
From: sue at xlsolutions-corp.com (sue@xlsolutions-corp.com)
Date: Wed, 23 Mar 2005 14:03:04 -0700
Subject: [R] Courses***April R/Splus Advanced and Intermediate level courses
	by XLSolutions
Message-ID: <20050323210304.18172.qmail@webmail14.mesa1.secureserver.net>

Here are our April courses:

R/Splus Advanced Programming: March 31st - April 1st, San Francisco
http://www.xlsolutions-corp.com/Radv.htm


R/Splus Programming Techniques: April 14th - April 15th,  New York City
http://www.xlsolutions-corp.com/Rfund.htm


Microarrays Data Analysis with R/S+ and GGobi
http://www.xlolutions-corp.com/Rarrays.htm:   April 27th-28th, Princeton

Please email for our May & Summer schedule

Ask  for group discounts.
Email Sue Turner: sue at xlsolutions-corp.com
Phone: 206-686-1578
Visit us: www.xlsolutions-corp.com/training.htm
Please let us know if you and your colleagues are interested in this
classto take advantage of group discount. Register now to secure your
seat!



Cheers,
Elvis Miller, PhD
Manager Training.
XLSolutions Corporation
206 686 1578
www.xlsolutions-corp.com
elvis at xlsolutions-corp.com



From andy_liaw at merck.com  Wed Mar 23 22:14:03 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 23 Mar 2005 16:14:03 -0500
Subject: [R] Gini's Importance Value  Variable = Inf
Message-ID: <3A822319EB35174CA3714066D590DCD50994E8E2@usrymx25.merck.com>

That result looks fishy:  Not only there shouldn't be Inf, but there
shouldn't be negative values in that measure (look at V6).  I will look into
it.

I hope by now you realize that there's not much point in asking such
package-specific questions on R-help...  Not all package maintainers are on
R-help, and they are the best persons to ask package specific questions or
report bugs.

Andy

> From: Melanie Vida
> 
> Hi All,
> 
> In the script below, the importance measure for column 4 (ie 
> MeanDecreaseGini) indicated "Inf" for V7.
> Running the getTree command showed that "V7" had been 
> selected at least 
> twice in one of the trees for Random Forest. So the "Inf" command was 
> not generated as a result of dividing the sum of the decreases by 0.
> 
> Any suggestions on what may be causing the Inf in "V7" would 
> be helpful?
> Thanks in advance,
> 
> -Melanie
> 
> ---------i
> 
>  library(randomForest)
> 
> credit<-read.csv(url("ftp://ftp.ics.uci.edu/pub/machine-learni
> ng-databases/credit-screening/crx.data"), 
> header=FALSE, na.string="?")
> 
> credit.rf <- randomForest(V16~., credit, imp=T, 
> do.trace=100,na.action=na.omit)
> 
> imp <- round(importance(credit.rf), 2)
> 
> imp
>  -     + MeanDecreaseAccuracy MeanDecreaseGini
> V1   0.00  0.00                 0.00             0.00
> V2   0.75  0.25                 0.55            19.92
> V3   0.41  0.57                 0.46            22.13
> V4   0.39  0.33                 0.33             4.93
> V5   0.26  0.24                 0.21             0.60
> V6   0.39  0.50                 0.40           -46.21
> V7   0.91  0.59                 0.71              Inf
> V8   1.35  1.35                 1.06            37.15
> V9   0.00  0.00                 0.00             0.00
> V10  0.00  0.00                 0.00             0.00
> V11  1.65  1.59                 1.23            49.16
> V12  0.00  0.00                 0.00             0.00
> V13 -0.11 -0.10                -0.10             0.21
> V14  0.82  0.57                 0.66            20.71
> V15  1.36  1.02                 1.01            33.47
> 
> getTree(credit.rf, 1)
> 
>  left daughter right daughter split var split point status prediction
>   [1,]             2              3        15    492.0000     
>  1          0
>   [2,]             4              5        11      2.5000     
>  1          0
>   [3,]             6              7         2     38.5000     
>  1          0
>   [4,]             8              9        14     83.0000     
>  1          0
>   [5,]            10             11         7    207.0000     
>  1          0
>   [6,]            12             13        11      0.5000     
>  1          0
>   [7,]             0              0         0      0.0000     
> -1          2
>   [8,]            14             15         7    117.0000     
>  1          0
>   [9,]            16             17         8      3.0625     
>  1          0
>  [10,]            18             19         3      0.2700     
>  1          0
>  [11,]             0              0         0      0.0000     
> -1          2
>  [12,]            20             21        15   4753.0000     
>  1          0
>  [13,]            22             23         2     37.0850     
>  1          0
>  [14,]            24             25        14      8.5000     
>  1          0
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From rbertolusso at yahoo.com  Wed Mar 23 22:46:48 2005
From: rbertolusso at yahoo.com (Roberto Bertolusso)
Date: Wed, 23 Mar 2005 15:46:48 -0600
Subject: [R] Error in unitrootTest (fSeries)
Message-ID: <1111614408.9487.7.camel@localhost>

Hello, I am getting the following error message from unitrootTest.
Do you have any clue of what could be wrong.

Details: AMD64 (x86_64) Gentoo Linux system.


library(fSeries)
kmodel <- list(ar=c(.3,0,0,0,0.7,-.4*.7),d=1)
x=armaSim(nobs,model=kmodel)
unitrootTest(x,trend="c",statistic="t",method="adf",lags=2)
Error in file(file, "r") : unable to open connection
In addition: Warning message: 
cannot open file `library/fSeries/libs/.urc1.tab' 


Thank you very much
Roberto
-- 
Roberto Bertolusso <rbertolusso at yahoo.com>



From ripley at stats.ox.ac.uk  Wed Mar 23 23:15:02 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 23 Mar 2005 22:15:02 +0000 (GMT)
Subject: [R] Error in unitrootTest (fSeries)
In-Reply-To: <1111614408.9487.7.camel@localhost>
References: <1111614408.9487.7.camel@localhost>
Message-ID: <Pine.LNX.4.61.0503232210300.1947@gannet.stats>

On Wed, 23 Mar 2005, Roberto Bertolusso wrote:

> Hello, I am getting the following error message from unitrootTest.
> Do you have any clue of what could be wrong.

A bug in the package: please contact the maintainer.  This *may* work if 
you run in R_HOME.

Hint to Diethelm: use system.file("libs", ".urc1.tab", package="fSeries") 
to find the file in a location-independent way.

> Details: AMD64 (x86_64) Gentoo Linux system.
>
>
> library(fSeries)
> kmodel <- list(ar=c(.3,0,0,0,0.7,-.4*.7),d=1)
> x=armaSim(nobs,model=kmodel)
> unitrootTest(x,trend="c",statistic="t",method="adf",lags=2)
> Error in file(file, "r") : unable to open connection
> In addition: Warning message:
> cannot open file `library/fSeries/libs/.urc1.tab'

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From brett at hbrc.govt.nz  Wed Mar 23 23:25:01 2005
From: brett at hbrc.govt.nz (Brett Stansfield)
Date: Thu, 24 Mar 2005 10:25:01 +1200
Subject: [R] Complete Linkage Clustering techniques
Message-ID: <3542A1BF5AE1984D9FF577DA2CF8BA9868B15C@MSX2>

Dear R
I recently asked for a cluster analysis

Using
*	cluster.results <- hclust(iris.dist, method="complete")
*	but nothing happened i.e the previous scatterplot matrix still
showed up whereas I was expecting a dendogram.

Could it be that because I had used cutree before on the scatter plots that
it somehow mucked it up. I tried detach then attach and commenced making the
data matrix again and followed the procedures through.

Not sure what I've done wrong here, can anyone help me

brett stansfield



From jeaneid at chass.utoronto.ca  Wed Mar 23 23:49:29 2005
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Wed, 23 Mar 2005 17:49:29 -0500
Subject: [R] non-derivative based optimization and standard errors. 
Message-ID: <Pine.SGI.4.40.0503231746300.1023470-100000@origin.chass.utoronto.ca>

Hi AlL,

I ahve this problem that my objective function is discontinous in the
paramaters and I need to use methods such as nelder-mead to get around
this. My question is: How do i compute standard errors to a problem that
does not have  a gradient?


Any literature on this is greatly appreciated.


Jean,



From dana at accelrys.com  Thu Mar 24 01:09:11 2005
From: dana at accelrys.com (Dana Honeycutt)
Date: Wed, 23 Mar 2005 16:09:11 -0800
Subject: [R] Mapping actual to expected columns for princomp object
Message-ID: <OFC7A195BC.18928FD0-ON88256FCD.00838B6E-88256FCE.0000D605@accelrys.com>

I am working with data sets in which the number and order of columns
may vary, but each column is uniquely identified by its name.  E.g.,
one data set might have columns
        MW logP Num_Rings Num_H_Donors
while another has columns
        Num_Rings Num_Atoms Num_H_Donors logP MW

I would like to be able to perform a principal component analysis (PCA)
on one data set and save the PCA object to a file.  In a later R session, 
I would like to load the object and then apply the loadings to a new 
data set in order to compute the principal component (PC) values for 
each row of new data.

I am trying to use the princomp method in R to do this. (I started 
with prcomp, but found that there is no predict method for objects
created by prcomp.)  The problem is that when using predict on a
princomp object, R ignores the names of columns and simply assumes
that the column order is the same as in the original data frame used
to do the PCA.  (This contrasts, for example, with the behavior of a
model produced by lm, which is aware of column names in a data frame.)

What I think I need to do is this:

1. After reloading the princomp object, extract the names and order
of columns that it expects. (If you look at the loadings for the
object, you can see that this info is there, but I would like to 
get at it directly somehow.)

2. Reorder the columns in the new data set to correspond to this
expected order, and remove any extra columns.

3. Use the predict method to predict the PC values for the new data set.

Is this the best approach to achieve what I am attempting?

If so, can anyone tell me how to accomplish steps 1 and 2 above?

Thanks,
Dana Honeycutt

P.S. Here's a script that demonstrates the problem:

x1 <- rnorm(10)
x2 <- rnorm(10)
y <- rnorm(10)

frx <- data.frame(x1,x2)
frxy <- data.frame(x1,x2,y)

lm1 <- lm(y~x1+x2,frxy)
pca1 <- princomp(frx)

rm(x1,x2,y,frx,frxy)

z1 <- rnorm(10)
z2 <- rnorm(10)
frz <- data.frame(z1,z2)

predict(lm1, frz)  # gives error: Object "x1" not found
predict(pca1, frz) # gives no error, indicating column names ignored

z3 <- rnorm(10)
fr3z <- data.frame(frz,z3)
predict(pca1,fr3z) # gives error due to unexpected number of columns

loadings(pca1) # shows linear combos of variables corresponding to PCs



From garey at biostat.ucsf.edu  Thu Mar 24 01:27:34 2005
From: garey at biostat.ucsf.edu (mark garey)
Date: Wed, 23 Mar 2005 16:27:34 -0800
Subject: [R] parallel r job on sun gridengine
Message-ID: <08f00f7b2abb05b11d5e71fcea66dc97@biostat.ucsf.edu>

greetings all,
this may be the wrong forum for my problem - if so please advise.
i am addressing this list because of an error i am getting from the snow
library rmpi (i think) after lam has booted the mpi nodes

i have a script (provided by a faculty member - i am not an R user but  
have the task
of making it run scucessfully as a batch job on the gridengine) that  
runs with success
as an interactive shell script, can be run interactively using qrsh on  
a sun gridengine,
but fails when submitted to the gridengine as a batch job. the lam/mpi  
nodes boot and
shutdown properly via a parallel environment defined in the gridengine.
where the job falls flat is when the snow RMPInode.sh script is called -
or so it seems. the error generated is:
___
/usr/local/lib/R.framework/Versions/2.0.0/Resources/library/snow/ 
RMPInode.sh: line 9: 13465 Trace/BPT trap          (core dumped)  
${RPROG:-R} --vanilla  >${OUT:-/dev/null} 2>&1 <<EOF

library(Rmpi)
library(snow)

runMPIslave()
EOF
___

environment is darwin (panther 10.3.8), r version is 2.0.0, gridengine  
version is 5.3.

i get the feeling this is not an r problem, but if you used r in batch  
mode in a parallel environment
maybe you could point me in the right direction.i also realize that  
many factors could contibute to this
error, but to be able to rule out r (or the snow library) would be  
helpful.

thanks in advance,

mark+ \ ucsf biostat

--
mark garey
ucsf department of epidemiology and biostatistics
500 parnassus ave, mu420w
san francisco, ca. 94143
415-502-8870



From jeff.hamann at forestinformatics.com  Thu Mar 24 02:07:20 2005
From: jeff.hamann at forestinformatics.com (Jeff D. Hamann)
Date: Wed, 23 Mar 2005 17:07:20 -0800 (PST)
Subject: [R] summing values as image
Message-ID: <1411.128.193.139.125.1111626440.squirrel@www.forestinformatics.com>

I'm trying to summarize irregularly spaced data (in data.frame with x,y,z)
and need to sum (not average as the as.image() function in fields does)
and I'm not sure if there is a function in on of the packages or if I'm
going to need to string a few functions together like fields::as.image()
and fields::image.count() to get what I need or if I should simply write
my own.

suggestions?


-- 
Jeff D. Hamann
Forest Informatics, Inc.
PO Box 1421
Corvallis, Oregon 97339-1421
phone 541-754-1428
fax 541-752-0288
jeff.hamann at forestinformatics.com
http://www.forestinformatics.com



From sdavis2 at mail.nih.gov  Thu Mar 24 02:36:32 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Wed, 23 Mar 2005 20:36:32 -0500
Subject: [R] Complete Linkage Clustering techniques
References: <3542A1BF5AE1984D9FF577DA2CF8BA9868B15C@MSX2>
Message-ID: <000c01c53011$e8777f90$1f6df345@WATSON>


----- Original Message ----- 
From: "Brett Stansfield" <brett at hbrc.govt.nz>
To: "R help (E-mail)" <R-help at stat.math.ethz.ch>
Sent: Wednesday, March 23, 2005 5:25 PM
Subject: [R] Complete Linkage Clustering techniques


> Dear R
> I recently asked for a cluster analysis
>
> Using
> * cluster.results <- hclust(iris.dist, method="complete")
> * but nothing happened i.e the previous scatterplot matrix still
> showed up whereas I was expecting a dendogram.
>
> Could it be that because I had used cutree before on the scatter plots 
> that
> it somehow mucked it up. I tried detach then attach and commenced making 
> the
> data matrix again and followed the procedures through.
>
> Not sure what I've done wrong here, can anyone help me

You need to plot the result.

plot(cluster.results)

Sean



From brett at hbrc.govt.nz  Thu Mar 24 04:42:12 2005
From: brett at hbrc.govt.nz (Brett Stansfield)
Date: Thu, 24 Mar 2005 15:42:12 +1200
Subject: [R] font sizes for row.names of dendograms
Message-ID: <3542A1BF5AE1984D9FF577DA2CF8BA9868B163@MSX2>

Dear R
I recently performed a cluster analysis. It produced the dendogram no
problem but unfortunately the font size of the row.names were all cluttered
due to their large size
So I tried to change the font size using
plclust(cluster.results, labels=iris$specie, cex=0.8)

and R came back to me saying
Error in plclust(cluster.results, labels = iris$specie, cex = 0.8) : 
        unused argument(s) (cex ...)
>
what am I doing wrong here

brett stansfield



From ggrothendieck at myway.com  Thu Mar 24 05:04:41 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 24 Mar 2005 04:04:41 +0000 (UTC)
Subject: [R] extracting numerical data from text field
References: <42416713.4070504@ebi-wasser.uni-karlsruhe.de>
Message-ID: <loom.20050324T050029-583@post.gmane.org>

Luis Tercero <luis.tercero <at> ebi-wasser.uni-karlsruhe.de> writes:

: 
: I have imported a data frame that looks like this:
: 
:            Measurement.Date.and.Time Z.Average..nm.   PDI
: 572 Dienstag, 22. M?rz 2005 11:05:59          366,4 0,468
: 573 Dienstag, 22. M?rz 2005 11:09:30          353,4 0,532
: 574 Dienstag, 22. M?rz 2005 11:12:59            343 0,428
: 575 Dienstag, 22. M?rz 2005 11:16:28          354,1 0,433
: 576 Dienstag, 22. M?rz 2005 11:19:59          341,9 0,349
: 577 Dienstag, 22. M?rz 2005 11:23:29          334,9 0,429
: ...
: 
: Would there be a way to extract the time in numerical form from the
: Measurement.Date.and.Time field?  What I would like to do is a time
: series where, for example,
: Dienstag, 22. M?rz 2005 11:05:59 is time=0 min
: Dienstag, 22. M?rz 2005 11:09:30 is time=3.5 min, etc.
: 
: Thank you in advance for your help.
: 
: Luis

Make sure that you are in a German locale:

  # this works on Windows XP.  On other OS, "ge" code may differ.
  Sys.setlocale("LC_TIME", "ge") 

Then if DF is your data frame use strptime (see ?strptime for more
on the % codes):

  dat <- strptime(DF[,1], "%A, %d. %B %Y %H:%M:%S")
  dat - dat[1]   # difference in time since the first date time



From ggrothendieck at myway.com  Thu Mar 24 05:13:04 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 24 Mar 2005 04:13:04 +0000 (UTC)
Subject: [R] extracting numerical data from text field
References: <42416713.4070504@ebi-wasser.uni-karlsruhe.de>
	<loom.20050324T050029-583@post.gmane.org>
Message-ID: <loom.20050324T051006-322@post.gmane.org>

Gabor Grothendieck <ggrothendieck <at> myway.com> writes:

> 
> Luis Tercero <luis.tercero <at> ebi-wasser.uni-karlsruhe.de> writes:
> 
> : 
> : I have imported a data frame that looks like this:
> : 
> :            Measurement.Date.and.Time Z.Average..nm.   PDI
> : 572 Dienstag, 22. M?rz 2005 11:05:59          366,4 0,468
> : 573 Dienstag, 22. M?rz 2005 11:09:30          353,4 0,532
> : 574 Dienstag, 22. M?rz 2005 11:12:59            343 0,428
> : 575 Dienstag, 22. M?rz 2005 11:16:28          354,1 0,433
> : 576 Dienstag, 22. M?rz 2005 11:19:59          341,9 0,349
> : 577 Dienstag, 22. M?rz 2005 11:23:29          334,9 0,429
> : ...
> : 
> : Would there be a way to extract the time in numerical form from the
> : Measurement.Date.and.Time field?  What I would like to do is a time
> : series where, for example,
> : Dienstag, 22. M?rz 2005 11:05:59 is time=0 min
> : Dienstag, 22. M?rz 2005 11:09:30 is time=3.5 min, etc.
> : 
> : Thank you in advance for your help.
> : 
> : Luis
> 
> Make sure that you are in a German locale:
> 
>   # this works on Windows XP.  On other OS, "ge" code may differ.
>   Sys.setlocale("LC_TIME", "ge") 
> 
> Then if DF is your data frame use strptime (see ?strptime for more
> on the % codes):
> 
>   dat <- strptime(DF[,1], "%A, %d. %B %Y %H:%M:%S")
>   dat - dat[1]   # difference in time since the first date time

One other comment.

I assumed your data time field is stored as character in the data
frame.  If its stored as a factor then you need to convert it to
character first using as.character.  If its already stored as a 
POSIXct date time then all you have to do is subtract off the
first one.  (Note that if you put the output of dput(DF) in your
post then people will be able to exactly recreate your data frame
and then know what you have.)

Also, RNews 4/1 has a table with lots of date time processing
idioms.



From kerryrekky at yahoo.com  Thu Mar 24 05:31:23 2005
From: kerryrekky at yahoo.com (Kerry Bush)
Date: Wed, 23 Mar 2005 20:31:23 -0800 (PST)
Subject: [R] Prediction using GAM
In-Reply-To: 6667
Message-ID: <20050324043123.68955.qmail@web51809.mail.yahoo.com>


Recently I was using GAM and couldn't help noticing
the following incoherence in prediction:

> data(gam.data)
> data(gam.newdata)
> gam.object <- gam(y ~ s(x,6) + z, data=gam.data)
> predict(gam.object)[1]
        1 
0.8017407 
>
predict(gam.object,data.frame(x=gam.data$x[1],z=gam.data$z[1]))
        1 
0.1668452 

I would expect that using two types of predict
arguments should give me the same results.
When I used this to predict a new data set then it
seems OK:

>
predict(gam.object,data.frame(x=gam.newdata$x[1],z=gam.newdata$z[1]))
        1 
0.4832136 
> predict(gam.object,gam.newdata)[1]
        1 
0.4832136 

Could anybody explain the strange behavior of
predict.gam function?

Thanks,
Kai



From spencer.graves at pdf.com  Thu Mar 24 06:11:10 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 23 Mar 2005 22:11:10 -0700
Subject: [R] non-derivative based optimization and standard errors.
In-Reply-To: <Pine.SGI.4.40.0503231746300.1023470-100000@origin.chass.utoronto.ca>
References: <Pine.SGI.4.40.0503231746300.1023470-100000@origin.chass.utoronto.ca>
Message-ID: <42424BEE.4070407@pdf.com>

      Have you considered bootstrap or Monte Carlo? 

      spencer graves

Jean Eid wrote:

>Hi AlL,
>
>I ahve this problem that my objective function is discontinous in the
>paramaters and I need to use methods such as nelder-mead to get around
>this. My question is: How do i compute standard errors to a problem that
>does not have  a gradient?
>
>
>Any literature on this is greatly appreciated.
>
>
>Jean,
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From Tom.Mulholland at dpi.wa.gov.au  Thu Mar 24 07:06:31 2005
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Thu, 24 Mar 2005 14:06:31 +0800
Subject: [R] font sizes for row.names of dendograms
Message-ID: <33F91FB3FDF42E4180428AC66A5CF30B02D3BAA9@afhex01.dpi.wa.gov.au>

The error message states that you are passing a parameter called cex which has not been used. If you look at ?plclust more closely you will see it does not have cex parameter. However the S3 method for class hclust, plot, does?


So does this help?
hc <- hclust(dist(USArrests), "ave")
plot(hc,cex = 0.5)

Tom


> -----Original Message-----
> From: Brett Stansfield [mailto:brett at hbrc.govt.nz]
> Sent: Thursday, 24 March 2005 11:42 AM
> To: R help (E-mail)
> Subject: [R] font sizes for row.names of dendograms
> 
> 
> Dear R
> I recently performed a cluster analysis. It produced the dendogram no
> problem but unfortunately the font size of the row.names were 
> all cluttered
> due to their large size
> So I tried to change the font size using
> plclust(cluster.results, labels=iris$specie, cex=0.8)
> 
> and R came back to me saying
> Error in plclust(cluster.results, labels = iris$specie, cex = 0.8) : 
>         unused argument(s) (cex ...)
> >
> what am I doing wrong here
> 
> brett stansfield
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From mmmm at st.jyu.fi  Thu Mar 24 08:19:48 2005
From: mmmm at st.jyu.fi (Markku Mielityinen)
Date: Thu, 24 Mar 2005 09:19:48 +0200
Subject: [R] Robust multivariate regression with rlm
Message-ID: <000601c53041$e038bf30$e101a8c0@MARKKUNOTEBOOK>

Dear Group,

I am having trouble with using rlm on multivariate data sets. When I
call rlm I get 

Error in lm.wfit(x, y, w, method = "qr") : 
        incompatible dimensions

lm on the same data sets seem to work well (see code example). Am I
doing something wrong?

I have already browsed through the forums and google but could not find
any related discussions.

I use Windows XP and R Version 2.0.1  (2004-11-15) (if that makes a
difference).

Example code:

> Mx
          [,1]      [,2]
[1,]  49.10899  45.75513
[2,] 505.92018  48.81037
[3,] 973.30659  50.28478
[4,]  55.99533 508.94504
[5,] 964.96028 513.69579
[6,]  48.25670 975.94972
[7,] 510.21291 967.62767
[8,] 977.12363 978.29216
> My
     [,1] [,2]
[1,]   50   50
[2,]  512   50
[3,]  974   50
[4,]   50  512
[5,]  974  512
[6,]   50  974
[7,]  512  974
[8,]  974  974
> model<-lm(My~Mx)
> model

Call:
lm(formula = My ~ Mx)

Coefficients:
             [,1]       [,2]     
(Intercept)   0.934727   3.918421
Mx1           1.003517  -0.004202
Mx2          -0.002624   0.998155

> model<-rlm(My~Mx)
Error in lm.wfit(x, y, w, method = "qr") : 
        incompatible dimensions
> model<-rlm(My~Mx,psi=psi.bisquare)
Error in lm.wfit(x, y, w, method = "qr") : 
        incompatible dimensions

Another example (this one seems to work):

> Mx<-matrix(c(0,0,1,0,0,1),ncol=2,byrow=TRUE)+1
> My<-matrix(c(0,0,1,1,-1,1),ncol=2,byrow=TRUE)+1
> model<-rlm(My~Mx)
> model
Call:
rlm(formula = My ~ Mx)
Converged in 0 iterations

Coefficients:
            [,1] [,2]
(Intercept)    1   -1
Mx1            1    1
Mx2           -1    1

Degrees of freedom: 6 total; 0 residual
Scale estimate: 0

Best regards,
        Markku Mielityinen



From ligges at statistik.uni-dortmund.de  Thu Mar 24 08:43:55 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 24 Mar 2005 08:43:55 +0100
Subject: [R] R on red hat 2.1 problem while trying to generate image
In-Reply-To: <2B47B68F97330841AC8C670749084A7D06C441@wdexchmb01.lexicon.lexgen.com>
References: <2B47B68F97330841AC8C670749084A7D06C441@wdexchmb01.lexicon.lexgen.com>
Message-ID: <42426FBB.2070801@statistik.uni-dortmund.de>

Ghosh, Sandeep wrote:

> Running R 1.9.1 under red hat 2.1 version

Please upgrade.


> When I try to generate an image, we get an error as in the following
> 
> plot(rnorm(100))
> Error in PS(file, old$paper, old$family, old$encoding, old$bg, old$fg,  : 
>         unable to start device PostScript
> In addition: Warning message: 
> cannot open `postscript' file argument `Rplots.ps'

Do you have write permission in the current working directory?
If not, use postscript() explicitly.

Uwe Ligges


> If anyone can throw some light or any pointers into why we are facing this problem then it would be really helpful. 
> 
> Thanks,
> Sandeep.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From r at swisscarto.ch  Thu Mar 24 08:46:28 2005
From: r at swisscarto.ch (Christian Kaiser)
Date: Thu, 24 Mar 2005 08:46:28 +0100
Subject: [R] Does R work in 64 bit on apple G5?
In-Reply-To: <24ba4bb7b8ddb584baca0eb305aff3cd@rwth-aachen.de>
References: <bda0ce399e1bbb6c2a8c53cd802ed94a@rwth-aachen.de>
	<Pine.A41.4.61b.0503230943040.164148@homer03.u.washington.edu>
	<24ba4bb7b8ddb584baca0eb305aff3cd@rwth-aachen.de>
Message-ID: <95a322100c1375d85e9fb59e28474f49@swisscarto.ch>

Hi,

I never used XGrid with R. But did you have a look at the Apple lists?
For example: 
<http://lists.apple.com/archives/xgrid-users/2004/Aug/msg00005.html>
Seems to work for them.

Christian

Le 23 mars 05, ? 19:40, David Ruau a ?crit :

> Thanks,
> I was sure the pre-compile version was 32 bit but not if you compile 
> it your self...
> It give the same infos when you run gc() or .Machine$sizeof.pointer 
> either on OS X client with a pre-compiled version or on OS X Server 
> with a home compile version.
> > .Machine$sizeof.pointer
> [1] 4
> > gc()
>          used (Mb) gc trigger (Mb)
> Ncells 140949  3.8     350000  9.4
> Vcells  52967  0.5     786432  6.0
>
> Did anybody use R with Xgrid?
> I am trying but it's not so easy to send the R job to the controller...
>
> David
>
> On Mar 23, 2005, at 18:44, Thomas Lumley wrote:
>
>> On Wed, 23 Mar 2005, David Ruau wrote:
>>
>>> Hi,
>>>
>>> I am working with R on 2xG5 1.8Ghz from Apple under 10.3.8
>>> The G5 chip is 64 bits but does R run in 64 bit or 32 under OS X?
>>> How can know?
>>> I think it run in 32 bits... but not sure...
>>
>> Under the current OS X it runs 32bit.  You can tell by looking at
>>      .Machine$sizeof.pointer
>> which is 4.
>>
>> The next version of OS X is advertised as having full 64bit support 
>> so this limitation will go away then.
>>
>> 	-thomas
>>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
>



From Bill.Venables at csiro.au  Thu Mar 24 08:52:43 2005
From: Bill.Venables at csiro.au (Bill.Venables@csiro.au)
Date: Thu, 24 Mar 2005 18:52:43 +1100
Subject: [R] Robust multivariate regression with rlm
Message-ID: <B998A44C8986644EA8029CFE6396A9241B2F4C@exqld2-bne.qld.csiro.au>

lm works for multivariate responses
rlm does not - check what the help file says about the response.

That's about it, really.

Bill Venables.

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Markku
Mielityinen
Sent: Thursday, 24 March 2005 5:20 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Robust multivariate regression with rlm


Dear Group,

I am having trouble with using rlm on multivariate data sets. When I
call rlm I get 

Error in lm.wfit(x, y, w, method = "qr") : 
        incompatible dimensions

lm on the same data sets seem to work well (see code example). Am I
doing something wrong?

I have already browsed through the forums and google but could not find
any related discussions.

I use Windows XP and R Version 2.0.1  (2004-11-15) (if that makes a
difference).

Example code:

> Mx
          [,1]      [,2]
[1,]  49.10899  45.75513
[2,] 505.92018  48.81037
[3,] 973.30659  50.28478
[4,]  55.99533 508.94504
[5,] 964.96028 513.69579
[6,]  48.25670 975.94972
[7,] 510.21291 967.62767
[8,] 977.12363 978.29216
> My
     [,1] [,2]
[1,]   50   50
[2,]  512   50
[3,]  974   50
[4,]   50  512
[5,]  974  512
[6,]   50  974
[7,]  512  974
[8,]  974  974
> model<-lm(My~Mx)
> model

Call:
lm(formula = My ~ Mx)

Coefficients:
             [,1]       [,2]     
(Intercept)   0.934727   3.918421
Mx1           1.003517  -0.004202
Mx2          -0.002624   0.998155

> model<-rlm(My~Mx)
Error in lm.wfit(x, y, w, method = "qr") : 
        incompatible dimensions
> model<-rlm(My~Mx,psi=psi.bisquare)
Error in lm.wfit(x, y, w, method = "qr") : 
        incompatible dimensions

Another example (this one seems to work):

> Mx<-matrix(c(0,0,1,0,0,1),ncol=2,byrow=TRUE)+1
> My<-matrix(c(0,0,1,1,-1,1),ncol=2,byrow=TRUE)+1
> model<-rlm(My~Mx)
> model
Call:
rlm(formula = My ~ Mx)
Converged in 0 iterations

Coefficients:
            [,1] [,2]
(Intercept)    1   -1
Mx1            1    1
Mx2           -1    1

Degrees of freedom: 6 total; 0 residual
Scale estimate: 0

Best regards,
        Markku Mielityinen

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Thu Mar 24 09:00:48 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Mar 2005 08:00:48 +0000 (GMT)
Subject: [R] Prediction using GAM
In-Reply-To: <20050324043123.68955.qmail@web51809.mail.yahoo.com>
References: <20050324043123.68955.qmail@web51809.mail.yahoo.com>
Message-ID: <Pine.LNX.4.61.0503240750210.8159@gannet.stats>

R has *two* gam() functions in contributed packages 'mgcv' and 'gam'. 
Which is this?

Please see the posting guide and provide a reproducible example.

If this is package 'gam', prediction difficulties of this sort for the S 
version are discussed in the White Book, MASS and elsewhere (but I recall 
reading that they did not apply to the R version).


On Wed, 23 Mar 2005, Kerry Bush wrote:

> Recently I was using GAM and couldn't help noticing
> the following incoherence in prediction:
>
>> data(gam.data)
>> data(gam.newdata)

It is unusual to use data() on your own objects, but we cannot reproduce 
what you did without data.

>> gam.object <- gam(y ~ s(x,6) + z, data=gam.data)
>> predict(gam.object)[1]
>        1
> 0.8017407
>>
> predict(gam.object,data.frame(x=gam.data$x[1],z=gam.data$z[1]))
>        1
> 0.1668452
>
> I would expect that using two types of predict
> arguments should give me the same results.
> When I used this to predict a new data set then it
> seems OK:
>
>>
> predict(gam.object,data.frame(x=gam.newdata$x[1],z=gam.newdata$z[1]))
>        1
> 0.4832136
>> predict(gam.object,gam.newdata)[1]
>        1
> 0.4832136
>
> Could anybody explain the strange behavior of
> predict.gam function?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From nioniodesbois at yahoo.fr  Thu Mar 24 09:01:41 2005
From: nioniodesbois at yahoo.fr (Guillaume STORCHI)
Date: Thu, 24 Mar 2005 09:01:41 +0100 (CET)
Subject: [R] Sorry everyone
Message-ID: <20050324080142.83305.qmail@web86903.mail.ukl.yahoo.com>

Ok, sorry for the critics, but I just find that sometimes some important
subjects are rejected, and others are dicussed with intensity yet they are not
that relevant, that's it!

All apologise

Guillaume Storchi



From schouwla at yahoo.com  Thu Mar 24 09:11:34 2005
From: schouwla at yahoo.com (Lars Schouw)
Date: Thu, 24 Mar 2005 00:11:34 -0800 (PST)
Subject: [R] build failed of package
Message-ID: <20050324081134.86569.qmail@web50304.mail.yahoo.com>

I am trying to install the rpvm package doing this:

C:\R\rw2000\bin>rcmd install rpvm_0.6-2.tar.gz

'.' is not recognized as an internal or external
command,
operable program or batch file.
'.' is not recognized as an internal or external
command,
operable program or batch file.
make: *** /rpvm: No such file or directory.  Stop.
make: *** [pkg-rpvm] Error 2
*** Installation of rpvm failed ***

Removing 'C:/R/rw2000/library/rpvm'

What does this error message tell me? 

Regards
Lars Schouw



From ripley at stats.ox.ac.uk  Thu Mar 24 09:12:30 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Mar 2005 08:12:30 +0000 (GMT)
Subject: [R] Robust multivariate regression with rlm
In-Reply-To: <B998A44C8986644EA8029CFE6396A9241B2F4C@exqld2-bne.qld.csiro.au>
References: <B998A44C8986644EA8029CFE6396A9241B2F4C@exqld2-bne.qld.csiro.au>
Message-ID: <Pine.LNX.4.61.0503240804240.8159@gannet.stats>

On Thu, 24 Mar 2005 Bill.Venables at csiro.au wrote:

> lm works for multivariate responses
> rlm does not - check what the help file says about the response.
>
> That's about it, really.

Actually lm() works for multiple responses, that is it fits each column of 
the response separately by least squares.  It does not do multivariate 
regression in any real sense.

You can apply rlm to each column of the response, just as lm does. Because 
different outliers will appear in each column, there is no benefit in 
doing the columns in parallel as lm can do.

> -----Original Message-----
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Markku Mielityinen
> Sent: Thursday, 24 March 2005 5:20 PM
>
> I am having trouble with using rlm on multivariate data sets. When I
> call rlm I get
>
> Error in lm.wfit(x, y, w, method = "qr") :
>        incompatible dimensions
>
> lm on the same data sets seem to work well (see code example). Am I
> doing something wrong?

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From blindglobe at gmail.com  Thu Mar 24 09:15:17 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Thu, 24 Mar 2005 09:15:17 +0100
Subject: [R] build failed of package
In-Reply-To: <20050324081134.86569.qmail@web50304.mail.yahoo.com>
References: <20050324081134.86569.qmail@web50304.mail.yahoo.com>
Message-ID: <1abe3fa9050324001550d4a655@mail.gmail.com>

Looks like you are trying to install source tarball on Windows without
the relevant toolset (compiler, etc)?


On Thu, 24 Mar 2005 00:11:34 -0800 (PST), Lars Schouw
<schouwla at yahoo.com> wrote:
> I am trying to install the rpvm package doing this:
> 
> C:\R\rw2000\bin>rcmd install rpvm_0.6-2.tar.gz
> 
> '.' is not recognized as an internal or external
> command,
> operable program or batch file.
> '.' is not recognized as an internal or external
> command,
> operable program or batch file.
> make: *** /rpvm: No such file or directory.  Stop.
> make: *** [pkg-rpvm] Error 2
> *** Installation of rpvm failed ***
> 
> Removing 'C:/R/rw2000/library/rpvm'
> 
> What does this error message tell me?
> 
> Regards
> Lars Schouw
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
best,
-tony

"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).

A.J. Rossini
blindglobe at gmail.com



From guillaume.allain at cbconseil.com  Thu Mar 24 09:43:56 2005
From: guillaume.allain at cbconseil.com (guillaume allain)
Date: Thu, 24 Mar 2005 09:43:56 +0100
Subject: [R] problem with pdf() on Mac Os X
Message-ID: <DC22ED15-9C40-11D9-A404-0050E499F31C@cbconseil.com>

Hello R helpers,

I am quite new as a R user, and even more on a Mac Os. I am running R 
under Emacs 21.3.30.5 through ESS.

I have some problems with the pdf() device :  when sent to it, plots 
don't come out with any
labels, titles or whatever written. I don't have that problem when 
plots are sent to X11 or postscript devices.

As pdf is the native format on Mac Os X, i find it sad to have to go 
through .ps then .pdf using ps2pdf... Here's my R version

platform powerpc-apple-darwin6.8
arch     powerpc
os       darwin6.8
system   powerpc, darwin6.8
status
major    2
minor    0.1
year     2004
month    11
day      15
language R
 >

______________________________
Guillaume Allain
Carte Blanche Conseil
47 rue de Lancry 75010



From ligges at statistik.uni-dortmund.de  Thu Mar 24 10:29:00 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 24 Mar 2005 10:29:00 +0100
Subject: [R] build failed of package
In-Reply-To: <1abe3fa9050324001550d4a655@mail.gmail.com>
References: <20050324081134.86569.qmail@web50304.mail.yahoo.com>
	<1abe3fa9050324001550d4a655@mail.gmail.com>
Message-ID: <4242885C.5060709@statistik.uni-dortmund.de>

A.J. Rossini wrote:

> Looks like you are trying to install source tarball on Windows without
> the relevant toolset (compiler, etc)?


Tony,

sorry, but your answer is too easy:

Obviously, Lars Schouw has not *exactly* followed the instructions on 
how to install contributed source packages. If he has done so, he should 
at first try with a "simple" package, e.g. one that has a binary on CRAN.

BUT: Lars has to modify rpvm quite extensively in order to get it 
compiled for Windows (in particular - at least! - Makevars.win). And you 
as one of the authors are now asked to give some hints how to proceed.

Uwe



> 
> On Thu, 24 Mar 2005 00:11:34 -0800 (PST), Lars Schouw
> <schouwla at yahoo.com> wrote:
> 
>>I am trying to install the rpvm package doing this:
>>
>>C:\R\rw2000\bin>rcmd install rpvm_0.6-2.tar.gz
>>
>>'.' is not recognized as an internal or external
>>command,
>>operable program or batch file.
>>'.' is not recognized as an internal or external
>>command,
>>operable program or batch file.
>>make: *** /rpvm: No such file or directory.  Stop.
>>make: *** [pkg-rpvm] Error 2
>>*** Installation of rpvm failed ***
>>
>>Removing 'C:/R/rw2000/library/rpvm'
>>
>>What does this error message tell me?
>>
>>Regards
>>Lars Schouw
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
> 
>



From ligges at statistik.uni-dortmund.de  Thu Mar 24 10:34:43 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 24 Mar 2005 10:34:43 +0100
Subject: [R] replace values in a matrix subject to boolean condition
In-Reply-To: <20050323141449.75181.qmail@web25810.mail.ukl.yahoo.com>
References: <20050323141449.75181.qmail@web25810.mail.ukl.yahoo.com>
Message-ID: <424289B3.4000503@statistik.uni-dortmund.de>

Werner Wernersen wrote:

> Hi everybody!
> 
> I am sorry to bother you with a question so simple but
> I think there might be a 
> better solution:
> I have a matrix of size 360x501 where I want to check
> the value of each 5th 
> column of each row and replace it (and the 6th, 7th,
> 8th column) by zero if the 
> value is less than 1000. I have written a double loop
> to do that but that 
> requires a lot of time.
> 
> Is there a faster way to achieve this?


Two ways to interpret your question:

1) if col5 < 100 replace col5 & col6 & col7 & col8 by 0:

    X[X[,5] < 1000, 5:8] <- 0


2) if col5 < 100 replace col5 by 0, if col6 < 100 replace col6 by 0, ...:


for(i in 5:8)
    X[X[,i] < 1000, i] <- 0

Uwe Ligges





> Thanks,
>    Werner
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Thu Mar 24 11:08:01 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 24 Mar 2005 11:08:01 +0100
Subject: [R] build failed of package
In-Reply-To: <4242885C.5060709@statistik.uni-dortmund.de>
References: <20050324081134.86569.qmail@web50304.mail.yahoo.com>
	<1abe3fa9050324001550d4a655@mail.gmail.com>
	<4242885C.5060709@statistik.uni-dortmund.de>
Message-ID: <x2d5tpqrum.fsf@turmalin.kubism.ku.dk>

Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:

> A.J. Rossini wrote:
> 
> > Looks like you are trying to install source tarball on Windows without
> > the relevant toolset (compiler, etc)?
> 
> 
> Tony,
> 
> sorry, but your answer is too easy:
> 
> Obviously, Lars Schouw has not *exactly* followed the instructions on
> how to install contributed source packages. If he has done so, he
> should at first try with a "simple" package, e.g. one that has a
> binary on CRAN.
> 
> BUT: Lars has to modify rpvm quite extensively in order to get it
> compiled for Windows (in particular - at least! - Makevars.win). And
> you as one of the authors are now asked to give some hints how to
> proceed.

But trying to execute "." like that (and not as a bash internal)
suggests that Lars is not even set up to pick up the bash shell at the
appropriate point, so perhaps he needs to get the configuration right
before messing with rpvm makefiles?

> >>I am trying to install the rpvm package doing this:
> >>
> >>C:\R\rw2000\bin>rcmd install rpvm_0.6-2.tar.gz
> >>
> >>'.' is not recognized as an internal or external
> >>command,
> >>operable program or batch file.
> >>'.' is not recognized as an internal or external
> >>command,
> >>operable program or batch file.
....

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From emmanuelle.comets at bch.ap-hop-paris.fr  Thu Mar 24 11:01:55 2005
From: emmanuelle.comets at bch.ap-hop-paris.fr (Emmanuelle Comets)
Date: Thu, 24 Mar 2005 11:01:55 +0100
Subject: [R] Problem loading library Design
Message-ID: <42429013.9000108@bch.ap-hop-paris.fr>

I have used library Design (Frank Harrell) in the 
past but when I tried this week, I get :
 > library(Design)
Error in eval(expr, envir, enclos) : Object 
"formula.default" not found

I updated to the latest version of the library 
(2.0) with the same result. My version of R may 
not be the latest but it's recent (and I probably 
changed since using Design for the last time) :

 > version
          _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    9.1
year     2004
month    06
day      21
language R

Could anyone please point me in the right 
direction to solve my problem? Thank you in advance,
Emmanuelle



From ripley at stats.ox.ac.uk  Thu Mar 24 11:37:25 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Mar 2005 10:37:25 +0000 (GMT)
Subject: [R] build failed of package
In-Reply-To: <1abe3fa9050324001550d4a655@mail.gmail.com>
References: <20050324081134.86569.qmail@web50304.mail.yahoo.com>
	<1abe3fa9050324001550d4a655@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0503241033270.6412@gannet.stats>

On Thu, 24 Mar 2005, A.J. Rossini wrote:

> Looks like you are trying to install source tarball on Windows without
> the relevant toolset (compiler, etc)?

To save further hassle, rpvm is not going to build on Windows 
unless you have PVM installed and working on Windows.

If that is the case, this looks like the use of the wrong make, with the 
wrong shell (that message is coming from a Windows shell, not sh.exe). 
Do see the warnings in README.packages about the MinGW make.

> On Thu, 24 Mar 2005 00:11:34 -0800 (PST), Lars Schouw
> <schouwla at yahoo.com> wrote:
>> I am trying to install the rpvm package doing this:
>>
>> C:\R\rw2000\bin>rcmd install rpvm_0.6-2.tar.gz
>>
>> '.' is not recognized as an internal or external
>> command,
>> operable program or batch file.
>> '.' is not recognized as an internal or external
>> command,
>> operable program or batch file.
>> make: *** /rpvm: No such file or directory.  Stop.
>> make: *** [pkg-rpvm] Error 2
>> *** Installation of rpvm failed ***
>>
>> Removing 'C:/R/rw2000/library/rpvm'
>>
>> What does this error message tell me?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gb at stat.umu.se  Thu Mar 24 11:40:45 2005
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Thu, 24 Mar 2005 11:40:45 +0100
Subject: [R] Books on survival analysis and R/S
Message-ID: <20050324104045.GA30062@stat.umu.se>

I will be giving a course in survival analysis using R (of course!) for
people who know nothing about the subject (including R), but know basic
statistics. I'm looking for a suitable course book. Therneau & Grambsch
(2000) is an excellent book, but too much for this course. I need somthing
more elementary. 

I have a vague memory saying that such books exist, but I cannot find any
for the moment. Any suggestions are welcome.

Thanks,

G?ran 
-- 
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se



From ripley at stats.ox.ac.uk  Thu Mar 24 11:43:38 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Mar 2005 10:43:38 +0000 (GMT)
Subject: [R] problem with pdf() on Mac Os X
In-Reply-To: <DC22ED15-9C40-11D9-A404-0050E499F31C@cbconseil.com>
References: <DC22ED15-9C40-11D9-A404-0050E499F31C@cbconseil.com>
Message-ID: <Pine.LNX.4.61.0503241039510.6412@gannet.stats>

There is an R-sig-mac list for MacOS-specific questions.

Do check that it is the pdf file and not your viewer that is giving the 
problem.  Many similar reports have been traced to faulty PDF viewers.

On Thu, 24 Mar 2005, guillaume allain wrote:

> Hello R helpers,
>
> I am quite new as a R user, and even more on a Mac Os. I am running R under 
> Emacs 21.3.30.5 through ESS.
>
> I have some problems with the pdf() device :  when sent to it, plots don't 
> come out with any
> labels, titles or whatever written. I don't have that problem when plots are 
> sent to X11 or postscript devices.
>
> As pdf is the native format on Mac Os X, i find it sad to have to go through 
> .ps then .pdf using ps2pdf... Here's my R version
>
> platform powerpc-apple-darwin6.8
> arch     powerpc
> os       darwin6.8
> system   powerpc, darwin6.8
> status
> major    2
> minor    0.1
> year     2004
> month    11
> day      15
> language R

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tobias.verbeke at telenet.be  Thu Mar 24 11:55:28 2005
From: tobias.verbeke at telenet.be (Tobias Verbeke)
Date: Thu, 24 Mar 2005 10:55:28 +0000
Subject: [R] Books on survival analysis and R/S
Message-ID: <W61630262315941111661728@asteria.telenet-ops.be>


>----- Oorspronkelijk bericht -----
>Van
: G?ran Brostr?m [mailto:gb at stat.umu.se]
>Verzonden
: donderdag
, maart
 24, 2005 10:40 AM
>Aan
: r-help at stat.math.ethz.ch
>Onderwerp
: [R] Books on survival analysis and R/S
>
>I will be giving a course in survival analysis using R (of course!) for
>people who know nothing about the subject (including R), but know basic
>statistics. I'm looking for a suitable course book. Therneau & Grambsch
>(2000) is an excellent book, but too much for this course. I need somthing
>more elementary. 
>
>I have a vague memory saying that such books exist, but I cannot find any
>for the moment. Any suggestions are welcome.

Tableman, Kim & Portnoy,
Survival Analysis using S,
Chapman & Hall, 2003

Here's a review: 
http://www.jstatsoft.org/v11/b05/v11b05.pdf

HTH,
Tobias

>Thanks,
>
>G?ran 
>-- 
> G?ran Brostr?m                    tel: +46 90 786 5223
> Department of Statistics          fax: +46 90 786 6614
> Ume? University                   http://www.stat.umu.se/egna/gb/
> SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>



From sdavis2 at mail.nih.gov  Thu Mar 24 12:02:11 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Thu, 24 Mar 2005 06:02:11 -0500
Subject: [R] font sizes for row.names of dendograms
In-Reply-To: <3542A1BF5AE1984D9FF577DA2CF8BA9868B163@MSX2>
References: <3542A1BF5AE1984D9FF577DA2CF8BA9868B163@MSX2>
Message-ID: <b7244dc811b6c61da8c7232b5f10a463@mail.nih.gov>


On Mar 23, 2005, at 10:42 PM, Brett Stansfield wrote:

> Dear R
> I recently performed a cluster analysis. It produced the dendogram no
> problem but unfortunately the font size of the row.names were all 
> cluttered
> due to their large size
> So I tried to change the font size using
> plclust(cluster.results, labels=iris$specie, cex=0.8)
>
> and R came back to me saying
> Error in plclust(cluster.results, labels = iris$specie, cex = 0.8) :
>         unused argument(s) (cex ...)
>>
> what am I doing wrong here
>

Brett,

If you take a look at the help for hclust, you can see that there are 
two methods for plotting.  The second is plclust and looking at the 
arguments that you can give, there is not one for cex and there are not 
other arguments besides those listed available.  On the other hand, 
there is a "plot" method for hclust objects that includes "..." as an 
argument.  That "..." means take any other arguments and pass them to 
some underlying function--in this case plot.  So, using cex with plot 
rather than plclust will likely give what you want.

Obviously, there are some subtleties to reading R help files, but it is 
definitely worth the extra effort at the beginning to read the help for 
EVERY command that you use, if for no other reason than you are reading 
the help files (but an added bonus, at least for me, is that I often 
discover another feature of a function that saves me time down the 
road).

Sean



From stefaan.lhermitte at biw.kuleuven.be  Thu Mar 24 12:05:19 2005
From: stefaan.lhermitte at biw.kuleuven.be (Stefaan Lhermitte)
Date: Thu, 24 Mar 2005 12:05:19 +0100
Subject: [R] Endmemlber selection of a cloud
Message-ID: <42429EEF.5050205@biw.kuleuven.be>

Dear R-ians,

I am trying to do an endmember unmixing. For this process I need to 
define my endmembers (= the extremes of a 3D or 2D cloud).
Is there anyone who has advice on how to automatically extract those 
endpoints out of a data matrix that represents a 2D or 3D cloud?

Thanx in advance!

Kind regards,
Stef



From ligges at statistik.uni-dortmund.de  Thu Mar 24 12:07:24 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 24 Mar 2005 12:07:24 +0100
Subject: [R] Problem loading library Design
In-Reply-To: <42429013.9000108@bch.ap-hop-paris.fr>
References: <42429013.9000108@bch.ap-hop-paris.fr>
Message-ID: <42429F6C.8030702@statistik.uni-dortmund.de>

Emmanuelle Comets wrote:

> I have used library Design (Frank Harrell) in the past but when I tried 

Do you mean *package* Design?


> this week, I get :
>  > library(Design)
> Error in eval(expr, envir, enclos) : Object "formula.default" not found
> 
> I updated to the latest version of the library (2.0) with the same 

The latest version of package Design on CRAN is not 2.0 but 2.0-9.


> result. My version of R may not be the latest but it's recent (and I 

R-1.9.1 is not that recent, we have R-2.0.1 (second release since 
R-1.9.1, first (!) number changed in the meantime) these days, and 
R-2.1.0 already is in alpha testing.

I'd recommend to upgrade and try again (it works with recent version of 
R and Design).

Uwe Ligges



> probably changed since using Design for the last time) :
> 
>  > version
>          _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    1
> minor    9.1
> year     2004
> month    06
> day      21
> language R
> 
> Could anyone please point me in the right direction to solve my problem? 
> Thank you in advance,
> Emmanuelle
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From markus.jantti at iki.fi  Thu Mar 24 13:24:41 2005
From: markus.jantti at iki.fi (=?ISO-8859-1?Q?Markus_J=E4ntti?=)
Date: Thu, 24 Mar 2005 14:24:41 +0200
Subject: [R] Problem loading library Design
In-Reply-To: <42429013.9000108@bch.ap-hop-paris.fr>
References: <42429013.9000108@bch.ap-hop-paris.fr>
Message-ID: <4242B189.5080000@iki.fi>

Emmanuelle Comets wrote:
> I have used library Design (Frank Harrell) in the past but when I tried 
> this week, I get :
>  > library(Design)
> Error in eval(expr, envir, enclos) : Object "formula.default" not found
> 
> I updated to the latest version of the library (2.0) with the same 
> result. My version of R may not be the latest but it's recent (and I 
> probably changed since using Design for the last time) :
> 
>  > version
>          _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    1
> minor    9.1
> year     2004
> month    06
> day      21
> language R

I just tried this in
 > version
          _
platform i386-pc-linux-gnu
arch     i386
os       linux-gnu
system   i386, linux-gnu
status
major    2
minor    0.1
year     2004
month    11
day      15
language R

where it works. Your R is pretty old and there were many changes in 
moving to 2.0 (including the namespaces, which may be the reason you are
getting that particular error).

Upgrading R would appear to be the solution.

Regards,

markus

> 
> Could anyone please point me in the right direction to solve my problem? 
> Thank you in advance,
> Emmanuelle
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


-- 
Markus Jantti
Abo Akademi University
markus.jantti at iki.fi
http://www.iki.fi/~mjantti



From pensterfuzzer at yahoo.de  Thu Mar 24 14:27:14 2005
From: pensterfuzzer at yahoo.de (Werner Wernersen)
Date: Thu, 24 Mar 2005 14:27:14 +0100 (CET)
Subject: [R] replace values in a matrix subject to boolean condition
Message-ID: <20050324132714.90715.qmail@web25808.mail.ukl.yahoo.com>

Uwe Ligges wrote:
> Werner Wernersen wrote:
> 
>> Hi everybody!
>>
>> I am sorry to bother you with a question so simple
but
>> I think there might be a better solution:
>> I have a matrix of size 360x501 where I want to
check
>> the value of each 5th column of each row and
replace it (and the 6th, 
>> 7th,
>> 8th column) by zero if the value is less than 1000.
I have written a 
>> double loop
>> to do that but that requires a lot of time.
>>
>> Is there a faster way to achieve this?
> 
> 
> 
> Two ways to interpret your question:
> 
> 1) if col5 < 100 replace col5 & col6 & col7 & col8
by 0:
> 
>    X[X[,5] < 1000, 5:8] <- 0
> 
> 
> 2) if col5 < 100 replace col5 by 0, if col6 < 100
replace col6 by 0, ...:
> 
> 
> for(i in 5:8)
>    X[X[,i] < 1000, i] <- 0
> 
> Uwe Ligges
> 
> 
> 
> 
> 
>> Thanks,
>>    Werner
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
> 
> 
> 
> 
Thanks for all your answers!
Now I did it with
	for (j in seq(3,length(d[1,]),by=5)) {
		d[d[,j]<1000,j:(j+3)] <- c(0,0,0,0)
	}
which is so much faster than the double loop.

Thanks again,
   Werner



From luis.tercero at ebi-wasser.uni-karlsruhe.de  Thu Mar 24 15:01:52 2005
From: luis.tercero at ebi-wasser.uni-karlsruhe.de (Luis Tercero)
Date: Thu, 24 Mar 2005 15:01:52 +0100
Subject: [R] extracting numerical data from text field
Message-ID: <4242C850.7090907@ebi-wasser.uni-karlsruhe.de>

I have imported a data frame that looks like this:

           Measurement.Date.and.Time Z.Average..nm.   PDI
572 Dienstag, 22. M?rz 2005 11:05:59          366,4 0,468
573 Dienstag, 22. M?rz 2005 11:09:30          353,4 0,532
574 Dienstag, 22. M?rz 2005 11:12:59            343 0,428
575 Dienstag, 22. M?rz 2005 11:16:28          354,1 0,433
576 Dienstag, 22. M?rz 2005 11:19:59          341,9 0,349
577 Dienstag, 22. M?rz 2005 11:23:29          334,9 0,429
...

Would there be a way to extract the time in numerical form from the
Measurement.Date.and.Time field?  What I would like to do is a time
series where, for example,
Dienstag, 22. M?rz 2005 11:05:59 is time=0 min
Dienstag, 22. M?rz 2005 11:09:30 is time=3.5 min, etc.

Thank you in advance for your help.

Luis



From jeaneid at chass.utoronto.ca  Thu Mar 24 15:12:28 2005
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Thu, 24 Mar 2005 09:12:28 -0500
Subject: [R] non-derivative based optimization and standard errors.
In-Reply-To: <42424BEE.4070407@pdf.com>
Message-ID: <Pine.SGI.4.40.0503240906570.1104974-100000@origin.chass.utoronto.ca>

The problem is that it is a very complicated model and bootstrap will
probably take months. The objective function itself is making use of Monte
Carlo simulation because it is next to impossible to get at a closed form
solution (of the objective function itself). So I simulate this function
and get its expectation and match that to data. I thought of doing a
bootstrap but it will take so much time. I guess if this is the only way,
then it has to be done.


Jean

On Wed, 23 Mar 2005, Spencer Graves wrote:

>       Have you considered bootstrap or Monte Carlo?
>
>       spencer graves
>
> Jean Eid wrote:
>
> >Hi AlL,
> >
> >I ahve this problem that my objective function is discontinous in the
> >paramaters and I need to use methods such as nelder-mead to get around
> >this. My question is: How do i compute standard errors to a problem that
> >does not have  a gradient?
> >
> >
> >Any literature on this is greatly appreciated.
> >
> >
> >Jean,
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> >
>
>



From gb at stat.umu.se  Thu Mar 24 15:18:15 2005
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Thu, 24 Mar 2005 15:18:15 +0100
Subject: [R] Books on survival analysis and R/S
In-Reply-To: <W61630262315941111661728@asteria.telenet-ops.be>
References: <W61630262315941111661728@asteria.telenet-ops.be>
Message-ID: <20050324141815.GB5396@stat.umu.se>

On Thu, Mar 24, 2005 at 10:55:28AM +0000, Tobias Verbeke wrote:
> 
> >----- Oorspronkelijk bericht -----
> >Van
> : G?ran Brostr?m [mailto:gb at stat.umu.se]
> >Verzonden
> : donderdag
> , maart
>  24, 2005 10:40 AM
> >Aan
> : r-help at stat.math.ethz.ch
> >Onderwerp
> : [R] Books on survival analysis and R/S
> >
> >I will be giving a course in survival analysis using R (of course!) for
> >people who know nothing about the subject (including R), but know basic
> >statistics. I'm looking for a suitable course book. Therneau & Grambsch
> >(2000) is an excellent book, but too much for this course. I need somthing
> >more elementary. 
> >
> >I have a vague memory saying that such books exist, but I cannot find any
> >for the moment. Any suggestions are welcome.
> 
> Tableman, Kim & Portnoy,
> Survival Analysis using S,
> Chapman & Hall, 2003
> 
> Here's a review: 
> http://www.jstatsoft.org/v11/b05/v11b05.pdf

Thanks Tobias,

I also found a review in Statistics in Medicine (2005:2). So I still need
suggestions:(. 

G?ran

> 
> HTH,
> Tobias
> 
> >Thanks,
> >
> >G?ran 
> >-- 
> > G?ran Brostr?m                    tel: +46 90 786 5223
> > Department of Statistics          fax: +46 90 786 6614
> > Ume? University                   http://www.stat.umu.se/egna/gb/
> > SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> >
> 

-- 
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se



From lzhtom at hotmail.com  Thu Mar 24 15:23:55 2005
From: lzhtom at hotmail.com (zhihua li)
Date: Thu, 24 Mar 2005 14:23:55 +0000
Subject: [R] (no subject)
Message-ID: <BAY12-F165FB85EC0476372F19C2FC7400@phx.gbl>

hi netters:

I have a series of  discrete variables which form a network and  I want to 
learn the network structure from some training data. I could have used 
packages like deal but there are two problems.

First of all, I have 10000 variables. So the possible network structure is 
awfully huge, I don't know how long it will take my PC to find the 
highest-scoring network..........maybe a month?
Secondly, I have some prior knowledge that only 500 out of the 10000 
variales are possible parents. In another word, only those arrows startting 
from the 500 variables and pointing to the remaining 99500 variables are 
allowed in the network.  In deal an assignment to "banlist" should help me 
rule out the impossible arrows. But in my case the number of "impossible 
arrows" is  500*499+99500*99549, and so the "banlist" would get 
unacceptable long. Are there any methods (in deal or other packages) to 
specify the parents set in advance?

Thanks a lot!



From roger.bos at gmail.com  Thu Mar 24 15:27:59 2005
From: roger.bos at gmail.com (roger bos)
Date: Thu, 24 Mar 2005 09:27:59 -0500
Subject: [R] client-server setup for R
Message-ID: <1db72680050324062736384bef@mail.gmail.com>

I am currently the only use-R at my company, but they are considering
buy a more powerful server and letting multiple people use it.  They
asked me if R supports client-server setups.  I know S+ has a server
version that does that.  I didn't find anything about that on CRAN,
but hopefully someone can correct me.

I did see some stuff about R web servers
(http://franklin.imgen.bcm.tmc.edu/R.web.servers/ )
and that looked very interesting, but I don't know which one is best
and I don't want to spend all my time in HTML programming to make
front ends of all the users.  If I have no choice but to go the web
server route, which one is the most mature?

If I can't show them a pluasible solution, IT will make use buy S+
server and I will have to modify all my code to make it work.  I
really enjoy working in R.

Thanks,

Roger J. Bos



From sway at tanox.com  Thu Mar 24 15:21:12 2005
From: sway at tanox.com (Shawn Way)
Date: Thu, 24 Mar 2005 08:21:12 -0600
Subject: [R] Error bars for Lattice Plots
Message-ID: <2DBF8A8E1A1AEE4AB3618AC4D6BF30880147B1C2@houston.tanox.net>

Has anyone found a method for creating error bars in lattice plots?

________________________________

"Policies are many, Principles are few, Policies will change, Principles
never do." 
-John C. Maxwell

________________________________

 	Shawn Way, PE	 Tanox, Inc.	
Engineering Manager	 10301 Stella Link	
sway at tanox.com	 Houston, TX 77025	
________________________________

Note: Any use, dissemination, forwarding, printing or copying of this
e-mail without consent of Tanox, Inc. is not authorized.  Further, this
communication may contain confidential information intended only for the
person to whom it is addressed, and any use, dissemination, forwarding,
printing or copying of such confidential information without the express
consent of Tanox or in violation of any agreements to which the
recipient is subject is prohibited.  If you have received this e-mail in
error, please immediately notify the sender and delete the original and
all copies.  Any views or opinions expressed may be solely those of the
author and do not necessarily represent the views or opinions of Tanox,
Inc.



From reid_huntsinger at merck.com  Thu Mar 24 15:47:53 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Thu, 24 Mar 2005 09:47:53 -0500
Subject: [R] client-server setup for R
Message-ID: <D9A95B4B7B20354992E165EEADA31999056A9362@uswpmx00.merck.com>

Is running R directly on the server machine and displaying via X or Xvnc an
option?

Reid Huntsinger

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of roger bos
Sent: Thursday, March 24, 2005 9:28 AM
To: R-help at stat.math.ethz.ch
Subject: [R] client-server setup for R


I am currently the only use-R at my company, but they are considering
buy a more powerful server and letting multiple people use it.  They
asked me if R supports client-server setups.  I know S+ has a server
version that does that.  I didn't find anything about that on CRAN,
but hopefully someone can correct me.

I did see some stuff about R web servers
(http://franklin.imgen.bcm.tmc.edu/R.web.servers/ )
and that looked very interesting, but I don't know which one is best
and I don't want to spend all my time in HTML programming to make
front ends of all the users.  If I have no choice but to go the web
server route, which one is the most mature?

If I can't show them a pluasible solution, IT will make use buy S+
server and I will have to modify all my code to make it work.  I
really enjoy working in R.

Thanks,

Roger J. Bos

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From rxg218 at psu.edu  Thu Mar 24 15:57:38 2005
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Thu, 24 Mar 2005 09:57:38 -0500
Subject: [R] Rggobi package
Message-ID: <1111676258.5003.5.camel@blue.chem.psu.edu>

Hi,
  I have an old version of the Rggobi package which now wont load (R
2.0.0). Looking for the package on CRAN does'nt turn up anything and 
the links on http://www.ggobi.org/RSggobi.html don't work.

Does anybody know where I can get the latest version of RSggobi or
Rggobi?

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
Despite the high cost of living, it remains popular.



From SAULEAUEA at ch-mulhouse.fr  Thu Mar 24 16:05:24 2005
From: SAULEAUEA at ch-mulhouse.fr (=?iso-8859-1?Q?SAULEAU_Erik-Andr=E9?=)
Date: Thu, 24 Mar 2005 16:05:24 +0100
Subject: [R] critical value for HEGY test in uroot
Message-ID: <A91EF0B9121F834EA6484582DFE1CF4436F754@messagerie.chm.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050324/468df654/attachment.pl

From tlumley at u.washington.edu  Thu Mar 24 16:21:50 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 24 Mar 2005 07:21:50 -0800 (PST)
Subject: [R] non-derivative based optimization and standard errors.
In-Reply-To: <Pine.SGI.4.40.0503240906570.1104974-100000@origin.chass.utoronto.ca>
References: <Pine.SGI.4.40.0503240906570.1104974-100000@origin.chass.utoronto.ca>
Message-ID: <Pine.A41.4.61b.0503240717530.350648@homer03.u.washington.edu>

On Thu, 24 Mar 2005, Jean Eid wrote:

> The problem is that it is a very complicated model and bootstrap will
> probably take months. The objective function itself is making use of Monte
> Carlo simulation because it is next to impossible to get at a closed form
> solution (of the objective function itself). So I simulate this function
> and get its expectation and match that to data. I thought of doing a
> bootstrap but it will take so much time. I guess if this is the only way,
> then it has to be done.

If the objective function is discontinuous it is entirely possible that 
the bootstrap will not work.  If the bootstrap does work, there are some 
recent methods by LJ Wei and colleagues that avoid some of the 
computation.  I don't know if they will help -- I do remember when 
listening to a talk on the subject that they would only be helpful when 
certain parts of the problem are much harder than others, but I'm not 
sure which parts.

 	-thomas


>
> Jean
>
> On Wed, 23 Mar 2005, Spencer Graves wrote:
>
>>       Have you considered bootstrap or Monte Carlo?
>>
>>       spencer graves
>>
>> Jean Eid wrote:
>>
>>> Hi AlL,
>>>
>>> I ahve this problem that my objective function is discontinous in the
>>> paramaters and I need to use methods such as nelder-mead to get around
>>> this. My question is: How do i compute standard errors to a problem that
>>> does not have  a gradient?
>>>
>>>
>>> Any literature on this is greatly appreciated.
>>>
>>>
>>> Jean,
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>
>>>
>>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From reid_huntsinger at merck.com  Thu Mar 24 16:23:35 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Thu, 24 Mar 2005 10:23:35 -0500
Subject: [R] non-derivative based optimization and standard errors.
Message-ID: <D9A95B4B7B20354992E165EEADA31999056A9363@uswpmx00.merck.com>

You'll really need to give some details if you want anything like a relevant
answer. There aren't really general methods for dealing with discontinuous
functions you can't compute. 

A few things come to mind. 1) You might have a look at the literature on
segmented regression. Non-differentiable and even discontinuous objective
functions arise there. 2) Monte Carlo: you may be able to adapt one of the
Monte Carlo optimization approaches to your situation, avoiding having to do
Monte Carlo within Monte Carlo. 

I'd be happy to be more specific if you'll supply details.

Reid Huntsinger

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jean Eid
Sent: Thursday, March 24, 2005 9:12 AM
To: Spencer Graves
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] non-derivative based optimization and standard errors.


The problem is that it is a very complicated model and bootstrap will
probably take months. The objective function itself is making use of Monte
Carlo simulation because it is next to impossible to get at a closed form
solution (of the objective function itself). So I simulate this function
and get its expectation and match that to data. I thought of doing a
bootstrap but it will take so much time. I guess if this is the only way,
then it has to be done.


Jean

On Wed, 23 Mar 2005, Spencer Graves wrote:

>       Have you considered bootstrap or Monte Carlo?
>
>       spencer graves
>
> Jean Eid wrote:
>
> >Hi AlL,
> >
> >I ahve this problem that my objective function is discontinous in the
> >paramaters and I need to use methods such as nelder-mead to get around
> >this. My question is: How do i compute standard errors to a problem that
> >does not have  a gradient?
> >
> >
> >Any literature on this is greatly appreciated.
> >
> >
> >Jean,
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
> >
> >
>
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From i.visser at uva.nl  Thu Mar 24 16:23:54 2005
From: i.visser at uva.nl (Ingmar Visser)
Date: Thu, 24 Mar 2005 10:23:54 -0500
Subject: [R] non-derivative based optimization and standard errors.
In-Reply-To: <Pine.SGI.4.40.0503240906570.1104974-100000@origin.chass.utoronto.ca>
Message-ID: <BE6845BA.2761%i.visser@uva.nl>

Hi Jean,

Profiling may be another option and/or finite difference gradients.

In any case, if your objective function is discontinuous at some point close
to the optimal parameter values, standard errors may not make much sense.

Best, Ingmar


On 3/24/05 9:12 AM, "Jean Eid" <jeaneid at chass.utoronto.ca> wrote:

> The problem is that it is a very complicated model and bootstrap will
> probably take months. The objective function itself is making use of Monte
> Carlo simulation because it is next to impossible to get at a closed form
> solution (of the objective function itself). So I simulate this function
> and get its expectation and match that to data. I thought of doing a
> bootstrap but it will take so much time. I guess if this is the only way,
> then it has to be done.
> 
> 
> Jean
> 
> On Wed, 23 Mar 2005, Spencer Graves wrote:
> 
>>       Have you considered bootstrap or Monte Carlo?
>> 
>>       spencer graves
>> 
>> Jean Eid wrote:
>> 
>>> Hi AlL,
>>> 
>>> I ahve this problem that my objective function is discontinous in the
>>> paramaters and I need to use methods such as nelder-mead to get around
>>> this. My question is: How do i compute standard errors to a problem that
>>> does not have  a gradient?
>>> 
>>> 
>>> Any literature on this is greatly appreciated.
>>> 
>>> 
>>> Jean,
>>> 
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide!
>>> http://www.R-project.org/posting-guide.html
>>> 
>>> 
>> 
>> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Ingmar Visser
Department of Psychology, University of Amsterdam
Roetersstraat 15, 1018 WB Amsterdam
The Netherlands
http://users.fmg.uva.nl/ivisser/
tel: +31-20-5256735



From JAROSLAW.W.TUSZYNSKI at saic.com  Thu Mar 24 16:32:33 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Thu, 24 Mar 2005 10:32:33 -0500
Subject: [R] Unexpected error "subset assignment" (bug?)
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD57F4001@us-arlington-0668.mail.saic.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050324/fc3309ba/attachment.pl

From roger.bos at gmail.com  Thu Mar 24 16:56:46 2005
From: roger.bos at gmail.com (roger bos)
Date: Thu, 24 Mar 2005 10:56:46 -0500
Subject: [R] client-server setup for R
In-Reply-To: <D9A95B4B7B20354992E165EEADA31999056A9362@uswpmx00.merck.com>
References: <D9A95B4B7B20354992E165EEADA31999056A9362@uswpmx00.merck.com>
Message-ID: <1db7268005032407562eefa39f@mail.gmail.com>

Maybe I didn't state my question as well as I should have.  First of
all, this is a windows environment.  I currently run R on my desktop
and I also have a server that I use that the connect to using remote
desktop.  Each machine has 4GB of memory and is a P4.  I run R on my
machine and on the server so I can have two programs running at once. 
Other people in the company don't have as much memory as I do and have
older machines, so they may have trouble running R on their desktop. 
And two people can't remote desktop into the server at the same time.

So my restated question is, how do I share my server with other useRs?
 If this is more of an IT question than an R question, I apologize,
but it seems that S+ have a server version where clients connect from
their desktop and submit jobs and I was wonder is there is an R
version.




On Thu, 24 Mar 2005 09:47:53 -0500, Huntsinger, Reid
<reid_huntsinger at merck.com> wrote:
> Is running R directly on the server machine and displaying via X or Xvnc an
> option?
> 
> Reid Huntsinger
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of roger bos
> Sent: Thursday, March 24, 2005 9:28 AM
> To: R-help at stat.math.ethz.ch
> Subject: [R] client-server setup for R
> 
> I am currently the only use-R at my company, but they are considering
> buy a more powerful server and letting multiple people use it.  They
> asked me if R supports client-server setups.  I know S+ has a server
> version that does that.  I didn't find anything about that on CRAN,
> but hopefully someone can correct me.
> 
> I did see some stuff about R web servers
> (http://franklin.imgen.bcm.tmc.edu/R.web.servers/ )
> and that looked very interesting, but I don't know which one is best
> and I don't want to spend all my time in HTML programming to make
> front ends of all the users.  If I have no choice but to go the web
> server route, which one is the most mature?
> 
> If I can't show them a pluasible solution, IT will make use buy S+
> server and I will have to modify all my code to make it work.  I
> really enjoy working in R.
> 
> Thanks,
> 
> Roger J. Bos
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any attachment...{{dropped}}



From B.Rowlingson at lancaster.ac.uk  Thu Mar 24 17:06:20 2005
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 24 Mar 2005 16:06:20 +0000
Subject: [R] client-server setup for R
In-Reply-To: <1db7268005032407562eefa39f@mail.gmail.com>
References: <D9A95B4B7B20354992E165EEADA31999056A9362@uswpmx00.merck.com>
	<1db7268005032407562eefa39f@mail.gmail.com>
Message-ID: <4242E57C.1000106@lancaster.ac.uk>

roger bos wrote:

> And two people can't remote desktop into the server at the same time.

> So my restated question is, how do I share my server with other useRs?

  What OS is your server running? If you are running Windows Server 2003 
and have the requisite licenses, you should be able to have more than 
one person connect via Remote Desktop and run R.

  I'm guessing this 'Server' is just running vanilla Win XP or 2000.

  We have a lab of thin clients that connect to a Windows box running 
Win 2003 Server, and have no problem with multiple logins, multiple R 
sessions and so on.

  However our users seem to prefer to connect to the Linux service in 
the lab and use R on that!

Baz



From roger.bos at gmail.com  Thu Mar 24 17:06:49 2005
From: roger.bos at gmail.com (roger bos)
Date: Thu, 24 Mar 2005 11:06:49 -0500
Subject: [R] Unexpected error "subset assignment" (bug?)
In-Reply-To: <CA0BCF3BED56294AB91E3AD74B849FD57F4001@us-arlington-0668.mail.saic.com>
References: <CA0BCF3BED56294AB91E3AD74B849FD57F4001@us-arlington-0668.mail.saic.com>
Message-ID: <1db72680050324080646a9daf5@mail.gmail.com>

I didn't know anything about as.raw(), so I did ?as.raw and it refer
to raw vector, so my guess is that it doesn't work with matrix types. 
The following modified code seems to work, however:

b = matrix(0, 8,8)
q = 1:8
b[1,] = q
b <- as.raw(b)
dim(b) <- c(8,8)

HTH,
Roger


On Thu, 24 Mar 2005 10:32:33 -0500, Tuszynski, Jaroslaw W.
<JAROSLAW.W.TUSZYNSKI at saic.com> wrote:
> Hi,
> 
> I run into following problem. It seems to me that operation in the 3rd line
> should be valid.
> 
> > b = matrix(as.raw(0), 8,8)
> > q = as.raw(1:8)
> > b[1,] = q
> Error: incompatible types in subset assignment
> > length(b[1,])
> [1] 8
> > typeof(b[1,])
> [1] "raw"
> > length(q)
> [1] 8
> > typeof(q)
> [1] "raw"
> 
> Is this a bug or a "feature"?
> 
> Jarek
> =====================================\====
> Jarek Tuszynski, PhD.                               o / \
> Science Applications International Corporation  <\__,|
> (703) 676-4192                        ">  \
> Jaroslaw.W.Tuszynski at saic.com                   `    \
> 
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From macq at llnl.gov  Thu Mar 24 17:07:12 2005
From: macq at llnl.gov (Don MacQueen)
Date: Thu, 24 Mar 2005 08:07:12 -0800
Subject: [R] problem with pdf() on Mac Os X
In-Reply-To: <DC22ED15-9C40-11D9-A404-0050E499F31C@cbconseil.com>
References: <DC22ED15-9C40-11D9-A404-0050E499F31C@cbconseil.com>
Message-ID: <p06210206be68913fbc44@[128.115.153.6]>

I had this problem last fall. It went away after a while, and I 
believe the "fix" was an OS version upgrade.
Later, I was sending PDF files created with R to a colleague. When I 
viewed them, the labels were there.
When he viewed them on his computer, they were not displayed. He 
upgraded his OS, after which they
were displayed.

Here is my version information, and note that I have a later version 
of the OS (10.3.8).

>  version
          _                       
platform powerpc-apple-darwin6.8.5
arch     powerpc                 
os       darwin6.8.5             
system   powerpc, darwin6.8.5    
status                           
major    2                       
minor    0.1                     
year     2004                    
month    11                      
day      15
language R

-Don


At 9:43 AM +0100 3/24/05, guillaume allain wrote:
>Hello R helpers,
>
>I am quite new as a R user, and even more on a Mac Os. I am running 
>R under Emacs 21.3.30.5 through ESS.
>
>I have some problems with the pdf() device :  when sent to it, plots 
>don't come out with any
>labels, titles or whatever written. I don't have that problem when 
>plots are sent to X11 or postscript devices.
>
>As pdf is the native format on Mac Os X, i find it sad to have to go 
>through .ps then .pdf using ps2pdf... Here's my R version
>
>platform powerpc-apple-darwin6.8
>arch     powerpc
>os       darwin6.8
>system   powerpc, darwin6.8
>status
>major    2
>minor    0.1
>year     2004
>month    11
>day      15
>language R
>>
>
>______________________________
>Guillaume Allain
>Carte Blanche Conseil
>47 rue de Lancry 75010
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From ljw1001 at gmail.com  Thu Mar 24 17:12:05 2005
From: ljw1001 at gmail.com (Larry White)
Date: Thu, 24 Mar 2005 11:12:05 -0500
Subject: [R] summing values by group
Message-ID: <d15ea14a050324081265d3350e@mail.gmail.com>

At the risk of being wacked for asking what should be obvious....  

I have a data frame with one categorical variable "CAT" and several
numeric variables.  I want to be able to get simple statistics on the
numeric variables by level.  For example, just as you can use table
(CAT) to get the counts, I'd like to be able to get the means and sums
by category.

If someone could point me in the right direction, I'd appreciate it.
I've been through the SimpleR and Using R for Data Analysis... docs
and I'm still clueless.

thanks for your help.



From dimitris.rizopoulos at med.kuleuven.ac.be  Thu Mar 24 17:27:11 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Thu, 24 Mar 2005 17:27:11 +0100
Subject: [R] summing values by group
References: <d15ea14a050324081265d3350e@mail.gmail.com>
Message-ID: <003201c5308e$54d5bc70$0540210a@www.domain>

you could use '?by()', e.g.,

dat <- data.frame(CAT=sample(letters[1:5], 100, TRUE), x=rnorm(100), 
y=rnorm(100), z=rnorm(100))
by(dat[sapply(dat, is.numeric)], dat$CAT, sum)
by(dat[sapply(dat, is.numeric)], dat$CAT, mean)


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Larry White" <ljw1001 at gmail.com>
To: <R-help at stat.math.ethz.ch>
Sent: Thursday, March 24, 2005 5:12 PM
Subject: [R] summing values by group


> At the risk of being wacked for asking what should be obvious....
>
> I have a data frame with one categorical variable "CAT" and several
> numeric variables.  I want to be able to get simple statistics on 
> the
> numeric variables by level.  For example, just as you can use table
> (CAT) to get the counts, I'd like to be able to get the means and 
> sums
> by category.
>
> If someone could point me in the right direction, I'd appreciate it.
> I've been through the SimpleR and Using R for Data Analysis... docs
> and I'm still clueless.
>
> thanks for your help.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From Dubravko.Dolic at komdat.com  Thu Mar 24 17:38:50 2005
From: Dubravko.Dolic at komdat.com (Dubravko Dolic)
Date: Thu, 24 Mar 2005 17:38:50 +0100
Subject: [R] Histogram over times (without dates)
Message-ID: <52D1AC81378E9342947189B0417601471E44BD@agentsmith.komdat.intern>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050324/d3cdf0d1/attachment.pl

From andy_liaw at merck.com  Thu Mar 24 18:16:05 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 24 Mar 2005 12:16:05 -0500
Subject: [R] Rggobi package
Message-ID: <3A822319EB35174CA3714066D590DCD50994E8E4@usrymx25.merck.com>

Try:
http://ggobi.hadley.textdriven.com/

Andy

> From: Rajarshi Guha
>
> Hi,
>   I have an old version of the Rggobi package which now wont load (R
> 2.0.0). Looking for the package on CRAN does'nt turn up anything and 
> the links on http://www.ggobi.org/RSggobi.html don't work.
> 
> Does anybody know where I can get the latest version of RSggobi or
> Rggobi?
> 
> Thanks,
> 
> -------------------------------------------------------------------
> Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
> GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
> -------------------------------------------------------------------
> Despite the high cost of living, it remains popular.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From greg.snow at ihc.com  Thu Mar 24 18:16:46 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Thu, 24 Mar 2005 10:16:46 -0700
Subject: [R] Histogram over times (without dates)
Message-ID: <s24293a6.050@lp-msg1.co.ihc.com>

Have you looked at the "CircStats" and "circular"? They have some plotting functions that may be of help to you. 

Greg Snow, Ph.D.
Statistical Data Center
greg.snow at ihc.com
(801) 408-8111

>>> "Dubravko Dolic" <Dubravko.Dolic at komdat.com> 03/24/05 09:38AM >>>
Dear Group,

Having a character vector like this one:

 

[1] "03:38:55" "07:42:38" "08:04:27" "08:17:13" "08:41:14" "08:46:58"

[7] "08:47:11" "08:53:51" "08:57:51" "08:58:56"

 

I try to do a histogram over times of a day. All I want to know, if my solution is proper or if there is another way to go.

 

There is no Information about the day on which this time occurred. it is unimportant as I want to know at what times on a day a costumer buys anything (times are collected from logfiles).

The values span 24 hours (e.g. 00:00:00 to 23:59:59)

 

I converted the characters to chron objects (library(chron)) and then to numeric vectors:

 

ordertm.num <- as.numeric(chron(times = ecom$Ordertime))

 

 

Then I put the numeric values to hist(), printed the hist without axes=F and constructed my own axis.

 

The result is satisfactory. But as there are so many possibilities with times on R (namely using the POSIX classes) I want to be shure if there is no "standard" approach to handle such time related problems (note that the date is irrelevant to my problem).

 

have a goof Easter holiday

 

All the best

 

Dubravko Dolic

 

 

 

 

 

 

 

Dubravko Dolic <http://www.dolic.de/pagedd.html> 

-- Statistik --

Tel:      +49 (0)89-55 27 44 - 4630

Fax:     +49 (0)89-55 27 44 - 2463

Email: dubravko.dolic at komdat.com      

--------------------------------------------

Komdat GmbH

Nymphenburger Stra?e 86 / TH 3

80636 M?nchen

--------------------------------------------

Partners for your success 

www.komdat.com <outbind://96-000000009676DC1A07BA5142BC1A44984B6E7FAC070052D1AC81378E9342947189B04176014700000017F023000052D1AC81378E9342947189B04176014700000017F7DA0000/www.komdat.com> 

--------------------------------------------

 


	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From reid_huntsinger at merck.com  Thu Mar 24 18:27:12 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Thu, 24 Mar 2005 12:27:12 -0500
Subject: [R] client-server setup for R
Message-ID: <D9A95B4B7B20354992E165EEADA31999056A9366@uswpmx00.merck.com>

You have probably considered this and it's not an option, but just in case
it is, I suspect you could buy a dual Xeon machine with 4 GB RAM and run
Linux + Samba etc for far less than the license fees for the Windows Server
OS and S+ components. (Probably a whole cluster, in fact!) Then users could
use Cygwin's X server or Xvnc on their Windows desktops to run things like R
on it. The setup takes a little time, but ongoing maintenance requirements
are very low. 

Reid Huntsinger

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of roger bos
Sent: Thursday, March 24, 2005 10:57 AM
To: R-help at stat.math.ethz.ch
Subject: Re: [R] client-server setup for R


Maybe I didn't state my question as well as I should have.  First of
all, this is a windows environment.  I currently run R on my desktop
and I also have a server that I use that the connect to using remote
desktop.  Each machine has 4GB of memory and is a P4.  I run R on my
machine and on the server so I can have two programs running at once. 
Other people in the company don't have as much memory as I do and have
older machines, so they may have trouble running R on their desktop. 
And two people can't remote desktop into the server at the same time.

So my restated question is, how do I share my server with other useRs?
 If this is more of an IT question than an R question, I apologize,
but it seems that S+ have a server version where clients connect from
their desktop and submit jobs and I was wonder is there is an R
version.




On Thu, 24 Mar 2005 09:47:53 -0500, Huntsinger, Reid
<reid_huntsinger at merck.com> wrote:
> Is running R directly on the server machine and displaying via X or Xvnc
an
> option?
> 
> Reid Huntsinger
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of roger bos
> Sent: Thursday, March 24, 2005 9:28 AM
> To: R-help at stat.math.ethz.ch
> Subject: [R] client-server setup for R
> 
> I am currently the only use-R at my company, but they are considering
> buy a more powerful server and letting multiple people use it.  They
> asked me if R supports client-server setups.  I know S+ has a server
> version that does that.  I didn't find anything about that on CRAN,
> but hopefully someone can correct me.
> 
> I did see some stuff about R web servers
> (http://franklin.imgen.bcm.tmc.edu/R.web.servers/ )
> and that looked very interesting, but I don't know which one is best
> and I don't want to spend all my time in HTML programming to make
> front ends of all the users.  If I have no choice but to go the web
> server route, which one is the most mature?
> 
> If I can't show them a pluasible solution, IT will make use buy S+
> server and I will have to modify all my code to make it work.  I
> really enjoy working in R.
> 
> Thanks,
> 
> Roger J. Bos
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
>
----------------------------------------------------------------------------
--
> Notice:  This e-mail message, together with any attachment...{{dropped}}

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Thu Mar 24 18:42:31 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 24 Mar 2005 12:42:31 -0500
Subject: [R] client-server setup for R
Message-ID: <3A822319EB35174CA3714066D590DCD50994E8E6@usrymx25.merck.com>

If I'm not mistaken, the problem of sharing applications on a Windows server
among several users is not particular to R, but applies generally to that
environment, and Reid's suggestion is the cheap(-est.?) way of getting
around it.  (Windows is simply not designed for that kind of usage, whereas
Linux, like Unix, _is_ designed for that.)  The problem is that it'd be
difficult to cut-and-paste graphics as you could on a Windows box (although
that might not be doable via remote desktop, either --- I don't know).

I routinely run upwards of 4 different, simultaneous R sessions on my 1.6GHz
P-M laptop with 1GB ram, along with a few other applications.  Never have
problems as long as none of them deal with very large data.

Andy

> From: Huntsinger, Reid
> 
> You have probably considered this and it's not an option, but 
> just in case
> it is, I suspect you could buy a dual Xeon machine with 4 GB 
> RAM and run
> Linux + Samba etc for far less than the license fees for the 
> Windows Server
> OS and S+ components. (Probably a whole cluster, in fact!) 
> Then users could
> use Cygwin's X server or Xvnc on their Windows desktops to 
> run things like R
> on it. The setup takes a little time, but ongoing maintenance 
> requirements
> are very low. 
> 
> Reid Huntsinger
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of roger bos
> Sent: Thursday, March 24, 2005 10:57 AM
> To: R-help at stat.math.ethz.ch
> Subject: Re: [R] client-server setup for R
> 
> 
> Maybe I didn't state my question as well as I should have.  First of
> all, this is a windows environment.  I currently run R on my desktop
> and I also have a server that I use that the connect to using remote
> desktop.  Each machine has 4GB of memory and is a P4.  I run R on my
> machine and on the server so I can have two programs running at once. 
> Other people in the company don't have as much memory as I do and have
> older machines, so they may have trouble running R on their desktop. 
> And two people can't remote desktop into the server at the same time.
> 
> So my restated question is, how do I share my server with other useRs?
>  If this is more of an IT question than an R question, I apologize,
> but it seems that S+ have a server version where clients connect from
> their desktop and submit jobs and I was wonder is there is an R
> version.
> 
> 
> 
> 
> On Thu, 24 Mar 2005 09:47:53 -0500, Huntsinger, Reid
> <reid_huntsinger at merck.com> wrote:
> > Is running R directly on the server machine and displaying 
> via X or Xvnc
> an
> > option?
> > 
> > Reid Huntsinger
> > 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of roger bos
> > Sent: Thursday, March 24, 2005 9:28 AM
> > To: R-help at stat.math.ethz.ch
> > Subject: [R] client-server setup for R
> > 
> > I am currently the only use-R at my company, but they are 
> considering
> > buy a more powerful server and letting multiple people use it.  They
> > asked me if R supports client-server setups.  I know S+ has a server
> > version that does that.  I didn't find anything about that on CRAN,
> > but hopefully someone can correct me.
> > 
> > I did see some stuff about R web servers
> > (http://franklin.imgen.bcm.tmc.edu/R.web.servers/ )
> > and that looked very interesting, but I don't know which one is best
> > and I don't want to spend all my time in HTML programming to make
> > front ends of all the users.  If I have no choice but to go the web
> > server route, which one is the most mature?
> > 
> > If I can't show them a pluasible solution, IT will make use buy S+
> > server and I will have to modify all my code to make it work.  I
> > really enjoy working in R.
> > 
> > Thanks,
> > 
> > Roger J. Bos
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > 
> >
> --------------------------------------------------------------
> --------------
> --
> > Notice:  This e-mail message, together with any 
> attachment...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
> --------------------------------------------------------------
> ----------------
> Notice:  This e-mail message, together with any attachments, 
> contains information of Merck & Co., Inc. (One Merck Drive, 
> Whitehouse Station, New Jersey, USA 08889), and/or its 
> affiliates (which may be known outside the United States as 
> Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as 
> Banyu) that may be confidential, proprietary copyrighted 
> and/or legally privileged. It is intended solely for the use 
> of the individual or entity named on this message.  If you 
> are not the intended recipient, and have received this 
> message in error, please notify us immediately by reply 
> e-mail and then delete it from your system.
> --------------------------------------------------------------
> ----------------
> 
>



From clint at ecy.wa.gov  Thu Mar 24 18:50:19 2005
From: clint at ecy.wa.gov (Clint Bowman)
Date: Thu, 24 Mar 2005 09:50:19 -0800 (PST)
Subject: [R] Histogram over times (without dates)
In-Reply-To: <s24293a6.050@lp-msg1.co.ihc.com>
Message-ID: <Pine.LNX.4.44.0503240948030.10199-100000@aeolus.ecy.wa.gov>

I do analyses of that sort all the time with air quality data where I wish 
to begin to understand daily behavior -- works well in doing model 
evaluation as well. 

I'd say your approach should give you useful information; however, I'd 
think you'd also be interested in a possible day of week variation.

On Thu, 24 Mar 2005, Greg Snow wrote:

> Have you looked at the "CircStats" and "circular"? They have some plotting functions that may be of help to you. 
> 
> Greg Snow, Ph.D.
> Statistical Data Center
> greg.snow at ihc.com
> (801) 408-8111
> 
> >>> "Dubravko Dolic" <Dubravko.Dolic at komdat.com> 03/24/05 09:38AM >>>
> Dear Group,
> 
> Having a character vector like this one:
> 
>  
> 
> [1] "03:38:55" "07:42:38" "08:04:27" "08:17:13" "08:41:14" "08:46:58"
> 
> [7] "08:47:11" "08:53:51" "08:57:51" "08:58:56"
> 
>  
> 
> I try to do a histogram over times of a day. All I want to know, if my solution is proper or if there is another way to go.
> 
>  
> 
> There is no Information about the day on which this time occurred. it is unimportant as I want to know at what times on a day a costumer buys anything (times are collected from logfiles).
> 
> The values span 24 hours (e.g. 00:00:00 to 23:59:59)
> 
>  
> 
> I converted the characters to chron objects (library(chron)) and then to numeric vectors:
> 
>  
> 
> ordertm.num <- as.numeric(chron(times = ecom$Ordertime))
> 
>  
> 
>  
> 
> Then I put the numeric values to hist(), printed the hist without axes=F and constructed my own axis.
> 
>  
> 
> The result is satisfactory. But as there are so many possibilities with times on R (namely using the POSIX classes) I want to be shure if there is no "standard" approach to handle such time related problems (note that the date is irrelevant to my problem).
> 
>  
> 
> have a goof Easter holiday
> 
>  
> 
> All the best
> 
>  
> 
> Dubravko Dolic
> 
>  
> 
>  
> 
>  
> 
>  
> 
>  
> 
>  
> 
>  
> 
> Dubravko Dolic <http://www.dolic.de/pagedd.html> 
> 
> -- Statistik --
> 
> Tel:      +49 (0)89-55 27 44 - 4630
> 
> Fax:     +49 (0)89-55 27 44 - 2463
> 
> Email: dubravko.dolic at komdat.com      
> 
> --------------------------------------------
> 
> Komdat GmbH
> 
> Nymphenburger Stra?e 86 / TH 3
> 
> 80636 M?nchen
> 
> --------------------------------------------
> 
> Partners for your success 
> 
> www.komdat.com <outbind://96-000000009676DC1A07BA5142BC1A44984B6E7FAC070052D1AC81378E9342947189B04176014700000017F023000052D1AC81378E9342947189B04176014700000017F7DA0000/www.komdat.com> 
> 
> --------------------------------------------
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600



From roger.bos at gmail.com  Thu Mar 24 18:58:53 2005
From: roger.bos at gmail.com (roger bos)
Date: Thu, 24 Mar 2005 12:58:53 -0500
Subject: [R] client-server setup for R
In-Reply-To: <3A822319EB35174CA3714066D590DCD50994E8E6@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50994E8E6@usrymx25.merck.com>
Message-ID: <1db7268005032409582e7c0ccb@mail.gmail.com>

Thanks to everyone for your suggestions.  I will take them to our IT
department and see what can be done.  In windows I manage two R
sessions by running one Rgui and one Rterm.  Only thing that slows me
down is the input/output to the SQL Server tables.  Thanks again...


On Thu, 24 Mar 2005 12:42:31 -0500, Liaw, Andy <andy_liaw at merck.com> wrote:
> If I'm not mistaken, the problem of sharing applications on a Windows server
> among several users is not particular to R, but applies generally to that
> environment, and Reid's suggestion is the cheap(-est.?) way of getting
> around it.  (Windows is simply not designed for that kind of usage, whereas
> Linux, like Unix, _is_ designed for that.)  The problem is that it'd be
> difficult to cut-and-paste graphics as you could on a Windows box (although
> that might not be doable via remote desktop, either --- I don't know).
> 
> I routinely run upwards of 4 different, simultaneous R sessions on my 1.6GHz
> P-M laptop with 1GB ram, along with a few other applications.  Never have
> problems as long as none of them deal with very large data.
> 
> Andy
> 
> > From: Huntsinger, Reid
> >
> > You have probably considered this and it's not an option, but
> > just in case
> > it is, I suspect you could buy a dual Xeon machine with 4 GB
> > RAM and run
> > Linux + Samba etc for far less than the license fees for the
> > Windows Server
> > OS and S+ components. (Probably a whole cluster, in fact!)
> > Then users could
> > use Cygwin's X server or Xvnc on their Windows desktops to
> > run things like R
> > on it. The setup takes a little time, but ongoing maintenance
> > requirements
> > are very low.
> >
> > Reid Huntsinger
> >
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of roger bos
> > Sent: Thursday, March 24, 2005 10:57 AM
> > To: R-help at stat.math.ethz.ch
> > Subject: Re: [R] client-server setup for R
> >
> >
> > Maybe I didn't state my question as well as I should have.  First of
> > all, this is a windows environment.  I currently run R on my desktop
> > and I also have a server that I use that the connect to using remote
> > desktop.  Each machine has 4GB of memory and is a P4.  I run R on my
> > machine and on the server so I can have two programs running at once.
> > Other people in the company don't have as much memory as I do and have
> > older machines, so they may have trouble running R on their desktop.
> > And two people can't remote desktop into the server at the same time.
> >
> > So my restated question is, how do I share my server with other useRs?
> >  If this is more of an IT question than an R question, I apologize,
> > but it seems that S+ have a server version where clients connect from
> > their desktop and submit jobs and I was wonder is there is an R
> > version.
> >
> >
> >
> >
> > On Thu, 24 Mar 2005 09:47:53 -0500, Huntsinger, Reid
> > <reid_huntsinger at merck.com> wrote:
> > > Is running R directly on the server machine and displaying
> > via X or Xvnc
> > an
> > > option?
> > >
> > > Reid Huntsinger
> > >
> > > -----Original Message-----
> > > From: r-help-bounces at stat.math.ethz.ch
> > > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of roger bos
> > > Sent: Thursday, March 24, 2005 9:28 AM
> > > To: R-help at stat.math.ethz.ch
> > > Subject: [R] client-server setup for R
> > >
> > > I am currently the only use-R at my company, but they are
> > considering
> > > buy a more powerful server and letting multiple people use it.  They
> > > asked me if R supports client-server setups.  I know S+ has a server
> > > version that does that.  I didn't find anything about that on CRAN,
> > > but hopefully someone can correct me.
> > >
> > > I did see some stuff about R web servers
> > > (http://franklin.imgen.bcm.tmc.edu/R.web.servers/ )
> > > and that looked very interesting, but I don't know which one is best
> > > and I don't want to spend all my time in HTML programming to make
> > > front ends of all the users.  If I have no choice but to go the web
> > > server route, which one is the most mature?
> > >
> > > If I can't show them a pluasible solution, IT will make use buy S+
> > > server and I will have to modify all my code to make it work.  I
> > > really enjoy working in R.
> > >
> > > Thanks,
> > >
> > > Roger J. Bos
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> > >
> > >
> > --------------------------------------------------------------
> > --------------
> > --
> > > Notice:  This e-mail message, together with any
> > attachment...{{dropped}}
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> >
> > --------------------------------------------------------------
> > ----------------
> > Notice:  This e-mail message, together with any attachments,
> > contains information of Merck & Co., Inc. (One Merck Drive,
> > Whitehouse Station, New Jersey, USA 08889), and/or its
> > affiliates (which may be known outside the United States as
> > Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as
> > Banyu) that may be confidential, proprietary copyrighted
> > and/or legally privileged. It is intended solely for the use
> > of the individual or entity named on this message.  If you
> > are not the intended recipient, and have received this
> > message in error, please notify us immediately by reply
> > e-mail and then delete it from your system.
> > --------------------------------------------------------------
> > ----------------
> >
> >
> 
> ------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any attachment...{{dropped}}



From iacolonn at uiuc.edu  Thu Mar 24 19:00:21 2005
From: iacolonn at uiuc.edu (Ignacio Colonna)
Date: Thu, 24 Mar 2005 12:00:21 -0600
Subject: [R] summing values by group
In-Reply-To: <d15ea14a050324081265d3350e@mail.gmail.com>
Message-ID: <200503241800.j2OI0NTP016756@expredir6.cites.uiuc.edu>

Maybe aggregate() is what you are looking for?

e.g. say your data frame is called 'mydata'

sum.by.CAT<-aggregate(mydata,list(CAT),sum)

this will give you sums by CAT for all the variables in the data set and
will yield 'NA' for any character variables you may have.

Ignacio


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Larry White
Sent: Thursday, March 24, 2005 10:12 AM
To: R-help at stat.math.ethz.ch
Subject: [R] summing values by group

At the risk of being wacked for asking what should be obvious....  

I have a data frame with one categorical variable "CAT" and several
numeric variables.  I want to be able to get simple statistics on the
numeric variables by level.  For example, just as you can use table
(CAT) to get the counts, I'd like to be able to get the means and sums
by category.

If someone could point me in the right direction, I'd appreciate it.
I've been through the SimpleR and Using R for Data Analysis... docs
and I'm still clueless.

thanks for your help.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From prasad.chalasani at gs.com  Thu Mar 24 19:14:33 2005
From: prasad.chalasani at gs.com (Chalasani, Prasad)
Date: Thu, 24 Mar 2005 13:14:33 -0500
Subject: [R] Bloomberg data import
Message-ID: <AF003EF88447964B88823C3F50A6AB750ACFD33E@gsnbp25es.firmwide.corp.gs.com>

Dear R Folks,

I know that Enrique Bengoechea ( Credit Suisse ) had posted some code
snippets for importing Bloomberg historical data into R.
I found them to be very useful.

Has anyone succeeded in getting the below items
from Bloomberg to R?
(a) historical economic release data,
(b) tick/intra-day data
(c) bulk data such as Index membership info, etc.

If someone is willing to share their code
to get Bloomberg data into R, that would be 
extremely appreciated.

Regards,
Prasad



From edd at debian.org  Thu Mar 24 20:23:32 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 24 Mar 2005 19:23:32 +0000 (UTC)
Subject: [R] Bloomberg data import
References: <AF003EF88447964B88823C3F50A6AB750ACFD33E@gsnbp25es.firmwide.corp.gs.com>
Message-ID: <loom.20050324T201708-418@post.gmane.org>


Prasad,

Chalasani, Prasad <prasad.chalasani <at> gs.com> writes:
> I know that Enrique Bengoechea ( Credit Suisse ) had posted some code
> snippets for importing Bloomberg historical data into R.
> I found them to be very useful.
> 
> Has anyone succeeded in getting the below items
> from Bloomberg to R?
> (a) historical economic release data,
> (b) tick/intra-day data
> (c) bulk data such as Index membership info, etc.

Yes, I have a package that can do all of the above. See the presentation at
    http://dirk.eddelbuettel.com/papers/r_lim_bloomberg.pdf

> If someone is willing to share their code
> to get Bloomberg data into R, that would be 
> extremely appreciated.

Unfortunately the code belongs to my (former) employer and cannot be shared.

That said, with a modicum of effort and knowledge of C programming, you can
replicate the package based on a) the excellent Bloomberg C Api documentation
and examples, and b) the 'Writing R Extensions' manual, as well as your choice
among the 500+ packages on CRAN for concrete C linkage examples.  May be
worthwhile discussing with your IT group.  

Regards,  Dirk



From msvika at mscc.huji.ac.il  Thu Mar 24 20:38:23 2005
From: msvika at mscc.huji.ac.il (Vicky Landsman)
Date: Thu, 24 Mar 2005 21:38:23 +0200
Subject: [R] How to stop the minimization when the condition does not hold
Message-ID: <003301c530a9$0b16ff70$a200a8c0@HOME2>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050324/00011210/attachment.pl

From prasad.chalasani at gs.com  Thu Mar 24 20:40:37 2005
From: prasad.chalasani at gs.com (Chalasani, Prasad)
Date: Thu, 24 Mar 2005 14:40:37 -0500
Subject: [R] Bloomberg data import
Message-ID: <AF003EF88447964B88823C3F50A6AB750ACFD33F@gsnbp25es.firmwide.corp.gs.com>

Dirk,
Yes I am aware of your presentation.
Seems to me your approach is different from the one of Enrique Bengoechea:
you use the C API, whereas he uses the bloomberg ActiveX/COM API ( which
requires the RDCOMClient package 
from OmegaHat -- it doesn't work with R2001, so I actually downloaded Thomas
Baier's build of that package ).

I found that with Enrique's approach it's extremely easy to bang together 
R code to grab historical *daily* data from Bloomberg.
However when I tried to extend it to to grab Tick/Intraday data, 
it didn't work. I did look at the Bloomberg ActiveX documentation on 
my Bloomberg screen, and thought I followed their instructions, 
e.g I do ( with slight modification of  Enrique's framework ):

dat <- '2005-03-22'
from.t <- '10:00:00'
to.t <- '11:00:00'
# convert date + time to COM format.
comFrom <- as.comDate.Date(as.Date(dat), from.t)
comTo <- as.comDate.Date(as.Date(dat), to.t)
histData <- try(blCon$BLPGetHistoricalData(Security='IBM US Equity',
Fields="Last_Price",
                        StartDate=comFrom, EndDate=comTo, BarSize=0));

The documentation says that I can get tick data by simply setting BarSize to
0,
and using the appropriate field name -- I tried Last_Price, LAST_TRADE, etc
but to no avail -- I keep getting some kind of exception.

If someone has any hints as to how to get Tick/Intraday data, that would be
nice.


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Dirk Eddelbuettel
Sent: Thursday, March 24, 2005 2:24 PM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] Bloomberg data import



Prasad,

Chalasani, Prasad <prasad.chalasani <at> gs.com> writes:
> I know that Enrique Bengoechea ( Credit Suisse ) had posted some code 
> snippets for importing Bloomberg historical data into R. I found them 
> to be very useful.
> 
> Has anyone succeeded in getting the below items
> from Bloomberg to R?
> (a) historical economic release data,
> (b) tick/intra-day data
> (c) bulk data such as Index membership info, etc.

Yes, I have a package that can do all of the above. See the presentation at
    http://dirk.eddelbuettel.com/papers/r_lim_bloomberg.pdf

> If someone is willing to share their code
> to get Bloomberg data into R, that would be
> extremely appreciated.

Unfortunately the code belongs to my (former) employer and cannot be shared.

That said, with a modicum of effort and knowledge of C programming, you can
replicate the package based on a) the excellent Bloomberg C Api
documentation and examples, and b) the 'Writing R Extensions' manual, as
well as your choice among the 500+ packages on CRAN for concrete C linkage
examples.  May be worthwhile discussing with your IT group.  

Regards,  Dirk

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Thu Mar 24 20:48:44 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Mar 2005 19:48:44 +0000 (GMT)
Subject: [R] client-server setup for R
In-Reply-To: <3A822319EB35174CA3714066D590DCD50994E8E6@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50994E8E6@usrymx25.merck.com>
Message-ID: <Pine.LNX.4.61.0503241938430.8255@gannet.stats>

Running Hummingbird Exceed on the desktops would take a small proportion 
of the budget but provide full X and Windows interworking.  We regularly 
access R on remote Linux servers from Windows via PUTTY and Exceed (in 
fact I am writing this email that way from my laptop on my lap).

One comment on Reid's comment: these days I would very much advise getting 
a 64-bit server, and it is unlikely to be cost effective to buy a Xeon 
rather than AMD64.  That would put me off any form of Windows server 
unless you can acquire the appropriate 64-bit software (and R under 
Windows is not 64-bit with no suitable compiler/runtime in sight, and I 
believe the same is true of S-PLUS).

Note that the various DCOM servers do provide an R client-server solution 
under Windows.


On Thu, 24 Mar 2005, Liaw, Andy wrote:

> If I'm not mistaken, the problem of sharing applications on a Windows server
> among several users is not particular to R, but applies generally to that
> environment, and Reid's suggestion is the cheap(-est.?) way of getting
> around it.  (Windows is simply not designed for that kind of usage, whereas
> Linux, like Unix, _is_ designed for that.)  The problem is that it'd be
> difficult to cut-and-paste graphics as you could on a Windows box (although
> that might not be doable via remote desktop, either --- I don't know).
>
> I routinely run upwards of 4 different, simultaneous R sessions on my 1.6GHz
> P-M laptop with 1GB ram, along with a few other applications.  Never have
> problems as long as none of them deal with very large data.
>
> Andy
>
>> From: Huntsinger, Reid
>>
>> You have probably considered this and it's not an option, but just in 
>> case it is, I suspect you could buy a dual Xeon machine with 4 GB RAM 
>> and run Linux + Samba etc for far less than the license fees for the 
>> Windows Server OS and S+ components. (Probably a whole cluster, in 
>> fact!) Then users could use Cygwin's X server or Xvnc on their Windows 
>> desktops to run things like R on it. The setup takes a little time, but 
>> ongoing maintenance requirements are very low.
>>
>> Reid Huntsinger
>>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of roger bos
>> Sent: Thursday, March 24, 2005 10:57 AM
>> To: R-help at stat.math.ethz.ch
>> Subject: Re: [R] client-server setup for R
>>
>>
>> Maybe I didn't state my question as well as I should have.  First of
>> all, this is a windows environment.  I currently run R on my desktop
>> and I also have a server that I use that the connect to using remote
>> desktop.  Each machine has 4GB of memory and is a P4.  I run R on my
>> machine and on the server so I can have two programs running at once.
>> Other people in the company don't have as much memory as I do and have
>> older machines, so they may have trouble running R on their desktop.
>> And two people can't remote desktop into the server at the same time.
>>
>> So my restated question is, how do I share my server with other useRs?
>>  If this is more of an IT question than an R question, I apologize,
>> but it seems that S+ have a server version where clients connect from
>> their desktop and submit jobs and I was wonder is there is an R
>> version.
>>
>>
>>
>>
>> On Thu, 24 Mar 2005 09:47:53 -0500, Huntsinger, Reid
>> <reid_huntsinger at merck.com> wrote:
>>> Is running R directly on the server machine and displaying
>> via X or Xvnc
>> an
>>> option?
>>>
>>> Reid Huntsinger
>>>
>>> -----Original Message-----
>>> From: r-help-bounces at stat.math.ethz.ch
>>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of roger bos
>>> Sent: Thursday, March 24, 2005 9:28 AM
>>> To: R-help at stat.math.ethz.ch
>>> Subject: [R] client-server setup for R
>>>
>>> I am currently the only use-R at my company, but they are
>> considering
>>> buy a more powerful server and letting multiple people use it.  They
>>> asked me if R supports client-server setups.  I know S+ has a server
>>> version that does that.  I didn't find anything about that on CRAN,
>>> but hopefully someone can correct me.
>>>
>>> I did see some stuff about R web servers
>>> (http://franklin.imgen.bcm.tmc.edu/R.web.servers/ )
>>> and that looked very interesting, but I don't know which one is best
>>> and I don't want to spend all my time in HTML programming to make
>>> front ends of all the users.  If I have no choice but to go the web
>>> server route, which one is the most mature?
>>>
>>> If I can't show them a pluasible solution, IT will make use buy S+
>>> server and I will have to modify all my code to make it work.  I
>>> really enjoy working in R.
>>>
>>> Thanks,
>>>
>>> Roger J. Bos
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide!
>>> http://www.R-project.org/posting-guide.html
>>>
>>>
>> --------------------------------------------------------------
>> --------------
>> --
>>> Notice:  This e-mail message, together with any
>> attachment...{{dropped}}
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>>
>> --------------------------------------------------------------
>> ----------------
>> Notice:  This e-mail message, together with any attachments,
>> contains information of Merck & Co., Inc. (One Merck Drive,
>> Whitehouse Station, New Jersey, USA 08889), and/or its
>> affiliates (which may be known outside the United States as
>> Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as
>> Banyu) that may be confidential, proprietary copyrighted
>> and/or legally privileged. It is intended solely for the use
>> of the individual or entity named on this message.  If you
>> are not the intended recipient, and have received this
>> message in error, please notify us immediately by reply
>> e-mail and then delete it from your system.
>> --------------------------------------------------------------
>> ----------------
>>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From edd at debian.org  Thu Mar 24 21:00:01 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 24 Mar 2005 20:00:01 +0000 (UTC)
Subject: [R] Bloomberg data import
References: <AF003EF88447964B88823C3F50A6AB750ACFD33F@gsnbp25es.firmwide.corp.gs.com>
Message-ID: <loom.20050324T205242-249@post.gmane.org>


Prasad,

Chalasani, Prasad <prasad.chalasani <at> gs.com> writes:
> I found that with Enrique's approach it's extremely easy to bang together 
> R code to grab historical *daily* data from Bloomberg.
> However when I tried to extend it to to grab Tick/Intraday data, 
> it didn't work. I did look at the Bloomberg ActiveX documentation on 
> my Bloomberg screen, and thought I followed their instructions, 
> e.g I do ( with slight modification of  Enrique's framework ):
> 
> dat <- '2005-03-22'
> from.t <- '10:00:00'
> to.t <- '11:00:00'
> # convert date + time to COM format.
> comFrom <- as.comDate.Date(as.Date(dat), from.t)
> comTo <- as.comDate.Date(as.Date(dat), to.t)
> histData <- try(blCon$BLPGetHistoricalData(Security='IBM US Equity',
> Fields="Last_Price",
>                         StartDate=comFrom, EndDate=comTo, BarSize=0));
> 
> The documentation says that I can get tick data by simply setting BarSize to
> 0,
> and using the appropriate field name -- I tried Last_Price, LAST_TRADE, etc
> but to no avail -- I keep getting some kind of exception.
> 
> If someone has any hints as to how to get Tick/Intraday data, that would be
> nice.

I don't use ActiveX, so take this with a grain of salt. 

Based on the names of functions in the older C interface, I would conjecture
that the BLPGetHistoricalData() function does not return intra-daily data.
So you may need to find different functions for the intraday data and for the 
static data you were seeking as well. May be worth a try -- report back here
or on R-SIG-Finance if you succeed.  In any event, whatever you want to put
together for R via (D)COM has to first work in plain VB, no?

Do you have a current URL for the (D)COM code?  I haven't found it ever since
they had to take their server down after it got attacked.

Cheers, Dirk



From darrenleeweber at gmail.com  Thu Mar 24 21:02:31 2005
From: darrenleeweber at gmail.com (Darren Weber)
Date: Thu, 24 Mar 2005 12:02:31 -0800
Subject: [R] Tool for update
In-Reply-To: <1111554772.6580.1.camel@zhangqiang>
References: <1111554772.6580.1.camel@zhangqiang>
Message-ID: <d2095b8c05032412022d0ec3e4@mail.gmail.com>

Is there a way to set a cron job to automatically update packages?
Maybe something like this:

$unixprompt> R --vanilla update.packages()

Alternately, is it possible to use the RSPython plugin to create a
cron job.  Effectively calling R and update.packages() from a python
script?

Best, Darren


On Wed, 23 Mar 2005 16:12:52 +1100, Yuandan Zhang
<yzhang4 at turing.une.edu.au> wrote:
> Hi,
> 
> Is there any tool to check if there is update version of a package
> available? I look for things alike YUM for linux?
> 
> YD
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From millerj at truman.edu  Thu Mar 24 21:48:46 2005
From: millerj at truman.edu (Jason Miller)
Date: Thu, 24 Mar 2005 14:48:46 -0600
Subject: [R] OS X, exporting graphics, postscript()
Message-ID: <85bd9a07a812a5b58b2d3d53bd21b8a5@truman.edu>

Hello everyone,

I am new to R, using version 2.0.1 on a Macintosh running OS X 10.3.  I 
am learning how to export graphics to postscript format using the 
postscript() function, but R is only writing empty files.

Yesterday, postscript() was working for me.  Today, I don't know what's 
wrong.  Can somebody suggest some things that might fix this problem?

Thanks in advance for you help.

Jason


================================================================
Jason E. Miller, Ph.D.
Associate Professor of Mathematics
Truman State University
Kirksville, MO
http://pyrite.truman.edu/~millerj/
660.785.7430



From msvika at mscc.huji.ac.il  Thu Mar 24 22:01:04 2005
From: msvika at mscc.huji.ac.il (Vicky Landsman)
Date: Thu, 24 Mar 2005 23:01:04 +0200
Subject: [R] Bivariate lognormal distribution 
Message-ID: <007901c530b4$981840e0$a200a8c0@HOME2>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050324/2d3ac5e5/attachment.pl

From tlumley at u.washington.edu  Thu Mar 24 22:03:25 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 24 Mar 2005 13:03:25 -0800 (PST)
Subject: [R] Tool for update
In-Reply-To: <d2095b8c05032412022d0ec3e4@mail.gmail.com>
References: <1111554772.6580.1.camel@zhangqiang>
	<d2095b8c05032412022d0ec3e4@mail.gmail.com>
Message-ID: <Pine.A41.4.61b.0503241254280.52736@homer05.u.washington.edu>

On Thu, 24 Mar 2005, Darren Weber wrote:

> Is there a way to set a cron job to automatically update packages?
> Maybe something like this:
>
> $unixprompt> R --vanilla update.packages()
>

If you put
update.packages(repos="http://cran.us.r-project.org", ask=FALSE)

in a file update.R you can do
   R CMD BATCH update.R update.log
or even fancier, something like
   R CMD BATCH update.R update-`date --iso-8601`.log

to keep dated log files.

 	-thomas



From prasad.chalasani at gs.com  Thu Mar 24 22:09:40 2005
From: prasad.chalasani at gs.com (Chalasani, Prasad)
Date: Thu, 24 Mar 2005 16:09:40 -0500
Subject: [R] Bloomberg data import
Message-ID: <AF003EF88447964B88823C3F50A6AB750ACFD341@gsnbp25es.firmwide.corp.gs.com>

Dirk,

the URL for the working binary of RDCOMClient is at the bottom this page:
http://tolstoy.newcastle.edu.au/R/help/04/11/6759.html

it works with my R 2001.


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Dirk Eddelbuettel
Sent: Thursday, March 24, 2005 3:00 PM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] Bloomberg data import



Prasad,

Chalasani, Prasad <prasad.chalasani <at> gs.com> writes:
> I found that with Enrique's approach it's extremely easy to bang 
> together
> R code to grab historical *daily* data from Bloomberg.
> However when I tried to extend it to to grab Tick/Intraday data, 
> it didn't work. I did look at the Bloomberg ActiveX documentation on 
> my Bloomberg screen, and thought I followed their instructions, 
> e.g I do ( with slight modification of  Enrique's framework ):
> 
> dat <- '2005-03-22'
> from.t <- '10:00:00'
> to.t <- '11:00:00'
> # convert date + time to COM format.
> comFrom <- as.comDate.Date(as.Date(dat), from.t)
> comTo <- as.comDate.Date(as.Date(dat), to.t)
> histData <- try(blCon$BLPGetHistoricalData(Security='IBM US Equity', 
> Fields="Last_Price",
>                         StartDate=comFrom, EndDate=comTo, BarSize=0));
> 
> The documentation says that I can get tick data by simply setting 
> BarSize to 0, and using the appropriate field name -- I tried 
> Last_Price, LAST_TRADE, etc but to no avail -- I keep getting some 
> kind of exception.
> 
> If someone has any hints as to how to get Tick/Intraday data, that 
> would be nice.

I don't use ActiveX, so take this with a grain of salt. 

Based on the names of functions in the older C interface, I would conjecture
that the BLPGetHistoricalData() function does not return intra-daily data.
So you may need to find different functions for the intraday data and for
the 
static data you were seeking as well. May be worth a try -- report back here
or on R-SIG-Finance if you succeed.  In any event, whatever you want to put
together for R via (D)COM has to first work in plain VB, no?

Do you have a current URL for the (D)COM code?  I haven't found it ever
since they had to take their server down after it got attacked.

Cheers, Dirk

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From Carlisle.Thacker at noaa.gov  Thu Mar 24 22:15:50 2005
From: Carlisle.Thacker at noaa.gov (Carlisle Thacker)
Date: Thu, 24 Mar 2005 16:15:50 -0500
Subject: [R] help.start search
In-Reply-To: <4d7b149f8a.49f8a4d7b1@noaa.gov>
References: <4d7b149f8a.49f8a4d7b1@noaa.gov>
Message-ID: <42432E06.7000405@noaa.gov>

Dear R experts,

When using R 2.1 under Red Hat Enterprise Linux 4 with Mozilla 1.7.6 as
browser, help.start() almost works correctly.  When I follow one of the
search result links everything is fine, but when I go back to follow
another link, I find them all inactive.  So I have to redo the search.

Any suggestions?

Thanks,

Carlisle Thacker

> version
         _
platform i686-redhat-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    2
minor    0.1
year     2004
month    11
day      15
language R



From edd at debian.org  Thu Mar 24 22:21:18 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 24 Mar 2005 21:21:18 +0000 (UTC)
Subject: [R] Bloomberg data import
References: <AF003EF88447964B88823C3F50A6AB750ACFD341@gsnbp25es.firmwide.corp.gs.com>
Message-ID: <loom.20050324T221925-481@post.gmane.org>


Prasad,

Chalasani, Prasad <prasad.chalasani <at> gs.com> writes:
> the URL for the working binary of RDCOMClient is at the bottom this page:
> http://tolstoy.newcastle.edu.au/R/help/04/11/6759.html
> 
> it works with my R 2001.

My bad -- I was looking for the Beier/Neuwirth one which seems to have 
disappeared. I knew about the Omegahat-based RDCOMClient, but tend to confuse
them at times.

Thanks for this pointer, though.

Regards, Dirk



From MSchwartz at MedAnalytics.com  Thu Mar 24 22:35:14 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu, 24 Mar 2005 15:35:14 -0600
Subject: [R] help.start search
In-Reply-To: <42432E06.7000405@noaa.gov>
References: <4d7b149f8a.49f8a4d7b1@noaa.gov>  <42432E06.7000405@noaa.gov>
Message-ID: <1111700114.17043.7.camel@horizons.localdomain>

On Thu, 2005-03-24 at 16:15 -0500, Carlisle Thacker wrote:
> Dear R experts,
> 
> When using R 2.1 under Red Hat Enterprise Linux 4 with Mozilla 1.7.6 as
> browser, help.start() almost works correctly.  When I follow one of the
> search result links everything is fine, but when I go back to follow
> another link, I find them all inactive.  So I have to redo the search.
> 
> Any suggestions?

This is a known problem with Mozilla based browsers when viewing
dynamically generated HTML pages, which is the case with the HTML pages
resulting from help.start() searches.

The best work-around is to open a link from the search results in a new
tab rather than in the same window. That way you can close the tab when
done and be back at the results page with live links, rather than having
to redo the search itself.

Also, presumably you are using R 2.0.1, not R 2.1?

HTH,

Marc Schwartz



From ripley at stats.ox.ac.uk  Thu Mar 24 22:38:51 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Mar 2005 21:38:51 +0000 (GMT)
Subject: [R] help.start search
In-Reply-To: <42432E06.7000405@noaa.gov>
References: <4d7b149f8a.49f8a4d7b1@noaa.gov> <42432E06.7000405@noaa.gov>
Message-ID: <Pine.LNX.4.61.0503242133001.9482@gannet.stats>

On Thu, 24 Mar 2005, Carlisle Thacker wrote:

> Dear R experts,
>
> When using R 2.1 under Red Hat Enterprise Linux 4 with Mozilla 1.7.6 as

There is no such version.  If you are using an alpha test of 2.1.0, please 
report exactly which one.  It is not relevant here, but could have been.

> browser, help.start() almost works correctly.  When I follow one of the
> search result links everything is fine, but when I go back to follow
> another link, I find them all inactive.  So I have to redo the search.
>
> Any suggestions?

Use another browser or live with it.

It is a known Mozilla quirk (shared by all the browsers that use the 
Mozilla engine).  As far as I recall, Opera and IE6 do this correctly, but 
I just live with it.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Mar 24 22:47:57 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Mar 2005 21:47:57 +0000 (GMT)
Subject: [R] Bivariate lognormal distribution 
In-Reply-To: <007901c530b4$981840e0$a200a8c0@HOME2>
References: <007901c530b4$981840e0$a200a8c0@HOME2>
Message-ID: <Pine.LNX.4.61.0503242140340.9482@gannet.stats>

On Thu, 24 Mar 2005, Vicky Landsman wrote:

> Is there a package that enables to create the bivariate log-normal 
> variables?

Just exponentiate each of a bivariate normal pair.  You can get the 
latter from mvrnorm in package MASS.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Thu Mar 24 23:11:33 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 24 Mar 2005 23:11:33 +0100
Subject: [R] help.start search
In-Reply-To: <42432E06.7000405@noaa.gov>
References: <4d7b149f8a.49f8a4d7b1@noaa.gov> <42432E06.7000405@noaa.gov>
Message-ID: <x2sm2k4ru2.fsf@turmalin.kubism.ku.dk>

"Carlisle Thacker" <Carlisle.Thacker at noaa.gov> writes:

> Dear R experts,
> 
> When using R 2.1 under Red Hat Enterprise Linux 4 with Mozilla 1.7.6 as
> browser, help.start() almost works correctly.  When I follow one of the
> search result links everything is fine, but when I go back to follow
> another link, I find them all inactive.  So I have to redo the search.
> 
> Any suggestions?

There are issues with the Mozilla rendering engines and dynamically
generated pages. Check out Marc Schwartz' analysis of the situation in
e.g. https://stat.ethz.ch/pipermail/r-help/2003-April/030972.html. He
also points out that a workaround is to use tabbed browsind so that
you don't have to use Back.

I still see the same effect with Firefox 1.0.2 and j2re-1.4.2 on FC3.

BTW, R 2.0.1 is not R 2.1. The distinction is going to be important
about 3.5 weeks from now.


> Thanks,
> 
> Carlisle Thacker
> 
> > version
>          _
> platform i686-redhat-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    2
> minor    0.1
> year     2004
> month    11
> day      15
> language R
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From vokey at uleth.ca  Thu Mar 24 23:22:07 2005
From: vokey at uleth.ca (Dr. John R. Vokey)
Date: Thu, 24 Mar 2005 15:22:07 -0700
Subject: [R] Has the add parameter of plot commands been deprecated?
Message-ID: <ba7862d06a98699b2bb48a0a44344909@uleth.ca>

R for OS X, version 2.0.1

Has the add parameter of plot commands been deprecated?  It no longer 
occurs in the help listing for plot, and doesn't work, either.  If it 
has been deprecated, what is the replacement?  That is, how does one 
overlay an existing plot?
--
John R. Vokey, PhD
Professor
B.E.R.G. - Behaviour and Evolution Research Group
Micro-Cognition Laboratory
Department of Psychology & Neuroscience
University of Lethbridge
Lethbridge, Alberta T1K 3M4
CANADA



From andy_liaw at merck.com  Thu Mar 24 23:43:23 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 24 Mar 2005 17:43:23 -0500
Subject: [R] Has the add parameter of plot commands been deprecated?
Message-ID: <3A822319EB35174CA3714066D590DCD50994E8F1@usrymx25.merck.com>

For what class?  I believe that argument was never part of plot.default().
You might have been using the plot method of some class that provide that
argument.

Andy

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Dr. John R. Vokey
Sent: Thursday, March 24, 2005 5:22 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Has the add parameter of plot commands been deprecated?


R for OS X, version 2.0.1

Has the add parameter of plot commands been deprecated?  It no longer 
occurs in the help listing for plot, and doesn't work, either.  If it 
has been deprecated, what is the replacement?  That is, how does one 
overlay an existing plot?
--
John R. Vokey, PhD
Professor
B.E.R.G. - Behaviour and Evolution Research Group
Micro-Cognition Laboratory
Department of Psychology & Neuroscience
University of Lethbridge
Lethbridge, Alberta T1K 3M4
CANADA

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From macq at llnl.gov  Fri Mar 25 00:07:20 2005
From: macq at llnl.gov (Don MacQueen)
Date: Thu, 24 Mar 2005 15:07:20 -0800
Subject: [R] OS X, exporting graphics, postscript()
In-Reply-To: <85bd9a07a812a5b58b2d3d53bd21b8a5@truman.edu>
References: <85bd9a07a812a5b58b2d3d53bd21b8a5@truman.edu>
Message-ID: <p06210212be68f7b3bfe5@[128.115.153.6]>

Since it was only yesterday, perhaps you can think over what you did 
between then and now that might have affected things.

R is very stable; it is very unlikely that R has changed. Hence, 
either something outside R changed that affects R's postscript output 
-- also unlikely -- or you are doing something different in what you 
are telling R to do. Since you didn't provide examples that fail, we 
can only guess...

Are you giving exactly the same commands today on exactly the same data?
Are you remembering to use dev.off() after the graphics commands are complete?

-Don

At 2:48 PM -0600 3/24/05, Jason Miller wrote:
>Hello everyone,
>
>I am new to R, using version 2.0.1 on a Macintosh running OS X 10.3. 
>I am learning how to export graphics to postscript format using the 
>postscript() function, but R is only writing empty files.
>
>Yesterday, postscript() was working for me.  Today, I don't know 
>what's wrong.  Can somebody suggest some things that might fix this 
>problem?
>
>Thanks in advance for you help.
>
>Jason
>
>
>================================================================
>Jason E. Miller, Ph.D.
>Associate Professor of Mathematics
>Truman State University
>Kirksville, MO
>http://pyrite.truman.edu/~millerj/
>660.785.7430
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From p.murrell at auckland.ac.nz  Fri Mar 25 00:31:49 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Fri, 25 Mar 2005 11:31:49 +1200
Subject: [R] Lattice : factor levels in the margins
References: <4240316C.1050201@fsagx.ac.be>
Message-ID: <42434DE5.4070403@stat.auckland.ac.nz>

Hi


Yves Brostaux wrote:
> Hello !
> 
> I'm struggling again against lattice graprhics. ;) I'm trying to produce 
> a conditionnal xyplot with two conditionning factors (let's say A and 
> B). I want the levels of those factors (A1, A2, etc)  to show in the 
> margins of the lattice plot, not in the strips between the panels.
> 
> A1     A2     A3
> 
> plot11 plot12 plot13  B1
> 
> plot21 plot22 plot23  B2
> 
> 
> I managed to remove the strips with strip=FALSE, but now I can't find 
> how to write the levels of the factors in the margin in front of their 
> respective lines/columns. It doesn't seems that xlab and ylab arguments 
> could help doing this, as I can't insert multiple xlab's (x variable and 
> A levels, or y variable and B levels) and can't decide which side to use 
> for writing them.
> 
> Does anybody have a hint ? Thank you very much !


Here's one approach, using trellis.focus() and grid.text().  This 
particular example is obviously hand-tuned to the example data set, but 
it shouldn't be too hard to generalise.  I don't think you can do this 
via a panel function because output is clipped to the current panel for 
panel functions (Deepayan Sarkar may be able to confirm or deny that).

# "standard" dotplot
dotplot(variety ~ yield | year * site, data=barley)

# Customised version
library(grid)
# lattice plot without strips
dotplot(variety ~ yield | year * site, data=barley,
         strip=FALSE)
# move to panel (1, 6) and turn clipping off so can draw outside panel
trellis.focus("panel", 1, 6, clip.off=TRUE, highlight=FALSE)
# draw factor label 2 lines above the top of the panel
grid.text("1932", y=unit(1, "npc") + unit(2, "lines"))
# move to next panel, repeat ad nauseam
trellis.focus("panel", 2, 6, clip.off=TRUE, highlight=FALSE)
grid.text("1931", y=unit(1, "npc") + unit(2, "lines"))
grid.text("Waseca", x=unit(1, "npc") + unit(1, "lines"), rot=90)
trellis.focus("panel", 2, 5, clip.off=TRUE, highlight=FALSE)
grid.text("Crookston", x=unit(1, "npc") + unit(1, "lines"), rot=90)
trellis.focus("panel", 2, 4, clip.off=TRUE, highlight=FALSE)
grid.text("Morris", x=unit(1, "npc") + unit(1, "lines"), rot=90)
trellis.focus("panel", 2, 3, clip.off=TRUE, highlight=FALSE)
grid.text("University Farm", x=unit(1, "npc") + unit(1, "lines"), rot=90)
trellis.focus("panel", 2, 2, clip.off=TRUE, highlight=FALSE)
grid.text("Duluth", x=unit(1, "npc") + unit(1, "lines"), rot=90)
trellis.focus("panel", 2, 1, clip.off=TRUE, highlight=FALSE)
grid.text("Grand Rapids", x=unit(1, "npc") + unit(1, "lines"), rot=90)

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From wgshi2001 at yahoo.ca  Fri Mar 25 01:29:52 2005
From: wgshi2001 at yahoo.ca (Weiguang Shi)
Date: Thu, 24 Mar 2005 19:29:52 -0500 (EST)
Subject: [R] questions on ARMA and KPSS
Message-ID: <20050325002952.40782.qmail@web30014.mail.mud.yahoo.com>

Hi,

I have been fitting a series of data representing 
a week of Internet traffic (which is daily seasonal 
and have a general trend toward lower rate at the 
weekends). 

Before I do the ARMA fit (which takes care of
seasonality with a lag equal to one day), do I 
have to make sure the data is stationary? From the
results and visually, it seems that this was taken 
care of. But the residual failed the kpss test with 
a p-value less than 0.01.

Thank you,
Weiguang



From kjetil at acelerate.com  Fri Mar 25 01:28:51 2005
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Thu, 24 Mar 2005 20:28:51 -0400
Subject: [R] mixtures as outcome variables
In-Reply-To: <42419B19.5020309@acelerate.com>
References: <1111533080.4000.98.camel@wizard> <42419B19.5020309@acelerate.com>
Message-ID: <42435B43.3090308@acelerate.com>

Kjetil Brinchmann Halvorsen wrote:

> Jason W. Martinez wrote:
>
>> Dear R-users,
>>
>> I have an outcome variable and I'm unsure about how to treat it. Any
>> advice?
>>
> If you only concentrate on the relative proportions, this are called 
> compositional data. I f your data are in
> mydata (n x 4), you obtain compositions by
> sweep(mydata, 1, apply(mydata, 1, sum), "/")
>
> There are not (AFAIK) specific functions/packages for R for 
> compositional data AFAIK, but you
> can try googling. Aitchison  has a monography (Chapman & Hall) and a 
> paper in JRSS B.
>
> One way to start might be lm's or anova on the symmetric logratio 
> transform of the
> compositons. The R function lm can take a multivariate response, but 
> some extra programming will be needed
> for interpretation. With simulated data:
>
> > slr
> function(y) { # y should sum to 1
>          v <- log(y)
>          return( v - mean(v) ) }
> > testdata <- matrix( rgamma(120, 2,3), 30, 4)
> > str(testdata)
> num [1:30, 1:4] 0.200 0.414 0.311 2.145 0.233 ...
> > comp <- sweep(testdata, 1, apply(testdata,1,sum), "/")
> # To get the symmetric logratio transform:
> comp <- t(apply(comp, 1, slr))
> # Observe:
> apply(cov(comp), 1, sum)
> [1] -5.551115e-17  2.775558e-17  5.551115e-17 -2.775558e-17
> > lm( comp ~ 1)
>
> Call:
> lm(formula = comp ~ 1)
>
> Coefficients:
>             [,1]      [,2]      [,3]      [,4]   (Intercept)   
> 0.17606   0.06165  -0.03783  -0.19988

Followup:

 > mmod <- manova(comp ~ x)
 > summary(mmod)
Error in summary.manova(mmod) : residuals have rank 3 < 4
 >

So the manova() function cannot be used. I guess MANOVA for 
compositional data should be
a straight extension, but it must be programmed , standard manova cannot 
be used.

Kjetil

-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra





-- 
No virus found in this outgoing message.
Checked by AVG Anti-Virus.



From kjetil at acelerate.com  Fri Mar 25 01:31:09 2005
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Thu, 24 Mar 2005 20:31:09 -0400
Subject: [R] Bivariate lognormal distribution
In-Reply-To: <007901c530b4$981840e0$a200a8c0@HOME2>
References: <007901c530b4$981840e0$a200a8c0@HOME2>
Message-ID: <42435BCD.2020206@acelerate.com>

Vicky Landsman wrote:

>Dear experts! 
>Is there a package that enables to create the bivariate log-normal variables? 
>  
>

What do you mean by create? If you mean simulate, why not use mvrnorm 
from MASS, and
then exponentiate?

Kjetil

>Thanks a lot, 
>Vicky Landsman. 
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>


-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra





-- 
No virus found in this outgoing message.
Checked by AVG Anti-Virus.



From w.northcott at unsw.edu.au  Fri Mar 25 03:36:42 2005
From: w.northcott at unsw.edu.au (Bill Northcott)
Date: Fri, 25 Mar 2005 13:36:42 +1100
Subject: [R] Does R work in 64 bit on apple G5
In-Reply-To: <200503241110.j2OB5Vpk025258@hypatia.math.ethz.ch>
References: <200503241110.j2OB5Vpk025258@hypatia.math.ethz.ch>
Message-ID: <3021c3e55354f6cf6fd51f2377d6926c@unsw.edu.au>

On 24/03/2005, at 10:10 PM, David Ruau wrote:
> I am working with R on 2xG5 1.8Ghz from Apple under 10.3.8
> The G5 chip is 64 bits but does R run in 64 bit or 32 under OS X?
> How can know?
> I think it run in 32 bits... but not sure...
>
It is not possible to build and run 64bit apps in MacOS X under 10.3.x. 
  The problem is not just the compiler.  For a workable 64 bit app you 
also need 64bit system libraries libm etc.  As a matter of interest the 
current kernel is 64 bit and can manage large continuous memory spaces. 
  However, application memory partitions are limited to 2GB each.

MacOS X 10.4 (Tiger) will have 'fat' (64/32 bit) system libraries and 
it will be possible to build 64 bit apps.  However, Cocoa, Carbon and 
all the GUI stuff will remain 32 bit, because making it 64 bit would 
slow performance and increase memory footprint with no user benefit.  
You can find the full story at:
http://developer.apple.com/macosx/tiger/64bit.html

What benefit do you think you are going to get from running 64 bit?  In 
general there will be a performance penalty and unless you need an 
application memory space larger than 2GB there is no benefit.  
Processor arithmetic is unchanged between 32 and 64 bit modes.

Bill Northcott



From deepayan at stat.wisc.edu  Fri Mar 25 05:11:26 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 24 Mar 2005 22:11:26 -0600
Subject: [R] Error bars for Lattice Plots
In-Reply-To: <2DBF8A8E1A1AEE4AB3618AC4D6BF30880147B1C2@houston.tanox.net>
References: <2DBF8A8E1A1AEE4AB3618AC4D6BF30880147B1C2@houston.tanox.net>
Message-ID: <200503242211.26572.deepayan@stat.wisc.edu>

On Thursday 24 March 2005 08:21, Shawn Way wrote:
> Has anyone found a method for creating error bars in lattice plots?

Yes.

You'll have to be more specific to get anything useful (but check out 
xYplot in the Hmisc package).

Deepayan



From deepayan at stat.wisc.edu  Fri Mar 25 05:31:17 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 24 Mar 2005 22:31:17 -0600
Subject: [R] Lattice : factor levels in the margins
In-Reply-To: <42434DE5.4070403@stat.auckland.ac.nz>
References: <4240316C.1050201@fsagx.ac.be>
	<42434DE5.4070403@stat.auckland.ac.nz>
Message-ID: <200503242231.17631.deepayan@stat.wisc.edu>

On Thursday 24 March 2005 17:31, Paul Murrell wrote:
> Hi
>
> Yves Brostaux wrote:
> > Hello !
> >
> > I'm struggling again against lattice graprhics. ;) I'm trying to
> > produce a conditionnal xyplot with two conditionning factors (let's
> > say A and B). I want the levels of those factors (A1, A2, etc)  to
> > show in the margins of the lattice plot, not in the strips between
> > the panels.
> >
> > A1     A2     A3
> >
> > plot11 plot12 plot13  B1
> >
> > plot21 plot22 plot23  B2
> >
> >
> > I managed to remove the strips with strip=FALSE, but now I can't
> > find how to write the levels of the factors in the margin in front
> > of their respective lines/columns. It doesn't seems that xlab and
> > ylab arguments could help doing this, as I can't insert multiple
> > xlab's (x variable and A levels, or y variable and B levels) and
> > can't decide which side to use for writing them.
> >
> > Does anybody have a hint ? Thank you very much !
>
> Here's one approach, using trellis.focus() and grid.text().  This
> particular example is obviously hand-tuned to the example data set,
> but it shouldn't be too hard to generalise.  I don't think you can do
> this via a panel function because output is clipped to the current
> panel for panel functions (Deepayan Sarkar may be able to confirm or
> deny that).

That can be overridden with 

par.settings = list(clip = list(panel = "off"))

The problem with doing this inside the panel function is that the panel 
function has no way of knowing (in general) where in the eventual 
layout it is.

Deepayan

> [...]



From lzhtom at hotmail.com  Fri Mar 25 06:13:23 2005
From: lzhtom at hotmail.com (zhihua li)
Date: Fri, 25 Mar 2005 05:13:23 +0000
Subject: [R] learning networks with a large number of variables and pre-set
	parents.
In-Reply-To: <BAY12-F165FB85EC0476372F19C2FC7400@phx.gbl>
Message-ID: <BAY12-F34713F9618A7E4D3FB72AEC7410@phx.gbl>

hi netters: 

I have a series of  discrete variables which form a network and  I want to 
learn the network structure from some training data. I could have used 
packages like deal but there are two problems. 

First of all, I have 10000 variables. So the possible network structure is 
awfully huge, I don't know how long it will take my PC to find the 
highest-scoring network..........maybe a month? 
Secondly, I have some prior knowledge that only 500 out of the 10000 
variales are possible parents. In another word, only those arrows startting 
from the 500 variables and pointing to the remaining 99500 variables are 
allowed in the network.  In deal an assignment to "banlist" should help me 
rule out the impossible arrows. But in my case the number of "impossible 
arrows" is  500*499+99500*99549, and so the "banlist" would get 
unacceptable long. Are there any methods (in deal or other packages) to 
specify the parents set in advance? 

Thanks a lot!



From ales.ziberna at guest.arnes.si  Fri Mar 25 09:16:29 2005
From: ales.ziberna at guest.arnes.si (=?windows-1250?Q?Ale=9A_=8Eiberna?=)
Date: Fri, 25 Mar 2005 09:16:29 +0100
Subject: [R] How to stop the minimization when the condition does not hold
References: <003301c530a9$0b16ff70$a200a8c0@HOME2>
Message-ID: <007d01c53113$1c03d500$5506f9c2@ales>

First you have to be more specific, what are actually the parameters of the 
function that
you want to optiomize and what are actually constants.

So you would need to specify your objective function
"function(theta)=lambda*(Constr)^2-f(x,theta)" (which is not realy writen
the R-way)
as
fun<-function(Constr,theta){lambda*(Constr)^2-f(x,theta)}
However, since, if I understand correclty, you don't want Constr to be
smaller or equal to d, you should somehow build this into your objective
function, like:

fun<-function(Constr,theta){lambda*(Constr)^2-f(x,theta)+ifelse(Constr<=d,
Inf, 0)}

I hope this helps,
Ales Ziberna


----- Original Message ----- 
From: "Vicky Landsman" <msvika at mscc.huji.ac.il>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, March 24, 2005 8:38 PM
Subject: [R] How to stop the minimization when the condition does not hold


> Dear experts!
> I have a minimization problem with non-linear constraint and Objective
> function(theta)=lambda*(Constr)^2-f(x,theta). Theta is a vector of
> parameters.
> I'd like to stop the optimization after the value of the constraint is
> less
> or equal some constant value, say d, and save the last computed value of
> the
> function.
> For this purpose, I thought to define the Objective function like this:
>
> if (Constraint>d) fun<- ....
> else stop
>
> but this does not work with error message:
> Error in f(x, ...) : Object "fun" not found
>
> I am using nlm for minimization.
> Thanks a lot for help and suggestions,
> Vicky Landsman.
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>
>



From gregor.gorjanc at bfro.uni-lj.si  Fri Mar 25 09:32:02 2005
From: gregor.gorjanc at bfro.uni-lj.si (Gregor GORJANC)
Date: Fri, 25 Mar 2005 09:32:02 +0100
Subject: [R] Re: Cross-building R packages
In-Reply-To: <Pine.LNX.4.44.0503240823540.3155-100000@p-lnx401.stat.uiowa.edu>
References: <Pine.LNX.4.44.0503240823540.3155-100000@p-lnx401.stat.uiowa.edu>
Message-ID: <4243CC82.5010609@bfro.uni-lj.si>

Jun hi again!

Sorry for bothering. Although I had no problem with building Windows 
package under Linux, I noticed that man pages are not processed as they 
should or maybe I have a problem with my setup.

My package is called 'GeneticsPed'. Instead of HTML or text files I just 
got a GeneticsPed.Rd.gz in man directory of a package (this is within 
GeneticsPed_0.1.zip file!). The file GeneticsPed.Rd.gz contains is one 
file, where all man pages are in in Rd format. When I install package I 
just get this (GeneticsPed.Rd.gz) file in library.

I understand that I should dig into Makefiles and I tried, but I got lost. 
  I added below the output I got when compiling and there are some errors, 
but as I said I got lost when searching for cause.

Do you or any other from r-help have any clue what is wrong?

$ make pkg-GeneticsPed_0.1
export 
PATH=/home/packages/RCrossBuild/cross-tools/bin:/home/packages/RCrossBuild/cross-tools/mingw32/bin:.:/home/ggorjan/bin:/sbin:/bin:/usr/sbin:/usr/bin:/usr/X11R6/bin:/usr/local/sbin:/usr/local/bin:.:/home/ggorjan/apiis/apiis/bin:/home/ggorjan/apiis/apiis/../ref_breedprg/bin; 
\
export mypkg=`echo GeneticsPed_0.1 | cut -d'_' -f1,1`; \
cd /home/packages/RCrossBuild/pkgsrc; \
rm -rf $mypkg; \
tar zxf GeneticsPed_0.1.tar.gz; \
echo -------$mypkg------; \
cd /home/packages/RCrossBuild/WinR/R-2.0.1/src/gnuwin32/; \
make PKGDIR=/home/packages/RCrossBuild/pkgsrc 
RLIB=/home/packages/RCrossBuild/WinRlibs STAMP=no HELP=YES pkg-$mypkg; \
mkdir -p /home/packages/RCrossBuild/WinRlibs; \
cd /home/packages/RCrossBuild/WinRlibs; \
rm -rf $mypkg.zip; \
zip -rl $mypkg.zip $mypkg -x \*.so \*.dll \*.RData \*.rda \*.zip \*.rds 
\*.pdf \*.ps;\
zip -r9 $mypkg.zip $mypkg -i \*.so \*.dll \*.RData \*.rda \*.zip \*.rds 
\*.pdf \*.ps;\
rm -rf $mypkg
-------GeneticsPed------
make[1]: Entering directory 
`/home/packages/RCrossBuild/WinR/R-2.0.1/src/gnuwin32'

---------- Making package GeneticsPed ------------
   adding build stamp to DESCRIPTION
   installing R files
   installing man source files
   installing indices
cat: /home/packages/RCrossBuild/WinR/R-2.0.1/library/*/CONTENTS: No such 
file or directory
make[3]: *** [indices] Error 1
make[2]: *** [all] Error 2
make[1]: *** [pkg-GeneticsPed] Error 2
make[1]: Leaving directory 
`/home/packages/RCrossBuild/WinR/R-2.0.1/src/gnuwin32'
   adding: GeneticsPed/ (stored 0%)
   adding: GeneticsPed/DESCRIPTION (deflated 39%)
   adding: GeneticsPed/Meta/ (stored 0%)
   adding: GeneticsPed/R/ (stored 0%)
   adding: GeneticsPed/R/GeneticsPed (deflated 77%)
   adding: GeneticsPed/man/ (stored 0%)
   adding: GeneticsPed/man/GeneticsPed.Rd.gz     zip warning: -l used on 
binary file
  (stored 0%)
   adding: GeneticsPed/CONTENTS (deflated 74%)
   adding: GeneticsPed/INDEX (deflated 55%)
   adding: GeneticsPed/Meta/package.rds (deflated 51%)
   adding: GeneticsPed/Meta/Rd.rds (deflated 72%)
   adding: GeneticsPed/Meta/hsearch.rds (deflated 82%)


Jun Yan wrote:
> It's great to know that someone finds it helpful! Thanks for letting us 
> know. We'll keep it updated.
> 
> Jun
> 
> On Thu, 24 Mar 2005, Gregor GORJANC wrote:
> 
> 
>>Hello!
>>
>>I just went thourgh the process of creating a Windows package on my Linux 
>>box and I must say that it took me no longer than 30 minutes to wrap 
>>everything up and that's just because you two put everything together so 
>>nicely. I must say that you've done an excellent work. Keep on going!
>>
>>-- 
>>Lep pozdrav / With regards,
>>     Gregor Gorjanc
>>
>>-----------------------------------------------------------------------
>>University of Ljubljana
>>Biotechnical Faculty        URI: http://www.bfro.uni-lj.si/MR/ggorjan
>>Zootechnical Department     mail: gregor.gorjanc <at> bfro.uni-lj.si
>>Groblje 3                   tel: +386 (0)1 72 17 861
>>SI-1230 Domzale             fax: +386 (0)1 72 17 888
>>Slovenia, Europe
>>-----------------------------------------------------------------------
>>
> 
> 
> 

-- 
Lep pozdrav / With regards,
     Gregor Gorjanc

-----------------------------------------------------------------------
University of Ljubljana
Biotechnical Faculty        URI: http://www.bfro.uni-lj.si/MR/ggorjan
Zootechnical Department     mail: gregor.gorjanc <at> bfro.uni-lj.si
Groblje 3                   tel: +386 (0)1 72 17 861
SI-1230 Domzale             fax: +386 (0)1 72 17 888
Slovenia, Europe



From lami at faunalia.it  Fri Mar 25 10:35:37 2005
From: lami at faunalia.it (Leonardo Lami)
Date: Fri, 25 Mar 2005 10:35:37 +0100
Subject: [R] tapply and NA value
Message-ID: <200503251035.37640.lami@faunalia.it>

Hi,
I'm writing for a little help.
I have a dataframe with same NA value and I'd like to obtain the means of the 
value of a coloumn grouped by the levels of a factor coloumn of the datframe.
I'm using the function "tapply" but I see that if only a NA value is present 
the result is NA.
There is an option to have the correct result or I must use an other function?

Thanks of all
Leonardo
-- 
Leonardo Lami
lami at faunalia.it            www.faunalia.it
Via Colombo 3 - 51010 Massa e Cozzile (PT), Italy   Tel: (+39)349-1310164
GPG key @: hkp://wwwkeys.pgp.net http://www.pgp.net/wwwkeys.html
https://www.biglumber.com



From dimitris.rizopoulos at med.kuleuven.ac.be  Fri Mar 25 10:52:57 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Fri, 25 Mar 2005 10:52:57 +0100
Subject: [R] tapply and NA value
References: <200503251035.37640.lami@faunalia.it>
Message-ID: <00b901c53120$6c60e0d0$0540210a@www.domain>

you should look at the 'na.rm=FALSE' argument of '?mean()', i.e.,

x <- rnorm(100); x[sample(100, 10)] <- NA
f <- sample(letters[1:5], 100, TRUE)
###############
tapply(x, f, mean)
tapply(x, f, mean, na.rm=TRUE)


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Leonardo Lami" <lami at faunalia.it>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, March 25, 2005 10:35 AM
Subject: [R] tapply and NA value


> Hi,
> I'm writing for a little help.
> I have a dataframe with same NA value and I'd like to obtain the 
> means of the
> value of a coloumn grouped by the levels of a factor coloumn of the 
> datframe.
> I'm using the function "tapply" but I see that if only a NA value is 
> present
> the result is NA.
> There is an option to have the correct result or I must use an other 
> function?
>
> Thanks of all
> Leonardo
> -- 
> Leonardo Lami
> lami at faunalia.it            www.faunalia.it
> Via Colombo 3 - 51010 Massa e Cozzile (PT), Italy   Tel: 
> (+39)349-1310164
> GPG key @: hkp://wwwkeys.pgp.net http://www.pgp.net/wwwkeys.html
> https://www.biglumber.com
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ales.ziberna at guest.arnes.si  Fri Mar 25 10:59:10 2005
From: ales.ziberna at guest.arnes.si (=?ISO-8859-1?Q?Ales_Ziberna?=)
Date: Fri, 25 Mar 2005 10:59:10 +0100
Subject: [R] tapply and NA value
References: <200503251035.37640.lami@faunalia.it>
Message-ID: <00b301c53121$4fa173f0$5506f9c2@ales>

I am not really sure what you mean. If I understand you correctly, than all 
ylu have to do is to give additiona parameter to tapply, na.rm=TRUE,

tapply(...., na.rm=TRUE)

However as I already said, I'm not sure what you did and what is the 
problem. Plese provide the code that did not work, possibly with a workable 
example, as the posting guide suggests:
"PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html"

I hope this helps in anyway,
Ales Ziberna


----- Original Message ----- 
From: "Leonardo Lami" <lami at faunalia.it>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, March 25, 2005 10:35 AM
Subject: [R] tapply and NA value


> Hi,
> I'm writing for a little help.
> I have a dataframe with same NA value and I'd like to obtain the means of 
> the
> value of a coloumn grouped by the levels of a factor coloumn of the 
> datframe.
> I'm using the function "tapply" but I see that if only a NA value is 
> present
> the result is NA.
> There is an option to have the correct result or I must use an other 
> function?
>
> Thanks of all
> Leonardo
> -- 
> Leonardo Lami
> lami at faunalia.it            www.faunalia.it
> Via Colombo 3 - 51010 Massa e Cozzile (PT), Italy   Tel: (+39)349-1310164
> GPG key @: hkp://wwwkeys.pgp.net http://www.pgp.net/wwwkeys.html
> https://www.biglumber.com
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
>



From Achim.Zeileis at wu-wien.ac.at  Fri Mar 25 11:40:46 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Fri, 25 Mar 2005 11:40:46 +0100 (CET)
Subject: [R] learning networks with a large number of variables and
	pre-set parents.
In-Reply-To: <BAY12-F34713F9618A7E4D3FB72AEC7410@phx.gbl>
References: <BAY12-F34713F9618A7E4D3FB72AEC7410@phx.gbl>
Message-ID: <Pine.LNX.4.58.0503251137020.3626@thorin.ci.tuwien.ac.at>

This is the second time within 24 hours that you cross-posted the same
question to two of the R mailing lists, please read the posting guide
linked at the bottom of this mail on how to properly ask your questions.

As for your question: I'm not aware of an R package that would be able to
do what you are looking for, but you might also ask the maintainer of the
package you're specifically interested in for more details.
Z



On Fri, 25 Mar 2005, zhihua li wrote:

> hi netters:
>
> I have a series of  discrete variables which form a network and  I want to
> learn the network structure from some training data. I could have used
> packages like deal but there are two problems.
>
> First of all, I have 10000 variables. So the possible network structure is
> awfully huge, I don't know how long it will take my PC to find the
> highest-scoring network..........maybe a month?
> Secondly, I have some prior knowledge that only 500 out of the 10000
> variales are possible parents. In another word, only those arrows startting
> from the 500 variables and pointing to the remaining 99500 variables are
> allowed in the network.  In deal an assignment to "banlist" should help me
> rule out the impossible arrows. But in my case the number of "impossible
> arrows" is  500*499+99500*99549, and so the "banlist" would get
> unacceptable long. Are there any methods (in deal or other packages) to
> specify the parents set in advance?
>
> Thanks a lot!
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Allan at STATS.uct.ac.za  Fri Mar 25 12:48:44 2005
From: Allan at STATS.uct.ac.za (Clark Allan)
Date: Fri, 25 Mar 2005 13:48:44 +0200
Subject: [R] R: VAR package
Message-ID: <4243FA9C.A3694ED6@STATS.uct.ac.za>

hi all

i would like to fit VAR, vector autoregressive models, to a data set. is
there a package in R that does this?

From lami at faunalia.it  Fri Mar 25 12:51:48 2005
From: lami at faunalia.it (Leonardo Lami)
Date: Fri, 25 Mar 2005 12:51:48 +0100
Subject: [R] tapply and NA value
In-Reply-To: <00b901c53120$6c60e0d0$0540210a@www.domain>
References: <200503251035.37640.lami@faunalia.it>
	<00b901c53120$6c60e0d0$0540210a@www.domain>
Message-ID: <200503251251.48291.lami@faunalia.it>

Thanks very much!
Best of all,
Leonardo


Alle 10:52, venerd? 25 marzo 2005, Dimitris Rizopoulos ha scritto:
> you should look at the 'na.rm=FALSE' argument of '?mean()', i.e.,
>
> x <- rnorm(100); x[sample(100, 10)] <- NA
> f <- sample(letters[1:5], 100, TRUE)
> ###############
> tapply(x, f, mean)
> tapply(x, f, mean, na.rm=TRUE)
>
>
> I hope it helps.
>
> Best,
> Dimitris
>
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
>
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/16/336899
> Fax: +32/16/337015
> Web: http://www.med.kuleuven.ac.be/biostat/
>      http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
>
>
> ----- Original Message -----
> From: "Leonardo Lami" <lami at faunalia.it>
> To: <r-help at stat.math.ethz.ch>
> Sent: Friday, March 25, 2005 10:35 AM
> Subject: [R] tapply and NA value
>
> > Hi,
> > I'm writing for a little help.
> > I have a dataframe with same NA value and I'd like to obtain the
> > means of the
> > value of a coloumn grouped by the levels of a factor coloumn of the
> > datframe.
> > I'm using the function "tapply" but I see that if only a NA value is
> > present
> > the result is NA.
> > There is an option to have the correct result or I must use an other
> > function?
> >
> > Thanks of all
> > Leonardo
> > --
> > Leonardo Lami
> > lami at faunalia.it            www.faunalia.it
> > Via Colombo 3 - 51010 Massa e Cozzile (PT), Italy   Tel:
> > (+39)349-1310164
> > GPG key @: hkp://wwwkeys.pgp.net http://www.pgp.net/wwwkeys.html
> > https://www.biglumber.com
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html

-- 
Leonardo Lami
lami at faunalia.it            www.faunalia.it
Via Colombo 3 - 51010 Massa e Cozzile (PT), Italy   Tel: (+39)349-1310164
GPG key @: hkp://wwwkeys.pgp.net http://www.pgp.net/wwwkeys.html
https://www.biglumber.com



From Allan at STATS.uct.ac.za  Fri Mar 25 13:00:08 2005
From: Allan at STATS.uct.ac.za (Clark Allan)
Date: Fri, 25 Mar 2005 14:00:08 +0200
Subject: [R] R:var models
Message-ID: <4243FD48.AEDBB394@STATS.uct.ac.za>

HI ALL

i have found two package: dse and dse2.  are there others

From liuwensui at gmail.com  Fri Mar 25 14:11:19 2005
From: liuwensui at gmail.com (Wensui Liu)
Date: Fri, 25 Mar 2005 08:11:19 -0500
Subject: [R] newbie's question about dataframe
Message-ID: <1115a2b005032505114974e0cb@mail.gmail.com>

I have a dataframe containing X and Y. Right now, I want to create
another variable in the dataframe, named Z, such that for Z = 1 for
the top 10 largest value of Y and Z = 0 for the rest values of Y.

I really appreciate your help. Have a great weekend.



From andy_liaw at merck.com  Fri Mar 25 14:24:14 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 25 Mar 2005 08:24:14 -0500
Subject: [R] newbie's question about dataframe
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076CE3@usctmx1106.merck.com>

Something like this should do it:

 dat$Z <- with(dat, as.numeric(Y >= Y[order(Y, decreasing=TRUE)[10]]))

Andy

> From: Wensui Liu
> 
> I have a dataframe containing X and Y. Right now, I want to create
> another variable in the dataframe, named Z, such that for Z = 1 for
> the top 10 largest value of Y and Z = 0 for the rest values of Y.
> 
> I really appreciate your help. Have a great weekend.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From millerj at truman.edu  Fri Mar 25 14:26:26 2005
From: millerj at truman.edu (Jason Miller)
Date: Fri, 25 Mar 2005 07:26:26 -0600
Subject: [R] OS X, exporting graphics, postscript()
In-Reply-To: <p06210212be68f7b3bfe5@[128.115.153.6]>
References: <85bd9a07a812a5b58b2d3d53bd21b8a5@truman.edu>
	<p06210212be68f7b3bfe5@[128.115.153.6]>
Message-ID: <14f238e4d4ac11ebfa55598eb05769a0@truman.edu>

R users,

OK, so I feel dumb.  I didn't understand that dev.off() turns off the 
process of writing a file, and that I can't open a file until dev.off() 
is called to complete the file.

Thanks to everyone who responded to my call for help.

I'm really liking what I'm learning about R.  I hope to learn enough to 
teach my colleagues and students about it.

Jason

On Mar 24, 2005, at 5:07 PM, Don MacQueen wrote:

> Since it was only yesterday, perhaps you can think over what you did 
> between then and now that might have affected things.
>
> R is very stable; it is very unlikely that R has changed. Hence, 
> either something outside R changed that affects R's postscript output 
> -- also unlikely -- or you are doing something different in what you 
> are telling R to do. Since you didn't provide examples that fail, we 
> can only guess...
>
> Are you giving exactly the same commands today on exactly the same 
> data?
> Are you remembering to use dev.off() after the graphics commands are 
> complete?
>
> -Don
>
> At 2:48 PM -0600 3/24/05, Jason Miller wrote:
>> Hello everyone,
>>
>> I am new to R, using version 2.0.1 on a Macintosh running OS X 10.3. 
>> I am learning how to export graphics to postscript format using the 
>> postscript() function, but R is only writing empty files.
>>
>> Yesterday, postscript() was working for me.  Today, I don't know 
>> what's wrong.  Can somebody suggest some things that might fix this 
>> problem?
>>
>> Thanks in advance for you help.
>>
>> Jason
>>
>>
>> ================================================================
>> Jason E. Miller, Ph.D.
>> Associate Professor of Mathematics
>> Truman State University
>> Kirksville, MO
>> http://pyrite.truman.edu/~millerj/
>> 660.785.7430
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>
>
> -- 
> --------------------------------------
> Don MacQueen
> Environmental Protection Department
> Lawrence Livermore National Laboratory
> Livermore, CA, USA
> --------------------------------------
>
>
Jason E. Miller, Ph.D.
Associate Professor
Division of Mathematics & Computer Science
Truman State University
Kirksville, MO
millerj at truman.edu
http://pyrite.truman.edu/~millerj/
660.785.7430



From ligges at statistik.uni-dortmund.de  Fri Mar 25 14:33:16 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 25 Mar 2005 14:33:16 +0100
Subject: [R] newbie's question about dataframe
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076CE3@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076CE3@usctmx1106.merck.com>
Message-ID: <4244131C.7020704@statistik.uni-dortmund.de>

Liaw, Andy wrote:
> Something like this should do it:
> 
>  dat$Z <- with(dat, as.numeric(Y >= Y[order(Y, decreasing=TRUE)[10]]))

I was just about to post

   dat$Z <- as.numeric(rank(-dat$Y) <= 10)

so here it is, anyway. ;-)


Uwe



> Andy
> 
> 
>>From: Wensui Liu
>>
>>I have a dataframe containing X and Y. Right now, I want to create
>>another variable in the dataframe, named Z, such that for Z = 1 for
>>the top 10 largest value of Y and Z = 0 for the rest values of Y.
>>
>>I really appreciate your help. Have a great weekend.
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
>>
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From liuwensui at gmail.com  Fri Mar 25 14:38:25 2005
From: liuwensui at gmail.com (Wensui Liu)
Date: Fri, 25 Mar 2005 08:38:25 -0500
Subject: [R] newbie's question about dataframe
In-Reply-To: <4244131C.7020704@statistik.uni-dortmund.de>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076CE3@usctmx1106.merck.com>
	<4244131C.7020704@statistik.uni-dortmund.de>
Message-ID: <1115a2b0050325053819c6ee12@mail.gmail.com>

Thank you all for help. Have a nice day.


On Fri, 25 Mar 2005 14:33:16 +0100, Uwe Ligges
<ligges at statistik.uni-dortmund.de> wrote:
> Liaw, Andy wrote:
> > Something like this should do it:
> >
> >  dat$Z <- with(dat, as.numeric(Y >= Y[order(Y, decreasing=TRUE)[10]]))
> 
> I was just about to post
> 
>    dat$Z <- as.numeric(rank(-dat$Y) <= 10)
> 
> so here it is, anyway. ;-)
> 
> 
> Uwe
> 
> 
> > Andy
> >
> >
> >>From: Wensui Liu
> >>
> >>I have a dataframe containing X and Y. Right now, I want to create
> >>another variable in the dataframe, named Z, such that for Z = 1 for
> >>the top 10 largest value of Y and Z = 0 for the rest values of Y.
> >>
> >>I really appreciate your help. Have a great weekend.
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide!
> >>http://www.R-project.org/posting-guide.html
> >>
> >>
> >>
> >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 


-- 
WenSui Liu, MS MA
Senior Decision Support Analyst
Division of Health Policy and Clinical Effectiveness
Cincinnati Children Hospital Medical Center



From abunn at whrc.org  Fri Mar 25 15:05:03 2005
From: abunn at whrc.org (abunn)
Date: Fri, 25 Mar 2005 09:05:03 -0500
Subject: [R] Error in save.image...recursive default argument reference
In-Reply-To: <1115a2b0050325053819c6ee12@mail.gmail.com>
Message-ID: <NEBBIPHDAMMOKDKPOFFIEEGMDCAA.abunn@whrc.org>

Any ideas on this one? I get the save error with compress = T also. The
workspace is big. Rgui is sitting on about 300 mb of RAM. I can write
objects using write.table. -Thx, Andy


R > save.image("lm.gs.has.run.RData")
Error in save.image("lm.gs.has.run.RData") :
        recursive default argument reference
R > version
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    0.1
year     2004
month    11
day      15
language R
R >



From abunn at whrc.org  Fri Mar 25 15:16:09 2005
From: abunn at whrc.org (abunn)
Date: Fri, 25 Mar 2005 09:16:09 -0500
Subject: [R] Tool for update
In-Reply-To: <Pine.A41.4.61b.0503241254280.52736@homer05.u.washington.edu>
Message-ID: <NEBBIPHDAMMOKDKPOFFIOEGMDCAA.abunn@whrc.org>

I edited Rprofile to update everything on Tuesdays. I've been doing this
since 2.0 and I think I've had R running almost every Tuesday, which begs
the question of what I would be doing if R hadn't come into existence.

In any case, It works pretty well:

## This script gets all the packages I don't already have
# Run this once a week - say Tuesdays
if (interactive() ) { library(utils)}
is.tuesday <- as.POSIXlt(Sys.time())$wday == 2
if (is.tuesday == T)
{
    cat("Running a package check...\nOccurs once a week, on Tuesdays\n")
    cat("Upgrade existing packages and check for new packages (y/N)? ")
    check.new <- as.character(readLines(n = 1))
    if (any(check.new == "y", check.new == "Y"))
    {
        options(CRAN = "http://cran.us.r-project.org/")
        cat("This can take a few seconds...\n")
        x <- packageStatus(repositories = getOption("repositories")()[[1]])
        print(x)
        install.packages(x$avail$Package[x$avail$Status == "not installed"])
        cat("Upgrading to new versions if available\n")
        upgrade(x)
   }
}


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Thomas Lumley
> Sent: Thursday, March 24, 2005 4:03 PM
> To: Darren Weber
> Cc: r-help at stat.math.ethz.ch; jblock at radiology.ucsf.edu
> Subject: Re: [R] Tool for update
>
>
> On Thu, 24 Mar 2005, Darren Weber wrote:
>
> > Is there a way to set a cron job to automatically update packages?
> > Maybe something like this:
> >
> > $unixprompt> R --vanilla update.packages()
> >
>
> If you put
> update.packages(repos="http://cran.us.r-project.org", ask=FALSE)
>
> in a file update.R you can do
>    R CMD BATCH update.R update.log
> or even fancier, something like
>    R CMD BATCH update.R update-`date --iso-8601`.log
>
> to keep dated log files.
>
>  	-thomas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From spencer.graves at pdf.com  Fri Mar 25 15:40:50 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 25 Mar 2005 08:40:50 -0600
Subject: [R] Bivariate lognormal distribution
In-Reply-To: <Pine.LNX.4.61.0503242140340.9482@gannet.stats>
References: <007901c530b4$981840e0$a200a8c0@HOME2>
	<Pine.LNX.4.61.0503242140340.9482@gannet.stats>
Message-ID: <424422F2.8050903@pdf.com>

      I hope Professor Ripley will correct me if I'm mistaken, but the 
documentation for "mvrnorm" in library(MASS) says it will, "Simulate 
from a Multivariate Normal Distribution".  If you want the density 
function or probabilities or quantiles, you can get those from 
library(mvtnorm). 

      Just for completeness, to use normal for a lognormal, you need to 
take the logarithms of your number (which must be all positive;  zeros 
and negative numbers become NA), then compute mean vector and variance 
matrix of the logs, compute probabilities on the log scale, then back 
transform by exponentiating to get the results back into the original 
scale. 

      hope this helps.  spencer graves

Prof Brian Ripley wrote:

> On Thu, 24 Mar 2005, Vicky Landsman wrote:
>
>> Is there a package that enables to create the bivariate log-normal 
>> variables?
>
>
> Just exponentiate each of a bivariate normal pair.  You can get the 
> latter from mvrnorm in package MASS.
>



From r_xprt_wannabe at yahoo.com  Fri Mar 25 16:12:09 2005
From: r_xprt_wannabe at yahoo.com (R_xprt_wannabe)
Date: Fri, 25 Mar 2005 07:12:09 -0800 (PST)
Subject: [R] How to split a single vector into a multiple-column and
	multiple-row matrix
Message-ID: <20050325151209.24016.qmail@web31315.mail.mud.yahoo.com>

Dear List,

I have, say, a 2000x1 numeric vector and would like to
split it into, say, a 200x10 matrix.  Any help is
appreciated.



From rpeng at jhsph.edu  Fri Mar 25 16:16:11 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Fri, 25 Mar 2005 10:16:11 -0500
Subject: [R] How to split a single vector into a multiple-column
	and	multiple-row matrix
In-Reply-To: <20050325151209.24016.qmail@web31315.mail.mud.yahoo.com>
References: <20050325151209.24016.qmail@web31315.mail.mud.yahoo.com>
Message-ID: <42442B3B.1000600@jhsph.edu>

You can use 'matrix()', as in

x <- 1:2000
matrix(x, nrow = 200, ncol = 10)

-roger

R_xprt_wannabe wrote:
> Dear List,
> 
> I have, say, a 2000x1 numeric vector and would like to
> split it into, say, a 200x10 matrix.  Any help is
> appreciated.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/



From dimitris.rizopoulos at med.kuleuven.ac.be  Fri Mar 25 16:21:34 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Fri, 25 Mar 2005 16:21:34 +0100
Subject: [R] How to split a single vector into a multiple-column
	andmultiple-row matrix
References: <20050325151209.24016.qmail@web31315.mail.mud.yahoo.com>
Message-ID: <001201c5314e$54ab4dd0$0540210a@www.domain>

x <- rnorm(2000)

dim(x) <- c(200, 10)
## or if you want it by row:
matrix(x, 200, 10, TRUE)


Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "R_xprt_wannabe" <r_xprt_wannabe at yahoo.com>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, March 25, 2005 4:12 PM
Subject: [R] How to split a single vector into a multiple-column 
andmultiple-row matrix


> Dear List,
>
> I have, say, a 2000x1 numeric vector and would like to
> split it into, say, a 200x10 matrix.  Any help is
> appreciated.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From gunter.berton at gene.com  Fri Mar 25 16:56:58 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Fri, 25 Mar 2005 07:56:58 -0800
Subject: [R] R Reference Card (especially useful for Newbies)
Message-ID: <200503251557.j2PFuw4I019793@meitner.gene.com>


Newbies (and others!) may find the R Reference Card made available by  Tom
Short and Rpad at http://www.rpad.org/Rpad/Rpad-refcard.pdf  or through the
"Contributed" link on CRAN (where some other reference cards are also
linked) useful. It categorizes and organizes a bunch of R's basic, most used
functions so that they can be easily found. For example, paste() is under
the "Strings" heading and expand.grid() is under "Data Creation." For
newbies struggling to find the right R function as well as veterans who
can't quite remember the function name, it's very handy.
 
-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box



From JAROSLAW.W.TUSZYNSKI at saic.com  Fri Mar 25 17:06:16 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Fri, 25 Mar 2005 11:06:16 -0500
Subject: [R] Casting in R
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD57F4004@us-arlington-0668.mail.saic.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050325/879572d4/attachment.pl

From gunter.berton at gene.com  Fri Mar 25 17:28:10 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Fri, 25 Mar 2005 08:28:10 -0800
Subject: [R] Casting in R
In-Reply-To: <CA0BCF3BED56294AB91E3AD74B849FD57F4004@us-arlington-0668.mail.saic.com>
Message-ID: <200503251628.j2PGS9w5023472@hertz.gene.com>

Have you looked at the XML package on CRAN?

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Tuszynski, Jaroslaw W.
> Sent: Friday, March 25, 2005 8:06 AM
> To: (r-help at stat.math.ethz.ch.)
> Subject: [R] Casting in R
> 
> Hi,
> 
> I am looking for functions that would allow me to access raw 
> binary data of
> R vectors.  One way would be to use:
> 	x = (1:10)*pi
>    	writeBin(x, "temp.bin")
>    	r = readBin("temp.bin", "raw", n=length(x)*8)
> 
> Other to write my own C code. Is there any other simpler way?
> 
> I this message is a rewording of my yesterday message 
> "Looking for function
> for Double to raw to double conversions", to which I got no 
> replies. I need
> this functionality to implement Base64 encoding for 
> reading/writing XML
> files.
> 
> Jarek
> =====================================\====                 
>  Jarek Tuszynski, PhD.                               o / \ 
>  Science Applications International Corporation  <\__,|  
>  (703) 676-4192                        ">  \
>  Jaroslaw.W.Tuszynski at saic.com                   `    \
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From JAROSLAW.W.TUSZYNSKI at saic.com  Fri Mar 25 17:33:06 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Fri, 25 Mar 2005 11:33:06 -0500
Subject: [R] Casting in R
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD57F4005@us-arlington-0668.mail.saic.com>

Yes, XML package does not seem to support Base64 encoding so I wrote my own
encoder/decoder working with "raw" vectors. The only problem is casting R's
vectors of doubles into vectors of type "raw".

Jarek

-----Original Message-----
From: Berton Gunter [mailto:gunter.berton at gene.com] 
Sent: Friday, March 25, 2005 11:28 AM
To: 'Tuszynski, Jaroslaw W.'; r-help at stat.math.ethz.ch
Subject: RE: [R] Casting in R

Have you looked at the XML package on CRAN?

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Tuszynski, 
> Jaroslaw W.
> Sent: Friday, March 25, 2005 8:06 AM
> To: (r-help at stat.math.ethz.ch.)
> Subject: [R] Casting in R
> 
> Hi,
> 
> I am looking for functions that would allow me to access raw binary 
> data of R vectors.  One way would be to use:
> 	x = (1:10)*pi
>    	writeBin(x, "temp.bin")
>    	r = readBin("temp.bin", "raw", n=length(x)*8)
> 
> Other to write my own C code. Is there any other simpler way?
> 
> I this message is a rewording of my yesterday message "Looking for 
> function for Double to raw to double conversions", to which I got no 
> replies. I need this functionality to implement Base64 encoding for 
> reading/writing XML files.
> 
> Jarek
> =====================================\====                 
>  Jarek Tuszynski, PhD.                               o / \ 
>  Science Applications International Corporation  <\__,|  
>  (703) 676-4192                        ">  \
>  Jaroslaw.W.Tuszynski at saic.com                   `    \
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From reilly at stat.auckland.ac.nz  Fri Mar 25 17:43:10 2005
From: reilly at stat.auckland.ac.nz (James Reilly)
Date: Sat, 26 Mar 2005 04:43:10 +1200
Subject: [R] mixtures as outcome variables
Message-ID: <42443F9E.9090206@stat.auckland.ac.nz>


A collection of functions for compositional data analysis were posted on 
the S-news mailing list about a year ago.

Basic Compositional Data Analysis functions for S+/R
http://www.biostat.wustl.edu/archives/html/s-news/2003-12/msg00139.html

James

> Date: Thu, 24 Mar 2005 20:28:51 -0400 
> From: Kjetil Brinchmann Halvorsen <kjetil at acelerate.com> 
> Subject: Re: [R] mixtures as outcome variables 
> Cc: r-help at stat.math.ethz.ch, "Jason W. Martinez" <jmartinez5 at verizon.net> 
> 
> Kjetil Brinchmann Halvorsen wrote:
> 
>>> Jason W. Martinez wrote:
>>>
>>
>>>>> Dear R-users,
>>>>>
>>>>> I have an outcome variable and I'm unsure about how to treat it. Any
>>>>> advice?
>>>>>
>>
>>> If you only concentrate on the relative proportions, this are called 
>>> compositional data. I f your data are in
>>> mydata (n x 4), you obtain compositions by
>>> sweep(mydata, 1, apply(mydata, 1, sum), "/")
>>>
>>> There are not (AFAIK) specific functions/packages for R for 
>>> compositional data AFAIK, but you
>>> can try googling. Aitchison  has a monography (Chapman & Hall) and a 
>>> paper in JRSS B.
>>>
>>> One way to start might be lm's or anova on the symmetric logratio 
>>> transform of the
>>> compositons. The R function lm can take a multivariate response, but 
>>> some extra programming will be needed
>>> for interpretation. With simulated data:
>>>
>>
>>>> > slr
>>
>>> function(y) { # y should sum to 1
>>>          v <- log(y)
>>>          return( v - mean(v) ) }
>>
>>>> > testdata <- matrix( rgamma(120, 2,3), 30, 4)
>>>> > str(testdata)
>>
>>> num [1:30, 1:4] 0.200 0.414 0.311 2.145 0.233 ...
>>
>>>> > comp <- sweep(testdata, 1, apply(testdata,1,sum), "/")
>>
>>> # To get the symmetric logratio transform:
>>> comp <- t(apply(comp, 1, slr))
>>> # Observe:
>>> apply(cov(comp), 1, sum)
>>> [1] -5.551115e-17  2.775558e-17  5.551115e-17 -2.775558e-17
>>
>>>> > lm( comp ~ 1)
>>
>>>
>>> Call:
>>> lm(formula = comp ~ 1)
>>>
>>> Coefficients:
>>>             [,1]      [,2]      [,3]      [,4]   (Intercept)   
>>> 0.17606   0.06165  -0.03783  -0.19988
> 
> 
> Followup:
> 
>  > mmod <- manova(comp ~ x)
>  > summary(mmod)
> Error in summary.manova(mmod) : residuals have rank 3 < 4
>  >
> 
> So the manova() function cannot be used. I guess MANOVA for 
> compositional data should be
> a straight extension, but it must be programmed , standard manova cannot 
> be used.
> 
> Kjetil
> 
> -- Kjetil Halvorsen. Peace is the most effective weapon of mass construction. -- Mahdi Elmandjra



From msvika at mscc.huji.ac.il  Fri Mar 25 18:13:00 2005
From: msvika at mscc.huji.ac.il (Vicky Landsman)
Date: Fri, 25 Mar 2005 19:13:00 +0200
Subject: [R] Bivariate lognormal distribution
References: <007901c530b4$981840e0$a200a8c0@HOME2>
	<Pine.LNX.4.61.0503242140340.9482@gannet.stats>
	<424422F2.8050903@pdf.com>
Message-ID: <004101c5315d$e5a3e450$a200a8c0@HOME2>


Thanks to Prof. Ripley, Kjetil and Spencer Graves for help.
I will be more specific.
I have to simulate a bivariate lognormal pair (Y1,Y0) where E(Y1)=X'b, 
E(Y0)=X'd, Var(Y1)=c1, Var(Y0)=c0,
X is a data matrix, and b and d are vectors of parameters.
Vicky.


----- Original Message ----- 
From: "Spencer Graves" <spencer.graves at pdf.com>
To: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
Cc: "Vicky Landsman" <msvika at mscc.huji.ac.il>; "R-help list" 
<R-help at stat.math.ethz.ch>
Sent: Friday, March 25, 2005 4:40 PM
Subject: Re: [R] Bivariate lognormal distribution


>
>      I hope Professor Ripley will correct me if I'm mistaken, but the 
> documentation for "mvrnorm" in library(MASS) says it will, "Simulate from 
> a Multivariate Normal Distribution".  If you want the density function or 
> probabilities or quantiles, you can get those from library(mvtnorm).
>      Just for completeness, to use normal for a lognormal, you need to 
> take the logarithms of your number (which must be all positive;  zeros and 
> negative numbers become NA), then compute mean vector and variance matrix 
> of the logs, compute probabilities on the log scale, then back transform 
> by exponentiating to get the results back into the original scale.
>      hope this helps.  spencer graves
>
> Prof Brian Ripley wrote:
>
>> On Thu, 24 Mar 2005, Vicky Landsman wrote:
>>
>>> Is there a package that enables to create the bivariate log-normal 
>>> variables?
>>
>>
>> Just exponentiate each of a bivariate normal pair.  You can get the 
>> latter from mvrnorm in package MASS.
>>
>



From jeff.hamann at forestinformatics.com  Fri Mar 25 18:21:34 2005
From: jeff.hamann at forestinformatics.com (Jeff D. Hamann)
Date: Fri, 25 Mar 2005 09:21:34 -0800
Subject: [R] home and search buttons in help files?
Message-ID: <000c01c5315f$1b0c9230$0a00a8c0@rodan>

My thumb grows tired of having to back arrow so much in the help files :-(

Would it be possible to add to the wish list that a link to the help index 
page (since the up button at the top of the package index never seems to 
work for me) and another link to the search page?

Jeff.

---
Jeff D. Hamann
Forest Informatics, Inc.
PO Box 1421
Corvallis, Oregon USA 97339-1421
541-754-1428
jeff.hamann at forestinformatics.com
www.forestinformatics.com



From msck9 at mizzou.edu  Fri Mar 25 19:24:12 2005
From: msck9 at mizzou.edu (msck9@mizzou.edu)
Date: Fri, 25 Mar 2005 12:24:12 -0600
Subject: [R] if..else.. need help
In-Reply-To: <000c01c5315f$1b0c9230$0a00a8c0@rodan>
References: <000c01c5315f$1b0c9230$0a00a8c0@rodan>
Message-ID: <20050325182412.GA4896@localhost>

Dear all, 
 I don't know why the following doesn't work.
if(cls$size[1]>cls$size[2])
 {cls1<-tempforce[cls$cluster==1];cls2<-tempforce[cls$cluster==2]}
else {cls1<-tempforce[cls$cluster==2];cls2<-tempforce[cls$cluster==1]}

Error: syntax error

What is the problem here? 

thanks.
Ming



From Gregor.Gorjanc at bfro.uni-lj.si  Fri Mar 25 19:31:58 2005
From: Gregor.Gorjanc at bfro.uni-lj.si (Gorjanc Gregor)
Date: Fri, 25 Mar 2005 19:31:58 +0100
Subject: [R] Gmail invitation
Message-ID: <7FFEE688B57D7346BC6241C55900E730B70002@pollux.bfro.uni-lj.si>

Hello R users!

I just found out that I have 49 invitations for Gmail (gmail.google.com).
I have been using it now for a while and is really nice. Don't forget 
1 GB for free.

I will invite those who respond to this mail by FIFO.

--
Lep pozdrav / With regards,
    Gregor Gorjanc

------------------------------------------------------------------------
University of Ljubljana
Biotechnical Faculty       URI: http://www.bfro.uni-lj.si/MR/ggorjan
Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
Groblje 3                  tel: +386 (0)1 72 17 861
SI-1230 Domzale            fax: +386 (0)1 72 17 888
Slovenia



From reid_huntsinger at merck.com  Fri Mar 25 19:35:12 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Fri, 25 Mar 2005 13:35:12 -0500
Subject: [R] if..else.. need help
Message-ID: <D9A95B4B7B20354992E165EEADA31999056A9372@uswpmx00.merck.com>

Well, if you type that at a command prompt, the expression is complete after
the end of the "if" so you have an "else {}" which is orphaned. I think
people usually use this style

if() {

} else {

}

or something similar to prevent this.

Reid Huntsinger

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of msck9 at mizzou.edu
Sent: Friday, March 25, 2005 1:24 PM
To: Jeff D. Hamann
Cc: r-help at stat.math.ethz.ch
Subject: [R] if..else.. need help


Dear all, 
 I don't know why the following doesn't work.
if(cls$size[1]>cls$size[2])
 {cls1<-tempforce[cls$cluster==1];cls2<-tempforce[cls$cluster==2]}
else {cls1<-tempforce[cls$cluster==2];cls2<-tempforce[cls$cluster==1]}

Error: syntax error

What is the problem here? 

thanks.
Ming

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From br44114 at yahoo.com  Fri Mar 25 19:51:03 2005
From: br44114 at yahoo.com (bogdan romocea)
Date: Fri, 25 Mar 2005 10:51:03 -0800 (PST)
Subject: [R] Gmail invitation
Message-ID: <20050325185103.55734.qmail@web50103.mail.yahoo.com>

You can also buy these things on Ebay. I noticed the supply about 2
months ago when I guess you would have made about $1-2 per invitation.
The profit opportunity is much diminished now that the supply has
greatly increased (it appears every gmail account was allocated 50
invitations instead of 5 a few weeks ago). By the way, how much do you
charge? :-)



-----Original Message-----
From: Gorjanc Gregor [mailto:Gregor.Gorjanc at bfro.uni-lj.si]
Sent: Friday, March 25, 2005 1:32 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Gmail invitation


Hello R users!

I just found out that I have 49 invitations for Gmail
(gmail.google.com).
I have been using it now for a while and is really nice. Don't forget 
1 GB for free.

I will invite those who respond to this mail by FIFO.

--
Lep pozdrav / With regards,
    Gregor Gorjanc

------------------------------------------------------------------------
University of Ljubljana
Biotechnical Faculty       URI: http://www.bfro.uni-lj.si/MR/ggorjan
Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
Groblje 3                  tel: +386 (0)1 72 17 861
SI-1230 Domzale            fax: +386 (0)1 72 17 888
Slovenia

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From erithid at bellsouth.net  Fri Mar 25 20:04:47 2005
From: erithid at bellsouth.net (BJ)
Date: Fri, 25 Mar 2005 14:04:47 -0500
Subject: [R] Gmail invitation
In-Reply-To: <7FFEE688B57D7346BC6241C55900E730B70002@pollux.bfro.uni-lj.si>
References: <7FFEE688B57D7346BC6241C55900E730B70002@pollux.bfro.uni-lj.si>
Message-ID: <424460CF.8080509@bellsouth.net>

I got 48 if anyone wants em just let me know. :-) ~Erithid
Gorjanc Gregor wrote:

>Hello R users!
>
>I just found out that I have 49 invitations for Gmail (gmail.google.com).
>I have been using it now for a while and is really nice. Don't forget 
>1 GB for free.
>
>I will invite those who respond to this mail by FIFO.
>
>--
>Lep pozdrav / With regards,
>    Gregor Gorjanc
>
>------------------------------------------------------------------------
>University of Ljubljana
>Biotechnical Faculty       URI: http://www.bfro.uni-lj.si/MR/ggorjan
>Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
>Groblje 3                  tel: +386 (0)1 72 17 861
>SI-1230 Domzale            fax: +386 (0)1 72 17 888
>Slovenia
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>



From kerryrekky at yahoo.com  Fri Mar 25 20:25:55 2005
From: kerryrekky at yahoo.com (Kerry Bush)
Date: Fri, 25 Mar 2005 11:25:55 -0800 (PST)
Subject: Fwd: Re: [R] Prediction using GAM
Message-ID: <20050325192555.88495.qmail@web51805.mail.yahoo.com>


Note: forwarded message attached.


__________________________________________________


-------------- next part --------------
An embedded message was scrubbed...
From: unknown sender
Subject: no subject
Date: Fri, 25 Mar 2005 10:44:47 -0800 (PST)
Size: 2520
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050325/32a76790/attachment.mht

From kerryrekky at yahoo.com  Fri Mar 25 20:34:30 2005
From: kerryrekky at yahoo.com (Kerry Bush)
Date: Fri, 25 Mar 2005 11:34:30 -0800 (PST)
Subject: [R] gam in library(gam)
Message-ID: <20050325193430.14816.qmail@web51807.mail.yahoo.com>

I know there are two versions of gam in R. One is in
library(mgcv) and one is in library(gam). The one in
mgcv can automatically calculate the smoothing
parameter. However, the one in gam can't although it
can incorporate a larger variety of smoothers (besides
spline). Can anybody educate me if there is a way to
do smoothing parameter selection in gam from
library(gam)? I know I can always program
cross-validation by myself. But it might be more
friendly for the software if it can take this into
account automatically. (like gam in library(mgcv))



From Gregor.Gorjanc at bfro.uni-lj.si  Fri Mar 25 21:08:42 2005
From: Gregor.Gorjanc at bfro.uni-lj.si (Gorjanc Gregor)
Date: Fri, 25 Mar 2005 21:08:42 +0100
Subject: [R] Gmail invitation
Message-ID: <7FFEE688B57D7346BC6241C55900E730B70003@pollux.bfro.uni-lj.si>

Bogdan,

my charge is 0$. In the begining (in autumn 2004) I also got 5 invitations,
but now I just realized I got another portion with 50. Now I have 46 left.

--
Lep pozdrav / With regards,
    Gregor Gorjanc

------------------------------------------------------------------------
University of Ljubljana
Biotechnical Faculty       URI: http://www.bfro.uni-lj.si/MR/ggorjan
Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
Groblje 3                  tel: +386 (0)1 72 17 861
SI-1230 Domzale            fax: +386 (0)1 72 17 888
Slovenia
------------------------------------------------------------------------



-----Original Message-----
From: bogdan romocea [mailto:br44114 at yahoo.com]
Sent: pet 2005-03-25 19:51
To: Gorjanc Gregor
Cc: r-help at stat.math.ethz.ch
Subject: RE: [R] Gmail invitation
 
You can also buy these things on Ebay. I noticed the supply about 2
months ago when I guess you would have made about $1-2 per invitation.
The profit opportunity is much diminished now that the supply has
greatly increased (it appears every gmail account was allocated 50
invitations instead of 5 a few weeks ago). By the way, how much do you
charge? :-)



-----Original Message-----
From: Gorjanc Gregor [mailto:Gregor.Gorjanc at bfro.uni-lj.si]
Sent: Friday, March 25, 2005 1:32 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Gmail invitation


Hello R users!

I just found out that I have 49 invitations for Gmail
(gmail.google.com).
I have been using it now for a while and is really nice. Don't forget 
1 GB for free.

I will invite those who respond to this mail by FIFO.

--
Lep pozdrav / With regards,
    Gregor Gorjanc

------------------------------------------------------------------------
University of Ljubljana
Biotechnical Faculty       URI: http://www.bfro.uni-lj.si/MR/ggorjan
Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
Groblje 3                  tel: +386 (0)1 72 17 861
SI-1230 Domzale            fax: +386 (0)1 72 17 888
Slovenia

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
		
__________________________________ 


From ripley at stats.ox.ac.uk  Fri Mar 25 22:02:06 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 25 Mar 2005 21:02:06 +0000 (GMT)
Subject: [R] Tool for update
In-Reply-To: <NEBBIPHDAMMOKDKPOFFIOEGMDCAA.abunn@whrc.org>
References: <NEBBIPHDAMMOKDKPOFFIOEGMDCAA.abunn@whrc.org>
Message-ID: <Pine.LNX.4.61.0503252058520.11523@gannet.stats>

You might want to look at the new tools in 2.1.0alpha for this sort of 
thing.  In particular, packageStatus() is now built on top of the new 
tools that it may be cleaner to call directly.

For what I understand you run this every time you use R on a Tuesday, 
which is not what I would want.

On Fri, 25 Mar 2005, abunn wrote:

> I edited Rprofile to update everything on Tuesdays. I've been doing this
> since 2.0 and I think I've had R running almost every Tuesday, which begs
> the question of what I would be doing if R hadn't come into existence.
>
> In any case, It works pretty well:
>
> ## This script gets all the packages I don't already have
> # Run this once a week - say Tuesdays
> if (interactive() ) { library(utils)}
> is.tuesday <- as.POSIXlt(Sys.time())$wday == 2
> if (is.tuesday == T)
> {
>    cat("Running a package check...\nOccurs once a week, on Tuesdays\n")
>    cat("Upgrade existing packages and check for new packages (y/N)? ")
>    check.new <- as.character(readLines(n = 1))
>    if (any(check.new == "y", check.new == "Y"))
>    {
>        options(CRAN = "http://cran.us.r-project.org/")
>        cat("This can take a few seconds...\n")
>        x <- packageStatus(repositories = getOption("repositories")()[[1]])
>        print(x)
>        install.packages(x$avail$Package[x$avail$Status == "not installed"])
>        cat("Upgrading to new versions if available\n")
>        upgrade(x)
>   }
> }
>
>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Thomas Lumley
>> Sent: Thursday, March 24, 2005 4:03 PM
>> To: Darren Weber
>> Cc: r-help at stat.math.ethz.ch; jblock at radiology.ucsf.edu
>> Subject: Re: [R] Tool for update
>>
>>
>> On Thu, 24 Mar 2005, Darren Weber wrote:
>>
>>> Is there a way to set a cron job to automatically update packages?
>>> Maybe something like this:
>>>
>>> $unixprompt> R --vanilla update.packages()
>>>
>>
>> If you put
>> update.packages(repos="http://cran.us.r-project.org", ask=FALSE)
>>
>> in a file update.R you can do
>>    R CMD BATCH update.R update.log
>> or even fancier, something like
>>    R CMD BATCH update.R update-`date --iso-8601`.log
>>
>> to keep dated log files.
>>
>>  	-thomas
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From abunn at whrc.org  Fri Mar 25 22:12:28 2005
From: abunn at whrc.org (abunn)
Date: Fri, 25 Mar 2005 16:12:28 -0500
Subject: [R] Tool for update
In-Reply-To: <Pine.LNX.4.61.0503252058520.11523@gannet.stats>
Message-ID: <NEBBIPHDAMMOKDKPOFFIOEHJDCAA.abunn@whrc.org>

> For what I understand you run this every time you use R on a Tuesday,
> which is not what I would want.

What's wrong with Tuesday? Indeed, it's not the ideal solution but has kept
me up-to-date. What has amazed me is that I think I've used R every Tuesday
(and other workdays) since I did that. So, it ends up working pretty well. I
will look forward to a cleaner implementation with 2.1

Much thanks, Andy



From qiana at biostat.umn.edu  Fri Mar 25 23:09:47 2005
From: qiana at biostat.umn.edu (Qian An)
Date: Fri, 25 Mar 2005 16:09:47 -0600 (CST)
Subject: [R] Stratified bootstrap question
Message-ID: <Pine.GSO.4.44.0503251556160.21934-100000@smelt.biostat.umn.edu>

Dear experts,
I am asking for help with a question regarding to stratified bootstrap.

My dataset is a longitudinal dataset (3 measurements per person at year
1, 4 and 7) composed of multiple clinic centers and multiple participants
within each clinic. It has missing values.

I want to do a bootstrap to find the standard errors and confidence
intervals for my variance components. My model is a mixed model with
random clinic and random participant within clinic.

I thought two methods to do bootstrap:
(1) bootstrap data; however, I have problem specifying the second
parameter for my statistic function, shall I use indices, weight or
frequency and how shall I relate to my dataset.
(2) bootstrap residuals; however, the dataset has multiple measurements
and missing values. I am wondering how to construct a new data frame
containing the residuals and fitted values.

Your help will be highly appreciated!
Sincerely yours,
Qian



***************************************
Qian An
Division of Biostatistics
University of Minnesota
(phone) 612-626-2263
(fax) 612-626-8892
Email: qiana at biostat.umn.edu



From gabriel.rossetti at movemail.com  Fri Mar 25 23:32:42 2005
From: gabriel.rossetti at movemail.com (Gabriel Rossetti)
Date: Sat, 26 Mar 2005 06:32:42 +0800
Subject: [R] R-2.0.1 Gentoo g77 problem
Message-ID: <20050325223243.345AD1027BE@ws3.hk5.outblaze.com>

Thank you for your help,

I tried Ioannis's f2c approach (Thanks Ioannis!!), and it works with the source from the R-Project site, but not with the Gentoo Portage system. I did have to use the source version, because I really need R, which I have to say Good job to all that work on it, it is really a great program! I would really rather have the gentoo ebuild, to keep my system clean. I then read the Gentoo forum page, and tried the symlinks, but no luck. I don't know how you did if Charles, but the links don't do much, I get :

...
...
checking how to get verbose linking output from g77... configure: WARNING: compilation failed

checking for Fortran libraries of g77...
checking for dummy main to link with Fortran libraries... none
checking for Fortran name-mangling scheme... configure: error: cannot compile a simple Fortran program
See `config.log' for more details.

I did compile gcc with fortran support, and gcc -v does give me f77, but I still can't get the R ebuild to build. I asked a classmate if he had any problems with R, he had non, I haven't had the pssibility to see if his system has the same gcc and such versions as me. I hope that I'll get it working one day!

Thanks again for all of your replys and have a good easter!

Gabriel Rossetti
University of Applied Science 
of Western Switzerland (EIVD)
E+I Department


----- Original Message -----
From: "Charles C. Berry" <cberry at tajo.ucsd.edu>
To: "Dimakos Ioannis" <idimakos at upatras.gr>
Subject: Re: [R] R-2.0.1 Gentoo g77 problem
Date: Wed, 9 Mar 2005 15:08:04 -0800

> 
> 
> Dimakos said:
> 
> > As I pointed out in a private message to the original poster, g77 is not
> > found in the gentoo system.  However, the system does provide f2c which
>   [ Dimakos' full text below]
> 
> 
> It IS found on my gentoo system:
> 
> bash-2.05b$ g77 -fversion
> GNU Fortran (GCC) 3.3.5  (Gentoo Linux 3.3.5-r1, ssp-3.3.2-3, pie-8.7.7.1)
> Copyright (C) 2002 Free Software Foundation, Inc.
> [snip]
> 
> This is where portage puts it:
> 
> ------------------------
> 
> bash-2.05b$ locate g77
> 
> [stuff deleted]
> 
> /usr/share/gcc-data/sparc-unknown-linux-gnu/3.3.5/man/man1/g77.1.gz
> /usr/sparc-unknown-linux-gnu/gcc-bin/3.3.5/g77
> /usr/sparc-unknown-linux-gnu/gcc-bin/3.3.5/sparc-unknown-linux-gnu-g77
> 
> [more stuff deleted]
> 
> bash-2.05b$ locate f771
> /usr/lib/gcc-lib/sparc-unknown-linux-gnu/3.3.5/f771
> 
> ------------------------
> 
> As someone else noted you have to set the USE flags to include 
> 'f77' or 'g77' and emerge gcc.
> 
> But setting USE = f77 did not leave a link or copy of g77 in 
> /usr/bin. Hence, the symlink referred to in my message below.
> 
> Apparently, Gabriel and I are not the only ones to come up against 
> this. There are a number of discussions like this one:
> 
> 	http://forums.gentoo.org/viewtopic.php?t=266985
> 
> where the solution was to copy or symlink /usr/bin/gcc to /usr/bin/g77.
> 
> Chuck
> 
> On Thu, 10 Mar 2005, Dimakos Ioannis wrote:
> 
> >> On Wed, 9 Mar 2005, Gabriel Rossetti wrote:
> >>
> >>> Hello,
> >>>
> >>> I use Gentoo and I can't get R 2.0.1 to compile. I used the portage
> >>> system, Gentoo's source package sytem, and after it uncompresses the
> >>> source to R, it says that I don't have a fortran compiler. It told me to
> >>> use f77 flag and re-emerge gcc, which I did with the f77 and fortran
> >>> flags, but it still won't compile. Does anyone have any ideas? I suspect
> >>> that gcc has changed it's interworkings, because if I do a gcc -v it
> >>> says that I can compile fortran(f77) programs, but I don't have g77. If
> >>> anyone has any ideas or workarounds, it would be great. I really need it
> >>> for a P&S class. Thanks!
> >>
> >>
> >> After experiencing similar problems and noticing that g77 was nowhere to
> >> be found, I symlinked /usr/bin/g77 --> /usr/bin/gcc.
> >>
> >> R then built and passed 'make check'.
> >
> > As I pointed out in a private message to the original poster, g77 is not
> > found in the gentoo system.  However, the system does provide f2c which
> > will translate fortran to C code and then R-2.0.1 passes configure, and
> > make and make check and make install and everything
> >
> > HTH,
> >
> > ICD
> >
> > -- Ioannis C. Dimakos
> > University of Patras
> > Department of Elementary Education
> > Patras, GR-26500 GREECE
> > http://www.elemedu.upatras.gr/dimakos/
> > http://yannishome.port5.com/
> >
> > -- Ioannis C. Dimakos
> > University of Patras
> > Department of Elementary Education
> > Patras, GR-26500 GREECE
> > http://www.elemedu.upatras.gr/dimakos/
> > http://yannishome.port5.com/
> >
> 
> Charles C. Berry                        (858) 534-2098
>                                           Dept of Family/Preventive Medicine
> E mailto:cberry at tajo.ucsd.edu	         UC San Diego
> http://hacuna.ucsd.edu/members/ccb.html  La Jolla, San Diego 92093-0717

--



From RML27 at cornell.edu  Sat Mar 26 03:26:31 2005
From: RML27 at cornell.edu (Ronnen Levinson)
Date: Fri, 25 Mar 2005 18:26:31 -0800
Subject: [R] Trouble with expression() in R-win 2.0.1
Message-ID: <4244C857.9030100@cornell.edu>


   Hi.
   The following statement works fine in R-win 1.8.0, but yields a syntax
   error in R-win 2.0.1 (and possibly in other versions after 1.8.0):

     plot(c(1,2),main=expression(a==b==c))

   I  note  that  the  following workaround executes successfully in both
   versions of R...

     plot(c(1,2),main=expression(a*"="*b*"="*c))

   ...but  I don't really understand why the first version works in 1.8.0
   and not in 2.0.1.
   Yours truly,
   Ronnen.
   P.S. E-mailed CCs of posted replies appreciated.
-- 
Ronnen Levinson, Ph.D.            \/      [1]RML27 at cornell.edu
scientist                         ||      [2]http://ronnen.com
Lawrence Berkeley National Lab    /\      fax 425.955.1992

======================================
Men in colored shirts and seersucker suits, women in slacks and midriff dresses
 displaying various grades of abdomen, moved in and out of California Spanish s
hops and office buildings. Nobody looked at the mountains standing above the to
wn, but the mountains were there, making them all look silly.

-- Ross Macdonald, "The Moving Target"
======================================

References

   1. mailto:RML27 at cornell.edu
   2. http://ronnen.com/


From deepayan at stat.wisc.edu  Sat Mar 26 04:11:14 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 25 Mar 2005 21:11:14 -0600
Subject: [R] Trouble with expression() in R-win 2.0.1
In-Reply-To: <4244C857.9030100@cornell.edu>
References: <4244C857.9030100@cornell.edu>
Message-ID: <200503252111.14658.deepayan@stat.wisc.edu>

On Friday 25 March 2005 20:26, Ronnen Levinson wrote:
>    Hi.
>    The following statement works fine in R-win 1.8.0, but yields a
> syntax error in R-win 2.0.1 (and possibly in other versions after
> 1.8.0):
>
>      plot(c(1,2),main=expression(a==b==c))
>
>    I  note  that  the  following workaround executes successfully in
> both versions of R...
>
>      plot(c(1,2),main=expression(a*"="*b*"="*c))
>
>    ...but  I don't really understand why the first version works in
> 1.8.0 and not in 2.0.1.

The relevant NEWS entry says:

    o   R no longer accepts associative use of relational operators.
        That is, 3 < 2 < 1 (which used to evalute as TRUE!) now causes
        a syntax error.  If this breaks existing code, just add
        parentheses -- or braces in the case of plotmath.

i.e., you want

plot(c(1,2),main=expression(a=={b==c}))

Deepayan



From jsorkin at grecc.umaryland.edu  Sat Mar 26 04:23:13 2005
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Fri, 25 Mar 2005 22:23:13 -0500
Subject: [R] trouble with help.start()
Message-ID: <s2448f61.028@grecc.umaryland.edu>

R 2.0.1 running on Linux Core 3.

I am having trouble running the HTML help system. 
When I issue the command help.start() as a "normal" users I receive the
following messssage

> help.start()
Making links in per-session dir ...
If /usr/bin/firefox is already running, it is *not* restarted, and you
    must switch to its window.
Otherwise, be patient ...
> Error: No running window found
*** loading the extensions datasource
*** ExtensionManager:_updateManifests: no access privileges to
application directory, skipping.

When I issue the command as root everything works fine. I suspect the
problem is related to file rights, but I do not know which file I do not
have rights to. Any help would be appreciated

Thanks 
John

John Sorkin M.D., Ph.D.
Chief, Biostatistics and Informatics
Baltimore VA Medical Center GRECC and
University of Maryland School of Medicine Claude Pepper OAIC

University of Maryland School of Medicine
Division of Gerontology
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524

410-605-7119 
- NOTE NEW EMAIL ADDRESS:
jsorkin at grecc.umaryland.edu



From MSchwartz at MedAnalytics.com  Sat Mar 26 04:52:51 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Fri, 25 Mar 2005 21:52:51 -0600
Subject: [R] trouble with help.start()
In-Reply-To: <s2448f61.028@grecc.umaryland.edu>
References: <s2448f61.028@grecc.umaryland.edu>
Message-ID: <1111809171.30364.13.camel@horizons.localdomain>

On Fri, 2005-03-25 at 22:23 -0500, John Sorkin wrote:
> R 2.0.1 running on Linux Core 3.
> 
> I am having trouble running the HTML help system. 
> When I issue the command help.start() as a "normal" users I receive the
> following messssage
> 
> > help.start()
> Making links in per-session dir ...
> If /usr/bin/firefox is already running, it is *not* restarted, and you
>     must switch to its window.
> Otherwise, be patient ...
> > Error: No running window found
> *** loading the extensions datasource
> *** ExtensionManager:_updateManifests: no access privileges to
> application directory, skipping.
> 
> When I issue the command as root everything works fine. I suspect the
> problem is related to file rights, but I do not know which file I do not
> have rights to. Any help would be appreciated
> 
> Thanks 
> John


A Google search would suggest that the error may be the result of having
installed a Firefox extension as root, that you do not have access
privileges to as a regular user. The message indicating that the Firefox
extension manager is attempting to load or initialize the extension and
cannot do so.

You might want to open Firefox as root, check to see what extensions are
loaded, remove them, and then reload them as your regular username, if
you determine that you want them available.

Some posts found during the search suggest that this may be unique to
particular extensions that do not properly set access rights during
installation. If you have the time, you might want to test the installed
extensions one by one to see if you can isolate which one is problematic
and then report the bug to the extension author.

HTH,

Marc Schwartz



From lzhtom at hotmail.com  Sat Mar 26 07:08:57 2005
From: lzhtom at hotmail.com (zhihua li)
Date: Sat, 26 Mar 2005 06:08:57 +0000
Subject: [R] learning networks with a large number of variables and
	pre-set parents.
In-Reply-To: <Pine.LNX.4.58.0503251137020.3626@thorin.ci.tuwien.ac.at>
Message-ID: <BAY12-F11D53FDA95481A21DABEF4C7420@phx.gbl>

Sorry, I didn't mean to break the posting rules. I just thought that r-help 
and r-sig-gr are two seperate mailing list. And the reason I posted my 
messages twice within 24 hours was that I forgot to add subjects to my 
first postings, so I'm afraid my first postings would be ignored at all.
Thank you.

>From: Achim Zeileis <Achim.Zeileis at wu-wien.ac.at>
>To: zhihua li <lzhtom at hotmail.com>
>CC: r-help at stat.math.ethz.ch
>Subject: Re: [R] learning networks with a large number of variables and 
pre-set parents.
>Date: Fri, 25 Mar 2005 11:40:46 +0100 (CET)
>
>This is the second time within 24 hours that you cross-posted the same
>question to two of the R mailing lists, please read the posting guide
>linked at the bottom of this mail on how to properly ask your questions.
>
>As for your question: I'm not aware of an R package that would be able to
>do what you are looking for, but you might also ask the maintainer of the
>package you're specifically interested in for more details.
>Z
>
>
>
>On Fri, 25 Mar 2005, zhihua li wrote:
>
> > hi netters:
> >
> > I have a series of  discrete variables which form a network and  I want 
to
> > learn the network structure from some training data. I could have used
> > packages like deal but there are two problems.
> >
> > First of all, I have 10000 variables. So the possible network structure 
is
> > awfully huge, I don't know how long it will take my PC to find the
> > highest-scoring network..........maybe a month?
> > Secondly, I have some prior knowledge that only 500 out of the 10000
> > variales are possible parents. In another word, only those arrows 
startting
> > from the 500 variables and pointing to the remaining 99500 variables 
are
> > allowed in the network.  In deal an assignment to "banlist" should help 
me
> > rule out the impossible arrows. But in my case the number of 
"impossible
> > arrows" is  500*499+99500*99549, and so the "banlist" would get
> > unacceptable long. Are there any methods (in deal or other packages) to
> > specify the parents set in advance?
> >
> > Thanks a lot!
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html
> >



From lzhtom at hotmail.com  Sat Mar 26 07:23:04 2005
From: lzhtom at hotmail.com (zhihua li)
Date: Sat, 26 Mar 2005 06:23:04 +0000
Subject: [R] learning networks with a large number of variables andpre-set
	parents.
In-Reply-To: <003701c5314b$5b907830$0201a8c0@shelbyhome>
Message-ID: <BAY12-F20C74FBD87D9A7BB0B602AC7420@phx.gbl>

I didn't go into details when I asked the question for feat that I would 
overly specific and blur my real goals. 
The links between variables are defined as conditional probability 
distributions. So if the probability distribution of a variable X's value 
is conditioned on the probability distribution of the values of Y and Z, we 
say Y and Z are X's parents, and in the network, there are two arrows 
starting from Y and Z and poining both to X.
Clearly it's something like a bayesian network. And I do know some 
packages, such as deal, can learn the bayesian networks structure from 
training data. But I'm not sure if deal or other similar packages can 
handle 10000 variables......
Thanks a lot for your information.


>From: "Shelby Berkowitz" <berkowi4 at msu.edu>
>To: "'zhihua li'" <lzhtom at hotmail.com>
>Subject: RE: [R] learning networks with a large number of variables 
andpre-set parents.
>Date: Fri, 25 Mar 2005 10:00:17 -0500
>
>It's not really clear to me what it is you're trying to do, how you've
>defined links between these variables, or how you're defining 'highest
>scoring network', but for manipulating a network of that size you might
>want to check out Pajek http://vlado.fmf.uni-lj.si/pub/networks/pajek/
>network analysis software - there is probably a way from there to
>extract the network you want, and you can export from it back into R for
>further analysis.
>
>HTH,
>
>Shelby
>
> >-----Original Message-----
> >From: r-help-bounces at stat.math.ethz.ch
> >[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Achim Zeileis
> >Sent: Friday, March 25, 2005 5:41 AM
> >To: zhihua li
> >Cc: r-help at stat.math.ethz.ch
> >Subject: Re: [R] learning networks with a large number of
> >variables andpre-set parents.
> >
> >
> >This is the second time within 24 hours that you cross-posted
> >the same question to two of the R mailing lists, please read
> >the posting guide linked at the bottom of this mail on how to
> >properly ask your questions.
> >
> >As for your question: I'm not aware of an R package that would
> >be able to do what you are looking for, but you might also ask
> >the maintainer of the package you're specifically interested
> >in for more details. Z
> >
> >
> >
> >On Fri, 25 Mar 2005, zhihua li wrote:
> >
> >> hi netters:
> >>
> >> I have a series of  discrete variables which form a network and  I
> >> want to learn the network structure from some training data. I could
> >> have used packages like deal but there are two problems.
> >>
> >> First of all, I have 10000 variables. So the possible network
> >> structure is awfully huge, I don't know how long it will
> >take my PC to
> >> find the highest-scoring network..........maybe a month? Secondly, I
> >> have some prior knowledge that only 500 out of the 10000
> >variales are
> >> possible parents. In another word, only those arrows startting from
> >> the 500 variables and pointing to the remaining 99500 variables are
> >> allowed in the network.  In deal an assignment to "banlist" should
> >> help me rule out the impossible arrows. But in my case the number of
> >> "impossible arrows" is  500*499+99500*99549, and so the "banlist"
> >> would get unacceptable long. Are there any methods (in deal or other
> >> packages) to specify the parents set in advance?
> >>
> >> Thanks a lot!
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide!
> >> http://www.R-project.org/posting-guide.html
> >>
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read
> >the posting guide! http://www.R-project.org/posting-guide.html
> >
> >--
> >No virus found in this incoming message.
> >Checked by AVG Anti-Virus.
> >Version: 7.0.308 / Virus Database: 266.8.1 - Release Date: 3/23/2005
> >
> >
>



From ozric at web.de  Sat Mar 26 08:13:34 2005
From: ozric at web.de (Christian Schulz)
Date: Sat, 26 Mar 2005 08:13:34 +0100
Subject: [R] learning networks with a large number of variables and pre-set
	parents.
In-Reply-To: <BAY12-F34713F9618A7E4D3FB72AEC7410@phx.gbl>
References: <BAY12-F34713F9618A7E4D3FB72AEC7410@phx.gbl>
Message-ID: <42450B9E.4020206@web.de>

Hi,

you have 10000 variables and how many cases?
In my experience you need a lot of memory working with this kind/size of
data and deal!

>> dim(pk.df)
[1] 7321 24
>> pk <- network(pk.df)
>> pk.prior <- jointprior(pk)
Error in rep.default(data, length.out = vl) :
cannot allocate vector of length 577368000

Perhaps this is usefuel for you?

Ines - Induction of Network Structure
(learning probabilistic and possibilistic graphical models)

http://fuzzy.cs.uni-magdeburg.de/~borgelt/ines.html

regards,
Christian


zhihua li schrieb:

> hi netters:
> I have a series of discrete variables which form a network and I want
> to learn the network structure from some training data. I could have
> used packages like deal but there are two problems.
> First of all, I have 10000 variables. So the possible network
> structure is awfully huge, I don't know how long it will take my PC to
> find the highest-scoring network..........maybe a month? Secondly, I
> have some prior knowledge that only 500 out of the 10000 variales are
> possible parents. In another word, only those arrows startting from
> the 500 variables and pointing to the remaining 99500 variables are
> allowed in the network. In deal an assignment to "banlist" should help
> me rule out the impossible arrows. But in my case the number of
> "impossible arrows" is 500*499+99500*99549, and so the "banlist" would
> get unacceptable long. Are there any methods (in deal or other
> packages) to specify the parents set in advance?
> Thanks a lot!
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From montse.rue at gmail.com  Sat Mar 26 10:20:43 2005
From: montse.rue at gmail.com (Montse Rue)
Date: Sat, 26 Mar 2005 10:20:43 +0100
Subject: [R] lme: random effects of a quadratic term
Message-ID: <605cea3f05032601202c46248@mail.gmail.com>

Hello,

I am estimating the following model:

so2.lme<-lme(so2~1+I(alcadakm^2)+dia,data=subjectes2,na.action=na.omit)

And when I try to plot the random effects of the quadratic term with
respect to a covariate (mam) I get an error:

> so2.lmeRE<-ranef(so2.lme,augFrame=T)
> plot(so2.lmeRE,form=I(alcadakm^2)~mam)
Error in plot.ranef.lme(so2.lmeRE, form = I(alcadakm^2) ~ mam ) : 
	Only single effects allowed in left side of form.

Any suggestion?

Thanks!

Montse Rue



From ripley at stats.ox.ac.uk  Sat Mar 26 10:39:07 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 26 Mar 2005 09:39:07 +0000 (GMT)
Subject: [R] lme: random effects of a quadratic term
In-Reply-To: <605cea3f05032601202c46248@mail.gmail.com>
References: <605cea3f05032601202c46248@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0503260936150.23263@gannet.stats>

On Sat, 26 Mar 2005, Montse Rue wrote:

> I am estimating the following model:
>
> so2.lme<-lme(so2~1+I(alcadakm^2)+dia,data=subjectes2,na.action=na.omit)
>
> And when I try to plot the random effects of the quadratic term with
> respect to a covariate (mam) I get an error:
>
>> so2.lmeRE<-ranef(so2.lme,augFrame=T)
>> plot(so2.lmeRE,form=I(alcadakm^2)~mam)
> Error in plot.ranef.lme(so2.lmeRE, form = I(alcadakm^2) ~ mam ) :
> 	Only single effects allowed in left side of form.
>
> Any suggestion?

Try renaming the variable, e.g. alcadakm2 = alcadakm^2, and refit.

NB: this is not `a quadratic term' but a transformed variable, since you 
used I().

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From lzhtom at hotmail.com  Sat Mar 26 11:00:23 2005
From: lzhtom at hotmail.com (zhihua li)
Date: Sat, 26 Mar 2005 10:00:23 +0000
Subject: [R] learning networks with a large number of variables and
	pre-set parents.
In-Reply-To: <42450B9E.4020206@web.de>
Message-ID: <BAY12-F426E6E8B8EC55966E61500C7420@phx.gbl>

I have 100 cases. So i think the dimension is (100, 10000). 
The PC has a pentium 4 CPU with 512M memory. I don't know if it is enough?



>From: Christian Schulz <ozric at web.de>
>To: zhihua li <lzhtom at hotmail.com>
>CC: r-help at stat.math.ethz.ch
>Subject: Re: [R] learning networks with a large number of variables and 
pre-set parents.
>Date: Sat, 26 Mar 2005 08:13:34 +0100
>
>Hi,
>
>you have 10000 variables and how many cases?
>In my experience you need a lot of memory working with this kind/size of
>data and deal!
>
> >> dim(pk.df)
>[1] 7321 24
> >> pk <- network(pk.df)
> >> pk.prior <- jointprior(pk)
>Error in rep.default(data, length.out = vl) :
>cannot allocate vector of length 577368000
>
>Perhaps this is usefuel for you?
>
>Ines - Induction of Network Structure
>(learning probabilistic and possibilistic graphical models)
>
>http://fuzzy.cs.uni-magdeburg.de/~borgelt/ines.html
>
>regards,
>Christian
>
>
>zhihua li schrieb:
>
> > hi netters:
> > I have a series of discrete variables which form a network and I want
> > to learn the network structure from some training data. I could have
> > used packages like deal but there are two problems.
> > First of all, I have 10000 variables. So the possible network
> > structure is awfully huge, I don't know how long it will take my PC to
> > find the highest-scoring network..........maybe a month? Secondly, I
> > have some prior knowledge that only 500 out of the 10000 variales are
> > possible parents. In another word, only those arrows startting from
> > the 500 variables and pointing to the remaining 99500 variables are
> > allowed in the network. In deal an assignment to "banlist" should help
> > me rule out the impossible arrows. But in my case the number of
> > "impossible arrows" is 500*499+99500*99549, and so the "banlist" would
> > get unacceptable long. Are there any methods (in deal or other
> > packages) to specify the parents set in advance?
> > Thanks a lot!
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
>
>



From 0034058 at fudan.edu.cn  Sat Mar 26 10:22:24 2005
From: 0034058 at fudan.edu.cn (ronggui)
Date: Sat, 26 Mar 2005 17:22:24 +0800
Subject: [R] about prcomp's result
Message-ID: <20050326172224.051e7f47.0034058@fudan.edu.cn>

i know we can carry out principle component analysis by prcomp() and princomp().and the result is similar but not identical.

i know ratation in prcomp is the loadings form princomp,sdev from both command is the standard deviations of the principal components.

and my question is: is the x from prcomp has the same meaning of  score from princomp?and what is the relationship between x(from prcomp),scores(from princomp)and principle components. it seems the same.is that right?

thank you



From samuel_mwalili at yahoo.com  Sat Mar 26 12:02:56 2005
From: samuel_mwalili at yahoo.com (Mwalili, S. M.)
Date: Sat, 26 Mar 2005 03:02:56 -0800 (PST)
Subject: [R] summing values by group
In-Reply-To: 6667
Message-ID: <20050326110257.87196.qmail@web53401.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050326/707eeb07/attachment.pl

From Gregor.Gorjanc at bfro.uni-lj.si  Sat Mar 26 15:19:04 2005
From: Gregor.Gorjanc at bfro.uni-lj.si (Gorjanc Gregor)
Date: Sat, 26 Mar 2005 15:19:04 +0100
Subject: [R] RE: Gmail invitation
Message-ID: <7FFEE688B57D7346BC6241C55900E730B70008@pollux.bfro.uni-lj.si>

I still have 40 invitations! Do not hesitate ;)

This is last remainder on r-help.

--
Lep pozdrav / With regards,
    Gregor Gorjanc

------------------------------------------------------------------------
University of Ljubljana
Biotechnical Faculty       URI: http://www.bfro.uni-lj.si/MR/ggorjan
Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
Groblje 3                  tel: +386 (0)1 72 17 861
SI-1230 Domzale            fax: +386 (0)1 72 17 888
Slovenia



From srini_iyyer_bio at yahoo.com  Sat Mar 26 15:34:29 2005
From: srini_iyyer_bio at yahoo.com (Srinivas Iyyer)
Date: Sat, 26 Mar 2005 06:34:29 -0800 (PST)
Subject: [R] PCA - princomp can only be used with more units than variables
In-Reply-To: 6667
Message-ID: <20050326143429.92533.qmail@web53509.mail.yahoo.com>

Hi all:
I am trying to do PCA on the following matrix. 


            N1     N2    A1      A2     B1     B2
gene_a      90    110    190    210    290    310
gene_b     190    210    390    410    590    610
gene_c      90    110    110     90    120     80
gene_d     200    100    400     90    600    200


>dataf<-read.table("matrix")

> pca<-princomp(dataf,cor=TRUE,scores=TRUE)
Error in princomp.default(dataf, cor = TRUE, scores =
TRUE) : 
        princomp can only be used with more units than
variables


Can any one help me, whats wrong here. 

thanks
srini



From blindglobe at gmail.com  Sat Mar 26 15:41:03 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Sat, 26 Mar 2005 15:41:03 +0100
Subject: [R] RE: Gmail invitation
In-Reply-To: <7FFEE688B57D7346BC6241C55900E730B70008@pollux.bfro.uni-lj.si>
References: <7FFEE688B57D7346BC6241C55900E730B70008@pollux.bfro.uni-lj.si>
Message-ID: <1abe3fa9050326064169e4cefd@mail.gmail.com>

Heck, if anyone cares, I've got 50 or so.  Just drop an email.  It's
not a bad service.


On Sat, 26 Mar 2005 15:19:04 +0100, Gorjanc Gregor
<Gregor.Gorjanc at bfro.uni-lj.si> wrote:
> I still have 40 invitations! Do not hesitate ;)
> 
> This is last remainder on r-help.
> 
> --
> Lep pozdrav / With regards,
>     Gregor Gorjanc
> 
> ------------------------------------------------------------------------
> University of Ljubljana
> Biotechnical Faculty       URI: http://www.bfro.uni-lj.si/MR/ggorjan
> Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
> Groblje 3                  tel: +386 (0)1 72 17 861
> SI-1230 Domzale            fax: +386 (0)1 72 17 888
> Slovenia
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
best,
-tony

"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).

A.J. Rossini
blindglobe at gmail.com



From ripley at stats.ox.ac.uk  Sat Mar 26 16:00:04 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 26 Mar 2005 15:00:04 +0000 (GMT)
Subject: [R] PCA - princomp can only be used with more units than variables
In-Reply-To: <20050326143429.92533.qmail@web53509.mail.yahoo.com>
References: <20050326143429.92533.qmail@web53509.mail.yahoo.com>
Message-ID: <Pine.LNX.4.61.0503261456420.10747@gannet.stats>

On Sat, 26 Mar 2005, Srinivas Iyyer wrote:

> Hi all:
> I am trying to do PCA on the following matrix.
>
>
>            N1     N2    A1      A2     B1     B2
> gene_a      90    110    190    210    290    310
> gene_b     190    210    390    410    590    610
> gene_c      90    110    110     90    120     80
> gene_d     200    100    400     90    600    200
>
>
>> dataf<-read.table("matrix")
>
>> pca<-princomp(dataf,cor=TRUE,scores=TRUE)
> Error in princomp.default(dataf, cor = TRUE, scores =
> TRUE) :
>        princomp can only be used with more units than
> variables
>
>
> Can any one help me, whats wrong here.

What is wrong is that you failed to read the help page before posting as 
the posting guide asks you to.  The explanation *IS* on the help page.
Please don't expect a help list to read the help for you.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tring at gvdnet.dk  Sat Mar 26 16:42:33 2005
From: tring at gvdnet.dk (Troels Ring)
Date: Sat, 26 Mar 2005 16:42:33 +0100
Subject: [R] "which"  is wrong?
Message-ID: <6.2.1.2.0.20050326160606.04e72880@home.gvdnet.dk>

Dear friends,
R 2.0.1 on windows XP:

TOT <-  seq(0.01,1,by=0.01)
  which(TOT==0.06)
# numeric(0)
which(TOT>0.06)
# [1]   6   7   8  etc
which(TOT<0.06)
#[1] 1 2 3 4 5
  TOT[6]
#[1] 0.06
TOT[6]==0.06
#[1] FALSE

but
TOT[5]==0.05
#[1] TRUE
  and
  which(TOT==0.05)
# [1] 5





TOT looks as expected when printed,
0.35 and 0.36 behaves similarly

I have tried on another machine with the same result - wonder what happens 
and whether
this is as expected ?

Best wishes
Troels Ring,
Aalborg, Denmark



From ligges at statistik.uni-dortmund.de  Sat Mar 26 16:52:46 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 26 Mar 2005 16:52:46 +0100
Subject: [R] "which"  is wrong?
In-Reply-To: <6.2.1.2.0.20050326160606.04e72880@home.gvdnet.dk>
References: <6.2.1.2.0.20050326160606.04e72880@home.gvdnet.dk>
Message-ID: <4245854E.1060704@statistik.uni-dortmund.de>

Troels Ring wrote:

> Dear friends,
> R 2.0.1 on windows XP:
> 
> TOT <-  seq(0.01,1,by=0.01)
>  which(TOT==0.06)
> # numeric(0)
> which(TOT>0.06)
> # [1]   6   7   8  etc
> which(TOT<0.06)
> #[1] 1 2 3 4 5
>  TOT[6]
> #[1] 0.06
> TOT[6]==0.06
> #[1] FALSE
> 
> but
> TOT[5]==0.05
> #[1] TRUE
>  and
>  which(TOT==0.05)
> # [1] 5
> 
> 
> 
> 
> 
> TOT looks as expected when printed,
> 0.35 and 0.36 behaves similarly
> 
> I have tried on another machine with the same result - wonder what 
> happens and whether
> this is as expected ?


It is expected: the 0.06 *calculated* by seq() is computationally a 
little bit different than the 0.06 you have typed - we are working with 
floating point calculations on a digital computer.
See ?all.equal for help.

Uwe Ligges


> Best wishes
> Troels Ring,
> Aalborg, Denmark
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From montse.rue at gmail.com  Sat Mar 26 18:16:49 2005
From: montse.rue at gmail.com (Montse Rue)
Date: Sat, 26 Mar 2005 18:16:49 +0100
Subject: [R] lme: random effects of a quadratic term
In-Reply-To: <Pine.LNX.4.61.0503260936150.23263@gannet.stats>
References: <605cea3f05032601202c46248@mail.gmail.com>
	<Pine.LNX.4.61.0503260936150.23263@gannet.stats>
Message-ID: <605cea3f05032609164a6f2d95@mail.gmail.com>

Thanks! I already tried it, but then I have problems with the augPred
values. I get straight lines instead of quadratic lines when plotting
the augPred values.

What can I do?

Montse


On Sat, 26 Mar 2005 09:39:07 +0000 (GMT), Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On Sat, 26 Mar 2005, Montse Rue wrote:
> 
> > I am estimating the following model:
> >
> > so2.lme<-lme(so2~1+I(alcadakm^2)+dia,data=subjectes2,na.action=na.omit)
> >
> > And when I try to plot the random effects of the quadratic term with
> > respect to a covariate (mam) I get an error:
> >
> >> so2.lmeRE<-ranef(so2.lme,augFrame=T)
> >> plot(so2.lmeRE,form=I(alcadakm^2)~mam)
> > Error in plot.ranef.lme(so2.lmeRE, form = I(alcadakm^2) ~ mam ) :
> >       Only single effects allowed in left side of form.
> >
> > Any suggestion?
> 
> Try renaming the variable, e.g. alcadakm2 = alcadakm^2, and refit.
> 
> NB: this is not `a quadratic term' but a transformed variable, since you
> used I().
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From 0034058 at fudan.edu.cn  Sat Mar 26 18:22:07 2005
From: 0034058 at fudan.edu.cn (ronggui)
Date: Sun, 27 Mar 2005 01:22:07 +0800
Subject: [R] how does predict.princomp work?
Message-ID: <20050327012207.60a0192f.0034058@fudan.edu.cn>

i want to know how the predict function to caculate the principal component,especially when has the newdata argument,i try to find out,but i fail.anyone knows?thank you!



From ripley at stats.ox.ac.uk  Sat Mar 26 18:39:43 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 26 Mar 2005 17:39:43 +0000 (GMT)
Subject: [R] lme: random effects of a quadratic term
In-Reply-To: <605cea3f05032609164a6f2d95@mail.gmail.com>
References: <605cea3f05032601202c46248@mail.gmail.com> 
	<Pine.LNX.4.61.0503260936150.23263@gannet.stats>
	<605cea3f05032609164a6f2d95@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0503261736250.31262@gannet.stats>

On Sat, 26 Mar 2005, Montse Rue wrote:

> Thanks! I already tried it, but then I have problems with the augPred
> values. I get straight lines instead of quadratic lines when plotting
> the augPred values.
>
> What can I do?

WHy are you expecting a non-linear plot from a linear fit?

> Montse
>
>
> On Sat, 26 Mar 2005 09:39:07 +0000 (GMT), Prof Brian Ripley
> <ripley at stats.ox.ac.uk> wrote:
>> On Sat, 26 Mar 2005, Montse Rue wrote:
>>
>>> I am estimating the following model:
>>>
>>> so2.lme<-lme(so2~1+I(alcadakm^2)+dia,data=subjectes2,na.action=na.omit)
>>>
>>> And when I try to plot the random effects of the quadratic term with
>>> respect to a covariate (mam) I get an error:
>>>
>>>> so2.lmeRE<-ranef(so2.lme,augFrame=T)
>>>> plot(so2.lmeRE,form=I(alcadakm^2)~mam)
>>> Error in plot.ranef.lme(so2.lmeRE, form = I(alcadakm^2) ~ mam ) :
>>>       Only single effects allowed in left side of form.
>>>
>>> Any suggestion?
>>
>> Try renaming the variable, e.g. alcadakm2 = alcadakm^2, and refit.
>>
>> NB: this is not `a quadratic term' but a transformed variable, since you
>> used I().
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From stephane.hess at imperial.ac.uk  Sat Mar 26 18:44:30 2005
From: stephane.hess at imperial.ac.uk (Hess, Stephane)
Date: Sat, 26 Mar 2005 17:44:30 -0000
Subject: [R] Multi-plot figures with different numbers of plots in different
	rows
Message-ID: <8CEECA6FD6736340AB8B3EB87769E09E4382FA@icex1.ic.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050326/323fee4a/attachment.pl

From f.calboli at imperial.ac.uk  Sat Mar 26 18:56:54 2005
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Sat, 26 Mar 2005 17:56:54 +0000
Subject: [R] Multi-plot figures with different numbers of plots in
	different rows
In-Reply-To: <8CEECA6FD6736340AB8B3EB87769E09E4382FA@icex1.ic.ac.uk>
References: <8CEECA6FD6736340AB8B3EB87769E09E4382FA@icex1.ic.ac.uk>
Message-ID: <1111859814.11063.429.camel@localhost.localdomain>

On Sat, 2005-03-26 at 17:44 +0000, Hess, Stephane wrote:
> Dear all, 
> 
> I have 5 plots that I would like to include in a single figure, spread over two rows. If I use mfrow=c(2,3), and produce my plots one after the other, I will end up with three plots in the first row, and 2 in the second row, which is what I want. However, I would like the two plots in the second row to be moved to the centre of that row, rather than occupying the two left-most cells.
> 
> I have also considered using split.screen, but this would mean that the plots in the lower half would be wider than in the upper half, whereas I want them all to be of the same size.
> 
> Thanks in advance for any suggestions on how this can be done.

There is a book called `Gr?ficos Estad?sticos con R' under "contributed
documentation" in the main R website. It should prove useful. The book
is in spanish, but as it is a "graphical" manual, it should not matter
much. If in troubles email me privately.

Cheers,

Federico 

-- 
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St Mary's Campus
Norfolk Place, London W2 1PG

Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From kjetil at acelerate.com  Sat Mar 26 19:01:35 2005
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Sat, 26 Mar 2005 14:01:35 -0400
Subject: [R] RE: Gmail invitation
In-Reply-To: <1abe3fa9050326064169e4cefd@mail.gmail.com>
References: <7FFEE688B57D7346BC6241C55900E730B70008@pollux.bfro.uni-lj.si>
	<1abe3fa9050326064169e4cefd@mail.gmail.com>
Message-ID: <4245A37F.50403@acelerate.com>

What is this stuff about' gmail invitation'?

Kjetil


A.J. Rossini wrote:

>Heck, if anyone cares, I've got 50 or so.  Just drop an email.  It's
>not a bad service.
>
>
>On Sat, 26 Mar 2005 15:19:04 +0100, Gorjanc Gregor
><Gregor.Gorjanc at bfro.uni-lj.si> wrote:
>  
>
>>I still have 40 invitations! Do not hesitate ;)
>>
>>This is last remainder on r-help.
>>
>>--
>>Lep pozdrav / With regards,
>>    Gregor Gorjanc
>>
>>------------------------------------------------------------------------
>>University of Ljubljana
>>Biotechnical Faculty       URI: http://www.bfro.uni-lj.si/MR/ggorjan
>>Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
>>Groblje 3                  tel: +386 (0)1 72 17 861
>>SI-1230 Domzale            fax: +386 (0)1 72 17 888
>>Slovenia
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>>    
>>
>
>
>  
>


-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra




-- 
No virus found in this outgoing message.
Checked by AVG Anti-Virus.



From rpeng at jhsph.edu  Sat Mar 26 20:19:15 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Sat, 26 Mar 2005 14:19:15 -0500
Subject: [R] how does predict.princomp work?
In-Reply-To: <20050327012207.60a0192f.0034058@fudan.edu.cn>
References: <20050327012207.60a0192f.0034058@fudan.edu.cn>
Message-ID: <4245B5B3.1030800@jhsph.edu>

Try doing

getS3method("predict", "princomp")

-roger

ronggui wrote:
> i want to know how the predict function to caculate the principal
> component,especially when has the newdata argument,i try to find
> out,but i fail.anyone knows?thank you!
> 
> ______________________________________________ 
> R-help at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
> posting guide! http://www.R-project.org/posting-guide.html
>



From p.murrell at auckland.ac.nz  Sat Mar 26 20:39:01 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Sun, 27 Mar 2005 07:39:01 +1200
Subject: [R] Multi-plot figures with different numbers of plots in
	different rows
References: <8CEECA6FD6736340AB8B3EB87769E09E4382FA@icex1.ic.ac.uk>
Message-ID: <4245BA55.3040407@stat.auckland.ac.nz>

Hi


Hess, Stephane wrote:
 > Dear all,
 >
 > I have 5 plots that I would like to include in a single figure,
 > spread over two rows. If I use mfrow=c(2,3), and produce my plots one
 > after the other, I will end up with three plots in the first row, and
 > 2 in the second row, which is what I want. However, I would like the
 > two plots in the second row to be moved to the centre of that row,
 > rather than occupying the two left-most cells.
 >
 > I have also considered using split.screen, but this would mean that
 > the plots in the lower half would be wider than in the upper half,
 > whereas I want them all to be of the same size.


Something like ...?

layout(rbind(c(1, 1, 2, 2, 3, 3),
              c(0, 4, 4, 5, 5, 0)))
for (i in 1:5) {
   plot(i, type="n")
   text(1, i, paste("Plot", i), cex=4)
}

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From jsorkin at grecc.umaryland.edu  Sat Mar 26 21:27:36 2005
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Sat, 26 Mar 2005 15:27:36 -0500
Subject: [R] does lmRobMM or an equivalent exist in R
Message-ID: <s2457f86.044@grecc.umaryland.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050326/be2d8173/attachment.pl

From HDoran at air.org  Sat Mar 26 21:43:12 2005
From: HDoran at air.org (Doran, Harold)
Date: Sat, 26 Mar 2005 15:43:12 -0500
Subject: [R] Function Arguments
Message-ID: <88EAF3512A55DF46B06B1954AEF73F7407E41AE3@dc1ex2.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050326/544223a6/attachment.pl

From MSchwartz at MedAnalytics.com  Sat Mar 26 21:52:05 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Sat, 26 Mar 2005 14:52:05 -0600
Subject: [R] does lmRobMM or an equivalent exist in R
In-Reply-To: <s2457f86.044@grecc.umaryland.edu>
References: <s2457f86.044@grecc.umaryland.edu>
Message-ID: <1111870325.30855.10.camel@horizons.localdomain>

On Sat, 2005-03-26 at 15:27 -0500, John Sorkin wrote:
> Does R have a function similiar to the SPlus functoin lmRobMM?
>  
> R 2.0.1
> Linux

John,

Page 161 of V&R's MASS4 suggests using the rlm() function in the MASS
package, which has a 'method = "MM"' argument.

So:

library(MASS)
?rlm

HTH,

Marc Schwartz



From york at zipcon.net  Sat Mar 26 19:20:12 2005
From: york at zipcon.net (Anne York)
Date: Sat, 26 Mar 2005 13:20:12 -0500 (EST)
Subject: [R] Multi-plot figures with different numbers of plots in
	different rows
In-Reply-To: <8CEECA6FD6736340AB8B3EB87769E09E4382FA@icex1.ic.ac.uk>
References: <8CEECA6FD6736340AB8B3EB87769E09E4382FA@icex1.ic.ac.uk>
Message-ID: <Pine.LNX.4.62.0503261316330.2758@sasquatch>



On Sat, 26 Mar 2005, Hess, Stephane wrote:

HS > Dear all, 
HS > 
HS > I have 5 plots that I would like to include in a single figure, spread over two rows. If I use mfrow=c(2,3), and produce my plots one after the other, I will end up with three plots in the first row, and 2 in the second row, which is what I want. However, I would like the two plots in the second row to be moved to the centre of that row, rather than occupying the two left-most cells.
HS > 
HS > I have also considered using split.screen, but this would mean that the plots in the lower half would be wider than in the upper half, whereas I want them all to be of the same size.
HS > 
HS > Thanks in advance for any suggestions on how this can be done.
HS > 
HS > Stephane
HS > 
HS > 
HS > --------------------------------------------------------------------------------------
HS > Mr Stephane Hess
HS > Centre for Transport Studies
HS > Imperial College London
HS > -------------------------------------------------------------------------------------- 


Here is a brute force way:

par(mfrow=c(2,3)) #set up 2 rows x 3 colums
plot(1:10) #plot 1
plot(1:10) #plot 2
plot(1:10) #plot 3
par(mfg=c(2,2))  # start next plot at 2,2 instead of 2,1
 plot(1:10)       # 4th plot



From montse.rue at gmail.com  Sat Mar 26 22:21:36 2005
From: montse.rue at gmail.com (Montse Rue)
Date: Sat, 26 Mar 2005 22:21:36 +0100
Subject: [R] lme: random effects of a quadratic term
In-Reply-To: <Pine.LNX.4.61.0503261736250.31262@gannet.stats>
References: <605cea3f05032601202c46248@mail.gmail.com>
	<Pine.LNX.4.61.0503260936150.23263@gannet.stats>
	<605cea3f05032609164a6f2d95@mail.gmail.com>
	<Pine.LNX.4.61.0503261736250.31262@gannet.stats>
Message-ID: <605cea3f05032613216dc402d4@mail.gmail.com>

I tried to replicate in R the example that Pinheiro and Bates present
on section 1.5 of their mixed-effects book, the pixel intensity
example.

> fm1Pixel<-lme(pixel~day+day^2,data=Pixel,random=list(Dog=~day,Side=~1))

When I run it in R the second order term does not appear in the
estimated model. But, when I write

> fm1Pixel<-lme(pixel~day+I(day^2),data=Pixel,random=list(Dog=~day,Side=~1))

I get the same results as in the Pinheiro and Bates book, and the plot
of the augPred values is a quadratic function as in Figure 1.18. The
same happens with my data when I use the I(alcadakm^2) .

Can it be that S accepts day^2 but R doesn't?

Thanks again!

Montse



On Sat, 26 Mar 2005 17:39:43 +0000 (GMT), Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On Sat, 26 Mar 2005, Montse Rue wrote:
> 
> > Thanks! I already tried it, but then I have problems with the augPred
> > values. I get straight lines instead of quadratic lines when plotting
> > the augPred values.
> >
> > What can I do?
> 
> WHy are you expecting a non-linear plot from a linear fit?
> 
> > Montse
> >
> >
> > On Sat, 26 Mar 2005 09:39:07 +0000 (GMT), Prof Brian Ripley
> > <ripley at stats.ox.ac.uk> wrote:
> >> On Sat, 26 Mar 2005, Montse Rue wrote:
> >>
> >>> I am estimating the following model:
> >>>
> >>> so2.lme<-lme(so2~1+I(alcadakm^2)+dia,data=subjectes2,na.action=na.omit)
> >>>
> >>> And when I try to plot the random effects of the quadratic term with
> >>> respect to a covariate (mam) I get an error:
> >>>
> >>>> so2.lmeRE<-ranef(so2.lme,augFrame=T)
> >>>> plot(so2.lmeRE,form=I(alcadakm^2)~mam)
> >>> Error in plot.ranef.lme(so2.lmeRE, form = I(alcadakm^2) ~ mam ) :
> >>>       Only single effects allowed in left side of form.
> >>>
> >>> Any suggestion?
> >>
> >> Try renaming the variable, e.g. alcadakm2 = alcadakm^2, and refit.
> >>
> >> NB: this is not `a quadratic term' but a transformed variable, since you
> >> used I().
> >>
> >> --
> >> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >> University of Oxford,             Tel:  +44 1865 272861 (self)
> >> 1 South Parks Road,                     +44 1865 272866 (PA)
> >> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >>
> >
> >
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From MSchwartz at MedAnalytics.com  Sat Mar 26 22:37:31 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Sat, 26 Mar 2005 15:37:31 -0600
Subject: [R] lme: random effects of a quadratic term
In-Reply-To: <605cea3f05032613216dc402d4@mail.gmail.com>
References: <605cea3f05032601202c46248@mail.gmail.com>
	<Pine.LNX.4.61.0503260936150.23263@gannet.stats>
	<605cea3f05032609164a6f2d95@mail.gmail.com>
	<Pine.LNX.4.61.0503261736250.31262@gannet.stats>
	<605cea3f05032613216dc402d4@mail.gmail.com>
Message-ID: <1111873051.30855.23.camel@horizons.localdomain>

On Sat, 2005-03-26 at 22:21 +0100, Montse Rue wrote:
> I tried to replicate in R the example that Pinheiro and Bates present
> on section 1.5 of their mixed-effects book, the pixel intensity
> example.
> 
> > fm1Pixel<-lme(pixel~day+day^2,data=Pixel,random=list(Dog=~day,Side=~1))
> 
> When I run it in R the second order term does not appear in the
> estimated model. But, when I write
> 
> > fm1Pixel<-lme(pixel~day+I(day^2),data=Pixel,random=list(Dog=~day,Side=~1))
> 
> I get the same results as in the Pinheiro and Bates book, and the plot
> of the augPred values is a quadratic function as in Figure 1.18. The
> same happens with my data when I use the I(alcadakm^2) .
> 
> Can it be that S accepts day^2 but R doesn't?
> 
> Thanks again!
> 
> Montse

<SNIP of prior exchange>

As per the main R FAQ "3.3.2 Models":

There are some differences in the modeling code, such as 

      * Whereas in S, you would use lm(y ~ x^3) to regress y on x^3, in
        R, you have to insulate powers of numeric vectors (using I()),
        i.e., you have to use lm(y ~ I(x^3))

Please read the FAQ's when comparing R and S[-PLUS] as this is but one
of the important differences:

http://cran.r-project.org/doc/FAQ/R-FAQ.html#R-and-S

Marc Schwartz



From MSchwartz at MedAnalytics.com  Sat Mar 26 23:29:40 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Sat, 26 Mar 2005 16:29:40 -0600
Subject: [R] Function Arguments
In-Reply-To: <88EAF3512A55DF46B06B1954AEF73F7407E41AE3@dc1ex2.air.org>
References: <88EAF3512A55DF46B06B1954AEF73F7407E41AE3@dc1ex2.air.org>
Message-ID: <1111876180.30855.54.camel@horizons.localdomain>

On Sat, 2005-03-26 at 15:43 -0500, Doran, Harold wrote:
> Hello,
>  
> I am trying to wrap some code that I repeatedly use into a function
> for efficiency. The following is a toy example simply to illustrate
> the problem. 
>  
> foobar.fun<-function(data,idvar,dv){
> id.list<-unique(idvar)
> result<-numeric(0)
>      for (i in id.list){
>      tmp1<-subset(data, idvar == i)
>      result[i]<-mean(get("tmp1")[[dv]])
>      }
> return(result)
> }
>  
> The issue is that when the variable 'dv' is replaced by the name of
> the actual variable in the dataframe the function works as expected.
> However, when 'dv' is used the function does not identify this as a
> variable, even though it is one of the function arguments and the
> function fails.
>  
> How can function arguments be passed to a loop in such cases? 
>  
> Thank you,
> Harold

Harold,

Perhaps I am being confused by your example code, which can all be
replaced by:

  tapply(data$dv, list(data$idvar), mean)

Using the 'warpbreaks' data in ?tapply, get the mean of 'breaks' for
each level of 'tension':

> tapply(warpbreaks$breaks, list(warpbreaks$tension), mean)
       L        M        H
36.38889 26.38889 21.66667


Of course, 'mean' can be replaced by more a more complex function call
and additional arguments.


Or you can use by():

> by(warpbreaks$breaks, warpbreaks$tension, mean)
INDICES: L
[1] 36.38889
------------------------------------------------------ 
INDICES: M
[1] 26.38889
------------------------------------------------------ 
INDICES: H
[1] 21.66667


or you can use split() on the data frame first, followed by sapply():

# split warpbreaks into a list of 3 data frames by the value of 
# tension, each containing only 'breaks'
> warp.s <- split(warpbreaks$breaks, warpbreaks$tension)

# now use sapply to get the mean of breaks in each df:
> sapply(warp.s, mean)
       L        M        H 
36.38889 26.38889 21.66667


Or even:

> aggregate(warpbreaks$breaks, list(Tension = warpbreaks$tension), mean)
  Tension        x
1       L 36.38889
2       M 26.38889
3       H 21.66667


However, presuming that your actual code is rather different and the key
is that you are really having problems referencing the column elements
in your data frame, the line:

  result[i]<-mean(get("tmp1")[[dv]])

would require that you pass the argument 'dv' as a character variable in
the original function call, such as:

  foobar.fun(..., ..., dv = "VectorName")

When extracting a data frame column or list element using '[' or '[[',
the index(s) value must be either numeric or character.

So, again using the warpbreaks data to get the breaks column:

> warpbreaks$breaks
 [1] 26 30 54 25 70 52 51 26 67 18 21 29 17 12 18 35 30 36 36 21 24 18
[23] 10 43 28 15 26 27 14 29 19 29 31 41 20 44 42 26 19 16 39 28 21 39
[45] 29 20 21 24 17 13 15 15 16 28

> warpbreaks[["breaks"]]
 [1] 26 30 54 25 70 52 51 26 67 18 21 29 17 12 18 35 30 36 36 21 24 18
[23] 10 43 28 15 26 27 14 29 19 29 31 41 20 44 42 26 19 16 39 28 21 39
[45] 29 20 21 24 17 13 15 15 16 28

> warpbreaks[[1]]
 [1] 26 30 54 25 70 52 51 26 67 18 21 29 17 12 18 35 30 36 36 21 24 18
[23] 10 43 28 15 26 27 14 29 19 29 31 41 20 44 42 26 19 16 39 28 21 39
[45] 29 20 21 24 17 13 15 15 16 28

> warpbreaks[, "breaks"]
 [1] 26 30 54 25 70 52 51 26 67 18 21 29 17 12 18 35 30 36 36 21 24 18
[23] 10 43 28 15 26 27 14 29 19 29 31 41 20 44 42 26 19 16 39 28 21 39
[45] 29 20 21 24 17 13 15 15 16 28

However:

> warpbreaks[[breaks]]
Error in (function(x, i) if (is.matrix(i)) as.matrix(x)[[i]]
else .subset2(x,  : 
	Object "breaks" not found

or

> warpbreaks[, breaks]
Error in "[.data.frame"(warpbreaks, , breaks) : 
	Object "breaks" not found


HTH,

Marc Schwartz
<Will be away from e-mail for a while)



From giljustino at yahoo.com.br  Sat Mar 26 23:59:12 2005
From: giljustino at yahoo.com.br (Gilvan Justino)
Date: Sat, 26 Mar 2005 19:59:12 -0300 (ART)
Subject: [R] Is there a diferent way to do this?
Message-ID: <20050326225912.10266.qmail@web50403.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050326/92addf47/attachment.pl

From lisas at salford-systems.com  Sun Mar 27 00:01:16 2005
From: lisas at salford-systems.com (Lisa Solomon)
Date: Sat, 26 Mar 2005 15:01:16 -0800
Subject: [R] LAST CHANCE: Data Mining Conference in NEW YORK CITY: Two
 full-days of Case Study Presentations
Message-ID: <4245E9BC.3050200@salford-systems.com>

Apologies for cross posting
-----------------------------------------------------------------------------
                    Salford Systems Data Mining 2005
                      New York, March 29-30, 2005
Focusing on the Contributions of Data Mining to Solving Real World 
Challenges

Two Full Days of Case Study Presentation, Tuesday March 29th and 
Wednesday March 30th
Opening Session March 28th with Data Mining Visionary Jerome Friedman

                           CONFERENCE SCHEDULE
              http://www.salforddatamining.com/program.htm
------------------------------------------------------------------------------
REGISTRATION OPTIONS:
**Phone In: (619) 543-8880
**PDF: http://www.salforddatamining.com//FINALConfBrochure.pdf
**Onsite Registration during the conference:
American Conference Centers, 780 3rd Ave, New York, NY 10017
Monday Registration: 3PM - 7PM
Tuesday Registration: 7:30AM - 7PM
Wednesday Registration: 7:30AM - 1PM

TRACKS:
Data Mining Issues and Implementation
Real World Success Stories: Business
Real World Success Stories: Biomedical
Real World Success Stories: Environmental
Novel Methodologies

POST-CONFERENCE HANDS-ON TRAINING
March 31 - April 1, 2005

Network with Data Mining Experts and Pick up Pointers from Companies, 
Research Centers and Laboratories Including:
The International Monetary Fund, American Express, Barnes and Noble, 
Visa, Pfizer, International Steel, Wells Fargo Bank, Ciphergen, Stanford 
Linear Accelerator, Johns Hopkins University Medical School, AT&T Labs - 
Research and the Columbia University School of Public Health.

If you have an interest in attending this conference or the 
post-conference training, please call: (619) 543-8880.
If you would like to be kept informed regarding future conferences, 
please contact: lisas at salford-systems.com
Conference Website: http://www.salforddatamining.com



From kjetil at acelerate.com  Sat Mar 26 19:58:24 2005
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Sat, 26 Mar 2005 14:58:24 -0400
Subject: [R] Bivariate lognormal distribution
In-Reply-To: <004101c5315d$e5a3e450$a200a8c0@HOME2>
References: <007901c530b4$981840e0$a200a8c0@HOME2>	<Pine.LNX.4.61.0503242140340.9482@gannet.stats>	<424422F2.8050903@pdf.com>
	<004101c5315d$e5a3e450$a200a8c0@HOME2>
Message-ID: <4245B0D0.8030200@acelerate.com>

Vicky Landsman wrote:

>
> Thanks to Prof. Ripley, Kjetil and Spencer Graves for help.
> I will be more specific.
> I have to simulate a bivariate lognormal pair (Y1,Y0) where E(Y1)=X'b, 
> E(Y0)=X'd, Var(Y1)=c1, Var(Y0)=c0,
> X is a data matrix, and b and d are vectors of parameters.
> Vicky.

You did'nt specify the dependence!

Kjetil

>
>
> ----- Original Message ----- From: "Spencer Graves" 
> <spencer.graves at pdf.com>
> To: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
> Cc: "Vicky Landsman" <msvika at mscc.huji.ac.il>; "R-help list" 
> <R-help at stat.math.ethz.ch>
> Sent: Friday, March 25, 2005 4:40 PM
> Subject: Re: [R] Bivariate lognormal distribution
>
>
>>
>>      I hope Professor Ripley will correct me if I'm mistaken, but the 
>> documentation for "mvrnorm" in library(MASS) says it will, "Simulate 
>> from a Multivariate Normal Distribution".  If you want the density 
>> function or probabilities or quantiles, you can get those from 
>> library(mvtnorm).
>>      Just for completeness, to use normal for a lognormal, you need 
>> to take the logarithms of your number (which must be all positive;  
>> zeros and negative numbers become NA), then compute mean vector and 
>> variance matrix of the logs, compute probabilities on the log scale, 
>> then back transform by exponentiating to get the results back into 
>> the original scale.
>>      hope this helps.  spencer graves
>>
>> Prof Brian Ripley wrote:
>>
>>> On Thu, 24 Mar 2005, Vicky Landsman wrote:
>>>
>>>> Is there a package that enables to create the bivariate log-normal 
>>>> variables?
>>>
>>>
>>>
>>> Just exponentiate each of a bivariate normal pair.  You can get the 
>>> latter from mvrnorm in package MASS.
>>>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
>
>


-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra





-- 
No virus found in this outgoing message.
Checked by AVG Anti-Virus.



From jsorkin at grecc.umaryland.edu  Sun Mar 27 03:36:19 2005
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Sat, 26 Mar 2005 20:36:19 -0500
Subject: [R] p values when using rlm
Message-ID: <s245c7d3.048@grecc.umaryland.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050326/5a17aeea/attachment.pl

From brett at hbrc.govt.nz  Sun Mar 27 04:36:48 2005
From: brett at hbrc.govt.nz (Brett Stansfield)
Date: Sun, 27 Mar 2005 14:36:48 +1200
Subject: [R] Subject [applying labels to a scatter plot matrix]
Message-ID: <3542A1BF5AE1984D9FF577DA2CF8BA9868B169@MSX2>

Dear R
Is there a way to apply row names as labels to a scatter plot matrix , 
I tried

pairs(dogs, labels=row.names)
Error in strwidth(labels, "user") : cannot coerce type closure to character
vector

I'm not sure what this means, however maybe you might know of a way to do
this?

brett stansfield



From 0034058 at fudan.edu.cn  Sun Mar 27 04:51:18 2005
From: 0034058 at fudan.edu.cn (ronggui)
Date: Sun, 27 Mar 2005 10:51:18 +0800
Subject: [R] question about predict.princomp
Message-ID: <20050327105118.66e3308a.0034058@fudan.edu.cn>

from the code of predict for princomp,it scale the new data using the object$center and pbject$scores,i wander why?if the predict function desgined for validitation?but "analyzing multivariate data"(lattin,carrol and green) say:in general,when we raise the notion of validity,we are questioning the generalizability of the results frome our analysis the particular sample......one way to adress this question is to use a holdout sample....thus ...form the linear combination X(s)u(1) using the standardized data from the second (holdout)sample,and have the variance of component thus formed be appoximately equal to the variance of Z1 from the principal components analysis of the first sample.

so ,why the predict scale the newdata using   scale(newdata, object$center, object$scale) but NOT scale(newdata,scale=T,center=T)?



From MSchwartz at MedAnalytics.com  Sun Mar 27 05:05:07 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Sat, 26 Mar 2005 21:05:07 -0600
Subject: [R] Subject [applying labels to a scatter plot matrix]
In-Reply-To: <3542A1BF5AE1984D9FF577DA2CF8BA9868B169@MSX2>
References: <3542A1BF5AE1984D9FF577DA2CF8BA9868B169@MSX2>
Message-ID: <1111892707.30855.65.camel@horizons.localdomain>

On Sun, 2005-03-27 at 14:36 +1200, Brett Stansfield wrote:
> Dear R
> Is there a way to apply row names as labels to a scatter plot matrix , 
> I tried
> 
> pairs(dogs, labels=row.names)
> Error in strwidth(labels, "user") : cannot coerce type closure to character
> vector
> 
> I'm not sure what this means, however maybe you might know of a way to do
> this?


Brett,

'row.names' is a function, that either gets or sets row names in a data
frame. It requires an argument, which is a data frame, such as:

> row.names(dogs)

By itself you are attempting to set the labels to a function:

> typeof(row.names)
[1] "closure"

Thus, the error message.

Try:

> pairs(dogs, labels=row.names(dogs))

If 'dogs' is not a data frame, but is a matrix or array, try using:

> pairs(dogs, labels=rownames(dogs))

See ?row.names and ?rownames for more information.

HTH,

Marc Schwartz



From MSchwartz at MedAnalytics.com  Sun Mar 27 05:15:19 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Sat, 26 Mar 2005 21:15:19 -0600
Subject: [R] p values when using rlm
In-Reply-To: <s245c7d3.048@grecc.umaryland.edu>
References: <s245c7d3.048@grecc.umaryland.edu>
Message-ID: <1111893319.30855.73.camel@horizons.localdomain>

On Sat, 2005-03-26 at 20:36 -0500, John Sorkin wrote:
> R 2.0.1
> Linux
>  
> I am using rlm() to fit a model, e.g. fit1<-rlm(y~x). My model is more
> complex than the one shown.
>  
> When I enter summary(fit1) 
> I get estimates for the model's coefficients along with their SEs, and
> t values, but no p values. The p value column is blank.
> Similarly, when I enter anova(fit1) I get DF, Sum Sq, Mean Sq, but the
> column for F value and Pr(>F) are blank. 
>  
> Any suggestions that will allow me to get the p values for summary, the
> F and p values for anova?
> Thanks,
> John

John,

Perhaps these two posts may be of help to you:

http://tolstoy.newcastle.edu.au/R/help/04/10/5260.html

http://tolstoy.newcastle.edu.au/R/help/04/10/5252.html

I also located via a Google search the f.robftest() function in the
'sfsmisc' package on CRAN:

http://finzi.psych.upenn.edu/R/library/sfsmisc/html/f.robftest.html

but I would have to defer to the respective authors as to the pros and
cons of any of these approaches.

HTH,

Marc Schwartz



From cuteymei at yahoo.com.tw  Sun Mar 27 05:42:18 2005
From: cuteymei at yahoo.com.tw (=?big5?q?=AC=FC=B5=E2=20=B6=C0?=)
Date: Sun, 27 Mar 2005 11:42:18 +0800 (CST)
Subject: [R] Where can I found the package "ordinal" ?
Message-ID: <20050327034218.44802.qmail@web18107.mail.tpe.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050327/2a2dbe6d/attachment.pl

From gb at stat.umu.se  Sun Mar 27 07:38:14 2005
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Sun, 27 Mar 2005 07:38:14 +0200
Subject: [R] Re: [Rd] F90
In-Reply-To: <7FFEE688B57D7346BC6241C55900E730B70004@pollux.bfro.uni-lj.si>
References: <7FFEE688B57D7346BC6241C55900E730B70004@pollux.bfro.uni-lj.si>
Message-ID: <20050327053814.GA24296@stat.umu.se>

On Sun, Mar 27, 2005 at 03:26:39AM +0200, Gorjanc Gregor wrote:
> Hello!
> 
> Has anyone successfully compiled F90 sources in R-package? I found the
> same question on r-devel list from 2002 and I wonder if there is any
> progress. I heard that g95 and gfortran can be usable. 
> 
> And one more thing. I have a program written in F90 and lets suppose that
> compiler is not a problem. I've read manual 'Writing R Extensions' and
> successfully loaded one F77 subroutine in R for test and I had no problem. 
> However, what is the strategy if one has a whole program i.e. main program 
> + subroutines and wants to call it from R?

Well, you have essentially two options:

1. Rewrite your main program as an R function, from which you call the
   subroutines (thru the .Fortran interface).

2. Rewrite your main program as a Fortran subroutine, write an R wrapper,
   that calls your new subroutine (thru the .Fortran interface).

Choose whatever is simplest.

G?ran

> 
> Thanks in advance!
> 
> --
> Lep pozdrav / With regards,
>     Gregor Gorjanc
> 
> ------------------------------------------------------------------------
> University of Ljubljana
> Biotechnical Faculty       URI: http://www.bfro.uni-lj.si/MR/ggorjan
> Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
> Groblje 3                  tel: +386 (0)1 72 17 861
> SI-1230 Domzale            fax: +386 (0)1 72 17 888
> Slovenia
> 
> ______________________________________________
> R-devel at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se



From Gregor.Gorjanc at bfro.uni-lj.si  Sun Mar 27 10:10:47 2005
From: Gregor.Gorjanc at bfro.uni-lj.si (Gorjanc Gregor)
Date: Sun, 27 Mar 2005 10:10:47 +0200
Subject: [R] RE: [Rd] F90
Message-ID: <7FFEE688B57D7346BC6241C55900E730B7000E@pollux.bfro.uni-lj.si>

G?ran, thanks.

Happy easter!

-----Original Message-----
From: G?ran Brostr?m [mailto:gb at stat.umu.se]
Sent: ned 2005-03-27 07:38
To: Gorjanc Gregor
Cc: r-help at stat.math.ethz.ch
Subject: Re: [Rd] F90
 
On Sun, Mar 27, 2005 at 03:26:39AM +0200, Gorjanc Gregor wrote:
> Hello!
> 
> Has anyone successfully compiled F90 sources in R-package? I found the
> same question on r-devel list from 2002 and I wonder if there is any
> progress. I heard that g95 and gfortran can be usable. 
> 
> And one more thing. I have a program written in F90 and lets suppose that
> compiler is not a problem. I've read manual 'Writing R Extensions' and
> successfully loaded one F77 subroutine in R for test and I had no problem. 
> However, what is the strategy if one has a whole program i.e. main program 
> + subroutines and wants to call it from R?

Well, you have essentially two options:

1. Rewrite your main program as an R function, from which you call the
   subroutines (thru the .Fortran interface).

2. Rewrite your main program as a Fortran subroutine, write an R wrapper,
   that calls your new subroutine (thru the .Fortran interface).

Choose whatever is simplest.

G?ran

> 
> Thanks in advance!
> 
> --
> Lep pozdrav / With regards,
>     Gregor Gorjanc
> 
> ------------------------------------------------------------------------
> University of Ljubljana
> Biotechnical Faculty       URI: http://www.bfro.uni-lj.si/MR/ggorjan
> Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
> Groblje 3                  tel: +386 (0)1 72 17 861
> SI-1230 Domzale            fax: +386 (0)1 72 17 888
> Slovenia
> 
> ______________________________________________
> R-devel at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Umea University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Umea, Sweden             e-mail: gb at stat.umu.se



From p.dalgaard at biostat.ku.dk  Sun Mar 27 11:29:50 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 27 Mar 2005 11:29:50 +0200
Subject: [R] Where can I found the package "ordinal" ?
In-Reply-To: <20050327034218.44802.qmail@web18107.mail.tpe.yahoo.com>
References: <20050327034218.44802.qmail@web18107.mail.tpe.yahoo.com>
Message-ID: <x2vf7dfnch.fsf@turmalin.kubism.ku.dk>

?? ? <cuteymei at yahoo.com.tw> writes:

> Hello,dear all: 
> 
> 
> I want to install the package "ordinal",but I don't see the package listed under package sources.
> 
> I try to search it by "google",then I found this:
> 
> http://euridice.tue.nl/~plindsey/rlibs.html 
> 
> but the connect does not work.
> 
> Where can I found the package "ordinal" ?   Is it still available? 

Try

http://fdg-popgen146.unimaas.nl/~plindsey/rlibs.html

(I really don't know why I should even take the time Googling for Jim
& Pat's current whereabouts. They clearly do not believe in neither
version control, CRAN, nor in following standard terminology.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From gordon.dinetto at gmx.net  Sun Mar 27 14:13:07 2005
From: gordon.dinetto at gmx.net (gordon dinetto)
Date: Sun, 27 Mar 2005 14:13:07 +0200 (MEST)
Subject: [R] Time varying coefficients with Kalman
Message-ID: <17463.1111925587@www28.gmx.net>

Dear R-users

Is there any possibility to estimate a regression model with time varying
intercept and slope of the form: 

r(t)   = a(t) + b(t)*x(t) + eta(t)
a(t+1) = a(t) + v(t)
b(t+1) = b(t) + w(t)

by utilising the Kalman routines in R. I have tried the KalmanLike in (ts)
but it seems to be designed for univariate models whereas the (dse) bundle
deals with multivariate time series only. The state space form of this model
is as follows: 
z(t+1) = F*z(t) + Q(t)
r(t)   = H*z(t) + R(t)

where z(t+1) = [a(t+1),b(t+1)]' is the state vector containing the time
varying coefficients, F = I the transition matrix, and H = [1,x(t)]' the
output matrix, with Q(t) and R(t) as system noise and output noise matrix
respectively.
Any suggestions for alternative solutions are greatly appreciated.

Best regards,
Gordon Dinetto

-- 
Sparen beginnt mit GMX DSL: http://www.gmx.net/de/go/dsl



From kjetil at acelerate.com  Sun Mar 27 14:19:21 2005
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Sun, 27 Mar 2005 08:19:21 -0400
Subject: [R] Where can I found the package "ordinal" ?
In-Reply-To: <x2vf7dfnch.fsf@turmalin.kubism.ku.dk>
References: <20050327034218.44802.qmail@web18107.mail.tpe.yahoo.com>
	<x2vf7dfnch.fsf@turmalin.kubism.ku.dk>
Message-ID: <4246A4C9.7050609@acelerate.com>

Peter Dalgaard wrote:

>?? ? <cuteymei at yahoo.com.tw> writes:
>
>  
>
>>Hello,dear all: 
>>
>>
>>I want to install the package "ordinal",but I don't see the package listed under package sources.
>>
>>I try to search it by "google",then I found this:
>>
>>http://euridice.tue.nl/~plindsey/rlibs.html 
>>
>>but the connect does not work.
>>
>>Where can I found the package "ordinal" ?   Is it still available? 
>>    
>>
>
>Try
>
>http://fdg-popgen146.unimaas.nl/~plindsey/rlibs.html
>
>(I really don't know why I should even take the time Googling for Jim
>& Pat's current whereabouts. They clearly do not believe in neither
>version control, CRAN, nor in following standard terminology.)
>
>  
>
By the way, ordinal does not compile under rw2010dev.

Kjetil

-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra





-- 
No virus found in this outgoing message.
Checked by AVG Anti-Virus.



From ligges at statistik.uni-dortmund.de  Sun Mar 27 16:27:48 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 27 Mar 2005 16:27:48 +0200
Subject: [R] Is there a diferent way to do this?
In-Reply-To: <20050326225912.10266.qmail@web50403.mail.yahoo.com>
References: <20050326225912.10266.qmail@web50403.mail.yahoo.com>
Message-ID: <4246C2E4.6090304@statistik.uni-dortmund.de>

Gilvan Justino wrote:
> Hi,
>  
> I started creating a small class but I'm courious about how it is working.
>  
> To create a instance of my class "Partri" I write this at Rgui:
> x <- new("Partri", name="Gilvan")
>  
> and to change the slot "name" of this instance, I write:
> setName(x, newname="Justino")
>  
> It is not working, because when I type "x" at Rgui, it shows the initial value, which was "Gilvan". What I am doing wrong?
>  
> I'll appreciate any king of help!
> Gilvan
>  
>  
> # Classe para representar um par?metro
> setClass("Partri",
>    # par?metros
>    representation( name="character"),
>    # se??o de inicializa??o
>    prototype( name="undefined name" )
> )
> 
> setGeneric("setName",
>            function(object, newname,...)
>            standardGeneric("setName"))
> setMethod("setName", 
>           signature(object="Partri",newname="character"),        
>           function(object, newname)
>           {
>             object at name = newname


You set the "name" in the environment of the method, but you don't 
assign it to the environment that you seem to expect erroneously. To see 
that it works, simply insert

              print(object at name)

Instead, you want to write some non-standard replacement function. See 
?setReplaceMethod and friends (you might want to take a look into the 
green book as well).

Uwe Ligges




>           }
>           )




> 
> 		
> ---------------------------------
> 
> ora!
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From faebly at neb.rr.com  Sun Mar 27 18:27:44 2005
From: faebly at neb.rr.com (Frank Aebly)
Date: Sun, 27 Mar 2005 10:27:44 -0600
Subject: [R] netcdf
Message-ID: <261E0E78-9EDD-11D9-8464-0050E4A07343@neb.rr.com>

Hi All,
I'm very knew to R.  I downloaded and am running it on my redhat so 
that I can use the clim.pact package.  Everything is downloaded and 
installed correctly.  When trying to read a netcdf file from the 
NCEP/NCAR reanalysis dataset using retrieve.nc I keep getting errors 
that the number of dimensions are wrong.

If I use
x.1 <- retrieve.nc("geopothgt.nc")
I get the above error.
this file is a subset created from the NCEP website with only the 500 
mb level

I've tried both
force 365.25=TRUE
daysayear=365.25
  one at a time, and without these arguments and I still get the same 
error

I also tried to use retrieve.nc with the whole data set and I get the 
message that data is in months when time units are set to days. Set 
time unit to month.  But I haven't been able to find in the 
documentation what the values are for t.unit.
I've tried
t.unit=month
t.unit="month"
t.unit=MONTH
t.unit="MONTH"
all of these result in a return of "unused argument t.unit"
I'm apparently not entering the correct value for t.unit, but I can't 
find a list of options anywhere

Any help?

Thanks
Frank Aebly



From jun at cc.gatech.edu  Sun Mar 27 19:18:54 2005
From: jun at cc.gatech.edu (Seung Jun)
Date: Sun, 27 Mar 2005 12:18:54 -0500
Subject: [R] "Fold" in R?
Message-ID: <4246EAFE.7090501@cc.gatech.edu>

Fold in Mathematica (or reduce in Python) works as follows:

Fold[f, x, {a, b, c}] := f[f[f[x,a],b],c]

That is, f is a binary operator, x is the initial value, and the results 
are cascaded along the list.  I've found it useful for reducing lists 
when I only have a function that accepts two arguments (e.g., merge in R).

Is there any R equivalent?  I'm a newbie in R and having a hard time 
finding such one.  Thank you.

Seung



From p.dalgaard at biostat.ku.dk  Sun Mar 27 19:43:01 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 27 Mar 2005 19:43:01 +0200
Subject: [R] "Fold" in R?
In-Reply-To: <4246EAFE.7090501@cc.gatech.edu>
References: <4246EAFE.7090501@cc.gatech.edu>
Message-ID: <x2r7i1f0ii.fsf@turmalin.kubism.ku.dk>

Seung Jun <jun at cc.gatech.edu> writes:

> Fold in Mathematica (or reduce in Python) works as follows:
> 
> Fold[f, x, {a, b, c}] := f[f[f[x,a],b],c]
> 
> That is, f is a binary operator, x is the initial value, and the
> results are cascaded along the list.  I've found it useful for
> reducing lists when I only have a function that accepts two arguments
> (e.g., merge in R).
> 
> Is there any R equivalent?  I'm a newbie in R and having a hard time
> finding such one.  Thank you.

Tried searching the mailing list for "Fold"? It was discussed on this
very list in November.

http://cran.r-project.org/search.html
http://maths.newcastle.edu.au/~rking/R/ 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ggrothendieck at myway.com  Sun Mar 27 19:46:23 2005
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 27 Mar 2005 17:46:23 +0000 (UTC)
Subject: [R] "Fold" in R?
References: <4246EAFE.7090501@cc.gatech.edu>
Message-ID: <loom.20050327T194225-636@post.gmane.org>

Seung Jun <jun <at> cc.gatech.edu> writes:

: 
: Fold in Mathematica (or reduce in Python) works as follows:
: 
: Fold[f, x, {a, b, c}] := f[f[f[x,a],b],c]
: 
: That is, f is a binary operator, x is the initial value, and the results 
: are cascaded along the list.  I've found it useful for reducing lists 
: when I only have a function that accepts two arguments (e.g., merge in R).
: 
: Is there any R equivalent?  I'm a newbie in R and having a hard time 
: finding such one.  Thank you.
: 

You could define it yourself like this:

   Fold <- function(f, x, L) for(e in L) x <- f(x, e)

   # example of its use
   result <- Fold(sum, 0, 1:3)  # result is 6


Note that merge.zoo in the zoo package does handle multiple
arguments; however, that is intended for merging time series
along their times, in case that is your application.



From andersn at hawaii.edu  Sun Mar 27 23:34:57 2005
From: andersn at hawaii.edu (Anders Nielsen)
Date: Sun, 27 Mar 2005 11:34:57 -1000 (HST)
Subject: [R] Negative binomial GLMMs in R
Message-ID: <Pine.GSO.4.58a.0503271116550.9119@uhunix2>


Dear List,

I have tried the program (Linux version) supplied to fit the
negative binomial mixed model. It seems to work really well and
converge fast.

Since this is apparently a model that is difficult to fit with
what is presently in R, and more difficult to fit with other
standard tools, it would be nice to have this solution wrapped
into a real R-package with documentation and all. I for one
would like to encourage the authors to make such a package
available (and would be willing to help if requested).

I don't know if such a package could be posted on CRAN since it
relies on a closed source library for automatic differentiation,
but if that is a problem it could at least be made available on
a personal web-page.

Cheers,

Anders.

On Wed, 23 Mar 2005 Hans.Skaug at mi.uib.no wrote:

> Dear R-users,
>
> A recent post (Feb 16) to R-help inquired about fitting
> a glmm with  a negative binomial distribution.
> Professor Ripley responded that this was a difficult problem with the
> simpler Poisson model already being a difficult case:
>
> https://stat.ethz.ch/pipermail/r-help/2005-February/064708.html
>
> Since we are developing software for fitting general nonlinear random
> effects models we thought this might be an interesting challenge.
> We contacted Professor Ripley who kindly directed us to the epilepsy data
> in Venables & Ripley section 10.4 (4th ed.). While V&B did not actually
> fit a negative binomial to these data they did refer to evidence
> of overdispersion in the response.  Fortunately Booth et al. (2003) did
> attempt to fit this model with a negative binomial which gave us something
> to which we could compare our results. Booth et al. fitted two forms of
> the model a simpler one and a more complicated model. They reported some
> difficulty fitting the more complicated  model. We found that we could
> reliably fit (MLE) both the complicated and simpler model in 20 seconds
> or less (although the more complicated turns out to be overparameterized)
>
> Using the random effects module of AD Model Builder we have developed
> a shared library (Windows dll) that can be called from R via the driver
> function glmm.admb(). The function can be downloaded from
>
> http://otter-rsch.com/admbre/examples/nbmm/nbmm.html
>
> The two models of Booth et al are fit by the commands:
>
> glmm.admb(y~Base*trt+Age+Visit,random=~1,group="subject",data=epil2)
> glmm.admb(y~Base*trt+Age+Visit,random=~Visit,group="subject",data=epil2)
>
> I will be happy to receive feedback on the function glmm.admb().
>
>
> Best regards,
>
> Hans Skaug
>
>
>
> Reference:
> Booth J.G.; Casella G.; Friedl H.; Hobert J.P, Negative binomial loglinear
> mixed models.
> Statistical Modelling, October 2003, vol. 3, no. 3, pp. 179-191
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From RML27 at cornell.edu  Mon Mar 28 01:38:37 2005
From: RML27 at cornell.edu (Ronnen Levinson)
Date: Sun, 27 Mar 2005 15:38:37 -0800
Subject: [R] Applying function to multiple input vectors
Message-ID: <424743FD.5080009@cornell.edu>


   Hi.
   Say I have a function f with two inputs, x and y

     f <- function(x,y) {something}

   that I wish to evaluate with two input vectors of length N

     X <- c(x1, x2, ..., xN)
     Y <- c(y1, y2, ..., yN)

   to  obtain  the  length-N  output  vector  c( f(x1,y1), f(x2,y2), ...,
   f(xN,yN) ).
   Is there a method analogous to sapply() for this operation?
   Yours truly,
   Ronnen.
   P.S. E-mailed CCs of posted replies appreciated.


From h.wickham at gmail.com  Mon Mar 28 02:44:55 2005
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 27 Mar 2005 18:44:55 -0600
Subject: [R] Applying function to multiple input vectors
In-Reply-To: <424743FD.5080009@cornell.edu>
References: <424743FD.5080009@cornell.edu>
Message-ID: <f8e6ff0505032716443a389879@mail.gmail.com>

>    Is there a method analogous to sapply() for this operation?

Check out mapply.

Hadley



From cuteymei at yahoo.com.tw  Mon Mar 28 04:09:19 2005
From: cuteymei at yahoo.com.tw (=?big5?q?=AC=FC=B5=E2=20=B6=C0?=)
Date: Mon, 28 Mar 2005 10:09:19 +0800 (CST)
Subject: [R] Where can I found the package "ordinal" ?
In-Reply-To: 6667
Message-ID: <20050328020919.88342.qmail@web18102.mail.tpe.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050328/cd1c206a/attachment.pl

From andrew_g_peterson at yahoo.com  Mon Mar 28 04:59:13 2005
From: andrew_g_peterson at yahoo.com (Andrew Peterson)
Date: Sun, 27 Mar 2005 18:59:13 -0800 (PST)
Subject: [R] Can I use a variable to pass a file name to scan() ?
Message-ID: <20050328025913.88421.qmail@web53506.mail.yahoo.com>

Hi, can anyone please tell me if it is possible to use
a variable to pass a file name to scan()?

I am trying to write a program that loops through a
series of text files. I use list.files() to create a
character vector of file names. Then I would like to
take  one string at a time from the character vector
and use that string to specify the name of the text
file I want to open using scan().

I have used constructs such as

x <- list.files()

y <- scan(file = x[1])

but I always get the following error message:

Error in scan(file = x[1]) : "scan" expected a real,
got "<CLOSE>"

I've read all the documentation at least a couple of
times and have searched this list to no avail. Any
help would be greatly appreciated!

Thanks,

Andrew.



From spencer.graves at pdf.com  Mon Mar 28 05:35:49 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 27 Mar 2005 21:35:49 -0600
Subject: [R] Can I use a variable to pass a file name to scan() ?
In-Reply-To: <20050328025913.88421.qmail@web53506.mail.yahoo.com>
References: <20050328025913.88421.qmail@web53506.mail.yahoo.com>
Message-ID: <42477B95.7060209@pdf.com>

      What operating system and which version of R? 

      I got a similar error message under R 2.0.1 under Windows 2000: 

 > y <- scan(file = x[1])
Error in scan(file = x[1]) : "scan" expected a real, got "?????"

      Part of the function definition for "scan" is 'scan(file = "", 
what = double(0), ...'.  This means that by default, "scan" was 
expecting double precision numbers.  When it found an unrecognizable 
binary, it complained.  Using 'what="raw"' produced something: 

 > y <- scan(file = x[1], what="raw")
Read 1 items

      The file x[1] was an MS Word *.wbk file, and scan was only able to 
read a portion of the header using "raw". 

      Have you considered "try"? 

 > y <- try(scan(file=x[1]))
Error in scan(file = x[1]) : "scan" expected a real, got "?????"
 > y
[1] "Error in scan(file = x[1]) : \"scan\" expected a real, got 
\"??\021??\261\"\n" 
attr(,"class")
[1] "try-error"

       What are you trying to do?  The following worked for me just now? 

 > write(pi, "pi.txt")
 > scan('pi.txt')
Read 1 items
[1] 3.141593
 > all.equal(scan('pi.txt'), pi)
Read 1 items
[1] "Mean relative  difference: 1.102658e-07"

      hope this helps.  spencer graves

Andrew Peterson wrote:

>Hi, can anyone please tell me if it is possible to use
>a variable to pass a file name to scan()?
>
>I am trying to write a program that loops through a
>series of text files. I use list.files() to create a
>character vector of file names. Then I would like to
>take  one string at a time from the character vector
>and use that string to specify the name of the text
>file I want to open using scan().
>
>I have used constructs such as
>
>x <- list.files()
>
>y <- scan(file = x[1])
>
>but I always get the following error message:
>
>Error in scan(file = x[1]) : "scan" expected a real,
>got "<CLOSE>"
>
>I've read all the documentation at least a couple of
>times and have searched this list to no avail. Any
>help would be greatly appreciated!
>
>Thanks,
>
>Andrew.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From ramasamy at cancer.org.uk  Mon Mar 28 12:04:35 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 28 Mar 2005 11:04:35 +0100
Subject: [R] Applying function to multiple input vectors
In-Reply-To: <424743FD.5080009@cornell.edu>
References: <424743FD.5080009@cornell.edu>
Message-ID: <1112004275.30399.10.camel@dhcp-63.ccc.ox.ac.uk>

set.seed(1)
xx <- sample( 1:10 )
xx
 [1]  3  4  5  7  2  8  9  6 10  1

yy <- sample( 1:10 )
yy
 [1]  3  2  6 10  5  7  8  4  1  9

(xx + yy)^2
 [1]  36  36 121 289  49 225 289 100 121 100

myfun <- function(x, y) ( x + y )^2
mapply( myfun, xx, yy )
 [1]  36  36 121 289  49 225 289 100 121 100

diag( outer( xx, yy, FUN=myfun) )
 [1]  36  36 121 289  49 225 289 100 121 100

Regards, Adai



On Sun, 2005-03-27 at 15:38 -0800, Ronnen Levinson wrote:
>    Hi.
>    Say I have a function f with two inputs, x and y
> 
>      f <- function(x,y) {something}
> 
>    that I wish to evaluate with two input vectors of length N
> 
>      X <- c(x1, x2, ..., xN)
>      Y <- c(y1, y2, ..., yN)
> 
>    to  obtain  the  length-N  output  vector  c( f(x1,y1), f(x2,y2), ...,
>    f(xN,yN) ).
>    Is there a method analogous to sapply() for this operation?
>    Yours truly,
>    Ronnen.
>    P.S. E-mailed CCs of posted replies appreciated.
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Mon Mar 28 12:11:18 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 28 Mar 2005 12:11:18 +0200
Subject: [R] Where can I found the package "ordinal" ?
In-Reply-To: <20050328020919.88342.qmail@web18102.mail.tpe.yahoo.com>
References: <20050328020919.88342.qmail@web18102.mail.tpe.yahoo.com>
Message-ID: <4247D846.7000503@statistik.uni-dortmund.de>

?? ? wrote:
> Thanks for your apply.
>  
> I have tried the link:  http://fdg-popgen146.unimaas.nl/~plindsey/rlibs.html
> 
> but it show that :
>  
> Access forbidden!
> 
>    You don't have permission to access the requested object. It is either read-protected or not readable by the server. 
>    If you think this is a server error, please contact the webmaster Error 403
>    fdg-popgen146.unimaas.nl 
> Mon 28 Mar 2005 03:49:49 AM CEST 
> Apache/2.0.40 (Red Hat Linux) 
>   That seem like I need some permission to download it?
>  
>   Where can I ask for the permission?


What about asking the package maintainer? Nobody else on this list can help.

Uwe Ligges



>   Thank you again. 
> 
> 
> Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote: ?? ? writes:
> 
> 
>>Hello,dear all: 
>>
>>
>>I want to install the package "ordinal",but I don't see the package listed under package sources.
>>
>>I try to search it by "google",then I found this:
>>
>>http://euridice.tue.nl/~plindsey/rlibs.html 
>>
>>but the connect does not work.
>>
>>Where can I found the package "ordinal" ? Is it still available? 
> 
> 
> Try
> 
> http://fdg-popgen146.unimaas.nl/~plindsey/rlibs.html
> 
> (I really don't know why I should even take the time Googling for Jim
> & Pat's current whereabouts. They clearly do not believe in neither
> version control, CRAN, nor in following standard terminology.)
>



From ligges at statistik.uni-dortmund.de  Mon Mar 28 12:16:29 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 28 Mar 2005 12:16:29 +0200
Subject: [R] Can I use a variable to pass a file name to scan() ?
In-Reply-To: <20050328025913.88421.qmail@web53506.mail.yahoo.com>
References: <20050328025913.88421.qmail@web53506.mail.yahoo.com>
Message-ID: <4247D97D.1040308@statistik.uni-dortmund.de>

Andrew Peterson wrote:

> Hi, can anyone please tell me if it is possible to use
> a variable to pass a file name to scan()?

Yes.

> I am trying to write a program that loops through a
> series of text files. I use list.files() to create a
> character vector of file names. Then I would like to
> take  one string at a time from the character vector
> and use that string to specify the name of the text
> file I want to open using scan().
> 
> I have used constructs such as
> 
> x <- list.files()
> 
> y <- scan(file = x[1])
> 
> but I always get the following error message:
> 
> Error in scan(file = x[1]) : "scan" expected a real,
> got "<CLOSE>"

Right, the file named in x[1] is a text file that starts with "<CLOSE>" 
which is not a number (and scan expects a number, by default), hence 
scan complains.

Use
    y <- scan(file = x[1], what="character")
and you will see that it works.

Uwe Ligges


> I've read all the documentation at least a couple of
> times and have searched this list to no avail. Any
> help would be greatly appreciated!
> 
> Thanks,
> 
> Andrew.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From s0454869 at sms.ed.ac.uk  Mon Mar 28 13:06:25 2005
From: s0454869 at sms.ed.ac.uk (JEB Halliday)
Date: Mon, 28 Mar 2005 12:06:25 +0100
Subject: [R] glmmPQL questions
Message-ID: <1112007985.4247e531657c5@sms.ed.ac.uk>


I am looking a risk factors for disease in cattle and am interested in modelling
farm and sampling cluster as random effects (My outcome is positive or negative
at the level of the farm).  I am using R version 2.0.1 on a Mac and have
identified glmmPQL as hopefully the correct function to use. I have run a
couple of models using this but was hoping that you might be able to answer a
few questions.

e.g. model<-glmmPQL(farmstatus~cattlenumber,random~1|farm,binomial)

I am pretty new to both R and stats so if these questions are very simple and I
am just missing something, suggestions about good texts on GLMM in R would be
great.

First up, what is the best way to constrain the model to only look at certain
levels of a multi-level factor e.g. a categorisation of cattle number where all
points of high influence

(as determined using: summary(influence.measures(model)) )

are confined to the largest class (D) and I want to run the model which just
looks at levels A,B and C? (or only months May-September..)

I was also wondering about the best way to force specified variables to remain
in the model when running e.g. stepwise selection of interaction terms?

Finally, is there is a recognised method for dealing with missing values in
these models?
and as a minor point the models do not run unless i specify the data= part of
the syntax and as this is apparently an optional piece of information I was
wondering why this is required when all of my variables are in the same data
frame (and even when this data frame is attached?)

Any help would be greatly appreciated

Jo Halliday
MSc student
University of Edinburgh
s0454869 at sms.ed.ac.uk



From roger.bos at gmail.com  Mon Mar 28 15:19:27 2005
From: roger.bos at gmail.com (roger bos)
Date: Mon, 28 Mar 2005 08:19:27 -0500
Subject: [R] RE: Gmail invitation
In-Reply-To: <4245A37F.50403@acelerate.com>
References: <7FFEE688B57D7346BC6241C55900E730B70008@pollux.bfro.uni-lj.si>
	<1abe3fa9050326064169e4cefd@mail.gmail.com>
	<4245A37F.50403@acelerate.com>
Message-ID: <1db7268005032805193439cb6@mail.gmail.com>

I have 50 too, aparently you can't give these things away today.

Thanks,

Roger


On Sat, 26 Mar 2005 14:01:35 -0400, Kjetil Brinchmann Halvorsen
<kjetil at acelerate.com> wrote:
> What is this stuff about' gmail invitation'?
> 
> Kjetil
> 
> 
> A.J. Rossini wrote:
> 
> >Heck, if anyone cares, I've got 50 or so.  Just drop an email.  It's
> >not a bad service.
> >
> >
> >On Sat, 26 Mar 2005 15:19:04 +0100, Gorjanc Gregor
> ><Gregor.Gorjanc at bfro.uni-lj.si> wrote:
> >
> >
> >>I still have 40 invitations! Do not hesitate ;)
> >>
> >>This is last remainder on r-help.
> >>
> >>--
> >>Lep pozdrav / With regards,
> >>    Gregor Gorjanc
> >>
> >>------------------------------------------------------------------------
> >>University of Ljubljana
> >>Biotechnical Faculty       URI: http://www.bfro.uni-lj.si/MR/ggorjan
> >>Zootechnical Department    email: gregor.gorjanc <at> bfro.uni-lj.si
> >>Groblje 3                  tel: +386 (0)1 72 17 861
> >>SI-1230 Domzale            fax: +386 (0)1 72 17 888
> >>Slovenia
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >>
> >>
> >>
> >
> >
> >
> >
> 
> --
> 
> Kjetil Halvorsen.
> 
> Peace is the most effective weapon of mass construction.
>               --  Mahdi Elmandjra
> 
> --
> No virus found in this outgoing message.
> Checked by AVG Anti-Virus.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From giljustino at yahoo.com.br  Mon Mar 28 17:56:10 2005
From: giljustino at yahoo.com.br (Gilvan Justino)
Date: Mon, 28 Mar 2005 12:56:10 -0300 (ART)
Subject: [R] Is there a diferent way to do this?
In-Reply-To: 6667
Message-ID: <20050328155610.34244.qmail@web50410.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050328/ab2ab5f8/attachment.pl

From davidr at rhotrading.com  Mon Mar 28 18:13:55 2005
From: davidr at rhotrading.com (davidr@rhotrading.com)
Date: Mon, 28 Mar 2005 10:13:55 -0600
Subject: [R] Bloomberg data import
Message-ID: <12AE52872B5C5348BE5CF47C707FF53A502A78@rhosvr02.rhotrading.com>

Pasad,
I think GetHistoricalData might work for tick data. (At least it does
from VB and VBA.)
HTH,
David L. Reiner

p.s. Static data was mentioned, and that you get with Subscribe.

-----Original Message-----
From: Chalasani, Prasad [mailto:prasad.chalasani at gs.com] 
Sent: Thursday, March 24, 2005 3:10 PM
To: r-help at stat.math.ethz.ch
Subject: RE: [R] Bloomberg data import

Dirk,

the URL for the working binary of RDCOMClient is at the bottom this
page:
http://tolstoy.newcastle.edu.au/R/help/04/11/6759.html

it works with my R 2001.


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Dirk Eddelbuettel
Sent: Thursday, March 24, 2005 3:00 PM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] Bloomberg data import



Prasad,

Chalasani, Prasad <prasad.chalasani <at> gs.com> writes:
> I found that with Enrique's approach it's extremely easy to bang 
> together
> R code to grab historical *daily* data from Bloomberg.
> However when I tried to extend it to to grab Tick/Intraday data, 
> it didn't work. I did look at the Bloomberg ActiveX documentation on 
> my Bloomberg screen, and thought I followed their instructions, 
> e.g I do ( with slight modification of  Enrique's framework ):
> 
> dat <- '2005-03-22'
> from.t <- '10:00:00'
> to.t <- '11:00:00'
> # convert date + time to COM format.
> comFrom <- as.comDate.Date(as.Date(dat), from.t)
> comTo <- as.comDate.Date(as.Date(dat), to.t)
> histData <- try(blCon$BLPGetHistoricalData(Security='IBM US Equity', 
> Fields="Last_Price",
>                         StartDate=comFrom, EndDate=comTo, BarSize=0));
> 
> The documentation says that I can get tick data by simply setting 
> BarSize to 0, and using the appropriate field name -- I tried 
> Last_Price, LAST_TRADE, etc but to no avail -- I keep getting some 
> kind of exception.
> 
> If someone has any hints as to how to get Tick/Intraday data, that 
> would be nice.

I don't use ActiveX, so take this with a grain of salt. 

Based on the names of functions in the older C interface, I would
conjecture
that the BLPGetHistoricalData() function does not return intra-daily
data.
So you may need to find different functions for the intraday data and
for
the 
static data you were seeking as well. May be worth a try -- report back
here
or on R-SIG-Finance if you succeed.  In any event, whatever you want to
put
together for R via (D)COM has to first work in plain VB, no?

Do you have a current URL for the (D)COM code?  I haven't found it ever
since they had to take their server down after it got attacked.

Cheers, Dirk

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Mon Mar 28 18:19:10 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 28 Mar 2005 18:19:10 +0200
Subject: [R] Is there a diferent way to do this?
In-Reply-To: <20050328155610.34244.qmail@web50410.mail.yahoo.com>
References: <20050328155610.34244.qmail@web50410.mail.yahoo.com>
Message-ID: <42482E7E.3090106@statistik.uni-dortmund.de>

Gilvan Justino wrote:

> Hi,
>  
> Thanks for your reply.
>  
> I found a sample at http://www.angelfire.com/tx4/cus/shapes/r.html
>  
> I did the same with my class and now it is working
> ###
>  setGeneric("setName<-",
>             function(this, value)
>             standardGeneric("setName<-")
>             )
>  setReplaceMethod("setName", "Partri",
>            function(this, value)
>            {
>              this at name <- value
>              this
>            }
>            )
> ##
> I have other doubts:
> a) The usual representation of a method calling in other languages (I mean, Java, Delphi) is:
>    obj.method(<parameters>)

In S4 it is simple generic(object), the generic chooses the right method 
along the class of object.


> So, I believed that in R it was the same thing. Thats it, to call the method setName of my instance "x" I could write:
>    x.setName("blablabla")

Replacement methods are somehow special.
For the "regular" case, you say generic(object, otherArg1, otherArg2, 
......)

For a replacement method, you can also say
   "generic<-"(object, otherArg1, otherARg2, ...)

but for convenience and intuition, you can say

generic(object) <- otherArg1



> The right way really is? 
>      method(instance) <- parameters
> Thats it:
>      setName(x) <- "blablabla" ?

Yes, but as I already mentioned, replacement methods are somehow special.


> It sounds strange to me. Maybe because I used with other languages, but it doen?t seem legible to me this sintaxe.
>  
> b) I realised I have to use the name "value" as the parameter name, what else it won?t work. Is that corret?
>  
> c) and in the case I have two or more parameters. How should I do?

You don't want to do replacements in that way, do you?


> I typed ?setReplaceMethod in RGui how you suggested, but it doesn?t bring any information about this instruction.

I assumed (since your questions was quite complex) you are much more 
familar with R, sorry for causing confusion. I think the best way is to 
start reading some docs, not only about S4, but also about S3 classes, 
so you will see why things have been developed this way.

Uwe Ligges


> Thanks again and sorry for my english mistakes.
> Gilvan Justino
> 
> Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:
> Gilvan Justino wrote:
> 
>>Hi,
>>
>>I started creating a small class but I'm courious about how it is working.
>>
>>To create a instance of my class "Partri" I write this at Rgui:
>>x <- new("Partri", name="Gilvan")
>>
>>and to change the slot "name" of this instance, I write:
>>setName(x, newname="Justino")
>>
>>It is not working, because when I type "x" at Rgui, it shows the initial value, which was "Gilvan". What I am doing wrong?
>>
>>I'll appreciate any king of help!
>>Gilvan
>>
>>
>># Classe para representar um par?metro
>>setClass("Partri",
>># par?metros
>>representation( name="character"),
>># se??o de inicializa??o
>>prototype( name="undefined name" )
>>)
>>
>>setGeneric("setName",
>>function(object, newname,...)
>>standardGeneric("setName"))
>>setMethod("setName", 
>>signature(object="Partri",newname="character"), 
>>function(object, newname)
>>{
>>object at name = newname
> 
> 
> 
> You set the "name" in the environment of the method, but you don't 
> assign it to the environment that you seem to expect erroneously. To see 
> that it works, simply insert
> 
> print(object at name)
> 
> Instead, you want to write some non-standard replacement function. See 
> ?setReplaceMethod and friends (you might want to take a look into the 
> green book as well).
> 
> Uwe Ligges
> 
> 
> 
> 
> 
>>}
>>)
> 
> 
> 
> 
> 
>>
>>---------------------------------
>>
>>ora!
>>[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 
> 
> __________________________________________________
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From qiana at biostat.umn.edu  Mon Mar 28 18:31:40 2005
From: qiana at biostat.umn.edu (qiana@biostat.umn.edu)
Date: Mon, 28 Mar 2005 10:31:40 -0600
Subject: [R] A question regarding stratified bootstrap
Message-ID: <1112027500.4248316cc9cb6@webmail.ccbr.umn.edu>

Dear experts,
I am asking for help with a question regarding to stratified bootstrap. How
shall I implement my stratified bootstrap in boot() using boot package in R?

My dataset is a longitudinal dataset (3 measurements per person at year
1, 4 and 7) composed of multiple clinic centers and multiple participants
within each clinic. It has missing values.

I want to do a bootstrap to find the standard errors and confidence
intervals for my variance components. My model is a mixed model with
random clinic and random participant within clinic.

I thought two methods to do bootstrap:
(1) bootstrap data; however, I have problem specifying the second
parameter for my statistic function, shall I use indices, weight or
frequency and how shall I relate to my dataset.
(2) bootstrap residuals; however, the dataset has multiple measurements
and missing values. I am wondering how to construct a new data frame
containing the residuals and fitted values.

Your help will be highly appreciated!
Sincerely yours,
Qian



From fredrik.bg.lundgren at bredband.net  Mon Mar 28 19:37:37 2005
From: fredrik.bg.lundgren at bredband.net (Fredrik Lundgren)
Date: Mon, 28 Mar 2005 19:37:37 +0200
Subject: [R] gnuclient problems witrh R/ESS in linux
Message-ID: <000b01c533bc$d60afe00$149d72d5@Larissa>

Dear list,

Not strictly R ...

In R on Xemacs with ESS (R-2.0.1, Xemacs-21.4.15-r3, ESS-5.2.6)
on gentoo-linux

when I use k<-edit(k) or fix(k)
to change a small vector k <- c(1,2,3,4,5,6)

the opened window (called '6b8b4567') appears not to be connected to the
gnuclient
and I'm able to edit the file but has no instructions in the
minibuffer
and
C-x # gives
'6b8b4567 does not belong to gnuserv client'

in init.el I have
(require 'gnuserv)
(gnuserv-start)
(setq gnuserv-frame (selected-frame))

Any help please?

Fredrik



From mvida at mitre.org  Mon Mar 28 19:39:29 2005
From: mvida at mitre.org (Melanie Vida)
Date: Mon, 28 Mar 2005 12:39:29 -0500
Subject: [R] Model Selection and Data
Message-ID: <42484151.3090206@mitre.org>

Hi All,
   Are there times when random forests should not be used as a 
classification or regression model for determining variable importance. 
If so, then is it the properties of the training data that causes the 
issue? Are there other classification and regression models better 
suited for particular data sets? If so, what are the properties for the 
data set causing one to choose one model rather than another?
Thanks in advance,
-Melanie



From hb at maths.lth.se  Mon Mar 28 19:50:46 2005
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Mon, 28 Mar 2005 19:50:46 +0200
Subject: [R] RE: Gmail invitation
In-Reply-To: <1db7268005032805193439cb6@mail.gmail.com>
Message-ID: <000201c533be$adcc7e30$ccc52ac0@hblaptop>

To avoid future gmail invitations from individuals, here is what you find by
googling "gmail free invitations";

  http://isnoop.net/gmail/

 "This page offers a place for people with Gmail invites and those who want
them to come together with minimal effort and fuss. [...] 602,497 invites
available to share."

Henrik

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of roger bos
> Sent: Monday, March 28, 2005 3:19 PM
> To: Kjetil Brinchmann Halvorsen
> Cc: r-help at stat.math.ethz.ch; Gorjanc Gregor
> Subject: Re: [R] RE: Gmail invitation
> 
> 
> I have 50 too, aparently you can't give these things away today.
> 
> Thanks,
> 
> Roger
> 
> 
> On Sat, 26 Mar 2005 14:01:35 -0400, Kjetil Brinchmann 
> Halvorsen <kjetil at acelerate.com> wrote:
> > What is this stuff about' gmail invitation'?
> > 
> > Kjetil
> > 
> > 
> > A.J. Rossini wrote:
> > 
> > >Heck, if anyone cares, I've got 50 or so.  Just drop an 
> email.  It's 
> > >not a bad service.
> > >
> > >
> > >On Sat, 26 Mar 2005 15:19:04 +0100, Gorjanc Gregor 
> > ><Gregor.Gorjanc at bfro.uni-lj.si> wrote:
> > >
> > >
> > >>I still have 40 invitations! Do not hesitate ;)
> > >>
> > >>This is last remainder on r-help.
> > >>
> > >>--
> > >>Lep pozdrav / With regards,
> > >>    Gregor Gorjanc
> > >>
> > 
> >>--------------------------------------------------------------------
> > >>----
> > >>University of Ljubljana
> > >>Biotechnical Faculty       URI: 
> http://www.bfro.uni-lj.si/MR/ggorjan
> > >>Zootechnical Department    email: gregor.gorjanc <at> 
> bfro.uni-lj.si
> > >>Groblje 3                  tel: +386 (0)1 72 17 861
> > >>SI-1230 Domzale            fax: +386 (0)1 72 17 888
> > >>Slovenia
> > >>
> > >>______________________________________________
> > >>R-help at stat.math.ethz.ch mailing list 
> > >>https://stat.ethz.ch/mailman/listinfo/r-help
> > >>PLEASE do read the posting guide! 
> > >>http://www.R-project.org/posting-guide.html
> > >>
> > >>
> > >>
> > >
> > >
> > >
> > >
> > 
> > --
> > 
> > Kjetil Halvorsen.
> > 
> > Peace is the most effective weapon of mass construction.
> >               --  Mahdi Elmandjra
> > 
> > --
> > No virus found in this outgoing message.
> > Checked by AVG Anti-Virus.
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From drew.balazs at gmail.com  Mon Mar 28 20:32:19 2005
From: drew.balazs at gmail.com (Drew Balazs)
Date: Mon, 28 Mar 2005 12:32:19 -0600
Subject: [R] RODBC and OS X
Message-ID: <6a2c704c050328103222ab1edd@mail.gmail.com>

All,

I'm having a problem connecting to an MS SQL Database via RODBC on OS
X. If I try to connect through the GUI using  chan <-
odbcConnect("drewdb", uid="user", pwd ="pwd") it simply crashes R with
the following crash report:

Date/Time:      2005-03-28 12:30:48 -0600
OS Version:     10.3.8 (Build 7U16)
Report Version: 2

Command: R
Path:    /Applications/R.app/Contents/MacOS/R
Version: 1.01 (1.01)
PID:     507
Thread:  0

Exception:  EXC_BAD_ACCESS (0x0001)
Codes:      KERN_PROTECTION_FAILURE (0x0002) at 0x000001fc


However, if I try it through an xterm (command line), I get the following:

Warning messages: 
1: [RODBC] ERROR: state IM004, code 0, message [iODBC][Driver
Manager]Driver's SQLAllocEnv() failed
2: ODBC connection failed in: odbcDriverConnect(st, case = case,
believeNRows = believeNRows)

I'm reasonably sure the DSN is okay because I can use it to connect to
the DB with other applications.
Any suggestions?

-Drew


Specific Info:
  Machine Model:	PowerBook5,6
  CPU Type:	PowerPC G4  (1.2)
  Number Of CPUs:	1
  CPU Speed:	1.67 GHz
  L2 Cache (per CPU):	512 KB
  Memory:	2 GB
  Bus Speed:	167 MHz
  System Version:	Mac OS X 10.3.8 (7U16)
  Kernel Version:	Darwin 7.8.0
  Boot Volume:	Macintosh HD

R : Copyright 2004, The R Foundation for Statistical Computing
Version 2.0.1  (2004-11-15), ISBN 3-900051-07-0



From pbruce at statistics.com  Mon Mar 28 21:29:01 2005
From: pbruce at statistics.com (Peter C. Bruce)
Date: Mon, 28 Mar 2005 14:29:01 -0500
Subject: [R] online course:  Modeling in R
Message-ID: <6.1.0.6.2.20050328142847.046120e0@mail.statistics.com>

Online short course: Modeling in R

Dr. Phillip Good will offer the short course "Modeling in R" online at 
statistics.com April 8-29, 2005.

This 3-week course will show you how to use R to create models for use in 
classification and prediction. You will be introduced to advanced graphing 
methods as needed. Modeling techniques include OLS, LAD, and EIV 
regression, quantile regression, and decision trees.

Dr. Phillip Good is the author of Introduction to Statistics via Resampling 
Methods and R (Wiley, 2005), Common Errors in Statistics (and How to Avoid 
Them) (Wiley, 2003 with James Hardin), plus a number of other books in 
statistics. He has given tutorials at the Joint Statistical Meetings (U.S.) 
and Deming Conference, lectured in Belgium, France, Holland, Ireland, and 
Spain, and was a traveling lecturer for the American Statistical Association.

The course lasts three weeks and consists of a series of three lessons 
(assigned readings and/or notes, plus exercises).  Direct interaction (Q&A) 
with the instructor throughout the three week period takes place via a 
private discussion board.  Expect to spend about 10 hours per week 
(participants earn 1.5 CEU's); there are no set hours when you must be online.

Details and registration:

http://www.statistics.com/content/courses/modelingR/index.html

Peter Bruce
pbruce at statistics.com



From bennfine at yahoo.com  Mon Mar 28 22:06:33 2005
From: bennfine at yahoo.com (Benn Fine)
Date: Mon, 28 Mar 2005 12:06:33 -0800 (PST)
Subject: [R] mixed model question
Message-ID: <20050328200633.77880.qmail@web61302.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050328/b81e1db7/attachment.pl

From r_xprt_wannabe at yahoo.com  Mon Mar 28 22:40:33 2005
From: r_xprt_wannabe at yahoo.com (R_xprt_wannabe)
Date: Mon, 28 Mar 2005 12:40:33 -0800 (PST)
Subject: [R] Reading data from "clipboard"
Message-ID: <20050328204033.55740.qmail@web31304.mail.mud.yahoo.com>

Dear List,

As a way to learn R, I am trying out some of the
examples shown in the Reference Cards.

I use the following to read a column of numbers from
Excel:

x <- read.delim("clipboard")

My questions are:

1. Why is it that the first number is omitted from the
selected data range?  How do I tell R to pick up the
first number as part of the entire selection?

2. The next thing I want to do once my data are read
in the way described above is

y <- ppoints(sort(x))

but I get the following:

Error in sort(x): 'x' must be atomic

What does 'atomic' mean in this context?  How do I
make 'x' atomic?

3. While I understand there are other ways to
accomplish the same thing, I seem to recall there is a
way to invoke within R a spreadsheet-like window for
data input, but I can't seem to locate the command for
the life of me.

Any help is appreciated.



From andy_liaw at merck.com  Mon Mar 28 22:53:45 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 28 Mar 2005 15:53:45 -0500
Subject: [R] Reading data from "clipboard"
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076CF5@usctmx1106.merck.com>

> From: R_xprt_wannabe
> 
> Dear List,
> 
> As a way to learn R, I am trying out some of the
> examples shown in the Reference Cards.
> 
> I use the following to read a column of numbers from
> Excel:
> 
> x <- read.delim("clipboard")
> 
> My questions are:
> 
> 1. Why is it that the first number is omitted from the
> selected data range?  How do I tell R to pick up the
> first number as part of the entire selection?

It's probably because read.delim() has the argument `header' that is TRUE by
default, so unless you set that to FALSE, it treats the first row as column
headers.

 
> 2. The next thing I want to do once my data are read
> in the way described above is
> 
> y <- ppoints(sort(x))
> 
> but I get the following:
> 
> Error in sort(x): 'x' must be atomic
> 
> What does 'atomic' mean in this context?  How do I
> make 'x' atomic?

read.delim() outputs a data frame, which is a collection of variables.  In
your case it's probably just one variable.  You can do x <- x[[1]] to change
x into the first column of the data frame.

If you only have one column of data, scan() would be a better choice than
read.delim() (and friends).
 
> 3. While I understand there are other ways to
> accomplish the same thing, I seem to recall there is a
> way to invoke within R a spreadsheet-like window for
> data input, but I can't seem to locate the command for
> the life of me.

You're probably looking for data.entry().

Andy
 
> Any help is appreciated.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From gerifalte28 at hotmail.com  Mon Mar 28 23:18:55 2005
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Mon, 28 Mar 2005 21:18:55 +0000
Subject: [R] RE: Gmail invitation
In-Reply-To: <000201c533be$adcc7e30$ccc52ac0@hblaptop>
Message-ID: <BAY103-F31DEF39FAB0D3C0B548255A6440@phx.gbl>

FYI revise this page for some privacy concerns about gmail 
http://www.google-watch.org/gmail.html
Personally I do not think this is a big deal so I do have a gmail account 
and I use it.  You might want to consider better free services with same 
storage capacity like gmx mail (www.gmx.net). The downside of GMX is that 
you need to know some basic German to get started.  In the long run it works 
better than gmail though.  Anyway, enough gmail and more R related posting 
guys! ;)

Cheers

Francisco


>From: "Henrik Bengtsson" <hb at maths.lth.se>
>To: "'roger bos'" <roger.bos at gmail.com>,        "'Kjetil Brinchmann 
>Halvorsen'" <kjetil at acelerate.com>
>CC: r-help at stat.math.ethz.ch,        "'Gorjanc Gregor'" 
><Gregor.Gorjanc at bfro.uni-lj.si>
>Subject: RE: [R] RE: Gmail invitation
>Date: Mon, 28 Mar 2005 19:50:46 +0200
>
>To avoid future gmail invitations from individuals, here is what you find 
>by
>googling "gmail free invitations";
>
>   http://isnoop.net/gmail/
>
>  "This page offers a place for people with Gmail invites and those who 
>want
>them to come together with minimal effort and fuss. [...] 602,497 invites
>available to share."
>
>Henrik
>
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of roger bos
> > Sent: Monday, March 28, 2005 3:19 PM
> > To: Kjetil Brinchmann Halvorsen
> > Cc: r-help at stat.math.ethz.ch; Gorjanc Gregor
> > Subject: Re: [R] RE: Gmail invitation
> >
> >
> > I have 50 too, aparently you can't give these things away today.
> >
> > Thanks,
> >
> > Roger
> >
> >
> > On Sat, 26 Mar 2005 14:01:35 -0400, Kjetil Brinchmann
> > Halvorsen <kjetil at acelerate.com> wrote:
> > > What is this stuff about' gmail invitation'?
> > >
> > > Kjetil
> > >
> > >
> > > A.J. Rossini wrote:
> > >
> > > >Heck, if anyone cares, I've got 50 or so.  Just drop an
> > email.  It's
> > > >not a bad service.
> > > >
> > > >
> > > >On Sat, 26 Mar 2005 15:19:04 +0100, Gorjanc Gregor
> > > ><Gregor.Gorjanc at bfro.uni-lj.si> wrote:
> > > >
> > > >
> > > >>I still have 40 invitations! Do not hesitate ;)
> > > >>
> > > >>This is last remainder on r-help.
> > > >>
> > > >>--
> > > >>Lep pozdrav / With regards,
> > > >>    Gregor Gorjanc
> > > >>
> > >
> > >>--------------------------------------------------------------------
> > > >>----
> > > >>University of Ljubljana
> > > >>Biotechnical Faculty       URI:
> > http://www.bfro.uni-lj.si/MR/ggorjan
> > > >>Zootechnical Department    email: gregor.gorjanc <at>
> > bfro.uni-lj.si
> > > >>Groblje 3                  tel: +386 (0)1 72 17 861
> > > >>SI-1230 Domzale            fax: +386 (0)1 72 17 888
> > > >>Slovenia
> > > >>
> > > >>______________________________________________
> > > >>R-help at stat.math.ethz.ch mailing list
> > > >>https://stat.ethz.ch/mailman/listinfo/r-help
> > > >>PLEASE do read the posting guide!
> > > >>http://www.R-project.org/posting-guide.html
> > > >>
> > > >>
> > > >>
> > > >
> > > >
> > > >
> > > >
> > >
> > > --
> > >
> > > Kjetil Halvorsen.
> > >
> > > Peace is the most effective weapon of mass construction.
> > >               --  Mahdi Elmandjra
> > >
> > > --
> > > No virus found in this outgoing message.
> > > Checked by AVG Anti-Virus.
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> > >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> >
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From gerifalte28 at hotmail.com  Mon Mar 28 23:42:58 2005
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Mon, 28 Mar 2005 21:42:58 +0000
Subject: [R] Reading data from "clipboard"
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076CF5@usctmx1106.merck.com>
Message-ID: <BAY103-F176B33AD24F10ACDB24435A6440@phx.gbl>



>From: "Liaw, Andy" <andy_liaw at merck.com>
>To: "'R_xprt_wannabe'" <r_xprt_wannabe at yahoo.com>, r-help at stat.math.ethz.ch
>Subject: RE: [R] Reading data from "clipboard"
>Date: Mon, 28 Mar 2005 15:53:45 -0500
>
> > From: R_xprt_wannabe
> >
> > Dear List,
> >
> > As a way to learn R, I am trying out some of the
> > examples shown in the Reference Cards.
> >
> > I use the following to read a column of numbers from
> > Excel:
> >
> > x <- read.delim("clipboard")
> >
> > My questions are:
> >
> > 1. Why is it that the first number is omitted from the
> > selected data range?  How do I tell R to pick up the
> > first number as part of the entire selection?
>
>It's probably because read.delim() has the argument `header' that is TRUE 
>by
>default, so unless you set that to FALSE, it treats the first row as column
>headers.
>
>
> > 2. The next thing I want to do once my data are read
> > in the way described above is
> >
> > y <- ppoints(sort(x))
> >
> > but I get the following:
> >
> > Error in sort(x): 'x' must be atomic
> >
> > What does 'atomic' mean in this context?  How do I
> > make 'x' atomic?
>
>read.delim() outputs a data frame, which is a collection of variables.  In
>your case it's probably just one variable.  You can do x <- x[[1]] to 
>change
>x into the first column of the data frame.
>
>If you only have one column of data, scan() would be a better choice than
>read.delim() (and friends).
>
> > 3. While I understand there are other ways to
> > accomplish the same thing, I seem to recall there is a
> > way to invoke within R a spreadsheet-like window for
> > data input, but I can't seem to locate the command for
> > the life of me.
>
>You're probably looking for data.entry().

You can also access the same spreadsheet-like feature using fix() or edit(). 
  I like fix() better because it does not write the resuts of your edits 
back to the console once you make changes/add data.

Francisco


>
>Andy
>
> > Any help is appreciated.
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> >
> >
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From RML27 at cornell.edu  Tue Mar 29 01:20:46 2005
From: RML27 at cornell.edu (Ronnen Levinson)
Date: Mon, 28 Mar 2005 15:20:46 -0800
Subject: [R] Generating list of vector coordinates
Message-ID: <4248914E.2000409@cornell.edu>


   Hi.
   Can  anyone  suggest  a  simple  way  to  obtain in R a list of vector
   coordinates of the following form? The code below is Mathematica.

     In[5]:=
     Flatten[Table[{i,j,k},{i,3},{j,4},{k,5}], 2]
     Out[5]=
     {{1,1,1},{1,1,2},{1,1,3},{1,1,4},{1,1,5},{1,2,1},{1,2,2},{1,2,3},{1
     ,2,4},{1,2,

     5},{1,3,1},{1,3,2},{1,3,3},{1,3,4},{1,3,5},{1,4,1},{1,4,2},{1,4,3},
     {1,4,

     4},{1,4,5},{2,1,1},{2,1,2},{2,1,3},{2,1,4},{2,1,5},{2,2,1},{2,2,2},
     {2,2,

     3},{2,2,4},{2,2,5},{2,3,1},{2,3,2},{2,3,3},{2,3,4},{2,3,5},{2,4,1},
     {2,4,

     2},{2,4,3},{2,4,4},{2,4,5},{3,1,1},{3,1,2},{3,1,3},{3,1,4},{3,1,5},
     {3,2,

     1},{3,2,2},{3,2,3},{3,2,4},{3,2,5},{3,3,1},{3,3,2},{3,3,3},{3,3,4},
     {3,3,
         5},{3,4,1},{3,4,2},{3,4,3},{3,4,4},{3,4,5}}

   I've  been  futzing with apply(), outer(), and so on but haven't found
   an elegant solution.
   Thanks,
   Ronnen.
   P.S. E-mailed CCs of posted replies appreciated.


From cznm4 at mizzou.edu  Tue Mar 29 01:20:54 2005
From: cznm4 at mizzou.edu (Chao Zhu)
Date: Mon, 28 Mar 2005 17:20:54 -0600
Subject: [R] a cox model question
Message-ID: <001401c533ec$ca384170$0923ce80@chao>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050328/33f459df/attachment.pl

From Bill.Venables at csiro.au  Tue Mar 29 02:09:28 2005
From: Bill.Venables at csiro.au (Bill.Venables@csiro.au)
Date: Tue, 29 Mar 2005 10:09:28 +1000
Subject: [R] Generating list of vector coordinates
Message-ID: <B998A44C8986644EA8029CFE6396A9241B2F66@exqld2-bne.qld.csiro.au>

> rev(expand.grid(k = 1:5, j = 1:4, i = 1:3))
   i j k
1  1 1 1
2  1 1 2
3  1 1 3
4  1 1 4
5  1 1 5
6  1 2 1
7  1 2 2
8  1 2 3

...

55 3 3 5
56 3 4 1
57 3 4 2
58 3 4 3
59 3 4 4
60 3 4 5
> 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ronnen Levinson
Sent: Tuesday, 29 March 2005 9:21 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Generating list of vector coordinates



   Hi.
   Can  anyone  suggest  a  simple  way  to  obtain in R a list of
vector
   coordinates of the following form? The code below is Mathematica.

     In[5]:=
     Flatten[Table[{i,j,k},{i,3},{j,4},{k,5}], 2]
     Out[5]=
     {{1,1,1},{1,1,2},{1,1,3},{1,1,4},{1,1,5},{1,2,1},{1,2,2},{1,2,3},{1
     ,2,4},{1,2,

     5},{1,3,1},{1,3,2},{1,3,3},{1,3,4},{1,3,5},{1,4,1},{1,4,2},{1,4,3},
     {1,4,

     4},{1,4,5},{2,1,1},{2,1,2},{2,1,3},{2,1,4},{2,1,5},{2,2,1},{2,2,2},
     {2,2,

     3},{2,2,4},{2,2,5},{2,3,1},{2,3,2},{2,3,3},{2,3,4},{2,3,5},{2,4,1},
     {2,4,

     2},{2,4,3},{2,4,4},{2,4,5},{3,1,1},{3,1,2},{3,1,3},{3,1,4},{3,1,5},
     {3,2,

     1},{3,2,2},{3,2,3},{3,2,4},{3,2,5},{3,3,1},{3,3,2},{3,3,3},{3,3,4},
     {3,3,
         5},{3,4,1},{3,4,2},{3,4,3},{3,4,4},{3,4,5}}

   I've  been  futzing with apply(), outer(), and so on but haven't
found
   an elegant solution.
   Thanks,
   Ronnen.
   P.S. E-mailed CCs of posted replies appreciated.
______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ggrothendieck at gmail.com  Tue Mar 29 02:59:22 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 28 Mar 2005 19:59:22 -0500
Subject: [R] Generating list of vector coordinates
In-Reply-To: <4248914E.2000409@cornell.edu>
References: <4248914E.2000409@cornell.edu>
Message-ID: <971536df0503281659bae6f24@mail.gmail.com>

If the odometer order in your post is essential then 
you  could try this:

  expand.grid(1:5, 1:4, 1:3)[,3:1]

If R's reverse odometer order is ok then you could
simplify it to this:

  expand.grid(1:3, 1:4, 1:5)

On Mon, 28 Mar 2005 15:20:46 -0800, Ronnen Levinson <RML27 at cornell.edu> wrote:
> 
>   Hi.
>   Can  anyone  suggest  a  simple  way  to  obtain in R a list of vector
>   coordinates of the following form? The code below is Mathematica.
> 
>     In[5]:=
>     Flatten[Table[{i,j,k},{i,3},{j,4},{k,5}], 2]
>     Out[5]=
>     {{1,1,1},{1,1,2},{1,1,3},{1,1,4},{1,1,5},{1,2,1},{1,2,2},{1,2,3},{1
>     ,2,4},{1,2,
> 
>     5},{1,3,1},{1,3,2},{1,3,3},{1,3,4},{1,3,5},{1,4,1},{1,4,2},{1,4,3},
>     {1,4,
> 
>     4},{1,4,5},{2,1,1},{2,1,2},{2,1,3},{2,1,4},{2,1,5},{2,2,1},{2,2,2},
>     {2,2,
> 
>     3},{2,2,4},{2,2,5},{2,3,1},{2,3,2},{2,3,3},{2,3,4},{2,3,5},{2,4,1},
>     {2,4,
> 
>     2},{2,4,3},{2,4,4},{2,4,5},{3,1,1},{3,1,2},{3,1,3},{3,1,4},{3,1,5},
>     {3,2,
> 
>     1},{3,2,2},{3,2,3},{3,2,4},{3,2,5},{3,3,1},{3,3,2},{3,3,3},{3,3,4},
>     {3,3,
>         5},{3,4,1},{3,4,2},{3,4,3},{3,4,4},{3,4,5}}
> 
>   I've  been  futzing with apply(), outer(), and so on but haven't found
>   an elegant solution.
>   Thanks,
>   Ronnen.
>   P.S. E-mailed CCs of posted replies appreciated.
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From sivak1976 at yahoo.co.in  Tue Mar 29 03:15:57 2005
From: sivak1976 at yahoo.co.in (Sivakumaran Raman)
Date: Mon, 28 Mar 2005 19:15:57 -0600
Subject: [R] Aggregating data (with more than one function)
Message-ID: <4248AC4D.4080603@yahoo.co.in>

I have the data similar to the following in a data frame:
    LastName   Department  Salary
1   Johnson    IT          56000
2   James      HR          54223
3   Howe       Finance     80000
4   Jones      Finance     82000
5   Norwood    IT          67000
6   Benson     Sales       76000
7   Smith      Sales       65778
8   Baker      HR          56778
9   Dempsey    HR          78999
10  Nolan      Sales       45667
11  Garth      Finance     89777
12  Jameson    IT          56786

I want to calculate both the mean salary broken down by Department and 
also the
total amount paid out per department i.e. I want both sum(Salary) and
mean(Salary) for each Department. Right now, I am using aggregate.data.frame
twice, creating two data frames, and then combining them using data.frame.
However, this seems to be very memory and processor intensive and is 
taking a
very long time on my data set. Is there a quicker way to do this?

Thanks in advance,
Siv Raman



From andy_liaw at merck.com  Tue Mar 29 03:45:00 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 28 Mar 2005 20:45:00 -0500
Subject: [R] Aggregating data (with more than one function)
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076CF7@usctmx1106.merck.com>

Here's one possible way, using the data you supplied:

> dat <- read.table("clipboard", header=T, row=1)
> do.call("rbind",by(dat$Salary, dat$Department, function(x) c(mean=mean(x),
total=sum(x))))
            mean  total
Finance 83925.67 251777
HR      63333.33 190000
IT      59928.67 179786
Sales   62481.67 187445

If you need the department names as a variable, you can add that easily.

HTH,
Andy

> From: Sivakumaran Raman
> 
> I have the data similar to the following in a data frame:
>     LastName   Department  Salary
> 1   Johnson    IT          56000
> 2   James      HR          54223
> 3   Howe       Finance     80000
> 4   Jones      Finance     82000
> 5   Norwood    IT          67000
> 6   Benson     Sales       76000
> 7   Smith      Sales       65778
> 8   Baker      HR          56778
> 9   Dempsey    HR          78999
> 10  Nolan      Sales       45667
> 11  Garth      Finance     89777
> 12  Jameson    IT          56786
> 
> I want to calculate both the mean salary broken down by 
> Department and 
> also the
> total amount paid out per department i.e. I want both sum(Salary) and
> mean(Salary) for each Department. Right now, I am using 
> aggregate.data.frame
> twice, creating two data frames, and then combining them 
> using data.frame.
> However, this seems to be very memory and processor intensive and is 
> taking a
> very long time on my data set. Is there a quicker way to do this?
> 
> Thanks in advance,
> Siv Raman
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From MSchwartz at MedAnalytics.com  Tue Mar 29 03:56:13 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Mon, 28 Mar 2005 19:56:13 -0600
Subject: [R] Aggregating data (with more than one function)
In-Reply-To: <4248AC4D.4080603@yahoo.co.in>
References: <4248AC4D.4080603@yahoo.co.in>
Message-ID: <1112061373.5042.8.camel@horizons.localdomain>

On Mon, 2005-03-28 at 19:15 -0600, Sivakumaran Raman wrote:
> I have the data similar to the following in a data frame:
>     LastName   Department  Salary
> 1   Johnson    IT          56000
> 2   James      HR          54223
> 3   Howe       Finance     80000
> 4   Jones      Finance     82000
> 5   Norwood    IT          67000
> 6   Benson     Sales       76000
> 7   Smith      Sales       65778
> 8   Baker      HR          56778
> 9   Dempsey    HR          78999
> 10  Nolan      Sales       45667
> 11  Garth      Finance     89777
> 12  Jameson    IT          56786
> 
> I want to calculate both the mean salary broken down by Department and 
> also the
> total amount paid out per department i.e. I want both sum(Salary) and
> mean(Salary) for each Department. Right now, I am using aggregate.data.frame
> twice, creating two data frames, and then combining them using data.frame.
> However, this seems to be very memory and processor intensive and is 
> taking a
> very long time on my data set. Is there a quicker way to do this?
> 
> Thanks in advance,
> Siv Raman


Here is one approach:

Presuming that 'df' is your data frame:

# Create a function that returns both values
my.summ <- function(x)
{
  c(mean = mean(x), sum = sum(x))
}


# Now split() 'df'  by Department
df.s <- split(df$Salary, df$Department)


# Now run the summary, using sapply()
> sapply(df.s, my.summ)
     Finance  HR       IT       Sales   
mean 83925.67 63333.33 59928.67 62481.67
sum  251777   190000   179786   187445


HTH,

Marc Schwartz



From ramasamy at cancer.org.uk  Tue Mar 29 03:59:21 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 29 Mar 2005 02:59:21 +0100
Subject: [R] Aggregating data (with more than one function)
In-Reply-To: <4248AC4D.4080603@yahoo.co.in>
References: <4248AC4D.4080603@yahoo.co.in>
Message-ID: <1112061561.6432.26.camel@dhcp-63.ccc.ox.ac.uk>

In the Arguments section of help(aggregate), you will find :

     FUN: a scalar function to compute the summary statistics which can
          be applied to all data subsets.


a) So you can try the 'by' function :

> by( df[ , 3], df$Department, function(x) c(mean(x), sum(x)) )
  INDICES: Finance
  [1]  83925.67 251777.00
  ------------------------------------------------------------
  INDICES: HR
  [1]  63333.33 190000.00
  ------------------------------------------------------------
  INDICES: IT
  [1]  59928.67 179786.00
  ------------------------------------------------------------
  INDICES: Sales
  [1]  62481.67 187445.00


b) or use tapply more directly :

> tmp <- tapply(df$Salary, df$Department, function(x) 
                                            c( mean(x), sum(x) ) )
  $Finance
  [1]  83925.67 251777.00

  $HR
  [1]  63333.33 190000.00

  $IT
  [1]  59928.67 179786.00

  $Sales
  [1]  62481.67 187445.00


And using the 'sapply( tmp, c )' gives you a slightly more compact
output as

       Finance        HR        IT     Sales
[1,]  83925.67  63333.33  59928.67  62481.67
[2,] 251777.00 190000.00 179786.00 187445.00


Regards, Adai


On Mon, 2005-03-28 at 19:15 -0600, Sivakumaran Raman wrote:
> I have the data similar to the following in a data frame:
>     LastName   Department  Salary
> 1   Johnson    IT          56000
> 2   James      HR          54223
> 3   Howe       Finance     80000
> 4   Jones      Finance     82000
> 5   Norwood    IT          67000
> 6   Benson     Sales       76000
> 7   Smith      Sales       65778
> 8   Baker      HR          56778
> 9   Dempsey    HR          78999
> 10  Nolan      Sales       45667
> 11  Garth      Finance     89777
> 12  Jameson    IT          56786
> 
> I want to calculate both the mean salary broken down by Department and 
> also the
> total amount paid out per department i.e. I want both sum(Salary) and
> mean(Salary) for each Department. Right now, I am using aggregate.data.frame
> twice, creating two data frames, and then combining them using data.frame.
> However, this seems to be very memory and processor intensive and is 
> taking a
> very long time on my data set. Is there a quicker way to do this?
> 
> Thanks in advance,
> Siv Raman
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From millerj at truman.edu  Fri Mar 25 14:26:26 2005
From: millerj at truman.edu (Jason Miller)
Date: Fri, 25 Mar 2005 07:26:26 -0600
Subject: [R] OS X, exporting graphics, postscript()
In-Reply-To: <p06210212be68f7b3bfe5@[128.115.153.6]>
References: <85bd9a07a812a5b58b2d3d53bd21b8a5@truman.edu>
	<p06210212be68f7b3bfe5@[128.115.153.6]>
Message-ID: <14f238e4d4ac11ebfa55598eb05769a0@truman.edu>

R users,

OK, so I feel dumb.  I didn't understand that dev.off() turns off the 
process of writing a file, and that I can't open a file until dev.off() 
is called to complete the file.

Thanks to everyone who responded to my call for help.

I'm really liking what I'm learning about R.  I hope to learn enough to 
teach my colleagues and students about it.

Jason

On Mar 24, 2005, at 5:07 PM, Don MacQueen wrote:

> Since it was only yesterday, perhaps you can think over what you did 
> between then and now that might have affected things.
>
> R is very stable; it is very unlikely that R has changed. Hence, 
> either something outside R changed that affects R's postscript output 
> -- also unlikely -- or you are doing something different in what you 
> are telling R to do. Since you didn't provide examples that fail, we 
> can only guess...
>
> Are you giving exactly the same commands today on exactly the same 
> data?
> Are you remembering to use dev.off() after the graphics commands are 
> complete?
>
> -Don
>
> At 2:48 PM -0600 3/24/05, Jason Miller wrote:
>> Hello everyone,
>>
>> I am new to R, using version 2.0.1 on a Macintosh running OS X 10.3. 
>> I am learning how to export graphics to postscript format using the 
>> postscript() function, but R is only writing empty files.
>>
>> Yesterday, postscript() was working for me.  Today, I don't know 
>> what's wrong.  Can somebody suggest some things that might fix this 
>> problem?
>>
>> Thanks in advance for you help.
>>
>> Jason
>>
>>
>> ================================================================
>> Jason E. Miller, Ph.D.
>> Associate Professor of Mathematics
>> Truman State University
>> Kirksville, MO
>> http://pyrite.truman.edu/~millerj/
>> 660.785.7430
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>
>
> -- 
> --------------------------------------
> Don MacQueen
> Environmental Protection Department
> Lawrence Livermore National Laboratory
> Livermore, CA, USA
> --------------------------------------
>
>
Jason E. Miller, Ph.D.
Associate Professor
Division of Mathematics & Computer Science
Truman State University
Kirksville, MO
millerj at truman.edu
http://pyrite.truman.edu/~millerj/
660.785.7430



From gerard.tromp at sanger.med.wayne.edu  Tue Mar 29 05:08:58 2005
From: gerard.tromp at sanger.med.wayne.edu (Gerard Tromp)
Date: Mon, 28 Mar 2005 22:08:58 -0500
Subject: [R] Annotation metadata "kills" help.search
Message-ID: <NCEEILPLHGEMJBGGKFCLKEODCAAA.gerard.tromp@sanger.med.wayne.edu>

Greetings!

OS: Windows
R 2.0.1

Before anyone flames -- I tried to query this on the R searchable web site
and using google and did not find anything applicable.

As of about a week ago the help.search function dies when used in the simple
help.search("something") usage.
The error is
Error in rbind(...) : number of columns of matrices must match (see arg 203)

After some effort I have traced it down to the annotation packages. I
installed
GO, KEGG, mgu74[abc]v2 and hgu133plus2 all version 1.7.0

When I move these out of the library directory, help.search() functions
correctly again.

I have not tracked it any further -- just wanted to know if anyone else had
noticed it.


Gerard Tromp



From ggrothendieck at gmail.com  Tue Mar 29 05:18:08 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 28 Mar 2005 22:18:08 -0500
Subject: [R] Annotation metadata "kills" help.search
In-Reply-To: <NCEEILPLHGEMJBGGKFCLKEODCAAA.gerard.tromp@sanger.med.wayne.edu>
References: <NCEEILPLHGEMJBGGKFCLKEODCAAA.gerard.tromp@sanger.med.wayne.edu>
Message-ID: <971536df0503281918237f431f@mail.gmail.com>

This happened to me in R 2.1.0 (I forget which specific version
since I now have March 27th) on Windows XP which I traced to
package dataRep.  Once I removed that package help.search 
worked again.


On Mon, 28 Mar 2005 22:08:58 -0500, Gerard Tromp
<gerard.tromp at sanger.med.wayne.edu> wrote:
> Greetings!
> 
> OS: Windows
> R 2.0.1
> 
> Before anyone flames -- I tried to query this on the R searchable web site
> and using google and did not find anything applicable.
> 
> As of about a week ago the help.search function dies when used in the simple
> help.search("something") usage.
> The error is
> Error in rbind(...) : number of columns of matrices must match (see arg 203)
> 
> After some effort I have traced it down to the annotation packages. I
> installed
> GO, KEGG, mgu74[abc]v2 and hgu133plus2 all version 1.7.0
> 
> When I move these out of the library directory, help.search() functions
> correctly again.
> 
> I have not tracked it any further -- just wanted to know if anyone else had
> noticed it.
> 
> Gerard Tromp
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From dimitris.rizopoulos at med.kuleuven.ac.be  Tue Mar 29 10:30:43 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Tue, 29 Mar 2005 10:30:43 +0200
Subject: [R] mixed model question
References: <20050328200633.77880.qmail@web61302.mail.yahoo.com>
Message-ID: <008d01c53439$9932f140$0540210a@www.domain>

probably you could fit this model using the 'varIdent()' function for 
the 'weights' argument of the 'lme()' function in package "nlme".

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Benn Fine" <bennfine at yahoo.com>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, March 28, 2005 10:06 PM
Subject: [R] mixed model question


>I am trying to fit a linear mixed model of the form
>
> y_ij = X_ij \beta + delta_i + e_ij
>
> where e_ij ~N(0,s^2_ij) with s_ij known
> and delta_i~N(0,tau^2)
>
> I looked at the ecme routine in package:pan, but this routine
> does not allow for different Vi (variance covariance matrix of
> the e_i vector) matrices for each cluster.
>
> Is there an easy way to fit this model in R or should I bite the
> bullet and code the likelihood functions ?
>
> Also, is there an easy way to fit a Bayesian version of this ? Again
> there is mgibbs.lmm but it also does not allow easily for a 
> different
> Vi matrix for each cluster/.
>
> Thanks,
>
> Benn
>
>
>
>
> ---------------------------------
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From jstenberg at ice.mpg.de  Tue Mar 29 10:56:06 2005
From: jstenberg at ice.mpg.de (Johan Stenberg)
Date: Tue, 29 Mar 2005 10:56:06 +0200
Subject: [R] R-squared in Logistic Regression
Message-ID: <42491826.99AE8000@ice.mpg.de>

Dear all,

How do I make R show the R-squared (deviance explained by the model) in
a logistic regression?

Below is how I write my syntax. Basically I want to investigate
density-dependence in parasitism of larvae. Note that in the end I
perform a F-test because the dispersion factor (residual deviance /
residual df) is significantly higher than 1. But how do I make R show
the "R-squared"?

Best wishes
Johan

> y<-cbind(para,unpara)
> model<-glm(y~log(larvae),binomial)
> summary(model)

Call:
glm(formula = y ~ log(larvae), family = binomial)

Deviance Residuals:
    Min       1Q   Median       3Q      Max
-2.0633  -1.6218  -0.1871   0.7907   2.7670

Coefficients:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)   1.0025     0.7049   1.422  0.15499
log(larvae)  -1.0640     0.3870  -2.749  0.00597 **

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 35.981  on 12  degrees of freedom
Residual deviance: 27.298  on 11  degrees of freedom
AIC: 40.949

Number of Fisher Scoring iterations: 4

> anova(model,test="F")
Analysis of Deviance Table

Model: binomial, link: logit

Response: y

Terms added sequentially (first to last)


            Df Deviance Resid. Df Resid. Dev      F   Pr(>F)
NULL                           12     35.981
log(larvae)  1    8.683        11     27.298 8.6828 0.003212 **



From Chloe.ARCHINARD at cefe.cnrs.fr  Tue Mar 29 11:57:25 2005
From: Chloe.ARCHINARD at cefe.cnrs.fr (Chloe ARCHINARD)
Date: Tue, 29 Mar 2005 11:57:25 +0200
Subject: [R] Plot Moran's I
Message-ID: <EB09E5B9F0E2684F863B525E5C7E0F890B36D8@ZZML.newcefe.newage.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050329/4f22fee5/attachment.pl

From pleissner at mpiib-berlin.mpg.de  Tue Mar 29 12:24:26 2005
From: pleissner at mpiib-berlin.mpg.de (Klaus-Peter Pleissner)
Date: Tue, 29 Mar 2005 12:24:26 +0200
Subject: [R] strange result of acos
Message-ID: <42492CDA.5040501@mpiib-berlin.mpg.de>

Hi all,

I have to calculate an expression using acos -function.  A strange 
result of acos appears

*1. case with error*

ss <- sin(10.74*pi/180)**2 
+(cos(10.74*pi/180)*cos(10.74*pi/180)*cos(0*pi/180))
 ss
 acos(ss)


[1] NaN
Warning message:
NaNs produced in: acos(ss)

*2. case without  error*

 ss <- sin(10.7*pi/180)**2 
+(cos(10.7*pi/180)*cos(10.7*pi/180)*cos(0*pi/180))
 ss
 acos(ss)



In both cases the variable ss equals 1.   I  think there is a problem 
with precision. If I multiply ss  by 0.999999999  (ss*0.99999999) no 
error occurs.  How  the results can be explained ?

Regards

Klaus-P.



-- 

Dr. Klaus-Peter Pleissner
Max Planck Institute for Infection Biology
Core Facility Bioinformatics
Campus Charit? Mitte
Schumannstr. 21/22
D-10117 Berlin
Germany

*Phone:* +49-30-28460-119
*Fax:*   +49-30-28460-507
*URL:*   http://web.mpiib-berlin.mpg.de/bioinformatik <http://web.mpiib-berlin.mpg.de/bioinformatik/>
*Email:* pleissner at mpiib-berlin.mpg.de  <mailto:pleissner at mpiib-berlin.mpg.de>



From Ted.Harding at nessie.mcc.ac.uk  Tue Mar 29 13:59:28 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 29 Mar 2005 11:59:28 -0000 (BST)
Subject: [R] strange result of acos
In-Reply-To: <42492CDA.5040501@mpiib-berlin.mpg.de>
Message-ID: <XFMail.050329115928.Ted.Harding@nessie.mcc.ac.uk>

On 29-Mar-05 Klaus-Peter Pleissner wrote:
> Hi all,
> I have to calculate an expression using acos -function.
> A strange result of acos appears
> 
> *1. case with error*
> 
> ss <- sin(10.74*pi/180)**2 
> +(cos(10.74*pi/180)*cos(10.74*pi/180)*cos(0*pi/180))
>  ss
>  acos(ss)
> 
> [1] NaN
> Warning message:
> NaNs produced in: acos(ss)
> 
> *2. case without  error*
> 
>  ss <- sin(10.7*pi/180)**2 
> +(cos(10.7*pi/180)*cos(10.7*pi/180)*cos(0*pi/180))
>  ss
>  acos(ss)
> 
> In both cases the variable ss equals 1. I  think there
> is a problem with precision. If I multiply ss  by
> 0.999999999 (ss*0.99999999) no error occurs. How the
> results can be explained ?

The explanation is:

sin(10.74*pi/180)**2
+(cos(10.74*pi/180)*cos(10.74*pi/180)
*cos(0*pi/180))
-1

[1] 2.220446e-16

I.e. the expression, as internally evaluated, is very
slightly greater than 1. When you multiply ss by
0.999999999, you bring it back down a bit.

Theoretically, of course, it is sin(t)^2 + cos(t)^2,
which should be exactly 1, but you can't count on it
in digital computation. As you suspected, it is indeed
a question of precision.

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 29-Mar-05                                       Time: 11:59:28
------------------------------ XFMail ------------------------------



From Ted.Harding at nessie.mcc.ac.uk  Tue Mar 29 14:27:11 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 29 Mar 2005 12:27:11 -0000 (BST)
Subject: [R] strange result of acos
In-Reply-To: <XFMail.050329115928.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <XFMail.050329122711.Ted.Harding@nessie.mcc.ac.uk>

On 29-Mar-05 Ted Harding wrote:
> The explanation is:
> 
> sin(10.74*pi/180)**2
> +(cos(10.74*pi/180)*cos(10.74*pi/180)
> *cos(0*pi/180))
> -1
> 
> [1] 2.220446e-16
> 
> I.e. the expression, as internally evaluated, is very
> slightly greater than 1. When you multiply ss by
> 0.999999999, you bring it back down a bit.
> 
> Theoretically, of course, it is sin(t)^2 + cos(t)^2,
> which should be exactly 1, but you can't count on it
> in digital computation. As you suspected, it is indeed
> a question of precision.

Just to make more explicit what's happening here:

t<-0.01*(0:200)*pi

sin(t)^2 + cos(t)^2 -1
##[output omitted]

unique(sin(t)^2 + cos(t)^2 -1)
##[1]  0.000000e+00 -1.110223e-16  2.220446e-16

2^(-53)
##[1] 1.110223e-16

so the error is either +2^(-52) or -2^(-53)

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 29-Mar-05                                       Time: 12:27:11
------------------------------ XFMail ------------------------------



From danbebber at forestecology.co.uk  Tue Mar 29 13:45:03 2005
From: danbebber at forestecology.co.uk (Dan Bebber)
Date: Tue, 29 Mar 2005 12:45:03 +0100
Subject: [R] RE: glmmPQL questions
In-Reply-To: <200503291013.j2TA9YtH003641@hypatia.math.ethz.ch>
Message-ID: <000501c53454$bf0b1940$25e82950@plants.ox.ac.uk>

Jo,

It looks like farm is your level of replication, so you don't need to
specify farm as a random factor. A linear model 'lm' with binomial errors
(a.k.a. logistic regression) is enough. You only need to specify different
error strata if, say, you had sampled each farm several times. Is that what
you mean by 'sampling cluster'?
BUT, there is very likely some spatial dependence among farms, so you will
also need to model this.
If you want to constrain the analysis, check out 'subset'.
Missing values: you have to remove farms with missing values from the
analysis. Look up 'na.omit'.
I think perhaps you need to consult a statistician at the Edinburgh stats
department to get info on the appropriate analyses, as the R-help list is
usually restricted to R-specific questions.
There is a massive amount of literature on agricultural epidemiology (esp.
following foot & mouth), so read up to see what has been done before.

Cheers,
Dan Bebber

Department of Plant Sciences
University of Oxford
South Parks Road
Oxford OX1 3RB



>
> Message: 4
> Date: Mon, 28 Mar 2005 12:06:25 +0100
> From: JEB Halliday <s0454869 at sms.ed.ac.uk>
> Subject: [R] glmmPQL questions
> To: r-help at stat.math.ethz.ch
> Message-ID: <1112007985.4247e531657c5 at sms.ed.ac.uk>
> Content-Type: text/plain; charset=ISO-8859-15
>
>
> I am looking a risk factors for disease in cattle and am
> interested in modelling
> farm and sampling cluster as random effects (My outcome is
> positive or negative
> at the level of the farm).  I am using R version 2.0.1 on a Mac and have
> identified glmmPQL as hopefully the correct function to use. I have run a
> couple of models using this but was hoping that you might be able
> to answer a
> few questions.
>
> e.g. model<-glmmPQL(farmstatus~cattlenumber,random~1|farm,binomial)
>
> I am pretty new to both R and stats so if these questions are
> very simple and I
> am just missing something, suggestions about good texts on GLMM
> in R would be
> great.
>
> First up, what is the best way to constrain the model to only
> look at certain
> levels of a multi-level factor e.g. a categorisation of cattle
> number where all
> points of high influence
>
> (as determined using: summary(influence.measures(model)) )
>
> are confined to the largest class (D) and I want to run the model
> which just
> looks at levels A,B and C? (or only months May-September..)
>
> I was also wondering about the best way to force specified
> variables to remain
> in the model when running e.g. stepwise selection of interaction terms?
>
> Finally, is there is a recognised method for dealing with missing
> values in
> these models?
> and as a minor point the models do not run unless i specify the
> data= part of
> the syntax and as this is apparently an optional piece of
> information I was
> wondering why this is required when all of my variables are in
> the same data
> frame (and even when this data frame is attached?)
>
> Any help would be greatly appreciated
>
> Jo Halliday
> MSc student
> University of Edinburgh
> s0454869 at sms.ed.ac.uk
>



From henric.nilsson at statisticon.se  Tue Mar 29 14:33:02 2005
From: henric.nilsson at statisticon.se (Henric Nilsson)
Date: Tue, 29 Mar 2005 14:33:02 +0200 (CEST)
Subject: [R] R-squared in Logistic Regression
In-Reply-To: <42491826.99AE8000@ice.mpg.de>
References: <42491826.99AE8000@ice.mpg.de>
Message-ID: <3154.10.0.10.126.1112099582.squirrel@poisson.statisticon.se>


On Ti, 2005-03-29, 10:56, Johan Stenberg skrev:

> How do I make R show the R-squared (deviance explained by the model) in
> a logistic regression?

Several definitions of R^2 exists in the GLM case. See e.g.

Menard, S. (2000) Coefficients of determination for multiple logistic
regression analysis. American Statistician, 54, 17-24.

Mittlbock, M. and Schemper, M. (2002) Explained variation for logistic
regression - small sample adjustments, confidence intervals and predictive
precision. Biometrical Journal, 44, 263-272.

Liao, J.G. and McGee, D. (2003) Adjusted coefficients of determination for
logistic regression. American Statistician, 57, 161-165.

IIRC, the last paper contains R code.

HTH,
Henric



From f.harrell at vanderbilt.edu  Tue Mar 29 14:40:32 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Tue, 29 Mar 2005 06:40:32 -0600
Subject: [R] R-squared in Logistic Regression
In-Reply-To: <42491826.99AE8000@ice.mpg.de>
References: <42491826.99AE8000@ice.mpg.de>
Message-ID: <42494CC0.9050105@vanderbilt.edu>

Johan Stenberg wrote:
> Dear all,
> 
> How do I make R show the R-squared (deviance explained by the model) in
> a logistic regression?
> 
> Below is how I write my syntax. Basically I want to investigate
> density-dependence in parasitism of larvae. Note that in the end I
> perform a F-test because the dispersion factor (residual deviance /
> residual df) is significantly higher than 1. But how do I make R show
> the "R-squared"?
> 
> Best wishes
> Johan

The proportion of deviance explained has been shown to not be such a 
good measure.  You can use the lrm function in the Design package to get 
various measures including ROC area (C index), Somers' Dxy and Kendall 
tau rank correlation, Nagelkerke generalization of R-squared for maximum 
likelihood-based models (related to Maddala and others).

Frank Harrell

> 
> 
>>y<-cbind(para,unpara)
>>model<-glm(y~log(larvae),binomial)
>>summary(model)
> 
> 
> Call:
> glm(formula = y ~ log(larvae), family = binomial)
> 
> Deviance Residuals:
>     Min       1Q   Median       3Q      Max
> -2.0633  -1.6218  -0.1871   0.7907   2.7670
> 
> Coefficients:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)   1.0025     0.7049   1.422  0.15499
> log(larvae)  -1.0640     0.3870  -2.749  0.00597 **
> 
> (Dispersion parameter for binomial family taken to be 1)
> 
>     Null deviance: 35.981  on 12  degrees of freedom
> Residual deviance: 27.298  on 11  degrees of freedom
> AIC: 40.949
> 
> Number of Fisher Scoring iterations: 4
> 
> 
>>anova(model,test="F")
> 
> Analysis of Deviance Table
> 
> Model: binomial, link: logit
> 
> Response: y
> 
> Terms added sequentially (first to last)
> 
> 
>             Df Deviance Resid. Df Resid. Dev      F   Pr(>F)
> NULL                           12     35.981
> log(larvae)  1    8.683        11     27.298 8.6828 0.003212 **
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From caroline.truntzer at chu-lyon.fr  Tue Mar 29 16:25:13 2005
From: caroline.truntzer at chu-lyon.fr (Caroline TRUNTZER)
Date: Tue, 29 Mar 2005 16:25:13 +0200
Subject: [R] Help about PLS
Message-ID: <42496549.FDAF6A9B@chu-lyon.fr>

Dear all,
I would like to use the PLS method to reduce the dimension of my data
because there are much more variables that individuals. I looked at the
pcr.pls package. Do someone know if there is a mean to project a new
individual in  the latent variables space (as supplementary point)?
Thank you for your help
Caroline



From kevinvol2002 at yahoo.com  Tue Mar 29 16:58:51 2005
From: kevinvol2002 at yahoo.com (Hai Lin)
Date: Tue, 29 Mar 2005 06:58:51 -0800 (PST)
Subject: [R] pairewise plots
Message-ID: <20050329145851.36289.qmail@web60507.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050329/85d7d62d/attachment.pl

From murdoch at stats.uwo.ca  Tue Mar 29 17:17:05 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 29 Mar 2005 10:17:05 -0500
Subject: [R] pairewise plots
In-Reply-To: <20050329145851.36289.qmail@web60507.mail.yahoo.com>
References: <20050329145851.36289.qmail@web60507.mail.yahoo.com>
Message-ID: <itri4158gs0bt3jp14mhorol2noa61k2l4@4ax.com>

On Tue, 29 Mar 2005 06:58:51 -0800 (PST), Hai Lin
<kevinvol2002 at yahoo.com> wrote :

>Dear R users,
> 
>I have a data generated as the following,
> 
>dat <- data.frame(matrix(sample(24), nrow=4))
>dimnames(dat) <-list(rownames=c('g1','g2','g3','g4'), colnames=c("A_CH1","A_CH2","B_CH1","B_CH2","C_CH3","C_CH3"))
> 
>? dat
>   A_CH1 A_CH2 B_CH1 B_CH2 C_CH3 C_CH3
>g1    16    24     7     9    14    20
>g2     4    10    19    22     5    17
>g3    11    18    21    12    13     1
>g4     2     3    15     6    23     8
> 
>I am trying to plot them pairwise by column(might extend to more than 3 pairs) 
>Instead manually plotting as below, could you please point me out with easier ways? 
> 
>par(mfrow=c(3,1))
>plot(dat$A_CH1+dat$A_CH2, dat$A_CH1-dat$A_CH2)
>plot(dat$B_CH1+dat$B_CH2, dat$B_CH1-dat$B_CH2)
>plot(dat[,5]+dat[,6], dat[,5]-dat[,6])

Your last line gives the hint:

for (i in 1:3) {
  c1 <- dat[,2*i - 1]
  c2 <- dat[,2*i]
  n1 <- colnames(dat)[2*i - 1]
  n2 <- colnames(dat)[2*i]
  plot(c1+c2, c1-c2, main=paste("Pair", i,":",n1, n2))
}

Duncan Murdoch



From andy_liaw at merck.com  Tue Mar 29 17:17:02 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 29 Mar 2005 10:17:02 -0500
Subject: [R] pairewise plots
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076CF8@usctmx1106.merck.com>

Something like this should do it:

invisible(lapply(seq(1, length(dat), by=2), 
                 function(i) plot(dat[[i]]+dat[[i+1]], dat[[i]] -
dat[[i+1]])))

Andy

> From: Hai Lin
> 
> Dear R users,
>  
> I have a data generated as the following,
>  
> dat <- data.frame(matrix(sample(24), nrow=4))
> dimnames(dat) <-list(rownames=c('g1','g2','g3','g4'), 
> colnames=c("A_CH1","A_CH2","B_CH1","B_CH2","C_CH3","C_CH3"))
>  
> > dat
>    A_CH1 A_CH2 B_CH1 B_CH2 C_CH3 C_CH3
> g1    16    24     7     9    14    20
> g2     4    10    19    22     5    17
> g3    11    18    21    12    13     1
> g4     2     3    15     6    23     8
>  
> I am trying to plot them pairwise by column(might extend to 
> more than 3 pairs) 
> Instead manually plotting as below, could you please point me 
> out with easier ways? 
>  
> par(mfrow=c(3,1))
> plot(dat$A_CH1+dat$A_CH2, dat$A_CH1-dat$A_CH2)
> plot(dat$B_CH1+dat$B_CH2, dat$B_CH1-dat$B_CH2)
> plot(dat[,5]+dat[,6], dat[,5]-dat[,6])
> 
> Thanks a lot for your help
> 
> __________________________________________________
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From sfalcon at fhcrc.org  Tue Mar 29 17:21:40 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 29 Mar 2005 07:21:40 -0800
Subject: [R] Annotation metadata "kills" help.search
In-Reply-To: <NCEEILPLHGEMJBGGKFCLKEODCAAA.gerard.tromp@sanger.med.wayne.edu>
	(Gerard Tromp's message of "Mon, 28 Mar 2005 22:08:58 -0500")
References: <NCEEILPLHGEMJBGGKFCLKEODCAAA.gerard.tromp@sanger.med.wayne.edu>
Message-ID: <m2k6nq32bf.fsf@macaroni.local>

Hi Gerard,

"Gerard Tromp" <gerard.tromp at sanger.med.wayne.edu> writes:
> OS: Windows
> R 2.0.1
>
> As of about a week ago the help.search function dies when used in the simple
> help.search("something") usage.
> The error is
> Error in rbind(...) : number of columns of matrices must match (see arg 203)
>
> After some effort I have traced it down to the annotation packages. I
> installed
> GO, KEGG, mgu74[abc]v2 and hgu133plus2 all version 1.7.0

We (the Bioconductor team) will look into this and see if we can
reproduce what you are reporting.  This is the first we've heard of
difficulties with the help system caused by the annotation data
packages.

+ seth



From petr.pikal at precheza.cz  Tue Mar 29 17:22:55 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 29 Mar 2005 17:22:55 +0200
Subject: [R] pairewise plots
In-Reply-To: <20050329145851.36289.qmail@web60507.mail.yahoo.com>
Message-ID: <42498EEF.32280.1A5EA21@localhost>

Hallo

On 29 Mar 2005 at 6:58, Hai Lin wrote:

> Dear R users,
> 
> I have a data generated as the following,
> 
> dat <- data.frame(matrix(sample(24), nrow=4))
> dimnames(dat) <-list(rownames=c('g1','g2','g3','g4'),
> colnames=c("A_CH1","A_CH2","B_CH1","B_CH2","C_CH3","C_CH3"))
> 
> ? dat
>    A_CH1 A_CH2 B_CH1 B_CH2 C_CH3 C_CH3
> g1    16    24     7     9    14    20
> g2     4    10    19    22     5    17
> g3    11    18    21    12    13     1
> g4     2     3    15     6    23     8
> 
> I am trying to plot them pairwise by column(might extend to more than
> 3 pairs) Instead manually plotting as below, could you please point me
> out with easier ways? 
> 
> par(mfrow=c(3,1))

You can use for construction

for(i in c(1,3,5)) plot(dat[,i]+dat[,i+1], dat[,i]-dat[,i+1])

but if you want x or y labels formated differently, you probably 
need to ad some kind of expression in xlab (ylab) parameters.

Cheers
Petr



> plot(dat$A_CH1+dat$A_CH2, dat$A_CH1-dat$A_CH2)
> plot(dat$B_CH1+dat$B_CH2, dat$B_CH1-dat$B_CH2)
> plot(dat[,5]+dat[,6], dat[,5]-dat[,6])
> 
> Thanks a lot for your help
> 
> __________________________________________________
> 
> 
> 
>  [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From dimitris.rizopoulos at med.kuleuven.ac.be  Tue Mar 29 17:30:21 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Tue, 29 Mar 2005 17:30:21 +0200
Subject: [R] pairewise plots
References: <20050329145851.36289.qmail@web60507.mail.yahoo.com>
Message-ID: <002d01c53474$389d70e0$0540210a@www.domain>

you could try something like this:

dat <- array(sample(24), dim=c(4,2,3))
par(mfrow=c(3,1))
apply(dat, 3, function(x) plot(rowSums(x), x[,2]-x[,1]))

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Hai Lin" <kevinvol2002 at yahoo.com>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, March 29, 2005 4:58 PM
Subject: [R] pairewise plots


Dear R users,

I have a data generated as the following,

dat <- data.frame(matrix(sample(24), nrow=4))
dimnames(dat) <-list(rownames=c('g1','g2','g3','g4'), 
colnames=c("A_CH1","A_CH2","B_CH1","B_CH2","C_CH3","C_CH3"))

? dat
   A_CH1 A_CH2 B_CH1 B_CH2 C_CH3 C_CH3
g1    16    24     7     9    14    20
g2     4    10    19    22     5    17
g3    11    18    21    12    13     1
g4     2     3    15     6    23     8

I am trying to plot them pairwise by column(might extend to more than 
3 pairs)
Instead manually plotting as below, could you please point me out with 
easier ways?

par(mfrow=c(3,1))
plot(dat$A_CH1+dat$A_CH2, dat$A_CH1-dat$A_CH2)
plot(dat$B_CH1+dat$B_CH2, dat$B_CH1-dat$B_CH2)
plot(dat[,5]+dat[,6], dat[,5]-dat[,6])

Thanks a lot for your help

__________________________________________________



[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html



From tlumley at u.washington.edu  Tue Mar 29 17:40:39 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 29 Mar 2005 07:40:39 -0800 (PST)
Subject: [R] a cox model question
In-Reply-To: <001401c533ec$ca384170$0923ce80@chao>
References: <001401c533ec$ca384170$0923ce80@chao>
Message-ID: <Pine.A41.4.61b.0503290740170.168558@homer11.u.washington.edu>

On Mon, 28 Mar 2005, Chao Zhu wrote:

> Hi,
>
> Is there anyone can tell me how to estimate baseline cumulative hazard function and baseline survival function
> by using Breslow's method in R?

survfit() does this.

 	-thomas



From deepayan at stat.wisc.edu  Tue Mar 29 17:46:09 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 29 Mar 2005 09:46:09 -0600
Subject: [R] pairewise plots
In-Reply-To: <20050329145851.36289.qmail@web60507.mail.yahoo.com>
References: <20050329145851.36289.qmail@web60507.mail.yahoo.com>
Message-ID: <200503290946.09564.deepayan@stat.wisc.edu>

On Tuesday 29 March 2005 08:58, Hai Lin wrote:
> Dear R users,
>
> I have a data generated as the following,
>
> dat <- data.frame(matrix(sample(24), nrow=4))
> dimnames(dat) <-list(rownames=c('g1','g2','g3','g4'),
> colnames=c("A_CH1","A_CH2","B_CH1","B_CH2","C_CH3","C_CH3"))
>
>  dat
>    A_CH1 A_CH2 B_CH1 B_CH2 C_CH3 C_CH3
> g1    16    24     7     9    14    20
> g2     4    10    19    22     5    17
> g3    11    18    21    12    13     1
> g4     2     3    15     6    23     8

Why would you want two columns with the same name?

> I am trying to plot them pairwise by column(might extend to more than
> 3 pairs) Instead manually plotting as below, could you please point
> me out with easier ways?

If your data frame can be easily restructured (using reshape perhaps), 
one possible solution would be to use the lattice package:

require(lattice)
tmd(xyplot(c(A_CH1, B_CH1, C_CH1) ~ c(A_CH2, B_CH2, C_CH2) | gl(3, 4),
           dat, layout = c(3, 1)))

Note that 
1. This is with the data frame as it is, except that I assume the 
   last 2 columns are named C_CH1 and C_CH2
2. This plots the mean instead of the sum (but on the other hand, 
   it's a standard plot that way)

Deepayan

> par(mfrow=c(3,1))
> plot(dat$A_CH1+dat$A_CH2, dat$A_CH1-dat$A_CH2)
> plot(dat$B_CH1+dat$B_CH2, dat$B_CH1-dat$B_CH2)
> plot(dat[,5]+dat[,6], dat[,5]-dat[,6])
>
> Thanks a lot for your help



From efg at stowers-institute.org  Tue Mar 29 18:07:55 2005
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Tue, 29 Mar 2005 10:07:55 -0600
Subject: [R] Multi-plot figures with different numbers of plots
	indifferent rows
References: <8CEECA6FD6736340AB8B3EB87769E09E4382FA@icex1.ic.ac.uk>
	<Pine.LNX.4.62.0503261316330.2758@sasquatch>
Message-ID: <d2bufb$d44$1@sea.gmane.org>

"Anne York" <york at zipcon.net> wrote in message
news:Pine.LNX.4.62.0503261316330.2758 at sasquatch...

> par(mfrow=c(2,3)) #set up 2 rows x 3 colums
> plot(1:10) #plot 1
> plot(1:10) #plot 2
> plot(1:10) #plot 3
> par(mfg=c(2,2))  # start next plot at 2,2 instead of 2,1
>  plot(1:10)       # 4th plot

If you want to leave the last plot(s) in a such a figure blank,
and continue on with another figure, how does that work?

For example:

par(mfrow=c(2,3)) #set up 2 rows x 3 columns
plot(1:10, main="Plot 1")
plot(1:20, main="Plot 2")
plot(1:30, main="Plot 3")
par(mfg=c(2,2))  # start next plot at 2,2 instead of 2,1
plot(1:40, main="Plot 4")

# What if 5th plot is to start on next page?
# Why do plots 5 and 6 overlay plots 1 and 2 instead
# of being on a new page?
par(mfg=c(1,1))
plot(1:50, main="Plot 5")
plot(1:60, main="Plot 6")

If "par(mfg=c(1,1))" is left out, Plot 6 is on the next figure.

The "new=T" parameters seems like a possible solution, but gives this
warning and is ignored:
     Warning messages:
     1: parameter "new" couldn't be set in high-level plot() function

par(mfrow=c(2,3)) #set up 2 rows x 3 columns
plot(1:10, main="Plot 1", new=T)
plot(1:20, main="Plot 2")
plot(1:30, main="Plot 3")
par(mfg=c(2,2))  # start next plot at 2,2 instead of 2,1
plot(1:40, main="Plot 4")

# What if 5th plot is to start on next page?
# Why do plots 5 and 6 overlay plots 1 and 2 instead
# of being on a new page?
par(mfg=c(1,1))
plot(1:50, main="Plot 5", new=T)
plot(1:60, main="Plot 6")

How do I create a series of plots in one figure and control
when a new figure is created? (without using dummy blank placeholder plots)

The example above is only for discussion.  I really want to do this in a
loop
and create 5 plots per figure, and repeat this for many pages in a PDF file.

Thanks for any insight on this.

efg
--
Earl F. Glynn
Scientific Programmer
Stowers Institute for Medical Research



From HankeA at mar.dfo-mpo.gc.ca  Tue Mar 29 18:31:45 2005
From: HankeA at mar.dfo-mpo.gc.ca (Hanke, Alex)
Date: Tue, 29 Mar 2005 12:31:45 -0400
Subject: [R] Problem installing packages and weird R site behaviour
Message-ID: <E37EEC6DE3A0C5439B7E7B07406C24AE124AF2@msgmarsta01.bio.dfo.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050329/47c00727/attachment.pl

From smiller02 at fs.fed.us  Tue Mar 29 19:10:31 2005
From: smiller02 at fs.fed.us (Sherri Miller)
Date: Tue, 29 Mar 2005 09:10:31 -0800
Subject: [R] regression tree xerror
Message-ID: <OF79699F05.D31A5E1F-ON88256FD3.005DC52E-88256FD3.005E58A9@notes.fs.fed.us>

I am running some models (for the first time) using rpart and am getting
results I don't know how to interpret. I'm using cross-validation to prune
the tree and the results look like:
Root node error: 172.71/292 = 0.59148

n= 292

         CP nsplit rel error  xerror     xstd
1  0.124662      0   1.00000 1.00731 0.093701
2  0.064634      1   0.87534 1.08076 0.092337
3  0.057300      2   0.81070 1.07684 0.095582
4  0.038462      4   0.69610 0.99104 0.091659
5  0.036200      5   0.65764 1.01596 0.094635
6  0.029228      7   0.58524 1.00058 0.095440
7  0.028779      8   0.55601 1.00704 0.093242
8  0.024192      9   0.52724 0.97844 0.088936
9  0.018038     11   0.47885 1.02749 0.092263
10 0.016867     13   0.44278 1.08704 0.092112
11 0.015465     14   0.42591 1.10805 0.097813
12 0.015000     15   0.41044 1.11130 0.097881

I do not understand why the rel error rate is going down, but the xerror
generally goes up. For some of the runs, the xerror never goes down. Is
result caused by something in my data structure? I have run some example
datasets from the various help manuals and the xerror goes down, as one
would expect. Any suggestions?

Sherri

Sherri L. Miller
Wildlife Biologist
Redwood Sciences Laboratory
707.825.2949
707.825.2901 (FAX)



From vincent.goulet at act.ulaval.ca  Tue Mar 29 19:43:36 2005
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Tue, 29 Mar 2005 12:43:36 -0500
Subject: [R] Tool for update
In-Reply-To: <NEBBIPHDAMMOKDKPOFFIOEHJDCAA.abunn@whrc.org>
References: <NEBBIPHDAMMOKDKPOFFIOEHJDCAA.abunn@whrc.org>
Message-ID: <200503291243.36212.vincent.goulet@act.ulaval.ca>

Le 25 Mars 2005 16:12, abunn a ?crit :
> > For what I understand you run this every time you use R on a Tuesday,
> > which is not what I would want.
>
> What's wrong with Tuesday? Indeed, it's not the ideal solution but has kept
> me up-to-date. What has amazed me is that I think I've used R every Tuesday
> (and other workdays) since I did that. So, it ends up working pretty well.
> I will look forward to a cleaner implementation with 2.1

I think what Prof. Ripley meant is: you have to run R on a Tuesday in order to 
update your packages. You could lift this requirement --- and still update on 
Tuesdays --- by using a cron job instead. (That's assuming you're using a 
Unix variant, I suppose there is some equivalent way to achieve the same 
thing on Windows.)

Regards,

-- 
  Vincent Goulet, Associate Professor
  ?cole d'actuariat
  Universit? Laval, Qu?bec 
  Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca



From qiana at biostat.umn.edu  Tue Mar 29 19:53:16 2005
From: qiana at biostat.umn.edu (qiana@biostat.umn.edu)
Date: Tue, 29 Mar 2005 11:53:16 -0600
Subject: [R] Stratified Bootstrap question
Message-ID: <1112118796.4249960ce0550@webmail.ccbr.umn.edu>

Dear R users,

I have a question regarding stratified bootstrap question and how to implement
it using boot() in R's boot package.

My dataset is a longitudinal dataset (3 measurements per person at year
1, 4 and 7) composed of multiple clinic centers and multiple participants
within each clinic. It has missing values.

I want to do a bootstrap to find the standard errors and confidence
intervals for my variance components. My model is a mixed model with
random clinic and random participant within clinic.

I thought two methods to do bootstrap:
(1) bootstrap data; however, I have problem specifying the second
parameter for my statistic function, shall I use indices, weight or
frequency and how shall I relate to my dataset.
(2) bootstrap residuals; however, the dataset has multiple measurements
and missing values. I am wondering how to construct a new data frame
containing the residuals and fitted values.

Any ideas will be highly appreciated!
Sincerely yours,
Qian



From p.dalgaard at biostat.ku.dk  Tue Mar 29 20:01:34 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 29 Mar 2005 20:01:34 +0200
Subject: [R] Problem installing packages and weird R site behaviour
In-Reply-To: <E37EEC6DE3A0C5439B7E7B07406C24AE124AF2@msgmarsta01.bio.dfo.ca>
References: <E37EEC6DE3A0C5439B7E7B07406C24AE124AF2@msgmarsta01.bio.dfo.ca>
Message-ID: <x2br92gwld.fsf@turmalin.kubism.ku.dk>

"Hanke, Alex" <HankeA at mar.dfo-mpo.gc.ca> writes:

> Hi,
> I tried to install a package using the menu option and was presented a list
> filled with NA's.
> I then tried visiting the R site and each option on the side bar (eg. CRAN,
> Search,FAQ) sends me to the address attached below (NB: I left off the h in
> http).
> The first problem seems to be related to the second.
> Is anyone else experiencing this behaviour and how do I restore normal
> behaviour?
> Regards
> Alex
> 
> Problem 1
> >local({a <- CRAN.packages()
> + install.packages(select.list(a[,1],,TRUE), .libPaths()[1], available=a,
> dependencies=TRUE)})
> trying URL `http://cran.r-project.org/bin/windows/contrib/2.0/PACKAGES'
> Content type `text/html' length unknown
> opened URL
> downloaded 953 bytes
> 
> Problem 2
> {ttp://64.235.246.142/?a_id=794&adultfilter=on&domainname=r-project.org}
> 
> Alex Hanke
> Department of Fisheries and Oceans
> St. Andrews Biological Station
> 531 Brandy Cove Road
> St. Andrews, NB
> Canada
> E5B 2L9

[pd at titmouse ~]$ host search.domainsponsor.com
search.domainsponsor.com has address 64.235.246.141

Looks like foul play (domainname hijacking, or some sort of spyware on
your machine). Things look normal from here.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From abunn at whrc.org  Tue Mar 29 20:10:33 2005
From: abunn at whrc.org (abunn)
Date: Tue, 29 Mar 2005 13:10:33 -0500
Subject: [R] Tool for update
In-Reply-To: <200503291243.36212.vincent.goulet@act.ulaval.ca>
Message-ID: <NEBBIPHDAMMOKDKPOFFIMEINDCAA.abunn@whrc.org>

> I think what Prof. Ripley meant is: you have to run R on a
> Tuesday in order to
> update your packages. You could lift this requirement --- and
> still update on
> Tuesdays --- by using a cron job instead. (That's assuming you're using a
> Unix variant, I suppose there is some equivalent way to achieve the same
> thing on Windows.)

I'm very sorry for causing such a stir - asking "What's wrong with Tuesday?"
was a poor attempt at humor. I was subconsciously trying to make it into the
fortunes package but my wit pales in comparison to the greats.

Mea culpa,

Andy



From kevinvol2002 at yahoo.com  Tue Mar 29 20:10:30 2005
From: kevinvol2002 at yahoo.com (Hai Lin)
Date: Tue, 29 Mar 2005 10:10:30 -0800 (PST)
Subject: [R] Re: follow up on "pairewise plots"
Message-ID: <20050329181030.95101.qmail@web60507.mail.yahoo.com>

--- Dimitris Rizopoulos
<dimitris.rizopoulos at med.kuleuven.ac.be> wrote:
> you could try something like this:
> 
> dat <- array(sample(24), dim=c(4,2,3))
> par(mfrow=c(3,1))
> apply(dat, 3, function(x) plot(rowSums(x),
> x[,2]-x[,1]))

##

Thank you all for the inputs. It's great of help. 

The above solution also opens my mind that I could
convert my data to an array. 

dat <- data.frame(matrix(sample(24), nrow=4))
dimnames(dat) <-list(rownames=c('g1','g2','g3','g4'),
colnames=c("A_CH1","A_CH2","B_CH1","B_CH2","C_CH1","C_CH2"))

Sorry for the typo. (C_CH1, C_CH2)

dat2 <- array(unlist(dat), dim=c(4,2,3))  
and then plot them using Dimitris' solution.

Other statements of converting form are welcomed...

Thanks again.



From ltorgo at liacc.up.pt  Tue Mar 29 20:13:23 2005
From: ltorgo at liacc.up.pt (Luis Torgo)
Date: Tue, 29 Mar 2005 19:13:23 +0100
Subject: [R] regression tree xerror
In-Reply-To: <OF79699F05.D31A5E1F-ON88256FD3.005DC52E-88256FD3.005E58A9@notes.fs.fed.us>
References: <OF79699F05.D31A5E1F-ON88256FD3.005DC52E-88256FD3.005E58A9@notes.fs.fed.us>
Message-ID: <42499AC3.50005@liacc.up.pt>

Sherri Miller wrote:

>I am running some models (for the first time) using rpart and am getting
>results I don't know how to interpret. I'm using cross-validation to prune
>the tree and the results look like:
>Root node error: 172.71/292 = 0.59148
>
>n= 292
>
>         CP nsplit rel error  xerror     xstd
>1  0.124662      0   1.00000 1.00731 0.093701
>2  0.064634      1   0.87534 1.08076 0.092337
>3  0.057300      2   0.81070 1.07684 0.095582
>4  0.038462      4   0.69610 0.99104 0.091659
>5  0.036200      5   0.65764 1.01596 0.094635
>6  0.029228      7   0.58524 1.00058 0.095440
>7  0.028779      8   0.55601 1.00704 0.093242
>8  0.024192      9   0.52724 0.97844 0.088936
>9  0.018038     11   0.47885 1.02749 0.092263
>10 0.016867     13   0.44278 1.08704 0.092112
>11 0.015465     14   0.42591 1.10805 0.097813
>12 0.015000     15   0.41044 1.11130 0.097881
>
>I do not understand why the rel error rate is going down, but the xerror
>generally goes up. For some of the runs, the xerror never goes down. Is
>result caused by something in my data structure? I have run some example
>datasets from the various help manuals and the xerror goes down, as one
>would expect. Any suggestions?
>
>Sherri
>
>Sherri L. Miller
>Wildlife Biologist
>Redwood Sciences Laboratory
>707.825.2949
>707.825.2901 (FAX)
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>
rel error is estimated with the training data (the sample used for 
obtaining the tree) and thus it decreases as the tree increases, because 
the tree becomes more and more adjusted to the data. This apparently 
better performance should not be taken for "real" when predicting for a 
new sample of data because larger trees do tend to overfit the traning 
sample and will hardly generalise well on new fresh data samples.

That's the motivation for the xerror (and xstd) estimates. These are 
more realistic estimates of the performance of the tree on new samples 
of data. They are obtained by the rpart function by an internal cross 
validation process. The function prune() can be used to select a subtree 
of the tree obtained with rpart() if you think (by looking at the xerror 
estimates) you would be better off with this subtree.

Hope this helps.

Luis Torgo

-- 
Luis Torgo
    FEP/LIACC, University of Porto   Phone : (+351) 22 339 20 93
    Machine Learning Group           Fax   : (+351) 22 339 20 99
    R. de Ceuta, 118, 6o             email : ltorgo at liacc.up.pt
    4050-190 PORTO - PORTUGAL        WWW   : http://www.liacc.up.pt/~ltorgo



From sfalcon at fhcrc.org  Tue Mar 29 20:16:15 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 29 Mar 2005 10:16:15 -0800
Subject: [R] Annotation metadata "kills" help.search
In-Reply-To: <m2k6nq32bf.fsf@macaroni.local> (Seth Falcon's message of "Tue,
	29 Mar 2005 07:21:40 -0800")
References: <NCEEILPLHGEMJBGGKFCLKEODCAAA.gerard.tromp@sanger.med.wayne.edu>
	<m2k6nq32bf.fsf@macaroni.local>
Message-ID: <m2u0muz5ao.fsf@macaroni.local>

Seth Falcon <sfalcon at fhcrc.org> writes:

> Hi Gerard,
>
> "Gerard Tromp" <gerard.tromp at sanger.med.wayne.edu> writes:
>> OS: Windows
>> R 2.0.1
>>
>> As of about a week ago the help.search function dies when used in the simple
>> help.search("something") usage.
>> The error is
>> Error in rbind(...) : number of columns of matrices must match (see arg 203)
>>
>> After some effort I have traced it down to the annotation packages. I
>> installed
>> GO, KEGG, mgu74[abc]v2 and hgu133plus2 all version 1.7.0
>
> We (the Bioconductor team) will look into this and see if we can
> reproduce what you are reporting.  This is the first we've heard of
> difficulties with the help system caused by the annotation data
> packages.

We are not able to reproduce this issue.  If you reinstall the
annotation packages does the error reappear? 

If so, an exact transcript of the commands entered, their output, and
the output of traceback() right after the error would be helpful ---
and it would be best to move the discussion to the bioconductor list. 

+ seth



From jrgruen at email.med.yale.edu  Tue Mar 29 21:18:38 2005
From: jrgruen at email.med.yale.edu (Jeffrey Gruen, M.D.)
Date: Tue, 29 Mar 2005 14:18:38 -0500
Subject: [R] final stages of installing R - please help?
Message-ID: <bcdb659bd83f3817b30d15af11df2883@email.med.yale.edu>

Hello,

This morning I downloaded, unzipped, and compiled the latest version of 
R for unix, in my HOME/APPLICATIONS directory.
My current unix machine is a sparc-sun-solaris2.9, running SunOS 5.9.
Here are the last few lines of the output following ./configure:

R is now configured for sparc-sun-solaris2.9

   Source directory:          .
   Installation directory:    /usr/local

   C compiler:                /usr/local/bin/gcc  -g -O2
   C++ compiler:              g++
   Fortran compiler:          /usr/local/bin/g77  -g -O2

   Interfaces supported:      X11
   External libraries:
   Additional capabilities:
   Options enabled:           R profiling

   Recommended packages:      yes

Then I checked my HOME/APPLICATIONS directory and indeed following the 
compiling, I now had a new bin directory:
HOME/APPLICATIONS/R-2.0.1/bin
And within the bin, I had many new files including an executable 
(theoretically) R file:
-rwxr-xr-x   1 root        6099 Mar 29 13:18 R

I then ran 'make'.
Here are the last few lines from the 'make' output to the screen:
rm -f libappl.a
false cr libappl.a approx.o bakslv.o bandwidths.o binning.o chull.o 
cpoly.o cumsum.o fft.o fmin.o integrate.o interv.o lbfgsb.o loglin.o 
lowess.o machar.o maxcol.o massdist.o pretty.o rcont.o rowsum.o 
splines.o stem.o strsignif.o tabulate.o uncmin.o zeroin.o ch2inv.o 
chol.o dchdc.o dpbfa.o dpbsl.o dpoco.o dpodi.o dpofa.o dposl.o dqrdc.o 
dqrdc2.o dqrls.o dqrsl.o dqrutl.o dsvdc.o dtrco.o dtrsl.o eigen.o 
lminfl.o blas.o  zgemm.o
make[3]: *** [libappl.a] Error 1
make[3]: Leaving directory `/home/gruen/Applications/R-2.0.1/src/appl'
make[2]: *** [R] Error 2
make[2]: Leaving directory `/home/gruen/Applications/R-2.0.1/src/appl'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/home/gruen/Applications/R-2.0.1/src'
make: *** [R] Error 1

I then ran 'make check'.
Here is the output:
# /usr/local/bin/make check
make[1]: Entering directory `/home/gruen/Applications/R-2.0.1/tests'
make[2]: Entering directory `/home/gruen/Applications/R-2.0.1/tests'
make[3]: Entering directory 
`/home/gruen/Applications/R-2.0.1/tests/Examples'
make[4]: Entering directory 
`/home/gruen/Applications/R-2.0.1/tests/Examples'
make[4]: Leaving directory 
`/home/gruen/Applications/R-2.0.1/tests/Examples'
make[4]: Entering directory 
`/home/gruen/Applications/R-2.0.1/tests/Examples'
make[4]: *** No rule to make target `../../bin/exec/R', needed by 
`base-Ex.Rout'.  Stop.
make[4]: Leaving directory 
`/home/gruen/Applications/R-2.0.1/tests/Examples'
make[3]: *** [test-Examples-Base] Error 2
make[3]: Leaving directory 
`/home/gruen/Applications/R-2.0.1/tests/Examples'
make[2]: *** [test-Examples] Error 2
make[2]: Leaving directory `/home/gruen/Applications/R-2.0.1/tests'
make[1]: *** [test-all-basics] Error 1
make[1]: Leaving directory `/home/gruen/Applications/R-2.0.1/tests'
make: *** [check] Error 2


I was not sure if the errors were important so I tried additional 'make 
check' operations:
# /usr/local/bin/make check FORCE=FORCE
make: Nothing to be done for `check'.
# /usr/local/bin/make check-devel
make: *** No rule to make target `check-devel'.  Stop.
# /usr/local/bin/make check-all
make: *** No rule to make target `check-all'.  Stop.

Then I relogged on and tried to execute 'R' in my bin, as either myself 
or even root, but got the same message:
gruen@/home/gruen% R
/usr/local/bin/R: /home/gruen/Applications/R-2.0.1/bin/exec/R: not found

But it does not execute.

Any thoughts?

Thank you!

Jeff Gruen
jeffrey.gruen at yale.edu



From ssherman at cemml.colostate.edu  Tue Mar 29 21:27:14 2005
From: ssherman at cemml.colostate.edu (Steve Sherman)
Date: Tue, 29 Mar 2005 12:27:14 -0700
Subject: [R] dependency help for FC2 rpm
Message-ID: <4249AC12.1020007@cemml.colostate.edu>

I am having difficulty with dependencies for the R rpm for Fedora Core 2.

In attempting to load R-2.0.0.0.fdr.1.fc2.i386.rpm it fails the 
libtk8.4.so dependency even though I have this library loaded. The 
library is located in:  /usr/local/lib.

How might I tell R where to find this library? I am new to Linux and 
loading rpms so I am hoping there is a simple answer and that the 
problem is related to my inexperience. Thanks in advance for any 
assistance.

 

Steve



From p.dalgaard at biostat.ku.dk  Tue Mar 29 22:01:05 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 29 Mar 2005 22:01:05 +0200
Subject: [R] final stages of installing R - please help?
In-Reply-To: <bcdb659bd83f3817b30d15af11df2883@email.med.yale.edu>
References: <bcdb659bd83f3817b30d15af11df2883@email.med.yale.edu>
Message-ID: <x27jjqgr26.fsf@turmalin.kubism.ku.dk>

"Jeffrey Gruen, M.D." <jrgruen at email.med.yale.edu> writes:

> Hello,
> 
> This morning I downloaded, unzipped, and compiled the latest version
> of R for unix, in my HOME/APPLICATIONS directory.
> My current unix machine is a sparc-sun-solaris2.9, running SunOS 5.9.
> Here are the last few lines of the output following ./configure:
> 
> R is now configured for sparc-sun-solaris2.9
> 
>    Source directory:          .
>    Installation directory:    /usr/local
> 
>    C compiler:                /usr/local/bin/gcc  -g -O2
>    C++ compiler:              g++
>    Fortran compiler:          /usr/local/bin/g77  -g -O2
> 
>    Interfaces supported:      X11
>    External libraries:
>    Additional capabilities:
>    Options enabled:           R profiling
> 
>    Recommended packages:      yes
> 
> Then I checked my HOME/APPLICATIONS directory and indeed following the
> compiling, I now had a new bin directory:
> HOME/APPLICATIONS/R-2.0.1/bin
> And within the bin, I had many new files including an executable
> (theoretically) R file:
> -rwxr-xr-x   1 root        6099 Mar 29 13:18 R
> 
> I then ran 'make'.
> Here are the last few lines from the 'make' output to the screen:
> rm -f libappl.a
> false cr libappl.a approx.o bakslv.o bandwidths.o binning.o chull.o
> cpoly.o cumsum.o fft.o fmin.o integrate.o interv.o lbfgsb.o loglin.o
> lowess.o machar.o maxcol.o massdist.o pretty.o rcont.o rowsum.o
> splines.o stem.o strsignif.o tabulate.o uncmin.o zeroin.o ch2inv.o
> chol.o dchdc.o dpbfa.o dpbsl.o dpoco.o dpodi.o dpofa.o dposl.o dqrdc.o
> dqrdc2.o dqrls.o dqrsl.o dqrutl.o dsvdc.o dtrco.o dtrsl.o eigen.o
> lminfl.o blas.o  zgemm.o
> make[3]: *** [libappl.a] Error 1
> make[3]: Leaving directory `/home/gruen/Applications/R-2.0.1/src/appl'
> make[2]: *** [R] Error 2
> make[2]: Leaving directory `/home/gruen/Applications/R-2.0.1/src/appl'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/home/gruen/Applications/R-2.0.1/src'
> make: *** [R] Error 1

Looks like it couldn't find the "ar" program and set it to "false". I
don't quite understand why configure allows itself to complete in that
case, but the basic problem could be that you don't have your PATH set
right. I believe the standard version sits in /usr/ccs/bin.
 
> I then ran 'make check'.

Won't do anything useful if you haven't built R succesfully first.


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Tue Mar 29 22:04:51 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 29 Mar 2005 22:04:51 +0200
Subject: [R] dependency help for FC2 rpm
In-Reply-To: <4249AC12.1020007@cemml.colostate.edu>
References: <4249AC12.1020007@cemml.colostate.edu>
Message-ID: <x23buegqvw.fsf@turmalin.kubism.ku.dk>

Steve Sherman <ssherman at cemml.colostate.edu> writes:

> I am having difficulty with dependencies for the R rpm for Fedora Core 2.
> 
> In attempting to load R-2.0.0.0.fdr.1.fc2.i386.rpm it fails the
> libtk8.4.so dependency even though I have this library loaded. The
> library is located in:  /usr/local/lib.
> 
> How might I tell R where to find this library? I am new to Linux and
> loading rpms so I am hoping there is a simple answer and that the
> problem is related to my inexperience. Thanks in advance for any
> assistance.

You need to install the RPM dependencies that it depends on. A
libtk8.4.so in /usr/local/lib doesn't come from a standard RPM. You
need to install the tk (and tcl) RPM from CD's or a Fedora repository.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From T.A.Wassenaar at rug.nl  Tue Mar 29 22:17:06 2005
From: T.A.Wassenaar at rug.nl (T.A.Wassenaar)
Date: Tue, 29 Mar 2005 22:17:06 +0200
Subject: [R] Lattice - parallel: xlim and adding lines
Message-ID: <web-2159588@mail3.rug.nl>


Hi,

I'm trying to set the minimum and maximum in a parallel 
plot, but trying xlim=c(-1,1) gives strange results. Am I 
missing something? The call I give is:

parallel(~X[,c(6,9,12,15,18)]|X$ff,X,panel=panel.parallel.new,groups=X$protein,layout=c(3,1),xlim=c(-1,1))

Besides, I would like to add a reference line to the plot, 
but can't find how to do that.

I hope someone can give me a hint or two.

Thanks in advance,

Tsjerk



From sundar.dorai-raj at pdf.com  Tue Mar 29 22:42:05 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 29 Mar 2005 14:42:05 -0600
Subject: [R] Lattice - parallel: xlim and adding lines
In-Reply-To: <web-2159588@mail3.rug.nl>
References: <web-2159588@mail3.rug.nl>
Message-ID: <4249BD9D.4030208@pdf.com>



T.A.Wassenaar wrote on 3/29/2005 2:17 PM:
> 
> Hi,
> 
> I'm trying to set the minimum and maximum in a parallel plot, but trying 
> xlim=c(-1,1) gives strange results. Am I missing something? The call I 
> give is:
> 
> parallel(~X[,c(6,9,12,15,18)]|X$ff,X,panel=panel.parallel.new,groups=X$protein,layout=c(3,1),xlim=c(-1,1)) 
> 
> 
> Besides, I would like to add a reference line to the plot, but can't 
> find how to do that.
> 
> I hope someone can give me a hint or two.
> 
> Thanks in advance,
> 
> Tsjerk
> 

Tsjerk,

I don't think you'll get much help without knowing, first, what 
"strange" means, and second, what "panel.parallel.new" does. And you can 
always add a reference line by using panel.abline in your panel function.

And, from the signature:

PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html

--sundar



From piet.vanremortel at gmail.com  Tue Mar 29 22:47:02 2005
From: piet.vanremortel at gmail.com (Piet van Remortel)
Date: Tue, 29 Mar 2005 22:47:02 +0200
Subject: [R] matching vectors against vectors
Message-ID: <3f177c8625945c63c175b049737a24d8@gmail.com>

Hi all.

I have a re-occuring typical problem that I don't know how to solve 
efficiently.

The situation is the following:   I have a number of data-sets 
(A,B,C,...) , consisting of an identifier (e.g. 11,12,13,...,20) and a 
measurement (e.g. in the range 100-120).   I want to compile a large 
table, with all availabe identifiers in all data-sets in the rows, and 
a column for every dataset.

Now, not all datasets have a measurement for every identifier, so I 
want NA if the set does not contain the identifier.

an example for a single dataset:

#all identifiers
 > rep <- c(10:20)

#Identifiers in my dataset (a subset of rep)
 > rep1 <- c(12,13,15,16,17,18)

#measurements in this dataset
 > rep1.r <- c(112,113,115,116,117,118)

#a vector which should become a column in the final table, now 
containing all NAs
 > res <- rep(NA,10)

#the IDs and values of my dataset together
 > data <- cbind(rep1, rep1.r)

data looks like this:
      rep1 rep1.r
[1,]   12    112
[2,]   13    113
[3,]   15    115
[4,]   16    116
[5,]   17    117
[6,]   18    118

Now, I want to put the values 112, 113, 115,... in the correct rows of 
the final table, using the identifiers as an indicator of which row to 
put it in, so that I finally obtain:

rep     res
10    NA
11    NA
12    112
13    113
14    NA
15    115
16    116
17    117
18    118
19    NA
20    NA

I try to avoid repeating 'which' a lot and filling in every 
identifier's observation etc, since I will be doing this for thousands 
of rows at once.    There must be an efficient way using factors, 
tapply etc, but I have trouble finding it.  Ideal would be if this 
could be done in one go, instead of looping.

Any suggestions ?

Thanks,

Piet



From George_Heine at blm.gov  Tue Mar 29 22:54:14 2005
From: George_Heine at blm.gov (George_Heine@blm.gov)
Date: Tue, 29 Mar 2005 13:54:14 -0700
Subject: [R] slide show with R
Message-ID: <OFC183180D.4DB88F80-ON87256FD3.00671463-87256FD3.0072D418@blm.gov>





Trying to use R to build an interactive "slide show", to be displayed on a
projector.  The purpose of the presentation is to show how one could
construct a simple graph using R.  It is meant as a general overview rather
than as detailed instruction.

For example, something like the following sequence of commands.    At
lecture time, I want the interpreter to read these commands one at a time
from a file, display and execute the command, (or two or three commands)
and then wait for another prompt.

pale.yellow="#ffff99"
par(bg=pale.yellow)
plot(c(0,2*pi),c(-1,1),type="n",ylab="",yaxt="n")
mirror<-function(t) { c(t,rev(2*max(t)-t)) }
z<-log(1:1000)/log(1000)
zz<-z*pi/2
zzz<-mirror(mirror(zz))
polygon(zzz,sin(25*zzz)*sin(zzz),border="blue")
polygon(zzz,sin(5*zzz)*sin(zzz),border="green")
polygon(zzz,sin(zzz),lwd=2)
points(zzz,rep(0,length(zzz)),col="red",pch="|")


Wrapping the following around each command works, sort of :

a<-expression(<command>)
x<-readline(a)
eval(a)

However, this doesn't work properly for the function definition, and it
gets very clumsy to display two or three lines as a block and then
evaluate.

Any help would be much appreciated.


<>=<>=<>=<>=<>=<>=<>=<>=<>=<>=<>
George Heine, PhD
Mathematical Analyst
National IRM Center
U.S. Bureau of Land Management
voice   (303) 236-0099
fax       (303) 236-1974
cell      (303) 905-5382
pager   gheine at my2way.com
<>=<>=<>=<>=<>=<>=<>=<>=<>=<>=<>



From gunter.berton at gene.com  Tue Mar 29 23:18:29 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Tue, 29 Mar 2005 13:18:29 -0800
Subject: [R] slide show with R
In-Reply-To: <OFC183180D.4DB88F80-ON87256FD3.00671463-87256FD3.0072D418@blm.gov>
Message-ID: <200503292118.j2TLITNW018911@ohm.gene.com>

One possible strategy:

see ?readLines

Write a text file with your R commands. Then
write a little function that opens a connection to the file and runs a loop
to:

1)read a line from your file via readLines
2) cat() the line on your terminal
3) prompt via readline to execute it.

You'll have to get a little fancy to check for expressions that span several
lines and check for the end of file, but this should work, I think.

Cheers,

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> George_Heine at blm.gov
> Sent: Tuesday, March 29, 2005 12:54 PM
> To: R-Help
> Subject: [R] slide show with R
> 
> 
> 
> 
> 
> Trying to use R to build an interactive "slide show", to be 
> displayed on a
> projector.  The purpose of the presentation is to show how one could
> construct a simple graph using R.  It is meant as a general 
> overview rather
> than as detailed instruction.
> 
> For example, something like the following sequence of commands.    At
> lecture time, I want the interpreter to read these commands 
> one at a time
> from a file, display and execute the command, (or two or 
> three commands)
> and then wait for another prompt.
> 
> pale.yellow="#ffff99"
> par(bg=pale.yellow)
> plot(c(0,2*pi),c(-1,1),type="n",ylab="",yaxt="n")
> mirror<-function(t) { c(t,rev(2*max(t)-t)) }
> z<-log(1:1000)/log(1000)
> zz<-z*pi/2
> zzz<-mirror(mirror(zz))
> polygon(zzz,sin(25*zzz)*sin(zzz),border="blue")
> polygon(zzz,sin(5*zzz)*sin(zzz),border="green")
> polygon(zzz,sin(zzz),lwd=2)
> points(zzz,rep(0,length(zzz)),col="red",pch="|")
> 
> 
> Wrapping the following around each command works, sort of :
> 
> a<-expression(<command>)
> x<-readline(a)
> eval(a)
> 
> However, this doesn't work properly for the function 
> definition, and it
> gets very clumsy to display two or three lines as a block and then
> evaluate.
> 
> Any help would be much appreciated.
> 
> 
> <>=<>=<>=<>=<>=<>=<>=<>=<>=<>=<>
> George Heine, PhD
> Mathematical Analyst
> National IRM Center
> U.S. Bureau of Land Management
> voice   (303) 236-0099
> fax       (303) 236-1974
> cell      (303) 905-5382
> pager   gheine at my2way.com
> <>=<>=<>=<>=<>=<>=<>=<>=<>=<>=<>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From gunter.berton at gene.com  Tue Mar 29 23:20:31 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Tue, 29 Mar 2005 13:20:31 -0800
Subject: [R] slide show with R
In-Reply-To: <OFC183180D.4DB88F80-ON87256FD3.00671463-87256FD3.0072D418@blm.gov>
Message-ID: <200503292120.j2TLKVT2009025@volta.gene.com>

Oops, I should have said that you can execute the text line via the
construction:

eval(parse(text=textline))



-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> George_Heine at blm.gov
> Sent: Tuesday, March 29, 2005 12:54 PM
> To: R-Help
> Subject: [R] slide show with R
> 
> 
> 
> 
> 
> Trying to use R to build an interactive "slide show", to be 
> displayed on a
> projector.  The purpose of the presentation is to show how one could
> construct a simple graph using R.  It is meant as a general 
> overview rather
> than as detailed instruction.
> 
> For example, something like the following sequence of commands.    At
> lecture time, I want the interpreter to read these commands 
> one at a time
> from a file, display and execute the command, (or two or 
> three commands)
> and then wait for another prompt.
> 
> pale.yellow="#ffff99"
> par(bg=pale.yellow)
> plot(c(0,2*pi),c(-1,1),type="n",ylab="",yaxt="n")
> mirror<-function(t) { c(t,rev(2*max(t)-t)) }
> z<-log(1:1000)/log(1000)
> zz<-z*pi/2
> zzz<-mirror(mirror(zz))
> polygon(zzz,sin(25*zzz)*sin(zzz),border="blue")
> polygon(zzz,sin(5*zzz)*sin(zzz),border="green")
> polygon(zzz,sin(zzz),lwd=2)
> points(zzz,rep(0,length(zzz)),col="red",pch="|")
> 
> 
> Wrapping the following around each command works, sort of :
> 
> a<-expression(<command>)
> x<-readline(a)
> eval(a)
> 
> However, this doesn't work properly for the function 
> definition, and it
> gets very clumsy to display two or three lines as a block and then
> evaluate.
> 
> Any help would be much appreciated.
> 
> 
> <>=<>=<>=<>=<>=<>=<>=<>=<>=<>=<>
> George Heine, PhD
> Mathematical Analyst
> National IRM Center
> U.S. Bureau of Land Management
> voice   (303) 236-0099
> fax       (303) 236-1974
> cell      (303) 905-5382
> pager   gheine at my2way.com
> <>=<>=<>=<>=<>=<>=<>=<>=<>=<>=<>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From Michaell.Taylor at boxwoodmeans.com  Tue Mar 29 23:30:36 2005
From: Michaell.Taylor at boxwoodmeans.com (Michaell Taylor)
Date: Tue, 29 Mar 2005 15:30:36 -0600
Subject: [R] slide show with R
In-Reply-To: <OFC183180D.4DB88F80-ON87256FD3.00671463-87256FD3.0072D418@blm.gov>
References: <OFC183180D.4DB88F80-ON87256FD3.00671463-87256FD3.0072D418@blm.gov>
Message-ID: <1112131836.17748.177.camel@localhost>

Seems like emacs-ess would do the trick.  You can read in the entire
file - formatted or spaced as appropriate - execute one line or several
at a time and see the results in real time.

Obviously less a "slide show" than an R session, but that seems to be
what you want.  

A more "canned" slide show like approach might be something like
Sweave/Prosper.  This is considerably more work, loses the ability to
interact with the interpreter -- but does achieve a very slick slideshow
sort of look.

On Tue, 2005-03-29 at 14:54, George_Heine at blm.gov wrote:
> 
> 
> Trying to use R to build an interactive "slide show", to be displayed on a
> projector.  The purpose of the presentation is to show how one could
> construct a simple graph using R.  It is meant as a general overview rather
> than as detailed instruction.
> 
> For example, something like the following sequence of commands.    At
> lecture time, I want the interpreter to read these commands one at a time
> from a file, display and execute the command, (or two or three commands)
> and then wait for another prompt.
> 
> pale.yellow="#ffff99"
> par(bg=pale.yellow)
> plot(c(0,2*pi),c(-1,1),type="n",ylab="",yaxt="n")
> mirror<-function(t) { c(t,rev(2*max(t)-t)) }
> z<-log(1:1000)/log(1000)
> zz<-z*pi/2
> zzz<-mirror(mirror(zz))
> polygon(zzz,sin(25*zzz)*sin(zzz),border="blue")
> polygon(zzz,sin(5*zzz)*sin(zzz),border="green")
> polygon(zzz,sin(zzz),lwd=2)
> points(zzz,rep(0,length(zzz)),col="red",pch="|")
> 
> 
> Wrapping the following around each command works, sort of :
> 
> a<-expression(<command>)
> x<-readline(a)
> eval(a)
> 
> However, this doesn't work properly for the function definition, and it
> gets very clumsy to display two or three lines as a block and then
> evaluate.
> 
> Any help would be much appreciated.
> 
> 
> <>=<>=<>=<>=<>=<>=<>=<>=<>=<>=<>
> George Heine, PhD
> Mathematical Analyst
> National IRM Center
> U.S. Bureau of Land Management
> voice   (303) 236-0099
> fax       (303) 236-1974
> cell      (303) 905-5382
> pager   gheine at my2way.com
> <>=<>=<>=<>=<>=<>=<>=<>=<>=<>=<>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From jan.sabee at gmail.com  Tue Mar 29 23:35:43 2005
From: jan.sabee at gmail.com (Jan Sabee)
Date: Tue, 29 Mar 2005 23:35:43 +0200
Subject: [R] Mosaicplot with different colors
Message-ID: <96507a8e05032913353df364a8@mail.gmail.com>

This dataset below is one sample answer the questioner from our customer.

> testbank <- read.table("testbank.txt", header=T)
> testbank
     age married income gender ownhouse class
1  20-30      no   high female      yes   1st
2  30-40      no   high female      yes   1st
3  40-50      no    low female      yes   1st
4  50-60      no   high female      yes   1st
5  60-70      no   high female      yes   1st
6  20-30      no   high female      yes   1st
7  20-30      no medium female      yes   1st
8  20-30      no    low female      yes   1st
9  20-30      no   high   male      yes   1st
10 20-30      no   high female      yes   1st
11 30-40      no   high female      yes   1st
12 40-50      no   high female      yes   1st
13 50-60      no medium female      yes   1st
14 20-30      no medium female      yes   1st
15 20-30      no    low female      yes   1st
16 20-30      no   high   male      yes   1st
> testbank.tab <- table(testbank)
> library(vcd)
> mosaicplot(testbank.tab)
> mosaicplot(testbank.tab, shade=T)

I know mosaicplot (package vcd) can handle for this dataset.
I want to plot that dataset which different colors for age, income and gender.
How can I do that? Or are there any others package?
Thanks in advance for any assistance.

Jan Sabee



From Robin.Schroeder at asu.edu  Tue Mar 29 23:57:39 2005
From: Robin.Schroeder at asu.edu (Robin Schroeder)
Date: Tue, 29 Mar 2005 14:57:39 -0700
Subject: [R] Aggregating data (with more than one function)
Message-ID: <6FDC16223A03A6448994101EBF44F1A501497515@ex1.asurite.ad.asu.edu>

Dear list & Andy, 

I am hopelessly stumped, how would one add the department names as a variable?

Robin

> Robin Tori Schroeder
> International Institute for Sustainability 
> P.O. Box 873211
> Arizona State University
> Tempe, Arizona 85287-3211
> Phone: (480) 727-7290
> 
> 


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Liaw, Andy
Sent: Monday, March 28, 2005 6:45 PM
To: 'Sivakumaran Raman'; r-help at stat.math.ethz.ch
Subject: RE: [R] Aggregating data (with more than one function)


Here's one possible way, using the data you supplied:

> dat <- read.table("clipboard", header=T, row=1)
> do.call("rbind",by(dat$Salary, dat$Department, function(x) c(mean=mean(x),
total=sum(x))))
            mean  total
Finance 83925.67 251777
HR      63333.33 190000
IT      59928.67 179786
Sales   62481.67 187445

If you need the department names as a variable, you can add that easily.

HTH,
Andy

> From: Sivakumaran Raman
> 
> I have the data similar to the following in a data frame:
>     LastName   Department  Salary
> 1   Johnson    IT          56000
> 2   James      HR          54223
> 3   Howe       Finance     80000
> 4   Jones      Finance     82000
> 5   Norwood    IT          67000
> 6   Benson     Sales       76000
> 7   Smith      Sales       65778
> 8   Baker      HR          56778
> 9   Dempsey    HR          78999
> 10  Nolan      Sales       45667
> 11  Garth      Finance     89777
> 12  Jameson    IT          56786
> 
> I want to calculate both the mean salary broken down by 
> Department and 
> also the
> total amount paid out per department i.e. I want both sum(Salary) and
> mean(Salary) for each Department. Right now, I am using 
> aggregate.data.frame
> twice, creating two data frames, and then combining them 
> using data.frame.
> However, this seems to be very memory and processor intensive and is 
> taking a
> very long time on my data set. Is there a quicker way to do this?
> 
> Thanks in advance,
> Siv Raman
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Achim.Zeileis at wu-wien.ac.at  Wed Mar 30 00:06:34 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Wed, 30 Mar 2005 00:06:34 +0200 (CEST)
Subject: [R] Mosaicplot with different colors
In-Reply-To: <96507a8e05032913353df364a8@mail.gmail.com>
References: <96507a8e05032913353df364a8@mail.gmail.com>
Message-ID: <Pine.LNX.4.58.0503300000170.12549@thorin.ci.tuwien.ac.at>

On Tue, 29 Mar 2005, Jan Sabee wrote:

> This dataset below is one sample answer the questioner from our customer.
>
> > testbank <- read.table("testbank.txt", header=T)
> > testbank
>      age married income gender ownhouse class
> 1  20-30      no   high female      yes   1st
> 2  30-40      no   high female      yes   1st
> 3  40-50      no    low female      yes   1st
> 4  50-60      no   high female      yes   1st
> 5  60-70      no   high female      yes   1st
> 6  20-30      no   high female      yes   1st
> 7  20-30      no medium female      yes   1st
> 8  20-30      no    low female      yes   1st
> 9  20-30      no   high   male      yes   1st
> 10 20-30      no   high female      yes   1st
> 11 30-40      no   high female      yes   1st
> 12 40-50      no   high female      yes   1st
> 13 50-60      no medium female      yes   1st
> 14 20-30      no medium female      yes   1st
> 15 20-30      no    low female      yes   1st
> 16 20-30      no   high   male      yes   1st
> > testbank.tab <- table(testbank)
> > library(vcd)
> > mosaicplot(testbank.tab)

You don't see very much in that plot, do you? 16 observations is not too
much for 6-way information.

> > mosaicplot(testbank.tab, shade=T)
>
> I know mosaicplot (package vcd) can handle for this dataset.
> I want to plot that dataset which different colors for age, income and gender.

Do you want to have a color code which codes all three variables at the
same time? I wouldn't have a straightforward solution for that. But if you
want to shade with respect to a single variable, that might be possible.
You can use
  mosaicplot(mytable, col = ...)
and shade with respect to the last margin added.

> How can I do that? Or are there any others package?

We have a much more flexible implementation of mosaicplots (written in
grid) which will (hopefully) soon be released that allows the
specification of arbitrary color patterns in mosaicplots. If you're
interested, contact me offlist and we'll send you a devel-snapshot.
Z

> Thanks in advance for any assistance.
>
> Jan Sabee
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From T.A.Wassenaar at rug.nl  Wed Mar 30 00:17:19 2005
From: T.A.Wassenaar at rug.nl (T.A.Wassenaar)
Date: Wed, 30 Mar 2005 00:17:19 +0200
Subject: [R] Lattice - parallel: xlim and adding lines
In-Reply-To: <4249BD9D.4030208@pdf.com>
References: <web-2159588@mail3.rug.nl>
 <4249BD9D.4030208@pdf.com>
Message-ID: <web-2161385@mail3.rug.nl>


Hi Sundar,

Thanks for the reply. And, oops, the panel.parallel.new 
shouldn't be in there. That is a revised panel function to 
color according to a group. As with strange, that would 
generally be 'not-expected', i.e., in the present case, 
not having an x-axis running from -1 to 1 for all ranges. 
I would at least expect to have zero in the middle, but 
that is not so. Excuse me for not expanding 'strange' 
previously. I have read the guide.., some while ago.

Thanks again,

Tsjerk

On Tue, 29 Mar 2005 14:42:05 -0600
  Sundar Dorai-Raj <sundar.dorai-raj at pdf.com> wrote:
> 
> 
> T.A.Wassenaar wrote on 3/29/2005 2:17 PM:
>> 
>> Hi,
>> 
>> I'm trying to set the minimum and maximum in a parallel 
>>plot, but trying 
>> xlim=c(-1,1) gives strange results. Am I missing 
>>something? The call I 
>> give is:
>> 
>> parallel(~X[,c(6,9,12,15,18)]|X$ff,X,panel=panel.parallel.new,groups=X$protein,layout=c(3,1),xlim=c(-1,1)) 
>> 
>> 
>> Besides, I would like to add a reference line to the 
>>plot, but can't 
>> find how to do that.
>> 
>> I hope someone can give me a hint or two.
>> 
>> Thanks in advance,
>> 
>> Tsjerk
>> 
> 
> Tsjerk,
> 
> I don't think you'll get much help without knowing, 
>first, what "strange" means, and second, what 
>"panel.parallel.new" does. And you can always add a 
>reference line by using panel.abline in your panel 
>function.
> 
> And, from the signature:
> 
> PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html
> 
> --sundar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From greg.snow at ihc.com  Wed Mar 30 00:18:18 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Tue, 29 Mar 2005 15:18:18 -0700
Subject: [R] slide show with R
Message-ID: <s24971c6.053@lp-msg1.co.ihc.com>


Another approach is to put your commands below into a text file.

Add a line like:

tmp <- readline('Press Enter to Continue:')

everywhere you want to pause.

Then do:

source('path/to/text/file', echo=T)

it will print out the commands and execute them, but everytime it gets
to the tmp <- ... line it will pause and wait for you to press enter
before continuing on.  you can discuss the lines that have just been
executed and the current plot, then press enter for the next chunk.

hope this helps,




Greg Snow, Ph.D.
Statistical Data Center
greg.snow at ihc.com
(801) 408-8111

>>> <George_Heine at blm.gov> 03/29/05 01:54PM >>>

Trying to use R to build an interactive "slide show", to be displayed
on a
projector.  The purpose of the presentation is to show how one could
construct a simple graph using R.  It is meant as a general overview
rather
than as detailed instruction.

For example, something like the following sequence of commands.    At
lecture time, I want the interpreter to read these commands one at a
time
from a file, display and execute the command, (or two or three
commands)
and then wait for another prompt.

pale.yellow="#ffff99"
par(bg=pale.yellow)
plot(c(0,2*pi),c(-1,1),type="n",ylab="",yaxt="n")
mirror<-function(t) { c(t,rev(2*max(t)-t)) }
z<-log(1:1000)/log(1000)
zz<-z*pi/2
zzz<-mirror(mirror(zz))
polygon(zzz,sin(25*zzz)*sin(zzz),border="blue")
polygon(zzz,sin(5*zzz)*sin(zzz),border="green")
polygon(zzz,sin(zzz),lwd=2)
points(zzz,rep(0,length(zzz)),col="red",pch="|")


Wrapping the following around each command works, sort of :

a<-expression(<command>)
x<-readline(a)
eval(a)

However, this doesn't work properly for the function definition, and
it
gets very clumsy to display two or three lines as a block and then
evaluate.

Any help would be much appreciated.


<>=<>=<>=<>=<>=<>=<>=<>=<>=<>=<>
George Heine, PhD
Mathematical Analyst
National IRM Center
U.S. Bureau of Land Management
voice   (303) 236-0099
fax       (303) 236-1974
cell      (303) 905-5382
pager   gheine at my2way.com 
<>=<>=<>=<>=<>=<>=<>=<>=<>=<>=<>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From p.murrell at auckland.ac.nz  Wed Mar 30 00:37:43 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 30 Mar 2005 10:37:43 +1200
Subject: [R] Multi-plot figures with different numbers of plots	indifferent
	rows
References: <8CEECA6FD6736340AB8B3EB87769E09E4382FA@icex1.ic.ac.uk>	<Pine.LNX.4.62.0503261316330.2758@sasquatch>
	<d2bufb$d44$1@sea.gmane.org>
Message-ID: <4249D8B7.9070702@stat.auckland.ac.nz>

Hi


Earl F. Glynn wrote:
> "Anne York" <york at zipcon.net> wrote in message
> news:Pine.LNX.4.62.0503261316330.2758 at sasquatch...
> 
> 
>>par(mfrow=c(2,3)) #set up 2 rows x 3 colums
>>plot(1:10) #plot 1
>>plot(1:10) #plot 2
>>plot(1:10) #plot 3
>>par(mfg=c(2,2))  # start next plot at 2,2 instead of 2,1
>> plot(1:10)       # 4th plot
> 
> 
> If you want to leave the last plot(s) in a such a figure blank,
> and continue on with another figure, how does that work?
> 
> For example:
> 
> par(mfrow=c(2,3)) #set up 2 rows x 3 columns
> plot(1:10, main="Plot 1")
> plot(1:20, main="Plot 2")
> plot(1:30, main="Plot 3")
> par(mfg=c(2,2))  # start next plot at 2,2 instead of 2,1
> plot(1:40, main="Plot 4")
> 
> # What if 5th plot is to start on next page?
> # Why do plots 5 and 6 overlay plots 1 and 2 instead
> # of being on a new page?
> par(mfg=c(1,1))
> plot(1:50, main="Plot 5")
> plot(1:60, main="Plot 6")
> 
> If "par(mfg=c(1,1))" is left out, Plot 6 is on the next figure.
> 
> The "new=T" parameters seems like a possible solution, but gives this
> warning and is ignored:
>      Warning messages:
>      1: parameter "new" couldn't be set in high-level plot() function
> 
> par(mfrow=c(2,3)) #set up 2 rows x 3 columns
> plot(1:10, main="Plot 1", new=T)
> plot(1:20, main="Plot 2")
> plot(1:30, main="Plot 3")
> par(mfg=c(2,2))  # start next plot at 2,2 instead of 2,1
> plot(1:40, main="Plot 4")
> 
> # What if 5th plot is to start on next page?
> # Why do plots 5 and 6 overlay plots 1 and 2 instead
> # of being on a new page?
> par(mfg=c(1,1))
> plot(1:50, main="Plot 5", new=T)
> plot(1:60, main="Plot 6")
> 
> How do I create a series of plots in one figure and control
> when a new figure is created? (without using dummy blank placeholder plots)
> 
> The example above is only for discussion.  I really want to do this in a
> loop
> and create 5 plots per figure, and repeat this for many pages in a PDF file.


Does this do what you want?

layout(rbind(c(1, 2, 3),
              c(0, 4, 0)))
plot(1:10, main="Plot 1")
plot(1:20, main="Plot 2")
plot(1:30, main="Plot 3")
plot(1:40, main="Plot 4")
# new page!
plot(1:40, main="Plot 5")

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From efg at stowers-institute.org  Wed Mar 30 00:59:58 2005
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Tue, 29 Mar 2005 16:59:58 -0600
Subject: [R] Multi-plot figures with different numbers of
	plots	indifferentrows
References: <8CEECA6FD6736340AB8B3EB87769E09E4382FA@icex1.ic.ac.uk>	<Pine.LNX.4.62.0503261316330.2758@sasquatch><d2bufb$d44$1@sea.gmane.org>
	<4249D8B7.9070702@stat.auckland.ac.nz>
Message-ID: <d2cmj8$k3$1@sea.gmane.org>

"Paul Murrell" <p.murrell at auckland.ac.nz> wrote in message
news:<4249D8B7.9070702 at stat.auckland.ac.nz>...
> Does this do what you want?
>
> layout(rbind(c(1, 2, 3),
>               c(0, 4, 0)))
> plot(1:10, main="Plot 1")
> plot(1:20, main="Plot 2")
> plot(1:30, main="Plot 3")
> plot(1:40, main="Plot 4")
> # new page!
> plot(1:40, main="Plot 5")

Yes, that works nicely.  Thank you very much.

I tried this wrapped with a pdf/dev.off and it works great:

pdf("test.pdf")
  <plot statements here>
dev.off()

I guess I should always use layout and avoid using mfrow or mfcol, since
it's more flexible in general.

I can't decide if the existing behavio(u)r of mfrow/mfcol is a "bug" or a
"feature" when some plots are to be left blank, and one wants to advance to
the next figure.  With your solution, I won't need to care <g>.  Thanks.

efg



From sundar.dorai-raj at pdf.com  Wed Mar 30 01:04:14 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 29 Mar 2005 17:04:14 -0600
Subject: [R] Lattice - parallel: xlim and adding lines
In-Reply-To: <web-2161385@mail3.rug.nl>
References: <web-2159588@mail3.rug.nl> <4249BD9D.4030208@pdf.com>
	<web-2161385@mail3.rug.nl>
Message-ID: <4249DEEE.4090107@pdf.com>



T.A.Wassenaar wrote on 3/29/2005 4:17 PM:
> 
> Hi Sundar,
> 
> Thanks for the reply. And, oops, the panel.parallel.new shouldn't be in 
> there. That is a revised panel function to color according to a group. 
> As with strange, that would generally be 'not-expected', i.e., in the 
> present case, not having an x-axis running from -1 to 1 for all ranges. 
> I would at least expect to have zero in the middle, but that is not so. 
> Excuse me for not expanding 'strange' previously. I have read the 
> guide.., some while ago.
> 
> Thanks again,
> 
> Tsjerk
> 

Tsjerk,

 From panel.parallel, the x values are being scaled to c(0, 1)

x <- (as.numeric(z[subscripts[i], , ]) - llim)/dif

This puts the "Min" at x == 0 and the "Max" at x == 1 on the x-axis. If 
you want to leave it in the raw scale of the x, you will have to write 
your own panel and prepanel function, or simply determine what xlim = 
c(-1, 1) is in the scaled coordinates.

E.g.

lin.scale <- function(x, a = 0, b = 1, new.x = NULL) {
   slope <- (b - a)/diff(range(x))
   inter <- a - slope * min(x)
   if(is.null(new.x)) {
     inter + slope * x
   } else {
     inter + slope * new.x
   }
}
xlim <- lin.scale(range(iris[1:4]), new.x = c(-2, 10))
parallel(~ iris[1:4] | Species, iris, xlim = xlim)

The next question would be how to set the x labels to something other 
than "Min" and "Max" because (to me) they appear to be hard-coded in 
parallel. I will leave that question to Deepayan.

As for adding lines, you will also have to scale your reference line to 
the panel units. For my example, each panel has a x range of c(0, 1) and 
a y range of c(1, 4). E.g.

my.panel.parallel <- function(z, subscripts, col = superpose.line$col,
                               lwd = superpose.line$lwd,
                               lty = superpose.line$lty, ...) {
   superpose.line <- trellis.par.get("superpose.line")
   panel.abline(v = 0.5, lwd = 3)
   panel.parallel(z, subscripts, col, lwd, lty, ...)
}

HTH,

--sundar



> On Tue, 29 Mar 2005 14:42:05 -0600
>  Sundar Dorai-Raj <sundar.dorai-raj at pdf.com> wrote:
> 
>>
>>
>> T.A.Wassenaar wrote on 3/29/2005 2:17 PM:
>>
>>>
>>> Hi,
>>>
>>> I'm trying to set the minimum and maximum in a parallel plot, but 
>>> trying xlim=c(-1,1) gives strange results. Am I missing something? 
>>> The call I give is:
>>>
>>> parallel(~X[,c(6,9,12,15,18)]|X$ff,X,panel=panel.parallel.new,groups=X$protein,layout=c(3,1),xlim=c(-1,1)) 
>>>
>>>
>>> Besides, I would like to add a reference line to the plot, but can't 
>>> find how to do that.
>>>
>>> I hope someone can give me a hint or two.
>>>
>>> Thanks in advance,
>>>
>>> Tsjerk
>>>
>>
>> Tsjerk,
>>
>> I don't think you'll get much help without knowing, first, what 
>> "strange" means, and second, what "panel.parallel.new" does. And you 
>> can always add a reference line by using panel.abline in your panel 
>> function.
>>
>> And, from the signature:
>>
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
>> --sundar
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From tuechler at gmx.at  Wed Mar 30 00:40:12 2005
From: tuechler at gmx.at (Heinz Tuechler)
Date: Wed, 30 Mar 2005 00:40:12 +0200
Subject: [R] From FAQ 7.21 to a command like
 apply(sapply(list(f1,f2,f3),is.na),2,sum)
Message-ID: <3.0.6.32.20050330004012.007944d0@pop.gmx.net>

Dear all,

Last December there was a thread regarding the famous FAQ 7.21 "How can I
turn a string into a variable?" and asking what people want to do with
these strings.
My, certainly trivial application would be as follows:
Assume I have a data.frame containing besides others also the columns f1,
f2, ..., fn and I want to create a command like:
apply(sapply(list(f1,f2,f3),is.na),2,sum)
or
summary(cbind(f1,f2,f3))

Can I start from paste('f',1:3,sep='') to arrive at the abovementioned
command?
I tried get, parse, as.name, eval in diverse combinations but did not reach
a solution.
More generally my question is, how can I produce a "list" of variables like
x1 to xn in a convenient way within a command.
I am quite sure that this has been answered several times, but I did not
find one of these answers. So I welcome any hint, where to look.

Heinz T?chler



From pkleiber at honlab.nmfs.hawaii.edu  Wed Mar 30 01:46:33 2005
From: pkleiber at honlab.nmfs.hawaii.edu (Pierre Kleiber)
Date: Tue, 29 Mar 2005 13:46:33 -1000
Subject: [R] matching vectors against vectors
In-Reply-To: <3f177c8625945c63c175b049737a24d8@gmail.com>
References: <3f177c8625945c63c175b049737a24d8@gmail.com>
Message-ID: <4249E8D9.2060308@honlab.nmfs.hawaii.edu>

merge() may be just what you want.

    Cheers, Pierre

Piet van Remortel wrote:
> Hi all.
> 
> I have a re-occuring typical problem that I don't know how to solve 
> efficiently.
> 
> The situation is the following:   I have a number of data-sets 
> (A,B,C,...) , consisting of an identifier (e.g. 11,12,13,...,20) and a 
> measurement (e.g. in the range 100-120).   I want to compile a large 
> table, with all availabe identifiers in all data-sets in the rows, and a 
> column for every dataset.
> 
> Now, not all datasets have a measurement for every identifier, so I want 
> NA if the set does not contain the identifier.
> 
> an example for a single dataset:
> 
> #all identifiers
>  > rep <- c(10:20)
> 
> #Identifiers in my dataset (a subset of rep)
>  > rep1 <- c(12,13,15,16,17,18)
> 
> #measurements in this dataset
>  > rep1.r <- c(112,113,115,116,117,118)
> 
> #a vector which should become a column in the final table, now 
> containing all NAs
>  > res <- rep(NA,10)
> 
> #the IDs and values of my dataset together
>  > data <- cbind(rep1, rep1.r)
> 
> data looks like this:
>      rep1 rep1.r
> [1,]   12    112
> [2,]   13    113
> [3,]   15    115
> [4,]   16    116
> [5,]   17    117
> [6,]   18    118
> 
> Now, I want to put the values 112, 113, 115,... in the correct rows of 
> the final table, using the identifiers as an indicator of which row to 
> put it in, so that I finally obtain:
> 
> rep     res
> 10    NA
> 11    NA
> 12    112
> 13    113
> 14    NA
> 15    115
> 16    116
> 17    117
> 18    118
> 19    NA
> 20    NA
> 
> I try to avoid repeating 'which' a lot and filling in every identifier's 
> observation etc, since I will be doing this for thousands of rows at 
> once.    There must be an efficient way using factors, tapply etc, but I 
> have trouble finding it.  Ideal would be if this could be done in one 
> go, instead of looping.
> 
> Any suggestions ?
> 
> Thanks,
> 
> Piet
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 

-- 
-----------------------------------------------------------------
Pierre Kleiber, Ph.D       Email: pkleiber at honlab.nmfs.hawaii.edu
Fishery Biologist            Tel: 808 983-5399 / (hm)808 737-7544
NOAA Fisheries Service - Honolulu Laboratory    Fax: 808 983-2902
2570 Dole St., Honolulu, HI 96822-2396
-----------------------------------------------------------------
  "God could have told Moses about galaxies and mitochondria and
   all.  But behold... It was good enough for government work."



From deepayan at stat.wisc.edu  Wed Mar 30 02:10:28 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 29 Mar 2005 18:10:28 -0600
Subject: [R] Lattice - parallel: xlim and adding lines
In-Reply-To: <4249DEEE.4090107@pdf.com>
References: <web-2159588@mail3.rug.nl> <web-2161385@mail3.rug.nl>
	<4249DEEE.4090107@pdf.com>
Message-ID: <200503291810.28556.deepayan@stat.wisc.edu>

On Tuesday 29 March 2005 17:04, Sundar Dorai-Raj wrote:
> T.A.Wassenaar wrote on 3/29/2005 4:17 PM:
> > Hi Sundar,
> >
> > Thanks for the reply. And, oops, the panel.parallel.new shouldn't
> > be in there. That is a revised panel function to color according to
> > a group. As with strange, that would generally be 'not-expected',
> > i.e., in the present case, not having an x-axis running from -1 to
> > 1 for all ranges. I would at least expect to have zero in the
> > middle, 

Why???  Why on earth would [-1,1] be something you ``expect'' and [0,1] 
be something ``strange''? As far as I can see, neither are documented 
(and hence you shouldn't expect anything).

You can of course set 'xlim=c(0,1)', but the better way of doing that 
would have been 'scales=list(x = list(axs = "i")))'. Unfortunately, 
this doesn't currently work in 'parallel', which is a bug.

It's still not very clear to me what you want to.

> > but that is not so. Excuse me for not expanding 'strange' 
> > previously. I have read the guide.., some while ago.
> >
> > Thanks again,
> >
> > Tsjerk
>
> Tsjerk,
>
>  From panel.parallel, the x values are being scaled to c(0, 1)
>
> x <- (as.numeric(z[subscripts[i], , ]) - llim)/dif
>
> This puts the "Min" at x == 0 and the "Max" at x == 1 on the x-axis.
> If you want to leave it in the raw scale of the x, 

That doesn't really make sense. The whole point of a parallel plot is to 
show several variables (with different ranges) in a single plot with a 
common axis. This is done by transforming (shifting and linearly 
scaling) each variable to have a common range. As such, there's no 
'natural choice' for this common range, [0,1] is just as good as any 
other [a,b] for -Inf < a < b < Inf.

If you want to do something else, you might as well write your own 
prepanel and panel functions.

> you will have to 
> write your own panel and prepanel function, or simply determine what
> xlim = c(-1, 1) is in the scaled coordinates.
>
> E.g.
>
> lin.scale <- function(x, a = 0, b = 1, new.x = NULL) {
>    slope <- (b - a)/diff(range(x))
>    inter <- a - slope * min(x)
>    if(is.null(new.x)) {
>      inter + slope * x
>    } else {
>      inter + slope * new.x
>    }
> }
> xlim <- lin.scale(range(iris[1:4]), new.x = c(-2, 10))
> parallel(~ iris[1:4] | Species, iris, xlim = xlim)
>
> The next question would be how to set the x labels to something other
> than "Min" and "Max" because (to me) they appear to be hard-coded in
> parallel. I will leave that question to Deepayan.

My bad (relic of early days). I'll fix it so that they can be overridden 
by 'scales'.

> As for adding lines, you will also have to scale your reference line
> to the panel units. For my example, each panel has a x range of c(0,
> 1) and a y range of c(1, 4). E.g.
>
> my.panel.parallel <- function(z, subscripts, col =
> superpose.line$col, lwd = superpose.line$lwd,
>                                lty = superpose.line$lty, ...) {
>    superpose.line <- trellis.par.get("superpose.line")
>    panel.abline(v = 0.5, lwd = 3)
>    panel.parallel(z, subscripts, col, lwd, lty, ...)
> }
>
> HTH,
>
> --sundar
>
> > On Tue, 29 Mar 2005 14:42:05 -0600
> >
> >  Sundar Dorai-Raj <sundar.dorai-raj at pdf.com> wrote:
> >> T.A.Wassenaar wrote on 3/29/2005 2:17 PM:
> >>> Hi,
> >>>
> >>> I'm trying to set the minimum and maximum in a parallel plot, but
> >>> trying xlim=c(-1,1) gives strange results. Am I missing
> >>> something? The call I give is:
> >>>
> >>> parallel(~X[,c(6,9,12,15,18)]|X$ff,X,panel=panel.parallel.new,gro
> >>>ups=X$protein,layout=c(3,1),xlim=c(-1,1))
> >>>
> >>>
> >>> Besides, I would like to add a reference line to the plot, but
> >>> can't find how to do that.
> >>>
> >>> I hope someone can give me a hint or two.
> >>>
> >>> Thanks in advance,
> >>>
> >>> Tsjerk
> >>
> >> Tsjerk,
> >>
> >> I don't think you'll get much help without knowing, first, what
> >> "strange" means, and second, what "panel.parallel.new" does. And
> >> you can always add a reference line by using panel.abline in your
> >> panel function.
> >>
> >> And, from the signature:
> >>
> >> PLEASE do read the posting guide!
> >> http://www.R-project.org/posting-guide.html
> >>
> >> --sundar



From tlumley at u.washington.edu  Wed Mar 30 02:13:18 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 29 Mar 2005 16:13:18 -0800 (PST)
Subject: [R] From FAQ 7.21 to a command like apply(sapply(list(f1, f2, f3),
	is.na), 2, sum)
In-Reply-To: <3.0.6.32.20050330004012.007944d0@pop.gmx.net>
References: <3.0.6.32.20050330004012.007944d0@pop.gmx.net>
Message-ID: <Pine.A41.4.61b.0503291606590.222566@homer04.u.washington.edu>

On Wed, 30 Mar 2005, Heinz Tuechler wrote:

> Dear all,
>
> Last December there was a thread regarding the famous FAQ 7.21 "How can I
> turn a string into a variable?" and asking what people want to do with
> these strings.
> My, certainly trivial application would be as follows:
> Assume I have a data.frame containing besides others also the columns f1,
> f2, ..., fn and I want to create a command like:
> apply(sapply(list(f1,f2,f3),is.na),2,sum)
> or
> summary(cbind(f1,f2,f3))
>
> Can I start from paste('f',1:3,sep='') to arrive at the abovementioned
> command?

No parse,as.name or other complications needed. It's all just indexing. 
Suppose your data frame is called dd

fs<-paste('f',1:3,sep='')
apply(sapply(dd[,fs],is.na),2,sum)
summary(dd[,fs])

 	-thomas



From muster at gmail.com  Wed Mar 30 02:21:33 2005
From: muster at gmail.com (Terry Mu)
Date: Tue, 29 Mar 2005 19:21:33 -0500
Subject: [R] Is there a convenient function that can check if a vector is a
	subset of another one?
Message-ID: <b68812e7050329162159ea6df5@mail.gmail.com>

x <- 2:5
y <- 1:10

Is there something like:

is.subset(x, y) == T

Thank you,



From millerj at truman.edu  Wed Mar 30 02:32:37 2005
From: millerj at truman.edu (Jason Miller)
Date: Tue, 29 Mar 2005 18:32:37 -0600
Subject: [R] discriminant function analysis in R
Message-ID: <39b17dc1268d1390753d87a65061a26a@truman.edu>

Dear R Users,

I'm very very interested in learning how to use R to carry out a 
classification of data using discriminant function analysis.  I've 
found the MASS package and the lda function, but the examples in the 
help system are a bit over my head.  I'm not exactly sure how to 
interpret the output, for example, of if the inputs I've chosen are 
best suited to my needs.

I was hoping I could converse with a lister or two to help me get 
started on the road to involving R in this project.  (I'm willing to 
carry on the conversation using the R-users list, but I am wary of 
abusing the list.)  The alternative to R is for me to use SPSS.  It's 
what we've used up until now, but nobody loves it.  The undergraduates 
that I'm working with would have a much better learning experience if 
they were able to explore our multivariate with data using R.

By students and I have data sets with sixteen continuous variables, and 
DFA has been shown to do a reasonable job of classifying the origin of 
a new datum correctly.  We want to learn how to do this ourselves so 
that we can work on improving the DFA model by adding new variables or 
modifying the nature of the data sets we work with in a "natural way."

If you are willing to answer questions and can help me get to the point 
where I can use R to do some of my analysis, I'd write up what I 
learned about using the tool and make it available on my website and on 
http://mathbio.truman.edu.

So, if you can help, please shoot me a note.  Thanks in advance.

Jason

================================================================
Jason E. Miller, Ph.D.
Associate Professor of Mathematics
Truman State University
Kirksville, MO
http://pyrite.truman.edu/~millerj/
660.785.7430



From pkleiber at honlab.nmfs.hawaii.edu  Wed Mar 30 02:37:47 2005
From: pkleiber at honlab.nmfs.hawaii.edu (Pierre Kleiber)
Date: Tue, 29 Mar 2005 14:37:47 -1000
Subject: [R] Is there a convenient function that can check if a vector
	is a	subset of another one?
In-Reply-To: <b68812e7050329162159ea6df5@mail.gmail.com>
References: <b68812e7050329162159ea6df5@mail.gmail.com>
Message-ID: <4249F4DB.4070002@honlab.nmfs.hawaii.edu>

all(x %in% y) should do what you want:

 > x <- 2:5
 > y <- 1:10
 > all(x %in% y)
[1] TRUE
 > all(y %in% x)
[1] FALSE
 >

Cheers, Pierre

Terry Mu wrote:
> x <- 2:5
> y <- 1:10
> 
> Is there something like:
> 
> is.subset(x, y) == T
> 
> Thank you,
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
-----------------------------------------------------------------
Pierre Kleiber, Ph.D       Email: pkleiber at honlab.nmfs.hawaii.edu
Fishery Biologist            Tel: 808 983-5399 / (hm)808 737-7544
NOAA Fisheries Service - Honolulu Laboratory    Fax: 808 983-2902
2570 Dole St., Honolulu, HI 96822-2396
-----------------------------------------------------------------
  "God could have told Moses about galaxies and mitochondria and
   all.  But behold... It was good enough for government work."



From jeff.hamann at forestinformatics.com  Wed Mar 30 03:16:42 2005
From: jeff.hamann at forestinformatics.com (Jeff D. Hamann)
Date: Tue, 29 Mar 2005 17:16:42 -0800
Subject: [R] help with plotting a grid on levelplot
Message-ID: <000d01c534c6$24f8a0d0$0a00a8c0@rodan>

I'm trying to plot a grid over a levelplot

print( levelplot( var1.pred~x+y,
                 data=saw.pred,
                 aspect=mapasp(saw.pred),
                 col.regions=terrain.colors(80),
                 main=main) )

using the data...

> saw.pred
      x   y var1.pred var1.var sort
1     5   5 3.3761200 256.3363  saw
2    15   5 3.3884142 499.5695  saw
3    25   5 3.5394769 362.5490  saw
4    35   5 3.6386983 439.3200  saw
5    45   5 3.1866799 458.5570  saw
6    55   5 2.8838555 331.2363  saw
..blah...blah...blah...
15  145   5 0.8705088 256.3363  saw
16    5  15 3.1183053 455.3765  saw
17   15  15 3.2780465 443.1954  saw
18   25  15 3.7146268 435.1166  saw

which looks just fine. I know want to plot a grid such that the cells are 
grouped into 5x5 cells (or some other grid spacing) over the levelplot for a 
demonstration and I'm getting stuck when trying to modify my levelplot() 
call above to include the extra calls to panel.levelplot...

I've gotten this far,

## plot the results (10mx10m plot that's 150m x 200m)
main=expression( paste( widehat(V)[saw], ", in ", m^3, ha^{-1} ) )
print( levelplot( var1.pred~x+y,
                 data=saw.pred,
                 aspect=mapasp(saw.pred),
                 main=main,
                 panel = function(x,y,z=var1.pred )
                 {
                   panel.levelplot( x=x, y=y, z=z,
                                   subscripts=1:nrow(saw.pred),
                                   col.regions=terrain.colors(80),
                                   )
                   panel.last=grid( 15, 20, lwd=2, lty="solid", 
col="black" )
                 }
                 ) )

and the legend does match the same colors as the levelplot and the grid 
isn't centered on the levelplot either.

Could someone give me some direction? I've stayed away from modifying the 
panel.XX args when I use lattice, and now I need help.

Thanks,
Jeff.

---
Jeff D. Hamann
Forest Informatics, Inc.
PO Box 1421
Corvallis, Oregon USA 97339-1421
541-754-1428
jeff.hamann at forestinformatics.com
www.forestinformatics.com



From andy_liaw at merck.com  Wed Mar 30 03:22:27 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 29 Mar 2005 20:22:27 -0500
Subject: [R] Aggregating data (with more than one function)
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA076CFF@usctmx1106.merck.com>

> agg.dat <- do.call("rbind", by(dat$Salary, dat$Department, 
+                function(x) c(mean=mean(x), total=sum(x))))
> agg.dat <- data.frame(dept=rownames(agg.dat), agg.dat)
> agg.dat
           dept     mean  total
Finance Finance 83925.67 251777
HR           HR 63333.33 190000
IT           IT 59928.67 179786
Sales     Sales 62481.67 187445

Andy 

> From: Robin Schroeder 
> 
> Dear list & Andy, 
> 
> I am hopelessly stumped, how would one add the department 
> names as a variable?
> 
> Robin
> 
> > Robin Tori Schroeder
> > International Institute for Sustainability 
> > P.O. Box 873211
> > Arizona State University
> > Tempe, Arizona 85287-3211
> > Phone: (480) 727-7290
> > 
> > 
> 
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Liaw, Andy
> Sent: Monday, March 28, 2005 6:45 PM
> To: 'Sivakumaran Raman'; r-help at stat.math.ethz.ch
> Subject: RE: [R] Aggregating data (with more than one function)
> 
> 
> Here's one possible way, using the data you supplied:
> 
> > dat <- read.table("clipboard", header=T, row=1)
> > do.call("rbind",by(dat$Salary, dat$Department, function(x) 
> c(mean=mean(x),
> total=sum(x))))
>             mean  total
> Finance 83925.67 251777
> HR      63333.33 190000
> IT      59928.67 179786
> Sales   62481.67 187445
> 
> If you need the department names as a variable, you can add 
> that easily.
> 
> HTH,
> Andy
> 
> > From: Sivakumaran Raman
> > 
> > I have the data similar to the following in a data frame:
> >     LastName   Department  Salary
> > 1   Johnson    IT          56000
> > 2   James      HR          54223
> > 3   Howe       Finance     80000
> > 4   Jones      Finance     82000
> > 5   Norwood    IT          67000
> > 6   Benson     Sales       76000
> > 7   Smith      Sales       65778
> > 8   Baker      HR          56778
> > 9   Dempsey    HR          78999
> > 10  Nolan      Sales       45667
> > 11  Garth      Finance     89777
> > 12  Jameson    IT          56786
> > 
> > I want to calculate both the mean salary broken down by 
> > Department and 
> > also the
> > total amount paid out per department i.e. I want both 
> sum(Salary) and
> > mean(Salary) for each Department. Right now, I am using 
> > aggregate.data.frame
> > twice, creating two data frames, and then combining them 
> > using data.frame.
> > However, this seems to be very memory and processor 
> intensive and is 
> > taking a
> > very long time on my data set. Is there a quicker way to do this?
> > 
> > Thanks in advance,
> > Siv Raman
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From max.marinucci at ya.com  Wed Mar 30 04:47:28 2005
From: max.marinucci at ya.com (max.marinucci)
Date: Wed, 30 Mar 2005 04:47:28 +0200
Subject: [R] slide show with R
References: <200503292120.j2TLKVT2009025@volta.gene.com>
Message-ID: <000901c534d2$d0d9ac30$d0991a50@maxmad9rubu4nk>

Why don't use R-Winedt package?
If you have Winedt installed on your machine, it does something similar to
what you want.
Just highlight the command you want to execute from a text command file and
then press the R-paste button.
Good luck!

M.


**********************************************
Massimiliano Marinucci
http://personales.ya.com/max_mar/
Ph.D Candidate in Economics
Fundamentos del Analisis Econ?mico II
(Econom?a Cuantitativa)
Facultad de CC.EE.
Universidad Complutense Madrid
Campus de Somosaguas
Madrid - Spain
**********************************************



----- Original Message ----- 
From: "Berton Gunter" <gunter.berton at gene.com>
To: <George_Heine at blm.gov>; "'R-Help'" <r-help at stat.math.ethz.ch>
Sent: Tuesday, March 29, 2005 11:20 PM
Subject: RE: [R] slide show with R


> Oops, I should have said that you can execute the text line via the
> construction:
>
> eval(parse(text=textline))
>
>
>
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
>
> "The business of the statistician is to catalyze the scientific learning
> process."  - George E. P. Box
>
>
>
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
> > George_Heine at blm.gov
> > Sent: Tuesday, March 29, 2005 12:54 PM
> > To: R-Help
> > Subject: [R] slide show with R
> >
> >
> >
> >
> >
> > Trying to use R to build an interactive "slide show", to be
> > displayed on a
> > projector.  The purpose of the presentation is to show how one could
> > construct a simple graph using R.  It is meant as a general
> > overview rather
> > than as detailed instruction.
> >
> > For example, something like the following sequence of commands.    At
> > lecture time, I want the interpreter to read these commands
> > one at a time
> > from a file, display and execute the command, (or two or
> > three commands)
> > and then wait for another prompt.
> >
> > pale.yellow="#ffff99"
> > par(bg=pale.yellow)
> > plot(c(0,2*pi),c(-1,1),type="n",ylab="",yaxt="n")
> > mirror<-function(t) { c(t,rev(2*max(t)-t)) }
> > z<-log(1:1000)/log(1000)
> > zz<-z*pi/2
> > zzz<-mirror(mirror(zz))
> > polygon(zzz,sin(25*zzz)*sin(zzz),border="blue")
> > polygon(zzz,sin(5*zzz)*sin(zzz),border="green")
> > polygon(zzz,sin(zzz),lwd=2)
> > points(zzz,rep(0,length(zzz)),col="red",pch="|")
> >
> >
> > Wrapping the following around each command works, sort of :
> >
> > a<-expression(<command>)
> > x<-readline(a)
> > eval(a)
> >
> > However, this doesn't work properly for the function
> > definition, and it
> > gets very clumsy to display two or three lines as a block and then
> > evaluate.
> >
> > Any help would be much appreciated.
> >
> >
> > <>=<>=<>=<>=<>=<>=<>=<>=<>=<>=<>
> > George Heine, PhD
> > Mathematical Analyst
> > National IRM Center
> > U.S. Bureau of Land Management
> > voice   (303) 236-0099
> > fax       (303) 236-1974
> > cell      (303) 905-5382
> > pager   gheine at my2way.com
> > <>=<>=<>=<>=<>=<>=<>=<>=<>=<>=<>
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>
>



From ssherman at cemml.colostate.edu  Wed Mar 30 05:05:35 2005
From: ssherman at cemml.colostate.edu (ssherman)
Date: Tue, 29 Mar 2005 20:05:35 -0700
Subject: [R] dependency help for FC2 rpm
Message-ID: <428EE889@webmail.colostate.edu>

That worked great. Thank you.

>===== Original Message From Peter Dalgaard <p.dalgaard at biostat.ku.dk> =====
>Steve Sherman <ssherman at cemml.colostate.edu> writes:
>
>> I am having difficulty with dependencies for the R rpm for Fedora Core 2.
>>
>> In attempting to load R-2.0.0.0.fdr.1.fc2.i386.rpm it fails the
>> libtk8.4.so dependency even though I have this library loaded. The
>> library is located in:  /usr/local/lib.
>>
>> How might I tell R where to find this library? I am new to Linux and
>> loading rpms so I am hoping there is a simple answer and that the
>> problem is related to my inexperience. Thanks in advance for any
>> assistance.
>
>You need to install the RPM dependencies that it depends on. A
>libtk8.4.so in /usr/local/lib doesn't come from a standard RPM. You
>need to install the tk (and tcl) RPM from CD's or a Fedora repository.
>
>--
>   O__  ---- Peter Dalgaard             Blegdamsvej 3
>  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
> (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
>~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From deepayan at stat.wisc.edu  Wed Mar 30 05:21:33 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 29 Mar 2005 21:21:33 -0600
Subject: [R] help with plotting a grid on levelplot
In-Reply-To: <000d01c534c6$24f8a0d0$0a00a8c0@rodan>
References: <000d01c534c6$24f8a0d0$0a00a8c0@rodan>
Message-ID: <200503292121.33494.deepayan@stat.wisc.edu>

On Tuesday 29 March 2005 19:16, Jeff D. Hamann wrote:
> I'm trying to plot a grid over a levelplot
>
> print( levelplot( var1.pred~x+y,
>                  data=saw.pred,
>                  aspect=mapasp(saw.pred),
>                  col.regions=terrain.colors(80),
>                  main=main) )
>
> using the data...
>
> > saw.pred
>
>       x   y var1.pred var1.var sort
> 1     5   5 3.3761200 256.3363  saw
> 2    15   5 3.3884142 499.5695  saw
> 3    25   5 3.5394769 362.5490  saw
> 4    35   5 3.6386983 439.3200  saw
> 5    45   5 3.1866799 458.5570  saw
> 6    55   5 2.8838555 331.2363  saw
> ..blah...blah...blah...
> 15  145   5 0.8705088 256.3363  saw
> 16    5  15 3.1183053 455.3765  saw
> 17   15  15 3.2780465 443.1954  saw
> 18   25  15 3.7146268 435.1166  saw
>
> which looks just fine. I know want to plot a grid such that the cells
> are grouped into 5x5 cells (or some other grid spacing) over the
> levelplot for a demonstration and I'm getting stuck when trying to
> modify my levelplot() call above to include the extra calls to
> panel.levelplot...
>
> I've gotten this far,
>
> ## plot the results (10mx10m plot that's 150m x 200m)
> main=expression( paste( widehat(V)[saw], ", in ", m^3, ha^{-1} ) )
> print( levelplot( var1.pred~x+y,
>                  data=saw.pred,
>                  aspect=mapasp(saw.pred),
>                  main=main,
>                  panel = function(x,y,z=var1.pred )
>                  {
>                    panel.levelplot( x=x, y=y, z=z,
>                                    subscripts=1:nrow(saw.pred),
>                                    col.regions=terrain.colors(80),
>                                    )
>                    panel.last=grid( 15, 20, lwd=2, lty="solid",
> col="black" )

You are not allowed to use base graphics functions (like grid) in 
lattice panel functions. You have to use grid (the package, not the 
function) functions. There are many such functions defined in lattice 
which can be useful, in this case 'panel.grid' or more likely 
'panel.abline'.

I'm not sure I understand your attempted usage though; you seem to 
assign the value of grid() (which would be NULL) to a variable called 
panel.last. This does not have any possible use that I can see.

>                  }
>                  ) )
>
> and the legend does match the same colors as the levelplot and the
> grid isn't centered on the levelplot either.
>
> Could someone give me some direction? I've stayed away from modifying
> the panel.XX args when I use lattice, and now I need help.

Unless you understand very well what you are doing, I would stay away 
from micro-managing calls to complicated panel functions like 
panel.levelplot. In particular, I would suggest something like

panel = function(...) {
  panel.levelplot(...)
  panel.abline(h=<whatever>, v=<whatever>)
}


> Thanks,
> Jeff.
>
> ---
> Jeff D. Hamann
> Forest Informatics, Inc.
> PO Box 1421
> Corvallis, Oregon USA 97339-1421
> 541-754-1428
> jeff.hamann at forestinformatics.com
> www.forestinformatics.com
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From john.maindonald at anu.edu.au  Wed Mar 30 06:32:50 2005
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 30 Mar 2005 14:32:50 +1000
Subject: [R] Base and lattice graphics on the same graphics page
Message-ID: <9c4fa8ef707059a5a35d24c8bf008259@anu.edu.au>

Although base graphics does not mix with lattice in the one graph,
I've found that print.trellis(position=..., ) and the use of 
par(fig=...)
to put regular and trellis graphics on the one graphics page works
like a treat, at least in version 2.0.1 of R.  [Base graphics functions
that are themselves inconsistent with par(fig=...) are obviously
disallowed.]

I am wondering whether there are caveats of which I and others
should be aware, or whether there is a risk that the ongoing
development of R's graphics abilities will render such a cohabitation
unworkably fractious.

Example:

gph <- bwplot(voice.part ~ height, data=singer)
print(gph, position=c(0, 0.5, 1, 1)) # x0, y0, x1, y1
par(fig=c(0, 1, 0,0.5), new=TRUE) # x0, x1, y0, y1
boxplot(height ~ voice.part, data=singer, horiz=TRUE)

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Bioinformation Science, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.



From deepayan at stat.wisc.edu  Wed Mar 30 06:59:51 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 29 Mar 2005 22:59:51 -0600
Subject: [R] Base and lattice graphics on the same graphics page
In-Reply-To: <9c4fa8ef707059a5a35d24c8bf008259@anu.edu.au>
References: <9c4fa8ef707059a5a35d24c8bf008259@anu.edu.au>
Message-ID: <200503292259.52001.deepayan@stat.wisc.edu>

On Tuesday 29 March 2005 22:32, John Maindonald wrote:
> Although base graphics does not mix with lattice in the one graph,
> I've found that print.trellis(position=..., ) and the use of
> par(fig=...)
> to put regular and trellis graphics on the one graphics page works
> like a treat, at least in version 2.0.1 of R.  [Base graphics
> functions that are themselves inconsistent with par(fig=...) are
> obviously disallowed.]
>
> I am wondering whether there are caveats of which I and others
> should be aware, or whether there is a risk that the ongoing
> development of R's graphics abilities will render such a cohabitation
> unworkably fractious.

Paul would know better, but I think that's unlikely. In fact, the 
gridBase package allows you to do use grid (and hence lattice) 
functions to add to a base plot, as well as (I didn't realize this 
before) the other way round. The only caveat is that resizing the 
device may mess things up. 

You may have to be careful with new devices. Your example pasted on a 
fresh session (tested only on r-devel) starts a new page for the 
boxplot since it thinks that new=TRUE doesn't make sense (because 
there's no 'old' plot yet).

Deepayan



From cuiczhao at yahoo.com  Wed Mar 30 08:11:08 2005
From: cuiczhao at yahoo.com (Cuichang Zhao)
Date: Tue, 29 Mar 2005 22:11:08 -0800 (PST)
Subject: [R] how i can get input from "user input"
Message-ID: <20050330061109.53769.qmail@web30708.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050329/169b4e0d/attachment.pl

From ashajayanthi at hotmail.com  Wed Mar 30 08:20:37 2005
From: ashajayanthi at hotmail.com (Asha Jayanthi)
Date: Wed, 30 Mar 2005 06:20:37 +0000
Subject: [R] 2d plotting and colours
In-Reply-To: <mailman.0.1112156633.31311.r-help@stat.math.ethz.ch>
Message-ID: <BAY10-F4856867F083DD9F7AE0270DC460@phx.gbl>

Hi!

I am new to R just 3 days in it and i apologize if my questions seem very 
trivial and consumed your valuable time.

I am coding in perl and i stumbled upon R regarding plotting good 
statistical graphs.

I tried the kmean clustering for a large matrix ,say > 150 * 150 . I tried 
the example code given in the tutorial to perform 2d plot

# i ranges from 2 to 10
cl <- kmeans(x, i, 20)
plot(x, col = cl$cluster)
points(cl$centers, col = 1:i )

I see that there are only 8 colours defined , namely 
black,red,green,blue,cyan,magenta,yello,gray.

How should i set my colour preferences to obtain my palette of colours? I  
checked in the totorial which talks about R.colors and palatte , but i 
failed to understand how to set it.

Thank You

Asha




From yzhang4 at une.edu.au  Wed Mar 30 08:33:16 2005
From: yzhang4 at une.edu.au (Yuandan Zhang)
Date: Wed, 30 Mar 2005 16:33:16 +1000
Subject: [R] dependency help for FC2 rpm
In-Reply-To: <x23buegqvw.fsf@turmalin.kubism.ku.dk>
References: <4249AC12.1020007@cemml.colostate.edu>
	<x23buegqvw.fsf@turmalin.kubism.ku.dk>
Message-ID: <20050330163316.3343d839.yzhang4@une.edu.au>

On 29 Mar 2005 22:04:51 +0200
Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:

> Steve Sherman <ssherman at cemml.colostate.edu> writes:
> 
> > I am having difficulty with dependencies for the R rpm for Fedora Core 2.
> > 
> > In attempting to load R-2.0.0.0.fdr.1.fc2.i386.rpm it fails the
> > libtk8.4.so dependency even though I have this library loaded. The
> > library is located in:  /usr/local/lib.
> > 
> > How might I tell R where to find this library? I am new to Linux and
> > loading rpms so I am hoping there is a simple answer and that the
> > problem is related to my inexperience. Thanks in advance for any
> > assistance.

It is most likely the rpm looks for this lib at /usr/lib, you may create a symbolic link 
eg 

cd /usr/lib
ln -s /usr/local/libtk8.4.so .

of cource, you must have a root access to do this.

> 
> You need to install the RPM dependencies that it depends on. A
> libtk8.4.so in /usr/local/lib doesn't come from a standard RPM. You
> need to install the tk (and tcl) RPM from CD's or a Fedora repository.
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Wed Mar 30 08:43:02 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 30 Mar 2005 08:43:02 +0200
Subject: [R] how i can get input from "user input"
In-Reply-To: <20050330061109.53769.qmail@web30708.mail.mud.yahoo.com>
References: <20050330061109.53769.qmail@web30708.mail.mud.yahoo.com>
Message-ID: <424A4A76.9090505@statistik.uni-dortmund.de>

Cuichang Zhao wrote:

> Hello, 
> Could you please tell me how i can get an input from the user in R?

Depends on the kind of input.

See, e.g., ?scan or ?menu

Uwe Ligges


> C-Ming 
>  
> Mar 29, 2005
> 
> 		
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Matthias.Templ at statistik.gv.at  Wed Mar 30 08:45:54 2005
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Wed, 30 Mar 2005 08:45:54 +0200
Subject: [R] 2d plotting and colours
Message-ID: <83536658864BC243BE3C06D7E936ABD5027BA99E@xchg1.statistik.local>

Hi!

There are more than 8 colors.

x <- rbind(matrix(rnorm(100, sd = 0.3), ncol = 2),
                matrix(rnorm(100, mean = 1, sd = 0.3), ncol = 2))
     
(cl <- kmeans(x, i, 20))
    
s <- c("tomato4", "turquoise", "slateblue", "wheat", "snow", "skyblue",
"peru", "pink")
# see at:    
colors()
     
plot(x, col = s)
     
points(cl$centers, col = s, pch = 8, cex=2)


Best,
Matthias




> Hi!
> 
> I am new to R just 3 days in it and i apologize if my 
> questions seem very 
> trivial and consumed your valuable time.
> 
> I am coding in perl and i stumbled upon R regarding plotting good 
> statistical graphs.
> 
> I tried the kmean clustering for a large matrix ,say > 150 * 
> 150 . I tried 
> the example code given in the tutorial to perform 2d plot
> 
> # i ranges from 2 to 10
> cl <- kmeans(x, i, 20)
> plot(x, col = cl$cluster)
> points(cl$centers, col = 1:i )
> 
> I see that there are only 8 colours defined , namely 
> black,red,green,blue,cyan,magenta,yello,gray.
> 
> How should i set my colour preferences to obtain my palette 
> of colours? I  
> checked in the totorial which talks about R.colors and 
> palatte , but i 
> failed to understand how to set it.
> 
> Thank You
> 
> Asha
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read 
> the posting guide! http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Wed Mar 30 09:18:04 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 30 Mar 2005 09:18:04 +0200
Subject: [R] 2d plotting and colours
In-Reply-To: <83536658864BC243BE3C06D7E936ABD5027BA99E@xchg1.statistik.local>
References: <83536658864BC243BE3C06D7E936ABD5027BA99E@xchg1.statistik.local>
Message-ID: <424A52AC.8050800@statistik.uni-dortmund.de>

TEMPL Matthias wrote:

> Hi!
> 
> There are more than 8 colors.

Yes, e.g. for rgb space there are 16777216, see ?rgb.

Uwe Ligges



> x <- rbind(matrix(rnorm(100, sd = 0.3), ncol = 2),
>                 matrix(rnorm(100, mean = 1, sd = 0.3), ncol = 2))
>      
> (cl <- kmeans(x, i, 20))
>     
> s <- c("tomato4", "turquoise", "slateblue", "wheat", "snow", "skyblue",
> "peru", "pink")
> # see at:    
> colors()
>      
> plot(x, col = s)
>      
> points(cl$centers, col = s, pch = 8, cex=2)
> 
> 
> Best,
> Matthias
> 
> 
> 
> 
> 
>>Hi!
>>
>>I am new to R just 3 days in it and i apologize if my 
>>questions seem very 
>>trivial and consumed your valuable time.
>>
>>I am coding in perl and i stumbled upon R regarding plotting good 
>>statistical graphs.
>>
>>I tried the kmean clustering for a large matrix ,say > 150 * 
>>150 . I tried 
>>the example code given in the tutorial to perform 2d plot
>>
>># i ranges from 2 to 10
>>cl <- kmeans(x, i, 20)
>>plot(x, col = cl$cluster)
>>points(cl$centers, col = 1:i )
>>
>>I see that there are only 8 colours defined , namely 
>>black,red,green,blue,cyan,magenta,yello,gray.
>>
>>How should i set my colour preferences to obtain my palette 
>>of colours? I  
>>checked in the totorial which talks about R.colors and 
>>palatte , but i 
>>failed to understand how to set it.
>>
>>Thank You
>>
>>Asha
>>
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list 
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read 
>>the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Tom.Mulholland at dpi.wa.gov.au  Wed Mar 30 09:59:46 2005
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Wed, 30 Mar 2005 15:59:46 +0800
Subject: [R] 2d plotting and colours
Message-ID: <33F91FB3FDF42E4180428AC66A5CF30B02D3BAAE@afhex01.dpi.wa.gov.au>

And getting back to your question about the palette

there are a lot of ways to do this

assuming you have just started a session 

palette() 
# will give 
#[1] "black"   "red"     "green3"  "blue"    "cyan"   
#[6] "magenta" "yellow"  "gray"  

palette(rainbow(24))  # There's also 'heat.colors' & 'topo.colors'
palette()

# [1] "red"         "#FF4000"     "#FF8000"    
# [4] "#FFBF00"     "yellow"      "#BFFF00"    
# [7] "#80FF00"     "#40FF00"     "green"      
#[10] "#00FF40"     "#00FF80"     "#00FFBF"    
#[13] "cyan"        "deepskyblue" "#0080FF"    
#[16] "#0040FF"     "blue"        "#4000FF"    
#[19] "#8000FF"     "#BF00FF"     "magenta"    
#[22] "#FF00BF"     "#FF0080"     "#FF0040"   

palette(rgb((0:15)/15, g=0,b=0, names=paste("red",0:15,sep=".")))
palette()
# [1] "black"   "#110000" "#220000" "#330000" "#440000"
# [6] "#550000" "#660000" "#770000" "#880000" "#990000"
#[11] "#AA0000" "#BB0000" "#CC0000" "#DD0000" "red2"   
#[16] "red" 

If you are looking to use colours that take account of colour blindness
you could try the package dichromat. (I think 2.1 will have some of this inbuilt)

Once you look through the help files associated with some of these options you 
will find the way that best suits your method of working.

Tom






> -----Original Message-----
> From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
> Sent: Wednesday, 30 March 2005 3:18 PM
> To: TEMPL Matthias
> Cc: r-help at stat.math.ethz.ch; Asha Jayanthi
> Subject: Re: [R] 2d plotting and colours
> 
> 
> TEMPL Matthias wrote:
> 
> > Hi!
> > 
> > There are more than 8 colors.
> 
> Yes, e.g. for rgb space there are 16777216, see ?rgb.
> 
> Uwe Ligges
> 
> 
> 
> > x <- rbind(matrix(rnorm(100, sd = 0.3), ncol = 2),
> >                 matrix(rnorm(100, mean = 1, sd = 0.3), ncol = 2))
> >      
> > (cl <- kmeans(x, i, 20))
> >     
> > s <- c("tomato4", "turquoise", "slateblue", "wheat", 
> "snow", "skyblue",
> > "peru", "pink")
> > # see at:    
> > colors()
> >      
> > plot(x, col = s)
> >      
> > points(cl$centers, col = s, pch = 8, cex=2)
> > 
> > 
> > Best,
> > Matthias
> > 
> > 
> > 
> > 
> > 
> >>Hi!
> >>
> >>I am new to R just 3 days in it and i apologize if my 
> >>questions seem very 
> >>trivial and consumed your valuable time.
> >>
> >>I am coding in perl and i stumbled upon R regarding plotting good 
> >>statistical graphs.
> >>
> >>I tried the kmean clustering for a large matrix ,say > 150 * 
> >>150 . I tried 
> >>the example code given in the tutorial to perform 2d plot
> >>
> >># i ranges from 2 to 10
> >>cl <- kmeans(x, i, 20)
> >>plot(x, col = cl$cluster)
> >>points(cl$centers, col = 1:i )
> >>
> >>I see that there are only 8 colours defined , namely 
> >>black,red,green,blue,cyan,magenta,yello,gray.
> >>
> >>How should i set my colour preferences to obtain my palette 
> >>of colours? I  
> >>checked in the totorial which talks about R.colors and 
> >>palatte , but i 
> >>failed to understand how to set it.
> >>
> >>Thank You
> >>
> >>Asha
> >>
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list 
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read 
> >>the posting guide! http://www.R-project.org/posting-guide.html
> >>
> > 
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From r.hankin at soc.soton.ac.uk  Wed Mar 30 10:28:08 2005
From: r.hankin at soc.soton.ac.uk (Robin Hankin)
Date: Wed, 30 Mar 2005 09:28:08 +0100
Subject: [R] Recall() and sapply()
Message-ID: <ae7dd0c40fdd93fcf0d522d99760678d@soc.soton.ac.uk>

Hi.

I'm having difficulty following the advice given in help(Recall).  
Consider the two
following toy functions:


f1 <- function(n){
   if(length(n)>1){return(sapply(n,f1))}
   matrix(n,n,n)
}

f2 <- function(n){
   if(length(n)>1){return(sapply(n,Recall))}
   matrix(n,n,n)
}


f1() works as desired (that is, f(1:3), say, gives me a three element 
list whose i-th element
is an i-by-i matrix whose elements are all i).

But f2() doesn't.

How do I modify either function to use Recall()?  What exactly is 
Recall() calling here?




--
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From tuechler at gmx.at  Wed Mar 30 09:32:40 2005
From: tuechler at gmx.at (Heinz Tuechler)
Date: Wed, 30 Mar 2005 09:32:40 +0200
Subject: [R] From FAQ 7.21 to a command like
	apply(sapply(list(f1,f2,f3),is.na),2,sum)
In-Reply-To: <Pine.A41.4.61b.0503291606590.222566@homer04.u.washington.e
 du>
References: <3.0.6.32.20050330004012.007944d0@pop.gmx.net>
	<3.0.6.32.20050330004012.007944d0@pop.gmx.net>
Message-ID: <3.0.6.32.20050330093240.007c6b70@pop.gmx.net>

At 16:13 29.03.2005 -0800, Thomas Lumley wrote:
>On Wed, 30 Mar 2005, Heinz Tuechler wrote:
>
>> Dear all,
>>
>> Last December there was a thread regarding the famous FAQ 7.21 "How can I
>> turn a string into a variable?" and asking what people want to do with
>> these strings.
>> My, certainly trivial application would be as follows:
>> Assume I have a data.frame containing besides others also the columns f1,
>> f2, ..., fn and I want to create a command like:
>> apply(sapply(list(f1,f2,f3),is.na),2,sum)
>> or
>> summary(cbind(f1,f2,f3))
>>
>> Can I start from paste('f',1:3,sep='') to arrive at the abovementioned
>> command?
>
>No parse,as.name or other complications needed. It's all just indexing. 
>Suppose your data frame is called dd
>
>fs<-paste('f',1:3,sep='')
>apply(sapply(dd[,fs],is.na),2,sum)
>summary(dd[,fs])
>
> 	-thomas
>
>
Thank you, Thomas, for your answer. I was curious if there was a simple way
to do this without referring to the data.frame, so that the resulting
command would correspond in its effect exactly to the abovementioned examples.
It's not urgent, but I will try further.

Many thanks

Heinz



From tuechler at gmx.at  Wed Mar 30 09:51:06 2005
From: tuechler at gmx.at (Heinz Tuechler)
Date: Wed, 30 Mar 2005 09:51:06 +0200
Subject: [R] From FAQ 7.21 to a command
	likeapply(sapply(list(f1,f2,f3),is.na),2,sum)
In-Reply-To: <3.0.6.32.20050330093240.007c6b70@pop.gmx.net>
References: <Pine.A41.4.61b.0503291606590.222566@homer04.u.washington.e du>
	<3.0.6.32.20050330004012.007944d0@pop.gmx.net>
	<3.0.6.32.20050330004012.007944d0@pop.gmx.net>
Message-ID: <3.0.6.32.20050330095106.007ca1e0@pop.gmx.net>

At 09:32 30.03.2005 +0200, Heinz Tuechler wrote:
>At 16:13 29.03.2005 -0800, Thomas Lumley wrote:
>>On Wed, 30 Mar 2005, Heinz Tuechler wrote:
>>
>>> Dear all,
>>>
>>> Last December there was a thread regarding the famous FAQ 7.21 "How can I
>>> turn a string into a variable?" and asking what people want to do with
>>> these strings.
>>> My, certainly trivial application would be as follows:
>>> Assume I have a data.frame containing besides others also the columns f1,
>>> f2, ..., fn and I want to create a command like:
>>> apply(sapply(list(f1,f2,f3),is.na),2,sum)
>>> or
>>> summary(cbind(f1,f2,f3))
>>>
>>> Can I start from paste('f',1:3,sep='') to arrive at the abovementioned
>>> command?
>>
>>No parse,as.name or other complications needed. It's all just indexing. 
>>Suppose your data frame is called dd
>>
>>fs<-paste('f',1:3,sep='')
>>apply(sapply(dd[,fs],is.na),2,sum)
>>summary(dd[,fs])
>>
>> 	-thomas
>>
>>
>Thank you, Thomas, for your answer. I was curious if there was a simple way
>to do this without referring to the data.frame, so that the resulting
>command would correspond in its effect exactly to the abovementioned
examples.
>It's not urgent, but I will try further.
>
>Many thanks
>
>Heinz
>
Continuation:
Maybe not an elegant solution, but it seems to work:
apply(sapply(eval(parse(text=paste('list(',paste('f',1:3,sep='',
collapse=','),')'))) ,is.na),2,sum)
What I missed in my earlier attempts was "collapse=','".

Heinz



From mailingr at yahoo.it  Wed Mar 30 12:02:36 2005
From: mailingr at yahoo.it (. .)
Date: Wed, 30 Mar 2005 12:02:36 +0200 (CEST)
Subject: [R] locfit
Message-ID: <20050330100237.87405.qmail@web25805.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050330/6117cd54/attachment.pl

From r+Steven.Murdoch at cl.cam.ac.uk  Wed Mar 30 12:06:17 2005
From: r+Steven.Murdoch at cl.cam.ac.uk (Steven J. Murdoch)
Date: Wed, 30 Mar 2005 11:06:17 +0100
Subject: [R] Finding the "height of a line of text" for axis
Message-ID: <20050330100617.GA7312@cl.cam.ac.uk>

I would like to draw only the ticks of an axis, but not the axis
itself. I don't think this can be done using axis(), so I am trying to
write a cut-down version in R, which only draws ticks.

The point at which I am stuck is that the length of a tick is set by
par("tcl") as a fraction of the "height of a line of text". So I would
like to draw a line whose length is also this length. However I cannot
find out how to convert the into units I can pass into lines(). I
thought par("cxy"), but it is too large, as is shown in the code
below. Here the red tick marks are longer than the black ones created
by axis. I have found the relevant function in plot.c:
 "GConvertYUnits(Rf_gpptr(dd)->tcl, LINES, NFC, dd);"
but can't find the corresponding R function.

Can anyone suggest how to find this out, or solve the problem in a
different way?

# Inward pointing ticks
par("tcl"=1)

drawticks <- function(at) {
 # Start of the ticks
 base<-par("usr")[1]
 # Length of the ticks
 l<-par("cxy")[2]*par("tcl")
 for (i in at) {
  lines(c(base,base+l),rep(i,2),col="red")
 }
}

# Test plot
plot(c(1,2,3), axes=FALSE)
# Draw ticks in red
drawticks(axTicks(2))
# Overprint with normal axis
axis(2, axTicks(2))

Thanks in advance,
Steven Murdoch.
-- 
w: http://www.cl.cam.ac.uk/users/sjm217/



From Matthias.Templ at statistik.gv.at  Wed Mar 30 12:16:56 2005
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Wed, 30 Mar 2005 12:16:56 +0200
Subject: [R] Problems with lpSolve/Memory ? R crashes
Message-ID: <83536658864BC243BE3C06D7E936ABD5027BA9A0@xchg1.statistik.local>

Hello!

I have a curious problem, which I cannot solve.
With my code I solve thousands of small linear programs with the package lpSolve automatically.
But R crashes sometimes (~always, but always on different linear programs) in a strange way.
For illustration, I tried to prepare a simple example, which shows the nature of the problem.
The function aaa (see below) declares some constants (only in this special example) and in the end it solves the linear program.

aaa(1)
      [,1] [,2]
 [1,]    0    0
 [2,]    0    0
 [3,]    0    0
 [4,]    0    0
 [5,]   52    0
 [6,]    2    2
 [7,]    0    0
 [8,]    2    0
 [9,]    0    0
[10,]    0    0
[11,]    0    0
[12,]    0    0
[13,]   54    0

Works fine.
Now I make the *same* calculation, say 1000 times:
aaa(1000)
R (I have tried it with R2.0.1, 2.0.0, 1.9.1, 2.1.0dev) crashes completly - without warning and error message under Windows XP, Intel Pentium 3 with 256 MB RAM
Under Linux SuSe 8.2 R (2.0.1) it crashes again, but in this case I get the following message:
Calloc of 40004 bytes failed on line 114 of file lpkit.c
...
Calloc of 80008 bytes failed on line 113 of file lpkit.c
Error: cannot allocate vector of size 3 Kb

Now I?m completly lost. Solving the linear program one time makes no problem. Solving it twice in the same way makes no problem either. Running the same calculation, say 1000 times, causes a crash. Why should there be a problem with memory?

For any hint, I would be really happy. 
Thank you,
Matthias


### ---------- function aaa ------------

aaa <- function(amount=1){
f.obj <- rep(0,33)

w <- c(3,4,5,6,11,13,17,22,25,26,27,28,33)

m <- matrix(c(0,0,1,1,1,1,0,0,0,0,-1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,

              0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,-1,0,0,0,0,0,0,0,0,0,0,0,

              0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1,-1,-1,-1,0,0,0,0,1,

              0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,

              0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,

              0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,0,0,

              0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,0,

              0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,

              0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,

              0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,

              0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,

              0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,

              0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,

              0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,0,0,0,0,1

              ),ncol=33,byrow=TRUE)

f.dir <- c("=","=","=","=","=","=","=","=","=","=","=",
"=","=","=","=","=","=","=","=","=","=","=","=",
"=","=","=","=","=","=","=","=","=","=")

f.rhs <- c(-52,0,54,0,2,0,0,0,0,0,0,0,0,0)

lp.out <- matrix( ncol = 2, nrow = 13 )

for(ii in 1:amount){ # - simple iterate the same

for( i in 1:13 ){

	f.obj[ w[i] ] <- 1

	lp.out[ i, 1 ] <- lp("min", f.obj, m, f.dir, f.rhs)$objval

	lp.out[ i, 2 ] <- lp("max", f.obj, m, f.dir, f.rhs)$objval

	f.obj <- rep( 0, 33 )

}

}
lp.out

}



From 0034058 at fudan.edu.cn  Wed Mar 30 12:36:37 2005
From: 0034058 at fudan.edu.cn (ronggui)
Date: Wed, 30 Mar 2005 18:36:37 +0800
Subject: [R] about memory
Message-ID: <20050330183637.481b3c46.0034058@fudan.edu.cn>

here is my system memory:
ronggui at 0[ronggui]$ free
             total       used       free     shared    buffers     cached
Mem:        256728      79440     177288          0       2296      36136
-/+ buffers/cache:      41008     215720
Swap:       481908      60524     421384

and i want to cluster my data using hclust.my data has 3 variables and 10000 cases.but it fails and saying have not enough memory for the vector size.  I read the help doc and use $R --max-vsize=800M to start the R 2.1.0beta under debian linux.but it still can not get the solution.so is my pc'memory not enough to carry this analysis or my mistake on setting the memory?

thank you.



From lfanchon at vet-alfort.fr  Wed Mar 30 14:06:49 2005
From: lfanchon at vet-alfort.fr (Laurent Fanchon)
Date: Wed, 30 Mar 2005 14:06:49 +0200
Subject: [R] Habituation model
Message-ID: <424A9659.2070606@vet-alfort.fr>

Dear all, 

I am looking at habituation of dogs trotting on a treadmill. 
I record the ground reaction force and I analyze it with several discrete variables (maximum, minimum,...)
For each variable, I get between 40 and 50 data per sample. 

I record data at time 1 min, 2 min, and 4 min a day, and I have 4 days of measurement (one day a week). 
That means I have 12 samples : Day1_Min1, Day1_Min2, Day1_Min4, Day2_Min1,...

Furthermore, I have 28 dogs to analyze. 

My questions is : when can I consider the data stabilized?
The problem is I am studying habituation with several sessions. 
It seems logical that values from each first minute could be very dissimilar to others. 
It is not a fully linear training system. 
I have already done some ANOVAs with "Day" and "Min" factors. I found a significant effect.
It is quite logical because the dog is learning. The question is then when does it stop learning? or more precisely when is it trained enough to be analyzed?

I could do comparisons among all samples with Student test, but it is surely a simple approach. 

I can presuppose the maximal allowed variability for each variable : in the region of 5%. 

I am really new to both R and stats so if these questions are very simple and I am just missing something, suggestions about good texts or examples on R would be great. 
I am generating data with Scilab, I have a single matrix corresponding to each dog. But I can change it if needed. 

Any help would be greatly appreciated

Thanks

Laurent Fanchon
DVM, MS
Ecole Nationale Veterinaire d'Alfort
France



From butchar.2 at osu.edu  Wed Mar 30 14:34:13 2005
From: butchar.2 at osu.edu (jon butchar)
Date: Wed, 30 Mar 2005 07:34:13 -0500
Subject: [R] about memory
In-Reply-To: <20050330183637.481b3c46.0034058@fudan.edu.cn>
References: <20050330183637.481b3c46.0034058@fudan.edu.cn>
Message-ID: <20050330073413.25a2b5f0.butchar.2@osu.edu>

How much memory is free when R fails (e.g., what does "top" show while trying to run your clustering)?  If there's still a sizeable amount of free memory you may have to look into the system limits, maximum data segment size in particular.  Many Linux distros have it set to "unlimited" but default Debian may not.  If this turns out to be the problem, please do not, _do not_ raise it to "unlimited," but only to enough for R to work.

hth,

jon b



On Wed, 30 Mar 2005 18:36:37 +0800
ronggui <0034058 at fudan.edu.cn> wrote:

> here is my system memory:
> ronggui at 0[ronggui]$ free
>              total       used       free     shared    buffers     cached
> Mem:        256728      79440     177288          0       2296      36136
> -/+ buffers/cache:      41008     215720
> Swap:       481908      60524     421384
> 
> and i want to cluster my data using hclust.my data has 3 variables and 10000 cases.but it fails and saying have not enough memory for the vector size.  I read the help doc and use $R --max-vsize=800M to start the R 2.1.0beta under debian linux.but it still can not get the solution.so is my pc'memory not enough to carry this analysis or my mistake on setting the memory?
> 
> thank you.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From johannes at huesing.name  Wed Mar 30 14:34:57 2005
From: johannes at huesing.name (Johannes =?iso-8859-1?Q?H=FCsing?=)
Date: Wed, 30 Mar 2005 14:34:57 +0200 (CEST)
Subject: [R] error messages on R CMD check
Message-ID: <36045.129.206.90.2.1112186097.squirrel@mail.panix.com>

Dear all,
I am trying to wrap up a package. On entering
R CMD check, I get the following error messages:

[...]
* checking S3 generic/method consistency ... WARNING
Error in .try_quietly({ : Error in library(package, lib.loc = lib.loc,
character.only = TRUE, verbose = FALSE) :
	package/namespace load failed for 'resper'
Execution halted
See section 'Generic functions and methods' of the 'Writing R Extensions'
manual.
* checking replacement functions ... WARNING
Error in .try_quietly({ : Error in library(package, lib.loc = lib.loc,
character.only = TRUE, verbose = FALSE) :
	package/namespace load failed for 'resper'
Execution halted
In R, the argument of a replacement function which corresponds to the right
hand side must be named 'value'.
* checking foreign function calls ... WARNING
Error in .try_quietly({ : Error in library(package, lib.loc = lib.loc,
character.only = TRUE, verbose = FALSE) :
	package/namespace load failed for 'resper'
Execution halted
See section 'System and foreign language interfaces' of the 'Writing R
Extensions' manual.
* checking Rd files ... OK
* checking for missing documentation entries ... ERROR
Error in .try_quietly({ : Error in library(package, lib.loc = lib.loc,
character.only = TRUE, verbose = FALSE) :

I am not getting these messages, nor their relation to
section 'Generic functions and methods' of the 'Writing
R Extensions' manual, as I did not write any generic methods
in my package.

There has been some discussion of the error message around
Christmas 2003: http://maths.newcastle.edu.au/~rking/R/devel/03b/1438.html,
but I can't see how the circumstances described there apply to
my situation ("export a class name").

Could somebody give me a clue on how to give my search a
direction?

Greetings


Johannes



From dimitris.rizopoulos at med.kuleuven.ac.be  Wed Mar 30 14:57:28 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Wed, 30 Mar 2005 14:57:28 +0200
Subject: [R] Habituation model
References: <424A9659.2070606@vet-alfort.fr>
Message-ID: <006501c53528$07453ff0$0540210a@www.domain>

since you measure the same dog several times its measurements are 
correlated and you should take this into account in your analysis 
(i.e., "aov()" is not appropriate in this case). Probably you could 
find functions "lme()" and "gls()" in the "nlme" package very useful 
for your problem and for which a very good reference is:

@Book{pinheiro.bates:00,
  author    = {J. Pinheiro and D. Bates},
  title     = {Mixed-Effects Models in S and S-PLUS},
  year      = {2000},
  address   = {New York},
  publisher = {Springer-Verlag}
}


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm




----- Original Message ----- 
From: "Laurent Fanchon" <lfanchon at vet-alfort.fr>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, March 30, 2005 2:06 PM
Subject: [R] Habituation model


> Dear all,
> I am looking at habituation of dogs trotting on a treadmill. I 
> record the ground reaction force and I analyze it with several 
> discrete variables (maximum, minimum,...)
> For each variable, I get between 40 and 50 data per sample.
> I record data at time 1 min, 2 min, and 4 min a day, and I have 4 
> days of measurement (one day a week). That means I have 12 samples : 
> Day1_Min1, Day1_Min2, Day1_Min4, Day2_Min1,...
>
> Furthermore, I have 28 dogs to analyze.
> My questions is : when can I consider the data stabilized?
> The problem is I am studying habituation with several sessions. It 
> seems logical that values from each first minute could be very 
> dissimilar to others. It is not a fully linear training system. I 
> have already done some ANOVAs with "Day" and "Min" factors. I found 
> a significant effect.
> It is quite logical because the dog is learning. The question is 
> then when does it stop learning? or more precisely when is it 
> trained enough to be analyzed?
>
> I could do comparisons among all samples with Student test, but it 
> is surely a simple approach.
> I can presuppose the maximal allowed variability for each variable : 
> in the region of 5%.
> I am really new to both R and stats so if these questions are very 
> simple and I am just missing something, suggestions about good texts 
> or examples on R would be great. I am generating data with Scilab, I 
> have a single matrix corresponding to each dog. But I can change it 
> if needed.
> Any help would be greatly appreciated
>
> Thanks
>
> Laurent Fanchon
> DVM, MS
> Ecole Nationale Veterinaire d'Alfort
> France
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From flom at ndri.org  Wed Mar 30 15:36:33 2005
From: flom at ndri.org (Peter Flom)
Date: Wed, 30 Mar 2005 08:36:33 -0500
Subject: [R] fastbw question
Message-ID: <s24a6527.047@MAIL.NDRI.ORG>

Hello

I am running R 2.0.1 on Windows, I am attempting to use Frank Harrell's
'fastbw' function (from the Design library), but I get an error that the
fit was not created with a Design library fitting function; yet when I
go to the help for fastbw (and also look in Frank's book Regression
Modeling Strategies) it appears that fastbw should work with a model
created with lm.....

Relevant code
<<<<<
model.borrow.logols<- lm(logborrow~age + sex + racgp + yrseduc + 
 needlchg + gallery  + totni + inject + poly(year.of.int,3)  + druginj
+ inj.years  + HTLV3)

fastbw(model.borrow.logols)
>>>>

Thanks in advance


Peter

Peter L. Flom, PhD
Assistant Director, Statistics and Data Analysis Core
Center for Drug Use and HIV Research
National Development and Research Institutes
71 W. 23rd St
www.peterflom.com
New York, NY 10010
(212) 845-4485 (voice)
(917) 438-0894 (fax)



From maillists at visiv.co.uk  Wed Mar 30 15:59:12 2005
From: maillists at visiv.co.uk (Graham Jones)
Date: Wed, 30 Mar 2005 14:59:12 +0100
Subject: [R] discriminant function analysis in R
In-Reply-To: <200503301005.j2UA3CBr019053@hypatia.math.ethz.ch>
References: <200503301005.j2UA3CBr019053@hypatia.math.ethz.ch>
Message-ID: <bMwvvNAwCrSCFwQF@visiv.co.uk>

In message <200503301005.j2UA3CBr019053 at hypatia.math.ethz.ch>, r-help-
request at stat.math.ethz.ch writes
>Dear R Users,
>
>I'm very very interested in learning how to use R to carry out a 
>classification of data using discriminant function analysis.  I've 
>found the MASS package and the lda function, but the examples in the 
>help system are a bit over my head.  I'm not exactly sure how to 
>interpret the output, for example, of if the inputs I've chosen are 
>best suited to my needs.
[...]

I would recommend writing your own simple version of lda in R. For
example, stick to two class problems, and don't worry too much about
efficiency or dealing with bad input. Then think about how you might
make your routines of more general use (but don't bother to implement
this). This is a good way of learning R, and having got this far on your
own, you will find the documentation and examples for lda make sense.
Well, it worked for me.

Here's some useful functions:
?"%*%"
?t
?determinant
?solve
?mean
?cov
?cat
?scan

-- 
Graham Jones, author of SharpEye Music Reader
http://www.visiv.co.uk
21e Balnakeil, Durness, Lairg, Sutherland, IV27 4PT, Scotland, UK



From MSchwartz at MedAnalytics.com  Wed Mar 30 16:03:10 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed, 30 Mar 2005 08:03:10 -0600
Subject: [R] Finding the "height of a line of text" for axis
In-Reply-To: <20050330100617.GA7312@cl.cam.ac.uk>
References: <20050330100617.GA7312@cl.cam.ac.uk>
Message-ID: <1112191390.4905.11.camel@horizons.localdomain>

On Wed, 2005-03-30 at 11:06 +0100, Steven J. Murdoch wrote:
> I would like to draw only the ticks of an axis, but not the axis
> itself. I don't think this can be done using axis(), so I am trying to
> write a cut-down version in R, which only draws ticks.
> 
> The point at which I am stuck is that the length of a tick is set by
> par("tcl") as a fraction of the "height of a line of text". So I would
> like to draw a line whose length is also this length. However I cannot
> find out how to convert the into units I can pass into lines(). I
> thought par("cxy"), but it is too large, as is shown in the code
> below. Here the red tick marks are longer than the black ones created
> by axis. I have found the relevant function in plot.c:
>  "GConvertYUnits(Rf_gpptr(dd)->tcl, LINES, NFC, dd);"
> but can't find the corresponding R function.
> 
> Can anyone suggest how to find this out, or solve the problem in a
> different way?
> 
> # Inward pointing ticks
> par("tcl"=1)
> 
> drawticks <- function(at) {
>  # Start of the ticks
>  base<-par("usr")[1]
>  # Length of the ticks
>  l<-par("cxy")[2]*par("tcl")
>  for (i in at) {
>   lines(c(base,base+l),rep(i,2),col="red")
>  }
> }
> 
> # Test plot
> plot(c(1,2,3), axes=FALSE)
> # Draw ticks in red
> drawticks(axTicks(2))
> # Overprint with normal axis
> axis(2, axTicks(2))

Steven,

Are you trying to do something like this:

 plot(1:5, axes = FALSE)
 axis(1, col.axis = "white", tcl = 1)
 axis(2, col.axis = "white", tcl = 1)

or perhaps something like this:

 plot(1:5, axes = FALSE)
 axis(1, col.axis = "white", col = "red", tcl = 1)
 axis(1, col.axis = "white", col = "black", tcl = 0)
 axis(2, col.axis = "white", col = "red", tcl = 1)
 axis(2, col.axis = "white", col = "black", tcl = 0)

or even something like this:

 plot(1:5, axes = FALSE)
 axis(1, col.axis = "white", col = "red", tcl = 1)
 axis(1, col.axis = "white", col = "white", tcl = 0)
 axis(2, col.axis = "white", col = "red", tcl = 1)
 axis(2, col.axis = "white", col = "white", tcl = 0)

If you do not want the axis labels, use:

 plot(1:5, axes = FALSE, ann = FALSE)


HTH,

Marc Schwartz



From Robert.McGehee at geodecapital.com  Wed Mar 30 16:14:29 2005
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Wed, 30 Mar 2005 09:14:29 -0500
Subject: [R] Recall() and sapply()
Message-ID: <67DCA285A2D7754280D3B8E88EB548020C946565@MSGBOSCLB2WIN.DMN1.FMR.COM>

I doubt it's possible to use Recall inside a sapply like this. sapply
(and lapply) make a copy of the function (FUN <- match.fun(FUN)) before
passing it inside an internal function (rval <- .Internal(lapply(X,
FUN)). So, while I'm not precisely sure how Recall is coded up, I bet
that once it is copied inside of sapply (and lapply), it loses the
context from which it was called.

I can think of a couple ways around this. First, you could construct a
for loop instead of a sapply and use Recall. Second, you could replace
Recall by just asking R what the name of the calling function is and
pass that in to sapply. Something like this should work:

sapply(n, match.fun(sys.call()[[1]]))

HTH,
Robert

-----Original Message-----
From: Robin Hankin [mailto:r.hankin at soc.soton.ac.uk] 
Sent: Wednesday, March 30, 2005 3:28 AM
To: R-help at stat.math.ethz.ch
Subject: [R] Recall() and sapply()


Hi.

I'm having difficulty following the advice given in help(Recall).  
Consider the two
following toy functions:


f1 <- function(n){
   if(length(n)>1){return(sapply(n,f1))}
   matrix(n,n,n)
}

f2 <- function(n){
   if(length(n)>1){return(sapply(n,Recall))}
   matrix(n,n,n)
}


f1() works as desired (that is, f(1:3), say, gives me a three element 
list whose i-th element
is an i-by-i matrix whose elements are all i).

But f2() doesn't.

How do I modify either function to use Recall()?  What exactly is 
Recall() calling here?




--
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ggrothendieck at gmail.com  Wed Mar 30 16:21:53 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 30 Mar 2005 09:21:53 -0500
Subject: [R] Recall() and sapply()
In-Reply-To: <ae7dd0c40fdd93fcf0d522d99760678d@soc.soton.ac.uk>
References: <ae7dd0c40fdd93fcf0d522d99760678d@soc.soton.ac.uk>
Message-ID: <971536df050330062144f5b799@mail.gmail.com>

I believe that the function that Recall executes is the
function in which Recall, itself, is evaluated -- not the
function in which Recall appears.  In normal cases these are
the same but if you pass Recall to another function then
they are not the same.  Here Recall is being passed to
sapply (which in turn is likely passing it to other
functions).  Because of lazy evaluation Recall does not get
evaluated until it is found within sapply (or a function
called by it or called by one called by it, etc.) and at
that point its recalling the wrong function.  AFAICS one
cannot pass Recall to another function.

You could rewrite the expression that uses sapply to use 
iteration instead or you could do it as shown below.  
In this example, the use of f2 within supply refers to 
the inner f2 which does not change even if the name of 
the outer f2 does.

  f2 <- function(n) {
     f2 <- function(n) if(length(n)>1) sapply(n,f2) else matrix(n,n,n)
     f2(n)
   }
   f3 <- f2
   f2(1:3)
   f3(1:3)  # gives same result



On Wed, 30 Mar 2005 09:28:08 +0100, Robin Hankin
<r.hankin at soc.soton.ac.uk> wrote:
> Hi.
> 
> I'm having difficulty following the advice given in help(Recall).
> Consider the two
> following toy functions:
> 
> f1 <- function(n){
>   if(length(n)>1){return(sapply(n,f1))}
>   matrix(n,n,n)
> }
> 
> f2 <- function(n){
>   if(length(n)>1){return(sapply(n,Recall))}
>   matrix(n,n,n)
> }
> 
> f1() works as desired (that is, f(1:3), say, gives me a three element
> list whose i-th element
> is an i-by-i matrix whose elements are all i).
> 
> But f2() doesn't.
> 
> How do I modify either function to use Recall()?  What exactly is
> Recall() calling here?
> 
> --
> Robin Hankin
> Uncertainty Analyst
> Southampton Oceanography Centre
> European Way, Southampton SO14 3ZH, UK
>  tel  023-8059-7743
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From 0034058 at fudan.edu.cn  Wed Mar 30 16:02:04 2005
From: 0034058 at fudan.edu.cn (ronggui)
Date: Wed, 30 Mar 2005 22:02:04 +0800
Subject: [R] about memory
In-Reply-To: <20050330073413.25a2b5f0.butchar.2@osu.edu>
References: <20050330183637.481b3c46.0034058@fudan.edu.cn>
	<20050330073413.25a2b5f0.butchar.2@osu.edu>
Message-ID: <20050330220204.3d873889.0034058@fudan.edu.cn>

root at 2[ronggui]# ulimit -a
core file size        (blocks, -c) 0
data seg size         (kbytes, -d) unlimited
file size             (blocks, -f) unlimited
max locked memory     (kbytes, -l) unlimited
max memory size       (kbytes, -m) unlimited
open files                    (-n) 1024
pipe size          (512 bytes, -p) 8
stack size            (kbytes, -s) 8192
cpu time             (seconds, -t) unlimited
max user processes            (-u) unlimited
virtual memory        (kbytes, -v) unlimited

so it seems the data segment size is not limited.
and it is still free mem(1000k or so),and swap(100000k or so),and the error is(i translate it from chinese into english,maybe not exactly ,but i think the meanings are right):
error:can not allocate the vector size of 390585kb.
(: 390585 Kb)



On Wed, 30 Mar 2005 07:34:13 -0500
jon butchar <butchar.2 at osu.edu> wrote:

> How much memory is free when R fails (e.g., what does "top" show while trying to run your clustering)?  If there's still a sizeable amount of free memory you may have to look into the system limits, maximum data segment size in particular.  Many Linux distros have it set to "unlimited" but default Debian may not.  If this turns out to be the problem, please do not, _do not_ raise it to "unlimited," but only to enough for R to work.
> 
> hth,
> 
> jon b
> 
> 
> 
> On Wed, 30 Mar 2005 18:36:37 +0800
> ronggui <0034058 at fudan.edu.cn> wrote:
> 
> > here is my system memory:
> > ronggui at 0[ronggui]$ free
> >              total       used       free     shared    buffers     cached
> > Mem:        256728      79440     177288          0       2296      36136
> > -/+ buffers/cache:      41008     215720
> > Swap:       481908      60524     421384
> > 
> > and i want to cluster my data using hclust.my data has 3 variables and 10000 cases.but it fails and saying have not enough memory for the vector size.  I read the help doc and use $R --max-vsize=800M to start the R 2.1.0beta under debian linux.but it still can not get the solution.so is my pc'memory not enough to carry this analysis or my mistake on setting the memory?
> > 
> > thank you.
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From yunwxy at yahoo.com.cn  Wed Mar 30 16:34:29 2005
From: yunwxy at yahoo.com.cn (xiaoyun wu)
Date: Wed, 30 Mar 2005 22:34:29 +0800 (CST)
Subject: [R] A question about multiple comparison of analysis of covariance
	using SPSS
Message-ID: <20050330143429.10611.qmail@web15211.mail.bjs.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050330/f90b8b15/attachment.pl

From d.firth at warwick.ac.uk  Wed Mar 30 16:46:13 2005
From: d.firth at warwick.ac.uk (David Firth)
Date: Wed, 30 Mar 2005 15:46:13 +0100
Subject: [R] error messages on R CMD check
In-Reply-To: <36045.129.206.90.2.1112186097.squirrel@mail.panix.com>
References: <36045.129.206.90.2.1112186097.squirrel@mail.panix.com>
Message-ID: <55dec880034182a5964cc0e01a539ce8@warwick.ac.uk>

Dear Johannes

I have noticed the same complaint, and you are right that it can be 
unconnected with faulty S3 methods, etc., in your package.

For example, in my "relimp" package (current version 0.9-1, new on CRAN 
today) the DESCRIPTION file has
   Suggests: tcltk
and that works fine (ie it passes R CMD check).

But if I change that to
   Depends: tcltk
I get the same kind of errors that you got:

david% R CMD check relimp
[...]
* checking S3 generic/method consistency ... WARNING
Error in .try_quietly({ : Error: package 'tcltk' could not be loaded
Execution halted
See section 'Generic functions and methods' of the 'Writing R 
Extensions'
manual.
* checking replacement functions ... WARNING
Error in .try_quietly({ : Error: package 'tcltk' could not be loaded
Execution halted
In R, the argument of a replacement function which corresponds to the 
right
hand side must be named 'value'.
* checking foreign function calls ... WARNING
Error in .try_quietly({ : Error: package 'tcltk' could not be loaded
Execution halted
See section 'System and foreign language interfaces' of the 'Writing R
Extensions' manual.
* checking Rd files ... OK
* checking for missing documentation entries ... ERROR
Error in .try_quietly({ : Error: package 'tcltk' could not be loaded

In this case it is because the calling environment for R CMD check did 
not have the DISPLAY variable set, so tcltk could not be loaded.  If 
instead I do

david% setenv DISPLAY :0
david% R CMD check relimp

then all checks are passed.  This is with

david% R --version
R 2.0.1 (2004-11-15).

This is not really an explanation of what you got, just a confirmation 
that something here probably needs fixing (even if it's only the error 
message).  Perhaps one of us should file a bug report (having checked 
first that a fix is not already made in the latest development 
version)?

David

On 30 Mar, 2005, at 13:34, Johannes H?sing wrote:

> Dear all,
> I am trying to wrap up a package. On entering
> R CMD check, I get the following error messages:
>
> [...]
> * checking S3 generic/method consistency ... WARNING
> Error in .try_quietly({ : Error in library(package, lib.loc = lib.loc,
> character.only = TRUE, verbose = FALSE) :
> 	package/namespace load failed for 'resper'
> Execution halted
> See section 'Generic functions and methods' of the 'Writing R 
> Extensions'
> manual.
> * checking replacement functions ... WARNING
> Error in .try_quietly({ : Error in library(package, lib.loc = lib.loc,
> character.only = TRUE, verbose = FALSE) :
> 	package/namespace load failed for 'resper'
> Execution halted
> In R, the argument of a replacement function which corresponds to the 
> right
> hand side must be named 'value'.
> * checking foreign function calls ... WARNING
> Error in .try_quietly({ : Error in library(package, lib.loc = lib.loc,
> character.only = TRUE, verbose = FALSE) :
> 	package/namespace load failed for 'resper'
> Execution halted
> See section 'System and foreign language interfaces' of the 'Writing R
> Extensions' manual.
> * checking Rd files ... OK
> * checking for missing documentation entries ... ERROR
> Error in .try_quietly({ : Error in library(package, lib.loc = lib.loc,
> character.only = TRUE, verbose = FALSE) :
>
> I am not getting these messages, nor their relation to
> section 'Generic functions and methods' of the 'Writing
> R Extensions' manual, as I did not write any generic methods
> in my package.
>
> There has been some discussion of the error message around
> Christmas 2003: 
> http://maths.newcastle.edu.au/~rking/R/devel/03b/1438.html,
> but I can't see how the circumstances described there apply to
> my situation ("export a class name").
>
> Could somebody give me a clue on how to give my search a
> direction?
>
> Greetings
>
>
> Johannes
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From mmdoka at egs.uct.ac.za  Wed Mar 30 16:47:04 2005
From: mmdoka at egs.uct.ac.za (Marshall Mdoka)
Date: Wed, 30 Mar 2005 16:47:04 +0200
Subject: [R] Re:Plotting to A4 and replacing x-axis with actual years.
References: <200503161120.j2GB6w8j008015@hypatia.math.ethz.ch>
Message-ID: <021501c53537$997fa540$170815c4@DANISH>

Hie,

I have written before and probably missed the reply.

1.) I have my figures in a 3X3 array and want to fit them onto a A4 size
page. I have written commands to try a represent them in eps format but
still their cutting out information.

2.) I have an odd number of years and wanted to represent them say 1980 1985
1990 1995 2000 instead of 1 5 10 etc. However, the years are not
overwritting in the year I want since the first year in my x-axis is 1979
which is year 1 and year 5 being 1984.

Could you please help especially on the first problem.

Thanking you in advance,

Marshall Mdoka



From mmdoka at egs.uct.ac.za  Wed Mar 30 16:47:23 2005
From: mmdoka at egs.uct.ac.za (Marshall Mdoka)
Date: Wed, 30 Mar 2005 16:47:23 +0200
Subject: [R] Re:Plotting to A4 and replacing x-axis with actual years.
References: <200503161120.j2GB6w8j008015@hypatia.math.ethz.ch>
Message-ID: <022001c53537$df591d80$170815c4@DANISH>

Hie,

I have written before and probably missed the reply.

1.) I have my figures in a 3X3 array and want to fit them onto a A4 size
page. I have written commands to try a represent them in eps format but
still their cutting out information.

2.) I have an odd number of years and wanted to represent them say 1980 1985
1990 1995 2000 instead of 1 5 10 etc. However, the years are not
overwritting in the year I want since the first year in my x-axis is 1979
which is year 1 and year 5 being 1984.

Could you please help especially on the first problem.

Thanking you in advance,

Marshall Mdoka



From reid_huntsinger at merck.com  Wed Mar 30 17:23:57 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Wed, 30 Mar 2005 10:23:57 -0500
Subject: [R] about memory
Message-ID: <D9A95B4B7B20354992E165EEADA31999056A9385@uswpmx00.merck.com>

hclust creates a distance matrix. In your case it is 10,000 x 10,000. For
various reasons several copies are created, so you probably need at least 

100M x 8 bytes per entry x 3 copies = 2.4 GB

just for the distance matrix. If you don't have that much RAM the
computation will probably take longer than you're willing to wait.

Reid Huntsinger

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of ronggui
Sent: Wednesday, March 30, 2005 5:37 AM
To: r-help at stat.math.ethz.ch
Subject: [R] about memory


here is my system memory:
ronggui at 0[ronggui]$ free
             total       used       free     shared    buffers     cached
Mem:        256728      79440     177288          0       2296      36136
-/+ buffers/cache:      41008     215720
Swap:       481908      60524     421384

and i want to cluster my data using hclust.my data has 3 variables and 10000
cases.but it fails and saying have not enough memory for the vector size.  I
read the help doc and use $R --max-vsize=800M to start the R 2.1.0beta under
debian linux.but it still can not get the solution.so is my pc'memory not
enough to carry this analysis or my mistake on setting the memory?

thank you.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From f.harrell at vanderbilt.edu  Wed Mar 30 17:41:40 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Wed, 30 Mar 2005 09:41:40 -0600
Subject: [R] fastbw question
In-Reply-To: <s24a6527.047@MAIL.NDRI.ORG>
References: <s24a6527.047@MAIL.NDRI.ORG>
Message-ID: <424AC8B4.7000708@vanderbilt.edu>

Peter Flom wrote:
> Hello
> 
> I am running R 2.0.1 on Windows, I am attempting to use Frank Harrell's
> 'fastbw' function (from the Design library), but I get an error that the
> fit was not created with a Design library fitting function; yet when I
> go to the help for fastbw (and also look in Frank's book Regression
> Modeling Strategies) it appears that fastbw should work with a model
> created with lm.....
> 
> Relevant code
> <<<<<
> model.borrow.logols<- lm(logborrow~age + sex + racgp + yrseduc + 
>  needlchg + gallery  + totni + inject + poly(year.of.int,3)  + druginj
> + inj.years  + HTLV3)
> 
> fastbw(model.borrow.logols)

The error message was exactly correct.  lm is not a Design fitting 
function.  Try ols.  -Frank

> 
> 
> Thanks in advance
> 
> 
> Peter
> 
> Peter L. Flom, PhD
> Assistant Director, Statistics and Data Analysis Core
> Center for Drug Use and HIV Research
> National Development and Research Institutes
> 71 W. 23rd St
> www.peterflom.com
> New York, NY 10010
> (212) 845-4485 (voice)
> (917) 438-0894 (fax)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From pkhomski at wiwi.uni-bielefeld.de  Wed Mar 30 17:11:14 2005
From: pkhomski at wiwi.uni-bielefeld.de (Pavel Khomski)
Date: Wed, 30 Mar 2005 17:11:14 +0200
Subject: [R] R --max-vsize=4000M --max-nsize=4000M
Message-ID: <424AC192.7010703@wiwi.uni-bielefeld.de>

hello!

what's wrong???

i use 32 bit machine.
every time i 'm connecting the server  to do my work with R on it , 
after having done

 > ................
 > R --max-vsize=4000M --max-nsize=4000M

i become  wrong limits specification  for Ncells:

 > .....
 > gc()
                    used        (Mb)       gc trigger       (Mb)   limit 
(Mb)
Ncells   698799         18.7          1644099           44       112000
Vcells 65744346    501.6      189257063       1444           4000

is there anything wrong?

thanks a lot



From tlumley at u.washington.edu  Wed Mar 30 18:10:17 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 30 Mar 2005 08:10:17 -0800 (PST)
Subject: [R] Recall() and sapply()
In-Reply-To: <ae7dd0c40fdd93fcf0d522d99760678d@soc.soton.ac.uk>
References: <ae7dd0c40fdd93fcf0d522d99760678d@soc.soton.ac.uk>
Message-ID: <Pine.A41.4.61b.0503300802210.328928@homer06.u.washington.edu>

On Wed, 30 Mar 2005, Robin Hankin wrote:

> Hi.
>
> I'm having difficulty following the advice given in help(Recall).  Consider 
> the two
> following toy functions:
>
>
> f1 <- function(n){
>  if(length(n)>1){return(sapply(n,f1))}
>  matrix(n,n,n)
> }
>
> f2 <- function(n){
>  if(length(n)>1){return(sapply(n,Recall))}
>  matrix(n,n,n)
> }
>
>
> f1() works as desired (that is, f(1:3), say, gives me a three element list 
> whose i-th element
> is an i-by-i matrix whose elements are all i).
>
> But f2() doesn't.
>
> How do I modify either function to use Recall()?  What exactly is Recall() 
> calling here?
>

You can't use Recall here. I thought this was explicitly documented, but 
it turns out that it isn't, an omission I will fix.


You don't need Recall, because R can easily have recursive functions 
without it (unlike S)
- as you show in f1, the function can call itself
- the problem with f1 is that it stops working if you change the name, but
   ?local shows how to get around this. This is probably the best way to
   implement recursion.
- You can even implement Y, the "appplicative-order fixed point operator"
   to create anonymous recursive functions a la lambda calculus.


 	-thomas



From fredrik.bg.lundgren at bredband.net  Wed Mar 30 19:04:25 2005
From: fredrik.bg.lundgren at bredband.net (Fredrik Lundgren)
Date: Wed, 30 Mar 2005 19:04:25 +0200
Subject: [R] Solved - gnuclient problems witrh R/ESS in linux
References: <000b01c533bc$d60afe00$149d72d5@Larissa>
Message-ID: <001301c5354a$870a0500$149d72d5@Larissa>

Finally,

I found a way to make fix() and edit() work with gnuclient
in ESS-5.2.6/R-2.0.1/Xemacs-21.4.15-r3 on gentoo-linux.

When invoking R/ESS the following is induced by ESS
> options(STERM='iESS', editor='gnuclient -q')

It appears as if the problem is with 'gnuclient -q'
(whatever does -q signify?? From the man page it appears to disconnect 
the association between the opened buffer and gnuclient - which was teh 
very problem)
and when i changed a row in ess-5.2.6/lisp/gnu-cust.el
things worked in the expected way.
Change row

if (featurep 'xemacs) "gnuclient -q" "emacsclient"))) ;; unix

to

if (featurep 'xemacs) "gnuclient" "emacsclient"))) ;; unix

and all things work OK.

The only thing needed in init.el for gnuclient to work in this setup
is

(gnuserv-start)

and possibly

(setq gnuserv-frame (selected-frame))

if you whant the gnuclient frame to open within Xemacs

and no fuss with PATH


Many thanks to Richard M. Heiberger for all help!

Fredrik

PS A peculiar thing though - In the latest manual for ESS it's said:
4.9 Using emacsclient

When starting R or S under Unix, ESS sets options(editor="emacsclient").
(Under

Microsoft Windows, it will use gnuclient.exe rather than emacsclient,
but the same principle

applies.)

but I got options(editor="gnuclient -q")

now changed to options(editor="gnuclient ")

DS

----- Original Message ----- 
From: "Fredrik Lundgren" <fredrik.bg.lundgren at bredband.net>
To: "R-help" <r-help at stat.math.ethz.ch>
Sent: Monday, March 28, 2005 7:37 PM
Subject: [R] gnuclient problems witrh R/ESS in linux


> Dear list,
>
> Not strictly R ...
>
> In R on Xemacs with ESS (R-2.0.1, Xemacs-21.4.15-r3, ESS-5.2.6)
> on gentoo-linux
>
> when I use k<-edit(k) or fix(k)
> to change a small vector k <- c(1,2,3,4,5,6)
>
> the opened window (called '6b8b4567') appears not to be connected to 
> the
> gnuclient
> and I'm able to edit the file but has no instructions in the
> minibuffer
> and
> C-x # gives
> '6b8b4567 does not belong to gnuserv client'
>
> in init.el I have
> (require 'gnuserv)
> (gnuserv-start)
> (setq gnuserv-frame (selected-frame))
>
> Any help please?
>
> Fredrik
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From timh at insightful.com  Wed Mar 30 19:05:45 2005
From: timh at insightful.com (Tim Hesterberg)
Date: 30 Mar 2005 09:05:45 -0800
Subject: [R] Stratified Bootstrap question
Message-ID: <SE2KEXCH01pYfKHq0dT00001632@se2kexch01.insightful.com>

Dear Qian,

You might try the S+Resample library, which has built-in support
for both sampling by subject and stratified sampling.

If you are a student, there is a free student version of S+.

See
www.insightful.com/downloads/libraries	(S+Resample)
www.insightful.com/Hesterberg/bootstrap	(has link to the student version)

For the missing values, consider the S+Missing library,
which offers multiple imputation.  With S+, do
	library(missing)

Tim Hesterberg

P.S.  The combination of sampling by subject and stratified sampling
was terribly messy to program.  If I'd known in advance how messy, I
never would have done it :-(  But it is done now.

>Dear R users,
>
>I have a question regarding stratified bootstrap question and how to implement
>it using boot() in R's boot package.
>
>My dataset is a longitudinal dataset (3 measurements per person at year
>1, 4 and 7) composed of multiple clinic centers and multiple participants
>within each clinic. It has missing values.
>
>I want to do a bootstrap to find the standard errors and confidence
>intervals for my variance components. My model is a mixed model with
>random clinic and random participant within clinic.
>
>I thought two methods to do bootstrap:
>(1) bootstrap data; however, I have problem specifying the second
>parameter for my statistic function, shall I use indices, weight or
>frequency and how shall I relate to my dataset.
>(2) bootstrap residuals; however, the dataset has multiple measurements
>and missing values. I am wondering how to construct a new data frame
>containing the residuals and fitted values.
>
>Any ideas will be highly appreciated!
>Sincerely yours,
>Qian

========================================================
| Tim Hesterberg       Research Scientist              |
| timh at insightful.com  Insightful Corp.                |
| (206)802-2319        1700 Westlake Ave. N, Suite 500 |
| (206)283-8691 (fax)  Seattle, WA 98109-3044, U.S.A.  |
|                      www.insightful.com/Hesterberg   |
========================================================
Download the S+Resample library from www.insightful.com/downloads/libraries



From tcallawa at redhat.com  Wed Mar 30 19:10:06 2005
From: tcallawa at redhat.com (Tom 'spot' Callaway)
Date: Wed, 30 Mar 2005 11:10:06 -0600
Subject: [R] Installing GO 1.7.0
Message-ID: <1112202606.12235.18.camel@in-141-199.dhcp-149-166.iupui.edu>

I'm in the process of packaging R (and R modules) for future inclusion
in Fedora Extras, and I've managed to get several hundred modules
installed without issue, however, the GO metadata package is refusing to
comply.

Since I'm packaging this in rpm format, I can't use any of the automated
functions for build, I've got to do it locally through R.

The following steps work for other metadata packages (directory names
changing, obviously), but not for GO:

With the GO tarball unpacked into R-GO-1.7.0/GO...

cd R-GO-1.7.0/
rm -rf /var/tmp/R-GO-1.7.0-1-root-root
mkdir -p /var/tmp/R-GO-1.7.0-1-root-root/usr/lib/R/library
export R_LIBS=/var/tmp/R-GO-1.7.0-1-root-root/usr/lib/R/library
/usr/bin/R CMD INSTALL \
-l /var/tmp/R-GO-1.7.0-1-root-root/usr/lib/R/library GO

I get the following output:
* Installing *source* package 'GO' ...
** R
** data
** preparing package for lazy loading

** help
 >>> Building/Updating help pages for package 'GO'
     Formats: text html latex example
  GO                                text    html    latex
  GOALLLOCUSID                      text    html    latex   example
  GOBPANCESTOR                      text    html    latex   example
  GOBPCHILDREN                      text    html    latex   example
  GOBPOFFSPRING                     text    html    latex   example
  GOBPPARENTS                       text    html    latex   example
  GOCCANCESTOR                      text    html    latex   example
  GOCCCHILDREN                      text    html    latex   example
  GOCCOFFSPRING                     text    html    latex   example
  GOCCPARENTS                       text    html    latex   example
  GOLOCUSID                         text    html    latex   example
  GOLOCUSID2ALLGO                   text    html    latex   example
  GOLOCUSID2GO                      text    html    latex   example
  GOMFANCESTOR                      text    html    latex   example
  GOMFCHILDREN                      text    html    latex   example
  GOMFOFFSPRING                     text    html    latex   example
  GOMFPARENTS                       text    html    latex   example
  GOQC                              text    html    latex
  GOTERM                            text    html    latex   example

But I never get the "* DONE (GO)" that I'm expecting. Instead, all of
the memory on the machine allocates (512MB), it starts to swap out, and
never completes.

When I look at the output from ps, I see:
 8290 pts/5    S+     0:00 /bin/sh /usr/lib/R/bin/INSTALL
-l /var/tmp/R-GO-1.7.0-1-root-root/us 8364 ?        S      0:00 
 8421 pts/5    D+     1:11 /usr/lib/R/bin/exec/R --vanilla

When I kill the 8421 process, I get:

/usr/lib/R/bin/INSTALL: line 381:  8088 Done                    echo
"invisible(.libPaths(c(\"${lib}\", .libPaths())));
tools:::.install_package_indices(\".\", \"${R_PACKAGE_DIR}\")"
      8089 Killed                  | R_DEFAULT_PACKAGES=NULL LANG=C
"${R_EXE}" --vanilla >/dev/null
ERROR: installing package indices failed

I let this run for over 6 hours, and it didn't seem to complete (or make
any changes).

Unfortunately, lots of Bioconductor seems to depend on GO... so any help
on getting this to install is appreciated.

Thanks,

~spot
-- 
Tom "spot" Callaway: Red Hat Sales Engineer || GPG Fingerprint: 93054260
Fedora Extras Steering Committee Member (RPM Standards and Practices)
Aurora Linux Project Leader: http://auroralinux.org
Lemurs, llamas, and sparcs, oh my!



From greg.snow at ihc.com  Wed Mar 30 19:44:30 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Wed, 30 Mar 2005 10:44:30 -0700
Subject: [R] how i can get input from "user input"
Message-ID: <s24a8322.063@lp-msg1.co.ihc.com>

Also look at ?readline

Greg Snow, Ph.D.
Statistical Data Center
greg.snow at ihc.com
(801) 408-8111

>>> Uwe Ligges <ligges at statistik.uni-dortmund.de> 03/29/05 11:43PM >>>
Cuichang Zhao wrote:

> Hello, 
> Could you please tell me how i can get an input from the user in R?

Depends on the kind of input.

See, e.g., ?scan or ?menu

Uwe Ligges


> C-Ming 
>  
> Mar 29, 2005
> 
> 		
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html 

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From butchar.2 at osu.edu  Wed Mar 30 19:56:36 2005
From: butchar.2 at osu.edu (jon butchar)
Date: Wed, 30 Mar 2005 12:56:36 -0500
Subject: [R] about memory
In-Reply-To: <20050330220204.3d873889.0034058@fudan.edu.cn>
References: <20050330183637.481b3c46.0034058@fudan.edu.cn>
	<20050330073413.25a2b5f0.butchar.2@osu.edu>
	<20050330220204.3d873889.0034058@fudan.edu.cn>
Message-ID: <20050330125636.1dcda7f7.butchar.2@osu.edu>

Yes, you may need more memory unless you can somehow free a good amount of RAM or find a more memory-efficient method for clustering.  If I'm reading it correctly, R wanted to allocate about 382 MB memory on top of what it had already taken but your computer had only about 98 MB swap plus about 1 MB RAM left to give.


On Wed, 30 Mar 2005 22:02:04 +0800
ronggui <0034058 at fudan.edu.cn> wrote:

> root at 2[ronggui]# ulimit -a
> core file size        (blocks, -c) 0
> data seg size         (kbytes, -d) unlimited
> file size             (blocks, -f) unlimited
> max locked memory     (kbytes, -l) unlimited
> max memory size       (kbytes, -m) unlimited
> open files                    (-n) 1024
> pipe size          (512 bytes, -p) 8
> stack size            (kbytes, -s) 8192
> cpu time             (seconds, -t) unlimited
> max user processes            (-u) unlimited
> virtual memory        (kbytes, -v) unlimited
> 
> so it seems the data segment size is not limited.
> and it is still free mem(1000k or so),and swap(100000k or so),and the error is(i translate it from chinese into english,maybe not exactly ,but i think the meanings are right):
> error:can not allocate the vector size of 390585kb.
> (????: ??????????????390585 Kb??????)



From sfalcon at fhcrc.org  Wed Mar 30 20:04:22 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 30 Mar 2005 10:04:22 -0800
Subject: [R] Installing GO 1.7.0
In-Reply-To: <1112202606.12235.18.camel@in-141-199.dhcp-149-166.iupui.edu> (Tom
	Callaway's message of "Wed, 30 Mar 2005 11:10:06 -0600")
References: <1112202606.12235.18.camel@in-141-199.dhcp-149-166.iupui.edu>
Message-ID: <m2sm2dt3h5.fsf@macaroni.local>

Hi Tom,

I'm cc'ing to Bioconductor as that is probably a better place for the
discussion.


"Tom 'spot' Callaway" <tcallawa at redhat.com> writes:

> I'm in the process of packaging R (and R modules) for future inclusion
> in Fedora Extras, and I've managed to get several hundred modules
> installed without issue, however, the GO metadata package is refusing to
> comply.

> ERROR: installing package indices failed
>
> I let this run for over 6 hours, and it didn't seem to complete (or make
> any changes).

We have a solution for this and will send or make available an updated
GO package shortly.  With the updated GO package you should be able to
R CMD INSTALL without it taking much time.

Best,

+ seth



From sfalcon at fhcrc.org  Wed Mar 30 20:05:53 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 30 Mar 2005 10:05:53 -0800
Subject: [BioC] Follow-up to:  [R] Annotation metadata "kills" help.search
In-Reply-To: <NCEEILPLHGEMJBGGKFCLOEOHCAAA.gerard.tromp@sanger.med.wayne.edu>
	(Gerard Tromp's message of "Tue, 29 Mar 2005 14:30:25 -0500")
References: <NCEEILPLHGEMJBGGKFCLOEOHCAAA.gerard.tromp@sanger.med.wayne.edu>
Message-ID: <m2oed1t3em.fsf@macaroni.local>

"Gerard Tromp" <gerard.tromp at sanger.med.wayne.edu> writes:

> Greetings,
>
> this is a follow-up to the mailing below. Seth Falcon replied and indicated
> that he and several others were unable to replicate the problem.
> Specifically he requested:
>
> ============
> We are not able to reproduce this issue.  If you reinstall the
> annotation packages does the error reappear?
>
> If so, an exact transcript of the commands entered, their output, and
> the output of traceback() right after the error would be helpful ---
> and it would be best to move the discussion to the bioconductor list.
> =======
>
> The answers are: Yes, the problem is reproducible. I did a complete
> reinstall of R and bioconductor end everything worked fine until I installed
> an annotation package.

With the added information from Gerard, we were able to reproduce the
problem and are currently working on a fix.  

Thanks,

+ seth



From gunter.berton at gene.com  Wed Mar 30 20:09:38 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 30 Mar 2005 10:09:38 -0800
Subject: [R] how i can get input from "user input"
In-Reply-To: <s24a8322.063@lp-msg1.co.ihc.com>
Message-ID: <200503301809.j2UI9cuT013760@meitner.gene.com>

If you are on Windows and want to go GUI, see ?choose.files, ?winMenuAdd,
?winDialog, ?select.list

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Greg Snow
> Sent: Wednesday, March 30, 2005 9:45 AM
> To: ligges at statistik.uni-dortmund.de; cuiczhao at yahoo.com
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] how i can get input from "user input"
> 
> Also look at ?readline
> 
> Greg Snow, Ph.D.
> Statistical Data Center
> greg.snow at ihc.com
> (801) 408-8111
> 
> >>> Uwe Ligges <ligges at statistik.uni-dortmund.de> 03/29/05 11:43PM >>>
> Cuichang Zhao wrote:
> 
> > Hello, 
> > Could you please tell me how i can get an input from the user in R?
> 
> Depends on the kind of input.
> 
> See, e.g., ?scan or ?menu
> 
> Uwe Ligges
> 
> 
> > C-Ming 
> >  
> > Mar 29, 2005
> > 
> > 		
> > ---------------------------------
> > 
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help 
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From vasileios_p at yahoo.gr  Wed Mar 30 20:24:13 2005
From: vasileios_p at yahoo.gr (vasilis pappas)
Date: Wed, 30 Mar 2005 19:24:13 +0100 (BST)
Subject: [R] Step error
Message-ID: <20050330182413.87952.qmail@web25610.mail.ukl.yahoo.com>

Could anyone tell me what am I doing wrong?

> pro<-function(indep,dep){
+  d<-data.frame(indep)
+  form<-formula(lm(dep~.,data=d))
+ 
forward<-step(lm(dep~X1,data=d),scope=form,trace=0,direction='f')
+  return(forward) 
+ }
> pro(m,q)
Error in inherits(x, "data.frame") : Object "d" not
found

Where q is a vector with the dependent variable's
values
and m is a matrix containing the values of the
independent variables.

While writing the above without a function form has no
problem, that is :

> d<-data.frame(m)
> form<-formula(lm(q~.,data=d))
>
forward<-step(lm(q~X1,data=d),scope=form,trace=0,direction='f')
> forward

Call:
lm(formula = q ~ X1 + X2 + X5, data = d)

Coefficients:
(Intercept)           X1           X2           X5  
    -15.798        8.765        6.774       -4.245  


Thank you in advance!
Vasilis



From lukelu1983 at yahoo.com  Wed Mar 30 20:56:40 2005
From: lukelu1983 at yahoo.com (Steven Lu)
Date: Wed, 30 Mar 2005 10:56:40 -0800 (PST)
Subject: [R] compute adjusted mean
Message-ID: <20050330185640.9997.qmail@web42108.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050330/69c6455b/attachment.pl

From hhalvors at Princeton.EDU  Wed Mar 30 21:43:23 2005
From: hhalvors at Princeton.EDU (Hans Halvorson)
Date: Wed, 30 Mar 2005 14:43:23 -0500
Subject: [R] PDF and PS output 
Message-ID: <m364z8j4x0.fsf@princeton.edu>

I'm using R 2.0 on Redhat Linux 9.  When I try to produce PDF or PS
output, the files are corrupted -- they won't open in Acroread, xpdf,
ggv, and on attempting to convert to PNG, I get message "This file has
corrupted %%EOF marker."  Perhaps I am just doing something wrong.  I
did:

> pdf()
> hist(unlist(foo.bar))

I have no trouble viewing the output in Xwindows.

Thanks,
Hans



From qiana at biostat.umn.edu  Wed Mar 30 21:47:09 2005
From: qiana at biostat.umn.edu (Qian An)
Date: Wed, 30 Mar 2005 13:47:09 -0600 (CST)
Subject: [R] Stratified Bootstrap question
In-Reply-To: <SE2KEXCH01pYfKHq0dT00001632@se2kexch01.insightful.com>
Message-ID: <Pine.GSO.4.44.0503301320500.21162-100000@smelt.biostat.umn.edu>

Dear Tim,

Thank you very much for your information. I will try to play with S+ as
you suggested. At the same time, I would like to share our idea with you
about the stratified bootstrapping for my scenario. I am not sure if it is
correct. I am playing with it now.

We created a new dataset containing clinic and patient id within clinic,
then stratified boot() function was used to bootstrap
the newly-created dataset. Based on the indices of the bootstrap result,
since patient id is unique, we found the patient ids from the new dataset,
then found the corresponding dataset to fit a mixed model from the
original dataset using patient ids.

I am trying to run the program now, but it takes longer than what I
expected. 500 times takes more than 3 hours and it is still running. I
will see if this is working properly.

Thank you very much for your input,
Qian



On 30 Mar 2005, Tim Hesterberg wrote:

> Dear Qian,
>
> You might try the S+Resample library, which has built-in support
> for both sampling by subject and stratified sampling.
>
> If you are a student, there is a free student version of S+.
>
> See
> www.insightful.com/downloads/libraries	(S+Resample)
> www.insightful.com/Hesterberg/bootstrap	(has link to the student version)
>
> For the missing values, consider the S+Missing library,
> which offers multiple imputation.  With S+, do
> 	library(missing)
>
> Tim Hesterberg
>
> P.S.  The combination of sampling by subject and stratified sampling
> was terribly messy to program.  If I'd known in advance how messy, I
> never would have done it :-(  But it is done now.
>
> >Dear R users,
> >
> >I have a question regarding stratified bootstrap question and how to implement
> >it using boot() in R's boot package.
> >
> >My dataset is a longitudinal dataset (3 measurements per person at year
> >1, 4 and 7) composed of multiple clinic centers and multiple participants
> >within each clinic. It has missing values.
> >
> >I want to do a bootstrap to find the standard errors and confidence
> >intervals for my variance components. My model is a mixed model with
> >random clinic and random participant within clinic.
> >
> >I thought two methods to do bootstrap:
> >(1) bootstrap data; however, I have problem specifying the second
> >parameter for my statistic function, shall I use indices, weight or
> >frequency and how shall I relate to my dataset.
> >(2) bootstrap residuals; however, the dataset has multiple measurements
> >and missing values. I am wondering how to construct a new data frame
> >containing the residuals and fitted values.
> >
> >Any ideas will be highly appreciated!
> >Sincerely yours,
> >Qian
>
> ========================================================
> | Tim Hesterberg       Research Scientist              |
> | timh at insightful.com  Insightful Corp.                |
> | (206)802-2319        1700 Westlake Ave. N, Suite 500 |
> | (206)283-8691 (fax)  Seattle, WA 98109-3044, U.S.A.  |
> |                      www.insightful.com/Hesterberg   |
> ========================================================
> Download the S+Resample library from www.insightful.com/downloads/libraries
>
>

***************************************
Qian An
Division of Biostatistics
University of Minnesota
(phone) 612-626-2263
(fax) 612-626-8892
Email: qiana at biostat.umn.edu



From p.dalgaard at biostat.ku.dk  Wed Mar 30 21:49:43 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 30 Mar 2005 21:49:43 +0200
Subject: [R] PDF and PS output
In-Reply-To: <m364z8j4x0.fsf@princeton.edu>
References: <m364z8j4x0.fsf@princeton.edu>
Message-ID: <x2ekdwsylk.fsf@turmalin.kubism.ku.dk>

Hans Halvorson <hhalvors at princeton.edu> writes:

> I'm using R 2.0 on Redhat Linux 9.  When I try to produce PDF or PS
> output, the files are corrupted -- they won't open in Acroread, xpdf,
> ggv, and on attempting to convert to PNG, I get message "This file has
> corrupted %%EOF marker."  Perhaps I am just doing something wrong.  I
> did:
> 
> > pdf()
> > hist(unlist(foo.bar))
> 
> I have no trouble viewing the output in Xwindows.

Did you terminate the device properly (dev.off() or exit from R)?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From hhalvors at Princeton.EDU  Wed Mar 30 22:04:41 2005
From: hhalvors at Princeton.EDU (Hans Halvorson)
Date: Wed, 30 Mar 2005 15:04:41 -0500
Subject: [R] PDF and PS output
In-Reply-To: <x2ekdwsylk.fsf@turmalin.kubism.ku.dk> (Peter Dalgaard's
	message of "Wed, 30 Mar 2005 21:49:43 +0200")
References: <m364z8j4x0.fsf@princeton.edu>
	<x2ekdwsylk.fsf@turmalin.kubism.ku.dk>
Message-ID: <m34qeslx2e.fsf@princeton.edu>

Ach -- such a simple mistake.  Thank you for pointing out my error,
and I apologize for wasting your time.

Best wishes,
Hans



Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:

> Hans Halvorson <hhalvors at princeton.edu> writes:
>
>> I'm using R 2.0 on Redhat Linux 9.  When I try to produce PDF or PS
>> output, the files are corrupted -- they won't open in Acroread, xpdf,
>> ggv, and on attempting to convert to PNG, I get message "This file has
>> corrupted %%EOF marker."  Perhaps I am just doing something wrong.  I
>> did:
>> 
>> > pdf()
>> > hist(unlist(foo.bar))
>> 
>> I have no trouble viewing the output in Xwindows.
>
> Did you terminate the device properly (dev.off() or exit from R)?
>
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From umalvarez at fata.unam.mx  Wed Mar 30 22:07:08 2005
From: umalvarez at fata.unam.mx (Ulises M. Alvarez)
Date: Wed, 30 Mar 2005 14:07:08 -0600
Subject: [R] PDF and PS output
In-Reply-To: <m364z8j4x0.fsf@princeton.edu>
References: <m364z8j4x0.fsf@princeton.edu>
Message-ID: <424B06EC.20104@fata.unam.mx>

Hi:

dev.off()

Check your file now...

That's it!

Hans Halvorson wrote:
> I'm using R 2.0 on Redhat Linux 9.  When I try to produce PDF or PS
> output, the files are corrupted -- they won't open in Acroread, xpdf,
> ggv, and on attempting to convert to PNG, I get message "This file has
> corrupted %%EOF marker."  Perhaps I am just doing something wrong.  I
> did:
> 
> 
>>pdf()
>>hist(unlist(foo.bar))
> 
> 
> I have no trouble viewing the output in Xwindows.
> 
> Thanks,
> Hans
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
U.M.A.
http://sophie.fata.unam.mx/



From qiana at biostat.umn.edu  Wed Mar 30 22:08:17 2005
From: qiana at biostat.umn.edu (Qian An)
Date: Wed, 30 Mar 2005 14:08:17 -0600 (CST)
Subject: [R] Stratified Bootstrap question
In-Reply-To: <SE2KEXCH01YPKsNb3Hn0000164c@se2kexch01.insightful.com>
Message-ID: <Pine.GSO.4.44.0503301401350.21162-100000@smelt.biostat.umn.edu>

Dear Tim,

Thank you so much for your help. My random mixed model is as follows:

b.lme <- lme(sbp ~ age + gender, data=bdat, random=~1/clinic/id,
             na.action=na.omit)

When doing bootstrap with stratum clinic, a patient's data may appear
multiple times in the boostrap dataset and all of them share the same id.
I am wondering if the data from the same patient will cause problems in
lme fitting or not. Do you happen to know this or not?

I am really sorry for coming up more questions. Thank you so much for your
help.

Sincerely yours,
Qian








On 30 Mar 2005, Tim Hesterberg wrote:

> >Dear Tim,
> >
> >Thank you very much for your information. I will try to play with S+ as
> >you suggested. At the same time, I would like to share our idea with you
> >about the stratified bootstrapping for my scenario. I am not sure if it is
> >correct. I am playing with it now.
> >
> >We created a new dataset containing clinic and patient id within clinic,
> >then stratified boot() function was used to bootstrap
> >the newly-created dataset. Based on the indices of the bootstrap result,
> >since patient id is unique, we found the patient ids from the new dataset,
> >then found the corresponding dataset to fit a mixed model from the
> >original dataset using patient ids.
>
> That sounds reasonable.  That is what the S+Resample library does
> internally.
>
> >I am trying to run the program now, but it takes longer than what I
> >expected. 500 times takes more than 3 hours and it is still running. I
> >will see if this is working properly.
>
> This may be normal.  Fitting mixed models is iterative, unlike
> simple linear regression for which there is a closed-form solution.
> So running many replications can take a while.
>
> It might help if you specify starting values for the fixed-effects
> coefficients.  Run the model for the original data, and extract
> the fixed-effects coefficients.  Then specify those as starting
> values; this could make the bootstrap replicates run faster.
>
> >
> >Thank you very much for your input,
> >Qian
> >
> >
> >
> >On 30 Mar 2005, Tim Hesterberg wrote:
> >
> >> Dear Qian,
> >>
> >> You might try the S+Resample library, which has built-in support
> >> for both sampling by subject and stratified sampling.
> >>
> >> If you are a student, there is a free student version of S+.
> >>
> >> See
> >> www.insightful.com/downloads/libraries	(S+Resample)
> >> www.insightful.com/Hesterberg/bootstrap	(has link to the student version)
> >>
> >> For the missing values, consider the S+Missing library,
> >> which offers multiple imputation.  With S+, do
> >> 	library(missing)
> >>
> >> Tim Hesterberg
> >>
> >> P.S.  The combination of sampling by subject and stratified sampling
> >> was terribly messy to program.  If I'd known in advance how messy, I
> >> never would have done it :-(  But it is done now.
> >>
> >> >Dear R users,
> >> >
> >> >I have a question regarding stratified bootstrap question and how to implement
> >> >it using boot() in R's boot package.
> >> >
> >> >My dataset is a longitudinal dataset (3 measurements per person at year
> >> >1, 4 and 7) composed of multiple clinic centers and multiple participants
> >> >within each clinic. It has missing values.
> >> >
> >> >I want to do a bootstrap to find the standard errors and confidence
> >> >intervals for my variance components. My model is a mixed model with
> >> >random clinic and random participant within clinic.
> >> >
> >> >I thought two methods to do bootstrap:
> >> >(1) bootstrap data; however, I have problem specifying the second
> >> >parameter for my statistic function, shall I use indices, weight or
> >> >frequency and how shall I relate to my dataset.
> >> >(2) bootstrap residuals; however, the dataset has multiple measurements
> >> >and missing values. I am wondering how to construct a new data frame
> >> >containing the residuals and fitted values.
> >> >
> >> >Any ideas will be highly appreciated!
> >> >Sincerely yours,
> >> >Qian
> >>
> >> ========================================================
> >> | Tim Hesterberg       Research Scientist              |
> >> | timh at insightful.com  Insightful Corp.                |
> >> | (206)802-2319        1700 Westlake Ave. N, Suite 500 |
> >> | (206)283-8691 (fax)  Seattle, WA 98109-3044, U.S.A.  |
> >> |                      www.insightful.com/Hesterberg   |
> >> ========================================================
> >> Download the S+Resample library from www.insightful.com/downloads/libraries
> >>
> >>
> >
> >***************************************
> >Qian An
> >Division of Biostatistics
> >University of Minnesota
> >(phone) 612-626-2263
> >(fax) 612-626-8892
> >Email: qiana at biostat.umn.edu
> >***************************************
> >
>
>

***************************************
Qian An
Division of Biostatistics
University of Minnesota
(phone) 612-626-2263
(fax) 612-626-8892
Email: qiana at biostat.umn.edu



From dreamhouse at gmail.com  Wed Mar 30 22:27:08 2005
From: dreamhouse at gmail.com (dream home)
Date: Wed, 30 Mar 2005 12:27:08 -0800
Subject: [R] French Curve
Message-ID: <988c1eae0503301227bb699f0@mail.gmail.com>

Dear R experts,

Did someone implemented French Curve yet?  Or can anyone point me some
papers that I can follow to implement it?

thanks in advance for your help.

Paul



From p.murrell at auckland.ac.nz  Wed Mar 30 22:45:31 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Thu, 31 Mar 2005 08:45:31 +1200
Subject: [R] Base and lattice graphics on the same graphics page
References: <9c4fa8ef707059a5a35d24c8bf008259@anu.edu.au>
	<200503292259.52001.deepayan@stat.wisc.edu>
Message-ID: <424B0FEB.2080304@stat.auckland.ac.nz>

Hi


Deepayan Sarkar wrote:
> On Tuesday 29 March 2005 22:32, John Maindonald wrote:
> 
>>Although base graphics does not mix with lattice in the one graph,
>>I've found that print.trellis(position=..., ) and the use of
>>par(fig=...)
>>to put regular and trellis graphics on the one graphics page works
>>like a treat, at least in version 2.0.1 of R.  [Base graphics
>>functions that are themselves inconsistent with par(fig=...) are
>>obviously disallowed.]
>>
>>I am wondering whether there are caveats of which I and others
>>should be aware, or whether there is a risk that the ongoing
>>development of R's graphics abilities will render such a cohabitation
>>unworkably fractious.
> 
> 
> Paul would know better, but I think that's unlikely. In fact, the 
> gridBase package allows you to do use grid (and hence lattice) 
> functions to add to a base plot, as well as (I didn't realize this 
> before) the other way round. The only caveat is that resizing the 
> device may mess things up. 


Yep, sounds like you're doing exactly the sort of thing that gridBase 
does.  See R News 3(2) for a discussion.

Paul


> You may have to be careful with new devices. Your example pasted on a 
> fresh session (tested only on r-devel) starts a new page for the 
> boxplot since it thinks that new=TRUE doesn't make sense (because 
> there's no 'old' plot yet).
> 
> Deepayan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From sfalcon at fhcrc.org  Wed Mar 30 22:56:03 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 30 Mar 2005 12:56:03 -0800
Subject: [BioC] Follow-up to:  [R] Annotation metadata "kills" help.search
In-Reply-To: <NCEEILPLHGEMJBGGKFCLOEOHCAAA.gerard.tromp@sanger.med.wayne.edu>
	(Gerard Tromp's message of "Tue, 29 Mar 2005 14:30:25 -0500")
References: <NCEEILPLHGEMJBGGKFCLOEOHCAAA.gerard.tromp@sanger.med.wayne.edu>
Message-ID: <m2fyycua3g.fsf@macaroni.local>

Hello Gerard, all,

The annotation packages breaking help.search was due to improperly
built annotation packages.

We have posted updated annotation packages to the Bioconductor meta
data repository.

Reinstalling the annotation data packages should resolve the issue and
allow help.search to function normally.

Please let us know (on bioconductor at stat.math.ethz.ch) if you find
otherwise.

Thanks,

+ seth



From r+Steven.Murdoch at cl.cam.ac.uk  Thu Mar 31 01:00:12 2005
From: r+Steven.Murdoch at cl.cam.ac.uk (Steven J. Murdoch)
Date: Thu, 31 Mar 2005 00:00:12 +0100
Subject: [R] Finding the "height of a line of text" for axis
In-Reply-To: <1112191390.4905.11.camel@horizons.localdomain>
References: <20050330100617.GA7312@cl.cam.ac.uk>
	<1112191390.4905.11.camel@horizons.localdomain>
Message-ID: <20050330230012.GA9261@cl.cam.ac.uk>

Thanks for your reply.

On Wed, Mar 30, 2005 at 08:03:10AM -0600, Marc Schwartz wrote:
> or even something like this:
> 
>  plot(1:5, axes = FALSE)
>  axis(1, col.axis = "white", col = "red", tcl = 1)
>  axis(1, col.axis = "white", col = "white", tcl = 0)
>  axis(2, col.axis = "white", col = "red", tcl = 1)
>  axis(2, col.axis = "white", col = "white", tcl = 0)

This is the effect I am trying to achieve. I did try the route of
overdrawing in white, but decided against it. The reason I haven't
used that, is that firstly I wasn't sure if there would be some
rounding error in a printer which would cause the background to
appear. Secondly, the end of the ticks look weird due to the different
line end types:
 http://www.cl.cam.ac.uk/users/sjm217/volatile/r-lineend.png

Changing to square caps might help, but I was hoping there would be a
nice solution that would let me keep round caps. Any suggestions?

Thank you,
Steven Murdoch.
-- 
w: http://www.cl.cam.ac.uk/users/sjm217/



From cznm4 at mizzou.edu  Thu Mar 31 01:04:58 2005
From: cznm4 at mizzou.edu (Chao Zhu)
Date: Wed, 30 Mar 2005 17:04:58 -0600
Subject: [R] Cox model qustion in R
Message-ID: <001601c5357c$e51f7cb0$0923ce80@chao>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050330/f163982a/attachment.pl

From p.murrell at auckland.ac.nz  Thu Mar 31 02:17:19 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Thu, 31 Mar 2005 12:17:19 +1200
Subject: [R] Finding the "height of a line of text" for axis
References: <20050330100617.GA7312@cl.cam.ac.uk>	<1112191390.4905.11.camel@horizons.localdomain>
	<20050330230012.GA9261@cl.cam.ac.uk>
Message-ID: <424B418F.2090203@stat.auckland.ac.nz>

Hi


Steven J. Murdoch wrote:
> Thanks for your reply.
> 
> On Wed, Mar 30, 2005 at 08:03:10AM -0600, Marc Schwartz wrote:
> 
>>or even something like this:
>>
>> plot(1:5, axes = FALSE)
>> axis(1, col.axis = "white", col = "red", tcl = 1)
>> axis(1, col.axis = "white", col = "white", tcl = 0)
>> axis(2, col.axis = "white", col = "red", tcl = 1)
>> axis(2, col.axis = "white", col = "white", tcl = 0)
> 
> 
> This is the effect I am trying to achieve. I did try the route of
> overdrawing in white, but decided against it. The reason I haven't
> used that, is that firstly I wasn't sure if there would be some
> rounding error in a printer which would cause the background to
> appear. Secondly, the end of the ticks look weird due to the different
> line end types:
>  http://www.cl.cam.ac.uk/users/sjm217/volatile/r-lineend.png
> 
> Changing to square caps might help, but I was hoping there would be a
> nice solution that would let me keep round caps. Any suggestions?


The function GConvertYUnits() (and the functions it calls) are in the 
file graphics.c (same directory as plot.c), but I'd book a week off 
before trying to trace the calculations performed therein.

A more accurate calculation than ...
   l<-par("cxy")[2]*par("tcl")
... is ...
   l<-par("cin")[2]/par("pin")[1]*diff(par("usr")[1:2])*par("tcl")
... but that still needs par("cex") and a par("mex") multipliers to be 
(possibly) fully par() compliant.  This general 
replicate-par()-in-R-code route is likely to be a recipe for unhappiness.

Some sort of overplotting trick is probably a better choice if you can 
cope with the compromise.  The following variation on Marc's suggestion 
might provide a slight improvement:

  plot(1:5, axes = FALSE)
  axis(1, col.axis = "white", col = "red", tcl = 1)
  axis(2, col.axis = "white", col = "red", tcl = 1)
  box(col="white")

Something like box(col="white", lwd=1.1) could be used to allay fears of 
axes peeking through from behind.

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From Tom.Mulholland at dpi.wa.gov.au  Thu Mar 31 03:01:57 2005
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Thu, 31 Mar 2005 09:01:57 +0800
Subject: [R] Re:Plotting to A4 and replacing x-axis with actual years.
Message-ID: <33F91FB3FDF42E4180428AC66A5CF30B02D3BAAF@afhex01.dpi.wa.gov.au>

I think you need to read the posting guide (see the bottom of each post made) and once you have done this take some time to compose your message.

The issue is that I have too little information about what you have done. It looks to me as if you are using postscript, but I am not sure if you have plotted your 3 x 3 array to the device and used the command parameter or if your reference to "written commands" is actually the 'postscript' command.

Specifically the posting guide notes that a small reproducible example of the issue that you are facing will make it much easier for people to help you. It also talks about the need to identify the hardware that you are using as for certain processes the answer is quite different in Windows than it is in some flavour of Unix.

The same is true of your second inquiry. Dummy code would make it easier to see what you are doing.

Tom



> -----Original Message-----
> From: Marshall Mdoka [mailto:mmdoka at egs.uct.ac.za]
> Sent: Wednesday, 30 March 2005 10:47 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Re:Plotting to A4 and replacing x-axis with actual years.
> 
> 
> Hie,
> 
> I have written before and probably missed the reply.
> 
> 1.) I have my figures in a 3X3 array and want to fit them 
> onto a A4 size
> page. I have written commands to try a represent them in eps 
> format but
> still their cutting out information.
> 
> 2.) I have an odd number of years and wanted to represent 
> them say 1980 1985
> 1990 1995 2000 instead of 1 5 10 etc. However, the years are not
> overwritting in the year I want since the first year in my 
> x-axis is 1979
> which is year 1 and year 5 being 1984.
> 
> Could you please help especially on the first problem.
> 
> Thanking you in advance,
> 
> Marshall Mdoka
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ashajayanthi at hotmail.com  Thu Mar 31 03:17:18 2005
From: ashajayanthi at hotmail.com (Asha Jayanthi)
Date: Thu, 31 Mar 2005 01:17:18 +0000
Subject: [R] 2d plotting and colours
In-Reply-To: <33F91FB3FDF42E4180428AC66A5CF30B02D3BAAE@afhex01.dpi.wa.gov.au>
Message-ID: <BAY10-F1510FF0D69017F3FC380B5DC470@phx.gbl>

Thank you very much.

the code
plot(x, col = s)
points(cl$centers, col = s, pch = 8, cex=2)

does not plot the points according to the group colors. The plots are used 
to identify the groups by colors

That could be done by

plot(x, col = cl$cluster)

This means that we need to set the default colours , say col = cl$cluster = 
a set of group numbers say 1...10 should produce 10 distinct colours points 
grouped by colour.

how to do this when you have more than 8 group colours to plot

>From: "Mulholland, Tom" <Tom.Mulholland at dpi.wa.gov.au>
>To: <r-help at stat.math.ethz.ch>,"Asha Jayanthi" <ashajayanthi at hotmail.com>
>Subject: RE: [R] 2d plotting and colours
>Date: Wed, 30 Mar 2005 15:59:46 +0800
>
>And getting back to your question about the palette
>
>there are a lot of ways to do this
>
>assuming you have just started a session
>
>palette()
># will give
>#[1] "black"   "red"     "green3"  "blue"    "cyan"
>#[6] "magenta" "yellow"  "gray"
>
>palette(rainbow(24))  # There's also 'heat.colors' & 'topo.colors'
>palette()
>
># [1] "red"         "#FF4000"     "#FF8000"
># [4] "#FFBF00"     "yellow"      "#BFFF00"
># [7] "#80FF00"     "#40FF00"     "green"
>#[10] "#00FF40"     "#00FF80"     "#00FFBF"
>#[13] "cyan"        "deepskyblue" "#0080FF"
>#[16] "#0040FF"     "blue"        "#4000FF"
>#[19] "#8000FF"     "#BF00FF"     "magenta"
>#[22] "#FF00BF"     "#FF0080"     "#FF0040"
>
>palette(rgb((0:15)/15, g=0,b=0, names=paste("red",0:15,sep=".")))
>palette()
># [1] "black"   "#110000" "#220000" "#330000" "#440000"
># [6] "#550000" "#660000" "#770000" "#880000" "#990000"
>#[11] "#AA0000" "#BB0000" "#CC0000" "#DD0000" "red2"
>#[16] "red"
>
>If you are looking to use colours that take account of colour blindness
>you could try the package dichromat. (I think 2.1 will have some of this 
>inbuilt)
>
>Once you look through the help files associated with some of these options 
>you
>will find the way that best suits your method of working.
>
>Tom
>
>
>
>
>
>
> > -----Original Message-----
> > From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
> > Sent: Wednesday, 30 March 2005 3:18 PM
> > To: TEMPL Matthias
> > Cc: r-help at stat.math.ethz.ch; Asha Jayanthi
> > Subject: Re: [R] 2d plotting and colours
> >
> >
> > TEMPL Matthias wrote:
> >
> > > Hi!
> > >
> > > There are more than 8 colors.
> >
> > Yes, e.g. for rgb space there are 16777216, see ?rgb.
> >
> > Uwe Ligges
> >
> >
> >
> > > x <- rbind(matrix(rnorm(100, sd = 0.3), ncol = 2),
> > >                 matrix(rnorm(100, mean = 1, sd = 0.3), ncol = 2))
> > >
> > > (cl <- kmeans(x, i, 20))
> > >
> > > s <- c("tomato4", "turquoise", "slateblue", "wheat",
> > "snow", "skyblue",
> > > "peru", "pink")
> > > # see at:
> > > colors()
> > >
> > > plot(x, col = s)
> > >
> > > points(cl$centers, col = s, pch = 8, cex=2)
> > >
> > >
> > > Best,
> > > Matthias
> > >
> > >
> > >
> > >
> > >
> > >>Hi!
> > >>
> > >>I am new to R just 3 days in it and i apologize if my
> > >>questions seem very
> > >>trivial and consumed your valuable time.
> > >>
> > >>I am coding in perl and i stumbled upon R regarding plotting good
> > >>statistical graphs.
> > >>
> > >>I tried the kmean clustering for a large matrix ,say > 150 *
> > >>150 . I tried
> > >>the example code given in the tutorial to perform 2d plot
> > >>
> > >># i ranges from 2 to 10
> > >>cl <- kmeans(x, i, 20)
> > >>plot(x, col = cl$cluster)
> > >>points(cl$centers, col = 1:i )
> > >>
> > >>I see that there are only 8 colours defined , namely
> > >>black,red,green,blue,cyan,magenta,yello,gray.
> > >>
> > >>How should i set my colour preferences to obtain my palette
> > >>of colours? I
> > >>checked in the totorial which talks about R.colors and
> > >>palatte , but i
> > >>failed to understand how to set it.
> > >>
> > >>Thank You
> > >>
> > >>Asha
> > >>
> > >>




From ashajayanthi at hotmail.com  Thu Mar 31 03:22:03 2005
From: ashajayanthi at hotmail.com (Asha Jayanthi)
Date: Thu, 31 Mar 2005 01:22:03 +0000
Subject: [R] NA's?
In-Reply-To: <33F91FB3FDF42E4180428AC66A5CF30B02D3BAAE@afhex01.dpi.wa.gov.au>
Message-ID: <BAY10-F4880785D65EA9CEBE11EF6DC470@phx.gbl>

I have a large matrix of data .

The size of the matrix ranges from 100 x 100 to 1000 x 1000

Now i have to do computations on that. And should not consider the diagonal 
elements.

I tried setting diag(M) = NA  and M = na.omit(M).

But this omits all the rows. I only want to omit that diagonal elements only 
but consider the whole row.

diag(M) = 0 seems like a good option but this will affect my result.

How to proceed with this. How to just ignore some specific values. what if i 
want to consider only the upper / lower triangular matrix

Asha


http://adfarm.mediaplex.com/ad/ck/4686-26272-10936-31?ck=RegSell Start your 
business.



From ssk2031 at columbia.edu  Thu Mar 31 03:29:09 2005
From: ssk2031 at columbia.edu (Suresh Krishna)
Date: Wed, 30 Mar 2005 20:29:09 -0500
Subject: [R] Contingency table: logistic regression
Message-ID: <424B5265.30205@columbia.edu>


Hi,

I am analyzing a data set with greater than 1000 independent cases 
(collected in an unrestricted manner), where each case has 3 variables 
associated with it: one, a factor variable with 0/1 levels (called XX), 
another factor variable with 8 levels (X) and a third response variable 
with two levels (Y: 0/1). I am trying to see if X1 has an effect on the 
relationship between X2 and the proportion of 1-s in Y.

I have three questions:

a) I have never used glm-s for this or any other sort of analysis before 
today, so am I interpreting the output correctly ?

After setting options(contrasts=c("contr.treatment","contr.poly"))

I did:

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Begin R output~~~~~~~~~~~~~~~~~~~~~~
Call:
glm(formula = Y ~ X * Fac, family = "binomial", data = mat, subset = 
sactype < 3 & numstim == 16)

Deviance Residuals:
    Min      1Q  Median      3Q     Max
-2.232  -0.901   0.416   0.985   1.656

Coefficients:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)    2.405      0.209   11.52  < 2e-16 ***
X2            -2.511      0.293   -8.57  < 2e-16 ***
X3            -3.283      0.286  -11.47  < 2e-16 ***
X4            -2.009      0.302   -6.65    3e-11 ***
X5            -3.098      0.276  -11.22  < 2e-16 ***
X6            -2.580      0.288   -8.97  < 2e-16 ***
X7            -3.484      0.288  -12.09  < 2e-16 ***
X8            -2.811      0.328   -8.56  < 2e-16 ***
Fac           -1.558      0.721   -2.16  0.03071 *
X2:Fac         2.133      0.942    2.26  0.02351 *
X3:Fac         1.848      0.932    1.98  0.04748 *
X4:Fac         2.836      0.982    2.89  0.00386 **
X5:Fac         3.263      0.945    3.45  0.00056 ***
X6:Fac         3.630      0.971    3.74  0.00018 ***
X7:Fac         3.256      0.883    3.69  0.00023 ***
X8:Fac         3.350      1.000    3.35  0.00081 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

(Dispersion parameter for binomial family taken to be 1)

     Null deviance: 1619.4  on 1178  degrees of freedom
Residual deviance: 1271.2  on 1163  degrees of freedom
AIC: 1303

Number of Fisher Scoring iterations: 5

~~~~~~~~~~~~~~~~~~~~~~~~End R output~~~~~~~~~~~~~~~~~~~~~~~~~~~

I am reading this like this: each of the X2....X8 terms tell me whether 
the proportions associated with those factors at level 0 of Fac, are 
different from the proportion associated with factor X1 for level 0 of 
Fac. And each of the terms associated with Fac (X2:Fac,.......X8:Fac) is 
telling me whether the difference between X2...X8 and X1 is different 
for Fac=0 and Fac=1; and this is the same thing as whether the 
proportion associated with X2......X8 are different for the two levels 
of Fac. So these X2...X8:Fac terms are like performing a simple 2x2 
analysis of the effect of Fac on Y, given X2 (....X8).

How much of this is incorrect ?

My other two questions are:

b) Is this the right way to approach this analysis in R ? Or am I better 
off reading about multi-way contingency table analyses and using them ?

and

c) How do I incorporate a correction for multiple-testing into the above 
analysis ? The effect of Fac on the relationship between X and Y was 
planned.

I would greatly, and respectfully appreciate all pointers, tips and 
admonitions.

Thank you !!!!

Suresh



From ssk2031 at columbia.edu  Thu Mar 31 03:32:57 2005
From: ssk2031 at columbia.edu (Suresh Krishna)
Date: Wed, 30 Mar 2005 20:32:57 -0500
Subject: [R] Re: Contingency table: logistic regression
Message-ID: <424B5349.4020107@columbia.edu>


Oops, I corrected some errors in the first paragraph; sorry for the 
repeated posting.

Suresh

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Hi,

I am analyzing a data set with greater than 1000 independent cases
(collected in an unrestricted manner), where each case has 3 variables
associated with it: one, a factor variable with 0/1 levels (called Fac),
another factor variable with 8 levels (X) and a third response variable
with two levels (Y: 0/1). I am trying to see if Fac has an effect on the
relationship between X and the proportion of 1-s in Y.

I have three questions:

a) I have never used glm-s for this or any other sort of analysis before
today, so am I interpreting the output correctly ?

After setting options(contrasts=c("contr.treatment","contr.poly"))

I did:

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Begin R output~~~~~~~~~~~~~~~~~~~~~~
Call:
glm(formula = Y ~ X * Fac, family = "binomial", data = mat, subset =
sactype < 3 & numstim == 16)

Deviance Residuals:
    Min      1Q  Median      3Q     Max
-2.232  -0.901   0.416   0.985   1.656

Coefficients:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)    2.405      0.209   11.52  < 2e-16 ***
X2            -2.511      0.293   -8.57  < 2e-16 ***
X3            -3.283      0.286  -11.47  < 2e-16 ***
X4            -2.009      0.302   -6.65    3e-11 ***
X5            -3.098      0.276  -11.22  < 2e-16 ***
X6            -2.580      0.288   -8.97  < 2e-16 ***
X7            -3.484      0.288  -12.09  < 2e-16 ***
X8            -2.811      0.328   -8.56  < 2e-16 ***
Fac           -1.558      0.721   -2.16  0.03071 *
X2:Fac         2.133      0.942    2.26  0.02351 *
X3:Fac         1.848      0.932    1.98  0.04748 *
X4:Fac         2.836      0.982    2.89  0.00386 **
X5:Fac         3.263      0.945    3.45  0.00056 ***
X6:Fac         3.630      0.971    3.74  0.00018 ***
X7:Fac         3.256      0.883    3.69  0.00023 ***
X8:Fac         3.350      1.000    3.35  0.00081 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

(Dispersion parameter for binomial family taken to be 1)

     Null deviance: 1619.4  on 1178  degrees of freedom
Residual deviance: 1271.2  on 1163  degrees of freedom
AIC: 1303

Number of Fisher Scoring iterations: 5

~~~~~~~~~~~~~~~~~~~~~~~~End R output~~~~~~~~~~~~~~~~~~~~~~~~~~~

I am reading this like this: each of the X2....X8 terms tell me whether
the proportions associated with those factors at level 0 of Fac, are
different from the proportion associated with factor X1 for level 0 of
Fac. And each of the terms associated with Fac (X2:Fac,.......X8:Fac) is
telling me whether the difference between X2...X8 and X1 is different
for Fac=0 and Fac=1; and this is the same thing as whether the
proportion associated with X2......X8 are different for the two levels
of Fac. So these X2...X8:Fac terms are like performing a simple 2x2
analysis of the effect of Fac on Y, given X2 (....X8).

How much of this is incorrect ?

My other two questions are:

b) Is this the right way to approach this analysis in R ? Or am I better
off reading about multi-way contingency table analyses and using them ?

and

c) How do I incorporate a correction for multiple-testing into the above
analysis ? The effect of Fac on the relationship between X and Y was
planned.

I would greatly, and respectfully appreciate all pointers, tips and
admonitions.

Thank you !!!!

Suresh



From Bill.Venables at csiro.au  Thu Mar 31 03:42:05 2005
From: Bill.Venables at csiro.au (Bill.Venables@csiro.au)
Date: Thu, 31 Mar 2005 11:42:05 +1000
Subject: [R] NA's?
Message-ID: <B998A44C8986644EA8029CFE6396A9241B2FA3@exqld2-bne.qld.csiro.au>

Your message doesn't help us very much.  You haven't said what kind of
calculation it is you want to do, and that certainly matters.  For
example, for some kinds of computations the solution you started below
would work fine:

> M <- matrix(1:16, 4, 4)
> is.na(diag(M)) <- TRUE
> M
     [,1] [,2] [,3] [,4]
[1,]   NA    5    9   13
[2,]    2   NA   10   14
[3,]    3    7   NA   15
[4,]    4    8   12   NA
> rowSums(M, na.rm = TRUE)
[1] 27 26 25 24
> colSums(M, na.rm = TRUE)
[1]  9 20 31 42

You can also use apply( ) with functions that will accept missing values
(and ignore them) for computations on either the rows or the columns.

Hoping for a general mechanism that would somehow signal the diagonal
values as values to be "ignored" in a general way is not a possibility.
Just as a curiosity, what were you hoping that na.omit(M) would do?

V.

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Asha Jayanthi
Sent: Thursday, 31 March 2005 11:22 AM
To: r-help at stat.math.ethz.ch
Subject: [R] NA's?


I have a large matrix of data .

The size of the matrix ranges from 100 x 100 to 1000 x 1000

Now i have to do computations on that. And should not consider the
diagonal 
elements.

I tried setting diag(M) = NA  and M = na.omit(M).

But this omits all the rows. I only want to omit that diagonal elements
only 
but consider the whole row.

diag(M) = 0 seems like a good option but this will affect my result.

How to proceed with this. How to just ignore some specific values. what
if i 
want to consider only the upper / lower triangular matrix

Asha


http://adfarm.mediaplex.com/ad/ck/4686-26272-10936-31?ck=RegSell Start
your 
business.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From Tom.Mulholland at dpi.wa.gov.au  Thu Mar 31 04:14:13 2005
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Thu, 31 Mar 2005 10:14:13 +0800
Subject: [R] 2d plotting and colours
Message-ID: <33F91FB3FDF42E4180428AC66A5CF30B02D3BAB0@afhex01.dpi.wa.gov.au>

Since I was only concentrating on colour issues and not on your specific problem I was just showing the possibilities.

Does this code help

n <- 5
par(mfrow = c(2,2))
palette("default")
barplot(1:25,col = 1:25)
palette(rainbow(n))
barplot(1:25,col = 1:25)
palette(rgb((0:15)/15, g=0,b=0, names=paste("red",0:15,sep=".")))
barplot(1:25,col = 1:25)


require(cluster)
x <- runif(100) * 8 + 2
cl <- kmeans(x, n)
palette(rainbow(n))
plot(x, col = cl$cluster)
abline(h = cl$centers, lty = 2,col = "grey" )
palette(palette()[order(cl$centers)])
points(x,col = cl$cluster,pch = 20,cex = 0.4)

However you may wish to choose your colours in a way that is different from cl$cluster which is why I changed the palette before plotting the points. You should see that they now are ordered from bottom to top of the last plot.

You could also choose to create a vector with your colours and then use the value in cl$cluster to select the colours

mycols <- rainbow(n)
plot(x,col = mycols[cl$cluster])

Tom

> -----Original Message-----
> From: Asha Jayanthi [mailto:ashajayanthi at hotmail.com]
> Sent: Thursday, 31 March 2005 9:17 AM
> To: r-help at stat.math.ethz.ch
> Subject: RE: [R] 2d plotting and colours
> 
> 
> Thank you very much.
> 
> the code
> plot(x, col = s)
> points(cl$centers, col = s, pch = 8, cex=2)
> 
> does not plot the points according to the group colors. The 
> plots are used 
> to identify the groups by colors
> 
> That could be done by
> 
> plot(x, col = cl$cluster)
> 
> This means that we need to set the default colours , say col 
> = cl$cluster = 
> a set of group numbers say 1...10 should produce 10 distinct 
> colours points 
> grouped by colour.
> 
> how to do this when you have more than 8 group colours to plot
> 
> >From: "Mulholland, Tom" <Tom.Mulholland at dpi.wa.gov.au>
> >To: <r-help at stat.math.ethz.ch>,"Asha Jayanthi" 
> <ashajayanthi at hotmail.com>
> >Subject: RE: [R] 2d plotting and colours
> >Date: Wed, 30 Mar 2005 15:59:46 +0800
> >
> >And getting back to your question about the palette
> >
> >there are a lot of ways to do this
> >
> >assuming you have just started a session
> >
> >palette()
> ># will give
> >#[1] "black"   "red"     "green3"  "blue"    "cyan"
> >#[6] "magenta" "yellow"  "gray"
> >
> >palette(rainbow(24))  # There's also 'heat.colors' & 'topo.colors'
> >palette()
> >
> ># [1] "red"         "#FF4000"     "#FF8000"
> ># [4] "#FFBF00"     "yellow"      "#BFFF00"
> ># [7] "#80FF00"     "#40FF00"     "green"
> >#[10] "#00FF40"     "#00FF80"     "#00FFBF"
> >#[13] "cyan"        "deepskyblue" "#0080FF"
> >#[16] "#0040FF"     "blue"        "#4000FF"
> >#[19] "#8000FF"     "#BF00FF"     "magenta"
> >#[22] "#FF00BF"     "#FF0080"     "#FF0040"
> >
> >palette(rgb((0:15)/15, g=0,b=0, names=paste("red",0:15,sep=".")))
> >palette()
> ># [1] "black"   "#110000" "#220000" "#330000" "#440000"
> ># [6] "#550000" "#660000" "#770000" "#880000" "#990000"
> >#[11] "#AA0000" "#BB0000" "#CC0000" "#DD0000" "red2"
> >#[16] "red"
> >
> >If you are looking to use colours that take account of 
> colour blindness
> >you could try the package dichromat. (I think 2.1 will have 
> some of this 
> >inbuilt)
> >
> >Once you look through the help files associated with some of 
> these options 
> >you
> >will find the way that best suits your method of working.
> >
> >Tom
> >
> >
> >
> >
> >
> >
> > > -----Original Message-----
> > > From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
> > > Sent: Wednesday, 30 March 2005 3:18 PM
> > > To: TEMPL Matthias
> > > Cc: r-help at stat.math.ethz.ch; Asha Jayanthi
> > > Subject: Re: [R] 2d plotting and colours
> > >
> > >
> > > TEMPL Matthias wrote:
> > >
> > > > Hi!
> > > >
> > > > There are more than 8 colors.
> > >
> > > Yes, e.g. for rgb space there are 16777216, see ?rgb.
> > >
> > > Uwe Ligges
> > >
> > >
> > >
> > > > x <- rbind(matrix(rnorm(100, sd = 0.3), ncol = 2),
> > > >                 matrix(rnorm(100, mean = 1, sd = 0.3), 
> ncol = 2))
> > > >
> > > > (cl <- kmeans(x, i, 20))
> > > >
> > > > s <- c("tomato4", "turquoise", "slateblue", "wheat",
> > > "snow", "skyblue",
> > > > "peru", "pink")
> > > > # see at:
> > > > colors()
> > > >
> > > > plot(x, col = s)
> > > >
> > > > points(cl$centers, col = s, pch = 8, cex=2)
> > > >
> > > >
> > > > Best,
> > > > Matthias
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >>Hi!
> > > >>
> > > >>I am new to R just 3 days in it and i apologize if my
> > > >>questions seem very
> > > >>trivial and consumed your valuable time.
> > > >>
> > > >>I am coding in perl and i stumbled upon R regarding 
> plotting good
> > > >>statistical graphs.
> > > >>
> > > >>I tried the kmean clustering for a large matrix ,say > 150 *
> > > >>150 . I tried
> > > >>the example code given in the tutorial to perform 2d plot
> > > >>
> > > >># i ranges from 2 to 10
> > > >>cl <- kmeans(x, i, 20)
> > > >>plot(x, col = cl$cluster)
> > > >>points(cl$centers, col = 1:i )
> > > >>
> > > >>I see that there are only 8 colours defined , namely
> > > >>black,red,green,blue,cyan,magenta,yello,gray.
> > > >>
> > > >>How should i set my colour preferences to obtain my palette
> > > >>of colours? I
> > > >>checked in the totorial which talks about R.colors and
> > > >>palatte , but i
> > > >>failed to understand how to set it.
> > > >>
> > > >>Thank You
> > > >>
> > > >>Asha
> > > >>




From Sophie.Bestley at csiro.au  Thu Mar 31 05:33:25 2005
From: Sophie.Bestley at csiro.au (Sophie.Bestley@csiro.au)
Date: Thu, 31 Mar 2005 13:33:25 +1000
Subject: [R] Using kmeans given cluster centroids and data with NAs
Message-ID: <4D99275E380CA94F998977EDACE548DC058A52@extas2-hba.tas.csiro.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050331/83cab25e/attachment.pl

From Tom.Mulholland at dpi.wa.gov.au  Thu Mar 31 05:55:55 2005
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Thu, 31 Mar 2005 11:55:55 +0800
Subject: [R] NA's?
Message-ID: <33F91FB3FDF42E4180428AC66A5CF30B02D3BAB1@afhex01.dpi.wa.gov.au>

See upper.tri and lower.tri.

I think that you might also look for specific packages that function using matrices, from what I have seen these often have the capacity to ignore the diagonal or use just the upper or lower triangle. This is not an area that I use very much, but I have seen various posts about different types of matrices and there appears to be quite a lot of code that deals with the range of types and uses. Obvious candidates include the Matrix package, but a search for matrix in all of the CRAN packages brings up a bewildering variety of matrix related functions. You may find it useful to search for the specific type of manipulation that you are attempting.

Tom

> -----Original Message-----
> From: Asha Jayanthi [mailto:ashajayanthi at hotmail.com]
> Sent: Thursday, 31 March 2005 9:22 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] NA's?
> 
> 
> I have a large matrix of data .
> 
> The size of the matrix ranges from 100 x 100 to 1000 x 1000
> 
> Now i have to do computations on that. And should not 
> consider the diagonal 
> elements.
> 
> I tried setting diag(M) = NA  and M = na.omit(M).
> 
> But this omits all the rows. I only want to omit that 
> diagonal elements only 
> but consider the whole row.
> 
> diag(M) = 0 seems like a good option but this will affect my result.
> 
> How to proceed with this. How to just ignore some specific 
> values. what if i 
> want to consider only the upper / lower triangular matrix
> 
> Asha
> 
> 
> http://adfarm.mediaplex.com/ad/ck/4686-26272-10936-31?ck=RegSe
ll Start your 
business.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Tom.Mulholland at dpi.wa.gov.au  Thu Mar 31 06:14:43 2005
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Thu, 31 Mar 2005 12:14:43 +0800
Subject: [R] Using kmeans given cluster centroids and data with NAs
Message-ID: <33F91FB3FDF42E4180428AC66A5CF30B02D3BAB2@afhex01.dpi.wa.gov.au>

Does ?na.omit help

x <- kmeans(na.omit(data),centres)

of course if you have too many NAs you need to be sure that their removal does not unduly influence the results.

Although I am a bit confused as I thought that agnes did not allow NAs. I assume that you are running an alternative clustering method using the results of the first process as the starting point for the partitioning process and are thus using the same initial data.

Tom

> -----Original Message-----
> From: Sophie.Bestley at csiro.au [mailto:Sophie.Bestley at csiro.au]
> Sent: Thursday, 31 March 2005 11:33 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Using kmeans given cluster centroids and data with NAs
> 
> 
> Hello,
> 
> I have used the functions agnes and cutree to cluster my data (4977
> objects x 22 variables) into 8 clusters. I would like to refine the
> solution using a k-means or similar algorithm, setting the initial
> cluster centres as the group means from agnes. However my data matrix
> has NA's in it and the function kmeans does not appear to accept this?
> 
> > dim(centres)
> [1]  8 22
> 
> > dim(data)
> [1] 4977   22
> 
> > x <- kmeans(data,centres)
> Error in kmeans(data, centres) : NA/NaN/Inf in foreign function call
> (arg 1)
> 
> I have looked extensively through the mail archives but cannot find
> if/where someone has provided the answer.
> 
> Thanks in advance,
> SB
> 
> Sophie Bestley
> Pelagic Fisheries and Ecosystems
> CSIRO Marine Research
> GPO Box 1538 
> Hobart, Tasmania 7001
> AUSTRALIA 
> 
> Phone: +61 3 6232 5048	
> Fax: +61 3 6232 5053	
> Email: sophie.bestley at csiro.au
> Website: http://www.marine.csiro.au
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ashajayanthi at hotmail.com  Thu Mar 31 07:47:53 2005
From: ashajayanthi at hotmail.com (Asha Jayanthi)
Date: Thu, 31 Mar 2005 05:47:53 +0000
Subject: [R] NA's?
In-Reply-To: <B998A44C8986644EA8029CFE6396A9241B2FA3@exqld2-bne.qld.csiro.au>
Message-ID: <BAY10-F1671175235A0F095D6A81BDC470@phx.gbl>

I am sorry about that.


I like to do column mean, sd, var

as well as kmeans on the matrix

does this  na.rm = TRUE work for such fuctions and only the diagonal is 
ignored?

>From: <Bill.Venables at csiro.au>
>To: <ashajayanthi at hotmail.com>,<r-help at stat.math.ethz.ch>
>Subject: RE: [R] NA's?
>Date: Thu, 31 Mar 2005 11:42:05 +1000
>
>Your message doesn't help us very much.  You haven't said what kind of
>calculation it is you want to do, and that certainly matters.  For
>example, for some kinds of computations the solution you started below
>would work fine:
>
> > M <- matrix(1:16, 4, 4)
> > is.na(diag(M)) <- TRUE
> > M
>      [,1] [,2] [,3] [,4]
>[1,]   NA    5    9   13
>[2,]    2   NA   10   14
>[3,]    3    7   NA   15
>[4,]    4    8   12   NA
> > rowSums(M, na.rm = TRUE)
>[1] 27 26 25 24
> > colSums(M, na.rm = TRUE)
>[1]  9 20 31 42
>
>You can also use apply( ) with functions that will accept missing values
>(and ignore them) for computations on either the rows or the columns.
>
>Hoping for a general mechanism that would somehow signal the diagonal
>values as values to be "ignored" in a general way is not a possibility.
>Just as a curiosity, what were you hoping that na.omit(M) would do?
>
>V.
>
>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Asha Jayanthi
>Sent: Thursday, 31 March 2005 11:22 AM
>To: r-help at stat.math.ethz.ch
>Subject: [R] NA's?
>
>
>I have a large matrix of data .
>
>The size of the matrix ranges from 100 x 100 to 1000 x 1000
>
>Now i have to do computations on that. And should not consider the
>diagonal
>elements.
>
>I tried setting diag(M) = NA  and M = na.omit(M).
>
>But this omits all the rows. I only want to omit that diagonal elements
>only
>but consider the whole row.
>
>diag(M) = 0 seems like a good option but this will affect my result.
>
>How to proceed with this. How to just ignore some specific values. what
>if i
>want to consider only the upper / lower triangular matrix
>
>Asha
>
>
>http://adfarm.mediaplex.com/ad/ck/4686-26272-10936-31?ck=RegSell Start
>your
>business.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide!
>http://www.R-project.org/posting-guide.html


http://ads.mediaturf.net/event.ng/Type=click&FlightID=17307&AdID=44925&TargetID=9763&Targets=9763&Values=414,868,1093,2385&Redirect=http:%2F%2Fwww.icicibanknripromotions.com%2Fm2i_feb%2Fnri_M2I_feb.jsp%3Fadid%3D44925%26siteid%3D1093%26flightid%3D17307 
Get a FREE 30 minute India Calling Card.



From ashajayanthi at hotmail.com  Thu Mar 31 07:52:56 2005
From: ashajayanthi at hotmail.com (Asha Jayanthi)
Date: Thu, 31 Mar 2005 05:52:56 +0000
Subject: [R] NA's?
In-Reply-To: <B998A44C8986644EA8029CFE6396A9241B2FA3@exqld2-bne.qld.csiro.au>
Message-ID: <BAY10-F309F21E9E950B21E6339CEDC470@phx.gbl>

i have not answered your query in the last mail.

I hoped na.omit(M) will just ingnore the diagonal elements. i learnt by 
practice that it removes the whole row which has atleast one NA!! (that is 
not the case in Perl)

Since I am bit new to R, i did not knew how to just ignore those elements in 
R


>From: <Bill.Venables at csiro.au>
>To: <ashajayanthi at hotmail.com>,<r-help at stat.math.ethz.ch>
>Subject: RE: [R] NA's?
>Date: Thu, 31 Mar 2005 11:42:05 +1000
>
>Your message doesn't help us very much.  You haven't said what kind of
>calculation it is you want to do, and that certainly matters.  For
>example, for some kinds of computations the solution you started below
>would work fine:
>
> > M <- matrix(1:16, 4, 4)
> > is.na(diag(M)) <- TRUE
> > M
>      [,1] [,2] [,3] [,4]
>[1,]   NA    5    9   13
>[2,]    2   NA   10   14
>[3,]    3    7   NA   15
>[4,]    4    8   12   NA
> > rowSums(M, na.rm = TRUE)
>[1] 27 26 25 24
> > colSums(M, na.rm = TRUE)
>[1]  9 20 31 42
>
>You can also use apply( ) with functions that will accept missing values
>(and ignore them) for computations on either the rows or the columns.
>
>Hoping for a general mechanism that would somehow signal the diagonal
>values as values to be "ignored" in a general way is not a possibility.
>Just as a curiosity, what were you hoping that na.omit(M) would do?
>
>V.
>
>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Asha Jayanthi
>Sent: Thursday, 31 March 2005 11:22 AM
>To: r-help at stat.math.ethz.ch
>Subject: [R] NA's?
>
>
>I have a large matrix of data .
>
>The size of the matrix ranges from 100 x 100 to 1000 x 1000
>
>Now i have to do computations on that. And should not consider the
>diagonal
>elements.
>
>I tried setting diag(M) = NA  and M = na.omit(M).
>
>But this omits all the rows. I only want to omit that diagonal elements
>only
>but consider the whole row.
>
>diag(M) = 0 seems like a good option but this will affect my result.
>
>How to proceed with this. How to just ignore some specific values. what
>if i
>want to consider only the upper / lower triangular matrix
>
>Asha
>
>
>http://adfarm.mediaplex.com/ad/ck/4686-26272-10936-31?ck=RegSell Start
>your
>business.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide!
>http://www.R-project.org/posting-guide.html


http://creative.mediaturf.net/creatives/citibankrca/rca_msntagofline.htm 
Without minimum balance for 20 yrs!



From muster at gmail.com  Thu Mar 31 08:18:43 2005
From: muster at gmail.com (Terry Mu)
Date: Thu, 31 Mar 2005 01:18:43 -0500
Subject: [R] Can I extract result row of table()?
Message-ID: <b68812e705033022186ed53e0e@mail.gmail.com>

> x <- c(5, 5, 8, 8, 8, 27)
> table(x)
x
 5  8 27 
 2  3  1 

I want a way to use only "2, 3, 1", nomatter table or what other function used.
Thanks.



From ligges at statistik.uni-dortmund.de  Thu Mar 31 08:24:27 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 31 Mar 2005 08:24:27 +0200
Subject: [R] Can I extract result row of table()?
In-Reply-To: <b68812e705033022186ed53e0e@mail.gmail.com>
References: <b68812e705033022186ed53e0e@mail.gmail.com>
Message-ID: <424B979B.8010106@statistik.uni-dortmund.de>

Terry Mu wrote:

>>x <- c(5, 5, 8, 8, 8, 27)
>>table(x)
> 
> x
>  5  8 27 
>  2  3  1 
> 
> I want a way to use only "2, 3, 1", nomatter table or what other function used.


as.vector() removes the attributes, if that is your question.

Uwe Ligges


> Thanks.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ashajayanthi at hotmail.com  Thu Mar 31 08:36:22 2005
From: ashajayanthi at hotmail.com (Asha Jayanthi)
Date: Thu, 31 Mar 2005 06:36:22 +0000
Subject: [R] 2d plotting and colours
In-Reply-To: <33F91FB3FDF42E4180428AC66A5CF30B02D3BAB0@afhex01.dpi.wa.gov.au>
Message-ID: <BAY10-F35ADC9F41134651280FAADDC470@phx.gbl>

Thank you.

mycols <- c("brown","orange","tomato")
plot(x,col = mycols[cl$cluster])

this works. I can define distinct colours and check the graph.

the rest of the examples does not give a wide palette to choose from

Asha
>From: "Mulholland, Tom" <Tom.Mulholland at dpi.wa.gov.au>
>To: "Asha Jayanthi" <ashajayanthi at hotmail.com>,<r-help at stat.math.ethz.ch>
>Subject: RE: [R] 2d plotting and colours
>Date: Thu, 31 Mar 2005 10:14:13 +0800
>
>Since I was only concentrating on colour issues and not on your specific 
>problem I was just showing the possibilities.
>
>Does this code help
>
>n <- 5
>par(mfrow = c(2,2))
>palette("default")
>barplot(1:25,col = 1:25)
>palette(rainbow(n))
>barplot(1:25,col = 1:25)
>palette(rgb((0:15)/15, g=0,b=0, names=paste("red",0:15,sep=".")))
>barplot(1:25,col = 1:25)
>
>
>require(cluster)
>x <- runif(100) * 8 + 2
>cl <- kmeans(x, n)
>palette(rainbow(n))
>plot(x, col = cl$cluster)
>abline(h = cl$centers, lty = 2,col = "grey" )
>palette(palette()[order(cl$centers)])
>points(x,col = cl$cluster,pch = 20,cex = 0.4)
>
>However you may wish to choose your colours in a way that is different from 
>cl$cluster which is why I changed the palette before plotting the points. 
>You should see that they now are ordered from bottom to top of the last 
>plot.
>
>You could also choose to create a vector with your colours and then use the 
>value in cl$cluster to select the colours
>
>mycols <- rainbow(n)
>plot(x,col = mycols[cl$cluster])
>
>Tom
>
> > -----Original Message-----
> > From: Asha Jayanthi [mailto:ashajayanthi at hotmail.com]
> > Sent: Thursday, 31 March 2005 9:17 AM
> > To: r-help at stat.math.ethz.ch
> > Subject: RE: [R] 2d plotting and colours
> >
> >
> > Thank you very much.
> >
> > the code
> > plot(x, col = s)
> > points(cl$centers, col = s, pch = 8, cex=2)
> >
> > does not plot the points according to the group colors. The
> > plots are used
> > to identify the groups by colors
> >
> > That could be done by
> >
> > plot(x, col = cl$cluster)
> >
> > This means that we need to set the default colours , say col
> > = cl$cluster =
> > a set of group numbers say 1...10 should produce 10 distinct
> > colours points
> > grouped by colour.
> >
> > how to do this when you have more than 8 group colours to plot
> >
> > >From: "Mulholland, Tom" <Tom.Mulholland at dpi.wa.gov.au>
> > >To: <r-help at stat.math.ethz.ch>,"Asha Jayanthi"
> > <ashajayanthi at hotmail.com>
> > >Subject: RE: [R] 2d plotting and colours
> > >Date: Wed, 30 Mar 2005 15:59:46 +0800
> > >
> > >And getting back to your question about the palette
> > >
> > >there are a lot of ways to do this
> > >
> > >assuming you have just started a session
> > >
> > >palette()
> > ># will give
> > >#[1] "black"   "red"     "green3"  "blue"    "cyan"
> > >#[6] "magenta" "yellow"  "gray"
> > >
> > >palette(rainbow(24))  # There's also 'heat.colors' & 'topo.colors'
> > >palette()
> > >
> > ># [1] "red"         "#FF4000"     "#FF8000"
> > ># [4] "#FFBF00"     "yellow"      "#BFFF00"
> > ># [7] "#80FF00"     "#40FF00"     "green"
> > >#[10] "#00FF40"     "#00FF80"     "#00FFBF"
> > >#[13] "cyan"        "deepskyblue" "#0080FF"
> > >#[16] "#0040FF"     "blue"        "#4000FF"
> > >#[19] "#8000FF"     "#BF00FF"     "magenta"
> > >#[22] "#FF00BF"     "#FF0080"     "#FF0040"
> > >
> > >palette(rgb((0:15)/15, g=0,b=0, names=paste("red",0:15,sep=".")))
> > >palette()
> > ># [1] "black"   "#110000" "#220000" "#330000" "#440000"
> > ># [6] "#550000" "#660000" "#770000" "#880000" "#990000"
> > >#[11] "#AA0000" "#BB0000" "#CC0000" "#DD0000" "red2"
> > >#[16] "red"
> > >
> > >If you are looking to use colours that take account of
> > colour blindness
> > >you could try the package dichromat. (I think 2.1 will have
> > some of this
> > >inbuilt)
> > >
> > >Once you look through the help files associated with some of
> > these options
> > >you
> > >will find the way that best suits your method of working.
> > >
> > >Tom
> > >
> > >
> > >
> > >
> > >
> > >
> > > > -----Original Message-----
> > > > From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
> > > > Sent: Wednesday, 30 March 2005 3:18 PM
> > > > To: TEMPL Matthias
> > > > Cc: r-help at stat.math.ethz.ch; Asha Jayanthi
> > > > Subject: Re: [R] 2d plotting and colours
> > > >
> > > >
> > > > TEMPL Matthias wrote:
> > > >
> > > > > Hi!
> > > > >
> > > > > There are more than 8 colors.
> > > >
> > > > Yes, e.g. for rgb space there are 16777216, see ?rgb.
> > > >
> > > > Uwe Ligges
> > > >
> > > >
> > > >
> > > > > x <- rbind(matrix(rnorm(100, sd = 0.3), ncol = 2),
> > > > >                 matrix(rnorm(100, mean = 1, sd = 0.3),
> > ncol = 2))
> > > > >
> > > > > (cl <- kmeans(x, i, 20))
> > > > >
> > > > > s <- c("tomato4", "turquoise", "slateblue", "wheat",
> > > > "snow", "skyblue",
> > > > > "peru", "pink")
> > > > > # see at:
> > > > > colors()
> > > > >
> > > > > plot(x, col = s)
> > > > >
> > > > > points(cl$centers, col = s, pch = 8, cex=2)
> > > > >
> > > > >
> > > > > Best,
> > > > > Matthias
> > > > >
> > > > >
> > > > >
> > > > >
> > > > >
> > > > >>Hi!
> > > > >>
> > > > >>I am new to R just 3 days in it and i apologize if my
> > > > >>questions seem very
> > > > >>trivial and consumed your valuable time.
> > > > >>
> > > > >>I am coding in perl and i stumbled upon R regarding
> > plotting good
> > > > >>statistical graphs.
> > > > >>
> > > > >>I tried the kmean clustering for a large matrix ,say > 150 *
> > > > >>150 . I tried
> > > > >>the example code given in the tutorial to perform 2d plot
> > > > >>
> > > > >># i ranges from 2 to 10
> > > > >>cl <- kmeans(x, i, 20)
> > > > >>plot(x, col = cl$cluster)
> > > > >>points(cl$centers, col = 1:i )
> > > > >>
> > > > >>I see that there are only 8 colours defined , namely
> > > > >>black,red,green,blue,cyan,magenta,yello,gray.
> > > > >>
> > > > >>How should i set my colour preferences to obtain my palette
> > > > >>of colours? I
> > > > >>checked in the totorial which talks about R.colors and
> > > > >>palatte , but i
> > > > >>failed to understand how to set it.
> > > > >>
> > > > >>Thank You
> > > > >>
> > > > >>Asha
> > > > >>
> > > > >>
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
>http://www.R-project.org/posting-guide.html



From Tom.Mulholland at dpi.wa.gov.au  Thu Mar 31 08:59:01 2005
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Thu, 31 Mar 2005 14:59:01 +0800
Subject: [R] 2d plotting and colours
Message-ID: <33F91FB3FDF42E4180428AC66A5CF30B02D3BAB4@afhex01.dpi.wa.gov.au>

I'm not sure that I understand you comment about the other examples not giving a wide palette. Are you using wide to refer to the difference in colours rather than the number of choices in the palette? If this is your issue you should look at the dichromat package that I referred to, in particular the colorRamp function. You might also want to have a look at the RColorBrewer package and run the ColorBrewer example. This package specifically deals with the ability to distinguish one colour from another.As the ColorBrewer website notes the tool is "designed to help people select good color schemes for maps and other graphics".

By the way if the mycols code works then

palette(c("brown","orange","tomato"))
plot(x,col = cl$cluster)

should produce exactly the same result.

Tom

> -----Original Message-----
> From: Asha Jayanthi [mailto:ashajayanthi at hotmail.com]
> Sent: Thursday, 31 March 2005 2:36 PM
> To: Mulholland, Tom; r-help at stat.math.ethz.ch
> Subject: RE: [R] 2d plotting and colours
> 
> 
> Thank you.
> 
> mycols <- c("brown","orange","tomato")
> plot(x,col = mycols[cl$cluster])
> 
> this works. I can define distinct colours and check the graph.
> 
> the rest of the examples does not give a wide palette to choose from
> 
> Asha
> >From: "Mulholland, Tom" <Tom.Mulholland at dpi.wa.gov.au>
> >To: "Asha Jayanthi" 
> <ashajayanthi at hotmail.com>,<r-help at stat.math.ethz.ch>
> >Subject: RE: [R] 2d plotting and colours
> >Date: Thu, 31 Mar 2005 10:14:13 +0800
> >
> >Since I was only concentrating on colour issues and not on 
> your specific 
> >problem I was just showing the possibilities.
> >
> >Does this code help
> >
> >n <- 5
> >par(mfrow = c(2,2))
> >palette("default")
> >barplot(1:25,col = 1:25)
> >palette(rainbow(n))
> >barplot(1:25,col = 1:25)
> >palette(rgb((0:15)/15, g=0,b=0, names=paste("red",0:15,sep=".")))
> >barplot(1:25,col = 1:25)
> >
> >
> >require(cluster)
> >x <- runif(100) * 8 + 2
> >cl <- kmeans(x, n)
> >palette(rainbow(n))
> >plot(x, col = cl$cluster)
> >abline(h = cl$centers, lty = 2,col = "grey" )
> >palette(palette()[order(cl$centers)])
> >points(x,col = cl$cluster,pch = 20,cex = 0.4)
> >
> >However you may wish to choose your colours in a way that is 
> different from 
> >cl$cluster which is why I changed the palette before 
> plotting the points. 
> >You should see that they now are ordered from bottom to top 
> of the last 
> >plot.
> >
> >You could also choose to create a vector with your colours 
> and then use the 
> >value in cl$cluster to select the colours
> >
> >mycols <- rainbow(n)
> >plot(x,col = mycols[cl$cluster])
> >
> >Tom
> >
> > > -----Original Message-----
> > > From: Asha Jayanthi [mailto:ashajayanthi at hotmail.com]
> > > Sent: Thursday, 31 March 2005 9:17 AM
> > > To: r-help at stat.math.ethz.ch
> > > Subject: RE: [R] 2d plotting and colours
> > >
> > >
> > > Thank you very much.
> > >
> > > the code
> > > plot(x, col = s)
> > > points(cl$centers, col = s, pch = 8, cex=2)
> > >
> > > does not plot the points according to the group colors. The
> > > plots are used
> > > to identify the groups by colors
> > >
> > > That could be done by
> > >
> > > plot(x, col = cl$cluster)
> > >
> > > This means that we need to set the default colours , say col
> > > = cl$cluster =
> > > a set of group numbers say 1...10 should produce 10 distinct
> > > colours points
> > > grouped by colour.
> > >
> > > how to do this when you have more than 8 group colours to plot
> > >
> > > >From: "Mulholland, Tom" <Tom.Mulholland at dpi.wa.gov.au>
> > > >To: <r-help at stat.math.ethz.ch>,"Asha Jayanthi"
> > > <ashajayanthi at hotmail.com>
> > > >Subject: RE: [R] 2d plotting and colours
> > > >Date: Wed, 30 Mar 2005 15:59:46 +0800
> > > >
> > > >And getting back to your question about the palette
> > > >
> > > >there are a lot of ways to do this
> > > >
> > > >assuming you have just started a session
> > > >
> > > >palette()
> > > ># will give
> > > >#[1] "black"   "red"     "green3"  "blue"    "cyan"
> > > >#[6] "magenta" "yellow"  "gray"
> > > >
> > > >palette(rainbow(24))  # There's also 'heat.colors' & 
> 'topo.colors'
> > > >palette()
> > > >
> > > ># [1] "red"         "#FF4000"     "#FF8000"
> > > ># [4] "#FFBF00"     "yellow"      "#BFFF00"
> > > ># [7] "#80FF00"     "#40FF00"     "green"
> > > >#[10] "#00FF40"     "#00FF80"     "#00FFBF"
> > > >#[13] "cyan"        "deepskyblue" "#0080FF"
> > > >#[16] "#0040FF"     "blue"        "#4000FF"
> > > >#[19] "#8000FF"     "#BF00FF"     "magenta"
> > > >#[22] "#FF00BF"     "#FF0080"     "#FF0040"
> > > >
> > > >palette(rgb((0:15)/15, g=0,b=0, names=paste("red",0:15,sep=".")))
> > > >palette()
> > > ># [1] "black"   "#110000" "#220000" "#330000" "#440000"
> > > ># [6] "#550000" "#660000" "#770000" "#880000" "#990000"
> > > >#[11] "#AA0000" "#BB0000" "#CC0000" "#DD0000" "red2"
> > > >#[16] "red"
> > > >
> > > >If you are looking to use colours that take account of
> > > colour blindness
> > > >you could try the package dichromat. (I think 2.1 will have
> > > some of this
> > > >inbuilt)
> > > >
> > > >Once you look through the help files associated with some of
> > > these options
> > > >you
> > > >will find the way that best suits your method of working.
> > > >
> > > >Tom
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > > > -----Original Message-----
> > > > > From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
> > > > > Sent: Wednesday, 30 March 2005 3:18 PM
> > > > > To: TEMPL Matthias
> > > > > Cc: r-help at stat.math.ethz.ch; Asha Jayanthi
> > > > > Subject: Re: [R] 2d plotting and colours
> > > > >
> > > > >
> > > > > TEMPL Matthias wrote:
> > > > >
> > > > > > Hi!
> > > > > >
> > > > > > There are more than 8 colors.
> > > > >
> > > > > Yes, e.g. for rgb space there are 16777216, see ?rgb.
> > > > >
> > > > > Uwe Ligges
> > > > >
> > > > >
> > > > >
> > > > > > x <- rbind(matrix(rnorm(100, sd = 0.3), ncol = 2),
> > > > > >                 matrix(rnorm(100, mean = 1, sd = 0.3),
> > > ncol = 2))
> > > > > >
> > > > > > (cl <- kmeans(x, i, 20))
> > > > > >
> > > > > > s <- c("tomato4", "turquoise", "slateblue", "wheat",
> > > > > "snow", "skyblue",
> > > > > > "peru", "pink")
> > > > > > # see at:
> > > > > > colors()
> > > > > >
> > > > > > plot(x, col = s)
> > > > > >
> > > > > > points(cl$centers, col = s, pch = 8, cex=2)
> > > > > >
> > > > > >
> > > > > > Best,
> > > > > > Matthias
> > > > > >
> > > > > >
> > > > > >
> > > > > >
> > > > > >
> > > > > >>Hi!
> > > > > >>
> > > > > >>I am new to R just 3 days in it and i apologize if my
> > > > > >>questions seem very
> > > > > >>trivial and consumed your valuable time.
> > > > > >>
> > > > > >>I am coding in perl and i stumbled upon R regarding
> > > plotting good
> > > > > >>statistical graphs.
> > > > > >>
> > > > > >>I tried the kmean clustering for a large matrix ,say > 150 *
> > > > > >>150 . I tried
> > > > > >>the example code given in the tutorial to perform 2d plot
> > > > > >>
> > > > > >># i ranges from 2 to 10
> > > > > >>cl <- kmeans(x, i, 20)
> > > > > >>plot(x, col = cl$cluster)
> > > > > >>points(cl$centers, col = 1:i )
> > > > > >>
> > > > > >>I see that there are only 8 colours defined , namely
> > > > > >>black,red,green,blue,cyan,magenta,yello,gray.
> > > > > >>
> > > > > >>How should i set my colour preferences to obtain my palette
> > > > > >>of colours? I
> > > > > >>checked in the totorial which talks about R.colors and
> > > > > >>palatte , but i
> > > > > >>failed to understand how to set it.
> > > > > >>
> > > > > >>Thank You
> > > > > >>
> > > > > >>Asha
> > > > > >>
> > > > > >>
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> >http://www.R-project.org/posting-guide.html



From Bill.Venables at csiro.au  Thu Mar 31 09:12:50 2005
From: Bill.Venables at csiro.au (Bill.Venables@csiro.au)
Date: Thu, 31 Mar 2005 17:12:50 +1000
Subject: [R] NA's?
Message-ID: <B998A44C8986644EA8029CFE6396A9241B2FD1@exqld2-bne.qld.csiro.au>

is.na(diag(M)) <- TRUE

cmeans <- colMeans(M, na.rm = TRUE)
csd <- apply(M, 2, sd, na.rm = TRUE)
cvar <- csd ^2

(or

cvar <- apply(M, 2, var, na.rm = TRUE)

)

Using 'kmeans' on a matrix but 'ignoring the diagonal entries' just
doesn't make sense as it stands, so I can't help you there.

V.

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Asha Jayanthi
Sent: Thursday, 31 March 2005 3:48 PM
To: r-help at stat.math.ethz.ch
Subject: RE: [R] NA's?


I am sorry about that.


I like to do column mean, sd, var

as well as kmeans on the matrix

does this  na.rm = TRUE work for such fuctions and only the diagonal is 
ignored?

>From: <Bill.Venables at csiro.au>
>To: <ashajayanthi at hotmail.com>,<r-help at stat.math.ethz.ch>
>Subject: RE: [R] NA's?
>Date: Thu, 31 Mar 2005 11:42:05 +1000
>
>Your message doesn't help us very much.  You haven't said what kind of
>calculation it is you want to do, and that certainly matters.  For
>example, for some kinds of computations the solution you started below
>would work fine:
>
> > M <- matrix(1:16, 4, 4)
> > is.na(diag(M)) <- TRUE
> > M
>      [,1] [,2] [,3] [,4]
>[1,]   NA    5    9   13
>[2,]    2   NA   10   14
>[3,]    3    7   NA   15
>[4,]    4    8   12   NA
> > rowSums(M, na.rm = TRUE)
>[1] 27 26 25 24
> > colSums(M, na.rm = TRUE)
>[1]  9 20 31 42
>
>You can also use apply( ) with functions that will accept missing
values
>(and ignore them) for computations on either the rows or the columns.
>
>Hoping for a general mechanism that would somehow signal the diagonal
>values as values to be "ignored" in a general way is not a possibility.
>Just as a curiosity, what were you hoping that na.omit(M) would do?
>
>V.
>
>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Asha Jayanthi
>Sent: Thursday, 31 March 2005 11:22 AM
>To: r-help at stat.math.ethz.ch
>Subject: [R] NA's?
>
>
>I have a large matrix of data .
>
>The size of the matrix ranges from 100 x 100 to 1000 x 1000
>
>Now i have to do computations on that. And should not consider the
>diagonal
>elements.
>
>I tried setting diag(M) = NA  and M = na.omit(M).
>
>But this omits all the rows. I only want to omit that diagonal elements
>only
>but consider the whole row.
>
>diag(M) = 0 seems like a good option but this will affect my result.
>
>How to proceed with this. How to just ignore some specific values. what
>if i
>want to consider only the upper / lower triangular matrix
>
>Asha
>
>
>http://adfarm.mediaplex.com/ad/ck/4686-26272-10936-31?ck=RegSell Start
>your
>business.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide!
>http://www.R-project.org/posting-guide.html


http://ads.mediaturf.net/event.ng/Type=click&FlightID=17307&AdID=44925&T
argetID=9763&Targets=9763&Values=414,868,1093,2385&Redirect=http:%2F%2Fw
ww.icicibanknripromotions.com%2Fm2i_feb%2Fnri_M2I_feb.jsp%3Fadid%3D44925
%26siteid%3D1093%26flightid%3D17307 
Get a FREE 30 minute India Calling Card.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From maechler at stat.math.ethz.ch  Thu Mar 31 09:17:23 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 31 Mar 2005 09:17:23 +0200
Subject: [R] how i can get input from "user input"
In-Reply-To: <200503301809.j2UI9cuT013760@meitner.gene.com>
References: <s24a8322.063@lp-msg1.co.ihc.com>
	<200503301809.j2UI9cuT013760@meitner.gene.com>
Message-ID: <16971.41987.799142.525026@stat.math.ethz.ch>

>>>>> "BertG" == Berton Gunter <gunter.berton at gene.com>
>>>>>     on Wed, 30 Mar 2005 10:09:38 -0800 writes:

    BertG> If you are on Windows and want to go GUI, see
    BertG> ?choose.files, ?winMenuAdd, ?winDialog, ?select.list

with the big drawback that it will only work on Windows.

As Uwe says below, it depends on your context;
for relative simple things, however please consider a portable
solution, using
	  	  menu(), readline(), ..

BTW, menu() has been improved in R 2.1.0 (alpha --> please test!),
and is now connected with select.list() which should work on all
platforms (and uses tcltk on Linux when available).


Martin Maechler, ETH Zurich


    BertG> -- Bert Gunter
    BertG> Genentech Non-Clinical Statistics
    BertG> South San Francisco, CA
 
    BertG> "The business of the statistician is to catalyze the scientific learning
    BertG> process."  - George E. P. Box
 
 

    >> -----Original Message-----
    >> From: r-help-bounces at stat.math.ethz.ch 
    >> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Greg Snow
    >> Sent: Wednesday, March 30, 2005 9:45 AM
    >> To: ligges at statistik.uni-dortmund.de; cuiczhao at yahoo.com
    >> Cc: r-help at stat.math.ethz.ch
    >> Subject: Re: [R] how i can get input from "user input"
    >> 
    >> Also look at ?readline
    >> 
    >> Greg Snow, Ph.D.
    >> Statistical Data Center
    >> greg.snow at ihc.com
    >> (801) 408-8111
    >> 
    >> >>> Uwe Ligges <ligges at statistik.uni-dortmund.de> 03/29/05 11:43PM >>>
    >> Cuichang Zhao wrote:
    >> 
    >> > Hello, 
    >> > Could you please tell me how i can get an input from the user in R?
    >> 
    >> Depends on the kind of input.
    >> 
    >> See, e.g., ?scan or ?menu
    >> 
    >> Uwe Ligges
    >> 
    >> 
    >> > C-Ming 
    >> >  
    >> > Mar 29, 2005
    >> > 
    >> > 		
    >> > ---------------------------------
    >> > 
    >> > 
    >> > 	[[alternative HTML version deleted]]
    >> > 
    >> > ______________________________________________
    >> > R-help at stat.math.ethz.ch mailing list
    >> > https://stat.ethz.ch/mailman/listinfo/r-help 
    >> > PLEASE do read the posting guide!
    >> http://www.R-project.org/posting-guide.html 
    >> 
    >> ______________________________________________
    >> R-help at stat.math.ethz.ch mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-help 
    >> PLEASE do read the posting guide!
    >> http://www.R-project.org/posting-guide.html
    >> 
    >> ______________________________________________
    >> R-help at stat.math.ethz.ch mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide! 
    >> http://www.R-project.org/posting-guide.html
    >> 

    BertG> ______________________________________________
    BertG> R-help at stat.math.ethz.ch mailing list
    BertG> https://stat.ethz.ch/mailman/listinfo/r-help
    BertG> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ahenningsen at agric-econ.uni-kiel.de  Thu Mar 31 09:50:13 2005
From: ahenningsen at agric-econ.uni-kiel.de (Arne Henningsen)
Date: Thu, 31 Mar 2005 09:50:13 +0200
Subject: [R] Problems with lpSolve/Memory ? R crashes
In-Reply-To: <83536658864BC243BE3C06D7E936ABD5027BA9A0@xchg1.statistik.local>
References: <83536658864BC243BE3C06D7E936ABD5027BA9A0@xchg1.statistik.local>
Message-ID: <200503310950.13410.ahenningsen@agric-econ.uni-kiel.de>

Unfortunately, I can't tell you how to solve this problem. However, I can 
confirm that this crash happens also on my machines (R 2.0.1 on Debian Sarge, 
AMD Athlon, 750 MHz, 256 MB RAM and R 2.0.0 on SuSE 9.0, Intel P4, 2.6 GHz, 
512 MB RAM):
R> aaa(1000)
alloc of 80000 bytes failed
alloc of 40000 bytes failed
Speicherzugriffsfehler

We had a model, which consists of 1000+ linear programs with each about 550 
rows and 1100 columns (http://www.unipr.it/arpa/dipseq/EAAE/PR/Parallel/ 
42b4_henningsen.pdf). On MS-Windows 2000/XP this model always crashed after 
some hundreds linear programs, but using Linux on the same machines it 
_never_ crashed. I really can't see the reason why our much larger programs 
worked, but these small programs let R crash. 
I hope that this information may help to solve this problem.

Arne

On Wednesday 30 March 2005 12:16, TEMPL Matthias wrote:
> Hello!
>
> I have a curious problem, which I cannot solve.
> With my code I solve thousands of small linear programs with the package
> lpSolve automatically. But R crashes sometimes (~always, but always on
> different linear programs) in a strange way. For illustration, I tried to
> prepare a simple example, which shows the nature of the problem. The
> function aaa (see below) declares some constants (only in this special
> example) and in the end it solves the linear program.
>
> aaa(1)
>       [,1] [,2]
>  [1,]    0    0
>  [2,]    0    0
>  [3,]    0    0
>  [4,]    0    0
>  [5,]   52    0
>  [6,]    2    2
>  [7,]    0    0
>  [8,]    2    0
>  [9,]    0    0
> [10,]    0    0
> [11,]    0    0
> [12,]    0    0
> [13,]   54    0
>
> Works fine.
> Now I make the *same* calculation, say 1000 times:
> aaa(1000)
> R (I have tried it with R2.0.1, 2.0.0, 1.9.1, 2.1.0dev) crashes completly -
> without warning and error message under Windows XP, Intel Pentium 3 with
> 256 MB RAM Under Linux SuSe 8.2 R (2.0.1) it crashes again, but in this
> case I get the following message: Calloc of 40004 bytes failed on line 114
> of file lpkit.c
> ...
> Calloc of 80008 bytes failed on line 113 of file lpkit.c
> Error: cannot allocate vector of size 3 Kb
>
> Now I?m completly lost. Solving the linear program one time makes no
> problem. Solving it twice in the same way makes no problem either. Running
> the same calculation, say 1000 times, causes a crash. Why should there be a
> problem with memory?
>
> For any hint, I would be really happy.
> Thank you,
> Matthias
>
>
> ### ---------- function aaa ------------
>
> aaa <- function(amount=1){
> f.obj <- rep(0,33)
>
> w <- c(3,4,5,6,11,13,17,22,25,26,27,28,33)
>
> m <-
> matrix(c(0,0,1,1,1,1,0,0,0,0,-1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
>,
>
>              
> 0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,-1,0,0,0,0,0,0,0,0,0,0,0,
>
>              
> 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1,-1,-1,-1,0,0,0,0,1,
>
>              
> 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
>
>              
> 0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
>
>              
> 0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,0,0,
>
>              
> 0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,0,
>
>              
> 0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,
>
>              
> 0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,
>
>              
> 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
>
>              
> 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
>
>              
> 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
>
>              
> 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
>
>              
> 0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,0,0,0,0,1
>
>               ),ncol=33,byrow=TRUE)
>
> f.dir <- c("=","=","=","=","=","=","=","=","=","=","=",
> "=","=","=","=","=","=","=","=","=","=","=","=",
> "=","=","=","=","=","=","=","=","=","=")
>
> f.rhs <- c(-52,0,54,0,2,0,0,0,0,0,0,0,0,0)
>
> lp.out <- matrix( ncol = 2, nrow = 13 )
>
> for(ii in 1:amount){ # - simple iterate the same
>
> for( i in 1:13 ){
>
> 	f.obj[ w[i] ] <- 1
>
> 	lp.out[ i, 1 ] <- lp("min", f.obj, m, f.dir, f.rhs)$objval
>
> 	lp.out[ i, 2 ] <- lp("max", f.obj, m, f.dir, f.rhs)$objval
>
> 	f.obj <- rep( 0, 33 )
>
> }
>
> }
> lp.out
>
> }
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From tura at centroin.com.br  Thu Mar 31 11:21:10 2005
From: tura at centroin.com.br (Bernardo Rangel Tura)
Date: Thu, 31 Mar 2005 06:21:10 -0300
Subject: [R] help im lme()
Message-ID: <6.1.2.0.2.20050331061356.03651770@centroin.com.br>

Hi R people!

I have a doubt in lme().
I use this model:

m2.lme<-lme(log(cmort)~idade+ano,random=~idade|ano,data=dados)

If i use summary I recive this output:

 > summary(m2.lme)
Linear mixed-effects model fit by REML
  Data: dados
        AIC      BIC    logLik
   1139.313 1170.554 -562.6563

Random effects:
  Formula: ~idade | ano
  Structure: General positive-definite, Log-Cholesky parametrization
             StdDev       Corr
(Intercept) 3.131076e-03 (Intr)
idade       3.515018e-05 -0.042
Residual    5.687940e-01

...etc...

I know the value of Residula random effects is m2.lme$sigma but how do I 
find the value of idade or intercept random effects


Thanks in advance

Bernardo Rangel Tura, MD, MSc
National Institute of Cardiology Laranjeiras
Rio de Janeiro Brazil 


-- 
No virus found in this outgoing message.
Checked by AVG Anti-Virus.



From ripley at stats.ox.ac.uk  Thu Mar 31 11:47:46 2005
From: ripley at stats.ox.ac.uk (Brian D Ripley)
Date: Thu, 31 Mar 2005 10:47:46 +0100 (BST)
Subject: [R] how i can get input from "user input"
In-Reply-To: <16971.41987.799142.525026@stat.math.ethz.ch>
Message-ID: <Pine.GSO.4.31.0503310910550.2237-100000@markov.stats>

On Thu, 31 Mar 2005, Martin Maechler wrote:

> >>>>> "BertG" == Berton Gunter <gunter.berton at gene.com>
> >>>>>     on Wed, 30 Mar 2005 10:09:38 -0800 writes:
>
>     BertG> If you are on Windows and want to go GUI, see
>     BertG> ?choose.files, ?winMenuAdd, ?winDialog, ?select.list
>
> with the big drawback that it will only work on Windows.

I don't think that a `big' drawback if you `want to go GUI', as GUI
conventions are so different between platforms (and tcltk being different
from the `native' one on each platform).  But we are beginning to attempt
to add platform-independent wrappers to GUI widgets.

> As Uwe says below, it depends on your context;
> for relative simple things, however please consider a portable
> solution, using
> 	  	  menu(), readline(), ..
>
> BTW, menu() has been improved in R 2.1.0 (alpha --> please test!),
> and is now connected with select.list() which should work on all
> platforms (and uses tcltk on Linux when available).

To be a bit more specific,

menu() has a 'graphics' argument that uses a listbox on Windows, MacOS or
tcltk (where available).

select.list() works on all platforms, graphically as for
menu(graphics=TRUE), otherwise in text mode.

I intend to add a tcltk-based version of choose.files().  (One of the
problems with tcltk is that its widgets are OS-specific, and getting
select.list to choose a reasonable height tooks ages: there needs to a
fudge factor of 3 pixels/line on Unix and 1 pixel/line on Windows.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dimitris.rizopoulos at med.kuleuven.ac.be  Thu Mar 31 12:13:11 2005
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Thu, 31 Mar 2005 12:13:11 +0200
Subject: [R] help im lme()
References: <6.1.2.0.2.20050331061356.03651770@centroin.com.br>
Message-ID: <004001c535da$3e65d190$0540210a@www.domain>

you can get the estimated covariance matrix of the random-effects 
using:

library(nlme)
m <- lme(Orthodont)

# scaled by the residuals variance
pdMatrix(m$modelStruct$reStruct)

# raw
lapply(pdMatrix(m$modelStruct$reStruct), "*", m$sigma^2)


However, it seems that in your model you use as a fixed-effect your 
grouping factor "ano", which is not in the spirit of mixed-models.


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Bernardo Rangel Tura" <tura at centroin.com.br>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, March 31, 2005 11:21 AM
Subject: [R] help im lme()


> Hi R people!
>
> I have a doubt in lme().
> I use this model:
>
> m2.lme<-lme(log(cmort)~idade+ano,random=~idade|ano,data=dados)
>
> If i use summary I recive this output:
>
> > summary(m2.lme)
> Linear mixed-effects model fit by REML
>  Data: dados
>        AIC      BIC    logLik
>   1139.313 1170.554 -562.6563
>
> Random effects:
>  Formula: ~idade | ano
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev       Corr
> (Intercept) 3.131076e-03 (Intr)
> idade       3.515018e-05 -0.042
> Residual    5.687940e-01
>
> ...etc...
>
> I know the value of Residula random effects is m2.lme$sigma but how 
> do I find the value of idade or intercept random effects
>
>
> Thanks in advance
>
> Bernardo Rangel Tura, MD, MSc
> National Institute of Cardiology Laranjeiras
> Rio de Janeiro Brazil
>
> -- 
> No virus found in this outgoing message.
> Checked by AVG Anti-Virus.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From j.van_den_hoff at fz-rossendorf.de  Thu Mar 31 12:31:49 2005
From: j.van_den_hoff at fz-rossendorf.de (joerg van den hoff)
Date: Thu, 31 Mar 2005 12:31:49 +0200
Subject: [R] y-label on right hand side of plot
In-Reply-To: <20050330125636.1dcda7f7.butchar.2@osu.edu>
References: <20050330183637.481b3c46.0034058@fudan.edu.cn>	<20050330073413.25a2b5f0.butchar.2@osu.edu>	<20050330220204.3d873889.0034058@fudan.edu.cn>
	<20050330125636.1dcda7f7.butchar.2@osu.edu>
Message-ID: <424BD195.8020800@fz-rossendorf.de>

Is there a better way than:


par(mar=c(6,6,6,6))
plot(1:10,yaxt="n",ylab="")
axis(4)
text(12,5.5,'y-label',xpd=T,srt=90)


to get the y-ticks _and_ the y-label to the rhs of the plot? I did not 
find anything in the  'par', 'plot', 'axis' and 'title' manpages to 
solve the problem. (the above is ugly, because one needs to hardcode the 
   text position or needs to calculate it 'manually' from par('usr'). it 
would be much nicer, if there were a flag to 'title' controlling were 
the labels occur).

thanks
joerg



From coforfe at gmail.com  Thu Mar 31 12:50:22 2005
From: coforfe at gmail.com (Carlos Ortega)
Date: Thu, 31 Mar 2005 12:50:22 +0200
Subject: [R] y-label on right hand side of plot
In-Reply-To: <424BD195.8020800@fz-rossendorf.de>
References: <20050330183637.481b3c46.0034058@fudan.edu.cn>
	<20050330073413.25a2b5f0.butchar.2@osu.edu>
	<20050330220204.3d873889.0034058@fudan.edu.cn>
	<20050330125636.1dcda7f7.butchar.2@osu.edu>
	<424BD195.8020800@fz-rossendorf.de>
Message-ID: <7b18cd4d0503310250c1306cd@mail.gmail.com>

Hello,

Please check if this is acceptable for you..

par(mar=c(6,6,6,6))
plot(1:10,yaxt="n",ylab="")
axis(4)
mtext('y-label',4,line=2)

Regards,
Carlos.

On Thu, 31 Mar 2005 12:31:49 +0200, joerg van den hoff
<j.van_den_hoff at fz-rossendorf.de> wrote:
> Is there a better way than:
> 
> par(mar=c(6,6,6,6))
> plot(1:10,yaxt="n",ylab="")
> axis(4)
> text(12,5.5,'y-label',xpd=T,srt=90)
> 
> to get the y-ticks _and_ the y-label to the rhs of the plot? I did not
> find anything in the  'par', 'plot', 'axis' and 'title' manpages to
> solve the problem. (the above is ugly, because one needs to hardcode the
>    text position or needs to calculate it 'manually' from par('usr'). it
> would be much nicer, if there were a flag to 'title' controlling were
> the labels occur).
> 
> thanks
> joerg
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From jakob.petersen at qmul.ac.uk  Thu Mar 31 12:57:33 2005
From: jakob.petersen at qmul.ac.uk (Jakob Petersen)
Date: Thu, 31 Mar 2005 11:57:33 +0100
Subject: [R] Weighted median for matrices
Message-ID: <424BD79D.304@qmul.ac.uk>



I am working with a matrix (x),

where rows are non-overlapping geographical areas (postcodes; here 
denoted with letter row names),

and columns are income bands with a central value (e.g. ?7.5k, here 
denoted x1,x2, etc.).

The data are counts (how many households with 0-5k pa, 5-10k pa?, etc.)

 

I would like to summarise this data set.

First row-wise as suggested by Henrik Bengtsson 
(www.maths.lth.se/help/R/R.classes/ 
<http://www.maths.lth.se/help/R/R.classes/>  ), example:

 

library (R.basic)

x<-cbind(x1=3,x2=c(4:1,2:5))

dimnames(x)[[1]]<-letters[1:8]

w<-c(1,2)

wm <- apply(x, MARGIN=1, FUN=weighted.median, w=w, na.rm=TRUE)

wm

 

QUESTION
Secondly, I would like to aggregate rows (postcodes) into bigger units 
according additional factor vectors (higher administrative order or 
environmental attributes).

I would be grateful for ideas to how I can achieve this in our R.

 

Jakob

 

Software:

R ver 2.01 (Windows)

R.basic ver 0.59

 

Jakob Petersen

GISc student (MSc)

Birkbeck, University of London



From alexbri at netcabo.pt  Thu Mar 31 13:44:51 2005
From: alexbri at netcabo.pt (alexbri)
Date: Thu, 31 Mar 2005 12:44:51 +0100
Subject: [R] multinom function
Message-ID: <EA91707AE6F4C84495513EFF5117E897062217A5@VS2.hdi.tvcabo>

Dear all:

 

I am trying to fit a multinomial log linear model to the following data:

 

worms<- data.frame(year= rep(2000:2004, c(3,3,3,3,3)),age=rep(1:3,5), mud=c(2,5,0,8,7,7,5,9,14,12,8,7,5,13,11),sand=c(4,7,13,4,14,13,20,17,15,23,20,9,35,27,18), rocks=c(2,6,7,9,3,2,2,10,5,19,13,17,11,20,29))

 

mud, sand and rocks are the 3 factors while age and year are predictors.

Can I fit a model with the multinom function (nnet library) to the data in this form?

 

k<- as.matrix(worms[,3:5])

m1<- multinom(k~year+age,data=worms)

 

Is this correct, or is there another way?

 

Thanks for your help, best wishes

 

Alex



From wvbaarle at wxs.nl  Thu Mar 31 14:33:39 2005
From: wvbaarle at wxs.nl (wim van baarle)
Date: Thu, 31 Mar 2005 14:33:39 +0200
Subject: [R] question
Message-ID: <000601c535ed$de1c3900$9600000a@wim>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050331/2c609a11/attachment.pl

From ramasamy at cancer.org.uk  Thu Mar 31 14:36:25 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 31 Mar 2005 13:36:25 +0100
Subject: [R] matching vectors against vectors
In-Reply-To: <3f177c8625945c63c175b049737a24d8@gmail.com>
References: <3f177c8625945c63c175b049737a24d8@gmail.com>
Message-ID: <1112272585.6172.13.camel@ndmpc126.orc.ox.ac.uk>

You can use merge but to do so you will need to define the common key
first. This can be a rowname in the case of a matrix or names in the
case of a vector.

v1 <- 1:10
names(v1) <- LETTERS[1:10]

v2 <- 101:105
names(v2) <- sample( LETTERS[1:10], 5 )

> merge( v1, v2, by=0, all=TRUE )
   Row.names  x   y
1          A  1  NA
2          B  2 102
3          C  3 104
4          D  4 103
5          E  5 105
6          F  6  NA
7          G  7  NA
8          H  8 101
9          I  9  NA
10         J 10  NA


Regards, Adai



On Tue, 2005-03-29 at 22:47 +0200, Piet van Remortel wrote:
> Hi all.
> 
> I have a re-occuring typical problem that I don't know how to solve 
> efficiently.
> 
> The situation is the following:   I have a number of data-sets 
> (A,B,C,...) , consisting of an identifier (e.g. 11,12,13,...,20) and a 
> measurement (e.g. in the range 100-120).   I want to compile a large 
> table, with all availabe identifiers in all data-sets in the rows, and 
> a column for every dataset.
> 
> Now, not all datasets have a measurement for every identifier, so I 
> want NA if the set does not contain the identifier.
> 
> an example for a single dataset:
> 
> #all identifiers
>  > rep <- c(10:20)
> 
> #Identifiers in my dataset (a subset of rep)
>  > rep1 <- c(12,13,15,16,17,18)
> 
> #measurements in this dataset
>  > rep1.r <- c(112,113,115,116,117,118)
> 
> #a vector which should become a column in the final table, now 
> containing all NAs
>  > res <- rep(NA,10)
> 
> #the IDs and values of my dataset together
>  > data <- cbind(rep1, rep1.r)
> 
> data looks like this:
>       rep1 rep1.r
> [1,]   12    112
> [2,]   13    113
> [3,]   15    115
> [4,]   16    116
> [5,]   17    117
> [6,]   18    118
> 
> Now, I want to put the values 112, 113, 115,... in the correct rows of 
> the final table, using the identifiers as an indicator of which row to 
> put it in, so that I finally obtain:
> 
> rep     res
> 10    NA
> 11    NA
> 12    112
> 13    113
> 14    NA
> 15    115
> 16    116
> 17    117
> 18    118
> 19    NA
> 20    NA
> 
> I try to avoid repeating 'which' a lot and filling in every 
> identifier's observation etc, since I will be doing this for thousands 
> of rows at once.    There must be an efficient way using factors, 
> tapply etc, but I have trouble finding it.  Ideal would be if this 
> could be done in one go, instead of looping.
> 
> Any suggestions ?
> 
> Thanks,
> 
> Piet
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From bates at stat.wisc.edu  Thu Mar 31 14:54:26 2005
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 31 Mar 2005 06:54:26 -0600
Subject: [R] Repeated Measures, groupedData and lme
In-Reply-To: <13DEE40AE4BF764586DBF27022F0D6A7A962D6@nwe2knas1.igernet.bbsrc.reserved>
References: <13DEE40AE4BF764586DBF27022F0D6A7A962D6@nwe2knas1.igernet.bbsrc.reserved>
Message-ID: <424BF302.6050301@stat.wisc.edu>

emma pilgrim (IGER-NW) wrote:
> Hello
> 
> I am trying to fit a REML to some soil mineral data which has been
> collected over the time period 1999 - 2004. I want to know if the 19
> different treatments imposed, differ in terms of their soil mineral
> content. A tree model of the data has shown differences between the
> treatments can be attributed to the Magnesium, Potassium and organic
> matter content of the soil, with Magnesium being the primary separating
> variable.
> 
> I am looking at soil mineral data were collected : 99, 02, 04. 
> 
> In the experiment, there are 19 different treatments (treatmentcontrol,
> treatment6TFYM, treatment 12TFYM etc),  which are replicated in 3
> blocks.
> 
> For the magnesium soil data, I have created the following groupedData
> object: 
> 
> magnesium<-groupedData(Mg~year|treatment, inner=~block) 
> Where mg=magnesium Kg/ha

Are you sure you want treatment to be the grouping factor?

> As it is a repeated measures I was going to use an lme.  I have looked
> at Pinherio and Bates : Mixed-Effects models in S and S-plus and I am
> getting slightly confused.  In order to fit the lme, should I specify
> the data to use in the model as the grouped structure model?
> 
> If so is the following command correct:
> 
> Model1<-lme(mg~treatment, random=block|year, data=magnesium)? 
> 
> I am slightly worried that it isn't, because in model summary, instead
> of listing the 19 different treatments in the fixed effects section, it
> writes intercept (as normal), then treatment^1, treatment^2 etc.

This is an unfortunate side-effect of creating a groupedData object - to 
create plots with panels in a natural order the grouping factor is 
changed to an ordered factor.  In your case the treatment factor will 
become an ordered factor and the default contrasts for an ordered factor 
are the polynomial contrasts.

There are two ways to get around this - don't create a groupedData 
object or change the default contrasts using

options(contrasts = c(unordered = "contr.treatment", ordered = 
"contr.treatment")


> However if I don't specify the groupedData object in the model, then in
> the fixed effects section, it names the treatments (i.e. intercept,
> treatmentcontrol, treatment6TFYM.

Yes.

> Should I be fitting the model using the whole data set rather than the
> groupedData object?

Probably that is the best course.



From f.harrell at vanderbilt.edu  Thu Mar 31 15:02:24 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Thu, 31 Mar 2005 08:02:24 -0500
Subject: [R] question
In-Reply-To: <000601c535ed$de1c3900$9600000a@wim>
References: <000601c535ed$de1c3900$9600000a@wim>
Message-ID: <424BF4E0.9070000@vanderbilt.edu>

wim van baarle wrote:
> Sir,
> I found your description of the dataset about nodal involvement in prostate cancer. It comes from the book biostatistics casebook. I like to use the dataset for doing logistics regression. Can you tell me where I can find the dataset.
> 
> Thanks and greetings
> 
> Wim van Baarle
> wvbaarle at wxs.nl
You didn't say which prostate cancer study that represented.  One famous 
one has data in R form on our web site http://biostat.mc.vanderbilt.edu.

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From 0034058 at fudan.edu.cn  Thu Mar 31 15:02:34 2005
From: 0034058 at fudan.edu.cn (ronggui)
Date: Thu, 31 Mar 2005 21:02:34 +0800
Subject: [R] multinom function
In-Reply-To: <EA91707AE6F4C84495513EFF5117E897062217A5@VS2.hdi.tvcabo>
References: <EA91707AE6F4C84495513EFF5117E897062217A5@VS2.hdi.tvcabo>
Message-ID: <20050331210234.059b9724.0034058@fudan.edu.cn>

i think it is right!
i rearrage your data in the following form and carry multinom angain,it get the same result as yours.

> multinom(k~year+age,data=worms)
....
Call:
multinom(formula = k ~ year + age, data = worms)

Coefficients:
      (Intercept)       year         age
sand    -106.3405 0.05368317 -0.20612839
rocks   -438.4518 0.21899290  0.09911392

Residual Deviance: 1054.121
AIC: 1066.121

> multinom(factor(x4)~X1+X2,weight=X3,data=newdata)
Call:
multinom(formula = factor(x4) ~ X1 + X2, data = newdata, weights = X3)

Coefficients:
  (Intercept)         X1          X2
2   -106.3407 0.05368328 -0.20612838
3   -438.4522 0.21899311  0.09911394

Residual Deviance: 1054.121
AIC: 1066.121


> newdata
      X1 X2 X3 x4
1   2000  1  2  1
2   2000  2  5  1
3   2000  3  0  1
4   2001  1  8  1
5   2001  2  7  1
6   2001  3  7  1
7   2002  1  5  1
8   2002  2  9  1
9   2002  3 14  1
10  2003  1 12  1
11  2003  2  8  1
12  2003  3  7  1
13  2004  1  5  1
14  2004  2 13  1
15  2004  3 11  1
16  2000  1  4  2
21  2000  2  7  2
31  2000  3 13  2
41  2001  1  4  2
51  2001  2 14  2
61  2001  3 13  2
71  2002  1 20  2
81  2002  2 17  2
91  2002  3 15  2
101 2003  1 23  2
111 2003  2 20  2
121 2003  3  9  2
131 2004  1 35  2
141 2004  2 27  2
151 2004  3 18  2
17  2000  1  2  3
22  2000  2  6  3
32  2000  3  7  3
42  2001  1  9  3
52  2001  2  3  3
62  2001  3  2  3
72  2002  1  2  3
82  2002  2 10  3
92  2002  3  5  3
102 2003  1 19  3
112 2003  2 13  3
122 2003  3 17  3
132 2004  1 11  3
142 2004  2 20  3
152 2004  3 29  3



On Thu, 31 Mar 2005 12:44:51 +0100
alexbri <alexbri at netcabo.pt> wrote:

> Dear all:
> 
>  
> 
> I am trying to fit a multinomial log linear model to the following data:
> 
>  
> 
> worms<- data.frame(year= rep(2000:2004, c(3,3,3,3,3)),age=rep(1:3,5), mud=c(2,5,0,8,7,7,5,9,14,12,8,7,5,13,11),sand=c(4,7,13,4,14,13,20,17,15,23,20,9,35,27,18), rocks=c(2,6,7,9,3,2,2,10,5,19,13,17,11,20,29))
> 
>  
> 
> mud, sand and rocks are the 3 factors while age and year are predictors.
> 
> Can I fit a model with the multinom function (nnet library) to the data in this form?
> 
>  
> 
> k<- as.matrix(worms[,3:5])
> 
> m1<- multinom(k~year+age,data=worms)
> 
>  
> 
> Is this correct, or is there another way?
> 
>  
> 
> Thanks for your help, best wishes
> 
>  
> 
> Alex
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From br44114 at yahoo.com  Thu Mar 31 17:17:23 2005
From: br44114 at yahoo.com (bogdan romocea)
Date: Thu, 31 Mar 2005 07:17:23 -0800 (PST)
Subject: [R] how to simulate a time series
Message-ID: <20050331151723.44887.qmail@web50106.mail.yahoo.com>

Dear useRs,

I want to simulate a time series (stationary; the distribution of
values is skewed to the right; quite a few ARMA absolute standardized
residuals above 2 - about 8% of them). Is this the right way to do it?
#--------------------------------
load("rdtb")	#the time series
> summary(rdtb)
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-1.11800 -0.65010 -0.09091  0.30390  1.12500  2.67600 

farma <- arima(rdtb,order=c(1,0,1),include.mean=T)
> farma[["coef"]]
       ar1        ma1  intercept 
0.58091575 0.02313803 0.30417062 

sim <- list(NULL)	#simulated
for (i in 1:5) {
	sim[[i]] <- as.vector(arima.sim(list(ar=c(farma[["coef"]][1]),
		ma=c(farma[["coef"]][2])),n=length(rdtb),innov=rdtb))
	}
allsim <- as.data.frame(sim)
colnames(allsim) <- paste("sim",1:5,sep="")
all <- cbind(rdtb,allsim)
#--------------------------------

I don't understand why the simulation runs generate virtually identical
values:
> all[100:105,]
          rdtb     sim1     sim2     sim3     sim4     sim5
100  2.3863636 1.065661 1.065661 1.065661 1.065661 1.065661
101  1.9318182 2.606093 2.606093 2.606093 2.606093 2.606093
102  2.2954545 3.854074 3.854074 3.854074 3.854074 3.854074
103  2.5882353 4.880240 4.880240 4.880240 4.880240 4.880240
104  2.0227273 4.917622 4.917622 4.917622 4.917622 4.917622
105 -0.1521739 2.751352 2.751352 2.751352 2.751352 2.751352

It appears I may be missing something (very) basic, but don't know
what.

Thank you,
b.



From ullrichj at staff.uni-marburg.de  Thu Mar 31 17:50:16 2005
From: ullrichj at staff.uni-marburg.de (Johannes Ullrich)
Date: Thu, 31 Mar 2005 17:50:16 +0200
Subject: [R] Surface plot for polynomial regression
Message-ID: <ALEAKNLMNGHJKGBKFHNJOENLCAAA.ullrichj@staff.uni-marburg.de>

Dear R-experts,

my goal is to visualize the following polynomial regression as a 3D-surface:

Z = b0 + b1*X + b2*Y + b3*XY + b4*X^2 + b5*Y^2

I believe that a solution to this problem may be of interest to a wider
range of scientists because the problem is a derivative of a more general
problem, i.e.: how to describe the relationship between one dependent
variable and the DIFFERENCE between two other variables. There are numerous
problems associated with difference scores (e.g., reliability). One
suggested alternative consists of using the components of the difference
score separately in polynomial regression. So this is how I ended up with
the above regression, which is essentially a reformulation of b1*(X-Y)^2.

After consulting the help pages and archives my best guess was that the
function scatter3d could be rewritten in part to produce the desired output.
In fact, the quadratic fit output of the scatter3d function comes closest to
what I have in mind. However, I think the XY term is missing from the
quadratic fit equation. When I use wireframe to visualize the raw data,
there is a peak of the dependent variable when both X AND Y are high. Yet
this peak does not appear in the quadratic fit of scatter3d.

Any pointers would be welcome. I should add that I am not a programmer and
mainly work with high-level functions.

Thank you very much for R and for your help

Johannes

           Dipl.-Psych. Johannes Ullrich
            Philipps-Universit?t Marburg
                                 Germany



From rolf at math.unb.ca  Thu Mar 31 17:43:18 2005
From: rolf at math.unb.ca (Rolf Turner)
Date: Thu, 31 Mar 2005 11:43:18 -0400 (AST)
Subject: [R] how to simulate a time series
Message-ID: <200503311543.j2VFhIrN027795@erdos.math.unb.ca>

Bogdan Romocea wrote:

> I want to simulate a time series (stationary; ... <snip> ...
> values is skewed to the right; quite a few ARMA absolute standardized

	<snip>
> 
> sim <- list(NULL)	#simulated
> for (i in 1:5) {
> 	sim[[i]] <- as.vector(arima.sim(list(ar=c(farma[["coef"]][1]),
> 		ma=c(farma[["coef"]][2])),n=length(rdtb),innov=rdtb))
> 	}
> 
> I don't understand why the simulation runs generate virtually
> identical values:

	<snip>

	They are identical because you are using the same
	innovations i.e. rdtb, over and over!!!

	If you want different results, you have to use
	different innovations.

	BTW it would seem to make more sense to use the
	***residuals*** from your fit to rdtb, rather than rdtb
	itself, as your innovations.  (But then you would
	be essentially reconstructing rdtb.)

	You probably want to ***fit*** some distribution to the
	residuals from rdtb, and then sample from that distribution
	to get your innovations.

			cheers,

				Rolf Turner
				rolf at math.unb.ca



From adrian at atstatconsulting.com  Thu Mar 31 17:46:49 2005
From: adrian at atstatconsulting.com (Adrian Katschke)
Date: Thu, 31 Mar 2005 07:46:49 -0800 (PST)
Subject: [R] loadings or summary in Principal components
Message-ID: <20050331154649.87788.qmail@web201.biz.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050331/33e83428/attachment.pl

From ripley at stats.ox.ac.uk  Thu Mar 31 17:51:01 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 31 Mar 2005 16:51:01 +0100 (BST)
Subject: [R] how to simulate a time series
In-Reply-To: <20050331151723.44887.qmail@web50106.mail.yahoo.com>
References: <20050331151723.44887.qmail@web50106.mail.yahoo.com>
Message-ID: <Pine.LNX.4.61.0503311643080.16823@gannet.stats>

On Thu, 31 Mar 2005, bogdan romocea wrote:

> Dear useRs,
>
> I want to simulate a time series (stationary; the distribution of
> values is skewed to the right; quite a few ARMA absolute standardized
> residuals above 2 - about 8% of them). Is this the right way to do it?
> #--------------------------------
> load("rdtb")	#the time series
>> summary(rdtb)
>    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
> -1.11800 -0.65010 -0.09091  0.30390  1.12500  2.67600
>
> farma <- arima(rdtb,order=c(1,0,1),include.mean=T)
>> farma[["coef"]]
>       ar1        ma1  intercept
> 0.58091575 0.02313803 0.30417062
>
> sim <- list(NULL)	#simulated
> for (i in 1:5) {
> 	sim[[i]] <- as.vector(arima.sim(list(ar=c(farma[["coef"]][1]),
> 		ma=c(farma[["coef"]][2])),n=length(rdtb),innov=rdtb))
> 	}
> allsim <- as.data.frame(sim)
> colnames(allsim) <- paste("sim",1:5,sep="")
> all <- cbind(rdtb,allsim)
> #--------------------------------
>
> I don't understand why the simulation runs generate virtually identical
> values:
>> all[100:105,]
>          rdtb     sim1     sim2     sim3     sim4     sim5
> 100  2.3863636 1.065661 1.065661 1.065661 1.065661 1.065661
> 101  1.9318182 2.606093 2.606093 2.606093 2.606093 2.606093
> 102  2.2954545 3.854074 3.854074 3.854074 3.854074 3.854074
> 103  2.5882353 4.880240 4.880240 4.880240 4.880240 4.880240
> 104  2.0227273 4.917622 4.917622 4.917622 4.917622 4.917622
> 105 -0.1521739 2.751352 2.751352 2.751352 2.751352 2.751352
>
> It appears I may be missing something (very) basic, but don't know
> what.

The meaning of `innovations'.  The innovations determine the series, so 
you asked for the same series five times.  In the reference, the 
innovations are e[t].

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Mar 31 17:58:26 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 31 Mar 2005 16:58:26 +0100 (BST)
Subject: [R] Surface plot for polynomial regression
In-Reply-To: <ALEAKNLMNGHJKGBKFHNJOENLCAAA.ullrichj@staff.uni-marburg.de>
References: <ALEAKNLMNGHJKGBKFHNJOENLCAAA.ullrichj@staff.uni-marburg.de>
Message-ID: <Pine.LNX.4.61.0503311653530.16823@gannet.stats>

Please note there is no `scatter3d' function in R.
There is one in John Fox's package Rcmdr: please give credit where it is 
due.

However, I think you have overlooked functions like persp, image, contour, 
cloud wireframe and levelplot (lattice), all of which can plot any 
function of two variables and whose examples (and some of the demos) show 
you how.  You might also want to look at rgl.surface (package rgl).

On Thu, 31 Mar 2005, Johannes Ullrich wrote:

> Dear R-experts,
>
> my goal is to visualize the following polynomial regression as a 3D-surface:

It is a 2D surface, by any reasonable definition of `dimension'.

> Z = b0 + b1*X + b2*Y + b3*XY + b4*X^2 + b5*Y^2
>
> I believe that a solution to this problem may be of interest to a wider
> range of scientists because the problem is a derivative of a more general
> problem, i.e.: how to describe the relationship between one dependent
> variable and the DIFFERENCE between two other variables. There are numerous
> problems associated with difference scores (e.g., reliability). One
> suggested alternative consists of using the components of the difference
> score separately in polynomial regression. So this is how I ended up with
> the above regression, which is essentially a reformulation of b1*(X-Y)^2.
>
> After consulting the help pages and archives my best guess was that the
> function scatter3d could be rewritten in part to produce the desired output.
> In fact, the quadratic fit output of the scatter3d function comes closest to
> what I have in mind. However, I think the XY term is missing from the
> quadratic fit equation. When I use wireframe to visualize the raw data,
> there is a peak of the dependent variable when both X AND Y are high. Yet
> this peak does not appear in the quadratic fit of scatter3d.
>
> Any pointers would be welcome. I should add that I am not a programmer and
> mainly work with high-level functions.
>
> Thank you very much for R and for your help
>
> Johannes
>
>           Dipl.-Psych. Johannes Ullrich
>            Philipps-Universit?t Marburg
>                                 Germany
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From jfox at mcmaster.ca  Thu Mar 31 18:31:14 2005
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 31 Mar 2005 11:31:14 -0500
Subject: [R] Surface plot for polynomial regression
In-Reply-To: <Pine.LNX.4.61.0503311653530.16823@gannet.stats>
Message-ID: <20050331163115.WHYO16985.tomts36-srv.bellnexxia.net@JohnDesktop8300>

Dear Johannes and Brian,

scatter3d() in the Rcmdr packages does indeed fit a full quadratic surface
including the product term, which can you verify by setting the argument
model.summary=TRUE in the call to the function. Perhaps the grid over which
scatter3d evaluates the fitted surface is too coarse to resolve all of the
features of the surface in which you're interested; this is currently fixed
at 26*26 but could easily be changed, and really should be an argument to
the function. I'll do that that in the next version.

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Prof 
> Brian Ripley
> Sent: Thursday, March 31, 2005 10:58 AM
> To: Johannes Ullrich
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Surface plot for polynomial regression
> 
> Please note there is no `scatter3d' function in R.
> There is one in John Fox's package Rcmdr: please give credit 
> where it is due.
> 
> However, I think you have overlooked functions like persp, 
> image, contour, cloud wireframe and levelplot (lattice), all 
> of which can plot any function of two variables and whose 
> examples (and some of the demos) show you how.  You might 
> also want to look at rgl.surface (package rgl).
> 
> On Thu, 31 Mar 2005, Johannes Ullrich wrote:
> 
> > Dear R-experts,
> >
> > my goal is to visualize the following polynomial regression 
> as a 3D-surface:
> 
> It is a 2D surface, by any reasonable definition of `dimension'.
> 
> > Z = b0 + b1*X + b2*Y + b3*XY + b4*X^2 + b5*Y^2
> >
> > I believe that a solution to this problem may be of interest to a 
> > wider range of scientists because the problem is a derivative of a 
> > more general problem, i.e.: how to describe the 
> relationship between 
> > one dependent variable and the DIFFERENCE between two other 
> variables. 
> > There are numerous problems associated with difference 
> scores (e.g., 
> > reliability). One suggested alternative consists of using the 
> > components of the difference score separately in polynomial 
> > regression. So this is how I ended up with the above 
> regression, which is essentially a reformulation of b1*(X-Y)^2.
> >
> > After consulting the help pages and archives my best guess was that 
> > the function scatter3d could be rewritten in part to 
> produce the desired output.
> > In fact, the quadratic fit output of the scatter3d function comes 
> > closest to what I have in mind. However, I think the XY term is 
> > missing from the quadratic fit equation. When I use wireframe to 
> > visualize the raw data, there is a peak of the dependent 
> variable when 
> > both X AND Y are high. Yet this peak does not appear in the 
> quadratic fit of scatter3d.
> >
> > Any pointers would be welcome. I should add that I am not a 
> programmer 
> > and mainly work with high-level functions.
> >
> > Thank you very much for R and for your help
> >
> > Johannes
> >
> >           Dipl.-Psych. Johannes Ullrich
> >            Philipps-Universit?t Marburg
> >                                 Germany
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tlumley at u.washington.edu  Thu Mar 31 19:09:54 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 31 Mar 2005 09:09:54 -0800 (PST)
Subject: [R] Cox model qustion in R
In-Reply-To: <001601c5357c$e51f7cb0$0923ce80@chao>
References: <001601c5357c$e51f7cb0$0923ce80@chao>
Message-ID: <Pine.A41.4.61b.0503310908010.270904@homer05.u.washington.edu>

On Wed, 30 Mar 2005, Chao Zhu wrote:
>
> But it only gives me the curve with combined treatment. How do I get a 
> plot with two curves for different treatments. I don't want to do 
> new<-data.frame(treat=c(0,1)) and plot(survfit(fit,newdata=new))
> cause  it gives you predicted curves for two treatments.
>

I think you are going to have to be clearer about what you want.  If you 
want the Kaplan--Meier estimator for each treatment separately then
   plot(survfit(Surv(t)~treat))
will do it. Otherwise I don't know what you're trying to do.

By the way, do you really have no censoring in the time variable?

 	-thomas



From jeff.hamann at forestinformatics.com  Thu Mar 31 19:17:34 2005
From: jeff.hamann at forestinformatics.com (Jeff D. Hamann)
Date: Thu, 31 Mar 2005 09:17:34 -0800 (PST)
Subject: [R] aggregate question...
Message-ID: <1250.128.193.137.164.1112289454.squirrel@www.forestinformatics.com>

R-folks,

Is there a function, like aggregate, that allows users to bin values?

I've got to break down a data frame into classes of 5cm (or something like
it), and I only know how to do it using code like,

signif <- symnum( stems$dbh,
                 corr = FALSE,
                 na = FALSE,
                 cutpoints = c(0,10,20,30,40,999),
                 symbols = c(0,10,20,30,40) )


rt <- data.frame( stems$expf,
		  signif = ordered( signif,
                    levels = c(0,10,20,30,40) )

st <- aggregate( rt$stems.expf, by=list(signif), sum )

Is there a one line command to do this?


-- 
Jeff D. Hamann
Forest Informatics, Inc.
PO Box 1421
Corvallis, Oregon 97339-1421
phone 541-754-1428
fax 541-752-0288
jeff.hamann at forestinformatics.com
http://www.forestinformatics.com



From chris.ward at db.com  Thu Mar 31 20:14:20 2005
From: chris.ward at db.com (Chris Ward)
Date: Thu, 31 Mar 2005 10:14:20 -0800
Subject: [R] Unable to start R due to error with tempdir()
Message-ID: <OF7F95D320.F73CDDF0-ON85256FD5.006381FE-88256FD5.00643086@db.com>


Fatal error: cannot find unused tempdir names

I am having the same problem as Michael Epstein (100% of the time)  even after clearing out all the Rtmp* files from the temporary directory. I have tried reinstalling R, to no avail. Is there some profile setting that is trying to create temp directories in an inaccessible place? I had to guess where the tempdir was using a colleague's machine. In his case it seems to be in /documents and settings/userid/local/temp and I cleared out the corresponding directory on my machine.

Christopher B. Ward



--

This e-mail may contain confidential and/or privileged infor...{{dropped}}



From MSchwartz at MedAnalytics.com  Thu Mar 31 20:17:34 2005
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu, 31 Mar 2005 12:17:34 -0600
Subject: [R] aggregate question...
In-Reply-To: <1250.128.193.137.164.1112289454.squirrel@www.forestinformatics.com>
References: <1250.128.193.137.164.1112289454.squirrel@www.forestinformatics.com>
Message-ID: <1112293054.32553.8.camel@horizons.localdomain>

On Thu, 2005-03-31 at 09:17 -0800, Jeff D. Hamann wrote: 
> R-folks,
> 
> Is there a function, like aggregate, that allows users to bin values?
> 
> I've got to break down a data frame into classes of 5cm (or something like
> it), and I only know how to do it using code like,
> 
> signif <- symnum( stems$dbh,
>                  corr = FALSE,
>                  na = FALSE,
>                  cutpoints = c(0,10,20,30,40,999),
>                  symbols = c(0,10,20,30,40) )
> 
> 
> rt <- data.frame( stems$expf,
> 		  signif = ordered( signif,
>                     levels = c(0,10,20,30,40) )
> 
> st <- aggregate( rt$stems.expf, by=list(signif), sum )
> 
> Is there a one line command to do this?

Jeff,

Sometimes the notion of a single line command is in the eye of the
beholder, since things can become easily obfuscated. However, something
like the following could work:

stems <- data.frame(expf = 1:100, 
                    dbh = sample(1:500, 100, replace = TRUE))

st <- aggregate(stems$expf, 
                by=list(cut(stems$dbh, 
                            breaks = c(0, 10, 20, 30, 40, 999))),
                sum)


> st
   Group.1    x
1   (0,10]   69
2  (10,20]  172
3  (20,30]  181
4  (30,40]  131
5 (40,999] 4497


Note that in the use of cut(), there are additional arguments relative
to including or not including the left and/or right hand interval values
in the respective intervals and what the labels should be. See ?cut for
more information.

HTH,

Marc Schwartz



From gunter.berton at gene.com  Thu Mar 31 20:22:04 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Thu, 31 Mar 2005 10:22:04 -0800
Subject: [R] loadings or summary in Principal components
In-Reply-To: <20050331154649.87788.qmail@web201.biz.mail.re2.yahoo.com>
Message-ID: <200503311822.j2VIM49S019350@volta.gene.com>

(R 2.0.1)

summary() gives the correct results.

The print.loadings() print method is just giving the squared length of each
of the eigenvectors, which is 1 by definition, of course. I don't know
whether this is a bug or intentional, but it certainly seems silly. 

In general, it is good practice to use summary() and other supplied
extraction methods for obtaining information about a fitted object rather
than directly accessing the components themselves (however, I, too, often
violate this rule of thumb).

Finally, prcomp() is the preferred way of doing PCA in R, as the princomp
documentation says. The fit object has no "loadings" component and therefore
no problem.


-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Adrian Katschke
> Sent: Thursday, March 31, 2005 7:47 AM
> To: RHelp
> Subject: [R] loadings or summary in Principal components
> 
> May be a simple question, but not understanding why in 
> princomp I get different results for loadings and summary for 
> my eigenvectors and eigenvalues. 
>  
> When I use pc.cr$loadings using the USArrests dataset the 
> proportion of variance is equal for each of the components, 
> but when summary(pc.cr) is used the proportion of variance is 
> showing different proportions. My question is why do they 
> differ? I thought that they would report the same thing?
>  
> Thanks in advance for clearing this confusion for me.
> Adrian Katschke
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From Steve.Rowley at sanofi-aventis.com  Thu Mar 31 20:29:49 2005
From: Steve.Rowley at sanofi-aventis.com (Steve.Rowley@sanofi-aventis.com)
Date: Thu, 31 Mar 2005 13:29:49 -0500
Subject: [R] pictex graphics device and color
Message-ID: <9C1DED999162AD41815C721A7FDD80EB063000@cbdsmxsusr01.pharma.aventis.com>

Is the pictex graphics device known not to support color?

In R 2.0.1 Patched (2004-11-17), it produced very pretty output:

## pictex(file = "modern-metatheonomy.tex", bg = "transparent");
## plotData(data);
## dev.off()

... but it appears to have ignored all color information.
__________
Steve Rowley <steve.rowley at sanofi-aventis.com> Cambridge, MA: (617) 768-4054 ICQ: 52-377-390



From jasonparcon at yahoo.com  Thu Mar 31 20:43:13 2005
From: jasonparcon at yahoo.com (Jason Parcon)
Date: Thu, 31 Mar 2005 10:43:13 -0800 (PST)
Subject: [R] Partial Mantel Test
Message-ID: <20050331184313.44100.qmail@web60305.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050331/890cb024/attachment.pl

From cznm4 at mizzou.edu  Thu Mar 31 21:41:06 2005
From: cznm4 at mizzou.edu (Chao Zhu)
Date: Thu, 31 Mar 2005 13:41:06 -0600
Subject: [R] Cox model qustion in R
References: <001601c5357c$e51f7cb0$0923ce80@chao>
	<Pine.A41.4.61b.0503310908010.270904@homer05.u.washington.edu>
Message-ID: <000801c53629$9496d880$0923ce80@chao>


----- Original Message ----- 
From: "Thomas Lumley" <tlumley at u.washington.edu>
To: "Chao Zhu" <cznm4 at mizzou.edu>
Cc: <r-help at stat.math.ethz.ch>
Sent: Thursday, March 31, 2005 11:09 AM
Subject: Re: [R] Cox model qustion in R


> On Wed, 30 Mar 2005, Chao Zhu wrote:
>>
>> But it only gives me the curve with combined treatment. How do I get a 
>> plot with two curves for different treatments. I don't want to do 
>> new<-data.frame(treat=c(0,1)) and plot(survfit(fit,newdata=new))
>> cause  it gives you predicted curves for two treatments.
>>
> 
> I think you are going to have to be clearer about what you want.  If you 
> want the Kaplan--Meier estimator for each treatment separately then
>   plot(survfit(Surv(t)~treat))
> will do it. Otherwise I don't know what you're trying to do.
> 
> By the way, do you really have no censoring in the time variable?
> 
>  -thomas
> 
>



From demiourgos at gmail.com  Thu Mar 31 22:14:11 2005
From: demiourgos at gmail.com (Alexander Sirotkin)
Date: Thu, 31 Mar 2005 22:14:11 +0200
Subject: [R] question about plot.acf
Message-ID: <c4357ccd050331121438f93d5e@mail.gmail.com>

Hi.

I'm looking for a way to plot autocorrelation, but in a little bit
different way than
plot.acf does. Instead of plotting NxN graphs (assuming N is ht enumber of 
variables) like plot.acf does, I'd like to have one graph of sum of
all autocorrelations
vs. lag. Is there any function that already does this or should a try
to write it
myslef ? 

Thanks a lot.



From p.murrell at auckland.ac.nz  Thu Mar 31 22:58:41 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Fri, 01 Apr 2005 08:58:41 +1200
Subject: [R] pictex graphics device and color
References: <9C1DED999162AD41815C721A7FDD80EB063000@cbdsmxsusr01.pharma.aventis.com>
Message-ID: <424C6481.1040806@stat.auckland.ac.nz>

Hi


Steve.Rowley at sanofi-aventis.com wrote:
> Is the pictex graphics device known not to support color?
> 
> In R 2.0.1 Patched (2004-11-17), it produced very pretty output:
> 
> ## pictex(file = "modern-metatheonomy.tex", bg = "transparent");
> ## plotData(data);
> ## dev.off()
> 
> ... but it appears to have ignored all color information.


Unfortunately, the source code for the pictex driver contains no 
handling of colour.

Not sure how hard it would be to add; 
https://svn.r-project.org/R/trunk/src/library/grDevices/src/devPicTeX.c
is the file to look at if you're interested.

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From ripley at stats.ox.ac.uk  Thu Mar 31 23:08:06 2005
From: ripley at stats.ox.ac.uk (Brian D Ripley)
Date: Thu, 31 Mar 2005 22:08:06 +0100 (BST)
Subject: [R] pictex graphics device and color
In-Reply-To: <9C1DED999162AD41815C721A7FDD80EB063000@cbdsmxsusr01.pharma.aventis.com>
Message-ID: <Pine.GSO.4.31.0503312144020.8373-100000@markov.stats>

On Thu, 31 Mar 2005 Steve.Rowley at sanofi-aventis.com wrote:

> Is the pictex graphics device known not to support color?

Yes, amongst other settings like lwd and metric info for character output.

If you read the code you will see that the arguments fg and bg are
ignored.  In any case, there is no obligation for a graphics device to
support transparency, and in particular pictex() predates its introduction
into R.

As far as I am aware, pictex is a plain TeX package (that also
more-or-less works in LaTeX: it is barely mentioned in the LaTeX Companion
referred to on the help page, nor covered in any detail in the LaTeX
Graphics Companion), and plain TeX per se does not support colour.

> In R 2.0.1 Patched (2004-11-17), it produced very pretty output:
>
> ## pictex(file = "modern-metatheonomy.tex", bg = "transparent");
> ## plotData(data);
> ## dev.off()
>
> ... but it appears to have ignored all color information.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From davidr at rhotrading.com  Thu Mar 31 23:14:26 2005
From: davidr at rhotrading.com (davidr@rhotrading.com)
Date: Thu, 31 Mar 2005 15:14:26 -0600
Subject: [R] Bloomberg data import SOLVED
Message-ID: <12AE52872B5C5348BE5CF47C707FF53A502B1B@rhosvr02.rhotrading.com>

Together with Enrique's running start and Prasad's work, we figured out
how to get tick data and bulk data from Bloomberg into R. Here is a code
snippet which builds on Enrique's.

----------------------------
require("RDCOMClient")

blCon <<- try(blCon <- COMCreate("Bloomberg.Data.1"), silent=TRUE)
# Always check the class of blCon before proceeding!

# First tick data

ticker <- "IBM US Equity"
fields <- c("Last Price","Volume")

comFrom <- new("COMDate",38442.4583333333)
comTo <- new("COMDate",38442.58247696760)
z <- as.integer(0)

histData <- try(blCon$BLPGetHistoricalData(Security=ticker,
Fields=fields, StartDate=comFrom, EndDate=comTo, BarSize=z))

# Notes:
# Passing in just a 0 instead of an int 0 (as z) crashes Rgui
# For tick data, only one ticker is allowed in each call.
# Beware of asking for a long date range; tick data can be very
voluminous.
# I'm sure someone can do some R-magic to fix my start and end datetimes
(please!)

# Bulk data is just like getting prices, except for the return object
being more complex
tickers <- c("TYM5 Comdty", "USM5 Comdty")
fields <- c("FUT_DELIVERABLE_BONDS", "FUT_DLVRBLE_BNDS_CUSIPS")
bulkData <- try(blCon$BlpSubscribe(Security=tickers, Fields=fields))
----------------------------

Note that my original idea about GetHistoricalData was wrong since that
isn't a function. (At least I couldn't get it to work.)

As a last note, it would be very nice if RDCOMClient were directly
available from CRAN so we could use install.packages, etc. (hint, hint!)

Enjoy,
David L. Reiner

p.s. I know cross-posting is discouraged, but I thought some people
might be looking for this information on r-sig-finance someday.



From ramasamy at cancer.org.uk  Thu Mar 31 23:46:29 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 31 Mar 2005 22:46:29 +0100
Subject: [R] hexbin and grid - input data values as coordinates
Message-ID: <1112305589.6131.45.camel@dhcp-63.ccc.ox.ac.uk>

Dear all,

I am trying to use hexbin and read the very interesting article on grid
( http://www.ci.tuwien.ac.at/Conferences/useR-2004/Keynotes/Murrell.pdf ) and am hoping for some advice from more experienced users of hexbin.

I am trying to visualise a data and fit a straight line trough it. For
example, here is how I would do it in the usual way

 # simulate data  
 x <- rnorm(1000)
 y <- 5*x + rnorm(1000, sd=0.5) 

 plot( x, y, pch="*" )
 abline(0, 1, col=2)


And here is my failed attempt at fitting the "abline" on hexbin
 
 library(hexbin); library(grid)
 plot( hexbin( x, y ), style = "nested.lattice") 
 grid.move.to(0.2,0.2)
 grid.line.to(0.8,0.8)

I realise that grid.* is taking plotting coordinates on the graph but
how do I tell it to use the coordinates based on the data values ? For
my real data, I would like lines with different slopes and intercepts.


I am using the hexbin version 1.2-0 ( which is the devel version ),
R-2.0.1 and Fedora Core 3.

Many thanks in advance.

Regards, Adai



From Peter.Ruckdeschel at uni-bayreuth.de  Thu Mar 31 23:45:56 2005
From: Peter.Ruckdeschel at uni-bayreuth.de (Peter Ruckdeschel)
Date: Thu, 31 Mar 2005 23:45:56 +0200
Subject: [R] [R-pkgs] version 1.5 of package "distr" available
Message-ID: <424C6F94.6060706@uni-bayreuth.de>

We would like to announce the availability on CRAN of a new version (1.5)
of our package "distr" .
-----------------------------------------------------------------------------------------
Changes from 1.4 to 1.5

-package is now using /lazy loading/ 
-minor changes in the help pages
-minor enhancements in plot for distributions 
 (Gamma, discrete distributions)
-package now includes a demo - folder; try /demo("distr")/
-class /Gamma/ has been renamed /Gammad/ to avoid name collisions
-we have a CITATION file now; consider /citation("distr")/
-enhanced demos:
  +convolution of uniform variables now includes exact expressions
  +min/max of two variables now available for discrete distributions
-rd-Files have now a keyword entry for distribution and thus may be
 found by the search engine
-exact formula for  "Unif" o "numeric" where o \in { +,-,*,/ }

-----------------------------------------------------------------------------------------
Short Description of "distr":
"distr" is to provide a conceptual treatment of random variables
(r.v.'s) by means of S4--classes. A virtual mother class "Distribution" 
is introduced.
All distributions of the "base" package are implemented as subclasses of
either "AbscontDistribution" or "DiscreteDistribution".

Using these classes, we also provide (default) methods to automatically
generate the image distributions under unary mathematical operations as
well as a general convolution algorithm.

Additionally, we also provide classes for a standardized treatment of
simulations (also under contaminations) and evaluations of statistical
procedures on such simulations.
-----------------------------------------------------------------------------------------


DESCRIPTION:

Package: distr
Version: 1.5
Date: 2005/03/29
Title: distr
Authors: Peter Ruckdeschel <peter.ruckdeschel at uni-bayreuth.de>,
Matthias Kohl <matthias.kohl at uni-bayreuth.de>,
Thomas Stabla <statho3 at web.de>,
Florian Camphausen <fcampi at gmx.de>
Maintainer: Peter Ruckdeschel <peter.ruckdeschel at uni-bayreuth.de>
Description: S4 Classes for Distributions
Depends: R (>= 2.0.1),  (versions for <=2.0.0, on URL cited below),
         setRNG (>= 2004.3-1)
License: GPL version 2 or later
URL: http://www.uni-bayreuth.de/departments/math/org/mathe7/DISTR/

Reference:  
http://www.uni-bayreuth.de/departments/math/org/mathe7/DISTR/distr.pdf

We look forward to receiving questions, comments and suggestions

Peter Ruckdeschel
Matthias Kohl
Thomas Stabla
Florian Camphausen

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



