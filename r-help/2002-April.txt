From jfox at mcmaster.ca  Mon Apr  1 00:21:44 2002
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 31 Mar 2002 17:21:44 -0500
Subject: [R] lme degrees of freedoms: SAS and R
In-Reply-To: <5.0.0.25.2.20020331125150.00aabeb0@pop.service.ohio-state.
 edu>
Message-ID: <5.1.0.14.2.20020331171209.01d4fc40@pop>

Dear Kaiya Liu,

I don't have time now to check, but as I recall, the default "containment 
method" for determining degrees of freedom used by proc mixed in SAS 
doesn't always give the right answer. You can try adding ddfm=satterth as 
an option to the model statement to use Satterthwaite's method for 
calculating df. Again, if I recall right, there's a discussion in the book 
The SAS System for Mixed Models by Littell et al.

Maybe this accounts for the discrepancy.

I hope that this helps,
  John

At 12:52 PM 3/31/2002 +0200, Kaiya Liu wrote:

>I ran a mixed effect model using R 1.4.1 and SAS 8.0 on the SIMS data 
>found in the SASmixed package and found that the degrees of freedoms for 
>fixed effects are very different.
> From R, df = n - v -1 where n is total # of observations, v is the # of 
> levels for the grouping factor. From SAS df = v -1. Am I wrong about this 
> or can somebody explain which is correct and why?
>
>Thanks a lot!
>
>Kaiya Liu
>
>-------------------------------------
>Here are the codes:
>
>For R:
> > formula (SIMS)
>Gain ~ Pretot | Class
> > data(SIMS)
> > fm1SIMS <- lme(Gain ~ Pretot, data = SIMS, random = ~ Pretot | Class, 
> control = list(msVerbose = TRUE))
> > summary (fm1SIMS)
>_________________________________
>For SAS:
>
>proc mixed data=sims;
>    class class;
>    model gain = pretot / solution;
>    random intercept pretot / subject=class type=un;
>run;
>
>Most of the results are comparable except the degrees of freedoms for the 
>fixed effects:
>
> From R: DF = 3500
>
>Fixed effects: Gain ~ Pretot
>                 Value Std.Error   DF   t-value p-value
>(Intercept)  7.066218 0.3631916 3500  19.45589  <.0001
>Pretot      -0.187538 0.0163680 3500 -11.45756  <.0001
>
>Number of Observations: 3691
>Number of Groups: 190
>__________________________________________________________
> From SAS: DF = 189
>
>                     Solution for Fixed Effects
>
>                                          Standard
>                 Effect       Estimate       Error      DF    t 
> Value    Pr > |t|
>
>                 Intercept      7.0595      0.3658     189      19.30 <.0001
>                 pretot        -0.1860     0.01610     189     -11.56 <.0001
>
>-----------------------------------------------------------

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jg_liao at yahoo.com  Mon Apr  1 16:49:24 2002
From: jg_liao at yahoo.com (Jason Liao)
Date: Mon, 1 Apr 2002 06:49:24 -0800 (PST)
Subject: [R] writing a package for generalized linear mixed modesl
Message-ID: <20020401144925.28025.qmail@web10505.mail.yahoo.com>

Happy new month, everyone!

I am planning to write a NIH grant proposal to study ways to speed
Monte Carlo based maximum likelihood algorithm for hierarchical models
with a focus on generalized linear mixed models (GLM with random
effects). I thought it would be nice and also increase the chance of
funding if I could produce an R package in the process. I understand
that Prof. Pinheiro ang Bates have produced LME for linear mixed models
and NLME for non-linear mixed models. But these do not fit logistic
mixed models or Poisson mixed models. SAS Proc NLMIXED can fit simple
logistic or Poisson mixed models but the syntax is not specific for
generalized mixed models. There can be only one level of random
effects. STATA version 7 can fit random intercept models but not more.
There are also some standalone programs such as MIXOR by Don Hendeker
of Chicago. But it is hard to use a stnadalone program for data
analysis efficiently because you have to convert the data set and you
lose all the familiar tools for data transformation and graphics.

I would appeciate your comments on the following points:

1. Is there a strong need for a package for generalized linear mixed
models? Could someone have already written or in the process of writing
one?

2. Will production of a package as part of the algorithm research
increase the chance of funding from NIH?

3. How big is the undertaking? I have some R code for GLMM that runs at
an acceptable speed. I can see that some part can benifit from
converting to C or Fortran. I am not familiar with R's interface with C
and Fortran. I do not know either how to make the package available for
different platforms. Will the multi-platform issue become easier if I
stay with 100% pure R?

 

=====
Jason G. Liao, Ph.D.
Division of Biometrics
University of Medicine and Dentistry of New Jersey
335 George Street, Suite 2200
New Brunswick, NJ 08903-2688
phone (732) 235-9748, fax (732) 235-9777
http://www.geocities.com/jg_liao

__________________________________________________

Yahoo! Greetings - send holiday greetings for Easter, Passover

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Apr  1 18:18:06 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 1 Apr 2002 17:18:06 +0100 (BST)
Subject: [R] writing a package for generalized linear mixed modesl
In-Reply-To: <20020401144925.28025.qmail@web10505.mail.yahoo.com>
Message-ID: <Pine.LNX.4.31.0204011708060.1321-100000@gannet.stats>

On Mon, 1 Apr 2002, Jason Liao wrote:

> Happy new month, everyone!
>
> I am planning to write a NIH grant proposal to study ways to speed
> Monte Carlo based maximum likelihood algorithm for hierarchical models
> with a focus on generalized linear mixed models (GLM with random
> effects). I thought it would be nice and also increase the chance of
> funding if I could produce an R package in the process. I understand
> that Prof. Pinheiro ang Bates have produced LME for linear mixed models
> and NLME for non-linear mixed models. But these do not fit logistic
> mixed models or Poisson mixed models. SAS Proc NLMIXED can fit simple

GLME (beta, S-PLUS only) does.

> logistic or Poisson mixed models but the syntax is not specific for
> generalized mixed models. There can be only one level of random
> effects. STATA version 7 can fit random intercept models but not more.
> There are also some standalone programs such as MIXOR by Don Hendeker
> of Chicago. But it is hard to use a stnadalone program for data
> analysis efficiently because you have to convert the data set and you
> lose all the familiar tools for data transformation and graphics.
>
> I would appeciate your comments on the following points:
>
> 1. Is there a strong need for a package for generalized linear mixed
> models? Could someone have already written or in the process of writing
> one?

See package GLMMgibbs on CRAN, function glmmPQL in package MASS and
function glmm (only a random intercept) in one of Jim Lindsey's packages.

GLMMs are half a chapter in the upcoming fourth edition of Venables &
Ripley.

> 3. How big is the undertaking? I have some R code for GLMM that runs at
> an acceptable speed. I can see that some part can benifit from
> converting to C or Fortran. I am not familiar with R's interface with C
> and Fortran. I do not know either how to make the package available for
> different platforms. Will the multi-platform issue become easier if I
> stay with 100% pure R?

100% pure R would be unacceptably slow.

I would rate this as a research problem, and a major undertaking.
GLMMgibbs is an existence proof, but not able to handle many quite simple
problems.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dstierman at micron.com  Mon Apr  1 22:51:44 2002
From: dstierman at micron.com (dstierman)
Date: Mon, 1 Apr 2002 13:51:44 -0700 
Subject: [R] creating an output file name using cat
Message-ID: <CFEFA50C9BCAD21197470001FA7EBA6B0DECF0FF@ntexchange05.micron.com>

I am having problems trying to create file names using the cat function. I
have an array of column headers, called cnames[] that I want to use as part
of a jpeg output file. Here is the basic code I am using:

data<-read.csv("inputfile.txt")
cnames<-colnames(data)         
for(i in 9:dim(data)[2]) {     
	...
	jpeg(file=cat("data",cnames[i],".jpg",sep=""), width=800,
height=400, bg="white")
	...
}

I get the following error with this code:

R is cool->     jpeg(file=cat("data",cnames[i],".jpg",sep=""), width=800,
height=400, bg="white")

ERROR:
dataGL.jpgError in X11(paste("jpeg::", quality, ":", filename, sep = ""),
width,  : 
        unable to start device JPEG
In addition: Warning message: 
could not open JPEG file `' 

Does anyone have an idea on what is wrong?
Thanks, Don
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Mon Apr  1 23:16:03 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 1 Apr 2002 13:16:03 -0800 (PST)
Subject: [R] creating an output file name using cat
In-Reply-To: <CFEFA50C9BCAD21197470001FA7EBA6B0DECF0FF@ntexchange05.micron.com>
Message-ID: <Pine.A41.4.44.0204011315270.62530-100000@homer36.u.washington.edu>

On Mon, 1 Apr 2002, dstierman wrote:

> I am having problems trying to create file names using the cat function. I
> have an array of column headers, called cnames[] that I want to use as part
> of a jpeg output file. Here is the basic code I am using:
>
> data<-read.csv("inputfile.txt")
> cnames<-colnames(data)
> for(i in 9:dim(data)[2]) {
> 	...
> 	jpeg(file=cat("data",cnames[i],".jpg",sep=""), width=800,
> height=400, bg="white")
> 	...
> }
>
> I get the following error with this code:
>
> R is cool->     jpeg(file=cat("data",cnames[i],".jpg",sep=""), width=800,
> height=400, bg="white")
>
> ERROR:
> dataGL.jpgError in X11(paste("jpeg::", quality, ":", filename, sep = ""),
> width,  :
>         unable to start device JPEG
> In addition: Warning message:
> could not open JPEG file `'
>
> Does anyone have an idea on what is wrong?

Yes. The function you want is called paste(), not cat().

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From stevec at berl.ab.ca  Tue Apr  2 00:44:47 2002
From: stevec at berl.ab.ca (Steve Cumming)
Date: Mon, 1 Apr 2002 15:44:47 -0700
Subject: [R] something confusing about stepAIC
In-Reply-To: <200203311418.QAA06638@stat.math.ethz.ch>
Message-ID: <NDBBKPBLOLKNDPPMIFMOKEFBDAAA.stevec@berl.ab.ca>



Folks, I'm using stepAIC(MASS) to do some automated, exploratory, model
selection for binomial and Poisson glm models in R 1.3. Because I wanted to
experiment with the small-sample correction AICc, I dug around in the code
for the functions
	glm.fit
	stepAIC
	dropterm.glm
	addterm.glm
	extractAIC.glm
and came across something I just don't understand.

stepAIC() passes dropterm.glm() a model object. dropterm.glm() then fits a
number of submodels, computing for each some measure DeltaFit of the
relative change in goodness of fit. It then returns to stepAIC() with some
indication of which submodel is best. addterm.glm behaves similarly. The
problem is, both functions use the submodel deviances to compute the
DeltaFits, not the submodel AICs, even though these are available for at
least the poisson, binomial and negbin families. The step() function works
much the same way.

Is this behaviour correct? It is not obvious to me that the deviance-based
criteria will produce the same sequence of steps as the AIC criteria, in
general. Surely that depends on the exact deviance statistic used, and/or
the error model? It seems to me that the appropriate change to the inner
loop in dropterm.glm() and addterm.glm() would not break anything, and would
make stepAIC() safe to use on models returned by glm.nb().

Am I missing something?

I note that v.1.4 has some new AIC methods. Should I migrate?

Any comments or suggestions would be much appreciated.

Steve Cumming
Boreal Ecosystems Research Ltd.

P.S. I don't know how to express my gratitude and amazement to the people
responsible for R, so I'll just say "thanks".


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From phillip.stafford at motorola.com  Tue Apr  2 01:53:31 2002
From: phillip.stafford at motorola.com (Stafford Phillip-APS095)
Date: Mon, 1 Apr 2002 17:53:31 -0600 
Subject: [R] Compiling R for Solaris 8/Intel CPU
Message-ID: <07077F6C2A38D511920800D0B7821B3204022F41@il06exm01.corp.mot.com>

Has anyone successfully compiled R on an intel machine running Sun OS?

I have heard it can't be done, I know S+ hasn't.

Thanks for any guidance;

Phillip Stafford
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ypeng at math.mun.ca  Tue Apr  2 05:04:07 2002
From: ypeng at math.mun.ca (Paul Y. Peng)
Date: Mon, 01 Apr 2002 23:34:07 -0330
Subject: [R] Two R sessions?
Message-ID: <3CA91FA7.A7A202F7@math.mun.ca>

Hi R users,

I am still a relatively new R user migrated from S+. I wonder in R
how do you handle one difference between R and S+. S+ saves objects
as different files in .Data directory while R saves all objects in
a big file .RData. In S+, I can start two S+ sessions from the same
directory and work simultaneously as long as new objects in the two
sessions are not in the same names. This is particularly useful in
simulation studies. However, this method fails for R. I am curious
how other R users handle this thing in R. Naively, I can copy .Rdata
into another directory and then start another R session there. When
the job is done, dump all new objects in one .Rdata into the other
.Rdata. But maybe someone has a better way to do it.

BTW, why does R save objects in one big file rather than as different
files in a directory as S+ does?

Thanks.
Paul.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ggrothendieck at yifan.net  Tue Apr  2 07:26:41 2002
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Tue, 2 Apr 2002 00:26:41 -0500
Subject: [R] cbind.ts bug?
Message-ID: <3CA8FAC1.13575.30C5446@localhost>


The following creates a time series tt1 whose values rise from 1
to 20 and another time series tt2 each of whose values are 10 larger
than the corresponding value in tt1.  When we attempt to bind them
together as columns, the entry after Dec 1960 is erroneously listed
as NA 1960 instead of Jan 1961.   If n is changed to either 19 or is 
changed to 21 in the  example below, the example suddenly works 
correctly.

> n <- 20
> x <- 1:n
> tt1 <- ts(x,start=c(1960,2),freq=12)
> tt2 <- ts(10+x,start=c(1960,2),freq=12)
> cbind(tt1,tt2)

         tt1 tt2
Feb 1960   1  11
Mar 1960   2  12
Apr 1960   3  13
May 1960   4  14
Jun 1960   5  15
Jul 1960   6  16
Aug 1960   7  17
Sep 1960   8  18
Oct 1960   9  19
Nov 1960  10  20
Dec 1960  11  21
NA 1960   12  22  <-- Note this line !!!
Feb 1961  13  23
Mar 1961  14  24
Apr 1961  15  25
May 1961  16  26
Jun 1961  17  27
Jul 1961  18  28
Aug 1961  19  29
Sep 1961  20  30
> 

P.S. I am using R 1.4.1 on Windows 2000.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gregory_r_warnes at groton.pfizer.com  Mon Apr  1 20:47:40 2002
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Mon, 1 Apr 2002 13:47:40 -0500 
Subject: [R] RE: [S] R for UNIX on Intel platform
Message-ID: <5429125E11E4D411AF7300805FE603A8040DE892@groexmbcr02.pfizer.com>


You may get more response by posting this question on the R news list:
r-help at stat.math.ethz.ch

As for using R on Solaris, its easy to compile, looks and acts almost
exactly like S-Plus 3.X.  I use R on Sparc Solaris every day.

-Greg

> -----Original Message-----
> From: Stafford Phillip-APS095 [mailto:phillip.stafford at motorola.com]
> Sent: Monday, April 01, 2002 12:11 PM
> To: 's-news at wubios.wustl.edu'
> Subject: [S] R for UNIX on Intel platform
> 
> 
> Greetings NewGroup;
> 
> Has anyone here had experience compiling and/or running R in 
> the UNIX environment (Sun OS) on an Intel platform?  I cannot 
> use Linux due to intranet compromises so I'm stuck with the 
> SunOS an Intel-based machine, thus this weird and not very 
> friendly combination.  S+ (at least the current version) has 
> not been compiled for Intel running Sun OS so I'll have to 
> try working with R, but I've never used R before and am not 
> sure where to start.  I'm afraid I may run into the same 
> problem.  Another possibility is getting an old version of S+ 
> that might be compiled on the Intel machine.
> 
> Thank you for any help;
> 
> Phillip Stafford
> Motorola Life Sciences
> --------------------------------------------------------------------
> This message was distributed by s-news at lists.biostat.wustl.edu.  To
> unsubscribe send e-mail to s-news-request at lists.biostat.wustl.edu with
> the BODY of the message:  unsubscribe s-news
> 


LEGAL NOTICE
Unless expressly stated otherwise, this message is confidential and may be privileged. It is intended for the addressee(s) only. Access to this E-mail by anyone else is unauthorized. If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful. If you are not an addressee, please inform the sender immediately.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr  2 00:20:00 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 1 Apr 2002 23:20:00 +0100 (BST)
Subject: [R] creating an output file name using cat
In-Reply-To: <CFEFA50C9BCAD21197470001FA7EBA6B0DECF0FF@ntexchange05.micron.com>
Message-ID: <Pine.LNX.4.31.0204012319180.2759-100000@gannet.stats>

On Mon, 1 Apr 2002, dstierman wrote:

> I am having problems trying to create file names using the cat function. I

I think you meant the paste() function.

> have an array of column headers, called cnames[] that I want to use as part
> of a jpeg output file. Here is the basic code I am using:
>
> data<-read.csv("inputfile.txt")
> cnames<-colnames(data)
> for(i in 9:dim(data)[2]) {
> 	...
> 	jpeg(file=cat("data",cnames[i],".jpg",sep=""), width=800,
> height=400, bg="white")
> 	...
> }
>
> I get the following error with this code:
>
> R is cool->     jpeg(file=cat("data",cnames[i],".jpg",sep=""), width=800,
> height=400, bg="white")
>
> ERROR:
> dataGL.jpgError in X11(paste("jpeg::", quality, ":", filename, sep = ""),
> width,  :
>         unable to start device JPEG
> In addition: Warning message:
> could not open JPEG file `'
>
> Does anyone have an idea on what is wrong?
> Thanks, Don
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr  2 08:51:00 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 2 Apr 2002 07:51:00 +0100 (BST)
Subject: [R] cbind.ts bug?
In-Reply-To: <3CA8FAC1.13575.30C5446@localhost>
Message-ID: <Pine.GSO.4.44.0204020741540.28605-100000@auk.stats>

It's a bug, but in print.ts, so you can safely ignore it,
The output from cbind.ts is correct.

In print.ts

	    t2 <- 1 + round(fr.x*((tm+0.001) %%1))

needs the tolerance I have just added.


On Tue, 2 Apr 2002 ggrothendieck at yifan.net wrote:

>
> The following creates a time series tt1 whose values rise from 1
> to 20 and another time series tt2 each of whose values are 10 larger
> than the corresponding value in tt1.  When we attempt to bind them
> together as columns, the entry after Dec 1960 is erroneously listed
> as NA 1960 instead of Jan 1961.   If n is changed to either 19 or is
> changed to 21 in the  example below, the example suddenly works
> correctly.
>
> > n <- 20
> > x <- 1:n
> > tt1 <- ts(x,start=c(1960,2),freq=12)
> > tt2 <- ts(10+x,start=c(1960,2),freq=12)
> > cbind(tt1,tt2)
>
>          tt1 tt2
> Feb 1960   1  11
> Mar 1960   2  12
> Apr 1960   3  13
> May 1960   4  14
> Jun 1960   5  15
> Jul 1960   6  16
> Aug 1960   7  17
> Sep 1960   8  18
> Oct 1960   9  19
> Nov 1960  10  20
> Dec 1960  11  21
> NA 1960   12  22  <-- Note this line !!!
> Feb 1961  13  23
> Mar 1961  14  24
> Apr 1961  15  25
> May 1961  16  26
> Jun 1961  17  27
> Jul 1961  18  28
> Aug 1961  19  29
> Sep 1961  20  30
> >
>
> P.S. I am using R 1.4.1 on Windows 2000.
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From indra_calisto at yahoo.com  Tue Apr  2 08:59:10 2002
From: indra_calisto at yahoo.com (Indrajit SenGupta)
Date: Tue, 2 Apr 2002 12:29:10 +0530
Subject: [R] A request
Message-ID: <MABBJPBLPNLDIFMIAAOJMEAKCFAA.indra_calisto@yahoo.com>

Can we expect to see an R package on Statistical Quality Control in the
future like SPLUS? I can't understand why nobody made this package before.

______________________
Indrajit SenGupta
Department Of Statistics
St. Xavier's College
Calcutta University
indra_calisto at yahoo.com
indrajitsg at vsnl.net
______________________
EC- 195
Salt Lake City, Sector -1
Calcutta 700064
West Bengal
India
Phone #337-5424
______________________



_________________________________________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Tue Apr  2 09:27:23 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 02 Apr 2002 09:27:23 +0200
Subject: [R] A request
References: <MABBJPBLPNLDIFMIAAOJMEAKCFAA.indra_calisto@yahoo.com>
Message-ID: <3CA95D5B.353C470@statistik.uni-dortmund.de>



Indrajit SenGupta wrote:
> 
> Can we expect to see an R package on Statistical Quality Control in the
> future like SPLUS? I can't understand why nobody made this package before.

Nice to hear you would like to contribute!
Thank you!

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From egonw at sci.kun.nl  Tue Apr  2 09:36:54 2002
From: egonw at sci.kun.nl (E.L. Willighagen)
Date: Tue, 2 Apr 2002 09:36:54 +0200
Subject: [R] A request
In-Reply-To: <3CA95D5B.353C470@statistik.uni-dortmund.de>
References: <MABBJPBLPNLDIFMIAAOJMEAKCFAA.indra_calisto@yahoo.com> <3CA95D5B.353C470@statistik.uni-dortmund.de>
Message-ID: <200204020736.g327asg06139@wn1.sci.kun.nl>

On Tuesday 02 April 2002 09:27, Uwe Ligges wrote:
> Indrajit SenGupta wrote:
> > Can we expect to see an R package on Statistical Quality Control in the
> > future like SPLUS? I can't understand why nobody made this package
> > before.
>
> Nice to hear you would like to contribute!
> Thank you!

Rather often, I get the feeling that the developer are feeling 
underappreciated? Don't.

Egon
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Tue Apr  2 10:05:28 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 02 Apr 2002 10:05:28 +0200
Subject: [R] A request
References: <MABBJPBLPNLDIFMIAAOJMEAKCFAA.indra_calisto@yahoo.com> <3CA95D5B.353C470@statistik.uni-dortmund.de> <200204020736.g327asg06139@wn1.sci.kun.nl>
Message-ID: <3CA96648.77B42E5B@statistik.uni-dortmund.de>

"E.L. Willighagen" wrote:
> 
> On Tuesday 02 April 2002 09:27, Uwe Ligges wrote:
> > Indrajit SenGupta wrote:
> > > Can we expect to see an R package on Statistical Quality Control in the
> > > future like SPLUS? I can't understand why nobody made this package
> > > before.
> >
> > Nice to hear you would like to contribute!
> > Thank you!
> 
> Rather often, I get the feeling that the developer are feeling
> underappreciated? Don't.

After first thoughts about ignoring your message: No, I don't feel
underappreciated. 
Well, I'm not a member of the core team, I don't contribute much code. I
am just trying to answer questions on r-help and to fix some bugs. I
don't earn any money for providing help, fixing bugs or contributing
code.

When I have got a statistical problem that cannot be solved with recent
functions of R or any of the packages on CRAN, I write one or several R
functions, write a little documentation and put it together into a
package.
Most of the things are not worth to be published, but if it is worth, I
put it on CRAN.

My understanding of the R project is that everybody should do it
similar, because that's from my point of view the spirit of this
wonderful GNU project.

R provides the tools for easily documenting and packaging functions.

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From egonw at sci.kun.nl  Tue Apr  2 10:38:07 2002
From: egonw at sci.kun.nl (E.L. Willighagen)
Date: Tue, 2 Apr 2002 10:38:07 +0200
Subject: Finding code (was: [R] A request)
In-Reply-To: <3CA96648.77B42E5B@statistik.uni-dortmund.de>
References: <MABBJPBLPNLDIFMIAAOJMEAKCFAA.indra_calisto@yahoo.com> <200204020736.g327asg06139@wn1.sci.kun.nl> <3CA96648.77B42E5B@statistik.uni-dortmund.de>
Message-ID: <200204020838.g328c8g23867@wn1.sci.kun.nl>

On Tuesday 02 April 2002 10:05, Uwe Ligges wrote:
> "E.L. Willighagen" wrote:
> > On Tuesday 02 April 2002 09:27, Uwe Ligges wrote:
> > > Indrajit SenGupta wrote:
> > > > Can we expect to see an R package on Statistical Quality Control in
> > > > the future like SPLUS? I can't understand why nobody made this
> > > > package before.
> > >
> > > Nice to hear you would like to contribute!
> > > Thank you!
> >
> > Rather often, I get the feeling that the developer are feeling
> > underappreciated? Don't.
>
> After first thoughts about ignoring your message: No, I don't feel
> underappreciated. 

<snip>

> R provides the tools for easily documenting and packaging functions.

Interesting point, because I am working on a library with the same issues:
how to make stuff easy to find... R offers keywords, aliases and full-text 
search. But that is all, right? 

And these only work for installed packages (i.e. those within the search 
path...) And (just tested), full-text search does not include searching 
references or descriptions, right (i.e. \description{} and \reference{})? 

For example,
> help.search("Dongarra")
No help files found with alias or title matching `Dongarra'

Dongarra is author from article in svd().

Did I miss some crucial functionality of help() and help.search()? Why can 
only keywords and aliasses be searched?

To return to Indrajit's question: there must be several other packages with 
which one can do statistical quality control, or at least with some minor 
extensions... But he seems not be able to find them. Ofcourse, that could be
imcompetence, but even then... should R be only used by experts, and not
by novice? In other words, is there a reason why R does not have more 
extensive search methods that can be used by novice to get to know R in such 
depth that the do not have to bug the R-help@ mailling list?

Egon



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Tue Apr  2 10:48:58 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 2 Apr 2002 10:48:58 +0200
Subject: [R] Two R sessions?
In-Reply-To: <3CA91FA7.A7A202F7@math.mun.ca>
References: <3CA91FA7.A7A202F7@math.mun.ca>
Message-ID: <15529.28794.934561.402835@gargle.gargle.HOWL>

>>>>> "PaulYP" == Paul Y Peng <ypeng at math.mun.ca> writes:

    PaulYP> Hi R users, I am still a relatively new R user
    PaulYP> migrated from S+. I wonder in R how do you handle
    PaulYP> one difference between R and S+. S+ saves objects as
    PaulYP> different files in .Data directory while R saves all
    PaulYP> objects in a big file .RData. In S+, I can start two
    PaulYP> S+ sessions from the same directory and work
    PaulYP> simultaneously as long as new objects in the two
    PaulYP> sessions are not in the same names. This is
    PaulYP> particularly useful in simulation studies. However,
    PaulYP> this method fails for R. I am curious how other R
    PaulYP> users handle this thing in R. Naively, I can copy
    PaulYP> .Rdata into another directory and then start another
    PaulYP> R session there. When the job is done, dump all new
    PaulYP> objects in one .Rdata into the other .Rdata. But
    PaulYP> maybe someone has a better way to do it.

I never work with .RData at all.
I believe in the virtue of ``reproducible'' research and data
analysis and hence almost exclusively work with "scripts", where
I define functions, and call functions defining other objects.
In most cases, I rerun my scripts which may call other scripts
via source(.).

Only rarely (but always when doing simulations), I *do* save
specific objects explicitely, but then I use different file
names than .RData,
e.g. after some expensive simulations,
I might have
  save(list= c("x","K0","Kset","n","nK","B", "vK0", "n.matches", "rr"),
       file= file.path(PROJDIR,"EB1k-bootstrap-r2-4.rda"))
where PROJDIR is a character variable containing the project
directory.

Then, to start from these results,
I explicitely do
    load(file.path(PROJDIR,"EB1k-bootstrap-r2-4.rda"))
which will restore the "x", "K0", ... objects but only those.


    PaulYP> BTW, why does R save objects in one big file rather
    PaulYP> than as different files in a directory as S+ does?

Originally, S and S+ save objects in files ``all the time'' (this
is an oversimplification nowadays; in early versions of S it was true)
whereas R does not save anything in files unless told so.
Saving everything in .RData is only upon (direct or indirect)
user request!  Look at 
     
     help(save.image)
     help(q)
     help(save)

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From zedshaw at zedshaw.com  Tue Apr  2 12:15:02 2002
From: zedshaw at zedshaw.com (Zed Shaw)
Date: 02 Apr 2002 02:15:02 -0800
Subject: [R] A request
In-Reply-To: <3CA95D5B.353C470@statistik.uni-dortmund.de>
References: <MABBJPBLPNLDIFMIAAOJMEAKCFAA.indra_calisto@yahoo.com> 
	<3CA95D5B.353C470@statistik.uni-dortmund.de>
Message-ID: <1017742502.12802.17.camel@workhorse.killnine.net>

Uwe,

While I may be a newbie on the R list, I do have some experience with
running open source projects.  My advice is that, if you want people to
contribute, then be friendly and courteous.  If people don't contribute,
then it may be because of the way they were treated on this very list.
This is especially true on lists that have the word "help" in them.
Generally, the people who send messages to "help" lists do it to get
"help", and are thus, by definition, clueless.  Treating them like
morons does not make them happy.  

I personally have had quite a bit of backlashing from folks on here for
very simple mistakes.  It has contributed to some of my reluctance to
continue working on my R Report Generator, the crossplatform R graphical
user interface I was working on, and lots of nice documentation for SPSS
users.  I may begin it again, but it'd help a lot if people were a bit
friendlier on here.

Just food for thought, don't take it personally.  I'm sure you meant it
in a fun loving, sarcastic way :-)


On the subject of statistical process control, I would gladly
participate.  My numerical programming skills are rather weak (too much
Java has made me soft) and I despise fortran, but I'd contribute just
about anything I could to such a project.  It is actually the reason why
I'm using R in the first place.

Anyway, take care.

Zed A. Shaw



On Mon, 2002-04-01 at 23:27, Uwe Ligges wrote:
> 
> 
> Indrajit SenGupta wrote:
> > 
> > Can we expect to see an R package on Statistical Quality Control in the
> > future like SPLUS? I can't understand why nobody made this package before.
> 
> Nice to hear you would like to contribute!
> Thank you!
> 
> Uwe Ligges
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mrufino at cmima.csic.es  Tue Apr  2 11:57:39 2002
From: mrufino at cmima.csic.es (Marta Rufino)
Date: Tue, 02 Apr 2002 11:57:39 +0200
Subject: [R] R-geostatistica
Message-ID: <3.0.1.32.20020402115739.008298c0@cucafera.icm.csic.es>

>Hello,
>
>I have two questions:
>1. Does anyone knows geostatiscal modules for R (besides Ribeiro's), in
particular that does co-kriging?
>
>2. Does anyone knows of any workshops, courses, etc... about R in the world?
>I saw the web, and there is nothing now... posted in the web!
>
>Thank you very much
>Marta 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Ko-Kang at xtra.co.nz  Tue Apr  2 12:46:36 2002
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Tue, 2 Apr 2002 22:46:36 +1200
Subject: [R] A request
References: <MABBJPBLPNLDIFMIAAOJMEAKCFAA.indra_calisto@yahoo.com> <3CA95D5B.353C470@statistik.uni-dortmund.de> <1017742502.12802.17.camel@workhorse.killnine.net>
Message-ID: <000701c1da33$aa231e20$fc5736d2@n1bliarfyrd5b7>

Hi,

----- Original Message -----
From: "Zed Shaw" <zedshaw at zedshaw.com>
To: "R- Mailing List" <r-help at stat.math.ethz.ch>
Sent: Tuesday, April 02, 2002 10:15 PM
Subject: Re: [R] A request


> Uwe,
>
> While I may be a newbie on the R list, I do have some experience with
> running open source projects.  My advice is that, if you want people to
> contribute, then be friendly and courteous.  If people don't contribute,
> then it may be because of the way they were treated on this very list.
> This is especially true on lists that have the word "help" in them.
> Generally, the people who send messages to "help" lists do it to get
> "help", and are thus, by definition, clueless.  Treating them like
> morons does not make them happy.

I agree.

However, most of the time it may be a misunderstanding.  I am very sure that
people, in particular the R Core Team, mean no offense at all when replying
to the list.  It is sometimes, however, that "humorous" words can be
"sarcastic" to some people.  I personally prefer to treat all these as
jokes, and have a laugh.

On the other hand, sometimes on the first read I also detect some kind of
"sarcastics" when people posting a question!

The list can become a bit boring if we all reply in a very formal, offical,
serious manor.  I often find it is these humours, and sometimes even the
positive sarcasm that really helps me to learn.

> I personally have had quite a bit of backlashing from folks on here for
> very simple mistakes.  It has contributed to some of my reluctance to
> continue working on my R Report Generator, the crossplatform R graphical
> user interface I was working on, and lots of nice documentation for SPSS
> users.  I may begin it again, but it'd help a lot if people were a bit
> friendlier on here.

Well again, I'm sure those are not really intended to mean backlashing.
Treat them as positive humour :-)

Your R Report Generator is very useful.  Please do not stop working on it!
It is extremely valuable especially when one wish to publish something on
the WWW!  (Some positive feedback :-)).

> On the subject of statistical process control, I would gladly
> participate.  My numerical programming skills are rather weak (too much
> Java has made me soft) and I despise fortran,

I totally agree with this!

Which brings me to this question.  Does R understands Fortran 90, or do we
must use Fortran 77?  Fortran 77 is extremely horrible and difficult to
learn, as I learnt more advanced languages like Java and HTML first!

Cheers,

Ko-Kang Kevin Wang



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Tue Apr  2 12:51:22 2002
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Tue, 2 Apr 2002 05:51:22 -0500
Subject: Finding code (was: [R] A request)
In-Reply-To: <200204020838.g328c8g23867@wn1.sci.kun.nl>; from egonw@sci.kun.nl on Tue, Apr 02, 2002 at 10:38:07AM +0200
References: <MABBJPBLPNLDIFMIAAOJMEAKCFAA.indra_calisto@yahoo.com> <200204020736.g327asg06139@wn1.sci.kun.nl> <3CA96648.77B42E5B@statistik.uni-dortmund.de> <200204020838.g328c8g23867@wn1.sci.kun.nl>
Message-ID: <20020402055122.C8349@cattell.psych.upenn.edu>

On 04/02/02 10:38, E.L. Willighagen wrote:
>On Tuesday 02 April 2002 10:05, Uwe Ligges wrote:
>> "E.L. Willighagen" wrote:
>Interesting point, because I am working on a library with the same issues:
>how to make stuff easy to find... R offers keywords, aliases and full-text 
>search. But that is all, right? 
>
>And these only work for installed packages (i.e. those within the search 
>path...) And (just tested), full-text search does not include searching 
>references or descriptions, right (i.e. \description{} and \reference{})? 
>
>For example,
>> help.search("Dongarra")
>No help files found with alias or title matching `Dongarra'
>
>Dongarra is author from article in svd().
>
>Did I miss some crucial functionality of help() and help.search()? Why can 
>only keywords and aliasses be searched?

Searching for "Dongarra" on
http://finzi.psych.upenn.edu
in the link called
"Search R documents, functions, and R-help archive"
yields 7 matches for "Dongarra".
(The new default includes R-help only after 1999, but the earlier
stuff is still available.)

It seems to me rather difficult to build into R itself a search
facility for functions that are not installed on your system.  As
more and more packages are contributed - and, really, they ARE
getting contributed at what seems to me a high rate, and some
from people other than the core team - it would be hard to keep
up with them.  This is, I think, a good use for the web.  There
are now several alterantive search engines listed in CRAN under
"Search".

Jon Baron
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From zedshaw at zedshaw.com  Tue Apr  2 13:28:13 2002
From: zedshaw at zedshaw.com (Zed Shaw)
Date: 02 Apr 2002 03:28:13 -0800
Subject: [R] A Few Suggestions to help out newbies
In-Reply-To: <3CA98528.FA3E7011@statistik.uni-dortmund.de>
References: <MABBJPBLPNLDIFMIAAOJMEAKCFAA.indra_calisto@yahoo.com> 
	<3CA95D5B.353C470@statistik.uni-dortmund.de>
	<1017742502.12802.17.camel@workhorse.killnine.net> 
	<3CA98528.FA3E7011@statistik.uni-dortmund.de>
Message-ID: <1017746894.11200.53.camel@workhorse.killnine.net>

Hey Folks,

I may have some suggestions for you, based on my experience as a newbie
with R.  Implementing these very simple resources would be fairly easy
to do and would give volumes of help in return:

1)  An R Cookbook section of the site where people can submit pieces of
interesting code that satisfies a need.  This would be similar to the
Perl/Python/Java Cookbook texts that O'Reilly puts out, but with a more
dynamic activity.  The python folks have something like this, and people
love it.  I learned a lot of python this way.

2)  A Series of Documents helping people translate from another package
to R.  For example, "R for SPSS People", "R for SAS People", etc.

3)  A dynamic FAQ, placed prominently on the front page, ready for
people to access and search.  The idea is that, as you encounter these
dumb questions, you can slap up another faq question about it.  When it
is asked again, don't bother replying, just *politely* say, "go to
http://www.r-project.com/somefaqquestion/".  That saves everyone
headaches, and encapsulates the knowledge on the list.  If it were setup
right, it could be searchable through R.

4)  Better web site layout.  It is hard to read the manuals if you can't
find them.

5)  Better search for the site.  It would be nice if you used google on
the site, but even htdig setup properly would help.

6)  Better layout of packages listed on CRAN.  This listing format will
collapse under its own weight once it gets too large.

7)  Create the "Encyclopedia of Statstics" online.  I would kill for a
repository of all the "trade secrets" of statistics, related to R.  For
example: a brief discussion of the merits of factor analysis,
considering its heritage with IQ tests.  Or, "The History of Student".
If this were organized right, it would even be possible to access it
from R itself and provide people with help with the statistics part of
using R (which is probably the most difficult portion).


And, related to R:

8) Command completion and contextual help in R.  The first one is
probably fairly easy.  The second one is probably impossible.  It would
involve giving out detailed help messages when things go wrong.  Not
sure how to do that.

9) Finally, my personal pet peeve of R:  tell me the line number of
errors.  It's nearly impossible to fix a broken function when I don't
know where it is broken.


Anyway, those are just a few suggestions.  You'll notice that there is a
common thread through all of them:  record the knowledge somewhere, make
it easy to find.  I think doing at least some of these things would
improve support for R, and make it fairly famous (especially if the
statistics encyclopedia worked out). 

Zed A. Shaw

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ernesto at ipimar.pt  Tue Apr  2 14:22:11 2002
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 02 Apr 2002 13:22:11 +0100
Subject: [R] R-geostatistica
In-Reply-To: <3.0.1.32.20020402115739.008298c0@cucafera.icm.csic.es>
References: <3.0.1.32.20020402115739.008298c0@cucafera.icm.csic.es>
Message-ID: <1017750131.6457.75.camel@gandalf>

Hi

I thinks geoR does co-kriging you shall also take a look at sgeostat.

Regards

EJ

On Tue, 2002-04-02 at 10:57, Marta Rufino wrote:
> >Hello,
> >
> >I have two questions:
> >1. Does anyone knows geostatiscal modules for R (besides Ribeiro's), in
> particular that does co-kriging?
> >
> >2. Does anyone knows of any workshops, courses, etc... about R in the world?
> >I saw the web, and there is nothing now... posted in the web!
> >
> >Thank you very much
> >Marta 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From egonw at sci.kun.nl  Tue Apr  2 13:11:24 2002
From: egonw at sci.kun.nl (E.L. Willighagen)
Date: Tue, 2 Apr 2002 13:11:24 +0200
Subject: Finding code (was: [R] A request)
In-Reply-To: <20020402055122.C8349@cattell.psych.upenn.edu>
References: <MABBJPBLPNLDIFMIAAOJMEAKCFAA.indra_calisto@yahoo.com> <200204020838.g328c8g23867@wn1.sci.kun.nl> <20020402055122.C8349@cattell.psych.upenn.edu>
Message-ID: <200204021111.g32BBQg10022@wn1.sci.kun.nl>

On Tuesday 02 April 2002 12:51, Jonathan Baron wrote:
> On 04/02/02 10:38, E.L. Willighagen wrote:
> >On Tuesday 02 April 2002 10:05, Uwe Ligges wrote:
> >> "E.L. Willighagen" wrote:
> Searching for "Dongarra" on
> http://finzi.psych.upenn.edu
> in the link called
> "Search R documents, functions, and R-help archive"
> yields 7 matches for "Dongarra".
> (The new default includes R-help only after 1999, but the earlier
> stuff is still available.)
>
> It seems to me rather difficult to build into R itself a search
> facility for functions that are not installed on your system.  As
> more and more packages are contributed - and, really, they ARE
> getting contributed at what seems to me a high rate, and some
> from people other than the core team - it would be hard to keep
> up with them.  This is, I think, a good use for the web.  There
> are now several alterantive search engines listed in CRAN under
> "Search".

Indeed. A "Search" link under "Documentation" on www.r-projects.org itself 
pointing to it would be nice. Who is the person to ask for this?

Egon
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr  2 13:17:47 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 2 Apr 2002 12:17:47 +0100 (BST)
Subject: [R] A request
In-Reply-To: <000701c1da33$aa231e20$fc5736d2@n1bliarfyrd5b7>
Message-ID: <Pine.GSO.4.44.0204021211100.10947-100000@auk.stats>

On Tue, 2 Apr 2002, Ko-Kang Kevin Wang wrote:

> Which brings me to this question.  Does R understands Fortran 90, or do we
> must use Fortran 77?  Fortran 77 is extremely horrible and difficult to
> learn, as I learnt more advanced languages like Java and HTML first!

R doesn't care: it only uses compiled code in shared libraries/DLLs.

Unfortunately you cannot assume that users have an F95 (or F90) compiler.
In particular, gcc does not provide one, so Linux and Windows users do not
(necessarily) have one, and MacOS uses f2c which does not handle F90/5
constructs, AFAIK.  We are hard enough pressed to assume Fortran
(which R used not to).

I use f95 on Solaris, which works well with R (better than f77 because of
the enhanced libraries).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From noel at univ-lille3.fr  Tue Apr  2 12:40:15 2002
From: noel at univ-lille3.fr (Yvonnick NOEL)
Date: Tue, 2 Apr 2002 12:40:15 +0200
Subject: [R] Repeated aov residuals
Message-ID: <200204021140.NAA04758@stat.math.ethz.ch>

Hello,

Are there any access functions to the various residual variables that should 
result from a repeated measures ANOVA ? MyAOVObject$residuals does not exist, 
and simply printing MyAOVObject gives a very long print of all fields in the 
result list, many of which I can't see what they are exactly : 
$error.qr$qraux, for instance.

What I would like basically is to inspect those residuals as to sphericity 
for instance.

I'd be curious to know how other R users proceed for checking ANOVA 
assumptions in the repeated measures case.

Thanks a lot for your help,

Y. Noel
Dpt. of Psychology
U. of Lille 3
FRANCE
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Tue Apr  2 13:51:42 2002
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Tue, 2 Apr 2002 06:51:42 -0500
Subject: [R] A Few Suggestions to help out newbies
In-Reply-To: <1017746894.11200.53.camel@workhorse.killnine.net>; from zedshaw@zedshaw.com on Tue, Apr 02, 2002 at 03:28:13AM -0800
References: <MABBJPBLPNLDIFMIAAOJMEAKCFAA.indra_calisto@yahoo.com> <3CA95D5B.353C470@statistik.uni-dortmund.de> <1017742502.12802.17.camel@workhorse.killnine.net> <3CA98528.FA3E7011@statistik.uni-dortmund.de> <1017746894.11200.53.camel@workhorse.killnine.
Message-ID: <20020402065142.A11737@cattell.psych.upenn.edu>

Once again, I think a lot of this has been done, although not
quite the way you would like.

Another point is that the sort of things you are asking are
things that can be done by non-statisticians, e.g., anyone with a
web server and some extra disk space.

On 04/02/02 03:28, Zed Shaw wrote:
>Hey Folks,
>
>I may have some suggestions for you, based on my experience as a newbie
>with R.  Implementing these very simple resources would be fairly easy
>to do and would give volumes of help in return:
>
>1)  An R Cookbook section of the site where people can submit pieces of
>interesting code that satisfies a need.  This would be similar to the
>Perl/Python/Java Cookbook texts that O'Reilly puts out, but with a more
>dynamic activity.  The python folks have something like this, and people
>love it.  I learned a lot of python this way.

I like this, but see below.

>2)  A Series of Documents helping people translate from another package
>to R.  For example, "R for SPSS People", "R for SAS People", etc.

The "R for psychology" thing I wrote with Yuelin Li is a LITTLE
like this, as it makes a lot of comparisons with Systat and SAS.
(Systat, believe it or not, is the "scientific" package sold by
SPSS, and SPSS is the "business" package.)

>3)  A dynamic FAQ, placed prominently on the front page, ready for
>people to access and search.  The idea is that, as you encounter these
>dumb questions, you can slap up another faq question about it.  When it
>is asked again, don't bother replying, just *politely* say, "go to
>http://www.r-project.com/somefaqquestion/".  That saves everyone
>headaches, and encapsulates the knowledge on the list.  If it were setup
>right, it could be searchable through R.

There is a FAQ, and perhaps you can figure out how to make it
"dynamic".

>4)  Better web site layout.  It is hard to read the manuals if you can't
>find them.

They come with R itself, and you can point your browser to files
on your disk.  They are also on http://finzi.psych.upenn.edu, and
elsewhere.

>5)  Better search for the site.  It would be nice if you used google on
>the site, but even htdig setup properly would help.

I have htdig set up on http://finzi.psych.upenn.edu, along with
other things that might interest you and others.

>6)  Better layout of packages listed on CRAN.  This listing format will
>collapse under its own weight once it gets too large.
>
>7)  Create the "Encyclopedia of Statstics" online.  I would kill for a
>repository of all the "trade secrets" of statistics, related to R.  For
>example: a brief discussion of the merits of factor analysis,
>considering its heritage with IQ tests.  Or, "The History of Student".
>If this were organized right, it would even be possible to access it
>from R itself and provide people with help with the statistics part of
>using R (which is probably the most difficult portion).

I like this, and (1) above.  We have some of this in our "R for
psychology" piece, but more of this could be done, _if_ it were
properly searchable.

A problem is that a lot of uses of R (or any such program) are
discipline dependent.  Thus, an alternative is to develop things
like this for different disciplines, which is the approach we've
taken.  I'm not sure ANYONE, even the members of the core team,
could anticipate the needs of all the various users of R, well
enough to make a more detailed FAQ.  It is hard enough for me
just in the grab bag called "psychology," which includes
time-series analysis of neural impulses, fMRI data, questionnaire
studies, and treatment outcome studies.  But at least I know
about them because I sit through job talks!  Thus, I encourage
more of what we did, and I think you have provided some good
suggestions that we can use for revision.

>And, related to R:
>
>8) Command completion and contextual help in R.  The first one is
>probably fairly easy.  The second one is probably impossible.  It would
>involve giving out detailed help messages when things go wrong.  Not
>sure how to do that.

Doesn't ESS do this?

>9) Finally, my personal pet peeve of R:  tell me the line number of
>errors.  It's nearly impossible to fix a broken function when I don't
>know where it is broken.

If you run a script like source("myscript.R",echo=T) you see
exactly what it is doing and you can find where it bombs.
Moreover - and Systat never did this - all the variables created
up to the point where it bombs are there for you to examine.
Even when it bombs within a loop, the index of the loop is
available.  (This often happens to me when I have one subject
with no variance on the dependent variable in a within-subject
regression, and this is the easiest way to find such cases.)

>Anyway, those are just a few suggestions.  You'll notice that there is a
>common thread through all of them:  record the knowledge somewhere, make
>it easy to find.  I think doing at least some of these things would
>improve support for R, and make it fairly famous (especially if the
>statistics encyclopedia worked out). 
>
>Zed A. Shaw
>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From till.baumgaertel at epost.de  Tue Apr  2 14:51:26 2002
From: till.baumgaertel at epost.de (=?ISO-8859-1?Q?Till=20Baumgaertel?=)
Date: Tue, 2 Apr 2002 14:51:26 +0200
Subject: [R] =?ISO-8859-1?Q?=22Large=22=20data=20set=3A=20performance=20issue?=
Message-ID: <3C97A93300008A7B@mail.epost.de>

hi all,

I've got to import CSV-datasets (with variable-names in the first line)
into data.frames. each is about 12MB (or more!) with 1823 columns and about
500 rows. the first 22 columns are in "character"-mode, the rest is "numeric".

I run R 1.4.1 on a Windows 2000 system.

First I tried read.table() which works fine for a low number of cases (say,
40). with all cases the function does not return within one hour (celeron at 600mhz,
256 MB).

Then I tried scan() which is almost OK.
I scan() the first line for var-names, then the rest. the data-matrix get
transposed and as.data.frame()'ed. 

the problem is converting the last 1801 variabales to "numeric"-mode.

i use the following snippet:
i <- 23;
while( i <= totCols){
	datframe[,i]<-as.numeric(datframe[,i]);
	i <- i + 1;
}

each step takes ~2 secs which makes all in all about an hour.

I suppose I do something really stupid. For reading the data I use
datfull<-scan(filename,sep=",",skip=1,what="character")
which gives me a transposed matrix of my data (variables in rows).

If this wasn't, maybe I could give the "what"-parameter a vector value with
the appropriate variable-types?

Sorry, but I really got stuck and don't know any further.

thanks,
Till







________________________________________
Zeitschriftenabos online bestellen - jetzt neu im Infoboten! http://www.epost.de


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wolski at molgen.mpg.de  Tue Apr  2 16:16:44 2002
From: wolski at molgen.mpg.de (witold eryk wolski)
Date: Tue, 02 Apr 2002 15:16:44 +0100
Subject: [R] newbee to XML library
Message-ID: <5.1.0.14.0.20020402151005.00b0ac60@pop.gmx.net>

Hi!
I wanted to read out from an xml document values of some tags using the xml 
library in R.
Has anyone out ther a example that is doing something like:
take a xml file and return all values of the set of elements named eg 
myvalue as an array.

The document that i have to parse looks like:

<open>
	<firstchild>
		<secondchild>
			<myvalue>0.44</myvalue>
		</secondchild>
		<secondchild>
			<myvalue>0.55</myvalue>
		</secondchild>
	</firstchild>
</open>

Eryk.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jzhang at jimmy.harvard.edu  Tue Apr  2 15:23:09 2002
From: jzhang at jimmy.harvard.edu (John Zhang)
Date: Tue, 2 Apr 2002 08:23:09 -0500 (EST)
Subject: [R] newbee to XML library
Message-ID: <200204021323.IAA14873@blaise.dfci.harvard.edu>


>X-Sender: wolski at harry.molgen.mpg.de
>Date: Tue, 02 Apr 2002 15:16:44 +0100
>To: R- Mailing List <r-help at stat.math.ethz.ch>
>From: witold eryk wolski <wolski at molgen.mpg.de>
>Subject: [R] newbee to XML library
>Mime-Version: 1.0
>
>Hi!
>I wanted to read out from an xml document values of some tags using the xml 
>library in R.
>Has anyone out ther a example that is doing something like:
>take a xml file and return all values of the set of elements named eg 
>myvalue as an array.

Have a look at the function GOXMLParser.R in package AnnBuilder at 
www.bioconductor.org.

>
>The document that i have to parse looks like:
>
><open>
>	<firstchild>
>		<secondchild>
>			<myvalue>0.44</myvalue>
>		</secondchild>
>		<secondchild>
>			<myvalue>0.55</myvalue>
>		</secondchild>
>	</firstchild>
></open>
>
>Eryk.
>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pingping.zheng at lancaster.ac.uk  Tue Apr  2 15:36:38 2002
From: pingping.zheng at lancaster.ac.uk (Pingping Zheng)
Date: Tue, 02 Apr 2002 14:36:38 +0100
Subject: [R] compile C code
Message-ID: <3CA9B3E6.9060201@lancs.ac.uk>

  Hello

I run R 1.4.1 on a Windows XP. I have downloaded and installed the tools 
from
http://www.stats.ox.ac.uk/pub/Rtools/tools.zip. I also installed 
MinGW-1.1 and
perl as recommanded at http://www.stats.ox.ac.uk/pub/Rtools/. When I run
...\bin\Rcmd SHLIB hello.cc
I got message "/bin/sh.exe" file not exist. I have put unzipped 
tools.zip at C:\bin
and added the path to the system enviroment PATH.

Can anyone help me?

Pingping

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr  2 16:45:10 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 2 Apr 2002 15:45:10 +0100 (BST)
Subject: [R] Repeated aov residuals
In-Reply-To: <200204021140.NAA04758@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.31.0204021541390.18858-100000@gannet.stats>

On Tue, 2 Apr 2002, Yvonnick NOEL wrote:

> Are there any access functions to the various residual variables that should
> result from a repeated measures ANOVA ? MyAOVObject$residuals does not exist,
> and simply printing MyAOVObject gives a very long print of all fields in the
> result list, many of which I can't see what they are exactly :
> $error.qr$qraux, for instance.

Do this by stratum: see e.g. the MASS script which contains

oats.aov <- aov(Y ~ Nf*V + Error(B/V), data = oats, qr = T)
plot(fitted(oats.aov[[4]]), studres(oats.aov[[4]]))
abline(h=0, lty=2)
oats.pr <- proj(oats.aov)
qqnorm(oats.pr[[4]][,"Residuals"], ylab="Stratum 4 residuals")
qqline(oats.pr[[4]][,"Residuals"])

You may need the book to understand the context, but a multi-stratum aov
object is a list of aov objects, one for each stratum.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From laurent at genome.cbs.dtu.dk  Tue Apr  2 16:10:56 2002
From: laurent at genome.cbs.dtu.dk (Laurent Gautier)
Date: Tue, 2 Apr 2002 16:10:56 +0200
Subject: [R] A Few Suggestions to help out newbies
In-Reply-To: <1017746894.11200.53.camel@workhorse.killnine.net>
References: <MABBJPBLPNLDIFMIAAOJMEAKCFAA.indra_calisto@yahoo.com> <3CA95D5B.353C470@statistik.uni-dortmund.de> <1017742502.12802.17.camel@workhorse.killnine.net> <3CA98528.FA3E7011@statistik.uni-dortmund.de> <1017746894.11200.53.camel@workhorse.killnine.
Message-ID: <20020402141056.GD17964@giraffa.cbs.dtu.dk>

On Tue, Apr 02, 2002 at 03:28:13AM -0800, Zed Shaw wrote:
> Hey Folks,
> 
> I may have some suggestions for you, based on my experience as a newbie
> with R.  Implementing these very simple resources would be fairly easy
> to do and would give volumes of help in return:
> 
> 1)  An R Cookbook section of the site where people can submit pieces of
> interesting code that satisfies a need.  This would be similar to the
> Perl/Python/Java Cookbook texts that O'Reilly puts out, but with a more
> dynamic activity.  The python folks have something like this, and people
> love it.  I learned a lot of python this way.


You may try get in contact with the author of the following web document

http://lark.cc.ukans.edu/~pauljohn/R/statsRus.html


> 
> 2)  A Series of Documents helping people translate from another package
> to R.  For example, "R for SPSS People", "R for SAS People", etc.


http://www.r-project.org/other-docs.html


> 
> 3)  A dynamic FAQ, placed prominently on the front page, ready for
> people to access and search.  The idea is that, as you encounter these
> dumb questions, you can slap up another faq question about it.  When it
> is asked again, don't bother replying, just *politely* say, "go to
> http://www.r-project.com/somefaqquestion/".  That saves everyone
> headaches, and encapsulates the knowledge on the list.  If it were setup
> right, it could be searchable through R.


Several FAQs are accessible at
http://www.-r-projects.org/faqs.html

Personally I never remember how to download r-devel using rsync. I am going
to the 'R FAQ' then I am using the 'text search feature' of my web browser
(Alt+F, Ctr+F, or / in my case) and I find the answer.

Do not mistake a concise answer for an impolite answer. Busy people
sometimes allow themselfves to skip some of the formalities.


> 
> 4)  Better web site layout.  It is hard to read the manuals if you can't
> find them.
> 

?! I have a menu item 'Manuals' when I go to http://www.r-project.org/ 
(on the left, third from the top in the 'Documentation' section)



> 5)  Better search for the site.  It would be nice if you used google on
> the site, but even htdig setup properly would help.
> 

'www.google.com' aficionados may try the string 'site:www.r-project.org'
in their queryi for example. 



> 6)  Better layout of packages listed on CRAN.  This listing format will
> collapse under its own weight once it gets too large.


Memory has become more expensive over the last few months but displaying a
html document that weights even few hundred kilobytes remains a reasonable
assumption (the document is currently 164 kb).


> 
> 7)  Create the "Encyclopedia of Statstics" online.  I would kill for a
> repository of all the "trade secrets" of statistics, related to R.  For
> example: a brief discussion of the merits of factor analysis,
> considering its heritage with IQ tests.  Or, "The History of Student".
> If this were organized right, it would even be possible to access it
> from R itself and provide people with help with the statistics part of
> using R (which is probably the most difficult portion).
> 

I remembered being a happy user of statlib

http://lib.stat.cmu.edu/



> 
> And, related to R:
> 
> 8) Command completion and contextual help in R.  The first one is
> probably fairly easy.  The second one is probably impossible.  It would
> involve giving out detailed help messages when things go wrong.  Not
> sure how to do that.
>


I am not certain about how 'easy' is the first, but I am surely happy a
brave soul did it (I am an humble user, I am not sure I could have done it).
Did you check ESS ?
(accessible through the menu 'Other' at www.r-project.org).

If you are not sure about how to accomplish what you believe being
 impossible...    :)


 
> 9) Finally, my personal pet peeve of R:  tell me the line number of
> errors.  It's nearly impossible to fix a broken function when I don't
> know where it is broken.
> 

I usually reach the faulty part in my function within an acceptable time.
Did you try 
help(traceback)
help(debug)

?

> 
> Anyway, those are just a few suggestions.  You'll notice that there is a
> common thread through all of them:  record the knowledge somewhere, make
> it easy to find.  I think doing at least some of these things would
> improve support for R, and make it fairly famous (especially if the
> statistics encyclopedia worked out). 
> 
> Zed A. Shaw
>



Hopin' it helps,




Laurent
 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Apr  2 16:16:41 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 02 Apr 2002 16:16:41 +0200
Subject: [R] "Large" data set: performance issue
In-Reply-To: <3C97A93300008A7B@mail.epost.de>
References: <3C97A93300008A7B@mail.epost.de>
Message-ID: <x2wuvqgp86.fsf@blueberry.kubism.ku.dk>

Till Baumgaertel <till.baumgaertel at epost.de> writes:

> hi all,
> 
> I've got to import CSV-datasets (with variable-names in the first line)
> into data.frames. each is about 12MB (or more!) with 1823 columns and about
> 500 rows. the first 22 columns are in "character"-mode, the rest is "numeric".
> 
> I run R 1.4.1 on a Windows 2000 system.

What happens if you try this?:

datfull <- read.csv("foo", colClasses=rep(c("character","numeric"),c(22,1801)))


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From flom at ndri.org  Tue Apr  2 16:25:31 2002
From: flom at ndri.org (Peter Flom)
Date: Tue, 02 Apr 2002 09:25:31 -0500
Subject: [R] A Few Suggestions to help out newbies
Message-ID: <sca9792c.064@NDRI2.NDRI.ORG>

As a true R-Newbie, I thought I would respond to Zed Shaw's ideas.  I think they're all good.  I've put comments re the ones which would be critical for me

>>>1)  An R Cookbook section of the site where people can submit pieces >>>of interesting code that satisfies a need.  This would be similar to the
>>>Perl/Python/Java Cookbook texts that O'Reilly puts out, but with a >>>more dynamic activity.  The python folks have something like this, and >>>people love it.  I learned a lot of python this way.

I think the critical issue with this would be indexing and documentation.  Also possibly copyright problems

e.g., If I or someone wrote a function to apply the formula for CIs around a proportion given by Agresti and Coull (1998).  Approximate is better than exact for interval estimation of binomial proportions" American Statistician, 52 119-126.

Would I file it under CI? proportion? binomial? or what?
would I need to get permission from the authors before posting it?


>>>2)  A Series of Documents helping people translate from another
 >>>package to R.  For example, "R for SPSS People", "R for SAS People", >>>etc.

If someone did a good job of this, it would be TREMENDOUSLY useful to me, and I am sure to others as well.  I'm used to SAS, and am finding the learning curve for R pretty steep....

>>>3)  A dynamic FAQ, placed prominently on the front page, ready for
>>>people to access and search.  The idea is that, as you encounter >>>these dumb questions, you can slap up another faq question about it.  

A good idea.  But, one quibble: Questions aren't "dumb".  They may be ignorant.  As another thread here is making clear, e-mail is not conducive to shadings of emotion.  While I am sure Zed meant no disrespect to anyone, conceiving of questions as "dumb" leads one to thinking that the person ASKING the question is "dumb" which leads to responses that treat the person as dumb, which isn't good.

If someone asks a question which you don't feel like answering, don't answer! :-).   If you answer, be polite.  

Just my two cents; again, from a real newbie.








Peter L. Flom, PhD
Assistant Director, Statistics and Data Analysis Core
Center for Drug Use and HIV Research
National Development and Research Institutes
71 W. 23rd St
New York, NY 10010
(212) 845-4485 (voice)
(917) 438-0894 (fax)


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at u.washington.edu  Tue Apr  2 16:37:49 2002
From: rossini at u.washington.edu (Anthony Rossini)
Date: Tue, 2 Apr 2002 06:37:49 -0800 (PST)
Subject: [R] A Few Suggestions to help out newbies
In-Reply-To: <20020402141056.gd17964@giraffa.cbs.dtu.dk>
Message-ID: <Pine.LNX.4.43.0204020637490.31764@hymn04.u.washington.edu>

> On Tue, Apr 02, 2002 at 03:28:13AM -0800, Zed Shaw wrote:

> > 7)  Create the "Encyclopedia of Statstics" online.  I would kill for a
> > repository of all the "trade secrets" of statistics, related to R.  For
> > example: a brief discussion of the merits of factor analysis,
> > considering its heritage with IQ tests.  Or, "The History of Student".
> > If this were organized right, it would even be possible to access it
> > from R itself and provide people with help with the statistics part of
> > using R (which is probably the most difficult portion).

This is a great idea, one which I started working on around late 1994 (the "online history and/or course thing").  One of the cool things that the early WWW had going for it was lots of people trying to integrate and collaborate, and one such project was the world-wide web encyclopaedia.   It had two extremely fatal flaws -- funding and academic credit (for people who worked on it).

It has a secondary flaw -- people worry more about contributing to a documentation project than to a software project (at least in my experience -- I've had 2 on-line text books since 1996 that many, many people have asked for hard-copy (at least PDF/PS versions) of).  But apparently the asking price was too high (fix mistakes/typos or contribute a paragraph).

And while I'm ranting, there are another set of problems -- people prefer to speculate than to write (code/docs/prototypes), and write than read (existing frameworks, and integrate with them).  Leads to many wheel reinventions.

If you really want something like that (on-line encyclopedia), there are plenty of approximations, for example.  I think the Statistica folk (I might be getting the package wrong) have something like that on their WWW site.

Of course, I didn't integrate with R back then, R wasn't too much at that point (and XML wasn't really worth noticing, let along developing with, until 1997/1998)...  But note the real point -- discussing how great something would be is quite silly until you attempt a prototype of it, to see how it might work out.  

And to reiterate what someone else mentioned -- most of the core people are busy; suggestions are best accompanied with at least a prototype to be fixed.

Finally, with respect to SPC -- yes, all the tools are there, in the sense that EVERY stat package, including plain excel, has all the tools.  Even C and Fortran have all the tools, in the sense I'm talking about.  Functions to make it easier, on the other hand, aren't present (yet).  And this is the crux of the matter.

best,
-tony


----
A.J. Rossini                            Rsrch Asst Professor of Biostatistics
rossini at u.washington.edu                http://software.biostat.washington.edu/
Biostatistics/Univ. of Washington       206-543-1044 (3286=fax) (Thursdays)
HIV Vaccine Trials Network/FHCRC        206-667-7025 (4812=fax) (M/Tu/W)
(Friday location is generally unknown).



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Tue Apr  2 16:42:52 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 02 Apr 2002 16:42:52 +0200
Subject: [R] compile C code
References: <3CA9B3E6.9060201@lancs.ac.uk>
Message-ID: <3CA9C36C.DDDD745B@statistik.uni-dortmund.de>



Pingping Zheng wrote:
> 
>   Hello
> 
> I run R 1.4.1 on a Windows XP. I have downloaded and installed the tools
> from
> http://www.stats.ox.ac.uk/pub/Rtools/tools.zip. I also installed
> MinGW-1.1 and
> perl as recommanded at http://www.stats.ox.ac.uk/pub/Rtools/. When I run
> ...\bin\Rcmd SHLIB hello.cc
> I got message "/bin/sh.exe" file not exist. I have put unzipped
> tools.zip at C:\bin
> and added the path to the system enviroment PATH.
> 
> Can anyone help me?


Is your compiler installed on another drive than c: (d: for example) ?
Then you have to create the /bin directory on the identical one (here
d:).

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From nina at math.uni-bremen.de  Tue Apr  2 17:26:55 2002
From: nina at math.uni-bremen.de (Nina Lieske)
Date: Tue, 2 Apr 2002 17:26:55 +0200
Subject: [R] label tickmarks in persp()-plot
Message-ID: <031b01c1da5a$d2ce93f0$557c6686@tating>

Dear R-users,

is there a way to label the tickmarks other than persp does it? I didn't
find anything on that in the archive.

To plot the surface with equi-distant tickmarks, I assigned
x<-c(1:6)
y<-x
persp(x,y,z,....)
Instead of labels 1 to 6, I need something like 0.05, 0.1,10,15,100,1000.

Any hint and help appreciated,
Nina


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From till.baumgaertel at epost.de  Tue Apr  2 17:32:05 2002
From: till.baumgaertel at epost.de (=?ISO-8859-1?Q?Till=20Baumgaertel?=)
Date: Tue, 2 Apr 2002 17:32:05 +0200
Subject: [R] =?ISO-8859-1?Q?AW=3A=20Re=3A=20=5BR=5D=20=22Large=22=20data=20set=3A=20performance=20issue?=
In-Reply-To: <x2wuvqgp86.fsf@blueberry.kubism.ku.dk>
Message-ID: <3C97A93300008C99@mail.epost.de>

>What happens if you try this?:
>
>datfull <- read.csv("foo", colClasses=rep(c("character","numeric"),c(22,1801)))

nope, sorry. it's not working.
it complains about the following:
####
Error in scan(file = file, what = what, sep = sep, quote = quote, dec =
dec,  : 
        "scan" expected a real, got ""+1073741824""
####

ok, i forgot to tell you my numbers are just like the characters quoted
("\""). sorry!

therefore i tried
###
datfull <- read.csv2(file.choose(), colClasses=rep(c("character","numeric"),c(22,1801)),quote="\"",sep=",")
###

But it's still not working.

it seems to be critical to do the translation of character ("+1234") to
numeric(1234.0) AFTER the file was totally read into (any kind of?) a data
structure. 

It seems I really  have to write an external (PERL-)programm, but that's
not exactly what I wanted, because read.table() does the job quite good
(despite the fact ot's not capable of handling large data sets).

but thank you for your help,
till




________________________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Apr  2 17:35:49 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 02 Apr 2002 17:35:49 +0200
Subject: [R] A Few Suggestions to help out newbies
In-Reply-To: <20020402141056.GD17964@giraffa.cbs.dtu.dk>
References: <MABBJPBLPNLDIFMIAAOJMEAKCFAA.indra_calisto@yahoo.com>
	<3CA95D5B.353C470@statistik.uni-dortmund.de>
	<1017742502.12802.17.camel@workhorse.killnine.net>
	<3CA98528.FA3E7011@statistik.uni-dortmund.de>
	<1017746894.11200.53.camel@workhorse.killnine.
	<20020402141056.GD17964@giraffa.cbs.dtu.dk>
Message-ID: <x2sn6eglka.fsf@blueberry.kubism.ku.dk>

Laurent Gautier <laurent at genome.cbs.dtu.dk> writes:

> On Tue, Apr 02, 2002 at 03:28:13AM -0800, Zed Shaw wrote:
> > Hey Folks,
> > 
> > I may have some suggestions for you, based on my experience as a newbie
> > with R.  Implementing these very simple resources would be fairly easy
> > to do and would give volumes of help in return:
> > 
> > 1)  An R Cookbook section of the site where people can submit pieces of
> > interesting code that satisfies a need.  This would be similar to the
> > Perl/Python/Java Cookbook texts that O'Reilly puts out, but with a more
> > dynamic activity.  The python folks have something like this, and people
> > love it.  I learned a lot of python this way.
> 
> 
> You may try get in contact with the author of the following web document
> 
> http://lark.cc.ukans.edu/~pauljohn/R/statsRus.html
> 

Or start building a Wiki (cf. wiki.tcl.tk), one of my long-time
desires. It's not quite as simple as it sounds, since you need
procedures to keep the information up to date, create a sensible
superstructure, and for that matter also to ensure that the
information is sound in the first place.

(Paul's page is generally sound, but every once in a while there's a
spot where you think "there's a better way". E.g. plotting the Normal
density with

 x<-seq(-3,3,.1) 
 plot(x,dnorm(x,0,1), type="l")

Yes, it works, but how about curve(dnorm(x), -3, 3) ?)

> > 6)  Better layout of packages listed on CRAN.  This listing format will
> > collapse under its own weight once it gets too large.
> 
> 
> Memory has become more expensive over the last few months but displaying a
> html document that weights even few hundred kilobytes remains a reasonable
> assumption (the document is currently 164 kb).

Yes, but I think Zed meant that it needs some kind of superstructure
or keyword system attached. Could be true but someone need to invent
the structure or keyword set...

> > And, related to R:
> > 
> > 8) Command completion and contextual help in R.  The first one is
> > probably fairly easy.  The second one is probably impossible.  It would
> > involve giving out detailed help messages when things go wrong.  Not
> > sure how to do that.
> 
> I am not certain about how 'easy' is the first, but I am surely happy a
> brave soul did it (I am an humble user, I am not sure I could have done it).
> Did you check ESS ?
> (accessible through the menu 'Other' at www.r-project.org).

ESS does name completion, yes. And the readline front end could be
made to do likewise on Unix-alikes.

> If you are not sure about how to accomplish what you believe being
>  impossible...    :)

It sounds rather easy with ESS. (Basically just search backwards to the
function name, then call help() or args() on it). Not massively
difficult with other interfaces either. Someone needs to do it,
though... 

> > 9) Finally, my personal pet peeve of R:  tell me the line number of
> > errors.  It's nearly impossible to fix a broken function when I don't
> > know where it is broken.
> > 
> 
> I usually reach the faulty part in my function within an acceptable time.
> Did you try 
> help(traceback)
> help(debug)
> 
> ?

and help(dump.frames). The line number issue is somewhat nasty, due to
the non-uniqueness of parse/deparse in R (and S). Essentially, once a
function is parsed, the line numbers are lost, and deparsing may cause
statements to end up on lines different from where they originated.
Similar issues relate to comment handling. It requires rather intimate
knowledge of parser generators to get a handle on this, I'm afraid. 

> > 
> > Anyway, those are just a few suggestions.  You'll notice that there is a
> > common thread through all of them:  record the knowledge somewhere, make
> > it easy to find.  I think doing at least some of these things would
> > improve support for R, and make it fairly famous (especially if the
> > statistics encyclopedia worked out). 

Once you've been in the game for a while, you realize that it is
extremely important to make documentation *writable*. Only if you have
rather fixed rules for what needs to be documented, and some minimum
standards for what must be in the documentation, then there is a
reasonable chance that things will actually be written down. So the
developers tend to be looking for structural ways of improving the
documentation system, and some new ideas are currently being explored
(have a look at Sweave when 1.5.0 comes out at the end of this month).

And don't be mistaken: The documentation level of R is already much
higher than average for open source software and even than some
commercial packages (esp. SPSS is notorious for its attitude of "You
want to do one of these things. If you don't understand what the
output means, click help and we'll pop up five lines of mumbo-jumbo
that you're not going to understand either.")

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Apr  2 17:58:35 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 02 Apr 2002 17:58:35 +0200
Subject: AW: Re: [R] "Large" data set: performance issue
In-Reply-To: <3C97A93300008C99@mail.epost.de>
References: <3C97A93300008C99@mail.epost.de>
Message-ID: <x2ofh2gkic.fsf@blueberry.kubism.ku.dk>

Till Baumgaertel <till.baumgaertel at epost.de> writes:
datfull <- read.csv
> >What happens if you try this?:
> >
> >datfull <- read.csv("foo", colClasses=rep(c("character","numeric"),c(22,1801)))
> 
> nope, sorry. it's not working.
> it complains about the following:
> ####
> Error in scan(file = file, what = what, sep = sep, quote = quote, dec =
> dec,  : 
>         "scan" expected a real, got ""+1073741824""
> ####
> 
> ok, i forgot to tell you my numbers are just like the characters quoted
> ("\""). sorry!
> 
> therefore i tried
> ###
> datfull <- read.csv2(file.choose(), colClasses=rep(c("character","numeric"),c(22,1801)),quote="\"",sep=",")
> ###
> 
> But it's still not working.
> 
> it seems to be critical to do the translation of character ("+1234") to
> numeric(1234.0) AFTER the file was totally read into (any kind of?) a data
> structure. 

Hum. I wonder whether that quoting behaviour is really as intended.
You might try this

library(methods)
setAs("character","num", function(from)as.numeric(from))
datfull <- read.csv(file.choose(), 
    colClasses=rep(c("character","num"), c(22,1801)))


Otherwise, try something like

datfull <- read.csv(file.choose(),colClasses="character")
datfull[-(1:22)] <- lapply(datfull[-(1:22)], as.numeric)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lukas.kubin at permonik.com  Tue Apr  2 17:04:51 2002
From: lukas.kubin at permonik.com (Lukas Kubin)
Date: Tue, 2 Apr 2002 17:04:51 +0200 (CEST)
Subject: [R] A Few Suggestions to help out newbies
In-Reply-To: <20020402065142.A11737@cattell.psych.upenn.edu>
Message-ID: <Pine.LNX.4.33.0204021656410.2415-100000@x.opf.slu.cz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On Tue, 2 Apr 2002, Jonathan Baron wrote:

> >8) Command completion and contextual help in R.  The first one is
> >probably fairly easy.  The second one is probably impossible.  It would
> >involve giving out detailed help messages when things go wrong.  Not
> >sure how to do that.
>
> Doesn't ESS do this?

Isn't this too automatical answer? I don't use Emacs and believe I'm not
the only. But it is not the core problem. Why to connect as important
basic (in my opinion) interface feature as command completion (at least)
is with using a special text editor? In Octave, database interfaces and
others command completion is a standard. So what's the reason not to
include it in R?

lukas

- -- 
Lukas Kubin
lukas.kubin at permonik.com
phone: 00420603836180
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.0.5 (GNU/Linux)
Comment: Made with pgp4pine 1.75-6

iD8DBQE8qciY4TIZ2lmUAtsRAkH2AJ9/AFgD1lbCSNyxlV/2KO/pQYUFkwCfdcWq
lN/IvP8BdjHgd0dnAl53o3c=
=bN+L
-----END PGP SIGNATURE-----


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lukas.kubin at permonik.com  Tue Apr  2 17:04:51 2002
From: lukas.kubin at permonik.com (Lukas Kubin)
Date: Tue, 2 Apr 2002 17:04:51 +0200 (CEST)
Subject: [R] A Few Suggestions to help out newbies
In-Reply-To: <20020402065142.A11737@cattell.psych.upenn.edu>
Message-ID: <Pine.LNX.4.33.0204021656410.2415-100000@x.opf.slu.cz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On Tue, 2 Apr 2002, Jonathan Baron wrote:

> >8) Command completion and contextual help in R.  The first one is
> >probably fairly easy.  The second one is probably impossible.  It would
> >involve giving out detailed help messages when things go wrong.  Not
> >sure how to do that.
>
> Doesn't ESS do this?

Isn't this too automatical answer? I don't use Emacs and believe I'm not
the only. But it is not the core problem. Why to connect as important
basic (in my opinion) interface feature as command completion (at least)
is with using a special text editor? In Octave, database interfaces and
others command completion is a standard. So what's the reason not to
include it in R?

lukas

- -- 
Lukas Kubin
lukas.kubin at permonik.com
phone: 00420603836180
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.0.5 (GNU/Linux)
Comment: Made with pgp4pine 1.75-6

iD8DBQE8qciY4TIZ2lmUAtsRAkH2AJ9/AFgD1lbCSNyxlV/2KO/pQYUFkwCfdcWq
lN/IvP8BdjHgd0dnAl53o3c=
=bN+L
-----END PGP SIGNATURE-----


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Tue Apr  2 18:26:29 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 2 Apr 2002 18:26:29 +0200
Subject: [R] Doubled and delayed message(s) on R-help
In-Reply-To: <Pine.LNX.4.33.0204021656410.2415-100000@x.opf.slu.cz>
References: <20020402065142.A11737@cattell.psych.upenn.edu>
	<Pine.LNX.4.33.0204021656410.2415-100000@x.opf.slu.cz>
Message-ID: <15529.56245.911888.720829@gargle.gargle.HOWL>

Accidentally,
Lukas message was finally sent twice to the mailing list.
My fault. 
I'm experimenting with new anti-spam filters and unfortunately,
the line
    `-----BEGIN PGP SIGNED MESSAGE-----'
lead to a false alarm, i.e. bounce.
These I have to approve manually; accidentally, I did this
twice.

The reason for the current message is just to avert you of the
problem.  Whenever the anti-spam filters catch a message
accidentally, I have to approve it manually -- and this only
happens when I'm reading e-mail myself -- hence you have
sometimes long delays (that you can reconstruct partially
looking at the message's "Received:" headers).

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Tue Apr  2 18:28:06 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 2 Apr 2002 08:28:06 -0800 (PST)
Subject: [R] A request
In-Reply-To: <MABBJPBLPNLDIFMIAAOJMEAKCFAA.indra_calisto@yahoo.com>
Message-ID: <Pine.A41.4.44.0204020820090.209546-100000@homer06.u.washington.edu>

On Tue, 2 Apr 2002, Indrajit SenGupta wrote:

> Can we expect to see an R package on Statistical Quality Control in the
> future like SPLUS? I can't understand why nobody made this package before.
>

There are some of these features in the strucchange package.  You can
often find this sort of thing out by using Jonathan Baron's search site,
which is linked from R homepage. (I searched on `process control',
which didn't work, and on `CUSUM', which did.)

This probably doesn't have everything you want, but it might.

The reason you got some less than helpful responses might well be the `I
can't understand...' comment.  The usual reason that R doesn't have a
particular feature is that no-one who needs that feature in their everyday
work contributes to R.

R has some features that are there because they are important for
completeness, but it is quite heavily biased towards things that the users
and developers actually do.  Someone who doesn't routinely do statistical
process control is less likely to implement it in R (and less likely to do
a good job of implementing it if they do).


	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Tue Apr  2 18:31:08 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 2 Apr 2002 08:31:08 -0800 (PST)
Subject: Finding code (was: [R] A request)
In-Reply-To: <200204021111.g32BBQg10022@wn1.sci.kun.nl>
Message-ID: <Pine.A41.4.44.0204020830070.209546-100000@homer06.u.washington.edu>

On Tue, 2 Apr 2002, E.L. Willighagen wrote:

>
> Indeed. A "Search" link under "Documentation" on www.r-projects.org itself
> pointing to it would be nice. Who is the person to ask for this?
>

There *is* a Search link under "R-project" on www.r-project.org

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From till.baumgaertel at epost.de  Tue Apr  2 18:43:39 2002
From: till.baumgaertel at epost.de (=?ISO-8859-1?Q?Till=20Baumgaertel?=)
Date: Tue, 2 Apr 2002 18:43:39 +0200
Subject: [R] =?ISO-8859-1?Q?solved=20elegantly=21=20Was=3A=20=22Large=22=20data=20set=3A=20performance=20issue?=
In-Reply-To: <x2ofh2gkic.fsf@blueberry.kubism.ku.dk>
Message-ID: <3C97A93300008D69@mail.epost.de>

>library(methods)
>setAs("character","num", function(from)as.numeric(from))
>datfull <- read.csv(file.choose(), 
>    colClasses=rep(c("character","num"), c(22,1801)))
WOW! now, this helps!!

thank you, excellent performance!
import took quite excactly 50 sec!

i am **very** impressed!

also i'm glad that i asked, because all of your hints gave me some deeper
insights of the R-syntax.

thank you very much!!
till




________________________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deleeuw at stat.ucla.edu  Tue Apr  2 18:46:38 2002
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Tue, 2 Apr 2002 08:46:38 -0800
Subject: [R] A Few Suggestions to help out newbies
In-Reply-To: <1017746894.11200.53.camel@workhorse.killnine.net>
Message-ID: <33D04496-4659-11D6-A9DC-000393860F3C@stat.ucla.edu>

The JSS editorial board is considering a  JSS section "R Snippets",
possibly edited by our editors Kurt Hornik and Roger Koenker,
which will have "interesting pieces of R code", with only a
minimal amount of text /comments. Reactions ?

JSS is at http://www.jstatsoft.org

--- Jan

On Tuesday, April 2, 2002, at 03:28 AM, Zed Shaw wrote:

> 1)  An R Cookbook section of the site where people can submit pieces of
> interesting code that satisfies a need.  This would be similar to the
> Perl/Python/Java Cookbook texts that O'Reilly puts out, but with a more
> dynamic activity.  The python folks have something like this, and people
> love it.  I learned a lot of python this way.
>
===
Jan de Leeuw; Professor and Chair, UCLA Department of Statistics;
US mail: 9432 Boelter Hall, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
homepage: http://www.stat.ucla.edu/~deleeuw
========================================================
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://www.stat.ucla.edu/~deleeuw/sounds/nomatter.au
========================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Tue Apr  2 18:58:32 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 2 Apr 2002 08:58:32 -0800 (PST)
Subject: [R] A Few Suggestions to help out newbies
In-Reply-To: <Pine.LNX.4.33.0204021656410.2415-100000@x.opf.slu.cz>
Message-ID: <Pine.A41.4.44.0204020845190.209546-100000@homer06.u.washington.edu>

On Tue, 2 Apr 2002, Lukas Kubin wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On Tue, 2 Apr 2002, Jonathan Baron wrote:
>
> > >8) Command completion and contextual help in R.  The first one is
> > >probably fairly easy.  The second one is probably impossible.  It would
> > >involve giving out detailed help messages when things go wrong.  Not
> > >sure how to do that.
> >
> > Doesn't ESS do this?
>
> Isn't this too automatical answer? I don't use Emacs and believe I'm not
> the only. But it is not the core problem. Why to connect as important
> basic (in my opinion) interface feature as command completion (at least)
> is with using a special text editor? In Octave, database interfaces and
> others command completion is a standard. So what's the reason not to
> include it in R?

This could presumably be done with the readline interface, though that
currently does filename completion, which I think is more useful.  There
would be no reason not to include it in R if the code existed (and was
portable and didn't mess up other things).

However, ESS almost certainly is the *reason* that there isn't command
completion in R. Since most R developers and many users run R under ESS
there is little motivation for duplicating features of ESS in R. It's
much easier to learn Emacs/ESS than to write command completion code.

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Tue Apr  2 19:01:44 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 02 Apr 2002 12:01:44 -0500
Subject: [R] A Few Suggestions to help out newbies
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC18F@usrymx10.merck.com>

> From: Lukas Kubin [mailto:lukas.kubin at permonik.com]
> On Tue, 2 Apr 2002, Jonathan Baron wrote:
> 
> > >8) Command completion and contextual help in R.  The first one is
> > >probably fairly easy.  The second one is probably 
> impossible.  It would
> > >involve giving out detailed help messages when things go 
> wrong.  Not
> > >sure how to do that.
> >
> > Doesn't ESS do this?
> 
> Isn't this too automatical answer? I don't use Emacs and 
> believe I'm not
> the only. But it is not the core problem. Why to connect as important
> basic (in my opinion) interface feature as command completion 
> (at least)
> is with using a special text editor? In Octave, database 
> interfaces and
> others command completion is a standard. So what's the reason not to
> include it in R?

Well, as Thomas Lumley said in the other message, because no one who wants
it bad enough had *contributed* the code.  Many things in Open Source
projects such as R get done because some users wanted them bad enough that
they wrote the code, and then contributed to the project.  Just think about
it, how many people have the motivation to write and contribute code that
they don't need themselves, just to please some people who do nothing but
complain?

Andy


> lukas
> - -- 
> Lukas Kubin
> lukas.kubin at permonik.com
> phone: 00420603836180
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.0.5 (GNU/Linux)
> Comment: Made with pgp4pine 1.75-6
> 
> iD8DBQE8qciY4TIZ2lmUAtsRAkH2AJ9/AFgD1lbCSNyxlV/2KO/pQYUFkwCfdcWq
> lN/IvP8BdjHgd0dnAl53o3c=
> =bN+L
> -----END PGP SIGNATURE-----
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named in this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Tue Apr  2 19:44:07 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 2 Apr 2002 09:44:07 -0800 (PST)
Subject: [R] Two R sessions?
In-Reply-To: <3CA91FA7.A7A202F7@math.mun.ca>
Message-ID: <Pine.A41.4.44.0204020936410.209546-100000@homer06.u.washington.edu>

On Mon, 1 Apr 2002, Paul Y. Peng wrote:

> Hi R users,
>
> I am still a relatively new R user migrated from S+. I wonder in R
> how do you handle one difference between R and S+. S+ saves objects
> as different files in .Data directory while R saves all objects in
> a big file .RData. In S+, I can start two S+ sessions from the same
> directory and work simultaneously as long as new objects in the two
> sessions are not in the same names. This is particularly useful in
> simulation studies. However, this method fails for R. I am curious
> how other R users handle this thing in R. Naively, I can copy .Rdata
> into another directory and then start another R session there. When
> the job is done, dump all new objects in one .Rdata into the other
> .Rdata. But maybe someone has a better way to do it.

You can save the workspace to a file with a different name using the
save.image() function.  That way you could have oneproject.rdata,
and anotherproject.rdata holding the two sets of data. You could also have
a third file with objects you wanted to use in more than one project, say
commonobjects.rdata.

You might then do

R> load("oneproject.rdata")
R> attach("commonobjects.rdata")
R>  work, work, work
R> save.image("oneproject.rdata")
R> q("no")

so that the common objects aren't saved into "oneproject.rdata" but the
rest of your work is.

> BTW, why does R save objects in one big file rather than as different
> files in a directory as S+ does?
>

Partly because it's harder to separate objects in R.  The fact that
functions and model formulas have attached environments means that you may
have to keep quite large collections of objects together in an R file.

I actually think it's easier to keep track of things the R way -- you
decide when things go in the same file, whereas with S-PLUS it depends on
what your working directory happens to be. This might just indicate
successful brainwashing, though.

	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brad at aris.ss.uci.edu  Tue Apr  2 20:11:46 2002
From: brad at aris.ss.uci.edu (Brad Buchsbaum)
Date: Tue, 2 Apr 2002 10:11:46 -0800 (PST)
Subject: [R] Re: variable argument lists
In-Reply-To: <031b01c1da5a$d2ce93f0$557c6686@tating>
Message-ID: <Pine.LNX.4.44.0204021002230.8224-100000@sebring.ss.uci.edu>


Hi,

Is it possible to make a function treat an R list as if it were a sequence
arguments?

For instance, the "order" function has a variable length argument list.
So one could do: x <- order(a,b)

Suppose one does not know in advance the number of arguments to the order
function and those arguments are stored in a list.

e.g. x <-  list(a,b,c)


How would one go about ordering the list of vectors contained in x
(with b, c, etc. representing "tie-breaking" vectors for the order
function).

thanks for any help on this.

Brad Buchsbaum


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Tue Apr  2 20:30:11 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 2 Apr 2002 10:30:11 -0800 (PST)
Subject: [R] Re: variable argument lists
In-Reply-To: <Pine.LNX.4.44.0204021002230.8224-100000@sebring.ss.uci.edu>
Message-ID: <Pine.A41.4.44.0204021029331.209546-100000@homer06.u.washington.edu>

On Tue, 2 Apr 2002, Brad Buchsbaum wrote:

>
> Suppose one does not know in advance the number of arguments to the order
> function and those arguments are stored in a list.
>
> e.g. x <-  list(a,b,c)
>
>
> How would one go about ordering the list of vectors contained in x
> (with b, c, etc. representing "tie-breaking" vectors for the order
> function).

do.call("order",x)

	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr  2 21:00:27 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 2 Apr 2002 20:00:27 +0100 (BST)
Subject: [R] Re: variable argument lists
In-Reply-To: <Pine.LNX.4.44.0204021002230.8224-100000@sebring.ss.uci.edu>
Message-ID: <Pine.LNX.4.31.0204021956080.2579-100000@gannet.stats>

See

?do.call

It's a very powerful device, and in some places known as `Bill Venables'
favorite function' (the spelling is a clue) which given Bill's status (not
least as the editor of R-news `Programmer's Niche') tells you all you need
to know.

On Tue, 2 Apr 2002, Brad Buchsbaum wrote:

> Is it possible to make a function treat an R list as if it were a sequence
> arguments?
>
> For instance, the "order" function has a variable length argument list.
> So one could do: x <- order(a,b)
>
> Suppose one does not know in advance the number of arguments to the order
> function and those arguments are stored in a list.
>
> e.g. x <-  list(a,b,c)
>
>
> How would one go about ordering the list of vectors contained in x
> (with b, c, etc. representing "tie-breaking" vectors for the order
> function).
>
> thanks for any help on this.
>
> Brad Buchsbaum
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maj at waikato.ac.nz  Tue Apr  2 20:58:51 2002
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Wed, 03 Apr 2002 06:58:51 +1200
Subject: [R] Extract psuedo model matrix from nls?
Message-ID: <4.3.2.7.0.20020403065440.01e7fef8@mail.stats.waikato.ac.nz>

Hi R-list,

I'd like to extract the psuedo model matrix (derivative of fitted values 
wrt the parameters) from an nls object.

Any suggestions?

Thanks,

Murray Jorgensen


Dr Murray Jorgensen               on leave from:
Mathematics and Statistics       Department of Statistics
University of Victoria           University of Waikato
PO BOX 3045 STN CSC              Hamilton, New Zealand
Victoria, B.C.      Email: maj at waikato.ac.nz
Canada V8W 3P4      Phone: (250) 721-7460 wk  (250) 477 2581 home

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From olivier.martin at inrialpes.fr  Wed Apr  3 04:32:03 2002
From: olivier.martin at inrialpes.fr (Olivier Martin)
Date: Wed, 03 Apr 2002 04:32:03 +0200
Subject: [R] help on lme and variance estimation
Message-ID: <3CAA69A3.2040807@inrialpes.fr>

Hi all,

I have a random effect model that can be written as

y_{ij} = \beta +\alpha_i+ \epslion_{ij}

where \alpha_i ~ N(0,\sigma^2_effect) and \espilon_{ij} ~ 
N(0,\sigma^2_error)

and i compute

res<-lme(data~1,data=Data,random=~1 | veci)

The estimation of \sigma_error is given by res$sigma  but
I don't understand how i can find the estimation of \sigma _effect  with 
the object res
(I would like to have access to the value of the estimation and not 
print the result by using summary(res) or print(res) )

Could you help me ?

Best regards

-- 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
Olivier MARTIN
PhD student                  phone : (33) 04 76 61 53 55
Projet IS2                               06 08 67 93 42		
INRIA Rhone-Alpes            fax   : (33) 04 76 61 54 77
655, Av. de l'Europe
Montbonnot                   e-mail: olivier.martin at inrialpes.fr
38334 Saint Ismier cedex     web   : http://www.inrialpes.fr/is2/people/omartin
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hodgess at uhddx01.dt.uh.edu  Tue Apr  2 22:53:36 2002
From: hodgess at uhddx01.dt.uh.edu (Erin Hodgess)
Date: Tue, 2 Apr 2002 14:53:36 -0600 (CST)
Subject: [R] predict with arima0
Message-ID: <200204022053.OAA14429@uhddx01.dt.uh.edu>

Dear R People:

I'm trying to use the predict command on an arima0 object.

I do the following:

xm.arma <- arima0(xm2,order=c(1,0,1))
predict(xm.arma,n.ahead=2)

and I get the message:
Error in round(x, digits) : Non-numeric argument to mathematical function


Any ideas what the problem might be, please?

R version 1 4 1 on Windows.

Thanks in advance!

Sincerely,
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
1 Main Street 
Houston, TX 77002
mailto: hodgess at uhddx01.dt.uh.edu
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ggrothendieck at yifan.net  Tue Apr  2 23:01:29 2002
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Tue, 2 Apr 2002 16:01:29 -0500
Subject: [R] A Few Suggestions to help out newbies
In-Reply-To: <51F9C42DA15CD311BD220008C707D81906FFC18F@usrymx10.merck.com>
Message-ID: <3CA9D5D9.20086.664264F@localhost>

On 2 Apr 2002 at 12:01, Liaw, Andy wrote:
> Well, as Thomas Lumley said in the other message, because no one who wants
> it bad enough had *contributed* the code.  Many things in Open Source
> projects such as R get done because some users wanted them bad enough that
> they wrote the code, and then contributed to the project.  Just think about
> it, how many people have the motivation to write and contribute code that
> they don't need themselves, just to please some people who do nothing but
> complain?

We need to be careful here.  Its an advantage to have user feedback and it
should never be viewed as complaints.  Without such feedback, how 
else can one know what people find easy and difficult and what they view 
as needed?   

Providing personal requirements and wish list items and telling others what they 
find easy and difficult contributes to development just as much as programming 
and design does. The entire process is a feedback loop and the loop is not closed
unless all the links are in place.

Since many people in the R community likely work in academia let me drraw a
parallel in that world.  A course which has been given multiple times is generally
better than one given the first time since on subsequent rounds one can focus better
on those items that students had difficulty with in prior rounds.  Knowing the material is 
different from knowing what material the students find difficult.  This feedback from 
user to developer/teacher is crucial.   The same goes with text books.  If you can find 
one that has been student tested its often more useful than one that has not.

It has been said that the key difference between Open Source projects and commercial 
projects is not just that the commercial packages cost money but 
that the commercial developers listen to their users better than Open Source
developers do. (I am not saying that R developers don't listen, I am just
bringing out this view of Open Source vs. Commerical, in general).   If commercial developers 
don't listen to their users then they don't stay in business very long!   

Its worthwhile for Open Source projects to set up some sort of analogous dynamic as well.
In the case of the R, the R Help list is an integral part of R since it provides some of this 
needed feedback.  

Another thing that would be nice would be some sort of organized wish 
list / requirements. This already exists to some degree (see the NEWS files 
at http://stat.ethz.ch/R-alpha/ ).   However, it might be nice to give this aspect
better prominence and provide a mechanism for the large community focused
on R to provide this feedback.

This would be helpful since anyone who wished to contribute would then have 
a framework for understanding what is needed.  


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Wed Apr  3 00:12:48 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 02 Apr 2002 16:12:48 -0600
Subject: [R] Extract psuedo model matrix from nls?
In-Reply-To: <4.3.2.7.0.20020403065440.01e7fef8@mail.stats.waikato.ac.nz>
References: <4.3.2.7.0.20020403065440.01e7fef8@mail.stats.waikato.ac.nz>
Message-ID: <6r7knp697j.fsf@franz.stat.wisc.edu>

Murray Jorgensen <maj at waikato.ac.nz> writes:

> Hi R-list,
> 
> I'd like to extract the psuedo model matrix (derivative of fitted
> values wrt the parameters) from an nls object.
> 
> Any suggestions?

The short answer is fm$m$gradient() when your fitted nls model is
called fm.

The longer answer is that the component m in a fitted nls model object
is a list of functions that share a function closure.  The function
closure contains the data and other information about the fit.  One of
those functions is called gradient.  Calling that function either
returns the precalculated gradient or, if necessary, evaluates and
returns the gradient.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Apr  3 00:50:49 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 03 Apr 2002 00:50:49 +0200
Subject: [R] A Few Suggestions to help out newbies
In-Reply-To: <3CA9D5D9.20086.664264F@localhost>
References: <3CA9D5D9.20086.664264F@localhost>
Message-ID: <x21ydxhfzq.fsf@blueberry.kubism.ku.dk>

ggrothendieck at yifan.net writes:

> It has been said that the key difference between Open Source
> projects and commercial projects is not just that the commercial
> packages cost money but that the commercial developers listen to
> their users better than Open Source developers do. (I am not saying
> that R developers don't listen, I am just bringing out this view of
> Open Source vs. Commerical, in general). If commercial developers
> don't listen to their users then they don't stay in business very
> long!

Sorry, but this is just plain wrong. The main difference is that Open
Source people try to get it right, commercial entities try to get it
sold. There are plenty of examples where user feedback and wishes have
been very long in finding their way into commercial software (much of
the early free software came out of Unix environments where
development was stalled because they were tied to an AT&T codebase
that noone had the capacity to start improving upon). Even more often,
you'll find that features in commercial software get added after some
sort of market analysis and then a targeted effort is made or
contracted to supply what is *perceived* to be user requirements. Not
always with fortunate results.

I'm not saying that user input isn't useful, but it is not always that
simple to respond to it. Apart from the basic issue of manpower, it is
also a question of analyzing the subject matter to an extent where you
can see what kind of code makes sense and which does not. If wishes
start taking on a tone of demand, with nothing offered in return, they
tend to get overheard or become the target of sarcasm. Notice however,
that the sarcasm has a component of sincerity: R is a programming
language; it should not be beyond the capacity of experienced users to
develop simple functions to perform tasks in their subject area. If
people don't realize that then maybe it's about time?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Richard.Rowe at jcu.edu.au  Wed Apr  3 01:38:30 2002
From: Richard.Rowe at jcu.edu.au (Richard Rowe)
Date: Wed, 03 Apr 2002 09:38:30 +1000
Subject: [R] A Few Suggestions to help out newbies
In-Reply-To: <x2sn6eglka.fsf@blueberry.kubism.ku.dk>
References: <20020402141056.GD17964@giraffa.cbs.dtu.dk>
 <MABBJPBLPNLDIFMIAAOJMEAKCFAA.indra_calisto@yahoo.com>
 <3CA95D5B.353C470@statistik.uni-dortmund.de>
 <1017742502.12802.17.camel@workhorse.killnine.net>
 <3CA98528.FA3E7011@statistik.uni-dortmund.de>
 <1017746894.11200.53.camel@workhorse.killnine. <20020402141056.GD17964@giraffa.cbs.dtu.dk>
Message-ID: <5.0.0.25.1.20020403092948.030da250@pop.jcu.edu.au>


>
> > > 6)  Better layout of packages listed on CRAN.  This listing format will
> > > collapse under its own weight once it gets too large.
> >
> >
> > Memory has become more expensive over the last few months but displaying a
> > html document that weights even few hundred kilobytes remains a reasonable
> > assumption (the document is currently 164 kb).
>
>Yes, but I think Zed meant that it needs some kind of superstructure
>or keyword system attached. Could be true but someone need to invent
>the structure or keyword set...


I've been thinking about this as I've found (or been referred to) useful 
packages with names that didn't click during a scan down the list.    What 
about moving to a naming convention where the first two letters of a 
package name reflect its broad category.  Most spatial stats packages 
already begin with 'sp', but some which are of great use don't; 'ts' starts 
the time series packages ... I recognise that economics and ecology 
packages will clash, but it should be possible to get around that.  Anyway, 
just a thought,

Richard



Richard Rowe
Senior Lecturer
Department of Zoology and Tropical Ecology, James Cook University
Townsville, Queensland 4811, Australia
fax (61)7 47 25 1570
phone (61)7 47 81 4851
e-mail: Richard.Rowe at jcu.edu.au
http://www.jcu.edu.au/school/tbiol/zoology/homepage.html

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dstierman at micron.com  Wed Apr  3 01:51:48 2002
From: dstierman at micron.com (dstierman)
Date: Tue, 2 Apr 2002 16:51:48 -0700 
Subject: [R] Trouble with R and cronjobs
Message-ID: <CFEFA50C9BCAD21197470001FA7EBA6B0DECF10A@ntexchange05.micron.com>

I am having problems with trying to run R from a crontab job. I have a
c-shell file that calls the R script. I get an error concerning the X11
display (see below). I have included the c-shell file and the output from
the crontab job. It appears that my DISPLAY environmental variable is not
set. Is that necessary, even when the output of the plot command is to a png
file? Can someone tell me how to fix this?
Thanks, Don

C-SHELL FILE:

#!/usr/bin/csh
source /u/dstierma/.cshrc
env
# /u/dstierma/bin/prbdata_bylot.pl
# /u/pesoft/bin/psums -lotlist -fab=3 -dbase=Y16A -30 >!
/u1yedh2/dstierma/probe/corr/Y16A.30
# /u/pesoft/bin/fabx @/u1yedh2/dstierma/probe/corr/Y16A.30 -fxt -sep='_'
-step=/3010-50 DUV PHOTO/ -ci~/%MACHINE%/ -exceldate -csv >!
/u1yedh2/dstierma/probe/corr/50duv.fxt
# /u/dstierma/bin/mergecsv2.pl 7 /u1yedh2/dstierma/probe/corr/50duv.fxt
/u1yedh2/dstierma/probe/corr/Y16A_scat.txt
# /usr/bin/cp merge.csv /u1yedh2/dstierma/probe/corr/y16a.txt
/usr/micron/sun4-sunos5.4/bin/R --no-save < /u/dstierma/bin/y16a_scat2.r

CRONTAB JOB OUTPUT:

Your "cron" job on unix1
/u/generic/bin/50duv.csh

produced the following output:

HOME=/u/dstierma
LOGNAME=dstierma
PATH=/usr/openwin/bin:/usr/openwin/bin/xview:/usr/X11/bin:/usr/openwin/demo:
/usr/openwin/demo/xview:/usr/micron/sun4/bin/xview:/usr/micron/sun4-sunos5.4
/bin/:/u/dstierma/bin:/u/dstierma/scripts:/usr/micron/sun4/bin:/usr/micron/b
in:/u/pesoft/bin:/u/test2end/bin:/u/summary/bin:/usr/local/bin:/usr/ucb:/usr
/bin:/bin:/u1yedh2/ye/cgi-bin:/amd/pefs2-f0/u7pefs2/dstierman/bin:/usr/micro
n/sun4-sunos5.5.1/bin:/u1yedh2/dstierma/bin:/u1yedh2/dstierma/cgi-bin:/u/kma
jor/programs:/etc:/usr/etc:/u1yedh2/ye/docs/java/graph/classes:/usr/5bin:/op
t/gnu/bin:/opt/gnu/sparc-sun-solaris2.6/bin:.:/vol/rs1/r5.3/rs1r5/sun4/bin/:
/vol/rs1/r5.3/rs1r5/solaris/bin/:/u/prbsoft/bin:/u/chirst/perl:/u/dstierma/b
in/ps2html:/u/pesoft/bin/proddram:/u/pesoft/bin/perl:/u/dstierma/bin/html2ps
-1.0b1:/u/fabya/bin:/usr/ccs/bin:/usr/newsprint/bin:/u1yedh2/dstierma/bin
SHELL=/usr/bin/sh
TZ=US/Mountain
PWD=/amd/pesfs2/u2pesfs2/dstierman
USER=dstierma
LD_LIBRARY_PATH=/u1yedh2/dstierma/lib:/u1yedh2/dstierma/lib/esda/lib:/u1yedh
2/dstierma/lib/oracle/product/8.0.5/lib:/u1yedh2/dstierma/lib/IXImotif/lib:/
u1yedh2/dstierma/lib/orbix/home/lib:/u1yedh2/dstierma/lib/esda/lib/IXI:/usr/
openwin/lib:/usr/X11/lib:/usr/lib/X11:/usr/micron/sun4-sunos5.6/lib
OPENWINHOME=/usr/openwin
PGPLOT_FONT=/usr/micron/sun4-sunos5.5.1/lib/pgplot/grfont.dat
ESDA_DIR=/u1yedh2/dstierma/bin/esda
LM_LICENSE_FILE=/u/dstierma/licenses/LIC_ESDA
HOST=yedh2
EXINIT=set redraw autoindent showmatch nowrapscan tabstop=8 shiftwidth=8

R : Copyright 2002, The R Development Core Team
Version 1.4.1  (2002-01-30)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type `license()' or `licence()' for distribution details.

R is a collaborative project with many contributors.
Type `contributors()' for more information.

Type `demo()' for some demos, `help()' for on-line help, or
`help.start()' for a HTML browser interface to help.
Type `q()' to quit R.

R is cool-> data<-read.csv("/u1yedh2/dstierma/probe/corr/y16a.txt")
R is cool-> cnames<-colnames(data)          # list of all the column names
in dataset
R is cool-> ncols<-length(cnames)           # number of columns in dataset
R is cool-> z<-as.vector(data$X3010.50DUVPHOTO.MACHINEPD.1)
R is cool-> x<-as.vector(data$X3010.50DUVPHOTO.DATE.0)
R is cool-> time<-strptime(x,"%d %b %Y %H:%M")
R is cool-> data$X3010.50DUVPHOTO.DATE.0<-as.POSIXct(time)
R is cool-> for(i in 9:dim(data)[2]) {      # number of columns of data
(data[1] is number of rows)
+	    y<-as.vector(data[cnames[i]])   
+	    an<-anova(lm(data[[cnames[i]]] ~
data$X3010.50DUVPHOTO.MACHINEPD.1))
+
png(file=paste("/u1yedh2/dstierma/probe/corr/Y16A_",cnames[i],".png",sep="")
, width=800, height=400, bg="white")
+	    par(las=c(2))
+	    par(oma=c(4,4,.2,.2))
+	    plot(data[[cnames[i]]] ~ data$X3010.50DUVPHOTO.DATE.0,xlab="\n50
DUV
Date",ylab=cnames[i],col=palette()[(as.numeric(factor(data$X3010.50DUVPHOTO.
MACHINEPD.1))%%6)+1],pch=((as.numeric(factor(data$X3010.50DUVPHOTO.MACHINEPD
.1))%%17)+1))
+	    par(las=c(1))
+	    title("Y16A DUV vs SCAT")
+
mtext(cnames[i],side=3,line=0,outer=TRUE,at=NA,adj=NA,cex=NA,col=1,font=NA)
+
legend.mar(legend=levels(factor(data$X3010.50DUVPHOTO.MACHINEPD.1)),col=pale
tte()[(1:length(levels(factor(data$X3010.50DUVPHOTO.MACHINEPD.1)))%%6)+1],pc
h=(1:length(levels(factor(data$X3010.50DUVPHOTO.MACHINEPD.1)))%%17)+1)
+	    zm<-tapply(data[[cnames[i]]], data$X3010.50DUVPHOTO.MACHINEPD.1,
mean)
+	    zmd<-tapply(data[[cnames[i]]],
data$X3010.50DUVPHOTO.MACHINEPD.1, median)
+	    zc<-table(data$X3010.50DUVPHOTO.MACHINEPD.1)
+	    mtext("P-val",1, outer=TRUE,adj = -0.08)
+	    mtext(round(an[1,5],digits=3),1, line=1, col="red",
outer=TRUE,adj = -0.08)
+	    mtext("X3010.50DUVPHOTO.MACHINEPD.1",1, line=-1,outer=TRUE, adj=
0)
+	    mtext("MEAN",1, line=1, outer=TRUE, adj= 0)
+	    mtext("MEDIAN",1, line=2, outer=TRUE, adj= 0)
+	    mtext("COUNT",1, line=3, outer=TRUE, adj= 0)
+	    for(a in 1:length(zm)) {
+	          mtext(labels(zm[a]),1, outer=TRUE, adj= a/10)
+	          mtext(round(zm[a],digits=2),1, line=1, outer=TRUE, adj=
a/10)
+	          mtext(round(zmd[a],digits=2),1, line=2, outer=TRUE, adj=
a/10)
+	          mtext(zc[a],1, line=3, outer=TRUE, adj= a/10)
+	      }
+	
+	}
Error in X11(paste("png::", filename, sep = ""), width, height, pointsize,
: 
	unable to start device PNG
In addition: Warning message: 
unable to open connection to X11 display`' 
Execution halted


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From edd at debian.org  Wed Apr  3 03:46:46 2002
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 2 Apr 2002 19:46:46 -0600
Subject: [R] Trouble with R and cronjobs
In-Reply-To: <CFEFA50C9BCAD21197470001FA7EBA6B0DECF10A@ntexchange05.micron.com>
References: <CFEFA50C9BCAD21197470001FA7EBA6B0DECF10A@ntexchange05.micron.com>
Message-ID: <20020403014646.GA15414@sonny.eddelbuettel.com>

On Tue, Apr 02, 2002 at 04:51:48PM -0700, dstierman wrote:
> I am having problems with trying to run R from a crontab job. I have a
[...]
> unable to open connection to X11 display`' 
> Execution halted

Known issue that x11() needs an actual display and is therefore unavailable
during cronjobs. There are several workarounds. IIRC both bitmap() and
dev2bitmap() should work but I haven't had to do this in a while...

Hth, Dirk

-- 
Good judgement comes from experience; experience comes from bad judgement. 
							    -- Fred Brooks
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ypeng at math.mun.ca  Wed Apr  3 04:26:19 2002
From: ypeng at math.mun.ca (Paul Y. Peng)
Date: Tue, 02 Apr 2002 22:56:19 -0330
Subject: [R] Two R sessions? Solved. Thanks.
References: <3CA91FA7.A7A202F7@math.mun.ca> <15529.28794.934561.402835@gargle.gargle.HOWL>
Message-ID: <3CAA684B.BAE7906C@math.mun.ca>

Many thanks to Jason Turner, Martin Maechler and Thomas Lumley.
They all pointed to save.image(), which is really what I am after.
Sorry for my ignorant. Before I posted my question, I did checked
the help page of q() and the manual "An Introduction to R", "R
Language Definition" etc. Unfortunately none of them mentions
save.image(). However, I am glad that my intuition is right and
that R has a nice way to manage objects. Thanks for help.

Paul.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From j_turner at ihug.co.nz  Wed Apr  3 04:53:05 2002
From: j_turner at ihug.co.nz (j_turner@ihug.co.nz)
Date: Wed, 3 Apr 2002 02:53:05 GMT
Subject: [R] Trouble with R and cronjobs
Message-ID: <200204030258.OAA17986@smtp1.ihug.co.nz>

<dstierman <dstierman at micron.com> on April 3 said...>
> It appears that my DISPLAY environmental variable is not
> set. Is that necessary, even when the output of the plot command is to a png
> file?

Yes.  And No.

Yes:
A running X server is absolutely necessary for the png() command.  If X isn't 
running, you get no png().  No jpeg(), either, for that matter.  help(png) 
states:
--
These devices [png, jpeg] effectively plot on a hidden screen and then copy
the image to the required format.
--
In other words, they do their own (hidden) X11 plot, then convert that to a 
jpeg or png image.  However...

No:
> Can someone tell me how to fix this?

1) have X running all the time (yuck).
or
2) install ghostscript (if you don't have it already), and use 

bitmap(file="foo.png", type="png256",res=300)

If it *must* be png format, I'd pick 2. For quality plots over web services, 
you really can't beat the pdf() driver, though.  Yum.  

Cheers

Jason

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From xyzzy at speakeasy.org  Wed Apr  3 05:54:25 2002
From: xyzzy at speakeasy.org (Trent Piepho)
Date: Tue, 2 Apr 2002 19:54:25 -0800 (PST)
Subject: [R] Trouble with R and cronjobs
In-Reply-To: <200204030258.OAA17986@smtp1.ihug.co.nz>
Message-ID: <Pine.LNX.4.04.10204021944490.5399-100000@xyzzy.dsl.speakeasy.net>

On Wed, 3 Apr 2002 j_turner at ihug.co.nz wrote:
> > Can someone tell me how to fix this?
> 
> 1) have X running all the time (yuck).
> or
> 2) install ghostscript (if you don't have it already), and use 
> 
> bitmap(file="foo.png", type="png256",res=300)
> 
> If it *must* be png format, I'd pick 2. For quality plots over web services, 
> you really can't beat the pdf() driver, though.  Yum.  

Or 
 3) run the virtual X server, Xvfb, which simulates an X server but doesn't
    actually drive any hardware.

Note that the plots will look different when you use the png vs bitmap device,
especially fonts.  

Xvfb has advantages even if you have an X server, if you are working remotely. 
R has to send the graphics commands over the network to the X server, then
download the finished graph.  One user here generated a batch of png plots
from a remote PC with an X server and ssh X forwarding.  It look about 6
hours.  I told him how to setup Xvfb to run on the same machine as R, and the
same process took about 1 minute.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From david.whiting at ncl.ac.uk  Tue Apr  2 19:46:00 2002
From: david.whiting at ncl.ac.uk (david.whiting@ncl.ac.uk)
Date: Tue, 2 Apr 2002 20:46:00 +0300
Subject: [R] A Few Suggestions to help out newbies
In-Reply-To: <1017746894.11200.53.camel@workhorse.killnine.net>
References: <MABBJPBLPNLDIFMIAAOJMEAKCFAA.indra_calisto@yahoo.com> <3CA95D5B.353C470@statistik.uni-dortmund.de> <1017742502.12802.17.camel@workhorse.killnine.net> <3CA98528.FA3E7011@statistik.uni-dortmund.de> <1017746894.11200.53.camel@workhorse.killnine.
Message-ID: <20020402204600.A4803@192.168.57.2>


On Tue, Apr 02, 2002 at 03:28:13AM -0800, Zed Shaw wrote:


...

> 2)  A Series of Documents helping people translate from another package
> to R.  For example, "R for SPSS People", "R for SAS People", etc.
> 

The way I started to teach myself how to use and program in R was to
write some functions that either simulated STATA output or at least spat
out a reminder about how to get the output I needed. Here's one example:


stata.encode <- function(){
cat("*** STATA to R ***\nEncode character data as a numbered factor. Take a look at\nas.factor(). Here's a quick example:\n\nx <- as.factor(x)\n\nTo see the codes, use codes(x)\n")
}

I created a crude library called stata so I could then type:

library(stata)
stata.encode()

...which gave me...

*** STATA to R ***
Encode character data as a numbered factor. Take a look at
as.factor(). Here's a quick example:

x <- as.factor(x)

To see the codes, use codes(x)


Not elegant, but this approah helped me. The library is not anywhere
near ready for submitting to CRAN but I agree with the idea behind Zed's
suggestion that people migrating from one system to another think in the
old system to begin with.

Dave

-- 
Dave Whiting
Dar es Salaam, Tanzania
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From egonw at sci.kun.nl  Wed Apr  3 11:03:14 2002
From: egonw at sci.kun.nl (Egon Willighagen)
Date: Wed, 3 Apr 2002 11:03:14 +0200
Subject: Finding code (was: [R] A request)
In-Reply-To: <Pine.A41.4.44.0204020830070.209546-100000@homer06.u.washington.edu>
References: <Pine.A41.4.44.0204020830070.209546-100000@homer06.u.washington.edu>
Message-ID: <E16sgfi-0000AJ-00@garak>

On Tuesday 2 April 2002 18:31, Thomas Lumley wrote:
> On Tue, 2 Apr 2002, E.L. Willighagen wrote:
> > Indeed. A "Search" link under "Documentation" on www.r-projects.org
> > itself pointing to it would be nice. Who is the person to ask for this?
>
> There *is* a Search link under "R-project" on www.r-project.org

Yes, but that one is able to search the site (which ofcourse includes the
docs, i know) and the mailarchives... but most of the time i do not want to
search the complete site, or the mailarchives... just the documentation...
and, hence, the request...

Egon
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Apr  3 09:05:44 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed, 3 Apr 2002 08:05:44 +0100 (BST)
Subject: [R] A Few Suggestions to help out newbies
In-Reply-To: <20020402204600.A4803@192.168.57.2>
Message-ID: <Pine.GSO.4.44.0204030754110.16258-100000@auk.stats>

On Tue, 2 Apr 2002 david.whiting at ncl.ac.uk wrote:

>
> On Tue, Apr 02, 2002 at 03:28:13AM -0800, Zed Shaw wrote:
>
>
> ...
>
> > 2)  A Series of Documents helping people translate from another package
> > to R.  For example, "R for SPSS People", "R for SAS People", etc.
> >
>
> The way I started to teach myself how to use and program in R was to
> write some functions that either simulated STATA output or at least spat
> out a reminder about how to get the output I needed. Here's one example:
>
>
> stata.encode <- function(){
> cat("*** STATA to R ***\nEncode character data as a numbered factor. Take a look at\nas.factor(). Here's a quick example:\n\nx <- as.factor(x)\n\nTo see the codes, use codes(x)\n")
> }
>
> I created a crude library called stata so I could then type:
>
> library(stata)
> stata.encode()
>
> ...which gave me...
>
> *** STATA to R ***
> Encode character data as a numbered factor. Take a look at
> as.factor(). Here's a quick example:
>
> x <- as.factor(x)
>
> To see the codes, use codes(x)

Sorry, but that just shows the dangers.  Where did you get that from?
It's not the right answer, and there is a note on the help page for codes
to that effect.  codes() is never necessary, and it is better to forget it
exists.  I use unclass, but as.numeric and as.integer also work.

Similarly, factor(x) is better than as.factor(x), both in avoiding a step
but more importantly because factor has other arguments you should be
considering using.

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From zedshaw at zedshaw.com  Wed Apr  3 09:59:19 2002
From: zedshaw at zedshaw.com (Zed Shaw)
Date: 02 Apr 2002 23:59:19 -0800
Subject: [R] Great Replies!  Give me some time...
Message-ID: <1017820760.2857.9.camel@workhorse.killnine.net>

Hello All,

Wow, what a response.  There were quite a few good comments, most of
them constructive, so I'd like to compile them together and come up with
a reasoned response.  Just off the top of my head, it looks like most
people like the ideas, but quibble over the implementations.  This
should make for some interesting discussions later.  I have a couple of
ideas for solutions to the problems which I'll outline briefly later.

Also, I'm not a mathematician by any stretch, I simply use R at  work as
a software developer and at school as a student of Management
Information Systems.  So, my solutions are more targeted at the things I
know: usability aspects, information organization, software
architectures, etc.  This means that, I need feedback from practicing
statisticians and researchers as to whether these things are valid.  

Finally, these are NOT complaints, they are suggested improvements.  I
think R is a fantastic little project and is very good.  So, please take
my suggestions as topics of discussion for possible improvement.

Anyway, talk at you later.  And thanks for the great feedback!

Zed A. Shaw






-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From alobo at ija.csic.es  Wed Apr  3 10:03:49 2002
From: alobo at ija.csic.es (Agustin Lobo)
Date: Wed, 3 Apr 2002 10:03:49 +0200 (MET DST)
Subject: [R] A Few Suggestions to help out newbies
In-Reply-To: <Pine.LNX.4.33.0204021656410.2415-100000@x.opf.slu.cz>
Message-ID: <Pine.OSF.3.96.1020403095127.18963C-100000@ija.csic.es>



On Tue, 2 Apr 2002, Lukas Kubin wrote:

> On Tue, 2 Apr 2002, Jonathan Baron wrote:
> 
> > >8) Command completion and contextual help in R.  The first one is
> > >probably fairly easy.  The second one is probably impossible.  It would
> > >involve giving out detailed help messages when things go wrong.  Not
> > >sure how to do that.
> >
> > Doesn't ESS do this?
> 
> Isn't this too automatical answer? I don't use Emacs and believe I'm not
> the only. But it is not the core problem. Why to connect as important
> basic (in my opinion) interface feature as command completion (at least)
> is with using a special text editor? In Octave, database interfaces and
> others command completion is a standard. So what's the reason not to
> include it in R?
> 

No, I don't think it's automatic, it's very reasonable. I'm not
quite a fan of (x)emacs-ESS, but it must be recognized that
it is much easier learning and using (x)emacs-ESS 
than developing the command completion feature. I think that 
an open source project such as R must take advantage 
of other open source projects whenever this is possible. If the
command completing feature exists in emacs-ESS, let's use
it there. Geting too big could kill R, because any new feature
implies maintainance and documentation. Therefore, I understand
that the R-core team focuses on developments that either
do not exist in other packages or that exist in packages that
cannot be easily linked to R.

Agus

Dr. Agustin Lobo
Instituto de Ciencias de la Tierra (CSIC)
Lluis Sole Sabaris s/n
08028 Barcelona SPAIN
tel 34 93409 5410
fax 34 93411 0012
alobo at ija.csic.es





-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From alobo at ija.csic.es  Wed Apr  3 10:04:37 2002
From: alobo at ija.csic.es (Agustin Lobo)
Date: Wed, 3 Apr 2002 10:04:37 +0200 (MET DST)
Subject: [R] A Few Suggestions to help out newbies
In-Reply-To: <33D04496-4659-11D6-A9DC-000393860F3C@stat.ucla.edu>
Message-ID: <Pine.OSF.3.96.1020403100420.18963E-100000@ija.csic.es>


On Tue, 2 Apr 2002, Jan de Leeuw wrote:

> The JSS editorial board is considering a  JSS section "R Snippets",
> possibly edited by our editors Kurt Hornik and Roger Koenker,
> which will have "interesting pieces of R code", with only a
> minimal amount of text /comments. Reactions ?
> 

Excellent!

Agus

Dr. Agustin Lobo
Instituto de Ciencias de la Tierra (CSIC)
Lluis Sole Sabaris s/n
08028 Barcelona SPAIN
tel 34 93409 5410
fax 34 93411 0012
alobo at ija.csic.es


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Apr  3 11:32:41 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 03 Apr 2002 11:32:41 +0200
Subject: [R] A Few Suggestions to help out newbies
In-Reply-To: <Pine.OSF.3.96.1020403100420.18963E-100000@ija.csic.es>
References: <Pine.OSF.3.96.1020403100420.18963E-100000@ija.csic.es>
Message-ID: <x21ydxqg92.fsf@blueberry.kubism.ku.dk>

Agustin Lobo <alobo at ija.csic.es> writes:

> On Tue, 2 Apr 2002, Jan de Leeuw wrote:
> 
> > The JSS editorial board is considering a  JSS section "R Snippets",
> > possibly edited by our editors Kurt Hornik and Roger Koenker,
> > which will have "interesting pieces of R code", with only a
> > minimal amount of text /comments. Reactions ?
> > 
> 
> Excellent!

Yes, but...

Yesterday I went through Paul J's site and looked at several of his
code snippets, quite a few of them originally due to myself, and I got
struck by how esoteric many of the issues seemed compared to how
interesting and challenging they were originally. Perhaps it would be
an idea to use a format of exercises or challenges? (Of course, this
assumes that the reader already knows about S and R, which could be a
problem if the purpose is to "spread the gospel".)

        -p

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lecca at science.unitn.it  Wed Apr  3 11:39:40 2002
From: lecca at science.unitn.it (Lecca Paola)
Date: Wed, 3 Apr 2002 11:39:40 +0200 (MET DST)
Subject: [R] non-stationary covariance
Message-ID: <Pine.OSF.4.30.0204031125480.7792-100000@science.unitn.it>

Hi !

Sorry for my ignorance. I have two questions:

1) which is in R the function to make a covariogram of spatial data ?

2) does anyone know if there exist the possibility in R of performing
kriging with an arbitrary covariance function ?

If I have well understood the Krig procedure offers only three
possibilities (expcov, gauscov and sphercov) that are the common models
for stationary and isotropic processes.

Thanks,
Paola.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lecca at science.unitn.it  Wed Apr  3 11:44:03 2002
From: lecca at science.unitn.it (Lecca Paola)
Date: Wed, 3 Apr 2002 11:44:03 +0200 (MET DST)
Subject: [R] non-stationary covariance
Message-ID: <Pine.OSF.4.30.0204031143250.21627-100000@science.unitn.it>

Hi !

Sorry for my ignorance. I have two questions:

1) which is in R the function to make a covariogram of spatial data ?

2) does anyone know if there exist the possibility in R of performing
kriging with an arbitrary covariance function ?

If I have well understood the Krig procedure offers only three
possibilities (expcov, gauscov and sphercov) that are the common models
for stationary and isotropic processes.

Thanks,
Paola.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lecca at science.unitn.it  Wed Apr  3 11:45:26 2002
From: lecca at science.unitn.it (Lecca Paola)
Date: Wed, 3 Apr 2002 11:45:26 +0200 (MET DST)
Subject: [R] non-stationary covariance
Message-ID: <200204030945.LAA27698@science.unitn.it>

A non-text attachment was scrubbed...
Name: not available
Type: text
Size: 1227 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20020403/b073aa9b/attachment.pl

From ripley at stats.ox.ac.uk  Wed Apr  3 11:47:13 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 3 Apr 2002 10:47:13 +0100 (BST)
Subject: [R] non-stationary covariance
In-Reply-To: <Pine.OSF.4.30.0204031125480.7792-100000@science.unitn.it>
Message-ID: <Pine.LNX.4.31.0204031042280.9881-100000@gannet.stats>

There are at least three R packages to do this, spatial, geoR and
sgeostat. Look at library(help=) for each.

On Wed, 3 Apr 2002, Lecca Paola wrote:

> Hi !
>
> Sorry for my ignorance. I have two questions:
>
> 1) which is in R the function to make a covariogram of spatial data ?
>
> 2) does anyone know if there exist the possibility in R of performing
> kriging with an arbitrary covariance function ?

Certainly.  It's just linear algebra which R does fairly well (and I've
written code to do so in S long ago, when it was too slow on a 12Mb 20MHz
machine).

> If I have well understood the Krig procedure offers only three
> possibilities (expcov, gauscov and sphercov) that are the common models
> for stationary and isotropic processes.

surf.gls allows arbitrary stationary and isotropic processes, for example.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Apr  3 11:47:16 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 03 Apr 2002 11:47:16 +0200
Subject: [R] non-stationary covariance
In-Reply-To: <200204030945.LAA27698@science.unitn.it>
References: <200204030945.LAA27698@science.unitn.it>
Message-ID: <x2wuvpp10b.fsf@blueberry.kubism.ku.dk>

Lecca Paola <lecca at science.unitn.it> writes:


> Forwarded message:
> From lecca Wed Apr  3 11:39:41 2002
> Date: Wed, 3 Apr 2002 11:39:40 +0200 (MET DST)
> From: Lecca Paola <lecca at science.unitn.it>
> To: <r-help at hypatia.math.ethz.ch>

Ahem! Once is enough. Three copies is excessive.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From danny at intuitivemedia.com  Wed Apr  3 12:26:47 2002
From: danny at intuitivemedia.com (Danny Ruttle)
Date: Wed, 03 Apr 2002 11:26:47 +0100
Subject: [R] Text Labels on plots in R
Message-ID: <5.1.0.14.0.20020403112132.028649b8@mail.intuitivemedia.com>

Hi

Is it possible to plot values against strings, i.e. the x axis has people's 
names and the
y axis as values, as shown below:


5    x
4             x                         x
3                     x
2                               x
1
0
     Dave  Tim    Ian   Steve  Paul

Sorry if this is a little primitive, but I think it gets the point across.

regards
Danny

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From danny at intuitivemedia.com  Wed Apr  3 12:59:20 2002
From: danny at intuitivemedia.com (Danny Ruttle)
Date: Wed, 03 Apr 2002 11:59:20 +0100
Subject: [R] Text Labels on plots in R
Message-ID: <5.1.0.14.0.20020403115740.02862bb8@mail.intuitivemedia.com>

Hi

Is it possible to plot values against strings, i.e. the x axis has people's 
names and the
y axis as values, as shown below:


5    x
4           x                        x
3                    x
2                            x
1
0
     Dave  Tim    Ian   Steve  Paul

Sorry if this illustration is a little primitive, but I think it gets the 
point across.

regards
Danny 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Wed Apr  3 13:01:33 2002
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Wed, 3 Apr 2002 06:01:33 -0500
Subject: Finding code (was: [R] A request)
In-Reply-To: <E16sgfi-0000AJ-00@garak>; from egonw@sci.kun.nl on Wed, Apr 03, 2002 at 11:03:14AM +0200
References: <Pine.A41.4.44.0204020830070.209546-100000@homer06.u.washington.edu> <E16sgfi-0000AJ-00@garak>
Message-ID: <20020403060133.A4560@cattell.psych.upenn.edu>

On 04/03/02 11:03, Egon Willighagen wrote:
>On Tuesday 2 April 2002 18:31, Thomas Lumley wrote:
>> On Tue, 2 Apr 2002, E.L. Willighagen wrote:
>> > Indeed. A "Search" link under "Documentation" on www.r-projects.org
>> > itself pointing to it would be nice. Who is the person to ask for this?
>>
>> There *is* a Search link under "R-project" on www.r-project.org
>
>Yes, but that one is able to search the site (which ofcourse includes the
>docs, i know) and the mailarchives... but most of the time i do not want to
>search the complete site, or the mailarchives... just the documentation...
>and, hence, the request...
>
>Egon

The htdig search facility at http://finzi.psych.upenn.edu
allows search of just the documentation, or just the functions,
or just R-help (now divided into pre-1.0 and since-1.0), or some
combinations.  Suggestions welcome for others.

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From david.barron at jesus.ox.ac.uk  Wed Apr  3 13:07:17 2002
From: david.barron at jesus.ox.ac.uk (David Barron)
Date: Wed, 3 Apr 2002 12:07:17 +0100
Subject: [R] Text Labels on plots in R
References: <5.1.0.14.0.20020403115740.02862bb8@mail.intuitivemedia.com>
Message-ID: <000f01c1daff$b7f3ac00$cb8801a3@sbs.ox.ac.uk>

This should do what you want:

plot(x,y,axes=FALSE)
axis(1,at=1:5,labels=c("Dave","Tim","Ian","Steve","Paul"))
axis(2)

David

----- Original Message -----
From: "Danny Ruttle" <danny at intuitivemedia.com>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, April 03, 2002 11:59 AM
Subject: [R] Text Labels on plots in R


> Hi
>
> Is it possible to plot values against strings, i.e. the x axis has
people's
> names and the
> y axis as values, as shown below:
>
>
> 5    x
> 4           x                        x
> 3                    x
> 2                            x
> 1
> 0
>      Dave  Tim    Ian   Steve  Paul
>
> Sorry if this illustration is a little primitive, but I think it gets the
> point across.
>
> regards
> Danny
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
>
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gregory_r_warnes at groton.pfizer.com  Wed Apr  3 13:55:27 2002
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Wed, 3 Apr 2002 06:55:27 -0500 
Subject: [R] RE: random forests for R
Message-ID: <5429125E11E4D411AF7300805FE603A8040DE8A4@groexmbcr02.pfizer.com>


Hi Andy,

I'm glad to see that someone has put up an R package of Leo's code.  I made
an R package using his first release of the code, but never had/took the
time to push it through the publication review process here so that I could
distribute it.  I'm glad you have.

-Greg


> -----Original Message-----
> From: Liaw, Andy [mailto:andy_liaw at merck.com]
> Sent: Tuesday, April 02, 2002 10:23 AM
> To: 'r-announce at lists.R-project.org'
> Subject: random forests for R
> 
> 
> 
> Hi all,
> 
> There is now a package available on CRAN that provides an R 
> interface to Leo
> Breiman's random forest classifier.
> 
> Basically, random forest does the following:
> 
> 1.  Select ntree, the number of trees to grow, and mtry, a 
> number no larger
> than number of variables.
> 2.  For i = 1 to ntree:
> 3.  Draw a bootstrap sample from the data.  Call those not in 
> the bootstrap
> sample the "out-of-bag" data.
> 4.  Grow a "random" tree, where at each node, the best split 
> is chosen among
> mtry randomly selected variables.  The tree is grown to 
> maximum size and not
> pruned back.
> 5.  Use the tree to predict out-of-bag data.
> 6.  In the end, use the predictions on out-of-bag data to 
> form majority
> votes.
> 7.  Prediction of test data is done by majority votes from 
> predictions from
> the ensemble of trees.
> 
> In the tech report
> http://oz.berkeley.edu/users/breiman/randomforest2001.pdf, 
> Breiman showed
> that this technique is very competitive to boosting 
> classification trees.
> In our own experience, it is competitive with nonlinear 
> classifiers such as
> artificial neural nets and support vector machines.  Two of 
> the significant
> advantages of random forests over other methods (IMHO) are: 
> a) there is only
> one parameter (mtry) to adjust, and the result usually not 
> sensititve to it;
> and b) the built-in cross-validation via the use of 
> out-of-bag data gives
> quite accurate estimate of test set error, and offers quite effective
> protection against overfitting.
> 
> The code is based on version 3.1 of the original Fortran code 
> written by
> Breiman and Cutler 
(http://www.stat.berkeley.edu/users/breiman/).  The User
Guide for the Fortran code on Breiman's web site explains some of the
facilities provided in the code (such as assessing variable importance, and
proximity measures).  Some facilities provided in the original Fortran code
have be taken out:  transforming data to principal components, and
multidimensional scaling of the "proximity" matrix.  These can easily be
done in R before and after calls to the random forest functions.  Random
numbers are generated by R's RNG, rather than the one supplied in the
original Fortran code.

I'd like to thank Profs. B. D. Ripley, J. Lindsey, and others on R-help that
answered many of my questions when I was working on this package.  The
formula interface and part of the code in the predict method are out-right
"stolen" from svm() in the e1071 package and nnet() in the VR bundle.

Questions/comments/bugs/patches welcomed!

Regards,
Andy
Andy I. Liaw, PhD
Biometrics Research          Phone: (732) 594-0820
Merck & Co., Inc.              Fax: (732) 594-1565
P.O. Box 2000, RY70-38            Rahway, NJ 07065
mailto:andy_liaw at merck.com



----------------------------------------------------------------------------
--
Notice: This e-mail message, together with any attachments, contains
information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that
may be confidential, proprietary copyrighted and/or legally privileged, and
is intended solely for the use of the individual or entity named on this
message.  If you are not the intended recipient, and have received this
message in error, please immediately return this by e-mail and then delete
it.

============================================================================
==

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-announce mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-announce-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._


LEGAL NOTICE
Unless expressly stated otherwise, this message is confidential and may be privileged. It is intended for the addressee(s) only. Access to this E-mail by anyone else is unauthorized. If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful. If you are not an addressee, please inform the sender immediately.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Wed Apr  3 14:26:41 2002
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 03 Apr 2002 07:26:41 -0500
Subject: Finding code (was: [R] A request)
In-Reply-To: <E16sgfi-0000AJ-00@garak>
References: <Pine.A41.4.44.0204020830070.209546-100000@homer06.u.washington.edu>
 <Pine.A41.4.44.0204020830070.209546-100000@homer06.u.washington.edu>
Message-ID: <5.1.0.14.2.20020403072052.01d516a8@pop>

Dear Egon,

At 11:03 AM 4/3/2002 +0200, Egon Willighagen wrote:
>On Tuesday 2 April 2002 18:31, Thomas Lumley wrote:
> > On Tue, 2 Apr 2002, E.L. Willighagen wrote:
> > > Indeed. A "Search" link under "Documentation" on www.r-projects.org
> > > itself pointing to it would be nice. Who is the person to ask for this?
> >
> > There *is* a Search link under "R-project" on www.r-project.org
>
>Yes, but that one is able to search the site (which ofcourse includes the
>docs, i know) and the mailarchives... but most of the time i do not want to
>search the complete site, or the mailarchives... just the documentation...
>and, hence, the request...

Jonathan Baron's R Search Site, which is two clicks from either the CRAN or 
R home page, has a "limit search to" drop-down menu that provides this 
capability (or perhaps I misunderstand what you want to do).

I hope that this helps,
  John


-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From laurent at genome.cbs.dtu.dk  Wed Apr  3 15:00:49 2002
From: laurent at genome.cbs.dtu.dk (Laurent Gautier)
Date: Wed, 3 Apr 2002 15:00:49 +0200
Subject: [R] A Few... -> 'R snippets in JSS'
In-Reply-To: <x21ydxqg92.fsf@blueberry.kubism.ku.dk>
References: <Pine.OSF.3.96.1020403100420.18963E-100000@ija.csic.es> <x21ydxqg92.fsf@blueberry.kubism.ku.dk>
Message-ID: <20020403130049.GG22372@giraffa.cbs.dtu.dk>

On Wed, Apr 03, 2002 at 11:32:41AM +0200, Peter Dalgaard BSA wrote:
> Agustin Lobo <alobo at ija.csic.es> writes:
> 
> > On Tue, 2 Apr 2002, Jan de Leeuw wrote:
> > 
> > > The JSS editorial board is considering a  JSS section "R Snippets",
> > > possibly edited by our editors Kurt Hornik and Roger Koenker,
> > > which will have "interesting pieces of R code", with only a
> > > minimal amount of text /comments. Reactions ?
> > > 
> > 
> > Excellent!
> 
> Yes, but...
> 
> Yesterday I went through Paul J's site and looked at several of his
> code snippets, quite a few of them originally due to myself, and I got
> struck by how esoteric many of the issues seemed compared to how
> interesting and challenging they were originally. Perhaps it would be
> an idea to use a format of exercises or challenges? (Of course, this
> assumes that the reader already knows about S and R, which could be a
> problem if the purpose is to "spread the gospel".)
> 
>         -p


The 'exercise' or 'challenge' format seems a neat idea... a bit like the
 'chess' challenges you can sometimes find in the magazines (you are
given a certain 'game configuration' and you need to do something in a
given number of moves)... 
A short problem is set, and the ways to solve it are
detailed (eventually in the next issue to let people think about it, or
publishing the answers sent (in categories 'shortest' , 'fastest', ...))

... I found myself taking the 'how do I do that' mails on r-helps as
such... and learning from reading the answers... may be what has been
 already asked on this list represents enough starting material.


L.




--------------------------------------------------------------
Laurent Gautier			CBS, Building 208, DTU
PhD. Student			D-2800 Lyngby,Denmark	
tel: +45 45 25 24 85		http://www.cbs.dtu.dk/laurent
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From clange at epost.de  Wed Apr  3 15:42:48 2002
From: clange at epost.de (Christoph Lange)
Date: Wed, 3 Apr 2002 15:42:48 +0200
Subject: [R] Still needing help with LDA
Message-ID: <20020403154248.A15629@rivka.biologie.fu-berlin.de>


In the meantime I found out that it should be possible to compute
wilks' lambda from the singular values that are returned by "lda". But
since I'm only a biologist I got totally stuck in formulas I don't
understand ...

Can anybody help me to get equivalent outputs of wilks' lambda in R as
in SPSS?

  Yours, Christoph.

-- 
Christoph Lange                                    clange at epost.de
Verhaltensbiologie, FU Berlin                            838-55068
Haderslebener Str. 9, 12163 Berlin
http://www.verhaltensbiologie.fu-berlin.de/
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From nychka at cgd.ucar.edu  Wed Apr  3 15:54:36 2002
From: nychka at cgd.ucar.edu (Doug Nychka)
Date: Wed, 3 Apr 2002 06:54:36 -0700 (MST)
Subject: [R] non-stationary covariance
In-Reply-To: <x2wuvpp10b.fsf@blueberry.kubism.ku.dk>
Message-ID: <Pine.GSO.4.30.0204030652420.3271-100000@student.cgd.ucar.edu>


The R package Fields allows for "kriging" with an arbitrary covariance
function written in R code.
There are also supporting diagnostic and plkotting functions.
Doug


-----------------------------------------------------------------------------
Doug Nychka,

Geophysical Statistics Project              Email: nychka at ucar.edu
National Center for Atmospheric Research    Voice: 303-497-1711
PO Box 3000                                 FAX: 303-497-1333
Boulder, CO  80307-3000                     Web: www.cgd.ucar.edu/~nychka

Address for overnight mail: 1850 Table Mesa Drive, Boulder, CO 80305


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Apr  3 16:08:41 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 3 Apr 2002 15:08:41 +0100 (BST)
Subject: [R] Still needing help with LDA
In-Reply-To: <20020403154248.A15629@rivka.biologie.fu-berlin.de>
Message-ID: <Pine.LNX.4.31.0204031457310.11926-100000@gannet.stats>

On Wed, 3 Apr 2002, Christoph Lange wrote:

> In the meantime I found out that it should be possible to compute
> wilks' lambda from the singular values that are returned by "lda". But
> since I'm only a biologist I got totally stuck in formulas I don't
> understand ...
>
> Can anybody help me to get equivalent outputs of wilks' lambda in R as
> in SPSS?

Perhaps you could explain to us exactly what SPSS does.  `Exactly' because
we've already seen that SPSS's equivalent of summary.manova does not do
what it says it does ....  But one possibility is that you just need to do
summary(manova(data ~ grouping), test="Wilks"), which will test if there
is a difference between the groups.  As in

data(iris)
X <- as.matrix(iris[-5])
summary(manova(X ~ iris$Species), test="Wilks")

Remember this assumes rather a lot: multivariate normality, common
covariances.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kari.ruohonen at saunalahti.fi  Wed Apr  3 16:15:44 2002
From: kari.ruohonen at saunalahti.fi (Kari Ruohonen)
Date: Wed, 3 Apr 2002 17:15:44 +0300 (EEST)
Subject: [R] Segmentation fault with xyplot
Message-ID: <Pine.LNX.4.44.0204031654300.4307-100000@www.trane.oma>

Hi - Are there any known bugs or other issues that may cause R to crash
when trying to use xyplot()? For example,

> x<-1:100
> y<-rnorm(100)
> library(lattice)
Loading required package: grid
> xyplot(y~x)

causes this:

Process R segmentation fault at Wed Apr  3 16:56:42 2002

I am running linux debian unstable on i386. R says it is R 1.5.0 in the
header text when starting but according to my installation files it is a
debian package 1.4.1.cvs20020331-1. I use ESS to run R and did
update.packages() from CRAN before testing.

Regards, Kari

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Wed Apr  3 16:35:13 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 03 Apr 2002 16:35:13 +0200
Subject: [R] Segmentation fault with xyplot
References: <Pine.LNX.4.44.0204031654300.4307-100000@www.trane.oma>
Message-ID: <3CAB1321.6C525163@statistik.uni-dortmund.de>



Kari Ruohonen wrote:
> 
> Hi - Are there any known bugs or other issues that may cause R to crash
> when trying to use xyplot()? For example,
> 
> > x<-1:100
> > y<-rnorm(100)
> > library(lattice)
> Loading required package: grid
> > xyplot(y~x)
> 
> causes this:
> 
> Process R segmentation fault at Wed Apr  3 16:56:42 2002
> 
> I am running linux debian unstable on i386. R says it is R 1.5.0 in the
> header text when starting but according to my installation files it is a
> debian package 1.4.1.cvs20020331-1. I use ESS to run R and did
> update.packages() from CRAN before testing.

Looks like you have got a development version ("unstable") of R.
Use 
 version
to see what version you really have got.

The latest official release is R-1.4.1 (2002-01-30).

For R-1.5.0 (in development !) you'll need other versions of grid and
lattice, available at CRAN:
http://cran.r-project.org/src/contrib/1.5.0/

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Apr  3 16:30:20 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 3 Apr 2002 15:30:20 +0100 (BST)
Subject: [R] Segmentation fault with xyplot
In-Reply-To: <Pine.LNX.4.44.0204031654300.4307-100000@www.trane.oma>
Message-ID: <Pine.LNX.4.31.0204031523200.13133-100000@gannet.stats>

Yes, you need grid 0.6 with R-devel or grid 0.5-1 with R-1.4.1.

I suggest that you get the debian package of a released version of R and
use that.

Lots of packages will not run with a snapshot of Mar 31.  There are
updates on CRAN, but update.packages() will not get them for you.

Notice that your snapshot says in its header that it is *unstable*.
It means what it says.


On Wed, 3 Apr 2002, Kari Ruohonen wrote:

> Hi - Are there any known bugs or other issues that may cause R to crash
> when trying to use xyplot()? For example,
>
> > x<-1:100
> > y<-rnorm(100)
> > library(lattice)
> Loading required package: grid
> > xyplot(y~x)
>
> causes this:
>
> Process R segmentation fault at Wed Apr  3 16:56:42 2002
>
> I am running linux debian unstable on i386. R says it is R 1.5.0 in the
> header text when starting but according to my installation files it is a
> debian package 1.4.1.cvs20020331-1. I use ESS to run R and did
> update.packages() from CRAN before testing.
>
> Regards, Kari
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From friendly at yorku.ca  Wed Apr  3 16:44:28 2002
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 03 Apr 2002 09:44:28 -0500
Subject: [R] R package organization
Message-ID: <3CAB154C.E45D7CC1@yorku.ca>


>6)  Better layout of packages listed on CRAN.  This listing
format will
>collapse under its own weight once it gets too large.
>

As a new R user, I have thought for some time that the organization
of packages, and functions within packages, in R needs some more
coherent structure, perhaps something like the hierarchy of classes
used in Perl and contributed to CPAN.  For example, Perl modules
are listed on CPAN organized in a tree containing top-level categories
like

Archiving and Compression
Commercial Software Interfaces
Control Flow Utilities
Data Type Utilities
Database Interfaces
Development Support
File Handle Input Output
  ...
each of these contain numerous subcategories, and there is a
coherent relationship between the subcategories and the directory
structure for installed modules.  So, to use functions to search
for files on my file system, I say

use File::Find;

and if someone writes a new module, say FastCopy.pm it goes into
/usr/lib/perl5/File/FastCopy.pm in my Perl library.

In R, on the other hand, everything goes into R/rw104x/library,
and each pachage contains all its functions within packagename/R,
so there is only a very flat organization across packages
and within packages.

Some packages are quite coherent and relate to a single general
class of methods (John Fox's sem package, for example), while
others are a heterogeneous collection of tools which someone
found useful, and kindly took the effort to document and make public.
 
This makes it quite difficult, sometimes to find a function for
a given task, and I see this reflected both in my own
efforts to use R as well as in many queries on this list, often
answered repeated with a brief

library(foo)
?bar

It also makes it difficult for one person to extend another's
work, e.g., by writing new functions or enhancing others
from an existing package.

This is not a criticism of the R Development Team, but, as
R continues to grow, and more people make contributions to
CRAN, perhaps it is time for some thought to be given to a
reorganization of package structure.

As I look over the list of packages on CRAN, I don't see
any obvious categories, but perhaps others will have some
ideas on this topic.

-Michael

-- 
Michael Friendly              friendly at yorku.ca
York University               http://www.math.yorku.ca/SCS/friendly.html
Psychology Department
4700 Keele Street             Tel:  (416) 736-5115 x66249
Toronto, Ontario, M3J 1P3     Fax:  (416) 736-5814
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From york at noaa.gov  Wed Apr  3 17:03:31 2002
From: york at noaa.gov (Anne York)
Date: Wed, 3 Apr 2002 07:03:31 -0800 (PST)
Subject: [R] A Few Suggestions to help out newbies
In-Reply-To: <3CA9D5D9.20086.664264F@localhost>
Message-ID: <Pine.GSO.4.05.10204030657300.12393-100000@ofis450a.akctr.noaa.gov>


On Tue, 2 Apr 2002 ggrothendieck at yifan.net wrote:
(most of message deleted) ...

>It has been said that the key difference between Open Source projects and commercial 
>projects is not just that the commercial packages cost money but 
>that the commercial developers listen to their users better than Open Source
>developers do. (I am not saying that R developers don't listen, I am just
>bringing out this view of Open Source vs. Commerical, in general).   If commercial developers 
>don't listen to their users then they don't stay in business very long!   
>
...
Counterexample:

In my experience the R-team has been incredibly helpful. The last time I
found a major bug in a function, a member of the team sent me a fix in 30
minutes.  That's an incredible response. With Microsoft, maybe the biggest
money maker in the software business, you pay for your fixes-- if you can
get Microsoft to even acknowledge that there is a bug. 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From egonw at sci.kun.nl  Wed Apr  3 19:09:46 2002
From: egonw at sci.kun.nl (Egon Willighagen)
Date: Wed, 3 Apr 2002 19:09:46 +0200
Subject: [R] R package organization
In-Reply-To: <3CAB154C.E45D7CC1@yorku.ca>
References: <3CAB154C.E45D7CC1@yorku.ca>
Message-ID: <E16soGY-0000EX-00@garak>

On Wednesday 3 April 2002 16:44, Michael Friendly wrote:
> As I look over the list of packages on CRAN, I don't see
> any obvious categories, but perhaps others will have some
> ideas on this topic.

It does not have to be just one map... Freshmeat.net and some other
sites use something called Trove categories (e.g. 
http://freshmeat.net/projects/jchempaint).
There can be several trees in which a package can be found, possibly even
at different leaves in the same tree.

Example trees for R could based on general method or data type, or whatever.
A tree could be based on chapters in some standard encyclopedia, for example.
We could develop several trees, each one aiming at a specific discipline: one 
for chemometrics, one for sociometrics, econometrics etc...

A paradigma in webdesign is that each webpage should be accessible within at 
most three click, otherwise it will not be read... the same holds for these 
kind of search trees (compare for example with descision trees, where the 
depth is rather irrelevant)...

If adding more trees make packages more used, we gain something...

Egon


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ggrothendieck at yifan.net  Wed Apr  3 17:10:58 2002
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Wed, 3 Apr 2002 10:10:58 -0500
Subject: [R] Text Labels on plots in R
In-Reply-To: <5.1.0.14.0.20020403112132.028649b8@mail.intuitivemedia.com>
Message-ID: <3CAAD532.12397.875ACD@localhost>

Suppose

y <- c(5:2,4)
names(y) <- c("Dave", "Tim", "Ian", "Steve", "Paul")

Here are 3 possibilities which are close to what you want:

dotchart(y)            <-- axes are switched from what you specified
plot(as.table(y))   <-- uses vertical bars rather than points
plot( y ~ factor(names(y),levels=names(y)), boxwex = .05)  <-- not so pretty



On 3 Apr 2002 at 11:26, Danny Ruttle wrote:

> Hi
> 
> Is it possible to plot values against strings, i.e. the x axis has people's 
> names and the
> y axis as values, as shown below:
> 
> 
> 5    x
> 4             x                         x
> 3                     x
> 2                               x
> 1
> 0
>      Dave  Tim    Ian   Steve  Paul
> 
> Sorry if this is a little primitive, but I think it gets the point across.
> 
> regards
> Danny
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From egonw at sci.kun.nl  Wed Apr  3 19:16:47 2002
From: egonw at sci.kun.nl (Egon Willighagen)
Date: Wed, 3 Apr 2002 19:16:47 +0200
Subject: Finding code (was: [R] A request)
In-Reply-To: <5.1.0.14.2.20020403072052.01d516a8@pop>
References: <Pine.A41.4.44.0204020830070.209546-100000@homer06.u.washington.edu> <5.1.0.14.2.20020403072052.01d516a8@pop>
Message-ID: <E16soNM-0000Ee-00@garak>

Dear all,

On Wednesday 3 April 2002 14:26, John Fox wrote:
> At 11:03 AM 4/3/2002 +0200, Egon Willighagen wrote:
> >On Tuesday 2 April 2002 18:31, Thomas Lumley wrote:
> > > On Tue, 2 Apr 2002, E.L. Willighagen wrote:
> > > > Indeed. A "Search" link under "Documentation" on www.r-projects.org
> > > > itself pointing to it would be nice. Who is the person to ask for
> > > > this?
> > >
> > > There *is* a Search link under "R-project" on www.r-project.org
> >
> >Yes, but that one is able to search the site (which ofcourse includes the
> >docs, i know) and the mailarchives... but most of the time i do not want
> > to search the complete site, or the mailarchives... just the
> > documentation... and, hence, the request...
>
> Jonathan Baron's R Search Site, which is two clicks from either the CRAN or
> R home page, has a "limit search to" drop-down menu that provides this
> capability (or perhaps I misunderstand what you want to do).

You're all absolutely right. The search engine there.

The problem I see is that when people see a header "Documentation" and want 
to search this documentation, they do not start looking for a search engine 
elsewhere... otherwise they would have gone to Google in the first place...
I've been webdesigner for several years now; this is what I experienced... I 
am just trying to give some feedback on how the website may be improved...

regards,

Egon



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pgilbert at bank-banque-canada.ca  Wed Apr  3 18:04:38 2002
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed, 03 Apr 2002 11:04:38 -0500
Subject: [R] libraries in $HOME/lib
Message-ID: <3CAB2816.51C61C9F@bank-banque-canada.ca>

I have installed zlib and png libraries in $HOME/lib with headers in
$HOME/include and would like to pass this information along when I
configure R, but cannot find the proper incantation (R-1.4.1, Solaris,
csh). From the R-admin guide, I believe that

(setenv LIBS -L$HOME/lib ; setenv CPPFLAGS -L$HOME/include ; ./configure
)

should work, but I still get

checking for png.h... no

(starting clean, no config.cache). I have tried some variations,
including

(setenv LIBS $HOME/lib ; setenv CPPFLAGS $HOME/include ; ./configure )

which breaks gcc, as things do need to be found in other places too.
Enlightment would be appreciated. (And might I suggest an example of
this in the R-admin guide, as it it may be a common problem encountered
by compiler neophytes like me.)

Paul Gilbert
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cdeclercq at nordnet.fr  Wed Apr  3 18:12:50 2002
From: cdeclercq at nordnet.fr (Christophe Declercq)
Date: Wed, 3 Apr 2002 18:12:50 +0200
Subject: [R] Text Labels on plots in R
In-Reply-To: <3CAAD532.12397.875ACD@localhost>
Message-ID: <NEBBLCMFGLNFBEBKHFCECEEICGAA.cdeclercq@nordnet.fr>


> De : owner-r-help at stat.math.ethz.ch
> [mailto:owner-r-help at stat.math.ethz.ch]
> De la part de ggrothendieck at yifan.net
> Envoy? : mercredi 3 avril 2002 17:11
> Objet : Re: [R] Text Labels on plots in R
>
>
> Suppose
>
> y <- c(5:2,4)
> names(y) <- c("Dave", "Tim", "Ian", "Steve", "Paul")

[...]

> On 3 Apr 2002 at 11:26, Danny Ruttle wrote:
>
> > Hi
> >
> > Is it possible to plot values against strings, i.e. the x
> axis has people's
> > names and the
> > y axis as values, as shown below:
[...]

Perhaps, what Danny wants is just:

> stripchart(y~names(y), vertical=TRUE)

Hope it helps.

Christophe
--
Christophe DECLERCQ, MD
Observatoire R?gional de la Sant? Nord-Pas-de-Calais
13, rue Faidherbe 59046 LILLE Cedex FRANCE
Phone +33 3 20 15 49 24
Fax   +33 3 20 55 92 30
E-mail c.declercq at orsnpdc.org


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Wed Apr  3 18:10:30 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 3 Apr 2002 08:10:30 -0800 (PST)
Subject: [R] Text Labels on plots in R
In-Reply-To: <000f01c1daff$b7f3ac00$cb8801a3@sbs.ox.ac.uk>
Message-ID: <Pine.A41.4.44.0204030806240.145628-100000@homer07.u.washington.edu>

On Wed, 3 Apr 2002, David Barron wrote:

> This should do what you want:
>
> plot(x,y,axes=FALSE)
> axis(1,at=1:5,labels=c("Dave","Tim","Ian","Steve","Paul"))
> axis(2)
>


Or if x is a factor
  plot(codes(x),y,xaxt="n",xlab="x")
  axis(1,at=codes(x),labels=levels(x))
(perhaps the only use for the codes() function)

You might also want to look at the dotchart() function.

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Wed Apr  3 18:23:28 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 3 Apr 2002 08:23:28 -0800 (PST)
Subject: [R] R package organization
In-Reply-To: <E16soGY-0000EX-00@garak>
Message-ID: <Pine.A41.4.44.0204030814020.145628-100000@homer07.u.washington.edu>

On Wed, 3 Apr 2002, Egon Willighagen wrote:

> On Wednesday 3 April 2002 16:44, Michael Friendly wrote:
> > As I look over the list of packages on CRAN, I don't see
> > any obvious categories, but perhaps others will have some
> > ideas on this topic.
>
> It does not have to be just one map... Freshmeat.net and some other
> sites use something called Trove categories (e.g.
> http://freshmeat.net/projects/jchempaint).
> There can be several trees in which a package can be found, possibly even
> at different leaves in the same tree.
>

That sounds more promising than anything that's been suggested so far.
It wouldn't actually have to be done centrally at CRAN, and different
trees could be constructed for different disciplines (eg some people think
that logistic and linear regression are basically the same thing and
MANOVA is very different, other people think that linear regression and
MANOVA are basically the same thing and logistic regression is different).


	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Wed Apr  3 18:29:45 2002
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Wed, 3 Apr 2002 11:29:45 -0500
Subject: [R] R package organization
In-Reply-To: <3CAB154C.E45D7CC1@yorku.ca>; from friendly@yorku.ca on Wed, Apr 03, 2002 at 09:44:28AM -0500
References: <3CAB154C.E45D7CC1@yorku.ca>
Message-ID: <20020403112945.A3761@cattell.psych.upenn.edu>

On 04/03/02 09:44, Michael Friendly wrote:
>
>>6)  Better layout of packages listed on CRAN.  This listing
>format will
>>collapse under its own weight once it gets too large.
>>
>
>As a new R user, I have thought for some time that the organization
>of packages, and functions within packages, in R needs some more
>coherent structure, perhaps something like the hierarchy of classes
>used in Perl and contributed to CPAN.  For example, Perl modules
>are listed on CPAN organized in a tree containing top-level categories
>like [...]

As an occasional CPAN user, I never use this and doubt I ever
will.  I usually go there for some specific thing that I hear
about somewhere else or find through Google (e.g., html2latex).

I tend to think that the effort involved in making a good
classification would be better spent in making better search
tools, or something else altogether.  I also think that CRAN may
require a lot more expertise to understand than CPAN does.

But there is a simple way to settle this.  You, or anyone, could
copy the CRAN page and re-organize it.  Announce it, and ask for
comments.  See if it flies.

Jon Baron
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ggrothendieck at yifan.net  Wed Apr  3 18:32:03 2002
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Wed, 3 Apr 2002 11:32:03 -0500
Subject: [R] Text Labels on plots in R
In-Reply-To: <NEBBLCMFGLNFBEBKHFCECEEICGAA.cdeclercq@nordnet.fr>
References: <3CAAD532.12397.875ACD@localhost>
Message-ID: <3CAAE833.21428.D196A6@localhost>

On 3 Apr 2002 at 18:12, Christophe Declercq wrote:

> >
> > Suppose
> >
> > y <- c(5:2,4)
> > names(y) <- c("Dave", "Tim", "Ian", "Steve", "Paul")
> 
> 
> stripchart(y~names(y), vertical=TRUE)

Note that this rearranges the order of the elements on the x axis.
If maintaining this order is important then use:

ynames <- factor(  names(y), levels = names(y)  )
stripchart( y ~ ynames, vertical=TRUE )
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From danny at intuitivemedia.com  Wed Apr  3 18:49:38 2002
From: danny at intuitivemedia.com (Danny Ruttle)
Date: Wed, 03 Apr 2002 17:49:38 +0100
Subject: Fixed: [R] Text Labels on plots in R 
In-Reply-To: <3CAAFF1D.4EE3E4DA@optonline.net>
References: <5.1.0.14.0.20020403112132.028649b8@mail.intuitivemedia.com>
Message-ID: <5.1.0.14.0.20020403174809.02891e40@mail.intuitivemedia.com>

Thanks to all those who chipped in to help.
The snippet below solved the problem.

regards
Danny

At 08:09 03/04/2002 -0500, Chuck Cleland wrote:
>Danny Ruttle wrote:
> > Is it possible to plot values against strings, i.e. the x axis has people's
> > names and the
> > y axis as values, as shown below:
>
>Danny:
>
>mynames <- c("Dave", "Tim", "Ian", "Steve", "Paul")
>y <- runif(5)
>plot(1:5, y, xaxt="n")
>axis(side=1, at=1:5, mynames)
>
>Hope this helps,
>
>Chuck

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brahm at alum.mit.edu  Wed Apr  3 18:51:57 2002
From: brahm at alum.mit.edu (David Brahm)
Date: Wed, 3 Apr 2002 11:51:57 -0500
Subject: [R] Two R sessions?
In-Reply-To: <63276505@toto.iv>
Message-ID: <15531.13101.561683.215671@gargle.gargle.HOWL>

Paul Y. Peng <ypeng at math.mun.ca> wrote:
> I wonder in R how do you handle one difference between R and S+.  S+ saves
> objects as different files in .Data directory while R saves all objects in
> a big file .RData.

In both S+ and R, I treat objects in the workspace (pos=1) as disposable, and
objects in attached databases (pos>1) as permanent.  I wrote the R package
"g.data" to store these permanent objects in separate files as S+ does:
  <http://cran.r-project.org/src/contrib/g.data_1.2.tar.gz>

"g.data" only loads the objects you actually use, so you don't have to read a
huge .RData file if you only want a small subset of the data.  Give it a try!

> ..I can start two S+ sessions from the same directory and work simultaneously
> as long as new objects in the two sessions are not in the same names.

This strikes me as dangerous, especially since I have so many "x" and "y"
variables all over.  Multiple sessions in R are much nicer, since I never store
my workspace and so there is never any interference.  No need to worry about
what working directory I started R up in.
-- 
                              -- David Brahm (brahm at alum.mit.edu)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mel at mcs.st-and.ac.uk  Wed Apr  3 19:33:02 2002
From: mel at mcs.st-and.ac.uk (Mike Lonergan)
Date: Wed, 3 Apr 2002 18:33:02 +0100
Subject: [R] optim() 
Message-ID: <NEBBJLLBCLEDFLCCBKDAEEJNCEAA.mel@mcs.st-andrews.ac.uk>


I was having some problems persuading optim() to give me the answers I
wanted,
 & simplified down to:

   sqr<-function(x){(x+1)^2}
   optim(1,sqr)

I accept this is a hammer to crack a nut, but was still expecting the
answer -1.
I got:

   $par
   [1] -0.8

   $value
   [1] 0.04

   $counts
   function gradient
      12       NA

   $convergence
   [1] 0

   $message
   NULL

so I've obviously misunderstood something.
(The default 'robust but slow' method did seem appropriate.)

Repeating this for:
   v<--100:100/5
   v2<-1;for(i in 1:201) v2[i]<-optim(v[i],sqr)$par
   plot(v,v2)

gave a bit more than 10% unexpected answers. Playing with control reduces
the scatter, but rather relies on knowing the answer in advance.
(function(x){x^2} gives another nice pattern.)

So, with the usual apologies for my ignorance (of both kinds, though I have
had a look in the archives), I'd be grateful for an indication of where I've
messed up.

Thanks,

Mike.

> version
         _
platform i386-pc-mingw32
arch     x86
os       Win32
system   x86, Win32
status   Patched
major    1
minor    4.0
year     2002
month    01
day      23
language R

(but also tried on a couple of other machines)



----------------------------------------------------------------
Mike Lonergan
Research Unit for Wildlife Population Assessment
Mathematical Institute
University of St Andrews
North Haugh                             Tel: +44 (0) 1334 463760
St Andrews                              Fax: +44 (0) 1334 463714
Fife KY16 9SS                      Email: mel at mcs.st-and.ac.uk
Scotland
----------------------------------------------------------------



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Apr  3 19:51:16 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 3 Apr 2002 18:51:16 +0100 (BST)
Subject: [R] optim() 
In-Reply-To: <NEBBJLLBCLEDFLCCBKDAEEJNCEAA.mel@mcs.st-andrews.ac.uk>
Message-ID: <Pine.LNX.4.31.0204031848190.15880-100000@gannet.stats>

The default Nelder-Mead method does not work well in one dimension.
> optim(1,sqr, method="BFGS")
$par
[1] -1

$value
[1] 2.071992e-29

$counts
function gradient
       8        3

...

I never really expected people to use optim for one-dimensional input
(there is optimize).

I'll add a warning in that case.


On Wed, 3 Apr 2002, Mike Lonergan wrote:

>
> I was having some problems persuading optim() to give me the answers I
> wanted,
>  & simplified down to:
>
>    sqr<-function(x){(x+1)^2}
>    optim(1,sqr)
>
> I accept this is a hammer to crack a nut, but was still expecting the
> answer -1.
> I got:
>
>    $par
>    [1] -0.8
>
>    $value
>    [1] 0.04
>
>    $counts
>    function gradient
>       12       NA
>
>    $convergence
>    [1] 0
>
>    $message
>    NULL
>
> so I've obviously misunderstood something.
> (The default 'robust but slow' method did seem appropriate.)
>
> Repeating this for:
>    v<--100:100/5
>    v2<-1;for(i in 1:201) v2[i]<-optim(v[i],sqr)$par
>    plot(v,v2)
>
> gave a bit more than 10% unexpected answers. Playing with control reduces
> the scatter, but rather relies on knowing the answer in advance.
> (function(x){x^2} gives another nice pattern.)
>
> So, with the usual apologies for my ignorance (of both kinds, though I have
> had a look in the archives), I'd be grateful for an indication of where I've
> messed up.
>
> Thanks,
>
> Mike.
>
> > version
>          _
> platform i386-pc-mingw32
> arch     x86
> os       Win32
> system   x86, Win32
> status   Patched
> major    1
> minor    4.0
> year     2002
> month    01
> day      23
> language R
>
> (but also tried on a couple of other machines)
>
>
>
> ----------------------------------------------------------------
> Mike Lonergan
> Research Unit for Wildlife Population Assessment
> Mathematical Institute
> University of St Andrews
> North Haugh                             Tel: +44 (0) 1334 463760
> St Andrews                              Fax: +44 (0) 1334 463714
> Fife KY16 9SS                      Email: mel at mcs.st-and.ac.uk
> Scotland
> ----------------------------------------------------------------
>
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hodgess at uhddx01.dt.uh.edu  Wed Apr  3 20:01:08 2002
From: hodgess at uhddx01.dt.uh.edu (Erin Hodgess)
Date: Wed, 3 Apr 2002 12:01:08 -0600 (CST)
Subject: [R] arima0 with unusual poly
Message-ID: <200204031801.MAA18715@uhddx01.dt.uh.edu>

Dear R People:

Suppose I want to estimate the parameters of the
following AR model:

(1 - phi_1 B - phi_2 B^2 - phi_9 B^9) x_t = a_t

and I want to use the arima0 command from the 
ts library.

How would I use the order subcommand, please?

R Version 1.4.1 for Windows.

Thanks!

Sincerely,
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
1 Main Street 
Houston, TX 77002
mailto: hodgess at uhddx01.dt.uh.edu
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Apr  3 20:08:11 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 3 Apr 2002 19:08:11 +0100 (BST)
Subject: [R] arima0 with unusual poly
In-Reply-To: <200204031801.MAA18715@uhddx01.dt.uh.edu>
Message-ID: <Pine.LNX.4.31.0204031904370.15880-100000@gannet.stats>

On Wed, 3 Apr 2002, Erin Hodgess wrote:

> Dear R People:
>
> Suppose I want to estimate the parameters of the
> following AR model:
>
> (1 - phi_1 B - phi_2 B^2 - phi_9 B^9) x_t = a_t
>
> and I want to use the arima0 command from the
> ts library.
>
> How would I use the order subcommand, please?

You can only do that in the version in the upcoming 1.5.0, which has a
`fixed' argument to allow it.  There is a pre-release available from

http://www.stats.uwo.ca/faculty/murdoch/software/r-devel

Alternatively, arma in package tseries can do an OLS fit with terms set to
zero, I believe.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ggrothendieck at yifan.net  Wed Apr  3 21:31:26 2002
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Wed, 3 Apr 2002 14:31:26 -0500
Subject: [R] Text Labels on plots in R
In-Reply-To: <3CAAE833.21428.D196A6@localhost>
References: <NEBBLCMFGLNFBEBKHFCECEEICGAA.cdeclercq@nordnet.fr>
Message-ID: <3CAB123E.30384.175D1A5@localhost>

On 3 Apr 2002 at 11:32, ggrothendieck at yifan.net wrote:

> On 3 Apr 2002 at 18:12, Christophe Declercq wrote:
> > > Suppose
> > >
> > > y <- c(5:2,4)
> > > names(y) <- c("Dave", "Tim", "Ian", "Steve", "Paul")
> > 
> > stripchart(y~names(y), vertical=TRUE)
> 
> Note that this rearranges the order of the elements on the x axis.
> If maintaining this order is important then use:
> 
> ynames <- factor(  names(y), levels = names(y)  )
> stripchart( y ~ ynames, vertical=TRUE )

Just noticed one improvement here:

stripchart( as.list(y), vertical = TRUE )

works and also preserves the order of the x axis elements.  

One suggestion. If dotchart were to also support the vertical keyword 
then one could have an even simpler solution: dotchart(y,vertical=TRUE)

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Wed Apr  3 22:37:44 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Wed, 3 Apr 2002 15:37:44 -0500
Subject: [R] Linear extrapolation; revision to earlier posting
Message-ID: <20020403153744.04fa94b5.fharrell@virginia.edu>

The S-Plus approx function implements rule=3 (linear extrapolation), which is not implemented in R.  Has anyone extended approx to handle linear extrapolation?  

Regarding the use of approx for "closest matching" in my post from last week, you need to add ties=function(x)x[1], e.g.

round(approx(c(1,3,5,2,4,2,4),1:7,xout=c(1,3,5,2,4,2,4),rule=2,
       ties=function(x)x[1])$y)

-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hodgess at uhddx01.dt.uh.edu  Wed Apr  3 22:57:25 2002
From: hodgess at uhddx01.dt.uh.edu (Erin Hodgess)
Date: Wed, 3 Apr 2002 14:57:25 -0600 (CST)
Subject: [R] predict with arima0
Message-ID: <200204032057.OAA21028@uhddx01.dt.uh.edu>

Dear R People:

I'm having some problems with the predict command after the arima0
fit.  Here is my output:

> xx <- arima0(xm1,order=c(1,1,1))
> xx

Call:
arima0(x = xm1, order = c(1, 1, 1))

Coefficients:
    ar1      ma1  
 0.5084  -0.6205  

Approx standard errors:
   ar1     ma1  
0.2100  0.1889  

sigma^2 estimated as 9.055:  log likelihood = -814.17,  aic = 1632.34
> predict(xx,n.ahead=3)
Error in round(x, digits) : Non-numeric argument to mathematical function
> 

Is there anything obviously wrong, please?  I'd be glad to send over the 
data if it would help!

Sincerely,
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
1 Main Street 
Houston, TX 77002
mailto: hodgess at uhddx01.dt.uh.edu
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Ralf.Kloessinger at student.fh-nuernberg.de  Thu Apr  4 00:50:56 2002
From: Ralf.Kloessinger at student.fh-nuernberg.de (Ralf.Kloessinger@student.fh-nuernberg.de)
Date: Thu, 4 Apr 2002 00:50:56 +0200
Subject: [R] Another question on locfit
Message-ID: <isapiwc.4b8d1e19.7df4.3cab8750.695bd.f4@stud-iss.cs.fh-nuernberg.de>

Hello!!!

Thank you all for your suggestion on my last question about locfit.

Now I have another question:

I would like to change the evalution structure ev in locfit() to a vector/matrix.
I created a vector and a matrix:
>  vec <- mat.or.vec(101, 1)
>  vec <- c(0:100)
>  mat <- matrix(data = vec, nrow = 101, ncol = 1)

and I tried to change the ev parameter:

>  fit <- locfit(~imposter, kern="gauss", renorm=T, xlim=c(1e-20,100), ev=vec)

This works good but when I tried to get the density points I get an error, this happens also when I use the matrix (mat) for ev:

>  fhat <- fitted(fit)
   Error in fitted.locfit(fit) : NA/NaN/Inf in foreign function call (arg 10)

I think arg 10 means "dp" and there I got the following parameters:

> fit$dp
nnalph   fixh  adpen    cut     lk    df1    df2     rv 
   0.7    0.0    0.0    0.8    0.0    0.0    0.0    1.0 
   swt    rsc 
6228.0    0.0 

When I tried locfit with ev="tree", lk, df1, df2, rsc are changed, so I think there is the problem!!

If I use the predict() function, I get also an error message:

> pre <- predict.locfit(fit, mat)
Error in preplot.locfit.raw(object, newdata, where, what, band)  
        NA/NaN/Inf in foreign function call (arg 2)

But here the problem could be the newdata parameter. I don't know an other way to get around of this problems to get what I need. 

Also when I change the xlim to c(0,100) I get for the fitted() and predict() function only 1s in each row. It would be nice to know, why this happen.

Thank you for your time and your help

Ralf




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jimrc at gauss.math.montana.edu  Thu Apr  4 02:19:32 2002
From: jimrc at gauss.math.montana.edu (Jim Robison-Cox)
Date: Wed, 3 Apr 2002 17:19:32 -0700 (MST)
Subject: [R] non-32-bit integer problem on SUN-Blade
Message-ID: <Pine.GSO.4.33.0204031636530.2794-100000@gauss.math.montana.edu>

Hello,

  Perhaps this is a bug, but I thought I'd start with R-Help.

I'm trying to compile R-1.4.1 on a new Sun-Blade running Solaris 2.8
( I got it running with no problem on older SUNs)


I get the following error after doing the usual ./configure and make:
gcc -I. -I../../src/include -I../../src/include -I/usr/local/include
-DHAVE_CONFIG_H   -g -O2 -c arithmetic.c -o arithmetic.o
arithmetic.c:672: #error code requires that int have 32 bits
*** Error code 1

which is generated by the following lines in  src/main/arithmetic.c

#######################################################################
1. /* The tests using integer comparisons are a bit faster than the tests
   using doubles, but they depend on a two's complement representation
   (but that is almost universal).  The tests that compare results to
   double's depend on being able to accurately represent all int's as
   double's.  Since int's are almost universally 32 bit that should be
   OK. */

#ifndef INT_32_BITS
/* configure checks whehter int is 32 bits.  If not this code will
   need to be rewritten.  Since 32 bit ints are pretty much universal,
   we can worry about writing alternate code when the need arises.
   To be safe, we signal a compiler error if int is not 32 bits. */
# error code requires that int have 32 bits
#else
/* Just to be on the safe side, configure ought to check that the
   mashine uses two's complement. A define like
#define USES_TWOS_COMPLEMENT (~0 == (unsigned) -1)
   might work, but at least one compiler (CodeWarrior 6) chokes on it.
   So for now just assume it is true.
*/
#######################################################################

So it seems that I now have 64 bit integers?
Has anyone else had this problem?
I did search the bugs list, and didn't find it.
R-Help archive shows a query:

  [R] [ 1.4.0] Compilation with 64 bits on Irix Luca.Toldo at merck.de (Mon
Jan 21 2002 -  14:44:16 CET)

which has no answer.

If it relates to the SGI build question from
[R] R in IRIX 64-bit Isaac Neuhaus (Mon Feb 04 2002 - 17:41:53 CET)
 I don't know how to translate the answers.

Help would be much appreciated.
Jim


Jim Robison-Cox               ____________
Department of Math Sciences  |            |       phone: (406)994-5340
2-214 Wilson Hall             \   BZN, MT |       FAX:   (406)994-1789
Montana State University       |  *_______|
Bozeman, MT 59717-2400          \_|      e-mail: jimrc at math.montana.edu



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Thu Apr  4 02:34:16 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 3 Apr 2002 16:34:16 -0800 (PST)
Subject: [R] non-32-bit integer problem on SUN-Blade
In-Reply-To: <Pine.GSO.4.33.0204031636530.2794-100000@gauss.math.montana.edu>
Message-ID: <Pine.A41.4.44.0204031628340.152576-100000@homer04.u.washington.edu>

On Wed, 3 Apr 2002, Jim Robison-Cox wrote:

>
> So it seems that I now have 64 bit integers?
> Has anyone else had this problem?

There should be a compiler flag to have 32bit ints and 64bit longs.  On
some Unix compilers this is the default even for 64bit machines (eg the
Sun Enterprise Server we used to have).

I'm surprised that configure didn't find a problem with the Fortran
compiler -- I thought Fortran INTEGER was specified to be a 32 bit type,
but we test that Fortran and C agree during configuration.

	-thomas


	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kari.ruohonen at saunalahti.fi  Thu Apr  4 07:23:52 2002
From: kari.ruohonen at saunalahti.fi (Kari Ruohonen)
Date: Thu, 4 Apr 2002 08:23:52 +0300 (EEST)
Subject: [R] Segmentation fault with xyplot
In-Reply-To: <Pine.LNX.4.31.0204031523200.13133-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0204040821380.1286-100000@www.trane.oma>

Thanks for this answer and others. Updating the libraries as suggested
helped. I got the development version by "accident" when updating my
debian system as usual and did a "distribution upgrade". My fault.

Kari

On Wed, 3 Apr 2002 ripley at stats.ox.ac.uk wrote:

> Yes, you need grid 0.6 with R-devel or grid 0.5-1 with R-1.4.1.
>
> I suggest that you get the debian package of a released version of R and
> use that.
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Apr  4 07:33:09 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 4 Apr 2002 06:33:09 +0100 (BST)
Subject: [R] non-32-bit integer problem on SUN-Blade
In-Reply-To: <Pine.GSO.4.33.0204031636530.2794-100000@gauss.math.montana.edu>
Message-ID: <Pine.GSO.4.44.0204040626380.29459-100000@auk.stats>

On Wed, 3 Apr 2002, Jim Robison-Cox wrote:

> Hello,
>
>   Perhaps this is a bug, but I thought I'd start with R-Help.
>
> I'm trying to compile R-1.4.1 on a new Sun-Blade running Solaris 2.8
> ( I got it running with no problem on older SUNs)

Which version of gcc, which options?  gcc is normally built to have
32-bit ints and 32-bit longs on 64-bit Solaris.

There are flags such as -m32, -m64, -mcmodel=code-model, However,
my Solaris version of gcc says

     -m32
     -m64
         Generate code for a 32-bit or 64-bit environment.  The
         32-bit environment sets int, long and pointer to 32
         bits.  The 64-bit environment sets int to 32 bits and
         long and pointer to 64 bits.

I use Sun compilers on 64-bit Solaris, as they perform a lot better
in my tests.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Apr  4 07:56:12 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 4 Apr 2002 06:56:12 +0100 (BST)
Subject: [R] predict with arima0
In-Reply-To: <200204032057.OAA21028@uhddx01.dt.uh.edu>
Message-ID: <Pine.GSO.4.44.0204040652590.29515-100000@auk.stats>

On Wed, 3 Apr 2002, Erin Hodgess wrote:

> Dear R People:
>
> I'm having some problems with the predict command after the arima0
> fit.  Here is my output:
>
> > xx <- arima0(xm1,order=c(1,1,1))
> > xx
>
> Call:
> arima0(x = xm1, order = c(1, 1, 1))
>
> Coefficients:
>     ar1      ma1
>  0.5084  -0.6205
>
> Approx standard errors:
>    ar1     ma1
> 0.2100  0.1889
>
> sigma^2 estimated as 9.055:  log likelihood = -814.17,  aic = 1632.34
> > predict(xx,n.ahead=3)
> Error in round(x, digits) : Non-numeric argument to mathematical function
> >
>
> Is there anything obviously wrong, please?  I'd be glad to send over the
> data if it would help!

Is xm1 actually a time series?  That's what happens if it is not,
but it is documented that the `x' argument must be a time series.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Michael.Dondrup at Genetik.Uni-Bielefeld.DE  Thu Apr  4 10:51:16 2002
From: Michael.Dondrup at Genetik.Uni-Bielefeld.DE (Michael Dondrup)
Date: Thu, 04 Apr 2002 10:51:16 +0200
Subject: [R] libraries in $HOME/lib
References: <3CAB2816.51C61C9F@bank-banque-canada.ca>
Message-ID: <3CAC1404.2E9DB1BC@Genetik.Uni-Bielefeld.DE>

Paul Gilbert wrote:
> 
> I have installed zlib and png libraries in $HOME/lib with headers in
> $HOME/include and would like to pass this information along when I
> configure R, but cannot find the proper incantation (R-1.4.1, Solaris,
> csh). From the R-admin guide, I believe that
> 
> (setenv LIBS -L$HOME/lib ; setenv CPPFLAGS -L$HOME/include ; ./configure
> )
> 
> should work, but I still get
> 
> checking for png.h... no
> 

I think you want to use option "-I" not "-L" with CPPFLAGS here:
> setenv CPPFLAGS -I$HOME/include ;
additionally you need to tell the linker where to find the libs:
> setenv LDFLAGS -L$HOME/lib -R$HOME/lib ; (at least I did...)

Michael
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Apr  4 11:21:28 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 4 Apr 2002 10:21:28 +0100 (BST)
Subject: [R] libraries in $HOME/lib
In-Reply-To: <3CAC1404.2E9DB1BC@Genetik.Uni-Bielefeld.DE>
Message-ID: <Pine.LNX.4.31.0204041014400.11187-100000@gannet.stats>

On Thu, 4 Apr 2002, Michael Dondrup wrote:

> Paul Gilbert wrote:
> >
> > I have installed zlib and png libraries in $HOME/lib with headers in
> > $HOME/include and would like to pass this information along when I
> > configure R, but cannot find the proper incantation (R-1.4.1, Solaris,
> > csh). From the R-admin guide, I believe that
> >
> > (setenv LIBS -L$HOME/lib ; setenv CPPFLAGS -L$HOME/include ; ./configure
> > )
> >
> > should work, but I still get
> >
> > checking for png.h... no
> >
>
> I think you want to use option "-I" not "-L" with CPPFLAGS here:
> > setenv CPPFLAGS -I$HOME/include ;
> additionally you need to tell the linker where to find the libs:
> > setenv LDFLAGS -L$HOME/lib -R$HOME/lib ; (at least I did...)

R does that by setting LD_LIBRARY_PATH in its front end script `R',
so it should not be necessary to use -R.  I don't need it ....


One possible source of confusion: in R-devel (and 1.5.0-to-be) the
variable LIBS has been replaced by LDFLAGS, so there you would use

./configure -C CPPFLAGS=-I/$HOME/include LDFLAGS=-L$HOME/lib

(and you should set the variables this way as they are now `precious'
and will be re-used if re-configuration is needed).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From paradis at isem.univ-montp2.fr  Thu Apr  4 12:15:36 2002
From: paradis at isem.univ-montp2.fr (Emmanuel Paradis)
Date: Thu, 04 Apr 2002 12:15:36 +0200
Subject: [R] A Few Suggestions to help out newbies
Message-ID: <3.0.32.20020404121536.008e9a00@162.38.183.200>

At 06:37 02/04/02 -0800, Anthony Rossini wrote:
>> On Tue, Apr 02, 2002 at 03:28:13AM -0800, Zed Shaw wrote:
>
>> > 7)  Create the "Encyclopedia of Statstics" online.  I would kill for a
>> > repository of all the "trade secrets" of statistics, related to R.  For
>> > example: a brief discussion of the merits of factor analysis,
>> > considering its heritage with IQ tests.  Or, "The History of Student".
>> > If this were organized right, it would even be possible to access it
>> > from R itself and provide people with help with the statistics part of
>> > using R (which is probably the most difficult portion).
>
>This is a great idea, one which I started working on around late 1994 (the
"online history and/or course thing").  One of the cool things that the
early WWW had going for it was lots of people trying to integrate and
collaborate, and one such project was the world-wide web encyclopaedia.
It had two extremely fatal flaws -- funding and academic credit (for people
who worked on it).
>
>It has a secondary flaw -- people worry more about contributing to a
documentation project than to a software project (at least in my experience
-- I've had 2 on-line text books since 1996 that many, many people have
asked for hard-copy (at least PDF/PS versions) of).  But apparently the
asking price was too high (fix mistakes/typos or contribute a paragraph).
>
>And while I'm ranting, there are another set of problems -- people prefer
to speculate than to write (code/docs/prototypes), and write than read
(existing frameworks, and integrate with them).  Leads to many wheel
reinventions.
>
>If you really want something like that (on-line encyclopedia), there are
plenty of approximations, for example.  I think the Statistica folk (I
might be getting the package wrong) have something like that on their WWW
site.
>
>Of course, I didn't integrate with R back then, R wasn't too much at that
point (and XML wasn't really worth noticing, let along developing with,
until 1997/1998)...  But note the real point -- discussing how great
something would be is quite silly until you attempt a prototype of it, to
see how it might work out.  
>
>And to reiterate what someone else mentioned -- most of the core people
are busy; suggestions are best accompanied with at least a prototype to be
fixed.
>
>Finally, with respect to SPC -- yes, all the tools are there, in the sense
that EVERY stat package, including plain excel, has all the tools.  Even C
and Fortran have all the tools, in the sense I'm talking about.  Functions
to make it easier, on the other hand, aren't present (yet).  And this is
the crux of the matter.
>
>best,
>-tony

I take this opportunity to mention that I revised thoroughly "R for
beginners" (currently on CRAN in French and in English). The new version is
now about 60 pages long (30 for the previous one). For the moment, only a
French version is available, you can download it with the following link
(only by FTP):

ftp://evol.isem.univ-montp2.fr/pub/pc/Log-manu/Rdebuts_fr-DRAFT.pdf

Translation in other languages is in progress. As usual, comments and
suggestions are welcome.

Best,

Emmanuel Paradis
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ernesto at ipimar.pt  Thu Apr  4 14:01:32 2002
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Thu, 4 Apr 2002 13:01:32 +0100
Subject: [R] Histograms with coplot
Message-ID: <20020404130132.1e9f6e00.ernesto@ipimar.pt>

Hi

Is it possible to use coplot to draw histograms ?

Regards

EJ



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mariabeth.silkey at predict.ch  Thu Apr  4 13:45:10 2002
From: mariabeth.silkey at predict.ch (Mariabeth Silkey)
Date: Thu, 4 Apr 2002 13:45:10 +0200
Subject: [R] =?iso-8859-1?Q?Basle/_Aller=F8d:_Survival_Analysis_in_S-PLUS_with_Terry_T?=
	=?iso-8859-1?Q?herneau?=
Message-ID: <JPEBKBMBPPHHPEIOHMGHGEJIHLAA.mariabeth.silkey@predict.ch>


SURVIVAL ANALYSIS IN S-PLUS
by Dr Terry Therneau

14/15 May Aller?d, Denmark
16/17 May Basel, Switzerland


Dr. Terry Therneau has worked in medical research statistics for
over 15 years. He has written several papers on the use of residuals
in the Cox model, and is the author of the survival routines found in
S-PLUS, as well as the SAS routines COXREG and SURVTEST.

Note: Due to his employer's policies and participation in "speaker's
bureaus",
and a recent decision to include the Insightful sponsored courses under that
categorization, these are likely to be the last courses offered by Dr.
Therneau
through our sponsorship.

Course Description
The survival analysis software available in standard statistical packages
has recently experienced a major increment in functionality, and is no
longer
limited to the triad of Kaplan-Meier curves, log rank tests, and simple
Cox models. This course provides an overview of modern survival analysis
methods available in S-PLUS. Topics include time-dependent coefficient
models, expected survival calculations, weighted sampling, penalized
models and frailty models.

Course:  Survival Models in S-PLUS
(full description:
http://www.uk.insightful.com/SPLUSMain/training/guru/therneau.htm
Dates:   14/15 May Aller?d, Denmark
         16/17 May Basel, Switzerland

Price	Commercial:	1,330 Euro + VAT
	Academic:	1,066 Euro + VAT

To Register
 Aller?d:   - Contact Adept Scientific
            - Email: infodk at adeptscientific.dk
		- Phone +45 48 25 17 77

 Basel:	- Contact Insightful Switzerland
            - Email: info at ch.insightful.com
		- Phone +41 61 717 93 40
		- Fax +41 61 717 93 41






Insightful Switzerland
Christoph Merian-Ring 11
CH - 4153 Reinach
Tel.      +41 61 717 93 42
Fax       +41 61 717 93 41
Mobile    +41 79 582 19 44

http://www.predict.ch

"Do you know what you know?"



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From alobo at ija.csic.es  Thu Apr  4 15:04:12 2002
From: alobo at ija.csic.es (Agustin Lobo)
Date: Thu, 4 Apr 2002 15:04:12 +0200 (MET DST)
Subject: [R] ozone.xy
Message-ID: <Pine.OSF.3.96.1020404150127.981R-100000@ija.csic.es>


Hi!

Where is ozone.xy? I've found ozone in package fields,
but cannot find ozone.xy
Actually, is there any way to find in which package
lives a particular
dataset (if the package is not installed in the local system?)

Thanks

Dr. Agustin Lobo
Instituto de Ciencias de la Tierra (CSIC)
Lluis Sole Sabaris s/n
08028 Barcelona SPAIN
tel 34 93409 5410
fax 34 93411 0012
alobo at ija.csic.es


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From paradis at isem.univ-montp2.fr  Thu Apr  4 14:52:47 2002
From: paradis at isem.univ-montp2.fr (Emmanuel Paradis)
Date: Thu, 04 Apr 2002 14:52:47 +0200
Subject: [R] Histograms with coplot
Message-ID: <3.0.32.20020404145247.00912ba0@162.38.183.200>

At 13:01 04/04/02 +0100, Ernesto Jardim wrote:
>Hi
>
>Is it possible to use coplot to draw histograms ?
>
>Regards
>
>EJ

I think what you want can be done with the function histogram() in the
package lattice.

EP

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Friedrich.Leisch at ci.tuwien.ac.at  Thu Apr  4 15:39:04 2002
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Thu, 4 Apr 2002 15:39:04 +0200
Subject: [R] A Few Suggestions to help out newbies
In-Reply-To: <1017746894.11200.53.camel@workhorse.killnine.net>
References: <MABBJPBLPNLDIFMIAAOJMEAKCFAA.indra_calisto@yahoo.com>
	<3CA95D5B.353C470@statistik.uni-dortmund.de>
	<1017742502.12802.17.camel@workhorse.killnine.net>
	<3CA98528.FA3E7011@statistik.uni-dortmund.de>
	<1017746894.11200.53.camel@workhorse.killnine.net>
Message-ID: <15532.22392.648356.990823@galadriel.ci.tuwien.ac.at>


Hi,


sorry to join late on the thread, I was on easter vacation. I'm mostly
responding to the first mail rather the latest mail in the thread
because the thread has forked into several branches.

So comments from one of the two CRAN maintainers:

Ad "dynamic" features of CRAN (cookbook section, dynamic FAQ, multiple
views of package lists, ...:
The CRAN master site must unfortuneately remain static, because
mirroring won't work any more. We cannot (and do not want to) assume
anything about the software/web server/... installed on mirror
sites, hence CRAN is plain HTML. And we need the mirror sites, because
the computing center of our university is already complaining from
time to time about the network usage CRAN generates (we are among the
top 3 servers of the university almost all of the time). 

If somebody provides a dynamic site for a feature [s]he finds useful,
we are more than happy to link to it from the R homepage and/or
CRAN. E.g., searching CRAN is something where volunteers have stepped
in and provide the feature on their site [thanks a
lot!]. *.r-project.org is already a virtual newtork, the main site is
in vienna, the bug repsoitory in copenhagen, the developers site in
wisconsin and the mailing list server sits in z?rich ...




>>>>> On 02 Apr 2002 03:28:13 -0800,
>>>>> Zed Shaw (ZS) wrote:

  > Hey Folks,
  > I may have some suggestions for you, based on my experience as a newbie
  > with R.  Implementing these very simple resources would be fairly easy
  > to do and would give volumes of help in return:

  > 1)  An R Cookbook section of the site where people can submit pieces of
  > interesting code that satisfies a need.  This would be similar to the
  > Perl/Python/Java Cookbook texts that O'Reilly puts out, but with a more
  > dynamic activity.  The python folks have something like this, and people
  > love it.  I learned a lot of python this way.

See above, volunteers are more than welcome.


  > 2) A Series of Documents helping people translate from another
package > to R.  For example, "R for SPSS People", "R for SAS People",
etc.

Send us the document, it will be on CRAN in a minute (or two :-)

  > 3)  A dynamic FAQ, placed prominently on the front page, ready for
  > people to access and search.  The idea is that, as you encounter these
  > dumb questions, you can slap up another faq question about it.  When it
  > is asked again, don't bother replying, just *politely* say, "go to
  > http://www.r-project.com/somefaqquestion/".  That saves everyone
  > headaches, and encapsulates the knowledge on the list.  If it were setup
  > right, it could be searchable through R.

See above, volunteers are more than welcome.


  > 4)  Better web site layout.  It is hard to read the manuals if you can't
  > find them.

???

I admit that I'm not a professional web designer, but I still think
that the job I did is not that bad. What's wrong or hard to find about
a menu entry "Manuals" in section "Documentation"???

They also come as part of every standard R distribution, and R asks
you kindly to try help.start() on startup ...


  > 5)  Better search for the site.  It would be nice if you used google on
  > the site, but even htdig setup properly would help.

There is a htdig search kindly provided by Jonathan Baron.

  > 6)  Better layout of packages listed on CRAN.  This listing format will
  > collapse under its own weight once it gets too large.


It already is too large. The current format was designed when we had
20 or 30 packages on CRAN. But given schedules of the people involved
don't expect anything to happen for the next 2-3 months.


  > 8) Command completion and contextual help in R.  The first one is
  > probably fairly easy.  The second one is probably impossible.  It would
  > involve giving out detailed help messages when things go wrong.  Not
  > sure how to do that.

As a happy ESS user I've got nothing to add to previous emails.

.f

PS: And now back to improving R CMD check/build for the upcoming 1.5
release.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dieter.menne at menne-biomed.de  Thu Apr  4 16:35:16 2002
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Thu, 4 Apr 2002 16:35:16 +0200
Subject: [R] Something like se.contrast.lme?
Message-ID: <JLEPLGAANFCEAEDCAGJNGEMDCBAA.dieter.menne@menne-biomed.de>

Is there an equivalent to se.contrast.aov (base) that works with lme?




---------------------------------------
Dr. Dieter Menne
Biomed Software
72074 T?bingen
Tel (49) (7071) 52176
FAX (49) (7071) 55 10 46
dieter.menne at menne-biomed.de
www.menne-biomed.de



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From murdoch at stats.uwo.ca  Thu Apr  4 16:51:02 2002
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 04 Apr 2002 09:51:02 -0500
Subject: [R] A Few Suggestions to help out newbies
Message-ID: <mgpoau4k6q8p740mdn78hdf1p3tj3bi5ul@4ax.com>

The suggestion to include command completion in R has been discussed
over the last few days.  I just wanted to say two things:

  - I'm now the Windows maintainer, and command completion is on my
wish list for Rgui.  It might make sense to have it in the standard
console, but that's not up to me, that's Rcore's business. 

  - There are a lot of other things on the wish list, and I haven't
even had time to prioritize them, let alone start work on any of them.
Certainly I won't be making any changes to Rgui in 1.5.0.  

Duncan Murdoch
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pflugshaupt at geobot.umnw.ethz.ch  Thu Apr  4 16:58:29 2002
From: pflugshaupt at geobot.umnw.ethz.ch (Kaspar Pflugshaupt)
Date: Thu, 04 Apr 2002 16:58:29 +0200
Subject: [R] html documentation bug in: help(par), 'las'
Message-ID: <B8D236B5.7F45%pflugshaupt@geobot.umnw.ethz.ch>

Currently (R-1.4.1 as well as R-devel, according to
http://stat.ethz.ch/R-alpha/R-devel/library/base/html/par.html), the html
version of help(par) shows

[...]

lab
   A numerical vector of the form c(x, y, len) which modifies the way that
   axes are annotated. The values of x and y give the (approximate) number
   of tickmarks on the x and y axes and len specifies the label size. The
   default is c(5, 5, 7). Currently, len is unimplemented.
3:
   always vertical.
   numeric in {0,1,2,3}; the style of axis labels.

0:
   always parallel to the axis [default],
1:
   always horizontal,
2:
   always perpendicular to the axis,
3:
   always vertical.

[...]

The label for parameter "las" somehow got lost. The text help gives:

[...]

     `las' numeric in {0,1,2,3}; the style of axis labels.

          0: always parallel to the axis [default],

[...]

> version
         _         
platform powerpc-apple-darwin5.3
arch     powerpc   
os       darwin5.3 
system   powerpc, darwin5.3
status             
major    1         
minor    4.1       
year     2002      
month    01        
day      30        
language R         


Kaspar Pflugshaupt


-- 

Kaspar Pflugshaupt
Geobotanisches Institut
Zuerichbergstr. 38
CH-8044 Zuerich

Tel. ++41 1 632 43 19
Fax  ++41 1 632 12 15

mailto:pflugshaupt at geobot.umnw.ethz.ch
privat:pflugshaupt at mails.ch
http://www.geobot.umnw.ethz.ch

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Apr  4 17:59:09 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 4 Apr 2002 16:59:09 +0100 (BST)
Subject: [R] html documentation bug in: help(par), 'las'
In-Reply-To: <B8D236B5.7F45%pflugshaupt@geobot.umnw.ethz.ch>
Message-ID: <Pine.LNX.4.31.0204041656390.24473-100000@gannet.stats>

This is in the R-bugs repository (PR#1257) and I fixed it yesterday.


On Thu, 4 Apr 2002, Kaspar Pflugshaupt wrote:

> Currently (R-1.4.1 as well as R-devel, according to
> http://stat.ethz.ch/R-alpha/R-devel/library/base/html/par.html), the html
> version of help(par) shows
>
> [...]
>
> lab
>    A numerical vector of the form c(x, y, len) which modifies the way that
>    axes are annotated. The values of x and y give the (approximate) number
>    of tickmarks on the x and y axes and len specifies the label size. The
>    default is c(5, 5, 7). Currently, len is unimplemented.
> 3:
>    always vertical.
>    numeric in {0,1,2,3}; the style of axis labels.
>
> 0:
>    always parallel to the axis [default],
> 1:
>    always horizontal,
> 2:
>    always perpendicular to the axis,
> 3:
>    always vertical.
>
> [...]
>
> The label for parameter "las" somehow got lost. The text help gives:
>
> [...]
>
>      `las' numeric in {0,1,2,3}; the style of axis labels.
>
>           0: always parallel to the axis [default],
>
> [...]
>
> > version
>          _
> platform powerpc-apple-darwin5.3
> arch     powerpc
> os       darwin5.3
> system   powerpc, darwin5.3
> status
> major    1
> minor    4.1
> year     2002
> month    01
> day      30
> language R
>
>
> Kaspar Pflugshaupt
>
>
> --
>
> Kaspar Pflugshaupt
> Geobotanisches Institut
> Zuerichbergstr. 38
> CH-8044 Zuerich
>
> Tel. ++41 1 632 43 19
> Fax  ++41 1 632 12 15
>
> mailto:pflugshaupt at geobot.umnw.ethz.ch
> privat:pflugshaupt at mails.ch
> http://www.geobot.umnw.ethz.ch
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hodgess at uhddx01.dt.uh.edu  Thu Apr  4 22:33:18 2002
From: hodgess at uhddx01.dt.uh.edu (Erin Hodgess)
Date: Thu, 4 Apr 2002 14:33:18 -0600 (CST)
Subject: [R] summary on predict with arima0
Message-ID: <200204042033.OAA21628@uhddx01.dt.uh.edu>

Here is the summary on predict when
using an arima0 object:

The arima0 object must be based on a time series vector.

That is;
x <- ts(xm1, frequency=12, start=c(1975,1))
x.ar <- arima0(x,order=c(1,1,1))
predict(x.ar,n.ahead=3)

Thanks so much to Prof. Brian Ripley and David Brahm and other!

Sincerely,
Erin Hodgess
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From seniorr at aracnet.com  Fri Apr  5 04:45:43 2002
From: seniorr at aracnet.com (Russell Senior)
Date: 04 Apr 2002 18:45:43 -0800
Subject: [R] FAQ not in the FAQ??
In-Reply-To: <200204042033.OAA21628@uhddx01.dt.uh.edu>
Message-ID: <86hemqn9rc.fsf@coulee.tdb.com>


I know how to pull a copy of the current R release sources using
rsync.  How do I do the same thing for the current add-on packages?

Thanks.

-- 
Russell Senior         ``The two chiefs turned to each other.        
seniorr at aracnet.com      Bellison uncorked a flood of horrible       
                         profanity, which, translated meant, `This is
                         extremely unusual.' ''                      
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jeff_hamann at hamanndonald.com  Fri Apr  5 09:19:25 2002
From: jeff_hamann at hamanndonald.com (Jeff D. Hamann)
Date: Thu, 4 Apr 2002 23:19:25 -0800
Subject: [R] weighted 2 or 3 parameter weibull estimation?
Message-ID: <01c701c1dc72$378e2710$01000001@godzilla>


  I've figured out how to use optim (barely) to estimate 2 parameter =
  weibull distributions. I can't get over how easy this is. What I need to =
  do is use a weight in the observations.....

  For example,=20

  the tree diameters and weights are are=20

  4.70 , 100
  6.00, 98
  7.10,  75.0
  8.10, 86.3
  8.60, 80.456
  8.90, 20.5
  9.50, 16.6
  11.40, 12.657
  11.80, 12.47
  14.50, 8.98
  16.00,4.5
  16.90,2.36
  18.90, 0.256

  which yield

 LOCATION =3D   0.0000              MEAN =3D   10.9921
    SCALE =3D  12.3436          VARIANCE =3D   18.0027
    SHAPE =3D   2.8050          SKEWNESS =3D    0.2354

  which are the values without the weights. I can't find any reference to =
  weights in the optim function and I'm afraid I'm a little stuck here. =
  After I figure out how to include the weights, I'll then need to =
  estimate the 3-parameter estimates. Any help would be greatful.=20

  Thanks,
  Jeff.


Jeff D. Hamann
Hamann, Donald & Associates, Inc.
PO Box 1421
Corvallis, Oregon USA 97339-1421
Bus. 541-753-7333
Cell. 541-740-5988
jeff_hamann at hamanndonald.com
www.hamanndonald.com




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Friedrich.Leisch at ci.tuwien.ac.at  Fri Apr  5 09:41:49 2002
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Fri, 5 Apr 2002 09:41:49 +0200
Subject: [R] FAQ not in the FAQ??
In-Reply-To: <86hemqn9rc.fsf@coulee.tdb.com>
References: <200204042033.OAA21628@uhddx01.dt.uh.edu>
	<86hemqn9rc.fsf@coulee.tdb.com>
Message-ID: <15533.21821.955689.760753@galadriel.ci.tuwien.ac.at>

>>>>> On 04 Apr 2002 18:45:43 -0800,
>>>>> Russell Senior (RS) wrote:

  > I know how to pull a copy of the current R release sources using
  > rsync.  How do I do the same thing for the current add-on packages?

E.g.,

galadriel:Leisch$ rsync cran.r-project.org::
CRAN           	complete CRAN ftp area                    <<<<<<<<<<<
r-project-web  	Web pages for www.r-project.org
FTP            	E1071/CI anonymous FTP area

galadriel:Leisch$ rsync cran.us.r-project.org::
r-release      	R-1.4.0 sources (current released version - approx 25 MB)
r-patched      	R sources (patched released version - approx 25 MB)
r-devel        	R sources (devel version, less stable - approx 25 MB)
r-ng           	R source (next generation - unstable - approx 25 MB)
r-manuals      	Development sources for manuals for R
xlispstat      	xlispstat sources (development version) CVS tree (approx 12 MB)
ess-cvs        	ess (Emacs Speaks Statistics) CVS tree (approx 8.5 MB)
CRAN           	Complete CRAN ftp area                    <<<<<<<<<<<
ESS            	Complete ftp archive for ESS - Emacs Speaks Statistics
omega-cvs      	Omega Project for Statistical Computing CVS tree
r-project-web  	Web pages for www.r-project.org and mirrors
Omegahat       	Complete ftp archive for Omegahat



give you access to all of CRAN via rsync (untarred versions of add-ons
are not available, this would use way too much space)

best,

-- 
-------------------------------------------------------------------
                        Friedrich  Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071      Friedrich.Leisch at ci.tuwien.ac.at
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch
-------------------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Hildegard.Goelz-Huwe at t-online.de  Fri Apr  5 10:56:03 2002
From: Hildegard.Goelz-Huwe at t-online.de (Bernd Huwe)
Date: Fri, 5 Apr 2002 10:56:03 +0200
Subject: [R] AW: random forests for R
In-Reply-To: <51F9C42DA15CD311BD220008C707D81906FFC18C@usrymx10.merck.com>
Message-ID: <AJEFKAJJEADAJOBBBMAGGEBLCBAA.bernd.huwe@uni-bayreuth.de>

Super. Der Algorithmus gef?llt mir sehr gut und scheint auch gar nicht so
schwierig zu realisieren zu sein. Er erinnert etwas an die genetischen
Algorithmen.

Gru?
Bernd Huwe

-----Urspr?ngliche Nachricht-----
Von: owner-r-announce at stat.math.ethz.ch
[mailto:owner-r-announce at stat.math.ethz.ch]Im Auftrag von Liaw, Andy
Gesendet: Dienstag, 2. April 2002 17:23
An: 'r-announce at lists.R-project.org'
Betreff: random forests for R



Hi all,

There is now a package available on CRAN that provides an R interface to Leo
Breiman's random forest classifier.

Basically, random forest does the following:

1.  Select ntree, the number of trees to grow, and mtry, a number no larger
than number of variables.
2.  For i = 1 to ntree:
3.  Draw a bootstrap sample from the data.  Call those not in the bootstrap
sample the "out-of-bag" data.
4.  Grow a "random" tree, where at each node, the best split is chosen among
mtry randomly selected variables.  The tree is grown to maximum size and not
pruned back.
5.  Use the tree to predict out-of-bag data.
6.  In the end, use the predictions on out-of-bag data to form majority
votes.
7.  Prediction of test data is done by majority votes from predictions from
the ensemble of trees.

In the tech report
http://oz.berkeley.edu/users/breiman/randomforest2001.pdf, Breiman showed
that this technique is very competitive to boosting classification trees.
In our own experience, it is competitive with nonlinear classifiers such as
artificial neural nets and support vector machines.  Two of the significant
advantages of random forests over other methods (IMHO) are: a) there is only
one parameter (mtry) to adjust, and the result usually not sensititve to it;
and b) the built-in cross-validation via the use of out-of-bag data gives
quite accurate estimate of test set error, and offers quite effective
protection against overfitting.

The code is based on version 3.1 of the original Fortran code written by
Breiman and Cutler (http://www.stat.berkeley.edu/users/breiman/).  The User
Guide for the Fortran code on Breiman's web site explains some of the
facilities provided in the code (such as assessing variable importance, and
proximity measures).  Some facilities provided in the original Fortran code
have be taken out:  transforming data to principal components, and
multidimensional scaling of the "proximity" matrix.  These can easily be
done in R before and after calls to the random forest functions.  Random
numbers are generated by R's RNG, rather than the one supplied in the
original Fortran code.

I'd like to thank Profs. B. D. Ripley, J. Lindsey, and others on R-help that
answered many of my questions when I was working on this package.  The
formula interface and part of the code in the predict method are out-right
"stolen" from svm() in the e1071 package and nnet() in the VR bundle.

Questions/comments/bugs/patches welcomed!

Regards,
Andy
Andy I. Liaw, PhD
Biometrics Research          Phone: (732) 594-0820
Merck & Co., Inc.              Fax: (732) 594-1565
P.O. Box 2000, RY70-38            Rahway, NJ 07065
mailto:andy_liaw at merck.com



----------------------------------------------------------------------------
--
Notice: This e-mail message, together with any attachments, contains
information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that
may be confidential, proprietary copyrighted and/or legally privileged, and
is intended solely for the use of the individual or entity named on this
message.  If you are not the intended recipient, and have received this
message in error, please immediately return this by e-mail and then delete
it.

============================================================================
==

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-announce mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-announce-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lecca at science.unitn.it  Fri Apr  5 11:02:21 2002
From: lecca at science.unitn.it (Lecca Paola)
Date: Fri, 5 Apr 2002 11:02:21 +0200 (MET DST)
Subject: [R] uncorrect image dimension
Message-ID: <Pine.OSF.4.30.0204051053440.7563-100000@science.unitn.it>

Hi !

I'm performing kriging on a squared grid 12cm x 12cm. Each cell of the
grid is 0.5cm x 0.5cm.

I'm using sgeostat package "krige" funtion. When I plot the kriging
predictions the image occupies only the upper corner of my grid. I don't
understand my error.

The code of my script is

grid <- list(x=seq(-6,6,by=0.5),y=seq(-6,6,by=0.5))

grid$xr <- range(grid$x)
grid$xs <- grid$xr[2] - grid$xr[1]
grid$yr <- range(grid$y)
grid$ys <- grid$yr[2] - grid$yr[1]
grid$max <- max(grid$xs, grid$ys)
grid$xy <- data.frame(cbind(c(matrix(grid$x, length(grid$x),
length(grid$y))), c(matrix(grid$y, length(grid$x), length(grid$y),
byrow=T))))

colnames(grid$xy) <- c("x", "y")
grid$point <- point(grid$xy)

grid$krige <-krige(grid$point, dbpoint, variomd, at="Counts")

Thanks,
Paola.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From clange at epost.de  Fri Apr  5 14:41:54 2002
From: clange at epost.de (Christoph Lange)
Date: Fri, 5 Apr 2002 14:41:54 +0200
Subject: [R] Still needing help with LDA
In-Reply-To: <Pine.LNX.4.31.0204031457310.11926-100000@gannet.stats>; from ripley@stats.ox.ac.uk on Wed, Apr 03, 2002 at 03:08:41PM +0100
References: <20020403154248.A15629@rivka.biologie.fu-berlin.de> <Pine.LNX.4.31.0204031457310.11926-100000@gannet.stats>
Message-ID: <20020405144154.B31526@rivka.biologie.fu-berlin.de>

(reply to ripley at stats.ox.ac.uk)

> on wed, 3 apr 2002, christoph lange wrote:
> 
> [...]
>
> > can anybody help me to get equivalent outputs of wilks' lambda in r as
> > in spss?
> 
> perhaps you could explain to us exactly what spss does.  `exactly' because
> we've already seen that spss's equivalent of summary.manova does not do
> what it says it does ....  but one possibility is that you just need to do
> summary(manova(data ~ grouping), test="wilks"), which will test if there
> is a difference between the groups.  as in
> 
> data(iris)
> x <- as.matrix(iris[-5])
> summary(manova(x ~ iris$species), test="wilks")

Thanks a lot for your help so far. But, alas, I'm still stuck in the
statistical swamp of synonyms and other horrible things.

Below I send a sample output of SPSS's discriminant analysis.

What I'd need are measures for how much of the group differences one
DF explains, as the eigenvalues below (is this, perhaps, somehow
connected to what R puts out as "Proportion of trace"?)

A second thing would be something like the "structure matrix" below,
by some called loadings (that's what I meant with synonyms ...) to see
which variable contributes most to each function.


... hope I don't bother you too much.

  Yours,

     Christoph.

=========================================================================
eigenvalues
 ?
 | -------- | ---------- | ------------- | ------------ | ----------
 | function | eigenvalue | % of variance | cumulative % | canonical 
 |          |            |               |              | correlation
 | -------- | ---------- | ------------- | ------------ | ----------
 | 1        | 15.562(a)  | 81.3          | 81.3         | .969      
 | -------- | ---------- | ------------- | ------------ | ----------
 | 2        | 2.564(a)   | 13.4          | 94.7         | .848      
 | -------- | ---------- | ------------- | ------------ | ----------
 | 3        | .514(a)    | 2.7           | 97.3         | .583      
 | -------- | ---------- | ------------- | ------------ | ----------
 | 4        | .265(a)    | 1.4           | 98.7         | .458      
 | -------- | ---------- | ------------- | ------------ | ----------
 | 5        | .140(a)    | .7            | 99.5         | .350      
 | -------- | ---------- | ------------- | ------------ | ----------
 | 6        | .069(a)    | .4            | 99.8         | .255      
 | -------- | ---------- | ------------- | ------------ | ----------
 | 7        | .034(a)    | .2            | 100.0        | .181      
 | -------- | ---------- | ------------- | ------------ | ----------
 | 8        | .002(a)    | .0            | 100.0        | .044      
 | -------- | ---------- | ------------- | ------------ | ----------

a first 8 canonical discriminant functions were used in the analysis.

wilks' lambda
 ?
 | ------------------- | ------------- | ---------- | -- | ---- | 
 | test of function(s) | wilks' lambda | chi-square | df | sig. | 
 | ------------------- | ------------- | ---------- | -- | ---- | 
 | 1 through 8         | .007          | 446.493    | 72 | .000 | 
 | ------------------- | ------------- | ---------- | -- | ---- | 
 | 2 through 8         | .116          | 193.853    | 56 | .000 | 
 | ------------------- | ------------- | ---------- | -- | ---- | 
 | 3 through 8         | .413          | 79.479     | 42 | .000 | 
 | ------------------- | ------------- | ---------- | -- | ---- | 
 | 4 through 8         | .626          | 42.155     | 30 | .069 | 
 | ------------------- | ------------- | ---------- | -- | ---- | 
 | 5 through 8         | .792          | 20.980     | 20 | .398 | 
 | ------------------- | ------------- | ---------- | -- | ---- | 
 | 6 through 8         | .903          | 9.204      | 12 | .685 | 
 | ------------------- | ------------- | ---------- | -- | ---- | 
 | 7 through 8         | .965          | 3.160      | 6  | .789 | 
 | ------------------- | ------------- | ---------- | -- | ---- | 
 | 8                   | .998          | .171       | 2  | .918 | 
 | ------------------- | ------------- | ---------- | -- | ---- | 

standardized canonical discriminant function coefficients
 ?
 | ------ | ---------------------------------------------------------------- | 
 |        | function                                                         | 
 |        | ----- | ----- | ----- | ------ | ----- | ------ | ----- | ------ | 
 |        | 1     | 2     | 3     | 4      | 5     | 6      | 7     | 8      | 
 | ------ | ----- | ----- | ----- | ------ | ----- | ------ | ----- | ------ | 
 | int1   | .141  | .231  | -.164 | .538   | .374  | .285   | -.553 | -.525  | 
 | ------ | ----- | ----- | ----- | ------ | ----- | ------ | ----- | ------ | 
 | int2   | -.091 | -.026 | 1.162 | .362   | .173  | -.229  | .113  | -.056  | 
 | ------ | ----- | ----- | ----- | ------ | ----- | ------ | ----- | ------ | 
 | int3   | .443  | .271  | -.120 | 1.320  | -.256 | .975   | .506  | .233   | 
 | ------ | ----- | ----- | ----- | ------ | ----- | ------ | ----- | ------ | 
 | int4   | .461  | 1.054 | .513  | .623   | -.160 | 1.670  | -.090 | .638   | 
 | ------ | ----- | ----- | ----- | ------ | ----- | ------ | ----- | ------ | 
 | int5   | .172  | .651  | .010  | .790   | .127  | -.035  | -.024 | .847   | 
 | ------ | ----- | ----- | ----- | ------ | ----- | ------ | ----- | ------ | 
 | int6   | .080  | .818  | -.154 | .017   | .417  | .384   | .645  | -.088  | 
 | ------ | ----- | ----- | ----- | ------ | ----- | ------ | ----- | ------ | 
 | minint | 1.006 | -.471 | -.527 | -.483  | -.071 | -.013  | -.094 | .079   | 
 | ------ | ----- | ----- | ----- | ------ | ----- | ------ | ----- | ------ | 
 | maxint | -.699 | -.552 | -.271 | -1.367 | -.589 | -2.077 | -.176 | -1.061 | 
 | ------ | ----- | ----- | ----- | ------ | ----- | ------ | ----- | ------ | 

structure matrix
(last two functions cut off for e-mail line length ;-)
 ?
 | ------- | -----------------------------------------------------------
 |         | function                                                   
 |         | ------- | ------- | ------- | ----- | -------- | -------- |
 |         | 1       | 2       | 3       | 4     | 5        | 6        |
 | ------- | ------- | ------- | ------- | ----- | -------- | -------- |
 | minint  | .961(*) | -.005   | .078    | -.159 | .010     | -.205    |
 | ------- | ------- | ------- | ------- | ----- | -------- | -------- |
 | time(a) | .447    | .634(*) | .091    | .246  | -.441    | -.213    |
 | ------- | ------- | ------- | ------- | ----- | -------- | -------- |
 | int2    | .480    | -.031   | .752(*) | .119  | .164     | -.277    |
 | ------- | ------- | ------- | ------- | ----- | -------- | -------- |
 | maxint  | .232    | .489    | .050    | .014  | -.689(*) | -.328    |
 | ------- | ------- | ------- | ------- | ----- | -------- | -------- |
 | int4    | .187    | .515    | .271    | -.272 | -.633(*) | .196     |
 | ------- | ------- | ------- | ------- | ----- | -------- | -------- |
 | int3    | .161    | -.096   | -.128   | .520  | -.611(*) | -.044    |
 | ------- | ------- | ------- | ------- | ----- | -------- | -------- |
 | int5    | .201    | .444    | -.137   | .274  | .035     | -.599(*) |
 | ------- | ------- | ------- | ------- | ----- | -------- | -------- |
 | int6    | .210    | .499    | -.065   | -.207 | .448     | -.090    |
 | ------- | ------- | ------- | ------- | ----- | -------- | -------- |
 | int1    | .213    | .230    | -.107   | .313  | .316     | -.069    |
 | ------- | ------- | ------- | ------- | ----- | -------- | -------- |

pooled within-groups correlations between discriminating variables and
standardized canonical discriminant functions variables ordered by
absolute size of correlation within function. 
* largest absolute correlation between each variable and any
* discriminant function
a this variable not used in the analysis.
=========================================================================

-- 
Christoph Lange                                    clange at epost.de
Verhaltensbiologie, FU Berlin                            838-55068
Haderslebener Str. 9, 12163 Berlin
http://www.verhaltensbiologie.fu-berlin.de/
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dieter.menne at menne-biomed.de  Fri Apr  5 16:23:43 2002
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Fri, 5 Apr 2002 16:23:43 +0200
Subject: [R] Something like se.contrast.lme?
Message-ID: <JLEPLGAANFCEAEDCAGJNKEMFCBAA.dieter.menne@menne-biomed.de>

> Is there an equivalent to se.contrast.aov (base) that works with lme?

Gregory Warnes (aka gregmisc) pointed me to his function "estimable".
He will check if contrast.lm can be fixed to work with lme.


Dieter

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From roger at ysidro.econ.uiuc.edu  Fri Apr  5 16:54:11 2002
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Fri, 5 Apr 2002 08:54:11 -0600 (CST)
Subject: [R] rbind(NULL,NULL)
Message-ID: <Pine.GSO.4.33.0204050838410.5065-100000@ysidro.econ.uiuc.edu>


In the time honored spirit of wishing to do nothing well, could I suggest
that the Splus (versions 5 and 6)  response to:

> rbind(NULL,NULL)
NULL

is preferable to the R response:

> rbind(NULL,NULL)
Error in rbind(NULL, NULL) : attempt to set an attribute on NULL

This is on:

platform sparc-sun-solaris2.8
arch     sparc
os       solaris2.8
system   sparc, solaris2.8
status
major    1
minor    4.1
year     2002
month    01
day      30
language R

It is tempting to conclude from this that Splus does nothing better than R,
but it is always dangerous to generalize from one example.


url:	http://www.econ.uiuc.edu		Roger Koenker
email	roger at ysidro.econ.uiuc.edu		Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tklistaddr at keittlab.bio.sunysb.edu  Fri Apr  5 17:21:19 2002
From: tklistaddr at keittlab.bio.sunysb.edu (Timothy H. Keitt)
Date: 05 Apr 2002 10:21:19 -0500
Subject: [R] weighted 2 or 3 parameter weibull estimation?
In-Reply-To: <01c701c1dc72$378e2710$01000001@godzilla>
References: <01c701c1dc72$378e2710$01000001@godzilla>
Message-ID: <1018020079.14132.3.camel@keittlab-6>

Without knowing your cost function (i.e., that passed to optim) its hard
to help.

T.

On Fri, 2002-04-05 at 02:19, Jeff D. Hamann wrote:
> 
>   I've figured out how to use optim (barely) to estimate 2 parameter =
>   weibull distributions. I can't get over how easy this is. What I need to =
>   do is use a weight in the observations.....
> 
>   For example,=20
> 
>   the tree diameters and weights are are=20
> 
>   4.70 , 100
>   6.00, 98
>   7.10,  75.0
>   8.10, 86.3
>   8.60, 80.456
>   8.90, 20.5
>   9.50, 16.6
>   11.40, 12.657
>   11.80, 12.47
>   14.50, 8.98
>   16.00,4.5
>   16.90,2.36
>   18.90, 0.256
> 
>   which yield
> 
>  LOCATION =3D   0.0000              MEAN =3D   10.9921
>     SCALE =3D  12.3436          VARIANCE =3D   18.0027
>     SHAPE =3D   2.8050          SKEWNESS =3D    0.2354
> 
>   which are the values without the weights. I can't find any reference to =
>   weights in the optim function and I'm afraid I'm a little stuck here. =
>   After I figure out how to include the weights, I'll then need to =
>   estimate the 3-parameter estimates. Any help would be greatful.=20
> 
>   Thanks,
>   Jeff.
> 
> 
> Jeff D. Hamann
> Hamann, Donald & Associates, Inc.
> PO Box 1421
> Corvallis, Oregon USA 97339-1421
> Bus. 541-753-7333
> Cell. 541-740-5988
> jeff_hamann at hamanndonald.com
> www.hamanndonald.com
> 
> 
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From iku713 at yahoo.com  Fri Apr  5 20:55:57 2002
From: iku713 at yahoo.com (S. YU)
Date: Fri, 5 Apr 2002 10:55:57 -0800 (PST)
Subject: [R] Rgui.exe cannot start on Win2000 professional vesion!
Message-ID: <20020405185557.60623.qmail@web13401.mail.yahoo.com>

Dear R-ers:
I'm sorry to disturb you, I downloaded the
latest version R1.401 binary on my win2000
professional, after installation, when I click the
shortcut on the desktop to start R, it says:

Rgui.exe Application Error
The instruction at '0x780027oe' referenced memory at
'0x00000000'. The memory could not be read.
click on Ok to terminate the program
click on CANCEL to debug the program.

so what's the problem on earth?!
Thank you in advance!
Sincerely,
S.YU


__________________________________________________

Yahoo! Tax Center - online filing with TurboTax

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From steve at biostat.ucsf.edu  Fri Apr  5 22:23:35 2002
From: steve at biostat.ucsf.edu (Steve Shiboski)
Date: Fri, 5 Apr 2002 12:23:35 -0800
Subject: [R] randomForest() segfaults under Solaris(SPARC) 2.7
Message-ID: <20020405202335.GA11586@chanane.ucsf.edu>

Invocation of randomForest() using the iris example in the help
file crashes R with a segmentation fault. This happens on
all of our ultraSPARC machines running Solaris 2.7.

We're using R-1.4.1, compiled using Sun cc and f77 and
the flags:

CC=cc
CFLAGS="-xO5 -xlibmil -dalign"
FC=f77
FFLAGS="-xO5 -xlibmil -dalign"

"make check" runs withour errors, and R has been working
well for all other applications/installations.

Incidentally, randomForest() runs fine on one of our ultraSPARC machines 
running Solaris 2.6 and R-1.4.1 compiled using the same compilers and flags.
It also reportedly works if gcc/g77 are used.

Any suggestions appreciated.

-- 
Stephen Shiboski  -------------------  steve at biostat.ucsf.edu
Division of Biostatistics                 voice: 415-476-0533
University of California, San Francisco     fax: 415-476-6014
500 Parnassus Avenue, MU 420-W;  San Francisco, CA 94143-0560
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From robut at forest.go.th  Sat Apr  6 07:03:46 2002
From: robut at forest.go.th (Robert Cunningham)
Date: Sat, 6 Apr 2002 12:03:46 +0700
Subject: [R] white in the default palette
Message-ID: <FAD37E46320F154CA434D82BBFE41CE014C6C0@dc-server.forest.go.th>

Dear All,

I recently encountered a problem (actually missed some data) because
"white" is one of colours in the "default" palette and that does not
show up to well on my transparent (on white background). Of course it is
easily fixed but I think white should not be a default colour.


> palette("default")
> palette()
[1] "black"   "red"     "green3"  "blue"    "cyan"    "magenta" "yellow"

[8] "white"  
> par()$bg
[1] "transparent"
> 

> version
         _              
platform i386-pc-mingw32
arch     x86            
os       Win32          
system   x86, Win32     
status                  
major    1              
minor    4.1            
year     2002           
month    01             
day      30             
language R              


Cheers,
Robert Cunningham
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jeff_hamann at hamanndonald.com  Sat Apr  6 09:19:02 2002
From: jeff_hamann at hamanndonald.com (Jeff D. Hamann)
Date: Fri, 5 Apr 2002 23:19:02 -0800
Subject: [R] weighted 2 or 3 parameter weibull estimation?
Message-ID: <000701c1dd3b$545e7510$01000001@godzilla>

Subject: Re: [R] weighted 2 or 3 parameter weibull estimation?

Without knowing your cost function (i.e., that passed to optim) its hard
to help.

T.


Here's what I used to obtain my estimates:


# estimate the two parameter weibull
loglike <- function(p) -2*sum(dweibull(expf,p[1],p[2],log=T))
est <- optim( c(1,5), loglike )

as I mentioned, I'm very much a newbie at using optim (and maybe less so
with R), but I hope this help answer your question.

Thanks,
Jeff.



>   I've figured out how to use optim (barely) to estimate 2 parameter =
>   weibull distributions. I can't get over how easy this is. What I need to
=
>   do is use a weight in the observations.....
>
>   For example,=20
>
>   the tree diameters and weights are are=20
>
>   4.70 , 100
>   6.00, 98
>   7.10,  75.0
>   8.10, 86.3
>   8.60, 80.456
>   8.90, 20.5
>   9.50, 16.6
>   11.40, 12.657
>   11.80, 12.47
>   14.50, 8.98
>   16.00,4.5
>   16.90,2.36
>   18.90, 0.256
>
>   which yield
>
>  LOCATION =3D   0.0000              MEAN =3D   10.9921
>     SCALE =3D  12.3436          VARIANCE =3D   18.0027
>     SHAPE =3D   2.8050          SKEWNESS =3D    0.2354
>
>   which are the values without the weights. I can't find any reference to
=
>   weights in the optim function and I'm afraid I'm a little stuck here. =
>   After I figure out how to include the weights, I'll then need to =
>   estimate the 3-parameter estimates. Any help would be greatful.=20
>
>   Thanks,
>   Jeff.



Jeff D. Hamann
Hamann, Donald & Associates, Inc.
PO Box 1421
Corvallis, Oregon USA 97339-1421
Bus. 541-753-7333
Cell. 541-740-5988
jeff_hamann at hamanndonald.com
www.hamanndonald.com


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sat Apr  6 10:03:24 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Sat, 6 Apr 2002 09:03:24 +0100 (GMT Daylight Time)
Subject: [R] Rgui.exe cannot start on Win2000 professional vesion!
In-Reply-To: <20020405185557.60623.qmail@web13401.mail.yahoo.com>
Message-ID: <Pine.WNT.4.44.0204060902010.1288-100000@tern.stats>

I don't know, except to say it is not at all a common problem and most
likely due to corrupt software on your system.  Please read through the
rw-FAQ and try the workaround suggested there.

On Fri, 5 Apr 2002, S. YU wrote:

> Dear R-ers:
> I'm sorry to disturb you, I downloaded the
> latest version R1.401 binary on my win2000
> professional, after installation, when I click the
> shortcut on the desktop to start R, it says:
>
> Rgui.exe Application Error
> The instruction at '0x780027oe' referenced memory at
> '0x00000000'. The memory could not be read.
> click on Ok to terminate the program
> click on CANCEL to debug the program.
>
> so what's the problem on earth?!
> Thank you in advance!
> Sincerely,
> S.YU
>
>
> __________________________________________________
>
> Yahoo! Tax Center - online filing with TurboTax
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sat Apr  6 14:02:40 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat, 6 Apr 2002 13:02:40 +0100 (BST)
Subject: [R] weighted 2 or 3 parameter weibull estimation?
In-Reply-To: <000701c1dd3b$545e7510$01000001@godzilla>
Message-ID: <Pine.LNX.4.31.0204061256050.25601-100000@gannet.stats>

On Fri, 5 Apr 2002, Jeff D. Hamann wrote:

> Subject: Re: [R] weighted 2 or 3 parameter weibull estimation?
>
> Without knowing your cost function (i.e., that passed to optim) its hard
> to help.
>
> T.
>
>
> Here's what I used to obtain my estimates:
>
>
> # estimate the two parameter weibull
> loglike <- function(p) -2*sum(dweibull(expf,p[1],p[2],log=T))
> est <- optim( c(1,5), loglike )
>
> as I mentioned, I'm very much a newbie at using optim (and maybe less so
> with R), but I hope this help answer your question.

fitdistr in package MASS would be even easier.

I'm afraid I don't understand your weights here.  I can understand integer
weights (where weight 3 means `I have three cases like this one'), where
one just uses

loglike <- function(p, wt) -2*sum(wt * dweibull(expf,p[1],p[2],log=T))
est <- optim( c(1,5), loglike, wt=wt )

But your example looks much more like a bivariate problem.

>
> Thanks,
> Jeff.
>
>
>
> >   I've figured out how to use optim (barely) to estimate 2 parameter =
> >   weibull distributions. I can't get over how easy this is. What I need to
> =
> >   do is use a weight in the observations.....
> >
> >   For example,=20
> >
> >   the tree diameters and weights are are=20
> >
> >   4.70 , 100
> >   6.00, 98
> >   7.10,  75.0
> >   8.10, 86.3
> >   8.60, 80.456
> >   8.90, 20.5
> >   9.50, 16.6
> >   11.40, 12.657
> >   11.80, 12.47
> >   14.50, 8.98
> >   16.00,4.5
> >   16.90,2.36
> >   18.90, 0.256
> >
> >   which yield
> >
> >  LOCATION =3D   0.0000              MEAN =3D   10.9921
> >     SCALE =3D  12.3436          VARIANCE =3D   18.0027
> >     SHAPE =3D   2.8050          SKEWNESS =3D    0.2354
> >
> >   which are the values without the weights. I can't find any reference to
> =
> >   weights in the optim function and I'm afraid I'm a little stuck here. =
> >   After I figure out how to include the weights, I'll then need to =
> >   estimate the 3-parameter estimates. Any help would be greatful.=20
> >
> >   Thanks,
> >   Jeff.
>
>
>
> Jeff D. Hamann
> Hamann, Donald & Associates, Inc.
> PO Box 1421
> Corvallis, Oregon USA 97339-1421
> Bus. 541-753-7333
> Cell. 541-740-5988
> jeff_hamann at hamanndonald.com
> www.hamanndonald.com
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rikkoe at softhome.net  Sat Apr  6 21:42:23 2002
From: rikkoe at softhome.net (Rikkoe@softhome.net)
Date: Sat, 6 Apr 2002 21:42:23 +0200
Subject: [R] Keep labels when importing data from SPSS?
Message-ID: <01d901c1dda3$2e012800$2317b43e@user2soggyji1z>

Do you know if there is a way to keep all value labels and variable lables
when importing data from SPSS? I tried the function read.spss from the
package "foreign",  but only got the numbers and not the labels.

Thanks for any hint!

Michael


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From abunn at montana.edu  Sat Apr  6 22:41:01 2002
From: abunn at montana.edu (Andy Bunn)
Date: Sat, 6 Apr 2002 13:41:01 -0700
Subject: [R] read.table and trouble
Message-ID: <NEBBIPHDAMMOKDKPOFFIAEIOCFAA.abunn@montana.edu>

Hi all,

I'm porting a library I wrote in S-plus over to R. All but one of the
functions work fine. The only one that doesn't is really giving me a
headache. I'm admitting defeat. Can anybody help?

Object example3 has been read in using read.table. The statement works fine
in S-Plus.
When I run the same statement in R the column Prefix, which is read in using
the
as.character coercion, is wacky. It reads in as numeric.

> example3
   nRows nWaves nYears Noise  Amp Freq AmpTwo FreqTwo  Prefix
1      1      1   1000  0.02 0.01    2     NA      NA  "test"
2      2      1   1000  0.02 0.02    2     NA      NA "test2"
3      3      1   1000  0.02 0.03    2     NA      NA      NA
4      4      1   1000  0.02 0.04    2     NA      NA      NA
5      5      1   1000  0.02 0.05    2     NA      NA      NA
6      6      1   1000  0.02 0.06    2     NA      NA      NA
7      7      1   1000  0.02 0.07    2     NA      NA      NA
8      8      1   1000  0.02 0.08    2     NA      NA      NA
9      9      1   1000  0.02 0.09    2     NA      NA "test3"
10    10      1   1000  0.02 0.10    2     NA      NA      NA
11    11      2   1000  0.02 0.01    2   0.01       5      NA
12    12      2   1000  0.02 0.02    2   0.02       5      NA
13    13      2   1000  0.02 0.03    2   0.03       5      NA
14    14      2   1000  0.02 0.04    2   0.04       5      NA
15    15      2   1000  0.02 0.05    2   0.05       5      NA
16    16      2   1000  0.02 0.06    2   0.06       5      NA
17    17      2   1000  0.02 0.07    2   0.07       5      NA
18    18      2   1000  0.02 0.08    2   0.08       5      NA
19    19      2   1000  0.02 0.09    2   0.09       5      NA
20    20      2   1000  0.02 0.10    2   0.10       5      NA
> attach(example3)
> Prefix[1]
[1] 3
> Prefix[2]
[1] NA
> is.numeric(Prefix[1])
[1] TRUE
> is.character(Prefix[1])
[1] FALSE


Here's the read.table command:

DriverTable <- read.table(file = DriverFile, header = T, sep = ",",
row.names = NULL, na.strings = "NA")

I then pass a bunch of arguments to another function like so:

for(i in 1:length(nRows))
	{
		RingSim(nWaves[i], nYears[i], Noise[i], Amp[i], Freq[i], AmpTwo[i],
FreqTwo[i], as.character(Prefix[i]))
	}

This works in S. All the variables (nWaves, nYears, etc.) are numeric except
Prefix. How can I read Prefix in correctly - that is as a string.

Here's the file that is read in:

nRows, nWaves, nYears, Noise, Amp, Freq, AmpTwo, FreqTwo, Prefix
1,1,1000,0.02,0.01,2,NA,NA,test1
2,1,1000,0.02,0.02,2,NA,NA,test2
3,1,1000,0.02,0.03,2,NA,NA,NA
4,1,1000,0.02,0.04,2,NA,NA,test3
5,1,1000,0.02,0.05,2,NA,NA,NA
6,1,1000,0.02,0.06,2,NA,NA,NA
7,1,1000,0.02,0.07,2,NA,NA,NA
8,1,1000,0.02,0.08,2,NA,NA,NA
9,1,1000,0.02,0.09,2,NA,NA,test4
10,1,1000,0.02,0.1,2,NA,NA,NA
11,2,1000,0.02,0.01,2,0.01,5,NA
12,2,1000,0.02,0.02,2,0.02,5,NA
13,2,1000,0.02,0.03,2,0.03,5,NA
14,2,1000,0.02,0.04,2,0.04,5,NA
15,2,1000,0.02,0.05,2,0.05,5,NA
16,2,1000,0.02,0.06,2,0.06,5,NA
17,2,1000,0.02,0.07,2,0.07,5,NA
18,2,1000,0.02,0.08,2,0.08,5,NA
19,2,1000,0.02,0.09,2,0.09,5,NA
20,2,1000,0.02,0.1,2,0.1,5,NA

Why on earth is everything read in correctly except the Prefix column? Why
does Prefix[1] return 3 and the rest of the column is NA?

Thanks in advance,
Andy

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Sat Apr  6 23:41:27 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 06 Apr 2002 23:41:27 +0200
Subject: [R] read.table and trouble
In-Reply-To: <NEBBIPHDAMMOKDKPOFFIAEIOCFAA.abunn@montana.edu>
References: <NEBBIPHDAMMOKDKPOFFIAEIOCFAA.abunn@montana.edu>
Message-ID: <x2it745wu0.fsf@blueberry.kubism.ku.dk>

"Andy Bunn" <abunn at montana.edu> writes:

> > attach(example3)
> > Prefix[1]
> [1] 3
> > Prefix[2]
> [1] NA
> > is.numeric(Prefix[1])
> [1] TRUE
> > is.character(Prefix[1])
> [1] FALSE
> 
> 
> Here's the read.table command:
> 
> DriverTable <- read.table(file = DriverFile, header = T, sep = ",",
> row.names = NULL, na.strings = "NA")
> 
...
> This works in S. All the variables (nWaves, nYears, etc.) are numeric except
> Prefix. How can I read Prefix in correctly - that is as a string.
> 
> Here's the file that is read in:
> 
> nRows, nWaves, nYears, Noise, Amp, Freq, AmpTwo, FreqTwo, Prefix
> 1,1,1000,0.02,0.01,2,NA,NA,test1
> 2,1,1000,0.02,0.02,2,NA,NA,test2
> 3,1,1000,0.02,0.03,2,NA,NA,NA
> 4,1,1000,0.02,0.04,2,NA,NA,test3
...
> Why on earth is everything read in correctly except the Prefix column? Why
> does Prefix[1] return 3 and the rest of the column is NA?

It reads as expected for me. Are you sure there isn't another Prefix
variable around? (attach() attaches at position 2, *after* the global
environment). 

> zz <- read.csv("xyzzy.dat") # should suffice
> attach(zz)
> Prefix[1]
[1] test1
Levels:  test1 test2 test3 test4 
>  Prefix[2]
[1] test2
Levels:  test1 test2 test3 test4 
> is.numeric(Prefix[1])
[1] FALSE
>  is.character(Prefix[1])
[1] FALSE

(notice that it is a factor, not an character vector).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From makram.talih at yale.edu  Sun Apr  7 01:07:00 2002
From: makram.talih at yale.edu (Makram Talih)
Date: Sat, 6 Apr 2002 18:07:00 -0500 (EST)
Subject: [R] An R (or S) to C/C++ translator?
In-Reply-To: <200204060201.EAA10275@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.44.0204061800340.11906-100000@ares.its.yale.edu>

Hello,

Is there an R (or S) to C/C++ translator in the spirit of the one found in
Matlab? [I would like to avoid re-writing my entire R code in C.] If not,
are there any plans to implement such a thing?

Thank you for any suggestions that you may have.

Regards,

Makram Talih

Yale University (Statistics)


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From feldesmanm at pdx.edu  Sun Apr  7 03:39:53 2002
From: feldesmanm at pdx.edu (Marc R. Feldesman)
Date: Sat, 06 Apr 2002 17:39:53 -0800
Subject: [R] save.image() error
Message-ID: <5.1.0.14.2.20020406173644.00b85120@pop4.attglobal.net>

Running 1.4.1 (Windows) under Windows XP Pro.  Have had no difficulty for 
several weeks since moving to the new OS.  Today, while checking the 
behavior of my mouse, I loaded Rgui as usual.  I then immediately tried to 
exit the program.  Upon exiting, I got the following message:

Error in save.image(name) : image could not be renamed and is left in .RDataTmp

I can move the .RData file to any other machine and use it without 
difficulty, which suggests that the file itself is not corrupt.  Since I 
didn't do anything (that I'm aware of) to precipitate this error -- I 
haven't installed or updated any packages for a few weeks -- I'm a bit 
baffled by the error.

What is its cause and what are the suggested "cures".

Thanks for your help.


Dr. Marc R. Feldesman
email:  feldesmanm at pdx.edu
email:  feldesman at attglobal.net
fax:    503-725-3905

"Don't know where I'm going.
Don't like where I've been.
There may be no exit.
But hell, I'm going in."  Jimmy Buffett

Powered by Superchoerus - the 700 MHz Coppermine Box

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From feldesmanm at pdx.edu  Sun Apr  7 03:48:20 2002
From: feldesmanm at pdx.edu (Marc R. Feldesman)
Date: Sat, 06 Apr 2002 17:48:20 -0800
Subject: [R] save.image() followup
Message-ID: <5.1.0.14.2.20020406174516.00bbb3c0@pop4.attglobal.net>

I have no difficulty using save.image() from the pull down menus.  It is 
only when I try to q() that I run into this problem.  The *one* thing that 
has changed about my system is that I did install a new mouse (Microsoft 
Intellimouse Explorer 3.0 - an optical mouse).  That hardly explains this 
problem, but is the one difference in my system that I can think of since 
the last time I used R 1.4.1




Dr. Marc R. Feldesman
email:  feldesmanm at pdx.edu
email:  feldesman at attglobal.net
fax:    503-725-3905

"Don't know where I'm going.
Don't like where I've been.
There may be no exit.
But hell, I'm going in."  Jimmy Buffett

Powered by Tyrannochoerus - the 2.2 GHz WinXPP Box

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sun Apr  7 13:25:26 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun, 7 Apr 2002 12:25:26 +0100 (BST)
Subject: [R] save.image() error
In-Reply-To: <5.1.0.14.2.20020406173644.00b85120@pop4.attglobal.net>
Message-ID: <Pine.LNX.4.31.0204071212170.7823-100000@gannet.stats>

On Sat, 6 Apr 2002, Marc R. Feldesman wrote:

> Running 1.4.1 (Windows) under Windows XP Pro.  Have had no difficulty for
> several weeks since moving to the new OS.  Today, while checking the
> behavior of my mouse, I loaded Rgui as usual.  I then immediately tried to
> exit the program.  Upon exiting, I got the following message:
>
> Error in save.image(name) : image could not be renamed and is left in .RDataTmp
>
> I can move the .RData file to any other machine and use it without
> difficulty, which suggests that the file itself is not corrupt.  Since I
> didn't do anything (that I'm aware of) to precipitate this error -- I
> haven't installed or updated any packages for a few weeks -- I'm a bit
> baffled by the error.
>
> What is its cause and what are the suggested "cures".

R 1.4.x saves the image as a temporary file, and then renames it to
.RData.  This is a precaution against wiping out a saved workspace
and then being unable to write out the current workspace, say from lack of
file space.

This mechanism can be over-ridden: see ?save.image.

In your case file.rename has failed.  Now file-renaming works better
on Unix than on Windows, and if Windows has the file open (or thinks it
has) it cannot be renamed.  So if you did this immediately, before the
command prompt had come up, from the menu or x button, you might get
a race condition.  (I've tried to reproduce that, but I can't even on my
slowest machine.)  It's not unknown for Windows to get confused and
need to be re-started (log out and in again on NT/2000/XP) to allow
files to be deleted.

The only known problems with using XP Pro are colour schemes (which are
not used as documented in even the latest SDK), and the need for a
manifest to get the XP version of the common controls (and there is one on
CRAN).  Both are resolved in R-devel, 1.5.0-to-be.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From steinep at uni-muenster.de  Sun Apr  7 15:41:44 2002
From: steinep at uni-muenster.de (Petra Steiner)
Date: Sun, 7 Apr 2002 15:41:44 +0200
Subject: [R] German umlaut in xlab
Message-ID: <002a01c1de39$f6405d40$53ecb080@oemcomputer>

Dear all,

which font do I have to choose to use German umlauts at x/ylab in plot? Do I
have to change Rdevga; and how? Or should I use these Hershey vectors?

I looked quite a long time for a solution, which should be easy, so I
thought I'd better ask here.
Maybe some other people have already solved this problem.

Regards,
Petra

-
---------------------------------------------------
Petra Steiner
Arbeitsbereich Linguistik
Universitaet Muenster
Huefferstrasse 27
48149  Muenster

Tel: 0251 / 83 39442
petra at marley.uni-muenster.de
http://santana.uni-muenster.de/~petra/


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sun Apr  7 16:20:02 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun, 7 Apr 2002 15:20:02 +0100 (BST)
Subject: [R] German umlaut in xlab
In-Reply-To: <002a01c1de39$f6405d40$53ecb080@oemcomputer>
Message-ID: <Pine.LNX.4.31.0204071511080.13306-100000@gannet.stats>

On Sun, 7 Apr 2002, Petra Steiner wrote:

> Dear all,
>
> which font do I have to choose to use German umlauts at x/ylab in plot? Do I
> have to change Rdevga; and how? Or should I use these Hershey vectors?

So you are using Windows: please do remember to tell us!

> I looked quite a long time for a solution, which should be easy, so I
> thought I'd better ask here.
> Maybe some other people have already solved this problem.

There is nothing to solve!  Did you try the obvious: enter the characters
from your keyboard in the xlab and ylab strings?   It should work, and
there are examples in ?text.

If this perchance does not work, please tell us a lot more details about
your system.  (It works even in English-language versions of Windows
95, 98, NT4, 2000 and XP to my knowledge.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Sun Apr  7 16:36:44 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 07 Apr 2002 16:36:44 +0200
Subject: [R] German umlaut in xlab
References: <002a01c1de39$f6405d40$53ecb080@oemcomputer>
Message-ID: <3CB0597C.DF4149F7@statistik.uni-dortmund.de>

Petra Steiner wrote:
> 
> Dear all,
> 
> which font do I have to choose to use German umlauts at x/ylab in plot? Do I
> have to change Rdevga; and how? Or should I use these Hershey vectors?
> 
> I looked quite a long time for a solution, which should be easy, so I
> thought I'd better ask here.
> Maybe some other people have already solved this problem.

plot(1:10, xlab="???") works for me (R-1.4.1 on WinNT4 and Linux) on
windows() and postscript() device.
In which case (and OS) does the problem appear?


Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From feldesmanm at pdx.edu  Sun Apr  7 18:21:03 2002
From: feldesmanm at pdx.edu (Marc R. Feldesman)
Date: Sun, 07 Apr 2002 09:21:03 -0700
Subject: [R] save.image() error
In-Reply-To: <Pine.LNX.4.31.0204071212170.7823-100000@gannet.stats>
References: <5.1.0.14.2.20020406173644.00b85120@pop4.attglobal.net>
Message-ID: <5.1.0.14.2.20020407091431.0171b2c0@pop4.attglobal.net>

At 04:25 AM 4/7/2002, ripley at stats.ox.ac.uk wrote:
 >On Sat, 6 Apr 2002, Marc R. Feldesman wrote:
 >
 >> Running 1.4.1 (Windows) under Windows XP Pro.  Have had no difficulty for
 >> several weeks since moving to the new OS.  Today, while checking the
 >> behavior of my mouse, I loaded Rgui as usual.  I then immediately tried to
 >> exit the program.  Upon exiting, I got the following message:
 >>
 >> Error in save.image(name) : image could not be renamed and is left in
 >.RDataTmp
 >>
 >> I can move the .RData file to any other machine and use it without
 >> difficulty, which suggests that the file itself is not corrupt.  Since I
 >> didn't do anything (that I'm aware of) to precipitate this error -- I
 >> haven't installed or updated any packages for a few weeks -- I'm a bit
 >> baffled by the error.
 >>
 >> What is its cause and what are the suggested "cures".
 >
 >R 1.4.x saves the image as a temporary file, and then renames it to
 >.RData.  This is a precaution against wiping out a saved workspace
 >and then being unable to write out the current workspace, say from lack of
 >file space.
 >
 >This mechanism can be over-ridden: see ?save.image.
 >
 >In your case file.rename has failed.  Now file-renaming works better
 >on Unix than on Windows, and if Windows has the file open (or thinks it
 >has) it cannot be renamed.  So if you did this immediately, before the
 >command prompt had come up, from the menu or x button, you might get
 >a race condition.  (I've tried to reproduce that, but I can't even on my
 >slowest machine.)  It's not unknown for Windows to get confused and
 >need to be re-started (log out and in again on NT/2000/XP) to allow
 >files to be deleted.
 >
 >The only known problems with using XP Pro are colour schemes (which are
 >not used as documented in even the latest SDK), and the need for a
 >manifest to get the XP version of the common controls (and there is one on
 >CRAN).  Both are resolved in R-devel, 1.5.0-to-be.


The "fix" in ?save.image solves the problem, but this seems to be a 
definite *issue* with Windows XP Pro.  I took the identical .RData file 
from the XP machine and moved it onto a machine with Windows NT 4, and two 
others running Windows 2000 Pro.  Neither of them evidence the problem 
"unfixed".  The XP Pro machine is a 2.2 GHz P4 running 1024 MB RAM and a 
120 GB Harddrive with about 100 GB free.  BTW, logging out of the XP box 
doesn't result in the temp files being erased.  Once created, I have to go 
in and manually delete them.

How is the behavior of "File|Save Image" different 
from >save.image("a.file.image.name")?  The former works without the "fix" 
while the latter fails unless I have the "fix" in place in the .RProfile

What is a "race" condition?

   

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sun Apr  7 18:31:35 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun, 7 Apr 2002 17:31:35 +0100 (BST)
Subject: [R] save.image() error
In-Reply-To: <5.1.0.14.2.20020407091431.0171b2c0@pop4.attglobal.net>
Message-ID: <Pine.LNX.4.31.0204071726270.15871-100000@gannet.stats>

On Sun, 7 Apr 2002, Marc R. Feldesman wrote:

> The "fix" in ?save.image solves the problem, but this seems to be a
> definite *issue* with Windows XP Pro.  I took the identical .RData file

For you.  I have never seen it on Windows XP Pro, and I use that as much
as 2000.  And that includes a dual-processor XP machine.

We have had no other reports.

> from the XP machine and moved it onto a machine with Windows NT 4, and two
> others running Windows 2000 Pro.  Neither of them evidence the problem
> "unfixed".  The XP Pro machine is a 2.2 GHz P4 running 1024 MB RAM and a
> 120 GB Harddrive with about 100 GB free.  BTW, logging out of the XP box
> doesn't result in the temp files being erased.  Once created, I have to go
> in and manually delete them.
>
> How is the behavior of "File|Save Image" different
> from >save.image("a.file.image.name")?  The former works without the "fix"
> while the latter fails unless I have the "fix" in place in the .RProfile

You have the sources ....  It actually calls save.image(), so I don't
think it is different in any way.  There is a difference between the cases
where the file already exists and when it does not.

> What is a "race" condition?

Two processes trying to access the same resource at the same time.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From feldesmanm at pdx.edu  Sun Apr  7 19:01:18 2002
From: feldesmanm at pdx.edu (Marc R. Feldesman)
Date: Sun, 07 Apr 2002 10:01:18 -0700
Subject: [R] save.image() error
In-Reply-To: <Pine.LNX.4.31.0204071726270.15871-100000@gannet.stats>
References: <5.1.0.14.2.20020407091431.0171b2c0@pop4.attglobal.net>
Message-ID: <5.1.0.14.2.20020407095341.0170bb88@pop4.attglobal.net>



Here is a followup to the save.image() problem.

The XP machine is configured differently than the other machines.  On all 
other machines, I created a \data subdirectory *under* the main \rw1041 
directory (on the same logical drive).  When I set up the XP machine, I had 
such a large hard drive that I partitioned it into several logical drives, 
one of which I designated as the "data repository".  There I created a 
directory called \r141data\treeproj (for example).  So, the program binary 
is in:

f:\rw1041\bin

The data reside in:

g:\R141data\treeproj

The "start in" directory has been changed to the "g" logical drive.  This 
arrangement fails.

However, if I move the data directory back to the same logical drive as the 
binary file, I don't have the save.image errors.

Is there some other setting that needs to be changed to get the binary to 
recognize that the data are on a different logical drive?


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hb at maths.lth.se  Sun Apr  7 19:14:00 2002
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Sun, 7 Apr 2002 19:14:00 +0200
Subject: [R] German umlaut in xlab
In-Reply-To: <3CB0597C.DF4149F7@statistik.uni-dortmund.de>
Message-ID: <KKEGJOGBELBHDIKPINBMAEHECLAA.hb@maths.lth.se>

I have the same problem on WinMe and R v1.4.1 with Swedish keyboard
settings:

  plot(1:10, xlab="???")

works in Rgui but not in Rterm under Cygwin bash where it instead prints
"quote down", "qoute up" and a "open box". However,

  plot(1:10, xlab="\344\366\374")

does the same thing. Trying

  print("\344\366\374")

"???" will not be shown. Again, with Rgui it works. So there seems to be
some differences in the character encoding etc for the upper ASCII half. I
noticed that when I changed my keyboard settings from Swedish to English the
plot call above works (but not the print call which I believe is due to my
Cygwin/bash settings).

To Petra Steiner: Use the following function to identify your wanted
characters and its ASCII integer code:

plotSymbols <- function() {
  i <- 0:255;
  ncol <-16;
  opar <- par(cex.axis=0.7, mar=c(3,3,3,3)+0.1)
  plot(i%%ncol, 1+i%/%ncol, pch=i, xlab="", ylab="", axes=FALSE)
  axis(1, at=0:15)
  axis(2, at=1:16, labels=0:15*16, las=2)
  axis(3, at=0:15)
  axis(4, at=1:16, labels=0:15*16+15, las=2)
  par(opar)
}

and then use

intToHex <- function(x) {
  x <- as.integer(x)
  class(x) <- "octmode"
  as.character(x)
}

to transform this integer to an octal numbers. For instance, your are
looking for "?" and from the plot you'll find that its ASCII value is 252,
which gives intToHex(252) equal to "\374" which is what you want to use in
your 'xlab' argument.

FYI: The plotSymbols() function generates the same results under Rgui and
Rterm and with any device driver.

Henrik Bengtsson

Dept. of Mathematical Statistics @ Centre for Mathematical Sciences
Lund Institute of Technology/Lund University, Sweden (+2h UTC)
Office: P316, +46 46 222 9611 (phone), +46 46 222 4623 (fax)
h b @ m a t h s . l t h . s e, http://www.maths.lth.se/bioinformatics/


> -----Original Message-----
> From: owner-r-help at stat.math.ethz.ch
> [mailto:owner-r-help at stat.math.ethz.ch]On Behalf Of Uwe Ligges
> Sent: Sunday, April 07, 2002 4:37 PM
> To: Petra Steiner
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] German umlaut in xlab
>
>
> Petra Steiner wrote:
> >
> > Dear all,
> >
> > which font do I have to choose to use German umlauts at x/ylab
> in plot? Do I
> > have to change Rdevga; and how? Or should I use these Hershey vectors?
> >
> > I looked quite a long time for a solution, which should be easy, so I
> > thought I'd better ask here.
> > Maybe some other people have already solved this problem.
>
> plot(1:10, xlab="???") works for me (R-1.4.1 on WinNT4 and Linux) on
> windows() and postscript() device.
> In which case (and OS) does the problem appear?
>
>
> Uwe Ligges
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sun Apr  7 19:56:08 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun, 7 Apr 2002 18:56:08 +0100 (BST)
Subject: [R] German umlaut in xlab
In-Reply-To: <KKEGJOGBELBHDIKPINBMAEHECLAA.hb@maths.lth.se>
Message-ID: <Pine.LNX.4.31.0204071841510.16034-100000@gannet.stats>

On Sun, 7 Apr 2002, Henrik Bengtsson wrote:

> I have the same problem on WinMe and R v1.4.1 with Swedish keyboard
> settings:
>
>   plot(1:10, xlab="")
>
> works in Rgui but not in Rterm under Cygwin bash where it instead prints
> "quote down", "qoute up" and a "open box". However,

Prints?  It is a plot command. What does it plot?

>   plot(1:10, xlab="\344\366\374")
>
> does the same thing. Trying
>
>   print("\344\366\374")
>
> "" will not be shown. Again, with Rgui it works. So there seems to be
> some differences in the character encoding etc for the upper ASCII half. I
> noticed that when I changed my keyboard settings from Swedish to English the
> plot call above works (but not the print call which I believe is due to my
> Cygwin/bash settings).

I/O in Rterm is entirely at the mercy of the terminal within which it is
run. In particular, it is unlikely that it is set up to use ISOLatin1
encoding, whereas Rgui is set up to use WinANSI (which is almost the
same).

For example, Rterm should work under a correctly set up NTemacs and ESS,
and indeed it seems to under my rarely used setup.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Sun Apr  7 21:43:36 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 07 Apr 2002 21:43:36 +0200
Subject: [R] save.image() error
In-Reply-To: <Pine.LNX.4.31.0204071726270.15871-100000@gannet.stats>
References: <Pine.LNX.4.31.0204071726270.15871-100000@gannet.stats>
Message-ID: <x2k7rjb8gn.fsf@blueberry.kubism.ku.dk>

ripley at stats.ox.ac.uk writes:

> > What is a "race" condition?
> 
> Two processes trying to access the same resource at the same time.

...and the result depending on who gets there first.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From steinep at uni-muenster.de  Sun Apr  7 21:57:19 2002
From: steinep at uni-muenster.de (Petra Steiner)
Date: Sun, 7 Apr 2002 21:57:19 +0200
Subject: [R] German umlaut in xlab
References: <Pine.LNX.4.31.0204071511080.13306-100000@gannet.stats>
Message-ID: <005701c1de6e$6dcb66a0$53ecb080@oemcomputer>

Thanks to you all for your quick replies!
I work under Windows98 and I am still using version 1.3.1. The output file
is in postscript or eps format.

Henrik Bengtssons tip
>plot(1:10, xlab="\344\366\374")

solved the problem, for I call the program in Rterm.
A special thank-you to Henrik for his useful functions.
Regards,
Petra




> There is nothing to solve!  Did you try the obvious: enter the characters
> from your keyboard in the xlab and ylab strings?   It should work, and
> there are examples in ?text.
>
> If this perchance does not work, please tell us a lot more details about
> your system.  (It works even in English-language versions of Windows
> 95, 98, NT4, 2000 and XP to my knowledge.)
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hb at maths.lth.se  Sun Apr  7 22:25:25 2002
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Sun, 7 Apr 2002 22:25:25 +0200
Subject: [R] German umlaut in xlab
In-Reply-To: <Pine.LNX.4.31.0204071841510.16034-100000@gannet.stats>
Message-ID: <KKEGJOGBELBHDIKPINBMIEHGCLAA.hb@maths.lth.se>

> -----Original Message-----
> From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk]
> Sent: Sunday, April 07, 2002 7:56 PM
> To: Henrik Bengtsson
> Cc: r-help at stat.math.ethz.ch
> Subject: RE: [R] German umlaut in xlab
>
>
> On Sun, 7 Apr 2002, Henrik Bengtsson wrote:
>
> > I have the same problem on WinMe and R v1.4.1 with Swedish keyboard
> > settings:
> >
> >   plot(1:10, xlab="???")
> >
> > works in Rgui but not in Rterm under Cygwin bash where it instead prints
> > "quote down", "qoute up" and a "open box". However,
>
> Prints?  It is a plot command. What does it plot?

"Writes" or "draws" is maybe better. So, is it correct English to say "plot
a string of characters"? For me "plot" is more for shapes and data points. I
am asking because I don't know.

> >   plot(1:10, xlab="\344\366\374")
> >
> > does the same thing. Trying
> >
> >   print("\344\366\374")
> >
> > "???" will not be shown. Again, with Rgui it works. So there seems to be
> > some differences in the character encoding etc for the upper
> ASCII half. I
> > noticed that when I changed my keyboard settings from Swedish
> to English the
> > plot call above works (but not the print call which I believe
> is due to my
> > Cygwin/bash settings).
>
> I/O in Rterm is entirely at the mercy of the terminal within which it is
> run. In particular, it is unlikely that it is set up to use ISOLatin1
> encoding, whereas Rgui is set up to use WinANSI (which is almost the
> same).
>
> For example, Rterm should work under a correctly set up NTemacs and ESS,
> and indeed it seems to under my rarely used setup.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

Best

Henrik Bengtsson

Dept. of Mathematical Statistics @ Centre for Mathematical Sciences
Lund Institute of Technology/Lund University, Sweden (+2h UTC)
Office: P316, +46 46 222 9611 (phone), +46 46 222 4623 (fax)
h b @ m a t h s . l t h . s e, http://www.maths.lth.se/bioinformatics/

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ssong at nicco.sscnet.ucla.edu  Mon Apr  8 00:48:43 2002
From: ssong at nicco.sscnet.ucla.edu (Shige Song)
Date: Sun, 7 Apr 2002 15:48:43 -0700 (PDT)
Subject: [R] help with the "pch" option in plot.locfit
Message-ID: <Pine.GSO.4.33.0204071539260.14052-100000@nicco.sscnet.ucla.edu>

Dear All,

I am trying to plot a smoothed hazard funciton using the LOCFIT library.
Suppose my locfit model is "loc.fit", my plot command looks like this:

plot(loc.rw, lty="solid", pch=1, xlab="Age at Risk",
ylab="Hazard Rate", ylim=c(0, .5), lwd=2)

What's interesting is that whichever number I used in the "pch=" option,
I still get a line without any symbles. Is this something about the LOCFIT
library or I did something wrong?

I have four lines in my graph, without differetn symbles on different
lines,  it can be difficult to read.

Any help will be greatly appreciated.

Best,
Shige Song
Department of Sociology, UCLA

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ssong at nicco.sscnet.ucla.edu  Mon Apr  8 08:10:35 2002
From: ssong at nicco.sscnet.ucla.edu (Shige Song)
Date: Sun, 7 Apr 2002 23:10:35 -0700 (PDT)
Subject: [R] LOCFIT and survival function
Message-ID: <Pine.GSO.4.33.0204072307450.9405-100000@nicco.sscnet.ucla.edu>

Dear All,

A quick quesiton about the LOCFIT library: is it possible to produce
cumulative hazard function or survival function estimate as opposed to
hazard funciton estimate using LOCFIT? If not, are there other ways to get
smoothed survival function estimates? Thanks!

Best,
Shige

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Mon Apr  8 09:35:15 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 8 Apr 2002 09:35:15 +0200
Subject: [R] rbind(NULL,NULL)
In-Reply-To: <Pine.GSO.4.33.0204050838410.5065-100000@ysidro.econ.uiuc.edu>
References: <Pine.GSO.4.33.0204050838410.5065-100000@ysidro.econ.uiuc.edu>
Message-ID: <15537.18483.169679.218927@gargle.gargle.HOWL>

>>>>> "Roger" == Roger Koenker <roger at ysidro.econ.uiuc.edu> writes:

    Roger> In the time honored spirit of wishing to do nothing
    Roger> well, could I suggest that the Splus (versions 5 and 6) response to:

    >> rbind(NULL,NULL)
    Roger> NULL

    Roger> is preferable to the R response:

    >> rbind(NULL,NULL)
    Roger> Error in rbind(NULL, NULL) : attempt to set an
    Roger> attribute on NULL

a simpler example is

   rbind(NULL)
or cbind(NULL).

However, I don't see why allowing the above should be better than
giving an error.  In R, we have made a distinction between
0-length vectors and NULL for quite a while, and AFAIR, S-plus
has done so, too, in other contexts.

Note that   rbind(numeric(0))  {as in rbind(x[x!=x])} *does* work
(i.e. give 0 x 0 matrix, not "NULL"!).


    <...>

    Roger> It is tempting to conclude from this that Splus does
    Roger> nothing better than R, but it is always dangerous to
    Roger> generalize from one example.

[ big ;-) ]

Note that S-plus has a bug here: It does not work according to
documentation, since its  help(cbind) {or (rbind)} says

>>                        Build Matrix from Columns or Rows
>>                                        
>> DESCRIPTION:
>> 
>>    Returns a matrix that is pieced together from several vectors and/or
>>    matrices. The functions cbind and rbind are generic. In particular,
>>    there are cbind and rbind methods for data frames and classes in the
>>    Matrix library.

whereas in your example it returns NULL which is not a matrix...
I hope this doesn't sound too nitpicking, but you started to
talk about the nits.. :-)

With high regards,
Martin

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From a296180 at mica.fmr.com  Mon Apr  8 12:38:53 2002
From: a296180 at mica.fmr.com (David Kane  <David Kane)
Date: Mon, 8 Apr 2002 06:38:53 -0400
Subject: [R] subsetting with NA's
Message-ID: <15537.29501.381608.739104@gargle.gargle.HOWL>

Hi,

I often have large dataframes with many variables and many NA's, from which I
would like to subset out some rows. Here is a toy example:

> x <- data.frame(a = c("x", "y", "z"), b = c(1, NA, 5))
> x
  a  b
1 x  1
2 y NA
3 z  5

I realize that, if I know the values in x$b that I want to subset, things are easy:

> x[x$b %in% c(1),]
  a b
1 x 1

However, if I only know the *range", then the NA's will flomux me.

> x[x$b < 3,]
    a  b
1   x  1
NA NA NA

Of course, I can explicitly avoid the NA's by doing something like:

> x[x$b < 3 & ! is.na(x$b),]
  a b
1 x 1

My problem is that this sort of syntax can become quite annoying when their are
many variables in the subseting expression. That is, I want to writing
something like:

x[x$b < 3 & x$c > 5 & x$d > 100,]

without having to write:

x[! is.na(x$b) & ! is.na(x$c) & ! is.na(x$d) & x$b < 3 & x$c > 5 & x$d > 100,]

Is there a trick for achieving this, for ignoring all NA's during subsetting?

To the extent that it matters: 

> version
         _                   
platform sparc-sun-solaris2.6
arch     sparc               
os       solaris2.6          
system   sparc, solaris2.6   
status   Patched             
major    1                   
minor    4.0                 
year     2002                
month    01                  
day      13                  
language R                   
> 

Thanks,

Dave Kane
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Apr  8 13:08:24 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 08 Apr 2002 13:08:24 +0200
Subject: [R] subsetting with NA's
In-Reply-To: <15537.29501.381608.739104@gargle.gargle.HOWL>
References: <15537.29501.381608.739104@gargle.gargle.HOWL>
Message-ID: <x2adsephw7.fsf@blueberry.kubism.ku.dk>

"David Kane  <David Kane" <a296180 at mica.fmr.com> writes:

> My problem is that this sort of syntax can become quite annoying when their are
> many variables in the subseting expression. That is, I want to writing
> something like:
> 
> x[x$b < 3 & x$c > 5 & x$d > 100,]
> 
> without having to write:
> 
> x[! is.na(x$b) & ! is.na(x$c) & ! is.na(x$d) & x$b < 3 & x$c > 5 & x$d > 100,]
> 
> Is there a trick for achieving this, for ignoring all NA's during subsetting?

subset(x, b < 3 & c > 5 & d > 100) exists for that very reason...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Ko-Kang at xtra.co.nz  Mon Apr  8 13:19:56 2002
From: Ko-Kang at xtra.co.nz (Ko-Kang Kevin Wang)
Date: Mon, 8 Apr 2002 23:19:56 +1200
Subject: [R] subsetting with NA's
References: <15537.29501.381608.739104@gargle.gargle.HOWL>
Message-ID: <003f01c1deef$509e0d90$a56c36d2@n1bliarfyrd5b7>


----- Original Message -----
From: "David Kane <David Kane" <a296180 at mica.fmr.com>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, April 08, 2002 10:38 PM
Subject: [R] subsetting with NA's


> without having to write:
>
> x[! is.na(x$b) & ! is.na(x$c) & ! is.na(x$d) & x$b < 3 & x$c > 5 & x$d >
100,]
>
> Is there a trick for achieving this, for ignoring all NA's during
subsetting?

Have you tried na.omit()?

Kevin



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lukas.kubin at permonik.com  Mon Apr  8 14:29:05 2002
From: lukas.kubin at permonik.com (Lukas Kubin)
Date: Mon, 8 Apr 2002 14:29:05 +0200 (CEST)
Subject: [R] example of exponential regression
Message-ID: <Pine.LNX.4.33.0204081418340.1834-100000@localhost.localdomain>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

could somebody write me an example of how to do a simple exponential
smooth on a time series?
thank you

lukas

- -- 
Lukas Kubin
lukas.kubin at permonik.com
phone: 00420603836180
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.0.5 (GNU/Linux)
Comment: Made with pgp4pine 1.75-6

iD8DBQE8sY0V4TIZ2lmUAtsRAiuNAJ9cl1ohW4pVd6xbcjIETKydXWi7sACeNtxU
miPsqmoStK5bzYM/eCWNhpw=
=xb69
-----END PGP SIGNATURE-----


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Mon Apr  8 16:11:39 2002
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 08 Apr 2002 10:11:39 -0400
Subject: [R] user coordinates and rug plots in lattice graphics
Message-ID: <5.1.0.14.2.20020408095750.01d53918@pop>

Dear R list members,

I'd like to produce rug plots at the bottom of panels in a trellis display 
(using the lattice package), but par("usr") doesn't return user coordinates 
for panels, and consequently rug fails, as the following example (suggested 
to me by Georges Monette) illustrates:

     > x <- rnorm(50)
     > y <- rnorm(50)
     > f <- factor(sample(c('a','b','c'),size=50, replace=T))
     > z <- xyplot(y~x|f,
     +        panel = function(x,y,...) {
     +                panel.xyplot(x,y,...)
     +                rug(x)
     +                print(par('usr'))
     +        })
     > z
     [1] 0 1 0 1
     [1] 0 1 0 1
     [1] 0 1 0 1
     Warning messages:
     1: some values will be clipped in: rug(x)
     2: some values will be clipped in: rug(x)
     3: some values will be clipped in: rug(x)

(R Version 1.4.1 on a Windows 2000 PC.)

This code runs properly in S-PLUS, by the way, where par("usr") returns 
user coordinates when invoked within a panel function.

I don't see a way around the problem. If I could determine the minimum 
value of y in a panel, I could make my own rug plot. Any help would be 
greatly appreciated.

Thanks,
  John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From millon at cebc.cnrs.fr  Mon Apr  8 16:14:54 2002
From: millon at cebc.cnrs.fr (Millon Alexandre)
Date: Mon, 08 Apr 2002 16:14:54 +0200
Subject: [R] glmm
Message-ID: <3CB1A5DE.D2F9724C@cebc.cnrs.fr>

Hello,

I would like to fit generalized linear mixed models but I did not find
the package allowing such procedure.
R help under nlme package gives me "glmmPQL(MASS)" but this file does
not appear in contributed packages.

Thanks in advance for your answer.

Alexandre MILLON

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ben at zoo.ufl.edu  Mon Apr  8 17:19:28 2002
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Mon, 8 Apr 2002 11:19:28 -0400 (EDT)
Subject: [R] glmm
In-Reply-To: <3CB1A5DE.D2F9724C@cebc.cnrs.fr>
Message-ID: <Pine.LNX.4.30.0204081104180.18721-100000@bolker.zoo.ufl.edu>


  This is becoming a FAQ ...

  you have three choices at the moment --

  glmmPQL is in the MASS package, in the VR bundle, which is typically
distributed with the R package

  GLMMGibbs is on CRAN

  Jim Lindsey has a variety of glmm options at
http://www.luc.ac.be/~jlindsey/rcode.html

  geoRglm on CRAN does spatial generalized linear models, which
incorporate one particular kind of mixed structure

  There does seem to be some debate as to the best method, though -- you
may have to try out a few different possibilities.
(e.g.)
http://maths.newcastle.edu.au/~rking/R/help/01a/2202.html
http://maths.newcastle.edu.au/~rking/R/help/01a/2184.html



On Mon, 8 Apr 2002, Millon Alexandre wrote:

> Hello,
>
> I would like to fit generalized linear mixed models but I did not find
> the package allowing such procedure.
> R help under nlme package gives me "glmmPQL(MASS)" but this file does
> not appear in contributed packages.
>
> Thanks in advance for your answer.
>
> Alexandre MILLON
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From imij at columbus.rr.com  Mon Apr  8 17:12:56 2002
From: imij at columbus.rr.com (jimi adams)
Date: Mon, 8 Apr 2002 11:12:56 -0400
Subject: [R] changing the form of a list
Message-ID: <00e201c1df0f$dcdc1980$768f1941@columbus.rr.com>

i have a 2 x n matrix that is a paired list of connections, i am working
with that looks something like:
1 2
1 3
1 5
2 1
2 3
3 1
3 2
4 5
5 1
5 4
for later operations it would be helpful if i could change this into the
form of:
1  2 3 5
2  1 3
3  1 2
4  5
5  1 4
the initial list is randomly generated and the max number of times that any
one number can appear is previoulsy defined by a limiting function (which is
variable depending on the numbers involved)
is there a clean way to change the form of that list?
i could do it with some big nasty if loops, but i was hoping that there
might be a quick generic way to do it that i am missing.
jimi adams
Department of Sociology
The Ohio State University
300 Bricker Hall
190 N Oval Mall
Columbus, OH 43210-1353
614-688-4261

our mind has a remarkable ability to think of contents as being independent
of the act of thinking
                                            -georg simmel


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Apr  8 17:27:22 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 08 Apr 2002 17:27:22 +0200
Subject: [R] changing the form of a list
In-Reply-To: <00e201c1df0f$dcdc1980$768f1941@columbus.rr.com>
References: <00e201c1df0f$dcdc1980$768f1941@columbus.rr.com>
Message-ID: <x2elhqcisl.fsf@blueberry.kubism.ku.dk>

"jimi adams" <imij at columbus.rr.com> writes:

> i have a 2 x n matrix that is a paired list of connections, i am working
> with that looks something like:
> 1 2
> 1 3
> 1 5
> 2 1
> 2 3
> 3 1
> 3 2
> 4 5
> 5 1
> 5 4
> for later operations it would be helpful if i could change this into the
> form of:
> 1  2 3 5
> 2  1 3
> 3  1 2
> 4  5
> 5  1 4

Something like this?

> zz <- matrix(scan(),ncol=2,byrow=T)
1: 1 2
3: 1 3
5: 1 5
7: 2 1
9: 2 3
11: 3 1
13: 3 2
15: 4 5
17: 5 1
19: 5 4
21: Read 20 items
> x <- zz[,1]
> y <- zz[,2]
> tapply(y,x,sort)
$"1"
[1] 2 3 5

$"2"
[1] 1 3

$"3"
[1] 1 2

$"4"
[1] 5

$"5"
[1] 1 4

You might want something slightly more complicated like

tapply(y,factor(x,levels=1:5), function(z) sort(unique(x))) 

to account for empty groups and duplicated pairs.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Mon Apr  8 17:37:10 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 8 Apr 2002 08:37:10 -0700 (PDT)
Subject: [R] changing the form of a list
In-Reply-To: <00e201c1df0f$dcdc1980$768f1941@columbus.rr.com>
Message-ID: <Pine.A41.4.44.0204080826060.91766-100000@homer21.u.washington.edu>

On Mon, 8 Apr 2002, jimi adams wrote:

> i have a 2 x n matrix that is a paired list of connections, i am working
> with that looks something like:
> 1 2
> 1 3
> 1 5
> 2 1
> 2 3
> 3 1
> 3 2
> 4 5
> 5 1
> 5 4
> for later operations it would be helpful if i could change this into the
> form of:
> 1  2 3 5
> 2  1 3
> 3  1 2
> 4  5
> 5  1 4
> the initial list is randomly generated and the max number of times that any
> one number can appear is previoulsy defined by a limiting function (which is
> variable depending on the numbers involved)
> is there a clean way to change the form of that list?

Suppose the matrix is actually a data.frame (if it isn't, use
as.data.frame) called df with columns called i and x

tapply(df$x, df$i, c)

> df
   i  x
1  1  1
2  2  2
3  3  3
4  3  4
5  4  5
6  2  6
7  1  7
8  3  8
9  4  9
10 3 10
>  tapply(df$x,df$i,c)
$"1"
[1] 1 7

$"2"
[1] 2 6

$"3"
[1]  3  4  8 10

$"4"
[1] 5 9

Or by()

> by(df, df$i, function(subset) subset$x)
df$i: 1
[1] 1 7
------------------------------------------------------------
df$i: 2
[1] 2 6
------------------------------------------------------------
df$i: 3
[1]  3  4  8 10
------------------------------------------------------------
df$i: 4
[1] 5 9

Or you might want to leave the data in its current form and use tapply()
or by() to do whatever it is you want to do with it.

	-thomas




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deepayansarkar at yahoo.com  Mon Apr  8 18:09:24 2002
From: deepayansarkar at yahoo.com (Deepayan Sarkar)
Date: Mon, 8 Apr 2002 09:09:24 -0700 (PDT)
Subject: [R] user coordinates and rug plots in lattice graphics
In-Reply-To: <5.1.0.14.2.20020408095750.01d53918@pop>
Message-ID: <20020408160924.22755.qmail@web13905.mail.yahoo.com>


--- John Fox <jfox at mcmaster.ca> wrote:
> Dear R list members,
> 
> I'd like to produce rug plots at the bottom of panels in a trellis display 
> (using the lattice package), but par("usr") doesn't return user coordinates 
> for panels, and consequently rug fails, as the following example (suggested 
> to me by Georges Monette) illustrates:
> 
>      > x <- rnorm(50)
>      > y <- rnorm(50)
>      > f <- factor(sample(c('a','b','c'),size=50, replace=T))
>      > z <- xyplot(y~x|f,
>      +        panel = function(x,y,...) {
>      +                panel.xyplot(x,y,...)
>      +                rug(x)
>      +                print(par('usr'))
>      +        })
>      > z
>      [1] 0 1 0 1
>      [1] 0 1 0 1
>      [1] 0 1 0 1
>      Warning messages:
>      1: some values will be clipped in: rug(x)
>      2: some values will be clipped in: rug(x)
>      3: some values will be clipped in: rug(x)
> 
> (R Version 1.4.1 on a Windows 2000 PC.)
> 
> This code runs properly in S-PLUS, by the way, where par("usr") returns 
> user coordinates when invoked within a panel function.

The problem arises because lattice is based on grid graphics, and conventional
R graphics do not work under grid. The way around (to get the user 
coordinates) here would be to use current.viewport()$xscale and 
current.viewport()$yscale (both should be vectors of length 2).

> I don't see a way around the problem. If I could determine the minimum 
> value of y in a panel, I could make my own rug plot. Any help would be 
> greatly appreciated.

For this, you might want to use lsegments. (This may be slow now, but should
be faster in the next release.)


> 
> Thanks,
>   John
> -----------------------------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada L8S 4M4
> email: jfox at mcmaster.ca
> phone: 905-525-9140x23604
> web: www.socsci.mcmaster.ca/jfox


__________________________________________________

Yahoo! Tax Center - online filing with TurboTax

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Mon Apr  8 18:33:35 2002
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 08 Apr 2002 12:33:35 -0400
Subject: [R] user coordinates and rug plots in lattice graphics
In-Reply-To: <20020408160924.22755.qmail@web13905.mail.yahoo.com>
References: <5.1.0.14.2.20020408095750.01d53918@pop>
Message-ID: <5.1.0.14.2.20020408123005.01d54060@pop>

Dear Deepayan,

Using current.viewport()$yscale does the trick -- for example:

     x <- rnorm(50)
     y <- rnorm(50)
     f <- factor(sample(c('a','b','c'),size=50, replace=T))
     par(tck = 0.03)
     z <- xyplot(y~x|f,
         panel = function(x,y,...) {
                 panel.xyplot(x,y,...)
                 ymin <- current.viewport()$yscale[1]
                 lpoints(x, rep(ymin, length(x)), pch="|", col='black')
         })
     z

Thank you very much,
  John

At 09:09 AM 4/8/2002 -0700, Deepayan Sarkar wrote:

>--- John Fox <jfox at mcmaster.ca> wrote:
> > Dear R list members,
> >
> > I'd like to produce rug plots at the bottom of panels in a trellis display
> > (using the lattice package), but par("usr") doesn't return user 
> coordinates
> > for panels, and consequently rug fails, as the following example 
> (suggested
> > to me by Georges Monette) illustrates:
> >
> >      > x <- rnorm(50)
> >      > y <- rnorm(50)
> >      > f <- factor(sample(c('a','b','c'),size=50, replace=T))
> >      > z <- xyplot(y~x|f,
> >      +        panel = function(x,y,...) {
> >      +                panel.xyplot(x,y,...)
> >      +                rug(x)
> >      +                print(par('usr'))
> >      +        })
> >      > z
> >      [1] 0 1 0 1
> >      [1] 0 1 0 1
> >      [1] 0 1 0 1
> >      Warning messages:
> >      1: some values will be clipped in: rug(x)
> >      2: some values will be clipped in: rug(x)
> >      3: some values will be clipped in: rug(x)
> >
> > (R Version 1.4.1 on a Windows 2000 PC.)
> >
> > This code runs properly in S-PLUS, by the way, where par("usr") returns
> > user coordinates when invoked within a panel function.
>
>The problem arises because lattice is based on grid graphics, and conventional
>R graphics do not work under grid. The way around (to get the user
>coordinates) here would be to use current.viewport()$xscale and
>current.viewport()$yscale (both should be vectors of length 2).
>
> > I don't see a way around the problem. If I could determine the minimum
> > value of y in a panel, I could make my own rug plot. Any help would be
> > greatly appreciated.
>
>For this, you might want to use lsegments. (This may be slow now, but should
>be faster in the next release.)

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Ted.Harding at nessie.mcc.ac.uk  Mon Apr  8 19:23:32 2002
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 08 Apr 2002 17:23:32 -0000 (BST)
Subject: [R] Missing data and Imputation
Message-ID: <XFMail.020408172332.Ted.Harding@nessie.mcc.ac.uk>

Hi Folks,

I'm currently looking at missing data/imputation
methods (including multiple imputation).

S-Plus has a "missing data library".

What similar resources are available within R?

Or does one roll one's own?

Best wishes to all,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 08-Apr-02                                       Time: 17:23:32
------------------------------ XFMail ------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From friendly at yorku.ca  Mon Apr  8 19:53:57 2002
From: friendly at yorku.ca (Michael Friendly)
Date: Mon, 08 Apr 2002 13:53:57 -0400
Subject: [R] pooling categories in a table
Message-ID: <3CB1D935.C0825829@yorku.ca>

I have a large n-way contingency table, constructed as a table
object, and want to pool (collapse) some categories, summing the
frequencies in all collapsed cells.  How can I do this?

thx,
-Michael

-- 
Michael Friendly              friendly at yorku.ca
York University               http://www.math.yorku.ca/SCS/friendly.html
Psychology Department
4700 Keele Street             Tel:  (416) 736-5115 x66249
Toronto, Ontario, M3J 1P3     Fax:  (416) 736-5814
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at blindglobe.net  Mon Apr  8 19:58:20 2002
From: rossini at blindglobe.net (A.J. Rossini)
Date: 08 Apr 2002 10:58:20 -0700
Subject: [R] Missing data and Imputation
In-Reply-To: <XFMail.020408172332.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.020408172332.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <87zo0e3web.fsf@jeeves.blindglobe.net>

>>>>> "ted" == Ted Harding <Ted> writes:

    ted> Hi Folks,
    ted> I'm currently looking at missing data/imputation
    ted> methods (including multiple imputation).

    ted> S-Plus has a "missing data library".

    ted> What similar resources are available within R?

Joe Shafer's packages (cat, norm, mix), which may form the basis for
S-Plus'  library (I don't remember this, any more) are available.  

A general framework would be nice for creating and recreating imputed
data sets, but in general, it isn't hard to roll your own.

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M-W: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my friday location is usually completely unpredictable.)


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Mon Apr  8 19:58:09 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Mon, 8 Apr 2002 13:58:09 -0400
Subject: [R] Missing data and Imputation
In-Reply-To: <XFMail.020408172332.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.020408172332.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <20020408135809.73ea5347.fharrell@virginia.edu>

Look at transcan in the Hmisc package, or the new aregImpute which currently is under construction.  There's also MICE, which has very good performance except possibly for speed.  See
http://hesweb1.med.virginia.edu/biostat/rms

Frank Harrell

On Mon, 08 Apr 2002 17:23:32 -0000 (BST)
Ted.Harding at nessie.mcc.ac.uk wrote:

> Hi Folks,
> 
> I'm currently looking at missing data/imputation
> methods (including multiple imputation).
> 
> S-Plus has a "missing data library".
> 
> What similar resources are available within R?
> 
> Or does one roll one's own?
> 
> Best wishes to all,
> Ted.
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 167 1972
> Date: 08-Apr-02                                       Time: 17:23:32
> ------------------------------ XFMail ------------------------------
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From macq at llnl.gov  Mon Apr  8 21:33:38 2002
From: macq at llnl.gov (Don MacQueen)
Date: Mon, 8 Apr 2002 12:33:38 -0700
Subject: [R] Problem(?) in strptime()
Message-ID: <p05101500b8d77b58229f@[128.115.153.6]>

I think the following examples illustrate the crux of the matter 
(version and OS info are below).

The problem has to do with the transition from standard time to 
daylight savings time. My timezone, US/Pacific, has two parts: 
standard time (PST) 8 hours behind GMT and daylight savings time 
(PDT) 7 hours behind GMT. The transition takes place this year on 7 
April at 02:00, when 02:00 is re-labeled 03:00.

## April 6, 01:30 and 02:30
>  ISOdatetime(2002, 4, 6, 1:2, 30, 0,tz='GMT')
[1] "2002-04-05 17:30:00 PST" "2002-04-05 18:30:00 PST"

## April 7 , 01:30 and 02:30
>  ISOdatetime(2002, 4, 7, 1:2, 30, 0,tz='GMT')
[1] "2002-04-06 17:30:00 PST" "2002-04-06 17:30:00 PST"

The dates supplied are one day apart. The times supplied are one hour 
apart. However, the times returned are one hour apart in the first 
case, but identical in the second case.

>  tmp <- ISOdatetime(2002, 4, 7, 1:2, 30, 0,tz='GMT')
>  identical(tmp[1],tmp[2])
[1] TRUE

Of the four values returned, the last one is incorrect, because 
2002-4-7 2:30 GMT truly is 2002-4-6 18:30 PST.

What I need is a way to have that fourth case interpreted correctly.


Investigating a bit:

>  ISOdatetime
function (year, month, day, hour, min, sec, tz = "")
{
     x <- paste(year, month, day, hour, min, sec)
     as.POSIXct(strptime(x, "%Y %m %d %H %M %S"), tz = tz)
}

>  strptime
function (x, format)
.Internal(strptime(x, format))

ISOdatetime() uses strptime(), and strptime() does not use the 
timezone information. Indeed, from ?strptime, TZ as part of a format 
specification is available for output only.

As far as I can tell, strptime() interprets everything in the local 
timezone, and when provided a time such as 2002-4-7 2:30 that 
"doesn't exist" in the local timezone, makes a reasonable attempt to 
guess what the user meant. But it doesn't work for what ISOdatetime() 
does with it when tz is something other than ''.

What I need is a way to tell R that the date-time string really truly 
should be interpreted as GMT. I haven't found a way. (maybe setenv TZ 
GMT before starting R, but I'm still exploring that)

Also as far as I can tell, strptime() uses an OS-supplied strptime if 
one is available, and R is entirely dependent on its behavior. I 
don't entirely understand what man strptime on my system says about 
this, but maybe it suggests that timezone information might be used 
if provided...

      %Z    Timezone name or no characters if no time zone  infor-
            mation  exists.  Local timezone information is used as
            though  strptime()  called  tzset()  (see  ctime(3C)).
            Errors  may not be detected.  This behavior is subject
            to change in a future release.


>  Sys.getlocale()
[1] "C"
>  version

>  Sys.getenv('TZ')
           TZ
"US/Pacific"
        _
platform sparc-sun-solaris2.7
arch     sparc
os       solaris2.7
system   sparc, solaris2.7
status
major    1
minor    4.1
year     2002
month    01
day      30
language R

I tried changing the locale
    Sys.setlocale('LC_TIME','en_GB')
(based on entries in /usr/lib/locale/lcttab), and
    Sys.putenv('TZ=GMT')
to no avail.

----------------------------------------------
This whole thing is motivated by the fact that I am receiving some 
data that is time-stamped, and the time stamps (in addition to having 
a poorly chosen format) ignore the daylight savings time convention. 
That is, they always use an 8 hour offset from GMT. Thus, the three 
times shown are in fact an hourly sequence.

Sun Apr 07 01:30:58 2002
Sun Apr 07 02:30:58 2002
Sun Apr 07 03:30:58 2002

In order to convert these correctly to POSIXct, I thought a 
reasonable approach would be to tell R that they are in GMT, read 
them as such, and then convert to US/Pacific.

Here is what I have been using.

tmpd <- c('Sun Apr 07 01:30:58 2002',
           'Sun Apr 07 02:30:58 2002',
           'Sun Apr 07 03:30:58 2002')
tmpt <- as.POSIXct(strptime(tmpd,'%a %b %d %H:%M:%S %Y'),tz='GMT')+28800

>  tmpt
[1] "2002-04-07 01:30:58 PST" "2002-04-07 01:30:58 PST" "2002-04-07 
04:30:58 PDT"

It works for the first and last times, but not the middle one
(3:30 "PST" = 4:30 PDT is correct, but 2:30 "PST" should be 3:30 PDT).

I would appreciate help finding a way that works for all of them 
simultaneously.

Thanks
-Don


-----------------
Here are some more attempts at various ways of looking at these 
dates, if anyone cares to wade through them.

>  strptime('2002-4-7 1:30' , '%Y-%m-%d %H:%M')
[1] "2002-04-07 01:30:00"
>  strptime('2002-4-7 2:30' , '%Y-%m-%d %H:%M')
[1] "2002-04-07 01:30:00"
>  strptime('2002-4-7 3:30' , '%Y-%m-%d %H:%M')
[1] "2002-04-07 03:30:00"

The first and last display as two hours apart.
The second one is interpreted by strptime() to be the same as the 
first one. Not unreasonable, but problematic as illustrated above.

-------
>  as.numeric(as.POSIXct(strptime('2002-4-7 1:30' , '%Y-%m-%d %H:%M')))
[1] 1018171800
>  as.numeric(as.POSIXct(strptime('2002-4-7 2:30' , '%Y-%m-%d %H:%M')))
[1] 1018171800
>  as.numeric(as.POSIXct(strptime('2002-4-7 3:30' , '%Y-%m-%d %H:%M')))
[1] 101817540

>  1018175400 - 1018171800
[1] 3600

But in fact, the first and last are only one hour apart. This is 
correct, because the first one is PST, the third one is PDT.

-------
>  as.POSIXct(strptime('2002-4-7 1:30' , '%Y-%m-%d %H:%M'),tz='GMT')
[1] "2002-04-06 17:30:00 PST"
>  as.POSIXct(strptime('2002-4-7 2:30' , '%Y-%m-%d %H:%M'),tz='GMT')
[1] "2002-04-06 17:30:00 PST"
>  as.POSIXct(strptime('2002-4-7 3:30' , '%Y-%m-%d %H:%M'),tz='GMT')
[1] "2002-04-06 19:30:00 PST"

>  as.POSIXct(strptime('2002-4-7 1:30' , '%Y-%m-%d %H:%M'),tz='US/Pacific')
[1] "2002-04-07 01:30:00 PST"
>  as.POSIXct(strptime('2002-4-7 2:30' , '%Y-%m-%d %H:%M'),tz='US/Pacific')
[1] "2002-04-07 01:30:00 PST"
>  as.POSIXct(strptime('2002-4-7 3:30' , '%Y-%m-%d %H:%M'),tz='US/Pacific')
[1] "2002-04-07 03:30:00 PDT"

-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
--------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dyang at nrcan.gc.ca  Mon Apr  8 21:51:11 2002
From: dyang at nrcan.gc.ca (Yang, Richard)
Date: Mon, 8 Apr 2002 15:51:11 -0400 
Subject: [R] Error in nlme ranef plot()
Message-ID: <F0E0B899CB43D5118D220002A55113CF21BAA2@s2-edm-r1.nofc.cfs.nrcan.gc.ca>

Dear R list members;

I have a 10 x 423 data frame which consisting of response, time, subject,
site, plot and covariates (continueous and categorical) measured at the plot
level. When the data frame was converted into a groupedData object, a
warning appeared

> A <- groupedData(ht ~ time | Subject, data = tt, outer = ~ site * plot,
+      labels=list(y = "Height", x = "Time", units = list( y = "(m)", x =
"(Yr)")) )
Warning message: 
argument lengths differ in: split(x, f).

The warning did not affect the estimation of a nlme model with parameters
B1, B2, and B3. However, when plotting  the estimated ranef versus
covariates, an error resulted

> A1Mod.nlmeRE <- ranef(A1Mod.nlme, aug=T)

> plot(A1Mod.nlmeRE, form = B1 ~ Ps + Dr + El + As + Sl) results in 
Error in max(length(x0), length(x1), length(y0), length(y1)) : 
        Argument "x0" is missing, with no default 

The same data frame and commands works fine with Splus 6 on W2K. Is this a
bug in nlme 3.3.x? I use R 1.4.1.

Thanks,

Richard








-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ccleland at optonline.net  Mon Apr  8 21:58:45 2002
From: ccleland at optonline.net (Chuck Cleland)
Date: Mon, 08 Apr 2002 15:58:45 -0400
Subject: [R] Missing data and Imputation
References: <XFMail.020408172332.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <3CB1F675.D49078F0@optonline.net>

Ted Harding wrote:
> I'm currently looking at missing data/imputation
> methods (including multiple imputation).
> 
> S-Plus has a "missing data library".
> 
> What similar resources are available within R?

Ted:
  If you are using Unix/Linux, 

http://web.inter.nl.net/users/S.van.Buuren/mi/docs/miceR.zip

Hope this helps,

Chuck Cleland
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Mon Apr  8 22:15:49 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 08 Apr 2002 15:15:49 -0500
Subject: [R] Error in nlme ranef plot()
In-Reply-To: <F0E0B899CB43D5118D220002A55113CF21BAA2@s2-edm-r1.nofc.cfs.nrcan.gc.ca>
References: <F0E0B899CB43D5118D220002A55113CF21BAA2@s2-edm-r1.nofc.cfs.nrcan.gc.ca>
Message-ID: <6rn0wex7yi.fsf@franz.stat.wisc.edu>

"Yang, Richard" <dyang at nrcan.gc.ca> writes:

> I have a 10 x 423 data frame which consisting of response, time, subject,
> site, plot and covariates (continueous and categorical) measured at the plot
> level. When the data frame was converted into a groupedData object, a
> warning appeared
> 
> > A <- groupedData(ht ~ time | Subject, data = tt, outer = ~ site * plot,
> +      labels=list(y = "Height", x = "Time", units = list( y = "(m)", x =
> "(Yr)")) )
> Warning message: 
> argument lengths differ in: split(x, f).

I think you are missing a closing parenthesis in that call to
groupedData.

It should be 

A <- groupedData(ht ~ time | Subject, data = tt, outer = ~ site * plot,
   labels=list(y = "Height", x = "Time"), 
   units = list( y = "(m)", x ="(Yr)"))

That won't affect the fitting routines but it can affect the plots.

Please remember that you must use

library(lattice)

to do any of the plotting in the nlme package.  Once R-1.5.0 is out
the nlme package will require the lattice package.
               
> The warning did not affect the estimation of a nlme model with parameters
> B1, B2, and B3. However, when plotting  the estimated ranef versus
> covariates, an error resulted
> 
> > A1Mod.nlmeRE <- ranef(A1Mod.nlme, aug=T)
> 
> > plot(A1Mod.nlmeRE, form = B1 ~ Ps + Dr + El + As + Sl) results in 
> Error in max(length(x0), length(x1), length(y0), length(y1)) : 
>         Argument "x0" is missing, with no default 
> 
> The same data frame and commands works fine with Splus 6 on W2K. Is this a
> bug in nlme 3.3.x? I use R 1.4.1.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Mon Apr  8 22:22:44 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 08 Apr 2002 16:22:44 -0400
Subject: [R] randomForest() segfaults under Solaris(SPARC) 2.7
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC1BB@usrymx10.merck.com>

As the package maintainer, I'd like to find out what's wrong.
Unfortunately I do not have access to a suitable Solaris box
to try it.  Can anyone with similar platform help?

I already found one (unrelated) bug in the predict.randomForest
function.  The randomForest.default function accepts matrix
or data frame, but predict.randomForest assumes data frame.
If a matrix is passed to the predict method, error will occur.
As a temporary fix, coerce matrix to data frame before handing
it to the predict method.

Regards,
Andy

> -----Original Message-----
> From: Steve Shiboski [mailto:steve at biostat.ucsf.edu]
> Sent: Friday, April 05, 2002 3:24 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] randomForest() segfaults under Solaris(SPARC) 2.7
> 
> 
> Invocation of randomForest() using the iris example in the help
> file crashes R with a segmentation fault. This happens on
> all of our ultraSPARC machines running Solaris 2.7.
> 
> We're using R-1.4.1, compiled using Sun cc and f77 and
> the flags:
> 
> CC=cc
> CFLAGS="-xO5 -xlibmil -dalign"
> FC=f77
> FFLAGS="-xO5 -xlibmil -dalign"
> 
> "make check" runs withour errors, and R has been working
> well for all other applications/installations.
> 
> Incidentally, randomForest() runs fine on one of our 
> ultraSPARC machines 
> running Solaris 2.6 and R-1.4.1 compiled using the same 
> compilers and flags.
> It also reportedly works if gcc/g77 are used.
> 
> Any suggestions appreciated.
> 
> -- 
> Stephen Shiboski  -------------------  steve at biostat.ucsf.edu
> Division of Biostatistics                 voice: 415-476-0533
> University of California, San Francisco     fax: 415-476-6014
> 500 Parnassus Avenue, MU 420-W;  San Francisco, CA 94143-0560
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> 

------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.murrell at auckland.ac.nz  Mon Apr  8 22:53:47 2002
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue, 9 Apr 2002 08:53:47 +1200
Subject: [R] user coordinates and rug plots in lattice graphics
References: <5.1.0.14.2.20020408095750.01d53918@pop> <5.1.0.14.2.20020408123005.01d54060@pop>
Message-ID: <009c01c1df3f$7ac35580$7632d882@stat.auckland.ac.nz>

Hi


> Using current.viewport()$yscale does the trick -- for example:


One note of warning about this approach -- this is poking around in the
internal structure of grid viewports, which are not guaranteed to stay that
way.  This is not your fault of course because I have failed to supply
decent (or any) support for querying grid's coordinate system state :)

OTOH, there is a "better" way to do this -- at least, there is a way to do
this which is more inkeeping with grid's philosophy.  If you want the rug
lines anchored at the bottom of the plot region, the easy way to specify
that is to use grid's "npc" coordinates -- bottom-left = (0, 0) and
top-right = (1, 1).  Furthermore, you could draw the rug lines as actual
line segments and make use of grid's other coordinate systems to control the
height of the rug lines properly.  Here are a couple of alternative xyplot
calls to show what I mean ...

     # rug lines are 3mm high
     xyplot(y~x|f,
            panel = function(x,y,...) {
              panel.xyplot(x,y,...)
              grid.segments(x, unit(0, "npc"), x, unit(3, "mm"),
                            default.units="native")
         })
     # rug lines are 1/20th of the height of the plot
     xyplot(y~x|f,
            panel = function(x,y,...) {
              panel.xyplot(x,y,...)
              grid.segments(x, unit(0, "npc"), x, unit(0.05, "npc"),
                            default.units="native")
         })

... of course, the downside is that you have to encounter the raw grid
functions to do this.

Paul


>      x <- rnorm(50)
>      y <- rnorm(50)
>      f <- factor(sample(c('a','b','c'),size=50, replace=T))
>      par(tck = 0.03)
>      z <- xyplot(y~x|f,
>          panel = function(x,y,...) {
>                  panel.xyplot(x,y,...)
>                  ymin <- current.viewport()$yscale[1]
>                  lpoints(x, rep(ymin, length(x)), pch="|", col='black')
>          })
>      z
>
> Thank you very much,
>   John
>
> At 09:09 AM 4/8/2002 -0700, Deepayan Sarkar wrote:
>
> >--- John Fox <jfox at mcmaster.ca> wrote:
> > > Dear R list members,
> > >
> > > I'd like to produce rug plots at the bottom of panels in a trellis
display
> > > (using the lattice package), but par("usr") doesn't return user
> > coordinates
> > > for panels, and consequently rug fails, as the following example
> > (suggested
> > > to me by Georges Monette) illustrates:
> > >
> > >      > x <- rnorm(50)
> > >      > y <- rnorm(50)
> > >      > f <- factor(sample(c('a','b','c'),size=50, replace=T))
> > >      > z <- xyplot(y~x|f,
> > >      +        panel = function(x,y,...) {
> > >      +                panel.xyplot(x,y,...)
> > >      +                rug(x)
> > >      +                print(par('usr'))
> > >      +        })
> > >      > z
> > >      [1] 0 1 0 1
> > >      [1] 0 1 0 1
> > >      [1] 0 1 0 1
> > >      Warning messages:
> > >      1: some values will be clipped in: rug(x)
> > >      2: some values will be clipped in: rug(x)
> > >      3: some values will be clipped in: rug(x)
> > >
> > > (R Version 1.4.1 on a Windows 2000 PC.)
> > >
> > > This code runs properly in S-PLUS, by the way, where par("usr")
returns
> > > user coordinates when invoked within a panel function.
> >
> >The problem arises because lattice is based on grid graphics, and
conventional
> >R graphics do not work under grid. The way around (to get the user
> >coordinates) here would be to use current.viewport()$xscale and
> >current.viewport()$yscale (both should be vectors of length 2).
> >
> > > I don't see a way around the problem. If I could determine the minimum
> > > value of y in a panel, I could make my own rug plot. Any help would be
> > > greatly appreciated.
> >
> >For this, you might want to use lsegments. (This may be slow now, but
should
> >be faster in the next release.)
>
> -----------------------------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada L8S 4M4
> email: jfox at mcmaster.ca
> phone: 905-525-9140x23604
> web: www.socsci.mcmaster.ca/jfox
> -----------------------------------------------------
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Mon Apr  8 22:58:16 2002
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 08 Apr 2002 16:58:16 -0400
Subject: [R] pooling categories in a table
In-Reply-To: <3CB1D935.C0825829@yorku.ca>
Message-ID: <5.1.0.14.2.20020408165358.01d60dd0@pop>

Dear Mike,

At 01:53 PM 4/8/2002 -0400, Michael Friendly wrote:
>I have a large n-way contingency table, constructed as a table
>object, and want to pool (collapse) some categories, summing the
>frequencies in all collapsed cells.  How can I do this?

Use apply; for example:

     > tab <- as.table(array(1:24, c(2,3,4)))
     > tab
     , , A

     A B C
     A 1 3 5
     B 2 4 6

     , , B

     A  B  C
     A 7  9 11
     B 8 10 12

     , , C

     A  B  C
     A 13 15 17
     B 14 16 18

     , , D

     A  B  C
     A 19 21 23
     B 20 22 24

    > apply(tab, c(2,3), sum)  # sums over first coordinate
     A  B  C  D
     A  3 15 27 39
     B  7 19 31 43
     C 11 23 35 47

I hope that this helps,
  John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From macq at llnl.gov  Mon Apr  8 23:13:00 2002
From: macq at llnl.gov (Don MacQueen)
Date: Mon, 8 Apr 2002 14:13:00 -0700
Subject: [R] Problem(?) in strptime() -- short version
Message-ID: <p05101502b8d7b4818847@[128.115.153.6]>

I decided my earlier email on this topic was rather long and wordy; 
here's a condensed version.

I am sitting at a Solaris computer in the US/Pacific timezone.
I have a file of data having times that includes the following three values

   2002-4-7 1:30:00 GMT
   2002-4-7 2:30:00 GMT
   2002-4-7 3:30:00 GMT

I have not been able to find a way to correctly convert these to 
either of the POSIX datetime classes with the OS timezone set to 
US/Pacific. And I've tried everything I could think of. The bottom 
line appears to be the fact that strptime() always uses the local 
timezone.

>  Sys.getenv('TZ')
           TZ
"US/Pacific"
>
>  gdat <- c('2002-4-7 1:30:00 GMT',
+           '2002-4-7 2:30:00 GMT',
+           '2002-4-7 3:30:00 GMT')
>
>
>  as.POSIXct(gdat)
[1] "2002-04-07 01:30:00 PST" "2002-04-07 01:30:00 PST" "2002-04-07 
03:30:00 PDT"
>
>  as.POSIXct(gdat,tz='GMT')
[1] "2002-04-06 17:30:00 PST" "2002-04-06 17:30:00 PST" "2002-04-06 
19:30:00 PST"
>
>  strptime(gdat,'%Y-%m-%d %H:%M:%S')
[1] "2002-04-07 01:30:00" "2002-04-07 01:30:00" "2002-04-07 03:30:00"
>
>  strptime(gdat,'%Y-%m-%d %H:%M:%S %Z')
[1] "NA" "NA" "NA"

The middle element is converted/interpreted incorrectly.

>  version
          _
platform sparc-sun-solaris2.7
arch     sparc
os       solaris2.7
system   sparc, solaris2.7
status
major    1
minor    4.1
year     2002
month    01
day      30
language R
>
>  Sys.getlocale()
[1] "C"

If I setenv TZ GMT before starting R, then the data is converted 
correctly. However, this is not entirely satisfactory, because 
ultimately I want to work with the data in my local timezone (for 
example, make graphs where the time axis is in local time), and that 
means going through a multiple step process:

   1) setenv TZ GMT
   2) start R, read the data
   3) quit R
   4) setenv TZ US/Pacific
   5) start R, work with the data

strptime() appears to rely on the operating system's strptime, so 
perhaps the problem is out of R's hands, so to speak. But it does 
seem reasonable that I should be able to convert such data no matter 
where I am. For example, it is my understanding that a world-wide 
standard among meteorologists is that times are always recorded in 
GMT.
-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
--------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gregory_r_warnes at groton.pfizer.com  Mon Apr  8 23:37:43 2002
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Mon, 8 Apr 2002 17:37:43 -0400 
Subject: [R] Missing data and Imputation
Message-ID: <5429125E11E4D411AF7300805FE603A8040DE8F9@groexmbcr02.pfizer.com>


There is already a (rough) R package for Shafer's 'norm' C library on CRAN,
I've mostly got a package for the 'mix' based on that set up as well.

-Greg

> -----Original Message-----
> From: rossini at blindglobe.net [mailto:rossini at blindglobe.net]
> Sent: Monday, April 08, 2002 1:58 PM
> To: Ted.Harding at nessie.mcc.ac.uk
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Missing data and Imputation
> 
> 
> >>>>> "ted" == Ted Harding <Ted> writes:
> 
>     ted> Hi Folks,
>     ted> I'm currently looking at missing data/imputation
>     ted> methods (including multiple imputation).
> 
>     ted> S-Plus has a "missing data library".
> 
>     ted> What similar resources are available within R?
> 
> Joe Shafer's packages (cat, norm, mix), which may form the basis for
> S-Plus'  library (I don't remember this, any more) are available.  
> 
> A general framework would be nice for creating and recreating imputed
> data sets, but in general, it isn't hard to roll your own.
> 
> best,
> -tony
> 
> -- 
> A.J. Rossini				Rsrch. Asst. Prof. of 
> Biostatistics
> U. of Washington Biostatistics		
> rossini at u.washington.edu	
> FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
> -------------- http://software.biostat.washington.edu/ 
> ----------------
> FHCRC: M-W: 206-667-7025 (fax=4812)|Voicemail is pretty 
> sketchy/use Email
> UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
> (my friday location is usually completely unpredictable.)
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._


LEGAL NOTICE
Unless expressly stated otherwise, this message is confidential and may be privileged. It is intended for the addressee(s) only. Access to this E-mail by anyone else is unauthorized. If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful. If you are not an addressee, please inform the sender immediately.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Mon Apr  8 23:41:54 2002
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 08 Apr 2002 17:41:54 -0400
Subject: [R] user coordinates and rug plots in lattice graphics
In-Reply-To: <009c01c1df3f$7ac35580$7632d882@stat.auckland.ac.nz>
References: <5.1.0.14.2.20020408095750.01d53918@pop>
 <5.1.0.14.2.20020408123005.01d54060@pop>
Message-ID: <5.1.0.14.2.20020408173907.01d54858@pop>

Dear Paul,

At 08:53 AM 4/9/2002 +1200, Paul Murrell wrote:

> > Using current.viewport()$yscale does the trick -- for example:
>
>
>One note of warning about this approach -- this is poking around in the
>internal structure of grid viewports, which are not guaranteed to stay that
>way.  This is not your fault of course because I have failed to supply
>decent (or any) support for querying grid's coordinate system state :)
>
>OTOH, there is a "better" way to do this -- at least, there is a way to do
>this which is more inkeeping with grid's philosophy.  If you want the rug
>lines anchored at the bottom of the plot region, the easy way to specify
>that is to use grid's "npc" coordinates -- bottom-left = (0, 0) and
>top-right = (1, 1).  Furthermore, you could draw the rug lines as actual
>line segments and make use of grid's other coordinate systems to control the
>height of the rug lines properly.  Here are a couple of alternative xyplot
>calls to show what I mean ...
>
>      # rug lines are 3mm high
>      xyplot(y~x|f,
>             panel = function(x,y,...) {
>               panel.xyplot(x,y,...)
>               grid.segments(x, unit(0, "npc"), x, unit(3, "mm"),
>                             default.units="native")
>          })
>      # rug lines are 1/20th of the height of the plot
>      xyplot(y~x|f,
>             panel = function(x,y,...) {
>               panel.xyplot(x,y,...)
>               grid.segments(x, unit(0, "npc"), x, unit(0.05, "npc"),
>                             default.units="native")
>          })
>
>... of course, the downside is that you have to encounter the raw grid
>functions to do this.

This is exactly what I wanted. I'll just encapsulate the call to 
grid.segments in an lrug function.

Thank you,
  John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From alvaro at novo-online.net  Tue Apr  9 00:41:55 2002
From: alvaro at novo-online.net (Alvaro A. Novo)
Date: Mon, 8 Apr 2002 22:41:55 +0000
Subject: [R] Missing data and Imputation
In-Reply-To: <87zo0e3web.fsf@jeeves.blindglobe.net>
References: <XFMail.020408172332.Ted.Harding@nessie.mcc.ac.uk> <87zo0e3web.fsf@jeeves.blindglobe.net>
Message-ID: <200204082241.55247.alvaro@novo-online.net>

On Mon April 8 2002 17:58, A.J. Rossini wrote:
   > >>>>> "ted" == Ted Harding <Ted> writes:
   >
   >     ted> Hi Folks,
   >     ted> I'm currently looking at missing data/imputation
   >     ted> methods (including multiple imputation).
   >
   >     ted> S-Plus has a "missing data library".
   >
   >     ted> What similar resources are available within R?
   >
   > Joe Shafer's packages (cat, norm, mix), which may form the basis for
   > S-Plus'  library (I don't remember this, any more) are available.

In particular norm is available at

http://cran.r-project.org/src/contrib/norm_1.0-7.tar.gz

Windows version might also be available.

Alvaro Novo
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Apr  9 00:25:42 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 09 Apr 2002 00:25:42 +0200
Subject: [R] user coordinates and rug plots in lattice graphics
In-Reply-To: <009c01c1df3f$7ac35580$7632d882@stat.auckland.ac.nz>
References: <5.1.0.14.2.20020408095750.01d53918@pop>
	<5.1.0.14.2.20020408123005.01d54060@pop>
	<009c01c1df3f$7ac35580$7632d882@stat.auckland.ac.nz>
Message-ID: <x2wuvhddzt.fsf@blueberry.kubism.ku.dk>

"Paul Murrell" <p.murrell at auckland.ac.nz> writes:

>      # rug lines are 3mm high
>      xyplot(y~x|f,
>             panel = function(x,y,...) {
>               panel.xyplot(x,y,...)
>               grid.segments(x, unit(0, "npc"), x, unit(3, "mm"),
>                             default.units="native")
>          })
>      # rug lines are 1/20th of the height of the plot
>      xyplot(y~x|f,
>             panel = function(x,y,...) {
>               panel.xyplot(x,y,...)
>               grid.segments(x, unit(0, "npc"), x, unit(0.05, "npc"),
>                             default.units="native")
>          })
> 
> ... of course, the downside is that you have to encounter the raw grid
> functions to do this.

Sorry for butting in (and possibly revealing my ignorance about the
inner workings of grid and lattice), but wouldn't lines of text be a
natural unit here? 

It has BTW crossed my mind that the current rug() using axis() is
rather unfortunate if you want to have multiple rugs on several lines
at the bottom of a plot, and that a version using segments() might be
better.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.murrell at auckland.ac.nz  Tue Apr  9 00:37:56 2002
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue, 9 Apr 2002 10:37:56 +1200
Subject: [R] user coordinates and rug plots in lattice graphics
References: <5.1.0.14.2.20020408095750.01d53918@pop><5.1.0.14.2.20020408123005.01d54060@pop><009c01c1df3f$7ac35580$7632d882@stat.auckland.ac.nz> <x2wuvhddzt.fsf@blueberry.kubism.ku.dk>
Message-ID: <010901c1df4e$070e10d0$7632d882@stat.auckland.ac.nz>

Hi


> "Paul Murrell" <p.murrell at auckland.ac.nz> writes:
>
> >      # rug lines are 3mm high
> >      xyplot(y~x|f,
> >             panel = function(x,y,...) {
> >               panel.xyplot(x,y,...)
> >               grid.segments(x, unit(0, "npc"), x, unit(3, "mm"),
> >                             default.units="native")
> >          })
> >      # rug lines are 1/20th of the height of the plot
> >      xyplot(y~x|f,
> >             panel = function(x,y,...) {
> >               panel.xyplot(x,y,...)
> >               grid.segments(x, unit(0, "npc"), x, unit(0.05, "npc"),
> >                             default.units="native")
> >          })
> >
> > ... of course, the downside is that you have to encounter the raw grid
> > functions to do this.
>
> Sorry for butting in (and possibly revealing my ignorance about the
> inner workings of grid and lattice), but wouldn't lines of text be a
> natural unit here?


If you like.  Lines of text are possible too ...

     # rug lines are half a line of text in height
     xyplot(y~x|f,
            panel = function(x,y,...) {
              panel.xyplot(x,y,...)
              grid.segments(x, unit(0, "npc"), x, unit(0.5, "lines"),
                            default.units="native")
         })

... my main point is that you can choose which one you prefer if you go down
to the low-level grid functions.

Paul


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Apr  9 00:49:19 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 09 Apr 2002 00:49:19 +0200
Subject: [R] pooling categories in a table
In-Reply-To: <5.1.0.14.2.20020408165358.01d60dd0@pop>
References: <5.1.0.14.2.20020408165358.01d60dd0@pop>
Message-ID: <x2sn65dcwg.fsf@blueberry.kubism.ku.dk>

John Fox <jfox at mcmaster.ca> writes:

> Dear Mike,
> 
> At 01:53 PM 4/8/2002 -0400, Michael Friendly wrote:
> >I have a large n-way contingency table, constructed as a table
> >object, and want to pool (collapse) some categories, summing the
> >frequencies in all collapsed cells.  How can I do this?
> 
> Use apply; for example:
> 
>      > tab <- as.table(array(1:24, c(2,3,4)))
..
>     > apply(tab, c(2,3), sum)  # sums over first coordinate
>      A  B  C  D
>      A  3 15 27 39
>      B  7 19 31 43
>      C 11 23 35 47
> 
> I hope that this helps,

margin.table does this too. However, I'm afraid this wasn't the
question. I suspect it was to reduce, say, the 3rd classifier from
four levels to two. 

This is more tricky, but at least with xtabs objects you can do things
like this:

 data(UCBAdmissions)
 DF <- as.data.frame(UCBAdmissions)
 DF$Dept <- factor(c(1,2,2,3,4,5)[DF$Dept],
     labels=c("A","B+C","D","E","F"))
 xtabs(Freq~.,DF)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From John.Strumila at team.telstra.com  Tue Apr  9 01:23:40 2002
From: John.Strumila at team.telstra.com (Strumila, John)
Date: Tue, 9 Apr 2002 09:23:40 +1000 
Subject: [R] pooling categories in a table
Message-ID: <61411576E951D211AF330008C7245DD90D7C6C04@ntmsg0005.corpmail.telstra.com.au>

beautiful, I didn't realise you could use "c(2,3)".  Its not in "help".  I
guess it's so obvious now...

John Strumila

    > apply(tab, c(2,3), sum)  # sums over first coordinate
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From abunn at montana.edu  Tue Apr  9 01:24:28 2002
From: abunn at montana.edu (Andy Bunn)
Date: Mon, 8 Apr 2002 17:24:28 -0600
Subject: [R] Still having a problem with Rcmd - TMPDIR
Message-ID: <LMEJKIHONHAAOFDBLDHCCEJKCCAA.abunn@montana.edu>

Hello R-users:

I'm experiencing difficulty in building a package in R 1.4.1 under Windows
2000. When I run Rcmd I get this:

F:\r\library>f:\r\bin\rcmd check ringsim
Please set TMPDIR to a valid temporary directory

F:\r\library>f:\r\bin\rcmd build ringsim
Please set TMPDIR to a valid temporary directory


This problem was discussed over a year ago - the problem was attributed to a
Perl bug. The CHECK file was amended in the build and indeed mine has the
line:

unless (-e $tmpdir);

It was thought that the -d was the bug. I added a print statement to CHECK
as per B. Ripley's suggestion:

$WINDOWS = ($OS eq "windows");
if($WINDOWS) {
    $TMPDIR = R_getenv("TMPDIR", "/TEMP");
    print "tmpdir is $tmpdir\n"; # added line
    die "Please set TMPDIR to a valid temporary directory\n"
      unless (-e $tmpdir);
    $R_exe = "Rterm.exe";
    $LATEX = "latex";
    $MAKE = "make";
}

The output is below:

F:\r\library>f:\r\bin\rcmd check ringsim
tmpdir is
Please set TMPDIR to a valid temporary directory

So it does indeed appear that there is no tmpdir. How can I set this
variable? The default temp directory on my machine is e:\temp but all other
applications see it. I'm running the latest perl (v5.6.1 built for
MSWin32-x86-multi-thread).

Any help appreciated.

Thanks in advance,
Andy

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From nawlnz at yahoo.com  Tue Apr  9 01:46:31 2002
From: nawlnz at yahoo.com (Dennis L. Malandro)
Date: Mon, 8 Apr 2002 16:46:31 -0700 (PDT)
Subject: [R] factor labels in model.frame
Message-ID: <20020408234631.51642.qmail@web14403.mail.yahoo.com>

Hello,

model.frame changes the factor labels when na.action =
na.omit.

> f <- gl(3, 2, 6, paste('m', 1:3, sep = ''))
> r <- c(NA, NA, 3:6)
> mf <- model.frame(~ r + f, na.action = na.omit)
> mf
  r  f
3 3 m1
4 4 m1
5 5 m2
6 6 m2

But it seems like it should be this
> mf
  r  f
3 3 m2
4 4 m2
5 5 m3
6 6 m3

intead.

How do I get the second mf?

Thanks a lot,
Dennis

R 1.4.1
Windows 98



__________________________________________________

Yahoo! Tax Center - online filing with TurboTax

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From r.hankin at auckland.ac.nz  Tue Apr  9 01:34:12 2002
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Tue, 9 Apr 2002 11:34:12 +1200
Subject: [R] pooling categories in a table
In-Reply-To: <x2sn65dcwg.fsf@blueberry.kubism.ku.dk> (message from Peter
	Dalgaard BSA on 09 Apr 2002 00:49:19 +0200)
References: <5.1.0.14.2.20020408165358.01d60dd0@pop> <x2sn65dcwg.fsf@blueberry.kubism.ku.dk>
Message-ID: <200204082334.g38NYC704556@r.hankin.sems.auckland.ac.nz>

Peter Dalgaard writes:

> 
>  data(UCBAdmissions)
>  DF <- as.data.frame(UCBAdmissions)
>  DF$Dept <- factor(c(1,2,2,3,4,5)[DF$Dept],
>      labels=c("A","B+C","D","E","F"))
>  xtabs(Freq~.,DF)
> 


This is simply brilliant.  I found it very very instructive; any
chance of adding it to the examples section of xtabs()' help file?




-- 

Robin Hankin, Lecturer,
School of Geographical and Environmental Science
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042

as of: Tue Apr  9 11:29:00 NZST 2002
This (linux) system up continuously for:  222 days, 18 hours, 24 minutes
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Tue Apr  9 01:59:26 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 8 Apr 2002 16:59:26 -0700 (PDT)
Subject: [R] factor labels in model.frame
In-Reply-To: <20020408234631.51642.qmail@web14403.mail.yahoo.com>
Message-ID: <Pine.A41.4.44.0204081656060.91766-100000@homer21.u.washington.edu>

On Mon, 8 Apr 2002, Dennis L. Malandro wrote:

> Hello,
>
> model.frame changes the factor labels when na.action =
> na.omit.
>
> > f <- gl(3, 2, 6, paste('m', 1:3, sep = ''))
> > r <- c(NA, NA, 3:6)
> > mf <- model.frame(~ r + f, na.action = na.omit)
> > mf
>   r  f
> 3 3 m1
> 4 4 m1
> 5 5 m2
> 6 6 m2
>
> But it seems like it should be this
> > mf
>   r  f
> 3 3 m2
> 4 4 m2
> 5 5 m3
> 6 6 m3
>
> intead.

It certainly should, and on my machine it is (both Linux and Win2k). I
don't see how you can get the first answer.

	-thomas



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ggrothendieck at yifan.net  Tue Apr  9 02:58:29 2002
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Mon, 8 Apr 2002 20:58:29 -0400
Subject: [R] Problem(?) in strptime()
In-Reply-To: <p05101500b8d77b58229f@[128.115.153.6]>
Message-ID: <3CB20475.15044.20EE2D1@localhost>

Try this:

library(chron)
dts <- dates(c("04/07/02","04/07/02"))
tms <- times(c("01:30:00","02:30:00"))
x <- chron(dts,tms)
y <- as.POSIXct(x,tz="GMT")
y   # returns date/times
y[2]-y[1]   # returns a difference of 1 hour





On 8 Apr 2002 at 12:33, Don MacQueen wrote:

> I think the following examples illustrate the crux of the matter 
> (version and OS info are below).
> 
> The problem has to do with the transition from standard time to 
> daylight savings time. My timezone, US/Pacific, has two parts: 
> standard time (PST) 8 hours behind GMT and daylight savings time 
> (PDT) 7 hours behind GMT. The transition takes place this year on 7 
> April at 02:00, when 02:00 is re-labeled 03:00.
> 
> ## April 6, 01:30 and 02:30
> >  ISOdatetime(2002, 4, 6, 1:2, 30, 0,tz='GMT')
> [1] "2002-04-05 17:30:00 PST" "2002-04-05 18:30:00 PST"
> 
> ## April 7 , 01:30 and 02:30
> >  ISOdatetime(2002, 4, 7, 1:2, 30, 0,tz='GMT')
> [1] "2002-04-06 17:30:00 PST" "2002-04-06 17:30:00 PST"
> 
> The dates supplied are one day apart. The times supplied are one hour 
> apart. However, the times returned are one hour apart in the first 
> case, but identical in the second case.
> 
> >  tmp <- ISOdatetime(2002, 4, 7, 1:2, 30, 0,tz='GMT')
> >  identical(tmp[1],tmp[2])
> [1] TRUE
> 
> Of the four values returned, the last one is incorrect, because 
> 2002-4-7 2:30 GMT truly is 2002-4-6 18:30 PST.
> 
> What I need is a way to have that fourth case interpreted correctly.
> 
> 
> Investigating a bit:
> 
> >  ISOdatetime
> function (year, month, day, hour, min, sec, tz = "")
> {
>      x <- paste(year, month, day, hour, min, sec)
>      as.POSIXct(strptime(x, "%Y %m %d %H %M %S"), tz = tz)
> }
> 
> >  strptime
> function (x, format)
> .Internal(strptime(x, format))
> 
> ISOdatetime() uses strptime(), and strptime() does not use the 
> timezone information. Indeed, from ?strptime, TZ as part of a format 
> specification is available for output only.
> 
> As far as I can tell, strptime() interprets everything in the local 
> timezone, and when provided a time such as 2002-4-7 2:30 that 
> "doesn't exist" in the local timezone, makes a reasonable attempt to 
> guess what the user meant. But it doesn't work for what ISOdatetime() 
> does with it when tz is something other than ''.
> 
> What I need is a way to tell R that the date-time string really truly 
> should be interpreted as GMT. I haven't found a way. (maybe setenv TZ 
> GMT before starting R, but I'm still exploring that)
> 
> Also as far as I can tell, strptime() uses an OS-supplied strptime if 
> one is available, and R is entirely dependent on its behavior. I 
> don't entirely understand what man strptime on my system says about 
> this, but maybe it suggests that timezone information might be used 
> if provided...
> 
>       %Z    Timezone name or no characters if no time zone  infor-
>             mation  exists.  Local timezone information is used as
>             though  strptime()  called  tzset()  (see  ctime(3C)).
>             Errors  may not be detected.  This behavior is subject
>             to change in a future release.
> 
> 
> >  Sys.getlocale()
> [1] "C"
> >  version
> 
> >  Sys.getenv('TZ')
>            TZ
> "US/Pacific"
>         _
> platform sparc-sun-solaris2.7
> arch     sparc
> os       solaris2.7
> system   sparc, solaris2.7
> status
> major    1
> minor    4.1
> year     2002
> month    01
> day      30
> language R
> 
> I tried changing the locale
>     Sys.setlocale('LC_TIME','en_GB')
> (based on entries in /usr/lib/locale/lcttab), and
>     Sys.putenv('TZ=GMT')
> to no avail.
> 
> ----------------------------------------------
> This whole thing is motivated by the fact that I am receiving some 
> data that is time-stamped, and the time stamps (in addition to having 
> a poorly chosen format) ignore the daylight savings time convention. 
> That is, they always use an 8 hour offset from GMT. Thus, the three 
> times shown are in fact an hourly sequence.
> 
> Sun Apr 07 01:30:58 2002
> Sun Apr 07 02:30:58 2002
> Sun Apr 07 03:30:58 2002
> 
> In order to convert these correctly to POSIXct, I thought a 
> reasonable approach would be to tell R that they are in GMT, read 
> them as such, and then convert to US/Pacific.
> 
> Here is what I have been using.
> 
> tmpd <- c('Sun Apr 07 01:30:58 2002',
>            'Sun Apr 07 02:30:58 2002',
>            'Sun Apr 07 03:30:58 2002')
> tmpt <- as.POSIXct(strptime(tmpd,'%a %b %d %H:%M:%S %Y'),tz='GMT')+28800
> 
> >  tmpt
> [1] "2002-04-07 01:30:58 PST" "2002-04-07 01:30:58 PST" "2002-04-07 
> 04:30:58 PDT"
> 
> It works for the first and last times, but not the middle one
> (3:30 "PST" = 4:30 PDT is correct, but 2:30 "PST" should be 3:30 PDT).
> 
> I would appreciate help finding a way that works for all of them 
> simultaneously.
> 
> Thanks
> -Don
> 
> 
> -----------------
> Here are some more attempts at various ways of looking at these 
> dates, if anyone cares to wade through them.
> 
> >  strptime('2002-4-7 1:30' , '%Y-%m-%d %H:%M')
> [1] "2002-04-07 01:30:00"
> >  strptime('2002-4-7 2:30' , '%Y-%m-%d %H:%M')
> [1] "2002-04-07 01:30:00"
> >  strptime('2002-4-7 3:30' , '%Y-%m-%d %H:%M')
> [1] "2002-04-07 03:30:00"
> 
> The first and last display as two hours apart.
> The second one is interpreted by strptime() to be the same as the 
> first one. Not unreasonable, but problematic as illustrated above.
> 
> -------
> >  as.numeric(as.POSIXct(strptime('2002-4-7 1:30' , '%Y-%m-%d %H:%M')))
> [1] 1018171800
> >  as.numeric(as.POSIXct(strptime('2002-4-7 2:30' , '%Y-%m-%d %H:%M')))
> [1] 1018171800
> >  as.numeric(as.POSIXct(strptime('2002-4-7 3:30' , '%Y-%m-%d %H:%M')))
> [1] 101817540
> 
> >  1018175400 - 1018171800
> [1] 3600
> 
> But in fact, the first and last are only one hour apart. This is 
> correct, because the first one is PST, the third one is PDT.
> 
> -------
> >  as.POSIXct(strptime('2002-4-7 1:30' , '%Y-%m-%d %H:%M'),tz='GMT')
> [1] "2002-04-06 17:30:00 PST"
> >  as.POSIXct(strptime('2002-4-7 2:30' , '%Y-%m-%d %H:%M'),tz='GMT')
> [1] "2002-04-06 17:30:00 PST"
> >  as.POSIXct(strptime('2002-4-7 3:30' , '%Y-%m-%d %H:%M'),tz='GMT')
> [1] "2002-04-06 19:30:00 PST"
> 
> >  as.POSIXct(strptime('2002-4-7 1:30' , '%Y-%m-%d %H:%M'),tz='US/Pacific')
> [1] "2002-04-07 01:30:00 PST"
> >  as.POSIXct(strptime('2002-4-7 2:30' , '%Y-%m-%d %H:%M'),tz='US/Pacific')
> [1] "2002-04-07 01:30:00 PST"
> >  as.POSIXct(strptime('2002-4-7 3:30' , '%Y-%m-%d %H:%M'),tz='US/Pacific')
> [1] "2002-04-07 03:30:00 PDT"
> 
> -- 
> --------------------------------------
> Don MacQueen
> Environmental Protection Department
> Lawrence Livermore National Laboratory
> Livermore, CA, USA
> --------------------------------------
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hammour at msn.com  Tue Apr  9 05:27:09 2002
From: hammour at msn.com (Ahmad Abu Hammour)
Date: Mon, 8 Apr 2002 23:27:09 -0400
Subject: [R] Restricted Least Squares
Message-ID: <OE150gXLsxpTljBOh8s0000d005@hotmail.com>

Hi,
I need help regarding estimating a linear model where restrictions are imposed on the coefficients. An example is as follows:
Y_{t+2}=a1Y_{t+1} + a2 Y_t + b x_t + e_t
restriction
a1+ a2 =1
Is there a function or a package that can estimate the coefficient of a model like this? I want to estimate the coefficients rather than test them.
Thank you for your help
Ahmad Abu Hammour  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20020408/691e8359/attachment.html

From ligges at statistik.uni-dortmund.de  Tue Apr  9 08:25:43 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 09 Apr 2002 08:25:43 +0200
Subject: [R] Still having a problem with Rcmd - TMPDIR
References: <LMEJKIHONHAAOFDBLDHCCEJKCCAA.abunn@montana.edu>
Message-ID: <3CB28967.2857ADCD@statistik.uni-dortmund.de>

Andy Bunn wrote:
> 
> Hello R-users:
> 
> I'm experiencing difficulty in building a package in R 1.4.1 under Windows
> 2000. When I run Rcmd I get this:
> 
> F:\r\library>f:\r\bin\rcmd check ringsim
> Please set TMPDIR to a valid temporary directory
> 
> F:\r\library>f:\r\bin\rcmd build ringsim
> Please set TMPDIR to a valid temporary directory
> 
> This problem was discussed over a year ago - the problem was attributed to a
> Perl bug. The CHECK file was amended in the build and indeed mine has the
> line:
> 
> unless (-e $tmpdir);
> 
> It was thought that the -d was the bug. I added a print statement to CHECK
> as per B. Ripley's suggestion:
> 
> $WINDOWS = ($OS eq "windows");
> if($WINDOWS) {
>     $TMPDIR = R_getenv("TMPDIR", "/TEMP");
>     print "tmpdir is $tmpdir\n"; # added line
>     die "Please set TMPDIR to a valid temporary directory\n"
>       unless (-e $tmpdir);
>     $R_exe = "Rterm.exe";
>     $LATEX = "latex";
>     $MAKE = "make";
> }
> 
> The output is below:
> 
> F:\r\library>f:\r\bin\rcmd check ringsim
> tmpdir is
> Please set TMPDIR to a valid temporary directory
> 
> So it does indeed appear that there is no tmpdir. How can I set this
> variable? The default temp directory on my machine is e:\temp but all other
> applications see it. I'm running the latest perl (v5.6.1 built for
> MSWin32-x86-multi-thread).

>From ..../src/gnuwin32/readme.packages:
"You may need to set TMPDIR to a suitable temporary directory: the
default is c:\TEMP."
How to set environment variables should be explained in your Windows
2000 help. You can set this to your temp directory e:\temp. 
(Control Panel - System - anywhere ???  Sorry, cannot remember the right
way on Win2k, not installed on any machine around here).

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Apr  9 09:59:52 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 09 Apr 2002 09:59:52 +0200
Subject: [R] pooling categories in a table
In-Reply-To: <200204082334.g38NYC704556@r.hankin.sems.auckland.ac.nz>
References: <5.1.0.14.2.20020408165358.01d60dd0@pop>
	<x2sn65dcwg.fsf@blueberry.kubism.ku.dk>
	<200204082334.g38NYC704556@r.hankin.sems.auckland.ac.nz>
Message-ID: <x2d6x91evb.fsf@blueberry.kubism.ku.dk>

Robin Hankin <r.hankin at auckland.ac.nz> writes:

> Peter Dalgaard writes:
> 
> > 
> >  data(UCBAdmissions)
> >  DF <- as.data.frame(UCBAdmissions)
> >  DF$Dept <- factor(c(1,2,2,3,4,5)[DF$Dept],
> >      labels=c("A","B+C","D","E","F"))
> >  xtabs(Freq~.,DF)
> > 
> 
> 
> This is simply brilliant.  I found it very very instructive; any
> chance of adding it to the examples section of xtabs()' help file?

Not at this stage with 1.5.0 in feature freeze, I think. (Help page
examples are "features" because they become part of the test suite. An
unfortunate example could break the test suite on some platforms and
destabilize the whole process. Of course *this* particular case is
very likely harmless, but we need hard rules.) We can do it for
r-devel afterwards.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kwan022 at stat.auckland.ac.nz  Tue Apr  9 10:05:11 2002
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 9 Apr 2002 20:05:11 +1200 (NZST)
Subject: [R] Fortran (77)  in R
Message-ID: <Pine.SOL.4.21.0204092002440.5386-100000@stat1.stat.auckland.ac.nz>

Hi,

I'm learning Fortran and trying to load a Fortran subroutine into R.

I've done:
   R SHLIB Fibonacci.f
and it compiled fine.

Then I went into R and done:
> dyn.load("Fibonacci.so")
> Fib <- function(n) {
+     .Fortran("Fibonacci",
+              as.integer(n))[[1]]
+ }
> Fib(5) 
Error in .Fortran("Fibonacci", as.integer(n)) : 
        C/Fortran function name not in load table

The dyn.load() worked fine, or so it seems.  I then tried writing a
function that calls my Fortran subroutine.  However the error message was
displayed, which I have no idea what it mean ;-(

Any help will be greatly appreciated!


Cheers,

Kevin

------------------------------------------------------------------------------
Ko-Kang Kevin Wang
Postgraduate PGDipSci Student
Department of Statistics
University of Auckland
New Zealand

Homepage: http://www.stat.auckland.ac.nz/~kwan022

E-mail: kwan022 at stat.auckland.ac.nz

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Apr  9 10:13:30 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 09 Apr 2002 10:13:30 +0200
Subject: [R] Fortran (77)  in R
In-Reply-To: <Pine.SOL.4.21.0204092002440.5386-100000@stat1.stat.auckland.ac.nz>
References: <Pine.SOL.4.21.0204092002440.5386-100000@stat1.stat.auckland.ac.nz>
Message-ID: <x24ril1e8l.fsf@blueberry.kubism.ku.dk>

Ko-Kang Kevin Wang <kwan022 at stat.auckland.ac.nz> writes:

> Hi,
> 
> I'm learning Fortran and trying to load a Fortran subroutine into R.
> 
> I've done:
>    R SHLIB Fibonacci.f
> and it compiled fine.
> 
> Then I went into R and done:
> > dyn.load("Fibonacci.so")
> > Fib <- function(n) {
> +     .Fortran("Fibonacci",
> +              as.integer(n))[[1]]
> + }
> > Fib(5) 
> Error in .Fortran("Fibonacci", as.integer(n)) : 
>         C/Fortran function name not in load table
> 
> The dyn.load() worked fine, or so it seems.  I then tried writing a
> function that calls my Fortran subroutine.  However the error message was
> displayed, which I have no idea what it mean ;-(
> 
> Any help will be greatly appreciated!

It cannot find the entry point "Fibonacci" in your .so file. What is
the name of the subroutine you are trying to call? One possible issue
is that Fortran is not case sensitive, so it might be "fibonacci",
whichever way you spelled it originally. "nm Fibonacci.so" could be
enlightening.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From phgrosje at ulb.ac.be  Tue Apr  9 10:22:48 2002
From: phgrosje at ulb.ac.be (Philippe Grosjean)
Date: Tue, 9 Apr 2002 10:22:48 +0200
Subject: [R] Restricted Least Squares
Message-ID: <MABBLJDICACNFOLGIHJOKEJKCKAA.phgrosje@ulb.ac.be>

 > Hi,

> I need help regarding estimating a linear model where restrictions are
imposed on the coefficients. An example is as follows:

> Y_{t+2}=a1Y_{t+1} + a2 Y_t + b x_t + e_t

> restriction
> a1+ a2 =1

> Is there a function or a package that can estimate the coefficient of a
model like this? I want to estimate the coefficients rather than test them.

> Thank you for your help

> Ahmad Abu Hammour

You don't need something special. Just consider that

a2 = 1 - a1 and replace it in your equation, which gives:

Y_{t+2}=a1Y_{t+1} + (1 - a1) Y_t + b x_t + e_t

Best,

Philippe Grosjean



...........]<(({?<...............<?}))><...............................
 ) ) ) ) )       __                      __
( ( ( ( (       |__)                    |  _
 ) ) ) ) )      |   hilippe             |__)rosjean
( ( ( ( (       Marine Biol. Lab., ULB, Belgium
 ) ) ) ) )                               __
( ( ( ( (       |\  /|                  |__)
 ) ) ) ) )      | \/ |ariculture &      |__)iostatistics
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosje at ulb.ac.be or phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )      tel: 00-32-2-650.29.70 (lab), 00-32-2-673.31.33 (home)
( ( ( ( (
 ) ) ) ) )      "I'm 100% confident that p is between 0 and 1"
( ( ( ( (                                  L. Gonick & W. Smith (1993)
 ) ) ) ) )
.......................................................................


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kwan022 at stat.auckland.ac.nz  Tue Apr  9 10:30:13 2002
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 9 Apr 2002 20:30:13 +1200 (NZST)
Subject: [R] Fortran (77)  in R
In-Reply-To: <x24ril1e8l.fsf@blueberry.kubism.ku.dk>
Message-ID: <Pine.SOL.4.21.0204092027570.6612-100000@stat1.stat.auckland.ac.nz>

On 9 Apr 2002, Peter Dalgaard BSA wrote:

> Date: 09 Apr 2002 10:13:30 +0200
> From: Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk>
> To: Ko-Kang Kevin Wang <kwan022 at stat.auckland.ac.nz>
> Cc: R Help <r-help at stat.math.ethz.ch>
> Subject: Re: [R] Fortran (77)  in R
> 
> Ko-Kang Kevin Wang <kwan022 at stat.auckland.ac.nz> writes:
> 
> > Hi,
> > 
> 
> It cannot find the entry point "Fibonacci" in your .so file. What is
> the name of the subroutine you are trying to call? One possible issue
> is that Fortran is not case sensitive, so it might be "fibonacci",
> whichever way you spelled it originally. "nm Fibonacci.so" could be
> enlightening.

I've doubled checked my spelling, my Fortran program looks like:
c23456789
      SUBROUTINE Fibonacci(num)
      IMPLICIT NONE
      INTEGER num, i, fib, prev1, prev2
      prev1 = 1
      prev2 = 0
      DO 10 i = 0, num
        fib = prev1 + prev2
        prev2 = prev1
        prev1 = fib
10     continue
       return
      END SUBROUTINE

The first couple of lines from "nm Fibonacci.so" looks like:
Fibonacci.so:

[Index]   Value      Size    Type  Bind  Other Shndx   Name

[16]    |     84368|       0|SECT |LOCL |0    |15     |
[2]     |       148|       0|SECT |LOCL |0    |1      |
[3]     |      1000|       0|SECT |LOCL |0    |2      |
[4]     |      2728|       0|SECT |LOCL |0    |3      |
[5]     |      3672|       0|SECT |LOCL |0    |4      |
[6]     |      3704|       0|SECT |LOCL |0    |5      |
[7]     |      9860|       0|SECT |LOCL |0    |6      |
[8]     |     10352|       0|SECT |LOCL |0    |7      |
[9]     |     10436|       0|SECT |LOCL |0    |8      |
[snip]

Cheers,

Kevin

------------------------------------------------------------------------------
Ko-Kang Kevin Wang
Postgraduate PGDipSci Student
Department of Statistics
University of Auckland
New Zealand

Homepage: http://www.stat.auckland.ac.nz/~kwan022

E-mail: kwan022 at stat.auckland.ac.nz

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Tue Apr  9 11:30:44 2002
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Tue, 9 Apr 2002 11:30:44 +0200 (CEST)
Subject: [R] Fortran (77)  in R
In-Reply-To: <Pine.SOL.4.21.0204092027570.6612-100000@stat1.stat.auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0204091128400.16369-100000@tal.stat.umu.se>

On Tue, 9 Apr 2002, Ko-Kang Kevin Wang wrote:

> On 9 Apr 2002, Peter Dalgaard BSA wrote:
> 
> > Date: 09 Apr 2002 10:13:30 +0200
> > From: Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk>
> > To: Ko-Kang Kevin Wang <kwan022 at stat.auckland.ac.nz>
> > Cc: R Help <r-help at stat.math.ethz.ch>
> > Subject: Re: [R] Fortran (77)  in R
> > 
> > Ko-Kang Kevin Wang <kwan022 at stat.auckland.ac.nz> writes:
> > 
> > > Hi,
> > > 
> > 
> > It cannot find the entry point "Fibonacci" in your .so file. What is
> > the name of the subroutine you are trying to call? One possible issue
> > is that Fortran is not case sensitive, so it might be "fibonacci",
> > whichever way you spelled it originally. "nm Fibonacci.so" could be
> > enlightening.
> 
> I've doubled checked my spelling, my Fortran program looks like:
> c23456789
>       SUBROUTINE Fibonacci(num)
>       IMPLICIT NONE
>       INTEGER num, i, fib, prev1, prev2
>       prev1 = 1
>       prev2 = 0
>       DO 10 i = 0, num
>         fib = prev1 + prev2
>         prev2 = prev1
>         prev1 = fib
> 10     continue
>        return
>       END SUBROUTINE
[...]

Did you check the case matter Peter mentioned? Besides, your subroutine 
doesn't seem to do anything useful...

G?ran


> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-- 
 G?ran Brostr?m                      tel: +46 90 786 5223
 professor                           fax: +46 90 786 6614
 Department of Statistics            http://www.stat.umu.se/egna/gb/
 Ume? University
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Apr  9 11:52:22 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 09 Apr 2002 11:52:22 +0200
Subject: [R] pooling categories in a table
In-Reply-To: <x2d6x91evb.fsf@blueberry.kubism.ku.dk>
References: <5.1.0.14.2.20020408165358.01d60dd0@pop>
	<x2sn65dcwg.fsf@blueberry.kubism.ku.dk>
	<200204082334.g38NYC704556@r.hankin.sems.auckland.ac.nz>
	<x2d6x91evb.fsf@blueberry.kubism.ku.dk>
Message-ID: <x2g0252o89.fsf@blueberry.kubism.ku.dk>

Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:

> Robin Hankin <r.hankin at auckland.ac.nz> writes:
> 
> > Peter Dalgaard writes:
> > 
> > > 
> > >  data(UCBAdmissions)
> > >  DF <- as.data.frame(UCBAdmissions)
> > >  DF$Dept <- factor(c(1,2,2,3,4,5)[DF$Dept],
> > >      labels=c("A","B+C","D","E","F"))
> > >  xtabs(Freq~.,DF)
> > > 
> > 
> > 
> > This is simply brilliant.  I found it very very instructive; any
> > chance of adding it to the examples section of xtabs()' help file?
> 
> Not at this stage with 1.5.0 in feature freeze, I think. (Help page
> examples are "features" because they become part of the test suite. An
> unfortunate example could break the test suite on some platforms and
> destabilize the whole process. Of course *this* particular case is
> very likely harmless, but we need hard rules.) We can do it for
> r-devel afterwards.

And BTW, the canonical way of joining factor levels escaped me last
night:

levels(DF$Dept) <- c("A","B+C","B+C","D","E","F")

is usually clearer, unless you have inordinately long level labels.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From snw at mcs.st-and.ac.uk  Tue Apr  9 12:10:19 2002
From: snw at mcs.st-and.ac.uk (Simon Wood)
Date: Tue, 9 Apr 2002 11:10:19 +0100 (BST)
Subject: [R] Restricted Least Squares
In-Reply-To: <OE150gXLsxpTljBOh8s0000d005@hotmail.com>
Message-ID: <Pine.GSO.4.21.0204091037050.24600-100000@dolphin>

> I need help regarding estimating a linear model where restrictions are imposed on the coefficients. An example is as follows:
> Y_{t+2}=a1Y_{t+1} + a2 Y_t + b x_t + e_t
> restriction
> a1+ a2 =1
> Is there a function or a package that can estimate the coefficient of a model like this? I want to estimate the coefficients rather than test them.
- pcls() in package mgcv will do this (although you'll need to
re-parameterize so that the restriction is a1+a2=0). 

Alternatively the following fits: 
y = b0 + b1 x + e subject to b0 + b1 = 1
having reparameterized as
y = b0 + (b1+1) x + e subject to b0 + b1 = 0

x<-runif(100)
y<-x+rnorm(100)*0.1            # simulate some data
cm<-matrix(c(1,1),1,2)         # make constraint matrix C so Cb=0 
cqr<-qr(t(cm))                 # QR decomp of C'
# if m constraints then last m cols of Q give null space Z of constraints: 
Z<-qr.Q(cqr,complete=TRUE)[,2] 
X<-model.matrix(y~x)            # model matrix
XZ<-X%*%Z                     # model matrix in constraint null space
p<-lm(y~XZ-1+offset(x))$coeff # estimate model in null space 
p<-Z%*%as.matrix(p)           # estimates in original space 
p[2]<-p[2]+1                  # undo reparameterization
p      
plot(x,y);abline(p)

... this can be easily generalized to do what you want.

Simon

  ______________________________________________________________________
> Simon Wood  snw at st-and.ac.uk  http://www.ruwpa.st-and.ac.uk/simon.html
> The Mathematical Institute, North Haugh, St. Andrews, Fife KY16 9SS UK
> Direct telephone: (0)1334 463799          Indirect fax: (0)1334 463748 




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From schlatti at mailer.ukbf.fu-berlin.de  Tue Apr  9 14:45:46 2002
From: schlatti at mailer.ukbf.fu-berlin.de (Dr. Peter Schlattmann)
Date: Tue, 9 Apr 2002 14:45:46 +0200 (CEST)
Subject: [R] readline editor
Message-ID: <Pine.LNX.4.21.0204091442210.3884-100000@postamt.ukbf.fu-berlin.de>


Dear all,

I have a problem with the readline editor of R since it doesn't work.
Setting ./configure --with-readline does not the fix the problem.

Does anyone have an idea how to fix this? Many thanks in advance!



Peter Schlattmann


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From friendly at yorku.ca  Tue Apr  9 15:34:27 2002
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 09 Apr 2002 09:34:27 -0400
Subject: [R] re: pooling categories in a table
Message-ID: <3CB2EDE3.E29B379A@yorku.ca>

Perhaps I should have given an example.

#  5 column matrix:  Day, Time, Station, State, Freq    
 tv.matrix<-read.table("C:/R/mosaics/tv.dat")

> tv.matrix[1:5,]
  V1 V2 V3 V4 V5
1  1  1  1  1  6
2  2  1  1  1 18
3  3  1  1  1  6
4  4  1  1  1  2
5  5  1  1  1 11
> 

 tv <- array(tv.matrix[,5], dim=c(5,11,5,3))                            
dimnames(tv) <-
list(c("Monday","Tuesday","Wednesday","Thursday","Friday"), 
               
c("8:00","8:15","8:30","8:45","9:00","9:15","9:30",                    
"9:45","10:00","10:15","10:30"), 
                c("A","C","N","F","Other"), c("O","S","P"))
 names(dimnames(tv))<-c("Day", "Time", "Station", "State")

Say I want to collapse the 11 time categories to 3. The real problem
is when I have only the 4-way array (or an equivalent table).  But
here, I thought I could just collapse the 2nd column to 3 categories:

tv.matrix[,2] <- 1+ as.integer((tv.matrix[,2]-1) /4)
tv2 <- array(tv.matrix[,5],
dim=c(5,3,5,3))                                        
dimnames(tv2) <-
list(c("Monday","Tuesday","Wednesday","Thursday","Friday"), 
                c("8:00-8:45","9:00-9:45","10:00-10:30"), 
                c("A","C","N","F","Other"), c("O","S","P"))
 names(dimnames(tv2))<-c("Day", "Time", "Station", "State")

But something is wrong, because the margins are not the same:

> margin.table(tv,1)
Day
   Monday   Tuesday Wednesday  Thursday    Friday 
    21271     20486     19304     19779     17275 
> margin.table(tv2,1)
Day
   Monday   Tuesday Wednesday  Thursday    Friday 
      996       912       962       898       771 

What am I missing?

-Michael

-- 
Michael Friendly              friendly at yorku.ca
York University               http://www.math.yorku.ca/SCS/friendly.html
Psychology Department
4700 Keele Street             Tel:  (416) 736-5115 x66249
Toronto, Ontario, M3J 1P3     Fax:  (416) 736-5814
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From psu17772 at yahoo.com  Tue Apr  9 14:46:40 2002
From: psu17772 at yahoo.com (sonchawan tamkaew)
Date: Tue, 9 Apr 2002 05:46:40 -0700 (PDT)
Subject: [R] matrix dimension and for loop
Message-ID: <20020409124640.83338.qmail@web14506.mail.yahoo.com>

Dear all,

My questions are that if I have

> x<-rnorm(50)
> dim(x)<-c(10,5)
> y=1:5
> Z<-matrix(0,NROW(x),NROW(y))
> for (j in 1:NROW(y)) Z[,j]<-x[,j]*y[j]

1. Is there any other way to write this without 'for'
loop?

2. and if I don't know the dimension of x, which could
be only 1 column, how could I write the command
without using if (NCOL(x)==1), or something like that?
(in case I want to include them in my function.

Example of x is a vector.
> x<-rnorm(10)
> y=2
> Z<-matrix(0,NROW(x),NROW(y))
> for (j in 1:NROW(y)) Z[,j]<-x[,j]*y[j]
Error in x[, j] : incorrect number of dimensions

Could anyone please help me to solve these problem? 
Thank you very much for your kindness.


Sonchawan Tamkaew 

__________________________________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mel at mcs.st-and.ac.uk  Tue Apr  9 14:36:30 2002
From: mel at mcs.st-and.ac.uk (Mike Lonergan)
Date: Tue, 9 Apr 2002 13:36:30 +0100
Subject: [R] Restricted Least Squares
In-Reply-To: <MABBLJDICACNFOLGIHJOKEJKCKAA.phgrosje@ulb.ac.be>
Message-ID: <NEBBJLLBCLEDFLCCBKDAEELFCEAA.mel@mcs.st-andrews.ac.uk>



     > -----Original Message-----
     > From: owner-r-help at stat.math.ethz.ch
     > [mailto:owner-r-help at stat.math.ethz.ch]On Behalf Of Philippe Grosjean
     > Sent: 09 April 2002 09:23
     > To: Ahmad Abu Hammour
     > Cc: R-help at stat.math.ethz.ch
     > Subject: RE: [R] Restricted Least Squares
     >
     >
     >  > Hi,
     >
     > > I need help regarding estimating a linear model where
     > restrictions are
     > imposed on the coefficients. An example is as follows:
     >
     > > Y_{t+2}=a1Y_{t+1} + a2 Y_t + b x_t + e_t
     >
     > > restriction
     > > a1+ a2 =1
     >
     > > Is there a function or a package that can estimate the
     > coefficient of a
     > model like this? I want to estimate the coefficients rather
     > than test them.
     >
     > > Thank you for your help
     >
     > > Ahmad Abu Hammour
     >
     > You don't need something special. Just consider that
     >
     > a2 = 1 - a1 and replace it in your equation, which gives:
     >
     > Y_{t+2}=a1Y_{t+1} + (1 - a1) Y_t + b x_t + e_t
     >
     > Best,
     >
     > Philippe Grosjean


& it becomes really nice when Y_{t+1} is subtracted from both sides:

Y_{t+2} - Y_{t+1} = a1Y_{t+1} - Y_{t+1} + (1 - a1) Y_t + b x_t + e_t

Substituting

Z_{t+1} = Y_{t+1} - Y_{t}


then gives:

Z_{t+1} = -a2Z_{t} + bx_t + e_t

Which is unconstrained and much easier, unless I've entirely missed the
point.

Cheers,

Mike.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Apr  9 16:20:21 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 09 Apr 2002 16:20:21 +0200
Subject: [R] readline editor
In-Reply-To: <Pine.LNX.4.21.0204091442210.3884-100000@postamt.ukbf.fu-berlin.de>
References: <Pine.LNX.4.21.0204091442210.3884-100000@postamt.ukbf.fu-berlin.de>
Message-ID: <x27knh2btm.fsf@blueberry.kubism.ku.dk>

"Dr. Peter Schlattmann" <schlatti at mailer.ukbf.fu-berlin.de> writes:

> Dear all,
> 
> I have a problem with the readline editor of R since it doesn't work.
> Setting ./configure --with-readline does not the fix the problem.
> 
> Does anyone have an idea how to fix this? Many thanks in advance!

Which system?

On Linuxen, the common mistake is not to have installed the
development libraries and header files for readline. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lukas.kubin at permonik.com  Tue Apr  9 16:13:47 2002
From: lukas.kubin at permonik.com (Lukas Kubin)
Date: Tue, 9 Apr 2002 16:13:47 +0200 (CEST)
Subject: [R] how to deal with singularities in lm()
Message-ID: <Pine.LNX.4.33.0204091611010.27239-100000@localhost.localdomain>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

I got the report

Coefficients: (1 not defined because of singularities)

while trying to get my model's coefficients from lm()
What shall I do to avoid it and get the one missing coefficient?
Thank you.

lukas

- -- 
Lukas Kubin
lukas.kubin at permonik.com
phone: 00420603836180
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.0.5 (GNU/Linux)
Comment: Made with pgp4pine 1.75-6

iD8DBQE8svcf4TIZ2lmUAtsRAi1XAKCh93LmQUAgzPSJD4ZiiGneNTJUjwCguVds
oS5X569AKQV6+tTsuzy4aCg=
=si5U
-----END PGP SIGNATURE-----


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Tue Apr  9 16:42:01 2002
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Tue, 9 Apr 2002 10:42:01 -0400
Subject: [R] matrix dimension and for loop
In-Reply-To: <20020409124640.83338.qmail@web14506.mail.yahoo.com>; from psu17772@yahoo.com on Tue, Apr 09, 2002 at 05:46:40AM -0700
References: <20020409124640.83338.qmail@web14506.mail.yahoo.com>
Message-ID: <20020409104201.A22180@cattell.psych.upenn.edu>

On 04/09/02 05:46, sonchawan tamkaew wrote:
>My questions are that if I have
>
>> x<-rnorm(50)
>> dim(x)<-c(10,5)
>> y=1:5
>> Z<-matrix(0,NROW(x),NROW(y))
>> for (j in 1:NROW(y)) Z[,j]<-x[,j]*y[j]
>
>1. Is there any other way to write this without 'for'
>loop?

x <- matrix(rnorm(50),10,5) # collapsing your first two commands
y <- 1:5
Z <- matrix(0,nrow(x),length(y)) # case sensitive, and y is a vector 
Z[,length(y)] <- x %*% y

It isn't clear that this is what you want, though.  It fills up
one column of Z.

>2. and if I don't know the dimension of x, which could
>be only 1 column, how could I write the command
>without using if (NCOL(x)==1), or something like that?
>(in case I want to include them in my function.

I think it will still work.  So long as you pay attention to what
is a matrix - to which dim() applies - and what is a vector, to
which length() applies.

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Tue Apr  9 16:56:02 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 09 Apr 2002 16:56:02 +0200
Subject: [R] matrix dimension and for loop
References: <20020409124640.83338.qmail@web14506.mail.yahoo.com>
Message-ID: <3CB30102.F9980FEF@statistik.uni-dortmund.de>



sonchawan tamkaew wrote:
> 
> Dear all,
> 
> My questions are that if I have
> 
> > x<-rnorm(50)
> > dim(x)<-c(10,5)
> > y=1:5
> > Z<-matrix(0,NROW(x),NROW(y))
> > for (j in 1:NROW(y)) Z[,j]<-x[,j]*y[j]
> 
> 1. Is there any other way to write this without 'for'
> loop?
> 
> 2. and if I don't know the dimension of x, which could
> be only 1 column, how could I write the command
> without using if (NCOL(x)==1), or something like that?
> (in case I want to include them in my function.
> 
> Example of x is a vector.
> > x<-rnorm(10)
> > y=2
> > Z<-matrix(0,NROW(x),NROW(y))
> > for (j in 1:NROW(y)) Z[,j]<-x[,j]*y[j]
> Error in x[, j] : incorrect number of dimensions
> 
> Could anyone please help me to solve these problem?
> Thank you very much for your kindness.


 x %*% diag(y, ncol(x))

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Tue Apr  9 16:54:56 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 09 Apr 2002 09:54:56 -0500
Subject: [R] matrix dimension and for loop
In-Reply-To: <20020409124640.83338.qmail@web14506.mail.yahoo.com>
References: <20020409124640.83338.qmail@web14506.mail.yahoo.com>
Message-ID: <6rd6x8gbwf.fsf@franz.stat.wisc.edu>

sonchawan tamkaew <psu17772 at yahoo.com> writes:

> Dear all,
> 
> My questions are that if I have
> 
> > x<-rnorm(50)
> > dim(x)<-c(10,5)
> > y=1:5
> > Z<-matrix(0,NROW(x),NROW(y))
> > for (j in 1:NROW(y)) Z[,j]<-x[,j]*y[j]
> 
> 1. Is there any other way to write this without 'for'
> loop?

Yes.  If you multiply (i.e. the '*' operator) a matrix and a vector
you will do operations columnwise on the matrix.  Here you want to
multiply the rows so you could transpose x, multiply by y and
transpose the result.

> x <- array(rnorm(50), dim = c(10,5))
> dim(x)
[1] 10  5
> y <- 1:5
> Z <- t(y * t(x))
> dim(Z)
[1] 10  5
> x[1,]
[1]  0.23144399 -0.25393369  0.06469486 -0.13116405  0.48534804
> Z[1,]
[1]  0.2314440 -0.5078674  0.1940846 -0.5246562  2.4267402

> 2. and if I don't know the dimension of x, which could
> be only 1 column, how could I write the command
> without using if (NCOL(x)==1), or something like that?
> (in case I want to include them in my function.

The above will work in that case too.

> x <- rnorm(10)
> y <- 2
> t(y * t(x))
            [,1]
 [1,]  1.5755705
 [2,]  0.3811325
 [3,] -0.4629773
 [4,]  1.7612785
 [5,]  0.7881174
 [6,] -0.2815202
 [7,]  0.4315893
 [8,]  1.1609736
 [9,]  1.8737894
[10,]  5.3069982
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Tue Apr  9 17:23:06 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 9 Apr 2002 08:23:06 -0700 (PDT)
Subject: [R] Fortran (77)  in R
In-Reply-To: <Pine.SOL.4.21.0204092027570.6612-100000@stat1.stat.auckland.ac.nz>
Message-ID: <Pine.A41.4.44.0204090820590.22398-100000@homer32.u.washington.edu>

On Tue, 9 Apr 2002, Ko-Kang Kevin Wang wrote:

>
> The first couple of lines from "nm Fibonacci.so" looks like:
> Fibonacci.so:
>
YOu don't want the first few lines, you want the line where `Fibonacci' is
defined.

	nm Fibonacci.so | fgrep ibonacci

should do it.

	-thomas



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From uleopold at science.uva.nl  Tue Apr  9 17:22:44 2002
From: uleopold at science.uva.nl (Ulrich Leopold)
Date: Tue, 09 Apr 2002 17:22:44 +0200
Subject: [R] couldn't find function "nclass.fd"
Message-ID: <3CB30744.3020004@science.uva.nl>

Dear list,

I get the following message while computing truehist in R 1.4.1 on 
Redhat Linux 7.1:


 > truehist(lsk$Pox, nbins = "FD" , prob = TRUE, xlab = "Pox [mmol/kg]")
Error in switch(casefold(nbins), scott = nclass.scott(data), 
"freedman-diaconis" = ,  :
         couldn't find function "nclass.fd"


Maybe the "nclass.fd" should be changed into "nclass.FD"?

But I could not find it in the directories.

Regards, Ulrich

-- 
__________________________________________________

Ulrich Leopold MSc.

Department of Physical Geography
Institute for Biodiversity and Ecosystem Dynamics
Faculty of Science
University of Amsterdam
Nieuwe Achtergracht 166
NL-1018WV Amsterdam

Phone: +31-(0)20-525-7456 (7451 Secretary)
Fax:   +31-(0)20-525-7431
Email: uleopold at science.uva.nl
http://www.frw.uva.nl/soil/Welcome.html

Check us also out at:
Netherlands Centre for Geo-ecological Research
http://www.frw.uva.nl/icg



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From PLauren at genelogic.com  Tue Apr  9 17:15:44 2002
From: PLauren at genelogic.com (PLauren@genelogic.com)
Date: Tue, 9 Apr 2002 11:15:44 -0400
Subject: [R] Mixture Modeling in R
Message-ID: <OF41A916D3.DA38052C-ON85256B96.0053D671@genelogic.com>

An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20020409/a5781d42/attachment.html

From tlumley at u.washington.edu  Tue Apr  9 17:26:25 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 9 Apr 2002 08:26:25 -0700 (PDT)
Subject: [R] how to deal with singularities in lm()
In-Reply-To: <Pine.LNX.4.33.0204091611010.27239-100000@localhost.localdomain>
Message-ID: <Pine.A41.4.44.0204090825310.22398-100000@homer32.u.washington.edu>

On Tue, 9 Apr 2002, Lukas Kubin wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> I got the report
>
> Coefficients: (1 not defined because of singularities)
>
> while trying to get my model's coefficients from lm()
> What shall I do to avoid it and get the one missing coefficient?

It means that one of your coefficients can be computed as a linear
combination of the others.  Do that.

	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kroisand at itwm.fhg.de  Tue Apr  9 17:37:49 2002
From: kroisand at itwm.fhg.de (G. Kroisandt)
Date: Tue, 9 Apr 2002 17:37:49 +0200 (CEST)
Subject: [R] restoring .RData with older version of R
Message-ID: <E16uxgv-0004m0-00@ms1.itwm.uni-kl.de>

Hi,

I am working at a research institute and I am using R on different
machines, but for the same data in the same directory.
Unfortunately, there are also different versions of R running on these
machines (1.3.0 and 1.4.1).
The problem is that I cannot get R 1.3.0 running with the .RData file
created by 1.4.1.
The same problem arises with objects saved (routine save) in the
R-format under 1.4.1 when I want to load them in 1.3.0.

The reason for these 2 versions is that I received now another computer
with version 1.3.0 having a fast processor and a lot of memory, i.e. I
want to make the computations there. In former times, I had a slow
computer and had to login to another computer. That one is not so fast
as my new computer and has not so much memory, however, there is version
1.4.1 installed.

Is there any possibility to work with both versions on the same data?

Thank you very much,
Gerald Kroisandt


==============================================
|  Dr. Gerald Kroisandt                      |
|  Fraunhofer Institut                       |
|   Techno- und Wirtschaftsmathematik (ITWM) |
|  Gottlieb-Daimler-Str., Geb. 49/311   |
|                                            |
|  67663 Kaiserslautern                      |
|  Germany                                   |
==============================================
|  Phone:     +49-(0)631-205-4189            |
|  Fax:       +49-(0)631-205-4139            |
|  E-Mail:    kroisandt at itwm.fhg.de          |
|  Internet:  http://www.itwm.fhg.de         |
==============================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Tue Apr  9 17:48:57 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 9 Apr 2002 08:48:57 -0700 (PDT)
Subject: [R] restoring .RData with older version of R
In-Reply-To: <E16uxgv-0004m0-00@ms1.itwm.uni-kl.de>
Message-ID: <Pine.A41.4.44.0204090841560.22398-100000@homer32.u.washington.edu>

On Tue, 9 Apr 2002, G. Kroisandt wrote:

> Hi,
>
> I am working at a research institute and I am using R on different
> machines, but for the same data in the same directory.
> Unfortunately, there are also different versions of R running on these
> machines (1.3.0 and 1.4.1).
> The problem is that I cannot get R 1.3.0 running with the .RData file
> created by 1.4.1.
> The same problem arises with objects saved (routine save) in the
> R-format under 1.4.1 when I want to load them in 1.3.0.
>
> The reason for these 2 versions is that I received now another computer
> with version 1.3.0 having a fast processor and a lot of memory, i.e. I
> want to make the computations there. In former times, I had a slow
> computer and had to login to another computer. That one is not so fast
> as my new computer and has not so much memory, however, there is version
> 1.4.1 installed.


You can save the workspace explicitly using the old save format with
    save.image(version=1)
and even make this the default (so it happens on q()) with
    options(save.image.defaults=list(version=1))

More details are in help(save.image).

You would be much better off getting the computer with R 1.3.0 to upgrade
There have been definite improvements since then.

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hennig at stat.math.ethz.ch  Tue Apr  9 18:05:45 2002
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Tue, 9 Apr 2002 18:05:45 +0200 (CEST)
Subject: [R] Mixture Modeling in R
In-Reply-To: <OF41A916D3.DA38052C-ON85256B96.0053D671@genelogic.com>
Message-ID: <Pine.LNX.4.44.0204091805130.2463-100000@florence>

I don't know what exactly you want to do but take a look at package mclust.

On Tue, 9 Apr 2002 PLauren at genelogic.com wrote:

> I was wondering if anyone knew there are functions to do mixture modeling in R.
> ?
> Many thanks in advance,
> Peter Lauren.
> ?
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html Send
> "info", "help", or "[un]subscribe" (in the "body", not the subject !) To:
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (current)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wolski at molgen.mpg.de  Tue Apr  9 19:11:57 2002
From: wolski at molgen.mpg.de (witold eryk wolski)
Date: Tue, 09 Apr 2002 18:11:57 +0100
Subject: [R] SJava! java.library.path. A next simple configuration question.
Message-ID: <5.1.0.14.0.20020409180309.00ac2d40@pop.gmx.net>




R 1.4.1
Windows NT
Java 1.4
SJAVA_Win 0.62-8


I am trying to start the examples for calling R from within Java. Compiling 
the examples is not a problem.
The problem is that i am getting errors from the ROmegahatInterpreter.... 
when they is calling System.library("RInterpreter"); when the file is started!
Error Messages for example:
.....
No RInterpreter Library.
....

R_HOME I have set!

Help?
Please!
Eryk

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From White.Denis at epamail.epa.gov  Tue Apr  9 18:12:30 2002
From: White.Denis at epamail.epa.gov (White.Denis@epamail.epa.gov)
Date: Tue, 09 Apr 2002 09:12:30 -0700
Subject: [R] summer R job in Oregon
Message-ID: <OFCDD81558.14F06F11-ON88256B96.0058E770@rtp.epa.gov>

Summer job opportunity using Splus/R in Corvallis, Oregon:

Great opportunity to gain experience in application of survey
designs to natural resources.  Graduate level statistician/programmer
competent in the development of algorithms using the statistical
software SPlus or R to work as a summer hire as part of the U.S.
Environmental Protection Agency's Environmental Monitoring and
Assessment Program (EMAP) Design Team, located in Corvallis, Oregon.
EMAP develops survey designs for aquatic resources using unequal
probability sampling based on a hierarchical grid randomization
process.  The person filling the position will write SPlus/R
functions to implement this process.  Research level functions
currently exist for parts of the process.  The objective is to
generalize these functions and make into a coherent survey design
library in SPlus/R.

The person will work in collaboration with several research
statisticians and geographers who will provide specific guidance.
No specific knowledge of survey design is expected.  Development
of the functions may include identifying portions that are best
completed as C functions.  Although it would be beneficial if the
person knew C programming, that is not a requirement.  Work will
be completed in a Windows computing environment.  Must be a U.S.
citizen and a student in good standing.  Approximate pay scale:
GS-7 (in the range of $13-$14/hr.; no travel/housing allowance).
Duration of employment: June - September (flexible start/stop
dates).  Deadline for applications:  15 May 2002.

Contact: Phil Larsen (larsen.david at epa.gov) or
         Tony Olsen (olsen.tony at epa.gov).

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cjf at fonnesbeck.net  Tue Apr  9 18:16:48 2002
From: cjf at fonnesbeck.net (Christopher Fonnesbeck)
Date: 09 Apr 2002 12:16:48 -0400
Subject: [R] factanal prediction
Message-ID: <1018369008.2856.3.camel@volterra>

I was wondering if there is a way of predicting factor scores of new
data for factor analysis in R (similar to "predict" in S-plus). So far I
have not been able to find it, nor found reference to it.

Thanks,
Chris Fonnesbeck
-- 
~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*

Christopher J. Fonnesbeck 
Ph.D. Student

Georgia Cooperative Wildlife Unit
University of Georgia 
Athens, GA 30602

Email: cjf at fonnesbeck.net
Yahoo: fonnesbeck_chris

~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From laurent at genome.cbs.dtu.dk  Tue Apr  9 19:06:01 2002
From: laurent at genome.cbs.dtu.dk (Laurent Gautier)
Date: Tue, 9 Apr 2002 19:06:01 +0200
Subject: [R] matrix dimension and for loop
In-Reply-To: <20020409124640.83338.qmail@web14506.mail.yahoo.com>
References: <20020409124640.83338.qmail@web14506.mail.yahoo.com>
Message-ID: <20020409170601.GR22993@giraffa.cbs.dtu.dk>

On Tue, Apr 09, 2002 at 05:46:40AM -0700, sonchawan tamkaew wrote:
> Dear all,
> 
> My questions are that if I have
> 
> > x<-rnorm(50)
> > dim(x)<-c(10,5)
> > y=1:5
> > Z<-matrix(0,NROW(x),NROW(y))
> > for (j in 1:NROW(y)) Z[,j]<-x[,j]*y[j]
> 
> 1. Is there any other way to write this without 'for'
> loop?


Z <- x * y

seems to do the job....


> 
> 2. and if I don't know the dimension of x, which could
> be only 1 column, how could I write the command
> without using if (NCOL(x)==1), or something like that?
> (in case I want to include them in my function.
> 


still seems to do the job...


> Example of x is a vector.
> > x<-rnorm(10)
> > y=2
> > Z<-matrix(0,NROW(x),NROW(y))
> > for (j in 1:NROW(y)) Z[,j]<-x[,j]*y[j]
> Error in x[, j] : incorrect number of dimensions
> 





note: I discovered above that assignment like 'y=2' where now valid....
(learn something new evryday on r-help.... ;-) )




 where now valid....
(learn something new evryday on r-help.... ;-) )




L







> Could anyone please help me to solve these problem? 
> Thank you very much for your kindness.
> 
> 
> Sonchawan Tamkaew 
> 
> __________________________________________________
> 
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
--------------------------------------------------------------
other email: lgautier at altern.org
--------------------------------------------------------------
Laurent Gautier			CBS, Building 208, DTU
PhD. Student			D-2800 Lyngby,Denmark	
tel: +45 45 25 24 85		http://www.cbs.dtu.dk/laurent
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Apr  9 19:12:08 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 09 Apr 2002 19:12:08 +0200
Subject: [R] matrix dimension and for loop
In-Reply-To: <20020409170601.GR22993@giraffa.cbs.dtu.dk>
References: <20020409124640.83338.qmail@web14506.mail.yahoo.com>
	<20020409170601.GR22993@giraffa.cbs.dtu.dk>
Message-ID: <x2pu1823vb.fsf@blueberry.kubism.ku.dk>

Laurent Gautier <laurent at genome.cbs.dtu.dk> writes:

> On Tue, Apr 09, 2002 at 05:46:40AM -0700, sonchawan tamkaew wrote:
> > Dear all,
> > 
> > My questions are that if I have
> > 
> > > x<-rnorm(50)
> > > dim(x)<-c(10,5)
> > > y=1:5
> > > Z<-matrix(0,NROW(x),NROW(y))
> > > for (j in 1:NROW(y)) Z[,j]<-x[,j]*y[j]
> > 
> > 1. Is there any other way to write this without 'for'
> > loop?
> 
> 
> Z <- x * y
> 
> seems to do the job....

Nope. Try it with x <- matrix(1,10,5) and see.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rik.bradt at cropdesign.com  Tue Apr  9 19:13:44 2002
From: rik.bradt at cropdesign.com (Rik Bradt)
Date: Tue, 09 Apr 2002 19:13:44 +0200
Subject: [R] dynamically including R-code into R-code
Message-ID: <3CB32148.8000406@cropdesign.com>

Hello,

I have a R-script, R1, that contains some variables and some R-functions.
I want to include/require this script into another R-script, R2, so that I
can access the the variables and functions that are inside script R1 in 
script R2.

Is this possible?

Script R1 could for example contain information about database 
connections, paths etc.
that would be used in several R scripts. I do not want to change all my 
R-scripts
every time I change the password of my database for example!

Regards,

Rik


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ggrothendieck at yifan.net  Tue Apr  9 19:23:14 2002
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Tue, 9 Apr 2002 13:23:14 -0400
Subject: [R] matrix dimension and for loop
In-Reply-To: <20020409124640.83338.qmail@web14506.mail.yahoo.com>
Message-ID: <3CB2EB42.3741.1280668@localhost>

On 9 Apr 2002 at 5:46, sonchawan tamkaew wrote:

> Dear all,
> 
> My questions are that if I have
> 
> > x<-rnorm(50)
> > dim(x)<-c(10,5)
> > y=1:5
> > Z<-matrix(0,NROW(x),NROW(y))
> > for (j in 1:NROW(y)) Z[,j]<-x[,j]*y[j]
> 
> 1. Is there any other way to write this without 'for'
> loop?

Z <- t( t(x) * y )

> 
> 2. and if I don't know the dimension of x, which could
> be only 1 column, how could I write the command
> without using if (NCOL(x)==1), or something like that?
> (in case I want to include them in my function.
> 
> Example of x is a vector.
> > x<-rnorm(10)
> > y=2
> > Z<-matrix(0,NROW(x),NROW(y))
> > for (j in 1:NROW(y)) Z[,j]<-x[,j]*y[j]
> Error in x[, j] : incorrect number of dimensions

The answer already given to theprevious
question automatically handles the case 
where x is a vector so its not necessary to 
provide special code for it.

However, even though its not needed here,
just for interest:

x <- as.matrix( x ) 

will turn vector x into a 1 column matrix and leave it
as is if its already a matrix.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From john.janmaat at acadiau.ca  Tue Apr  9 18:27:35 2002
From: john.janmaat at acadiau.ca (John Janmaat)
Date: Tue, 09 Apr 2002 13:27:35 -0300
Subject: [R] expressions on graphs
Message-ID: <3CB31677.4010809@acadiau.ca>

Hello,

I am trying to get a time derivative on a plot title.  I prefer to have 
it in the form \dot{s_i}, but \partial s_i/\partial t would be O.K.  In 
the graphics demo I cannot find either a dot or a partial equivalent.

Thanks,

John.
-- 
==========================================
John Janmaat
Department of Economics
Acadia University, Wolfville, NS, B0P 1X0
(902)585-1461

All opinions stated are personal, unless
otherwise indicated.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Tue Apr  9 20:46:02 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 09 Apr 2002 20:46:02 +0200
Subject: [R] dynamically including R-code into R-code
References: <3CB32148.8000406@cropdesign.com>
Message-ID: <3CB336EA.F28E3835@statistik.uni-dortmund.de>

Rik Bradt wrote:
> 
> Hello,
> 
> I have a R-script, R1, that contains some variables and some R-functions.
> I want to include/require this script into another R-script, R2, so that I
> can access the the variables and functions that are inside script R1 in
> script R2.
> 
> Is this possible?
> 
> Script R1 could for example contain information about database
> connections, paths etc.
> that would be used in several R scripts. I do not want to change all my
> R-scripts
> every time I change the password of my database for example!

I don't know if I understand your question correctly, but I think
source() should do the job.

Or maybe better: Make a package of the objects in "R1". Then you can use
library(R1) in your script R2.

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Apr  9 22:30:39 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 09 Apr 2002 22:30:39 +0200
Subject: [R] expressions on graphs
In-Reply-To: <3CB31677.4010809@acadiau.ca>
References: <3CB31677.4010809@acadiau.ca>
Message-ID: <x2r8lovcls.fsf@blueberry.kubism.ku.dk>

John Janmaat <john.janmaat at acadiau.ca> writes:

> Hello,
> 
> I am trying to get a time derivative on a plot title.  I prefer to
> have it in the form \dot{s_i}, but \partial s_i/\partial t would be
> O.K.  In the graphics demo I cannot find either a dot or a partial
> equivalent.

Hmmm... Peculiarly, we actually have "partialdiff" in the symbol
table, but it doesn't work. That would require modification of the 
TranslatedSymbol() routine in plotmath.c. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From laurent at genome.cbs.dtu.dk  Tue Apr  9 19:16:08 2002
From: laurent at genome.cbs.dtu.dk (Laurent Gautier)
Date: Tue, 9 Apr 2002 19:16:08 +0200
Subject: [R] matrix dimension and for loop
In-Reply-To: <x2pu1823vb.fsf@blueberry.kubism.ku.dk>
References: <20020409124640.83338.qmail@web14506.mail.yahoo.com> <20020409170601.GR22993@giraffa.cbs.dtu.dk> <x2pu1823vb.fsf@blueberry.kubism.ku.dk>
Message-ID: <20020409171608.GB1625@giraffa.cbs.dtu.dk>

On Tue, Apr 09, 2002 at 07:12:08PM +0200, Peter Dalgaard BSA wrote:
> Laurent Gautier <laurent at genome.cbs.dtu.dk> writes:
> 
> > On Tue, Apr 09, 2002 at 05:46:40AM -0700, sonchawan tamkaew wrote:
> > > Dear all,
> > > 
> > > My questions are that if I have
> > > 
> > > > x<-rnorm(50)
> > > > dim(x)<-c(10,5)
> > > > y=1:5
> > > > Z<-matrix(0,NROW(x),NROW(y))
> > > > for (j in 1:NROW(y)) Z[,j]<-x[,j]*y[j]
> > > 
> > > 1. Is there any other way to write this without 'for'
> > > loop?
> > 
> > 
> > Z <- x * y
> > 
> > seems to do the job....
> 
> Nope. Try it with x <- matrix(1,10,5) and see.


...right... it was 'y[j]' and not 'y[,j]' (blurry eyes... looking too long at the screen)


this is probably what everybody already gave:
(I receive r-help few hours before the first ones to receive it)


 x * matrix(y, ncol=ncol(x), nrow=nrow(x), byrow=T)


(I hope it work for good now... :)  )




L.







> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ben at zoo.ufl.edu  Tue Apr  9 21:18:29 2002
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Tue, 9 Apr 2002 15:18:29 -0400 (EDT)
Subject: [R] expressions on graphs
In-Reply-To: <3CB31677.4010809@acadiau.ca>
Message-ID: <Pine.LNX.4.30.0204091515380.23549-100000@bolker.zoo.ufl.edu>


 This came up a bit earlier on the r-help list, and I hacked on it some
with Paul Murrell's help.  The short answer is that there is no dot in
plotmath (and it is now feature-frozen out of 1.5.0), but it's not too
hard to hack.

  If you're up to it and want it badly enough you can probably piece
together a solution from what's included below; otherwise, if you ask I
can send you a modified plotmath.c to re-compile with.

  Ben


---------------
>From p.murrell at auckland.ac.nz Tue Apr  9 15:15:28 2002
Date: Tue, 5 Mar 2002 14:59:48 +1300
From: Paul Murrell <p.murrell at auckland.ac.nz>
To: bolker at zoo.ufl.edu
Cc: tobias.hoevekamp at ilw.agrl.ethz.ch
Subject: Re: [R] R-plots with 'complex' axis-labelling

Hi


>   Here's what I've got so far -- trivially easy to get this far but I'm
> not sure where to go from here.  The change is effectively a one-line
> change in plotmath.c, although I've complicated it slightly for testing
> purposes:
>
> *** /usr/local/src/R/R-1.4.1/src/main/plotmath.c.orig Fri Mar  1 10:05:01
2002
> --- /usr/local/src/R/R-1.4.1/src/main/plotmath.c Fri Mar  1 13:56:30 2002
> ***************
> *** 1600,1605 ****
> --- 1600,1610 ----
>       { "hat", 94 },
>       { "ring", 176 },
>       { "tilde", 126 },
> +     { "dot1",            46 },  /* period (46) is too small */
> +     { "dot2",           215 },
> +     { "dot3",           183 },
> +                        /* 215 produces an x instead of "dotmath"? */
> +                                 /* 183 is square */
>       { NULL,   0 },
>   };


Thanks Ben.
If you make the following additional changes, the "dotmath" symbol will work
(it is a character in the symbol font).

1642c1647,1650
<     accentBBox = RenderChar(code, 0);
---
>     if (code == 215) /* dotmath */
>       accentBBox = RenderSymbolChar(code, 0);
>     else
>       accentBBox = RenderChar(code, 0);
1655c1663,1666
<       RenderChar(code, draw);
---
>       if (code == 215) /* dotmath */
>           RenderSymbolChar(code, draw);
>       else
>           RenderChar(code, draw);



> postscript("test.ps",family="Times")
> plot(c(0,1),c(0,1),type="n")
> text(0.2,0.2,expression(dot1(a)))
> text(0.3,0.3,expression(dot2(b)))
> text(0.4,0.4,expression(dot3(c)))
> text(0.5,0.5,expression(a.b))
> par(cex=3)
> text(0.6,0.6,expression(dot1(a)))
> text(0.7,0.7,expression(dot2(b)))
> text(0.8,0.8,expression(dot3(c)))
> text(0.9,0.9,expression(a.b))
> dev.off()
>
> Results vary slightly depending on what font you use -- in Helvetica all
> dots come out square and bullet/period spacing looks slightly different,
> in Palatino and Times they're round and apparently equivalent.  "dotmath"
> seems to come out as an x in every font.


With the dotmath change, this symbol always comes out round.  Perhaps we
could offer both a dot() and a dotmath() expression if we were able to
choose between dot1() and dot3() for our dot()?


>   So, if one were satisfied with the spacing etc. this could probably work
> as is.


I guess it needs someone who wants to use these dots to tell us whether this
approach is acceptable.  Does it look ok to you Tobias?  Would you prefer
some postscript files to see the examples?

Paul




On Tue, 9 Apr 2002, John Janmaat wrote:

> Hello,
>
> I am trying to get a time derivative on a plot title.  I prefer to have
> it in the form \dot{s_i}, but \partial s_i/\partial t would be O.K.  In
> the graphics demo I cannot find either a dot or a partial equivalent.
>
> Thanks,
>
> John.
>

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From nawlnz at yahoo.com  Tue Apr  9 20:16:07 2002
From: nawlnz at yahoo.com (Dennis L. Malandro)
Date: Tue, 9 Apr 2002 11:16:07 -0700 (PDT)
Subject: [R] factor labels in model.frame
In-Reply-To: <Pine.A41.4.44.0204081656060.91766-100000@homer21.u.washington.edu>
Message-ID: <20020409181607.84494.qmail@web14403.mail.yahoo.com>

Hmm, I rebooted my computer and now it works fine. 
How weird is that?

Thanks a lot Thomas,
Dennis


--- Thomas Lumley <tlumley at u.washington.edu> wrote:
> On Mon, 8 Apr 2002, Dennis L. Malandro wrote:
> 
> > Hello,
> >
> > model.frame changes the factor labels when
> na.action =
> > na.omit.
> >
> > > f <- gl(3, 2, 6, paste('m', 1:3, sep = ''))
> > > r <- c(NA, NA, 3:6)
> > > mf <- model.frame(~ r + f, na.action = na.omit)
> > > mf
> >   r  f
> > 3 3 m1
> > 4 4 m1
> > 5 5 m2
> > 6 6 m2
> >
> > But it seems like it should be this
> > > mf
> >   r  f
> > 3 3 m2
> > 4 4 m2
> > 5 5 m3
> > 6 6 m3
> >
> > intead.
> 
> It certainly should, and on my machine it is (both
> Linux and Win2k). I
> don't see how you can get the first answer.
> 
> 	-thomas
> 
> 
> 


__________________________________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From yuelin at pandora.outcomes.chop.edu  Tue Apr  9 19:56:20 2002
From: yuelin at pandora.outcomes.chop.edu (Yuelin Li)
Date: Tue, 9 Apr 2002 13:56:20 -0400 (EDT)
Subject: [R] readline editor
Message-ID: <200204091756.g39HuKn01189@pandora.outcomes.chop.edu>

Which Linux/UNIX are you using?  

On Solaris 8 for SPARC the readline header files (history.h and 
readline.h, etc.) are located under /opt/sfw/include/readline.  
They have to be compiled with R from the source on Solaris.  You 
need to add this path to the CPPFLAGS variable in config.site.  
./configure --with-readline will not work.  You can use the tee 
utility to dump the output of configure to check if readline.h is 
found.

Yuelin Li.


  Date: Tue, 9 Apr 2002 14:45:46 +0200 (CEST)
  From: "Dr. Peter Schlattmann" 
<schlatti at mailer.ukbf.fu-berlin.de>
  To: r-help at stat.math.ethz.ch
  Subject: [R] readline editor
  
  
  Dear all,
  
  I have a problem with the readline editor of R since it doesn't 
work.
  Setting ./configure --with-readline does not the fix the 
problem.
  
  Does anyone have an idea how to fix this? Many thanks in 
advance!
  
  
  
  Peter Schlattmann
  

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jonathan_li at agilent.com  Wed Apr 10 03:31:06 2002
From: jonathan_li at agilent.com (jonathan_li@agilent.com)
Date: Tue, 9 Apr 2002 18:31:06 -0700 
Subject: [R] Discriminant Adaptive Nearest Neighbor
Message-ID: <FC0B9DA2600ED4118F76009027AA5DDD05ABD12A@ALEX2>

Dear R users,

Is there anyone who is aware of a R or S package that has Discriminant
Adaptive Nearest Neighbor (DANN) classification by Hastie and Tibshirani?  
I have used the search services in R website but no luck.

Thanks in advance!
Jonathan
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mrappe at gwdg.de  Wed Apr 10 00:34:44 2002
From: mrappe at gwdg.de (Matthias Rappe)
Date: Wed, 10 Apr 2002 00:34:44 +0200
Subject: [R] installation
Message-ID: <20020410003444.A8400@gwdg.de>

Hello,

I am trying to install R from a tarball, version 1.4.1, on a SuSE (6.4)
box. Although zlib.h 1.1.3 is installed "make" stops on error with these:

---[snip]
connections.o: In function `gzfile_fgetc':
/usr/src/packages/SOURCES/R-1.4.1/src/main/connections.c:773: undefined
reference to `gzeof'
/usr/src/packages/SOURCES/R-1.4.1/src/main/connections.c:774: undefined
reference to `gzgetc'
connections.o: In function `gzfile_seek':
/usr/src/packages/SOURCES/R-1.4.1/src/main/connections.c:780: undefined
reference to `gztell'
/usr/src/packages/SOURCES/R-1.4.1/src/main/connections.c:788: undefined
reference to `gzseek'
collect2: ld returned 1 exit status
   [snip]------

Any suggestions out there, please? 
Sincerely, Matthias
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.murrell at auckland.ac.nz  Wed Apr 10 00:18:05 2002
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 10 Apr 2002 10:18:05 +1200
Subject: [R] expressions on graphs
References: <3CB31677.4010809@acadiau.ca>
Message-ID: <00c901c1e014$6cbd2f30$7632d882@stat.auckland.ac.nz>

Hi


> I am trying to get a time derivative on a plot title.  I prefer to have
> it in the form \dot{s_i}, but \partial s_i/\partial t would be O.K.  In
> the graphics demo I cannot find either a dot or a partial equivalent.


Ben Bolker has submitted a patch to allow plotmath expressions of the form
...

    dot(x)

... but it needs a bit more fine-tuning.  For example, producing something
along the lines of dot(s[i]) puts the dot a bit too close to the expression
I think.  If you are able to (re)compile R, I could send you a patched file
that would let you use what we currently have.  I'd be interested in your
comments on the "look" of what we've got -- if you can't use a patched file
yourself, could I send you some sample postscript output for you to look at?

Paul

p.s. Ben, having thought a little more about this, we probably only want the
"dotmath" version (code = 215) (?)

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pols1oh at bestweb.net  Wed Apr 10 00:10:43 2002
From: pols1oh at bestweb.net (Michaell Taylor)
Date: 09 Apr 2002 18:10:43 -0400
Subject: [R] write.table
Message-ID: <1018390244.31119.54.camel@penguin>


Hello,

When using write.table I am getting two variables pasted together (not
by choice).  Has anyone else had this happen?

Specifically, I have the following:

d _ read.dta(paste('/montecarlo/forecast/off/',F,'.dta',sep=''))
write.table(d,file=paste('/montecarlo/forecast/off/csv/',F,'.csv',sep=''),
    row.names=FALSE, col.names=FALSE,
    quote=FALSE, sep=' , ')

which gives:

[mtaylor at statamatic Verify]$ head
/montecarlo/forecast/off/csv/mcoffmetaa.csv

   1,AA2002 ,0.004 ,  288000 ,0.004 ,   263000 ,  0.000 ,-0.015 , -0.014
   1,AA2003 ,0.000 ,       0 ,0.007 ,   493000 , -0.006 ,-0.017 , -0.015
   1,AA2004 ,0.000 ,       0 ,0.018 ,  1273000 , -0.016 ,-0.008 , -0.003
   1,AA2005 ,0.000 ,       0 ,0.012 ,   841000 , -0.010 ,0.033 ,  0.037
   1,AA2006 ,0.000 ,   30000 ,0.018 ,  1266000 , -0.015 ,0.054 ,  0.059
   1,AA2007 ,0.007 ,  528000 ,0.026 ,  1903000 , -0.018 ,0.047 ,  0.052
   1,AA2008 ,0.011 ,  900000 ,0.036 ,  2676000 , -0.022 ,0.041 ,  0.046
   1,AA2009 ,0.011 ,  914000 ,0.025 ,  1898000 , -0.012 ,0.070 ,  0.073

The problem is with the "AA2002", "AA2003" - as can be seen below - the
R object has metcode and yr as seperate variables.

> d[1:5,]
  scenario metcode   yr  ginv   cons  gocc     abs   dvac   gmre   gmer
1        1      AA 2002 0.004 288000 0.004  263000  0.000 -0.015 -0.014
2        1      AA 2003 0.000      0 0.007  493000 -0.006 -0.017 -0.015
3        1      AA 2004 0.000      0 0.018 1273000 -0.016 -0.008 -0.003
4        1      AA 2005 0.000      0 0.012  841000 -0.010  0.033  0.037
5        1      AA 2006 0.000  30000 0.018 1266000 -0.015  0.054  0.059


I've seen similiar issues when reading dta files, but seems like the R
object is good. i.e.

lapply(d,mode)

$scenario
[1] "numeric"

$metcode
[1] "character"

$yr
[1] "numeric"

<snip>


I've tried ....
d$metcode <- paste(d$metcode,' , ',sep='')

as a cheap work around - no luck.

Any suggestions would be appreciated.

Michaell


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From chenhsh at mail.disa.pku.edu.cn  Wed Apr 10 07:06:10 2002
From: chenhsh at mail.disa.pku.edu.cn (Chen Huashan)
Date: Wed, 10 Apr 2002 13:06:10 +0800
Subject: [R] mailing list archive
In-Reply-To: <HBECLPCKNJCMJDFHNKJGOEKKCMAA.chenhsh@mail.disa.pku.edu.cn>
Message-ID: <HBECLPCKNJCMJDFHNKJGEEOKCNAA.chenhsh@mail.disa.pku.edu.cn>

Dear R users:

The searchable list archives(R Help, Dev, Announce) are here:

http://www.baidao.net/r/archives/index.cgi

The database will be updated monthly.

The R Help archive (http://www.baidao.net/r/maillist/index.cgi) is updated 
every day  and contains posts within 3 monthes.

Special thanks to Patrick, Laurent, Friedrich! 




Chen Huashan


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From l.bargeot at educagri.fr  Wed Apr 10 09:03:22 2002
From: l.bargeot at educagri.fr (Lionel)
Date: Wed, 10 Apr 2002 09:03:22 +0200
Subject: [R] readline editor
In-Reply-To: <fc.0edd96e90edd96e9e996dd0e3b9aca00.177449a@educagri.fr>
References: <fc.0edd96e90edd96e9e996dd0e3b9aca00.177449a@educagri.fr>
Message-ID: <02041009032200.01769@agrogeomatic>

Le Mardi  9 Avril 2002 14:45, schlatti at mailer.ukbf.fu-berlin.de a ?crit :
> Dear all,
>
> I have a problem with the readline editor of R since it doesn't work.
> Setting ./configure --with-readline does not the fix the problem.
>
> Does anyone have an idea how to fix this? Many thanks in advance!
>
>
>
> Peter Schlattmann

Hello,
I work on a SuSE 7.2 and I 've had to download last readline sources and 
recompile it (quiet easy). Then you can recompile R with readline, but don't 
forget to delete your config.cache in your source tree.

regards

Lionel

-- 
CNERTA-ENESAD
4 rue champs-prevois
batiment grand-champs
21000 Dijon
tel:03.80.77.28.49
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Friedrich.Leisch at ci.tuwien.ac.at  Wed Apr 10 09:14:42 2002
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Wed, 10 Apr 2002 09:14:42 +0200
Subject: [R] mailing list archive
In-Reply-To: <HBECLPCKNJCMJDFHNKJGEEOKCNAA.chenhsh@mail.disa.pku.edu.cn>
References: <HBECLPCKNJCMJDFHNKJGOEKKCMAA.chenhsh@mail.disa.pku.edu.cn>
	<HBECLPCKNJCMJDFHNKJGEEOKCNAA.chenhsh@mail.disa.pku.edu.cn>
Message-ID: <15539.58978.40113.667943@galadriel.ci.tuwien.ac.at>

>>>>> On Wed, 10 Apr 2002 13:06:10 +0800,
>>>>> Chen Huashan (CH) wrote:

  > Dear R users:
  > The searchable list archives(R Help, Dev, Announce) are here:

  > http://www.baidao.net/r/archives/index.cgi

  > The database will be updated monthly.

  > The R Help archive (http://www.baidao.net/r/maillist/index.cgi) is updated 
  > every day  and contains posts within 3 monthes.

  > Special thanks to Patrick, Laurent, Friedrich! 


Thanks a lot!

Could you create a single page with links to the two archives
explaining them (basically a web page with the text of your mail). I
would then link from CRAN to that page.

Best,
Fritz

-- 
-------------------------------------------------------------------
                        Friedrich  Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071      Friedrich.Leisch at ci.tuwien.ac.at
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch
-------------------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mark at myatt.demon.co.uk  Wed Apr 10 10:09:50 2002
From: mark at myatt.demon.co.uk (Mark Myatt)
Date: Wed, 10 Apr 2002 09:09:50 +0100
Subject: [R] dynamically including R-code into R-code
In-Reply-To: <3CB32148.8000406@cropdesign.com>
References: <3CB32148.8000406@cropdesign.com>
Message-ID: <nDqR4AAON$s8Ew9R@myatt.demon.co.uk>

Rik Bradt <rik.bradt at cropdesign.com> writes:
>Hello,
>
>I have a R-script, R1, that contains some variables and some R-functions.
>I want to include/require this script into another R-script, R2, so that I
>can access the the variables and functions that are inside script R1 in 
>script R2.
>
>Is this possible?

You can use source() to load (e.g.) the R1 script in another script.

Mark

--
Mark Myatt


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Wed Apr 10 11:38:04 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 10 Apr 2002 11:38:04 +0200
Subject: [R] Re: New Package: ipred - Improved predictors
References: <Pine.LNX.4.33.0204091937400.28610-100000@imbe78.imbe.med.uni-erlangen.de>
Message-ID: <3CB407FC.885F8DAC@statistik.uni-dortmund.de>



Andrea Peters wrote:
> 
> The package ipred is uploaded to CRAN.

Hi Andrea!

Es lebe die R Gemeinde!

Gruss,
uwe
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Wed Apr 10 11:41:42 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 10 Apr 2002 11:41:42 +0200
Subject: [R] Re: New Package: ipred - Improved predictors
References: <Pine.LNX.4.33.0204091937400.28610-100000@imbe78.imbe.med.uni-erlangen.de> <3CB407FC.885F8DAC@statistik.uni-dortmund.de>
Message-ID: <3CB408D6.2D8486C5@statistik.uni-dortmund.de>

Uwe Ligges wrote:
> 
> Andrea Peters wrote:
> >
> > The package ipred is uploaded to CRAN.
> 
> Hi Andrea!
> 
> Es lebe die R Gemeinde!

Ouch! My apologies!
I didn't recognize that  "r-help" was in the reply-to field, why ever,
of my mail-tool instead of Andrea's e-mail address.

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rik.bradt at cropdesign.com  Wed Apr 10 11:38:49 2002
From: rik.bradt at cropdesign.com (Rik Bradt)
Date: Wed, 10 Apr 2002 11:38:49 +0200
Subject: [R] dynamically including R-code into R-code
References: <3CB32148.8000406@cropdesign.com> <3CB336EA.F28E3835@statistik.uni-dortmund.de>
Message-ID: <3CB40829.3070408@cropdesign.com>

An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20020410/0ca9a6e0/attachment.html

From p.dalgaard at biostat.ku.dk  Wed Apr 10 11:49:20 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 10 Apr 2002 11:49:20 +0200
Subject: [R] dynamically including R-code into R-code
In-Reply-To: <3CB40829.3070408@cropdesign.com>
References: <3CB32148.8000406@cropdesign.com>
	<3CB336EA.F28E3835@statistik.uni-dortmund.de>
	<3CB40829.3070408@cropdesign.com>
Message-ID: <x23cy3993z.fsf@blueberry.kubism.ku.dk>

Rik Bradt <rik.bradt at cropdesign.com> writes:

> <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
> <html>
> <head>
>   <title></title>
> </head>
> <body>
> Hello,<br>
> <br>
> thanks for the good suggestion. This is indeed what I was looking for:<br>
> As an example:<br>
> <br>
> R1.R<br>
> &nbsp; &nbsp; a &lt;- 1:10<br>
> <br>
> R2.R<br>
> &nbsp; &nbsp; source("R2.R")<br>
> &nbsp; &nbsp; a<br>
> <br>

....

Ick! Please resend that in a readable format!
(There seems to be several ways of doing that in Mozilla.)


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ernesto at ipimar.pt  Wed Apr 10 14:00:05 2002
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 10 Apr 2002 13:00:05 +0100
Subject: [R] problem with do.call
Message-ID: <1018440005.19767.25.camel@gandalf>

Hi

I'm writing a function that uses four parameters (scalars) and I need to
run it in an iterative process (the parameters vary to find the minimum
RSS). 

I don't want to use loops and so tried the do.call function. However it
didn't work. My understanding is that the do.call simple runs the
function replacing the arguments (scalars by vectors), instead of runing
the function for each set of scalars in the list, what I need.

Can you please tell me if there is another way of doing it whithout
using the for loop ?

Thanks

EJ

ps: Follows an example (off course the example doesn't make much sense
but describes the problem).

> fun
function(a,b){

        vec <- rnorm(25)
        res <- a*vec^b
        res

}
> fun(2,3)
 [1]  7.006278e+00  3.515010e-01  7.989718e+00 -3.377766e-02
-1.879471e-02
 [6] -2.920680e-01  1.174834e+00 -1.088638e-03  6.448725e+00 
2.591805e+00
[11] -4.313672e-04 -9.171867e-03 -6.793569e+00 -2.480562e+01
-1.514828e+01
[16] -1.259896e-01 -7.504192e-02  6.647855e-02  5.609645e-01 
1.093114e-01
[21]  1.802123e+00  7.650033e-03 -3.534951e+00 -2.028473e-03
-2.837360e+01
> do.call("fun",list(a=c(1:6),b=rnorm(6)))
 [1]  1.4766338        NaN  3.0214852  3.8132530  0.2753699        NaN
 [7]        NaN        NaN  2.9998547        NaN        NaN  6.3050385
[13]  0.5970596  0.8722498  2.9931344  4.0664852        NaN        NaN
[19]  2.8121803        NaN  2.9989127        NaN        NaN        NaN
[25] 14.4631627
Warning messages: 
1: longer object length
        is not a multiple of shorter object length in: vec^b 
2: longer object length
        is not a multiple of shorter object length in: a * vec^b 
> 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Wed Apr 10 12:51:47 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 10 Apr 2002 12:51:47 +0200
Subject: [R] Re: New Package: ipred - Improved predictors
In-Reply-To: <3CB408D6.2D8486C5@statistik.uni-dortmund.de>
References: <Pine.LNX.4.33.0204091937400.28610-100000@imbe78.imbe.med.uni-erlangen.de>
	<3CB407FC.885F8DAC@statistik.uni-dortmund.de>
	<3CB408D6.2D8486C5@statistik.uni-dortmund.de>
Message-ID: <15540.6467.731421.875499@gargle.gargle.HOWL>

>>>>> "UweL" == Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:

    UweL> Uwe Ligges wrote:

        (something meant to one person only)

    UweL> Ouch! My apologies!
    UweL> I didn't recognize that  "r-help" was in the reply-to field, why ever,
    UweL> of my mail-tool instead of Andrea's e-mail address.

This has been on purpose, in order to make sure people do *NOT*
reply to R-announce  (which *did* happen before I've added that reply-to).

I'm just now looking if it's easy setting the `reply-to' to the original
sender of the message instead..

Martin
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From siim at obs.ee  Wed Apr 10 13:18:06 2002
From: siim at obs.ee (Ott Toomet)
Date: Wed, 10 Apr 2002 13:18:06 +0200 (CEST)
Subject: [R] write.table
In-Reply-To: <1018390244.31119.54.camel@penguin>
Message-ID: <Pine.LNX.4.44.0204101313290.6127-100000@localhost.localdomain>

Hi,

I see that you are using stata file as input.  It was a bug in foreign
library in R 1.3.x which resulted wrong length for string variables.  The
only function affected (which I am aware) is paste() and other functions,
depending on paste() as, e.g., write.table().

You do not mention your version of R but I think it should be corrected in
1.4.

Cheers,

Ott Toomet


On 9 Apr 2002, Michaell Taylor wrote:

  |
  |Hello,
  |
  |When using write.table I am getting two variables pasted together (not
  |by choice).  Has anyone else had this happen?
  |
  |Specifically, I have the following:
  |
  |d _ read.dta(paste('/montecarlo/forecast/off/',F,'.dta',sep=''))
  |write.table(d,file=paste('/montecarlo/forecast/off/csv/',F,'.csv',sep=''),
  |    row.names=FALSE, col.names=FALSE,
  |    quote=FALSE, sep=' , ')
  |
  |which gives:
  |
  |[mtaylor at statamatic Verify]$ head
  |/montecarlo/forecast/off/csv/mcoffmetaa.csv
  |
  |   1,AA2002 ,0.004 ,  288000 ,0.004 ,   263000 ,  0.000 ,-0.015 , -0.014
  |   1,AA2003 ,0.000 ,       0 ,0.007 ,   493000 , -0.006 ,-0.017 , -0.015
  |   1,AA2004 ,0.000 ,       0 ,0.018 ,  1273000 , -0.016 ,-0.008 , -0.003
  |   1,AA2005 ,0.000 ,       0 ,0.012 ,   841000 , -0.010 ,0.033 ,  0.037
  |   1,AA2006 ,0.000 ,   30000 ,0.018 ,  1266000 , -0.015 ,0.054 ,  0.059
  |   1,AA2007 ,0.007 ,  528000 ,0.026 ,  1903000 , -0.018 ,0.047 ,  0.052
  |   1,AA2008 ,0.011 ,  900000 ,0.036 ,  2676000 , -0.022 ,0.041 ,  0.046
  |   1,AA2009 ,0.011 ,  914000 ,0.025 ,  1898000 , -0.012 ,0.070 ,  0.073
  |
  |The problem is with the "AA2002", "AA2003" - as can be seen below - the
  |R object has metcode and yr as seperate variables.
  |
  |> d[1:5,]
  |  scenario metcode   yr  ginv   cons  gocc     abs   dvac   gmre   gmer
  |1        1      AA 2002 0.004 288000 0.004  263000  0.000 -0.015 -0.014
  |2        1      AA 2003 0.000      0 0.007  493000 -0.006 -0.017 -0.015
  |3        1      AA 2004 0.000      0 0.018 1273000 -0.016 -0.008 -0.003
  |4        1      AA 2005 0.000      0 0.012  841000 -0.010  0.033  0.037
  |5        1      AA 2006 0.000  30000 0.018 1266000 -0.015  0.054  0.059
  |
  |
  |I've seen similiar issues when reading dta files, but seems like the R
  |object is good. i.e.
  |
  |lapply(d,mode)
  |
  |$scenario
  |[1] "numeric"
  |
  |$metcode
  |[1] "character"
  |
  |$yr
  |[1] "numeric"
  |
  |<snip>
  |
  |
  |I've tried ....
  |d$metcode <- paste(d$metcode,' , ',sep='')
  |
  |as a cheap work around - no luck.
  |
  |Any suggestions would be appreciated.
  |
  |Michaell
  |
  |
  |-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
  |r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
  |Send "info", "help", or "[un]subscribe"
  |(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
  |_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
  |

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pols1oh at bestweb.net  Wed Apr 10 14:12:31 2002
From: pols1oh at bestweb.net (Michaell Taylor)
Date: 10 Apr 2002 08:12:31 -0400
Subject: [R] foreign/write.table
Message-ID: <1018440752.29799.58.camel@penguin>




Hello,

When using write.table I am getting two variables pasted together (not
by choice).  Has anyone else had this happen?

Specifically, I have the following on a RH7.2/R1.4 box:

d _ read.dta(paste('/montecarlo/forecast/off/',F,'.dta',sep=''))
write.table(d,file=paste('/montecarlo/forecast/off/csv/',F,'.csv',sep=''),
    row.names=FALSE, col.names=FALSE,
    quote=FALSE, sep=' , ')

which gives:

[mtaylor at statamatic Verify]$ head
/montecarlo/forecast/off/csv/mcoffmetaa.csv

   1,AA2002 ,0.004 ,  288000 ,0.004 ,   263000 ,  0.000 ,-0.015 , -0.014
   1,AA2003 ,0.000 ,       0 ,0.007 ,   493000 , -0.006 ,-0.017 , -0.015
   1,AA2004 ,0.000 ,       0 ,0.018 ,  1273000 , -0.016 ,-0.008 , -0.003
   1,AA2005 ,0.000 ,       0 ,0.012 ,   841000 , -0.010 ,0.033 ,  0.037
   1,AA2006 ,0.000 ,   30000 ,0.018 ,  1266000 , -0.015 ,0.054 ,  0.059
   1,AA2007 ,0.007 ,  528000 ,0.026 ,  1903000 , -0.018 ,0.047 ,  0.052
   1,AA2008 ,0.011 ,  900000 ,0.036 ,  2676000 , -0.022 ,0.041 ,  0.046
   1,AA2009 ,0.011 ,  914000 ,0.025 ,  1898000 , -0.012 ,0.070 ,  0.073

The problem is with the "AA2002", "AA2003" - as can be seen below - the
R object has metcode and yr as seperate variables.

> d[1:5,]
  scenario metcode   yr  ginv   cons  gocc     abs   dvac   gmre   gmer
1        1      AA 2002 0.004 288000 0.004  263000  0.000 -0.015 -0.014
2        1      AA 2003 0.000      0 0.007  493000 -0.006 -0.017 -0.015
3        1      AA 2004 0.000      0 0.018 1273000 -0.016 -0.008 -0.003
4        1      AA 2005 0.000      0 0.012  841000 -0.010  0.033  0.037
5        1      AA 2006 0.000  30000 0.018 1266000 -0.015  0.054  0.059


I've seen similiar issues when reading dta files, but seems like the R
object is good. i.e.

lapply(d,mode)

$scenario
[1] "numeric"

$metcode
[1] "character"

$yr
[1] "numeric"

<snip>


I've tried ....
d$metcode <- paste(d$metcode,' , ',sep='')

as a cheap work around - no luck.

Any suggestions would be appreciated.

Michaell


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Apr 10 14:11:03 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 10 Apr 2002 14:11:03 +0200
Subject: [R] problem with do.call
In-Reply-To: <1018440005.19767.25.camel@gandalf>
References: <1018440005.19767.25.camel@gandalf>
Message-ID: <x2lmbv7nzc.fsf@blueberry.kubism.ku.dk>

Ernesto Jardim <ernesto at ipimar.pt> writes:

> Hi
> 
> I'm writing a function that uses four parameters (scalars) and I need to
> run it in an iterative process (the parameters vary to find the minimum
> RSS). 
> 
> I don't want to use loops and so tried the do.call function. However it
> didn't work. My understanding is that the do.call simple runs the
> function replacing the arguments (scalars by vectors), instead of runing
> the function for each set of scalars in the list, what I need.
> 
> Can you please tell me if there is another way of doing it whithout
> using the for loop ?

That's not what do.call does. It is for situations where the argument
list of a single call needs to be constructed from simpler components.
Your example is equivalent to fun(a=c(1:6), b=rnorm(6))

The loop over multiple parallel vectors is only doable via something
like lapply(1:6, function(i)fun(a[i],b[i]))

However, I recently played with this and got as far as this:

napply <-
function(..., FUN) {
   FUN <- match.fun(FUN)
   x <- list(...)
   lens <- sapply(x,length)
   len <- max(lens)
   if (any(lens != len))
      x <- lapply(x, rep, length=len)
   tuples <- lapply(seq(length=len), function(i)lapply(x,"[", i))
   sapply(tuples, function(t)eval(as.call(c(FUN,t))))
}

>  napply(a=c(1:6),b=rnorm(6), FUN=fun)
           [,1]     [,2]     [,3]       [,4]     [,5]        [,6]
 [1,] 1.0259135      NaN 3.003882        NaN      NaN   20.299212
 [2,]       NaN 1.977696 3.026111        NaN 3.951746   19.107481
 [3,] 1.1840499 2.024837      NaN   8.289768      NaN    7.479917
 [4,] 0.9756922 2.003576      NaN        NaN 4.236000         NaN
 [5,] 1.0010550 2.006045      NaN        NaN      NaN 1302.330425
 [6,]       NaN      NaN      NaN   2.472650      NaN         NaN
 [7,]       NaN 2.094956      NaN        NaN      NaN    3.685879
 [8,] 0.8646628      NaN 2.993435        NaN 3.369501         NaN
 [9,]       NaN 2.044915 3.006433   6.426090 6.123980   19.235790
[10,] 1.6051736      NaN 3.011986        NaN 3.638641         NaN
....

> > fun
> function(a,b){
> 
>         vec <- rnorm(25)
>         res <- a*vec^b
>         res
> 
> }
> > fun(2,3)
>  [1]  7.006278e+00  3.515010e-01  7.989718e+00 -3.377766e-02
> -1.879471e-02
>  [6] -2.920680e-01  1.174834e+00 -1.088638e-03  6.448725e+00 
> 2.591805e+00
> [11] -4.313672e-04 -9.171867e-03 -6.793569e+00 -2.480562e+01
> -1.514828e+01
> [16] -1.259896e-01 -7.504192e-02  6.647855e-02  5.609645e-01 
> 1.093114e-01
> [21]  1.802123e+00  7.650033e-03 -3.534951e+00 -2.028473e-03
> -2.837360e+01
> > do.call("fun",list(a=c(1:6),b=rnorm(6)))
>  [1]  1.4766338        NaN  3.0214852  3.8132530  0.2753699        NaN
>  [7]        NaN        NaN  2.9998547        NaN        NaN  6.3050385
> [13]  0.5970596  0.8722498  2.9931344  4.0664852        NaN        NaN
> [19]  2.8121803        NaN  2.9989127        NaN        NaN        NaN
> [25] 14.4631627
> Warning messages: 
> 1: longer object length
>         is not a multiple of shorter object length in: vec^b 
> 2: longer object length
>         is not a multiple of shorter object length in: a * vec^b 
> > 


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Apr 10 14:25:01 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 10 Apr 2002 14:25:01 +0200
Subject: [R] Re: New Package: ipred - Improved predictors
In-Reply-To: <15540.6467.731421.875499@gargle.gargle.HOWL>
References: <Pine.LNX.4.33.0204091937400.28610-100000@imbe78.imbe.med.uni-erlangen.de>
	<3CB407FC.885F8DAC@statistik.uni-dortmund.de>
	<3CB408D6.2D8486C5@statistik.uni-dortmund.de>
	<15540.6467.731421.875499@gargle.gargle.HOWL>
Message-ID: <x2hemj7nc2.fsf@blueberry.kubism.ku.dk>

Martin Maechler <maechler at stat.math.ethz.ch> writes:

> >>>>> "UweL" == Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:
> 
>     UweL> Uwe Ligges wrote:
> 
>         (something meant to one person only)
> 
>     UweL> Ouch! My apologies!
>     UweL> I didn't recognize that  "r-help" was in the reply-to field, why ever,
>     UweL> of my mail-tool instead of Andrea's e-mail address.
> 
> This has been on purpose, in order to make sure people do *NOT*
> reply to R-announce  (which *did* happen before I've added that reply-to).
> 
> I'm just now looking if it's easy setting the `reply-to' to the original
> sender of the message instead..

Please don't. It would drive the release manager and maintainers crazy
(or crazier...) if all followups to release announcements went to them
instead of to r-help.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Wed Apr 10 15:04:54 2002
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 10 Apr 2002 09:04:54 -0400
Subject: [R] factanal prediction
In-Reply-To: <1018369008.2856.3.camel@volterra>
Message-ID: <5.1.0.14.2.20020410084509.01d55910@pop>

At 12:16 PM 4/9/2002 -0400, Christopher Fonnesbeck wrote:
>I was wondering if there is a way of predicting factor scores of new
>data for factor analysis in R (similar to "predict" in S-plus). So far I
>have not been able to find it, nor found reference to it.

Dear Chris,

The problem is that factanal doesn't save the factor-score coefficients 
(even if you ask for factor scores). It's not hard to recompute these. For 
example, for the "regression" method with orthogonally rotated factors and 
standardized variables, the factor score coefficients are

         coef <- solve(obj$correlation) %*% obj$loadings

where obj is the object returned by factanal. Then you can calculate the 
predicted factor scores as

         scale(newdata, means, sds) %*% coef

where the means and standard deviations used to standardize the "new" data 
are from the data used to do the factor analysis.

I hope that this does what you need,
  John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Wed Apr 10 15:04:15 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 10 Apr 2002 15:04:15 +0200
Subject: [R] 'Reply-To:' of R-announce [was ... New Package: ipred ..]
In-Reply-To: <x2hemj7nc2.fsf@blueberry.kubism.ku.dk>
References: <Pine.LNX.4.33.0204091937400.28610-100000@imbe78.imbe.med.uni-erlangen.de>
	<3CB407FC.885F8DAC@statistik.uni-dortmund.de>
	<3CB408D6.2D8486C5@statistik.uni-dortmund.de>
	<15540.6467.731421.875499@gargle.gargle.HOWL>
	<x2hemj7nc2.fsf@blueberry.kubism.ku.dk>
Message-ID: <15540.14415.370345.112803@gargle.gargle.HOWL>

>>>>> "PD" == Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:

    PD> Martin Maechler <maechler at stat.math.ethz.ch> writes:
    >> >>>>> "UweL" == Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:
    >> 
    UweL> Uwe Ligges wrote:
    >> 
    >> (something meant to one person only)
    >> 
    UweL> Ouch! My apologies!
    UweL> I didn't recognize that  "r-help" was in the reply-to field, why ever,
    UweL> of my mail-tool instead of Andrea's e-mail address.
    >> 
    >> This has been on purpose, in order to make sure people do *NOT*
    >> reply to R-announce  (which *did* happen before I've added that reply-to).
    >> 
    >> I'm just now looking if it's easy setting the `reply-to' to the original
    >> sender of the message instead..

    PD> Please don't. It would drive the release manager and maintainers crazy
    PD> (or crazier...) if all followups to release announcements went to them
    PD> instead of to r-help.

I see;  hmm, I had already activated the change.
So, I'm reverting now.

Is there a good alternative to the status quo?
Should we have more text in the "footer" of each message, or add
a "header" additionally ?

One possibility would be to have R-announce really moderated; but I'm not
volunteering for moderator -- but as a matter of fact, I then
could teach a selected group of people on how to post to
R-announce with a password in way that no moderator interaction happens)

BTW, most of the stuff to R-announce nowadays is spam that you
all don't see, but I do..

What do you think? 

Maybe, we can keep this discussion private to the few people
interested; and I will summarize to R-help?

Martin
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pols1oh at bestweb.net  Wed Apr 10 15:44:36 2002
From: pols1oh at bestweb.net (Michaell Taylor)
Date: 10 Apr 2002 09:44:36 -0400
Subject: [R] write.table
In-Reply-To: <Pine.LNX.4.44.0204101313290.6127-100000@localhost.localdomain>
References: <Pine.LNX.4.44.0204101313290.6127-100000@localhost.localdomain>
Message-ID: <1018446277.29801.67.camel@penguin>


I actually remember something about that in R 1.3, but I am using R 1.4
now :

R : Copyright 2001, The R Development Core Team
Version 1.4.0  (2001-12-19)

(I just double checked).

BUT, I see I am one step out of date in the foreign library. I have 
foreign_0.4-6.tar.gz, but I see a  foreign_0.5-2.tar.gz on cran, so
perhaps that is the issue.


On Wed, 2002-04-10 at 07:18, Ott Toomet wrote:
> Hi,
> 
> I see that you are using stata file as input.  It was a bug in foreign
> library in R 1.3.x which resulted wrong length for string variables.  The
> only function affected (which I am aware) is paste() and other functions,
> depending on paste() as, e.g., write.table().
> 
> You do not mention your version of R but I think it should be corrected in
> 1.4.
> 
> Cheers,
> 
> Ott Toomet
> 
> 
> On 9 Apr 2002, Michaell Taylor wrote:
> 
>   |
>   |Hello,
>   |
>   |When using write.table I am getting two variables pasted together (not
>   |by choice).  Has anyone else had this happen?
>   |
>   |Specifically, I have the following:
>   |
>   |d _ read.dta(paste('/montecarlo/forecast/off/',F,'.dta',sep=''))
>   |write.table(d,file=paste('/montecarlo/forecast/off/csv/',F,'.csv',sep=''),
>   |    row.names=FALSE, col.names=FALSE,
>   |    quote=FALSE, sep=' , ')
>   |
>   |which gives:
>   |
>   |[mtaylor at statamatic Verify]$ head
>   |/montecarlo/forecast/off/csv/mcoffmetaa.csv
>   |
>   |   1,AA2002 ,0.004 ,  288000 ,0.004 ,   263000 ,  0.000 ,-0.015 , -0.014
>   |   1,AA2003 ,0.000 ,       0 ,0.007 ,   493000 , -0.006 ,-0.017 , -0.015
>   |   1,AA2004 ,0.000 ,       0 ,0.018 ,  1273000 , -0.016 ,-0.008 , -0.003
>   |   1,AA2005 ,0.000 ,       0 ,0.012 ,   841000 , -0.010 ,0.033 ,  0.037
>   |   1,AA2006 ,0.000 ,   30000 ,0.018 ,  1266000 , -0.015 ,0.054 ,  0.059
>   |   1,AA2007 ,0.007 ,  528000 ,0.026 ,  1903000 , -0.018 ,0.047 ,  0.052
>   |   1,AA2008 ,0.011 ,  900000 ,0.036 ,  2676000 , -0.022 ,0.041 ,  0.046
>   |   1,AA2009 ,0.011 ,  914000 ,0.025 ,  1898000 , -0.012 ,0.070 ,  0.073
>   |
>   |The problem is with the "AA2002", "AA2003" - as can be seen below - the
>   |R object has metcode and yr as seperate variables.
>   |
>   |> d[1:5,]
>   |  scenario metcode   yr  ginv   cons  gocc     abs   dvac   gmre   gmer
>   |1        1      AA 2002 0.004 288000 0.004  263000  0.000 -0.015 -0.014
>   |2        1      AA 2003 0.000      0 0.007  493000 -0.006 -0.017 -0.015
>   |3        1      AA 2004 0.000      0 0.018 1273000 -0.016 -0.008 -0.003
>   |4        1      AA 2005 0.000      0 0.012  841000 -0.010  0.033  0.037
>   |5        1      AA 2006 0.000  30000 0.018 1266000 -0.015  0.054  0.059
>   |
>   |
>   |I've seen similiar issues when reading dta files, but seems like the R
>   |object is good. i.e.
>   |
>   |lapply(d,mode)
>   |
>   |$scenario
>   |[1] "numeric"
>   |
>   |$metcode
>   |[1] "character"
>   |
>   |$yr
>   |[1] "numeric"
>   |
>   |<snip>
>   |
>   |
>   |I've tried ....
>   |d$metcode <- paste(d$metcode,' , ',sep='')
>   |
>   |as a cheap work around - no luck.
>   |
>   |Any suggestions would be appreciated.
>   |
>   |Michaell
>   |
>   |
>   |-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>   |r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>   |Send "info", "help", or "[un]subscribe"
>   |(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>   |_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>   |
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ggrothendieck at yifan.net  Wed Apr 10 15:55:26 2002
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Wed, 10 Apr 2002 09:55:26 -0400
Subject: [R] matrix dimension and for loop
In-Reply-To: <20020409124640.83338.qmail@web14506.mail.yahoo.com>
Message-ID: <3CB40C0E.10317.1B6ED5@localhost>


> My questions are that if I have
> 
> > x<-rnorm(50)
> > dim(x)<-c(10,5)
> > y=1:5
> > Z<-matrix(0,NROW(x),NROW(y))
> > for (j in 1:NROW(y)) Z[,j]<-x[,j]*y[j]
> 
> 1. Is there any other way to write this without 'for'
> loop?
> 
> 2. and if I don't know the dimension of x, which could
> be only 1 column, how could I write the command

I thought I would collect together some of the solutions that have
been posted as well as mention a few others.  I have also added
some discussion particularly with reference to the second question.
There appears to be a myriad of ways to address this problem in R.
Since I am learning R I found it useful for myself to explore various
solutions and maybe others will find this helpful too.

The problem is to multiply the jth column of a matrix x by y[j] for each j.
Its also possible for x to be a vector in which case y may be a scalar.

The first 4 solutions regard x as a one column matrix if x is a vector and
so always return a matrix.  The 5th solution returns a vector if x is a 
vector.


1. Matrix multiplication. Note that if x is a vector then it is treated as a
   one column matrix.  Also note that NROW(x) is the same as nrow(x), if x is a
   matrix; however, if x is a vector, then NROW(x) is its length while nrow(x) 
   is NULL.  Thus it is important here to use NROW and not nrow. This is 
   discussed in the help on nrow.

	x %*% diag(y,NROW(x))  

2. Scalar multiplication and transpose.  Note that if x is a vector then t(x) 
   is a row matrix made out of it, so no special processing is necessary.  

	t(t(x)*y)  

3. Sweep.  Note that as.matrix(x) is the same as x, if x is a matrix, but is a 
   column matrix made out of x, if x is a vector.

	sweep(as.matrix(x),2,y,FUN="*")  

4. Scalar multiplication and col.  col(m) is a matrix the same size as
   matrix m.  Every entry in column j equals j (for all columns).

	as.matrix(x) * y[col(as.matrix(x))]   

5. Variant of #4. The following is the same as #4 except that it returns a 
   vector if x is a vector.

	x * y[col(as.matrix(x))]   


as.matrix(x) can be abbreviated to just x, in #3, #4 and #5 
if x is known always to be a matrix.  For example, the last two solutions 
would be  just x*y[col(x)].


I had not expected the last 2 solutions to work in the case that x is a vector
and y is a scalar, since they involve subscripting of a scalar, but apparently
that works in R.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From olivier.martin at inrialpes.fr  Thu Apr 11 03:24:22 2002
From: olivier.martin at inrialpes.fr (Olivier Martin)
Date: Thu, 11 Apr 2002 03:24:22 +0200
Subject: [R] paste dataframe
Message-ID: <3CB4E5C6.80606@inrialpes.fr>

Hi all,
Assume i have two dataframes A and B with characters objects
for example,
A<-rbind(c("the","is"),c("and","!"))
B<-rbind(c("car","red"),c("blue","!"))

and i would like to obtain the C dataframe
C<-rbind(c("the car", "is red"),c("and blue","!!"))

What is the solution without loops ?
Thanks
Olivier



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From macq at llnl.gov  Wed Apr 10 16:23:31 2002
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 10 Apr 2002 07:23:31 -0700
Subject: [R] R cross-platform compatibility--wow!
Message-ID: <p05101500b8d9f54b5215@[128.115.153.6]>

I am impressed!

I have R 1.4.1 installed on a remote Solaris system, and R 1.4.0 
installed on my desktop Macintosh running OS X.

I did some work using R on the Solaris system, i.e., read some data, 
wrote some functions to do things with the data, including x11 
graphics.

I mounted the Solaris directories where I did the work on my Mac 
using NFS. Running R 1.4.0 on my Mac in the mounted directories, 
using the data and functions created with R 1.4.1 on the Solaris box, 
works like a charm. No need to actually transfer the .RData files 
from one computer to the other.

Congratulations and thanks to the R core team and other contributors 
for this achievement.

-Don

-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
--------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Wed Apr 10 16:47:48 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 10 Apr 2002 16:47:48 +0200
Subject: [R] matrix dimension and for loop
References: <3CB40C0E.10317.1B6ED5@localhost>
Message-ID: <3CB45094.E1CFE4FE@statistik.uni-dortmund.de>

ggrothendieck at yifan.net wrote:
> 
> > My questions are that if I have
> >
> > > x<-rnorm(50)
> > > dim(x)<-c(10,5)
> > > y=1:5
> > > Z<-matrix(0,NROW(x),NROW(y))
> > > for (j in 1:NROW(y)) Z[,j]<-x[,j]*y[j]
> >
> > 1. Is there any other way to write this without 'for'
> > loop?
> >
> > 2. and if I don't know the dimension of x, which could
> > be only 1 column, how could I write the command
> 
> I thought I would collect together some of the solutions that have
> been posted as well as mention a few others.  I have also added
> some discussion particularly with reference to the second question.
> There appears to be a myriad of ways to address this problem in R.
> Since I am learning R I found it useful for myself to explore various
> solutions and maybe others will find this helpful too.
> 
> The problem is to multiply the jth column of a matrix x by y[j] for each j.
> Its also possible for x to be a vector in which case y may be a scalar.
> 
> The first 4 solutions regard x as a one column matrix if x is a vector and
> so always return a matrix.  The 5th solution returns a vector if x is a
> vector.
> 
> 1. Matrix multiplication. Note that if x is a vector then it is treated as a
>    one column matrix.  Also note that NROW(x) is the same as nrow(x), if x is a
>    matrix; however, if x is a vector, then NROW(x) is its length while nrow(x)
>    is NULL.  Thus it is important here to use NROW and not nrow. This is
>    discussed in the help on nrow.
> 
>         x %*% diag(y,NROW(x))


Not quite. The number of *columns* of x, ncol(x), is interesting here,
not NROW(x),
or just use length(y) instead of ncol(x) ....


Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deepayansarkar at yahoo.com  Wed Apr 10 17:16:28 2002
From: deepayansarkar at yahoo.com (Deepayan Sarkar)
Date: Wed, 10 Apr 2002 08:16:28 -0700 (PDT)
Subject: [R] paste dataframe
In-Reply-To: <3CB4E5C6.80606@inrialpes.fr>
Message-ID: <20020410151628.31020.qmail@web13906.mail.yahoo.com>


--- Olivier Martin <olivier.martin at inrialpes.fr> wrote:
> Hi all,
> Assume i have two dataframes A and B with characters objects
> for example,
> A<-rbind(c("the","is"),c("and","!"))
> B<-rbind(c("car","red"),c("blue","!"))

I believe these would be just matrices, and not data frames.

> and i would like to obtain the C dataframe
> C<-rbind(c("the "is red"),c("and blue","!!"))
> 
> What is the solution without loops ?

If you mean 

C<-rbind(c("the "is red"),c("and blue","! !"))

you could try

C <- matrix(paste(A, B), dim(A))

(this is assuming that dim(A)==dim(B), you could put a check for that).
This will not work if A and B are data frames, BTW.

-Deepayan




__________________________________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ernesto at ipimar.pt  Wed Apr 10 19:12:25 2002
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 10 Apr 2002 18:12:25 +0100
Subject: [R] R cross-platform compatibility--wow!
In-Reply-To: <p05101500b8d9f54b5215@[128.115.153.6]>
References: <p05101500b8d9f54b5215@[128.115.153.6]>
Message-ID: <1018458745.19766.68.camel@gandalf>

Hi

I usually work on the same .RData in windows and linux whithout any
problem, for a long time.

This is one of preferred features in R.

In my opinion R is one of the best examples in cross-platform
compatibility.

Best regards, thanks and keep the good work.

EJ 

On Wed, 2002-04-10 at 15:23, Don MacQueen wrote:
> I am impressed!
> 
> I have R 1.4.1 installed on a remote Solaris system, and R 1.4.0 
> installed on my desktop Macintosh running OS X.
> 
> I did some work using R on the Solaris system, i.e., read some data, 
> wrote some functions to do things with the data, including x11 
> graphics.
> 
> I mounted the Solaris directories where I did the work on my Mac 
> using NFS. Running R 1.4.0 on my Mac in the mounted directories, 
> using the data and functions created with R 1.4.1 on the Solaris box, 
> works like a charm. No need to actually transfer the .RData files 
> from one computer to the other.
> 
> Congratulations and thanks to the R core team and other contributors 
> for this achievement.
> 
> -Don
> 
> -- 
> --------------------------------------
> Don MacQueen
> Environmental Protection Department
> Lawrence Livermore National Laboratory
> Livermore, CA, USA
> --------------------------------------
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ggrothendieck at yifan.net  Wed Apr 10 18:06:35 2002
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Wed, 10 Apr 2002 12:06:35 -0400
Subject: [R] matrix dimension and for loop
In-Reply-To: <3CB45094.E1CFE4FE@statistik.uni-dortmund.de>
Message-ID: <3CB42ACB.14215.93828A@localhost>

On 10 Apr 2002 at 16:47, Uwe Ligges wrote:

> ggrothendieck at yifan.net wrote:

> > 1. Matrix multiplication. Note that if x is a vector then it is treated as a
> >    one column matrix.  Also note that NROW(x) is the same as nrow(x), if x is a
> >    matrix; however, if x is a vector, then NROW(x) is its length while nrow(x)
> >    is NULL.  Thus it is important here to use NROW and not nrow. This is
> >    discussed in the help on nrow.
> > 
> >         x %*% diag(y,NROW(x))
> 
> 
> Not quite. The number of *columns* of x, ncol(x), is interesting here,
> not NROW(x),
> or just use length(y) instead of ncol(x) ....

Thanks for pointing out this error.  Note, however, that NROW(x) should
be NCOL(x), and not ncol(x), since x can be a vector.   length(y) is
probably best.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Wed Apr 10 18:13:27 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 10 Apr 2002 09:13:27 -0700 (PDT)
Subject: [R] problem with do.call
In-Reply-To: <1018440005.19767.25.camel@gandalf>
Message-ID: <Pine.A41.4.44.0204100912030.103838-100000@homer25.u.washington.edu>

On 10 Apr 2002, Ernesto Jardim wrote:

> Hi
>
> I'm writing a function that uses four parameters (scalars) and I need to
> run it in an iterative process (the parameters vary to find the minimum
> RSS).
>
> I don't want to use loops and so tried the do.call function. However it
> didn't work. My understanding is that the do.call simple runs the
> function replacing the arguments (scalars by vectors), instead of runing
> the function for each set of scalars in the list, what I need.
>
> Can you please tell me if there is another way of doing it whithout
> using the for loop ?

And why wouldn't you want to use the for() loop?  Unless your function is
vectorised you're not going to gain anything by getting rid of the for()
loop.

	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Wed Apr 10 18:17:21 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 10 Apr 2002 09:17:21 -0700 (PDT)
Subject: [R] write.table
In-Reply-To: <1018446277.29801.67.camel@penguin>
Message-ID: <Pine.A41.4.44.0204100914130.103838-100000@homer25.u.washington.edu>

On 10 Apr 2002, Michaell Taylor wrote:

>
> I actually remember something about that in R 1.3, but I am using R 1.4
> now :
>
> R : Copyright 2001, The R Development Core Team
> Version 1.4.0  (2001-12-19)
>
> (I just double checked).
>
> BUT, I see I am one step out of date in the foreign library. I have
> foreign_0.4-6.tar.gz, but I see a  foreign_0.5-2.tar.gz on cran, so
> perhaps that is the issue.
>

You're actually a few steps out of date.  According to the Changelog the
bug was fixed in November and 0.4-8 was released in December.

The problem is that R sometimes uses the C length of a string and
sometimes uses the allocated length, and that read.dta was making these
differ.

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Wed Apr 10 18:19:02 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 10 Apr 2002 09:19:02 -0700 (PDT)
Subject: [R] paste dataframe
In-Reply-To: <3CB4E5C6.80606@inrialpes.fr>
Message-ID: <Pine.A41.4.44.0204100918250.103838-100000@homer25.u.washington.edu>

On Thu, 11 Apr 2002, Olivier Martin wrote:

> Hi all,
> Assume i have two dataframes A and B with characters objects
> for example,
> A<-rbind(c("the","is"),c("and","!"))
> B<-rbind(c("car","red"),c("blue","!"))
>
> and i would like to obtain the C dataframe
> C<-rbind(c("the car", "is red"),c("and blue","!!"))
>
> What is the solution without loops ?

One solution is
  matrix(paste(A,B),2)


	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ernesto at ipimar.pt  Wed Apr 10 19:48:50 2002
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 10 Apr 2002 18:48:50 +0100
Subject: [R] problem with do.call
In-Reply-To: 
	<Pine.A41.4.44.0204100912030.103838-100000@homer25.u.washington.edu>
References: 
	<Pine.A41.4.44.0204100912030.103838-100000@homer25.u.washington.edu>
Message-ID: <1018460930.19767.87.camel@gandalf>

On Wed, 2002-04-10 at 17:13, Thomas Lumley wrote:
> On 10 Apr 2002, Ernesto Jardim wrote:
> 
> > Hi
> >
> > I'm writing a function that uses four parameters (scalars) and I need to
> > run it in an iterative process (the parameters vary to find the minimum
> > RSS).
> >
> > I don't want to use loops and so tried the do.call function. However it
> > didn't work. My understanding is that the do.call simple runs the
> > function replacing the arguments (scalars by vectors), instead of runing
> > the function for each set of scalars in the list, what I need.
> >
> > Can you please tell me if there is another way of doing it whithout
> > using the for loop ?
> 
> And why wouldn't you want to use the for() loop?  Unless your function is
> vectorised you're not going to gain anything by getting rid of the for()
> loop.
> 
> 	-thomas
> 
> Thomas Lumley			Asst. Professor, Biostatistics
> tlumley at u.washington.edu	University of Washington, Seattle

define "vectorize function"

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Wed Apr 10 18:41:30 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 10 Apr 2002 09:41:30 -0700 (PDT)
Subject: [R] problem with do.call
In-Reply-To: <1018460930.19767.87.camel@gandalf>
Message-ID: <Pine.A41.4.44.0204100937010.103838-100000@homer25.u.washington.edu>

On 10 Apr 2002, Ernesto Jardim wrote:
>
> define "vectorize function"
>

Many R functions can operate on a vector of parameter values, eg

log(10,c(2,e,10)) gives the log of 10 to base 2, e, and 10

If your function can do this, you can construct a set of vectors
containing all your parameter values (expand.grid() is useful for this)
and evaluate your function once.

This can be faster than for() loops when much of the iteration is done in
compiled code.  If the iteration has to be done in interpreted code then
you can't really speed up the for() loops.  You can hide the loops with
the apply() functions, which may make your code more readable, but it
won't typically speed it up.


	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Wed Apr 10 18:52:16 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 10 Apr 2002 18:52:16 +0200
Subject: [R] S-plus spam to R-announce ..
In-Reply-To: <JPEBKBMBPPHHPEIOHMGHOEBBHMAA.mariabeth.silkey@predict.ch>
References: <JPEBKBMBPPHHPEIOHMGHOEBBHMAA.mariabeth.silkey@predict.ch>
Message-ID: <15540.28096.781921.902278@gargle.gargle.HOWL>


aargh!  This was not according to R-announce "policy" as in
	http://www.r-project.org/mail.html
I think it would only barely have been fit for R-help.
Well, this should have been the last E-mail from "@predict.ch" to
R-announce;  The next ones should end up in the trashcan
(well, in one of my mail inboxes..)

Note that we try to guarantee that R-announce is a very low
volume list really only for (somewhat important) announcements
about R.

(And if you have forgotten: 
 Everyone subscribed to R-help automatically gets everything
 posted to R-announce and hence it does not really make sense to
 be subscribed to both lists, whereas it *does* make some sense to be
 on R-announce and R-help-DIGEST
)

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ggrothendieck at yifan.net  Wed Apr 10 18:59:19 2002
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Wed, 10 Apr 2002 12:59:19 -0400
Subject: [R] Newsgroup
Message-ID: <3CB43727.5811.C3CB84@localhost>


This morning I had 37 messages from the r-help list in my mailbox.
I think its becoming excessive for an e-mail list.

I wonder if whoever looks after this list could either move or gateway
it to a usenet group?

That would also eliminate the need for special purpose archiving and
searching facilities since the site: 

http://groups.google.com 

would automatically provide that. That site also allows one to both read 
and post via the web (with a delay of several hours) in case one does not
care to use newsgroup software.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lancelot at sentoo.sn  Wed Apr 10 19:39:10 2002
From: lancelot at sentoo.sn (Renaud Lancelot)
Date: Wed, 10 Apr 2002 17:39:10 +0000
Subject: [R] Newsgroup
References: <3CB43727.5811.C3CB84@localhost>
Message-ID: <3CB478BE.9FC18DA3@sentoo.sn>

I agree with you: the list is VERY busy. This is sometimes a problem for
modem users with rather poor internet facilities (my case). An
alternative to your proposal would be to adopt the same behaviour as for
S-news: reply directly to the caller who summarizes to the group. Of
course, it's more time-consuming for the caller, but it should divide at
least by 2 or 3 the number of messages on R-Help...

Best,

Renaud

ggrothendieck at yifan.net wrote:
> 
> This morning I had 37 messages from the r-help list in my mailbox.
> I think its becoming excessive for an e-mail list.
> 
> I wonder if whoever looks after this list could either move or gateway
> it to a usenet group?
> 
> That would also eliminate the need for special purpose archiving and
> searching facilities since the site:
> 
> http://groups.google.com
> 
> would automatically provide that. That site also allows one to both read
> and post via the web (with a delay of several hours) in case one does not
> care to use newsgroup software.
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
Dr Renaud Lancelot, v?t?rinaire
CIRAD, D?partement Elevage et M?decine V?t?rinaire (CIRAD-Emvt)
Programme Productions Animales
http://www.cirad.fr/presentation/programmes/prod-ani.shtml (Fran?ais)
http://www.cirad.fr/presentation/en/program-eng/prod-ani.shtml (English)

ISRA-LNERV                      tel    (221) 832 49 02
BP 2057 Dakar-Hann              fax    (221) 821 18 79 (CIRAD)
Senegal                         e-mail renaud.lancelot at cirad.fr
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ggrothendieck at yifan.net  Wed Apr 10 19:44:18 2002
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Wed, 10 Apr 2002 13:44:18 -0400
Subject: [R] paste dataframe
In-Reply-To: <3CB4E5C6.80606@inrialpes.fr>
Message-ID: <3CB441B2.9646.ECF96F@localhost>

apply(array(c(A,B),dim=c(2,2,2)),c(1,2),function(x)paste(x[1],x[2]))

On 11 Apr 2002 at 3:24, Olivier Martin wrote:

> Hi all,
> Assume i have two dataframes A and B with characters objects
> for example,
> A<-rbind(c("the","is"),c("and","!"))
> B<-rbind(c("car","red"),c("blue","!"))
> 
> and i would like to obtain the C dataframe
> C<-rbind(c("the car", "is red"),c("and blue","!!"))
> 
> What is the solution without loops ?

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rhskelto at atm.ox.ac.uk  Wed Apr 10 21:20:36 2002
From: rhskelto at atm.ox.ac.uk (Randall Skelton)
Date: Wed, 10 Apr 2002 20:20:36 +0100 (BST)
Subject: [R] Newsgroup
In-Reply-To: <3CB43727.5811.C3CB84@localhost>
Message-ID: <Pine.LNX.4.33.0204102013550.26796-100000@mulligan.atm.ox.ac.uk>

I absolutely agree.

Cheers,
Randall

On Wed, 10 Apr 2002 ggrothendieck at yifan.net wrote:

> This morning I had 37 messages from the r-help list in my mailbox.
> I think its becoming excessive for an e-mail list.
>
> I wonder if whoever looks after this list could either move or gateway
> it to a usenet group?
>
> That would also eliminate the need for special purpose archiving and
> searching facilities since the site:
>
> http://groups.google.com
>
> would automatically provide that. That site also allows one to both read
> and post via the web (with a delay of several hours) in case one does not
> care to use newsgroup software.
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ggrothendieck at yifan.net  Wed Apr 10 22:11:51 2002
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Wed, 10 Apr 2002 16:11:51 -0400
Subject: [R] Newsgroup
In-Reply-To: <3CB478BE.9FC18DA3@sentoo.sn>
Message-ID: <3CB46447.32401.1740D0A@localhost>

Good idea.  

One other benefit of this is that if one later wanted to
search the list archives one could find a summary of the
issue of interest in a single message instead of wading through 
multiple posts.  

It would thus provide interm documentation for idioms and ease
the subsequent creation of idiom lists such as the excellent one 
by Paul Johnson:

  http://lark.cc.ukans.edu/~pauljohn/R/statsRus.html


On 10 Apr 2002 at 17:39, Renaud Lancelot wrote:

> I agree with you: the list is VERY busy. This is sometimes a problem for
> modem users with rather poor internet facilities (my case). An
> alternative to your proposal would be to adopt the same behaviour as for
> S-news: reply directly to the caller who summarizes to the group. Of
> course, it's more time-consuming for the caller, but it should divide at
> least by 2 or 3 the number of messages on R-Help...

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at blindglobe.net  Wed Apr 10 22:19:21 2002
From: rossini at blindglobe.net (A.J. Rossini)
Date: 10 Apr 2002 13:19:21 -0700
Subject: [R] Newsgroup
In-Reply-To: <3CB46447.32401.1740D0A@localhost>
References: <3CB46447.32401.1740D0A@localhost>
Message-ID: <873cy35mt2.fsf@jeeves.blindglobe.net>


it's not too hard to setup the gateway by yourself.  It just takes a
bit of knowledge of NNTP servers, and there are open source scripts
for doing the gating.   (not hard, but it is time consuming, at least
from what I recall from 5 years ago).

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M-W: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my friday location is usually completely unpredictable.)


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Wed Apr 10 22:31:29 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 10 Apr 2002 13:31:29 -0700 (PDT)
Subject: [R] Newsgroup
In-Reply-To: <3CB46447.32401.1740D0A@localhost>
Message-ID: <Pine.A41.4.44.0204101322310.67164-100000@homer10.u.washington.edu>

On Wed, 10 Apr 2002 ggrothendieck at yifan.net wrote:

> Good idea.
>
> One other benefit of this is that if one later wanted to
> search the list archives one could find a summary of the
> issue of interest in a single message instead of wading through
> multiple posts.

I actually disagree (strongly, about reply-to-sender and weakly about
newsgroup).

The last time this was discussed it was pointed out that there really
aren't enough of us for a newgroup (not much over 1000), and that
newsgroups tend to attract quite a bit more spam. Its fairly easy to
filter r-help into a separate mail folder and some mail readers (and the
mailing list archive) can even given you a threaded version. However, a
newsgroup might be useful.

Reply-to-sender, OTOH, i think is a really bad idea.  In the first place
it removes the discussion of answers -- some really are better than
others.  In addition, you can't tell which questions have been
answered already, so questions are more likely to fall through the cracks.

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rpeng at stat.ucla.edu  Wed Apr 10 23:07:14 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Wed, 10 Apr 2002 14:07:14 -0700 (PDT)
Subject: [R] Newsgroup
In-Reply-To: <Pine.A41.4.44.0204101322310.67164-100000@homer10.u.washington.edu>
Message-ID: <Pine.GSO.4.10.10204101406070.8559-100000@fisher.stat.ucla.edu>

Correct me if I'm wrong, but isn't there a digest version of r-help?
Perhaps this might be a simple alternative to getting 40 messages in your
inbox everyday.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Wed, 10 Apr 2002, Thomas Lumley wrote:

> On Wed, 10 Apr 2002 ggrothendieck at yifan.net wrote:
> 
> > Good idea.
> >
> > One other benefit of this is that if one later wanted to
> > search the list archives one could find a summary of the
> > issue of interest in a single message instead of wading through
> > multiple posts.
> 
> I actually disagree (strongly, about reply-to-sender and weakly about
> newsgroup).
> 
> The last time this was discussed it was pointed out that there really
> aren't enough of us for a newgroup (not much over 1000), and that
> newsgroups tend to attract quite a bit more spam. Its fairly easy to
> filter r-help into a separate mail folder and some mail readers (and the
> mailing list archive) can even given you a threaded version. However, a
> newsgroup might be useful.
> 
> Reply-to-sender, OTOH, i think is a really bad idea.  In the first place
> it removes the discussion of answers -- some really are better than
> others.  In addition, you can't tell which questions have been
> answered already, so questions are more likely to fall through the cracks.
> 
> 	-thomas
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lancelot at sentoo.sn  Wed Apr 10 23:15:43 2002
From: lancelot at sentoo.sn (Renaud Lancelot)
Date: Wed, 10 Apr 2002 21:15:43 +0000
Subject: [R] Newsgroup
References: <Pine.A41.4.44.0204101322310.67164-100000@homer10.u.washington.edu>
Message-ID: <3CB4AB7F.2F625493@sentoo.sn>

Thomas Lumley wrote:
> 
> On Wed, 10 Apr 2002 ggrothendieck at yifan.net wrote:
> 
> > Good idea.
> >
> > One other benefit of this is that if one later wanted to
> > search the list archives one could find a summary of the
> > issue of interest in a single message instead of wading through
> > multiple posts.
> 
> I actually disagree (strongly, about reply-to-sender and weakly about
> newsgroup).
> 
> The last time this was discussed it was pointed out that there really
> aren't enough of us for a newgroup (not much over 1000), and that
> newsgroups tend to attract quite a bit more spam. Its fairly easy to
> filter r-help into a separate mail folder and some mail readers (and the
> mailing list archive) can even given you a threaded version. However, a
> newsgroup might be useful.

That's what I do, but when I leave my office for a 2-day field trip, I
have to unsubscribe from R-help just because I'm scared of the 100 msgs
or so waiting for me when I come back.

> Reply-to-sender, OTOH, i think is a really bad idea.  In the first place
> it removes the discussion of answers -- some really are better than
> others.  In addition, you can't tell which questions have been
> answered already, so questions are more likely to fall through the cracks.

IMHO it works pretty well with S-news, and there are quite "hot"
discussions there, too. Why couldn't it be the same here ? When I find
interesting questions, I keep them apart and go back to the sender in
case he (she) does not summarize.

Renaud
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tklistaddr at keittlab.bio.sunysb.edu  Thu Apr 11 00:28:54 2002
From: tklistaddr at keittlab.bio.sunysb.edu (Timothy H. Keitt)
Date: 10 Apr 2002 18:28:54 -0400
Subject: [R] Newsgroup
In-Reply-To: <3CB478BE.9FC18DA3@sentoo.sn>
References: <3CB43727.5811.C3CB84@localhost>  <3CB478BE.9FC18DA3@sentoo.sn>
Message-ID: <1018477734.11413.14.camel@keittlab-6>

The reply-to-list is quite useful IMHO. The real solution is to filter
your list email into separate folders. Its quite easy with procmail,
although I currently use evolutions filters (and a seperate email
address for lists).

Tim

On Wed, 2002-04-10 at 13:39, Renaud Lancelot wrote:
> I agree with you: the list is VERY busy. This is sometimes a problem for
> modem users with rather poor internet facilities (my case). An
> alternative to your proposal would be to adopt the same behaviour as for
> S-news: reply directly to the caller who summarizes to the group. Of
> course, it's more time-consuming for the caller, but it should divide at
> least by 2 or 3 the number of messages on R-Help...
> 
> Best,
> 
> Renaud
> 
> ggrothendieck at yifan.net wrote:
> > 
> > This morning I had 37 messages from the r-help list in my mailbox.
> > I think its becoming excessive for an e-mail list.
> > 
> > I wonder if whoever looks after this list could either move or gateway
> > it to a usenet group?
> > 
> > That would also eliminate the need for special purpose archiving and
> > searching facilities since the site:
> > 
> > http://groups.google.com
> > 
> > would automatically provide that. That site also allows one to both read
> > and post via the web (with a delay of several hours) in case one does not
> > care to use newsgroup software.
> > 
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 
> -- 
> Dr Renaud Lancelot, v?t?rinaire
> CIRAD, D?partement Elevage et M?decine V?t?rinaire (CIRAD-Emvt)
> Programme Productions Animales
> http://www.cirad.fr/presentation/programmes/prod-ani.shtml (Fran?ais)
> http://www.cirad.fr/presentation/en/program-eng/prod-ani.shtml (English)
> 
> ISRA-LNERV                      tel    (221) 832 49 02
> BP 2057 Dakar-Hann              fax    (221) 821 18 79 (CIRAD)
> Senegal                         e-mail renaud.lancelot at cirad.fr
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From markhall at gol.com  Thu Apr 11 00:38:30 2002
From: markhall at gol.com (Mark E. Hall)
Date: Thu, 11 Apr 2002 07:38:30 +0900
Subject: [R] Newsgroup
In-Reply-To: <3CB43727.5811.C3CB84@localhost>
Message-ID: <000201c1e0e0$7678aa00$a114d8cb@01680437>


It is actually much cheaper for me to download 37 messages than read
from the web.
Some of us have to pay dearly for our on-line time; newsgroups are damn
expensive in that case.  Clearly you don't live in a country that has
obscene phone rates like those here in Japan...:)

Best, MEH


> -----Original Message-----
> From: owner-r-help at stat.math.ethz.ch
[mailto:owner-r-help at stat.math.ethz.ch] On
> Behalf Of ggrothendieck at yifan.net
> Sent: Thursday, April 11, 2002 1:59 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Newsgroup
> 
> 
> This morning I had 37 messages from the r-help list in my mailbox.
> I think its becoming excessive for an e-mail list.
> 
> I wonder if whoever looks after this list could either move or gateway
> it to a usenet group?
> 
> That would also eliminate the need for special purpose archiving and
> searching facilities since the site:
> 
> http://groups.google.com
> 
> would automatically provide that. That site also allows one to both
read
> and post via the web (with a delay of several hours) in case one does
not
> care to use newsgroup software.
> 
>
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To:
r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kjetilh at umsanet.edu.bo  Thu Apr 11 00:46:29 2002
From: kjetilh at umsanet.edu.bo (Kjetilh Halvorsen)
Date: Wed, 10 Apr 2002 18:46:29 -0400 (BOT)
Subject: =?iso-8859-1?Q?Re:_[R]_Newsgroup?=
In-Reply-To: <3CB43727.5811.C3CB84@localhost>
References: <3CB43727.5811.C3CB84@localhost>
Message-ID: <2574.65.119.23.160.1018478789.squirrel@www.umsanet.edu.bo>

Hola!

This topic has arised before, since then I larned about google groups, but 
it is still a fact that there are no newsserver (google or otherwise) on 
this continent, and reading newsgroups is little more than waste of time. 

With a mailing list I can  take down all mail, and close telephone 
connection, reading offline.

I vote strongly against a newsgroup!

Kjetil Halvorsen


 
> This morning I had 37 messages from the r-help list in my mailbox. I
> think its becoming excessive for an e-mail list.
> 
> I wonder if whoever looks after this list could either move or gateway
> it to a usenet group?
> 
> That would also eliminate the need for special purpose archiving and
> searching facilities since the site: 
> 
> http://groups.google.com 
> 
> would automatically provide that. That site also allows one to both
> read  and post via the web (with a delay of several hours) in case one
> does not care to use newsgroup software.
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
.-.-.-
> r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html Send "info", "help", or
> "[un]subscribe"
> (in the "body", not the subject !)  To:
> r-help-request at stat.math.ethz.ch
> 
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From do_joly at yahoo.ca  Thu Apr 11 00:43:43 2002
From: do_joly at yahoo.ca (Damien Joly)
Date: Wed, 10 Apr 2002 17:43:43 -0500
Subject: [R] Principal Component analysis question
Message-ID: <3CB4C01F.10901@yahoo.ca>

I have a question about princomp(mva) that I hope isn't too newbie.

I used the sample data from Table 1.1 in "Manly (1986/1994) Multivariate 
Statistical Methods: a primer. Chapman and Hall" on sparrow body 
measurements.

I rescaled the data to mean 0 and SD 1, and the covariance matrix is:

           V1        V2        V3        V4        V5
V1 1.0000000 0.7349642 0.6618119 0.6452841 0.6051247
V2 0.7349642 1.0000000 0.6737411 0.7685087 0.5290138
V3 0.6618119 0.6737411 1.0000000 0.7631899 0.5262701
V4 0.6452841 0.7685087 0.7631899 1.0000000 0.6066493
V5 0.6051247 0.5290138 0.5262701 0.6066493 1.0000000

Now when I call princomp [fun<-princomp(~V1+V2+V3+V4+V5)], I get the 
following loadings:

        Comp.1      Comp.2     Comp.3      Comp.4     Comp.5
V1 -0.4517989 -0.05072137  0.6904702  0.42041399 -0.3739091
V2 -0.4616809  0.29956355  0.3405484 -0.54786307  0.5300805
V3 -0.4505416  0.32457242 -0.4544927  0.60629605  0.3427923
V4 -0.4707389  0.18468403 -0.4109350 -0.38827811 -0.6516665
V5 -0.3976754 -0.87648935 -0.1784558 -0.06887199  0.1924341

However, this is in contrast to the results in Manly's book:

       Comp.1      Comp.2     Comp.3      Comp.4     Comp.5
V1 0.4517989 -0.05072137  0.6904702 -0.42041399  0.3739091
V2 0.4616809  0.29956355  0.3405484  0.54786307 -0.5300805
V3 0.4505416  0.32457242 -0.4544927 -0.60629605 -0.3427923
V4 0.4707389  0.18468403 -0.4109350  0.38827811  0.6516665
V5 0.3976754 -0.87648935 -0.1784558  0.06887199 -0.1924341

Interestingly, when I do the same in SAS, I get:

        Comp.1      Comp.2     Comp.3      Comp.4     Comp.5
V1  0.4517989  0.05072137 -0.6904702  0.42041399 -0.3739091
V2  0.4616809 -0.29956355 -0.3405484 -0.54786307  0.5300805
V3  0.4505416 -0.32457242  0.4544927  0.60629605  0.3427923
V4  0.4707389 -0.18468403  0.4109350 -0.38827811 -0.6516665
V5  0.3976754  0.87648935  0.1784558 -0.06887199  0.1924341

Finally, when I do it by "hand" in R (i.e., c<-cov(data); e<-eigen(c)), 
I get a fourth answer:

           V5          V4         V3          V2         V1
V1 0.4517989  0.05072137 -0.6904702 -0.42041399 -0.3739091
V2 0.4616809 -0.29956355 -0.3405484  0.54786307  0.5300805
V3 0.4505416 -0.32457242  0.4544927 -0.60629605  0.3427923
V4 0.4707389 -0.18468403  0.4109350  0.38827811 -0.6516665
V5 0.3976754  0.87648935  0.1784558  0.06887199  0.1924341


Can anyone point me in the right direction here?  I can email the raw 
data to anyone if that would help.

Thank you in advance...

Damien

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at blindglobe.net  Thu Apr 11 00:38:41 2002
From: rossini at blindglobe.net (A.J. Rossini)
Date: 10 Apr 2002 15:38:41 -0700
Subject: [R] Newsgroup
In-Reply-To: <2574.65.119.23.160.1018478789.squirrel@www.umsanet.edu.bo>
References: <3CB43727.5811.C3CB84@localhost>
	<2574.65.119.23.160.1018478789.squirrel@www.umsanet.edu.bo>
Message-ID: <87d6x72n7y.fsf@jeeves.blindglobe.net>

>>>>> "kjetilh" == Kjetilh Halvorsen <kjetilh at umsanet.edu.bo> writes:

    kjetilh> I vote strongly against a newsgroup!

I would suggest that there is no reason to vote.  Those that want one,
can implement it, without affecting others.  The software exists.

Note that in the distant past, various departments did do mailing-list
<-> local USENET/NNTP for the S news list.  It was quite amusing (at
least now it is) when they became mis-configured...

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M-W: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my friday location is usually completely unpredictable.)


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Timothy.Keitt at stonybrook.edu  Thu Apr 11 00:45:38 2002
From: Timothy.Keitt at stonybrook.edu (Timothy H. Keitt)
Date: 10 Apr 2002 18:45:38 -0400
Subject: [R] Layout of Fourier frequencies
Message-ID: <1018478739.11031.32.camel@keittlab-6>

I'm doing convolutions in the frequency domain and need to know the
layout of the Fourier modes returned by fft. (This is leading up to a
more involved question about moment generating functions, but I need to
know if I've got this part correct first.)

I think in 1D the pattern is:

0 1 2 3 -2 1 (even)
0 1 2 3 -3 2 1 (odd)

In 2D is it simply (for a square matrix):

0 1 2 -1 (horizontal)
0 1 2 -1
0 1 2 -1
0 1 2 -1

and the above transposed for the vertical? Thanks.

Tim

-- 
Timothy H. Keitt
Department of Ecology and Evolution
State University of New York at Stony Brook
Stony Brook, New York 11794 USA
Phone: 631-632-1101, FAX: 631-632-7626
http://life.bio.sunysb.edu/ee/keitt/
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ggrothendieck at yifan.net  Thu Apr 11 01:21:50 2002
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Wed, 10 Apr 2002 19:21:50 -0400
Subject: [R] Newsgroup
In-Reply-To: <2574.65.119.23.160.1018478789.squirrel@www.umsanet.edu.bo>
References: <3CB43727.5811.C3CB84@localhost>
Message-ID: <3CB490CE.2724.221FEE4@localhost>


You don't have to access the newsgroup via google.  You can
download all the news from a newsgroup using a news client
such as Netscape's news client, pine, Outlook Express (Windows)
or Forte FreeAgent (Windows).  This works very similarly to how 
email works.   

Also, it would be possible to have the newsgroup and the email
list at the same time such that anything posted to one automatically
shows up on the other too.  That was what I meant when
I referred to a gateway.

On 10 Apr 2002 at 18:46, Kjetilh Halvorsen wrote:

> Hola!
> 
> This topic has arised before, since then I larned about google groups, but 
> it is still a fact that there are no newsserver (google or otherwise) on 
> this continent, and reading newsgroups is little more than waste of time. 
> 
> With a mailing list I can  take down all mail, and close telephone 
> connection, reading offline.
> 
> I vote strongly against a newsgroup!
> 
> Kjetil Halvorsen
> 
> 
>  
> > This morning I had 37 messages from the r-help list in my mailbox. I
> > think its becoming excessive for an e-mail list.
> > 
> > I wonder if whoever looks after this list could either move or gateway
> > it to a usenet group?
> > 
> > That would also eliminate the need for special purpose archiving and
> > searching facilities since the site: 
> > 
> > http://groups.google.com 
> > 
> > would automatically provide that. That site also allows one to both
> > read  and post via the web (with a delay of several hours) in case one
> > does not care to use newsgroup software.
> > 
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> .-.-.-
> > r-help mailing list -- Read
> > http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html Send "info", "help", or
> > "[un]subscribe"
> > (in the "body", not the subject !)  To:
> > r-help-request at stat.math.ethz.ch
> > 
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._
> 
> 
> 



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From nklepeis at uclink4.berkeley.edu  Thu Apr 11 01:26:08 2002
From: nklepeis at uclink4.berkeley.edu (Neil Klepeis)
Date: Wed, 10 Apr 2002 16:26:08 -0700
Subject: [R] Newsgroup
References: <Pine.A41.4.44.0204101322310.67164-100000@homer10.u.washington.edu> <3CB4AB7F.2F625493@sentoo.sn>
Message-ID: <3CB4CA10.E3B91E5D@uclink4.berkeley.edu>

What about splitting R-help into:

R-help
R-help-basics

or

R-help-beginner
R-help-advanced

[all current R-help subscribers would be automatically subscribed to
both]


Or even (after perusing the R key-words index):

R-help-basics
R-help-graphics
R-help-programming
R-help-input-output
R-help-mathematics
R-help-statistics
R-help-misc

Or a simpler grouping:

R-help-basics
R-help-statistics
R-help-misc

Or some other grouping.


Rationale:  Avoid high-volume beginner questions by unsubscribing to
R-beginner & R-basics (but still get individual undigested messages). 
It would also help facilitate searches of the R archives.  Those
subscribed to everything would not notice any difference from the status
quo. 

This is just a suggestion...I wouldn't want to create a lot of work for
Martin  :).   


-- 
___________________________________________________________
Neil E. Klepeis -- School of Public Health, UC Berkeley and
Lawrence Berkeley National Laboratory, Berkeley, CA USA
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rpeng at stat.ucla.edu  Thu Apr 11 01:36:26 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Wed, 10 Apr 2002 16:36:26 -0700 (PDT)
Subject: [R] Principal Component analysis question
In-Reply-To: <3CB4C01F.10901@yahoo.ca>
Message-ID: <Pine.GSO.4.10.10204101628520.27509-100000@fisher.stat.ucla.edu>

It seems that you have gotten the same answer as the book, with the
exception that the first, fourth and fifth components have different
signs.  I believe that when doing eigenvalue decompositions it's possible
(and I think documented) that you might get a sign flip here and there
depending on your machine. 

It appears that princomp.default() uses La.eigen() and the help page for
La.eigen says:

     `La.eigen' is preferred to `eigen' for new projects, but its
     eigenvectors may differ in sign and (in the asymmetric case) in
     normalization. (They may also differ between methods and between
     platforms.)

Nevertheless, your PCA results will still be valid.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Wed, 10 Apr 2002, Damien Joly wrote:

> I have a question about princomp(mva) that I hope isn't too newbie.
> 
> I used the sample data from Table 1.1 in "Manly (1986/1994) Multivariate 
> Statistical Methods: a primer. Chapman and Hall" on sparrow body 
> measurements.
> 
> I rescaled the data to mean 0 and SD 1, and the covariance matrix is:
> 
>            V1        V2        V3        V4        V5
> V1 1.0000000 0.7349642 0.6618119 0.6452841 0.6051247
> V2 0.7349642 1.0000000 0.6737411 0.7685087 0.5290138
> V3 0.6618119 0.6737411 1.0000000 0.7631899 0.5262701
> V4 0.6452841 0.7685087 0.7631899 1.0000000 0.6066493
> V5 0.6051247 0.5290138 0.5262701 0.6066493 1.0000000
> 
> Now when I call princomp [fun<-princomp(~V1+V2+V3+V4+V5)], I get the 
> following loadings:
> 
>         Comp.1      Comp.2     Comp.3      Comp.4     Comp.5
> V1 -0.4517989 -0.05072137  0.6904702  0.42041399 -0.3739091
> V2 -0.4616809  0.29956355  0.3405484 -0.54786307  0.5300805
> V3 -0.4505416  0.32457242 -0.4544927  0.60629605  0.3427923
> V4 -0.4707389  0.18468403 -0.4109350 -0.38827811 -0.6516665
> V5 -0.3976754 -0.87648935 -0.1784558 -0.06887199  0.1924341
> 
> However, this is in contrast to the results in Manly's book:
> 
>        Comp.1      Comp.2     Comp.3      Comp.4     Comp.5
> V1 0.4517989 -0.05072137  0.6904702 -0.42041399  0.3739091
> V2 0.4616809  0.29956355  0.3405484  0.54786307 -0.5300805
> V3 0.4505416  0.32457242 -0.4544927 -0.60629605 -0.3427923
> V4 0.4707389  0.18468403 -0.4109350  0.38827811  0.6516665
> V5 0.3976754 -0.87648935 -0.1784558  0.06887199 -0.1924341
> 
> Interestingly, when I do the same in SAS, I get:
> 
>         Comp.1      Comp.2     Comp.3      Comp.4     Comp.5
> V1  0.4517989  0.05072137 -0.6904702  0.42041399 -0.3739091
> V2  0.4616809 -0.29956355 -0.3405484 -0.54786307  0.5300805
> V3  0.4505416 -0.32457242  0.4544927  0.60629605  0.3427923
> V4  0.4707389 -0.18468403  0.4109350 -0.38827811 -0.6516665
> V5  0.3976754  0.87648935  0.1784558 -0.06887199  0.1924341
> 
> Finally, when I do it by "hand" in R (i.e., c<-cov(data); e<-eigen(c)), 
> I get a fourth answer:
> 
>            V5          V4         V3          V2         V1
> V1 0.4517989  0.05072137 -0.6904702 -0.42041399 -0.3739091
> V2 0.4616809 -0.29956355 -0.3405484  0.54786307  0.5300805
> V3 0.4505416 -0.32457242  0.4544927 -0.60629605  0.3427923
> V4 0.4707389 -0.18468403  0.4109350  0.38827811 -0.6516665
> V5 0.3976754  0.87648935  0.1784558  0.06887199  0.1924341
> 
> 
> Can anyone point me in the right direction here?  I can email the raw 
> data to anyone if that would help.
> 
> Thank you in advance...
> 
> Damien
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Thu Apr 11 01:41:41 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 10 Apr 2002 16:41:41 -0700 (PDT)
Subject: [R] Principal Component analysis question
In-Reply-To: <3CB4C01F.10901@yahoo.ca>
Message-ID: <Pine.A41.4.44.0204101635480.73964-100000@homer10.u.washington.edu>

On Wed, 10 Apr 2002, Damien Joly wrote:

> Now when I call princomp [fun<-princomp(~V1+V2+V3+V4+V5)], I get the
> following loadings:
>
>         Comp.1      Comp.2     Comp.3      Comp.4     Comp.5
> V1 -0.4517989 -0.05072137  0.6904702  0.42041399 -0.3739091
> V2 -0.4616809  0.29956355  0.3405484 -0.54786307  0.5300805
> V3 -0.4505416  0.32457242 -0.4544927  0.60629605  0.3427923
> V4 -0.4707389  0.18468403 -0.4109350 -0.38827811 -0.6516665
> V5 -0.3976754 -0.87648935 -0.1784558 -0.06887199  0.1924341
>
> However, this is in contrast to the results in Manly's book:
>
>        Comp.1      Comp.2     Comp.3      Comp.4     Comp.5
> V1 0.4517989 -0.05072137  0.6904702 -0.42041399  0.3739091
> V2 0.4616809  0.29956355  0.3405484  0.54786307 -0.5300805
> V3 0.4505416  0.32457242 -0.4544927 -0.60629605 -0.3427923
> V4 0.4707389  0.18468403 -0.4109350  0.38827811  0.6516665
> V5 0.3976754 -0.87648935 -0.1784558  0.06887199 -0.1924341

<and two other ways snipped>

These four are all the same principal components, it's just that the sign
is reversed on some of them. That is, if vectors (v1,v2,v3,v4,v5) are
principal components, so are (-v1,-v2,-v3,-v4,-v5), or as in this case
(v1, v2,v3,-v4,-v5).

Principal components are only defined up to sign changes (they specify
lines in n-space and you can go along a line in either direction).
Different computations will likely give different signs

	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at blindglobe.net  Thu Apr 11 01:50:17 2002
From: rossini at blindglobe.net (A.J. Rossini)
Date: 10 Apr 2002 16:50:17 -0700
Subject: [R] programmatic installation
Message-ID: <87u1qjyuyu.fsf@jeeves.blindglobe.net>


Okay, so I've got a set of directories containing unpacked R packages
(unpacked, since for various sensible reasons, I'm editing them in warped
ways). 

Supposing that these are in:

        /home/rossini/Runpacked

I thought I could do something like:

install.packages("MyUnPackedRPackage",   # top package name
                 lib="/home/rossini/lib/R", # where I'd like to install
                 destdir="/home/faculty/rossini/sandbox/madman/Rpacks") ## assuming
                                        ## this is where it goes.

But this isn't the right incantation.  I know that I could simply
shell out using system, i.e. system("R CMD install /path/to/dir"), 
but is there a cleaner way?

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M-W: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my friday location is usually completely unpredictable.)


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From paulocardoso at netvisao.pt  Thu Apr 11 02:45:40 2002
From: paulocardoso at netvisao.pt (Paulo Cardoso)
Date: Thu, 11 Apr 2002 01:45:40 +0100
Subject: [R] Newsgroup
References: <Pine.A41.4.44.0204101322310.67164-100000@homer10.u.washington.edu>
Message-ID: <006001c1e0f2$344180a0$c80f81d9@mshome.net>

Use of something like keywords in the subject defining the content of email,
should be sufficient to allow filtering of messages.

----- Original Message -----
From: "Thomas Lumley" <tlumley at u.washington.edu>
To: <ggrothendieck at yifan.net>
Cc: "Renaud Lancelot" <lancelot at sentoo.sn>; <r-help at stat.math.ethz.ch>;
<pauljohn at ukans.edu>
Sent: Wednesday, April 10, 2002 9:31 PM
Subject: Re: [R] Newsgroup


> On Wed, 10 Apr 2002 ggrothendieck at yifan.net wrote:
>
> > Good idea.
> >
> > One other benefit of this is that if one later wanted to
> > search the list archives one could find a summary of the
> > issue of interest in a single message instead of wading through
> > multiple posts.
>
> I actually disagree (strongly, about reply-to-sender and weakly about
> newsgroup).
>
> The last time this was discussed it was pointed out that there really
> aren't enough of us for a newgroup (not much over 1000), and that
> newsgroups tend to attract quite a bit more spam. Its fairly easy to
> filter r-help into a separate mail folder and some mail readers (and the
> mailing list archive) can even given you a threaded version. However, a
> newsgroup might be useful.
>
> Reply-to-sender, OTOH, i think is a really bad idea.  In the first place
> it removes the discussion of answers -- some really are better than
> others.  In addition, you can't tell which questions have been
> answered already, so questions are more likely to fall through the cracks.
>
> -thomas
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Thu Apr 11 03:55:42 2002
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 10 Apr 2002 21:55:42 -0400
Subject: [R] Principal Component analysis question
In-Reply-To: <3CB4C01F.10901@yahoo.ca>
Message-ID: <5.1.0.14.2.20020410215136.01d56070@pop>

Dear Damien,

Principal components are identified up to a reflection through the origin, 
so the solutions are really all equivalent -- corresponding components are 
the same, except for a possible change in sign.

John

At 05:43 PM 4/10/2002 -0500, you wrote:
>I have a question about princomp(mva) that I hope isn't too newbie.
>
>I used the sample data from Table 1.1 in "Manly (1986/1994) Multivariate 
>Statistical Methods: a primer. Chapman and Hall" on sparrow body measurements.
>
>I rescaled the data to mean 0 and SD 1, and the covariance matrix is:
>
>           V1        V2        V3        V4        V5
>V1 1.0000000 0.7349642 0.6618119 0.6452841 0.6051247
>V2 0.7349642 1.0000000 0.6737411 0.7685087 0.5290138
>V3 0.6618119 0.6737411 1.0000000 0.7631899 0.5262701
>V4 0.6452841 0.7685087 0.7631899 1.0000000 0.6066493
>V5 0.6051247 0.5290138 0.5262701 0.6066493 1.0000000
>
>Now when I call princomp [fun<-princomp(~V1+V2+V3+V4+V5)], I get the 
>following loadings:
>
>        Comp.1      Comp.2     Comp.3      Comp.4     Comp.5
>V1 -0.4517989 -0.05072137  0.6904702  0.42041399 -0.3739091
>V2 -0.4616809  0.29956355  0.3405484 -0.54786307  0.5300805
>V3 -0.4505416  0.32457242 -0.4544927  0.60629605  0.3427923
>V4 -0.4707389  0.18468403 -0.4109350 -0.38827811 -0.6516665
>V5 -0.3976754 -0.87648935 -0.1784558 -0.06887199  0.1924341
>
>However, this is in contrast to the results in Manly's book:
>
>       Comp.1      Comp.2     Comp.3      Comp.4     Comp.5
>V1 0.4517989 -0.05072137  0.6904702 -0.42041399  0.3739091
>V2 0.4616809  0.29956355  0.3405484  0.54786307 -0.5300805
>V3 0.4505416  0.32457242 -0.4544927 -0.60629605 -0.3427923
>V4 0.4707389  0.18468403 -0.4109350  0.38827811  0.6516665
>V5 0.3976754 -0.87648935 -0.1784558  0.06887199 -0.1924341
>
>Interestingly, when I do the same in SAS, I get:
>
>        Comp.1      Comp.2     Comp.3      Comp.4     Comp.5
>V1  0.4517989  0.05072137 -0.6904702  0.42041399 -0.3739091
>V2  0.4616809 -0.29956355 -0.3405484 -0.54786307  0.5300805
>V3  0.4505416 -0.32457242  0.4544927  0.60629605  0.3427923
>V4  0.4707389 -0.18468403  0.4109350 -0.38827811 -0.6516665
>V5  0.3976754  0.87648935  0.1784558 -0.06887199  0.1924341
>
>Finally, when I do it by "hand" in R (i.e., c<-cov(data); e<-eigen(c)), I 
>get a fourth answer:
>
>           V5          V4         V3          V2         V1
>V1 0.4517989  0.05072137 -0.6904702 -0.42041399 -0.3739091
>V2 0.4616809 -0.29956355 -0.3405484  0.54786307  0.5300805
>V3 0.4505416 -0.32457242  0.4544927 -0.60629605  0.3427923
>V4 0.4707389 -0.18468403  0.4109350  0.38827811 -0.6516665
>V5 0.3976754  0.87648935  0.1784558  0.06887199  0.1924341
>
>
>Can anyone point me in the right direction here?  I can email the raw data 
>to anyone if that would help.
>
>Thank you in advance...
>
>Damien




-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From scottrsm at mindspring.com  Thu Apr 11 06:07:48 2002
From: scottrsm at mindspring.com (R. Scott McIntire)
Date: Thu, 11 Apr 2002 00:07:48 -0400
Subject: [R] Help installing from Rpm
Message-ID: <B8DA8454.8391%scottrsm@mindspring.com>

All,

I'm trying to install R-base on RedHat Linux 7.2.
Rpm complains that libreadline.4.1.so is needed; the problem is that I have
libreadline4.2.so.
What can I do to get around this?

-Scott 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gonin at genethon.fr  Thu Apr 11 08:11:13 2002
From: gonin at genethon.fr (Patrick Gonin)
Date: Thu, 11 Apr 2002 08:11:13 +0200
Subject: [R] Newsgroup
In-Reply-To: <3CB43727.5811.C3CB84@localhost>
References: <3CB43727.5811.C3CB84@localhost>
Message-ID: <a05100302b8dad7d26d0d@[192.168.100.154]>

Hi,

I use a mail threading utility (thanks to :"[R]", which is in the 
header of almost all messages), so that I don't see R messages in my 
inbox: they are directly dropped in another one.
I think reply-to-sender would render the list useless, because now, I 
read about other people's problems and I learn a lot this way.
I might also say that I subscribed to other lists and did the same: 
everything is fine.

Cheers,

>This morning I had 37 messages from the r-help list in my mailbox.
>I think its becoming excessive for an e-mail list.
>
>I wonder if whoever looks after this list could either move or gateway
>it to a usenet group?
>
>That would also eliminate the need for special purpose archiving and
>searching facilities since the site:
>
>http://groups.google.com
>
>would automatically provide that. That site also allows one to both read
>and post via the web (with a delay of several hours) in case one does not
>care to use newsgroup software.
>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-- 
----------------------------
Patrick Gonin, DVM, PhD
Head of in vivo Evaluation Dept
G?n?thon
1 bis, rue de l'Internationale- BP 60
91002 EVRY CEDEX
FRANCE
Tel: 33-1-69-47-10-21
Fax: 33-1-60-77-86-98
gonin at genethon.fr
----------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From LindnerW at t-online.de  Thu Apr 11 08:42:36 2002
From: LindnerW at t-online.de (Wolfgang Lindner)
Date: Thu, 11 Apr 2002 08:42:36 +0200
Subject: [R] Newsgroup
Message-ID: <16vYI0-19SEwiC@fwd08.sul.t-online.com>

Dear R-Group,

let me tell you, that I am very content, that the R-group is so busy:

- I have learnt many insights to R-handling and/or programming this way, the 
  group works for me like an livley wunderful online tutorial

- I found it interesting to watch the discussions (silently), because one has 
  sometimes similar problems..

So I see no problem with the current system: because one has a "[R]" mark in the 
subject field of the message, one can delete unwanted messages directly on the 
server.

Best whishes for this active group,

Wolfgang Lindner

--
OStR Wolfgang Lindner                     Tel  : +49 (0203) 379-1326
Gerhard-Mercator-Universit?t Duisburg     Fax  : +49 (0203) 379-2528
Fakult?t 4 - Naturwissenschaften          eMail: Lindner at math.uni-duisburg.de
Institut fuer Mathematik, LE 424
Lotharstr. 65
D 47048  Duisburg (Germany)

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From s-thapa-11 at alumni.uchicago.edu  Thu Apr 11 09:42:24 2002
From: s-thapa-11 at alumni.uchicago.edu (Suchandra Thapa)
Date: Thu, 11 Apr 2002 02:42:24 -0500
Subject: [R] Help installing from Rpm
In-Reply-To: <B8DA8454.8391%scottrsm@mindspring.com>; from scottrsm@mindspring.com on Thu, Apr 11, 2002 at 12:07:48AM -0400
References: <B8DA8454.8391%scottrsm@mindspring.com>
Message-ID: <20020411024224.E828@hepcat>

On Thu, Apr 11, 2002 at 12:07:48AM -0400, R. Scott McIntire wrote:
> I'm trying to install R-base on RedHat Linux 7.2.
> Rpm complains that libreadline.4.1.so is needed; the problem is that I have
> libreadline4.2.so.
> What can I do to get around this?

    I have R-1.4.1 rpms that have been compiled on a redhat 7.2 system
and should install without problems that I can let you have.  However,
I compiled it using the 3.0.4 version of gcc and g77 so you'll need to 
install the runtime libraries for gcc 3.0.4.  They're a part of 
the redhat updates so you can download them from http://www.redhat.com/errata
or any suitable mirror. Oh yes, I've compiled R with pentium specific 
optimizations so you'll need a pentium or better to run it.

-- 
------------------------------------------------------------------

Suchandra S. Thapa 
s-thapa-11 at alumni.uchicago.edu

------------------------------------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Apr 11 10:10:50 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 11 Apr 2002 10:10:50 +0200
Subject: [R] Help installing from Rpm
In-Reply-To: <B8DA8454.8391%scottrsm@mindspring.com>
References: <B8DA8454.8391%scottrsm@mindspring.com>
Message-ID: <x24riilkol.fsf@blueberry.kubism.ku.dk>

"R. Scott McIntire" <scottrsm at mindspring.com> writes:

> All,
> 
> I'm trying to install R-base on RedHat Linux 7.2.
> Rpm complains that libreadline.4.1.so is needed; the problem is that I have
> libreadline4.2.so.
> What can I do to get around this?

Install RedHat's compatibility RPM from CD #2:

readline41-4.1-10.i386.rpm

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rhskelto at atm.ox.ac.uk  Thu Apr 11 10:18:01 2002
From: rhskelto at atm.ox.ac.uk (Randall Skelton)
Date: Thu, 11 Apr 2002 09:18:01 +0100 (BST)
Subject: [R] unsusbscribe
Message-ID: <Pine.LNX.4.33.0204110917390.28227-100000@mulligan.atm.ox.ac.uk>

unsusbscribe

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From garbade at psy.uni-muenchen.de  Thu Apr 11 13:34:42 2002
From: garbade at psy.uni-muenchen.de (Sven Garbade)
Date: Thu, 11 Apr 2002 11:34:42 +0000
Subject: [R] Help installing from Rpm
References: <B8DA8454.8391%scottrsm@mindspring.com>
Message-ID: <3CB574D2.CACBB9C9@psy.uni-muenchen.de>

"R. Scott McIntire" wrote:

> All,
>
> I'm trying to install R-base on RedHat Linux 7.2.
> Rpm complains that libreadline.4.1.so is needed; the problem is that I have
> libreadline4.2.so.
> What can I do to get around this?

Maybe as a workaround, link libreadline.4.1.so to libreadline4.2.so:

ln -s /lib/libreadline4.2.so /lib/libreadline.4.1.so

if libreadline is in /lib. BTW, on Debian they are called /lib/libreadline.so.4
and /lib/libreadline.so.4.2 and not libreadline.4.1.so or libreadline4.2.so (but I
think this is a spelling mistake).
              ^^                        ^
By, Sven

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ernesto at ipimar.pt  Thu Apr 11 11:51:12 2002
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 11 Apr 2002 10:51:12 +0100
Subject: [R] problem with do.call
In-Reply-To: 
	<Pine.A41.4.44.0204100937010.103838-100000@homer25.u.washington.edu>
References: 
	<Pine.A41.4.44.0204100937010.103838-100000@homer25.u.washington.edu>
Message-ID: <1018518672.17310.10.camel@gandalf>

Hi

This was not my understanding. I thougth that if you can use functions
like apply and similar instead of for loops your code will be faster.
Basicly relying on these functions code which is (should be) optimized
for speed.

If what you're saying is true then using functions like apply is a
matter of simplicity and not speeding up the code. 

Is this correct ?

Thanks

EJ

On Wed, 2002-04-10 at 17:41, Thomas Lumley wrote:
> On 10 Apr 2002, Ernesto Jardim wrote:
> >
> > define "vectorize function"
> >
> 
> Many R functions can operate on a vector of parameter values, eg
> 
> log(10,c(2,e,10)) gives the log of 10 to base 2, e, and 10
> 
> If your function can do this, you can construct a set of vectors
> containing all your parameter values (expand.grid() is useful for this)
> and evaluate your function once.
> 
> This can be faster than for() loops when much of the iteration is done in
> compiled code.  If the iteration has to be done in interpreted code then
> you can't really speed up the for() loops.  You can hide the loops with
> the apply() functions, which may make your code more readable, but it
> won't typically speed it up.
> 
> 
> 	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ernesto at ipimar.pt  Thu Apr 11 12:11:45 2002
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 11 Apr 2002 11:11:45 +0100
Subject: [R] Newsgroup
In-Reply-To: <3CB43727.5811.C3CB84@localhost>
References: <3CB43727.5811.C3CB84@localhost>
Message-ID: <1018519905.17309.18.camel@gandalf>

Hi

I've subscribed the R mailing list a long time a go and I'm quite happy
that it has so much volume. I've learned a lot reading messages.

For people with slow conections there is the diggest and the mail
filters.

The newsgroups are annoying and more difficult to use. If you want to
take a quick look to most of the messages, it will take even more time
then downloading the mail into your machine.

And there's allways the problem of spam and publicity.

If it gets completely out of control, which I think it will not, there's
allways the chance of spliting the mailing list, as someone posted.

Regards

EJ

ps: During 1997-1999 I was on the snews list and it was very difficult
to get help in more specific problems. I never had that problem in [R].

On Wed, 2002-04-10 at 17:59, ggrothendieck at yifan.net wrote:
> 
> This morning I had 37 messages from the r-help list in my mailbox.
> I think its becoming excessive for an e-mail list.
> 
> I wonder if whoever looks after this list could either move or gateway
> it to a usenet group?
> 
> That would also eliminate the need for special purpose archiving and
> searching facilities since the site: 
> 
> http://groups.google.com 
> 
> would automatically provide that. That site also allows one to both read 
> and post via the web (with a delay of several hours) in case one does not
> care to use newsgroup software.
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mark at myatt.demon.co.uk  Thu Apr 11 11:42:02 2002
From: mark at myatt.demon.co.uk (Mark Myatt)
Date: Thu, 11 Apr 2002 10:42:02 +0100
Subject: [R] Newsgroup
In-Reply-To: <1018477734.11413.14.camel@keittlab-6>
References: <3CB43727.5811.C3CB84@localhost> <3CB478BE.9FC18DA3@sentoo.sn>
 <1018477734.11413.14.camel@keittlab-6>
Message-ID: <BpC4yKAqpVt8EwSF@myatt.demon.co.uk>

Timothy H. Keitt <tklistaddr at keittlab.bio.sunysb.edu> writes:

>The reply-to-list is quite useful IMHO. The real solution is to filter
>your list email into separate folders. Its quite easy with procmail,
>although I currently use evolutions filters (and a seperate email
>address for lists).

I'd just like to put in my tuppence in this one ... some lists like
STAT-L are implemented as both mailing lists and Usenet groups. I do
prefer the Usenet format as newsreaders thread the messages making it
easier to follow discussions than in the flat mailing list. I think that
threaded groups allow for a better discussion.

One downside is that Usenet servers are regularly scanned by
organisations that compile address lists for spammers (or for their own
spam) and the release from 30+ e-mails about R (some of which you may be
interested in) can quickly become a deluge of adverts for pornography,
get-rich-quick schemes, baldness cures, and (just recently) anti-Semitic
polemic.

Just my tuppence,

Mark

--
Mark Myatt


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kari.ruohonen at saunalahti.fi  Thu Apr 11 13:05:43 2002
From: kari.ruohonen at saunalahti.fi (Kari Ruohonen)
Date: Thu, 11 Apr 2002 14:05:43 +0300 (EEST)
Subject: [R] Newsgroup
In-Reply-To: <BpC4yKAqpVt8EwSF@myatt.demon.co.uk>
Message-ID: <Pine.LNX.4.44.0204111403530.12135-100000@localhost>

Just a small thing to add to the discussion and it is the fact that
everybody has not an access to a new server but everyone has an email.

Kari

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From o.christensen at lancaster.ac.uk  Thu Apr 11 13:12:29 2002
From: o.christensen at lancaster.ac.uk (Ole Christensen)
Date: Thu, 11 Apr 2002 12:12:29 +0100
Subject: [R] Re: new acf package
References: <Pine.LNX.4.33.0204111049500.30461-100000@chim252.unife.it>
Message-ID: <3CB56F9D.4CE18F7E@lancs.ac.uk>

Dear Nicola

Your mail seems to have gone wrong - it went to R-announce instead of
R-help.

In the third issue of R-news (see http://cran.r-project.org/doc/Rnews)
there a nice article by Roger Bivand on spatial data analysis using R.
See also the second issue of R-news, the article by Ripley and the
presentation of package geoR.

Use a function to calculte the empirical variogram (for instance
function variog in package geoR). Using the empirical variogram is more
stable than using the empirical covariance function.

Cheers Ole

nicola marchetti wrote:
> 
> I'm a PhD student and I'm working with covariance function. I'm interested
> to know if exist some packages in R to calculate and plot the
> bidimensional Autocovariance Function. the input matrix is a matrix that
> describe a spatial location over a 2-D space and I want to use it in the
> same way I can use a time serie in the 1-D acf.
> Thanks,
> Nicola.
> 
> =================================================================
> Dr. Nicola Marchetti                    Phone: +39 0532 291331
> Chemistry Department                      Fax: +39 0532 240709
> University of Ferrara
> Luigi Borsari, 46
> I-44100 Ferrara
> ITALY
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-announce mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-announce-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
Ole F. Christensen
Department of Mathematics and Statistics
Fylde College, Lancaster University 
Lancaster, LA1 4YF, England
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From arv at ono.com  Thu Apr 11 13:39:16 2002
From: arv at ono.com (arv@ono.com)
Date: Thu, 11 Apr 2002 13:39:16 +0200
Subject: [R] RE: new acf package
Message-ID: <3001cd30305a.30305a3001cd@ono.com>

Hi,


I think the functions: correlogram and variogram in package 'spatial' 
could do the task

Antonio
----- Mensaje Original -----
Remitente: nicola marchetti <nicola at chim252.unife.it>
Fecha: Jueves, Abril 11, 2002 11:09 am
Asunto: new acf package

> 
> I'm a PhD student and I'm working with covariance function. I'm 
> interestedto know if exist some packages in R to calculate and 
> plot the
> bidimensional Autocovariance Function. the input matrix is a 
> matrix that
> describe a spatial location over a 2-D space and I want to use it 
> in the
> same way I can use a time serie in the 1-D acf.
> Thanks,
> Nicola.
> 
> 
> 
> =================================================================
> Dr. Nicola Marchetti                    Phone: +39 0532 291331
> Chemistry Department                      Fax: +39 0532 240709
> University of Ferrara
> Luigi Borsari, 46
> I-44100 Ferrara
> ITALY
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> .-.-.-.-.-.-
> r-announce mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-announce-
> 
request at stat.math.ethz.ch_._._._._._._._._._._._._._._._._._._._._._._._
._._._._._._._._._._._._._._._._
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From alobo at ija.csic.es  Thu Apr 11 14:35:02 2002
From: alobo at ija.csic.es (Agustin Lobo)
Date: Thu, 11 Apr 2002 14:35:02 +0200 (MET DST)
Subject: [R] graphics in batch mode
Message-ID: <Pine.OSF.3.96.1020411142126.16084B-100000@ija.csic.es>


Hi!

The R-intro guide states that:
"The graphics facilities can be used in both interactive and batch
modes,.."

but I'm trying both

R BATCH commands.file
and
R --no-save < commands.file

and, although I get no errors and
the output file with the results is
written to disk, I get no graphics.
(I want the R function to leave
results in a file that a shell script
reads and use, and to draw a graphic).

Am I missing another option in the command line?

Thanks

Dr. Agustin Lobo
Instituto de Ciencias de la Tierra (CSIC)
Lluis Sole Sabaris s/n
08028 Barcelona SPAIN
tel 34 93409 5410
fax 34 93411 0012
alobo at ija.csic.es


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wackernagel at cg.ensmp.fr  Thu Apr 11 13:44:17 2002
From: wackernagel at cg.ensmp.fr (wackernagel@cg.ensmp.fr)
Date: Thu, 11 Apr 2002 13:44:17 +0200 (MET DST)
Subject: [R] new acf package
In-Reply-To: <Pine.LNX.4.33.0204111049500.30461-100000@chim252.unife.it>
References: <Pine.LNX.4.33.0204111049500.30461-100000@chim252.unife.it>
Message-ID: <15541.29914.442596.768725@rhea>

You should better use a variogram for this: have a look at the package 
"spatial" which by the way also contains a function "correlogram",
which is what you asked for.

You have also the variogram in the package "sgeostat".

Hans

nicola marchetti writes:
 > 
 > I'm a PhD student and I'm working with covariance function. I'm interested
 > to know if exist some packages in R to calculate and plot the
 > bidimensional Autocovariance Function. the input matrix is a matrix that
 > describe a spatial location over a 2-D space and I want to use it in the
 > same way I can use a time serie in the 1-D acf.
 > Thanks,
 > Nicola.
 > 
 > 
 > 
 > =================================================================
 > Dr. Nicola Marchetti                    Phone: +39 0532 291331
 > Chemistry Department                      Fax: +39 0532 240709
 > University of Ferrara
 > Luigi Borsari, 46
 > I-44100 Ferrara
 > ITALY
 > 

-- 

Hans Wackernagel

___________________________________________________ 
Centre de G?ostatistique    35,  rue  Saint  Honor? 
Ecole des Mines de Paris    F - 77305 Fontainebleau 
Phone: +33-1.64.69.47.60    Fax:  +33-1.64.69.47.05 
http://cg.ensmp.fr/~hans    wackernagel at cg.ensmp.fr 
___________________________________________________

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lutz.thieme at amd.com  Thu Apr 11 15:17:30 2002
From: lutz.thieme at amd.com (lutz.thieme@amd.com)
Date: Thu, 11 Apr 2002 15:17:30 +0200
Subject: [R] "CTRL-C" and "try"
Message-ID: <E540DF203FFED21182EB0008C72875600AEDA6F3@deexmta4.amd.com>

Hello everybody,

if I'm running a R-script on a command line R-session which uses the function "try" and I'd like
to interrupt the execution of my R-script pressing "CTRL-C" than R ignores the first "CTRL-C"
key stroke and after I pressed "CTRL-C" second time R by itself is interrupted and I fall back 
to the (UNIX-) command prompt. Without using "try" all works fine and I'm able to interrupt my
R-script. How can I avoid this behavior?

platform sparc-sun-solaris2.8
arch     sparc               
os       solaris2.8          
system   sparc, solaris2.8   
status                       
major    1                   
minor    3.0                 
year     2001                
month    06                  
day      22                  
language R  

Thanks in advance - regards,

Lutz

Lutz Thieme
AMD Saxony Manfacturing GmbH
Product Engineering
phone:	+49 351 277-4269
fax:	+49 351 277-9-4269
email:	lutz.thieme at amd.com


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From murdoch at stats.uwo.ca  Thu Apr 11 15:22:24 2002
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 11 Apr 2002 09:22:24 -0400
Subject: [R] Newsgroup
Message-ID: <4k2bbu8e9vmkmrnk0ggi5aqpqfriaek0nk@4ax.com>

I agree that a newsgroup gateway would be a good idea.  I volunteer to
help whoever wants to set one up.  If nobody volunteers to head the
project, then I'll put it on my list of things to do myself, but it's
unlikely to happen before my sabbatical in 2004 if it's on that list.

I think the mailing list is fine for people who read mail on a machine
with an SMTP server on it, i.e. most of the *nix people.  However, for
people picking up mail from a POP server (i.e. most of the Windows
people), each message can take several *seconds* of download time.
Having 50 messages in your inbox makes the mail pickup excruciatingly
slow, and prone to failure due to timeouts when the network is busy.

Since I use a POP server I found that the digests are the only
reasonable way to read the list.  But the digests have their own
problems:

 - You can't reply to them, replies go to the wrong address.  (I don't
know if setting "Reply-to" to the r-help address would be a good idea.
Probably not.)  For replies like this one I have to write a new
message to r-help.  If I make a typo in the header, then my message
won't show up in the same thread as the others.

It's also hard to quote previous messages:  you can easily quote the
entire digest, but then you have to edit out all the other messages.

 - They aren't organized by thread, they're in serial order.

 - They arrive once a day, later than the original messages, so
responses like this one aren't timely.

I believe some software can automatically burst digests into
individual messages, which would help with some of these problems.  In
fact, the program I use (Agent) can do it, but the r-help digests
aren't in a format it understands.  I don't know if that's because
it's buggy, because r-help is in an unusual format, or because Agent
only supports some weird formats, but it means I can't do the
bursting.

Newsgroups also have the advantage of maintaining several days of
messages on the central server, with easy retrieval.  If I see a reply
to a message that looks interesting, I often want to read the
original:  but that is hard to find in old digests, and I've likely
deleted it anyway.

Duncan Murdoch
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Torsten.Hothorn at rzmail.uni-erlangen.de  Thu Apr 11 15:19:31 2002
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Thu, 11 Apr 2002 15:19:31 +0200 (MEST)
Subject: [R] graphics in batch mode
In-Reply-To: <Pine.OSF.3.96.1020411142126.16084B-100000@ija.csic.es>
Message-ID: <Pine.LNX.4.21.0204111519040.27517-100000@artemis.imbe.med.uni-erlangen.de>

> Hi!
> 
> The R-intro guide states that:
> "The graphics facilities can be used in both interactive and batch
> modes,.."
> 
> but I'm trying both
> 
> R BATCH commands.file
> and
> R --no-save < commands.file

have a look at the `Rplots.ps' file in the working directory

Torsten

> 
> and, although I get no errors and
> the output file with the results is
> written to disk, I get no graphics.
> (I want the R function to leave
> results in a file that a shell script
> reads and use, and to draw a graphic).
> 
> Am I missing another option in the command line?
> 
> Thanks
> 
> Dr. Agustin Lobo
> Instituto de Ciencias de la Tierra (CSIC)
> Lluis Sole Sabaris s/n
> 08028 Barcelona SPAIN
> tel 34 93409 5410
> fax 34 93411 0012
> alobo at ija.csic.es
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pflugshaupt at geobot.umnw.ethz.ch  Thu Apr 11 15:31:42 2002
From: pflugshaupt at geobot.umnw.ethz.ch (Kaspar Pflugshaupt)
Date: Thu, 11 Apr 2002 15:31:42 +0200
Subject: [R] graphics in batch mode
In-Reply-To: <Pine.OSF.3.96.1020411142126.16084B-100000@ija.csic.es>
Message-ID: <B8DB5CDE.81FE%pflugshaupt@geobot.umnw.ethz.ch>

On 11.4.2002 14:35 Uhr, Agustin Lobo wrote:

> The R-intro guide states that:
> "The graphics facilities can be used in both interactive and batch
> modes,.."
> 
> but I'm trying both
> 
> R BATCH commands.file
> and
> R --no-save < commands.file
> 
> and, although I get no errors and
> the output file with the results is
> written to disk, I get no graphics.
> (I want the R function to leave
> results in a file that a shell script
> reads and use, and to draw a graphic).

What kind of graphics file did you try to write? For me, postscript() or
pdf() work fine in any situation.

[trying to remember past issues on this list]

Some other graphics drivers depend on Xwindows to work and, for some
reasons, don't work from a batch file. I believe that the driver bitmap()
will work in any case, have a look at that.

[trying the "obvious"]

You did close the graphics device after plotting, didn't you?  :-)


HTH

Kaspar Pflugshaupt

-- 

Kaspar Pflugshaupt
Geobotanisches Institut
Zuerichbergstr. 38
CH-8044 Zuerich

Tel. ++41 1 632 43 19
Fax  ++41 1 632 12 15

mailto:pflugshaupt at geobot.umnw.ethz.ch
privat:pflugshaupt at mails.ch
http://www.geobot.umnw.ethz.ch

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jrgonzalez at ico.scs.es  Thu Apr 11 15:42:42 2002
From: jrgonzalez at ico.scs.es (Juan Ramon Gonzalez)
Date: Thu, 11 Apr 2002 15:42:42 +0200
Subject: [R] extract week from date
Message-ID: <006101c1e15e$c2bc99c0$1100a8c0@ico.scs.es>

Hello R-users,

Does anyone know how obtain the week of a date?  
(in SPPS the instruction is "xdate.week")

Thanks,

Juan Ramon

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From alobo at ija.csic.es  Thu Apr 11 16:03:56 2002
From: alobo at ija.csic.es (Agustin Lobo)
Date: Thu, 11 Apr 2002 16:03:56 +0200 (MET DST)
Subject: [R] graphics in batch mode
In-Reply-To: <Pine.LNX.4.21.0204111519040.27517-100000@artemis.imbe.med.uni-erlangen.de>
Message-ID: <Pine.OSF.3.96.1020411154001.16084F-100000@ija.csic.es>

Thanks, yes, the Rplots.ps is a like
a gift in the working directory. And 
using xv -rotate -90 Rplots.ps in the 
script is enough. 

Solved!

Agus

Dr. Agustin Lobo
Instituto de Ciencias de la Tierra (CSIC)
Lluis Sole Sabaris s/n
08028 Barcelona SPAIN
tel 34 93409 5410
fax 34 93411 0012
alobo at ija.csic.es


On Thu, 11 Apr 2002, Torsten Hothorn wrote:

> > Hi!
> > 
> > The R-intro guide states that:
> > "The graphics facilities can be used in both interactive and batch
> > modes,.."
> > 
> > but I'm trying both
> > 
> > R BATCH commands.file
> > and
> > R --no-save < commands.file
> 
> have a look at the `Rplots.ps' file in the working directory
> 
> Torsten
> 
> > 
> > and, although I get no errors and
> > the output file with the results is
> > written to disk, I get no graphics.
> > (I want the R function to leave
> > results in a file that a shell script
> > reads and use, and to draw a graphic).
> > 
> > Am I missing another option in the command line?
> > 
> > Thanks
> > 
> > Dr. Agustin Lobo
> > Instituto de Ciencias de la Tierra (CSIC)
> > Lluis Sole Sabaris s/n
> > 08028 Barcelona SPAIN
> > tel 34 93409 5410
> > fax 34 93411 0012
> > alobo at ija.csic.es
> > 
> > 
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> > 
> 
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Thu Apr 11 15:59:44 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 11 Apr 2002 09:59:44 -0400
Subject: [R] time (or output of function) in the R prompt
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC1EB@usrymx10.merck.com>

Dear R-help,

Would it be possible to have the "prompt" option accept a function, such as
date()?  This way, I can easily deduce the elapse time of top level R
expressions.  This would be similar to how Unix shells handle their prompt
variables.

Cheers,
Andy


------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From luke at stat.umn.edu  Thu Apr 11 16:12:53 2002
From: luke at stat.umn.edu (Luke Tierney)
Date: Thu, 11 Apr 2002 09:12:53 -0500
Subject: [R] "CTRL-C" and "try"
In-Reply-To: <E540DF203FFED21182EB0008C72875600AEDA6F3@deexmta4.amd.com>; from lutz.thieme@amd.com on Thu, Apr 11, 2002 at 03:17:30PM +0200
References: <E540DF203FFED21182EB0008C72875600AEDA6F3@deexmta4.amd.com>
Message-ID: <20020411091253.A31918@nokomis.stat.umn.edu>

The first one is probably not being ignored but is being caught by the
`try'.  This is the way `try' and C-c currently interact--it is not
clear this is the right thing to do or that this will remain true.
One of the things in the works is a more structured exception handling
system that will allow the interaction of try, C-c, and other
non-local exits to be specified more clearly.

I suspect you are using C-c again before R has a chance to get back to
the top level command loop.  I believe solaris is one of those systems
where signal handlers need to be re-installed after a signal is
received.  We currently do this at the top level loop but not at the
point where a `try' intercepts a jump out of a C-c.  As a result the
default signal handler is in place for the period between the first
C-c and return to the top level loop, and the default handler exits
when a C-c is received.  [I'm speculating a bit here since I don't
have easy access to a solaris system, but you should be able to
confirm it by running

{ try(repeat{}); cat("got through try\n"); repeat{}}

at the command line.  The first C-c should take you out of the `try'.
On my Linux system a second C-c takes me to the command line but on
your it probably exits R.]

luke

On Thu, Apr 11, 2002 at 03:17:30PM +0200, lutz.thieme at amd.com wrote:
> Hello everybody,
> 
> if I'm running a R-script on a command line R-session which uses the function "try" and I'd like
> to interrupt the execution of my R-script pressing "CTRL-C" than R ignores the first "CTRL-C"
> key stroke and after I pressed "CTRL-C" second time R by itself is interrupted and I fall back 
> to the (UNIX-) command prompt. Without using "try" all works fine and I'm able to interrupt my
> R-script. How can I avoid this behavior?
> 
> platform sparc-sun-solaris2.8
> arch     sparc               
> os       solaris2.8          
> system   sparc, solaris2.8   
> status                       
> major    1                   
> minor    3.0                 
> year     2001                
> month    06                  
> day      22                  
> language R  
> 
> Thanks in advance - regards,
> 
> Lutz
> 
> Lutz Thieme
> AMD Saxony Manfacturing GmbH
> Product Engineering
> phone:	+49 351 277-4269
> fax:	+49 351 277-9-4269
> email:	lutz.thieme at amd.com
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
Luke Tierney
University of Minnesota                      Phone:           612-625-7843
School of Statistics                         Fax:             612-624-8868
313 Ford Hall, 224 Church St. S.E.           email:      luke at stat.umn.edu
Minneapolis, MN 55455 USA                    WWW:  http://www.stat.umn.edu
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at blindglobe.net  Thu Apr 11 16:29:45 2002
From: rossini at blindglobe.net (A.J. Rossini)
Date: 11 Apr 2002 07:29:45 -0700
Subject: [R] Newsgroup
In-Reply-To: <4k2bbu8e9vmkmrnk0ggi5aqpqfriaek0nk@4ax.com>
References: <4k2bbu8e9vmkmrnk0ggi5aqpqfriaek0nk@4ax.com>
Message-ID: <87662yxq92.fsf@jeeves.blindglobe.net>

>>>>> "duncan" == Duncan Murdoch <murdoch at stats.uwo.ca> writes:


    duncan> Newsgroups also have the advantage of maintaining several
    duncan> days of messages on the central server, with easy
    duncan> retrieval.  If I see a reply to a message that looks
    duncan> interesting, I often want to read the original: but that
    duncan> is hard to find in old digests, and I've likely deleted it
    duncan> anyway.

Depends on whose news server/spool.  The ones I use expire after 48
hours, sigh...

Note that modern email packages (actually, it's been doing it for
many, many years) can present email in the same manner/scope as news.

The package is Emacs/Gnus, and while it's a PITA to set up, it does
everything else for you.

(including such useless features as presenting AltaVista queries as a
newsgroup, etc, etc...).

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M-W: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my friday location is usually completely unpredictable.)


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From garbade at psy.uni-muenchen.de  Thu Apr 11 19:33:31 2002
From: garbade at psy.uni-muenchen.de (Sven Garbade)
Date: Thu, 11 Apr 2002 17:33:31 +0000
Subject: [R] graphics in batch mode
References: <Pine.OSF.3.96.1020411142126.16084B-100000@ija.csic.es>
Message-ID: <3CB5C8EB.147785C3@psy.uni-muenchen.de>

Agustin Lobo wrote:

> Hi!
>
> The R-intro guide states that:
> "The graphics facilities can be used in both interactive and batch
> modes,.."
>
> but I'm trying both
>
> R BATCH commands.file
> and
> R --no-save < commands.file
>
> and, although I get no errors and
> the output file with the results is
> written to disk, I get no graphics.
> (I want the R function to leave
> results in a file that a shell script
> reads and use, and to draw a graphic).
>
> Am I missing another option in the command line?

It works for me. Maybe you have missed to open a device?
Example:

postscript(file="fig1.ps")
plot(1:10)
dev.off()
postscript(file="fig2.ps")
plot(11:20)
dev.off()

draws two graphics in ps files. I think you can use other devices as well.

By, Sven


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From apjaworski at mmm.com  Thu Apr 11 17:08:12 2002
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Thu, 11 Apr 2002 10:08:12 -0500
Subject: [R] extract week from date
Message-ID: <OF67601CDE.EBB2EEAA-ON86256B98.0052BBED@mmm.com>


I am not quite sure what the "week of a date" is, but here is my best
guess:

     > format(as.POSIXct("2002-04-11"), "%U")
     > 14

This returns a number between 0 and 53 representing the week-of-the-year.

Check the manpages for the date-related functions.

Andy

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


                                                                                                                                               
                    "Juan Ramon                                                                                                                
                    Gonzalez"            To:     r-help at stat.math.ethz.ch                                                                      
                    <jrgonzalez at ico      cc:     (bcc: Andrzej P. Jaworski/US-Corporate/3M/US)                                                 
                    .scs.es>             Subject:     [R] extract week from date                                                               
                                                                                                                                               
                    04/11/2002                                                                                                                 
                    08:42                                                                                                                      
                                                                                                                                               
                                                                                                                                               





Hello R-users,

Does anyone know how obtain the week of a date?
(in SPPS the instruction is "xdate.week")

Thanks,

Juan Ramon

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._._




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bojaniss at poczta.onet.pl  Thu Apr 11 17:13:49 2002
From: bojaniss at poczta.onet.pl (Michal Bojanowski)
Date: Thu, 11 Apr 2002 17:13:49 +0200
Subject: Odp: [R] graphics in batch mode
Message-ID: <002101c1e16b$7d6e1080$5a01a8c0@iss.local>



>
> Hi!
>
> The R-intro guide states that:
> "The graphics facilities can be used in both interactive and batch
> modes,.."
>
> but I'm trying both
>
> R BATCH commands.file
> and
> R --no-save < commands.file
>
> and, although I get no errors and
> the output file with the results is
> written to disk, I get no graphics.
> (I want the R function to leave
> results in a file that a shell script
> reads and use, and to draw a graphic).

As I understand it is possible to make plots an save them to a file with for
example dev.print(),
but no on-screen graphics device is opened. Like in:

hist(rnorm(100))
dev.print(png, file="foo.png", width=300, height=300)
dev.off()

>
> Am I missing another option in the command line?
>
> Thanks
>
> Dr. Agustin Lobo
> Instituto de Ciencias de la Tierra (CSIC)
> Lluis Sole Sabaris s/n
> 08028 Barcelona SPAIN
> tel 34 93409 5410
> fax 34 93411 0012
> alobo at ija.csic.es
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._




-- 
Encyklopedia multimedialna w prezencie!
http://www.e-mail.onet.pl


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pingping.zheng at lancaster.ac.uk  Thu Apr 11 17:18:20 2002
From: pingping.zheng at lancaster.ac.uk (Pingping Zheng)
Date: Thu, 11 Apr 2002 16:18:20 +0100
Subject: [R] extract week from date
References: <006101c1e15e$c2bc99c0$1100a8c0@ico.scs.es>
Message-ID: <3CB5A93C.1070004@lancs.ac.uk>

Juan Ramon Gonzalez wrote:

>Hello R-users,
>
>Does anyone know how obtain the week of a date?  
>(in SPPS the instruction is "xdate.week")
>
>Thanks,
>
>Juan Ramon
>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>
weekday<-format(x, "%w")
will change the date x into week as decimal number (0-6, Sunday is 0), or
week<-format(x, "%U%)
week of the year as decimal number (00-53) using the first Sunday as day 
1 of week 1, or
week<-format(x, "%W")
week of the year as decimal number (00-53) using the first Monday as day 
1 of week 1.

See help.start("strptime").

Pingping Zheng

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Thu Apr 11 17:27:22 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 11 Apr 2002 10:27:22 -0500
Subject: [R] problem with do.call
In-Reply-To: <1018518672.17310.10.camel@gandalf>
References: <Pine.A41.4.44.0204100937010.103838-100000@homer25.u.washington.edu>
	<1018518672.17310.10.camel@gandalf>
Message-ID: <6r7knedzmt.fsf@franz.stat.wisc.edu>

Ernesto Jardim <ernesto at ipimar.pt> writes:

> Hi
> 
> This was not my understanding. I thougth that if you can use functions
> like apply and similar instead of for loops your code will be faster.
> Basicly relying on these functions code which is (should be) optimized
> for speed.
> 
> If what you're saying is true then using functions like apply is a
> matter of simplicity and not speeding up the code. 
> 
> Is this correct ?

Yes.

If you examine the apply function you will see that the bulk of the
work is done in a loop

    if (length(d.call) < 2) {
        if (length(dn.call)) 
            dimnames(newX) <- c(dn.call, list(NULL))
        for (i in 1:d2) ans[[i]] <- FUN(newX[, i], ...)
    }
    else for (i in 1:d2) ans[[i]] <- FUN(array(newX[, i], d.call, 
        dn.call), ...)

In their book "S Programming" (Springer, 2000) Venables and Ripley
discuss general strategies for writing R functions and for making them
faster.  One general principle is to profile the code before
implementing changes.  The manual "Writing R Extensions" has a section
on "Profiling R code" which is highly recommended.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Thu Apr 11 17:42:54 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 11 Apr 2002 10:42:54 -0500
Subject: [R] extract week from date
In-Reply-To: <006101c1e15e$c2bc99c0$1100a8c0@ico.scs.es>
References: <006101c1e15e$c2bc99c0$1100a8c0@ico.scs.es>
Message-ID: <6r3cy2dywx.fsf@franz.stat.wisc.edu>

"Juan Ramon Gonzalez" <jrgonzalez at ico.scs.es> writes:

> Does anyone know how obtain the week of a date?  
> (in SPPS the instruction is "xdate.week")

If you convert a date to a POSIXlt class, say by using the strptime
function, you get a list with components


     `sec' 0-61: seconds

     `min' 0-59: minutes

     `hour' 0-23: hours

     `mday' 1-31: day of the month

     `mon' 0-11: months after the first of the year.

     `year' Years since 1900.

     `wday' 0-6 day of the week, starting on Sunday.

     `yday' 0-365: day of the year.

     `isdst' Daylight savings time flag. Positive if in force, zero if
          not, negative if unknown.

You should be able to compute the week of the year from yday. I think
it would be ceiling(dd$yday/7 + 0.5) but you should check this.

For example

> as.character(unique(cheese[,1]))
 [1] "5/4/99"  "5/5/99"  "5/7/99"  "5/11/99" "5/12/99" "5/14/99" "5/18/99"
 [8] "5/19/99" "5/21/99" "5/25/99" "5/27/99" "5/28/99" "8/3/99"  "8/4/99" 
[15] "8/6/99"  "8/10/99" "8/11/99" "8/12/99" "8/13/99" "8/17/99" "8/18/99"
[22] "8/19/99" "8/20/99" "8/24/99" "8/25/99" "8/27/99" "8/31/99"
> dd <- strptime(as.character(unique(cheese[,1])), format = '%m/%d/%y')
> ceiling(dd$yday/7)
 [1] 18 18 18 19 19 19 20 20 20 21 21 21 31 31 31 32 32 32 32 33 33 33 33 34 34
[26] 34 35
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From macq at llnl.gov  Thu Apr 11 18:02:38 2002
From: macq at llnl.gov (Don MacQueen)
Date: Thu, 11 Apr 2002 09:02:38 -0700
Subject: [R] Newsgroup
In-Reply-To: <4k2bbu8e9vmkmrnk0ggi5aqpqfriaek0nk@4ax.com>
References: <4k2bbu8e9vmkmrnk0ggi5aqpqfriaek0nk@4ax.com>
Message-ID: <p05101502b8db5e0e2a11@[128.115.153.6]>

Personally, I dislike the newsgroup approach. I dislike it a lot. 
Mostly because I find the software for reading newsgroups unpleasant 
to use.

My mail reader, which doesn't have any official threading feature, 
still makes it easy to group all the messages on any given subject 
together.

I certainly don't object to a group of people setting one up for 
r-help, as an option for those who prefer it.

-Don

-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
--------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From virgil at uv.es  Thu Apr 11 17:54:32 2002
From: virgil at uv.es (virgil@uv.es)
Date: Thu, 11 Apr 2002 17:54:32 +0200 (CEST)
Subject: [R] Re: Newsgroup
In-Reply-To: <200204110201.EAA26013@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.31.0204111752360.10244-100000@matheron.estadi.uv.es>

Hello,

I completely disagree. If the problem is the number of e-mails, you should
sub_scribe to the list in digest mode. This way, you only will receive a
message a day.

Regards,

  Virgilio


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brahm at alum.mit.edu  Thu Apr 11 18:10:30 2002
From: brahm at alum.mit.edu (David Brahm)
Date: Thu, 11 Apr 2002 12:10:30 -0400
Subject: [R] Layout of Fourier frequencies
In-Reply-To: <123584780@toto.iv>
Message-ID: <15541.46454.154807.318130@gargle.gargle.HOWL>

Timothy H. Keitt <Timothy.Keitt at stonybrook.edu> wrote:
> I'm doing convolutions in the frequency domain and need to know the
> layout of the Fourier modes returned by fft...
> I think in 1D the pattern is:
> 0 1 2 3 -2 1 (even)
> 0 1 2 3 -3 2 1 (odd)

I believe that's correct.  Perhaps you'll find my fft cheat-sheet (below)
handy, though it's only relevant to a univariate real series "z".

Define:
  N <- length(z)
  w <- fft(z)/N                 # Division by N here is a little unconventional
  jmax <- floor(N/2+1)
  tv <- 0:(N-1)                                    # Time values, starting at 0

w[1]==mean(z) is the constant term.

For j=2:jmax, w[j] is the Fourier coefficient for frequency (j-1)/N, and
  w[N+2-j] = Conj(w[j]).  Note that for even N, this implies w[jmax] is real.

You could derive the Fourier transform yourself (more slowly) with:
  w <- rep(NA, N)
  w[1] <- mean(z)
  for (j in 2:jmax) {
    w[j] <- sum(z * exp(-2i*pi*tv*(j-1)/N)) / N
    w[N+2-j] <- Conj(w[j])
  }
or even:
  w <- rep(NA, N)
  w[1] <- mean(z)
  for (j in 2:jmax) {
    phi <- 2*pi*tv*(j-1)/N
    w[j]     <- sum(z * (cos(phi) - 1i*sin(phi))) / N
    w[N+2-j] <- sum(z * (cos(phi) + 1i*sin(phi))) / N
  }

You can reconstruct the original series "z" either by:
  zz <- Re(fft(w, inverse=T))
or (more slowly) by:
  zz <- rep(Re(w[1]), N)
  for (j in 2:jmax) {
    dup <- if (N%%2==0 && j==jmax) 1 else 2       # Don't double jmax if N even
    zz <- zz + dup * Mod(w[j]) * cos(Arg(w[j]) + 2*pi*tv*(j-1)/N)
  }

The power spectrum ("periodogram"):
  s <- N * abs(w[2:jmax])^2
  plot((2:jmax-1)/N, s, type="l", log="y", xlab="frequency", ylab="spectrum")
can also be obtained from the "spectrum" function:
  s1 <- spectrum(z, fast=F, taper=0, detrend=F)           # Plots automatically
  plot(s1$freq, s1$spec, type="l", log="y", xlab="frequency", ylab="spectrum")

Note I had to override the default to detrend, taper, and pad z.  Smoother
(more meaningful?) spectra are obtained with, e.g.:
  s2 <- spectrum(z, spans=c(2*round(N/20)+1, 2*round(N/10)+1))
  s3 <- spec.ar(z)

Among other things, the power spectrum shows the distribution in frequency
space of the "sum-of-squares" errors.  Again you must watch that tricky jmax:
  sp <- s;  if (N%%2==0) sp[jmax-1] <- sp[jmax-1]/2
but then (N-1)*var(z) == 2*sum(sp).

-- 
                              -- David Brahm (brahm at alum.mit.edu)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Thu Apr 11 18:19:29 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 11 Apr 2002 11:19:29 -0500
Subject: [R] extract week from date
In-Reply-To: <6r3cy2dywx.fsf@franz.stat.wisc.edu>
References: <006101c1e15e$c2bc99c0$1100a8c0@ico.scs.es>
	<6r3cy2dywx.fsf@franz.stat.wisc.edu>
Message-ID: <6rg022b432.fsf@franz.stat.wisc.edu>

Douglas Bates <bates at cs.wisc.edu> writes:

> For example
> 
> > as.character(unique(cheese[,1]))
>  [1] "5/4/99"  "5/5/99"  "5/7/99"  "5/11/99" "5/12/99" "5/14/99" "5/18/99"
>  [8] "5/19/99" "5/21/99" "5/25/99" "5/27/99" "5/28/99" "8/3/99"  "8/4/99" 
> [15] "8/6/99"  "8/10/99" "8/11/99" "8/12/99" "8/13/99" "8/17/99" "8/18/99"
> [22] "8/19/99" "8/20/99" "8/24/99" "8/25/99" "8/27/99" "8/31/99"
> > dd <- strptime(as.character(unique(cheese[,1])), format = '%m/%d/%y')
> > ceiling(dd$yday/7)
>  [1] 18 18 18 19 19 19 20 20 20 21 21 21 31 31 31 32 32 32 32 33 33 33 33 34 34
> [26] 34 35

As Andy and Pingping pointed out, this is more compactly written as

> format(dd, "%U")
 [1] "18" "18" "18" "19" "19" "19" "20" "20" "20" "21" "21" "21" "31" "31" "31"
[16] "32" "32" "32" "32" "33" "33" "33" "33" "34" "34" "34" "35"
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Apr 11 18:50:12 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 11 Apr 2002 17:50:12 +0100 (BST)
Subject: [R] R cross-platform compatibility--wow!
In-Reply-To: <1018458745.19766.68.camel@gandalf>
Message-ID: <Pine.LNX.4.31.0204111746490.6950-100000@gannet.stats>

For the record, complete cross-platform compatibility is not guaranteed
until 1.5.0, although all known platforms support XDR (the last piece of
the jigsaw, which we supply in 1.5.0).

All platforms have been able to read files with all line endings (LF,
CRLF, even CR from a Mac) for a long time.

On 10 Apr 2002, Ernesto Jardim wrote:

> Hi
>
> I usually work on the same .RData in windows and linux whithout any
> problem, for a long time.
>
> This is one of preferred features in R.
>
> In my opinion R is one of the best examples in cross-platform
> compatibility.
>
> Best regards, thanks and keep the good work.
>
> EJ
>
> On Wed, 2002-04-10 at 15:23, Don MacQueen wrote:
> > I am impressed!
> >
> > I have R 1.4.1 installed on a remote Solaris system, and R 1.4.0
> > installed on my desktop Macintosh running OS X.
> >
> > I did some work using R on the Solaris system, i.e., read some data,
> > wrote some functions to do things with the data, including x11
> > graphics.
> >
> > I mounted the Solaris directories where I did the work on my Mac
> > using NFS. Running R 1.4.0 on my Mac in the mounted directories,
> > using the data and functions created with R 1.4.1 on the Solaris box,
> > works like a charm. No need to actually transfer the .RData files
> > from one computer to the other.
> >
> > Congratulations and thanks to the R core team and other contributors
> > for this achievement.
> >
> > -Don
> >
> > --
> > --------------------------------------
> > Don MacQueen
> > Environmental Protection Department
> > Lawrence Livermore National Laboratory
> > Livermore, CA, USA
> > --------------------------------------
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Thu Apr 11 19:04:15 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 11 Apr 2002 10:04:15 -0700 (PDT)
Subject: [R] problem with do.call
In-Reply-To: <1018518672.17310.10.camel@gandalf>
Message-ID: <Pine.A41.4.44.0204111000270.112274-100000@homer24.u.washington.edu>

On 11 Apr 2002, Ernesto Jardim wrote:

> Hi
>
> This was not my understanding. I thougth that if you can use functions
> like apply and similar instead of for loops your code will be faster.
> Basicly relying on these functions code which is (should be) optimized
> for speed.
>
> If what you're saying is true then using functions like apply is a
> matter of simplicity and not speeding up the code.
>
> Is this correct ?
>

Yes. As you can easily verify [and always should verify if you're doing
optimisation], the apply commands are rarely faster than their for() loop
equivalents. They can be slower.

The speed advantage of apply is partly mythical -- there's never been that
much advantage -- and partly historical, as in some versions of S-PLUS 3.x
apply was often faster for complicated reasons due to memory management.

The real point of the apply() family is to suppress unnecessary loop
variables and make your code tidier.  If we ever get parallel processing
then apply() could really become faster, but that's not going to happen
any time soon.

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Thu Apr 11 19:14:57 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 11 Apr 2002 10:14:57 -0700 (PDT)
Subject: [R] extract week from date
In-Reply-To: <006101c1e15e$c2bc99c0$1100a8c0@ico.scs.es>
Message-ID: <Pine.A41.4.44.0204111013470.112274-100000@homer24.u.washington.edu>

On Thu, 11 Apr 2002, Juan Ramon Gonzalez wrote:

> Hello R-users,
>
> Does anyone know how obtain the week of a date?
> (in SPPS the instruction is "xdate.week")

Extract the day and divide by seven?

as.POSIXlt(a.date)$yday %/% 7

Perhaps add 1 if you want the year to start at week 1 rather than week 0.

	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Thu Apr 11 19:50:34 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 11 Apr 2002 10:50:34 -0700 (PDT)
Subject: [R] time (or output of function) in the R prompt
In-Reply-To: <51F9C42DA15CD311BD220008C707D81906FFC1EB@usrymx10.merck.com>
Message-ID: <Pine.A41.4.44.0204111047150.112274-100000@homer24.u.washington.edu>

On Thu, 11 Apr 2002, Liaw, Andy wrote:

> Dear R-help,
>
> Would it be possible to have the "prompt" option accept a function, such as
> date()?  This way, I can easily deduce the elapse time of top level R
> expressions.  This would be similar to how Unix shells handle their prompt
> variables.

You can almost do this with the taskCallback Manager

> h <- taskCallbackManager()
> h$add(function(expr, value, ok, visible) {
		options(prompt=paste(date(),"> "));
		return(TRUE)},
       name="dateprompt")

Thu Apr 11 10:47:06 2002 > 1+1
[1] 2
Thu Apr 11 10:48:28 2002 >

I say `almost' because the time is updated only when you actually compute
something.  If you just press <return> it doesn't change. Apart from that
it works.


	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Thu Apr 11 20:11:06 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 11 Apr 2002 14:11:06 -0400
Subject: [R] time (or output of function) in the R prompt
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC1F2@usrymx10.merck.com>

> On Thu, 11 Apr 2002, Liaw, Andy wrote:
> 
> > Dear R-help,
> >
> > Would it be possible to have the "prompt" option accept a 
> function, such as
> > date()?  This way, I can easily deduce the elapse time of 
> top level R
> > expressions.  This would be similar to how Unix shells 
> handle their prompt
> > variables.
> 
> You can almost do this with the taskCallback Manager
> 
> > h <- taskCallbackManager()
> > h$add(function(expr, value, ok, visible) {
> 		options(prompt=paste(date(),"> "));
> 		return(TRUE)},
>        name="dateprompt")
> 
> Thu Apr 11 10:47:06 2002 > 1+1
> [1] 2
> Thu Apr 11 10:48:28 2002 >
> 
> I say `almost' because the time is updated only when you 
> actually compute
> something.  If you just press <return> it doesn't change. 
> Apart from that
> it works.

Thanks a lot Thomas!  This gives the same desired effect, thru different
mechanism (than the Unix shells?).  I can also use it to add the output of
getwd() to remind myself which R session I'm staring at, when I have several
running simultaneously.

Also thanks to DTL for providing taskCallbackManager().  It's a lot more
useful than my original question about timed autosave.

Cheers,
Andy


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named in this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ozric at web.de  Thu Apr 11 20:19:31 2002
From: ozric at web.de (christian)
Date: Thu, 11 Apr 2002 20:19:31 +0200
Subject: [R] Principal Component analysis question
Message-ID: <E16vj4i-0000Io-00@smtp.web.de>

IMHO try 
princomp [fun<-princomp(V1+V2+V3+V4+V5)]  without ~ for negation in this manner !?
regards,christian


Am 11.04.2002 00:43:43, schrieb Damien Joly <do_joly at yahoo.ca>:

>I have a question about princomp(mva) that I hope isn't too newbie.
>
>I used the sample data from Table 1.1 in "Manly (1986/1994) Multivariate 
>Statistical Methods: a primer. Chapman and Hall" on sparrow body 
>measurements.
>
>I rescaled the data to mean 0 and SD 1, and the covariance matrix is:
>
>           V1        V2        V3        V4        V5
>V1 1.0000000 0.7349642 0.6618119 0.6452841 0.6051247
>V2 0.7349642 1.0000000 0.6737411 0.7685087 0.5290138
>V3 0.6618119 0.6737411 1.0000000 0.7631899 0.5262701
>V4 0.6452841 0.7685087 0.7631899 1.0000000 0.6066493
>V5 0.6051247 0.5290138 0.5262701 0.6066493 1.0000000
>
>Now when I call princomp [fun<-princomp(~V1+V2+V3+V4+V5)], I get the 
>following loadings:
>
>        Comp.1      Comp.2     Comp.3      Comp.4     Comp.5
>V1 -0.4517989 -0.05072137  0.6904702  0.42041399 -0.3739091
>V2 -0.4616809  0.29956355  0.3405484 -0.54786307  0.5300805
>V3 -0.4505416  0.32457242 -0.4544927  0.60629605  0.3427923
>V4 -0.4707389  0.18468403 -0.4109350 -0.38827811 -0.6516665
>V5 -0.3976754 -0.87648935 -0.1784558 -0.06887199  0.1924341
>
>However, this is in contrast to the results in Manly's book:
>
>       Comp.1      Comp.2     Comp.3      Comp.4     Comp.5
>V1 0.4517989 -0.05072137  0.6904702 -0.42041399  0.3739091
>V2 0.4616809  0.29956355  0.3405484  0.54786307 -0.5300805
>V3 0.4505416  0.32457242 -0.4544927 -0.60629605 -0.3427923
>V4 0.4707389  0.18468403 -0.4109350  0.38827811  0.6516665
>V5 0.3976754 -0.87648935 -0.1784558  0.06887199 -0.1924341
>
>Interestingly, when I do the same in SAS, I get:
>
>        Comp.1      Comp.2     Comp.3      Comp.4     Comp.5
>V1  0.4517989  0.05072137 -0.6904702  0.42041399 -0.3739091
>V2  0.4616809 -0.29956355 -0.3405484 -0.54786307  0.5300805
>V3  0.4505416 -0.32457242  0.4544927  0.60629605  0.3427923
>V4  0.4707389 -0.18468403  0.4109350 -0.38827811 -0.6516665
>V5  0.3976754  0.87648935  0.1784558 -0.06887199  0.1924341
>
>Finally, when I do it by "hand" in R (i.e., c<-cov(data); e<-eigen(c)), 
>I get a fourth answer:
>
>           V5          V4         V3          V2         V1
>V1 0.4517989  0.05072137 -0.6904702 -0.42041399 -0.3739091
>V2 0.4616809 -0.29956355 -0.3405484  0.54786307  0.5300805
>V3 0.4505416 -0.32457242  0.4544927 -0.60629605  0.3427923
>V4 0.4707389 -0.18468403  0.4109350  0.38827811 -0.6516665
>V5 0.3976754  0.87648935  0.1784558  0.06887199  0.1924341
>
>
>Can anyone point me in the right direction here?  I can email the raw 
>data to anyone if that would help.
>
>Thank you in advance...
>
>Damien
>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wagman at enteract.com  Thu Apr 11 21:24:49 2002
From: wagman at enteract.com (Barnet Wagman)
Date: Thu, 11 Apr 2002 14:24:49 -0500
Subject: [R] Need help decyphering 'make check' errors
Message-ID: <3CB5E301.9020205@enteract.com>

  I haven't been able to find any documentation explaining what these
errors mean (and if they're serious).  If anyone can give me some
guidance on this, I'd very much appreciate it.

The error messages are

    make[4]: *** [ctest-Ex.Rout] Error 1
    make[3]: *** [test-Examples] Error 2
    make[2]: *** [test-Examples] Error 2
    make[1]: *** [test-all-basics] Error 1
    make: *** [check] Error 2

The full output is below.

Thanks,

Barnet Wagman


=============================================================

/usr/local/R-1.4.1 # make check
make[1]: Entering directory `/usr/local/R-1.4.1/tests'
make[2]: Entering directory `/usr/local/R-1.4.1/tests'
make[3]: Entering directory `/usr/local/R-1.4.1/tests/Examples'
make[4]: Entering directory `/usr/local/R-1.4.1/tests/Examples'
make[4]: Leaving directory `/usr/local/R-1.4.1/tests/Examples'
make[4]: Entering directory `/usr/local/R-1.4.1/tests/Examples'
collecting examples for package `base' ...
make[5]: Entering directory `/usr/local/R-1.4.1/src/library'
 >>> Building/Updating help pages for package `base'
     Formats: text example
make[5]: Leaving directory `/usr/local/R-1.4.1/src/library'
running code in `base-Ex.R' ... OK
collecting examples for package `ctest' ...
make[5]: Entering directory `/usr/local/R-1.4.1/src/library'
 >>> Building/Updating help pages for package `ctest'
     Formats: text example
make[5]: Leaving directory `/usr/local/R-1.4.1/src/library'
running code in `ctest-Ex.R' ...make[4]: *** [ctest-Ex.Rout] Error 1
make[4]: Leaving directory `/usr/local/R-1.4.1/tests/Examples'
make[3]: *** [test-Examples] Error 2
make[3]: Leaving directory `/usr/local/R-1.4.1/tests/Examples'
make[2]: *** [test-Examples] Error 2
make[2]: Leaving directory `/usr/local/R-1.4.1/tests'
make[1]: *** [test-all-basics] Error 1
make[1]: Leaving directory `/usr/local/R-1.4.1/tests'
make: *** [check] Error 2


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Apr 11 20:32:22 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 11 Apr 2002 19:32:22 +0100 (BST)
Subject: [R] problem with do.call
In-Reply-To: <Pine.A41.4.44.0204111000270.112274-100000@homer24.u.washington.edu>
Message-ID: <Pine.LNX.4.31.0204111926020.7240-100000@gannet.stats>

On Thu, 11 Apr 2002, Thomas Lumley wrote:

> On 11 Apr 2002, Ernesto Jardim wrote:
>
> > Hi
> >
> > This was not my understanding. I thougth that if you can use functions
> > like apply and similar instead of for loops your code will be faster.
> > Basicly relying on these functions code which is (should be) optimized
> > for speed.
> >
> > If what you're saying is true then using functions like apply is a
> > matter of simplicity and not speeding up the code.
> >
> > Is this correct ?
> >
>
> Yes. As you can easily verify [and always should verify if you're doing
> optimisation], the apply commands are rarely faster than their for() loop
> equivalents. They can be slower.
>
> The speed advantage of apply is partly mythical -- there's never been that
> much advantage -- and partly historical, as in some versions of S-PLUS 3.x
> apply was often faster for complicated reasons due to memory management.

I think that is a little pessimistic. It is true for apply() in R, which
just streamlines a for() loop, and also does things you may not want.
However, lapply is an internal function (written by me) because it is
sometimes a lot faster, and in my experiments never slower.

lapply() was a lot faster in S-PLUS 3.4.  It was often slower than for()
in 5.0, hence a lot of consternation.   There *are* a lot of myths about,
but not all in one direction.  As others have said, `S Programming' tries
to give a balanced view across 3 different S implementations, and
profiling can be a great tool in optimizing code (it can be misleading
too, but rarely when it matters).

Summary: lapply is enoouraged.  apply is a matter of style.  Test out
whatever you do to see if it is really worthwhile.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Apr 11 20:34:43 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 11 Apr 2002 19:34:43 +0100 (BST)
Subject: [R] Need help decyphering 'make check' errors
In-Reply-To: <3CB5E301.9020205@enteract.com>
Message-ID: <Pine.LNX.4.31.0204111932570.7240-100000@gannet.stats>

They are serious.  Take a look at tests/Examples/ctest-Ex.Rout.fail to see
what the error was, or look for a core dump in tests/Examples in that
file shows nothing amiss.

On Thu, 11 Apr 2002, Barnet Wagman wrote:

>   I haven't been able to find any documentation explaining what these
> errors mean (and if they're serious).  If anyone can give me some
> guidance on this, I'd very much appreciate it.
>
> The error messages are
>
>     make[4]: *** [ctest-Ex.Rout] Error 1
>     make[3]: *** [test-Examples] Error 2
>     make[2]: *** [test-Examples] Error 2
>     make[1]: *** [test-all-basics] Error 1
>     make: *** [check] Error 2
>
> The full output is below.
>
> Thanks,
>
> Barnet Wagman
>
>
> =============================================================
>
> /usr/local/R-1.4.1 # make check
> make[1]: Entering directory `/usr/local/R-1.4.1/tests'
> make[2]: Entering directory `/usr/local/R-1.4.1/tests'
> make[3]: Entering directory `/usr/local/R-1.4.1/tests/Examples'
> make[4]: Entering directory `/usr/local/R-1.4.1/tests/Examples'
> make[4]: Leaving directory `/usr/local/R-1.4.1/tests/Examples'
> make[4]: Entering directory `/usr/local/R-1.4.1/tests/Examples'
> collecting examples for package `base' ...
> make[5]: Entering directory `/usr/local/R-1.4.1/src/library'
>  >>> Building/Updating help pages for package `base'
>      Formats: text example
> make[5]: Leaving directory `/usr/local/R-1.4.1/src/library'
> running code in `base-Ex.R' ... OK
> collecting examples for package `ctest' ...
> make[5]: Entering directory `/usr/local/R-1.4.1/src/library'
>  >>> Building/Updating help pages for package `ctest'
>      Formats: text example
> make[5]: Leaving directory `/usr/local/R-1.4.1/src/library'
> running code in `ctest-Ex.R' ...make[4]: *** [ctest-Ex.Rout] Error 1
> make[4]: Leaving directory `/usr/local/R-1.4.1/tests/Examples'
> make[3]: *** [test-Examples] Error 2
> make[3]: Leaving directory `/usr/local/R-1.4.1/tests/Examples'
> make[2]: *** [test-Examples] Error 2
> make[2]: Leaving directory `/usr/local/R-1.4.1/tests'
> make[1]: *** [test-all-basics] Error 1
> make[1]: Leaving directory `/usr/local/R-1.4.1/tests'
> make: *** [check] Error 2
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Apr 11 20:40:15 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 11 Apr 2002 19:40:15 +0100 (BST)
Subject: [R] pooling categories in a table
In-Reply-To: <61411576E951D211AF330008C7245DD90D7C6C04@ntmsg0005.corpmail.telstra.com.au>
Message-ID: <Pine.LNX.4.31.0204111938070.7240-100000@gannet.stats>

On Tue, 9 Apr 2002, Strumila, John wrote:

> beautiful, I didn't realise you could use "c(2,3)".  Its not in "help".  I
> guess it's so obvious now...

I beg to differ: it is under MARGIN in help(apply) (and in a couple of
good books on S).

Also note that some 1.5.0 colSums() will do this sort of thing a mite
more efficiently.

>
> John Strumila
>
>     > apply(tab, c(2,3), sum)  # sums over first coordinate
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wagman at enteract.com  Thu Apr 11 21:57:32 2002
From: wagman at enteract.com (Barnet Wagman)
Date: Thu, 11 Apr 2002 14:57:32 -0500
Subject: [R] Need help decyphering 'make check' errors
References: <Pine.LNX.4.31.0204111932570.7240-100000@gannet.stats>
Message-ID: <3CB5EAAC.8080007@enteract.com>

The file 'tests/Examples/ctest-Ex.Rout.fail' ends with the following error:

    > ## Formula interface.
    > data(USJudgeRatings)
    > pairs(USJudgeRatings)
    > cor.test(~ CONT + INTG, data = USJudgeRatings)
    Error in cor.test.default(~CONT + INTG, data = USJudgeRatings) :
        unused argument(s) (data ...)
    Execution halted


There was no core dump.  Could this be a bug in the test source?  If not,
any suggestions as to how I should proceed?


I'm running under SuSE 7.3; has anyone else built R on this version of SuSE?
(There's no pre-compiled version of R for SuSE 7.3, which is why I'm 
building
from source.)

Thanks,

bw

ripley at stats.ox.ac.uk wrote:

>They are serious.  Take a look at tests/Examples/ctest-Ex.Rout.fail to see
>what the error was, or look for a core dump in tests/Examples in that
>file shows nothing amiss.
>
>On Thu, 11 Apr 2002, Barnet Wagman wrote:
>
>>  I haven't been able to find any documentation explaining what these
>>errors mean (and if they're serious).  If anyone can give me some
>>guidance on this, I'd very much appreciate it.
>>
>>The error messages are
>>
>>    make[4]: *** [ctest-Ex.Rout] Error 1
>>    make[3]: *** [test-Examples] Error 2
>>    make[2]: *** [test-Examples] Error 2
>>    make[1]: *** [test-all-basics] Error 1
>>    make: *** [check] Error 2
>>






-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rolf at math.unb.ca  Thu Apr 11 21:21:46 2002
From: rolf at math.unb.ca (Rolf Turner)
Date: Thu, 11 Apr 2002 16:21:46 -0300 (ADT)
Subject: [R] Obtaining names of ``...'' arguments.
Message-ID: <200204111921.QAA03139@tanner.math.unb.ca>

This may be an FAQ, but a (perfunctory) search failed to turn it up.

Suppose I have a function foo(...){<something>} and I want to obtain,
inside foo, the names of items comprising the ``...''.  E.g. if I
call

	foo(melvin,clyde,irving)

I want to be able to loop through the ``...'' and successively obtain
the text strings "melvin", "clyde", and "irving".

Is there any way to do this?

I know that if I had a function foo(x,y,z){<something>}, and I called
foo(melvin,clyde,irving), I could get the text strings I want by
means of

	deparse(substitute(x)) # Giving "melvin".
	deparse(substitute(y)) # Giving "clyde".
	deparse(substitute(z)) # Giving "irving".

but if foo() is to take an arbitrary number of arguments then this
sort of syntax is not available.

					cheers,

						Rolf Turner
						rolf at math.unb.ca
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Thu Apr 11 21:43:07 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 11 Apr 2002 12:43:07 -0700 (PDT)
Subject: [R] Obtaining names of ``...'' arguments.
In-Reply-To: <200204111921.QAA03139@tanner.math.unb.ca>
Message-ID: <Pine.A41.4.44.0204111241330.112274-100000@homer24.u.washington.edu>

On Thu, 11 Apr 2002, Rolf Turner wrote:

> This may be an FAQ, but a (perfunctory) search failed to turn it up.
>
> Suppose I have a function foo(...){<something>} and I want to obtain,
> inside foo, the names of items comprising the ``...''.  E.g. if I
> call
>
> 	foo(melvin,clyde,irving)
>
> I want to be able to loop through the ``...'' and successively obtain
> the text strings "melvin", "clyde", and "irving".
>
> Is there any way to do this?
>


R> f
function(...){
substitute(list(...))
}
R> f(melvin,clyde,irving)
list(melvin, clyde, irving)

If you want text strings you will have to convert them with eg
as.character, or supply text strings as the arguments

R> f("melvin","clyde","irving")
list("melvin", "clyde", "irving")

	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Thu Apr 11 21:51:44 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 11 Apr 2002 12:51:44 -0700 (PDT)
Subject: [R] Need help decyphering 'make check' errors
In-Reply-To: <3CB5EAAC.8080007@enteract.com>
Message-ID: <Pine.A41.4.44.0204111245080.112274-100000@homer24.u.washington.edu>

On Thu, 11 Apr 2002, Barnet Wagman wrote:

> The file 'tests/Examples/ctest-Ex.Rout.fail' ends with the following error:
>
>     > ## Formula interface.
>     > data(USJudgeRatings)
>     > pairs(USJudgeRatings)
>     > cor.test(~ CONT + INTG, data = USJudgeRatings)
>     Error in cor.test.default(~CONT + INTG, data = USJudgeRatings) :
>         unused argument(s) (data ...)
>     Execution halted
>
>
> There was no core dump.  Could this be a bug in the test source?  If not,
> any suggestions as to how I should proceed?

The first step would be to see if the error is reproducible just from
those few lines, so in R do
  data(USJudgeRatings)
  pairs(USJudgeRatings)
  cor.test(~ CONT + INTG, data = USJudgeRatings)

That's not likely, but it would be so much simpler than the alternative,
which is that some earlier command has corrupted some internal structure
in R.  In this more likely case it may be necessary to progressively
remove code from the test file until the bug goes away, to try to locate
it.

	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Ted.Harding at nessie.mcc.ac.uk  Thu Apr 11 21:55:24 2002
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 11 Apr 2002 20:55:24 +0100 (BST)
Subject: [R] Missing data and Imputation
In-Reply-To: <20020408135809.73ea5347.fharrell@virginia.edu>
Message-ID: <XFMail.020411205524.Ted.Harding@nessie.mcc.ac.uk>

Thanks to all who gave very useful replies to my query.

Best wishes,
Ted.

> On Mon, 08 Apr 2002 17:23:32 -0000 (BST)
> Ted.Harding at nessie.mcc.ac.uk wrote:
> 
>> Hi Folks,
>> 
>> I'm currently looking at missing data/imputation
>> methods (including multiple imputation).
>> 
>> S-Plus has a "missing data library".
>> 
>> What similar resources are available within R?
>> 
>> Or does one roll one's own?
>> 
>> Best wishes to all,
>> Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 11-Apr-02                                       Time: 20:55:24
------------------------------ XFMail ------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deepayansarkar at yahoo.com  Thu Apr 11 22:15:24 2002
From: deepayansarkar at yahoo.com (Deepayan Sarkar)
Date: Thu, 11 Apr 2002 13:15:24 -0700 (PDT)
Subject: [R] Obtaining names of ``...'' arguments.
In-Reply-To: <200204111921.QAA03139@tanner.math.unb.ca>
Message-ID: <20020411201524.9771.qmail@web13908.mail.yahoo.com>



foo <- function(...) as.character(match.call(expand.dots = FALSE)$"...")

should give you the names a a character vector.

--- Rolf Turner <rolf at math.unb.ca> wrote:
> This may be an FAQ, but a (perfunctory) search failed to turn it up.
> 
> Suppose I have a function foo(...){<something>} and I want to obtain,
> inside foo, the names of items comprising the ``...''.  E.g. if I
> call
> 
>  foo(melvin,clyde,irving)
>
> I want to be able to loop through the ``...'' and successively obtain
> the text strings "melvin", "clyde", and "irving".
> 
> Is there any way to do this?
> 
> I know that if I had a function foo(x,y,z){<something>}, and I called
> foo(melvin,clyde,irving), I could get the text strings I want by
> means of
> 
>  deparse(substitute(x)) # Giving "melvin".
>  deparse(substitute(y)) # Giving "clyde".
>  deparse(substitute(z)) # Giving "irving".
> 
> but if foo() is to take an arbitrary number of arguments then this
> sort of syntax is not available.
> 
>      cheers,
> 
>       Rolf Turner
>       rolf at math.unb.ca
>
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

__________________________________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From P.Connolly at hortresearch.co.nz  Fri Apr 12 00:54:56 2002
From: P.Connolly at hortresearch.co.nz (Patrick Connolly)
Date: Fri, 12 Apr 2002 10:54:56 +1200 (NZST)
Subject: [R] Newsgroup and spammers
In-Reply-To: <4k2bbu8e9vmkmrnk0ggi5aqpqfriaek0nk@4ax.com> from "Duncan Murdoch" at Apr 11, 2002 09:22:24 AM
Message-ID: <200204112254.g3BMsu002463@biomat1.marc.hort.cri.nz>

According to Duncan Murdoch:
|> 
|> I agree that a newsgroup gateway would be a good idea.  I volunteer to
|> help whoever wants to set one up.  If nobody volunteers to head the
|> project, then I'll put it on my list of things to do myself, but it's
|> unlikely to happen before my sabbatical in 2004 if it's on that list.

If mail to R-help ends up on a newsgroup, I would want my email
address removed from such postings.  I'd be surprised if I am the only
one who doesn't want my email address put in the firing line of
address harvesters for onselling to spammers.  The idea commonly used
with newsgroups of adding spurious characters into the address won't
work because I then won't get mail from r-help.

I have a suggestion and request for whomsoever sets up a gateway:

A list of addresses of people who don't want real email addresses in
the firing line could be stored in a safe place.  Any text that is to
be sent through the gateway could pass through a filter that would
remove those text strings before it went out to pasture (so to speak).
A simple perl script would probably be sufficient.

The logistics of just how subscribers to r-help get their names onto
that list I'm not clear on, but I'm sure someone would have a good idea.

best

-- 
*************************************************************
   ___      Patrick Connolly
 {~._.~}    HortResearch             Great minds discuss ideas;
 _( Y )_    Mt Albert                Average minds discuss events; 
(:_~*~_:)   Auckland                 Small minds discuss people.
 (_)-(_)    New Zealand                                    .... Anon
            Ph: +64-9 815 4200 x 7188
*************************************************************


______________________________________________________
The contents of this e-mail are privileged and/or confidential to the
named recipient and are not to be used by any other person and/or
organisation. If you have received this e-mail in error, please notify 
the sender and delete all material pertaining to this e-mail.
______________________________________________________
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From erich.neuwirth at univie.ac.at  Fri Apr 12 00:22:25 2002
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Fri, 12 Apr 2002 00:22:25 +0200
Subject: [R] extract week from date
References: <Pine.A41.4.44.0204111013470.112274-100000@homer24.u.washington.edu>
Message-ID: <3CB60CA1.9020707@univie.ac.at>

this is more complicated.
the definition of week 1 is noct clear.
but as far as i know
the week containing the first of january counts as last week
if at least 4 of its days belong to the old year,
and it is the first week if at least 4 of its days
belong to the new year.

i do not know if there is a standardized definiton
with regard to the fact that the week starts on sunday
in soem countries (us?)
and on monday in some other countries (most european countries?)


>>Does anyone know how obtain the week of a date?
>>(in SPPS the instruction is "xdate.week")
>>
> 
> Extract the day and divide by seven?
> 
> as.POSIXlt(a.date)$yday %/% 7
> 



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From John.Strumila at team.telstra.com  Fri Apr 12 00:52:12 2002
From: John.Strumila at team.telstra.com (Strumila, John)
Date: Fri, 12 Apr 2002 08:52:12 +1000
Subject: [R] pooling categories in a table
Message-ID: <61411576E951D211AF330008C7245DD90D7C6F18@ntmsg0005.corpmail.telstra.com.au>

you're right as usual.  I only looked at the 'arguments' section.

-----Original Message-----
From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk]
Sent: Friday, 12 April 2002 4:40 AM
To: Strumila, John
Cc: r-help
Subject: RE: [R] pooling categories in a table


On Tue, 9 Apr 2002, Strumila, John wrote:

> beautiful, I didn't realise you could use "c(2,3)".  Its not in "help".  I
> guess it's so obvious now...

I beg to differ: it is under MARGIN in help(apply) (and in a couple of
good books on S).

Also note that some 1.5.0 colSums() will do this sort of thing a mite
more efficiently.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From erich.neuwirth at univie.ac.at  Fri Apr 12 01:01:49 2002
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Fri, 12 Apr 2002 01:01:49 +0200
Subject: [R] extract week from date
References: <006101c1e15e$c2bc99c0$1100a8c0@ico.scs.es> <6r3cy2dywx.fsf@franz.stat.wisc.edu>
Message-ID: <3CB615DD.2080701@univie.ac.at>

from the calendar faq

5.7. What is the week number?
-----------------------------

International standard ISO-8601 (mentioned in section 5.6) assigns a
number to each week of the year. A week that lies partly in one year
and partly in another is assigned a number in the year in which most
of its days lie. This means that

         Week 1 of any year is the week that contains 4 January,

or equivalently

         Week 1 of any year is the week that contains the first
         Thursday in January.

Most years have 52 weeks, but years that start on a Thursday and leap
years that start on a Wednesday have 53 weeks.

Note: This week numbering system is not used in the United States.

-=-=-=-=-=


can somebody from the united states tell us how weeks are numbered there?





-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lutz.thieme at amd.com  Fri Apr 12 09:09:10 2002
From: lutz.thieme at amd.com (lutz.thieme@amd.com)
Date: Fri, 12 Apr 2002 09:09:10 +0200
Subject: [R] "CTRL-C" and "try"
Message-ID: <E540DF203FFED21182EB0008C72875600AEDA6F5@deexmta4.amd.com>

First of all - thank you Luke for your detailed explainations. 

	{ try(repeat{}); cat("got through try\n"); repeat{}}

	at the command line.  The first C-c should take you out of the `try'.
	On my Linux system a second C-c takes me to the command line but on
	your it probably exits R.]
That's right - it works, as you described: First CTRL-C takes me out of "try" and the second to the
UNIX-command line. My suggestions is to change (if possible) this behavior in further R-versions so, 
that it is possible to interrupt a "try"-call.

Regards,

Lutz


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Jussi.Makinen at valtiokonttori.fi  Fri Apr 12 10:12:47 2002
From: Jussi.Makinen at valtiokonttori.fi (=?iso-8859-1?Q?M=E4kinen_Jussi?=)
Date: Fri, 12 Apr 2002 11:12:47 +0300
Subject: [R] Matrix to data.frame without factors
Message-ID: <7EFB6224454CD511B9D700306E00F4070199AB90@VKYHA01>

Hello and thank you dear R-people in advance.

This is quite basic question but which I have confronted occasionally and
get over it without satisfying solution. The question is about factors, this
time I would just like convert a data.frames NA-terms to 0 and get a
data.frame as a result. There might be a way to do that inside of the
data.frame but I think that it might be overcomplicated and possible slow.
With matrix it is easy and clean:

X <- (ifelse(is.na(X), 0, X))	### Applying data.frames yields list..

or 

"na.to.0" <- function(x)
{
	x <- as.matrix(x)	### Just to be sure
	x[is.na(x)] <- 0
	x <- data.frame(x)	### PROBLEM
	x
}

So the problem comes when converting the result to a data.frame (this is
sometimes also a problem when importing data.frame!). All character columns
goes to factors as documented in help. That's something one can avoid by
using I() or later call type.convert (convert.col.type in Splus if I can
recall) but somehow I think that there should be a way to make it easier. At
least in a case when converting data.frame to matrix and back to data.frame.

The other but related question is odd. This time I have numeric col in a
data.frame (at least it should be) which I have fetched from Excel through
RODBC (it's great). But when I'm trying to convert Na to 0 as a side effect
these columns get converted to characters:

> is.numeric(as.matrix(KUNTADATA[,15]))
[1] TRUE
> is.numeric(as.data.frame(as.matrix(KUNTADATA[,15])))
[1] FALSE
or
> is.numeric(data.frame(as.matrix(KUNTADATA[,15])))
[1] FALSE

as.numeric works of course but that's not to way to do well and error robust
code.

Please let me know if you have any idea how to avoid automatic factor or
character (last case) conversion.

Jussi
Analytics
State Treasury of Finland, Finance


PS.

version:
platform i386-pc-mingw32
arch     x86            
os       Win32          
system   x86, Win32     
status                  
major    1              
minor    4.1            
year     2002           
month    01             
day      30             
language R

Platform is Windows NT4 (not my choice..)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Jussi.Makinen at valtiokonttori.fi  Fri Apr 12 10:45:26 2002
From: Jussi.Makinen at valtiokonttori.fi (=?iso-8859-1?Q?M=E4kinen_Jussi?=)
Date: Fri, 12 Apr 2002 11:45:26 +0300
Subject: [R] RE: Matrix to data.frame without factors
Message-ID: <7EFB6224454CD511B9D700306E00F4070199AB91@VKYHA01>

To answer at least partially to my own question:

"na.to.0" <- function(x)
{
	xx <- data.matrix(x)
	xx[is.na(x)] <- 0
	xx <- data.frame(xx)
	xx
}

seems to work (Idea is/was replace a data.frame NAs by 0s and return a
data.frame as a result).

Still I'm a little bit confused with these converts but now I can move on.

Sorry this monology,

Jussi
________________________________________________
Hello and thank you dear R-people in advance.

This is quite basic question but which I have confronted occasionally and
get over it without satisfying solution. The question is about factors, this
time I would just like convert a data.frames NA-terms to 0 and get a
data.frame as a result. There might be a way to do that inside of the
data.frame but I think that it might be overcomplicated and possible slow.
With matrix it is easy and clean:

X <- (ifelse(is.na(X), 0, X))	### Applying data.frames yields list..

or 

"na.to.0" <- function(x)
{
	x <- as.matrix(x)	### Just to be sure
	x[is.na(x)] <- 0
	x <- data.frame(x)	### PROBLEM
	x
}

So the problem comes when converting the result to a data.frame (this is
sometimes also a problem when importing data.frame!). All character columns
goes to factors as documented in help. That's something one can avoid by
using I() or later call type.convert (convert.col.type in Splus if I can
recall) but somehow I think that there should be a way to make it easier. At
least in a case when converting data.frame to matrix and back to data.frame.

The other but related question is odd. This time I have numeric col in a
data.frame (at least it should be) which I have fetched from Excel through
RODBC (it's great). But when I'm trying to convert Na to 0 as a side effect
these columns get converted to characters:

> is.numeric(as.matrix(KUNTADATA[,15]))
[1] TRUE
> is.numeric(as.data.frame(as.matrix(KUNTADATA[,15])))
[1] FALSE
or
> is.numeric(data.frame(as.matrix(KUNTADATA[,15])))
[1] FALSE

as.numeric works of course but that's not to way to do well and error robust
code.

Please let me know if you have any idea how to avoid automatic factor or
character (last case) conversion.

Jussi
Analytics
State Treasury of Finland, Finance


PS.

version:
platform i386-pc-mingw32
arch     x86            
os       Win32          
system   x86, Win32     
status                  
major    1              
minor    4.1            
year     2002           
month    01             
day      30             
language R

Platform is Windows NT4 (not my choice..)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Apr 12 10:59:23 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Fri, 12 Apr 2002 09:59:23 +0100 (BST)
Subject: [R] RE: Matrix to data.frame without factors
In-Reply-To: <7EFB6224454CD511B9D700306E00F4070199AB91@VKYHA01>
Message-ID: <Pine.GSO.4.44.0204120956260.13869-100000@auk.stats>

On Fri, 12 Apr 2002, [iso-8859-1] Mkinen Jussi wrote:

> To answer at least partially to my own question:
>
> "na.to.0" <- function(x)
> {
> 	xx <- data.matrix(x)
> 	xx[is.na(x)] <- 0
> 	xx <- data.frame(xx)
> 	xx
> }
>
> seems to work (Idea is/was replace a data.frame NAs by 0s and return a
> data.frame as a result).
>
> Still I'm a little bit confused with these converts but now I can move on.

I'm confused by your questions.  Is this a data frame with only numeric
columns?   If so, your comments about factors/characters make no sense, and
if not your conversion makes little sense.

For a *numeric* data frame X

X[] <- lapply(X, function(x) {x[is.na(x)] <- 0; x})

seems to be what you want.

>
> Sorry this monology,
>
> Jussi
> ________________________________________________
> Hello and thank you dear R-people in advance.
>
> This is quite basic question but which I have confronted occasionally and
> get over it without satisfying solution. The question is about factors, this
> time I would just like convert a data.frames NA-terms to 0 and get a
> data.frame as a result. There might be a way to do that inside of the
> data.frame but I think that it might be overcomplicated and possible slow.
> With matrix it is easy and clean:
>
> X <- (ifelse(is.na(X), 0, X))	### Applying data.frames yields list..
>
> or
>
> "na.to.0" <- function(x)
> {
> 	x <- as.matrix(x)	### Just to be sure
> 	x[is.na(x)] <- 0
> 	x <- data.frame(x)	### PROBLEM
> 	x
> }
>
> So the problem comes when converting the result to a data.frame (this is
> sometimes also a problem when importing data.frame!). All character columns
> goes to factors as documented in help. That's something one can avoid by
> using I() or later call type.convert (convert.col.type in Splus if I can
> recall) but somehow I think that there should be a way to make it easier. At
> least in a case when converting data.frame to matrix and back to data.frame.
>
> The other but related question is odd. This time I have numeric col in a
> data.frame (at least it should be) which I have fetched from Excel through
> RODBC (it's great). But when I'm trying to convert Na to 0 as a side effect
> these columns get converted to characters:
>
> > is.numeric(as.matrix(KUNTADATA[,15]))
> [1] TRUE
> > is.numeric(as.data.frame(as.matrix(KUNTADATA[,15])))
> [1] FALSE
> or
> > is.numeric(data.frame(as.matrix(KUNTADATA[,15])))
> [1] FALSE
>
> as.numeric works of course but that's not to way to do well and error robust
> code.
>
> Please let me know if you have any idea how to avoid automatic factor or
> character (last case) conversion.
>
> Jussi
> Analytics
> State Treasury of Finland, Finance
>
>
> PS.
>
> version:
> platform i386-pc-mingw32
> arch     x86
> os       Win32
> system   x86, Win32
> status
> major    1
> minor    4.1
> year     2002
> month    01
> day      30
> language R
>
> Platform is Windows NT4 (not my choice..)
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From nina at math.uni-bremen.de  Fri Apr 12 11:10:22 2002
From: nina at math.uni-bremen.de (Nina Lieske)
Date: Fri, 12 Apr 2002 11:10:22 +0200
Subject: [R] persp(): z-axis annotation overwrites numbers at tickmark
Message-ID: <00db01c1e201$e052ec20$557c6686@tating>

Dear R-users

first, thanks to Paul Murrell for fixing my problem "What line is labeled in
persp()".
It works great now (in the development version).

One more question (I don't  know if it's related to the "old" problem): the
annotation on the z-axis
overwrites the numbers at the tickmarks and sometimes, if numbers are pretty
long, the numbers themselfe overlap the actual tickmark.

I tried moving the annotation by adj or lower the fontsize and tried out
kind of all other parameters given in par() but didn't succeed.

Is this actually the same kind of problem (like the old one) and does anyone
have a quick solution for that?

Thanks for your help,
Nina



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From juli at ceam.es  Fri Apr 12 12:14:16 2002
From: juli at ceam.es (juli g. pausas)
Date: Fri, 12 Apr 2002 11:14:16 +0100
Subject: [R] writing a package for generalized linear mixed modesl
Message-ID: <3CB6B378.BBD73CB9@ceam.es>

Hi,

I think that "reglm"  fits GLM with random effects in S (see
http://www.statsci.org/s/reglm.html).
In fact I was looking for a R equivalent of reglm, but I didn't find it.

Juli


On Mon, 1 Apr 2002, Jason Liao wrote:

> Happy new month, everyone!
>
> I am planning to write a NIH grant proposal to study ways to speed
> Monte Carlo based maximum likelihood algorithm for hierarchical models

> with a focus on generalized linear mixed models (GLM with random
> effects). I thought it would be nice and also increase the chance of
> funding if I could produce an R package in the process. I understand
> that Prof. Pinheiro ang Bates have produced LME for linear mixed
models
> and NLME for non-linear mixed models. But these do not fit logistic
> mixed models or Poisson mixed models. SAS Proc NLMIXED can fit simple

GLME (beta, S-PLUS only) does.

> logistic or Poisson mixed models but the syntax is not specific for
> generalized mixed models. There can be only one level of random
> effects. STATA version 7 can fit random intercept models but not more.

> There are also some standalone programs such as MIXOR by Don Hendeker
> of Chicago. But it is hard to use a stnadalone program for data
> analysis efficiently because you have to convert the data set and you
> lose all the familiar tools for data transformation and graphics.
>
> I would appeciate your comments on the following points:
>
> 1. Is there a strong need for a package for generalized linear mixed
> models? Could someone have already written or in the process of
writing
> one?

See package GLMMgibbs on CRAN, function glmmPQL in package MASS and
function glmm (only a random intercept) in one of Jim Lindsey's
packages.

GLMMs are half a chapter in the upcoming fourth edition of Venables &
Ripley.

> 3. How big is the undertaking? I have some R code for GLMM that runs
at
> an acceptable speed. I can see that some part can benifit from
> converting to C or Fortran. I am not familiar with R's interface with
C
> and Fortran. I do not know either how to make the package available
for
> different platforms. Will the multi-platform issue become easier if I
> stay with 100% pure R?

100% pure R would be unacceptably slow.

I would rate this as a research problem, and a major undertaking.
GLMMgibbs is an existence proof, but not able to handle many quite
simple
problems.

--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-

r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch

_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Jussi.Makinen at valtiokonttori.fi  Fri Apr 12 11:31:47 2002
From: Jussi.Makinen at valtiokonttori.fi (=?iso-8859-1?Q?M=E4kinen_Jussi?=)
Date: Fri, 12 Apr 2002 12:31:47 +0300
Subject: [R] RE: Matrix to data.frame without factors
Message-ID: <7EFB6224454CD511B9D700306E00F4070199AB93@VKYHA01>

>> To answer at least partially to my own question:
>>
>> "na.to.0" <- function(x)
>> {
>> 	xx <- data.matrix(x)
>> 	xx[is.na(x)] <- 0
>> 	xx <- data.frame(xx)
>> 	xx
>> }
>>
>> seems to work (Idea is/was replace a data.frame NAs by 0s and return =
a
>> data.frame as a result).
>>
>> Still I'm a little bit confused with these converts but now I can mov=
e on.

>I'm confused by your questions.  Is this a data frame with only numeric
>columns?   If so, your comments about factors/characters make no sense,=
> and
>if not your conversion makes little sense.

>=46or a *numeric* data frame X

>X[] <- lapply(X, function(x) {x[is.na(x)] <- 0; x})

>seems to be what you want.

Here is a sample of my data.frame (KUNTADATA):



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Apr 12 11:32:53 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Fri, 12 Apr 2002 10:32:53 +0100 (BST)
Subject: [R] writing a package for generalized linear mixed modesl
In-Reply-To: <3CB6B378.BBD73CB9@ceam.es>
Message-ID: <Pine.GSO.4.44.0204121027330.14309-100000@auk.stats>

On Fri, 12 Apr 2002, juli g. pausas wrote:

> Hi,
>
> I think that "reglm"  fits GLM with random effects in S (see
> http://www.statsci.org/s/reglm.html).
> In fact I was looking for a R equivalent of reglm, but I didn't find it.

Look at glmmPQL as detailed below.  It's not the `equivalent of reglm', but
it does what reglm does, and much besides.

I looked at porting reglm to R, but its style is so inefficient S it
appeared to be better to rewrite it from scratch.  In the end I wrote code
for a more powerful approach.

>
> Juli
>
>
> On Mon, 1 Apr 2002, Jason Liao wrote:
>
> > Happy new month, everyone!
> >
> > I am planning to write a NIH grant proposal to study ways to speed
> > Monte Carlo based maximum likelihood algorithm for hierarchical models
>
> > with a focus on generalized linear mixed models (GLM with random
> > effects). I thought it would be nice and also increase the chance of
> > funding if I could produce an R package in the process. I understand
> > that Prof. Pinheiro ang Bates have produced LME for linear mixed
> models
> > and NLME for non-linear mixed models. But these do not fit logistic
> > mixed models or Poisson mixed models. SAS Proc NLMIXED can fit simple
>
> GLME (beta, S-PLUS only) does.
>
> > logistic or Poisson mixed models but the syntax is not specific for
> > generalized mixed models. There can be only one level of random
> > effects. STATA version 7 can fit random intercept models but not more.
>
> > There are also some standalone programs such as MIXOR by Don Hendeker
> > of Chicago. But it is hard to use a stnadalone program for data
> > analysis efficiently because you have to convert the data set and you
> > lose all the familiar tools for data transformation and graphics.
> >
> > I would appeciate your comments on the following points:
> >
> > 1. Is there a strong need for a package for generalized linear mixed
> > models? Could someone have already written or in the process of
> writing
> > one?
>
> See package GLMMgibbs on CRAN, function glmmPQL in package MASS and
> function glmm (only a random intercept) in one of Jim Lindsey's
> packages.
>
> GLMMs are half a chapter in the upcoming fourth edition of Venables &
> Ripley.
>
> > 3. How big is the undertaking? I have some R code for GLMM that runs
> at
> > an acceptable speed. I can see that some part can benifit from
> > converting to C or Fortran. I am not familiar with R's interface with
> C
> > and Fortran. I do not know either how to make the package available
> for
> > different platforms. Will the multi-platform issue become easier if I
> > stay with 100% pure R?
>
> 100% pure R would be unacceptably slow.
>
> I would rate this as a research problem, and a major undertaking.
> GLMMgibbs is an existence proof, but not able to handle many quite
> simple
> problems.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>
> r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Jussi.Makinen at valtiokonttori.fi  Fri Apr 12 11:50:46 2002
From: Jussi.Makinen at valtiokonttori.fi (=?iso-8859-1?Q?M=E4kinen_Jussi?=)
Date: Fri, 12 Apr 2002 12:50:46 +0300
Subject: [R] RE: Matrix to data.frame without factors
Message-ID: <7EFB6224454CD511B9D700306E00F4070199AB94@VKYHA01>

Sorry, last answer slipped away because accidental key shortcut typing.

Thank you for your reply. Here is a sample of my data.frame (KUNTADATA):

KUNTADATA[1:10,c(6:8, 20)]
                            Kunta Period Name Asunnot 1100 intarr_14
1  ESPOON KAUPUNKI                     1993/1        14164  41336.27
2  ESPOON KAUPUNKI                     1993/2        14164        NA
3  ESPOON KAUPUNKI                     1994/1        14164      0.00
4  ESPOON KAUPUNKI                     1994/2        14164    330.29
5  ESPOON KAUPUNKI                     1995/1        14164      0.00
6  ESPOON KAUPUNKI                     1995/2        14164      0.00
7  ESPOON KAUPUNKI                     1996/1        14164  67277.18
8  ESPOON KAUPUNKI                     1996/2        14164   7860.26
9  ESPOON KAUPUNKI                     1997/1        14164        NA
10 ESPOON KAUPUNKI                     1997/2        14164 231701.05


So there is both character vector and numerical vectors. But truly - I could
just use na.to.0 when neccessary with numerical rows. But because I have
face this "problem" with factors quite often I though that it might be a
common interest to ask my question.

Still I cannot understand the result:

> is.numeric(as.matrix(KUNTADATA[,15]))
[1] TRUE
> is.numeric(as.data.frame(as.matrix(KUNTADATA[,15])))
[1] FALSE


Yes, your code works nicely (as always) and do the trick I wanted, something
I couldn't write down myself. There is for me a lot to learn within R/Splus.
Thank you, I appreciated your help and this list,

Jussi Makinen

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Fri Apr 12 12:00:02 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 12 Apr 2002 12:00:02 +0200
Subject: [R] writing a package for generalized linear mixed modesl
In-Reply-To: <3CB6B378.BBD73CB9@ceam.es>
References: <3CB6B378.BBD73CB9@ceam.es>
Message-ID: <x2n0w9w82l.fsf@blueberry.kubism.ku.dk>

"juli g. pausas" <juli at ceam.es> writes:

> Hi,
> 
> I think that "reglm"  fits GLM with random effects in S (see
> http://www.statsci.org/s/reglm.html).
> In fact I was looking for a R equivalent of reglm, but I didn't find it.
> 
> Juli

Well, you could port it... (Or maybe Gordon is going to do that
himself eventually? I'm pretty sure he wouldn't have anything against
a GPL'ed port after talking with him in Odense last year.)

I did a quick check and it is slightly tricky because the code
accesses internals of glm family structures in a rather S-Plus
specific way. 

It's not like the information isn't there in R, though, just that
family$family["name"] doesn't work (the vector is there, but has no
names attribute in R), as.family is missing in R (but we do similar
stuff at the top of glm()), etc.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From macleod_lee at tynesys.com  Fri Apr 12 12:39:22 2002
From: macleod_lee at tynesys.com (Macleod Lee)
Date: Fri, 12 Apr 2002 18:39:22 +0800
Subject: [R] RJava , bitmap ,PNG
Message-ID: <KAEOJIKANNDONGNIOFFDAEBCCAAA.macleod_lee@tynesys.com>

Hi ,

I try to use Java -> RJava -> R to generate a image(PNG or JPEG)) , but it cause Java core dump .
Anyone can help me to slove this problem ?? Is it a proven solution ??

My computer enviroment : 
   OS: Solaris 8
   R : R-1.4.1
   SJava : 0.64
   Java : 1.3.1_03

Java Source code:
import org.omegahat.R.Java.ROmegahatInterpreter;
import org.omegahat.R.Java.REvaluator;
public class test2
{
public static void main(String[] args) {
  ROmegahatInterpreter interp = new ROmegahatInterpreter(ROmegahatInterpreter.fixArgs(args), false);
  REvaluator e = new REvaluator();

  e.eval("bitmap('z.png')");

}
}

Macleod
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From paul.quataert at lin.vlaanderen.be  Fri Apr 12 13:08:47 2002
From: paul.quataert at lin.vlaanderen.be (QUATAERT, Paul)
Date: Fri, 12 Apr 2002 13:08:47 +0200
Subject: [R] xgobi
Message-ID: <3CB6C03F.E1527B66@lin.vlaanderen.be>

Hi,

Just started with exploring R. Nice ! (for many years using Splus).

I tried to install and activate the package xgobi.
- first download of xgobi.zip
- then the R-command to install:
    install.packages('N:\\d024\\xgobi.zip',CRAN=NULL)
- finally the command to attach the library:
    library(xgobi)

Up to now, everything seemed to work. Also the help. No warnings that
the installation was not appropriate.

However when running the example of the help-file nothing seems to
happen.

After
     data(laser)
     xgobi(laser)

I get no reaction on the screen, only following message:

D:/soft/rw1041/library/xgobi/scripts/xgobi.bat -vtitle 'laser' -std mmx
C:/TEMP/xgobi-laser29358

Probably as a novice I forgot something to do. Has anybody a suggestion
?

Thanks,
Paul Quataert

======================================================
ir. Paul Quataert
Biostatisticus

Ministerie Vlaamse Gemeenschap
Instituut voor Bosbouw en Wildbeheer

Ministry of The Flemish Community
Institute for Forestry and Game Management

Gaverstraat 4
B-9500 Geraardsbergen
BELGIUM

Tel: +32-54-43.71.36
Fax: +32-54-43.61.60
Email: Paul.Quataert at lin.vlaanderen.be
======================================================




-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20020412/39617b21/attachment.html

From ripley at stats.ox.ac.uk  Fri Apr 12 13:18:02 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 12 Apr 2002 12:18:02 +0100 (BST)
Subject: [R] xgobi
In-Reply-To: <3CB6C03F.E1527B66@lin.vlaanderen.be>
Message-ID: <Pine.LNX.4.31.0204121211430.31084-100000@gannet.stats>

On Fri, 12 Apr 2002, QUATAERT, Paul wrote:

> Just started with exploring R. Nice ! (for many years using Splus).

On Windows I see, but you forgot to tell us that.  The installation is
rather different for the xgobi package under Unix and Windows.

> I tried to install and activate the package xgobi.
> - first download of xgobi.zip
> - then the R-command to install:
>     install.packages('N:\\d024\\xgobi.zip',CRAN=NULL)
> - finally the command to attach the library:
>     library(xgobi)
>
> Up to now, everything seemed to work. Also the help. No warnings that
> the installation was not appropriate.
>
> However when running the example of the help-file nothing seems to
> happen.
>
> After
>      data(laser)
>      xgobi(laser)
>
> I get no reaction on the screen, only following message:
>
> D:/soft/rw1041/library/xgobi/scripts/xgobi.bat -vtitle 'laser' -std mmx
> C:/TEMP/xgobi-laser29358
>
> Probably as a novice I forgot something to do. Has anybody a suggestion
> ?

Reading the documentation is always a good idea (and often forgotten).
>From the DESCRIPTION file:

   Suggests: xgobi must be installed additionally, see file INSTALL.



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From marlon at lscp.pqi.ep.usp.br  Fri Apr 12 13:42:27 2002
From: marlon at lscp.pqi.ep.usp.br (Marlon Martins dos Reis)
Date: Fri, 12 Apr 2002 08:42:27 -0300
Subject: [R] Problems with memory
Message-ID: <3CB6C818.FD0EEFA2@lscp.pqi.ep.usp.br>

Dear all,

I've started working with R (vs 1041) a few weeks ago, and now I'm
having problems with the amount of memory.
I'm working on the windows-me, my computer has 128 Mb of memory. I'm
using the R under the emacs (ESS-5.1.20) and it is started by the
command:
Rterm --min-vsize=10M --max-vsize=100M --min-nsize=500k --max-nsize=1M

I've been had problems when executing a loop like:
attach("data.Rdata")
for (i in 1:n)
{
         object1<-fun1(data...)
         object2<-fun2(...object1)
         object3<-fun3(...object2)
         object4[,i]<-fun4(...object3)
        rm("object1","object2","object3")
}
After few interactions  it stops with the message:
"Error: cannot allocate vector of size 7890 Kb
In addition: Warning message:
Reached total allocation of 127Mb: see help(memory.size)"

I thought that using "rm" I would avoid problem with memory. Did I miss
some point on using "rm"? Is there any other way to remove objects from
the memory?

Thanks in advance,
Marlon!!!


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Apr 12 14:03:02 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 12 Apr 2002 13:03:02 +0100 (BST)
Subject: [R] Problems with memory
In-Reply-To: <3CB6C818.FD0EEFA2@lscp.pqi.ep.usp.br>
Message-ID: <Pine.LNX.4.31.0204121256100.31287-100000@gannet.stats>

On Fri, 12 Apr 2002, Marlon Martins dos Reis wrote:

> Dear all,
>
> I've started working with R (vs 1041) a few weeks ago, and now I'm
> having problems with the amount of memory.
> I'm working on the windows-me, my computer has 128 Mb of memory. I'm
> using the R under the emacs (ESS-5.1.20) and it is started by the
> command:
> Rterm --min-vsize=10M --max-vsize=100M --min-nsize=500k --max-nsize=1M

The only flag it might be worth using is --max-mem-size (see the rw-FAQ).
Omit all the others.

> I've been had problems when executing a loop like:
> attach("data.Rdata")
> for (i in 1:n)
> {
>          object1<-fun1(data...)
>          object2<-fun2(...object1)
>          object3<-fun3(...object2)
>          object4[,i]<-fun4(...object3)
>         rm("object1","object2","object3")
> }
> After few interactions  it stops with the message:
> "Error: cannot allocate vector of size 7890 Kb
> In addition: Warning message:
> Reached total allocation of 127Mb: see help(memory.size)"
>
> I thought that using "rm" I would avoid problem with memory. Did I miss
> some point on using "rm"? Is there any other way to remove objects from
> the memory?

It's rm(object1, object2, object3) (no quotes).

You've told us very little of what is going on, but as you keep on
re-creating object1 to object3 in the loop, deleting them at the bottom is
almost pointless.  If you don't need the objects, why name them?
Just nest the calls.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rolf at math.unb.ca  Fri Apr 12 14:19:22 2002
From: rolf at math.unb.ca (Rolf Turner)
Date: Fri, 12 Apr 2002 09:19:22 -0300 (ADT)
Subject: [R] Summary: Obtaining names of ``...'' arguments.
Message-ID: <200204121219.JAA04247@tanner.math.unb.ca>


I received two answers to my inquiry:

(1) as.character(substitute(list(...)))[-1]

		(due to Thomas Lumley)

(2) as.character(match.call(expand.dots = FALSE)$"...")

		(due to Deepayan Sarkar)

Both seem to do exactly what I want.

Thanks.

					cheers,

						Rolf Turner
						rolf at math.unb.ca
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From schlatti at mailer.ukbf.fu-berlin.de  Fri Apr 12 14:20:34 2002
From: schlatti at mailer.ukbf.fu-berlin.de (Dr. Peter Schlattmann)
Date: Fri, 12 Apr 2002 14:20:34 +0200 (CEST)
Subject: [R] correlated binary random numbers
Message-ID: <Pine.LNX.4.21.0204121418170.15485-100000@postamt.ukbf.fu-berlin.de>

Dear all,

does any of you know a source for R code for
the generation of correlated binary random numbers?


Thanks a lot

Peter Schlattmann


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Jussi.Makinen at valtiokonttori.fi  Fri Apr 12 14:58:19 2002
From: Jussi.Makinen at valtiokonttori.fi (=?iso-8859-1?Q?M=E4kinen_Jussi?=)
Date: Fri, 12 Apr 2002 15:58:19 +0300
Subject: [R] RE: Matrix to data.frame without factors
Message-ID: <7EFB6224454CD511B9D700306E00F4070199AB95@VKYHA01>

Sorry, my previous answer slipped away because accidental key shortcut
typing when I was trying to copy/paste the example.
***

Thank you for your reply. Here is a sample of my data.frame (KUNTADATA):

KUNTADATA[1:10,c(6:8, 20)]
                            Kunta Period Name Asunnot 1100 intarr_14
1  ESPOON KAUPUNKI                     1993/1        14164  41336.27
2  ESPOON KAUPUNKI                     1993/2        14164        NA
3  ESPOON KAUPUNKI                     1994/1        14164      0.00
4  ESPOON KAUPUNKI                     1994/2        14164    330.29
5  ESPOON KAUPUNKI                     1995/1        14164      0.00
6  ESPOON KAUPUNKI                     1995/2        14164      0.00
7  ESPOON KAUPUNKI                     1996/1        14164  67277.18
8  ESPOON KAUPUNKI                     1996/2        14164   7860.26
9  ESPOON KAUPUNKI                     1997/1        14164        NA
10 ESPOON KAUPUNKI                     1997/2        14164 231701.05


So there is both type of vectors: characterical and numerical. But truly - I
could just use na.to.0 when neccessary with numerical rows. But because I
have faced this "problem" with conversions quite often I though that it
might be a common interest to ask my question.

I still cannot understand the result:

> is.numeric(as.matrix(KUNTADATA[,15]))
[1] TRUE
> is.numeric(as.data.frame(as.matrix(KUNTADATA[,15])))
[1] FALSE
> mode(as.data.frame(as.matrix(KUNTADATA[1,15])))
[1] "list"

I'm sure that I just do not get the basic feature behind data.frame()
function and that would be valuable for me and might be to somebody else as
well.

Yes, your code works nicely (as always) and do the trick I wanted, something
I couldn't write down myself. There is for me a lot to learn within R/Splus.
Thank you, I appreciated your help and all the learning I have achieved
through the list,

Jussi Makinen
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Apr 12 15:27:17 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 12 Apr 2002 14:27:17 +0100 (BST)
Subject: [R] RE: Matrix to data.frame without factors
In-Reply-To: <7EFB6224454CD511B9D700306E00F4070199AB95@VKYHA01>
Message-ID: <Pine.LNX.4.31.0204121416530.1688-100000@gannet.stats>

On Fri, 12 Apr 2002, [iso-8859-1] Mkinen Jussi wrote:

> Sorry, my previous answer slipped away because accidental key shortcut
> typing when I was trying to copy/paste the example.
> ***
>
> Thank you for your reply. Here is a sample of my data.frame (KUNTADATA):
>
> KUNTADATA[1:10,c(6:8, 20)]
>                             Kunta Period Name Asunnot 1100 intarr_14
> 1  ESPOON KAUPUNKI                     1993/1        14164  41336.27
> 2  ESPOON KAUPUNKI                     1993/2        14164        NA
> 3  ESPOON KAUPUNKI                     1994/1        14164      0.00
> 4  ESPOON KAUPUNKI                     1994/2        14164    330.29
> 5  ESPOON KAUPUNKI                     1995/1        14164      0.00
> 6  ESPOON KAUPUNKI                     1995/2        14164      0.00
> 7  ESPOON KAUPUNKI                     1996/1        14164  67277.18
> 8  ESPOON KAUPUNKI                     1996/2        14164   7860.26
> 9  ESPOON KAUPUNKI                     1997/1        14164        NA
> 10 ESPOON KAUPUNKI                     1997/2        14164 231701.05
>
>
> So there is both type of vectors: characterical and numerical. But truly - I

There are 6 types of vectors in R:  logical, integer, numeric, complex,
character and list aka `generic')!

> could just use na.to.0 when neccessary with numerical rows. But because I
> have faced this "problem" with conversions quite often I though that it
> might be a common interest to ask my question.
>
> I still cannot understand the result:
>
> > is.numeric(as.matrix(KUNTADATA[,15]))
> [1] TRUE
> > is.numeric(as.data.frame(as.matrix(KUNTADATA[,15])))
> [1] FALSE
> > mode(as.data.frame(as.matrix(KUNTADATA[1,15])))
> [1] "list"
>
> I'm sure that I just do not get the basic feature behind data.frame()
> function and that would be valuable for me and might be to somebody else as
> well.

data.frames allow colunns of different types. Matrices do not. So if
column 15 is numeric (and how can we tell, it is not in your sample!)
then as.matrix(KUNTADATA[,15]) is a one-dimensional numeric matrix.

as.data.frame(as.matrix(KUNTADATA[,15])) is a data frame with one
column.  Data frames are a class, based on a list, hence the rest of
your results.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From sway at tanox.com  Fri Apr 12 15:50:21 2002
From: sway at tanox.com (Shawn Way)
Date: Fri, 12 Apr 2002 08:50:21 -0500
Subject: [R] Lattice Package...
Message-ID: <0565F48FC373D411BE4D00B0D049602628E76F@nt40hou1.tanox.com>


I have two questions:

1.  I've tried to use the lattice package with the development version of R
(1.5.0), windows 2000, and it consistantly crashes RGUI and Rterm, on two
seperate installations...

2. The real question...  Is it possible to change the barchart horizontal
bars on lattice to give vertical bars?  If so, could you please give me a
hint on how to do so?

Thanks,

Shawn Way
Process Engineer
Tanox, Inc.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Apr 12 16:27:31 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 12 Apr 2002 15:27:31 +0100 (BST)
Subject: [R] Lattice Package...
In-Reply-To: <0565F48FC373D411BE4D00B0D049602628E76F@nt40hou1.tanox.com>
Message-ID: <Pine.LNX.4.31.0204121523130.1871-100000@gannet.stats>

On Fri, 12 Apr 2002, Shawn Way wrote:

>
> I have two questions:
>
> 1.  I've tried to use the lattice package with the development version of R
> (1.5.0), windows 2000, and it consistantly crashes RGUI and Rterm, on two
> seperate installations...

You do need grid 0.6 and lattice 0.5, and those are in the 1.5.0 areas
on CRAN.

You gave us no idea where you got `the development version of R' from,
nor who compiled it ....  Please take this up with whoever did provide it.

Today's R-devel sources and the current versions of grid and lattice
do work under Windows (but lattice gives some spurious debugging output).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From david.meyer at ci.tuwien.ac.at  Fri Apr 12 16:39:12 2002
From: david.meyer at ci.tuwien.ac.at (David Meyer)
Date: Fri, 12 Apr 2002 16:39:12 +0200
Subject: [R] correlated binary random numbers
References: <Pine.LNX.4.21.0204121418170.15485-100000@postamt.ukbf.fu-berlin.de>
Message-ID: <3CB6F190.F5F89FCD@ci.tuwien.ac.at>

"Dr. Peter Schlattmann" wrote:
> 
> Dear all,
> 
> does any of you know a source for R code for
> the generation of correlated binary random numbers?

look at package: ``bindata''

g.
-d

> 
> Thanks a lot
> 
> Peter Schlattmann
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
	Mag. David Meyer		Wiedner Hauptstrasse 8-10
Vienna University of Technology		A-1040 Vienna/AUSTRIA
         Department of			Tel.: (+431) 58801/10772
Statistics and Probability Theory	mail: david.meyer at ci.tuwien.ac.at
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From klavan at tiscalinet.it  Fri Apr 12 16:37:47 2002
From: klavan at tiscalinet.it (Ambrosini Alessandro)
Date: Fri, 12 Apr 2002 16:37:47 +0200
Subject: [R] Help
Message-ID: <PPEGLLABFLFCJDLCGPGHEEHACAAA.klavan@tiscalinet.it>

I have an adjacency matrix and I want to obtain a matrix of the minimum
paths between the nodes. Thank you
Alessandro Ambrosini

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jg_liao at yahoo.com  Fri Apr 12 16:42:53 2002
From: jg_liao at yahoo.com (Jason Liao)
Date: Fri, 12 Apr 2002 07:42:53 -0700 (PDT)
Subject: [R] summary: Generalized linear mixed model software
Message-ID: <20020412144253.7958.qmail@web10507.mail.yahoo.com>

Thanks to those who responded to my inquiry about generalized linear
mixed models on R and S-plus. Before I summarize the software, I note
that there are several ways of doing statistical inference for
generalized linear mixed models:

(1)Standard maximum likelihood estimation, computationally intensive
due to intractable likelihood function

(2) Penalized quasi likelihood or similar approximations (Breslow &
Clayton, 1993; Lee & Nelder, 1999, Schall 1991). This method is not
good for binomial outcomes in particular. Theoretically, it is
consistent when the cluster size increases. It is not consistent when
the number of clusters increases while the size of each cluster remain
constant. The standard MLE (1) is consistent under either increasing
cluster size or the number of clusters. For theoretical result, see
Lin, X. & Breslow N.E. (1996) in JASA. For empirical demonstartion, see
Carlin et al (2001) in Biostatistics. 

(3)Bayesian approach. See for example, Clayton, D. G. (1996).
Generalized linear mixed models. In Markov Chain Monte Carlo in
Practice, Ed W.R. Gilks, S. Richardson & D.J. Spiegelhalter, pp.
275-301. London: Chapman and Hall. 

(4)REML estimation in GLMM. I will have a paper in June issue of
Bioemtrika. REML estimation has the same asymptotic property as
standard MLE but less bias for finite samples. Of course, one can argue
that Bayesian formulation automatically generates REML for variance
components.

Now the software.

PQL and variations: GLME in beta by Jos Pinheiro,  reglm by Gordon
Smyth, glmmPQL in package MASS  by Venables & Ripley 

Bayesian method: GLMMgibbs and BUGS (not a R or S-plus package).
 
Standard MLE: glmm (only a random intercept) in one of Jim Lindsey's
packages?

	Ok, this still leaves us without a good way of doing standard MLE. I
have programmed standard MLE using R. It takes 6 minutes for a
clustered binary outcome dataset, with 50 clusters and each cluster
with 10 binary responses, 6 fixed effects and two random effects for
each cluster. 





 

 

=====
Jason G. Liao, Ph.D.
Division of Biometrics
University of Medicine and Dentistry of New Jersey
335 George Street, Suite 2200
New Brunswick, NJ 08903-2688
phone (732) 235-9748, fax (732) 235-9777
http://www.geocities.com/jg_liao

__________________________________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From david.barron at jesus.ox.ac.uk  Fri Apr 12 16:48:14 2002
From: david.barron at jesus.ox.ac.uk (David Barron)
Date: Fri, 12 Apr 2002 15:48:14 +0100
Subject: [R] Help
References: <PPEGLLABFLFCJDLCGPGHEEHACAAA.klavan@tiscalinet.it>
Message-ID: <015201c1e231$13ad8ba0$cb8801a3@sbs.ox.ac.uk>

Look at the function geodist in the package sna.

David


----- Original Message -----
From: "Ambrosini Alessandro" <klavan at tiscalinet.it>
To: <R-help at stat.math.ethz.ch>
Sent: Friday, April 12, 2002 3:37 PM
Subject: [R] Help


> I have an adjacency matrix and I want to obtain a matrix of the minimum
> paths between the nodes. Thank you
> Alessandro Ambrosini
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
>
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ggrothendieck at yifan.net  Fri Apr 12 16:57:05 2002
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Fri, 12 Apr 2002 10:57:05 -0400
Subject: [R] Parrot
Message-ID: <3CB6BD81.15685.D84604@localhost>

This is just an idea for comment.  Perl6, the upcoming version of Perl has
separated out the runtime into a virtual machine called Parrot.  There are
already several small languages (one is C-like, one is Java-like and one is
BASIC-like) that target Parrot and given the popularity of Perl its likely that
others may attempt to target it too.

If R could interface easily with Parrot then it might be possible to use this
to interface with a large number of scripting languages in the future with
little or no additional interfacing work per language.

See www.parrotcode.org .

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From valdentro at hotmail.com  Fri Apr 12 17:37:54 2002
From: valdentro at hotmail.com (juan pablo perez)
Date: Fri, 12 Apr 2002 15:37:54 +0000
Subject: [R] add columns to a data.frame
Message-ID: <F1413KDKNLg00IwYrVP00009247@hotmail.com>



Dear R community:

it is possible to add a column wich results from an algebraic combination of 
columns from a data frame to the same data frame?

e.g

I have a data frame like
$X: num[1:10] 10,20,25,20...
$Y: num[1:10] 152,458,698,587,...
and I want to add a new column like
$Z where Z=X+5*Y

what should I do?

Thanks in advance

Juan Pablo



_________________________________________________________________
Hable con sus amigos en l?nea, pruebe MSN Messenger: http://messenger.msn.es

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ernesto at ipimar.pt  Fri Apr 12 18:56:29 2002
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 12 Apr 2002 17:56:29 +0100
Subject: [R] problem with do.call or how to speed code avoiding for()
	loops [SUMMARY]
In-Reply-To: <1018440005.19767.25.camel@gandalf>
References: <1018440005.19767.25.camel@gandalf>
Message-ID: <1018630589.27223.887.camel@gandalf>

Hi

These is the summary of the discussion about do.call posted on Wed,
2002-04-10 at 13:00, by Ernesto Jardim.

The initial problem was about the use of do.call function. The purpose
was to avoid for() loops and speed up code.

Regarding do.call it was referred by Peter Dalgaard that do.call is for
"situations where the argument list of a single call needs to be
constructed from simpler components".

Also Peter said that, to loop over paralel vectors something like lapply
should be used and presented a napply function example.

Thomas Lumley raised the problem that for() loops should only be avoided
if one is using vectorised functions and explained what it means (see
message bellow).

Ernesto Jardim questioned the fact that, if the family of apply
functions are writean entirly in R, then these functions would only be
usefull for simplicity in writing code.

Several messages referred that apply is only R code. Douglas Bates said
that "S Programming" discuss the need to profile the code before
implementing changes, if one wants to make it faster. Thomas referred to
paralel processing and the increase in speed that it will bring to
apply() when it will be implemented.

Prof. Ripley answered this issue saying that apply() just streamlines a
for() loop but lapply() is faster (it makes a call to compiled code) and
its use is encouradge. Also stating that apply() is a matter of style.

All relevant messages are pasted bellow. If something is wrong in this
summary please let me know and I'll correct it.

Regards

EJ   

---------------------------------------
Starting message: On Wed, 2002-04-10 at 13:00, Ernesto Jardim wrote:

Hi

I'm writing a function that uses four parameters (scalars) and I need to
run it in an iterative process (the parameters vary to find the minimum
RSS). 

I don't want to use loops and so tried the do.call function. However it
didn't work. My understanding is that the do.call simple runs the
function replacing the arguments (scalars by vectors), instead of runing
the function for each set of scalars in the list, what I need.

Can you please tell me if there is another way of doing it whithout
using the for loop ?

Thanks

EJ

ps: Follows an example (off course the example doesn't make much sense
but describes the problem).

> fun
function(a,b){

        vec <- rnorm(25)
        res <- a*vec^b
        res

}
> fun(2,3)
 [1]  7.006278e+00  3.515010e-01  7.989718e+00 -3.377766e-02
-1.879471e-02
 [6] -2.920680e-01  1.174834e+00 -1.088638e-03  6.448725e+00 
2.591805e+00
[11] -4.313672e-04 -9.171867e-03 -6.793569e+00 -2.480562e+01
-1.514828e+01
[16] -1.259896e-01 -7.504192e-02  6.647855e-02  5.609645e-01 
1.093114e-01
[21]  1.802123e+00  7.650033e-03 -3.534951e+00 -2.028473e-03
-2.837360e+01
> do.call("fun",list(a=c(1:6),b=rnorm(6)))
 [1]  1.4766338        NaN  3.0214852  3.8132530  0.2753699        NaN
 [7]        NaN        NaN  2.9998547        NaN        NaN  6.3050385
[13]  0.5970596  0.8722498  2.9931344  4.0664852        NaN        NaN
[19]  2.8121803        NaN  2.9989127        NaN        NaN        NaN
[25] 14.4631627
Warning messages: 
1: longer object length
        is not a multiple of shorter object length in: vec^b 
2: longer object length
        is not a multiple of shorter object length in: a * vec^b 
> 

---------------------------------------
Peter Dalgaard:

That's not what do.call does. It is for situations where the argument
list of a single call needs to be constructed from simpler components.
Your example is equivalent to fun(a=c(1:6), b=rnorm(6))

The loop over multiple parallel vectors is only doable via something
like lapply(1:6, function(i)fun(a[i],b[i]))

However, I recently played with this and got as far as this:

napply <-
function(..., FUN) {
   FUN <- match.fun(FUN)
   x <- list(...)
   lens <- sapply(x,length)
   len <- max(lens)
   if (any(lens != len))
      x <- lapply(x, rep, length=len)
   tuples <- lapply(seq(length=len), function(i)lapply(x,"[", i))
   sapply(tuples, function(t)eval(as.call(c(FUN,t))))
}

>  napply(a=c(1:6),b=rnorm(6), FUN=fun)
           [,1]     [,2]     [,3]       [,4]     [,5]        [,6]
 [1,] 1.0259135      NaN 3.003882        NaN      NaN   20.299212
 [2,]       NaN 1.977696 3.026111        NaN 3.951746   19.107481
 [3,] 1.1840499 2.024837      NaN   8.289768      NaN    7.479917
 [4,] 0.9756922 2.003576      NaN        NaN 4.236000         NaN
 [5,] 1.0010550 2.006045      NaN        NaN      NaN 1302.330425
 [6,]       NaN      NaN      NaN   2.472650      NaN         NaN
 [7,]       NaN 2.094956      NaN        NaN      NaN    3.685879
 [8,] 0.8646628      NaN 2.993435        NaN 3.369501         NaN
 [9,]       NaN 2.044915 3.006433   6.426090 6.123980   19.235790
[10,] 1.6051736      NaN 3.011986        NaN 3.638641         NaN
....

> > fun
> function(a,b){
> 
>         vec <- rnorm(25)
>         res <- a*vec^b
>         res
> 
> }
> > fun(2,3)
>  [1]  7.006278e+00  3.515010e-01  7.989718e+00 -3.377766e-02
> -1.879471e-02
>  [6] -2.920680e-01  1.174834e+00 -1.088638e-03  6.448725e+00 
> 2.591805e+00
> [11] -4.313672e-04 -9.171867e-03 -6.793569e+00 -2.480562e+01
> -1.514828e+01
> [16] -1.259896e-01 -7.504192e-02  6.647855e-02  5.609645e-01 
> 1.093114e-01
> [21]  1.802123e+00  7.650033e-03 -3.534951e+00 -2.028473e-03
> -2.837360e+01
> > do.call("fun",list(a=c(1:6),b=rnorm(6)))
>  [1]  1.4766338        NaN  3.0214852  3.8132530  0.2753699        NaN
>  [7]        NaN        NaN  2.9998547        NaN        NaN  6.3050385
> [13]  0.5970596  0.8722498  2.9931344  4.0664852        NaN        NaN
> [19]  2.8121803        NaN  2.9989127        NaN        NaN        NaN
> [25] 14.4631627
> Warning messages: 
> 1: longer object length
>         is not a multiple of shorter object length in: vec^b 
> 2: longer object length
>         is not a multiple of shorter object length in: a * vec^b 
> > 

---------------------------------------
Thomas Lumley:

And why wouldn't you want to use the for() loop?  Unless your function
is vectorised you're not going to gain anything by getting rid of the
for() loop.

Definition of vectorised function by Thomas:

Many R functions can operate on a vector of parameter values, eg

log(10,c(2,e,10)) gives the log of 10 to base 2, e, and 10

If your function can do this, you can construct a set of vectors
containing all your parameter values (expand.grid() is useful for this)
and evaluate your function once.

This can be faster than for() loops when much of the iteration is done
in compiled code. If the iteration has to be done in interpreted code
then you can't really speed up the for() loops.  You can hide the loops
with the apply() functions, which may make your code more readable, but
it won't typically speed it up.

---------------------------------------
Ernesto Jardim:

This was not my understanding. I thougth that if you can use functions
like apply and similar instead of for loops your code will be faster.
Basicly relying on these functions code which is (should be) optimized
for speed.

If what you're saying is true then using functions like apply is a
matter of simplicity and not speeding up the code. 

Is this correct ?

---------------------------------------
Douglas Bates:

Yes.

If you examine the apply function you will see that the bulk of the
work is done in a loop

    if (length(d.call) < 2) {
        if (length(dn.call)) 
            dimnames(newX) <- c(dn.call, list(NULL))
        for (i in 1:d2) ans[[i]] <- FUN(newX[, i], ...)
    }
    else for (i in 1:d2) ans[[i]] <- FUN(array(newX[, i], d.call, 
        dn.call), ...)

In their book "S Programming" (Springer, 2000) Venables and Ripley
discuss general strategies for writing R functions and for making them
faster.  One general principle is to profile the code before
implementing changes.  The manual "Writing R Extensions" has a section
on "Profiling R code" which is highly recommended.

---------------------------------------
Thomas Lumley:

Yes. As you can easily verify [and always should verify if you're doing
optimisation], the apply commands are rarely faster than their for()
loop equivalents. They can be slower.
The speed advantage of apply is partly mythical -- there's never been
that much advantage -- and partly historical, as in some versions of
S-PLUS 3.x apply was often faster for complicated reasons due to memory
management.

The real point of the apply() family is to suppress unnecessary loop
variables and make your code tidier.  If we ever get parallel processing
then apply() could really become faster, but that's not going to happen
any time soon.

---------------------------------------
Brian Ripley:

I think that is a little pessimistic. It is true for apply() in R, which
just streamlines a for() loop, and also does things you may not want.
However, lapply is an internal function (written by me) because it is
sometimes a lot faster, and in my experiments never slower.

lapply() was a lot faster in S-PLUS 3.4.  It was often slower than for()
in 5.0, hence a lot of consternation.   There *are* a lot of myths
about,
but not all in one direction.  As others have said, `S Programming'
tries
to give a balanced view across 3 different S implementations, and
profiling can be a great tool in optimizing code (it can be misleading
too, but rarely when it matters).

Summary: lapply is encouraged.  apply is a matter of style.  Test out
whatever you do to see if it is really worthwhile.



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thoar at cgd.ucar.edu  Fri Apr 12 17:57:55 2002
From: thoar at cgd.ucar.edu (Tim Hoar)
Date: Fri, 12 Apr 2002 09:57:55 -0600 (MDT)
Subject: [R] documentation widget
Message-ID: <Pine.GSO.4.30.0204021149030.28519-100000@sunray1>

If imitation is the sincerest form of flattery ...

I am thinking of imitating the R documentation mechanism.

I have a largeish software project that needs documentation for
each of the functions/modules. The ability to create html, latex,
and pdf documentation from one source is very attractive. Since
my collaborators already know html and latex there is little
incentive to learn XML ... but using latex as the source seems
overly complicated. Using the Rd boilerplate seems much simpler
than trying to use raw latex.

I have looked under R's hood at Rdconv and would like to see if
I could make it work outside the R environment.

Any objections from the authors?

I intend to follow the spirit of the GNU license and will zing it
back to you after I've finished with it (if I need to make any
changes, that is).

Thanks. Once again, you are way ahead of me -- Tim

## Tim Hoar, Associate Scientist              email: thoar at ucar.edu     ##
## Geophysical Statistics Project             phone: 303-497-1708       ##
## National Center for Atmospheric Research   FAX  : 303-497-1333       ##
## Boulder, CO  80307                    http://www.cgd.ucar.edu/~thoar ##

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pflugshaupt at geobot.umnw.ethz.ch  Fri Apr 12 18:08:52 2002
From: pflugshaupt at geobot.umnw.ethz.ch (Kaspar Pflugshaupt)
Date: Fri, 12 Apr 2002 18:08:52 +0200
Subject: [R] add columns to a data.frame
In-Reply-To: <F1413KDKNLg00IwYrVP00009247@hotmail.com>
Message-ID: <B8DCD334.82A4%pflugshaupt@geobot.umnw.ethz.ch>

On 12.4.2002 17:37 Uhr, juan pablo perez wrote:

> it is possible to add a column wich results from an algebraic combination of
> columns from a data frame to the same data frame?
> 
> e.g
> 
> I have a data frame like
> $X: num[1:10] 10,20,25,20...
> $Y: num[1:10] 152,458,698,587,...
> and I want to add a new column like
> $Z where Z=X+5*Y
> 
> what should I do?

Just this (assuming your data frame is called "data"):

data$Z <- data$X + 5 * data$Y

The new column is created automatically.

You may want to read the "Introduction to R" manual that came with the
software. This is quite a basic way to use data frames.

Cheers

Kaspar Pflugshaupt


-- 

Kaspar Pflugshaupt
Geobotanisches Institut
Zuerichbergstr. 38
CH-8044 Zuerich

Tel. ++41 1 632 43 19
Fax  ++41 1 632 12 15

mailto:pflugshaupt at geobot.umnw.ethz.ch
privat:pflugshaupt at mails.ch
http://www.geobot.umnw.ethz.ch

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Fri Apr 12 18:06:31 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri, 12 Apr 2002 12:06:31 -0400
Subject: [R] How to specify search order for require()
Message-ID: <20020412120631.7726eb8e.fharrell@virginia.edu>

In a .First.lib I want to issue two require()s to insure that two other packages are loaded.  But I want the package being loaded by .First.lib using library.dynam("mypackage",pkb,lib) to be higher in the search order than the two required packages, because I want to have a couple of functions from the two required packages overridden.  What is the best way to do that?  Thanks in advance -Frank

-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at blindglobe.net  Fri Apr 12 18:27:58 2002
From: rossini at blindglobe.net (A.J. Rossini)
Date: 12 Apr 2002 09:27:58 -0700
Subject: [R] How to specify search order for require()
In-Reply-To: <20020412120631.7726eb8e.fharrell@virginia.edu>
References: <20020412120631.7726eb8e.fharrell@virginia.edu>
Message-ID: <871ydk286p.fsf@jeeves.blindglobe.net>

>>>>> "frank" == Frank E Harrell, <Frank> writes:

    frank> In a .First.lib I want to issue two require()s to insure
    frank> that two other packages are loaded.  But I want the package
    frank> being loaded by .First.lib using
    frank> library.dynam("mypackage",pkb,lib) to be higher in the
    frank> search order than the two required packages, because I want
    frank> to have a couple of functions from the two required
    frank> packages overridden.  What is the best way to do that?
    frank> Thanks in advance -Frank 

Good question.  If you find out, let me know, too!

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M-W: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my friday location is usually completely unpredictable.)


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Fri Apr 12 18:31:00 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 12 Apr 2002 09:31:00 -0700 (PDT)
Subject: [R] How to specify search order for require()
In-Reply-To: <20020412120631.7726eb8e.fharrell@virginia.edu>
Message-ID: <Pine.A41.4.44.0204120925440.232216-100000@homer05.u.washington.edu>

On Fri, 12 Apr 2002, Frank E Harrell Jr wrote:

> In a .First.lib I want to issue two require()s to insure that two other
> packages are loaded.  But I want the package being loaded by .First.lib
> using library.dynam("mypackage",pkb,lib) to be higher in the search
> order than the two required packages, because I want to have a couple of
> functions from the two required packages overridden.  What is the best
> way to do that?  Thanks in advance -Frank

This would really need library() and require() to take a pos= argument (I
don't see why they shouldn't, but given the current feature freeze it's
not happening right now).

A work-around is to define two packages, say,
"mypackage" and "my.actual.package" and bundle them together.

.First.lib in "mypackage" would require() the two additional packages and
then require() "my.actual.package".

.First.lib in "my.actual.package" would check that the required packages
(and "mypackage") had been loaded, and otherwise give an error telling the
user to use library(mypackage) instead of library(my.actual.package).

As one of the comments in the R source code says in a different context,
this is the sort of thing that gives horrible hacks a bad name, but it
should work.

	-thomas


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deepayansarkar at yahoo.com  Fri Apr 12 18:34:30 2002
From: deepayansarkar at yahoo.com (Deepayan Sarkar)
Date: Fri, 12 Apr 2002 09:34:30 -0700 (PDT)
Subject: [R] Lattice Package...
In-Reply-To: <0565F48FC373D411BE4D00B0D049602628E76F@nt40hou1.tanox.com>
Message-ID: <20020412163430.84513.qmail@web13904.mail.yahoo.com>


--- Shawn Way <sway at tanox.com> wrote:
> 
> I have two questions:
> 
> 2. The real question...  Is it possible to change the barchart horizontal
> bars on lattice to give vertical bars?  If so, could you please give me a
> hint on how to do so?

This should be doable in the development version of Lattice. There is an 
example in example(xyplot), and it's exactly as you would expect (I hope);
i.e, you would get  vertical bars if you do 

barchart(y~x)

where x is a factor/shingle/character vector and y is numeric. 
If you really want this when x is numeric, you have to additionally give

barchart(y~x, horizontal = FALSE)

One issue is how to write the levels of x on the x-axis. If the labels are 
long, I would suggest either 

scales = list(x=list(rot = 90))

or

scales = list(x=list(abbreviate = TRUE))


-Deepayan


__________________________________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From apjaworski at mmm.com  Fri Apr 12 18:40:21 2002
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Fri, 12 Apr 2002 11:40:21 -0500
Subject: [R] add columns to a data.frame
Message-ID: <OF092D8DAB.B1CAFD74-ON86256B99.005B5CA1@mmm.com>


Yes.  Here is one way of doing this:

> zz <- data.frame(x=1:10, y=rnorm(10))
> zz
    x           y
1   1  0.43665715
2   2 -0.23219549
3   3  0.20102028
4   4  0.85460148
5   5  1.83858972
6   6  0.83336441
7   7 -0.01167367
8   8 -0.08473429
9   9  0.52357340
10 10  0.23190303

> zz$z <- zz$x*10+zz$y
> zz

    x           y         z
1   1  0.43665715  10.43666
2   2 -0.23219549  19.76780
3   3  0.20102028  30.20102
4   4  0.85460148  40.85460
5   5  1.83858972  51.83859
6   6  0.83336441  60.83336
7   7 -0.01167367  69.98833
8   8 -0.08473429  79.91527
9   9  0.52357340  90.52357
10 10  0.23190303 100.23190

Cheers,

Andy
__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


                                                                                                                                               
                    "juan pablo                                                                                                                
                    perez"               To:     r-help at stat.math.ethz.ch                                                                      
                    <valdentro at hotm      cc:     (bcc: Andrzej P. Jaworski/US-Corporate/3M/US)                                                 
                    ail.com>             Subject:     [R] add columns to a data.frame                                                          
                                                                                                                                               
                    04/12/2002                                                                                                                 
                    10:37                                                                                                                      
                                                                                                                                               
                                                                                                                                               






Dear R community:

it is possible to add a column wich results from an algebraic combination
of
columns from a data frame to the same data frame?

e.g

I have a data frame like
$X: num[1:10] 10,20,25,20...
$Y: num[1:10] 152,458,698,587,...
and I want to add a new column like
$Z where Z=X+5*Y

what should I do?

Thanks in advance

Juan Pablo



_________________________________________________________________
Hable con sus amigos en lnea, pruebe MSN Messenger:
http://messenger.msn.es

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._._


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From clange at epost.de  Fri Apr 12 18:50:02 2002
From: clange at epost.de (Christoph Lange)
Date: Fri, 12 Apr 2002 18:50:02 +0200
Subject: [R] add columns to a data.frame
In-Reply-To: <F1413KDKNLg00IwYrVP00009247@hotmail.com>; from valdentro@hotmail.com on Fri, Apr 12, 2002 at 03:37:54PM +0000
References: <F1413KDKNLg00IwYrVP00009247@hotmail.com>
Message-ID: <20020412185002.H1568@rivka.biologie.fu-berlin.de>

(Reply to juan pablo perez)

> Dear R community:
> 
> it is possible to add a column wich results from an algebraic combination of 
> columns from a data frame to the same data frame?
> 
> e.g
> 
> I have a data frame like
> $X: num[1:10] 10,20,25,20...
> $Y: num[1:10] 152,458,698,587,...
> and I want to add a new column like
> $Z where Z=X+5*Y
> 
> what should I do?

Use

  cbind.data.frame



Christoph.
-- 
Christoph Lange                                    clange at epost.de
Verhaltensbiologie, FU Berlin                            838-55068
Haderslebener Str. 9, 12163 Berlin
http://www.verhaltensbiologie.fu-berlin.de/
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ozric at web.de  Fri Apr 12 19:20:30 2002
From: ozric at web.de (christian)
Date: Fri, 12 Apr 2002 19:20:30 +0200
Subject: [R] plot-history
Message-ID: <E16w4dA-0006Tc-00@smtp.web.de>

Hi,
how is it possible that the several
plot devices are not closed, or better how i can use
a plot history. 



normal <- function(x) {
    par(mfrow=c(2,2))
    hist(x)
    boxplot(x)
    sd <- summary(x)[5] - summary(x)[2]
    plot(density(x,width=2*sd),xlab="x",ylab="",type="l")
    qqnorm(x)
    qqline(x)
    }
    
apply(data,2,normal)
    

thanks for advance
& regards,Christian

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From luke at stat.umn.edu  Fri Apr 12 19:45:17 2002
From: luke at stat.umn.edu (Luke Tierney)
Date: Fri, 12 Apr 2002 12:45:17 -0500
Subject: [R] How to specify search order for require()
In-Reply-To: <20020412120631.7726eb8e.fharrell@virginia.edu>; from fharrell@virginia.edu on Fri, Apr 12, 2002 at 12:06:31PM -0400
References: <20020412120631.7726eb8e.fharrell@virginia.edu>
Message-ID: <20020412124517.C8205@nokomis.stat.umn.edu>

As of 1.4 (I believe) packages loaded by a require in the package
source, as oopsed to .First.lib, are loaded after the package that
calls require.  This was done in part to allow packages to
require(methods) and then use functions defined in methods within the
package body.

Hopefully R 1.6 will add a name space mechanism that will provide much
finer control over package dependencies; some information on how that
might work along with a draft implementation is available off the
developer page developer.r-project.org or at
http://www.stat.umn.edu/~luke/R/namespaces/morenames.html.

luke

On Fri, Apr 12, 2002 at 12:06:31PM -0400, Frank E Harrell Jr wrote:
> In a .First.lib I want to issue two require()s to insure that two other packages are loaded.  But I want the package being loaded by .First.lib using library.dynam("mypackage",pkb,lib) to be higher in the search order than the two required packages, because I want to have a couple of functions from the two required packages overridden.  What is the best way to do that?  Thanks in advance -Frank
> 
> -- 
> Frank E Harrell Jr              Prof. of Biostatistics & Statistics
> Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
> U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
Luke Tierney
University of Minnesota                      Phone:           612-625-7843
School of Statistics                         Fax:             612-624-8868
313 Ford Hall, 224 Church St. S.E.           email:      luke at stat.umn.edu
Minneapolis, MN 55455 USA                    WWW:  http://www.stat.umn.edu
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From luke at stat.umn.edu  Fri Apr 12 20:00:58 2002
From: luke at stat.umn.edu (Luke Tierney)
Date: Fri, 12 Apr 2002 13:00:58 -0500
Subject: [R] Parrot
In-Reply-To: <3CB6BD81.15685.D84604@localhost>; from ggrothendieck@yifan.net on Fri, Apr 12, 2002 at 10:57:05AM -0400
References: <3CB6BD81.15685.D84604@localhost>
Message-ID: <20020412130058.D8205@nokomis.stat.umn.edu>

The last time I looked at parrot (a couple of months or so ago, so
things may be quite different) parrot was still in very early
development stages (it had no proper memory management system yet, for
example). At this point it is still very unclear whether anyone
outside of perl is interested in what they are doing.  The python
folks in particular don't seem very excited about it as far as I can
tell.  The parrot folks have also made a number of unusal design
decisions that may or may not pan out in the end.  My impression is
that the presentation of their ideas at the Lightweight Languages
Workshop last year at MIT (http://ll1.mit.edu/) was not received with
overwhelming entusiasm by an audience who know something about this
stuff.  But who knows, it's still early days.

There is work in progress on compiling R to byte code for a virtual
machine that is specific to and optimized for R (includes things like
opcoded for vectorized arithmetic).  Once this is complete it should
be possible to use the R byte code as an intermediate language for
different back endt including portable assembly languages (C, C--,
e.g.), JVM byte code, .NET byte code, or maybe parrot byte code if
that project matures into something interesting.

luke

On Fri, Apr 12, 2002 at 10:57:05AM -0400, ggrothendieck at yifan.net wrote:
> This is just an idea for comment.  Perl6, the upcoming version of Perl has
> separated out the runtime into a virtual machine called Parrot.  There are
> already several small languages (one is C-like, one is Java-like and one is
> BASIC-like) that target Parrot and given the popularity of Perl its likely that
> others may attempt to target it too.
> 
> If R could interface easily with Parrot then it might be possible to use this
> to interface with a large number of scripting languages in the future with
> little or no additional interfacing work per language.
> 
> See www.parrotcode.org .
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
Luke Tierney
University of Minnesota                      Phone:           612-625-7843
School of Statistics                         Fax:             612-624-8868
313 Ford Hall, 224 Church St. S.E.           email:      luke at stat.umn.edu
Minneapolis, MN 55455 USA                    WWW:  http://www.stat.umn.edu
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Fri Apr 12 22:25:48 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 12 Apr 2002 15:25:48 -0500
Subject: [R] summary: Generalized linear mixed model software
In-Reply-To: <20020412144253.7958.qmail@web10507.mail.yahoo.com>
References: <20020412144253.7958.qmail@web10507.mail.yahoo.com>
Message-ID: <6rvgawwto3.fsf@franz.stat.wisc.edu>

Jason Liao <jg_liao at yahoo.com> writes:

> Thanks to those who responded to my inquiry about generalized linear
> mixed models on R and S-plus. Before I summarize the software, I note
> that there are several ways of doing statistical inference for
> generalized linear mixed models:
> 
> (1)Standard maximum likelihood estimation, computationally intensive
> due to intractable likelihood function
> 
> (2) Penalized quasi likelihood or similar approximations (Breslow &
> Clayton, 1993; Lee & Nelder, 1999, Schall 1991). This method is not
> good for binomial outcomes in particular. Theoretically, it is
> consistent when the cluster size increases. It is not consistent when
> the number of clusters increases while the size of each cluster remain
> constant. The standard MLE (1) is consistent under either increasing
> cluster size or the number of clusters. For theoretical result, see
> Lin, X. & Breslow N.E. (1996) in JASA. For empirical demonstartion, see
> Carlin et al (2001) in Biostatistics. 
> 
> (3)Bayesian approach. See for example, Clayton, D. G. (1996).
> Generalized linear mixed models. In Markov Chain Monte Carlo in
> Practice, Ed W.R. Gilks, S. Richardson & D.J. Spiegelhalter, pp.
> 275-301. London: Chapman and Hall. 
> 
> (4)REML estimation in GLMM. I will have a paper in June issue of
> Bioemtrika. REML estimation has the same asymptotic property as
> standard MLE but less bias for finite samples. Of course, one can argue
> that Bayesian formulation automatically generates REML for variance
> components.
> 
> Now the software.
> 
> PQL and variations: GLME in beta by Jos? Pinheiro,  reglm by Gordon
> Smyth, glmmPQL in package MASS  by Venables & Ripley 
> 
> Bayesian method: GLMMgibbs and BUGS (not a R or S-plus package).
>  
> Standard MLE: glmm (only a random intercept) in one of Jim Lindsey's
> packages?
> 
> 	Ok, this still leaves us without a good way of doing standard MLE. I
> have programmed standard MLE using R. It takes 6 minutes for a
> clustered binary outcome dataset, with 50 clusters and each cluster
> with 10 binary responses, 6 fixed effects and two random effects for
> each cluster. 

Good summary.  I have a couple of comments to add.

Stating that a method is penalized quasi-likelihood (PQL) does not
give a full description.  There are different algorithms that can be
derived from penalized quasi-likelihood.  Prof. Ripley's approach in
glmmPQL is elegant and effective.  He uses that same iteratively
reweighted least squares approach used with GLMs except that the
iterations are with respect to a weighted linear mixed-effects
estimation problem rather than a weighted least squares problem.

Different implementations of PQL for GLMMs will yield different
estimates.  The same is true for maximum likelihood approaches that
use numerical quadrature.  As you said, determining MLEs for GLMMs
requires optimization of a criterion that requires evaluation of an
intractable integral.  Doing this reliably while allowing easy and
flexible specification of the model is difficult.

I have been looking at some comparisons recently using simulated data
described in Rodriguez and Goldman (JRSS-A, 1995) (see also Rodriguez
and Goldman, JRSS-A, 2001).  Some of these data are available at
                http://data.princeton.edu/multilevel/
Prof. Rodriguez has also used these data to compare methods that
have been implemented since the 1995 paper was written.  He may be
willing to share these results.

I can provide you with the results of those fits if you are
interested.  I have created an R package from the simulated data sets.
One of the tests run by R CMD check will fit each of the data sets
using glmmPQL.  It takes about 45 minutes for the 100 simulations on a
1.2 GHz desktop computer running Linux.

When evaluating the MLEs it is important to state how the numerical
quadrature is being done, because it influence the results.  I like
adaptive methods that determine the conditional modes of the random
effects and center an evaluation grid around them.  Such methods
require optimization within quadrature within optimization so the
programming is complex.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Fri Apr 12 23:23:27 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri, 12 Apr 2002 17:23:27 -0400
Subject: [R] How to specify search order for require()
In-Reply-To: <20020412120631.7726eb8e.fharrell@virginia.edu>
References: <20020412120631.7726eb8e.fharrell@virginia.edu>
Message-ID: <20020412172327.31499e7a.fharrell@virginia.edu>

Thank you Thomas Lumley and Luke Tierney for your responses.  I think in the long run Luke's approach is a good one.  For now I decided to be expeditious by redefining library to take a pos= argument.  All that's needed is to pass this to the attach( ) inside library, which I hope R-core will add to the library function.  I also modified require (calling it requirePos) to implement a pos argument.  My usage of these is as follows:

library(Hmisc)    
# attaches Hmisc library, redefine library, define requirePos

library(Design, pos=2)

.First.lib in Design:

.First.lib <- function(lib, pkg) {
  library.dynam("Design", pkg, lib)
  requirePos('Hmisc',pos=2)
  requirePos('survival',pos=3)
  p <- .packages()
  if(match('Design',p) > match('survival',p))
    warning('By not specifying library(Design,pos=2), functions in the\nsurvival package such as survfit will override those in Design.')
  invisible()
}

I realize that overrides are to be avoided but there are a few I couldn't get around easily.  I hope that library and require are enhanced with pos=.

Frank

On Fri, 12 Apr 2002 12:06:31 -0400
Frank E Harrell Jr <fharrell at virginia.edu> wrote:

> In a .First.lib I want to issue two require()s to insure that two other packages are loaded.  But I want the package being loaded by .First.lib using library.dynam("mypackage",pkb,lib) to be higher in the search order than the two required packages, because I want to have a couple of functions from the two required packages overridden.  What is the best way to do that?  Thanks in advance -Frank
> 
> -- 
> Frank E Harrell Jr              Prof. of Biostatistics & Statistics
> Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
> U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From chenhsh at mail.disa.pku.edu.cn  Sat Apr 13 10:19:55 2002
From: chenhsh at mail.disa.pku.edu.cn (Chen Huashan)
Date: Sat, 13 Apr 2002 16:19:55 +0800
Subject: [R] mailing list archive
In-Reply-To: <15539.58978.40113.667943@galadriel.ci.tuwien.ac.at>
Message-ID: <HBECLPCKNJCMJDFHNKJGOECFCOAA.chenhsh@mail.disa.pku.edu.cn>

Hi , Fritz,

I merged those two URLs together yesterday to make it easier for
most people. Now the url is  http://www.baidao.net/r/archives/index.cgi .

The archive contains two parts now: 
1, Monthly updates from CRAN including 3 lists.
2, Daily update of R Help list.  ( I will add the other 2 lists if necessary)

I noticed that there was an argue about newsgroup.  And I think this
archive is suitable for those who dont' want to receive many emails since
every people has a browser and can read every new post from the archive.

I am planning to add such features :
1, registered users can mark some threads as their personal favoriates for further use.
2, registered users receive replys of threads that they have interests through email. 
And then, they don't have to receive all posts from the list.

Best regards!

Chen Huashan


> -----Original Message-----
> Thanks a lot!
> 
> Could you create a single page with links to the two archives
> explaining them (basically a web page with the text of your mail). I
> would then link from CRAN to that page.
> 
> Best,
> Fritz
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Sat Apr 13 13:40:44 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Sat, 13 Apr 2002 07:40:44 -0400
Subject: [R] Follow-up: pos= in library and require
Message-ID: <20020413074044.05acf422.fharrell@virginia.edu>

Unfortunately I found that adding pos= in the attach( ) inside library( ) results in a corruption of the search list.  Packages will be attached in the desired position but the system then can't find any objects in that position.  I would really appreciate R correctly implementing pos= in library( ) and require( ).  

Frank
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sat Apr 13 15:01:01 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat, 13 Apr 2002 14:01:01 +0100 (BST)
Subject: [R] Follow-up: pos= in library and require
In-Reply-To: <20020413074044.05acf422.fharrell@virginia.edu>
Message-ID: <Pine.LNX.4.31.0204131353090.11180-100000@gannet.stats>

On Sat, 13 Apr 2002, Frank E Harrell Jr wrote:

> Unfortunately I found that adding pos= in the attach( ) inside library( ) results in a corruption of the search list.  Packages will be attached in the desired position but the system then can't find any objects in that position.  I would really appreciate R correctly implementing pos= in library( ) and require( ).

As you know (I hope) R 1.5.0 is currently in feature freeze.
We've had a request to do this before, and we will look into it for 1.6.x.

One issue that occurred to me was what one should do about calls to
library() or require() from the .First.lib (or on loading the code) of a
package if a pos argument is allowed.  Are the dependent packages supposed
to displace the first package or not?  What if the dependent packages are
themselves given a pos= argument (as I think you wanted)?

I prefer to do tricky things early in the release cycle, to allow plenty
of experience with them.  Time has shown that few changes are
transparently simple.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From luke at stat.umn.edu  Sat Apr 13 16:26:43 2002
From: luke at stat.umn.edu (Luke Tierney)
Date: Sat, 13 Apr 2002 09:26:43 -0500
Subject: [R] Follow-up: pos= in library and require
In-Reply-To: <Pine.LNX.4.31.0204131353090.11180-100000@gannet.stats>; from ripley@stats.ox.ac.uk on Sat, Apr 13, 2002 at 02:01:01PM +0100
References: <20020413074044.05acf422.fharrell@virginia.edu> <Pine.LNX.4.31.0204131353090.11180-100000@gannet.stats>
Message-ID: <20020413092643.B3316@nokomis.stat.umn.edu>

On Sat, Apr 13, 2002 at 02:01:01PM +0100, ripley at stats.ox.ac.uk wrote:
> On Sat, 13 Apr 2002, Frank E Harrell Jr wrote:
> 
> > Unfortunately I found that adding pos= in the attach( ) inside library( ) results in a corruption of the search list.  Packages will be attached in the desired position but the system then can't find any objects in that position.  I would really appreciate R correctly implementing pos= in library( ) and require( ).
> 
> As you know (I hope) R 1.5.0 is currently in feature freeze.
> We've had a request to do this before, and we will look into it for 1.6.x.
> 
> One issue that occurred to me was what one should do about calls to
> library() or require() from the .First.lib (or on loading the code) of a
> package if a pos argument is allowed.  Are the dependent packages supposed
> to displace the first package or not?  What if the dependent packages are
> themselves given a pos= argument (as I think you wanted)?
> 
> I prefer to do tricky things early in the release cycle, to allow plenty
> of experience with them.  Time has shown that few changes are
> transparently simple.
> 

I agree.  And the more I think about trying to do this at the
library/require level the more nervous I get--because of the dynamic
nature of the search path I worry that it will lead to all sorts of
nasty litle bugs.  Hopefully I will be able to put a first pass at
name spaces into R-devel very soon after 1.5 is released, which should
give us a significant period to exercise it before 1.6 is released. I
think it would be better to try to use that approach to manage this
sort of thing and only resort to changing library/require if for some
reason name spaces prove inadequate.  I am actually fairly hopeful
that name spaces will allow us to deprecate require before too long,

luke

-- 
Luke Tierney
University of Minnesota                      Phone:           612-625-7843
School of Statistics                         Fax:             612-624-8868
313 Ford Hall, 224 Church St. S.E.           email:      luke at stat.umn.edu
Minneapolis, MN 55455 USA                    WWW:  http://www.stat.umn.edu
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From feldesmanm at pdx.edu  Sat Apr 13 20:18:23 2002
From: feldesmanm at pdx.edu (Marc R. Feldesman)
Date: Sat, 13 Apr 2002 11:18:23 -0700
Subject: [R] save.image() error reappears
Message-ID: <5.1.0.14.2.20020413110359.00bc1288@pop4.attglobal.net>

A week or so ago, I reported a problem on my new Windows XP box getting R 
1.4.1 and R 1.5.0 (development from BDR's site) to save the .RData file 
upon program exit.  Specifically, either clicking on the "X" in the GUI or 
invoking q() from the command line produced the following error:

Error in save.image(name) : image could not be renamed and is left in 
.RDataTmp1

After some fiddling, I was able to "cure" this problem by repartitioning 
the hard drive to add a small amount of space to my data drive.

This worked until yesterday when the problem reappeared.  As far as I can 
see, there are no permission problems, the drive is not in any way 
write-protected, and every diagnostic program I can throw at the machine 
finds absolutely no problem with either the physical surface of the drive 
or the FAT.  The entire (large) hard drive is partitioned and formatted as 
NTFS5.

I have no difficulty writing any other files to the "g" partition, and 
every other program that makes use of temporary copies of large working 
files on "g" has no difficulty.

If I move the R data directories to the same partition as the binary file 
("f" in this case), I don't have this problem.  If I save the .RData via an 
explicit call to save.image("file name"), I don't have any problem, and I 
can save the .RData file by using the pull-down menu in the GUI (File|Save 
Workspace) without difficulty.

I can, of course, modify the defaults to save.image (...safe=FALSE) and get 
around this problem, but I am plain out of ideas of why this should be 
happening.

Brian Ripley has suggested "permission" problems, but there are none that I 
can see.  Brian and Peter have both mentioned possible RACE problems (but 
why only on "g" and not anywhere else?).  Brian also confirms that having 
the binary on one logical partition and the data on another should not be 
the problem as his wife's system is set up this way.

I'm left with a couple of questions:  1)  does R have any way of knowing 
how large the hard drive is (unpartitioned).  The "g" partition lies out in 
the region beyond 80 GB, which is the upper limit for some programs and 
BIOS revisions - obviously my BIOS supports this.  2)  does anyone have any 
experience with running R under Windows XP on a 2.2 GHz P4?  (This should 
hardly be an issue, but I'm grasping at straws right now.  My machine has 
1024 MB RAM and a 120 GB Hard drive).

Any suggestions welcomed.  I'm tearing out what little hair I have left.








Dr. Marc R. Feldesman
Professor and Chairman
Anthropology Department - Portland State University
email:  feldesmanm at pdx.edu
email:  feldesman at attglobal.net
fax:    503-725-3905

"I've proved who I am so many times,
the magnetic strip's worn thin"   Bruce Cockburn

Powered by Tyrannochoerus - the 2.2 GHz WinXPP Box

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Sat Apr 13 20:59:36 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Sat, 13 Apr 2002 14:59:36 -0400
Subject: [R] Follow-up: pos= in library and require
In-Reply-To: <Pine.LNX.4.31.0204131353090.11180-100000@gannet.stats>
References: <20020413074044.05acf422.fharrell@virginia.edu>
	<Pine.LNX.4.31.0204131353090.11180-100000@gannet.stats>
Message-ID: <20020413145936.139501af.fharrell@virginia.edu>

On Sat, 13 Apr 2002 14:01:01 +0100 (BST)
ripley at stats.ox.ac.uk wrote:

> On Sat, 13 Apr 2002, Frank E Harrell Jr wrote:
> 
> > Unfortunately I found that adding pos= in the attach( ) inside library( ) results in a corruption of the search list.  Packages will be attached in the desired position but the system then can't find any objects in that position.  I would really appreciate R correctly implementing pos= in library( ) and require( ).
> 
> As you know (I hope) R 1.5.0 is currently in feature freeze.
> We've had a request to do this before, and we will look into it for 1.6.x.
> 
> One issue that occurred to me was what one should do about calls to
> library() or require() from the .First.lib (or on loading the code) of a
> package if a pos argument is allowed.  Are the dependent packages supposed
> to displace the first package or not?  What if the dependent packages are
> themselves given a pos= argument (as I think you wanted)?

That's a good question.  But there needs to be some kind of simple way to make require or library attach at the end of the search list instead of position 2, i.e., to get S-Plus's behavior.

A safe approach for now is to instruct users to put library() commands in .Rprofile for dependent packages that we do not wish to override others.  They will be put high in the search path when R starts, and then will move down the list.  

> 
> I prefer to do tricky things early in the release cycle, to allow plenty
> of experience with them.  Time has shown that few changes are
> transparently simple.

Yes, that makes complete sense.  Thanks -Frank

> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 


-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From feldesmanm at pdx.edu  Sat Apr 13 23:48:33 2002
From: feldesmanm at pdx.edu (Marc R. Feldesman)
Date: Sat, 13 Apr 2002 14:48:33 -0700
Subject: [R] save.image() issue resolved - I hope
Message-ID: <5.1.0.14.2.20020413144008.00b8aa90@pop4.attglobal.net>

I've been combing through logs I keep of all my activities.  I've found a 
possible correlation between the save.image() problem I'm having and one 
particular event.

My system has a rewriteable DVD drive.  I keep a 4.7 GB DVD/RW disk in the 
E: drive and have a system scheduler synchronize the contents of the g: 
drive with the e: drive every Friday night.  Interestingly, both times I've 
discovered the save.image() problem have been on Saturday mornings.  I 
discovered that if I copy the entire data directory on the g: drive to a 
new directory on the same drive, I don't have the save.image() 
problem.  However, if I manually synchronize the two drives (G -> E), 
save.image() fails.  The only difference I can see between the data 
directory *before* synchronization and *after* synchronization is that 
synchronization "unsets" the archive bit.  If I make a new directory, the 
"archive bit" is set and save.image() works.

I'm not sure why this is a problem for the routines in R -- it certainly 
doesn't seem to be a problem with other programs -- but either avoiding 
synchronization (a straight copy also works, but copies far more than is 
actually necessary), or manually resetting the archive bit before using R 
seems to "solve" the problem.

BTW, I've been using a program called Powerdesk 5.0 (for Windows XP) to do 
the synchronization.  The DVD-RW is prepared using Roxio's Direct CD/DVD 5.14.




Dr. Marc R. Feldesman
Professor and Chairman
Anthropology Department - Portland State University
email:  feldesmanm at pdx.edu
email:  feldesman at attglobal.net
fax:    503-725-3905

"I've proved who I am so many times,
the magnetic strip's worn thin"   Bruce Cockburn

Powered by Tyrannochoerus - the 2.2 GHz WinXPP Box

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pauljohn at ku.edu  Sun Apr 14 00:28:27 2002
From: pauljohn at ku.edu (Paul Johnson)
Date: Sat, 13 Apr 2002 17:28:27 -0500
Subject: [R] trouble getting output from graphs, again
Message-ID: <3CB8B10B.50606@ku.edu>

It seems like every time I try to do something a little different, I 
cannot get output saved just right.

This is on RedHat 7.2 with R 1.4.1.

The png output looks fine, but the eps output has the problem that the 
bounding box on the legend cuts the legend in half. I put a copy of a 
bad one here:

http://lark.cc.ukans.edu/~pauljohn/ResearchPapers/meanProtest-box.eps

When I asked about these chores about 6 months ago, I got some tips 
which have worked other times. I had the impression that if I set the 
size of the x11 device to match the eventual ps output size, then all 
would be OK. But its not this time.

Here's my code:

dat <- read.table("a816bstat7vis.csv",header=T);
attach(dat)

x11(height=6, width=6,pointsize=12)

plot (pop,meanProtWnoActivists,pch=22, main="Mean Protest Level During 
Experiment",xlab="population",ylab="mean protest",ylim=c(0,100));

points(pop,meanProtW10Activists,pch=23,col="blue")

points(pop,meanProtW20Activists,pch=24,col="red")

legend(locator(1),c("w/0 activists","w/10 activists","w/20 
activists"),pch=c(22,23,24),col=c("black","blue","red"))

dev.copy(device=postscript,file="meanProtest.eps",width=6,height=6,pointsize=12)
dev.off()
dev.copy(device=png,file="meanProtest.png",width=500,height=500)
dev.off()


I tried doing this with the postscript device on, but then I couldn't 
see a graph to use my locator for the legend, so I reverted to this 
draw-first, write-later way.

If I change the legend command to not draw the bounding box, then the 
output is OK, but I'm still asking! I put copies of those pictures in 
the same directory referred to above.

Incidentally, I used a Windows machine last week and the EMF output is 
slick and easy to make.  As I was using it, I was wondering if the size 
of the Window in which the graphic was being displayed had an impact on 
the output that was created by EMF or PS in Windows. It seemed to not be 
affected, as it is in X11 systems. Is this true?

-- 
Paul E. Johnson                       email: pauljohn at ukans.edu
Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
University of Kansas                  Office: (785) 864-9086
Lawrence, Kansas 66045                FAX: (785) 864-5700

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Sun Apr 14 00:35:50 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 14 Apr 2002 00:35:50 +0200
Subject: [R] save.image() error reappears
In-Reply-To: <5.1.0.14.2.20020413110359.00bc1288@pop4.attglobal.net>
References: <5.1.0.14.2.20020413110359.00bc1288@pop4.attglobal.net>
Message-ID: <x2r8ljuszd.fsf@blueberry.kubism.ku.dk>

"Marc R. Feldesman" <feldesmanm at pdx.edu> writes:

> Brian Ripley has suggested "permission" problems, but there are none
> that I can see.  Brian and Peter have both mentioned possible RACE
> problems (but why only on "g" and not anywhere else?).  Brian also
> confirms that having the binary on one logical partition and the data
> on another should not be the problem as his wife's system is set up
> this way.

[I think Brian suggested the race condition and I supplied the
definition of the term?] 
 
> I'm left with a couple of questions:  1)  does R have any way of
> knowing how large the hard drive is (unpartitioned).  The "g"
> partition lies out in the region beyond 80 GB, which is the upper
> limit for some programs and BIOS revisions - obviously my BIOS
> supports this.  2)  does anyone have any experience with running R
> under Windows XP on a 2.2 GHz P4?  (This should hardly be an issue,
> but I'm grasping at straws right now.  My machine has 1024 MB RAM and
> a 120 GB Hard drive).
> 
> Any suggestions welcomed.  I'm tearing out what little hair I have left.

(Tearing out hair by grasping at straws? Hmm... ;-) )

Just a few curious questions:

Can you do the rename manually? (From the Explorer or suchlike?)

What are the file sizes of the .RData files?

A quick google run suggests that XP has problems with files
erroneously being marked as being in use in several other contexts.
E.g.

http://groups.google.com/groups?q=windows+xp+file+rename

One of the notes has a hint about "disabling the LastAccess feature in
the registry" or somesuch, but don't take my advice on this stuff, I
don't know anything about Windows....


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From sundard at pdf.com  Sun Apr 14 00:42:34 2002
From: sundard at pdf.com (Sundar Dorai-Raj)
Date: Sat, 13 Apr 2002 17:42:34 -0500
Subject: [R] grayscale postscript plots
Message-ID: <3CB8B45A.70D37E4D@pdf.com>

Is there an easy way to convert a postscript plot to grayscale in R?
I've tried to convert the raw postscript using gsview but the resulting
image is poor. So I thought I would just recreate the plots in R.
However I would have to delve deep into the code to change all the color
options. Not something I want to do unless I absolutely have to.


> version
         _              
platform i386-pc-mingw32
arch     x86            
os       Win32          
system   x86, Win32     
status                  
major    1              
minor    4.0            
year     2001           
month    12             
day      19             
language R              
> 


-- 

Sundar Dorai-Raj, Ph.D.
Statistical Methods Engineer
PDF Solutions, Inc.
(972) 889-3085 x216
(214) 392-7619 cell
sundard at pdf.com
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Sun Apr 14 01:01:15 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 14 Apr 2002 01:01:15 +0200
Subject: [R] trouble getting output from graphs, again
In-Reply-To: <3CB8B10B.50606@ku.edu>
References: <3CB8B10B.50606@ku.edu>
Message-ID: <x2n0w7urt0.fsf@blueberry.kubism.ku.dk>

Paul Johnson <pauljohn at ku.edu> writes:

> http://lark.cc.ukans.edu/~pauljohn/ResearchPapers/meanProtest-box.eps
> 
> When I asked about these chores about 6 months ago, I got some tips
> which have worked other times. I had the impression that if I set the
> size of the x11 device to match the eventual ps output size, then all
> would be OK. But its not this time.
> 
> Here's my code:
> 
> dat <- read.table("a816bstat7vis.csv",header=T);
> attach(dat)
> 
> x11(height=6, width=6,pointsize=12)
> 
> plot (pop,meanProtWnoActivists,pch=22, main="Mean Protest Level During
> Experiment",xlab="population",ylab="mean protest",ylim=c(0,100));
> 
> points(pop,meanProtW10Activists,pch=23,col="blue")
> 
> points(pop,meanProtW20Activists,pch=24,col="red")
> 
> legend(locator(1),c("w/0 activists","w/10 activists","w/20 activists"),pch=c(22,23,24),col=c("black","blue","red"))
> 
> dev.copy(device=postscript,file="meanProtest.eps",width=6,height=6,pointsize=12)
> dev.off()
> dev.copy(device=png,file="meanProtest.png",width=500,height=500)
> dev.off()

Hm? I don't have your data file, but this works for me:

x11(height=6, width=6, pointsize=12)
plot(1)
legend(locator(1),c("w/0 activists","w/10 activists",
   "w/20 activists"),pch=c(22,23,24),col=c("black","blue","red"))
dev.copy(device=postscript,file="meanProtest.eps",
   width=6,height=6,pointsize=12)
dev.off()

Looks like all your point markers and fonts have become inflated
somehow? 




-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brahm at alum.mit.edu  Sun Apr 14 02:30:31 2002
From: brahm at alum.mit.edu (David Brahm)
Date: Sat, 13 Apr 2002 20:30:31 -0400
Subject: [R] How to specify search order for require()
In-Reply-To: <35704623@toto.iv>
Message-ID: <15544.52647.296295.364248@gargle.gargle.HOWL>

Frank E Harrell Jr <fharrell at virginia.edu> writes:
> For now I decided to be expeditious by redefining library to take a pos=
> argument.  All that's needed is to pass this to the attach( ) inside library,
> which I hope R-core will add to the library function.

I second that; in fact I've requested it a couple times (most recently in
R-devel on 3/28/02).  I believe it really is just as simple as passing "pos" to
attach(), and I also override the built-in function.
-- 
                              -- David Brahm (brahm at alum.mit.edu)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sun Apr 14 09:22:34 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Sun, 14 Apr 2002 08:22:34 +0100 (BST)
Subject: [R] save.image() issue resolved - I hope
In-Reply-To: <5.1.0.14.2.20020413144008.00b8aa90@pop4.attglobal.net>
Message-ID: <Pine.GSO.4.44.0204140809100.22596-100000@auk.stats>

On Sat, 13 Apr 2002, Marc R. Feldesman wrote:

> I've been combing through logs I keep of all my activities.  I've found a
> possible correlation between the save.image() problem I'm having and one
> particular event.
>
> My system has a rewriteable DVD drive.  I keep a 4.7 GB DVD/RW disk in the
> E: drive and have a system scheduler synchronize the contents of the g:
> drive with the e: drive every Friday night.  Interestingly, both times I've
> discovered the save.image() problem have been on Saturday mornings.  I
> discovered that if I copy the entire data directory on the g: drive to a
> new directory on the same drive, I don't have the save.image()
> problem.  However, if I manually synchronize the two drives (G -> E),
> save.image() fails.  The only difference I can see between the data
> directory *before* synchronization and *after* synchronization is that
> synchronization "unsets" the archive bit.  If I make a new directory, the
> "archive bit" is set and save.image() works.
>
> I'm not sure why this is a problem for the routines in R -- it certainly
> doesn't seem to be a problem with other programs -- but either avoiding
> synchronization (a straight copy also works, but copies far more than is
> actually necessary), or manually resetting the archive bit before using R
> seems to "solve" the problem.

Renaming via the ISO C call is an unusual thing for Windows programs to
use.  The Windows implementation is not POSIX-compliant.  I'll see if there
are better ways to do this under Windows (but not for 1.5.0).  Sometimes
Explorer can works with files that tools ported from Unix think are in use.

Manually resetting the archive bit may well release the file too.

> BTW, I've been using a program called Powerdesk 5.0 (for Windows XP) to do
> the synchronization.  The DVD-RW is prepared using Roxio's Direct CD/DVD 5.14.

Looks like Powerdesk is not releasing files it has copied.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sun Apr 14 09:48:54 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Sun, 14 Apr 2002 08:48:54 +0100 (BST)
Subject: [R] trouble getting output from graphs, again
In-Reply-To: <3CB8B10B.50606@ku.edu>
Message-ID: <Pine.GSO.4.44.0204140832090.22675-100000@auk.stats>

On Sat, 13 Apr 2002, Paul Johnson wrote:

> It seems like every time I try to do something a little different, I
> cannot get output saved just right.
>
> This is on RedHat 7.2 with R 1.4.1.
>
> The png output looks fine, but the eps output has the problem that the
> bounding box on the legend cuts the legend in half. I put a copy of a
> bad one here:
>
> http://lark.cc.ukans.edu/~pauljohn/ResearchPapers/meanProtest-box.eps
>
> When I asked about these chores about 6 months ago, I got some tips
> which have worked other times. I had the impression that if I set the
> size of the x11 device to match the eventual ps output size, then all
> would be OK. But its not this time.

It's not so.  Matching sizes and pointsizes helps a great deal, but
the idea of copying graphs by replaying the display list (as used by
R and S) is fundamentally limited.  I do this by using the postscript
device directly and by experimenting with where to put the legend.

One fundamental limitation is that font metrics will be computed on the X11
device, but the PS device will layout the text.  I think that is what you
are seeing here.  You may just be being caught by rounding in the
pointsize requested: as I recall it on X11 the pointsize is approximated
by the available fonts.  (On the postscript() device it is for some reason
rounded down.  On X11 what happens depends on the screen dpi, for example.)

> Here's my code:
>
> dat <- read.table("a816bstat7vis.csv",header=T);
> attach(dat)
>
> x11(height=6, width=6,pointsize=12)
>
> plot (pop,meanProtWnoActivists,pch=22, main="Mean Protest Level During
> Experiment",xlab="population",ylab="mean protest",ylim=c(0,100));
>
> points(pop,meanProtW10Activists,pch=23,col="blue")
>
> points(pop,meanProtW20Activists,pch=24,col="red")
>
> legend(locator(1),c("w/0 activists","w/10 activists","w/20
> activists"),pch=c(22,23,24),col=c("black","blue","red"))
>
> dev.copy(device=postscript,file="meanProtest.eps",width=6,height=6,pointsize=12)
> dev.off()
> dev.copy(device=png,file="meanProtest.png",width=500,height=500)
> dev.off()
>
>
> I tried doing this with the postscript device on, but then I couldn't
> see a graph to use my locator for the legend, so I reverted to this
> draw-first, write-later way.
>
> If I change the legend command to not draw the bounding box, then the
> output is OK, but I'm still asking! I put copies of those pictures in
> the same directory referred to above.
>
> Incidentally, I used a Windows machine last week and the EMF output is
> slick and easy to make.  As I was using it, I was wondering if the size
> of the Window in which the graphic was being displayed had an impact on
> the output that was created by EMF or PS in Windows. It seemed to not be
> affected, as it is in X11 systems. Is this true?

EMF, yes, ps no.  The issue is that the screen device and EMF are sharing
the same fonts and hence font metrics, whereas PS is not.  You may do
better because the on-screen font size is approximated less: Windows
is using (by default) scaleable fonts whereas X11() is not.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pedro.aphalo at cc.jyu.fi  Sun Apr 14 14:30:09 2002
From: pedro.aphalo at cc.jyu.fi (Pedro J. Aphalo)
Date: Sun, 14 Apr 2002 15:30:09 +0300
Subject: [R] gls
Message-ID: <3CB97651.FA20C6D5@cc.jyu.fi>

Dear all, I am confused.

I have encountered some strange behaviour of gls

> data(co2)
> co2.y <- aggregate(co2,1,mean)
> co2.y.data <- data.frame(co2=as.numeric(co2.y),year=seq(1959-1980,along=co2.y))
> co2.1.gls <- gls(co2~year+I(year^2), co2.y.data)
> co2.2.gls <- update(CO2.1.gls, corr=corAR1())
> summary(CO2.2.gls)
> plot(CO2.2.gls)

plot shows standardized residuals that range between 0.007 and -0.005.
summary(CO2.2.gls) shows results very different from summary(CO2.1.gls).

residual standard error seems to be badly estimated.

Are the data a pathological case? or am I doing something wrong?

Thanks in advance for any help.

(I was planning to use this example in a course...)

Pedro.

-- 
==================================================================
Pedro J. Aphalo
Department of Biological and Environmental Science
University of Jyv?skyl?
P.O. Box 35, 40351 JYV?SKYL?, Finland
Phone  +358 14 260 2339
Mobile +358 50 3721504
Fax    +358 14 260 2321
mailto:pedro.aphalo at cc.jyu.fi
http://www.jyu.fi/~aphalo/                       ,,,^..^,,,
==================================================================
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sun Apr 14 15:00:42 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun, 14 Apr 2002 14:00:42 +0100 (BST)
Subject: [R] save.image() issue resolved - I hope
In-Reply-To: <Pine.GSO.4.44.0204140809100.22596-100000@auk.stats>
Message-ID: <Pine.LNX.4.31.0204141347410.20701-100000@gannet.stats>

On Sun, 14 Apr 2002, Prof Brian D Ripley wrote:

> On Sat, 13 Apr 2002, Marc R. Feldesman wrote:
>
> > I've been combing through logs I keep of all my activities.  I've found a
> > possible correlation between the save.image() problem I'm having and one
> > particular event.
> >
> > My system has a rewriteable DVD drive.  I keep a 4.7 GB DVD/RW disk in the
> > E: drive and have a system scheduler synchronize the contents of the g:
> > drive with the e: drive every Friday night.  Interestingly, both times I've
> > discovered the save.image() problem have been on Saturday mornings.  I
> > discovered that if I copy the entire data directory on the g: drive to a
> > new directory on the same drive, I don't have the save.image()
> > problem.  However, if I manually synchronize the two drives (G -> E),
> > save.image() fails.  The only difference I can see between the data
> > directory *before* synchronization and *after* synchronization is that
> > synchronization "unsets" the archive bit.  If I make a new directory, the
> > "archive bit" is set and save.image() works.
> >
> > I'm not sure why this is a problem for the routines in R -- it certainly
> > doesn't seem to be a problem with other programs -- but either avoiding
> > synchronization (a straight copy also works, but copies far more than is
> > actually necessary), or manually resetting the archive bit before using R
> > seems to "solve" the problem.

I can't reproduce any problem with the archive bit manually unset.

> Renaming via the ISO C call is an unusual thing for Windows programs to
> use.  The Windows implementation is not POSIX-compliant.  I'll see if there
> are better ways to do this under Windows (but not for 1.5.0).  Sometimes
> Explorer can works with files that tools ported from Unix think are in use.

It seems that most Windows applications would use DeleteFile/MoveFile (not
unlink/rename) and Windows NT (but not 9X) supports renaming existing
files using MoveFileEx.  Looks like it would be worth exploring the latter
for 1.6.x.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From clange at epost.de  Sun Apr 14 20:00:59 2002
From: clange at epost.de (Christoph Lange)
Date: Sun, 14 Apr 2002 20:00:59 +0200
Subject: [R] Suggestion for implementation
Message-ID: <20020414200059.C26976@rivka.biologie.fu-berlin.de>


I wonder if it was possible (and desireable) to implement means to
protect data objects (and functions) from overwriting them. So for
instance:

> x <- 5
> protect(x)
> x <- 8
Error: x is read only


Or would that be against the philosophy of R to be compatible to S?!

Just a RFC ;-)

  Yours,
    Christoph.

ps. Your probably know the situations that let you think of such a
feature :-( ...

-- 
Christoph Lange                                    clange at epost.de
Verhaltensbiologie, FU Berlin                            838-55068
Haderslebener Str. 9, 12163 Berlin
http://www.verhaltensbiologie.fu-berlin.de/
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From luke at stat.umn.edu  Sun Apr 14 20:53:11 2002
From: luke at stat.umn.edu (Luke Tierney)
Date: Sun, 14 Apr 2002 13:53:11 -0500
Subject: [R] Suggestion for implementation
In-Reply-To: <20020414200059.C26976@rivka.biologie.fu-berlin.de>; from clange@epost.de on Sun, Apr 14, 2002 at 08:00:59PM +0200
References: <20020414200059.C26976@rivka.biologie.fu-berlin.de>
Message-ID: <20020414135311.A6586@nokomis.stat.umn.edu>

In 1.4 or later have a look at ?lockBinding:

> x <- 5
> lockBinding("x",.GlobalEnv)
NULL
Warning message: 
saved workspaces with locked bindings may not work properly when loaded into older versions of R 
> x <- 8
Error: can't change value of a locked binding

The facility and the interface are still experimental, so details may
change.

luke

On Sun, Apr 14, 2002 at 08:00:59PM +0200, Christoph Lange wrote:
> 
> I wonder if it was possible (and desireable) to implement means to
> protect data objects (and functions) from overwriting them. So for
> instance:
> 
> > x <- 5
> > protect(x)
> > x <- 8
> Error: x is read only
> 
> 
> Or would that be against the philosophy of R to be compatible to S?!
> 
> Just a RFC ;-)
> 
>   Yours,
>     Christoph.
> 
> ps. Your probably know the situations that let you think of such a
> feature :-( ...
> 
> -- 
> Christoph Lange                                    clange at epost.de
> Verhaltensbiologie, FU Berlin                            838-55068
> Haderslebener Str. 9, 12163 Berlin
> http://www.verhaltensbiologie.fu-berlin.de/
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
Luke Tierney
University of Minnesota                      Phone:           612-625-7843
School of Statistics                         Fax:             612-624-8868
313 Ford Hall, 224 Church St. S.E.           email:      luke at stat.umn.edu
Minneapolis, MN 55455 USA                    WWW:  http://www.stat.umn.edu
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From walterm at cmat.edu.uy  Mon Apr 15 03:12:36 2002
From: walterm at cmat.edu.uy (Walter Moreira)
Date: Sun, 14 Apr 2002 22:12:36 -0300
Subject: [R] ANN: RPy (R from Python) 0.2
Message-ID: <20020414221236.A4604@cmat.edu.uy>

Hello.

RPy version 0.2 is released.  You can download it from the Sourceforge site:

    http://rpy.sourceforge.net

WHAT IS RPy?

RPy is a very simple, yet robust, Python interface to the R Programming
Language (http://www.r-project.org).  It can manage all kinds of R objects and
can execute arbitrary R functions (including the graphic functions).  All the
errors from the R language are converted to Python exceptions.  Any module
that later were installed on the R system, can easily be used from within
Python, without introducing any changes.  Currently it works only on POSIX
systems.

CHANGES IN RPy 0.2

Fixed bugs

o There were several bugs related to memory and R and Python garbage
  collectors, which caused Python segfaults.
o There was a problem with signals traped by R, which made Python crash when
  <Ctl-C> was pressed.
o R objects of class 'factor' or 'data.frame' were incorrect converted to
  Python.
o Instances of any class converted to R were treated as sequences and made
  Python segfault.

Conversion

o RPy has now a new system for conversion of types from R to Python (see the
  docs), which includes user defined conversion functions.
o The conversion to R types is also customizable.
o Some utility functions are added.
o When Numeric (NumPy) is available, it is used for the standard conversion
  between R arrays and Python objects.

Documentation

o The documentation is converted to texinfo format, updated and enlarged.  In
  particular, better documentation for the compilation procedure and for the
  location of libraries is included.

Distribution

o There are now some examples included in the distribution.
o Regression tests are also included.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From W.Simpson at gcal.ac.uk  Mon Apr 15 10:47:31 2002
From: W.Simpson at gcal.ac.uk (Bill Simpson)
Date: Mon, 15 Apr 2002 09:47:31 +0100 (BST)
Subject: [R] vector average
Message-ID: <Pine.LNX.4.10.10204150940480.792-100000@localhost.localdomain>

I have some x,y data like this:

> Age
 [1]  9  9  9  9  9  9  9 10 10 10 10 10 10 10 10 10 10 13 13 13 13 13 14
14 14
[26] 14 14 20 20 24 24 24 24 25 25 26 26 26 26 26 26 27 27 27 27 28 28 28
31 31
[51] 33 33 33 33 42 42
> Eff
 [1] 0.0020974230 0.0027592200 0.0005083383 0.0032771380 0.0103963000
 [6] 0.0001853803 0.0003308799 0.0013806050 0.0011010700 0.0004344708
[11] 0.0004218284 0.0005980084 0.0010793970 0.0028892260 0.0052878420
[16] 0.0018294950 0.0053974560 0.0090520070 0.0080538370 0.0016778090
[21] 0.0028991400 0.0087036000 0.0025774670 0.0007077176 0.0114549000
[26] 0.0075118350 0.0039684140 0.0052012410 0.0014330880 0.0029195920
[31] 0.0035333520 0.0014361830 0.0137326300 0.0016086470 0.0003588453
[36] 0.0066563540 0.0006436416 0.0084010880 0.0072078140 0.0069549490
[41] 0.0047324600 0.0175518600 0.0028563290 0.0111100700 0.0029967400
[46] 0.0015195310 0.0060652090 0.0024862060 0.0126991500 0.0064851260
[51] 0.0104344000 0.0011785500 0.0016925290 0.0002736497 0.0144059200
[56] 0.0064315460

I would like a plot (unique(Age),E) where E is the average Eff at each
age. For example, the first point would be:
(9, 0.002793526)

Please tell me how to compute E.  Thanks!

Bill Simpson

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Apr 15 11:02:47 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 15 Apr 2002 11:02:47 +0200
Subject: [R] vector average
In-Reply-To: <Pine.LNX.4.10.10204150940480.792-100000@localhost.localdomain>
References: <Pine.LNX.4.10.10204150940480.792-100000@localhost.localdomain>
Message-ID: <x2vgatnxl4.fsf@blueberry.kubism.ku.dk>

Bill Simpson <W.Simpson at gcal.ac.uk> writes:

> I have some x,y data like this:
> 
> > Age
>  [1]  9  9  9  9  9  9  9 10 10 10 10 10 10 10 10 10 10 13 13 13 13 13 14
> 14 14
> [26] 14 14 20 20 24 24 24 24 25 25 26 26 26 26 26 26 27 27 27 27 28 28 28
> 31 31
> [51] 33 33 33 33 42 42
> > Eff
>  [1] 0.0020974230 0.0027592200 0.0005083383 0.0032771380 0.0103963000
>  [6] 0.0001853803 0.0003308799 0.0013806050 0.0011010700 0.0004344708
> [11] 0.0004218284 0.0005980084 0.0010793970 0.0028892260 0.0052878420
> [16] 0.0018294950 0.0053974560 0.0090520070 0.0080538370 0.0016778090
> [21] 0.0028991400 0.0087036000 0.0025774670 0.0007077176 0.0114549000
> [26] 0.0075118350 0.0039684140 0.0052012410 0.0014330880 0.0029195920
> [31] 0.0035333520 0.0014361830 0.0137326300 0.0016086470 0.0003588453
> [36] 0.0066563540 0.0006436416 0.0084010880 0.0072078140 0.0069549490
> [41] 0.0047324600 0.0175518600 0.0028563290 0.0111100700 0.0029967400
> [46] 0.0015195310 0.0060652090 0.0024862060 0.0126991500 0.0064851260
> [51] 0.0104344000 0.0011785500 0.0016925290 0.0002736497 0.0144059200
> [56] 0.0064315460
> 
> I would like a plot (unique(Age),E) where E is the average Eff at each
> age. For example, the first point would be:
> (9, 0.002793526)
> 
> Please tell me how to compute E.  Thanks!

tapply(Eff, Age, mean)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kwan022 at stat.auckland.ac.nz  Mon Apr 15 11:33:05 2002
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Mon, 15 Apr 2002 21:33:05 +1200 (NZST)
Subject: [R] Re: Writting R Function
In-Reply-To: <Pine.SOL.4.21.0204151724000.29713-100000@stat1.stat.auckland.ac.nz>
Message-ID: <Pine.SOL.4.21.0204152131440.18876-100000@stat1.stat.auckland.ac.nz>

Hi,

I think I found the problem.  It lies in my Fortran program.  Is there a
way, after a DO loop, to make sure it does NOT return anything?

Cheers,

Kevin

On Mon, 15 Apr 2002, Ko-Kang Kevin Wang wrote:

> Date: Mon, 15 Apr 2002 17:27:20 +1200 (NZST)
> From: Ko-Kang Kevin Wang <kwan022 at stat1.stat.auckland.ac.nz>
> To: R Help <r-help at stat.math.ethz.ch>
> Subject: Writting R Function
> 
> Hi,
> 
> Suppose I have a function as below:
>   Fibonacci <- function(n, all = T) {
>       .Fortran("fibonacci",
>                ans = as.double(n),
>                as.character(all))$ans
>   }
> which produces:
>   Fibonacci(10)
>    1
>    1
>    2
>    3
>    5
>    8
>    13
>    21
>    34
>    55
>    [1] 10
> this is fine but I'd like to a) display in a vector format, i.e.:
>   [1] 1  1  2  3  5
>   [6] 8 13 21 34 55
> and b) do not display the last line in the above output ([1] 55).
> 
> Is there anyway to achieve this?
> 
> Cheers,
> 
> Kevin
> 
> ------------------------------------------------------------------------------
> Ko-Kang Kevin Wang
> Postgraduate PGDipSci Student
> Department of Statistics
> University of Auckland
> New Zealand
> 
> Homepage: http://www.stat.auckland.ac.nz/~kwan022
> 
> E-mail: kwan022 at stat.auckland.ac.nz
> 
> 

Cheers,

Kevin

------------------------------------------------------------------------------
Ko-Kang Kevin Wang
Postgraduate PGDipSci Student
Department of Statistics
University of Auckland
New Zealand

Homepage: http://www.stat.auckland.ac.nz/~kwan022

E-mail: kwan022 at stat.auckland.ac.nz

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From osiander at 24on.cc  Mon Apr 15 12:37:03 2002
From: osiander at 24on.cc (osiander@24on.cc)
Date: Mon, 15 Apr 2002 12:37:03 +0200
Subject: [R] required sample size
Message-ID: <039a01c1e469$7b4e90d0$2b04110a@24on.cc>

Hi,

Is there a function in R already to estimate the required sample size to test H0:  = 0 ?

Thank you,

-- 
osiander at 24on.cc
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Apr 15 13:24:09 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 15 Apr 2002 13:24:09 +0200
Subject: [R] required sample size
In-Reply-To: <039a01c1e469$7b4e90d0$2b04110a@24on.cc>
References: <039a01c1e469$7b4e90d0$2b04110a@24on.cc>
Message-ID: <x2n0w5nr1i.fsf@blueberry.kubism.ku.dk>

osiander at 24on.cc writes:

> Hi,
> 
> Is there a function in R already to estimate the required sample size to test H0: ? = ?0 ?

power.t.test()

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Mon Apr 15 13:35:58 2002
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Mon, 15 Apr 2002 13:35:58 +0200 (CEST)
Subject: [R] Re: Writting R Function
In-Reply-To: <Pine.SOL.4.21.0204152131440.18876-100000@stat1.stat.auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0204151330420.9565-100000@tal.stat.umu.se>

On Mon, 15 Apr 2002, Ko-Kang Kevin Wang wrote:

> Hi,
> 
> I think I found the problem.  It lies in my Fortran program.  Is there a
> way, after a DO loop, to make sure it does NOT return anything?

A DO loop in FORTRAN does not "return" anyting. I guess you have to be 
more specific in formulating your question. From below I guess that you 
have a WRITE (or the equivalent under  R) statement in your Fortran 
subroutine, which gives you the 
output you want to avoid. How about removing that statement and return the 
values as a vector instead?

G?ran

> 
> Cheers,
> 
> Kevin
> 
> On Mon, 15 Apr 2002, Ko-Kang Kevin Wang wrote:
> 
> > Date: Mon, 15 Apr 2002 17:27:20 +1200 (NZST)
> > From: Ko-Kang Kevin Wang <kwan022 at stat1.stat.auckland.ac.nz>
> > To: R Help <r-help at stat.math.ethz.ch>
> > Subject: Writting R Function
> > 
> > Hi,
> > 
> > Suppose I have a function as below:
> >   Fibonacci <- function(n, all = T) {
> >       .Fortran("fibonacci",
> >                ans = as.double(n),
> >                as.character(all))$ans
> >   }
> > which produces:
> >   Fibonacci(10)
> >    1
> >    1
> >    2
> >    3
> >    5
> >    8
> >    13
> >    21
> >    34
> >    55
> >    [1] 10
> > this is fine but I'd like to a) display in a vector format, i.e.:
> >   [1] 1  1  2  3  5
> >   [6] 8 13 21 34 55
> > and b) do not display the last line in the above output ([1] 55).
> > 
> > Is there anyway to achieve this?
> > 
> > Cheers,
> > 
> > Kevin
> > 
> > ------------------------------------------------------------------------------
> > Ko-Kang Kevin Wang
> > Postgraduate PGDipSci Student
> > Department of Statistics
> > University of Auckland
> > New Zealand
> > 
> > Homepage: http://www.stat.auckland.ac.nz/~kwan022
> > 
> > E-mail: kwan022 at stat.auckland.ac.nz
> > 
> > 
> 
> Cheers,
> 
> Kevin
> 
> ------------------------------------------------------------------------------
> Ko-Kang Kevin Wang
> Postgraduate PGDipSci Student
> Department of Statistics
> University of Auckland
> New Zealand
> 
> Homepage: http://www.stat.auckland.ac.nz/~kwan022
> 
> E-mail: kwan022 at stat.auckland.ac.nz
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-- 
 G?ran Brostr?m                      tel: +46 90 786 5223
 professor                           fax: +46 90 786 6614
 Department of Statistics            http://www.stat.umu.se/egna/gb/
 Ume? University
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From W.Simpson at gcal.ac.uk  Mon Apr 15 14:29:20 2002
From: W.Simpson at gcal.ac.uk (Bill Simpson)
Date: Mon, 15 Apr 2002 13:29:20 +0100 (BST)
Subject: [R] Greek in text()
Message-ID: <Pine.LNX.4.10.10204151326340.1338-100000@localhost.localdomain>

I have gone over the examples and can't figure this out:
rho<-.77
text(x=.05,y=.5,paste(expression(rho),rho))

I was hoping to get this to print a Greek rho with 0.77 beside it.
Instead I get: rho 0.77 (i.e. Roman lettering)
The help on expression() is quite opaque so I don't understand how it
works.

Thanks for any help.

Bill Simpson

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From benjamin.janson at gmx.de  Mon Apr 15 14:53:40 2002
From: benjamin.janson at gmx.de (Benjamin Janson)
Date: Mon, 15 Apr 2002 14:53:40 +0200 (MEST)
Subject: [R] Newbie problem with ox package
Message-ID: <31270.1018875220@www16.gmx.net>

HI,
I need urgently garch and egarch models. After looking through the R mail
archives I found http://www.egss.ulg.ac.be/garch/default.htm which is an Ox
package. After downloading and installing it in R (Version 1.4.1 through the
windows dialog "Packages") I received the following warning:

install.packages("D:/benjamin/bartels/R/packages/garch22/garch_v22.zip",
.libPaths()[1], CRAN = NULL)
updating HTML package descriptions
Warning message: 
DESCRIPTION file of package garch22 missing or broken in:
package.description(i, field = "Title") 

then I tried to use the EGarch:
> egarch()
Error: couldn't find function "egarch"

And so I tried to load the package again:
> {pkg <- select.list(sort(.packages(all.available = TRUE)))
+ if(nchar(pkg)) library(pkg, character.only=TRUE)}
Warning message: 
Package  `garch22' contains no R code in: library(pkg, character.only =
TRUE) 

Well I really need the GARCH/EGARCH modells. So I was wondering whether
anyone could help me out.
Thanks in advance.
Benjamin

-- 
"Rowe's Rule: The odds are five to six that the light at the end of
the tunnel is the headlight of an oncoming train."	--Paul Dickson  		

GMX - Die Kommunikationsplattform im Internet.
http://www.gmx.net

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Mon Apr 15 14:48:28 2002
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Mon, 15 Apr 2002 14:48:28 +0200 (CEST)
Subject: [R] Configuring with gcc3 
In-Reply-To: <Pine.LNX.4.44.0204151330420.9565-100000@tal.stat.umu.se>
Message-ID: <Pine.LNX.4.44.0204151436480.10118-100000@tal.stat.umu.se>


I'm trying to build the latest snapshot of  R  on RedHat 7.2 with gcc3, 
g77-3 and g++3, which correspond to gcc version 3.04 (is this a bad 
idea?).
I made the required changes in config.site (CC=gcc3, CFLAGS=-g -O2, 
F77=g77-3, FFLAGS=O2, CXX=c++3), but  ./configure  gives warnings:

-------------------------------------------------------------------------
R is now configured for i686-pc-linux-gnu

  Source directory:          .
  Installation directory:    /usr/local
  C compiler:                gcc3  -D__NO_MATH_INLINES -mieee-fp -g -O2
  C++ compiler:              c++3  
  FORTRAN compiler:          g77-3  -O2

  X11 support:               yes
  Gnome support:             yes
  Tcl/Tk support:            yes
  Readline support:          yes

  R profiling support:       yes
  R as a shared library:     yes

configure: WARNING: I could not determine CXXPICFLAGS
configure: WARNING: I could not determine SHLIB_CXXLDFLAGS
-----------------------------------------------------------------------

I guess I have to set these guys manually. What are proper values?

Thanks,

G?ran
-- 
 G?ran Brostr?m                      tel: +46 90 786 5223
 professor                           fax: +46 90 786 6614
 Department of Statistics            http://www.stat.umu.se/egna/gb/
 Ume? University
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From klavan at tiscalinet.it  Mon Apr 15 14:54:35 2002
From: klavan at tiscalinet.it (Ambrosini Alessandro)
Date: Mon, 15 Apr 2002 14:54:35 +0200
Subject: [R] two questions
Message-ID: <PPEGLLABFLFCJDLCGPGHIEHECAAA.klavan@tiscalinet.it>

The first: if I have a vector as (1,1,3,2,1,1), which is the command that
gives all the positions of the min value? From the vector of the example a
would like to obtain a new vector as (1,2,5,6) that give me all the
positions of the minimum value 1.

The second: if I have a matrix "A" and I want to obtain a new matrix
deleting a column or a row of A, what have I to do?
Thank you.
           Alessandro

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Jussi.Makinen at valtiokonttori.fi  Mon Apr 15 14:58:10 2002
From: Jussi.Makinen at valtiokonttori.fi (=?iso-8859-1?Q?M=E4kinen_Jussi?=)
Date: Mon, 15 Apr 2002 15:58:10 +0300
Subject: [R] glm link = logit, passing arguments
Message-ID: <7EFB6224454CD511B9D700306E00F4070199ABA1@VKYHA01>

Hello R-users.

I haven't use R for a life time and this might be trivial - I hope you do
not mind.

I have a  questions about arguments in the Glm-function. There seems to be
something that I cannot cope.

The basics are ok:
> y <- as.double(rnorm(20) > .5)
>  logit.model <- glm(y ~ rnorm(20), family=binomial(link=logit), trace =
TRUE)
Deviance = 28.34255 Iterations - 1 
Deviance = 27.72554 Iterations - 2 
Deviance = 27.72527 Iterations - 3 
Warning message: 
non-integer #successes in a binomial glm! in: eval(expr, envir, enclos).

But trying to exclude intercept (or pass anything to glm.fit, especially
mustart to improve convergence if I have understand the role of mustart
correctly):

glm(as.matrix(y) ~ as.matrix(X), family=binomial(link=logit), intercept =
FALSE, TRACE = TRUE)

seems not to be a correct since it returns:

Error in glm.control(...) : unused argument(s) (intercept ...)		###
Same apply to the mustart

But using instead

glm(as.matrix(y) ~ as.matrix(X), family=binomial(link=logit), intercept =
FALSE, TRACE = TRUE, 
			control = glm.control(epsilon=1e-04, maxit = 1000))

yields:

Call:  glm(formula = as.matrix(y) ~ as.matrix(X), family = binomial(link =
logit),      control = glm.control(epsilon = 1e-04, maxit = 1000), intercept
= FALSE,      TRACE = TRUE) 

Coefficients:
      (Intercept)  as.matrix(X)due14  as.matrix(X)due45  as.matrix(X)due90  
           -22.05            -305.47            -283.72            -144.07  

Degrees of Freedom: 7775 Total (i.e. Null);  7772 Residual
Null Deviance:      7959 
Residual Deviance: 3.589e-06    AIC: 8 
Warning message: 
fitted probabilities numerically 0 or 1 occurred in: (if
(is.empty.model(mt)) glm.fit.null else glm.fit)(x = X, y = Y, 

which seems to work without explicite errors. For me its a little strange
that including an argument does help to pass an other one. But trace doesn't
show anything and also intercept is still included eventhough intercept =
FALSE is set up (probably unwisely but the judgement should here be users I
think). Obviously there is something wrong with my arguments passing. Is it
alright to try to pass arguments to glm.fit at all?

The estimation process seems to have hard times (because of myriad of 0s, I
guess) with data and it is not able to reach convergence (even after maxit =
1000). Is there any other estimation methods available in the R-packages? Or
would you have any other idea to transform data a prior to make it possible.
Making explanatory also binary seems to be a remedy but that's something I
do not want to do (and I'm not sure is it even statistically correct way).

I have a binary response variable y: 0 1 1 1 1 1 1 0 0 0 (a sample)

and a matrix of continous (but includin a lot of zeros)  explanatory
variables X1, X2, X3:
X1, X2, X3
198 0.0045861625 0.001717838  0.0000000
199 0.0000000000 0.000000000 -0.9992498
200 0.0000000000 0.000000000 -0.9988129
201 0.0000000000 0.000000000 -0.9984882
202 0.0000000000 0.000000000 -0.9983429
203 0.0000000000 0.000000000 -0.9980252
204 0.0003933059 0.000000000 -0.9980207
205 0.0000000000 0.000000000  0.0000000
206 0.0000000000 0.000000000  0.0000000
207 0.0000000000 0.000000000  0.0000000

version
         _              
platform i386-pc-mingw32
arch     x86            
os       Win32          
system   x86, Win32     
status                  
major    1              
minor    4.1            
year     2002           
month    01             
day      30             
language R

One more basic question crossed my mind - is this iterative weighted OLS
with a link function practically same than Maximum Likelihood estimation
which I would like to use? Can you recommend any reference to the
probit/Logit within R/Splus (other than Modern Applied Statistics with
S-PLUS which is in my list anyway).

Regards and thank you for sharing your knowledge,

Jussi Makinen
Analyst
State Treasure of Finland
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Apr 15 15:02:48 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 15 Apr 2002 15:02:48 +0200
Subject: [R] Greek in text()
In-Reply-To: <Pine.LNX.4.10.10204151326340.1338-100000@localhost.localdomain>
References: <Pine.LNX.4.10.10204151326340.1338-100000@localhost.localdomain>
Message-ID: <x21ydhnmh3.fsf@blueberry.kubism.ku.dk>

Bill Simpson <W.Simpson at gcal.ac.uk> writes:

> I have gone over the examples and can't figure this out:
> rho<-.77
> text(x=.05,y=.5,paste(expression(rho),rho))
> 
> I was hoping to get this to print a Greek rho with 0.77 beside it.
> Instead I get: rho 0.77 (i.e. Roman lettering)
> The help on expression() is quite opaque so I don't understand how it
> works.

Pasting an expression and a number gives a character string before the
math plotting routines get to it:

> paste(expression(rho),rho)
[1] "rho 0.77"

try

substitute(rho==val,list(val=rho))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Mon Apr 15 15:11:49 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 15 Apr 2002 15:11:49 +0200
Subject: [R] Greek in text()
References: <Pine.LNX.4.10.10204151326340.1338-100000@localhost.localdomain>
Message-ID: <3CBAD195.58C9D7D1@statistik.uni-dortmund.de>



Bill Simpson wrote:
> 
> I have gone over the examples and can't figure this out:
> rho<-.77
> text(x=.05,y=.5,paste(expression(rho),rho))
> 
> I was hoping to get this to print a Greek rho with 0.77 beside it.
> Instead I get: rho 0.77 (i.e. Roman lettering)
> The help on expression() is quite opaque so I don't understand how it
> works.

It's described in ?plotmath. You can use

 text(x=.05,y=.5,substitute(paste(rho, rho2), list(rho2=rho)))

or maybe without that paste() something like:

 text(x=.05, y=.5, substitute(rho == rho2, list(rho2=rho))) 


Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rwehrens at sci.kun.nl  Mon Apr 15 15:13:04 2002
From: rwehrens at sci.kun.nl (Ron Wehrens)
Date: Mon, 15 Apr 2002 15:13:04 +0200
Subject: [R] two questions
In-Reply-To: <PPEGLLABFLFCJDLCGPGHIEHECAAA.klavan@tiscalinet.it>
References: <PPEGLLABFLFCJDLCGPGHIEHECAAA.klavan@tiscalinet.it>
Message-ID: <200204151513.04714.rwehrens@sci.kun.nl>

On Monday 15 April 2002 14:54, Ambrosini Alessandro wrote:
> The first: if I have a vector as (1,1,3,2,1,1), which is the command that
> gives all the positions of the min value? From the vector of the example a
> would like to obtain a new vector as (1,2,5,6) that give me all the
> positions of the minimum value 1.


which(x==min(x))
>
> The second: if I have a matrix "A" and I want to obtain a new matrix
> deleting a column or a row of A, what have I to do?
> Thank you.
>            Alessandro

A[,-1] and A[-1,] give you matrix A without the first column or row, 
respectively.

Ron
-- 
Ron Wehrens            
Dept. of Chemometrics  
University of Nijmegen	Email: rwehrens at sci.kun.nl
Toernooiveld 1		http://www-cac.sci.kun.nl/cac/
6525 ED Nijmegen	Tel: +31 24 365 2053
The Netherlands		Fax: +31 24 365 2653

     

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Mon Apr 15 15:22:08 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 15 Apr 2002 15:22:08 +0200
Subject: [R] two questions
References: <PPEGLLABFLFCJDLCGPGHIEHECAAA.klavan@tiscalinet.it>
Message-ID: <3CBAD400.AB2A7608@statistik.uni-dortmund.de>



Ambrosini Alessandro wrote:
> 
> The first: if I have a vector as (1,1,3,2,1,1), which is the command that
> gives all the positions of the min value? From the vector of the example a
> would like to obtain a new vector as (1,2,5,6) that give me all the
> positions of the minimum value 1.

 which(x == min(x))


> The second: if I have a matrix "A" and I want to obtain a new matrix
> deleting a column or a row of A, what have I to do?

A.new <- A[-k,]  # delete the k-th row
A.new <- A[-k,]  # delete the k-th column

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Apr 15 15:21:19 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 15 Apr 2002 15:21:19 +0200
Subject: [R] Newbie problem with ox package
In-Reply-To: <31270.1018875220@www16.gmx.net>
References: <31270.1018875220@www16.gmx.net>
Message-ID: <x2wuv9m71s.fsf@blueberry.kubism.ku.dk>

Benjamin Janson <benjamin.janson at gmx.de> writes:

> HI,
> I need urgently garch and egarch models. After looking through the R mail
> archives I found http://www.egss.ulg.ac.be/garch/default.htm which is an Ox
> package. After downloading and installing it in R (Version 1.4.1 through the
> windows dialog "Packages") I received the following warning:
> 
> install.packages("D:/benjamin/bartels/R/packages/garch22/garch_v22.zip",
> .libPaths()[1], CRAN = NULL)
> updating HTML package descriptions
> Warning message: 
> DESCRIPTION file of package garch22 missing or broken in:
> package.description(i, field = "Title") 
> 
> then I tried to use the EGarch:
> > egarch()
> Error: couldn't find function "egarch"
> 
> And so I tried to load the package again:
> > {pkg <- select.list(sort(.packages(all.available = TRUE)))
> + if(nchar(pkg)) library(pkg, character.only=TRUE)}
> Warning message: 
> Package  `garch22' contains no R code in: library(pkg, character.only =
> TRUE) 
> 
> Well I really need the GARCH/EGARCH modells. So I was wondering whether
> anyone could help me out.
> Thanks in advance.

It's an Ox package. Try running it in Ox, not R!

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Torsten.Hothorn at rzmail.uni-erlangen.de  Mon Apr 15 15:29:48 2002
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Mon, 15 Apr 2002 15:29:48 +0200 (MEST)
Subject: [R] two questions
In-Reply-To: <PPEGLLABFLFCJDLCGPGHIEHECAAA.klavan@tiscalinet.it>
Message-ID: <Pine.LNX.4.21.0204151527030.421-100000@artemis.imbe.med.uni-erlangen.de>

On Mon, 15 Apr 2002, Ambrosini Alessandro wrote:

> The first: if I have a vector as (1,1,3,2,1,1), which is the command that
> gives all the positions of the min value? From the vector of the example a

x <- c(1,1,3,2,1,1)
wm <- which.min(x)	# first position

> would like to obtain a new vector as (1,2,5,6) that give me all the
> positions of the minimum value 1.

which(x == wm) 

> 
> The second: if I have a matrix "A" and I want to obtain a new matrix
> deleting a column or a row of A, what have I to do?

A <- matrix(1:25, ncol=5)
A[-2,-4] 		# delete 2nd row and 4th col
     [,1] [,2] [,3] [,4]
[1,]    1    6   11   21
[2,]    3    8   13   23
[3,]    4    9   14   24
[4,]    5   10   15   25

Torsten

> Thank you.
>            Alessandro
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Mon Apr 15 15:47:18 2002
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Mon, 15 Apr 2002 15:47:18 +0200 (CEST)
Subject: [R] two questions
In-Reply-To: <PPEGLLABFLFCJDLCGPGHIEHECAAA.klavan@tiscalinet.it>
Message-ID: <Pine.LNX.4.44.0204151543060.10118-100000@tal.stat.umu.se>

On Mon, 15 Apr 2002, Ambrosini Alessandro wrote:

> The first: if I have a vector as (1,1,3,2,1,1), which is the command that
> gives all the positions of the min value? From the vector of the example a
> would like to obtain a new vector as (1,2,5,6) that give me all the
> positions of the minimum value 1.

> x <- c(1,1,3,2,1,1)
> which(x == min(x))
[1] 1 2 5 6

>
> 
> The second: if I have a matrix "A" and I want to obtain a new matrix
> deleting a column or a row of A, what have I to do?
> Thank you.

A[-1, ] removes the first row, etc.

G?ran

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From matthew.norton at umontreal.ca  Mon Apr 15 16:12:48 2002
From: matthew.norton at umontreal.ca (Matthew Norton)
Date: Mon, 15 Apr 2002 10:12:48 -0400
Subject: [R] nested anova not giving expected results
Message-ID: <200204151012.48151.matthew.norton@umontreal.ca>

Hello all. This may be a trivially simple question to answer, but I'm a little 
bit stumped with respect to the calculation of the F statistics in nested 
anovas in R. If I understand correctly, the F statistic for the 
among-subgroups but within groups hypothesis is calculated as 
MS_subgroups/MS_error, while the F statistic for the factor is calculated as 
MS_factor/MS_subgroups (I'm getting this from Sokal & Rohlf's _Biometry_). 
However, as I understand the output from R, it calculates the F for the 
factor as MS_factor/MS_error, which can significantly change the results.

As an example, I took the values from Sokal & Rohlf's example on mosquitos, 
which are as follows:

   cage animal length
1     1      a   58.5
2     1      a   59.5
3     1      b   77.8
4     1      b   80.9
5     1      c   84.0
6     1      c   83.6
7     1      d   70.1
8     1      d   68.3
9     2      a   69.8
10    2      a   69.8
11    2      b   56.0
12    2      b   54.5
13    2      c   50.7
14    2      c   49.3
15    2      d   63.8
16    2      d   65.8
17    3      a   56.6
18    3      a   57.5
19    3      b   77.8
20    3      b   79.2
21    3      c   69.9
22    3      c   69.2
23    3      d   62.1
24    3      d   64.5

Using the following R commands, I get this output for a nested anova:

> model<-lm(length~cage/animal)
> anova(model)
Analysis of Variance Table

Response: length
            Df  Sum Sq Mean Sq F value    Pr(>F)
cage         2  665.68  332.84  255.70 1.452e-10 ***
cage:animal  9 1720.68  191.19  146.88 6.981e-11 ***
Residuals   12   15.62    1.30
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

According to the book and my understanding of nested anovas, the F statistic 
for the cage:animal component is correct, but the F statistic for 'cage' 
should be 332.84/191.19, giving a value of 1.741 which is not significant, 
and highly different than 255.70.

Perhaps I've misunderstood, but could someone explain to me what R is doing?

In order to guide you, I'm running linux and my R-version is:

 R 1.4.1 (2002-01-30).
Copyright (C) 2002 R Development Core Team


Thanks in advance,


-- 
Matthew Norton
nortonm at magellan.umontreal.ca 
D?pt. des Sciences Biologiques, Universit? de Montr?al
C.P. 6128 Succ. centre-ville,  Montr?al, Qc H3C 3J7
(514) 343-6111 x1233
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Mon Apr 15 16:44:03 2002
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Mon, 15 Apr 2002 16:44:03 +0200 (CEST)
Subject: [R] Configuring with gcc3 
In-Reply-To: <Pine.LNX.4.44.0204151436480.10118-100000@tal.stat.umu.se>
Message-ID: <Pine.LNX.4.44.0204151628410.5997-100000@tal.stat.umu.se>

I think I found my error: There is no  c++3, it is  g++3. Changeing this 
made the warnings disappear. The c++ compiler is actually not used in the 
building process, which is the reason it was possible to build  R  while
specifying a non-existing c++ compiler.

G?ran

On Mon, 15 Apr 2002, G?ran Brostr?m wrote:

> 
> I'm trying to build the latest snapshot of  R  on RedHat 7.2 with gcc3, 
> g77-3 and g++3, which correspond to gcc version 3.04 (is this a bad 
> idea?).
> I made the required changes in config.site (CC=gcc3, CFLAGS=-g -O2, 
> F77=g77-3, FFLAGS=O2, CXX=c++3), but  ./configure  gives warnings:
> 
> -------------------------------------------------------------------------
> R is now configured for i686-pc-linux-gnu
> 
>   Source directory:          .
>   Installation directory:    /usr/local
>   C compiler:                gcc3  -D__NO_MATH_INLINES -mieee-fp -g -O2
>   C++ compiler:              c++3  
>   FORTRAN compiler:          g77-3  -O2
> 
>   X11 support:               yes
>   Gnome support:             yes
>   Tcl/Tk support:            yes
>   Readline support:          yes
> 
>   R profiling support:       yes
>   R as a shared library:     yes
> 
> configure: WARNING: I could not determine CXXPICFLAGS
> configure: WARNING: I could not determine SHLIB_CXXLDFLAGS
> -----------------------------------------------------------------------
> 
> I guess I have to set these guys manually. What are proper values?
> 
> Thanks,
> 
> G?ran
> 

-- 
 G?ran Brostr?m                      tel: +46 90 786 5223
 professor                           fax: +46 90 786 6614
 Department of Statistics            http://www.stat.umu.se/egna/gb/
 Ume? University
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From macq at llnl.gov  Mon Apr 15 16:49:30 2002
From: macq at llnl.gov (Don MacQueen)
Date: Mon, 15 Apr 2002 07:49:30 -0700
Subject: [R] Problem(?) in strptime() -- short version -- followup
In-Reply-To: <p05101502b8d7b4818847@[128.115.153.6]>
References: <p05101502b8d7b4818847@[128.115.153.6]>
Message-ID: <p05101502b8e090262915@[128.115.153.6]>

Sorry to take so long with the followup; I needed to work with this 
idea for a little while.

ggrothendieck at yifan.net made this suggestion:
>library(chron)
>dts <- dates(c("04/07/02","04/07/02"))
>tms <- times(c("01:30:00","02:30:00"))
>x <- chron(dts,tms)
>y <- as.POSIXct(x,tz="GMT")
>y   # returns date/times
>y[2]-y[1]   # returns a difference of 1 hour


What I found was that (1) it works, (2) it's slower [I sometimes have 
vectors of ~250,000 dates], and (3) it introduces a small rounding 
error by converting from seconds to partial days and then converting 
back to seconds, with the result that sometimes the POSIXct value is 
displayed 1 second off from the value that was supplied.

I solved (3) by using the chron() approach on only the date portion, 
converting it to POSIXct, and then adding the times in seconds to 
these. This also improved the speed. So, thank you, ggrothendieck.

-Don

At 2:13 PM -0700 4/8/02, Don MacQueen wrote:
>I decided my earlier email on this topic was rather long and wordy; 
>here's a condensed version.
>
>I am sitting at a Solaris computer in the US/Pacific timezone.
>I have a file of data having times that includes the following three values
>
>   2002-4-7 1:30:00 GMT
>   2002-4-7 2:30:00 GMT
>   2002-4-7 3:30:00 GMT
>
>I have not been able to find a way to correctly convert these to 
>either of the POSIX datetime classes with the OS timezone set to 
>US/Pacific. And I've tried everything I could think of. The bottom 
>line appears to be the fact that strptime() always uses the local 
>timezone.
>
>>  Sys.getenv('TZ')
>           TZ
>"US/Pacific"
>>
>>  gdat <- c('2002-4-7 1:30:00 GMT',
>+           '2002-4-7 2:30:00 GMT',
>+           '2002-4-7 3:30:00 GMT')
>>
>>
>>  as.POSIXct(gdat)
>[1] "2002-04-07 01:30:00 PST" "2002-04-07 01:30:00 PST" "2002-04-07 
>03:30:00 PDT"
>>
>>  as.POSIXct(gdat,tz='GMT')
>[1] "2002-04-06 17:30:00 PST" "2002-04-06 17:30:00 PST" "2002-04-06 
>19:30:00 PST"
>>
>>  strptime(gdat,'%Y-%m-%d %H:%M:%S')
>[1] "2002-04-07 01:30:00" "2002-04-07 01:30:00" "2002-04-07 03:30:00"
>>
>>  strptime(gdat,'%Y-%m-%d %H:%M:%S %Z')
>[1] "NA" "NA" "NA"
>
>The middle element is converted/interpreted incorrectly.
>
>>  version
>          _
>platform sparc-sun-solaris2.7
>arch     sparc
>os       solaris2.7
>system   sparc, solaris2.7
>status
>major    1
>minor    4.1
>year     2002
>month    01
>day      30
>language R
>>
>>  Sys.getlocale()
>[1] "C"
>
>If I setenv TZ GMT before starting R, then the data is converted 
>correctly. However, this is not entirely satisfactory, because 
>ultimately I want to work with the data in my local timezone (for 
>example, make graphs where the time axis is in local time), and that 
>means going through a multiple step process:
>
>   1) setenv TZ GMT
>   2) start R, read the data
>   3) quit R
>   4) setenv TZ US/Pacific
>   5) start R, work with the data
>
>strptime() appears to rely on the operating system's strptime, so 
>perhaps the problem is out of R's hands, so to speak. But it does 
>seem reasonable that I should be able to convert such data no matter 
>where I am. For example, it is my understanding that a world-wide 
>standard among meteorologists is that times are always recorded in 
>GMT.
>--
>--------------------------------------
>Don MacQueen
>Environmental Protection Department
>Lawrence Livermore National Laboratory
>Livermore, CA, USA
>--------------------------------------


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
--------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Apr 15 16:48:45 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 15 Apr 2002 16:48:45 +0200
Subject: [R] nested anova not giving expected results
In-Reply-To: <200204151012.48151.matthew.norton@umontreal.ca>
References: <200204151012.48151.matthew.norton@umontreal.ca>
Message-ID: <x2sn5xm302.fsf@blueberry.kubism.ku.dk>

Matthew Norton <matthew.norton at umontreal.ca> writes:

> Hello all. This may be a trivially simple question to answer, but I'm a little 
> bit stumped with respect to the calculation of the F statistics in nested 
> anovas in R. If I understand correctly, the F statistic for the 
> among-subgroups but within groups hypothesis is calculated as 
> MS_subgroups/MS_error, while the F statistic for the factor is calculated as 
> MS_factor/MS_subgroups (I'm getting this from Sokal & Rohlf's _Biometry_). 
> However, as I understand the output from R, it calculates the F for the 
> factor as MS_factor/MS_error, which can significantly change the results.
> 
> As an example, I took the values from Sokal & Rohlf's example on mosquitos, 
> which are as follows:
> 
>    cage animal length
> 1     1      a   58.5
> 2     1      a   59.5
> 3     1      b   77.8
> 4     1      b   80.9
> 5     1      c   84.0
> 6     1      c   83.6
> 7     1      d   70.1
> 8     1      d   68.3
> 9     2      a   69.8
> 10    2      a   69.8
> 11    2      b   56.0
> 12    2      b   54.5
> 13    2      c   50.7
> 14    2      c   49.3
> 15    2      d   63.8
> 16    2      d   65.8
> 17    3      a   56.6
> 18    3      a   57.5
> 19    3      b   77.8
> 20    3      b   79.2
> 21    3      c   69.9
> 22    3      c   69.2
> 23    3      d   62.1
> 24    3      d   64.5
> 
> Using the following R commands, I get this output for a nested anova:
> 
> > model<-lm(length~cage/animal)
> > anova(model)
> Analysis of Variance Table
> 
> Response: length
>             Df  Sum Sq Mean Sq F value    Pr(>F)
> cage         2  665.68  332.84  255.70 1.452e-10 ***
> cage:animal  9 1720.68  191.19  146.88 6.981e-11 ***
> Residuals   12   15.62    1.30
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
> 
> According to the book and my understanding of nested anovas, the F statistic 
> for the cage:animal component is correct, but the F statistic for 'cage' 
> should be 332.84/191.19, giving a value of 1.741 which is not significant, 
> and highly different than 255.70.
> 
> Perhaps I've misunderstood, but could someone explain to me what R is doing?

R is doing the same thing as SAS and Genstat and probably others: If
you don't specify that there are multiple error components, it assumes
that there is only one. So you get the decomposition of the sum of
squares with everything compared to the residual. 

Effectively, this makes any test for a main effect if it appears in a
significant interaction with another factor. Logically, this makes
sense: You cannot talk about an overall cage effect if it differs
between animals, *unless* you interpret differences between animals as
random.

To get a multistratum analysis try 

aov(length~cage+Error(cage:animal))

(Notice that this only works out correctly for balanced designs. In
other cases, you may have to look into using lme().)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Apr 15 16:55:08 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 15 Apr 2002 16:55:08 +0200
Subject: [R] nested anova not giving expected results
In-Reply-To: <x2sn5xm302.fsf@blueberry.kubism.ku.dk>
References: <200204151012.48151.matthew.norton@umontreal.ca>
	<x2sn5xm302.fsf@blueberry.kubism.ku.dk>
Message-ID: <x2ofglm2pf.fsf@blueberry.kubism.ku.dk>

Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:

> Effectively, this makes any test for a main effect if it appears in a
                                                    ^

Argh. Not my day, it seems. Insert "useless".


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From benjamin.janson at gmx.de  Mon Apr 15 17:11:27 2002
From: benjamin.janson at gmx.de (Benjamin Janson)
Date: Mon, 15 Apr 2002 17:11:27 +0200 (MEST)
Subject: [R] eGRACH
Message-ID: <25185.1018883487@www16.gmx.net>

Sorry for my ignorance. But does anyone know a package that includes EGRACH.
tseries only includes GARCH.
Thanks for your help.
Benjamin

-- 
"Rowe's Rule: The odds are five to six that the light at the end of
the tunnel is the headlight of an oncoming train."	--Paul Dickson  		

GMX - Die Kommunikationsplattform im Internet.
http://www.gmx.net

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Mon Apr 15 17:11:45 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 15 Apr 2002 08:11:45 -0700 (PDT)
Subject: [R] glm link = logit, passing arguments
In-Reply-To: <7EFB6224454CD511B9D700306E00F4070199ABA1@VKYHA01>
Message-ID: <Pine.A41.4.44.0204150800590.166716-100000@homer03.u.washington.edu>

On Mon, 15 Apr 2002, [iso-8859-1] Mkinen Jussi wrote:

> Hello R-users.
>
> I haven't use R for a life time and this might be trivial - I hope you do
> not mind.
>
> I have a  questions about arguments in the Glm-function. There seems to be
> something that I cannot cope.
>
> The basics are ok:
> > y <- as.double(rnorm(20) > .5)
> >  logit.model <- glm(y ~ rnorm(20), family=binomial(link=logit), trace =
> TRUE)
> Deviance = 28.34255 Iterations - 1
> Deviance = 27.72554 Iterations - 2
> Deviance = 27.72527 Iterations - 3
> Warning message:
> non-integer #successes in a binomial glm! in: eval(expr, envir, enclos).

Even this isn't ideal -- if your data are really binomial it would be
better to pass them as a number of successes and failures, if they aren't
really binomial then family=quasibinomial() would probably be better.

> But trying to exclude intercept (or pass anything to glm.fit, especially
> mustart to improve convergence if I have understand the role of mustart
> correctly):
>
> glm(as.matrix(y) ~ as.matrix(X), family=binomial(link=logit), intercept =
> FALSE, TRACE = TRUE)
>
> seems not to be a correct since it returns:
>
> Error in glm.control(...) : unused argument(s) (intercept ...)		###

That's because intercept is not one of the arguments that glm() takes. You
can fit a model without intercept by using  y~x+0 or y~x-1 as the formula.

> Same apply to the mustart

Yes, there is no mustart argument to glm() either.

> But using instead
>
> glm(as.matrix(y) ~ as.matrix(X), family=binomial(link=logit), intercept =
> FALSE, TRACE = TRUE,
> 			control = glm.control(epsilon=1e-04, maxit = 1000))
>
> yields:
>
<snipped>

> which seems to work without explicite errors. For me its a little strange
> that including an argument does help to pass an other one. But trace doesn't
> show anything and also intercept is still included eventhough intercept =
> FALSE is set up (probably unwisely but the judgement should here be users I
> think). Obviously there is something wrong with my arguments passing. Is it
> alright to try to pass arguments to glm.fit at all?
>

No. If you want to call glm.fit() you have to call it directly. If you
look at the code for glm() you can see that it doesn't pass the ...
arguments to glm.fit.

The ... argument is passed to glm.control() if there is no explicit
glm.control= argument -- that's what caused the error and why it went away
when you supplied the glm.control argument.  Otherwise it's there for
future expansion.

>
> One more basic question crossed my mind - is this iterative weighted OLS
> with a link function practically same than Maximum Likelihood estimation
> which I would like to use? Can you recommend any reference to the
> probit/Logit within R/Splus (other than Modern Applied Statistics with
> S-PLUS which is in my list anyway).

It is exactly maximum likelihood.

	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Apr 15 17:14:16 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 15 Apr 2002 16:14:16 +0100 (BST)
Subject: [R] Configuring with gcc3 
In-Reply-To: <Pine.LNX.4.44.0204151436480.10118-100000@tal.stat.umu.se>
Message-ID: <Pine.LNX.4.31.0204151610250.27232-100000@gannet.stats>

On Mon, 15 Apr 2002, [iso-8859-1] Gran Brostrm wrote:

>
> I'm trying to build the latest snapshot of  R  on RedHat 7.2 with gcc3,
> g77-3 and g++3, which correspond to gcc version 3.04 (is this a bad
> idea?).

I use gcc 3.0.4 on RH7.2 all the time, conpiled from courses, though.

> I made the required changes in config.site (CC=gcc3, CFLAGS=-g -O2,
> F77=g77-3, FFLAGS=O2, CXX=c++3), but  ./configure  gives warnings:
>
> -------------------------------------------------------------------------
> R is now configured for i686-pc-linux-gnu
>
>   Source directory:          .
>   Installation directory:    /usr/local
>   C compiler:                gcc3  -D__NO_MATH_INLINES -mieee-fp -g -O2
>   C++ compiler:              c++3
>   FORTRAN compiler:          g77-3  -O2
>
>   X11 support:               yes
>   Gnome support:             yes
>   Tcl/Tk support:            yes
>   Readline support:          yes
>
>   R profiling support:       yes
>   R as a shared library:     yes
>
> configure: WARNING: I could not determine CXXPICFLAGS
> configure: WARNING: I could not determine SHLIB_CXXLDFLAGS

The same as CPICFLAGS and SHLIB_LDFLAGS.

CXXPICFLAGS = -fPIC
SHLIB_LDFLAGS = -shared



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From amurta at ipimar.pt  Mon Apr 15 18:41:50 2002
From: amurta at ipimar.pt (Alberto Murta)
Date: Mon, 15 Apr 2002 16:41:50 +0000
Subject: [R] error fitting lme model
Message-ID: <3CBB02CE.5AF8B55F@ipimar.pt>

Dear all

A colleague that does not have access to this list asked me to post this
message:

> When fitting a lme model for an incomplete and unbalanced design
> 
> > lme(dur~sp, data=clara, random=~1|sp/indiv)
> 
> the following error message appears
> 
> Error in if (any(wchLv <- (as.double(levels(xtTab[, wchPval])) == 0))) {
> :
>         missing value where logical needed
> In addition: Warning message:
> NaNs produced in: pt(q, df, lower.tail, log.p)  
> 
> The number of observations is different for each cell and there is a
> different number of levels of factor "indiv" for each level of factor
> "sp". Is this error due to the characteristics of the data set or am i
> doing something wrong? I used nlme 3.1-19 and R 1.4.1. 
> Thanks in advance
> 
> Clara
> 
> Full summary() output is below:
> 
> > summary(lme(dur~sp, data=clara, random=~1|sp/indiv))
> Linear mixed-effects model fit by REML
>  Data: clara
>        AIC      BIC    logLik
>   3628.559 3649.493 -1808.279
>  
> Random effects:
>  Formula: ~1 | sp
>         (Intercept)
> StdDev:    120.1199
>  
>  Formula: ~1 | indiv %in% sp
>         (Intercept) Residual
> StdDev:    95.65147 407.0695
>  
> Fixed effects: dur ~ sp
> Error in if (any(wchLv <- (as.double(levels(xtTab[, wchPval])) == 0))) {
> :
>         missing value where logical needed
> In addition: Warning message:
> NaNs produced in: pt(q, df, lower.tail, log.p)



-- 
                           Alberto G. Murta                      
           IPIMAR - Institute of Fisheries and Sea Research
            Avenida de Brasilia, 1449-006 Lisboa, Portugal       
Tel:+351 213027062; Fax:+351 213015849; http://www.ipimar.pt/pelagicos/
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gb at stat.umu.se  Mon Apr 15 17:27:34 2002
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Mon, 15 Apr 2002 17:27:34 +0200 (CEST)
Subject: [R] Configuring with gcc3 
In-Reply-To: <Pine.LNX.4.31.0204151610250.27232-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0204151725200.25357-100000@tal.stat.umu.se>


Thank you! As I just reported, I had made a typo (c++3 instead of g++3).
Correcting it made the warnings disappear.

G?ran


On Mon, 15 Apr 2002 ripley at stats.ox.ac.uk wrote:

> On Mon, 15 Apr 2002, [iso-8859-1] G?ran Brostr?m wrote:
> 
> >
> > I'm trying to build the latest snapshot of  R  on RedHat 7.2 with gcc3,
> > g77-3 and g++3, which correspond to gcc version 3.04 (is this a bad
> > idea?).
> 
> I use gcc 3.0.4 on RH7.2 all the time, conpiled from courses, though.
> 
> > I made the required changes in config.site (CC=gcc3, CFLAGS=-g -O2,
> > F77=g77-3, FFLAGS=O2, CXX=c++3), but  ./configure  gives warnings:
> >
> > -------------------------------------------------------------------------
> > R is now configured for i686-pc-linux-gnu
> >
> >   Source directory:          .
> >   Installation directory:    /usr/local
> >   C compiler:                gcc3  -D__NO_MATH_INLINES -mieee-fp -g -O2
> >   C++ compiler:              c++3
> >   FORTRAN compiler:          g77-3  -O2
> >
> >   X11 support:               yes
> >   Gnome support:             yes
> >   Tcl/Tk support:            yes
> >   Readline support:          yes
> >
> >   R profiling support:       yes
> >   R as a shared library:     yes
> >
> > configure: WARNING: I could not determine CXXPICFLAGS
> > configure: WARNING: I could not determine SHLIB_CXXLDFLAGS
> 
> The same as CPICFLAGS and SHLIB_LDFLAGS.
> 
> CXXPICFLAGS = -fPIC
> SHLIB_LDFLAGS = -shared
> 
> 
> 
> 

-- 
 G?ran Brostr?m                      tel: +46 90 786 5223
 professor                           fax: +46 90 786 6614
 Department of Statistics            http://www.stat.umu.se/egna/gb/
 Ume? University
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From sundard at pdf.com  Mon Apr 15 17:52:03 2002
From: sundard at pdf.com (Sundar Dorai-Raj)
Date: Mon, 15 Apr 2002 10:52:03 -0500
Subject: [R] Greek in text()
References: <Pine.LNX.4.10.10204151326340.1338-100000@localhost.localdomain>
Message-ID: <3CBAF723.ADE48DE5@pdf.com>

Try this instead:

text(x=.05,y=.5,labels=substitute(rho*r,list(r=0.77)))

or, to print "rho=0.77":

text(x=.05,y=.5,labels=substitute(rho==r,list(r=0.77)))


Look at ?plotmath for more help.

Sundar

Bill Simpson wrote:
> 
> I have gone over the examples and can't figure this out:
> rho<-.77
> text(x=.05,y=.5,paste(expression(rho),rho))
> 
> I was hoping to get this to print a Greek rho with 0.77 beside it.
> Instead I get: rho 0.77 (i.e. Roman lettering)
> The help on expression() is quite opaque so I don't understand how it
> works.
> 
> Thanks for any help.
> 
> Bill Simpson
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 

Sundar Dorai-Raj, Ph.D.
Statistical Methods Engineer
PDF Solutions, Inc.
(972) 889-3085 x216
(214) 392-7619 cell
sundard at pdf.com
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From l.bargeot at educagri.fr  Mon Apr 15 17:03:48 2002
From: l.bargeot at educagri.fr (Lionel)
Date: Mon, 15 Apr 2002 17:03:48 +0200
Subject: [R] krige and polygon limit problem
Message-ID: <02041517034802.16509@agrogeomatic>

Dear all,

I'm new on R and this mailing list. We work on spatial rainfall estimation 
with R and Grass.
We have a problem with the krige function from the sgeostat package. We would 
like to limit the estimated area with a polygon limit.
I use a 50 points polygon to describe my work area. The krige function work 
quiet well without limit. But if I use this option I have the following error 
messages :
-------------------------------
Using points within c(2210907, 2212817, 2214516, 2216568, 2216985, 2215795, 
2217396,  units of prediction points.
 
Using points within c(785291, 789980, 794030, 798282, 805920, 813151, 817000, 
820902,  units of prediction points.
  Predicting.Error: (list) object cannot be coerced to vector type 14
In addition: Warning messages: 
1: X matrix was collinear in: lsfit(xmat, y, wt = w, intercept = FALSE) 
2: X matrix was collinear in: lsfit(xmat, y, wt = w, intercept = FALSE) 
3: X matrix was collinear in: lsfit(xmat, y, wt = w, intercept = FALSE) 
4: X matrix was collinear in: lsfit(xmat, y, wt = w, intercept = FALSE) 
-------------------------------

Do you have an idea of the origine of the problem ?

Thanks,

Lionel
-- 
CNERTA-ENESAD
4 rue champs-prevois
batiment grand-champs
21000 Dijon
tel:03.80.77.28.49
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From clange at epost.de  Mon Apr 15 18:42:47 2002
From: clange at epost.de (Christoph Lange)
Date: Mon, 15 Apr 2002 18:42:47 +0200
Subject: [R] two questions
In-Reply-To: <PPEGLLABFLFCJDLCGPGHIEHECAAA.klavan@tiscalinet.it>; from klavan@tiscalinet.it on Mon, Apr 15, 2002 at 02:54:35PM +0200
References: <PPEGLLABFLFCJDLCGPGHIEHECAAA.klavan@tiscalinet.it>
Message-ID: <20020415184247.A1112@rivka.biologie.fu-berlin.de>

(Reply to Ambrosini Alessandro)


> The first: if I have a vector as (1,1,3,2,1,1), which is the command that
> gives all the positions of the min value? From the vector of the example a
> would like to obtain a new vector as (1,2,5,6) that give me all the
> positions of the minimum value 1.

> x <- c(1,1,3,2,1,1)
> x[x==min(x)]
[1] 1 1 1 1
> which(x==min(x))
[1] 1 2 5 6
> 

> The second: if I have a matrix "A" and I want to obtain a new matrix
> deleting a column or a row of A, what have I to do?

> A
     [,1] [,2] [,3]
[1,]    1    4    7
[2,]    2    5    8
[3,]    3    6    9
> A[,-2]
     [,1] [,2]
[1,]    1    7
[2,]    2    8
[3,]    3    9
> A[-2,]
     [,1] [,2] [,3]
[1,]    1    4    7
[2,]    3    6    9
> 

That's the solutions.

  Christoph.

-- 
Christoph Lange                                    clange at epost.de
Verhaltensbiologie, FU Berlin                            838-55068
Haderslebener Str. 9, 12163 Berlin
http://www.verhaltensbiologie.fu-berlin.de/
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From plxmh at nottingham.ac.uk  Mon Apr 15 18:45:53 2002
From: plxmh at nottingham.ac.uk (Martin Hoyle)
Date: Mon, 15 Apr 2002 17:45:53 +0100
Subject: [R] Nested ANOVA with covariates
Message-ID: <scbb11d5.026@gwmail.nottingham.ac.uk>

Dear All,
I'm rather a beginner on nested ANOVAs, so here goes with my 2
questions;

Qu 1:
I'm modelling the number of galls on a leaf (the response variable) as
a function of;
the tree on which I find the leaf,
the branch on which I find the leaf.

Then, the tree and the branch are both random factors, and I'm quite
happy that I should write;

aov(galls~tree/branch + Error(tree/branch))

But, I'd also like to introduce the size of the leaf as a covariate.
I'm not sure how I can do this in R. Any suggestions?


Qu 2:
I'm measuring the stress response of some tiny worms (the response
variable) by the effect of the presence of absence of cadmium (a fixed
factor), and by the presence of absence of an electric field (a fixed
factor). This would normally be a straight forward 2 way anova;

stress ~ cadmium*electric.

But, I have the complication that I have nesting. I have 4 reps for
each combination of cadmium and electic field. Within each of these 4
reps, I have pseudoreplication. Specifically, I have 3 reps within each
of the 4 main reps. In detail, worms are held in little wells in plates
(random factor). I have 4 plates for each combination of cadmium and
electic field. These are geniune reps. Within each plate, there are 3
pseudoreps. I thought I could model this as;

aov(stress~cadmium + cadmium:plate + electic + electic:plate +
cadmium:elecric+ cadmium:elecric:plate   + Error(??????))

I don't really know what to put in the error.

Thanks v much for your time.

Regards,
Martin.


Martin Hoyle,
School of Life and Environmental Sciences,
University of Nottingham,
University Park,
Nottingham,
NG7 2RD,
UK
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From plxmh at nottingham.ac.uk  Mon Apr 15 19:32:33 2002
From: plxmh at nottingham.ac.uk (Martin Hoyle)
Date: Mon, 15 Apr 2002 18:32:33 +0100
Subject: [R] Nested ANOVA with covariates
Message-ID: <scbb1cca.000@gwmail.nottingham.ac.uk>

Dear All,
I'm rather a beginner on nested ANOVAs, so here goes with my 2
questions;

Qu 1:
I'm modelling the number of galls on a leaf (the response variable) as
a function of;
the tree on which I find the leaf,
the branch on which I find the leaf.

Then, the tree and the branch are both random factors, and I'm quite
happy that I should write;

aov(galls~tree/branch + Error(tree/branch))

But, I'd also like to introduce the size of the leaf as a covariate.
I'm not sure how I can do this in R. Any suggestions?


Qu 2:
I'm measuring the stress response of some tiny worms (the response
variable) by the effect of the presence of absence of cadmium (a fixed
factor), and by the presence of absence of an electric field (a fixed
factor). This would normally be a straight forward 2 way anova;

stress ~ cadmium*electric.

But, I have the complication that I have nesting. I have 4 reps for
each combination of cadmium and electic field. Within each of these 4
reps, I have pseudoreplication. Specifically, I have 3 reps within each
of the 4 main reps. In detail, worms are held in little wells in plates
(random factor). I have 4 plates for each combination of cadmium and
electic field. These are geniune reps. Within each plate, there are 3
pseudoreps. I thought I could model this as;

aov(stress~cadmium + cadmium:plate + electic + electic:plate +
cadmium:elecric+ cadmium:elecric:plate   + Error(??????))

I don't really know what to put in the error.

Thanks v much for your time.

Regards,
Martin.


Martin Hoyle,
School of Life and Environmental Sciences,
University of Nottingham,
University Park,
Nottingham,
NG7 2RD,
UK
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ambrosini77 at libero.it  Mon Apr 15 20:15:09 2002
From: ambrosini77 at libero.it (=?utf-8?Q?ambrosini77@libero.it?=)
Date: Mon, 15 Apr 2002 20:15:09 +0200
Subject: [R] =?iso-8859-1?Q?Problem?=
Message-ID: <GUMG19$C3888C6D1514A9E29CB98C2AFDB37D17@libero.it>

Hello! If I have a matrix as 1 2
                             2 3
and I want to change the value 2 in 0, what can I do?
Thank you
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ben at zoo.ufl.edu  Mon Apr 15 20:38:14 2002
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Mon, 15 Apr 2002 14:38:14 -0400 (EDT)
Subject: [R] =?iso-8859-1?Q?Problem?=
In-Reply-To: <GUMG19$C3888C6D1514A9E29CB98C2AFDB37D17@libero.it>
Message-ID: <Pine.LNX.4.30.0204151434190.16806-100000@bolker.zoo.ufl.edu>


  x <- matrix(c(1,2,2,3))
  x[x==2] <- 0

  I suggest reading the "Introduction to R" that comes with the R package,
it will help you with basic questions like this ... (see "Index vectors;
selecting and modifying subsets of a data set")



On Mon, 15 Apr 2002, [utf-8] ambrosini77 at libero.it wrote:

> Hello! If I have a matrix as 1 2
>                              2 3
> and I want to change the value 2 in 0, what can I do?
> Thank you
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From o.christensen at lancaster.ac.uk  Mon Apr 15 20:31:23 2002
From: o.christensen at lancaster.ac.uk (Ole Christensen)
Date: Mon, 15 Apr 2002 19:31:23 +0100
Subject: [R] Problem
References: <GUMG19$C3888C6D1514A9E29CB98C2AFDB37D17@libero.it>
Message-ID: <3CBB1C7B.22566949@lancs.ac.uk>

A[A==2] <- 0

"ambrosini77 at libero.it" wrote:
> 
> Hello! If I have a matrix as 1 2
>                              2 3
> and I want to change the value 2 in 0, what can I do?
> Thank you
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
Ole F. Christensen
Department of Mathematics and Statistics
Fylde College, Lancaster University 
Lancaster, LA1 4YF, England
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From o.christensen at lancaster.ac.uk  Mon Apr 15 21:04:28 2002
From: o.christensen at lancaster.ac.uk (Ole Christensen)
Date: Mon, 15 Apr 2002 20:04:28 +0100
Subject: [R] krige and polygon limit problem
References: <02041517034802.16509@agrogeomatic>
Message-ID: <3CBB243C.10892B65@lancs.ac.uk>

Dear Lionel

It is difficult to say exactly what your problem is, because you haven't
provided the call you used.
But see my guess below.

> I'm new on R and this mailing list. We work on spatial rainfall estimation
> with R and Grass.
> We have a problem with the krige function from the sgeostat package. We would
> like to limit the estimated area with a polygon limit.
> I use a 50 points polygon to describe my work area. The krige function work
> quiet well without limit. But if I use this option I have the following error
> messages :
> -------------------------------
> Using points within c(2210907, 2212817, 2214516, 2216568, 2216985, 2215795,
> 2217396,  units of prediction points.


This should be a number (``maxdist'' in the call) not a vector. 
My guess is that you have given the polygon-coordinates as input to
``maxdist'' instead of to ``border'' .

Cheers Ole

 

-- 
Ole F. Christensen
Department of Mathematics and Statistics
Fylde College, Lancaster University 
Lancaster, LA1 4YF, England
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From osiander at 24on.cc  Mon Apr 15 23:20:09 2002
From: osiander at 24on.cc (osiander@24on.cc)
Date: Mon, 15 Apr 2002 23:20:09 +0200
Subject: [R] simple Q: required sample size & usage of power.t.test()
Message-ID: <045c01c1e4c3$52a00920$2b04110a@24on.cc>

Hi community,

Seems I am too stupid:

I try to calculate with power.t.test() an example from the statistics textbook [Jerrold H. Zar, Biostatistical Analysis, 2nd edition, Prentice Hall, 1984, Chapter 8, Exercise 8.4, (page 120)]:

-------
A sample of size 18 has a mean of 13.55cm and a variance of 6.4512cm^2.
(a) Calculate the 95% confidence interval for the population mean.
(b) How large a sample would have to be taken from this population to estimate  to within 1.00cm, 
 with 95% confidence?
(c) 2.00cm with 95% confidence?
(d) 2.00cm with 99% confidence?

Result should be - according to the answers appendix - (a) 13.55 +- 1.26cm (b) n=29, (c) n=10, (d) n=11
-------

Here my questions:

(1) which functions in R can be used to solve (a)
(2) what has to be the syntax to answer (b), (c) and (d) ?


Thanks in advance,

Osiander


-- 
osiander at 24on.cc
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dmcwilli at utk.edu  Mon Apr 15 23:31:29 2002
From: dmcwilli at utk.edu (dmcwilli)
Date: Mon, 15 Apr 2002 17:31:29 -0400
Subject: [R] Problem with read.table()
Message-ID: <3CBBC8B1@webmail.utk.edu>

I am trying to read machine output data with a 21 row header and 2 row footer.
 Numbers of rows and columns are variable.  Just skipping the header causes 
read.table to choke on the last 2 rows since the number of fields is not the 
same as the data table.  The header contains information for calculating the 
number of rows.  I can successfully pick this out and do the calculation, but 
cannot get the second read.table() to see the assign the number to "nrows" 
(the number is correct; if I enter it manually, the everything works fine).  
Currently the function reads all the way to the end and crashes on the footer.

Code follows.

# function to read data with header and footer
grid.layout <- read.table(fname, as.is=T, header=F, sep="\t", comment.char="", 
skip=7, nrows=1)
row.ctr <- grid.layout[4]*grid.layout[5]*grid.layout[6]*grid.layout[7]

# tells me I have the right dimensions ...
print(row.ctr)

tmp.df <- read.table(fname, as.is=T, header=T, sep="\t", comment.char="", 
skip=20, nrows=row.ctr )

tmp.df
# end function


Regards,

David McWilliams

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Apr 15 23:50:44 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 15 Apr 2002 23:50:44 +0200
Subject: [R] simple Q: required sample size & usage of power.t.test()
In-Reply-To: <045c01c1e4c3$52a00920$2b04110a@24on.cc>
References: <045c01c1e4c3$52a00920$2b04110a@24on.cc>
Message-ID: <x28z7opr63.fsf@blueberry.kubism.ku.dk>

osiander at 24on.cc writes:

> Hi community,
> 
> Seems I am too stupid:
> 
> I try to calculate with power.t.test() an example from the statistics textbook [Jerrold H. Zar, Biostatistical Analysis, 2nd edition, Prentice Hall, 1984, Chapter 8, Exercise 8.4, (page 120)]:

Ah, this is not a standard sample size calculation, but a pedagogical
exercise. t tests and power.t.test are irrelevant for this.
 
> -------
> A sample of size 18 has a mean of 13.55cm and a variance of 6.4512cm^2.
> (a) Calculate the 95% confidence interval for the population mean.
> (b) How large a sample would have to be taken from this population to estimate ? to within 1.00cm, 
>  with 95% confidence?
> (c) 2.00cm with 95% confidence?
> (d) 2.00cm with 99% confidence?
> 
> Result should be - according to the answers appendix - (a) 13.55 +- 1.26cm (b) n=29, (c) n=10, (d) n=11
> -------
> 
> Here my questions:
> 
> (1) which functions in R can be used to solve (a)
> (2) what has to be the syntax to answer (b), (c) and (d) ?

Hmmm, now are you trying to learn R for yourself by trying it on some
textbook examples, or are you trying to get us to help with your
homework?

Either way: You'll need the formula for the confidence interval
(presumably a couple of pages earlier in the book). The qnorm()
function gives you quantiles of the Normal distibution, the rest
should be basic algebra.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dstierman at cableone.net  Tue Apr 16 05:34:09 2002
From: dstierman at cableone.net (Don Stierman)
Date: Mon, 15 Apr 2002 21:34:09 -0600
Subject: [R] draw.tree help
Message-ID: <HCEOIJNHAIMCCJIBNOFFIECCCAAA.dstierman@cableone.net>

Is it possible for the draw.tree module to display the full factor name
instead of the letter it corresponds to? I see an option in tree/plot to do
this, using the text function, but can't find a corresponding function in
draw.tree.
Thanks, Don

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From iowahawk89 at yahoo.com  Tue Apr 16 05:43:08 2002
From: iowahawk89 at yahoo.com (Don Stierman)
Date: Mon, 15 Apr 2002 20:43:08 -0700 (PDT)
Subject: [R] draw.tree help
Message-ID: <20020416034308.83799.qmail@web12706.mail.yahoo.com>

Sorry, used the wrong account in previous email.
Is it possible for the draw.tree module to display the
full factor name instead of the letter it corresponds
to? I see an option in tree/plot to do this, using the
text function, but can't find a corresponding function
in draw.tree.
Thanks, Don

__________________________________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From FJMolina at lbl.gov  Tue Apr 16 06:23:49 2002
From: FJMolina at lbl.gov (Francisco J Molina)
Date: Mon, 15 Apr 2002 21:23:49 -0700
Subject: [R] Problem with dyn.load()
Message-ID: <3CBBA755.2F3B2FD4@lbl.gov>

I tried to dynamically load a c++ function. Everything seems to be OK
when dyn.load() is  executed but then I get this error


Error in .C("integral", sumInMean, sumInVar, boundError,
numberSampleClasses,  : 
        C/Fortran function name not in load table


The code of the function is something like this:

#include <cmath>

extern "C" {
#include "/usr/local/include/gsl/gsl_statistics_double.h"
#include "/usr/local/include/gsl/gsl_randist.h"
#include "/usr/local/include/gsl/gsl_roots.h"
#include "/usr/local/include/gsl/gsl_sf_erf.h"
#include "/usr/local/include/gsl/gsl_math.h"
#include "/usr/local/include/gsl/gsl_integration.h"

void integral( arguments ){
...
return;
}
}

I compile with:

g++ -c integral.C -fPIC -I/usr/local/include/gsl -o integral.o; R CMD
SHLIB integral.o

What could go wrong? The function modify its arguments ( the arguments
are  pointers )

I put my function with the C header directives in extern{}.

gsl is a library written in C, so I put the gsl's header directives also
inside extern{}.

I placed in my compiling directory a Makevars file with this content:

PKG_LIBS = -lm -lgsl -lgslcblas

and my R code looks like:

dyn.load('/usr/local/lib/libgslcblas.so',F,)
dyn.load('/usr/local/lib/libgsl.so',F,)
dyn.load('/home/f/p/integral.so')

Any hint?
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ozric at web.de  Tue Apr 16 08:36:18 2002
From: ozric at web.de (ozric@web.de)
Date: Tue, 16 Apr 2002 08:36:18 +0200
Subject: [R] multiple plot devices
Message-ID: <200204160636.g3G6aHv17018@mailgate5.cinetic.de>

Hello,
sorry but i found no way or help to work
with multiple graph devices (Rdocs,SearchIndex).
When is use the function  only the graphic device of the last variable is open.
How is it possible to let the several plot-device open or save this in a file with different names ?
(win 2000 - R1.4.1)

thanks for advance
& regards,Christian

normal <- function(x) {
    par(mfrow=c(2,2))
    hist(x)
    boxplot(x)
    sd <- summary(x)[5] - summary(x)[2]
    plot(density(x,width=2*sd),xlab="x",ylab="",type="l")
    qqnorm(x)
    qqline(x)
    }
apply(data,2,normal)
______________________________________________________________________________
F?r ganz Eilige: Lotto per Quicktipp! Klick und weg!


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr 16 09:08:11 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 16 Apr 2002 08:08:11 +0100 (BST)
Subject: [R] Problem with dyn.load()
In-Reply-To: <3CBBA755.2F3B2FD4@lbl.gov>
Message-ID: <Pine.GSO.4.44.0204160748230.25486-100000@auk.stats>

On Mon, 15 Apr 2002, Francisco J Molina wrote:

> I tried to dynamically load a c++ function. Everything seems to be OK
> when dyn.load() is  executed but then I get this error
>
>
> Error in .C("integral", sumInMean, sumInVar, boundError,
> numberSampleClasses,  :
>         C/Fortran function name not in load table
>
>
> The code of the function is something like this:
>
> #include <cmath>
>
> extern "C" {
> #include "/usr/local/include/gsl/gsl_statistics_double.h"
> #include "/usr/local/include/gsl/gsl_randist.h"
> #include "/usr/local/include/gsl/gsl_roots.h"
> #include "/usr/local/include/gsl/gsl_sf_erf.h"
> #include "/usr/local/include/gsl/gsl_math.h"
> #include "/usr/local/include/gsl/gsl_integration.h"
>
> void integral( arguments ){
> ...
> return;
> }
> }
>
> I compile with:
>
> g++ -c integral.C -fPIC -I/usr/local/include/gsl -o integral.o; R CMD
> SHLIB integral.o
>
> What could go wrong? The function modify its arguments ( the arguments
> are  pointers )
>
> I put my function with the C header directives in extern{}.
>
> gsl is a library written in C, so I put the gsl's header directives also
> inside extern{}.
>
> I placed in my compiling directory a Makevars file with this content:
>
> PKG_LIBS = -lm -lgsl -lgslcblas
>
> and my R code looks like:
>
> dyn.load('/usr/local/lib/libgslcblas.so',F,)
> dyn.load('/usr/local/lib/libgsl.so',F,)
> dyn.load('/home/f/p/integral.so')

Why are you doing this?  Only the last should be necessary. The
dynamic module integral.so will be linked against any dynamic libraries
on which it depends by the dlopen call underlying dyn.load (at least
on common implementations of dlopen).

The first thing to do is to check what symbols integral.so exports (with nm
-g) and what it depends on (with R CMD ldd integral.so since the R script
sets LD_LIBRARY_PATH).

You haven't told us your OS or compiler.  An experiment with what you gave
(and no content to the integral function) worked for me on Solaris 2.7 and
gcc 3.0.4 with just the final dyn.load.  (Not a complete test, of course,
since gsl was not really being used.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr 16 09:17:03 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 16 Apr 2002 08:17:03 +0100 (BST)
Subject: [R] multiple plot devices
In-Reply-To: <200204160636.g3G6aHv17018@mailgate5.cinetic.de>
Message-ID: <Pine.GSO.4.44.0204160809300.25486-100000@auk.stats>

On Tue, 16 Apr 2002 ozric at web.de wrote:

> Hello,
> sorry but i found no way or help to work
> with multiple graph devices (Rdocs,SearchIndex).

There is a section in `An Introduction to R' on `Multiple graphics
devices', so I don't know what you looked at but that was the most obvious
place to look.

See also

?dev.cur `Control Multiple Devices'


> When is use the function  only the graphic device of the last variable is open.
> How is it possible to let the several plot-device open or save this in a file with different names ?
> (win 2000 - R1.4.1)
>
> thanks for advance
> & regards,Christian
>
> normal <- function(x) {
>     par(mfrow=c(2,2))
>     hist(x)
>     boxplot(x)
>     sd <- summary(x)[5] - summary(x)[2]
>     plot(density(x,width=2*sd),xlab="x",ylab="",type="l")
>     qqnorm(x)
>     qqline(x)
>     }
> apply(data,2,normal)

?density will show you better bandwidth selectors than that one, including
the default (and we do suggest you use `bw' not `width').

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tobias.hoevekamp at ilw.agrl.ethz.ch  Tue Apr 16 09:20:51 2002
From: tobias.hoevekamp at ilw.agrl.ethz.ch (Tobias Hoevekamp)
Date: Tue, 16 Apr 2002 09:20:51 +0200
Subject: [R] Can one aply 'mgp' to individual axis?
Message-ID: <1018941651.3cbbd0d3bb404@email.ethz.ch>

Dear R-wizards! 

I want to move the axis label of the y-axis a little bit
more apart from the border of the plot (otherwise, it would overlap 
with my horizontal numbering). 'par(mgp(3.5, 1, 0))' does it properly. 
Unfortunately, it also moves the x-axis label which does not look good.

Is there a way to specify 'mgp' for each axis separately or 
is there another way to move just the y-axis label on its own? 

Thanks for looking into my problem. I hope there is a solution to it :-) 

Bye 




Tobias 

TOBIAS HOEVEKAMP 
mailto:tobias.hoevekamp at ilw.agrl.ethz.ch
http://www.vt.ilw.agrl.ethz.ch/~hoevekam
WORK: ETH Zurich, LFO E21, CH-8092 Zurich, +41 1 632 3304
HOME: Anna Heer-Str. 2,  CH-8057  Zurich,  +41 1 350 5986


-------------------------------------------------
This mail sent through IMP 3.0 at http://email.ethz.ch/horde/imp
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From gonin at genethon.fr  Tue Apr 16 09:29:36 2002
From: gonin at genethon.fr (Patrick Gonin)
Date: Tue, 16 Apr 2002 09:29:36 +0200
Subject: [R] Book
Message-ID: <a05100300b8e182eb1b2e@[192.168.100.154]>

Hi R colleagues,

Does anyone know about a good book devoted to statistical image 
analysis (especially using S/R) ?
Thanks in advance.
-- 
----------------------------
Patrick Gonin, DVM, PhD
G?n?thon
1 bis, rue de l'Internationale- BP 60
91002 EVRY CEDEX
FRANCE
Tel: 33-1-69-47-10-21
Fax: 33-1-60-77-86-98
gonin at genethon.fr
----------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Torsten.Hothorn at rzmail.uni-erlangen.de  Tue Apr 16 09:32:40 2002
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue, 16 Apr 2002 09:32:40 +0200 (MEST)
Subject: [R] symbols in lattice
Message-ID: <Pine.LNX.4.21.0204160924380.31323-100000@artemis.imbe.med.uni-erlangen.de>


Dear plotting experts, 

I simply can't figure out how I can force bwplot to print mathematical
symbols in the strips.

Example: 

x <- rnorm(30)
lab <- factor(c(rep("one", 10), rep("two", 10), rep("three", 10)))
bwplot(~ x | lab)

gives labels "one", "two", "tree" but I would like to change this into
expression(lambda == 1), expression(lambda == 2) and expression(lambda ==
3). 

The only way to modify the labels is changing the levels of lab, right? Or
is there something else?

Torsten

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr 16 09:38:02 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 16 Apr 2002 08:38:02 +0100 (BST)
Subject: [R] Can one aply 'mgp' to individual axis?
In-Reply-To: <1018941651.3cbbd0d3bb404@email.ethz.ch>
Message-ID: <Pine.LNX.4.31.0204160833280.12454-100000@gannet.stats>

On Tue, 16 Apr 2002, Tobias Hoevekamp wrote:

> Dear R-wizards!
>
> I want to move the axis label of the y-axis a little bit
> more apart from the border of the plot (otherwise, it would overlap
> with my horizontal numbering). 'par(mgp(3.5, 1, 0))' does it properly.

(That's not a valid par call.)

> Unfortunately, it also moves the x-axis label which does not look good.
>
> Is there a way to specify 'mgp' for each axis separately or
> is there another way to move just the y-axis label on its own?
>
> Thanks for looking into my problem. I hope there is a solution to it :-)

Use ylab="" in your main call to plot(), and place the ylabel subsequently
via a call such as title(ylab = "foo", mgp = c(3.5, 1, 0)).
Alternatively, use mtext to place the label exactly where you want it.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr 16 09:47:53 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 16 Apr 2002 08:47:53 +0100 (BST)
Subject: [R] symbols in lattice
In-Reply-To: <Pine.LNX.4.21.0204160924380.31323-100000@artemis.imbe.med.uni-erlangen.de>
Message-ID: <Pine.LNX.4.31.0204160841110.12454-100000@gannet.stats>

On Tue, 16 Apr 2002, Torsten Hothorn wrote:

>
> Dear plotting experts,
>
> I simply can't figure out how I can force bwplot to print mathematical
> symbols in the strips.
>
> Example:
>
> x <- rnorm(30)
> lab <- factor(c(rep("one", 10), rep("two", 10), rep("three", 10)))
> bwplot(~ x | lab)
>
> gives labels "one", "two", "tree" but I would like to change this into
> expression(lambda == 1), expression(lambda == 2) and expression(lambda ==
> 3).
>
> The only way to modify the labels is changing the levels of lab, right? Or
> is there something else?

You can set your own strip function to replace strip=strip.default
However, I am not aware that grid functions (on which lattice is based) do
plotmath.  ?grid.text suggests not.

   label: A vector of strings to draw.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From l.bargeot at educagri.fr  Tue Apr 16 08:50:11 2002
From: l.bargeot at educagri.fr (Lionel)
Date: Tue, 16 Apr 2002 08:50:11 +0200
Subject: [R] krige and polygon limit problem
In-Reply-To: <fc.554ee4ef554ee4efac3a45093b9aca00.179a981@educagri.fr>
References: <fc.554ee4ef554ee4efac3a45093b9aca00.179a981@educagri.fr>
Message-ID: <02041608501101.16622@agrogeomatic>

Le Lundi 15 Avril 2002 21:04, o.christensen at lancaster.ac.uk a ?crit :
> It is difficult to say exactly what your problem is, because you haven't
> provided the call you used.
Yes, I'm confused, it was the end of the day.

> This should be a number (``maxdist'' in the call) not a vector.
> My guess is that you have given the polygon-coordinates as input to
> ``maxdist'' instead of to ``border'' .

You're right ! My call was 
grid2.krige<-krige(grid2.point,logtab.point,"lz",logtab.Exp,extrap=T,border=li)

without maxdist and point.obj

Thanks for all

Lionel
-- 
CNERTA-ENESAD
4 rue champs-prevois
batiment grand-champs
21000 Dijon
tel:03.80.77.28.49
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Lennart.Araskoug at astrazeneca.com  Tue Apr 16 11:28:48 2002
From: Lennart.Araskoug at astrazeneca.com (Lennart.Araskoug@astrazeneca.com)
Date: Tue, 16 Apr 2002 11:28:48 +0200
Subject: [R] Multithreading
Message-ID: <709F5DB77812D61187A60001FA7E1D051C6403@se-drc-mail2.selu.astrazeneca.net>

Hi !

I wonder if the R application is capable of utilizing more than one CPU. I
need to know since we run it on a SunFire 3800 with 8 750 USIII cpu:s and on
a E420R with 4 USII cpu:s and we don't feel like we get the performance we
could expect.

I've seen some old discussions claiming that it isn't.

With kind regards

Lennart Araskoug
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mark at myatt.demon.co.uk  Tue Apr 16 11:27:29 2002
From: mark at myatt.demon.co.uk (Mark Myatt)
Date: Tue, 16 Apr 2002 10:27:29 +0100
Subject: [R] two questions
In-Reply-To: <PPEGLLABFLFCJDLCGPGHIEHECAAA.klavan@tiscalinet.it>
References: <PPEGLLABFLFCJDLCGPGHIEHECAAA.klavan@tiscalinet.it>
Message-ID: <UybNkQAB6+u8EwZF@myatt.demon.co.uk>

Ambrosini Alessandro <klavan at tiscalinet.it> writes:
>The first: if I have a vector as (1,1,3,2,1,1), which is the command that
>gives all the positions of the min value? From the vector of the example a
>would like to obtain a new vector as (1,2,5,6) that give me all the
>positions of the minimum value 1.

Something like:

        (1:length(x))[x == min(x)]

Does it. There is also a which() function:

        which(x == min(x))

This does it too.

>The second: if I have a matrix "A" and I want to obtain a new matrix
>deleting a column or a row of A, what have I to do?

Use negated row and column indices:

        m <- matrix(1:12, nrow = 3)
        # drop the second row
        m[-2, ]
        # drop the second column
        m[ ,-2]

>Hello! If I have a matrix as 1 2
>                             2 3
>and I want to change the value 2 in 0, what can I do?

        m <- matrix(c(1, 2, 2, 3), nrow = 2)
        m[m == 2] <- 0
        m

I Hope that helps. These sorts of questions are dealt with very fully in
most of the introductory texts available in the help system and from the
CRAN website.

Mark

--
Mark Myatt


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Apr 16 12:10:43 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 16 Apr 2002 12:10:43 +0200
Subject: [R] Multithreading
In-Reply-To: <709F5DB77812D61187A60001FA7E1D051C6403@se-drc-mail2.selu.astrazeneca.net>
References: <709F5DB77812D61187A60001FA7E1D051C6403@se-drc-mail2.selu.astrazeneca.net>
Message-ID: <x23cxwt0m4.fsf@blueberry.kubism.ku.dk>

Lennart.Araskoug at astrazeneca.com writes:

> Hi !
> 
> I wonder if the R application is capable of utilizing more than one CPU. I
> need to know since we run it on a SunFire 3800 with 8 750 USIII cpu:s and on
> a E420R with 4 USII cpu:s and we don't feel like we get the performance we
> could expect.
> 
> I've seen some old discussions claiming that it isn't.

It isn't ... yet. Duncan and Luke hope to get it going for 1.6.0.

You can in principle link against a threaded ATLAS library (although
there are known signal handling problems with that) and get multi-CPU
numerics performance. And of course run multiple instances of R.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Tue Apr 16 12:46:05 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Tue, 16 Apr 2002 06:46:05 -0400
Subject: [R] Can one aply 'mgp' to individual axis?
In-Reply-To: <Pine.LNX.4.31.0204160833280.12454-100000@gannet.stats>
References: <1018941651.3cbbd0d3bb404@email.ethz.ch>
	<Pine.LNX.4.31.0204160833280.12454-100000@gannet.stats>
Message-ID: <20020416064605.793a2d7c.fharrell@virginia.edu>

A general solution in which mgp.x and mgp.y could be specified in par would be extremely useful as it would allow a myriad of high-level plot functions to be called without change.  Absence of mgp.x or .y would cause a reversion to mgp.  I too have found a frequent need for unequal mgp for x and y.

Frank Harrell

On Tue, 16 Apr 2002 08:38:02 +0100 (BST)
ripley at stats.ox.ac.uk wrote:

> On Tue, 16 Apr 2002, Tobias Hoevekamp wrote:
> 
> > Dear R-wizards!
> >
> > I want to move the axis label of the y-axis a little bit
> > more apart from the border of the plot (otherwise, it would overlap
> > with my horizontal numbering). 'par(mgp(3.5, 1, 0))' does it properly.
> 
> (That's not a valid par call.)
> 
> > Unfortunately, it also moves the x-axis label which does not look good.
> >
> > Is there a way to specify 'mgp' for each axis separately or
> > is there another way to move just the y-axis label on its own?
> >
> > Thanks for looking into my problem. I hope there is a solution to it :-)
> 
> Use ylab="" in your main call to plot(), and place the ylabel subsequently
> via a call such as title(ylab = "foo", mgp = c(3.5, 1, 0)).
> Alternatively, use mtext to place the label exactly where you want it.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Lennart.Araskoug at astrazeneca.com  Tue Apr 16 13:24:30 2002
From: Lennart.Araskoug at astrazeneca.com (Lennart.Araskoug@astrazeneca.com)
Date: Tue, 16 Apr 2002 13:24:30 +0200
Subject: [R] Benchmarks
Message-ID: <709F5DB77812D61187A60001FA7E1D051C6411@se-drc-mail2.selu.astrazeneca.net>

Hi !

Is there anyone that has any current benchmark results from Sparc CPU's ?

I'm mostly interested of US-III 750 and US-II 450, But any US-II/III would
be interesting.

Regards

Lennart Araskoug
Astra Zeneca R & D
Lund, Sweden
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From luke at stat.umn.edu  Tue Apr 16 13:29:15 2002
From: luke at stat.umn.edu (Luke Tierney)
Date: Tue, 16 Apr 2002 06:29:15 -0500
Subject: [R] Multithreading
In-Reply-To: <x23cxwt0m4.fsf@blueberry.kubism.ku.dk>; from p.dalgaard@biostat.ku.dk on Tue, Apr 16, 2002 at 12:10:43PM +0200
References: <709F5DB77812D61187A60001FA7E1D051C6403@se-drc-mail2.selu.astrazeneca.net> <x23cxwt0m4.fsf@blueberry.kubism.ku.dk>
Message-ID: <20020416062915.A26216@nokomis.stat.umn.edu>

On Tue, Apr 16, 2002 at 12:10:43PM +0200, Peter Dalgaard BSA wrote:
> Lennart.Araskoug at astrazeneca.com writes:
> 
> > Hi !
> > 
> > I wonder if the R application is capable of utilizing more than one CPU. I
> > need to know since we run it on a SunFire 3800 with 8 750 USIII cpu:s and on
> > a E420R with 4 USII cpu:s and we don't feel like we get the performance we
> > could expect.
> > 
> > I've seen some old discussions claiming that it isn't.
> 
> It isn't ... yet. Duncan and Luke hope to get it going for 1.6.0.
> 
> You can in principle link against a threaded ATLAS library (although
> there are known signal handling problems with that) and get multi-CPU
> numerics performance. And of course run multiple instances of R.
> 

A bit more detail, from my perspective at least:

By 1.6 we hope to have the signal issue sorted out so that threaded
ATLAS can be used safely.  We may also have some early experiments at
parallelizing vectorized arithmetic going by then, but this is likely
to still be very rough at that point.  These are mechanisms that will
allow some degree of implicit parallelism in R; no explicit user
action will be needed to use this (except for the process of enabling
and setting this up, which is likely to be somewhat involved for a
while).

For explicit parallelism the rpvm package is already available, and a
couple of additional simpler (but less powerful) higher level
distributed memory tools are likely to be available by then as
packages. These are essentially ways of organizing and managing the
use of multiple R instances.

Concurrent threads within a single R process is something Duncan and I
have been working towards, off and on, for a while.  The main
motivation is to get improved responsiveness in things like embedding
in data bases and to allow conceptually concurrent tasks, like
concurrent user interaction read-eval-print loops and GUI event loops,
to be programmed more naturally--the same sorts of reasons many
applications use multiple threads on single processor systems.  It is,
in my view, highly unlikely that these R level threads will be able to
run in parallel any time soon, if ever.  At least initially it is
almost certain that we will have to use an approach similar to the one
used in Python and have a global lock that makes sure at most one
threads is running in R code at any given time. (There will be context
switching, just as there is among processes on single processor
machines, so these threads will execute concurrently, but no matter
how many processors you have there will be only one thread actively
running at any given time, at least initially.)  Getting to this point
by 1.7 or 1.8 is feasible in principle, if we don't get sidetracked by
other issues, but it's unlikely to happen by 1.6.

luke

-- 
Luke Tierney
University of Minnesota                      Phone:           612-625-7843
School of Statistics                         Fax:             612-624-8868
313 Ford Hall, 224 Church St. S.E.           email:      luke at stat.umn.edu
Minneapolis, MN 55455 USA                    WWW:  http://www.stat.umn.edu
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Tue Apr 16 14:00:17 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 16 Apr 2002 08:00:17 -0400
Subject: [R] Multithreading
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC20D@usrymx10.merck.com>

> From: Peter Dalgaard BSA [mailto:p.dalgaard at biostat.ku.dk]
> 
> Lennart.Araskoug at astrazeneca.com writes:
> 
> > Hi !
> > 
> > I wonder if the R application is capable of utilizing more 
> than one CPU. I
> > need to know since we run it on a SunFire 3800 with 8 750 
> USIII cpu:s and on
> > a E420R with 4 USII cpu:s and we don't feel like we get the 
> performance we
> > could expect.
> > 
> > I've seen some old discussions claiming that it isn't.
> 
> It isn't ... yet. Duncan and Luke hope to get it going for 1.6.0.
> 
> You can in principle link against a threaded ATLAS library (although
> there are known signal handling problems with that) and get multi-CPU
> numerics performance. And of course run multiple instances of R.

When I was fooling with ATLAS and MKL a while ago, I found that when I use
the threaded ATLAS, the elapsed time is actually longer than ATLAS w/o
threads.  MKL, OTOH, did provide the almost doubled speed expected on the
dual CPU box.  (Mandrake 7.1/R1.4.1/P3-866 Xeon).

Andy

------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message. If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From luke at stat.umn.edu  Tue Apr 16 14:12:00 2002
From: luke at stat.umn.edu (Luke Tierney)
Date: Tue, 16 Apr 2002 07:12:00 -0500
Subject: [R] Multithreading
In-Reply-To: <51F9C42DA15CD311BD220008C707D81906FFC20D@usrymx10.merck.com>; from andy_liaw@merck.com on Tue, Apr 16, 2002 at 08:00:17AM -0400
References: <51F9C42DA15CD311BD220008C707D81906FFC20D@usrymx10.merck.com>
Message-ID: <20020416071200.A27430@nokomis.stat.umn.edu>

On Tue, Apr 16, 2002 at 08:00:17AM -0400, Liaw, Andy wrote:
> > From: Peter Dalgaard BSA [mailto:p.dalgaard at biostat.ku.dk]
> > 
> > Lennart.Araskoug at astrazeneca.com writes:
> > 
> > > Hi !
> > > 
> > > I wonder if the R application is capable of utilizing more 
> > than one CPU. I
> > > need to know since we run it on a SunFire 3800 with 8 750 
> > USIII cpu:s and on
> > > a E420R with 4 USII cpu:s and we don't feel like we get the 
> > performance we
> > > could expect.
> > > 
> > > I've seen some old discussions claiming that it isn't.
> > 
> > It isn't ... yet. Duncan and Luke hope to get it going for 1.6.0.
> > 
> > You can in principle link against a threaded ATLAS library (although
> > there are known signal handling problems with that) and get multi-CPU
> > numerics performance. And of course run multiple instances of R.
> 
> When I was fooling with ATLAS and MKL a while ago, I found that when I use
> the threaded ATLAS, the elapsed time is actually longer than ATLAS w/o
> threads.  MKL, OTOH, did provide the almost doubled speed expected on the
> dual CPU box.  (Mandrake 7.1/R1.4.1/P3-866 Xeon).
> 
> Andy
> 

As I recall I did get about double speed with threaded ATLAS on a dual
P3 processor with the one or two examples I tread.  (SuSE
7.3/R-devel).

luke

-- 
Luke Tierney
University of Minnesota                      Phone:           612-625-7843
School of Statistics                         Fax:             612-624-8868
313 Ford Hall, 224 Church St. S.E.           email:      luke at stat.umn.edu
Minneapolis, MN 55455 USA                    WWW:  http://www.stat.umn.edu
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ozric at web.de  Tue Apr 16 16:18:01 2002
From: ozric at web.de (ozric@web.de)
Date: Tue, 16 Apr 2002 16:18:01 +0200
Subject: [R] multiple plot devices
Message-ID: <200204161418.g3GEI1v31939@mailgate5.cinetic.de>

....yes i know and normally "playing"  a little bit with the commands in R get a positive insight and result.
But my attempts with dev.*  and windows()  are until now negative,
but it can't be so difficult !?

thanks & regards,Christian

>
>There is a section in `An Introduction to R' on `Multiple graphics
>devices', so I don't know what you looked at but that was the most obvious
>place to look.
>
>See also
>
>?dev.cur `Control Multiple Devices'
>
>
>> When is use the function  only the graphic device of the last variable is open.
>> How is it possible to let the several plot-device open or save this in a file with different names ?
>> (win 2000 - R1.4.1)
>>
>> thanks for advance
>> & regards,Christian
>>
>> normal <- function(x) {
>>     par(mfrow=c(2,2))
>>     hist(x)
>>     boxplot(x)
>>     sd <- summary(x)[5] - summary(x)[2]
>>     plot(density(x,width=2*sd),xlab="x",ylab="",type="l")
>>     qqnorm(x)
>>     qqline(x)
>>     }
>> apply(data,2,normal)
>
>?density will show you better bandwidth selectors than that one, including
>the default (and we do suggest you use `bw' not `width').
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272860 (secr)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>
________________________________________________________________
Keine verlorenen Lotto-Quittungen, keine vergessenen Gewinne mehr! 



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tklistaddr at keittlab.bio.sunysb.edu  Tue Apr 16 17:11:05 2002
From: tklistaddr at keittlab.bio.sunysb.edu (Timothy H. Keitt)
Date: 16 Apr 2002 11:11:05 -0400
Subject: [R] Multithreading
In-Reply-To: <20020416062915.A26216@nokomis.stat.umn.edu>
References: 
	<709F5DB77812D61187A60001FA7E1D051C6403@se-drc-mail2.selu.astrazeneca.net>
	<x23cxwt0m4.fsf@blueberry.kubism.ku.dk> 
	<20020416062915.A26216@nokomis.stat.umn.edu>
Message-ID: <1018969865.14740.12.camel@keittlab-6>

This seems entirely reasonable. We shouldn't expect a language like R to
deliver native high performance computing; its value is as a layer above
highly optimized C/Fortran/other code, e.g. Atlas. Probably, the biggest
short term gain in performance would be to implement parallel versions
(threads, pvm, mpi) of apply and friends. I've lately been getting up to
10x performance improvements after replacing explicit loops with lapply
statements called on closures.

T.

On Tue, 2002-04-16 at 07:29, Luke Tierney wrote:
> in my view, highly unlikely that these R level threads will be able to
> run in parallel any time soon, if ever.  At least initially it is
> almost certain that we will have to use an approach similar to the one
> used in Python and have a global lock that makes sure at most one
> threads is running in R code at any given time. (There will be context

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rg117 at ohm.york.ac.uk  Tue Apr 16 17:13:39 2002
From: rg117 at ohm.york.ac.uk (Rishabh Gupta)
Date: Tue, 16 Apr 2002 16:13:39 +0100
Subject: [R] Classification Analysis
Message-ID: <000f01c1e559$49d79600$35892090@ohm.york.ac.uk>

Hi everyone,
    Could somebody explain to me what is the package/function for
classification analysis. I am performing analysis of music files in the form
of MIDI files. I end up with about 750 dependent variables from the
analysis, I also have a number of independent/grouping variables that I set
manually. What I would like is to be able to predict which group a
particular MIDI files belongs to given the 750 dependent variables. In order
to this I have to perform classification analysis on a sample set of MIDI
files where I know what group they belong to. I want to extract the
'classification rule' that would enable me to predict the group of each MIDI
file (there would be a different classification rule for each grouping
variable). Can anybody explain what is the best way of doing this in R. What
is the best package/function that would enable me to perform classification
analysis.

Any help would be greatly appreciated.

Many Thanks For Your Help!

Rishabh

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Tue Apr 16 17:14:07 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 16 Apr 2002 08:14:07 -0700 (PDT)
Subject: [R] Benchmarks
In-Reply-To: <709F5DB77812D61187A60001FA7E1D051C6411@se-drc-mail2.selu.astrazeneca.net>
Message-ID: <Pine.A41.4.44.0204160807180.117774-100000@homer05.u.washington.edu>

On Tue, 16 Apr 2002 Lennart.Araskoug at astrazeneca.com wrote:

> Hi !
>
> Is there anyone that has any current benchmark results from Sparc CPU's ?
>
> I'm mostly interested of US-III 750 and US-II 450, But any US-II/III would
> be interesting.

We used to have some UltraSparc II machines, I believe at 450MHz.  R ran
very slightly faster on a 450MHz Pentium III than on the UltraSparc, based
on make check and on the survival package tests. I don't have any absolute
figures, but they would be obsolete anyway.

	-thomas


Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr 16 17:22:14 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 16 Apr 2002 16:22:14 +0100 (BST)
Subject: [R] Multithreading
In-Reply-To: <1018969865.14740.12.camel@keittlab-6>
Message-ID: <Pine.LNX.4.31.0204161616320.21647-100000@gannet.stats>

On 16 Apr 2002, Timothy H. Keitt wrote:

> This seems entirely reasonable. We shouldn't expect a language like R to
> deliver native high performance computing; its value is as a layer above
> highly optimized C/Fortran/other code, e.g. Atlas. Probably, the biggest
> short term gain in performance would be to implement parallel versions
> (threads, pvm, mpi) of apply and friends. I've lately been getting up to
> 10x performance improvements after replacing explicit loops with lapply
> statements called on closures.

Careful!  They are running (arbitrary) R code, and Luke's caveats apply.
Internally lapply does an eval(), and we can't have more than one of
those running at once without all the perils of user R-level threads,
as I understand it.

apply() is expensive because of the checking/housekeeping it does, and so
it seems not worthwhile re-writing it in internal code, whereas it was
worth it for lapply.  Generally if an apply call is expensive, see if it
can (easily) be rewritten with lapply.


>
> T.
>
> On Tue, 2002-04-16 at 07:29, Luke Tierney wrote:
> > in my view, highly unlikely that these R level threads will be able to
> > run in parallel any time soon, if ever.  At least initially it is
> > almost certain that we will have to use an approach similar to the one
> > used in Python and have a global lock that makes sure at most one
> > threads is running in R code at any given time. (There will be context
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr 16 17:40:31 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 16 Apr 2002 16:40:31 +0100 (BST)
Subject: [R] Benchmarks
In-Reply-To: <Pine.A41.4.44.0204160807180.117774-100000@homer05.u.washington.edu>
Message-ID: <Pine.LNX.4.31.0204161625100.21647-100000@gannet.stats>

On Tue, 16 Apr 2002, Thomas Lumley wrote:

> On Tue, 16 Apr 2002 Lennart.Araskoug at astrazeneca.com wrote:
>
> > Hi !
> >
> > Is there anyone that has any current benchmark results from Sparc CPU's ?
> >
> > I'm mostly interested of US-III 750 and US-II 450, But any US-II/III would
> > be interesting.
>
> We used to have some UltraSparc II machines, I believe at 450MHz.  R ran
> very slightly faster on a 450MHz Pentium III than on the UltraSparc, based
> on make check and on the survival package tests. I don't have any absolute
> figures, but they would be obsolete anyway.

We have what I believe is a dual 400MHz UltraSparc box.  It's a server,
and uname -a says it is Ultra-4.  With the native compilers (especially
f77/f95) it is quite a bit faster (maybe 50%) running R than our (dual)
450MHz Pentium III server.  But this is irrelevant given the price and
speed of, say, an Athlon XP1800.

One issue is that R runs slower (say 10%) when targetted at v9 (64-bit
mode) chips (and hence compiled to use 64-bit pointers and longs).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From reid_huntsinger at merck.com  Tue Apr 16 18:00:32 2002
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Tue, 16 Apr 2002 12:00:32 -0400
Subject: [R] Classification Analysis
Message-ID: <2C23DE2983BE034CB1CB90DB6B813FD639E944@uswpmx11.merck.com>

This is a very general problem and a very large area of statistics/computer
science/etc is concerned with it. R provides lots of possibilities; you
might find tree-based approaches (recursive partitioning) to suit your
needs; in that case, rpart and the new random forests package will be of
interest. Also see package e1071 and the VR packages for starters. There are
lot of other possibilities; you might want to have a look at Ripley, Pattern
Recognition and Neural Networks, for example, to see some.

Reid Huntsinger

-----Original Message-----
From: Rishabh Gupta [mailto:rg117 at ohm.york.ac.uk]
Sent: Tuesday, April 16, 2002 11:14 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Classification Analysis


Hi everyone,
    Could somebody explain to me what is the package/function for
classification analysis. I am performing analysis of music files in the form
of MIDI files. I end up with about 750 dependent variables from the
analysis, I also have a number of independent/grouping variables that I set
manually. What I would like is to be able to predict which group a
particular MIDI files belongs to given the 750 dependent variables. In order
to this I have to perform classification analysis on a sample set of MIDI
files where I know what group they belong to. I want to extract the
'classification rule' that would enable me to predict the group of each MIDI
file (there would be a different classification rule for each grouping
variable). Can anybody explain what is the best way of doing this in R. What
is the best package/function that would enable me to perform classification
analysis.

Any help would be greatly appreciated.

Many Thanks For Your Help!

Rishabh

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named in this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From l.bargeot at educagri.fr  Tue Apr 16 18:08:04 2002
From: l.bargeot at educagri.fr (Lionel)
Date: Tue, 16 Apr 2002 18:08:04 +0200
Subject: [R] still have problem with krige and border option
Message-ID: <02041618080402.18980@agrogeomatic>

Dear all,

I would like to estimate rainfall with the krige function. First, I produce a 
polygon of my region of interest (where poly_test.txt is a x,y suite of 
points defining a polygon, obtained with the grass v.out.ascii command) :

user>border_limite<-read.table("/home/lionel/rwork/poly_test.txt",header=FALSE)
user>polygone<-list(x=border_limite[,1],y=border_limite[,2])

So now I have a list of x,y coordinates to limit my work area.
If I call the function krige with extrap=FALSE like this

user>grid2.krige<-krige(grid2.point,logtab.point,'lz', 
logtab.Exp,maxdist=NULL,extrap=FALSE)

[ where grid2.point is a point object to store prediction, logtab.point a 
point object containing points data, 'lz' is the variable name in 
logtab.point, logtab.Exp is a variogram object ]

all works quiet well, but I am limited to a convex hull inside the limite 
designed by points of measure.

If I set extrap=TRUE, all works, but values are estimated all over my area.

Now if use the polygon I defined, and specifie it in the function call
user>grid2.krige<-krige(grid2.point,logtab.point,'lz', 
logtab.Exp,maxdist=NULL,extrap=TRUE,border=polygone)
all points in the area are estimated.

I've tried to put extrap=FALSE with border, but then there is no result, and 
no points are found.
Here is my polygon definition:
$x
[1] 2272048 2275274 2296044 2293826 2280517 2272048
$y
[1] 781270.4 801031.7 795385.6 773003.0 765945.4 781270.4

So my question is, do you see any stupid mistake I can make ?

last point (optional!) about krige.G
I also tried to use krige.G from the grass package, but for the moment I have 
a strange error message : (where G is obtained with gmeta() command)

user>grid2.krige<-krige.G(logtab.point,"lz",logtab.Exp,G)
Error in surf.gls(0, expcov, x = point.obj$x, y = point.obj$y, z = at.val,  : 
        Rank failure in Choleski decomposition

I've just reported my point and variogram definition in the options. Perhap's 
is there a small difference between parameters when they are passed to krige 
function but I don't see wich.

Thanks in advance for all kind of help

Lionel

-- 
CNERTA-ENESAD
4 rue champs-prevois
batiment grand-champs
21000 Dijon
tel:03.80.77.28.49
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Tue Apr 16 18:34:18 2002
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Tue, 16 Apr 2002 12:34:18 -0400
Subject: [R] sum(NA,na.rm=T)
Message-ID: <20020416123418.A29266@cattell.psych.upenn.edu>

This is zero!

That causes serious problems when I'm using sum() or mean() to
get the sum or mean of the non-missing data for each of several
subjects, some of whom have all data missing (on some variable),
and thus get a mean of 0.  E.g., with
apply(matrix1,1,sum,na.rm=T)
some rows have all NA's, so the result I want is NA, but I get 0.

Is there an ELEGANT workaround that gives NA instead of 0?

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Tue Apr 16 18:40:19 2002
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Tue, 16 Apr 2002 12:40:19 -0400
Subject: [R] sum(NA,na.rm=T) - answered my own question - sorry
Message-ID: <20020416124019.A328@cattell.psych.upenn.edu>

This problem does not exist for "mean()" in fact, so that is the
elegant workaround.  Sorry.  Jon

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From forporphyry at hotmail.com  Tue Apr 16 22:29:58 2002
From: forporphyry at hotmail.com (graham lawrence)
Date: Tue, 16 Apr 2002 13:29:58 -0700
Subject: [R] passing ", betrayed by the non-vanishing \
Message-ID: <F170rP0695hUEY8AERr0000b154@hotmail.com>

mtex[3]<-"I need\'s a \"double quote\" with no backslash"
mtex[3]
[1] "I need's a \"double quote\" with no backslash"

so how is it done?  Thanks in advance,

graham lawrence

_________________________________________________________________


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tklistaddr at keittlab.bio.sunysb.edu  Tue Apr 16 21:06:15 2002
From: tklistaddr at keittlab.bio.sunysb.edu (Timothy H. Keitt)
Date: 16 Apr 2002 15:06:15 -0400
Subject: [Fwd: Re: [R] Multithreading]
Message-ID: <1018983975.14740.23.camel@keittlab-6>

Oops. Seems I only sent this to myself.

T.

-------------- next part --------------
An embedded message was scrubbed...
From: "Timothy H. Keitt" <tklistaddr at keittlab.bio.sunysb.edu>
Subject: Re: [R] Multithreading
Date: 16 Apr 2002 12:34:52 -0400
Size: 2091
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20020416/dd6c9385/attachment.mht

From p.dalgaard at biostat.ku.dk  Tue Apr 16 23:03:47 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 16 Apr 2002 23:03:47 +0200
Subject: [R] passing ", betrayed by the non-vanishing \
In-Reply-To: <F170rP0695hUEY8AERr0000b154@hotmail.com>
References: <F170rP0695hUEY8AERr0000b154@hotmail.com>
Message-ID: <x2ads3qrt8.fsf@blueberry.kubism.ku.dk>

"graham lawrence" <forporphyry at hotmail.com> writes:

> mtex[3]<-"I need\'s a \"double quote\" with no backslash"
> mtex[3]
> [1] "I need's a \"double quote\" with no backslash"
> 
> so how is it done?  Thanks in advance,

You's got two of them in there already! Try cat(mtex[3], "\n")

Printing character strings will always escape double quotes,
backaslashes and various control characters. No way around that except
by using cat().

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Tue Apr 16 23:07:54 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 16 Apr 2002 14:07:54 -0700 (PDT)
Subject: [R] passing ", betrayed by the non-vanishing \
In-Reply-To: <F170rP0695hUEY8AERr0000b154@hotmail.com>
Message-ID: <Pine.A41.4.44.0204161405170.117774-100000@homer05.u.washington.edu>

On Tue, 16 Apr 2002, graham lawrence wrote:

> mtex[3]<-"I need\'s a \"double quote\" with no backslash"
> mtex[3]
> [1] "I need's a \"double quote\" with no backslash"
>
> so how is it done?  Thanks in advance,

Do you want to construct a string that contains a double quote and no
backslash or to print a double quote on the screen without printing a
backslash?

You've done the first, as this shows
> a<-"\""
> a
[1] "\""
> nchar(a)
[1] 1
so a contains a single character, the double quote.

To display on the screen without a backslash use
> print(a,quote=F)
[1] "
or
> cat(a)
">

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at blindglobe.net  Tue Apr 16 23:21:09 2002
From: rossini at blindglobe.net (A.J. Rossini)
Date: 16 Apr 2002 14:21:09 -0700
Subject: [Fwd: Re: [R] Multithreading]
In-Reply-To: <1018983975.14740.23.camel@keittlab-6>
References: <1018983975.14740.23.camel@keittlab-6>
Message-ID: <87sn5v7322.fsf@jeeves.blindglobe.net>

>>>>> "timothy" == Timothy H Keitt <tklistaddr at keittlab.bio.sunysb.edu> writes:

    timothy> On Tue, 2002-04-16 at 11:22, ripley at stats.ox.ac.uk wrote:
    >> Careful!  They are running (arbitrary) R code, and Luke's caveats apply.
    >> Internally lapply does an eval(), and we can't have more than one of
    >> those running at once without all the perils of user R-level threads,
    >> as I understand it.

    timothy> Ah, yes, I see the problem there. Sounds like the rpvm version might be
    timothy> interesting though. In practice, most of the problems I work on are of
    timothy> the 'embarrassingly parallel' variety -- running the same code with
    timothy> different parameters -- and wouldn't really benefit much from low-level
    timothy> parallelism. For those, I've found that having a process query a
    timothy> database for parameter sets, compute a result and then write the result
    timothy> back to the database before proceeding to the next parameter set works
    timothy> well. You get automatic load balancing and can query the database for
    timothy> intermediate results. Maybe I'll package that up for general consumption
    timothy> at some point.

While RPVM is annoying to setup, I should mention that features that
we are working for "Release Soon"(tm), are
1. use of the SPRNG library, as a separate package (this is a parallel
   RNG, which gives reasonable results and is designed for parallel
   situations).  This might be useful in other contexts as well
2. simple examples for bootstrap.

I should note that someone (to remain nameless) has offered to provide
a means to serialize R objects sensibly.  We'll see when that happens;
it's simple provided that you program carefully.  However, I'd like a
variant which is simple even when you are a programming klutz.

I'd also like to construct simple examples for simple global
optimization as well as MCMC, but I don't see doing these personally
in the near-ish future.

In addition, note that PVM jobs migrate on MOSIX/OpenMOSIX.  I've
preliminary evidence that this is true for RPVM jobs, as well (since
Python is problematic under MOSIX, I'm not going to claim more than
preliminary evidence). 

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M-W: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my friday location is usually completely unpredictable.)


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Ralf.Kloessinger at student.fh-nuernberg.de  Wed Apr 17 01:51:53 2002
From: Ralf.Kloessinger at student.fh-nuernberg.de (Ralf.Kloessinger@student.fh-nuernberg.de)
Date: Wed, 17 Apr 2002 01:51:53 +0200
Subject: [R] k-Nearest Neighbour density estimation
Message-ID: <isapiwc.4b8d1e19.6dde.3cbcb919.9c454.df@stud-iss.cs.fh-nuernberg.de>

Hello!!!

I search for a function which does a k-Nearest Neighbour density estimation.
I found the package class with the function knn, but this is only an classifier.

What i need is:
I have a file with one variable which is a score with the range between 0 and 100. The scores occur often, so that we have a histogram. The histogram has gaps, especially at the scores higher than 50. 
What i like to do is to remap the histogram to fill up the gaps. Than using the knn function: p(s)=(k-1)/N*V(x) to get the density.

Example:
score: histogram: remaped:
0      2345       2345
1      5678       5678
2      6789       6789
3      0          14 
4      0          9999  
5      9
6      5
7      9999
...

Thank you for your help and your time.

Ralf
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ozric at web.de  Wed Apr 17 08:43:39 2002
From: ozric at web.de (ozric@web.de)
Date: Wed, 17 Apr 2002 08:43:39 +0200
Subject: [R] Classification Analysis
Message-ID: <200204170643.g3H6hcv21849@mailgate5.cinetic.de>

Rishabh,
Software which extract rules from data are my main "WorkingField" but
it's to bad that in present nothing rule generating algorithm (package) exist.
I do my best to get R programming skills until end2002 for my contribution in data-mining package development,because R is a great basic for this.

Some nice free-software ressources ( not R ) for this purpose are:
http://www.cs.waikato.ac.nz/ml/weka/    (look C4.5Part for rule generating)
http://fuzzy.cs.uni-magdeburg.de/~borgelt/software.html#dtree   
(that's for you probably interesting, because it's very fast C4.5 implementation and you can use in lot of way prune to
reduce the complexity 750 variables!)

http://fuzzy.cs.uni-magdeburg.de/nefclass/nefclass.html  


Or my present favorit  from J.Mortensen (it's great)  when you want analyse your data
with fuzzy strategies..........
http://inet.uni2.dk/~jemor/jfs.htm

P.S.
One question - i make electronic music with ComputerSoftware,too
and i'm statistican - what are the 750 variables and what is your classification criterium ? (if it is not a secret !)
regards,christian




Am 16.04.2002 17:13:39, schrieb "Rishabh Gupta" <rg117 at ohm.york.ac.uk>:
>Hi everyone,
>    Could somebody explain to me what is the package/function for
>classification analysis. I am performing analysis of music files in the form
>of MIDI files. I end up with about 750 dependent variables from the
>analysis, I also have a number of independent/grouping variables that I set
>manually. What I would like is to be able to predict which group a
>particular MIDI files belongs to given the 750 dependent variables. In order
>to this I have to perform classification analysis on a sample set of MIDI
>files where I know what group they belong to. I want to extract the
>'classification rule' that would enable me to predict the group of each MIDI
>file (there would be a different classification rule for each grouping
>variable). Can anybody explain what is the best way of doing this in R. What
>is the best package/function that would enable me to perform classification
>analysis.
>
>Any help would be greatly appreciated.
>
>Many Thanks For Your Help!
>
>Rishabh
>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>
______________________________________________________________________________
100 MB und noch mehr gute Gr?nde! Jetzt anmelden und profitieren. Da ist mehr 
f?r Sie drin unter http://club.web.de/?mc=021103

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Wed Apr 17 08:42:35 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 17 Apr 2002 08:42:35 +0200
Subject: [R] passing ", betrayed by the non-vanishing \
In-Reply-To: <x2ads3qrt8.fsf@blueberry.kubism.ku.dk>
References: <F170rP0695hUEY8AERr0000b154@hotmail.com>
	<x2ads3qrt8.fsf@blueberry.kubism.ku.dk>
Message-ID: <15549.6491.602298.747831@gargle.gargle.HOWL>


    PD> "graham lawrence" <forporphyry at hotmail.com> writes:

    >>> mtex[3]<-"I need\'s a \"double quote\" with no backslash"
    >>> mtex[3]
    >>> [1] "I need's a \"double quote\" with no backslash"

    >>> so how is it done?  Thanks in advance,

    PD> You's got two of them in there already! Try
    > cat(mtex[3], "\n")

    PD> Printing character strings will always escape double quotes,
    PD> backaslashes and various control characters. No way around that except
    PD> by using cat().

the really amusing thing about this topic: about a dozen mail
hosts from R-help subscribers have bounced the above message,
giving as reason

>>   Diagnostic-Code: SMTP; 553 5.0.0 Unbalanced '"'

Quite a funny example of an error of the 2nd kind when trying to
do spam/virus protection...

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wolfram at fischer-zim.ch  Wed Apr 17 09:38:33 2002
From: wolfram at fischer-zim.ch (Wolfram Fischer - Z/I/M)
Date: Wed, 17 Apr 2002 09:38:33 +0200
Subject: [R] No output from (lattice) xyplot called within loops
Message-ID: <NDBBINKOMLDCOHBLDMGHMELOCMAA.wolfram@fischer-zim.ch>

Hello

>From the following script I received 
a grafic output when I called:

	- xyplot.test( 'green3' )
	- call.xyplot.test( 'blue3' )

I did NOT receive a grafic output 
when I called:

	- loop.xyplot.test( 'red3' )

What's the Problem?

NB: I am using R 1.4.1 on Linux.

--------- START OF SCRIPT ----------------
n <- 1000
x <- seq( 1, n )
y <- rnorm( n )

xyplot.test <- function( col ){
	xyplot( y ~ x , col=col )
}

call.xyplot.test <- function( col ){
	xyplot.test( col )
}

loop.xyplot.test <- function( c.col ){
	for( col in c.col ){
		xyplot.test( col )
	}
}

--------- END OF SCRIPT ----------------

Wolfram Fischer
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Apr 17 09:53:23 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 17 Apr 2002 08:53:23 +0100 (BST)
Subject: [R] No output from (lattice) xyplot called within loops
In-Reply-To: <NDBBINKOMLDCOHBLDMGHMELOCMAA.wolfram@fischer-zim.ch>
Message-ID: <Pine.LNX.4.31.0204170851450.5898-100000@gannet.stats>

You have to *print* the output from lattice.  Auto-printing did this for
you in the first two cases but not the third.

On Wed, 17 Apr 2002, Wolfram Fischer - Z/I/M wrote:

> Hello
>
> >From the following script I received
> a grafic output when I called:
>
> 	- xyplot.test( 'green3' )
> 	- call.xyplot.test( 'blue3' )
>
> I did NOT receive a grafic output
> when I called:
>
> 	- loop.xyplot.test( 'red3' )
>
> What's the Problem?
>
> NB: I am using R 1.4.1 on Linux.
>
> --------- START OF SCRIPT ----------------
> n <- 1000
> x <- seq( 1, n )
> y <- rnorm( n )
>
> xyplot.test <- function( col ){
> 	xyplot( y ~ x , col=col )
        ^print(                  ^)

> }
>
> call.xyplot.test <- function( col ){
> 	xyplot.test( col )
> }
>
> loop.xyplot.test <- function( c.col ){
> 	for( col in c.col ){
> 		xyplot.test( col )
> 	}
> }
>
> --------- END OF SCRIPT ----------------

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ken_lee at tynesys.com  Wed Apr 17 11:45:39 2002
From: ken_lee at tynesys.com (ken_lee)
Date: Wed, 17 Apr 2002 17:45:39 +0800
Subject: [R] Converter issues
Message-ID: <IPECKKKLFINFHEGMEKKGOEADCAAA.ken_lee@tynesys.com>

Hi,
    If I had java array reda 
        Integer[][] reda=new Integer[3][2];
       reda[0][0]=new Integer(1);   
       reda[1][0]=new Integer(2);
       reda[2][0]=new Integer(3);
       reda[0][1]=new Integer(4);   
       reda[1][1]=new Integer(5);
       reda[2][1]=new Integer(6);

 How can I  converter the java object  to R object?

 Thanks,
   Ken Lee
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From l.bargeot at educagri.fr  Wed Apr 17 12:39:25 2002
From: l.bargeot at educagri.fr (Lionel)
Date: Wed, 17 Apr 2002 12:39:25 +0200
Subject: [R] still have problem with krige and border option [end]
In-Reply-To: <fc.8b31bfd78b31bfd7d7bf318b3b9aca00.17a5ad4@educagri.fr>
References: <fc.8b31bfd78b31bfd7d7bf318b3b9aca00.17a5ad4@educagri.fr>
Message-ID: <02041712392505.25916@agrogeomatic>

> both "_ "and "<-" are assignment operators
well, I've changed it in my script, but the result is the same.

> what do you get if you call
>
> in.polygon(grid2.point$x,grid2.point$y,polygon$x,polygon$y)


That's it !

In fact all my points in grid2.point where xy inverted. And I had no points 
in polygon.

It was really a stupid mistake. Thanks for all !

Lionel

-- 
CNERTA-ENESAD
4 rue champs-prevois
batiment grand-champs
21000 Dijon
tel:03.80.77.28.49
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rasmus.benestad at met.no  Wed Apr 17 14:34:20 2002
From: rasmus.benestad at met.no (Rasmus Benestad)
Date: Wed, 17 Apr 2002 12:34:20 +0000
Subject: [R] using the netCDF.zip package in Windows (XP).
Message-ID: <3CBD6BCC.9070903@met.no>

Dear R-help,

I have a question relating to the netCDF package for R in the Windows 
environment. I
have used this package in the Linux version with no problem, and the 
Windows version
of R installed the package without problems. But there are problems when 
I try to read a
netCDF file:

Error in .C("open_netcdf", filename, id=as.integer(verbose)):
C/Fortran function name not in load table

Do I need to install a netCDF library for Windows and if so, do you know 
where the
library ought to be located?

Yours sinvcerely Rasmus

-- 
______________________________________________________________________________
Rasmus E. Benestad, D.Phil, AMINSTP,    The Norwegian Meteorological Institute
rasmus.benestad at met.no            
phone: (+47) 22 96 33 77   mobile: (+47) 99 45 04 16    fax: (+47) 22 96 30 50
______________________________________________________________________________


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From garbade at psy.uni-muenchen.de  Wed Apr 17 16:55:57 2002
From: garbade at psy.uni-muenchen.de (Sven Garbade)
Date: Wed, 17 Apr 2002 14:55:57 +0000
Subject: [R] Cross-correlation
Message-ID: <3CBD8CFD.45C30F8@psy.uni-muenchen.de>

Hi all,

I want to recalculate an analysis found in a paper. An empirical time
series (velocities, altogether 241 data values) were cross-correlated
with an invertited cosine function (200 milliseconds duration).
Following the authors the resulting values should offer some advantages:
being independent of gain and peak latency differences between single
trials and preserving the temporal aspect of the modulation. Is there a
function to calculate cross-correlations in R? I think cor() is ot the
right one.

Thanks, Sven
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rg117 at ohm.york.ac.uk  Wed Apr 17 15:13:47 2002
From: rg117 at ohm.york.ac.uk (Rishabh Gupta)
Date: Wed, 17 Apr 2002 14:13:47 +0100
Subject: [R] Classification Analysis
References: <2C23DE2983BE034CB1CB90DB6B813FD639E944@uswpmx11.merck.com>
Message-ID: <002b01c1e611$b58e02e0$35892090@ohm.york.ac.uk>

Thanks for your reply.
I am still learning these aspects of statistical analysis, so if I don't
make sense please forgive me.
All this work I am doing is part of a Phd and my deparment does not really
neural network for situations like these because they say it acts like a
black box and we don't really know what is happening in the inside. So I
would like to concentrate on using pure statistical techniques. Ideally what
I would like is some kind of a function that calculates the "classification
rule" when given a grouped data set :
    rule <- classification( GroupVar ~ DepVar1 + DepVar2 + DepVar3 + DepVar4
..... + ...... DepVarX )

Then I would be able to use that rule and apply to a single data element for
which the group is not known:

    theGroup <- rule( DataElement )

I have looked at the rpart package in R but I am not entirely sure how to
use in a way that I can create the "classification rule" and then use that
rule. I understand that it is a general problem but it's made more difficult
for me because I have to deal with 750 dependent variables.

Your help is greatly appreciated.

Many Thanks

Rishabh

----- Original Message -----
From: "Huntsinger, Reid" <reid_huntsinger at merck.com>
To: "'Rishabh Gupta'" <rg117 at ohm.york.ac.uk>; <r-help at stat.math.ethz.ch>
Sent: Tuesday, April 16, 2002 5:00 PM
Subject: RE: [R] Classification Analysis


> This is a very general problem and a very large area of
statistics/computer
> science/etc is concerned with it. R provides lots of possibilities; you
> might find tree-based approaches (recursive partitioning) to suit your
> needs; in that case, rpart and the new random forests package will be of
> interest. Also see package e1071 and the VR packages for starters. There
are
> lot of other possibilities; you might want to have a look at Ripley,
Pattern
> Recognition and Neural Networks, for example, to see some.
>
> Reid Huntsinger
>
> -----Original Message-----
> From: Rishabh Gupta [mailto:rg117 at ohm.york.ac.uk]
> Sent: Tuesday, April 16, 2002 11:14 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Classification Analysis
>
>
> Hi everyone,
>     Could somebody explain to me what is the package/function for
> classification analysis. I am performing analysis of music files in the
form
> of MIDI files. I end up with about 750 dependent variables from the
> analysis, I also have a number of independent/grouping variables that I
set
> manually. What I would like is to be able to predict which group a
> particular MIDI files belongs to given the 750 dependent variables. In
order
> to this I have to perform classification analysis on a sample set of MIDI
> files where I know what group they belong to. I want to extract the
> 'classification rule' that would enable me to predict the group of each
MIDI
> file (there would be a different classification rule for each grouping
> variable). Can anybody explain what is the best way of doing this in R.
What
> is the best package/function that would enable me to perform
classification
> analysis.
>
> Any help would be greatly appreciated.
>
> Many Thanks For Your Help!
>
> Rishabh
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.
> -.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._
>
>
> --------------------------------------------------------------------------
----
> Notice:  This e-mail message, together with any attachments, contains
information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that
may be confidential, proprietary copyrighted and/or legally privileged, and
is intended solely for the use of the individual or entity named in this
message.  If you are not the intended recipient, and have received this
message in error, please immediately return this by e-mail and then delete
it.
>
>
============================================================================
==
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From alobo at ija.csic.es  Wed Apr 17 15:24:49 2002
From: alobo at ija.csic.es (Agustin Lobo)
Date: Wed, 17 Apr 2002 15:24:49 +0200 (MET DST)
Subject: [R] union of lists
Message-ID: <Pine.OSF.3.96.1020417151201.30270B-100000@ija.csic.es>

Hi there,

Given 2 lists of integer vectors, i.e.:

> lista1
$"1"
[1]  1 34  5
$"2"
[1] 2 1
$"3"
[1]  3 10 15

> lista2
$"1"
[1] 1 5
$"2"
[1] 2 1
$"3"
[1]  3 10 29


I want to obtain the union of both, defined
as the union of the vectors, that is 
lista.union[[1]] <- union(lista1[[1]],lista2[[1]]):

> lista.union
$"1"
[1]  1 34  5
$"2"
[1] 2 1
$"3"
[1]  3 10 15 29

I'm now using a for loop and applying
union() to each pair of vectors, but is
there a faster way avoiding the for ?

Thanks!

Agus


Dr. Agustin Lobo
Instituto de Ciencias de la Tierra (CSIC)
Lluis Sole Sabaris s/n
08028 Barcelona SPAIN
tel 34 93409 5410
fax 34 93411 0012
alobo at ija.csic.es


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rg117 at ohm.york.ac.uk  Wed Apr 17 15:22:08 2002
From: rg117 at ohm.york.ac.uk (Rishabh Gupta)
Date: Wed, 17 Apr 2002 14:22:08 +0100
Subject: [R] Classification Analysis
References: <200204170643.g3H6hcv21849@mailgate5.cinetic.de>
Message-ID: <003a01c1e612$e052b100$35892090@ohm.york.ac.uk>

Thanks For your reply
I would really prefer to use R as I am using R for all the other exploratory
analysis that I am doing on the data

P.S.
One question - i make electronic music with ComputerSoftware,too
and i'm statistican - what are the 750 variables and what is your
classification criterium ? (if it is not a secret !)
regards,christian

I have a large of variables (750) because I have a lot of version of each
kind of data. I analyse melody, rhythm, harmony, etc as a different stream
of data. For each one, I calculate a different versions, intervals, contour,
modulo, modulo of interval, etc. For each one of those I perform a different
kind of analysis, basic statistics, complexity measurements, etc. For each
kind of analysis there are five results each. E.g. for statistical, there is
mean, SD, MAD, COV, etc.
After performing all these different conversions/analysis I end up with
about 750 variables (6 * 5 * 5 * 5)
The classification groups are different depending on what set of MIDI files
I am analysing. In some sets the criteria is genre, subject (who played the
piece), composer, extract (which piece of music), etc.




Am 16.04.2002 17:13:39, schrieb "Rishabh Gupta" <rg117 at ohm.york.ac.uk>:
>Hi everyone,
>    Could somebody explain to me what is the package/function for
>classification analysis. I am performing analysis of music files in the
form
>of MIDI files. I end up with about 750 dependent variables from the
>analysis, I also have a number of independent/grouping variables that I set
>manually. What I would like is to be able to predict which group a
>particular MIDI files belongs to given the 750 dependent variables. In
order
>to this I have to perform classification analysis on a sample set of MIDI
>files where I know what group they belong to. I want to extract the
>'classification rule' that would enable me to predict the group of each
MIDI
>file (there would be a different classification rule for each grouping
>variable). Can anybody explain what is the best way of doing this in R.
What
>is the best package/function that would enable me to perform classification
>analysis.
>
>Any help would be greatly appreciated.
>
>Many Thanks For Your Help!
>
>Rishabh
>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
._._
>
____________________________________________________________________________
__
100 MB und noch mehr gute Gr?nde! Jetzt anmelden und profitieren. Da ist
mehr
f?r Sie drin unter http://club.web.de/?mc=021103



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pflugshaupt at geobot.umnw.ethz.ch  Wed Apr 17 15:42:34 2002
From: pflugshaupt at geobot.umnw.ethz.ch (Kaspar Pflugshaupt)
Date: Wed, 17 Apr 2002 15:42:34 +0200
Subject: [R] Cross-correlation
In-Reply-To: <3CBD8CFD.45C30F8@psy.uni-muenchen.de>
Message-ID: <B8E3486A.8416%pflugshaupt@geobot.umnw.ethz.ch>

On 17.4.2002 16:55 Uhr, Sven Garbade wrote:

> I want to recalculate an analysis found in a paper. An empirical time
> series (velocities, altogether 241 data values) were cross-correlated
> with an invertited cosine function (200 milliseconds duration).
> Following the authors the resulting values should offer some advantages:
> being independent of gain and peak latency differences between single
> trials and preserving the temporal aspect of the modulation. Is there a
> function to calculate cross-correlations in R? I think cor() is ot the
> right one.

You need the function ccf() in library(ts).

Cheers

Kaspar Pflugshaupt


-- 

Kaspar Pflugshaupt
Geobotanisches Institut
Zuerichbergstr. 38
CH-8044 Zuerich

Tel. ++41 1 632 43 19
Fax  ++41 1 632 12 15

mailto:pflugshaupt at geobot.umnw.ethz.ch
privat:pflugshaupt at mails.ch
http://www.geobot.umnw.ethz.ch

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Apr 17 15:41:55 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 17 Apr 2002 15:41:55 +0200
Subject: [R] union of lists
In-Reply-To: <Pine.OSF.3.96.1020417151201.30270B-100000@ija.csic.es>
References: <Pine.OSF.3.96.1020417151201.30270B-100000@ija.csic.es>
Message-ID: <x2vgaq4f30.fsf@blueberry.kubism.ku.dk>

Agustin Lobo <alobo at ija.csic.es> writes:

> I'm now using a for loop and applying
> union() to each pair of vectors, but is
> there a faster way avoiding the for ?

Not faster, I think. Maybe neater, using something like

lapply(seq(along=l1), function(i)union(l1[[i]],l2[[i]]))

or (with napply from an earlier post of mine)

napply(l1,l2,FUN=union)

where

napply <-
function(..., FUN) {
   x <- list(...)
   lens <- sapply(x,length)
   len <- max(lens)
   if (any(lens != len))
      x <- lapply(x, rep, length=len)
   tuples <- lapply(seq(length=len), function(i)lapply(x,"[", i))
   lapply(tuples, function(t)eval(as.call(c(FUN,t))))
}

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From phgrosje at ulb.ac.be  Wed Apr 17 15:56:37 2002
From: phgrosje at ulb.ac.be (Philippe Grosjean)
Date: Wed, 17 Apr 2002 15:56:37 +0200
Subject: [R] rbind() very slow
Message-ID: <MABBLJDICACNFOLGIHJOIENBCKAA.phgrosje@ulb.ac.be>

Hi,

I have 16 tables of 39 variables with around 1500 to 3500 cases in each
table. These 16 tables are in 16 different data frames. I want to merge them
in a single large data frame, so:

All <- rbind(T1, T2, ...)

The problem: it is VERY slow, and takes a lot of memory (> 500 Mb) on my
Athlon XP1800+, 1.75 Go memory, Win 2000 Pro SP1, R 1.4.1. Any suggestion to
improve speed, and/or memory use?
Thanx,

Philippe Grosjean


...........]<(({?<...............<?}))><...............................
 ) ) ) ) )	 __               	 __
( ( ( ( ( 	|__)              	|  _
 ) ) ) ) )	|   hilippe       	|__)rosjean
( ( ( ( ( 	Marine Biol. Lab., ULB, Belgium
 ) ) ) ) )	                  	 __
( ( ( ( ( 	|\  /|            	|__)
 ) ) ) ) )	| \/ |ariculture &	|__)iostatistics
( ( ( ( (
 ) ) ) ) )	e-mail: phgrosje at ulb.ac.be or phgrosjean at sciviews.org
( ( ( ( ( 	SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )      tel: 00-32-2-650.29.70 (lab), 00-32-2-673.31.33 (home)
( ( ( ( (
 ) ) ) ) )      "I'm 100% confident that p is between 0 and 1"
( ( ( ( (                                  L. Gonick & W. Smith (1993)
 ) ) ) ) )
......................................................................


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From garbade at psy.uni-muenchen.de  Wed Apr 17 18:01:03 2002
From: garbade at psy.uni-muenchen.de (Sven Garbade)
Date: Wed, 17 Apr 2002 16:01:03 +0000
Subject: [R] Cross-correlation
References: <B8E3486A.8416%pflugshaupt@geobot.umnw.ethz.ch>
Message-ID: <3CBD9C3F.1AFF0C10@psy.uni-muenchen.de>

Kaspar Pflugshaupt wrote:
> 
> On 17.4.2002 16:55 Uhr, Sven Garbade wrote:
> 
> > I want to recalculate an analysis found in a paper. An empirical time
> > series (velocities, altogether 241 data values) were cross-correlated
> > with an invertited cosine function (200 milliseconds duration).
> > Following the authors the resulting values should offer some advantages:
> > being independent of gain and peak latency differences between single
> > trials and preserving the temporal aspect of the modulation. Is there a
> > function to calculate cross-correlations in R? I think cor() is ot the
> > right one.
> 
> You need the function ccf() in library(ts).

Thanks, but I'm wondering why the R search engine found nothing
appropriate for the keyword "cross-correlation".

By, Sven
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lystig at math.chalmers.se  Wed Apr 17 16:23:53 2002
From: lystig at math.chalmers.se (Ted Lystig)
Date: Wed, 17 Apr 2002 16:23:53 +0200 (MET DST)
Subject: [R] Installation of R-1.4.1 on Solaris 2.7
Message-ID: <Pine.SOL.4.30.0204171611140.9600-100000@ankh.math.chalmers.se>

I am trying to install R-1.4.1 on the Solaris 2.7 OS by compiling the
source code.  Unfortunately, I obtain a fatal error during make
(apparently while using gcc to compile arithmetic.c).  The configure
command seemed to work acceptably (end of output follows).

--(snip)--

R is now configured for sparc-sun-solaris2.7

  Source directory:          .
  Installation directory:    /usr/local
  C compiler:                gcc  -g -O2
  C++ compiler:              c++  -g -O2
  FORTRAN compiler:          g77  -g -O2

  X11 support:               yes
  Gnome support:             no
  Tcl/Tk support:            no

  R profiling support:       yes
  R as a shared library:     no

configure: warning: you cannot build info versions of the R manuals

--(snip)--

I don't have the latest version of makeinfo installed, hence the above
warning, which I'm not concerned about.  What does concern me is the error
message from make (which is longer, and follows).  Any suggestions as to
how to proceed would be greatly appreciated.

	-Ted

--(snip)--

ankh(81)> make
creating src/scripts/R.fe
`libappl.a' is up to date.
`libnmath.a' is up to date.
`libunix.a' is up to date.
gcc -I. -I../../src/include -I../../src/include -I/usr/local/include
-DHAVE_CONFIG_H   -g -O2 -c arithmetic.c -o arithmetic.o
arithmetic.c:58: warning: `struct exception' declared inside parameter
list
arithmetic.c:58: warning: its scope is only this definition or
declaration,
arithmetic.c:58: warning: which is probably not what you want.
arithmetic.c: In function `matherr':
arithmetic.c:60: dereferencing pointer to incomplete type
arithmetic.c:61: `DOMAIN' undeclared (first use this function)
arithmetic.c:61: (Each undeclared identifier is reported only once
arithmetic.c:61: for each function it appears in.)
arithmetic.c:62: `SING' undeclared (first use this function)
arithmetic.c:65: `OVERFLOW' undeclared (first use this function)
arithmetic.c:68: `UNDERFLOW' undeclared (first use this function)
arithmetic.c:69: dereferencing pointer to incomplete type
arithmetic.c: In function `do_math1':
arithmetic.c:1075: `acosh' undeclared (first use this function)
arithmetic.c:1076: `asinh' undeclared (first use this function)
arithmetic.c:1077: `atanh' undeclared (first use this function)
*** Error code 1
make: Fatal error: Command failed for target `arithmetic.o'
Current working directory
/.../chalmers.se/fs/cab/math/.users/lystig/home/BIN/R-DIR/R-1.4.1/src/main
*** Error code 1
make: Fatal error: Command failed for target `R'
Current working directory
/.../chalmers.se/fs/cab/math/.users/lystig/home/BIN/R-DIR/R-1.4.1/src/main
*** Error code 1
make: Fatal error: Command failed for target `R'
Current working directory
/.../chalmers.se/fs/cab/math/.users/lystig/home/BIN/R-DIR/R-1.4.1/src
*** Error code 1
make: Fatal error: Command failed for target `R'
ankh(82)>

--(snip)--

=======================================
Ted Lystig, Ph.D.
Department of Mathematical Statistics
Chalmers University of Technology
S-412 96 G?teborg
Sweden

email:  lystig at math.chalmers.se
phone: +46 31 772 5342
FAX:   +46 31 772 3508
=======================================


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Corey.Moffet at ttu.edu  Wed Apr 17 16:24:51 2002
From: Corey.Moffet at ttu.edu (Moffet, Corey)
Date: Wed, 17 Apr 2002 09:24:51 -0500
Subject: [R] Problem w/ axis and distortion in a plotting function
Message-ID: <938690ACF269D311928B0090279C2772E91EEF@cyclops.net.ttu.edu>

I have a function for plotting soil texture that I am having a problem with.

The function is:

plot.psd <- function(sand, clay, ...) {
  conv.ter <- function(x, y) {
     x.con <- 100 - x - y*cos(1/3*pi)
     y.con <- y*sin(1/3*pi)
     data.frame(x=x.con, y=y.con)
  }
  plot(conv.ter(sand, clay), xlim = c(0,100), ylim = c(0,100*sin(1/3*pi)),
axes = FALSE, xlab="", ylab="", ...)
  lines(conv.ter(c(100,0), c(0,100)))
  lines(conv.ter(c(100,0), c(0,0)))
  lines(conv.ter(c(0,0), c(0,100)))
  lines(conv.ter(c(85,90), c(0,10)))
  lines(conv.ter(c(70,85), c(0,15)))
  lines(conv.ter(c(50,43,52,52,80), c(0,7,7,20,20)))
  lines(conv.ter(c(43,23,45,52), c(7,27,27,20)))
  lines(conv.ter(c(45,45,65), c(27,35,35)))
  lines(conv.ter(c(45,45), c(35,55)))
  lines(conv.ter(c(45,20,20,23), c(40,40,27,27)))
  lines(conv.ter(c(20,0), c(40,60)))
  lines(conv.ter(c(20,0), c(27,27)))
  lines(conv.ter(c(20,0), c(40,40)))
  lines(conv.ter(c(0,8,20), c(12,12,0)))
  for(i in seq(10, 90, 10)) {
    lines(conv.ter(c(i,i), c(0,(100-i))), lty = 3)
    lines(conv.ter(c((100-i),0), c(i,i)), lty = 3)
    lines(conv.ter(c(i,0), c(0,i)), lty = 3)
  }
  text(conv.ter(c(50, 60, -10), c(-10, 55, 55) ), c("Sand", "Clay", "Silt"),
cex = 0.9 )
  text(conv.ter(c(0,20,40,60,80,100 ), c(rep(-2, 6)) ), c("0", "20", "40",
"60", "80", "100"), cex = 0.75 )
  text(conv.ter(c(103,83,63,43,23,3 ), c(0,20,40,60,80,100) ), c("0", "20",
"40", "60", "80", "100"), cex = 0.75 )
  text(conv.ter(c(rep(-3,6)), c(102,82,62,42,22,2)), c("0", "20", "40",
"60", "80", "100"), cex = 0.75 )
}

The label for the Sand axis (first text line above) is not shown.

The second problem I have with this is that the triangle should be
equilateral but when I print
it the triangle is not.  If I use par(pty = "s") before the plot.psd call
than the triangle is
always stretched vertically.

Any Ideas?


With best wishes and kind regards I am

Sincerely,

Corey A. Moffet
Instructor
Department of Range, Wildlife, and Fisheries Management
Mail Stop 2125
Texas Tech University
Lubbock, Texas 79409-2125
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From W.Simpson at gcal.ac.uk  Wed Apr 17 16:28:35 2002
From: W.Simpson at gcal.ac.uk (Bill Simpson)
Date: Wed, 17 Apr 2002 15:28:35 +0100 (BST)
Subject: [R] Cross-correlation
In-Reply-To: <3CBD8CFD.45C30F8@psy.uni-muenchen.de>
Message-ID: <Pine.LNX.4.10.10204171525360.4537-100000@localhost.localdomain>

Despite the name, convolve() computes the cross-correlation function.
Do something like:

q<-convolve(x,y,conj=TRUE,type="open")

Bill

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Apr 17 16:33:30 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 17 Apr 2002 16:33:30 +0200
Subject: [R] rbind() very slow
In-Reply-To: <MABBLJDICACNFOLGIHJOIENBCKAA.phgrosje@ulb.ac.be>
References: <MABBLJDICACNFOLGIHJOIENBCKAA.phgrosje@ulb.ac.be>
Message-ID: <x2r8le4cp1.fsf@blueberry.kubism.ku.dk>

"Philippe Grosjean" <phgrosje at ulb.ac.be> writes:

> Hi,
> 
> I have 16 tables of 39 variables with around 1500 to 3500 cases in each
> table. These 16 tables are in 16 different data frames. I want to merge them
> in a single large data frame, so:
> 
> All <- rbind(T1, T2, ...)
> 
> The problem: it is VERY slow, and takes a lot of memory (> 500 Mb) on my
> Athlon XP1800+, 1.75 Go memory, Win 2000 Pro SP1, R 1.4.1. Any suggestion to
> improve speed, and/or memory use?
> Thanx,

No fix, but could you try running the profiler over this? I.e.

Rprof()
All <- rbind(T1, T2, ...)
Rprof(NULL)

and then on the command line

Rcmd Rprof Rprof.out

If this proves awkward on Windows, could you cook up an example (e.g.
with random data) that reproduces the effect?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ozric at web.de  Wed Apr 17 16:54:51 2002
From: ozric at web.de (ozric@web.de)
Date: Wed, 17 Apr 2002 16:54:51 +0200
Subject: [R] Classification Analysis
Message-ID: <200204171454.g3HEspv05913@mailgate5.cinetic.de>

really interesting!
is there some url/docs for more information or are this your own
thoughts - maybe for Ph.D thesis ?


Am 17.04.2002 15:22:08, schrieb "Rishabh Gupta" <rg117 at ohm.york.ac.uk>:
>Thanks For your reply
>I would really prefer to use R as I am using R for all the other exploratory analysis that I am doing on the data

In my humble opinion in R the package(Rpart) is good starting point
for this, but in fact you get no really rules. The result are more
sub-segmentation's which habit different with the classification (dependent) variable. But you can formulate rules on the basis of the results in a sophisticated way..........

regards,christian

>
>P.S.
>One question - i make electronic music with ComputerSoftware,too
>and i'm statistican - what are the 750 variables and what is your
>classification criterium ? (if it is not a secret !)
>regards,christian
>
>I have a large of variables (750) because I have a lot of version of each
>kind of data. I analyse melody, rhythm, harmony, etc as a different stream
>of data. For each one, I calculate a different versions, intervals, contour,
>modulo, modulo of interval, etc. For each one of those I perform a different
>kind of analysis, basic statistics, complexity measurements, etc. For each
>kind of analysis there are five results each. E.g. for statistical, there is
>mean, SD, MAD, COV, etc.
>After performing all these different conversions/analysis I end up with
>about 750 variables (6 * 5 * 5 * 5)
>The classification groups are different depending on what set of MIDI files
>I am analysing. In some sets the criteria is genre, subject (who played the
>piece), composer, extract (which piece of music), etc.
>
>
>
______________________________________________________________________________
100 MB und noch mehr gute Gr?nde! Jetzt anmelden und profitieren. Da ist mehr 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Apr 17 17:02:46 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed, 17 Apr 2002 16:02:46 +0100 (GMT Daylight Time)
Subject: [R] Installation of R-1.4.1 on Solaris 2.7
In-Reply-To: <Pine.SOL.4.30.0204171611140.9600-100000@ankh.math.chalmers.se>
Message-ID: <Pine.WNT.4.44.0204171559310.128-100000@gannet.stats.ox.ac.uk>

These are (as far as I recall) the symptoms of using gcc compiled for
Solaris <=2.6 on Solaris 2.7.  As gcc makes copies of header files, it is
essential that it is re-compiled when the OS is upgraded.

R 1.4.1 compiles out of the box on Solaris 2,7 with the current gcc, 3.0.4,
and also with 2.95,3,

On Wed, 17 Apr 2002, Ted Lystig wrote:

> I am trying to install R-1.4.1 on the Solaris 2.7 OS by compiling the
> source code.  Unfortunately, I obtain a fatal error during make
> (apparently while using gcc to compile arithmetic.c).  The configure
> command seemed to work acceptably (end of output follows).
>
> --(snip)--
>
> R is now configured for sparc-sun-solaris2.7
>
>   Source directory:          .
>   Installation directory:    /usr/local
>   C compiler:                gcc  -g -O2
>   C++ compiler:              c++  -g -O2
>   FORTRAN compiler:          g77  -g -O2
>
>   X11 support:               yes
>   Gnome support:             no
>   Tcl/Tk support:            no
>
>   R profiling support:       yes
>   R as a shared library:     no
>
> configure: warning: you cannot build info versions of the R manuals
>
> --(snip)--
>
> I don't have the latest version of makeinfo installed, hence the above
> warning, which I'm not concerned about.  What does concern me is the error
> message from make (which is longer, and follows).  Any suggestions as to
> how to proceed would be greatly appreciated.
>
> 	-Ted
>
> --(snip)--
>
> ankh(81)> make
> creating src/scripts/R.fe
> `libappl.a' is up to date.
> `libnmath.a' is up to date.
> `libunix.a' is up to date.
> gcc -I. -I../../src/include -I../../src/include -I/usr/local/include
> -DHAVE_CONFIG_H   -g -O2 -c arithmetic.c -o arithmetic.o
> arithmetic.c:58: warning: `struct exception' declared inside parameter
> list
> arithmetic.c:58: warning: its scope is only this definition or
> declaration,
> arithmetic.c:58: warning: which is probably not what you want.
> arithmetic.c: In function `matherr':
> arithmetic.c:60: dereferencing pointer to incomplete type
> arithmetic.c:61: `DOMAIN' undeclared (first use this function)
> arithmetic.c:61: (Each undeclared identifier is reported only once
> arithmetic.c:61: for each function it appears in.)
> arithmetic.c:62: `SING' undeclared (first use this function)
> arithmetic.c:65: `OVERFLOW' undeclared (first use this function)
> arithmetic.c:68: `UNDERFLOW' undeclared (first use this function)
> arithmetic.c:69: dereferencing pointer to incomplete type
> arithmetic.c: In function `do_math1':
> arithmetic.c:1075: `acosh' undeclared (first use this function)
> arithmetic.c:1076: `asinh' undeclared (first use this function)
> arithmetic.c:1077: `atanh' undeclared (first use this function)
> *** Error code 1
> make: Fatal error: Command failed for target `arithmetic.o'
> Current working directory
> /.../chalmers.se/fs/cab/math/.users/lystig/home/BIN/R-DIR/R-1.4.1/src/main
> *** Error code 1
> make: Fatal error: Command failed for target `R'
> Current working directory
> /.../chalmers.se/fs/cab/math/.users/lystig/home/BIN/R-DIR/R-1.4.1/src/main
> *** Error code 1
> make: Fatal error: Command failed for target `R'
> Current working directory
> /.../chalmers.se/fs/cab/math/.users/lystig/home/BIN/R-DIR/R-1.4.1/src
> *** Error code 1
> make: Fatal error: Command failed for target `R'
> ankh(82)>
>
> --(snip)--
>
> =======================================
> Ted Lystig, Ph.D.
> Department of Mathematical Statistics
> Chalmers University of Technology
> S-412 96 Gteborg
> Sweden
>
> email:  lystig at math.chalmers.se
> phone: +46 31 772 5342
> FAX:   +46 31 772 3508
> =======================================
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Wed Apr 17 17:30:16 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 17 Apr 2002 17:30:16 +0200
Subject: [R] Problem w/ axis and distortion in a plotting function
In-Reply-To: <938690ACF269D311928B0090279C2772E91EEF@cyclops.net.ttu.edu>
References: <938690ACF269D311928B0090279C2772E91EEF@cyclops.net.ttu.edu>
Message-ID: <15549.38152.892636.914215@gargle.gargle.HOWL>

Hi Corey,

>>>>> "CoMo" == Moffet, Corey <Corey.Moffet at ttu.edu> writes:

    CoMo> I have a function for plotting soil texture that I am
    CoMo> having a problem with.  The function is:

    ...........

(it would be helpful if together with the function,
 you'd give an example call that we can use as well, i.e., with
 "R builtin" or random (sand <- rnorm(...)) data, so we can
 easily see what you mean) 

    CoMo> The label for the Sand axis (first text line above) is
    CoMo> not shown.

you have an explicit  xlab = "" -- so why would you expect a label?

    CoMo> The second problem I have with this is that the
    CoMo> triangle should be equilateral but when I print it the
    CoMo> triangle is not.  If I use par(pty = "s") before the
    CoMo> plot.psd call than the triangle is always stretched
    CoMo> vertically.

plot(....,  asp = 1 )  ## !!!

This is found (only?) on  help(plot.default),
a very nice feature and probably much under-used possibility
for specifying and fixing the ASPect ratio.

Does it help?

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tklistaddr at keittlab.bio.sunysb.edu  Wed Apr 17 17:38:18 2002
From: tklistaddr at keittlab.bio.sunysb.edu (Timothy H. Keitt)
Date: 17 Apr 2002 11:38:18 -0400
Subject: [R] union of lists
In-Reply-To: <Pine.OSF.3.96.1020417151201.30270B-100000@ija.csic.es>
References: <Pine.OSF.3.96.1020417151201.30270B-100000@ija.csic.es>
Message-ID: <1019057898.21232.12.camel@keittlab-6>

This would require either a binary form of lapply, or a version of
lapply that passed the current index to the function. Another solution
is to use an iterator closure:

f <- function(l1, l2) {
	i <- 0
	function(...) {
		i <<- i + 1
		union(l1[[i]], l2[[i]])
	}
}


out <- lapply(lista1, f(lista1, lista2))

I assume here that the lists are of the same length and in the same
order.

T.


On Wed, 2002-04-17 at 09:24, Agustin Lobo wrote:
> Hi there,
> 
> Given 2 lists of integer vectors, i.e.:
> 
> > lista1
> $"1"
> [1]  1 34  5
> $"2"
> [1] 2 1
> $"3"
> [1]  3 10 15
> 
> > lista2
> $"1"
> [1] 1 5
> $"2"
> [1] 2 1
> $"3"
> [1]  3 10 29
> 
> 
> I want to obtain the union of both, defined
> as the union of the vectors, that is 
> lista.union[[1]] <- union(lista1[[1]],lista2[[1]]):
> 
> > lista.union
> $"1"
> [1]  1 34  5
> $"2"
> [1] 2 1
> $"3"
> [1]  3 10 15 29
> 
> I'm now using a for loop and applying
> union() to each pair of vectors, but is
> there a faster way avoiding the for ?
> 
> Thanks!
> 
> Agus
> 
> 
> Dr. Agustin Lobo
> Instituto de Ciencias de la Tierra (CSIC)
> Lluis Sole Sabaris s/n
> 08028 Barcelona SPAIN
> tel 34 93409 5410
> fax 34 93411 0012
> alobo at ija.csic.es
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rg117 at ohm.york.ac.uk  Wed Apr 17 17:48:01 2002
From: rg117 at ohm.york.ac.uk (Rishabh Gupta)
Date: Wed, 17 Apr 2002 16:48:01 +0100
Subject: [R] Classification Analysis
References: <200204171454.g3HEspv05913@mailgate5.cinetic.de>
Message-ID: <000e01c1e627$7d7335e0$35892090@ohm.york.ac.uk>

----- Original Message -----
From: <ozric at web.de>
To: "Rishabh Gupta" <rg117 at ohm.york.ac.uk>
Cc: <r-help at hypatia.math.ethz.ch>
Sent: Wednesday, April 17, 2002 3:54 PM
Subject: Re: [R] Classification Analysis


really interesting!
is there some url/docs for more information or are this your own
thoughts - maybe for Ph.D thesis ?


Am 17.04.2002 15:22:08, schrieb "Rishabh Gupta" <rg117 at ohm.york.ac.uk>:
>Thanks For your reply
>I would really prefer to use R as I am using R for all the other
exploratory analysis that I am doing on the data

In my humble opinion in R the package(Rpart) is good starting point
for this, but in fact you get no really rules. The result are more
sub-segmentation's which habit different with the classification (dependent)
variable. But you can formulate rules on the basis of the results in a
sophisticated way..........

regards,christian




Thanks!
It is for a PhD, but to this point I am still trying prove/disprove so there
is not documentation. That's why I need to get to grips with the statistical
analysis system.





>
>P.S.
>One question - i make electronic music with ComputerSoftware,too
>and i'm statistican - what are the 750 variables and what is your
>classification criterium ? (if it is not a secret !)
>regards,christian
>
>I have a large of variables (750) because I have a lot of version of each
>kind of data. I analyse melody, rhythm, harmony, etc as a different stream
>of data. For each one, I calculate a different versions, intervals,
contour,
>modulo, modulo of interval, etc. For each one of those I perform a
different
>kind of analysis, basic statistics, complexity measurements, etc. For each
>kind of analysis there are five results each. E.g. for statistical, there
is
>mean, SD, MAD, COV, etc.
>After performing all these different conversions/analysis I end up with
>about 750 variables (6 * 5 * 5 * 5)
>The classification groups are different depending on what set of MIDI files
>I am analysing. In some sets the criteria is genre, subject (who played the
>piece), composer, extract (which piece of music), etc.
>
>
>
____________________________________________________________________________
__
100 MB und noch mehr gute Gr?nde! Jetzt anmelden und profitieren. Da ist
mehr




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From james.lindsey at luc.ac.be  Wed Apr 17 18:20:44 2002
From: james.lindsey at luc.ac.be (Jim Lindsey)
Date: Wed, 17 Apr 2002 18:20:44 +0200 (MET DST)
Subject: [R] Newbie problem with ox package
In-Reply-To: <31270.1018875220@www16.gmx.net> from "Benjamin Janson" at Apr 15, 2002 02:53:40 PM
Message-ID: <200204171620.SAA16989@luc.ac.be>

> 
> HI,
> I need urgently garch and egarch models. After looking through the R mail
> archives I found http://www.egss.ulg.ac.be/garch/default.htm which is an Ox

That is a package for Ox by a colleague of mine here in Liege.

The gar function in my repeated library does the standard Engle arch
models, for normal and a selection of other distributions. Nothing
very fancy.
www.luc.ac.be/~jlindsey/rcode.html
  Jim
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From emb7 at st-andrews.ac.uk  Wed Apr 17 18:30:09 2002
From: emb7 at st-andrews.ac.uk (Martin Biuw)
Date: Wed, 17 Apr 2002 17:30:09 +0100
Subject: [R] Stochastyic frontier regression
Message-ID: <5.1.0.14.0.20020417171845.0229f110@gatty.st-and.ac.uk>

Hello,

Does anyone know if there is an R-package that includes stochastic frontier 
regression models?

Cheers,

Martin

Martin Biuw
SEA MAMMAL RESEARCH UNIT
Gatty Marine Laboratory
School of Environmental and Evolutionary Biology
University of St Andrews
Fife, Scotland KY16 8LB
UK
phone +44 (0)1334 462630
fax + 44 (0)1334 462632
http://www.smru.st-and.ac.uk

-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20020417/19d5d0bd/attachment.html

From phgrosje at ulb.ac.be  Wed Apr 17 18:38:26 2002
From: phgrosje at ulb.ac.be (Philippe Grosjean)
Date: Wed, 17 Apr 2002 18:38:26 +0200
Subject: [R] rbind() very slow... Oops sorry!
In-Reply-To: <x2r8le4cp1.fsf@blueberry.kubism.ku.dk>
Message-ID: <MABBLJDICACNFOLGIHJOEENECKAA.phgrosje@ulb.ac.be>

Indeed, for some reasons during pretreatment of my data, I ended up with
15x39 variables in each table (15 copies of each!!), meaning I was trying to
create a 585 x 3500 table with rbind(), i.e., about 2 millions of entries.
So, memory requirements and time are not surprising in this case. Sorry for
this.

Best,

Philippe Grosjean

-----Message d'origine-----
De : owner-r-help at stat.math.ethz.ch
[mailto:owner-r-help at stat.math.ethz.ch]De la part de Peter Dalgaard BSA
Envoye : mercredi 17 avril 2002 16:34
A : Philippe Grosjean
Cc : r-help at stat.math.ethz.ch
Objet : Re: [R] rbind() very slow


"Philippe Grosjean" <phgrosje at ulb.ac.be> writes:

> Hi,
>
> I have 16 tables of 39 variables with around 1500 to 3500 cases in each
> table. These 16 tables are in 16 different data frames. I want to merge
them
> in a single large data frame, so:
>
> All <- rbind(T1, T2, ...)
>
> The problem: it is VERY slow, and takes a lot of memory (> 500 Mb) on my
> Athlon XP1800+, 1.75 Go memory, Win 2000 Pro SP1, R 1.4.1. Any suggestion
to
> improve speed, and/or memory use?
> Thanx,

No fix, but could you try running the profiler over this? I.e.

Rprof()
All <- rbind(T1, T2, ...)
Rprof(NULL)

and then on the command line

Rcmd Rprof Rprof.out

If this proves awkward on Windows, could you cook up an example (e.g.
with random data) that reproduces the effect?

--
   O__  ---- Peter Dalgaard             Blegdamsvej 3
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Corey.Moffet at ttu.edu  Wed Apr 17 18:51:20 2002
From: Corey.Moffet at ttu.edu (Moffet, Corey)
Date: Wed, 17 Apr 2002 11:51:20 -0500
Subject: [R] Problem w/ axis and distortion in a plotting function
Message-ID: <938690ACF269D311928B0090279C2772E91EF0@cyclops.net.ttu.edu>

Thank you for your quick response.  Using asp = 1 fixed 1 problem but I
still have the problem with labeling the sand axis.  I have made some
changes to the function so I will include it again and give an example call:

plot.psd <- function(sand, clay, ...) {
  conv.ter <- function(x, y) {
     x.con <- 100 - x - y*cos(1/3*pi)
     y.con <- y*sin(1/3*pi)
     data.frame(x=x.con, y=y.con)
  }
  plot(conv.ter(sand, clay), xlim = c(0,100), ylim = c(0,100*sin(1/3*pi)),
axes = FALSE, xlab="", ylab="", asp = 1, ...)
  lines(conv.ter(c(100,0), c(0,100)))
  lines(conv.ter(c(100,0), c(0,0)))
  lines(conv.ter(c(0,0), c(0,100)))
  lines(conv.ter(c(85,90), c(0,10)))
  lines(conv.ter(c(70,85), c(0,15)))
  lines(conv.ter(c(50,43,52,52,80), c(0,7,7,20,20)))
  lines(conv.ter(c(43,23,45,52), c(7,27,27,20)))
  lines(conv.ter(c(45,45,65), c(27,35,35)))
  lines(conv.ter(c(45,45), c(35,55)))
  lines(conv.ter(c(45,20,20,23), c(40,40,27,27)))
  lines(conv.ter(c(20,0), c(40,60)))
  lines(conv.ter(c(20,0), c(27,27)))
  lines(conv.ter(c(20,0), c(40,40)))
  lines(conv.ter(c(0,8,20), c(12,12,0)))
  for(i in seq(10, 90, 10)) {
    lines(conv.ter(c(i,i), c(0,(100-i))), lty = 3)
    lines(conv.ter(c((100-i),0), c(i,i)), lty = 3)
    lines(conv.ter(c(i,0), c(0,i)), lty = 3)
  }
  text(conv.ter(c(53, 58, -10), c(-7, 55, 55) ), c("Sand", "Clay", "Silt"),
cex = 0.9 )
  text(conv.ter(c(20,40,60,80,100 ), c(rep(-2, 5)) ), c("20", "40", "60",
"80", "100"), cex = 0.75 )
  text(conv.ter(c(83,63,43,23,3 ), c(20,40,60,80,100) ), c("20", "40", "60",
"80", "100"), cex = 0.75 )
  text(conv.ter(c(rep(-3,5)), c(82,62,42,22,2)), c("20", "40", "60", "80",
"100"), cex = 0.75 )
}

plot.psd(c(33,43,53), c(33,23,13), pch = c("1", "2", "3"), col = c("blue",
"black", "red"), cex = 0.5)


What I am trying to do is replace the default x-axis with a custom axis but
Sand is obscured from view in the R Graphics Device window.  I have used
axes = FALSE, xlab="", ylab="" to clear the defaults and the four text calls
at the bottom of the function are trying to replace the blank defaults with
my custom axis.  What am I missing?

With best wishes and kind regards I am

Sincerely,

Corey A. Moffet
Instructor
Department of Range, Wildlife, and Fisheries Management
Mail Stop 2125
Texas Tech University
Lubbock, Texas 79409-2125

-----Original Message-----
From: Martin Maechler [mailto:maechler at stat.math.ethz.ch]
Sent: Wednesday, April 17, 2002 10:30 AM
To: Moffet, Corey
Cc: R-Help (E-mail)
Subject: Re: [R] Problem w/ axis and distortion in a plotting function


Hi Corey,

>>>>> "CoMo" == Moffet, Corey <Corey.Moffet at ttu.edu> writes:

    CoMo> I have a function for plotting soil texture that I am
    CoMo> having a problem with.  The function is:

    ...........

(it would be helpful if together with the function,
 you'd give an example call that we can use as well, i.e., with
 "R builtin" or random (sand <- rnorm(...)) data, so we can
 easily see what you mean) 

    CoMo> The label for the Sand axis (first text line above) is
    CoMo> not shown.

you have an explicit  xlab = "" -- so why would you expect a label?

    CoMo> The second problem I have with this is that the
    CoMo> triangle should be equilateral but when I print it the
    CoMo> triangle is not.  If I use par(pty = "s") before the
    CoMo> plot.psd call than the triangle is always stretched
    CoMo> vertically.

plot(....,  asp = 1 )  ## !!!

This is found (only?) on  help(plot.default),
a very nice feature and probably much under-used possibility
for specifying and fixing the ASPect ratio.

Does it help?

Martin Maechler <maechler at stat.math.ethz.ch>
http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Apr 17 19:09:43 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 17 Apr 2002 18:09:43 +0100 (BST)
Subject: [R] Problem w/ axis and distortion in a plotting function
In-Reply-To: <938690ACF269D311928B0090279C2772E91EF0@cyclops.net.ttu.edu>
Message-ID: <Pine.LNX.4.31.0204171807030.16099-100000@gannet.stats>

On Wed, 17 Apr 2002, Moffet, Corey wrote:

> Thank you for your quick response.  Using asp = 1 fixed 1 problem but I
> still have the problem with labeling the sand axis.  I have made some
> changes to the function so I will include it again and give an example call:
>
> plot.psd <- function(sand, clay, ...) {
>   conv.ter <- function(x, y) {
>      x.con <- 100 - x - y*cos(1/3*pi)
>      y.con <- y*sin(1/3*pi)
>      data.frame(x=x.con, y=y.con)
>   }
>   plot(conv.ter(sand, clay), xlim = c(0,100), ylim = c(0,100*sin(1/3*pi)),
> axes = FALSE, xlab="", ylab="", asp = 1, ...)
>   lines(conv.ter(c(100,0), c(0,100)))
>   lines(conv.ter(c(100,0), c(0,0)))
>   lines(conv.ter(c(0,0), c(0,100)))
>   lines(conv.ter(c(85,90), c(0,10)))
>   lines(conv.ter(c(70,85), c(0,15)))
>   lines(conv.ter(c(50,43,52,52,80), c(0,7,7,20,20)))
>   lines(conv.ter(c(43,23,45,52), c(7,27,27,20)))
>   lines(conv.ter(c(45,45,65), c(27,35,35)))
>   lines(conv.ter(c(45,45), c(35,55)))
>   lines(conv.ter(c(45,20,20,23), c(40,40,27,27)))
>   lines(conv.ter(c(20,0), c(40,60)))
>   lines(conv.ter(c(20,0), c(27,27)))
>   lines(conv.ter(c(20,0), c(40,40)))
>   lines(conv.ter(c(0,8,20), c(12,12,0)))
>   for(i in seq(10, 90, 10)) {
>     lines(conv.ter(c(i,i), c(0,(100-i))), lty = 3)
>     lines(conv.ter(c((100-i),0), c(i,i)), lty = 3)
>     lines(conv.ter(c(i,0), c(0,i)), lty = 3)
>   }
>   text(conv.ter(c(53, 58, -10), c(-7, 55, 55) ), c("Sand", "Clay", "Silt"),
> cex = 0.9 )
>   text(conv.ter(c(20,40,60,80,100 ), c(rep(-2, 5)) ), c("20", "40", "60",
> "80", "100"), cex = 0.75 )
>   text(conv.ter(c(83,63,43,23,3 ), c(20,40,60,80,100) ), c("20", "40", "60",
> "80", "100"), cex = 0.75 )
>   text(conv.ter(c(rep(-3,5)), c(82,62,42,22,2)), c("20", "40", "60", "80",
> "100"), cex = 0.75 )
> }
>
> plot.psd(c(33,43,53), c(33,23,13), pch = c("1", "2", "3"), col = c("blue",
> "black", "red"), cex = 0.5)
>
>
> What I am trying to do is replace the default x-axis with a custom axis but
> Sand is obscured from view in the R Graphics Device window.  I have used
> axes = FALSE, xlab="", ylab="" to clear the defaults and the four text calls
> at the bottom of the function are trying to replace the blank defaults with
> my custom axis.  What am I missing?

xpd=TRUE.  text is not designed for the margins: that is what mtext is
used for, so you need

text(conv.ter(c(53, 58, -10), c(-7, 55, 55) ), c("Sand", "Clay", "Silt"),
    cex = 0.9, xpd = TRUE )

to avoid clipping to the plot region.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From domi at sun11.ukl.uni-freiburg.de  Wed Apr 17 19:15:40 2002
From: domi at sun11.ukl.uni-freiburg.de (1-27206531-0-90000491)
Date: Wed, 17 Apr 2002 19:15:40 +0200 (MET DST)
Subject: [R] manipulating colors in lattice
In-Reply-To: <MABBLJDICACNFOLGIHJOEENECKAA.phgrosje@ulb.ac.be>
Message-ID: <Pine.SOL.4.21.0204171911440.25698-100000@sun11.ukl.uni-freiburg.de>

Dear R-users,

I use:

$platform 
[1] "i386-pc-mingw32"
$arch
[1] "x86"
$os
[1] "Win32"
$system
[1] "x86, Win32"
$status
[1] ""
$major
[1] "1"
$minor
[1] "4.1"
$year
[1] "2002"
$month
[1] "01"
$day
[1] "30"
$language
[1] "R"

I try  to repeat the analysis of Jose Pinheiro and Douglas Bates described
in their book: Mixed-Effects Models in S and S-PLUS.

library(lattice)
library(nlme)
data(Orthodont)
plot(Orthodont)
fm1OrthF.lis <- lmList(distance ~ age, data=Orthodont)
plot(intervals(fm1OrthF.lis))
fm1OrthF <- lme(distance ~ age, data=Orthodont, random= ~ 1| Subject)
plot(augPred(fm1OrthF), aspect="xy", grid=TRUE)

My question: How can I manipulate the colours of the different plots, say
changing symbols and lines from light-blue to black?
e.g. plot(Orthodont, col="black") changes only symbols to black and I have
no idea how to change the lines to black. 

Thanks in advance,

Dominik

----------------------------------------------------------------------------
Dominik Grathwohl; Bussstr. 34; D-79102 Freiburg

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Corey.Moffet at ttu.edu  Wed Apr 17 19:20:59 2002
From: Corey.Moffet at ttu.edu (Moffet, Corey)
Date: Wed, 17 Apr 2002 12:20:59 -0500
Subject: [R] Problem w/ axis and distortion in a plotting function
Message-ID: <938690ACF269D311928B0090279C2772E91EF1@cyclops.net.ttu.edu>

Thank you both.  These suggestions fixed my problem.  I added asp = 1 to the
plot call in the function
to keep the triangle equilateral, and xpd = TRUE in the first text call in
the function.


With best wishes and kind regards I am

Sincerely,

Corey A. Moffet
Instructor
Department of Range, Wildlife, and Fisheries Management
Mail Stop 2125
Texas Tech University
Lubbock, Texas 79409-2125

-----Original Message-----
From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk]
Sent: Wednesday, April 17, 2002 12:10 PM
To: Moffet, Corey
Cc: 'Martin Maechler'; R-Help (E-mail)
Subject: RE: [R] Problem w/ axis and distortion in a plotting function


On Wed, 17 Apr 2002, Moffet, Corey wrote:

> Thank you for your quick response.  Using asp = 1 fixed 1 problem but I
> still have the problem with labeling the sand axis.  I have made some
> changes to the function so I will include it again and give an example
call:
>
> plot.psd <- function(sand, clay, ...) {
>   conv.ter <- function(x, y) {
>      x.con <- 100 - x - y*cos(1/3*pi)
>      y.con <- y*sin(1/3*pi)
>      data.frame(x=x.con, y=y.con)
>   }
>   plot(conv.ter(sand, clay), xlim = c(0,100), ylim = c(0,100*sin(1/3*pi)),
> axes = FALSE, xlab="", ylab="", asp = 1, ...)
>   lines(conv.ter(c(100,0), c(0,100)))
>   lines(conv.ter(c(100,0), c(0,0)))
>   lines(conv.ter(c(0,0), c(0,100)))
>   lines(conv.ter(c(85,90), c(0,10)))
>   lines(conv.ter(c(70,85), c(0,15)))
>   lines(conv.ter(c(50,43,52,52,80), c(0,7,7,20,20)))
>   lines(conv.ter(c(43,23,45,52), c(7,27,27,20)))
>   lines(conv.ter(c(45,45,65), c(27,35,35)))
>   lines(conv.ter(c(45,45), c(35,55)))
>   lines(conv.ter(c(45,20,20,23), c(40,40,27,27)))
>   lines(conv.ter(c(20,0), c(40,60)))
>   lines(conv.ter(c(20,0), c(27,27)))
>   lines(conv.ter(c(20,0), c(40,40)))
>   lines(conv.ter(c(0,8,20), c(12,12,0)))
>   for(i in seq(10, 90, 10)) {
>     lines(conv.ter(c(i,i), c(0,(100-i))), lty = 3)
>     lines(conv.ter(c((100-i),0), c(i,i)), lty = 3)
>     lines(conv.ter(c(i,0), c(0,i)), lty = 3)
>   }
>   text(conv.ter(c(53, 58, -10), c(-7, 55, 55) ), c("Sand", "Clay",
"Silt"),
> cex = 0.9 )
>   text(conv.ter(c(20,40,60,80,100 ), c(rep(-2, 5)) ), c("20", "40", "60",
> "80", "100"), cex = 0.75 )
>   text(conv.ter(c(83,63,43,23,3 ), c(20,40,60,80,100) ), c("20", "40",
"60",
> "80", "100"), cex = 0.75 )
>   text(conv.ter(c(rep(-3,5)), c(82,62,42,22,2)), c("20", "40", "60", "80",
> "100"), cex = 0.75 )
> }
>
> plot.psd(c(33,43,53), c(33,23,13), pch = c("1", "2", "3"), col = c("blue",
> "black", "red"), cex = 0.5)
>
>
> What I am trying to do is replace the default x-axis with a custom axis
but
> Sand is obscured from view in the R Graphics Device window.  I have used
> axes = FALSE, xlab="", ylab="" to clear the defaults and the four text
calls
> at the bottom of the function are trying to replace the blank defaults
with
> my custom axis.  What am I missing?

xpd=TRUE.  text is not designed for the margins: that is what mtext is
used for, so you need

text(conv.ter(c(53, 58, -10), c(-7, 55, 55) ), c("Sand", "Clay", "Silt"),
    cex = 0.9, xpd = TRUE )

to avoid clipping to the plot region.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From roger at ysidro.econ.uiuc.edu  Wed Apr 17 19:33:16 2002
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Wed, 17 Apr 2002 12:33:16 -0500 (CDT)
Subject: [R] Stochastyic frontier regression
In-Reply-To: <5.1.0.14.0.20020417171845.0229f110@gatty.st-and.ac.uk>
Message-ID: <Pine.GSO.4.33.0204171231130.4731-100000@ysidro.econ.uiuc.edu>

Martin,

You can model conditional near extreme quantile functions  of a univariate
response variable with the quantreg package.  The following reference:


@article{CTS.99,
        Author = {Cade, B.S. and Terrell, J.W. and Schroeder, R.L.},
        Title = { Estimating effects of limiting factors with regression
                quantiles},
        Journal = {Ecology},
        Volume = {80},
        Pages = {311-323},
        Year = 1999
}

describes some ecological applications.


url:	http://www.econ.uiuc.edu		Roger Koenker
email	roger at ysidro.econ.uiuc.edu		Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On Wed, 17 Apr 2002, Martin Biuw wrote:

> Hello,
>
> Does anyone know if there is an R-package that includes stochastic frontier
> regression models?
>
> Cheers,
>
> Martin
>
> Martin Biuw
> SEA MAMMAL RESEARCH UNIT
> Gatty Marine Laboratory
> School of Environmental and Evolutionary Biology
> University of St Andrews
> Fife, Scotland KY16 8LB
> UK
> phone +44 (0)1334 462630
> fax + 44 (0)1334 462632
> http://www.smru.st-and.ac.uk
>
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Apr 17 19:30:13 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 17 Apr 2002 18:30:13 +0100 (BST)
Subject: [R] manipulating colors in lattice
In-Reply-To: <Pine.SOL.4.21.0204171911440.25698-100000@sun11.ukl.uni-freiburg.de>
Message-ID: <Pine.LNX.4.31.0204171827350.16120-100000@gannet.stats>

?lset
?trellis.settings.

Reminder: Lattice is not Trellis and it is built on grid not S graphics,
so you can't mix in ideas from S graphics.

If you want a black-and-white plot, use lset to set the bw theme.


On Wed, 17 Apr 2002, 1-27206531-0-90000491 wrote:

> Dear R-users,
>
> I use:
>
> $platform
> [1] "i386-pc-mingw32"
> $arch
> [1] "x86"
> $os
> [1] "Win32"
> $system
> [1] "x86, Win32"
> $status
> [1] ""
> $major
> [1] "1"
> $minor
> [1] "4.1"
> $year
> [1] "2002"
> $month
> [1] "01"
> $day
> [1] "30"
> $language
> [1] "R"
>
> I try  to repeat the analysis of Jose Pinheiro and Douglas Bates described
> in their book: Mixed-Effects Models in S and S-PLUS.
>
> library(lattice)
> library(nlme)
> data(Orthodont)
> plot(Orthodont)
> fm1OrthF.lis <- lmList(distance ~ age, data=Orthodont)
> plot(intervals(fm1OrthF.lis))
> fm1OrthF <- lme(distance ~ age, data=Orthodont, random= ~ 1| Subject)
> plot(augPred(fm1OrthF), aspect="xy", grid=TRUE)
>
> My question: How can I manipulate the colours of the different plots, say
> changing symbols and lines from light-blue to black?
> e.g. plot(Orthodont, col="black") changes only symbols to black and I have
> no idea how to change the lines to black.
>
> Thanks in advance,
>
> Dominik
>
> ----------------------------------------------------------------------------
> Dominik Grathwohl; Bussstr. 34; D-79102 Freiburg
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ozric at web.de  Wed Apr 17 20:22:52 2002
From: ozric at web.de (ozric@web.de)
Date: Wed, 17 Apr 2002 20:22:52 +0200
Subject: [R] Classification Analysis
Message-ID: <200204171822.g3HIMqv31593@mailgate5.cinetic.de>

Rishabh,
yes your "PseudoCode" idea is what i want in R,too.
But even i mentioned , i didn't know of something like that in R/S-plus and i have got open eyes for this.

Perhaps anybody in the whole R community work on machineLearning-algorithm 
with rule generating,too ???

So you must program a function for yourself (i.e. C4.5 or FS-ID3) !?

(If you are interesting for papers (pdf) with algorithm let me know).
regards,Christian



Am 17.04.2002 15:13:47, schrieb "Rishabh Gupta" <rg117 at ohm.york.ac.uk>:
>Thanks for your reply.
>I am still learning these aspects of statistical analysis, so if I don't
>make sense please forgive me.
>All this work I am doing is part of a Phd and my deparment does not really
>neural network for situations like these because they say it acts like a
>black box and we don't really know what is happening in the inside. So I
>would like to concentrate on using pure statistical techniques. Ideally what
>I would like is some kind of a function that calculates the "classification
>rule" when given a grouped data set :
>    rule <- classification( GroupVar ~ DepVar1 + DepVar2 + DepVar3 + DepVar4
>..... + ...... DepVarX )
>
>Then I would be able to use that rule and apply to a single data element for
>which the group is not known:
>
>    theGroup <- rule( DataElement )
>
>I have looked at the rpart package in R but I am not entirely sure how to
>use in a way that I can create the "classification rule" and then use that
>rule. I understand that it is a general problem but it's made more difficult
>for me because I have to deal with 750 dependent variables.
>
>Your help is greatly appreciated.
>
>Many Thanks
>
>Rishabh
>
>----- Original Message -----
>From: "Huntsinger, Reid" <reid_huntsinger at merck.com>
>To: "'Rishabh Gupta'" <rg117 at ohm.york.ac.uk>; <r-help at stat.math.ethz.ch>
>Sent: Tuesday, April 16, 2002 5:00 PM
>Subject: RE: [R] Classification Analysis
>
>
>> This is a very general problem and a very large area of
>statistics/computer
>> science/etc is concerned with it. R provides lots of possibilities; you
>> might find tree-based approaches (recursive partitioning) to suit your
>> needs; in that case, rpart and the new random forests package will be of
>> interest. Also see package e1071 and the VR packages for starters. There
>are
>> lot of other possibilities; you might want to have a look at Ripley,
>Pattern
>> Recognition and Neural Networks, for example, to see some.
>>
>> Reid Huntsinger
>>
>> -----Original Message-----
>> From: Rishabh Gupta [mailto:rg117 at ohm.york.ac.uk]
>> Sent: Tuesday, April 16, 2002 11:14 AM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] Classification Analysis
>>
>>
>> Hi everyone,
>>     Could somebody explain to me what is the package/function for
>> classification analysis. I am performing analysis of music files in the
>form
>> of MIDI files. I end up with about 750 dependent variables from the
>> analysis, I also have a number of independent/grouping variables that I
>set
>> manually. What I would like is to be able to predict which group a
>> particular MIDI files belongs to given the 750 dependent variables. In
>order
>> to this I have to perform classification analysis on a sample set of MIDI
>> files where I know what group they belong to. I want to extract the
>> 'classification rule' that would enable me to predict the group of each
>MIDI
>> file (there would be a different classification rule for each grouping
>> variable). Can anybody explain what is the best way of doing this in R.
>What
>> is the best package/function that would enable me to perform
>classification
>> analysis.
>>
>> Any help would be greatly appreciated.
>>
>> Many Thanks For Your Help!
>>
>> Rishabh
>>
>> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
>-.
>> -.-
>> r-help mailing list -- Read
>http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>> Send "info", "help", or "[un]subscribe"
>> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>>
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
>> _._
>>
>>
>> --------------------------------------------------------------------------
>----
>> Notice:  This e-mail message, together with any attachments, contains
>information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that
>may be confidential, proprietary copyrighted and/or legally privileged, and
>is intended solely for the use of the individual or entity named in this
>message.  If you are not the intended recipient, and have received this
>message in error, please immediately return this by e-mail and then delete
>it.
>>
>>
>============================================================================
>==
>>
>> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
>-.-.-
>> r-help mailing list -- Read
>http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>> Send "info", "help", or "[un]subscribe"
>> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>>
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
>_._
>>
>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>
________________________________________________________________
Keine verlorenen Lotto-Quittungen, keine vergessenen Gewinne mehr! 



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From trjohns at uidaho.edu  Wed Apr 17 20:53:42 2002
From: trjohns at uidaho.edu (Timothy R. Johnson)
Date: Wed, 17 Apr 2002 11:53:42 -0700
Subject: [R] nls error control
Message-ID: <001101c1e641$32a93fe0$51566581@2d51301>

I'm running a simulation that uses nls on each run. Sometimes, not
unexpectedly, nls doesn't return parameter estimates (e.g., "singular
gradient" error). Of course when this happens the simulation (in a loop)
stops and no results are recorded. What I would like is for the simulation
to simply record that nls couldn't obtain estimates on a particular run due
to whatever difficulties it encountered but to not return an error that
stops the entire simulation.

Has anyone worked-out a tweak to do this? I'm using version 1.4.1 under
Linux.

Best regards,

Tim Johnson

---------------------------------
Assistant Professor of Statistics
University of Idaho
Moscow, Idaho 83844-1104
trjohns at uidaho.edu
http://www.uidaho.edu/~trjohns


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From adams.644 at osu.edu  Wed Apr 17 21:12:34 2002
From: adams.644 at osu.edu (jimi adams)
Date: Wed, 17 Apr 2002 15:12:34 -0400
Subject: [R] concat
Message-ID: <4.3.2.7.2.20020417150704.00a9f910@pop.service.ohio-state.edu>

i have a function that returns a list containing a variety of variable types
i am trying to run the function multiple times and return the output into a 
variable with a semi-consistent naming pattern

i.e., for ten trials i want to return the list into variables
trial1,trial2,...trial10

is there a generic way to get this to happen

i have a similar process that does the same thing to an external file:

   paste("connection", trial, ".net", sep="") -> outfile
   write(header, file=outfile, ncolumns=2)
   write("*Edges", file=outfile, append=TRUE)
   write(connection, file=outfile, ncolumns=2, append=TRUE)

where trial progresses so that these outputs are written to 
connection1.net, coneection2.net and so forth

i am having a tough time figuring out how to do the same for a variable 
within R

thanks
and sorry, i just couldn't figure out the right place to look for this one.

jimi
jimi adams
Department of Sociology
The Ohio State University
300 Bricker Hall
190 N. Oval Mall
Columbus, OH 43210-1353
614-688-4261

our mind has a remarkable ability to think of contents as being independent 
of the act of thinking
                                             -georg simmel

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From o.christensen at lancaster.ac.uk  Wed Apr 17 21:15:51 2002
From: o.christensen at lancaster.ac.uk (Ole Christensen)
Date: Wed, 17 Apr 2002 20:15:51 +0100
Subject: [R] nls error control
References: <001101c1e641$32a93fe0$51566581@2d51301>
Message-ID: <3CBDC9E7.5AD163E2@lancs.ac.uk>

Hi Tim

Maybe ``try'' is be the solution to your problem.

The follwoing silly example illustrates the use (error messages are
printed but there is no crash)

for(i in 1:10){
 x <- try(chol(matrix(NA,2,2)))
 print(i)
}


Cheers Ole


"Timothy R. Johnson" wrote:
> 
> I'm running a simulation that uses nls on each run. Sometimes, not
> unexpectedly, nls doesn't return parameter estimates (e.g., "singular
> gradient" error). Of course when this happens the simulation (in a loop)
> stops and no results are recorded. What I would like is for the simulation
> to simply record that nls couldn't obtain estimates on a particular run due
> to whatever difficulties it encountered but to not return an error that
> stops the entire simulation.
> 
> Has anyone worked-out a tweak to do this? I'm using version 1.4.1 under
> Linux.
> 
> Best regards,
> 
> Tim Johnson
> 
> ---------------------------------
> Assistant Professor of Statistics
> University of Idaho
> Moscow, Idaho 83844-1104
> trjohns at uidaho.edu
> http://www.uidaho.edu/~trjohns
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
Ole F. Christensen
Department of Mathematics and Statistics
Fylde College, Lancaster University 
Lancaster, LA1 4YF, England
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From matthew_wiener at merck.com  Wed Apr 17 21:28:13 2002
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Wed, 17 Apr 2002 15:28:13 -0400
Subject: [R] nls error control
Message-ID: <7C4F091F6140D411A29300508B5C73B906D72036@usrymx04.merck.com>

Check the "try" command.

Hope this helps,

Matt

-----Original Message-----
From: Timothy R. Johnson [mailto:trjohns at uidaho.edu]
Sent: Wednesday, April 17, 2002 2:54 PM
To: r-help at stat.math.ethz.ch
Subject: [R] nls error control


I'm running a simulation that uses nls on each run. Sometimes, not
unexpectedly, nls doesn't return parameter estimates (e.g., "singular
gradient" error). Of course when this happens the simulation (in a loop)
stops and no results are recorded. What I would like is for the simulation
to simply record that nls couldn't obtain estimates on a particular run due
to whatever difficulties it encountered but to not return an error that
stops the entire simulation.

Has anyone worked-out a tweak to do this? I'm using version 1.4.1 under
Linux.

Best regards,

Tim Johnson

---------------------------------
Assistant Professor of Statistics
University of Idaho
Moscow, Idaho 83844-1104
trjohns at uidaho.edu
http://www.uidaho.edu/~trjohns


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named in this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From sundard at pdf.com  Wed Apr 17 21:31:19 2002
From: sundard at pdf.com (Sundar Dorai-Raj)
Date: Wed, 17 Apr 2002 14:31:19 -0500
Subject: [R] union of lists
References: <Pine.OSF.3.96.1020417151201.30270B-100000@ija.csic.es>
Message-ID: <3CBDCD87.9DA01186@pdf.com>

Would this work?

lista <- list(1:3,4:7,2:10)
listb <- list(2:4,6:10,1:6)
lapply(1:3,function(x,lista,listb) 
       union(lista[[x]],listb[[x]]),lista=lista,listb=listb)

Or, alternatively, if the list has names:

lista <- list("s"=1:3,"u"=4:7,"n"=2:10,"d"=0,"a"=-1:1,"r"=3:12)
listb <- list("s"=2:4,"u"=6:10,"n"=1:6,"r"=2:4)
lapply(union(names(lista),names(listb)),
       function(x,lista,listb) 
         union(lista[[x]],listb[[x]]),
       lista=lista,listb=listb)

The latter option allows for lista and listb to have different lengths
as well.

Sundar

Agustin Lobo wrote:
> 
> Hi there,
> 
> Given 2 lists of integer vectors, i.e.:
> 
> > lista1
> $"1"
> [1]  1 34  5
> $"2"
> [1] 2 1
> $"3"
> [1]  3 10 15
> 
> > lista2
> $"1"
> [1] 1 5
> $"2"
> [1] 2 1
> $"3"
> [1]  3 10 29
> 
> I want to obtain the union of both, defined
> as the union of the vectors, that is
> lista.union[[1]] <- union(lista1[[1]],lista2[[1]]):
> 
> > lista.union
> $"1"
> [1]  1 34  5
> $"2"
> [1] 2 1
> $"3"
> [1]  3 10 15 29
> 
> I'm now using a for loop and applying
> union() to each pair of vectors, but is
> there a faster way avoiding the for ?
> 
> Thanks!
> 
> Agus
> 
> Dr. Agustin Lobo
> Instituto de Ciencias de la Tierra (CSIC)
> Lluis Sole Sabaris s/n
> 08028 Barcelona SPAIN
> tel 34 93409 5410
> fax 34 93411 0012
> alobo at ija.csic.es
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 

Sundar Dorai-Raj, Ph.D.
Statistical Methods Engineer
PDF Solutions, Inc.
(972) 889-3085 x216
(214) 392-7619 cell
sundard at pdf.com
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ggrothendieck at yifan.net  Wed Apr 17 21:51:25 2002
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Wed, 17 Apr 2002 15:51:25 -0400
Subject: [R] union of lists
In-Reply-To: <Pine.OSF.3.96.1020417151201.30270B-100000@ija.csic.es>
Message-ID: <3CBD99FD.20758.6DCDCB@localhost>



Paste the lists together to create character strings and then parse them
back into R expressions and apply unique:

list1 <- list(c(1,34,5),c(2,1),c(3,10,15))
list2 <- list(c(1,5),c(2,1),c(3,10,29))

xx <- gsub("\\) *c\\(",",",paste(list1,list2))
xx <- sapply( xx , FUN=function(x)unique(eval(parse(text=x))) )




On 17 Apr 2002 at 15:24, Agustin Lobo wrote:

> Hi there,
> 
> Given 2 lists of integer vectors, i.e.:
> 
> > lista1
> $"1"
> [1]  1 34  5
> $"2"
> [1] 2 1
> $"3"
> [1]  3 10 15
> 
> > lista2
> $"1"
> [1] 1 5
> $"2"
> [1] 2 1
> $"3"
> [1]  3 10 29
> 
> 
> I want to obtain the union of both, defined
> as the union of the vectors, that is 
> lista.union[[1]] <- union(lista1[[1]],lista2[[1]]):
> 
> > lista.union
> $"1"
> [1]  1 34  5
> $"2"
> [1] 2 1
> $"3"
> [1]  3 10 15 29
> 
> I'm now using a for loop and applying
> union() to each pair of vectors, but is
> there a faster way avoiding the for ?
> 
> Thanks!
> 
> Agus
> 
> 
> Dr. Agustin Lobo
> Instituto de Ciencias de la Tierra (CSIC)
> Lluis Sole Sabaris s/n
> 08028 Barcelona SPAIN
> tel 34 93409 5410
> fax 34 93411 0012
> alobo at ija.csic.es
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From reid_huntsinger at merck.com  Wed Apr 17 21:54:33 2002
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Wed, 17 Apr 2002 15:54:33 -0400
Subject: [R] Classification Analysis
Message-ID: <2C23DE2983BE034CB1CB90DB6B813FD639E94B@uswpmx11.merck.com>

rpart will calculate the classification rule (represented as a tree) given a
grouped data set. predict.rpart will apply that rule to a single data
element (or data set) for which groupings are not known. path.rpart will
return the rules explicitly, if that's needed. Try the examples from
help("rpart"), help("predict.rpart") and help("path.rpart") to see.

Reid Huntsinger

-----Original Message-----
From: ozric at web.de [mailto:ozric at web.de]
Sent: Wednesday, April 17, 2002 2:23 PM
To: Rishabh Gupta
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Classification Analysis


Rishabh,
yes your "PseudoCode" idea is what i want in R,too.
But even i mentioned , i didn't know of something like that in R/S-plus and
i have got open eyes for this.

Perhaps anybody in the whole R community work on machineLearning-algorithm 
with rule generating,too ???

So you must program a function for yourself (i.e. C4.5 or FS-ID3) !?

(If you are interesting for papers (pdf) with algorithm let me know).
regards,Christian



Am 17.04.2002 15:13:47, schrieb "Rishabh Gupta" <rg117 at ohm.york.ac.uk>:
>Thanks for your reply.
>I am still learning these aspects of statistical analysis, so if I don't
>make sense please forgive me.
>All this work I am doing is part of a Phd and my deparment does not really
>neural network for situations like these because they say it acts like a
>black box and we don't really know what is happening in the inside. So I
>would like to concentrate on using pure statistical techniques. Ideally
what
>I would like is some kind of a function that calculates the "classification
>rule" when given a grouped data set :
>    rule <- classification( GroupVar ~ DepVar1 + DepVar2 + DepVar3 +
DepVar4
>..... + ...... DepVarX )
>
>Then I would be able to use that rule and apply to a single data element
for
>which the group is not known:
>
>    theGroup <- rule( DataElement )
>
>I have looked at the rpart package in R but I am not entirely sure how to
>use in a way that I can create the "classification rule" and then use that
>rule. I understand that it is a general problem but it's made more
difficult
>for me because I have to deal with 750 dependent variables.
>
>Your help is greatly appreciated.
>
>Many Thanks
>
>Rishabh
>
>----- Original Message -----
>From: "Huntsinger, Reid" <reid_huntsinger at merck.com>
>To: "'Rishabh Gupta'" <rg117 at ohm.york.ac.uk>; <r-help at stat.math.ethz.ch>
>Sent: Tuesday, April 16, 2002 5:00 PM
>Subject: RE: [R] Classification Analysis
>
>
>> This is a very general problem and a very large area of
>statistics/computer
>> science/etc is concerned with it. R provides lots of possibilities; you
>> might find tree-based approaches (recursive partitioning) to suit your
>> needs; in that case, rpart and the new random forests package will be of
>> interest. Also see package e1071 and the VR packages for starters. There
>are
>> lot of other possibilities; you might want to have a look at Ripley,
>Pattern
>> Recognition and Neural Networks, for example, to see some.
>>
>> Reid Huntsinger
>>
>> -----Original Message-----
>> From: Rishabh Gupta [mailto:rg117 at ohm.york.ac.uk]
>> Sent: Tuesday, April 16, 2002 11:14 AM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] Classification Analysis
>>
>>
>> Hi everyone,
>>     Could somebody explain to me what is the package/function for
>> classification analysis. I am performing analysis of music files in the
>form
>> of MIDI files. I end up with about 750 dependent variables from the
>> analysis, I also have a number of independent/grouping variables that I
>set
>> manually. What I would like is to be able to predict which group a
>> particular MIDI files belongs to given the 750 dependent variables. In
>order
>> to this I have to perform classification analysis on a sample set of MIDI
>> files where I know what group they belong to. I want to extract the
>> 'classification rule' that would enable me to predict the group of each
>MIDI
>> file (there would be a different classification rule for each grouping
>> variable). Can anybody explain what is the best way of doing this in R.
>What
>> is the best package/function that would enable me to perform
>classification
>> analysis.
>>
>> Any help would be greatly appreciated.
>>
>> Many Thanks For Your Help!
>>
>> Rishabh
>>
>>
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
>-.
>> -.-
>> r-help mailing list -- Read
>http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>> Send "info", "help", or "[un]subscribe"
>> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>>
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
.
>> _._
>>
>>
>>
--------------------------------------------------------------------------
>----
>> Notice:  This e-mail message, together with any attachments, contains
>information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that
>may be confidential, proprietary copyrighted and/or legally privileged, and
>is intended solely for the use of the individual or entity named in this
>message.  If you are not the intended recipient, and have received this
>message in error, please immediately return this by e-mail and then delete
>it.
>>
>>
>===========================================================================
=
>==
>>
>>
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
>-.-.-
>> r-help mailing list -- Read
>http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>> Send "info", "help", or "[un]subscribe"
>> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>>
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
.
>_._
>>
>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
._._
>
________________________________________________________________
Keine verlorenen Lotto-Quittungen, keine vergessenen Gewinne mehr! 



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named in this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hvillalo at ipn.mx  Wed Apr 17 22:24:36 2002
From: hvillalo at ipn.mx (=?ISO-8859-1?Q?H=E9ctor_Villalobos?=)
Date: Wed, 17 Apr 2002 14:24:36 -0600
Subject: [R] zero center a group of variables
Message-ID: <3CBD85A4.30826.119CEB5@localhost>

*This message was transferred with a trial version of CommuniGate(tm) Pro*

A simple question, perhaps to simple, but I am new to R:
For a data frame with k variables and n1+n2 observations (two 
groups) how can i substract the group means for every variable, so 
both group variables become centered to mean zero?

Thanks in advance for your help

H?ctor



...................................................
H?ctor Villalobos
  Depto. de Pesquer?as y Biolog?a Marina
  Instituto Polit?cnico Nacional - Centro
  Interdisciplinario de Ciencias Marinas 
  (IPN-CICIMAR)
  A.P. 592. Col. Centro
  La Paz, Baja California Sur, M?XICO. 23000
  Tel.: (+52 612) 122 53 44 ext. 2426 
  Fax.: (+52 612) 122 53 22
....................................................

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Apr 17 22:57:19 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 17 Apr 2002 22:57:19 +0200
Subject: [R] zero center a group of variables
In-Reply-To: <3CBD85A4.30826.119CEB5@localhost>
References: <3CBD85A4.30826.119CEB5@localhost>
Message-ID: <x2u1qam4b4.fsf@blueberry.kubism.ku.dk>

"H?ctor Villalobos" <hvillalo at ipn.mx> writes:

> A simple question, perhaps to simple, but I am new to R:
> For a data frame with k variables and n1+n2 observations (two 
> groups) how can i substract the group means for every variable, so 
> both group variables become centered to mean zero?
> 
> Thanks in advance for your help
> 
> H?ctor

in 1.5.0, we'll have

 split(x, g) <- lapply(split(x, g), scale, scale=FALSE)

Till then, you'll have to do something like

x[g==1,] <- scale(x[g==1,], scale=FALSE)
x[g==2,] <- scale(x[g==2,], scale=FALSE)

or, more general

for ( i in split(1:length(g), g) )
   x[i,] <- scale(x[i,], scale=FALSE)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Wed Apr 17 23:18:12 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 17 Apr 2002 23:18:12 +0200
Subject: [R] concat
References: <4.3.2.7.2.20020417150704.00a9f910@pop.service.ohio-state.edu>
Message-ID: <3CBDE694.D82BDFD8@statistik.uni-dortmund.de>

jimi adams wrote:
> 
> i have a function that returns a list containing a variety of variable types
> i am trying to run the function multiple times and return the output into a
> variable with a semi-consistent naming pattern
> 
> i.e., for ten trials i want to return the list into variables
> trial1,trial2,...trial10
>
> is there a generic way to get this to happen
> 
> i have a similar process that does the same thing to an external file:
> 
>    paste("connection", trial, ".net", sep="") -> outfile
>    write(header, file=outfile, ncolumns=2)
>    write("*Edges", file=outfile, append=TRUE)
>    write(connection, file=outfile, ncolumns=2, append=TRUE)
> 
> where trial progresses so that these outputs are written to
> connection1.net, coneection2.net and so forth
> 
> i am having a tough time figuring out how to do the same for a variable
> within R
> 
> thanks
> and sorry, i just couldn't figure out the right place to look for this one.


  assign(paste("trial", i, sep=""), anything.to.be.assigned)

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From r_stuff_online at hotmail.com  Thu Apr 18 00:13:07 2002
From: r_stuff_online at hotmail.com (Neil Osborne)
Date: Wed, 17 Apr 2002 22:13:07 +0000
Subject: [R] Problems embedding R in a C application
Message-ID: <F2018tP9DLf4bg5Xmll000058ef@hotmail.com>

Hello,

I've encountered two serious issues that have stopped me in my tracks, and I 
would be most grateful to anyone who can provide some answers.

I am using the examples provided on the page "Testing the Embeddable R 
Library". I am writing a C application, that I want to embedd R into (I'm 
not interested in embedding my application in R, that's not an option). I'm 
developing on a Win2K box. The two problems I've hit (so far!) are these:

Macro definition (R is using a macro already defined in one of the core 
windows libraries)
Unresolved external - missing definition for func Rf_initEmbeddedR which is 
prototyped as an extern in EmbeddedRCall.c


Here are the issues again (in more detail)
===========================================================

1. Macro re-definition

In file ..\include\R_ext\RS.h

the line (37):

#define ERROR			),error(R_problem_buf);}


causes this problem :

warning C4005: 'ERROR' : macro redefinition
        d:\visualstudio\vc98\include\wingdi.h(93) : see previous definition 
of 'ERROR'



2. Unresolved external:

unresolved external symbol _Rf_initEmbeddedR

This function is not defined anywhere. Does anyone know how I can init a 
"session" of R in "embedded" mode (i.e. no direct writing to the console 
etc) ?


Any help is very welcome


Many thanks in advance




_________________________________________________________________
Join the worlds largest e-mail service with MSN Hotmail. 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pem at theriver.com  Thu Apr 18 00:26:59 2002
From: pem at theriver.com (Patrick McKnight)
Date: 17 Apr 2002 15:26:59 -0700
Subject: [R] placing objects with format statements into text file
Message-ID: <1019082419.31864.129.camel@copernicus>

Greetings,

Is there a way to explicitly state the format statement for each object
in a write statement?  For example, I have data frame with four
variables (SSN that is 11 characters, and three other variables with
values ranging between 0 and 10).  I would like to have a text file
written that preserves a specific formatting.  Specifically, I would
like the following result:

129-02-1102 1 3 4 5
123-45-345610 9 810
etc.

As you can see, the SSN takes up only 11 columns and the other four
variables are formated with no seperator but are "put" there with the
format statement of f2.0.  So, is there a way to accomplish this in R? 
If so, I would be extremely greatful for direction.


-- 
Cheers,

Patrick
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From sergei at stams.strath.ac.uk  Thu Apr 18 01:34:37 2002
From: sergei at stams.strath.ac.uk (Sergei Zuyev)
Date: Thu, 18 Apr 2002 00:34:37 +0100
Subject: [R] User defined macros for Rd-files?
Message-ID: <02041800343701.01573@mstera>

Dear R-developers,

I am trying to make use of my own defined macros in Rd-files in order I could 
simply type, say, \Splus, to get a font similar to \R in help files. So I put 
the corresponding entry in Rd.cfg which now contains the line:
\newcommand{\Splus}{{\normalfont\textsf{Splus}}}
similar to the way \R defined in Rd.sty. So now so good:
R CMD Rd2dvi generates a dvi-file with a proper font. But building the 
package and documentation just ignores definitions in Rd.cfg.
1. Is there a way to define macros which then will be understood by R CMD 
build and install generating the html and text help files also?
2. I experimented with Rd.cfg and found that it is found only if it is in the 
same directory as Rd.sty (at least on my machine). It would, however, be 
logical to have it where the package's Rd-files are held so the macros could 
be different for different packages. Also a user may not have an access to 
the R_HOME. Is there a way around it?

Thanks for your great efforts and best wishes!
Sergei

PS. When replying, could you, please, send a copy to my email.



-- 
======================================================
                                      Dr. Sergei ZUYEV
Statistics and Modelling Science dept., University of Strathclyde
    Livingston Tower, 26 Richmond str., Glasgow, G1 1XH, U.K.
     Tel.: +44 (0)141 548 3663    Fax:  +44 (0)141 552 2079
E-mail: sergei at stams.strath.ac.uk   http://www.stams.strath.ac.uk
======================================================
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From m.harris at botany.uq.edu.au  Thu Apr 18 02:51:25 2002
From: m.harris at botany.uq.edu.au (Mark Harris)
Date: Thu, 18 Apr 2002 10:51:25 +1000
Subject: [R] Changing tick mark labels
Message-ID: <3CBE188D.A6B2AB96@botany.uq.edu.au>

Hello,

Can anyone help me out with this problem?
After performing logistic regressions and testing the significance with
likelihood ratios, I have plotted the results using "termplot". I am
wondering, how to get the names of my variables to appear on the x-axis
rather than ascending numbers?
I have used:

termplot(fm, se=T, axes=FALSE, col.se="black")
axis(1, 1:4, LETTERS[1:4])
axis(2)
box()

to replace the numbers with letters - but I want to be able to have the
names of the plotted varibles from say Data$Expt1, so that instead of A,
B, C - I have Control, Subs1, Subs2 etc

Can anyone tell me how I can do this?

Thankyou for your time and assistance, I appreciate it highly.

Mark Harris


--
Mark Harris
School of Life Sciences
University of Queensland, Brisbane Australia

Ph: (07) 3365 7237
International: 0061 7 3365 7237
Mobile: 0407203678


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Thu Apr 18 03:32:18 2002
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Wed, 17 Apr 2002 21:32:18 -0400
Subject: [R] Changing tick mark labels
In-Reply-To: <3CBE188D.A6B2AB96@botany.uq.edu.au>; from m.harris@botany.uq.edu.au on Thu, Apr 18, 2002 at 10:51:25AM +1000
References: <3CBE188D.A6B2AB96@botany.uq.edu.au>
Message-ID: <20020417213218.A10234@cattell.psych.upenn.edu>

On 04/18/02 10:51, Mark Harris wrote:
>Hello,
>
>Can anyone help me out with this problem?
>After performing logistic regressions and testing the significance with
>likelihood ratios, I have plotted the results using "termplot". I am
>wondering, how to get the names of my variables to appear on the x-axis
>rather than ascending numbers?
>I have used:
>
>termplot(fm, se=T, axes=FALSE, col.se="black")
>axis(1, 1:4, LETTERS[1:4])
>axis(2)
>box()
>
>to replace the numbers with letters - but I want to be able to have the
>names of the plotted varibles from say Data$Expt1, so that instead of A,
>B, C - I have Control, Subs1, Subs2 etc
>
>Can anyone tell me how I can do this?

I don't know termplot, but for other plottting functions, it
works to say

axis(1,1:4,labels=c("Control","Subs1","Subs2","etc"))

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ricardo at icmc.sc.usp.br  Thu Apr 18 05:16:06 2002
From: ricardo at icmc.sc.usp.br (=?iso-8859-1?Q?Ricardo_Gon=E7alves?=)
Date: Thu, 18 Apr 2002 00:16:06 -0300
Subject: [R] Silly Question
Message-ID: <001901c1e687$6146d510$0100000a@stats>

After I source an R code, how can I call the function?
Thanks
Rick


---
Outgoing mail is certified Virus Free.
Checked by AVG anti-virus system (http://www.grisoft.com).
Version: 6.0.350 / Virus Database: 196 - Release Date: 17/4/2002

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From FJMolina at lbl.gov  Thu Apr 18 06:43:31 2002
From: FJMolina at lbl.gov (Francisco J Molina)
Date: Wed, 17 Apr 2002 21:43:31 -0700
Subject: [R] R and C++ in Solaris
Message-ID: <3CBE4EF3.96E092D7@lbl.gov>

I am using a script written in R that calls a C++ function. I got this
error

Segmentation fault

I am getting this error with gcc version 2.95.2 and R version 1.3.0
running in Solaris.

Why am I getting this error?

Professor Ripley, I got this error when the code we were discussing.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From FJMolina at lbl.gov  Thu Apr 18 06:52:24 2002
From: FJMolina at lbl.gov (Francisco J Molina)
Date: Wed, 17 Apr 2002 21:52:24 -0700
Subject: [R] C++ and R in Solaris
Message-ID: <3CBE5108.9C54F548@lbl.gov>

Continuation of my previous message:(maybe this information could be
relevant)

I run the same script written in R calling the same C++ function. I got
the error

Segmentation fault (core dumped)

I am getting this error with gcc version 2.95.3 and R version 1.4.1
running in Solaris.

Why? How can I avoid it?
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ozric at web.de  Thu Apr 18 08:32:22 2002
From: ozric at web.de (ozric@web.de)
Date: Thu, 18 Apr 2002 08:32:22 +0200
Subject: [R] Classification Analysis
Message-ID: <200204180632.g3I6WLv30945@mailgate5.cinetic.de>

Hi Bill,
a really nice fundus especially for "fuzzy-papers" 
what is in present my main interesting) you can download at http://www.scch.at/index.html . If you have a special method  interest let me now ,beacuse i have got a growing pdf-archive.
....my learning by doing project for R is a fuzzy association rule approach.

suggestion for Rishabh:
>> >All this work I am doing is part of a Phd and my deparment does not really
>> >neural network for situations like these because they say it acts like a
>> >black box and we don't really know what is happening in the inside. So I
>> >would like to concentrate on using pure statistical techniques. 
I'm not complete agree that neural networks are a black box, because
it is possible to measure the sensitivity.

One sophisticated strategy i.e. is 
1. learn a neural network with independent and classification variable
2. If the neural network have got a good learning result test the generalization. 
3.If this is ok for your purporse, change the values for all cases  of the independent variable (which sens. you interested).
4. Now generalize again the neural network with the modified data and you get a new distribution of the classification variable and now the influence of the modification.

The advantage in contradiction to "logistic regression" is that you are not bound to linearity and can i.e. test interaction effects when you change 2 variables at the same time.
The difficulty with ANN here is the estimation of the neural network paramteres for good training and test approximation, but for this exist genetic algorithm.


regards,christian

>Hello Ozric,
>
>I am interested in knowing what papers you have available.
>
>Thanks,
>
>Bill
>
>ozric at web.de wrote:
>
>> Rishabh,
>> yes your "PseudoCode" idea is what i want in R,too.
>> But even i mentioned , i didn't know of something like that in R/S-plus and i have got open eyes for this.
>>
>> Perhaps anybody in the whole R community work on machineLearning-algorithm
>> with rule generating,too ???
>>
>> So you must program a function for yourself (i.e. C4.5 or FS-ID3) !?
>>
>> (If you are interesting for papers (pdf) with algorithm let me know).
>> regards,Christian
>>
>> Am 17.04.2002 15:13:47, schrieb "Rishabh Gupta" <rg117 at ohm.york.ac.uk>:
>> >Thanks for your reply.
>> >I am still learning these aspects of statistical analysis, so if I don't
>> >make sense please forgive me.
>> >All this work I am doing is part of a Phd and my deparment does not really
>> >neural network for situations like these because they say it acts like a
>> >black box and we don't really know what is happening in the inside. So I
>> >would like to concentrate on using pure statistical techniques. Ideally what
>> >I would like is some kind of a function that calculates the "classification
>> >rule" when given a grouped data set :
>> >    rule <- classification( GroupVar ~ DepVar1 + DepVar2 + DepVar3 + DepVar4
>> >..... + ...... DepVarX )
>> >
>> >Then I would be able to use that rule and apply to a single data element for
>> >which the group is not known:
>> >
>> >    theGroup <- rule( DataElement )
>> >
>> >I have looked at the rpart package in R but I am not entirely sure how to
>> >use in a way that I can create the "classification rule" and then use that
>> >rule. I understand that it is a general problem but it's made more difficult
>> >for me because I have to deal with 750 dependent variables.
>> >
>> >Your help is greatly appreciated.
>> >
>> >Many Thanks
>> >
>> >Rishabh
>> >
>> >----- Original Message -----
>> >From: "Huntsinger, Reid" <reid_huntsinger at merck.com>
>> >To: "'Rishabh Gupta'" <rg117 at ohm.york.ac.uk>; <r-help at stat.math.ethz.ch>
>> >Sent: Tuesday, April 16, 2002 5:00 PM
>> >Subject: RE: [R] Classification Analysis
>> >
>> >
>> >> This is a very general problem and a very large area of
>> >statistics/computer
>> >> science/etc is concerned with it. R provides lots of possibilities; you
>> >> might find tree-based approaches (recursive partitioning) to suit your
>> >> needs; in that case, rpart and the new random forests package will be of
>> >> interest. Also see package e1071 and the VR packages for starters. There
>> >are
>> >> lot of other possibilities; you might want to have a look at Ripley,
>> >Pattern
>> >> Recognition and Neural Networks, for example, to see some.
>> >>
>> >> Reid Huntsinger
>> >>
>> >> -----Original Message-----
>> >> From: Rishabh Gupta [mailto:rg117 at ohm.york.ac.uk]
>> >> Sent: Tuesday, April 16, 2002 11:14 AM
>> >> To: r-help at stat.math.ethz.ch
>> >> Subject: [R] Classification Analysis
>> >>
>> >>
>> >> Hi everyone,
>> >>     Could somebody explain to me what is the package/function for
>> >> classification analysis. I am performing analysis of music files in the
>> >form
>> >> of MIDI files. I end up with about 750 dependent variables from the
>> >> analysis, I also have a number of independent/grouping variables that I
>> >set
>> >> manually. What I would like is to be able to predict which group a
>> >> particular MIDI files belongs to given the 750 dependent variables. In
>> >order
>> >> to this I have to perform classification analysis on a sample set of MIDI
>> >> files where I know what group they belong to. I want to extract the
>> >> 'classification rule' that would enable me to predict the group of each
>> >MIDI
>> >> file (there would be a different classification rule for each grouping
>> >> variable). Can anybody explain what is the best way of doing this in R.
>> >What
>> >> is the best package/function that would enable me to perform
>> >classification
>> >> analysis.
>> >>
>> >> Any help would be greatly appreciated.
>> >>
>> >> Many Thanks For Your Help!
>> >>
>> >> Rishabh
>> >>
>> >> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
>> >-.
>> >> -.-
>> >> r-help mailing list -- Read
>> >http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>> >> Send "info", "help", or "[un]subscribe"
>> >> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>> >>
>> >_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
>> >> _._
>> >>
>> >>
>> >> --------------------------------------------------------------------------
>> >----
>> >> Notice:  This e-mail message, together with any attachments, contains
>> >information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that
>> >may be confidential, proprietary copyrighted and/or legally privileged, and
>> >is intended solely for the use of the individual or entity named in this
>> >message.  If you are not the intended recipient, and have received this
>> >message in error, please immediately return this by e-mail and then delete
>> >it.
>> >>
>> >>
>> >============================================================================
>> >==
>> >>
>> >> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
>> >-.-.-
>> >> r-help mailing list -- Read
>> >http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>> >> Send "info", "help", or "[un]subscribe"
>> >> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>> >>
>> >_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
>> >_._
>> >>
>> >
>> >-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>> >r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>> >Send "info", "help", or "[un]subscribe"
>> >(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>> >_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>> >
>> ________________________________________________________________
>> Keine verlorenen Lotto-Quittungen, keine vergessenen Gewinne mehr!
>>
>> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>> Send "info", "help", or "[un]subscribe"
>> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>
>
______________________________________________________________________________
Sie wollen mehr? Mehr Speicher, mehr Mail, mehr Erlebnis, mehr Leistung, 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Apr 18 08:42:31 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 18 Apr 2002 07:42:31 +0100 (BST)
Subject: [R] Problems embedding R in a C application
In-Reply-To: <F2018tP9DLf4bg5Xmll000058ef@hotmail.com>
Message-ID: <Pine.GSO.4.44.0204180732300.28415-100000@auk.stats>

On Wed, 17 Apr 2002, Neil Osborne wrote:

> I've encountered two serious issues that have stopped me in my tracks, and I
> would be most grateful to anyone who can provide some answers.
>
> I am using the examples provided on the page "Testing the Embeddable R
> Library". I am writing a C application, that I want to embedd R into (I'm
> not interested in embedding my application in R, that's not an option). I'm
> developing on a Win2K box. The two problems I've hit (so far!) are these:

But embedding R in that sense is not supported on Windows, AFAIK.  What is
supported is the DCOM interface on CRAN.

> Macro definition (R is using a macro already defined in one of the core
> windows libraries)
> Unresolved external - missing definition for func Rf_initEmbeddedR which is
> prototyped as an extern in EmbeddedRCall.c
>
>
> Here are the issues again (in more detail)
> ===========================================================
>
> 1. Macro re-definition
>
> In file ..\include\R_ext\RS.h
>
> the line (37):
>
> #define ERROR			),error(R_problem_buf);}
>
>
> causes this problem :
>
> warning C4005: 'ERROR' : macro redefinition
>         d:\visualstudio\vc98\include\wingdi.h(93) : see previous definition
> of 'ERROR'

Easy!  Just #undef ERROR after the include.  Or use a more selective set of
headers.

> 2. Unresolved external:
>
> unresolved external symbol _Rf_initEmbeddedR
>
> This function is not defined anywhere. Does anyone know how I can init a
> "session" of R in "embedded" mode (i.e. no direct writing to the console
> etc) ?

It *is* defined in src/unix/system.c: note *unix*.

Answer to Q: use the DCOM interface.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Thu Apr 18 08:50:05 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 18 Apr 2002 08:50:05 +0200
Subject: [R] placing objects with format statements into text file
In-Reply-To: <1019082419.31864.129.camel@copernicus>
References: <1019082419.31864.129.camel@copernicus>
Message-ID: <15550.27805.294314.860269@gargle.gargle.HOWL>

>>>>> "Patrick" == Patrick McKnight <pem at theriver.com> writes:

    Patrick> Greetings, Is there a way to explicitly state the
    Patrick> format statement for each object in a write
    Patrick> statement?  For example, I have data frame with
    Patrick> four variables (SSN that is 11 characters, and
    Patrick> three other variables with values ranging between 0
    Patrick> and 10).  I would like to have a text file written
    Patrick> that preserves a specific formatting.
    Patrick> Specifically, I would like the following result:

    Patrick> 129-02-1102 1 3 4 5
    Patrick> 123-45-345610 9 810

    Patrick> etc.

    Patrick> As you can see, the SSN takes up only 11 columns
    Patrick> and the other four variables are formated with no
    Patrick> seperator but are "put" there with the format
    Patrick> statement of f2.0.  So, is there a way to
    Patrick> accomplish this in R?  If so, I would be extremely
    Patrick> greatful for direction.

Here is an example (providing these explicitly in such questions
		   makes the question often easier to understand)

d1 <- data.frame(ssn = c("123-345-789","987-654-3"), id = 1:2, age=c(20,60))
> d1
          ssn id age
1 123-345-789  1  20
2   987-654-3  2  60

Now the idea is to use
-  write.table with  sep=""
-  format each column - coercing to character (of same width) :

> write.table(lapply(d1,format), quote=FALSE,row.names=FALSE,col.names=FALSE,sep="")

123-345-789120
987-654-3  260

----

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From maechler at stat.math.ethz.ch  Thu Apr 18 08:59:44 2002
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 18 Apr 2002 08:59:44 +0200
Subject: [R] Cross-correlation -- help.search()
In-Reply-To: <3CBD9C3F.1AFF0C10@psy.uni-muenchen.de>
References: <B8E3486A.8416%pflugshaupt@geobot.umnw.ethz.ch>
	<3CBD9C3F.1AFF0C10@psy.uni-muenchen.de>
Message-ID: <15550.28384.305155.354757@gargle.gargle.HOWL>

>>>>> "Sven" == Sven Garbade <garbade at psy.uni-muenchen.de> writes:

    Sven> Kaspar Pflugshaupt wrote:
    >> 
    >> On 17.4.2002 16:55 Uhr, Sven Garbade wrote:
    >> 
    >> > I want to recalculate an analysis found in a paper. An empirical time
    >> > series (velocities, altogether 241 data values) were cross-correlated
    >> > with an invertited cosine function (200 milliseconds duration).
    >> > Following the authors the resulting values should offer some advantages:
    >> > being independent of gain and peak latency differences between single
    >> > trials and preserving the temporal aspect of the modulation. Is there a
    >> > function to calculate cross-correlations in R? I think cor() is ot the
    >> > right one.
    >> 
    >> You need the function ccf() in library(ts).

    Sven> Thanks, but I'm wondering why the R search engine found nothing
    Sven> appropriate for the keyword "cross-correlation".

Because, unfortunately it only looks at the 
\title{}, \name{}, \alias{}, and \keyword{} entries, but *NOT* the
\description{} one.

I think we should consider changing this eventually. Including
the \description{} would blow up the search database by more
than a factor of two probably, but since the introduction of
help.search() computers have more than quadrupled in
performance. 

((and I have also changed the title of library/ts/man/acf.Rd
  such that  help.search("cross.*corr")  will find the proper
  help page, namely the one of "acf()" which also contains
  "ccf()"
))

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From lutz.thieme at amd.com  Thu Apr 18 09:48:01 2002
From: lutz.thieme at amd.com (lutz.thieme@amd.com)
Date: Thu, 18 Apr 2002 09:48:01 +0200
Subject: [R] grid lines outside plot region in version  R1.4.1
Message-ID: <E540DF203FFED21182EB0008C72875600AEDA70A@deexmta4.amd.com>

Hello everybody,

if I'm using par(xpd=NA) gridlines will plotted outside the plotting region. This is "new" (and, in my
opinion, unaesthetic) in version 1.4 - compared to version 1.3. Is this a bug or a feature?

Example:
------------------
par(xpd=NA)
plot(1:11)
grid()
------------------
platform sparc-sun-solaris2.6
arch     sparc               
os       solaris2.6          
system   sparc, solaris2.6   
status                       
major    1                   
minor    4.1                 
year     2002                
month    01                  
day      30                  
language R   

Best regards,

Lutz

Lutz Thieme
AMD Saxony Manfacturing GmbH
Product Engineering
phone:	+49 351 277-4269
fax:	+49 351 277-9-4269
email:	lutz.thieme at amd.com


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Apr 18 10:14:04 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 18 Apr 2002 09:14:04 +0100 (BST)
Subject: [R] grid lines outside plot region in version  R1.4.1
In-Reply-To: <E540DF203FFED21182EB0008C72875600AEDA70A@deexmta4.amd.com>
Message-ID: <Pine.LNX.4.31.0204180907540.30339-100000@gannet.stats>

On Thu, 18 Apr 2002 lutz.thieme at amd.com wrote:

> Hello everybody,
>
> if I'm using par(xpd=NA) gridlines will plotted outside the plotting region. This is "new" (and, in my
> opinion, unaesthetic) in version 1.4 - compared to version 1.3. Is this a bug or a feature?

There are no such versions.  I am not being picky here: see the NEWS for
1.3.1.  It appears this was changed by a bug fix for abline in that
version, so 1.3.0 and 1.3.1 behaved differently.

Try adding xpd=FALSE to the abline calls inside grid().

>
> Example:
> ------------------
> par(xpd=NA)
> plot(1:11)
> grid()
> ------------------
> platform sparc-sun-solaris2.6
> arch     sparc
> os       solaris2.6
> system   sparc, solaris2.6
> status
> major    1
> minor    4.1
> year     2002
> month    01
> day      30
> language R
>
> Best regards,
>
> Lutz
>
> Lutz Thieme
> AMD Saxony Manfacturing GmbH
> Product Engineering
> phone:	+49 351 277-4269
> fax:	+49 351 277-9-4269
> email:	lutz.thieme at amd.com
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From P.Connolly at hortresearch.co.nz  Thu Apr 18 12:58:25 2002
From: P.Connolly at hortresearch.co.nz (Patrick Connolly)
Date: Thu, 18 Apr 2002 22:58:25 +1200 (NZST)
Subject: [R] Background in lattice plots using dotplot()
Message-ID: <200204181058.g3IAwPV13421@biomat1.marc.hort.cri.nz>


platform i586-pc-linux-gnu
arch     i586             
os       linux-gnu        
system   i586, linux-gnu  
status                    
major    1                
minor    4.1              
year     2002             
month    01               
day      30               
language R   


I can't seem to get rid of the slightly green background when I use
dotplot().  It shows on the screen in the X11 device and when a
postscript file is viewed with the Gimp or GhostView.  Fortunately, it
is too faint to print on a Xerox colour printer.

However, if I attempt to make a monochrome bitmap file either using
bitmap(type = "pngmono") or converting a postscript file, it comes up
(and prints) as a very noticeable grey.  I've tried specifically
setting bg to "white" in every place I can think of, but without
success.

The problem doesn't appear when using bwplot() which I'd have thought
had a lot in common.

Has anyone experience with such a problem?


-- 
*************************************************************
   ___      Patrick Connolly
 {~._.~}    HortResearch             Great minds discuss ideas;
 _( Y )_    Mt Albert                Average minds discuss events; 
(:_~*~_:)   Auckland                 Small minds discuss people.
 (_)-(_)    New Zealand                                    .... Anon
            Ph: +64-9 815 4200 x 7188
*************************************************************


______________________________________________________
The contents of this e-mail are privileged and/or confidential to the
named recipient and are not to be used by any other person and/or
organisation. If you have received this e-mail in error, please notify 
the sender and delete all material pertaining to this e-mail.
______________________________________________________
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From zeileis at ci.tuwien.ac.at  Thu Apr 18 11:21:24 2002
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Thu, 18 Apr 2002 11:21:24 +0200
Subject: [R] Background in lattice plots using dotplot()
References: <200204181058.g3IAwPV13421@biomat1.marc.hort.cri.nz>
Message-ID: <3CBE9014.6F7E0025@ci.tuwien.ac.at>

Patrick Connolly wrote:
> 
> platform i586-pc-linux-gnu
> arch     i586
> os       linux-gnu
> system   i586, linux-gnu
> status
> major    1
> minor    4.1
> year     2002
> month    01
> day      30
> language R
> 
> I can't seem to get rid of the slightly green background when I use
> dotplot().  It shows on the screen in the X11 device and when a
> postscript file is viewed with the Gimp or GhostView.  Fortunately, it
> is too faint to print on a Xerox colour printer.
> 
> However, if I attempt to make a monochrome bitmap file either using
> bitmap(type = "pngmono") or converting a postscript file, it comes up
> (and prints) as a very noticeable grey.  I've tried specifically
> setting bg to "white" in every place I can think of, but without
> success.

Simply saying

R> trellis.device("x11", bg=0)

to open the trellis device doesn't work? That's at least, what I use to
get a white background. Then I usually change the colours and plotting
symbols with trellis.par.set().

Hope that helps
Z

> The problem doesn't appear when using bwplot() which I'd have thought
> had a lot in common.
> 
> Has anyone experience with such a problem?
> 
> --
> *************************************************************
>    ___      Patrick Connolly
>  {~._.~}    HortResearch             Great minds discuss ideas;
>  _( Y )_    Mt Albert                Average minds discuss events;
> (:_~*~_:)   Auckland                 Small minds discuss people.
>  (_)-(_)    New Zealand                                    .... Anon
>             Ph: +64-9 815 4200 x 7188
> *************************************************************
> 
> ______________________________________________________
> The contents of this e-mail are privileged and/or confidential to the
> named recipient and are not to be used by any other person and/or
> organisation. If you have received this e-mail in error, please notify
> the sender and delete all material pertaining to this e-mail.
> ______________________________________________________
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mark at myatt.demon.co.uk  Thu Apr 18 10:20:35 2002
From: mark at myatt.demon.co.uk (Mark Myatt)
Date: Thu, 18 Apr 2002 09:20:35 +0100
Subject: [R] Silly Question
In-Reply-To: <001901c1e687$6146d510$0100000a@stats>
References: <001901c1e687$6146d510$0100000a@stats>
Message-ID: <tEOj5BATHov8EwVg@myatt.demon.co.uk>

Ricardo Gon?alves <ricardo at icmc.sc.usp.br> writes:

>After I source an R code, how can I call the function?


I assume the your R code that you source contains function definitions.
If that is the case then call the functions as you would any other R
function.

Mark


--
Mark Myatt


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From siim at obs.ee  Thu Apr 18 11:46:08 2002
From: siim at obs.ee (Ott Toomet)
Date: Thu, 18 Apr 2002 11:46:08 +0200 (CEST)
Subject: [R] Silly Question
In-Reply-To: <001901c1e687$6146d510$0100000a@stats>
Message-ID: <Pine.LNX.4.44.0204181143310.2804-100000@localhost.localdomain>

Hi,

I am not quite sure, but as I understand you have a file (like "foo.R")
containing some commands like

cat("Hello world\n")
f2 <- function(x) x*x

when saying 

> source("foo.R")

you get message

Hello world

and you get also the function f defined.  So simply say 

> f(4)

to get 16.

Was it what you wanted?

Ott



On Thu, 18 Apr 2002, [iso-8859-1] Ricardo Gon?alves wrote:

  |After I source an R code, how can I call the function?
  |Thanks
  |Rick

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From P.Connolly at hortresearch.co.nz  Thu Apr 18 13:48:35 2002
From: P.Connolly at hortresearch.co.nz (Patrick Connolly)
Date: Thu, 18 Apr 2002 23:48:35 +1200 (NZST)
Subject: [R] Background in lattice plots using dotplot()
Message-ID: <200204181148.g3IBmZx13505@biomat1.marc.hort.cri.nz>

According to Achim Zeileis:


|> Simply saying
|> 
|> R> trellis.device("x11", bg=0)
|> 

Yes, that does work with a postscript trellis.device also.  It's one I
hadn't thought of.

It won't work for bitmap(), even using "white" instead of 0, but
perhaps that's understandable since bitmap isn't made for trellis
conventions.  

It's not a big deal to convert a postscript file into a bitmap using
the Gimp, so that will suit my purposes.

Thanks a lot.

-- 
*************************************************************
   ___      Patrick Connolly
 {~._.~}    HortResearch             Great minds discuss ideas;
 _( Y )_    Mt Albert                Average minds discuss events; 
(:_~*~_:)   Auckland                 Small minds discuss people.
 (_)-(_)    New Zealand                                    .... Anon
            Ph: +64-9 815 4200 x 7188
*************************************************************


______________________________________________________
The contents of this e-mail are privileged and/or confidential to the
named recipient and are not to be used by any other person and/or
organisation. If you have received this e-mail in error, please notify 
the sender and delete all material pertaining to this e-mail.
______________________________________________________
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From duncan at research.bell-labs.com  Thu Apr 18 12:49:53 2002
From: duncan at research.bell-labs.com (Duncan Temple Lang)
Date: Thu, 18 Apr 2002 06:49:53 -0400
Subject: [R] Problems embedding R in a C application
In-Reply-To: <Pine.GSO.4.44.0204180732300.28415-100000@auk.stats>; from ripley@stats.ox.ac.uk on Thu, Apr 18, 2002 at 07:42:31AM +0100
References: <F2018tP9DLf4bg5Xmll000058ef@hotmail.com> <Pine.GSO.4.44.0204180732300.28415-100000@auk.stats>
Message-ID: <20020418064953.A24233@jessie.research.bell-labs.com>

The embedding of R inside an application is slightly different for
Windows than Unix and it is not guaranteed to stay the same.  So it is
not part of the official R API. This is primarily because I have not
had time to add and _test_ the code to make things the same on both
systems.

If you want to do this under Windows you can take a look at the source
code for the SJava package. Within that you can take a look at the
file REmbed.c and specifically the call to winInit_R(). That is
defined in REmbedWin.c and essentially one replaces the call to
Rf_initEbeddedR() with a call to winInit_R() (currently with no
arguments).

Hopefully this still works with the current version of R (1.4).  It
should unless there have been changes to the way R under Windows is
initialized, but even if it has, the changes probably can be easily
adopted into REmbedWin.c.  I will try to find some time in the future
to provide a Rf_initEmbeddedR() for Windows.

The characteristics of the DCOM interface are different from the
embedding approachj, from what I understand.  The DCOM approach is
fixed however so won't change underneath you. 

 D.



Prof Brian D Ripley wrote:
> On Wed, 17 Apr 2002, Neil Osborne wrote:
> 
> > I've encountered two serious issues that have stopped me in my tracks, and I
> > would be most grateful to anyone who can provide some answers.
> >
> > I am using the examples provided on the page "Testing the Embeddable R
> > Library". I am writing a C application, that I want to embedd R into (I'm
> > not interested in embedding my application in R, that's not an option). I'm
> > developing on a Win2K box. The two problems I've hit (so far!) are these:
> 
> But embedding R in that sense is not supported on Windows, AFAIK.  What is
> supported is the DCOM interface on CRAN.
> 
> > Macro definition (R is using a macro already defined in one of the core
> > windows libraries)
> > Unresolved external - missing definition for func Rf_initEmbeddedR which is
> > prototyped as an extern in EmbeddedRCall.c
> >
> >
> > Here are the issues again (in more detail)
> > ===========================================================
> >
> > 1. Macro re-definition
> >
> > In file ..\include\R_ext\RS.h
> >
> > the line (37):
> >
> > #define ERROR			),error(R_problem_buf);}
> >
> >
> > causes this problem :
> >
> > warning C4005: 'ERROR' : macro redefinition
> >         d:\visualstudio\vc98\include\wingdi.h(93) : see previous definition
> > of 'ERROR'
> 
> Easy!  Just #undef ERROR after the include.  Or use a more selective set of
> headers.
> 
> > 2. Unresolved external:
> >
> > unresolved external symbol _Rf_initEmbeddedR
> >
> > This function is not defined anywhere. Does anyone know how I can init a
> > "session" of R in "embedded" mode (i.e. no direct writing to the console
> > etc) ?
> 
> It *is* defined in src/unix/system.c: note *unix*.
> 
> Answer to Q: use the DCOM interface.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From c.schulz at metafacts.de  Thu Apr 18 13:03:12 2002
From: c.schulz at metafacts.de (Christian Schulz)
Date: Thu, 18 Apr 2002 13:03:12 +0200
Subject: [R] Data.Frame Multiplication 
Message-ID: <3CBEA7F0.3020900@metafacts.de>

Have got  any  R-proffessional  a starting point for me
how i can write me a function which multiply every column with
every other column in the data.frame - indenpendent from the dim's .

Thanks in advance
regards,Christian



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From zeileis at ci.tuwien.ac.at  Thu Apr 18 13:14:00 2002
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Thu, 18 Apr 2002 13:14:00 +0200
Subject: [R] Data.Frame Multiplication
References: <3CBEA7F0.3020900@metafacts.de>
Message-ID: <3CBEAA78.22703647@ci.tuwien.ac.at>

Christian Schulz wrote:
> 
> Have got  any  R-proffessional  a starting point for me
> how i can write me a function which multiply every column with
> every other column in the data.frame - indenpendent from the dim's .

You could start from a function that multiplies a chosen column `col' of
a data.frame `df' with the following columns

  multiply <- function(df, col) df[,col] * df[,-(1:col), drop = FALSE]

and then apply that to your data.frame `mydata' like

  sapply(1:(ncol(mydata) - 1), function(x) multiply(mydata, x))

For the latter part, there might be a better way to do that depending on
how you want to format the output...
Z 

> Thanks in advance
> regards,Christian
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From josep.perarnau at upc.es  Thu Apr 18 14:00:44 2002
From: josep.perarnau at upc.es (Josep Perarnau i Codina)
Date: Thu, 18 Apr 2002 14:00:44 +0200
Subject: [R] using R with c++
Message-ID: <000301c1e6d0$ab9db4f0$2c185393@upc.es>

Hi,

I know that it is possible to use C++ functions under the R environment.
In any case my intention is the opposite way: use R functions like "glm"
or "lm" in my  C++ code. How should I deal with this problem?

Josep. 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pedro.aphalo at cc.jyu.fi  Thu Apr 18 14:07:18 2002
From: pedro.aphalo at cc.jyu.fi (Pedro J. Aphalo)
Date: Thu, 18 Apr 2002 15:07:18 +0300
Subject: [R] lattice
Message-ID: <3CBEB6F6.D3666DE8@cc.jyu.fi>

I cannot find the equivalent of cex.axis for lattice.

How does one change the size of the labels of the axis tick marks in
xyplot et al.?

Thanks in advance for any help.

Pedro.

p.s.: I looked in the FAQ and Trellis manual, but I diidn't find an
answer... so I hope I am not asking about something obvious.

I am using 
R 1.4.1 on windows 9X.
Lattice 0.4-0

-- 
==================================================================
Pedro J. Aphalo
Department of Biological and Environmental Science
University of Jyv?skyl?
P.O. Box 35, 40351 JYV?SKYL?, Finland
Phone  +358 14 260 2339
Mobile +358 50 3721504
Fax    +358 14 260 2321
mailto:pedro.aphalo at cc.jyu.fi
http://www.jyu.fi/~aphalo/                       ,,,^..^,,,
==================================================================
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rg117 at ohm.york.ac.uk  Thu Apr 18 14:07:03 2002
From: rg117 at ohm.york.ac.uk (Rishabh Gupta)
Date: Thu, 18 Apr 2002 13:07:03 +0100
Subject: [R] Classification Analysis
References: <2C23DE2983BE034CB1CB90DB6B813FD639E94B@uswpmx11.merck.com>
Message-ID: <000f01c1e6d1$8d4be840$35892090@ohm.york.ac.uk>

Excellent, this appears to be exactly what I need. Many Thanks!

Rishabh
----- Original Message -----
From: "Huntsinger, Reid" <reid_huntsinger at merck.com>
To: "Rishabh Gupta" <rg117 at ohm.york.ac.uk>
Cc: <r-help at stat.math.ethz.ch>
Sent: Wednesday, April 17, 2002 8:54 PM
Subject: RE: [R] Classification Analysis


> rpart will calculate the classification rule (represented as a tree) given
a
> grouped data set. predict.rpart will apply that rule to a single data
> element (or data set) for which groupings are not known. path.rpart will
> return the rules explicitly, if that's needed. Try the examples from
> help("rpart"), help("predict.rpart") and help("path.rpart") to see.
>
> Reid Huntsinger
>
> -----Original Message-----
> From: ozric at web.de [mailto:ozric at web.de]
> Sent: Wednesday, April 17, 2002 2:23 PM
> To: Rishabh Gupta
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Classification Analysis
>
>
> Rishabh,
> yes your "PseudoCode" idea is what i want in R,too.
> But even i mentioned , i didn't know of something like that in R/S-plus
and
> i have got open eyes for this.
>
> Perhaps anybody in the whole R community work on machineLearning-algorithm
> with rule generating,too ???
>
> So you must program a function for yourself (i.e. C4.5 or FS-ID3) !?
>
> (If you are interesting for papers (pdf) with algorithm let me know).
> regards,Christian
>
>
>
> Am 17.04.2002 15:13:47, schrieb "Rishabh Gupta" <rg117 at ohm.york.ac.uk>:
> >Thanks for your reply.
> >I am still learning these aspects of statistical analysis, so if I don't
> >make sense please forgive me.
> >All this work I am doing is part of a Phd and my deparment does not
really
> >neural network for situations like these because they say it acts like a
> >black box and we don't really know what is happening in the inside. So I
> >would like to concentrate on using pure statistical techniques. Ideally
> what
> >I would like is some kind of a function that calculates the
"classification
> >rule" when given a grouped data set :
> >    rule <- classification( GroupVar ~ DepVar1 + DepVar2 + DepVar3 +
> DepVar4
> >..... + ...... DepVarX )
> >
> >Then I would be able to use that rule and apply to a single data element
> for
> >which the group is not known:
> >
> >    theGroup <- rule( DataElement )
> >
> >I have looked at the rpart package in R but I am not entirely sure how to
> >use in a way that I can create the "classification rule" and then use
that
> >rule. I understand that it is a general problem but it's made more
> difficult
> >for me because I have to deal with 750 dependent variables.
> >
> >Your help is greatly appreciated.
> >
> >Many Thanks
> >
> >Rishabh
> >
> >----- Original Message -----
> >From: "Huntsinger, Reid" <reid_huntsinger at merck.com>
> >To: "'Rishabh Gupta'" <rg117 at ohm.york.ac.uk>; <r-help at stat.math.ethz.ch>
> >Sent: Tuesday, April 16, 2002 5:00 PM
> >Subject: RE: [R] Classification Analysis
> >
> >
> >> This is a very general problem and a very large area of
> >statistics/computer
> >> science/etc is concerned with it. R provides lots of possibilities; you
> >> might find tree-based approaches (recursive partitioning) to suit your
> >> needs; in that case, rpart and the new random forests package will be
of
> >> interest. Also see package e1071 and the VR packages for starters.
There
> >are
> >> lot of other possibilities; you might want to have a look at Ripley,
> >Pattern
> >> Recognition and Neural Networks, for example, to see some.
> >>
> >> Reid Huntsinger
> >>
> >> -----Original Message-----
> >> From: Rishabh Gupta [mailto:rg117 at ohm.york.ac.uk]
> >> Sent: Tuesday, April 16, 2002 11:14 AM
> >> To: r-help at stat.math.ethz.ch
> >> Subject: [R] Classification Analysis
> >>
> >>
> >> Hi everyone,
> >>     Could somebody explain to me what is the package/function for
> >> classification analysis. I am performing analysis of music files in the
> >form
> >> of MIDI files. I end up with about 750 dependent variables from the
> >> analysis, I also have a number of independent/grouping variables that I
> >set
> >> manually. What I would like is to be able to predict which group a
> >> particular MIDI files belongs to given the 750 dependent variables. In
> >order
> >> to this I have to perform classification analysis on a sample set of
MIDI
> >> files where I know what group they belong to. I want to extract the
> >> 'classification rule' that would enable me to predict the group of each
> >MIDI
> >> file (there would be a different classification rule for each grouping
> >> variable). Can anybody explain what is the best way of doing this in R.
> >What
> >> is the best package/function that would enable me to perform
> >classification
> >> analysis.
> >>
> >> Any help would be greatly appreciated.
> >>
> >> Many Thanks For Your Help!
> >>
> >> Rishabh
> >>
> >>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> >-.
> >> -.-
> >> r-help mailing list -- Read
> >http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> >> Send "info", "help", or "[un]subscribe"
> >> (in the "body", not the subject !)  To:
r-help-request at stat.math.ethz.ch
> >>
>
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> .
> >> _._
> >>
> >>
> >>
> --------------------------------------------------------------------------
> >----
> >> Notice:  This e-mail message, together with any attachments, contains
> >information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA)
that
> >may be confidential, proprietary copyrighted and/or legally privileged,
and
> >is intended solely for the use of the individual or entity named in this
> >message.  If you are not the intended recipient, and have received this
> >message in error, please immediately return this by e-mail and then
delete
> >it.
> >>
> >>
>
>===========================================================================
> =
> >==
> >>
> >>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.

> >-.-.-
> >> r-help mailing list -- Read
> >http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> >> Send "info", "help", or "[un]subscribe"
> >> (in the "body", not the subject !)  To:
r-help-request at stat.math.ethz.ch
> >>
>
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> .
> >_._
> >>
> >
>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> .-.-
> >r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> >Send "info", "help", or "[un]subscribe"
> >(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> ._._
> >
> ________________________________________________________________
> Keine verlorenen Lotto-Quittungen, keine vergessenen Gewinne mehr!
>
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.
> -.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._
>
>
> --------------------------------------------------------------------------
----
> Notice:  This e-mail message, together with any attachments, contains
information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that
may be confidential, proprietary copyrighted and/or legally privileged, and
is intended solely for the use of the individual or entity named in this
message.  If you are not the intended recipient, and have received this
message in error, please immediately return this by e-mail and then delete
it.
>
>
============================================================================
==
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
> r-help mailing list -- Read
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From alobo at ija.csic.es  Thu Apr 18 14:28:38 2002
From: alobo at ija.csic.es (Agustin Lobo)
Date: Thu, 18 Apr 2002 14:28:38 +0200 (MET DST)
Subject: [R] Silly Question
In-Reply-To: <tEOj5BATHov8EwVg@myatt.demon.co.uk>
Message-ID: <Pine.OSF.3.96.1020418141612.12347F-100000@ija.csic.es>

(I reply to Mark's reply as I went too fast
deleting the original message).

Ricardo,

Assuming your text file "saludos.R" has 2 R functions, i.e.

"hola" <- function()
{ 
	print ("HOLA")
}

"adios" <- function()
{ 
	print ("ADIOS")
}

if you do in R:
> source("/directory_info/saludos.R")

functions hola() and adios() will become
available in your def. environment
as you can check with ls(), and just
run as hola() and adios().

(I think the problem might be that source() is
used for two very different goals: run a demo
and "load" functions strored in ascii files.
The name "source" seems not intuitive for the
second purpose and often confuses beginers).


Agus

Dr. Agustin Lobo
Instituto de Ciencias de la Tierra (CSIC)
Lluis Sole Sabaris s/n
08028 Barcelona SPAIN
tel 34 93409 5410
fax 34 93411 0012
alobo at ija.csic.es


On Thu, 18 Apr 2002, Mark Myatt wrote:

> Ricardo Gonalves <ricardo at icmc.sc.usp.br> writes:
> 
> >After I source an R code, how can I call the function?
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Apr 18 14:36:44 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 18 Apr 2002 13:36:44 +0100 (BST)
Subject: [R] lattice
In-Reply-To: <3CBEB6F6.D3666DE8@cc.jyu.fi>
Message-ID: <Pine.LNX.4.31.0204181328390.5657-100000@gannet.stats>

On Thu, 18 Apr 2002, Pedro J. Aphalo wrote:

> I cannot find the equivalent of cex.axis for lattice.
>
> How does one change the size of the labels of the axis tick marks in
> xyplot et al.?
>
> Thanks in advance for any help.
>
> Pedro.
>
> p.s.: I looked in the FAQ and Trellis manual, but I diidn't find an
> answer... so I hope I am not asking about something obvious.

It's done via the Trellis argument `scales' in Trellis.  That seems to
work in lattice too:

xyplot(rnorm(10) ~ rnorm(10), scales=list(cex=2))

That is on the help page for xyplot in lattice (and ?trellis.args in
Trellis).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tklistaddr at keittlab.bio.sunysb.edu  Thu Apr 18 15:51:38 2002
From: tklistaddr at keittlab.bio.sunysb.edu (Timothy H. Keitt)
Date: 18 Apr 2002 09:51:38 -0400
Subject: [R] using R with c++
In-Reply-To: <000301c1e6d0$ab9db4f0$2c185393@upc.es>
References: <000301c1e6d0$ab9db4f0$2c185393@upc.es>
Message-ID: <1019137898.25922.11.camel@keittlab-6>

In either direction, you need to use C-style linking. Lookup the "extern
C" directive in a C++ language reference. In the R-extensions manual,
there is some example code for evaluating R expressions within C/C++.

Tim

On Thu, 2002-04-18 at 08:00, Josep Perarnau i Codina wrote:
> Hi,
> 
> I know that it is possible to use C++ functions under the R environment.
> In any case my intention is the opposite way: use R functions like "glm"
> or "lm" in my  C++ code. How should I deal with this problem?
> 
> Josep. 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From A.Nuzzo at motorola.com  Thu Apr 18 16:16:58 2002
From: A.Nuzzo at motorola.com (Nuzzo Art-CINT116)
Date: Thu, 18 Apr 2002 09:16:58 -0500
Subject: [R] Problem compiling on HP-UX 10.20
Message-ID: <CF5B20DBDE16D4119B9800D0B73E984806453A6A@il02exm25.comm.mot.com>

I am having a problem compiling R on an HP-UX 10.20 system using gcc/g77
compiler. It appears to compile without problems until it gets to the lapack
module and I get the following error:

gcc -I. -I../../../src/include -I../../../src/include -I/usr/local/include
-DHAVE_CONFIG_H -D_HPUX_SOURCE -fPIC  -O2 -c Lapack.c -o Lapack.lo
g77  -fPIC  -O2 -c double.f -o double.lo
g77  -fPIC  -O2 -c cmplx.f -o cmplx.lo
g77  -fPIC  -O2 -c blas2.f -o blas2.lo
g77  -fPIC  -O2 -c cmplxblas.f -o cmplxblas.lo
gcc -shared -fPIC  -o lapack.sl  Lapack.lo double.lo  cmplx.lo blas2.lo
cmplxblas.lo   -lg2c -lm -L/lib/pa1.1 -L/usr/lib/pa1.1 -u main
-L/opt/gnu/lib/gcc-lib/hppa2.0-hp-hpux10.20/3.0.4 -L/usr/ccs/bin
-L/usr/ccs/lib -L/opt/langtools/lib
-L/opt/gnu/lib/gcc-lib/hppa2.0-hp-hpux10.20/3.0.4/../../.. -lm
-L/usr/local/lib  -lz -ltermcap -lm
/usr/ccs/bin/ld: DP relative code in file
/opt/gnu/lib/gcc-lib/hppa2.0-hp-hpux10.20/3.0.4/libg2c.a(fmt.o) - shared
library must be position
    independent.  Use +z or +Z to recompile.
collect2: ld returned 1 exit status
make[4]: *** [lapack.sl] Error 1
make[4]: Leaving directory `/tmp_mnt/users/artn/R-1.4.1/src/modules/lapack'


Any help is appreciated, thanks,


Art Nuzzo


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From c.schulz at metafacts.de  Thu Apr 18 16:25:11 2002
From: c.schulz at metafacts.de (Christian Schulz)
Date: Thu, 18 Apr 2002 16:25:11 +0200
Subject: [R] Data.Frame Multiplication
References: <3CBEA7F0.3020900@metafacts.de> <3CBEAA78.22703647@ci.tuwien.ac.at>
Message-ID: <3CBED747.1020300@metafacts.de>

..many thanks !

Achim Zeileis wrote:

>Christian Schulz wrote:
>
>>Have got  any  R-proffessional  a starting point for me
>>how i can write me a function which multiply every column with
>>every other column in the data.frame - indenpendent from the dim's .
>>
>
>You could start from a function that multiplies a chosen column `col' of
>a data.frame `df' with the following columns
>
>  multiply <- function(df, col) df[,col] * df[,-(1:col), drop = FALSE]
>
>and then apply that to your data.frame `mydata' like
>
>  sapply(1:(ncol(mydata) - 1), function(x) multiply(mydata, x))
>
>For the latter part, there might be a better way to do that depending on
>how you want to format the output...
>Z 
>
>>Thanks in advance
>>regards,Christian
>>
>>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>>Send "info", "help", or "[un]subscribe"
>>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Mit freundlichen Gr??en


Christian Schulz
MetaFacts GmbH

Fon: +49 (0)30  69 51 71 - 0
Fax: +49 (0)30  69 51 71 - 33
mailto:c.schulz at metafacts.de
http://www.metafacts.de



-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20020418/75d86981/attachment.html

From ggrothendieck at yifan.net  Thu Apr 18 16:30:19 2002
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Thu, 18 Apr 2002 10:30:19 -0400
Subject: [R] Data.Frame Multiplication 
In-Reply-To: <3CBEA7F0.3020900@metafacts.de>
Message-ID: <3CBEA03B.14562.96063D@localhost>

The code below takes a matrix x and converts it to a matrix
whose columns are the pairwise columns of x.  If your data comes
in a data frame,df, you can always convert it to a matrix like this:
x <- as.matrix(df)

In the code below, 
zz is a matrix whose i,j-th element contains the product
of column i and column j.  Extract the upper triangular
portion of this matrix and reshape that into a matrix.  (You can
convert that to a data frame if you prefer.)

zz <- apply(outer(t(x),x),c(1,4),function(x)list(diag(x)))
matrix(unlist(zz[upper.tri(zz)]),nrow=nrow(x))

You might want to test this out a bit since the
construction is a bit tricky and I  have not extensively
tested it.

On 18 Apr 2002 at 13:03, Christian Schulz wrote:

> Have got  any  R-proffessional  a starting point for me
> how i can write me a function which multiply every column with
> every other column in the data.frame - indenpendent from the dim's .
> 
> Thanks in advance
> regards,Christian

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Thu Apr 18 16:44:04 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 18 Apr 2002 10:44:04 -0400
Subject: [R] trouble compiling R on Irix
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC223@usrymx10.merck.com>

Dear R-help,

I'm trying to compile R-1.4.1 on Irix, and run into the following error when
making R.bin:

The linker (ld32) complained that "gzeof", "gzgetc", "gztell", and "gzseek"
are unresolved symbols in connection.o.  Are these supposed to be in libz.a?
My suspicion is that maybe the libz.a on this system is outdated.  Any
hints?

TIA!

Andy


------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message. If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From iowahawk89 at yahoo.com  Thu Apr 18 17:14:09 2002
From: iowahawk89 at yahoo.com (Don Stierman)
Date: Thu, 18 Apr 2002 08:14:09 -0700 (PDT)
Subject: No subject
Message-ID: <20020418151409.72689.qmail@web12706.mail.yahoo.com>

I have created a tree and want to save some of the
data so that I can create a html table from it.
I would like to save the output from data.ltr (see
example below) to a file, but haven't found a way to
do that, keeping the nice format that typing data.ltr
gives me (see output below). Is there a way to do
this? 

Example:
library (maptree)
library (tree)
data<-read.csv("C:\\data.txt")
cnames<-colnames(data)
data$Vendor=as.factor(data$Vendor)
data$Yield=as.numeric(data$Yield)
data.ltr <- tree(Yield ~ ., data)

Output:
> data.ltr
node), split, n, deviance, yval
      * denotes terminal node

1) root 22 18.590 1.1360  
  2) X0100.WAFER.START.SCRIBE.PROD:
1TAGG3,1TAHK2,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
17  3.059 0.7647  
    4) e.F: 0,2,5 6  1.333 0.3333 *
    5) e.F: 1,3,4 11  0.000 1.0000 *
  3) X0100.WAFER.START.SCRIBE.PROD: 1TAHL7,NA,NA,NA 5 
5.200 2.4000 *
>


__________________________________________________
Do You Yahoo!?


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Thu Apr 18 17:24:17 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 18 Apr 2002 08:24:17 -0700 (PDT)
Subject: [R] Changing tick mark labels
In-Reply-To: <3CBE188D.A6B2AB96@botany.uq.edu.au>
Message-ID: <Pine.A41.4.44.0204180820230.156828-100000@homer03.u.washington.edu>

On Thu, 18 Apr 2002, Mark Harris wrote:

> Hello,
>
> Can anyone help me out with this problem?
> After performing logistic regressions and testing the significance with
> likelihood ratios, I have plotted the results using "termplot". I am
> wondering, how to get the names of my variables to appear on the x-axis
> rather than ascending numbers?
> I have used:
>

The following revised version of termplot() does this (not extensively
checked, but it works on a few examples). It's a two-line change but as
R1.5.0 is already frozen this won't get added until the next version.

	-thomas




"termplot" <-
function (model, data = model.frame(model), partial.resid = FALSE,
    rug = FALSE, terms = NULL, se = FALSE, xlabs = NULL, ylabs = NULL,
    main = NULL, col.term = 2, lwd.term = 1.5, col.se = "orange",
    lty.se = 2, lwd.se = 1, col.res = "gray", cex = 1, pch = par("pch"),
    ask = interactive() && nb.fig < n.tms && .Device != "postscript",
    ...)
{
    terms <- if (is.null(terms))
        predict(model, type = "terms", se = se)
    else predict(model, type = "terms", se = se, terms = terms)
    n.tms <- ncol(tms <- as.matrix(if (se)
        terms$fit
    else terms))
    mf <- model.frame(model)
    nmt <- colnames(tms)
    cn <- parse(text = nmt)
    if (is.null(ylabs))
        ylabs <- paste("Partial for", nmt)
    if (is.null(main))
        main <- ""
    else if (is.logical(main))
        main <- if (main)
            deparse(model$call)
        else ""
    else if (!is.character(main))
        stop("`main' must be TRUE, FALSE, NULL or character (vector).")
    main <- rep(main, length = n.tms)
    pf <- parent.frame()
    carrier <- function(term) {
        if (length(term) > 1)
            carrier(term[[2]])
        else eval(term, data, enclos = pf)
    }
    carrier.name <- function(term) {
        if (length(term) > 1)
            carrier.name(term[[2]])
        else as.character(term)
    }
    if (is.null(xlabs))
        xlabs <- unlist(lapply(cn, carrier.name))
    if (partial.resid)
        pres <- residuals(model, "partial")
    is.fac <- sapply(nmt, function(i) is.factor(mf[, i]))
    se.lines <- function(x, iy, i, ff = 2) {
        tt <- ff * terms$se.fit[iy, i]
        lines(x, tms[iy, i] + tt, lty = lty.se, lwd = lwd.se,
            col = col.se)
        lines(x, tms[iy, i] - tt, lty = lty.se, lwd = lwd.se,
            col = col.se)
    }
    nb.fig <- prod(par("mfcol"))
    if (ask) {
        op <- par(ask = TRUE)
        on.exit(par(op))
    }
    for (i in 1:n.tms) {
        ylims <- range(tms[, i], na.rm = TRUE)
        if (se)
            ylims <- range(ylims, tms[, i] + 1.05 * 2 * terms$se.fit[,
                i], tms[, i] - 1.05 * 2 * terms$se.fit[, i],
                na.rm = TRUE)
        if (partial.resid)
            ylims <- range(ylims, pres[, i], na.rm = TRUE)
        if (rug)
            ylims[1] <- ylims[1] - 0.07 * diff(ylims)
        if (is.fac[i]) {
            ff <- mf[, nmt[i]]
            ll <- levels(ff)
            xlims <- range(seq(along = ll)) + c(-0.5, 0.5)
            xx <- codes(ff)
            if (rug) {
                xlims[1] <- xlims[1] - 0.07 * diff(xlims)
                xlims[2] <- xlims[2] + 0.03 * diff(xlims)
            }
	## use factor levels, not numbers, on x-axis
            plot(1, 0, type = "n", xlab = xlabs[i], ylab = ylabs[i],
                xlim = xlims, ylim = ylims, main = main[i], xaxt="n",...)
	    axis(1,1:length(ll),ll)
            for (j in seq(along = ll)) {
                ww <- which(ff == ll[j])[c(1, 1)]
                jf <- j + c(-0.4, 0.4)
                lines(jf, tms[ww, i], col = col.term, lwd = lwd.term,
                  ...)
                if (se)
                  se.lines(jf, iy = ww, i = i)
            }
        }
        else {
            xx <- carrier(cn[[i]])
            xlims <- range(xx, na.rm = TRUE)
            if (rug)
                xlims[1] <- xlims[1] - 0.07 * diff(xlims)
            oo <- order(xx)
            plot(xx[oo], tms[oo, i], type = "l", xlab = xlabs[i],
                ylab = ylabs[i], xlim = xlims, ylim = ylims,
                main = main[i], col = col.term, lwd = lwd.term,
                ...)
            if (se)
                se.lines(xx[oo], iy = oo, i = i)
        }
        if (partial.resid)
            points(xx, pres[, i], cex = cex, pch = pch, col = col.res)
        if (rug) {
            n <- length(xx)
            lines(rep(jitter(xx), rep(3, n)), rep(ylims[1] +
                c(0, 0.05,   NA) * diff(ylims), n))
            if (partial.resid)
                lines(rep(xlims[1] + c(0, 0.05,   NA) * diff(xlims),
                  n), rep(pres[, i], rep(3, n)))
        }
    }
    invisible(n.tms)
}

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Thu Apr 18 17:29:53 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 18 Apr 2002 08:29:53 -0700 (PDT)
Subject: [R] using R with c++
In-Reply-To: <000301c1e6d0$ab9db4f0$2c185393@upc.es>
Message-ID: <Pine.A41.4.44.0204180826380.156828-100000@homer03.u.washington.edu>

On Thu, 18 Apr 2002, Josep Perarnau i Codina wrote:

> Hi,
>
> I know that it is possible to use C++ functions under the R environment.
> In any case my intention is the opposite way: use R functions like "glm"
> or "lm" in my  C++ code. How should I deal with this problem?
>

There's more than one way, and it depends on your application and your
operating system which is best.

* You could write an R program that calls the C++ program, which then
calls back to R as needed.

* Under Windows you could use the DCOM interface

* Under Unix you could use the embedded R library


	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Apr 18 17:33:14 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 18 Apr 2002 16:33:14 +0100 (BST)
Subject: [R] trouble compiling R on Irix
In-Reply-To: <51F9C42DA15CD311BD220008C707D81906FFC223@usrymx10.merck.com>
Message-ID: <Pine.LNX.4.31.0204181625390.17263-100000@gannet.stats>

On Thu, 18 Apr 2002, Liaw, Andy wrote:

> Dear R-help,
>
> I'm trying to compile R-1.4.1 on Irix, and run into the following error when
> making R.bin:
>
> The linker (ld32) complained that "gzeof", "gzgetc", "gztell", and "gzseek"
> are unresolved symbols in connection.o.  Are these supposed to be in libz.a?

Yes (or libz.so).

> My suspicion is that maybe the libz.a on this system is outdated.  Any
> hints?

Seems pretty unlikely.  We test for >= 1.1.3, and that dates from 1998 and
does contain those symbols.  It seems more likely that the library is
corrupt.

It is highly recommended to use zlib 1.1.4 for security reasons, so
I suggest replacing libz.a with that version.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Apr 18 17:34:05 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 18 Apr 2002 16:34:05 +0100 (BST)
Subject: [R] Re: your mail
In-Reply-To: <20020418151409.72689.qmail@web12706.mail.yahoo.com>
Message-ID: <Pine.LNX.4.31.0204181633560.17263-100000@gannet.stats>

On Thu, 18 Apr 2002, Don Stierman wrote:

> I have created a tree and want to save some of the
> data so that I can create a html table from it.
> I would like to save the output from data.ltr (see
> example below) to a file, but haven't found a way to
> do that, keeping the nice format that typing data.ltr
> gives me (see output below). Is there a way to do
> this?

?sink.

>
> Example:
> library (maptree)
> library (tree)
> data<-read.csv("C:\\data.txt")
> cnames<-colnames(data)
> data$Vendor=as.factor(data$Vendor)
> data$Yield=as.numeric(data$Yield)
> data.ltr <- tree(Yield ~ ., data)
>
> Output:
> > data.ltr
> node), split, n, deviance, yval
>       * denotes terminal node
>
> 1) root 22 18.590 1.1360
>   2) X0100.WAFER.START.SCRIBE.PROD:
> 1TAGG3,1TAHK2,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
> 17  3.059 0.7647
>     4) e.F: 0,2,5 6  1.333 0.3333 *
>     5) e.F: 1,3,4 11  0.000 1.0000 *
>   3) X0100.WAFER.START.SCRIBE.PROD: 1TAHL7,NA,NA,NA 5
> 5.200 2.4000 *
> >
>
>
> __________________________________________________
> Do You Yahoo!?
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Thu Apr 18 17:34:23 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 18 Apr 2002 08:34:23 -0700 (PDT)
Subject: [R] Re: your mail
In-Reply-To: <20020418151409.72689.qmail@web12706.mail.yahoo.com>
Message-ID: <Pine.A41.4.44.0204180833200.156828-100000@homer03.u.washington.edu>

On Thu, 18 Apr 2002, Don Stierman wrote:

> I have created a tree and want to save some of the
> data so that I can create a html table from it.
> I would like to save the output from data.ltr (see
> example below) to a file, but haven't found a way to
> do that, keeping the nice format that typing data.ltr
> gives me (see output below). Is there a way to do
> this?

Look at sink()
  sink("filename")
sends output to that file, and you can also send the output to a character
vector by sink()ing to a textConnection()

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From White.Denis at epamail.epa.gov  Thu Apr 18 18:01:33 2002
From: White.Denis at epamail.epa.gov (White.Denis@epamail.epa.gov)
Date: Thu, 18 Apr 2002 09:01:33 -0700
Subject: [R] Re: printing tree results
Message-ID: <OF7D60FA84.706FF70C-ON88256B9F.0057BD18@rtp.epa.gov>


Look at help(sink).  I have figured out how to fix up draw.tree to do
factor labels correctly and will be doing that in the next few days.
Meanwhile I discovered that rpart() provides factor labels in a much
more satisfactory way than tree() does.  Because of this and because of
the additional information rpart provides about the tree building, I
recommend you switch to that.

> I have created a tree and want to save some of the
> data so that I can create a html table from it.
> I would like to save the output from data.ltr (see
> example below) to a file, but haven't found a way to
> do that, keeping the nice format that typing data.ltr
> gives me (see output below). Is there a way to do
> this?
>
> Example:
> library (maptree)
> library (tree)
> data<-read.csv("C:\\data.txt")
> cnames<-colnames(data)
> data$Vendor=as.factor(data$Vendor)
> data$Yield=as.numeric(data$Yield)
> data.ltr <- tree(Yield ~ ., data)
>
> Output:
> > data.ltr
> node), split, n, deviance, yval
>       * denotes terminal node
>
> 1) root 22 18.590 1.1360
>   2) X0100.WAFER.START.SCRIBE.PROD:
> 1TAGG3,1TAHK2,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
> 17  3.059 0.7647
>     4) e.F: 0,2,5 6  1.333 0.3333 *
>     5) e.F: 1,3,4 11  0.000 1.0000 *
>   3) X0100.WAFER.START.SCRIBE.PROD: 1TAHL7,NA,NA,NA 5
> 5.200 2.4000 *
> >

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From White.Denis at epamail.epa.gov  Thu Apr 18 18:01:33 2002
From: White.Denis at epamail.epa.gov (White.Denis@epamail.epa.gov)
Date: Thu, 18 Apr 2002 09:01:33 -0700
Subject: [R] Re: printing tree results
Message-ID: <OF7D60FA84.706FF70C-ON88256B9F.0057BD18@rtp.epa.gov>


Look at help(sink).  I have figured out how to fix up draw.tree to do
factor labels correctly and will be doing that in the next few days.
Meanwhile I discovered that rpart() provides factor labels in a much
more satisfactory way than tree() does.  Because of this and because of
the additional information rpart provides about the tree building, I
recommend you switch to that.

> I have created a tree and want to save some of the
> data so that I can create a html table from it.
> I would like to save the output from data.ltr (see
> example below) to a file, but haven't found a way to
> do that, keeping the nice format that typing data.ltr
> gives me (see output below). Is there a way to do
> this?
>
> Example:
> library (maptree)
> library (tree)
> data<-read.csv("C:\\data.txt")
> cnames<-colnames(data)
> data$Vendor=as.factor(data$Vendor)
> data$Yield=as.numeric(data$Yield)
> data.ltr <- tree(Yield ~ ., data)
>
> Output:
> > data.ltr
> node), split, n, deviance, yval
>       * denotes terminal node
>
> 1) root 22 18.590 1.1360
>   2) X0100.WAFER.START.SCRIBE.PROD:
> 1TAGG3,1TAHK2,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
> 17  3.059 0.7647
>     4) e.F: 0,2,5 6  1.333 0.3333 *
>     5) e.F: 1,3,4 11  0.000 1.0000 *
>   3) X0100.WAFER.START.SCRIBE.PROD: 1TAHL7,NA,NA,NA 5
> 5.200 2.4000 *
> >

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From luke at stat.umn.edu  Thu Apr 18 18:17:08 2002
From: luke at stat.umn.edu (Luke Tierney)
Date: Thu, 18 Apr 2002 11:17:08 -0500
Subject: [R] trouble compiling R on Irix
In-Reply-To: <Pine.LNX.4.31.0204181625390.17263-100000@gannet.stats>; from ripley@stats.ox.ac.uk on Thu, Apr 18, 2002 at 04:33:14PM +0100
References: <51F9C42DA15CD311BD220008C707D81906FFC223@usrymx10.merck.com> <Pine.LNX.4.31.0204181625390.17263-100000@gannet.stats>
Message-ID: <20020418111708.A23674@nokomis.stat.umn.edu>

I seem to recall that on some IRIX systems there is occasionally
another library called libz that has nothing to do with the one we
want.  Maybe this is confusing things?

luke

On Thu, Apr 18, 2002 at 04:33:14PM +0100, ripley at stats.ox.ac.uk wrote:
> On Thu, 18 Apr 2002, Liaw, Andy wrote:
> 
> > Dear R-help,
> >
> > I'm trying to compile R-1.4.1 on Irix, and run into the following error when
> > making R.bin:
> >
> > The linker (ld32) complained that "gzeof", "gzgetc", "gztell", and "gzseek"
> > are unresolved symbols in connection.o.  Are these supposed to be in libz.a?
> 
> Yes (or libz.so).
> 
> > My suspicion is that maybe the libz.a on this system is outdated.  Any
> > hints?
> 
> Seems pretty unlikely.  We test for >= 1.1.3, and that dates from 1998 and
> does contain those symbols.  It seems more likely that the library is
> corrupt.
> 
> It is highly recommended to use zlib 1.1.4 for security reasons, so
> I suggest replacing libz.a with that version.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
Luke Tierney
University of Minnesota                      Phone:           612-625-7843
School of Statistics                         Fax:             612-624-8868
313 Ford Hall, 224 Church St. S.E.           email:      luke at stat.umn.edu
Minneapolis, MN 55455 USA                    WWW:  http://www.stat.umn.edu
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jgreenb2 at ford.com  Thu Apr 18 18:06:58 2002
From: jgreenb2 at ford.com (Greenberg, Jeff (J.A.))
Date: Thu, 18 Apr 2002 12:06:58 -0400
Subject: [R] Help with lme basics
Message-ID: <200204181626.g3IGQ1t10440@dymwsm10.mailwatch.com>

In Baron and Li's "Notes on the use of R for psychology experiments and questionnaires" http://cran.r-project.org/doc/contrib/rpsych.htm they describe a balanced data set for a drug experiment:

"... a test of drug treatment effect by one between-subject factor: group (two groups of 8 subjects each) and two within-subject factors: drug (2 levels) and dose (3 levels). "

This design is identical to an unbalanced one that I am interested in analyzing in R. I have both missing cells and unequal number of observations per cell. This is a repeated-measures design with test subject as a random factor.

Baron and Li show how to analyze this design using aov:

summary(aov(effect ~ gp * drug * dose + Error(subj/(dose+drug)), data=Ela.uni))

When I analyze my design I get additional terms in each error stratum because of the missing cells. The results appear sensible, but I've been told that lme is a better way to model this data. 

My question is: how do I set up an equivalent model using lme? Using the balanced data set in Baron and Li I've tried this model:

ela.lme<-lme(effect~gp*dose*drug,random=~1|subj/drug/dose)

But this does not produce a sensible (to me!) anova table. I don't think I understand the method lme uses to specify nesting. 

Thanks in advance.

--------------------------------------------------------------------
Jeff Greenberg        Ford Research Laboratory     Dearborn, MI
jgreenb2 at ford.com     Phone: (313) 323-8273        Fax: (313) 248-4602


 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From klavan at tiscalinet.it  Thu Apr 18 18:42:59 2002
From: klavan at tiscalinet.it (Ambrosini Alessandro)
Date: Thu, 18 Apr 2002 18:42:59 +0200
Subject: [R] Two problems
Message-ID: <PPEGLLABFLFCJDLCGPGHEEHLCAAA.klavan@tiscalinet.it>

Hello! Two questions:

1: I have to import a matrix of adjacency from a file of a software that is
not R (for example "bloc notes" of Windows). The problem is that the matrix
is not in the explicit form as
 0 1 1
 1 0 0
 1 0 0
but it is a scattered matrix where in each row there are two nodes that have
a direct path.
The matrix is

 a   b
 a   c
 b   a
 c   a

For example, the first row exspress that node a and node b are connected by
a direct line.
Can R transform this matrix in the first matrix that I wrote ? Are there any
struments?

2: Which is the max dimension of a matrix that R can use (1000X1000?,
500000X500000?)? What is the biggest dimension of a file that R can import?

Thank you so much.
Alessandro


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Apr 18 19:12:22 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 18 Apr 2002 19:12:22 +0200
Subject: [R] Two problems
In-Reply-To: <PPEGLLABFLFCJDLCGPGHEEHLCAAA.klavan@tiscalinet.it>
References: <PPEGLLABFLFCJDLCGPGHEEHLCAAA.klavan@tiscalinet.it>
Message-ID: <x2n0w1szgp.fsf@blueberry.kubism.ku.dk>

"Ambrosini Alessandro" <klavan at tiscalinet.it> writes:

> Hello! Two questions:
> 
> 1: I have to import a matrix of adjacency from a file of a software that is
> not R (for example "bloc notes" of Windows). The problem is that the matrix
> is not in the explicit form as
>  0 1 1
>  1 0 0
>  1 0 0
> but it is a scattered matrix where in each row there are two nodes that have
> a direct path.
> The matrix is
> 
>  a   b
>  a   c
>  b   a
>  c   a
> 
> For example, the first row exspress that node a and node b are connected by
> a direct line.
> Can R transform this matrix in the first matrix that I wrote ? Are there any
> struments?

Use matrix indexing:

i <- matrix(c(1,2,
              1,3,
              2,1,
              3,1),ncol=2,byrow=T)

m <- matrix(0,3,3)
m[i] <- 1
m


> 2: Which is the max dimension of a matrix that R can use (1000X1000?,
> 500000X500000?)? What is the biggest dimension of a file that R can import?

It has to fit in available memory. On a 32 bit machine, you can only
address 4GB (and only if the OS allows), so in principle the workspace
holds 500 million double cells which would allow a 20000x20000 matrix.
However, you generally need to have room for several copies, so 5k x
5k sounds more realistic. I forget what current status is on 64-bit
architectures.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ychen at dogwood.botany.uga.edu  Thu Apr 18 20:46:29 2002
From: ychen at dogwood.botany.uga.edu (Yu-Yun Chen)
Date: Thu, 18 Apr 2002 13:46:29 -0500
Subject: [R] About duplicates
Message-ID: <20020418.AAA1019151762@botany.uga.edu>

Dear Sir:

I am learning R and found it interesting and useful. However, I have a problem here. If I got duplicates in my dataframe, how can I get rid of those rows? I couldn't find a suitable function for that. In SAS, the internal code will help. How about R? Thanks for your attention.

Sincerely,

Yu-Yun Chen




-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20020418/d84977a5/attachment.html

From pem at theriver.com  Thu Apr 18 19:49:32 2002
From: pem at theriver.com (Patrick McKnight)
Date: Thu, 18 Apr 2002 10:49:32 -0700 (MST)
Subject: [R] placing objects with format statements into text file
In-Reply-To: <15550.27805.294314.860269@gargle.gargle.HOWL>
Message-ID: <Pine.LNX.4.44.0204181011540.2409-100000@galileo2.mcknightconsulting.com>

Martin,

Thanks for your help.  It worked flawlessly!  The lapply(d1,format) was
the part that I was missing.  Thanks again.

Cheers,

Patrick


On Thu, 18 Apr 2002, Martin Maechler wrote:

> >>>>> "Patrick" == Patrick McKnight <pem at theriver.com> writes:
> 
>     Patrick> Greetings, Is there a way to explicitly state the
>     Patrick> format statement for each object in a write
>     Patrick> statement?  For example, I have data frame with
>     Patrick> four variables (SSN that is 11 characters, and
>     Patrick> three other variables with values ranging between 0
>     Patrick> and 10).  I would like to have a text file written
>     Patrick> that preserves a specific formatting.
>     Patrick> Specifically, I would like the following result:
> 
>     Patrick> 129-02-1102 1 3 4 5
>     Patrick> 123-45-345610 9 810
> 
>     Patrick> etc.
> 
>     Patrick> As you can see, the SSN takes up only 11 columns
>     Patrick> and the other four variables are formated with no
>     Patrick> seperator but are "put" there with the format
>     Patrick> statement of f2.0.  So, is there a way to
>     Patrick> accomplish this in R?  If so, I would be extremely
>     Patrick> greatful for direction.
> 
> Here is an example (providing these explicitly in such questions
> 		   makes the question often easier to understand)
> 
> d1 <- data.frame(ssn = c("123-345-789","987-654-3"), id = 1:2, age=c(20,60))
> > d1
>           ssn id age
> 1 123-345-789  1  20
> 2   987-654-3  2  60
> 
> Now the idea is to use
> -  write.table with  sep=""
> -  format each column - coercing to character (of same width) :
> 
> > write.table(lapply(d1,format), quote=FALSE,row.names=FALSE,col.names=FALSE,sep="")
> 
> 123-345-789120
> 987-654-3  260
> 
> ----
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Apr 18 19:56:51 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 18 Apr 2002 18:56:51 +0100 (GMT Daylight Time)
Subject: [R] About duplicates
In-Reply-To: <20020418.AAA1019151762@botany.uga.edu>
Message-ID: <Pine.WNT.4.44.0204181855100.484-100000@tern.stats>

On Thu, 18 Apr 2002, Yu-Yun Chen wrote:

> I am learning R and found it interesting and useful. However, I have
a problem here. If I got duplicates in my dataframe, how can I get rid of
those rows? I couldn't find a suitable function for that. In SAS,
the internal code will help. How about R? Thanks for your attention.

?dupicated and ?unique should help.  They do have methods for data frames
(in the current version of R).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Thu Apr 18 20:33:31 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 18 Apr 2002 14:33:31 -0400
Subject: trouble with tcltk (was RE: [R] trouble compiling R on Irix)
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC22C@usrymx10.merck.com>

Hi,

Thanks to Profs. Ripley and Tierney for their tips, I compiled zlib from
source and gotten further.

Here's where I get stuck, when it tries to compile the tcltk package:

ld32: FATAL   12 : Expecting n32 objects: /usr/local/lib/libtcl8.3.so is
n64.

Now I'm confused.  Sounds like 32-bit vs. 64-bit problem.  What can I do at
this point?

(This is on Irix.)

Regards,
Andy

------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message. If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From richmond at saintmarys.edu  Thu Apr 18 21:11:39 2002
From: richmond at saintmarys.edu (David A Richmond)
Date: Thu, 18 Apr 2002 14:11:39 -0500 (EST)
Subject: [R] Two problems
In-Reply-To: <PPEGLLABFLFCJDLCGPGHEEHLCAAA.klavan@tiscalinet.it>
Message-ID: <Pine.GSO.4.43.0204181355250.11887-100000@jade.saintmarys.edu>

question 1:
Try this:
> list <- cbind(c(1,1,2,3),c(2,3,1,1))
> list
     [,1] [,2]
[1,]    1    2
[2,]    1    3
[3,]    2    1
[4,]    3    1
> mat <- matrix(0,max(list),max(list))
> mat[list] <- 1
> mat
     [,1] [,2] [,3]
[1,]    0    1    1
[2,]    1    0    0
[3,]    1    0    0

Now you just need to figure out how to get R to read an ascii file, and
convert the a's and b's to 1's and 2's etc. (I don't know how to do this
off the top of my head, but you might look at "read" and look for some
kind of recoding function)

question2:
I believe the dimension size limited only by available memory.

dave r.


On Thu, 18 Apr 2002, Ambrosini Alessandro wrote:

> Hello! Two questions:
>
> 1: I have to import a matrix of adjacency from a file of a software that is
> not R (for example "bloc notes" of Windows). The problem is that the matrix
> is not in the explicit form as
>  0 1 1
>  1 0 0
>  1 0 0
> but it is a scattered matrix where in each row there are two nodes that have
> a direct path.
> The matrix is
>
>  a   b
>  a   c
>  b   a
>  c   a
>
> For example, the first row exspress that node a and node b are connected by
> a direct line.
> Can R transform this matrix in the first matrix that I wrote ? Are there any
> struments?
>
> 2: Which is the max dimension of a matrix that R can use (1000X1000?,
> 500000X500000?)? What is the biggest dimension of a file that R can import?
>
> Thank you so much.
> Alessandro

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From richmond at saintmarys.edu  Thu Apr 18 21:36:13 2002
From: richmond at saintmarys.edu (David A Richmond)
Date: Thu, 18 Apr 2002 14:36:13 -0500 (EST)
Subject: [R] Two problems
In-Reply-To: <PPEGLLABFLFCJDLCGPGHEEHLCAAA.klavan@tiscalinet.it>
Message-ID: <Pine.GSO.4.43.0204181425120.13161-100000@jade.saintmarys.edu>

On Thu, 18 Apr 2002, Ambrosini Alessandro wrote:

> Hello! Two questions:
>
> 1: I have to import a matrix of adjacency from a file of a software that is
> not R (for example "bloc notes" of Windows). The problem is that the matrix
> is not in the explicit form as
>  0 1 1
>  1 0 0
>  1 0 0
> but it is a scattered matrix where in each row there are two nodes that have
> a direct path.
> The matrix is
>
>  a   b
>  a   c
>  b   a
>  c   a
>

after doing a little research, I have discovered "charmatch" which will
give the indices of the matches between two sets of strings. For instance:

> list1 <- c("a","b","c","d")
> list2 <- c("d","d","b")
> charmatch(list2,list1)
[1] 4 4 2

Using this you can convert a list of letters to a list of numbers. For
instance:

> rowlist <- c("a","a","b","c")
> collist <- c("b","c","a","a")
> uniquelist <- sort(unique(c(rowlist,collist)))
> uniquelist
[1] "a" "b" "c"
> rownums <- charmatch(rowlist,uniquelist)
> colnums <- charmatch(collist,uniquelist)
> list <- cbind(rownums,colnums)
> list
     rownums colnums
[1,]       1       2
[2,]       1       3
[3,]       2       1
[4,]       3       1
> n <- length(uniquelist)
> mat <- matrix(0,n,n)
> mat[list] <- 1
> mat
     [,1] [,2] [,3]
[1,]    0    1    1
[2,]    1    0    0
[3,]    1    0    0


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From haun_jung at yahoo.com  Thu Apr 18 22:05:53 2002
From: haun_jung at yahoo.com (Haun Jung)
Date: Thu, 18 Apr 2002 13:05:53 -0700 (PDT)
Subject: [R] naming boxes in boxplot
Message-ID: <20020418200553.44366.qmail@web11906.mail.yahoo.com>

Hi, this may be a too simple question, but I was not
able to find how to do it. 

So when I boxplot two vectors, i.e. 
x<-rbind(1,2,3,4)
y<-rbind(3,4,5,6)
boxplot(x,y)

, could somebody tell me how to name the two boxes as
apple and banana?

Thanks much,
Haun

__________________________________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From zeileis at ci.tuwien.ac.at  Thu Apr 18 22:14:45 2002
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Thu, 18 Apr 2002 22:14:45 +0200
Subject: [R] naming boxes in boxplot
References: <20020418200553.44366.qmail@web11906.mail.yahoo.com>
Message-ID: <3CBF2935.C28FF261@ci.tuwien.ac.at>

Haun Jung wrote:
> 
> Hi, this may be a too simple question, but I was not
> able to find how to do it.

Well, it's not so hard

R> help(boxplot)

tells you about the argument
   names: group labels which will be printed under each boxplot.

Set that to apple and banana...
Z

> So when I boxplot two vectors, i.e.
> x<-rbind(1,2,3,4)
> y<-rbind(3,4,5,6)
> boxplot(x,y)
>
> , could somebody tell me how to name the two boxes as
> apple and banana?
> 
> Thanks much,
> Haun
> 
> __________________________________________________
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Apr 18 22:19:10 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 18 Apr 2002 22:19:10 +0200
Subject: trouble with tcltk (was RE: [R] trouble compiling R on Irix)
In-Reply-To: <51F9C42DA15CD311BD220008C707D81906FFC22C@usrymx10.merck.com>
References: <51F9C42DA15CD311BD220008C707D81906FFC22C@usrymx10.merck.com>
Message-ID: <x2y9fkg3pd.fsf@blueberry.kubism.ku.dk>

"Liaw, Andy" <andy_liaw at merck.com> writes:

> Hi,
> 
> Thanks to Profs. Ripley and Tierney for their tips, I compiled zlib from
> source and gotten further.
> 
> Here's where I get stuck, when it tries to compile the tcltk package:
> 
> ld32: FATAL   12 : Expecting n32 objects: /usr/local/lib/libtcl8.3.so is
> n64.
> 
> Now I'm confused.  Sounds like 32-bit vs. 64-bit problem.  What can I do at
> this point?
> 
> (This is on Irix.)

Well, there seems to be three options:

1) Build without tcltk (configure --without-tcltk)

2) get a 32-bit tcltk

3) compile everything else for 64 bits

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Apr 18 22:22:24 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 18 Apr 2002 22:22:24 +0200
Subject: [R] naming boxes in boxplot
In-Reply-To: <20020418200553.44366.qmail@web11906.mail.yahoo.com>
References: <20020418200553.44366.qmail@web11906.mail.yahoo.com>
Message-ID: <x2u1q8g3jz.fsf@blueberry.kubism.ku.dk>

Haun Jung <haun_jung at yahoo.com> writes:

> Hi, this may be a too simple question, but I was not
> able to find how to do it. 
> 
> So when I boxplot two vectors, i.e. 
> x<-rbind(1,2,3,4)
> y<-rbind(3,4,5,6)
> boxplot(x,y)
> 
> , could somebody tell me how to name the two boxes as
> apple and banana?

The easiest would seem to be

boxplot(list(apple=x,banana=y))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From richmond at saintmarys.edu  Thu Apr 18 22:49:45 2002
From: richmond at saintmarys.edu (David A Richmond)
Date: Thu, 18 Apr 2002 15:49:45 -0500 (EST)
Subject: [R] Two problems
In-Reply-To: <PPEGLLABFLFCJDLCGPGHEEHLCAAA.klavan@tiscalinet.it>
Message-ID: <Pine.GSO.4.43.0204181544510.13161-100000@jade.saintmarys.edu>

On Thu, 18 Apr 2002, Ambrosini Alessandro wrote:

> Hello! Two questions:
>
> 1: I have to import a matrix of adjacency from a file of a software that is
> not R (for example "bloc notes" of Windows). The problem is that the matrix
> is not in the explicit form as
>  0 1 1
>  1 0 0
>  1 0 0
> but it is a scattered matrix where in each row there are two nodes that have
> a direct path.
> The matrix is
>
>  a   b
>  a   c
>  b   a
>  c   a

one more thing: here's how to read from a text file into a matrix of
strings so that you can use my charmatching solution:

> lines <- readLines("textfile.txt")
> lines
[1] "a b" "a c" "b a" "c a"
> chars <- c(strsplit(lines," "),recursive=TRUE)
> chars
[1] "a" "b" "a" "c" "b" "a" "c" "a"
> chars <- t(matrix(chars,2,length(chars)/2))
> chars
     [,1] [,2]
[1,] "a"  "b"
[2,] "a"  "c"
[3,] "b"  "a"
[4,] "c"  "a"
>

dave r.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From THotchi at lbl.gov  Fri Apr 19 00:48:22 2002
From: THotchi at lbl.gov (T. Hotchi)
Date: Thu, 18 Apr 2002 15:48:22 -0700
Subject: [R] Variable definition problem
Message-ID: <3CBF4D36.3020306@lbl.gov>

Hello, what does this error message indicate and how do I avoid this? 
(sample code below)

Thank you.

-Tosh

#read in the data table
co<-read.table("co.txt",header=T,as.is=T)

for (i in 1:3){
   paste("logco",i, sep="")<-log(co$co[co$day==i])
}

Gives the error:
Error: Target of assignment expands to non-language object

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.murrell at auckland.ac.nz  Fri Apr 19 01:21:06 2002
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Fri, 19 Apr 2002 11:21:06 +1200
Subject: [R] symbols in lattice
References: <Pine.LNX.4.31.0204160841110.12454-100000@gannet.stats>
Message-ID: <01fe01c1e72f$b7307550$7632d882@stat.auckland.ac.nz>

Hi


> > I simply can't figure out how I can force bwplot to print mathematical
> > symbols in the strips.
> >
> > Example:
> >
> > x <- rnorm(30)
> > lab <- factor(c(rep("one", 10), rep("two", 10), rep("three", 10)))
> > bwplot(~ x | lab)
> >
> > gives labels "one", "two", "tree" but I would like to change this into
> > expression(lambda == 1), expression(lambda == 2) and expression(lambda
==
> > 3).
> >
> > The only way to modify the labels is changing the levels of lab, right?
Or
> > is there something else?
>
> You can set your own strip function to replace strip=strip.default
> However, I am not aware that grid functions (on which lattice is based) do
> plotmath.  ?grid.text suggests not.
>
>    label: A vector of strings to draw.


Unfortunately, grid.text() does not handle mathematical expressions yet (and
will not in grid_0.6 which will be released with R 1.5.0).  It is on the
todo list.

Paul


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pkleiber at honlab.nmfs.hawaii.edu  Fri Apr 19 01:24:05 2002
From: pkleiber at honlab.nmfs.hawaii.edu (Pierre Kleiber)
Date: Thu, 18 Apr 2002 13:24:05 -1000
Subject: [R] Variable definition problem
References: <3CBF4D36.3020306@lbl.gov>
Message-ID: <3CBF5595.D739A3A2@honlab.nmfs.hawaii.edu>

  The statement in your for loop doesn't make much sense.  It's
attempting to assign something to the function paste().  Instead,
log(co$co[co$day==i]) should probably be in the argument list of
paste() and the result should then be assigned to a character
object, i.e. something like:

    sometxt[i] <- paste("logco",i,log(co$co[co$day==i], sep="")

If you let us know what you're trying to do, we might be more
help.

   Pierre


"T. Hotchi" wrote:
> 
> Hello, what does this error message indicate and how do I avoid this?
> (sample code below)
> 
> Thank you.
> 
> -Tosh
> 
> #read in the data table
> co<-read.table("co.txt",header=T,as.is=T)
> 
> for (i in 1:3){
>    paste("logco",i, sep="")<-log(co$co[co$day==i]")
> }
> 
> Gives the error:
> Error: Target of assignment expands to non-language object
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
-----------------------------------------------------------------
Pierre Kleiber             Email: pkleiber at honlab.nmfs.hawaii.edu
Fishery Biologist                     Tel: 808 983-5399/737-7544
NOAA FISHERIES - Honolulu Laboratory         Fax: 808 983-2902
2570 Dole St., Honolulu, HI 96822-2396 
-----------------------------------------------------------------
 "God could have told Moses about galaxies and mitochondria and
  all.  But behold... It was good enough for government work."
-----------------------------------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.murrell at auckland.ac.nz  Fri Apr 19 01:51:09 2002
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Fri, 19 Apr 2002 11:51:09 +1200
Subject: [R] persp(): z-axis annotation overwrites numbers at tickmark
References: <00db01c1e201$e052ec20$557c6686@tating>
Message-ID: <024001c1e733$eaacb520$7632d882@stat.auckland.ac.nz>

Hi


> One more question (I don't  know if it's related to the "old" problem):
the
> annotation on the z-axis
> overwrites the numbers at the tickmarks and sometimes, if numbers are
pretty
> long, the numbers themselfe overlap the actual tickmark.
>
> I tried moving the annotation by adj or lower the fontsize and tried out
> kind of all other parameters given in par() but didn't succeed.
>
> Is this actually the same kind of problem (like the old one) and does
anyone
> have a quick solution for that?


No good news on this I'm afraid ... the general problem is the same -- the
axes for persp() plots are not as fully implemented as axes for normal 2D
plots.  The only workaround I can think of is to switch off the default axes
and preform custom annotations using the 3D-to-2D transformation discussed
previously on this list.

Paul


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rmurison at turing.une.edu.au  Fri Apr 19 03:41:14 2002
From: rmurison at turing.une.edu.au (Bob Murison)
Date: Fri, 19 Apr 2002 11:41:14 +1000
Subject: [R] Variable definition problem
References: <3CBF4D36.3020306@lbl.gov>
Message-ID: <3CBF75BA.8E0D3CD4@turing.une.edu.au>

Give assign a rev.

"T. Hotchi" wrote:
> 
> Hello, what does this error message indicate and how do I avoid this?
> (sample code below)
> 
> Thank you.
> 
> -Tosh
> 
> #read in the data table
> co<-read.table("co.txt",header=T,as.is=T)
> 
> for (i in 1:3){
>    paste("logco",i, sep="")<-log(co$co[co$day==i])

assign(paste("logco",i,sep=""),log(co$co[co$day==1]))   

> }

Bob Murison
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hammour at msn.com  Fri Apr 19 06:48:03 2002
From: hammour at msn.com (Ahmad Abu Hammour)
Date: Fri, 19 Apr 2002 00:48:03 -0400
Subject: [R] Durbin-Watson test in packages "car" and "lmtest"
Message-ID: <OE147XUo0Y9qAr5ztVO00006a5c@hotmail.com>

Hi,
P-values in Durbin-Watson test obtained through the use of functions available in packages "lmtest" and "car" are different. The difference is quite significant. function "dwtest" in "lmtest" is much faster than "burbinwatson" in "car". Actually, you can take a nap while the latter trying to calculated Durbin-Watson test. My question is which p-value is better?
  
Thank you,
Ahmad Abu Hammour
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20020419/274907c1/attachment.html

From Torsten.Hothorn at rzmail.uni-erlangen.de  Fri Apr 19 10:49:58 2002
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Fri, 19 Apr 2002 10:49:58 +0200 (MEST)
Subject: [R] Durbin-Watson test in packages "car" and "lmtest"
In-Reply-To: <OE147XUo0Y9qAr5ztVO00006a5c@hotmail.com>
Message-ID: <Pine.LNX.4.21.0204191039250.1205-100000@artemis.imbe.med.uni-erlangen.de>

> Hi,
> P-values in Durbin-Watson test obtained through the use of 
> functions available in packages "lmtest" and "car" are different. The
> difference is quite significant. function "dwtest" in "lmtest" is much
> faster than "burbinwatson" in "car". Actually, you can take a nap while
> the latter trying to calculated Durbin-Watson test. My question is which
> p-value is better?

The answer is essencially given in ?durbin.watson and ?dwtest. The latter
states that

 The p value is computed
     using a Fortran version of the Applied Statistics Algorithm AS 153
     by Farebrother (1980, 1984). This algorithm is called "pan" or
     "gradsol". For large sample sizes the algorithm might fail to
     compute the p value; in that case a warning is printed and an
     approximate p value will be given; this p value is computed using
     a normal approximation with mean and variance of the Durbin-Watson
     test statistic.

while ?durbin.watson says

  simulate: if `TRUE' p-values will be estimated by bootstrapping.

What is a "quite significant" difference for p-values? 

Looking at the example from ?durbin.watson gives: 

R> durbin.watson(lm(fconvict ~ tfr + partic + degrees + mconvict,
data=Hartnagel))
 lag Autocorrelation D-W Statistic p-value
   1        0.688345     0.6168636       0
R> dwtest(fconvict ~ tfr + partic + degrees + mconvict, data=Hartnagel)

        Durbin-Watson test

data:  fconvict ~ tfr + partic + degrees + mconvict 
DW = 0.6169, p-value = 6.96e-09

which is fairly close, so you might give us more details (that is: a
working example) to see what the "difference" is (that is: a bug in
either function or a difference due to simulation error / bad
approximation ...). 

Torsten

>   
> Thank you,
> Ahmad Abu Hammour
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From alobo at ija.csic.es  Fri Apr 19 11:31:58 2002
From: alobo at ija.csic.es (Agustin Lobo)
Date: Fri, 19 Apr 2002 11:31:58 +0200 (MET DST)
Subject: [R] Two problems
In-Reply-To: <PPEGLLABFLFCJDLCGPGHEEHLCAAA.klavan@tiscalinet.it>
Message-ID: <Pine.OSF.3.96.1020419112843.29671A-100000@ija.csic.es>

On Thu, 18 Apr 2002, Ambrosini Alessandro wrote:

> Hello! Two questions:
> 
> 1: I have to import a matrix of adjacency from a file of a software that is
> not R (for example "bloc notes" of Windows). The problem is that the matrix
> is not in the explicit form as
>  0 1 1
>  1 0 0
>  1 0 0
> but it is a scattered matrix where in each row there are two nodes that have
> a direct path.
> The matrix is
> 
>  a   b
>  a   c
>  b   a
>  c   a
> 

I would use table():

> d1 <- c("a","a","b","c")
> d2 <- c("b","c","a","a")
> table(d1,d2)
   d2
d1  a b c
  a 0 1 1
  b 1 0 0
  c 1 0 0


But is this not a very unefficient way of storing adjacencies?

Agus

Dr. Agustin Lobo
Instituto de Ciencias de la Tierra (CSIC)
Lluis Sole Sabaris s/n
08028 Barcelona SPAIN
tel 34 93409 5410
fax 34 93411 0012
alobo at ija.csic.es




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From juli at ceam.es  Fri Apr 19 12:50:22 2002
From: juli at ceam.es (juli g. pausas)
Date: Fri, 19 Apr 2002 11:50:22 +0100
Subject: [R] merge
Message-ID: <3CBFF66E.F243D9FC@ceam.es>

Dear R-users,
I'm trying to merge 2 data.frames that have different number of rows,
with a common column. Is this possible? Here a simple exemple, with the
error that I get:

a <- 1:20
b <- 21:40
ab <- data.frame(a, b)
a <- 1:40
c <- 41:80
ac <- data.frame(a, c)
rm(a, b, c)
zz <- merge(ab, ac, by.x=ab$a, by.y=ac$a)

Error in fix.by(by.x, x) : `by' must match numbers of columns

What's wrong? Any suggestion?
I'm using R 1.4.1 under MS windows
Thanks

Juli

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Apr 19 12:29:05 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 19 Apr 2002 11:29:05 +0100 (BST)
Subject: [R] merge
In-Reply-To: <3CBFF66E.F243D9FC@ceam.es>
Message-ID: <Pine.LNX.4.31.0204191125220.5426-100000@gannet.stats>

On Fri, 19 Apr 2002, juli g. pausas wrote:

> Dear R-users,
> I'm trying to merge 2 data.frames that have different number of rows,
> with a common column. Is this possible? Here a simple exemple, with the

Yes, see the example on the help page.

> error that I get:
>
> a <- 1:20
> b <- 21:40
> ab <- data.frame(a, b)
> a <- 1:40
> c <- 41:80
> ac <- data.frame(a, c)
> rm(a, b, c)
> zz <- merge(ab, ac, by.x=ab$a, by.y=ac$a)
>
> Error in fix.by(by.x, x) : `by' must match numbers of columns

I think you intended

     merge(ab, ac, by="a")

You can read up on how to specify the `by' columns in the Details section,
or just follow the example.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From david.meyer at ci.tuwien.ac.at  Fri Apr 19 12:30:58 2002
From: david.meyer at ci.tuwien.ac.at (David Meyer)
Date: Fri, 19 Apr 2002 12:30:58 +0200
Subject: [R] merge
References: <3CBFF66E.F243D9FC@ceam.es>
Message-ID: <3CBFF1E2.8D2A0A7E@ci.tuwien.ac.at>

"juli g. pausas" wrote:
> 
> Dear R-users,
> I'm trying to merge 2 data.frames that have different number of rows,
> with a common column. Is this possible? Here a simple exemple, with the
> error that I get:
> 
> a <- 1:20
> b <- 21:40
> ab <- data.frame(a, b)
> a <- 1:40
> c <- 41:80
> ac <- data.frame(a, c)
> rm(a, b, c)
> zz <- merge(ab, ac, by.x=ab$a, by.y=ac$a)

use sth like

> zz <- merge(ab, ac, by="a")

instead.

g.
-d

> 
> Error in fix.by(by.x, x) : `by' must match numbers of columns
> 
> What's wrong? Any suggestion?
> I'm using R 1.4.1 under MS windows
> Thanks
> 
> Juli
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
	Mag. David Meyer		Wiedner Hauptstrasse 8-10
Vienna University of Technology		A-1040 Vienna/AUSTRIA
         Department of			Tel.: (+431) 58801/10772
Statistics and Probability Theory	mail: david.meyer at ci.tuwien.ac.at
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From YERUPAJA01 at terra.es  Fri Apr 19 12:42:09 2002
From: YERUPAJA01 at terra.es (YERUPAJA01)
Date: Fri, 19 Apr 2002 12:42:09 +0200
Subject: [R] Problem with installation on Mandrake 8.1
Message-ID: <438df407df.407df438df@teleline.es>

Hi,

I have dowloaded the rpm file for Mandrake 8.1 and when I try to 
install it a message asking for 'libblas.so.3' prompts out. I've search 
through www.rpmfind.net and freshmeat.net for the file, but I couldn't 
find it.

System:
Mandrake linux 8.1
AMD Duron

Thanks in advance

Antonio Rodr?guez


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Fri Apr 19 13:06:17 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri, 19 Apr 2002 07:06:17 -0400
Subject: [R] Problem with installation on Mandrake 8.1
In-Reply-To: <438df407df.407df438df@teleline.es>
References: <438df407df.407df438df@teleline.es>
Message-ID: <20020419070617.051cf039.fharrell@virginia.edu>

I had to install libgcc3.0-3.0.1-1mdk from Mandrake
installation disk # 2 and liblapack3-3.0-3mdk from Mandrake
disk # 3 (for blas).   You may only need the latter.  -Frank Harrell

On Fri, 19 Apr 2002 12:42:09 +0200
YERUPAJA01 <YERUPAJA01 at terra.es> wrote:

> Hi,
> 
> I have dowloaded the rpm file for Mandrake 8.1 and when I try to 
> install it a message asking for 'libblas.so.3' prompts out. I've search 
> through www.rpmfind.net and freshmeat.net for the file, but I couldn't 
> find it.
> 
> System:
> Mandrake linux 8.1
> AMD Duron
> 
> Thanks in advance
> 
> Antonio Rodr?guez
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Fri Apr 19 15:11:12 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 19 Apr 2002 09:11:12 -0400
Subject: trouble with tcltk (was RE: [R] trouble compiling R on Irix
 )
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC230@usrymx10.merck.com>

Thanks to Peter Dalgaard and Suchandra Thapa for answering my question!

Before I settle on a particular option, I'd like to ask one more question if
I may: Are there any practical advantages to compiling R to 64-bit vs
32-bit?

Regards,
Andy

> -----Original Message-----
> From: Peter Dalgaard BSA [mailto:p.dalgaard at biostat.ku.dk]
> Sent: Thursday, April 18, 2002 4:19 PM
> To: Liaw, Andy
> Cc: 'R-help at stat.math.ethz.ch'
> Subject: Re: trouble with tcltk (was RE: [R] trouble 
> compiling R on Irix
> )
> 
> 
> "Liaw, Andy" <andy_liaw at merck.com> writes:
> 
> > Hi,
> > 
> > Thanks to Profs. Ripley and Tierney for their tips, I 
> compiled zlib from
> > source and gotten further.
> > 
> > Here's where I get stuck, when it tries to compile the 
> tcltk package:
> > 
> > ld32: FATAL   12 : Expecting n32 objects: 
> /usr/local/lib/libtcl8.3.so is
> > n64.
> > 
> > Now I'm confused.  Sounds like 32-bit vs. 64-bit problem.  
> What can I do at
> > this point?
> > 
> > (This is on Irix.)
> 
> Well, there seems to be three options:
> 
> 1) Build without tcltk (configure --without-tcltk)
> 
> 2) get a 32-bit tcltk
> 
> 3) compile everything else for 64 bits
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: 
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: 
> (+45) 35327907
> 

------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jgreenb2 at ford.com  Fri Apr 19 15:31:58 2002
From: jgreenb2 at ford.com (Greenberg, Jeff (J.A.))
Date: Fri, 19 Apr 2002 09:31:58 -0400
Subject: [R] Help with lme basics
Message-ID: <200204191332.g3JDWlr02474@dymwsm12.mailwatch.com>

Renaud,

Thanks. Im not a statistician so maybe I have this all wrong but here's what I was expecting. When I model this data set with:

summary(aov(effect ~ gp * drug * dose + Error(subj/(dose+drug)), data=Ela.uni))

what I mean is that subj is a random factor nested within gp and that dose and drug are fixed effects. So I want to construct tests that have the fixed effects crossed with random effects in the denominator. The output of aov is exactly what I would get from fitting this model in SYSTAT and the error strata and error df's are exactly what I would compute by hand:

Error: subj
          Df Sum Sq Mean Sq F value  Pr(>F)  
gp         1 270.01  270.01  7.0925 0.01855 *
Residuals 14 532.98   38.07                  
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

Error: subj:dose
          Df Sum Sq Mean Sq F value    Pr(>F)    
dose       2 758.77  379.39 36.5097 1.580e-08 ***
gp:dose    2  42.27   21.14  2.0339    0.1497    
Residuals 28 290.96   10.39                      
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

Error: subj:drug
          Df Sum Sq Mean Sq F value   Pr(>F)   
drug       1 348.84  348.84  13.001 0.002866 **
gp:drug    1 326.34  326.34  12.163 0.003624 **
Residuals 14 375.65   26.83                    
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

Error: Within
             Df  Sum Sq Mean Sq F value Pr(>F)
drug:dose     2  12.062   6.031  0.6815 0.5140
gp:drug:dose  2  14.812   7.406  0.8369 0.4436
Residuals    28 247.792   8.850

If I then follow your suggestion for fitting with lme the results I get are confusing:

> fm <- lme(fixed = effect ~ gp * drug * dose,
+   random = ~ 1 | subj,
+   data = Ela.uni)
> anova(fm)
             numDF denDF   F-value p-value
(Intercept)      1    70 1461.2979  <.0001
gp               1    14    7.0924  0.0185
drug             1    70   26.7052  <.0001
dose             2    70   29.0433  <.0001
gp:drug          1    70   24.9828  <.0001
gp:dose          2    70    1.6180  0.2056
drug:dose        2    70    0.4617  0.6321
gp:drug:dose     2    70    0.5670  0.5698

Here the gp term is similar to what I expect (at least the number of degrees of freedom in the denominator is right) but the rest of the table makes no sense to me (70 df's in the denominator???).

I have been assuming that for a balanced case like this I should be able to get lme to report results that are very similar to the results of a 'traditional' analysis like aov. Until I can figure this out, I have no confidence that I can use lme for the unbalanced data I'm really interested in.


-----Original Message-----
From: Renaud Lancelot [mailto:lancelot at sentoo.sn]
Sent: Thursday, April 18, 2002 2:52 PM
To: Greenberg, Jeff (J.A.)
Subject: Re: [R] Help with lme basics


Hi Jeff,

"Greenberg, Jeff (J.A.)" wrote:
> 
> In Baron and Li's "Notes on the use of R for psychology experiments and questionnaires" http://cran.r-project.org/doc/contrib/rpsych.htm they describe a balanced data set for a drug experiment:
> 
> "... a test of drug treatment effect by one between-subject factor: group (two groups of 8 subjects each) and two within-subject factors: drug (2 levels) and dose (3 levels). "
> 
> This design is identical to an unbalanced one that I am interested in analyzing in R. I have both missing cells and unequal number of observations per cell. This is a repeated-measures design with test subject as a random factor.
> 
> Baron and Li show how to analyze this design using aov:
> 
> summary(aov(effect ~ gp * drug * dose + Error(subj/(dose+drug)), data=Ela.uni))
> 
> When I analyze my design I get additional terms in each error stratum because of the missing cells. The results appear sensible, but I've been told that lme is a better way to model this data.
> 
> My question is: how do I set up an equivalent model using lme? Using the balanced data set in Baron and Li I've tried this model:
> 
> ela.lme<-lme(effect~gp*dose*drug,random=~1|subj/drug/dose)

I don't thing dose and drugs can be considered as random effects like
you specified it in the above model. They are both within-subject fixed
effects. So:

fm <- lme(fixed = effect ~ gp * drug * dose,
  random = ~ 1 | subj,
  data = Ela.uni)

will give you population means for gp, drug and dose and interaction
terms, and a subject-specific baseline (subject random effect).

If you have strong evidence (e.g. graphical exploration of residuals) of
an heterogeneous residuals variance according to strata defined by drug
and dose, this can be specified with the weights argument:

fm <- lme(fixed = effect ~ gp * drug * dose,
  random = ~ 1 | subj,
  weights = varIdent(form = ~ 1 | drug * dose),
  data = Ela.uni)

This will give you one residuals variance for each combination of drug
by dose.

To examine the numeric results, you can use the summary, anova and
intervals methods for lme objects. For example:
anova(fm, type = "marginal")
will produce an anova table for the fixed effects;
intervals(fm)
will produce confidence intervals for fixed and random parameters
(random effects and variance parameters).

A very useful and nice reference for mixed-effects models with lme is
Pinheiro, J.C., Bates, D.M., 2000. Mixed-effect models in S and S-Plus.
New York (USA), Springer, 598 p.
which was written by the authors of nlme.

Hope this helps,

Renaud

-- 
Dr Renaud Lancelot, v?t?rinaire
CIRAD, D?partement Elevage et M?decine V?t?rinaire (CIRAD-Emvt)
Programme Productions Animales
http://www.cirad.fr/presentation/programmes/prod-ani.shtml (Fran?ais)
http://www.cirad.fr/presentation/en/program-eng/prod-ani.shtml (English)

ISRA-LNERV                      tel    (221) 832 49 02
BP 2057 Dakar-Hann              fax    (221) 821 18 79 (CIRAD)
Senegal                         e-mail renaud.lancelot at cirad.fr
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tristanpeery at hotmail.com  Fri Apr 19 16:56:16 2002
From: tristanpeery at hotmail.com (Tristan Peery)
Date: Fri, 19 Apr 2002 14:56:16 +0000
Subject: [R] y-intercept forcing
Message-ID: <F22UYLqVpUOF9vJZTuG000012e3@hotmail.com>


R-gurus,

I am plotting data against each other using t-tests.  In this scenario, I am 
plotting coinage / total money.  When there is no total money, then there is 
no coinage, but the plots I generate do not reflect this.  Instead the 
y-axis always has an intecept that is not zero in these instances.  Is there 
any way to force the y-intercept to begin at zero?  Thank you in advance for 
any input.

Tristan




_________________________________________________________________


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlorino at vet-alfort.fr  Fri Apr 19 17:03:52 2002
From: tlorino at vet-alfort.fr (Tristan Lorino)
Date: Fri, 19 Apr 2002 17:03:52 +0200
Subject: [R] R and OS X
In-Reply-To: <3CC02E89.4957FC4A@sentoo.sn>
References: <a05101500b8e5b785fdaa@[10.5.12.44]>
 <3CC02E89.4957FC4A@sentoo.sn>
Message-ID: <a05101507b8e5e21af89d@[10.5.12.44]>

>  Dears users,
>  I'm trying to run R on a computer with OS X. I installed the R folder
>  and the dylibs, where they must be installed. I updated my path, and
>  R runs but tells me :
>
>  dyld: /usr/local/R-1.4.0/lib/R/bin/R.bin version mismatch for
>  library: /usr/lib/libz.1.dylib (compatibility version of user: 1.1.3
>  greater than library's version: 1.0.0)
>
>  The only thing I didn't do -- because I don't know how one can do
>  this -- is to put /sw/lib first in the
>  DYLD_LIBRARY_PATH environmental variable.
>
>  Could you please help me?
>
>  Thank you,
>  Tristan Lorino
>

-- 
------------------------------------------
Ecole Nationale V?t?rinaire d'Alfort
7 av. du Gal de Gaulle 94704 Maisons-Alfort
T?l. 01 43 96 70 33
Site personnel : http://daedale.free.fr
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Fri Apr 19 17:11:24 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 19 Apr 2002 17:11:24 +0200
Subject: [R] y-intercept forcing
In-Reply-To: <F22UYLqVpUOF9vJZTuG000012e3@hotmail.com>
References: <F22UYLqVpUOF9vJZTuG000012e3@hotmail.com>
Message-ID: <x2znzziuzn.fsf@blueberry.kubism.ku.dk>

"Tristan Peery" <tristanpeery at hotmail.com> writes:

> R-gurus,
> 
> I am plotting data against each other using t-tests. 

Er? I don't think that means what you intended it to mean....

> In this
> scenario, I am plotting coinage / total money.  When there is no total
> money, then there is no coinage, but the plots I generate do not
> reflect this.  Instead the y-axis always has an intecept that is not
> zero in these instances.  Is there any way to force the y-intercept to
> begin at zero?  Thank you in advance for any input.

abline(lm(y~x-1)) plots a fitted regression line with no intercept.
(Or, y~x+0 does the same thing).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rpeng at stat.ucla.edu  Fri Apr 19 17:28:54 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Fri, 19 Apr 2002 08:28:54 -0700 (PDT)
Subject: [R] y-intercept forcing
In-Reply-To: <F22UYLqVpUOF9vJZTuG000012e3@hotmail.com>
Message-ID: <Pine.GSO.4.10.10204190828380.5487-100000@quetelet.stat.ucla.edu>

Try the 'ylim' argument in plot.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Fri, 19 Apr 2002, Tristan Peery wrote:

> 
> R-gurus,
> 
> I am plotting data against each other using t-tests.  In this scenario, I am 
> plotting coinage / total money.  When there is no total money, then there is 
> no coinage, but the plots I generate do not reflect this.  Instead the 
> y-axis always has an intecept that is not zero in these instances.  Is there 
> any way to force the y-intercept to begin at zero?  Thank you in advance for 
> any input.
> 
> Tristan
> 
> 
> 
> 
> _________________________________________________________________
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Fri Apr 19 17:34:49 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 19 Apr 2002 10:34:49 -0500
Subject: [R] Help with lme basics
In-Reply-To: <200204191332.g3JDWlr02474@dymwsm12.mailwatch.com>
References: <200204191332.g3JDWlr02474@dymwsm12.mailwatch.com>
Message-ID: <6rofgf4s86.fsf@franz.stat.wisc.edu>

The lme model divides the terms in the fixed effects into those that
change within subjects and those that do not.  Apparently both dose
and drug change within subject and only gp does not change within
subject.  Thus the only term whose denominator degrees of freedom is
determined by the number of subjects is the gp term.  All other terms
and interactions are estimated by all the data on all the subjects
hence they have 70 denominator degrees of freedom.

We explain the reasoning behind the lme model in chapter 3 of our book
@Book{pinh:bate:2000,
  author =	 {Jos\'{e} C. Pinheiro and Douglas M. Bates},
  title = 	 {Mixed-Effects Models in \textsf{S} and \textsf{S-PLUS}},
  publisher = 	 {Springer},
  year = 	 2000,
  series =	 {Statistics and Computing}
}
It is derived from a hierarchical linear model with random effects at
the subject level.

I think this comparison shows that lme evaluates the significance of
terms differently from models that employ error strata.  I don't think
it shows that the lme model is "wrong".  

I will leave it to someone who understands error strata better than I
do to explain the rationale of the results based on error strata.

"Greenberg, Jeff (J.A.)" <jgreenb2 at ford.com> writes:

> Thanks. Im not a statistician so maybe I have this all wrong but here's what I was expecting. When I model this data set with:
> 
> summary(aov(effect ~ gp * drug * dose + Error(subj/(dose+drug)), data=Ela.uni))
> 
> what I mean is that subj is a random factor nested within gp and that dose and drug are fixed effects. So I want to construct tests that have the fixed effects crossed with random effects in the denominator. The output of aov is exactly what I would get from fitting this model in SYSTAT and the error strata and error df's are exactly what I would compute by hand:
> 
> Error: subj
>           Df Sum Sq Mean Sq F value  Pr(>F)  
> gp         1 270.01  270.01  7.0925 0.01855 *
> Residuals 14 532.98   38.07                  
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
> 
> Error: subj:dose
>           Df Sum Sq Mean Sq F value    Pr(>F)    
> dose       2 758.77  379.39 36.5097 1.580e-08 ***
> gp:dose    2  42.27   21.14  2.0339    0.1497    
> Residuals 28 290.96   10.39                      
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
> 
> Error: subj:drug
>           Df Sum Sq Mean Sq F value   Pr(>F)   
> drug       1 348.84  348.84  13.001 0.002866 **
> gp:drug    1 326.34  326.34  12.163 0.003624 **
> Residuals 14 375.65   26.83                    
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
> 
> Error: Within
>              Df  Sum Sq Mean Sq F value Pr(>F)
> drug:dose     2  12.062   6.031  0.6815 0.5140
> gp:drug:dose  2  14.812   7.406  0.8369 0.4436
> Residuals    28 247.792   8.850
> 
> If I then follow your suggestion for fitting with lme the results I get are confusing:
> 
> > fm <- lme(fixed = effect ~ gp * drug * dose,
> +   random = ~ 1 | subj,
> +   data = Ela.uni)
> > anova(fm)
>              numDF denDF   F-value p-value
> (Intercept)      1    70 1461.2979  <.0001
> gp               1    14    7.0924  0.0185
> drug             1    70   26.7052  <.0001
> dose             2    70   29.0433  <.0001
> gp:drug          1    70   24.9828  <.0001
> gp:dose          2    70    1.6180  0.2056
> drug:dose        2    70    0.4617  0.6321
> gp:drug:dose     2    70    0.5670  0.5698
> 
> Here the gp term is similar to what I expect (at least the number of degrees of freedom in the denominator is right) but the rest of the table makes no sense to me (70 df's in the denominator???).
> 
> I have been assuming that for a balanced case like this I should be able to get lme to report results that are very similar to the results of a 'traditional' analysis like aov. Until I can figure this out, I have no confidence that I can use lme for the unbalanced data I'm really interested in.
> 
> 
> -----Original Message-----
> From: Renaud Lancelot [mailto:lancelot at sentoo.sn]
> Sent: Thursday, April 18, 2002 2:52 PM
> To: Greenberg, Jeff (J.A.)
> Subject: Re: [R] Help with lme basics
> 
> 
> Hi Jeff,
> 
> "Greenberg, Jeff (J.A.)" wrote:
> > 
> > In Baron and Li's "Notes on the use of R for psychology experiments and questionnaires" http://cran.r-project.org/doc/contrib/rpsych.htm they describe a balanced data set for a drug experiment:
> > 
> > "... a test of drug treatment effect by one between-subject factor: group (two groups of 8 subjects each) and two within-subject factors: drug (2 levels) and dose (3 levels). "
> > 
> > This design is identical to an unbalanced one that I am interested in analyzing in R. I have both missing cells and unequal number of observations per cell. This is a repeated-measures design with test subject as a random factor.
> > 
> > Baron and Li show how to analyze this design using aov:
> > 
> > summary(aov(effect ~ gp * drug * dose + Error(subj/(dose+drug)), data=Ela.uni))
> > 
> > When I analyze my design I get additional terms in each error stratum because of the missing cells. The results appear sensible, but I've been told that lme is a better way to model this data.
> > 
> > My question is: how do I set up an equivalent model using lme? Using the balanced data set in Baron and Li I've tried this model:
> > 
> > ela.lme<-lme(effect~gp*dose*drug,random=~1|subj/drug/dose)
> 
> I don't thing dose and drugs can be considered as random effects like
> you specified it in the above model. They are both within-subject fixed
> effects. So:
> 
> fm <- lme(fixed = effect ~ gp * drug * dose,
>   random = ~ 1 | subj,
>   data = Ela.uni)
> 
> will give you population means for gp, drug and dose and interaction
> terms, and a subject-specific baseline (subject random effect).
> 
> If you have strong evidence (e.g. graphical exploration of residuals) of
> an heterogeneous residuals variance according to strata defined by drug
> and dose, this can be specified with the weights argument:
> 
> fm <- lme(fixed = effect ~ gp * drug * dose,
>   random = ~ 1 | subj,
>   weights = varIdent(form = ~ 1 | drug * dose),
>   data = Ela.uni)
> 
> This will give you one residuals variance for each combination of drug
> by dose.
> 
> To examine the numeric results, you can use the summary, anova and
> intervals methods for lme objects. For example:
> anova(fm, type = "marginal")
> will produce an anova table for the fixed effects;
> intervals(fm)
> will produce confidence intervals for fixed and random parameters
> (random effects and variance parameters).
> 
> A very useful and nice reference for mixed-effects models with lme is
> Pinheiro, J.C., Bates, D.M., 2000. Mixed-effect models in S and S-Plus.
> New York (USA), Springer, 598 p.
> which was written by the authors of nlme.
> 
> Hope this helps,
> 
> Renaud
> 
> -- 
> Dr Renaud Lancelot, v?t?rinaire
> CIRAD, D?partement Elevage et M?decine V?t?rinaire (CIRAD-Emvt)
> Programme Productions Animales
> http://www.cirad.fr/presentation/programmes/prod-ani.shtml (Fran?ais)
> http://www.cirad.fr/presentation/en/program-eng/prod-ani.shtml (English)
> 
> ISRA-LNERV                      tel    (221) 832 49 02
> BP 2057 Dakar-Hann              fax    (221) 821 18 79 (CIRAD)
> Senegal                         e-mail renaud.lancelot at cirad.fr
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Fri Apr 19 17:44:25 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 19 Apr 2002 10:44:25 -0500
Subject: [R] Help with lme basics
In-Reply-To: <6rofgf4s86.fsf@franz.stat.wisc.edu>
References: <200204191332.g3JDWlr02474@dymwsm12.mailwatch.com>
	<6rofgf4s86.fsf@franz.stat.wisc.edu>
Message-ID: <6r7kn34rs6.fsf@franz.stat.wisc.edu>

Douglas Bates <bates at cs.wisc.edu> writes:

> We explain the reasoning behind the lme model in chapter 3 of our book

Duh.  The theory for the linear mixed-effects model is in chapter 2
not chapter 3.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From s-thapa-11 at alumni.uchicago.edu  Fri Apr 19 17:55:40 2002
From: s-thapa-11 at alumni.uchicago.edu (Suchandra Thapa)
Date: Fri, 19 Apr 2002 10:55:40 -0500
Subject: trouble with tcltk (was RE: [R] trouble compiling R on Irix )
In-Reply-To: <51F9C42DA15CD311BD220008C707D81906FFC230@usrymx10.merck.com>; from andy_liaw@merck.com on Fri, Apr 19, 2002 at 09:11:12AM -0400
References: <51F9C42DA15CD311BD220008C707D81906FFC230@usrymx10.merck.com>
Message-ID: <20020419105540.D29732@hepcat>

On Fri, Apr 19, 2002 at 09:11:12AM -0400, Liaw, Andy wrote:
> Before I settle on a particular option, I'd like to ask one more question if
> I may: Are there any practical advantages to compiling R to 64-bit vs
> 32-bit?

    If you compile R as a 64 bit application you should be able to address more
than 4GB of ram, but I'm not sure if R will support this. Also 32bit 
applications will run a bit faster since their pointers are smaller and thus
more information can be kept on cpu caches.  The difference isn't that big 
however (I think it's about 5% or so).

-- 
------------------------------------------------------------------

Suchandra S. Thapa 
s-thapa-11 at alumni.uchicago.edu

------------------------------------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Fri Apr 19 18:26:41 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 19 Apr 2002 09:26:41 -0700 (PDT)
Subject: trouble with tcltk (was RE: [R] trouble compiling R on Irix )
In-Reply-To: <20020419105540.D29732@hepcat>
Message-ID: <Pine.A41.4.44.0204190921130.80724-100000@homer27.u.washington.edu>

On Fri, 19 Apr 2002, Suchandra Thapa wrote:

> On Fri, Apr 19, 2002 at 09:11:12AM -0400, Liaw, Andy wrote:
> > Before I settle on a particular option, I'd like to ask one more question if
> > I may: Are there any practical advantages to compiling R to 64-bit vs
> > 32-bit?
>
>     If you compile R as a 64 bit application you should be able to address more
> than 4GB of ram, but I'm not sure if R will support this.


According to src/main/memory.c, R will allocate up to INT_MAX records in
each heap, which would be 56Gb of Ncells (or probably a bit more with
64bit pointers) and 16Gb of vector heap. I don't know of anyone who has
actually tried addressing more than 4Gb of RAM, and it's possible that
there is some other limit that prevents it working.

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From A.Nuzzo at motorola.com  Fri Apr 19 18:30:13 2002
From: A.Nuzzo at motorola.com (Nuzzo Art-CINT116)
Date: Fri, 19 Apr 2002 11:30:13 -0500
Subject: [R] Problem compiling on HP-UX 10.20
Message-ID: <CF5B20DBDE16D4119B9800D0B73E984806453A6D@il02exm25.comm.mot.com>

Thanks for the help. I am getting closer.  Switching to the fort77 compiler
fixed that problem.  Now it compiles completely but I am unable to run the
check.  


artn at bs752> make check
make[1]: Entering directory `/tmp_mnt/users/artn/R-1.4.1/tests'
make[2]: Entering directory `/tmp_mnt/users/artn/R-1.4.1/tests'
make[3]: Entering directory `/tmp_mnt/users/artn/R-1.4.1/tests/Examples'
make[4]: Entering directory `/tmp_mnt/users/artn/R-1.4.1/tests/Examples'
make[4]: Leaving directory `/tmp_mnt/users/artn/R-1.4.1/tests/Examples'
make[4]: Entering directory `/tmp_mnt/users/artn/R-1.4.1/tests/Examples'
make[4]: *** Warning: File `Makefile' has modification time in the future
(2002-04-19 11:17:56 > 2002-04-19 11:17:53)
collecting examples for package `base' ...
make[5]: Entering directory `/tmp_mnt/users/artn/R-1.4.1/src/library'
 >>> Building/Updating help pages for package `base'
     Formats: text example 
make[5]: Leaving directory `/tmp_mnt/users/artn/R-1.4.1/src/library'
running code in `base-Ex.R' ...make[4]: *** [base-Ex.Rout] Error 1
make[4]: Leaving directory `/tmp_mnt/users/artn/R-1.4.1/tests/Examples'
make[3]: *** [test-Examples] Error 2
make[3]: Leaving directory `/tmp_mnt/users/artn/R-1.4.1/tests/Examples'
make[2]: *** [test-Examples] Error 2
make[2]: Leaving directory `/tmp_mnt/users/artn/R-1.4.1/tests'
make[1]: *** [test-all-basics] Error 1
make[1]: Leaving directory `/tmp_mnt/users/artn/R-1.4.1/tests'
make: *** [check] Error 2
artn at bs752> 



Initially I tried with the default compiler flags and then with CFLAGS=-O
and also tried with CXXFLAGS=-O with the same results. My current
configuration is:


R is now configured for hppa2.0-hp-hpux10.20

  Source directory:          .
  Installation directory:    /users/artn
  C compiler:                gcc  -D_HPUX_SOURCE -O
  C++ compiler:              c++  -O
  FORTRAN compiler:          fort77  -g

  X11 support:               yes
  Gnome support:             no
  Tcl/Tk support:            no

  R profiling support:       yes
  R as a shared library:     no

configure: warning: you cannot build DVI versions of the R manuals
configure: warning: you cannot build PDF versions of the R manuals


Thanks for any help,


Art Nuzzo

> -----Original Message-----
> From: Luke Tierney [mailto:luke at stat.umn.edu]
> Sent: Thursday, April 18, 2002 9:28 AM
> To: Nuzzo Art-CINT116
> Subject: Re: [R] Problem compiling on HP-UX 10.20
> 
> 
> Have a look at the notes on HP-UX in the R-admin manual.  In nutshell,
> you will either need to make sure libg2c is compiled with PIC flags or
> use the HP compiler fort77.
> 
> luke
> 
> On Thu, Apr 18, 2002 at 09:16:58AM -0500, Nuzzo Art-CINT116 wrote:
> > I am having a problem compiling R on an HP-UX 10.20 system 
> using gcc/g77
> > compiler. It appears to compile without problems until it 
> gets to the lapack
> > module and I get the following error:
> > 
> > gcc -I. -I../../../src/include -I../../../src/include 
> -I/usr/local/include
> > -DHAVE_CONFIG_H -D_HPUX_SOURCE -fPIC  -O2 -c Lapack.c -o Lapack.lo
> > g77  -fPIC  -O2 -c double.f -o double.lo
> > g77  -fPIC  -O2 -c cmplx.f -o cmplx.lo
> > g77  -fPIC  -O2 -c blas2.f -o blas2.lo
> > g77  -fPIC  -O2 -c cmplxblas.f -o cmplxblas.lo
> > gcc -shared -fPIC  -o lapack.sl  Lapack.lo double.lo  
> cmplx.lo blas2.lo
> > cmplxblas.lo   -lg2c -lm -L/lib/pa1.1 -L/usr/lib/pa1.1 -u main
> > -L/opt/gnu/lib/gcc-lib/hppa2.0-hp-hpux10.20/3.0.4 -L/usr/ccs/bin
> > -L/usr/ccs/lib -L/opt/langtools/lib
> > -L/opt/gnu/lib/gcc-lib/hppa2.0-hp-hpux10.20/3.0.4/../../.. -lm
> > -L/usr/local/lib  -lz -ltermcap -lm
> > /usr/ccs/bin/ld: DP relative code in file
> > 
> /opt/gnu/lib/gcc-lib/hppa2.0-hp-hpux10.20/3.0.4/libg2c.a(fmt.o
> ) - shared
> > library must be position
> >     independent.  Use +z or +Z to recompile.
> > collect2: ld returned 1 exit status
> > make[4]: *** [lapack.sl] Error 1
> > make[4]: Leaving directory 
> `/tmp_mnt/users/artn/R-1.4.1/src/modules/lapack'
> > 
> > 
> > Any help is appreciated, thanks,
> > 
> > 
> > Art Nuzzo
> > 
> > 
> > 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> > 
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> 
> -- 
> Luke Tierney
> University of Minnesota                      Phone:           
> 612-625-7843
> School of Statistics                         Fax:             
> 612-624-8868
> 313 Ford Hall, 224 Church St. S.E.           email:      
> luke at stat.umn.edu
> Minneapolis, MN 55455 USA                    WWW:  
http://www.stat.umn.edu
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Fri Apr 19 18:44:18 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 19 Apr 2002 18:44:18 +0200
Subject: [R] Help with lme basics
In-Reply-To: <6rofgf4s86.fsf@franz.stat.wisc.edu>
References: <200204191332.g3JDWlr02474@dymwsm12.mailwatch.com>
	<6rofgf4s86.fsf@franz.stat.wisc.edu>
Message-ID: <x2r8lbiqot.fsf@blueberry.kubism.ku.dk>

Douglas Bates <bates at stat.wisc.edu> writes:

> I think this comparison shows that lme evaluates the significance of
> terms differently from models that employ error strata.  I don't think
> it shows that the lme model is "wrong".  
> 
> I will leave it to someone who understands error strata better than I
> do to explain the rationale of the results based on error strata.

Well, it's all a matter of orthogonal decompositions and dimensions of
subspaces. If you have an orthogonal design for the error components,
and the treatment terms each fall within a single part of the
decomposition, then all the tests are exact (if the model holds!).
Mostly, it comes down to analyzing certain sets of means and
differences of means. There's only a slight approximation involved in
that the variance components are allowed to be slightly negative.

However, it doesn't generalize well to non-orthogonal designs. If you
have one of those and persist in performing the decompostion into
error strata, this will correspond to a strange model for the
covariance structure of the data set. For instance, in one-way ANOVA
with random group effects, you'll end up with a different
"between"-variance for smaller groups than for larger.

In contrast, lme() fits perfectly sensible models for these cases, but
the price of the generality is that it doesn't have the exact
distribution of the test statistics, even when data happens to be from
an orthogonal design. As far as I know, all current mixed-effects
codes "get it wrong" in slightly different ways. The results only hold
asymptotically. Heuristical arguments get employed but it is fairly
easy to construct examples where they would seem to be insufficient.

(E.g. suppose you have Y = mu + Z_g + Z_gi, with groups g = 1...8  and
varying observations within groups. The containment method suggests
that you have 7 DF for inferences about mu, but if you have 1000
observations in each of groups 1-4 and only 1 in groups 5-8, and the
Z_g variance is relatively small, then I'd expect the "correct"
number of DF to be closer to 3).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Fri Apr 19 18:47:58 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 19 Apr 2002 18:47:58 +0200
Subject: [R] Problem compiling on HP-UX 10.20
In-Reply-To: <CF5B20DBDE16D4119B9800D0B73E984806453A6D@il02exm25.comm.mot.com>
References: <CF5B20DBDE16D4119B9800D0B73E984806453A6D@il02exm25.comm.mot.com>
Message-ID: <x2n0vziqip.fsf@blueberry.kubism.ku.dk>

Nuzzo Art-CINT116 <A.Nuzzo at motorola.com> writes:

> Thanks for the help. I am getting closer.  Switching to the fort77 compiler
> fixed that problem.  Now it compiles completely but I am unable to run the
> check.  
> 
> 
> artn at bs752> make check
> make[1]: Entering directory `/tmp_mnt/users/artn/R-1.4.1/tests'
> make[2]: Entering directory `/tmp_mnt/users/artn/R-1.4.1/tests'
> make[3]: Entering directory `/tmp_mnt/users/artn/R-1.4.1/tests/Examples'
> make[4]: Entering directory `/tmp_mnt/users/artn/R-1.4.1/tests/Examples'
> make[4]: Leaving directory `/tmp_mnt/users/artn/R-1.4.1/tests/Examples'
> make[4]: Entering directory `/tmp_mnt/users/artn/R-1.4.1/tests/Examples'
> make[4]: *** Warning: File `Makefile' has modification time in the future
> (2002-04-19 11:17:56 > 2002-04-19 11:17:53)
> collecting examples for package `base' ...
> make[5]: Entering directory `/tmp_mnt/users/artn/R-1.4.1/src/library'
>  >>> Building/Updating help pages for package `base'
>      Formats: text example 
> make[5]: Leaving directory `/tmp_mnt/users/artn/R-1.4.1/src/library'
> running code in `base-Ex.R' ...make[4]: *** [base-Ex.Rout] Error 1

What comes at the end of base-Ex.Rout.fail?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From snow at fisher.byu.edu  Fri Apr 19 19:10:41 2002
From: snow at fisher.byu.edu (Greg Snow)
Date: Fri, 19 Apr 2002 11:10:41 -0600 (MDT)
Subject: [R] Variable definition problem
In-Reply-To: <3CBF4D36.3020306@lbl.gov>
Message-ID: <Pine.GSO.4.21.0204191102010.12195-100000@fisher.byu.edu>

On Thu, 18 Apr 2002, T. Hotchi wrote:

> Hello, what does this error message indicate and how do I avoid this? 
> (sample code below)
> 
> Thank you.
> 
> -Tosh
> 
> #read in the data table
> co<-read.table("co.txt",header=T,as.is=T)
> 
> for (i in 1:3){
>    paste("logco",i, sep="")<-log(co$co[co$day==i])
> }
> 
> Gives the error:
> Error: Target of assignment expands to non-language object

Another response pointed you to the assign function which is the way to do
what you are trying to do.  However assigning to global variables in a
loop or function is often not a good idea.  If you want to save a bunch of
things and generate their names on the fly then a list is often a better
approach.  Replace your above code with something like:

mylogs <- list() # create an empty list to put data into
for (i in 1:3){
   mylogs[[ paste("logco",i, sep="") ]] <- log(co$co[co$day==i])
}

now you can access the results in several different ways:

mylogs[["logco1"]]
mylogs$logco1

or 

attach(mylogs)
logco1


This approach generaly does what you want and keeps from creating to many
top level global variables.  It is also easier to dump one single list to
a file for backup or tranfer than to do the same with all of your global
variables.

hope this helps,


-- 
Greg Snow, PhD                Office: 223A TMCB
Department of Statistics      Phone:  (801) 378-7049
Brigham Young University      Dept.:  (801) 378-4505
Provo, UT  84602              email:  gls at byu.edu

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From A.Nuzzo at motorola.com  Fri Apr 19 19:11:18 2002
From: A.Nuzzo at motorola.com (Nuzzo Art-CINT116)
Date: Fri, 19 Apr 2002 12:11:18 -0500
Subject: FW: [R] Problem compiling on HP-UX 10.20
Message-ID: <CF5B20DBDE16D4119B9800D0B73E984806453A6F@il02exm25.comm.mot.com>



Here is a copy of the last few lines in base-Ex.Rout.fail:

>  x <- seq(3,500);yl <- c(-.3, .2)
>  plot(x,x, ylim = yl, ylab="",type='n', main = "Bessel Functions
Y_nu(x)")
>  for(nu in nus){xx <- x[x > .6*nu]; lines(xx,besselY(xx,nu=nu), col =
nu+2)}
>  legend(300,-.08, leg=paste("nu=",nus), col = nus+2, lwd=1)
> 
>  x <- seq(10,50000,by=10);yl <- c(-.1, .1)
>  plot(x,x, ylim = yl, ylab="",type='n', main = "Bessel Functions
Y_nu(x)")
>  for(nu in nus){xx <- x[x > .6*nu]; lines(xx,besselY(xx,nu=nu), col =
nu+2)}
>  summary(bY <- besselY(2,nu = nu <- seq(0,100,len=501)))
       Min.     1st Qu.      Median        Mean     3rd Qu.        Max. 
-3.001e+155 -1.067e+107  -1.976e+62 -9.961e+152  -2.059e+23   5.104e-01 
>  which(bY >= 0)
[1] 1 2 3 4 5
>  summary(bY <- besselY(2,nu = nu <- seq(3,300,len=51)))
Error in vector("character", length) : negative length vectors are not
allowed
In addition: There were 23 warnings (use warnings() to see them)
Execution halted



Thanks,


Art Nuzzo




> -----Original Message-----
> From: Peter Dalgaard BSA [mailto:p.dalgaard at biostat.ku.dk]
> Sent: Friday, April 19, 2002 11:48 AM
> To: Nuzzo Art-CINT116
> Cc: R-help at stat.math.ethz.ch
> Subject: Re: [R] Problem compiling on HP-UX 10.20
> 
> 
> Nuzzo Art-CINT116 <A.Nuzzo at motorola.com> writes:
> 
> > Thanks for the help. I am getting closer.  Switching to the 
> fort77 compiler
> > fixed that problem.  Now it compiles completely but I am 
> unable to run the
> > check.  
> > 
> > 
> > artn at bs752> make check
> > make[1]: Entering directory `/tmp_mnt/users/artn/R-1.4.1/tests'
> > make[2]: Entering directory `/tmp_mnt/users/artn/R-1.4.1/tests'
> > make[3]: Entering directory 
> `/tmp_mnt/users/artn/R-1.4.1/tests/Examples'
> > make[4]: Entering directory 
> `/tmp_mnt/users/artn/R-1.4.1/tests/Examples'
> > make[4]: Leaving directory 
> `/tmp_mnt/users/artn/R-1.4.1/tests/Examples'
> > make[4]: Entering directory 
> `/tmp_mnt/users/artn/R-1.4.1/tests/Examples'
> > make[4]: *** Warning: File `Makefile' has modification time 
> in the future
> > (2002-04-19 11:17:56 > 2002-04-19 11:17:53)
> > collecting examples for package `base' ...
> > make[5]: Entering directory 
> `/tmp_mnt/users/artn/R-1.4.1/src/library'
> >  >>> Building/Updating help pages for package `base'
> >      Formats: text example 
> > make[5]: Leaving directory `/tmp_mnt/users/artn/R-1.4.1/src/library'
> > running code in `base-Ex.R' ...make[4]: *** [base-Ex.Rout] Error 1
> 
> What comes at the end of base-Ex.Rout.fail?
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: 
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: 
> (+45) 35327907
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From A.Nuzzo at motorola.com  Fri Apr 19 20:07:37 2002
From: A.Nuzzo at motorola.com (Nuzzo Art-CINT116)
Date: Fri, 19 Apr 2002 13:07:37 -0500
Subject: FW: [R] Problem compiling on HP-UX 10.20
Message-ID: <CF5B20DBDE16D4119B9800D0B73E984806453A71@il02exm25.comm.mot.com>

This appears to have run without a problem.  Here is part of the results:

> bY <-besselY(2,nu = nu <-seq(0,100,len=501))
> bY
  [1]   5.103757e-01   4.203932e-01   3.010522e-01   1.662137e-01
2.736566e-02
  [6]  -1.070324e-01  -2.316581e-01  -3.440740e-01  -4.442857e-01
-5.342464e-01
 [11]  -6.174081e-01  -6.983829e-01  -7.827559e-01  -8.770708e-01
-9.890092e-01
 [16]  -1.127784e+00  -1.304784e+00  -1.534540e+00  -1.836098e+00
-2.234979e+00
 [21]  -2.765943e+00  -3.476927e+00  -4.434680e+00  -5.732883e+00
-7.503913e+00
 [26]  -9.935989e+00  -1.329831e+01  -1.797805e+01  -2.453517e+01
-3.378380e+01
 [31]  -4.691400e+01  -6.567428e+01  -9.264681e+01  -1.316640e+02
-1.884421e+02
...
[486] -3.189664e+149 -7.956669e+149 -1.985626e+150 -4.957272e+150
-1.238132e+151
[491] -3.093642e+151 -7.733056e+151 -1.933793e+152 -4.837785e+152
-1.210766e+153
[496] -3.031450e+153 -7.593065e+153 -1.902654e+154 -4.769560e+154
-1.196113e+155
[501] -3.000826e+155
> summary(bY)
       Min.     1st Qu.      Median        Mean     3rd Qu.        Max. 
-3.001e+155 -1.067e+107  -1.976e+62 -9.961e+152  -2.059e+23   5.104e-01 
> 




Art Nuzzo



> -----Original Message-----
> From: Martin Maechler [mailto:maechler at stat.math.ethz.ch]
> Sent: Friday, April 19, 2002 12:30 PM
> To: Nuzzo Art-CINT116
> Cc: R-core at stat.math.ethz.ch
> Subject: Re: FW: [R] Problem compiling on HP-UX 10.20
> 
> 
> [ NB: Taken off R-help for the moment;
>     We should summarize when we found the problem/solution
> ]
> 
> >>>>> "Nuzzo" == Nuzzo Art-CINT116 <A.Nuzzo at motorola.com> writes:
> 
>     Nuzzo> Here is a copy of the last few lines in base-Ex.Rout.fail:
> 
>     >> x <- seq(3,500);yl <- c(-.3, .2)
>     >> plot(x,x, ylim = yl, ylab="",type='n', main = "Bessel Functions
>     Nuzzo> Y_nu(x)")
>     >> for(nu in nus){xx <- x[x > .6*nu]; 
> lines(xx,besselY(xx,nu=nu), col =
>     Nuzzo> nu+2)}
>     >> legend(300,-.08, leg=paste("nu=",nus), col = nus+2, lwd=1)
>     >> 
>     >> x <- seq(10,50000,by=10);yl <- c(-.1, .1)
>     >> plot(x,x, ylim = yl, ylab="",type='n', main = "Bessel Functions
>     Nuzzo> Y_nu(x)")
>     >> for(nu in nus){xx <- x[x > .6*nu]; 
> lines(xx,besselY(xx,nu=nu), col =
>     Nuzzo> nu+2)}
>     >> summary(bY <- besselY(2,nu = nu <- seq(0,100,len=501)))
>     Nuzzo> Min.     1st Qu.      Median        Mean     3rd 
> Qu.        Max. 
>     Nuzzo> -3.001e+155 -1.067e+107  -1.976e+62 -9.961e+152  
> -2.059e+23   5.104e-01 
>     >> which(bY >= 0)
>     Nuzzo> [1] 1 2 3 4 5
>     >> summary(bY <- besselY(2,nu = nu <- seq(3,300,len=51)))
>     Nuzzo> Error in vector("character", length) : negative 
> length vectors are not
>     Nuzzo> allowed
>     Nuzzo> In addition: There were 23 warnings (use 
> warnings() to see them)
>     Nuzzo> Execution halted
> 
> Thank you,
> now try 
> 
>  bY <- besselY(2,nu = nu <- seq(0,100,len=501))
>  bY
>  summary(bY)
> 
> (I guess the first (compuation) will do fine; and printing will
>  be the problem; but who knows ?)
> 
> On a recent 386-Linux, I get
> 
> > bY <- besselY(2,nu = nu <- seq(0,100,len=501))
> > bY
>   [1]   5.103757e-01   4.203932e-01   3.010522e-01   
> 1.662137e-01   2.736566e-02
>   [6]  -1.070324e-01  -2.316581e-01  -3.440740e-01  
> -4.442857e-01  -5.342464e-01
>  [11]  -6.174081e-01  -6.983829e-01  -7.827559e-01  
> -8.770708e-01  -9.890092e-01
>  [16]  -1.127784e+00  -1.304784e+00  -1.534540e+00  
> -1.836098e+00  -2.234979e+00
>  [21]  -2.765943e+00  -3.476927e+00  -4.434680e+00  
> -5.732883e+00  -7.503913e+00
>  [26]  -9.935989e+00  -1.329831e+01  -1.797805e+01  
> -2.453517e+01  -3.378380e+01
>  [31]  -4.691400e+01  -6.567428e+01  -9.264681e+01  
> -1.316640e+02  -1.884421e+02
> .................
> .................
> [481] -3.322931e+147 -8.271870e+147 -2.060002e+148 
> -5.132308e+148 -1.279200e+149
> [486] -3.189664e+149 -7.956669e+149 -1.985626e+150 
> -4.957272e+150 -1.238132e+151
> [491] -3.093642e+151 -7.733056e+151 -1.933793e+152 
> -4.837785e+152 -1.210766e+153
> [496] -3.031450e+153 -7.593065e+153 -1.902654e+154 
> -4.769560e+154 -1.196113e+155
> [501] -3.000826e+155
> > summary(bY)
>        Min.     1st Qu.      Median        Mean     3rd Qu.   
>      Max. 
> -3.001e+155 -1.067e+107  -1.976e+62 -9.961e+152  -2.059e+23   
> 5.104e-01 
> 
> ---------
> 
> Martin Maechler <maechler at stat.math.ethz.ch>	
http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jiscmail-support at jiscmail.ac.uk  Fri Apr 19 21:44:16 2002
From: jiscmail-support at jiscmail.ac.uk (jiscmail-support@jiscmail.ac.uk)
Date: Fri, 19 Apr 2002 20:44:16 +0100
Subject: [R] Your mail sent to mailbase.ac.uk with subject  Meeting notice
Message-ID: <200204191944.g3JJiGo16013@ori.rl.ac.uk>

This Mailbase list has moved to JISCmail.

For further information see http://www.jiscmail.ac.uk/docs/transition.htm.

The email message that you sent has not been delivered, if you
want your email to be delivered you must re-address it as described on the
pages referenced above.

If you have any queries about this message then please contact

jiscmail-helpline at jiscmail.ac.uk


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wall at chop.swmed.edu  Fri Apr 19 22:26:06 2002
From: wall at chop.swmed.edu (Mark Wall)
Date: Fri, 19 Apr 2002 15:26:06 -0500
Subject: [R] 2D cluster of 2D matrix in R?
Message-ID: <a05101001b8e62cde7200@[129.112.5.53]>

Hello!

I would love to use R for the following 2 tasks, but am unable to 
determine if R is well suited for this.  My primary question- is this 
possible in R?  Secondary- if yes, how?

We routinely use MatLab with the Statistics Tool Box to manipulate 
and plot a 2 dimensional matrix (m x n) of real numbers.  If you 
think of each dimension as an array of vectors (e.g. a collection of 
m vectors (each n-dimensions), we 1) cluster these (and generate a 
dendrogram) for both dimensions as below using a city-block distance 
measure:

original matrix with labels
----------------
    W X Y Z
A  0 1 0 0
B  0 1 0 1
C  5 0 0 0
D  0 0 0 2
E  5 0 0 0

Clustered matrix
----------------
    W Y X Z
E  5 0 0 0
C  5 0 0 0
A  0 0 1 0
B  0 0 1 1
D  0 0 0 2

In reality, m and n are between 50 and 1000 so we 2) display these 
matrices as an x-y-color plot for easy visualization.  Think of this 
as a square frame with each pixel representing a matrix element.  The 
values are represented by a continuous color scale (dark blue = low 
values, through yellow to red = high values).  I can provide a JPEG 
if necessary.

With large matrices, we isolate sub-clusters by creating new matrices 
that are the appropriate slices of the original matrix and then 
repeat steps 1 and 2 for each sub-cluster.


Thank you,

Mark Wall
---------
HHMI/UT Southwestern Medical Center
5323 Harry Hines Blvd.
Dallas, Texas  75390-9050
USA
214.648.5050
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hodgess at uhddx01.dt.uh.edu  Fri Apr 19 23:07:39 2002
From: hodgess at uhddx01.dt.uh.edu (Erin Hodgess)
Date: Fri, 19 Apr 2002 16:07:39 -0500 (CDT)
Subject: [R] exponential smoothing
Message-ID: <200204192107.QAA24926@uhddx01.dt.uh.edu>

Dear R People:

Is there a function for exponential smoothing, please?

R version 1.4.1 for Windows.

Thanks in advance!  Have a great weekend!

Sincerely,
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
1 Main Street 
Houston, TX 77002
mailto: hodgess at uhddx01.dt.uh.edu
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From reid_huntsinger at merck.com  Fri Apr 19 23:32:57 2002
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Fri, 19 Apr 2002 17:32:57 -0400
Subject: [R] 2D cluster of 2D matrix in R?
Message-ID: <2C23DE2983BE034CB1CB90DB6B813FD639E954@uswpmx11.merck.com>

The "image" function displays a matrix as an image. You have full control
over the color map. You might also want to look at the "pixmap" package. R
certainly also has packages available to do clustering of many kinds
(mclust, mva, e1071, multiv, cluster, cclust, ...?) but I'm afraid I don't
quite understand what your procedure is. Perhaps you could elaborate a
little? It sounds like you do hierarchical clustering of some type twice,
once for rows and again for columns. The fact that your example has the
column labels permuted also suggests this to me. ???

Reid Huntsinger

-----Original Message-----
From: Mark Wall [mailto:wall at chop.swmed.edu]
Sent: Friday, April 19, 2002 4:26 PM
To: r-help at stat.math.ethz.ch
Subject: [R] 2D cluster of 2D matrix in R?


Hello!

I would love to use R for the following 2 tasks, but am unable to 
determine if R is well suited for this.  My primary question- is this 
possible in R?  Secondary- if yes, how?

We routinely use MatLab with the Statistics Tool Box to manipulate 
and plot a 2 dimensional matrix (m x n) of real numbers.  If you 
think of each dimension as an array of vectors (e.g. a collection of 
m vectors (each n-dimensions), we 1) cluster these (and generate a 
dendrogram) for both dimensions as below using a city-block distance 
measure:

original matrix with labels
----------------
    W X Y Z
A  0 1 0 0
B  0 1 0 1
C  5 0 0 0
D  0 0 0 2
E  5 0 0 0

Clustered matrix
----------------
    W Y X Z
E  5 0 0 0
C  5 0 0 0
A  0 0 1 0
B  0 0 1 1
D  0 0 0 2

In reality, m and n are between 50 and 1000 so we 2) display these 
matrices as an x-y-color plot for easy visualization.  Think of this 
as a square frame with each pixel representing a matrix element.  The 
values are represented by a continuous color scale (dark blue = low 
values, through yellow to red = high values).  I can provide a JPEG 
if necessary.

With large matrices, we isolate sub-clusters by creating new matrices 
that are the appropriate slices of the original matrix and then 
repeat steps 1 and 2 for each sub-cluster.


Thank you,

Mark Wall
---------
HHMI/UT Southwestern Medical Center
5323 Harry Hines Blvd.
Dallas, Texas  75390-9050
USA
214.648.5050
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._

------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jmiyamot at u.washington.edu  Sat Apr 20 00:37:45 2002
From: jmiyamot at u.washington.edu (John Miyamoto)
Date: Fri, 19 Apr 2002 15:37:45 -0700 (PDT)
Subject: [R] Multidimensional scaling
Message-ID: <Pine.A41.4.44.0204191431210.24232-100000@mead5.u.washington.edu>

A student of mine wants to use R to do some nonmetric multidimensional
scaling.  According to the R FAQ, there's a package called pcurve that
computes multidimensional scaling solutions, but I was not able to locate
it the contrib page (I am a Windows user with R version 1.4.1).  Can
anyone tell me whether it is possible to do nonmetric multidimensional
scaling with R, and if so, how?

John

--------------------------------------------------------------------
John Miyamoto, Dept. of Psychology, Box 351525
University of Washington, Seattle, WA 98195-1525
Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
Homepage http://faculty.washington.edu/jmiyamot/
--------------------------------------------------------------------



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at blindglobe.net  Sat Apr 20 00:56:34 2002
From: rossini at blindglobe.net (A.J. Rossini)
Date: 19 Apr 2002 15:56:34 -0700
Subject: [R] Multidimensional scaling
In-Reply-To: <Pine.A41.4.44.0204191431210.24232-100000@mead5.u.washington.edu>
References: <Pine.A41.4.44.0204191431210.24232-100000@mead5.u.washington.edu>
Message-ID: <87g01rxpp9.fsf@jeeves.blindglobe.net>

>>>>> "john" == John Miyamoto <jmiyamot at u.washington.edu> writes:

    john> A student of mine wants to use R to do some nonmetric multidimensional
    john> scaling.  According to the R FAQ, there's a package called pcurve that
    john> computes multidimensional scaling solutions, but I was not able to locate
    john> it the contrib page (I am a Windows user with R version 1.4.1).  Can
    john> anyone tell me whether it is possible to do nonmetric multidimensional
    john> scaling with R, and if so, how?

I thought there was one in MASS?

isoMDS(MASS)            Kruskal's Non-metric Multidimensional Scaling
cmdscale(mva)           Classical (Metric) Multidimensional Scaling

(see CRAN for the libraries).

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M-W: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my friday location is usually completely unpredictable.)


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Sat Apr 20 01:20:13 2002
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Fri, 19 Apr 2002 19:20:13 -0400
Subject: [R] Multidimensional scaling
In-Reply-To: <Pine.A41.4.44.0204191431210.24232-100000@mead5.u.washington.edu>; from jmiyamot@u.washington.edu on Fri, Apr 19, 2002 at 03:37:45PM -0700
References: <Pine.A41.4.44.0204191431210.24232-100000@mead5.u.washington.edu>
Message-ID: <20020419192013.A17558@cattell.psych.upenn.edu>

I just searched http://finzi.psych.upenn.edu (the search part)
and it seems that there are several packages that do
multidimensional scaling: MASS (isoMDS), mva (cmdscale), etc.

I certainly am not in a position to compare them.

(I think it was invented by a psychologist, Roger Shepard.)

Jon

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From sundard at pdf.com  Sat Apr 20 03:48:23 2002
From: sundard at pdf.com (Sundar Dorai-Raj)
Date: Fri, 19 Apr 2002 20:48:23 -0500
Subject: [R] Multidimensional scaling
References: <Pine.A41.4.44.0204191431210.24232-100000@mead5.u.washington.edu>
Message-ID: <3CC0C8E7.908EFB84@pdf.com>

pcurve is on the contrib webpage I have bookmarked:

http://cran.r-project.org/src/contrib/PACKAGES.html

According to the info provided on the web site the pcurve library
requires the modreg, mva, mgcv, and MASS libraries.

Sundar


John Miyamoto wrote:
> 
> A student of mine wants to use R to do some nonmetric multidimensional
> scaling.  According to the R FAQ, there's a package called pcurve that
> computes multidimensional scaling solutions, but I was not able to locate
> it the contrib page (I am a Windows user with R version 1.4.1).  Can
> anyone tell me whether it is possible to do nonmetric multidimensional
> scaling with R, and if so, how?
> 
> John
> 
> --------------------------------------------------------------------
> John Miyamoto, Dept. of Psychology, Box 351525
> University of Washington, Seattle, WA 98195-1525
> Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
> Homepage http://faculty.washington.edu/jmiyamot/
> --------------------------------------------------------------------
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 

Sundar Dorai-Raj, Ph.D.
Statistical Methods Engineer
PDF Solutions, Inc.
(972) 889-3085 x216
(214) 392-7619 cell
sundard at pdf.com
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cjlu at ibm.stat.ncku.edu.tw  Sat Apr 20 04:17:10 2002
From: cjlu at ibm.stat.ncku.edu.tw (Lu Chi-Hsien Joseph)
Date: Sat, 20 Apr 2002 11:17:10 +0900
Subject: [R] Durbin-Watson test in packages "car" and "lmtest"
Message-ID: <200204200217.LAA34890@ibm.stat.ncku.edu.tw>

The difference that I found in applying Durbin-Watson test in
"car" and "lmtest" is the latter only works for testing
NH: rho = 0 versus AH: rho > 0.

C. Joseph Lu
Department of Statistics
National Cheng-Kung University
Tainan, Taiwan
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ggrothendieck at yifan.net  Sat Apr 20 05:10:18 2002
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Fri, 19 Apr 2002 23:10:18 -0400
Subject: [R] exponential smoothing
In-Reply-To: <200204192107.QAA24926@uhddx01.dt.uh.edu>
Message-ID: <3CC0A3DA.22846.C758C1@localhost>

See 

http://maths.newcastle.edu.au/~rking/R/help/01a/1164.html


On 19 Apr 2002 at 16:07, Erin Hodgess wrote:

> Dear R People:
> 
> Is there a function for exponential smoothing, please?
> 
> R version 1.4.1 for Windows.
> 
> Thanks in advance!  Have a great weekend!
> 
> Sincerely,
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> 1 Main Street 
> Houston, TX 77002
> mailto: hodgess at uhddx01.dt.uh.edu
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sat Apr 20 09:53:58 2002
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 20 Apr 2002 08:53:58 +0100 (GMT Daylight Time)
Subject: [R] exponential smoothing
In-Reply-To: <200204192107.QAA24926@uhddx01.dt.uh.edu>
Message-ID: <Pine.WNT.4.44.0204200852030.2660-100000@Reeve>

On Fri, 19 Apr 2002, Erin Hodgess wrote:

> Dear R People:
>
> Is there a function for exponential smoothing, please?
>
> R version 1.4.1 for Windows.
>
> Thanks in advance!  Have a great weekend!

It's in the upcoming 1.5.0, as part of Holt-Winters.  It can also be done
simply via filter(): exponential smoothing is applying a one-term recursive
filter, that is foreasting as an AR(1) process.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sat Apr 20 10:05:24 2002
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 20 Apr 2002 09:05:24 +0100 (GMT Daylight Time)
Subject: [R] Multidimensional scaling
In-Reply-To: <Pine.A41.4.44.0204191431210.24232-100000@mead5.u.washington.edu>
Message-ID: <Pine.WNT.4.44.0204200855280.2660-100000@Reeve>

On Fri, 19 Apr 2002, John Miyamoto wrote:

> A student of mine wants to use R to do some nonmetric multidimensional
> scaling.  According to the R FAQ, there's a package called pcurve that
> computes multidimensional scaling solutions, but I was not able to locate
> it the contrib page (I am a Windows user with R version 1.4.1).  Can
> anyone tell me whether it is possible to do nonmetric multidimensional
> scaling with R, and if so, how?

pcurve fails make pkgcheck on Windows, *as mentioned in the ReadMe on that
page on CRAN*.  Its isomds function is a tiny variant of a copy of an older
vsersion of my isoMDS function in package MASS (and the rest of it seems
based on princurve or is yet another PCA function: there are already three
others available for R).

There are several other possibilities, cmdscale{mva}, sammon{MASS},
isoMDS{MASS} and xgvis{xgobi} all having some merits.  `nonmetric MDS' is
like `nonlinear models': it tells you what it is not (and even then the
term `metric MDS' is not always used in the same sense).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From zeileis at ci.tuwien.ac.at  Sat Apr 20 13:44:29 2002
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Sat, 20 Apr 2002 13:44:29 +0200
Subject: [R] Durbin-Watson test in packages "car" and "lmtest"
References: <200204200217.LAA34890@ibm.stat.ncku.edu.tw>
Message-ID: <3CC1549D.78BB855E@ci.tuwien.ac.at>

Lu Chi-Hsien Joseph wrote:
> 
> The difference that I found in applying Durbin-Watson test in
> "car" and "lmtest" is the latter only works for testing
> NH: rho = 0 versus AH: rho > 0.

That is true. The one-sided alternative is in my experience the one of
most interest. But I want to implement an alternative argument as in
most classical tests for the next version of lmtest. I just didn't get
round to do it.

Nevertheless, even for the same alternative there can be differences
between the p values due to the different computing techniques in
dwtest() and durbin.watson()...
Z


> C. Joseph Lu
> Department of Statistics
> National Cheng-Kung University
> Tainan, Taiwan
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hammour at msn.com  Fri Apr 19 23:05:34 2002
From: hammour at msn.com (Ahmad Abu Hammour)
Date: Fri, 19 Apr 2002 17:05:34 -0400
Subject: [R] Durbin-Watson test in packages "car" and "lmtest"
Message-ID: <OE82j0aImPiZxOASWTg0001df30@hotmail.com>

Hi Torsten,
Here is an example in which P-values have a significant difference. The data is a sub sample of a larger one.
Basically the model I am using is as follows:
y_{t+2}= y_{t+1} + y_t + I(x_{t+1}-z_{t+1}-w_{t+1}) +e_{t+2}
  
> ydata
                  y            z           w         x
 [1,]  0.0101705342 -5.363636567  0.80677087 -2.425968
 [2,] -0.0040963887 -4.930336567 -0.01515276 -1.852668
 [3,]  0.0007996203 -2.795136567  0.28412361 -0.849268
 [4,]  0.0231375722 -2.523036567 -0.33650002 -0.315968
 [5,]  0.0576658597 -2.925936567 -0.68112365  0.060732
 [6,]  0.0930807057 -2.283836567 -1.59374728  0.214032
 [7,]  0.0904861271 -1.908436567 -3.15057091  0.347332
 [8,]  0.0815802452 -3.063936567 -3.60669454 -0.175968
 [9,]  0.0463679856 -3.947236567 -2.89361816 -1.012668
[10,]  0.0283314000 -3.528136567 -1.68974179 -1.522668
[11,]  0.0158693958 -2.890536567 -1.03456542 -1.629268
[12,] -0.0177988767 -2.165736567 -0.23008905 -1.532668
[13,] -0.0263232785 -2.400436567 -0.29991268 -1.369268
[14,] -0.0377695478 -3.243136567 -0.31953631 -0.539268
[15,] -0.0520095622 -3.241336567  0.22174006  0.120732
[16,] -0.0773138815 -2.765236567 -0.22328356  1.467332
[17,] -0.0804307590 -2.833236567  0.09209281  2.107332
[18,] -0.0446189151 -3.710136567  0.57246918  2.057332
[19,] -0.0439761920 -4.232636567  0.11764555  2.687332
[20,] -0.0508314286 -3.445136567  0.91252192  4.874032
[21,] -0.0373526376 -2.123836567  1.03269829  5.340732
[22,] -0.0363366045 -4.549336567  1.16137466  3.614032
[23,] -0.0119795294 -4.660636567  2.10495103  1.744032
[24,] -0.0271166745  0.940863433  2.73172741  5.450732
[25,] -0.0319279899  2.972463433  3.93230378  7.954032
[26,] -0.0285519284  2.601663433  4.25698015  9.447332
[27,] -0.0362890374  3.900363433  4.49975652 11.397332
[28,] -0.0193261619  2.440563433  4.24003289  7.057332
[29,] -0.0211604332  4.133063433  3.62460926  5.907332
[30,] -0.0393599621  4.764863433  3.78798563  6.740732
[31,] -0.0368496844  2.967363433  3.09016201  5.137332
[32,] -0.0111656400  2.374163433  2.32173838  1.820732
[33,] -0.0049543837  2.858663433  0.59471475  0.570732
[34,] -0.0085112660  3.900063433 -0.96020888  0.424032
[35,]  0.0002988086  3.956163433 -1.40353251  0.500732
[36,] -0.0021387277  2.276463433 -1.99135614  0.720732
[37,] -0.0143497002  2.857863433 -1.40157977  1.270732
[38,] -0.0459512047  3.589163433 -1.78060340  2.574032
[39,] -0.0620556482  4.248163433 -2.43422702  3.537332
[40,] -0.0665723041  3.225363433 -2.45305065  1.830732
[41,] -0.0990262190  2.638163433 -2.34577428  1.634032
[42,] -0.0993943457  2.160963433 -2.00509791  0.780732
[43,] -0.0896954664  1.651763433 -1.79992154  0.164032
[44,] -0.1047509912  2.106963433 -1.59274517  0.117332
[45,] -0.1188326548  3.230463433 -1.40576880  2.007332
[46,] -0.1012159404  2.484063433 -1.60469242 -0.209268
[47,] -0.0975617833  2.185163433 -1.23841605 -0.442668
[48,] -0.0859923186  1.244563433 -0.99983968 -0.495968
[49,] -0.0467949427 -0.185636567 -1.19776331 -1.649268
[50,] -0.0351160760 -0.510836567 -0.50778694 -0.569268
[51,] -0.0233943108 -0.356136567 -0.53781057  0.347332
[52,] -0.0080094290  0.005063433 -0.71733420 -0.569268
[53,]  0.0312603960 -0.149336567 -0.69205783 -0.349268
[54,]  0.0614944090  0.181063433 -0.76188145  0.237332
[55,]  0.0775709808  0.795863433 -0.58080508  1.110732
[56,]  0.0952235601  1.131763433 -0.38712871  1.907332
[57,]  0.1069545973  1.509763433  0.06534766  2.887332
[58,]  0.1136253179  1.785763433  0.64482403  3.450732
[59,]  0.1275201332  1.348463433  1.06650040  3.410732
[60,]  0.1387864450  0.581263433  1.05767677  3.444032
[61,]  0.1244438565  1.253563433  1.35555315  4.164032
[62,]  0.1344048716  0.334263433  0.69162952  4.844032
[63,]  0.1487305153 -0.634036567  0.37670589  4.010732
[64,]  0.1420063384 -0.159036567  1.22928226  3.190732
[65,]  0.1469999823 -0.707536567  1.67200000  1.200732
> library(car)
Attaching package `car':

        The following object(s) are masked from package:base :
         dfbetas rstudent  
> library(lmtest)
> lmy=lm(y[-c(1,2)]~y[-c(1,65)]+y[-c(64,65)]+I(x-z-w)[-c(64,65)]-1,data=as.ts(ydata))
> dwtest(lmy)
        Durbin-Watson test
data:  lmy  
DW = 2.0077, p-value = 0.4404
> durbin.watson(lmy)
 lag Autocorrelation D-W Statistic p-value
   1     -0.01370151      2.007701    0.92
>  
So, which P-value should I adopt 0.44 or 0.92?
Thank you for your help.
Ahmad Abu Hammour
  
----- Original Message -----
From: Torsten Hothorn
Sent: Friday, April 19, 2002 4:51 AM
To: Ahmad Abu Hammour
Cc: R-help at stat.math.ethz.ch
Subject: Re: [R] Durbin-Watson test in packages "car" and "lmtest"
  
> Hi,
> P-values in Durbin-Watson test obtained through the use of
> functions available in packages "lmtest" and "car" are different. The
> difference is quite significant. function "dwtest" in "lmtest" is much
> faster than "burbinwatson" in "car". Actually, you can take a nap while
> the latter trying to calculated Durbin-Watson test. My question is which
> p-value is better?

The answer is essencially given in ?durbin.watson and ?dwtest. The latter
states that

The p value is computed
     using a Fortran version of the Applied Statistics Algorithm AS 153
     by Farebrother (1980, 1984). This algorithm is called "pan" or
     "gradsol". For large sample sizes the algorithm might fail to
     compute the p value; in that case a warning is printed and an
     approximate p value will be given; this p value is computed using
     a normal approximation with mean and variance of the Durbin-Watson
     test statistic.

while ?durbin.watson says

  simulate: if `TRUE' p-values will be estimated by bootstrapping.

What is a "quite significant" difference for p-values?

Looking at the example from ?durbin.watson gives:

R> durbin.watson(lm(fconvict ~ tfr + partic + degrees + mconvict,
data=Hartnagel))
lag Autocorrelation D-W Statistic p-value
   1        0.688345     0.6168636       0
R> dwtest(fconvict ~ tfr + partic + degrees + mconvict, data=Hartnagel)

        Durbin-Watson test

data:  fconvict ~ tfr + partic + degrees + mconvict
DW = 0.6169, p-value = 6.96e-09

which is fairly close, so you might give us more details (that is: a
working example) to see what the "difference" is (that is: a bug in
either function or a difference due to simulation error / bad
approximation ...).

Torsten

>
> Thank you,
> Ahmad Abu Hammour
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20020419/85bd6b79/attachment.html

From gpagnon at emory.edu  Sat Apr 20 16:52:53 2002
From: gpagnon at emory.edu (Giuseppe Pagnoni)
Date: Sat, 20 Apr 2002 10:52:53 -0400 (EDT)
Subject: [R] integration of a discrete function
Message-ID: <Pine.GSO.4.05.10204201051170.2481-100000@paladin>

Dear R list

I am looking for a function in R that computes the integration of a
discrete curve, such as a power spectrum, in a specified interval (in my
case, that would be 'power in a certain frequency band').  I found only
functions, such as 'integrate', that perform adaptive quadrature on
analytic functions, and not on a curve specified as a set of (x,y) pairs.
I have the impression that I am not looking in the right place....  or I
should code the algorithm myself?

thanks for any suggestion

    Giuseppe


-----------------
Giuseppe Pagnoni
Emory University
Dept.of Psychiatry and Behavioral Sciences
1639 Pierce Dr.
Suite 4000, WMB Bldg.
Atlanta, GA, 30322
phone: 404-7128431
fax: 404-7273233

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sat Apr 20 18:41:56 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat, 20 Apr 2002 17:41:56 +0100 (BST)
Subject: [R] Durbin-Watson test in packages "car" and "lmtest"
In-Reply-To: <OE82j0aImPiZxOASWTg0001df30@hotmail.com>
Message-ID: <Pine.LNX.4.31.0204201722290.16684-100000@gannet.stats>

1) Achim pointed out that dwtest was one-sided and durbin.watson is
two-sided (from memory), so these are both indicators of close to
expectation.

2) Even if 0.44 and 0.92 were comparable, would it make the slightest
difference to your conclusions?  You have no evidence of serial
correlation either way.

3) Do worry about the big things first.  Your model (with the missing
coefficients supplied on the RHS, I presume) is an autoregression, and so
neither lm nor the Durbin-Watson test is entirely appropriate.  You should
be using functions such as gls (nlme) or arima0 (ts) to fit this model.
(It may be that least-squares will do a reasonable job, but it's always
suboptimal and the easiest way to find out by how much is to do the job
properly.  Things have changed since that 1951 paper.)

On Fri, 19 Apr 2002, Ahmad Abu Hammour wrote:

> Here is an example in which P-values have a significant difference.
  The data is a sub sample of a larger one.
> Basically the model I am using is as follows:
> y_{t+2}= y_{t+1} + y_t + I(x_{t+1}-z_{t+1}-w_{t+1}) +e_{t+2}

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From domi at sun11.ukl.uni-freiburg.de  Sat Apr 20 19:04:02 2002
From: domi at sun11.ukl.uni-freiburg.de (1-27206531-0-90000491)
Date: Sat, 20 Apr 2002 19:04:02 +0200 (MET DST)
Subject: [R] manipulating colors in lattice
In-Reply-To: <Pine.LNX.4.31.0204171827350.16120-100000@gannet.stats>
Message-ID: <Pine.SOL.4.21.0204201900400.3074-100000@sun11.ukl.uni-freiburg.de>

Dear Prof. Ripley

Using your advice:

>library(lattice)
>library(nlme)
>data(Orthodont)
>plot(Orthodont)

>lset(theme = c("bw"))
Error in trellis.par.set("background", list(col = bg)) : 
        Object "bg" not found

I also do not understand the description of the help file:

>Usage:
>
>    lset(theme = c("col.bg", "white.bg", "bw"), file)
>
>Arguments:
>
>    file: the name of a file that will be `source()'d.

which file should be sourced in my case?

Also one sentence in the help file seems strange to me:

>     `lset' implements a concept of `themes' in Lattice. Themes are
>     predefined values of `trellis.settings' that modify the overall
>     look. The only current theme significantly different from the
>     defaults is the `"white.bg"' theme, which hopefully

The sentence ends after hopefully and I expect something after hopefully

I feel that the concept of themes is exactly what I need. But I can't
activate it. I also searching for examples in the help. But I cant find
one.

After reading cross help files and with some try and error I found a dirty
solution for my problem.

library(nlme)
library(lattice)
trellis.device(device="windows", color=F) # sets the output to bw
data(Orthodont)
plot(Orthodont)

Now I got exactly what I want. But if I want to export the plot to jpeg:

trellis.device(device="jpeg", color=F)
if(interactive()) {
	jpeg("c:/temp/mist.jpg", quality = 100)
	plot(Orthodont)
	dev.off()
}

The Jpeg- file is white without a picture. Then I tried to export it via
the GUI. This works fine. 

Now my question. How can I make proper use of "theme"? I'm aware that my
problem is probably caused by not understanding the principles of making
figures with Trellis. But perhaps you, ore someone else can clarify my
confuse thoughts or point me to some examples.

Thank you for your help,

Dominik
--------------------------------------------------------------------------
Domink Grathwohl; Bussstr. 34; D-79102 Freiburg



On Wed, 17 Apr 2002 ripley at stats.ox.ac.uk wrote:

> ?lset
> ?trellis.settings.
> 
> Reminder: Lattice is not Trellis and it is built on grid not S graphics,
> so you can't mix in ideas from S graphics.
> 
> If you want a black-and-white plot, use lset to set the bw theme.
> 
> 
> On Wed, 17 Apr 2002, 1-27206531-0-90000491 wrote:
> 
> > Dear R-users,
> >
> > I use:
> >
> > $platform
> > [1] "i386-pc-mingw32"
> > $arch
> > [1] "x86"
> > $os
> > [1] "Win32"
> > $system
> > [1] "x86, Win32"
> > $status
> > [1] ""
> > $major
> > [1] "1"
> > $minor
> > [1] "4.1"
> > $year
> > [1] "2002"
> > $month
> > [1] "01"
> > $day
> > [1] "30"
> > $language
> > [1] "R"
> >
> > I try  to repeat the analysis of Jose Pinheiro and Douglas Bates described
> > in their book: Mixed-Effects Models in S and S-PLUS.
> >
> > library(lattice)
> > library(nlme)
> > data(Orthodont)
> > plot(Orthodont)
> > fm1OrthF.lis <- lmList(distance ~ age, data=Orthodont)
> > plot(intervals(fm1OrthF.lis))
> > fm1OrthF <- lme(distance ~ age, data=Orthodont, random= ~ 1| Subject)
> > plot(augPred(fm1OrthF), aspect="xy", grid=TRUE)
> >
> > My question: How can I manipulate the colours of the different plots, say
> > changing symbols and lines from light-blue to black?
> > e.g. plot(Orthodont, col="black") changes only symbols to black and I have
> > no idea how to change the lines to black.
> >
> > Thanks in advance,
> >
> > Dominik
> >
> > ----------------------------------------------------------------------------
> > Dominik Grathwohl; Bussstr. 34; D-79102 Freiburg
> >
> > -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> > _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deepayansarkar at yahoo.com  Sat Apr 20 20:19:57 2002
From: deepayansarkar at yahoo.com (Deepayan Sarkar)
Date: Sat, 20 Apr 2002 11:19:57 -0700 (PDT)
Subject: [R] manipulating colors in lattice
In-Reply-To: <Pine.SOL.4.21.0204201900400.3074-100000@sun11.ukl.uni-freiburg.de>
Message-ID: <20020420181957.48374.qmail@web13907.mail.yahoo.com>


--- 1-27206531-0-90000491 <domi at sun11.ukl.uni-freiburg.de> wrote:
> Dear Prof. Ripley
> 
> Using your advice:
> 
> >library(lattice)
> >library(nlme)
> >data(Orthodont)
> >plot(Orthodont)
> 
> >lset(theme = c("bw"))
> Error in trellis.par.set("background", list(col = bg)) : 
>         Object "bg" not found

Sorry, that's a bug in lset. you can get the equivalent effect by

trellis.device(new = FALSE, col = FALSE, bg = "white")

(if you already have a device open).


> I also do not understand the description of the help file:
> 
> >Usage:
> >
> >    lset(theme = c("col.bg", "white.bg", "bw"), file)
> >
> >Arguments:
> >
> >    file: the name of a file that will be `source()'d.
> 
> which file should be sourced in my case?

Ignore this option, it has been scrapped in the next version. See below.

> Also one sentence in the help file seems strange to me:
> 
> >     `lset' implements a concept of `themes' in Lattice. Themes are
> >     predefined values of `trellis.settings' that modify the overall
> >     look. The only current theme significantly different from the
> >     defaults is the `"white.bg"' theme, which hopefully
> 
> The sentence ends after hopefully and I expect something after hopefully

Sorry, another bug :)


> I feel that the concept of themes is exactly what I need. But I can't
> activate it. I also searching for examples in the help. But I cant find
> one.

As the documentation says, this was a very preliminary implementation of 
themes. The development version (to be released with R 1.5.0) handles 
these things very differently, and hopefully in a much better way. Till 
then, it's probably better not to use lset directly, but rather use 
trellis.device, trellis.par.get and trellis.par.set. In particular, to change
the background to white, you need 

trellis.par.set("background", list(col = "white"))

To change the default plotting symbol and line color, you'll have to change
the "plot.symbol" and "plot.line" components.


> After reading cross help files and with some try and error I found a dirty
> solution for my problem.
> 
> library(nlme)
> library(lattice)
> trellis.device(device="windows", color=F) # sets the output to bw
> data(Orthodont)
> plot(Orthodont)

Why is this a dirty solution ? It looks perfect to me.

> Now I got exactly what I want. But if I want to export the plot to jpeg:
> 
> trellis.device(device="jpeg", color=F)
> if(interactive()) {
>  jpeg("c:/temp/mist.jpg", quality = 100)
>  plot(Orthodont)
>  dev.off()
> }

I'm not sure why this might happen. But why are you calling jpeg() again ?
trellis.device does that itself (with a filename of "Rplot.jpeg" probably, 
unless you specify a filename).

> The Jpeg- file is white without a picture. Then I tried to export it via
> the GUI. This works fine. 
> 
> Now my question. How can I make proper use of "theme"? I'm aware that my
> problem is probably caused by not understanding the principles of making
> figures with Trellis. But perhaps you, ore someone else can clarify my
> confuse thoughts or point me to some examples.

Depends on what you want to do. The standard way of changing settings in 
Trellis is using trellis.par.get and trellis.par.set, look at the help page
for those functions for how to use them. If you want to change many settings,
this can become a bit tedious, as you would have to call these functions many 
times, and it might be a better idea to store the calls in a file and source 
them all at once.

Incidentally, all these problems with light colors are caused by a somewhat
serious bug in trellis.device(), which assigns the background color
incorrectly.
The actual intended defaults can be simulated by 

trellis.device(device=<whatever>, col = TRUE, bg = "#909090")

for color devices and

trellis.device(device=<whatever>, col = FALSE, bg = "white")

for black and white devices.

Hope that helps.


> Thank you for your help,
> 
> Dominik
> --------------------------------------------------------------------------
> Domink Grathwohl; Bussstr. 34; D-79102 Freiburg
> 
> 
> 
> On Wed, 17 Apr 2002 ripley at stats.ox.ac.uk wrote:
> 
> > ?lset
> > ?trellis.settings.
> > 
> > Reminder: Lattice is not Trellis and it is built on grid not S graphics,
> > so you can't mix in ideas from S graphics.
> > 
> > If you want a black-and-white plot, use lset to set the bw theme.
> > 
> > 
> > On Wed, 17 Apr 2002, 1-27206531-0-90000491 wrote:
> > 
> > > Dear R-users,
> > >
> > > I use:
> > >
> > > $platform
> > > [1] "i386-pc-mingw32"
> > > $arch
> > > [1] "x86"
> > > $os
> > > [1] "Win32"
> > > $system
> > > [1] "x86, Win32"
> > > $status
> > > [1] ""
> > > $major
> > > [1] "1"
> > > $minor
> > > [1] "4.1"
> > > $year
> > > [1] "2002"
> > > $month
> > > [1] "01"
> > > $day
> > > [1] "30"
> > > $language
> > > [1] "R"
> > >
> > > I try  to repeat the analysis of Jose Pinheiro and Douglas Bates
> described
> > > in their book: Mixed-Effects Models in S and S-PLUS.
> > >
> > > library(lattice)
> > > library(nlme)
> > > data(Orthodont)
> > > plot(Orthodont)
> > > fm1OrthF.lis <- lmList(distance ~ age, data=Orthodont)
> > > plot(intervals(fm1OrthF.lis))
> > > fm1OrthF <- lme(distance ~ age, data=Orthodont, random= ~ 1| Subject)
> > > plot(augPred(fm1OrthF), aspect="xy", grid=TRUE)
> > >
> > > My question: How can I manipulate the colours of the different plots, say
> > > changing symbols and lines from light-blue to black?
> > > e.g. plot(Orthodont, col="black") changes only symbols to black and I
> have
> > > no idea how to change the lines to black.
> > >
> > > Thanks in advance,
> > >
> > > Dominik
> > >
> > >
> ----------------------------------------------------------------------------
> > > Dominik Grathwohl; Bussstr. 34; D-79102 Freiburg
> > >
> > >
>
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > > r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > > Send "info", "help", or "[un]subscribe"
> > > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> > >
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> > >
> > 
> > -- 
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272860 (secr)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > 
> >
>
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> >
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> > 
> > 
> 
>
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

__________________________________________________

Yahoo! Games - play chess, backgammon, pool and more

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From klavan at tiscalinet.it  Sat Apr 20 20:58:54 2002
From: klavan at tiscalinet.it (Ambrosini Alessandro)
Date: Sat, 20 Apr 2002 20:58:54 +0200
Subject: [R] Problem with a matrix
Message-ID: <PPEGLLABFLFCJDLCGPGHGEHPCAAA.klavan@tiscalinet.it>

I have a scattered matrix that I have to import from an external file. In
this case all the lines could have a different size. The graph is oriented.
I give you an example:
a b c
b a c d
c b

The first row expresses that "a" has a direct path with "b" and also with
"c".
In the second "b" has a path with "a" and one with "c". In the third "c"
there is a direct path with "b".
I want to obtain the adjacency matrix.  In this case it is:
0 1 1 0
1 0 1 1
0 1 0 0
0 0 0 0

What have I to do?
Please help me. Excuse me for my english.
Alessandro Ambrosini

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Sat Apr 20 23:33:47 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 20 Apr 2002 23:33:47 +0200
Subject: [R] Problem with a matrix
In-Reply-To: <PPEGLLABFLFCJDLCGPGHGEHPCAAA.klavan@tiscalinet.it>
References: <PPEGLLABFLFCJDLCGPGHGEHPCAAA.klavan@tiscalinet.it>
Message-ID: <x2hem6cax0.fsf@blueberry.kubism.ku.dk>

"Ambrosini Alessandro" <klavan at tiscalinet.it> writes:

> I have a scattered matrix that I have to import from an external file. In
> this case all the lines could have a different size. The graph is oriented.
> I give you an example:
> a b c
> b a c d
> c b
> 
> The first row expresses that "a" has a direct path with "b" and also with
> "c".
> In the second "b" has a path with "a" and one with "c". In the third "c"
> there is a direct path with "b".
> I want to obtain the adjacency matrix.  In this case it is:
> 0 1 1 0
> 1 0 1 1
> 0 1 0 0
> 0 0 0 0
> 
> What have I to do?
> Please help me. Excuse me for my english.
[seen much worse]

Here you go:

>x <- readLines("lines.txt")
> x
[1] "a b c"   "b a c d" "c b"    
> x <- strsplit(x," ")
> x
[[1]]
[1] "a" "b" "c"

[[2]]
[1] "b" "a" "c" "d"

[[3]]
[1] "c" "b"

> x <- lapply(x,match,letters)
> x
[[1]]
[1] 1 2 3

[[2]]
[1] 2 1 3 4

[[3]]
[1] 3 2

> x <- lapply(x, function(z) cbind(z[1],z[-1]))
> x
[[1]]
     [,1] [,2]
[1,]    1    2
[2,]    1    3

[[2]]
     [,1] [,2]
[1,]    2    1
[2,]    2    3
[3,]    2    4

[[3]]
     [,1] [,2]
[1,]    3    2

> x <- do.call("rbind", x) 
> x
     [,1] [,2]
[1,]    1    2
[2,]    1    3
[3,]    2    1
[4,]    2    3
[5,]    2    4
[6,]    3    2
> m <- matrix(0,4,4)
> m[x] <- 1
> m 
     [,1] [,2] [,3] [,4]
[1,]    0    1    1    0
[2,]    1    0    1    1
[3,]    0    1    0    0
[4,]    0    0    0    0


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Sun Apr 21 04:49:41 2002
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 20 Apr 2002 22:49:41 -0400
Subject: [R] Durbin-Watson test in packages "car" and "lmtest"
Message-ID: <5.1.0.14.2.20020420224740.01d6ee50@pop>

Dear Ahmad,

I think that the discrepancy has been cleared up, since durbin.watson, as 
has been pointed out, calculates two-sided tests.

Some other relevant points: (1) durbin.watson will calculate dw statistics 
and associated p-values for lags greater than 1. (2) I prefer the approach 
currently in dwtest, but when durbin.watson was written, dwtest in lmtest 
didn't compute p-values. (3) I also agree that it would be useful to allow 
one-sided alternatives in durbin.watson and will likely add this if I don't 
remove the function from the car package.

I apologize for my slow response to your original posting and the 
subsequent exchange -- I was out of town.

John


At 05:05 PM 4/19/2002 -0400, Ahmad Abu Hammour wrote:
>Hi Torsten,
>Here is an example in which P-values have a significant difference. The 
>data is a sub sample of a larger one.
>Basically the model I am using is as follows:
>y_{t+2}= y_{t+1} + y_t + I(x_{t+1}-z_{t+1}-w_{t+1}) +e_{t+2}
>
> > ydata
>                   y            z           w         x
>  [1,]  0.0101705342 -5.363636567  0.80677087 -2.425968
>  [2,] -0.0040963887 -4.930336567 -0.01515276 -1.852668
>  [3,]  0.0007996203 -2.795136567  0.28412361 -0.849268
>  [4,]  0.0231375722 -2.523036567 -0.33650002 -0.315968
>  [5,]  0.0576658597 -2.925936567 -0.68112365  0.060732
>  [6,]  0.0930807057 -2.283836567 -1.59374728  0.214032
>  [7,]  0.0904861271 -1.908436567 -3.15057091  0.347332
>  [8,]  0.0815802452 -3.063936567 -3.60669454 -0.175968
>  [9,]  0.0463679856 -3.947236567 -2.89361816 -1.012668
>[10,]  0.0283314000 -3.528136567 -1.68974179 -1.522668
>[11,]  0.0158693958 -2.890536567 -1.03456542 -1.629268
>[12,] -0.0177988767 -2.165736567 -0.23008905 -1.532668
>[13,] -0.0263232785 -2.400436567 -0.29991268 -1.369268
>[14,] -0.0377695478 -3.243136567 -0.31953631 -0.539268
>[15,] -0.0520095622 -3.241336567  0.22174006  0.120732
>[16,] -0.0773138815 -2.765236567 -0.22328356  1.467332
>[17,] -0.0804307590 -2.833236567  0.09209281  2.107332
>[18,] -0.0446189151 -3.710136567  0.57246918  2.057332
>[19,] -0.0439761920 -4.232636567  0.11764555  2.687332
>[20,] -0.0508314286 -3.445136567  0.91252192  4.874032
>[21,] -0.0373526376 -2.123836567  1.03269829  5.340732
>[22,] -0.0363366045 -4.549336567  1.16137466  3.614032
>[23,] -0.0119795294 -4.660636567  2.10495103  1.744032
>[24,] -0.0271166745  0.940863433  2.73172741  5.450732
>[25,] -0.0319279899  2.972463433  3.93230378  7.954032
>[26,] -0.0285519284  2.601663433  4.25698015  9.447332
>[27,] -0.0362890374  3.900363433  4.49975652 11.397332
>[28,] -0.0193261619  2.440563433  4.24003289  7.057332
>[29,] -0.0211604332  4.133063433  3.62460926  5.907332
>[30,] -0.0393599621  4.764863433  3.78798563  6.740732
>[31,] -0.0368496844  2.967363433  3.09016201  5.137332
>[32,] -0.0111656400  2.374163433  2.32173838  1.820732
>[33,] -0.0049543837  2.858663433  0.59471475  0.570732
>[34,] -0.0085112660  3.900063433 -0.96020888  0.424032
>[35,]  0.0002988086  3.956163433 -1.40353251  0.500732
>[36,] -0.0021387277  2.276463433 -1.99135614  0.720732
>[37,] -0.0143497002  2.857863433 -1.40157977  1.270732
>[38,] -0.0459512047  3.589163433 -1.78060340  2.574032
>[39,] -0.0620556482  4.248163433 -2.43422702  3.537332
>[40,] -0.0665723041  3.225363433 -2.45305065  1.830732
>[41,] -0.0990262190  2.638163433 -2.34577428  1.634032
>[42,] -0.0993943457  2.160963433 -2.00509791  0.780732
>[43,] -0.0896954664  1.651763433 -1.79992154  0.164032
>[44,] -0.1047509912  2.106963433 -1.59274517  0.117332
>[45,] -0.1188326548  3.230463433 -1.40576880  2.007332
>[46,] -0.1012159404  2.484063433 -1.60469242 -0.209268
>[47,] -0.0975617833  2.185163433 -1.23841605 -0.442668
>[48,] -0.0859923186  1.244563433 -0.99983968 -0.495968
>[49,] -0.0467949427 -0.185636567 -1.19776331 -1.649268
>[50,] -0.0351160760 -0.510836567 -0.50778694 -0.569268
>[51,] -0.0233943108 -0.356136567 -0.53781057  0.347332
>[52,] -0.0080094290  0.005063433 -0.71733420 -0.569268
>[53,]  0.0312603960 -0.149336567 -0.69205783 -0.349268
>[54,]  0.0614944090  0.181063433 -0.76188145  0.237332
>[55,]  0.0775709808  0.795863433 -0.58080508  1.110732
>[56,]  0.0952235601  1.131763433 -0.38712871  1.907332
>[57,]  0.1069545973  1.509763433  0.06534766  2.887332
>[58,]  0.1136253179  1.785763433  0.64482403  3.450732
>[59,]  0.1275201332  1.348463433  1.06650040  3.410732
>[60,]  0.1387864450  0.581263433  1.05767677  3.444032
>[61,]  0.1244438565  1.253563433  1.35555315  4.164032
>[62,]  0.1344048716  0.334263433  0.69162952  4.844032
>[63,]  0.1487305153 -0.634036567  0.37670589  4.010732
>[64,]  0.1420063384 -0.159036567  1.22928226  3.190732
>[65,]  0.1469999823 -0.707536567  1.67200000  1.200732
> > library(car)
>Attaching package `car':
>
>         The following object(s) are masked from package:base :
>          dfbetas rstudent
> > library(lmtest)
> > 
> lmy=lm(y[-c(1,2)]~y[-c(1,65)]+y[-c(64,65)]+I(x-z-w)[-c(64,65)]-1,data=as.ts(ydata))
> > dwtest(lmy)
>         Durbin-Watson test
>data:  lmy
>DW = 2.0077, p-value = 0.4404
> > durbin.watson(lmy)
>  lag Autocorrelation D-W Statistic p-value
>    1     -0.01370151      2.007701    0.92
> >
>So, which P-value should I adopt 0.44 or 0.92?
>Thank you for your help.
>Ahmad Abu Hammour
>
>----- Original Message -----
>From: Torsten Hothorn
>Sent: Friday, April 19, 2002 4:51 AM
>To: Ahmad Abu Hammour
>Cc: R-help at stat.math.ethz.ch
>Subject: Re: [R] Durbin-Watson test in packages "car" and "lmtest"
>
> > Hi,
> > P-values in Durbin-Watson test obtained through the use of
> > functions available in packages "lmtest" and "car" are different. The
> > difference is quite significant. function "dwtest" in "lmtest" is much
> > faster than "burbinwatson" in "car". Actually, you can take a nap while
> > the latter trying to calculated Durbin-Watson test. My question is which
> > p-value is better?
>
>The answer is essencially given in ?durbin.watson and ?dwtest. The latter
>states that
>
>The p value is computed
>      using a Fortran version of the Applied Statistics Algorithm AS 153
>      by Farebrother (1980, 1984). This algorithm is called "pan" or
>      "gradsol". For large sample sizes the algorithm might fail to
>      compute the p value; in that case a warning is printed and an
>      approximate p value will be given; this p value is computed using
>      a normal approximation with mean and variance of the Durbin-Watson
>      test statistic.
>while ?durbin.watson says
>
>   simulate: if `TRUE' p-values will be estimated by bootstrapping.
>
>What is a "quite significant" difference for p-values?
>
>Looking at the example from ?durbin.watson gives:
>
>R> durbin.watson(lm(fconvict ~ tfr + partic + degrees + mconvict,
>data=Hartnagel))
>lag Autocorrelation D-W Statistic p-value
>    1        0.688345     0.6168636       0
>R> dwtest(fconvict ~ tfr + partic + degrees + mconvict, data=Hartnagel)
>
>         Durbin-Watson test
>
>data:  fconvict ~ tfr + partic + degrees + mconvict
>DW = 0.6169, p-value = 6.96e-09
>
>which is fairly close, so you might give us more details (that is: a
>working example) to see what the "difference" is (that is: a bug in
>either function or a difference due to simulation error / bad
>approximation ...).
>
>Torsten
>
> >
> > Thank you,
> > Ahmad Abu Hammour
> >

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ken_lee at tynesys.com  Sun Apr 21 12:00:00 2002
From: ken_lee at tynesys.com (ken_lee)
Date: Sun, 21 Apr 2002 18:00:00 +0800
Subject: [R] Problems with call R from java
Message-ID: <IPECKKKLFINFHEGMEKKGOEBGCAAA.ken_lee@tynesys.com>

Hi,
   I had some problems with the java data converter to R, where i can get some examples or more detail infomation?

 Thanks  vary much,
   Ken Lee
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From calvinw at ces.clemson.edu  Sun Apr 21 16:33:20 2002
From: calvinw at ces.clemson.edu (Calvin L. Williams, Ph.D.)
Date: Sun, 21 Apr 2002 10:33:20 -0400
Subject: [R] Simple Coding problem ?
Message-ID: <p05100300b8e87c7fe43a@[130.127.112.242]>

R-users,

This may be a simple problem, but I don't have an intuition of
how simple it could be. Suppose I have a sequence of numbers
corresponding to a series of diagnoses on the same patient
over a sequence of time. The diagnoses are coded 1,2,3,4,5, but
could come in a sequence like 1,3,2,5,3,5,...etc. Is there a simple
way to count the number of times a 1 diagnosis is followed by a 2, or
a 3, ... A 2 by a 1, or 3,....etc. It's almost like a mover-stayer problem.
I think.

I know this seems simple but any help would be appreciated.

Cheers,
Calvin


-- 

====================  Calvin L. Williams, Ph.D.  ====================
      Department of Mathematical Sciences, Clemson University
                             Box 340975 ,   0-323 Martin Hall
                       Clemson, South Carolina 29634-0975
       VOICE: (864) 656-5241  or leave message (864) 654-7187
                  EMAIL: calvinw at ces.clemson.edu
                                FAX: 1-(864) 656-5230
         WWW:   http://www.ces.clemson.edu/~calvinw/
============================================================
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mikalzet at libero.it  Sun Apr 21 17:49:46 2002
From: mikalzet at libero.it (mikalzet@libero.it)
Date: Sun, 21 Apr 2002 17:49:46 +0200 (CEST)
Subject: [R] help.start() and Mozilla
In-Reply-To: <20020402141056.GD17964@giraffa.cbs.dtu.dk>
Message-ID: <Pine.LNX.4.33L2.0204211707590.2867-100000@localhost.localdomain>


Searching the archives I found a thread about this a while ago
(november 2001) but it seems something has changed since then.

R 1.4.1, mozilla 0.9.4, linux mandrake 8.1,
default help.start browser = netscape,
jre 1.3.1

If mozilla is not yet started and I do:

help.start(browser = 'mozilla')
mozilla is started on the default mozilla homepage.
Once mozilla is going, doing
help.start() once again will get the R help page.

Is this a bug with help.start() or with my system's configuration,
I wonder ?

The R help page works all right except for the search page; does the
search page require something in particular ?

-- 
Michele Alzetta


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Sun Apr 21 18:07:01 2002
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Sun, 21 Apr 2002 12:07:01 -0400
Subject: [R] Simple Coding problem ?
In-Reply-To: <p05100300b8e87c7fe43a@[130.127.112.242]>; from calvinw@ces.clemson.edu on Sun, Apr 21, 2002 at 10:33:20AM -0400
References: <p05100300b8e87c7fe43a@[130.127.112.242]>
Message-ID: <20020421120701.A7038@cattell.psych.upenn.edu>

On 04/21/02 10:33, Calvin L. Williams, Ph.D. wrote:
>R-users,
>
>This may be a simple problem, but I don't have an intuition of
>how simple it could be. Suppose I have a sequence of numbers
>corresponding to a series of diagnoses on the same patient
>over a sequence of time. The diagnoses are coded 1,2,3,4,5, but
>could come in a sequence like 1,3,2,5,3,5,...etc. Is there a simple
>way to count the number of times a 1 diagnosis is followed by a 2, or
>a 3, ... A 2 by a 1, or 3,....etc. It's almost like a mover-stayer problem.
>I think.

Suppose you have these in a vector v1.  How about something like

w1 <- length(v1)
table(v1[-w1],v1[2:w1])

If each subject is a row in a matrix m1, then you could do this
something like (where w1 is now the number of columns)

apply(m1,1,function(x) table(x[-w1],x[2:w1]))

I haven't tested this, and I might have it slightly wrong, or not
optimal.

I'm sure there are better ways, but I'm sure this general idea
will work.

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mikem at salter-point.com  Sun Apr 21 18:10:14 2002
From: mikem at salter-point.com (Michael M. Meyer)
Date: Sun, 21 Apr 2002 09:10:14 -0700
Subject: [R] Simple Coding problem ? 
In-Reply-To: Message from "Calvin L. Williams, Ph.D." <calvinw@ces.clemson.edu> 
   of "Sun, 21 Apr 2002 10:33:20 EDT." <p05100300b8e87c7fe43a@[130.127.112.242]> 
Message-ID: <200204211610.g3LGAEB26895@home.salter-point.com>

Let x be the sequence of numbers.

What about forming a table of x[-1] against x[-length(x)],
e.g.
   table(x[-1], x[-length(x)])

That should give you the transition matrix from each state to each
other state.

 --Mike

Mike Meyer, Salter Point Associates, Seattle WA
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From klavan at tiscalinet.it  Sun Apr 21 18:53:17 2002
From: klavan at tiscalinet.it (Ambrosini Alessandro)
Date: Sun, 21 Apr 2002 18:53:17 +0200
Subject: R: [R] Problem with a matrix
In-Reply-To: <x2hem6cax0.fsf@blueberry.kubism.ku.dk>
Message-ID: <PPEGLLABFLFCJDLCGPGHMEIBCAAA.klavan@tiscalinet.it>


Thank you very much. Everything is ok.
I make you another question (and I hope that it will be the last one).
If names of nodes are not "a", "b", "c" but "Italy", "Spain", "England" how
can I change the command

 x <- lapply(x,match,letters) to obtain the usual matrix?
If I write the command in this way, the output is NA NA NA ... and so maybe
I have to change "letters". What have I to write?
Thank you and excuse me for the disturb.
Alessandro

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Sun Apr 21 19:36:54 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun, 21 Apr 2002 18:36:54 +0100 (BST)
Subject: [R] help.start() and Mozilla
In-Reply-To: <Pine.LNX.4.33L2.0204211707590.2867-100000@localhost.localdomain>
Message-ID: <Pine.LNX.4.31.0204211833150.26592-100000@gannet.stats>

On Sun, 21 Apr 2002 mikalzet at libero.it wrote:

>
> Searching the archives I found a thread about this a while ago
> (november 2001) but it seems something has changed since then.
>
> R 1.4.1, mozilla 0.9.4, linux mandrake 8.1,

That's way out of date.  Try 0.9.9.

> default help.start browser = netscape,
> jre 1.3.1
>
> If mozilla is not yet started and I do:
>
> help.start(browser = 'mozilla')
> mozilla is started on the default mozilla homepage.
> Once mozilla is going, doing
> help.start() once again will get the R help page.
>
> Is this a bug with help.start() or with my system's configuration,
> I wonder ?

With your mozilla.  There are a few other things that don't work with that
version, for example the menu links in the HTML manual versions.

> The R help page works all right except for the search page; does the
> search page require something in particular ?

A working Java sub-system.

For me on RH7.2 mozilla 0.9.9 worked as expected with R-1.5.0pre.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tdlong at uci.edu  Sun Apr 21 20:16:40 2002
From: tdlong at uci.edu (Tony Long)
Date: Sun, 21 Apr 2002 11:16:40 -0700
Subject: [R] updating R - old version still runs
Message-ID: <a05101510b8e8b1cba56e@[128.200.28.179]>

All:

	I apologize as I think I had this problem before, and 
misplaced my notes on the solution.

	I just tried to upgrade my version of R on a Redhat Linux 
computer.  I downloaded and ran the rpm for

R-recommended-1.4.1-1.i386.rpm

Problem is that when I type R from any directory the "old" version 
still seems to run.  I can only guess this has to do with where the 
new and old version are being put.  Any suggestions?  Tony
-- 

Tony Long

Ecology and Evolutionary Biology
Steinhaus Hall
University of California at Irvine
Irvine, CA
92697-2525

Tel:  (949) 824-2562   (office)
Tel:  (949) 824-5994   (lab)
Fax: (949) 824-2181

email:  tdlong at uci.edu
http://hjmuller.bio.uci.edu/~labhome/
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Sun Apr 21 21:07:33 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 21 Apr 2002 21:07:33 +0200
Subject: R: [R] Problem with a matrix
References: <PPEGLLABFLFCJDLCGPGHMEIBCAAA.klavan@tiscalinet.it>
Message-ID: <3CC30DF5.F48AF7B1@statistik.uni-dortmund.de>

Ambrosini Alessandro wrote:
> 
> Thank you very much. Everything is ok.
> I make you another question (and I hope that it will be the last one).
> If names of nodes are not "a", "b", "c" but "Italy", "Spain", "England" how
> can I change the command
> 
>  x <- lapply(x,match,letters) to obtain the usual matrix?
> If I write the command in this way, the output is NA NA NA ... and so maybe
> I have to change "letters". What have I to write?
> Thank you and excuse me for the disturb.

Instead of the
 letters
[1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o" "p" "q"
"r" "s" "t" "u" "v" "w" "x" "y" "z"
you might want to define and use a variable
 countries <- c("Italy", "Spain", "England")

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Sun Apr 21 21:18:52 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 21 Apr 2002 21:18:52 +0200
Subject: [R] updating R - old version still runs
References: <a05101510b8e8b1cba56e@[128.200.28.179]>
Message-ID: <3CC3109C.31269F@statistik.uni-dortmund.de>

Tony Long wrote:
> 
> All:
> 
>         I apologize as I think I had this problem before, and
> misplaced my notes on the solution.
> 
>         I just tried to upgrade my version of R on a Redhat Linux
> computer.  I downloaded and ran the rpm for
> 
> R-recommended-1.4.1-1.i386.rpm
> 
> Problem is that when I type R from any directory the "old" version
> still seems to run.  I can only guess this has to do with where the
> new and old version are being put.  Any suggestions?  Tony

If you don't need the old one, just uninstall it.
Obviously it is installed into a directory with higher priority in your
search path than the newer version of R (or you set an alias?).
Maybe one version is installed in /usr/.... (/usr/bin/R, /usr/lib/R/...)
, the other one in /usr/local/.... (/usr/local/bin/R,
/usr/local/lib/R/...)?

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Sun Apr 21 21:23:41 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 21 Apr 2002 21:23:41 +0200
Subject: [R] updating R - old version still runs
References: <a05101510b8e8b1cba56e@[128.200.28.179]> <3CC3109C.31269F@statistik.uni-dortmund.de>
Message-ID: <3CC311BD.CCEA96F2@statistik.uni-dortmund.de>

Uwe Ligges wrote:
> 
> Tony Long wrote:
> >
> > All:
> >
> >         I apologize as I think I had this problem before, and
> > misplaced my notes on the solution.
> >
> >         I just tried to upgrade my version of R on a Redhat Linux
> > computer.  I downloaded and ran the rpm for
> >
> > R-recommended-1.4.1-1.i386.rpm

Arrgh. Sorry. Just forget my last mail...

If you really downloaded *R-recommended*: AFAIK in that package there
are the recommended packages of R, not R itself! So, of course, your old
version of R is still running.

To upgarde R itself you have to install R-base-1.4.1-1.i386.rpm.

Uwe Ligges

> > Problem is that when I type R from any directory the "old" version
> > still seems to run.  I can only guess this has to do with where the
> > new and old version are being put.  Any suggestions?  Tony
> 
> If you don't need the old one, just uninstall it.
> Obviously it is installed into a directory with higher priority in your
> search path than the newer version of R (or you set an alias?).
> Maybe one version is installed in /usr/.... (/usr/bin/R, /usr/lib/R/...)
> , the other one in /usr/local/.... (/usr/local/bin/R,
> /usr/local/lib/R/...)?
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Sun Apr 21 22:54:31 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 21 Apr 2002 13:54:31 -0700 (PDT)
Subject: [R] integration of a discrete function
In-Reply-To: <Pine.GSO.4.05.10204201051170.2481-100000@paladin>
Message-ID: <Pine.A41.4.44.0204211351010.146982-100000@homer41.u.washington.edu>

On Sat, 20 Apr 2002, Giuseppe  Pagnoni wrote:

> Dear R list
>
> I am looking for a function in R that computes the integration of a
> discrete curve, such as a power spectrum, in a specified interval (in my
> case, that would be 'power in a certain frequency band').  I found only
> functions, such as 'integrate', that perform adaptive quadrature on
> analytic functions, and not on a curve specified as a set of (x,y) pairs.
> I have the impression that I am not looking in the right place....  or I
> should code the algorithm myself?

You should probably code it yourself.

When you have a genuinely discrete function the integral will usually be
exactly
    sum(w*x)
where w is a vector of weights that will depend on x in a problem-specific
way (that being why you want to do it yourself). You probably don't want
the sort of approximations that adaptive quadrature would do.

OTOH, if you have data (x,y) and want to integrate a smooth or
interpolated curve you could use approxfun() or splinefun() to create that
smooth curve and integrate it. [Someone will probably point out that you
don't actually need to integrate() it, since linear and spline functions
have closed-form integrals]

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From richmond at saintmarys.edu  Sun Apr 21 23:15:21 2002
From: richmond at saintmarys.edu (David A Richmond)
Date: Sun, 21 Apr 2002 16:15:21 -0500 (EST)
Subject: [R] Help
In-Reply-To: <PPEGLLABFLFCJDLCGPGHEEHACAAA.klavan@tiscalinet.it>
Message-ID: <Pine.GSO.4.43.0204211607580.4401-100000@jade.saintmarys.edu>

On Fri, 12 Apr 2002, Ambrosini Alessandro wrote:

> I have an adjacency matrix and I want to obtain a matrix of the minimum
> paths between the nodes. Thank you
> Alessandro Ambrosini

In my experience "geodist" in the sna package is rather slow. Compare its
system time on a 100x100 adj matrix to a routine that doesn't rely quite
so much on loops:

> system.time(graph.geod(a) -> result)
[1] 0.08 0.00 0.18 0.00 0.00
> system.time(geodist(a) -> result2)
[1]  78.58   0.00 184.73   0.00   0.00

(this test was done on a G3 iMac running os X/R 1.4.0)

here is the 'meat' of graph.geod()

graph.geod <- function(dat) {
	d <- dim(dat)
	dists <- dat
	dat2 <- dat
	for (i in 2:d[1]) {
		dat2 <- dat2 %*% dat
		dists2 <- dists + (i*(dat2 != 0) * !dists)
		if (all(dists==dists2)) break
		dists <- dists2
	}
	return(dists)
}


+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|David Richmond                It works on a          |
+ Dept. of Sociology          complex scientific      +
|Saint Mary's College          principle, known as    |
+ Notre Dame, IN 46556               "pot luck."      +
|574-284-4517                    - The Doctor         |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From steve at stat.tku.edu.tw  Mon Apr 22 01:04:33 2002
From: steve at stat.tku.edu.tw (Steve Chen)
Date: Mon, 22 Apr 2002 07:04:33 +0800 (CST)
Subject: [R] New R CGI gateway: TKU-Stat
Message-ID: <Pine.LNX.4.21.0204220651330.9978-100000@paradise.stat.tku.edu.tw>

Hi boys and girls,

This is to let you know that I am writing a new R CGI gateway: TKU-Stat
which has its page on

http://tkustat.stat.tku.edu.tw
(There is an "English" option on main menu)

It's based on PHP language, but it's NOT a R <-> PHP API
(I am not a good C programmer :( )

It's just a CGI. Basically, I use PHP and some template engine
to get inputs/selections from webpage, forward them 
to R's batch mode, get the result, and show the results on Web page.

Currently it's in developing stage, but modules for basic statistics
are almost done.

This package is not limited to pure CGI for R only. It should be able 
to handle all programs with batch-processing capability. In fact,
I am using randlib and dcdflib fortran codes to do probability
calculation, as a demo of alternatives. It should also be able to
handle SAS :)

I will release the codes in GPL licence as soon as possible,
after I clean bunch of messy codes and unify module standard.

from Steve Chen (email: steve at steve-chen.net)
Associate Professor
Department of Statistics
Tamkang University, Taipei, Taiwan

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From r.hankin at auckland.ac.nz  Mon Apr 22 06:14:53 2002
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Mon, 22 Apr 2002 16:14:53 +1200
Subject: [R] how can a function tell if defaults are used?
Message-ID: <200204220414.g3M4ErD04198@r.hankin.sems.auckland.ac.nz>


Hello everybody


Is there a good way for a function to tell whether the caller used the
defaults?

I'm writing a little function that may take a pair of real arguments
or a single complex argument (in which case I want the real and
imaginary components).


"e" <-   function(first,second=first) {
  if (all(first == second) & is.complex(first)) {
    return(c(Re(first),Im(first)))
  } else {
    return (c(Re(first),Re(second)))
  }
}


Thus

> e(1+5i)
[1] 1 5
> e(1,5)
[1] 1 5


which is what I want, but what is the best way to test whether the
second argument is explicitly set by the caller or the default is
used?  My only idea was to test for first == second but this can't be
optimal.  Help anyone?


-- 

Robin Hankin, Lecturer,
School of Geographical and Environmental Science
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rpeng at stat.ucla.edu  Mon Apr 22 07:04:46 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Sun, 21 Apr 2002 22:04:46 -0700 (PDT)
Subject: [R] how can a function tell if defaults are used?
In-Reply-To: <200204220414.g3M4ErD04198@r.hankin.sems.auckland.ac.nz>
Message-ID: <Pine.GSO.4.10.10204212202450.23329-100000@quetelet.stat.ucla.edu>

Maybe a better way is:

e <- function(first, second) {
  if(missing(second)) 
    return(c(Re(first), Im(first)))
  else
    return(c(Re(first), Re(second)))
}

I'm not sure if this is what you're going for.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Mon, 22 Apr 2002, Robin Hankin wrote:

> 
> Hello everybody
> 
> 
> Is there a good way for a function to tell whether the caller used the
> defaults?
> 
> I'm writing a little function that may take a pair of real arguments
> or a single complex argument (in which case I want the real and
> imaginary components).
> 
> 
> "e" <-   function(first,second=first) {
>   if (all(first == second) & is.complex(first)) {
>     return(c(Re(first),Im(first)))
>   } else {
>     return (c(Re(first),Re(second)))
>   }
> }
> 
> 
> Thus
> 
> > e(1+5i)
> [1] 1 5
> > e(1,5)
> [1] 1 5
> 
> 
> which is what I want, but what is the best way to test whether the
> second argument is explicitly set by the caller or the default is
> used?  My only idea was to test for first == second but this can't be
> optimal.  Help anyone?
> 
> 
> -- 
> 
> Robin Hankin, Lecturer,
> School of Geographical and Environmental Science
> Private Bag 92019 Auckland
> New Zealand
> 
> r.hankin at auckland.ac.nz
> tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From petr.pikal at precheza.cz  Mon Apr 22 09:01:04 2002
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 22 Apr 2002 09:01:04 +0200
Subject: [R] integration of a discrete function
In-Reply-To: <Pine.GSO.4.05.10204201051170.2481-100000@paladin>
Message-ID: <3CC3D150.32589.4FC2E4@localhost>



On 20 Apr 2002 at 10:52, Giuseppe  Pagnoni wrote:

> Dear R list
> 
> I am looking for a function in R that computes the integration of a
> discrete curve, such as a power spectrum, in a specified interval (in
> my case, that would be 'power in a certain frequency band').  I found
> only functions, such as 'integrate', that perform adaptive quadrature
> on analytic functions, and not on a curve specified as a set of (x,y)
> pairs. I have the impression that I am not looking in the right
> place....  or I should code the algorithm myself?
> 
I am sure there are some functions elsewhere, but here I constructed simple 
functions which I use to compute an area for peaks from let say Xray diffraction 
spectrum. It was intended for my use only and it is not documented at all.

The first one is used for selection from graphics (i.e. you have to use

plot(x,y) 

first, use mouse pointer to specify an area of interest (one upper and oposite 
lower corner, therefore the function replot) and using the mouse pointer again to 
specify the lower and upper margin for area computing. Second function integ1 
will enable you to set lower and upper margin directlz bz numbers.

Both functions will give you two numbers - area above from line x (y=0) and area 
from above the line connecting "lowest" points in required interval (x1,x2).

Hope this helps.

#------------------------------------------------------------------

integ<-function (x,y)
{
replot(x,y)
meze<-locator(2)
dm<-meze$x[1]
hm<-meze$x[2]
abline(v=c(dm,hm),col=2)
vyber<-x<=hm&x>=dm
l<-length(x[vyber])
v<-diff(x[vyber])
z<-y[vyber][1:l-1]+y[vyber][2:l]
o<-z*v/2
osum<-sum(o)
o1<-(y[x==min(x[vyber])]+y[x==max(x[vyber])])*(max(x[vyber])-
min(x[vyber]))/2
cista<-osum-o1
return(c(osum,cista))
}

integ1<-function (x,y,dm=-Inf,hm=+Inf)
{
if(dm==-Inf)dm<-min(x)
if(hm==+Inf)hm<-max(x)
vyber<-x<=hm&x>=dm
l<-length(x[vyber])
v<-diff(x[vyber])
z<-y[vyber][1:l-1]+y[vyber][2:l]
o<-z*v/2
osum<-sum(o)
o1<-(y[x==min(x[vyber])]+y[x==max(x[vyber])])*(max(x[vyber])-
min(x[vyber]))/2
cista<-osum-o1
return(c(osum,cista))
}

#---------------------------------------------------------------------------------

replot <- function(x, y, type="l")
{
   body <- locator(2)
   plot(x, y, xlim=range(body$x), ylim=range(body$y), type=type)
}




> thanks for any suggestion
> 
>     Giuseppe
> 
> 
> -----------------
> Giuseppe Pagnoni
> Emory University
> Dept.of Psychiatry and Behavioral Sciences
> 1639 Pierce Dr.
> Suite 4000, WMB Bldg.
> Atlanta, GA, 30322
> phone: 404-7128431
> fax: 404-7273233
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.- r-help mailing list -- Read
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html Send "info", "help",
> or "[un]subscribe" (in the "body", not the subject !)  To:
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._

Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From psu17772 at hotmail.com  Mon Apr 22 09:21:41 2002
From: psu17772 at hotmail.com (sonchawan tamkaew)
Date: Mon, 22 Apr 2002 07:21:41 +0000
Subject: [R] PP.test
Message-ID: <F52kKlMJr0nSrGpeuDm0000513f@hotmail.com>

Hello there,

I would like to know whether PP.test from library(ts) is appropriate to test 
unit root in financial data (daily)?

Thank you for your help.

Sonchawan



_________________________________________________________________


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From amaitour at pasteur.fr  Mon Apr 22 09:56:05 2002
From: amaitour at pasteur.fr (Aboubakar Maitournam)
Date: Mon, 22 Apr 2002 09:56:05 +0200
Subject: [R] .RData
Message-ID: <3CC3C213.4A63986D@pasteur.fr>

Dear all,

I have a version 1.3.1 of R which is under Linux Redhat. I have worked
with it without any problem.
But now when I try to run R, I get the error message as follows :

Error: an xdr real data read error occured
Fatal error: unable to restore saved data in .RData

Thank you in advance and sorry if my question is perhaps simple.

Aboubakar Maitournam.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Apr 22 10:18:20 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 22 Apr 2002 09:18:20 +0100 (BST)
Subject: [R] .RData
In-Reply-To: <3CC3C213.4A63986D@pasteur.fr>
Message-ID: <Pine.LNX.4.31.0204220911590.29703-100000@gannet.stats>

On Mon, 22 Apr 2002, Aboubakar Maitournam wrote:

> Dear all,
>
> I have a version 1.3.1 of R which is under Linux Redhat. I have worked
> with it without any problem.
> But now when I try to run R, I get the error message as follows :
>
> Error: an xdr real data read error occured
> Fatal error: unable to restore saved data in .RData

It means that the workspace .RData is corrupted or that you have a
disk-reading problem on your system.  It might be worth trying it again,
but if that fails there is no alternative that I know of to deleting
.RData (and your saved work is then lost).

R 1.3.1 is not very recent, and 1.4.x tries harder to ensure that the
saving process is safe.  However, many of us do not rely on saved
workspaces to store information precisely because they are so vulnerable.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tobias.hoevekamp at ilw.agrl.ethz.ch  Mon Apr 22 10:44:53 2002
From: tobias.hoevekamp at ilw.agrl.ethz.ch (Tobias Hoevekamp)
Date: Mon, 22 Apr 2002 10:44:53 +0200
Subject: [R] Problem with logarithmic axes labelling
Message-ID: <1019465093.3cc3cd853a2d6@email.ethz.ch>

Dear R-helpers!

Using logarithmic axes sometimes results in an odd labelling.
In some cases, only half of the axes do have labels. Hmmmm.
I've played around with par(lab=c(5,5,7)) but that didn't help.

An example:

---- begin example ----

x <-  c(0.12,  0.3,   0.53,  1.1,   1.8,  2.6, 4.5)
y <-  c(0.012, 0.021, 0.032, 0.055, 0.1,  0.2, 0.35)

plot(x, y,
     log="xy",
     main="Problem with axes labelling on logarithmic scales",
     xlab="x, why aren't 0.5, or even smaller tic-values displyed?",
     ylab="y, why isn't 0.05 diplayed?")

---- end example ------

I've submitted this a while ago as a bug (#1235) but now, I rather think
it's just a little setting that has to be adjusted. But which...

Thanks for looking into my problem.

Bye



Tobias


TOBIAS HOEVEKAMP 
mailto:tobias.hoevekamp at ilw.agrl.ethz.ch
http://www.vt.ilw.agrl.ethz.ch/~hoevekam
WORK: ETH Zurich, LFO E21, CH-8092 Zurich, +41 1 632 3304
HOME: Anna Heer-Str. 2,  CH-8057  Zurich,  +41 1 350 5986


-------------------------------------------------
This mail sent through IMP 3.0 at http://email.ethz.ch/horde/imp
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jasont at indigoindustrial.co.nz  Mon Apr 22 23:59:01 2002
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Mon, 22 Apr 2002 21:59:01 +0000
Subject: [R] .RData
In-Reply-To: <3CC3C213.4A63986D@pasteur.fr>; from amaitour@pasteur.fr on Mon, Apr 22, 2002 at 09:56:05AM +0200
References: <3CC3C213.4A63986D@pasteur.fr>
Message-ID: <20020422215901.A3756@camille.indigoindustrial.co.nz>

On Mon, Apr 22, 2002 at 09:56:05AM +0200, Aboubakar Maitournam wrote:
> But now when I try to run R, I get the error message as follows :
> 
> Error: an xdr real data read error occured
> Fatal error: unable to restore saved data in .RData

looks like your .RData file has been corrupted.  The only way to start
R in that directory is now to rename .RData, such as:

mv .RData .RData.broken

(or, en Francais  ;-)

mv .RData .RData.cass?

It's unlikely you'll get the data back.

> I have a version 1.3.1 of R which is under Linux Redhat. 

You should also upgrade.  1.4.1 has lots of nice new stuff.
Read the bit about 1.4.x file formats for .RData before you
do, though.

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Apr 22 13:37:21 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 22 Apr 2002 13:37:21 +0200
Subject: [R] .RData
In-Reply-To: <20020422215901.A3756@camille.indigoindustrial.co.nz>
References: <3CC3C213.4A63986D@pasteur.fr>
	<20020422215901.A3756@camille.indigoindustrial.co.nz>
Message-ID: <x2bsccj766.fsf@blueberry.kubism.ku.dk>

Jason Turner <jasont at indigoindustrial.co.nz> writes:

> On Mon, Apr 22, 2002 at 09:56:05AM +0200, Aboubakar Maitournam wrote:
> > But now when I try to run R, I get the error message as follows :
> > 
> > Error: an xdr real data read error occured
> > Fatal error: unable to restore saved data in .RData
> 
> looks like your .RData file has been corrupted.  The only way to start
> R in that directory is now to rename .RData, such as:
> 
> mv .RData .RData.broken
> 
> (or, en Francais  ;-)
> 
> mv .RData .RData.cass?
> 
> It's unlikely you'll get the data back.
> 
> > I have a version 1.3.1 of R which is under Linux Redhat. 
> 
> You should also upgrade.  1.4.1 has lots of nice new stuff.
> Read the bit about 1.4.x file formats for .RData before you
> do, though.

...although 1.5.0 will have even more nice stuff, and it's supposed to
come out next Monday (in the source version - allow a few more days
for binary distributions).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From siim at obs.ee  Mon Apr 22 14:48:17 2002
From: siim at obs.ee (Ott Toomet)
Date: Mon, 22 Apr 2002 14:48:17 +0200 (CEST)
Subject: [R] updating R - old version still runs
In-Reply-To: <a05101510b8e8b1cba56e@[128.200.28.179]>
Message-ID: <Pine.LNX.4.44.0204221443560.8203-100000@localhost.localdomain>

Hi,

On Sun, 21 Apr 2002, Tony Long wrote:

  |All:
  |
  |	I apologize as I think I had this problem before, and 
  |misplaced my notes on the solution.
  |
  |	I just tried to upgrade my version of R on a Redhat Linux 
  |computer.  I downloaded and ran the rpm for
  |
  |R-recommended-1.4.1-1.i386.rpm
  |

I think you just upgraded the recommended packages but not the R itself
(install R-base-1.4.1-1.i386.rpm).

If you _have_ installed R-base-1.4.1, the things are more strange.  You
should look where exactly is the R which is executed, which package it
belongs to, and where is the new R executable.  

I hope it helps.


Ott Toomet

  |Problem is that when I type R from any directory the "old" version 
  |still seems to run.  I can only guess this has to do with where the 
  |new and old version are being put.  Any suggestions?  Tony
  |

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From a296180 at mica.fmr.com  Mon Apr 22 15:06:40 2002
From: a296180 at mica.fmr.com (David Kane  <David Kane)
Date: Mon, 22 Apr 2002 09:06:40 -0400
Subject: [R] skipping specific rows in read.table
Message-ID: <15556.2784.448531.984818@gargle.gargle.HOWL>

Hi,

We are considering organizing some of our ascii files with multiple "column
names" like so:

a.long.but.complete.name	a.different.complex.name
short.name.1	short.name.2
1	7
2	8
3	9
[more data]

The basic idea is that we want to keep, in one location, both a long descriptive
name of each variable (in row 1) and a short convenient name (in row 2). I
could imagine keeping other information about the data in here as well.

[Comment: Of course, my CS buddies would say that the "grown up" way to handle
this sort of thing is XML, but I haven't seen much discussion of people reading
XML files directly into R -- although Duncan Temple Lang's R/SPlus XML Parsing
Package looks quite interesting. In any event, since I don't have complete
control over the format of these files, my options may be limitted. I would
certainly love to hear about any XML/R success stories.]

In any event, I can easily use the "skip" argument to read.table to ignore the
first row.

> read.delim("/home/a296180/tmp/junk.txt", skip = 1)
  short.name.1 short.name.2
1            1            7
2            2            8
3            3            9

Is there a similar trick for ignoring the second row? That is, I want to
produce a dataframe that looks like:

  a.long.but.complete.name a.different.complex.name
1                        1                        7
2                        2                        8
3                        3                        9

I can think of various hacks, including 1) adding a comment character to the
second row prior to reading it in and 2) reading everything in and then
deleting the second row and, perhaps, coercing the variable to be the
appropriate type and 3) changing the code to read.table itself (which we did
before to handle some issues made moot by Professor Ripley's marvelous
`colClasses' addition to read.table), but I am hoping that there is a better
way. To the extent that it matters, I am using R 1.4.0 patched on Solaris.

Thanks,

Dave Kane
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Apr 22 15:31:53 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 22 Apr 2002 14:31:53 +0100 (BST)
Subject: [R] skipping specific rows in read.table
In-Reply-To: <15556.2784.448531.984818@gargle.gargle.HOWL>
Message-ID: <Pine.LNX.4.31.0204221430180.30610-100000@gannet.stats>

On Mon, 22 Apr 2002, David Kane  <David Kane wrote:

> Hi,
>
> We are considering organizing some of our ascii files with multiple "column
> names" like so:
>
> a.long.but.complete.name	a.different.complex.name
> short.name.1	short.name.2
> 1	7
> 2	8
> 3	9
> [more data]
>
> The basic idea is that we want to keep, in one location, both a long descriptive
> name of each variable (in row 1) and a short convenient name (in row 2). I
> could imagine keeping other information about the data in here as well.
>
> [Comment: Of course, my CS buddies would say that the "grown up" way to handle
> this sort of thing is XML, but I haven't seen much discussion of people reading
> XML files directly into R -- although Duncan Temple Lang's R/SPlus XML Parsing
> Package looks quite interesting. In any event, since I don't have complete
> control over the format of these files, my options may be limitted. I would
> certainly love to hear about any XML/R success stories.]
>
> In any event, I can easily use the "skip" argument to read.table to ignore the
> first row.
>
> > read.delim("/home/a296180/tmp/junk.txt", skip = 1)
>   short.name.1 short.name.2
> 1            1            7
> 2            2            8
> 3            3            9
>
> Is there a similar trick for ignoring the second row? That is, I want to
> produce a dataframe that looks like:
>
>   a.long.but.complete.name a.different.complex.name
> 1                        1                        7
> 2                        2                        8
> 3                        3                        9

Use the facilities of connections to read two lines and push back the
first one.

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mmiller3 at iupui.edu  Mon Apr 22 15:50:38 2002
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: 22 Apr 2002 08:50:38 -0500
Subject: [R] y-intercept forcing
References: <Pine.GSO.4.10.10204190828380.5487-100000@quetelet.stat.ucla.edu>
Message-ID: <877kmzrgep.fsf@lumen.indyrad.iupui.edu>

>>>>> "Roger" == Roger Peng <rpeng at stat.ucla.edu> writes:

    > Try the 'ylim' argument in plot.

Also, see the help for par.  The graphical parameter yaxs sets
the style of axis interval calculation to be used for the y-axis
(xaxs for the x-axis).  If I read his question correctly, I think
par(yaxs='i') will do what the original poster was looking for.

Mike

-- 
Michael A. Miller                               mmiller3 at iupui.edu
  Imaging Sciences, Department of Radiology, IU School of Medicine
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Mon Apr 22 17:10:16 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 22 Apr 2002 08:10:16 -0700 (PDT)
Subject: [R] how can a function tell if defaults are used?
In-Reply-To: <200204220414.g3M4ErD04198@r.hankin.sems.auckland.ac.nz>
Message-ID: <Pine.A41.4.44.0204220759590.166864-100000@homer06.u.washington.edu>

On Mon, 22 Apr 2002, Robin Hankin wrote:

>
> Hello everybody
>
>
> Is there a good way for a function to tell whether the caller used the
> defaults?

Yes, or then again, no.

You can use the function missing() to test whether an explicit argument
was supplied.

>
> "e" <-   function(first,second=first) {
>   if (all(first == second) & is.complex(first)) {
ie
    if (missing(second)){

>     return(c(Re(first),Im(first)))
>   } else {
>     return (c(Re(first),Re(second)))
>   }
> }
>



This will not preserve the missingness

   f<-function(a,b,c,d=c){

        e(c,d)

   }

This will work, but not if you modify d before calling e()
   f<-function(a,b,c,d){

        e(c,d)

   }


That's why we often use NULL as the default:

 "e" <-   function(first,second=NULL) {
    if (is.null(second)){
     return(c(Re(first),Im(first)))
   } else {
     return (c(Re(first),Re(second)))
   }
  }


  f<-function(a,b,c,d=NULL){

        e(c,d)

  }


	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From sundard at pdf.com  Mon Apr 22 17:38:07 2002
From: sundard at pdf.com (Sundar Dorai-Raj)
Date: Mon, 22 Apr 2002 10:38:07 -0500
Subject: [R] lattice help
Message-ID: <3CC42E5F.FF6CA4A0@pdf.com>

I'm new to lattice and can't figure out what the problem is with the
following example:

#########################
> library(lattice)
Loading required package: grid 

Attaching package `lattice':


	The following object(s) are masked _by_ .GlobalEnv :

	 xyplot 


	The following object(s) are masked from package:base :

	 levels 

> test.data <- data.frame(x=rnorm(100),
+                         y=rnorm(100),
+                         group=gl(5,20))
> xyplot(y~x|group,data=test.data,
+        panel=function(x,y,subscripts,df) {
+          text(x,y,labels=as.character(df[subscripts,"group"]))
+          abline(lm(y~x))
+        },df=test.data)
Error in unique(by) : Argument "by" is missing, with no default
> 
#########################

I get the same error when I try the examples from the `xyplot' help
page:

#########################
> data(quakes)
> xyplot(long ~ lat , data = quakes)
Error in unique(by) : Argument "by" is missing, with no default
>
#########################

What am I missing?


> version
         _              
platform i386-pc-mingw32
arch     x86            
os       Win32          
system   x86, Win32     
status                  
major    1              
minor    4.0            
year     2001           
month    12             
day      19             
language R              

Thanks,

Sundar

-- 

Sundar Dorai-Raj, Ph.D.
Statistical Methods Engineer
PDF Solutions, Inc.
(972) 889-3085 x216
(214) 392-7619 cell
sundard at pdf.com
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From richard.nixon at mrc-bsu.cam.ac.uk  Mon Apr 22 17:51:21 2002
From: richard.nixon at mrc-bsu.cam.ac.uk (Richard Nixon)
Date: Mon, 22 Apr 2002 16:51:21 +0100 (BST)
Subject: [R] glm() function not finding the maximum
Message-ID: <Pine.GSO.4.44.0204221641030.4377-100000@moeran>


Hello,

I have found a problem with using the glm function with a gamma
family.

I have a vector of data, assumed to be generated by a gamma distribution.
The parameters of this gamma distribution are estimated in two ways (i)
using the glm() function, (ii) "by hand", using the optim() function.

I find that the -2*likelihood at the maximum found by (i) is substantially
larger than that found by (ii), i.e. the glm() function is not finding the
maximum.

This is some what of a pathological example, as the data set is highly
skewed and contains a couple of outliers.

I've tested this in S+ and the same problem is there too.

Is this cause for concern, or is my data set just a "nasty" one to deal
with?

I am really impressed with the optim() function. Indeed, it is the reason
why I switched to R from Splus. The Splus analogue was very slow, and
didn't find the maximum.

The data set and code for the two methods of estimation are included
below. I don't think I am making a mistake here. Sorry if I have.

Thanks

Richard

> gamma1(data) #uses the glm() function
$loglik
[1] 875.4274

$par
[1] 9.572403e-02 4.345771e+03

> gamma2(data) #"by hand" using optim()
$loglik
[1] 793.3913

$par
[1]   0.518145 802.854297

#Data set
data_c(51.47, 210.19, 49.55, 61.93, 60.61, 744.57, 338.59, 133.93,
191.57, 111.43, 432.83, 185.23, 155.61, 84.72, 120.2, 15.33,
77.05, 115.77, 25.23, 657.94, 108.39, 61.08, 142.42, 87.86, 272.87,
213.78, 65.23, 102.45, 58.16, 176.58, 76.58, 434.12, 362.35,
102.53, 103.6, 25.23, 97.19, 88.52, 118.55, 151.9, 2.7, 156.41,
21.79, 272.27, 23.16, 32.07, 6325.23, 92.37, 8340.04, 51.08,
55.59, 94.08, 69.98, 554.13, 104.88, 170.15, 945.1, 143.52)

#Fits data to a gamma distribution using glm()
gamma1_function(data){
n_length(data)
m_summary(glm(data~1, family=Gamma(link=identity)))
shape_1/as.numeric(m$disp)
scale_as.numeric(m$coeff[1]*m$disp)

dev.res_-2*log(dgamma(data,shape=shape,scale=scale))
loglik_sum(dev.res)  #actually -2 * log like

list(loglik=loglik,par=c(shape,scale))
}

#Fits data to a gamma distribution "by hand" using optim()
gamma2_function(data){
n_length(data)
m_summary(glm(data~1, family=Gamma))
shape_1/as.numeric(m$disp)

#L = -Log likelihood
L_function(x){-(-n*log(gamma(x[1]))+n*x[1]*log(x[1]/x[2])+(x[1]-1)*sum(log(data))-x[1]/x[2]
*sum(data))}
start_c(shape, mean(data))
parscale_start
fit_optim(start,L,method="L-BFGS-B",lower=c(shape/100,0),
upper=c(NA,NA),control=list(parscale=parscale))
shape_fit$par[1]
mu_fit$par[2]
scale_mu/shape

dev.res_-2*log(dgamma(data,shape=shape,scale=scale))
loglik_sum(dev.res)  #actually -2 * log like

list(loglik=loglik,par=c(shape,scale))
}


--
Dr. Richard Nixon
MRC Biostatistics Unit, Institute of Public Health,
Robinson Way, Cambridge, CB2 2SR
http://www.mrc-bsu.cam.ac.uk/personal/richard
Tel: +44 (0)1223 330382, Fax: +44 (0)1223 330388

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Mon Apr 22 17:54:05 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 22 Apr 2002 08:54:05 -0700 (PDT)
Subject: [R] lattice help
In-Reply-To: <3CC42E5F.FF6CA4A0@pdf.com>
Message-ID: <Pine.A41.4.44.0204220853020.166864-100000@homer06.u.washington.edu>

On Mon, 22 Apr 2002, Sundar Dorai-Raj wrote:

> I'm new to lattice and can't figure out what the problem is with the
> following example:
>
> #########################
> > library(lattice)
> Loading required package: grid
>
> Attaching package `lattice':
>
>
> 	The following object(s) are masked _by_ .GlobalEnv :
>
> 	 xyplot
>

	^^^^^^
  You have a function xyplot() in your global environment, and you're
using that function rather than the one in the 'lattice package'

You probably want to do
  rm(xyplot)
before loading 'lattice'

	-thomas
Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Apr 22 17:59:40 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Mon, 22 Apr 2002 16:59:40 +0100 (GMT Daylight Time)
Subject: [R] lattice help
In-Reply-To: <3CC42E5F.FF6CA4A0@pdf.com>
Message-ID: <Pine.WNT.4.44.0204221656580.2056-100000@gannet.stats.ox.ac.uk>

Two problems:

1) You have a version of xyplot in your workspace: see the message you
quoted.

2) Your R version is old, and may not match your version of lattice.


On Mon, 22 Apr 2002, Sundar Dorai-Raj wrote:

> I'm new to lattice and can't figure out what the problem is with the
> following example:
>
> #########################
> > library(lattice)
> Loading required package: grid
>
> Attaching package `lattice':
>
>
> 	The following object(s) are masked _by_ .GlobalEnv :
>
> 	 xyplot
>
>
> 	The following object(s) are masked from package:base :
>
> 	 levels
>
> > test.data <- data.frame(x=rnorm(100),
> +                         y=rnorm(100),
> +                         group=gl(5,20))
> > xyplot(y~x|group,data=test.data,
> +        panel=function(x,y,subscripts,df) {
> +          text(x,y,labels=as.character(df[subscripts,"group"]))
> +          abline(lm(y~x))
> +        },df=test.data)
> Error in unique(by) : Argument "by" is missing, with no default
> >
> #########################
>
> I get the same error when I try the examples from the `xyplot' help
> page:
>
> #########################
> > data(quakes)
> > xyplot(long ~ lat , data = quakes)
> Error in unique(by) : Argument "by" is missing, with no default
> >
> #########################
>
> What am I missing?
>
>
> > version
>          _
> platform i386-pc-mingw32
> arch     x86
> os       Win32
> system   x86, Win32
> status
> major    1
> minor    4.0
> year     2001
> month    12
> day      19
> language R
>
> Thanks,
>
> Sundar
>
> --
>
> Sundar Dorai-Raj, Ph.D.
> Statistical Methods Engineer
> PDF Solutions, Inc.
> (972) 889-3085 x216
> (214) 392-7619 cell
> sundard at pdf.com
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From sundard at pdf.com  Mon Apr 22 18:07:49 2002
From: sundard at pdf.com (Sundar Dorai-Raj)
Date: Mon, 22 Apr 2002 11:07:49 -0500
Subject: [R] lattice help
References: <Pine.WNT.4.44.0204221656580.2056-100000@gannet.stats.ox.ac.uk>
Message-ID: <3CC43555.B0D792D0@pdf.com>



Prof Brian D Ripley wrote:
> 
> Two problems:
> 
> 1) You have a version of xyplot in your workspace: see the message you
> quoted.

D'oh! Thanks to Thomas Lumley and Douglas Bates for pointing this out as
well. 

> 
> 2) Your R version is old, and may not match your version of lattice.

Could this by why Rterm is crashing when xyplot is invoked?

Sundar

-- 

Sundar Dorai-Raj, Ph.D.
Statistical Methods Engineer
PDF Solutions, Inc.
(972) 889-3085 x216
(214) 392-7619 cell
sundard at pdf.com
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Apr 22 18:11:46 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Mon, 22 Apr 2002 17:11:46 +0100 (GMT Daylight Time)
Subject: [R] lattice help
In-Reply-To: <3CC43555.B0D792D0@pdf.com>
Message-ID: <Pine.WNT.4.44.0204221710370.2476-100000@gannet.stats.ox.ac.uk>

On Mon, 22 Apr 2002, Sundar Dorai-Raj wrote:

>
>
> Prof Brian D Ripley wrote:
> >
> > Two problems:
> >
> > 1) You have a version of xyplot in your workspace: see the message you
> > quoted.
>
> D'oh! Thanks to Thomas Lumley and Douglas Bates for pointing this out as
> well.
>
> >
> > 2) Your R version is old, and may not match your version of lattice.
>
> Could this by why Rterm is crashing when xyplot is invoked?

Yes, it could be. lattice was bundled with rw1041 for that reason.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From sundard at pdf.com  Mon Apr 22 18:24:12 2002
From: sundard at pdf.com (Sundar Dorai-Raj)
Date: Mon, 22 Apr 2002 11:24:12 -0500
Subject: [R] lattice help
References: <Pine.WNT.4.44.0204221710370.2476-100000@gannet.stats.ox.ac.uk>
Message-ID: <3CC4392C.59E7FFA0@pdf.com>

> > > 2) Your R version is old, and may not match your version of lattice.
> >
> > Could this by why Rterm is crashing when xyplot is invoked?
> 
> Yes, it could be. lattice was bundled with rw1041 for that reason.
> 

Upgrading to 1.4.1 seems to work.

Thanks for the quick replies.

Sundar

-- 

Sundar Dorai-Raj, Ph.D.
Statistical Methods Engineer
PDF Solutions, Inc.
(972) 889-3085 x216
(214) 392-7619 cell
sundard at pdf.com
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dmcwilli at utk.edu  Mon Apr 22 19:12:57 2002
From: dmcwilli at utk.edu (David R. McWillliams)
Date: Mon, 22 Apr 2002 13:12:57 -0400 (EDT)
Subject: [R] Problem passing data into read.table()
Message-ID: <Pine.GSO.4.21.0204221304170.20346-100000@moe.cas.utk.edu>

I am trying to read in a tab-delimited data file with a 21 row header and
2 row footer using two calls to read.table().  Numbers of rows and columns
are variable.  The header contains information for calculating the number
of rows of data.  I can successfully pick this out and calculate the
number of rows to read, but cannot get the second read.table() to assign
this number to "nrows"  (the number is correct; if I enter it manually,
the everything works fine).  Currently the function reads all the way to
the end and crashes on the footer, since the number of fields is different
from that of the data.

I know this could easily be done with some Perl pre-processing of the
file, but it is going to run on a Windows machine and I am trying to
minimize the number of packages to download.  Nevertheless, there is the
general problem of why I cannnot pass a calculated value into the 
function.

Code follows.

#
# function to read data with header and footer
#

# pick line 8 with the data layout information and calculate the number of rows ...
grid.layout <- read.table(fname, as.is=T, header=F, sep="\t", comment.char="", skip=7, nrows=1)
row.ctr <- grid.layout[4]*grid.layout[5]*grid.layout[6]*grid.layout[7]

# tells me I have the right dimensions ...
print(row.ctr)

# but they do not get passed into this read.table() ...
tmp.df <- read.table(fname, as.is=T, header=T, sep="\t", comment.char="", skip=20, nrows=row.ctr )
tmp.df

# end function


Regards,



David R. McWilliams
dmcwilli at utk.edu




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Vansickle.John at epamail.epa.gov  Mon Apr 22 20:31:34 2002
From: Vansickle.John at epamail.epa.gov (Vansickle.John@epamail.epa.gov)
Date: Mon, 22 Apr 2002 11:31:34 -0700
Subject: [R] recording an R session
Message-ID: 
 <OF36367C95.C8CEC08A-ON88256BA3.0065408D-88256BA3.0065C54E@rtp.epa.gov>

Folks --

Is there any way to record an entire interactive R-session
(all commands AND results appearing in the Commands
window, excluding plots ) to a single external file? The
.Rhistory function only seems to record the commands.
This is for  the Windows version of R.

Thanks!

John Van Sickle
USEPA, National Health and Environmental Effects
       Laboratory, Western Ecology Division
200 SW 35th St.
Corvallis, OR 97333
ph: 541-754-4314
fax: 541-754-4716


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Apr 22 20:56:31 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 22 Apr 2002 19:56:31 +0100 (BST)
Subject: [R] recording an R session
In-Reply-To: <OF36367C95.C8CEC08A-ON88256BA3.0065408D-88256BA3.0065C54E@rtp.epa.gov>
Message-ID: <Pine.LNX.4.31.0204221952240.2038-100000@gannet.stats>

On Mon, 22 Apr 2002 Vansickle.John at epamail.epa.gov wrote:

> Folks --
>
> Is there any way to record an entire interactive R-session
> (all commands AND results appearing in the Commands
> window, excluding plots ) to a single external file? The
> .Rhistory function only seems to record the commands.
> This is for  the Windows version of R.

Up to a point.  File | Save to File... saves everything which has been
retained (if nothing is selected), but that may be less than the whole
session (and Ctrl-L clears it).  Incidentally, the history also has a
limited number of lines.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From reid_huntsinger at merck.com  Mon Apr 22 21:02:31 2002
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Mon, 22 Apr 2002 15:02:31 -0400
Subject: [R] Problem passing data into read.table()
Message-ID: <2C23DE2983BE034CB1CB90DB6B813FD639E95C@uswpmx11.merck.com>

I think you should avoid read.table here. It tries to set various parameters
(number of columns, etc) by looking at a part of your file. Even if you
specify col.names, it can get confused by this looking-ahead. Better look at
the definition of read.table in terms of scan and readLines and modify to
your needs.

Perhaps your problem isn't that nrows doesn't get the right value, but that
read.table is using the wrong number of columns. (Actually, I can't create
an example like yours that read.table doesn't complain about line 1 not
having n elements, where n is the number of elements in the longest line.)

If you really want to make read.table work, you can probably use the
fill=TRUE option and lots of caution.

Reid Huntsinger

-----Original Message-----
From: David R. McWillliams [mailto:dmcwilli at utk.edu]
Sent: Monday, April 22, 2002 1:13 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Problem passing data into read.table()


I am trying to read in a tab-delimited data file with a 21 row header and
2 row footer using two calls to read.table().  Numbers of rows and columns
are variable.  The header contains information for calculating the number
of rows of data.  I can successfully pick this out and calculate the
number of rows to read, but cannot get the second read.table() to assign
this number to "nrows"  (the number is correct; if I enter it manually,
the everything works fine).  Currently the function reads all the way to
the end and crashes on the footer, since the number of fields is different
from that of the data.

I know this could easily be done with some Perl pre-processing of the
file, but it is going to run on a Windows machine and I am trying to
minimize the number of packages to download.  Nevertheless, there is the
general problem of why I cannnot pass a calculated value into the 
function.

Code follows.

#
# function to read data with header and footer
#

# pick line 8 with the data layout information and calculate the number of
rows ...
grid.layout <- read.table(fname, as.is=T, header=F, sep="\t",
comment.char="", skip=7, nrows=1)
row.ctr <- grid.layout[4]*grid.layout[5]*grid.layout[6]*grid.layout[7]

# tells me I have the right dimensions ...
print(row.ctr)

# but they do not get passed into this read.table() ...
tmp.df <- read.table(fname, as.is=T, header=T, sep="\t", comment.char="",
skip=20, nrows=row.ctr )
tmp.df

# end function


Regards,



David R. McWilliams
dmcwilli at utk.edu




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._

------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message. If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dmcwilli at utk.edu  Mon Apr 22 21:21:34 2002
From: dmcwilli at utk.edu (David R. McWillliams)
Date: Mon, 22 Apr 2002 15:21:34 -0400 (EDT)
Subject: [R] Problem passing data into read.table()
In-Reply-To: <2C23DE2983BE034CB1CB90DB6B813FD639E95C@uswpmx11.merck.com>
Message-ID: <Pine.GSO.4.21.0204221516070.28351-100000@moe.cas.utk.edu>

I thought about scan(), but I think that would require knowing the number
of columns beforehand.  As I noted before, if I put in the number of
rows in the second call to read.table(), say 'nrows=2000', it correctly
detects the number of columns and rows.  I just can't get it to see the
calculated value as in 'nrows=row.ctr'.  The intervening print() can fetch
the value of row.ctr, so I don't understand why read.table() can't get it.



On Mon, 22 Apr 2002, Huntsinger, Reid wrote:

>Date: Mon, 22 Apr 2002 15:02:31 -0400
>From: "Huntsinger, Reid" <reid_huntsinger at merck.com>
>To: 'David R. McWillliams' <dmcwilli at utk.edu>, r-help at stat.math.ethz.ch
>Subject: RE: [R] Problem passing data into read.table()
>
>I think you should avoid read.table here. It tries to set various parameters
>(number of columns, etc) by looking at a part of your file. Even if you
>specify col.names, it can get confused by this looking-ahead. Better look at
>the definition of read.table in terms of scan and readLines and modify to
>your needs.
>
>Perhaps your problem isn't that nrows doesn't get the right value, but that
>read.table is using the wrong number of columns. (Actually, I can't create
>an example like yours that read.table doesn't complain about line 1 not
>having n elements, where n is the number of elements in the longest line.)
>
>If you really want to make read.table work, you can probably use the
>fill=TRUE option and lots of caution.
>
>Reid Huntsinger
>
>-----Original Message-----
>From: David R. McWillliams [mailto:dmcwilli at utk.edu]
>Sent: Monday, April 22, 2002 1:13 PM
>To: r-help at stat.math.ethz.ch
>Subject: [R] Problem passing data into read.table()
>
>
>I am trying to read in a tab-delimited data file with a 21 row header and
>2 row footer using two calls to read.table().  Numbers of rows and columns
>are variable.  The header contains information for calculating the number
>of rows of data.  I can successfully pick this out and calculate the
>number of rows to read, but cannot get the second read.table() to assign
>this number to "nrows"  (the number is correct; if I enter it manually,
>the everything works fine).  Currently the function reads all the way to
>the end and crashes on the footer, since the number of fields is different
>from that of the data.
>
>I know this could easily be done with some Perl pre-processing of the
>file, but it is going to run on a Windows machine and I am trying to
>minimize the number of packages to download.  Nevertheless, there is the
>general problem of why I cannnot pass a calculated value into the 
>function.
>
>Code follows.
>
>#
># function to read data with header and footer
>#
>
># pick line 8 with the data layout information and calculate the number of
>rows ...
>grid.layout <- read.table(fname, as.is=T, header=F, sep="\t",
>comment.char="", skip=7, nrows=1)
>row.ctr <- grid.layout[4]*grid.layout[5]*grid.layout[6]*grid.layout[7]
>
># tells me I have the right dimensions ...
>print(row.ctr)
>
># but they do not get passed into this read.table() ...
>tmp.df <- read.table(fname, as.is=T, header=T, sep="\t", comment.char="",
>skip=20, nrows=row.ctr )
>tmp.df
>
># end function
>
>
>Regards,
>
>
>
>David R. McWilliams
>dmcwilli at utk.edu
>
>
>
>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
>-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
>_._
>
>------------------------------------------------------------------------------
>Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message. If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.
>
>==============================================================================
>
>

David R. McWilliams
dmcwilli at utk.edu


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From presnell at stat.ufl.edu  Mon Apr 22 21:46:17 2002
From: presnell at stat.ufl.edu (Brett Presnell)
Date: Mon, 22 Apr 2002 15:46:17 -0400
Subject: [R] glm() function not finding the maximum
In-Reply-To: <Pine.GSO.4.44.0204221641030.4377-100000@moeran>
References: <Pine.GSO.4.44.0204221641030.4377-100000@moeran>
Message-ID: <15556.26761.953196.820776@minke.stat.ufl.edu>


In message <Pine.GSO.4.44.0204221641030.4377-100000 at moeran> you write:
> 
> #Fits data to a gamma distribution using glm()
> gamma1_function(data){
> n_length(data)
> m_summary(glm(data~1, family=Gamma(link=identity)))
> shape_1/as.numeric(m$disp)

You're not using the mle of the gamma shape parameter.  See the
function shape.gamma in library(MASS).

-- 
Brett Presnell
Department of Statistics
University of Florida
http://www.stat.ufl.edu/~presnell/
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From sundard at pdf.com  Mon Apr 22 22:31:42 2002
From: sundard at pdf.com (Sundar Dorai-Raj)
Date: Mon, 22 Apr 2002 15:31:42 -0500
Subject: [R] lattice x(y)lab and expression
Message-ID: <3CC4732E.6CCFB310@pdf.com>

Another question about lattice:

Is there a way to use plotmath in the labels and strips?

E.g.

xyplot(y~x|group,data=test.df,
       panel=function(x,y,subscripts,df) {
         llines(x,y,col="black",lwd=2)
         llines(x,df[subscripts,"lowerCI"],lty=2,col="#aaaaaa")
         llines(x,df[subscripts,"upperCI"],lty=2,col="#aaaaaa")
       },
       strip=function(...) {
         # not sure what to put here
         # but I would like something like
         # substitute(gamma[r]==2*pi*r,list(r=group))
         strip.default(strip.names=c(F,F),...)
       },
       par.strip.text=list(col="white",font=7),
       xlab=expression(rho),                     # this is ignored
       ylab=expression(f[r]*group("(",rho,")"))  # this is ignored
       df=test.df,as.table=T)

-- 

Sundar Dorai-Raj, Ph.D.
Statistical Methods Engineer
PDF Solutions, Inc.
(972) 889-3085 x216
(214) 392-7619 cell
sundard at pdf.com
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.murrell at auckland.ac.nz  Mon Apr 22 22:42:17 2002
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue, 23 Apr 2002 08:42:17 +1200
Subject: [R] lattice x(y)lab and expression
References: <3CC4732E.6CCFB310@pdf.com>
Message-ID: <004801c1ea3e$30ef0fd0$7632d882@stat.auckland.ac.nz>

Hi


> Another question about lattice:
> 
> Is there a way to use plotmath in the labels and strips?


Not currently.  It is planned for future versions.

Paul


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deepayansarkar at yahoo.com  Mon Apr 22 23:13:37 2002
From: deepayansarkar at yahoo.com (Deepayan Sarkar)
Date: Mon, 22 Apr 2002 14:13:37 -0700 (PDT)
Subject: [R] lattice x(y)lab and expression
In-Reply-To: <3CC4732E.6CCFB310@pdf.com>
Message-ID: <20020422211337.37256.qmail@web13904.mail.yahoo.com>


--- Sundar Dorai-Raj <sundard at pdf.com> wrote:
> Another question about lattice:
> 
> Is there a way to use plotmath in the labels and strips?


Not at present, since grid doesn't support it yet, but there are plans to
implement this in future. The closest you can get now is by using font=5 for
Greek, but I don't think it can be combined with other fonts, so that might not
be very useful.


> E.g.
> 
> xyplot(y~x|group,data=test.df,
>        panel=function(x,y,subscripts,df) {
>          llines(x,y,col="black",lwd=2)
>          llines(x,df[subscripts,"lowerCI"],lty=2,col="#aaaaaa")
>          llines(x,df[subscripts,"upperCI"],lty=2,col="#aaaaaa")
>        },
>        strip=function(...) {
>          # not sure what to put here
>          # but I would like something like
>          # substitute(gamma[r]==2*pi*r,list(r=group))
>          strip.default(strip.names=c(F,F),...)
>        },
>        par.strip.text=list(col="white",font=7),
>        xlab=expression(rho),                     # this is ignored
>        ylab=expression(f[r]*group("(",rho,")"))  # this is ignored
>        df=test.df,as.table=T)
> 
> -- 
> 
> Sundar Dorai-Raj, Ph.D.
> Statistical Methods Engineer
> PDF Solutions, Inc.
> (972) 889-3085 x216
> (214) 392-7619 cell
> sundard at pdf.com
>
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


__________________________________________________

Yahoo! Games - play chess, backgammon, pool and more

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlr25 at hermes.cam.ac.uk  Tue Apr 23 01:40:34 2002
From: tlr25 at hermes.cam.ac.uk (Tomek)
Date: Tue, 23 Apr 2002 00:40:34 +0100 (BST)
Subject: [R] Goodness-of-fit
Message-ID: <Pine.SOL.4.44.0204230032510.22910-100000@orange.csi.cam.ac.uk>

Hi,

I want to perform goodness of fit test for multinominal distribution. The
easiest way would be to use Chi2, but the measurment errors are not
normally distributed. I thought about using some bootstraping method to
perform the analysis. How can I do it in R?

Tomek

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jkawczak at uncc.edu  Tue Apr 23 02:53:24 2002
From: jkawczak at uncc.edu (Janusz Kawczak)
Date: Mon, 22 Apr 2002 20:53:24 -0400 (EDT)
Subject: [R] Goodness-of-fit
In-Reply-To: <Pine.SOL.4.44.0204230032510.22910-100000@orange.csi.cam.ac.uk>
Message-ID: <Pine.SOL.4.33.0204222045310.706-100000@is-sm1.uncc.edu>

Tomek:

I don't quite understand your problem. You are testing (or at least would
like to test) for the multinomial distribution and you are talking about
normal errors. What is the relationship to the errors? and why would one
need any assumption on normal errors in order to perform a Chi-Squared
test in the spirit of Pearson or Fisher (when the parameters of the
distribution are estimated from the sample)?

Maybe by answering these questions you will solve your problem.

Janusz.

** Janusz Kawczak							**
** UNC at Charlotte, Department of Mathematics, Room 350F		**
** 9201 University City Blvd.						**
** Charlotte, NC, 28223-0001, U.S.A.					**
** Tel.: (704) 687-2566 (W) (704) 921-0273 (H) Fax.: (704) 687-6415	**

On Tue, 23 Apr 2002, Tomek wrote:

tlr25>Hi,
tlr25>
tlr25>I want to perform goodness of fit test for multinominal distribution. The
tlr25>easiest way would be to use Chi2, but the measurment errors are not
tlr25>normally distributed. I thought about using some bootstraping method to
tlr25>perform the analysis. How can I do it in R?
tlr25>
tlr25>Tomek
tlr25>
tlr25>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
tlr25>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
tlr25>Send "info", "help", or "[un]subscribe"
tlr25>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
tlr25>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
tlr25>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jmiyamot at u.washington.edu  Tue Apr 23 03:04:53 2002
From: jmiyamot at u.washington.edu (John Miyamoto)
Date: Mon, 22 Apr 2002 18:04:53 -0700 (PDT)
Subject: [R] Summary: Multidimensional scaling
Message-ID: <Pine.A41.4.44.0204221803380.94242-100000@mead2.u.washington.edu>

I sent a query to R-Help about the availability of nonmetric
multidimensional scaling (MDS) algorithms in R.  I would like to thank
Tony Rossini, Jonathan Baron, Sundar Dorai-Raj, and Brian Ripley for
helpful replies.  The gist of the replies is that isoMDS in the MASS
library provides Kruskal's method for nonmetric MDS, sammon in the MASS
library provides Sammon's nonlinear mapping method for nonmetric MDS, and
cmdscale in the mva library provides metric MDS.  A function xgvis in the
xgobi package was mentioned but I have not acquired this package as yet.
The pcurve package is mentioned in R-FAQ as an MDS procedure, but it is
not on the Windows contributed page.

Thank you,

John

--------------------------------------------------------------------
John Miyamoto, Dept. of Psychology, Box 351525
University of Washington, Seattle, WA 98195-1525
Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
Homepage http://faculty.washington.edu/jmiyamot/
--------------------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jmiyamot at u.washington.edu  Tue Apr 23 03:17:11 2002
From: jmiyamot at u.washington.edu (John Miyamoto)
Date: Mon, 22 Apr 2002 18:17:11 -0700 (PDT)
Subject: [R] Subsetting by a logical condition and NA's
Message-ID: <Pine.A41.4.44.0204221808140.94242-100000@mead2.u.washington.edu>

I have run into a general problem with subsetting of which the following
is a simple example.  Suppose that

x <- c(5, NA, 7, 5, NA, 3)
y <- c(1,  2, 3, 4,  5, 6)

I want to extract the values of y for which x = 5, but y[x==5] yields

> y[x==5]
[1]  1 NA  4 NA

I find that y[!is.na(x) & x==5] yields the desired result:

> y[!is.na(x) & x==5]
[1] 1 4

but I am wondering whether there is a general way to specify a logical
condition such that it yields TRUE when the condition is true and FALSE
when the condition is either false or the input data is NA?  For example,
is there a simpler way to produce the same results as y[!is.na(x) & x==5]?

John

--------------------------------------------------------------------
John Miyamoto, Dept. of Psychology, Box 351525
University of Washington, Seattle, WA 98195-1525
Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
Homepage http://faculty.washington.edu/jmiyamot/
--------------------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ggrothendieck at yifan.net  Tue Apr 23 04:13:43 2002
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Mon, 22 Apr 2002 22:13:43 -0400
Subject: [R] skipping specific rows in read.table
In-Reply-To: <15556.2784.448531.984818@gargle.gargle.HOWL>
Message-ID: <3CC48B17.25636.2A4218@localhost>


read.table(fname,skip=2,col.names=read.table(fname,skip=1,nrows=1,as.is=T))

On 22 Apr 2002 at 9:06, David Kane  David Kane wrote:

> Hi,
> 
> We are considering organizing some of our ascii files with multiple "column
> names" like so:
> 
> a.long.but.complete.name	a.different.complex.name
> short.name.1	short.name.2
> 1	7
> 2	8
> 3	9
> [more data]
> 
> The basic idea is that we want to keep, in one location, both a long descriptive
> name of each variable (in row 1) and a short convenient name (in row 2). I
> could imagine keeping other information about the data in here as well.
> 
> [Comment: Of course, my CS buddies would say that the "grown up" way to handle
> this sort of thing is XML, but I haven't seen much discussion of people reading
> XML files directly into R -- although Duncan Temple Lang's R/SPlus XML Parsing
> Package looks quite interesting. In any event, since I don't have complete
> control over the format of these files, my options may be limitted. I would
> certainly love to hear about any XML/R success stories.]
> 
> In any event, I can easily use the "skip" argument to read.table to ignore the
> first row.
> 
> > read.delim("/home/a296180/tmp/junk.txt", skip = 1)
>   short.name.1 short.name.2
> 1            1            7
> 2            2            8
> 3            3            9
> 
> Is there a similar trick for ignoring the second row? That is, I want to
> produce a dataframe that looks like:
> 
>   a.long.but.complete.name a.different.complex.name
> 1                        1                        7
> 2                        2                        8
> 3                        3                        9
> 
> I can think of various hacks, including 1) adding a comment character to the
> second row prior to reading it in and 2) reading everything in and then
> deleting the second row and, perhaps, coercing the variable to be the
> appropriate type and 3) changing the code to read.table itself (which we did
> before to handle some issues made moot by Professor Ripley's marvelous
> `colClasses' addition to read.table), but I am hoping that there is a better
> way. To the extent that it matters, I am using R 1.4.0 patched on Solaris.
> 
> Thanks,
> 
> Dave Kane
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From emoriyama2 at unlnotes.unl.edu  Tue Apr 23 06:20:39 2002
From: emoriyama2 at unlnotes.unl.edu (Etsuko Moriyama)
Date: Mon, 22 Apr 2002 23:20:39 -0500
Subject: [R] Lattice graphics on Mac OS X
Message-ID: <77FC557F-5671-11D6-B592-00039301E590@unlnotes.unl.edu>

Hi, everybody.

I just started using R on Mac OS X.  I'm trying both of Carbon and 
Darwin version.   I used to use S-PLUS on Linux and want to use splom to 
do multi-plot.

I looked at both Carbon and Darwin version, but Carbon version doesn't 
seem to have Lattice library.  I downloaded the binary for Darwin 
version.  I have XDarwin/OroborOSX installed on my Mac's (G4 Powerbook 
and G4 desktop).  I attached Lattice/Grid and MASS libraries.  I tried 
"pairs" function, and it worked.  But what I really want to do is to 
superimpose 2 different sets of multi-plots.  I did it before with splom 
on SPLUS.  And now I want to do it on R.  But when I tried, the trellis 
like graphic window pops out, but no graphics.  On SPLUS, the window had 
some menu for print etc, but no such thing on R's Lattice empty window.

I'm doing what I used to do on SPLUS.  But am I missing something?  Just 
a very simple example like:

data(iris)
splom(~iris[1:4])

doesn't produce any graphics.  What I see is only a gray empty window 
with no menu or button...

Is there anybody who could use trellis/Lattice graphics on OS X?  I'm 
using OSX 10.1.4.

Thank you very much!

Etsuko



------------------------------------------------------------
Etsuko Moriyama
University of Nebraska
Lincoln, NE 68588-0660

Phone: (402) 472-4979
Email: emoriyama2 at unl.edu

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From yuelin at mail.med.upenn.edu  Tue Apr 23 06:24:21 2002
From: yuelin at mail.med.upenn.edu (Yuelin Li)
Date: Tue, 23 Apr 2002 00:24:21 -0400 (EDT)
Subject: [R] Subsetting by a logical condition and NA's
In-Reply-To: <Pine.A41.4.44.0204221808140.94242-100000@mead2.u.washington.edu>
Message-ID: <Pine.OSF.4.33.0204230010390.161064-100000@pobox.upenn.edu>

Hi, John,

Often I use y[ which(x == 5) ] to bypass the NAs, and
y[ -which(x == 5) ] includes the mismatches and NAs.  In
all cases I have tested it works on both R and Splus,
which I think is worth the extra which().  Also
I think "x %in% c(5)" or match(x, table=5) in R gives you
what you wanted.

Yuelin.


-----  On Mon, 22 Apr 2002, John Miyamoto wrote:

I have run into a general problem with subsetting of which the following
is a simple example.  Suppose that

x <- c(5, NA, 7, 5, NA, 3)
y <- c(1,  2, 3, 4,  5, 6)

I want to extract the values of y for which x = 5, but y[x==5] yields

> y[x==5]
[1]  1 NA  4 NA

I find that y[!is.na(x) & x==5] yields the desired result:

> y[!is.na(x) & x==5]
[1] 1 4

but I am wondering whether there is a general way to specify a logical
condition such that it yields TRUE when the condition is true and FALSE
when the condition is either false or the input data is NA?  For example,
is there a simpler way to produce the same results as y[!is.na(x) & x==5]?

John

--------------------------------------------------------------------
John Miyamoto, Dept. of Psychology, Box 351525
University of Washington, Seattle, WA 98195-1525
Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
Homepage http://faculty.washington.edu/jmiyamot/
--------------------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From macq at llnl.gov  Tue Apr 23 06:24:07 2002
From: macq at llnl.gov (Don MacQueen)
Date: Mon, 22 Apr 2002 21:24:07 -0700
Subject: [R] Subsetting by a logical condition and NA's
In-Reply-To: 
 <Pine.A41.4.44.0204221808140.94242-100000@mead2.u.washington.edu>
References: 
 <Pine.A41.4.44.0204221808140.94242-100000@mead2.u.washington.edu>
Message-ID: <a05111701b8ea91da44c3@[12.232.80.173]>


>  x <- c(5, NA, 7, 5, NA, 3)
>  y <- c(1,  2, 3, 4,  5, 6)
>  y[x %in% 5]
[1] 1 4

I learned about this trick, if I remember correctly, from reading the 
notes on what's new in the upcoming R 1.5.1

-Don

At 6:17 PM -0700 4/22/02, John Miyamoto wrote:
>I have run into a general problem with subsetting of which the following
>is a simple example.  Suppose that
>
>x <- c(5, NA, 7, 5, NA, 3)
>y <- c(1,  2, 3, 4,  5, 6)
>
>I want to extract the values of y for which x = 5, but y[x==5] yields
>
>>  y[x==5]
>[1]  1 NA  4 NA
>
>I find that y[!is.na(x) & x==5] yields the desired result:
>
>>  y[!is.na(x) & x==5]
>[1] 1 4
>
>but I am wondering whether there is a general way to specify a logical
>condition such that it yields TRUE when the condition is true and FALSE
>when the condition is either false or the input data is NA?  For example,
>is there a simpler way to produce the same results as y[!is.na(x) & x==5]?
>
>John
>
>--------------------------------------------------------------------
>John Miyamoto, Dept. of Psychology, Box 351525
>University of Washington, Seattle, WA 98195-1525
>Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
>Homepage http://faculty.washington.edu/jmiyamot/
>--------------------------------------------------------------------
>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Peter.Watkins at foodscience.afisc.csiro.au  Tue Apr 23 06:23:48 2002
From: Peter.Watkins at foodscience.afisc.csiro.au (Peter.Watkins@foodscience.afisc.csiro.au)
Date: Tue, 23 Apr 2002 14:23:48 +1000
Subject: [R] Use of nls command
Message-ID: <1F8EDF0AE0FFC643BC8FE577BC4919E624ADCE@tomtom-wb.mel.foodscience.afisc.csiro.au>

Hello.

I am trying to do a non-linear fit using the 'nls' command.

The data that I'm using is as follows
    pH     k
1 3.79 34.21
2 4.14 25.85
3 4.38 20.45
4 4.57 15.61
5 4.74 12.42
6 4.92  9.64
7 5.11  7.30
8 5.35  5.15
9 5.67  3.24
	
with a transformation of pH to H <- 10^-pH

When using the nls command for a set of parameters - a, b and c, I receive
two sets of errors:

> ba.nls <- nls( k ~ a/(1+(H/b)) +c*(H/b)/(1+(H/b)), data = obs, start =
list( a= 1, b = 1, c = 2), trace = TRUE )
2579.16 :  1 1 2 
1266.912 :   8.041114e+00 -1.811360e+08 -1.809427e+08 
1243.136 :  8.237232e+00 2.304521e+15 2.269853e+15 
Error in nls(k ~ a/(1 + (H/b)) + c * (H/b)/(1 + (H/b)), data = obs, start =
list(a = 1,  : 
        step factor 0.000488281 reduced below `minFactor' of 0.000976563

> ba.nls <- nls( k ~ a/(1+(H/b)) +c*(H/b)/(1+(H/b)), data = obs, start =
list( a= 5, b = 1, c = 2), trace = TRUE )
1724.262 :  5 1 2 
Error in nls(k ~ a/(1 + (H/b)) + c * (H/b)/(1 + (H/b)), data = obs, start =
list(a = 5,  : 
        singular gradient

I suspect that my initial set of starting values are the problem but I'm
open for comments.

Regards, Peter
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ggrothendieck at yifan.net  Tue Apr 23 06:40:04 2002
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Tue, 23 Apr 2002 00:40:04 -0400
Subject: [R] Subsetting by a logical condition and NA's
In-Reply-To: <Pine.A41.4.44.0204221808140.94242-100000@mead2.u.washington.edu>
Message-ID: <3CC4AD64.9215.B03F0E@localhost>


subset(y,x==5)

On 22 Apr 2002 at 18:17, John Miyamoto wrote:

> I have run into a general problem with subsetting of which the following
> is a simple example.  Suppose that
> 
> x <- c(5, NA, 7, 5, NA, 3)
> y <- c(1,  2, 3, 4,  5, 6)
> 
> I want to extract the values of y for which x = 5, but y[x==5] yields
> 
> > y[x==5]
> [1]  1 NA  4 NA
> 
> I find that y[!is.na(x) & x==5] yields the desired result:
> 
> > y[!is.na(x) & x==5]
> [1] 1 4
> 
> but I am wondering whether there is a general way to specify a logical
> condition such that it yields TRUE when the condition is true and FALSE
> when the condition is either false or the input data is NA?  For example,
> is there a simpler way to produce the same results as y[!is.na(x) & x==5]?
> 
> John
> 
> --------------------------------------------------------------------
> John Miyamoto, Dept. of Psychology, Box 351525
> University of Washington, Seattle, WA 98195-1525
> Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
> Homepage http://faculty.washington.edu/jmiyamot/
> --------------------------------------------------------------------
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr 23 09:12:34 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 23 Apr 2002 08:12:34 +0100 (BST)
Subject: [R] Lattice graphics on Mac OS X
In-Reply-To: <77FC557F-5671-11D6-B592-00039301E590@unlnotes.unl.edu>
Message-ID: <Pine.LNX.4.31.0204230803240.4130-100000@gannet.stats>

On Mon, 22 Apr 2002, Etsuko Moriyama wrote:

> I just started using R on Mac OS X.  I'm trying both of Carbon and
> Darwin version.   I used to use S-PLUS on Linux and want to use splom to
> do multi-plot.
>
> I looked at both Carbon and Darwin version, but Carbon version doesn't
> seem to have Lattice library.  I downloaded the binary for Darwin
> version.  I have XDarwin/OroborOSX installed on my Mac's (G4 Powerbook
> and G4 desktop).  I attached Lattice/Grid and MASS libraries.  I tried
> "pairs" function, and it worked.  But what I really want to do is to
> superimpose 2 different sets of multi-plots.  I did it before with splom
> on SPLUS.  And now I want to do it on R.  But when I tried, the trellis
> like graphic window pops out, but no graphics.  On SPLUS, the window had
> some menu for print etc, but no such thing on R's Lattice empty window.

How graphics windows work depends on the platform in both R and S-PLUS.
For R under Unix-alikes (which darwin is) there are no menus on a graphics
window. (It is an R graphics window, not a Lattice window, BTW.)
The Windows and Carbin ports of R do have such menus, as does the
gnome GUI front-end for Unix.  (You might want to explore the latter if it
is provided on your build.)

> I'm doing what I used to do on SPLUS.  But am I missing something?  Just
> a very simple example like:
>
> data(iris)
> splom(~iris[1:4])
>
> doesn't produce any graphics.  What I see is only a gray empty window
> with no menu or button...

That works under Linux and Windows, so presumably something is up with
your build of R.

> Is there anybody who could use trellis/Lattice graphics on OS X?  I'm
> using OSX 10.1.4.

More usefully, which version of R, lattice and grid are you using?
You said it was `gray': because of the bug the current version of lattice
for R 1.4.1 uses a white background, so I suspect yours is not current.

You may want to wait a week until R 1.5.0 is released. That will ship with
lattice, and the grid/lattice packages included have been considerably
improved since 1.4.1.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From adrian.trapletti at lmttrading.com  Tue Apr 23 09:20:45 2002
From: adrian.trapletti at lmttrading.com (Adrian Trapletti)
Date: Tue, 23 Apr 2002 09:20:45 +0200
Subject: [R] Re: R-help Digest V2 #710
References: <200204230201.EAA24556@stat.math.ethz.ch>
Message-ID: <3CC50B4D.7E09DC5E@lmttrading.com>

> Date: Mon, 22 Apr 2002 07:21:41 +0000
> From: "sonchawan tamkaew" <psu17772 at hotmail.com>
> Subject: [R] PP.test
>
> Hello there,
>
> I would like to know whether PP.test from library(ts) is appropriate to test
> unit root in financial data (daily)?
>
> Thank you for your help.
>
> Sonchawan
>

In principle yes. However, it is by now a well know fact that the PP test has severe size distortions for certain processes (e.g. integrated MA(1)). A more robust alternative in some situations is the Augmented-Dickey-Fuller test which is provided by tseries (see adf.test).

best
Adrian



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From klaus.langohr at upc.es  Tue Apr 23 10:00:06 2002
From: klaus.langohr at upc.es (Klaus Langohr)
Date: Tue, 23 Apr 2002 10:00:06 +0200
Subject: [R] kaplanMeier & censorReg
Message-ID: <3CC51486.643CB86C@upc.es>

Hi everybody,
Working with interval censored data using S+, I often use the survival
analysis' functions kaplanMeier() and censorReg().
Does anybody know, whether these functions exist in R, too?
Thanks in advance for any answer!

Saludos,

Klaus.

----------------------------------------------------
Klaus Langohr
Departament d?Estad?stica i Investigaci? Operativa
Universitat Polit?cnica de Catalunya
C/ Pau Gargallo, 5
E-08028 Barcelona
Tel: (+34) 93.401.6939
Fax: (+34) 93.401.5855
-----------------------------------------------------


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From zedshaw at zedshaw.com  Tue Apr 23 11:51:45 2002
From: zedshaw at zedshaw.com (Zed Shaw)
Date: 23 Apr 2002 02:51:45 -0700
Subject: [R] Improving R Editing:  JEdit Support for R
Message-ID: <1019555505.3920.45.camel@workhorse.killnine.net>

Hello All,

So, after sending out the comments earlier in the list, giving
suggestions for improvement to the R project, I went into hiding and
started working on some of them.  Most of the R web site stuff I have no
control over, but I plan to work up a proposed site layout and a plan to
add features for navigation improvements.  Everyone will be free to
comment on these when they are available.

My first order of business was to improve the editing and usability of
R.  At first I thought about writing my own interface, but after using
JEdit (http://www.jedit.org) and finding that I can add most of the
features, and then some, that ESS provides very easily, I decided to
just create plugins and support files for JEdit.  What I have right now
is a decent syntax edit mode for JEdit.  Everyone can get it from the
http://community.jedit.org/ and going to the downloads section.

My plans for integration JEdit with R are as follows:

1)  Improve syntax highlighting edit mode.
2)  Create easy ways to run R scripts from within JEdit.
3)  Provide R help file searching and browsing with JEdit Help support.
4)  CodeAid support for R so you can have nice command/variable
completion.
5)  Possibly integrate R for Java from Omegahat.

Everyone is free to check out both JEdit and the edit mode to see if
they like it.  JEdit is an excellent editor written in Java that
provides a very nice editing interface, and is supported on many
platforms (including Windows).  It is fast, has excellent XML support,
Java, C++, and allows you to extend it with Plugins and other things.
Give it a try, and feel free to contact me if you have problems getting
the RS.xml edit mode file working.

More stuff to come...

Zed A. Shaw




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From david.pearson at mail.nerc-essc.ac.uk  Tue Apr 23 11:03:04 2002
From: david.pearson at mail.nerc-essc.ac.uk (David Pearson)
Date: Tue, 23 Apr 2002 10:03:04 +0100
Subject: [R] R and OS X
References: <a05101500b8e5b785fdaa@[10.5.12.44]>
	 <3CC02E89.4957FC4A@sentoo.sn> <a05101507b8e5e21af89d@[10.5.12.44]>
Message-ID: <3CC52348.8B9F2EFA@mail.nerc-essc.ac.uk>



Tristan Lorino wrote:
> 
> >  Dears users,
> >  I'm trying to run R on a computer with OS X. I installed the R folder
> >  and the dylibs, where they must be installed. I updated my path, and
> >  R runs but tells me :
> >
> >  dyld: /usr/local/R-1.4.0/lib/R/bin/R.bin version mismatch for
> >  library: /usr/lib/libz.1.dylib (compatibility version of user: 1.1.3
> >  greater than library's version: 1.0.0)
> >
> >  The only thing I didn't do -- because I don't know how one can do
> >  this -- is to put /sw/lib first in the
> >  DYLD_LIBRARY_PATH environmental variable.

Hello Tristan,


I think your problem may be a different one. See item 5 of my
R installation notes below. (I copy the whole lot as other items
may be of interest also.)

The ReadMe.txt file of the Darwin installation says this:
"If R asks for a 
version of any of these dylibs which is named slightly differently
(for instance libz.1.dylib), then just put in a symbolic link in /sw/lib,
i.e. "ln -s libz.1.1.3.dylib libz.1.dylib"."

This is what I had to do to make R work.

Regards,
David.


020328

1. Installed the binary files for R-1.4.0 today (now Thursday).
2. tried to run it today, got dyld errors.
3. Copied all the .dylibs into /sw/lib, as instructed.
4. Got dyld errors again.
5. Made symbolic links as instructed.
6. Now works, but gives runtime error:
/usr/local/R-1.4.0/lib/R/bin/pager: no such file or directory: /sw/bin/less
7. Fixed this by putting the correct path to "less" in
/usr/local/R-1.4.0/lib/R/etc/Renviron
8. Now get postscript error.
9. Restart then OK.
10. Forgot to say that I tar'd the /sw/lib directory, and it is (I hope)
in this here directory now.

020409

1. Tried to install the "as.date" etc. functions in the "date" package,
as follows:
(a)  Got date_1.2-12.tar.gz on desktop.
(b)  R CMD INSTALL date

2. Got errors saying gcc not found - actually need to pick up cc.
3. Tracked down the problem to
	/usr/local/R-1.4.0/lib/R/etc/Makeconf
.. so copied this to Makeconf_as_installed and edited original
to change "gcc" to "cc" in both places.

4. Got another error, saying couldn't find perl.
5. Tracked down the problem to
	/usr/local/R-1.4.0/lib/R/etc/Renviron
.. so copied this to Renviron_as_installed and edited original
to change "PERL=${PERL-/usr/local/bin/perl}" to "PERL=${PERL-/usr/bin/perl}"
at its only occurence.

6. Installation then OK.

7. Ran R, did "library()" and saw "date" was there. Did "library(date)" and
accessed the date things OK. Can now do things like:

> mdy.date(10,29,65)
[1] 29Oct65

> mdy.date(4,9,2002) - mdy.date(10,29,65)
[1] 13311

> as.integer( mdy.date(10,31,1970) )
[1] 3956



-- 
David Pearson,              Phone: +44 (0)118  9318741
ESSC,                       Fax:   +44 (0)118  9316413 
University of Reading,      Email: dwcp at mail.nerc-essc.ac.uk
Reading RG6 6AL,           
UK.                         www.nerc-essc.ac.uk/~dwcp/Home.html
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jasont at indigoindustrial.co.nz  Tue Apr 23 23:24:31 2002
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Tue, 23 Apr 2002 21:24:31 +0000
Subject: [R] Problem passing data into read.table()
In-Reply-To: <Pine.GSO.4.21.0204221516070.28351-100000@moe.cas.utk.edu>; from dmcwilli@utk.edu on Mon, Apr 22, 2002 at 03:21:34PM -0400
References: <2C23DE2983BE034CB1CB90DB6B813FD639E95C@uswpmx11.merck.com> <Pine.GSO.4.21.0204221516070.28351-100000@moe.cas.utk.edu>
Message-ID: <20020423212431.A1575@camille.indigoindustrial.co.nz>

On Mon, Apr 22, 2002 at 03:21:34PM -0400, David R. McWillliams wrote:
> I thought about scan(), but I think that would require knowing the number
> of columns beforehand.  

Sounds like you need file(),readLines(), and strsplit(), with
a home-brewed data frame filler loop.

Something like (untested - just giving the idea here):

con <- file(fname)
header <- readLines(con, n=21)

#some magic here, to get the max number of columns
max.cols <- magic stuff

my.data <- readLines(con)

#and let's be hygenic
close(con) 

#chop off the last 2 lines, as they're footer stuff we don't want
#pushBack would probably work too, but I'm less familiar with it.
last.two <- ( length(my.data)-1 ):length(my.data)
my.data <- my.data[-last.two]

#split by tabs
my.data <- strsplit(my.data,"\t")

my.mat <- matrix(NA,ncol=max.cols,nrow=length(my.data))

for(i in seq(along=my.data)) {
	for(j in seq(along=my.data[[i]]) {
		my.mat[i][j] <- as.numeric(my.data[[i]][j])
	}
}


> As I noted before, if I put in the number of
> rows in the second call to read.table(), say 'nrows=2000', it correctly
> detects the number of columns and rows.  I just can't get it to see the
> calculated value as in 'nrows=row.ctr'.  The intervening print() can fetch
> the value of row.ctr, so I don't understand why read.table() can't get it.

Not sure.  Have you played with debug() ?  I've found that very, very
handy for when I lose values - just walk slowly through the function,
one step at a time, and print out values as you think they might be 
changing.

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Tue Apr 23 11:30:03 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 23 Apr 2002 11:30:03 +0200
Subject: [R] kaplanMeier & censorReg
References: <3CC51486.643CB86C@upc.es>
Message-ID: <3CC5299B.1A18D73E@statistik.uni-dortmund.de>

Klaus Langohr wrote:
> 
> Hi everybody,
> Working with interval censored data using S+, I often use the survival
> analysis' functions kaplanMeier()
>
> and censorReg().
> Does anybody know, whether these functions exist in R, too?
> Thanks in advance for any answer!

Hi Klaus!

There is a package survival for survival analysis available in R (e.g.
function survfit()).

Another point to look is the function km() (Kaplan Meier) in package
"event" (by Jim Lindsey), available at Jim's homepage: 
http://alpha.luc.ac.be/~lucp0753/

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baba at muj.biglobe.ne.jp  Tue Apr 23 11:35:22 2002
From: baba at muj.biglobe.ne.jp (baba@muj.biglobe.ne.jp)
Date: Tue, 23 Apr 2002 18:35:22 +0900
Subject: [R] Tree package on R 1.4.1
Message-ID: <10204230935.AA00248@MyComputer.muj.biglobe.ne.jp>

Dear R-users

I would like to apply classification and regression tree(CART) to the following data. 
I have some question on using 'tree' package.
The data contains one response variable Y and five explanatory variables.
The explanatory variable "x2" is categorical and not ordinal.
But, the result obtained after running following R code 
has indicated that x2 is regard as continuous variable.
I think that CART procedure can be available to categorical and continuous variables.

How can I correct the R code such that x2 is regard as categorical and not ordinal?
By all means, reply me your suggestion or comments.

Thanks and best regards,
Baba

----------beginning  of R code --------------------
inputlist <- list(Y=0, x1=0, x2=0, x3=0,x4=0,x5=0)
# inputlist <- list(Y=0, x1=0, x2="", x3=0,x4=0,x5=0)
Ex6 <- scan("c:\\data\\CART\\EX6.txt",inputlist)
Ex6.ltr <- tree(Y ~ x1 + x2 +x3 + x4 +x5 ,Ex6)
----------end of R code ---------------------------


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr 23 12:16:08 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 23 Apr 2002 11:16:08 +0100 (BST)
Subject: [R] Tree package on R 1.4.1
In-Reply-To: <10204230935.AA00248@MyComputer.muj.biglobe.ne.jp>
Message-ID: <Pine.LNX.4.31.0204231055380.5443-100000@gannet.stats>

On Tue, 23 Apr 2002 baba at muj.biglobe.ne.jp wrote:

> Dear R-users
>
> I would like to apply classification and regression tree(CART) to the following data.

You can use a classification tree or a regression tree, but not a
`classification and regression tree'.  Your usage below suggests you want
a regression tree.

> I have some question on using 'tree' package.
> The data contains one response variable Y and five explanatory variables.
> The explanatory variable "x2" is categorical and not ordinal.
> But, the result obtained after running following R code
> has indicated that x2 is regard as continuous variable.

Well, that *is* what you asked for!  You read x2 as a numeric variable in
scan.  ?tree will tell you how to specify a categorical variable (via a
factor).

> I think that CART procedure can be available to categorical and continuous variables.
>
> How can I correct the R code such that x2 is regard as categorical and not ordinal?

Try  Ex6$x2 <- factor(Ex6$x2).


Note that the rpart package is the recommended way to perform tree-based
analyses in R, and that `CART' is a trademark of a commercial package.

> By all means, reply me your suggestion or comments.
>
> Thanks and best regards,
> Baba
>
> ----------beginning  of R code --------------------
> inputlist <- list(Y=0, x1=0, x2=0, x3=0,x4=0,x5=0)
> # inputlist <- list(Y=0, x1=0, x2="", x3=0,x4=0,x5=0)
> Ex6 <- scan("c:\\data\\CART\\EX6.txt",inputlist)
> Ex6.ltr <- tree(Y ~ x1 + x2 +x3 + x4 +x5 ,Ex6)
> ----------end of R code ---------------------------

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From james.lindsey at luc.ac.be  Tue Apr 23 13:17:01 2002
From: james.lindsey at luc.ac.be (Jim Lindsey)
Date: Tue, 23 Apr 2002 13:17:01 +0200 (MET DST)
Subject: [R] kaplanMeier & censorReg
In-Reply-To: <3CC5299B.1A18D73E@statistik.uni-dortmund.de> from "Uwe Ligges" at Apr 23, 2002 11:30:03 AM
Message-ID: <200204231117.NAA31646@luc.ac.be>

> 
> Klaus Langohr wrote:
> > 
> > Hi everybody,
> > Working with interval censored data using S+, I often use the survival
> > analysis' functions kaplanMeier()
> >
> > and censorReg().
> > Does anybody know, whether these functions exist in R, too?
> > Thanks in advance for any answer!
> 
> Hi Klaus!
> 
> There is a package survival for survival analysis available in R (e.g.
> function survfit()).
> 
> Another point to look is the function km() (Kaplan Meier) in package
> "event" (by Jim Lindsey), available at Jim's homepage: 
> http://alpha.luc.ac.be/~lucp0753/

For parametric regression models with a wide variety of distributions,
the functions in my gnlm library handle, left-, right-, and
interval-censoring. Jim

> 
> Uwe Ligges
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From swisdom at techemail.com  Tue Apr 23 16:41:28 2002
From: swisdom at techemail.com (Steve Wisdom)
Date: Tue, 23 Apr 2002 07:41:28 -0700 (PDT)
Subject: [R] re| `Upgrading to 1.4.1 seems to work'
Message-ID: <20020423144128.5C85F36FA@sitemail.everyone.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20020423/e187768b/attachment.pl

From email at email.com  Tue Apr 23 15:25:22 2002
From: email at email.com (email@email.com)
Date: Tue, 23 Apr 2002 15:25:22
Subject: [R] Website ? FAST !
Message-ID: <auto-000001868174@albion.co.uk>


Thankyou for taking the time to read this email,

HoLmeComputing is offering you a special offer on website hosting and domain name registration.

Set on a Windows 2000 secure server, running ASP, Frontpage and noe ASP.NET for the advanced users.

Hosting from 1 per month
Domain name registration from 8

We also conduct high end NO fuss website design to meet your needs.

Please reply to this email for a full price list.

Regards

Gavin Holmes
www.holmecomputing.com
E: holmecomputing at hotmail.com
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Tue Apr 23 17:36:48 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 23 Apr 2002 11:36:48 -0400
Subject: [R] error loading huge .RData
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC23F@usrymx10.merck.com>

Dear R-help,

I've run into a problem loading .RData:  I was running a large computation,
which supposedly produce a large R object.  At the end of the session, I did
a save.image() and then quit.  The .RData has size 613,249,399 bytes.  Now I
can't get R to load this .RData file.  Whenever I tried, I get "Error:
vector memory exhausted (limit reached)".  I tried adding
"--min-vsize=1000M", but that didn't help.  I also tried R  --vanilla and
then attach(".RData"), same error.

>From what I can see, the file is not corrupted.  How can I get R to load it?

System info:
R-1.4.1 on Mandrake Linux 7.1 (kernel 2.4.3)
Dual P3-866 Xeon with 2GB RAM.

Regards,
Andy



------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named in this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ltorgo at liacc.up.pt  Tue Apr 23 18:05:04 2002
From: ltorgo at liacc.up.pt (Luis Torgo)
Date: Tue, 23 Apr 2002 17:05:04 +0100
Subject: [R] Writing text in lattice graphics
Message-ID: <20020423155204.D0ED31B96F@mail.liacc.up.pt>

I'm trying to obtain a set of regression lines obtained for different values 
of a factor using lattice. I would like to add a string to each panel showing 
the R^2 value of the respective line, but I'm having difficulties positioning 
the text (namely on which coordinates to give to the "ltext" function).
Here is what I'm using (I've used ?? for the things I would like you to be so 
kind to help me on how to fill in).

>  xyplot(O2 ~ Am | Site, data = mydata, scales=list(x='free'),
	panel=function(x,y,...) {
		panel.xyplot(x,y,...)
		panel.lmline(x,y,...)
		ltext(??, ??, round(summary(lm(y ~ x))$r.squared,3))
	})

I would like the R^2 values to appear in the top left corner of each of the 
panels I get.
I've tried fixed values for the "x", "y" parameters of "ltext", but as I'm 
using different X scales for each panel things get messy...

I'm using R 1.4.1 on a Windows 2000 machine.

Thank you in advance.

-- 
Luis Torgo
    FEP/LIACC, University of Porto   Phone : (+351) 22 607 88 30
    Machine Learning Group           Fax   : (+351) 22 600 36 54
    R. Campo Alegre, 823             email : ltorgo at liacc.up.pt
    4150 PORTO   -  PORTUGAL         WWW   : http://www.liacc.up.pt/~ltorgo
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From elvis at xlsolutions-corp.com  Tue Apr 23 18:09:58 2002
From: elvis at xlsolutions-corp.com (Elvis Miller, PhD)
Date: Tue, 23 Apr 2002 12:09:58 -0400
Subject: [R] New Course*** R/S-Plus Programming Techniques II, May 20-21
Message-ID: <200204231609.g3NG9wJ79449@email.featureprice.com>

XLSolutions Corporation (www.xlsolutions-corp.com) is pleased
to announce a new course: "R/S-plus Programming Techniques II".

****Salt Lake city, UTAH ------------->  May 20-21, 2002
****Boston, MA ----------------------->  May 27-28, 2002
****Chicago, IL ----------------------->  May 27-28, 2002


Course Description:

This intermediate level course is recommended for
statisticians/analysts who have some previous experience
using R/S-plus and who wish to hone their skills.
Casual users can "fill in the gaps" of their knowledge 
to make better use of R/S-PLus.

This course will focus on advanced graphics, Vectorization, 
resource management, connecting to C++, introduction to 
classes and methods (including S4 classes)  and statistical
modeling. 


Course Outline:

- Overview of R/S-Plus
- Comparison of R and S-Plus
- How can R Complement SAS?
- Data Manipulation and Graphics
- Taking advantage of fast objects and fast functions
- Using Advanced Lattice/Trellis Graphics
- Enhancing Plots
- Using High-level Plotting Functions
- Writing Functions
- Avoiding Loops
- Vectorization
- Statistical Modeling 
- Generalized Linear Models
- Linear Regression
- Survival Analysis
- Parametric Models, etc
- Project Management
- Resource Management
- Techniques for Effective use of R and S
- Connecting to C++
- Introduction to Classes (S4/S-Plus) and Methods
- Building and Distributing Packages (libraries)

Price:
 
Early-bird Commercial: $995.  Includes Continental Breakfast!
Email us for SPECIAL group academic fee.

Registration: 

Email Sue Turner: sue at xlsolutions-corp.com
Phone: 206-686-1578 x221
Visit us: www.xlsolutions-corp.com/training.htm


Course Format:

This course consists of a series of short lectures with 
demonstrations and interactive sessions for the participants. 
Each student is provided with bound copies of the notes and 
a CD-ROM containing all examples, exercises and software used 
on the course.



Share Your Thoughts:

Are there any additional topics you would like for this course to address?
Would you like for this course to be offered in another city? 

Please let us know by contributing to our recommendation list: 
training at xlsolutions-corp.com.

========================================================================

R/S-Plus Programming Techniques II / May 2002
Pre-registration Form (Please email or print and fax: 206-686-1578)
XLsolutions Corporation: For your Solutions needs, Consulting and Training.
www.xlsolutions-corp.com



Title...... First Name ................. Last Name....................

Organization..........................................................

Mailing Address....................................................... 

.....................................................................

.....................................................................

Zip Code...................... Country.............................

Telephone........................... Fax ...............................

E-mail................................................................

Payment will be made by: (1) check (2) invoice (3) bank transfer



Elvis Miller, PhD
Manager Training and Technical Support
North American Division
XLSolutions Corporation
Email: elvis at xlsolutions-corp.com
Phone: 206-686-1578
Web: www.xlsolutions-corp.com



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Tue Apr 23 18:27:34 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 23 Apr 2002 09:27:34 -0700 (PDT)
Subject: [R] kaplanMeier & censorReg
In-Reply-To: <3CC51486.643CB86C@upc.es>
Message-ID: <Pine.A41.4.44.0204230904320.115330-100000@homer34.u.washington.edu>

On Tue, 23 Apr 2002, Klaus Langohr wrote:

> Hi everybody,
> Working with interval censored data using S+, I often use the survival
> analysis' functions kaplanMeier() and censorReg().
> Does anybody know, whether these functions exist in R, too?

The survival functions are in the "survival" package

survreg()  fits accelerated failure models to left,right or interval
		censored data

The survfit() function doesn't handle interval censored data yet (the next
version will when I port it).

	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deepayansarkar at yahoo.com  Tue Apr 23 18:33:34 2002
From: deepayansarkar at yahoo.com (Deepayan Sarkar)
Date: Tue, 23 Apr 2002 09:33:34 -0700 (PDT)
Subject: [R] Writing text in lattice graphics
In-Reply-To: <20020423155204.D0ED31B96F@mail.liacc.up.pt>
Message-ID: <20020423163334.4540.qmail@web13901.mail.yahoo.com>


--- Luis Torgo <ltorgo at liacc.up.pt> wrote:
> I'm trying to obtain a set of regression lines obtained for different values 
> of a factor using lattice. I would like to add a string to each panel showing
> 
> the R^2 value of the respective line, but I'm having difficulties positioning
> 
> the text (namely on which coordinates to give to the "ltext" function).
> Here is what I'm using (I've used ?? for the things I would like you to be so
> 
> kind to help me on how to fill in).
> 
> >  xyplot(O2 ~ Am | Site, data = mydata, scales=list(x='free'),
>  panel=function(x,y,...) {
>   panel.xyplot(x,y,...)
>   panel.lmline(x,y,...)
>   ltext(??, ??, round(summary(lm(y ~ x))$r.squared,3))
>  })
> 
> I would like the R^2 values to appear in the top left corner of each of the 
> panels I get.
> I've tried fixed values for the "x", "y" parameters of "ltext", but as I'm 
> using different X scales for each panel things get messy...


This is where you can use the flexibility of grid. ltext calls grid.text with
the units fixed at the native x and y scales, but you can get all sorts of 
other coordinate systems if you use grid.text directly. For example,

grid.text(round(summary(lm(y ~ x))$r.squared,3), 0.1, 0.9)

should give you approximately what you want. See ?grid.text for details on 
how to customize this further.



> I'm using R 1.4.1 on a Windows 2000 machine.
> 
> Thank you in advance.
> 
> -- 
> Luis Torgo
>     FEP/LIACC, University of Porto   Phone : (+351) 22 607 88 30
>     Machine Learning Group           Fax   : (+351) 22 600 36 54
>     R. Campo Alegre, 823             email : ltorgo at liacc.up.pt
>     4150 PORTO   -  PORTUGAL         WWW   : http://www.liacc.up.pt/~ltorgo
>
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

__________________________________________________

Yahoo! Games - play chess, backgammon, pool and more

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From emoriyama2 at unlnotes.unl.edu  Tue Apr 23 19:01:48 2002
From: emoriyama2 at unlnotes.unl.edu (Etsuko Moriyama)
Date: Tue, 23 Apr 2002 12:01:48 -0500
Subject: [R] Lattice graphics on Mac OS X
In-Reply-To: <Pine.LNX.4.31.0204230803240.4130-100000@gannet.stats>
Message-ID: <CC99E322-56DB-11D6-B676-00039366F548@unlnotes.unl.edu>

Thank you for replying to my post!

The R version is 1.4.0, since this is the latest I found for Darwin 
binary on CRAN.  Carbon version is 1.4.1, but it doesn't do Lattice.  I 
guess I'll try to compile the 1.4.1 source on OS X/Darwin, but I'll wait 
for R1.5.0 as you said.

By the way, the gray window is sometimes solid gray, but other time, it 
has a gray square at the center with surrounding white region.  It may 
depend on the window size.

Thank you,
Etsuko


On Tuesday, April 23, 2002, at 02:12 AM, <ripley at stats.ox.ac.uk> wrote:
>
>> Is there anybody who could use trellis/Lattice graphics on OS X?  I'm
>> using OSX 10.1.4.
>
> More usefully, which version of R, lattice and grid are you using?
> You said it was `gray': because of the bug the current version of 
> lattice
> for R 1.4.1 uses a white background, so I suspect yours is not current.
>
> You may want to wait a week until R 1.5.0 is released. That will ship 
> with
> lattice, and the grid/lattice packages included have been considerably
> improved since 1.4.1.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>

-----------------------------------------------
Etsuko Moriyama, PhD
N107 Beadle Center for Genetics Research
University of Nebraska
Lincoln, NE 68588-0660

Email:  emoriyama2 at unl.edu

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From emoriyama2 at unlnotes.unl.edu  Tue Apr 23 19:11:42 2002
From: emoriyama2 at unlnotes.unl.edu (Etsuko Moriyama)
Date: Tue, 23 Apr 2002 12:11:42 -0500
Subject: [R] R and OS X
In-Reply-To: <3CC52348.8B9F2EFA@mail.nerc-essc.ac.uk>
Message-ID: <2EA09C3E-56DD-11D6-B676-00039366F548@unlnotes.unl.edu>

I had the same problem when I first installed R (Darwin version) on my 
OS X.  Then I installed FINK.  After that only what I had to manually 
install was "libreadline.4.dylib".  I didn't even have to do an symbolic 
link.  You can also install command line mozilla (still version 0.98, 
though) to use for R help from FINK (with symlink to netscape).  Some 
Java script on the first page of help don't work.  But individual help 
page works.  When the new command line mozilla is released I hope those 
java scripts work, too.

Etsuko

On Tuesday, April 23, 2002, at 04:03 AM, owner-r-help at stat.math.ethz.ch 
wrote:

>
>
> Tristan Lorino wrote:
>>
>>>  Dears users,
>>>  I'm trying to run R on a computer with OS X. I installed the R folder
>>>  and the dylibs, where they must be installed. I updated my path, and
>>>  R runs but tells me :
>>>
>>>  dyld: /usr/local/R-1.4.0/lib/R/bin/R.bin version mismatch for
>>>  library: /usr/lib/libz.1.dylib (compatibility version of user: 1.1.3
>>>  greater than library's version: 1.0.0)
>>>
>>>  The only thing I didn't do -- because I don't know how one can do
>>>  this -- is to put /sw/lib first in the
>>>  DYLD_LIBRARY_PATH environmental variable.
>
> Hello Tristan,
>
>
> I think your problem may be a different one. See item 5 of my
> R installation notes below. (I copy the whole lot as other items
> may be of interest also.)
>
> The ReadMe.txt file of the Darwin installation says this:
> "If R asks for a
> version of any of these dylibs which is named slightly differently
> (for instance libz.1.dylib), then just put in a symbolic link in 
> /sw/lib,
> i.e. "ln -s libz.1.1.3.dylib libz.1.dylib"."
>
> This is what I had to do to make R work.
>
> Regards,
> David.
>
>
> 020328
>
> 1. Installed the binary files for R-1.4.0 today (now Thursday).
> 2. tried to run it today, got dyld errors.
> 3. Copied all the .dylibs into /sw/lib, as instructed.
> 4. Got dyld errors again.
> 5. Made symbolic links as instructed.
> 6. Now works, but gives runtime error:
> /usr/local/R-1.4.0/lib/R/bin/pager: no such file or directory: 
> /sw/bin/less
> 7. Fixed this by putting the correct path to "less" in
> /usr/local/R-1.4.0/lib/R/etc/Renviron
> 8. Now get postscript error.
> 9. Restart then OK.
> 10. Forgot to say that I tar'd the /sw/lib directory, and it is (I hope)
> in this here directory now.
>
> 020409
>
> 1. Tried to install the "as.date" etc. functions in the "date" package,
> as follows:
> (a)  Got date_1.2-12.tar.gz on desktop.
> (b)  R CMD INSTALL date
>
> 2. Got errors saying gcc not found - actually need to pick up cc.
> 3. Tracked down the problem to
> 	/usr/local/R-1.4.0/lib/R/etc/Makeconf
> .. so copied this to Makeconf_as_installed and edited original
> to change "gcc" to "cc" in both places.
>
> 4. Got another error, saying couldn't find perl.
> 5. Tracked down the problem to
> 	/usr/local/R-1.4.0/lib/R/etc/Renviron
> .. so copied this to Renviron_as_installed and edited original
> to change "PERL=${PERL-/usr/local/bin/perl}" to 
> "PERL=${PERL-/usr/bin/perl}"
> at its only occurence.
>
> 6. Installation then OK.
>
> 7. Ran R, did "library()" and saw "date" was there. Did "library(date)" 
> and
> accessed the date things OK. Can now do things like:
>
>> mdy.date(10,29,65)
> [1] 29Oct65
>
>> mdy.date(4,9,2002) - mdy.date(10,29,65)
> [1] 13311
>
>> as.integer( mdy.date(10,31,1970) )
> [1] 3956
>
>
>
> --
> David Pearson,              Phone: +44 (0)118  9318741
> ESSC,                       Fax:   +44 (0)118  9316413
> University of Reading,      Email: dwcp at mail.nerc-essc.ac.uk
> Reading RG6 6AL,
> UK.                         www.nerc-essc.ac.uk/~dwcp/Home.html
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> .-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-
> FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> ._._._
>
>

-----------------------------------------------
Etsuko Moriyama
University of Nebraska
Lincoln, NE 68588-0660

Email:  emoriyama2 at unl.edu

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From richmond at saintmarys.edu  Tue Apr 23 19:13:26 2002
From: richmond at saintmarys.edu (David A Richmond)
Date: Tue, 23 Apr 2002 12:13:26 -0500 (EST)
Subject: [R] Lattice graphics on Mac OS X
In-Reply-To: <Pine.LNX.4.31.0204230803240.4130-100000@gannet.stats>
Message-ID: <Pine.GSO.4.43.0204231206210.21363-100000@jade.saintmarys.edu>

On Tue, 23 Apr 2002 ripley at stats.ox.ac.uk wrote:

> On Mon, 22 Apr 2002, Etsuko Moriyama wrote:
>
> How graphics windows work depends on the platform in both R and S-PLUS.
> For R under Unix-alikes (which darwin is) there are no menus on a graphics
> window. (It is an R graphics window, not a Lattice window, BTW.)
> The Windows and Carbin ports of R do have such menus, as does the
> gnome GUI front-end for Unix.  (You might want to explore the latter if it
> is provided on your build.)

I used to use Carbon R since it had a graphics window, but found it to be
much slower for some things than Darwin-R. If you run Darwin R in
X-windows (XFree86) it will display graphics, but I found XFree86 somewhat
cumbersome to use with osX, so now I just run R in a Terminal window, and
use the following to direct output to a pdf file:

pdf(filename,horizontal=TRUE,paper="letter",enc="MacRoman")
# where filename = the full path of the file I want to create

# do the plotting commands here

dev.off(2)

and then view the resulting file using 'Preview'.

dave r.

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|David Richmond                It works on a          |
+ Dept. of Sociology          complex scientific      +
|Saint Mary's College          principle, known as    |
+ Notre Dame, IN 46556               "pot luck."      +
|574-284-4517                    - The Doctor         |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ltorgo at liacc.up.pt  Tue Apr 23 19:39:10 2002
From: ltorgo at liacc.up.pt (Luis Torgo)
Date: Tue, 23 Apr 2002 18:39:10 +0100
Subject: [R] Writing text in lattice graphics
In-Reply-To: <20020423163334.4540.qmail@web13901.mail.yahoo.com>
References: <20020423163334.4540.qmail@web13901.mail.yahoo.com>
Message-ID: <20020423172609.B9E861B96F@mail.liacc.up.pt>

Thank you very much for your help. It worked perfectly.

Without abusing your time I wonder if you could give me a help on another 
problem with lattice graphics.

I have the following box-and-whisker plot:

> bwplot(Season ~ O2 | Site, 
	panel = function(x,y,...) {
		panel.bwplot(x,y,...)
		panel.grid(h=0,v=-1)
	})

I would like to add to each box-and-whisker a dot showing the respective mean 
value (i.e. the mean O2 value for each combination of Season and Site).

I guess it has something to do with the function "grid.points" that will 
allow me to plot a set of points on each panel, but I'm unable to obtain the 
points...

Any help is appreciated.

Thanks.

-- 
Luis Torgo
    FEP/LIACC, University of Porto   Phone : (+351) 22 607 88 30
    Machine Learning Group           Fax   : (+351) 22 600 36 54
    R. Campo Alegre, 823             email : ltorgo at liacc.up.pt
    4150 PORTO   -  PORTUGAL         WWW   : http://www.liacc.up.pt/~ltorgo
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From emoriyama2 at unlnotes.unl.edu  Tue Apr 23 19:26:54 2002
From: emoriyama2 at unlnotes.unl.edu (Etsuko Moriyama)
Date: Tue, 23 Apr 2002 12:26:54 -0500
Subject: [R] Lattice graphics on Mac OS X
In-Reply-To: <Pine.GSO.4.43.0204231206210.21363-100000@jade.saintmarys.edu>
Message-ID: <4E300278-56DF-11D6-B676-00039366F548@unlnotes.unl.edu>

Do any of Lattice function (splom etc.) show the graphics on the graphic 
window on your machine?  It works with non-Lattice graphics like pairs, 
but not with Lattice.

But I will try your suggestion.  Actually I used postscript function to 
download the graphics on a file.  But I tried it only with pairs, but 
not with splom.  I should have thought about it!

I haven't tried pdf, but with postscript, strangely, only plots and 
texts become correctly horizontal, but axes stay in vertical mode.  So I 
have to rotate manually to correct the problem.  Somehow 
"horizontal=FALSE" works correctly for both plots/texts and axes.

Etsuko

On Tuesday, April 23, 2002, at 12:13 PM, David A Richmond wrote:
>
> I used to use Carbon R since it had a graphics window, but found it to 
> be
> much slower for some things than Darwin-R. If you run Darwin R in
> X-windows (XFree86) it will display graphics, but I found XFree86 
> somewhat
> cumbersome to use with osX, so now I just run R in a Terminal window, 
> and
> use the following to direct output to a pdf file:
>
> pdf(filename,horizontal=TRUE,paper="letter",enc="MacRoman")
> # where filename = the full path of the file I want to create
>
> # do the plotting commands here
>
> dev.off(2)
>
> and then view the resulting file using 'Preview'.
>
> dave r.
>
> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
> |David Richmond                It works on a          |
> + Dept. of Sociology          complex scientific      +
> |Saint Mary's College          principle, known as    |
> + Notre Dame, IN 46556               "pot luck."      +
> |574-284-4517                    - The Doctor         |
> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
>
>
>

-----------------------------------------------
Etsuko Moriyama
University of Nebraska
Lincoln, NE 68588-0660

Email:  emoriyama2 at unl.edu

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deepayansarkar at yahoo.com  Tue Apr 23 20:22:06 2002
From: deepayansarkar at yahoo.com (Deepayan Sarkar)
Date: Tue, 23 Apr 2002 11:22:06 -0700 (PDT)
Subject: [R] Writing text in lattice graphics
In-Reply-To: <20020423172609.B9E861B96F@mail.liacc.up.pt>
Message-ID: <20020423182206.66733.qmail@web13905.mail.yahoo.com>


--- Luis Torgo <ltorgo at liacc.up.pt> wrote:
> Thank you very much for your help. It worked perfectly.
> 
> Without abusing your time I wonder if you could give me a help on another 
> problem with lattice graphics.
> 
> I have the following box-and-whisker plot:
> 
> > bwplot(Season ~ O2 | Site, 
>  panel = function(x,y,...) {
>   panel.bwplot(x,y,...)
>   panel.grid(h=0,v=-1)
>  })
> 
> I would like to add to each box-and-whisker a dot showing the respective mean
> 
> value (i.e. the mean O2 value for each combination of Season and Site).

Because of the way arguments are passed to the panel function in bwplot, the
following should do (in this case, grid.points would probably be overkill) : 

bwplot(y ~ x,
       panel = function(x,y,...) {
           panel.bwplot(x,y,...)
           panel.grid(h=0,v=-1)
           foo <- by(x, y, mean)
           lpoints(foo, seq(along=foo), col = 'yellow', pch = 16)
       })




> I guess it has something to do with the function "grid.points" that will 
> allow me to plot a set of points on each panel, but I'm unable to obtain the 
> points...
> 
> Any help is appreciated.
> 
> Thanks.
> 
> -- 
> Luis Torgo
>     FEP/LIACC, University of Porto   Phone : (+351) 22 607 88 30
>     Machine Learning Group           Fax   : (+351) 22 600 36 54
>     R. Campo Alegre, 823             email : ltorgo at liacc.up.pt
>     4150 PORTO   -  PORTUGAL         WWW   : http://www.liacc.up.pt/~ltorgo

__________________________________________________

Yahoo! Games - play chess, backgammon, pool and more

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dmcwilli at utk.edu  Tue Apr 23 20:51:04 2002
From: dmcwilli at utk.edu (dmcwilli)
Date: Tue, 23 Apr 2002 14:51:04 -0400
Subject: [R] Problem passing data into read.table()
Message-ID: <3CC5D1F2@webmail.utk.edu>

Sorry for the delay, only just now got back to it ...

1. debug() did not help, would not show state of nrows inside read.table()
2. fill=T did help, could have dropped the last 2 rows (footer).

By accident I found the problem.  read.table() returns a dataframe and the 
result of the calculation of the number of rows has mode "list".  Coercing it 
to numeric solves the problem.

Working solution:

function(fname) {

# my.func(fname)
#
# Function to read file with header and footer
# Number of rows calculable from header row 8
#

grid.layout <- read.table(fname, as.is=T, header=F, sep="\t", comment.char="", 
skip=7, nrows=1)

# coerce rows calculation to numeric
row.ctr <- 
as.numeric(grid.layout[4]*grid.layout[5]*grid.layout[6]*grid.layout[7])

#read.table now sees row.ctr
tmp.df <- read.table(fname, as.is=T, header=T, sep="\t", comment.char="", 
skip=20, nrows=row.ctr )

# drop empty first column
tmp.df <- tmp.df[, -1 ]

tmp.df

#  end of my.func()
}


Thanks to all who helped.

regards,

>===== Original Message From Jason Turner <jasont at indigoindustrial.co.nz> 
=====
>On Mon, Apr 22, 2002 at 03:21:34PM -0400, David R. McWillliams wrote:
>> I thought about scan(), but I think that would require knowing the number
>> of columns beforehand.
>
>Sounds like you need file(),readLines(), and strsplit(), with
>a home-brewed data frame filler loop.
>
>Something like (untested - just giving the idea here):
>
>con <- file(fname)
>header <- readLines(con, n=21)
>
>#some magic here, to get the max number of columns
>max.cols <- magic stuff
>
>my.data <- readLines(con)
>
>#and let's be hygenic
>close(con)
>
>#chop off the last 2 lines, as they're footer stuff we don't want
>#pushBack would probably work too, but I'm less familiar with it.
>last.two <- ( length(my.data)-1 ):length(my.data)
>my.data <- my.data[-last.two]
>
>#split by tabs
>my.data <- strsplit(my.data,"\t")
>
>my.mat <- matrix(NA,ncol=max.cols,nrow=length(my.data))
>
>for(i in seq(along=my.data)) {
>	for(j in seq(along=my.data[[i]]) {
>		my.mat[i][j] <- as.numeric(my.data[[i]][j])
>	}
>}
>
>
>> As I noted before, if I put in the number of
>> rows in the second call to read.table(), say 'nrows=2000', it correctly
>> detects the number of columns and rows.  I just can't get it to see the
>> calculated value as in 'nrows=row.ctr'.  The intervening print() can fetch
>> the value of row.ctr, so I don't understand why read.table() can't get it.
>
>Not sure.  Have you played with debug() ?  I've found that very, very
>handy for when I lose values - just walk slowly through the function,
>one step at a time, and print out values as you think they might be
>changing.
>
>Cheers
>
>Jason
>--
>Indigo Industrial Controls Ltd.
>64-21-343-545
>jasont at indigoindustrial.co.nz

David McWilliams

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Apr 23 22:04:47 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 23 Apr 2002 22:04:47 +0200
Subject: [R] Problem passing data into read.table()
In-Reply-To: <3CC5D1F2@webmail.utk.edu>
References: <3CC5D1F2@webmail.utk.edu>
Message-ID: <x2ofgatc4g.fsf@blueberry.kubism.ku.dk>

dmcwilli <dmcwilli at utk.edu> writes:

> Sorry for the delay, only just now got back to it ...
> 
> 1. debug() did not help, would not show state of nrows inside read.table()
> 2. fill=T did help, could have dropped the last 2 rows (footer).
> 
> By accident I found the problem.  read.table() returns a dataframe and the 
> result of the calculation of the number of rows has mode "list".  Coercing it 
> to numeric solves the problem.

Oho. Now why didn't I spot that the first time?..

> # coerce rows calculation to numeric
> row.ctr <- 
> as.numeric(grid.layout[4]*grid.layout[5]*grid.layout[6]*grid.layout[7])

However, you're mutiplying data frames there, and there's some amount
of unnecessary bureaucracy it that. Using: 

grid.layout[1,4]*... 

or 

grid.layout[[4]]*...

might be a neater solution. 

Or simply:

row.ctr <-  prod(grid.layout[1,4:7])
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wouter.buytaert at yucom.be  Tue Apr 23 22:08:27 2002
From: wouter.buytaert at yucom.be (wouter.buytaert@yucom.be)
Date: Tue, 23 Apr 2002 22:08:27 +0200 (CEST)
Subject: [R] column-plot of rainfall data
Message-ID: <1019592507.3cc5bf3bc613b@yuclnx4.yucom.be>




Hello,

I have some daily rainfall data from rain gages. E.g.:
date       p1   p2   p3
20/04/2002 10.2 8.6  6.3
21/04/2002 0.4  1.6  1.4
22/04/2002 0.2  0.0  0.4
23/04/2002 5.2  1.0  0.2

I'd like to plot them in a column plot by day, to be able to
compare them. I made an example in exell, that I attached, but
can't find out how to do it in R. The data vector is a POSIXct.

Thanks,

Wouter Buytaert
Institute for Land and Water Management
KULeuven, Belgium

---------------------------------------------------------------
M??r dan gratis internettoegang ... Yucom http://www.yucom.be !
-------------- next part --------------
A non-text attachment was scrubbed...
Name: plot.gif
Type: image/gif
Size: 11009 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20020423/d2ce30cc/plot.gif

From p.dalgaard at biostat.ku.dk  Tue Apr 23 22:28:05 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 23 Apr 2002 22:28:05 +0200
Subject: [R] column-plot of rainfall data
In-Reply-To: <1019592507.3cc5bf3bc613b@yuclnx4.yucom.be>
References: <1019592507.3cc5bf3bc613b@yuclnx4.yucom.be>
Message-ID: <x2k7qytb1m.fsf@blueberry.kubism.ku.dk>

wouter.buytaert at yucom.be writes:

> Hello,
> 
> I have some daily rainfall data from rain gages. E.g.:
> date       p1   p2   p3
> 20/04/2002 10.2 8.6  6.3
> 21/04/2002 0.4  1.6  1.4
> 22/04/2002 0.2  0.0  0.4
> 23/04/2002 5.2  1.0  0.2
> 
> I'd like to plot them in a column plot by day, to be able to
> compare them. I made an example in exell, that I attached, but
> can't find out how to do it in R. The data vector is a POSIXct.

Something like this:

rain <- read.table("rain.txt",header=T)
barplot(t(as.matrix(rain[-1])),
        names.arg=as.character(rain$date),beside=T)


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Tue Apr 23 23:47:17 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 23 Apr 2002 16:47:17 -0500
Subject: [R] Use of nls command
In-Reply-To: <1F8EDF0AE0FFC643BC8FE577BC4919E624ADCE@tomtom-wb.mel.foodscience.afisc.csiro.au>
References: <1F8EDF0AE0FFC643BC8FE577BC4919E624ADCE@tomtom-wb.mel.foodscience.afisc.csiro.au>
Message-ID: <6rvgaijdei.fsf@franz.stat.wisc.edu>

Peter.Watkins at foodscience.afisc.csiro.au writes:

> Hello.
> 
> I am trying to do a non-linear fit using the 'nls' command.
> 
> The data that I'm using is as follows
>     pH     k
> 1 3.79 34.21
> 2 4.14 25.85
> 3 4.38 20.45
> 4 4.57 15.61
> 5 4.74 12.42
> 6 4.92  9.64
> 7 5.11  7.30
> 8 5.35  5.15
> 9 5.67  3.24
> 	
> with a transformation of pH to H <- 10^-pH
> 
> When using the nls command for a set of parameters - a, b and c, I receive
> two sets of errors:
> 
> > ba.nls <- nls( k ~ a/(1+(H/b)) +c*(H/b)/(1+(H/b)), data = obs, start =
> list( a= 1, b = 1, c = 2), trace = TRUE )
> 2579.16 :  1 1 2 
> 1266.912 :   8.041114e+00 -1.811360e+08 -1.809427e+08 
> 1243.136 :  8.237232e+00 2.304521e+15 2.269853e+15 
> Error in nls(k ~ a/(1 + (H/b)) + c * (H/b)/(1 + (H/b)), data = obs, start =
> list(a = 1,  : 
>         step factor 0.000488281 reduced below `minFactor' of 0.000976563
> 
> > ba.nls <- nls( k ~ a/(1+(H/b)) +c*(H/b)/(1+(H/b)), data = obs, start =
> list( a= 5, b = 1, c = 2), trace = TRUE )
> 1724.262 :  5 1 2 
> Error in nls(k ~ a/(1 + (H/b)) + c * (H/b)/(1 + (H/b)), data = obs, start =
> list(a = 5,  : 
>         singular gradient
> 
> I suspect that my initial set of starting values are the problem but I'm
> open for comments.

Two comments:

 - As you indicate, your starting values are poor.  For one thing, the
   value of b has to be on the same order as a typical value of H
   before the expression 1+H/b will be influenced by b.

 - This is a situation where a and c occur linearly in the model.  The
   'plinear' algorithm reduced the optimization from a
   three-dimensional problem to a one-dimensional problem, which is a
   great advantage.

 > obs$H <- 10^-(obs$pH)
 > obs
     pH     k            H
 1 3.79 34.21 1.621810e-04
 2 4.14 25.85 7.244360e-05
 3 4.38 20.45 4.168694e-05
 4 4.57 15.61 2.691535e-05
 5 4.74 12.42 1.819701e-05
 6 4.92  9.64 1.202264e-05
 7 5.11  7.30 7.762471e-06
 8 5.35  5.15 4.466836e-06
 9 5.67  3.24 2.137962e-06
 > ba.nls <- nls(k ~ cbind(1, H/b)/(1+(H/b)), data = obs, start = list(b = 1),
 + algorithm = 'plinear', trace = TRUE)
 108.8751 : 1.000000e+00 7.652868e+00 1.868911e+05 
 Error in nls(k ~ cbind(1, H/b)/(1 + (H/b)), data = obs, start = list(b = 1),  : 
         step factor 0.000488281 reduced below `minFactor' of 0.000976562
 > ba.nls <- nls(k ~ cbind(1, H/b)/(1+(H/b)), data = obs, start = list(b = 1e-5),
 + algorithm = 'plinear', trace = TRUE)
 112.2968 :  0.000010 -7.344264 29.216662 
 27.55333 :  2.471682e-05 -1.713283e+00  3.574606e+01 
 3.158453 : 4.369706e-05 8.857246e-01 4.174971e+01 
 0.4362722 : 5.529106e-05 1.801907e+00 4.487485e+01 
 0.3711344 : 5.763303e-05 1.954527e+00 4.547583e+01 
 0.3709906 : 5.774858e-05 1.961829e+00 4.550526e+01 
 0.3709905 : 5.775135e-05 1.962004e+00 4.550597e+01 
 0.3709905 : 5.775142e-05 1.962008e+00 4.550598e+01 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dpowers at mail.la.utexas.edu  Wed Apr 24 01:05:53 2002
From: dpowers at mail.la.utexas.edu (Daniel A. Powers)
Date: Tue, 23 Apr 2002 18:05:53 -0500
Subject: [R] stacking vectors of unequal length
Message-ID: <3CC5E8D1.54FD9E3A@mail.la.utexas.edu>



R-users --

I would like to make a single vector out of something like the following:

y0 <- rep(0,100)

y1 <- rep(1,20)

and stack them one on top of the other to a vector y with length 120.

Thanks,
Dan
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
Dan Powers
Associate Professor, Sociology
University of Texas at Austin



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cinquett at fclar.unesp.br  Wed Apr 24 01:19:23 2002
From: cinquett at fclar.unesp.br (Carlos Alberto Cinquetti)
Date: Tue, 23 Apr 2002 20:19:23 -0300
Subject: [R] Install
Message-ID: <4.3.2.7.0.20020423201752.00d0f100@pop.fclar.unesp.br>

Dear Sirs,

I am an economist, and I have learned about R from an statician.

I would like to get some instructions on which packages of R should I 
install. I am intending to use R for graphical analysis, correlaction, and 
also estimation - this latter the least, since I have an econometric 
package which performes it very well. I should also mention that I am going 
to work mostly with longitudinal data.

Note: the computer center of my school accepted installing R in our network.

I thank you very much in advance for the attention.

Sincerely,

Prof. Carlos A. Cinquetti
Dep. Economics/State University of Sao Paulo (UNESP), Brazil.


-------------- next part --------------

---
Outgoing mail is certified Virus Free.
Checked by AVG anti-virus system (http://www.grisoft.com).
Version: 6.0.342 / Virus Database: 189 - Release Date: 14/03/2002

From hys11 at student.canterbury.ac.nz  Wed Apr 24 01:19:30 2002
From: hys11 at student.canterbury.ac.nz (Hung So)
Date: Wed, 24 Apr 2002 11:19:30 +1200
Subject: [R] Asking about how to use R to draw Time Series graph
Message-ID: <3CC5EC02.4296542A@student.canterbury.ac.nz>

Hi 
  I'm study at University of Canterbury. Now, We have one project use R
to do time series. The problem is I don't know how to use R to draw time
series graph! Can you help me sovle this problem? I can not find in
manuals book! Can you tearch me what fuction command I have to use?
Thanks alway!
                      Sam
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pkleiber at honlab.nmfs.hawaii.edu  Wed Apr 24 01:20:29 2002
From: pkleiber at honlab.nmfs.hawaii.edu (Pierre Kleiber)
Date: Tue, 23 Apr 2002 13:20:29 -1000
Subject: [R] stacking vectors of unequal length
References: <3CC5E8D1.54FD9E3A@mail.la.utexas.edu>
Message-ID: <3CC5EC3D.2090700@honlab.nmfs.hawaii.edu>

try:

   y <- c(y0,y1)


Daniel A. Powers wrote:
> 
> R-users --
> 
> I would like to make a single vector out of something like the following:
> 
> y0 <- rep(0,100)
> 
> y1 <- rep(1,20)
> 
> and stack them one on top of the other to a vector y with length 120.
> 
> Thanks,
> Dan
> =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
> Dan Powers
> Associate Professor, Sociology
> University of Texas at Austin
> 
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 



-- 
-----------------------------------------------------------------
Pierre Kleiber             Email: pkleiber at honlab.nmfs.hawaii.edu
Fishery Biologist                     Tel: 808 983-5399/737-7544
NOAA FISHERIES - Honolulu Laboratory         Fax: 808 983-2902
2570 Dole St., Honolulu, HI 96822-2396
-----------------------------------------------------------------
  "God could have told Moses about galaxies and mitochondria and
   all.  But behold... It was good enough for government work."
-----------------------------------------------------------------


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Wed Apr 24 01:42:26 2002
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Tue, 23 Apr 2002 19:42:26 -0400
Subject: [R] stacking vectors of unequal length
In-Reply-To: <3CC5E8D1.54FD9E3A@mail.la.utexas.edu>; from dpowers@mail.la.utexas.edu on Tue, Apr 23, 2002 at 06:05:53PM -0500
References: <3CC5E8D1.54FD9E3A@mail.la.utexas.edu>
Message-ID: <20020423194226.A27517@cattell.psych.upenn.edu>

On 04/23/02 18:05, Daniel A. Powers wrote:

>I would like to make a single vector out of something like the following:
>
>y0 <- rep(0,100)
>
>y1 <- rep(1,20)
>
>and stack them one on top of the other to a vector y with length 120.

c(y0,y1)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andrew_perrin at unc.edu  Wed Apr 24 02:07:42 2002
From: andrew_perrin at unc.edu (Andrew Perrin)
Date: Tue, 23 Apr 2002 20:07:42 -0400 (EDT)
Subject: [R] stacking vectors of unequal length
In-Reply-To: <3CC5E8D1.54FD9E3A@mail.la.utexas.edu>
Message-ID: <Pine.LNX.4.21L1.0204232007350.4310-100000@nujoma.perrins>

>  y0<-rep(0,100)
>  y1<-rep(1,20)
> y<-c(y0,y1)
>  y
  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0
 [38] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0
 [75] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1
1 1 1
[112] 1 1 1 1 1 1 1 1 1


----------------------------------------------------------------------
Andrew J Perrin - andrew_perrin at unc.edu - http://www.unc.edu/~aperrin
 Assistant Professor of Sociology, U of North Carolina, Chapel Hill
      269 Hamilton Hall, CB#3210, Chapel Hill, NC 27599-3210 USA


On Tue, 23 Apr 2002, Daniel A. Powers wrote:

> 
> 
> R-users --
> 
> I would like to make a single vector out of something like the following:
> 
> y0 <- rep(0,100)
> 
> y1 <- rep(1,20)
> 
> and stack them one on top of the other to a vector y with length 120.
> 
> Thanks,
> Dan
> =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
> Dan Powers
> Associate Professor, Sociology
> University of Texas at Austin
> 
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From emoriyama2 at unlnotes.unl.edu  Tue Apr 23 15:16:25 2002
From: emoriyama2 at unlnotes.unl.edu (Etsuko Moriyama)
Date: Tue, 23 Apr 2002 08:16:25 -0500
Subject: [R] Lattice graphics on Mac OS X
In-Reply-To: <Pine.LNX.4.31.0204230803240.4130-100000@gannet.stats>
Message-ID: <501E987E-56BC-11D6-B4FF-00039301E590@unlnotes.unl.edu>

Thank you very much for replying to my post!

The R version I have is 1.4.0, since that is the most recent binary for 
MacOS X/Darwin I found on the CRAN site.  Carbon version is 1.4.1, but 
it doesn't have Lattice.  Maybe I'll try to compile the 1.4.1 source on 
Darwin.  But as you said I will wait for the new 1.5.0 for this.

By the way, the window is sometimes solid gray, or other times it has a 
gray square area at the center, surrounded by thick white area.  I guess 
it depends on the size of the window.  But in any case, there is no 
content drawn.

Thank you,
Etsuko

On Tuesday, April 23, 2002, at 02:12 AM, <ripley at stats.ox.ac.uk> wrote:

>
>> Is there anybody who could use trellis/Lattice graphics on OS X?  I'm
>> using OSX 10.1.4.
>
> More usefully, which version of R, lattice and grid are you using?
> You said it was `gray': because of the bug the current version of 
> lattice
> for R 1.4.1 uses a white background, so I suspect yours is not current.
>
> You may want to wait a week until R 1.5.0 is released. That will ship 
> with
> lattice, and the grid/lattice packages included have been considerably
> improved since 1.4.1.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>

------------------------------------------------------------
Etsuko Moriyama
University of Nebraska
Lincoln, NE 68588-0660

Email: emoriyama2 at unl.edu

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mbalcilar at manas.kg  Wed Apr 24 07:22:30 2002
From: mbalcilar at manas.kg (Mehmet Balcilar)
Date: Wed, 24 Apr 2002 11:22:30 +0600
Subject: [R] Re: R-help Digest V2 #710
In-Reply-To: <3CC50B4D.7E09DC5E@lmttrading.com>
References: <200204230201.EAA24556@stat.math.ethz.ch> <3CC50B4D.7E09DC5E@lmttrading.com>
Message-ID: <1019625750.3cc6411630f35@posta.manas.kg>

PP test uses an estimate of the spectral density at frequency 0. For 
nonstationary processes this is an ill-posed estimation problem. This is 
another issue with the PP test. As far as I know, the ADF test does not have 
this problem.

Best wishes,

Mehmet


Quoting Adrian Trapletti <adrian.trapletti at lmttrading.com>:

> > Date: Mon, 22 Apr 2002 07:21:41 +0000
> > From: "sonchawan tamkaew" <psu17772 at hotmail.com>
> > Subject: [R] PP.test
> >
> > Hello there,
> >
> > I would like to know whether PP.test from library(ts) is appropriate to
> test
> > unit root in financial data (daily)?
> >
> > Thank you for your help.
> >
> > Sonchawan
> >
> 
> In principle yes. However, it is by now a well know fact that the PP test has
> severe size distortions for certain processes (e.g. integrated MA(1)). A more
> robust alternative in some situations is the Augmented-Dickey-Fuller test
> which is provided by tseries (see adf.test).
> 
> best
> Adrian
> 
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> 
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From P.Connolly at hortresearch.co.nz  Wed Apr 24 09:20:57 2002
From: P.Connolly at hortresearch.co.nz (Patrick Connolly)
Date: Wed, 24 Apr 2002 19:20:57 +1200 (NZST)
Subject: [R] Changing the colour in boxplots using bwplot()
Message-ID: <200204240720.g3O7Kvm23465@biomat1.marc.hort.cri.nz>

I've managed to find how to change 

trellis.settings$box.rectangle$col
and
trellis.settings$box.umbrella$col

but I can't figure out how to change the colour of the point used
to indicate outliers.  There doesn't seem to be a general colour.

What am I overlooking?

best

-- 
*************************************************************
   ___      Patrick Connolly
 {~._.~}    HortResearch             Great minds discuss ideas;
 _( Y )_    Mt Albert                Average minds discuss events; 
(:_~*~_:)   Auckland                 Small minds discuss people.
 (_)-(_)    New Zealand                                    .... Anon
            Ph: +64-9 815 4200 x 7188
*************************************************************


______________________________________________________
The contents of this e-mail are privileged and/or confidential to the
named recipient and are not to be used by any other person and/or
organisation. If you have received this e-mail in error, please notify 
the sender and delete all material pertaining to this e-mail.
______________________________________________________
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From P.Connolly at hortresearch.co.nz  Wed Apr 24 09:48:56 2002
From: P.Connolly at hortresearch.co.nz (Patrick Connolly)
Date: Wed, 24 Apr 2002 19:48:56 +1200 (NZST)
Subject: [R] Re: Changing the colour in boxplots using bwplot()
Message-ID: <200204240748.g3O7muF23481@biomat1.marc.hort.cri.nz>

Please disregard my previous question on this -- unless you wish to
know the answer.

trellis.settings$dot.symbol$col

is where this colour comes from.

best


 --
*************************************************************
   ___      Patrick Connolly
 {~._.~}    HortResearch             Great minds discuss ideas;
 _( Y )_    Mt Albert                Average minds discuss events; 
(:_~*~_:)   Auckland                 Small minds discuss people.
 (_)-(_)    New Zealand                                    .... Anon
            Ph: +64-9 815 4200 x 7188
*************************************************************


______________________________________________________
The contents of this e-mail are privileged and/or confidential to the
named recipient and are not to be used by any other person and/or
organisation. If you have received this e-mail in error, please notify 
the sender and delete all material pertaining to this e-mail.
______________________________________________________
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deepayansarkar at yahoo.com  Wed Apr 24 08:24:08 2002
From: deepayansarkar at yahoo.com (Deepayan Sarkar)
Date: Tue, 23 Apr 2002 23:24:08 -0700 (PDT)
Subject: [R] Changing the colour in boxplots using bwplot()
In-Reply-To: <200204240720.g3O7Kvm23465@biomat1.marc.hort.cri.nz>
Message-ID: <20020424062408.34933.qmail@web13904.mail.yahoo.com>


Changing trellis.settings$plot.symbol$col should work. This will unfortunately
change the default color for xyplot etc as well.

Incidentally, (although I'm not sure how you are doing it,) accessing
trellis.settings directly is not recommended, and will in fact fail in
subsequent versions of lattice. Instead use trellis.par.set (or lset once the
next version is out).


--- Patrick Connolly <P.Connolly at hortresearch.co.nz> wrote:
> I've managed to find how to change 
> 
> trellis.settings$box.rectangle$col
> and
> trellis.settings$box.umbrella$col
> 
> but I can't figure out how to change the colour of the point used
> to indicate outliers.  There doesn't seem to be a general colour.
> 
> What am I overlooking?
> 
> best




__________________________________________________

Yahoo! Games - play chess, backgammon, pool and more

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Wed Apr 24 08:39:09 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 24 Apr 2002 08:39:09 +0200
Subject: [R] Asking about how to use R to draw Time Series graph
References: <3CC5EC02.4296542A@student.canterbury.ac.nz>
Message-ID: <3CC6530D.B2F29036@statistik.uni-dortmund.de>

Hung So wrote:
> 
> Hi
>   I'm study at University of Canterbury. Now, We have one project use R
> to do time series. The problem is I don't know how to use R to draw time
> series graph! Can you help me sovle this problem? I can not find in
> manuals book! Can you tearch me what fuction command I have to use?
> Thanks alway!

Well, it's in "An Introduction to R", section 12.1.1.
Also searching for "time series" in the search engine you'll get using
help.start() might help.

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jbarnier at lille-metropole-2015.org  Wed Apr 24 09:49:06 2002
From: jbarnier at lille-metropole-2015.org (Julien Barnier)
Date: Wed, 24 Apr 2002 09:49:06 +0200
Subject: [R] Dummy newbie question
Message-ID: <3CC67F92.21381.368916@localhost>

Hi,

Excuse me for a so dummy question, but I really can't manage to do this 
very simple thing : I have a data frame, and I would like to calculate 
two vectors which contain the sums respectively of the rows and of the 
columns of the matrix.

There is surely a very simple way to do that, but I didn't find it...

Many thanks in advance.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Apr 24 10:07:30 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 24 Apr 2002 09:07:30 +0100 (BST)
Subject: [R] Dummy newbie question
In-Reply-To: <3CC67F92.21381.368916@localhost>
Message-ID: <Pine.LNX.4.31.0204240903290.22557-100000@gannet.stats>

On Wed, 24 Apr 2002, Julien Barnier wrote:

> Excuse me for a so dummy question, but I really can't manage to do this
> very simple thing : I have a data frame, and I would like to calculate
> two vectors which contain the sums respectively of the rows and of the
> columns of the matrix.

A data frame or a matrix?  You can only do this for data frames all of
whose columns are numeric, or for numeric matrices.  Suppose A is either
sort of object:

apply(A, 1, sum)  # row sums
apply(A, 2, sum)  # columns sums

As from next week's R 1.5.0 you will be able to use rowSums(A) and
colSums(A).

> There is surely a very simple way to do that, but I didn't find it...

Not `very simple' until next week.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Wed Apr 24 10:07:07 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 24 Apr 2002 10:07:07 +0200
Subject: [R] Dummy newbie question
References: <3CC67F92.21381.368916@localhost>
Message-ID: <3CC667AB.D1ECB067@statistik.uni-dortmund.de>



Julien Barnier wrote:
> 
> Hi,
> 
> Excuse me for a so dummy question, but I really can't manage to do this
> very simple thing : I have a data frame, and I would like to calculate
> two vectors which contain the sums respectively of the rows and of the
> columns of the matrix.
> 
> There is surely a very simple way to do that, but I didn't find it...

In  R <= 1.4.1:
 apply(x, 1, sum)
 apply(x, 2, sum)

In  R >= 1.5.0 (in development):
 colSums(x)
 rowSums(x)

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From idh at poulet.org  Wed Apr 24 10:11:18 2002
From: idh at poulet.org (Yannick Wurm)
Date: Wed, 24 Apr 2002 10:11:18 +0200
Subject: [R] Multiple frequencies
Message-ID: <DB357444-575A-11D6-A1A9-0003934A808C@poulet.org>

Hi!
	I'm having a small problem with an assignment I have to do.
	We want to do an anova on some values, given for four 
different types of medicine. The different sample numbers are 
not identical (eg for molecule A we have 8 values, for B we have 
14, etc.).
	What would the most elegant way of getting this info into R 
to do an lm be? I usually try to use data.frames but R 
categorically refuses to combine the values (i scan()'d them 
into four vectors) because their row numbers aren't identical. 
(even if I do check.rows = FALSE).

Thanks for your help,

Yannick

------------------------------------
      yannick.wurm at insa-lyon.fr
http://homepage.mac.com/yannickwurm/
tel: 06.16.41.71.92    icq: 22044361

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From macleod_lee at tynesys.com  Wed Apr 24 10:26:25 2002
From: macleod_lee at tynesys.com (Macleod Lee)
Date: Wed, 24 Apr 2002 16:26:25 +0800
Subject: [R] Which platform the R-JAVA support ??
Message-ID: <KAEOJIKANNDONGNIOFFDIEJNCAAA.macleod_lee@tynesys.com>

Hi all,

>From R-Java web site ,  the R-Java have used on Linux (2.2.14) and Solaris (SunOS 5.6 and 5.7). 
Anyone know how many platforms that R-Java support  :
ex : Solaris 5.8  or  IBM AIX  or  HP-UX or Alpha-DEC-OSF 

Thanks,
Macleod Lee
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From arv at ono.com  Wed Apr 24 10:33:33 2002
From: arv at ono.com (arv@ono.com)
Date: Wed, 24 Apr 2002 10:33:33 +0200
Subject: [R] Install
Message-ID: <13830a1334ed.1334ed13830a@ono.com>

Hi Carlos,

You should look at 'ts' 'tseries' and 'dse' packages. Don't forget to
take a look on the basic R manuals. 

Cheers,

Antonio Rodr?guez
CICEM Agua del Pino
Huelva, Spain


> Dear Sirs,
> 
> I am an economist, and I have learned about R from an statician.
> 
> I would like to get some instructions on which packages of R should 
> I 
> install. I am intending to use R for graphical analysis, 
> correlaction, and 
> also estimation - this latter the least, since I have an 
> econometric 
> package which performes it very well. I should also mention that I 
> am going 

-------------- next part --------------

---
Outgoing mail is certified Virus Free.
Checked by AVG anti-virus system (http://www.grisoft.com).
Version: 6.0.342 / Virus Database: 189 - Release Date: 14/03/2002

From zedshaw at zedshaw.com  Wed Apr 24 12:52:20 2002
From: zedshaw at zedshaw.com (Zed Shaw)
Date: 24 Apr 2002 03:52:20 -0700
Subject: [R] Everything You Need for JEdit/R Edit Mode
Message-ID: <1019645540.3223.19.camel@workhorse.killnine.net>

After a couple of e-mails asking how to get this to work, I decided that
I would send out a quick message with the stuff you need and
instructions on how to use it.

I've attached the two files you need to get the R syntax coloring and
indenting to work with JEdit.  They are just XML files.

Here's what you do:

1)  Copy these two files to your .jedit/modes directory.  Depending on
what you are running jedit on, this modes directory may be in a
different place.  There are two basic modes directories:  the jedit one
and yours.  The jedit one has lots of XML files already in it.  DO NOT
PUT MY FILES IN THIS DIRECTORY!!!!!  You will be sorry.  The modes
directory you want is probably in your home directory, in the .jedit
directory, and should have nothing in it.

2)  Once these files are in there, you'll have to resolve a conflict
between R file endings and REBOL file endings (both *.r in
case-insensitive land).  To do this, go to Utilities->Global
Options->Mode-Specific.  Select "REBOL" from the pulldown at the top
(look right).  Uncheck the, "Use default settings" check box.  Change
the "File name glob" to be *.rebol.  (NOTE:  If, in the rare event that
you actually do both REBOL and R, then you'll have to figure out how to
resolve this another way).  Click OK to save the changes.

3)  Restart JEdit and try an R file.  Everything should be fine.  If it
still doesn't work, but words like "to do" are bold, then you didn't
resolve the problem with REBOL files.  Try step 2 again.


Most of this was taken from the JEdit help feature, under "Writing Edit
Modes".  Take a look at it and see if you can improve on what I have.
Most of what you see is straight out of the R grammar specs, but I'm not
sure what functions in R should be considered keywords.  For example,
would you consider "plot" a keyword, or a function.

Anyway, enjoy.  And feel free to contact me if you still have problems.


-------------- next part --------------
<?xml version="1.0"?>
<!DOCTYPE MODES SYSTEM "catalog.dtd">

<MODES>

<!-- Add lines like the following, one for each edit mode you add: -->
<!-- <MODE NAME="foo" FILE="foo.xml" FILE_NAME_GLOB="*.foo" /> -->
		<MODE NAME="RS" FILE="RS.xml" FILE_NAME_GLOB="*.R" FIRST_LINE_GLOB="" />
</MODES>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: RS.xml
Type: text/xml
Size: 2270 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20020424/fd232401/RS.xml

From scs10 at st-andrews.ac.uk  Wed Apr 24 11:41:39 2002
From: scs10 at st-andrews.ac.uk (Sophie Smout)
Date: Wed, 24 Apr 2002 10:41:39 +0100
Subject: [R] nonlinear least squares, multiresponse
Message-ID: <3.0.1.32.20020424104139.00e148e0@gatty.st-and.ac.uk>

I'm trying to fit a model to solve a biological problem.

There are multiple independent variables, and also there are multiple
responses. 

Each response is a function of all the independent variables, plus a set of
parameters. All the responses depend on the same variables and parameters -
just the form of the function changes to define each seperate response. 

Any ideas how I can fit parameters to my data?
nls, as I understand it, will work for multiple independent variables, but
not multiple responses. 

All help gratefully recieved!

Sophie



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From YERUPAJA01 at terra.es  Wed Apr 24 12:21:52 2002
From: YERUPAJA01 at terra.es (YERUPAJA01)
Date: Wed, 24 Apr 2002 12:21:52 +0200
Subject: [R] Asking about how to use R to draw Time Series graph
Message-ID: <16e1c16bf3.16bf316e1c@teleline.es>

Hi,

Firts you need to set your data as ts series. Look at ?ts (first load 
library(ts)). For example:

>library(ts)
>rain.ts<-as.ts(rain)
>plot(rain.ts)

This is maybe the simplest form. You should look at ?ts in order to 
make more refinements in you plots

Cheers,

Antonio Rodr?guez
CICEM Agua del Pino
Huelva, Spain

----- Mensaje Original -----
De: Uwe Ligges <ligges at statistik.uni-dortmund.de>
Fecha: Miercoles, Abril 24, 2002 8:39 am
Asunto: Re: [R] Asking about how to use R to draw Time Series graph

> Hung So wrote:
> > 
> > Hi
> >   I'm study at University of Canterbury. Now, We have one 
> project use R
> > to do time series. The problem is I don't know how to use R to 
> draw time
> > series graph! Can you help me sovle this problem? I can not find in
> > manuals book! Can you tearch me what fuction command I have to use?
> > Thanks alway!
> 
> Well, it's in "An Introduction to R", section 12.1.1.
> Also searching for "time series" in the search engine you'll get using
> help.start() might help.
> 
> Uwe Ligges
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> .-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-
> FAQ.htmlSend "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-
> 
request at stat.math.ethz.ch_._._._._._._._._._._._._._._._._._._._._._._._
._._._._._._._._._._._._._._._._
> 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Wed Apr 24 12:29:32 2002
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 24 Apr 2002 06:29:32 -0400
Subject: [R] Dummy newbie question
In-Reply-To: <3CC67F92.21381.368916@localhost>
Message-ID: <5.1.0.14.2.20020424062441.01d59a28@pop>

Dear Julien,

Assuming that the data frame contains only numeric data, you can use apply: 
apply(data, 1, sum) will give you the row sums, and apply(data, 2, sum) the 
column sums.

John


At 09:49 AM 4/24/2002 +0200, Julien Barnier wrote:

>Excuse me for a so dummy question, but I really can't manage to do this
>very simple thing : I have a data frame, and I would like to calculate
>two vectors which contain the sums respectively of the rows and of the
>columns of the matrix.

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From siim at obs.ee  Wed Apr 24 13:36:38 2002
From: siim at obs.ee (Ott Toomet)
Date: Wed, 24 Apr 2002 13:36:38 +0200 (CEST)
Subject: [R] Install
In-Reply-To: <4.3.2.7.0.20020423201752.00d0f100@pop.fclar.unesp.br>
Message-ID: <Pine.LNX.4.44.0204241330010.12024-100000@localhost.localdomain>

Hi,

I think you should install the bundle of recommanded packages, which
includes e.g. MASS (functions from Venables & Ripley book), modreg (various
non-parametric methods), survival (which is not well suited for
econometrics).  Foreign allows data conversation between various formats
(like SPSS and stata), I think it is included in recommended).  If you are
working with latex, xtable may be of interest.

I think these are the packages which I am using, but I am rather a
microeconometrics guy.

Cheers,

Ott Toomet



On Tue, 23 Apr 2002, Carlos Alberto Cinquetti wrote:

  |Dear Sirs,
  |
  |I am an economist, and I have learned about R from an statician.
  |
  |I would like to get some instructions on which packages of R should I 
  |install. I am intending to use R for graphical analysis, correlaction, and 
  |also estimation - this latter the least, since I have an econometric 
  |package which performes it very well. I should also mention that I am going 
  |to work mostly with longitudinal data.
  |
  |Note: the computer center of my school accepted installing R in our network.
  |
  |I thank you very much in advance for the attention.
  |
  |Sincerely,
  |
  |Prof. Carlos A. Cinquetti
  |Dep. Economics/State University of Sao Paulo (UNESP), Brazil.
  |
  |
  |

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From laurent at genome.cbs.dtu.dk  Wed Apr 24 12:39:59 2002
From: laurent at genome.cbs.dtu.dk (Laurent Gautier)
Date: Wed, 24 Apr 2002 12:39:59 +0200
Subject: [R] Multiple frequencies
In-Reply-To: <DB357444-575A-11D6-A1A9-0003934A808C@poulet.org>
References: <DB357444-575A-11D6-A1A9-0003934A808C@poulet.org>
Message-ID: <20020424103959.GD26323@giraffa.cbs.dtu.dk>

On Wed, Apr 24, 2002 at 10:11:18AM +0200, Yannick Wurm wrote:
> Hi!
> 	I'm having a small problem with an assignment I have to do.
> 	We want to do an anova on some values, given for four 
> different types of medicine. The different sample numbers are 
> not identical (eg for molecule A we have 8 values, for B we have 
> 14, etc.).
> 	What would the most elegant way of getting this info into R 
> to do an lm be? I usually try to use data.frames but R 
> categorically refuses to combine the values (i scan()'d them 
> into four vectors) because their row numbers aren't identical. 
> (even if I do check.rows = FALSE).
> 
> Thanks for your help,
> 
> Yannick
> 
> ------------------------------------
>      yannick.wurm at insa-lyon.fr
> http://homepage.mac.com/yannickwurm/
> tel: 06.16.41.71.92    icq: 22044361
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._




It looks like a job for 'factor'...

The following R command should help you to figure out how...


help(factor)
data(InsectSprays)
help(InsectSprays)




Hopin' it helps,




Laurent





--------------------------------------------------------------
Laurent Gautier			CBS, Building 208, DTU
PhD. Student			D-2800 Lyngby,Denmark	
tel: +45 45 25 24 85		http://www.cbs.dtu.dk/laurent
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Wed Apr 24 14:17:06 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 24 Apr 2002 08:17:06 -0400
Subject: [R] error loading huge .RData
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC246@usrymx10.merck.com>

Patrick,

I appreciate your comments, and practice everything that you preach.
However, that workspace image contains only 2~3 R objects: the input and
output of a single R command.  I knew there could be problems, so I've
stripped it down to the bare minimum.  Yes, I also kept the commands in a
script.  That single command (in case you want to know: a random forest run
with 4000 rows and nearly 7000 variables) took over 3 days to run.  There's
not a whole lot I can do here when the data is so large.

Andy

> -----Original Message-----
> From: Patrick Connolly [mailto:P.Connolly at hortresearch.co.nz]
> Sent: Tuesday, April 23, 2002 7:18 PM
> To: andy_liaw at merck.com
> Subject: Re: [R] error loading huge .RData
> 
> 
> According to Liaw, Andy:
> |> 
> |> Dear R-help,
> |> 
> |> I've run into a problem loading .RData:  I was running a 
> large computation,
> |> which supposedly produce a large R object.  At the end of 
> the session, I did
> |> a save.image() and then quit.  The .RData has size 
> 613,249,399 bytes.  Now I
> |> can't get R to load this .RData file.  Whenever I tried, I 
> get "Error:
> |> vector memory exhausted (limit reached)".  I tried adding
> |> "--min-vsize=1000M", but that didn't help.  I also tried R 
>  --vanilla and
> |> then attach(".RData"), same error.
> |> 
> |> From what I can see, the file is not corrupted.  How can I 
> get R to load it?
> 
> What would you look for to see if it's corrupted?  That's a big file
> to find it in.
> 
> I've never used a .RData file greater than 100 Mb, so my experience is
> not directly comparable, but I feel uneasy having too much in one
> file.  It's a safer practice to make sure you keep a file of the
> commands you used to create your R objects so that it's easy (even if
> not quick) to reproduce them.  It's also good to keep not too many
> objects in one Data file.  I had only one occasion when I had a
> corrupt .RData file, but it was easy to recover.  The bigger the file,
> the more opportunity for corruption to happen.  How many objects would
> there have been in your .RData file?
> 
> 
> 
> Might not be much help for now, but it might help in the future.
> 
> 
> best
> 
> -- 
> *************************************************************
>    ___      Patrick Connolly
>  {~._.~}    HortResearch             Great minds discuss ideas;
>  _( Y )_    Mt Albert                Average minds discuss events; 
> (:_~*~_:)   Auckland                 Small minds discuss people.
>  (_)-(_)    New Zealand                                    .... Anon
>             Ph: +64-9 815 4200 x 7188
> *************************************************************
> 
> 
> ______________________________________________________
> The contents of this e-mail are privileged and/or confidential to the
> named recipient and are not to be used by any other person and/or
> organisation. If you have received this e-mail in error, 
> please notify 
> the sender and delete all material pertaining to this e-mail.
> ______________________________________________________
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named in this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Apr 24 14:39:15 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 24 Apr 2002 14:39:15 +0200
Subject: [R] error loading huge .RData
In-Reply-To: <51F9C42DA15CD311BD220008C707D81906FFC246@usrymx10.merck.com>
References: <51F9C42DA15CD311BD220008C707D81906FFC246@usrymx10.merck.com>
Message-ID: <x24ri1xocs.fsf@blueberry.kubism.ku.dk>

"Liaw, Andy" <andy_liaw at merck.com> writes:

> Patrick,
> 
> I appreciate your comments, and practice everything that you preach.
> However, that workspace image contains only 2~3 R objects: the input and
> output of a single R command.  I knew there could be problems, so I've
> stripped it down to the bare minimum.  Yes, I also kept the commands in a
> script.  That single command (in case you want to know: a random forest run
> with 4000 rows and nearly 7000 variables) took over 3 days to run.  There's
> not a whole lot I can do here when the data is so large.

Hmm. You could be running into some sort of situation where data
temporarily take up more space in memory than they need to. It does
sound like a bit of a bug if R can write images that are bigger than
it can read. Not sure how to proceed though. Does anyone on R-core
have a similarly big  system and a spare gigabyte of disk? Is it
possible to create a mock-up of similarly organized data that displays
the same effect, but takes less than three days?

        -p

 BTW: Did we ever hear what system this is happening on?
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Wed Apr 24 14:53:10 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 24 Apr 2002 08:53:10 -0400
Subject: [R] error loading huge .RData
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC248@usrymx10.merck.com>

> Hmm. You could be running into some sort of situation where data
> temporarily take up more space in memory than they need to. It does
> sound like a bit of a bug if R can write images that are bigger than
> it can read. Not sure how to proceed though. Does anyone on R-core
> have a similarly big  system and a spare gigabyte of disk? Is it
> possible to create a mock-up of similarly organized data that displays
> the same effect, but takes less than three days?
> 
>  BTW: Did we ever hear what system this is happening on?

Yes, in the original post:
R-1.4.1/Mandrake Linux 7.1 (kernel 2.4.3)
Dual P3-866 Xeon with 2GB RAM and 2GB swap.

Prof. Tierney has been trying to help me off-list.  I monitored the R.bin
process through ktop as Prof. Tierney suggested.  The strange thing is
that the memory usage for the R.bin process would reach nearly 1000MB
and then R just quits with the vector heap exhausted error.

I ran gdb on R, also as Prof. Tierney suggested, and he said that 
malloc was not able to get more memory.  I check ulimit and it says
"unlimited".  Prof. Tierney also suggested running strace, but I haven't
gotten arround to that.

Will keep you folks posted...

Regards,
Andy

------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message. If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From JWu at nctr.fda.gov  Wed Apr 24 15:39:16 2002
From: JWu at nctr.fda.gov (Wu, Jie)
Date: Wed, 24 Apr 2002 08:39:16 -0500
Subject: [R] can not compile R-1.4.1 on OSF5.1
Message-ID: <E4A6EB22F04AD411819000805F6FE968475F1B@exchange01.nctr.fda.gov>

I could not compile R-1.4.1 successfully. The error I got is:
	.......
	Building package 'ctest'
	mkdir ../../../library/ctest
	mkdir ../../../library/ctest/R
	mkdir ../../../library/ctest/man
	Make: Cannot open ../../../../share/make/../../../../etc/Makeconf.
Stop

What can I do to fix the problem? Thank you.

Jie
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From luke at stat.umn.edu  Wed Apr 24 15:59:01 2002
From: luke at stat.umn.edu (Luke Tierney)
Date: Wed, 24 Apr 2002 08:59:01 -0500
Subject: [R] error loading huge .RData
In-Reply-To: <x24ri1xocs.fsf@blueberry.kubism.ku.dk>; from p.dalgaard@biostat.ku.dk on Wed, Apr 24, 2002 at 02:39:15PM +0200
References: <51F9C42DA15CD311BD220008C707D81906FFC246@usrymx10.merck.com> <x24ri1xocs.fsf@blueberry.kubism.ku.dk>
Message-ID: <20020424085901.A4662@nokomis.stat.umn.edu>

On Wed, Apr 24, 2002 at 02:39:15PM +0200, Peter Dalgaard BSA wrote:
> "Liaw, Andy" <andy_liaw at merck.com> writes:
> 
> > Patrick,
> > 
> > I appreciate your comments, and practice everything that you preach.
> > However, that workspace image contains only 2~3 R objects: the input and
> > output of a single R command.  I knew there could be problems, so I've
> > stripped it down to the bare minimum.  Yes, I also kept the commands in a
> > script.  That single command (in case you want to know: a random forest run
> > with 4000 rows and nearly 7000 variables) took over 3 days to run.  There's
> > not a whole lot I can do here when the data is so large.
> 
> Hmm. You could be running into some sort of situation where data
> temporarily take up more space in memory than they need to. It does
> sound like a bit of a bug if R can write images that are bigger than
> it can read. Not sure how to proceed though. Does anyone on R-core
> have a similarly big  system and a spare gigabyte of disk? Is it
> possible to create a mock-up of similarly organized data that displays
> the same effect, but takes less than three days?

I guess we could make sure the write fails as well :-)

Actually that isn't entirely flippant. The serialization mechanism
only preserves sharing that is semantically meaningful (symbols,
environments, external references and weak references).  This has been
so since the first change in the save format in R 0.something.  As a
result, saving and loading a value may result in using more memory for
the restored version.  It would be possible to preserve all sharing
within a single save operation, but that would require keeping track
of all objects as they are written, which requires more memory, and
hence could make the write fail.

It is fairly hard to create values with shared data structure at the R
level (easy in C though) so it hasn't been much of an issue.  One
place where we might be getting bitten though is in the way names are
attached to things; those are often shared when objects are created
but will be duplicated by our save/load strategy. Whether that is an
issue here is hard to tell.

luke

-- 
Luke Tierney
University of Minnesota                      Phone:           612-625-7843
School of Statistics                         Fax:             612-624-8868
313 Ford Hall, 224 Church St. S.E.           email:      luke at stat.umn.edu
Minneapolis, MN 55455 USA                    WWW:  http://www.stat.umn.edu
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From friendly at yorku.ca  Wed Apr 24 16:29:30 2002
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 24 Apr 2002 10:29:30 -0400
Subject: [R] pooling categories in a contingency table
Message-ID: <3CC6C14A.5141B936@yorku.ca>

John Fox helped show me how to collapse the categories, pooling
frequencies, in an n-way table, using levels()<- on an equivalent
data frame:

    # create a table
     sex <- c("Male", "Female")
     age <- letters[1:6]
     education <- c("low", 'med', 'high')
     data <- expand.grid(sex=sex, age=age, education=education)

     counts <- rpois(36, 100) 
     data <- cbind(data, counts)
     t1 <- xtabs(counts ~ sex + age + education, data=data)

    # collapse age to 3 levels
     levels(data$age) <- c("A", "A", "B", "B", "C", "C")
     t2 <- xtabs(counts ~ sex + age + education, data=data)
     mosaicplot(t2,shade=T)

I'd like to generalize this to a function, collapse.table.  Here's what
I tried:

collapse.table <- function(table, ...) {
    nargs <- length(args <- list(...))
    if (!nargs) 
        return(table)
    if (inherits(table, "table")) {
        table <- as.data.frame.table(table)
        freq <- table[,"Freq"]
        tvars <- dimnames(table)
        }
    names <- names(args)
    print(cat("names: ", names, "\n"))
    for (i in 1:nargs) {
        vals <- args[[i]]
        nm <- names[[i]]
        print(cat("vals: ", vals, "\n"))
        print(cat("nm: ", nm, "\n"))
        levels(table$nm) <- vals
        }
    terms <- paste(tvars, sep = '+')
    result <- xtabs(freq ~ terms, data=table)
}

>From the output below, I see what the problem is, but don't know
how to fix it:

> collapse.table(t1, age=c("A", "A", "B", "B", "C", "C"))
names:  age 
NULL
vals:  A A B B C C 
NULL
nm:  age 
NULL
Error in "levels<-.default"(*tmp*, value = c("A", "A", "B", "B", "C",  : 
        attempt to set an attribute on NULL
> traceback()
3: "levels<-.default"(*tmp*, value = c("A", "A", "B", "B", "C", 
   "C"))
2: "levels<-"(*tmp*, value = c("A", "A", "B", "B", "C", "C"))
1: collapse.table(t1, age = c("A", "A", "B", "B", "C", "C"))

Can someone help?

-Michael

-- 
Michael Friendly              friendly at yorku.ca
York University               http://www.math.yorku.ca/SCS/friendly.html
Psychology Department
4700 Keele Street             Tel:  (416) 736-5115 x66249
Toronto, Ontario, M3J 1P3     Fax:  (416) 736-5814
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Wed Apr 24 17:57:55 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 24 Apr 2002 17:57:55 +0200
Subject: [R] pooling categories in a contingency table
In-Reply-To: <3CC6C14A.5141B936@yorku.ca>
References: <3CC6C14A.5141B936@yorku.ca>
Message-ID: <x2lmbd84xo.fsf@blueberry.kubism.ku.dk>

Michael Friendly <friendly at yorku.ca> writes:

....
>     for (i in 1:nargs) {
>         vals <- args[[i]]
>         nm <- names[[i]]
>         print(cat("vals: ", vals, "\n"))
>         print(cat("nm: ", nm, "\n"))
>         levels(table$nm) <- vals
>         }
....

> From the output below, I see what the problem is, but don't know
> how to fix it:
...
> Can someone help?

table$nm looks for a component called "nm". I think you want 
table[[nm]].

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rgentlem at jimmy.harvard.edu  Wed Apr 24 18:15:41 2002
From: rgentlem at jimmy.harvard.edu (Robert Gentleman)
Date: Wed, 24 Apr 2002 12:15:41 -0400
Subject: [R] pooling categories in a contingency table
In-Reply-To: <x2lmbd84xo.fsf@blueberry.kubism.ku.dk>; from p.dalgaard@biostat.ku.dk on Wed, Apr 24, 2002 at 05:57:55PM +0200
References: <3CC6C14A.5141B936@yorku.ca> <x2lmbd84xo.fsf@blueberry.kubism.ku.dk>
Message-ID: <20020424121541.K11850@jimmy.harvard.edu>

On Wed, Apr 24, 2002 at 05:57:55PM +0200, Peter Dalgaard BSA wrote:
> Michael Friendly <friendly at yorku.ca> writes:
> 
> ....
> >     for (i in 1:nargs) {
> >         vals <- args[[i]]
> >         nm <- names[[i]]
> >         print(cat("vals: ", vals, "\n"))
> >         print(cat("nm: ", nm, "\n"))
> >         levels(table$nm) <- vals

 The "problem" is that $ does not evaluate its second argument (which
 is unlike all other operators in S) so as Peter says you can use
 table[[nm]] since the "[[" operator does evaluate its argument.


> >         }
> ....
> 
> > From the output below, I see what the problem is, but don't know
> > how to fix it:
> ...
> > Can someone help?
> 
> table$nm looks for a component called "nm". I think you want 
> table[[nm]].
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
+---------------------------------------------------------------------------+
| Robert Gentleman                 phone : (617) 632-5250                   |
| Associate Professor              fax:   (617)  632-2444                   |
| Department of Biostatistics      office: M1B28
| Harvard School of Public Health  email: rgentlem at jimmy.dfci.harvard.edu   |
+---------------------------------------------------------------------------+
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Han-Lin.Lai at noaa.gov  Wed Apr 24 19:16:47 2002
From: Han-Lin.Lai at noaa.gov (Han-Lin Lai)
Date: Wed, 24 Apr 2002 10:16:47 -0700
Subject: [R] degrees of freedom for t-tests in lme
Message-ID: <3CC6E87F.5400277D@noaa.gov>

Hi,

I have trouble to figure out how the df is derived in LME.  Here is my
model,

   lme(y~x+log(den)+sex+dep,data=lwd,random= list(group=~x))

Number of total samples (N) is 3237
number of groups (J) is 26
number of level-1 variables (Q1) is 3, i.e., x, log(den) and sex
number of level-2 variables (Q2) is 1, i.e., dep
x and den are continuous variable
sex is associated with individual samples and has 2 levels
dep is associated with group has 4 levels: depD15, depD27, and depD35,
and depD35.

I got the results:

Fixed effects: y ~ x + log(den) + sex + dep
                         Value       Std.Error   DF   t-value p-value
(Intercept) -11.29271     0.1681915 3206 -67.14200  <.0001
              x     3.05937     0.0367970 3206  83.14182  <.0001
   log(den)     0.00898     0.0022357 3206   4.01732  0.0001
           sex     0.01980     0.0057675 3206   3.43216  0.0006
    depD27   -0.01505     0.0560142 3206  -0.26872  0.7882
    depD35   -0.06102     0.0548647 3206  -1.11227  0.2661
    depD50   -0.29123     0.0567132     24  -5.13511  <.0001

Are these coefficients are the level-2, and thus, DF for testing dep's
should be (J-Q2_1=26-1-1=24).  Why I get the number 3206, especially for
depD27 depD35 and depD50.

Thanks
Han
Han-Lin.Lai at noaa.gov


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mjw at celos.net  Wed Apr 24 18:29:15 2002
From: mjw at celos.net (Mark White)
Date: Wed, 24 Apr 2002 17:29:15 +0100
Subject: [R] error loading huge .RData
In-Reply-To: <51F9C42DA15CD311BD220008C707D81906FFC248@usrymx10.merck.com>; from andy_liaw@merck.com on Wed, Apr 24, 2002 at 08:53:10AM -0400
References: <51F9C42DA15CD311BD220008C707D81906FFC248@usrymx10.merck.com>
Message-ID: <20020424172915.A993@celos.net>

Liaw, Andy writes:
> > Hmm. You could be running into some sort of situation where data
> > temporarily take up more space in memory than they need to. It does
> > sound like a bit of a bug if R can write images that are bigger than
> > it can read. Not sure how to proceed though.

I regularly carry around image processing workspaces 600+ MB
and haven't had any problems so far...

> R-1.4.1/Mandrake Linux 7.1 (kernel 2.4.3)
> Dual P3-866 Xeon with 2GB RAM and 2GB swap.

...and I'm using fairly similar hardware, too, running NetBSD.

> Prof. Tierney has been trying to help me off-list.  I monitored the R.bin
> process through ktop as Prof. Tierney suggested.  The strange thing is
> that the memory usage for the R.bin process would reach nearly 1000MB
> and then R just quits with the vector heap exhausted error.
> [...] I check ulimit and it says "unlimited".

That's consistent with a datasize limit of 1024 MB, with
typical other limit values.  What does 'ulimit -a' say?

You can explicitly raise the various limits (look at the
manpage for your favourite shell under limit and/or
ulimit).  Note there are 'hard' and 'soft' limits; the
former can only be raised above a predefined ceiling by the
superuser.

Mark <><
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From richard.nixon at mrc-bsu.cam.ac.uk  Wed Apr 24 19:38:24 2002
From: richard.nixon at mrc-bsu.cam.ac.uk (Richard Nixon)
Date: Wed, 24 Apr 2002 18:38:24 +0100 (BST)
Subject: [R] glm() function not finding the maximum
In-Reply-To: <15556.26761.953196.820776@minke.stat.ufl.edu>
Message-ID: <Pine.GSO.4.44.0204241833290.14252-100000@moeran>


Hello,

Thanks to Brett Presnell and Brian Ripley I see the error of my ways.

I now conclude one of two things, either:

(1)
model_glm(data~1, family=Gamma)
summary(model)$dispersion

is not the same thing as dispersion as defined by McCullagh and Nelder
(M+N) (Generalized linear models).

Because the shape parameter of a gamma distribution is 1/(M+N dispersion),
but
1/summary(model)$dispersion is not the shape parameter. However,

or (2)
1/summary(model)$dispersion is supposed to equal M+N dispersion but my
pathological data set messes it up.

note that the moment estimator of the shape parameter
mean(data)^2/var(data) = 0.09572403
is close to
1/summary(model)$dispersion = 0.09622557

Brian Ripley also points out that optim() is now part of the latest MASS
library for splus6.

Thanks
Richard

> library(MASS)
> gamma1(data) #uses the glm() function
$loglik1
[1] 875.0035

$loglik2
[1] 793.3913       # Now agrees with log likelihood below

$par
[1]   0.09622557   0.51814501 415.99465517
# $par[2]=shape = gamma.shape(m)$alpha is correct
# $par[1]=shape = 1/summary(m)$disp is not correct

> gamma2(data) #"by hand" using optim()
$loglik
[1] 793.3913

$par
[1]   0.518145 415.994662

data_c(51.47, 210.19, 49.55, 61.93, 60.61, 744.57, 338.59, 133.93,
191.57, 111.43, 432.83, 185.23, 155.61, 84.72, 120.2, 15.33,
77.05, 115.77, 25.23, 657.94, 108.39, 61.08, 142.42, 87.86, 272.87,
213.78, 65.23, 102.45, 58.16, 176.58, 76.58, 434.12, 362.35,
102.53, 103.6, 25.23, 97.19, 88.52, 118.55, 151.9, 2.7, 156.41,
21.79, 272.27, 23.16, 32.07, 6325.23, 92.37, 8340.04, 51.08,
55.59, 94.08, 69.98, 554.13, 104.88, 170.15, 945.1, 143.52)

#Fits data to a gamma distribution using glm()
gamma1_function(data){
m_glm(data~1, family=Gamma)
shape1_1/summary(m)$disp
shape2_gamma.shape(m)$alpha
mu_mean(data)

dev.res1_-2*log(dgamma(data,shape=shape1,scale=mu/shape1))
loglik1_sum(dev.res1)  #actually -2 * log like
dev.res2_-2*log(dgamma(data,shape=shape2,scale=mu/shape2))
loglik2_sum(dev.res2)  #actually -2 * log like

list(loglik1=loglik1,loglik2=loglik2,par=c(shape1,shape2,mu))
}

#Fits data to a gamma distribution "by hand" using optim()
gamma2_function(data){
n_length(data)
m_glm(data~1, family=Gamma)
shape_gamma.shape(m)$alpha

#L = -Log likelihood
L_function(x){-(-n*log(gamma(x[1]))+n*x[1]*log(x[1]/x[2])+(x[1]-1)*sum(log(data))-x[1]/x[2]
*sum(data))}
start_c(shape, mean(data))
parscale_start
fit_optim(start,L,method="L-BFGS-B",lower=c(shape/100,0),
upper=c(NA,NA),control=list(parscale=parscale))
shape_fit$par[1]
mu_fit$par[2]

dev.res_-2*log(dgamma(data,shape=shape,scale=mu/shape))
loglik_sum(dev.res)  #actually -2 * log like

list(loglik=loglik,par=c(shape,mu))
}



--
Dr. Richard Nixon
MRC Biostatistics Unit, Institute of Public Health,
Robinson Way, Cambridge, CB2 2SR
http://www.mrc-bsu.cam.ac.uk/personal/richard
Tel: +44 (0)1223 330382, Fax: +44 (0)1223 330388

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Wed Apr 24 19:51:03 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 24 Apr 2002 12:51:03 -0500
Subject: [R] Multiple frequencies
In-Reply-To: <DB357444-575A-11D6-A1A9-0003934A808C@poulet.org>
References: <DB357444-575A-11D6-A1A9-0003934A808C@poulet.org>
Message-ID: <6rpu0pouig.fsf@franz.stat.wisc.edu>

Yannick Wurm <idh at poulet.org> writes:

> 	I'm having a small problem with an assignment I have to do.

> 	We want to do an anova on some values, given for four
> different types of medicine. The different sample numbers are not
> identical (eg for molecule A we have 8 values, for B we have 14, etc.).

> 	What would the most elegant way of getting this info into R to
> do an lm be? I usually try to use data.frames but R categorically
> refuses to combine the values (i scan()'d them into four vectors)
> because their row numbers aren't identical. (even if I do check.rows =
> FALSE).

Once you have the four vectors use stack to convert them to a data
frame with the values all stacked in one column and a companion column
of the indicators of the group.

> m1 <- 1:6
> m2 <- 101:104
> m3 <- 201:205
> stack(list(m1 = m1, m2 = m2, m3 = m3))
   values ind
1       1  m1
2       2  m1
3       3  m1
4       4  m1
5       5  m1
6       6  m1
7     101  m2
8     102  m2
9     103  m2
10    104  m2
11    201  m3
12    202  m3
13    203  m3
14    204  m3
15    205  m3
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Wed Apr 24 19:57:02 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 24 Apr 2002 12:57:02 -0500
Subject: [R] nonlinear least squares, multiresponse
In-Reply-To: <3.0.1.32.20020424104139.00e148e0@gatty.st-and.ac.uk>
References: <3.0.1.32.20020424104139.00e148e0@gatty.st-and.ac.uk>
Message-ID: <6rk7qxou8h.fsf@franz.stat.wisc.edu>

Sophie Smout <scs10 at st-andrews.ac.uk> writes:

> I'm trying to fit a model to solve a biological problem.

> There are multiple independent variables, and also there are multiple
> responses. 

> Each response is a function of all the independent variables, plus a set of
> parameters. All the responses depend on the same variables and parameters -
> just the form of the function changes to define each seperate response. 

> Any ideas how I can fit parameters to my data?
> nls, as I understand it, will work for multiple independent variables, but
> not multiple responses. 

The Box-Draper criterion for multiresponse parameter estimation is
discussed in chapter 4 of Bates and Watts, "Nonlinear Regression
Analysis and Its Applications" (Wiley, 1988).  There is even a
detailed explanation there of a generalized Gauss-Newton algorithm to
optimize the criterion.  We did not implement that in the nls function
for R and, given the state of my "To Do" list, it is not likely to
happen soon.

If a skilled and energetic R/C programmer would like to undertake this
project I would be happy to provide advice on how it could be
implemented.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From haianlin at agere.com  Wed Apr 24 20:32:02 2002
From: haianlin at agere.com (Lin, Hai-An (Hai-An))
Date: Wed, 24 Apr 2002 14:32:02 -0400
Subject: [R] Boxplot
Message-ID: <C093F2B9DDFD544283D02A8BB125884307D646A0@pai820excuag02.ags.agere.com>

Dear Sir,

Here is my question: if i have a table like 

 <<...OLE_Obj...>> 
How can I creat a boxplot with data (parameter) grouped by "lot number" and
x axis is ordered by "date"? I know that boxplot(split(parameter, lot
number) ) will give you the plot group by "lot number". however, the x axis
will also be ordered by "lot number" in this case.

Thanks!

Hai-An Lin

                       Systems
Agere
Yield Improvement Engineering
Phone:610-712-8702
Fax:610-712-6327
Addr:24D-214 AK
555 Union Boulevard
Allentown, PA 18109 





-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rjohn at dogwood.botany.uga.edu  Wed Apr 24 21:55:24 2002
From: rjohn at dogwood.botany.uga.edu (Robert John)
Date: Wed, 24 Apr 2002 15:55:24 -0400 (EDT)
Subject: [R] Newton-Raphson 
Message-ID: <Pine.LNX.4.33.0204241550200.3168-100000@dogwood.botany.uga.edu>


Hi,

Is there a routine available in R for the Newton-Raphson method for
simulataneous equations in several unknowns?

Thanks

Robert

-- 
Robert J. Chandran
Department of Botany
3506 Miller Plant Sciences Building
University of Georgia
Athens, GA 30602
Phone: (706)-583-0943


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Wed Apr 24 22:27:18 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 24 Apr 2002 21:27:18 +0100 (BST)
Subject: [R] Newton-Raphson 
In-Reply-To: <Pine.LNX.4.33.0204241550200.3168-100000@dogwood.botany.uga.edu>
Message-ID: <Pine.LNX.4.31.0204242123300.20561-100000@gannet.stats>

On Wed, 24 Apr 2002, Robert John wrote:

> Is there a routine available in R for the Newton-Raphson method for
> simulataneous equations in several unknowns?

No, but then it not a particulary good method unless you have a very good
starting point.

The best we can offer is to apply optim(method="BFGS") to the (possibly
weighted) sum of squares of differences between the lhs and rhs.  In my
experience that works very well.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rmalayam at ic.sunysb.edu  Wed Apr 24 19:35:02 2002
From: rmalayam at ic.sunysb.edu (Ravi Malayambakkam-n)
Date: Wed, 24 Apr 2002 13:35:02 -0400 (EDT)
Subject: [R] Regarding pp.plot(){CircStats}
Message-ID: <Pine.GSO.4.21.0204241324390.9453-100000@sparky.ic.sunysb.edu>

	      [message needed manual approvement:
	       it had a single line "help"  -- MM ]

I have a table containing two columns and some 600 rows.  The first column 
is a time series in the sense contains the amount of time the model that i
am studying stays in a particular state(ie sojourn time).  I 
extract the contents of the table using read.table. and extract the
first column from the table as follows.
	ft <-read.table(<filename>)
	firstcol <-ft[1].
When I pass firstcol as a parameter to pp.plot(firstcol) I get the 
following error :
Error in if (abs(term) < acc) flag <- "false" : 
         missing value where logical needed
 
Can anyone tell me where the mistake is.

end.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Apr 25 09:17:48 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 25 Apr 2002 09:17:48 +0200
Subject: [R] Regarding pp.plot(){CircStats}
In-Reply-To: <Pine.GSO.4.21.0204241324390.9453-100000@sparky.ic.sunysb.edu>
References: <Pine.GSO.4.21.0204241324390.9453-100000@sparky.ic.sunysb.edu>
Message-ID: <x2n0vsnt5v.fsf@blueberry.kubism.ku.dk>

Ravi Malayambakkam-n <rmalayam at ic.sunysb.edu> writes:

> 	      [message needed manual approvement:
> 	       it had a single line "help"  -- MM ]
> 
> I have a table containing two columns and some 600 rows.  The first column 
> is a time series in the sense contains the amount of time the model that i
> am studying stays in a particular state(ie sojourn time).  I 
> extract the contents of the table using read.table. and extract the
> first column from the table as follows.
> 	ft <-read.table(<filename>)
> 	firstcol <-ft[1].
> When I pass firstcol as a parameter to pp.plot(firstcol) I get the 
> following error :
> Error in if (abs(term) < acc) flag <- "false" : 
>          missing value where logical needed
>  
> Can anyone tell me where the mistake is.

Haven't tried pp.plot, but I would guess that it is because ft[1] is a
*data frame* with one column. Try ft[[1]] to get the column vector
itself. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ken_lee at tynesys.com  Thu Apr 25 09:20:16 2002
From: ken_lee at tynesys.com (ken_lee)
Date: Thu, 25 Apr 2002 15:20:16 +0800
Subject: [R] An unexpected exception has been detected in native code outside the VM
Message-ID: <IPECKKKLFINFHEGMEKKGCECICAAA.ken_lee@tynesys.com>

Dear all:
      I have a problem with calling R from Java,
It was ok at the first time,but the error message "An unexpected exception has been detected in native code outside the VM. "
will appear. What is the issue of "native code"?

Could somebody help me ? 
Thanks, 
ken

This is the log I obtained: 

executing: source('/export/home/users/ruser/java/Rmain.R')
Loading RInterpreter library

R : Copyright 2002, The R Development Core Team
Version 1.4.1  (2002-01-30)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type `license()' or `licence()' for distribution details.

R is a collaborative project with many contributors.
Type `contributors()' for more information.

Type `demo()' for some demos, `help()' for on-line help, or
`help.start()' for a HTML browser interface to help.
Type `q()' to quit R.

[Previously saved workspace restored]

now dyn.load(/usr/local/lib/R/library/ctest/libs/ctest.so)..
`envir' chosen:<environment: R_GlobalEnv>
--> parsed 1 expressions; now eval(.)ing them:

>>>> eval(expression_nr. 1 )
		 =================

> rmain <- function(Rvals = NULL) {
    library(SJava)
    library(nlme)
    library(ctest)
    print(Rvals)
    file <- "zz"
    dev <- "png"
    print .... [TRUNCATED] 
curr.fun: symbol <-
 .. after `expression(rmain <- function(Rvals = NULL) {    library(SJava)    library(nlme)    library(ctest)    print(Rvals)    file <- "zz"    dev <- "png"    print(dev)    draw <- "pairs_corr_scatter"    if (draw == "pairs_corr_scatter") {        source("/export/home/users/ruser/rsc/pcscatter01.R")        NODE = rnorm(77)        RSM2 = rnorm(77)        CADT = rnorm(77)        VTS = c(NODE - c(rnorm(12), rep(0, 65)))        xRS = c(NODE - c(rnorm(27), rep(0, 50)))        reda <- data.frame(NODE = NODE, RSM2 = RSM2, CADT = CADT,             VTS = VTS, xRS = xRS)        pcscatter01(file = file, dev = dev, reda = reda, title = "title",             footnote = "aaa")    }    print(file)    val <- 1    val})'
now dyn.load(/usr/local/lib/R/library/SJava/libs/SJava.so)..
Garbage collection 1 = 0+0+1 (level 2) ... 
146961 cons cells free (36%)
5.7 Mbytes of heap free (95%)
Loading required package: nls 
Garbage collection 2 = 1+0+1 (level 0) ... 
85806 cons cells free (21%)
5.5 Mbytes of heap free (92%)
now dyn.load(/usr/local/lib/R/library/nls/libs/nls.so)..
now dyn.load(/usr/local/lib/R/library/nlme/libs/nlme.so)..
`envir' chosen:<environment: R_GlobalEnv>
--> parsed 1 expressions; now eval(.)ing them:

>>>> eval(expression_nr. 1 )
		 =================

> pcscatter01 <- function(file = NULL, dev, reda, title, 
    footnote, width = 10, height = 7) {
    tmp <- paste(file, dev, sep = "_pcscatter.")
    c .... [TRUNCATED] 
curr.fun: symbol <-
 .. after `expression(pcscatter01 <- function(file = NULL, dev, reda, title,     footnote, width = 10, height = 7) {    tmp <- paste(file, dev, sep = "_pcscatter.")    cmd <- paste("| gs -dNOPAUSE -dBATCH -q -sDEVICE=png256 -r90 -g900x630 -sOutputFile=",         tmp, " -", sep = "")    postscript(file = cmd, width = width, height = height, pointsize = 10.5,         paper = "special", horizontal = F)    invisible()    par(mar = c(5, 4, 4, 2))    title <- list(title, col = "red", cex = 1.5)    panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor) {        usr <- par("usr")        on.exit(par(usr))        par(usr = c(0, 1, 0, 1))        r <- abs(cor(x, y))        txt <- format(c(r, 0.123456789), digits = digits)[1]        txt <- paste(prefix, txt, sep = "")        if (missing(cex.cor))             cex <- 0.8/strwidth(txt)        text(0.5, 0.5, txt, cex = cex * r)    }    pairs(reda, lower.panel = panel.smooth, upper.panel = panel.cor)    title(main = title, line = 2)    graphics.off()})'
Garbage collection 3 = 2+0+1 (level 0) ... 
83676 cons cells free (20%)
5.5 Mbytes of heap free (91%)
executing: source('/export/home/users/ruser/java/Rmain.R')

R : Copyright 2002, The R Development Core Team
Version 1.4.1  (2002-01-30)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type `license()' or `licence()' for distribution details.

R is a collaborative project with many contributors.
Type `contributors()' for more information.

Type `demo()' for some demos, `help()' for on-line help, or
`help.start()' for a HTML browser interface to help.
Type `q()' to quit R.


An unexpected exception has been detected in native code outside the VM.                      <=====ERROR MESSAGE====
Unexpected Signal : 11 occurred at PC=0xf27e2440
Function name=do_dump
Library=/usr/local/lib/R/bin/libR.so

Current Java thread:
	at org.omegahat.R.Java.ROmegahatInterpreter.initR(Native Method)
	at org.omegahat.R.Java.ROmegahatInterpreter.<init>(ROmegahatInterpreter.java:65)
	at com.tynesys.common.cpc01Action.perform(cpc01Action.java:231)
	at org.apache.struts.action.ActionServlet.processActionPerform(ActionServlet.java:1787)
	at org.apache.struts.action.ActionServlet.process(ActionServlet.java:1586)
	at org.apache.struts.action.ActionServlet.doPost(ActionServlet.java:510)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:760)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:853)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:247)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:243)
	at org.apache.catalina.core.StandardPipeline.invokeNext(StandardPipeline.java:566)
	at org.apache.catalina.core.StandardPipeline.invoke(StandardPipeline.java:472)
	at org.apache.catalina.core.ContainerBase.invoke(ContainerBase.java:943)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:190)
	at org.apache.catalina.core.StandardPipeline.invokeNext(StandardPipeline.java:566)
	at org.apache.catalina.core.StandardPipeline.invoke(StandardPipeline.java:472)
	at org.apache.catalina.core.ContainerBase.invoke(ContainerBase.java:943)
	at org.apache.catalina.core.StandardContext.invoke(StandardContext.java:2343)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:180)
	at org.apache.catalina.core.StandardPipeline.invokeNext(StandardPipeline.java:566)
	at org.apache.catalina.valves.ErrorDispatcherValve.invoke(ErrorDispatcherValve.java:170)
	at org.apache.catalina.core.StandardPipeline.invokeNext(StandardPipeline.java:564)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:170)
	at org.apache.catalina.core.StandardPipeline.invokeNext(StandardPipeline.java:564)
	at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:468)
	at org.apache.catalina.core.StandardPipeline.invokeNext(StandardPipeline.java:564)
	at org.apache.catalina.core.StandardPipeline.invoke(StandardPipeline.java:472)
	at org.apache.catalina.core.ContainerBase.invoke(ContainerBase.java:943)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:174)
	at org.apache.catalina.core.StandardPipeline.invokeNext(StandardPipeline.java:566)
	at org.apache.catalina.core.StandardPipeline.invoke(StandardPipeline.java:472)
	at org.apache.catalina.core.ContainerBase.invoke(ContainerBase.java:943)
	at org.apache.catalina.connector.http.HttpProcessor.process(HttpProcessor.java:1012)
	at org.apache.catalina.connector.http.HttpProcessor.run(HttpProcessor.java:1107)
	at java.lang.Thread.run(Thread.java:479)

Dynamic libraries:
0x10000 	/usr/java/bin/../bin/sparc/native_threads/java
0xff350000 	/usr/lib/libthread.so.1
0xff390000 	/usr/lib/libdl.so.1
0xff200000 	/usr/lib/libc.so.1
0xff330000 	/usr/platform/SUNW,Ultra-60/lib/libc_psr.so.1
0xfe480000 	/usr/j2se/jre/lib/sparc/client/libjvm.so
0xff2e0000 	/usr/lib/libCrun.so.1
0xff1e0000 	/usr/lib/libsocket.so.1
0xff100000 	/usr/lib/libnsl.so.1
0xff0d0000 	/usr/lib/libm.so.1
0xff310000 	/usr/lib/libw.so.1
0xff0b0000 	/usr/lib/libmp.so.2
0xff080000 	/usr/j2se/jre/lib/sparc/native_threads/libhpi.so
0xff050000 	/usr/j2se/jre/lib/sparc/libverify.so
0xfe440000 	/usr/j2se/jre/lib/sparc/libjava.so
0xff020000 	/usr/j2se/jre/lib/sparc/libzip.so
0xfaed0000 	/usr/j2se/jre/lib/sparc/libnet.so
0xfacd0000 	/usr/lib/nss_files.so.1
0xf3ee0000 	/usr/local/lib/R/library/SJava/libs/SJava.so
0xf3ec0000 	/usr/local/lib/R/library/SJava/libs/libRSNativeJava.so
0xf2780000 	/usr/local/lib/R/bin/libR.so
0xf3ea0000 	/usr/local/lib/libgcc_s.so.1
0xf3dd0000 	/usr/lib/libz.so.1
0xf3c30000 	/usr/lib/libcurses.so.1
0xf3db0000 	/usr/local/lib/R/library/ctest/libs/ctest.so
0xf3c10000 	/usr/local/lib/R/library/nls/libs/nls.so
0xf3b50000 	/usr/local/lib/R/library/nlme/libs/nlme.so

Local Time = Thu Apr 25 11:18:04 2002
Elapsed Time = 51
#
# The exception above was detected in native code outside the VM
#
# Java VM: Java HotSpot(TM) Client VM (1.3.1_03-b03 mixed mode)
#
# An error report file has been saved as hs_err_pid6344.log.
# Please refer to the file for further information.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Apr 25 09:26:50 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 25 Apr 2002 08:26:50 +0100 (BST)
Subject: [R] Regarding pp.plot(){CircStats}
In-Reply-To: <Pine.GSO.4.21.0204241324390.9453-100000@sparky.ic.sunysb.edu>
Message-ID: <Pine.LNX.4.31.0204250813580.24237-100000@gannet.stats>

On Wed, 24 Apr 2002, Ravi Malayambakkam-n wrote:

> 	      [message needed manual approvement:
> 	       it had a single line "help"  -- MM ]
>
> I have a table containing two columns and some 600 rows.  The first column
> is a time series in the sense contains the amount of time the model that i
> am studying stays in a particular state(ie sojourn time).

That is a vector of times, not a time series, unless the observations are
ordered in (calendar) time.  If this is a time series, statistical methods
that assume independence are probably inappropriate.

> I
> extract the contents of the table using read.table. and extract the
> first column from the table as follows.
> 	ft <-read.table(<filename>)
> 	firstcol <-ft[1].
> When I pass firstcol as a parameter to pp.plot(firstcol) I get the
> following error :
> Error in if (abs(term) < acc) flag <- "false" :
>          missing value where logical needed
>
> Can anyone tell me where the mistake is.

Well, you haven't given us anything to reproduce this, not even a
traceback().  R does come with quite a few debugging facilities to help
you find the error.

However, the first thing to do is to check if you passed the right
arguments.  For pp.plot, this is a vector of angular measurements in
radians.  That does not match your description!

Please send a reproducible example to the maintainers of CircStats.  At
the least they have been insufficiently defensive against incorrect
inputs, and there may be more to it that that.  Please also tell them
the version of the package you used, and the result of R.version.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at blindglobe.net  Thu Apr 25 09:31:21 2002
From: rossini at blindglobe.net (A.J. Rossini)
Date: 25 Apr 2002 00:31:21 -0700
Subject: [R] An unexpected exception has been detected in native code outside the VM
In-Reply-To: <IPECKKKLFINFHEGMEKKGCECICAAA.ken_lee@tynesys.com>
References: <IPECKKKLFINFHEGMEKKGCECICAAA.ken_lee@tynesys.com>
Message-ID: <878z7cdyk6.fsf@jeeves.blindglobe.net>



>>>>> "ken" == ken lee <ken_lee> writes:

    ken> Dear all:
    ken>       I have a problem with calling R from Java,
    ken> It was ok at the first time,but the error message "An unexpected exception has been detected in native code outside the VM. "
    ken> will appear. What is the issue of "native code"?

It refers to the R shared library, being loaded in using JNI.  The
message is quite clear about this:

    ken> An unexpected exception has been detected in native code outside the VM.                      <=====ERROR MESSAGE====
    ken> Unexpected Signal : 11 occurred at PC=0xf27e2440
    ken> Function name=do_dump
    ken> Library=/usr/local/lib/R/bin/libR.so


Good luck with that!  I've had better luck the other way (Java within
R).  Not perfect luck, but usually acceptable.

Cool!  Servlet processing.  You'll need luck, then...

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M-W: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my friday location is usually completely unpredictable.)


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From W.Simpson at gcal.ac.uk  Thu Apr 25 10:04:54 2002
From: W.Simpson at gcal.ac.uk (Bill Simpson)
Date: Thu, 25 Apr 2002 09:04:54 +0100 (BST)
Subject: [R] nonlinear least squares, multiresponse
In-Reply-To: <6rk7qxou8h.fsf@franz.stat.wisc.edu>
Message-ID: <Pine.LNX.4.10.10204250853450.4845-100000@localhost.localdomain>

Here is a solution that is fairly easy to do. (Not sure how statistically
reasonable it is--seems OK to me)

Use nlm() or optimize() to minimise the sum of the squared residuals
across all DVs simultaneously. If your IVs are a,b,c , your parameters
are b0,b1,b2, and your DVs are x,y,z, then nlm() will iteratively minimize

(x-fnx(a,b,c,b0,b1,b2))^2+
(y-fny(a,b,c,b0,b1,b2))^2+
(z-fnz(a,b,c,b0,b1,b2))^2

Or I suppose you could write a function that returns a vector
xhat, yhat, zhat

Here is a simple 1 IV 1 DV example to base your code on:

x<-c(0.02, 0.02, 0.06, 0.06, 0.11, 0.11, 0.22, 0.22, 0.56, 0.56, 1.10,
1.10)
y<-c(76, 47, 97, 107, 123, 139, 159, 152, 191, 201, 207, 200)
fn <- function(p) sum((y - (p[1] * x)/(p[2] + x))^2)
out<-nlm(fn,p=c(200,.1),hessian=TRUE)
out
#SSE = out$minimum; MSE = out$minimum/(n-p), n is #pts, p is #params
#estimates=out$estimate
se<-sqrt(diag(2*out$minimum/(length(y)-2)*solve(out$hessian)))  #SEs


Bill

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From HStevens at muohio.edu  Thu Apr 25 11:20:10 2002
From: HStevens at muohio.edu (Martin Henry H. Stevens)
Date: Thu, 25 Apr 2002 05:20:10 -0400
Subject: [R] Kendall's tau
Message-ID: <5.1.0.14.2.20020425050739.02a676a0@po.muohio.edu>

A search of the archives did not reveal an answer:
For basic tests of association, where one has no a priori knowledge of the 
form of the relation or of the distributions of the variables, rank 
correlation seems like a good start. Why is cor.test() with Kendall and 
Spearman options relegated to the ctest package, rather than in the base 
package? Does this suggest that the developers consider other tests of 
association more generally useful?
Thanks,
Hank

Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Tel: (513) 529-4206
FAX: (513) 529-4243
http://www.muohio.edu/~botcwis/bot/henry.html

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jonathan.williams at pharmacology.oxford.ac.uk  Thu Apr 25 11:50:57 2002
From: jonathan.williams at pharmacology.oxford.ac.uk (Jonathan Williams)
Date: Thu, 25 Apr 2002 10:50:57 +0100
Subject: [R] Crossed random effects
Message-ID: <OOEMKKHAJOAMJMBALHDNGEEACCAA.jonathan.williams@pharm.ox.ac.uk>

I would be very grateful for help with devising the correct formula 
for an analysis with crossed random effects.

The data consist of measurements of the width of a brain structure
from 145 subjects, on both the right and left. So, Side is nested
within Subject in a balanced design. 

3 raters measured the widths. One rater measured all 145 widths twice 
- so there were 2 replications. One rater measured all the widths, 
and then re-measured a random 30% of them. One measured only a random 
70% of the widths once. So, replication is nested within rater, and 
these random factors are highly unbalanced.

I want to analyse the relationship of the widths to subject variables 
such as age and gender. But, I do not know how to write the correct
formula for the random effects to specify how the Subject/Side structure 
is crossed with the Rater/Replication structure. I gather from reading
Pinheiro and Bates (p163) that "The crossed random effects structure is
represented in lme by a combination of pdBlocked and pdIdent objects".
But, I cannot see how to extend the example in the book to fit my data.

I would be very grateful for help with this.

Jonathan Williams
OPTIMA Clinical Fellow and Honorary Consultant Psychiatrist
Dept Pharmacology
Oxford University
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Apr 25 11:43:36 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 25 Apr 2002 10:43:36 +0100 (BST)
Subject: [R] Kendall's tau
In-Reply-To: <5.1.0.14.2.20020425050739.02a676a0@po.muohio.edu>
Message-ID: <Pine.LNX.4.31.0204251037070.24762-100000@gannet.stats>

On Thu, 25 Apr 2002, Martin Henry H. Stevens wrote:

> A search of the archives did not reveal an answer:
> For basic tests of association, where one has no a priori knowledge of the
> form of the relation or of the distributions of the variables, rank
> correlation seems like a good start. Why is cor.test() with Kendall and
> Spearman options relegated to the ctest package, rather than in the base
> package? Does this suggest that the developers consider other tests of
> association more generally useful?

It's *not* relegated.  t.test is there too!

There is no sense in which material in the standard or recommended
packages is not considered `generally useful'.  However, R does keep all
its code in memory, and the long-term aim has been to strip the base
package down to the bare essentials (e.g. removing lm).  Many R users
never use lm nor cor.test, and I suspect the vast majority of R sessions
do not use either.  If we had all the standard material in base, R would
run slower and need more memory (and the latter has been an issue until
recently, with 16Mb teaching labs).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Apr 25 11:42:59 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 25 Apr 2002 11:42:59 +0200
Subject: [R] Kendall's tau
In-Reply-To: <5.1.0.14.2.20020425050739.02a676a0@po.muohio.edu>
References: <5.1.0.14.2.20020425050739.02a676a0@po.muohio.edu>
Message-ID: <x2y9fc8670.fsf@blueberry.kubism.ku.dk>

"Martin Henry H. Stevens" <HStevens at muohio.edu> writes:

> A search of the archives did not reveal an answer:
> For basic tests of association, where one has no a priori knowledge of
> the form of the relation or of the distributions of the variables,
> rank correlation seems like a good start. Why is cor.test() with
> Kendall and Spearman options relegated to the ctest package, rather
> than in the base package? Does this suggest that the developers
> consider other tests of association more generally useful?


No. *All* "classical tests" are in ctest. Also t.test for instance.
Arguably other stuff (e.g. lm/glm) ought to be moved away from base
and automatically loaded upon startup in the same way that ctest is,
leaving a "lean, mean, and clean" core, that could be used efficiently
in e.g. shell scripts. (R has a start-up time of about a second on
current hardware - give or take a few powers of 2, which is generally
tolerable unless running in a loop.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From meinhard.ploner at univie.ac.at  Thu Apr 25 11:56:22 2002
From: meinhard.ploner at univie.ac.at (Meinhard Ploner)
Date: Thu, 25 Apr 2002 11:56:22 +0200
Subject: [R] polyclass
Message-ID: <B2A1F45F-5832-11D6-8170-0003938C0ABE@univie.ac.at>

Is the library polyclass (Kooperberg, ...) available in R?
thanks
Meinhard P.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Thu Apr 25 12:04:13 2002
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Thu, 25 Apr 2002 06:04:13 -0400
Subject: [R] Kendall's tau
In-Reply-To: <5.1.0.14.2.20020425050739.02a676a0@po.muohio.edu>; from HStevens@muohio.edu on Thu, Apr 25, 2002 at 05:20:10AM -0400
References: <5.1.0.14.2.20020425050739.02a676a0@po.muohio.edu>
Message-ID: <20020425060413.A1615@cattell.psych.upenn.edu>

On 04/25/02 05:20, Martin Henry H. Stevens wrote:
>A search of the archives did not reveal an answer:
>For basic tests of association, where one has no a priori knowledge of the 
>form of the relation or of the distributions of the variables, rank 
>correlation seems like a good start. Why is cor.test() with Kendall and 
>Spearman options relegated to the ctest package, rather than in the base 
>package? Does this suggest that the developers consider other tests of 
>association more generally useful?
>Thanks,
>Hank

I think I remember a version of R in which the ctest package had
to be loaded with library(), but it was a long time ago.
Everything in the ctest package is now simply available when you
start R.  I suspect that it is separate from "base" for
historical reasons.  It isn't clear to me whether change is
needed, and, if so, whether the base package should become even
larger or whether it should be broken up into yet more parts.  As
things are now, even on a fast computer loading from its own
disk, the html listing of the base package takes a bit of time to
load.  My own opinion is that this is a low-priority issue.

As for what to do when you don't know what your data look like,
my own recommendation is not to do anything in cor.test(), but,
use plot(), and then figure out what to do next, e.g., fix
errors, apply a tranform, or do a test.  Sometimes, of course,
you know in advance that tau is the appropriate test.

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Apr 25 13:16:12 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 25 Apr 2002 12:16:12 +0100 (BST)
Subject: [R] polyclass
In-Reply-To: <B2A1F45F-5832-11D6-8170-0003938C0ABE@univie.ac.at>
Message-ID: <Pine.LNX.4.31.0204251209070.24939-100000@gannet.stats>

On Thu, 25 Apr 2002, Meinhard Ploner wrote:

> Is the library polyclass (Kooperberg, ...) available in R?

Not as far as I know.  I did once look at it, and thought porting would be
easy.  However, I do not approve of its usage conditions, so did not
proceed.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From psu17772 at hotmail.com  Thu Apr 25 14:23:19 2002
From: psu17772 at hotmail.com (sonchawan tamkaew)
Date: Thu, 25 Apr 2002 12:23:19 +0000
Subject: [R] install a package from CRAN
Message-ID: <F247BHZXFZ0stgr3SU00000176a@hotmail.com>

Hi,

I've tried to install package "tseries" on my computer (on Windows) but it 
doesn't work so far. I have Perl but no compilers (C or Fortran) installed. 
So could anyone who happens to have them please mail me the binaries?

Many thanks in advance,

Sonchawan



_________________________________________________________________


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Thu Apr 25 14:54:27 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 25 Apr 2002 14:54:27 +0200
Subject: [R] install a package from CRAN
References: <F247BHZXFZ0stgr3SU00000176a@hotmail.com>
Message-ID: <3CC7FC83.74316BCF@statistik.uni-dortmund.de>

sonchawan tamkaew wrote:
> 
> Hi,
> 
> I've tried to install package "tseries" on my computer (on Windows) but it
> doesn't work so far. I have Perl but no compilers (C or Fortran) installed.
> So could anyone who happens to have them please mail me the binaries?

Windows binaries of many packages are on CRAN in 
.../bin/windows/contrib

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Apr 25 15:34:44 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 25 Apr 2002 15:34:44 +0200
Subject: [R] polyclass
In-Reply-To: <Pine.LNX.4.31.0204251209070.24939-100000@gannet.stats>
References: <Pine.LNX.4.31.0204251209070.24939-100000@gannet.stats>
Message-ID: <x2u1pz9a17.fsf@blueberry.kubism.ku.dk>

ripley at stats.ox.ac.uk writes:

> On Thu, 25 Apr 2002, Meinhard Ploner wrote:
> 
> > Is the library polyclass (Kooperberg, ...) available in R?
> 
> Not as far as I know.  I did once look at it, and thought porting would be
> easy.  However, I do not approve of its usage conditions, so did not
> proceed.

Just to save y'all from looking this up: It carries a "Thou must cite
our paper in publications" clause. I can see Brian's point.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From bates at stat.wisc.edu  Thu Apr 25 17:04:57 2002
From: bates at stat.wisc.edu (Douglas Bates)
Date: 25 Apr 2002 10:04:57 -0500
Subject: [R] nonlinear least squares, multiresponse
In-Reply-To: <Pine.LNX.4.10.10204250853450.4845-100000@localhost.localdomain>
References: <Pine.LNX.4.10.10204250853450.4845-100000@localhost.localdomain>
Message-ID: <6r4rhzes4m.fsf@franz.stat.wisc.edu>

Bill Simpson <W.Simpson at gcal.ac.uk> writes:

> Here is a solution that is fairly easy to do. (Not sure how statistically
> reasonable it is--seems OK to me)
> 
> Use nlm() or optimize() to minimise the sum of the squared residuals
> across all DVs simultaneously. If your IVs are a,b,c , your parameters
> are b0,b1,b2, and your DVs are x,y,z, then nlm() will iteratively minimize
> 
> (x-fnx(a,b,c,b0,b1,b2))^2+
> (y-fny(a,b,c,b0,b1,b2))^2+
> (z-fnz(a,b,c,b0,b1,b2))^2
> 
> Or I suppose you could write a function that returns a vector
> xhat, yhat, zhat
> 
> Here is a simple 1 IV 1 DV example to base your code on:
> 
> x<-c(0.02, 0.02, 0.06, 0.06, 0.11, 0.11, 0.22, 0.22, 0.56, 0.56, 1.10,
> 1.10)
> y<-c(76, 47, 97, 107, 123, 139, 159, 152, 191, 201, 207, 200)
> fn <- function(p) sum((y - (p[1] * x)/(p[2] + x))^2)
> out<-nlm(fn,p=c(200,.1),hessian=TRUE)
> out
> #SSE = out$minimum; MSE = out$minimum/(n-p), n is #pts, p is #params
> #estimates=out$estimate
> se<-sqrt(diag(2*out$minimum/(length(y)-2)*solve(out$hessian)))  #SEs

You are making assumptions in doing that.  You are assuming that the
"noise terms" on your responses are independent and have comparable
variances.  This may not be the case.

The Box-Draper criterion is to minimize the square of the product of
the singular values of the matrix of the residuals.  I would recommend
using that instead.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From richards at upci.pitt.edu  Thu Apr 25 17:25:32 2002
From: richards at upci.pitt.edu (Richards, Tom)
Date: Thu, 25 Apr 2002 11:25:32 -0400
Subject: [R] sum() with na.rm=TRUE, again
Message-ID: <5B9B19C8A522D411A8EC00A0C99D6A9A8D2924@mail.nsabp.pitt.edu>

Hi:

	I remember a post several days ago by Jon Baron, concerning the
behavior of sum() when one sets na.rm=TRUE:
the result will be a zero sum for a vector of all NA's, as here, for the
second row:

> ss<- data.frame(x=c(1,NA,3,4),y=c(2,NA,4,NA))
> ss
   x  y
1  1  2
2 NA NA
3  3  4
4  4 NA

> apply(ss,1,sum,na.rm=TRUE)
1 2 3 4 
3 0 7 4 

I am rather alarmed by that zero, because I was just about to place the sum
function into am apply() on a rather large data management project, where
about 5% of my matrix rows have two missing values.  Is there a "safe" way
to use sum(), so that such zeroes are not created?  A safe.sum() that takes
arguments just as general as sum()?  I mean, I think I could get around this
little problem like this,

apply(ss,1,function(x){ifelse(all(is.na(x)),NA,sum(!is.na(x))*mean(x,na.rm=T
RUE))})
 1  2  3  4 
 3 NA  7  4 

but is there a safer way to write a sum() function?  Or, do these zeroes
serve some purpose that I am missing?
Thanks in advance...

Tom
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From sundard at pdf.com  Thu Apr 25 17:56:56 2002
From: sundard at pdf.com (Sundar Dorai-Raj)
Date: Thu, 25 Apr 2002 10:56:56 -0500
Subject: [R] install a package from CRAN
References: <F247BHZXFZ0stgr3SU00000176a@hotmail.com>
Message-ID: <3CC82748.8E54BAD6@pdf.com>

> 
> I've tried to install package "tseries" on my computer (on Windows) but it
> doesn't work so far. I have Perl but no compilers (C or Fortran) installed.

Have you tried:

options(CRAN="http://cran.r-project.org")
install.packages("tseries")

Enter these at the command line.


> So could anyone who happens to have them please mail me the binaries?

If the above doesn't work I'll send you the directory.

Sundar

-- 

Sundar Dorai-Raj, Ph.D.
Statistical Methods Engineer
PDF Solutions, Inc.
Richardson TX
(972) 889-3085 x216
(214) 392-7619 cell
sundard at pdf.com
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Thu Apr 25 18:04:08 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 25 Apr 2002 17:04:08 +0100 (BST)
Subject: [R] sum() with na.rm=TRUE, again
In-Reply-To: <5B9B19C8A522D411A8EC00A0C99D6A9A8D2924@mail.nsabp.pitt.edu>
Message-ID: <Pine.LNX.4.31.0204251658410.1694-100000@gannet.stats>

On Thu, 25 Apr 2002, Richards, Tom wrote:

> Hi:
>
> 	I remember a post several days ago by Jon Baron, concerning the
> behavior of sum() when one sets na.rm=TRUE:
> the result will be a zero sum for a vector of all NA's, as here, for the
> second row:
>
> > ss<- data.frame(x=c(1,NA,3,4),y=c(2,NA,4,NA))
> > ss
>    x  y
> 1  1  2
> 2 NA NA
> 3  3  4
> 4  4 NA
>
> > apply(ss,1,sum,na.rm=TRUE)
> 1 2 3 4
> 3 0 7 4
>
> I am rather alarmed by that zero, because I was just about to place the sum
> function into am apply() on a rather large data management project, where
> about 5% of my matrix rows have two missing values.  Is there a "safe" way
> to use sum(), so that such zeroes are not created?  A safe.sum() that takes
> arguments just as general as sum()?  I mean, I think I could get around this
> little problem like this,
>
> apply(ss,1,function(x){ifelse(all(is.na(x)),NA,sum(!is.na(x))*mean(x,na.rm=T
> RUE))})
>  1  2  3  4
>  3 NA  7  4
>
> but is there a safer way to write a sum() function?  Or, do these zeroes
> serve some purpose that I am missing?

They are the correct answer!  The sum of an empty set is zero, by
definition.  If that is not what you want, then you don't want the sum and
should define a function to do what you do want.  That might be

> apply(ss,1,function(x){z <- x[!is.na(x)]; ifelse(length(z), sum(z), NA)})
 1  2  3  4
 3 NA  7  4

Yours accounts for all missing twice.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Thu Apr 25 18:10:17 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 25 Apr 2002 12:10:17 -0400
Subject: [R] sum() with na.rm=TRUE, again
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC257@usrymx10.merck.com>

After stripping NAs, you have a vector of 0 elements.  Sum of such vector is
0, not NA.  Try:

  sum(numeric(0))

Andy

> -----Original Message-----
> From: Richards, Tom [mailto:richards at upci.pitt.edu]
> Sent: Thursday, April 25, 2002 11:26 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] sum() with na.rm=TRUE, again
> 
> 
> Hi:
> 
> 	I remember a post several days ago by Jon Baron, concerning the
> behavior of sum() when one sets na.rm=TRUE:
> the result will be a zero sum for a vector of all NA's, as 
> here, for the
> second row:
> 
> > ss<- data.frame(x=c(1,NA,3,4),y=c(2,NA,4,NA))
> > ss
>    x  y
> 1  1  2
> 2 NA NA
> 3  3  4
> 4  4 NA
> 
> > apply(ss,1,sum,na.rm=TRUE)
> 1 2 3 4 
> 3 0 7 4 
> 
> I am rather alarmed by that zero, because I was just about to 
> place the sum
> function into am apply() on a rather large data management 
> project, where
> about 5% of my matrix rows have two missing values.  Is there 
> a "safe" way
> to use sum(), so that such zeroes are not created?  A 
> safe.sum() that takes
> arguments just as general as sum()?  I mean, I think I could 
> get around this
> little problem like this,
> 
> apply(ss,1,function(x){ifelse(all(is.na(x)),NA,sum(!is.na(x))*
> mean(x,na.rm=T
> RUE))})
>  1  2  3  4 
>  3 NA  7  4 
> 
> but is there a safer way to write a sum() function?  Or, do 
> these zeroes
> serve some purpose that I am missing?
> Thanks in advance...
> 
> Tom
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> 

------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message. If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Thu Apr 25 18:11:36 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 25 Apr 2002 18:11:36 +0200
Subject: [R] sum() with na.rm=TRUE, again
In-Reply-To: <5B9B19C8A522D411A8EC00A0C99D6A9A8D2924@mail.nsabp.pitt.edu>
References: <5B9B19C8A522D411A8EC00A0C99D6A9A8D2924@mail.nsabp.pitt.edu>
Message-ID: <x2helz92rr.fsf@blueberry.kubism.ku.dk>

"Richards, Tom" <richards at upci.pitt.edu> writes:

> but is there a safer way to write a sum() function?  Or, do these zeroes
> serve some purpose that I am missing?
> Thanks in advance...

Mathematically, the sum over an empty set is zero. This serves various
consistency purposes (sum over disjoint union of two index sets, etc.)

Just use something like

mysum <- function(x) if (all(is.na(x))) NA else sum(x,na.rm=T)
apply(ss,1,mysum)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From luke at stat.umn.edu  Thu Apr 25 18:13:16 2002
From: luke at stat.umn.edu (Luke Tierney)
Date: Thu, 25 Apr 2002 11:13:16 -0500
Subject: [R] error loading huge .RData
In-Reply-To: <51F9C42DA15CD311BD220008C707D81906FFC23F@usrymx10.merck.com>; from andy_liaw@merck.com on Tue, Apr 23, 2002 at 11:36:48AM -0400
References: <51F9C42DA15CD311BD220008C707D81906FFC23F@usrymx10.merck.com>
Message-ID: <20020425111316.A8440@nokomis.stat.umn.edu>

On Tue, Apr 23, 2002 at 11:36:48AM -0400, Liaw, Andy wrote:
> Dear R-help,
> 
> I've run into a problem loading .RData:  I was running a large computation,
> which supposedly produce a large R object.  At the end of the session, I did
> a save.image() and then quit.  The .RData has size 613,249,399 bytes.  Now I
> can't get R to load this .RData file.  Whenever I tried, I get "Error:
> vector memory exhausted (limit reached)".  I tried adding
> "--min-vsize=1000M", but that didn't help.  I also tried R  --vanilla and
> then attach(".RData"), same error.
> 
> >From what I can see, the file is not corrupted.  How can I get R to load it?
> 
> System info:
> R-1.4.1 on Mandrake Linux 7.1 (kernel 2.4.3)
> Dual P3-866 Xeon with 2GB RAM.
> 
> Regards,
> Andy
> 

Andy Liaw indicated privately that he decided to upgrade his Linux and
the problem went away (because glibc 2.2's malloc behaves by default
differently than earlier ones).

In tracking this down I learned a little more about address space use
on Linux than I wanted to know.  But as this may come up again I'll
report it for future reference.  The details are probably not quite
right, but I think the big picture is.  It may be worth knowing if you
want to use large amounts of memory on 32-bit Linux, or any other
32-bit OS--the details given here are specific to Linux, but the
general issue is not: Trying to carve out room for one or two
gigabytes of memory from a 32-bit address space, which is limited to
4G, is tricky.

The details: In 32-bit Linux you have a 4G address space.  The lower
3G of this is available for user mode.  The bottom contains program
text, data, and bss segments followed by the heap.  The heap, which is
what malloc traditionally uses, is a contiguous range of addresses
that goes up to a point that can be adjusted with the brk system
call. The brk can be adjusted to increase heap size as long as the
resulting range does not intersect any range that has been used for
memory mapping.

Shared libraries are loaded by memory mapping their data, text and bss
sections with mmap.  You can find out what is mapped where by looking
at /proc/<your process pid>/maps.  Every Linux program needs ld.so,
and that is always mapped to a range of addresses starting at
0x40000000.  [This is configurable when you build a custom kernel, and
it may now or soon be adjustable to some degree at boot or run time,
but this is the default.]  So the heap can grow at most to this point,
which means the contiguous heap is limited to a size of a little under
1G, no matter how much swap space or memory you have.

glibc malloc can either allocate only from the traditional contiguous
heap, which implies a 1G max on total allocation, or it can also
allocate using mmap, which allows it to use closer to the full 3G of
user mode address space.  The drawbacks of using mmap include a speed
penalty, at least by some measurements, and fragmentation of the
address space available for memory mapping large files.  Whether and
how glibc uses mmap is tunable by calling mallopt or by setting the
environment variables MALLOC_MMAP_THRESHOLD_ and MALLOC_MMAP_MAX_.
The default behavior seems to have changed between glibc 2.1 and 2.2,
and may have changed again with a patch to 2.2.  By default, 2.1 seems
to only use mmap for allocations of size above the mmap threshold
(which I think defaults to 128K), but glibc 2.2 will also use mmap for
smaller allocations if it can't get them from the standard heap.

So, because of the ld.so mapping, 1G is something of a critical
threshold.  In this particular example with the large .RData file, it
would appear that the malloc used was not using mmap when the
contiguous heap runs out.  The process that created the file was
probably quite close to the limit of 1G but did not exceed it, so it
did not fail.  Loading the file would push the required memory over
the limit, and so could not be done with the standard malloc settings
on this system.  Upgrading to a newer glibc changed the default
behavior and now the file can be loaded.  With the old libc it might
have been possible to get the file loaded by using environment
variable settings something like

    MALLOC_MMAP_THRESHOLD_=2000
    MALLOC_MMAP_MAX_=1000000

for the R process, though these may not be the safest choices and may
degrade performance.  But how much useful work one can do with this
high a portion of the address space in use is not entirely clear.

64-bit systems are starting to look real attractive.

A couple of references:

http://www.linuxshowcase.org/full_papers/ezolt/ezolt.pdf
http://mail.nl.linux.org/linux-mm/2000-07/msg00001.html
http://www.linux-mag.com/2001-06/compile_01.html
http://www.linux-mag.com/2001-07/compile_01.html
http://www.gnu.org/manual/glibc-2.2.3
http://sources.redhat.com/ml/libc-hacker/2000-07/msg00273.html
http://www.ussg.iu.edu/hypermail/linux/kernel/0101.1/0007.html

<R source root>/src/gnuwin32/malloc.c

luke


-- 
Luke Tierney
University of Minnesota                      Phone:           612-625-7843
School of Statistics                         Fax:             612-624-8868
313 Ford Hall, 224 Church St. S.E.           email:      luke at stat.umn.edu
Minneapolis, MN 55455 USA                    WWW:  http://www.stat.umn.edu
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Thu Apr 25 18:23:27 2002
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Thu, 25 Apr 2002 12:23:27 -0400
Subject: [R] sum() with na.rm=TRUE, again
In-Reply-To: <5B9B19C8A522D411A8EC00A0C99D6A9A8D2924@mail.nsabp.pitt.edu>; from richards@upci.pitt.edu on Thu, Apr 25, 2002 at 11:25:32AM -0400
References: <5B9B19C8A522D411A8EC00A0C99D6A9A8D2924@mail.nsabp.pitt.edu>
Message-ID: <20020425122327.A16667@cattell.psych.upenn.edu>

It is apparently a good convention to have the some of nothing be
zero.  But the mean of nothing involves dividing by infinity, so
the mean of c(NA,NA,NA) is NaN, which acts like NA for most
purposes.  So I think the trick is to compute the mean and then
multiply by the number of non-missing cases, e.g.,

apply(matrix1,1,mean,na.rm=T)*apply(!is.na(matrix1),1,sum)

but the all() method will work too.  Jon Baron


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From JBalint at alldata.net  Thu Apr 25 19:39:46 2002
From: JBalint at alldata.net (Balint, Jess)
Date: Thu, 25 Apr 2002 13:39:46 -0400
Subject: [R] Abilities of R
Message-ID: <CA8ED43817EFD211855E00805FE6FD7403AA1CF1@scadmail2.alldata.net>

Hello, I am new to this list and new to the R language. I am currently
evaluating the R language to see if it can be helpful. I currently use the
SAS language. In SAS, all my data sets are dealt with as files. This is
preferable as I tend to work with very large sets of data. I see that R can
read and write files of various formats, but can a data set be worked with
directly off the disk, not reading it into memory?

Thanks for your time.

-Jess Balint
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kjetilh at umsanet.edu.bo  Thu Apr 25 22:02:52 2002
From: kjetilh at umsanet.edu.bo (kjetil halvorsen)
Date: Thu, 25 Apr 2002 16:02:52 -0400
Subject: [R] Kendall's tau
References: <Pine.LNX.4.31.0204251037070.24762-100000@gannet.stats>
Message-ID: <3CC860EC.E1B5ADD@umsanet.edu.bo>



Brian Ripley wrote:

....
..
...
R would
> run slower and need more memory (and the latter has been an issue until
> recently, with 16Mb teaching labs). 

We will have 8MB teaching labs for a long time still.

Kjetil Halvorsen

> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andys at neptuneandco.com  Fri Apr 26 00:05:53 2002
From: andys at neptuneandco.com (Andrew Schuh)
Date: Thu, 25 Apr 2002 16:05:53 -0600
Subject: [R] Rdbi package and PgSQL
Message-ID: <3CC87DC1.8050601@neptuneandco.com>

I can use the Rdbi package to connect to a PostGreSQL server fine but 
when I use the dbDisconnect(), I get a segmentation error and it throws 
me out of R.  I'm using RH7.2, R1.4.1, Rdbi 0.1-2, and Rdbi.PgSQL 0.1-2.

Anyone else seen anything like this and have an possible answer?

Andrew Schuh


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From haun_jung at yahoo.com  Fri Apr 26 00:57:23 2002
From: haun_jung at yahoo.com (Haun Jung)
Date: Thu, 25 Apr 2002 15:57:23 -0700 (PDT)
Subject: [R] simple bar plot with confidence interval
Message-ID: <20020425225723.2914.qmail@web11904.mail.yahoo.com>

  Hi, I have the following numbers as a result of
  bootstrap:
  
  Bootstrap Statistics :
      original      bias    std. error
  t1* 0.2700797 0.02168322  0.05843803
  
  Intervals : 
  Level     Percentile     
  95%   ( 0.2048,  0.4256 )  
  
  Can somebodly please show me how to plot a bar with
  confidence interval? I've searched the archive, but
i'm a novice, so it didn't help much, and I need it
really urgently. I'd be immensely grateful. 


__________________________________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From haun_jung at yahoo.com  Fri Apr 26 02:02:03 2002
From: haun_jung at yahoo.com (Haun Jung)
Date: Thu, 25 Apr 2002 17:02:03 -0700 (PDT)
Subject: [R] Re: simple bar plot with confidence interval
Message-ID: <20020426000203.65865.qmail@web11907.mail.yahoo.com>

Hi again,

I camed up with the following script, which works
except it doesn't look very pretty. If someone can
suggest how to improve the graphics (e.g. adding a
horizontal bar, etc.), I'd appreciate it.

tbarHeight<-c(0.2700797, 0.7149945, 0.922099)
names(tbarHeight)<-c("A", "B", "C")
tbars<-barplot(height=tbarHeight,
axes=T,ylim=c(0,1.2))
tl<-c(0.4256, 0.8611, 0.9883) #lower whisks
tu<-c(0.2048, 0.5797, 0.7914) #upper whisks
segments(x0=tbars, x1=tbars, y0=tl, y1=tu)


--- Haun Jung <haun_jung at yahoo.com> wrote:
>   Hi, I have the following numbers as a result of
>   bootstrap:
>   
>   Bootstrap Statistics :
>       original      bias    std. error
>   t1* 0.2700797 0.02168322  0.05843803
>   
>   Intervals : 
>   Level     Percentile     
>   95%   ( 0.2048,  0.4256 )  
>   
>   Can somebodly please show me how to plot a bar
> with
>   confidence interval? I've searched the archive,
> but
> i'm a novice, so it didn't help much, and I need it
> really urgently. I'd be immensely grateful. 
> 
> 
> __________________________________________________
> Do You Yahoo!?

> http://games.yahoo.com/
> 


__________________________________________________



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From B.Mao at cerep.com  Fri Apr 26 02:50:26 2002
From: B.Mao at cerep.com (Boryeu Mao)
Date: Thu, 25 Apr 2002 17:50:26 -0700
Subject: [R] optimization of R on SGI/IRIX
Message-ID: <0957E70F25F7D111974B00A0C9833064AF88C3@mayo.cerep.com>

For R-1.4.0, I have been able to build R.bin with -O2 flag.  This however
did not yield any significant speed-up for my code.  I then tried building
the binary for 64 bit, but had not been able to configure the build; none of
the suggestions that I can find in the r-help search worked for me.  I'm
looking for any other suggestions -- TIA

mod:>> uname -a
IRIX64 mod 6.5 10100655 IP35
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Apr 26 08:29:23 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Fri, 26 Apr 2002 07:29:23 +0100 (BST)
Subject: [R] optimization of R on SGI/IRIX
In-Reply-To: <0957E70F25F7D111974B00A0C9833064AF88C3@mayo.cerep.com>
Message-ID: <Pine.GSO.4.44.0204260725040.7853-100000@auk.stats>

On Thu, 25 Apr 2002, Boryeu Mao wrote:

> For R-1.4.0, I have been able to build R.bin with -O2 flag.  This however
> did not yield any significant speed-up for my code.  I then tried building
> the binary for 64 bit, but had not been able to configure the build; none of
> the suggestions that I can find in the r-help search worked for me.  I'm
> looking for any other suggestions -- TIA
>
> mod:>> uname -a
> IRIX64 mod 6.5 10100655 IP35

R 1.4.1 (at least) has suggestions in the R-admin.texi manual for IRIX 6.5.
Given the imminence of R 1.5.0 we would suggest that you work with
the R-devel.tar.gz version in preparation for the release on Monday, and
definitely not with the version-before-last.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tring at gvdnet.dk  Fri Apr 26 09:39:08 2002
From: tring at gvdnet.dk (Troels Ring)
Date: Fri, 26 Apr 2002 09:39:08 +0200
Subject: [R] truncated observed
Message-ID: <5.1.0.14.0.20020426093205.02e1b910@mail.gvdnet.dk>


Dear friends.
I believe this problem has been discussed in various forms now and then, so 
I hope you will forgive me I ask how to do a truncated model like this, 
where the observed y is recorded as 10 whenever it is higher or equal to 
that value

x <- rnorm(1000)
y <- 10*x + rnorm(1000)
y[which(y>10)] <- 10
and recover the "true" model ?


Best wishes
Troels


Troels Ring, MD
Department of Nephrology
Aalborg Hospital, Denmark
tring at gvdnet.dk
fax 00 45 99 32 22 34
tlf 00 45 99 32 22 42
    00 45 98 14 05 82 (home)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20020426/a72d3ed5/attachment.html

From ripley at stats.ox.ac.uk  Fri Apr 26 10:51:57 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 26 Apr 2002 09:51:57 +0100 (BST)
Subject: [R] truncated observed
In-Reply-To: <5.1.0.14.0.20020426093205.02e1b910@mail.gvdnet.dk>
Message-ID: <Pine.LNX.4.31.0204260931000.6132-100000@gannet.stats>

On Fri, 26 Apr 2002, Troels Ring wrote:

>
> Dear friends.
> I believe this problem has been discussed in various forms now and then, so
> I hope you will forgive me I ask how to do a truncated model like this,
> where the observed y is recorded as 10 whenever it is higher or equal to
> that value
>
> x <- rnorm(1000)
> y <- 10*x + rnorm(1000)
> y[which(y>10)] <- 10
> and recover the "true" model ?

That's more commonly known as censored not truncated.  (In a truncated
model the observations larger than 10 are lost.)

In your specific case I believe you can fit the model by survreg in
package survival.  Something like

survreg(Surv(y, y < 10) ~ x, dist="gaussian")

In general you need to write a likelihood function and optimize it, e.g.
with optim, or make use of the ability to add your own distributions to
survreg.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From trevilla at strix.ciens.ucv.ve  Fri Apr 26 13:45:33 2002
From: trevilla at strix.ciens.ucv.ve (=?windows-1252?Q?Tom=E1s=20Revilla?=)
Date: Fri, 26 Apr 2002 07:45:33 -0400
Subject: [R] spreadsheet data import
Message-ID: <IG974Z4ZKJNJPKHJFNM1YUTQ64AEA.3cc93ddd@atlas>

Hi colleages!

I want to import data from ms-excel and other spreadsheet formats (lotus, etc). Does exist any way to do it within 
R? The main problem is that many spreadsheet data use comma as decimal separator and not the point as needed in R 
(and many software for Linux), so importing data first as a tab separated values does not solve this problem.

Thanks,

	Tom?s Revilla



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Fri Apr 26 13:54:54 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 26 Apr 2002 13:54:54 +0200
Subject: [R] spreadsheet data import
In-Reply-To: <IG974Z4ZKJNJPKHJFNM1YUTQ64AEA.3cc93ddd@atlas>
References: <IG974Z4ZKJNJPKHJFNM1YUTQ64AEA.3cc93ddd@atlas>
Message-ID: <x2y9fa1xpt.fsf@blueberry.kubism.ku.dk>

Tom?s Revilla <trevilla at strix.ciens.ucv.ve> writes:

> Hi colleages!
> 
> I want to import data from ms-excel and other spreadsheet formats (lotus, etc). Does exist any way to do it within 
> R? The main problem is that many spreadsheet data use comma as decimal separator and not the point as needed in R 
> (and many software for Linux), so importing data first as a tab separated values does not solve this problem.

Oh yes it does. Notice the "dec" argument and read.delim2().

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Apr 26 13:57:18 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 26 Apr 2002 12:57:18 +0100 (BST)
Subject: [R] spreadsheet data import
In-Reply-To: <IG974Z4ZKJNJPKHJFNM1YUTQ64AEA.3cc93ddd@atlas>
Message-ID: <Pine.LNX.4.31.0204261249090.7131-100000@gannet.stats>

On Fri, 26 Apr 2002, [windows-1252] Toms Revilla wrote:

> Hi colleages!
>
> I want to import data from ms-excel and other spreadsheet formats
(lotus, etc). Does exist any way to do it within
> R?

There exist several ways, and R has a manual `R Data Import/Export' to
explain them to you.  Since you haven't even told us what OS you are
using, it is hard to be more specific.  On Windows (and you mailed in a
Windows character set), RODBC can read directly from the spreadsheet.

> The main problem is that many spreadsheet data use comma as decimal
separator and not the point as needed in R
> (and many software for Linux), so importing data first as a tab separated
values does not solve this problem.

That's not correct.  Look at the manual, and functions read.delim2 and
read.csv2.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Fri Apr 26 14:01:02 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 26 Apr 2002 14:01:02 +0200
Subject: [R] spreadsheet data import
References: <IG974Z4ZKJNJPKHJFNM1YUTQ64AEA.3cc93ddd@atlas>
Message-ID: <3CC9417E.13F11F45@statistik.uni-dortmund.de>

Tom?s Revilla wrote:
> 
> Hi colleages!
> 
> I want to import data from ms-excel and other spreadsheet formats (lotus, etc). Does exist any way to do it within
> R? The main problem is that many spreadsheet data use comma as decimal separator and not the point as needed in R
> (and many software for Linux), so importing data first as a tab separated values does not solve this problem.

What about 
 read.table(..., dec=",")
as mentioned in ?read.table ?

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From luke at stat.umn.edu  Fri Apr 26 14:10:53 2002
From: luke at stat.umn.edu (Luke Tierney)
Date: Fri, 26 Apr 2002 07:10:53 -0500
Subject: [R] optimization of R on SGI/IRIX
In-Reply-To: <Pine.GSO.4.44.0204260725040.7853-100000@auk.stats>; from ripley@stats.ox.ac.uk on Fri, Apr 26, 2002 at 07:29:23AM +0100
References: <0957E70F25F7D111974B00A0C9833064AF88C3@mayo.cerep.com> <Pine.GSO.4.44.0204260725040.7853-100000@auk.stats>
Message-ID: <20020426071053.A2379@nokomis.stat.umn.edu>

On Fri, Apr 26, 2002 at 07:29:23AM +0100, Prof Brian D Ripley wrote:
> On Thu, 25 Apr 2002, Boryeu Mao wrote:
> 
> > For R-1.4.0, I have been able to build R.bin with -O2 flag.  This however
> > did not yield any significant speed-up for my code.  I then tried building
> > the binary for 64 bit, but had not been able to configure the build; none of
> > the suggestions that I can find in the r-help search worked for me.  I'm
> > looking for any other suggestions -- TIA
> >
> > mod:>> uname -a
> > IRIX64 mod 6.5 10100655 IP35
> 
> R 1.4.1 (at least) has suggestions in the R-admin.texi manual for IRIX 6.5.
> Given the imminence of R 1.5.0 we would suggest that you work with
> the R-devel.tar.gz version in preparation for the release on Monday, and
> definitely not with the version-before-last.
> 

For R 1.5.0 I built a 64-bit version on IRIX using IRIX compilers by
configuring with

	./configure CC="cc -64" F77="f77 -64" --with-tcltk=no

which is also given in R-admin.texi.  (You need a slightly different
command for 1.4.x but that is also given in the R-admin.texi for that
release.)  For me this produces

  C compiler:                cc -64  -OPT:IEEE_NaN_inf=ON -g
  C++ compiler:              g++  -g -O2
  FORTRAN compiler:          f77 -64  -OPT:IEEE_NaN_inf=ON -g

and builds and passes make check.  It is about 10% slower than the 32
bit version at running the base checks.  If you want optimization you
will need to tell configure to use the appropriate CFLAGS and FFLAGS

luke

-- 
Luke Tierney
University of Minnesota                      Phone:           612-625-7843
School of Statistics                         Fax:             612-624-8868
313 Ford Hall, 224 Church St. S.E.           email:      luke at stat.umn.edu
Minneapolis, MN 55455 USA                    WWW:  http://www.stat.umn.edu
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Fri Apr 26 14:14:00 2002
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Fri, 26 Apr 2002 08:14:00 -0400
Subject: [R] spreadsheet data import
In-Reply-To: <IG974Z4ZKJNJPKHJFNM1YUTQ64AEA.3cc93ddd@atlas>; from trevilla@strix.ciens.ucv.ve on Fri, Apr 26, 2002 at 07:45:33AM -0400
References: <IG974Z4ZKJNJPKHJFNM1YUTQ64AEA.3cc93ddd@atlas>
Message-ID: <20020426081400.A27652@cattell.psych.upenn.edu>

On 04/26/02 07:45, Tom?s Revilla wrote:
>Hi colleages!
>
>I want to import data from ms-excel and other spreadsheet formats (lotus, etc). Does exist any way to do it within 
>R? The main problem is that many spreadsheet data use comma as decimal separator and not the point as needed in R 
>(and many software for Linux), so importing data first as a tab separated values does not solve this problem.

See the help for read.table().  There are several different
versions of that for different kinds of delimiters and an option
"dec" to specify the kind of decimal point.

In general, the help files are very useful.

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tklistaddr at keittlab.bio.sunysb.edu  Fri Apr 26 15:32:46 2002
From: tklistaddr at keittlab.bio.sunysb.edu (Timothy H. Keitt)
Date: 26 Apr 2002 09:32:46 -0400
Subject: [R] Rdbi package and PgSQL
In-Reply-To: <3CC87DC1.8050601@neptuneandco.com>
References: <3CC87DC1.8050601@neptuneandco.com>
Message-ID: <1019827966.25455.7.camel@keittlab-6>

I've not seen this behavior. Try "R -d gdb" and then type "run" at the
gdb prompt. Run your R session until the seg fault and send me the
backtrace. Thanks.

Tim

On Thu, 2002-04-25 at 18:05, Andrew Schuh wrote:
> I can use the Rdbi package to connect to a PostGreSQL server fine but 
> when I use the dbDisconnect(), I get a segmentation error and it throws 
> me out of R.  I'm using RH7.2, R1.4.1, Rdbi 0.1-2, and Rdbi.PgSQL 0.1-2.
> 
> Anyone else seen anything like this and have an possible answer?
> 
> Andrew Schuh
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From garbade at psy.uni-muenchen.de  Fri Apr 26 17:38:54 2002
From: garbade at psy.uni-muenchen.de (Sven Garbade)
Date: Fri, 26 Apr 2002 15:38:54 +0000
Subject: [R] spreadsheet data import
References: <IG974Z4ZKJNJPKHJFNM1YUTQ64AEA.3cc93ddd@atlas>
Message-ID: <3CC9748E.9AED0CCC@psy.uni-muenchen.de>

Tom?s Revilla wrote:

> Hi colleages!
>
> I want to import data from ms-excel and other spreadsheet formats (lotus, etc). Does exist any way to do it within
> R? The main problem is that many spreadsheet data use comma as decimal separator and not the point as needed in R
> (and many software for Linux), so importing data first as a tab separated values does not solve this problem.
>
> Thanks,
>
>         Tom?s Revilla
>

Hi,

you can substitute the comma with a point in almost any editor (I think Notepad cannot...)  or use sed/Perl/awk etc
or R (R can read the data as character vectors and then use gsub to find the commas and replace them, transform the
data to a matrix or data frame).

Hope this helps,
Sven

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From xiaon at mail.nih.gov  Fri Apr 26 15:39:29 2002
From: xiaon at mail.nih.gov (Xiao, Nianqing (NCI))
Date: Fri, 26 Apr 2002 09:39:29 -0400
Subject: [R]Spearman Correlation
Message-ID: <9D7EF737FA4C6F4FBBFC52FC30B83690B70C40@nihexchange7.nih.gov>

Hi all, 

Is there a convenient way to calculate Spearman correlation coefficients in
R? 

Nick

Nianqing Xiao, Ph.D
NCI Center for Bioinformatics, NIH
SAIC/Advanced Systems Group
> 6116 EXECUTIVE BLVD 4026J 
> MSC 8335
> BETHESDA MD 20852
Phone: 301-451-6357
Fax: 301-480-4222

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From cjf at fonnesbeck.net  Fri Apr 26 15:42:27 2002
From: cjf at fonnesbeck.net (Christopher Fonnesbeck)
Date: 26 Apr 2002 09:42:27 -0400
Subject: [R] quadratic discriminant analysis?
Message-ID: <1019828547.19726.1.camel@volterra>

Can one perform a QDA in R? I do not see it anywhere within the mda
package.  Any pointers here would be appreciated.

Thanks,
cjf
-- 
~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*

Christopher J. Fonnesbeck 
Ph.D. Student

Georgia Cooperative Wildlife Unit
University of Georgia 
Athens, GA 30602

Email: cjf at fonnesbeck.net
Yahoo: fonnesbeck_chris

~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From flom at ndri.org  Fri Apr 26 15:59:09 2002
From: flom at ndri.org (Peter Flom)
Date: Fri, 26 Apr 2002 09:59:09 -0400
Subject: [R] SAS and R
Message-ID: <scc92509.077@NDRI2.NDRI.ORG>

Hello

I am sure this is elementary, but I can't figure it out.....

I am using SAS v8.2 and R 1.4.1 on a Windows platform.

I have a large (6 megabyte) file in .sd2 format.  I want to import it into R.
If necessary, I can create a smaller file, as I don't need all the variables that are in this file

I downloaded the package foreign.   I then tried to use PROC CPORT in SAS to create a transport file.  It gave no error message, but I cannot find the file it wrote.  I also tried the SAS Export Wizard, but this didn't work.

What's the best way to do this?  

More specifically

1) How do I import any .sd2 file to R ?
2) Is it better to create and import small files as needed, or one huge file which would contain all the data?
3) Any other tips on how to do this?


Thanks in advance



Peter L. Flom, PhD
Assistant Director, Statistics and Data Analysis Core
Center for Drug Use and HIV Research
National Development and Research Institutes
71 W. 23rd St
New York, NY 10010
(212) 845-4485 (voice)
(917) 438-0894 (fax)


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Fri Apr 26 15:59:41 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 26 Apr 2002 15:59:41 +0200
Subject: [R]Spearman Correlation
In-Reply-To: <9D7EF737FA4C6F4FBBFC52FC30B83690B70C40@nihexchange7.nih.gov>
References: <9D7EF737FA4C6F4FBBFC52FC30B83690B70C40@nihexchange7.nih.gov>
Message-ID: <x2it6ezhki.fsf@blueberry.kubism.ku.dk>

"Xiao, Nianqing (NCI)" <xiaon at mail.nih.gov> writes:

> Hi all, 
> 
> Is there a convenient way to calculate Spearman correlation coefficients in
> R? 
> 

cor.test(...., method="spearman")

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Fri Apr 26 16:02:44 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 26 Apr 2002 16:02:44 +0200
Subject: [R] quadratic discriminant analysis?
References: <1019828547.19726.1.camel@volterra>
Message-ID: <3CC95E04.AE1B7D96@statistik.uni-dortmund.de>



Christopher Fonnesbeck wrote:
> 
> Can one perform a QDA in R? I do not see it anywhere within the mda
> package.  Any pointers here would be appreciated.

A function for quadratic discriminant analysis is in package MASS (in
the VR bundle).

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From xiaon at mail.nih.gov  Fri Apr 26 16:18:46 2002
From: xiaon at mail.nih.gov (Xiao, Nianqing (NCI))
Date: Fri, 26 Apr 2002 10:18:46 -0400
Subject: [R]Spearman Correlation
Message-ID: <9D7EF737FA4C6F4FBBFC52FC30B83690B70C41@nihexchange7.nih.gov>

Thanks. 

I should have restated my question more clear. What I am looking for is a
method to calculate Pearson R for a large matrix, and handle the NA value
(with dif options) in the meantime, like what cor() does on a matrix for
Pearson correlation. I know I can write my own function with rank() and
cor(). I just want to find out if other people have already made the
available. 

Nick

-----Original Message-----
From: Peter Dalgaard BSA [mailto:p.dalgaard at biostat.ku.dk]
Sent: Friday, April 26, 2002 10:00 AM
To: Xiao, Nianqing (NCI)
Cc: 'r-help at stat.math.ethz.ch'
Subject: Re: [R]Spearman Correlation


"Xiao, Nianqing (NCI)" <xiaon at mail.nih.gov> writes:

> Hi all, 
> 
> Is there a convenient way to calculate Spearman correlation coefficients
in
> R? 
> 

cor.test(...., method="spearman")

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Apr 26 16:21:17 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 26 Apr 2002 15:21:17 +0100 (BST)
Subject: [R] quadratic discriminant analysis?
In-Reply-To: <1019828547.19726.1.camel@volterra>
Message-ID: <Pine.LNX.4.31.0204261520430.8549-100000@gannet.stats>

On 26 Apr 2002, Christopher Fonnesbeck wrote:

> Can one perform a QDA in R? I do not see it anywhere within the mda
> package.  Any pointers here would be appreciated.

It's in the recommended package MASS.  Why would you think it would be in
mda?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fharrell at virginia.edu  Fri Apr 26 16:18:42 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri, 26 Apr 2002 10:18:42 -0400
Subject: [R] SAS and R
In-Reply-To: <scc92509.077@NDRI2.NDRI.ORG>
References: <scc92509.077@NDRI2.NDRI.ORG>
Message-ID: <20020426101842.662c53cc.fharrell@virginia.edu>

Try the sas.get function in the Hmisc library.  Hmisc is available for Linux/Unix/MacOSX and will soon be updated for Windows.
http://hesweb1.med.virginia.edu/biostat/s/Hmisc.html

Frank Harrell

On Fri, 26 Apr 2002 09:59:09 -0400
Peter Flom <flom at ndri.org> wrote:

> Hello
> 
> I am sure this is elementary, but I can't figure it out.....
> 
> I am using SAS v8.2 and R 1.4.1 on a Windows platform.
> 
> I have a large (6 megabyte) file in .sd2 format.  I want to import it into R.
> If necessary, I can create a smaller file, as I don't need all the variables that are in this file
> 
> I downloaded the package foreign.   I then tried to use PROC CPORT in SAS to create a transport file.  It gave no error message, but I cannot find the file it wrote.  I also tried the SAS Export Wizard, but this didn't work.
> 
> What's the best way to do this?  
> 
> More specifically
> 
> 1) How do I import any .sd2 file to R ?
> 2) Is it better to create and import small files as needed, or one huge file which would contain all the data?
> 3) Any other tips on how to do this?
> 
> 
> Thanks in advance
> 
> 
> 
> Peter L. Flom, PhD
> Assistant Director, Statistics and Data Analysis Core
> Center for Drug Use and HIV Research
> National Development and Research Institutes
> 71 W. 23rd St
> New York, NY 10010
> (212) 845-4485 (voice)
> (917) 438-0894 (fax)
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Fri Apr 26 16:34:12 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 26 Apr 2002 16:34:12 +0200
Subject: [R] SAS and R
In-Reply-To: <scc92509.077@NDRI2.NDRI.ORG>
References: <scc92509.077@NDRI2.NDRI.ORG>
Message-ID: <x2662ezfyz.fsf@blueberry.kubism.ku.dk>

"Peter Flom" <flom at ndri.org> writes:

> Hello
> 
> I am sure this is elementary, but I can't figure it out.....
> 
> I am using SAS v8.2 and R 1.4.1 on a Windows platform.
> 
> I have a large (6 megabyte) file in .sd2 format.  I want to import it into R.
> If necessary, I can create a smaller file, as I don't need all the variables that are in this file
> 
> I downloaded the package foreign.   I then tried to use PROC CPORT in SAS to create a transport file.  It gave no error message, but I cannot find the file it wrote.  I also tried the SAS Export Wizard, but this didn't work.
> 
> What's the best way to do this?  
> 
> More specifically
> 
> 1) How do I import any .sd2 file to R ?

You don't. Not even SAS itself can do that, except on the same platform.

PROC CPORT is the wrong way. The template for creating files that
read.xport will accept is something like this:

libname peter xport "dataset.xpt";
DATA peter.foo;
  SET sasuser.bar;
run;

You may want to change "dataset.xpt" to something with a full path so
you can find it again (putting files in seemingly arbitrary locations
is a common feature of so-called user-friendly software...).

> 2) Is it better to create and import small files as needed, or one huge file which would contain all the data?

There are pros and cons. Small files put less strain on a small
system, but you need to be more careful in keeping them all up to date
if the database changes.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ggrothendieck at yifan.net  Fri Apr 26 16:46:35 2002
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Fri, 26 Apr 2002 10:46:35 -0400
Subject: [R] spreadsheet data import
In-Reply-To: <IG974Z4ZKJNJPKHJFNM1YUTQ64AEA.3cc93ddd@atlas>
Message-ID: <3CC9300B.18532.673916E@localhost>

Check out the dec= parameter of the scan command.

On 26 Apr 2002 at 7:45, Tom?s Revilla wrote:
> I want to import data from ms-excel and other spreadsheet formats (lotus, etc). Does exist any way to do it within 
> R? The main problem is that many spreadsheet data use comma as decimal separator and not the point as needed in R 
> (and many software for Linux), so importing data first as a tab separated values does not solve this problem.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Fri Apr 26 17:16:00 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 26 Apr 2002 08:16:00 -0700 (PDT)
Subject: [R] truncated observed
In-Reply-To: <Pine.LNX.4.31.0204260931000.6132-100000@gannet.stats>
Message-ID: <Pine.A41.4.44.0204260814140.40456-100000@homer11.u.washington.edu>

On Fri, 26 Apr 2002 ripley at stats.ox.ac.uk wrote:

> In your specific case I believe you can fit the model by survreg in
> package survival.  Something like
>
> survreg(Surv(y, y < 10) ~ x, dist="gaussian")
>
> In general you need to write a likelihood function and optimize it, e.g.
> with optim, or make use of the ability to add your own distributions to
> survreg.

The ability to add your own distributions to survreg() doesn't actually
work. It will work with the new version of "survival" coming out with
R1.5.0 and as it is now tested in an example it should keep working in the
future.

	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From HStevens at muohio.edu  Fri Apr 26 17:17:23 2002
From: HStevens at muohio.edu (Martin Henry H. Stevens)
Date: Fri, 26 Apr 2002 11:17:23 -0400
Subject: [R] Re: simple bar plot with confidence interval
In-Reply-To: <20020426000203.65865.qmail@web11907.mail.yahoo.com>
Message-ID: <5.1.0.14.2.20020426111513.02ab66e8@po.muohio.edu>

Haun -
Looks pretty pretty to me! You might look at arrows instead of segements 
and make the arrow heads 90 degrees. You should also check the mail 
archives regarding this frequently requested info - try plotCI() by Ben 
Bolker in archives.

At 08:02 PM 4/25/2002, you wrote:
>Hi again,
>
>I camed up with the following script, which works
>except it doesn't look very pretty. If someone can
>suggest how to improve the graphics (e.g. adding a
>horizontal bar, etc.), I'd appreciate it.
>
>tbarHeight<-c(0.2700797, 0.7149945, 0.922099)
>names(tbarHeight)<-c("A", "B", "C")
>tbars<-barplot(height=tbarHeight,
>axes=T,ylim=c(0,1.2))
>tl<-c(0.4256, 0.8611, 0.9883) #lower whisks
>tu<-c(0.2048, 0.5797, 0.7914) #upper whisks
>segments(x0=tbars, x1=tbars, y0=tl, y1=tu)
>
>
>--- Haun Jung <haun_jung at yahoo.com> wrote:
> >   Hi, I have the following numbers as a result of
> >   bootstrap:
> >
> >   Bootstrap Statistics :
> >       original      bias    std. error
> >   t1* 0.2700797 0.02168322  0.05843803
> >
> >   Intervals :
> >   Level     Percentile
> >   95%   ( 0.2048,  0.4256 )
> >
> >   Can somebodly please show me how to plot a bar
> > with
> >   confidence interval? I've searched the archive,
> > but
> > i'm a novice, so it didn't help much, and I need it
> > really urgently. I'd be immensely grateful.
> >
> >
> > __________________________________________________
> > Do You Yahoo!?
>
> > http://games.yahoo.com/
> >
>
>
>__________________________________________________
>
>
>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._ 
>

Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Tel: (513) 529-4206
FAX: (513) 529-4243
http://www.muohio.edu/~botcwis/bot/henry.html

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Fri Apr 26 17:21:10 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 26 Apr 2002 08:21:10 -0700 (PDT)
Subject: [R] SAS and R
In-Reply-To: <20020426101842.662c53cc.fharrell@virginia.edu>
Message-ID: <Pine.A41.4.44.0204260818540.40456-100000@homer11.u.washington.edu>

On Fri, 26 Apr 2002, Frank E Harrell Jr wrote:

> Try the sas.get function in the Hmisc library.  Hmisc is available for
> Linux/Unix/MacOSX and will soon be updated for Windows.
> http://hesweb1.med.virginia.edu/biostat/s/Hmisc.html

Similar functionality is available in the most recent version of the
"foreign" package as well, with read.ssd()

	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From s-luppescu at uchicago.edu  Fri Apr 26 17:28:00 2002
From: s-luppescu at uchicago.edu (Stuart Luppescu)
Date: 26 Apr 2002 10:28:00 -0500
Subject: [R] [OT] Inverting sparse matrices
Message-ID: <1019834880.27877.7.camel@musuko.uchicago.edu>

Sorry for the way off-topic post, but this list has the highest
concentration of statistical computing gurus anywhere.

I'm looking for a C routine for efficiently inverting large, sparse
matrices (at least 6000 x 6000 and potentially as large as 20,000 x
20,000 with perhaps 80% of the off-diagonal elements empty). 

I looked in 
http://gams.nist.gov/serve.cgi/Class/D2a4/
but I have no way of evaluating which of the routines on this page would
be fastest, most efficient and most accurate. Can anyone give me some
guidance?

Thanks very much.
-- 
Stuart Luppescu -=- s-luppescu at uchicago.edu        
University of Chicago -=- CCSR 
$B:MJ8$HCRF`H~$NIc(B -=-    Kernel 2.4.18-xfs                
You have the power to influence all with whom you
 come in contact. 
 

-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 240 bytes
Desc: This is a digitally signed message part
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20020426/d8fcd45e/attachment.bin

From fharrell at virginia.edu  Fri Apr 26 18:13:03 2002
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri, 26 Apr 2002 12:13:03 -0400
Subject: [R] SAS and R
In-Reply-To: <Pine.A41.4.44.0204260818540.40456-100000@homer11.u.washington.edu>
References: <20020426101842.662c53cc.fharrell@virginia.edu>
	<Pine.A41.4.44.0204260818540.40456-100000@homer11.u.washington.edu>
Message-ID: <20020426121303.0af13962.fharrell@virginia.edu>

It may be worth pointing out that the new read.ssd has to launch SAS to convert to xport format.  The sas.get philosophy is that if you are going to have to do that you might as well ask the sas session to dump the data to ASCII files, with optional restriction to a subset of the variables.   That way you can fetch all the SAS attributes such as variable labels, data/time info, etc.  -Frank

On Fri, 26 Apr 2002 08:21:10 -0700 (PDT)
Thomas Lumley <tlumley at u.washington.edu> wrote:

> On Fri, 26 Apr 2002, Frank E Harrell Jr wrote:
> 
> > Try the sas.get function in the Hmisc library.  Hmisc is available for
> > Linux/Unix/MacOSX and will soon be updated for Windows.
> > http://hesweb1.med.virginia.edu/biostat/s/Hmisc.html
> 
> Similar functionality is available in the most recent version of the
> "foreign" package as well, with read.ssd()
> 
> 	-thomas
> 
> Thomas Lumley			Asst. Professor, Biostatistics
> tlumley at u.washington.edu	University of Washington, Seattle
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Han-Lin.Lai at noaa.gov  Fri Apr 26 18:18:26 2002
From: Han-Lin.Lai at noaa.gov (Han-Lin Lai)
Date: Fri, 26 Apr 2002 09:18:26 -0700
Subject: [Fwd: Re: [R] degrees of freedom for t-tests in lme]
Message-ID: <3CC97DD2.3C795F87@noaa.gov>

Sorry, by mistake I sent this to Professor Bates instead of r-help.
Han

-------- Original Message --------
Subject: Re: [R] degrees of freedom for t-tests in lme
Date: Thu, 25 Apr 2002 09:16:16 -0700
From: Han-Lin Lai <Han-Lin.Lai at noaa.gov>
To: Douglas Bates <bates at stat.wisc.edu>
References: <3CC6E87F.5400277D at noaa.gov>
<6rg01lottu.fsf at franz.stat.wisc.edu>

Thank you very much for the answer.  I find that there is couple typo in
my
data.  Now I get the correct results from fitting the model:
 lme(y~x+log(den)+sex+dep,data=lwd,random= list(group=~x))

                    numDF denDF      F-value         p-value
(Intercept)             1  3209     17660.85      <.0001
          x                 1  3209       6411.56      <.0001
        sex                1  3209          12.07      0.0005
        dep               3    22            25.10      <.0001

Fixed effects: y ~ x + sex + dep
                            Value        Std.Error        DF   t-value
p-value
(Intercept)     -11.24380     0.1725474     3209 -65.16353  <.0001
              x        3.05784      0.0382305     3209  79.98440  <.0001
            sex       0.01958     0.0057823      3209   3.38548  0.0007
     depD27       0.01382     0.0593448          22   0.23293  0.8180
     depD35      -0.06537     0.0550606         22  -1.18723  0.2478
     depD50      -0.28581     0.0557979         22  -5.12220  <.0001

However, my real questions is:  How DF = 3209 and 22 are calculated?  I
follow
the book by Pinheiro and Bates (2000, p.91),
Q = 1
mo=1 because I have intercept in model
m1=26 groups
m2=3237 observations
p0=1
p1=3, (I have 4 levels of dep's, therefore, it is 4-1. Isn't it?)
p2=??

Then, DF for dep is 26-(1+3)=22.  Following this way, p2 = 2 so the DF
for
intercept, x, and sex is 3237-(26+2)=3209.  How is p2 determined?

Thanks for the help.
Han

Douglas Bates wrote:

> Han-Lin Lai <Han-Lin.Lai at noaa.gov> writes:
>
> > I have trouble to figure out how the df is derived in LME.  Here is my
> > model,
> >
> >    lme(y~x+log(den)+sex+dep,data=lwd,random= list(group=~x))
> >
> > Number of total samples (N) is 3237
> > number of groups (J) is 26
> > number of level-1 variables (Q1) is 3, i.e., x, log(den) and sex
> > number of level-2 variables (Q2) is 1, i.e., dep
> > x and den are continuous variable
> > sex is associated with individual samples and has 2 levels
> > dep is associated with group has 4 levels: depD15, depD27, and depD35,
> > and depD35.
> >
> > I got the results:
> >
> > Fixed effects: y ~ x + log(den) + sex + dep
> >                          Value       Std.Error   DF   t-value p-value
> > (Intercept) -11.29271     0.1681915 3206 -67.14200  <.0001
> >               x     3.05937     0.0367970 3206  83.14182  <.0001
> >    log(den)     0.00898     0.0022357 3206   4.01732  0.0001
> >            sex     0.01980     0.0057675 3206   3.43216  0.0006
> >     depD27   -0.01505     0.0560142 3206  -0.26872  0.7882
> >     depD35   -0.06102     0.0548647 3206  -1.11227  0.2661
> >     depD50   -0.29123     0.0567132     24  -5.13511  <.0001
> >
> > Are these coefficients are the level-2, and thus, DF for testing dep's
> > should be (J-Q2_1=26-1-1=24).  Why I get the number 3206, especially for
> > depD27 depD35 and depD50.
> >
> > Thanks
> > Han
> > Han-Lin.Lai at noaa.gov
>
> By saying that dep is a level-2 variable do you mean that it does not
> change within groups?  Have you checked that, say by
>
> gsummary(mydata, form = ~ group, invariants = TRUE)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mikalzet at libero.it  Fri Apr 26 18:25:52 2002
From: mikalzet at libero.it (mikalzet@libero.it)
Date: Fri, 26 Apr 2002 18:25:52 +0200 (CEST)
Subject: [R] Re: [Rd] Can't install packages (PR#1486)
In-Reply-To: <200204261519.RAA00213@pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.33L2.0204261810360.1884-100000@localhost.localdomain>

On Fri, 26 Apr 2002 poizot at cnam.fr wrote:

> Hello,
>
> I install R under Mandrake Linux 8.2.
> R itself work fine, but I had an error to install packages, i.e. fields, geoR
> and geoRglm :
>
> $: R CMD INSTALL geoRglm_0.4-3.tar.gz
> Installing *source* package `geoRglm' ...
>  libs
> gcc-3.0.1 -I/usr/lib/R/include  -I/usr/local/include -mieee-fp
> -D__NO_MATH_INLINES  -fPIC  -O3 -fomit-frame-pointer -pipe -mcpu=pentiumpro
> -march=i586 -fno-fast-math -fno-strength-reduce -c geoRgeoRglm.c -o
> geoRgeoRglm.o
> make: gcc-3.0.1 : Commande introuvable
> make: *** [geoRgeoRglm.o] Erreur 127
> ERROR: compilation failed for package `geoRglm

You are using the RPM package compiled for Mandrake 8.1, which does have
gcc-3.0.1. You need a Mandrake 8.2 package.

Mandrake 8.2 distribution includes an RPM package for R 1.4.1 which for
some strange reason is not distributed on the CD's but is downloadable
from the mandrake 8.2 mirror sites.
Unfortunately, as I have already signalled to the packager
(ghibo at mandrakesoft.com), there seem to be a couple of small bugs in this
package; specifically on uninstalling it the preun script produces an
error message. I would therefore not trust it.

You can do one of various things:

1) Download the SRPM from CRAN and recompile the RPM for your system.
That's what the SRPM is there for. The readme file explains what you need
to do.

2) Wait a few days. When R 1.5.0 comes out I mean to produce RPM's for
Mandrake 8.1 and 8.2 before erasing 8.1 from my HD and going over to 8.2
completely.

3) I think this dirty hack would work quite well: just make a symlink

ln -s /usr/bin/gcc-3.0.3 /usr/bin/gcc-3.0.1

Mandrake 8.2 has gcc-3.0.3.

-- 
Michele Alzetta

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hammour at msn.com  Fri Apr 26 20:37:03 2002
From: hammour at msn.com (Ahmad Abu Hammour)
Date: Fri, 26 Apr 2002 14:37:03 -0400
Subject: [R] optim or nlm with matrices
Message-ID: <OE140lMFAVNL9pdRpVV0001a134@hotmail.com>

Hi,
I have the following hypothetical optimization problem:
-det(t(x-A%*%x1)%*%(x-A%*%x1))
where A,x,x1 are matrices. A coefficients and x and x1 are variable matrices or vectors.
I tried to apply optim and nlm functions but I kept receive the following massage:
Error in A%*%x1 : non-conformable arguments.
The massage appears even the -det() can be calculated and the dimensions are checked.
here is my example although there might be no solution for the optimization problem.
A=A
myfn=function(A){
x=matrix(c(1.8,0),byrow=T)
x1=matrix(c(.8,1.8),byrow=T)
-det((t(x)-t(x1)%*%A)%*%(x-A%*%x1))
}
A=matrix(c(1,.3,2,-1.2),byrow=T,nrow=2)
optim(A,myfn)
Another question regarding optimization:
is there any chance that I can find a function or package that can do a constrained optimization such as: -det(x-A*x1-B*x2)' (x-A*x1-B*x2))  
subject to  
p-f(A,B,...)=0, where f denotes a function.
Thank you for your help in advance.
Ahmad Abu Hammour
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20020426/3776f60f/attachment.html

From macq at llnl.gov  Fri Apr 26 20:51:16 2002
From: macq at llnl.gov (Don MacQueen)
Date: Fri, 26 Apr 2002 11:51:16 -0700
Subject: [R] Problem with read.xport() from foreign package
Message-ID: <p05111706b8ef4fd871bc@[128.115.153.6]>

I have found that data imported from SAS using read.xport() in 
package foreign (installed recently) does not match the original 
data, when the data consists of character strings that are only one 
character long.

Here is an example.

---- SAS commands to create the data ----
options nocenter;
data foo;
     a='a';
     b='bb';
     length c d $2;
     c='c';
     d=' d';
     x=3.1;
     output;
run;
proc print data=foo;
run;

libname xpt xport 'xpt.foo';
proc copy in=work out=xpt memtype=data;
   select foo;
run;

proc contents data=foo;
run;


---------- output from proc print -------
OBS    A    B     C    D     X

  1     a    bb    c    d    3.1


--------- in R -------------
>  foo <- read.xport('xpt.foo')
>
>  foo
   A  B C  D   X
1   bb    d 3.1


note that neither foo$A nor foo$C has any data.

--------- version information ---------
NOTE: SAS (r) Proprietary Software Release 6.12  TS020

>  version
          _
platform sparc-sun-solaris2.7
arch     sparc
os       solaris2.7
system   sparc, solaris2.7
status
major    1
minor    4.1
year     2002
month    01
day      30
language R


>  tmp <- installed.packages()
>  tmp[tmp[,1]=='foreign',,drop=FALSE]
      Package   LibPath                                       Version 
Priority      Bundle Depends
[1,] "foreign" "/erd/statistic/apps/R/R-1.4.1/lib/R/library" "0.4-9"

-Don
-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
--------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Fri Apr 26 21:02:43 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 26 Apr 2002 21:02:43 +0200
Subject: [R] Problem with read.xport() from foreign package
In-Reply-To: <p05111706b8ef4fd871bc@[128.115.153.6]>
References: <p05111706b8ef4fd871bc@[128.115.153.6]>
Message-ID: <x2pu0m8er0.fsf@blueberry.kubism.ku.dk>

Don MacQueen <macq at llnl.gov> writes:

> I have found that data imported from SAS using read.xport() in package
> foreign (installed recently) does not match the original data, when
> the data consists of character strings that are only one character
> long.

This sounds very much like a bug that got fixed a short while ago. You
might try updating to the latest version.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kamal.desai at wachovia.com  Fri Apr 26 21:11:29 2002
From: kamal.desai at wachovia.com (kamal.desai@wachovia.com)
Date: Fri, 26 Apr 2002 15:11:29 -0400
Subject: [R] ORDGLM function - which package has it?
Message-ID: <OF97880921.A8FD6D22-ON85256BA7.0068B094@infra.fub.com>

I am new to the R.
I managed to download and install and got some basic summary work done. I
need to do ORDERED LOGIT model.

I searched web-site and mail archives and I think that I need to use
"ordglm"   function.  However, I am not sure what package has it. I tried
several (like RMUTIL, ORDINAL, REPEATED) etc. but no avail.  Any help is
useful.
I still haven't subscribed to the list so please respond to my e-mail.
Thanks in advance.
Kamal Desai

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From macq at llnl.gov  Fri Apr 26 21:12:38 2002
From: macq at llnl.gov (Don MacQueen)
Date: Fri, 26 Apr 2002 12:12:38 -0700
Subject: [R] Problem with read.xport() from foreign package
In-Reply-To: <x2pu0m8er0.fsf@blueberry.kubism.ku.dk>
References: <p05111706b8ef4fd871bc@[128.115.153.6]>
 <x2pu0m8er0.fsf@blueberry.kubism.ku.dk>
Message-ID: <p05111708b8ef56d514e3@[128.115.153.6]>

Thank you.
I see there is a newer version. I'll upgrade and test.
Apologies to all for not checking that first (only excuse is, I 
installed it only a couple of weeks ago).
-Don

At 9:02 PM +0200 4/26/02, Peter Dalgaard BSA wrote:
>Don MacQueen <macq at llnl.gov> writes:
>
>>  I have found that data imported from SAS using read.xport() in package
>>  foreign (installed recently) does not match the original data, when
>>  the data consists of character strings that are only one character
>>  long.
>
>This sounds very much like a bug that got fixed a short while ago. You
>might try updating to the latest version.
>
>--
>    O__  ---- Peter Dalgaard             Blegdamsvej 3 
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N  
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
>~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
--------------------------------------
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Fri Apr 26 22:09:22 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 26 Apr 2002 13:09:22 -0700 (PDT)
Subject: [R] ORDGLM function - which package has it?
In-Reply-To: <OF97880921.A8FD6D22-ON85256BA7.0068B094@infra.fub.com>
Message-ID: <Pine.A41.4.44.0204261308150.169132-100000@homer36.u.washington.edu>

On Fri, 26 Apr 2002 kamal.desai at wachovia.com wrote:

> I am new to the R.
> I managed to download and install and got some basic summary work done. I
> need to do ORDERED LOGIT model.

You want polr() in the MASS package.

	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wouter.buytaert at yucom.be  Fri Apr 26 22:42:06 2002
From: wouter.buytaert at yucom.be (wouter.buytaert@yucom.be)
Date: Fri, 26 Apr 2002 22:42:06 +0200 (CEST)
Subject: [R] different data series on one graph
Message-ID: <1019853726.3cc9bb9ec082e@yuclnx4.yucom.be>


Hello,

I'm looking for a way to plot different data series on one graph.
I have a series of hourly rainfall and quarterly flow
measurements (i.e. 4 times an hour) of a catchment. The rainfall
should be plotted in bars, the flow as a line. Both on the same X
axe (time) but with different Y axes.

The problem is the plot() function does not support add=TRUE...

Furthermore I'm not sure what's the best format for input data.
Now it are two data frames with a time (POSIXct) and a
rainfall/flow part. Maybe time series are easier, but in 

ts(data = NA, start = X,...

X should be a number or a vector. how does this coresponds to a
data and hour (e.g. april 26,2002, 15:00:00)?

Thanks,

Wouter Buytaert
Institute for Land and Water Management
Katholieke Universiteit Leuven

---------------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at blindglobe.net  Fri Apr 26 23:01:52 2002
From: rossini at blindglobe.net (A.J. Rossini)
Date: 26 Apr 2002 14:01:52 -0700
Subject: [R] different data series on one graph
In-Reply-To: <1019853726.3cc9bb9ec082e@yuclnx4.yucom.be>
References: <1019853726.3cc9bb9ec082e@yuclnx4.yucom.be>
Message-ID: <87elh2uqbj.fsf@jeeves.blindglobe.net>

>>>>> "wouter" == wouter buytaert <wouter.buytaert at yucom.be> writes:

    wouter> Hello,

    wouter> I'm looking for a way to plot different data series on one graph.
    wouter> I have a series of hourly rainfall and quarterly flow
    wouter> measurements (i.e. 4 times an hour) of a catchment. The rainfall
    wouter> should be plotted in bars, the flow as a line. Both on the same X
    wouter> axe (time) but with different Y axes.

    wouter> The problem is the plot() function does not support add=TRUE...

lines() and points() should work for you.


-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M-W: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my friday location is usually completely unpredictable.)


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Fri Apr 26 23:04:26 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 26 Apr 2002 14:04:26 -0700 (PDT)
Subject: [R] optim or nlm with matrices
In-Reply-To: <OE140lMFAVNL9pdRpVV0001a134@hotmail.com>
Message-ID: <Pine.A41.4.44.0204261401070.169132-100000@homer36.u.washington.edu>

On Fri, 26 Apr 2002, Ahmad Abu Hammour wrote:

> Hi, I have the following hypothetical optimization problem:
> -det(t(x-A%*%x1)%*%(x-A%*%x1)) where A,x,x1 are matrices. A coefficients
> and x and x1 are variable matrices or vectors. I tried to apply optim
> and nlm functions but I kept receive the following massage: Error in
> A%*%x1 : non-conformable arguments. The massage appears even the -det()
> can be calculated and the dimensions are checked. here is my example
> although there might be no solution for the optimization problem. A=A
> myfn=function(A){ x=matrix(c(1.8,0),byrow=T)
> x1=matrix(c(.8,1.8),byrow=T) -det((t(x)-t(x1)%*%A)%*%(x-A%*%x1)) }
> A=matrix(c(1,.3,2,-1.2),byrow=T,nrow=2) optim(A,myfn)

The first argument to optim() is a vector, not a matrix.  You need to
coerce to a matrix insider myfn(), eg
myfn=function(A){
A<-matrix(A,ncol=2)
x=matrix(c(1.8,0),byrow=T)
x1=matrix(c(.8,1.8),byrow=T)
-det((t(x)-t(x1)%*%A)%*%(x-A%*%x1))
}


> Another question
> regarding optimization: is there any chance that I can find a function
> or package that can do a constrained optimization such as:
> -det(x-A*x1-B*x2)' (x-A*x1-B*x2))  subject to p-f(A,B,...)=0, where f
> denotes a function. Thank you for your help in advance. Ahmad Abu

I don't know of such a function. You probably have to rewrite the function
being optimised, eg with Lagrange multipliers.

	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kamal.desai at wachovia.com  Fri Apr 26 23:14:31 2002
From: kamal.desai at wachovia.com (kamal.desai@wachovia.com)
Date: Fri, 26 Apr 2002 17:14:31 -0400
Subject: [R] Error in ORDGLM function
Message-ID: <OF677FE3CE.C9A1CEB2-ON85256BA7.0073E009@infra.fub.com>

I am trying this simple  model.

Following is the code:

newrate <- c(0,1,2,0,1,2,0,1,2,0,1,2)
totalast <- c(100,200,300,120,215,280,75,145,255,125,275,310)
ordglm(newrate~totalast,link="logit",maxiter=100, weights=1)

It runs for few seconds and get the error back

Error in ordglm(newrate ~ totalast, link = "logit", maxiter = 100, weights = 1) :
        Object "PearsRes" not found

I tried to use the example in the package

# McCullagh (1980) JRSS B42, 109-142
# tonsil size: 2x3 contingency table
y <- c(0:2,0:2)
carrier <- gl(2,3,6)
wt <- c(19,29,24,497,560,269)
ordglm(y~carrier, weights=wt)


It works fine.  So everything is installed correctly.

may be it has something to do with the weight?

Any help is welcome.

Thanks a lot.

Kamal Desai


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wouter.buytaert at yucom.be  Fri Apr 26 23:18:25 2002
From: wouter.buytaert at yucom.be (wouter.buytaert@yucom.be)
Date: Fri, 26 Apr 2002 23:18:25 +0200 (CEST)
Subject: [R] different data series on one graph
In-Reply-To: <87elh2uqbj.fsf@jeeves.blindglobe.net>
References: <1019853726.3cc9bb9ec082e@yuclnx4.yucom.be> <87elh2uqbj.fsf@jeeves.blindglobe.net>
Message-ID: <1019855904.3cc9c421013d5@yuclnx4.yucom.be>


So how do you add the second Y axe then? (flow is in m3/s, rain
in mm/h)

thanks!

Wouter

Aanhalen "A.J. Rossini" <rossini at blindglobe.net>:

> >>>>> "wouter" == wouter buytaert
> <wouter.buytaert at yucom.be> writes:
> 
>     wouter> Hello,
> 
>     wouter> I'm looking for a way to plot different data
> series on one graph.
>     wouter> I have a series of hourly rainfall and
> quarterly flow
>     wouter> measurements (i.e. 4 times an hour) of a
> catchment. The rainfall
>     wouter> should be plotted in bars, the flow as a
> line. Both on the same X
>     wouter> axe (time) but with different Y axes.
> 
>     wouter> The problem is the plot() function does not
> support add=TRUE...
> 
> lines() and points() should work for you.
> 
> 
> -- 
> A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
> U. of Washington
> Biostatistics		rossini at u.washington.edu

> FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
> -------------- http://software.biostat.washington.edu/
> ----------------
> FHCRC: M-W: 206-667-7025 (fax=4812)|Voicemail is pretty
> sketchy/use Email
> UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of
> phone to FAX
> (my friday location is usually completely
> unpredictable.)
> 
> 

---------------------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From zeileis at ci.tuwien.ac.at  Fri Apr 26 23:24:19 2002
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Fri, 26 Apr 2002 23:24:19 +0200
Subject: [R] different data series on one graph
References: <1019853726.3cc9bb9ec082e@yuclnx4.yucom.be>
Message-ID: <3CC9C583.7B26B34@ci.tuwien.ac.at>

wouter.buytaert at yucom.be wrote:
> 
> Hello,
> 
> I'm looking for a way to plot different data series on one graph.
> I have a series of hourly rainfall and quarterly flow
> measurements (i.e. 4 times an hour) of a catchment. The rainfall
> should be plotted in bars, the flow as a line. Both on the same X
> axe (time) but with different Y axes.
> 
> The problem is the plot() function does not support add=TRUE...
> 
> Furthermore I'm not sure what's the best format for input data.
> Now it are two data frames with a time (POSIXct) and a
> rainfall/flow part. Maybe time series are easier, but in
> 
> ts(data = NA, start = X,...
> 
> X should be a number or a vector. how does this coresponds to a
> data and hour (e.g. april 26,2002, 15:00:00)?

If your observations are equidistant, e.g. you've got 24 hourly
measurements per day, you could do something like this for the above
example:

R> rain <- ts(rain, start = c(26, 15), freq = 24)
R> flow <- ts(flow, start = c(26, 15), freq = 96)
and then you can just do

R> plot(rain)
R> lines(flow, col = 2)
for a time series plot.

If the observations are not equally spaced, then it is probably the
easiest thing to get a vector of dates on a reasonable scale (days or
something like that) and then do:

R> plot(time.rain, rain, type = "l")
R> lines(time.flow, flow, col = 2)

Hope this helps
Z

> Thanks,
> 
> Wouter Buytaert
> Institute for Land and Water Management
> Katholieke Universiteit Leuven
> 
> ---------------------------------------------------------------
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at blindglobe.net  Fri Apr 26 23:25:40 2002
From: rossini at blindglobe.net (A.J. Rossini)
Date: 26 Apr 2002 14:25:40 -0700
Subject: [R] different data series on one graph
In-Reply-To: <1019855904.3cc9c421013d5@yuclnx4.yucom.be>
References: <1019853726.3cc9bb9ec082e@yuclnx4.yucom.be>
	<87elh2uqbj.fsf@jeeves.blindglobe.net>
	<1019855904.3cc9c421013d5@yuclnx4.yucom.be>
Message-ID: <87adrqup7v.fsf@jeeves.blindglobe.net>

>>>>> "wouter" == wouter buytaert <wouter.buytaert at yucom.be> writes:

    wouter> So how do you add the second Y axe then? (flow is in m3/s, rain
    wouter> in mm/h)

How about judicious use of abline and text ?

(this is a hack'd solution, not a good one....)

best,
-tony

    wouter> thanks!

    wouter> Wouter

    wouter> Aanhalen "A.J. Rossini" <rossini at blindglobe.net>:

    >> >>>>> "wouter" == wouter buytaert
    >> <wouter.buytaert at yucom.be> writes:
    >> 
    wouter> Hello,
    >> 
    wouter> I'm looking for a way to plot different data
    >> series on one graph.
    wouter> I have a series of hourly rainfall and
    >> quarterly flow
    wouter> measurements (i.e. 4 times an hour) of a
    >> catchment. The rainfall
    wouter> should be plotted in bars, the flow as a
    >> line. Both on the same X
    wouter> axe (time) but with different Y axes.
    >> 
    wouter> The problem is the plot() function does not
    >> support add=TRUE...
    >> 
    >> lines() and points() should work for you.
    >> 
    >> 
    >> -- 
    >> A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
    >> U. of Washington
    >> Biostatistics		rossini at u.washington.edu

    >> FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
    >> -------------- http://software.biostat.washington.edu/
    >> ----------------
    >> FHCRC: M-W: 206-667-7025 (fax=4812)|Voicemail is pretty
    >> sketchy/use Email
    >> UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of
    >> phone to FAX
    >> (my friday location is usually completely
    >> unpredictable.)
    >> 
    >> 

    wouter> ---------------------------------------------------------------



-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M-W: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my friday location is usually completely unpredictable.)


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tchur at optushome.com.au  Sat Apr 27 00:19:06 2002
From: tchur at optushome.com.au (Tim Churches)
Date: Sat, 27 Apr 2002 08:19:06 +1000
Subject: [R] SAS and R
References: <20020426101842.662c53cc.fharrell@virginia.edu>
		<Pine.A41.4.44.0204260818540.40456-100000@homer11.u.washington.edu> <20020426121303.0af13962.fharrell@virginia.edu>
Message-ID: <3CC9D25A.1EA17692@optushome.com.au>

Frank E Harrell Jr wrote:
> 
> It may be worth pointing out that the new read.ssd has to launch SAS 
> to convert to xport format.  The sas.get philosophy is that if you are 
> going to have to do that you might as well ask the sas session to dump 
> the data to ASCII files, with optional restriction to a subset of the
> variables.   That way you can fetch all the SAS attributes such as variable
> labels, data/time info, etc.  -Frank

SAS Version 8.2 provides an XML "engine" which allows you to write one
or an
ensemble of SAS datasets to an XML file (with a SAS-supplied DTD). The
usual
WHERE clause subsetting etc can be used with this engine. The XML
properly
represents date/time values and preserves the full precision of floats
(unlike
the SAS xport format which reduces the precision of numeric variables
from
56 bits to 53 bits). Best of all, the new SAS XML format preserves all
the
metadata such as dataset and variable labels, and even "formats"
(codebooks,
lookup tables): if a format is permanently associated with a variable,
the 
XML engine can be told to fetch the relevant format from an external
format
catalogue, convert it to an XML representation and enbed that in the
dataset
XML file. Hallelujah!

I haven't tried this yet, but it should be possible to use Duncan Temple
Lang's
XML package to parse the SAS dataset XML files and create a
fully-fledged
data frame complete with labelled factors etc.

Tim C
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Fri Apr 26 23:39:49 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 26 Apr 2002 23:39:49 +0200
Subject: [R] different data series on one graph
In-Reply-To: <87adrqup7v.fsf@jeeves.blindglobe.net>
References: <1019853726.3cc9bb9ec082e@yuclnx4.yucom.be>
	<87elh2uqbj.fsf@jeeves.blindglobe.net>
	<1019855904.3cc9c421013d5@yuclnx4.yucom.be>
	<87adrqup7v.fsf@jeeves.blindglobe.net>
Message-ID: <x2d6wm87h6.fsf@blueberry.kubism.ku.dk>

rossini at blindglobe.net (A.J. Rossini) writes:

> >>>>> "wouter" == wouter buytaert <wouter.buytaert at yucom.be> writes:
> 
>     wouter> So how do you add the second Y axe then? (flow is in m3/s, rain
>     wouter> in mm/h)
> 
> How about judicious use of abline and text ?
> 
> (this is a hack'd solution, not a good one....)

axis() might be a more obvious idea. Then you just need to hack
labels= and at=.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From yerupaja01 at terra.es  Sat Apr 27 11:39:17 2002
From: yerupaja01 at terra.es (antonio)
Date: Sat, 27 Apr 2002 11:39:17 +0200
Subject: [R] Problem with installation on Mandrake 8.1: Solved
In-Reply-To: <20020419070617.051cf039.fharrell@virginia.edu>
References: <438df407df.407df438df@teleline.es> <20020419070617.051cf039.fharrell@virginia.edu>
Message-ID: <200204270935.LAA21554@stat.math.ethz.ch>

Dear Frank,

Sorry for the delay.


> I had to install libgcc3.0-3.0.1-1mdk from Mandrake
> installation disk # 2 and liblapack3-3.0-3mdk from Mandrake
> disk # 3 (for blas).   You may only need the latter.  -Frank Harrell

This is just what I needed. Now, everything is OK

Thanks!!

Antonio
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From pgilbert at bank-banque-canada.ca  Sat Apr 27 17:54:30 2002
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Sat, 27 Apr 2002 11:54:30 -0400
Subject: [R] S & R list virus warning
Message-ID: <3CCAC9B6.81757097@bank-banque-canada.ca>

It appears that someone has harvested email addresses from the S-news or
one of the R lists and is sending out viruses. The mail does not come
from the lists, but appears to come from people on these lists. (Closer
examination of the headers indicates that it does not really come from
the person indicated in the "from" field.) The mail is probably directed
to people on these lists as well as others. I have received at least
three already. The most recent one has the subject line "Introduction on
ADSL" and a previous one had the subject line "A good tool".

The messages are infected with the WORM_KLEZ.G virus in an attachment.

I am not sure what mechanisms can be used to deter spammers from
harvesting email addresses from lists, but something should be
considered. One thing I know people have tried is to put blanks or other
characters into the publicly displayed addresses on  lists. This means
that people can read the lists and figure out an email address, but
simple automatic tools are foiled. Another possibility is to not make
the addresses  available.

I realize I can ask that my name be hidden on the list, but that breaks
the original intent of having names available: to be able to know who
else is involved in the list community.

Paul Gilbert
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rossini at blindglobe.net  Sat Apr 27 18:46:23 2002
From: rossini at blindglobe.net (A.J. Rossini)
Date: 27 Apr 2002 09:46:23 -0700
Subject: [R] S & R list virus warning
In-Reply-To: <3CCAC9B6.81757097@bank-banque-canada.ca>
References: <3CCAC9B6.81757097@bank-banque-canada.ca>
Message-ID: <87g01hozs0.fsf@jeeves.blindglobe.net>


>>>>> "paul" == Paul Gilbert <pgilbert at bank-banque-canada.ca> writes:



    paul> It appears that someone has harvested email addresses from the S-news or
    paul> one of the R lists and is sending out viruses. The mail does not come
    paul> from the lists, but appears to come from people on these lists. (Closer
    paul> examination of the headers indicates that it does not really come from
    paul> the person indicated in the "from" field.) The mail is probably directed
    paul> to people on these lists as well as others. I have received at least
    paul> three already. The most recent one has the subject line "Introduction on
    paul> ADSL" and a previous one had the subject line "A good tool".

    paul> The messages are infected with the WORM_KLEZ.G virus in an attachment.

This has nothing to do with manual harvesting - it's from a
Microsoft-based worm that is particularly nasty.  See the usual
anti-virus warnings for more details.  Basically, it harvests from
your mailbox.  It also changes its subject line using information from
the mailbox.  

    paul> I am not sure what mechanisms can be used to deter spammers from
    paul> harvesting email addresses from lists, but something should be
    paul> considered. One thing I know people have tried is to put blanks or other
    paul> characters into the publicly displayed addresses on  lists. This means
    paul> that people can read the lists and figure out an email address, but
    paul> simple automatic tools are foiled. Another possibility is to not make
    paul> the addresses  available.

Or not to allow mailing list subscribers to use mail tools which while
convenient, can be subverted for other uses.  Note that the virus uses
a hole which has be subsequently patched; it's a human/organization
problem (not performing timely security updates).

However, this solution, while it works, doesn't seem to be an option.

best,
-tony

-- 
A.J. Rossini				Rsrch. Asst. Prof. of Biostatistics
U. of Washington Biostatistics		rossini at u.washington.edu	
FHCRC/SCHARP/HIV Vaccine Trials Net	rossini at scharp.org
-------------- http://software.biostat.washington.edu/ ----------------
FHCRC: M-W: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
(my friday location is usually completely unpredictable.)


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From baron at cattell.psych.upenn.edu  Sat Apr 27 18:55:46 2002
From: baron at cattell.psych.upenn.edu (Jonathan Baron)
Date: Sat, 27 Apr 2002 12:55:46 -0400
Subject: [R] S & R list virus warning
In-Reply-To: <3CCAC9B6.81757097@bank-banque-canada.ca>; from pgilbert@bank-banque-canada.ca on Sat, Apr 27, 2002 at 11:54:30AM -0400
References: <3CCAC9B6.81757097@bank-banque-canada.ca>
Message-ID: <20020427125546.A19870@cattell.psych.upenn.edu>

On 04/27/02 11:54, Paul Gilbert wrote:
>It appears that someone has harvested email addresses from the S-news or
>one of the R lists and is sending out viruses. The mail does not come
>from the lists, but appears to come from people on these lists.

I am quite sure that this is not intentional.  This virus is
spread through people's computers.  The virus itself finds the
email addresses and harvests them.  I get about 50 of these per
day, from all over the place.

The From addresses do not even tell you whose computer is
infected.  There is nothing we can do.  Just delete them.  If you
use a Unix mailer like Mail, Elm, or Mutt, you can recognize them
instantly because the attachment is improperly done and shows up
as garbage.

And if you have a Windows computer, you can do the world a favor
by making sure it is properly secured.  (Or get an accelerator
for it, one that accelerates at 9.81 m/s^2.)

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From forporphyry at hotmail.com  Sat Apr 27 21:26:58 2002
From: forporphyry at hotmail.com (graham lawrence)
Date: Sat, 27 Apr 2002 12:26:58 -0700
Subject: [R] Explanation of Error Diagnostics
Message-ID: <F41hriS325H21qJGyXN00001f25@hotmail.com>

Hi,

Is there any documentation to explain R's error diagnostics, e.g. messages 
like

>source("../src/sources/routine.R")
Read 8 records
Read 2 records
Error in "[<-"(*tmp*, !test, value = rep(no, length = length(ans))[!test]) :
        incompatible types

The nature of the problem incompatible types, is clear; but I'm more 
interested in its location, and feel that the cryptic elements
"[<-"(*tmp*, !test, value = rep(no, length = length(ans))[!test])
probably hold the key to finding it.

Thanks in advance for your help,
graham lawrence

_________________________________________________________________


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dstierman at cableone.net  Sun Apr 28 08:41:00 2002
From: dstierman at cableone.net (Don Stierman)
Date: Sun, 28 Apr 2002 00:41:00 -0600
Subject: [R] rpart problem
Message-ID: <HCEOIJNHAIMCCJIBNOFFCECJCAAA.dstierman@cableone.net>

I am having problems with rpart and a particular dataset. I try the
following code and get no significant results back from the script. However,
if I delete the value of 79 in the last row and column of the dataset, I do
get results. Is rpart really that dependent on a single value, or is there
something else wrong? How do I fix this so that I will get results without
having to change the dataset? Also, what is a good way to determine if a
single value or a single column is causing problems in the rpart package?
Thanks, Don

R script:

library (rpart)
data<-read.csv("C:\\temp.txt")
fit <- rpart(data$I ~ ., data,method="anova")
fit

Results with value of 79:

n= 703

node), split, n, deviance, yval
      * denotes terminal node

1) root 703 30738.37 12.02987 *

Results without value of 79:

n=702 (1 observations deleted due to missing)

node), split, n, deviance, yval
      * denotes terminal node

 1) root 702 26246.990 11.93447
   2) C>=0.325 615 19389.630 11.71382
     4) D< 11.635 522 12578.270 11.47893 *
     5) D>=11.635 93  6620.903 13.03226
      10) D>=11.655 82  1849.561 12.07317 *
      11) D< 11.655 11  4133.636 20.18182 *
   3) C< 0.325 87  6615.747 13.49425
     6) A< 28.68 69  1872.638 12.59420 *
     7) A>=28.68 18  4472.944 16.94444 *
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: temp.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20020428/b24c0219/temp.txt

From Bill.Venables at CMIS.CSIRO.AU  Sun Apr 28 09:30:14 2002
From: Bill.Venables at CMIS.CSIRO.AU (Bill.Venables@CMIS.CSIRO.AU)
Date: Sun, 28 Apr 2002 17:30:14 +1000
Subject: [R] rpart problem
Message-ID: <E09E527B56BE2D438A3D6A246DDD27A90C18AA@Roper-CV.qld.cmis.csiro.au>

Don Stierman asks:

>  -----Original Message-----
> From: 	Don Stierman [mailto:dstierman at cableone.net] 
> Sent:	Sunday, April 28, 2002 4:41 PM
> To:	r-help at stat.math.ethz.ch
> Subject:	[R] rpart problem
> 
> I am having problems with rpart and a particular dataset. I try the
> following code and get no significant results back from the script.
However,
> if I delete the value of 79 in the last row and column of the dataset, I
do
> get results. 

Actually you got results in the first case as well, you just did not get the
results you were expecting.  You have at least three outliers in your data
(both the values I = 79 and I = 81).  Regression trees are fitted by least
squares and it is pretty well known that outlying observations can seriously
influence any least squares procedure.  The tree model, in effect, shrugs
its shoulders and says the best tree has a single root node.

> Is rpart really that dependent on a single value, 

The problem, such as it is, is not with rpart but with your model.  You
might try a transformation of y, for example, and see if you get anything
more useful to you.  With a transformed response the least squares fitting
procedure might be more reasonable and productive.

For example

fit <- rpart(sqrt(I) ~ ., data)

Alterntively you might use log(I+1) as the response.  Some judgment based on
the context is necessary and you do not give the context.

> or is there
> something else wrong? How do I fix this so that I will get results without
> having to change the dataset? Also, what is a good way to determine if a
> single value or a single column is causing problems in the rpart package?

Tree models are not a magic bullet.  In particular they do not remove the
necessity to do some diagnostic checks afterwards.  You might just try
looking at qqnorm plots of the residuals or residuals vs fitted values plots
just to see if the model achieves reasonable symmetry in the residuals, for
example.  (For your example these all looked pretty dodgy even with a
transformation, I have to say!)

> Thanks, Don
> 
> R script:
> 
> library (rpart)
> data<-read.csv("C:\\temp.txt")
> fit <- rpart(data$I ~ ., data,method="anova")
> fit
> 
> Results with value of 79:
> 
> n= 703
> 
> node), split, n, deviance, yval
>       * denotes terminal node
> 
> 1) root 703 30738.37 12.02987 *
> 
> Results without value of 79:
> 
> n=702 (1 observations deleted due to missing)
> 
> node), split, n, deviance, yval
>       * denotes terminal node
> 
>  1) root 702 26246.990 11.93447
>    2) C>=0.325 615 19389.630 11.71382
>      4) D< 11.635 522 12578.270 11.47893 *
>      5) D>=11.635 93  6620.903 13.03226
>       10) D>=11.655 82  1849.561 12.07317 *
>       11) D< 11.655 11  4133.636 20.18182 *
>    3) C< 0.325 87  6615.747 13.49425
>      6) A< 28.68 69  1872.638 12.59420 *
>      7) A>=28.68 18  4472.944 16.94444 * << File: temp.txt >> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mikalzet at libero.it  Sun Apr 28 10:37:02 2002
From: mikalzet at libero.it (mikalzet@libero.it)
Date: Sun, 28 Apr 2002 10:37:02 +0200 (CEST)
Subject: [R] S & R list virus warning
In-Reply-To: <20020427125546.A19870@cattell.psych.upenn.edu>
Message-ID: <Pine.LNX.4.33L2.0204281026360.2274-100000@localhost.localdomain>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 04/27/02 11:54, Paul Gilbert wrote:

> >It appears that someone has harvested email addresses from the S-news or
> >one of the R lists and is sending out viruses. The mail does not come
> >from the lists, but appears to come from people on these lists.

A few days ago a mail apparently sent from me with a virus attachment was
brought to my attention, I quickly came to the conclusion that the 'From:'
address was spoofed but it is comforting that this hypothesis is
confirmed.

As a linux user I thought I was immune from the nasty effects of the
world virus epidemic, but it seems that at least indirectly it affects
everybody.

Viral spoofing is really a nuisance. In the limited environment of
mailing lists it could perhaps be defeated by use of gpg or
pgp-signed mail and automatic cancellation of false or unsigned
messages ... but I'm afraid this wouldn't be practical, and wouldn't
really eliminate the problem, as a similar policy would have to be
applied to the whole of internet to succeed.

- -- 
Michele Alzetta


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.0.6 (GNU/Linux)
Comment: Per informazioni si veda http://www.gnupg.org

iD8DBQE8y7S3CcFfzlIKnH4RAuWxAJ4kChWAu/Hd/7Kczy9m808kk9KjXQCgjPcs
EEAB04y1XW2un5NRoYnV4q4=
=d+fg
-----END PGP SIGNATURE-----

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wolski at molgen.mpg.de  Sun Apr 28 14:36:15 2002
From: wolski at molgen.mpg.de (wolski@molgen.mpg.de)
Date: Sun, 28 Apr 2002 14:36:15 +0200
Subject: [R] Image processing? Manipulating image data in R?
Message-ID: <1019997375.3ccbecbf66d8e@imp.molgen.mpg.de>

Hi!
I am looking for a R library by which i can load images (i found pixmap that
allows it to do).
But in addition i need methods to access the data, get them for example as an
array  or matrix to do with this data some processing.
1. Is there a method in the pixmap library to access the matrix in which the
image data is stored.
2. Is there an alternative library running under MS Windows?

Sincerely 
Eryk


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Sun Apr 28 15:12:12 2002
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 28 Apr 2002 09:12:12 -0400
Subject: [R] Explanation of Error Diagnostics
In-Reply-To: <F41hriS325H21qJGyXN00001f25@hotmail.com>
Message-ID: <5.1.0.14.2.20020428090013.01d69158@pop>

Dear Graham,

Errors and error messages are generated in individual functions by calls to 
the stop function, so documentation of an error message would have to be 
particular to the function that generated the error (unless an effort were 
made to standardize some kinds of messages). As well, since functions 
typically call other functions, unless the calling function catches an 
error, the message generated can be cryptic.

This problem is compounded when you source a file of commands. Specifying 
the argument verbose=TRUE to source will give you much more information, 
helping you to pinpoint the error. If that is insufficient, execute the 
commands individually to the point of the error and call the traceback 
function, which will show you the sequence of function calls culminating in 
the error. There are other debugging tools as well, but what I've suggested 
will probably suffice.

I hope that this helps,
  John

At 12:26 PM 4/27/2002 -0700, graham lawrence wrote:
>Hi,
>
>Is there any documentation to explain R's error diagnostics, e.g. messages 
>like
>
>>source("../src/sources/routine.R")
>Read 8 records
>Read 2 records
>Error in "[<-"(*tmp*, !test, value = rep(no, length = length(ans))[!test]) :
>        incompatible types
>
>The nature of the problem incompatible types, is clear; but I'm more 
>interested in its location, and feel that the cryptic elements
>"[<-"(*tmp*, !test, value = rep(no, length = length(ans))[!test])
>probably hold the key to finding it.
>
>Thanks in advance for your help,
>graham lawrence


-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From kuonen at statoo.com  Sun Apr 28 15:36:14 2002
From: kuonen at statoo.com (Dr. Diego Kuonen)
Date: Sun, 28 Apr 2002 15:36:14 +0200
Subject: [R] Image processing? Manipulating image data in R?
References: <1019997375.3ccbecbf66d8e@imp.molgen.mpg.de>
Message-ID: <3CCBFACE.3F78B11D@statoo.com>

wolski at molgen.mpg.de wrote:
> 
> I am looking for a R library by which i can load images...
> But in addition i need methods to access the data, get them for example as an
> array  or matrix to do with this data some processing.

Looking at your email address and assuming that you have gene expression
data in mind, you may find the following pages useful:

 * R Packages For Gene Expression Analysis
   http://www.stat.uni-muenchen.de/~strimmer/rexpress.html

 * Spot software package for the analysis of microarray images
   http://www.cmis.csiro.au/iap/spot.htm

 * Z-IMAGE image analysis environment
   http://www.cmis.csiro.au/IAP/zimage.htm

 * Terry Speed's microarray data analysis group 
   http://www.stat.berkeley.edu/users/terry/zarray/Html/

Hope that is what you were looking for.

Greets,

  Diego Kuonen


-- 
Dr. ?s sc. Diego Kuonen        CEO & Applied Statistician 
Statoo Consulting, PO Box 107, 1015 Lausanne, Switzerland
+ Have you ever been Statooed?   http://www.statoo.info +
+ Free Statooed newsletters:    http://lists.statoo.com +
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rgentlem at jimmy.harvard.edu  Sun Apr 28 16:48:51 2002
From: rgentlem at jimmy.harvard.edu (Robert Gentleman)
Date: Sun, 28 Apr 2002 10:48:51 -0400
Subject: [R] Image processing? Manipulating image data in R?
In-Reply-To: <3CCBFACE.3F78B11D@statoo.com>; from kuonen@statoo.com on Sun, Apr 28, 2002 at 03:36:14PM +0200
References: <1019997375.3ccbecbf66d8e@imp.molgen.mpg.de> <3CCBFACE.3F78B11D@statoo.com>
Message-ID: <20020428104851.T11850@jimmy.harvard.edu>

On Sun, Apr 28, 2002 at 03:36:14PM +0200, Dr. Diego Kuonen wrote:
> wolski at molgen.mpg.de wrote:
> > 
> > I am looking for a R library by which i can load images...
> > But in addition i need methods to access the data, get them for example as an
> > array  or matrix to do with this data some processing.
> 
> Looking at your email address and assuming that you have gene expression
> data in mind, you may find the following pages useful:
> 
>  * R Packages For Gene Expression Analysis
>    http://www.stat.uni-muenchen.de/~strimmer/rexpress.html
> 
>  * Spot software package for the analysis of microarray images
>    http://www.cmis.csiro.au/iap/spot.htm
> 
>  * Z-IMAGE image analysis environment
>    http://www.cmis.csiro.au/IAP/zimage.htm
> 
>  * Terry Speed's microarray data analysis group 
>    http://www.stat.berkeley.edu/users/terry/zarray/Html/
> 

  And,
    The Bioconductor project at:
     http:/www.bioconductor.org

> Hope that is what you were looking for.
> 
> Greets,
> 
>   Diego Kuonen
> 
> 
> -- 
> Dr. ?s sc. Diego Kuonen        CEO & Applied Statistician 
> Statoo Consulting, PO Box 107, 1015 Lausanne, Switzerland
> + Have you ever been Statooed?   http://www.statoo.info +
> + Free Statooed newsletters:    http://lists.statoo.com +
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
+---------------------------------------------------------------------------+
| Robert Gentleman                 phone : (617) 632-5250                   |
| Associate Professor              fax:   (617)  632-2444                   |
| Department of Biostatistics      office: M1B28
| Harvard School of Public Health  email: rgentlem at jimmy.dfci.harvard.edu   |
+---------------------------------------------------------------------------+
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ggrothendieck at yifan.net  Sun Apr 28 23:01:05 2002
From: ggrothendieck at yifan.net (ggrothendieck@yifan.net)
Date: Sun, 28 Apr 2002 17:01:05 -0400
Subject: [R] rank
Message-ID: <3CCC2AD1.7507.4794E00@localhost>

I would like to make a couple of small suggestions regarding
rank.  All of these can be done now but with the the indicated additions,
one could have clearer code:

PRESERVE NAMES
It would be nice if rank(v) preserved the names of vector v.
Currently you have to do this:  rv <- rank(v); names(rv) <- names(v)
which seems unnecessarily elaborate.    Note that when you rank
some items you often want to know which items were ranked 
where so its natural that you would want to preserve the names.

TIED RANKS
It would be nice if there were an option to control whether tied ranks
are averaged or not.  Currently they are averaged.

As a workaround, one can create a function to do this:

myrank <- function(x) {
   y <- order(order(x))
   names(y) <- names(x)
   return(y)
}

but it would be tidier if the option were available within rank itself.

ASCENDING OR DESCENDING
It would be nice if one could specify whether the rank was to be
computed in ascending or descending order.  rank(-x) (in the
case of numeric data) and rank(-rank(x)) with numeric or character
work but an option would be more direct.

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Timothy.Keitt at stonybrook.edu  Mon Apr 29 00:16:44 2002
From: Timothy.Keitt at stonybrook.edu (Timothy H. Keitt)
Date: 28 Apr 2002 18:16:44 -0400
Subject: [R] Compile R with Intel compilers on Linux?
Message-ID: <1020032204.17425.3.camel@keittlab-6>

Out of curiosity, has anyone tried it? (I managed to get the compilers
installed, but can't quite get R to configure.)

Tim

-- 
Timothy H. Keitt
Department of Ecology and Evolution
State University of New York at Stony Brook
Stony Brook, New York 11794 USA
Phone: 631-632-1101, FAX: 631-632-7626
http://life.bio.sunysb.edu/ee/keitt/
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From r_stuff_online at hotmail.com  Mon Apr 29 01:35:28 2002
From: r_stuff_online at hotmail.com (Neil Osborne)
Date: Sun, 28 Apr 2002 23:35:28 +0000
Subject: [R] Building Rgui.exe with Visual Studio
Message-ID: <F238c9ny7BXx4XFKpRc0000222e@hotmail.com>

Hi,

I have downloaded and modified the source for rgui - because I wanted to add 
a few more custom menus to the GUI. I have almost got it completed, but have 
spent the last four hours trying to resolve the following issues (no pun 
intended !)



Linking...
R.lib(R.dll) : error LNK2005: _WatchCursor already defined in cursors.obj
R.lib(R.dll) : error LNK2005: _ArrowCursor already defined in cursors.obj
R.lib(R.dll) : error LNK2005: _R_Interactive already defined in main.obj


I have tried just about everything I can think of (including the obvious 
commenting out the declspec dllimport statements in cursors.c) - to no 
avail. Actually that works but it's a desperate hack and causes the app to 
crash later on!

I've run out of ideas and I would appreciate a new set of eyes looking at 
this to see what I'm obviously doing wrong.


PS: I am compiling with MSDev Studio 6, OS  is Win2k


Regards


Redhat Hacker

_________________________________________________________________


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From r_stuff_online at hotmail.com  Mon Apr 29 01:43:36 2002
From: r_stuff_online at hotmail.com (Neil Osborne)
Date: Sun, 28 Apr 2002 23:43:36 +0000
Subject: [R] Building rgui with Visual C/C++ 6
Message-ID: <F146DrPixj6ZTCVk8xZ0000258b@hotmail.com>

Hi,

I have downloaded and modified the source for rgui - because I wanted to add 
a few more custom menus to the GUI. I have almost got it completed, but have 
spent the last four hours trying to resolve the following issue (no pun 
intended !)



Linking...
R.lib(R.dll) : error LNK2005: _WatchCursor already defined in cursors.obj
R.lib(R.dll) : error LNK2005: _ArrowCursor already defined in cursors.obj
R.lib(R.dll) : error LNK2005: _R_Interactive already defined in main.obj


I have tried just about everything I can think of (including the obvious 
commenting out the declspec dllimport statements in cursors.c) - to no 
avail. Actually that works but it's a desperate hack and causes the app to 
crash later on!

I've run out of ideas and I would appreciate a new set of eyes looking at 
this to see what I'm obviously doing wrong.


PS: I am compiling with MSDev Studio 6, OS  is Win2k


Regards


Redhat Hacker

_________________________________________________________________
Join the worlds largest e-mail service with MSN Hotmail. 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From P.Connolly at hortresearch.co.nz  Mon Apr 29 01:51:50 2002
From: P.Connolly at hortresearch.co.nz (Patrick Connolly)
Date: Mon, 29 Apr 2002 11:51:50 +1200 (NZST)
Subject: [R] dropterm() in MASS
Message-ID: <200204282351.g3SNpoG08653@biomat1.marc.hort.cri.nz>


To compare two different models, I've compared the result of using
dropterm() on both.


Single term deletions

Model:
growth ~ days + I(days^0.5)
            Df Sum of Sq     RSS     AIC
<none>                    2.8750 -0.2290
days         1    4.8594  7.7344  4.6984
I(days^0.5)  1    0.0234  2.8984 -2.1722

AND

Single term deletions

Model:
growth ~ days + I(days^2)
          Df Sum of Sq     RSS     AIC
<none>                  2.8750 -0.2290
days       1    5.8338  8.7088  5.5290
I(days^2)  1    0.0234  2.8984 -2.1722

I understood that the AIC column was the change in AIC when that term
was dropped from the model.

QUESTION: 

Why would (should) the effect of dropping quite different terms be
exactly the same?  It's consistent with all the data of this type I've
tried it on.

best

-- 
*************************************************************
   ___      Patrick Connolly
 {~._.~}    HortResearch             Great minds discuss ideas;
 _( Y )_    Mt Albert                Average minds discuss events; 
(:_~*~_:)   Auckland                 Small minds discuss people.
 (_)-(_)    New Zealand                                    .... Anon
            Ph: +64-9 815 4200 x 7188
*************************************************************


______________________________________________________
The contents of this e-mail are privileged and/or confidential to the
named recipient and are not to be used by any other person and/or
organisation. If you have received this e-mail in error, please notify 
the sender and delete all material pertaining to this e-mail.
______________________________________________________
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From FJMolina at lbl.gov  Mon Apr 29 02:27:28 2002
From: FJMolina at lbl.gov (Francisco J Molina)
Date: Sun, 28 Apr 2002 17:27:28 -0700
Subject: [R] ifelse versus ...
Message-ID: <3CCC9370.29271069@lbl.gov>

I read somewhere that, instead of the structure if(...) else(...)
it is better to use the command ifelse(...,...,...).

Currently I am using structures like

ifelse(...,{sequence; of; commands}, 0)

instead of if(...){sequence; of; commands}

and I am using 

ifelse(...,{sequence; of; commands}, {another; Sequence; Of; Commands })

instead of 

if(...){sequence; of; commands}
else{another; Sequence; Of; Commands })

In this way the program becomes a little bit more difficult to read but
I think that I am optimizing the performance.

The question is:

Am I actually optimizing the performance?
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From edd at debian.org  Mon Apr 29 02:40:42 2002
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 28 Apr 2002 19:40:42 -0500
Subject: [R] Building rgui with Visual C/C++ 6
In-Reply-To: <F146DrPixj6ZTCVk8xZ0000258b@hotmail.com>
References: <F146DrPixj6ZTCVk8xZ0000258b@hotmail.com>
Message-ID: <20020429004042.GA13552@sonny.eddelbuettel.com>

On Sun, Apr 28, 2002 at 11:43:36PM +0000, Neil Osborne wrote:
> PS: I am compiling with MSDev Studio 6, OS  is Win2k

I assume that you do understand that this is not a supported platform? In
other words, you are starting a new "port", at least tool-wise speaking.

Dirk

-- 
Good judgement comes from experience; experience comes from bad judgement. 
							    -- Fred Brooks
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jfox at mcmaster.ca  Mon Apr 29 06:36:00 2002
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 29 Apr 2002 00:36:00 -0400
Subject: [R] dropterm() in MASS
In-Reply-To: <200204282351.g3SNpoG08653@biomat1.marc.hort.cri.nz>
Message-ID: <5.1.0.14.2.20020429002926.01d6b6d0@pop>

Dear Patrick,

At 11:51 AM 4/29/2002 +1200, Patrick Connolly wrote:

>To compare two different models, I've compared the result of using
>dropterm() on both.
>
>
>Single term deletions
>
>Model:
>growth ~ days + I(days^0.5)
>             Df Sum of Sq     RSS     AIC
><none>                    2.8750 -0.2290
>days         1    4.8594  7.7344  4.6984
>I(days^0.5)  1    0.0234  2.8984 -2.1722
>
>AND
>
>Single term deletions
>
>Model:
>growth ~ days + I(days^2)
>           Df Sum of Sq     RSS     AIC
><none>                  2.8750 -0.2290
>days       1    5.8338  8.7088  5.5290
>I(days^2)  1    0.0234  2.8984 -2.1722
>
>I understood that the AIC column was the change in AIC when that term
>was dropped from the model.
>
>QUESTION:
>
>Why would (should) the effect of dropping quite different terms be
>exactly the same?  It's consistent with all the data of this type I've
>tried it on.

Notice that the residual sums of squares for the two models are identical, 
so the peculiar result here pertains not just to dropping a term but also 
to the general fit of the model. What does the variable days look like? Are 
there just three different values of this variable?

I hope that this helps,
  John



-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From P.Connolly at hortresearch.co.nz  Mon Apr 29 07:51:17 2002
From: P.Connolly at hortresearch.co.nz (Patrick Connolly)
Date: Mon, 29 Apr 2002 17:51:17 +1200 (NZST)
Subject: [R] dropterm() in MASS
In-Reply-To: <200204282351.g3SNpoG08653@biomat1.marc.hort.cri.nz> from "Patrick Connolly" at Apr 29, 2002 11:51:50 AM
Message-ID: <200204290551.g3T5pHq08851@biomat1.marc.hort.cri.nz>

I asked a question about dropterm():

Thanks to John Fox, I see it has to do with the inadequacies of the
model I was attempting to use and not to do with stepwise.  

best

-- 
*************************************************************
   ___      Patrick Connolly
 {~._.~}    HortResearch             Great minds discuss ideas;
 _( Y )_    Mt Albert                Average minds discuss events; 
(:_~*~_:)   Auckland                 Small minds discuss people.
 (_)-(_)    New Zealand                                    .... Anon
            Ph: +64-9 815 4200 x 7188
*************************************************************


______________________________________________________
The contents of this e-mail are privileged and/or confidential to the
named recipient and are not to be used by any other person and/or
organisation. If you have received this e-mail in error, please notify 
the sender and delete all material pertaining to this e-mail.
______________________________________________________
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Apr 29 08:13:35 2002
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 29 Apr 2002 07:13:35 +0100 (GMT Daylight Time)
Subject: [R] Building Rgui.exe with Visual Studio
In-Reply-To: <F238c9ny7BXx4XFKpRc0000222e@hotmail.com>
Message-ID: <Pine.WNT.4.44.0204290708310.2956-100000@Reeve>

It's a long time since anyone has reported trying to build R with VC++6.
It has been done, *but* it fails make check because of problems with the
handling of floating point numbers (e.g. it reported 3 < Inf as false, as I
recall).

It would have taken far less than 4 hours to set up and build using the
documented procedures and tools.  In any case, it is unnecessary to build
RGui to add custom menus, as the supplied package windlg shows.  And there
are instructions in the sources on how to build such packages with VC++6.


On Sun, 28 Apr 2002, Neil Osborne wrote:

> Hi,
>
> I have downloaded and modified the source for rgui - because I wanted to add
> a few more custom menus to the GUI. I have almost got it completed, but have
> spent the last four hours trying to resolve the following issues (no pun
> intended !)
>
>
>
> Linking...
> R.lib(R.dll) : error LNK2005: _WatchCursor already defined in cursors.obj
> R.lib(R.dll) : error LNK2005: _ArrowCursor already defined in cursors.obj
> R.lib(R.dll) : error LNK2005: _R_Interactive already defined in main.obj
>
>
> I have tried just about everything I can think of (including the obvious
> commenting out the declspec dllimport statements in cursors.c) - to no
> avail. Actually that works but it's a desperate hack and causes the app to
> crash later on!
>
> I've run out of ideas and I would appreciate a new set of eyes looking at
> this to see what I'm obviously doing wrong.
>
>
> PS: I am compiling with MSDev Studio 6, OS  is Win2k
>
>
> Regards
>
>
> Redhat Hacker
>
> _________________________________________________________________
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Apr 29 08:17:09 2002
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 29 Apr 2002 07:17:09 +0100 (GMT Daylight Time)
Subject: [R] ifelse versus ...
In-Reply-To: <3CCC9370.29271069@lbl.gov>
Message-ID: <Pine.WNT.4.44.0204290714460.2956-100000@Reeve>

On Sun, 28 Apr 2002, Francisco J Molina wrote:

> I read somewhere that, instead of the structure if(...) else(...)
> it is better to use the command ifelse(...,...,...).
>
> Currently I am using structures like
>
> ifelse(...,{sequence; of; commands}, 0)
>
> instead of if(...){sequence; of; commands}
>
> and I am using
>
> ifelse(...,{sequence; of; commands}, {another; Sequence; Of; Commands })
>
> instead of
>
> if(...){sequence; of; commands}
> else{another; Sequence; Of; Commands })
>
> In this way the program becomes a little bit more difficult to read but
> I think that I am optimizing the performance.
>
> The question is:
>
> Am I actually optimizing the performance?

No.  ifelse is only more efficient if used to replace constructs like

for(i in seq(along=x)) if(x[i]) foo(x[i]) else bar(x[i])

by ifelse(x, foo(x), bar(x)).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Mon Apr 29 08:36:56 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 29 Apr 2002 08:36:56 +0200
Subject: [R] ifelse versus ...
References: <3CCC9370.29271069@lbl.gov>
Message-ID: <3CCCEA08.781E93FB@statistik.uni-dortmund.de>

Francisco J Molina wrote:
> 
> I read somewhere that, instead of the structure if(...) else(...)
> it is better to use the command ifelse(...,...,...).
> 
> Currently I am using structures like
> 
> ifelse(...,{sequence; of; commands}, 0)
> 
> instead of if(...){sequence; of; commands}
> 
> and I am using
> 
> ifelse(...,{sequence; of; commands}, {another; Sequence; Of; Commands })
> 
> instead of
> 
> if(...){sequence; of; commands}
> else{another; Sequence; Of; Commands })
> 
> In this way the program becomes a little bit more difficult to read but
> I think that I am optimizing the performance.
> 
> The question is:
> 
> Am I actually optimizing the performance?

No. You can figure it out yourself by a little "simulation" (looping
over if() else() and ifelse()).
ifelse() is designed (and more efficient) for vectorized procedures.

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From marwan.khawaja at aub.edu.lb  Mon Apr 29 17:08:13 2002
From: marwan.khawaja at aub.edu.lb (Marwan Khawaja)
Date: Mon, 29 Apr 2002 08:08:13 -0700
Subject: [R] Hmisc library
Message-ID: <CLECJBOEBGOMOKJHJNDAOEDHCFAA.marwan.khawaja@aub.edu.lb>

Frank Harrell wrote:

>Date: Fri, 26 Apr 2002 10:18:42 -0400
>From: Frank E Harrell Jr <fharrell at virginia.edu>
>Subject: Re: [R] SAS and R

>Try the sas.get function in the Hmisc library.  Hmisc is available for
Linux/Unix/MacOSX and will soon be updated for >Windows.
>http://hesweb1.med.virginia.edu/biostat/s/Hmisc.html

I wonder how soon? -- some of us are still using the Windows OS.
Thanks Marwan

Frank Harrell

=======================
Marwan Khawaja						marwan.khawaja at aub.edu.lb
Center for Research on Population & Health	Tel:  +961 1 35 00 00-4668 (self)
Faculty of Health Sciences		    			+961 1 35 00 00-4640 (secr)
American University of Beirut					+961 1 35 00 00-2821 (home)
Beirut, Lebanon	 					Fax:  +961 1 47 44 70

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From fzoellne at techfak.uni-bielefeld.de  Mon Apr 29 09:38:25 2002
From: fzoellne at techfak.uni-bielefeld.de (Frank Gerrit Zoellner)
Date: Mon, 29 Apr 2002 09:38:25 +0200
Subject: [R] test
Message-ID: <20020429093825.A8029@hindemith.TechFak.Uni-Bielefeld.DE>

please ignore

Mfg
-- 
Frank G. Zoellner
AG Angewandte Informatik
Technische Fakult"at
Universit"at Bielefeld
phone: +49(0)521-106-2951
fax:   +49(0)521-106-2992
email: fzoellne at techfak.uni-bielefeld.de
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From siim at obs.ee  Mon Apr 29 09:40:08 2002
From: siim at obs.ee (Ott Toomet)
Date: Mon, 29 Apr 2002 09:40:08 +0200 (CEST)
Subject: [R] ifelse versus ...
In-Reply-To: <3CCC9370.29271069@lbl.gov>
Message-ID: <Pine.LNX.4.44.0204290932180.8059-100000@localhost.localdomain>

Hi,

On Sun, 28 Apr 2002, Francisco J Molina wrote:

  |I read somewhere that, instead of the structure if(...) else(...)
  |it is better to use the command ifelse(...,...,...).

  |The question is:
  |
  |Am I actually optimizing the performance?

I am sorry that I cannot answer exactly your question.  But:

-- you can find the speed of the alternate expressions using syste.time()

-- if() + else() and ifelse() are not quite the same.  The first form is for
scalar logic, the second for vector logic.  I think if you are using scalars
as your choice variables (e.g. block of expressions is conditional to a
scalar logical variable), then if()-else() and ifelse() do equally well.  If
you are looking for vector logic, i.e. the expressions for every element in
a vector depend on the corresponding element in a logical vector, then
ifelse should be faster, you need a cycle when doing the same with if() and
else().

When there are many conditions, one may get clearer code when writing as is
common in gauss, something like

a <- (b == 1)*expression1 + (b == 2)*expression2 + ....

I hope you got an idea.

Ott Toomet

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From alobo at ija.csic.es  Mon Apr 29 09:58:49 2002
From: alobo at ija.csic.es (Agustin Lobo)
Date: Mon, 29 Apr 2002 09:58:49 +0200 (MET DST)
Subject: [R] Image processing? Manipulating image data in R?
In-Reply-To: <1019997375.3ccbecbf66d8e@imp.molgen.mpg.de>
Message-ID: <Pine.OSF.3.96.1020428200025.13902C-100000@ija.csic.es>


Besides the pixmap facilities (from the help page:
" RGB pixmaps are three-dimensional arrays ..." and
" Grey and indexed pixmaps are matrices, the element `[1,1]'
     corresponds to the upper left corner as usual."),

I use to read in images in binary raw format
using raedBin() as R matrices. From there
on you can apply any R method you want. But
note that images are often too large for R. I have
a couple of functions to display matrices as grey and rgb 
images in R with some histogram stretching to
enhance contrast. Let me know if you are interested on them.

Also, look at message to r-help:

Date: Fri, 15 Mar 2002 10:15:57 -0800
From: "Jonathan Q. Li" <jonathan_li at agilent.com>

for a very interesting R function using tcl-tk.
(let me know if you want me to forward that message to you).

Finally, note that python has an image proc. library called
PIL and R has an interface to python.

N.B: Z-IMAGE looks like a very comprehensive image processing 
package in C that can be called as Splus
(and R?) functions thanks to an specific interface, but
you must pay for it.

Agus

Dr. Agustin Lobo
Instituto de Ciencias de la Tierra (CSIC)
Lluis Sole Sabaris s/n
08028 Barcelona SPAIN
tel 34 93409 5410
fax 34 93411 0012
alobo at ija.csic.es


On Sun, 28 Apr 2002 wolski at molgen.mpg.de wrote:

> Hi!
> I am looking for a R library by which i can load images (i found pixmap that
> allows it to do).
> But in addition i need methods to access the data, get them for example as an
> array  or matrix to do with this data some processing.
> 1. Is there a method in the pixmap library to access the matrix in which the
> image data is stored.
> 2. Is there an alternative library running under MS Windows?
> 
> Sincerely 
> Eryk
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mrufino at cmima.csic.es  Mon Apr 29 10:25:37 2002
From: mrufino at cmima.csic.es (Marta Rufino)
Date: Mon, 29 Apr 2002 10:25:37 +0200
Subject: [R] spreadsheet data import
Message-ID: <3.0.1.32.20020429102537.0081d430@cucafera.icm.csic.es>

Helo Tomas,


I just saw the R list email, sory for the lkat reply, but I think nobody
focused on this point, which might be important for "latin" users:

I think your problem as to do with the configuration of your computer. The
decimal separator "oficially" changes from contry to contry, so for example
in Spain it is a comma, although in UK it is a dot, as in R. So, you will
have this problem with most statistical packages,... In windows it is very
simple to solve it permenently:
you go to start> Control pannel> "configuracion regional" and either change
the country to UK, or manually change the character for decimal etc... 
This (as long as I know) does not affect your computer in nothing else,
except for the decimal separator!
BEst regards
Marta  




Hi colleages!

I want to import data from ms-excel and other spreadsheet formats (lotus,
etc). Does exist any way to do it within 
R? The main problem is that many spreadsheet data use comma as decimal
separator and not the point as needed in R 
(and many software for Linux), so importing data first as a tab separated
values does not solve this problem.

Thanks,

	Tom?s Revilla

    

><((((?>`?.??.???`?.?.???`?...?><((((?>`?.??.???`?.?.???`?...?><((((?>
`?.??.???`?.?.???`?...?><((((?>`?.??.???`?.?.???`?...?><((((?>`?.??.??

Marta Rufino

Centre Mediterrani d'Investigacions Marines i Ambientals
(CMIMA). CSIC
Passeig Maritim 37-49
08003  BARCELONA

Tfno:34 93 230 95 40
Tfax:34 93 230 95 55

><((((?>`?.??.???`?.?.???`?...?><((((?>`?.??.???`?.?.???`?...?><((((?>
`?.??.???`?.?.???`?...?><((((?>`?.??.???`?.?.???`?...?><((((?>`?.??.??

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From uleopold at science.uva.nl  Mon Apr 29 12:15:29 2002
From: uleopold at science.uva.nl (Ulrich Leopold)
Date: Mon, 29 Apr 2002 12:15:29 +0200
Subject: [R] append with write.table()
Message-ID: <3CCD1D41.6000206@science.uva.nl>

Dear list,

I get the following message while trying to append an object to a file. 
In addition it is not appended. Do you know why?

 > write.table(PoxAv, "/home/uleopold/lsk_PoxAv", append=TRUE , 
quote=FALSE, sep="\t")
Warning message:
appending column names to file in: write.table(PoxAv, 
"/home/uleopold/lsk_PoxAv", append = TRUE,

Regards, Ulrich
-- 
__________________________________________________

Ulrich Leopold MSc.

Department of Physical Geography
Institute for Biodiversity and Ecosystem Dynamics
Faculty of Science
University of Amsterdam
Nieuwe Achtergracht 166
NL-1018WV Amsterdam

Phone: +31-(0)20-525-7456 (7451 Secretary)
Fax:   +31-(0)20-525-7431
Email: uleopold at science.uva.nl
http://www.frw.uva.nl/soil/Welcome.html

Check us also out at:
Netherlands Centre for Geo-ecological Research
http://www.frw.uva.nl/icg



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Apr 29 12:30:45 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 29 Apr 2002 11:30:45 +0100 (BST)
Subject: [R] append with write.table()
In-Reply-To: <3CCD1D41.6000206@science.uva.nl>
Message-ID: <Pine.LNX.4.31.0204291125150.1366-100000@gannet.stats>

On Mon, 29 Apr 2002, Ulrich Leopold wrote:

> I get the following message while trying to append an object to a file.

You are writing a data frame to a file. You have asked that the column
names be written out.  That makes little sense in the middle of the file,
so you get a warning.  Appending is (more-or-less) only useful to add rows
to an existing data frame on a file.

> In addition it is not appended. Do you know why?

No, but then you haven't given us anything much to go on.
Here's a working example:

> library(MASS)
> data(hills)
> write.table(hills[1:20,], "hills.dat", quote=FALSE, sep="\t")
> write.table(hills[22:25,], "hills.dat", quote=FALSE, sep="\t",
              append=TRUE, col.names=FALSE)


>  > write.table(PoxAv, "/home/uleopold/lsk_PoxAv", append=TRUE ,
> quote=FALSE, sep="\t")
> Warning message:
> appending column names to file in: write.table(PoxAv,
> "/home/uleopold/lsk_PoxAv", append = TRUE,
>
> Ulrich Leopold MSc.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From r_stuff_online at hotmail.com  Mon Apr 29 12:55:31 2002
From: r_stuff_online at hotmail.com (Neil Osborne)
Date: Mon, 29 Apr 2002 10:55:31 +0000
Subject: [R] Building Rgui.exe with Visual Studio
Message-ID: <F140w3RJoyfBvW8XADQ0000275c@hotmail.com>

Thanks,

This will save me some time...
I have tested the windlg package. Is there anyway to "persit" the menus?. 
For instance, could I set R up so that it automatically re-creates my 
menu/dialogs upon startup. ?

Many thanks


>From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
>To: Neil Osborne <r_stuff_online at hotmail.com>
>CC: r-help at stat.math.ethz.ch
>Subject: Re: [R] Building Rgui.exe with Visual Studio
>Date: Mon, 29 Apr 2002 07:13:35 +0100 (GMT Daylight Time)
>
>It's a long time since anyone has reported trying to build R with VC++6.
>It has been done, *but* it fails make check because of problems with the
>handling of floating point numbers (e.g. it reported 3 < Inf as false, as I
>recall).
>
>It would have taken far less than 4 hours to set up and build using the
>documented procedures and tools.  In any case, it is unnecessary to build
>RGui to add custom menus, as the supplied package windlg shows.  And there
>are instructions in the sources on how to build such packages with VC++6.
>
>
>On Sun, 28 Apr 2002, Neil Osborne wrote:
>
> > Hi,
> >
> > I have downloaded and modified the source for rgui - because I wanted to 
>add
> > a few more custom menus to the GUI. I have almost got it completed, but 
>have
> > spent the last four hours trying to resolve the following issues (no pun
> > intended !)
> >
> >
> >
> > Linking...
> > R.lib(R.dll) : error LNK2005: _WatchCursor already defined in 
>cursors.obj
> > R.lib(R.dll) : error LNK2005: _ArrowCursor already defined in 
>cursors.obj
> > R.lib(R.dll) : error LNK2005: _R_Interactive already defined in main.obj
> >
> >
> > I have tried just about everything I can think of (including the obvious
> > commenting out the declspec dllimport statements in cursors.c) - to no
> > avail. Actually that works but it's a desperate hack and causes the app 
>to
> > crash later on!
> >
> > I've run out of ideas and I would appreciate a new set of eyes looking 
>at
> > this to see what I'm obviously doing wrong.
> >
> >
> > PS: I am compiling with MSDev Studio 6, OS  is Win2k
> >
> >
> > Regards
> >
> >
> > Redhat Hacker
> >
> > _________________________________________________________________
> >
> >
> > 
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > r-help mailing list -- Read 
>http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > Send "info", "help", or "[un]subscribe"
> > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> > 
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> >
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272860 (secr)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>
>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>Send "info", "help", or "[un]subscribe"
>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


_________________________________________________________________
Join the worlds largest e-mail service with MSN Hotmail. 


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Apr 29 12:57:34 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 29 Apr 2002 11:57:34 +0100 (BST)
Subject: [R] Building Rgui.exe with Visual Studio
In-Reply-To: <F140w3RJoyfBvW8XADQ0000275c@hotmail.com>
Message-ID: <Pine.LNX.4.31.0204291157010.22747-100000@gannet.stats>

On Mon, 29 Apr 2002, Neil Osborne wrote:

> Thanks,
>
> This will save me some time...
> I have tested the windlg package. Is there anyway to "persit" the menus?.
> For instance, could I set R up so that it automatically re-creates my
> menu/dialogs upon startup. ?

Make that part of your .Rprofile: see ?Startup, or read R-intro!

>
> Many thanks
>
>
> >From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> >To: Neil Osborne <r_stuff_online at hotmail.com>
> >CC: r-help at stat.math.ethz.ch
> >Subject: Re: [R] Building Rgui.exe with Visual Studio
> >Date: Mon, 29 Apr 2002 07:13:35 +0100 (GMT Daylight Time)
> >
> >It's a long time since anyone has reported trying to build R with VC++6.
> >It has been done, *but* it fails make check because of problems with the
> >handling of floating point numbers (e.g. it reported 3 < Inf as false, as I
> >recall).
> >
> >It would have taken far less than 4 hours to set up and build using the
> >documented procedures and tools.  In any case, it is unnecessary to build
> >RGui to add custom menus, as the supplied package windlg shows.  And there
> >are instructions in the sources on how to build such packages with VC++6.
> >
> >
> >On Sun, 28 Apr 2002, Neil Osborne wrote:
> >
> > > Hi,
> > >
> > > I have downloaded and modified the source for rgui - because I wanted to
> >add
> > > a few more custom menus to the GUI. I have almost got it completed, but
> >have
> > > spent the last four hours trying to resolve the following issues (no pun
> > > intended !)
> > >
> > >
> > >
> > > Linking...
> > > R.lib(R.dll) : error LNK2005: _WatchCursor already defined in
> >cursors.obj
> > > R.lib(R.dll) : error LNK2005: _ArrowCursor already defined in
> >cursors.obj
> > > R.lib(R.dll) : error LNK2005: _R_Interactive already defined in main.obj
> > >
> > >
> > > I have tried just about everything I can think of (including the obvious
> > > commenting out the declspec dllimport statements in cursors.c) - to no
> > > avail. Actually that works but it's a desperate hack and causes the app
> >to
> > > crash later on!
> > >
> > > I've run out of ideas and I would appreciate a new set of eyes looking
> >at
> > > this to see what I'm obviously doing wrong.
> > >
> > >
> > > PS: I am compiling with MSDev Studio 6, OS  is Win2k
> > >
> > >
> > > Regards
> > >
> > >
> > > Redhat Hacker
> > >
> > > _________________________________________________________________
> > >
> > >
> > >
> >-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> > > r-help mailing list -- Read
> >http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> > > Send "info", "help", or "[un]subscribe"
> > > (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> > >
> >_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> > >
> >
> >--
> >Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >University of Oxford,             Tel:  +44 1865 272861 (self)
> >1 South Parks Road,                     +44 1865 272860 (secr)
> >Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> >
> >-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> >r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> >Send "info", "help", or "[un]subscribe"
> >(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> >_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>
>
> _________________________________________________________________
> Join the worlds largest e-mail service with MSN Hotmail.
> http://www.hotmail.com
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From james.lindsey at luc.ac.be  Mon Apr 29 13:03:39 2002
From: james.lindsey at luc.ac.be (Jim Lindsey)
Date: Mon, 29 Apr 2002 13:03:39 +0200 (MET DST)
Subject: [R] Error in ORDGLM function
In-Reply-To: <OF677FE3CE.C9A1CEB2-ON85256BA7.0073E009@infra.fub.com> from "kamal.desai@wachovia.com" at Apr 26, 2002 05:14:31 PM
Message-ID: <200204291103.NAA03809@luc.ac.be>

> 
> I am trying this simple  model.
> 
> Following is the code:
> 
> newrate <- c(0,1,2,0,1,2,0,1,2,0,1,2)
> totalast <- c(100,200,300,120,215,280,75,145,255,125,275,310)
> ordglm(newrate~totalast,link="logit",maxiter=100, weights=1)
> 
> It runs for few seconds and get the error back
> 
> Error in ordglm(newrate ~ totalast, link = "logit", maxiter = 100, weights = 1) :
>         Object "PearsRes" not found

That error is not from my code: I do not have a PearsRes. Your three
lines work for me:

> library(gnlm)
Loading required package: rmutil 
> newrate <- c(0,1,2,0,1,2,0,1,2,0,1,2)
> totalast <- c(100,200,300,120,215,280,75,145,255,125,275,310)
> ordglm(newrate~totalast,link="logit",maxiter=100, weights=1)

Call:
ordglm(newrate ~ totalast, link = "logit", maxiter = 100, weights = 1)

-Log likelihood    149.5272 
AIC                152.5272 
Iterations         5 

Location coefficients
             estimate     s.e.
(Intercept)  -51.3812  0.05031
totalast       0.1969  3.41556

Intercept contrasts
      estimate   s.e.
b[2]    -5.513  11.46

Correlation matrix
        1       2       3
1  1.0000 -0.9890  0.7268
2 -0.9890  1.0000 -0.8065
3  0.7268 -0.8065  1.0000
> 

Jim

> 
> I tried to use the example in the package
> 
> # McCullagh (1980) JRSS B42, 109-142
> # tonsil size: 2x3 contingency table
> y <- c(0:2,0:2)
> carrier <- gl(2,3,6)
> wt <- c(19,29,24,497,560,269)
> ordglm(y~carrier, weights=wt)
> 
> 
> It works fine.  So everything is installed correctly.
> 
> may be it has something to do with the weight?
> 
> Any help is welcome.
> 
> Thanks a lot.
> 
> Kamal Desai
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From amurta at ipimar.pt  Mon Apr 29 15:28:18 2002
From: amurta at ipimar.pt (Alberto Murta)
Date: Mon, 29 Apr 2002 13:28:18 +0000
Subject: [R] masking functions
Message-ID: <3CCD4A72.FA2EBAC1@ipimar.pt>

Dear all

I was writing some code that needed functions from packages 'MASS' and
'CircStats', and I received a warning saying that the function
'eqscplot' in one of the packages was masked by another 'eqscplot' from
the other package (in fact 'eqscplot' from 'CircStats' seems a short
version of 'eqscplot' from 'MASS'). This masking of functions may become
a serious problem as the number of packages in CRAN grows. Maybe an
alphabetical list of all function names from all packages in CRAN could
be made available in the web-page, so that in the future people could
avoid using names that already exist when submitting packages to CRAN.

-- 
                           Alberto G. Murta                      
           IPIMAR - Institute of Fisheries and Sea Research
            Avenida de Brasilia, 1449-006 Lisboa, Portugal       
Tel:+351 213027062; Fax:+351 213015849; http://www.ipimar.pt/pelagicos/
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From uleopold at science.uva.nl  Mon Apr 29 13:59:03 2002
From: uleopold at science.uva.nl (Ulrich Leopold)
Date: Mon, 29 Apr 2002 13:59:03 +0200
Subject: [R] append with write.table()
References: <Pine.LNX.4.31.0204291125150.1366-100000@gannet.stats>
Message-ID: <3CCD3587.7070700@science.uva.nl>

>>I get the following message while trying to append an object to a file.
>>
> 
> You are writing a data frame to a file. You have asked that the column
> names be written out.  That makes little sense in the middle of the file,
> so you get a warning.  Appending is (more-or-less) only useful to add rows
> to an existing data frame on a file.
> 
> 
>>In addition it is not appended. Do you know why?
>>
> 
> No, but then you haven't given us anything much to go on.
> Here's a working example:
> 
> 
>>library(MASS)
>>data(hills)
>>write.table(hills[1:20,], "hills.dat", quote=FALSE, sep="\t")
>>write.table(hills[22:25,], "hills.dat", quote=FALSE, sep="\t",
>>
>               append=TRUE, col.names=FALSE)
> 
> 
> 
>>write.table(PoxAv, "/home/uleopold/lsk_PoxAv", append=TRUE ,
>>quote=FALSE, sep="\t")
>>Warning message:
>>appending column names to file in: write.table(PoxAv,
>>"/home/uleopold/lsk_PoxAv", append = TRUE,
>>
>>Ulrich Leopold MSc.

 
Thanks Brian for pointing out.I think was wrong in what I wanted to do.

I wanted to append columns not rows. I thought it is possible with that command.

Is there a command which is similar to that but adding columns to a file or an object?

Ulrich


-- 
__________________________________________________

Ulrich Leopold MSc.

Department of Physical Geography
Institute for Biodiversity and Ecosystem Dynamics
Faculty of Science
University of Amsterdam
Nieuwe Achtergracht 166
NL-1018WV Amsterdam

Phone: +31-(0)20-525-7456 (7451 Secretary)
Fax:   +31-(0)20-525-7431
Email: uleopold at science.uva.nl
http://www.frw.uva.nl/soil/Welcome.html

Check us also out at:
Netherlands Centre for Geo-ecological Research
http://www.frw.uva.nl/icg



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From marcos_sanches at gallup.com  Mon Apr 29 14:30:59 2002
From: marcos_sanches at gallup.com (Marcos Sanches)
Date: Mon, 29 Apr 2002 09:30:59 -0300
Subject: [R] Circular graphics
Message-ID: <000001c1ef79$b81d6520$b454a8c0@gallup.com.br>


Hello list!

I have a dataset with circular data, the angles are in radians. I trying to
plot the cases with circ.plot but it is not working. I am using the
following command:

circ.plot(data1$radian, stack=TRUE, bins=150)

and I am having a circular plot with points only in the first quadrant, but
I have the variable radian going from 0.044 to 6.240 so I expect to have
points all over the circle. The "rose.diag" works fine but it gives me a
histogram inside the circle, what I dont want.

Any help would be apreciated.

Thanks,

Marcos

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From andy_liaw at merck.com  Mon Apr 29 14:52:43 2002
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 29 Apr 2002 08:52:43 -0400
Subject: [R] append with write.table()
Message-ID: <51F9C42DA15CD311BD220008C707D81906FFC276@usrymx10.merck.com>

If you are on an Unix or Linux system (or have the cygwin tools under
Windoze), you can write it to a separate file, then use 'paste' to join them
column-wise at the shell.

Andy

> -----Original Message-----
> From: Ulrich Leopold [mailto:uleopold at science.uva.nl]
> Sent: Monday, April 29, 2002 7:59 AM
> To: ripley at stats.ox.ac.uk
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] append with write.table()
> 
> 
> >>I get the following message while trying to append an 
> object to a file.
> >>
> > 
> > You are writing a data frame to a file. You have asked that 
> the column
> > names be written out.  That makes little sense in the 
> middle of the file,
> > so you get a warning.  Appending is (more-or-less) only 
> useful to add rows
> > to an existing data frame on a file.
> > 
> > 
> >>In addition it is not appended. Do you know why?
> >>
> > 
> > No, but then you haven't given us anything much to go on.
> > Here's a working example:
> > 
> > 
> >>library(MASS)
> >>data(hills)
> >>write.table(hills[1:20,], "hills.dat", quote=FALSE, sep="\t")
> >>write.table(hills[22:25,], "hills.dat", quote=FALSE, sep="\t",
> >>
> >               append=TRUE, col.names=FALSE)
> > 
> > 
> > 
> >>write.table(PoxAv, "/home/uleopold/lsk_PoxAv", append=TRUE ,
> >>quote=FALSE, sep="\t")
> >>Warning message:
> >>appending column names to file in: write.table(PoxAv,
> >>"/home/uleopold/lsk_PoxAv", append = TRUE,
> >>
> >>Ulrich Leopold MSc.
> 
>  
> Thanks Brian for pointing out.I think was wrong in what I 
> wanted to do.
> 
> I wanted to append columns not rows. I thought it is possible 
> with that command.
> 
> Is there a command which is similar to that but adding 
> columns to a file or an object?
> 
> Ulrich
> 
> 
> -- 
> __________________________________________________
> 
> Ulrich Leopold MSc.
> 
> Department of Physical Geography
> Institute for Biodiversity and Ecosystem Dynamics
> Faculty of Science
> University of Amsterdam
> Nieuwe Achtergracht 166
> NL-1018WV Amsterdam
> 
> Phone: +31-(0)20-525-7456 (7451 Secretary)
> Fax:   +31-(0)20-525-7431
> Email: uleopold at science.uva.nl
> http://www.frw.uva.nl/soil/Welcome.html
> 
> Check us also out at:
> Netherlands Centre for Geo-ecological Research
> http://www.frw.uva.nl/icg
> 
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-.-.-.-.-.-.-.-
> r-help mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: 
> r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._._._._._._._._
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named in this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.

==============================================================================

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Corey.Moffet at ttu.edu  Mon Apr 29 14:56:27 2002
From: Corey.Moffet at ttu.edu (Moffet, Corey)
Date: Mon, 29 Apr 2002 07:56:27 -0500
Subject: [R] Lotos 1-2-3 date to POSIXct
Message-ID: <938690ACF269D311928B0090279C2772E91EFD@cyclops.net.ttu.edu>

I have some data that was created for import into a Lotus 1-2-3 spreadsheet
and on of the columns is time.  The
time is akin to Julian were the value 1 is mapped "01-Jan-00 12:00:00 AM" in
Lotus 1-2-3.  Is there a function in an R package that can convert this
numeric vector to a POSIXct vector?


With best wishes and kind regards I am

Sincerely,

Corey A. Moffet
Instructor
Department of Range, Wildlife, and Fisheries Management
Mail Stop 2125
Texas Tech University
Lubbock, Texas 79409-2125
 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Apr 29 15:18:09 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 29 Apr 2002 15:18:09 +0200
Subject: [R] Lotos 1-2-3 date to POSIXct
In-Reply-To: <938690ACF269D311928B0090279C2772E91EFD@cyclops.net.ttu.edu>
References: <938690ACF269D311928B0090279C2772E91EFD@cyclops.net.ttu.edu>
Message-ID: <x2it6ay772.fsf@blueberry.kubism.ku.dk>

"Moffet, Corey" <Corey.Moffet at ttu.edu> writes:

> I have some data that was created for import into a Lotus 1-2-3 spreadsheet
> and on of the columns is time.  The
> time is akin to Julian were the value 1 is mapped "01-Jan-00 12:00:00 AM" in
> Lotus 1-2-3.  Is there a function in an R package that can convert this
> numeric vector to a POSIXct vector?

Units are seconds? Subtract 1 and add "01-Jan-00 12:00:00 AM" using
ISOdate. Otherwise convert units, cf:

> ISOdate(2000,1,1)+2000*24*60*60 # 2000 days after the Millennium
[1] "2005-06-23 14:00:00 MET DST" 


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Apr 29 15:44:25 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 29 Apr 2002 14:44:25 +0100 (BST)
Subject: [R] masking functions
In-Reply-To: <3CCD4A72.FA2EBAC1@ipimar.pt>
Message-ID: <Pine.LNX.4.31.0204291425150.26859-100000@gannet.stats>

On Mon, 29 Apr 2002, Alberto Murta wrote:

> Dear all
>
> I was writing some code that needed functions from packages 'MASS' and
> 'CircStats', and I received a warning saying that the function
> 'eqscplot' in one of the packages was masked by another 'eqscplot' from
> the other package (in fact 'eqscplot' from 'CircStats' seems a short
> version of 'eqscplot' from 'MASS'). This masking of functions may become
> a serious problem as the number of packages in CRAN grows. Maybe an
> alphabetical list of all function names from all packages in CRAN could
> be made available in the web-page, so that in the future people could
> avoid using names that already exist when submitting packages to CRAN.

That would almost impossible to keep up to date.  Note that masking is
only a problem if packages are used together.

I really see no reason for CircStats to include an old version of my code
without attribution, though, espcially with the help message

     eqscplot should not be called by the users.

and suggest it be removed.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From claudio at unive.it  Mon Apr 29 16:41:50 2002
From: claudio at unive.it (Claudio Agostinelli)
Date: Mon, 29 Apr 2002 16:41:50 +0200 (CEST)
Subject: [R] masking functions
In-Reply-To: <Pine.LNX.4.31.0204291425150.26859-100000@gannet.stats>
Message-ID: <Pine.LNX.4.33L2.0204291625130.27328-100000@linaria.dst.unive.it>


Dear all,

the problem arise since the original CircStats package (the Splus version)
distribute a version of eqscplot function without help and copyright
statement. That is why I have considered it as an internal function
from this package.

Now that, thanks to Prof. Ripley, I know where the function come from I
will erase the function from the next release of the package and include
MASS package in the required package.

Claudio Agostinelli



On Mon, 29 Apr 2002 ripley at stats.ox.ac.uk wrote:

> On Mon, 29 Apr 2002, Alberto Murta wrote:
>
> > Dear all
> >
> > I was writing some code that needed functions from packages 'MASS' and
> > 'CircStats', and I received a warning saying that the function
> > 'eqscplot' in one of the packages was masked by another 'eqscplot' from
> > the other package (in fact 'eqscplot' from 'CircStats' seems a short
> > version of 'eqscplot' from 'MASS'). This masking of functions may become
> > a serious problem as the number of packages in CRAN grows. Maybe an
> > alphabetical list of all function names from all packages in CRAN could
> > be made available in the web-page, so that in the future people could
> > avoid using names that already exist when submitting packages to CRAN.
>
> That would almost impossible to keep up to date.  Note that masking is
> only a problem if packages are used together.
>
> I really see no reason for CircStats to include an old version of my code
> without attribution, though, espcially with the help message
>
>      eqscplot should not be called by the users.
>
> and suggest it be removed.
>
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rangrej at exchange.cheo.on.ca  Mon Apr 29 17:01:56 2002
From: rangrej at exchange.cheo.on.ca (Rangrej, Jagadish)
Date: Mon, 29 Apr 2002 11:01:56 -0400
Subject: [R] Organizing the help files in a package
Message-ID: <A032D3A4B7F0D411B9360008C71E3DA5038D4CF8@CHEONT3>

Dear all!!

I am using R1.4.1 on windows 98.
I had been trying to organize the package and has already been able to
document some of the functions in to .Rd (R documentation) files. From these
.Rd files I generated plain text files as well as html files.
I have also given the 00Index file in each of the directories:
html/
help/
data/
man/

Problem: I don't get the help using comand "help" after loading the package
using library command. Some how the html index gets updated and the help is
available in the link of packages in html help pages.

I tried using the command:
> Rcmd build,
gives the following error
* checking for file `pubbias/DESCRIPTION' ... OK
* preparing `pubbias':
* checking whether `INDEX' is up-to-date ... OK
* checking whether `data/00Index' is up-to-date ... O
* removing junk files
* building `pubbias_1.0.tar.gz'
Bad command or file name
Bad command or file name

So I organized it mannually to pubbias.zip.

any help will be greatly appreciated.

Thanking you,
-Jagadish
Jagadish Rangrej ( Statistician )
CHEO Research Institute, Ottawa, ON
613-7383951



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Zhuanshi at kjist.ac.kr  Mon Apr 29 18:10:20 2002
From: Zhuanshi at kjist.ac.kr (Zhuanshi He)
Date: Tue, 30 Apr 2002 0:10:20 +0800
Subject: [R] who has experience to do peakfit using R?
Message-ID: <200204291512.RAA08824@stat.math.ethz.ch>

Hi All,

I know we can write some curvefit procedure using R. How about peakfit?

Thx.

Z. He


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ricardo at icmc.sc.usp.br  Mon Apr 29 17:13:30 2002
From: ricardo at icmc.sc.usp.br (ricardo@icmc.sc.usp.br)
Date: Mon, 29 Apr 2002 12:13:30 -0300 (EST)
Subject: [R] New Realease
Message-ID: <1020093210.3ccd631a09c96@taba2.icmc.sc.usp.br>


Dear All
I'm currently using the R 1.4 for Window 2000. Now I would like to update
my system to new realease 1.5. I downloaded the base, now how I need to
procced in order to install it?
Sorry the silly question, but this is my first upgrade.
Thanks a lot
Rick

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Mon Apr 29 17:17:53 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 29 Apr 2002 08:17:53 -0700 (PDT)
Subject: [R] Explanation of Error Diagnostics
In-Reply-To: <F41hriS325H21qJGyXN00001f25@hotmail.com>
Message-ID: <Pine.A41.4.44.0204290811330.41800-100000@homer21.u.washington.edu>

On Sat, 27 Apr 2002, graham lawrence wrote:

> Hi,
>
> Is there any documentation to explain R's error diagnostics, e.g. messages
> like
>
> >source("../src/sources/routine.R")
> Read 8 records
> Read 2 records
> Error in "[<-"(*tmp*, !test, value = rep(no, length = length(ans))[!test]) :
>         incompatible types
>
> The nature of the problem incompatible types, is clear; but I'm more
> interested in its location, and feel that the cryptic elements
> "[<-"(*tmp*, !test, value = rep(no, length = length(ans))[!test])
> probably hold the key to finding it.
>

The first step is the traceback() function, which lists the function that
"[<-" was called from, the function that was called from, and so on up to
the source() function. It may then be obvious where to look.

Assignment functions are initially even more obscure than other functions
because what you see is not the actual call.  The actual call would have
been
  somevector[!test]<- rep(no, length = length(ans))[!test]
and while you can't work out the name of the vector, the rest may look
familiar.

Finally, in R1.5.0 look at the recover() function
  options(error=recover)
launches the browser when an error occurs, and options(error=NULL) turns
this off. In older versions of R, or for saving debugging information for
later examination look at dump.frames() and debugger().


	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Mon Apr 29 17:28:32 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 29 Apr 2002 08:28:32 -0700 (PDT)
Subject: [R] append with write.table()
In-Reply-To: <3CCD3587.7070700@science.uva.nl>
Message-ID: <Pine.A41.4.44.0204290826290.41800-100000@homer21.u.washington.edu>

On Mon, 29 Apr 2002, Ulrich Leopold wrote:

>
> Thanks Brian for pointing out.I think was wrong in what I wanted to do.
>
> I wanted to append columns not rows. I thought it is possible with that
> command.
>
> Is there a command which is similar to that but adding columns to a file
> or an object?
>

cbind() will add columns to an object.

Adding columns to a file requires reading the file in and writing it out
again (it has to, since the new data are mixed in with the old on the
disk).

If the whole file is too big to read in you could read in a few lines at a
time with connections, use cbind() to add the extra columns, and write
those lines out to a new file.

	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Mon Apr 29 17:29:33 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 29 Apr 2002 17:29:33 +0200
Subject: [R] New Realease
References: <1020093210.3ccd631a09c96@taba2.icmc.sc.usp.br>
Message-ID: <3CCD66DD.EC4C0EE9@statistik.uni-dortmund.de>

ricardo at icmc.sc.usp.br wrote:
> 
> Dear All
> I'm currently using the R 1.4 for Window 2000. Now I would like to update
> my system to new realease 1.5. I downloaded the base, now how I need to
> procced in order to install it?
> Sorry the silly question, but this is my first upgrade.

Well, I guess you have downloaded the sources.
If you don't want to compile from source as mentioned in the INSTALL
file, just wait a few days until the first binary release for windows
will be available.

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Mon Apr 29 17:32:54 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 29 Apr 2002 17:32:54 +0200
Subject: [R] who has experience to do peakfit using R?
References: <200204291512.RAA08824@stat.math.ethz.ch>
Message-ID: <3CCD67A6.D8EA97A6@statistik.uni-dortmund.de>

Zhuanshi He wrote:
> 
> Hi All,
> 
> I know we can write some curvefit procedure using R. How about peakfit?

Please excuse my ignorance, but what does "curvefit" / "peakfit" mean?
If you can write the first "procedure" (= function ?), why can't you
write the second one?

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From o.christensen at lancaster.ac.uk  Mon Apr 29 17:53:30 2002
From: o.christensen at lancaster.ac.uk (Ole Christensen)
Date: Mon, 29 Apr 2002 16:53:30 +0100
Subject: [R] code optimization
References: <5.0.2.1.0.20020624100755.01e2d008@deimos.tc.uaslp.mx>
Message-ID: <3CCD6C7A.B455B595@lancs.ac.uk>

A suggestion :

eval.delta <- function(delta){
      cat("VALUES\n")
      numbers <- 1:length(delta)
      case1 <- numbers[delta <= 2]
      case2 <- numbers[delta>2 & delta <= 4]
      case3 <- numbers[delta>4 & delta <= 7]
      case4 <- numbers[delta>7 & delta <= 10]
      case5 <- numbers[delta>10]
      cat("<= 2 (no credible
evidence)\t",length(case1),"\t",delta[case1],"\n")
      cat("> 2 y <= 4 (weak
evidence)\t",length(case2),"\t",delta[case2],"\n")
      cat("> 4 y <= 7 (definite
evidence)\t",length(case3),"\t",delta[case3],"\n")
      cat("> 7 y <= 10 (strong
evidence)\t",length(case4),"\t",delta[case4],"\n")
      cat("> 10 (very strong
evidence)\t",length(case5),"\t",delta[case5],"\n")
      cat("\nMODELS\n")
      cat("<= 2 (no credible evidence)\t",length(case1),"\t",case1,"\n")
      cat("> 2 y <= 4 (weak evidence)\t",length(case2),"\t",case2,"\n")
      cat("> 4 y <= 7 (definite
evidence)\t",length(case3),"\t",case3,"\n")
      cat("> 7 y <= 10 (strong
evidence)\t",length(case4),"\t",case4,"\n")
      cat("> 10 (very strong evidence)\t",length(case5),"\t",case5,"\n")
}


Ole


"Peter B. Mandeville" wrote:
> 
> I have a function "eval.delta" which does what I want but isn't very
> elegant. I have consulted the R documents, MASS, and S Programming. Is
> there a practical way to optimize the code? Thank you very much.
> 
> Peter B.
> 
> Function:
> 
> eval.delta <- function(delta){
>      cat("VALUES\n")
>      vlr <- NULL
>      k <- 0
>      for(j in 1:length(delta)) if(delta[j] <= 2){
>          k <- k+1
>          vlr[k] <- delta[j]
>      }
>      cat("<= 2 (no credible evidence)\t",k,"\t",vlr,"\n")
>      vlr <- NULL
>      k <- 0
>      for(j in 1:length(delta)) if(delta[j]>2 & delta[j] <= 4){
>          k <- k+1
>          vlr[k] <- delta[j]
>      }
>      cat("> 2 y <= 4 (weak evidence)\t",k,"\t",vlr,"\n")
>      vlr <- NULL
>      k <- 0
>      for(j in 1:length(delta)) if(delta[j]>4 & delta[j] <= 7){
>          k <- k+1
>          vlr[k] <- delta[j]
>      }
>      cat("> 4 y <= 7 (definite evidence)\t",k,"\t",vlr,"\n")
>      vlr <- NULL
>      k <- 0
>      for(j in 1:length(delta)) if(delta[j]>7 & delta[j] <= 10){
>          k <- k+1
>          vlr[k] <- delta[j]
>      }
>      cat("> 7 y <= 10 (strong evidence)\t",k,"\t",vlr,"\n")
>      vlr <- NULL
>      k <- 0
>      for(j in 1:length(delta)) if(delta[j]>10){
>          k <- k+1
>          vlr[k] <- delta[j]
>      }
>      cat("> 10 (very strong evidence)\t",k,"\t",vlr,"\n")
>      cat("\nMODELS\n")
>      vlr <- NULL
>      k <- 0
>      for(j in 1:length(delta)) if(delta[j] <= 2){
>          k <- k+1
>          vlr[k] <- j
>      }
>      cat("<= 2 (no credible evidence)\t",k,"\t",vlr,"\n")
>      vlr <- NULL
>      k <- 0
>      for(j in 1:length(delta)) if(delta[j]>2 & delta[j] <= 4){
>          k <- k+1
>          vlr[k] <- j
>      }
>      cat("> 2 y <= 4 (weak evidence)\t",k,"\t",vlr,"\n")
>      vlr <- NULL
>      k <- 0
>      for(j in 1:length(delta)) if(delta[j]>4 & delta[j] <= 7){
>          k <- k+1
>          vlr[k] <- j
>      }
>      cat("> 4 y <= 7 (definite evidence)\t",k,"\t",vlr,"\n")
>      vlr <- NULL
>      k <- 0
>      for(j in 1:length(delta)) if(delta[j]>7 & delta[j] <= 10){
>          k <- k+1
>          vlr[k] <- j
>      }
>      cat("> 7 y <= 10 (strong evidence)\t",k,"\t",vlr,"\n")
>      vlr <- NULL
>      k <- 0
>      for(j in 1:length(delta)) if(delta[j]>10){
>          k <- k+1
>          vlr[k] <- j
>      }
>      cat("> 10 (very strong evidence)\t",k,"\t",vlr,"\n")
> }
> 
> Data:
> 
>  > delta <- c(0,1.4,2.3,4.5,2.3,8.9,12.4,6.4,7.4,11.5,2,2)
> 
> Function Call and Output:
> 
>  > eval.delta(delta)
> VALUES
> <= 2 (no credible evidence)      4       0 1.4 2 2
>  > 2 y <= 4 (weak evidence)       2       2.3 2.3
>  > 4 y <= 7 (definite evidence)   2       4.5 6.4
>  > 7 y <= 10 (strong evidence)    2       8.9 7.4
>  > 10 (very strong evidence)      2       12.4 11.5
> 
> MODELS
> <= 2 (no credible evidence)      4       1 2 11 12
>  > 2 y <= 4 (weak evidence)       2       3 5
>  > 4 y <= 7 (definite evidence)   2       4 8
>  > 7 y <= 10 (strong evidence)    2       6 9
>  > 10 (very strong evidence)      2       7 10
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
Ole F. Christensen
Department of Mathematics and Statistics
Fylde College, Lancaster University 
Lancaster, LA1 4YF, England
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Mon Apr 29 17:51:47 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 29 Apr 2002 17:51:47 +0200
Subject: [R] Organizing the help files in a package
References: <A032D3A4B7F0D411B9360008C71E3DA5038D4CF8@CHEONT3>
Message-ID: <3CCD6C13.3817E979@statistik.uni-dortmund.de>



"Rangrej, Jagadish" wrote:
> 
> Dear all!!
> 
> I am using R1.4.1 on windows 98.
> I had been trying to organize the package and has already been able to
> document some of the functions in to .Rd (R documentation) files. From these
> .Rd files I generated plain text files as well as html files.

That will be done automatically by Rcmd INSTALL (for an already builded
package) and is not needed before Rcmd BUILD.


> I have also given the 00Index file in each of the directories:
> html/
> help/
> data/
> man/

The first two are not needed, but a directory called "R" is missing
which should contain your *.R files.

 
> Problem: I don't get the help using comand "help" after loading the package
> using library command. Some how the html index gets updated and the help is
> available in the link of packages in html help pages.
> 
> I tried using the command:
> > Rcmd build,
> gives the following error
> * checking for file `pubbias/DESCRIPTION' ... OK
> * preparing `pubbias':
> * checking whether `INDEX' is up-to-date ... OK
> * checking whether `data/00Index' is up-to-date ... O
> * removing junk files
> * building `pubbias_1.0.tar.gz'
> Bad command or file name
> Bad command or file name
> 
> So I organized it mannually to pubbias.zip.
> 
> any help will be greatly appreciated.

Do you have installed all the tools needed to build a package?


For details please read the manual "Writing R Extensions".


Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Mon Apr 29 18:08:31 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 29 Apr 2002 09:08:31 -0700 (PDT)
Subject: [R] code optimization
In-Reply-To: <5.0.2.1.0.20020624100755.01e2d008@deimos.tc.uaslp.mx>
Message-ID: <Pine.A41.4.44.0204290901220.41800-100000@homer21.u.washington.edu>

On Mon, 24 Jun 2002, Peter B. Mandeville wrote:

> I have a function "eval.delta" which does what I want but isn't very
> elegant. I have consulted the R documents, MASS, and S Programming. Is
> there a practical way to optimize the code? Thank you very much.
>
<snip>
> Function Call and Output:
>
>  > eval.delta(delta)
> VALUES
> <= 2 (no credible evidence)      4       0 1.4 2 2
>  > 2 y <= 4 (weak evidence)       2       2.3 2.3
>  > 4 y <= 7 (definite evidence)   2       4.5 6.4
>  > 7 y <= 10 (strong evidence)    2       8.9 7.4
>  > 10 (very strong evidence)      2       12.4 11.5
>
> MODELS
> <= 2 (no credible evidence)      4       1 2 11 12
>  > 2 y <= 4 (weak evidence)       2       3 5
>  > 4 y <= 7 (definite evidence)   2       4 8
>  > 7 y <= 10 (strong evidence)    2       6 9
>  > 10 (very strong evidence)      2       7 10
>

You can get something like this, but not quite the same, fairly easily:
   labels<-c("<= 2  (no credible evidence)",
             " 2-4  (weak evidence) ",
             " 4-7  (definite evidence)",
             " 7-10 (strong evidence)",
              ">10  (very strong evidence)")
    classes<-cut(delta,c(0,2,4,7,10,Inf),include.lowest=TRUE,labels=labels)
    models<-by(1:length(delta),list(level=classes),
		function(x) c(n=length(x),x))
    values<-by(1:length(delta),list(level=classes),
                function(x) c(n=length(x),x))


So, for example, models prints as
> models
level: <= 2  (no credible evidence)
 n
 4  1  2 11 12
------------------------------------------------------------
level:  2-4  (weak evidence)
n
2 3 5
------------------------------------------------------------
level:  4-7  (definite evidence)
n
2 4 8
------------------------------------------------------------
level:  7-10 (strong evidence)
n
2 6 9
------------------------------------------------------------
level: >10  (very strong evidence)
 n
 2  7 10



	-thomas


Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From psu17772 at hotmail.com  Mon Apr 29 18:46:03 2002
From: psu17772 at hotmail.com (sonchawan tamkaew)
Date: Mon, 29 Apr 2002 16:46:03 +0000
Subject: [R] data
Message-ID: <F20e7lLFIseSYU864Gh00000656@hotmail.com>

Hello,

Suppose I have a matrix with 1000 rows and 3 columns, 1st column date, 2nd 
one is type, 3rd one is yield. So it looks like this.

date        type    yield
01/01/01    A       3.4
01/01/01    B       3.2
01/01/01    C       1.8
02/01/01    B       3.3
03/01/01    A       3.3
03/01/01    B       3.4
04/01/01    A       3.5
...         .       ...
...         .       ...

I would like to have the data look like this instead.

date         A     B    C
01/01/01    3.4   3.2  1.8
02/01/01          3.3
03/01/01    3.3   3.4
04/01/01    3.5

The missing values could be either blank or NA.

How could I do this without writing for/if loop or do it in Excel before?

Thank you very much in advance.

Sonchawan

_________________________________________________________________


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From mail-list at linaria.dst.unive.it  Mon Apr 29 19:05:03 2002
From: mail-list at linaria.dst.unive.it (Claudio Agostinelli)
Date: Mon, 29 Apr 2002 19:05:03 +0200 (CEST)
Subject: [R] Circular graphics
In-Reply-To: <000001c1ef79$b81d6520$b454a8c0@gallup.com.br>
Message-ID: <Pine.LNX.4.33L2.0204291901230.29004-100000@linaria.dst.unive.it>

Dear Marcos,

there was a problem with the first release of the CircStats function
circ.plot, please download the latest version available in CRAN. If you
still have problem can you please send me the data set and the code
so I can take a look to it.

Best,
Claudio Agostinelli


On Mon, 29 Apr 2002, Marcos Sanches wrote:

>
> Hello list!
>
> I have a dataset with circular data, the angles are in radians. I trying to
> plot the cases with circ.plot but it is not working. I am using the
> following command:
>
> circ.plot(data1$radian, stack=TRUE, bins=150)
>
> and I am having a circular plot with points only in the first quadrant, but
> I have the variable radian going from 0.044 to 6.240 so I expect to have
> points all over the circle. The "rose.diag" works fine but it gives me a
> histogram inside the circle, what I dont want.
>
> Any help would be apreciated.
>
> Thanks,
>
> Marcos
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From james.holtman at convergys.com  Mon Apr 29 19:32:33 2002
From: james.holtman at convergys.com (james.holtman@convergys.com)
Date: Mon, 29 Apr 2002 13:32:33 -0400
Subject: [R] code optimization
Message-ID: <OF698C35F0.9FBD104C-ON85256BAA.00605376@cbis.com>


Try this:

 split(delta,cut(delta, breaks=c(0,2,4,7,10,max(delta)),include.lowest=T))
$"[0,2]"
[1] 0.0 1.4 2.0 2.0

$"(2,4]"
[1] 2.3 2.3

$"(4,7]"
[1] 4.5 6.4

$"(7,10]"
[1] 8.9 7.4

$"(10,12.4]"
[1] 12.4 11.5





"Peter B. Mandeville" <mandevip at uaslp.mx>@stat.math.ethz.ch on 06/24/2002
13:11:41

Sent by:  owner-r-help at stat.math.ethz.ch


To:   r-help at stat.math.ethz.ch
cc:
Subject:  [R] code optimization


I have a function "eval.delta" which does what I want but isn't very
elegant. I have consulted the R documents, MASS, and S Programming. Is
there a practical way to optimize the code? Thank you very much.

Peter B.

Function:

eval.delta <- function(delta){
     cat("VALUES\n")
     vlr <- NULL
     k <- 0
     for(j in 1:length(delta)) if(delta[j] <= 2){
         k <- k+1
         vlr[k] <- delta[j]
     }
     cat("<= 2 (no credible evidence)\t",k,"\t",vlr,"\n")
     vlr <- NULL
     k <- 0
     for(j in 1:length(delta)) if(delta[j]>2 & delta[j] <= 4){
         k <- k+1
         vlr[k] <- delta[j]
     }
     cat("> 2 y <= 4 (weak evidence)\t",k,"\t",vlr,"\n")
     vlr <- NULL
     k <- 0
     for(j in 1:length(delta)) if(delta[j]>4 & delta[j] <= 7){
         k <- k+1
         vlr[k] <- delta[j]
     }
     cat("> 4 y <= 7 (definite evidence)\t",k,"\t",vlr,"\n")
     vlr <- NULL
     k <- 0
     for(j in 1:length(delta)) if(delta[j]>7 & delta[j] <= 10){
         k <- k+1
         vlr[k] <- delta[j]
     }
     cat("> 7 y <= 10 (strong evidence)\t",k,"\t",vlr,"\n")
     vlr <- NULL
     k <- 0
     for(j in 1:length(delta)) if(delta[j]>10){
         k <- k+1
         vlr[k] <- delta[j]
     }
     cat("> 10 (very strong evidence)\t",k,"\t",vlr,"\n")
     cat("\nMODELS\n")
     vlr <- NULL
     k <- 0
     for(j in 1:length(delta)) if(delta[j] <= 2){
         k <- k+1
         vlr[k] <- j
     }
     cat("<= 2 (no credible evidence)\t",k,"\t",vlr,"\n")
     vlr <- NULL
     k <- 0
     for(j in 1:length(delta)) if(delta[j]>2 & delta[j] <= 4){
         k <- k+1
         vlr[k] <- j
     }
     cat("> 2 y <= 4 (weak evidence)\t",k,"\t",vlr,"\n")
     vlr <- NULL
     k <- 0
     for(j in 1:length(delta)) if(delta[j]>4 & delta[j] <= 7){
         k <- k+1
         vlr[k] <- j
     }
     cat("> 4 y <= 7 (definite evidence)\t",k,"\t",vlr,"\n")
     vlr <- NULL
     k <- 0
     for(j in 1:length(delta)) if(delta[j]>7 & delta[j] <= 10){
         k <- k+1
         vlr[k] <- j
     }
     cat("> 7 y <= 10 (strong evidence)\t",k,"\t",vlr,"\n")
     vlr <- NULL
     k <- 0
     for(j in 1:length(delta)) if(delta[j]>10){
         k <- k+1
         vlr[k] <- j
     }
     cat("> 10 (very strong evidence)\t",k,"\t",vlr,"\n")
}

Data:

 > delta <- c(0,1.4,2.3,4.5,2.3,8.9,12.4,6.4,7.4,11.5,2,2)

Function Call and Output:

 > eval.delta(delta)
VALUES
<= 2 (no credible evidence)      4       0 1.4 2 2
 > 2 y <= 4 (weak evidence)       2       2.3 2.3
 > 4 y <= 7 (definite evidence)   2       4.5 6.4
 > 7 y <= 10 (strong evidence)    2       8.9 7.4
 > 10 (very strong evidence)      2       12.4 11.5

MODELS
<= 2 (no credible evidence)      4       1 2 11 12
 > 2 y <= 4 (weak evidence)       2       3 5
 > 4 y <= 7 (definite evidence)   2       4 8
 > 7 y <= 10 (strong evidence)    2       6 9
 > 10 (very strong evidence)      2       7 10



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._._



--

NOTICE:  The information contained in this electronic mail transmission is
intended by Convergys Corporation for the use of the named individual or
entity to which it is directed and may contain information that is
privileged or otherwise confidential.  If you have received this electronic
mail transmission in error, please delete it from your system without
copying or forwarding it, and notify the sender of the error by reply email
or by telephone (collect), so that the sender's address records can be
corrected.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From B.Mao at cerep.com  Mon Apr 29 19:41:03 2002
From: B.Mao at cerep.com (Boryeu Mao)
Date: Mon, 29 Apr 2002 10:41:03 -0700
Subject: [R] building R-1.5.0 on SGI/IRIX
Message-ID: <0957E70F25F7D111974B00A0C9833064AF88C4@mayo.cerep.com>

The base build went without any problems (-O2 and -64).  For
R-1.5.0-recommended, two of the packages did not get built:
KernSmooth_2.22-7.tar.gz and cluster_1.4-2.tar.gz, both on a message of
"R-1.5.0/bin/f77: arg list too long".  Thanks in advance for any help on
fixing these.


> mod:>> uname -a
> IRIX64 mod 6.5 10100655 IP35 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rangrej at exchange.cheo.on.ca  Mon Apr 29 19:48:33 2002
From: rangrej at exchange.cheo.on.ca (Rangrej, Jagadish)
Date: Mon, 29 Apr 2002 13:48:33 -0400
Subject: [R] Organizing the help files in a package
Message-ID: <A032D3A4B7F0D411B9360008C71E3DA5038D4CF9@CHEONT3>

Hi Uwe!!!

thanks for the reply,

I have two question:
1. I am getting error of "bad command.." when I run:
   C:\......>rcmd install pubbias
      done till contians
      making ....
      Bad command or file name
      ...else part..   

   Which I found out, is due to "make" command, I suppose my computer(win
98)
   does not have make facility... where can i get that, if not can i 
   have any workaround method for it.

2. I have installed full binary of R1.4.1 for "developers..", I suppose
   the way it forms the zipped file is some what looks like unix type
   .tar.gz, I don't have tar appln in my machine, what should I do ?


I'd appreciate any pointers too...
thanking you and all,
-jag


   

> -----Original Message-----
> From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
> Sent: Monday, April 29, 2002 11:52 AM
> To: Rangrej, Jagadish
> Cc: R-help at stat.math.ethz.ch
> Subject: Re: [R] Organizing the help files in a package
> 
> 
> 
> 
> "Rangrej, Jagadish" wrote:
> > 
> > Dear all!!
> > 
> > I am using R1.4.1 on windows 98.
> > I had been trying to organize the package and has already 
> been able to
> > document some of the functions in to .Rd (R documentation) 
> files. From these
> > .Rd files I generated plain text files as well as html files.
> 
> That will be done automatically by Rcmd INSTALL (for an 
> already builded
> package) and is not needed before Rcmd BUILD.
> 
> 
> > I have also given the 00Index file in each of the directories:
> > html/
> > help/
> > data/
> > man/
> 
> The first two are not needed, but a directory called "R" is missing
> which should contain your *.R files.
> 
>  
> > Problem: I don't get the help using comand "help" after 
> loading the package
> > using library command. Some how the html index gets updated 
> and the help is
> > available in the link of packages in html help pages.
> > 
> > I tried using the command:
> > > Rcmd build,
> > gives the following error
> > * checking for file `pubbias/DESCRIPTION' ... OK
> > * preparing `pubbias':
> > * checking whether `INDEX' is up-to-date ... OK
> > * checking whether `data/00Index' is up-to-date ... O
> > * removing junk files
> > * building `pubbias_1.0.tar.gz'
> > Bad command or file name
> > Bad command or file name
> > 
> > So I organized it mannually to pubbias.zip.
> > 
> > any help will be greatly appreciated.
> 
> Do you have installed all the tools needed to build a package?
> 
> 
> For details please read the manual "Writing R Extensions".
> 
> 
> Uwe Ligges
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From dstierman at micron.com  Mon Apr 29 19:49:55 2002
From: dstierman at micron.com (dstierman)
Date: Mon, 29 Apr 2002 11:49:55 -0600
Subject: [R] RPart
Message-ID: <CFEFA50C9BCAD21197470001FA7EBA6B0DECF18B@ntexchange05.micron.com>

I am using the rpart package and seem to have trouble with data sets that
have columns with no data. I look at the column data in R and all values are
NA. When this occurs, I get nothing back from the rpart function. Is there a
way to get the rpart package to ignore these columns, without knowing what
columns are empty? I have tried the na.action=na.omit and
na.action=na.exclude, but neither one fixes the problem.
Thanks, Don
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brahm at alum.mit.edu  Mon Apr 29 19:49:53 2002
From: brahm at alum.mit.edu (David Brahm)
Date: Mon, 29 Apr 2002 13:49:53 -0400
Subject: [R] Lost Tcl/Tk support
Message-ID: <15565.34753.849633.280536@gargle.gargle.HOWL>

In prior versions, as recent as R-1.5.0pre (2002-04-08), Tcl/Tk support worked
just fine, with "configure" (no flags) finding /usr/local/lib/tclConfig.sh and
/usr/local/lib/tkConfig.sh.  In Monday's official release of R-1.5.0, Tcl/Tk
support now fails for me (under Solaris 2.6):
  ...
  checking for tclConfig.sh... no
  checking for tclConfig.sh in library (sub)directories... no
  checking for tkConfig.sh... no
  checking for tkConfig.sh in library (sub)directories... no
  checking for tcl.h... yes
  checking for tk.h... yes
  ...
  R is now configured for sparc-sun-solaris2.6

    Source directory:          .
    Installation directory:    /usr/local
    C compiler:                /res/local/bin/gcc  -g -O2
    C++ compiler:              g++  -g -O2
    FORTRAN compiler:          g77  -g -O2

    X11 support:               yes
    Gnome support:             no
    Tcl/Tk support:            no             <-----------------
    Readline support:          yes

    R profiling support:       yes
    R as a shared library:     no


Adding the --with-tcltk flag doesn't help, but adding flags:
   --with-tcl-config=/res/local/lib/tclConfig.sh
   --with-tk-config=/res/local/lib/tkConfig.sh
does the trick.  (Note we have these files under both /usr and /res.)

This suggests to me that in the past 3 weeks, "configure" has lost its ability
to find the tclConfig.sh and tkConfig.sh scripts.
-- 
                              -- David Brahm (brahm at alum.mit.edu)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Mon Apr 29 19:59:59 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 29 Apr 2002 19:59:59 +0200
Subject: [R] Organizing the help files in a package
References: <A032D3A4B7F0D411B9360008C71E3DA5038D4CF9@CHEONT3>
Message-ID: <3CCD8A1F.7563F062@statistik.uni-dortmund.de>

"Rangrej, Jagadish" wrote:
> 
> Hi Uwe!!!
> 
> thanks for the reply,
> 
> I have two question:
> 1. I am getting error of "bad command.." when I run:
>    C:\......>rcmd install pubbias
>       done till contians
>       making ....
>       Bad command or file name
>       ...else part..
> 
>    Which I found out, is due to "make" command, I suppose my computer(win
> 98)
>    does not have make facility... where can i get that, if not can i
>    have any workaround method for it.
> 
> 2. I have installed full binary of R1.4.1 for "developers..", I suppose
>    the way it forms the zipped file is some what looks like unix type
>    .tar.gz, I don't have tar appln in my machine, what should I do ?
> 
> I'd appreciate any pointers too...
> thanking you and all,
> -jag

Answer on both question as already mentioned: 
"For details please read the manual 'Writing R Extensions'".

What tools you'll need on Windows is also described at:
http://www.stats.ox.ac.uk/pub/Rtools/
You should also take a look into the files "Install", "readme" and
"readme.packages" in the ....\src\gnuwin32\  directory.

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Mon Apr 29 20:12:01 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 29 Apr 2002 19:12:01 +0100 (BST)
Subject: [R] RPart
In-Reply-To: <CFEFA50C9BCAD21197470001FA7EBA6B0DECF18B@ntexchange05.micron.com>
Message-ID: <Pine.LNX.4.31.0204291903561.1381-100000@gannet.stats>

On Mon, 29 Apr 2002, dstierman wrote:

> I am using the rpart package and seem to have trouble with data sets that
> have columns with no data. I look at the column data in R and all values are
> NA. When this occurs, I get nothing back from the rpart function. Is there a
> way to get the rpart package to ignore these columns, without knowing what
> columns are empty?

That's what happens by default!

data(kyphosis)
kyphosis$dummy <- as.numeric(rep(NA, 81))

rpart(Kyphosis ~ ., data=kyphosis)

has a column with all NAs and works correctly, so I don't think your
hypothesis is the correct one.

> I have tried the na.action=na.omit and
> na.action=na.exclude, but neither one fixes the problem.

Both na.omit and na.exclude all the rows if each contains an NA!  Why are
you putting a column that is entirely NAs (and that's not empty, BTW) in
your formula?

It is easy to find and omit empty columns if you want to:

kyphosis[sapply(kyphosis, function(x) !all(is.na(x)))]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From laurens_leerink at yahoo.com  Mon Apr 29 20:19:02 2002
From: laurens_leerink at yahoo.com (Laurens Leerink)
Date: Mon, 29 Apr 2002 11:19:02 -0700 (PDT)
Subject: [R] Garbage collection: RW1041
Message-ID: <20020429181902.1663.qmail@web10808.mail.yahoo.com>

Have searched through the archives but have been unable to find any related
issues - hopefully I'm not bringing up an old topic.

Am using RW1041 on a Windows NT on a machine with 1Gb of memory.  Have a
function doit() that reads in a chunk of data using readBin, performs a
regression, saves out coeffs and then returns.  When using Rgui with the
default memory limit of 256Mb I'm able to call this function twice before
running out of memory. After the allocation fails the GC is called & everything
is freed, ie we end up with the same memory as before.  Here is an example:

> gc()
         used (Mb) gc trigger (Mb)
Ncells 217415  5.9     467875 12.5
Vcells  63668  0.5     786432  6.0
> doit()
> gc()
          used (Mb) gc trigger  (Mb)
Ncells  342932  9.2     667722  17.9
Vcells 7966401 60.8   14760173 112.7
> doit()
> gc()
           used  (Mb) gc trigger  (Mb)
Ncells   468373  12.6     818163  21.9
Vcells 15869121 121.1   22798845 174.0
> doit()
Error: cannot allocate vector of size 3750 Kb
In addition: Warning message: 
Reached total allocation of 256Mb: see help(memory.size) 
> gc()
         used (Mb) gc trigger  (Mb)
Ncells 217515  5.9     787219  21.1
Vcells  63724  0.5   23990430 183.1
> 

Have increased memory size to 768Mb, but it just takes a few more iterations to
fail.  Got excited after reading the gctorture() documentation, so inserted a
few lines

    gctorture(on = TRUE)
    allocate some memory
    gctorture(on = FALSE)

hoping to trigger a GC but with varied success - the Vcell usage drops but only
slightly, so we seem to trigger a partial GC.  Usually fails on the next call
to "doit".

Have messed around with a few other cheats, eg using gc() to determine where
the trigger level is, then allocating and then deleting object(s) [one large
object or several smaller ones] so that we end up above the trigger level but
below the memory limits - limited success but nothing beyond adding one or two
more iterations.

Any advice/tips/cheats would be appreciated.

Regards,
Laurens Leerink

__________________________________________________

Yahoo! Health - your guide to health and wellness

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From White.Denis at epamail.epa.gov  Mon Apr 29 20:24:33 2002
From: White.Denis at epamail.epa.gov (White.Denis@epamail.epa.gov)
Date: Mon, 29 Apr 2002 11:24:33 -0700
Subject: [R] RPart
Message-ID: <OF5D8E2362.20B9BD83-ON88256BAA.006504D7@rtp.epa.gov>


> I am using the rpart package and seem to have trouble with data sets
that
> have columns with no data. I look at the column data in R and all
values are
> NA. When this occurs, I get nothing back from the rpart function. Is
there a
> way to get the rpart package to ignore these columns, without knowing
what
> columns are empty? I have tried the na.action=na.omit and
> na.action=na.exclude, but neither one fixes the problem.
> Thanks, Don

Either fill out the formula in the first argument to rpart() to exclude
those variables, or create a new data.frame without them.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Mon Apr 29 20:36:21 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 29 Apr 2002 11:36:21 -0700 (PDT)
Subject: [R] data
In-Reply-To: <F20e7lLFIseSYU864Gh00000656@hotmail.com>
Message-ID: <Pine.A41.4.44.0204291132560.41800-100000@homer21.u.washington.edu>

On Mon, 29 Apr 2002, sonchawan tamkaew wrote:

> Hello,
>
> Suppose I have a matrix with 1000 rows and 3 columns, 1st column date, 2nd
> one is type, 3rd one is yield. So it looks like this.
>
> date        type    yield
> 01/01/01    A       3.4
> 01/01/01    B       3.2
> 01/01/01    C       1.8
> 02/01/01    B       3.3
> 03/01/01    A       3.3
> 03/01/01    B       3.4
> 04/01/01    A       3.5
> ...         .       ...
> ...         .       ...
>
> I would like to have the data look like this instead.
>
> date         A     B    C
> 01/01/01    3.4   3.2  1.8
> 02/01/01          3.3
> 03/01/01    3.3   3.4
> 04/01/01    3.5
>
> The missing values could be either blank or NA.
>
> How could I do this without writing for/if loop or do it in Excel before?

Use the reshape() command

> reshape(data,idvar="date",timevar="type",direction="wide")
      date yield.A yield.B yield.C
1 01/01/01     3.4     3.2     1.8
4 02/01/01      NA     3.3      NA
5 03/01/01     3.3     3.4      NA
7 04/01/01     3.5      NA      NA


	-thomas

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From klavan at tiscalinet.it  Mon Apr 29 20:37:44 2002
From: klavan at tiscalinet.it (Ambrosini Alessandro)
Date: Mon, 29 Apr 2002 20:37:44 +0200
Subject: [R] Problem
Message-ID: <PPEGLLABFLFCJDLCGPGHIEINCAAA.klavan@tiscalinet.it>

Hello!
This is the situation.
I have a file in wich there is a scattered matrix. I give an example:

aa bb cc
bb xx
dd cv st rw
xx yu de qw ww zzp

where aa is a node that has a path with aa, one with bb, and one with cc.
bb has a path with xx, dd has a path with cv, one with st, ...
In my experiment I have more or less 100 lines. My nodes are Web pages.
I have another file that gives me a wich nodes are related with the query1

query1 0 aa 1
query1 0 cc 0
query1 0 dd 0
query1 0 cv 1
query1 0 rw 0
query1 0 qw 0
query1 0 ww 1

The query1 is not related with all the nodes of the scattered matrix but
only with someone. The third column gives me which node is related with
query1. This is the most important column.
The second column with all "0" is a vector of costant that is useless. The
fourth column tells me if the node considered in the second column is
relevant to the query or not and also this column is not important for my
work.
Now, considering the query1, I want to obtain a new scattered matrix where
only the nodes related with query1 appears. Starting from the example a have
to obtain:

aa cc
dd cv rw

The steps to do are: take the first line of the scattered matrix. If the
first node (of the first column) of the row doesn't appear in the list of
the nodes related to query, do not consider this line. If the node appears,
then look if at least  another node in the row is related with query1. Write
the lines with all the nodes related with query1, without writing the nodes
that are not related with query1.
Take the second line and do the same things...

Summarizing: starting from the first matrix I want to use the third column
of the second matrix to obtain a new one that contains only the nodes that
appear in the third column.
The output must be a matrix that has at least two elements for row.
The most important node is in the first column and so if it doesn't match
with the third column of query1, the row is not considered.
For example if I have a b c in a row of the matrix and "a" is not a node
related with query, the row must not be considered.

If a solve this problem I'm in a good point of my thesis.
Thank you very much. Excuseme for my english.
Alessandro Ambrosini



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From klavan at tiscalinet.it  Mon Apr 29 20:38:36 2002
From: klavan at tiscalinet.it (Ambrosini Alessandro)
Date: Mon, 29 Apr 2002 20:38:36 +0200
Subject: [R] I: Problem
Message-ID: <PPEGLLABFLFCJDLCGPGHMEINCAAA.klavan@tiscalinet.it>



-----Messaggio originale-----
Da: Ambrosini Alessandro [mailto:klavan at tiscalinet.it]
Inviato: luned? 29 aprile 2002 20.38
A: R-help at lists.R-project.org
Oggetto: Problem


Hello!
This is the situation.
I have a file in wich there is a scattered matrix. I give an example:

aa bb cc
bb xx
dd cv st rw
xx yu de qw ww zzp

where aa is a node that has a path with aa, one with bb, and one with cc.
bb has a path with xx, dd has a path with cv, one with st, ...
In my experiment I have more or less 100 lines. My nodes are Web pages.
I have another file that gives me a wich nodes are related with the query1

query1 0 aa 1
query1 0 cc 0
query1 0 dd 0
query1 0 cv 1
query1 0 rw 0
query1 0 qw 0
query1 0 ww 1

The query1 is not related with all the nodes of the scattered matrix but
only with someone. The third column gives me which node is related with
query1. This is the most important column.
The second column with all "0" is a vector of costant that is useless. The
fourth column tells me if the node considered in the second column is
relevant to the query or not and also this column is not important for my
work.
Now, considering the query1, I want to obtain a new scattered matrix where
only the nodes related with query1 appears. Starting from the example a have
to obtain:

aa cc
dd cv rw

The steps to do are: take the first line of the scattered matrix. If the
first node (of the first column) of the row doesn't appear in the list of
the nodes related to query, do not consider this line. If the node appears,
then look if at least  another node in the row is related with query1. Write
the lines with all the nodes related with query1, without writing the nodes
that are not related with query1.
Take the second line and do the same things...

Summarizing: starting from the first matrix I want to use the third column
of the second matrix to obtain a new one that contains only the nodes that
appear in the third column.
The output must be a matrix that has at least two elements for row.
The most important node is in the first column and so if it doesn't match
with the third column of query1, the row is not considered.
For example if I have a b c in a row of the matrix and "a" is not a node
related with query, the row must not be considered.

If a solve this problem I'm in a good point of my thesis.
Thank you very much. Excuseme for my english.
Alessandro Ambrosini



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Apr 29 21:07:32 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 29 Apr 2002 21:07:32 +0200
Subject: [R] Lost Tcl/Tk support
In-Reply-To: <15565.34753.849633.280536@gargle.gargle.HOWL>
References: <15565.34753.849633.280536@gargle.gargle.HOWL>
Message-ID: <x21ycygw7f.fsf@blueberry.kubism.ku.dk>

David Brahm  <brahm at alum.mit.edu> writes:

> 
>     X11 support:               yes
>     Gnome support:             no
>     Tcl/Tk support:            no             <-----------------
>     Readline support:          yes
> 
>     R profiling support:       yes
>     R as a shared library:     no
> 
> 
> Adding the --with-tcltk flag doesn't help, but adding flags:
>    --with-tcl-config=/res/local/lib/tclConfig.sh
>    --with-tk-config=/res/local/lib/tkConfig.sh
> does the trick.  (Note we have these files under both /usr and /res.)
> 
> This suggests to me that in the past 3 weeks, "configure" has lost its ability
> to find the tclConfig.sh and tkConfig.sh scripts.

Possibly while gaining the ability to find them on FreeBSD....

It does work under Solaris 7 with the files in /usr/local/lib, though.
Are you quite sure you didn't have to set something (LD_LIBRARY_PATH,
e.g.) last time around? What is the error recorded in config.log?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From B.Mao at cerep.com  Mon Apr 29 21:43:56 2002
From: B.Mao at cerep.com (Boryeu Mao)
Date: Mon, 29 Apr 2002 12:43:56 -0700
Subject: [R] how to trap any warnings from an R function 
Message-ID: <0957E70F25F7D111974B00A0C9833064AF88C5@mayo.cerep.com>

Within an user function, how are the warnings from an R function be trapped
(such that some proper actions can be taken)?  'last.warning' is returned
only at the top level.  Pointers are appreciated.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Mon Apr 29 21:52:24 2002
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 29 Apr 2002 21:52:24 +0200
Subject: [R] Garbage collection: RW1041
References: <20020429181902.1663.qmail@web10808.mail.yahoo.com>
Message-ID: <3CCDA478.BC6370A8@statistik.uni-dortmund.de>

Laurens Leerink wrote:
> 
> Have searched through the archives but have been unable to find any related
> issues - hopefully I'm not bringing up an old topic.
> 
> Am using RW1041 on a Windows NT on a machine with 1Gb of memory.  Have a
> function doit() that reads in a chunk of data using readBin, performs a
> regression, saves out coeffs and then returns.  When using Rgui with the
> default memory limit of 256Mb I'm able to call this function twice before
> running out of memory. After the allocation fails the GC is called & everything
> is freed, ie we end up with the same memory as before.  Here is an example:
>
> > gc()
>          used (Mb) gc trigger (Mb)
> Ncells 217415  5.9     467875 12.5
> Vcells  63668  0.5     786432  6.0
> > doit()
> > gc()
>           used (Mb) gc trigger  (Mb)
> Ncells  342932  9.2     667722  17.9
> Vcells 7966401 60.8   14760173 112.7
> > doit()
> > gc()
>            used  (Mb) gc trigger  (Mb)
> Ncells   468373  12.6     818163  21.9
> Vcells 15869121 121.1   22798845 174.0
> > doit()
> Error: cannot allocate vector of size 3750 Kb
> In addition: Warning message:
> Reached total allocation of 256Mb: see help(memory.size)
> > gc()
>          used (Mb) gc trigger  (Mb)
> Ncells 217515  5.9     787219  21.1
> Vcells  63724  0.5   23990430 183.1
> >
> 
> Have increased memory size to 768Mb, but it just takes a few more iterations to
> fail.  Got excited after reading the gctorture() documentation, so inserted a
> few lines
> 
>     gctorture(on = TRUE)
>     allocate some memory
>     gctorture(on = FALSE)
> 
> hoping to trigger a GC but with varied success - the Vcell usage drops but only
> slightly, so we seem to trigger a partial GC.  Usually fails on the next call
> to "doit".
> 
> Have messed around with a few other cheats, eg using gc() to determine where
> the trigger level is, then allocating and then deleting object(s) [one large
> object or several smaller ones] so that we end up above the trigger level but
> below the memory limits - limited success but nothing beyond adding one or two
> more iterations.
> 
> Any advice/tips/cheats would be appreciated.


This bug is known (I guess) and was discussed in a thread regarding 
   Subject: Re: [Rd] Memory "leak" in readChar (PR#1483)
on R-devel today. 

A partial fix for [from the News file:]
    o readChar() was not resetting vmax, so causing memory build-up.
      (PR#1483)
is already in R-1.5.0.

Uwe Ligges
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ben at zoo.ufl.edu  Mon Apr 29 22:14:56 2002
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Mon, 29 Apr 2002 16:14:56 -0400 (EDT)
Subject: [R] Problem
In-Reply-To: <PPEGLLABFLFCJDLCGPGHIEINCAAA.klavan@tiscalinet.it>
Message-ID: <Pine.LNX.4.30.0204291613310.24697-100000@bolker.zoo.ufl.edu>


  Assuming that your data below are located in space-separated files
"temp1.dat" and "temp2.dat", here's a reasonable solution ...

m1 <- read.table("temp1.dat",fill=TRUE,as.is=TRUE)
## makes a table of factors; not necessarily optimal but ...
m2 <- read.table("temp2.dat")

qvals <- levels(m2[[3]])
## take only rows with 1st column included in column 3 of m2
m1 <- m1[m1[,1] %in% qvals,]
relnodes <- apply(m1,1,function(x)sum(x %in% qvals))
m1 <- m1[relnodes>1,]  ## keep only rows with at least one extra

## turn m1 into a list
m1b <- as.list(as.data.frame(t(as.matrix(m1))))
m1c <- lapply(m1b,function(x)as.character(x[x %in% qvals]))  ## drop elements not in qvals

On Mon, 29 Apr 2002, Ambrosini Alessandro wrote:

> Hello!
> This is the situation.
> I have a file in wich there is a scattered matrix. I give an example:
>
> aa bb cc
> bb xx
> dd cv st rw
> xx yu de qw ww zzp
>
> where aa is a node that has a path with aa, one with bb, and one with cc.
> bb has a path with xx, dd has a path with cv, one with st, ...
> In my experiment I have more or less 100 lines. My nodes are Web pages.
> I have another file that gives me a wich nodes are related with the query1
>
> query1 0 aa 1
> query1 0 cc 0
> query1 0 dd 0
> query1 0 cv 1
> query1 0 rw 0
> query1 0 qw 0
> query1 0 ww 1
>
> The query1 is not related with all the nodes of the scattered matrix but
> only with someone. The third column gives me which node is related with
> query1. This is the most important column.
> The second column with all "0" is a vector of costant that is useless. The
> fourth column tells me if the node considered in the second column is
> relevant to the query or not and also this column is not important for my
> work.
> Now, considering the query1, I want to obtain a new scattered matrix where
> only the nodes related with query1 appears. Starting from the example a have
> to obtain:
>
> aa cc
> dd cv rw
>
> The steps to do are: take the first line of the scattered matrix. If the
> first node (of the first column) of the row doesn't appear in the list of
> the nodes related to query, do not consider this line. If the node appears,
> then look if at least  another node in the row is related with query1. Write
> the lines with all the nodes related with query1, without writing the nodes
> that are not related with query1.
> Take the second line and do the same things...
>
> Summarizing: starting from the first matrix I want to use the third column
> of the second matrix to obtain a new one that contains only the nodes that
> appear in the third column.
> The output must be a matrix that has at least two elements for row.
> The most important node is in the first column and so if it doesn't match
> with the third column of query1, the row is not considered.
> For example if I have a b c in a row of the matrix and "a" is not a node
> related with query, the row must not be considered.
>
> If a solve this problem I'm in a good point of my thesis.
> Thank you very much. Excuseme for my english.
> Alessandro Ambrosini
>
>
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jay at m5.chi.il.us  Mon Apr 29 23:50:50 2002
From: jay at m5.chi.il.us (Jay F Shachter)
Date: Mon, 29 Apr 2002 15:50:50 -0600 (CDT)
Subject: [R] deficiencies in readline capability
Message-ID: <200204292050.PAA10786@m5.chi.il.us>

When I first configured and built R, I did not have the GNU readline
library installed on my system, so naturally I got an R without
readline capabilities.  I then installed the GNU readline library, and
again configured and built R.  I now have an R with readline
capability, but it is a deficient readline capability, providing only
one-line editing capability (e.g., CTRL-A, CTRL-E, CTRL-B, CTRL-F,
CTRL-D) without any history functionality (e.g., CTRL-P, CTRL-N,
CTRL-R).  The shared libraries, version, and history capability of R
are as shown in the following logfile, where "$ " is my shell prompt:


$ ldd /opt/jay/lib/SunOS5/R/bin/R.bin
	libm.so.1 =>	 /usr/lib/libm.so.1
	libz.so =>	 /opt/jay/lib/SunOS5/libz.so
	libnsl.so.1 =>	 /usr/lib/libnsl.so.1
	libsocket.so.1 =>	 /usr/lib/libsocket.so.1
	libreadline.so.4 =>	 /gnu/lib/libreadline.so.4
	libdl.so.1 =>	 /usr/lib/libdl.so.1
	libcurses.so.1 =>	 /usr/lib/libcurses.so.1
	libc.so.1 =>	 /usr/lib/libc.so.1
	libucb.so.1 =>	 /usr/ucblib/libucb.so.1
	libresolv.so.2 =>	 /usr/lib/libresolv.so.2
	libelf.so.1 =>	 /usr/lib/libelf.so.1
	libmp.so.2 =>	 /usr/lib/libmp.so.2
	libgcc_s.so.1 =>	 /gnu/lib/libgcc_s.so.1
$ R --vanilla

R : Copyright 2002, The R Development Core Team
Version 1.4.1  (2002-01-30)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type `license()' or `licence()' for distribution details.

R is a collaborative project with many contributors.
Type `contributors()' for more information.

Type `demo()' for some demos, `help()' for on-line help, or
`help.start()' for a HTML browser interface to help.
Type `q()' to quit R.

> history()
Error in savehistory(file) : no history available to save
> q()
$ 



Clearly I am using the GNU readline libraries, but there is another,
and perhaps unrelated, problem, which is that no history is
accessible.  I gave R no configuration option to turn off history
capability when I configured it, nor am I aware that any such option
exists.

What am I doing wrong?

			Jay F. Shachter
			6424 N Whipple St
			Chicago IL  60645-4111
				(1-773)7613784
				jay at m5.chi.il.us
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From shyu at aecom.yu.edu  Mon Apr 29 22:59:28 2002
From: shyu at aecom.yu.edu (shyu@aecom.yu.edu)
Date: Mon, 29 Apr 2002 16:59:28 -0400 (EDT)
Subject: [R] Question on integrateing R to our system
Message-ID: <Pine.SOL.3.96.1020429165430.1621A-100000@post>

Dear Sir/Madam,

We are very interested in integrating R into our current project. We would
like to have further info regarding the web-enabled version in terms of
pricing, licensing & the complexity in integrating with Oracle Portal
3.0.9 with back end database running on Oracle 9i 9.0.1 on Solaris
platform.
Thank you very much.

Shaoqing Yu

Biotech Center
Albert Einstein College of Medicine




-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Corey.Moffet at ttu.edu  Mon Apr 29 23:09:09 2002
From: Corey.Moffet at ttu.edu (Moffet, Corey)
Date: Mon, 29 Apr 2002 16:09:09 -0500
Subject: [R] Lotos 1-2-3 date to POSIXct
Message-ID: <938690ACF269D311928B0090279C2772E91EFF@cyclops.net.ttu.edu>

Thanks for your response.  With a little modification I am getting closer to
the Lotus 1-2-3 results
but not exactly:

Lotus.time <- c(1, 36373.833, 36373.875, 36373.917, 36425.458, 36425.500,
36425.542, 37353.04, 37353.09)
POSIX.time <- ISOdate(1899,12,31,hour=0, tz="")+(Lotus.time)*24*60*60
POSIX.time 

which returns:

[1] "1900-01-01 00:00:00 Central Standard Time"    # Correct
[2] "1999-08-02 20:59:31 Central Daylight Time"    # 1 day and 1 hr fast
[3] "1999-08-02 22:00:00 Central Daylight Time"    # 1 day and 1 hr fast
[4] "1999-08-02 23:00:28 Central Daylight Time"    # 1 day, 1 hr fast and 1
sec slow 
[5] "1999-09-23 11:59:31 Central Daylight Time"    # 1 day and 1 hr fast
[6] "1999-09-23 13:00:00 Central Daylight Time"    # 1 day and 1 hr fast
[7] "1999-09-23 14:00:28 Central Daylight Time"    # 1 day, 1 hr fast and 1
sec slow
[8] "2002-04-07 00:57:35 Central Standard Time"    # 1 day fast and 1 sec
slow
[9] "2002-04-07 03:09:35 Central Daylight Time"    # 1 day, 1 hr fast and 1
sec slow

but Lotus gives:

unformatted  Date        Time
1.000       01/01/00    00:00:00
36373.833   08/01/99    19:59:31
36373.875   08/01/99    21:00:00
36373.917   08/01/99    22:00:29
36425.458   09/22/99    10:59:31
36425.500   09/22/99    12:00:00
36425.542   09/22/99    13:00:29
37353.04    04/07/2002  00:57:36
37353.09    04/07/2002  02:09:36

The error in the seconds I am not concerned with.  The apparent error in the
hr seems to be
related to Daylight savings not accounted for Lotus 1-2-3.  For the range of
data I will be
working with I think I can fix the 1 day error problem but this fix will
have problems between
1 and 36373.833.  Is there some exception to the leap year rule in the range
1900 to 1999 that
would explain this discrepancy?

With best wishes and kind regards I am

Sincerely,

Corey A. Moffet
Instructor
Department of Range, Wildlife, and Fisheries Management
Mail Stop 2125
Texas Tech University
Lubbock, Texas 79409-2125

-----Original Message-----
From: Peter Dalgaard BSA [mailto:p.dalgaard at biostat.ku.dk]
Sent: Monday, April 29, 2002 8:18 AM
To: Moffet, Corey
Cc: R-Help (E-mail)
Subject: Re: [R] Lotos 1-2-3 date to POSIXct


"Moffet, Corey" <Corey.Moffet at ttu.edu> writes:

> I have some data that was created for import into a Lotus 1-2-3
spreadsheet
> and on of the columns is time.  The
> time is akin to Julian were the value 1 is mapped "01-Jan-00 12:00:00 AM"
in
> Lotus 1-2-3.  Is there a function in an R package that can convert this
> numeric vector to a POSIXct vector?

Units are seconds? Subtract 1 and add "01-Jan-00 12:00:00 AM" using
ISOdate. Otherwise convert units, cf:

> ISOdate(2000,1,1)+2000*24*60*60 # 2000 days after the Millennium
[1] "2005-06-23 14:00:00 MET DST" 


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From brahm at alum.mit.edu  Mon Apr 29 23:19:34 2002
From: brahm at alum.mit.edu (David Brahm)
Date: Mon, 29 Apr 2002 17:19:34 -0400
Subject: [R] Lost Tcl/Tk support
In-Reply-To: <x2lmb6kyz6.fsf@blueberry.kubism.ku.dk>
References: <15565.34753.849633.280536@gargle.gargle.HOWL>
	<x21ycygw7f.fsf@blueberry.kubism.ku.dk>
	<15565.40960.601576.42631@gargle.gargle.HOWL>
	<x2ofg2ffs5.fsf@blueberry.kubism.ku.dk>
	<15565.42600.119210.546931@gargle.gargle.HOWL>
	<x2lmb6kyz6.fsf@blueberry.kubism.ku.dk>
Message-ID: <15565.47334.75618.798680@gargle.gargle.HOWL>

With Peter Dalgaard's kind help, I've figured out that the problem was on my
end.  We have 3 parallel machines, but only one of them has the *Config.sh
scripts in /usr/local/lib.  And despite my settings for LDFLAGS, "configure" is
hard-wired to look only in /opt/lib, /usr/local/lib, /usr/lib, and /lib.

Nothing is broken.  Sorry for the false alarm.  Thanks, Peter!
-- 
                              -- David Brahm (brahm at alum.mit.edu)
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Mon Apr 29 23:28:10 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 29 Apr 2002 23:28:10 +0200
Subject: [R] Lotos 1-2-3 date to POSIXct
In-Reply-To: <938690ACF269D311928B0090279C2772E91EFF@cyclops.net.ttu.edu>
References: <938690ACF269D311928B0090279C2772E91EFF@cyclops.net.ttu.edu>
Message-ID: <x2helukxed.fsf@blueberry.kubism.ku.dk>

"Moffet, Corey" <Corey.Moffet at ttu.edu> writes:

> The error in the seconds I am not concerned with.  The apparent error in the
> hr seems to be
> related to Daylight savings not accounted for Lotus 1-2-3.  For the range of
> data I will be
> working with I think I can fix the 1 day error problem but this fix will
> have problems between
> 1 and 36373.833.  Is there some exception to the leap year rule in the range
> 1900 to 1999 that
> would explain this discrepancy?

1900 was not a leap year, possibly Lotus has that wrong. The seconds
error could well be down to dealing in units of 1/1000th of a day =
86.4 seconds. The DST "error" might be better fixed by working in GMT
throughout. 


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From vograno at arbitrade.com  Tue Apr 30 00:08:14 2002
From: vograno at arbitrade.com (Vadim Ogranovich)
Date: Mon, 29 Apr 2002 17:08:14 -0500
Subject: [R] calling optim from external C/C++ program
Message-ID: <AFD78192EC49D311BFAE00902798AB8F23D93C@JUPITER>

Hi,

Does anyone have an example of calling optim() from a standalone C/C++
program? If possible please include the linker options (I am using gcc
version 2.96 20000731 (Red Hat Linux 7.1 2.96-98))

Thanks, Vadim

-------------------------------------------------- 
DISCLAIMER 
This e-mail, and any attachments thereto, is intended only for use by the
addressee(s) named herein and may contain legally privileged and/or
confidential information.  If you are not the intended recipient of this
e-mail, you are hereby notified that any dissemination, distribution or
copying of this e-mail, and any attachments thereto, is strictly prohibited.
If you have received this e-mail in error, please immediately notify me and
permanently delete the original and any copy of any e-mail and any printout
thereof. 

E-mail transmission cannot be guaranteed to be secure or error-free.  The
sender therefore does not accept liability for any errors or omissions in
the contents of this message which arise as a result of e-mail transmission.

NOTICE REGARDING PRIVACY AND CONFIDENTIALITY 

Knight Trading Group may, at its discretion, monitor and review the content
of all e-mail communications. 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From adams.644 at osu.edu  Tue Apr 30 00:37:33 2002
From: adams.644 at osu.edu (jimi adams)
Date: Mon, 29 Apr 2002 18:37:33 -0400
Subject: [R] efficiency
Message-ID: <4.3.2.7.2.20020429183649.00aa84a0@pop.service.ohio-state.edu>

i have a set of  files that i am reading into R one at a time and applying 
to a function that i have written
where each is a 'table' n (columns) x 10000 (rows)
n varies across the files and most of the rows only have data in the first 
few columns
currently i am reading them in with the command:
read.table(file="2.75.0.997.1", header=FALSE, sep="", skip=13, fill=, 
row.names=1, nrows=10000)->list

***and it works fine
however we are now working with a huge table.
i was wondering if there is a more efficient way to read this in

IDEALLY i would like to have it as a list where each element is a row from 
the input file, eliminating all of the NA's that the above approach results 
in , such that i would have a list with 10000 elements and each of variable 
length from 1:n

any help greatly appreciated
jimi adams
Department of Sociology
The Ohio State University
300 Bricker Hall
190 N. Oval Mall
Columbus, OH 43210-1353
614-688-4261

our mind has a remarkable ability to think of contents as being independent 
of the act of thinking
                                             -georg simmel

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From M.GRUM at CGIAR.ORG  Tue Apr 30 00:52:31 2002
From: M.GRUM at CGIAR.ORG (Grum, Mikkel)
Date: Mon, 29 Apr 2002 15:52:31 -0700
Subject: [R] cluster analyses
Message-ID: 
 <FC788AB9771FD6118E6F0002A5AD7B8F5A6C50@icrafnttrain.icraf.cgiar.org>

I'm clustering rather large data sets and would like to cut the dendrograms
to get a better view of specific components.  I calculate the dissimilarity
matrix using daisy() because I have a mixture of variable types: factors,
ordered factors and numerical variables.  If I want one dendrogram, I use
agnes() for the agglomerative nesting and pltree() to draw the dendrogram.
That way, I get the row names as labels, but I can't cut the tree.

Alternatively, I use hclust() on the dissimilarity matrix from daisy().
This allows me to cut the dendrogram with cutree(), but I loose the labels,
so that isn't much use.  I can change the output from hclust() to class
dendrogram with as.dendrogram().  This has a rather neat way of cutting the
dendrogram with cut.dendrogram(), which allows you to show specific lower
sections of the dendrogram with plot.dendrogram(object$lower[[1]]). Again, I
loose the labels.

Does anyone know how to keep the row names as labels when starting with
daisy() and ending with plot.dendrogram()?  A couple of months ago, I had a
look at the code for as.hclust() and managed to change it so that I could
keep the labels, but now I don't remember how I got to see the code. When I
type as.hclust, I get "function(x,...) UseMethod("as.hclust")".

Also, does anyone know how to get a horizontal dendrogram so that the labels
are readable? Ideally with the labels to the right??
Any help would be greatly appreciated.

Best wishes,
Mikkel
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tlumley at u.washington.edu  Tue Apr 30 00:59:32 2002
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 29 Apr 2002 15:59:32 -0700 (PDT)
Subject: [R] efficiency
In-Reply-To: <4.3.2.7.2.20020429183649.00aa84a0@pop.service.ohio-state.edu>
Message-ID: <Pine.A41.4.44.0204291556490.41800-100000@homer21.u.washington.edu>

On Mon, 29 Apr 2002, jimi adams wrote:

> i have a set of  files that i am reading into R one at a time and applying
> to a function that i have written
> where each is a 'table' n (columns) x 10000 (rows)
> n varies across the files and most of the rows only have data in the first
> few columns
> currently i am reading them in with the command:
> read.table(file="2.75.0.997.1", header=FALSE, sep="", skip=13, fill=,
> row.names=1, nrows=10000)->list
>
> ***and it works fine
> however we are now working with a huge table.
> i was wondering if there is a more efficient way to read this in
>
> IDEALLY i would like to have it as a list where each element is a row from
> the input file, eliminating all of the NA's that the above approach results
> in , such that i would have a list with 10000 elements and each of variable
> length from 1:n
>

You could declare a list with 10000 elements as
  data<-vector("list",10000)
and then open a connection to the file and read one line at a time:
  a<-file("2.75.0.997.1")
  open(a)
  for(i in 1:10000) data[[i]]<-scan(a,nlines=1)


I don't know if that would be more efficient, but it would use less
memory.

	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From camann at babylon.cnrs.humboldt.edu  Tue Apr 30 02:07:56 2002
From: camann at babylon.cnrs.humboldt.edu (Michael Camann)
Date: Mon, 29 Apr 2002 17:07:56 -0700 (PDT)
Subject: [R] cluster analyses
In-Reply-To: <FC788AB9771FD6118E6F0002A5AD7B8F5A6C50@icrafnttrain.icraf.cgiar.org>
Message-ID: <Pine.LNX.4.10.10204291704470.8092-100000@babylon.cnrs.humboldt.edu>

Mikkel--

I presume you modified plot.hclust() when last you hacked the labels--
I've done similar modifications in the past.

--Mike C.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Michael A. Camann                                  Voice: 707-826-3676
Associate Professor of Zoology                       Fax: 707-826-3201
Institute for Forest Canopy Research     Email: mac24 at axe.humboldt.edu
Department of Biology                            ifcr at axe.humboldt.edu
Humboldt State University           
Arcata, CA 95521

                 URL:http://www.humboldt.edu/~mac24/
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From White.Denis at epamail.epa.gov  Tue Apr 30 02:49:27 2002
From: White.Denis at epamail.epa.gov (White.Denis@epamail.epa.gov)
Date: Mon, 29 Apr 2002 17:49:27 -0700
Subject: [R] cluster analyses
Message-ID: <OFFCB128A1.68E004B4-ON88256BAB.0003C40B@rtp.epa.gov>


> I'm clustering rather large data sets and would like to cut the
dendrograms
> to get a better view of specific components.  I calculate the
dissimilarity
> matrix using daisy() because I have a mixture of variable types:
factors,
> ordered factors and numerical variables.  If I want one dendrogram, I
use
> agnes() for the agglomerative nesting and pltree() to draw the
dendrogram.
> That way, I get the row names as labels, but I can't cut the tree.
>
> Alternatively, I use hclust() on the dissimilarity matrix from daisy
().
> This allows me to cut the dendrogram with cutree(), but I loose the
labels,
> so that isn't much use.  I can change the output from hclust() to
class
> dendrogram with as.dendrogram().  This has a rather neat way of
cutting the
> dendrogram with cut.dendrogram(), which allows you to show specific
lower
> sections of the dendrogram with plot.dendrogram(object$lower[[1]]).
Again, I
> loose the labels.
>
> Does anyone know how to keep the row names as labels when starting
with
> daisy() and ending with plot.dendrogram()?  A couple of months ago, I
had a
> look at the code for as.hclust() and managed to change it so that I
could
> keep the labels, but now I don't remember how I got to see the code.
When I
> type as.hclust, I get "function(x,...) UseMethod("as.hclust")".
>
> Also, does anyone know how to get a horizontal dendrogram so that the
labels
> are readable? Ideally with the labels to the right??
> Any help would be greatly appreciated.
>
> Best wishes,
> Mikkel

If your data are "spatial", that is, they can be identified through two
dimensional coordinates, you could try the mapping techniques in package
maptree.  Groups of observations (rows) in higher level clusters can be
given the same symbol/color to show cluster patterns.  But the labels of
individual observations are not preserved through this process either.

There is a new function in that package, kgs(), that calculates, using a
penalty function, an optimal size to which to prune a dendrogram.


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr 30 08:15:31 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 30 Apr 2002 07:15:31 +0100 (BST)
Subject: [R] calling optim from external C/C++ program
In-Reply-To: <AFD78192EC49D311BFAE00902798AB8F23D93C@JUPITER>
Message-ID: <Pine.GSO.4.44.0204300712270.28784-100000@auk.stats>

On Mon, 29 Apr 2002, Vadim Ogranovich wrote:

> Hi,
>
> Does anyone have an example of calling optim() from a standalone C/C++
> program? If possible please include the linker options (I am using gcc
> version 2.96 20000731 (Red Hat Linux 7.1 2.96-98))

It's not possible.  An important part of optim() is in R.  R 1.5.0 makes
the underlying optimizers available to C code linked into R, but they are
only part of optim().

There is also no such thing as gcc 2.96: see gcc.gnu.org.  You would be
well-advised to use a released version of gcc.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From hkimscil at scils.rutgers.edu  Tue Apr 30 09:03:36 2002
From: hkimscil at scils.rutgers.edu (hkimscil)
Date: Tue, 30 Apr 2002 03:03:36 -0400
Subject: [R] Labeling matrix data
Message-ID: <000701c1f015$26635cb0$4c16e6a5@jetsky>

Hello all -

I am sorry if this simple question is addressed in somewhere else. But, I couldn't find it. It's been for about a week using R. . . 

My problem is: 

Reading matrix data with "scan" does not seem to allow me to incorporate matrix labels (columns, and rows). 

If I use read.table, I can import the lables. But, the problem is, I don't know how I make this data as matrix. 

I'd really appreciate any help, and will keep diggin the manual for more information.

Regrads, 

-hyo
Hyo Kim, student
Communicaiton Department 
Rutgers, New Jersey, US
hkimscil at scils.rutgers.edu
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rpeng at stat.ucla.edu  Tue Apr 30 08:56:34 2002
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Mon, 29 Apr 2002 23:56:34 -0700 (PDT)
Subject: [R] Labeling matrix data
In-Reply-To: <000701c1f015$26635cb0$4c16e6a5@jetsky>
Message-ID: <Pine.GSO.4.10.10204292356180.7309-100000@quetelet.stat.ucla.edu>

Try 

?as.matrix

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Tue, 30 Apr 2002, hkimscil wrote:

> Hello all -
> 
> I am sorry if this simple question is addressed in somewhere else. But, I couldn't find it. It's been for about a week using R. . . 
> 
> My problem is: 
> 
> Reading matrix data with "scan" does not seem to allow me to incorporate matrix labels (columns, and rows). 
> 
> If I use read.table, I can import the lables. But, the problem is, I don't know how I make this data as matrix. 
> 
> I'd really appreciate any help, and will keep diggin the manual for more information.
> 
> Regrads, 
> 
> -hyo
> Hyo Kim, student
> Communicaiton Department 
> Rutgers, New Jersey, US
> hkimscil at scils.rutgers.edu
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr 30 08:56:23 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 30 Apr 2002 07:56:23 +0100 (BST)
Subject: [R] Labeling matrix data
In-Reply-To: <000701c1f015$26635cb0$4c16e6a5@jetsky>
Message-ID: <Pine.GSO.4.44.0204300753310.28784-100000@auk.stats>

On Tue, 30 Apr 2002, hkimscil wrote:

> Hello all -
>
> I am sorry if this simple question is addressed in somewhere else. But, I couldn't find it. It's been for about a week using R. . .
>
> My problem is:
>
> Reading matrix data with "scan" does not seem to allow me to incorporate matrix labels (columns, and rows).
>
> If I use read.table, I can import the lables. But, the problem is, I don't know how I make this data as matrix.

Use as.matrix or data.matrix.

You need to consider if you want a character or numeric matrix, but if all
your input is numbers (apart from row and column names) either will do.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jasont at indigoindustrial.co.nz  Tue Apr 30 21:22:50 2002
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Tue, 30 Apr 2002 19:22:50 +0000
Subject: [R] how to trap any warnings from an R function
In-Reply-To: <0957E70F25F7D111974B00A0C9833064AF88C5@mayo.cerep.com>; from B.Mao@cerep.com on Mon, Apr 29, 2002 at 12:43:56PM -0700
References: <0957E70F25F7D111974B00A0C9833064AF88C5@mayo.cerep.com>
Message-ID: <20020430192250.A1035@camille.indigoindustrial.co.nz>

On Mon, Apr 29, 2002 at 12:43:56PM -0700, Boryeu Mao wrote:
> Within an user function, how are the warnings from an R function be trapped
> (such that some proper actions can be taken)?  

One way is with try()

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From vito.muggeo at giustizia.it  Tue Apr 30 10:06:27 2002
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Tue, 30 Apr 2002 10:06:27 +0200
Subject: [R] MemoryProblem in R-1.4.1
Message-ID: <005a01c1f01d$f0fb3f80$5c13070a@it.giustizia.it>

Hi all,
In a simulation context, I'm applying some my function, "myfun" say, to a
list of glm obj, "list.glm":
>length(list.glm) #number of samples simulated
[1] 1000
>class(list.glm[[324]]) #any component of the list
[1] "glm" "lm"
>length(list.glm[[290]]$y) #sample size
[1] 1000

Because length(list.glm) and the sample size are rather large, I've splitted
the list into 10 sub-list, say: list.glm1, list.glm2,....
Now I'm using of course:
out1<-lapply(list.glm1, myfun)
out2<-lapply(list.glm2, myfun)
....
However only the first works, for the second one it is:

Error: cannot allocate vector of size 3 Kb
In addition: Warning message:
Reached total allocation of 255Mb: see help(memory.size)

So I increase the memory
> memory.limit(size=300)
NULL
> out2<-lapply(list.glm2, myfun) #works
> out3<-lapply(list.glm3, myfun) #does not works
Error: cannot allocate vector of size 31 Kb
In addition: Warning message:
Reached total allocation of 300Mb: see help(memory.size)

Again I increase the memory.size
> memory.limit(size=320)
NULL
> out3<-lapply(list.glm3, myfun) #works!
> out4<-lapply(list.glm4, myfun) #does not work!
.....
So it seems I have to increase the memory.size each time before applying my
function. This is suprising because I know that returning to the prompt the
memory is fully available again. So being the lists similar, why the same
memory size is not sufficient for every list?

Is there any way to solve this problem or have I to modify memory.size()
after every call.
And if it is so, is there a limit?
Moreover the problem does not depends on the number of simulated samples
(i.e. length(list)), because I'm applying the function on sub-list having
just 100 components.


I'm running R 1.4.1 on WinMe pentium III 750 with 256RAM

By the way  there would be the same problem on Linux?

Thanks for your help,
best,
vito
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr 30 10:28:08 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 30 Apr 2002 09:28:08 +0100 (BST)
Subject: [R] MemoryProblem in R-1.4.1
In-Reply-To: <005a01c1f01d$f0fb3f80$5c13070a@it.giustizia.it>
Message-ID: <Pine.LNX.4.31.0204300916470.4436-100000@gannet.stats>

On Tue, 30 Apr 2002, vito muggeo wrote:

> Hi all,
> In a simulation context, I'm applying some my function, "myfun" say, to a
> list of glm obj, "list.glm":
> >length(list.glm) #number of samples simulated
> [1] 1000
> >class(list.glm[[324]]) #any component of the list
> [1] "glm" "lm"
> >length(list.glm[[290]]$y) #sample size
> [1] 1000
>
> Because length(list.glm) and the sample size are rather large, I've splitted
> the list into 10 sub-list, say: list.glm1, list.glm2,....
> Now I'm using of course:
> out1<-lapply(list.glm1, myfun)
> out2<-lapply(list.glm2, myfun)
> ....
> However only the first works, for the second one it is:
>
> Error: cannot allocate vector of size 3 Kb
> In addition: Warning message:
> Reached total allocation of 255Mb: see help(memory.size)
>
> So I increase the memory
> > memory.limit(size=300)
> NULL
> > out2<-lapply(list.glm2, myfun) #works
> > out3<-lapply(list.glm3, myfun) #does not works
> Error: cannot allocate vector of size 31 Kb
> In addition: Warning message:
> Reached total allocation of 300Mb: see help(memory.size)
>
> Again I increase the memory.size
> > memory.limit(size=320)
> NULL
> > out3<-lapply(list.glm3, myfun) #works!
> > out4<-lapply(list.glm4, myfun) #does not work!
> .....
> So it seems I have to increase the memory.size each time before applying my
> function. This is suprising because I know that returning to the prompt the
> memory is fully available again. So being the lists similar, why the same
> memory size is not sufficient for every list?

Because the returned objects are still in memory.  My guess is that
out1 etc are large objects: try object.size to see.  I do wonder if a
simple for() loop would not work better.

> Is there any way to solve this problem or have I to modify memory.size()
> after every call.

You could start R with --max-mem-size (and that's better than increasing
memory.limit) but swapping on WinME is likely to be painfully slow.

> And if it is so, is there a limit?

Somewhere around 1.5Gb, if you have enough swap space.

> Moreover the problem does not depends on the number of simulated samples
> (i.e. length(list)), because I'm applying the function on sub-list having
> just 100 components.
>
>
> I'm running R 1.4.1 on WinMe pentium III 750 with 256RAM
>
> By the way  there would be the same problem on Linux?

Very likely, but Linux's swap space works much better than WinME, at least
up to 1Gb.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From stefano.iacus at unimi.it  Tue Apr 30 10:46:05 2002
From: stefano.iacus at unimi.it (Stefano Iacus)
Date: Tue, 30 Apr 2002 10:46:05 +0200
Subject: [R] Re: Release of Design library; update of Hmisc library
In-Reply-To: <20020429111221.01cbe942.fharrell@virginia.edu>
Message-ID: <B5A63D7E-5C16-11D6-92C8-003065CC4CB8@unimi.it>

Hy Frank,

I'll try to build it for MacOS too.

Stefano

On Luned?, aprile 29, 2002, at 05:12 , Frank E Harrell Jr wrote:

>
> The Design library has been fully ported to R except for Cox 
> proportional hazards regression modeling (using Therneau's survival 
> package) which will be available in about two weeks.  It will take much 
> longer to make all the example code executable, is it currently 
> contains many examples for which data are not provided.  Thanks to Xiao 
> Gang Fan <xiao.gang.fan1 at libertysurf.fr> who kindly compiled Design for 
> Windows.  I also thank Doug Bates <bates at stat.wisc.edu> and Charles 
> Berry <cberry at tajo.ucsd.edu> who provided details to make it easy to 
> change LINPACK calls from S-Plus to R, and Robert Gentleman 
> <rgentlem at jimmy.harvard.edu> and Thomas Lumley 
> <tlumley at u.washington.edu> who provided help in dealing with formula 
> terms objects.
>
> The Design library implements methods used in my 2001 Springer book 
> Regression Modeling Strategies (see 
> http://hesweb1.med.virginia.edu/biostat/rms).  The web page for Design 
> is
> http://hesweb1.med.virginia.edu/biostat/s/Design.html from which you
> can download the ready-to-install package.  See
> http://hesweb1.med.virginia.edu/biostat/s/help/Design/html/Overview.html
> for a detailed overview of the library.
>
> Design does regression modeling, testing, estimation, validation, 
> graphics, prediction, and typesetting by storing enhanced model design 
> attributes in the fit.  Design is a collection of about 180 functions 
> that assist and streamline modeling, especially for biostatistical and 
> epidemiologic applications.  It also contains new functions for binary 
> and ordinal logistic regression models and the Buckley-James multiple 
> regression model for right-censored responses, and implements penalized 
> maximum likelihood estimation for logistic and ordinary linear models.  
> Design works with almost any regression model, but it was especially 
> written to work with logistic regression, Cox regression, accelerated 
> failure time models, and ordinary linear models.
>
> You should install the Hmisc library before using Design, as a few of 
> Design's options use Hmisc functions, and Hmisc has several functions 
> useful for data analysis (especially data reduction and imputation).
>
>
> Peter Malewski <peter.malewski at gmx.de> provided many more bug fixes for 
> the Hmisc library, and Xiao Gang Fan kindly compiled the latest Hmisc 
> for Windows.  New versions of Hmisc for all platforms may be obtained 
> from http://hesweb1.med.virginia.edu/biostat/s/library/r .  The new 
> versions are required when using Design.
>
> --
> Frank E Harrell Jr              Prof. of Biostatistics & Statistics
> Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
> U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> .-.-.-
> r-announce mailing list -- Read 
> http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-announce-
> request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
> ._._._
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From laurent at genome.cbs.dtu.dk  Tue Apr 30 10:23:58 2002
From: laurent at genome.cbs.dtu.dk (Laurent Gautier)
Date: Tue, 30 Apr 2002 10:23:58 +0200
Subject: [R] trouble with R-1.5.0 and readline.h at an odd place on SGI
Message-ID: <20020430082358.GA1253@giraffa.cbs.dtu.dk>


Hello,


I am trying to get readline to work on SGI IRIX 6.5 with R-1.5.0.
The '.h' files are scattered in many places to I had to specify where to look for them in CPPFLAGS in config.site. Unfortunately, this does not seem to be enough. Looking into 'config.log', I found the following:

configure:3896: gcc -c -g -O2 -I/usr/freeware/include -I/usr/local/include -I/usr/freeware/include/readline conftest.c >&5
conftest.c:2: parse error before "me"
configure:3899: $? = 1
configure: failed program was:
#ifndef __cplusplus
  choke me
#endif

suggestions ?


Thanks in advance,



Laurent



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From david.meyer at ci.tuwien.ac.at  Tue Apr 30 11:42:12 2002
From: david.meyer at ci.tuwien.ac.at (David Meyer)
Date: Tue, 30 Apr 2002 11:42:12 +0200
Subject: [R] calling optim from external C/C++ program
References: <Pine.GSO.4.44.0204300712270.28784-100000@auk.stats>
Message-ID: <3CCE66F4.ED7C9F31@ci.tuwien.ac.at>

> 
> There is also no such thing as gcc 2.96: see gcc.gnu.org.  You would be
> well-advised to use a released version of gcc.

..altough Red Hat claimed to use one (see e.g., 

http://www.redhat.com/support/errata/RHBA-2000-132.html

) but in any case it's a bad idea to use it ;)

g.,
-d

> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-- 
	Mag. David Meyer		Wiedner Hauptstrasse 8-10
Vienna University of Technology		A-1040 Vienna/AUSTRIA
         Department of			Tel.: (+431) 58801/10772
Statistics and Probability Theory	mail: david.meyer at ci.tuwien.ac.at
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr 30 11:47:13 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 30 Apr 2002 10:47:13 +0100 (BST)
Subject: [R] calling optim from external C/C++ program
In-Reply-To: <3CCE66F4.ED7C9F31@ci.tuwien.ac.at>
Message-ID: <Pine.GSO.4.44.0204301041440.28952-100000@auk.stats>

On Tue, 30 Apr 2002, David Meyer wrote:

> >
> > There is also no such thing as gcc 2.96: see gcc.gnu.org.  You would be
> > well-advised to use a released version of gcc.
>
> ...altough Red Hat claimed to use one (see e.g.,
>
> http://www.redhat.com/support/errata/RHBA-2000-132.html
>
> ) but in any case it's a bad idea to use it ;)

Oh, they have shipped a version of gcc purporting to be 2.96 (and still
do AFAIK).  However,  there is no such version of gcc, see

http://gcc.gnu.org/releases.html
http://gcc.gnu.org/gcc-2.96.html

and there are known problems with the `2.96' in RH7.1 and RH7.2 which have
affecting compiling R and its packages.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From steinep at uni-muenster.de  Tue Apr 30 15:11:13 2002
From: steinep at uni-muenster.de (Petra Steiner)
Date: Tue, 30 Apr 2002 15:11:13 +0200 (MES)
Subject: [R] read in a matrix, difference between 1.3.1 (Windows) and 1.4.1 (Unix)
In-Reply-To: <20020430192250.A1035@camille.indigoindustrial.co.nz>
Message-ID: <Pine.A41.4.40.0204301457040.53354-100000@zivunix.uni-muenster.de>


Hello,

I am reading in a matrix with ignoring the first line. With the exception of
the first column (column names) each value is numeric.

Up to now the following worked well, although a bit slow.

tabx <-  matrix(scan("myfile", what =
"", skip=1, quote = ""), byrow=T, nrow=reihenz, ncol=spaltenz)
print(tabx)
taby <- apply(tabx[1:reihenz,2:spaltenz], 2, as.numeric)
rownames(taby) <- tabx[,1]
print(taby)

Now, with Version 1.4.1 under Unix, for tabx I get a table with the first line
repeated many times. as.numeric is not applicable of course.

Maybe read.table would be better? But I have to read a lot of data!

Regards,
Petra Steiner

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jay at m5.chi.il.us  Tue Apr 30 16:18:36 2002
From: jay at m5.chi.il.us (Jay F Shachter)
Date: Tue, 30 Apr 2002 08:18:36 -0600 (CDT)
Subject: [R] followup -- deficiencies in readline capability
Message-ID: <200204301318.IAA13731@m5.chi.il.us>

Why would R lack history capability?

Someone in a private electronic mail message suggested the possibility
that I was running R in a non-writable directory.  This is not the
case, as the following logfile shows (where "$ " is my shell prompt):

$ ls -ld `pwd`
drwxrwxrwx   15 sys      sys          2560 Apr 30 08:10 /tmp
$ R --vanilla

R : Copyright 2002, The R Development Core Team
Version 1.4.1  (2002-01-30)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type `license()' or `licence()' for distribution details.

R is a collaborative project with many contributors.
Type `contributors()' for more information.

Type `demo()' for some demos, `help()' for on-line help, or
`help.start()' for a HTML browser interface to help.
Type `q()' to quit R.

> debug(history)
> debug(savehistory)
> history()
debugging in: history()
debug: {
    file1 <- tempfile("Rrawhist")
    savehistory(file1)
    rawhist <- scan(file1, what = "", quiet = TRUE, sep = "\n")
    unlink(file1)
    nlines <- length(rawhist)
    inds <- max(1, nlines - max.show):nlines
    if (reverse) 
        inds <- rev(inds)
    file2 <- tempfile("hist")
    write(rawhist[inds], file2)
    file.show(file2, title = "R History", delete.file = TRUE)
}

Browse[1]> 
debug: file1 <- tempfile("Rrawhist")

Browse[1]> 
debug: savehistory(file1)

Browse[1]> 
debugging in: savehistory(file1)
debug: invisible(.Internal(savehistory(file)))

Browse[1]> 
Error in savehistory(file) : no history available to save
> q()
$



My R clearly lacks history capability, and I have no idea why.
What can be the cause of this behavior, and how can it be undone?

			Jay F. Shachter
			6424 N Whipple St
			Chicago IL  60645-4111
				(1-773)7613784
				jay at m5.chi.il.us
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr 30 15:27:49 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 30 Apr 2002 14:27:49 +0100 (BST)
Subject: [R] followup -- deficiencies in readline capability
In-Reply-To: <200204301318.IAA13731@m5.chi.il.us>
Message-ID: <Pine.LNX.4.31.0204301421140.22582-100000@gannet.stats>

R 1.4.1 is not current.  I suggest you try again with the current version
1.5.0, as that has a lot of other benefits.

You get the `no history available to save' message from savehistroy() if
either of
HAVE_LIBREADLINE
HAVE_READLINE_HISTORY_H
is not defined (or you have a non-interactive session or used
--no-readline).  (I wrote that interface it ....)

So the issue is in *your* readline installation as described by *you* to
configure.  The answer is simple: you need to read the installation
manual and ensure that you supply a suitable version of readline
*and its headers*.

On Tue, 30 Apr 2002, Jay F Shachter wrote:

> Why would R lack history capability?
>
> Someone in a private electronic mail message suggested the possibility
> that I was running R in a non-writable directory.  This is not the
> case, as the following logfile shows (where "$ " is my shell prompt):
>
> $ ls -ld `pwd`
> drwxrwxrwx   15 sys      sys          2560 Apr 30 08:10 /tmp
> $ R --vanilla
>
> R : Copyright 2002, The R Development Core Team
> Version 1.4.1  (2002-01-30)
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type `license()' or `licence()' for distribution details.
>
> R is a collaborative project with many contributors.
> Type `contributors()' for more information.
>
> Type `demo()' for some demos, `help()' for on-line help, or
> `help.start()' for a HTML browser interface to help.
> Type `q()' to quit R.
>
> > debug(history)
> > debug(savehistory)
> > history()
> debugging in: history()
> debug: {
>     file1 <- tempfile("Rrawhist")
>     savehistory(file1)
>     rawhist <- scan(file1, what = "", quiet = TRUE, sep = "\n")
>     unlink(file1)
>     nlines <- length(rawhist)
>     inds <- max(1, nlines - max.show):nlines
>     if (reverse)
>         inds <- rev(inds)
>     file2 <- tempfile("hist")
>     write(rawhist[inds], file2)
>     file.show(file2, title = "R History", delete.file = TRUE)
> }
>
> Browse[1]>
> debug: file1 <- tempfile("Rrawhist")
>
> Browse[1]>
> debug: savehistory(file1)
>
> Browse[1]>
> debugging in: savehistory(file1)
> debug: invisible(.Internal(savehistory(file)))
>
> Browse[1]>
> Error in savehistory(file) : no history available to save
> > q()
> $
>
>
>
> My R clearly lacks history capability, and I have no idea why.
> What can be the cause of this behavior, and how can it be undone?
>
> 			Jay F. Shachter
> 			6424 N Whipple St
> 			Chicago IL  60645-4111
> 				(1-773)7613784
> 				jay at m5.chi.il.us
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Apr 30 15:38:38 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 30 Apr 2002 15:38:38 +0200
Subject: [R] read in a matrix, difference between 1.3.1 (Windows) and 1.4.1 (Unix)
In-Reply-To: <Pine.A41.4.40.0204301457040.53354-100000@zivunix.uni-muenster.de>
References: <Pine.A41.4.40.0204301457040.53354-100000@zivunix.uni-muenster.de>
Message-ID: <x2wuupmhlt.fsf@blueberry.kubism.ku.dk>

Petra Steiner <steinep at uni-muenster.de> writes:

> I am reading in a matrix with ignoring the first line. With the exception of
> the first column (column names) each value is numeric.
> 
> Up to now the following worked well, although a bit slow.
> 
> tabx <-  matrix(scan("myfile", what =
> "", skip=1, quote = ""), byrow=T, nrow=reihenz, ncol=spaltenz)
> print(tabx)
> taby <- apply(tabx[1:reihenz,2:spaltenz], 2, as.numeric)
> rownames(taby) <- tabx[,1]
> print(taby)
> 
> Now, with Version 1.4.1 under Unix, for tabx I get a table with the first line
> repeated many times. as.numeric is not applicable of course.
> 
> Maybe read.table would be better? But I have to read a lot of data!

An example of what your data look like would be helpful. Both for
helping you out and to help fix what sounds like a bug.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wolski at molgen.mpg.de  Tue Apr 30 16:58:23 2002
From: wolski at molgen.mpg.de (Witold Eryk Wolski)
Date: Tue, 30 Apr 2002 15:58:23 +0100
Subject: [R] data.frame package?
Message-ID: <3CCEB10F.4080607@molgen.mpg.de>

Is there a library that is able for example to
1. merge 2 dataframes by row  eg.: rbind(dataframe1, dataframe2):data.frame
2. delete a column from a dataframe del(dataframe, colname) or 
del(dataframe, colindex= 1):data.frame?
3. Select lines from a dataframe by a specific function ? 
select(dataframe, func=small(x){x<1}, colindex=3): data.frame?
4. converting all double columns of a data.frame to a matrix. 
datafram_to_matrix(dataframe1):matrix

If not would not it be usefull to have such a library on the cran?

Sincerely
Eryk


-- 
    \|/     \|/     \|/
    'v'     'v'     'v'
  //| |\\ //| |\\ //| |\\
----m-m-----m-m-----m-m-------w-w-----
                            \\| |//
   Eryk Witold Wolski         .^.
                              /|\
wolski at molen.mpg.de
tel      : 0049-(0)30-8413-1543
fax      : 0049-(0)30-8413-1139
mobile   : 0049-1793210931
http://www.molgen.mpg.de/~mass-spec
http://www.molgen.mpg.de/~wolski


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From steinep at uni-muenster.de  Tue Apr 30 16:24:31 2002
From: steinep at uni-muenster.de (Petra Steiner)
Date: Tue, 30 Apr 2002 16:24:31 +0200 (MES)
Subject: [R] read in a matrix, difference between 1.3.1 (Windows) and
 1.4.1 (Unix)
In-Reply-To: <x2wuupmhlt.fsf@blueberry.kubism.ku.dk>
Message-ID: <Pine.A41.4.40.0204301617300.79118-100000@zivunix.uni-muenster.de>

Hello and thanks for the reply,

let me first re-generate the data, maybe this is the reason why ... -
although it is strange.

Regards,
Petra



> Petra Steiner <steinep at uni-muenster.de> writes:
>
> > I am reading in a matrix with ignoring the first line. With the exception of
> > the first column (column names) each value is numeric.
> >
> > Up to now the following worked well, although a bit slow.
> >
> > tabx <-  matrix(scan("myfile", what =
> > "", skip=1, quote = ""), byrow=T, nrow=reihenz, ncol=spaltenz)
> > print(tabx)
> > taby <- apply(tabx[1:reihenz,2:spaltenz], 2, as.numeric)
> > rownames(taby) <- tabx[,1]
> > print(taby)
> >
> > Now, with Version 1.4.1 under Unix, for tabx I get a table with the first line
> > repeated many times. as.numeric is not applicable of course.
> >
> > Maybe read.table would be better? But I have to read a lot of data!
>
> An example of what your data look like would be helpful. Both for
> helping you out and to help fix what sounds like a bug.
>
> --
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From anielsen at dina.kvl.dk  Tue Apr 30 16:40:17 2002
From: anielsen at dina.kvl.dk (Anders Nielsen)
Date: 30 Apr 2002 16:40:17 +0200
Subject: [R] data.frame package?
In-Reply-To: <3CCEB10F.4080607@molgen.mpg.de>
References: <3CCEB10F.4080607@molgen.mpg.de>
Message-ID: <1020177617.2176.13.camel@fisher.dina.kvl.dk>

Dear Eryk

All of these operations are possible in R, as the following 
example show 

Kind regards, 

Anders.  

> data1<-data.frame(x=1:5, y=1:5/10)
> data2<-data.frame(x=6:10, y=6:10/10)
> data12<-rbind(data1,data2)
> data12
    x   y
1   1 0.1
2   2 0.2
3   3 0.3
4   4 0.4
5   5 0.5
6   6 0.6
7   7 0.7
8   8 0.8
9   9 0.9
10 10 1.0
> is.data.frame(data12)
[1] TRUE
> data12x<-subset(data12, select=-y)
> data12x
    x
1   1
2   2
3   3
4   4
5   5
6   6
7   7
8   8
9   9
10 10
> data12BigX<-subset(data12, x>5)
> data12BigX
    x   y
6   6 0.6
7   7 0.7
8   8 0.8
9   9 0.9
10 10 1.0
> data12BigX
> as.matrix(data12)
    x   y
1   1 0.1
2   2 0.2
3   3 0.3
4   4 0.4
5   5 0.5
6   6 0.6
7   7 0.7
8   8 0.8
9   9 0.9
10 10 1.0

On Tue, 2002-04-30 at 16:58, Witold Eryk Wolski wrote:
> Is there a library that is able for example to
> 1. merge 2 dataframes by row  eg.: rbind(dataframe1, dataframe2):data.frame
> 2. delete a column from a dataframe del(dataframe, colname) or 
> del(dataframe, colindex= 1):data.frame?
> 3. Select lines from a dataframe by a specific function ? 
> select(dataframe, func=small(x){x<1}, colindex=3): data.frame?
> 4. converting all double columns of a data.frame to a matrix. 
> datafram_to_matrix(dataframe1):matrix
> 
> If not would not it be usefull to have such a library on the cran?
> 
> Sincerely
> Eryk
> 
> 
> -- 
>     \|/     \|/     \|/
>     'v'     'v'     'v'
>   //| |\\ //| |\\ //| |\\
> ----m-m-----m-m-----m-m-------w-w-----
>                             \\| |//
>    Eryk Witold Wolski         .^.
>                               /|\
> wolski at molen.mpg.de
> tel      : 0049-(0)30-8413-1543
> fax      : 0049-(0)30-8413-1139
> mobile   : 0049-1793210931
> http://www.molgen.mpg.de/~mass-spec
> http://www.molgen.mpg.de/~wolski
> 
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From steinep at uni-muenster.de  Tue Apr 30 16:42:56 2002
From: steinep at uni-muenster.de (Petra Steiner)
Date: Tue, 30 Apr 2002 16:42:56 +0200 (MES)
Subject: [R] read in a matrix, difference between 1.3.1 (Windows) and
 1.4.1 (Unix)
In-Reply-To: <x2wuupmhlt.fsf@blueberry.kubism.ku.dk>
Message-ID: <Pine.A41.4.40.0204301635210.90748-100000@zivunix.uni-muenster.de>

After I generated the data anew, I am at least sure that the number of tabs
is ok.
Anyway, there must be something wrong with the data, maybe a meta character:

The data looks like that:
First row

	'	(	)	,	-	...	1920	1932	1939
1940	1945	1956	1960	1979	1982	1984	1985	1987	1988
1989	1990	1992	45	:	Aachen	Abb.	Abbau

etc. etc.

Next rows to the end:

,#die           and by tab separated numbers
zu#.            and by tab separated numbers

maybe # is now forbidden?
The program works for small test data.

Regards,
Petra









On 30 Apr 2002, Peter Dalgaard BSA wrote:

> Date: 30 Apr 2002 15:38:38 +0200
> From: Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk>
> To: Petra Steiner <steinep at uni-muenster.de>
> Cc: petra at uni-muenster.de, r-help at stat.math.ethz.ch
> Subject: Re: [R] read in a matrix,
>      difference between 1.3.1 (Windows) and 1.4.1 (Unix)
>
> Petra Steiner <steinep at uni-muenster.de> writes:
>
> > I am reading in a matrix with ignoring the first line. With the exception of
> > the first column (column names) each value is numeric.
> >
> > Up to now the following worked well, although a bit slow.
> >
> > tabx <-  matrix(scan("myfile", what =
> > "", skip=1, quote = ""), byrow=T, nrow=reihenz, ncol=spaltenz)
> > print(tabx)
> > taby <- apply(tabx[1:reihenz,2:spaltenz], 2, as.numeric)
> > rownames(taby) <- tabx[,1]
> > print(taby)
> >
> > Now, with Version 1.4.1 under Unix, for tabx I get a table with the first line
> > repeated many times. as.numeric is not applicable of course.
> >
> > Maybe read.table would be better? But I have to read a lot of data!
>
> An example of what your data look like would be helpful. Both for
> helping you out and to help fix what sounds like a bug.
>
> --
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From a296180 at mica.fmr.com  Tue Apr 30 16:47:12 2002
From: a296180 at mica.fmr.com (David Kane  <David Kane)
Date: Tue, 30 Apr 2002 10:47:12 -0400
Subject: [R] display of character NA's in a dataframe in 1.5.0
Message-ID: <15566.44656.913593.732620@gargle.gargle.HOWL>

I understand that NA's in character vectors are displayed differently than NA's
in factor vectors.

> c("x", NA, "y")
[1] "x" NA  "y"
> as.factor(c("x", NA, "y"))
[1] x    <NA> y   
Levels:  x y 

That seems sensible enough. But shouldn't I see the same behavior in a dataframe?

> test <- data.frame(a = c("x", NA, "y"))
> test
     a
1    x
2   <NA>
3    y
> is.factor(test$a)
[1] TRUE
> is.character(test$a)
[1] FALSE

This behavior is correct since R coerces `a' to be a factor as it constructs
the test dataframe. But consider what happens when I force `a' to be character:

> test$a <- as.character(test$a)
> is.factor(test$a)
[1] FALSE
> is.character(test$a)
[1] TRUE
> test
     a
1    x
2   <NA>
3    y

The display is the same. I would have expected it to be something like:

> test
     a
1    x
2   NA
3    y

If this is a bug, please let me know and I would be happy to submit it as
such. But, I suspect that it is more likely that there is something that I
don't fully understand about NA's and dataframes.


> R.version
         _                   
platform sparc-sun-solaris2.6
arch     sparc               
os       solaris2.6          
system   sparc, solaris2.6   
status                       
major    1                   
minor    5.0                 
year     2002                
month    04                  
day      29                  
language R                   

Thanks,

Dave Kane
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From wolski at molgen.mpg.de  Tue Apr 30 17:57:19 2002
From: wolski at molgen.mpg.de (Witold Eryk Wolski)
Date: Tue, 30 Apr 2002 16:57:19 +0100
Subject: Isnt it a a documentation bug in the data.fram or rbind docu?  Re: [R] data.frame package? 
References: <3CCEB10F.4080607@molgen.mpg.de> <1020177617.2176.13.camel@fisher.dina.kvl.dk>
Message-ID: <3CCEBEDF.7020605@molgen.mpg.de>

Thx i never used and heard about subset.
Subset isn't  mentioned in the see also section of the data.frame function.
And it is missing in the R intro to.

The rbind description says.
...         vectors or matrices. (but nothing about data.frames)

And subset is not working for strings.
But what if you have in your dataframe char (string data)?
eg.: subset(data1,name=grep("Anders")) wouldn't work.


Sincerely
Eryk


Anders Nielsen wrote:

>Dear Eryk
>
>All of these operations are possible in R, as the following 
>example show 
>
>Kind regards, 
>
>Anders.  
>
>>data1<-data.frame(x=1:5, y=1:5/10)
>>data2<-data.frame(x=6:10, y=6:10/10)
>>data12<-rbind(data1,data2)
>>data12
>>
>    x   y
>1   1 0.1
>2   2 0.2
>3   3 0.3
>4   4 0.4
>5   5 0.5
>6   6 0.6
>7   7 0.7
>8   8 0.8
>9   9 0.9
>10 10 1.0
>
>>is.data.frame(data12)
>>
>[1] TRUE
>
>>data12x<-subset(data12, select=-y)
>>data12x
>>
>    x
>1   1
>2   2
>3   3
>4   4
>5   5
>6   6
>7   7
>8   8
>9   9
>10 10
>
>>data12BigX<-subset(data12, x>5)
>>data12BigX
>>
>    x   y
>6   6 0.6
>7   7 0.7
>8   8 0.8
>9   9 0.9
>10 10 1.0
>
>>data12BigX
>>as.matrix(data12)
>>
>    x   y
>1   1 0.1
>2   2 0.2
>3   3 0.3
>4   4 0.4
>5   5 0.5
>6   6 0.6
>7   7 0.7
>8   8 0.8
>9   9 0.9
>10 10 1.0
>
>On Tue, 2002-04-30 at 16:58, Witold Eryk Wolski wrote:
>
>>Is there a library that is able for example to
>>1. merge 2 dataframes by row  eg.: rbind(dataframe1, dataframe2):data.frame
>>2. delete a column from a dataframe del(dataframe, colname) or 
>>del(dataframe, colindex= 1):data.frame?
>>3. Select lines from a dataframe by a specific function ? 
>>select(dataframe, func=small(x){x<1}, colindex=3): data.frame?
>>4. converting all double columns of a data.frame to a matrix. 
>>datafram_to_matrix(dataframe1):matrix
>>
>>If not would not it be usefull to have such a library on the cran?
>>
>>Sincerely
>>Eryk
>>
>>
>>-- 
>>    \|/     \|/     \|/
>>    'v'     'v'     'v'
>>  //| |\\ //| |\\ //| |\\
>>----m-m-----m-m-----m-m-------w-w-----
>>                            \\| |//
>>   Eryk Witold Wolski         .^.
>>                              /|\
>>wolski at molen.mpg.de
>>tel      : 0049-(0)30-8413-1543
>>fax      : 0049-(0)30-8413-1139
>>mobile   : 0049-1793210931
>>http://www.molgen.mpg.de/~mass-spec
>>http://www.molgen.mpg.de/~wolski
>>
>>
>>-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
>>r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
>>Send "info", "help", or "[un]subscribe"
>>(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>>_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>>
>
>

-- 
    \|/     \|/     \|/
    'v'     'v'     'v'
  //| |\\ //| |\\ //| |\\
----m-m-----m-m-----m-m-------w-w-----
                             \\| |//
   Eryk Witold Wolski          .^.
                               /|\
wolski at molen.mpg.de
tel      : 0049-(0)30-8413-1543
fax      : 0049-(0)30-8413-1139
mobile   : 0049-1793210931
http://www.molgen.mpg.de/~mass-spec
http://www.molgen.mpg.de/~wolski


-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20020430/9e4f60e0/attachment.html

From a296180 at mica.fmr.com  Tue Apr 30 17:08:33 2002
From: a296180 at mica.fmr.com (David Kane  <David Kane)
Date: Tue, 30 Apr 2002 11:08:33 -0400
Subject: [R] rbind'ing empty rows in dataframes in 1.4.1 versus 1.5.0
Message-ID: <15566.45937.8947.426293@gargle.gargle.HOWL>

Hi,

In 1.4.1, I was able to create extra "empty" rows in a dataframe as so:

> x <- data.frame(a = letters[1:3], b = 1:3)
> x
  a b
1 a 1
2 b 2
3 c 3
> x[4,]
    a  b
NA NA NA
> rbind(x, x[4,])
    a  b
1   a  1
2   b  2
3   c  3
NA NA NA
> R.version
         _                   
platform sparc-sun-solaris2.6
arch     sparc               
os       solaris2.6          
system   sparc, solaris2.6   
status                       
major    1                   
minor    4.1                 
year     2002                
month    01                  
day      30                  
language R                   

This does not work in 1.5.0

> x <- data.frame(a = letters[1:3], b = 1:3)
> x
  a b
1 a 1
2 b 2
3 c 3
> x[4,]
        a  b
<NA>     <NA> NA
> rbind(x, x[4,])
Error in if (nrow > 0 && all(ri == 1:ni)) seq(from = nrow + 1, length = ni) else ri : 
	missing value where logical needed
> R.version
         _                   
platform sparc-sun-solaris2.6
arch     sparc               
os       solaris2.6          
system   sparc, solaris2.6   
status                       
major    1                   
minor    5.0                 
year     2002                
month    04                  
day      29                  
language R                   

Note that, contrary to my first guess, this has nothing (?) to do with the new
NA in character vectors since I see the same behavior with numeric only
dataframes.

> x <- data.frame(a = 5:7, b = 1:3)
> x
  a b
1 5 1
2 6 2
3 7 3
> x[4,]
      a  b
<NA>   NA NA
> rbind(x, x[4,])
Error in if (nrow > 0 && all(ri == 1:ni)) seq(from = nrow + 1, length = ni) else ri : 
	missing value where logical needed


I didn't see anything in the NEWS about this change. Could someone please
explain what is going one? Any words of wisom about the "right" way to create
empty rows in dataframe (which I then fill in variable by variable later in the
program) would also be appreciated.

Thanks,

Dave Kane
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From anielsen at dina.kvl.dk  Tue Apr 30 17:15:17 2002
From: anielsen at dina.kvl.dk (Anders Nielsen)
Date: 30 Apr 2002 17:15:17 +0200
Subject: [R] Re: Isnt it a a documentation bug in the data.fram or rbind docu? 
	Re: [R] data.frame package?
In-Reply-To: <3CCEBEDF.7020605@molgen.mpg.de>
References: <3CCEB10F.4080607@molgen.mpg.de>
	<1020177617.2176.13.camel@fisher.dina.kvl.dk> 
	<3CCEBEDF.7020605@molgen.mpg.de>
Message-ID: <1020179718.2176.24.camel@fisher.dina.kvl.dk>

Dear Eryk



On Tue, 2002-04-30 at 17:57, Witold Eryk Wolski wrote:
> Thx i never used and heard about subset.
> Subset isn't  mentioned in the see also section of the data.frame function.
> And it is missing in the R intro to.
> 
> The rbind description says.
> ...         vectors or matrices. (but nothing about data.frames)
> 
> And subset is not working for strings.
> But what if you have in your dataframe char (string data)?
> eg.: subset(data1,name=grep("Anders")) wouldn't work.

But the following will: 

> dat<-data.frame(name=c("Anders", "Eryk", "Eryk"), y=1:3)
> dat
    name y
1 Anders 1
2   Eryk 2
3   Eryk 3
> dat.Anders<-subset(dat, name=="Anders")
> dat.Anders
    name y
1 Anders 1
>


Kind regards, 

anders. 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr 30 17:36:12 2002
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 30 Apr 2002 16:36:12 +0100 (GMT Daylight Time)
Subject: [R] read in a matrix, difference between 1.3.1 (Windows) and
 1.4.1 (Unix)
In-Reply-To: <Pine.A41.4.40.0204301635210.90748-100000@zivunix.uni-muenster.de>
Message-ID: <Pine.WNT.4.44.0204301635010.2888-100000@Reeve>

# is the comment character as from 1.4.1.  There is an option to turn it
off, and that is both in the NEWS file and on the help page.

On Tue, 30 Apr 2002, Petra Steiner wrote:

> After I generated the data anew, I am at least sure that the number of tabs
> is ok.
> Anyway, there must be something wrong with the data, maybe a meta character:
>
> The data looks like that:
> First row
>
> 	'	(	)	,	-	...	1920	1932	1939
> 1940	1945	1956	1960	1979	1982	1984	1985	1987	1988
> 1989	1990	1992	45	:	Aachen	Abb.	Abbau
>
> etc. etc.
>
> Next rows to the end:
>
> ,#die           and by tab separated numbers
> zu#.            and by tab separated numbers
>
> maybe # is now forbidden?
> The program works for small test data.
>
> Regards,
> Petra
>
>
>
>
>
>
>
>
>
> On 30 Apr 2002, Peter Dalgaard BSA wrote:
>
> > Date: 30 Apr 2002 15:38:38 +0200
> > From: Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk>
> > To: Petra Steiner <steinep at uni-muenster.de>
> > Cc: petra at uni-muenster.de, r-help at stat.math.ethz.ch
> > Subject: Re: [R] read in a matrix,
> >      difference between 1.3.1 (Windows) and 1.4.1 (Unix)
> >
> > Petra Steiner <steinep at uni-muenster.de> writes:
> >
> > > I am reading in a matrix with ignoring the first line. With the exception of
> > > the first column (column names) each value is numeric.
> > >
> > > Up to now the following worked well, although a bit slow.
> > >
> > > tabx <-  matrix(scan("myfile", what =
> > > "", skip=1, quote = ""), byrow=T, nrow=reihenz, ncol=spaltenz)
> > > print(tabx)
> > > taby <- apply(tabx[1:reihenz,2:spaltenz], 2, as.numeric)
> > > rownames(taby) <- tabx[,1]
> > > print(taby)
> > >
> > > Now, with Version 1.4.1 under Unix, for tabx I get a table with the first line
> > > repeated many times. as.numeric is not applicable of course.
> > >
> > > Maybe read.table would be better? But I have to read a lot of data!
> >
> > An example of what your data look like would be helpful. Both for
> > helping you out and to help fix what sounds like a bug.
> >
> > --
> >    O__  ---- Peter Dalgaard             Blegdamsvej 3
> >   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
> >  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> > ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
> >
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr 30 17:38:33 2002
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 30 Apr 2002 16:38:33 +0100 (GMT Daylight Time)
Subject: [R] display of character NA's in a dataframe in 1.5.0
In-Reply-To: <15566.44656.913593.732620@gargle.gargle.HOWL>
Message-ID: <Pine.WNT.4.44.0204301636430.2888-100000@Reeve>

This is not a bug, and it is described in the section on USER-VISIBLE
CHANGES in the NEWS file!

Hint: consider the setting of the quote argument when printing.


On Tue, 30 Apr 2002, David Kane  <David Kane wrote:

> I understand that NA's in character vectors are displayed differently than NA's
> in factor vectors.
>
> > c("x", NA, "y")
> [1] "x" NA  "y"
> > as.factor(c("x", NA, "y"))
> [1] x    <NA> y
> Levels:  x y
>
> That seems sensible enough. But shouldn't I see the same behavior in a dataframe?
>
> > test <- data.frame(a = c("x", NA, "y"))
> > test
>      a
> 1    x
> 2   <NA>
> 3    y
> > is.factor(test$a)
> [1] TRUE
> > is.character(test$a)
> [1] FALSE
>
> This behavior is correct since R coerces `a' to be a factor as it constructs
> the test dataframe. But consider what happens when I force `a' to be character:
>
> > test$a <- as.character(test$a)
> > is.factor(test$a)
> [1] FALSE
> > is.character(test$a)
> [1] TRUE
> > test
>      a
> 1    x
> 2   <NA>
> 3    y
>
> The display is the same. I would have expected it to be something like:
>
> > test
>      a
> 1    x
> 2   NA
> 3    y

But then you would have though NA meant Nabisco.

>
> If this is a bug, please let me know and I would be happy to submit it as
> such. But, I suspect that it is more likely that there is something that I
> don't fully understand about NA's and dataframes.
>
>
> > R.version
>          _
> platform sparc-sun-solaris2.6
> arch     sparc
> os       solaris2.6
> system   sparc, solaris2.6
> status
> major    1
> minor    5.0
> year     2002
> month    04
> day      29
> language R
>
> Thanks,
>
> Dave Kane
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Apr 30 17:40:53 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 30 Apr 2002 17:40:53 +0200
Subject: [R] rbind'ing empty rows in dataframes in 1.4.1 versus 1.5.0
In-Reply-To: <15566.45937.8947.426293@gargle.gargle.HOWL>
References: <15566.45937.8947.426293@gargle.gargle.HOWL>
Message-ID: <x2znzl19fe.fsf@blueberry.kubism.ku.dk>

"David Kane  <David Kane" <a296180 at mica.fmr.com> writes:

> This does not work in 1.5.0
> 
> > x <- data.frame(a = letters[1:3], b = 1:3)
> > x
>   a b
> 1 a 1
> 2 b 2
> 3 c 3
> > x[4,]
>         a  b
> <NA>     <NA> NA
> > rbind(x, x[4,])
> Error in if (nrow > 0 && all(ri == 1:ni)) seq(from = nrow + 1, length = ni) else ri : 
> 	missing value where logical needed
> > R.version
...
> Note that, contrary to my first guess, this has nothing (?) to do with the new
> NA in character vectors since I see the same behavior with numeric only
> dataframes.
...
> I didn't see anything in the NEWS about this change. Could someone please
> explain what is going one? Any words of wisom about the "right" way to create
> empty rows in dataframe (which I then fill in variable by variable later in the
> program) would also be appreciated.

We can't anticipate *everything* that people will try to do...

I bet the behaviour has to do with new NA in *rownames*. You could try
inserting a meaningful name. It probably counts as a bug:

> airquality[as.numeric(NA),]
     Ozone Solar.R Wind Temp Month Day
<NA>      NA      NA   NA   NA    NA  NA
> airquality[rep(as.numeric(NA),7),]
    Ozone Solar.R Wind Temp Month Day
NA     NA      NA   NA   NA    NA  NA
NA1    NA      NA   NA   NA    NA  NA
NA2    NA      NA   NA   NA    NA  NA
NA3    NA      NA   NA   NA    NA  NA
NA4    NA      NA   NA   NA    NA  NA
NA5    NA      NA   NA   NA    NA  NA
NA6    NA      NA   NA   NA    NA  NA

> airquality[c(1,NA),]
     Ozone Solar.R Wind Temp Month Day
<NA>      NA      NA   NA   NA    NA  NA

Notice that it is only when there's a single NA row that we see the problem.
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr 30 17:44:47 2002
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 30 Apr 2002 16:44:47 +0100 (GMT Daylight Time)
Subject: [R] rbind'ing empty rows in dataframes in 1.4.1 versus 1.5.0
In-Reply-To: <15566.45937.8947.426293@gargle.gargle.HOWL>
Message-ID: <Pine.WNT.4.44.0204301641210.2888-100000@Reeve>

This is indeed to do with missingness of character strings.  Data frames
cannot have missing row names, and that's what your code creates.  So give
your missing (it is definitely not `empty') row a valid row name.

On Tue, 30 Apr 2002, David Kane  <David Kane wrote:

> Hi,
>
> In 1.4.1, I was able to create extra "empty" rows in a dataframe as so:
>
> > x <- data.frame(a = letters[1:3], b = 1:3)
> > x
>   a b
> 1 a 1
> 2 b 2
> 3 c 3
> > x[4,]
>     a  b
> NA NA NA
> > rbind(x, x[4,])
>     a  b
> 1   a  1
> 2   b  2
> 3   c  3
> NA NA NA
> > R.version
>          _
> platform sparc-sun-solaris2.6
> arch     sparc
> os       solaris2.6
> system   sparc, solaris2.6
> status
> major    1
> minor    4.1
> year     2002
> month    01
> day      30
> language R
>
> This does not work in 1.5.0
>
> > x <- data.frame(a = letters[1:3], b = 1:3)
> > x
>   a b
> 1 a 1
> 2 b 2
> 3 c 3
> > x[4,]
>         a  b
> <NA>     <NA> NA
> > rbind(x, x[4,])
> Error in if (nrow > 0 && all(ri == 1:ni)) seq(from = nrow + 1, length = ni) else ri :
> 	missing value where logical needed
> > R.version
>          _
> platform sparc-sun-solaris2.6
> arch     sparc
> os       solaris2.6
> system   sparc, solaris2.6
> status
> major    1
> minor    5.0
> year     2002
> month    04
> day      29
> language R
>
> Note that, contrary to my first guess, this has nothing (?) to do with the new
> NA in character vectors since I see the same behavior with numeric only
> dataframes.
>
> > x <- data.frame(a = 5:7, b = 1:3)
> > x
>   a b
> 1 5 1
> 2 6 2
> 3 7 3
> > x[4,]
>       a  b
> <NA>   NA NA
> > rbind(x, x[4,])
> Error in if (nrow > 0 && all(ri == 1:ni)) seq(from = nrow + 1, length = ni) else ri :
> 	missing value where logical needed
>
>
> I didn't see anything in the NEWS about this change. Could someone please
> explain what is going one? Any words of wisom about the "right" way to create
> empty rows in dataframe (which I then fill in variable by variable later in the
> program) would also be appreciated.
>
> Thanks,
>
> Dave Kane
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From yiping.fan at syngenta.com  Tue Apr 30 18:23:14 2002
From: yiping.fan at syngenta.com (yiping.fan@syngenta.com)
Date: Tue, 30 Apr 2002 18:23:14 +0200
Subject: [R] regression, for loop
Message-ID: <AF84AD19B4A8D411B18500508BAF0E0EC299B5@se-excur01-uslj.nadi.uslj>

Hello, all
   Here are the questions I have:
data samples:
 Data          style  x   y
data1   r       2   3
data1   r       3  4
data1   r       4 5
data1   g      4  5
data1  g      6  7
data1  g     6   7
data2  r    8  9
data2  r     8  9
data2  r     8   9
data2  g     8    9 
data2  g      8   9
data2   g   8    9
...
datan


we have n data  (data1 - datan).  For each data, I want to do a simple
regression:
y ~ x+style
I am using a for loop now
for(i in 1:n){
   data.name=Data[i];
   res<-lm(y~x+style, data, subset=(Data == data.name) )
}  

I am wondering whether it is possible to do the same without using for loop?
Also,  after regression, I am only interested in getting  the P value for
style, how to extract it?

Thank you very much!
 
          Best regards,

Y. Fan
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From B.Mao at cerep.com  Tue Apr 30 18:52:54 2002
From: B.Mao at cerep.com (Boryeu Mao)
Date: Tue, 30 Apr 2002 09:52:54 -0700
Subject: [R] how to trap any warnings from an R function
Message-ID: <0957E70F25F7D111974B00A0C9833064AF88C7@mayo.cerep.com>

Thanks for the reply.  The problem that I have in a nutshell is the
following:

usertest <- function {
 ...
 reg<-polr(act~., data=mm)
 summary(reg)
 return(reg$AIC)
 }

For some data, NaN's are produced (in sqrt(diag(vc))), and I'd like to trap
this condition and any other warnings, so that a negative value, say, can be
returned to the calling function to indicate the warning condition.
Warnings from 
summary() are produced and placed in 'last.warning' but that is accessible
only at the top-level, not within usertest(); I've tried setting 'warn' in
options() but hadn't found a way to do this.  I'm still searching various
docs for any ideas, and it seems to be something that might be quite
straightforward.  Any points/ideas are appreciated.   Thanks!


-----Original Message-----
From: Jason Turner [mailto:jasont at indigoindustrial.co.nz]
Sent: Tuesday, April 30, 2002 12:23 PM
To: Boryeu Mao
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] how to trap any warnings from an R function


On Mon, Apr 29, 2002 at 12:43:56PM -0700, Boryeu Mao wrote:
> Within an user function, how are the warnings from an R function be
trapped
> (such that some proper actions can be taken)?  

One way is with try()

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From vograno at arbitrade.com  Tue Apr 30 19:01:39 2002
From: vograno at arbitrade.com (Vadim Ogranovich)
Date: Tue, 30 Apr 2002 12:01:39 -0500
Subject: [R] calling optim from external C/C++ program
Message-ID: <AFD78192EC49D311BFAE00902798AB8F23D93D@JUPITER>

I looked at optim.c in R 1.5.0 and realized that what I actually needed is
to call either vnmin() or lbfgsb(). The interfaces of these functions are
not R-specific (built-in types only) so if I could build R into a shared
library or use the executable itself as a shared library it would do for my
purposes. Is this possible? Where could I start from?

Thanks, Vadim

-----Original Message-----
From: Prof Brian D Ripley [mailto:ripley at stats.ox.ac.uk]
Sent: Monday, April 29, 2002 11:16 PM
To: Vadim Ogranovich
Cc: r-help at stat.math.ethz.ch; 'cyg at sympatico.ca'
Subject: Re: [R] calling optim from external C/C++ program


On Mon, 29 Apr 2002, Vadim Ogranovich wrote:

> Hi,
>
> Does anyone have an example of calling optim() from a standalone C/C++
> program? If possible please include the linker options (I am using gcc
> version 2.96 20000731 (Red Hat Linux 7.1 2.96-98))

It's not possible.  An important part of optim() is in R.  R 1.5.0 makes
the underlying optimizers available to C code linked into R, but they are
only part of optim().

There is also no such thing as gcc 2.96: see gcc.gnu.org.  You would be
well-advised to use a released version of gcc.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
_._

-------------------------------------------------- 
DISCLAIMER 
This e-mail, and any attachments thereto, is intended only for use by the
addressee(s) named herein and may contain legally privileged and/or
confidential information.  If you are not the intended recipient of this
e-mail, you are hereby notified that any dissemination, distribution or
copying of this e-mail, and any attachments thereto, is strictly prohibited.
If you have received this e-mail in error, please immediately notify me and
permanently delete the original and any copy of any e-mail and any printout
thereof. 

E-mail transmission cannot be guaranteed to be secure or error-free.  The
sender therefore does not accept liability for any errors or omissions in
the contents of this message which arise as a result of e-mail transmission.

NOTICE REGARDING PRIVACY AND CONFIDENTIALITY 

Knight Trading Group may, at its discretion, monitor and review the content
of all e-mail communications. 

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr 30 19:00:04 2002
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 30 Apr 2002 18:00:04 +0100 (BST)
Subject: [R] how to trap any warnings from an R function
In-Reply-To: <0957E70F25F7D111974B00A0C9833064AF88C7@mayo.cerep.com>
Message-ID: <Pine.GSO.4.44.0204301756370.14253-100000@auk.stats>

On Tue, 30 Apr 2002, Boryeu Mao wrote:

> Thanks for the reply.  The problem that I have in a nutshell is the
> following:
>
> usertest <- function {
>  ...
>  reg<-polr(act~., data=mm)
>  summary(reg)
>  return(reg$AIC)
>  }
>
> For some data, NaN's are produced (in sqrt(diag(vc))), and I'd like to trap
> this condition and any other warnings, so that a negative value, say, can be
> returned to the calling function to indicate the warning condition.
> Warnings from
> summary() are produced and placed in 'last.warning' but that is accessible
> only at the top-level, not within usertest(); I've tried setting 'warn' in
> options() but hadn't found a way to do this.  I'm still searching various
> docs for any ideas, and it seems to be something that might be quite
> straightforward.  Any points/ideas are appreciated.   Thanks!

To exmpand Jason's suggestion:

options(warn=2)
try(summary(reg))

should do this.  But of course you can test the condition directly, as
it will be in the object returned by summary(reg) (which in your code
sample does nothing useful, as it will not be auto-printed).


>
>
> -----Original Message-----
> From: Jason Turner [mailto:jasont at indigoindustrial.co.nz]
> Sent: Tuesday, April 30, 2002 12:23 PM
> To: Boryeu Mao
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] how to trap any warnings from an R function
>
>
> On Mon, Apr 29, 2002 at 12:43:56PM -0700, Boryeu Mao wrote:
> > Within an user function, how are the warnings from an R function be
> trapped
> > (such that some proper actions can be taken)?
>
> One way is with try()
>
> Cheers
>
> Jason
> --
> Indigo Industrial Controls Ltd.
> 64-21-343-545
> jasont at indigoindustrial.co.nz
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr 30 19:10:29 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 30 Apr 2002 18:10:29 +0100 (BST)
Subject: [R] calling optim from external C/C++ program
In-Reply-To: <AFD78192EC49D311BFAE00902798AB8F23D93D@JUPITER>
Message-ID: <Pine.LNX.4.31.0204301807040.24814-100000@gannet.stats>

On Tue, 30 Apr 2002, Vadim Ogranovich wrote:

> I looked at optim.c in R 1.5.0 and realized that what I actually needed is
> to call either vnmin() or lbfgsb(). The interfaces of these functions are
> not R-specific (built-in types only) so if I could build R into a shared
> library or use the executable itself as a shared library it would do for my
> purposes. Is this possible? Where could I start from?

As I said those interfaces are documented in R-exts, and you can fairly
easily make a standalone version from optim.c and src/appl/lbfgs.c.
You will need to watch calls to error() and R_FINITE and the like, but
suitable substitutes are easy to create (and standalone Rmath may help).

>
> Thanks, Vadim
>
> -----Original Message-----
> From: Prof Brian D Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Monday, April 29, 2002 11:16 PM
> To: Vadim Ogranovich
> Cc: r-help at stat.math.ethz.ch; 'cyg at sympatico.ca'
> Subject: Re: [R] calling optim from external C/C++ program
>
>
> On Mon, 29 Apr 2002, Vadim Ogranovich wrote:
>
> > Hi,
> >
> > Does anyone have an example of calling optim() from a standalone C/C++
> > program? If possible please include the linker options (I am using gcc
> > version 2.96 20000731 (Red Hat Linux 7.1 2.96-98))
>
> It's not possible.  An important part of optim() is in R.  R 1.5.0 makes
> the underlying optimizers available to C code linked into R, but they are
> only part of optim().
>
> There is also no such thing as gcc 2.96: see gcc.gnu.org.  You would be
> well-advised to use a released version of gcc.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272860 (secr)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.
> -.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._.
> _._
>
> --------------------------------------------------
> DISCLAIMER
> This e-mail, and any attachments thereto, is intended only for use by the
> addressee(s) named herein and may contain legally privileged and/or
> confidential information.  If you are not the intended recipient of this
> e-mail, you are hereby notified that any dissemination, distribution or
> copying of this e-mail, and any attachments thereto, is strictly prohibited.
> If you have received this e-mail in error, please immediately notify me and
> permanently delete the original and any copy of any e-mail and any printout
> thereof.
>
> E-mail transmission cannot be guaranteed to be secure or error-free.  The
> sender therefore does not accept liability for any errors or omissions in
> the contents of this message which arise as a result of e-mail transmission.
>
> NOTICE REGARDING PRIVACY AND CONFIDENTIALITY
>
> Knight Trading Group may, at its discretion, monitor and review the content
> of all e-mail communications.
>
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From Sebastien.LAITHIER at poleia.lip6.fr  Tue Apr 30 19:21:45 2002
From: Sebastien.LAITHIER at poleia.lip6.fr (Sebastien LAITHIER)
Date: Tue, 30 Apr 2002 19:21:45 +0200 (CEST)
Subject: [R] Matching a geometric distribution
Message-ID: <Pine.LNX.4.33L2.0204301915030.21606-100000@lapaz.lip6.fr>

Hello,

I'm a newbie with R, I'm using it to work on results of robotic
experiments. I obtained a result that looks like a geometric distribution
(exponential decrease). I would like to know if there is a statistical
test to match my sample with a geometric distribution.
If it exists, does R implements it? If so, how shall I do?

Thanks for answering.

S?bastien Laithier



-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From schlatti at mailer.ukbf.fu-berlin.de  Tue Apr 30 19:35:47 2002
From: schlatti at mailer.ukbf.fu-berlin.de (Dr. Peter Schlattmann)
Date: Tue, 30 Apr 2002 19:35:47 +0200 (CEST)
Subject: [R] update from 1.41. to 1.5.0
Message-ID: <Pine.LNX.4.21.0204301933030.14790-100000@postamt.ukbf.fu-berlin.de>

Dear all,

one perhaps stuoid question: If I want to update from 1.4.1 to 1.5.0
under Linux do I not to rebuild the whole software from scratch or is
there an update mechanism as in "update.packages" ?

Thanks a lot

Peter


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thoar at cgd.ucar.edu  Tue Apr 30 19:38:39 2002
From: thoar at cgd.ucar.edu (Tim Hoar)
Date: Tue, 30 Apr 2002 11:38:39 -0600 (MDT)
Subject: [R] JPEG library wierdness
Message-ID: <Pine.GSO.4.30.0204300953450.8805-100000@sunray1>


I am having a problem creating JPEG's ... but just lately

I had 1.3.1 installed properly on a Solaris 2.6 platform and everything
was working fine UNTIL last Wednesday, when I issued the fateful
update.packages()
and went to lunch.

When I came back, one of my cohorts informed me he could no longer
create jpeg's in the fashion he was accustomed:

> X11()
> plot(1:10)
> dev.print(jpeg, file="~/test.jpg")
Wrong JPEG library version: library is 61, caller expects 62X11
  2
>

I have been unable to track down the offending library (in hopes of
reinstalling the previous version) and nothing I have found mentions any
sort of dependency for a newer version of the jpeg library.

To make matters worse ... I built 1.5.0 on the same Solaris 2.6 system
last night ... and it has the same behaviour.

Any help?


More hints (this time with png):

> dev.print(png, file="~/test.png")

creates a bad (short) png file ...

> png()
> plot(1:10)
> dev.off()
null device
          1
> plot(1:10)
> dev.print(png,file="test.png")
X11
  2
> dev.off()
null device
          1

results in two very different files:

-rw-r--r--   1 thoar    cgdcas      1804 Apr 30 11:34 Rplot.png
-rw-r--r--   1 thoar    cgdcas        92 Apr 30 11:35 test.png

Sincerely -- Tim

## Tim Hoar, Associate Scientist              email: thoar at ucar.edu     ##
## Geophysical Statistics Project             phone: 303-497-1708       ##
## National Center for Atmospheric Research   FAX  : 303-497-1333       ##
## Boulder, CO  80307                    http://www.cgd.ucar.edu/~thoar ##

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr 30 19:43:45 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 30 Apr 2002 18:43:45 +0100 (BST)
Subject: [R] update from 1.41. to 1.5.0
In-Reply-To: <Pine.LNX.4.21.0204301933030.14790-100000@postamt.ukbf.fu-berlin.de>
Message-ID: <Pine.LNX.4.31.0204301840390.25168-100000@gannet.stats>

On Tue, 30 Apr 2002, Dr. Peter Schlattmann wrote:

> Dear all,
>
> one perhaps stuoid question: If I want to update from 1.4.1 to 1.5.0
> under Linux do I not to rebuild the whole software from scratch or is
> there an update mechanism as in "update.packages" ?

Actually, all update.packages does is to work out which packages have
changed, download and rebuild those from scratch.

You need to rebuild from scratch.  This if far too big a change to be
upgradeable.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Tue Apr 30 19:56:03 2002
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 30 Apr 2002 18:56:03 +0100 (BST)
Subject: [R] JPEG library wierdness
In-Reply-To: <Pine.GSO.4.30.0204300953450.8805-100000@sunray1>
Message-ID: <Pine.LNX.4.31.0204301845560.25168-100000@gannet.stats>

On Tue, 30 Apr 2002, Tim Hoar wrote:

>
> I am having a problem creating JPEG's ... but just lately
>
> I had 1.3.1 installed properly on a Solaris 2.6 platform and everything
> was working fine UNTIL last Wednesday, when I issued the fateful
> update.packages()
> and went to lunch.
>
> When I came back, one of my cohorts informed me he could no longer
> create jpeg's in the fashion he was accustomed:
>
> > X11()
> > plot(1:10)
> > dev.print(jpeg, file="~/test.jpg")
> Wrong JPEG library version: library is 61, caller expects 62X11
>   2
> >
>
> I have been unable to track down the offending library (in hopes of
> reinstalling the previous version) and nothing I have found mentions any
> sort of dependency for a newer version of the jpeg library.

No R package can change what jpeg version R is using: that is coming from
the module R_X11.so.  And the library it is finding is a very old one
(years old).

Has perchance someone has downdated the jpeg shared library in your
LD_LIBRARY_PATH?
>
> To make matters worse ... I built 1.5.0 on the same Solaris 2.6 system
> last night ... and it has the same behaviour.
>
> Any help?

Your jpeg header and library don't match.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From thoar at cgd.ucar.edu  Tue Apr 30 19:58:18 2002
From: thoar at cgd.ucar.edu (Tim Hoar)
Date: Tue, 30 Apr 2002 11:58:18 -0600 (MDT)
Subject: [R] R-1.5.0 and JPEG
Message-ID: <Pine.GSO.4.30.0204301153050.8805-100000@sunray1>


Upon more digging,

the R-1.5.0 install html document mentions needing
"... jpeg (version 6b or later) or libpng (versions 1.0.5 to 1.2.1) and
zlib (version 1.1.3 or later) respectively.  libpng-1.2.2 has moved its
header files, and you will need add something
like -I/usr/local/include/libpng12 to CPPFLAGS to make use of it."

I just wanted to confirm that the jpeg library we have is, in fact,
/contrib/libjpeg_v6b/lib/libjpeg.a

and the version of the png library we have is
/contrib/libpng-1.0.12/lib/libpng.a

I built 1.3.1 with  the config.site set to:
LIBS="-xlic_lib=sunperf -lpng -ljpeg"

I had never gotten it to build correctly with zlib ...

Tim

## Tim Hoar, Associate Scientist              email: thoar at ucar.edu     ##
## Geophysical Statistics Project             phone: 303-497-1708       ##
## National Center for Atmospheric Research   FAX  : 303-497-1333       ##
## Boulder, CO  80307                    http://www.cgd.ucar.edu/~thoar ##

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From smcnary at fellspt.charm.net  Tue Apr 30 20:12:30 2002
From: smcnary at fellspt.charm.net (Scot W McNary)
Date: Tue, 30 Apr 2002 14:12:30 -0400 (EDT)
Subject: [R] custom tick mark labels on bwplot
In-Reply-To: <000701c1f015$26635cb0$4c16e6a5@jetsky>
Message-ID: <Pine.BSI.4.40.0204301407410.10412-100000@fellspt.charm.net>


Hi,

I could use some help figuring out how to make some more useful tickmark
labels in a set of box and whisker plots I've made.  I'm really happy with
the bwplot code I'm using (borrowed heavily from examples) as it gives me
three sets of boxplots for each group (sourcedx) across seven variables
(X.NAME) all on the same page.  The problem is, I'd like to label the sets
of tickmarks with something less cumbersome than the original variable
labels (X.LABEL).

I've been playing around with strsplit:

lab1<-unlist(strsplit(milk$X.LABEL, "-"))

to try to get the label to pull off the part of X.LABEL before the

"- times/month" or "- times/mo"

that appears in each label.  That should give me a shorter but still
sufficiently descriptive label.

However, I can't seem to figure out how to get just that first part, since
what I end up with is a list:

[1] "Chocolate milk and hot cocoa "  " times/mo"
"Milk to drink or on cereal "
[4] " times/month"                   "Yogurt and frozen yogurt "      "
times/month"
[7] "Ice cream,ice milk,milkshakes "

Do I then figure out how to pick elements out of the list, or is there a
better way to trim a character variable?



My dataset (milk) looks like this:

     id X.NAME.                                 X.LABEL. amt1 sourcedx
nh10000  HAN1AS  Chocolate milk and hot cocoa - times/mo    0.00 NHANE
nh10000  HAN1BS Milk to drink or on cereal - times/month   30.00 NHANE
nh10000  HAN1ES   Yogurt and frozen yogurt - times/month    0.00 NHANE
nh10000  HAN1FS Ice cream,ice milk,milkshakes - times/mo    4.00 NHANE
nh10000  HAN1GS          Cheese, all types - times/month   17.00 NHANE
nh10000  HAN1HS    Pizza, calzone, lasagna - times/month    0.00 NHANE
nh10000  HAN1IS              Cheese dishes - times/month    3.00 NHANE
sp60048  HAN1AS  Chocolate milk and hot cocoa - times/mo    0.00 SOCOp
sp60048  HAN1BS Milk to drink or on cereal - times/month   30.40 SOCOp
sp60048  HAN1ES   Yogurt and frozen yogurt - times/month    0.00 SOCOp
sp60048  HAN1FS Ice cream,ice milk,milkshakes - times/mo    2.00 SOCOp
sp60048  HAN1GS          Cheese, all types - times/month   30.40 SOCOp
sp60048  HAN1HS    Pizza, calzone, lasagna - times/month    2.00 SOCOp
sp60048  HAN1IS              Cheese dishes - times/month    1.00 SOCOp
sa30007  HAN1AS  Chocolate milk and hot cocoa - times/mo   12.90 SOCOa
sa30007  HAN1BS Milk to drink or on cereal - times/month   60.80 SOCOa
sa30007  HAN1ES   Yogurt and frozen yogurt - times/month    NA   SOCOa
sa30007  HAN1FS Ice cream,ice milk,milkshakes - times/mo   30.40 SOCOa
sa30007  HAN1GS          Cheese, all types - times/month    0.00 SOCOa
sa30007  HAN1HS    Pizza, calzone, lasagna - times/month    0.00 SOCOa
sa30007  HAN1IS              Cheese dishes - times/month    4.00 SOCOa
sa30009  HAN1AS  Chocolate milk and hot cocoa - times/mo    0.00 SOCOa

Thanks,

Scot



--
  Scot W. McNary  email:smcnary at charm.net


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From a296180 at mica.fmr.com  Tue Apr 30 21:13:39 2002
From: a296180 at mica.fmr.com (David Kane  <David Kane)
Date: Tue, 30 Apr 2002 15:13:39 -0400
Subject: [R] display of character NA's in a dataframe in 1.5.0
Message-ID: <15566.60643.146231.944462@gargle.gargle.HOWL>

Thanks to Douglas Bates, Brian Ripley and Don MacQueen for taking the time to
answer my question. I think that Doug Bates puts it best when he writes:

>The difference in the display of character NA's is according to
>whether the quote option is on.  By default it is on for character
>vectors, so an NA is displayed as NA and the character string "NA" is
>displayed as "NA", and off for data frames, so an NA is displayed as
><NA> and the character string "NA" is displayed as NA.

So, in my example, we can see:

> c("x", NA, "y")
[1] "x" NA  "y"
> print(c("x", NA, "y"), quote = FALSE)
[1] x    <NA> y   
> data.frame(a = c("x", NA, "y"))
     a
1    x
2   <NA>
3    y
> print(data.frame(a = c("x", NA, "y")), quote = TRUE)
    a
1 "x"
2  NA
3 "y"

As best I can tell, this is not an "option," in the sense of something that the
user can set with options(). That is, unless you want to override the default
print methods, the display will be different for vectors and for
dataframes. There was also information about this in the NEWS file for 1.5.0.

Thanks to all,

Dave Kane
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From klavan at tiscalinet.it  Tue Apr 30 21:32:21 2002
From: klavan at tiscalinet.it (Ambrosini Alessandro)
Date: Tue, 30 Apr 2002 21:32:21 +0200
Subject: [R] A sample question
Message-ID: <PPEGLLABFLFCJDLCGPGHCEIPCAAA.klavan@tiscalinet.it>

Hello.
Given a vector 1 3 4 2 8 9 5
I want to obtain a vector with all 0 except in the second position and in
the fifth, where the numbers are the same of the first vector.
The new vector must be
 0 3 0 0 8 0 0

Thank you very much.
Excuseme but my mind is out of order.
Alessandro

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From deepayansarkar at yahoo.com  Tue Apr 30 21:46:03 2002
From: deepayansarkar at yahoo.com (Deepayan Sarkar)
Date: Tue, 30 Apr 2002 12:46:03 -0700 (PDT)
Subject: [R] custom tick mark labels on bwplot
In-Reply-To: <Pine.BSI.4.40.0204301407410.10412-100000@fellspt.charm.net>
Message-ID: <20020430194603.88855.qmail@web13906.mail.yahoo.com>


--- Scot W McNary <smcnary at fellspt.charm.net> wrote:
> 
> Hi,
> 
> I could use some help figuring out how to make some more useful tickmark
> labels in a set of box and whisker plots I've made.  I'm really happy with
> the bwplot code I'm using (borrowed heavily from examples) as it gives me
> three sets of boxplots for each group (sourcedx) across seven variables
> (X.NAME) all on the same page.  The problem is, I'd like to label the sets
> of tickmarks with something less cumbersome than the original variable
> labels (X.LABEL).
> 
> I've been playing around with strsplit:
> 
> lab1<-unlist(strsplit(milk$X.LABEL, "-"))
> 
> to try to get the label to pull off the part of X.LABEL before the
> 
> "- times/month" or "- times/mo"
> 
> that appears in each label.  That should give me a shorter but still
> sufficiently descriptive label.
> 
> However, I can't seem to figure out how to get just that first part, since
> what I end up with is a list:


unlist(lapply(strsplit(dtf$X.LABEL, "-"), "[", 1))

seems to work. abbreviate() can abbreviate strings, but the results
might not be informative enough.


> [1] "Chocolate milk and hot cocoa "  " times/mo"
> "Milk to drink or on cereal "
> [4] " times/month"                   "Yogurt and frozen yogurt "      "
> times/month"
> [7] "Ice cream,ice milk,milkshakes "
> 
> Do I then figure out how to pick elements out of the list, or is there a
> better way to trim a character variable?
> 
> 
> 
> My dataset (milk) looks like this:
> 
>      id X.NAME.                                 X.LABEL. amt1 sourcedx
> nh10000  HAN1AS  Chocolate milk and hot cocoa - times/mo    0.00 NHANE
> nh10000  HAN1BS Milk to drink or on cereal - times/month   30.00 NHANE
> nh10000  HAN1ES   Yogurt and frozen yogurt - times/month    0.00 NHANE
> nh10000  HAN1FS Ice cream,ice milk,milkshakes - times/mo    4.00 NHANE
> nh10000  HAN1GS          Cheese, all types - times/month   17.00 NHANE
> nh10000  HAN1HS    Pizza, calzone, lasagna - times/month    0.00 NHANE
> nh10000  HAN1IS              Cheese dishes - times/month    3.00 NHANE
> sp60048  HAN1AS  Chocolate milk and hot cocoa - times/mo    0.00 SOCOp
> sp60048  HAN1BS Milk to drink or on cereal - times/month   30.40 SOCOp
> sp60048  HAN1ES   Yogurt and frozen yogurt - times/month    0.00 SOCOp
> sp60048  HAN1FS Ice cream,ice milk,milkshakes - times/mo    2.00 SOCOp
> sp60048  HAN1GS          Cheese, all types - times/month   30.40 SOCOp
> sp60048  HAN1HS    Pizza, calzone, lasagna - times/month    2.00 SOCOp
> sp60048  HAN1IS              Cheese dishes - times/month    1.00 SOCOp
> sa30007  HAN1AS  Chocolate milk and hot cocoa - times/mo   12.90 SOCOa
> sa30007  HAN1BS Milk to drink or on cereal - times/month   60.80 SOCOa
> sa30007  HAN1ES   Yogurt and frozen yogurt - times/month    NA   SOCOa
> sa30007  HAN1FS Ice cream,ice milk,milkshakes - times/mo   30.40 SOCOa
> sa30007  HAN1GS          Cheese, all types - times/month    0.00 SOCOa
> sa30007  HAN1HS    Pizza, calzone, lasagna - times/month    0.00 SOCOa
> sa30007  HAN1IS              Cheese dishes - times/month    4.00 SOCOa
> sa30009  HAN1AS  Chocolate milk and hot cocoa - times/mo    0.00 SOCOa
> 
> Thanks,
> 
> Scot
> 
> 
> 
> --
>   Scot W. McNary  email:smcnary at charm.net
> 
> 
>
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
>
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


__________________________________________________

Yahoo! Health - your guide to health and wellness

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jsw9c at virginia.edu  Tue Apr 30 20:01:35 2002
From: jsw9c at virginia.edu (John S. Walker)
Date: Tue, 30 Apr 2002 14:01:35 -0400
Subject: [R] What am I doing wrong with xyplot?
Message-ID: <20020430140135.0e9b47ea.jsw9c@virginia.edu>

G'day

I was playing around with R trying out some of the plotting functions when I came across
what may be a bug in xyplot or (more likely) me doing something wrong.

try this:
	x<-1:10
 	y<-sin(x)   #yes I know it's an under sampled function
	xyplot(y~x)
	lines(x,y)  #at this point the lines do not lay on the xypoints
	spline(x,y)
	points(x,y)  # in my installation the points(x,y) do not lay on the xyplot points

My version is the latest available from debian (Version 1.5.0 Under development (unstable)
(2002-03-30)). Does anybody else see this?

John Walker

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From jsw9c at virginia.edu  Tue Apr 30 20:07:58 2002
From: jsw9c at virginia.edu (John S. Walker)
Date: Tue, 30 Apr 2002 14:07:58 -0400
Subject: Re [R] What am I doing wrong with xyplot?
Message-ID: <20020430140758.23d4b132.jsw9c@virginia.edu>

G'day

A quick followup is that it doesn't always happen. I managed to reproduce it on a fresh start-up 
by adding the two lines indicated by arrows 

try this:
	x<-1:10
 	y<-sin(x)   #yes I know it's an under sampled function
   ->	plot(x,y)    ###These two lines are required to reproduce the 
   ->	lines(x,y)   ### behaviour
	xyplot(y~x)
	lines(x,y)  #at this point the lines do not lay on the xypoints
	spline(x,y)
	points(x,y)  # in my installation the points(x,y) do not lay on the xyplot points

John Walker

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From rangrej at exchange.cheo.on.ca  Tue Apr 30 22:10:18 2002
From: rangrej at exchange.cheo.on.ca (Rangrej, Jagadish)
Date: Tue, 30 Apr 2002 16:10:18 -0400
Subject: [R] Organizing the help files in a package
Message-ID: <A032D3A4B7F0D411B9360008C71E3DA5038D4CFB@CHEONT3>

Hello all

thanks to Uwe for helping me resolve the issue of organizing help files.
Though the solution didn't work on Win98 it worked on win2000.

once again thanks to everybody who thought over the issue.

-Jag

> -----Original Message-----
> From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
> Sent: Monday, April 29, 2002 2:00 PM
> To: Rangrej, Jagadish
> Cc: r-help
> Subject: Re: [R] Organizing the help files in a package
> 
> 
> "Rangrej, Jagadish" wrote:
> > 
> > Hi Uwe!!!
> > 
> > thanks for the reply,
> > 
> > I have two question:
> > 1. I am getting error of "bad command.." when I run:
> >    C:\......>rcmd install pubbias
> >       done till contians
> >       making ....
> >       Bad command or file name
> >       ...else part..
> > 
> >    Which I found out, is due to "make" command, I suppose 
> my computer(win
> > 98)
> >    does not have make facility... where can i get that, if not can i
> >    have any workaround method for it.
> > 
> > 2. I have installed full binary of R1.4.1 for 
> "developers..", I suppose
> >    the way it forms the zipped file is some what looks like 
> unix type
> >    .tar.gz, I don't have tar appln in my machine, what should I do ?
> > 
> > I'd appreciate any pointers too...
> > thanking you and all,
> > -jag
> 
> Answer on both question as already mentioned: 
> "For details please read the manual 'Writing R Extensions'".
> 
> What tools you'll need on Windows is also described at:
> http://www.stats.ox.ac.uk/pub/Rtools/
> You should also take a look into the files "Install", "readme" and
> "readme.packages" in the ....\src\gnuwin32\  directory.
> 
> Uwe Ligges
> 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From klavan at tiscalinet.it  Tue Apr 30 22:15:18 2002
From: klavan at tiscalinet.it (Ambrosini Alessandro)
Date: Tue, 30 Apr 2002 22:15:18 +0200
Subject: [R] I: A sample question
Message-ID: <PPEGLLABFLFCJDLCGPGHIEIPCAAA.klavan@tiscalinet.it>


I solved the problem. Excuseme for the disturb.
Alessandro

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From charlieairspace at hotmail.com  Tue Apr 30 22:32:59 2002
From: charlieairspace at hotmail.com (Bryan Moss)
Date: Tue, 30 Apr 2002 16:32:59 -0400
Subject: [R] Examples of hypothesis testing Bryan Moss
Message-ID: <F287doLdJrs4QqIwTFg0000541d@hotmail.com>

An HTML attachment was scrubbed...
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20020430/a3cca3fc/attachment.html

From simon_cawley at affymetrix.com  Tue Apr 30 22:51:20 2002
From: simon_cawley at affymetrix.com (Simon Cawley)
Date: Tue, 30 Apr 2002 13:51:20 -0700 (PDT)
Subject: [R] generating graphical output when DISPLAY is not set?
Message-ID: <Pine.LNX.4.33.0204301341580.3566-100000@luino.neomorphic.com>


Is it possible to generate graphical output (to a file) when the
DISPLAY environment variable is not set?  Here's the problem:

  $ unset DISPLAY
  $ R
  > png("foo.png")
  Error in X11(paste("png::", filename, sep = ""), width, height, pointsize,  :
          unable to start device PNG
  In addition: Warning message:
  unable to open connection to X11 display`'

I want to have a process running on a server call R to generate graphical
output, and the problem is that I'm not guaranteed to have a valid
DISPLAY set.  I have some clumsy workarounds, but it would be cleaner if
if I had some way to have R not require the DISPLAY.

Thanks,

-Simon

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Apr 30 23:00:34 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 30 Apr 2002 23:00:34 +0200
Subject: [R] A sample question
In-Reply-To: <PPEGLLABFLFCJDLCGPGHCEIPCAAA.klavan@tiscalinet.it>
References: <PPEGLLABFLFCJDLCGPGHCEIPCAAA.klavan@tiscalinet.it>
Message-ID: <x28z74oqa5.fsf@blueberry.kubism.ku.dk>

"Ambrosini Alessandro" <klavan at tiscalinet.it> writes:

> Hello.
> Given a vector 1 3 4 2 8 9 5
> I want to obtain a vector with all 0 except in the second position and in
> the fifth, where the numbers are the same of the first vector.
> The new vector must be
>  0 3 0 0 8 0 0
> 
> Thank you very much.
> Excuseme but my mind is out of order.
> Alessandro

y <- x
y[-c(2,5)] <- 0

or

y <- ifelse(1:7 %in% c(2,5), x, 0)

or

y <- rep(0,length(x))
y[c(2,5)] <- x[c(2,5)]

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From smcnary at fellspt.charm.net  Tue Apr 30 23:31:04 2002
From: smcnary at fellspt.charm.net (Scot W McNary)
Date: Tue, 30 Apr 2002 17:31:04 -0400 (EDT)
Subject: [R] custom tick mark labels on bwplot
In-Reply-To: <20020430194603.88855.qmail@web13906.mail.yahoo.com>
Message-ID: <Pine.BSI.4.40.0204301729550.2697-100000@fellspt.charm.net>


That does it!  Thanks, Scot


On Tue, 30 Apr 2002, Deepayan Sarkar wrote:

> > I've been playing around with strsplit:
> >
> > lab1<-unlist(strsplit(milk$X.LABEL, "-"))
> >
> > to try to get the label to pull off the part of X.LABEL before the
> >
> > "- times/month" or "- times/mo"
> >
> > that appears in each label.  That should give me a shorter but still
> > sufficiently descriptive label.
> >
> > However, I can't seem to figure out how to get just that first part, since
> > what I end up with is a list:
>
>
> unlist(lapply(strsplit(dtf$X.LABEL, "-"), "[", 1))
>
> seems to work. abbreviate() can abbreviate strings, but the results
> might not be informative enough.
>
>

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From p.dalgaard at biostat.ku.dk  Tue Apr 30 23:32:38 2002
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 30 Apr 2002 23:32:38 +0200
Subject: [R] generating graphical output when DISPLAY is not set?
In-Reply-To: <Pine.LNX.4.33.0204301341580.3566-100000@luino.neomorphic.com>
References: <Pine.LNX.4.33.0204301341580.3566-100000@luino.neomorphic.com>
Message-ID: <x2znzkna89.fsf@blueberry.kubism.ku.dk>

Simon Cawley <simon_cawley at affymetrix.com> writes:

> I want to have a process running on a server call R to generate graphical
> output, and the problem is that I'm not guaranteed to have a valid
> DISPLAY set.  I have some clumsy workarounds, but it would be cleaner if
> if I had some way to have R not require the DISPLAY.

The png() driver takes its fonts from the X server pointed to by
DISPLAY, so no-go. However:

If you have ghostscript, you can use the bitmap() driver. (This *is*
on the help page for png()!)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From tklistaddr at keittlab.bio.sunysb.edu  Tue Apr 30 23:49:38 2002
From: tklistaddr at keittlab.bio.sunysb.edu (Timothy H. Keitt)
Date: 30 Apr 2002 17:49:38 -0400
Subject: [R] A sample question
In-Reply-To: <PPEGLLABFLFCJDLCGPGHCEIPCAAA.klavan@tiscalinet.it>
References: <PPEGLLABFLFCJDLCGPGHCEIPCAAA.klavan@tiscalinet.it>
Message-ID: <1020203378.24329.1.camel@keittlab-6>

Try

x <- 1:10
x[-c(2,5)] <- 0


T.

On Tue, 2002-04-30 at 15:32, Ambrosini Alessandro wrote:
> Hello.
> Given a vector 1 3 4 2 8 9 5
> I want to obtain a vector with all 0 except in the second position and in
> the fifth, where the numbers are the same of the first vector.
> The new vector must be
>  0 3 0 0 8 0 0
> 
> Thank you very much.
> Excuseme but my mind is out of order.
> Alessandro
> 
> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
> r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
> Send "info", "help", or "[un]subscribe"
> (in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
> _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._

-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


From arc at arcriswell.com  Thu Apr 11 18:41:27 2002
From: arc at arcriswell.com (Andrew Criswell)
Date: Fri, 11 Apr 2002 12:41:27 -0400
Subject: [R] Ordinal categorical data with GLM
Message-ID: <3E96F037.60105@arcriswell.com>

Hello All:

I am trying to replicate the results of an example found in Alan 
Agresti's "Categorical Data Analysis" on pages 267-269. The example is 
one of a 2 x 2 cross-classification table of ordinal counts: job 
satisfaction and income.

I am able to get Agresti's results for the independence model (G^2 = 
12.03 with df = 9) assuming as he does that the data is nominal, but I'm 
unable to derive his model of uniform association (linear-by-linear 
association, p. 263-269) for which he gets a value of G^2 = 2.39 with df 
= 8.

The observed data is represented by table 8.2 on page 268 as follows:

 > Freq <- c(20, 24,  80,  82,
+           22, 38, 104, 125,
+           13, 28,  81, 113,
+            7, 18,  54,  92)
 >
 > data.3 <- t(matrix(Freq, nrow = 4))
 >
 > list.3 <- list(Income       = c("< 6,000",
+                                 "6,000-15,000",
+                                 "15,000-25,000",
+                                 "> 25,000"),
+                Satisfaction = c("Very dissatisfied",
+                                 "Little dissatisfied",
+                                 "Moderately satisfied",
+                                 "Very satisfied"))
 >
 > dimnames(data.3) <- list.3
 >
 > ftable(data.3)
              Satisfaction Very dissatisfied Little dissatisfied 
Moderately satisfied Very satisfied
Income                                                                                              

< 6,000                                   20                  
24                   80             82
6,000-15,000                              22                  
38                  104            125
15,000-25,000                             13                  
28                   81            113
 > 25,000                                   7                  
18                   54             92
 >

I am able to obtain Agresti's results for the independence model which 
assumes the data is nominal, not ordinal, using either glm() or loglm().

 > library(MASS)
 > options(contrasts=c("contr.sum", "contr.poly"))
 >
 > X <- as.integer(gl(4, 4, 16)) - 1
 > Y <- as.integer(gl(4, 1, 16)) - 1
 >
 > data.2 <- data.frame(Freq, X = factor(X), Y = factor(Y))
 >
 > summary(fm3 <- glm(Freq ~ X + Y, data = data.2,
+                    family = poisson()))

Call:
glm(formula = Freq ~ X + Y, family = poisson(), data = data.2)

Deviance Residuals:
     Min        1Q    Median        3Q       Max 
-1.50416  -0.67501  -0.08592   0.53800   1.51852 

Coefficients:
            Estimate Std. Error z value Pr(>|z|)   
(Intercept)  3.74425    0.04444  84.259  < 2e-16 ***
X1          -0.07101    0.05982  -1.187    0.235   
X2           0.26754    0.05368   4.984 6.22e-07 ***
X3           0.06070    0.05726   1.060    0.289   
Y1          -1.02174    0.09995 -10.222  < 2e-16 ***
Y2          -0.46674    0.08101  -5.761 8.35e-09 ***
Y3           0.61632    0.05917  10.416  < 2e-16 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 445.763  on 15  degrees of freedom
Residual deviance:  12.037  on  9  degrees of freedom
AIC: 115.07

Number of Fisher Scoring iterations: 3

 > dummy.coef(fm3)
Full coefficients are
                                                              
(Intercept):       3.744253                                   
X:                        0           1           2           3
                -0.07101181  0.26753870  0.06069753 -0.25722441
Y:                        0           1           2           3
                 -1.0217353  -0.4667389   0.6163210   0.8721532
 >
 > fm4 <- loglm(Freq ~ X + Y, data = data.2, param = T, fit = T)
 > fm4;  fm4$param
Call:
loglm(formula = Freq ~ X + Y, data = data.2, param = T, fit = T)

Statistics:
                      X^2 df  P(> X^2)
Likelihood Ratio 12.03686  9 0.2112391
Pearson          11.98857  9 0.2139542
$"(Intercept)"
[1] 3.744253

$X
          0           1           2           3
-0.07101181  0.26753871  0.06069753 -0.25722443

$Y
         0          1          2          3
-1.0217356 -0.4667388  0.6163211  0.8721533

 >

My question is this:  can glm() or some other function be used in the 
manner Agresti employed for ordinal count data?

Thank you,
ANDREW

Andrew Criswell
Professor of Finance
Graduate School
Bangkok University


-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
r-help mailing list -- Read http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html
Send "info", "help", or "[un]subscribe"
(in the "body", not the subject !)  To: r-help-request at stat.math.ethz.ch
_._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._


